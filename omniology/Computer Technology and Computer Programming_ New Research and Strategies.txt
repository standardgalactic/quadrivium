Computer Technology and 
Computer Programming
New Research and Strategies
James L. Antonakos
Distinguished Professor of Computer Science,  
Broome Community College, State University of New York,  
Binghamton; Online Instructor and Faculty Advisor, Excelsior College,  
Albany, New York and Sullivan University, Kentucky, U.S.A.
Apple Academic Press
© 2011 by Apple Academic Press, Inc.

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
Apple Academic Press, Inc
3333 Mistwell Crescent
Oakville, ON L6L 0A2
Canada
© 2011 by Apple Academic Press, Inc.
Exclusive worldwide distribution by CRC Press an imprint of Taylor & Francis Group, an Informa 
business
No claim to original U.S. Government works
Version Date: 20120813
International Standard Book Number-13: 978-1-4665-6259-2 (eBook - PDF)
This book contains information obtained from authentic and highly regarded sources. Reasonable 
efforts have been made to publish reliable data and information, but the author and publisher cannot 
assume responsibility for the validity of all materials or the consequences of their use. The authors and 
publishers have attempted to trace the copyright holders of all material reproduced in this publication 
and apologize to copyright holders if permission to publish in this form has not been obtained. If any 
copyright material has not been acknowledged please write and let us know so we may rectify in any 
future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, 
transmitted, or utilized in any form by any electronic, mechanical, or other means, now known or 
hereafter invented, including photocopying, microfilming, and recording, or in any information stor-
age or retrieval system, without written permission from the publishers.
For permission to photocopy or use material electronically from this work, please access www.copy-
right.com (http://www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 
Rosewood Drive, Danvers, MA 01923, 978-750-8400. CCC is a not-for-profit organization that pro-
vides licenses and registration for a variety of users. For organizations that have been granted a pho-
tocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are 
used only for identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com
For information about Apple Academic Press product
http://www.appleacademicpress.com
© 2011 by Apple Academic Press, Inc.
  

Contents
	
Introduction	
7
  1.	 Novel FTLRNN with Gamma Memory for Short-Term 	
9 
and Long-Term Predictions of Chaotic Time Series
	
Sanjay L. Badjate and Sanjay V. Dudu
  2.	 Flexible Interconnection Network for Dynamically and 	
50 
Partially Reconfigurable Architectures
	
Ludovic Devaux, Sana Ben Sassi, Sebastien Pillement,  
Daniel Chillet and Didier Demigny
  3.	 A Hardware Solution for an “On the Fly” Encryption 	
82
	
Daniel Filipas
  4.	 SQL Generation for Natural Language Interface 	
90
	
László Kovács 
  5.	 Web 2.0 Technologies with jQuery and Ajax 	
99
	
Cornelia Györödi, Robert Györödi, George Pecherle, Tamas Lorand  
and Rosu Alin 
  6.	 Reconfigurable Computing—A New Paradigm	
111
	
Erica Mang, Ioan Mang and Popescu-Rotoiu Constantin
© 2011 by Apple Academic Press, Inc.
  

6  Computer Technology and Computer Programming: New Research and Strategies
  7.	 In-Network Adaptation of Video Streams Using Network Processors	
125
	
Mohammad Shorfuzzaman, Rasit Eskicioglu and Peter Graham
  8.	 A Survey of Visual Sensor Networks	
168	
Stanislava Soro and Wendi Heinzelman
  9.	 A Family of Tools for Supporting the Learning of Programming 	
213
	
Guido Rößling 
10.	 InfoVis Interaction Techniques in Animation of Recursive Programs 	 231
	
J. Ángel Velázquez-Iturbide and Antonio Pérez-Carrasco
11.	 Towards a Serious Game to Help Students Learn 	
250 
Computer Programming
	
Mathieu Muratet, Patrice Torguet, Jean-Pierre Jesse and  
Fabienne Viallet
12.	 Distributed Network, Wireless and Cloud Computing Enabled 	
276 
3-D Ultrasound; a New Medical Technology Paradigm
	
Arie Meir and Boris Rubinsky
13.	 miRMaid: A Unified Programming Interface for Microrna 	
293 
Data Resources
	
Anders Jacobsen, Anders Krogh, Sakari Kauppinen and Morten Lindow
14.	 Some Attributes of a Language for Property-Based Testing	
306
	
Matt Bishop and Vicentiu Neagoe
	
Index	
327
© 2011 by Apple Academic Press, Inc.
  

introduction
What I find most remarkable about the field of computer science is its vast scope. 
Practically any topic you might imagine falls in some way under the umbrella 
of computer science. Many topics may seem to naturally belong there, such as 
research into advanced computer architectures, distributed and cloud computing 
(and their associated high-speed networking components), computer forensics, 
operating systems, and the details of many different programming languages. But 
these areas are just a few of a wider array of topics and activities found in com-
puter science. Computer scientists spend a great deal of time and energy study-
ing compression algorithms for images, video, and data; encryption techniques; 
efficient hardware computation pipelines; computer gaming and its associated 
artificial intelligence; networking protocols that enable secure and reliable trans-
mission of information; image processing; database technologies; and new ways 
of sharing information over the Internet.
Of course, many areas of computer science require a good foundation in 
mathematics. Here it is remarkable to know that we use mathematics to prove 
that some things are possible and that other things are impossible. Some concepts 
or problems have not yet been proved either way, even with a great many research-
ers looking into them. When and if these open problems are eventually solved, 
the solutions will usher in a new age in computer science and also new challenges. 
For example, if we gain a deeper insight and understanding of random numbers, 
what will be the effect on the security algorithms we use every day to encrypt our 
private communication over the Internet?
© 2011 by Apple Academic Press, Inc.

8  Computer Technology and Computer Programming: New Research and Strategies
Let us also take note of the astounding visual reality now available, of com-
puter graphics algorithms so complex they render stunning visual effects in video 
games in real time and produce “Is it real or computer generated?” effects in mo-
tion pictures. Again, here the computer scientist must have programming skills, 
knowledge of mathematics, physics, optics, and the hardware details of the pro-
cessor or processors rendering the image. We can see for ourselves the fruits of 
many researchers’ labors over the years.
The time spent by computer scientists examining arcane topics that appear to 
have little practical application is very misleading. Advances in medical imaging, 
understanding biological processes, recognizing human speech, mining data and 
distinguishing patterns, and exploring the nature of memory via neural networks 
have all been made possible by computer scientists toiling away in their labs.
Today the line between software and hardware is becoming blurred. A com-
puter scientist crafting a new optimizing compiler must have detailed knowledge 
of the internal hardware workings of a processor in order to efficiently schedule 
instructions and generate code that utilizes the processor pipeline, registers, and 
cache memory to provide maximum performance. Even something as simple as 
extending the life of the battery in a laptop computer is a combined effort be-
tween the hardware designers and the software writers.
Perhaps the most important quality a computer scientist can possess is curi-
osity, a constant desire to understand how things work. When this curiosity is 
coupled with determination, the end result is often useful in ways that were not 
originally intended. Keep this curiosity in mind as you read the papers on Com-
puter Technology and Computer Programming contained within this book.
— James L. Antonakos
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma 
Memory for Short-Term and 
Long-Term Predictions of 
Chaotic Time Series
Sanjay L. Badjate and Sanjay V. Dudu
Abstract
Multistep ahead prediction of a chaotic time series is a difficult task that has 
attracted increasing interest in the recent years. The interest in this work is 
the development of nonlinear neural network models for the purpose of build-
ing multistep chaotic time series prediction. In the literature there is a wide 
range of different approaches but their success depends on the predicting per-
formance of the individual methods. Also the most popular neural models are 
based on the statistical and traditional feed forward neural networks. But it 
is seen that this kind of neural model may present some disadvantages when 
long-term prediction is required. In this paper focused time-lagged recurrent 
neural network (FTLRNN) model with gamma memory is developed for  
© 2011 by Apple Academic Press, Inc.

10  Computer Technology and Computer Programming: New Research and Strategies
different prediction horizons. It is observed that this predictor performs re-
markably well for short-term predictions as well as medium-term predictions. 
For coupled partial differential equations generated chaotic time series such 
as Mackey Glass and Duffing, FTLRNN-based predictor performs consis-
tently well for different depths of predictions ranging from short term to long 
term, with only slight deterioration after k is increased beyond 50. For real-
world highly complex and nonstationary time series like Sunspots and Laser, 
though the proposed predictor does perform reasonably for short term and me-
dium-term predictions, its prediction ability drops for long term ahead pre-
diction. However, still this is the best possible prediction results considering 
the facts that these are nonstationary time series. As a matter of fact, no oth-
er NN configuration can match the performance of FTLRNN model. The 
authors experimented the performance of this FTLRNN model on predict-
ing the dynamic behavior of typical Chaotic Mackey-Glass time series, Duff-
ing time series, and two real-time chaotic time series such as monthly sunspots 
and laser. Static multi layer perceptron (MLP) model is also attempted and 
compared against the proposed model on the performance measures like mean 
squared error (MSE), Normalized mean squared error (NMSE), and Cor-
relation Coefficient (r). The standard back-propagation algorithm with mo-
mentum term has been used for both the models.
Introduction
Predicting the future which has been the goal of many research activities in the 
last century is an important problem for human, arising from the fear of unknown 
phenomenon and calamities all around the infinitely large world with its many 
variables showing highly nonlinear and chaotic behavior. Chaotic time series have 
many applications in various fields of science, for example, astrophysics, fluid me-
chanics, medicine, stock market, weather, and are also useful in engineering such 
as speech coding [1], radar modeling of electromagnetic wave propagation and 
scattering [2]. The chaotic interconnected complex dynamical systems in nature 
are characterized by high sensitivity to initial conditions which results in long-
term unpredictability. The dynamical reconstruction seems to be extremely dif-
ficult, even in developing era of super computers, not because of computational 
complexity, but due to inaccessibility of perfect inputs and state variables. Many 
different methods have been developed to deal with chaotic time series prediction. 
Among them neural networks occupy an important place being adequate model 
of the nonlinearity and nonstationarity. 
Inspired from the structure of the human brain and the way it is supposed to 
operate, neural networks are parallel computational systems capable of solving 
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  11
number of complex problems in such a diverse areas as pattern recognition, com-
puter vision, robotics, control and medical diagnosis, to name just few [3]. Neural 
networks are an effective tool to perform any nonlinear input output mappings 
and prediction problem [4]. Predicting a chaotic time series using a neural net-
work is of particular interest [5]. Not only it is an efficient method to reconstruct 
a dynamical system from an observed time series, but it also has many applications 
in engineering problems like radar noise cancellation [6], radar [7] demodulation 
of chaotic secure communication systems [8], and spread spectrum/code division 
multiple access (CDMA) systems [9, 10]. It is already established that, under 
appropriate conditions, they are able to uniformly approximate any complex con-
tinuous function to any desired degree of accuracy [11]. Later, similar results were 
published independently in [12]. It is these fundamental results that allow us to 
employ neural network in time series prediction. Since neural networks’ models 
do not need any a priori assumption about the underlying statistical distribu-
tion of the series to be predicted, they are commonly classified as “data-driven” 
approach, to contrast them with the “model-driven” statistical methods. Neural 
networks that are the instruments in broad sense can learn the complex nonlinear 
mappings from the set of observations [13]. The static MLP network has gained 
an immense popularity from numerous practical application published over the 
past decade, there seems to be substantial evidence that multilayer perceptron 
indeed possesses an impressive ability [14]. There have been some theoretical re-
sults that try to explain the reasons for the success in [15, 16]. Most applications 
are based on feed-forward neural networks, such as the back-propagation (BP) 
network [17] and Radial basis function (RBF) network [18, 19]. It has also been 
shown that modeling capacity of feed-forward neural networks can be improved if 
the iteration of the network is incorporated into the learning process [20].
Several methods with different performance measures have been attempted 
in the literature to predict the chaotic time series. It is has been predicted for 
Mackey-Glass chaotic time series for short-term ahead prediction with a percent-
age error of 20% [21]. A new class of wavelet network was developed with a 
standard deviation of 0.0029 for short-term ahead prediction of Mackey-Glass 
chaotic time series and annual sunspots for 1 step ahead prediction [22]. By using 
recurrent predictor neural network for monthly sunspots chaotic time series for 6 
months ahead prediction with EPA (Prediction accuracy) equals 0.992 and ERMSE 
(Root mean squared error) equals 4.419, for 10 months ahead prediction with EPA 
of 0.980 and ERMSE of 7.050, for 15 months ahead prediction of EPA equals 0.9222 
and ERMSE equals 13.658, and 20 months ahead prediction with EPA of 0.866 and 
ERMSE of 16.79323 [23]. Also by using radial basis function with orthogonal least 
square Fuzzy model for monthly sunspots with prediction error +6 to -4 and for 
Mackey-Glass chaotic time series with ERMSE of 0.0015 [24]. It is also attempted 
with Hybrid network for Mackey-Glass time series with iterative prediction and 
© 2011 by Apple Academic Press, Inc.
  

12  Computer Technology and Computer Programming: New Research and Strategies
Normalized Mean Square Error NMSE of 0.053 [25]. By using Elman neural net-
work for yearly sunspots for 1 year ahead prediction with ERMSE equals 30.2931 
and prediction accuracy of 0.9732 [26].
From the scrupulous review of the related research work, it is noticed that 
no simple model is available for long-term prediction of chaotic time series so 
far. It is necessary to develop a simple model that is able to perform short-, me-
dium- and long-term predictions of chaotic time series with reasonable accuracy. 
In view of the remarkable ability of neural network in learning from the instances, 
it can prove as a potential candidate with a view to design a versatile predic-
tor (forecaster) for the chaotic time series. Hence in this paper a novel focused 
time-lagged recurrent neural network model with gamma memory filter is pro-
posed as an intelligent tool for predicting the two non linear differential equa-
tion Mackey-Glass and Duffing time series and two real-time monthly sunspots 
and Laser chaotic time series not only for short-term but long-term prediction 
also because they acquire temporal processing ability through the realization of 
short-term memory and information about the preceding units, which is impor-
tant when the long-term prediction is required. The Mackey-Glass chaotic time 
series was first proposed as a model for white blood cell production, the Duffing 
chaotic time series describes a specific nonlinear circuit or the hardening spring 
effect observed in many mechanical problems, monthly sunspots number is a 
good measure of solar activity which has a period of 11 years, so-called solar cycle. 
The solar activity has a measure effect on earth, climate, space weather, satellites, 
and space missions, and a highly nonlinear laser time series. These chaotic time 
series are the good benchmark for the proposed model. The various parameters 
like number of hidden layers, number of processing elements in the hidden layer, 
step size, the different learning rules, the various transfer functions like tanh, 
sigmoid, linear-tan-h, and linear sigmoid, different error norms L1,L2,L3,L4,L5, 
and L∞, the different memories TDNN, Laguarre and gamma filter, and different 
combination of training and testing samples are exhaustively varied and experi-
mented for obtaining the optimal values of performance measures as mentioned 
in the flow chart. The obtained results indicate the superior performance of esti-
mated dynamic FTLRNN-based model with gamma memory over the MLPNN 
in various performance measures such as Mean Square Error (MSE), Normalized 
Mean Square Error (NMSE), and correlation coefficient (r) on testing as well as 
training data set. The proposed network is attempted for training up to 20 000 
numbers of epochs for obtaining the improved values of performance measures. 
The experimentation process is demonstrated in flow chart of Figure 1. This pa-
per is organized as follows in Section 2 the static MLP model is presented, and 
the learning procedure is explained. In Section 3 the proposed FTLRNN model 
is explained. In Section 4 the performance measures and their importance are 
discussed. Section 5 explains about the significance of the benchmark chaotic 
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  13
time series. Section 6 explains the experimental procedure and analysis. Section 
7 summarizes the evaluation results and analyses for the proposed model. Finally 
concluding remarks on empirical findings are provided in Section 8.
Figure 1. Flow Chart.
Static NN-Based Model
Static Neural networks typically use Multilayer perceptron MLP as a backbone. 
They are layered feed-forward networks typically trained with static back propagation. 
© 2011 by Apple Academic Press, Inc.
  

14  Computer Technology and Computer Programming: New Research and Strategies
MLP solid-based model has a solid foundation [27, 28]. The main reason for this 
is its ability to model simple as well as complex functional relationships. This has 
been proven through a number of practical applications [29]. In [11] it is shown 
that all continuous functions can be approximated to any desired accuracy, in 
terms of the uniform norm, with a network of one hidden layer of sigmoid or 
(hyperbolic tangent) hidden units and a layer of linear or tanh output unit to in-
clude in the hidden layer. The paper does not explain how many units to include 
in the hidden layer. This is discussed in [30], and a significant result is derived 
approximation capabilities of two layer perception networks when the function to 
be approximated shows certain smoothness. The biggest advantage of using MLP 
NN for approximation of mapping from input to the output of the system re-
sides in its simplicity and the fact that it is well suited for online implementation. 
The objective of training is then to determine a mapping from a set of training 
data to the set of possible weights so that the network will produce predictions 
y(t), which in some sense are close to the true outputs y(t). The prediction error 
approach is based on the introduction of measure of closeness in terms of mean 
square error (MSE) criteria: 
	
^
^
1
2
1
1
( ,
)
( )
(
( )
(
)
2
1
( , ).
2
T
N
N
N
t
N
t
V
Z
y t
y t
y t
y t
N
t
N
θ
θ
ε
θ
=
=



=
−
−



=
∑
∑
	
(1)
The weights are then found as
	
ˆ
arg min
( ,
),
N
N
V
Z
=
θ
θ
θ
	
(2)
by some kind of iterative minimization scheme:
	
(
1)
( )
( )
( ),
i
i
i
i
f
θ
θ
µ
+ =
+
	
(3)
where θ
( i ) specifies the current iterate (number “i’’), f(i) is the search direction, and 
μ(i) is the step size.
When NN has been trained, the next step is to evaluate it. This is done by 
standard method in statistics called independent validation [31]. It is never a good 
idea to assess the generalization properties of an NN-based on training data alone. 
This method divides the available data sets into two sets, namely, training data set 
and testing data set. The training data set are next divided into two partitions: 
the first partition is used to update the weights in the network and the second 
partition is used to assess (or cross-validate) the training performance. The testing 
data set are then used to assess how the network has generalized. The learning and 
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  15
generalization ability of the estimated NN-based model is assessed on the basis of 
certain performance measures such as MSE, NMSE, and the regression ability of 
the NN by visual inspection of the correlation coefficient characteristics for differ-
ent outputs of system under study. 
FTLRNN Model
Time-lagged recurrent networks (TLRNs) are MLPs extended with short-term 
memory structures. Here, a “static” NN (e.g., MLP) is augmented with dynamic 
properties [14]. This, in turn, makes the network reactive to the temporal struc-
ture of information bearing signals. For an NN to be dynamic, it must be given 
memory. This memories may be classified into “short-term” and “long-term” 
memories. Long-term memory is built into an NN through supervised learning, 
whereby the information content of the training data set is stored (in part or in 
full) in the synaptic weights of the network [32]. However, if the task at hand has 
a temporal dimension, some form of “short-term” memory is needed to make 
the network dynamic. One simple way of building short-term memory into the 
structure of an NN is through the use of time delays, which can be applied at the 
input layer of the network (focused). A short-term memory structure transforms 
a sequence of samples into a point in the reconstruction space [33]. This memory 
structure is incorporated inside the learning machine. This means that instead of 
using a window over the input data, processing elements (PEs) created are dedi-
cated to store either the history of the input signal or the PE activations. 
The input PEs of an MLP are replaced with a tap delay line, which is followed 
by the MLPNN. This topology is called the focused time-delay NN (TDNN). 
The focused topology only includes the memory Kernels connected to the input 
layer. This way, only the past of the input is remembered. The delay line of the 
focused TDNN stores the past samples of the input. The combination of the tap 
delay line and the weights that connect the taps to the PEs of the first hidden layer 
is simply linear combiners followed by a static nonlinearity. Typically, a gamma 
short-term memory mechanism is combined with nonlinear PEs in restricted to-
pologies called focused. Basically, the first layer of the focused TDNN is a filtering 
layer, with as many adaptive filters as PEs in the first hidden layer. The outputs of 
the linear combiners are passed through a nonlinearity (of the hidden-layer PE) 
and are then further processed by the subsequent layers of the MLP for system 
identification, where the goal is to find the weights that produce a network output 
that best matches the present output of the system by combining the informa-
tion of the present and a predefined number of past samples (given by the size 
of the tap delay line) [32]. Size of the memory layer depends on the number of 
past samples that are needed to describe the input characteristics in time. This 
© 2011 by Apple Academic Press, Inc.
  

16  Computer Technology and Computer Programming: New Research and Strategies
number depends on the characteristics of the input and the task. This focused 
TDNN can still be trained with static back propagation, provided that a desired 
signal is available at each time step. This is because the tap delay line at the input 
layer does not have any free parameters. So the only adaptive parameters are in 
the static feed-forward path. 
The memory PE receives in general many inputs xi(n) and produces multiple 
outputs y = [y0(n),…, yD(n)]T, which are delayed versions of y0(n) the combined 
input, 
	
1
0
1
( )
(
( )),
( )
( ),
P
k
k
j
j
y n
g y
n
y n
x n
−
=
=
= ∑
	
(4)
where g(·) is a delay function.
These short-term memory structures can be studied by linear adaptive filter 
theory if g(·) is a linear operator. It is important to emphasize that the memory 
PE is a short-term memory mechanism, to make clear the distinction from the 
network weights, which represent the long-term memory of the network.
There are basically two types of memory mechanisms: memory by delay and 
memory by feedback. We seek to find the most general linear delay operator 
(special case of the Auto Regressive Moving Average model), where the memory 
traces yK(n) would be recursively computed from the previous memory trace 
yK-1(n). This memory PE is the generalized feed-forward memory PE. It can be 
shown that the defining relationship for the generalized feed-forward memory PE 
is mentioned 
	
gk(n) = g(n)*gk-1(n),	
k ≥ 1,	
(5)
where, * is the convolution operation, g(n) is a causal time function, and K is 
the tap index. Since this is a recursive equation, g0(n) should be assigned a value 
independently. This relationship means that the next memory trace is constructed 
from the previous memory trace by convolution with the same function g(n), the 
memory Kernel yet unspecified. Different choices of g(n) will provide different 
choices for the projection space axes. When we apply the input x(n) to the gener-
alized feed-forward memory PE, the tap signals yK(n) become
	
yK (n) = g (n)* yK-1 (n),	
(6)
the convolution of y_{k-1}(n) with the memory Kernel. For k=0, we have
	
y0 (n) = g0 (n)* x (n),	
(7)
where g0(n) may be specified separately. The projection x(n) of the input sig-
nal is obtained by linearly weighting the tap signals according to 
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  17
	
0
( )
( ).
D
k
k
k
x n
w y n
=
= ∑
	
(8)
The most obvious choice for the basis is to use the past samples of the input 
signal x(n) directly, that is, the Kth tap signal becomes yK(n)=x(n-K). This choice 
corresponds to 
	
( )
(
1).
g n
n
δ
=
−
	
(9)
In this case g0(n) is also a delta function δ(n) (delta function operator used 
in the tap delay line). The memory depth is strictly controlled by D, that is, the 
memory traces store the past D samples of the input. The time delay NN uses 
exactly this choice of basis.
The gamma memory PE attenuates the signals at each tap because it is a cas-
cade of leaky integrators with the same time constant gamma model. The gamma 
memory PE is a special case of the generalized feed-forward memory PE, where 
	
( )
(1
) ,
1,
n
g n
n
µ
µ
=
−
≥
	
(10)
and g0(n)=δ(n). The gamma memory is basically a cascade of low-pass filters with 
the same time constant 1-μ. The over all impulse response of the gamma memory 
is 
	
1
( )
(1
)
,
,
1
P
n
p
p
n
g
n
n
p
p
µ
µ
−
−


=
−
≥


−


	
(11)
where (:) is a binomial coefficient defined by
	
(
1)
(
1).
!
n
n n
n
p
p
p

−
−
+
=



	
(12)
For integer values of n and p, the overall impulse response gp(n) for varying p 
represents a discrete version of the integrand of the gamma function, hence the 
name of the memory. 
The gamma memory PE has a multiple pole that can be adaptively moved 
along the real Z-domain axis, that is, the gamma memory can implement only 
low-pass (0 < μ < 1) or high-pass (1 < μ < 2) transfer functions. The high-pass 
transfer function creates an extra ability to model fast-moving signals by alter-
nating the signs of the samples in the gamma PE (the impulse response for 1 
< μ < 2 has alternating signs). The depth in samples parameters (D) is used to 
compute the number of taps (T) contained within the memory structure (s) of 
the network.
© 2011 by Apple Academic Press, Inc.
  

18  Computer Technology and Computer Programming: New Research and Strategies
Performance Measures
Three different types of statistical performance evaluation criteria were employed 
to evaluate the performance of these models developed in this paper. These are as 
follows.
MSE: the mean square error is given by:
	
=
=
−
=
×
∑
∑
2
0
0(
) ,
P
N
j
i
dij
yij
MSE
N
P
	
(13)
where P = number of output PEs, N = number of exemplars in the data set, yij = 
network output for exemplar i at PEj, and dij = desired output for exemplar i at 
PEj.
NMSE (normalized mean square error). The normalized mean square error is 
defined by the following formula, where P = Number of output PEs, N = Number 
of exemplars in data set,
	
(
)
(
)
(
)
=
=
=
´
´
=
-
å
å
å
2
2
0
0
0
.
/
P
N
N
J
i
ij
i
ij
P
N
MSE
NMSE
N
d
d
N
	
(14)
MSE=Mean square error, dij = desired output for exemplar i at PEj ( jth ele-
ment of PEs) Correlation Coefficient (r). The mean square error (MSE) can be 
used to determine how well the network output fits the desired output but it 
does not necessarily reflect whether the two sets of data move in the same direc-
tion. For instance by simply scaling the network output, we can change the MSE 
without changing the directionality of the data. The correlation coefficient solves 
this problem. By definition, the correlation coefficient between a network output 
x and a desired output d is
	
(
)(
)
(
)
(
)
(
)
(
)
(
)
−
−
=
−
×
−
∑
∑
∑
/
,
/
/
i
i
i
xi
x
di
d
N
r
di
d
N
di
d
N
	
(15)
The correlation coefficient is confined to the range [-1,1].
Benchmark Chaotic Time Series
In science, chaos is used as a synonym for irregular behavior, whose long-term 
prediction is essentially unpredictable. Chaotic differential equations exhibit not 
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  19
only irregular behavior but they are also unstable with respect to small perturba-
tions of their initial condition. Consequently it is difficult to forecast the future of 
time series based on chaotic differential equations; they are the good benchmark 
for a neural network design algorithm. 
Mackey-Glass Time Series
The Mackey-Glass equation is time delay differential equation, which was first 
proposed as model of white blood cells production [34]. It is often used in prac-
tice as a benchmark set because of its nonlinear chaotic characteristics. Chaotic 
time series do not converge or diverge in time, and their trajectories are highly 
sensitive to initial conditions. Data are generated by using fourth order Runge-
Kutta method.The equation is given by:
	
(
)
( ),
1
(
)c
dx
ax t
bx t
dt
x t
τ
τ
−
=
−
+
−
	
(16)
where a, b, c are constant coefficients and t is time delay, the coefficient we are 
selected: a=0.2, b=0.1, c=10, τ=17. The Mackey-Glass time series is shown in 
Figure 2.
Figure 2. Mackey-Glass time series.
Duffing Time Series
Duffing time series describes a specific nonlinear circuit or the hardening spring 
effect observed in many mechanical problems [35]. The Duffing equation is time 
delay differential equation which is given as 
© 2011 by Apple Academic Press, Inc.
  

20  Computer Technology and Computer Programming: New Research and Strategies
	
{
}
τ
τ
=
=
−
−
=
3
,
( )
,
,
x
x
dy
y
dt
dy
F Cos
x
b y
dt
d
w
dt
	
(17)
where driving force F = 7.5, X0=initial position 1.0, damping constant (b = 0.05), 
frequency w = 1.0, Delay time = 0.001. The chaotic time series is as shown in 
Figure 3. 
Figure 3. Duffing time series (first 500 samples).
Sunspot Time Series
A sunspot number is a good measure of solar activity which has a period of 11 
years, so-called solar cycle. The solar activity has a measure effect on earth, cli-
mate, space weather, satellites, and space missions, thus is an important value 
to be predicted. But due to intrinsic complexity of time behavior and the lack 
of a quantitative theoretical model, the prediction of solar cycle is very difficult. 
Many prediction techniques have been examined on the yearly sunspots number 
time series as an indicator of solar activity. However, in more recent studies the 
international monthly sunspot time series, which has a better time resolution and 
accuracy, has been used. In particular, a nonlinear dynamics approach has been 
developed in [36], and prediction results are compared between several prediction 
techniques from both statistical and physical classes. There has been a lot of work 
on controversial issue of nonlinear characteristics of the solar activity [36–39]; 
several recent analyses have provided evidence for low-dimensional deterministic 
nonlinear chaotic behavior of the monthly smoothed sunspot time series [36–38] 
which has intense. The data considered the monthly variations from January 1749 
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  21
to December 2006. The total samples are 3096 considered and demonstrated in 
Figure 4. The series is normalized in the range of -1 to +1. The monthly smoothed 
sunspot number time series is downloaded from the SIDC (World Data Center 
for the Sunspot Index) [40].
Figure 4. Monthly Sunspot time series.
Laser Time Series
The laser data were recorded from a Far Infrared-laser in a chaotic state. The 
measurements were made on an 81.5-micron 14 NH3 cw (FIR) laser, pumped 
optically by the P (16) line of an N2O laser, via the vibrational aQ(8, 7) NH3 
transition. The basic laser setup can be found in [41]. The intensity data was 
recorded by an Le Croy oscilloscope. It was made available worldwide during a 
time series prediction competition organized by Santa Fe Institute and a highly 
nonlinear data set, since then, it has been used in benchmark studies. The time 
series has 1000 samples points which has been rescaled to the range of [-1,1]. The 
time series is shown in Figure 5.
Figure 5. Laser time series.
© 2011 by Apple Academic Press, Inc.
  

22  Computer Technology and Computer Programming: New Research and Strategies
Experimental Results
The choice of the number of hidden layers and the number of hidden units 
in each hidden layers is critical [42]. It has been established that an MLPNN 
that has only one hidden layer, with sufficient number of neurons, acts as a 
universal approximators of nonlinear mappings [43]. The tradeoff between 
accuracy and complexity of the model should be resolved accurately [44]. In 
practice, it is very difficult to determine a sufficient number of neurons neces-
sary to achieve the desired degree of approximation accuracy. Frequently the 
number of units in the hidden layer is determined by trial and error. To de-
termine the weight values, one must have a set of examples of how the output 
should relate to the inputs. The task of determining the weights from these ex-
amples is called training or learning and is basically a conventional estimation 
problem. That is, the weights are estimated from the examples in such away 
that the network, according to metric, models the true relationship as accu-
rately as possible. Since learning is a stochastic process, the learning curve may 
be drastically different from run to run. In order to compare the performance 
of a particular search methodology or the effects of different parameters have 
on a system, it is needed to obtain the average learning curve over the number 
of runs so that the randomness can be averaged out. An exhaustive and careful 
experimentation has been carried to determine the configuration of the static 
MLP model and the optimal proposed FTLRNN model with gamma memory 
for short-term and long-term ahead predictions for the benchmark chaotic 
time series for 60% training, 15% cross-validation and 25% testing samples 
for the considered benchmark chaotic time series. It is found that the perfor-
mance of the selected model is optimal for 38, 21, 15, and 43 neurons in the 
hidden layer with regard to the MSE, NMSE, and the correlation coefficient 
r performance for the testing data sets for Mackey-Glass, Duffing, Monthly 
Sunspots, and Laser time series, respectively, and the different parameters like 
transfer function, Learning rule, step size, and momentum values are men-
tioned in Table 1 for Mackey-Glass and Duffing chaotic time series and in 
Table 2 for monthly sunspots and Laser time series. 
Table 1. Optimal Parameters of FTLRNN for both time series.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  23
Table 2. Optimal Parameters of FTLRNN for both real-time series.
When we attempted to increase the number of hidden layer and the num-
ber of processing element in the hidden layer, the performance of the model 
is not to seen to improve significantly. On the contrary it takes too long time 
for training because of complexity of the model. As there is single input and 
single output for the given system, the number of input and output Process-
ing Elements is chosen as one. Now the NN models are trained three times 
with different weight initialization with 1000 iterations of the static back-
propagation algorithm with momentum term for these two models. All the 
possible variations for the model such as number of hidden layers, number of 
processing elements in each hidden layer, different transfer functions like tanh, 
linear tanh, sigmoid, linear sigmoid in output layer, the different supervised 
learning rules like momentum, conjugant gradient, and quick propagation are 
attempted for 10-step ahead prediction for Mackey-Glass, Duffing, and Laser 
time series, and 6 months ahead prediction for the monthly sunspots time 
series. The results are placed in Table 3 for Mackey-Glass and Duffing time 
series and in Table 4 for real-time monthly sunspots, and Laser time series for 
different learning rules on testing data set. 
Table 3. Learning rules variations for the Mackey-Glass and Duffing time series.
Table 4. Learning rules variations for the real sunspots and Laser time series.
© 2011 by Apple Academic Press, Inc.
  

24  Computer Technology and Computer Programming: New Research and Strategies
Also the various error norms L1, L2, L3, L4, L5, and L∞, are varied, and FTL-
RNN model is trained and tested for the optimum transfer function. The results 
are obtained and placed in Table 5 for artificial Mackey-Glass and Duffing time 
series and in Table 6 for real-time monthly sunspots and Laser time series. It is 
clear from Table 5 that for L2 error norm and tanh transfer function the value of 
MSE is minimum and correlation coefficient r is maximum for the Mackey-Glass 
chaotic time series. For Duffing chaotic time series the optimal values of MSE, 
NMSE, and correlation coefficient r is obtained for linear tanh transfer function 
and L1 error norm can be seen from Table 5.
Table 5. Error norms variations for the Mackey-Glass and Duffing time series for FTLRNN model on testing 
data set.
Table 6. Error norms variations for the real Sunspots time series and laser time series for FTLRNN model on 
testing data set.
Similarly, for real-time monthly sunspots time series, the minimum value of 
MSE and maximum value correlation relation coefficient r are obtained for L2 er-
ror norm and tanh transfer function. For Laser time series the minimum value of 
MSE and maximum value of correlation coefficient r resulted for L1 error norm 
and tanh transfer function.
Then on these resulted optimal parameters the FTLRNN model is trained 
and tested for short-term (1, 5, 10) and long-term (20, 50, and 100) step ahead 
prediction. The FTLRNN structure is the MLP extended with the short-term 
memory structures. So these optimal parameters obtained for FTLRNN model 
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  25
are used for training and testing the MLPNN. Then on the same optimal param-
eters the static MLPNN model was attempted, and the performance measures 
like MSE, NMSE, and correlation coefficient r for the short-term (1, 5, and 10) 
and long-term (20, 50, and 100) step ahead prediction were obtained as stated in 
Table 7 for Mackey-Glass chaotic time series, in Table 8 for Duffing chaotic time 
series, in Table 9 for laser time series, and in Table 10 for monthly sunspots time 
series. It is obvious from Tables 7, 8, 9, and 10 that for all the time series con-
sidered for short-term and long-term ahead predictions, the performance of this 
FTLRNN model is optimal on the test dataset for the following number of taps = 
6, Tap Delay = 1, Trajectory Length = 50 with regards to the value of correlation 
coefficient r, MSE, and NMSE.
Table 7. Performance of MLPNN and FTLRNN on testing data for Mackey-Glass time series.
Table 8. Performance of MLPNN and FTLRNN on testing data for Duffing time series.
Table 9. Performance of MLPNN and FTLRNN for testing data set for Laser time series.
Then training and testing samples are varied from 10% to 80% as training 
with the increments of 10% samples and 75% to 5% as testing on the proposed 
optimal FTLRNN model, the number of training and testing samples was as test-
ing samples with the decrements of 10% keeping exemplars for Cross-Validation 
© 2011 by Apple Academic Press, Inc.
  

26  Computer Technology and Computer Programming: New Research and Strategies
(CV) 15% constant. The performance measures were obtained and compared on 
testing and training datasets and to gauge the performance and robustness of the 
FTLRNN. The results are obtained and are placed in Table 11 for 1-step ahead 
predictions, Table 12 for 5-step ahead prediction, Table 13 for 10-step ahead pre-
diction, Table 14 for 20-step ahead prediction, Table 15 for 50-step ahead predic-
tion and Table 16 for 100-step ahead prediction for Mackey-Glass and Duffing 
chaotic time series. 
Table 10. Performance of MLPNN and FTLRNN for testing data set for monthly sunspot time series.
Table 11. For K = 1, training and testing samples variation for FTLRNN on testing data set.
Table 12. For K = 5, training and testing samples variation for FTLRNN on testing data set.
Table 13. For K = 10, training and testing samples variation for FTLRNN on testing data set.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  27
Table 14. For K = 20, training and testing samples variation for FTLRNN on testing data set.
Table 15. For K = 50, training and testing samples variation for FTLRNN on testing data set.
Table 16. For K = 100, training and testing samples variation for FTLRNN on testing data set.
In a similar way, for real-time monthly sunspots and Laser time series, the 
number of training and testing samples was varied from 10% to 80% as train-
ing with the increments of 10% samples and 75% to 5% as testing samples 
with the decrements of 10% keeping exemplars for Cross-Validation (CV) 
15% constant. The performance measures were obtained and compared on 
testing and training data sets and to gauge the performance and robustness of 
the FTLRNN. The obtained results are placed in Tables 17, 18, 19, 20, and 
21 for monthly sunspots and Laser time series for the value K in K-step ahead 
prediction.
© 2011 by Apple Academic Press, Inc.
  

28  Computer Technology and Computer Programming: New Research and Strategies
Table 17. For K = 1, training and testing samples variation for FTLRNN on testing data set.
Table 18. For K = 6, training and testing samples variation for FTLRNN on testing data set for monthly sunspot 
time series and K = 5 for laser time series.
Table 19. For K = 12 , training and testing samples variation for FTLRNN on testing data set for monthly 
sunspot time series and K = 10 for laser time series.
Table 20. For K = 18 , training and testing samples variation for FTLRNN on testing data set for monthly 
sunspot time series and K = 20 for laser time series.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  29
Table 21. For K = 24, training and testing samples variation for FTLRNN on testing data set for monthly 
sunspot time series and for laser time series (K = 50).
Next for the optimum values of performance measures obtained from the 
combinations data partition as training and testing samples for the chaotic time 
series as mentioned in Tables 11 to 16 for the Mackey-Glass chaotic time series 
for all the cases of multistep ahead prediction and Duffing time series all the step 
ahead prediction. Similarly, for the real-time monthly sunspots and Laser time 
series for all the multistep ahead prediction. 
Then for the optimal data partition of training and testing samples combina-
tion resulted for the K-step ahead prediction for the cases of K-value in K-step 
ahead prediction for all the considered time series. For those combinations, the 
number of epochs is varied from 2000 to 20,000 in a step of 2000, and again the 
proposed FTLRNN model is trained to observe the more prominent values of 
performance measures for all the chaotic time series and for all the steps ahead 
prediction.
Discussion
It can be clearly observed that dynamic FTLRNN model with gamma mem-
ory clearly outperforms the static MLP not only for short-term prediction 
but also for long-term prediction for testing data as well as training data set. 
From the results of Table 7, for Mackey-Glass chaotic time series, it is noticed 
that up to the 20-step ahead prediction the Performance measures values of 
MLP and dynamic FTLRNN are slightly deviating but for long 50- and 100-
step ahead prediction the Performance measures values of MSE, NMSE, and 
correlation coefficient (r) for FTLRNN model are significantly improved as 
compared to the static MLP. For the Duffing time series from Table 8 it is ob-
served that for short- and long-step ahead predictions the proposed dynamic 
FTLRNN with gamma memory filter clearly outperforms well as compared 
to the static MLP with regards to the performance metrics like MSE, NMSE, 
and correlation coefficient r. 
© 2011 by Apple Academic Press, Inc.
  

30  Computer Technology and Computer Programming: New Research and Strategies
Also for the real monthly sunspots time series, it is observed from Table 9 
that for the 1, 6, 12, months ahead predictions the performance metrics values 
of MLP and dynamic FTLRNN are slightly deviating but for 18 and 24 months 
ahead prediction, the performance metrics values for FTLRNN are significantly 
improved as compared to the static MLP. For the Laser time series from Table 10 
it is observed that for short- and long-term ahead (K=1, 5, 10, 20, 50) prediction 
the proposed dynamic FTLRNN with gamma memory filter clearly outperforms 
well as compared to the static MLP for the values of MSE, NMSE, and correla-
tion coefficient r.
Next for the resulted optimal parameters the FTLRNN model is trained for 
different training and testing samples combinations varying from 10% to 80% 
as a training sample and 75% to 5% as a testing sample and Keeping cross-vali-
dation samples constant equal to 15% for short-term and long-term step ahead 
predictions for finding robustness of model and obtaining the significant results 
of performance measures for training and testing samples combinations. Tables 
11 to 16 show the performance metrics values for one-step ahead to 100-step 
ahead predictions for different combination of training and testing samples for 
the equation generated Mackey-Glass and Duffing time series.
Similarly for real-time series the training and testing samples are varied in 
combination as mentioned in Tables 17 to 21 for one month ahead to twenty 
four months ahead predictions for monthly sunspot time series and for one-step 
to fifty-step ahead predictions for Laser time series. 
For which training and testing samples the values of MSE NMSE are mini-
mum, and correlation coefficient is closed to unity for short-term and long-term 
predictions for the chaotic time series for that training and testing samples the 
FTLRNN with gamma filter is trained for 2000 to 20,000 epochs in the steps 
of 2000 for obtaining more significant values and observing the network per-
formance with regards to the performance measures. The results are plotted in 
Figure 6 for 1- and 5-step ahead predictions, Figure 7 for 10- and 20-step ahead 
predictions and Figure 8 for 50- and 100-step ahead predictions for performance 
on MSE and NMSE due to epochs variation, and Figure 9 for performance on 
regression due to epochs variation for 1-, 5-, 10-, 20-, 50- and 100-step ahead 
predictions for Mackey-Glass chaotic time series. It is observed that up to 50 steps 
ahead prediction the performance metrics are slightly deviating but for long-term 
100-step ahead predictions above the values of 12 000 epochs training the per-
formance measure like MSE and NMSE values are decreased, and the correlation 
coefficient r is substantially increased. 
Also it can be visually inspected closely from Figures 10, 11, 12, and 13 that 
the output of the proposed FTLRNN model closely follows the desired output 
for 1-, 5-, 10-, 20-step ahead predictions. 
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  31
From Figure 14 and Figure 15, it is clear that, the output of the network is 
slightly deviating from the desired output for long 50-step and 100-step ahead 
predictions.
Figure 6. Performance of epoch’s variation on Errors for 1 and 5 step for Mackey-Glass time series.
Figure 7. Performance of epoch’s variation on Errors for 10 and 20 step for Mackey-Glass time series.
Figure 8. Performance of epoch’s variation on Errors for 50 and 100 step for Mackey-Glass time series.
© 2011 by Apple Academic Press, Inc.
  

32  Computer Technology and Computer Programming: New Research and Strategies
Figure 9. Performance of epochs variation on Correlation Coefficient r for 1, 5, 10, 20, 50, and 100 step for 
Mackey-Glass time series.
Figure 10. Desired output and network output for 1-step ahead Prediction for Mackey-Glass time series.
Figure 11. Desired output and FTLRNN output for 5-step ahead prediction for Mackey-Glass time series.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  33
Figure 12. Desired output and FTLRNN output for 10-step ahead prediction for Mackey-Glass time series.
Figure 13. Desired output and FTLRNN output for 20-step ahead prediction for Mackey-Glass time series.
Figure 14. Desired output and FTLRNN Output for Testing data set 50-step ahead prediction for Mackey-
Glass time series.
© 2011 by Apple Academic Press, Inc.
  

34  Computer Technology and Computer Programming: New Research and Strategies
Figure 15. Desired output and FTLRNN Output for testing data 100-step ahead prediction for Mackey-Glass 
time series.
Figure 16. Epochs variation performance on errors for K = 1 and K = 5 for Duffing time series.
Figure 17. Epochs variation performance on errors for K = 10 and K = 20 for Duffing time series.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  35
Figure 18. Epochs variation performance on errors for K = 50 and K = 100 for Duffing time series.
Figure 19. Performance of epochs variation on Correlation Coefficient r for 1, 5, 10, 20, 50, and 100 step for 
Duffing time series.
For the Duffing time series the results are shown in Figure 16 for 1- and 5-step 
ahead predictions, Figure 17 for 10- and 20-step ahead predictions and Figure 18 
for 50- and 100-step ahead predictions for performance on MSE and NMSE due 
to epochs variation, and Figure 19 for Correlation coefficient for 1-, 5-, 10-, 20-, 
50- and 100-step ahead predictions. It is observed that for short-term prediction 
and up to 50-step ahead predictions the results are not deviating much. But for 
100-step ahead prediction, the performance measures values are improved well.
From the close inspection of Figure 20 and Figure 21 for 1- and 5-step ahead 
predictions the output of the FTLRNN closely follows the desired output. From 
Figure 22 and Figure 23 for 10- and 20-step ahead predictions, up to the first 20 
samples the FTLRNN output is slightly deviating and after that the actual output 
closely follows the desired output. Similarly from the Figure 24 and Figure 25 
the FTLRNN output follows the desired output for long-term 50- and 100-step 
ahead predictions.
© 2011 by Apple Academic Press, Inc.
  

36  Computer Technology and Computer Programming: New Research and Strategies
Figure 20. Desired and FTLRNN Outputs for Testing data for 1-step ahead prediction for Duffing time 
series.
Figure 21. Desired and FTLRNN Outputs for Testing data for 5-step ahead prediction for Duffing time 
series.
Figure 22. Desired and FTLRNN Outputs for testing data for 10-step ahead prediction for Duffing time 
series.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  37
Figure 23. Desired and FTLRNN Outputs for testing data for 20-step ahead prediction for Duffing time 
series.
Figure 24. Desired and FTLRNN Outputs for Testing data for 50-step ahead prediction for Duffing time 
series.
Figure 25. Desired and FTLRNN Outputs for Testing data for 100-step ahead prediction for Duffing time 
series.
© 2011 by Apple Academic Press, Inc.
  

38  Computer Technology and Computer Programming: New Research and Strategies
Similarly for real monthly sunspots time series the results are plotted in Fig-
ure 26 and Figure 27 for performance on MSE and NMSE, respectively, due to 
epochs variations for 1 and 6 months ahead prediction, Figure 28 and Figure 29 
for due to epochs variations for 12, 18, and 24 months ahead prediction and Fig-
ure 30 for the correlation coefficient (r) for all the month ahead prediction. For 
short-term 1 and 6 months ahead prediction the performance values are slightly 
improved. Also for 12 and 18 months ahead prediction the results are slightly de-
viating but for 24 months ahead prediction for 10,000 epochs training the values 
of MSE , NMSE, and Correlation Coefficient r are significantly improved that is, 
MSE of 0.00824 and NMSE of 0.23236, respectively, and the value of Correla-
tion Coefficient r is 0.88460 where as for the 1000 epochs training the value of 
MSE and NMSE is 0.0339, 0.57734, and r is 0.8012.
Also from the close inspection of Figure 31 , Figure 32 and Figure 33 for 
short-term 1, 6, and 12 months ahead prediction the FTLRNN output closely 
follows the desired output and from Figure 34 and Figure 35 for long-term 18 
and 24 months ahead prediction the FTLRNN output is slightly deviating from 
the desired output.
Figure 26. Epochs variation performance on MSE for 1 month and 6 months ahead prediction for sunspot 
time series.
Figure 27. Epochs variation performance on NMSE for 1 month and 6 months ahead prediction for sunspot 
time series.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  39
Figure 28. Epochs variation performance on MSE for 12, 18, and 24 months ahead prediction for sunspot 
time series.
Figure 29. Epochs variation performance on NMSE for 12, 18, and 24 months ahead prediction for sunspot 
time series.
Figure 30. Epochs variation performance on Correlation Coefficient r for 1, 6, 12, 18, and 24 months ahead 
prediction for sunspot time series.
© 2011 by Apple Academic Press, Inc.
  

40  Computer Technology and Computer Programming: New Research and Strategies
Figure 31. Plot between Desired versus Actual FTLRNN outputs for 1 month ahead prediction for FTLRNN 
model
Figure 32. Plot between Desired versus FTLRNN Outputs for 6-month ahead prediction for FTLRNN 
Model.
Figure 33. Plot between Desired versus Actual FTLRNN Outputs for 12 month ahead prediction for FTLRNN 
Model.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  41
Figure 34. Plot between Desired versus Actual FTLRNN Outputs for 18 month ahead prediction for FTLRNN 
Model.
Figure 35. Plot between Desired versus Actual FTLRNN Output for 24 months ahead prediction for FTLRNN 
Model.
For Laser time series the results are plotted in Figure 36 and Figure 37 for 
1-, 5-, and 10-step ahead prediction and Figure 38 and Figure 39 for 20- and 
50-step ahead prediction for performance on MSE and NMSE due to epochs 
variations, and Figure 40 for the performance on Correlation coefficient r due 
to epochs variation for all the step ahead predictions. It is observed that for 
short-step ahead prediction the performance metrics are slightly deviating but 
for 50-step ahead prediction, the error values MSE and NMSE and correla-
tion coefficient r are improved substantially. For 1000 epochs training the val-
ues of MSE and NMSE are 0.03447 and 0.89215, and value of r is 0.44330 
and when the number of epochs for training is increased to 20,000 the values 
of MSE and NMSE are 0.154 and 0.412, and the value of r is significantly 
improved to 0.789.
© 2011 by Apple Academic Press, Inc.
  

42  Computer Technology and Computer Programming: New Research and Strategies
Figure 36. Epochs variation performance on MSE for 1, 5, 10, step ahead prediction for laser time series.
Figure 37. Epochs variation performance on NMSE for 1, 5, 10, step ahead prediction for laser time series.
Figure 38. Epochs variation performance on MSE for 20- and 50-step ahead prediction for laser time series.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  43
Figure 39. Epochs variation performance on NMSE for 20- and 50-Step ahead prediction for laser time series.
Figure 40. Epochs variation performance on Correlation Coefficient r for 1-, 5-, 10-, 20-, and 50-Step ahead 
predictions for laser time series.
Also from the close inspection Figures 41, 42 and 43 for short-term 1-, 5-, and 
10-step ahead prediction the FTLRNN output closely follows the desired output 
and from Figure 44 and Figure 45 for long-term 20- and 50-step ahead predic-
tions, it is clear that the FTLRNN output is slightly deviating from the desired 
output. 
© 2011 by Apple Academic Press, Inc.
  

44  Computer Technology and Computer Programming: New Research and Strategies
Figure 41. Plot between Desired versus Actual FTLRNN outputs for 1-step ahead predictions for FTLRNN 
Model.
Figure 42. Plot between Desired versus Actual FTLRNN Outputs for 5-step ahead prediction for FTLRNN 
Model.
Figure 43. Plot between Desired versus FTLRNN Outputs for 10-step ahead prediction for FTLRNN Model.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  45
Figure 44. Plot between Desired versus FTLRNN Output for 20-step ahead prediction for FTLRNN Model.
Figure 45. Plot between Desired versus Actual FTLRNN Output for 50-step ahead prediction for FTLRNN 
Model.
Conclusions
It is seen that focused time-lagged recurrent network with gamma memory is able 
to predict the differential equation generated Mackey-Glass and Duffing time 
series and real-world monthly sunspots and laser time series quite elegantly in 
comparison with the Multilayer perceptron (MLP). Static NN configuration such 
as MLPNN-based model fails to cope up with the underlying nonlinear dynam-
ics of the all the time series for short-term and long-term ahead predictions. It is 
observed that MSE NMSE of the proposed focused time-lagged recurrent neural 
network (FTLRNN) dynamic model for testing data set as well as for training 
data set are significant better than those of static MLP NN. In addition, it is also 
observed that the correlation coefficient of this model for testing and training 
© 2011 by Apple Academic Press, Inc.
  

46  Computer Technology and Computer Programming: New Research and Strategies
exemplars is much higher than that of MLPNN for the short-term and long-
term ahead predictions for the chaotic time series considered. The FTLRNN is 
trained for different combination of training samples and tested on testing data 
sets to find the robustness and sustainability of FTLRNN model for all the step 
ahead predictions for the differential equation generated and real-time chaotic 
time series. Also for the proposed FTLRNN model, the output closely follows the 
desired output and learned the true trajectory for short-term prediction. For long-
term prediction the output is slightly deviating for the considered benchmark 
chaotic time series as discussed.It is inferred from the experiments that the FTL-
RNN model with gamma memory has learned the dynamics of chaotic time series 
quite well as compared to multilayer perceptron network for testing data set (data 
set not used for training) with reasonable accuracy. On the contrary, it is observed 
that static MLP performs poorly bad, because on the one hand it yields much 
higher MSE and NMSE on testing data sets and on the other hand the correlation 
coefficient for testing data set is far less than unity. Hence the focused time-lagged 
recurrent neural network with gamma memory filter has outperformed the static 
MLP-based neural network better for short-term and for long-term ahead predic-
tions. Then the number of epochs is varied from 2000 to 20,000 in the steps of 
2000, and the network is trained for finding out the performance of the model 
for epoch’s variation. 
References
1.	 B. Townshend, “Nonlinear prediction of speech signals,” in Nonlinear Model-
ing and Forecasting, M. Casdagli and S. Euban, Eds., pp. 433–453, Addison-
Wesley, Reading, Mass, USA, 1992.
2.	 P. G. Cooper, M. N. Hays, and J. E. Whalen, “Neural networks for propaga-
tion modeling,” Atlantic Research Corporation Repot, Electromagnetic Envi-
ronmental Test facility, Fort Huachuca, Ariz, USA, 1992.
3.	 S. HayKin, Neural Networks: A Comprehensive Foundation, Pearson Educa-
tion, Delhi, India, 2nd edition, 2006.
4.	 A. S. Weigend and N. A. Greshenfeld, Time Series Prediction: Forecasting the 
Future and Understanding the Past, vol. 15 of Santa Fe Institute Studies in the 
Sciences of Complexity, Addison-Wesley, Reading, Mass, USA, 1993.
5.	 M. Casdagli, “Nonlinear prediction of chaotic time series,” Physica D, vol. 35, 
no. 3, pp. 335–356, 1989.
6.	 H. Leung and T. Lo, “Chaotic radar signal processing over the sea,” IEEE  
Journal of Oceanic Engineering, vol. 18, no. 3, pp. 287–295, 1993.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  47
7.	 H. Leung, “Applying chaos to radar detection in an ocean environment: an 
experimental study,” IEEE Journal of Oceanic Engineering, vol. 20, no. 1,  
pp. 56–64, 1995.
8.	 K. M. Short, “Steps toward unmasking secure communications,” International 
Journal of Bifurcation and Chaos, vol. 4, no. 4, pp. 959–977, 1994.
9.	 G. Heidari-Bateni and C. D. McGillen, “A chaotic direct-sequence spread-
spectrum communication system,” IEEE Transactions on Communications, 
vol. 42, no. 234, pp. 1524–1527, 1994.
10.	 Y. Fu and H. Leung, “Narrow-band interference cancellation in spread-spec-
trum communication systems using chaos,” IEEE Transactions on Circuits and 
Systems I, vol. 48, no. 7, pp. 847–858, 2001.
11.	 G. Cybenko, “Approximation by superpositions of a sigmoidal function,” 
Mathematics of Control, Signals, and Systems, vol. 2, no. 4, pp. 303–314, 
1989.
12.	 K. Hornik, M. Stinchcombe, and H. White, “Multilayer feedforward networks 
are universal approximators,” Neural Networks, vol. 2, no. 5, pp. 359–366, 
1989.
13.	 S. V. Dudul, “Prediction of a Lorenz chaotic attractor using two-layer percep-
tron neural network,” Applied Soft Computing, vol. 5, no. 4, pp. 333–355, 
2005.
14.	 S. V. Dudul, “Identification of a liquid saturated steam heat exchanger using 
focused time lagged recurrent neural network model,” IETE Journal of Re-
search, vol. 53, no. 1, pp. 69–82, 2007.
15.	 A. R. Barron, “Universal approximation bounds for superpositions of a sig-
moidal function,” IEEE Transactions on Information Theory, vol. 39, no. 3,  
pp. 930–945, 1993.
16.	 A. Juditsky, H. Hjalmarson, A. Benveniste, et al., “Nonlinear black-box mod-
els in system identification: mathematical foundations,” Automatica, vol. 31,  
no. 12, pp. 1725–1750, 1995.
17.	 R. Bakker, J. C. Schouten, C. L. Giles, F. Takens, and C. M. van den Bleek, 
“Learning chaotic attractors by neural networks,” Neural Computations,  
vol. 12, no. 10, pp. 2355–2383, 2000.
18.	 Z. Zhaocoui and D. Yurong, “Chaotic time series analysis based on radial basis 
function network,” Chinese Journal of Chongqing University, vol. 22, no. 6, 
pp. 113–120, 1999.
© 2011 by Apple Academic Press, Inc.
  

48  Computer Technology and Computer Programming: New Research and Strategies
19.	 H. Leung, T. Lo, and S. Wang, “Prediction of noisy chaotic time series using 
an optimal radialbasis function neural network,” IEEE Transactions on Neural 
Networks, vol. 12, no. 5, pp. 1163–1172, 2001.
20.	 G. Deco and M. Schurmann, “Neural learning of chaotic system behavior,” IE-
ICE Transactions Fundamentals, vol. E77-A, no. 11, pp. 1840–1845, 1994.
21.	 U. Thissen, R. van Brakel, A. P. de Weijer, W. J. Melssen, and L. M. C. Buydens, 
“Using support vector machines for time series prediction,” Chemometrics and 
Intelligent Laboratory Systems, vol. 69, no. 1-2, pp. 35–49, 2003.
22.	 S. A. Billings and H.-L. Wei, “A new class of wavelet networks for nonlinear 
system identification,” IEEE Transactions on Neural Networks, vol. 16, no. 4, 
pp. 862–874, 2005.
23.	 M. Han, J. Xi, S. Xu, and F.-L. Yin, “Prediction of chaotic time series based on 
the recurrent predictor neural network,” IEEE Transactions on Signal Process-
ing, vol. 52, no. 12, pp. 3409–3416, 2004.
24.	 A. Gholipour, B. N. Araabi, and C. Lucas, “Predicting chaotic time series using 
neural and neurofuzzy models: a comparative study,” Neural Processing Let-
ters, vol. 24, no. 3, pp. 217–239, 2006.
25.	 H. Inoue, Y. Fukunaga, and H. Narihisa, “Efficient hybrid neural network for 
chaotic time series prediction,” in Proceedings of the International Conference 
on Artificial Neural Networks (ICANN ‘01), vol. 2130 of Lecture Notes in 
Computer Science, pp. 712–718, Springer, Vienna, Austria, August 2001.
26.	 M. Han, M. Fan, and J. Xi, “Study of nonlinear multivariate time series pre-
diction based on neural networks,” in Proceedings of the 2nd International 
Symposium on Neural Networks (ISNN ‘05), vol. 3497 of Lecture Notes in 
Computer Science, pp. 618–623, Chongqing, China, May-June 2005.
27.	 S.-Z. Qin, H.-T. Su, and T. J. McAvoy, “Comparison of four neural net learn-
ing methods for dynamic system identification,” IEEE Transactions on Neural 
Networks, vol. 3, no. 1, pp. 122–130, 1992.
28.	 K. S. Naraendra and K. Parthasarathy, “Identification and control of dynam-
ic systems using neural networks,” IEEE Transactions on Neural Networks,  
vol. 1, no. 1, pp. 4–27, 1990.
29.	 Demuth and M. Beale, “Neural network tool box for use with MATLAB,” 
Users Guide, Version 4.0, The MathWorks, Inc., Natick, Mass, USA, 2004, 
http://www.mathworks.com.
30.	 G. F. FranKlin, J. D. Powell, and M. L. WorKman, Digital Control of Dynam-
ics Systems, Addison-Wesley, Reading, Mass, USA, 3rd edition, 1998.
© 2011 by Apple Academic Press, Inc.
  

Novel FTLRNN with Gamma Memory for Short-Term and Long-Term  49
31.	 F. M. Ham and I. Kostanic, Principles of Neurocomputing for Science and 
Engineering, Tata McGraw-Hill, New Delhi, India, 2002.
32.	 B. de Vries and J. C. Principe, “The gamma model—a new neural model for 
temporal processing,” Neural Networks, vol. 5, no. 4, pp. 565–576, 1992.
33.	 J. C. Principe and N. R. Euliano, Neural and Adaptive Systems: Fundamental 
through Simulations, John Wiley & Sons, New York, NY, USA, 2000.
34.	 M. C. Mackey and L. Glass, “Oscillation and chaos in physiological control 
systems,” Science, vol. 197, no. 4300, pp. 287–289, 1977.
35.	 H. Nijmeijer and H. Berghuis, “On Lyapunov control of the Duffing equa-
tion,” IEEE Transactions on Circuits and Systems I, vol. 42, no. 8, pp. 473–
477, 1995.
36.	 S. Sello, “Solar cycle forecasting: a nonlinear dynamics approach,” Astronomy 
and Astrophysics, vol. 377, no. 1, pp. 312–320, 2001.
37.	 J. K. Lawrence, A. C. Cadavid, and A. A. Ruzmaikin, “Turbulent and cha-
otic dynamics underlying solar magnetic variability,” Astrophysical Journal,  
vol. 455, p. 366, 1995.
38.	 Q. Zhang, “A nonlinear prediction of the smoothed monthly sunspot num-
bers,” Astronomy and Astrophysics, vol. 310, pp. 646–650, 1996.
39.	 T. Schreiber, “Interdisciplinary application of nonlinear time series methods,” 
Physical Reports, vol. 308, no. 1, pp. 2–64, 1998.
40.	 http://sidc.oma.be/index.php3.
41.	 U. Hübner, N. B. Abraham, and C. O. Weiss, “Dimensions and entropies of 
chaotic intensity pulsations in a single-mode far-infrared NH3 laser,” Physical 
Review A, vol. 40, no. 11, pp. 6354–6365, 1989.
42.	 I. V. Turchenko, “Simulation modeling of multi-parameter sensor signal iden-
tification using neural networks,” in Proceedings of the 2nd IEEE International 
Conference on Intelligent Systems (IS ‘04), vol. 3, pp. 48–53, Varna, Bulgaria, 
June 2004.
43.	 G.-B. Huang, Y.-Q. Chen, and H. A. Babri, “Classification ability of single 
hidden layer feedforward neural networks,” IEEE Transactions on Neural Net-
works, vol. 11, no. 3, pp. 799–801, 2000.
44.	 K. W. Lee and H. N. Lam, “Optimal sizing of feed-forward neural networks: 
case studies,” in Proceedings of the 2nd New Zealand Two-Stream Interna-
tional Conference on Artificial Neural Networks and Expert Systems (ANNES 
‘95), pp. 71–82, Dunedin, New Zealand, November 1995.
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection 
Network for Dynamically 
and Partially Reconfigurable 
Architectures
Ludovic Devaux, Sana Ben Sassi, Sebastien Pillement,  
Daniel Chillet and Didier Demigny
Abstract
The dynamic and partial reconfiguration of FPGAs enables the dynamic 
placement in reconfigurable zones of the tasks that describe an application. 
However, the dynamic management of the tasks impacts the communica-
tions since tasks are not present in the FPGA during all computation time. 
So, the task manager should ensure the allocation of each new task and their 
interconnection which is performed by a flexible interconnection network. In 
this article, various communication architectures, in particular interconnec-
tion networks, are studied. Each architecture is evaluated with respect to its  
© 2011 by Apple Academic Press, Inc.

Flexible Interconnection Network for Dynamically  51
suitability for the paradigm of the dynamic and partial reconfiguration in 
FPGA implementations. This study leads us to propose the DRAFT network 
that supports the communication constraints into the context of dynamic re-
configuration. We also present DRAGOON, the automatic generator of net-
works, which allows to implement and to simulate the DRAFT topology. 
Finally, DRAFT and the two most popular Networks-on-Chip are imple-
mented in several configurations using DRAGOON, and compared consider-
ing real implementation results.
Introduction
Steady technological evolutions, increasingly complex applications, can be sup-
ported by reconfigurable architectures. This is particularly true into the frame-
work of complex signal processing applications. However, when the number of 
tasks constituting an application exceeds the available hardware resources, design-
ers have two options: increasing the number of resources (which increase the com-
plexity of the systems) or implementing only the tasks that should be executed at 
a given time. In the latter case, tasks are swapped at the end of their execution by 
freeing logical resources for the others. However, this concept is relevant only if a 
new task can be implemented instead of a former one without disrupting the ex-
ecution of other tasks. This concept of hardware preemption of the tasks is called 
Dynamic and Partial Reconfiguration (DPR). 
The objective of the FOSFOR research project (Flexible Operating System for 
Reconfigurable devices) [1] is to specify and to implement an Operating System 
(OS) that provides an abstraction of technology for future applications. For this 
purpose, the FOSFOR OS operates the DPR in order to support complex appli-
cations that cannot be statically implemented due to physical restrictions. Several 
services of the OS are implemented in hardware whereas others are computed in 
software. Physical implementation of some services allows the OS to efficiently 
manage hardware and software tasks. In this direction, the FOSFOR project fo-
cuses on the hardware implementation of the main services: the task placer and 
scheduler, the memory manager, and the communication service.
In this work, the communication service is investigated. The objective is to de-
fine and to implement in an FPGA a generic interconnection architecture which 
should support the diversity of applications and the dynamic management of 
the tasks. For this purpose, the architecture takes into account the constraints 
imposed by the DPR. Through the physical interconnection architecture and its 
control, the communication service provides a flexible way for transferring data 
between every Communicating Element (CE) in an FPGA. Since an application 
© 2011 by Apple Academic Press, Inc.
  

52  Computer Technology and Computer Programming: New Research and Strategies
task can be implemented in hardware or processed in software by a hardware pro-
cessor, CEs are defined as the hardware elements which exchange data. So, a CE 
can be the hardware implementation of a task (static or dynamic), a shared ele-
ment (memory, input/output), or a hardware processor running software tasks. 
The paper is organized as follows. Assumptions induced by the DPR that 
should be supported by an interconnection architecture are presented in Section 
2. Then, current interconnection architectures are detailed and reviewed in Sec-
tion 3. The interconnection network called Dynamic Reconfiguration Adapted 
Fat-Tree (DRAFT), which is specifically designed to support the DPR require-
ments in FPGAs, is presented in Section 4. Dynamically Reconfigurable Archi-
tectures compliant Generator and simulatOr Of Network (DRAGOON), the 
automatic generator of networks supporting the DRAFT topology is introduced 
in Section 5. Then, the comparison between DRAFT and the two more popular 
Networks-on-Chip (NoC) topologies is presented with respect to implementa-
tion costs and network performances in Section 6. Finally, an implementation of 
the DRAFT network into the framework of an application from the FOSFOR 
project is detailed in Section 7.
Assumptions on Considered Interconnection 
Architectures
Keeping in view of a large range of applications, an interconnection architecture 
should support several constraints into the framework of an implementation in 
FPGAs. Current applications are very complex and their task graphs exhibit a 
large degree of parallelism. Thus, from the interconnection point of view, the ar-
chitecture must provide the possibility to realize several communications in paral-
lel. Furthermore, dynamic placement and scheduling of CEs in an FPGA require 
a high level of flexibility, since the placement and the scheduling of the CEs are 
dynamic. So, neither the location of CEs nor the data traffic (uniform, all to one, 
etc.) can be predicted at compile time. These requirements of flexibility should be 
considered by the network topology, the routing protocol, and the available net-
work performances (bandwidth and latency). An application is typically split into 
dynamic and static tasks, and there are no reason for every task to be implemented 
in homogeneous hardware CEs. This point differs from approaches like [2] where 
CEs are supposed to be homogeneous so that the interconnection topology can be 
dynamically reconfigured into an FPGA in order to fit the application. Heteroge-
neous hardware CEs are considered in this work. Hence, a single interconnection 
topology compliant with this heterogeneity is preferred to dynamically reconfigu-
rable topologies considering their placement constraints as the placement of the 
CEs themselves. 
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  53
Considering current FPGAs, Altera devices provide abundant programmable 
resources but do not support the partial reconfiguration of everyone of them [3, 
4]. Atmel series AT40K5AL to AT40K40AL are compliant with the DPR of their 
resources but do not provide more than 50 K gates which are few when con-
sidering complex applications [5]. Hence, Xilinx FPGAs (especially the Virtex 
2Pro, Virtex 4, Virtex 5, and Virtex 6) are the only ones that both provide suf-
ficient programmable resources to implement complex applications and support 
the DPR paradigm [6]. Xilinx architectures offer a column-based distribution of 
their resources, as shown Figure 1. In a Virtex family (except in Virtex 2Pro), the 
center column is very specific because it contains not only Input/Output (IO) 
banks, but also clock managers and DPR ports (ICAP). So, despite their column-
based structure, FPGAs are very heterogeneous. Consequently, the interconnec-
tion should support the heterogeneity of the FPGAs.
Figure 1. View of a Xilinx Virtex5 5VSX50T FPGA captured from the PlanAhead Xilinx software [7].
Xilinx DPR takes place in specific reconfigurable regions called Partially 
Reconfigurable Regions (PRRs), which hence constitute the dynamic parts of 
a system. Dynamic CEs are allocated in these regions. Static CEs (static hard-
ware tasks, memories, processors, etc.) are implemented all around the PRRs 
and constitute the static part of the system. Communications between dy-
namic and static regions are performed through interfaces called Bus Macros 
(BMs) in Xilinx architectures [8]. Since PRRs and BMs are defined statically 
at compile time, every CE is connected to the interconnection architecture 
through static interfaces (despite the dynamic locations of the CEs). So, the 
interconnection architecture can be static if it provides sufficient flexibility to 
support the DPR paradigm.
© 2011 by Apple Academic Press, Inc.
  

54  Computer Technology and Computer Programming: New Research and Strategies
Interconnection Architectures: State of the Art
In this section, several interconnection architectures, suitable for supporting the 
paradigm of the DPR, are analyzed and evaluated. The main constraints are the 
parallelism of the communications, the flexibility, and the compliance with the 
connection of heterogeneous CEs in heterogeneous FPGAs.
Bus-Based Architectures
Buses are interconnection architectures which are simple to implement and con-
trol, while requiring few hardware resources.
Main-Bus-Based Architectures
One of the first bus-based approaches designed for DPR was Core Unifier [9]. 
Core Unifier is a tool that allows connecting on the fly dynamic CEs on a bus. 
For this, the tool adds 3-states buffers to the bus on which dynamic CEs are con-
nected. However, at compile time, Core Unifier needs the knowledge of when 
and where the CEs should be allocated. So, this approach is not compliant with 
systems in which scheduling and placement are dynamic. 
The Bus-Macro-based architecture [10] and Recobus [11] are the most recent 
bus-based dynamic interconnection architectures. The communication interfaces 
of the Recobus approach require less logical resources than the Bus-Macro-based 
architecture. However, both approaches are based over a horizontal bus connect-
ing vertically placed CEs. CEs are implemented using all the logical resources of 
a column. So, those approaches are only compliant with the 1D placement (CEs 
are allocated using several columns of resources of the FPGA) of the dynamic 
CEs. It is the major limitation of these architectures because it leads to a waste of 
hardware resources, depending on the size of the CEs. Furthermore, current FP-
GAs (except the Xilinx Virtex 2Pro series) are compliant with the 2D placement 
(rectangular region based) of CEs. So, none of these approaches seems suitable 
to implement a system using DPR in latest FPGAs. Another architecture is the 
HoneyComb [12], which is a static interconnection architecture connecting static 
CEs but differing from other bus-based structures. This network, made of regular 
hexagonal cells linked together through bidirectional buses, allows data routing. 
HoneyComb offers flexibility at the data path level while using few hardware re-
sources. However, the regular structure is not compliant with current FPGAs nor 
with dynamic and heterogeneous CEs. So, Honeycomb brings more flexibility 
than other bus-based architectures but it does not support the DPR paradigm due 
to its regular structure.
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  55
Limitations of Buses
Buses exhibit several drawbacks when considering an application using the DPR. 
A major constraint for the bus-based interconnection architecture is the neces-
sity to support several data transfers in parallel. One bus supports only a single 
transfer at a time. There are two solutions for this problem. One is to use several 
communication lines (multiple buses [13]); the other is to split a bus into a set of 
independent segments interconnected through several bridges (GALS approach 
[14]). However, either solution implies an increase of the required hardware re-
sources: the connection of two buses generates a need of buffers (synchronous or 
asynchronous FIFOs). In order to estimate the size of these buffers, the knowledge 
of the data traffic is required to avoid bottleneck risks. In a dynamic system where 
the locations of CEs and the data traffic are unknown at compile time, buffers 
should be designed to support the worst cases of communication. For instance, 
the RMBoC approach [15] uses multiple and segmented buses for DPR compli-
ance. However, despite the estimation of buffer sizes, this approach requires a lot 
of hardware resources to connect the CEs. 
To date, the bus-based architectures have not been implemented efficiently 
to answer the DPR paradigm. Poor flexibility and scalability also with placement 
limited to 1D are the main drawbacks of bus-based approaches which motivated 
many researchers to consider the Network-on-Chip (NoC) paradigm [16].
Network-on-Chip Based Architectures
A NoC can be seen as a set of routers, links and network interfaces. The commu-
nication topologies and routing protocols (including data flow control, schedul-
ing policies, etc.) are key domains of research [17]. Nowadays, there are a lot of 
NoCs which can be classified in a few basic families, depending on their topology. 
Hence, we shall concentrate on the meshes, the application-dependent topolo-
gies, the rings and the trees (Figure 2).
Mesh Topology
A mesh topology offers a simple connection scheme (Figure 2(a)), based on a 
matrix of routers interconnecting regularly implemented CEs. Many meshes were 
implemented such as HERMES [18]. If the number of connected CEs is N and 
if D is the radix of the mesh, then the number of routers needed to build a square 
mesh is
	
2
2.
mesh
R
N
D
é
ù
=
=
ê
ú
	
(1)
© 2011 by Apple Academic Press, Inc.
  

56  Computer Technology and Computer Programming: New Research and Strategies
Figure 2. Network topologies: (a) mesh, (b) application-dependent topology, (c) ring, and (d) tree. Routers are 
denoted with “R” and communicating elements with “CE.”
Whereas the number of needed communication links is
	
Lmesh=N+2(D2-D).	
(2)
The connection of heterogeneous CEs to a regular matrix based network may 
be problematic. A solution consists in considering that tasks are implemented 
using one or several homogeneous CEs [19] which are interconnected regularly 
by the mesh. This solution is used, for example, by the DyNoC approach [20]. 
Unfortunately, logical resources could be wasted when a small task is executed 
by a large CE. When a large task is implemented using several CEs, some logical 
resources are also wasted depending on the granularity of the CEs (Figure 3).
When a task is implemented using several CEs, then CEs can communicate 
in two ways. The first one is to consider that the communications between the 
CEs are performed through the network. However, this solution constrains the 
design of the tasks because each internal communication should be designed 
to be performed by the network. So, with this solution, the complexity of the 
tasks increases and the number of required resources too. Thus, this solution is  
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  57
impractical for designers. Another solution is to consider that a task is imple-
mented with dedicated links between the CEs. However, the compliance between 
the task and the technology becomes difficult due to the limited (and reduced) 
number of available communication links. 
Figure 3. Implementation of three different tasks (executed by one or several CEs) using a mesh network.
A truly regular mesh is based on the assumption that the FPGA is intrinsically 
homogeneous. So, every CE presents the same hardware properties for task imple-
mentation. Considering the heterogeneous structure of available FPGAs, it seems 
quite difficult to implement a truly regular mesh. Finally, another problem of the 
mesh structure lies in the connection of shared elements like memories or IOs. 
Indeed, the communication requirements between tasks (hardware or software) 
and shared elements induce the creation of hot-spots, which could increase the 
likelihood of livelock and deadlock.
Application-Dependent Topology
CoNoChi (Figure 2(b)) shows an example of network which topology differs de-
pending on the application [21]. In this approach, the FPGA is divided into 
regular dynamically reconfigurable regions, with each being defined dynamically 
as a router, a set of interconnection links, or a CE. 
Despite many advantages, the concept of dynamic topology is impractical 
since PRRs are statically defined in current FPGAs. Hence, their use for link 
© 2011 by Apple Academic Press, Inc.
  

58  Computer Technology and Computer Programming: New Research and Strategies
implementation implies wasting a lot of logical resources. Moreover, considering 
the resulting topology of CoNoChi which differs with the application, the design 
time can be important to obtain optimal network performances. Indeed, the rout-
ing protocol should take into account the network topology which is application-
dependent. Keeping in mind these drawbacks, static and generic topologies are 
preferred to dynamic ones in order to limit the design times and to increase the 
predictable nature of the network performances.
Ring Topology
Rings (Figure 2(c)) are presently used by industrials like IBM with the Cell Broad-
band Engine [22]. This architecture can be very efficient. However, in some ap-
plications, it offers lower performances than a mesh [23]. Indeed, the available 
bandwidth depends on the characteristics of the routers and on the number of 
interconnected CEs. Another drawback of the rings lies in the dependence be-
tween latencies and CE locations. So, in the context of the DPR, rings should be 
interesting if bandwidth did not decreased when the number of connected CEs 
increases, and furthermore if the latency was not dependent with the placement 
of the CEs.
Fat-Tree Topology
Trees, and more precisely fat-trees (Figure 2(d)), are indirect interconnection net-
works. Some routers are only used for data transfers and do not connect directly 
the CEs. A fat-tree is based on complete binary tree. Every CE is connected to a 
router located at the base-level of the tree. Each hierarchical level of the fat-tree is 
linked to upper and lower levels through bidirectional links [23]. The main char-
acteristic of a fat-tree is the aggregative bandwidth (offered by all the links located 
at the base of the tree) which remains constant between each hierarchical level all 
the way to the root. A fat-tree offers many advantages compared with other to-
pologies, two of which are a large bandwidth and a low latency [24]. A fat-tree can 
also simulate every other topology at the cost of the appropriate control [25]. 
Since every CE is connected to a base-level router of the fat-tree, they are 
not distributed into the network structure. This point is important because CEs 
can be heterogeneous from the resource consumption point of view. Indeed, the 
resource heterogeneity does not impact the transfer times like in a mesh. Further-
more, the structure of the tree does not need to be implemented regularly. So, a 
fat-tree is compliant with current FPGAs. 
Thanks to its constant bandwidth between every hierarchical level, the fat-
tree avoids deadlock risks which exist in other topologies without an appropriate 
control [26]. 
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  59
However, a fat-tree needs many logical resources for routing purpose when 
the number of connected CEs increases significantly. If the number of connected 
CEs is N and the number of communication ports for each router is k, then the 
number of routers in a fat-tree [26] is
	
Rfat-tree = 
/2
2
(log
).
k
N
N
k
	
(3)
In this formula, assuming that the fat-tree is complete in terms of connected 
CEs, N is expressed by N=2x where x is an integer and x≥1. When N does not 
match the previous formula, designers should build the network considering the 
admissible value of N just higher in order to keep the complete tree-based struc-
ture of the network. The number of connection links needed by the fat-tree topol-
ogy [26] is
	
/2
(log
).
fat
tree
k
L
N
N
-
=
	
(4)
To limit the resource consumption, the XGFT [27] allows the connection of 
several CEs to only one communication port of a router. Indeed, the fat-tree con-
nects several sets of CEs, which are interconnected by a bus. This approach is very 
interesting in the context of a static application because this topology optimizes 
the number of connected CEs in comparison with used resources for routing pur-
pose. However, the XGFT is not optimal into the framework of the DPR. Indeed, 
the sets of CEs have the same drawbacks as bus-based architectures (control time, 
one communication at a time without multiple buses, etc.).
Summary of the Interconnection Architectures
The compliance between presented interconnections and the constraints of the 
DPR paradigm are summarized in Table 1.
Table 1. Compliance between current interconnection structures and DPR constraints.
© 2011 by Apple Academic Press, Inc.
  

60  Computer Technology and Computer Programming: New Research and Strategies
From Table 1, a fat-tree is best adapted to the DPR paradigm and applicative 
requirements. However, its resource consumption remains the main drawback for 
an implementation into an FPGA. Thereby, this study of current interconnections 
leads to the Dynamic Reconfiguration Adapted Fat-Tree (DRAFT) network.
Flexible Interconnection: DRAFT
From the comparison of current NoCs, the fat-tree appears to be the most suit-
able interconnection architecture to support the DPR paradigm and applicative 
requirements. DRAFT is a fat-tree-based network whose main characteristic lies 
in the reduction of needed resources for routing purpose. Like a fat-tree, DRAFT 
interconnects several CEs, which could be implementations of hardware tasks 
(static or dynamic), processors running software tasks, and shared elements like 
shared memories.
DRAFT Topology
The concept proposed in DRAFT is to directly connect half of the CEs to the 
root-level routers of a fat-tree (Figure 4). This concept reduces a lot the number 
of hardware resources used for routing purpose compared with the number of 
connected CEs. Indeed, for the same number of connected CEs, the number of 
routers is divided by two when compared with the fat-tree topology.
Figure 4. The DRAFT topology. Communicating elements “CEs” are connected to the root and base-levels of 
a fat-tree network.
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  61
Concerning network performances, the distances between the root and base-
level CEs are constant whatever their locations. So, the minimal latencies of these 
communications are constant. However, for the effectiveness of this topology, 
it is necessary that the CEs connected to the root communicate only with the 
base-level connected ones. This assumption avoids the creation of hotspots in the 
root-level router. Communications between the CEs connected to the root would 
require additional hierarchical levels (leading to the fat-tree topology) in order not 
to increase the load on the root-level router. However, the base-level connected 
CEs can freely communicate with every other CE. This assumption is very impor-
tant and while it is observed, there is no limitation concerning the nature of the 
CEs. A designer is free to connect its shared elements to the root-level of DRAFT, 
but also some hardware tasks (static or dynamic) or even processors. So, at the cost 
of this assumption, DRAFT is completely flexible.
Hardware Requirements
The hardware resources required by DRAFT should be considered first. If the 
number of connected CEs is N and the number of communication ports for each 
router is k, then the number of routers in DRAFT is
	
(
)
(
)
/2
log
1 .
DRAFT
k
N
R
N
k
=
-
	
(5)
In this formula, assuming that DRAFT is complete in terms of connected 
CEs, N should be in the form of N=2x where x is an integer and x≥2. If the num-
ber of CEs does not match previous formula at design time, then designers should 
build the network considering the just higher admissible value of N. Similarly, the 
number of connection links needed by DRAFT is
	
(
)
/2
log
.
2
DRAFT
k
N
L
N
=
	
(6)
From this last formula, DRAFT uses two times less connection links than a 
fat-tree. This is an advantage for the implementation in current FPGAs. 
There are several ways to see a fat-tree and so is DRAFT. Thereby, the two 
fat-trees presented in Figures 4 and 5 have the same properties regarding the CEs. 
Indeed, a router in Figure 4 can be broken up into a set of several unitary routers 
called fat-node (Figure 5). This permits to build the network by using a single 
router type, which is generically defined, and makes the automatic generation of 
DRAFT easier. However, the latter structure is not fully compliant with the con-
nexion of the CEs to the root-level, since there is only one admissible data path 
between base- and root-level CEs. The router-based structure (Figure 4) is more 
© 2011 by Apple Academic Press, Inc.
  

62  Computer Technology and Computer Programming: New Research and Strategies
flexible due to multiple data paths. If a communication link is already used, data 
can be transferred through another one to the same destination. This traffic adap-
tive approach is not possible in the fat-node-based structure for the communica-
tions between CEs from the root and base-levels. However, in both structures, a 
traffic adaptive routing can be implemented for the communications between two 
base-level connected CEs. So, the fat-node-based structure is less flexible than the 
router-based one but more generic. Furthermore, it allows to demonstrate the vi-
ability of DRAFT even if it constrains the data paths. In a first time, the focus is 
over the fat-node-based structure due to the generic routers. In future works, the 
structure will be switched to the router-based one in order to support applications 
requiring multiple data paths between elements from the base and root-levels.
Figure 5. Fat-node view of DRAFT architecture. A fat-node is a set of unitary routers.
Principles of Connection of Various CEs
Since many applications require data transfers between static and dynamic CEs, 
they should be connected to DRAFT. For this purpose, designers can connect 
the static CEs directly to the routers, or with a bus-based sub-network (multiple 
buses e.g.,) connected to a single router, like for the XGFT network. In the lat-
ter structure, while CEs are static, the sub-network can be optimally designed 
for their communication needs. Then, the sub-network and its connected CEs 
(statically implemented tasks, processors, shared elements, etc.) are viewed by 
DRAFT as a single CE. On the other hand, the static CEs which do not exchange 
data with dynamic ones should be interconnected through a separate network  
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  63
optimally designed for this purpose. Similarly, the shared elements which do not 
communicate with dynamic CEs but only with static ones should be connected to 
a sub-network rather than to DRAFT. These principles are advised to reduce the 
size of DRAFT and so its resource consumption. Doing so, DRAFT can be seen 
as an independent core of network or even as an Intellectual Property (IP) block 
connecting each part of the application, while providing the flexibility required 
by the DPR paradigm. 
For applications using the DPR, DRAFT does not directly connect the tasks 
through their network interfaces, but through the Bus Macros (BMs). So, BMs 
are the interfaces between DRAFT and the dynamic CEs (including their net-
work interfaces (NIs)) as presented in Figure 6.
Figure 6. PRR receiving a dynamic CE connected to DRAFT through the dynamic NI and the static BMs.
This concept of dynamically reconfigurable NIs is important because they can 
be designed optimally for their corresponding CEs. This allows to reduce the 
hardware cost of the NIs when a CE does not have the same interface as the oth-
ers. So during the dynamic reconfiguration of a given PRR, DRAFT interface 
remains the same even if the newly allocated CE presents a specific interface. So, 
this concept makes DRAFT more generic and more flexible considering the loca-
tion of the CEs.
Hardware Characteristics of the Routers
The router architecture (Figure 7) is based over four bidirectional communica-
tion ports, each including an asynchronous FIFO. FIFO sizes are defined by the 
designer depending on the flit width (data are fractioned into several small sets 
© 2011 by Apple Academic Press, Inc.
  

64  Computer Technology and Computer Programming: New Research and Strategies
of bits called flits), and on the number of flits to store, according to the data flow 
and the livelock management protocol (credit based, priority, round robin, etc.). 
A crossbar, controlled by a routing manager which protocol is based on a Turn-
Back algorithm [28], performs the routing of data.
Figure 7. View of the DRAFT unitary router architecture.
The next destination of a message is computed by each router receiving it. The 
decision is made using several masks over the message source and destination ad-
dresses included into the message header. Each router is identified by an internal 
address which indicates its hierarchical level and its location into this level. Simi-
larly, every CE connected to DRAFT is identified by an internal address which is 
used to specify the source and the destination of a message. This addressing of the 
CEs and routers is presented in Figure 8.
Figure 8. Generic addressing of the CEs and routers depending on their hierarchical levels and their locations 
into these levels.
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  65
Thanks to these addresses, each router uses a hierarchical level dependent mask 
to determine if a flit should be routed toward an upper hierarchical level in order 
to reach a different part of the tree. So, each data is routed toward the high until 
it is able to go down to the desired half (or subpart) of the tree. This lowering 
routing is directly applied to the CEs connected to the root-level of DRAFT. Des-
tination addresses are sufficient to determine toward which part of the tree a data 
should be routed. This algorithm, presented in Algorithm 1, provides a minimal 
distance to the data transfers and the guaranty that there is no deadlock risk [27]. 
In this algorithm, the source and destination addresses of a data are called, respec-
tively, CEsrc and CEdest. The mask is directly calculated from the Y address of the 
router corresponding to its hierarchical level. As an example, for router X:0010 
Y:0001, the corresponding mask is 0011. The Mshift parameter is the mask previ-
ously calculated shifted right of one bit set to 1. Thus, in this example, Mshift is 
1001. Similarly, the RXshift is calculated from the X address of the router shifted 
left of one bit, that is, 0100 in the example.
Algorithm 1: Routing algorithm implemented into DRAFT routers.
In order to keep static the DRAFT architecture into the framework of the 
DPR, addressing of the routers and CEs is generic. However, since many CEs are 
dynamic, it constrains the designer to make sure that the task placer/scheduler 
keeps up-to-date a routing table. This table is essential for the network interfaces 
of the CEs to make the correspondence between the internal addresses and the 
physical elements (implemented task, memory, etc.).
© 2011 by Apple Academic Press, Inc.
  

66  Computer Technology and Computer Programming: New Research and Strategies
Implementation of DRAFT in a Xilinx FPGA
DRAFT placement is important in the conception of a system using the DPR, 
because it impacts the use of the reconfigurable resources as well as the network 
performances. Thus, the concept presented in Figure 9 is to implement DRAFT 
as a central column into the FPGA. This concept is particularly adapted to current 
technologies supporting the DPR: Xilinx Virtex 4, Virtex 5, and Virtex 6 FPGAs. 
CEs are implemented into both halves of the FPGA with the static elements of 
the application (processor, etc.). Since DRAFT is not distributed into the FPGA, 
the designer is not constrained by the network for the definition of the CEs in 
terms of sizes and locations. This is an advantage for the implementation of het-
erogeneous dynamic CEs. Thus, the implementation of DRAFT is fully compli-
ant with current technology and the DPR requirements.
Figure 9. Implementation of DRAFT as a central column interconnecting CEs which are located into both 
halves of the FPGA.
In present technology, PRRs and BMs are defined statically, but there is no 
physical obstacle to make them dynamic. The limitation is only due to the design 
tools which do not support the dynamic definition of the partially reconfigurable 
regions. Consequently, if the design software allows the definition of dynamically 
locatable PRRs, then every base- (or roots) level router should be reachable from 
both halves of the FPGA. Doing so, the dynamic relocation of a PRR from one 
half of the FPGA to the other will be supported. 
In Xilinx FPGAs, shared IOs should be located into the central IO bank col-
umn. Similarly, it is recommended to locate the shared memories into the BRAM 
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  67
columns the nearest of the central column. Thereby, the communications between 
the CEs and the shared elements encounter a minimal latency.
Presentation of DRAGOON
In this section, the design software called Dynamically Reconfigurable Architec-
ture compliant Generator and simulatOr Of Network (DRAGOON) is present-
ed. DRAGOON is a conception environment specifically designed to generate 
and to simulate the DRAFT topology. It is inspired from ATLAS which was 
developed to support Hermes NoCs [18]. DRAGOON is also compliant with 
the fat-tree topology. The conception flow provided by DRAGOON is illustrated 
Figure 10, in which every step corresponds to a tool.
Figure 10. Conception flow of DRAGOON.
The NoC generation tool produces the VHDL description of DRAFT and 
test benches written on SystemC, according to the configuration chosen by the 
user. This latter is able to choose the network dimension in terms of connected 
CEs, and also the flit width or the buffer depth. The flit width parameter deter-
mines the length of the data (fractioned into unitary flits) exchanged through the 
© 2011 by Apple Academic Press, Inc.
  

68  Computer Technology and Computer Programming: New Research and Strategies
network. Flit width can be set to 16, 32, or 64 bits. The buffer depth indicates 
how many flits can be stored into one of the four FIFOs of a router. So, a router 
can store 4, 8, 16, or 32 flits into each of its 4 ports. The number of virtual 
channels can also be chosen by the user. Using virtual channels, a router is able 
to support several communications in parallel at the cost of hardware resources. 
Concerning the data traffic, the type of flow control (credit based or handshake) 
and the scheduling policy (round robin or priority) are parameterizable. So, the 
NoC generation tool allows generating DRAFT networks adapted to the require-
ments of many applications. 
The traffic generation tool produces different data traffics (uniform, normal, 
pareto on/off). Each traffic simulates an application supported by DRAFT. A 
uniform traffic simulates applications using a constant data flow like video pro-
cessing. A normal traffic is provided by applications using data dependency like 
pattern recognition or target tracking. Finally, the pareto on/off traffic simulates 
the communications between a task and a shared memory where data is transmit-
ted using a burst mode (period of uninterrupted data transmission followed by a 
period of silence). Furthermore, the traffic generation tool allows the designer to 
simulate several configurations of the connected CEs. Indeed, the frequencies of 
the CEs, the targets of data (random or specific), the number of packets to send, 
and the number of flits in a packet are parameterizable. Designer can also specify 
the transmission rate of each CE. Using all these parameters, the traffic generator 
builds input files containing data to be transmitted through the network. 
The simulation tool invokes an external VHDL simulator (ModelSim). This 
simulator was chosen because it supports mixed VHDL and SystemC. Thus, the 
simulation tool uses the description of the NoC and the generated traffic. This 
traffic is injected into DRAFT during the simulation phase, which is concluded 
when the output files are generated. 
The evaluation tool provides the interpretation of the results thanks to the pre-
viously generated output files. Results are analyzed and presented through graph-
ics and analysis reports. Network performances like latency and throughput are 
the main results provided by the evaluation tool.
Implementation Results
In this section, DRAFT implementation results are presented. Thanks to the 
automatic network generator (DRAGOON), DRAFT is compared with the 
mesh and the fat-tree topologies. This comparison takes into account the use of 
hardware resources and the network performances. The impacts of the NoC and 
traffic parameters over hardware and network characteristics are also presented. 
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  69
Hardware resources are obtained thanks to Xilinx ISE 9.2i tool chain [29], and 
network performances are measured through ModelSim 9.5c [30] and presented 
thanks to DRAGOON. From this comparison, the viability and the effectiveness 
of DRAFT are demonstrated. 
For a fair comparison of the three different network topologies, some hy-
pothesis must be considered. Every topology is implemented for maximal net-
work performances. So, both DRAFT and fat-tree architectures are based over 
a complete binary tree whatever the number of connected CEs. Similarly, every 
implemented mesh presents a square matrix based structure whatever the number 
of connected CEs. The mesh topology is implemented and simulated using AT-
LAS while DRAFT and fat-tree topologies are provided by DRAGOON. Since 
the fat-tree and DRAFT are generated with a fat-node-based structure, the three 
networks are implemented with the same router architectures and without vir-
tual channels. The routing algorithm is the only component which differs from a 
topology to another one, so the topologies are compared independently of their 
router architecture. Every router is clocked at 100 MHz.
Hardware Resources
DRAFT is defined as a network which supports the DPR requirements and mini-
mizes the hardware resource consumption. In this part, implementation results 
are investigated, and presented in Figure 11. For this purpose, each router was 
implemented with a flit width of 32 bits and a buffer depth of 4 flits.
From these implementation results, as expected, a fat-tree needs more hard-
ware resources and more communication links than every other topology. How-
ever, using the root-level connection of the CEs, DRAFT needs less hardware 
resources and less communication links than a mesh when the number of con-
nected CEs is less than 16. When this number increases, resource consumptions 
are very close but DRAFT needs less resources when the number of connected 
CEs becomes close to a power of 2. However, DRAFT outnumbers mesh re-
sources in small ranges like from 17 to 25 connected CEs. This point is due to the 
assumption that DRAFT is implemented as a complete binary tree and the mesh 
as a square matrix. Hence, DRAFT needs 32 routers to connect from 17 to 32 
CEs while a mesh needs only 25 routers to connect from 17 to 25 CEs. Then, this 
latter needs 36 routers to connect from 26 to 32 routers. The number of routing 
wires increasingly becomes a limiting factor in FPGAs, so the fact that DRAFT 
requires less links than a mesh is an important matter for the designers. Using 
the DRAFT network, designers have more communication links available for the 
implementation of their tasks.
© 2011 by Apple Academic Press, Inc.
  

70  Computer Technology and Computer Programming: New Research and Strategies
Figure 11. Number of registers (a), LUTs (b), and links (c) used for DRAFT, fat-tree, and mesh implementations 
in a Xilinx Virtex5 depending on the number of connected CEs.
Network Performances
Usually, latency and throughput results are presented depending on the injection 
rate. The injection rate corresponds to the percentage of the maximal bandwidth 
which is used to send data from the CEs point of view. DRAFT and fat-tree to-
pologies have two CEs connected to each base- (or roots) level router. However, in 
a mesh, only one CE is connected to a router, which directly impacts the injection 
rate. As an example, a 100% injection rate in a mesh corresponds to a data rate of 
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  71
3200 Mbit/s per CE whereas it corresponds to 1600 Mbit/s per CE in DRAFT or 
in a fat-tree. The three topologies are simulated connecting 8 CEs with 32 bits flit 
width and a buffer depth of 4 flits. The frequency of each CE is 100 MHz, and 
data are sent with a uniform repartition of their sources and destinations. Results 
are presented in Figure 12. The number of data to transmit is calculated depend-
ing on the injection rates for 1ms of continuous data injection.
Figure 12. Comparison of the average throughputs (a) and latencies (b) depending on the injection rates for 8 
connected CEs.
For a fair comparison of the three topologies, a comparison of the latencies 
and throughputs depending on the transfer rates is presented in Figure 13. 
© 2011 by Apple Academic Press, Inc.
  

72  Computer Technology and Computer Programming: New Research and Strategies
Figure 13. Comparison of the average throughputs (a) and latencies (b) depending on each CE transfer rate.
From these results, if the NoCs are compared depending on the injection rates 
calculated from their maximal bandwidth, the mesh topology saturates with an 
injection rate of 25%. The fat-tree and DRAFT saturate, respectively, around 55% 
and 60% of injection rates. This point is important because it shows that DRAFT 
supports a higher injection rate than every other topology. Furthermore, with the 
comparisons depending on the transfer rates, it appears that DRAFT provides a 
lower average latency while supporting higher transfer rates than the others. This 
minimal latency is due to the reduction of the number of routers. DRAFT offers 
also a higher throughput when considering the data rates. This demonstrates a 
better use of the routing resources than for mesh and fat-tree topologies.
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  73
Scalability
From previous implementation results, the lower resource consumption of the 
DRAFT network was pointed out. However, it is interesting to verify the scalabil-
ity of the three topologies considering the network performances and the hard-
ware needs. For this comparison, the networks are implemented with the same 
characteristics as in previous parts. For the network performances, the highest 
acceptable data rates are chosen in order to place the networks in the worst condi-
tions. So, the data rate is fixed to 800 Mbit/s for each router. Simulations are real-
ized sending 1562 packets of 16 flits each for an injection time of 1ms. Network 
performances are presented in Figure 14.
Figure 14. Comparison of the average latencies depending on the number of simultaneously connected CEs.
Thanks to its higher resource consumption, a fat-tree is able to support a 
higher number of simultaneously connected CEs than other topologies. In these 
worst transfer conditions, a mesh can manage 9 CEs, DRAFT can handle 10, and 
the fat-tree supports 13 CEs. Consequently, until 10 simultaneously connected 
CEs, DRAFT needs less hardware resources and provides a lower latency than 
other networks. For the connection of more than 10 CEs, the data rates should be 
restricted or the networks should be adapted for higher network performances at 
the cost of hardware resources. 
The adaptation of the network parameters is now considered in order to im-
prove the network performances. Two parameters are investigated: the flit width 
and the buffer depth. Results are presented for each parameter considering the 
required registers and LUTs also with the average latencies. The impact of the 
flit width is shown Figure 15. The networks are always designed for the connec-
tion of 8 CEs, with a buffer depth of 4 flits. The data rate could not be fixed to 
© 2011 by Apple Academic Press, Inc.
  

74  Computer Technology and Computer Programming: New Research and Strategies
800 Mbit/s due to a saturation of the latencies with a flit size of 16 bits. Thus, 
presented latencies were obtained for a data rate of 400 Mbit/s per CE.
Figure 15. Influence of the flit sizes over the hardware resources (registers (a) and LUTs (b)) and the latencies (c) 
with a data rate of 400 Mbit/s per CE.
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  75
So, the flit size has a great influence over the resource consumption. The im-
pact of this parameter, between 32 and 64 bits, is limited with a data rate of 400 
Mbit/s. However, at 800 Mbit/s, it reduces the latencies from 48.05 to 32.31 
average cycles, respectively, for 32 and 64 bits in DRAFT. This phenomenon can 
also be observed for the fat-tree and the mesh. Considering the hardware cost of 
the flit size, this parameter should be minimized according to the desired perfor-
mances. 
Similarly, the impact of the buffer depth is presented in Figure 16. The pre-
sented results were obtained with a flit width of 32 bits and with a data rate of 
800 Mbit/s per CE.
Figure 16. Influence of the buffer depths over the hardware resources (registers (a) and LUTs (b)) and the 
latencies (c) with a data rate of 800 Mbit/s per CE.
© 2011 by Apple Academic Press, Inc.
  

76  Computer Technology and Computer Programming: New Research and Strategies
Concerning the buffer depth, an increase of the depths decreases the av-
erage latencies, but its impact over the hardware resources is lower than for 
the flit size. So, if the flit size is set to a minimum, the buffer depth can be 
increased in order to reach the network performances and the scalability required 
by the application. 
In conclusion over the scalability, every topology can support a relatively low 
number of simultaneously connected CEs at full network performances. In order 
to increase this number, the designer should reduce first the data rate of its CEs. 
This point is particularly true with the DRAFT topology. If it is not possible, the 
designer should try to increase the flit size and buffer depth parameters. However, 
these solutions have an important impact on resource overhead. The use of virtual 
channels can also increase the scalability of the networks, but the impact over 
hardware resources is impractical for an implementation in an FPGA.
Type of Data Traffic
In this part, the influence of the data traffic is presented. Each network is designed 
to connect 8 CEs with a flit size of 32 bits and a buffer depth of 4 flits. Three 
types of traffic are studied. Thus, data are produced with a uniform, a normal, or 
a “pareto on/off” distribution. This latter is a periodic distribution where a period 
without any emission of data is followed by a period of emission. Results are pre-
sented in Table 2.
Table 2. Influence of the different data traffics over the latency (average clock cycles).
From these results, DRAFT appears to better support the different types of 
traffic, even at maximum data rate. A uniform traffic can be encountered in many 
applications using an constant flow of data like video processing. The normal 
repartition of the data rates during computation time is required by applications 
which depend on the received data like the automatic recognition of a target. 
The “pareto on/off” corresponds to the traffic between a hardware element and a 
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  77
shared memory using the burst mode, which is the continuous emission of several 
data during a short period of time. Thus, DRAFT can support all these applica-
tions with better performances than other networks.
Implementation of an Application Using DRAFT
In this section, the implementation results (hardware resources and network 
performances) of an application, designed into the framework of the FOSFOR 
project, are presented. This application is implemented into a middle size Xilinx 
Virtex5 FPGA: the XC5VSX50T. 
A system using DRAFT to interconnect 4 PRRs and 4 shared IOs is imple-
mented with a MicroBlaze processor to control the DPR [31]. The application 
realizes a target tracking in a video stream. For this purpose, the application is 
composed of statically implemented tasks, which transform the video stream, 
and of dynamically implemented ones, which realize the tracking. Dynamically 
implemented tasks depend on the dynamic number of targets and on the nature 
of these targets. Thus, these tasks are very heterogeneous in terms of hardware 
resource requirements. The four shared IOs are located in the central column of 
the FPGA. This system operates at 100 MHz with a 32 bits data width. In this 
Virtex 5, DRAFT needs only 2% of the registers and 10% of the LUTs. So, while 
including the MicroBlaze processor with its memory and peripherals for the DPR 
management, 92% of the registers and 85% of the LUTs (also with 88% of the 
BRAMs) remain free for task implementation. Complete implementation results 
are shown Table 3.
Table 3. Complete implementation results of DRAFT interconnecting 4 PRRs and 4 shared IOs.
Concerning network performances, the routers are implemented with a criti-
cal path of 9,09 ns (110 MHz). DRAFT presents an average latency of 46 clock 
cycles. In this implementation without virtual channels, it also offers an aggrega-
tive bandwidth of 880 MByte/s. A view of the hardware implementation of the 
system is presented in Figure 17.
© 2011 by Apple Academic Press, Inc.
  

78  Computer Technology and Computer Programming: New Research and Strategies
Figure 17. 90-degree rotated view of DRAFT connecting 4 PRRs and 4 shared IOs.
Conclusion
In this article, a flexible interconnection network is described. This network is 
compliant with applications requiring the DPR, and with current FPGA tech-
nologies. Thus, from the comparison of current interconnections, even bus-based 
or NoC based, the fat-tree appeared as a particularly well suited topology for the 
compliance with the DPR paradigm. Indeed, this structure offers higher network 
performances than other topologies in terms of bandwidth and latency. A fat-tree 
is an indirect network that provides high flexibility at the data path level, and 
supports the parallelization of the communications. Its structure allows intercon-
necting heterogeneous CEs in heterogeneous FPGAs. The main drawback of this 
topology is the hardware resource requirements. Hence, the DRAFT flexible net-
work is proposed. DRAFT is indeed the sum of several concepts concerning the 
structure and the implementation of a fat-tree. These concepts are proposed in 
order to significantly reduce the resource consumption, and to obtain a network 
fully compliant with the DPR paradigm. The main idea of DRAFT consists in 
connecting half of the CEs directly to the root of a fat-tree. The connection of 
the static elements and the unshared resources is also presented in order to reduce 
the number of routers, and so the resource consumption. Then, the way to imple-
ment DRAFT as a central column into an FPGA is proposed for taking advantage 
of current FPGA structures. 
The DRAGOON generator is designed to parameterize and to automatically 
generate the DRAFT topology. DRAGOON also supports the simulation of the 
network allowing to characterize its performances. According with these con-
cepts and thanks to DRAGOON, the DRAFT viability is demonstrated by the  
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  79
comparison with a fat-tree and a mesh network. DRAFT needs fewer resources 
and fewer communication links than a mesh and a fat-tree. DRAFT presents a 
lower average latency than every other topology, and supports higher transfer and 
injection rates (until 1000 Mbit/s). DRAFT is also less sensitive to the flit sizes 
and the buffer depths than the others so that it can be implemented minimizing 
its hardware requirements according with the application. Consequently, DRAFT 
is very well adapted for an implementation into the framework of applications 
using DPR where there are around 10 simultaneously connected CEs. Finally, the 
DRAFT viability in terms of compliance with current applications using DPR, 
and with current technologies, is demonstrated by the implementation of a target 
tracking application in a Xilinx Virtex5.
Acknowledgement
This research was supported by the ANR (French National Research Agency) 
within the framework of the FOSFOR project (Flexible OS FOr Reconfigurable 
devices), http://www.polytech.unice.fr/~fmuller/fosfor/.
References
1.	 FOSFOR, http://users.polytech.unice.fr/~fmuller/fosfor/.
2.	 D. Cozzi, C. Far, A. Meroni, V. Rana, M. D. Santambrogio, and D. Sciuto, 
“Reconfigurable NoC design flow for multiple applications run-time mapping 
on FPGA devices,” in Proceedings of the 19th ACM Great Lakes Symposium 
on VLSI (GLSVLSI ‘09), pp. 421–424, Boston, Mass, USA, May 2009.
3.	 Altera, “Stratix IV Device Handbook—Volume 1,” ver 4.0, November 2009.
4.	 Altera, “Stratix IV Device Handbook—Volume 2,” ver 4.0, November 2009.
5.	 ATMEL, “AT40K05/10/20/40AL. 5K–50K Gate FPGA with DSP Optimized 
Core Cell and Distributed FreeRam, Enhanced Performance Improvement and 
Bi-directional I/Os (3.3 V),” revision F, 2006.
6.	 Xilinx, “Virtex-5 FPGA Configuration User Guide,” v3.5, 2008.
7.	 “PlanAhead User Guide—version 1.1,” Xilinx, 2008.
8.	 Xilinx, “Difference-Based Partial Reconfiguration, Application Note XAPP290,” 
2007.
9.	 F. Moraes, N. Calazans, L. Mller, E. Brio, and E. Carvalho, “Dynamic and 
partial reconfiguration in FPGA SoCs: requirements tools and a case study,” in 
© 2011 by Apple Academic Press, Inc.
  

80  Computer Technology and Computer Programming: New Research and Strategies
New Algorithms, Architectures and Applications for Reconfigurable Comput-
ing, pp. 157–168, Springer, New York, NY, USA, 2005.
10.	 J. Becker, M. Hubner, G. Hettich, R. Constapel, J. Eisenmann, and J. Luka, 
“Dynamic and partial FPGA exploitation,” Proceedings of the IEEE, vol. 95, 
no. 2, pp. 438–452, 2007.
11.	 D. Koch, C. Beckhoff, and J. Teich, “Recobus-builder—a novel tool and tech-
nique to build statically and dynamically reconfigurable systems for FPGAs,” 
in Proceedings of the International Conference on Field Programmable Logic 
and Applications (FPL ‘08), pp. 119–124, Heidelberg, Germany, September 
2008.
12.	 A. Thomas and J. Becker, “Dynamic adaptive runtime routing techniques 
in multigrain reconfigurable hardware architectures,” in Field Programmable 
Logic and Application, vol. 3203 of Lecture Notes in Computer Science,  
pp. 115–124, Springer, Berlin, Germany, 2004.
13.	 S. Winegarden, “Bus architecture of a system on a chip with user-configurable 
system logic,” IEEE Journal of Solid-State Circuits, vol. 35, no. 3, pp. 425–
433, 2000.
14.	 T. Seceleanu, J. Plosila, and P. Liljeberg, “On-chip segmented bus: a self timed 
approach,” in Proceedings of the Annual IEEE International ASIC/SOC Con-
ference—System-on-Chip in a Networked World, pp. 216–220, September 
2002.
15.	 A. Ahmadinia, C. Bobda, J. Ding, et al., “A practical approach for circuit rout-
ing on dynamic reconfigurable devices,” in Proceedings of the International 
Workshop on Rapid System Prototyping (RSP ‘05), pp. 84–90, Montreal, 
Canada, June 2005.
16.	 L. Benini and G. De Micheli, “Networks on chips: a new SoC paradigm,” 
Computer, vol. 35, no. 1, pp. 70–78, 2002.
17.	 E. Salminen, A. Kulmala, and T. D. Hamalainen, “Survey of network-on-chip 
proposals,” http://www.ocpip.org/white_papers.php.
18.	 F. Moraes, N. Calazans, A. Mello, L. Moller, and L. Ost, “Hermes: an infra-
structure for low area overhead packet-switching networks on chip,” Integra-
tion, the VLSI Journal, vol. 38, no. 1, pp. 69–93, 2004.
19.	 C. Bobda and A. Ahmadinia, “Dynamic interconnection of reconfigurable 
modules on reconfigurable devices,” IEEE Design & Test of Computers, vol. 
22, no. 5, pp. 443–451, 2005.
20.	 C. Bobda, A. Ahmadinia, M. Majer, J. Teich, S. Fekete, and J. van der Veen, 
“DyNoC: a dynamic infrastructure for communication in dynamically  
© 2011 by Apple Academic Press, Inc.
  

Flexible Interconnection Network for Dynamically  81
reconfigurable devices,” in Proceedings of the International Conference on 
Field Programmable Logic and Applications (FPL ‘05), vol. 2005, pp. 153–
158, Tampere, Finland, August 2005.
21.	 T. Pionteck, R. Koch, and C. Albrecht, “Applying partial reconfiguration to 
networks-on-chips,” in Proceedings of the International Conference on Field 
Programmable Logic and Applications (FPL ‘06), pp. 155–160, Madrid, Spain, 
August 006.
22.	 “Cell Broadband Engine Programming Handbook,” IBM, version, 1.11, 
2008.
23.	 C. Neeb and N. Wehn, “Designing efficient irregular networks for heteroge-
neous systems-on-chip,” Journal of Systems Architecture, vol. 54, no. 3-4, pp. 
384–396, 2008.
24.	 P. P. Pande, C. Grecu, M. Jones, A. Ivanov, and R. Saleh, “Performance evalu-
ation and design trade-offs for network-on-chip interconnect architectures,” 
IEEE Transactions on Computers, vol. 54, no. 8, pp. 1025–1040, 2005.
25.	 T. Bjerregaard and S. Mahadevan, “A survey of research and practices of net-
work-on-chip,” ACM Computing Surveys, vol. 38, no. 1, pp. 71–121, 2006.
26.	 J. L. Hennessy and D. A. Patterson, “Appendix E: interconnection networks,” 
in Computer Architecture: A Quantitative Approach, Morgan Kaufmann, San 
Mateo, Calif, USA, 2006.
27.	 H. Kariniemi and J. Nurmi, “Reusable XGFT interconnect IP for network-
on-chip implementations,” in Proceedings of the International Symposium on 
System-on-Chip, pp. 95–102, Tampere, Finland, November 2004.
28.	 H. Kariniemi, On-line reconfigurable extended generalized fat tree network-
on-chip for multiprocessor system-on-chip circuits, Ph.D. dissertation, Tam-
pere University of Technology, Tampere, Finland, 2006.
29.	 “Synthesis and Simulation Design Guide—ISE 9.2i,” Xilinx, 2008.
30.	 “ModelSim LE/PE Users Manual 6.5.c,” Mentor graphics, 2009.
31.	 K. Park and H. Kim, “Remote FPGA Reconfiguration Using MicroBlaze or 
PowerPC Processors,” Application Note: XAPP441 (v1.1) ed., Xilinx.
© 2011 by Apple Academic Press, Inc.
  

A Hardware Solution for an 
“On the Fly” Encryption 
Daniel Filipas
Abstract 
This paper presents an implementation of a secured transmission of binary 
data, using a hardware encryption based on multiple keys, stored in a small 
read-only memory. The advantages of such a solution are the increased speed 
of encryption (since a hardware implemenation is much faster than a soft-
ware one) and an automatic process (since the user doesn’t have to provide 
himself the keys for encryption/decryption). Also, the paper presents the results 
of simulation obtained using the Quartus II Web Edition 9.0 design software 
provided by Altera. 
Keywords: encryption, hardware, memory 
Introduction 
Data encryption is a very important issue when important files are transmitted 
over a public channel (such as the Internet), so the algorithms and methods of 
protecting the information have to be considered as a priority. 
© 2011 by Apple Academic Press, Inc.

A Hardware Solution for an “On the Fly” Encryption  83
Of course, there are lots of algorithms implemented and, as the time passes, 
they are more and more sophisticated, in order to prevent hackers’ intrusions [1]. 
Every algorithm tries to operate on the data to be transmitted so that it might be 
protected against unauthorized “readers.” 
Almost every algorithm encrypts the plain message using a “key” (a sequence 
of binary digits supposed to be known only by the transmitter and the receiver) 
[2]. And every algorithm claims to offer security for the sent information, as long 
as the key is not available for others. 
There are many software implementations of these algorithms (because the 
software doesn’t need extra hardware devices, so it is a less expensive solution), yet 
they remain slower comparing to hardware solutions [3]. 
In the same time, many software solutions offered to the problem of data en-
cryption require that the key for encryption and decryption to be provided by the 
user. That leaves the chance that someone unauthorized “listens” and “steals” the 
key, so the encryption becomes useless. 
In this paper is provided a simple solution for an “on the fly” hardware encryp-
tion, using a read-only memory to store the keys. 
A Simple Hardware Encryption 
The Principle 
The basic idea is the following: let’s suppose that, instead of a single key, we use 
multiple keys (in this implementation there are 32 keys, each one having the 
length of 8 bits), a different key for each byte of data. All 32 keys are stored in a 
read-only memory. Every byte of data is simply added with a key. The key address 
in memory is provided by a counter, as shown in Fig. 1 (of course, it is possible to 
choose a different way to select the key, this solution was chosen only to illustrate 
the principle). 
Figure 1
© 2011 by Apple Academic Press, Inc.
  

84  Computer Technology and Computer Programming: New Research and Strategies
For every byte of data, the counter provides a different key address (one of the 
32 available), so every byte is encrypted using the key stored in memory at that 
address. The transmission of the information is not delayed but for a clock cycle, 
so we can say that encryption is “on the fly.” 
At the receiver there is the same logic, except the adder (which is replaced by 
a substractor). 
The only information sent through the public channel is the encrypted data. 
The keys are stored only in the ROM memories (one located at the transmission 
point, the other one at the receiver). At the receiver, the encrypted data is eas-
ily decrypted by substracting the key (if the receiver’s memory stores the two’s 
complement of the keys then it will be also a sum—this time with a negative 
number). 
Examples 
Let’s take an example. Assuming that the plain, unencrypted data, is 00101001 
and the current key is 01100111, the encrypted byte will be their sum: 
00101001 + 01100111 = 10010000.
This is the only information sent by the transmitter. 
At the receiver, one will have to substract the key (knowing that this is the 
same key that was used by the transmitter—because the two memories have the 
exact same lines): 
10010000 – 01100111 = 00101001
As mentioned, if the receiver’s ROM memory stores the two’s complement of 
the keys, one can use the exact logic described earlier for encryption (involving 
the adder): 
10010000 + 10011001 = 00101001
The carry-out bit was ignored (it has no importance in this case). 
Considering the data and the keys as unsigned numbers, even if the sum be-
tween the data and the key is greater than 255, the encryption and the decryption 
will work properly. 
Let’s consider the following situation: 
Data to be transmitted: 11010111 (binary representation for 215) 
Encryption key: 11100101 (binary representation for 229) 
© 2011 by Apple Academic Press, Inc.
  

A Hardware Solution for an “On the Fly” Encryption  85
In this case, the encrypted data will be: 
11010111 + 11100101 = 10111100,
which is binary representation for 188, not the correct sum 444, because of 
the overflow. Yet, the decryption will provide the correct data: 
10111100 – 11100101 = 11010111,
which is exactly the data we’ve encrypted. 
This simple encryption (based only on a sum) provides an “on the fly” method 
which not only offers an increased speed of encryption, but also a good security 
for the keys (because they are invisible for the user). 
Hardware Implementation 
Fig. 2 presents an implementation of this method using Quartus II Web Edition 
9.0 design software provided by Altera [4]. 
Figure 2 
In order to offer an overview of the results for both the encryption and decryp-
tion, this implementation contains not only the adder used to encrypt data, but 
also the substractor, which would be a part of the receiver’s logic. Here, it is used 
only to show how data is decrypted. 
The read-only memory was initialized using hexadecimal values stored in a 
file. The content of the memory is shown in Fig. 3. 
© 2011 by Apple Academic Press, Inc.
  

86  Computer Technology and Computer Programming: New Research and Strategies
Figure 3 
Of course, to improve system’s security, a EPROM memory can be used, in 
order to have the possibility to periodically update the values of the keys. But this 
is beyond the scope of this paper. 
Figure 4 
Simulation Results 
Running the simulation for random values of Data_in byte, the result was the one 
shown in Fig. 4. 
These waveforms show that the input bytes (Data_in values) and the decrypt-
ed bytes (Data_test values) are the same. 
As we can see, the delay is just a clock cycle. This is probably the fastest solu-
tion for a secured transmission. 
In Fig. 4 were also considered intermediary values (in order to observe the 
entire process): 
-Mem—which shows the value of the key at every clock cycle, 
-Num—which indicates the address of the key in the memory. In this simu-
lation, the counting is up-down (it is very important that both counters—the 
© 2011 by Apple Academic Press, Inc.
  

A Hardware Solution for an “On the Fly” Encryption  87
transmitter’s and the receiver’s—to follow the same rule for counting, otherwise 
the decryption is impossible and data is lost). 
-Data_out—which shows the encrypted information (Data_in + Mem). 
In the waveforms above, every value of Data_in, Data_out and Data_test is 
represented by its corresponding character in ASCII code, for an easier reading. 
In this case, the input waveforms were chosen to change every two clock cycles 
(of course, it is just an example, the input data may follow any other pattern—
changes can occur every clock cycle or can be irregular). 
However, the counter decrements its value every clock cycle, pointing to an-
other address in memory (another key), so the key changes even if Data_in doesn’t. 
For this reason, the output has about two different values for the same input. 
This aspect illustrates another advantage of this implementation: even if some-
one unauthorized intercepts the encrypted information, he doesn’t have any idea 
about the number of valid input data or about the number of the keys used for 
encryption, so the attacks against this method become more difficult. 
As the simulation results show, for 6 valid input bytes, there are 12 output 
encrypted bytes (the noises—the unstable signals—are not considered). 
Even if someone “listens” to the information being sent, he won’t be able to 
find that there are two bytes encrypting the same value, because there are differ-
ent keys they were encrypted with. And even if he finds it or guess it, he couldn’t 
say which two bytes go together. When data frequency is not constant, this issue 
become almost impossible. So, the frequency of input data is, also, hidden. 
And there is also another important thing to be noticed. Because of the key 
changing at every clock cycle, the same input byte will have a different encryption 
almost every time it appears. The chance of being added to the same key is very 
small. This chance decreases even more if the number of keys used is greater than 
the one considered here (32 keys). 
And if we consider the frequent update of keys in memory (that would be pos-
sible only if a EPROM memory is available), the chance of “breaking” the system 
is about zero. 
For the refresh of the keys, there are many methods that could be imple-
mented: 
-a right/left shift of the bits for every key (or only for some of the keys); 
-an offset that could be added from time to time to every key; 
-conditional change of the key, depending on the data bits etc. 
Of course, the transmitter and the receiver have to use the same method. 
© 2011 by Apple Academic Press, Inc.
  

88  Computer Technology and Computer Programming: New Research and Strategies
We should focus only on the synchronization between the two counters, 
which is the most important issue here. If the counters are not synchronized, the 
decryption is impossible. 
An idea for this would be to transmit blocks of data (not only bytes), so that 
the receiver could easily identify if the transmission was successful or not. At the 
beginning of every block of data, the transmitter would notify the receiver that 
there is something to be transmitted. If the block size is not always the same, 
then the transmitter has also to send a signal at the end of data block. A failure in 
transmission would generate a failure in decryption. 
When the receiver has the entire block, the decryption can start. 
Resource Usage 
Fig. 5 presents the information offered by the resource usage report generated by 
Quartus II Web Edition. 
Figure 5 
As Fig. 5 shows, this system uses less than 1% of the resources provided by 
the selected device (EP2S15F484C3). It means that such an encryption module 
could be very easily integrated, without consuming too much of the available 
memory blocks, dedicated logic registers and combinational ALUTs. 
© 2011 by Apple Academic Press, Inc.
  

A Hardware Solution for an “On the Fly” Encryption  89
There is, indeed, a large number of pins (39—that is 11% of their total num-
ber), but most of them are only for testing purpose in this implementation. 
Data_test, Mem and Num (a total of 21 pins) were insert only to give a better 
view of the process. They are not needed in a real system. 
In fact, as a module of a transmission system, it would’t use not even a single 
output pin, if we consider the Data_in and Data_out pins as a part of the trans-
mitter’s main architecture. 
Conclusions
As the results of the simulation show, this hardware encryption offers a very fast 
encryption (the data to be transmitted is not delayed but for a clock cycle), a 
strong encryption (based on multiple keys) and an automatic process (since the 
user doesn’t have to provide the keys). 
The main disadvantage consists in the requirement of synchronizing the re-
ceiver’s and the transmitter’s key addressing mode. In this implementation, the 
synchronization implies the clock signal which enables the counting. But, as pre-
viously mentioned, if the information is sent in blocks of data, this issue is no 
longer important, because each one (the transmitter and the receiver) will have its 
own timing system, that will not affect the data. 
The resources needed for implementation show that such a module would not 
increase too much the cost of the system. 
The main advantage of this solution is the “on the fly” encryption. 
The possibility of regularly updating the keys stored in memory by using an 
EPROM memory (so that the encryption may be even stronger) and a better 
way to address the memory could be future improvements of this encryption 
method. 
References
1.	 http://www.truecrypt.org/docs/?s=encryption-algorithms 
2.	 http://www.mycrypto.net/encryption/crypto_algorithms. html 
3.	 http://www.encryptedusb.net/Software_vs_Hardware_Ba sed_USB_encryp-
tion.html 
4.	 Quartus II Web Edition is available at: https://www.altera.com/support/soft-
ware/download/altera_d esign/quartus_we/dnl-quartus_we.jsp 
© 2011 by Apple Academic Press, Inc.
  

SQL Generation for Natural 
Language Interface 
László Kovács 
Abstract
A hot issue in the area of database management is to provide a high level in-
terface for non-technical users. An important research direction is the appli-
cation of natural language interface. The paper presents an interface mod-
ule that converts user’s query given in natural language into a corresponding 
SQL command. After clustering the input sentence, a push-down automaton 
is used to verify the syntax. The corresponding SQL code is generated by a se-
mantic matcher module.
Keywords: NLP, NLI, SQL, formal grammar
Introduction
One area of research efforts in the query interfaces is focused on improving the 
usability. The main goal is to provide a high level interface that can be used 
© 2011 by Apple Academic Press, Inc.

SQL Generation for Natural Language Interface  91
by non-technical users without any requested DBMS oriented knowledge. An 
important area in this direction is the application of natural language interface for 
databases (NLIDB). The NLIDB means that a user can use some natural language 
to create query expressions and also the answer is presented in the same language. 
The history of NLIDB goes back as early as 1960’s [2]. The era of peak research 
activity on NLIDB was in the 1980’s. In that time, the development of a domain 
and language independent NLIDB module seemed as a realistic task. The proto-
type projects showed that the building of a natural language interface is a much 
more complex task than it was expected. 
Regarding the usability of NLIDB, there can be found some tests in the litera-
ture that evaluates the efficiency of the NLI interfaces. In these tests the NLIDB is 
compared with traditional interfaces like SQL [1]. The results show that expert users 
can perform more efficiently the special command interface (SQL) than the NLI in-
terface [6]. On the other hand, the un-experienced users could achieve better results 
with the NLI interface than with the imperative SQL interface. A similar result was 
experienced with the NLI interface for spreadsheet management [7] too. 
In the years around the millennium the situation of NLIDB can be character-
ized on one hand with the decreased interest on theory of general NLIDB (due to 
the disappointment in the research results to generate a general NLIDB), and on 
the other hand with the increased number of domain specific commercial prod-
ucts and with the high activity on studying the natural language in general [3]. In 
the recent years, a lot of new related research areas has arisen and improved. The 
potential application area of domain specific NLIDB is unlimited. The research 
projects cover among others the scientific databases (chemistry, biology, geology, 
mathematics, physics,...), the libraries and the WEB queries. 
Background
The late sixties and early seventies were an active period in database research. The 
first NLIDB research projects for databases used a domain specific engine like 
the LUNAR [2] system (1972) that contained data on chemical analysis of moon 
rocks. In the next decades the number of test systems increased and also the first 
general NLIDB applications appeared. The RENDEZVOUS (1977) [4] system 
was one of the first general purpose NLIDB modules. A key element of the de-
velopments was to provide database independence (see LADDER [2]) and large 
flexibility in the grammar’s usage (see ASK [2]). 
Based on the success of Chomsky’s transformational language model, the 
grammar oriented approaches have gained a great importance. Related to the 
viewpoint of generative linguistics, the most appropriate tools to process the sen-
tences are the declarative logical programming languages. One of the first members of 
© 2011 by Apple Academic Press, Inc.
  

92  Computer Technology and Computer Programming: New Research and Strategies
this group is the CHAT-80 [1] project. One of the commercial NLIDB products 
is the ELF [5] system. It provides an interface to the Access desktop database. The 
system understands plain-English queries and transforms it into SQL commands. 
A popular NLIDB interface is the English Query [5] from the Microsoft Its lan-
guage repository is open, the mapping to the underlying database is generated 
manually by the developers. Its semantic modeling system stores the relationships 
between the database objects and the language elements. The natural language 
commands are translated into the corresponding SQL commands. Beside the 
mentioned systems, there are a lot of pilot NLIDB systems like INTELLECT, 
ASKjeeves or Ianywhere. 
Our methodology is related to the current approaches of Giordani [12] and 
Tikk [13]. In the model of Giordani the sentences are represented by parsing 
trees. The training pool consists of pair of parsing trees: one tree (NLT) for the 
sentence in natural language, the other one (SQT) is for the sentence in SQL. 
There is a knowledge base to store the relationships between the nodes of NLT 
and SQT. For a new input NL sentence, a similar NLT is searched from the 
knowledge base. To measure the syntactic similarity between the pairs of trees tree 
kernel structures are used which computes the number of common substructures. 
The significance of work [13] is that it creates an efficient NL module for the 
Hungarian language. The system accepts only simple, well-formed interrogative 
sentences with a question word from a given list. The engine incorporates several 
sub-modules to perform a deeper analysis of the sentences. The morphological 
parser identifies the multi-word tokens of the input sentence and assigns part of 
speech labels to the tokens. The recognition of multi-word tokens is performed 
base don decreasing size of expression. The second part of the NL module groups 
related tokens in brackets. The context recognizer gets bracketed sentence alter-
natives as input. This module generates SQL like Context Language sentence 
alternatives. The main information elements during the context recognition are 
the attribute names, entity names type of entities, verbs used in the query and 
attribute values. 
These approaches show the importance of two base components: first, a deep 
linguistic and morphologic analysis is required in the case of Hungarian language 
and second, the similarity based schema matching is an effective way to reduce the 
computational costs of the engine. 
Grammar Model
The test language of the investigation is the Hungarian language which has a very 
complex grammar. The Hungarian language belongs to the family of agglomera-
tive languages, where a stem word can be extended with several suffixes. During 
© 2011 by Apple Academic Press, Inc.
  

SQL Generation for Natural Language Interface  93
the joining of suffixes the chaining of tags may cause inflection of the root part. 
For example, the word
kutyáimmal
can be translated into the following expression: 
with my dogs,
where 
kutya: stem(dog),
kutyá-im: plural + genitive (my dogs),
kutyáim-mal: preposition (with).
The second difficulty of the target language is the free word order, the ordering 
of the words within a sentence has only few constraints. The sentences:
Én olvasok egy könyvet a szobában, 
Olvasok egy könyvet a szobában, 
Egy könyvet olvasok a szobában, 
Könyvet olvasok a szobában, 
Egy könyvet olvasok én a szobában, 
A szobában olvasok egy könyvet, 
A szobában én olvasok egy könyvet, 
A szobában könyvet olvasok, 
A szobában egy könyvet olvasok 
are all grammatically correct and have only slight differences in the meaning (I 
am reading a book in the room). 
Chomsky introduced four types of formal grammars in terms of their gen-
erative power known as Chomsky-hierarchy. A hotly contested issue over several 
decades has been the question where natural languages are located within this hi-
erarchy. Chomsky showed [8] that NLs are not regular and he also presumed that 
NLs are not context-free. On the other hand, context sensitive languages are not 
adequate for practical use, as they can take up to exponential time to simulate on 
computers. Thus, the most approaches are based on grammar between context-
free and context-sensitive levels. The traditional grammar formalism like TAG 
[9], HMM [10] are usually effective for languages with strict word ordering and 
with low set of acceptable words, but they are inefficient for larger size problems. 
The grammars like dependency grammar[10] or word grammar are strong on 
handling flexible structure but their implementation details are not well explored 
yet. 
© 2011 by Apple Academic Press, Inc.
  

94  Computer Technology and Computer Programming: New Research and Strategies
To cope with the complexity problem, the probabilistic context free grammar 
was selected. A context-free grammar G=(A,V,P) over an alphabet of terminals A 
is composed of a finite alphabet V of nonterminals and a finite set P ⊆ V ∉ V × 
(V∪A)* of production rules. The production rules are given in the form u → v 
where u is nonterminal symbol and v is a sequence of terminal and nonterminal 
symbols. The context-free grammar can be represented with a push¬down au-
tomaton. The push-down automaton is based on the LIFO processing model and 
has the following formal description: 
P(Q,S,G,P,q,F), 
where 
Q: set of states 
S: the alphabet of the language 
G: the alphabet of the automaton 
P: set of transition rules 
q: initial state 
F: final states. 
At each phase of the sentence processing, the state of the automaton is given 
with a triplet (w,q,s), where w: the input sequence to be processed, q: state of the 
automaton, s: content of the stack. 
If for a given v terminal symbol several production rules exist, the model is 
called probabilistic CGF model (PCGF). The main benefits of PCFG model is 
that it can be learned from positive data alone and it provides a robust grammar. 
Although the averaged entropy related to the PCFG model is higher than of n-
gram models, a combination of PCGF and HMM models should superior to the 
traditional models [11]. 
Conversion of NL into SQL
The NLIDB module has the task to convert a command given in natural language 
into SQL statements. This transformation is done usually in several distinct steps. 
The main components of the module are [3] shown in Fig 1. 
The main goal of the engine is to convert the user’s input given in natural 
language into an SQL command. The conversion usually based on four different 
base repositories: 
• language dependent grammar base, 
• domain specific semantic repository, 
© 2011 by Apple Academic Press, Inc.
  

SQL Generation for Natural Language Interface  95
• database specific semantic repository, 
• SQL specific grammar base.
Figure 1. Engine schema
The conversion engine consists of four main modules to perform the conver-
sion steps. The first module takes the user’s input sentence and converts it into a 
sentence of the controlled language. The second module is for the checking the 
this generated sentence. The elements of the syntactically correct sentences are 
mapped into the concepts of the database domain in the third conversion module. 
The fourth module generates the SQL command from the semantic description. 
The main module of the conversion engine performs a syntax checking of the 
incoming sentence. The syntax checking is based primary on the PCFG grammar. 
As the grammar tree of the full language is too complex, the full grammar can not 
be involved into the parser module. In order to cope with the complexity prob-
lem, the module involves only the grammar of a controlled Hungarian language. 
The restriction is based on the following elements: 
• limited word pool, 
• restricted ordering of words, 
• limited inflection. 
The PCFG grammar is stored in a normalized Chomsky format using the 
XML standard. The Chomsky normal form means that the right side of the pro-
duction rule consists of only one or two symbols. The grammar is stored in a 
grammar tree where the parsing of sentence uses a top-down and left-to-right 
traversing of the tree. The stack stores the path to the current node under investi-
gation. A rule node has a form 
© 2011 by Apple Academic Press, Inc.
  

96  Computer Technology and Computer Programming: New Research and Strategies
	
	
v → w* 
where w* expression can contain some wildcard symbols to define 
• type of inflection 
• type of stem 
• type of matching 
For example, the rule 
(1,”FBN”,”FN[NOM] FNNM[NOM]”,”2”) 
has the following meaning: 
• FBN is terminal symbol 
• It should match either to FN[NOM] or to FNNM[NOM] 
• The internal checking routine with id #2 should be called for extra constraint 
validation 
• FNNM[NOM] means that the stem is noun or pronoun and is in nominative 
case. 
The PCFG parser module is based on the word stemmer module. The Hu-
morph parser is used to determine the stem part and the different inflection com-
ponents for a given input word. For example, for the input word ‘fizetése’(his 
salary), the following output is generated: 
fizetés[FN]+e[PSe3] + [NOM]. 
The list of stems and morphemes can be used to determine the semantic roles 
of a given word. 
As the applied PCFG repository describes only a subpart of grammatically and 
semantically valid sentences, the incoming sentences should first converted into 
controlled format. The mapping is based on a clustering approach. The cluster 
centers are sentence schemas where each schema is a parameterized sentence. The 
rules have the general form:
s → s’ 
where s is a normal parameterized input sentence and s’ is the parameterized sen-
tence of the controlled language. Let us take the following sample: 
“hogyannevezik nevezzükDET#1#$E[ACC][PL]” → “kérem a #$1tanárok# nevEt” 
In this sentence, the input sentence should consist of four words:
first word: fix word ‘hogyan’, 
second word: fix word ‘nevezik’ or ‘nevezzük’ 
third word: determinant, 
© 2011 by Apple Academic Press, Inc.
  

SQL Generation for Natural Language Interface  97
fourth word: #1#E[ACC][PL]: a parameter with id number 1, it should 
be of type E (entity name) and it is in a plural and accusative case. 
The output sentence consists of four words, where the # separator symbol 
denotes the parameter substitution. The substation expression may contain some 
additional inflection rules and a default value too. Taking the input sentence: 
Hogyan nevezik a tanárokat? 
is converted into the output sentence 
Kérem a tanárok nevét. 
Having the sentence of the controlled language, the sentence elements will be 
mapped to the concepts of database domains. There are several tables for semantic 
level mapping: 
• synonyms for the database concepts
• synonyms for the relationships 
• relationship between the question words and database concepts 
• relationship between basic question sentences and database concepts 
The mapping for question words is given in the form 
w → (d,w’) 
where w is a question word, d is the domain of interpretation and w’ is a list of 
substitution concepts. For example, in the rule 
“mi”,””,”TANTARGYAK”,”TARGYNEV” 
the word ‘tantargyak’ denotes a table name (a domain) and the word ‘targynev’ is 
a fieldname (a concept name). The word ’mi’ denotes a question word (what). 
The SQL command generator application is developed in Java. The input of 
the program is the NL sentence, and there are output fields for the sentence of the 
controlled language and for the generated SQL command. The developed SQL 
generator program can be used for several purposes. First, it can be used as a mod-
ule in a e-learning tool to train the SQL commands. The second application area 
is the intelligent database query interfaces for non-technical users. In domains like 
tourism, public transport ad-hoc and flexible queries should be supported. 
In the current prototype system, the domain independent and domain specific 
repositories are all generated on manual way. This is a major restriction regard-
ing the extension of the method to larger domains. In order to cope with this 
efficiency limits, the next phase of the project focuses on automated repository 
generation from external ontology databases. 
© 2011 by Apple Academic Press, Inc.
  

98  Computer Technology and Computer Programming: New Research and Strategies
Conclusion
In this paper, some results on development of an NLP engine for transforming 
natural language sentences into SQL commands were presented. The novelty of 
the approach relates to combination of the following characteristics: processing of 
the Hungarian language, multi-level stages of command generation and similarity 
based sentence processing. The generated system provides a flexible and efficient 
commend generation for a predefined application domain. 
References
1.	 J. Melton and A. R. Simon,”SQL1999 Understanding Relational Language 
Components,” Morgan Kaufmann, 2002. 
2.	 Androutsopoulos, Ritchie and Thanish, “Natural language interfaces to da-
tabases-an introduction,” Journal of Natural Language Engineering. v1 i1.  
pp. 29–81 1995. 
3.	 L Kovács and D. Tikk, “Full-text Search Engines for Databases,”Encyclopedia 
of Artificial Intelligence, IGI Global Publisher, Hersey, 2008. 
4.	 E. Codd: “Access to Relational Database for Causal Users (Rendezvous),”  
SIGART Newsletter, 1977, pp. 31–32. 
5.	 Popescu, Etzioni and Kautz, “Towards a Theory of Natural Language Interfaces 
to Databases,” ICIUI, 2003, pp. 149–157. 
6.	 Odgen and Bernick, “Using Natural Language Interface,” Handbook of  
Human-Computer Interaction, Elsevier, 1996. 
7.	 A. Shankar and W. Yung, “gNarLI: A Practical Approach to Natural Language 
Interfaces to Databases,” Term report, Harvard University, 2000. 
8.	 N. Chomsky, “Syntactic Structures,” Mouton De Gruyter, 1957. 
9.	 A.Joshi,”Tree Adjunct Grammars,” Journal of Computer Systems Science,” 
Vol 10, 1975, pp. 136–163. 
10.	 L. Kovács and E. Baksa-Varga, ”A semantic model for knowledge base repre-
sentation in a grammar induction system,” CIMCI, 2008. 
11.	 M. Johnson, “PCFG models of linguistic tree representations,” Computational 
Linguistics, 1998, pp. 613–632. 
12.	 Giordani, a.: Mapping Natural Language into SQL in a NLIDB, NLDB 2008, 
LNCS 5039, pp. 367–371. 
13.	 Tikk, D., Kardkovacs Zs., Magyar G.,Babarczy A. and Szakadát I.: Natural 
Language Question Processing for Hungarian Deep Web Searcher, 2nd IEEE 
International Conference on Computational Cybernetics, edited by W. Elmen-
reich, W. Haidinger, T. Machado. ICCC , pages 303–309. 
© 2011 by Apple Academic Press, Inc.
  

Web 2.0 Technologies with 
jQuery and Ajax 
Cornelia Györödi, Robert Györödi, George Pecherle,  
Tamas Lorand and Rosu Alin 
Abstract
The development of a web 2.0 portal using Ajax and jQuery techniques. This 
paper describes the development of a web portal using technologies like PHP, 
jQuery and Ajax. Regular web portals simply use PHP and MySQL, which 
is not enough to provide the interactivity the user needs from a web portal. 
jQuery technique is designed to change the way you write JavaScript, because 
it is very compact and easy to use and understand. jQuery is also very popu-
lar being used by Google, IBM, NBC, Amazon, Wordpress and many others. 
Ajax technique is used to increase responsiveness and interactivity of the web 
pages achieved by exchanging small amounts of data « behind the scenes » so 
that the entire web pages do not have to be reloaded each time there is a need 
to fetch data from the server. 
Keywords: web portals, JavaScript, jQuery, Ajax, PHP, MySQL, HTML, CSS, 
DOM, XML 
© 2011 by Apple Academic Press, Inc.

100  Computer Technology and Computer Programming: New Research and Strategies
Introduction
Web 2.0 seems to be like Pink Floyd lyrics: “it can mean different things to dif-
ferent people, depending on your state of mind” [1]. So Web 2.0 for some people 
it means moving some of the thinking client side so making it more immediate, 
but the idea of the Web as interaction between people is really what the Web is. 
That was what it was designed to be as a collaborative space where people can in-
teract [2]. In fact, it means using the standard which has been produced by all the 
people working on Web 1.0. It means using the document object model, it means 
for HTML and SVG and so on, it’s using HTTP, so it’s building stuff using the 
Web standards, plus Java script of course. 
According to Tim O’Reilly, “Web 2.0 is the business revolution in the com-
puter industry caused by the move to the internet as platform, and an attempt to 
understand the rules for success on that new platform” [3]. 
Some technology experts, notably Tim Berners-Lee, have questioned whether 
one can use the term in a meaningful way, since many of the technology compo-
nents of “Web 2.0” have existed since the beginnings of the World Wide Web. 
A web portal is a site that provides a single function via a web page or site. 
Web portals often function as a point of access to information on the World Wide 
Web [14]. The first attempt is to write the web portal in PHP and MySQL only, 
however the whole idea of the web portal is to be interactive and provide the ac-
cesibility that most users need. 
This interactivity can be achieved in a very easy and fashionable way, by using 
a compact language such as jQuery. jQuery technology is a lightweight JavaScript 
library that emphasizes interaction between JavaScript and HTML. It was re-
leased in January 2006 at BarCamp NYC by John Resig. It is free and open source 
software [15]. 
jQuery works closely with Ajax, whose main characteristic is to load data on 
a web page without reloading the entire page. The advantages of Ajax include 
Bandwidth usage, and separation of data, format, style and function [6]. One 
downside is that for search engine optimization of web sites using Ajax, you have 
to provide public sitemaps. 
Web 2.0 and the Related Technologies 
Democracy and Ajax are the core elements of “Web 2.0” [4]. The shortest defini-
tion of it is: “Web 2.0 is made of people” [5]. The key aspects of web 2.0 are: 
• The Web and all its connected devices as one global platform of reusable services 
and data 
© 2011 by Apple Academic Press, Inc.
  

Web 2.0 Technologies with jQuery and Ajax  101
• Data consumption and remixing from all sources, particularly user generated 
data 
• Continuous and seamless update of software and data, often very rapidly 
• Rich and interactive user interfaces 
• Architecture of participation that encourages user contribution [5]. 
Figure 1. The Web 2.0 Architecture 
Ajax, (AJAX—shorthand for “Asynchronous JavaScript and XML,”) is a devel-
opment technique for creating interactive web applications. The intent is to make 
web pages feel more responsive by exchanging small amounts of data with the 
server behind the scenes, so that the entire web page does not have to be reloaded 
each time the user requests a change. This is intended to increase the web page’s 
interactivity, speed, and usability. More information about Ajax you can find in 
[6], [7] or [8]. The XHR (XMLHttpRequest) object is the core of the Ajax engine. 
It is the object that enables a page to get data from or post data to the server as a 
background request, which means that it does not refresh the browser during this 
© 2011 by Apple Academic Press, Inc.
  

102  Computer Technology and Computer Programming: New Research and Strategies
process. In figure 2 we present how the classic and the AJAX web applications 
work (Fig.3). 
Figure 2. Comparison between classic and AJAX web applications 
jQuery is actually an open source JavaScript library that simplifies the in-
teraction between HTML and JavaScript. It is ideal for prototyping, it is com-
pletely unobtrusive, uses CSS to layer functionality and it has an easy to separate  
behavior.
Dave Methvin, Chief Technology Officer at PC Pitstop (a well known com-
munity where you can get computer help) says: “You start with 10 lines of jQuery 
that would have been 20 lines of tedious DOM JavaScript. By the time you are 
done it’s down to two or three lines and it couldn’t get any shorter unless it read 
your mind” [22]. 
The focus of jQuery can be resumed by “finding some elements” then “doing 
something with them” [19]. You can find below an example of how a block of text 
in HTML can be made to fade in with a “slow” effect (Fig. 3). 
Applications that act on data are a fundamental of computer science. His-
torically, these applications have been written in wide variety of programming 
languages, with an equally wide variety of storage mechanisms for the data. Over 
time, programming languages evolved to use an essentially hierarchical model 
(part of the suite of advancements encompassed by object-oriented develop-
ment). In comparison, the most popular form of reasonably scalable data storage 
is the relational database tables, columns, and rows model. Developers wind up  
© 2011 by Apple Academic Press, Inc.
  

Web 2.0 Technologies with jQuery and Ajax  103
developing systems to bridge two worlds the hierarchical world of a modern pro-
gramming language and the tabular world of relational databases.
Figure 3. The simplicity of jQuery 
MySQL is a database management system distributed, and supported by 
MySQL AB. MySQL AB is a Swedish commercial company, founded by the 
MySQL developers, now a subsidiary of Sun Microsystems. MySQL is a rela-
tional database management system. MySQL software is Open Source. MySQL 
has many attractive features to offer: speed, ease of use, query language support, 
capability, connectivity and security, portability, small size, availability and cost, 
open distribution and source code. 
Client-side scripts are embedded in web pages and executed by the JavaScript 
interpreter built into browser. 
They add extra functionality to an otherwise static HTML page. 
JavaScript was developed from a language called LiveScript, which was devel-
oped by Netscape for use in its early browsers. JavaScript source code is embedded 
within the HTML code of web pages and interpreted and executed by the browser 
when the page is displayed. 
HTML (Hypertext Markup Language) it is a markup language that is used to 
present the data to users through web browsers [11]. Hypertext is ordinary text 
that has been dressed up with extra features, such as formatting, images, multime-
dia, and links to other documents. Markup is the process of taking ordinary text 
and adding extra symbols. These symbols are called tags. “These tags can describe 
the appearance or layout of the text, but the majority simply describe the content 
(this is a main heading) and leave many of the appearance and layout decisions to 
the browser” [10]. 
© 2011 by Apple Academic Press, Inc.
  

104  Computer Technology and Computer Programming: New Research and Strategies
CSS (Cascading Style Sheets) is a language that is used to define the way a doc-
ument’s content is presented to the user [10]. Although CSS is mostly used with 
HTML and XHTML, it can be applied to any kind of XML document, includ-
ing SVG (Scalable Vector Graphics) and XUL (XML User Interface Language). 
The presentation is specified with styles that are placed directly into HTML ele-
ments, the head of the HTML document, or separate style sheets. Style sheets are 
constructed from style rules, each rule specifying the way one ore many HTML 
elements are displayed to the user. 
Styling rules can be included directly on HTML’s element who’s appear-
ance we want to change. This is done by using the style attribute of the el-
ement. Also CSS rules can be defined inside the “style” element which is 
usually used embedded in the head of the document. The third way we can 
include CSS in a document is by using separate files which are included using 
the “link” element. 
Practical Part
The developed application is a portal for the internal use of a dentistry medical 
centre for managing the medical activity and the database needed for it. 
The principal idea of this application is: 
• rich application 
• less traffic between client and server 
• intuitive interface 
• the interface behaviours are more responsive 
• the client interacts with the server asynchronously, in this way the data is 
moved (transferred) between the client and the server without making the 
user to wait 
The Application’s Architecture 
The Application’s Interaction Structure
The current web application is designed for a dentistry medical centre. It can be 
fragmented in two areas: the first one for the visitors of the web page, and another 
one for the medical sphere. 
© 2011 by Apple Academic Press, Inc.
  

Web 2.0 Technologies with jQuery and Ajax  105
Figure 4. Application architecture & interaction 
The Technologies we used
Technologies: 
• DOM—Document Object Model—a platform and language independent 
standard object model 
• jQuery & AJAX 
• PHP & MySQL—we generated the pages with PHP, loading only the specific 
part of the HTML code 
Languages: 
• HTML—markup language 
• CSS—stylesheet language 
• XML—markup language 
• JavaScript & JQuery 
• SQL—query language 
Prototype is used for Ajax calls, cross-browser calls, easy setting of the sent 
parameters and the sending options (request method, contentType, encoding, 
headers), multitude of events for which callback functions can be attached. 
Files Used
- index.html is the only html file used. It loads the main page when it is accessed. 
It contains separate div tags for the two kind of menus (visitors, and medics). 
The visitor’s menu div contains the links grouped in a table that access the 
specific pages, and target them to the “mainFrame” frame. These links are: 
© 2011 by Apple Academic Press, Inc.
  

106  Computer Technology and Computer Programming: New Research and Strategies
• “Home Page”—accesses the main page (mainpage.html) 
• “Services”—gives information about the Medical Centre’s services and the ser-
vices price list in a dynamic slide (services.html) 
• “Schedule”—by selecting a doctor from the list, the visitor can schedule an ap-
pointment to the Dentistry Centre. The appointments can be set starting from 
the next day. The visitor can select the time interval from a dynamically created 
table. A time interval selected by another visitor cannot be used (that time in-
tervals are highlighted with red, and the free ones with light green). After the 
registration, an e-mail message is sent to the corresponding doctor to inform 
him/her. (programming.php) 
• “Advices”—the visitor can read advices on how to maintain his/her teeth. This 
page (advices.html) contains a separate internal frame which contain the book-
marked advices (iframe.html). 
• “Contact”—contact information. (contact.php) 
The other div tag initially displays the log in form, and dynamically changes 
the appropriate div tag (dentist’s menu, radiologist’s menu, administrator’s menu, 
etc.) by AJAX. 
The username and password are sent to Login.php that searches for the user 
then saves the user’s ID and “specialization” for managing the access level of the 
pages. Without this information the user has no access to the medical pages. 
When another page is loaded, or when exiting the browser, the user is logged 
out using AJAX, by calling the login.php, like during log in, or natural log out. 
The medical part is more complex. A username and a password are required 
to log in. Based on the user type, a specific menu becomes accessible. There are 
three types of menus: for the dentist, for the radiologist and for the administrator. 
The dentist and the radiologist have a lot of functions to manage the patients. The 
administrator has the privileges to modify the information saved about the med-
ics, to make changes in the entire medical centre’s timetable and to manipulate 
the online schedule for medics. The administrator can view the medical activity 
(by using the logs), and can manage IP restrictions, too 
There are three types of menus for the medics: 
• The doctor’s menu (the menu for the dentist and the radiologist that are a little 
different. The radiologist has no access to the registered users information, so 
that link was hidden): 
• “Schedules”—(Schedules.PHP): the medic can add, view, modify or delete the 
scheduled patients. When accessed, the PHP script looks for the user ID in 
the “Timetable” table, to show the current user timeline then look for the ID 
© 2011 by Apple Academic Press, Inc.
  

Web 2.0 Technologies with jQuery and Ajax  107
in “Schedule” table to dynamically update the scheduled tasks. The light green 
background of the cell means that the doctor is working, so those cells are ac-
tivated and they can be selected; the red ones mean the doctor has a sched-
uled task, the gray ones mean the medic is not in the Centre. When a green 
cell is clicked, the system dynamically saves the patient information and the 
timestamp into the “Schedule” table. The mouse-over event on the red table 
shows who was registered to that timestamp, and the onclick event can delete 
the scheduled task. 
• “Patient Administration” dynamically shows a small menu for patient admin-
istration. Here the dentist can view and add patients to the registry. Only the 
dentist can manage the registered patients, and make the monthly report. When 
accessing the “Registry” menu, the “Registry.PHP” is loaded into the “main-
Frame,” and displays his registry, looking for id in the “Registry” table where all 
the registry inputs of all the doctors are saved. The numbering for patient entry 
is separate for all doctors. On the registry.php file, there is the list of the doctor’s 
registry, and an input tag, where we can make a search by the name of a patient. 
On the keypress event of the tag, an AJAX function is called, for searching sug-
gestions. By selecting a user from the suggestions, the table is filtered, and only 
that user is displayed. 
When accessing the “Add to registry” menu, the “Addreg.php” file is accessed, 
and opened in a small popup window. Here you will see a set of fields for the 
patient information. The first input tag, designed for the name has suggestion op-
tions, too. When a user from the suggestion list is selected, all his data is automati-
cally entered in the form and the doctor must only fill in the treatment fields. 
The “Price” field is filled automatically depending on the “Treatment code” 
field. If the patient is under 18 and wasn’t registered, a prompt appears to confirm 
if you want to add to the registered patients list. If the question is answered posi-
tively, the cost is replaced from the pricelist for registered users, and the patient is 
added to the registry. Then a new popup window appears to enter the information 
needed to register the patient. This popup window has two div tags, one for the 
necessary information to register, and another for more information about the 
patient teeth. The doctor can enter more such information for the patient. When 
this popup window is active another one isn’t accessible. 
The “Records” menu accesses the “Records.PHP” and displays a list of the 
registered patients. This page contains an input tag with suggestion options, too. 
When a patient from the list below is clicked, a little popup appears with other 
necessary information of the patient. On this popup you can modify information 
about the patient, and in the top right corner, there is a little icon to delete the 
patient. 
© 2011 by Apple Academic Press, Inc.
  

108  Computer Technology and Computer Programming: New Research and Strategies
The “Monthly Report” menu shows a list of the treatments for all registered 
patients during a specified month. (Report.PHP) 
“Timetable Edit”—to modify the timing for the current doctor. (Edit_time-
table.php) 
The administrator’s menu: 
• “Medics”—can manage (add, modify, delete) medic’s information, and view 
their status (online/offline). By selecting this menu, the Administration.PHP 
file is accessed, with a parameter to show this content. All of the medics are 
listed, with their personal information. By clicking on a medic, their informa-
tion is loaded into the above input tags for editing. Each row has a delete button 
to delete the selected doctor. 
• “Schedules”—can manage the schedules of all the doctors. The Adminstration.
PHP is accessed by another specific parameter then by selecting a doctor from 
the drop-down list, an internal frame appears for the selected doctor. All the op-
erations that can be done by the medic can also be done by the administrator. 
• “Center Timetable”—can modify the entire Centre’s timetable. The Administra-
tion.PHP file is used with another parameter to read the schedules saved by the 
medics. This information is saved in input tags for editing. 
• “Frauds”—can view and delete the restricted IP addresses saved in the “Denied” 
table. 
• “Log events”—on log in, log out, or unauthorised access the log.db file is up-
dated. This file is displayed here. 
• jQuery.JS, jQuery.form.JS—the jQuery language and one of its plugin used for 
the login form [16]. 
• Disablestatus.JS—to hide the status window content 
• Testinput.JS—Used in Addreg.PHP, Addpac.PHP to validate the forms before 
zending them. 
• Suggest.JS—To show suggestions when the user is searching for a patient. 
Some of the possible operations are: 
• View—the data is fetched from the server into a JSON array, a FilteringTable 
is being created with the corresponding data. First of all, the column names are 
brought and then the data for each row in the FilteringTable that correspond to 
a record from a table in the database. The primary key from the database table is 
used to uniquely identify each row in the FilteringTable. 
• Add—a FilteringTable is loaded with existing data from the target table. For 
adding, comboboxes or textboxes are used as follows: if the target table does not 
have foreign keys, the components used are textboxes otherwise the connections 
© 2011 by Apple Academic Press, Inc.
  

Web 2.0 Technologies with jQuery and Ajax  109
between two tables are made by a previous loading of the comboboxes with the 
value and the id. 
• Delete—data from the server is loaded in a FilteringTable and below it an empty 
one is build. The rows wanted to be deleted, respectively the corresponding re-
cords are dragged in the bottom table making usage of the drag and drop feature 
of another JavaScript library named Dojo. If the administrator changes his mind 
and doesn’t want anymore to delete a record he can drag the corresponding row 
back to the original table. After all desired rows to be deleted were dragged, 
the delete button can be used and after the delete confirmation the records are 
deleted from the database. 
• Edit—when the administrator selects a row from the initial loaded Filtering-
Table, data from that row is populating the comboboxes respectively the text-
boxes, and then he can edit the text in the textboxes or can chose another option 
in the comboboxes, after all this he can save the changes made. 
Conclusion
This portal gives us a very good example of the advantages of using Ajax. We 
could have built the web page in a classical way without using web 2.0. In the 
classical way is reloaded on almost every action of the client, which results in a 
higher traffic between the client and the server and an unpleasant experience for 
the user. This portal gives us a very good example of the advantages of using Ajax 
and jQuery. It is meant to be a practical guide for those looking to make quality 
web portals quickly and without having to write a lot of code. The technologies 
and the model presented in this article are an example and a starting point for 
those who need to develop such a system, using new, easy-to-use and advanced 
web programming techniques and languages. 
References
1.	 Kevin Maney, Technologie—“Tech people appear hyped about their industry 
again,” on http://www.usatoday.com/tech/columnist/kevinmaney/2005-10-
11-tech-industry_x.htm 
2.	 Tim Berners-Lee, Wendy Hall, James Hendler, Nigel Shadbolt, Daniel J. 
Weitzner—”Creating a Science of the Web”. Science 313, 11 August 2006. 
3.	 John Musser with Tim O’Reilly–“Web 2.0 Principles and Best Practices” An 
O’Reilly Radar Report, November 2006, ISBN 0-596-52769-1. 
4.	 Paul Graham—“Web 2.0,” on http://www.paulgraham.com/web20.html 
© 2011 by Apple Academic Press, Inc.
  

110  Computer Technology and Computer Programming: New Research and Strategies
5.	 Dion Hinchcliffe’s Web 2.0 Blog—“The State of Web 2.0,” 2 April 2006. 
6.	 http://en.wikipedia.org/wiki/AJAX 
7.	 http://www.w3schools.com/ajax/default.asp 
8.	 Kris Hadlock—“Sams Ajax for Web Application Developers,” Sams Publisher, 
2006. 
9.	 http://tomcat.apache.org 
10.	 CSS—http://en.wikipedia.org/wiki/CSS 
11.	 HTML—http://en.wikipedia.org/wiki/Html 
12.	 Marty Hall, Larry Brown—“Core Web Programming” (Second Edition), The 
Sun Microsystems Press, 2001. 
13.	 Russ Weakley—“Sams Teach Yourself CSS in 10 Minutes,” Sams Publishing, 
2005. 
14.	 Web portal—http://en.wikipedia.org/wiki/Web_portal 
15.	 jQuery—http://en.wikipedia.org/wiki/Jquery 
16.	 Use jQuery Javascript library to make easy effects for your website—http://
www.nowcss.com/articles/use-jquery-javascript-library-to-make-easy-effects-
for-your-website 
17.	 Bear Bibeault, Yehuda Katz—”jQuery in Action”, February 2008, Manning 
Publications, ISBN: 1933988355. 
18.	 Karl Swedberg, Jonathan Chaffer—”Learning jQuery : Better Interaction De-
sign and Web Development with Simple JavaScript Techniques”, July 2007, 
ISBN 1847192505. 
19.	 John Resig—”Building Interactive Prototypes with jQuery” http://ejohn.org/
files/jquery-atmedia.pdf 
20.	 PHP—http://en.wikipedia.org/wiki/PHP 
21.	 MySQL—http://en.wikipedia.org/wiki/MySQL 
22.	 jQuery official website—http://jquery.com/ 
© 2011 by Apple Academic Press, Inc.
  

Reconfigurable Computing— 
A New Paradigm 
Erica Mang, Ioan Mang and Popescu-Rotoiu Constantin 
Abstract
Computational science applications and advanced scientific computing have 
made tremendous gains in the past decade. Researchers are regularly employ-
ing the power of large computing systems and parallel processing to tackle 
larger and more complex problems in all of the physical sciences. For the past 
decade or so, most of this growth in computing power has been “free” with in-
creased efficiency more-or-less governed by Moore’s Law. However, increases 
in performance are becoming harder to achieve due to the complexity of the 
parallel computing platforms and the software required for these systems. Re-
configurable computing, or heterogeneous computing, is offering some hope to 
the scientific computing community as a means to continued growth in com-
puting capability. 
Keywords: morphware, flowware, configware, recon-figurable computing, 
FPGA 
© 2011 by Apple Academic Press, Inc.

112  Computer Technology and Computer Programming: New Research and Strategies
Introduction
The von Neumann architecture (vN) is a design model for a stored-program digi-
tal computer that uses a processing unit and a single separate storage structure to 
hold both instructions and data. The general structure of a vN machine consists 
of: 1) a memory for storing program and data. Harvard architectures contain 
two parallel accessible memories for storing program and data separately; 2) a 
control unit (also called control path) featuring a program counter that holds the 
address of the next instruction to be executed; 3) an arithmetic and logic unit 
(also called data path) in which instructions are executed. The main advantage of 
the vN computing paradigm is its flexibility, because it can be used to program 
almost all existing algorithms. However, each algorithm can be implemented on 
a vN computer only if it is coded according to the vN rules. With the fact that 
all algorithms must be sequentially programmed to run on a vN computer, many 
algorithms cannot be executed with their potential best perfor-mance. Algorithms 
that usually perform the same set of inherent parallel operations on a huge set 
of data are not good candidates for implementation on a vN machine. The von 
Neumann (figure 1) basic common model [11] lost its dominance decades ago 
[3], also having been criticized for being overhead-based. In industry it has been 
replaced by a cooperation of vN CPU and non-vN accelerators. Today, the micro-
processor has become the tail wagging the dog and the basic accelerator model is 
data-stream-based—not instruction-stream-based. Also, since 2006, RC is also a 
hot spot in supercomputing, mostly FPGA-based. 
Figure 1. von Neumann architecture 
The separation between the CPU and memory leads to the Von Neumann 
bottleneck, the limited throughput (data transfer rate) between the CPU and 
memory compared to the amount of memory. In most modern computers, 
throughput is much smaller than the rate at which the CPU can work. This seri-
ously limits the effective processing speed when the CPU is required to perform 
© 2011 by Apple Academic Press, Inc.
  

Reconfigurable Computing—A New Paradigm   113
minimal processing on large amounts of data. The CPU is continuously forced to 
wait for needed data to be transferred to or from memory. Since CPU speed and 
memory size have increased much faster than the throughput between them, the 
bottleneck has become more of a problem. 
The traditional hardware/software distinguishes software running on pro-
grammable computing engines (microprocessors) driven by instruction streams 
scanned from RAM, and application-specific fixed hardware like accelerators 
which are not programmable after fabrication. The operations of accelerators are 
primarily driven by data streams and are needed because of the microprocessor’s 
performance limits caused by the sequential nature of its operation. 
The contemporary common model of computing systems is the cooperation 
of microprocessor and its accelerators including an interface between both (figure 
2) [8]. This model holds not only for embedded systems, but also for the PC 
needing accelerators not only for running its own display. The accelerators are a 
kind of slaves. Operating system and other software is running on the micropro-
cessor, which is the host and master of the accelerators. The host may send param-
eters (like for mode select, start, stop, reset etc.) and receive interrupts and some 
result data. Such accelerator design is affected by the 2nd design crisis. Compared 
to microprocessor design the SoC (System on Chip) design productivity in terms 
of gates per day is slower by a factor of about 10-4 [7]. Another symptom of 
increasing design implementation problems and the silicon technology crisis is 
the drastically decreasing number of wafer starts for newer technology fabrication 
and the still decreasing low number of ASIC design starts. Another major cost 
factor of the application-specific silicon needed for accelerators is increasing mask 
cost, driven by growing wafer size and the growing number of masks needed. 
ASIC (application-specific IC) stands for mask-configurable gate arrays and simi-
lar methodologies. 
Figure 2. Embedded microprocessor model.[8] 
© 2011 by Apple Academic Press, Inc.
  

114  Computer Technology and Computer Programming: New Research and Strategies
The gap between vN type procedural compute engines and application-spe-
cific hardware is morph-ware, the fastest growing segment of the semiconductor 
market. Morphware is the new computing paradigm, the alternative RAM-based 
general purpose computing platform model. Morphware is a term used for recon-
figurable hardware, for instance a FPGA or a Reconfigurable datapath array. A 
morphware unit can be structurally programmed from configware sources com-
piled into configware code to be downloaded into the hidden RAM of the mor-
phware unit. Compared to application-specific hardwired hardware, morphware 
provides flexibility and avoids the need for expensive application-specific silicon. 
So we need two kinds of input sources: traditional software for programming 
instruction streams, and, configware (Configuration Ware) for structural recon-
figuration of morphware. So, configware is the program source for morphware, 
i. e. for reconfigurable platforms like FPGAs (field-programmable gate arrays), 
or, to coarse-grained reconfigurable platforms like reconfigurable datapath arrays 
(rDPAs). Software is the counterpart to configware. In contrast to software which 
is instruction-stream-based and deserves procedural programming for instruc-
tion scheduling onto von-Neumann-like machine resources, configware deserves 
structural programming like e. g. for placement and routing before the appli-
cation run time [8]. 
By introducing morphware we obtain a new general model of embedded com-
puters the accelerator has become reconfigurable. With a morphware accelerator 
the host may also use the host/accelerator interface to organize the reconfiguration 
process. Also mixed-type accelerators are possible: hardware and morphware. 
There are two classes of morphware: fine grain reconfigurable morphware, 
and, coarse grain reconfigurable morphware. Reconfigurability of fine granularity 
means, that the functional blocks have a datapath width of about one bit what 
means, that programming at low abstraction level is logic design. All products on 
the market are FPGAs (field-programmable gate arrays, called FRGAs or rGAs: 
((field-) reconfigurable gate arrays). Modern FRGAs support mapping entire sys-
tems onto the chip by offering on board all components needed. In contrast to 
fine grain morphware using CLBs of smallest datapath width, coarse grain mor-
phware uses reconfigurable Data Path Units (rDPUs) with wide data paths (for 
instance, 32 bit path width). Instead of FRGAs we have rDPAs (reconfigurable 
DPU Arrays). 
Reconfigurable computing is a new computing paradigm that bridges the gap 
between software and hardware, combining the high performance of hardware 
with the flexibility of software. Reconfigurable computing technologies offer the 
promise of substantial performance gains over traditional architectures via the 
customizing, even at run-time, the topology of the underlying architecture to 
match the specific needs of a given application. This type of computing is based 
© 2011 by Apple Academic Press, Inc.
  

Reconfigurable Computing—A New Paradigm   115
upon Field Programmable Gate Arrays (FPGAs). These devices contain an array 
of computational elements whose functionality is determined through multiple 
SRAM configuration bits. These elements, also known as logic blocks, are con-
nected using a set of routing resources that are also programmable. In this way, 
custom circuits can be mapped to the FPGA by computing the logic functions of 
the circuit within the logic blocks, and using the configurable routing to connect 
the blocks together to form the necessary circuit. 
Morphware in Computing Sciences 
The growth rate of algorithmic complexity, whereas the growth rate of micropro-
cessor integration density and the improvement o computational efficiency has 
slowed down and goes toward a saturation. The performance requirements for 
wireless communication is jumping up by huge steps from device generation to 
device generation. Also in a number of other application areas, like multimedia, 
or, scientific computing for instance, suffer from similar growth of requirements. 
Conventional systems for high-performance computing (HPC) have grown into 
mammoth structures with concomitant requirements for power and cooling, where 
reliability is a challenge due to the massive number of components involved. A 
highly promising alternative is the microprocessor interfaced to a suitable coarse 
grain array, maybe for converting a PC into a PS (personal supercomputer). But 
such a PS will be accepted by the market only, when it comes along with a good 
co-compiler, the feasibility of which has been demonstrated. 
The future of the microprocessor is no more very promising: only marginal 
improvements can be expected for performance area efficiency. Power dissipation 
is going worse, generation by generation. Pipelined execution units within vN 
machines yield only marginal benefit for the price of sophisticated speculative 
scheduling strategies. Multi-threading needs substantial overhead required for any 
kind of multiplexing [4]. All these bad messages add to old limitations like the vN 
bottleneck [4]. Because of the increasing weakness of the microprocessor we need 
a new computing paradigm as an auxiliary resource to cooperate with the micro-
processor. Morphware came just in time. Future acceptance of stand-alone opera-
tion of morphware is not very likely. Adding a rDPA and a good co-compiler to a 
microprocessor enables the PC to become a PS (personal supercomputer). 
About Reconfigurable Computer Architectures 
Reconfigurable computing is defined as the study of computation using recon-
figurable devices. For a given application, at a given time, the spatial structure of 
the device will be modified such as to use the best computing approach to speed 
© 2011 by Apple Academic Press, Inc.
  

116  Computer Technology and Computer Programming: New Research and Strategies
up that application. If a new application has to be computed, the device structure 
will be modified again to match the new application. Contrary to the vN comput-
ers, which are programmed by a set of instructions to be executed sequentially, 
the structure of reconfigurable devices are changed by modifying all or part of 
the hardware at compile-time or at run-time, usually by downloading a socalled 
bitstream into the device. 
Configuration respectively reconfiguration is the process of changing the 
structure of a reconfigurable device at star-up-time respectively at run-time. Prog-
ress in reconfiguration has been amazing in the last two decades. This is mostly 
due to the wide acceptance of the Field Programmable Gate Array (FPGAs) that 
are now established as the most widely used reconfigurable devices. 
Todman et al. [7] provided a 5-class classification of RC architectures as shown 
in Figure 3 (a) to (e). The first four classes are characterized by the physical pres-
ence of a single controlling processor. They differ in the way that the processor 
communicates with the reconfigurable fabric (RF) of the system. The structure in 
figure a because of this simplicity, it is by far the most common RC architecture 
found in commercial systems. Here, reconfigurable fabrics are connected to the 
processor through its system I/O bus. Although it provides the least data band-
width between the processor and the RF, it is easiest to implement. Figure b and c 
depict systems that incorporate RF into two different locations within the proces-
sor’s memory subsystem. 
Data bandwidth between the processor and the RF is usually the performance 
bottleneck of a system. Figure d shows a system that integrates RF directly into 
the data path of the controlling processor as functional units. It allows the RF to 
have access to all local information about the running processor, such as the reg-
ister file. Such tight integration ensures maximum integration between software 
and hardware. Figure e represents a new class of RC that is made only possible 
with advances in reconfigurable hardware technologies. Instead of connecting re-
configurable fabrics to a processor system, these machines embed processors with-
in reconfigurable fabrics. These embedded processors can either be implemented 
physically or as soft processors. Soft processors are processors that are built as 
needed by an application using reconfigurable hardware. This class of RC system 
has the benefit of allowing a user to determine the type and number of processors 
needed in the system, especially by using soft processor, thereby increasing system 
performance and efficiency. Most importantly, this class of system breaks away 
from the processor-centric compute model in the previous 4 classes of systems. 
Figure 3 illustrates the sixth class of system that consists of two or more machines 
in the previous 5 classes connected through a direct network [2]. On a system 
level, these systems share similar properties such as system topology and routing 
strategies with conventional multi-processor systems. However, because of the 
© 2011 by Apple Academic Press, Inc.
  

Reconfigurable Computing—A New Paradigm   117
proximity of computational fabric to the network, RC systems provide much 
higher potential performance benefit over multi-processor systems. For example, 
sending a word of data from a hardware application on one FPGA to another 
directly connected FPGA takes only a few clock cycles for synchronization. If the 
system is fully synchronized, latency can potentially be further reduced to zero 
cycle, virtually doubling the size of the FPGA. By shifting away from the sequen-
tial compute model of the controlling processor, this class of system has much 
higher performance potential than the previous four. 
Figure 3. 6 classes of reconfigurable computer architectures. 
© 2011 by Apple Academic Press, Inc.
  

118  Computer Technology and Computer Programming: New Research and Strategies
One of the most important structures that differen-tiate a reconfigurable com-
puter from a conventional processor-based system is its reconfigurable fabric [9]. 
Many different types of reconfigurable fabrics have been proposed in the literature 
but most widely used fabric is the field programmable gate array (FPGA). 
The configuration granularity of a reconfigurable hardware fabric affects its 
flexibility in implementing different logic functions. There is always a trade-off 
between flexibility and efficiency of the fabric. Fine grain reconfigurable fabrics 
are very flexible. They can be used to implement any sequential and combina-
tional Boolean logic function, but are slower and physically bigger in general. On 
the other hand, coarse grain reconfigurable fabrics are faster, occupy smaller ar-
eas, but are limited to implementing only one of the predefined functions. Some 
reconfigurable fabrics, such as modern FPGAs, contain a mix of both fine grain 
and coarse grain reconfigurable units. For example, Xilinx Virtex-4 FPGAs [13] 
contain dedicated blocks. This block can be programmed by the user to perform a 
combination of multiplication, addition or subtraction. Although the same func-
tions could have been implemented using general fine-grain programmable fab-
rics on the FPGA, having such dedicated blocks result in designs that are smaller, 
faster, and consume less energy. The correct mix of coarse grain and fine grain 
reconfigurable units is highly application specific. As a reconfigurable computing 
platform, designers must adjust the mix according to the area, power and perfor-
mance requirements for the target application domain. 
Field Programmable Gate Array (FPGA) is one of the most readily available 
commercial programmable logic devices. Starting as ASIC replacements similar 
to other PLDs, FPGAs have slowly evolved into complex embedded system plat-
forms that are flexible and are able to deliver performances comparable to ASICs. 
Reconfigurable devices can be used in a wide number of fields, and reconfigura-
tion can be of great interest for: rapid prototyping, In-System Customization, 
Multi-modal Computation, Adaptive Computing Systems. 
Reconfigurable computers are sometimes difficult to be classified because their 
machines can be reconfigured to compute in many different modes. This is par-
ticularly true for fine-grain reconfigurable hardware such as FPGAs. For instance, 
one design may choose to configure an FPGA into a shared memory multi-pro-
cessor system using soft processors, while another design requires the same FPGA 
to be configured as a fully synchronous data flow machine. 
Cryptography on FPGAs 
Most cryptographic algorithms function more efficiently when implemented in 
hardware than in software. Here are some potential advantages of recon-figurable 
hardware (RCHW) in cryptographic applications: 
© 2011 by Apple Academic Press, Inc.
  

Reconfigurable Computing—A New Paradigm   119
Algorithm Agility—refers to the switching of cryptographic algorithms dur-
ing operation of the targeted application. Advantages of algorithm independent 
protocols are: ability to delete broken algorithms, choose algorithms according to 
certain preferences, ability to add new algorithms. Whereas algorithm agility is 
costly with traditional hardware, FPGAs can be reprogrammed on-the-fly. 
Algorithm Upload—fielded devices are upgraded with a new encryption algo-
rithm e.g. the product has to be compatible to new applications. From a crypto-
graphical point of view, algorithm upload can be necessary because a current al-
gorithm was broken, a new standard was created or that the list of ciphers in an 
algorithm independent protocol was extended. 
Architecture Efficiency—the more specific an algorithm is implemented the 
more efficient it can become. FPGAs allow design and optimization with specific 
parameter set. Due to the nature of FPGAs, the application can be changed totally 
or partially. 
Resource Efficiency—The majority of security protocols are hybrid protocols. It 
means, that a public-key algorithm is used to transmit the session key. After the 
key was established a private-key algorithm is needed for data encryption. Since 
the algorithms are not used simultaneously, the same FPGA device can be used 
for both through run-time reconfiguration. 
Algorithm Modification—There are applications which require modification of 
standardized cryptographic algorithms or to customize block cipher such as DES 
or AES with proprietary S-boxes for certain applications. 
Throughput—Modular arithmetic operations include for example exponentia-
tion and multiplication, squaring, inversion, and addition for elliptic curve cryp-
tosystems. FPGA implementations have the potential of running substantially 
faster than software implementations. 
Cost Efficiency—There are two cost factors, that have to be taken into consid-
eration, when analyzing the cost efficiency of FPGAs: cost of development and 
unit prices. The costs to develop an FPGA implementation of a given algorithm 
are much lower than for an ASIC implementation, because one is actually able 
to use the given structure of the FPGA (e.g. look-up table) and one can test the 
reconfigured chip endless times without any further costs. This results in a shorter 
time-to-market period, which is nowadays an important cost factor. The unit 
prices are not so significant when comparing them with the development costs. 
However, for high-volume applications, ASIC solutions usually become the more 
cost-efficient choice. 
In [10] we presented a hardware implementation of RC6 algorithm using 
VHDL (VHSIC Hardware Description Language). For this implementation we 
© 2011 by Apple Academic Press, Inc.
  

120  Computer Technology and Computer Programming: New Research and Strategies
use Xilinx Foundation Software and VIRTEX XCV1000 board family. Figure 4 
presents the encryption module. 
Figure 4. The encryption module of RC6. 
Adaptive Cryptographic Systems 
Applications like e-commerce, e-government, virtual private network, on-line 
banking must provide a high degree of security. A large variety of standards, have 
been developed to provide high security. With this large variety of standards and 
the customized implementation possibilities for each standard, cryptography can 
be seen as one of the most versatile application domains of computer science. 
Depending on criteria such as speed, degree of flexibility and degree of security, 
single implementations of cryptography application were developed either as soft-
ware or as intellectual property component. 
Flexibility and performance offered by reconfigurable hardware is impor-
tant in cryptography. Flexibility offers the possibility to use the same hardware 
to switch from one algorithm to the next one at run-time, according to factors 
such as the degree of security, the computational speed, the power consumption. 
Also, according to some parameters, a given algorithm can be tuned. Moreover, 
algorithms that has been broken and where the security is no more insured can 
be changed by means of reconfiguration. The system can easily be upgraded to 
include new standards, developed while the system was already deployed. The 
corresponding algorithm can therefore be compiled and included in the library of 
bitstreams for the device configuration. On the other hand, performance can be 
used to efficiently implement the components, by using the inherent parallelism 
and building efficient operators for computing Boolean operation on a very large 
amount of data. This results on a large throughput and a cost efficiency. 
© 2011 by Apple Academic Press, Inc.
  

Reconfigurable Computing—A New Paradigm   121
The general architecture of an adaptive cryptographic engine proposed by 
Prasanna and Dandalis [6] [12] basically consists of a database to hold the dif-
ferent configuration that can be downloaded at run-time onto the device, like 
an FPGA for instance, to perform the computation and a configuration control-
ler to perform the reconfiguration, i.e. downloading the corresponding bitstream 
form the database into the FPGA. Each bitstream represents a given algorithm 
implementing a given standard and tuned with some parameters according to the 
current user’s need. 
With the recent development in FPGA, it is possible to have a complete sys-
tem on programmable chip (processor, peripherals, custom hardware compo-
nents, interconnection) implemented on an FPGA. The configuration controller 
therefore must no more resides off chip. It can be implemented as custom onchip 
hardware module or as software running on an embedded processor. Also the pos-
sibility to reconfigure only part of the chip opens new possibilities. In the archi-
tecture presented in [6] [12], the whole device must be reset on reconfiguration, 
thus increasing the power consumption because of the amount of the data that 
must be downloaded on a chip. Power consumption is usually a big problem in 
mobile environments, and the implementation must consider such issues. Besides 
this power saving, partial reconfiguration also provides the possibility of keeping 
a skeleton structure into the device and perform only few modifications at run-
time on the basic structure to move from one algorithm to the next one. In [4], 
a cryptographic application is implemented as exchangeable module of a partial 
reconfigurable platform. The system, which is based on the AES algorithm con-
sumes only 954 Virtex slices and 3 block RAMS. The cryptographic algorithm is 
used in this case just as a block to test the partial reconfigurable platform, instead 
of using the partial reconfiguration to enhance the flexibility of the cryptographic 
algorithm. 
Figure 5 presents a possible architecture of an adaptive cryptography system, 
using the previous mentioned advantages of partial reconfigurable devices. 
The main difference with the architecture presented in [6] is the use of partial 
reconfiguration, which allows for an integration of all components on a single 
chip. Also, in contrast to the adaptive architecture for a control system, the loader 
module resides into the device. Depending on the implementation chosen, the 
loader can reside inside or outside the device. However, if the configuration hap-
pens through the normal SelectMap port, then we need an external loader module 
for collecting configuration data from the database and copy them on the con-
figuration port. 
In figure 5, the architecture is logically divided into two main blocks. A fix 
one, which remains continuously on the chip. It consist of the parts, which are 
common to all the cryptographic algorithms in general or common to the algorithms 
© 2011 by Apple Academic Press, Inc.
  

122  Computer Technology and Computer Programming: New Research and Strategies
in a given class only. On the figure, we show only one reconfigurable slot; how-
ever, it can be implemented as set of configurable blocks, each of which can be 
changed by means of reconfiguration to realize a given customized standard. 
Figure 5. Architecture of an adaptive cryptographic system 
The last point concerns the development of building blocks that will be com-
piled in bitstreams to be downloaded into the device at run-time. A designer is 
no more required to focus on the hardware implementation of the cryptographic 
algorithm. A lot of work was done in this direction, and the results are available. 
We need mostly to focus on the architecture of the overall system and find out 
how a viable partitioning can be done, according to the reconfiguration scheme. 
Most of the work have focussed in various implementations of a given approach 
or the implementations mostly parameterizable and based on the Elliptic Curve 
approach. Generators for producing a customized description in a hardware de-
scription language have been developed for example in [5]. This can be used to 
generate various configurations that will be used at run-time to move from one 
implementation to the next one. 
Conclusions
The HPC community is currently facing a capability gap that is only going to get 
worse. There are numerous hardware and software development challenges that 
lie ahead as we attempt to construct larger computer systems to focus on compu-
tational science applications requirements. Reconfigurable computing holds the 
promise of a solution, but it will take substantial effort to reach maturity. 
© 2011 by Apple Academic Press, Inc.
  

Reconfigurable Computing—A New Paradigm   123
Morphware has become an essential and indispensable ingredient in SoC (Sys-
tem on a Chip) design and beyond. Already HDLs like VHDL, Verilog, or oth-
ers, are languages at higher abstraction levels, and should be taught also to CS 
students. We should not hesitate to reform CS and CSE curricula for avoiding a 
disqualification for the job market of the near future. Introductory undergraduate 
programming lab courses should not support the development of a procedural-
only mind set. Such courses should rather be a guide to the world of embedded 
systems requiring the algorithmic cleverness for partitioning an application prob-
lem into cooperating software, flowware, and configware blocks. 
References
1.	 T. Todman, G. Constantinides, S. Wilton, O. Mencer, W. Luk, and P. Ch-
eung, “Reconfigurable computing: architectures and design methods,” in IEE 
Proceedings: Computer & Digital Techniques, vol. 152, no. 2, March 2005,  
pp. 193–208. 
2.	 C. Bobda, Introduction to Reconfigurable Computing, Springer-Verlag, Ed., 
2007. 
3.	 A. Burks, H. Goldstein, J. von Neumann: Preliminary discussion of the logical 
design of an electronic computing instrument; US Army Ordnance Depart-
ment Report 1946. 
4.	 J. Castillo, P. Huerta, V. López, and J. I. Martínez, “A secure self-reconfiguring 
architecture based on open-source hardware,” reconfig, vol. 0, p. 10, 2005. 
5.	 R. C. C. Cheung, N. J. Telle,W. Luk, and P. Y. K. Cheung, “Customizable el-
liptic curve cryptosystems.” IEEE Trans. VLSI Syst., vol. 13, no. 9, pp. 1048–
1059, 2005. 
6.	 A. Dandalis and V. K. Prasanna, “An adaptive cryptographic engine for inter-
net protocol security architectures,” ACM Trans. Des. Autom. Electron. Syst.,  
vol. 9, no. 3, pp. 333–353, 2004. 
7.	 P. Gillick: “State of the art FPGA development tools; Reconfigurable Comput-
ing Workshop,” Orsay, France, Sept. 2003. 
8.	 R. Hartenstein, Morphware and Configware, A. Y. Zomaya, Ed. New York: 
Springer-Verlag, 2006. 
9.	 Hayden Kwok-Hay So, BORPH: An Operating System for FPGA-Based Re-
configurable Computers,” A dissertation for the degree of Doctor of Philoso-
phy, 2007 
© 2011 by Apple Academic Press, Inc.
  

124  Computer Technology and Computer Programming: New Research and Strategies
10.	 I. Mang, E. Mang, “Hardware Implementation with Off-Line Test Capabili-
ties of the RC6 Block Cipher,” 2002 Military Comunications Conference,  
Anaheim, USA, IEEE Catalog Number: 02CH37397C. 
11.	 http://morphware.net/. 
12.	 V. K. Prasanna and A. Dandalis, “Fpga-based cryptography for internet secu-
rity.” [Online]. Available: halcyon.usc.edu/∼pk/prasannawebsite/papers/dan-
dalisOSEE00.pdf. 
13.	 Xilinx, XtremeDSP for Virtex-4 FPGAs User Guide. http://direct.xilinx.com/
bvdocs/userguides/ug073.pdf.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of 
Video Streams Using Network 
Processors
Mohammad Shorfuzzaman, Rasit Eskicioglu and Peter Graham
Abstract
The increasing variety of networks and end systems, especially wireless devic-
es, pose new challenges in communication support for, particularly, multi-
cast-based collaborative applications. In traditional multicasting, the sender 
transmits video at the same rate and resolution to all receivers independent 
of their network characteristics, end system equipment, and users’ preferenc-
es about video quality and significance. Such an approach results in resources 
being wasted and may also result in some receivers having their quality expec-
tations unsatisfied. This problem can be addressed, near the network edge, by 
applying dynamic, in-network adaptation (e.g., transcoding) of video streams 
to meet available connection bandwidth, machine characteristics, and client 
preferences. In this paper, we extrapolate from earlier work of Shorfuzzaman 
et al. 2006 in which we implemented and assessed an MPEG-1 transcoding 
© 2011 by Apple Academic Press, Inc.

126  Computer Technology and Computer Programming: New Research and Strategies
system on the Intel IXP1200 network processor to consider the feasibility of 
in-network transcoding for other video formats and network processor archi-
tectures. The use of “on-the-fly” video adaptation near the edge of the network 
offers the promise of simpler support for a wide range of end devices with dif-
ferent display, and so forth, characteristics that can be used in different types 
of environments.
Introduction
The rapid growth of distributed computing and the Internet has led to demand for 
collaboration over wide area networks. This demand has been only partially met 
by existing multimedia and collaborative applications such as video-on-demand, 
teleconferencing, and telemedicine, which use the Internet for communication. 
For many such applications, group communication is a core component and the 
timely transfer of various types of media streams is a requirement.
Multicasting [1] is one of the building blocks of many collaborative applica-
tions and provides efficient communication between a single sender and multiple 
receivers. Messages originating from the sender are duplicated in the network 
as they are routed to the receivers that constitute the multicast group. Messages 
are forwarded through the use of a tree of routers called a “multicast tree” that is 
rooted from the sender, or possibly another predetermined point in the network, 
and which contains all multicast destinations (i.e., receivers) as leaves.
Initial efforts at implementing multimedia and collaborative applications for 
well-connected, high-end devices have proven to be successful (ivs [2], nv [3], vat 
[4], and vic [5] are widely used video and audio conferencing tools deployed over 
the Internet and the multicast backbone (MBONE) [6]). However, the usability 
of these new applications has been limited by a number of problems. One prob-
lem is how to deal with heterogeneity in the Internet. This heterogeneity, resulting 
from an increasing variety of networks and end systems, poses new challenges in 
communication support for collaborative applications. For example, consider a 
scenario where receivers have end systems ranging from simple, low-power Per-
sonal Digital Assistants (PDAs) to high performance workstations. Due to lim-
ited processing capabilities or slow network links, low-end receivers may not be 
capable of handling the same video streams as high-end receivers. Thus, different 
users in a group may have different requirements with respect to Quality of Ser-
vice (QoS).
Multicasting performs one-to-many transmission so video is normally trans-
mitted at the same rate to all receivers independent of their network attachment 
and end systems equipment. This means the source can only generate data at a 
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  127
rate that meets the capability of the most constrained receiver, although receiv-
ers having high bandwidth links would be capable of receiving correspondingly 
higher quality video streams. Additionally, not all the video streams possess equal 
value to all recipients since receivers may have different levels of interest in the 
incoming video streams. Unfortunately, most existing collaborative applications 
are not capable of capturing and exploiting user interest and thus must transmit 
the same, full quality, video streams to all participants. This approach results in 
resource wastage. Further, ignoring receivers’ interests may also result in some 
receivers’ quality expectations being unsatisfied since bandwidth may be wasted 
on unimportant streams. 
Video adaptation (or transcoding) is a viable solution to these problems. Vid-
eo streams originating from the source can be transcoded (i.e., modified) dynami-
cally in the network according to the requirements of heterogeneous receivers 
and the capacity of their access links “downstream” in the multicast tree. Figure 1 
illustrates in-network transcoding. Three high performance and one low perfor-
mance receivers are connected to the video-quality adjustment nodes (i.e., rout-
ers) through high and low bandwidth links. The adjustment nodes dynamically 
adapt the rate of an incoming stream to meet the requirements of the receivers 
and network links they deliver to.
Figure 1. In-network transcoding in heterogeneous multicasting.
Work on active networks [7] has identified a number of issues that suggest that 
an active network-based approach to dynamic adaptation of video streams could 
be beneficial. Active networks allow users to inject customized programs into the 
© 2011 by Apple Academic Press, Inc.
  

128  Computer Technology and Computer Programming: New Research and Strategies
network nodes and also support individual packets being programmed to per-
form specific actions as they traverse through the network. In the active networks 
paradigm, these packets are called “capsules” and they carry not only data but also 
references to the routines to be invoked at the nodes through which a capsule 
will pass. In this network model, programmability migrates from the application 
layer to the network layer and the network and application layers are, essentially, 
bridged together. Active network services running at the network layer can also 
exploit such information as knowledge of network topology and load conditions 
to achieve greater efficiency while application-level schemes can only use indirect 
metrics like data loss rate to speculate on network conditions.
In this paper, we seek to support the use of a wide range of end devices, 
varying connection characteristics and different user interests through the use of 
in-network video transcoding techniques implemented near the network edge 
in a fashion similar, but not limited, to that of active networks. The edge of the 
network being the boundary between the core network infrastructure and access 
network equipment provides an ideal location for doing video adaptation. In our 
system, video adaptation is done using a video adaptation node. The architecture 
of our prototype video adaptation node conforms to the node architecture pro-
vided by the active networks “reference model” [8].
The recent development of network processors has been motivated by the de-
sire to support high data processing speed and greater programmability (for flex-
ibility) in the network. Such devices offer an ideal environment for deploying the 
proposed system and this research contributes by helping to determine whether or 
not they are sufficiently powerful to support in-network video transcoding. Our 
current implementation uses the IXP1200 network processor for implementing 
the nodes that transcode MPEG-1 (MPEG-1 was chosen due to the limited in-
struction store and processing capability of the IXP1200.) video data to a desired 
bit rate. The functionalities provided by the active video adaptation node are ar-
ranged according to an active network architecture [8]. We implement our video 
adaptation process as an Active Application (AA), one of the major components 
of an active node. Capsules are not used.
We use requantization and selective frame dropping as transcoding tech-
niques to adapt the video streams. Requantization is the process of dequantizing 
the Discrete Cosine Transform (DCT) coefficients of the video stream and then 
“requantizing” them with a new quantization step size to reduce the bit rate. 
In frame-dropping, frames that are not referenced by any other frames in the 
video sequence are dropped to keep the generated bit rate of a video stream from 
exceeding the allocated channel bandwidth and to reduce the frame rate. We 
evaluate our transcoding techniques in terms of transcoding latency, throughput, 
and accuracy. Finally, we provide some simple extrapolation of our results for 
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  129
MPEG-1 using the IXP1200 to different encoding schemes and more powerful 
network processors.
The remainder of this paper is organized as follows. Section 2 provides related 
work, Section 3 overviews videocoding techniques, and Section 4 reviews video 
adaptation algorithms. Sections 5 and 6 discuss a simple low-pass filter and frame 
resizing, respectively. Section 7 presents a brief discussion of the use of network 
processors for video transcoding, which is followed by Section 8, which reviews and 
compares current network processor architectures. Sections 9 and 10 present the 
implementation details and experimental results for our system, respectively. Finally, 
the paper concludes in Section 11 and discusses some directions for future work.
Related Work
A number of approaches to dynamically adaptive video multicast have been pro-
posed in recent years aiming to address various issues and challenges including 
network heterogeneity in the Internet. The approaches can generally be divided 
into two categories. The first category adopts layered video [9–12] at the source 
(where video is composed of multiple layers with a base layer providing the lowest 
quality video signal, and each additional layer enhancing the quality of the base 
layer). Layered video is transmitted over multiple multicast sessions where each 
session corresponds to one layer. A receiver may subscribe to as many sessions as 
can be effectively supported by its processing capacity and link bandwidth. The 
second category uses video filtering/transformation [13–16] inside the network to 
produce a video stream of the desired quality “on the fly.”
These existing adaptation approaches have a number of drawbacks and are 
subject to network heterogeneity problems. First, the video stream used in layered 
multicast schemes has to be layer encoded which makes such schemes restric-
tive and incompatible with most existing video applications. Second, the use of 
receiver-driven resource reservation in some approaches [15] leads to suboptimal 
use of network resources due to the lack of receivers’ knowledge about the current 
network load and the varying nature of the network load over time. For example, 
if the receiver makes its reservation during a busy period, the network can only 
provide limited resources leaving the receiver with poor video quality even if the 
load is mitigated later. Third, the packet discarding technique used in some ap-
proaches [10] to handle network congestion is regarded as flawed [17] as it does 
not provide the best overall performance in terms of bandwidth utilization and 
end-to-end QoS. Instead of dropping a packet or sending it over a congested link 
by dropping high-frequency coefficients of video streams [14], the packet could 
be forwarded through a suboptimal route to attain better overall performance and 
efficient use of bandwidth. Fourth, many approaches focus only on single specific 
© 2011 by Apple Academic Press, Inc.
  

130  Computer Technology and Computer Programming: New Research and Strategies
aspects of the problem. For example, Akamine et al. [13] describe a technique for 
the construction of multicast trees to be used in video transmission that satisfy 
different QoS requirements, but their work focuses only on which nodes should 
do video filtering. How the filtering mechanisms are implemented is not dis-
cussed. Finally, most work focuses only on congestion and bandwidth issues while 
the varying preferences of clients and the heterogenous characteristics of clients’ 
devices also make group communication with multicast difficult.
Yamada et al. [16] present an active network-based video-quality adjustment 
method for heterogenous video multicast using the IXP1200 network processor. 
This was the first effort to use network processors in adaptive video multicast-
ing. They only implemented a low-pass filter as a quality adjustment technique 
for real-time multicasting of MPEG-2 video. Their system, as described, cannot 
perform the required video adjustment at an acceptable rate.
Addressing these problems in collaborative applications requires an efficient 
mechanism for in-network adaptation of video streams, which influences user 
perceived quality and resource requirements both for the end-systems and the 
network. As described, though several application level schemes have already em-
ployed dynamic adaptation, none of them provides a complete solution to the 
problems faced by collaborative applications. Responding to this issue, the prob-
lem addressed in this paper is “how can network performance in collaborative 
applications be improved by detecting and managing preferences from the receiv-
ers for use in dynamic, in-network adaptation of data streams?” To this end, we 
discuss a framework that not only addresses network heterogeneity by considering 
clients’ network connections and device characteristics but also supports deliver-
ing activity-based user interest hints into the network and using those hints at 
routers to adapt to changing user requirements through the dynamic modifica-
tion of data streams.
Different Video Coding Standards
This section reviews video coding standards with a focus on the major video com-
pression techniques. The characteristics of these standards play a key role in build-
ing practical video adaptation systems. Understanding the differences between 
MPEG-1 and the other standards provides a basis for extrapolating from our 
MPEG-1 results to other formats.
MPEG-1 Video Coding
In MPEG-1, video is represented as a sequence of individual still images con-
sisting of a two-dimensional array of picture elements (pels). MPEG-1 video  
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  131
compression employs two basic coding techniques: intraframe coding and inter-
frame coding.
In intraframe coding, spatial redundancy in the same video frame is reduced by 
DCT-based frequency transformation. In interframe coding, similarity between 
pels in adjacent frames, temporal redundancy, is reduced by motion compensa-
tion (MC). MPEG-1 divides the frames in a sequence into three types: intrac-
oded frames (I-frames), forward predicted frames (P-frames), and bidirectional 
predicted frames (B-frames). An I-frame is encoded by intraframe coding without 
any reference to past or future frames. P and B frames are encoded using inter-
frame coding. P-frames are coded with respect to the temporally closest preceding 
I-frame or P-frame. B-frames are encoded with respect to immediately adjacent I 
or P-frames past, future, or both.
An MPEG-1 video bitstream is divided into six layers: the video sequence, 
group of pictures, picture, slice, macroblock, and block layers [18]. The video se-
quence layer contains one or more groups of pictures (GOPs). A GOP contains a 
sequence of pictures/frames beginning with an I picture followed by several P and 
B pictures. A picture corresponds to a single frame in the video sequence consist-
ing of one or more 16-pixel high stripes called slices. A slice contains a contiguous 
sequence of raster ordered macroblocks. Each macroblock contains a group of 
six 8×8 DCT blocks, four luminance blocks and two chrominance blocks. Each 
block corresponds to the basic coding unit on which the DCT is applied and 
consists of 64 pels arranged in an 8×8 array.
MPEG-2 Video Coding
The MPEG-2 coding standard [19] supports a wide range of bit rates, resolutions 
(both spatial and temporal), quality levels, and services for applications such as 
digital storage, High-Definition TV (HDTV), and so forth.
Unlike MPEG-1, MPEG-2 supports interlaced video input images which are 
scanned as even and odd fields to form frames. Thus, there are two new picture 
types. “Frame pictures” are obtained by interleaving the lines of an odd field and 
its corresponding even field while “field pictures” are formed from a field of pixels 
alone. All picture types can be I, P, or B frames. A coded I-frame consists of an 
I-frame picture, a pair of I-field pictures or an I-field picture followed by a P-field 
picture. A coded P-frame consists of a P-frame picture or a pair of P field pictures. 
A coded B-frame consists of a B-frame picture or a pair of B-field pictures.
MPEG-2 maintains MPEG-1 syntax, but uses extensions to add flexibility 
and functions. “Scalable” extensions support video data streams with multiple 
resolutions and the ability to partition the data stream into two pieces, one part 
© 2011 by Apple Academic Press, Inc.
  

132  Computer Technology and Computer Programming: New Research and Strategies
containing all of the key headers, motion vectors, and low-frequency DCT coef-
ficients and the second part transmitting less critical information such as high-
frequency DCT coefficients. Other extensions offer temporal flexibility so not all 
frames have to be reconstructed.
MPEG-4 Video Coding
MPEG-4 was originally targeted to support low bit rates and error prone channels 
(e.g., for wireless devices) but also includes support for object-based user interac-
tivity. MPEG-4 allows video objects to be placed anywhere in the coordinate sys-
tem and transformations can be used to change the geometrical appearance of the 
objects. Streamed data can be applied to video objects to modify their attributes 
and the user’s viewing point can be changed.
The basis of MPEG-4 video coding [20] is a block-based predictive differential 
video coding scheme as in MPEG-1 and MPEG-2. MPEG-4 video also specifies 
the coded representation of visual objects that can be synthetic (as in interactive 
graphics) or natural (as in digital TV). These visual objects can be combined to 
form compound objects. MPEG-4 multiplexes and synchronizes the visual ob-
jects before transmission to provide QoS and allows interaction with the scene 
generated at the receiver’s end.
MPEG-4 video provides methods for compressing textures, for texture map-
ping of 2D and 3D meshes, compression of implicit 2D meshes, and compression 
of time-varying geometry streams that animate meshes. MPEG-4 also supports 
coding of video objects with spatial and temporal scalability. Scalability allows de-
coding a part of a stream and constructing images with reduced quality, reduced 
spatial resolution, reduced temporal resolution, or with equal temporal and spa-
tial resolution but reduced quality.
H.261 Video Coding
H.261 [21] has many elements in common with MPEG-1. Both intraframe and 
interframe coding techniques are used for compression. Like MPEG-1, H.261 
uses DCT-based frequency transformation and motion compensation (MC). The 
video is also organized in layers. However, there are some differences between 
these two coding standards. In H.261, the quantization is a single variable instead 
of a matrix of 64 terms and the syntax is simpler with only four layers. To mini-
mize delay, only the previous picture is used for motion compensation. So, there 
are no B frames.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  133
H.263 Video Coding
H.263 [22] is an evolutionary improvement to H.261, building on ideas from 
MPEG-1 and MPEG-2. H.263 is intended for low bitrate communication and it 
supports additional video frames. H.263 has MPEG-like blocks and macroblocks 
with prediction and motion compensation. The zigzagged quantized coefficients 
are coded using the MPEG run-level methods although with different tables. The 
video has four layers as in H.261.
Four optional modes enhance the functionality of H.263. The “unrestrict-
ed motion vector” mode allows motion vectors to point outside a picture. The 
“syntax-based arithmetic coding” mode supports arithmetic instead of huffman 
coding giving the same picture quality with fewer coded bits. The “advanced pre-
diction” mode uses overlapped block motion compensation with four 8×8 block 
vectors instead of a single 16×16 macroblock motion vector. The “PB-frames” 
mode allows a P-frame and a B-frame to be coded together as a single PB-frame.
H.264 Video Coding
H.264 [23], MPEG-4 Part 10, or Advanced Video Coding (AVC) achieves very 
high-data compression. The goal of H.264/AVC was to provide good quality at 
substantially lower bit rates. An additional goal was to do this in a flexible way 
that would allow the standard to be applied to a wide variety of applications and 
to work well in a variety of networks and systems.
The basic functional elements (prediction, transform, quantization, and en-
tropy encoding) are similar to previous standards. H.264 provides a number of 
new features that allow it to compress video much more effectively. These include 
what follows. (i) Multipicture motion compensation using up to 32 previously-
encoded pictures as references. This usually allows modest improvements in bit 
rate and quality in most scenes. (ii) Variable block-size motion compensation 
(VBSMC) with block sizes as large as 16×16 and as small as 4×4, enabling very 
precise segmentation of moving regions. (iii) Quarter-pixel precision for motion 
compensation, enabling very precise description of the displacements of moving 
areas. (iv) A 4×4 integer block transform is used as opposed to the 8×8 DCT 
blocks. (v) Context-adaptive binary arithmetic coding (CABAC) is used to loss-
lessly compress syntax elements in the video stream knowing the probabilities of 
syntax elements in a given context. (vi) Context-adaptive variable-length coding 
(CAVLC) a lower-complexity alternative to CABAC, is used for the coding of 
quantized transform coefficient values.
© 2011 by Apple Academic Press, Inc.
  

134  Computer Technology and Computer Programming: New Research and Strategies
Video Adaptation Algorithms
To support the transmission of pre-encoded video over heterogeneous networks, 
the video streams need to be dynamically adapted based on the channel band-
width and receivers’ requirements. The device or system that performs this process 
is called a video transcoder. One salient function provided by video transcoding 
is bit rate conversion, which accepts a pre-encoded video stream as input and 
produces an output stream having a different bit rate. Other functionalities that 
may be provided by a transcoding process include conversion of the frame rate, 
spatial resolution, or compression standard (coding syntax). Figure 2 illustrates 
the transcoding process.
Figure 2. Video format conversion using a transcoder.
Different transcoding operations entail different levels of processing complex-
ity. This complexity is determined by how much a compressed video stream must 
be decompressed before a transcoding operation is applied. Thus, a transcoding 
operation can be optimized by performing it in the appropriate stage of the com-
pression/decompression process. Figure 3 shows different regions where various 
transcoding operations can be performed on a compressed discrete cosine trans-
form and motion compensated video bit-stream. Region 1 represents uncom-
pressed source image data where operations such as frame resizing (i.e., conver-
sion of spatial resolution) and frame dropping (by reestimating motion vectors) 
can be performed relatively simply although a large amount of data has to be 
processed due to its uncompressed nature. Region 2 contains the same amount 
of data as region 1, but transcoding operations at this region can be performed 
without using the computationally intensive functions of Forward-DCT and 
Inverse-DCT transforms. Requantization (i.e., bit rate conversion) can be per-
formed at this point by applying the new quantization factor on the dequantized 
DCT coefficients. In region 3, the data size is considerably smaller due to the 
absence of zero coefficients in DCT blocks that are quantized and run length en-
coded. Operations such as frequency filtering (i.e., bit rate conversion) and color 
to monochrome conversion are feasible at this region. Finally, region 4 contains 
fully compressed data and allows standard-specific and relatively simple opera-
tions such as intelligent frame dropping (i.e., frame rate conversion).
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  135
Figure 3. Different levels of compression/decompression process on a generic discrete cosine transform and 
motion compensation-based video.
Adaptive Requantization
Requantization is an efficient transcoding technique for converting MPEG and 
H.261/263 video at a high bit rate to a lower bit rate. The requantization process 
involves several steps.
Figure 4 shows a requantization transcoder with bit rate control. First, the 
original video stream is decoded through variable length decoding (VLD) [24] to 
obtain the quantized DCT coefficients with coding information such as quantizer 
scale (also called quantizer step size), macroblock type, and motion vectors. A 
near-optimal decoding technique based on Huffman decoding is used to gener-
ate the quantized DCT values from the variable length codes in the compressed 
stream. An inverse quantizer then dequantizes these decoded coefficients using 
the quantization step size and produces the actual DCT coefficients. These coef-
ficients are requantized with a larger quantization step size to reduce the bit rate. 
The quantized coefficients are then coded again with other coding information in-
cluding the new quantization step and modified macroblock information through 
variable length coding (VLC) to get the resulting transcoded stream.
Figure 4. Transcoding using requantization.
© 2011 by Apple Academic Press, Inc.
  

136  Computer Technology and Computer Programming: New Research and Strategies
Quantization
The quantization process entails the division of the integer DCT coefficients 
by integer quantizing values. Intra- and interframe coding conform to different 
quantization rules. The quantized DCT coefficient (QDCT) in intracoding is cal-
culated from the unquantized coefficient (DCT) by the following formulae [18]:
	
(16
)
(
(
)
_
),
2
_
DCT
Sign DCT
quantizer
scale
Q
QDCT
quantizer
scale
Q
´
+
´
´
=
´
´
	
(1)
where Q is the quantization table value for the coefficient and the function 
Sign() in the rounding term produces the following values:
	
1,
0,
(
)
0,
0,
1,
0.
when DCT
Sign DCT
when DCT
when DCT
ìï+
>
ïïï
=
=
íïïï-
<
ïî
	
(2)
For intercoding, a similar equation is used for the quantization with the excep-
tion that the rounding is always to the smaller integer value. Hence, the equation 
does not hold any rounding term:
	
(16
)
.
2
_
DCT
QDCT
quantizer
scale
Q
´
=
´
´
	
(3)
Dequantization
Dequantization of the quantized DCT coefficients is performed by the inverse of 
the quantization procedure. For intra coding [18]
	
(2
)
_
,
16
QDCT
quantizer
scale
Q
DCT
´
´
´
=
	
(4)
and for inter coding
	
((2
)
(
))
_
.
16
QDCT
Sign QDCT
quantizer
scale
Q
DCT
´
+
´
´
=
	
(5)
Rate Control
Rate control in requantization is used to determine quantization parameters, and 
is responsible for preserving consistent video quality while satisfying both band-
width and delay constraints. The relationship between quantizer step size and bit 
rate for a video stream can be used to determine the quantizer step size and bit 
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  137
allocation during requantization on a frame, slice, or macroblock basis. We used 
slice level rate control. The rate controller needs to know the target bit rate that 
is to be transmitted. At the slice level, the actual bit count in the original video 
stream can be scaled to obtain the target bit count. The scaling factor is the ratio 
between the transcoder’s desired output (e.g., R2) and input bit rates (e.g., R1). 
This maintains the proportion of bits allocated among different frame types in the 
transcoded video sequence. The actual bit count from the original stream and cor-
responding target bit count for the i th slice in a frame are calculated as follows:
	
target
actual
actual
stream
2
( )
( )
,
1
( )
( )
,
R
B
i
B
i
R
B
i
B
i
=
´
=
+D
	
(6)
where Δ is defined as
	
actual
target
0,
for the first slice of the
first frame of any type,
(
1)
(
1),
otherwise.
B
i
B
i
ìïïïï
D =íïïï
-
-
-
ïî
	
(7)
To meet the target bit rate, the quantizer step size is adjusted based on feed-
back to the rate controller (as shown in Figure 4). The rate controller updates the 
quantizer step size for the next slice on the basis of the difference between the 
target and actual bit count for the previous slice (i.e., the value of Δ). The new 
quantizer step size for the i th slice in a frame is calculated as follows:
	
( )
( )
,
base
Q i
Q
i
offset
=
+
	
(8)
where Qbase(i) is the original quantizer step size for that slice and offset is deter-
mined by the value of Δ for the previous slice. For the first slice of each frame, off-
set is initialized to the mean value used for the previous frame of the same type.
As quantization is the only operation in the DCT-based video compression al-
gorithm that introduces quality loss, requantization can produce some noticeable 
edge effects on the transcoded video stream. However, as each DCT coefficient is 
requantized to a smaller value, the bit rate reduction achieved by the mechanism 
is significant.
Frame Dropping in Compressed Domain
Frame dropping can be used to keep the generated bit rate of a video stream from 
exceeding the allocated channel bandwidth and to reduce the frame rate. Thus, 
© 2011 by Apple Academic Press, Inc.
  

138  Computer Technology and Computer Programming: New Research and Strategies
a frame dropping mechanism is used to reduce the data rate of a video stream in 
a sensible way by discarding a number of frames according to importance and 
transmitting the remaining frames at a lower rate. Usually, in a transcoding pro-
cess, the video transcoder reuses the decoded motion vectors to speed up the 
re-encoding process [25]. In this case, the frames cannot be discarded because 
the motion vectors of each frame are estimated from their immediate predeces-
sor frames. However, if frame dropping is allowed in a transcoding process, those 
motion vectors cannot be reused because the motion vectors of the current frame 
are no longer estimated from the immediate past frame. If frame dropping needs 
to be used, the current frame must be decompressed completely and the motion 
vectors have to be estimated again before recompression. This method introduces 
heavy computational overhead, which is undesirable in real-time transcoding. 
However, frames that are not referenced by other frames in the video sequence 
can be discarded in a specific interval to reduce the data rate thus avoiding the 
computation for recomputing motion vectors.
In an MPEG-1 video sequence, for example, I and P frames in a GOP are 
referenced by subsequent P and B frames in the group. Hence, I and P frames 
in the video sequence cannot be dropped without going through the process of 
re-estimation of motion vectors (done in region 1 of video compression/decom-
pression processing shown in Figure 3) and thus requires complete decompression 
and recompression of the video sequence. On the other hand, B frames are not 
referenced by any other frames in the sequence. Therefore, a number of B frames 
in a specific interval can be discarded to control the bit rate while maintaining ac-
ceptable image quality. In this case, the transcoding operation is performed com-
pletely in the compressed domain (region 4 in Figure 3). By dropping a specific 
number of B frames, it is possible to produce a video stream with a desired rate, 
however, due to the small size of B frames in the video sequence, this approach has 
limited impact. A sample frame dropping scenario is illustrated in Figure 5.
Figure 5. (a) A sample precoded MPEG-1 video sequence. (b) The transcoded sequence with alternate B frames 
dropped.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  139
Frame Dropping in Pixel Domain
To achieve increased data reduction, a pixel domain frame dropping technique 
could be used. In this case, the frame must be decompressed completely and mo-
tion estimation must be done again. To reduce the computational overhead of 
motion vector re-estimation, a bilinear interpolation method has been developed 
[26] to estimate the motion vectors for the current frame relative to the previous 
nondropped frame.
If the motion vectors between adjacent frames are known, the problem of 
tracing the motion from frame four to frame one as shown in Figure 6 could be 
partly solved using the repeated applications of bilinear interpolation. A shifted 
macroblock as shown in Figure 7 is located in the middle of four neighbor mac-
roblocks. The bilinear interpolation is then defined as 
	
int
1
2
3
4
(1
)(1
)
( )(1
)
(1
)( )
( )( )
.
MV
MV
MV
MV
MV
a
b
a
b
a b
a b
=
-
-
+
-
+
-
+
	
(9)
Here, MV1,…,MV4 are the motion vectors of the four neighboring macrob-
locks. α and β are determined by the pixel distance to MV1. The weighting factor 
of each neighboring macroblock is inversely proportional to the pixel distance. By 
repeating the motion tracing, it is possible to create an extended motion vector for 
each macroblock in the current frame relative to its previously nondropped frame.
Figure 6. A motion tracing example.
Figure 7. Interpolation of motion vectors.
© 2011 by Apple Academic Press, Inc.
  

140  Computer Technology and Computer Programming: New Research and Strategies
Bilinear interpolation only partially solves the motion vector reuse problem. 
Hence, further adjustment of the re-estimated motion vectors has to be performed 
by using a smaller search range. For each macroblock, the new position located by 
the interpolated and composed motion vectors is used as the search center for the 
final motion re-estimation stage.
The frame rate is controlled by dynamically determining the length of dropped 
frames. The goal is to make the motion of the decoded sequence smoother. A 
threshold is set beforehand and if the accumulated magnitude of motion vec-
tors after a nondropped frame exceeds this threshold, this frame is encoded. The 
threshold is determined by using the number of frames to divide the accumulated 
magnitude of motion vectors in a buffer. The threshold is recursively updated 
after transcoding each frame because the number of encoded frames should be 
dynamically adjusted according to the variation of the generated bits when the 
last nondropped frame is transcoded.
Low-Pass Filter
A low-pass filter provides rate reduction by progressively eliminating high-fre-
quency components of the video signal [16]. In essence, the low-pass filter elimi-
nates an appropriately determined number of DCT coefficients from the high-
frequency ones that comprise a luminance or chrominance block. The low-pass 
parameter is related to the number of DCT coefficients left in each block after 
quality adjustment. At the beginning of each GOP, initial low-pass parameter 
values are set independently for I, P, and B pictures based on the compression ra-
tio for the current GOP. The compression ratio for a GOP is calculated from the 
predicted size (in bits) of the GOP, the predictor for the total bits used by header 
data in the GOP, and the number of bits allowed for the current GOP, which in 
turn is calculated from a specified target rate, the number of pictures in the GOP, 
and the frame rate.
This technique implies that the rate averaged over a GOP-time is regulated by 
the target rate. However, the result of per-packet adjustment does not necessarily 
match the target rate. To make up the balance, an adjustment value is introduced. 
After the initial low-pass parameter value is set, it is changed dynamically for each 
of the following macroblocks in the GOP based on the size difference between 
the previous original and filter macroblock. Using this technique the low-pass 
parameter value for each macroblock is appropriately determined. By eliminating 
the specified number of DCT coefficients, it is possible to produce a video stream 
that has the desired rate.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  141
Frame Resizing
One common solution to reduce bit rate is to generate a new compressed video 
with a lower spatial resolution from the original precoded video bit stream. This 
method requires downsizing of the original video and estimation of new motion 
vectors for each intercoded macroblock in the downsized video.
The algorithm proposed in [27] can achieve arbitrary image/video downsizing. 
This algorithm takes advantage of compressed domain processing techniques and 
is processed completely in DCT domains without introducing further computa-
tion. When combined with the transcoding method described in [28], which can 
estimate the motion vectors from the input bit stream for arbitrary downscaled 
video, the proposed method can efficiently process video stream downsizing.
In a spatial domain, for an arbitrary downsizing ratio R, defined as the ratio 
of original resolution to the desired resolution, more than one pixel in the origi-
nal frame may contribute to one single pixel in the downsized frame [27]. For 
example, one 8×8 output block in the downsized frame can come from as many 
as M × N related blocks, which the supporting area in size of 8Rx×8Ry (where Rx 
and Ry are the horizontal and vertical downsizing ratio, resp.) may cover in the 
original frame. For arbitrary downsizing, these supporting areas may not align to 
the block border. This approach realizes downsizing in two steps: (1) extracting 
the supporting area from the original frame, and (2) downsizing it into an 8×8 
output block.
Due to the noninteger downsizing ratio, some related blocks in the original 
frame might partially contribute to certain output blocks in the downsized frame. 
These related blocks can be totally covered or partially covered by the supporting 
area. The spatial information (DCT) of the supporting area is extracted by par-
tially decoding the related blocks. The size of the extracted DCT block depends 
on the covered pixels of each related block. Then the supporting area can be 
represented by combining the extracted pixels from all the related blocks in DCT 
domain.
In a natural image, most of the signal energy is concentrated in the lower 
frequency part in the DCT domain. A reasonable downsizing scheme, as pro-
posed in [29], is to retain only the lower frequency components and discard the 
high-frequency components of the block. Thus, most of the energy of the original 
block is preserved. As the supporting area of size 8Rx×8Ry may contribute to one 
8×8 output block, it is necessary to discard the high-frequency component and 
extract only the low-frequency part of size 8×8 to downsize the block to 8×8 in 
the DCT domain.
© 2011 by Apple Academic Press, Inc.
  

142  Computer Technology and Computer Programming: New Research and Strategies
The motion vector estimation approach proposed in [28] extends the exist-
ing video downsizing methods by considering an arbitrary downsizing scheme 
operating on several macroblocks. Since different numbers of pixels from the pre-
coded macroblocks are used to form the new macroblock in the downsized video, 
existing methods using the spatial activity as a weighting factor for motion vector 
re-estimation are not well suited for the case of video downsizing by an arbitrary 
scale factor. The reason is that motion vectors are usually obtained by finding a 
matched macroblock within a search window of a reference frame by minimizing 
the sum of absolute differences (SAD) between the two macroblocks under com-
parison. To minimize the SAD, the new motion vector should be skewed toward 
the motion vector of the precoded macroblock that has more pixels involved in 
forming the new macroblock. For this reason, we consider another weighting 
factor, which is obtained by multiplying the number of horizontal pixels by the 
number of vertical pixels engaged from a precoded macroblock. Then the mo-
tion vector for each macroblock in the downsized video can be computed from 
the motion vectors and spatial activity (i.e., number of nonzero AC coefficients) 
of the related macroblocks of the precoded video, the weighting factor, and the 
downsizing factors.
Network Processors for Video Transcoding
To deliver enhanced next generation services such as converged voice and data, 
streaming video, and differentiated Quality of Service (QoS), an efficient in-net-
work processing architecture needs to be developed. Such an architecture must be 
fast enough to process network data, flexible enough to allow for application spe-
cific functions and future upgrades, and reliable enough to provide QoS guarantees.
Network processors (NPs), specialized programmable CPUs optimized to per-
form packet processing at wire speed, can be used for this purpose. Network 
processors can perform many functions such as packet classification and possibly 
modification of packet contents at wire-speed near the edge of the network. The 
feasibility of network processor-based video transcoding is an area of research that 
has not yet been fully addressed.
Overview of Network Processors
Network processors have evolved over time to introduce greater processing 
and storage capability and, in some cases, additional functionality. These are 
critical issues in determining the feasibility of video transcoding using network  
processors.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  143
Intel IXP1200
The IXP1200 contains one StrongARM processor core, six programmable mul-
tithreaded co-processors (microengines), SRAM, SDRAM, and PCI and IX bus 
interface units.
The StrongARM 32-bit RISC microprocessor core running at 232 MHz is 
used for processing control packets, and doing tasks such as managing forwarding 
tables and other network state information. The microengines are minimal 32-
bit RISC processor cores that are typically used to receive, process, and transmit 
packets independently. Each microengine supports four hardware threads so up to 
24 threads can be executed “in parallel.” The instruction store of each microengine 
has space for 1024, 32-bit instructions that each execute in one clock cycle.
The IX bus unit provides the on-chip scratchpad memory, receive and trans-
mit queues (FIFOs), and a hash generation unit. The 64-bit IX bus connects the 
processor to Media Access Control (MAC) devices and is responsible for moving 
data to and from the receive and transmit FIFOs.
Intel IXP2400
The Intel IXP2400 [30] offers a wire-speed OC-48 data plane as well as control 
plane capability on a single chip. Each IXP2400 contains eight multithreaded 
packet-processing microengines, a low-power general-purpose Intel XScale core, 
network media and switch fabric interfaces, memory and PCI controllers, and 
interfaces to flash PROM and peripheral devices.
The eight 32-bit microengines run at 400/600 MHz and support multi-
threading up to eight threads each. These microengines provide a variety of net-
work processing functions in hardware. Each of the microengines has space for 
4096, 40-bit instructions. The IXP2400 also offers Intel’s Hyper Task chaining 
technology which allows a single stream packet/cell processing problem to be 
decomposed into multiple, sequential tasks that can be easily linked together. The 
hardware design uses fast and flexible sharing of data and event signals among 
threads and microengines to manage data-dependent operations among multiple 
parallel processing stages.
The integrated 32-bit XScale core offers high-performance processing of rout-
ing table maintenance and system management functions. The memory control-
lers facilitate efficient access to 32-bit SRAM and 64-bit DRAM, which hold the 
routing table, networking data, and so on. In addition, a programmable hash 
engine (48, 64, and 128 bit) is provided.
© 2011 by Apple Academic Press, Inc.
  

144  Computer Technology and Computer Programming: New Research and Strategies
Intel IXP2800
The Intel IXP2800 [31] offers increased processing to support deep packet inspec-
tion and filtering, traffic management, and forwarding at up to OC-192 (10 Gbps) 
wire speed on a single chip. Its store-and-forward architecture combines a high-
performance Intel XScale core with sixteen 32-bit independent multi-threaded 
microengines that cumulatively provide up to 25 Giga-operations per second.
The 32-bit Intel XScale core operates at up to 750 MHz. The sixteen 32-bit 
microengines running at up to 1.5 GHz, support multi-threading with up to eight 
threads each, and provide space for 8192, 32-bit instructions.
IBM PowerNP
The IBM PowerNP [32] supports multiple network interfaces including Giga-
bit Ethernet at 2.5 Gbps and OC-3 to OC-48 packet-over-SONET (POS). The 
core of the PowerNP contains 16 programmable protocol processing engines and 
seven coprocessors. Additional custom logic supports management of data move-
ment at the physical and MAC layers.
The protocol processors are grouped into pairs which share a co-processor to 
accelerate packet processing. Each protocol processor supports two threads and 
includes a 3-stage pipeline (fetch, decode, and execute), general-purpose registers, 
eight instruction caches, and a dedicated ALU. The instruction memory (128 KB) 
consists of eight embedded RAMs and is initialized with picocode for packet pro-
cessing and system management.
EZChip (NP-1c)
The NP-1c [33] provides a scalable and programmable network processor archi-
tecture providing 10 Gbps wire speed. EZchip uses Task Optimized Processing 
Core (TOP core) technology. TOPs employ a super-pipelined and superscalar 
architecture for increased processing power. There are four types of TOPs, each 
having a customized instruction set and data path: (i) TOPparse identifies and 
extracts various packet headers and fields to classify packets; (ii) TOPsearch per-
forms various table lookups required for layer 2 switching, layer 3 routing, layer 
4 session switching, and layer 5–7 context switching and policy enforcement; (iii) 
TOPresolve allocates packets to an appropriate output port and queue; (iv) TOP-
modify modifies packet contents.
Data plane packet processing in the TOPcore is pipelined; packets are passed 
from TOPparse to TOPmodify. A set of software commands from the system’s 
host processor control the operations performed by the TOP processors. The  
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  145
programmability of the NP-1c makes it possible to adapt to new applications 
through simple changes in software without necessitating hardware changes.
Agere (PayloadPlus)
The Agere PayloadPlus [34] network processor exploits pattern matching optimi-
zation technology to achieve high performance. Two main components are pro-
vided: the Fast Pattern Processor (FPP) and the Routing Switch Processor (RSP). 
The FPP is a pipelined, multi-threaded processor, that receives packets through 
the physical interface and carries out protocol recognition and classification at lay-
ers 2 through 7. The FPP reassembles traffic into protocol data units (PDUs) and 
sends them to the RSP which does queuing, packet modification, traffic shaping, 
and traffic management.
Motorola (C-5e)
Motorola’s C-5e [35] is capable of layer 2–7 processing at 5 Gbps. The C-5e con-
tains 16 Channel Processors (CPs) for packet forwarding which each contain a 
transmit and receive Serial Data Processor (SDP) used for processing bit streams. 
The programmability of the SDPs supports diversity in media access control 
(MAC) interfaces, as well as parsing requirements, and can support different pro-
tocol implementations on a port-by-port basis. Each CP also contains a RISC 
core that is used for application-specific processing.
The Executive Processor (XP) integrated in the C-5e is responsible for super-
visory tasks and management of the host processor. An on-chip Table Lookup 
Unit (TLU) offers a high-speed flexible classification engine that supports over 
46 million IPv4 lookups per second. The TLU is connected to a 64-bit 128 MB 
SRAM. The C-5e also contains 128 MB SDRAM for payload storage. By con-
necting multiple C-5e NPs through their fabric interfaces to a fabric switch, it is 
possible to achieve Terabits per second of aggregate bandwidth. The C-5e NP’s 
highly configurable Fabric Processor (FP) enables implementation of per-flow 
congestion control, segmentation and re-assembly, and integrated scheduling of 
up to 128 queues.
Implementation of the Active Video Adaptation 
Node
We used the Intel IXP1200 network processor to implement our active video 
adaptation node [36]. More powerful, second generation, NPs suggest that 
© 2011 by Apple Academic Press, Inc.
  

146  Computer Technology and Computer Programming: New Research and Strategies
still better results than those we report are now achievable. The architecture 
of our active video adaptation node conforms to the node architecture pro-
vided by the active networks “reference model” [8]. An active node runs a 
Node Operating System (NodeOS) and one or more Execution Environments 
(EEs) and provides services to users through Active Applications (AAs). The 
functionality of an active network node is divided among these three major 
components.
Active Node Components
Figure 8 illustrates the architecture of an active network node. Underlying 
each active network node is a Node Operating System that manages the re-
sources of the active node such as processors, channels, and memory. The 
channels implemented by the NodeOS carry packets to and from underly-
ing communication substrates and also perform protocol processing. An Ex-
ecution Environment provides a virtual machine programming interface for 
executing programs on the active node. Thus, an EE is analogous to a shell 
program in a general purpose computing system exporting, in this case, an 
interface through which end-to-end network services can be implemented. 
Multiple EEs can be present on a single active node at the same time. EEs are 
isolated from the details of resource management by the NodeOS. An EE can 
accept active packets that initiate the execution of packet specific programs, 
also called Active Applications. AAs program the virtual machine provided 
by an EE to implement an end-to-end service. The code constituting the AA 
may be contained in a packet itself or, more likely, preloaded at the node. An 
EE can invoke multiple AAs to provide multiple services simultaneously and 
manages the initiation, execution, and termination of these AAs. All of the 
EE and AA functionalities are programs running on the microengines and the 
NodeOS functionalities are provided by the operating system running on the 
StrongARM.
We have implemented our video adaptation algorithm as an AA. The video 
adaptation AA is notified of a target output rate for the input video stream 
by the EE that initiates it. For the adaptation of multiple independent video 
streams belonging to different multicast groups, multiple AAs may be initi-
ated by the same or different EEs. The same is also true for the adaptation of a 
single video stream into streams having different data rates. Figure 9 illustrates 
these two scenarios.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  147
Figure 8. Schematic representation of the active node architecture.
Figure 9. (a) Two video streams with rates R 1i and R 2i are adapted to streams with rate R 1o and R 2o , (b) A 
single stream with rate R is adapted to two different streams with rate R 1 and R2.
Flow of Video Packets through the Active Node
Figure 10 shows a general flow of video packets through the active node. Once 
video packets are received on an input port they are classified based on informa-
tion contained in the packet headers such as protocol number, port numbers 
in UDP headers, and/or Type ID in an ANEP [37] header. Incoming packets 
may have to wait in one or more queues before classification. The classification 
of packets determines the input channel to the appropriate EE to which pack-
ets are directed. Afterwards, the input channel processing packets are passed on 
to the corresponding EE. Upon receiving a packet, the EE sends it to the ap-
propriate AA and receives the result packet from the AA after adaptation of the 
packet in accordance with the specified target rate. Video adaptation AAs used by 
the EE are chosen based on a set of identifiers consisting of a source IP address 
and port number, a multicast group address for sending the video packet, and a 
destination port number. On the output side, the EE sends the adapted video 
packets to the scheduler through output channels. Packets are then transmitted 
through appropriate output ports. Before transmission, the packets may have to 
wait in output queues. Besides active video packets having an ANEP header, the 
node can also process legacy traffic (conventional IP packets) by setting up the  
© 2011 by Apple Academic Press, Inc.
  

148  Computer Technology and Computer Programming: New Research and Strategies
appropriate channels that simply forward the packets without applying any video 
adaptation. 
Figure 10. Video packet flow through the active node.
Mapping the Algorithms to the IXP1200
Reception and classification of packets, transcoding, and scheduling and trans-
mitting adapted packets are all implemented on the microengines to provide wire-
speed packet processing. The processing done by each microengine differs and is 
determined prior to run time.
Receiving Packets
We allocate microengine zero for receiving packets. All four hardware threads are 
used for this task. Incoming packets received by microengine zero are queued to 
avoid packet loss during packet processing by other microengines. Each thread 
on the receiving microengine queues packets to be used by the microengines that 
classify, transcode, and finally retransmit them. We have implemented array-based 
circular queues in SRAM where each entry in the queue contains a packet descrip-
tor consisting of the packet buffer handle (in SRAM) and the packet size. We 
experimented with two different queue configurations: single input and multiple 
input.
Single Input-Queue Configuration
In this configuration, one 100 Mbps port is mapped to a single packet queue to 
be served by all four threads of the classification microengine. Each of the four 
threads in the receiving microengine is dedicated to receiving packets from the 
single port and to queuing them. The single queue implementation can be used 
for the adaptation of a single input video stream into single or multiple output 
streams having different data rates. Figure 11 shows the single input-queue con-
figuration.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  149
Figure 11. Single queue configuration for the video transcoding node.
Multiple Input-Queue Configuration
In this configuration a queue is created for each of the four threads in the receiv-
ing microengine. The assignment of these receiving threads to input ports can 
be done in different ways. Each thread can be assigned to a single port or to a 
different port (specified in advance). Thus, the receiving microengine can receive 
packets from up to four ports. The multiple-queue implementation can be used 
for transcoding single or multiple video streams. In single stream transcoding, 
packets received by the four threads are put in the queues sequentially. In multi-
ple-stream transcoding, each queue contains packets belonging to a separate video 
stream that is handled by a thread assigned to that queue. The multiple-queue 
configuration is illustrated in Figure 12.
Figure 12. Multiple queue configuration for the video transcoding node.
© 2011 by Apple Academic Press, Inc.
  

150  Computer Technology and Computer Programming: New Research and Strategies
Classification of Packets
We allocate microengine one for dequeuing packets from the input queues and 
classifying them. Packet classification separates convention IP data packets from 
the video packets to be transcoded. Both dequeuing and classification of a giv-
en packet are performed by a single thread. Packets are also analyzed to extract 
MPEG-1 video start codes. In the single queue configuration, each thread waits 
for its turn to retrieve a packet from the queue. In the multiple-queue configura-
tion, threads wait for new entries in their respective queues.
Video Transcoding
We allocate three microengines (2, 3, and 4) for transcoding video packets from 
the classification microengine. All three microengines are used by the requantiza-
tion technique while one microengine is sufficient for implementing the frame 
dropping technique. Video transcoding for a packet is done by a single thread in 
each of these video processing microengines, as shown in Figures 11 and 12.
Requantization
Processing DCT coefficients during requantization requires a simple but frequent 
operation due to the large portion of MPEG-1 video data coming from the block 
layer consisting of these coefficients. Implementing the entire requantization 
process in one microengine is not possible since each microengine has a limited 
instruction store capable of holding only 1024 instructions. Hence, we allocate 
microengine 2 for processing up to the macroblock layer and microengines 3 and 
4 for processing the block layer.
Packet data are fed into the input buffer from the SDRAM. Microengine 2 
processes the data from the sequence layer to the macroblock layer and moves the 
necessary coding information to the shared SRAM and SDRAM for processing 
the block layer on microengines 3 and 4. The picture and slice layers are parsed to 
extract the frame type (I, P, or B) and quantization scale, respectively. The frame 
type determines the macroblock coding type (i.e., intra- or intercoding) which 
defines the dequantization approach required (i.e., intraframe or interframe). The 
quantization scale is used to dequantize the original DCT coefficients. The coding 
information includes the macroblock type and quantization scale for processing 
the DCT coefficients. Microengine 2 also processes the macroblock layer based 
on the macroblock type to obtain the macroblock pattern, motion vectors, and 
macroblock quantization scale. The macroblock pattern and quantization scale 
(if it is different from the slice layer quantization scale) are also included in the 
coding information. The macroblock pattern provides a coded block pattern that 
describes which blocks within the macroblock are coded.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  151
The block layer processing is divided into two parts. The DC components of 
the block are processed by microengine 3 and the AC components are processed 
by microengine 4. The microengine threads obtain the coding information from 
the SRAM and SDRAM and additional information such as the quantization ta-
ble (intra or inter), the VLC tables, and a new quantization scale (chosen accord-
ing to the rate control mechanism described in the previous section) from the IXP 
1200’s scratchpad memory. The microengines decode the quantized DCT coef-
ficients and dequantize them to get the actual DCT coefficients. The coefficients 
are then requantized with the new quantization step and are encoded using VLC 
to get the transcoded DCT coefficients. The microengines store the processed 
DCT coefficients in the output buffer and write them back to the SDRAM. Fig-
ure 13 illustrates the data processing through the input and output buffers during 
requantization. Once the whole packet has been processed, the thread puts it in 
the correct output queue (one for each of the four threads in microengine 4). The 
transmit microengine dequeues the packets from the output queues in round 
robin fashion and transmits them through one or more output ports.
Figure 13. Data flow through the input and output buffers during requantization.
Frame Dropping
Frame dropping refers to a compressed domain transcoding technique which is 
relatively simple and entails less video computation. We allocate one microen-
gine (number 2) for transcoding the video stream through frame dropping. As 
the transcoding technique selectively drops a number of B frames to produce an 
output video stream with the desired rate, the microengine processes the video 
data from the sequence layer to the picture layer to recognize the frame type. The 
picture rate in the sequence layer is updated based on the new frame transmission 
rate. The microengine achieves the new transmission rate by discarding a specific 
number of B frames. The microengine threads put the packets that belong to a 
nondropped frame into the output queues. A single queue is created for each 
© 2011 by Apple Academic Press, Inc.
  

152  Computer Technology and Computer Programming: New Research and Strategies
thread in the microengine. Like requantization, packets are dequeued from the 
output queues in a circular manner and are transmitted through appropriate out-
put port(s).
Transmitting Packets
We allocate microengine 5 for dequeuing packets from the output queues and 
transmitting them. One thread is assigned to dequeue the packets and the remain-
ing threads are used to schedule and send the packets out on the wire as illustrated 
in Figures 11 and 12. Once a packet is received from the output queue, new 
checksums are calculated for the IP and UDP headers based on the new packet 
size and contents. Packets are then transmitted out of the IXP1200.
Hashing
The IXP1200 provides a hardware hash unit located within the IX bus unit and 
the hash unit implements a hash function that produces values with a uniform 
statistical distribution regardless of the input. Packet processing that requires one 
or more table lookups is greatly eased by the hardware assisted hashing functional-
ity provided by the IXP1200. This hashing unit is only accessible to microengines 
and is capable of performing either 48 bit or 64 bit hashes.
In our framework, we have used a hash table to store, retrieve, and update 
hints from the receivers at the active node. These hints describe user preferences 
such as interest levels in particular video streams and the capability of the end de-
vices such as processing power, screen size, and so on. Receivers transmit the hints 
upstream (through the active node) to the sender in capsule form. Video packets 
originating from the source pass through the active node that adapts the packets 
based on the hints from the intended receivers and network connections.
Implementation Complexity and Portability
The active video adaptation node entails greater implementation complexity than 
a conventional router to provide support for video adaptation. This complexity 
and the associated overhead is not insignificant. Fortunately, the “cost” of design-
ing the adaptation node is incurred only once and may be amortized over the 
number of network processors it runs on. Further, the programmability of NPs 
will allow for relatively easy extension of adaptation node functionality. Despite 
the high-level similarity of NP architectures, there is currently no readily accepted 
standard programming model for network processors. Thus, our code is largely 
IXP specific.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  153
The different phases of the video adaptation algorithm executed by each mi-
croengine are predetermined prior to execution. This makes the allocation of 
work simpler than assigning it to the microengines dynamically. The concept of 
“microblock” in packet receiving is used to balance the code performance and 
modularity. A microblock is a sequence of microengine code that operates on a 
single packet that is currently being processed. One or more microblocks can be 
combined together in a loop, called a “dispatch” loop that calls these microblocks 
in a particular order to perform specific functions. We have used a while loop as 
the dispatch loop that calls the packet receiving microblock and a packet queuing 
microblock to receive packets from the input ports and to queue them for use by 
the other microengines. As the packet length is unknown during the reception of 
the start of the packet, a fixed size buffer (large enough to hold the maximum size 
packet) is allocated for each packet. Hardware supported SRAM LIFO stacks are 
used for such buffer allocation without any overhead for writing code to create 
stacks. This approach is largely generalizable to most current NP architectures.
Another challenge was to determine the granularity of segmentation for an 
MPEG-1 video stream at the server. We decided to segment the video stream into 
a sequence of independent packets on a per slice basis since the slice in a frame 
represents the smallest independent coding unit in an MPEG-1 video sequence. 
This suited the comparatively low power of the IXP1200 but could still be used 
with more powerful NPs. The granularity of segmentation does not significantly 
affect coding complexity.
We used a nonpreemptive thread arbiter and shared variables to implement 
intra-microengine thread communication and mutual exclusion. The nonpre-
emptive thread arbiter allows one thread to run until the thread itself explicitly 
releases control of the microengine by waiting for a signal, swapping out on a 
memory read, or voluntarily releasing control. Shared variables are implemented 
in the hardware with absolute registers providing extremely fast interthread com-
munication and mutual exclusion. Synchronization was a key performance issue 
in our IXP 1200 implementation and will likely continue to be regardless of net-
work processor architecture.
Most of the computation overhead and complexity comes from implement-
ing different levels of decompression and compression tasks during the actual 
transcoding of the video packets. However, multiple microengines capable of 
wire-speed packet processing made the transcoding task fast enough to provide 
a realistic video transfer rate (24–30 frames per second for MPEG-1) despite the 
limitations of the IXP1200. Processing requiring table lookups was simplified 
and expedited by the hardware assisted hashing functionality provided by the 
IXP1200.
© 2011 by Apple Academic Press, Inc.
  

154  Computer Technology and Computer Programming: New Research and Strategies
Implementing our video adaptation algorithm on other network processors 
would require a modified strategy for allocating various tasks such as reception 
and classification of packets, transcoding, and scheduling and transmitting adapt-
ed packets based on the hardware resources provided by the particular network 
processor. Similarly, other architecture specific coding patterns would have to be 
revised. Not surprisingly, porting NP code is similar to porting low-level parallel 
code.
Protoype Evaluation
We now present the results obtained from our evaluation of our IXP1200-based 
video transcoder. The metrics used to measure transcoder performance included 
transcoding latency, throughput, and accuracy. These criteria capture the effec-
tiveness of transcoding MPEG-1 streams using the IXP1200. Transcoding latency 
determines how fast video transformation takes place. Low transcoding latency 
is preferred. The goodness of transcoding latency is determined by how close the 
transcoded video transfer rate is to the actual video transfer rate (i.e., for MPEG-1, 
24–30 frames per second). Transcoding throughput determines the number of 
streams that can be processed simultaneously. Finally, the amount of “blocki-
ness,” “blurriness,” and “noise” in the transcoded video determines the accuracy of 
transcoding which is assessed by comparing the quality of the transcoded streams 
with that of the original streams.
A test environment was set up to verify the practicality and applicability of the 
video transcoding mechanism. The experimental system consisted of a video serv-
er (sender), an IXP1200-based transcoding node, and several clients connected 
to the trancoding node. A number of experiments were conducted to transcode 
MPEG-1 video streams according to the various requirements of the clients and 
their link bandwidths.
For our experiments, we used a selection of MPEG-1 video streams whose 
properties are summarized in Table 1. The frame size represents the width and 
height of each frame in pixels. The average size of I, P, and B frames are given in 
bytes. The frame pattern represents the order in which frames in a GOP are dis-
played. Each of the video streams is viewed at a rate of 30 fps.
Table 1. Properties of the test MPEG-1 video sequences.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  155
Transcoding Latency
We experimented using various numbers of microengine threads to get an idea of 
the capabilities of the IXP1200. The test video streams were transmitted from the 
video server to the video transcoding node at a rate of 300 Kbps. We set the out-
put target rate of the active node to 200 Kbps. We then conducted experiments 
for each video sequence to observe any packet loss. The system was found to be 
capable of processing the video streams at that input rate.
Requantization
Figure 14 and Table 2 show the transcoding latency per frame for each test video 
stream using requantization. The transcoding latency for requantization includes 
the time required for decoding the frame through VLD, further processing re-
lated to dequantization and quantization of DCT coefficients, and encoding us-
ing VLC.
Table 2. Transcoding latency per frame using requantization.
Figure 14. Transcoding latency per frame using requantization.
© 2011 by Apple Academic Press, Inc.
  

156  Computer Technology and Computer Programming: New Research and Strategies
To take advantage of the IXP1200’s multithreading architecture and to im-
prove transcoding performance, multiple threads in each microengine can be 
used. The latencies (approximate values in milliseconds) are shown in Table 2 and 
Figure 14 for different numbers of threads running on the transcoding microen-
gines. Employing two threads leads to lower transcoding latency and the same is 
true for higher numbers of threads. However, employing more than three threads 
provides little benefit. The reason for this is the increasing level of intramicroen-
gine mutual exclusion that is required.
The transcoding latencies shown in Table 2 indicate that the test video 
sequences can be transcoded at 24–30 frames or more per second while using 
two or more threads in each video transcoding microengine. This meets the 
minimum display frame rate for MPEG-1 video. Note that a single thread im-
plementation cannot meet this transcoding rate for all the test video sequenc-
es. (e.g., “danger.mpeg,” “vessel.mpeg,” and “rotate.mpeg” are transcoded at 
rates of around 22.22, 18.51, and 23.28 fps which are at least close to the 
minimum display rate, 24 fps.) The salient point to note from Table 2 (with 
reference to Table 1) is the relationship between frame size and transcoding 
latency. The smaller frame sizes or coding bit rates imply sparser blocks in the 
frame resulting in greater speedup during requantization. The opposite is true 
for larger frames.
In our next experiment, we evaluated the transcoding latency for the 
transcoding of two video streams (e.g., intended for different multicast 
groups). (No actual multicast implementation was done. For assessing perfor-
mance of transcoding multiple streams, however, this was not required.) Two 
threads (dedicated) in each video transcoding microengine were responsible 
for transcoding one video stream. The transcoding latency obtained for each 
video stream was slightly higher than (previous experiment) when they are 
separately transcoded with two threads in each microengine. For the streams 
“canyon.mpeg” and “rotate.mpeg,” the latencies obtained per frame were 7.80 
and 30.64 milliseconds, respectively, which are slightly higher than in the case 
of the single stream transcoding (6.41 and 26.18 milliseconds from Table 2). 
This is due to intra-microengine mutual exclusion.
Frame Dropping
Table 3 and Figure 15 show the transcoding latency (approximate values in mi-
croseconds) per frame for several test video streams that contain B frames in the 
sequence. The major component of the transcoding latency using frame dropping 
includes the time required to process the video data from the sequence to the 
picture layer and the slice headers of a frame.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  157
Table 3. Transcoding latency per frame using frame dropping.
Figure 15. Transcoding latency per frame using frame dropping.
As in requantization, employing two threads leads to lower transcoding la-
tency than using one thread and the same is true for higher number of threads. 
However, as shown in Table 3 and Figure 15, employing more than two threads 
contributes little to the performance. This is due to the greater amount of intra-
microengine mutual exclusion that is performed by the video adaptation code.
Transcoding latencies obtained for frame dropping indicate the real-time 
performance of this compressed domain transcoding technique. Compared to 
requantization, transcoding speed is much higher in this case. This is due to the 
amount of video data that must be processed by the frame dropping code. Ap-
proximately 4.83% of video data coded at 333 Kbps, as an example, come from 
the sequence to the picture layer and the slice headers of a frame.
Since the frame dropping technique does not process macroblock and block 
layer data, the transcoding latency for a frame depends on the number of slices in 
the frame. As each frame is processed per slice, more slices result in more packets 
that require increased processing time. The opposite is true for a smaller number 
of slices per frame. This is reflected in Table 3.
© 2011 by Apple Academic Press, Inc.
  

158  Computer Technology and Computer Programming: New Research and Strategies
In this case also, we evaluated the latency for the transcoding of two vid-
eo streams intended for different multicast groups. Two threads in each video 
transcoding microengine were responsible for transcoding one video stream. The 
transcoding latency obtained for each video stream was slightly higher than (pre-
vious experiment) when they are separately transcoded with two threads in each 
microengine. For the streams “ski.mpeg” and “vessel.mpeg,” the latencies obtained 
per frame were 346 and 418 microseconds, respectively, which are a little higher 
than the values obtained in the case of the single stream transcoding (335 and 403 
microseconds from Table 3).
Throughput
Next, we measured and compared the throughput attained by the active video 
adaptation node for the requantization and frame dropping techniques.
Requantization
For our throughput experiments, we set a target of 30% reduction in data rate for 
the output streams. The input rate of the test video streams from the video server 
to the transcoding node was then gradually increased until the node experienced 
packet loss. Thus, the throughput for each video stream was measured using the 
highest possible injection rate at which the node could perform the transcoding 
without losing packets. 
Throughputs affored (approximate values in Kbps) are shown in Table 4 and 
Figure 16 for different numbers of threads running on the video transcoding mi-
croengines. Using two threads leads to higher throughput than using one thread 
and the same is true for higher numbers of threads. However, employing more 
than three threads has decreasing significance. The reason is, again, the amount 
of intra-microengine mutual exclusion. Overall, requantization produces a sig-
nificant reduction in data rate while maintaining reasonable image quality (as 
discussed later), but at the expense of incurred delay. The results from Table 4 
show that requantizing streams with high transcoding latency results in decreased 
throughput.
Table 4. Throughput of video transcoding for MPEG-1 sequences.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  159
Figure 16. Throughput using requantization.
We also evaluated throughput when transcoding two video streams target-
ed for different multicast groups. The total throughput attained for these two 
streams was somewhat lower than the overall throughput attained when they were 
separately transcoded using two threads in each microengine. For example, the 
throughput obtained from this experiment for the video streams “ski.mpeg” and 
“vessel.mpeg,” 2214 Kbps, was a little lower than the aggregate throughput ob-
tained in the case of the single stream implementation (1277+1208=2485 Kbps 
from Table 4).
Frame Dropping
As in requantization, the input rate of the test video streams from the video server 
to the active node was gradually increased until the node experienced packet loss. 
Since the test video sequences were coded at 30 frames per second, we decided 
to drop six B frames from every 30 consecutive frames to meet the minimum re-
quirement of MPEG-1 picture rate (24 frames per second). Table 5 and Figure 17 
show the throughput attained for the test video streams that contain B frames.
Table 5. Throughput of video adaptation for different test MPEG-1 sequences using frame dropping.
© 2011 by Apple Academic Press, Inc.
  

160  Computer Technology and Computer Programming: New Research and Strategies
Figure 17. Throughput using frame dropping.
The throughputs (approximate values in Kbps) are shown for changing num-
bers of threads running on the video adaptation microengines. The trend in the 
change of throughput for frame dropping based on the change in the number of 
microengine threads is similar to that for requantization. As in our compressed 
domain frame dropping, B frames are selectively dropped, the reduction in output 
data rate depends on the number and size of the B frames in the video sequence. A 
video stream having high average size of B frames produces less post frame drop-
ping throughput. This is illustrated in Table 5 for the sequence “vessel.mpeg.”
We also evaluated throughput when transcoding two video streams targeted 
for different multicast groups. The total throughput attained for these two streams 
was, again, a little lower than the overall throughput attained when they were 
separately transcoded using two threads in each microengine. For example, the 
throughput obtained from this experiment for video streams “blazer.mpeg” and 
“vessel.mpeg,” 2657 Kbps, was slightly lower than the total throughput obtained 
in the case of the single stream implementation (1389+1521=2910 Kbps from 
Table 5).
Compared to requantization, frame dropping produces less reduction in data 
rate. Moreover, the reduction in data rate achieved by the frame dropping tech-
nique is limited by the number and size of B frames in the video sequence. For 
this reason, this compression domain frame dropping technique may not always 
be able to meet the data rate desired by the receiver. However, this transcod-
ing technique is well suited to be used for ensuring that a receiver receives 
frames at a rate appropriate to its processing capabilities. On the other hand,  
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  161
requantization produces larger reduction in data rate though it involves more 
processing and thus takes longer than the other technique. Unlike the frame drop-
ping technique, requantization reduces the data rate without affecting the frame 
rate, but of course at the cost image quality.
Accuracy of Video Adaptation
We also measured the quality of the transcoded video streams by comparing them 
with the original streams. In evaluating the transcoded video quality, we made 
use of peak signal-to-noise ratio (PSNR) and percentage error (PE) introduced, as 
our error metrics. The PSNR measures are estimates of the quality of a transcoded 
image compared to the corresponding original image. PSNR in decibels (dB) is 
computed as
	
10
255
20log
PSNR
RMSE
æ
ö÷
ç
=
÷
ç
÷
çè
ø	
(10)
for an 8-bit (pixel values of 0 to 255) image where RMSE represents the root-
mean-squared error of the transcoded image. For an original image Fo(i,j) of N by 
N pixels and the corresponding transcoded image Ft(i,j) of the same size, RMSE 
is computed as
	
RMSE =
i=1
N
j=1
N
Ft(i, j)−F0(i, j)
[
]
2
∑
∑
N
.	
(11)
Next, the PE introduced in a transcoded image is calculated from the relative 
error (RE) as follows:
	
(
)
1
1
0
1
1
0
( , )
( , ) ,
( , )
100%
N
N
i
j
t
N
N
i
j
F i j
F i j
RE
F i j
PE
RE
=
=
=
=
-
=
+
´
å å
å å
	
(12)
In computing RMSE and RE, the RGB values for each pixel in a frame were 
considered.
Typical PSNR values range from 20 to 40. Transcoded images with higher 
PSNR and lower PE values are judged to be better. Table 6 summarizes the aver-
age PSNRs and PEs for the I, P, and B frames, respectively, of several requantized 
test video sequences given a 30% reduction in output data rate. The values ob-
tained for each frame type indicate the degree of quantization that was achieved 
by the transcoder in reducing the bit rate (lower PSNR and higher PE values 
specify coarser quantization and vice versa).
© 2011 by Apple Academic Press, Inc.
  

162  Computer Technology and Computer Programming: New Research and Strategies
Table 6. Quality of various test MPEG-1 video sequences-PSNR and PE.
It is important to note that these error metrics do not always correlate well 
with perceived image quality though they do provide a good measure of relative 
quality. A higher PSNR does not necessarily always imply a reconstructed image 
of better quality. For this reason, actual transcoded images from several streams 
are provided below to allow the visual effects of quantization to be seen. As the 
requantization achieves rate reduction by making the DCT values smaller (and 
some are rounded to zero), the transcoded video loses sharpness. Figure 18 shows 
the quality variation in several images comparing the original and corresponding 
transcoded streams.
Figure 18. Video quality variation in original and transcoded image (a) canyon.mpeg, (b) rotate.mpeg, and (c) 
vessel.mpeg.
Another useful technique for demonstrating errors is to construct an error 
image that shows pixel by pixel errors. Error images are created by taking the 
difference between the transcoded and original pixels. These error images are dif-
ficult to visualize as the difference values are often small and some are zeros which 
commonly represent black. To make the errors more visible, the difference values 
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  163
are multiplied by a constant and the entire image is translated to a gray level by 
adding an offset. Figure 19 shows error images for three selected test sequences.
Figure 19. Error images for selected video streams.
The quality of the transcoded video stream using frame dropping was evalu-
ated by quantifying the smoothness of the motion in the decoded sequence. If 
the frame (picture) rate is less than 12 fps it is easily detectable by the human eye. 
As we maintain the minimum frame rate (24 fps) required by the MPEG-1 stan-
dard in the frame dropping technique, the transcoded streams exhibit sufficient 
smoothness of motion in the decoded sequences.
Conclusions
In this paper, we discussed the design and implementation of a network proces-
sor-based transcoder for in-network adaptation of video streams to support col-
laborative applications. Our transcoder uses the IXP1200 network processor to 
transcode MPEG-1 streams.
Transcoding was done by requantizing the DCT coefficients with larger quan-
tization values to reduce the bit rate. To verify the practicality of the video ad-
aptation scheme, we conducted experiments and presented results in terms of 
transcoding latency, throughput, and accuracy of video adaptation. Our video 
transcoding node implementation can dynamically adapt the test video streams 
on a packet-by-packet basis at an acceptable rate for use near the network edge 
(where only a small number of concurrent streams are likely).
Transcoding latencies obtained for test video sequences confirm the real-time 
performance of the video transcoding. As expected, the speed depends on the bit 
rate of the compressed video stream; a high bit rate stream incurs higher transcod-
ing latency. We also evaluated the quality of the transcoded video by measur-
ing the average PSNR and percentage error (PE) and through the use of error  
images.
© 2011 by Apple Academic Press, Inc.
  

164  Computer Technology and Computer Programming: New Research and Strategies
The current implementation of the transcoder uses the microengines provided 
by the IXP1200. Involving the StrongARM processor is worth considering for 
future work as is implementation using more powerful network processors. Our 
results were not compared to any other system as currently no similar adaptation 
scheme exists. We did compare the performance of our prototype to an earlier 
system exploiting only the basic capabilities of the IXP1200 (one thread in each 
video adaptation microengine) as a baseline.
The prototype adaptation node could be re-implemented relatively easily on 
more recent IXP series network processors. The use of the IXP2400 or, particular-
ly, the IXP2800 would result in reduced transcoding latency and higher through-
put given the increased number and speed of the microengines and due to the 
larger number of threads supported per microengine. Coding of the adaptation 
routines would also be simplified on such machines owing to their larger instruc-
tion memory capacities. This would improve readability and portability of the 
code and, possibly, efficiency as well. More aggressive transcoding might also be 
attempted. Further, the increased capabilities of these newer network processors 
would be far more effective in supporting the concurrent transcoding of multiple 
streams (for different multicast transmissions) and/or higher resolution streams 
corresponding to new encoding standards (e.g., MPEG-2 and H.263). Finally, 
the significant control processor capabilities of network processors such as the 
PowerNP and C-5e can be effectively exploited in practical deployments.
Acknowledgement
This work was supported, in part, by a University of Manitoba Graduate  
Fellowship.
References
1.	 L. Chen and G. Singh, “Enhancing multicast communication to support pro-
tocol design,” in Proceedings of the 11th International Conference on Com-
puter Communications and Networks (ICCCN ‘02), pp. 328–333, Miami, 
Fla, USA, October 2002.
2.	 T. Turletti, “INRIA Videoconferencing system (IVS),” ConneXions-The In-
teroperability Report Journal, vol. 8, no. 10, pp. 20–24, 1994.
3.	 R. Frederick, “Experiences with real-time software video compression,” in Pro-
ceedings of the 6th International Workshop on Packet Video, pp. F1.1–F1.4, 
September 1994.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  165
4.	 S. McCanne and V. Jacobson, “Visual audio tool,” Lawrence Berkeley Labora-
tory, ftp://ftp.ee.lbl.gov/conferencing/vat.
5.	 S. McCanne and V. Jacobson, “vic: a flexible framework for packet video,” 
in Proceedings of the 3rd ACM International Conference on Multimedia,  
pp. 511–522, San Franscisco, Calif, USA, November 1995.
6.	 H. Eriksson, “MBONE: the multicast backbone,” Communications of the 
ACM, vol. 37, no. 8, pp. 54–60, 1994.
7.	 D. L. Tennenhouse and D. J. Wetherall, “Towards an active network architec-
ture,” Computer Communication Review, vol. 26, no. 2, pp. 5–17, 1996.
8.	 K. L. Calvert, “Architectural framework for active networks,” RFC Draft, ver-
sion 1.0, July 1999.
9.	 P. S. Goncalves, J. F. Rezende, O. M. Duarte, and G. Pujolle, “Improving lay-
ered video multicast using active networks,” Pierre and Marie Curie University, 
Paris, France, March 2001.
10.	 R. Ramanujan and K. Thurber, “An active network based design of a QoS 
adaptive video multicast service,” in Proceedings of the World Conference on 
Systems, Cybernetics and Informatics, pp. 643–650, July 1998.
11.	 H.-F. Hsiao and J.-N. Hwang, “Layered FGS video over active network with 
selective drop and adaptive rate control,” in Proceedings of IEEE International 
Conference on Acoustics, Speech and Signal Processing (ICASSP ‘03), vol. 5, 
pp. 752–755, Hong Kong, April 2003.
12.	 L. Cheng and M. R. Ito, “Layered multicast with TCP-friendly congestion 
control using active networks,” in Proceedings of the 10th International Con-
ference on Telecommunications, pp. 806–811, March 2003.
13.	 H. Akamine, N. Wakamiya, M. Murata, and H. Miyahara, “On the construc-
tion of heterogeneous multicast distribution trees using filtering in an active 
network,” in Proceedings of the 1st International Workshop on Quality of Fu-
ture Internet Services (QoFIS ‘00), pp. 272–284, Berlin, Germany, September 
2000.
14.	 R. Keller, S. Choi, M. Dasen, D. Decasper, G. Fankhauser, and B. Plattner, 
“An active router architecture for multicast video distribution,” in Proceedings 
of the 19th Annual Joint Conference of the IEEE Computer and Communi-
cations Societies (INFOCOM ‘00), vol. 3, pp. 1137–1146, Tel-Aviv, Israel, 
March 2000.
15.	 R. Wittmann, K. Krasnodembski, and M. Zitterbart, “Heterogeneous multi-
casting based on RSVP and QoS filters,” in Broadband European Networks 
and Multimedia Services, vol. 3408 of Proceedings of SPIE, pp. 357–365,  
Zurich, Switzerland, May 1998.
© 2011 by Apple Academic Press, Inc.
  

166  Computer Technology and Computer Programming: New Research and Strategies
16.	 T. Yamada, N. Wakamiya, M. Murata, and H. Miyahara, “Implementation 
and evaluation of video-quality adjustment for heterogeneous video multicast,” 
in Proceedings of the 8th Asia-Pacific Conference on Communications (APCC 
‘02), pp. 454–457, September 2002.
17.	 Y. Jia, I. Nikolaidis, and P. Gburzynski, “Buffer space trade-offs in multihop 
networks,” in Proceedings of the Conference on Communication Networks 
and Services Research (CNSR ‘03), pp. 74–79, May 2003.
18.	 J. L. Mitchell, W. B. Pennebaker, C. E. Fogg, and D. J. LeGall, MPEG Video 
Compression Standard, Chapman & Hall, Boca Raton, Fla, USA, 1996.
19.	 “Information Technology—Generic Coding of Moving Pictures and Associ-
ated Audio Information—Part 2 (Video),” ISO/IEC 13818-2, 1998.
20.	 “Visual: a compression codec for visual data—part 2,” ISO/IEC 14496-2, 
1998.
21.	 H.261, “Video codec for audiovisual services at px64 kbits,” International Tele-
communications Union Telecommunications Standardisation Sector, ITU-T 
Recommendation H.261, 1993.
22.	 D. H.263, “Video coding for low bitrate communication,” International Tele-
communications Union Telecommunications Standardisation Sector, ITU-T 
Recommendation H.263, 1996.
23.	 T. Wiegand, G. J. Sullivan, G. Bjøntegaard, and A. Luthra, “Overview of the 
H.264/AVC video coding standard,” IEEE Transactions on Circuits and Sys-
tems for Video Technology, vol. 13, no. 7, pp. 560–576, 2003.
24.	 “Information Technology—Coding of Moving Pictures and Associated Audio 
for Digital Storage Media at up to about 1.5 Mbit/s—Part 2 (Video),” ISO/
IEC 11172-2, 1993.
25.	 G. Keeman, R. Hellinghuizen, F. Hoeksema, and G. Heideman, “Transcod-
ing of MPEG-2 bitstreams,” Signal Processing: Image Communication, vol. 8,  
pp. 481–500, 1996.
26.	 J. Hwang, T. Wu, and C. Lin, “Dynamic frame-skipping in video transcoding,” 
in Proceedings of the 2nd IEEE Workshop on Multimedia Signal Processing 
(MMSP ‘98), pp. 616–621, Redondo Beach, Calif, USA, December 1998.
27.	 H. Shu and L.-P. Chau, “An efficient arbitrary downsizing algorithm for video 
transcoding,” IEEE Transactions on Circuits and Systems for Video Technol-
ogy, vol. 14, no. 6, pp. 887–891, 2004.
28.	 Y. Liang, L.-P. Chau, and Y.-P. Tan, “Arbitrary downsizing video transcoding 
using fast motion vector reestimatlon,” IEEE Signal Processing Letters, vol. 9, 
no. 11, pp. 352–355, 2002.
© 2011 by Apple Academic Press, Inc.
  

In-Network Adaptation of Video Streams Using Network Processors  167
29.	 R. Dugad and N. Ahuja, “A fast scheme for image size change in the com-
pressed domain,” IEEE Transactions on Circuits and Systems for Video Tech-
nology, vol. 11, no. 4, pp. 461–474, 2001.
30.	 “Intel IXP2400 Network Processor—Product Brief,” Intel Corp., 2003.
31.	 “Intel IXP2805 Network Processor—Product Brief,” Intel Corp., 2005.
32.	 J. R. Allen, Jr., B. M. Bass, C. Basso, et al., “IBM PowerNP network processor: 
hardware, software, and applications,” IBM Journal of Research and Develop-
ment, vol. 47, no. 2-3, pp. 177–193, 2003.
33.	 “NP1c Network Processor—Product Brief,” EZchip Technology, 2002.
34.	 Agere Systems Proprietary, “The challenge for next generation network proces-
sors,” white paper, April 2001.
35.	 “C-5e Network Processor—Product Brief,” Motorola, Plantation, Fla, USA, 
2003.
36.	 M. Shorfuzzaman, R. Eskicioglu, and P. Graham, “Video transcoding using 
network processors to support dynamically adaptive video multicast,” in Pro-
ceedings of the 20th IEEE International Conference on Advanced Informa-
tion Networking and Applications (AINA ‘06), vol. 1, pp. 471–476, Vienna,  
Austria, April 2006.
37.	 D. S. Alexander, B. Braden, C. A. Gunter, et al., “Active network encapsulation 
protocol (ANEP),” RFC Draft, July 1997.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor 
Networks
Stanislava Soro and Wendi Heinzelman
Abstract
Visual sensor networks have emerged as an important class of sensor-based 
distributed intelligent systems, with unique performance, complexity, and 
quality of service challenges. Consisting of a large number of low-power cam-
era nodes, visual sensor networks support a great number of novel vision-
based applications. The camera nodes provide information from a monitored 
site, performing distributed and collaborative processing of their collected 
data. Using multiple cameras in the network provides different views of the 
scene, which enhances the reliability of the captured events. However, the 
large amount of image data produced by the cameras combined with the net-
work’s resource constraints require exploring new means for data processing, 
communication, and sensor management. Meeting these challenges of visu-
al sensor networks requires interdisciplinary approaches, utilizing vision pro-
cessing, communications and networking, and embedded processing. In this 
paper, we provide an overview of the current state-of-the-art in the field of 
© 2011 by Apple Academic Press, Inc.

A Survey of Visual Sensor Networks  169
visual sensor networks, by exploring several relevant research directions. Our 
goal is to provide a better understanding of current research problems in the 
different research fields of visual sensor networks, and to show how these dif-
ferent research fields should interact to solve the many challenges of visual sen-
sor networks.
Introduction
Camera-based networks have been used for security monitoring and surveillance 
for a very long time. In these networks, surveillance cameras act as independent 
peers that continuously send video streams to a central processing server, where 
the video is analyzed by a human operator.
With the advances in image sensor technology, low-power image sensors 
have appeared in a number of products, such as cell phones, toys, comput-
ers, and robots. Furthermore, recent developments in sensor networking and 
distributed processing have encouraged the use of image sensors in these 
networks, which has resulted in a new ubiquitous paradigm—visual sensor 
networks. Visual sensor networks (VSNs) consist of tiny visual sensor nodes 
called camera nodes, which integrate the image sensor, embedded processor, 
and wireless transceiver. Following the trends in low-power processing, wire-
less networking, and distributed sensing, visual sensor networks have devel-
oped as a new technology with a number of potential applications, ranging 
from security to monitoring to telepresence.
In a visual sensor network a large number of camera nodes form a distributed 
system, where the camera nodes are able to process image data locally and to ex-
tract relevant information, to collaborate with other cameras on the application-
specific task, and to provide the system’s user with information-rich descriptions 
of captured events. With current trends moving toward development of distrib-
uted processing systems and with an increasing number of devices with built-in 
image sensors, a question of how these devices can be used together appears [1]. 
There are several specific questions that have intrigued the research community. 
How can the knowledge gained from wireless sensor networks be used in the 
development of visual sensor networks? What kind of data processing algorithms 
can be supported by these networks? What is the best way to manage a large num-
ber of cameras in an efficient and scalable manner? What are the most efficient 
camera node architectures? Inspired by the tremendous potential of visual sensor 
networks as well as by the current progress in this research field, we provide in 
this paper an overview of the current research directions, challenges, and potential 
applications for visual sensor networks.
© 2011 by Apple Academic Press, Inc.
  

170  Computer Technology and Computer Programming: New Research and Strategies
Several survey papers on multimedia sensor networks and visual processing 
can be found in the current literature. In [2], Misra et al. provide a survey of pro-
posed solutions for different layers of the network protocol stack used for multi-
media transmission over the wireless medium. Charfi et al. [3] provide a survey on 
several challenging issues in the design of visual sensor networks design, including 
coverage requirements, network architectures, and energy-aware data communi-
cation and processing. Here, we go one step further, by discussing these and other 
aspects of visual sensor networks in more detail and taking a multidisciplinary 
look at these topics. An extensive survey of wireless multimedia sensor networks 
is provided in [4], where Akyildiz et al. discuss various open research problems in 
this research area, including networking architectures, single layer and crosslayer 
communication protocol stack design, and multimedia sensor hardware. Here, 
we discuss similar problems, but considering visual sensor networks as distributed 
systems of embedded devices, highly constrained in terms of available energy, 
bandwidth resources and with limiting processing capabilities. Thus, we are fo-
cusing on the low power and low complexity aspects of visual sensor networks. 
Considering that many aspects of visual sensor networks, such as those related to 
the design of the networking protocol stack or data encoding techniques in the 
application layer have already been thoroughly discussed in [2, 4], we focus here 
on other aspects of data communication, by emphasizing the need for collab-
orative data communication and sensor management in visual sensor networks. 
Thus, this paper complements these other survey papers and can be a valuable 
source of information regarding the state-of-the-art in several research directions 
that are vital to the success of visual sensor networks.
Characteristics of Visual Sensor Networks
One of the main differences between visual sensor networks and other types of 
sensor networks lies in the nature of how the image sensors perceive information 
from the environment. Most sensors provide measurements as 1D data signals. 
However, image sensors are composed of a large number of photosensitive cells. 
One measurement of the image sensor provides a 2D set of data points, which 
we see as an image. The additional dimensionality of the data set results in richer 
information content as well as in a higher complexity of data processing and 
analysis.
In addition, a camera’s sensing model is inherently different from the sensing 
model of any other type of sensor. Typically, a sensor collects data from its vicinity, 
as determined by its sensing range. Cameras, on the other hand, are character-
ized by a directional sensing model—cameras capture images of distant objects/
scenes from a certain direction. The 2D sensing range of traditional sensor nodes 
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  171
is, in the case of cameras, replaced by a 3D viewing volume (called field of view, 
or FoV).
Visual sensor networks are in many ways unique and more challenging com-
pared to other types of wireless sensor networks. These unique characteristics of 
visual sensor networks are described next.
Resource Requirements
The lifetime of battery-operated camera nodes is limited by their energy con-
sumption, which is proportional to the energy required for sensing, processing, 
and transmitting the data. Given the large amount of data generated by the cam-
era nodes, both processing and transmitting image data are quite costly in terms 
of energy, much more so than for other types of sensor networks. Furthermore, 
visual sensor networks require large bandwidth for transmitting image data. Thus 
both energy and bandwidth are even more constrained than in other types of 
wireless sensor networks.
Local Processing
Local (on-board) processing of the image data reduces the total amount of data 
that needs to be communicated through the network. Local processing can in-
volve simple image processing algorithms (such as background substraction for 
motion/object detection, and edge detection) as well as more complex image/vi-
sion processing algorithms (such as feature extraction, object classification, scene 
reasoning). Thus, depending on the application, the camera nodes may provide 
different levels of intelligence, as determined by the complexity of the processing 
algorithms they use [5]. For example, low-level processing algorithms (such as 
frame differencing for motion detection or edge detection algorithms) can pro-
vide a camera node with the basic information about the environment, and help it 
decide whether it is necessary to transmit the captured image or whether it should 
continue processing the image at a higher level. More complex vision algorithms 
(such as object feature extraction, object classification, etc.) enable cameras to rea-
son about the captured phenomena, such as to provide basic classification of the 
captured object. Furthermore, the cameras can collaborate by exchanging the de-
tected object features, enabling further processing to collectively reason about the 
object’s appearance or behavior. At this point the visual sensor network becomes 
a user-independent, intelligent system of distributed cameras that provides only 
relevant information about the monitored phenomena. Therefore, the increased 
complexity of vision processing algorithms results in highly intelligent camera 
systems that are oftentimes called smart camera networks [6].
© 2011 by Apple Academic Press, Inc.
  

172  Computer Technology and Computer Programming: New Research and Strategies
In order to extract necessary information from different images, a camera 
node must employ different image processing algorithms. One specific image 
processing algorithm cannot achieve the same performance for different types of 
images—for example, an algorithm for face extraction significantly differs from 
algorithm for vehicle detection. However, oftentimes it is impossible to keep all 
the necessary image processing algorithms in the constrained memory of a camera 
node. One solution to this problem is to use mobile agents—a specific piece of 
software dispatched by the sink node to the region of interest [7]. Mobile agents 
collect and aggregate the data using a specific image algorithm and send the pro-
cessed data back to the sink. Furthermore, the mobile agents can migrate between 
the nodes in order to perform the specific task, thereby performing distributed 
information processing [8]. In this way, the amount of data sent by the node, as 
well as the number of data flows in the network, can be significantly reduced.
Real-Time Performance
Most applications of visual sensor networks require real-time data from the cam-
era nodes, which imposes strict boundaries on maximum allowable delays of data 
from the sources (cameras) to the user (sink). The real-time performance of a vi-
sual sensor network is affected by the time required for image data processing and 
for the transmission of the processed data throughout the network. Constrained 
by limited energy resources and by the processing speed of embedded processors, 
most camera nodes have processors that support only lightweight processing algo-
rithms. On the network side, the real-time performance of a visual sensor network 
is constrained by the wireless channel limitations (available bandwidth, modula-
tion, data rate), employed wireless standard, and by the current network condi-
tion. For example, upon detection of an event, the camera nodes can suddenly 
inject large amounts of data in the network, which can cause data congestion and 
increase data delays.
Different error protection schemes can affect the real-time transmission of im-
age data through the network as well. Commonly used error protection schemes, 
such as automated-repeat-request (ARQ) and forward-error-correction (FEC) 
have been investigated in order to increase the reliability of wireless data trans-
missions [9]. However, due to the tight delay constraints, methods such as ARQ 
are not suitable to be used in visual sensor networks. On the other hand, FEC 
schemes usually require long blocks in order to perform well, which again can 
jeopardize delay constraints.
Finally, multihop routing is the preferred routing method in wireless sensor 
networks due to its energy-efficiency. However, multihop routing may result in 
increased delays, due to queueing and data processing at the intermediate nodes. 
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  173
Thus, the total delay from the data source (camera node) to the sink increases 
with the number of hops on the routing path. Additionally, bandwidth becomes 
a scarce resource in multihop networks consisting of traditional wireless sensor 
nodes. In order to support the transmission of real-time data, different wireless 
modules that provide larger bandwidths (such as those based on IEEE 802.11 
b,g,n) can be considered.
Precise Location and Orientation Information
In visual sensor networks, most of the image processing algorithms require infor-
mation about the locations of the camera nodes as well as information about the 
cameras’ orientations. This information can be obtained through a camera calibra-
tion process, which retrieves information on the cameras’ intrinsic and extrinsic 
parameters (explained in the Section 5.1). Estimation of calibration parameters 
usually requires knowledge of a set of feature point correspondences among the 
images of the cameras. When this is not provided, the cameras can be calibrated 
up to a similarity transformation [10], meaning that only relative coordinates and 
orientations of the cameras with respect to each other can be determined.
Time Synchronization
The information content of an image may become meaningless without proper 
information about the time at which this image was captured. Many processing 
tasks that involve multiple cameras (such as object localization) depend on highly 
synchronized cameras’ snapshots. Time synchronization protocols developed for 
wireless sensor networks [11] can be successfully used for synchronization of vi-
sual sensor networks as well.
Data Storage
The cameras generate large amounts of data over time, which in some cases should 
be stored for later analysis. An example is monitoring of remote areas by a group 
of camera nodes, where the frequent transmission of captured image data to a 
remote sink would quickly exhaust the cameras’ energy resources. Thus, in these 
cases the camera nodes should be equipped with memories of larger capacity in 
order to store the data. To minimize the amount of data that requires storage, 
the camera node should classify the data according to its importance by using 
spatiotemporal analysis of image frames, and decide which data should have pri-
ority to be stored. For example, if an application is interested in information 
© 2011 by Apple Academic Press, Inc.
  

174  Computer Technology and Computer Programming: New Research and Strategies
about some particular object, then the background can be highly compressed and 
stored, or even completely discarded [12].
The stored image data usually becomes less important over time, so it can 
be substituted with newly acquired data. In addition, reducing the redundancy 
in the data collected by cameras with overlapped views can be achieved via local 
communication and processing. This enables the cameras to reduce their needs 
for storage space by keeping only data of unique image regions. Finally, by in-
creasing the available memory, more complex processing tasks can be supported 
on-board, which in return can reduce data transmissions and reduce the space 
needed for storing processed data.
Autonomous Camera Collaboration
Visual sensor networks are envisioned as distributed and autonomous systems, 
where cameras collaborate and, based on exchanged information, reason autono-
mously about the captured event and decide how to proceed. Through collabora-
tion, the cameras relate the events captured in the images, and they enhance their 
understanding of the environment. Similar to wireless sensor networks, visual 
sensor networks should be data-centric, where captured events are described by 
their names and attributes. Communication between cameras should be based on 
some uniform ontology for the description of the event and interpretation of the 
scene dynamics [13].
Table 1. Applications of visual sensor networks.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  175
Applications of Visual Sensor Networks
With the rapid development of visual sensor networks, numerous applications for 
these networks have been envisioned, as illustrated in the Table 1. Here, we men-
tion some of these applications. 
(i)  Surveillance: Surveillance has been the primary application of camera-
based networks for a long time, where the monitoring of large public 
areas (such as airports, subways, etc.) is performed by hundreds or even 
thousands of security cameras. Since cameras usually provide raw video 
streams, acquiring important information from collected image data re-
quires a huge amount of processing and human resources, making it time-
consuming and prone to error. Current efforts in visual sensor networking 
are concentrated toward advancing the existing surveillance technology by 
utilizing intelligent methods for extracting information from image data 
locally on the camera node, thereby reducing the amount of data traffic. 
At the same time, visual sensor networks integrate resource-aware camera 
management policies and wireless networking aspects with surveillance-
specific tasks. Thus, visual sensor networks can be seen as a next generation 
of surveillance systems that are not limited by the absence of infrastruc-
ture, nor do they require large processing resources at one central server. 
These networks are adaptable to the environment dynamics, autonomous, 
and able to respond timely to a user’s requests by providing an immediate 
view from any desired viewpoint or by analyzing and providing informa-
tion from specific, user determined areas. 
(ii)  Environmental monitoring: Visual sensor networks can be used for moni-
toring remote and inaccessible areas over a long period of time. In these 
applications, energy-efficient operations are particularly important in or-
der to prolong monitoring over an extended period of time. Oftentimes 
the cameras are combined with other types of sensors into a heteroge-
neous network, such that the cameras are triggered only when an event is 
detected by other sensors used in the network [14].
(iii)  Smart homes: There are situations (such as patients in hospitals or people 
with disabilities), where a person must be under the constant care of 
others. Visual sensor networks can provide continuous monitoring of 
people, and using smart algorithms the network can provide information 
about the person needing care, such as information about any unusual 
behavior or an emergency situation.
(iv)  Smart meeting rooms: Remote participants in a meeting can enjoy a  
dynamic visual experience using visual and audio sensor network  
technology.
© 2011 by Apple Academic Press, Inc.
  

176  Computer Technology and Computer Programming: New Research and Strategies
(v)  Telepresence systems: Telepresence systems enable a remote user to “visit” 
some location that is monitored by a collection of cameras. For example, 
museums, galleries or exhibition rooms can be covered by a network of 
camera nodes that provide live video streams to a user who wishes to access 
the place remotely (e.g., over the Internet). The system is able to provide 
the user with any current view from any viewing point, and thus it pro-
vides the sense of being physically present at a remote location through 
interaction with the system’s interface [15]. Telereality aims to synthesize 
realistic novel views from images acquired from multiple cameras [16].
Research Directions in Visual Sensor Networks
Visual sensor networks are based on several diverse research fields, including im-
age/vision processing, communication and networking, and distributed and em-
bedded system processing. Thus, the design complexity involves finding the best 
tradeoff between performance and different aspects of these networks. According 
to Hengstler and Aghajan [17] the design of a camera-based network involves 
mapping application requirements to a set of network operation parameters that 
are generally related to several diverse research fields, including network topology, 
sensing, processing, communication, and resource utilization.
Due to its interdisciplinary nature, the research directions in visual sensor 
networks are numerous and diverse. In the following sections we present an 
overview of the ongoing research in several areas vital to visual sensor net-
works: vision processing, wireless networking, camera node hardware archi-
tectures, sensor management, and middleware, as illustrated in Figure 1. The 
survey begins by addressing problems in vision processing related to camera 
calibration. Then, research related to object detection, tracking, and high-
level vision processing is discussed. The survey next provides an overview of 
different networking problems, such as those related to real-time data com-
munication, camera collaboration and route selection. Next, various sensor 
management policies, which aim to provide balance between vision and net-
working tasks, are discussed. Since both vision processing and communica-
tion tasks are limited by the camera node hardware, an overview of the latest 
camera node’s prototype solutions are provided, along with a description of 
network architectures for several visual sensor network testbeds. Finally, an 
overview of visual sensor networks middleware that bridges the gap between 
the application and the low level network structure is provided. In the last 
part of this paper, we provide an overview of some of the many open research 
problems that lie in the intersections of these different research areas.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  177
Figure 1. Several research areas that contribute to the development of visual sensor networks.
Signal Processing Algorithms
Camera Calibration
Obtaining precise information about the cameras’ locations and orientations is 
crucial for many vision processing algorithms in visual sensor networks. The in-
formation on a camera’s location and orientation is obtained through the calibra-
tion process, where this information (presented as the camera’s orientation matrix 
R and translation vector T) is found from the set of feature points that the camera 
sees.
Calibration of cameras can be done at one processing center, which collects 
image feature points from all cameras in the system and, based on that, it es-
timates the calibration parameters for the entire system. However, such a cali-
bration method is expensive in terms of energy and is not scalable, and thus it 
is not suitable for energy-constrained visual sensor networks. Therefore, visual 
sensor networks require distributed energy-efficient algorithms for multicamera  
calibration.
© 2011 by Apple Academic Press, Inc.
  

178  Computer Technology and Computer Programming: New Research and Strategies
The localization algorithms developed for wireless sensor networks cannot be 
used for calibration of the cameras since they do not provide sufficient precision, 
nor do they provide information on the cameras’ orientations. The ad hoc deploy-
ment of camera nodes and the absence of human support after deployment im-
poses the need for autonomous camera calibration algorithms. Since usually there 
is no prior information about the network’s vision graph (a graph that provides 
information about overlapped cameras’ FoVs), communication graph, or about 
the environment, finding correspondences across cameras (presented as a set of 
points in one camera’s image plane that correspond to the points in another cam-
era’s image) is challenging and error prone. Ideally, cameras should have the ability 
to self-calibrate based on their observations from the environment. The first step 
in this process involves finding sets of cameras that image the same scene points. 
Finding correspondences among these cameras may require excessive, energy ex-
pensive inter-camera communication. Thus, the calibration process of distributed 
cameras is additionally constrained by the limited energy resources of the camera 
nodes. Additionally, the finite transmission ranges of the camera nodes can limit 
communication between them.
Therefore, camera calibration in a visual sensor network is challenged by find-
ing the cameras’ precise extrinsic parameters based on existing calibration pro-
cedures taken from computer vision, but considering the communication con-
straints and energy limitations of camera nodes. These calibration methods should 
cope successfully with changes in the communication graph (caused by variable 
channel conditions) and changes in the visual graph (due to the loss of cameras or 
a change in the cameras’ positions and orientations). 
Calibration based on a known object is a common calibration method 
from computer vision, that is, widely adopted in visual sensor networks [18, 
19]. In [18] Barton-Sweeney et al. present a light-wight protocol for cam-
era calibration based on such an approach, where the network contains a 
fraction of wireless nodes equipped with CMOS camera modules, while the 
rest of the nodes use unique modulated LED emissions in order to uniquely 
identify themselves to the cameras. This calibration method requires distance 
information among the cameras, which is obtained through finding epipoles 
(illustrated in Figure 2) among the pairs of cameras. The authors distinguish 
two cases for estimation of the distances between two cameras, the case when 
cameras, in addition of observing the common target (node), can see each 
other, and the case when they cannot see each other. In the first case the dis-
tances between the cameras and the node can be determined up to a scale fac-
tor [20]. In the second case, the epipoles estimation is based on estimation of 
fundamental matrix (based on a minimum of 8 points in the common view), 
which results in noisy data.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  179
Figure 2. Epipoles of a pair of cameras—the points where the line that connects the centers of the cameras 
intersects the cameras’ image planes [10, 18].
Thus, in [18] the authors do not provide fully automatic camera calibration 
methods, but instead they point out the difficulty of finding appropriate network 
configurations that can ease the calibration process.
Funiak et al. [19] provide a distributed method for camera calibration based 
on collaborative tracking of a moving target by multiple cameras. Here, the si-
multaneous localization and tracking (SLAT) problem is analyzed, which refers 
to estimation of both the trajectory of the object and the poses of the cameras. 
The proposed solution to the SLAT problem is based on an approximation of a 
Kalman filter. The restrictions imposed by the communication network are not 
considered in the proposed method.
Devarajan et al. [21] add the underlying communication network model into 
their proposed camera calibration algorithm, thereby analyzing its performances 
with respect to the calibration accuracy as well as communication overhead. Their 
calibration procedure is based on the bundle adjustment method that minimizes 
a nonlinear cost of the camera parameters and a collection of unknown 3D scene 
points projected on matched image correspondences. The distributed calibration 
is performed by clusters of cameras that share the same scene points. The simula-
tion results prove the advantage of using distributed over centralized calibration. 
The average error in the estimated parameters is similar in both cases, but the 
distributed calibration method requires less time since it performs optimization 
over a smaller number of estimating parameters. Additionally, the communica-
tion burden is smaller and more evenly distributed across the camera nodes in the 
case of distributed calibration compared to the centralized approach. However, 
this method includes finding accurate multiimage correspondences, requiring  
© 2011 by Apple Academic Press, Inc.
  

180  Computer Technology and Computer Programming: New Research and Strategies
excessive resources and computational burden, which makes this calibration pro-
tocol less attractive for resource constrained visual sensor networks.
Most of the algorithms for camera calibration in visual sensor networks are 
based on existing calibration methods established in computer vision, and rarely 
are they influenced by the underlying network. Thus, future camera calibration 
algorithms should explore how the outcome of these calibration algorithms can be 
affected by the communication constraints and network topology. In particular, 
it is necessary to find out how multicamera calibration methods can be affected 
by the underlying networking requirements for reliable and energy efficient inter-
camera communication. Such an analysis would provide an insight into the trade-
offs between the desired calibration precision and cost for achieving it.
Also, the calibration methods should be robust to the network’s dynamics; 
for example, considering how the addition of new cameras or the loss of existing 
cameras affect the calibration process. Above all, the calibration algorithms should 
be light-weight, meaning that they should not be based on extensive process-
ing operations. Instead, they should be easily implementable on the hardware 
platforms of existing camera nodes. Due to the ad hoc nature of visual sensor 
networks, future research is required to develop camera calibration algorithms 
that determine precise calibration parameters using a fully automatic approach 
that requires minimal or no a priori knowledge of network distances, network 
geometry or corresponding feature points.
Vision-Based Signal Processing
The appearance of small CMOS image sensors and the development of distrib-
uted wireless sensor networks opens the door to a new era in embedded vision 
processing. The challenge is how to adapt existing vision processing algorithms 
to be used in resource-constrained distributed networks of mostly low-resolution 
cameras. The main constraint comes from the amount of data that can be trans-
mitted through the network. Additionally, most vision processing algorithms are 
developed without regard to any processing limitations. Furthermore, timing 
constraints of existing algorithms need to be carefully reconsidered, as the data 
may travel over multiple hops. Finally, many vision processing algorithms are 
developed for single camera systems, so these algorithms now need to be adapted 
for multicamera distributed systems.
The limited processing capabilities of camera nodes dictate a need for light-
weight vision processing algorithms in visual sensor networks. However, distrib-
uted processing of image data and data fusion from multiple image sources re-
quires more intelligent embedded vision algorithms. As the processing algorithms 
start to become more demanding (such as those that rely on extraction of feature 
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  181
points and feature matching across multiple cameras’ views) the processing capa-
bilities can become a bottleneck. Considering the hierarchical model for vision 
processing provided in [17], here we describe the main vision processing tasks for 
visual sensor networks.
Object Detection and Occupancy Reasoning
The initial phase of visual data processing usually involves object detection. Ob-
ject detection may trigger a camera’s processing activity and data communication. 
Object detection is mostly based on light-weight background substraction algo-
rithms and presents the first step toward collective reasoning by the camera nodes 
about the objects that occupy the monitored space.
Many applications of visual sensor networks require reasoning about the pres-
ence of objects in the scene. In occupancy reasoning, the visual sensor network is 
not interested in extracting an individual object’s features, but instead extracting 
the state of the scene (such as information about the presence and quantity of 
objects in the monitored scene) based on light-weight image processing algo-
rithms. An example of such occupancy reasoning in visual sensor networks is the 
estimation of the number of people in a crowded scene, as discussed in [22]. Here 
the estimates are obtained using a planar projection of the scene’s visual hull, as 
illustrated in Figure 3. Since the objects may be occluded, the exact number of 
objects cannot be determined, but instead lower and upper bounds on the num-
ber of objects in each polygon are tracked. The estimated bounds on the number 
of objects are updated over time using a history tree, so that the lower and upper 
bounds converge toward the exact number of objects in each polygon.
Figure 3. Finding the polygons that contain people based on a projection of the person’ silhouettes on the planar 
scene [22].
© 2011 by Apple Academic Press, Inc.
  

182  Computer Technology and Computer Programming: New Research and Strategies
Determining good camera-network deployments and the number of camera 
nodes to use is also addressed in recent work on occupancy estimation problems. 
For example, in [23] Yang et al. study a model for managing (tasking) a set of 
cameras that collectively reason about the occupancy of the monitored area. Their 
goal is to provide an upper bound on the number of cameras needed to reason 
about the occupancy for a given accuracy. This task is performed by minimiz-
ing the area potentially occupied by the moving objects. Using the Monte Carlo 
method, the authors in [23] find the number of cameras necessary to provide a vi-
sual hull area for one object. However, in the case of multiple objects in the scene, 
the visual hull area does not converge to the actual area covered by the objects, due 
to occlusions. Thus, the authors compare several heuristic approaches (uniform, 
greedy, clustering, and optimal) for finding a subset of the cameras that minimize 
the visual hull area for the scenario with multiple objects in the scene.
Since detection of objects on the scene is usually the first step in image analy-
sis, it is important to minimize the chances of objects` fault detection. Thus, reli-
ability and light-weight operations will continue to be the main concerns of image 
processing algorithms for object detection and occupancy reasoning.
Object Tracking
Object tracking is a common task for many applications of visual sensor net-
works. Object tracking is a challenging task since it is computationally intensive 
and it requires real-time data processing. The basic methods for target tracking 
include temporal differencing and template correlation matching [24]. Temporal 
differencing requires finding the regions in frames separated in time that have 
been changed, and thus it fails if the object stops moving or if it gets occluded. 
On the other hand, template correlation matching aims to find the region of an 
image that best correlates to an image template. This method is not robust to 
changes in the object’s appearance, such as object size, orientation, or even light 
conditions. Sophisticated tracking algorithms, which rely on motion parameter 
estimation and probability estimates (such as tracking algorithms based on Kal-
man filtering [25] or particle filtering [26]) are suitable for smart camera networks 
with advanced processing capabilities.
The availability of multiple views in visual sensor networks improves tracking 
reliability, but with the price of an increased communication overhead among the 
cameras. Therefore, in resource-constrained visual sensor networks it is important 
to use lightweight processing algorithms and to minimize the data load that has 
to be communicated among the cameras. Lau et al. [27] provide an example of 
a simple algorithm for tracking multiple targets based on hue histograms. After 
background substraction and segmentation, the histogram of detected blobs in 
the scene is found and then compared with the histograms found for previous 
frames in order to track the objects.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  183
Ko and Berry [28] investigate a distributed scheme for target tracking in a 
multicamera environment. Their collaborative strategy is based on establishing 
information links between the cameras that detect the target (initiators) and their 
neighboring cameras that can share information about the tracked target. The 
cameras extract several target features (edge histogram, UV color histogram, and 
local position of target) which are correlated across the nodes in order to decide 
whether information links should be established between the nodes. Such an ap-
proach improves the accuracy of the target detection and significantly reduces the 
communication load.
The success of the proposed tracking algorithms can be jeopardized in the case 
when the tracked objects are occluded. Object occlusion, which happens when a 
camera looses sight of an object due to obstruction by another object, is an un-
avoidable problem in visual sensor networks. Although in most cases the positions 
of moving occluders cannot be predicted, still it is expected that a multicamera 
system can handle the occlusion problem more easily due to providing multiple 
object views. This problem is discussed in [29], where the authors examine the 
dependance of single object tracking on prior information about the movement 
of the tracked object and about static occluders. The real challenge in visual sensor 
networks however, is to avoid losing the tracked object due to occlusions in the 
situation when not all cameras are available for tracking at the same time. Thus, 
future research should be directed toward examining the best sensor management 
policies for selecting camera nodes that will enable multiple target views, thereby 
reducing the chances of occlusion while using the minimum number of cameras.
Advanced Signal Processing in VSNs
Many novel applications of visual sensor networks are based on advanced vision 
processing that provides a thorough analysis of the objects’ appearances and be-
haviors, thereby providing a better understanding of the relationships among the 
objects and situation awareness to the user. In these applications the objective is 
to provide the automated image understanding by developing efficient computa-
tional methods based on principled fundamental issues in automated image un-
derstanding. These issues include providing and understanding the performance 
of methods for object recognition, classification, activity recognition, context un-
derstanding, background modeling, and scene analysis.
In such an application a visual sensor network can be used to track human 
movements but also to interpret these movements in order to recognize semanti-
cally meaningful gestures. Human gesture analysis and behavior recognition have 
gained increasing interest in the research community and are used in a number of 
applications such as surveillance, video conferencing, smart homes, and assisted 
living. Behavior analysis applications require collaboration among the cameras, 
© 2011 by Apple Academic Press, Inc.
  

184  Computer Technology and Computer Programming: New Research and Strategies
which exchange preprocessed, high level descriptions of the observed scene, rather 
than the raw image information. In order to reduce the amount of information 
exchanged between the cameras, research is directed toward finding an effective 
way of describing the scene and providing the semantic meaning of the extracted 
data (features). An example of such research is provided in [45], where Teixeira et 
al. describe a camera-based network that uses symbolic information in order to 
summarize the motion activity of people. The extracted basic functions of human 
activity are analyzed using a sensing grammar, which provides the probability like-
lihood of each outcome. The sequences of basic features of human activity are fed 
into a inference model, that is, used to reason about the macroscopic behaviors of 
people—the behavior in some area over a long period of time.
Human behavior interpretation and gesture analysis often use explicit shape 
models that provide a priori knowledge of the human body in 3D. Oftentimes, 
these models assume a certain type of body movement, which eases the gesture 
interpretation problem in the case of body self-occlusion. Recent work of Aghajan 
and Wu [46] provides a framework for human behavior interpretation based on 
a 3D human model for estimation of a user’s posture from multiple cameras’ 
views. This model is reconstructed from previous model instances and current 
multiple camera views, and it contains information on geometric body configura-
tion, color/texture of body parts, and motion information. After fitting ellipses to 
corresponding body parts (segments), human posture is estimated by minimizing 
the distance between the posture and the ellipses.
Another approach in designing context-aware visual based networks involves 
using multimodal information for the analysis and interpretation of the objects’ 
dynamics. In addition to low-power camera nodes, such systems may contain 
other types of sensors such as audio, vibration, thermal, and PIR. By fusing multi-
modal information from various nodes, such a network can provide better models 
for understanding an object’s behavior and group interactions.
The aforementioned vision processing tasks require extracting features about 
an event, which in the case of energy and memory constrained camera nodes can 
be hard or even impossible to achieve, especially in real-time. Thus, although it is 
desirable to have high-resolution data features, costly feature extractions actually 
should be limited. This implies the need for finding optimal ways to determine 
when feature extraction tasks can be performed and when they should be skipped 
or left to other active cameras, without degrading overall performance. Also, most 
of the current work still use a centralized approach for data acquisition and fu-
sion. Thus, future research should be directed toward migrating the process of 
decision making to the sensors, and toward dynamically finding the best camera 
node that can serve as a fusion center to combine extracted information from all 
active camera nodes.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  185
Communication Protocols
Communication protocols for the “traditional” wireless sensor networks are mostly 
focused on supporting requirements for energy-efficiency in the low data rate com-
munications. On the other hand, in addition to energy-efficiency, visual sensor 
networks are constrained with much tighter quality of service (QoS) requirements 
compared to “traditional” wireless sensor networks. Some of the most important 
QoS requirements of visual sensor networks, such as requirements for low data 
delay and data reliability, are not the primary concerns in the design of communica-
tion protocols for “traditional” wireless sensor networks. Additionally, the sensing 
characteristics of image sensors can also affect the design of communication pro-
tocols for visual sensor networks. For example, in [30], we found that the perfor-
mance of a coverage-aware routing protocol that was initially developed for wireless 
sensor networks can change when such a protocol is applied to a visual sensor 
network. This change in protocol behavior is caused by the fact that distant out-of-
communication-range cameras can still observe (cover) a common part of the scene 
(illustrated in Figure 4), which can influence how this protocol selects routing paths 
in the network. Thus, the communication protocols developed for traditional wire-
less sensor networks cannot be simply reused in visual sensor networks.
Figure 4. Cameras C1 and C4 observe the same part of the scene, but are not in communication range of each 
other. Thus, data routing is performed over other camera nodes [30].
An event captured by a visual sensor network can trigger the injection of large 
amounts of data into the network from multiple sources. Each camera can inject 
variable amounts of data into the network, depending on the data processing 
(image processing algorithm, followed by the data compression and error correc-
tion). The end-to-end data transmissions should satisfy the delay guarantees, thus 
requiring stable data routes. At the same time, the choice of routing paths should 
be performed such that the available network resources (e.g., energy and channel 
bandwidth) are efficiently balanced across the network.
© 2011 by Apple Academic Press, Inc.
  

186  Computer Technology and Computer Programming: New Research and Strategies
Beside the energy efficiency and strict QoS constraints, the used data communi-
cation model can be influenced by the required quality of the image data provided 
by the visual sensor network. For example, in [47], Lecuire et al. use an adaptive 
energy-conserving data transmission model, where nodes, based on their remain-
ing energies, decide whether they will forward packets of a certain priority. The 
packet priority is defined either based on the resolution level (subband) of the im-
age’s wavelet transformation or based on the magnitude of the wavelet coefficients. 
In order to avoid situations where the data packets are dropped near the data sink, 
this transmission scheme decreases the probability of packet discarding as the packet 
approaches the sink. This transmission scheme offers a trade-off in consumed en-
ergy versus reconstructed image quality, and it demonstrates the advantage of the 
magnitude-based prioritization scheme over the resolution level scheme.
Another important aspect in the design of communication protocols for visual 
sensor networks includes the support for camera collaboration on a specific task. 
Therefore, the reliable transmission of delay constrained data obtained through 
collaboration of a number of camera nodes is the main focus of the networking 
protocols for visual sensor networks. Thus, we further discuss the influence of 
requirements for reliability, latency, and collaborative processing to the design of 
data communication protocols for visual sensor networks. Table 2 provides an 
overview of the networking protocols that are discussed throughout this section 
with respect to reliability, latency, and collaborative data routing. 
Table 2. Representatives of networking protocols used in visual sensor networks.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  187
Reliability
Reliable data transport is one of the main QoS requirements of visual sensor 
networks. In wireless sensor networks, the transport layer of the traditional pro-
tocol stack is not fully developed, since the traditional functions of this layer 
that should provide reliable data transport, such as congestion control, are not a 
primary concern in low data, low duty-cycle wireless sensor networks. However, 
the bursty and bulky data traffic in visual sensor networks imposes the need for 
establishing mechanisms that provide reliable data communication over the unre-
liable channels across the network.
The standard networking protocols designed to offer reliable data transport are 
not suitable for visual sensor networks. The commonly used transport protocol 
TCP cannot be simply reused in wireless networks, since it cannot distinguish 
between data losses due to network congestion and due to poor wireless channel 
conditions. In wireless sensor networks, providing reliability oftentimes assumes 
data retransmissions, which introduce intolerable delays for visual sensor net-
works. For example, protocols such as Pump Slowly Fetch Quickly (PSFQ) [48] 
enable the fast recovery of lost data from the local neighborhood using selective 
NACKs, however, it assumes that the data is lost only due to the channel condi-
tions, and not due to data congestion, basically assuming transmissions of small 
data amounts through the network.
Data routing over multiple paths is oftentimes considered as a way to reduce 
the correlations among the packet losses and to spread the energy consumption 
more evenly among the cameras. Since data retransmissions increase latency in 
the network, Wu and Abouzeid [31] propose a transport scheme that combines 
multipath diversity and Reed-Solomon error correction in order to increase data 
reliability. In their proposed model, the data source transmits several copies of the 
same data over multiple paths, which converge to the cluster head. Each cluster 
head compares the received data copies, and it retransmits the error-corrected ver-
sion of the data over multiple paths toward the next cluster head. Since the error 
correction is performed at the cluster heads, this transmission scheme improves 
the quality of the received image data at the sink (measured by PSNR). Another 
protocol that aims to increase the reliability of transmitted data over multiple 
paths is presented by Chen et al. [32]. Here, multiple routing paths are estab-
lished based on the proposed directional geographical routing (DGR) algorithm 
that, combined with FEC coding, provides more reliable data transmission com-
pared to single-path routing, and it achieves better performance in overall delay 
and quality of video data at the sink.
Visual sensor networks can experience significant loses of data due to network 
congestion. As a way to control data congestion in wireless multimedia networks, 
© 2011 by Apple Academic Press, Inc.
  

188  Computer Technology and Computer Programming: New Research and Strategies
Maimour et al. [33] explore several strategies for load repartition on multiple 
source-sink paths. They compare simple strategies that uniformly distribute the 
traffic from the data source on all available paths with more complex strategies 
that use explicit notifications from the congested nodes in order to balance traffic 
on available paths, while keeping the sending rate unchanged.
Congestion control is a dominant problem in the design of reliable protocols 
for visual sensor networks. Considering that multimedia data can tolerate a cer-
tain degree of loss [49], congestion control mechanisms should provide a trade-off 
between the quality of the data received from the cameras and the energy expense 
for transmitting this data. Having concurrent data flows increases the data reli-
ability, but it also greatly increases the transmission cost. Thus, further evaluation 
is needed to clarify the trade-offs between data reliability and data redundancy 
in multipath routing schemes for visual sensor networks. Furthermore, most of 
the described data transmission schemes neglect the requirements for low delays. 
Thus, we further discuss this QoS requirement of visual sensor networks in the 
next subsection.
Delay Sensitive Communication Protocols
Real-time data delivery is a common requirement for many applications of visual 
sensor networks. Data delays can happen in different layers of the network pro-
tocol stack, by unsynchronized interaction between different layers of stack, and 
delay can be further increased by the wireless channel variability. Thus, the design 
of different communication layers of the network protocol stack should be care-
fully considered in order to improve the data latency in the network.
The rising needs of delay-sensitive applications in wireless sensor networks 
have caused the appearance of a number of energy-efficient delay-aware MAC 
protocols. The main idea behind these protocols is to reduce the sleep delays of 
sensor nodes operating in duty cycles, and to adapt the nodes’ duty cycles ac-
cording the network traffic. Since there is already a comprehensive survey on the 
design of MAC protocols for multimedia applications in wireless sensor networks 
[2], we will not cover these protocols in detail, but instead we will mention some 
of the most representative delay-aware MAC protocols.
The SMAC [50] protocol developed by Ye et al. was among the first MAC 
protocols that explored adaptive listening in order to reduce multihop latency 
due to periodic sleep. (In adaptive listening, a node that overhears its neighbors 
transmission wakes up at the end of that transmission, so that it can receive a 
message, if it is the next hop for its neighbor transmission.) In the DSMAC [34] 
protocol, Lin et al. further improve the latency problem of SMAC by allowing the 
sensor nodes to dynamically change their sleeping intervals in order to adjust to 
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  189
the current traffic conditions. In this way, the latency is reduced in networks with 
high traffic load, while still supporting the energy efficiency when network traffic 
is low. In the DMAC [35] protocol, Lu et al. further explore the adaptive listen-
ing mechanism, pointing out the data forwarding interruption problem, which 
happens due to the limited overhearing range of the nodes, so that a node can 
be out of range for both sender and receiver and thus unaware of the ongoing 
data transmission. Such nodes go to sleep, which causes the interruption in data 
forwarding. The DMAC protocol eliminates the sleeping delays by providing the 
same schedule (receive-transmit-sleep cycles) to the nodes with the same depth 
in the data gathering tree. These protocols are contention-based, so they provide 
only best effort service. Other authors favor scheduling-based MAC protocols, as 
a way to avoid data delays and data loses due to channel contention and packet 
collisions. One such MAC protocol is presented by Ceken [36], where sensor 
nodes follow a TDMA schedule for data transmissions, but the delay-critical sen-
sor nodes can request extra time slots from the central node in the case when their 
queues exceed a certain threshold.
Finding routing strategies that enable data delivery within a certain time delay 
is an extremely hard problem. He et al. developed the SPEED protocol [37] for 
real-time communication in multihop wireless sensor networks. Since the end-
to-end delay in a multihop network depends on the distance a packet travels, 
SPEED routes packets according to the packet’s maximum delivery speed, defined 
as the rate at which the packet should travel along a straight line to the destina-
tion. Thus, SPEED determines the transmission delay of the packet considering 
its end-to-end distance and its delivery speed. However, such a routing scheme 
is not scalable, as the maximum delivery speed cannot guarantee that the packet 
will arrive before its delay deadline in larger networks. This issue is addressed 
in [38], where Felemban et al. propose MMSPEED, where nodes can forward 
packets with a higher (adjustable) speed over the multiple paths if it appears that 
the packet cannot meet its delay deadline. However, underlying network manage-
ment policies (discussed in Section 7) that regulate nodes’ activities have a large 
impact on the packets’ delivery latency. Thus, the data latency problem in visual 
sensor networks should be further analyzed considering the nodes’ resource-aware 
scheduling policies.
Such an approach is taken in [39], where Lu and Krishnamachari look into 
the joint problem of finding the routes and nodes activity schedules that pro-
vide the minimum average latency for current active data flows. It is assumed an 
FDMA channel model, which enables simultaneous packet transmissions from 
neighboring nodes with minimized interference. The proposed solution finds a 
number of disjoint paths over the delay graph constructed by considering the 
finite delays at each node between the reception and retransmission of a packet in 
preassigned time slots.
© 2011 by Apple Academic Press, Inc.
  

190  Computer Technology and Computer Programming: New Research and Strategies
The data delays at different layers of the network protocol stack may be caused 
by various factors (channel contention, packet retransmissions, long packet 
queues, nodes’ failure, and network congestion). The cross-layer approaches that 
consider close interactions between different layers of the protocol stack enable 
the design of frameworks that support delay-sensitive applications of visual sensor 
networks.
Andreopoulos et al. [40] propose a cross-layer optimization algorithm that 
aims to find several parameters that maximize the network’s capacity-distortion 
utility function, while considering delay-constrained streaming in a wireless net-
work. The proposed end-to-end optimization algorithm chooses the optimum 
routing path, the maximum number of retransmissions at the MAC layer as well 
as the best modulation scheme at the physical layer (considering thereby the 
available channel bandwidth and data rates). The proposed optimization model 
assumes the existence of predetermined time reservations per link with conten-
tion free access to the wireless channel. Van der Schaar and Turaga [41] propose 
cross-layer optimized packetization and retransmission strategies constrained by 
delay requirements for video delivery in wireless networks. Similarly to [40, 41] 
is based on rate-distortion optimization algorithms, and in both works the en-
ergy constrained resources of nodes in the network are not considered. Such a 
cross-layer resource allocation problem is analyzed in [42], where Wang et al. 
discuss the adaptive image transmission scheme that optimizes image quality over 
a multihop network while considering multihop path conditions such as delay 
constraints and the probability of delay violation. The design guideline of this 
work lies in the fact that the information about the position of coefficients in a 
wavelet transformed image have higher importance and thus higher protection 
levels than the information about the coefficients’ magnitudes. Optimizing the 
image quality over the multihop network involves finding the optimal source 
coding rates, which can be translated into the maximum source traffic rate with 
QoS delay bound.
Cross-layer optimization of the protocol stack enables visual sensor networks 
to meet various QoS constraints of visual data transmissions, including data com-
munication within delay bounds. This cross-layer optimization needs also to 
include different strategies for intra-camera collaborations, which will lead to a 
reduction of the total data transmitted in the network. We discuss this problem 
further in the next subsection.
Collaborative Image Data Routing
In current communication protocols, the camera nodes compete for the network 
resources, rather than collaborate in order to effectively exploit the available network 
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  191
resources. Thus, the design of communication protocols for visual sensor net-
works needs to be fundamentally changed, in order to support exchanges of infor-
mation regarding camera nodes’ information contents, which will help to reduce 
the communication of redundant data and to distribute resources equally among 
the camera nodes.
Collaboration-based communication should be established between cameras 
with overlapped FoVs that, based on the spatial-temporal correlation between 
their images, collectively reason about the events and thus reduce the amount 
of data and control overhead messages routed through the network [43]. Such 
a collaboration-based approach for communication is oftentimes used in object 
tracking applications, where camera nodes are organized into clusters, as for ex-
ample shown in [44]. Here, the formation of multiple clusters is triggered by the 
detection of objects. The cluster head node tracks the object, and the cluster head 
role is assigned to another cluster member once the object is out of the viewing 
field of the current cluster head. However, in visual sensor networks collaborative 
clusters can be formed by cameras that have overlapped FoVs, although they can 
be distant from each other, which can raise questions about the network con-
nectivity. In wireless sensor networks, two nodes are connected if they are able to 
exchange RF signals. Zhang and Hou [51] prove that if the communication range 
is at least twice the sensing range, then the complete coverage of a convex area 
implies that the nodes are connected. However, relation between connectivity and 
coverage in visual sensor networks needs further investigation, considering the 
fact that 3D coverage needs to be satisfied and that the area of a camera’s coverage 
usually does not overlap with the transmission range of the camera node.
Finally, supporting data priority has a large effect on the application QoS of 
visual sensor networks. Camera nodes that detect an event of interest should be 
given higher priority for data transmissions. In collaborative data processing, cam-
era nodes should collectively decide on data priorities from cameras that provide 
the most relevant information regarding the captured event. Therefore, protocols 
that provide differentiated service to support prioritized data flows are needed and 
must be investigated.
Sensor Management
In redundantly deployed visual sensor networks a subset of cameras can perform 
continuous monitoring and provide information with a desired quality. This sub-
set of active cameras can be changed over time, which enables balancing of the 
cameras’ energy consumption, while spreading the monitoring task among the 
cameras. In such a scenario the decision about the camera nodes’ activity and the 
duration of their activity is based on sensor management policies. Sensor management 
© 2011 by Apple Academic Press, Inc.
  

192  Computer Technology and Computer Programming: New Research and Strategies
policies define the selection and scheduling (that determines the activity dura-
tion) of the camera nodes’ activity in such a way that the visual information from 
selected cameras satisfies the application-specified requirements while the use of 
camera resources is minimized. Various quality metrics are used in the evalua-
tion of sensor management policies, such as the energy-efficiency of the selection 
method or the quality of the gathered image data from the selected cameras. In 
addition, camera management policies are directed by the application; for exam-
ple, target tracking usually requires selection of cameras that cover only a part of 
the scene that contains the non-occluded object, while monitoring of large areas 
requires the selection of cameras with the largest combined FoV.
While energy-efficient organization of camera nodes is oftentimes addressed 
by camera management policies, the quality of the data produced by the network 
is the main concern of the application. Table 3 compares several camera manage-
ment policies considering energy efficiency and bandwidth allocation as two qual-
ity metrics for camera selection in two common applications—target tracking and 
monitoring of large scenes. 
Table 3. Comparison of sensor management policies.
Monitoring of large areas (such as parking lots, public areas, large stores, etc.) 
requires complete coverage of the area at every point in time. Such an application 
is analyzed in [52], where Dagher et al. provide an optimal strategy for allocating 
parts of the monitored region to the cameras while maximizing the battery life-
time of the camera nodes. The optimal fractions of regions covered by every cam-
era are found in a centralized way at the base station. The cameras use JPEG2000 
to encode the allocated region such that the cost per bit transmission is reduced 
according to the fraction received from the base station. However, this sensor 
management policy only considers the coverage of a 2D plane, without occlusions 
and perspective effects, which makes it harder to use in a real situation.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  193
Oftentimes the quality of a reconstructed view from a set of selected cameras 
is used as a criterion for the evaluation of camera selection policies. Park et al. [53] 
use distributed look-up tables to rank the cameras according to how well they im-
age a specific location, and based on this they choose the best candidates that pro-
vide images of the desired location. Their selection criterion is based on the fact 
that the error in the captured image increases as the object gets further away from 
the center of the viewing frustum. Thus, they divide the frustum of each camera 
into smaller unit volumes (subfrustums). Then, based on the Euclidian distance 
of each 3D point to the centers of subfrustums that contain this 3D point, they 
sort the cameras and find the most favorable camera that contains this point in 
its field of view. The look-up table entries for each 3D location are propagated 
through the network in order to build a sorted list of favorable cameras. Thus, 
camera selection is based exclusively on the quality of the image data provided by 
the selected cameras, while the resource constraints are not considered.
A similar problem of finding the best camera candidates is investigated in 
[54]. In this work, we propose several cost metrics for the selection of a set of cam-
era nodes that provide images used for reconstructing a view from a user-specified 
view point. Two types of metrics are considered: coverage-aware cost metrics and 
quality-aware cost metrics. The coverage-aware cost metrics consider the remain-
ing energy of the camera nodes and the coverage of the indoor space, and favor 
the selection of the cameras with higher remaining energy and more redundant 
coverage. The quality-aware cost metrics favor the selection of the cameras that 
provide images from a similar view point as the user’s view point. Thus, these 
camera selection methods provide a trade-off between network lifetime and the 
quality of the reconstructed images.
In order to reduce the energy consumption of cameras Zamora and Mar-
culescu [55] explore distributed power management of camera nodes based on 
coordinated node wake-ups. The proposed policy assumes that each camera node 
is awake for a certain period of time, after which the camera node decides whether 
it should enter the low-power state based on the timeout statuses of its neighbor-
ing nodes. Alternatively, camera nodes can decide whether to enter the low-power 
state based on voting from other neighboring cameras.
Selection of the best cameras for target tracking has been discussed often [25, 
29]. In [25] Pahalawatta et al. present a camera selection method for target track-
ing applications used in energy-constrained visual sensor networks. The camera 
nodes are selected by minimizing an information utility function (obtained as the 
uncertainty of the estimated posterior distribution of a target) subject to energy 
constraints. However, the information obtained from the selected cameras can be 
lost in the case of object occlusions. This occlusion problem is further discussed in 
[29], where Ercan et al. propose a method for camera selection in the case when 
© 2011 by Apple Academic Press, Inc.
  

194  Computer Technology and Computer Programming: New Research and Strategies
the tracked object becomes occluded by static or moving occluders. Finding the 
best camera set for object tracking involves minimizing the MSE of the object po-
sition’s estimates. Such a greedy heuristic for camera selection shows results close 
to optimal and outperforms naive heuristics, such as selection of the closest set 
of cameras to the target, or uniformly spaced cameras. The authors here assume 
that some information about the scene is known in advance, such as the positions 
of static occluders, and the object and dynamic occluders’ prior probabilities for 
location estimates.
Although a large volume of data is transmitted in visual sensor networks, 
none of the aforementioned works consider channel bandwidth utilization. This 
problem is investigated in [56] where Yang and Nahrstedt provide a bandwidth 
management framework which, based on different camera selection policies and 
video content, dynamically coordinates the bandwidth requirements among the 
selected cameras’ flows. The bandwidth estimation is provided at the MAC layer 
of each camera node, and this information is sent to a centralized bandwidth 
coordinator that allocates the bandwidth to the selected cameras. The centralized 
bandwidth allocator guarantees that each camera has the minimum bandwidth 
required, but the flexibility of distributed bandwidth allocation is lost.
In visual sensor networks, sensor management policies are needed to assure 
balance between the oftentimes opposite requirements imposed by the wireless 
networking and vision processing tasks. While reducing energy consumption 
by limiting data transmissions is the primary challenge of energy-constrained 
visual sensor networks, the quality of the image data and application QoS 
improve as the network provides more data. In such an environment, the 
optimization methods for sensor management developed for wireless sensor 
networks are oftentimes hard to directly apply to visual sensor networks. Such 
sensor management policies usually do not consider the event-driven nature 
of visual sensor networks, nor do they consider the unpredictability of data 
traffic caused by an event detection.
Thus, more research is needed to further explore sensor management for 
visual sensor networks. Since sensor management policies depend on the un-
derlying networking policies and vision processing, future research lies in the 
intersection of finding the best trade-offs between these two aspects of vi-
sual sensor networks. Additional work is needed to compare the performance 
of different camera node scheduling sensor policies, including asynchronous 
(where every camera follows its own on-off schedule) and synchronous (where 
cameras are divided into different sets, so that in each moment one set of 
cameras is active) policies. From an application perspective, it would be inter-
esting to explore sensor management policies for supporting multiple applica-
tions utilizing a single visual sensor network.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  195
Hardware Architectures for Visual Sensor 
Networks
A typical wireless sensor node has an 8/16-bit microcontroller, limited memory, 
and it uses short active periods during which it processes and communicates col-
lected data. Limiting a node’s “idle” periods (long periods during which a node 
listens to the channel) and avoiding power-hungry transmissions of huge amounts 
of data keep the node’s energy consumption sufficiently small, so that it can op-
erate for months or even for years. It is desirable to keep the same low-power 
features in the design of camera nodes, although in this case more energy will be 
needed for data capture, processing and transmission. Here, we provide an over-
view of works that analyze energy consumption in visual sensor networks, as well 
as an overview of current visual sensor node hardware architectures and testbeds.
Energy Consumption
The lifetime of a battery-operated camera node is limited by its energy consump-
tion, which is determined by the hardware and working mode of the camera node. 
In order to collect data about energy consumption and to verify camera node de-
signs, a number of camera node prototypes have been recently built and tested. 
Energy consumption has been analyzed on camera node prototypes built using a 
wide range of imagers, starting from very low-power, low-resolution camera nodes 
[57, 58], to web cameras [59, 60] to advanced, high-resolution cameras.
An estimation of the camera node’s lifetime can be done based on its power 
consumption in different tasks, such as image capture, processing, and transmis-
sion. Such an analysis is provided in [60], where Margi et al. present results ob-
tained for the power consumption of a visual sensor network testbed consisting of 
camera nodes built using a Crossbow Stargate [61] board and a Logitech webcam. 
Each task has an associated power consumption cost and execution time. Several 
interesting results are reported in [60]. For example, in their setup the time to 
acquire and process an image takes 2.5 times longer than the time to transmit 
the compressed image. The energy cost of analyzing the image (via a foreground 
detection algorithm) and compression of a portion of the image (when an event is 
detected) is about the same as compression of the full image. Also, they found that 
transitioning between states can be expensive in terms of energy and time.
In [62] Jung et al. analyze how different operation modes, such as duty-cycle 
mode and event-driven mode, affect the lifetime of a camera node. The power 
consumption specifications of the camera node (which consisted of an iMote2 
[63] wireless node coupled with an Omnivision OV7649 camera) consider the 
power consumption profiles of the main components (CPU, radio, and camera) 
© 2011 by Apple Academic Press, Inc.
  

196  Computer Technology and Computer Programming: New Research and Strategies
in different operational modes (sleep, idle, and working). The generic power con-
sumption model provided in [62] can be used for the comparison of different 
hardware platforms in order to determine the most appropriate hardware solu-
tion/working mode for the particular application.
Considering the fact that data transmission is the most expensive operation 
in terms of energy, Ferrigno et al. [64] aim to find the most suitable compression 
method that provides the best compromise between energy consumption and the 
quality of the obtained image. Their analysis is drawn from the results of measure-
ments of the current consumption for each state: standby, sensing, processing, 
connection, and communication. The authors compare several lossy compres-
sion methods, including JPEG, JPEG2000, Set Partitioning in Hierarchical Trees 
(SPIHT), Subsampling (SS) and Discrete Cosine Transform (DCT). The choice 
of the most suitable compression technique was between SPIHT, which gives the 
best compression rate and SS, which requires the smallest execution time, has the 
simplest implementation and assures the best compromise between the compres-
sion rate and processing time.
Analysis of the energy consumption of a camera node when performing dif-
ferent tasks [60] and in different working modes [62] is essential for developing 
effective resource management policies. Understanding the trade-offs between 
data processing and data communication in terms of energy cost, as analyzed in 
[64], helps in choosing the best vision processing techniques that provide data of a 
certain quality while the lifetime of the camera node is prolonged. Analysis of the 
energy consumption profile helps the selection of hardware components for the 
specific application. However, the variety of hardware, processing algorithms and 
networking protocols used in various testbeds makes the comparison of existing 
camera nodes difficult. Today, there is no systematic overview and comparison of 
different visual sensor network testbeds from the energy consumption perspec-
tive. Therefore, further research should focus on comparing different camera node 
architectures and visual sensor network testbeds, in order to explore the energy-
performance trade-offs. 
Visual Sensor Node Platforms
Today, CMOS image sensors are commonly used in many devices, such as cell 
phones and PDAs. We can expect widespread use of image sensors in wireless 
sensor networks only if such networks still preserve the low power consumption 
profile. Because of energy and bandwidth constraints, low-resolution image sen-
sors are actually preferable in many applications of visual sensor networks. Table 4 
compares several prototypes of visual sensor nodes with respect to the main hard-
ware components such as processors, memory, image sensor, and RF transceiver.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  197
Table 4. Comparison of different visual sensor node architectures.
Compared with processors used for wireless sensor nodes, the processing units 
used in visual sensor node architectures are usually more powerful, with 32-bit 
architectures and higher processing speed that enables faster data processing. In 
some architectures [58, 66] a second processor is used for additional processing 
and control. Since most procesors have small internal memories, additional exter-
nal Flash memories are used for frame buffering and permanent data storage. Im-
age sensors also tends to provide small format images (CIF format and smaller). 
However, some implementations [5, 66] use two image sensors to provide bin-
ocular vision. For example, the Mesheye architecture [5] uses two low resolution 
image sensors (kilopixels) and one high resolution (VGA) image sensor located 
in between the two low resolution image sensors. With one kilopixel imager the 
camera node can detect the presence of an object in its FoV. Stereo vision from 
two kilopixel imagers enables estimation of object position and size, thereby pro-
viding the region of interest. Finally, a high resolution image of the region of 
interest can be obtained using the VGA camera.
It is evident that all camera node prototypes shown in Table 4 use IEEE 
802.15.4 RF transceivers, which is commonly used in wireless sensor nodes as 
well. The Chipcon CC2420 radio supports a maximum of 250Kb/s data rate, 
although the achievable data rate is often much smaller due to packet overhead 
and the transient states of the transciever. Since such insufficient data rates can be 
a bottleneck for vision-based applications, future implementations should con-
sider other radio standards with higher data rates, at the cost of increased energy 
dissipation. Also, by providing a simpler programming interface, the widespread 
use of visual sensor nodes can be expected. Such an interface is described in [57] 
© 2011 by Apple Academic Press, Inc.
  

198  Computer Technology and Computer Programming: New Research and Strategies
where Hengstler and Aghajan present a framework called Wireless Image Sensor 
Network Application Platform (WiSNAP) for research and development of ap-
plications in wireless visual networks. This Matlab-based application development 
platform contains APIs that provide a user with interfaces to the image sensor and 
the wireless node. The WiSNAP framework enables simulations of this visual sen-
sor node platform in different applications.
VSN Architectures—Testbed Research
Testbed implementations of visual sensor networks are an important final step in 
evaluating processing algorithms and communication protocols. Several architec-
tures for visual sensor networks can be found in the literature.
Among the first reported video-based sensor network systems is Panoptes [59], 
which consisted of video sensors built from COTS components and software 
that supports different functions including image capture, compression, filtering, 
video buffering, and data streaming. Panoptes supports a priority-based streaming 
mechanism, where the incoming video data is mapped to a number of priorities 
defined by the surveillance application. Panoptes provides storage and retrieval of 
video data from sensors, it handles queries from users, and it controls the stream-
ing of events of interest to the user. However, the system does not have real-time 
support—a user can only select to see past events already stored in the system. 
Also, there is no interaction between the cameras.
In [68], Kulkarni et al. present SensEye—a heterogeneous multitier camera 
sensor network consisting of different nodes and cameras in each tier. The Sens-
Eye system is designed for a surveillance application, thus supporting tasks such as 
object detection, recognition, and tracking. These tasks are performed across three 
network tiers. The lowest layer, which supports object detection and localization, 
is comprised of Mote nodes [69], and low-fidelity CMUCam camera sensors. The 
second tier contains Stargate nodes [61] equipped with web cameras, which are 
woken up on demand by the camera nodes from the lower tier to continue the 
object recognition task. The third tier contains sparsely deployed high-resolution 
pan-tilt-zoom cameras connected to a PC, which performs the object tracking. 
The SensEye platform proves that task allocation across tiers achieves a reduc-
tion in energy compared with a homogeneous platform, while the latency of the 
network response is close to the latency achieved by an always-on homogeneous 
system.
Researchers from Carnegie Melon University present a framework for a dis-
tributed network of vision-enabled sensor nodes called FireFly Mosaic [70] (il-
lustrated in Figure 5). The FireFly platform is built from FireFly sensor nodes 
enhanced with vision capabilities using the CMUCam3 vision processing board 
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  199
[67]. The CMUCam3 sensor supports a set of built-in image processing algo-
rithms, including JPEG compression, frame differencing, color tracking, histo-
gramming, and edge detection. Tight global synchronization throughout the net-
work is supported by using an out-of-band AM carrier current radio transmitter 
and on-board AM radio receiver.
Figure 5. Topology of the visual sensor network, that is, used for testing the FireFly system [70]. The dotted lines 
represent the communication links between the cameras.
The communication and collaboration of camera nodes is scheduled using a 
collision free, energy-efficient TDMA-based link layer protocol called RT-Link 
[71]. In order to support camera group communication (among the cameras with 
overlapped FoVs) both the network connectivity graph (that considers the links 
between nodes within communication range, shown in Figure 6(a)) and the cam-
era network graph (that considers the relationships between the cameras’ FoVs, 
Figure 6(b)) are considered. In this way cameras that share part of the view, but 
are out of each other’s communication range can still communicate via other 
nodes.
The size of the transmitted images with a given resolution is controlled by 
the quality parameter provided in the JPEG standard, which is used for image 
compression. The authors noticed that JPEG processing time does not vary 
significantly with the image quality level, but it changes with image resolu-
tion, mostly due to the large I/O transfer time between the camera and the 
CPU. The authors also measured the sensitivity of the system’s tracking per-
formances with the respect to the time jitter, that is, added to the cameras’ 
image capturing time.
© 2011 by Apple Academic Press, Inc.
  

200  Computer Technology and Computer Programming: New Research and Strategies
Figure 6. Connectivity graph and camera network graph of the FireFly system [70].
Middleware Support
The increased number of hardware and software platforms for smart camera nodes 
has created a problem in how to network these heterogeneous devices and how 
to easily build applications that use these networked devices. The integration of 
camera nodes into a distributed and collaborative network benefits from a well-
defined middleware that abstracts the physical devices into a logical model, pro-
viding a set of services defined through standardized APIs that are portable over 
different platforms. In wireless sensor networks, middleware provides abstractions 
for the networking and communication services, and the main challenges are as-
sociated with providing abstraction support, data fusion and and managing the 
limited resources [72].
In the case of visual sensor networks, the development of middleware sup-
port is additionally challenged by the need for high-level software for supporting 
complex and distributed vision processing tasks. In [73] this support is provided 
using agent-oriented middleware, where different image processing tasks are car-
ried out by different agents. The agents are responsible for task execution at the 
processing unit, they can create new agents, and they can remotely create new 
agents at other cameras, which is fundamental for distributed organization of a 
smart camera network.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  201
In [74], Detmold et al. propose using a Blackboard-based middleware ap-
proach instead of the popular multiagent approach. In this model, the results 
of processing of input video streams are published at the distributed Blackboard 
component. Thus, the Blackboard acts as a repository of information, where com-
putations are triggered in response to published results. The Blackboard has sev-
eral interacting levels. The “single scene analysis” provides information derived 
from object detection and activity analysis (e.g., it produces a “left luggage” hy-
pothesis). The “multi scene analysis” draws conclusions about tracked objects, 
such as the tracks of people throughout the scene. The “reasoning level” provides 
higher level hypotheses regarding unusual behavior. Each level contains drivers 
that process inputs and add them to the level’s information space. The informa-
tion are propagated upwards and shared among the Blackboard levels.
In the future, it is expected that the number of cameras in smart surveillance 
applications will scale to hundreds or even thousands—in this situation, the mid-
dleware will have a crucial role in scaling the network and in integrating the dif-
ferent software components into one automated vision system. In these systems, 
the middleware should address the system’s real-time requirements, together with 
the other resource (energy and bandwidth) constraints.
Open Research Problems in Visual Sensor 
Networks
The extensive research has been done in the many directions that contribute to 
the visual sensor networks. However, the real potential of these networks can 
be reached through a cross-disciplinary research approach that considers all the 
various aspects of visual sensor networks: vision processing, networking, sensor 
managemen, and hardware design.
However, in many cases of the existing work there is no coherence between 
the different aspects of visual sensor networks. For example, networking protocols 
used in visual sensor networks are mainly adapted from the routing protocols 
used in traditional wireless sensor networks, and thus do not provide sufficient 
support for the data-hungry, time-constrained, collaborative communication of 
visual sensor networks. Similarly, embedded vision processing algorithms used in 
visual sensor networks are based on existing computer vision algorithms, and thus 
they rarely consider the constraints imposed by the underlying wireless network.
Thus, future efforts should be directed toward finding ways to minimize the 
amount of data that has to be communicated, by finding ways to describe cap-
tured events with the least amount of data. Additionally, the processing should 
be lightweight—information rich descriptors of objects/scenes are not an option. 
© 2011 by Apple Academic Press, Inc.
  

202  Computer Technology and Computer Programming: New Research and Strategies
Hence, the choice of the “right” feature set, as well as support for real-time com-
munication will play a major role in a successfully operated task.
In order to keep communication between cameras minimal, the cameras need 
to have the ability to estimate whether the information they provide contrib-
utes to the monitoring task. In a postevent detection phase, sensor management 
policies should decide, based on known information from the cameras and the 
network status, whether more cameras need to be included in the monitoring. In 
addition, data exchanged between camera nodes should be aggregated in-network 
at one of the camera nodes, and the decision about the most suitable data fusion 
center should be dynamic, considering the best view and the communication/
fusion cost. However, considering the oftentimes arbitrary deployment of camera 
nodes, where the cameras’ positions and orientations are not known, the problem 
is to find the best ways to combine these arbitrary views in order to obtain useful 
information.
In the current literature distributed source coding (DSC) has been extensively 
investigated as a way to reduce the amount of transmitted data in wireless sen-
sor networks. In DSC, each data source encodes its data independently, without 
communicating with the other data sources, while joint data decoding is per-
formed at the base station. This model, where sensor nodes have simple encoders 
and the complexity is brought to the receiver’s end, fits well the needs of visual 
sensor networks. However, many issues have to be resolved before DSC can be 
practical for visual sensor networks. For example, it is extremely hard to define 
the correlation structure between different images, especially when the network 
topology is unknown or without a network training phase. Also, DSC requires 
tight synchronization between packets sent from correlated sources. Since DSC 
should be implemented in the upper layers of the network stack, it affects all the 
other layers below [75]. Thus, the implementation of DSC will also require care-
ful reconsideration of existing cross-layer designs.
From the communication perspective, novel protocols need to be developed 
that support bursty and collaborative in-network communication. Supporting 
time-constrained and reliable communication are problems at the forefront of 
protocol development for visual sensor networks. In order to support the collab-
orative processing, it is expected that some cameras acts as a fusion centers by col-
lecting and processing raw data from several cameras. Having several fusion cen-
ters can affect the data latency throughout the network as well as the amount of 
the postfusion data. Thus, further research should explore the trade-offs between 
the ways to combine (fuse) data from multiple sources and latency introduced by 
these operations.
Furthermore, in order to preserve network scalability and to cope with time-
constrained communication, there is a need for developing time-aware sensor 
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  203
management policies that will favor utilization of those cameras that can send 
data over multihop shortest delay routes. Such communication should support 
priority differentiation between different data flows, which can be determined 
based on vision information and acceptable delays for the particular data.
In the future we can expect to see various applications based on multimedia 
wireless networks, where camera nodes will be integrated with other types of sen-
sors, such as audio sensors, PIRs, vibration sensors, light sensors, and so forth. By 
utilizing these very low-cost and low-power sensors, the lifetime of the camera 
nodes can be significantly prolonged. However, many open problems appears in 
such multimedia networks. The first issue is network deployment, whereby it is 
necessary to determine network architecture and the numbers of different types of 
sensors that should be used in a particular application, so that all of the sensors are 
optimally utilized while at the same time the cost of the network is kept low. Such 
multimedia networks usually employ a hierarchical architecture, where ultra-low 
power sensors (such as microphones, PIRs, vibration, or light sensors) continu-
ously monitor the environment over long periods of time, while higher-level sen-
sors, such as cameras sleep most of the time. When the lower-level sensors register 
an event, they notify higher-level sensors about it. Such a hierarchical model (as 
seen in [68], e.g.) tends to minimize the amount of communication in the net-
work. However, it is important to reduce the number of false and missed alarms at 
the low-level sensors, so that the network reliability is not jeopardized. Thus, it is 
important to precisely define an event at the lower-level sensors that cameras can 
interpret without ambiguity. A high-level node acting as a data collector should 
be able to perform multimodal fusion of data received from different types of sen-
sors, in order to reason about captured events and decide an appropriate course 
of action. The reliability of multimodal data fusion thus depends on the accuracy 
of the data provided by each sensor modality, so the data from different types of 
sensors can be associated with different weights before the data fusion.
The growing trend of deploying an increasing number of smart sensors in 
people’s everyday lives poses several privacy issues. We have not discussed this 
problem in this paper, but it is clear that this problem is a source of concern for 
many people who can benefit from visual sensor networks, as information about 
their private life can be accessed through the network. The main problem is that 
the network can take much more information, such as private information, than 
it really needs in order to perform its tasks. As pointed out in [76], there are sev-
eral ways to work around this problem. The most radical solution is to exclude 
cameras from the network, using only nonimaging sensors. However, many situ-
ations cannot be resolved without obtaining image data from the area. Thus, the 
solutions where cameras perform high-level image analysis and provide descrip-
tive information instead of raw images are favorable. The user can be contacted by 
© 2011 by Apple Academic Press, Inc.
  

204  Computer Technology and Computer Programming: New Research and Strategies
the system only on occasions when the system is not sure how to react (e.g., if an 
unknown face is detected in the house). In the future, people will most probably 
need to sacrifice a bit of their privacy if they want to benefit from smart applica-
tions of visual sensor networks. However, privacy and security should be seriously 
addressed in all future designs of visual sensor networks.
Based on the work reviewed in this paper, we notice that current research 
trends in visual sensor networks are divided into two directions. The first di-
rection leads toward the development of visual sensor networks where cameras 
have large processing capabilities, which makes them suitable for use in a number 
of high-level reasoning applications. Research in this area is directed toward ex-
ploring ways to implement existing vision processing algorithm onto embedded 
processors. Oftentimes, the networking and sensor management aspects are not 
considered in this approach. The second direction in visual sensor networks re-
search is motivated by the existing research in wireless sensor networks. Thus, it 
is directed toward exploring the methods that will enable the network to provide 
small amounts of data from the camera nodes that are constrained by resource 
limitations, such as remaining energy and available bandwidth. Thus, such visual 
sensor networks are designed with the idea of having data provided by the net-
work of cameras for long periods of time.
We believe that in the future these two directions will converge toward the 
same path. Currently, visual sensor networks are limited by their hardware com-
ponents (COTS) that are not fully optimized for embedded vision processing ap-
plications. Future development of faster, low-power processing architectures and 
ultra low-power image sensors will open a door toward a new generation of visual 
sensor networks with better processing capabilities and lower energy consump-
tion. However, the main efforts in the current research of visual sensor networks 
should be directed toward integrating vision processing tasks and networking re-
quirements. Thus, future directions in visual sensor networks research should be 
aimed at exploring the following interdisciplinary problems.
(i)	
How should vision processing tasks depend on the underlying network 
conditions, such as limited bandwidth, limited (and potentially time-
varying) connectivity between camera nodes or data loss due to varying 
channel conditions? 
(ii)	 How should the design of network communication protocols be influ-
enced by the vision tasks? For example, how should different priorities 
be assigned to data flows to dynamically find the smallest delay route or 
to find the best fusion center? 
(iii)	 How should camera nodes be managed, considering the limited network 
resources as well as both the vision processing and networking tasks, in 
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  205
order to achieve application-specific QoS requirements, such as those 
related to the quality of the collected visual data or coverage of the moni-
tored area?
In the end, widespread use of visual sensor networks depends on the program-
ming complexity of the system, which includes implementation of both vision 
processing algorithms as well as networking protocols. Therefore, we believe that 
development of middleware for visual sensor networks will have a major role 
in making these networks widely accepted in a number of applications. We can 
envision that in the future visual sensor networks will consist of hundreds or 
even thousands of camera nodes (as well as other types of sensor nodes) scattered 
throughout an area. The scalability and integration of various vision and network-
ing tasks for such large networks of cameras should be addressed by future de-
velopments of distributed middleware architectures. Middleware should provide 
an abstraction of underlying vision-processing, networking and shared services 
(where shared services are those commonly used by both the vision processing 
and networking tasks and include synchronization service, localization service, 
or neighborhood discovery service, e.g.). By providing a number of APIs, the 
middleware will enable easy programming at the application layer, and the use of 
different hardware platforms in one visual sensor network.
Conclusions
Transmission of multimedia content over wireless and wired networks is a well-
established research area. However, the focus of this paper is to survey a new 
type of wireless networks, visual sensor networks, and to point out the unique 
characteristics and constraints that differentiate visual sensor networks from other 
types of multimedia networks. We present an overview of existing work in several 
research areas that support visual sensor networks. In the coming era of low-pow-
er distributed computing, visual sensor networks will continue to challenge the 
research community because of their complex application requirements and tight 
resource constraints. We discussed many problems encountered in visual sensor 
network research caused by the strict resource constraints, including embedded 
vision processing, data communication, camera management issues, and develop-
ment of effective visual sensor network testbeds. However, visual sensor networks’ 
potential to provide a comprehensive understanding of the environment and their 
ability to provide visual information from unaccessible areas will make them in-
dispensable in the coming years.
Many problems still need to be addressed through future research. We dis-
cussed some of the open issues not only in the different subfields of visual sen-
sor networks, but, more importantly, in the integration of these areas. Real  
© 2011 by Apple Academic Press, Inc.
  

206  Computer Technology and Computer Programming: New Research and Strategies
breakthroughs in visual sensor networks will occur only through a comprehensive 
solution that considers the vision, networking, management, and hardware issues 
in concert.
Acknowledgement
This work was supported by the National Science Foundation under Grant #ECS-
0428157.
References
1.	 P. Bolliger, M. Köhler, and K. Römer, “Facet: towards a smart camera net-
work of mobile phones,” in Proceedings of 1st ACM International Conference 
on Autonomic Computing and Communication Systems (Autonomics ‘07), 
2007.
2.	 S. Misra, M. Reisslein, and G. Xue, “A survey of multimedia streaming in wire-
less sensor networks,” IEEE Communications Surveys and Tutorials, vol. 10, 
pp. 18–39, 2008.
3.	 Y. Charfi, N. Wakamiya, and M. Murata, “Challenging issues in visual sen-
sor networks,” Advanced Network Architecture Laboratory, Osaka University, 
2007.
4.	 I. F. Akyildiz, T. Melodia, and K. R. Chowdhury, “A survey on wireless mul-
timedia sensor networks,” Computer Networks, vol. 51, no. 4, pp. 921–960, 
2007.
5.	 S. Hengstler, D. Prashanth, S. Fong, and H. Aghajan, “MeshEye: a hybrid-
resolution smart camera mote for applications in distributed intelligent sur-
veillance,” in Proceedings of the 6th International Symposium on Information 
Processing in Sensor Networks (IPSN ‘07), pp. 360–369, 2007.
6.	 W. Wolf, B. Ozer, and T. Lv, “Smart cameras as embedded systems,” Computer, 
vol. 35, no. 9, pp. 48–53, 2002.
7.	 M. Chen, S. Gonzalez, and V. C. M. Leung, “Applications and design issues for 
mobile agents in wireless sensor networks,” IEEE Wireless Communications, 
vol. 14, no. 6, pp. 20–26, 2007.
8.	 M. Chen, T. Kwon, Y. Yuan, Y. Choi, and V. C. M. Leung, “Mobile agent-
based directed diffusion in wireless sensor networks,” EURASIP Journal on 
Advances in Signal Processing, vol. 2007, 13 pages, 2007.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  207
9.	 M. Wu and C. W. Chen, “Multiple bitstream image transmission over wireless 
sensor networks,” in Proceedings of 2d IEEE International Conference on Sen-
sors, vol. 2, pp. 727–731, Toronto, Canada, October 2003.
10.	 R. Hartley and A. Zisserman, Multiple View Geometry in Computer Vision, 
Cambridge University Press, Cambridge, UK, 2000.
11.	 K. Römer, P. Blum, and L. Meier, “Time synchronization and calibration 
in wireless sensor networks,” in Handbook of Sensor Networks: Algorithms 
and Architectures, I. Stojmenovic, Ed., pp. 199–237, John Wiley & Sons,  
New York, NY, USA, 2005.
12.	 D. Ganesan, B. Greenstein, D. Perelyubskiy, D. Estrin, and J. Heidemann, 
“Multi-resolution storage and search in sensor networks,” ACM Transactions 
on Storage, vol. 1, pp. 277–315, 2005.
13.	 P. Remagnino, A. I. Shihab, and G. A. Jones, “Distributed intelligence 
for multi-camera visual surveillance,” Pattern Recognition, vol. 37, no. 4,  
pp. 675–689, 2004.
14.	 T. He, S. Krishnamurthy, L. Luo, et al., “VigilNet: an integrated sensor net-
work system for energy-efficient surveillance,” ACM Transactions on Sensor 
Networks, vol. 2, no. 1, pp. 1–38, 2006.
15.	 O. Schreer, P. Kauff, and T. Sikora, 3D Video Communication, John Wiley & 
Sons, New York, NY, USA, 2005.
16.	 N. J. McCurdy and W. Griswold, “A system architecture for ubiquitous video,” 
in Proceedings of the 3rd Annual International Conference on Mobile Systems, 
Applications, and Services (Mobisys ‘05), 2005.
17.	 S. Hengstler and H. Aghajan, “Application-oriented design of smart camera 
networks,” in Proceedings of the 1st ACM/IEEE International Conference on 
Distributed Smart Cameras (ICDSC ‘07), pp. 12–19, 2007.
18.	 A. Barton-Sweeney, D. Lymberopoulos, and A. Savvides, “Sensor localization 
and camera calibration in distributed camera sensor networks,” in Proceedings 
of the 3rd International Conference on Broadband Communications, Net-
works and Systems (BROADNETS ‘06), 2006.
19.	 S. Funiak, M. Paskin, C. Guestrin, and R. Sukthankar, “Distributed localiza-
tion of networked cameras,” in Proceedings of the 5th International Confer-
ence on Information Processing in Sensor Networks (IPSN ‘06), pp. 34–42, 
2006.
20.	 C. J. Taylor, “A scheme for calibrating smart camera networks using active 
lights,” in Proceedings of the 2nd International Conference on Embedded Net-
worked Sensor Systems (SenSys ‘04), p. 322, 2004.
© 2011 by Apple Academic Press, Inc.
  

208  Computer Technology and Computer Programming: New Research and Strategies
21.	 D. Devarajan, R. J. Radke, and H. Chung, “Distributed metric calibration of 
ad hoc camera networks,” ACM Transactions on Sensor Networks, vol. 2, no. 
3, pp. 380–403, 2006.
22.	 D. B. Yang, H. H. González-Baños, and L. J. Guibas, “Counting people in 
crowds with a real-time network of simple image sensors,” in Proceedings of the 
9th IEEE International Conference on Computer Vision, vol. 1, pp. 122–129, 
Nice, France, October 2003.
23.	 D. Yang, J. Shin, A. Ercan, and L. Guibas, “Sensor tasking for occupancy rea-
soning in a network of cameras,” in Proceedings of 2nd IEEE International 
Conference on Broadband Communications, Networks and Systems (BaseNets 
‘04), 2004.
24.	 A. Lipton, H. Fujiyoshi, and R. Patil, “Moving target classification and track-
ing from real-time video,” in Proceedings of IEEE Image Understanding Work-
shop, 1998.
25.	 P. V. Pahalawatta, T. N. Pappas, and A. K. Katsaggelos, “Optimal sensor selec-
tion for video-based target tracking in a wireless sensor network,” in Proceed-
ings of the International Conference on Image Processing (ICIP ‘04), vol. 2, 
pp. 3073–3076, 2004.
26.	 S. Fleck, F. Busch, and W. Straßer, “Adaptive probabilistic tracking embedded 
in smart cameras for distributed surveillance in a 3D model,” EURASIP Jour-
nal of Embedded Systems, vol. 2007, Article ID 29858, 17 pages, 2007.
27.	 F. Lau, E. Oto, and H. Aghajan, “Color-based multiple agent tracking for wire-
less image sensor networks,” in Proceedings of the Advanced Concepts for In-
telligent Vision Systems (ACIVS ‘06), pp. 299–310, 2006.
28.	 T. H. Ko and N. M. Berry, “On scaling distributed low-power wireless image 
sensors,” in Proceedings of the 39th Annual Hawaii International Conference 
on System Sciences, 2006.
29.	 A. Ercan, A. E. Gamal, and L. Guibas, “Camera network node selection for 
target localization in the presence of occlusions,” in Proceedings of the ACM 
SenSys Workshop on Distributed Smart Cameras, 2006.
30.	 S. Soro and W. B. Heinzelman, “On the coverage problem in video-based wire-
less sensor networks,” in Proceedings of the 2nd International Conference on 
Broadband Networks (BROADNETS ‘05), pp. 9–16, 2005.
31.	 H. Wu and A. A. Abouzeid, “Error resilient image transport in wireless sensor 
networks,” Computer Networks, vol. 50, no. 15, pp. 2873–2887, 2006.
32.	 M. Chen, V. C. M. Leung, S. Mao, and Y. Yuan, “Directional geographical 
routing for real-time video communications in wireless sensor networks,” 
Computer Communications, vol. 30, no. 17, pp. 3368–3383, 2007.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  209
33.	 M. Maimour, C. Pham, and J. Amelot, “Load repartition for congestion con-
trol in multimedia wireless sensor networks with multipath routing,” in Pro-
ceedings of the 3rd International Symposium on Wireless Pervasive Comput-
ing (ISWPC ‘08), pp. 11–15, 2008.
34.	 P. Lin, C. Qiao, and X. Wang, “Medium access control with a dynamic duty 
cycle for sensor networks,” in Proceedings of the IEEE Wireless Communi-
cations and Networking Conference (WCNC ‘04), vol. 3, pp. 1534–1539, 
2004.
35.	 G. Lu, B. Krishnamachari, and C. S. Raghavendra, “An adaptive energy-effi-
cient and low-latency MAC for data gathering in wireless sensor networks,” 
in Proceedings of the 18th International Parallel and Distributed Processing 
Symposium (IPDPS ‘04), pp. 3091–3098, Santa Fe, NM, USA, April 2004.
36.	 C. Ceken, “An energy efficient and delay sensitive centralized MAC protocol 
for wireless sensor networks,” Computer Standards and Interfaces, vol. 30, no. 
1-2, pp. 20–31, 2008.
37.	 T. He, J. A. Stankovic, C. Lu, and T. Abdelzaher, “SPEED: a stateless proto-
col for real-time communication in sensor networks,” in Proceedings of the 
International Conference on Distributed Computing Systems (ICDCS ‘03),  
pp. 46–55, 2003.
38.	 E. Felemban, C.-G. Lee, and E. Ekici, “MMSPEED: multipath multi-SPEED 
protocol for QoS guarantee of reliability and timeliness in wireless sensor net-
works,” IEEE Transactions on Mobile Computing, vol. 5, no. 6, pp. 738–753, 
2006.
39.	 G. Lu and B. Krishnamachari, “Minimum latency joint scheduling and rout-
ing in wireless sensor networks,” Ad Hoc Networks, vol. 5, no. 6, pp. 832–843, 
2007.
40.	 Y. Andreopoulos, N. Mastronarde, and M. van der Schaar, “Cross-layer opti-
mized video streaming over wireless multi-hop mesh networks,” IEEE Journal 
on Selected Areas in Communications, vol. 24, pp. 2104–1215, 2006.
41.	 M. van der Schaar and D. S. Turaga, “Cross-layer packetization and retrans-
mission strategies for delay-sensitive wireless multimedia transmission,” IEEE 
Transactions on Multimedia, vol. 9, no. 1, pp. 185–197, 2007.
42.	 W. Wang, D. Peng, H. Wang, and H. Sharif, “Adaptive image transmission 
with p-v diversity in multihop wireless mesh networks,” International Journal 
of Electrical, Computer, and Systems Engineering, vol. 1, no. 1, 2007.
43.	 K. Obraczka, R. Manduchi, and J. Garcia-Luna-Aceves, “Managing the infor-
mation flow in visual sensor networks,” in Proceedings of the 5th International 
Symposium on Wireless Personal Multimedia Communication, 2002.
© 2011 by Apple Academic Press, Inc.
  

210  Computer Technology and Computer Programming: New Research and Strategies
44.	 H. Medeiros, J. Park, and A. Kak, “A light-weight event-driven protocol for 
sensor clustering in wireless camera networks,” in Proceedings of the 1st ACM/
IEEE International Conference on Distributed Smart Cameras (ICDSC ‘07), 
pp. 203–210, 2007.
45.	 T. Teixeira, D. Lymberopoulos, E. Culurciello, Y. Aloimonos, and A. Savvides, 
“A lightweight camera sensor network operating on symbolic information,” in 
Proceedings of 1st Workshop on Distributed Smart Cameras, Held in Con-
junction with ACM SenSys, 2006.
46.	 H. Aghajan and C. Wu, “From distributed vision networks to human behavior 
interpretation,” in Proceedings of the Behaviour Monitoring and Interpretation 
Workshop at the 30th German Conference on Artificial Intelligence, 2007.
47.	 V. Lecuire, C. Duran-Faundez, and N. Krommenacker, “Energy-efficient 
transmission of wavelet-based images in wireless sensor networks,” EURASIP 
Journal on Image and Video Processing, vol. 2007, no. 1, 15 pages, 2007.
48.	 C.-Y. Wan, A. T. Campbell, and L. Krishnamurthy, “Pump-slowly, fetch-quick-
ly (PSFQ): a reliable transport protocol for sensor networks,” IEEE Journal on 
Selected Areas in Communications, vol. 23, no. 4, pp. 862–872, 2005.
49.	 M. van der Schaar and P. Chou, Multimedia over IP and Wireless Networks: 
Compression, Networking, and Systems, Academic Press, New York, NY, USA, 
2007.
50.	 W. Ye, J. Heidemann, and D. Estrin, “An energy-efficient MAC protocol for 
wireless sensor networks,” in Proceedings of 21st International Annual Joint 
Conference of the IEEE Computer and Communications Societies (INFO-
COM ‘02), vol. 3, pp. 1567–1576, 2002.
51.	 H. Zhang and J. C. Hou, “Maintaining sensing coverage and connectivity in 
large sensor networks,” International Journal of Wireless Ad Hoc and Sensor 
Networks, vol. 1, no. 2, pp. 89–124, 2005.
52.	 J. C. Dagher, M. W. Marcellin, and M. A. Neifeld, “A method for coordinating 
the distributed transmission of imagery,” IEEE Transactions on Image Process-
ing, vol. 15, no. 7, pp. 1705–1717, 2006.
53.	 J. Park, P. Bhat, and A. Kak, “A look-up table based approach for solving the 
camera selection problem in large camera networks,” in Proceedings of the 
International Workshop on Distributed Smart Cameras (DCS ‘06), 2006.
54.	 S. Soro and W. Heinzelman, “Camera selection in visual sensor networks,” in 
Proceedings of the IEEE Conference on Advanced Video and Signal Based 
Surveillance (AVSS ‘07), pp. 81–86, 2007.
© 2011 by Apple Academic Press, Inc.
  

A Survey of Visual Sensor Networks  211
55.	 N. H. Zamora and R. Marculescu, “Coordinated distributed power manage-
ment with video sensor networks: analysis, simulation, and prototyping,” in 
Proceedings of the 1st ACM/IEEE International Conference on Distributed 
Smart Cameras (ICDSC ‘07), pp. 4–11, 2007.
56.	 Z. Yang and K. Nahrstedt, “A bandwidth management framework for wire-
less camera array,” in Proceedings of the International Workshop on Network 
and Operating System Support for Digital Audio and Video (NOSSDAV ‘05),  
pp. 147–152, 2005.
57.	 S. Hengstler and H. Aghajan, “WiSNAP: a wireless image sensor network ap-
plication platform,” in Proceedings of the 2nd International Conference on 
Testbeds and Research Infrastructures for the Development of Networks and 
Communities (TRIDENTCOM ‘06), pp. 7–12, 2006.
58.	 M. Rahimi, R. Baer, O. I. Iroezi, et al., “Cyclops: in situ image sensing and 
interpretation in wireless sensor networks,” in Proceedings of the 3rd Interna-
tional Conference on Embedded Networked Sensor Systems, 2005.
59.	 W.-C. Feng, B. Code, E. Kaiser, M. Shea, W.-C. Feng, and L. Bavoil, “Panoptes: 
scalable low-power video sensor networking technologies,” in Proceedings of 
the 11th ACM International Multimedia Conference and Exhibition (MM 
‘03), pp. 562–571, Berkeley, Calif, USA, November 2003.
60.	 C. B. Margi, R. Manduchi, and K. Obraczka, “Energy consumption tradeoffs 
in visual sensor networks,” in Proceedings of 24th Brazilian Symposium on 
Computer Networks (SBRC ‘06), 2006.
61.	 Crossbow Stargate platform, http://www.xbow.com/.
62.	 D. Jung, T. Teixeira, A. Barton-Sweeney, and A. Savvides, “Model-based design 
exploration of wireless sensor node lifetimes,” in Proceedings of the 4th Euro-
pean Conference on Wireless Sensor Networks, pp. 277–292, 2007.
63.	 L. Nachman, “New Tinyos platforms panel: iMote2,” in Proceedings of the 
Second International TinyOS Technology Exchange, 2005.
64.	 L. Ferrigno, S. Marano, V. Paciello, and A. Pietrosanto, “Balancing computa-
tional and transmission power consumption in wireless image sensor networks,” 
in Poceedings of the IEEE International Conference onVirtual Environments, 
Human-Computer Interfaces, and Measurement Systems (VECIMS ‘05),  
pp. 61–66, 2005.
65.	 “Mica2 wireless sensor node,” http://www.xbow.com/Products/Product_pdf_
files/Wireless_pdf/MICA2_Datasheet.pdf.
© 2011 by Apple Academic Press, Inc.
  

212  Computer Technology and Computer Programming: New Research and Strategies
66.	 R. Kleihorst, B. Schueler, A. Danilin, and M. Heijligers, “Smart camera mote 
with high performance vision system,” in Proceedings of ACM SenSys Work-
shop on Distributed Smart Cameras (DSC ‘06), 2006.
67.	 A. Rowe, A. Goode, D. Goel, and I. Nourbakhsh, “CMUcam3: an open pro-
grammable embedded vision sensor,” Carnegie Mellon Robotics Institute, 
2007.
68.	 P. Kulkarni, D. Ganesan, P. Shenoy, and Q. Lu, “SensEye: a multi-tier camera 
sensor network,” in Proceedings of the ACM Multimedia, 2005.
69.	 “Crossbow wireless sensor platform,” http://www.xbow.com/Products/wprod-
uctsoverview.aspx.
70.	 A. Rowe, D. Goel, and R. Rajkumar, “FireFly Mosaic: a visionenabled wireless 
sensor networking system,” in Proceedings of 28th IEEE International Real-
Time Systems Symposium (RTSS ‘07), 2007.
71.	 A. Rowe, R. Mangharam, and R. Rajkumar, “RT-Link: a time synchronized 
link protocol for energy constrained multi-hop wireless networks,” in Proceed-
ings of IEEE Communications Society Conference on Sensor, Mesh and Ad 
Hoc Communications and Networks (SECON ‘06), 2006.
72.	 M. M. Molla and S. I. Ahamed, “A survey of middleware for sensor network 
and challenges,” in Proceedings of the International Conference on Parallel 
Processing Workshops, pp. 223–228, 2006.
73.	 B. Rinner, M. Jovanovic, and M. Quaritsch, “Embedded midddleware on dis-
tributed smart cameras,” in Proceedings of the IEEE International Conference 
on Acoustics, Speech, and Signal Processing (ICASSP ‘07), vol. 4, pp. 1381–
1384, Honolulu, Hawaii, USA, April 2007.
74.	 H. Detmold, A. Dick, K. Falkner, D. S. Munro, A. van den Hengel, and R. 
Morrison, “Middleware for video surveillance networks,” in Proceedings of the 
Middleware for Sensor Networks (MidSens ‘06), pp. 31–36, 2006.
75.	 Z. Xiong, A. D. Liveris, and S. Cheng, “Distributed source coding for sen-
sor networks,” IEEE Signal Processing Magazine, vol. 21, no. 5, pp. 80–94, 
2004.
76.	 S. Meyer and A. Rakotonirainy, “A survey of research on contextaware homes,” 
in Proceedings of the Australasian Information Security Workshop Conference 
on ACSW Frontiers, Australian Computer Society, Inc., 2003.
© 2011 by Apple Academic Press, Inc.
  

A Family of Tools for 
Supporting the Learning of 
Programming 
Guido Rößling 
Abstract
Both learning how to program and understanding algorithms or data struc-
tures are often difficult. This paper presents three complementary approaches 
that we employ to help our students in learning to program, especially during 
the first term of their study. We use a web-based programming task database 
as an easy and risk-free environment for taking the first steps in programming 
Java. The Animal algorithm visualization system is used to visualize the dy-
namic behavior of algorithms and data structures. We complement both ap-
proaches with tutorial videos on using the Eclipse IDE. We also report on the 
experiences with this combined approach. 
Keywords: algorithm animation; Animal; programming support; WebTasks 
© 2011 by Apple Academic Press, Inc.

214  Computer Technology and Computer Programming: New Research and Strategies
Introduction 
Programming is a fundamental part of Computer Science. Educators therefore 
typically expect that graduates of a CS course, or courses close to CS, will be 
able to program. However, many studies and the experiences of a large number 
of teachers agree that “programming is not easy,” and that learning to program is 
also not easy, see, e.g., [1]. 
Some effort has been put into investigating what factors contribute to this 
difficulty. For example, the problems seem not to depend on gender, but are cor-
related with problem solving skills and the first language of the student [2]. 
Over the last two decades, several tools for supporting the process of teach-
ing or learning programming have appeared. Tools like BlueJ [3–5], Alice [6,7], 
DrScheme [8–10], Greenfoot [11–13] or Academic Java [14] address program-
ming in their own unique way. For example, while both BlueJ and Alice target 
novices in object-oriented programming, BlueJ is based on UML and Java, while 
Alice uses a built-in drag-and-drop interface to program a 3D world with a high 
degree of interaction. DrScheme is used for teaching the fundamentals of how to 
design (good) programs in a set of pedagogically motivated teaching languages 
based on the functional language Scheme, while Greenfoot offers a framework for 
two-dimensional grid assignments in Java together with an IDE usable by novice 
programmers. Academic Java finally provides an interface to a large number of 
small programming examples that previous research had indicated covered both 
important and often misunderstood concepts in Java. 
On the other hand, there have been a number of approaches to help students 
better grasp programs by visualizing the program itself (“program visualization”), 
or to present the dynamic behavior of algorithms of data structures (“algorithm 
visualization”). These systems include for example Jeliot 3 [15], which can visual-
ize Java programs stepwise, or Leonardo [16], which can execute and also reverse 
the execution of C programs. The tools for visualizing or animating algorithms 
and data structures include ANIMAL [17] and JHAVE [18]. 
In this paper, we present a small family of tools that are used for teaching pro-
gramming, algorithms, and data structures at the TU Darmstadt. These tools con-
sist of a large database with easy to moderately difficult Java programming tasks, 
a system for visualizing algorithms and data structures, and recordings of tutorials 
on using the Eclipse IDE. Additionally, we outline our plans to integrate these 
features into the Moodle [19] open source distributed learning environment. 
In the following Sections, we will present the current state of these compo-
nents and outline the integration of the tools and learning materials that we are 
working on. 
© 2011 by Apple Academic Press, Inc.
  

A Family of Tools for Supporting the Learning of Programming  215
WebTasks: Programming Tasks Database 
Testing the programs written by students for syntactic and semantic correctness, 
functionality or style is common today. Some of the established systems for ac-
complishing this include Boss [20], CourseMarker [21], and Web-CAT [22]. 
In 2006, we were looking for a system that supports students with little to no 
previous programming experience in learning to solve simple Java programming 
tasks. At the same time, we wanted to have a large pool of possible tasks covering 
the spectrum from “extremely easy” to “moderately difficult,” in order to address 
both novice programmers and those with some previous exposure, but perhaps in 
a different programming language. At this stage, we did not yet expect students 
to be able to write their own tests, so that the test-driven development approach 
supported by Web-CAT did not apply to our students. In fact, we do not expect 
our students be able to write a full-fledged Java class including a main method: 
most tasks only require students to fill in the body of a prepared method. 
At the same time, the system was supposed to assist, not assess, students. For 
example, the results of a student’s submission are not taken into account for mea-
suring the same student’s accomplishments in the CS 1 course. While we encour-
age our students to use the system to get some hands-on practice in solving simple 
Java tasks, their submissions are not monitored and the use of the system is com-
pletely voluntary. Plagiarism or “cheating” are thus also not seen as a concern, as 
the students cannot benefit from this, but only succeed in cheating themselves. 
To further lower the barrier in using the system, the system was supposed to 
run completely in the web browser, without requiring any software installation or 
even a Java SDK on the students’ computers. 
For these reasons, the established systems such as Boss [20], CourseMarker 
[21], and Web-CAT [22] did not perfectly match our expectation. We instead 
used a competitive programming lab to develop our own solution, called WebT-
asks, based on the best of four competing systems. 
WebTasks [23] runs as a set of JSP pages on an Apache Tomcat server. As 
the contents mainly cover comparatively simple tasks, the target audience typi-
cally consists of students attending courses such as CS 1. No special algorithmic 
knowledge is required by most tasks, only a basic understanding of the Java pro-
gramming language. 
WebTasks currently contains 118 Java programming tasks. Only six of these 
tasks require the user to upload a complete class file, while the others require only 
that the body of a prepared method is implemented correctly. In this way, the 
student’s workload is reduced, and many potentially problematic issues, such as 
the correct use of the Java main method, can be avoided. This also makes using 
© 2011 by Apple Academic Press, Inc.
  

216  Computer Technology and Computer Programming: New Research and Strategies
WebTasks significantly easier for novices to Java, while at the same time improv-
ing the control we have over the submissions. 
Figure 1 shows a typical example of a programming task. Note that parts of 
this web page are in German, as the system was developed to support our local 
students; however, some tasks including the one shown here have been translated 
into English. Additionally, an internationalization of the user interface would not 
be difficult to do. The task shown requires the student to implement a variation 
on the Pascal triangle, where two initial values are passed in as an array of size 2. 
The student has to compute the nth step of a Pascal triangle based on this initial 
input, and return it as an array of int values. 
The difficulty level of the task is indicated by a colored difficulty bar. The task 
in Figure 1 is thus ranked as rather difficult, based on the assumed programming 
skills of an average student in the first year of CS. 
Figure 2 presents the basic work flow for a student working with WebTasks. 
The student will first pick an assignment and submit a solution proposal. This will 
be compiled by the server, and, if the compilation was successful, it will automati-
cally be tested for correctness. A correct solution will be submitted to the internal 
forum. We will now take a closer look at these steps. 
If the student decides on implementing the task, he will be taken to an input 
field as shown in Figure 3. Here, the student sees the predefined method header 
and return statement, and only needs to provide the correct implementation of 
the method body. In the Figure, a (slightly incorrect) solution proposal has al-
ready been filled in. 
Once students think that their code should solve the task, they can press the 
“Abschicken” (Submit) button to submit their solution. The solution will then 
be automatically validated using JUnit [24,25]. If the tests are not successful, the 
result will be shown to the student, as indicated in Figure 4. Here, the system in-
forms the user that test 2 out of 7 has failed, because the last value in the result was 
2, not 1. Note that the tests are aborted once one test has failed. Thus, in Figure 4, 
only the tests Test1 and Test2 were executed. This was done to avoid overwhelm-
ing programming novices with a large number of failing tests in the initial submis-
sions: novices shall be able to tackle one problem after the other. 
The most popular programming assignment asks students to determine the 
average value for an array of int values. This task currently has 627 valid solu-
tions. 617 students solved a second tasks that asked them to “append” an int to 
an array of int values, requiring them to create a new array of the proper size and 
copy all “old” values accordingly. In total, the 118 programming tasks have re-
ceived more than 10,000 solutions so far. Note that this number ignores the failed 
© 2011 by Apple Academic Press, Inc.
  

A Family of Tools for Supporting the Learning of Programming  217
submissions—only successful submissions that passed all internal JUnit tests are 
counted. 
Figure 1. Example task from the WebTasks database. 
Once a task has been solved by a student, he or she is able to view the solu-
tions of other students, and may comment on them. The underlying rationale 
for this feature is that students may learn much from peer solutions, especially 
if those use clever “tricks” that the student had not thought of before. These 
“tricks” can for example include the use of System.arraycopy to copy the ele-
ments in an array, the use of iterators or the modified “for each” version of the 
Java for loop. 
To use the system, a user first has to log in with the credentials of the CS 
Department of the TU Darmstadt, or register inside the system. While the first 
option is only available to students who take courses from our department, the 
system-internal registration is available to all interested users. The use of the sys-
tem is encouraged within our CS 1 course as an easy way to get fast feedback 
© 2011 by Apple Academic Press, Inc.
  

218  Computer Technology and Computer Programming: New Research and Strategies
on the correctness of programs. Compared to regularly submitted programming 
tasks which are corrected by a teaching assistant, the delay between submission 
and access to the result when using WebTasks is only a few seconds: the time 
needed for the server to compile and test the submission and then provide the 
output of the compiler and test system. 
Figure 2. Schematic workflow for a student submission to WebTasks. 
Figure 3. Example student code for a given WebTasks task. 
© 2011 by Apple Academic Press, Inc.
  

A Family of Tools for Supporting the Learning of Programming  219
Figure 4. Example validation failure output for code submitted to the WebTasks database. 
The database also contains 50 multiple choice tests. The topics covered in 
the tests include questions about various tree structures (Heaps, spanning trees, 
B-and AVL trees), complexity, maximum flow problems, hashing, shortest path 
problems, boolean and binary operators and sorting algorithms. All these topics 
belong to the first two Introduction to Computer Science courses taught at the 
TU Darmstadt, the core courses for teaching programming concepts, program-
ming languages, object orientation, algorithms and data structures. 
It should be pointed out that the system as it is is not meant for official grad-
ing of student submissions. Although students have to log in, no authentication 
beyond the login and password is done, so that no valid proof of identity can be 
guaranteed. WebTasks also offers an “exam” mode in which the access to the sys-
tem is limited to the computers from our central CS computer pool (with about 
100 terminals). Additionally, the pool network is manually reconfigured so that 
© 2011 by Apple Academic Press, Inc.
  

220  Computer Technology and Computer Programming: New Research and Strategies
each terminal can only access the WebTasks server, effectively preventing access to 
the home directory (as this might contain solutions), other computers inside the 
pool, or the Internet. Thus, given that the students in the pool will also be super-
vised by at least one person, we can be reasonably sure that the solution submitted 
by a given student will actually come from that student. 
The CS Department also considered using the system to grade students on 
their programming skills. The idea was to assign a number of “exam” dates for 
which students could register. Each such date would present them with three 
to five tasks chosen either randomly or by the educator, to be solved within two 
hours. As all tasks in the database are essentially easy, one would expect that all 
students with a certain basic skill in programming and a basic understanding of 
Java would be able to solve this task. WebTasks would have been able to support 
this testing in a special testing mode. 
However, after some internal discussions, the CS Department dropped these 
considerations in favor of a mandatory CS 1 programming project and a mentor-
ing system. This was done to place more emphasis on supporting students than 
on using exams to distinguish between “sufficiently qualified” students and those 
who were not allowed to continue. As the goal of WebTasks is to assist, not moni-
tor or evaluate, students in taking the first steps in programming Java in a threat-
free environment, we were glad that the plans were ultimately dropped. 
We initially also included an automatic and rigorous checking of the code qual-
ity with the use of CheckStyle [26]. Since our target users are programming novices 
who already felt challenged with the tasks, we decided not to follow up on this. 
Visualizing and Animating Algorithms and Data 
Structures 
The WebTasks database described in Section 2 is meant to provide students with 
little programming experience in Java with an easy and fault-tolerant environ-
ment for working on simple programming tasks. Another problematic area in 
programming is understanding common algorithms and data structures. Topics 
such as searching and sorting algorithms are usually taught in a CS 2 course, 
together with data structures such as binary trees, graphs, or more complex data 
structures such as AVL trees. 
The main problem here is often not that the students have to program these 
algorithms or data structures. Rather, the students first have to be able to under-
stand the behavior of these structures. For this purpose, the field of algorithm 
and program visualization has been active in implementing tools and providing 
guidelines for supporting the understanding of algorithms and data structures. 
© 2011 by Apple Academic Press, Inc.
  

A Family of Tools for Supporting the Learning of Programming  221
Our basic credo is that the highly dynamic nature of the underlying data 
structures or algorithms should also be presented dynamically, as getting a firm 
grasp of the “inner workings” based solely on the (static) code is difficult for 
many students. Besides supporting students by showing them how a given data 
structure or algorithm behaves, it has increasingly been recognized that it is also 
important to actively engage the learners. A seminal report by a set of experts in 
the field [27] has defined a taxonomy of “levels of engagement,” which has been 
referenced in more than 100 publications and has caused some follow-up research 
with similar results including [18,28]. The report was further supported by a sur-
vey of successful evaluations [29]. 
One of the most elaborate systems for visualizing (almost) arbitrary content is 
ANIMAL [17,30]. ANIMAL presents contents based on a set of built-in flexible 
graphical primitives and animation effects. It does not “understand” the underly-
ing “code,” but usually processes programs written in the ANIMALSCRIPT visu-
alization scripting language [31]. This notation allows the placement of objects in 
relation to each other, e.g., at an offset from another object’s top left corner. It also 
supports a number of computer science-specific data structures, such as arrays, 
lists or code blocks including indentation and highlighting. 
What sets ANIMAL apart from other related systems is the flexibility of pro-
viding content to the user. The presentation controls allow easy access in both 
directions and optionally also offer a “table of contents” for each animation—
provided that the animation author has populated this. More importantly, there 
are several ways how animation content can be generated: 
• Even novices can generate contents manually using drag and drop. While this 
may initially seem to be almost as time-consuming as doing it in programs such 
as PowerPoint, the support for data structures makes the process faster. Addi-
tionally, since each animation frame builds on the previous frame, the user does 
not have to copy all current elements to the next slide, as would be needed in 
presentation software such as PowerPoint or Keynote. 
• Content can be written directly in ANIMALSCRIPT. ANIMAL provides an 
online reference to the language, so that writing a syntactically correct program 
is not difficult. 
• Animations can be generated from a program by adding appropriate statements 
that will create ANIMALSCRIPT output at “interesting places.” 
• Programs can also be enriched by using the AlgoAnim API. This API will also 
create ANIMALSCRIPT output, but provides a far cleaner interface than incor-
porating the associated output statements into existing code [32]. 
• By placing output-producing programs into the generator framework, the as-
sociated programs can be run directly inside ANIMAL [33]. Additionally, this 
© 2011 by Apple Academic Press, Inc.
  

222  Computer Technology and Computer Programming: New Research and Strategies
allows the end-user to adjust parameters, such as the concrete values to be sorted 
or inserted, as well as visual properties, such as the color chosen for individual 
elements. 
Figure 5 shows an example screenshot of ANIMAL visualizing a version of 
Bubble Sort. The animation shows the array and the current values for the array 
index variables i and j. It also includes the complete source code with indentation 
below the array. The currently executing code line, in this case the inner “for” 
loop, is highlighted to make it easier for the user to link the code with the visual-
ized contents. Additionally, the value for the boolean variable “isSorted” is shown 
and the number of assignments and comparisons (“Zuweisungen” and “Vergle-
iche” in German, respectively) are visualized at the top. 
Figure 5. Example screenshot from the ANIMAL user front-end animating BubbleSort. 
© 2011 by Apple Academic Press, Inc.
  

A Family of Tools for Supporting the Learning of Programming  223
The user can navigate the animation using the basic navigation controls at the 
bottom left. Note that this also includes jumping to the start of the animation or 
taking one step backwards. ANIMAL places no limit on the number of steps to 
be taken backwards; users could easily jump to the end of the animation and then 
walk through it backwards if they wanted to do so. 
The “kiosk mode” buttons put the animation on continuous play until the 
end, or in reverse mode the beginning, of the animation has been reached. Users 
can also type in the number of the step they want to jump to, or drag the ruler 
to some point in the animation. Note that the ruler is always normalized to the 
percentage of the animation shown, and thus will always stay between 0 and 100 
(for 100%). Dragging the ruler from left to right gives a “fast fly-by overview” of 
the animation. 
One key aspect for the acceptance of algorithm visualization in a course is 
the integration of the visualization with the other lecture materials [34,35]. 
The report of an international expert group recommended what they termed 
as a visualization-based computer science hypertextbook (VizCoSH), which 
would have a structure similar to a textbook but would tightly integrate the 
teaching and learning materials with algorithm or program visualizations 
[34]. 
We have developed a VizCoSH prototype as an activity for the Moodle distrib-
uted learning environment [19]. This activity emulates a regular “textbook,” sepa-
rated into chapters and paragraphs. However, it also provides several additional 
features. For example, each paragraph can be discussed in a separate “thread” 
[35]. 
Figure 6 shows a screenshot of this activity. The top of the screen shows a 
screenshot of the animation. One click on this image will lead to an informa-
tion page about the animation, and a second click will cause the ANIMAL 
system to start up, load the animation from the web server, and display to the 
end user. Below, links to other animations are included, illustrating the way 
the algorithm—here, Insertion Sort—will behave on data placed in ascend-
ing, descending or alternating order. Additionally, users can start the built-in 
generator to generate an animation portraying how “their” custom input data 
will be sorted using Insertion Sort. The icons to the right of the main text 
provide access to the discussion about the current paragraph. The 3 next to 
the orange bubble indicates that three comments have been posted about this 
paragraph (visible to the right), while the 0 next to the blue icon shows that 
there are no private posts for this element. 
© 2011 by Apple Academic Press, Inc.
  

224  Computer Technology and Computer Programming: New Research and Strategies
Figure 6. Example screenshot of a hypertextbook with an included ANIMAL animation. 
In addition to commenting on paragraphs, users can also use a text marker, 
included above the comment threads on the right, to highlight individual words 
or passages in the text. The navigation between chapters is accomplished using 
the table of contents shown at the top of each page (missing on the screenshot), 
as well as the pair of back/forward buttons at the top and bottom of each page. 
Finally, users can print the complete “book” or a single chapter comfortably. 
The large benefit of the integration into Moodle is that the animations of al-
gorithms and data structures can now be placed together with the other learning 
materials, such as slides, exercise sheets, or homework submission and correction 
facilities. All these activities are placed in the same Moodle course, allowing stu-
dents to access them whenever needed without having to “switch context.” 
Tutorials for Teaching the Use of Eclipse 
To further enable our students to work with the comfortable but also complex 
Eclipse Java IDE, we have produced a small number of (German) screen record-
ings as tutorials. The videos were produced using the excellent Camtasia [36] 
© 2011 by Apple Academic Press, Inc.
  

A Family of Tools for Supporting the Learning of Programming  225
software, partially under Windows (Camtasia Studio 6) and under Mac OS X 
(Camtasia 1.0.1). 
Since the software is very easy to use and records the complete desktop or a 
part thereof, we first wrote a script of things we wanted to show. We defined five 
videos to be provided as tutorials: 
• Eclipse Basics presents the basics of using Eclipse: starting the IDE, explaining 
the initially visible icons, and taking a walk through the “Hello World” tutorial. 
During the programming, we have intentionally introduced a bug, in order to 
illustrate how Eclipse will highlight errors and how they can be fixed using the 
“Quick Fix” option. 
• Implementing a new class shows the implementation of a class, based on a basic 
piece of code. We show how code can be indented and formatted, and how 
mistakes can be addressed (in this case, by renaming a mistyped variable). We 
also implement the toString() method and use code completion as well as the 
generation of get-and set-methods including comments. The use of the code 
outline and the “Problems” and “JavaDoc” view is explained. The tutorial ends 
by discussing the look-up of definitions using the F3 key, using quick fixes, for-
matting source code, adding and organizing imports, and sorting members. 
• Implementing and testing a sample calculator presents a simple implementation 
of a basic calculator that is developed “live.” The tutorial starts by creating a new 
project, package, and class, and implementing several simple calculator meth-
ods, complete with some intentional bugs. We then show how a JUnit test can 
be implemented in a separate package, and how test methods are annotated with 
the @Test notation. The development of tests is done in parallel with re-runs of 
the existing and new tests. We then add an initialization method and show how 
methods not yet ready for testing can be ignored, how expected exceptions can 
be checked, and how infinite loops can be prevented during testing. 
• Extending classes illustrates how a new class can be defined to extend an existing 
class. We show one example each using an abstract and a concrete base class. We 
then repeat this by having a class implement an interface. 
• Debugging is illustrated in a separate video. Here, we use JUnit tests to pinpoint 
the offending method and code line, and then use breakpoints to narrow down 
the possible lines of code. The tutorial also shows how variables can be inspected 
and how (changed) method code can be re-run. 
Summary and Conclusions 
We have presented our tools for assisting students to learn programming Java. 
These consist of a web-based database of easy to moderately difficult programming 
© 2011 by Apple Academic Press, Inc.
  

226  Computer Technology and Computer Programming: New Research and Strategies
tasks, a system for visualizing the behavior of algorithm and data structures, and 
tutorials on how to use the Eclipse IDE. 
Our WebTasks system [23] has been in use since 2006. The system provides 
a set of programming tasks that mostly require the student to provide a method 
body. In this way, we can prevent a number of typical problems that novices to 
Java face, such as the correct use of the main method. Submissions are tested 
on upload, providing feedback within a few seconds of submitting a solution. 
Students who have solved a given task are granted access to all solutions for this 
task, so that they can look at what their peers did. They can also comment on 
other students’ solutions. The system has seen much use since its inception, with 
currently more than 10,000 (correct) submitted solutions to the more than 100 
programming tasks. 
To make understanding the dynamic behavior of algorithms and data struc-
tures easier, we provide the ANIMAL system [17,30]. ANIMAL offers full re-
versibility of the contents and thus makes following the display easier. ANIMAL 
animations typically also show the underlying source code and highlight the cur-
rently executing line, making it easier to connect the code with the visualized 
representation. 
Finally, the difficulties that especially novice programmers face when working 
with a full-fledged IDE like Eclipse are addressed by tutorial videos that illustrate 
the use of Eclipse. 
Our experiences with the tool support so far are very encouraging. Student 
feedback for the CS 1 lecture in which the tools are used has been very good, 
including winning the prize for the best lecture in the summer term 2009 
based on student evaluation results. Students also stated that using the tools 
had been a great help in getting ready to program Java and understand the 
presented algorithms. However, some students also stated that they would 
have preferred to have a single base system, rather than a set of independent 
elements. 
To provide better access to our materials, we are working on integrating both 
the WebTasks database, the algorithm visualizations and the tutorial materials 
into the Moodle Learning Management System [19]. This will allow students to 
use a single login to access all course materials, exercise their programming skills, 
and watch and interact with visualizations of algorithms and data structures. Cur-
rently, the visualization of ANIMAL content has already been implemented, and 
we are working on integrating the WebTasks database into Moodle. Once this 
integration has been accomplished, we will be glad to share the materials with 
interested educators. 
© 2011 by Apple Academic Press, Inc.
  

A Family of Tools for Supporting the Learning of Programming  227
Acknowledgements 
We gratefully acknowledge the assistance of our students who implemented parts 
of the system described in this paper, in alphabetical order: Tobias Ackermann, 
Sebastian Hartte, Stephan Mehlhase, Jens Pfau, Anselmo Stelzer, and Teena Vel-
laramkalayil. 
References
1.	 McCracken, M.; Almstrum, V.; Diaz, D.; Guzdial, M.; Hagan, D.; Kolikant, 
Y.B.D.; Laxer, C.; Thomas, L.; Utting, I.; Wilusz, T. A multi-national, multi-
institutional study of assessment of programming skills of first-year CS stu-
dents. SIGCSE Bull. 2001, 33, 125–180. 
2.	 Pillay, N.; Jugoo, V.R. An investigation into student characteristics affecting 
novice programming performance. SIGCSE Bull. 2005, 37, 107–110. 
3.	 Kouznetsova, S. Using BlueJ and Blackjack to teach object-oriented design 
concepts in CS1. J. Comput. Small Coll. 2007, 22, 49–55. 
4.	 Kölling, M., Using BlueJ to introduce programming. In Reflections on the 
Teaching of Programming: Methods and Implementations; Springer-Verlag: 
Berlin, Heidelberg, Germany, 2008; pp. 98–115. 
5.	 Barnes, D.J.; Kölling, M. Objects First with Java: A Practical Introduction Us-
ing BlueJ, 4th ed.; Prentice Hall: Upper Saddle River, NJ, USA, 2008. 
6.	 Dann, W.P.; Cooper, S.; Pausch, R. Learning to Program with Alice; Prentice 
Hall: Upper Saddle River, NJ, USA, 2006. 
7.	 Rodger, S.H.; Hayes, J.; Lezin, G.; Qin, H.; Nelson, D.; Tucker, R.; Lopez, 
M.; Cooper, S.; Dann, W.; Slater, D. Engaging middle school teachers and 
students with Alice in a diverse set of subjects. In SIGCSE ’09: Proceedings of 
the 40th ACM Technical Symposium on Computer Science Education; ACM: 
New York, NY, USA, 2009; pp. 271–275. 
8.	 Page, R.; Eastlund, C.; Felleisen, M. Functional programming and theorem 
proving for undergraduates: a progress report. In FDPE ’08: Proceedings of the 
2008 International Workshop on Functional and Declarative Programming in 
Education; ACM: New York, NY, USA, 2008; pp. 21–30. 
9.	 Bieniusa, A.; Degen, M.; Heidegger, P.; Thiemann, P.; Wehr, S.; Gasbichler, 
M.; Sperber, M.; Crestani, M.; Klaeren, H.; Knauel, E. HtDP and DMDA in 
the battlefield: A case study in first-year programming instruction. In FDPE 
’08: Proceedings of the 2008 International Workshop on Functional and  
© 2011 by Apple Academic Press, Inc.
  

228  Computer Technology and Computer Programming: New Research and Strategies
Declarative Programming in Education; ACM: New York, NY, USA, 2008; 
pp. 1–12. 
10.	 Felleisen, M.; Findler, R.B.; Flatt, M.; Krishnamurthi, S. How to Design Pro-
grams—An Introduction to Programming and Computing; MIT Press: Cam-
bridge, MA, USA, 2001. 
11.	 Gallant, R.J.; Mahmoud, Q.H. Using Greenfoot and a Moon Scenario to teach 
Java programming in CS1. In ACM-SE 46: Proceedings of the 46th Annual 
Southeast Regional Conference; ACM: New York, NY, USA, 2008; pp. 118–
121. 
12.	 Al-Bow, M.; Austin, D.; Edgington, J.; Fajardo, R.; Fishburn, J.; Lara, C.; Leu-
tenegger, S.; Meyer, S. Using Greenfoot and games to teach rising 9th and 10th 
grade novice programmers. In Sandbox ’08: Proceedings of the 2008 ACM 
SIGGRAPH Symposium on Video Games; ACM: New York, NY, USA, 2008; 
pp. 55–59. 
13.	 Kölling, M. Greenfoot: a highly graphical IDE for learning object-oriented 
programming. In ITiCSE ’08: Proceedings of the 13th Annual Conference 
on Innovation and Technology in Computer Science Education; ACM: New 
York, NY, USA, 2008; pp. 327–327. 
14.	 Academic Java. Availible online: http://academicjava.com/ (accessed on 25 
March 2010). 
15.	 Moreno, A.; Myller, N.; Sutinen, E.; Ben-Ari, M. Visualizing Programs with 
Jeliot 3. In Proceedings of the Working Conference on Advanced Visual Inter-
faces (AVI 2004); ACM Press: New York, NY, USA, 2004; pp. 373–380. 
16.	 Demetrescu, C.; Finocchi, I. A portable virtual machine for program debug-
ging and directing. In SAC ’04: Proceedings of the 2004 ACM Symposium on 
Applied Computing; ACM: New York, NY, USA, 2004; pp. 1524–1530. 
17.	 Rößling, G.; Freisleben, B. ANIMAL: A System for Supporting Multiple Roles 
in Algorithm Animation. J. Visual Lang. Computing 2002, 13, 341–354. 
18.	 Naps, T. JHAV ´E—Addressing the Need to Support Algorithm Visualization 
with Tools for Active Engagement. IEEE Comput. Graph. Appl. 2005, 25, 
49–55. 
19.	 Rice IV, W.H.; Nash, S.S. Moodle 1.9 Teaching Techniques -Creative ways to 
build powerful and effective online courses; Packt Publishing: Birmingham, 
UK, 2010. 
20.	 Joy, M.; Griffiths, N.; Boyatt, R. The Boss online submission and assessment 
system. J. Educ. Resour. Comput. 2005, 5, 2. 
© 2011 by Apple Academic Press, Inc.
  

A Family of Tools for Supporting the Learning of Programming  229
21.	 Higgins, C.A.; Gray, G.; Symeonidis, P.; Tsintsifas, A. Automated assessment 
and experiences of teaching programming. J. Educ. Resour. Comput. 2005, 5, 5. 
22.	 Edwards, S.H.; Perez-Quinones, M.A. Experiences using test-driven develop-
ment with an automated grader. J. Comput. Small Coll. 2007, 22, 44–50. 
23.	 Rößling, G.; Hartte, S. WebTasks: Online Programming Exercises Made Easy. 
In Proceedings of the 13th Annual SIGCSE Conference on Innovation and 
Technology in Computer Science Education (ITiCSE 2008); ACM Press: New 
York, NY, USA, 2008; p. 363. 
24.	 Wick, M.; Stevenson, D.; Wagner, P. Using testing and JUnit across the cur-
riculum. In SIGCSE ’05: Proceedings of the 36th SIGCSE Technical Sympo-
sium on Computer Science Education; ACM: New York, NY, USA, 2005; pp. 
236–240. 
25.	 Object Mentor. JUnit.org Resources for Test Driven Development. Available 
online: http://www. junit.org (accessed on 25 March 2010). 
26.	 Burn, O. Checkstyle 5.0. Availible online: http://checkstyle.sourceforge.net/ 
(accessed on 25 March 2010). 
27.	 Naps, T.L.; Rößling, G.; Almstrum, V.; Dann, W.; Fleischer, R.; Hundhausen, 
C.; Korhonen, A.; Malmi, L.; McNally, M.; Rodger, S.; Velazquez-Iturbide, J. 
A. Exploring the Role of Visualization and Engagement in Computer Science 
Education. ACM SIGCSE Bullet. 2003, 35, 131–152. 
28.	 Grissom, S.; McNally, M.; Naps, T.L. Algorithm Visualization in Computer 
Science Education: Comparing Levels of Student Engagement. In Proceedings 
of the First ACM Symposium on Software Visualization; ACM Press: New 
York, NY, USA, 2003; pp. 87–94. 
29.	 Urquiza-Fuentes, J.; Velazquez-Iturbide, J.A. A survey of successful evaluations 
of program visualization and algorithm animation systems. Trans. Comput. 
Educ. 2009, 9, 1–21. 
30.	 Rößling, G. Animal-Farm: An Extensible Framework for Algorithm Visualiza-
tion; VDM Verlag Dr. Mucken, Germany, 2008. 
31.	 Rößling, G.; Gliesche, F.; Jajeh, T.; Widjaja, T. Enhanced Expressiveness in 
Scripting Using ANIMALSCRIPT V2. In Proceedings of the Third Program 
Visualization Workshop, Warwick, UK, July 2004; pp. 15–19. 
32.	 Rößling, G.; Mehlhase, S.; Pfau, J. A Java API for Creating (not only) ANI-
MALSCRIPT. Electron. Note Theor. Comput. Sci. 2009, 224, 15–25. 
33.	 Rößling, G. Electr. Noteoßling, G.; Ackermann, T. A Framework for Generat-
ing AV Content on-the-fly. Theor. Comput. Sci. 2007, 178, 23–31. 
© 2011 by Apple Academic Press, Inc.
  

230  Computer Technology and Computer Programming: New Research and Strategies
34.	 Rößling, G.; Naps, T.; Hall, M.S.; Karavirta, V.; Kerren, A.; Leska, C.; More-
no, A.; Oechsle, R.; Rodger, S.H.; Urquiza-Fuentes, J.; Velazquez-Iturbide, J. 
A. Merging Interactive Visualizations with Hypertextbooks and Course Man-
agement. SIGCSE Bullet. inroad 2006, 38, 166–181. 
35.	 Rößling, G. A Visualization-Based Computer Science Hypertextbook; Vel-
laramkalayil, T. Prototype. ACM Trans. Comput. Educat. 2009, 9, 1–13. 
36.	 Aman, J.; Wilson, B.; Shirvani, S. Maintaining lecture context in a blended 
course. J. Comput. Small Coll. 2007, 23, 56–63. 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction 
Techniques in Animation of 
Recursive Programs 
J. Ángel Velázquez-Iturbide and Antonio Pérez-Carrasco
Abstract
Algorithm animations typically assist in educational tasks aimed simply at 
achieving understanding. Potentially, animations could assist in higher levels 
of cognition, such as the analysis level, but they usually fail in providing this 
support because they are not flexible or comprehensive enough. In particular, 
animations of recursion provided by educational systems hardly support the 
analysis of recursive algorithms. Here we show how to provide full support to 
the analysis of recursive algorithms. From a technical point of view, anima-
tions are enriched with interaction techniques inspired by the information vi-
sualization (InfoVis) field. Interaction tasks are presented in seven categories, 
and deal with both static visualizations and dynamic animations. All of these 
features are implemented in the SRec system, and visualizations generated by 
SRec are used to illustrate the article. 
© 2011 by Apple Academic Press, Inc.

232  Computer Technology and Computer Programming: New Research and Strategies
Keywords: program animation; program visualization; information visualization; 
recursion; human-computer interaction 
Introduction 
Recursion is a fundamental concept in Computer Science education, especially 
in programming courses. Its role varies from course to course. It is one of the 
concepts learnt in introductory courses to programming, but it is a programming 
construct applied in algorithm courses. For example, dynamic programming al-
gorithms are usually stated recursively in a first phase and transformed into a 
tabulated, iterative version in a second phase. As a consequence, an animation 
system of recursion may be a valuable tool for any course where recursion plays an 
important role, in particular in algorithm courses. 
Teaching and learning algorithms are often assisted by animations. Anima-
tions typically assist in understanding algorithms, but they could also assist in 
their analysis. We are not using the word “analysis” in any restricting sense (e.g., 
“complexity analysis”), but in the more general sense used by Bloom et al. [1]: 
“The student is able to distinguish, classify and relate hypothesis and evidences 
of the information given, as well as decomposing a problem into its parts.” 
We are interested in using animations to assist in analyzing interactively the 
behavior of recursive algorithms: in other words, we seek a kind of “software 
oscilloscope” [2] for recursion. Support for the analysis of algorithms is typically 
provided by debuggers, which are very flexible, complex systems. Therefore, ani-
mations for the analysis of recursive algorithms must exhibit as powerful visualiza-
tion features as debuggers do. We show that such analysis power can be feasibly 
achieved by using interaction techniques inspired by the information visualiza-
tion (InfoVis) field. 
In this article, we discuss and illustrate interaction techniques aimed at giving 
flexible, comprehensive support to recursion analysis in animation systems. Section 2 
shows common, effective visualizations of recursion, in general and also as supported 
by different systems, especially by the SRec system [3]. Section 3 shows interaction 
techniques tailored to the interactive analysis of recursive algorithms. These tech-
niques are classified into seven categories, and they deal with both static visualizations 
and dynamic animations. Finally, we summarize our conclusions in Section 4. 
Visualization of Recursion 
In this section, we first present different visualizations of recursion. We then pres-
ent the visualizations supported by the SRec system. Finally, we survey different 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction Techniques in Animation of Recursive Programs  233
visualization systems of recursion, and show the very limited facilities they pro-
vide to the user to interact with visualizations. In order to keep the discussion 
short, we restrict our survey to the imperative paradigm. 
Visualizations of Recursion 
There is no single visualization of recursion. A small number of visualizations 
can be found in the literature, for instance, traces, the control stack and recur-
sion trees (e.g., [4]). Another visualization, used in visualization systems, is called 
“multiple copies” (e.g., [5]) and shows a different copy of either code or data for 
each recursive call. 
We also find additional visualizations or variants of the visualizations cited 
above for specific cases of recursion. For instance, Stern and Naish [6] propose 
three visualizations for different recursive operations; their main feature is that 
they combine control and data. The most important class of recursive algorithms 
is divide-and-conquer. Variants of either traces or recursion trees have also been 
used to better illustrate divide-and-conquer algorithms [7 (p.158),8]; at each step, 
they focus on a part of the main data structure. It has also been noticed that some 
visualizations are effective both to show the inductive definition and the run-time 
behavior of divide-and-conquer algorithms, for instance, a sequence of visualiza-
tions of the main data structure [8]. 
No matter the quality of visualization, it will have merits and drawbacks and 
will be more useful for some aims. For instance, traces are good for novices, as 
they can easily follow the sequential flow of execution. Therefore, a system will 
probably be more useful if it provides multiple views, so that the user is able to 
choose the most adequate for the task she wants to perform. 
Visualizations of Recursion in SRec 
In this article, we focus on the visualizations generated by the SRec animation 
system. SRec supports visualization and animation of recursion in any Java algo-
rithm, with the only restriction of using primitive data types. Versions 1.0 and 
1.1 of SRec provided three general views (namely, traces, the control stack, and 
recursion trees) [3]. Version 1.1 enhanced substantially its interaction facilities, as 
shown here. Finally, version 1.2 of SRec supports three additional visualizations, 
specific to divide-and-conquer algorithms [8]; the system is currently capable of 
simultaneously showing two views. This evolution is partially due to the results 
of usability evaluations it has been subject to. SRec is a program animation sys-
tem that generates animations (semi)automatically. The user may load any file 
containing Java source code, and it is preprocessed. If the file contains any divide-and-
© 2011 by Apple Academic Press, Inc.
  

234  Computer Technology and Computer Programming: New Research and Strategies
conquer algorithms, the user must identify them in a dialog. Then, the user may 
launch any method invocation, and during its execution a trail of relevant events 
is generated. After completion, the user may freely interact with its visualiza-
tion and animation, which is automatically generated from the trail. The user has 
available five visualizations for divide-and-conquer algorithms and three visualiza-
tions for general recursive algorithms. We do not describe here implementation 
details, as they can be found elsewhere [9]. 
In the rest of the article, we use the well-known function fib for the Fibonacci 
series to illustrate recursive algorithms in general, and mergesort for divide-and-
conquer algorithms. 
The three general visualizations are briefly described: 
• Recursion tree. This visualization allows display of the complete history of a 
recursive process as a tree. The root corresponds to the initial invocation. The 
children of a node are the recursive calls that it has invoked, from left to right 
in chronological order. Leaves represent calls corresponding to base cases. Ev-
ery node is displayed with two areas, where the top area contains input values 
of parameters and the bottom one the result of the invocation (if the method 
does not return any value, the output state of parameters can be displayed). 
For example, Figure 1(a) displays the computation state for fib (5) where most 
recursive calls finished their execution, but the active call fib (1) and pending 
calls fib (3) and fib (5). In SRec, two states are displayed for every invocation: 
immediately after the invocation entry, and immediately before the invocation 
exit. The node framed in black in Figure 1(a) is the active node, so its computa-
tion is close to exit. Nodes framed in red correspond to pending invocations. In 
the figure, input values have a blue background and output values have a green 
background. 
• The control stack. The control stack is an internal data structure of the vir-
tual machine that makes possible the execution of programs with subrou-
tines. In SRec, records of the control stack only contain input and output 
values, so they have the same structure as the nodes of recursion trees. The 
control stack initially contains the first invocation. On entry of a method 
invocation, a new record is pushed at the top of the stack, becoming the 
active record. This new record contains input values, but the output area is 
empty. On exit of a method invocation, the output area of the record at the 
top is filled with the call results and it is later popped. Figure 1(b) displays 
the control stack at the same instant as Figure 1(a). Visualizations of the 
control stack can be quite complex [10]. Notice however that the control 
stack, as displayed by SRec, is isomorphic to the rightmost branch of its as-
sociated recursion tree. 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction Techniques in Animation of Recursive Programs  235
• Trace. A trace is a textual description of the sequence of events that take 
place during the execution of an algorithm, here entry or exit of every meth-
od invocation. Each entry (or exit) is represented as a text line that contains 
an indication that it is an entry (or exit), the method name and its actual 
parameters (or results). Using a color convention allows differentiating entry 
and exit invocations. In addition, indentation is commonly used to represent 
the level of nesting of invocations. Figure 1(c) contains a trace of the same 
computation of fib (5). Notice that the trace is isomorphic to a traversal of 
the recursion tree, where input values are printed inorder and ouput values 
are printed postorder. 
Figure 1. Three visualizations of fib (5): (a) recursion tree, (b) control stack, and (c) trace. 
Three additional representations, specific for divide-and-conquer algorithms, 
are supported by SRec. We briefly explain them below: 
• Divide-and-conquer recursion tree. Divide-and-conquer algorithms typically 
manipulate a large data structure, but in most recursive calls, the focus of inter-
est is limited to a part of it (i.e. a substructure). An effective variant of recursion 
trees for divide-and-conquer algorithms consists of displaying the whole structure 
© 2011 by Apple Academic Press, Inc.
  

236  Computer Technology and Computer Programming: New Research and Strategies
with the relevant substructure highlighted. SRec supports this additional display 
for vectors and matrices. Figure 2(a) shows this representation when mergesort-
ing the array {0,4,9,6,8,3}. 
• Sequence of visualizations of the data structure. This representation consists of a 
sequence of visualizations of the state of the data structure, displayed top-down. 
It can be considered a variant of the trace visualization, which differs in the 
layout and in the amount of information displayed. Every time a recursive call 
is invoked, the array state is displayed. In order to better illustrate the algorithm 
behavior, each line only shows the subarray delimited in the recursive call. Every 
time a recursive call exits, the output state of its associated subarray is displayed 
adjacent to its input state. Again, the relative placement and the use of colors 
allow differentiating input and output states of subarrays. Figure 2(b) shows this 
view at the same state as Figure 2(a). 
• Colored data structure. This is a mixed view that displays both the state of the 
data structure to manipulate and hints about the recursive process. In particular, 
if the data structure is a vector, a set of bars is displayed below the vector. The 
bars mirror the recursive process by underlining the subarray delimited in each 
recursive call. A coloring scheme that distinguishes input and output is also 
applied here. For each underlying bar, the coloring scheme indicates whether 
the corresponding recursive call is pending or finished. For each subarray, the 
scheme indicates whether the last update of its state by a recursive invocation 
was made with input or output values. Tones are also used to represent the dis-
tance in the activation tree to the active call. Figure 2(c) shows this representa-
tion at the same instant as Figure 2(a). 
Systems for Recursion Animation 
Programming environments fully support the analysis of execution, but they 
hardly support specific analysis of recursion. These are the most promising sys-
tems to analyze recursion, as they have available all the information on program 
execution, which should be rendered and interacted with adequate user interfaces. 
We point out ETV [11], a tool that allows visualizing the execution of a C++ 
program from the trace generated in execution time. 
Some systems were specifically designed to learn recursion. Most of them are 
based on the “copies model” of recursion, that is, they show a different copy of 
either code or data for each recursive call. We may cite Recursion Animator [5], 
SimRECUR [12], Function Visualizer [13] and EROSI [14]. Flopex 2 [15] is an 
Excel extension for visual programming. EROSI, Recursion Animator and Sim-
RECUR have been successfully evaluated. 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction Techniques in Animation of Recursive Programs  237
We have compared SRec to these systems with respect to several issues: gener-
ality, effort to construct animations, visualization and animation features, and in-
teraction features. We used two features to characterize system generality, namely 
methods to visualize, and range of types and input data supported. With respect 
to the methods visualized, Function Visualizer and Recursion Animator only vi-
sualize the first written method, while ETV and SRec are more flexible as they 
allow selecting any method. Only SRec allows changing interactively the set of vi-
sualizable methods. With respect to the range of types and input data supported, 
the literature reports that EROSI and SimRECUR are (again) very restrictive, 
SRec supports primitive data types, and the rest of the systems “seem” to allow 
any Java data type. 
Figure 2. Three visualizations of mergesort ({0,4,9,6,8,3}): (a) divide-and-conquer recursion tree, (b) sequence 
of visualizations of a data structure, and (c) colored data structure. 
The second feature we compared was the effort required for constructing ani-
mations. EROSI and SimRECUR only visualize predefined examples, Flopex 2 
© 2011 by Apple Academic Press, Inc.
  

238  Computer Technology and Computer Programming: New Research and Strategies
requires user construction of the recursion visualization, and the other four sys-
tems (including SRec) are automatic, which is the most comfortable method to 
construct animations. 
The comparison with respect to visualization and animation features can be 
found in Table 1. Notice that SRec is the system that offers more views and has 
the most complete set of animation controls. 
Finally, we found very few interaction facilities in most systems (with the ex-
ception of SRec). According to the system descriptions available in the literature, 
these systems do not have interaction facilities except for animation. The excep-
tion is ETV, which allows expanding/contracting nodes in the recursion tree, and 
transferring control to the entry of a function call. 
Table 1. Comparison of visualization and animation features in several animation systems of recursion. 
Interacting with Visualizations and Animations 
of Recursion 
Effective algorithm analysis demands more than static visualizations, but ad-
vanced interaction to give the user the capability to enquire flexibly. As there are 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction Techniques in Animation of Recursive Programs  239
many ways of interacting with visualizations, we need a framework to analyze 
interaction support. Consequently, we adopt a comprehensive framework [16] 
from information visualization, a very demanding field in this regard. The authors 
classify different kinds of interaction into seven categories, namely encode, con-
nect, filter, abstract/elaborate, explore, reconfigure, and select. 
However, we must bring attention to an important issue. Program visualiza-
tion can be considered a subfield of information visualization, but it also has some 
specific features. In particular, programs may be visualized statically “in space” 
(i.e., their declaration or their state), but also dynamically “in time” (i.e., evolu-
tion of its state during execution). This feature is called program animation, and 
the most common interaction techniques are animation controls. As we are deal-
ing with program visualizations, we take this duality space-time into account. 
In the following, we show how the categories can be effectively used to interact 
with recursion. Each category is first introduced by quoting a sentence from [16] 
that summarizes its meaning. Then, we present techniques of that category that 
allow interacting with recursion visualizations, both static and dynamic. 
Encode 
“Encode interaction techniques enable users to alter the fundamental visual rep-
resentation of the data including visual appearance (e.g., color, size, and shape) 
[16].” 
According to this definition, the most straightforward alteration consists of 
changing visual appearance. For example, Figure 3(a) displays the same computa-
tion state as Figure 1(a), close to execution termination. Changing colors and line 
and border styles leads to Figure 3(b). 
More drastic variations lead to different graphical representations of the same 
information, i.e., multiple views. We identified alternative views of recursion in 
Sections 2.1 and 2.2. Figure 4 shows two views, as displayed by the SRec system, 
of a computation state of fib (11). The views are contained in the central and right 
panels; corresponding to a recursion tree and control stack, respectively. The left 
panel contains the algorithm source code. 
Connect 
“Connect refers to interaction techniques that are used to (1) highlight associa-
tions and relationships between data items that are already represented, and (2) 
show hidden data items that are relevant to a specified item [16].” 
© 2011 by Apple Academic Press, Inc.
  

240  Computer Technology and Computer Programming: New Research and Strategies
The most important relationship in recursion connects caller and called invo-
cations. No special interaction must be provided to the user since this relationship 
is explicitly shown in the different views (see Figure 1). The control stack and 
recursion trees encode it with arcs or arrows. Traces suggest it with typographic 
means, especially indentation. 
Another relationship connects input and output values of a given invocation. 
Again, this connection is explicitly shown. The control stack and recursion trees 
encode it as the two halves of a given node. Traces represent it with typographic 
means, especially indentation. 
Multiples views are not independent of each other, but they are coordinated. 
Coordination may be shown in two ways. Firstly, by synchronizing the informa-
tion displayed in the views during an animation. Secondly, by having the views 
sharing visual conventions in the different representations used for the same ob-
jects. The two views in Figure 4 represent the same state of computation. They 
share color conventions and spatial orientation. 
Finally, relevant events in an animation are usually connected by means of the 
animation controls. For instance, entry and exit of an invocation can be animated 
adjacent in time by means of a “step over” control. 
Figure 3. Recursion tree for fib (5): (a) basic visualization (b–e) variants. 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction Techniques in Animation of Recursive Programs  241
Filter 
“Filter interaction techniques enable users to change the set of data items being 
presented based on some specific conditions [16].” 
Filtering can be applied to recursion trees in several ways. Firstly, we may omit 
input or output values. By displaying input, we give information about the recur-
sive structure of the algorithm, while also showing output gives the computation 
results. Leaving visible only the output can be useful for prediction exercises. For 
instance, Figure 3(c) is obtained from Figure 3(a) by omitting input. Notice that 
the two pending calls, squared in red, have no value inside.
Figure 4. The user interface of SRec, with the source code and two views of recursion for fib (11).
Secondly, past recursive calls that have finished execution can be filtered. 
Showing all the nodes in the recursion tree displays the complete history of the al-
gorithm. Alternatively, showing only pending nodes and the active one produces a 
display of the current state of execution. An intermediate display consists of blur-
ring finished nodes. Figure 3(d) and Figure 3(e) show the two latter possibilities. 
A related kind of filter can be applied to recursive invocations produced by 
a particular invocation. In the recursion tree, they generate a subtree with the 
© 2011 by Apple Academic Press, Inc.
  

242  Computer Technology and Computer Programming: New Research and Strategies
particular invocation as the root. An animation control to “step over” can either 
display or omit the resulting subtree; in any of these cases, its result is displayed. 
Finally, filtering can be applied to the parameters, return values and methods 
to visualize. For instance, the three recursion trees shown in Figure 5 were gener-
ated on mergesorting the array {0,4,9,6,8,3}. 
Figure 5(a) is a comprehensive picture of the computation actually performed. 
It displays an initial call to the main method (in the figure, s for sort) and calls to 
a recursive method (ms for msort) and to an auxiliary method (me for merge). In 
order to keep the visualization manageable, only some input values are displayed, 
namely the original array in the main method and the indices that bound the 
subarray in each call in the other two methods. 
Figure 5. Recursion tree variants for mergesort({0,4,9,6,8,3}). 
Figure 5(b) is similar, but focuses on the recursive structure of msort by fil-
tering the other two methods. As the resulting recursion tree is smaller, we may 
display more input values and also output values. Thus, Figure 5(c) shows the 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction Techniques in Animation of Recursive Programs  243
resulting recursion tree, where each node contains two occurrences of the array to 
sort: its input state and its output state. 
A facility complementary to filtering is semantic zoom, which can be applied 
to obtain full information of a given node. Positioning the mouse over the node 
and pressing the left button results in popping-up a small window that contains 
the values of all its parameter and result values. Figure 6 illustrates the effect of se-
mantically zooming a given node of the recursion tree displayed in Figure 5(b). 
Figure 6. Semantic zoom on a node of the recursion tree for mergesort({0,4,9,6,8,3}). 
Abstract/Elaborate 
“Abstract/elaborate interaction techniques provide users with the ability to change 
the level of abstraction of a data representation [16].” 
The level of abstraction is always kept equal in visualizations of recursion. 
However, we may achieve a higher level of abstraction by displaying on demand 
global information about the number of several kinds of nodes in an animation 
(e.g., visible nodes, past nodes, highlighted nodes, etc.). Semantic zooming can 
also be used to give global information about a given node (e.g., its relative num-
ber of invocation or the number of descendant nodes that descend from it). 
Explore 
“Explore interaction techniques enable users to examine a different subset of data 
cases [16].” 
This category is especially important to handle large visualizations. SRec 
supports two ways of selecting a subset of information in a visualization of  
recursion: 
• Panning+scrolling. Panning is another name for geometric zooming, which al-
lows changing the scale of the visualization and therefore the amount of infor-
mation that fits the screen. When a visualization does not fit its enclosing panel, 
© 2011 by Apple Academic Press, Inc.
  

244  Computer Technology and Computer Programming: New Research and Strategies
a scroll bar may be provided to allow the user to select the part that she wishes 
to focus on. 
• Overview+detail. Panning+scrolling allows navigating, but if the visualiza-
tion is much larger than the part visible in a panel, the user may get lost. An 
overview+detail interface provides two complementary views: the “detail” view 
makes readable a part of the visualization and the “overview” gives a sketch 
of the global view of the visualization, identifying the position of the “detail” 
view. 
Figure 4 contains visual cues of the first two of these interaction techniques. 
Several icons for zooming (that display a lens) can be identified at the right of the 
icon bar. The panels for traces and for recursion trees have their scrolling bars ac-
tivated to navigate. Finally, the recursion tree panel is split into two parts, jointly 
providing an overview+detail interface. 
Interaction techniques to explore time are typically provided as animation 
controls. Figure 4 shows a computation state close to its end. Program anima-
tion is controlled with the animation bar available at the top right corner. As the 
animation advances, new recursion nodes are generated. Nodes corresponding to 
finished calls may be kept or disappear from the visualization, depending on the 
particular view or user settings. 
Reconfigure 
“Reconfigure interaction techniques provide users with different perspec-
tives onto the data set by changing the spatial arrangement of representations 
[16].” 
The visualizations can be slightly reconfigured with certain customization 
options, e.g., distances between sibling nodes in a recursion tree. However, 
reconfiguring can be produced by other criteria, for example, where to place 
subarrays in the sequence of visualizations of the data structure. Figure 7 
shows two chronological sequences of subarrays of {0,4,9,6,8,3} on call entry 
and exit. Figure 7(a) keeps entry and exit states of subarrays joint for each call, 
while in Figure 7(b) they are separated and strict chronological order is used 
to display subarrays. 
Reconfiguration also makes sense in relation to multiple views. The screen 
usually only provides space for displaying a few views in an understandable way. 
The user should be allowed to choose the views to display and their relative posi-
tion. In Figure 4, the user selected two views and to display them vertically. This 
layout allows optimizing the space necessary to display the control stack, thus 
leaving more space for the recursion tree. 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction Techniques in Animation of Recursive Programs  245
Select 
“Select interaction techniques provide users with the ability to mark a data item 
of interest to keep track of it [16].” 
A user of a program visualization system may be interested in selecting infor-
mation either in space or in time. A case of selection in space consists of iden-
tifying multiple occurrences of a given node in a redundant algorithm, such as 
fibonacci. A dialog is enough to enter the input or output values that identify the 
target nodes. Figure 8 shows the recursion tree included in Figure 4, correspond-
ing to fib (11), after selecting nodes corresponding to fib (3). The selected nodes 
are highlighted in orange.
Figure 7. Two rearrangements of a sequence of array states for mergesort({0,4,9,6,8,3}). 
© 2011 by Apple Academic Press, Inc.
  

246  Computer Technology and Computer Programming: New Research and Strategies
With respect to time, the user may be interested in moving to a particular in-
stant of the animation. The interaction may consist in positioning the mouse over 
a node of the recursion tree and pressing the right bottom to make it the active 
node in the animation. 
Figure 8. Recursion tree for fib (11) with the nodes corresponding to fib (3) highlighted. 
Conclusions 
This article demonstrates techniques to support flexible analysis of recursive algo-
rithms by means of enhanced interaction features. All of these features are imple-
mented in the SRec system and were illustrated in the paper. We have also shown 
that interaction facilities in other animation systems of recursion are very limited. 
The SRec system and related information and documentation (including user 
manual and the results of usability evaluations) are freely available at the following 
URL: http://lite.etsii.urjc.es/srec. 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction Techniques in Animation of Recursive Programs  247
Much effort has been devoted in the two last decades to educational uses 
of algorithm animations. Their main drawbacks for general adoption have been 
identified elsewhere [17]: 
• Lack of evidence of their educational efficiency. 
• Heavy workload posed on animation constructors (typically, the instructors). 
Our current study dealt with both these problems. With respect to the issue 
of educational effectiveness, notice that educational effectiveness of animations 
requires student engagement [17,18]. Our proposal for enhanced interactivity 
provides attractive visual tools to engage students in analysis tasks. 
The issue of construction effort is also addressed by our contribution. In ef-
fect, automation and interaction are two of the four issues identified in a previous 
proposal [19] to identify “effortless” systems. The issue of improving interaction 
is clearly addressed in our study. With respect to automation, our approach to 
deliver program visualizations more easily supports flexible interaction by using 
processing language techniques. Program processing generates an annotated, in-
termediate representation of the program that allows gathering relevant infor-
mation in run-time. Execution information can be displayed by the animation 
system to the user by means of its interaction facilities. User effort is then reduced 
to interacting with the system. 
studying how to enhance visualization and interaction in animation systems 
to assist different user tasks is promising for programming education. We also 
plan to extend this work in several directions. Firstly, the comparison between 
SRec and other systems included one general program animation system (namely 
ETV), but the comparison should be extended to other general systems. Secondly, 
SRec can benefit from some additional interaction facilities; the work of Yi et al. 
[16] provides a good framework to identify such improvements. Finally, it would 
be very valuable for instructors to design a more structured mapping between 
interaction techniques and learning tasks. 
Acknowledgements 
This work was supported by project TIN2008-04103 of the Spanish Ministry of 
Science and Innovation. 
References 
1.	 Bloom, B.; Furst, E.; Hill, W.; Krathwohl, D.R. Taxonomy of Educational 
Objectives: Handbook I, The Cognitive Domain; Longmans: New York, NY, 
USA, 1959. 
© 2011 by Apple Academic Press, Inc.
  

248  Computer Technology and Computer Programming: New Research and Strategies
2.	 Böcker, H.D.; Fisher, G.; Nieper, H. The enhancement of understanding 
through visual representations. In Proceedings of the ACM SIGCHI Confer-
ence on Human Factors in Computing, Boston, MA, USA, April 1986; pp. 
44–50. 
3.	 Velázquez-Iturbide, J.Á.; Pérez-Carrasco, A.; Urquiza-Fuentes, J. SRec: An ani-
mation system of recursion for algorithm courses. In Proceedings of the 13th 
Annual Conference Innovation and Technology in Computer Science Educa-
tion, Madrid, Spain, June 2008; pp. 225–229. 
4.	 Haynes, S.M. Explaining recursion to the unsophisticated. ACM SIGCSE Bul-
letin 1995, 27, 3-6 and 14. 
5.	 Wilcocks, D.; Sanders, I. Animating recursion as an aid to instruction. Com-
put. Educ. 1994, 23, 221–226. 
6.	 Stern, L.; Naish, L. Visual representations for recursive algorithms. In Proceed-
ings of the 33rd SIGCSE technical symposium on Computer science educa-
tion, Cincinnati, KY, USA, February 2002; pp. 196–200. 
7.	 Software Visualization; Stasko, J.T., Domingue, J., Brown, M.H., Price, B.A., 
eds.; MIT Press: Cambridge, MA, USA, 1997. 
8.	 Velázquez-Iturbide, J.Á.; Pérez-Carrasco, A.; Urquiza-Fuentes, J. A design of 
automatic visualizations for divide-and-conquer algorithms. Electr. N. Theor. 
Comput. Sci. 2009, 224, 113–120. 
9.	 Fernández-Muñoz, L.; Pérez-Carrasco, A.; Velázquez-Iturbide, J.Á.; Urquiza-
Fuentes, J. A framework for the automatic generation of algorithm animations 
based on design techniques. In Proceedings of the Second European Confer-
ence on Technology Enhanced Learning, Crete, Greece, September 2007; pp. 
475–480. 
10.	 Velázquez-Iturbide, J.Á. Formalization of the control stack. ACM SIGPLAN 
Notices 1989, 24, 46–54. 
11.	 Terada, M. ETV: A program trace player for students. In Proceedings of the 
10th Annual Conference Innovation and Technology in Computer Science 
Education, Monte da Caparica, Portugal, June 2005; pp. 118–122. 
12.	 Wu, C.C.; Lin, J.M.C.; Hsu, I.Y.W. Closed laboratories using SimLIST and 
SimRECUR. Comput. Educat. 1997, 28, 55–64. 
13.	 Dershem, H.L.; Parker, D.E.; Weinhold, R. A Java function visualizer. J. Com-
put. Small Coll. 1999, 15, 220–230. 
14.	 George, C.E. EROSII Visualizing recursion and discovering new errors. In 
Proceedings of the SIGCSE’00, Austin, TX, USA, March 2000; pp. 305–309. 
© 2011 by Apple Academic Press, Inc.
  

InfoVis Interaction Techniques in Animation of Recursive Programs  249
15.	 Eskola, J.; Tarhio, J. On visualization of recursion with Excel. In Proceedings 
of the Second Program Visualization Workshop, HornstrupCentret, Denmark, 
June 2002; pp. 45–51. 
16.	 Yi, J.S.; Kang, Y.; Stasko, J.; Jacko, J.A. Toward a deeper understanding of the 
role of interaction in information visualization. IEEE Trans. Visualiz. Comput. 
Graph. 2007, 13, 1224–1231. 
17.	 Naps, T.; Roessling, G.; Almstrum, V.; Dann, W.; Fleischer, R.; Hundhausen, 
C.; Korhonen, A.; Malmi, L.; McNally, M.; Rodger, S.; Velázquez-Iturbide, 
J.Á. Exploring the role of visualization and engagement in computer science 
education. ACM SIGCSE Bulletin 2003, 35, 131–152. 
18.	 Hundhausen, C.; Douglas, S.; Stasko, J. A meta-study of algorithm visualiza-
tion effectiveness. J. Vis. Lang. Comput. 2002, 13, 259–290. 
19.	 Ihantola, P.; Karavirta, V.; Korhonen, A.; Nikander, J. Taxonomy of effortless 
creation of algorithm visualization. In Proceedings of the International Work-
shop on Computing Education Research, Seattle, WA, USA, October 2005; 
pp. 123–133.
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game 
to Help Students Learn 
Computer Programming
Mathieu Muratet, Patrice Torguet, Jean-Pierre Jesse  
and Fabienne Viallet
Abstract
Video games are part of our culture like TV, movies, and books. We believe 
that this kind of software can be used to increase students’ interest in comput-
er science. Video games with other goals than entertainment, serious games, 
are present, today, in several fields such as education, government, health, de-
fence, industry, civil security, and science. This paper presents a study around 
a serious game dedicated to strengthening programming skills. Real-Time 
Strategy, which is a popular game genre, seems to be the most suitable kind of 
game to support such a serious game. From programming teaching features to 
video game characteristics, we define a teaching organisation to experiment if 
a serious game can be adapted to learn programming.
© 2011 by Apple Academic Press, Inc.

Towards a Serious Game to Help Students Learn Computer Programming  251
Introduction
Since the first boom of video games in the 80s, the gaming industry has held an 
important place in the world market. According to the Entertainment Software 
Association figures (http://www.theesa.com/facts/pdfs/ESA_EF_2008.pdf) ac-
cessed 26 August 2008, in 2007 the market of U.S. computer and video games 
amounts to $9.5 billion. This is almost equal to the U.S. movie market (http://
www.the-numbers.com/market/2007.php) accessed 26 August 2008 ($9.6 billion 
in 2007). Students currently in university were born with video games, which are 
as much a part of their culture as TV, movies, or books.
However, to progress in video games, the player must at the same time play 
and learn. Serious games use this feature to interest players in specific topics, teach 
some specific educational content, or train workers to specific tasks. The idea is 
that entertainment can lead to learning if some specific constraints are respected.
On the other hand, all over the world, students are becoming less interested in 
science. In computer science, for example, according to Crenshaw et al. [1] and 
Kelleher [2], the number of students is shrinking. Moreover, “colleges and uni-
versities routinely report that 50% or more of those students who initially choose 
computer science study soon decide to abandon it” [3, page 39]. Our university 
experiences the same phenomenon with a decrease of 16.6% over the last four 
years in students studying computer science.
Therefore, in the computer science education research field, there is an impor-
tant area directed to the recruitment and retention of students [4]. A promising 
way explored by this specific research is using games to teach and learn program-
ming [5]. It allows students to better learn in a familiar and playful environment. 
Moreover, it promotes collaborative learning and spurs student to learn.
We propose to study if serious games, which can be collaborative learning 
games, could be of value in order to teach programming and to attract and keep 
computer science students. The question is: Is it interesting to use a serious game 
for teaching programming?
To achieve this goal, we propose the methodology of design experiments [6]: 
“prototypically, design experiments entail both “engineering” particular forms of 
learning and systematically studying those forms of learning within the context 
defined by the means of supporting them. This designed context is subject to test 
and revision, and the successive iterations that result play a role similar to that 
of systematic variation in experiment.” The intent of this methodology in edu-
cational research is to investigate the possibilities for educational improvement 
by bringing about new forms of learning in order to study them. Because designs 
are typically test-beds for innovation, the nature of the methodology is highly  
© 2011 by Apple Academic Press, Inc.
  

252  Computer Technology and Computer Programming: New Research and Strategies
interventionist, involving a research team, one or more teachers, at least one stu-
dent, and eventually school administrators. Design contexts are conceptualized 
as interacting systems and are implemented with a hypothesized learning process 
and the means of supporting it. Although design experiments are conducted in a 
limited number of settings, they aim to develop a relatively humble theory that 
targets a domain specific learning process. To prepare a design experiment, the 
research team has to define a theoretical intent and specify disciplinary ideas and 
forms of teaching that constitute the prospective goals or endpoints to student 
learning. The challenge is to formulate a design that embodies testable conjectures 
about both significant shifts in student learning and the specific means of sup-
porting those shifts. In our experiment, the theory we attempt to develop is the 
process of learning programming through serious games. In this paper, we discuss 
how to build a design context that will allow us to construct several conjectures to 
test our theory about an original form of programming teaching.
In the rest of this paper, we define briefly what a serious game is and what its 
learning aims are. After presenting programming teaching features and associated 
environment, we analyse some of them in reference to learning objectives and se-
rious games features. Because there is currently no serious game dedicated to this 
field and suitable to design experiments, the rest of the paper presents the serious 
game we built. Section 4 presents how we chose the video game that supports our 
serious game. Section 5 details the implementation of our serious game. Section 
6 describes how learning objectives are mapped into the game from the student, 
teacher, and knowledge points of view. Section 7 explains how we will conduct 
our first experiment.
Serious Games
Definitions
For Zyda [7], a serious game is “a mental contest, played with a computer in ac-
cordance with specific rules, that uses entertainment to further government or 
corporate training, education, health, public policy, and strategic communication 
objectives.” Thus, any video game built to differ from pure entertainment can be 
considered as a serious game. Serious games represent, therefore, a wide range 
of digital games. Blackman [8] gives a synopsis of the gaming industry and its 
applications. Sophisticated video game graphic engines are nowadays used for 
nongame applications because they offer real-time rendering and physical models. 
Applications such as simulators can use such video game technologies. Serious 
games are not restricted to video games; they can also be based on simulators. 
Figure 1 illustrates the relationship between video games, simulators, and serious 
games. 
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  253
Figure 1. Relation between video games, simulators, and serious games.
Example of Serious Games
To highlight the relationship between the target public and serious game objec-
tives we present three examples of serious games following different aims: “Darfur 
is Dying” (http://www.darfurisdying.com/) accessed 30 November 2008, “Tac-
tical Language & Culture” (http://www.tacticallanguage.com/) accessed 30 No-
vember 2008, and “America’s Army” (http://www.americasarmy.com/) accessed 
30 November 2008; “Darfur is Dying” is a game developed in partnership with 
the Reebok Human Rights Foundation and the International Crisis Group. The 
purpose of this game is to increase public awareness of the crisis in Darfur. The 
player controls a Darfurian who forages for water and develops his/her camp. 
Because the objective was to reach a maximum of people, “Darfur is Dying” is a 
minigame based on a platform game genre easy to play even for nongamers. It is 
free and accessible by everyone.
“Tactical Language & Culture” is a game started in 2003 as a research project 
at the University of Southern California’s Information Sciences Institute under 
funding from the Defence Advanced Research Projects Agency (DARPA). Its pur-
pose is to teach foreign languages and cultural knowledge needed to conduct tasks 
effectively and safely during both daily life and military missions. Currently, it of-
fers courses in Iraqi Arabic language and culture (Tactical Iraqi), Pashto language 
and culture for the Pashtun regions of Afghanistan (Tactical Pashto), and French 
as spoken in the countries of Sahel Africa (Tactical French). “Tactical Language & 
Culture” is a complex game targeted for servicemen. It is based on a role-playing 
game genre to enable an immersive communication with virtual avatars in the 
game. It is played in interaction with a virtual tutor who evaluates the learner’s 
speech and gives feedback on errors.
“America’s Army” is a game launched in July 2002 designed by the Modelling, 
Virtual Environments, and Simulation (MOVES) Institute at the Naval Postgrad-
uate School in Monterey, Calif, USA. It was initially built as a recruiting tool for 
the United States of America’s army. However it became the first really successful 
serious game and is currently one of the ten most popular PC action games played 
online. “America’s Army” is a complex game based on a shooter game genre to im-
merse the player in action. It is a free multiplayer game requiring a team effort.
© 2011 by Apple Academic Press, Inc.
  

254  Computer Technology and Computer Programming: New Research and Strategies
These serious games use entertainment to pursue different learning objectives: 
“Darfur is dying” tries to raise public awareness; “Tactical Language & Culture” 
aims to learn foreign languages and cultures; “America’s Army” tries to attract 
young people to join the US Army.
Video Games
Serious games are mainly based on video games that define their usability. Accord-
ing to the aims of the serious game, the video games characteristics of game genre, 
game mode, and game complexity define the target audience. The game genre is 
used to classify video games. Some examples are “shooters” like “Doom” series or 
“Counter Strike” (players combat several characters with projectile weapons, such 
as guns or missiles), “sports” like “Pro Evolution Soccer” or “Virtual Tennis” series 
(emulates the playing of traditional physical sports), “strategy” like “Age of Em-
pires” or “Civilization” series (players control an army and command it to achieve 
objectives), or “role-playing” like “Final Fantasy” series or “World of Warcraft” 
(players are cast in the role of one or more “adventurers” to progress through a 
predetermined storyline).
We define the game mode as the networked nature of the game. Single player 
refers to a game, where only one player can interact with the game. The player 
plays against preprogrammed challenges and/or opponents controlled by Artifi-
cial Intelligences (AI). A multiplayer mode allows players to interact with each 
other. Partnerships, cooperation, competitions, or rivalries emerge to provide a 
form of social communication.
The Game complexity refers as in [9] to the duration of the game. Minigames 
or trivial games take less than one hour to complete, treat only one subject, puz-
zle, or game play type in a small way. Complex games take more than ten hours 
to complete, provide a sophisticated mixture of difficult challenges that typically 
intertwine and support each other. Main features of complex games are levelling-
up, adaptability, clear and worthwhile goals, interaction with other players, and 
shared experiences.
The choice of a game genre, a game mode, and the complexity of the video 
game is a crucial point to be in agreement with the target audience and the serious 
game objectives.
Serious Games and Learning
The critical point of serious games is the relationship between the game and the 
educational content: Zyda [7] wrote that “Pedagogy must be subordinate to story—
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  255
the entertainment component comes first.” A hypothesis is that if the game is 
attractive, fun, and stimulating, and encourages the player to progress, then she/
he will automatically learn skills from the game and will absorb a lot of informa-
tion. What about serious games devoted to teaching how to program? Is there a 
need for such tools?
Programming Fundamentals Learning
In order to determine if serious games can be useful for teaching programming, 
we present educational features, bring to light problems encountered by students, 
and expose different solutions proposed by teachers. Among the developed tools 
devoted to this field, we chose to analyse some of them in reference to learning 
objectives and serious games features.
Features
An ACM/IEEE report [3] provides an overview of the different kinds of under-
graduate degree curricula in computing. This report divides computing in five 
major disciplines: Computer Engineering (CE), Computer Science (CS), Infor-
mation Systems (IS), Information Technology (IT), and Software Engineering 
(SE). It shows that the most important requirement for all these disciplines is the 
“Programming Fundamentals” topic, and the ability to “Do small-scale program-
ming” is the most expected performance capability. The requirements of “Pro-
gramming fundamentals” (PFs) are detailed in another report [10], which defines 
precisely the features of programming courses and outlines a set of recommenda-
tions for undergraduate curricula. It is divided in 5 core units: fundamental pro-
gramming constructs (PF1), algorithms and problem solving (PF2), fundamental 
data structures (PF3), recursion (PF4), and event-driven programming (PF5). 
There are no recommendations on the programming language used for teaching. 
The main topics taught in PF are variables, types, expressions, assignments, simple 
Input/Output, conditional and iterative control structures, functions, parameter 
passing, arrays, and records.
Problems
Programming fundamentals are hard skills to learn, especially for novices, for sev-
eral reasons. First, students encounter some unexpected epistemological obstacles, 
like learning looping constructs [11, 12], conditionals, or assembling programs 
out of base components: “Data structure and algorithms […] are often difficult 
© 2011 by Apple Academic Press, Inc.
  

256  Computer Technology and Computer Programming: New Research and Strategies
issues, since capturing the dynamic nature of abstract algorithms is not a straight-
forward task” [13]. Thus, “the lack of student programming skill even after a year 
of undergraduate studies in computer science was noted and measured in the 
early 80’s [14] and again in this decade [15]” [4, page 127].
Second, the computer environment they use daily, to play or chat for example, 
is very different from the one they use for learning and they do not immediately 
see the connection between the two universes: “People studying pedagogical tech-
niques agree that students who are new to computer science typically find the field 
full of theoretical, technical, or even tedious concepts” [16].
Third, learning how to program assumes lectures, classes, and practice ses-
sions. To be able to program, students need to know programming skills and 
concepts, but to learn those skills and concepts they have to practice program-
ming. Dealing with this paradox, Greitzer et al. [9] explain in particular that “an 
effective approach is to encourage learners to work immediately on meaningful, 
realistic tasks.”
Some Solutions
To the question as to what makes programming easier for novices and what helps 
students to acquire programming fundamentals, a great many answers are pro-
posed in the literature. For example, Stevenson and Wagner [17] analyse assign-
ments from textbooks and historical usage to look for student’s problems and pro-
pose a set of characteristics and assignments that should be a “good programming 
assignment” in CS1: (1) be based on a real-world problem; (2) allow the students 
to generate a realistic solution to that problem; (3) allow them to focus on current 
topic(s) from class within the context of larger programs; (4) be challenging; (5) 
be interesting; (6) make use of one or more existing application programming 
interfaces (APIs); (7) have multiple levels of challenge and achievement, thus sup-
porting possible refactoring; (8) allow some creativity and innovation. To imple-
ment this assignment, the authors propose a CS1 project based on a web crawler 
and a spam evaluator.
Another trend, studying how students relate to computer science and why 
they quit, has shown that a lack of meaning and relevance is key issues that create 
distaste for the discipline [4, page 150]. One answer is to develop specific inter-
esting and relevant computational artefacts that have meaning for students. In 
this direction, three approaches exist: (1) building novice-programming environ-
ments, using (2) programming contests or (3) video games.
Many novice-programming environments have been built. Most of them 
use block-based graphical languages. This programming metaphor allows students 
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  257
to forget syntax and directly experiment with programming. Here are a few  
examples.
(i)	 StarLogo The Next Generation [18] uses computer game design as the 
motivation and theme to introduce programming to middle or high 
school students. It is a modelling and simulation software. Students and 
teachers use agents-based programming and 3D graphics to create and 
understand simulations and complex systems.
(ii)	 Scratch [19] is a programming language that makes it easy to create inter-
active stories, animations, games, music, and art and share them through 
the web. It is designed to help young people (ages 8 and up) develop 
learning skills from several disciplines. As they create Scratch projects, 
young people learn important mathematical and computational ideas, 
while also gaining a deeper understanding of the process of design.
(iii)	 Alice2 [20] is a programming environment designed for teaching pro-
gramming while building 3D virtual worlds. This drag and drop program-
ming system allows users to experiment with the logic and programming 
structures taught in introductory programming classes without making 
syntax errors. It allows users to experiment with conditionals, loops, vari-
ables, parameters, and procedures.
(iv)	 Cleogo [21] is a groupware environment that allows several users to si-
multaneously develop programs through any mixture of three alternative 
programming metaphors: a direct manipulation language for program-
ming by demonstration an iconic language and a standard text-based lan-
guage. Cleogo is motivated by the pedagogical values of peer learning and 
of collaborative problem solving, at home and at work.
The second approach consists in using competition to motivate students. 
Robocode (http://robocode.sourceforge.net/) accessed 17 April 2007, is a Java 
programming game, where the goal is to develop a robot battle tank to battle 
against other tanks programmed by other players. It is designed to help people 
learn Java programming. The robot battles are running in real-time and on-screen. 
It is suitable to all kind of programmers from beginners (a simple robot can be 
written in just a few minutes) to experts (perfecting an AI can take months).
The last approach uses video games in order to hook the player and bring 
him/her to programming. Two uses have been experimented: implementing new 
video games and playing video games. For example, in [22], students are required 
to implement in C++, through a collaborative project, a small-to-medium scale 
interactive computer game in one semester, making use of a game framework. In 
[23], a case study based on EEClone is proposed. EEClone is an arcade-style com-
puter game implemented in Java: students analysed various design patterns within 
© 2011 by Apple Academic Press, Inc.
  

258  Computer Technology and Computer Programming: New Research and Strategies
EEClone, and from this experience, learned how to apply design patterns in their 
own game software. In [5], a “Game First” approach is used to teach introductory 
programming. These authors believe that game programming motivates most new 
programmers. They use 2D game development as a unifying theme.
Another solution is to let students learn when they play a game. Two games 
use this approach: the Wireless Intelligent agent Simulation Environment (WISE) 
[24] and Colobot (http://www.ceebot.com/colobot/index-e.php) accessed 21 
September 2007. WISE combines activities from virtual and physical versions 
of the Wumpus World game. It allows physically distributed agents to play an 
interactive game and provides a dynamic learning environment that can enhance 
a number of computer science courses: it can be used as a medium for demon-
strating techniques in lectures; in the classes students can work on laboratory 
exercises that test, expand, or modify the simulator. The Wumpus World game 
can be played cooperatively or competitively. But WISE requires a great number 
of resources (e.g., space, robots, and so on) for the physical version.
Colobot is the only example that we know, of a complete video game, which 
mixes interactivity, storytelling, and programming. In this game, the user must 
colonize a planet using some robots that she/he is able to program in a specific 
object oriented programming language similar to C++. The only drawback in our 
opinion is that Colobot has no multiplayer mode.
Conclusion
“Although there is a weak theoretical basis and few techniques for measuring 
learning in computer science” [21, page 151], several environments for teaching 
programming have been developed. Stevenson and Wagner [17] define a set of 
characteristics for a “good assignment.” All the studied environments agree with 
the criteria number two (generate a realistic solution), three (focus on current top-
ics from class), four (be challenging), five (be interesting), seven (offers multiple 
levels of challenge), and eight (allow creativity and innovation). However none is 
based on real-world problems. But when students use Robocode, EEClone, and 
Colobot, they use complex APIs.
Novice programming environments (StarLogo, Scratch, Alice2, and Cleogo) 
are not games and cannot be considered as serious games. In [5, 22, 23], since 
students have to build a game and not to play, these approaches cannot be con-
sidered as games. Among the others, only Robocode, WISE, and Colobot use a 
gaming activity to stimulate the player. However, only Colobot allows the player 
to interactively program in game. But it is not free and cannot be adapted to dif-
ferent teaching context. Indeed, it is devoted to a specific programming language 
and cannot be adapted to specific pedagogical choices. Since in [10] there is no  
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  259
recommendation about the programming language, there is no consensus about 
the choice of a language. Indeed for pedagogical reasons, some teachers develop 
their own programming languages. Moreover, it is not easy for a teacher to in-
troduce new exercises into the game. Since our experiment lies on design ex-
periments, we need to test a serious game dedicated to teaching programming in 
several contexts with different teachers and students. The existing games do not 
allow that, and thus we decided to build our own serious game.
What Kind of Video Game for Our Serious 
Game?
The usability of a serious game is based on the compatibility between the learn-
ing objectives and the target public. Since we want to build a serious game for 
students in computer science, we have to base it on one of their most played video 
games. Our first step was thus to ask what kind of video games our students prac-
tice, and to find the most suitable one to motivate students to program.
Students and Video Games
To check the interest of our students in the kind of game they practice, we sub-
mitted a survey: 181 students were questioned (154 males and 27 females) in 
three different curricula (two on computer science and one on civil engineering). 
The average age is 21 years old (see Figure 2 for distribution).
Figure 2. Age of students.
The first analysis verifies ESA’s results about the student interest in games at 
our university. Figure 3 shows the percentage of students who play (males and 
females). More players are males but a small majority of females also play video 
© 2011 by Apple Academic Press, Inc.
  

260  Computer Technology and Computer Programming: New Research and Strategies
games. We infer from these figures that video games are widely played by our stu-
dents, even for females. These results corroborate the potential of serious games 
for these students.
Figure 3. (a) Players’ percentage for all participants, (b) males, and (c) females.
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  261
The second analysis identifies the most used game genre played by our stu-
dents. Figure 4 shows the percentage of players who play each game genre. The 
most played game genre is strategy games. We notice that this game genre is also 
appreciated by females (57% of female players play strategy games).
Figure 4. Percentage of players who play each game genre.
Figure 5 shows the percentage of students who used multiplayer games. As we 
can see, most of them use this type of game.
Figure 5. Percentage of players who play multiplayer games.
© 2011 by Apple Academic Press, Inc.
  

262  Computer Technology and Computer Programming: New Research and Strategies
Thus, to be adapted to our target audience, our serious game should be based 
on a multiplayer strategy game.
What is a Strategy Game?
Strategy games are, by and large, represented by Real-Time Strategy (RTS) games. 
In this game genre players evolve in a virtual environment, where resources are 
scattered on a map. RTS is traditionally structured around three main phases 
closely linked: harvesting resources, building structures and units, and fighting 
opponents. To win a game, the player has to destroy all structures and units of 
opponents or achieve a specific goal. To build a strong army, a good economy is 
required and protection of strategic areas is essential.
A strong player should show abilities in planning and know how to antici-
pate and react. She/he has to command hundreds of units, which leads to a large 
cognitive load. Moreover, RTSs have an important feature: the “fog of war.” This 
hides the movements and actions of opponents until they come into the line of 
sight of one of the player troops. The player evolves in a virtual world with incom-
plete information, which increases the game interest.
Traditionally, RTSs provide two types of game: Campaign and Skirmish. Cam-
paigns attract the player and teach him/her how to play, and skirmishes extend 
the life of the game. A campaign is divided in missions that gradually introduce 
game contents and complexity. Skirmishes require a better control of the game. 
The player fights against computer AIs or other players. Moreover, to increase the 
game challenge, it is always possible to find better or equivalent players on the 
Internet.
In RTS games, a player gives orders to his/her units to carry out operations 
(i.e., moving, building, etc.). Typically, these instructions are given by clicking 
on a map with the mouse. An RTS game, where such instructions can be given 
through programs, might be the answer to our serious game. The idea is to stimu-
late the player to give orders through programs. These programs will assist the stu-
dent/player during the game and should increase his/her probability of winning, 
if they are efficient, relevant, and suitable to the game. Moreover, when they test 
their programs, students will still use the same environment (the game).
Are Strategy Games Compatible with Teaching Programming?
As we have seen before, serious games for teaching programming already exist and 
are used. In particular, Colobot is based on a sort of RTS. In Colobot, teaching 
is provided through an interactive library available for consultation but a teacher 
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  263
using Colobot cannot modify or adapt it to his/her courses. And there is only one 
course level for novice programmers (PF).
Learning how to program requires writing programs. A priori, RTS and pro-
gramming activities are incompatible: real-time games are dynamics and have a 
strong interactivity with the player, and programming tasks require time for de-
sign and implementation of programs. Integrating programming activities in an 
RTS should then modify foundations of the game. Colobot and Robocode found 
two different solutions to solve this problem.
(i)	 Colobot is based on a modified RTS to enable in-game programming. 
The common rules of the game are modified by this fact, and it demands 
a specific skill from the player. For example, the player cannot control 
several entities in the game at the same time.
(ii)	 Robocode distinguishes beteen programming and playing activities. First, 
the player writes an AI, and then she/he runs them. Thus the player is 
inactive during the simulation and is merely a spectator of his/her AI.
Implementation
RTSs are very complex programs, with more than tens of thousands of code lines. 
Because our goal was not to develop a new RTS, we decided to use an existing 
engine. This engine had to be open sourced to allow us to develop the specific 
features of the serious game.
Game Engine Choice
We found two open source multiplayer 3D RTS engines: the Spring project 
(http://spring.clan-sy.com/) accessed 2 February 2007, and Open Real-Time 
Strategy (ORTS). ORTS [25, 26] has been developed to provide a programming 
environment for discussing problems related to AI. This game is designed to al-
low the user to easily program and integrate his/her AIs. It is aimed at users who 
already know how to program. Spring is a project aiming to create a new and 
versatile RTS Engine which was built to reuse some game data from a commercial 
game called Total Annihilation. Currently, Spring is more successful than ORTS. 
A gamer community plays Spring everyday on the Internet. This community 
helps to discover bugs, which are fixed by a development group. This process is 
not present in ORTS which is experimental. We chose the Spring engine instead 
of ORTS because of this community.
© 2011 by Apple Academic Press, Inc.
  

264  Computer Technology and Computer Programming: New Research and Strategies
Characteristics of Spring
Along with the Spring engine, several “mods” exist (http://spring.clan-sy.com/
wiki/Mods) accessed 26 August 2008, (mods constitute additions to a game that 
change the way it works). For our experiment, we chose to use “Kernel Panic” 
(http://spring.clan-sy.com/wiki/Kernel_Panic) accessed 26 August 2008; Fig-
ure 6 presents a screenshot of Kernel Panic, where three players (red, green, and 
pink) fight on a map. Kernel Panic uses computer science metaphors, like bits 
and pointers, which is an asset for our training purposes. Moreover, Kernel Panic 
is a simplified RTS with the following features: there is no resource management 
except for time and space; all units are free to create; it has a small technology 
improvement tree with less than ten units; it uses low-end vectorial graphics, 
which match the universe. These characteristics emphasize strategy and tactics in 
an action-oriented game while always remaining user friendly.
Figure 6. Kernel Panic.
Serious Game Implementation
To adapt the Spring engine to the serious game we wanted to build, we had to 
take into account some constraints: (i) allow players to write code plugged dy-
namically into the game; (ii) protect the game engine against player’s code bugs; 
(iii) hide the complexity of the game engine; (iv) support different programming 
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  265
languages. The integration of the player’s code in the engine must be interactive 
(without stopping the game) in order to maintain the progress and coherence of 
the game.
In some previous works [27] we used an implementation based on a dy-
namic library. Use of dynamic libraries turned out to be inadaptable to inter-
preted languages. Indeed, dynamic libraries solve problems in a single process: 
the game engine. This process controls student’s computer programs. But in-
terpreted languages also require an interpreter which is carried out in its own 
process. Thus, we discovered limits of the use of a dynamic library containing 
the player’s code.
Considering this drawback, we designed a new system. Students’ programs are 
not included in a dynamic library loaded and performed by the game but are run-
ning in an independent process and communicate with the game. This enables the 
use of compiled or interpreted languages. A set of techniques exist for exchang-
ing data among processes. We needed a portable and fast solution designed for 
process communication and not just threads communication. We chose to use 
the Boost interprocess library (http://www.boost.org/doc/libs/1_37_0/doc/html/
interprocess.html) accessed 26 November 2008, that provides shared memory 
functionality. Moreover, this library offers the possibility to use complex data, like 
vectors or maps, in the shared memory.
The UML component diagram in Figure 7 expresses the dependencies be-
tween the player’s program and the game engine. These two components inter-
act through the Game Engine Interface (GEI). The “Supplier GEI” is used by 
the game engine. We have integrated into the game engine some modifications. 
When the game starts, it creates the “Supplier GEI,” and then the supplier inter-
face can be used through the subroutines in Table 1.
Table 1
The “Client GEI” is used by the player’s program. After creating the “Client 
GEI,” it can use the client interface to interact with the game engine through the 
subroutines in Table 2. 
© 2011 by Apple Academic Press, Inc.
  

266  Computer Technology and Computer Programming: New Research and Strategies
Figure 7. Architecture.
Table 2
GEIs use the Boost interprocess library to interact with the shared memory. 
GEIs hide the synchronization complexity of the shared memory and make com-
munication with the game easier. At the request of the student program, pertinent 
data is copied into the shared memory. To avoid incoherent situations, students’ 
programs work on this copy. In this way, at any time, the player can change his/
her code and carry it out to use the shared memory and to communicate with the 
game.
All languages that are able to use a C library can use the “Client GEI” and 
communicate with the game engine. Currently, we propose interfaces for the “Cli-
ent GEI” in C, C++, Java, Visual Basic for Application (VBA), and an interpreted 
language called “Compaglo” (used in a specific course at our university).
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  267
Mapping Learning Objectives into the Game
Is the built serious game compatible with learning objectives? Different viewpoints 
can be envisaged: the student view, the teacher view, and the knowledge view.
The Student Point of View
The first step for a student is to learn how to use the serious game. Especially at 
the beginning, students have to understand what they can program and how they 
can do it through the “client GEI.” A campaign seems to be very suitable for game 
appropriation where motivation is maintained by a story.
When players are over with all the missions, they should be able to control the 
serious game and develop their own AIs for skirmishes. To build these AIs, players 
need to call upon their skills learned during the campaign. They have to design 
and implement each AI. The developed AIs span from simpler ones for novices, 
to very complex ones for experts.
In skirmishes, a student can play against the computer or against his/her 
friends. Multiplayer sessions encourage them to carry out new challenges. The 
motivation is maintained by competition between players.
The player defines a strategy, composed by a set of tasks, to win. She/he can 
choose to carry out some of them through AI. If the developed AIs improve the 
game, students will be better when they play. They will then perhaps find inter-
est in programming, spend time to perform it and so increase their abilities in 
programming practice.
The Teacher Point of View
The serious game we built can be adapted to the programming language chosen 
by the teacher. According to the language characteristics, she/he can build activi-
ties for different course levels from PF to complex AI algorithms. Moreover, if s/
he chooses to use the multiplayer mode, she/he can use individual, competitive, 
and collaborative pedagogical methods.
The Knowledge Point of View
Because unlike Colobot, the tool has not an interactive library of programming 
skills, it cannot be used without an appropriate teaching environment: students 
need to be assisted by teachers and peers to write their AIs and, after playing, 
an institutionalization [28] stage is necessary to carry out collaborative learning. 
© 2011 by Apple Academic Press, Inc.
  

268  Computer Technology and Computer Programming: New Research and Strategies
Simon [29] defines institutionalization as a phase where ideas “constructed or 
modified during problem solving attain the status of knowledge in the classroom 
community.” PF skills are gradually introduced through the missions, which ini-
tial aims are to progress in the story.
GEI is a fairly complex Application Programming Interface (API) which is not 
simple for novices to use. Teachers can develop an overlay adapted to their own 
subroutines specifications.
First Experiment
Before conducting design experiments with different teachers and students, we 
decided to test our serious game on some of our students and first define a simpli-
fied design experiment. To comply with the traditional game mode of an RTS, 
we first propose to carry out a campaign and then to develop additional programs 
usable in multiplayer sessions. We first present an example of a campaign, then we 
show how to organise a skirmish to ensure learning.
Our Campaign
“Kernel Panic” is only a multiplayer game and does not provide campaigns. There-
fore, we built a campaign to gradually introduce learning topics and enable stu-
dents to learn how to play and to program AIs. We take advantage of the Kernel 
Panic universe and offer students the following scenario: “For a certain number of 
years, a secret war is rife inside computers. Steady attacks are led against innocent 
victims. Today is your turn. Your aggressor captured your mouse controller. You 
must recover it. Your only solution: programming.”
To achieve this objective, five missions are created.
(i)	 Mission 1. “You lost a lot of units in the last attack. Units currently alive 
are dispersed on the map. You have only one BIT under control. You must 
go to the rally point at position (1056, 1792) to find other units.” To suc-
ceed, the player has to make a small program where she/he uses variables, 
types, assignments, functions, parameter passing, and records. Algorithm 
1 shows a solution.
(ii)	 Mission 2. “You just found a BYTE unit. It tells you that other units are 
reassembled not far. It gives you the position (479, 1825) of a BYTE group 
that it tries to rally. Moreover, it warns you that a group of BITS is forming 
at position (1400, 1371). To retrieve these units, command your two units 
to meet up with their respective groups.” In this mission the conditional 
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  269
control structure is introduced to give a target position to each unit ac-
cording to their type (BYTE or BIT).
(iii)	 Mission 3. “All units you control are weakened. You must repair them be-
fore starting a counter attack. A report indicates that an ASSEMBLER is 
posted at the position (256, 1024). Find it and it will help you.” In this 
mission the iterative control structure is introduced to iterate through each 
unit and move them on the right position. Algorithm 2 shows a solution.
(iv)	 Mission 4. “You found an ASSEMBLER. Use it to repair your weakened 
units.” This mission is the most complicated and requires overlapping iter-
ative and conditional control structures. The player has to iterate through 
each units and commands the ASSEMBLER to repair a unit if this unit is 
weakened and if the ASSEMBLER is inactive.
(v)	 Mission 5. “All units are repaired. Now it is time to fight back. The mouse 
device is positioned at (1056, 256). Good luck commander.” This mission 
goal is to reward students with a simple fight. 
Algorithm 1: Mission one algorithm.
Algorithm 2: Mission three algorithm.
© 2011 by Apple Academic Press, Inc.
  

270  Computer Technology and Computer Programming: New Research and Strategies
Skirmishes
When students finish the campaign, they can write their own AIs and use them 
during skirmishes. Here are some examples of strategic AIs which could be writ-
ten by students and give an “in-game” asset to the player: “Search for opponent” 
to quickly find the enemy in order to adapt one’s strategy to the adversary’s; “Cre-
ate a mine field” which may slow down opponents’ expansion in order to give 
more time to develop our own strategy; “Repair” using specific units to keep 
strategic units in good health; “Withdraw” to protect units when facing a stronger 
opponent. All these examples support a part of a player strategy and let him/her 
take charge of the rest, and therefore play the game at the same time.
Algorithm 3 shows the algorithm of “search for opponent” where units search 
for the enemy. Random target areas are computed to move each unit until an ene-
my is found. It uses library subroutines, like “giveOrder(u, MOVE, pos)” to move 
the unit “u” to the position “pos.” Usually, the player does this with the mouse 
and has to select each unit one by one, a long and tedious process. The loop allows 
the player to perform this operation automatically. Moreover, while the player is 
selecting the enemy units with the mouse, she/he cannot carry out other tasks. 
With this program she/he can, for example, develop his/her base while the pro-
gram explores the map.
Algorithm 3: “Search for opponent” algorithm.
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  271
Organization of the Course
Table 3 shows the schedule of our teaching organization for our first experiment. 
Two instructors supervise each session: one game specialist and one computer 
science teacher. During the first session, students play the game to familiarize 
themselves with it. A discussion about what could be done to improve the game 
and which are the most efficient strategies for winning is initiated. The second 
session is a presentation of GEI. The computer science teacher proposes that all 
students carry out missions. The programming obstacles are dealt in concert with 
the teacher. During the two next weeks, students work autonomously but can 
call upon their instructors. They have to develop their own AIs. If they have no 
idea of what to program, a database of efficient algorithms is proposed such as the 
“Search for opponent” algorithm. The game specialist guides the students through 
different game strategies to improve the playing sessions. The computer science 
instructor deals with installations and programming problems. The students are 
allowed to communicate with each other. They can then elaborate alliances or 
cooperation strategies, or simply help each other with programming. When all 
the programs are completed and operational, the third session occurs: students 
play using their own programs. The game specialist teacher turns his attention 
to decipher what really happened during the game: the role of the programs, the 
activities of the students, and the strategies used. This observation is the base of 
the last session: students and teachers analyse games and try to find the reasons 
behind victories and defeats. A discussion about the importance of the programs 
is held. The learning objective is that our students continue to use by themselves 
this serious game and improve their programming skills.
Table 3. Teaching organization schedule.
This experiment will be conducted in our university this year with novice stu-
dents. To evaluate the process we will use several indicators such as student invest-
ment, number, quality and pertinence of the written programs, student retention, 
gained skills and exam results. We also want to evaluate the “feel good” factor as 
defined in [30].
© 2011 by Apple Academic Press, Inc.
  

272  Computer Technology and Computer Programming: New Research and Strategies
Conclusion
This paper deals with the compatibility between a serious game and teaching 
programming. Serious games are more and more popular and can meet learning 
objectives. On the other hand, computer science students encounter a lot of diffi-
culties while learning programming. Some researchers in computer science educa-
tion develop programming environments to encourage and retain students. Some 
of these environments can be considered as serious games but they are not adapt-
able enough to validate our hypothesis in regards to design experiments, which is 
why we decided to build an adaptable serious game dedicated to programming.
As a basis for our serious game we chose to use an RTS, because it is the most 
played game genre for our target audience. Because it was not possible to develop 
our own RTS engine, we decided to use the Spring game engine and the Kernel 
Panic game. The implementation of the serious game led to modifying the en-
gine to enable an interactive and secure programming activity through an API. 
The students can command game entities with their own AIs and have contests 
with their friends in the multiplayer mode. The game can be adapted to specific 
programming languages, and teachers can adapt the API to their own specifica-
tion subroutines. PF skills are mapped on the game through missions. In order to 
validate the game, we designed a first design experiment with our students.
The next step is to conduct this experimentation and to adapt it to several con-
texts with different instructors and students in order to apply the iterative process 
of design experiments. The possible evolution of the serious game is the introduc-
tion of teaching facilities, like Colobot, and in order to keep pace with the rapid 
evolution of video game standards, the use of another mod, or the integration of 
other RTS game engines.
We hope that these experiments will show us the breadth of teaching ap-
plications supported by our system as well as the range of potential audiences 
and teaching methodologies. Analysis of our experimentation will explore and 
resolve potential issues concerning usability and effectiveness of learning with se-
rious games. At the same time, it will be important to determine which skills are 
learned by students when the campaign is finished and how users switch between 
game play and coding elements. It would also be interesting to evaluate this ap-
proach with another video game genre and to compare it with our RTS-based 
serious game.
References
1.	 T. L. Crenshaw, E. W. Chambers, and H. Metcalf, “A case study of retention 
practices at the University of Illinois at Urbana-Champaign,” in Proceedings of the 
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  273
39th ACM Technical Symposium on Computer Science Education (SIGCSE 
‘08), pp. 412–416, Portland, Ore, USA, March 2008.
2.	 C. Kelleher, “Alice and The Sims: the story from the Alice side of the fence,” 
in The Annual Serious Games Summit (DC ‘06), Washington, DC, USA,  
October 2006.
3.	 ACM/IEEE-Curriculum 2005 Task Force, Computing Curricula 2005, The 
Overview Report, IEEE Computer Society Press and ACM Press, New York, 
NY, USA, September 2005.
4.	 S. Fincher and M. Petre, “Mapping the territory,” in Computer Science Educa-
tion Research, RoutledgeFalmer, pp. 1–8, Taylor & Francis, Boca Raton, Fla, 
USA, 2004.
5.	 S. Leutenegger and J. Edgington, “A games first approach to teaching introduc-
tory programming,” in Proceedings of the 38th SIGCSE Technical Symposium 
on Computer Science Education (SIGCSE ‘07), pp. 115–118, Covington, Ky, 
USA, March 2007.
6.	 P. Cobb, J. Confrey, A. DiSessa, R. Lehrer, and L. Schauble, “Design ex-
periments in educational research,” Educational Researcher, vol. 32, no. 1,  
pp. 9–13, 2003.
7.	 M. Zyda, “From visual simulation to virtual reality to games,” Computer,  
vol. 38, no. 9, pp. 25–32, 2005.
8.	 S. Blackman, “Serious games...and less!,” Computer Graphics, vol. 39, no. 1, 
pp. 12–16, 2005.
9.	 F. L. Greitzer, O. A. Kuchar, and K. Huston, “Cognitive science implications 
for enhancing training effectiveness in a serious gaming context,” ACM Journal 
on Educational Resources in Computing, vol. 7, no. 3, article no. 2, 2007.
10.	 ACM/IEEE-Curriculum 2001 Task Force, Computing Curricula 2001, Com-
puter Science, IEEE Computer Society Press and ACM Press, New York, NY, 
USA, December 2001.
11.	 D. Ginat, “On novice loop boundaries and range conceptions,” Computer Sci-
ence Education, vol. 14, no. 3, pp. 165–181, 2004.
12.	 E. Soloway, J. Bonar, and K. Ehrlich, “Cognitive strategies and looping con-
structs: an empirical study,” Communications of the ACM, vol. 26, no. 11, 
pp. 853–860, 1983.
13.	 O. Seppälä, L. Malmi, and A. Korhonen, “Observations on student miscon-
ceptions—a case study of the Build Heap Algorithm,” Computer Science Edu-
cation, vol. 16, no. 3, pp. 241–255, 2006.
© 2011 by Apple Academic Press, Inc.
  

274  Computer Technology and Computer Programming: New Research and Strategies
14.	 E. Soloway, K. Ehrlich, J. Bonar, and J. Greenspan, “What do novices know 
about programming?,” in Directions in Human-Computer Interaction,  
pp. 87–122, Ablex, New York, NY, USA, 1982.
15.	 M. McCracken, V. Almstrum, D. Diaz, et al., “A multi-national, multi-insti-
tutional study of assessment of programming skills of first-year CS students,” 
in Working Group Reports from ITiCSE on Innovation and Technology in 
Computer Science Education (ITiCSE-WGR ‘01), pp. 125–180, Canterbury, 
UK, June 2001.
16.	 S. Stamm, “Mixed nuts: atypical classroom techniques for computer science 
courses,” Crossroads, vol. 10, no. 4, p. 3, 2004.
17.	 D. E. Stevenson and P. J. Wagner, “Developing real-world programming as-
signments for CS1,” in Proceedings of the 11th Annual SIGCSE Conference 
on Innovation and Technology in Computer Science Education (ITiCSE ‘06 ), 
pp. 158–162, Bologna, Italy, June 2006.
18.	 E. Klopfer and S. Yoon, “Developing games and simulations for today and 
tomorrow’s tech savvy youth,” TechTrends, vol. 49, no. 3, pp. 33–41, 2005.
19.	 J. Maloney, L. Burd, Y. Kafai, N. Rusk, B. Silverman, and M. Resnick, “Scratch: 
a sneak preview,” in Proceedings of the 2nd International Conference on Creat-
ing, Connecting and Collaborating through Computing, pp. 104–109, Kyoto, 
Japan, January 2004.
20.	 C. Kelleher, D. Cosgrove, D. Culyba, C. Forlines, J. Pratt, and R. Pausch, 
“Alice2: programming without syntax errors,” in Proceedings of the 15th An-
nual Symposium on the User Interface Software and Technology, Paris, France, 
October 2002.
21.	 A. Cockburn and A. Bryant, “Cleogo: collaborative and multi-metaphor pro-
gramming for kids,” in Proceedings of the 3rd Asian Pacific Computer and 
Human Interaction, pp. 189–194, Shonan Village Center, Japan, July 1998.
22.	 W.-K. Chen and Y. C. Cheng, “Teaching object-oriented programming labora-
tory with computer game programming,” IEEE Transactions on Education, 
vol. 50, no. 3, pp. 197–203, 2007.
23.	 P. Gestwicki and F.-S. Sun, “Teaching design patterns through computer game 
development,” ACM Journal on Educational Resources in Computing, vol. 8, 
no. 1, article no. 2, pp. 1–22, 2008.
24.	 D. J. Cook, M. Huber, R. Yerraballi, and L. B. Holder, “Enhancing computer 
science education with a wireless intelligent simulation environment,” Journal 
of Computing in Higher Education, vol. 16, no. 1, pp. 106–127, 2004.
© 2011 by Apple Academic Press, Inc.
  

Towards a Serious Game to Help Students Learn Computer Programming  275
25.	 M. Buro, “ORTS: a hack-free RTS game environment,” in Proceedings of the 
3rd International Conference Computers and Games (CG ‘02), vol. 2883 of 
Lecture Notes in Computer Science, pp. 280–291, Edmonton, Canada, July 
2002.
26.	 M. Buro and T. Furtak, “On the development of a free RTS game engine,” 
in Proceedings of the 1st Annual North American Game-On Conference 
(GameOn’NA ‘05), pp. 1–5, Montreal, Canada, August 2005.
27.	 M. Muratet, P. Torguet, and J.-P. Jessel, “Learning programming with an RTS 
based Serious Game,” in Serious Games on the Move International Confer-
ence, Cambridge, UK, June 2008.
28.	 G. Brousseau, Theory of Didactical Situations in Mathematics, Kluwer Aca-
demic Publishers, Dordrecht, The Netherlands, 1997.
29.	 M. A. Simon, “Learning mathematics and learning to teach: learning cycles in 
mathematics teacher education,” Educational Studies in Mathematics, vol. 26, 
no. 1, pp. 71–94, 1994.
30.	 M. M. Muller and F. Padberg, “An empirical study about the feelgood factor 
in pair programming,” in Proceedings of the 10th International Software Met-
rics Symposium (METRICS ‘04), pp. 151–158, Chicago, Ill, USA, September 
2004.
© 2011 by Apple Academic Press, Inc.
  

Distributed Network, Wireless 
and Cloud Computing 
Enabled 3-D Ultrasound; a 
New Medical Technology 
Paradigm
Arie Meir and Boris Rubinsky
Abstract
Medical technologies are indispensable to modern medicine. However, they 
have become exceedingly expensive and complex and are not available to the 
economically disadvantaged majority of the world population in underdevel-
oped as well as developed parts of the world. For example, according to the 
World Health Organization about two thirds of the world population does 
not have access to medical imaging. In this paper we introduce a new medi-
cal technology paradigm centered on wireless technology and cloud computing 
© 2011 by Apple Academic Press, Inc.

Distributed Network, Wireless and Cloud Computing  277
that was designed to overcome the problems of increasing health technology 
costs. We demonstrate the value of the concept with an example; the design of 
a wireless, distributed network and central (cloud) computing enabled three-
dimensional (3-D) ultrasound system. Specifically, we demonstrate the feasi-
bility of producing a 3-D high end ultrasound scan at a central computing 
facility using the raw data acquired at the remote patient site with an inex-
pensive low end ultrasound transducer designed for 2-D, through a mobile 
device and wireless connection link between them. Producing high-end 3D 
ultrasound images with simple low-end transducers reduces the cost of imag-
ing by orders of magnitude. It also removes the requirement of having a high-
ly trained imaging expert at the patient site, since the need for hand-eye coor-
dination and the ability to reconstruct a 3-D mental image from 2-D scans, 
which is a necessity for high quality ultrasound imaging, is eliminated. This 
could enable relatively untrained medical workers in developing nations to 
administer imaging and a more accurate diagnosis, effectively saving the lives 
of people.
Introduction 
During the last century, major advances in medical technology have led to sub-
stantial improvements in health care. This has come at a cost; the health care tech-
nology has become complex and expensive which, in turn, has led to a very wide 
disparity in health care delivery between those who have the financial resources 
to benefit from the advanced medical technology and those that do not. The 
ultimate outcome of this situation is that the majority of the world population 
does not have access to advanced medical technology and advanced health care. 
For instance, according to WHO reports, “Around 95% of medical technology 
in developing countries is imported, much of which does not meet the needs of 
national health care systems. Over 50% of equipment is not being used, either 
because of a lack of maintenance or spare parts, because it is too sophisticated 
or in disrepair, or simply because the health personnel do not know how to use 
it.” [1]. This situation is particularly acute in the field of medical imaging, which 
is required for correct diagnostic in about 20% to 30% of cases worldwide and 
which is not available to over 60% of the world population [2]. The challenges 
in diagnostic imaging in developing countries include: a severe lack of safe and 
appropriate diagnostic imaging services because of the cost and complexity of the 
devices as well as a severe lack of technical skills and trained radiographers/tech-
nologists leading to a large number of images being misread or of poor quality and 
therefore of no diagnostic use [3].
© 2011 by Apple Academic Press, Inc.
  

278  Computer Technology and Computer Programming: New Research and Strategies
For over a decade, our group has been working on trying to find solutions to 
the medical technology delivery disparity between those who have the financial 
resources to purchase and use these technologies and those who do not. We have 
identified that one major factor affecting the cost and the complexity of advanced 
medical technologies, such as medical imaging, is the hardware and software for 
data processing. Currently, medical devices are mostly stand-alone units, with 
redundant and practically limited computational parts, both software and hard-
ware. The computational part becomes increasingly complex and expensive with 
an increase in the sophistication of the technology. In the recent years, advances 
in computer science, telecommunication and the Internet made information 
technology available at low cost to even remote villages everywhere in the world. 
Inspired by this fact, we conceived of a similar concept for delivering advanced 
medical care and medical technology. The key concept is that the computational 
part (hardware and software) is at a central facility, now called “cloud” which does 
the data processing and provides the most advanced computational service, at 
any time, to an unlimited number of users, connected through telecommunica-
tion to the central processing facility. The devices at the user site have limited or 
no data processing facility and are used primarily to transfer the raw data to the 
central processing facility and to display the processed data. To focus ideas, the 
remote devices become a dumb terminal for a central computational facility. This 
removes the cost and limitations of the computation, manipulation and inter-
pretation of data from the vicinity of the patient and uses instead a central and 
effectively unlimited computational facility. In the vicinity of the patient only the 
components that directly interact with the patient and which acquire or use the 
raw data are needed. It should be emphasized that this is different from conven-
tional telemedicine in which the data processing is still done in the vicinity of the 
patient and the processed images, for example, are sent on. In our concept the 
majority of the processing is done at the central facility that can be at a completely 
different geographical location than the patient. The central facility serves a large 
number of remote users and the telecommunication is used to transfer the raw or 
minimally processed data to this central processing.
We have demonstrated the feasibility of the concept described above using 
the Internet and land telecommunication for imaging with electrical impedance 
tomography (EIT) and for EIT monitored minimally invasive surgery [4], [5]. 
We have also shown that this concept can be used with cellular phone based 
wireless technology for remote medical imaging with EIT and that it is valuable 
to other computationally expensive procedures, such as developing classifiers 
and data bases for medical data analysis [6], [7], [8]. A review of some of the 
aspects of our cellular phone based work can be found in a recent Nature news 
feature [9].
© 2011 by Apple Academic Press, Inc.
  

Distributed Network, Wireless and Cloud Computing  279
The goal of this study is to elaborate on the fundamental paradigm we devel-
oped earlier and to illustrate the value of this paradigm with a new implementa-
tion, which could be immediately useful for medical imaging in economically 
disadvantaged parts of the world. We believe that in addition to EIT, ultrasound 
is one of the imaging modalities with the best potential to become widely used 
with this paradigm, due to its relatively small physical dimensions and relatively 
low-cost. Conventional ultrasound produces a two dimensional image. Successful 
use of ultrasound relies heavily on understanding the significance of the image 
displayed and optimal placement of the transducer through hand-eye coordina-
tion. The highly trained and experienced users of ultrasound have had to develop 
hand-eye coordination skills which enable them to create the mental 3D picture 
of the human body while watching 2D images acquired by the ultrasound system 
in real-time. They know exactly how to position the ultrasound (US) probe, at 
what angle to scan and how fast to move it along the patient’s body to get a good 
image. Since medical personnel with such skill-sets are scarce in economically 
disadvantaged parts of the world, medical imaging is usually not done. In cases 
when medical imaging is performed the patients may be subject to wrong diagno-
sis and ultimately wrong treatment or no treatment at all. Three dimensional ul-
trasound image reconstruction, which is a relative recent addition to ultrasound, 
removes the need for high quality radiological expertise by allowing the physician 
to perform the scan without getting into the minute details of the data acquisi-
tion process such as the precise probe angle and position [10]. The challenge 
with industrial 3D ultrasound systems is their prohibitive cost which precludes 
them from being used in the developing nations, the place they are needed the 
most. Even in developed countries, small clinics that lack highly trained special-
ists, which could benefit from owning a 3D-US system, cannot afford purchasing 
it due to the high market price.
In this work we took the concept of processing at a central facility a step for-
ward by implementing a fully functional 3D ultrasound system in which the 2-D 
intended raw data acquired at the patient site by a medical untrained person is 
transferred through telecommunication to a central processing facility, where it 
can be processed into a 3-D image or, in fact, for any conceivable use. The 3-D 
processed data can then be made available through communication to the data 
acquisition site or to an expert at any other location. The idea of coupling an ul-
trasound device with a communication device such as Wi-Fi adapter or a cellular 
phone is not new. In [11] Martini et al. have focused on the possibility of utilizing 
3 g/WiFi networks for the purpose of video-streaming the acquired and processed 
ultrasound imaging data to the remote expert station. In [12] Dickson has evalu-
ated several wireless communication options for ultrasound systems focusing on 
video-streaming capabilities in his analysis. However, to the best of our knowl-
edge no other work has evaluated the feasibility of using telecommunication and 
© 2011 by Apple Academic Press, Inc.
  

280  Computer Technology and Computer Programming: New Research and Strategies
wireless technology to transmit raw ultrasound data for processing on the central 
processing station that serves a large number of users and generates 3D image 
from the raw data.
We believe that the work presented in this study illustrates the value of our 
paradigm in a meaningful way. The powerful central processing facility, which can 
serve unlimited numbers of remote users, allows a remote unskilled user to em-
ploy an inexpensive technology and nevertheless obtain a state of the art product 
in terms of a 3-D ultrasound image, at a fraction of the cost and without the need 
for complex data processing facilities and software at the user site.
Results 
The system architecture aligned with the proposed general paradigm is shown 
to contain two major components: Mobile Console and Remote Expert System 
(Fig. 1a). The mobile console with its sensors acts as the data acquisition device 
which collects the raw data from the patient, and sends it to the remote server for 
processing. The processing server is capable of transforming the large amount of 
otherwise meaningless measurements into a human understandable form such as 
an image or diagnosis.
Figure 1. System Architecture. (a) Overall system architecture includes the mobile console component and the 
remote processing server (Expert System) which performs the computation-extensive work. (b) Mobile Console 
Architecture. The console has one or more data acquisition devices, a communication module and a display 
capability. (c) Server Architecture. Contains a communication module, a processing engine, a visualization 
engine and an expert assessment mechanism.
© 2011 by Apple Academic Press, Inc.
  

Distributed Network, Wireless and Cloud Computing  281
The mobile console (Fig. 1b) contains a hardware data acquisition device, a 
display and a communication component able to send raw data and receive re-
sults. The Processing Server (Fig. 1c) contains a communication component to 
receive the raw data, a processing (reconstruction) component to process the data 
into a useful form and a visualization (rendering) engine which shapes the data 
in a visually meaningful way. Optionally the server side can contain a human-as-
sessment mechanism, which enables an expert doctor to review the results before 
sending them back to the mobile console.
The implementation of the general paradigm of Fig. 1 for 3-D ultrasound is 
given in detail in the Materials and Methods section. Specifically, we have used 
Lenovo R61 1.5GHz, 2GB RAM Windows XP as our server test bed running 
the server-side of the application software including the processing engine and 
OpenMRS server. For the purpose of this study we’ve focused primarily on a data 
flow in a typical obstetrics US scan, performed in B-Mode, with spatial resolution 
of 256×256, maintaining a contrast resolution of 8 bits (256 shades of gray). In 
such a study, the raw data required for the reconstruction is acquired by driving 
the transducer in a rectilinear, uniform direction with constant speed [13], [14]. 
The number of slices acquired depends on the specific application. We’ve used 
80 slices in our study. We’ve used a standard, very inexpensive 3.5 MHz abdomi-
nal ultrasound probe manufactured by Interson Corporation for 2-D ultrasound 
(http://www.interson.com).
Our system is based on Google’s Android platform which we chose because it 
is fully open source and capable of utilizing all the modern features provided by 
cellular operators. We have tested the system in two configurations: a) running 
on HTC G1 mobile phone and b) running in an emulator environment on Asus 
EEE 1000HE netbook computer.
Since USB host mode is not enabled on the conventional HTC G1 phone, it 
was not possible to connect the USB ultrasound probe to the mobile phone. For 
this reason we have designed a frame-grabber software module, which is respon-
sible for capturing the raw data from the ultrasound probe and sending it to the 
G1 phone over short-range wireless network. We’ve used the same frame-grabber 
interface when we tested the system in an Android emulation environment run-
ning on Asus netbook. Android-powered netbooks are expected to appear in the 
nearest future and we envision our system running natively on those computers, 
getting the ultrasound data directly from the available USB port.
Although they have made great progress in the recent years, the cellular data 
channels available today are still limited when compared to broad-band Wi-Fi 
alternatives. Even HSDPA, commonly referred to as 3.5G, provides 14.0 Mbps 
downlink under optimal conditions and HSUPA, which is the uplink component 
© 2011 by Apple Academic Press, Inc.
  

282  Computer Technology and Computer Programming: New Research and Strategies
of 3.5G, provides an uplink of up to 5.76 Mbps. This is especially true in develop-
ing nations where available cellular services tend to lag behind the cutting edge 
technologies available in the developed world. This is important because medical 
imaging devices are often known for generating large quantities of data.
For this reason it is important that the mobile console provides a buffering 
zone between the actual sensor and the processing station. Even if the connection 
channel is low-speed and/or unreliable, given enough storage space, the mobile 
console will eventually succeed to send the data to the processing station once the 
connection becomes stable.
An alternative scenario might involve a local health worker acquiring large 
amounts of data from multiple patients and later, when he is back to the local 
clinic where wi-fi is available, uploading all the accumulated data to the remote 
station for processing.
Fortunately, the costs of memory have dropped dramatically in the recent 
years (a 16 gb micro-sd supported by the G1 costs less than $45) so the buffer-
ing problem can be efficiently solved; the mobile device (netbook/cellular phone) 
would accumulate the data on it’s internal memory card until connection for 
uploading this data is available. The raw data flows from the acquisition device, 
an US probe in our case, to the mobile device which is a mobile phone acting as a 
storage device, and then transferred to the processing server when the connection 
is available (Fig. 2).
Figure 2. Data Storage Mechanism. The raw data flowing from the mobile device which acts as a storage device. 
Once a connection is available, the data is being transferred to the server for processing.
To demonstrate a typical scan, we have followed an example from [15] and 
created an agar based box-shaped phantom, sized 3.5″x2.75″x2″. During the so-
lidifying process, we’ve embedded a marble ball, a peach pit and two cherry pits 
inside the phantom to be able to trace those objects in the resulting ultrasound 
scan (Fig. 3)
© 2011 by Apple Academic Press, Inc.
  

Distributed Network, Wireless and Cloud Computing  283
Figure 3. Ultrasound Phantom. Agar based 3.5″x2.75″x2″ box shaped phantom with embedded marble ball, 
peach pit and two cherry pits. The marble ball and the peach pit can be seen from the image.
Since our purpose was to generate 3-dimensional images, we needed some 
type of system to provide with positional information. We used a hand held 
steadily moved probe to avoid the need for a more complex positioning system. 
It has not escaped our attention that for a truly freehand 3D-US a positioning 
system is preferable, otherwise the image resolution is extremely low and the im-
age is unusable for clinical purposes. Nevertheless we have intentionally chosen 
to work around the position information problem since the focus of our work is 
the feasibility of the overall data acquisition and 3-D processing framework. We 
provide a brief review of possible alternatives for position and orientation estima-
tion later in this paper.
For performance evaluation, relevant measurements are summarized in Table 1.
Table 1. Performances measurements.
As can be seen from the time measurements, we transfer substantial amounts 
of raw data over the wireless connection, thus the round-trip time is not real-time. 
Although it is possible to make our system more efficient by using various data 
compression and channel quality adaptive algorithms, we’d like to emphasize an 
important point: due to the nature of the 3D ultrasound, the need for real-time 
feedback is removed because no hand-eye coordination is required anymore. The 
relatively unskilled health worker can acquire the data in a freehand manner and 
after the remote processing is done, have the complete 3D volume data available 
for review and diagnostic purposes.
© 2011 by Apple Academic Press, Inc.
  

284  Computer Technology and Computer Programming: New Research and Strategies
A snapshot of the 3D reconstructed phantom is presented in multiple projec-
tion views (Fig. 4a and 4b). The ROI (region of interest) is shown in higher zoom 
level (Fig. 4c and 4d) where the marble ball can be seen on the top, the peach pit 
on the right and two cherry pits on the left part of the scan (Fig. 4c)
Figure 4. Resulting 3D Volume Visualized. (a) Front projection, axial angle 0°, depth of 15 cm (b) Side 
projection, axial angle 90°, depth of 15 cm (c) Zoom on ROI from (a): the cherry pits, the peach pit and the 
marble ball are clearly seen. (d) Zoom on ROI from (b) the cherry pits, the peach pit and the marble ball are 
clearly seen.
Discussion
We’ve shown in this work the feasibility of performing a 3D ultrasound scan using 
an inexpensive ultrasound transducer designed for 2-D, a mobile device, a remote 
processing station and a wireless connection link between them. Acquiring 3D 
ultrasound data removes the requirement of having a highly trained expert since 
hand-eye coordination process becomes obsolete. This enables medical workers in 
developing nations to administer a more accurate diagnosis, effectively saving the 
lives of people who would have otherwise been misdiagnosed.
It has to be noted that although our system did not incorporate any posi-
tion information, due to the relatively steady motion of a US transducer by an 
untrained US user, we managed to get reasonable 3D results, without any posi-
tioning device or hand-eye coordination. To provide the health worker with even 
higher degree of freedom and flexibility during data acquisition we intend to 
research cost-effective position information mechanisms which can be embedded 
in our system as a part of our effort to design an affordable and effective medical 
imaging mechanism for developing nations.
© 2011 by Apple Academic Press, Inc.
  

Distributed Network, Wireless and Cloud Computing  285
Although our case study focused on US, the implementation of any another 
medical technology would be identical in its conceptual essence. We chose US 
since, due to it’s mobility and wide availability, it seems like the natural choice 
of medical diagnostic modality for the developing world. In addition, ultrasound 
utilizes the available cellular connection as opposed to EIT described in [7] which 
sends very little data. We expect medical imaging solutions following the paradigm 
we’ve demonstrated in this work to appear in the foreseeable future. Constantly 
lowering mobile devices costs and communication technology advancements will 
contribute to this process.
An alternative and conceptually similar solution, might include integrating a 
data acquisition device such as the ultrasound probe used in our case-study with 
a cellular-phone chip such as, for example Gobi or Snapdragon technologies by 
Qualcomm (http://www.qctconnect.com/products/snapd​ragon.html,http://go-
bianywhere.com/ ). This solution would include a small display which is capable 
of displaying the diagnostic information after the remote server has finished pro-
cessing the raw data. This architecture can be utilized in a consumer device. The 
possible drawback of such architecture is binding the medical device to a specific 
cellular technology such as CDMA or GSM. A solution to this problem might 
include a Bluetooth transmitter in the end device which will send the raw data to 
any standard cellular phone; most modern phones include Bluetooth capabilities 
in them. This would expand the possible reach of the technology, since now we 
can leverage any existing cellular infrastructure.
One such possible device could be used to perform the scan by a health worker 
or even a home user. The raw data acquired by the Data Acquisition Device would 
be sent to remote station for processing and a diagnostic result in the form of a 
text message would be displayed on the LCD line: “Healthy” or “Thorough test 
is required” (Fig. 5).
Figure 5. Integrated breast cancer self-examination device for home use.
© 2011 by Apple Academic Press, Inc.
  

286  Computer Technology and Computer Programming: New Research and Strategies
A class of such devices for self-diagnosis is the natural extension of our work 
and having such a device would enable early detection of diseases, such as cancers 
or internal bleeding, thus potentially saving the lives of many.
Materials and Methods 
We will describe here the details of the 3-D ultrasound system implemented in 
this study using the general raw data transfer and data processing algorithm de-
scribed in Fig. 1. Ultrasound imaging utilizes acoustic waves for the mapping 
of internal organs and tissues from changes in acoustic impedance between the 
tissues. Ultrasound works by sending acoustic pulse waves towards the mapped 
organ and then reconstructing the echoes of those waves into a visual image used 
for medical diagnosis. Due to the relatively compact size and low power con-
sumption, ultrasound provides an important alternative to other medical imaging 
modalities such as CT and MRI.
In classic 2D ultrasound, the trained radiologist views the monitor while con-
structing a mental 3D image of the patient’s body. The quality of the diagnostic 
is heavily biased in the favor of a well-trained radiologist with excellent hand eye 
coordination and ability to integrate a sequence the 2-D images into a 3-D men-
tal understanding of the image. In 3D ultrasound systems, computer algorithms 
reconstruct a 3D image from the acquired 2-dimensional images, and therefore 
simplify the diagnostics. Since the reconstruction engine needs to position the 2D 
image in the 3D volume, in addition to the image data itself, the exact position 
and orientation of the US probe are required for each 2D image taken. Several 
approaches to estimating position and orientation are described at the end of the 
materials and methods section.
On a highly abstract level, any typical Ultrasound Imaging System includes 4 
primary components: a) Transducer—a unit which emits and receives the acous-
tic waves and records the correlation between them, b) Control unit—used to 
control the operation of the transducer, c) Processing unit—which converts the 
raw data acquired by the transducer into a human usable form, usually a visual 
image, and d) Imaging—the final stage of the ultrasound scan chain where the 
visual image is being displayed on the monitor for diagnostic purposes.
The detailed step-by-step implementation of our wireless 3-D ultrasound al-
gorithm as illustrated (Fig. 6):
1.	 The raw data arrives from the ultrasound probe.
2.	 The data arrives to the mobile device which stores the information on its 
internal memory card until a reliable connection channel becomes avail-
able.
© 2011 by Apple Academic Press, Inc.
  

Distributed Network, Wireless and Cloud Computing  287
3.	 Every once in a while (frequency can be configured trading-off respon-
siveness vs. battery life) the mobile device tests the available connection 
in order to detect the right moment to send the data. Once a connection 
has been established, the data transfer begins to the processing server. The 
communication protocol between the mobile device and the processing 
server is based on XML-RPC (http://www.xmlrpc.com/) which in turn is 
based on the standard HTTP protocol for transport. The data is packaged 
in a way that supports operating in slow, unreliable connection channels.
	
3.1  Once all the raw data arrives to the server, the processing stage can 
begin. The data is grouped by the slice number it belongs to.
	
3.2  In this stage a stack of parallel slices is being turned into a volume data-
set for later manipulation. This can be achieved using the “DICOM 
Volume Render” open source software module by Mark Wyszomier-
ski which is based on the popular graphics engine VTK. 
	
	
Digital Imaging and Communications in Medicine (DICOM) is a 
standard for handling, storing, printing, and transmitting informa-
tion in medical imaging. In addition to the raw image data, DICOM 
format enables incorporation of various meta-parameters for exam-
ple, in our case slice sickness, slice number e.t.c. To design and build 
a quick prototype, we have decided to skip the direct generation of 
DICOM files, a process which might easily become mundane. In-
stead we have downloaded an existing 3D Ultrasound and simply 
replaced the raw image data with our data, in addition to modifying 
the relevant parameters. 
	
	
Once this process of generating the DICOM files is complete, the 
renderer can process the stack of 2d images in DICOM format and 
create a volumetric data-set which is later snapshot to generate mul-
tiple view projects for 3d visualization.
	
3.3  Once the volumetric data-set has been created, it is projected in 
multiple directions to create the effect of 3D viewing on the mo-
bile device. Given a high enough angular resolution, the effect is 
close to a full 3D manipulation in the commonly used axial, sagit-
tal and coronal planes. It’s worth noting that recent technological 
advances in mobile devices, specifically in CPU power and graphic 
processing abilities, already allow many cellular phones to perform 
3D rendering on the mobile unit itself, as demonstrated by [16]. 
The trade-off decision of battery life vs. visualization power will 
have to be taken into account by any application designer in the 
mobile medical imaging field. We’ve decided to benefit from both 
© 2011 by Apple Academic Press, Inc.
  

288  Computer Technology and Computer Programming: New Research and Strategies
worlds by enabling limited 3D visualization by pre-computed pro-
jections. 
	
	
Once the projections have been generated they are saved as jpeg for-
matted images which are sent back to the mobile device, again using 
the XML-RPC over HTTP protocol. By using jpeg images as op-
posed to sending the volumetric data and rendering the data on the 
mobile device, we engage only the image-displaying capability of the 
mobile device as opposed to it’s power-hungry 3D engine, thus saving 
precious battery life. 
	
	
One minute, yet important aspect of communication has to be 
noted: due to the nature of a mobile device, its IP address is highly 
unstable. The cellular network might decide at a certain point that 
the IP address of a certain mobile device has to be changed to a 
different one. This makes it difficult for the server to contact the 
mobile console to notify it that the processing was completed and 
results are pending. Even if the mobile console sends its ID to 
the server, in the time period between the raw-data transmission 
to the termination of the processing phase, the IP address might 
have been changed. For this reason we’ve implemented a console-
driven polling mechanism. Once the raw data has been sent, every 
once in a while, the mobile console polls the server if the results 
are ready. If they are, the console makes a request for them. The 
frequency of the polling procedure is a system parameter which 
can be configured to trade off responsiveness vs. battery life. We’ve 
found that the value of Tperiod = 30 seconds provides reasonable 
results.
	
3.4  Global Expert Opinion: to provide an optional expert opinion 
to the remote health worker, we have integrated our system with 
OpenMRS® (http://www.openmrs.org), a popular open source 
medical records system. Once the raw data has been reconstructed 
and 3D images are available, the processed images are being dis-
played in a “pending” queue in OpenMRS. After a medical ex-
pert reviews the data and adds his comments, the result is sent to 
the mobile console for display. Because we adapted the concept 
of distributing the components of the imaging system, the expert 
reviewing the diagnostic images can be at any geographic location, 
unrelated to the location of the health worker or the processing 
station. What this means is that a local health worker in rural 
Uganda can perform a scan that is being processed in data servers in 
© 2011 by Apple Academic Press, Inc.
  

Distributed Network, Wireless and Cloud Computing  289
India and an expert radiologist from the U.S. provides a diagnos-
tic opinion which is sent with the results back to the local health 
worker effectively in real-time.
Figure 6. Data flow. The raw data flows from the hardware acquisition device to the mobile console which acts as 
a storage and communication conduit. Once the data is processed on the server, the results are transferred back 
to the console for review and diagnosis.
An important aspect of any 3D ultrasound system concerns position and ori-
entation information. During the process of 3-dimensional image reconstruction, 
every surface element (pixel) from the 2-dimensional images is mapped to a vol-
ume element (voxel) in the 3D reconstructed volume. To perform such a map-
ping accurately, the reconstruction algorithm needs to know the precise position 
and orientation of the ultrasound probe at the moment of the 2D image acqui-
sition. There are several techniques to this end. Mercier et al. review common 
technologies for medical instruments tracking [17]. Electro-magnetic and optical 
technologies for ultrasound probe tracking are the most popular. While those 
approaches provide good accuracy, they are also relatively bulky and expensive. 
Since we are working with the needs of developing countries in mind, we want to 
emphasize more mobile, cost-effective solutions. Abdul Rahni et al. have studied 
the possible usage of Micro Electro-Mechanical Systems (MEMS) based approach 
to estimate position and orientation in 3D [18]. In their study, the authors have 
used an Internal Measurement Unit (IMU) which included an accelerometer and 
a gyroscope. The advantage of this approach is its simplicity—no external cam-
era or receiver is needed, as in the electromagnetic/optical technology case. The 
raw physical measurements (acceleration, angular velocity and static orientation) 
are read from the IMU and processed to calculate the absolute 3D position and 
© 2011 by Apple Academic Press, Inc.
  

290  Computer Technology and Computer Programming: New Research and Strategies
orientation. By adding redundant sensors, it is possible to compensate for some 
of the numeric errors inherent to the process. Another work that has caught our 
attention has used a conventional digital camera for position and orientation es-
timation [19]. During the data acquisition process, in addition to the US data, 
a video clip focusing on the ultrasound probe is captured. After the acquisition 
process is over, the position and orientation information are extracted by applying 
machine vision algorithms to the acquired video stream. By using a conventional 
digital camera, which often comes as an integral part of any modern cell-phone, it 
is possible to build a low-cost, ultra-mobile 3D position mechanism.
We believe that the approaches presented in [18], [19] can be used as a basis 
for a cost-effective, mobile position and orientation estimation mechanism which 
are required by a 3D reconstruction algorithm and we intend to explore those 
research directions. Since the primary focus of our current work was to illustrate 
the concept of the overall data acquisition and 3-D processing framework, we’ve 
decided to relax the freehand requirement and work around the 3D positioning 
issue by steadily moving the US probe in a straight line during the data acquisi-
tion stage. By sticking to the straight line trajectory, we were able to use a more 
straightforward reconstruction algorithm since it could simply stack the 2D imag-
es one next to each other and still get a 3D images of reasonable quality. In the future 
we intend to develop relevant variants of the techniques described in [18], [19].
Acknowledgements 
We would like to thank Mr. Eric Stein and Google Corporation for donating an 
HTC G1 mobile phone which made our work possible.
Authors’ Contributions 
Conceived and designed the experiments: BR. Performed the experiments: AM. 
Analyzed the data: AM. Wrote the paper: AM BR.
References 
1.	 WHO report (2003) Essential Health Technologies Strategy 2004–2007. 
World Health Organization. http://www.who.int/eht/en/EHT_strategy_2​
004-2007.pdf.
2.	 WHO report, Essential Diagnostic Imaging. World Health Organization, 
http://www.who.int/eht/en/DiagnosticImag​ing.pdf.
© 2011 by Apple Academic Press, Inc.
  

Distributed Network, Wireless and Cloud Computing  291
3.	 WHO report, About Diagnostic imaging. World Health Organization, http://
www.who.int/diagnostic_imaging/en​/.
4.	 Rubinsky B, Otten D (2004) Method and apparatus for remote imaging of 
biological tissue by electrical impedance tomography through a communica-
tion network. US Patent #6725087. 
5.	 Otten D, Onik G, Rubinsky B (2004) Distributed Network Imaging and Elec-
trical Impedance Tomography of Minimally Invasive Surgery. Technology in 
Cancer Research and Treatment Vol. 3, No. 2: 1–10. 
6.	 Granot T, Ivorra A, Rubinsky B (2008) A New Concept for Medical Imaging 
Centered on Cellular Phone Technology. PloS ONE 3(4): e2075. 
7.	 Laufer S, Rubinsky B (2009) “Tissue characterization with a multimodality 
classifier: electrical spectroscopy and medical imaging” IEEE Trans Biomed 
Eng Feb;56(2): 525–8. 
8.	 Laufer S, Rubinsky B (2009) Cellular Phone Enabled Non-Invasive Tissue 
Classifier. PLoS ONE 4(4): e5178. doi:10.1371/journal.pone.0005178.
9.	 Kwok R (2009) Personal technology: Phoning in data. Nature 458: 959–961. 
10.	 Gee A, Prager R, Treece G, Berman L (2003) Engineering a freehand 3-D ul-
trasound system. Pattern Recognit Lett vol. 24, no. 4–5: 757–777. 
11.	 Martini MG, Istepanian RSH, Mazzotti M, Philip N (2007) A Cross-Layer 
Approach for Wireless Medical Video Streaming in Robotic Teleultrasonogra-
phy. Conf Proc IEEE Eng Med Biol Soc 3082–5. 
12.	 Dickson BW (2008) Wireless Communication Options for a Mobile Ultra-
sound System, MSc. Thesis, Worcester Polytechnic Institute, http://www.wpi.
edu/Pubs/ETD/Available/et​d-090208-162440/.
13.	 Goes CE, Schiabel H, Nunes FLS, Berezowski AT (2006) “Volume Rendering 
for Ultrasound Computer Phantoms Images by Using Multiplatform Software” 
IFMBE Proceedings World Congress on Medical Physics and Biomedical En-
gineering. 2456–2459. 
14.	 Kelly M, Gardener JE, Brett AD, Richards R, Lees WR (1994) Three-dimen-
sional US of the fetus—work in progress. Radiology 192: 253–259. 
15.	 Bude RO, Adler RS (1995) An easily made, low-cost, tissue-like ultrasound 
phantom material. J Clin Ultrasound 23: 271–273. 
16.	 Moser M, Weiskopf D (2008): Interactive volume rendering on mobile devices. 
In Vision, Modeling, and Visualization ‘08 Conference Proceedings 217–226. 
17.	 Mercier L, Langø T, Lindseth F, Collins LD (2005) A review of calibration 
techniques for freehand 3-D ultrasound systems. Ultrasound in Medicine & 
Biology Volume 31, Issue 4: 587. 
© 2011 by Apple Academic Press, Inc.
  

292  Computer Technology and Computer Programming: New Research and Strategies
18.	 Abdul Rahni AA, Yahya I, Mustaza SM (2008) “2D Translation from a 
6-DOF MEMS IMU’s Orientation for Freehand 3D Ultrasound Scanning,” 
Proceedings of 4th Kuala Lumpur International Conference on Biomedical  
Engineering. 
19.	 Ali A, Logeswaran R (2007) “A visual probe localization and calibration system 
for cost-effective computer-aided 3D ultrasound,” Computers in Biology and 
Medicine 37: 1141–1147. 
© 2011 by Apple Academic Press, Inc.
  

miRMaid: A Unified 
Programming Interface for 
Microrna Data Resources
Anders Jacobsen, Anders Krogh, Sakari Kauppinen  
and Morten Lindow
Abstract
Background
MicroRNAs (miRNAs) are endogenous small RNAs that play a key role in 
post-transcriptional regulation of gene expression in animals and plants. The 
number of known miRNAs has increased rapidly over the years. The cur-
rent release (version 14.0) of miRBase, the central online repository for miR-
NA annotation, comprises over 10.000 miRNA precursors from 115 differ-
ent species. Furthermore, a large number of decentralized online resources are 
now available, each contributing with important miRNA annotation and 
information.
© 2011 by Apple Academic Press, Inc.

294  Computer Technology and Computer Programming: New Research and Strategies
Results
We have developed a software framework, designated here as miRMaid, with 
the goal of integrating miRNA data resources in a uniform web service inter-
face that can be accessed and queried by researchers and, most importantly, 
by computers. miRMaid is built around data from miRBase and is designed 
to follow the official miRBase data releases. It exposes miRBase data as inter-
connected web services. Third-party miRNA data resources can be modularly 
integrated as miRMaid plugins or they can loosely couple with miRMaid as 
individual entities in the World Wide Web. miRMaid is available as a pub-
lic web service but is also easily installed as a local application. The software 
framework is freely available under the LGPL open source license for academ-
ic and commercial use.
Conclusion
miRMaid is an intuitive and modular software platform designed to uni-
fy miRBase and independent miRNA data resources. It enables miRNA re-
searchers to computationally address complex questions involving the multi-
tude of miRNA data resources. Furthermore, miRMaid constitutes a basic 
framework for further programming in which microRNA-interested bioin-
formaticians can readily develop their own tools and data sources.
Background
MicroRNAs (miRNAs) are short regulatory RNA molecules that are encoded in 
the genomes of animals, plants and viruses. They function as post-transcription-
al regulators of mRNAs and have gained high interest due to their importance 
in many biological processes [1-3] and their potential as drug targets [4]. The 
relatively recent discovery and the main mechanism of action of miRNA-based 
regulation, which is based on Watson-Crick base pairing, has led to a recent ex-
plosion in algorithms, websites and databases that provide different data about 
microRNAs.
The large number of miRNAs discovered during the last couple of years has 
been supported by miRBase as the central clearing house for miRNA nomencla-
ture and annotation [5,6]. At the miRBase web site, scientists can submit newly 
discovered miRNAs and information about sequences and homologies in other 
species. Today miRBase has become a central and highly useful website for scien-
tists who search for information about specific miRNAs. A number of flat files in 
different formats are made available with each release of miRBase to support com-
putational analysis. In addition to miRBase, a variety of miRNA data resources 
has been developed by other research groups. These include resources that deal 
© 2011 by Apple Academic Press, Inc.
  

miRMaid: A Unified Programming Interface for Microrna Data Resources  295
with genomic contexts and evolutionary conservation of miRNAs (miROrtho 
[7], miRGen [8], miRfunc [9], microTranspoGene [10]), prediction and valida-
tion of miRNA targets (TargetScan [11], miRNAMap [12], microRNA.org [13], 
miRDB [14], miRecords [15], TarBase [16]) and biological functions and pheno-
types of individual miRNAs (miR2Disease [17], DIANA-mirPath [18], MMIA 
[19]). These miRNA resources are primarily available online as point-and-click 
web sites.
It is currently a burdensome task to do an integrated computational analysis 
using data from one or more of the online miRNA resources. For each resource, 
it requires manually downloading raw data files (if available), understanding the 
sometimes arcane format and structure of the resource in question and finally, 
construction of a script to parse the content and various identifiers. The researcher 
has to go through all these steps, and repeat them each time a resource is up-
dated. A more simple procedure would reduce errors, increase reproducibility of 
the scientific results and make the data analysis less labor-intensive. miRMaid is 
a software framework designed to eliminate the aforementioned preprocessing 
steps. It provides non-redundant, structured and inter-connected data that are 
accessible both through an object oriented interface (using the Ruby program-
ming language) and as web-based resources that are accessible remotely using 
most computer programming languages. The web-based resources follow a set 
of design principles, Representational State Transfer (REST) [20], implying that 
every resource is uniquely and uniformly addressable using an URL. The effect is 
that the web resources can be accessed equivalently by computer programs and 
researchers using a web browser.
Implementation
Core Architecture
miRMaid is built in the Ruby programming language using an open source web 
application framework, Ruby on Rails (RoR, http://www.rubyonrails.org ). RoR 
allows rapid development of web applications in a Model-View-Controller (MVC) 
architecture, which isolates business logic from the user interface and facilitates 
program maintenance and scalability. In the RoR framework, data is stored in a 
relational database management system (SQLite, PostgreSQL and MySQL are 
currently supported in miRMaid) and encapsulated in an object-oriented model 
layer (Figure 1). The models are inter-connected and can be queried directly from 
the Ruby programming language. When miRMaid is deployed, it automatically 
(unless a specific miRBase version is stated) fetches the online raw data files from 
the current miRBase release. This data is restructured to yield the set of miRMaid 
© 2011 by Apple Academic Press, Inc.
  

296  Computer Technology and Computer Programming: New Research and Strategies
core data models. An overview of these models and their associations is shown in 
Table 1.
Figure 1. Architecture overview. miRMaid uses a Model-View-controller architecture. The model layer provides 
object oriented encapsulation of data stored in a relational database. The model layer can be efficiently and 
directly queried using the Ruby programming language. Each model is additionally exposed as a RESTful web 
resource. The data returned from a resource URL can be returned as HTML (suitable for web browsers), XML 
(suitable for computer programs) and for some resources also as FASTA sequence format.
Table 1. Models
All models are also exposed on the web as read-only RESTful resources, ren-
dering HTML to researchers (using web browsers) and XML or FASTA repre-
sentations to computer programs. Figure 2 illustrates the miRMaid resources, the 
associations between resources and how they are addressed by an URL. miRMaid 
(using RoR) ships with a lightweight, but efficient, web server that can be loaded 
© 2011 by Apple Academic Press, Inc.
  

miRMaid: A Unified Programming Interface for Microrna Data Resources  297
from the command line, but miRMaid is also easily integrated with an existing 
Apache web server.
Figure 2. Resource map. Each data model (i.e. ‘Precursor’) in miRMaid has resource URLs for listing all objects 
(/precursors) or a single object (/precursors/hsa-mir-21). Relationships (denoted by edges in the figure) between 
models are captured by nested resource URLs (/matures/hsa-miR-21/papers). A solid circle at the end of an edge 
denotes a ‘many’ relationship. For example, a species ‘has many’ precursors (/species/hsa/precursors), while a 
precursor is related to only ‘one’ species (/precursors/hsa-mir-21/species).
Modular Design
A central feature of miRMaid is its modularity. It has a structured, but simple ap-
plication interface (RESTful web-service or the Ruby object-relational layer) and 
can be loosely coupled as an independent data component in existing systems. 
Furthermore, miRMaid is built as a framework that is easy to extend with new 
data and functionality. We have designed a plugin architecture, where the core 
miRMaid framework works independently of activated plugins. The plugins can 
dynamically integrate with and extend miRMaid data and functionality without 
making changes to the core application. It is a simple procedure to develop an 
extension or plugin to miRMaid that introduces new data models and resources 
integrated with the core miRMaid framework (Figure 3). The result is a mod-
ular web application, where the core miRMaid framework can be dynamically  
© 2011 by Apple Academic Press, Inc.
  

298  Computer Technology and Computer Programming: New Research and Strategies
extended with plugins to provide a unified browsing experience and application 
interface. Please, refer to the result section for an example of how the plugin inte-
gration works in practice.
Figure 3. Plugin integration. A miRMaid plugin is implemented as an isolated MVC slice (an ‘Engine’ in 
the Ruby on Rails framework). The plugin defines its own data models and the relationships between these 
models. The integration (model and resource relationships) between the miRMaid core framework and the 
plugin is configured inside the plugin. The core framework provides hooks where a plugin can register itself. 
In the example above, the miR2Disease plugin defines two data models, M2dDisease and M2dDiseaseLink, 
where only the M2dDiseaseLink integrates directly with the core framework (a ‘one-many’ relationship with the 
Mature data model and resource). The effect of this integration is that M2dDiseaseLink objects are connected to 
Mature objects and that these relationships can be queried directly through the data models or by using RESTful 
resource URLs.
© 2011 by Apple Academic Press, Inc.
  

miRMaid: A Unified Programming Interface for Microrna Data Resources  299
Results and Discussion
Maintenance and Lifecycle of miRMaid
miRBase is the data source of the core miRMaid framework. With every data 
release of miRBase there will be a corresponding public version of the miRMaid 
web service) while older miRMaid versions will be kept available for a limited 
time period. Besides being a public web service, miRMaid can easily be installed 
locally. When a new version of MirBase is released, a local installation can be 
updated simply by reinstalling the miRMaid framework (together with optional 
plugins) using a single command on the command line. The source code for miR-
Maid is under the LGPL license and utilizes the Git multi-user versioning system 
(accessible via http://www.github.com ). When changes are committed and re-
leased in the miRMaid project repository, it is a simple task to pull the changes 
and update a local miRMaid installation.
In miRMaid, there are unit tests for all models and RESTful resources. This 
is done to assist development and so that end-users can verify that their local 
miRMaid installation behaves as expected. The test suite can be run from the 
command-line. Plugins must also specify tests for models, RESTful resources and 
connections between the plugin and the core framework. The plugin unit tests are 
straightforward to implement and they are automatically evaluated together with 
the core test suite in miRMaid.
RESTful clients
A major benefit of a RESTful web service is the simplicity by which programs or 
other web services can retrieve information. Querying a RESTful web service only 
requires that the program is able to generate a HTTP request to the URL that 
specifies the resource and then parse the response document—most programming 
languages have such features readily available. miRMaid can generate HTML and 
XML response documents for all resource URLs and FASTA documents where it 
is appropriate. XML documents are suited for computer programs and they are 
easily handled and parsed in most programming languages. In Figure 4 we give 
two examples of RESTful clients implemented in the Ruby and Perl program-
ming languages. Both programs perform two simple tasks: 1) retrieving the com-
ment attribute for the cel-let-7 precursor, and 2) retrieving the sequences for the 
two mature miRNAs (hsa-miR-21 and hsa-miR-21*) in the hsa-mir-21 precur-
sor. In Figure 4, we have also included two examples to illustrate the simplicity 
of the RESTful interface. We use the R statistical framework [21] and the ‘curl’ 
command-line program to issue a HTTP request to retrieve all C. elegans mature 
sequences in FASTA format. Furthermore, a normal web-browser can be used as 
© 2011 by Apple Academic Press, Inc.
  

300  Computer Technology and Computer Programming: New Research and Strategies
a RESTful client to inspect the XML and FASTA response documents for a given 
URL. There is currently no widely adopted web service description standard for 
RESTful services. Until a standard has been adopted, the resource API for a given 
miRMaid instance (including installed plugins) is dynamically documented via 
the URL http://current.miRMaid.org/described_routes.txt (also available as an 
XML document). This feature is further documented on the miRMaid commu-
nity site.
Figure 4. RESTful clients. RESTful clients can be implemented in most programming languages. Listed above 
are two examples in the Ruby and Perl programming languages. Both programs perform the same tasks: getting 
the ‘comment’ attribute for the cel-let-7 miRNA precursor and getting the mature miRNA sequences (hsa-
miR-21 and hsa-miR-21*) for the hsa-mir-21 miRNA precursor. Both programs use standard libraries to issue 
HTTP GET requests and to parse the resulting XML documents. The final two examples demonstrate how 
miRMaid’s FASTA sequence rendering capability can be used. We use the R statistical framework [21] and the 
‘curl’ command-line program to issue a HTTP request to retrieve all C. elegans mature sequences in FASTA 
format.
© 2011 by Apple Academic Press, Inc.
  

miRMaid: A Unified Programming Interface for Microrna Data Resources  301
Local Ruby Clients with Direct Access to Data Models
The second leg of miRMaid is the object oriented model layer. With a local miR-
Maid installation data can be accessed efficiently through a Ruby program with-
out the overhead of HTTP protocol and network communication that is associ-
ated with the REST interface. miRMaid uses the RoR object-relational mapping 
library called ActiveRecord. This library provides an intuitive way to find objects, 
retrieve attributes and to navigate between associated models. In Figure 5, we 
provide an example of how the models can be queried interactively in a Ruby IRB 
session. We start out by retrieving all 8 human precursors in the mir-17 precursor 
family. Next, we identify all precursors in a neighborhood of +/- 1000 nucle-
otides. These nearby precursors are finally grouped into mir-17 family members 
and non mir-17 family members. This is a very simple example yet it illustrates 
how the data models can be queried swiftly in an intuitive manner.
Figure 5. Ruby data models. In a local miRMaid installation, the data models can be queried directly without 
the overhead of the HTTP protocol and network communication. The figure lists an interactive Ruby IRB 
session where the data models are queried to analyze the genomic clustering of human mir-17 family members.
miRMaid Plugins
As detailed earlier, data and functionality in miRMaid can be extended by plu-
gins. We have developed a proof-of-concept plugin using data from the miR2-
Disease web service [22]. The plugin extends miRMaid with two data models 
and RESTful resources: diseases and disease links. A disease link associates a 
mature miRNA and a disease and it carries information about the association, 
for example PubMed reference and target genes. A specific disease instance can 
be reached using the URL,/m2d_diseases/DOID, where DOID is the Disease 
Ontology identifier. Disease links are identified by a concatenation of DOID, 
© 2011 by Apple Academic Press, Inc.
  

302  Computer Technology and Computer Programming: New Research and Strategies
mature miRNA name and PubMed ID. Figure 3 demonstrates how the plugin 
connects with miRMaid to integrate the disease link model and resource with 
the miRMaid mature model and resource. The plugin should also define HTML 
representations for the resources that are being introduced. These plugin HTML 
representations are accessible from a web browser and are automatically integrated 
in the menu layout of the miRMaid web site. The net effect is a complete inte-
gration of miRMaid and plugin in both the web site and application interface. 
We host a public version of miRMaid with example plugins activated at http://
plugins.mirmaid.org.
Conclusion
First of all, miRMaid is a software framework aiming at easing the manual work-
load for researchers when doing computational analyses involving miRNA data. 
miRMaid provides a uniform, intuitive and flexible application interface that is 
independent of programming language. miRMaid is designed to live as a public 
service as well as being installed locally. The public service should be used when 
doing a simple and quick analysis and for integration with other web services. 
The local installation (using the Ruby data models) is recommended when a more 
data extensive analysis is needed. miRMaid is open-source software and users can 
contribute to the framework through the public source code repository or they 
can develop a miRMaid plugin that can be shared with the rest of the community. 
Furthermore, individual users or labs can integrate private data as miRMaid plu-
gins or they can couple existing information systems loosely to miRMaid using 
the RESTful API.
We believe that the miRMaid platform can pave a new and exciting way for 
scientists to share data and programs that involve miRNAs. miRMaid follows a 
design philosophy that web services and resources should be able to integrate: 
web services should participate in the web instead of merely living on the top of 
it. We envision that if new data resources are released as miRMaid plugins, or at 
least follow the RESTful design principles for web services, then this would be a 
big step towards a global integration of miRNA data. By developing miRMaid we 
hope that such an effort can be coordinated not only by huge centralized software 
development teams at Ensembl and the UCSC genome browser, but also by a 
community that shares a common scientific interest.
Availability and Requirements
• Project name: miRMaid
• Project home page: http://www.mirmaid.org.
© 2011 by Apple Academic Press, Inc.
  

miRMaid: A Unified Programming Interface for Microrna Data Resources  303
• Operating systems: Server software: Linux and Mac OSX, Client software: Plat-
form independent.
• Programming language; Server software: Ruby. RESTful clients: most modern 
programming languages.
• Other requirements; Database management system: PostgreSQL, MySQL or 
SQLite. Other minor requirements are detailed at http://www.mirmaid.org.
• License: Free for academic and commercial users under the GNU Lesser Gen-
eral Public License (LGPL).
• Public servers: A public server running the current miRMaid release can be 
found at http://current.mirmaid.org and a server instance with example plugins 
activated can be found at http://plugins.mirmaid.org.
Competing Interests
ML and SK are employees of Santaris Pharma A/S, a biopharmaceutical company 
developing RNA-based medicines.
Authors’ Contributions
AJ designed and implemented most of the software and drafted the manuscript. 
ML conceived of the project, designed and tested the software and helped draft the 
manuscript. All authors read, helped draft and approved the final manuscript.
Acknowledgements
AJ was funded by grants from the BioSys Innovation Network and the Novo 
Nordisk Foundation.
References
1.	 Bartel DP: MicroRNAs: Genomics, Biogenesis, Mechanism, and Function. 
Cell 2004, 116:281–297. 
2.	 Chekulaeva M, Filipowicz W: Mechanisms of miRNA-mediated post-tran-
scriptional regulation in animal cells. Current Opinion in Cell Biology 2009, 
21:452–460. 
3.	 Medina PP, Slack FJ: microRNAs and cancer: an overview. Cell Cycle 2008, 
7:2485–2492. 
© 2011 by Apple Academic Press, Inc.
  

304  Computer Technology and Computer Programming: New Research and Strategies
4.	 Petri A, Lindow M, Kauppinen S: MicroRNA silencing in primates: towards 
development of novel therapeutics. Cancer Res 2009, 69:393–395. 
5.	 Griffiths-Jones S, Saini HK, van Dongen S, Enright AJ: miRBase: tools for 
microRNA genomics. Nucleic Acids Res 2008, 36:D154–158. 
6.	 Ambros V, Bartel B, Bartel DP, et al.: A uniform system for microRNA annota-
tion. RNA 2003, 9:277–279. 
7.	 Gerlach D, Kriventseva EV, Rahman N, Vejnar CE, Zdobnov EM: miROrtho: 
computational survey of microRNA genes. Nucleic Acids Res 2009, 37:D111–
117. 
8.	 Megraw M, Sethupathy P, Corda B, Hatzigeorgiou AG: miRGen: a database 
for the study of animal microRNA genomic organization and function. Nucle-
ic Acids Res 2007, 35:D149–155. 
9.	 Taccioli C, Fabbri E, Visone R, et al.: UCbase & miRfunc: a database of ul-
traconserved sequences and microRNA function. Nucleic Acids Res 2009, 
37:D41–48. 
10.	 Levy A, Sela N, Ast G: TranspoGene and microTranspoGene: transposed ele-
ments influence on the transcriptome of seven vertebrates and invertebrates. 
Nucleic Acids Res 2008, 36:D47–52. 
11.	 Lewis B, Burge C, Bartel D: Conserved seed pairing, often flanked by ad-
enosines, indicates that thousands of human genes are microRNA targets. Cell 
2005, 120:20. 15.
12.	 Hsu S, Chu C, Tsou A, et al.: miRNAMap 2.0: genomic maps of microRNAs 
in metazoan genomes. Nucleic Acids Res 2008, 36:D165–169. 
13.	 Betel D, Wilson M, Gabow A, Marks DS, Sander C: The microRNA.org re-
source: targets and expression. Nucleic Acids Res 2008, 36:D149–153. 
14.	 Wang X: miRDB: a microRNA target prediction and functional annotation 
database with a wiki interface. RNA 2008, 14:1012–1017. 
15.	 Xiao F, Zuo Z, Cai G, et al.: miRecords: an integrated resource for microRNA-
target interactions. Nucleic Acids Res 2009, 37:D105–110. 
16.	 Papadopoulos GL, Reczko M, Simossis VA, Sethupathy P, Hatzigeorgiou AG: 
The database of experimentally supported targets: a functional update of Tar-
Base. Nucleic Acids Res 2009, 37:D155–8. 
17.	 Jiang Q, Wang Y, Hao Y, et al.: miR2Disease: a manually curated database for 
microRNA deregulation in human disease. Nucleic Acids Res 2009, 37:D98–
104. 
© 2011 by Apple Academic Press, Inc.
  

miRMaid: A Unified Programming Interface for Microrna Data Resources  305
18.	 Papadopoulos GL, Alexiou P, Maragkakis M, Reczko M, Hatzigeorgiou AG: 
DIANA-mirPath: Integrating human and mouse microRNAs in pathways. 
Bioinformatics 2009, 25:1991–1993. 
19.	 Nam S, Li M, Choi K, et al.: MicroRNA and mRNA integrated analysis 
(MMIA): a web tool for examining biological functions of microRNA expres-
sion. Nucleic Acids Res 2009, 37:W356–362. 
20.	 Fielding RT, Taylor RN: Principled design of the modern Web architecture. 
ACM Trans Internet Technol 2002, 2:115–150. 
21.	 R Development Core Team: R: A Language and Environment for Statistical 
Computing. Version 2.10.1 2009. 
22.	 Jiang Q, Wang Y, Hao Y, et al.: miR2Disease: a manually curated database for 
microRNA deregulation in human disease. Nucleic Acids Res 2009, 37:D98–
D104. 
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language 
for Property-Based Testing 
Matt Bishop and Vicentiu Neagoe 
Abstract 
Property-based testing is a testing technique that evaluates executions of a pro-
gram. The method checks that specifications, called properties, hold through-
out the execution of the program. TASpec is a language used to specify these 
properties. This paper compares some attributes of the language with the spec-
ification patterns used for model-checking languages, and then presents some 
descriptions of properties that can be used to detect common security flaws in 
programs. This report describes the results of a one-year research project at the 
University of California, Davis, which was funded by a University Collabo-
ration LDRD entitled “Property-based Testing for Cyber Security Assurance.” 
Introduction 
Property-based testing is a technique for testing the security of programs. Recall 
that secure means conforming to a security policy. The analyst doing the testing 
© 2011 by Apple Academic Press, Inc.

Some Attributes of a Language for Property-Based Testing  307
first specifies the properties she wishes the program to conform to. The program 
is then instrumented based on the specification of the properties. Consider the ex-
ecution of the program as a state machine, where as each instruction is executed, 
the state of the program changes. Relevant changes affect only those portions of 
the state used in the properties. The instrumentation produces output whenever 
such a change occurs. The program is then executed under control of another 
program called the test execution monitor (TEM). The TEM is given the proper-
ties, and whenever the execution enters a state forbidden by the specified by the 
properties, it reports a security error. 
These properties are written in a little language (called TASPEC) with con-
structs designed to aid testing. These include location specifiers (which specify 
specific places in the program where the properties hold, or where the state of the 
executing program will change), assertion statements (which assert that a certain 
property now holds), retraction statements (which assert that a certain property 
no longer holds), and temporal relationship operators (which specify whether 
something occurs before or after something else, or should occur and hold for the 
rest of the execution). 
This report first compares TASpec to other specification languages. We then 
examine some of the temporal operators used in TASpec in considerable detail. 
We analyze their precise meaning and show how to capture some of the notions in 
model checking and temporal logic languages using TASpec constructs. We con-
clude by presenting specifications of properties of programs that attackers com-
monly exploit in order to compromise the program (and, usually, the system on 
which the program runs). 
A word about motivation will clarify the goals of this report. The software life 
cycle, in terms of assurance, is usually described using the Waterfall Life Cycle 
Model. The relevant stages of that model are: 
1.	 Requirements definition and analysis, in which the specifications of the 
program or system are created and validated; 
2.	 Design, during which the program or system is architected, and the design 
is validated; 
3.	 Implementation, in which the program or system is created and tested; 
4.	 Integration and system testing, in which a set of programs are brought 
together and their union is tested and validated; and 
5.	 Operation and maintenance, in which the program or system is deployed 
and used. 
TASpec fits into the life cycle at steps 3 and 4, because it is a language tied to 
the implementation of the program or system. However, the properties it must 
© 2011 by Apple Academic Press, Inc.
  

308  Computer Technology and Computer Programming: New Research and Strategies
validate are often the same as, or derived from, properties that the design must 
meet. The design properties may be stated using a model checking language such 
as LTL. This naturally leads to the question of whether TASpec can describe the 
properties that LTL can describe, although at an implementation level. This is the 
reason for the analysis of the operators in TASpec. 
That said, there are vulnerabilities specific to an implementation that may 
have no counterpart to design flaws. For example, buffer overflows arise from a 
failure to check bounds. Models of systems and software usually do not have states 
in which the failure to check bounds causes a transition, unless that failure is nec-
essary for some reason. The model is at a level of abstraction in which this detail 
of checking is not relevant, and so is omitted. But it cannot be ignored at the 
implementation level. Hence, TASpec must be able to express these properties. 
The next section reviews TASpec very briefly to provide background. The third 
section discusses the temporal operators of TASpec with an emphasis on aspects 
found in LTL, a model checking language. The fourth presents some common 
implementation vulnerabilities and the TASpec properties that detect them 
TASpec and Property-Based Testing 
The goal of property-based testing is to validate that a program satisfies a set of 
specifications, called “properties.” The program to be validated is called the “target 
program.” 
As with formal methods, we do not discuss the derivation of requirements or, 
from them, specifications. We simply assume that the specifications are known. 
We also assume they are written in a low-level specification language (called 
“TASpec”) that describes the specifications in terms of the program being validat-
ed. We distinguish this type of specification from the higher-level specifications of 
formal methods by calling the former “properties.” 
The first step in property-based testing is instrumentation. The property file, 
which contains the properties, is analyzed to determine which variables and func-
tions will affect the properties. A program called the slicer eliminates all code in 
the target program that does not affect the properties. After slicing, the only paths 
of control and of data flow in the program are those that could affect the pro-
gram.1 The resulting program satisfies the properties if, and only if, the original 
program satisfies the properties. Next, a second program called the instrument-
er adds instructions to the target program to emit special directives describing 
changes of program state whenever a change of state occurs that could affect the 
desired properties. For example, suppose the property were “x > 5.” The following 
fragment:
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language for Property-Based Testing  309
if (y > 6) then x := 3; else x := 6 
would be instrumented to output the value of x after each part of the state-
ment: 
if (y > 6) then begin 
 x = 3; print “assert x = 3”; 
end else begin 
x = 6; print “assert x = 6”; 
end 
The directives will be saved in a file called the “state file” for later analysis. 
The next step is execution. The program is executed with appropriate test data. 
Ideally, all paths of execution should be tested. In practice, this number is too 
large, so some fraction of those paths are executed. Failure to test all paths means 
that some flows of control have not been validated. This illustrates the difference 
between validation and verification (in which all paths would be shown to be cor-
rect) as well as the need for careful test data generation. The inputs to each run are 
saved with the corresponding state file. 
The final step is analysis. A third program, called the test execution monitor 
or TEM, takes the property file and the state file, and tests whether the directives 
show that the properties have been violated. If so, the precise property violated, 
and the location at which the property was violated, will be printed. 
These steps differ from those for formal verification in two key ways. First, 
formal verification is primarily an a priori technique for developing correct code, 
although it can be used to prove an existing program correct. Property-based test-
ing is strictly an a posteriori testing technique. It requires an existing program to 
use. Secondly, the focus of property-based testing is on the implementation rather 
than the higher-level layers of abstraction such as design. The properties are writ-
ten in a little language similar to that of the target program. In formal verification, 
design is to be verified as well as implementation. So the language of specification 
is more abstract. 
How TASpec Works 
A brief description of the mechanics of TASpec and the TEM will be helpful in 
what follows. When the instrumented target program emits directives describing 
changes of program state, those changes have the form of assertions or retractions 
of particular predicates (called facts). The desired properties are expressed in terms 
of these predicates. As each assertion is emitted, the predicate being asserted is 
© 2011 by Apple Academic Press, Inc.
  

310  Computer Technology and Computer Programming: New Research and Strategies
added to a database; as each retraction is emitted, the predicate being retracted 
is deleted from that database. At each step, the TEM ensures that the facts in the 
database do not violate any of the properties. 
Basically, the state of the program execution is encapsulated in the set of facts 
in the database. 
TASpec and Model Checking Languages 
Our first question is the relationship between the language constructs in TASpec 
and the logic languages used to do model checking, as discussed earlier. For our 
purposes, we focus on the temporal operators. 
Taxonomy 
We use the taxonomy described in [3] to categorize TASpec as a hybrid approach 
between a history-based and a state-based specification language. 
State-based specification has been traditionally used for sequential programs 
while history-based specification with temporal logic has been traditionally used 
for concurrent programs. 
In history-based specification, time can be either linear or branching. Linear 
time makes assertions about paths and at each moment, there is only one possible 
future. Branching time has a treelike nature. Assertions are made about states 
and at each moment time may be split into alternate courses representing differ-
ent possible futures [2]. Branching time views events as concurrent “alternative 
universes” [1, p. 954]. 
TASpec implements a form of “history” that describes preconditions such as 
“predicate A must be true before predicate B becomes true.” It does not keep track 
of events that happened in the past. 
TASpec is a state-based specification language that focuses on functional re-
quirements describing what the software is expected to do. Aside from the state-
based paradigm, it borrows temporal logic from history-based specification lan-
guages. While the temporal operators do not increase its capability to express 
properties of programs, the temporal logic does allow some security properties 
to be expressed easily and clearly. History-based specification languages were de-
signed for dealing with concurrent systems and systems that simulate real-time. 
TASpec is unique in using temporal logic because it deals with single threaded 
programs, and therefore linear time. TASpec fits into the discrete time paradigm 
because each state represents a discrete point in time. 
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language for Property-Based Testing  311
If not designed carefully, specification languages can be cumbersome for ex-
pressing certain properties. Temporal logic does not enhance ease of expression 
when dealing with single threaded programs. It may make coding specifications 
easier and clearer, therefore reducing greatly the chances of introducing error in a 
specification. But even with temporal operators, simple specifications can require 
complex expressions. For example, consider a simple ordering property for mov-
ing an elevator. Between the time an elevator is summoned to a floor, and the time 
it opens its doors at that floor, the elevator can arrive at that floor at most twice 
[4]. This simple property requires “six levels of operator nesting in linear temporal 
logic” [3]. 
But without temporal operators, expressing temporal relationships between 
states and events becomes unnatural. Extra variables need to be added to indicate 
whether certain events happened, thereby making writing the specification more 
complex. Z is an example of a commonly used state-based specification language 
that lacks temporal operators. 
Branching and Linear Time
Branching and linear time has more to do with how a person views reality. In 
the case of TASpec, we are only handling the case of single threaded programs, 
so the discussion about concurrent programs in [Lamport80] does not apply. We 
think the concept of linear and branching temporal logic can be applied in the 
following way. If a program has all information which it needs to run, before the 
program starts (such as a calculation intensive program), we consider that linear 
time logic is the more appropriate paradigm because we have all the information 
before the program starts to determine what the final result will be. If a program 
takes external input as it is running, we consider branching logic to be more ap-
propriate because at any input state in the program, the next state depends upon 
the external input that may not be known when the program started. 
Time and Before and Until Temporal Operators 
In specification, there is a notion of “strong” and “weak” versions of the before 
and until temporal operators. Let A and B be states of the program. For the strong 
version of before, A before B means that if the execution enters state A, then the 
execution will enter state B at some point before the execution terminates. If the 
execution enters state A and thereafter never enters state B, then the expression 
is false. The expression becomes true only if state B is entered, and state A was 
entered before state B was entered. By comparison, for the weak version of before, 
A before B means that if the execution entered state A, it may or may not enter 
state B. As soon as state A is entered, the expression becomes true whether or not 
© 2011 by Apple Academic Press, Inc.
  

312  Computer Technology and Computer Programming: New Research and Strategies
state B is entered subsequently. This expression is false if state B is entered before 
state A is entered. 
However, the fundamental difference between checking specifications in 
TASpec and in logic creates a problem with mapping operators. Consider the 
before operator in (most) temporal logics. If A happened in the past, but is no 
longer true when B, then A before B would be true. Now consider the same op-
erator in TASpec, and recall TASpec considers states A and B as facts in a database. 
These facts may be asserted (added to the database of current facts) or retracted 
(removed from the database of current facts). All checking is done over the set of 
current facts in the database. This means that if state A is entered, then left, then 
state B is entered, there is no indication that when state B is entered (and the fact 
corresponding to B is in the database), that state A held earlier (because as state 
A holds no longer, the fact corresponding to state A has been retracted from the 
database and is not there). 
The TASpec interpretation of the before temporal operator actually states a 
precondition. So, A before B means “fact A is asserted before fact B is asserted, 
and must be asserted when B is asserted.” Because multiple assertions are allowed, 
this definition needs to be made more precise. With multiple assertions, it is pos-
sible that A could be retracted in the same event that asserts B, in which case A 
before B would be false. So we should say that A must be asserted when B is first 
asserted. This means that the TASpec equivalent of “strong before” is: 
A implies ((A before B) and eventually B) 
But what if fact A needs to remain asserted throughout the whole time that 
B is asserted? For example, for the fact Authenticated(user) (meaning the user is 
authenticated) and the fact LoggedIn(user) (meaning the user has logged in), we 
want the property that Authenticated(user) is asserted before LoggedIn(user) is as-
serted, and Authenticated(user) remains asserted while LoggedIn(user) is asserted. 
How can we express that? We might use two properties to express this: 
A before B 
(A and B) until (not B) 
In terms of strength, the TASpec before operator is weak, and the TASpec 
until operator is strong. The reason for this choice is simply that the security 
properties found so far were easier to express using this arrangement. An alternate 
arrangement would work equally well. 
Expressibility 
There is a tension between how easily a property can be expressed and how power-
ful the language is. It is the same tension that is found between high level and low 
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language for Property-Based Testing  313
level programming languages. Programming in a high level language like Modula 
makes high-level tasks easy, but the programmer loses the ability to access the 
machine architecture directly, as she can do when programming in assembly lan-
guage. But the effort to write an accounting system (for example) in assembly 
language is much higher than in Modula, and the programmer is more prone to 
make a mistake. 
Intuitively, we would like to be able to express every kind of property in 
one language. Someone may create a language in which this is possible. But, as 
[Lamport80] mentions, “this approach is based upon the misguided notion that 
the more expressive a system is, the better it is.” We have high level languages to 
create an abstraction in order to hide the irrelevant details of the specific model 
we are working with. 
TASpec has some limits that make expressing certain types of properties dif-
ficult. For example, consider the issue of “bounds”, where one wants to say that 
between states P and R, the system is always in state Q. In many logics, this could 
be expressed as: 
(P before Q) and (Q before R) 
In TASpec, because of the representation of states as facts in the database, this 
is more complex: 
(not P) implies (not Q) 
P implies Q 
Q and not R 
Taking these three properties together, we have: 
• If fact P has not been asserted, then if fact Q is asserted, the first property fails; 
• If fact P has been asserted and fact Q has not been asserted, the second property 
fails; 
• If fact R has been asserted and fact Q remains asserted, the third property fails 
Combining these three statements, we have the desired result. 
Now consider an “after” operator. This is more complex, because the 
TASpec before operator is weak. Expressing “A before B and ~A after B all the 
way to the end of the execution” would require converting the “after” operator 
to some expression using the before operator. A strong before operator would 
do this nicely, but the TASpec before operator is weak. So, this expression 
takes two steps: 
1.	 Convert the “after” operator into a form using the strong “before” opera-
tor. This gives:
© 2011 by Apple Academic Press, Inc.
  

314  Computer Technology and Computer Programming: New Research and Strategies
(A before B) and not ((B before not A) “strong before” A) 
2.	 Express the strong “before” operator using the weak before operator, as 
described above. 
This demonstrates the difficulty of mapping model checking specifications to 
TASpec. The reason for the difficulty is that the languages are fundamentally dif-
ferent, in that TASpec uses the model of facts in a database and logic languages 
use events. An event occurs. A fact is in the database or not in the database, but 
in TASpec’s model one can record that a fact was in the database but is no longer 
there only by entering another fact in the database. This makes the underlying 
model of TASpec more like an assembly language, and the model-checking lan-
guages more like higher level languages. Intuitively, this makes sense, as TASpec 
deals with a much lower level of detail than is found in most models. 
Common Vulnerabilities 
Four common vulnerabilities are the escalation of privileges before authentica-
tion, buffer overflows, race conditions involving file accesses, and the ability to ac-
cess files using a web server because the server does not adequately check the path 
name of the requested file. In this section, we present descriptions of how to write 
properties that will handle these problems. We assume a UNIX-like environment 
(this includes Linux), and present the first three properties for C programs, and 
the fourth for Java programs. 
Privilege Escalation without Authentication 
The problem of escalating privileges when a user has not properly authenticated 
herself arises because of programming flaws in most cases. In the UNIX world, 
consider the following program fragment: 
/* get user name */ 
if (fgets(stdin, uname, sizeof(uname)–1) == NULL) 
 return(FAILED); 
/* get user password */ 
typedpwd = getpass(“Password: “); 
/* now get information about user with that name */ 
if ((pw = getpwnam(uname)) != NULL){ 
 /* generate user’s password hash */ 
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language for Property-Based Testing  315
 hashtp = crypt(pw->pw_passwd, typedpwd); 
 /* compare this to stored hash; 
 if match, grant access */ 
 if (strcmp(pw->pw_passwd, hashtp) == 0){ 
 /* match -- grant access */ 
 setuid(pw->pw_uid); 
 return(SUCCESS); 
 } 
 /* didn’t match -- fall through to deny access */ 
} 
return(FAILED); 
This fragment reads a user’s name into a buffer, obtains the password from the 
user, and then validates it. If the password is correct, the user acquires privileges 
(the setuid system call). If not, an error code is returned. 
Although this segment of code is straightforward, the escalation often occurs 
long after the authentication. If the programmer errs, the escalation may occur 
despite a user’s having incorrectly authenticated herself. A bug in an FTP server 
illustrated this. The program authenticated the user, and set a “correct authentica-
tion” flag. If the user then tried to change to a new login (say, root), but entered 
an incorrect password, the authentication would fail but the flag would not be 
reset. As obtaining privileges was contingent on the flag being set, the user would 
promptly acquire root privileges without authorization. 
We define a set of properties to capture the various states. The authentication 
process begins when a name is mapped to a set of privileges (pwent->pw_uid) and 
a password. This property is described as: 
location func getpwnam(name) result pwent 
{ assert user_password(name, 
pwent->pw_passwd, pwent->pw_uid); } 
This instructs the instrumenter to add code to assert the predicate 
user_password(name, password, UID) 
with name, password, and UID the values stored in the variables name, pwent-
>passwd, and pwent->pw_uid, respectively. 
The next state occurs when the cleartext password is hashed to produce the 
stored password. This property is described as: 
© 2011 by Apple Academic Press, Inc.
  

316  Computer Technology and Computer Programming: New Research and Strategies
location func crypt(password,salt) result encryptpwd 
{ assert password_entered(encryptpwd); } 
This instructs the instrumenter to add code to assert the predicate 
password_entered(hash) 
where hash is the value returned by the function crypt, which is in fact a hash 
computed in the same way that a stored password is derived from the correct 
cleartext password. 
The next state is entered when the computed hash is compared to the stored 
password: 
location func strcmp(s1, s2) result 0 
{ assert equals(s1, s2); } 
At this point, the user would enter the authenticated state if the following 
holds:
password_entered(pwd1) and 
user_password(name, pwd2, uid) and 
equal(pwd1, pwd2) 
{ assert authenticated(uid) ; } 
Note this property is not tied to any function in the program. If, at any point, 
the three assertions joined by “and” in the above property hold, the predicate 
“authenticated(uid)” becomes asserted—and the “uid” corresponds to 
that of the predicate “user_password.” 
Finally, when privileges are escalated, we need to indicate this change of state. 
The relevant property is: 
location func setuid(uid) result 1 
{ assert access_acquired(uid); } 
Note this includes the UID to which privileges are given. 
To tie all this together, we require that one authenticate as a particular user 
before being given privileges of that user: 
check authenticated(uid) before access_acquired(uid) 
Now, let us consider two executions of this program. In the first, all proceeds 
as expected. The user “me” with UID 917 provides the correct password. During 
execution of the code fragment, after the setuid system call, the set of facts in the 
database is: 
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language for Property-Based Testing  317
user_password(“me”, “xyz”, 917) 
password_entered(“xyz”) 
equals(“xyz”, “xyz”) 
authenticated(917) 
access_acquired(917) 
At this point, the predicate 
authenticated(917) before access_acquired(917) 
holds, and no violations are found. But now the same user tries to become root, 
and supplies an incorrect password. After this (second) execution of the setuid 
system call, the database contains: 
user_password(“me”, “xyz”, 917) 
password_entered(“xyz”) 
equals(“xyz”, “xyz”) 
authenticated(917) 
access_acquired(917) 
user_password(“root”, “abc”, 0) 
password_entered(“xyz”) 
equals(“abc”, “xyz”) 
access_acquired(0) 
Now the property
authenticated(0) before access_acquired(0) 
is false, and the TEM would report a violation. 
File Creation Race Condition 
This flaw arises when two actions, in this example file creation and changing file 
ownership, are sequential and a third action can occur between the two. Consider 
a program executing as root that performs the following sequence of actions: 
Create file 
Read data from another program, adding it to file 
Close file 
Change ownership of file from root to user 
© 2011 by Apple Academic Press, Inc.
  

318  Computer Technology and Computer Programming: New Research and Strategies
If reading the data takes long enough for someone else to change the binding 
of the file name (used for the “create” and the “change ownership”) to the file 
object, then the file whose ownership is changed will not be the one that was cre-
ated. This can allow an unprivileged user to create a privileged program without 
authorization. 
The relevant code fragment is: 
/* create the file */ 
if ((fd = creat(“xyz”, O_WRITE) >= 0){ 
/* read input and copy it to the 
created file */ 
while(read(buf, 1000, finp) > 0) 
write(buf, n, fd); 
/* close it */ 
close(fd); 
/* change ownership from root to 
user 917 group 10 */ 
chown(“xyz”, 917, 10); 
} 
The race condition is exploited by a second program (one that does the re-
binding). But as noted earlier, TASpec does not deal with concurrent programs. 
So, we look for system calls and functions that can block execution, such as the 
“read” function. Then a window of time during which the race condition can be 
exploited can be detected. 
This involves two states. The first is access(file), in which the named file is be-
ing accessed. The second is block(file), in which the race condition exists. They 
work together as follows. 
When the file is created, the process enters the access(file) state, and is not in 
the block(file) state. This is expressed as: 
location func creat(file){ 
 assert access(file); retract block(file); 
} 
When the file is read, if the process is in the access(file) state, it then enters the 
block(file) state. The relevant property is: 
location func read(){ 
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language for Property-Based Testing  319
if access(file) { assert block(file) }; 
} 
Note here the file name carries over from the last creat system call. When the 
file’s ownership is changed, the process must not be in the block(file) state. That 
is expressed as: 
location func chown(file, user, group){ 
check not block(file); 
} 
Consider the database when the above code fragment is executed. After the 
creat, the database contains: 
access(“xyz”) 
After the while loop, the database contains: 
access(“xyz”) 
block(“xyz”) 
... 
where the block(“xyz”) predicate is repeated as many times as the loop is ex-
ecuted. 	When the chown system call is executed, the property 
not block(“xyz”) 
is tested, and fails. So this reports that a race condition exists. 
Buffer Overflows 
Buffer overflows are pernicious. A common source of buffer overflows is in the 
redaction of command line arguments. For example, in the fragment: 
int main(int argc, char *argv[]) 
{ 
char pname[1024]; 
for(i = 0; argv[0]; i++) 
pname[i] = argv[0][i]; 
pname[i] = ‘\0’ 
there is an implicit assumption that the name of the program (argv[0] will not 
be more than 1023 characters long. If it is, a buffer overflow will result. 
First, we need to define a property that describes buffer overflow. It occurs 
when an array reference is out of bounds. Every array has an upper bound (for 
© 2011 by Apple Academic Press, Inc.
  

320  Computer Technology and Computer Programming: New Research and Strategies
pname, 1023) and a lower bound (for pname, 0). Our property will say that when 
an array reference to element i occurs, and the array’s bounds are l (lower) and u 
(upper), then l _ i and i _ u must both hold. 
We define the predicate array(pname, 0, 1023) to mean that the array pname 
was declared with upper bound 1023 and lower bound 0. We define the predicate 
arrayref(pname, i) to mean that element i of array pname was referenced. The 
property to be tested is then: 
check array(aname,lower,upper) and arrayref(aname,index) 
implies (lower <= index and index <= upper) 
Note that we need not explicitly name the array in the property. The TEM will 
validate all array references when checking the property. 
Next, we must instruct the instrumenter to put these predicates, and the prop-
erty, into the source file appropriately. We use location specifiers to do this. The 
property file is: 
location decl pname[1024] { 
assert array(pname, 0, 1023); } 
location variable pname[i] { 
assert arrayref(pname, i); 
check array(aname,lower,upper) and 
arrayref(aname,index) 
implies (lower <= index and index <= upper); 
} 
Unlike the property, the “pname” and “i” in the first two lines must match 
the variables in the program. The instrumenter will transform the code fragment 
above into the following (conceptually; several implementation-level details and 
error checking are omitted): 
int main(int argc, char *argv[]) 
{ 
char pname[1024]; 
tf = open(“directivefile”, WR_ONLY); 
fprintf(tf, “assert array(pname, 0, 1023)\n”); 
for(i = 0; argv[0]; i++){ 
fprintf(tf, “assert arrayref(pname, i)\n”); 
fprintf(tf, “check ...\n”); 
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language for Property-Based Testing  321
pname[i] = argv[0][i]; 
} 
fprintf(tf, “assert arrayref(pname, i)\n”); 
fprintf(tf, “check ...\n”); 
pname[i] = ‘\0’ 
(The “check ...” refers to the entire check in the property file; it is elided for 
clarity.) The program containing this code fragment can now be compiled and 
executed. 
Assume the program is given a name of 1025 characters. When the run is 
complete, the state file will contain: 
assert array(pname, 0, 1023); 
assert arrayref(pname, 0); 
check array(aname,lower,upper) and arrayref(aname,index) 
implies (lower <= index and index <= upper); 
... 
assert arrayref(pname, 1024); 
check array(aname,lower,upper) and arrayref(aname,index) 
implies (lower <= index and index <= upper); 
assert arrayref(pname, 1025); 
check array(aname,lower,upper) and arrayref(aname,index) 
implies (lower <= index and index <= upper); 
(the ellipsis indicates 1023 lines elided). When the TEM is run over this state 
file, the property will be checked at every arrayref, because both predicates hold. 
At the next-to-last check above, the antecedents are true, but the consequent is 
false, as index is 1024. Hence the TEM will report a violation of the property. 
Improper Web Server Restriction
The next bug is one common to older web servers. When a web browser connects 
to a web server, the web server gives the browser access to a hierarchy of files. The 
area accessible to the browser is to be restricted to the top-level directory of this 
hierarchy, and its descendents. Hence an attempt to access the file “../../../../../
etc/passwd” should fail if made from the top-level directory. The “..” means to ac-
cess the parent directory. That directory exists on the web server, but the software 
should block access to it. Unfortunately, many web servers do not restrict this 
© 2011 by Apple Academic Press, Inc.
  

322  Computer Technology and Computer Programming: New Research and Strategies
type of access. In this case, attackers can read system and other files not in the 
web hierarchy. 
As a test of the Java implementation of property-based testing, we obtained 
a Java web server and had a student delete the checks for this flaw. We then used 
property-based testing to determine whether the flaw existed. 
The basic structure of the relevant parts of the web server are as follows. A 
method called HttpWorker.doit() is given the URL from the browser. If the URL 
is illegal in any way, the web server throws an exception with that URL passed as 
a parameter. 
First, we define the property. For this example, we will assume there are no 
subdirectories of the hierarchy. This simplifies the statement of properties without 
changing the basic ideas. Again, we define two predicates. The first, hasDotDot(url), 
asserts that the URL url has the “..” in it. The second, causedException(req), as-
serts that the URL req caused an exception to be thrown. Then the property of 
interest is: 
check hasDotDot(url) implies causedException(url); 
because if hasDotDot(url) is true, and causedException(url) is true, the URL 
referred to the parent directory and was caught. But if hasDotDot(url) is true and 
causedException(url) is not asserted, then the invalid URL is not caught and the 
property was violated. 
We next instrument the server. The assertion for a URL referring to the parent 
goes, as indicated, at the beginning of HttpWorker.doit(): 
location assign HttpWorker.doit()::req result r 
if “r.getRequestURI.indexOf(\.”./\”) > -1” { 
assert hasDotDot(r); 
}
This says to check whenever something is assigned to the variable req in the 
function doit() in the class HttpWorker. If the new value of req contains “..” (the 
“if” part) then the program will output the appropriate assertion. Similarly, the 
assertion for exceptions is output when the reply function in the exception part 
of the class is called: 
location funcall HttpException::reply(HttpRequest req, 
HttpResponse res){ 
assert causedexception(req); 
} 
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language for Property-Based Testing  323
This binds the assert to the call to the reply function in the class HttpEx-
ception. Note the URL is output; the specific response sent is irrelevant to the 
property. 
When the instrumented web server was run, and a browser requested an illegal 
URL, the state file contained: 
check hasDotDot(Areq) implies causedException(Areq); 
assert hasdoddot(“/../../../../../etc/passwd”); 
check hasDotDot(Areq) implies causedException(Areq); 
The first line is vacuously true, as hasDotDot(Areq) has not been asserted. 
The last line, however, is false, because hasDotDot(“/../../../../../etc/passwd”) is 
asserted, but the corresponding causedException(“/../../../../../etc/passwd”) has 
not been asserted. 
As a control, the same sequence of URLs was requested from an instrumented 
but correct version of the same web server. The state file for that version of the 
program contained: 
check hasDotDot(Areq) implies causedException(Areq); 
assert hasdoddot(“/../../../../../etc/passwd”); 
assert causedException(“/../../../../../etc/passwd”); 
check hasDotDot(Areq) implies causedException(Areq); 
Both hasDotDot(“/../../../../../etc/passwd”) and causedException(“/../../../../../
etc/passwd”) have been asserted when the final check is made. 
Summary
This section presented four examples of programs with common flaws. We 
showed the properties that described each, and the instrumenting necessary to 
enable the TEM to detect changes of state that affect the truth of the properties 
as the program runs. These examples demonstrate the usefulness of this testing  
methodology.
Conclusion
Although it is used to specify properties that programs must satisfy, TASPec is 
different from logic languages used to do model checking. The key difference 
comes from TASpec’s model of events (state changes are represented as facts in a 
database), which differs from the notion of state changes used in model checking. 
© 2011 by Apple Academic Press, Inc.
  

324  Computer Technology and Computer Programming: New Research and Strategies
TASpec’s lack of history constructs increases the complexity of expressing some 
temporal events. Fortunately, as shown by the description of several common 
vulnerabilities above, these do not affect the use of TASpec to describe many com-
mon implementation flaws. 
References 
1.	 M. Bishop, Computer Security – Art and Science, Addison Wesley, Boston, 
MA (2003).
2.	 L. Lamport Leslie, “‘Sometime’ Is Sometimes ‘Not Never’: On the Temporal 
Logic of Programs”, Proceedings of the 7th ACM SIGPLAN-SIGACT Sympo-
sium on Principles of Programming Languages pp. 174–185 (Jan. 1980).
3.	 A. van Lamsweerde, “Formal Specification: a Roadmap”, Proceedings of 
the Conference on The Future of Software Engineering, pp. 147–159 (June 
2000).
4.	 M. Dwyer, G. Avrunin, and James C. Corbett, “Property Specification Patterns 
for Finite-State Verification”, Proceedings of the Second Workshop on Formal 
Methods in Software Practice, pp. 7–15 (Mar. 1998).
5.	 M. Dwyer, “Spec Patterns”, athttp://patterns.projects.cis.ksu.edu/documenta-
tion/patterns.shtml.
6.	 G. Fink and M. Bishop, “Property Based Testing: A New Approach to Testing 
for Assurance,” ACM SIGSOFT Software Engineering Notes 22 (4) pp. 74–80 
(July 1997).
7.	 G. Fink, Discovering Security and Safety Flaws using Property-Based Testing, 
Ph.D. Thesis, Dept. of Computer Science, University of California, Davis, CA 
95616–8562 (1996).
© 2011 by Apple Academic Press, Inc.
  

Some Attributes of a Language for Property-Based Testing  325
Copyrights
1.	 Copyright © 2009 Sanjay L. Badjate and Sanjay V. Dudul. This is an open 
access article distributed under the Creative Commons Attribution License, 
which permits unrestricted use, distribution, and reproduction in any medium, 
provided the original work is properly cited.
2.	 Copyright © 2010 Ludovic Devaux et al. This is an open access article distrib-
uted under the Creative Commons Attribution License, which permits un-
restricted use, distribution, and reproduction in any medium, provided the 
original work is properly cited.
3.	 This is an open access article distributed under the Creative Commons Attribu-
tion License, which permits unrestricted use, distribution, and reproduction in 
any medium, provided the original work is properly cited.
4.	 This is an open access article distributed under the Creative Commons Attribu-
tion License, which permits unrestricted use, distribution, and reproduction in 
any medium, provided the original work is properly cited.
5.	 This is an open access article distributed under the Creative Commons Attribu-
tion License, which permits unrestricted use, distribution, and reproduction in 
any medium, provided the original work is properly cited.
6.	 This is an open access article distributed under the Creative Commons Attribu-
tion License, which permits unrestricted use, distribution, and reproduction in 
any medium, provided the original work is properly cited.
7.	 Copyright © 2009 Mohammad Shorfuzzaman et al. This is an open access 
article distributed under the Creative Commons Attribution License, which 
permits unrestricted use, distribution, and reproduction in any medium, pro-
vided the original work is properly cited.
8.	 Copyright © 2009 Stanislava Soro and Wendi Heinzelman. This is an open 
access article distributed under the Creative Commons Attribution License, 
which permits unrestricted use, distribution, and reproduction in any medium, 
provided the original work is properly cited.
9.	 © 2010 by the author; licensee Molecular Diversity Preservation International, 
Basel, Switzerland. This article is an open-access article distributed under the 
terms and conditions of the Creative Commons Attribution license http://cre-
ativecommons.org/licenses/by/3.0/. 
10.	 © 2010 by the authors; licensee Molecular Diversity Preservation Internation-
al, Basel, Switzerland. This article is an open-access article distributed under 
the terms and conditions of the Creative Commons Attribution license (http://
creativecommons.org/licenses/by/3.0/). 
© 2011 by Apple Academic Press, Inc.
  

326  Computer Technology and Computer Programming: New Research and Strategies
11.	 Copyright © 2009 Mathieu Muratet et al. This is an open access article dis-
tributed under the Creative Commons Attribution License, which permits un-
restricted use, distribution, and reproduction in any medium, provided the 
original work is properly cited.
12.	 © 2009 Meir, Rubinsky. This is an open-access article distributed under the 
terms of the Creative Commons Attribution License, which permits unrestrict-
ed use, distribution, and reproduction in any medium, provided the original 
author and source are credited.
13.	 © 2010 Jacobsen et al.; licensee BioMed Central Ltd. This is an Open Access 
article distributed under the terms of the Creative Commons Attribution Li-
cense (http://creativecommons.org/licenses/by/2.0), which permits unrestrict-
ed use, distribution, and reproduction in any medium, provided the original 
work is properly cited.
14.	 Public Domain
© 2011 by Apple Academic Press, Inc.
  

A
AAs. See active applications (AAs)
“Abschicken” (Submit) button, 216
Academic Java, 214
acoustic waves, 286
active applications (AAs), 128, 146
active network services, 128
active node architecture, schematic repre-
sentation of, 147
active video adaptation node, 152
implementation of
active node components, 146–47
complexity and portability imple-
mentation, 152–54
hashing, 152
IXP1200, mapping algorithms, 
148–49
packets, classification of, 150–52
transmitting packets, 152
video packets through active node, 
147–48
Index
adaptive cryptographic system,  
architecture of, 122
adaptive video multicast, 129
advanced video coding (AVC), 133
Ajax. See Asynchronous JavaScript and 
XML (Ajax)
algorithm animations, 247
algorithmic complexity, growth rate of, 115
Alice, 214
Altera, 85
ANIMAL animations, 221, 226
hypertextbook, screenshot of, 224
user front-end animating BubbleSort 
screenshot, 222
ANIMALSCRIPT visualization scripting 
language, 221, 222
animating algorithms, 220–24
animations, 232
application-specific IC (ASIC) design, 113
ARQ. See automated-repeat-request 
(ARQ)
ASCII code, 87
© 2011 by Apple Academic Press, Inc.

328  Computer Technology and Computer Programming: New Research and Strategies
ASIC. See application-specific IC (ASIC) 
design
ASSEMBLER, 269
Asynchronous JavaScript and XML (Ajax), 
101
bandwidth usage, 100
web applications vs. classic, 102
automated-repeat-request (ARQ), 172
auto regressive moving average model, 16
AVC. See advanced video coding (AVC)
AVL trees, 220
B
back-propagation (BP) network, 11
bandwidth, 52, 58
utilization, 129, 194
battery-operated camera nodes, 171
lifetime of, 195
behavior recognition, 183
bilinear interpolation, 139, 140
Blackboard-based middleware approach, 
201
BlueJ program, 214
bluetooth transmitter, 285
BMs. See bus macros (BMs)
boost interprocess library, 266
BP network. See back-propagation (BP) 
network
broad-band Wi-Fi, 281
Bubble Sort, 222
buffer depth, 75
influence of, 76
buffer overflows, 319–21
bus-based architectures, 55, 59
bus-macro-based architecture, 54
bus macros (BMs), 53, 63
definition of, 53
BYTE, 269
C
CABAC. See context-adaptive binary 
arithmetic coding (CABAC)
cameras, 170
autonomous camera calibration  
algorithms, 178, 180
autonomous systems, 174
calibration of, 177
communication, 174
energy resources, 173
epipoles of, 179
image capturing time, 199
JPEG2000, 192
locations, 177
network, 169, 176
nodes activity, 173, 191
capsules, 128
cascading style sheets (CSS), 102, 104
CAVLC. See context-adaptive variable-
length coding (CAVLC)
CDMA systems. See code division mul-
tiple access (CDMA) systems
CE. See communicating element (CE); 
computer engineering (CE)
CEdest, 65
CEsrc, 65
chaotic differential equations, 18
chaotic time series, 18
applications, 10
Duffing time series, 19–20
forecaster, 12
laser time series, 21
Mackey-Glass time series, 19
sunspot time series, 20–21
Chipcon CC2420, 197
Chomsky-hierarchy, 93
Chomsky’s transformational language 
model, 91
CMUCam camera sensors, 198
CMUCam3 sensor, 199
CMUCam3 vision, 198
code division multiple access (CDMA) 
systems, 11
Colobot, 258, 263
colored data structure, 236
communicating element (CE), 51
average and latencies, 72
base-and root-level, 61
© 2011 by Apple Academic Press, Inc.
  

Index  329
definition, 52
DRAFT, root-level of, 65
generic addressing of, 64
communication protocols, 185
adaptive energy-conserving data trans-
mission model, 186
collaborative image data routing, 
190–91
delay sensitive, 188–90
reliability, 187–8
wireless sensor networks, 185
compression domain frame dropping 
technique, 160
computational costs, 92
computer engineering (CE), 255
computing systems, 113
configuration ware, 114
configware, 114
CoNoChi, topology of, 58
context-adaptive binary arithmetic coding 
(CABAC), 133
context-adaptive variable-length coding 
(CAVLC), 133
conventional multi-processor systems, 116
correlation coefficient, 18
cross-validation (CV), 26
cryptographic algorithm, 121
cryptographic applications, reconfigurable 
hardware (RCHW), 118
CSS. See cascading style sheets (CSS)
CV. See cross-validation (CV)
D
“Darfur is Dying” game, 253, 254
DARPA. See Defence Advanced Research 
Projects Agency (DARPA)
data
acquisition, 283, 285, 289
bandwidth, 116
frequency, 87
performances measurements, 283
processing, 172
routing, 187
storage mechanism, 282
structures, 220–24
data encryption, 82, 83
algorithm of, 83
resource usage, 88–89
simulation for, 86–88
Data_in + Mem, 87
Data_test values, 86, 89
data traffic, 52
pareto on/off, 76
type of, 76
DCT. See discrete cosine transform 
(DCT)
Defence Advanced Research Projects 
Agency (DARPA), 253
DGR algorithm. See directional geograph-
ical routing (DGR) algorithm
DICOM files, 287
directional geographical routing (DGR) 
algorithm, 187
discrete cosine transform (DCT), 128, 
196
block, 141
coefficients, 140, 150
domain, 141
frequency transformation, 132
video compression algorithm, 137
distributed source coding (DSC), 202
divide-and-conquer algorithms, 235–36
document object model (DOM), 105
DPR. See dynamic and partial reconfigu-
ration (DPR)
DRAFT. See Dynamic Reconfiguration 
Adapted Fat-Tree (DRAFT)
DRAGOON. See Dynamically Reconfigu-
rable Architecture Compliant Generator 
and Simulator of Network (DRA-
GOON)
DrScheme, 214
DSC. See distributed source coding (DSC)
Duffing equation, 19
Duffing time series, 12, 20, 29, 35
chaotic, 25
desired and FTLRNN outputs, 36, 37
epoch’s variation on errors, 34, 35
© 2011 by Apple Academic Press, Inc.
  

330  Computer Technology and Computer Programming: New Research and Strategies
error norms variations for, 24
flow chart, 13
learning rules variations for, 23
MLPNN and FTLRNN, performance 
of, 25
MSE, optimal values of, 24
Dynamically Reconfigurable Architecture 
Compliant Generator and Simulator of 
Network (DRAGOON), 52, 60, 67
conception flow of, 67
flit width/buffer depth, 67
presentation of, 67–68
dynamic and partial reconfiguration 
(DPR), 51
constraints, current interconnection 
structures, 59
ports, 53
dynamic programming algorithms, 232
Dynamic Reconfiguration Adapted Fat-
Tree (DRAFT), 52
application, implementation of, 77–78
fat-node-based structure, 62
fat-tree-based network, 60
implementation of, 66–67, 68
data traffic, type of, 76–77
hardware resources, 69–70
network performances, 70–71
scalability, 73–76
interface, 63
networks, 68
router-based, 62
routing algorithm, 65
topology
communicating elements, 60
fat-tree, 61
hardware resources, 61
unitary router architecture, 64
used for, 70
view of, 78
E
e-commerce, 120
EEClone, 257, 258
EEs. See execution environments (EEs)
e-government, 120
electrical impedance tomography (EIT), 
278
electromagnetic wave propagation, radar 
modeling of, 10
embedded microprocessor model, 113
encryption algorithm, 119
encryption module, of RC6, 120
end-to-end data transmissions, 185
end-to-end QoS, 129
EPROM memory, 86, 87
EROSI, 237
Euclidian distance, 193
execution environments (EEs), 146
executive processor (XP), 145
F
fabric processor (FP), 145
fast fly-by overview, 223
fast pattern processor (FPP), 145
fat-tree topology, 59
FDMA channel model, 189
FEC. See forward-error-correction (FEC)
Fibonacci series, 234
field programmable gate array (FPGA), 
52, 53, 57, 78, 114, 115, 116, 118
communicating element (CE), 51
cryptography
algorithm agility, 119
algorithm modification, 119
algorithm upload, 119
architecture efficiency, 119
cost efficiency, 119
resource efficiency, 119
throughput, 119
heterogeneity of, 53
FireFly system, camera network graph of, 
200
FIR laser, 21
flexible interconnection
DRAFT topology, 60–61
hardware resources, 61–62
© 2011 by Apple Academic Press, Inc.
  

Index  331
flit size, 75
flowware, 123
formal grammars, 93
forward-error-correction (FEC), 172
FOSFOR research project, objective of, 51
FP. See fabric processor (FP)
FPGA. See field programmable gate array 
(FPGA)
FPP. See fast pattern processor (FPP)
frame dropping, 137
throughput of, 160
frame rate, 140
frame resizing, 141–42
frame transmission rate, 151
FTLRNN model, 12, 15–17, 24, 29
desired vs. actual FTLRNN
plot of, 40, 41, 44, 45
desired vs. actual plot of, 40
desired vs. FTLRNN plot of, 40, 44, 
45
dynamic model, 29
experimental results, 22–29
with gamma filter, 30
with gamma memory, 22
mean square error (MSE) criteria, 14, 
22–29
real sunspots time series and laser time 
series for, 24
real-time series, optimal parameters of, 
23
on testing data set, 26, 27, 28, 29
time series, optimal parameters of, 22
G
game
complexity, 254
course, organization of, 271
engine choice, 263
kernel panic, 268–69
mapping learning objectives
knowledge point of view, 267–68
student point of view, 267
teacher point of view, 267
skirmishes, 270
gamma memory, 16, 17, 30
filter, 12
PE, fast-moving signals, 17
gesture analysis, 183
Git multi-user versioning system, 299
Greenfoot programming tool, 214
H
hand-eye coordination process, 284
hardware acquisition device, raw data 
flows to mobile console, 289
hardware encryption, 83–85
example, 84–85
on the fly, 83
principle, 83–84
simulation for, 86–88
hardware implementation, 85–86
hardware processor, 52, 196
HDTV. See high-definition TV (HDTV)
health care technology, 277
high-definition TV (HDTV), 131
high-performance computing (HPC), 117
HMM models, 94
HoneyComb architecture, 54
HPC. See high-performance computing 
(HPC)
HTML. See hypertext markup language 
(HTML)
HTTP protocol, 287
HttpWorker.doit(), 322
human gesture analysis, 183
Hungarian language
grammer model, 92–94
NL module for, 92
processing of, 98
H.261 video coding, 132
H.263 video coding, 133
H.264 video coding, 133
hypertext markup language (HTML), 6, 
100, 103, 104, 296, 302
I
IBM PowerNP, 144
© 2011 by Apple Academic Press, Inc.
  

332  Computer Technology and Computer Programming: New Research and Strategies
image frames, analysis of, 173
image processing algorithms, 172
image resolution, 197
image sensors, 170
image transmition, 171
IMU. See internal measurement unit 
(IMU)
information systems (IS), 255
information technology (IT), 255
information visualization (InfoVis field), 
232, 239
in-network video transcoding techniques, 
128
in heterogeneous multicasting, 127
use of, 128
input/output buffers, requantization, 151
Insertion Sort, 223
integrated breast cancer self-examination 
device, 285
intellectual property (IP), 63
Intel’s hyper task chaining technology, 143
interconnection architectures
bus-based architectures
limitations of buses, 55
main-bus-based architectures, 54
network-on-chip based architectures
application-dependent topology, 
57–58
fat-tree topology, 58–59
mesh topology, 55–57
ring topology, 58
summary of, 59–60
internal measurement unit (IMU), 289
Internet, 82, 126, 220
int values, array of, 216
inverse-DCT transforms, 134
IP. See intellectual property (IP)
IP address, 288
IS. See information systems (IS)
IT. See information technology (IT)
IXP1200 network processor
multithreading architecture, 156
network processor, 128, 130
transcoding node, 154
video transcoder, 154
J
Java programming tasks, 215
Java programs, 97, 314
JavaScript, 100, 103
Java tasks, 215
JPEG processing, 199
jQuery technology, 100
JSON array, 108
JUnit tests, 217
K
Kalman filtering, 179, 182
kernel panic, 264
kiosk mode, 223
L
laser time series, 21, 22, 24, 27, 41
correlation coefficient, epochs variation 
performance, 43
learning rules variations for, 23
MLPNN and FTLRNN, performance 
of, 25
MSE, epochs variation performance, 
42
NMSE, epochs variation performance, 
42, 43
layered video, 129
LCD line, 285
learning algorithms, 232
learning programming, tools
Academic Java, 214
Alice, 214
BlueJ, 214
DrScheme, 214
Greenfoot, 214
LIFO processing model, 94
context-free grammar, 94
push-down automaton, 94
LoggedIn, 312
Login.php, 106
Logitech webcam, 195
low-pass filters, 140–41
© 2011 by Apple Academic Press, Inc.
  

Index  333
M
Mackey-Glass chaotic time series, 11, 12, 
19, 29, 30
correlation coefficient, 32
epoch’s variation on errors, perfor-
mance of, 31
error norms variations for, 24
flow chart, 13
FTLRNN output, 32, 33, 34
hybrid network, 11
learning rules variations for, 23
MLPNN and FTLRNN, performance 
of, 25
for short-term, 11
Mackey-Glass equation, 19
MAC layer, 194
mask-configurable gate arrays, 113
MC. See motion compensation (MC)
mean square error (MSE), 12, 18
media access control (MAC)
devices, 143
interfaces, 145
medical devices, 278
medical imaging, 277
medical technology, 277
memory
blocks, 88
costs of, 282
EPROM, 86
Kernel, 16
long-term, 15
PE, 16
ROM, 84
short-term, 15
types of, 16
MEMS. See micro electro-mechanical 
systems (MEMS)
mesh network, 57
MicroBlaze processor, 77
micro electro-mechanical systems 
(MEMS), 289
MicroRNAs (miRNAs), 294
miRBase web site, 294
miRMaid software
framework, 297
plugin, 298
resource map, 297
uses, 296
versions, 299
web site, 302
miRNAs. See MicroRNAs (miRNAs)
MLP. See multilayer perceptron (MLP)
mobile agents, 172
mobile console, 280, 281
Modelling, Virtual Environments, and 
Simulation (MOVES), 253
model-view-controller (MVC), 295, 296
Monte Carlo method, 182
monthly sunspot time series, 21
Moodle distributed learning environment, 
223
morphware, 114
in computing sciences, 115
adaptive cryptographic systems, 
120–22
FPGAs, cryptography, 118–20
reconfigurable computer architec-
tures, 115–18
motion compensation (MC), 131
quarter-pixel precision for, 133
motion compensation-based video, 135
motion tracing example, 139
motion vectors, 139
MOVES. See Modelling, Virtual Environ-
ments, and Simulation (MOVES)
MPEG-1 video, 156
coding, 130–31
compression, 131
sequences, 138
properties of, 154
video transcoding for, 158
sequences-PSNR, quality of, 162
MPEG-2 video, 130
coding, 131–32
MPEG-4 video coding, 132
MSE. See mean square error (MSE)
Mshift parameter, 65
© 2011 by Apple Academic Press, Inc.
  

334  Computer Technology and Computer Programming: New Research and Strategies
multicasting, 126, 127
adaptive video, 130
multilayer perceptron (MLP), 13
advantage of, 14
solid-based model, 14
multiple video streams, 149
multi scene analysis, 201
MVC. See model-view-controller (MVC)
MySQL software, 103
N
natural language interface for databases 
(NLIDB)
interface, 92
modules, 91, 94
network heterogeneity problems, 129
network interfaces (NIs), 63
network load, 129
network-on-chip (NoC) paradigm, 55
network processors (NPs), 142
overview of, 142
Agere PayloadPlus, 145
EZChip (NP-1c), 144–45
IBM PowerNP, 144
Intel IXP1200, 143
Intel IXP2400, 143–44
Intel IXP2800, 144
Motorola’s C-5e, 145
networks-on-chip (NoC) topologies, 52
network topologies, 56
neural networks, 11
design algorithm, 19
NIs. See network interfaces (NIs)
NLIDB. See natural language interface for 
databases (NLIDB)
NLI interface, 91
NLP engine, 98
NMSE. See normalized mean square error 
(NMSE)
NoC paradigm. See network-on-chip 
(NoC) paradigm
NoC topologies. See networks-on-chip 
(NoC) topologies
normalized mean square error (NMSE), 
12, 18
NPs. See network processors (NPs)
O
Omnivision OV7649 camera, 195
on-chip scratchpad memory, 143
OpenMRS, 288
open real-time strategy (ORTS), 263
operating system (OS), 51
ORTS. See open real-time strategy 
(ORTS)
OS. See operating system (OS)
P
packet classification, 150
packet-over-SONET (POS), 144
partially reconfigurable regions (PRRs)
definition of, 53
interface, 63
Pascal triangle, 216
PCGF. See probabilistic CGF model 
(PCGF)
PDAs. See personal digital assistants 
(PDAs)
PDUs. See protocol data units (PDUs)
PE. See percentage error (PE)
peak signal-to-noise ratio (PSNR), 161
percentage error (PE), 161
personal digital assistants (PDAs), 126
personal supercomputer (PS), 115
PEs. See processing elements (PEs)
PFs. See programming fundamentals (PFs) 
learning
PHP technology, 100
POS. See packet-over-SONET (POS)
power dissipation, 115
probabilistic CGF model (PCGF), 94
processing elements (PEs), 15
processing server, 281
program animation system, 233, 239, 
244, 247
programming fundamentals (PFs) learn-
ing, 255
features, 255
© 2011 by Apple Academic Press, Inc.
  

Index  335
problems, 255–57
solutions, 256–58
programming languages, 91
programming tasks database, 215–20
program visualization, 214, 220, 223, 
239, 245, 247
property-based testing, 306
protocol data units (PDUs), 145
protoype evaluation, video
IXP1200-based video transcoder, 154
throughput, 158
frame dropping, 159–61
requantization, 158–59
transcoding latency, 155
frame dropping, 156–58
requantization, 155–56
PRRs. See partially reconfigurable regions 
(PRRs)
PS. See personal supercomputer (PS)
PSFQ. See pump slowly fetch quickly 
(PSFQ)
PSNR. See peak signal-to-noise ratio 
(PSNR)
PubMed ID, 302
pump slowly fetch quickly (PSFQ), 187
Q
quality of service (QoS), 126, 142
end-to-end, 129
quantized DCT coefficient (QDCT), 
dequantization of, 136
Quartus II Web Edition 9.0 design soft-
ware, 82, 85, 88
R
radial basis function (RBF) network, 11
radiographers/technologists, 277
RBF network. See radial basis function 
(RBF) network
RC6, encryption module, 120
RCHW. See reconfigurable hardware 
(RCHW)
rDPAs. See reconfigurable datapath arrays 
(rDPAs)
rDPUs. See reconfigurable data path units 
(rDPUs)
read-only memory, 83, 85
real-time monthly sunspots, 27
reconfigurable computer architectures, 
classes of, 117
reconfigurable computing technologies, 
115
reconfigurable datapath arrays (rDPAs), 
114
reconfigurable data path units (rDPUs), 
114
reconfigurable fabric (RF), 116
reconfigurable gate arrays (rGAs), 114
reconfigurable hardware (RCHW), 118
Records.PHP, 107
recursion, 232, 233
animation systems, 236–38
visualization of, 232, 233
SRec, 233–36
visualizations/animations, interacting 
with, 238
abstract/elaborate interaction tech-
niques, 243
connect interaction techniques, 
239–40
encode interaction techniques, 239
explore interaction techniques, 
243–44
filter interaction techniques, 241–43
reconfigure interaction techniques, 
244
select interaction techniques, 
245–46
recursion tree
for fib, 240, 246
for mergesort(), 242, 243
Reed-Solomon error correction, 187
region of interest (ROI), 284
Registry.PHP, 107
remote expert system, 280
RENDEZVOUS system, 91
Report.PHP, 108
© 2011 by Apple Academic Press, Inc.
  

336  Computer Technology and Computer Programming: New Research and Strategies
representational state transfer (REST), 
295
RESTful clients, 300
RESTful web service, 299
RF. See reconfigurable fabric (RF)
rGAs. See reconfigurable gate arrays 
(rGAs)
RMBoC approach, 55
Robocode, 263
ROI. See region of interest (ROI)
ROM memories, 84
root mean squared error, 11
RoR object-relational mapping library, 
301
router architecture, hardware characteris-
tics of, 63–65
routing switch processor (RSP), 145
RTS game, 262
Ruby data models, 301
Ruby object-relational layer, 297
Ruby programming language, 295
Runge-Kutta method, 19
RXshift, 65
S
SAD. See sum of absolute differences 
(SAD)
scalability, 205
network performances, 73
Schedules.PHP, 106
SDP. See serial data processor (SDP)
SensEye platform, 198
sensor management
camera nodes, 192
energy consumption of, 193
policies, 194
comparison of, 192
visual sensor networks, 191, 194
serial data processor (SDP), 145
serious games
definitions, 252
example of, 253–54
implementation, 264–66
and learning, 254–55
students and video games, 259–62
set partitioning in hierarchical trees 
(SPIHT), 196
signal processing algorithms
camera calibration, 177–80
vision-based signal processing, 180
object detection, 181–82
object tracking, 182–83
occupancy reasoning, 181–82
signal processing applications, 51
SimRECUR, 237
simultaneous localization and tracking 
(SLAT) problem, 179
single scene analysis, 201
skirmishes, 262, 267, 270
SLAT problem. See simultaneous localiza-
tion and tracking (SLAT) problem
smart camera networks, 171
SoC. See system on chip (SoC)
software implementations, 83
solar cycle, 20
special command interface (SQL), 91
engine schema, 95
NL, conversion of, 94–97
SPEED protocol, 189
SPIHT. See set partitioning in hierarchical 
trees (SPIHT)
spring engine, 264
characteristics of, 264
SQL. See special command interface 
(SQL)
SQL command, 94
generator application, 97
SQL interface, 91
SRec system, 232
user interface of, 241
static MLP network, 11
static NN-based model, 13–15
use multilayer perceptron (MLP), 13
statistical performance evaluation criteria, 
18
strategy games, 261
compatible with, 262–63
implementation, 263
© 2011 by Apple Academic Press, Inc.
  

Index  337
StrongARM 32-bit RISC microprocessor, 
143
sum of absolute differences (SAD), 142
Sun Microsystems, 103
sunspots time series
correlation coefficient, 39
learning rules variations for, 23
MSE, epochs variation performance, 
38, 39
NMSE, epochs variation performance, 
38, 39
system architecture, mobile console com-
ponent, 280
System.arraycopy, 217
system on chip (SoC), 113
T
task optimized processing core (TOP core) 
technology, 144
TASpec, 307, 308
and model checking languages
branching and linear time, 311
buffer overflows, 319–21
expressibility, 312–14
privilege escalation without authen-
tication, 314–19
taxonomy, 310–11
before and until temporal operators, 
311–12
vulnerabilities, 314
properties, 308
uses, 312
web server restriction, 321–23
works, 309–10
TDNN. See time-delay NN (TDNN)
teaching algorithms, 232
teaching organization schedule, 271
TEM. See test execution monitor (TEM)
temporal logic, 311
test execution monitor (TEM), 306
throughput, using requantization, 159
time-delay NN (TDNN), 15
time-lagged recurrent networks (TLRNs), 
15
TOP core technology. See task optimized 
processing core (TOP core) technology
transcoded image, video quality variation, 
162
transcoded video stream, quality of, 163
transcoding. See also video adaptation
latencies, 156, 157
using frame dropping, 157
using requantization, 155
operations, 134
process, 134
using requantization, 135
TU Darmstadt, 217
turn-back algorithm, 64
U
ultrasound (US) system
algorithm, wireless 3-D, 286
electro-magnetic and optical technolo-
gies, 289
imaging acoustic waves, 286
imaging system, 286
phantom, 282
probe, 279
UML component diagram, 265
UNIX-like environment, 314
UV color histogram, 183
V
variable block-size motion compensation 
(VBSMC), 133
variable length coding (VLC), 135
variable length decoding (VLD), 135
variables, 311
VBA. See visual basic for application 
(VBA)
VBSMC. See variable block-size motion 
compensation (VBSMC)
VGA image sensor, 197
VHDL simulator, 68
video adaptation, 127, 147
accuracy of, 161–63
node, 128
© 2011 by Apple Academic Press, Inc.
  

338  Computer Technology and Computer Programming: New Research and Strategies
throughput of, 159
video adaptation algorithms, 153
adaptive requantization, 135–37
frame dropping
in compressed domain, 137–38
in pixel domain, 139–40
pre-encoded video, transmission of, 
134
video coding standards
H.261 video coding, 132
H.263 video coding, 133
H.264 video coding, 133
MPEG-1 video coding, 130–31
MPEG-2 video coding, 131–32
MPEG-4 video coding, 132
video coding techniques, 129
video format conversion, using transcoder, 
134
video games, 251, 254
simulators and serious games, 253
video packets, 152
through active node, flow of, 147–48
video-quality adjustment nodes, 127
videos, 224
definition, 225
video streams
dropping high-frequency coefficients 
of, 129
dynamic adaptation of, 127
error images for, 163
in-network adaptation of, 130
video transcoding, 150
network processors for, 142
video transcoding node
multiple queue configuration for, 149
single queue configuration for, 149
Virtex family, 53
Virtex 6 FPGAs, 66
Virtex 2Pro, 53
vision processing, 184, 201
hierarchical model for, 181
vision processing algorithms, 171
visual basic for application (VBA), 266
visualization-based computer science 
hypertextbook (VizCoSH), 223
visualizations
and animation features, 238
control stack, 234
of mergesort, 237
recursion tree, 234
trace, 235
visualizing, algorithms and data structures, 
220–24
visual sensor networks (VSNs), 169, 200, 
201
advanced signal processing, 183–84
applications of, 174, 175–76
environmental monitoring, 175
smart homes, 175
smart meeting rooms, 175
surveillance, 175
telepresence systems, 176
characteristics of, 170
autonomous camera collaboration, 
174
data storage, 173–74
local (on-board) processing of, 
171–72
orientation information, 173
precise location, 173
real-time performance, 172–73
resource requirements, 171
time synchronization, 173
cross-layer optimization, 190
development of, 177
hardware architectures for
energy consumption, 195–96
testbed research, 198–200
visual sensor node platforms, 
196–198
middleware support, 200–1
networking protocols, 186
representatives of, 186
open research problems in, 201–5
real-time data delivery, 188
real-time performance of, 172
research directions in, 176–77
© 2011 by Apple Academic Press, Inc.
  

Index  339
topology of, 199
visual sensor node architectures, compari-
son of, 197
VizCoSH. See visualization-based com-
puter science hypertextbook (VizCoSH)
VLC. See variable length coding (VLC)
VLD. See variable length decoding (VLD)
von Neumann architecture (vN), 112
VSNs. See visual sensor networks (VSNs)
W
Waterfall Life Cycle model, 307
Watson-Crick base pairing, 294
Web 2.0, 100
architecture, 101
application’s interaction structure, 
104–5
client-side scripts, 103
languages
CSS, 104
HTML, 103
JavaScript, 103
SQL, 105
technologies
Ajax, 100, 101
files used, 105–9
jQuery, 102, 103
XHR, 101
web browser, 321
webcam, 195
Web-CAT, 215
web portals, 100
web queries, 91
web servers, 321
WebTasks, 215–20
database, 217, 219, 220
goal of, 220
schematic workflow for, 218
server, 220
white blood cells production, 19
Wi-Fi adapter, 279
wireless image sensor network application 
platform (WiSNAP), 198
Wireless Intelligent Agent Simulation 
Environment (WISE), 258
wireless multimedia sensor networks, 170
wireless networks, video delivery, 190
wireless sensor networks, 200
multimedia, 170
time synchronization protocols, 173
wire-speed OC-48 data, 143
WISE. See Wireless Intelligent Agent 
Simulation Environment (WISE)
WiSNAP. See wireless image sensor net-
work application platform (WiSNAP)
World Wide Web, 100
Wumpus World game, 258
X
XGFT network, 62
XHR. See XMLHttpRequest (XHR)
Xilinx architectures, 53
Xilinx FPGAs, 53, 66
implementation of, 66–67
Xilinx ISE 9.2i tool chain, 69
Xilinx software, 53
Xilinx Virtex5, 70
5VSX50T FPGA, 53
XML, 101, 104
XMLHttpRequest (XHR), 101
XML-RPC, 288
XP. See executive processor (XP)
© 2011 by Apple Academic Press, Inc.
  

