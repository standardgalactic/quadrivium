
Computability 
in Context
Computation and Logic in the Real World

This page intentionally left blank
This page intentionally left blank

Imperial College Press
ICP
editors 
S Barry Cooper
University of Leeds, UK
Andrea Sorbi
Università degli Studi di Siena, Italy
Computability 
in Context
Computation and Logic in the Real World

Library of Congress Cataloging-in-Publication Data
Computability in context : computation and logic in the real world / edited by S. Barry Cooper
& Andrea Sorbi.
p. cm.
Includes bibliographical references.
ISBN-13: 978-1-84816-245-7 (hardcover : alk. paper)
ISBN-10: 1-84816-245-6 (hardcover : alk. paper)
1. Computable functions.  2. Computational intelligence.  3. Set theory.
4. Mathematics--Philosophy.   I. Cooper, S. B. (S. Barry)   II. Sorbi, Andrea, 1956–
QA9.59.C655 2011
511.3'52--dc22
2010039227
British Library Cataloguing-in-Publication Data
A catalogue record for this book is available from the British Library.
Published by
Imperial College Press
57 Shelton Street
Covent Garden
London WC2H 9HE
Distributed by
World Scientific Publishing Co. Pte. Ltd.
5 Toh Tuck Link, Singapore 596224
USA office:  27 Warren Street, Suite 401-402, Hackensack, NJ 07601
UK office:  57 Shelton Street, Covent Garden, London WC2H 9HE
Printed in Singapore.
For photocopying of material in this volume, please pay a copying fee through the Copyright
Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, USA. In this case permission to
photocopy is not required from the publisher.
All rights reserved. This book, or parts thereof, may not be reproduced in any form or by any means,
electronic or mechanical, including photocopying, recording or any information storage and retrieval
system now known or to be invented, without written permission from the Publisher.
Copyright © 2011 by Imperial College Press

Preface
Computability has played a crucial role in mathematics and computer sci-
ence – leading to the discovery, understanding and classiﬁcation of decid-
able/undecidable problems, paving the way to the modern computer era
and aﬀecting deeply our view of the world. Recent new paradigms of com-
putation, based on biological and physical models, address in a radically
new way questions of eﬃciency and even challenge assumptions about the
so-called Turing barrier.
This book addresses various aspects of the ways computability and the-
oretical computer science enable scientists and philosophers to deal with
mathematical and real world issues, ranging through problems related to
logic, mathematics, physical processes, real computation and learning the-
ory. At the same time it focuses on diﬀerent ways in which computability
emerges from the real world, and how this aﬀects our way of thinking about
everyday computational issues.
But the title Computability in Context has been carefully chosen.
The contributions to be found here are not strictly speaking ‘applied
computability’. The literature directly addressing everyday computational
questions has grown hugely since the days of Turing and the computer
pioneers. The Computability in Europe conference series and association is
built on the recognition of the complementary role that mathematics and
fundamental science plays in progressing practical work; and, at the same
time, of the vital importance of a sense of context of basic research. This
book positions itself at the interface between applied and fundamental re-
search, prioritising mathematical approaches to computational barriers.
For us, the conference Computability in Europe 2007: Computation and
Logic in the Real World was a hugely exciting – and taxing – experience.
It brought together a remarkable assembly of speakers, and a level of par-
ticipation around issues of computability that would surely have astounded
Turing and those other early pioneers of ‘computing with understanding’.
All of the contributions here come from invited plenary speakers or Pro-
v

vi
Preface
gramme Committee members of CiE 2007. Many of these articles are likely
to become key contributions to the literature of computability and its real-
world signiﬁcance. The authors are all world leaders in their ﬁelds, all much
in demand as speakers and writers. As editors, we very much appreciate
their work.
Barry Cooper and Andrea Sorbi

Contents
Preface
v
1.
Computation, Information, and the Arrow of Time
1
P. Adriaans & P. van Emde Boas
2.
The Isomorphism Conjecture for NP
19
M. Agrawal
3.
The Ershov Hierarchy
49
M. M. Arslanov
4.
Complexity and Approximation in Reoptimization
101
G. Ausiello, V. Bonifaci, & B. Escoﬃer
5.
Deﬁnability in the Real Universe
131
S. B. Cooper
6.
HF-Computability
169
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
7.
The Mathematics of Computing between Logic and Physics
243
G. Longo & T. Paul
vii

viii
Contents
8.
Liquid State Machines: Motivation, Theory, and Applications
275
W. Maass
9.
Experiments on an Internal Approach to Typed Algo-
rithms in Analysis
297
D. Normann
10.
Recursive Functions: An Archeological Look
329
P. Odifreddi
11.
Reverse Mathematics and Well-ordering Principles
351
M. Rathjen & A. Weiermann
12.
Discrete Transﬁnite Computation Models
371
P. D. Welch

Chapter 1
Computation, Information, and the Arrow of Time
Pieter Adriaans & Peter van Emde Boas
Adriaans ADZA Beheer B.V., and
FNWI, University of Amsterdam,
1098 XG Amsterdam, The Netherlands
E-mail: pieter@pieter-adriaans.com
Bronstee.com B.V., Heemstede, and
ILLC, FNWI, University of Amsterdam
1090 GE Amsterdam, The Netherlands
E-mail: peter@bronstee.com
In this chapter we investigate the relation between information and com-
putation under time symmetry. We show that there is a class of non-
deterministic automata, the quasi-reversible automata (QRTM), that is
the class of classical deterministic Turing machines operating in negative
time, and that computes all the languages in NP. The class QRTM is
isomorphic to the class of standard deterministic Turing machines TM,
in the sense that for every M ∈T M there is a M −1 in QRTM such
that each computation on M is mirrored by a computation on M −1
with the arrow of time reversed. This suggests that non-deterministic
computing might be more aptly described as deterministic computing
in negative time. If Mi is deterministic then M −1
i
is non deterministic.
If M is information discarding then M −1 “creates” information. The
two fundamental complexities involved in a deterministic computation
are Program Complexity and Program Counter Complexity. Programs
can be classiﬁed in terms of their “information signature” with pure
counting programs and pure information discarding programs as two
ends of the spectrum. The chapter provides a formal basis for a further
analysis of such diverse domains as learning, creative processes, growth,
and the study of the interaction between computational processes and
thermodynamics.
1

2
P. Adriaans & P. van Emde Boas
Contents
1.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.2
A Formal Framework: Meta-computational Space . . . . . . . . . . . . . . . .
4
1.3
Time Symmetries in Meta-computational Space . . . . . . . . . . . . . . . . .
7
1.4
The Interplay of Computation and Information . . . . . . . . . . . . . . . . .
11
1.5
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
1.6
Conclusion
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
1.1. Introduction
The motivation behind this research is expressed in a childhood memory of
one of the authors: “When I was a toddler my father was an enthusiastic
8-mm movie amateur. The events captured in these movies belong to my
most vivid memories. One of the things that fascinated me utterly was the
fact that you could reverse the time. In my favorite movie I was eating a
plate of French fries. When played forward one saw the fries vanish in my
mouth one by one, but when played backward a miracle happened. Like a
magician pulling a rabbit out of a hat I was pulling undamaged fries out
of my mouth. The destruction of fries in positive time was associated with
the creation of fries in negative time.”
This is a nice example of the kind of models we have been discussing
when we were working on the research for this paper. It deals with com-
putation and the growth and destruction of information.
Deterministic
computation seems to be incapable of creating new information. In fact
most recursive functions are non-reversible. They discard information. If
one makes a calculation like a + b = c then the input contains roughly
(log a + log b) bits of information whereas the answer contains log(a + b)
bits which is in general much less. Somewhere in the process of transform-
ing the input to the output we have lost bits. The amount of information
we have lost is exactly the information needed to separate c in to a and b.
There are many ways to select two numbers a and b that add up to c. So
there are many inputs that could create the output. The information about
the exact history of the computation is discarded by the algorithm. This
leaves us with an interesting question: If there is so much information in
the world and computation does not generate information, then where does
the information come from?
Things get more fascinating if we consider the Turing machine version
of the French fries example above. Suppose we make a Turing machine

Computation, Information, and the Arrow of Time
3
that only erases its input and we make a movie of its execution and play
it backward. What would we see? We see a machine creating information
out of nothing, just the same way the toddler in the reversed movie was
pulling neat French fries out of his mouth. So also in this case, if we reverse
the arrow of time, destruction of information becomes creation and vice
versa.
In previous papers the ﬁrst author has investigated the relation
between learning and data compression ([2, 4]). Here we are interested in
the converse problem: How do data-sets from which we can learn something
emerge in the world? What processes grow information?
There is a class of deterministic processes that discard or destroy in-
formation. Examples are: simple erasure of bits, (lossy) data compression,
and learning. There is another class of processes that seems to create infor-
mation: coin ﬂipping, growth, evolution. In general, stochastic processes
create information, exactly because we are uncertain of their future, and
deterministic processes discard information, precisely because the future
of the process is known. The basic paradigm of a stochastic information
generating process is coin ﬂipping. If we ﬂip a coin in such a way that the
probability of heads is equal to the probability of tails, and we note the
results as a binary string, then with high probability this string is random
and incompressible. The string will then have maximal Kolmogorov com-
plexity, i.e. a program that generates the string on a computer will be at
least as long as the string itself ([8]). On the other hand if we generate a
string by means of a simple deterministic program (say “For x = 1 to k
print("1")”) then the string is highly compressible and by deﬁnition has
a low Kolmogorov complexity which approximates log k for large enough k.
In the light of these observations one could formulate the following research
question: Given the fact that creation and destruction of information seem
to be symmetrical over the time axis, could one develop a time-invariant
description of computational processes for which creation of information
is the same process as destruction of information with the time arrow re-
versed? A more concise version of the same question is: Are destruction
and creation of information computationally symmetrical in time?
The
main part of this paper is dedicated to a positive answer to this question.
Prima facie it seems that we compute to get new information. So if
we want to know what the exact value of 10! is, then the answer 3628800
really contains information for us. It tells us something we did not know.
We also have the intuition, that the harder it is to compute a function, the
more value (i.e. information) the answer contains. So 10! in a way contains

4
P. Adriaans & P. van Emde Boas
more information than 102. Yet from a mathematical point of view 10! and
3628800 are just diﬀerent descriptions of the same number. The situation
becomes even more intriguing if we turn our intention to the simulation of
processes on a computer that really seem to create new information like
the growth of a tree, game playing, or the execution of a genetic algorithm.
What is happening here if computation cannot generate information? What
is the exact relation between information generating processes that we ﬁnd
in our world and our abstract models of computation?
In most curricula, theories about information and computation are
treated in isolation. That is probably the reason why the rather funda-
mental question studied in this paper up till now has received little at-
tention in computer science: What is the interaction between information
and computation? Samson Abramsky has posed this question in a recent
publication with some urgency (without oﬀering a deﬁnitive answer): We
compute in order to gain information, but how is this possible logically or
thermodynamically? How can it be reconciled with the point of view of In-
formation Theory? How does information increase appear in the various
extant theories?
([1], p. 487). Below we will formulate a partial answer
to this question by means of an analysis of time invariant descriptions of
computational processes.
1.2. A Formal Framework: Meta-computational Space
In order to study the interplay between entropy, information, and compu-
tation we need to develop a formal framework. For this purpose we develop
the notion of meta-computational space in this section: formally, the space
of the graphs of all possible computations of all possible Turing machines.
The physical equivalent would be the space of all possible histories of all
possible universes.
C(x) will be the classical Kolmogorov complexity of a binary string x,
i.e. the length of the shortest program p that computes x on a reference
universal Turing machine U. Given the correspondence between natural
numbers and binary strings, M consists of an enumeration of all possible
self-delimiting programs for a preselected arbitrary universal Turing ma-
chine U.
Let x be an arbitrary bit string.
The shortest program that
produces x on U is x∗= argminM∈M(U(M) = x) and the Kolmogorov
complexity of x is C(x) = |x∗|. The conditional Kolmogorov complexity of
a string x given a string y is C(x|y), this can be interpreted as the length
of a program for x given input y.
A string is deﬁned to be random if

Computation, Information, and the Arrow of Time
5
C(x) ≥|x|. I(x) is the classical integer complexity function that assigns to
each integer x another integer C(x) [8].
We will follow the standard textbook of Hopcroft, Motwani, and Ullman
for the basic deﬁnitions ([7]). A Turing machine (TM) is described by a
7-tuple
M = (Q, Σ, Γ, δ, q0, B, F).
Here, as usual, Q is the ﬁnite set of states, Σ is the ﬁnite set of input symbols
with Σ ⊂Γ, where Γ is the complete set of tape symbols, δ is a transition
function such that δ(q, X) = (p, Y, D), if it is deﬁned, where p ∈Q is the
next state, X ∈Γ is the symbol read in the cell being scanned, Y ∈Γ is
the symbol written in the cell being scanned, D ∈{L, R} is the direction
of the move, either left or right, q0 ∈Q is the start state, B ∈Γ −Σ is the
blank default symbol on the tape, and F ⊂Q is the set of accepting states.
A move of a TM is determined by the current content of the cell that is
scanned and the state the machine is in. It consists of three parts:
(1) Change state;
(2) Write a tape symbol in the current cell;
(3) Move the read-write head to the tape cell on the left or right.
A non-deterministic Turing machine (NTM) is equal to a deterministic
TM with the exception that the range of the transition function consists of
sets of triples:
δ(q, X) = {(p1, Y1, D1), (p2, Y2, D2), ..., (pk, Yk, Dk)}.
A TM is a reversible Turing machine (RTM) if the transition function
δ(q, X) = (p, Y, D) is one-to-one, with the additional constraint that the
movement D of the read-write head is uniquely determined by the target
state p.
Deﬁnition 1.1. An Instantaneous Description (ID) of a TM during its
execution is a string X1X2...Xi−1qXiXi+1...Xn in which q is the state
of the TM, the tape head is scanning the i-th head from the left,
X1X2...Xn is the portion of the tape between the leftmost and the rightmost
blank. Given an Instantaneous Description X1X2...Xi−1qXiXi+1...Xn it
will be useful to deﬁne an Extensional Instantaneous Description (EID)
X1X2...Xi−1XiXi+1...Xn, that only looks at the content of the tape and
ignores the internal state of the machine and an Intensional Instantaneous
Description (IID) qXiD, that only looks at the content of the current cell

6
P. Adriaans & P. van Emde Boas
of the tape, the internal state of the machine, and the direction D in which
the head will move.
We make the jump from an object- to a meta-level of descriptions of
computations by means of considering the set of all possible transitions
between instantaneous descriptions.
Deﬁnition 1.2. Let < IDM, ⊢M> be the conﬁguration graph of all possible
transformations of a machine M, i.e.
IDM is the countable set of all
possible instantaneous descriptions and for IDi,j ∈IDM:
IDi ⊢M IDj
if and only if TM can reach IDj in one move from IDi. IDm is reachable
from IDi iﬀthere exists a sequence of transformations from one to the
other:
(IDi ⊢∗
M IDm) ⇔IDi ⊢M IDj ⊢M IDk...IDl ⊢M IDm.
The intensional description of such a transformation will be: (IIDi ⊢∗
M
IIDm). The extensional description will be: (EIDi ⊢∗
M EIDm).
Note that two machines can perform computations that are extensionally
isomorphic without intensional isomorphism and vice versa. We refer here
to transformations rather than computations since, in most cases, only
a subpart of the conﬁguration graph represents valid computations that
begin with a start state and end in an accepting state. Note that the class
of all possible instantaneous descriptions for a certain machine contains
for each possible tape conﬁguration, at each possible position of the head
on the tape, an instance for each possible internal state. Most of these
conﬁgurations will only be the result, or lead to, fragments of computations.
On the other hand, all valid computations that begin with a start state and
either continue forever or end in an accepting state, will be represented in
the conﬁguration graph.
Note that there is a strict relation between the structure of the transi-
tion function δ and the conﬁguration graph: For a deterministic machine
the conﬁguration graph has only one outgoing edge for each conﬁguration,
for a non-deterministic machine the conﬁguration graph can have multiple
outgoing edges per ID, for a reversible machine the graph consists only of
a number of linear paths without bifurcations either way.
Lemma 1.1. Let M be a Turing machine. We have C(< IDM, ⊢M>) <
C(M) + O(1).

Computation, Information, and the Arrow of Time
7
Proof.
Given M the graph < IDM, ⊢M> can be constructed by the fol-
lowing algorithm: Create IDM by enumerating the language of all possible
IDs, at each step of this process run M for one step on all IDs created so
far and add appropriate edges to ⊢M when M transforms IDi in IDj.
□
The ﬁnite object M and the inﬁnite object < IDM, ⊢M> identify the
same structure. We use here two variants of the Kolmogorov complexity:
The complexity of the ﬁnite object M is deﬁned by the smallest program
that computes the object on a universal Turing machine and then halts; the
complexity of < IDM, ⊢M> is given by the shortest program that creates
the object in an inﬁnite run.
Deﬁnition 1.3. Given an enumeration of Turing machines the meta-
computational space is deﬁned as the disjunct sum of all conﬁguration
graphs < IDMi, ⊢Mi> for i ∈N.
The meta-computational space is a very rich object in which we can
study a number of fundamental questions concerning the interaction be-
tween information and computation. We can also restrict ourselves to the
study of either extensional or intensional descriptions of computations and
this will prove useful, e.g. when we want to study the class of all compu-
tational histories that have descriptions with isomorphic pre- or suﬃxes.
For the moment we want to concentrate on time symmetries in meta-
computational space.
1.3. Time Symmetries in Meta-computational Space
In this paragraph we study the fact that some well-known classes of compu-
tational processes can be interpreted as each others’ symmetrical images in
time, i.e. processes in one class can be described as processes in the other
class with the time arrow reversed, or, to say it diﬀerently, as processes tak-
ing place in negative time. We can reverse the time arrow for all possible
computations of a certain machine by means of reversing all the edges in
the computational graph. This motivates the following notation:
Deﬁnition 1.4.
(IDi ⊢IDj) ⇔(IDj ⊣IDi)
(IDi ⊢∗IDk) ⇔(IDk ⊣∗IDi).

8
P. Adriaans & P. van Emde Boas
The analysis of valid computations of T M can now be lifted to the
study of reachability in the conﬁguration graph. The introduction of such
a meta-computational model allows us to study a much more general class of
computations in which the arrow of time can be reversed. We will introduce
the following shorthand notation that allows us to say that M −1 is the same
machine as M with the arrow of time reversed:
M =< IDM, ⊢M>⇔M −1 =< IDM, ⊣M> .
Intuitively the class of languages that is “computed” in negative time by a
certain Turing machine is the class of accepting tape conﬁgurations that can
be reached from a start state. We have to stress however, that moving back
in time in the conﬁguration graph describes a process that is fundamentally
diﬀerent from the standard notion of “computation” as we know it. We give
some diﬀerences:
• The standard deﬁnition of a Turing machine knows only one starting
state and possibly several accepting states. Computing in negative time
will trace back from several accepting states to one start state.
• The interpretation of the δ-function or relation is diﬀerent. In positive
time we use the δ-function to decide which action to take given a certain
state-symbol combination. In negative time this situation is reversed:
We use the δ-function to decide which state-symbol-move combination
could have led to a certain action.
• At the start of a computation there could be a lot of rubbish on the
tape that is simply not used during the computation. All computations
starting with arbitrary rubbish are in the conﬁguration graph.
We
want to exclude these from our deﬁnitions and stick to some minimal
deﬁnition of the input of a computation in negative time.
In order to overcome these diﬃculties the following lemma will be useful:
Lemma 1.2. (Minimal Input-Output Reconstruction) If an inten-
sional description of a fragment of a (deterministic or non-deterministic)
computation of a machine M: (IIDi ⊢∗
M IIDm) can be interpreted as the
trace of a valid computation then there exist a minimal input conﬁguration
IDi and a minimal output conﬁguration IDm for which M will reach IDm
starting at IDi. Otherwise the minimal input and output conﬁguration are
undeﬁned.
Proof.
The proof ﬁrst gives a construction for the minimal output in a
positive sweep and then the minimal input in a negative sweep.

Computation, Information, and the Arrow of Time
9
Positive sweep: Note that (IIDi ⊢∗
M IIDm) consists of a sequence of
descriptions: qiXiDi ⊢qi+1Xi+1Di+1 ⊢... ⊢qmXmDm. Reconstruct a
computation in the following way: Start with an inﬁnite tape for which all
of the symbols are unknown. Position the read-write head at an arbitrary
cell and perform the following interpretation operation: Interpret this as
the state-symbol-move conﬁguration qiXiDi. Now we know the contents of
the cell Xi, the state qi, and the direction D of the move of the read-write
head. The action will consist of writing a symbol in the current cell and
moving the read-write head left or right. Perform this action. The content
of one cell is now ﬁxed. Now there are two possibilities:
(1) We have the read-write head in a new cell with unknown content. From
the intensional description we know that the state-symbol combination
is qi+1Xi+1Di+1, so we can repeat the interpretation operation for the
new cell.
(2) We have visited this cell before in our reconstruction and it already
contains a symbol. From the intensional description we know that the
state-symbol combination should be qi+1Xi+1Di+1. If this is inconsis-
tent with the content of the current cell, the reconstruction stops and
the minimal output is undeﬁned. If not, we can repeat the interpreta-
tion operation for the new cell.
Repeat this operation till the intensional description is exhausted. Cells
on the tape that still have unknown content have not been visited by the
computational process: We may consider them to contain blanks. We now
have the minimal output conﬁguration on the tape IDm.
Negative sweep: start with the minimal output conﬁguration IDm. We
know the current location of the read-write head and the content of the cell.
From the intensional description (IIDi ⊢∗
M IIDm) we know which state-
symbol combination qmXmDm has led to IDm: from this we can construct
IDm−1. Repeat this process till the intensional description is exhausted
and we read IDi, which is the minimal input conﬁguration.
□
Lemma 1.2 gives us a way to tame the richness of the conﬁguration
graphs: We can restrict ourselves to the study of computational processes
that are intensionally equivalent, speciﬁcally intensionally equivalent pro-
cesses that start with a starting state and end in an accepting state. This
facilitates the following deﬁnition:

10
P. Adriaans & P. van Emde Boas
Deﬁnition 1.5. If (IIDi ⊢∗
M IIDm) is an intensional description of a
computation then
INPUT(IIDi ⊢∗
M IIDm) = x
gives the minimal input x and
OUTPUT(IIDi ⊢∗
M IIDm) = y
gives the minimal output y. With some abuse of notation we will also apply
these functions to histories of full IDs.
Deﬁnition 1.6. Given a Turing machine M the language recognized by its
counterpart M −1 in negative time is the set of minimal output conﬁgura-
tions associated with intensional descriptions of computations on M that
begin in a start state and end in an accepting state.
Deﬁnition 1.7. The class P −1 is the class of languages that are recognized
by an M −1
i
with i ∈N in time polynomial to the length of minimal input
conﬁguration.
Note that, after a time reversal operation, the graph of a deterministic
machine is transformed into a speciﬁc non-deterministic graph with the
characteristic that each ID has only one incoming edge.
We will refer
to such a model of computation as quasi-reversible. The essence of this
analysis is that, given a speciﬁc machine M, we can study its behavior
under reversal of the arrow of time.
We can use the symmetry between deterministic and quasi-reversible
computing in proofs. Whatever we prove about the execution of a program
on M also holds for M −1 with the time reversed and vice versa.
Let QRT M be the class of quasi-reversible non-deterministic machines
that are the mirror image in time of the class of deterministic machines
T M, and QRP be the class of languages that can be recognized by QRT M
in polynomial time. The lemma below is at ﬁrst sight quite surprising. The
class of languages that we can recognize non-deterministically in polynomial
time is the same class as the class of polynomial quasi-reversible languages:
Lemma 1.3. The class LQRP of languages recognized by a QRT M in poly-
nomial time is NP.
Proof.
1) LQRP ⊆NP: The class of languages recognized by quasi-
reversible machines is a subclass of the class of languages recognized by

Computation, Information, and the Arrow of Time
11
non-deterministic machines. This is trivial since there is a non-deterministic
machine that produces any {0, 1}≤k in time k.
2) NP ⊆LQRP : The class NP is deﬁned in a standard way in terms of
a checking relation R ⊆Σ∗× Σ∗
1 for some ﬁnite alphabets Σ∗and Σ∗
1. We
associate with each such relation R a language LR over Σ∗∪Σ∗
1 ∪# deﬁned
by
LR = {w#y|R(w, y)}
where the symbol # is not in Σ. We say that R is polynomial-time iﬀ
LR ∈P. Now we deﬁne the class NP of languages by the condition that
a language L over Σ is in NP iﬀthere is k ∈N and a polynomial-time
checking relation R such that for all w ∈Σ∗,
w ∈L ⇔∃y(|y| < |w|k & R(w, y))
where |w| and |y| denote the lengths of w and y, respectively. Suppose
that M implements a polynomial-time checking relation for R. Adapt M
to form M ′ that takes R(w, y) as input and erases y from the tape after
checking the relation, the transformation of M to M −1 is polynomial. The
corresponding QRTM M ′−1 will start with guessing a value for y non-
deterministically and will ﬁnish in a conﬁguration for which the relation
R(w, y) holds in polynomial time since |y| < |w|k and the checking relation
R is polynomial.
□
We can formulate the following result:
Theorem 1.1. NP = P −1
Proof.
Immediate consequence of Lemma 1.3 and Deﬁnition 1.7.
□
NP is the class of languages that can be recognized by deterministic
Turing machines in negative time. This shows that quasi-reversible com-
puting is in a way a more natural model of non-deterministic computing
than the classical full-blown non-deterministic model. The additional power
is unnecessary.
1.4. The Interplay of Computation and Information
We now look at the interplay between information and computation. The
tool we use will be the study of the changes in C(IDt), i.e. changes in the
Kolmogorov complexity of instantaneous descriptions over time. We make
some observations:

12
P. Adriaans & P. van Emde Boas
• If IDi ⊢M IDj then the information distance between the instanta-
neous descriptions IDi and IDj is log k + 1 at most where k is the
number of internal states of M.
• If EIDi ⊢M EIDj then the information distance between the exten-
sional descriptions EIDi and EIDj is 1 bit at most.
• If IIDi ⊢M IIDj then the information distance between the intensional
descriptions IIDi and IIDj is log k + 2 at most where k is the number
of internal states of M.
• Let x be the minimal input of a computational fragment (IIDi ⊢∗
M
IIDm) and let y be the minimal output. We have
C(x|IIDi ⊢∗
M IIDm) = C(y|IIDi ⊢∗
M IIDm) = O(1).
This is an immediate consequence of Lemma 1.2.
We can now identify some interesting typical machines:
• No machine can produce information faster than 1 bit per computa-
tional step. There is indeed a non-deterministic machine that reaches
this “speed”: the non-deterministic “coin-ﬂip” automaton that writes
random bits. For such an automaton we have with high probability
C(IDt) ≈t. In negative time this machine is the maximal eraser. It
erases information with the maximum “speed” of 1 bit per computa-
tional step.
• A unary counting machine produces information with a maximum
speed of log t. Note that C(t) = I(t), i.e. the complexity at time t
is equal to the value of the integer complexity function. The function
I(x) has indeﬁnite “dips” in complexity, i.e. at those places where it
approaches a highly compressible number. When t approaches such a
dip the information produced by a unary counting machine will drop
as the machine continues to write bits. The counter part of the unary
counter in negative time is the unary eraser. It erases information with
the maximal speed of log t, although at times it will create information
by erasing bits.
• The slowest information producer for its size is the busy-beaver func-
tion. When it is ﬁnished it will have written an enormous number of
bits with a conditional complexity of O(1). Its counterpart in nega-
tive time will be a busy-glutton automaton that “eats” an enormous
number of bits of an exact size.

Computation, Information, and the Arrow of Time
13
These insights allow us to draw a picture that tells us how information
and computation are intertwined in a deterministic process.
Figure 1.1.
Schematic representation of the various types of complexity estimates in-
volved in a deterministic computation.
The complexity of the history of a computation is related to the com-
plexity of the input given the output. There are two forms of complexity
involved in a deterministic computation:
• Program Complexity: This is the complexity of the input and its sub-
sequent conﬁgurations during the process. It cannot grow during the
computation. Most computations reduce program complexity.
• Program Counter Complexity: This is the descriptive complexity of
the program counter during the execution of the process. It is 0 at the
beginning, grows to log a in the middle, and reduces to 0 again at the
end of the computation.

14
P. Adriaans & P. van Emde Boas
The relationship between these forms of complexity is given by the following
theorem:
Theorem 1.2. (Information exchange in Deterministic Comput-
ing) Suppose M is a deterministic machine and IDi ⊢M IDa is a fragment
of an accepting computation, where IDm contains an accepting state. For
every i ≤k ≤a we have:
(1) Determinism: C(IDi+k+1 ⊢M IDa|M, IDi+k) = O(1), i.e.
at any
moment of time if we have the present conﬁguration and the deﬁnition
of M then the future of the computation is known.
(2) Program Counter Complexity from the start:
C(IDt|ID0, M)
<
(log k) + O(1), this constraint is known during the computation.
(3) Program Counter Complexity from the end: C(IDt|ID0, M) < (log a−
k) + O(1), this constraint is not known during the computation.
(4) Program complexity:
C((IIDi+k ⊢∗
M IIDa)|M) = C(INPUT(IIDi+k ⊢∗
M IIDa)|M) + O(1).
Proof.
(1) Trivial, since M is deterministic.
(2) Any state IDk at time k can be identiﬁed by information of size log k
if the initial conﬁguration and M are known.
(3) Any state IDk at time k can be identiﬁed by information of size log(a−
k) if the total description of the accepting computational process and
M are known.
(4) By the fact that the computation is deterministic it can be recon-
structed from the minimal input, given M. By Lemma 1.2, given M,
the minimal input can be reconstructed from (IIDi ⊢∗
M IIDa). This
gives the equality modulo O(1).
□
We cannot prove such a nice equality for the minimal output. Note that
even if the following inequality holds:
C((IIDi ⊢∗
M IIDa)|M) ≥C((IIDi+k ⊢∗
M IIDa)|M) + O(1)
this does not imply that:
C(OUTPUT(IIDi ⊢∗
M IIDa)|M) ≥C(OUTPUT(IIDi+k ⊢∗
M IIDa)|M)+O(1).
As a counterexample, observe that a program that erases a random string
has a string of blanks as minimal output. A longer string still can have a
lower Kolmogorov complexity.

Computation, Information, and the Arrow of Time
15
In computations that use counters, Program Complexity and Program
Counter Complexity are mixed up during the execution. In fact one can
characterize various types of computations by means of their “information
signature”. Informally, at extremes of the spectrum, one could distinguish:
• Pure Information Discarding Processes: in such processes the program
counter does not play any role. They reach an accepting state by means
of systematically reducing the input. Summation of a set of numbers,
or erasing of a string are examples.
• Pure Counting Processes:
For x=1 to i write("1"):
The condi-
tional complexity of the tape conﬁguration grows from 0 to log i and
then diminishes to 0 again.
• Pure Search Processes: In such processes the input is not reduced but
is kept available during the whole process.
The information in the
program counter is used to explore the search space. Standard decision
procedures for NP-hard programs, where the checking function is tested
on an enumeration of all possible solutions, are an example.
A deeper analysis of various information signatures of computational pro-
cesses and their consequences for complexity theory is a subject of future
work.
1.5. Discussion
We can draw some conclusions and formulate some observations on the
basis of the analysis given above.
1) Erasing and creating information are indeed, as suggested in the
introduction, from a time invariant computational point of view the same
processes: The quasi-reversible machine that is associated with a simple de-
terministic machine that erases information is a non-deterministic machine
writing arbitrary bit-strings on the tape. This symmetry also implies that
creation of information in positive time involves destruction of information
in negative time.
2) The class of quasi-reversible machines indeed describes the class of
data-sets from which we can learn something in the following way: If L is
the language accepted by M then M −1 generates L. M −1 is an informer
for L in the sense of [6], every sentence in L will be non-deterministically
produced by M −1 in the limit. QRT M is the class of all informers for
type-0 languages.

16
P. Adriaans & P. van Emde Boas
3) These insights suggests that we can describe stochastic processes in
the real world as deterministic processes in negative time: e.g. throwing a
dice in positive time is erasing information about its “future” in negative
time, the evolution of species in positive time could be described as the
“deterministic” computation of their ancestor in negative time. A necessary
condition for the description of such growth processes as computational
processes is that the number of bits that can be produced per time unit is
restricted. A stochastic interpretation of a QRTM can easily be developed
by assigning a set of probabilities to each split in the δ relation.
The
resulting stochastic-QRTM is a suﬃcient statistic for the data-sets that are
generated.
4) The characterization of the class NP in terms of quasi-reversible com-
puting seems to be more moderate than the classical description in terms
of full non-deterministic computing. The full power of non-deterministic
computing is never realized in a system with only one time direction.
5) Processes like game playing and genetic algorithms seem to be meta-
computational processes in which non-deterministic processes (throwing a
dice, adding mutations) seem to be intertwined with deterministic phases
(making moves, checking the ﬁtness function).
6) Time-symmetry has consequences for some philosophical positions.
The idea that the evolution of our universe can be described as a determin-
istic computational process has been proposed by several authors (Zuse,
Bostrom, Schmidthuber, Wolfram [10], Lloyd [9], etc.). Nowadays it is re-
ferred to as pancomputationalism [5]. If deterministic computation is an
information discarding process then it implies that the amount of informa-
tion in the universe rapidly decreases. This contradicts the second law of
thermodynamics. On the other hand, if the universe evolves in a quasi-
reversible way, selecting possible conﬁgurations according to some quasi-
reversible computational model, it computes the Big Bang in negative time.
The exact implications of these observations can only be explained by means
of the notion of facticity [3], but that is another discussion. The concept of
quasi-reversible computing seems to be relevant for these discussions [2].
1.6. Conclusion
Computing is moving through meta-computational space. For a ﬁxed Tur-
ing machine Mi such movement is conﬁned to one local inﬁnite graph
< IDMi, ⊢Mi>.
If Mi is deterministic then M −1
i
is non-deterministic.
If M is information discarding then M −1 “creates” information. The two

Computation, Information, and the Arrow of Time
17
fundamental complexities involved in a deterministic computation are Pro-
gram Complexity and Program Counter Complexity.
Programs can be
classiﬁed in terms of their “information signature” with pure counting pro-
grams and pure information discarding programs as two ends of the spec-
trum. The class NP is simply the class of polynomial deterministic time
calculations in negative time. Thinking in terms of meta-computational
space allows us to conceptualize computation as movement in a certain
space and is thus a source of new intuitions to study computation. Specif-
ically a deeper analysis of various information signatures of computational
(and other) processes is a promising subject for further study.
References
[1] S. Abramsky. Information, Processes and Games. In eds. P. W. Adriaans
and J. F. A. K. van Benthem, Handbook of the Philosophy of Information,
In Handbooks of the Philosophy of Science, series edited by D. M. Gabbay,
P. Thagard and J. Woods, pp. 483–550. Elsevier, (2008).
[2] P. W. Adriaans and J. F. A. K. van Benthem, eds., Handbook of the Phi-
losophy of Information. In Handbooks of the Philosophy of Science, series
edited by D. M. Gabbay, P. Thagard and J. Woods. Elsevier, (2008).
[3] P. W. Adriaans, Between order and chaos: The quest for meaningful infor-
mation, Theor. Comp. Sys. 45(4), (2009).
[4] P. W. Adriaans and P. Vit´anyi, Approximation of the two-part MDL code,
IEEE Transactions on Information Theory. 55(1), 444–457, (2009).
[5] L. Floridi. Trends in the philosophy of information. In eds. P. W. Adriaans
and J. F. A. K. van Benthem, Handbook of the Philosophy of Information,
In Handbooks of the Philosophy of Science, series edited by D. M. Gabbay,
P. Thagard and J. Woods, pp. 113–132. Elsevier, (2008).
[6] E. M. Gold, Language identiﬁcation in the limit, Information and Control.
10(5), 447–474, (1967).
[7] J. E. Hopcroft, R. Motwani, and J. D. Ullman, Introduction to Automata
Theory, Languages, and Computation. Addison-Wesley, (2001), second edi-
tion.
[8] M. Li and P. Vit´anyi, An Introduction to Kolmogorov Complexity and its
Applications. Springer-Verlag, (2008), third edition.
[9] S. Lloyd, Ultimate physical limits to computation, Nature. 406, 1047–1054,
(2000).
[10] S. Wolfram, A New Kind of Science. Wolfram Media Inc., (2002).

This page intentionally left blank
This page intentionally left blank

Chapter 2
The Isomorphism Conjecture for NP
Manindra Agrawal ∗
Indian Institute of Technology
Kanpur, India
E-mail: manindra@iitk.ac.in
In this chapter, we survey the arguments and known results for and
against the Isomorphism Conjecture.
Contents
2.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.2
Deﬁnitions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
2.3
Formulation and Early Investigations . . . . . . . . . . . . . . . . . . . . . . .
23
2.4
A Counter Conjecture and Relativizations . . . . . . . . . . . . . . . . . . . .
26
2.5
The Conjectures for Other Classes . . . . . . . . . . . . . . . . . . . . . . . .
28
2.6
The Conjectures for Other Reducibilities . . . . . . . . . . . . . . . . . . . . .
30
2.6.1
Restricting the input head movement . . . . . . . . . . . . . . . . . . .
31
2.6.2
Reducing space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
2.6.3
Reducing depth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
2.6.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
39
2.7
A New Conjecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
41
2.8
Future Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
2.1. Introduction
The Isomorphism Conjecture for the class NP states that all polynomial-
time many-one complete sets for NP are polynomial-time isomorphic to each
other. It was made by Berman and Hartmanis [21]a, inspired in part by
a corresponding result in computability theory for computably enumerable
sets [50], and in part by the observation that all the existing NP-complete
∗N Rama Rao Professor, Indian Institute of Technology, Kanpur. Research supported
by J C Bose Fellowship FLW/DST/CS/20060225.
aThe conjecture is also referred as Berman–Hartmanis Conjecture after the proposers.
19

20
M. Agrawal
sets known at the time were indeed polynomial-time isomorphic to each
other. This conjecture has attracted a lot of attention because it predicts
a very strong structure of the class of NP-complete sets, one of the funda-
mental classes in complexity theory.
After an initial period in which it was believed to be true, Joseph and
Young [40] raised serious doubts against the conjecture based on the notion
of one-way functions. This was followed by investigation of the conjecture
in relativized worlds [27, 33, 46] which, on the whole, also suggested that
the conjecture may be false. However, disproving the conjecture using one-
way functions, or proving it, remained very hard (either implies DP ̸= NP).
Hence research progressed in three distinct directions from here.
The ﬁrst direction was to investigate the conjecture for complete degrees
of classes bigger than NP. Partial results were obtained for classes EXP and
NEXP [20, 29].
The second direction was to investigate the conjecture for degrees other
than complete degrees. For degrees within the 2-truth-table-complete degree
of EXP, both possible answers to the conjecture were found [41, 43, 44].
The third direction was to investigate the conjecture for reducibilities
weaker than polynomial-time. For several such reducibilities it was found
that the isomorphism conjecture, or something close to it, is true [1, 2, 8, 16].
These results, especially from the third direction, suggest that the Iso-
morphism Conjecture for the class NP may be true contrary to the evidence
from the relativized world. A recent work [13] shows that if all one-way
functions satisfy a certain property then a non-uniform version of the con-
jecture is true.
An excellent survey of the conjecture and results related to the ﬁrst two
directions is in [45].
2.2. Deﬁnitions
In this section, we deﬁne most of the notions that we will need.
We ﬁx the alphabet to Σ = {0, 1}. Σ∗denotes the set of all ﬁnite strings
over Σ and Σn denotes the set of strings of size n. We start with deﬁning
the types of functions we use.
Deﬁnition 2.1. Let r be a resource bound on Turing machines. Function
f, f : Σ∗7→Σ∗, is r-computable if there exists a Turing machine (TM, in
short) M working within resource bound of r that computes f. We also
refer to f as an r-function.

The Isomorphism Conjecture for NP
21
Function f is size-increasing if for every x, |f(x)| > |x|. f is honest if
there exists a polynomial p(·) such that for every x, p(|f(x)|) > |x|.
For function f, f −1 denotes a function satisfying the property that
for all x, f(f −1(f(x))) = f(x). We say f is r-invertible if some f −1 is
r-computable.
For function f, its range is denoted as: range(f) = {y | (∃x) f(x) = y}.
We will be primarily interested in the resource bound of polynomial-
time, and abbreviate it as p. We now deﬁne several notions of reducibilities.
Deﬁnition 2.2. Let r be a resource bound. Set A r-reduces to set B if
there exists an r-function f such that for every x, x ∈A iﬀf(x) ∈B. We
also write this as A ≤r
m B via f. Function f is called an r-reduction of A
to B.
Similarly, A ≤r
1 B (A ≤r
1,si B; A ≤r
1,si,i B) if there exists a 1-1 (1-1 and
size-increasing; 1-1, size-increasing and r-invertible) r-function f such that
A ≤r
m B via f.
A ≡r
m B if A ≤r
m B and B ≤r
m A. An r-degree is an equivalence class
induced by the relation ≡r
m.
Deﬁnition 2.3. A is r-isomorphic to B if A ≤r
m B via f where f is a 1-1,
onto, r-invertible r-function.
The deﬁnitions of complexity classes DP, NP, PH, EXP, NEXP etc. can
be found in [52]. We deﬁne the notion of completeness we are primarily
interested in.
Deﬁnition 2.4. Set A is r-complete for NP if A ∈NP and for every B ∈
NP, B ≤r
m A. For r = p, set A is called NP-complete in short. The class of
r-complete sets is also called the complete r-degree of NP.
Similarly one deﬁnes complete sets for other classes.
The Satisﬁability problem (SAT) is one of the earliest known NP-
complete problems [25].
SAT is the set of all satisﬁable propositional
Boolean formulas.
We now deﬁne one-way functions. These are p-functions that are not
p-invertible on most of the strings. One-way functions are one of the fun-
damental objects in cryptography.
Without loss of generality (see [30]), we can assume that one-way func-
tions are honest functions f for which the input length determines the
output length, i.e., there is a length function ℓsuch that |f(x)| = ℓ(|x|) for
all x ∈Σ∗.

22
M. Agrawal
Deﬁnition 2.5. Function f is a s(n)-secure one-way function if (1) f
is a p-computable, honest function and (2) the following holds for every
polynomial-time randomized Turing machine M and for all suﬃciently large
n:
Pr
x∈U Σn [ f(M(f(x))) = f(x) ] <
1
s(n).
In the above, the probability is also over random choices of M, and x ∈U Σn
mean that x is uniformly and randomly chosen from strings of size n.
We impose the property of honesty in the above deﬁnition since a func-
tion that shrinks length by more than a polynomial is trivially one-way.
It is widely believed that 2nǫ-secure one-way functions exist for some
ǫ > 0.
We give one example.
Start by deﬁning a modiﬁcation of the
multiplication function:
Mult(x, y) =



1z
if x and y are both prime numbers
and z is the product x ∗y
0xy otherwise.
In the above deﬁnition, (·, ·) is a pairing function. In this paper, we
assume the following deﬁnition of (·, ·): (x, y) = xyℓwhere |ℓ| = ⌈log |xy|⌉
and ℓequals |x| written in binary. With this deﬁnition, |(x, y)| = |x|+|y|+
⌈log |xy|⌉. This deﬁnition is easily extended for m-tuples for any m.
Mult is a p-function since testing primality of numbers is in DP [11].
Computing the inverse of Mult is equivalent to factorization, for which no
eﬃcient algorithm is known. However, Mult is easily invertible on most of
the inputs, e.g., when any of x and y is not prime. The density estimate
for prime numbers implies that Mult is p-invertible on at least 1 −
1
nO(1)
fraction of inputs. It is believed that Mult is (1 −
1
nO(1) )-secure, and it
remains so even if one lets the TM M work for time 2nδ for some small
δ > 0. From this assumption, one can show that arbitrary concatenation
of Mult:
MMult(x1, y1, x2, y2, . . . , xm, ym) =
Mult(x1, y1) · Mult(x2, y2) · · · Mult(xm, ym)
is a 2nǫ-secure one-way function [30](p. 43).
One-way functions that are 2nǫ-secure are not p-invertible almost any-
where.
The weakest form of one-way functions are worst-case one-way
functions:

The Isomorphism Conjecture for NP
23
Deﬁnition 2.6. Function f is a worst-case one-way function if (1) f is a
p-computable, honest function, and (2) f is not p-invertible.
2.3. Formulation and Early Investigations
The conjecture was formulated by Berman and Hartmanis [21] in 1977.
Part of their motivation for the conjecture was a corresponding result in
computability theory for computably enumerable sets [50]:
Theorem 2.1. (Myhill) All complete sets for the class of computably enu-
merable sets are isomorphic to each other under computable isomorphisms.
The non-trivial part in the proof of this theorem is to show that complete
sets for the class of computably enumerable sets reduce to each other via 1-1
reductions. It is then easy to construct isomorphisms between the complete
sets. In many ways, the class NP is the resource bounded analog of the
computably enumerable class, and polynomial-time functions the analog of
computable functions. Hence it is natural to ask if the resource bounded
analog of the above theorem holds.
Berman and Hartmanis noted that the requirement for p-isomorphisms
is stronger. Sets reducing to each other via 1-1 p-reductions does not guar-
antee p-isomorphisms as p-functions do not have suﬃcient time to perform
exponential searches. Instead, one needs p-reductions that are 1-1, size-
increasing, and p-invertible:
Theorem 2.2. (Berman–Hartmanis) If A ≤p
1,si,i B and B ≤p
1,si,i A
then A is p-isomorphic to B.
They deﬁned the paddability property which ensures the required kind
of reductions.
Deﬁnition 2.7. Set A is paddable if there exists a p-computable padding
function p, p : Σ∗× Σ∗7→Σ∗, such that:
• Function p is 1-1, size-increasing, and p-invertible,
• For every x, y ∈Σ∗, p(x, y) ∈A iﬀx ∈A.
Theorem 2.3. (Berman–Hartmanis) If B ≤p
m A and A is paddable,
then B ≤p
1,si,i A.
Proof.
Suppose B ≤p
m A via f. Deﬁne function g as: g(x) = p(f(x), x).
Then, x ∈B iﬀf(x) ∈A iﬀg(x) = p(f(x), x) ∈A. By its deﬁnition and

24
M. Agrawal
the fact that p is 1-1, size-increasing, and p-invertible, it follows that g is
also 1-1, size-increasing, and p-invertible.
□
Berman and Hartmanis next showed that the known complete sets for
NP at the time were all paddable and hence p-isomorphic to each other.
For example, the following is a padding function for SAT:
pSAT (x, y1y2 · · · ym) = x ∧
m
^
i=1
zi
m
^
i=1
ci
where ci = zm+i if bit yi = 1 and ci = ¯zi if yi = 0 and the Boolean variables
z1, z2, . . ., z2m do not occur in the formula x.
This observation led them to the following conjecture:
Isomorphism Conjecture. All NP-complete sets are p-isomorphic to
each other.
The conjecture immediately implies DP ̸= NP:
Proposition 2.1. If the Isomorphism Conjecture is true then DP ̸= NP.
Proof.
If DP = NP then all sets in DP are NP-complete. However, DP
has both ﬁnite and inﬁnite sets and there cannot exist an isomorphism
between a ﬁnite and an inﬁnite set. Hence the Isomorphism Conjecture is
false.
□
This suggests that proving the conjecture is hard because the problem
of separating DP from NP has resisted all eﬀorts so far. A natural question,
therefore, is: Can one prove the conjecture assuming a reasonable hypoth-
esis such as DP ̸= NP? We address this question later in the paper. In
their paper, Berman and Hartmanis also asked a weaker question: Does
DP ̸= NP imply that no sparse set can be NP-complete?
Deﬁnition 2.8. Set A is sparse if there exist constants k, n0 > 0 such that
for every n > n0, the number of strings in A of length ≤n is at most nk.
This was answered in the aﬃrmative by Mahaney [49]:
Theorem 2.4. (Mahaney) If DP ̸= NP then no sparse set is NP-
complete.
Proof Sketch. We give a proof based on an idea of [9, 19, 51]. Suppose
there is a sparse set S such that SAT ≤p
m S via f. Let F be a Boolean
formula on n variables. Start with the set T = {F} and do the following:

The Isomorphism Conjecture for NP
25
Replace each formula ˆF ∈T by ˆF0 and ˆF1 where ˆF0 and ˆF1 are obtained
by setting the ﬁrst variable of ˆF to 0 and 1 respectively.
Let T =
{F1, F2, . . . , Ft}. If t exceeds a certain threshold t0, then let Gj = F1 ∨
Fj and zj = f(Gj) for 1 ≤j ≤t.
If all zj’s are distinct then drop
F1 from T . Otherwise, zi = zj for some i ̸= j. Drop Fi from T and
repeat until |T | ≤t0. If T has only formulas with no variables, then
output Satisﬁable if T contains a True formula else output Unsatisﬁable.
Otherwise, go to the beginning of the algorithm and repeat.
The invariant maintained during the entire algorithm is that F is sat-
isﬁable iﬀT contains a satisﬁable formula. It is true in the beginning, and
remains true in each iteration after replacing every formula ˆF ∈T with ˆF0
and ˆF1. The threshold t0 must be such that t0 is a upper bound on the
number of strings in the set S of size maxj |f(Gj)|. This is a polynomial in
|F| since |Gj| ≤2|F|, f is a p-function, and S is sparse. If T has more than
t0 formulas at any stage then the algorithm drops a formula from T . This
formula is F1 when all zj’s are distinct. This means there are more than t0
zj’s all of size bounded by maxj |f(Gj)|. Not all of these can be in S due
to the choice of t0 and hence F1 ̸∈SAT. If zi = zj then Fi is dropped. If Fi
is satisﬁable then so is Gi. And since zi = zj and f is a reduction of SAT
to S, Gj is also satisﬁable; hence either F1 or Fj is satisﬁable. Therefore
dropping Fi from T maintains the invariant.
The above argument shows that the size of T does not exceed a poly-
nomial in |F| at any stage. Since the number of iterations of the algorithm
is bounded by n ≤|F|, the overall time complexity of the algorithm is
polynomial. Hence SAT ∈DP and therefore, DP = NP.
□
The “searching-with-pruning” technique used in the above proof has
been used proﬁtably in many results subsequently. The Isomorphism Con-
jecture, in fact, implies a much stronger density result: All NP-complete
sets are dense.
Deﬁnition 2.9. Set A is dense if there exist constants ǫ, n0 > 0 such that
for every n > n0, the number of strings in A of length ≤n is at least 2nǫ.
Buhrman and Hitchcock [22] proved that, under a plausible hypothesis,
every NP-complete set is dense inﬁnitely often:
Theorem 2.5. (Buhrman–Hitchcock) If PH is inﬁnite then for any
NP-complete set A, there exists ǫ > 0 such that for inﬁnitely many n, the
number of strings in A of length ≤n is at least 2nǫ.

26
M. Agrawal
Later, we show that a stronger density theorem holds if 2nǫ-secure one-
way functions exist.
2.4. A Counter Conjecture and Relativizations
After Mahaney’s result, there was not much progress on the conjecture
although researchers believed it to be true. However, this changed in 1984
when Joseph and Young [40] argued that the conjecture is false.
Their
argument was as follows (paraphrased by Selman [53]). Let f be any 1-1,
size-increasing, 2nǫ-secure one-way function. Consider the set A = f(SAT).
Set A is clearly NP-complete. If it is p-isomorphic to SAT, there must exist
a 1-1, honest p-reduction of SAT to A which is also p-invertible. However,
the set A is, in a sense, a “coded” version of SAT such that on most of the
strings of A, it is hard to “decode” it (because f is not p-invertible on most
of the strings). Thus, there is unlikely to be a 1-1, honest p-reduction of
SAT to A which is also p-invertible, and so A is unlikely to be p-isomorphic
to SAT. This led them to make a counter conjecture:
Encrypted Complete Set Conjecture.
There exists a 1-1, size-
increasing, one-way function f such that SAT and f(SAT) are not p-
isomorphic to each other.
It is useful to observe here that this conjecture is false in computable
setting: The inverse of any 1-1, size-increasing, computable function is also
computable. The restriction to polynomial-time computability is what gives
rise to the possible existence of one-way functions.
It is also useful to observe that this conjecture too implies DP ̸= NP:
Proposition 2.2. If the Encrypted Complete Set Conjecture is true then
DP ̸= NP.
Proof.
If DP = NP then every 1-1, size-increasing p-function is also
p-invertible.
Hence for every such function, SAT and f(SAT) are p-
isomorphic.
□
The Encrypted Complete Set conjecture fails if one-way functions do
not exist.
Can it be shown to follow from the existence of strong one-
way functions, such as 2nǫ-secure one-way functions?
This is not clear.
(In fact, later we argue the opposite.) Therefore, to investigate the two
conjectures further, the focus moved to relativized worlds. Building on a
result of Kurtz [42], Hartmanis and Hemachandra [33] showed that there

The Isomorphism Conjecture for NP
27
is an oracle relative to which DP = UP and the Isomorphism Conjecture is
false. This shows that both the conjectures fail in a relativized world since
DP = UP implies that no one-way functions exist.
Kurtz, Mahaney, and Royer [46] deﬁned the notion of scrambling func-
tions:
Deﬁnition 2.10. Function f is scrambling function if f is 1-1, size-
increasing, p-computable, and there is no dense polynomial-time subset
in range(f).
Kurtz et al. observed that,
Proposition 2.3. If scrambling functions exist then the Encrypted Com-
plete Set Conjecture is true.
Proof.
Let f be a scrambling function, and consider A = f(SAT). Set
A is NP-complete.
Suppose it is p-isomorphic to SAT and let p be the
isomorphism between SAT and A. Since SAT has a dense polynomial-time
subset, say D, p(D) is a dense polynomial time subset of A. This contradicts
the scrambling property of f.
□
Kurtz et al., [46], then showed that,
Theorem 2.6. (Kurtz, Mahaney, Royer) Relative to a random oracle,
scrambling functions exist.
Proof Sketch. Let O be an oracle. Deﬁne function f as:
f(x) = O(x)O(x1)O(x11) · · · O(x12|x|)
where O(z) = 1 if z ∈O, 0 otherwise.
For a random choice of O, f
is 1-1 with probability 1. So, f is a 1-1, size-increasing, pO-computable
function. Suppose a polynomial-time TM M with oracle O accepts a subset
of range(f). In order to distinguish a string in range of f from those outside,
M needs to check the answer of oracle O on several unique strings. And
since M can query only polynomially many strings from O, M can accept
only a sparse subset of range(f).
□
Therefore, relative to a random oracle, the Encrypted Complete Set
Conjecture is true and the Isomorphism Conjecture is false. The question
of existence of an oracle relative to which the Isomorphism Conjecture is
true was resolved by Fenner, Fortnow, and Kurtz [27]:
Theorem 2.7. (Fenner, Fortnow, Kurtz) There exists an oracle rela-
tive to which Isomorphism Conjecture is true.

28
M. Agrawal
Thus, there are relativizations in which each of the three possible an-
swers to the two conjectures is true.
However, the balance of evidence
provided by relativizations is towards the Encrypted Complete Set Conjec-
ture since properties relative to a random oracle are believed to be true in
unrelativized world too.b
2.5. The Conjectures for Other Classes
In search of more evidence for the two conjectures, researchers translated
them to classes bigger than NP. The hope was that diagonalization argu-
ments that do not work within NP can be used for these classes to prove
stronger results about the structure of complete sets. This hope was real-
ized, but not completely. In this section, we list the major results obtained
for classes EXP and NEXP which were the two main classes considered.
Berman [20] showed that,
Theorem 2.8. (Berman) Let A be a p-complete set for EXP. Then for
every B ∈EXP, B ≤p
1,si A.
Proof Sketch. Let M1, M2, . . . be an enumeration of all polynomial-time
TMs such that Mi halts, on input x, within time |x||i| + |i| steps.
Let
B ∈EXP and deﬁne ˆB to be the set accepted by the following algorithm:
Input (i, x). Let Mi(i, x) = y. If |y| ≤|x|, accept iﬀy ̸∈A. If there
exists a z, z < x (in lexicographic order), such that Mi(i, z) = y, then
accept iﬀz ̸∈B. Otherwise, accept iﬀx ∈B.
The set ˆB is clearly in EXP. Let ˆB ≤p
m A via f. Let the TM Mj compute
f. Deﬁne function g as: g(x) = f(j, x). It is easy to argue that f is 1-1
and size-increasing on inputs of the form (j, ⋆) using the deﬁnition of ˆB
and the fact that f is a reduction. It follows that g is a 1-1, size-increasing
p-reduction of B to A.
□
Remark 2.1. A case can be made that the correct translation of the iso-
morphism result of [50] to the polynomial-time realm is to show that the
complete sets are also complete under 1-1, size-increasing reductions. As
observed earlier, the non-trivial part of the result in the setting of com-
putability is to show the above implication. Inverting computable reduc-
tions is trivial. This translation will also avoid the conﬂict with Encrypted
Complete Set Conjecture as it does not require p-invertibility. In fact, as
bThere are notable counterexamples of this though.
The most prominent one is the
result IP = PSPACE [48, 54] which is false relative to a random oracle [24].

The Isomorphism Conjecture for NP
29
will be shown later, one-way functions help in proving an analog of the
above theorem for the class NP! However, the present formulation has a
nice symmetry to it (both the isomorphism and its inverse require the same
amount of resources) and hence is the preferred one.
For the class NEXP, Ganesan and Homer [29] showed that,
Theorem 2.9. (Ganesan–Homer) Let A be a p-complete set for NEXP.
Then for every B ∈NEXP, B ≤p
1 A.
The proof of this uses ideas similar to the previous proof for EXP. The
result obtained is not as strong since enforcing the size-increasing property
of the reduction requires accepting the complement of a NEXP set which
cannot be done in NEXP unless NEXP is closed under complement, a very
unlikely possibility. Later, the author [5] proved the size-increasing property
for reductions to complete sets for NEXP under a plausible hypothesis.
While the two conjectures could not be settled for the complete p-degree
of EXP (and NEXP), answers have been found for p-degrees close to the
complete p-degree of EXP. The ﬁrst such result was shown by Ko, Long,
and Du [41]. We need to deﬁne the notion of truth-table reductions to state
this result.
Deﬁnition 2.11. Set A k-truth-table reduces to set B if there exists a p-
function f, f : Σ∗7→Σ∗× Σ∗× · · · × Σ∗
|
{z
}
k
×Σ2k such that for every x ∈Σ∗,
if f(x) = (y1, y2, . . . , yk, T ) then x ∈A iﬀT (B(y1)B(y2) · · · B(yk)) = 1
where B(yi) = 1 iﬀyi ∈B and T (s), |s| = k, is the sth bit of string T .
Set B is k-truth-table complete for EXP if B ∈EXP and for every A ∈
EXP, A k-truth-table reduces to B.
The notion of truth-table reductions generalizes p-reductions. For both
EXP and NEXP, it is known that complete sets under 1-truth-table reduc-
tions are also p-complete [23, 38], and not all complete sets under 2-truth-
table reductions are p-complete [55]. Therefore, the class of 2-truth-table
complete sets for EXP is the smallest class properly containing the complete
p-degree of EXP.
Ko, Long, and Du [41] related the structure of certain p-degrees to the
existence of worst-case one-way functions:
Theorem 2.10. (Ko–Long–Du) If there exist worst-case one-way func-
tions then there is a p-degree in EXP such that the sets in the degree are not

30
M. Agrawal
all p-isomorphic to each other. Further, sets in this degree are 2-truth-table
complete for EXP.
Kurtz, Mahaney, and Royer [43] found a p-degree for which the sets are
unconditionally not all p-isomorphic to each other:
Theorem 2.11. (Kurtz–Mahaney–Royer) There exists a p-degree in
EXP such that the sets in the degree are not all p-isomorphic to each other.
Further, sets in this degree are 2-truth-table complete for EXP.
Soon afterwards, Kurtz, Mahaney, and Royer [44] found another p-
degree with the opposite structure:
Theorem 2.12. (Kurtz–Mahaney–Royer) There exists a p-degree in
EXP such that the sets in the degree are all p-isomorphic to each other.
Further, this degree is located inside the 2-truth-table complete degree of
EXP.
The set of results above on the structure of complete (or nearly com-
plete) p-degree of EXP and NEXP do not favor any of the two conjectures.
However, they do suggest that the third possibility, viz., both the conjec-
tures being false, is unlikely.
2.6. The Conjectures for Other Reducibilities
Another direction from which to approach the two conjectures is to weaken
the power of reductions instead of the class NP, the hope being that for
reductions substantially weaker than polynomial-time, one can prove un-
conditional results. For several weak reductions, this was proven correct
and in this section we summarize the major results in this direction.
The two conjectures for r-reductions can be formulated as:
r-Isomorphism
Conjecture.
All r-complete sets for NP are r-
isomorphic to each other.
r-Encrypted Complete Set Conjecture.
There is a 1-1, size-
increasing,
r-function f
such that SAT and f(SAT) are not r-
isomorphic to each other.
Weakening p-reductions to logspace-reductions (functions computable by
TMs with read-only input tape and work tape space bounded by O(log n),
n is the input size) does not yield unconditional results as any such result

The Isomorphism Conjecture for NP
31
will separate NP from L, another long-standing open problem. So we need
to weaken it further. There are three major ways of doing this.
2.6.1. Restricting the input head movement
Allowing the input head movement in only one direction leads to the notion
of 1-L-functions.
Deﬁnition 2.12. A 1-L-function is computed by deterministic TMs with
read-only input tape, the workspace bounded by O(log n) where n is the
input length, and the input head restricted to move in one direction only
(left-to-right by convention). In other words, the TM is allowed only one
scan of its input. To ensure the space bound, the ﬁrst O(log n) cells on the
work tape are marked at the beginning of the computation.
These functions were deﬁned by Hartmanis, Immerman, and Ma-
haney [34] to study the complete sets for the class L.
They also ob-
served that the “natural” NP-complete sets are also complete under 1-L-
reductions. Structure of complete sets under 1-L-reductions attracted a lot
of attention, and the ﬁrst result was obtained by Allender [14]:
Theorem 2.13. (Allender) For the classes PSPACE and EXP, complete
sets under 1-L-reductions are p-isomorphic to each other.
While this shows a strong structure of complete sets of some classes
under 1-L-reductions, it does not answer the 1-L-Isomorphism Conjecture.
After a number of extensions and improvements [10, 29, 37], the author [1]
showed that,
Theorem 2.14. (Agrawal) Let A be a 1-L-complete set for NP. Then for
every B ∈NP, B ≤1−L
1,si,i A.
Proof Sketch. We ﬁrst show that A is also complete under forgetful 1-
L-reductions. Forgetful 1-L-reductions are computed by TMs that, imme-
diately after reading a bit of the input, forget its value. This property is
formalized by deﬁning conﬁgurations: A conﬁguration of a 1-L TM is a
tuple ⟨q, j, w⟩where q is a state of the TM, j its input head position, and
w the contents of its worktape including the position of the worktape head.
A forgetful TM, after reading a bit of the input and before reading the
next bit, reaches a conﬁguration which is independent of the value of the
bit that is read.

32
M. Agrawal
Let B ∈NP, and deﬁne ˆB to be the set accepted by the following
algorithm:
Input x. Let x = y10b1k. Reject if b is odd or |y| ̸= tb for some integer
t. Otherwise, let y = y1y2 · · · yt with |yi| = b. Let vi = 1 if yi = uu for
some u, |u| = b
2; vi = 0 otherwise. Accept iﬀv1v2 · · · vt ∈B.
The set ˆB is a “coded” version of set B and reduces to B via a p-
reduction. Hence, ˆB ∈NP. Let f be a 1-L-reduction of ˆB to A computed
by TM M.
Consider the workings of M on inputs of size n.
Since M
has O(log n) space, the number of conﬁgurations of M will be bounded
by a polynomial, say q(·), in n. Let b = k⌈log n⌉such that 2b/2 > q(n).
Let C0 be the initial conﬁguration of M. By the Pigeon Hole Principle, it
follows that there exist two distinct strings u1 and u′
1, |u1| = |u′
1| = b
2, such
that M reaches the same conﬁguration, after reading either of u1 and u′
1.
Let C1 be the conﬁguration reached from this conﬁguration after reading
u1. Repeat the same argument starting from C1 to obtain strings u2, u′
2,
and conﬁguration C2. Continuing this way, we get triples (ui, u′
i, Ci) for
1 ≤i ≤t = ⌊n−b−1
b
⌋. Let k = n −b −1 −bt. It follows that the TM M
will go through the conﬁgurations C0, C1, . . ., Ct on any input of the form
y1y2 . . . yt10b1k with yi ∈{uiui, u′
iui}. Also, that the pair (ui, u′
i) can be
computed in logspace without reading the input.
Deﬁne a reduction g of B to ˆB as follows: On input v, |v| = t, compute
b such that 2b/2 > q(b + 1 + bt), and consider M on inputs of size b + 1 + bt.
For each i, 1 ≤i ≤t, compute the pair (ui, u′
i) and output uiui if the ith
bit of v is 1, output uiu′
i otherwise. It is easy to argue that the composition
of f and g is a forgetful 1-L-reduction of B to A.
Deﬁne another set B′ as accepted by the following algorithm:
Input x. Reject if |x| is odd. Otherwise, let x = x1x2 · · · xns1s2 · · · sn.
Accept if exactly one of s1, s2, . . ., sn, say sj, is zero and xj = 1. Accept
if all of s1, s2, . . ., sn are one and x1x2 · · · xn ∈B. Reject in all other
cases.
Set B′ ∈NP. As argued above, there exists a forgetful 1-L-reduction of
B′ to A, say h. Deﬁne a reduction g′ of B to B′ as: g′(v) = v1|v|. It is easy
to argue that h ◦g′ is a size-increasing, 1-L-invertible, 1-L-reduction of B
to A and h ◦g′ is 1-1 on strings of size n for all n. Modifying this to get a
reduction that is 1-1 everywhere is straightforward.
□
The above result strongly suggests that the 1-L-Isomorphism Conjecture
is true. However, the author [1] showed that,

The Isomorphism Conjecture for NP
33
Theorem
2.15. (Agrawal) 1-L-complete sets for NP are all 2-L-
isomorphic to each other but not 1-L-isomorphic.
The 2-L-isomorphism above is computed by logspace TMs that are al-
lowed two left-to-right scans of their input.
Thus, the 1-L-Isomorphism
Conjecture fails and a little more work shows that the 1-L-Encrypted Com-
plete Set Conjecture is true! However, the failure of the Isomorphism Con-
jecture here is for a very diﬀerent reason: it is because 1-L-reductions are
not powerful enough to carry out the isomorphism construction as in The-
orem 2.2. For a slightly more powerful reducibility, 1-NL-reductions, this
is not the case.
Deﬁnition 2.13. A 1-NL-function is computed by TMs satisfying the re-
quirements of deﬁnition 2.12, but allowed to be non-deterministic.
The
non-deterministic TM must output the same string on all paths on which
it does not abort the computation.
For 1-NL-reductions, the author [1] showed, using proof ideas similar to
the above one, that,
Theorem 2.16. (Agrawal) 1-NL-complete sets for NP are all 1-NL-
isomorphic to each other.
The author [1] also showed similar results for c-L-reductions for constant
c (functions that are allowed at most c left-to-right scans of the input).
2.6.2. Reducing space
The second way of restricting logspace reductions is by allowing the TMs
only sublogarithmic space, i.e., allowing the TM space o(log n) on input of
size n; we call such reductions sublog-reductions. Under sublog-reductions,
NP has no complete sets, and the reason is simple: Every sublog-reduction
can be computed by deterministic TMs in time O(n2) and hence if there
is a complete set for NP under sublog-reductions, then NTIME(nk+1) =
NTIME(nk) for some k > 0, which is impossible [26]. On the other hand,
each of the classes NTIME(nk), k ≥1, has complete sets under sublog-
reductions.
The most restricted form for sublog-reductions is 2-DFA-reductions:
Deﬁnition 2.14. A 2-DFA-function is computed by a TM with read-only
input tape and no work tape.

34
M. Agrawal
2-DFA functions do not require any space for their computation, and
therefore are very weak. Interestingly, the author [4] showed that sublog-
reductions do not add any additional power for complete sets:
Theorem 2.17. (Agrawal) For any k ≥1, sublog-complete sets for
NTIME(nk) are also 2-DFA-complete.
For 2-DFA-reductions, the author and Venkatesh [12] proved that,
Theorem 2.18. (Agrawal-Venkatesh) Let A be a 2-DFA-complete set
for NTIME(nk) for some k ≥1. Then, for every B ∈NTIME(nk), B ≤2DFA
1,si
A via a reduction that is mu-DFA-invertible.
muDFA-functions are computed by TMs with no space and multiple
heads, each moving in a single direction only. The proof of this is also
via forgetful TMs. The reductions in the theorem above are not 2-DFA-
invertible, and in fact, it was shown in [12] that,
Theorem 2.19. (Agrawal-Venkatesh) Let f(x) = xx. Function f is a
2-DFA-function and for any k ≥1, there is a 2-DFA-complete set A for
NTIME(nk) such that A ̸≤2DFA
1,si,i f(A).
The above theorem implies that 2-DFA-Encrypted Complete Set Con-
jecture is true.
2.6.3. Reducing depth
Logspace reductions can be computed by (unbounded fan-in) circuits of
logarithmic depth.c
Therefore, another type of restricted reducibility is
obtained by further reducing the depth of the circuit family computing the
reduction. Before proceeding further, let us deﬁne the basic notions of a
circuit model.
Deﬁnition 2.15. A circuit family is a set {Cn : n ∈N} where each Cn is an
acyclic circuit with n Boolean inputs x1, . . . , xn (as well as the constants 0
and 1 allowed as inputs) and some number of output gates y1, . . . , yr. {Cn}
has size s(n) if each circuit Cn has at most s(n) gates; it has depth d(n) if
the length of the longest path from input to output in Cn is at most d(n).
A circuit family has a notion of uniformity associated with it:
cFor a detailed discussion on the circuit model of computation, see [52].

The Isomorphism Conjecture for NP
35
Deﬁnition 2.16. A family C = {Cn} is uniform if the function n 7→Cn
is easy to compute in some sense.
This can also be deﬁned using the
complexity of the connection set of the family:
conn(C) = {(n, i, j, Ti, Tj) | the output of gate i of type Ti
is input to gate j of type Tj in Cn}.
Here, gate type Ti can be Input, Output, or some Boolean operator.
Family C is Dlogtime-uniform [18] if conn(C) is accepted by a linear-time
TM. It is p-uniform [15] if conn(C) is accepted by a exponential-time TM
(equivalently, by a TM running in time bounded by a polynomial in the
circuit size). If we assume nothing about the complexity of conn(C), then
we say that the family is non-uniform.
An important restriction of logspace functions is to functions computed
by constant depth circuits.
Deﬁnition 2.17. Function f is a u-uniform AC0-function if there is a u-
uniform circuit family {Cn} of size nO(1) and depth O(1) consisting of
unbounded fan-in AND and OR and NOT gates such that for each input
x of length n, the output of Cn on input x is f(x).
Note that with this deﬁnition, an AC0-function cannot map strings of
equal size to strings of diﬀerent sizes. To allow this freedom, we adopt the
following convention: Each Cn will have nk +k log(n) output bits (for some
k). The last k log n output bits will be viewed as a binary number r, and
the output produced by the circuit will be the binary string contained in
the ﬁrst r output bits.
It is worth noting that, with this deﬁnition, the class of Dlogtime-
uniform AC0-functions admits many alternative characterizations, includ-
ing expressibility in ﬁrst-order logic with {+, ×, ≤} [18, 47], the logspace-
rudimentary reductions [17, 39], logarithmic-time alternating Turing ma-
chines with O(1) alternations [18] etc. Moreover, almost all known NP-
complete sets are also complete under Dlogtime-uniform AC0-reductions
(an exception is provided by [7]). We will refer to Dlogtime-uniform AC0-
functions also as ﬁrst-order-functions.
AC0-reducibility is important for our purposes too, since the complete
sets under the reductions of the previous two subsections are also complete
under AC0-reductions (with uniformity being Dlogtime- or p-uniform). This
follows from the fact that these sets are also complete under some appro-
priate notion of forgetful reductions. Therefore, the class of AC0-complete
sets for NP is larger than all of the previous classes of this section.

36
M. Agrawal
The ﬁrst result for depth-restricted functions was proved by Allender,
Balc´azar, and Immerman [16]:
Theorem 2.20. (Allender–Balc´azar–Immerman) Complete sets for
NP under ﬁrst-order projections are ﬁrst-order-isomorphic to each other.
First-order projections are computed by a very restricted kind of
Dlogtime-uniform AC0 family in which no circuit has AND and OR gates.
This result was generalized by the author and Allender [6] to NC0-functions,
which are functions computed by AC0 family in which the fan-in of every
gate of every circuit is at most two.
Theorem 2.21. (Agrawal–Allender) Let A be a non-uniform NC0-
complete set for NP. Then for any B ∈NP, B non-uniform NC0-reduces
to A via a reduction that is 1-1, size-increasing, and non-uniform AC0-
invertible.
Further, all non-uniform NC0-complete sets for NP are non-
uniform AC0-isomorphic to each other where these isomorphisms can be
computed and inverted by depth three non-uniform AC0 circuits.
Proof Sketch. The proof we describe below is the one given in [3]. Let
B ∈NP, and deﬁne ˆB to be the set accepted by the following algorithm:
On input y, let y = 1k0z. If k does not divide |z|, then reject. Otherwise,
break z into blocks of k consecutive bits each. Let these be u1u2u3 . . . up.
Accept if there is an i, 1 ≤i ≤p, such that ui = 1k. Otherwise, reject
if there is an i, 1 ≤i ≤p, such that ui = 0k. Otherwise, for each i,
1 ≤i ≤p, label ui as null if the number of ones in it is 2 modulo 3; as
zero if the number of ones in it is 0 modulo 3; and as one otherwise. Let
vi = ǫ if ui is null, 0 if ui is zero, and 1 otherwise. Let x = v1v2 · · · vp,
and accept iﬀx ∈B.
Clearly, ˆB ∈NP. Let {Cn} be the NC0 circuit family computing a reduction
of ˆB to A. Fix size n and consider circuit Ck+1+n for k = 4⌈log n⌉. Let C
be the circuit that results from setting the ﬁrst input k + 1 bits of Ck+1+n
to 1k0. Randomly set each of the n input bits of C in the following way:
With probability 1
2, leave it unset; with probability 1
4 each, set it to 0 and
1 respectively. The probability that any block of k bits is completely set
is at most
1
n4 . Similarly, the probability that there is a block that has at
most three unset bits is at most
1
n, and therefore, with high probability,
every block has at least four unset bits.
Say that an output bit is good if, after the random assignment to the
input bits described above is completed, the value of the output bit depends
on exactly one unset input bit. Consider an output bit. Since C is an NC0

The Isomorphism Conjecture for NP
37
circuit, the value of this bit depends on at most a constant, say c, number
of input bits.
Therefore, the probability that this bit is good after the
assignment is at least 1
2 ·
1
4c−1 . Therefore, the expected number of good
output bits is at least
m
4c , where m is the number of output bits of C
whose value depends on some input bit. Using the deﬁnition of set ˆB, it
can be argued that Ω(n) output bits depend on some input bit, and hence
Ω(n) output bits are expected to be good after the assignment. Fix any
assignment that does this, as well as leaves at least four unset bits in each
block. Now set some more input bits so that each block that is completely
set is null, each block that has exactly two unset bits has number of ones
equal to 0 modulo 3, and there are no blocks with one, three, or more unset
bits. Further, for at least one unset input bit in a block, there is a good
output bit that depends on the bit, and there are Ω(
n
log n) unset input bits.
It is easy to see that all these conditions can be met.
Now deﬁne a reduction of B to ˆB as: On input x, |x| = p, consider
Ck+1+n such that the number of unset input bits in Ck+1+n after doing the
above process is at least p. Now map the ith bit of x to the unset bit in a
block that inﬂuences a good output bit and set the other unset input bit in
the block to zero. This reduction can be computed by an NC0 circuit (in
fact, the circuit does not need any AND or OR gate).
Deﬁne a reduction of B to A given by the composition of the above two
reductions. This reduction is a superprojection: it is computed by circuit
family {Dp} with each Dp being an NC0 circuit such that for every input
bit to Dp, there is an output bit that depends exactly on this input bit. A
superprojection has the input written in certain bit positions of the output.
Therefore, it is 1-1 and size-increasing. Inverting the function is also easy:
Given string y, identify the locations where the input is written, and check
if the circuit Dp (p = number of locations) on this input outputs y. This
checking can be done by a depth two AC0 circuit.
This gives a 1-1, size-increasing, AC0-invertible, NC0-reduction of B
to A.
The circuit family is non-uniform because it is not clear how to
deterministically compute the settings of the input bits.
Exploiting the
fact that the input is present in the output of the reductions, an AC0-
isomorphism, computed by depth three circuits, can be constructed between
two complete sets following [21] (see [8] for details).
□
Soon after, the author, Allender, and Rudich [8] extended it to all
AC0-functions, proving the Isomorphism Conjecture for non-uniform AC0-
functions.

38
M. Agrawal
Theorem 2.22. (Agrawal–Allender–Rudich) Non-uniform AC0-com-
plete sets for NP are non-uniform AC0-isomorphic to each other.
Fur-
ther, these isomorphisms can be computed and inverted by depth three non-
uniform AC0 circuits.
Proof Sketch. The proof shows that complete sets for NP under AC0-
reductions are also complete under NC0-reductions and invokes the above
theorem for the rest. Let A be a complete set for NP under AC0-reductions.
Let B ∈NP. Deﬁne set ˆB exactly as in the previous proof. Fix an AC0-
reduction of ˆB to A given by family {Cn}. Fix size n, and consider Ck+1+n
for k = n1−ǫ for a suitable ǫ > 0 to be ﬁxed later. Let D be the circuit that
results from setting the ﬁrst k + 1 input bits of Ck+1+n to 1k0.
Set each input bit of D to 0 and 1 with probability 1
2 −
1
2n1−2ǫ each and
leave it unset with probability
1
n1−2ǫ . By the Switching Lemma of Furst,
Saxe, and Sipser [28], the circuit D will reduce, with high probability, to an
NC0 circuit on the unset input bits for a suitable choice of ǫ > 0. In each
block of k bits, the expected number of unset bits will be nǫ, and therefore,
with high probability, each block has at least three unset bits. Fix any
settings satisfying both of the above.
Now deﬁne a reduction of B to ˆB that, on input x, |x| = p, identiﬁes n
for which the circuit D has at least p blocks, and then maps ith bit of input
x to an unset bit of the ith block of the input to D, setting the remaining
bits of the block so that the sum of ones in the block is 0 modulo 3. Unset
bits in all remaining blocks are set so that the sum of ones in the block
equals 2 modulo 3.
The composition of the reduction of B to ˆB and ˆB to A is an NC0-
reduction of B to A. Again, it is non-uniform due to the problem of ﬁnding
the right settings of the input bits.
□
The focus then turned towards removing the non-uniformity in the
above two reductions. In the proof of Theorem 2.21 given in [6], the uni-
formity condition is p-uniform. In [7], the uniformity of 2.22 was improved
to p-uniform by giving a polynomial-time algorithm that computes the cor-
rect settings of input bits. Both the conditions were further improved to
logspace-uniform in [3] by constructing a more eﬃcient derandomization
of the random assignments. And ﬁnally, in [2], the author obtained very
eﬃcient derandomizations to prove that,
Theorem 2.23. (Agrawal) First-order-complete sets for NP are ﬁrst-
order-isomorphic.

The Isomorphism Conjecture for NP
39
The isomorphisms in the theorem above are no longer computable by
depth three circuits; instead, their depth is a function of the depth of the
circuits computing reductions between the two complete sets.
2.6.4. Discussion
At ﬁrst glance, the results for the weak reducibilities above seem to provide
equal support to both the conjectures: The Isomorphism Conjecture is
true for 1-NL and AC0-reductions for any reasonable notion of uniformity,
while the Encrypted Complete Set Conjecture is true for 1-L and 2-DFA
reductions. However, on a closer look a pattern begins to emerge. First of
all, we list a common feature of all the results above:
Corollary 2.1. For r ∈{1-L, 1-NL, 2-DFA, NC0, AC0}, r-complete sets
for NP are also complete under 1-1, size-increasing, r-reductions.
The diﬀerences arise in the resources required to invert the reductions
and to construct the isomorphism. Some of the classes of reductions that
we consider are so weak, that for a given function f in the class, there is no
function in the class that can check, on input x and y, whether f(x) = y.
For example, suppose f is an NC0-function and one needs to construct
a circuit that, on input x and y, outputs 1 if y = f(x), and outputs 0
otherwise. Given x and y, an NC0 circuit can compute f(x), and can check
if the bits of f(x) are equal to the corresponding bits of y; however, it cannot
output 1 if f(x) = y, since this requires taking an AND of |y| bits. Similarly,
some of the reductions are too weak to construct the isomorphism between
two sets given two 1-1, size-increasing, and invertible reductions between
them. Theorems 2.14 and 2.15 show this for 1-L-reductions, and the same
can be shown for NC0-reductions too. Observe that p-reductions do not
suﬀer from either of these two drawbacks. Hence we cannot read too much
into the failure of the Isomorphism Conjecture for r-reductions. We now
formulate another conjecture that seems better suited to getting around
the above drawbacks of some of the weak reducibilities. This conjecture
was made in [1].
Consider a 1-1, size-increasing r-function f for a resource bound r. Con-
sider the problem of accepting the set range(f). A TM accepting this set
will typically need to guess an x and then verify whether f(x) = y. It
is, therefore, a non-deterministic TM with resource bound at least r. Let
rrange ≥r be the resource bound required by this TM. For a circuit accept-
ing range(f), the non-determinism is provided as additional “guess bits”

40
M. Agrawal
and its output is 1 if the circuit evaluates to 1 on some settings of the guess
bits. We can similarly deﬁne rrange to be the resource bound required by
such a non-deterministic circuit to accept range(f).
r-Complete Degree Conjecture. r-Complete sets for NP are also com-
plete under 1-1, size-increasing, r-reductions that are rrange-invertible.
Notice that the invertibility condition in the conjecture does not allow
non-determinism. For p-reductions,
Proposition 2.4. The p-Complete Degree Conjecture is equivalent to the
Isomorphism Conjecture.
Proof.
Follows from the observation that prange = p as range of a p-
function can be accepted in non-deterministic polynomial-time, and from
Theorem 2.2.
□
Moreover, for the weaker reducibilities that we have considered, one can
show that,
Theorem 2.24. For r ∈{1-L, 1-NL, 2-DFA, NC0, AC0}, the r-Complete
Degree Conjecture is true.
Proof.
It is an easy observation that for r ∈{1-L, 1-NL, AC0}, rrange =
r. The conjecture follows from Theorems 2.14, 2.16, and 2.23.
Accepting range of a 2-DFA-function requires verifying the output of
2-DFA TM on each of its constant number of passes on the input. The
minimum resources required for this are to have multiple heads stationed
at the beginning of the output of each pass, guess the input bit-by-bit, and
verify the outputs on this bit for each pass simultaneously. Thus, the TM
is a non-deterministic TM with no space and multiple heads, each moving
in one direction only. So Theorem 2.18 proves the conjecture.
Accepting range of an NC0-function requires a non-deterministic AC0
circuit. Therefore, Theorems 2.21 and 2.23 prove the conjecture for r =
NC0.
□
In addition to the reducibilities in the above theorem, the r-Complete
Degree Conjecture was proven for some more reducibilities in [1].
These results provide evidence that r-Complete Degree Conjecture is
true for all reasonable resource bounds; in fact, there is no known example
of a reasonable reducibility for which the conjecture is false.

The Isomorphism Conjecture for NP
41
The results above also raise doubts about the intuition behind the En-
crypted Complete Set Conjecture as we shall argue now. Consider AC0-
reductions. There exist functions computable by depth d, Dlogtime-uniform
AC0 circuits that cannot be inverted on most of the strings by depth three,
non-uniform AC0 circuits [35]. However, by Theorem 2.22, AC0-complete
sets are also complete under AC0-reductions that are invertible by depth
two, non-uniform AC0 circuits and the isomorphisms between all such sets
are computable and invertible by depth three, non-uniform AC0 circuits.
So, for every 1-1, size-increasing, AC0-function, it is possible to eﬃciently
ﬁnd a dense subset on which the function is invertible by depth two AC0
circuits.
Therefore, the results for weak reducibilities provide evidence that the
Isomorphism Conjecture is true.
2.7. A New Conjecture
In this section, we revert to the conjectures in their original form. The
investigations for weak reducibilities provide some clues about the struc-
ture of NP-complete sets. They strongly suggest that all NP-complete sets
should also be complete under 1-1, size-increasing p-reductions. Proving
this, of course, is hard as it implies DP ̸= NP (Proposition 2.1). Can we
prove this under a reasonable assumption? This question was addressed
and partially answered by the author in [5], and subsequently improved by
the author and Watanabe [13]:
Theorem 2.25. (Agrawal–Watanabe) If there exists a 1-1, 2nǫ-secure
one-way function for some ǫ > 0, then all NP-complete sets are also com-
plete under 1-1, and size-increasing, P/poly-reductions.
In the above theorem,
P/poly-functions are those computed by
polynomial-size, non-uniform circuit families.
Proof Sketch. Let A be an NP-complete set and let B ∈NP. Let f0 be a
1-1, 2nǫ-secure one-way function. Recall that we have assumed that |f0(y)|
is determined by |y| for all y. H˚astad et al., [36], showed how to construct a
pseudorandom generator using any one-way function. Pseudorandom gen-
erators are size-increasing functions whose output cannot be distinguished
from random strings by polynomial-time probabilistic TMs. Let G be the
pseudorandom generator constructed from f0. Without loss of generality,
we can assume that |G(y)| = 2|y| + 1 for all y. We also modify f0 to f
as: f(y, r) = f0(y)rb where |r| = |y| and b = y · r, the inner product of

42
M. Agrawal
strings y and r. It is known that the bit b is a hard-core bit, i.e., it cannot
be predicted by polynomial-time probabilistic TMs on input f0(y)r [32].
Deﬁne B1 to be the set:
B1 = {(x, w) | x ∈B ∧|w| = |x|2/ǫ} ∪range(G),
and B2 to be the set:
B2 = {f(z) | z ∈B1}.
Both the sets are in NP. Let B2 reduce to A via polynomial-time reduction
g. Since f is 1-1, h = g ◦f is a reduction of B1 to A. We now show that h
rarely maps a large number of strings to a single string. For an odd n, let
pn =
Pr
z,z′∈U Σn[h(z) = h(z′)].
In other words, pn is the collision probability of the function h for strings
of length n. Deﬁne function ¯f(y, r) = f0(y)r¯b where ¯b is the complement
of the inner product value y · r. Since f0 is 1-1, range(f) and range( ¯f) are
disjoint and therefore, range( ¯F ) is a subset of ¯B2. Let
¯pn =
Pr
z,z′∈U Σn[h(z) = g( ¯f(z′))].
Deﬁne a probabilistic TM M + that on input u, |u| = |f(z)| for |z| = n,
randomly picks z′ ∈Σn and accepts iﬀg(u) = h(z′). The probability, over
random z ∈Σn, that M + accepts f(z) is exactly pn. The probability, over
random y, r ∈Σ
n−1
2
and b ∈Σ, that M + accepts u = f0(y)rb is exactly
1
2pn + 1
2 ¯pn (since b is either y ·r or its complement with probability 1
2 each).
Hence the gap between the two probabilities is exactly | 1
2pn −1
2 ¯pn|. If this
is large, then M + can be used to predict the hard-core bit of f with high
probability, which is not possible. Therefore, the diﬀerence of pn and ¯pn is
small.
To show that ¯pn is small, deﬁne another TM M −that on input z,
|z| = n, randomly picks z′ ∈Σn and accepts iﬀh(z) = g( ¯f(z′)). On a
random z ∈Σn, the probability that M −accepts is exactly ¯pn. On input
G(x) when x is randomly chosen from Σ
n−1
2 , the probability that M −
accepts is zero since range(G) is contained in B1 and range( ¯f) is contained
in ¯B2. Hence the diﬀerence between the two probabilities is exactly ¯pn.
This cannot be large as otherwise it violates the pseudorandomness of G.
Therefore, pn is small.
Now deﬁne function t as follows. For every n, randomly choose a wn,
|wn| = n2/ǫ; let t(x) = (x, w|x|).
Note that t is a probabilistic func-
tion. It can be argued that with high probability (over the choices of wn),

The Isomorphism Conjecture for NP
43
(1) range(t) does not intersect with range(G), and so t is a reduction of B
to B1, and (2) h◦t is 1-1, and size-increasing. Non-uniformly ﬁxing a choice
of wn for every n, we get that h ◦t is a 1-1, size-increasing, non-uniform
polynomial-time reduction of B to A.
□
In hindsight, the above theorem is not surprising since the analogous
result for EXP was shown using diagonalization [20] and one-way functions
provide a strong form of diagonalization that works within NP in contrast
to standard diagonalization techniques. It is a little unsatisfactory though,
since it only shows completeness under non-uniform 1-1, size-increasing
reductions. It is, however, suﬃcient to conclude that,
Corollary 2.2. If there exists a 1-1, 2nǫ-secure one-way function for some
ǫ > 0, then all NP-complete sets are dense.
Proof.
By the above theorem, all NP-complete sets are also complete
under 1-1, size-increasing, P/poly-reductions. It is an easy observation that
if A is dense and reduces to B via a 1-1 reduction then B is also dense.
The corollary follows from the fact that SAT is dense.
□
Another suggestion from the previous section is that one-way functions
may have easily identiﬁable dense subsets on which they are p-invertible.
This was investigated in [13], where the easy cylinder property was deﬁned.
Deﬁnition 2.18. Let f be a 1-1, size-increasing, P/poly-function.
The
function f has an easy cylinder if there exist
• polynomials q(·), q′(·), and ℓ(·) with ℓ(n) ≥2q(q′(n) + n + ⌈log(q′(n) +
n)⌉), and
• a P/poly embedding function e, computable by circuits of size ≤
q(|e(y)|) on input y,
such that for every n and for every string u of length ℓ(n), there ex-
ists a polynomial size circuit Cu, and string su, |su| ≤q′(n), such that
Cu(f(u, e(su, x))) = x for all x ∈Σn.
Intuitively,
a function f
has an easy cylinder if there exists a
parametrized (on u) dense subset in its domain on which it is easy to
invert, and the dense subset depends on the parameter in a simple way (via
the string su). Note that the circuit Cu can be chosen depending on f as
well as u but the embedding function e must be independent of u.

44
M. Agrawal
Deﬁne set K as:
K = {(p, y) | p is a code of an NTM Mp
such that Mp accepts y in at most |py|2 steps}.
K is easily seen to be NP-complete. The author and Watanabe [13]
showed that,
Theorem 2.26. (Agrawal–Watanabe) Suppose K reduces to A via f
and f is a 1-1, size-increasing, P/poly-reduction with an easy cylinder.
Then K is P/poly-isomorphic to A.
Proof Sketch. Suppose f has an easy cylinder with embedding function e.
We deﬁne a P/poly-reduction h from K to K such that f is easy to invert
on the range of h.
Fix any n, and consider a non-deterministic Turing
machine M that executes as follows:
Input (u, y). Guess x, s, |x| = n, |s| ≤q′(n), and check whether e(s, x)
equals y; if not, reject; if yes, accept if and only if x is in K.
Here we note that the advice of size q(q′(n) + n + ⌈log(q′(n) + n)⌉) for
computing e on Σq′(n)+n+⌈log(q′(n)+n)⌉is hardwired in M. Further, from
the complexity of e, M(y) halts within 2q(q′(n) + n + ⌈log(q′(n) + n)⌉)
steps. Thus, by letting pn be a code of this machine M that is (with some
padding) of size ℓ(n) ≥2q(q′(n) + n + ⌈log(q′(n) + n)⌉), we have that Mpn
halts and accepts (pn, e(s, x)) in |pne(s, x)|2 steps iﬀM accepts (pn, e(s, x))
iﬀx ∈K for all x ∈Σn.
With these machine codes pn for all n, the reduction h of K to itself is
deﬁned as follows for each n and each x ∈Σn:
h(x) = (pn, e(spn, x)).
It follows from the above argument that h is a reduction of K to K.
Furthermore, h is P/poly-function.
Let g = f ◦h.
Function g is clearly a 1-1, size-increasing P/poly-
reduction of K to A. We show that g is also P/poly-invertible. This follows
from the existence of circuit Cpn such that x = Cpn(f(pn, e(spn, x))) for all
x ∈Σn.
□
Finally, [13] showed that many of the candidate one-way functions do
have easy cylinders. For example, the function Mult deﬁned above:
Mult has two inputs numbers x and y.
Fix polynomials q′(n) = 0,
q(n) = n, and ℓ(n) = 2(n + ⌈log n⌉). Fix su = ǫ and the embedding
function e(su, z) = (su, z) = zt where |t| = ⌈log |z|⌉and t equals the

The Isomorphism Conjecture for NP
45
number |z| in binary. Therefore, Mult(u, e(su, z)) = Mult(u, zt). Since
|u| ≥|zt|, ﬁxing u ﬁxes the ﬁrst number x and z determines the second
number y. Therefore, given u, it is trivial to invert Mult(u, zt).
The function Mult also has an easy cylinder: use u to ﬁx all but the
second string of the last pair. It is also proved in [13] that all 1-1, size-
increasing, AC0-functions have easy cylinders. The notion of easy cylinders
is a formalization of the property of AC0 functions identiﬁed at the end of
the last section. As already observed, many well-known candidate one-way
functions do have easy cylinders. Based on this, [13] conjectured that,
Easy Cylinder Conjecture. All 1-1, size-increasing, P/poly-functions
have an easy cylinder.
The following corollary follows from the above two theorems.
Corollary 2.3. If there exists a 2nǫ-secure one-way function and the Easy
Cylinder Conjecture is true, then all sets complete for NP under P/poly-
reductions are P/poly-isomorphic to each other.
It is not clear if the Easy Cylinder Conjecture is true. The only indica-
tion we have is that the conjecture is true when translated to AC0 settings,
and that many well-known candidate one-way functions have easy cylin-
ders. Goldreich [31] argued against the conjecture by deﬁning a candidate
one-way function of the form f n where f is a candidate one-way function
in NC0 based on expander graphs. He argued that it is not clear whether
f n has an easy cylinder, and conjectured that it does not.
2.8. Future Directions
The results of the previous two sections suggest that the Isomorphism Con-
jecture is true. However, the evidence is far from overwhelming. Answers
to the following questions should make the picture clearer:
• Can one prove the r-Complete Degree Conjecture for other reducibil-
ities, for example, AC0[2] (computed by constant depth circuits with
AND and PARITY gates)?
• Does Goldreich’s function have an easy cylinder? Can one prove it does
not under a reasonable hypothesis?
• Even if the Easy Cylinder Conjecture is true and strong one-way
functions exist, the Isomorphism Conjecture is true only for P/poly-

46
M. Agrawal
reductions. Can one deﬁne alternative and plausible conjecture(s) from
which the Isomorphism Conjecture for p-reductions follows?
Acknowledgement The author wishes to thank the anonymous referee
whose suggestions helped improve the paper substantially.
References
[1] M. Agrawal, On the isomorphism problem for weak reducibilities, J. Comput.
System Sci. 53(2), 267–282, (1996).
[2] M. Agrawal. The ﬁrst order isomorphism theorem. In Proceedings of the
FST&TCS, vol. 2245, LNCS, pp. 70–82, (2001).
[3] M. Agrawal. Towards uniform AC0 isomorphisms. In Proceedings of the Con-
ference on Computational Complexity, pp. 13–20, (2001).
[4] M. Agrawal, For completeness, sublogarithmic space is no space, Inform.
Process. Lett. 82(6), 321–325, (2002).
[5] M. Agrawal. Pseudo-random generators and structure of complete degrees.
In Proceedings of the Conference on Computational Complexity, pp. 139–147,
(2002).
[6] M. Agrawal and E. Allender. An isomorphism theorem for circuit complexity.
In Proc. 11th Conference on Computational Complexity, pp. 2–11, (1996).
[7] M. Agrawal, E. Allender, R. Impagliazzo, T. Pitassi, and S. Rudich, Re-
ducing the complexity of reductions, Comput. Complexity. 10(2), 117–138,
(2001).
[8] M. Agrawal, E. Allender, and S. Rudich, Reductions in circuit complexity:
An isomorphism theorem and a gap theorem, J. Comput. System Sci. 57,
127–143, (1998).
[9] M. Agrawal and V. Arvind, Quasi-linear truth-table reductions to p-selective
sets, Theoret. Comput. Sci. 158, 361–370, (1996).
[10] M. Agrawal and S. Biswas, Polynomial-time isomorphism of 1-L-complete
sets, J. Comput. System Sci. 53(2), 155–160, (1996).
[11] M. Agrawal, N. Kayal, and N. Saxena, PRIMES is in P, Ann. of Math. 160
(2), 781–793, (2004).
[12] M. Agrawal and S. Venkatesh, The isomorphism conjecture for 2-DFA re-
ductions, Internat. J. Found. Comput. Sci. 7(4), 339–352, (1996).
[13] M. Agrawal and O. Watanabe. One-way functions and Berman–Hartmanis
conjecture. In Proceedings of the Conference on Computational Complexity,
pp. 194–202, (2009).
[14] E. Allender, Isomorphisms and 1-L reductions, J. Comput. System Sci. 36
(6), 336–350, (1988).
[15] E. Allender, P-uniform circuit complexity, J. ACM. 36, 912–928, (1989).
[16] E. Allender, J. Balc´azar, and N. Immerman, A ﬁrst-order isomorphism the-
orem, SIAM J. Comput. 26(2), 557–567, (1997).
[17] E. Allender and V. Gore, Rudimentary reductions revisited, Inform. Process.
Lett. 40, 89–95, (1991).

The Isomorphism Conjecture for NP
47
[18] D. Barrington, N. Immerman, and H. Straubing, On uniformity within NC1,
J. Comput. System Sci. 74, 274–306, (1990).
[19] R. Beigel, M. Kummer, and F. Stephan, Approximable sets, Inform. and
Comput. 120(2), 73–90, (1995).
[20] L. Berman. Polynomial Reducibilities and Complete Sets. PhD thesis, Cor-
nell University, (1977).
[21] L. Berman and J. Hartmanis, On isomorphism and density of NP and other
complete sets, SIAM J. Comput. 1, 305–322, (1977).
[22] H. Buhrman and J. Hitchcock. NP-hard sets are exponentially dense un-
less coNP ⊆NP/poly. In Proceedings of the Conference on Computational
Complexity, pp. 1–7, (2008).
[23] H. Buhrman, S. Homer, and L. Torenvliet, Completeness for nondeter-
ministic complexity classes, Mathematical Systems Theory. 24(1), 179–200,
(1991).
[24] R. Chang, B. Chor, O. Goldreich, J. Hartmanis, J. H˚astad, D. Ranjan, and
P. Rohatgi, The random oracle hypothesis is false, J. Comput. System Sci.
49(1), 24–39, (1994).
[25] S. Cook. The complexity of theorem proving procedures. In Proceedings of
Annual ACM Symposium on the Theory of Computing, pp. 151–158, (1971).
[26] S. Cook, A hierarchy for nondeterministic time hierarchy, J. Comput. System
Sci. 7(4), 343–353, (1973).
[27] S. Fenner, L. Fortnow, and S. Kurtz, The isomorphism conjecture holds
relative to an oracle, SIAM J. Comput. 25(1), 193–206, (1996).
[28] M. Furst, J. Saxe, and M. Sipser, Parity, circuits, and the polynomial hier-
archy, Mathematical Systems Theory. 17, 13–27, (1984).
[29] K. Ganesan and S. Homer, Complete problems and strong polynomial re-
ducibilities, SIAM J. Comput. 21, 733–742, (1992).
[30] O. Goldreich, Foundation of Cryptography I: Basic Tools. Cambridge Uni-
versity Press, (2001).
[31] O. Goldreich. A candidate counterexample for the easy cylinder conjecture.
Technical report, TR09-028, Electronic Colloquium on Computational Com-
plexity. Available at: http://www.eccc.uni-trier.de/eccc, (2009).
[32] O. Goldreich and L. A. Levin. A hardcore predicate for all one-way functions.
In Proceedings of Annual ACM Symposium on the Theory of Computing, pp.
25–32, (1989).
[33] J. Hartmanis and L. Hemchandra,
One-way functions and the non-
isomorphism of NP-complete sets, Theoret. Comput. Sci. 81(1), 155–163,
(1991).
[34] J. Hartmanis, N. Immerman, and S. Mahaney. One-way log-tape reductions.
In Proceedings of Annual IEEE Symposium on Foundations of Computer
Science, pp. 65–72, (1978).
[35] J. H˚astad. Almost optimal lower bounds for small depth circuits. In Pro-
ceedings of Annual ACM Symposium on the Theory of Computing, pp. 6–20,
(1986).
[36] J. H˚astad, R. Impagliazzo, L. Levin, and M. Luby, A pseudo-random gener-

48
M. Agrawal
ator from any one-way function, SIAM J. Comput. pp. 221–243, (1998).
[37] L. A. Hemchandra and A. Hoene, Collapsing degrees via strong computation,
J. Comput. System Sci. 46(3), 363–380, (1993).
[38] S. Homer, S. Kurtz, and J. Royer, On 1-truth-table hard languages, Theoret.
Comput. Sci. 155, 383–389, (1993).
[39] N. Jones, Space-bounded reducibility among combinatorial problems, J.
Comput. System Sci. 11, 68–85, (1975).
[40] D. Joseph and P. Young, Some remarks on witness functions for nonpoly-
nomial and noncomplete sets in NP, Theoret. Comput. Sci. 39, 225–237,
(1985).
[41] K. Ko, T. Long, and D. Du, A note on one-way functions and polynomial-
time isomorphisms, Theoret. Comput. Sci. 47, 263–276, (1987).
[42] S. Kurtz. A relativized failure of Berman–Hartmanis conjecture. Unpub-
lished Manuscript, (1983).
[43] S. Kurtz, S. Mahaney, and J. Royer. Noncollapsing degrees. Technical report
87-001, Department of Computer Science, University of Chicago, (1987).
[44] S. Kurtz, S. Mahaney, and J. Royer, Collapsing degrees, J. Comput. System
Sci. 37, 247–268, (1988).
[45] S. Kurtz, S. Mahaney, and J. Royer. The structure of complete degrees. In ed.
A. Selman, Complexity Theory Retrospective, pp. 108–146. Springer-Verlag,
(1988).
[46] S. Kurtz, S. Mahaney, and J. Royer, The isomorphism conjecture fails rela-
tive to a random oracle, J. ACM. 42(2), 401–420, (1995).
[47] S. Lindell. A purely logical characterization of circuit complexity. In Pro-
ceedings of the Structure in Complexity Theory Conference, pp. 185–192,
(1992).
[48] C. Lund, L. Fortnow, H. Karloﬀ, and N. Nissan, Algebraic methods for
interactive proof systems, J. ACM. 39(4), 859–868, (1992).
[49] S. Mahaney, Sparse complete sets for NP: Solution of a conjecture of Berman
and Hartmanis, J. Comput. System Sci. 25(2), 130–143, (1982).
[50] J. Myhill, Creative sets, Z. Math. Logik Grundlag. Math. 1, 97–108, (1955).
[51] M. Ogihara, Polynomial time membership comparable sets, SIAM J. Com-
put. 24(5), 1068–1081, (1995).
[52] C. Papadimitriou, Computational Complexity. Addison-Wesley, (1995).
[53] A. L. Selman, A survey of one-way functions in complexity theory, Mathe-
matical Systems Theory. 25, 203–221, (1992).
[54] A. Shamir, IP = PSPACE, J. ACM. 39(4), 869–877, (1992).
[55] O. Watanabe, A comparison of polynomial time completeness notions, The-
oret. Comput. Sci. 54, 249–265, (1987).

Chapter 3
The Ershov Hierarchy
Marat M. Arslanov∗
Department of Mathematics
Kazan State University
420008 Kazan, Russia
E-mail: Marat.Arslanov@ksu.ru
In this chapter we investigate set-theoretic properties and the Turing
degree structure of the hierarchy of ∆0
2-sets, which is well known in the
literature as the Ershov hierarchy.
Contents
3.1
The Hierarchy of Sets
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
50
3.1.1
The ﬁnite levels of the Ershov hierarchy
. . . . . . . . . . . . . . . . .
51
3.1.2
The properties of productiveness and creativeness on the n-c.e. sets . .
54
3.1.3
The class of the ω-c.e. sets . . . . . . . . . . . . . . . . . . . . . . . . .
57
3.1.4
A description of the ∆0
2-sets using constructive ordinals
. . . . . . . .
62
3.1.5
The inﬁnite levels of the Ershov hierarchy . . . . . . . . . . . . . . . .
68
3.1.6
Levels of the Ershov hierarchy containing Turing jumps
. . . . . . . .
72
3.2
The Turing Degrees of the n-c.e. Sets
. . . . . . . . . . . . . . . . . . . . . .
76
3.2.1
The class of the n-c.e. degrees . . . . . . . . . . . . . . . . . . . . . . .
76
3.2.2
The degrees of the n-c.e. sets in the n-CEA hierarchy
. . . . . . . . .
79
3.2.3
The relative arrangement of the n-c.e. degrees . . . . . . . . . . . . . .
82
3.2.4
The cupping, capping and density properties . . . . . . . . . . . . . . .
83
3.2.5
Splitting properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
3.2.6
Isolated d-c.e. degrees
. . . . . . . . . . . . . . . . . . . . . . . . . . .
87
3.2.7
A generalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
3.2.8
Further results and open questions
. . . . . . . . . . . . . . . . . . . .
92
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
∗The author’s research was partially supported by the Russian Foundation for Basic
Research 05-01-00605. The author would like to thank the anonymous referee for many
suggestions and improvements throughout the chapter.
49

50
M. M. Arslanov
3.1. The Hierarchy of Sets
The notion of a computably enumerable (c.e.) set, i.e. a set of integers whose
members can be eﬀectively listed, is a fundamental one.
Another way
of approaching this deﬁnition is via an approximating function {As}s∈ω
to the set A in the following sense:
We begin by guessing x /∈A at
stage 0 (i.e. A0(x) = 0); when later x enters A at a stage s + 1, we
change our approximation from As(x) = 0 to As+1(x) = 1.
Note that
this approximation (for ﬁxed) x may change at most once as s increases,
namely when x enters A.
An obvious variation of this deﬁnition is to
allow more than one change: A set A is 2-c.e. (or d-c.e.) if for each x,
As(x) change at most twice as s increases. This is equivalent to requir-
ing the set A to be the diﬀerence of two c.e. sets A1 −A2.
Similarly,
one can deﬁne n-c.e. sets by allowing n changes for each x.
A direct
generalization of this reasoning leads to sets which are computably ap-
proximable in the following sense: For a set A there is a set of uniformly
computable sequences {f(0, x), f(1, x), . . . , f(s, x), . . . |x ∈ω} consisting of
0 and 1 such that for any x the limit of the sequence f(0, x), f(1, x), . . .
exists and is equal to the value of the characteristic function A(x) of
A.
The well-known Shoenﬁeld Limit Lemma states that the class of
such sets coincides with the class of all ∆0
2-sets.
Thus, for a set A,
A ⩽T ∅′ if and only if there is a computable function f(s, x) such that
A(x) = lims f(s, x).
The notion of d-c.e. and n-c.e. sets goes back to Putnam [51] and
Gold [37], and was ﬁrst investigated and generalized by Ershov [33–35].
The arising hierarchy of sets is now known as the Ershov diﬀerence hierar-
chy. The position of a set A in this hierarchy is determined by the number
of changes in the approximation of A described above, i.e. by the number
of diﬀerent pairs of neighboring elements of the sequence.
The Ershov hierarchy consists of the ﬁnite and inﬁnite levels. The ﬁnite
levels of the hierarchy consist of the n-c.e. sets for n ∈ω. Otherwise a set
belongs to one of the inﬁnite levels of the hierarchy. The inﬁnite levels of
the hierarchy are deﬁned using inﬁnite constructive ordinals. As it turns
out, the resulting hierarchy of sets exhausts the whole class of ∆0
2-sets.
Each subsequent level of the hierarchy contains all previous ones but does
not coincide with any of them. At the same time the levels of the hierarchy
are arranged so uniformly, that even the following conjecture was stated:
The semilattices of the Turing degrees of the sets from the ﬁnite levels of
the hierarchy starting with the second level are indistinguishable in ﬁrst

The Ershov Hierarchy
51
order predicate logic.
This conjecture became well known as Downey’s
Conjecture and involved a whole series of publications.
The Turing degrees of the sets from the ﬁnite levels of the Ershov hi-
erarchy have been intensively studied since the 1970s. It turned out that
they (partially ordered by Turing reducibility) have a suﬃciently rich in-
ner structure, in many respects repeating its paramount representative, the
class of c.e. degrees.
Our notation and terminology are standard and generally follow
Soare [56]. In particular, the standard enumerations of the c.e. sets and
partial computable functions are denoted by {Wx}x∈ω and {Φx}x∈ω re-
spectively. As usual, we append [s] to various functionals such as ΦA
e (x)[s]
to indicate the state of aﬀairs at stage s. In particular if A is c.e. (or oth-
erwise being approximated) we mean by this notation the result of running
the eth Turing machine for s steps on input x with oracle As, the subset
of A enumerated by stage s (or the approximation to A at stage s). We
take the use of this computation to be the greatest number about which
it queries the oracle and denote it by ϕe(A; x)[s]; so changing the oracle
at ϕe(A; x)[s] destroys the computation. We also use a modiﬁed version
of the restriction notation for functions to mesh with this deﬁnition of the
use: f⌈x means the restriction of the function f to numbers y ≤x. Thus if
ΦA
e (x) is convergent, then the use is A⌈ϕe(A; x) and changing A at ϕe(A; x)
destroys this computation (and similarly for computations and approxima-
tions at stage s of a construction). For a set A ⊆ω its complement ω −A
is denoted by ¯A. The cardinality of a set A is denoted by |A|.
The pairing function ⟨x, y⟩is deﬁned as ⟨x, y⟩:=
(x+y)2+3x+y
2
and
bijectively maps ω2 onto ω.
We denote by l and r the uniquely de-
ﬁned functions such that for all x, y, l(⟨x, y⟩) = x, r(⟨x, y⟩) = y and
⟨l(x), r(x)⟩= x; the n-place function ⟨x1, . . . xn⟩for n > 2 is deﬁned
as ⟨x1, . . . xn⟩= ⟨⟨. . . ⟨x1, x2⟩, x3⟩, . . . , xn⟩. In this case the s-th compo-
nent of ⟨x1, . . . xn⟩is denoted as cn,s. Thus, ⟨cn,1(x), . . . cn,n(x)⟩= x and
cn,s(⟨x1, . . . xn⟩) = xs. If a function f is deﬁned at x, then we write f(x) ↓,
otherwise f(x) ↑. The characteristic function of a set A is denoted by the
same letter: A(x) = 1, if x ∈A, and otherwise A(x) = 0.
3.1.1. The ﬁnite levels of the Ershov hierarchy
We begin with the following characterization of the ∆0
2-sets (i.e.
sets
A ⩽T ∅′).
Lemma 3.1. (Shoenﬁeld Limit Lemma) A set A is a ∆0
2-set if and only if

52
M. M. Arslanov
there is a computable function of two variables f such that f(s, x) ∈{0, 1}
for all s, x, f(0, x) = 0 and lims f(s, x) exists for each x (i.e. |{s : f(s, x) ̸=
f(s + 1, x)}| < ∞), and lims f(s, x) = A(x).
It follows easily from the Limit Lemma that
Theorem 3.1. A set A is Turing reducible (T-reducible) to ∅′ if and only if
there is a uniformly computably enumerable sequence of c.e. sets {Rx}x∈ω
such that
R0 ⊇R1 ⊇. . . ,
∞
\
x=0
Rx = ∅,
and
A =
∞
[
x=0
(R2x −R2x+1).
(1)
Proof.
(→) Let A ⩽T ∅′. By the Limit Lemma there is a computable
function f such that A = lims f(s, x), and for all x, f(0, x) = 0. Deﬁne c.e.
sets Rn, n ∈ω, as follows:
R0 = {y : ∃s(f(s, y) = 1)};
R1 = {y : ∃s0, s1(s0 < s1, f(s0, y) = 1, f(s1, y) = 0)}, and in general for
n > 0;
Rn = {y : ∃s0 < s1 < . . . < sn(f(s0, y) = 1, f(s1, y) = 0, . . . , f(sn, y) =
n + 1 mod 2}.
Obviously, all sets Rn are c.e., the sequence {Rx}x∈ω is uniformly c.e.,
and R0 ⊇R1 ⊇. . ..
It is also easy to check that T∞
x=0 Rx = ∅and
A = S∞
x=0(R2x −R2x+1).
(←) For this direction the proof is straightforward.
□
Note that if A is an arbitrary Σ0
2-set then it is easy to show that A =
S∞
x=0(R2x −R2x+1) for a uniformly computably enumerable sequence of
c.e. sets {Rx}x∈ω such that R0 ⊇R1 ⊇R2 ⊇. . .. Therefore, in Theorem
3.1 the condition T∞
x=0 Rx = ∅is necessary.
If in (1) starting from some n all elements of the sequence {Rx}x∈ω are
empty, then we obtain sets from the ﬁnite levels of the Ershov hierarchy.
Deﬁnition 3.1. A set A is n-computably enumerable (an n-c.e. set), if
either n = 0 and A = ∅, or n > 0 and there are c.e. sets R0 ⊇R1 ⊇R2 ⊇
. . . ⊇Rn−1 such that
A =

n−1
2

[
i=0
(R2i −R2i+1)
(here if n is an odd number then Rn = ∅).

The Ershov Hierarchy
53
It follows from this deﬁnition that if n > 1 and n is an even number
(n = 2m) then
A =
m−1
[
x=0
(R2x −R2x+1),
and if n > 1 and n is an odd number (n = 2m + 1) then
A =
 m−1
[
x=0
(R2x −R2x+1)
	
∪R2m.
Therefore, the class of 1-c.e. sets coincides with the class of c.e. sets,
2-c.e. sets can be written as R1 −R2, where R1 ⊇R2 c.e. sets, therefore
they are also called d-c.e. (diﬀerence-c.e.) sets, 3-c.e. sets can be written
as (R1 −R2) ∪R3 etc.
The n-c.e. sets constitute the level Σ−1
n
of the Ershov hierarchy. They
are also called Σ−1
n -sets. The complements of the Σ−1
n -sets constitute the
level Π−1
n
of the hierarchy (Π−1
n -sets). The intersection of these two classes
is denoted by ∆−1
n :
∆−1
n
= Σ−1
n ∩Π−1
n .
The proof of the following statement is straightforward.
Theorem 3.2.
A set A is an n-c.e. set for some n ⩾0 if and only if
there is a computable function g of two variables s and x such that A(x) =
lims g(s, x) for every x, g(0, x) = 0, and
|{s|g(s + 1, x) ̸= g(s, x)}| ⩽n.
(1)
The class of the n-c.e. sets is denoted by Rn. It is clear that every
n-c.e. set is also (n + 1)-c.e., therefore R0 ⊆R1 ⊆R2 ⊆. . . . It is easy to
see that the reverse inclusions do not hold and that for every n > 0 there
is an (n + 1)-c.e. set with an (n + 1)-c.e. complement which is not n-c.e.
and not even co-n-c.e.
Therefore, we have
Theorem 3.3. (Hierarchy Theorem) For every n > 0,
Σ−1
n
∪Π−1
n
⊊Σ−1
n+1 ∩Π−1
n+1.

54
M. M. Arslanov
Comment.
The Limit Lemma appeared for the ﬁrst time in Shoen-
ﬁeld [54]. The ﬁnite levels of the Ershov hierarchy were deﬁned and stud-
ied (under diﬀerent names) also in Putnam [51] and Gold [37]. Addison [1]
considered a general method of constructing “diﬀerence” hierarchies. In
particular, his hierarchy, generated by c.e. sets, deﬁnes the same classes of
n- and ω-c.e. sets (ω-c.e. sets will be deﬁned later). In the same paper
he also obtained several properties of n- and ω-c.e. sets, for instance, the
Hierarchy Theorem 3.3. The notations Σ−1
n , Π−1
n
and ∆−1
n
for the ﬁnite
levels of the hierarchy, as well as analogous notations for further levels (see
Theorem 3.14) were introduced by Ershov [33, 34].
3.1.2. The properties of productiveness and creativeness on
the n-c.e. sets
On the class of n-c.e. sets Ershov [33] introduced the notion of creative sets
which is similar to the appropriate deﬁnition on c.e. sets and preserves its
main properties.
Deﬁnition 3.2. A set P is Σ−1
n -productive, n ⩾2, if there is an n-place
computable function f(x1, . . . , xn) such that for any c.e. sets Wx1 ⊇Wx2 ⊇
. . . ⊇Wxn

n+1
2

[
i=1
(Wx2i−1 −Wx2i) ⊆P →f(x1, . . . , xn) ∈P −

n+1
2

[
i=1
(Wx2i−1 −Wx2i)
(for odd n, set Wxn+1 = ∅).
An n-c.e. set A is Σ−1
n -creative if its complement is Σ−1
n -productive.
For simplicity we will consider only the case n = 2, the general case is
similar.
For d-c.e. sets the deﬁnition of Σ−1
2 -productive sets can be reformula-
ted as follows: A set P is Σ−1
2 -productive, if there is a unary computable
function f such that for any x,
Wl(x) ⊇Wr(x) & (Wl(x) −Wr(x)) ⊆P →f(x) ∈P −(Wl(x) −Wr(x)).
Similarly to the case of c.e. sets, Σ−1
2 -productive sets cannot be d-c.e. sets.
Indeed, if P = Wx −Wy, Wx ⊇Wy, then f(⟨x, y⟩) ∈P −(Wx −Wy) = ∅,
a contradiction.

The Ershov Hierarchy
55
Deﬁne:
R1 = {x|x ∈Wl(x) ∪Wr(x)};
R2 = {x|x ∈Wr(x)}.
It is clear that R1 ⊇R2 and R1 −R2 = {x|x ∈Wl(x) & x /∈Wr(x)}.
Theorem 3.4. The set R1 −R2 is P−1
2 -creative.
Proof.
We have to prove that the set ω −(R1 −R2) = (ω −R1) ∪R2 is
P−1
2 -productive.
Let Wx −Wy ⊆(ω −R1) ∪R2.
If ⟨x, y⟩∈R1 −R2, then ⟨x, y⟩∈
R1 & ⟨x, y⟩/∈R2 implies ⟨x, y⟩∈Wx and ⟨x, y⟩/∈Wy, which implies ⟨x, y⟩∈
Wx−Wy. But this is impossible, since Wx−Wy ⊆(ω−R1)∪R2. Therefore
⟨x, y⟩∈ω −(R1 −R2).
If ⟨x, y⟩∈Wx −Wy, then ⟨x, y⟩∈Wx and
⟨x, y⟩/∈Wy. It follows that ⟨x, y⟩∈R1 −R2, a contradiction. Therefore,
for all x and y, Wx −Wy ⊆ω −(R1 −R2), which implies ⟨x, y⟩∈(ω −
(R1 −R2)) −(Wx −Wy).
□
Theorem 3.5. The set R1 −R2 is Σ−1
2 -complete in the sense that every
d-c.e. set is m-reducible to R1 −R2.
Proof.
We have R1 −R2 = {x|x ∈Wl(x)
&
x /∈Wr(x)}. It follows
from the proof of Theorem 3.4 that the function ⟨x, y⟩is a productive
function for R1 −R2, i.e.
Wx −Wy ⊆R1 −R2 →⟨x, y⟩∈R1 −R2 −
(Wx −Wy).
Let A1 and A2 be c.e. sets and A1 ⊇A2. Now we deﬁne a computable
function h which m-reduces A1 −A2 to R1 −R2.
We ﬁrst deﬁne computable functions g1 and g2 as follows:
Wg1(x) = {t|Φx(t, 0) ↓= 0}, Wg2(x) = {t|Φx(t, 0) ↓= 0 & Φx(t, 1) ↓= 1}.
Now deﬁne
q(y, z, t, n) =



0, if y ∈A1, t ∈Wz, n = 0;
1, if y ∈A2, t ∈Wz, n = 1;
↑, in all other cases.
By the s-m-n-theorem there is a computable function α such that
Φα(y,z)(t, n) = q(y, z, t, n). It follows that
Φα(y,z)(t, n) =
 n, if y ∈An+1, t ∈Wz, n ⩽1;
↑, otherwise.
Deﬁne p(x) = ⟨g1(x), g2(x)⟩. Let β be a computable function such that
for all y, z, Wβ(y,z) = {p(α(y, z))}.

56
M. M. Arslanov
By the Recursion Theorem there is a computable function f such that
for each y,
Wβ(y,f(y)) = Wf(y).
It follows from the deﬁnition of the function β that Wf(y) = {p(α(y, f(y)))}.
Finally deﬁne h(y) = p(α(y, f(y))).
To prove that for any y, y ∈A1 −A2 ↔h(y) ∈R1 −R2, suppose that
y ∈A1 −A2. We have Φα(y,f(y))(t, 0) ↓= 0 if and only if t ∈Wf(y) if and
only if t = p(α(y, f(y))) if and only if t = h(y). Therefore, Wg1(α(y,f(y))) =
{h(y)} = Wf(y). Since y /∈A2, Wg2(α(y,f(y))) = ∅.
Let us denote ⟨g1(α(y, f(y))), g2(α(y, f(y)))⟩by x.
Then x
=
p(α(y, f(y))).
If Wg1(α(y,f(y))) −Wg2(α(y,f(y))) ⊆R1 −R2, then x ∈
R1 −R2 −Wg1(α(y,f(y))), and since x = p(α(y, f(y))) = h(y), h(y) ∈
R1 −R2 −Wg1(α(y,f(y))), a contradiction.
Therefore, Wg1(α(y,f(y))) −Wg2(α(y,f(y))) ⊆R1 −R2. But the set
Wg1(α(y,f(y))) −Wg2(α(y,f(y))) consists of a single element h(y), therefore
h(y) ∈R1 −R2.
Now suppose that y /∈A1 −A2. In this case we have either a) y /∈A1,
or b) y ∈A1 ∩A2.
Case a) If y /∈A1, then the function q is undeﬁned at this y and all
z, t, n, therefore the function Φα(y,f(y)) is also undeﬁned for all t, n.
It
follows that the sets Wg1(α(y,f(y))) and Wg2(α(y,f(y))) are empty and
h(y) = ⟨g1(α(y, f(y))), g2(α(y, f(y)))⟩∈R1 −R2,
since the set R1 −R2 is productive.
Case b) If y ∈A1∩A2, then it follows from their deﬁnitions that the sets
Wg1(α(y,f(y))) and Wg2(α(y,f(y))) coincide. Therefore, since the set R1 −R2
is productive, we have h(y) ∈R1 −R2.
It follows that the function h(y) m-reduces the set A1 −A2 to the Σ−1
2 -
creative set R1 −R2, as required.
□
The proof of Theorem 3.5 can be reorganized to prove a more general
claim: Any Σ−1
n -creative set is Σ−1
n -complete in the sense that any n-c.e.
set is m-reducible to this set.
Theorem 3.6. Let Qn =
[ n+1
2
]
[
i=1
(R2i−1 −R2i) (letting Rn+1 = ∅), where c.e.
sets R1 ⊇R2 ⊇. . . ⊇Rn are deﬁned as follows: for every i, 1 ⩽i ⩽
n, Ri = {x|x ∈
n[
s=i
Wcns(x)}.

The Ershov Hierarchy
57
a) The sets Qn are Σ−1
n -creative sets for all n, 2 ⩽n < ω;
b) The sets Qn are Σ−1
n -complete.
The proof is similar to the proof of Theorem 3.5. Now the functions
gi, 1 ⩽i ⩽n, and p are deﬁned as follows: Wgi(x) = {t|Φx(t, 0) ↓=
0 & . . . & Φx(t, i−1) ↓= i−1}, p(x) = g(⟨g1(x), . . . , gn(x)⟩), where g is the
productive function for Qn.
Comment. Theorems 3.4, 3.5 and 3.6 are from Ershov [33].
3.1.3. The class of the ω-c.e. sets
As we can see, the n-c.e. sets for n < ω does not exhaust the collection
of ∆0
2-sets. Therefore, to obtain in this way a description of all ∆0
2-sets we
need to consider inﬁnite levels of the hierarchy.
In the deﬁnition of n-c.e. sets (n < ω) we have used non-increasing
sequences R0 ⊇R1 ⊇. . . ⊇Rn−1 of c.e. sets. The inﬁnite levels of the
Ershov hierarchy are deﬁned using uniformly c.e. sequences of c.e. sets,
such that the c.e. sets in these sequences satisfy the same ⊆-relations which
are consistent with the order type of the ordinal which deﬁnes the level of
this set in the hierarchy.
Deﬁnition 3.3. Let P(x, y) be a computable binary relation which par-
tially orders the set of natural numbers (for convenience instead of P(x, y)
we will write x ⩽P y.) By deﬁnition, a uniformly c.e. sequence {Rx} of
c.e. sets is a P- (or ⩽P -)sequence if for all pairs x, y, x ⩽P y implies that
Rx ⊆Ry.
Note that we can easily redeﬁne the n-c.e. sets for n < ω according to
this deﬁnition. Indeed, if, for instance, for some c.e. sets A1 ⊇A2 ⊇. . . An
we have A = (A1 −A2) ∪. . . ∪(An−1 −An) (where n is an even number),
then let R0 = An, R1 = An−1, . . . , Rn−1 = A1. We have thus obtained an
n-sequence (n = {0 < 1 < . . . < n −1}) R0 ⊆R1 ⊆. . . ⊆Rn−1 such that
A =
n−1
2[
i=0
(R2i+1 −R2i).
The sets from the ﬁrst inﬁnite level of the Ershov hierarchy are the ω-
c.e. sets. They are deﬁned using ω-sequences of c.e. sets, i.e. sequences
{Rx}x∈ω, in which the relation Rx ⊆Ry is consistent with the order type
of ω = {0 < 1 < . . .}: R0 ⊆R1 ⊆. . . .

58
M. M. Arslanov
Deﬁnition 3.4. A set A ⊆ω belongs to level Σ−1
ω
of the Ershov hier-
archy (or A is a Σ−1
ω -set) if there is an ω-sequence {Rx}x∈ω such that
A =
∞
[
n=0
(R2n+1 −R2n).
A belongs to level Π−1
ω
of the Ershov hierar-
chy (or A is a Π−1
ω -set), if A ∈Σ−1
ω . Finally, A belongs to level ∆−1
ω
of
the Ershov hierarchy (A is a ∆−1
ω -set), if A and A both are Σ−1
ω -sets, i.e.
∆−1
ω
= Σ−1
ω ∩Π−1
ω . ∆−1
ω -sets are also called ω-c.e. sets.
Theorem 3.7. (Epstein, Haas, and Kramer [32]) A set A ⊆ω belongs to
level Σ−1
ω
of the Ershov hierarchy if and only if there is a partial computable
function ψ such that for every x,
x ∈A implies ∃s(ψ(s, x) ↓) and A(x) = ψ(µs(ψ(s, x) ↓), x);
x /∈A implies either ∀s(ψ(s, x) ↑),
or ∃s(ψ(s, x) ↓) & A(x) = ψ(µs(ψ(s, x) ↓), x).
In other words, A ⊆dom(ψ(µs(ψ(s, x) ↓), x)), and for every x,
x ∈dom(ψ(µs(ψ(s, x) ↓), x)) implies A(x) = ψ(µs(ψ(s, x) ↓), x).
Proof.
(→) Let A =
∞
[
n=0
(R2n+1 −R2n) for some ω-sequence {Rx}x∈ω.
Deﬁne the required partial computable function ψ(s, x) as follows: For a
given x, wait for a stage s such that x ∈R2m+1,s for some (least) m. (If
this never happens then ψ(s, x) ↑for all s.) Then deﬁne ψ(2m + 1, x) = 1
and wait for a stage s1 > s and a number n < 2m + 1 such that x ∈
Rn,s1 −Rn−1,s1.
Then deﬁne ψ(n, x) = 1, if n is an odd number, and
ψ(n, x) = 0, if n is an even number, and so on. Obviously, the function ψ
is the required function.
(←) Deﬁne c.e. sets Ri, i ⩾0, as follows:
R0 = {x|ψ(0, x) ↓= 0},
R1 = R0 ∪{x|ψ(0, x) ↓= 1},
. . . . . . . . . . . . .
R2m = R2m−1 ∪{x|ψ(m, x) ↓= 0},
R2m+1 = R2m ∪{x|ψ(m, x) ↓= 1}.
Obviously, {Rn}n∈ω is a uniformly c.e. sequence of c.e. sets Ri, i ∈ω, and
R0 ⊆R1 ⊆. . . .
Now suppose that x ∈A. Then there is an integer s such that ψ(s, x) ↓,
A(x) = ψ(s, x) = 1, and if s > 0, then ψ(s −1, x) ↑. Therefore, x ∈R2n+1
for some (least) n, x /∈
[
m<2n+1
Rm and x ∈
∞
[
n=0
(R2n+1 −R2n).

The Ershov Hierarchy
59
Conversely, if x /∈A, then either ψ(s, x) ↑for all s, or there is an integer
s such that ψ(s, x) ↓= 0, and if s > 0 then ψ(s −1, x) ↑. Therefore, either
x /∈Ri for all i, or x ∈R2n for some (least) n and x /∈
[
m<2n
Rm. This
means that x /∈
∞
[
n=0
(R2n+1 −R2n).
□
Deﬁnition 3.5. Let f be a total unary function.
A set A is called f-
computably enumerable (an f-c.e. set), if there is a computable function g
such that for all s and x, A(x) = lims g(s, x), and
|{s : g(s, x) ̸= g(s + 1, x)}| ⩽f(x).
Theorem 3.8. a) There is an id-c.e. set (where id is the identity function)
which is not n-c.e. for any n ∈ω;
b) Let f and g be computable functions such that ∃∞x(f(x) < g(x)).
Then there is a g-c.e., but not f-c.e. set;
c) There is a ∆0
2-set which is not f-c.e. for any computable function f;
d) Let A be an f-c.e. set for some computable function f, A ̸= ∅, and
let g be a computable function such that ∀y∃x(g(x) ⩾y). Then there exists
a g-c.e. set B such that A ≡T B.
Proof.
For parts a)–c) use Cantor’s diagonalization argument. For part
d) let h be the following computable function: h(0) = 0, and h(x + 1) =
µy{y > h(x) & g(y) ⩾f(x + 1)}. Deﬁne B = {x : ∃z ∈A(x = h(z))}. Then
B is g-c.e. and B ≡T A.
□
Theorem 3.9. Let A ⊆ω. The following are equivalent:
a) A is ω-c.e.
b) There is an ω-sequence {Rx}x∈ω such that
[
x∈ω
Rx = ω; and A =
∞
[
n=0
(R2n+1 −R2n).
c) A is f-c.e. for some computable function f.
d) There is a partial computable function ψ such that for all x,
A(x) = ψ(k, x),
where
k = µt(ψ(t, x) ↓).
(1)
(In this case we write A(x) = ψ(µt(ψ(t, x) ↓), x).)
e) A is tt-reducible to ∅′.

60
M. M. Arslanov
Proof.
c) →d) Let A be ω-c.e. and
A(x) = lim
s g(s, x), |{s|g(s + 1, x) ̸= g(s, x)}| ⩽f(x)
for some computable functions g and f. Deﬁne a partial computable func-
tion ψ as follows: For any x
ψ(f(x), x) = g(0, x).
If ∃s(g(s + 1, x) ̸= g(s, x)), then let s1 be the least such s.
Deﬁne
ψ(f(x)−1, x) = g(s1+1, x). Further we proceed by induction: let ψ(f(x)−
i, x) = g(si + 1, x) be the last value of ψ deﬁned this way. If ∃s > si(g(s +
1, x) ̸= g(s, x)), then let si+1 be the least such s. Deﬁne ψ(f(x)−(i+1), x) =
g(si+1, x). It is clear that the function ψ is partial computable and for all
x, A(x) = ψ(µs(ψ(s, x) ↓), x).
Part d) →a) immediately follows from Theorem 3.7.
a) →b) Let {Px}x∈ω and {Qx}x∈ω be ω-sequences such that
A =
∞
[
n=0
(P2n+1 −P2n) and ¯A =
∞
[
n=0
(Q2n+1 −Q2n). Deﬁne a new ω-
sequence {Rx}x∈ω as follows: R0 = P0. For x > 0, Rx = Px ∪Qx−1. It is
clear, that A =
∞
[
n=0
(R2n+1 −R2n) and
[
x∈ω
Rx = ω;.
b) →c) Let A =
∞
[
n=0
(R2n+1 −R2n) for an ω-sequence {Rx}x∈ω such
that
[
x∈ω
Rx = ω;. Deﬁne computable functions g(s, x) and f(x) as follows:
For a given x ∈ω, ﬁrst ﬁnd the ﬁrst stage t such that either x ∈R0,t
or x ∈Rm,t −Rm−1,t for some m > 0. If x ∈R0,t then f(x) = 0 and
g(s, x) = 0 for all s ∈ω. Otherwise deﬁne f(x) = m, g(0, x) = 1, if m
is an odd number, and g(0, x) = 0, otherwise. Further, for s > 0 deﬁne
g(s, x) = g(s−1, x), if for any m, x ∈Rm,s implies x ∈Rm,s−1. Otherwise,
let n = µm(x ∈Rm,s). Deﬁne g(0, x) = 1, if n is an odd number, and
g(0, x) = 0 otherwise.
Obviously, the functions g and f are computable, A(x) = lims g(s, x)
for all x, and |{s : g(s, x) ̸= g(s + 1, x)}| ⩽f(x).
c) →e) Let A(x) = lims g(s, x) and |{s : g(s, x) ̸= g(s + 1, x)}| ≤f(x)
for some computable functions g and f. Deﬁne
M = {⟨i, x, a⟩: ∃t(|{s ≤t : g(s, x) ̸= g(s + 1, x)}| = i & g(t, x) = a)}.

The Ershov Hierarchy
61
Obviously, M is c.e. and x ∈A if and only if (⟨0, x, 1⟩∈M & ⟨1, x, 1⟩̸∈
M & ⟨1, x, 0⟩̸∈M) ∨(⟨1, x, 1⟩∈M & ⟨2, x, 1⟩̸∈M & ⟨2, x, 0⟩̸∈M) ∨. . .∨
⟨f(x), x, 1⟩∈M.
The last condition can be written as a tt-condition and, therefore, A ≤tt
M.
e) →c) For a given x we can eﬀectively ﬁnd an integer n, a Boolean
function α : {0, 1}n →{0, 1}, and a ﬁnite set {t1, . . . tn} such that x ∈A if
and only if α(K(t1), . . . K(tn)) = 1. Deﬁne
g(s, x) = α(Ks(t1), . . . Ks(tn)).
(Here K is the creative set {e : e ∈We} and {Ks}s∈ω is an eﬀective
enumeration of K.) It is clear, that A(x) = lims g(s, x), and |{s : g(s, x) ̸=
g(s + 1, x)}| ≤n.
□
If we replace in part d) of Theorem 3.9 µt by a bounded search opeara-
tor µt⩽n, then we obtain a similar description of the n-c.e. sets (more
precisely, the weakly n-c.e. sets) for 1 ⩽n < ω.
Deﬁnition 3.6. (Epstein, Haas, and Kramer [32]) A set A is weakly n-c.e.
for some n ⩾0, if there is a computable function g of two variables s and
x such that A(x) = lims g(s, x) and
|{s|g(s + 1, x) ̸= g(s, x)}| ⩽n
(in the deﬁnition of n-c.e. sets the condition “g(0, x) = 0 for every x” is
omitted).
The following properties of the weakly n-c.e. sets are straightforward.
a) A set is weakly 0-c.e. if and only if it is computable; b) Every n-c.e.
set also is weakly n-c.e.; c) A set A is weakly n-c.e. for an arbitrary n ⩾0
if and only if its complement ¯A is also weakly n-c.e.; d) The sets A and ¯A
are both (n + 1)-c.e. (i.e. A ∈∆−1
n+1) if and only if they are both weakly
n-c.e.; e) For any n > 0 there is a weakly n-c.e. set A such that neither A
nor ¯A is n-c.e.
Theorem 3.10. (Epstein, Haas, and Kramer [32], Carstens [15]) Let A ⊆
ω and n > 0. The following are equivalent:
a) A is weakly n-c.e.;
b)There is a partial computable function ψ such that for every x,
A(x) = ψ(µt⩽n(ψ(t, x) ↓), x);
(1)

62
M. M. Arslanov
c) A is bounded truth-table reducible to ∅′ with norm n.
Proof.
a) →b) Let A(x) = lims g(s, x) for some computable function g
and |{s|g(s + 1, x) ̸= g(s, x)}| ⩽n for every x.
The required function ψ is deﬁned as follows: for every x, ψ(n, x) =
g(0, x). If ∃s(g(s + 1, x) ̸= g(s, x)), then let s1 be the least such s. Deﬁne
ψ(n −1, x) = g(s1 + 1, x). Further proceed by induction: let ψ(n −i, x) =
g(si +1, x) be the last value of ψ which was deﬁned. If ∃s > si(g(s+1, x) ̸=
g(s, x)), then let si+1 be the least such s.
Deﬁne ψ(n −(i + 1), x) =
g(si+1, x).
It is clear, that ψ is partial computable and (1) holds.
b) →a) In this direction the proof is straightforward.
c) →a) Let A be btt-reducible to the creative set K with norm n. This
means that for any x we can eﬀectively ﬁnd an n-place Boolean function
αx and a ﬁnite set Fx = {t1, t2, . . . , tn} such that x ∈A if and only if
αx(K(t1), . . . , K(tn)).
Deﬁne a computable function g as follows:
g(s, x) = α(Ks(x1), . . . , Ks(xn)).
Obviously, A(x) = lims g(s, x), and |{s|g(s + 1, x) ̸= g(s, x)}| ≤n.
a) →c) The proof of this part is similar to the proof of part c) →e) of
Theorem 3.9.
□
3.1.4. A description of the ∆0
2-sets using constructive ordi-
nals
The ω-c.e. sets are the ﬁrst examples of sets from inﬁnite levels of the
Ershov hierarchy. Later we will consider sets from other inﬁnite levels of
the hierarchy exhausting all ∆0
2-sets.
In what follows we use Kleene’s system of ordinal notations (O, <0)
(Kleene [43], see also Rogers [53]). Recall that if a ∈O then |a|0 denotes
the ordinal α, which has O-notation a.
On O a computable function +0 is deﬁned which for all x, y and z, has
the following properties:
a) x, y ∈O →x +0 y ∈O;
b) x, y ∈O & y ̸= 1 →x <0 x +0 y;
c) x, y ∈O →|x +0 y|0 = |x|0 + |y|0;

The Ershov Hierarchy
63
d) x ∈O & y <0 z ↔x +0 y <0 x +0 z.
Remark 3.1. In general, the relation y <0 x+0 y does not necessarily hold
for all x, y ∈O. But it follows from part c), that for all x, y ∈O such that
1 ≤0 x, we have the following: |y|0 ≤|x +0 y|0.
Deﬁnition 3.7. Let a, b ∈O and |a|0 = α, |b|0 = β. We say that a is
monotonically reducible to b (written a ⪯0 b), if there is a partial com-
putable function h such that {x : x <0 a} ⊆domh, ∀x <0 a(h(x) <0 b),
and
1) (∀c, d <0 a)(c <0 d ↔h(c) <0 h(d)), and
2) (∀d <0 a)(k0(d) = k0(h(d))),
where k0 is the partial computable function which is used in the deﬁnition
of O as a system of notations: then, for x ∈O, k0(x) = 0, if |x|0 = 0;
k0(x) = 1, if |x|0 is a successor; and k0(x) = 2, if |x|0 is a limit ordinal.
It is clear that the relation ⪯0 is reﬂexive and transitive, and for all
a, b ∈O, a ⪯0 b implies Σ−1
a
⊆Σ−1
b . Now the properties c) and d) of +0
stated above imply the following useful property of notations from O which
will be used in Theorem 3.19.
Proposition 3.1. For all x, y ∈O, y ⪯0 x +0 y.
Deﬁnition 3.8. Let S be a univalent system of notations for constructive
ordinals, let α be an ordinal which has an S-notation, and let Ψ be a partial
computable function and f a unary function. We write Ψ →{α,S} f, if for
all x ∈domf we have f(x) = Ψ(n, x), where n is a notation for the least
ordinal λ < α such that Ψ(n, x) ↓.
For simplicity in this case we will also write (cf. Theorems 3.9 and 3.10)
f(x) = Ψ((µλ< α)S(Ψ((λ)S, x) ↓), x).
Let α be an ordinal. The parity function on ordinals is deﬁned as follows:
α is an even ordinal if either it is 0 or a limit ordinal, or it is the successor
of an odd ordinal. Otherwise α is an odd ordinal. Therefore, if α is even
then α′ (the successor of α) is odd and vice versa.
In the system of notations S the parity function e(x) is deﬁned as fol-
lows: Let n ∈DS. Then e(n) = 1, if |n|S is an odd ordinal, and e(n) = 0,
if |n|S is an even ordinal.
Let α be an ordinal which has a notation a in a notation system S, i.e.
|a|S = α. Suppose that for a set A, a partial computable function Ψ and
for every x we have

64
M. M. Arslanov
A(x) = Ψ((µλ< α)S(Ψ((λ)S, x) ↓, x))
(1)
(in symbols Ψ →{α,S} A).
We deﬁne an a-sequence of c.e. sets {Rx} as follows: For every x <S a,
Rx =
[
y<Sx
Ry ∪
 {z|
∃t ⩽S x(Ψ(t, z) ↓= 1)}, if e(x) ̸= e(a);
{z|
∃t ⩽S x(Ψ(t, z) ↓= 0)}, if e(x) = e(a).
Clearly,
A = {z|∃x <S a(z ∈Rx & e(x) ̸= e(a) & ∀y <S x(z /∈Ry)}.
(2)
In particular, if α = ω this agrees with our previous description of ω-c.e.
sets via ω-sequences, and if α = n < ω (α is a natural number) with our
description of n-c.e. sets.
If a set A is deﬁned as in (2) using some α-sequence {Rx} such that
[
x<Sa
Rx = ω, then the converse claim also holds: The set A can be deﬁned
as in (1) for some partial computable function Ψ.
Indeed, let Ψ be the following function:
Ψ(x, z) =



1, if z ∈Rx, e(x) ̸= e(a);
0, if z ∈Rx, e(x) = e(a);
↑, otherwise.
Since
[
x<Sa
Rx = ω we have ∀z∃x(Ψ(x, z) ↓). Now it is easy to see that
A(x) = Ψ((µλ< α)S(Ψ((λ)S, x) ↓, x)).
Remark 3.2. Here the condition
[
x<Sa
Rx = ω is necessary, otherwise the
condition ∀z∃x(Ψ(x, z) ↓), which we need for (1), does not hold. It is easy
to see that in (2) the a-sequence {Rx} has this property.
We have proved the following:
Theorem 3.11. Let S be a univalent system of notations for construc-
tive ordinals, A ⊆ω and α an ordinal which has S-notation a. Then the
following are equivalent:
a) There is a partial computable function Ψ such that for every x,
A(x) = Ψ((µλ< α)S(Ψ((λ)s, x) ↓, x));

The Ershov Hierarchy
65
b) There is an a-sequence {Rx}x<sa such that
[
x<Sa
Rx = ω, and
A = {z|
∃x <S a(z ∈Rx & e(x) ̸= e(a) & ∀y <S x(z /∈Ry)}.
Theorem 3.11 generalizes the previously obtained descriptions of ω-c.e.
and n-c.e. sets for n < ω using ω-sequences and n-sequences of c.e. sets
respectively. Now we will show that any ∆0
2-set has such a description for
some a-sequence {Rx}, where a is a notation for some ordinal α in the
notation system S. Moreover, we will have that α ⩽ω2.
We ﬁrst prove that any set which can be so deﬁned using an a-sequence
{Rx} for some a ∈S, is a ∆0
2-set, i.e. these deﬁnitions do not take us out
of the class of ∆0
2-sets.
Theorem 3.12. Let S be a univalent and recursively related system of
notations, α a constructive ordinal which has a notation in S, Ψ a partial
computable function, and let f be a function such that Ψ →{α,S} f. Then
f ⩽T ∅′.
Proof.
Let x be a given integer. To ∅′-compute f(x) ﬁnd the ﬁrst (if
any) integer n such that Ψ(n, x) ↓. (If there is no such n, then f(x) ↑.)
Let Ψ(n, x) ↓for some n.
Using the oracle ∅′ ﬁnd (if it exists) an
integer m such that νS(m) < νS(n) and Ψ(m, x) ↓. This is possible since
S is recursively related. Now repeat the same, replacing n by m and so
on. Since the set α is well-ordered we will repeat this process only ﬁnitely
many times. Now let m be an integer such that νs(m) is the least ordinal
such that Ψ(m, x) ↓. We have f(x) = Ψ(m, x).
□
Theorem 3.13. Let f ⩽T ∅′ be a total function. There is a partial com-
putable function Ψ such that for every x,
f(x) = Ψ(|µλ< ω2|0(Ψ(|λ|0, x) ↓), x).
Proof.
Since O is a universal system of notations, it is enough to con-
struct a univalent and recursively related system of notations S and a partial
computable function Ψ such that for every x,
f(x) = Ψ((µλ< ω2)S(Ψ((λ)S, x) ↓), x).
Let f(x) = lims g(s, x) for all x and some computable function g.
Let
0 = sx
0 < sx
1 < . . . < sx
kx be all integers s, for which g(s, x) ̸= g(s + 1, x).
Therefore kx is the number of diﬀerent values of the function g on the set
of pairs {(s, x)|s ∈ω}.

66
M. M. Arslanov
Arrange all pairs (y, x) (or rather, the indices ⟨y, x⟩of these pairs) into
an ω2-sequence as follows:
Block 0











⟨s0
k0, 0⟩, ⟨s0
k0 + 1, 0⟩, ⟨s0
k0 + 2, 0⟩, . . ., ⟨s0
k0 + j, 0⟩, . . .
⟨s0
k0−1, 0⟩, ⟨s0
k0−1 + 1, 0⟩, ⟨s0
k0−1 + 2, 0⟩, . . ., ⟨s0
k0 −1, 0⟩
...........................................................................
⟨s0
1, 0⟩, ⟨s0
1 + 1, 0⟩, ⟨s0
1 + 2, 0⟩, . . . , ⟨s0
2 −1, 0⟩
⟨0, 0⟩, ⟨1, 0⟩, ⟨2, 0⟩, . . ., ⟨s0
1 −1, 0⟩
Block 1











⟨s1
k1, 1⟩, ⟨s1
k1 + 1, 1⟩, ⟨s1
k1 + 2, 1⟩, . . ., ⟨s1
k1 + j, 1⟩, . . .
⟨s1
k1−1, 1⟩, ⟨s1
k1−1 + 1, 1⟩, ⟨s1
k1−1 + 2, 1⟩, . . ., ⟨s1
k1 −1, 1⟩
...........................................................................
⟨s1
1, 1⟩, ⟨s1
1 + 1, 1⟩, ⟨s1
1 + 2, 1⟩, . . . , ⟨s1
2 −1, 1⟩
⟨0, 1⟩, ⟨1, 1⟩, ⟨2, 1⟩, . . ., ⟨s1
1 −1, 1⟩
............................................................................
.
Each i-th row (except the 0th) of the x-th block (0 ⩽x < ∞) is ﬁlled with
numbers ⟨sx
i , x⟩, ⟨sx
i + 1, x⟩, ⟨sx
i + 2, x⟩, . . . , ⟨sx
i+1 −1, x⟩, and the 0th row
consists of the inﬁnite sequence of numbers ⟨sx
kx + j, x⟩, j ⩾0. It is clear
that x-th block of this matrix contains all numbers ⟨j, x⟩, j ⩾0, without
repetition.
Now, for each x, we transform rows of the x-th block so that its i-th
row for each i ⩾0 (not only for i = 0) contains inﬁnitely many integers,
but nevertheless we still have the following conditions:
1) The ﬁrst element of the i-th row is the number ⟨sx
kx−i, x⟩,
2) Each block contains all natural numbers ⟨j, x⟩, j ⩾0 without repetition.
For this we ﬁll the rows of the x-th block as follows:
Sequen-
tially compute g(0, x), g(1, x), . . . and simultaneously ﬁll with numbers
⟨0, x⟩, ⟨1, x⟩, ⟨2, x⟩, . . . the positions of the last row from left to right un-
til we reach the number sx
1, for which we have g(sx
1 −1, x) ̸= g(sx
1, x). After
that we begin to ﬁll with numbers ⟨sx
1, x⟩, ⟨sx
1 + 1, x⟩, . . . simultaneously
from left to right positions of the last two rows until we reach the number
sx
2, for which we have g(sx
2 −1, x) ̸= g(sx
2, x). Then we ﬁll with numbers
⟨sx
2, x⟩, ⟨sx
2 + 1, x⟩, . . . simultaneously from left to right positions of the last
three rows: the third to last, second to last and last (in this order), until we
reach the number sx
3 and so on. Let us denote this process of enumerating
elements of the constructed matrix by M, and by ai,j the element of the
matrix which is in the j-th place of its i-th row.

The Ershov Hierarchy
67
Thus, inside each block we have ﬁnitely many rows of order type ω. It is
clear that for each pair (x, y) the number ⟨x, y⟩belongs to exactly one row
of the matrix. Deﬁne a linear ordering <ϕ on the elements of the matrix
as follows: ai,j <ϕ ak,l, if either i < k, or i = k, but j < l. Therefore, each
of the ω blocks has order type ω · n for some n ⩾1, and all the numbers in
the matrix give order type ω2.
Now we deﬁne a univalent system of notations S for ordinals < ω2 as
follows: We map, in an order-preserving way (and denoting this map as
νS) the integer ai,j to the ordinal ω · i + j, 0 ⩽i < ω: α < β if and only if
(α)S <ϕ (β)S.
To verify that S is a univalent system of notations, deﬁne computable
functions kS, pS and a partial computable function qS as follows:
kS(⟨s, x⟩) =



0, if s = s0
k0, x = 0;
2, if s = 0 ∨(s > 0 & g(s, x) ̸= g(s −1, x));
1, otherwise.
Obviously kS is a computable function, and if kS(x) = 0, then νS(x) =
0; if νS(x) a successor, then kS(x) = 1, and if νS(x) a limit ordinal then
kS(x) = 2.
We deﬁne the function pS(x) as follows: If l(x) ̸= sr(x)
i
for some
i ⩽kr(x), then pS(x) = ⟨l(x) −1, r(x)⟩.
It is clear that pS is a partial computable function, and if νS(x) is a
successor then pS(x) is deﬁned and νS(x) = νS(pS(x)) + 1.
To deﬁne the function qS consider the following two cases.
Case 1. x = ⟨n, 0⟩. (The number x belongs to the 0-th block of the ta-
ble.) Deﬁne qS(x) as an index of the following partial computable function
f: If n < s0
k0, then we sequentially compute values of g(n, 0), g(n+1, 0), . . .
until we obtain a number s > n such that g(s −1, 0) ̸= g(s, 0). (It is clear
that if n = s0
i for some i < k0 then s = s0
i+1.) Deﬁne f(t) = g(s + t, 0) for
all t ⩾0.
Case 2. x = ⟨n, m⟩, m > 0. (The number x belongs to the m-th nonzero
block.) In this case qS(x) is an index of the following partial computable
function f:
We deﬁne f(0), f(1), . . . sequentially as ⟨0, m −1⟩, ⟨1, m −
1⟩, ⟨2, m −1⟩, . . . (the subsequent elements of the last row of the (m −1)th
block) and simultaneously compute g(n, m), g(n+1, m), g(n+2, m), . . . un-
til we again obtain a number s > n such that g(s −1, 0) ̸= g(s, 0). (It is
clear that if n = sm
i for some i < km, then again s = sm
i+1.) After that, the

68
M. M. Arslanov
remaining values of the function f are deﬁned as the subsequent values of
the function g(s + t, m), t ⩾0.
It is easy to see that if νS(x) is a limit ordinal then qS(x) is deﬁned and
{νS(ΦqS(x)(n))}n∈ω is an increasing sequence whose limit is νS(x).
Obviously νS(x) < νS(y) if and only if either r(x) < r(y) or r(x) = r(y),
but then l(x) < l(y).
Therefore S is also recursively related system of
notations for ordinals.
Now let
Ψ(⟨s, y⟩, x) =
 g(s, x), if x = y;
↑,
otherwise.
Obviously, Ψ is a partial computable function and for every x,
f(x) = Ψ((µλ< ω2)S(Ψ((λ)S, x) ↓), x).
□
Since O is a universal system of notations, Theorems 3.11, 3.12, and
3.13 imply the following:
Corollary 3.1. For any set A ⊆ω, A ⩽T ∅′ if and only if there is an
a-sequence {Rx}x<0a, |a|0 ⩽ω2, such that
[
x<0a
Rx = ω, and
A = {z|
∃x <0 a(z ∈Rx & e(x) ̸= e(a) & ∀y <0 x(z /∈Ry)}.
Comment. Theorems 3.12 and 3.13 are due to Ershov [34]. In the proofs,
we have used an approach suggested by Epstein, Haas, and Kramer [32].
Theorem 3.11 is also from this work.
3.1.5. The inﬁnite levels of the Ershov hierarchy
Since |a|0 has order-type ⟨{x : x <0 a}, <0⟩, the sentence “a-sequence of
c.e. sets {Rx}” for a ∈O has to be understood in the sense of Deﬁnition
3.3. Deﬁne for a ∈O the operations Sa and Pa, which map a-sequences
{Rx}x<0a into subsets of ω as follows:
Sa(R) = {z|∃x <0 a(z ∈Rx & e(x) ̸= e(a) & ∀y <0 x(z /∈Ry))}.
Pa(R) = {z|∃x <0 a(z ∈Rx & e(x) = e(a) & ∀y <0 x(z /∈Ry))}
∪{ω −
[
x<0a
Rx}.

The Ershov Hierarchy
69
It follows from these deﬁnitions that Pa(R) = Sa(R) for all a ∈O and
all a-sequences R.
By deﬁnition the class Σ−1
a
(Π−1
a ) for a ∈O is the class of sets Sa(R)
(Pa(R), respectively), where R = {Rx}x<0a runs through all a-sequences
of c.e. sets. Let ∆−1
a
= Σ−1
a
∩Π−1
a .
It is easy to see that for natural numbers n > 0 and for a ∈O such that
|a|0 = ω these deﬁnitions coincide with the previous ones. (The ﬁnite levels
of the Ershov hierarchy are denoted by ordinals, not by their O-notations.)
Theorem 3.14. (Hierarchy Theorem) Let a, b ∈O and a <0 b.
Then Σ−1
a
∪Π−1
a
⊊Σ−1
b
∩Π−1
b .
Proof.
It follows immediately from the deﬁnitions of the classes of Σ−1
a -
and Π−1
a - sets that if a <0 b then Σ−1
a
∪Π−1
a
⊆Σ−1
b
∩Π−1
b . It is easy to see
that here all the inclusions are proper.
□
Corollary 3.2. For every a ∈O, Σ−1
a
⊊Σ0
2 ∩Π0
2.
Proof.
Suppose, for the sake of contradiction, that for some a ∈O we
have Σ−1
a
= Σ0
2 ∩Π0
2. Let b ∈O be a notation such that a <0 b. Then,
by Theorem 3.14, Σ−1
a
⊂Σ−1
b .
Therefore, Σ0
2 ∩Π0
2 = Σ−1
a
⊂Σ−1
b , a
contradiction.
□
Theorem 3.15. Let |a|0 be a limit ordinal. The set A belongs to the class
∆−1
a
if and only if there is an a-sequence R such that A = Sa(R) and
S
b<0a Rb = ω.
Proof.
(→) Let A ∈∆−1
a . Then A = Sa(R0) and ω −A = Sa(R1) for
a-sequences of c. e. sets R0 = {R0,x}x<0a and R1 = {R1,x}x<0a.
We deﬁne a new a-sequence P = {Px}x<0a as follows: If in {x | x <0 a}
x is a notation for a limit ordinal, then we deﬁne Px = R0,x, otherwise |x|0
is the successor of an ordinal |y|0 such that y <0 x. Deﬁne Px = R0,x∪R1,y.
Since A ⊆
[
x<0a
R0,x and ω −A ⊆
[
x<0a
R1,x, and for all y <0 a we
have the inclusions R0,y ⊆Py and R1,y ⊆Px, where y <0 x <0 a, we
concluded that
[
x<0a
Px = ω. The veriﬁcation of the condition A = Sa(P)
is straightforward.
(←) Now suppose that A = Sa(P) for some a-sequence P = {Px}x<0a,
suppose also that
[
x<0a
Px = ω. Deﬁne a new a-sequence R = {Rx}x<0a

70
M. M. Arslanov
as follows: R1 = ∅. Further, for an arbitrary x ∈O, 1 <0 x <0 a, we
set Rx = ∪y<0xRy, if x is a notation of a limit ordinal in {x | x <0 a}.
Otherwise, we set Rx = Py for some y <0 x such that |x|0 is a successor of
|y|0. Again it is easy to check that ω −A = Sa(R).
□
Theorem 3.11 now immediately implies the following:
Corollary 3.3. Let |a|0 be a limit ordinal. The set A belongs to the class
∆−1
a
if and only if there is a partial computable function Ψ such that for
every x,
A(x) = Ψ(|µλ< α|0(Ψ(|λ|0, x) ↓, x)).
The proof of the following theorem is similar to the proofs of Theorems
3.11 and 3.15:
Theorem 3.16. Let A ⊆ω and a ∈O. The following are equivalent:
a) A belongs to the class Σ−1
a ;
b) There is a partial computable function Ψ such that for every x, x ∈A
if and only if Ψ(|µλ< α|0(Ψ(|λ|0, x) ↓, x)).
Generalizing Deﬁnition 3.4 of the ω-c.e.
sets to inﬁnite ordinals we
introduce the following deﬁnition:
Deﬁnition 3.9. Let |a|0 be a limit ordinal. If A ∈∆−1
a , then the set A is
called an |a|0-c.e. set (or an α-c.e. set, if |a|0 = α).
It is clear that if A ∈Σ−1
a
for some a ∈O, and B ⩽m A, then B ∈Σ−1
a ,
and if A is |a|0-c.e. for some limit ordinal |a|0, a ∈O, and B ⩽m A, then
B is also |a|0-c.e. set.
The following theorem is a direct corollary of Theorems 3.11, 3.12 and
3.13.
Theorem 3.17.
[
a∈O
Σ−1
a
=
[
a∈O,|a|0=ω2
Σ−1
a
= Σ0
2 ∩Π0
2.
Theorem 3.17 cannot be strengthened:
Theorem 3.18.
[
a∈O,|a|0<ω2
Σ−1
a
̸= Σ0
2 ∩Π0
2.
Proof.
Let a, b ∈O be notations such that |a|0 = ω2, |b|0 < ω2. It is
easy to see that b ⪯0 a, which implies Σ−1
b
⊆Σ−1
a . Therefore, for each
a ∈O such that |a|0 ⩾ω2, we have
[
b∈O,|b|0<ω2
Σ−1
b
⊆Σ−1
a
⊂Σ0
2 ∩Π0
2.
□

The Ershov Hierarchy
71
Theorem 3.19. a) For any a ∈O there is a path T0 in O through a such
that
[
b∈T0
Σ−1
b
= Σ0
2 ∩Π0
2;
b) There is a path T in O such that |T |0 = ω3 and
[
a∈T
Σ−1
a
= Σ0
2 ∩Π0
2.
Proof.
a) Let a ∈O, and let {b0, b1, . . .} be a listing of all b ∈O such
that |b|0 = ω2. We deﬁne T0 as a path through c0, c1, c2, . . . , where c0 =
a,
c1 = a+0 b0,
c2 = (a+0 b0)+0 b1, . . . , cn = (. . . (a+0 b0)+0 . . .)+0 bn.
Obviously c0 <0 c1 <0 c2 <0 . . ., and the order type of T0 is |a|0 + ω3.
Since for each n < ω we have cn = d +0 bn for some d ∈O, and for all x, y,
y ⪯0 x+0 y (see Proposition 3.1), we have, for every n, that bn ⪯0 cn. Now
it follows from Theorem 3.17 that
[
b∈T0
Σ−1
b
= Σ0
2 ∩Π0
2.
b) Immediate by the preceding proof for a = 1.
□
The following claim shows that Theorem 3.19 b) cannot be strength-
ened:
Proposition 3.2. If a path T in O is such that |T |0 < ω3, then
[
a∈T
Σ−1
a
̸=
Σ0
2 ∩Π0
2.
Proof.
We ﬁrst prove the following:
Lemma 3.2. For any a ∈O,
[
a⩽0b,|b|0−|a|0<ω2
Σ−1
b
̸= Σ0
2 ∩Π0
2.
Proof of Lemma. Let d ∈O be a notation such that a ⩽0 d and |d|0 =
|a|0 + ω2. It is not diﬃcult to see that for every b ∈O such that a ⩽0 b and
|b|0 −|a|0 < ω2 we have b ⪯0 d. Therefore,
[
a⩽0b,|b|0−|a|0<ω2
Σ−1
b
⊆Σ−1
d
̸=
Σ0
2 ∩Π0
2.
□(of Lemma)
(Proof of Proposition 3.2 continued.) Since |T |0 < ω3, in T there is
an element a such that for some ordinal ρ < ω2 we have |T |0 = |a|0 + ρ.
Hence, if b ∈T and a ⩽0 b, then |b|0 −|a|0 < ω2. Therefore,
[
b∈T
Σ−1
b
⊆
[
a⩽0b,|b|0−|a|0<ω2
Σ−1
b .
Now it remains to apply the preceding lemma.
□
Comment. All results of this section are due to Ershov [34].

72
M. M. Arslanov
3.1.6. Levels of the Ershov hierarchy containing Turing
jumps
M. C. Faizrahmanov [36] has investigated the levels of the Ershov hierarchy
containing Turing jumps.
Not every level of the hierarchy contains the
Turing jump of a set. For instance, its ﬁnite levels contain Turing jumps
only of computable sets. Indeed, if A′ is n-c.e. and A is non-computable,
then there is a non-n-c.e. set B <T A. Therefore B′ ⩽1 A′. It follows that
B <1 A′ and, hence, B is an n-c.e. set, a contradiction.
Theorem 3.20. (M. C. Faizrahmanov) If A′ ∈Π−1
a
for a set A and a
notation a ∈O, then A′ ∈∆−1
a .
Proof.
As usual, we denote domΦA
e by W A
e
for every e ∈ω.
Here
{ΦA
e }e∈ω is the standard enumeration of all unary functions partial com-
putable in A.
Since ω −A′ ∈Σ−1
a , then it follows from Theorem 3.16 that there
is a partial computable function Ψ such that x ∈A′ if and only if
Ψ(|µλ< α|0(Ψ(|λ|0, x) ↓, x)) = 1. (In this case we also say that ω−A′ ∈Σ−1
a
with function Ψ.)
Let B = {x : ∃t ∈O(Ψ(t, x) ↓
& t <0 a)}. Obviously, B is c.e. and
A′ ⊆B. Let {Bs}s∈ω be an eﬀective enumeration of B. Since A is a ∆0
2-set,
there is a uniformly computable sequence {As}s∈ω such that A = lims As.
Let e be an integer that A′(x) = lims W As
e,s (x) for all x.
Now we deﬁne a set U c.e. in A. Using the Recursion Theorem we
initially ﬁx an index of U (in the enumeration {W A
e }e∈ω) and, therefore,
we can ﬁx a computable function f such that
(∀x){x ∈U ↔f(x) ∈A′}.
Stage s = 0. Set U0 = ∅.
Stage s > 0. Let (s)0 = i. If f(i) ∈Bs and ΦA
e,s(i) ↓, then enumerate i
into Us.
Let U = S
s Us.
For every i we have f(i) ∈B.
Indeed, suppose f(i) /∈B for some
i.
Then i /∈U and, therefore, f(i) ∈A′.
It follows that f(i) ∈B, a
contradiction.

The Ershov Hierarchy
73
Now we deﬁne a partial computable function Θ as follows:
Θ(t, x) =







0,
if Ψ(t, f(x)) ↓= 1;
1,
if Ψ(t, f(x)) ↓̸= 1;
↑,
if Ψ(t, f(x)) ↑.
It is clear, that the function Θ deﬁnes A′ as a ∆−1
a -set.
□
Theorem 3.21 is proved for the following natural system of notations
⟨DC, |.|C⟩for ordinals below ωω with its domain DC and the map |.|C :
DC →ωω.
DC = {x : ∃m, k0, . . . , km(x = ⟨m, k0, . . . , km⟩& m ̸= 0 →k0 ̸= 0)},
|⟨m, k0, . . . , km⟩|C = ωmk0 + ωm−1k1 + · · · + km.
In this theorem the levels of the Ershov hierarchy Σ−1
a , Π−1
a
and ∆−1
a
are
also deﬁned for a ∈C. It is clear that C is a univalent and recursively
related system and for simplicity, in what follows we identify ordinals with
their notations.
Let α and β be ordinals < ωω and
α = ωmp0 + ωm−1p1 + · · · pm,
β = ωmq0 + ωm−1q1 + · · · qm,
for some m, p0, . . . , pm, q0, . . . , qm.
The ordinal α(+)β deﬁned as
α(+)β = ωm(p0 + q0) + ωm−1(p1 + q1) + · · · (pm + qm)
is called the natural sum of α and β.
Theorem 3.21. (M. C. Faizrahmanov) Let A ⊂ω.
a) If n > 0 and A′ ∈Σ−1
ωn, then A′ ∈∆−1
ωn;
b) If m, n > 0 and A′ ∈Σ−1
ωnm, then A′ ∈∆−1
ωn;
c) For every n > 0 there is a set A such that A′ ∈∆−1
ωn+1 −∆−1
ωn.
Proof.
We present only part a) of the theorem. The proof of part b) is
based on part a) and uses induction on m. The proof of part c) is achieved
by means of a direct construction using a ﬁnite injury priority argument.
Let n > 0 and A′ ∈Σ−1
ωn. Deﬁne
S = {2x(2y + 1) : x ∈A′ & y ∈ω}.

74
M. M. Arslanov
It is clear that S recursively isomorphic to A′ and, therefore, there is
a partial computable function Ψ such that x ∈S if and only if (∃β <
ωn)(Ψ(β, x) ↓= 1 & (∀γ < β)(Ψ(γ, x) ↑) (i.e. Ψ deﬁnes S as a Σ−1
ωn-set).
Deﬁne a c.e. set B as follows: B = {x : ∃β < ωn(Ψ(β, x) ↓)}. Let
{Bs}s∈ω be a computable enumeration of B. Since A is a ∆0
2-set, there
is a uniformly computable sequence {As}s∈ω such that A = lims As. Let
S = lims W A
e [s] for some integer e.
Deﬁne for all x, i and s
r(x, i) = 2x3i,
q(x, i, s) = |{t < s : ΦA
e (r(x, i))[t] ̸= ΦA
e (r(x, i))[t + 1]}|,
p(x, i, s) = 3x5i+17q(x,i,s).
For each partial computable function Φn we deﬁne partial computable
functions hn
0 and hn
1 as follows:
Let hn
0,0 = hn
1,0 = ∅. Suppose that hn
0,s and hn
1,s are already deﬁned
and let i = min{k : hn
0,s(k) ↑}. Let x ⩽s be the least (if any) integer
such that Φn,s(r(x, i)) ↓∈Bs, Φn,s(p(x, i, s)) ↓∈Bs, and ΦA
e (r(x, i))[s] ↑.
If there is such x, then deﬁne hn
0,s+1 = hn
0,s ∪{(i, r(x, i))}, hn
1,s+1 = hn
1,s ∪
{(i, p(x, i, s))}. Otherwise, deﬁne hn
0,s+1 = hn
0,s, hn
1,s+1 = hn
1,s. Let hn
0 =
S
s hn
0,s, hn
1 = S
s hn
1,s. It follows from the deﬁnitions of hn
0 and hn
1 that
hn
0,s(i) ↓if and only if hn
1,s(i) ↓. Since the ranges of r and p are disjoint,
the ranges of values of hn
0 and hn
1 are also disjoint.
Now we construct set U c.e. in A. By the Recursion Theorem we can
initially ﬁx an index of U and, therefore, ﬁx a computable function f such
that x ∈U ↔f(x) ∈S. Let n be an integer such that f = Φn and denote
hk = hn
k, hk,s = hn
k,s for k = 0, 1.
Stage s = 0. Let U0 = ∅.
Stage s + 1 consists of two steps.
Step 1. Let i = µj(j /∈dom h0,s). For each x ⩽s,
(a) If ΦA
e (r(x, i))[s] ↓and As ↾ϕe(A, r(x, i))[s] = A ↾ϕe(A, r(x, i))[s],
then enumerate r(x, i) into Us+1;
(b) Let ˆr = max{ϕe(A, r(x, i))[t] : t ⩽s}.
If As ↾ˆr = A ↾ˆr, then
enumerate p(x, i, s) into Us+1.
Step 2. For each j ∈dom h0,s such that ΦA
e,s+1(j) ↓, enumerate h0,s(j),
h1,s(j) into Us+1.
Now let U = S
s Us. There are two possibilities:

The Ershov Hierarchy
75
Case 1. The function h0 is not total.
Let i = min{k : h0(k) ↑}. In this case for all x we have that
f(r(x, i)) ∈B →r(x, i) ∈S.
Indeed, suppose that f(r(x, i)) ∈B.
Since S = lims W A
e [s], there is a
stage s such that As ↾ˆr = A ↾ˆr, where ˆr is deﬁned as above. Moreover,
the stage s can be chosen so that this equality will be preserved at all
subsequent stages. Then for all t ⩾s we have p(x, i, t) ∈U and, therefore,
f(p(x, i, t)) ∈B.
Since h0(i) is undeﬁned, ΦA
e (r(x, i)) is deﬁned, which
means that r(x, i) ∈S.
It follows from part (a) of the construction that
{r(x, i) : r(x, i) ∈U} = {r(x, i) : r(x, i) ∈S}.
Therefore, if r(x, i) ∈S, then f(r(x, i)) ∈B and we have A′ ⩽1 B via
the reduction function g(x) = f(r(x, i)). This means that A′ is c.e. and,
therefore, A′ ∈∆−1
ωn.
Case 2. The function h0 is total.
It follows that h1 is also total. Let i ∈ω be an arbitrary integer and
s be the least stage such that h0,s+1(i) ↓.
By deﬁnition of h0 we have
ΦA
e (h0(i))[s] ↑.
Let s0 = min{t ⩽s : ∀s′ ∈[t, s](ΦA
e (h0(i))[s′] ↑) }.
Obviously, for all t ∈[s0, s) we have q(x, i, t) = q(x, i, t + 1).
Hence
h1(i) = p(x, i, s0). Also it is clear that p(x, i, s0) ̸∈Us0.
Now either h0(i) ̸∈Us+1, or h1(i) ̸∈Us+1.
Indeed, suppose that
h0(i) ∈Us+1. Then there is a stage t < s0 such that ΦA
e (h0(i))[t] ↓and
At ↾ϕe(A, h0(i))[t] = A ↾ϕe(A, h0(i))[t]. Since for all u ∈[s0, s] we have
ΦA
e (h0(i))[u] ↑, we also have for all u ∈[s0, s], Au ↾ˆh ̸= A ↾ˆh, where
ˆh = max{ϕe(A, h0(i))[v] : v ⩽s0}. Therefore, p(x, i, s0) ̸∈Us+1. Now step
2 of the construction ensures that
∀i(i ∈S ↔(f(h0(i)) ∈S & f(h1(i)) ∈S)).
(1)
Now we deﬁne a function Θ, which deﬁnes S as a ∆−1
ωn-set.
Let Ψs
denote the part of the function Ψ deﬁned at the end of stage s.
For a given i ﬁnd a stage v and ordinals β0, β1 < ωn such that
Ψv(β0, f(h0(i))) ↓and Ψv(β1, f(h1(i))) ↓. (Such ordinals β0 and β1 ex-
ist, since by construction for all j we have {f(h0(j)), f(h1(j))} ⊂B.)
Deﬁne a partial computable function Θ0 so that
Θ0(β0(+)β1, i) = Ψv(β0, f(h0(i))) · Ψv(β1, f(h1(i))).

76
M. M. Arslanov
Now suppose that a partial computable function Θs is already deﬁned
and for k ∈{0, 1} let γk = µδ(Ψv+s(δ, f(hk(i)) ↓). Deﬁne a partial com-
putable function Θs+1 so that
Θs+1(γ0(+)γ1, i) = Ψv+s(γ0, f(h0(i))) · Ψv+s(γ1, f(h1(i))).
Let Θ = S
s Θs. To show that Θ deﬁnes S as a ∆−1
ωn-set, take an arbitrary
integer x and let αk = µβ(Ψ(β, f(hk(x))) ↓), k = 0, 1. Then α0(+)α1 =
µγ(Θ(γ, x) ↓).
Since α0 and α1 are below ωn, α0(+)α1 < ωn.
Now it
follows from (1) that
S(x) = Ψ(α0, f(h0(x))) · Ψ(α1, f(h1(x))) = Θ(α0(+)α1, x).
This means that A′ ∈∆−1
ωn.
□
3.2. The Turing Degrees of the n-c.e. Sets
3.2.1. The class of the n-c.e. degrees
The ﬁrst results on the Turing degrees of the sets from diﬀerent levels
of the Ershov hierarchy were obtained in 1970’s of the last century when
S.B. Cooper in his dissertation (Cooper [16]) proved the existence of a
Turing degree which contains a 2-c.e. set, but does not contain c.e. sets
(below such degrees are called properly 2-c.e.
degrees), and A.H. Lachlan
(unpublished) proved that for any n > 1 below any properly n-c.e. degree
there is a non-computable c.e. degree. These two results show that the
class of n-c.e. degrees for n > 1 diﬀers from the class of c.e. degrees as well
as from the class of degrees below 0′: By Lachlan’s above-mentioned result
no n-c.e. degree can be minimal while there are minimal degrees below
< 0′.
These results provoked a certain interest among mathematicians and
became the starting point for the investigation of properties of the n-c.e.
degrees. Generalizing Cooper’s theorem, M.Lerman and L. Hay established
that for any n > 1 there are (n + 1)-c.e. degrees c and d such that the
interval {b| c ⩽b ⩽d} does not contain n-c.e. degrees. They also noted
that combining Cooper’s proof with the permitting method, one can con-
struct below any non-computable c.e.
degree a properly 2-c.e.
degree.
Further, R.A. Shore and L. Hay combined Cooper’s method with Sacks’s
coding technique to construct a properly 2-c.e.
degree above any given
T-incomplete c.e. degree. (These results are not published, they are men-
tioned in Epstein, Haas, and Kramer [32].)

The Ershov Hierarchy
77
More active investigations toward the development of the structural
theory of the n-c.e. (mainly the 2-c.e.) degrees began after publications by
Arlsanov [5, 6], and Downey [26]. In these papers the authors prove that
the elementary theories of the semilattices of c.e. degrees and n-c.e. degrees
are diﬀerent. M.M. Arslanov proved that for any n ⩾1 and for any n-c.e.
degree a > 0 there exists a 2-c.e. degree d < 0′ such that a∪d = 0′. Earlier
S.B. Cooper and C.E.M. Yates (unpublished, see Miller [50]) independently
proved that this result fails in the c.e.
degrees.
This shows that these
theories are diﬀerent at the Σ0
3-level. R.G. Downey proved that the four-
element lattice ♦which is also called the diamond lattice, is embeddable into
the 2-c.e. degrees preserving 0 and 0′ (earlier Lachlan [44] had proved that
this is impossible in the c.e. degrees). Therefore, these theories are diﬀerent
also at the Σ0
2-level (at the Σ0
1-level they coincide, which easily follows from
Lachlan’s above-mentioned result on the n-c.e.
degrees).
In his paper
Downey also stated his famous conjecture on the elementarily equivalence
of the semilattices of n- and m- c.e. degrees for n ̸= m, n, m > 1.
At present the structural theory of the n-c.e. degrees is worked out fairly
well. Most important results obtained in this area of research in the past
forty years are (in addition to the above-mentioned results of Arslanov and
Downey) the proof of the non-density of the ordering of the n-c.e. degrees
for any n > 1 (Cooper, Harrington, Lachlan, Lempp, and Soare [21]), the
recent work of Arslanov, Kalimullin, and Lempp [11] on the non-elementary
equivalence of the semilattices of 2-c.e. and 3-c.e. degrees, the work of Yang
and Yu [59], where it is proved that in the signature {⩽} the c.e. degrees
do not form a Σ1-substructure of the n-c.e. degrees for any n ⩾2, and
a series of papers by Cooper, Li, Yi, and Ishmukhametov, in which the
authors investigated the splitting properties of the n-c.e. degrees for the
diﬀerent n ⩾1.
But a whole number of natural and important questions still remain
open. First of all there is the problem of deﬁnability of the c.e. degrees
in the ordering of the n-c.e. degrees for n > 1 (in a more general setting
the question on deﬁnability of the m-c.e. degrees in the orderings of n-
c.e. degrees for 1 ⩽m < n), the problem on the elementary equivalence
of the structures of n-c.e. degrees for diﬀerent n > 2, the decidability of
the restricted fragments of theories of these structures, in particular the
problem of the decidability of the ∃∀-theory of the 2-c.e. degrees.
Deﬁnition 3.10. A Turing degree a is n-computably enumerable (an n-c.e.
degree), if it contains some n-c.e. set; an n-c.e. degree a is properly n-c.e.
degree, if it contains no m-c.e. sets for any m < n.

78
M. M. Arslanov
The set of all n-c.e. degrees we denote by Dn, the class of all Turing
degrees by D, and the set of all Turing degrees below 0′ by D(⩽0′) . Dω
denotes the set of all ω-c.e. degrees. We have
D0 ⊊D1 ⊊D2 ⊊. . . ⊊Dω ⊊D(⩽0′).
Theorem 3.22. (Lachlan, unpublished) Let a be a properly n-c.e. degree
for some n > 1. There are degrees a1, a2 . . . , an such that 0 < a1 < . . . <
an = a and for every m, 1 < m ⩽n, am is c.e. in am−1, and a1 is a
properly c.e. degree. In particular, below any n-c.e. degree a > 0 there is
a non-computable c.e. degree.
Note that in this theorem we don’t require that every am, 1 < m < n,
must be a properly c.e. degree. It will follow from Corollary 3.5 that if a3 is
a properly 3-c.e. degree then a2 also must be a properly d-c.e. degree. We
don’t know whether this is true for any n > 3. Probably, not. An indirect
argument toward this conjecture is Theorem 3.29.
Theorem 3.22 allows us to transfer some properties of the c.e. degrees
to the case of the n-c.e. degrees for n > 1. We demonstrate this in the
following two examples.
It follows from Lachlan’s non-diamond theorem, Lachlan [44], that there
are no
c.e.
degrees, except
0 and 0′, which have complements in the
c.e. degrees. (By a complement of a c.e. degree a we mean a degree b such
that a ∪b = 0′ and a ∩b = 0. It is clear that 0 and 0′ are complements
to each other.) Later in Theorem 3.44 we show that this result does not
hold in the n-c.e. degrees for any n > 1, but it easily follows from Theorem
3.22 that a similar result holds in case of the n-c.e. degrees in the following
weaker formulation.
Theorem 3.23. For every n > 1 there is a n-c.e. degree which has no
complement.
Proof.
Let a > 0 be a c.e. degree such that a ∩b ̸= 0 for any c.e. degree
b > 0 (Yates [60]). If there is an n-c.e. degree b > 0 such that a ∩b = 0,
then by Theorem 3.22 we have a ∩c = 0 for some c.e. degree c > 0, a
contradiction.
□
Further, it follows from Theorem 3.22 that if a pair (d0, d1) is a minimal
pair of degrees in D2 then there is a pair (a0, a1) of c.e. degrees minimal
in R such that a0 < d0 and a1 < d1.
Therefore, Lachlan’s theorem

The Ershov Hierarchy
79
(Lachlan [46]) on the existence of a c.e. degree a > 0 such that there is no
minimal pair of c. e. degrees below a immediately gives the following:
Theorem 3.24. There is a non-computable c.e. degree such that below it
there is no minimal pair of d-c.e. degrees.
In Epstein [31] by a permitting argument below any given c.e. degree
a > 0 a minimal degree is constructed. Obviously, any such construction
produces an ω-c.e. set. Therefore, we have the following:
Theorem 3.25. For every c.e. degree a > 0 there is a minimal ω-c.e.
degree m < a.
3.2.2. The degrees of the n-c.e. sets in the n-CEA hierarchy
It follows from Theorem 3.22 that the hierarchy of the n-c.e. sets is closely
connected with the hierarchy of n-CEA (n-computably enumerable and
above) sets, which was ﬁrst deﬁned and studied in Arslanov [2, 4], and
Jockusch and Shore [40, 41].
Deﬁnition 3.11. The c.e. sets are 1-CEA sets. Further by induction, a
set A is an (n + 1)-CEA set for some n ≥1 if it is c.e. in an n-CEA set
B ⩽T A. Furthermore, if a set A c.e. in a set B ⩽T A, then A is called a
B-CEA set. A degree a is an n-CEA degree for some n ⩾1, if it contains
an n-CEA set.
By Theorem 3.22 every n-c.e. set is also an n-CEA set. The converse,
obviously, does not hold: For instance, the n-th jump of any c.e. set is
also an n-CEA set. Moreover, the hierarchy of the n-c.e. degrees does not
coincide with the hierarchy of the n-CEA degrees even among the degrees
below 0′:
Theorem 3.26. There is a 2-CEA degree a < 0′, which is not an ω-c.e.
degree.
Proof.
Let d < 0′ be a d-c.e. degree such that the interval (d, 0′) does
not contain ω-c.e. degrees (see Theorem 3.48 below). By Theorem 3.22 d
is CEA(a) for some c.e. degree a ⩽d, and by the Sacks Density Theorem
(relativized to a) there is a degree b c.e. in a such that d < b < 0′. By
choice of d, the degree b is not ω-c.e.
□
The following theorem asserts that, conversely, for any n > 1 there are
n-c.e. degrees, which are not (n −1)-CEA degrees.

80
M. M. Arslanov
Theorem 3.27. (Arslanov [4], Jockusch and Shore [41]) Let n > 1. There
is an n-c.e. set D such that the degree of D does not contain (n −1)-CEA
sets.
Theorem 3.28. (Arslanov, LaForte, and Slaman [12]) Let C be an ω-c.e.
set and let A be a c.e. set. If C ⩽T A ⊕W A, then there is a d-c.e. set D
such that C ⩽T D ⩽T A ⊕W A.
Notice that the d-c.e. set D constructed in the above theorem is itself
c.e. in A as a set, rather than merely being of A-c.e. degree.
Corollary 3.4. If C is ω-c.e., A is c.e., and the degree of C is A-CEA,
then there exists a d-c.e. set D which is itself c.e. in A as a set such that
C ≡T D.
Proof.
Take C ≡T A ⊕W A in the previous theorem. Then D ⩽T C, so
C ≡T D.
□
Theorem 3.28 immediately yields the following:
Corollary 3.5. Any ω-c.e. degree which is 2-CEA is also d-c.e.
It is natural to assume that a similar result holds for all n in the sense
that the n-c.e. and the n-CEA degrees agree on the ω-c.e. degrees. But
this is not true:
Theorem 3.29. (Arslanov, LaForte, and Slaman [12]) There exists a d-
c.e. set D such that, for every n ⩾3, there exists a set An which is simul-
taneously D-CEA and (n + 1)-c.e., yet fails to be of n-c.e. degree.
Now we turn to the discussion of the following question which has a
long history: Let a < 0′ be a non-computable c.e. degree. Is there a degree
b < 0′ CEA in a such that b is not c.e.? The following result is due to
Soare and Stob [57], and it is the ﬁrst result in this direction.
Theorem 3.30. Let a be a non-computable c.e. degree such that a′ = 0′.
Then there is a non c.e. degree b > a c. e. in a.
In Arslanov, Lempp, and Shore [14] we answer this question negatively
in the following very strong form:
Theorem 3.31. There is an incomplete non-computable c.e. set A such
that every set CEA in A and computable in 0′ is of c.e. degree.

The Ershov Hierarchy
81
On the other hand, in this paper, we also obtain the following result in
the positive direction:
Theorem 3.32. Let c < h be c.e. degrees such that c is low and h is high.
Then there is a degree a < h such that a is CEA in c.
Soare and Stob [57] also claimed that a modiﬁcation of their strate-
gy for a low a would make b 2-c.e. They have since withdrawn this claim
(personal communication) but Theorems 3.30 and 3.32 suggest the following
conjecture:
Conjecture 3.1. For every low c.e. degree a > 0 there is a d-c.e. degree
b CEA in a which is not c.e.
Unfortunately, we did not succeed in answering this question. The only
results we obtained in this direction are Theorems 3.33, 3.34 and 3.35.
Theorem 3.33. (Arslanov, Lempp, and Shore [14]) For all high c.e.
de-
grees h < g there is a properly d-c.e.
degree a such that h < a < g and a
c.e.
in h.
Theorem 3.34. (Arslanov, Lempp, and Shore [14]) There is a c.e. degree
a, 0 < a < 0′, such that for any degree b > a c.e. in a, if b ⩽0′ then b is
c.e.
Now suppose c is a low, non-computable c.e. degree and a the degree
CEA in c constructed by Soare and Stob [57].
Let C ∈c be a c.e. set and a set A ∈a c.e. in C, A ⩾T C. Let Φ be a
p.c. functional such that A = dom ΦC. Since c is low there is a computable
function g such that ΦC(x) ↓if and only if lims g(s, x) = 1, and ΦC(x) ↑if
and only if lims g(s, x) = 0.
Let us construct a d-c.e. set V which is c.e. in C:
For each x, wait for a stage s such that ΦC(x)[s] ↓and g(s, x) = 1.
Enumerate < x, 0 > into V
and wait for a stage t > s such that
Ct⌈ϕ(C, x)[s] ̸= Cs⌈ϕ(C, x)[s] and g(t, x) = 0, then remove ⟨x, 0⟩from
V . Wait for a stage s′ such that again ΦC(x)[s′] ↓with a new value of
ϕ(C, x)[s′] and g(s′, x) = 1, then put ⟨x, 1⟩into V , and so on.
Obviously, V is a d-c.e. set c.e. in C such that V ⩽T C ⊕A.
Now, if in addition C′ is ω-c.e. (and, therefore, by Theorem 3.9 C′ ≤tt
∅′) then there are computable functions f and g such that for all x, C′(x) =
lims g(s, x) and
|{s : g(s + 1, x) ̸= g(s, x)}| ⩽f(x).

82
M. M. Arslanov
In this case we have A ⩽T C ⊕V : To compute A(x) ﬁnd some i ⩽f(x)
such that < x, i >∈V . If there is no such i then x ̸∈A, if there is some
such i then x ∈A.
Therefore, if C′ is an ω-c.e. set then C ⊕A ≡T C ⊕V , and the degree
a CEA in c from Soare and Stob [57] is itself d-c.e., without an additional
construction. Recall that a set A is called superlow if A′ ≡tt ∅′. A degree
is superlow if it contains a superlow set. Therefore, we have the following:
Theorem 3.35. Let a > 0 be a superlow degree. Then there is a properly
d-c.e. degree d > a such that d is c.e. in a.
3.2.3. The relative arrangement of the n-c.e. degrees
In this section we study the relative arrangement of degrees from ﬁnite
levels of the Ershov hierarchy. We begin with the following theorem which
generalizes an unpublished result of R. Shore and L. Hay and can be proved
similarly to Cooper’s proof of the existence of a properly n-c.e. degree.
Theorem 3.36. For all n > 1 there are n-c.e. sets V <T U such that
between degrees V and U there are no (n −1)-c.e. degrees.
The assertion of the following theorem is wrong if n = 1 (see Theorem
3.55 below).
Theorem 3.37. For all n > 1, if a is a properly (n + 1)-c.e. degree, then
there is an n-c.e. degree b < a such that between b and a there are no c.e.
degrees.
Proof.
Let n > 1 and let A be an (n + 1)-c.e. set of properly (n + 1)-c.e.
degree. By Theorem 3.22 there is an n-c.e. set ˜A such that A is an ˜A-CEA
set. Obviously, ˜A <T A. Suppose that ˜A ⩽T W <T A for some c.e. set W.
Then A is a W-CEA set and, therefore, 2-CEA. But then by Corollary 3.5
the degree of A is d-c.e., a contradiction.
□
Suppose that in Theorem 3.36 one of the sets U >T ∅or V <T ∅′ is
ﬁxed. It is natural to ask the following question: Is there another set such
that the claim of Theorem 3.36 still holds? In general the answer to this
question is unknown. But:
Theorem 3.38. (R. Shore and L. Hay, unpublished) There is, for instance,
a d-c.e. set V of low degree such that between V and ∅′ in Turing reducibil-
ity there are no c.e. sets.

The Ershov Hierarchy
83
The properly n-c.e. degrees are situated dense enough among the de-
grees ≤0′, in particular, between any two c.e. degrees a < b there is a
properly n-c.e. degree, for any n > 1. For the case n = 2 this is proved in
Cooper, Lempp, and Watson [22], the proof for n > 2 is similar.
Theorem 3.39. Let V <T U be c.e. sets. There exists a d-c.e. set D such
that V <T D <T U and ∀x(Wx ̸≡T D).
Is it possible in Theorem 3.39 to make the degree of D c.e. in V ? This
question has been extensively studied. It follows from Theorem 3.34 that
in general it is impossible even if U = ∅′. Can we do that if V ′ ≡T U = ∅′?
This is an open question (see Conjecture 3.1 above).
Theorem 3.40. (Cooper and Yi [25] for n = 2; Arslanov, LaForte, and
Slaman [12] for n > 2) For any c.e. degree x and any n-c.e. degree y, if
x < y then x < z < y for some d-c.e. degree z.
Proof.
For n = 1 this is the Sacks Density Theorem, and for n = 2 this
is Theorem 3.55, part (iii). For n > 2 use an induction argument: Assume,
that the theorem is proved for m-c.e. sets for all m ⩽n and let B be
an (n + 1)-c.e. set, n > 1, and let A <T B be a c.e. set. There is an
n-c.e. set ˜B ⩽T B, in which B is c.e. Then the set A ⊕˜B is also n-c.e.
If A <T A ⊕˜B, then, by assumption, there is a d-c.e. set C such that
A <T C <T A ⊕˜B ⩽T B. If A ≡T A ⊕˜B, then the (n + 1)-c.e. set B is
c.e. in A and, therefore, by Corollary 3.5 the degree of B is d-c.e. Now the
claim follows from the case n = 2.
□
3.2.4. The cupping, capping and density properties
We begin with the following
Theorem 3.41. (Arslanov [5, 6]) Let a > 0 be an n-c.e. degree for some
n > 2. Then there is a d-c.e. degree d < 0′ such that a ∪d = 0′.
Since there is a non-computable c.e. set A such that A ⊕U <T ∅′ for
every c.e. set U <T ∅′ (Cooper, Yates, unpublished, see Miller [50]), it
follows from Theorem 3.41 that for every n ⩾2, the structures Dn and R
are not elementarily equivalent at the Σ3-level.
Generalizing Theorem 3.41 Cooper, Lempp, and Watson [22], proved
the following,
Theorem 3.42. If a > 0 is a c.e.
degree and h > a is a high c.e. degree
then there is a d-c.e. degree b < h such that a ∪b = h.

84
M. M. Arslanov
In turn Harrington (see Miller [50]) strengthened the above mentioned
result of Cooper and Yates replacing 0′ by an arbitrary high c.e.
degree.
Therefore, for every n ⩾2 and any high c.e.
degree h, the structures
Dn(⩽h) and R(⩽h) are also non-elementarily equivalent at the Σ0
3-level.
Further, Arslanov and Cooper (unpublished, see Arslanov [8] for the case
h = 0′) generalized Theorem 3.42 in the following way:
Theorem 3.43. Let h be a high c.e. degree, a < h and b < h arbitrary
non-computable c.e. degrees. Then there is a d-c.e. degree d < h such that
h = a ∪d = b ∪d.
As we already mentioned, the diamond lattice is not embeddable into
the c.e. degrees preserving 0 and 0′. Downey [26], proved that in the n-c.e.
degrees such an embedding is possible for any n, n ⩾2.
Theorem 3.44. There are incomparable d-c.e. degrees a and b such that
a ∪b = 0′ and a ∩b = 0.
Therefore, for every n ⩾2, the structures Dn and R are not elementarily
equivalent at the Σ2-level.
One can try to strengthen the Diamond Theorem 3.44 in several direc-
tions. First of all the following natural question arises: Is it possible in
this theorem to replace the degrees 0 and 0′ by arbitrary c.e.
degrees
a and b, a < b, respectively?
Further, it follows from Lachlan’s non-
diamond theorem, (Lachlan [44]), that in Theorem 3.44 at least one of the
d-c.e. degrees a or b cannot be c.e. Can we make one of these degrees
c.e.? Finally, Theorem 3.44 states that there is a non-trivial d-c.e. degree
d which has a complement in D2. (A degree c is a complement for d if
d ∪c = 0′ and d ∩c = 0.) A natural question asks: Which degrees in D2
have complements?
The ﬁrst question is connected with a general question on the decom-
posability of a c.e.
degree a over a given c.e.
degree b ⩽a into two
incomparable d-c.e. degrees, i.e. on the existence of incomparable d-c.e.
degrees c0 and c1 such that c0 > b, c1 > b and a = c0∪c1. (It follows from
Lachlan’s non-splitting theorem (Lachlan [45]) that in R such an assertion
does not hold for a = 0′ and some c.e. degree b > 0.)
A negative answer to the ﬁrst question was obtained by Kaddah [42]:
Theorem 3.45. In D2 below any c.e. degree a > 0 there is a c.e. degree
b ⩽a non-branching in d-c.e. degrees. (A degree a is branching, if there
are degrees b > a and c > a such that b ∩c = a.)

The Ershov Hierarchy
85
Therefore, there is, for instance, a low c.e. degree l > 0 such that the
diamond lattice is not embeddable between degrees 0′ and l, preserving l
as its least element.
The answer to the second question turned out to be positive. It follows
from the next theorem:
Theorem 3.46. (Li and Yi [49]) There are incomparable d-c.e. degrees
a0 and a1 such that for every n-c.e. degree x > 0, either a0 ∪x = 0′, or
a1 ∪x = 0′.
Corollary 3.6. There are a c.e. degree a > 0 and a d-c.e.
degree b > 0
such that a ∪b = 0′ and a ∩b = 0.
Proof.
Let a0 and a1 be as in Theorem 3.46. It is clear that a0 ∩a1 = 0.
Let d > 0 be an arbitrary d-c.e.
degree. Suppose for deﬁniteness that
d ∪a0 = 0′. If d ∩a0 ̸= 0, then there exists a c.e. degree b > 0 such that
b ⩽d and b ⩽a0. Since a0 ∩a1 = 0, b ∩a1 = 0. Since b ∪a0 = a0, we
have b ∪a1 = 0′ by Theorem 3.46. Therefore, the desired pair of degrees
is either d and a0, or b and a1.
□
Theorem 3.47. (Jiang [39]) For any high degree h there is a c.e.
set
H ∈h such that in Theorem 3.44 the set ∅′ can be replaced by H.
This result can be also obtained using Cooper’s proof in Cooper [17]
where below any high c.e. degree a minimal pair of c.e. degrees is con-
structed. On the other hand, it follows from Theorem 3.24 that not every
c.e. degree a > 0 in D2 is the top of a diamond lattice.
The ordering of the n-c.e. degrees is not dense for any n > 1:
Theorem 3.48. (Cooper, Harrington, Lachlan, Lempp, and Soare [21])
There is a d-c.e.
degree d < 0′ such that there are no ω-c.e.
degrees b
such that d < b < 0′.
For the class of 2-low n-c.e. degrees with n > 1 we have another picture:
Theorem 3.49. (Cooper [18]) For every n > 1 the partial ordering of
the
2-low n-c.e.
degrees is dense. Moreover, if b < a are 2-low n-c.e.
degrees, then there are n-c. e.
degrees a0 and a1 such that a = a0 ∪a1
and b < a0, a1.
Theorem 3.48 states that there is a maximal d-c.e. degree. But there are
no maximal low d-c.e. degrees (Arslanov, Cooper and Li [9, 10]). Jiang [39]
strengthened Theorem 3.48 establishing:

86
M. M. Arslanov
Theorem 3.50. For any n ≥1, above any low n-c.e. degree there is a
maximal d-c.e. degree.
On the other hand,
Theorem 3.51. (Yi, unpublished, see Cooper [20]) There is a high c.e.
degree h < 0′ such that below h there are no maximal d-c.e. degrees.
It follows from this theorem that the semilattices D2 and D2(⩽h) are
not elementarily equivalent.
Theorem 3.49 leaves open the question on the elementary equivalence
of the semilattices of the low2 c.e. and the low2 d-c.e. degrees. So far we
have no example which would distinguish these two semilattices.
3.2.5. Splitting properties
Let a > 0 be a properly n-c.e.
degree for some n > 1, and let b be
a c. e.
degree such that b < a.
Since a is c.e.
in some (n −1)-c.e.
degree a0 < a (Theorem 3.22), it follows from the Sacks Splitting Theorem,
relativized to a0 ∪b < a, that a is splittable into two ∆0
2-degrees which
are above b, i.e. there are ∆0
2-degrees c0 and c1 such that c0 ∪c1 = a and
b < c0 < a, b < c1 < a. It turns out that such a splitting is possible also
in the d-c.e. degrees.
Theorem 3.52. (Cooper and Li [23]) Any d-c.e.
degree a > 0 is non-
trivially splittable in D2 over any c.e. degree b < a.
Since the ordering of the d-c.e. degrees is non-dense, it follows that
in Theorem 3.52 we cannot replace the c.e. degree b by a d-c.e. degree.
Moreover, it follows from Theorem 3.48 that in general, this is impossible
even if a is a c.e. degree. However,
Theorem 3.53. (Arslanov, Cooper, and Li [9, 10]) Any c.e.
degree is
splittable in the d-c.e. degrees over any low d-c.e. degree.
It follows from Theorem 3.49 that the properties of density and splitting
can be combined in the low2 n-c.e. degrees. In the class of the low2 c.e.
degrees this result also holds (Shore and Slaman [55]). These and some
other similarities between the low2 c.e. and the low2 n-c.e. degrees for n > 1
suggest the following conjecture (Downey and Stob [28]):
Conjecture 3.2. The ordering of the low2 n-c.e. degrees is elementarily
equivalent to the ordering of the low2 c. e. degrees.

The Ershov Hierarchy
87
For the low3 n-c.e. degrees Cooper and Li [23] proved the following:
Theorem 3.54. For any n > 1, there is a low3 n-c.e. degree a and a c.e.
degree b, 0 < b < a, such that for any splitting of a into n-c.e. degrees a0
and a1, at least one of the degrees a0 or a1 is above b.
(In this case we say that a is not splittable avoiding the upper cone of
degrees above b.)
Since in R such a splitting of the low3 c.e. degrees is possible, it follows
that elementary theories of these two semilattices are diﬀerent.
3.2.6. Isolated d-c.e. degrees
Cooper and Yi [25] deﬁned the notion of an isolated d-c.e. degree. A d-c.e.
degree d is isolated by a c.e. degree a < d (we also say “a isolates d”), if
for any c.e. degree b, b ⩽d implies b ⩽a. Cooper and Yi [25] established
the following results about such degrees:
Theorem 3.55. (i) There exists an isolated d-c.e. degree;
(ii) There exists a non-isolated properly d-c.e. degree;
(iii) Given any c.e. degree a and any d-c.e. degree d > a, there is a
d-c.e. degree e between a and d.
Theorem 3.56. a) (LaForte [47], and Arslanov, Lempp, and Shore [13])
Given any two comparable c.e. degrees v < u, there exist an isolated d-c.e.
degree c and a non-isolated d-c.e. degree d between them.
b) (Arslanov, Lempp, and Shore [13]) There is a non-computable c.e.
degree a such that a does not isolate any degree b > a which is c.e. in a.
The following two results show that the c.e.
degrees a not isolating
any d-c.e. degree d which is CEA in a are widely distributed in the c.e.
degrees.
Theorem 3.57. (Arslanov, Lempp, and Shore [13]) a) For every non-
computable c.e.
degree c, there is a non-computable c.e.
degree a ⩽c
which isolates no degree CEA in it;
b) If c is a degree c.e. in 0′, then there is a c. e.
degree a, a′ = c,
which isolates no degree CEA in it.
Suppose that a c.e.
degree a isolates a d-c.e.
degree d > a.
Since
between a and d there are no c.e. degrees except a, then one might think
that the degrees a and d are situated “close enough” to each other. But it

88
M. M. Arslanov
follows from Theorem 3.58 that this is not true (if we agree that the high
degrees are situated “close” to 0′, and the low degrees are situated ”close”
to 0).
Theorem 3.58. (Ishmukhametov and Wu [38]) There are a high d-c.e.
degree d and a low c.e. degree a < d such that a isolates d.
The following result is due to Wu [58]. It can easily be derived from
known results and is an interesting generalization of the idea of isolated
degrees.
Theorem 3.59. There are d-c.e. degrees a < b such that there is exactly
one c.e. degree c between them. Moreover, the degree b can be included
into any given interval of high c.e. degree u and v, u < v.
Proof.
Let u and v, u < v, be high c.e. degrees. Between u and v there
is an isolated d-c.e. degree b (LaForte [47]). Let c < b be a c.e. degree
which isolates b. It is easy to see that u ⩽c, otherwise the c.e. degree
u ∪c contradicts the choice of b. Therefore, since the degree u is high,
the degree c is also high. It is known (Cooper [20]) that for any high c.e.
degree, in particular for the degree c, there exists a c.e. degree d < c, such
that for every c.e. degree x < c we have x∪d < c. Also, in Cooper, Lempp,
and Watson [22] it is proved that for any high c.e. degree, in particular
for the degree c, and for any nonzero c.e. degree below it, in particular for
the degree d, there exists a d-c.e. degree a < c such that a ∪d = c. It
follows that between a and c there are no c.e. degrees. (Since for any such
c.e. degree x we would have x ∪d = c, which contradicts the choice of d.)
Therefore, the c.e. degree c is the unique c.e. degree between a and b. □
3.2.7. A generalization
There are several ways to generalize the notion of isolated d-c.e. degrees.
Some of them can be found in Efremov [29, 30] and Wu [58]. Here we
consider the following common generalization.
Deﬁnition 3.12. Let A and B be classes of sets such that A ⊆B. By
deﬁnition, a set A ∈A isolates a set B ∈B, if A <T B and for any set
W ∈A, W ⩽T B →W ⩽T A. In this case we also say that the set B is
A-isolated by the set A. A Turing degree b is A-isolated, if it contains an
A-isolated set.

The Ershov Hierarchy
89
In particular, if A is the class of m-c.e. degrees, and B is the class of
n-c.e. degrees, m < n, then we obtain the notion of a n-c.e. degree which
is isolated by some m-c.e. degree, and of an m-c.e. degree, which isolates
some n-c.e. degree. (It is clear that if n = 2 and m = 1 this deﬁnition
coincides with the Cooper/Yi deﬁnition of isolated degrees.)
Deﬁnition 3.13. Let A and B be two classes of sets such that A ⊆B, and
let A, B ∈B. We deﬁne a relation A ⩽{A,B} B on B by
A ⩽{A,B} B if and only if for any set W ∈A we have W ⩽T A implies
W ⩽T B.
If here A is the class of all m-c.e. sets and B is the class of all n-c.e. sets
for some 1 ⩽m ⩽n, then instead of A ⩽{A,B} B we write A ⩽{m,n} B.
If in this deﬁnition A = B, then we obtain the usual notion of Turing
reducibility. In particular, for any n ⩾1, A ⩽{n,n} B if and only if A ⩽T B.
Also, it is obvious that for all A ⊆B, A, B ∈B,
1) A ⩽T B →A ⩽{A,B} B;
2) A ⩽{A,B} B, B ⩽{A,B} C →A ⩽{A,B} C.
We call the corresponding equivalency classes the {A,B}-degrees.
It
follows from 1), that every {A,B}-degree is a collection of possibly several
Turing degrees.
These deﬁnitions are naturally connected with the notion of isolated
degrees. For instance, if a c.e. degree a isolates a d-c.e. degree b, then
this means that b ⩽{1,2} a. Therefore, a ={1,2} b, i.e. all isolated d-c.e.
degrees and their isolating c.e. degrees belong to the same {1,2}-degree.
Cooper and Yi’s theorem on the existence of an isolated d-c.e. degree d
now means that there exists a {1,2}-degree, which contains a c.e. degree
and a non c.e. d-c.e. degree. On the other hand, the existence of a non-
isolated d-c.e. degree means that there exists a {1,2}-degree, which contains
a d-c.e. degree and does not contain c.e. degrees. Theorem 3.66 states that
there exists a {1,2}-degree which consists of a single c.e. degree. Theorem
3.55, part (iii) states that no c.e. degree d-c.e.-isolates a d-c.e. degree (on
the class of all d-c.e. degrees). Similarly, Theorem 3.40 states that no c.e.
degree d-c.e.-isolates any n-c.e. degree, for any n > 1.
Below, we will deal with the classes of d-c.e. sets and {1,2}-degrees.
It is clear that each {1,2}-degree contains at most one c. e. degree and, in
general, may contain several d-c.e. degrees. As usual, we call a {1,2}-degree
as a c.e. {1,2}-degree if it contains a c.e. degree.

90
M. M. Arslanov
The following theorem states that each c.e. {1,2}-degree either does not
contain any non c.e. d-c.e. degree or contains inﬁnitely many such degrees.
Theorem 3.60. Any c.e.
{1,2}-degree either consists of a single c.
e.
degree or contains an inﬁnite descending chain of non c.e. d-c.e. degrees.
Proof.
Let a c.e.
{1,2}-degree contain a c.e. set A and a d-c.e. set D,
which is not T-equivalent to any c.e. sets. Since A ≡{1,2} D, A <T D
and A isolates D.
By Theorem 3.55 there is a d-c.e.
set C such that
A <T C <T D. It is easy to see that the set A also isolates C, therefore
A ≡{1,2} C ≡{1,2} D. Now we repeat the same argument with A and C
instead of A and D and so on.
□
It is easy to see that the c.e.
{1,2}-degrees form an upper semilattice
where the least upper bound for the {1,2}-degrees of c.e. sets A and B is
the degree of the set A ⊕B. Indeed, if A ⩽{1,2} C and B ⩽{1,2} C for
some set C then we have A ⩽T C and B ⩽T C, otherwise the c.e. sets A
and B refute the {1,2}-reducibility of A and B to C, accordingly. Therefore,
A⊕B ⩽T C and, hence, A⊕B ⩽{1,2} C. We don’t know, whether the {1,2}-
degrees of the d-c.e. sets form an upper semilattice. In general, the join
operator A ⊕B does not give the least upper bound for the {1,2}-degrees of
sets A and B. (This can be easily proved by a routine ﬁnite injury priority
argument.)
Theorem 3.61. For each n ⩾2 there exists a {1,2}-degree, which contains
at least n incomparable Turing degrees.
Proof.
The proof is a direct generalization of the proof of Theorem 3.55,
part (i).
□
Theorem 3.62 states that there are no maximal {1,2}-degrees among the
low2 degrees.
Theorem 3.62. Let D be a d-c.e. set such that D′′ ≡T ∅′′. Then there is
a c.e. set A such that D <{1,2} A <{1,2} ∅′.
Proof.
It is enough to consider only the case when the degree of D is not
computably enumerable. Otherwise, since a ⩽b implies a ⩽{1,2} b, the
theorem follows from the Sacks Density Theorem.
The following lemma is proved in Arslanov [3] (see also Soare [56, The-
orem XII.5.1]).

The Ershov Hierarchy
91
Lemma 3.3. For any function ψ which is computable in ∅′′, there is a
computable function g such that Wg(e) ≡T Wψ(e) for all e.
Let S = {⟨i, j⟩| Wi = ΦD
j }. It is easy to see that S ∈ΠD
2 , therefore S is
computable in D′′ ≡T ∅′′, i.e. S ⩽T ∅′′. Now we deﬁne a function g ⩽T ∅′′:
Wg(⟨i,j⟩) =
(
Wi,
if⟨i, j⟩∈S;
∅,
otherwise.
Since g is a total function and g ⩽T ∅′′, by Lemma 3.3 there exists a com-
putable function f such that Wf(⟨i,j⟩) ≡T Wg(⟨i,j⟩). Let E = ⊕1⩽k<∞Wf(k).
Since for any k ∈ω we have Wf(k) ⩽T D and the degree of D does not con-
tain c.e. sets, the set E is computably enumerable and ∀n{D ̸⩽T E[<n] ≡T
⊕1⩽k⩽nWf(k)}.
By Shoenﬁeld’s Thickness Lemma (see Soare [56, Lemma VIII.1.1])
there is a c.e. set A ⩽T E such that A is a thick subset of E (i. e. A ⊆E,
and A[e] =∗E[e]), D ̸⩽T A. (We denote by X =∗Y that (X −Y )∪(Y −X)
is ﬁnite, and let X[e] = {⟨x, e⟩: ⟨x, e⟩∈X} be the e-th section of X.)
We have Wi = ΦD
j
implies Wi ≡T E[⟨i,j⟩] =∗A[⟨i,j⟩], i.e. Wi ⩽T D
implies Wi ⩽T A.
There are the following two possibilities:
1) A ⩽T D. Then A isolates D. Let B be an arbitrary c.e. set such
that A <T B <T ∅′. We have D <{1,2} B <{1,2} ∅′.
2) A ̸⩽T D. Then, obviously, D <{1,2} A <{1,2} ∅′.
□
Remark 3.3. Analyzing this proof we can see that we have proved a
slightly stronger result. For instance, let D be a d-c.e. set such that its
degree is not computably enumerable and there is a computable function f
with the following properties:
a) Wf(e) ⩽T D for any e ∈ω;
b) (∀e ∈ω)(We ⩽T D →(∃x ∈ω)[We ⩽T Wf(x)]).
Then, deﬁning the set E again as ⊕1⩽k<∞Wf(k) and repeating the con-
struction of the set A, we obtain that D <{1,2} A <{1,2} ∅′. Moreover, if we
have d-c.e. sets D1 and D2 such that D1 <{1,2} D2, and if for the set D1
there is a computable function f with properties a), b), and the additional
property E ⩽T D2, then, again repeating the previous argument we obtain
that D1 <{1,2} A <{1,2} D2 for some c.e. set A.

92
M. M. Arslanov
3.2.8. Further results and open questions
The following questions are the main open questions on the arrangement
of the n-c.e. degrees for various n ⩾1:
• Is the relation “x is c.e.” deﬁnable in Dn for each n ⩾2? Are there
non-trivial ﬁnite sets of c.e. degrees deﬁnable in Dn? (For an inﬁnite
deﬁnable set of c.e. degrees see Corollary 3.11 below.)
• Is the relation “x is m-c.e.” deﬁnable in Dn for each pair n, m, n >
m ⩾2?
• Are {Dm, <} and {Dn, <} elementarily equivalent for each n ̸=
m, m, n ⩾2 ? (For the case m = 2, n = 3 see Corollary 3.10 below.)
• Are there n ̸= m, m, n ⩾1, such that Dm(a, b) is elementarily equiva-
lent to Dn(a, b) for some c.e. degrees a < b?
• Are there numbers n > m ⩾1 such that {Dm, <} is a Σ1-substructure
of {Dn, <}?
An investigation of the problems listed above is driven by the need to
better understand the level of the structural similarity of the classes of
c.e. and n-c.e. degrees for diﬀerent n > 1, as well as of the level of the
homogeneity for the notion of c.e. with respect to n-c.e. degrees in the
sense of the level of the similarity of orderings of the c.e. degrees and of
the n-c.e. degrees which are CEA in some d.
a) Elementary equivalence.
We ﬁrst consider questions on the elementary equivalence.
Theorem 3.63. (Arslanov, Kalimullin, and Lempp [11]) There are 2-c.e.
degrees d and e such that 0 < d < e and for any 2-c.e. degree u < e either
u ⩽d or d ⩽u.
Theorem 3.64. (Arslanov, Kalimullin, and Lempp [11]) For all c.e. de-
grees x and 2-c.e. degrees d and e such that both d, e are c.e. in x and
0 < x < d < e, there is a 2-c.e. degree u c.e. in x such that x < u < e
and d|u.
The following theorem is a reﬁnement of Theorem 3.63.
Theorem 3.65. a) In Theorem 3.63 the degree d is necessarily c.e. and
b) for each 2-c.e. degree e there is at most one c.e. degree d < e with this
property.

The Ershov Hierarchy
93
Proof.
By Theorem 3.22 the degree e is c.e. in a c.e. degree b < e. If
b > d, then by the Sacks Splitting Theorem we split b into two c.e. degrees
b0 and b1 avoiding the upper cone of d (avoiding d, for short). At least
one of these degrees must be incomparable with d, a contradiction.
If b < d, then consider the c.e. degree c = b ∪a, where a < d is a c.e.
degree such that d is c.e. in a. Obviously, c ⩽d. If c < d then we obtain
a contradiction with Theorem 3.64, since both the 2-c.e. degrees e and d
are c.e. in c. Therefore, d = c. Similar arguments prove also the second
part of the theorem.
□
Corollary 3.7. (of Theorem 3.65). There are no strong minimal covers in
the 2-c.e. degrees.
Proof.
Indeed, if b is a strong minimal cover for a, then by Theorem
3.65, a is c.e. and, therefore, by Theorem 3.55 there is a d-c.e.
degree
strictly between a and b.
□
Corollary 3.8. (of Theorem 3.65). There are no 2-c.e. degrees f > e >
d > 0 such that for any u,
(i) if u ⩽f then either e ⩽u or u ⩽e, and
(ii) if u ⩽e then either d ⩽u or u ⩽d.
Proof.
If there are such degrees f > e > d > 0 then by Theorem 3.65 the
degree e is c.e. and by the Sacks Splitting Theorem is splittable avoiding
d which is a contradiction.
□
Question 3.1. Are there 3-c.e. degrees f > e > d > 0 with this property?
Obviously, an aﬃrmative answer to this question refutes the elementary
equivalence of D2 and D3.
Though this question still remains open, we can weaken a little this prop-
erty of degrees (d, e, f) to carry out the mission imposed to these degrees
to refute the Downey’s Conjecture. We consider triples of non-computable
n-c.e. degrees {(d, e, f) | 0 < d < e < f} with the following (weaker) prop-
erty: For any n-c.e. degree u,
(i) if u ⩽f then either u ⩽e or e ⩽d ∪u, and
(ii) if u ⩽e then either d ⩽u or u ⩽d.
(In the ﬁrst line the former condition e ⩽u was replaced by a weaker
condition e ⩽d ∪u.)

94
M. M. Arslanov
We still have the following corollary from Theorems 3.63 and 3.64:
Corollary 3.9. There are no 2-c.e. degrees f > e > d > 0 such that for
any 2-c.e. degree u,
(i) if u ⩽f then either u ⩽e or e ⩽d ∪u, and
(ii) if u ⩽e then either d ⩽u or u ⩽d.
Proof.
Suppose that there are such degrees f > e > d > 0. Let f1 ⩽f
and e1 ⩽e be c.e.
degrees such that f and e are c.e.
in f1 and e1,
respectively. Consider the degree x = d ∪e1 ∪f1. Obviously, d ⩽x ⩽f.
By Theorem 3.65 the degree x is c.e. and e ̸< x, otherwise x is splittable
in the c.e. degrees avoiding e, which is a contradiction. Also x ̸= e, since in
this case we can split x avoiding d, which is again a contradiction. Finally, if
x ̸⩽e then it follows from condition (i) that e ⩽d∪x = x, a contradiction.
Therefore, x < e. Since f and e are both c.e. in x, it follows now from
Theorem 3.64 that there is a 2-c.e. degree u such that x < u < f and u|e,
a contradiction.
□
Theorem 3.66. (Arslanov, Kalimullin, and Lempp [11]) There are a c.e.
degree d > 0, a 2-c.e. degree e > d, and a 3-c.e. degree f > e such that
for any 3-c.e. degree u,
(i) if u ⩽f then either u ⩽e or e ⩽d ∪u, and
(ii) if u ⩽e then either d ⩽u or u ⩽d.
Corollary 3.10. D2 ̸≡D3 at the Σ2- level.
Theorems 3.63 and 3.66 raise a whole series of new questions, study of
which could lead to the better understanding of the inner structure of the
ordering of the n-c.e. degrees. Below we consider some of these questions.
Deﬁnition 3.14. Let n > 1. An (n+1)-tuple of degrees a0, a1, . . . an−1, an
forms an n-bubble in Dm for some m ⩾1, if 0 = a0 < a1 < a2 < . . . <
an−1 < an, ak is k-c.e. for each k, 1 ⩽k ⩽n, and for any m-c.e. degree u,
if u ⩽ak then either u ⩽ak−1 or ak−1 ⩽u.
An (n+1)-tuple of degrees a0, a1, a2, . . . an−1, an forms a weak n-bubble
in Dm for some m ⩾1, if 0 = a0 < a1 < a2 < . . . < an−1 < an, ak is k-c.e.
for each k, 1 ⩽k ⩽n, and for any m-c.e. degree u, if u ⩽ak then either
u ⩽ak−1 or ak−1 ⩽u ∪ak−2.
Obviously, every n-bubble is also an n-weak bubble for every n > 1, but
we don’t know if the reverse holds. Theorem 3.63 and Corollary 3.8 state
that in the 2-c.e. degrees there are 2-bubbles and there are no n-bubbles

The Ershov Hierarchy
95
(and even that there are no n-weak bubbles), for every n > 2. Theorem 3.66
states that in the 3-c.e. degrees there are 3-weak bubbles. Questions on the
existence of n-bubbles (and even on n-week bubbles) in the n-c.e. degrees
for n > 3, and on the existence of the n-bubbles in the m-c.e. degrees for
2 < m < n are open.
Conjecture 3.3. For every n, 1 < n < ω, Dn contains an n-bubble, but
does not contain m-bubbles for any m > n. (As we already saw this is true
for n = 2.)
Obviously, if this conjecture holds for some n > 1 then this means that
Dn is not elementarily equivalent to Dm, m > n.
b) Deﬁnability.
Deﬁnition 3.15. (Cooper and Li [23]). A Turing approximation to the
class of the c.e. degrees R in the n-c.e. degrees is a Turing deﬁnable class
Sn of n-c.e. degrees such that
(i) either R ⊆Sn (in this case we say that Sn is an approximation to R
from above), or
(ii) Sn ⊆R (Sn is an approximation to R from below).
Obviously, R is deﬁnable in the n-c.e. degrees if and only if there is a
Turing deﬁnable class Sn of n-c.e. degrees which is a Turing approximation
to the class R in the n-c.e. degrees simultaneously from above and from
below.
There are a number of known nontrivial Turing approximations from
above to the class of the c.e. degrees in the n-c.e. degrees. For instance,
such an approximation can be obtained from Theorem 3.55 (iii).
A nontrivial Turing approximation from below can be obtained from
Theorems 3.1 and 3.65. Consider the following set of c.e. degrees: S2 =
{0} S{x > 0|(∃y > x)(∀z)(z ⩽y →z ⩽x ∨x ⩽z)}. It follows from
Theorem 3.65 that
Corollary 3.11. S2 ⊆R and S2 ̸= {0}.
Therefore, S2 is a nontrivial approximation from below to the class of
the c.e. degrees R in the class of the d-c.e. degrees. A small additional
construction in Theorem 3.63 allows to achieve that S2 contains inﬁnitely
many c.e. degrees.

96
M. M. Arslanov
Since each non-computable c.e. degree d from S2 isolates some d-c.e.
degree e, it follows from Theorem 3.57 that S2 does not coincide with the
class of all c.e. degrees.
Open Question. Is there for every pair of c.e. degrees a < b a degree
c ∈S2 such that a < c < b (i.e. S2 is dense in R)?
An aﬃrmative answer to this question implies deﬁnability of R in D2
as follows: Given a c.e. degree a > 0 we ﬁrst split a into two incomparable
c.e. degrees a0 and a1, then using the density of S2 in R ﬁnd between a
and ai, i ⩽1, a c.e. degree ci, i ⩽1, such that a = c0 ∪c1. This shows
that in this case a nonzero 2-c.e. degree is c.e. if and only if it is the least
upper bound of two incomparable 2-c.e. degrees from S2.
Conjecture 3.4. Each c.e. degree a > 0 is the least upper bound of two
incomparable degrees from S2 and, therefore, the class of the c.e. degrees is
deﬁnable in D2.
Question 3.2. Is R deﬁnable in D2?
Is Dm deﬁnable in Dn for some
1 < m < n?
c) Σ1-substructures.
There are only a few known results in this direction.
(T. Slaman, unpublished) The partial ordering of the n-c.e. degrees is
not a Σ1-substructure of {D(⩽0′), <}.
(Yang and Yu [59]) The structure {R, <} is not a Σ1-substructure of
{D2, <}.
In Theorem 3.66 we have a c.e.
degree d > 0 and a 2-c.e.
degree
e > d such that every 3-c.e. degree u ⩽e is comparable with d. Can this
condition be strengthened in the following sense: there are a c.e. degree
d > 0 and a 2-c.e. degree e > d such that every n-c.e. degree ⩽e for
every n < ω is comparable with d?
Question 3.3. Are there a c.e. degree d > 0 and a 2-c.e. degree e > d
such that for any n < ω and any n-c.e. degree u ⩽e either u ⩽d or
d ⩽u?
An aﬃrmative answer to this question would reveal an interesting pro-
perty of the ﬁnite levels of the Ershov diﬀerence hierarchy with far-reaching
consequences. From other side, if the question has a negative answer, then

The Ershov Hierarchy
97
let d > 0 and e > d be a c.e. degree and a 2-c.e. degree, respectively,
and let n ⩾3 be the greatest natural number such that every n-c.e. degree
u ⩽e is comparable with d and there is an (n+1)-c.e. degree v ⩽e which
is incomparable with d. Now consider the following Σ1-formula:
ϕ(x, y, z) ≡∃u(x < y < z & u ⩽z & u ̸⩽y & y ̸⩽u).
Let d and e be degrees and n be the integer whose existence is assumed
by the negative answer to the previous question. Then we have Dn+1 |=
ϕ(0, d, e), and Dn |= ¬ϕ(0, d, e), which means that in this case Dn is not
a Σ1-substructure of Dn+1. This is a well-known open question.
We see that an answer to this question in either direction leads to very
interesting consequences.
All sentences known so far in the language of partial ordering, which
are true in the n-c.e. degrees and false in the (n + 1)-c.e. degrees for some
n ⩾1, belong to the level ∀∃or to a higher level of the arithmetic hierarchy.
This and some other observations allow us to state the following plausible
conjecture:
Conjecture 3.5. For any n ⩾1 and for any ∃∀-sentence ϕ, Dn |= ϕ →
Dn+1 |= ϕ.
(The ∃∀-theory of the n-c.e.
degrees is a subtheory of the
∃∀-theory of the (n + 1)-c.e. degrees.)
How many parameters are needed in formulas which are witnesses in
the proof that D1 is not a Σ1-substructure of D(⩽0′) and D2?
• Slaman’s result (R ̸⪯Σ1 D(0′): 3 parameters;
• Yang and Yu (R ̸⪯Σ1 D2): 4 parameters.
Question 3.4. Can these numbers be reduced?
References
[1] J. W. Addison. The method of alternating chains. In Theory of Models, pp.
1–16, North–Holland, Amsterdam, (1965).
[2] M. M. Arslanov, Weakly recursively enumerable sets and limiting com-
putability, Ver. Metodi i Kibernetika. 15, 3–9, (1979).
[3] M. M. Arslanov, On some generalizations of the ﬁxed-point theorem, Sov.
Math. 228, 9–16, (1981).
[4] M. M. Arslanov, On a hierarchy of degrees of unsolvability, Ver. Metodi i
Kibernetika. 18, 10–18, (1982). (In Russian).

98
M. M. Arslanov
[5] M. M. Arslanov, Structural properties of the degrees below 0′, Dokl. Nauk.
SSSR. pp. 270–273, (1985).
[6] M. M. Arslanov, On the upper semilattice of Turing degrees below 0′, Sov.
Math. 7, 27–33, (1988).
[7] M. M. Arslanov, Completeness in the arithmetical hierarchy and ﬁxed-
points, Algebra and Logic. 28, 3–17, (1989).
[8] M. M. Arslanov. Degree structures in the local degree theory. In ed. A. Sorbi,
Complexity, Logic, and Recursion Theory 187, Lecture Notes in Pure and
Applied Mathematics, pp. 49–74. Marcel Dekker, New York, (1997).
[9] M. M. Arslanov, S. B. Cooper, and A. Li, There is no low maximal d.c.e.
degree, Math. Logic Quart. 46, 409–416, (2000).
[10] M. M. Arslanov, S. B. Cooper, and A. Li, There is no low maximal d.c.e.
degree – corrigendum, Math. Logic Quart. 50, 628–636, (2004).
[11] M. M. Arslanov, I. Sh. Kalimullin, and S. Lempp, On Downey’s conjecture,
J. Symbolic Logic. 75, 401–441, (2010).
[12] M. M. Arslanov, G. L. LaForte, and T. A. Slaman, Relative recursive enu-
merability in the diﬀerence hierarchy, J. Symbolic Logic. 63, 411–420, (1998).
[13] M. M. Arslanov, S. Lempp, and R. A. Shore. On isolating r.e. and isolated
d-r.e. degrees. In London Math. Soc. Lect. Note Series, vol. 224, pp. 41–80.
Cambridge University Press, (1996).
[14] M. M. Arslanov, S. Lempp, and R. A. Shore, Interpolating d-r.e. and REA
degrees between r.e. degrees, Ann. Pure Appl. Logic. 78, 29–56, (1996).
[15] H. G. Carstens, ∆0
2-mengen, Arch. Math. Log. Grundlag. 18, 55–65, (1978).
[16] S. B. Cooper, Degrees of Unsolvability, Ph. D. Thesis, Leicester University,
Leicester, England, (1971).
[17] S. B. Cooper, Minimal pairs and high recursively enumerable degrees, J.
Symbolic Logic. 39, 655–660, (1974).
[18] S. B. Cooper, The density of the low2 n-r. e. degrees, Arch. Math. Logic. 30
(1), 19–24, (1991).
[19] S. B. Cooper, A splitting theorem for the n-recursively enumerable degrees,
Proc. Amer. Math. Soc. 115, 461–472, (1992).
[20] S. B. Cooper. Local degree theory. In ed. E. R. Griﬀor, Handbook of Com-
putability Theory, pp. 121–153. Elsevier, Amsterdam, New York, Tokyo,
(1999).
[21] S. B. Cooper, L. A. Harrington, A. H. Lachlan, S. Lempp, and R. I. Soare,
The d.r.e. degrees are not dense, Ann. Pure Appl. Logic. 55, 125–151, (1991).
[22] S. B. Cooper, S. Lempp, and P. Watson, Weak density and cupping in the
d-r.e. degrees, Israel J. Math. 67, 137–152, (1989).
[23] S. B. Cooper and A. Li, Turing deﬁnability in the Ershov hierarchy, Journal
of London Math. Soc. 66(2), 513–526, (2002).
[24] S. B. Cooper and A. Li, Splitting and cone avoidance in the d.c.e. degrees,
Science in China (Series A). 45, 1135–1146, (2002).
[25] S. B. Cooper and X. Yi. Isolated d-r.e. degrees. Preprint Series 17, University
of Leeds, Dept. of Pure Math., (1995).
[26] R. G. Downey, D-r.e. degrees and the nondiamond theorem, Bull. London
Math. Soc. 21, 43–50, (1989).

The Ershov Hierarchy
99
[27] R. G. Downey, A. Li, and G. Wu, Complementary cappable degrees in the
diﬀerence hierarchy, Ann. Pure Appl. Logic. 125, 101–118, (2004).
[28] R. G. Downey and M. Stob, Splitting theorems in recursion theory, Ann.
Pure Appl. Logic. 65, 1–106, (1993).
[29] A. A. Efremov, Isolated from above d-r.e. degrees, I, Sov. Math. 2, 20–28,
(1998).
[30] A. A. Efremov, Isolated from above d-r.e. degrees, II, Sov. Math. 7, 18–25,
(1998).
[31] R. L. Epstein, Minimal Degrees of Unsolvability and the Full Approximation
Construction, 162, Memoirs Amer. Math. Soc., Amer. Math. Soc., Provi-
dence, R.I, (1975).
[32] R. L. Epstein, R. Haas, and R. L. Kramer. Hierarchies of sets and degrees
below 0′. In eds. M. Lerman, J. H. Shmerl, and R. I. Soare, Logic Year
1979–80, 859, Lecture Notes in Mathematics, pp. 32–48, Springer–Verlag,
Heidelberg, Tokyo, New York, (1981).
[33] Yu. L. Ershov, A hierarchy of sets, I, Algebra and Logic. 7, 47–73, (1968).
[34] Yu. L. Ershov, A hierarchy of sets, II, Algebra and Logic. 7, 15–47, (1968).
[35] Yu. L. Ershov, A hierarchy of sets, III, Algebra and Logic. 9, 34–51, (1970).
[36] M. C. Faizrahmanov. Turing jumps in the Ershov hierarchy. to appear in
Algebra and Logic (2010).
[37] E. M. Gold, Limiting recursion, J. Symbolic Logic. 30(1), 28–48, (1965).
[38] S. Ishmukhametov and G. Wu, Isolation and the high/low hierarchy, Arch.
Math. Logic. 41, 259–266, (2002).
[39] Z. Jiang, Diamond lattice embedded into d.r.e. degrees, Science in China
(Series A). 36, 803–811, (1993).
[40] C. G. Jockusch, Jr. and R. A. Shore, Pseudo-jump operators I: The r.e. case,
Trans. Amer. Math. Soc. 275, 599–609, (1983).
[41] C. G. Jockusch, Jr. and R. A. Shore, Pseudo-jump operators II: Transﬁnite
iterations, hierarchies, and minimal covers, J. Symbolic Logic. 49, 1205–1236,
(1984).
[42] D. Kaddah, Inﬁma in the d.r.e. degrees, Ann. Pure Appl. Logic. 62, 207–263,
(1993).
[43] S. C. Kleene, On notation for ordinal numbers, J. Symbolic Logic. 3, 150–
155, (1938).
[44] A. H. Lachlan, Lower bounds for pairs of recursively enumerable degrees,
Proc. London Math. Soc. 16, 537–569, (1966).
[45] A. H. Lachlan, A recursively enumerable degree which will not split over all
lesser ones, Ann. Math. Logic. 9, 307–365, (1975).
[46] A. H. Lachlan, Bounding minimal pairs, J. Symbolic Logic. 44, 626–642,
(1979).
[47] G. LaForte, The isolated d.r.e degrees are dense in the r.e. degrees, Math.
Log. Quarterly. 42, 83–103, (1996).
[48] A. Li, G. Wu, and Y. Yang, Bounding computable enumerable degrees in
the Ershov hierarchy, Ann. Pure Appl. Logic. 141, 79–88, (2006).
[49] A. Li and X. Yi, Cupping the recursively enumerable degrees by d.r.e. de-
grees, Proc. London Math. Soc. 78(3), 1–21, (1999).

100
M. M. Arslanov
[50] D. Miller. High recursively enumerable degrees and the anticupping prop-
erty. In eds. M. Lerman, J. H. Schmerl, and S. R. I., Logic Year 1979–80:
University of Connecticut, 859, Lecture Notes in Mathematics, pp. 230–245,
Springer–Verlag, Berlin, Heidelberg, Tokyo, New York, (1981).
[51] H. Putnam, Trial and error predicates and the solution to a problem of
Mostowski, J. Symbolic Logic. 30(1), 49–57, (1965).
[52] R. W. Robinson, Interpolation and embedding in the recursively enumerable
degrees, Ann. of Math. 93, 285–314, (1971).
[53] H. Rogers, Jr., Theory of Recursive Functions and Eﬀective Computability.
McGraw-Hill, New York, (1967).
[54] J. R. Shoenﬁeld, On degrees of unsolvability, Ann. of Math. 69, 644–653,
(1959).
[55] R. A. Shore and T. A. Slaman, Working below a low2 recursively enumerable
degree, Ann. Pure Appl. Logic. 52, 1–25, (1990).
[56] R. I. Soare, Recursively Enumerable Sets and Degrees. Perspectives in Math-
ematical Logic, Omega Series, Springer–Verlag, Berlin, Heidelberg, (1987).
[57] R. I. Soare and M. Stob. Relative recursive enumerability. In ed. J. Stern,
Proceedings of the Herbrand Symposium, Logic Colloquium 19881, pp. 299–
324, North–Holland, Amsterdam, New York, Oxford, (1982).
[58] G. Wu, Bi-isolation in the d.c.e. degrees, J. Symbolic Logic. 69, 409–420,
(2004).
[59] Y. Yang and L. Yu, On Σ1-structural diﬀerences among ﬁnite levels of the
Ershov hierarchy, J. Symbolic Logic. 71, 1223–1236, (2006).
[60] C. E. M. Yates, A minimal pair of recursively enumerable degrees, J. Sym-
bolic Logic. 31, 159–168, (1966).

Chapter 4
Complexity and Approximation in Reoptimization
Giorgio Ausiello, Vincenzo Bonifaci∗and Bruno Escoﬃer
Sapienza University of Rome,
Department of Computer and Systems Science,
00185 Rome, Italy
E-mail: ausiello@dis.uniroma1.it
Sapienza University of Rome,
Department of Computer and Systems Science,
00185 Rome, Italy, and
University of L’Aquila,
Department of Electrical and Information Engineering,
67040 L’Aquila, Italy
E-mail: bonifaci@dis.uniroma1.it
LAMSADE,
Universit´e Paris Dauphine and CNRS,
75775 Paris Cedex 16, France
E-mail: escoﬃer@lamsade.dauphine.fr
In this chapter the following model is considered: We assume that an
instance I of a computationally hard optimization problem has been
solved and that we know the optimum solution of such an instance. Then
a new instance I′ is proposed, obtained by means of a slight perturbation
of instance I. How can we exploit the knowledge we have on the solution
of instance I to compute an (approximate) solution of instance I′ in an
eﬃcient way? This computation model is called reoptimization and is
of practical interest in various circumstances. In this chapter we ﬁrst
discuss what kind of performance we can expect for speciﬁc classes of
problems and then we present some classical optimization problems (i.e.
Max Knapsack, Min Steiner Tree, Scheduling) in which this approach
has been fruitfully applied.
Subsequently, we address vehicle routing
∗This work was partially supported by the Future and Emerging Technologies Unit of
EC (IST priority - 6th FP), under contract no. FP6-021235-2 (project ARRIVAL).
101

102
G. Ausiello, V. Bonifaci, & B. Escoﬃer
problems and we show how the reoptimization approach can be used to
obtain good approximate solutions in an eﬃcient way for some of these
problems.
Contents
4.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
4.2
Basic Deﬁnitions and Results . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
4.3
Reoptimization of NP-hard Optimization Problem
. . . . . . . . . . . . . . . 106
4.3.1
General properties
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
4.3.2
Results on some particular problems
. . . . . . . . . . . . . . . . . . . 114
4.4
Reoptimization of Vehicle Routing Problems
. . . . . . . . . . . . . . . . . . 118
4.4.1
The Minimum Traveling Salesman Problem
. . . . . . . . . . . . . . . 120
4.4.2
The Maximum Traveling Salesman Problem . . . . . . . . . . . . . . . 124
4.4.3
The Minimum Latency Problem . . . . . . . . . . . . . . . . . . . . . . 125
4.5
Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
4.1. Introduction
In this chapter we illustrate the role that a new computational paradigm
called reoptimization plays in the solution of NP-hard problems in various
practical circumstances.
As it is well known a great variety of relevant
optimization problems are intrinsically diﬃcult and no solution algorithms
running in polynomial time are known for such problems. Although the
existence of eﬃcient algorithms cannot be ruled out at the present state
of knowledge, it is widely believed that this is indeed the case. The most
renowned approach to the solution of NP-hard problems consists in resort-
ing to approximation algorithms which, in polynomial time, provide a sub-
optimal solution whose quality (measured as the ratio between the values of
the optimum and approximate solution) is somehow guaranteed. In the last
twenty years the deﬁnition of better and better approximation algorithms
and the classiﬁcation of problems based on the quality of approximation
that can be achieved in polynomial time have been among the most impor-
tant research directions in theoretical computer science and have produced
a huge ﬂow of literature [4, 36].
More recently a new computational approach to the solution of NP-
hard problems has been proposed [1]. This approach can be meaningfully
adopted when the following situation arises: Given a problem Π, the in-
stances of Π that we need to solve are indeed all obtained by means of a
slight perturbation of a given reference instance I. In such a case we can de-
vote enough time to the exact solution of the reference instance I and then,

Complexity and Approximation in Reoptimization
103
any time that the solution for a new instance I′ is required, we can apply a
simple heuristic that eﬃciently provides a good approximate solution to I′.
Let us imagine, for example, that we know that a traveling salesman has
to visit a set S of, say, one thousand cities plus a few more cities that may
change from time to time. In such case it is quite reasonable to devote a
conspicuous amount of time to the exact solution of the traveling salesman
problem on the set S and then to reoptimize the solution whenever the
modiﬁed instance is known, with a (hopefully) very small computational
eﬀort.
To make the concept more precise let us consider the following simple
example (Max Weighted Sat): Let φ be a Boolean formula in conjunctive
normal form, consisting of m weighted clauses over n variables, and let us
suppose we know a truth assignment τ such that the weight of the clauses
satisﬁed by τ is maximum; let this weight be W. Suppose that now a new
clause c with weight w over the same set of variables is provided and that we
have to ﬁnd a “good” although possibly not optimum truth assignment τ ′
for the new formula φ′ = φ∧c. A very simple heuristic can always guarantee
a 1/2 approximate truth assignment in constant time. The heuristic is the
following: If W ≥w then put τ ′ = τ, otherwise take as τ ′ any truth
assignment that satisﬁes c. It is easy to see that, in any case, the weight
provided by this heuristic will be at least 1/2 of the optimum.
Actually the reoptimization concept is not new.
A similar approach
has been applied since the early 1980s to some polynomial time solvable
optimization problems such as minimum spanning tree [16] and shortest
path [14, 32] with the aim to maintain the optimum solution of the given
problem under input modiﬁcation (say elimination or insertion of an edge
or update of an edge weight). A big research eﬀort devoted to the study of
eﬃcient algorithms for the dynamic maintenance of the optimum solution
of polynomial time solvable optimization problems followed the ﬁrst results.
A typical example of this successful line of research has been the design of
algorithms for the partially or fully dynamic maintenance of a minimum
spanning tree in a graph under edge insertion and/or edge elimination [12,
22] where at any update, the computation of the new optimum solution
requires at most O(n1/3 log n) amortized time per operation, much less
than recomputing the optimum solution from scratch.
A completely diﬀerent picture arises when we apply the concept of reop-
timization to NP-hard optimization problems. In fact, reoptimization pro-
vides very diﬀerent results when applied to polynomial time optimization
problems with respect to what happens in the case of NP-hard problems.

104
G. Ausiello, V. Bonifaci, & B. Escoﬃer
In the case of NP-hard optimization problems, unless P=NP polynomial
time reoptimization algorithms can only help us to obtain approximate
solutions, since if we knew how to maintain an optimum solution under
input updates, we could solve the problem optimally in polynomial time
(see Section 4.3.1).
The application of the reoptimization computation paradigm to NP-
hard optimization problems is hence aimed at two possible directions: ei-
ther at achieving an approximate solution of better quality than we would
have obtained without knowing the optimum solution of the base instance,
or achieving an approximate solution of the same quality but at a lower
computational cost (as is the case in our previous example).
In the ﬁrst place the reoptimization model has been applied to classical
NP-hard optimization problems such as scheduling (see Bartusch et al. [6],
Sch¨aﬀter [34], or Bartusch et al. [7] for practical applications). More re-
cently it has been applied to various other NP-hard problems such as Steiner
Tree [9, 13] or the Traveling Salesman Problem [1, 5, 8]. In this chapter
we will discuss some general issues concerning reoptimization of NP-hard
optimization problems and we will review some of the most interesting ap-
plications.
The chapter is organized as follows. First, in Section 4.2 we provide
basic deﬁnitions concerning complexity and approximability of optimiza-
tion problems and we show simple preliminary results. Then in Section
4.3 the computational power of reoptimization is discussed and results con-
cerning the reoptimization of various NP-hard optimization problems are
shown. Finally Section 4.4 is devoted to the application of the reoptimiza-
tion concept to a variety of vehicle routing problems. While most of the
results contained in Section 4.3 and Section 4.4 derive from the literature,
it is worth noting that a few of the presented results – those for which no
reference is given – appear in this paper for the ﬁrst time.
4.2. Basic Deﬁnitions and Results
In order to characterize the performance of reoptimization algorithms and
analyze their application to speciﬁc problems we have to provide ﬁrst a basic
introduction to the class of NP optimization problems (NPO problems) and
to the notion of approximation algorithms and approximation classes. For
a more extensive presentation of the theory of approximation the reader
can refer to [4].

Complexity and Approximation in Reoptimization
105
Deﬁnition 4.1. An NP optimization (NPO) problem Π is deﬁned as a
four-tuple (I, Sol, m, opt) such that:
• I is the set of instances of Π and it can be recognized in polynomial
time;
• given I ∈I, Sol(I) denotes the set of feasible solutions of I; for every
S ∈Sol(I), |S| (the size of S) is polynomial in |I| (the size of I); given
any I and any S polynomial in |I|, one can decide in polynomial time
if S ∈Sol(I);
• given I ∈I and S ∈Sol(I), m(I, S) denotes the value of S; m is
polynomially computable and is commonly called objective function;
• opt ∈{min, max} indicates the type of optimization problem.
As it is well known, several relevant optimization problems, known as
NP-hard problems, are intrinsically diﬃcult and no solution algorithms run-
ning in polynomial time are known for such problems. For the solution of
NP-hard problems we have to resort to approximation algorithms, which in
polynomial time provide a suboptimal solution of guaranteed quality.
Let us brieﬂy recall the basic deﬁnitions regarding approximation algo-
rithms and the most important approximation classes of NPO problems.
Given an NPO problem Π = (I, Sol, m, opt), an optimum solution of an
instance I of Π is denoted S∗(I) and its measure m(I, S∗(I)) is denoted
opt(I).
Deﬁnition 4.2. Given an NPO problem Π = (I, Sol, m, opt), an approxi-
mation algorithm A is an algorithm that, given an instance I of Π, returns
a feasible solution S ∈Sol(I).
If A runs in polynomial time with respect to |I|, A is called a polynomial
time approximation algorithm for Π.
The quality of an approximation algorithm is usually measured as the
ratio ρA(I), approximation ratio, between the value of the approximate so-
lution, m(I, A(I)), and the value of the optimum solution opt(I). For mini-
mization problems, therefore, the approximation ratio is in [1, ∞), while for
maximization problems it is in [0, 1]. According to the quality of approxi-
mation algorithms that can be designed for their solution, NPO problems
can be classiﬁed as follows:
Deﬁnition 4.3. An NPO problem Π belongs to the class APX if there
exists a polynomial time approximation algorithm A and a rational value
r such that, given any instance I of Π, ρA(I) ⩽r (resp. ρA(I) ⩾r) if Π is

106
G. Ausiello, V. Bonifaci, & B. Escoﬃer
a minimization problem (resp. a maximization problem). In such case A is
called an r-approximation algorithm.
Examples of combinatorial optimization problems belonging to the class
APX are Max Weighted Sat, Min Vertex Cover, and Min Metric TSP.
For particular problems in APX a stronger form of approximability can
indeed be shown. For such problems, given any rational r > 1 (or r ∈
(0, 1) for a maximization problem), there exists an algorithm Ar and a
suitable polynomial pr such that Ar is an r-approximation algorithm whose
running time is bounded by pr as a function of |I|. The family of algorithms
Ar parametrized by r is called a polynomial time approximation scheme
(PTAS).
Deﬁnition 4.4. An NPO problem Π belongs to the class PTAS if it admits
a polynomial time approximation scheme Ar.
Examples of combinatorial optimization problems belonging to the class
PTAS are Min Partitioning, Max Independent Set on Planar Graphs, and
Min Euclidean TSP.
Notice that in the deﬁnition of PTAS, the running time of Ar is poly-
nomial in the size of the input, but it may be exponential (or worse) in
the inverse of |r −1|. A better situation arises when the running time is
polynomial in both the input size and the inverse of |r −1|. In the favor-
able case when this happens, the algorithm is called a fully polynomial time
approximation scheme (FPTAS).
Deﬁnition 4.5. An NPO problem Π belongs to the class FPTAS if it admits
a fully polynomial time approximation scheme.
It is important to observe that, under the (reasonable) hypothesis that
P ̸= NP, it is possible to prove that FPTAS ⊊PTAS ⊊APX ⊊NPO.
4.3. Reoptimization of NP-hard Optimization Problem
As explained in the introduction, the reoptimization setting leads to inter-
esting optimization problems for which the complexity properties and the
existence of good approximation algorithms have to be investigated. This
section deals with this question, and is divided into two parts: In Sub-
section 4.3.1, we give some general considerations on these reoptimization
problems, both on the positive side (obtaining good approximate solutions)
and on the negative side (hardness of reoptimization). In Subsection 4.3.2,

Complexity and Approximation in Reoptimization
107
we survey some results achieved on reoptimizing three well-known prob-
lems (the Min Steiner Tree problem, a scheduling problem, and the Max
Knapsack problem).
4.3.1. General properties
As mentioned previously, if one wishes to get an approximate solution on
the perturbed instance, she/he can compute it by applying directly, from
scratch, a known approximation algorithm for the problem dealt (on the
modiﬁed instance).
In other words, reoptimizing is at least as easy as
approximating. The goal of reoptimization is to determine if it is possible
to fruitfully use our knowledge on the initial instance in order to:
• either achieve better approximation ratios;
• or devise much faster algorithms;
• or both!
In this section, we present some general results dealing with reopti-
mization properties of some NPO problems. We ﬁrst focus on a class of
hereditary problems, then we discuss the diﬀerences between weighted and
unweighted versions of classical problems, and ﬁnally present some ways to
achieve hardness results in reoptimization.
Of course, many types of problems can be considered, and for each of
them many ways to modify the instances might be investigated. We mainly
focus here on graph problems where a modiﬁcation consists of adding a new
vertex on the instance, but show with various examples that the approaches
we present are also valid in many other cases.
4.3.1.1. Hereditary problems
We say that a property on graphs is hereditary if the following holds: If
G = (V, E) satisﬁes this property, then for any V ′ ⊆V , the subgraph G[V ′]
induced by V ′ veriﬁes the property. Following this deﬁnition, for instance,
being independent a, being bipartite, or being planar are three hereditary
properties. Now, let us deﬁne problems based on hereditary properties.
Deﬁnition 4.6. We call Hered the class of problems consisting, given a
vertex-weighted graph G = (V, E, w), of ﬁnding a subset of vertices S (i)
such that G[S] satisﬁes a given hereditary property (ii) that maximizes
w(S) = P
v∈S w(v).
ai.e. having no edge.

108
G. Ausiello, V. Bonifaci, & B. Escoﬃer
Hereditary problems have been studied before as a natural generaliza-
tion of important combinatorial problems [27]. For instance, Max Weighted
Independent Set, Max Weighted Bipartite Subgraph, Max Weighted Planar
Subgraph are three famous problems in Hered that correspond to the three
hereditary properties given above.
For all these problems, we have a simple reoptimization strategy that
achieves a ratio 1/2, based on the same idea used in the introduction. Note
that this is a huge improvement for some problems respect to their ap-
proximability properties; for instance, it is well known that Max Weighted
Independent Set is not approximable within any constant ratio, if P ̸= NPb.
Theorem 4.1. Let Π be a problem in Hered. Under a vertex insertion,
reoptimizing Π is approximable within ratio 1/2 (in constant time).
Proof.
Let I = (G, w) be the initial instance of Π, I′ = (G′, w′) be the
ﬁnal instance (a new vertex v has been inserted), S∗be an optimum solution
on I, and S∗
I′ be an optimum solution on I′. Notice that w′(u) = w(u) for
all u ̸= v.
Getting a 1/2-approximate solution is very easy: just consider the best
solution among S∗and (if feasible) S1 := {v}. Solution S∗is feasible by
heritability. We can also assume S1 feasible, as otherwise by heritability
no feasible solution can include v, and S∗must be optimal. Finally, by
heritability, S∗
I′ \ {v} is a feasible solution on the initial instance. Then,
w′(S∗
I′) ≤w′(S∗) + w′(v) = w′(S∗) + w′(S1) ≤2 max(w′(S∗), w′(S1)).
□
Now, let us try to outperform this trivial ratio 1/2. A ﬁrst idea that
comes to mind is to improve the solution S1 of the previous proof since
it only contains one vertex. In particular, one can think of applying an
approximation algorithm on the “remaining instance after taking v”. Con-
sider for instance Max Weighted Independent Set, and revisit the proof of
the previous property.
If S∗
I′ does not take the new vertex v, then our
initial solution S∗is optimum. If S∗
I′ takes v, then consider the remaining
instance Iv after having removed v and its neighbors. Suppose that we have
a ρ-approximate solution S2 on this instance Iv. Then S2 ∪{v} is a feasible
solution of weight:
w(S2 ∪{v}) ≥ρ(w(S∗
I′) −w(v)) + w(v) = ρw(S∗
I′) + (1 −ρ)w(v).
(4.1)
On the other hand, of course :
w(S∗) ≥w(S∗
I′) −w(v).
(4.2)
bAnd not even within ratio n1−ε for any ε > 0, under the same hypothesis [37].

Complexity and Approximation in Reoptimization
109
If we output the best solution S among S∗and S2 ∪{v}, then, by adding
equations (4.1) and (4.2) with coeﬃcients 1 and (1 −ρ), we get:
w(S) ≥
1
2 −ρw(S∗
I′).
Note that this ratio is always better than ρ.
This technique is actually quite general and applies to many problems
(not only graph problems and maximization problems). We illustrate this
on two well-known problems: Max Weighted Sat (Theorem 4.2) and Min
Vertex Cover (Theorem 4.3).
We will also use it for Max Knapsack in
Section 4.3.2.
Theorem 4.2. Under the insertion of a clause, reoptimizing Max Weighted
Sat is approximable within ratio 0.81.
Proof.
Let φ be a conjunction of clauses over a set of binary variables,
each clause being given with a weight, and let τ ∗(φ) be an initial optimum
solution. Let φ′ := φ ∧c be the ﬁnal formula, where the new clause c =
l1 ∨l2 ∨. . . ∨lk (where li is either a variable or its negation) has weight
w(c).
We consider k solutions τi, i = 1, . . . , k. Each τi is built as follows:
• We set li to true;
• We replace in φ each occurrence of li and li with its value;
• We apply a ρ-approximation algorithm on the remaining instance (note
that the clause c is already satisﬁed); together with li, this is a partic-
ular solution τi.
Then, our reoptimization algorithm outputs the best solution τ among
τ ∗(φ) and the τis.
As previously, if the optimum solution τ ∗(φ′) on the ﬁnal instance does
not satisfy c, then τ ∗(φ) is optimum. Otherwise, at least one literal in c,
say li, is true in τ ∗(φ′). Then, it is easy to see that
w(τi) ≥ρ(w(τ ∗(φ′)) −w(c)) + w(c) = ρw(τ ∗(φ′)) + (1 −ρ)w(c).
On the other hand, w(τ ∗(φ)) ≥w(τ ∗(φ′)) −w(c), and the following
result follows:
w(τ) ≥
1
2 −ρw(τ ∗(φ′)).
The fact that Max Weighted Sat is approximable within ratio ρ = 0.77 [3]
concludes the proof.
□

110
G. Ausiello, V. Bonifaci, & B. Escoﬃer
It is worth noticing that the same ratio (1/(2 −ρ)) is achievable for
other satisﬁability or constraint satisfaction problems. For instance, using
the result of Johnson [24], reoptimizing Max Weighted E3SATc when a new
clause is inserted is approximable within ratio 8/9.
Let us now focus on a minimization problem, namely Min Vertex Cover.
Given a vertex-weighted graph G = (V, E, w), the goal in this problem is
to ﬁnd a subset V ′ ⊆V such that (i) every edge e ∈E is incident to at
least one vertex in V ′, and (ii) the global weight of V ′, that is, P
v∈V ′ w(v)
is minimized.
Theorem 4.3. Under a vertex insertion, reoptimizing Min Vertex Cover is
approximable within ratio 3/2.
Proof.
Let v denote the new vertex and S∗the initial given solution.
Then, S∗∪{v} is a vertex cover on the ﬁnal instance. If S∗
I′ takes v, then
S∗∪{v} is optimum.
From now on, suppose that S∗
I′ does not take v. Then it has to take all
its neighbors N(v). S∗∪N(v) is a feasible solution on the ﬁnal instance.
Since w(S∗) ≤w(S∗
I′), we get:
w(S∗∪N(v)) ≤w(S∗
I′) + w(N(v)).
(4.3)
Then, as for Max Weighted Independent Set, consider the following feasible
solution S1:
• Take all the neighbors N(v) of v in S1;
• Remove v and its neighbors from the graph;
• Apply a ρ-approximation algorithm on the remaining graph and add
these vertices to S1.
Since we are in the case where S∗
I′ does not take v, it has to take all its
neighbors, and ﬁnally:
w(S1) ≤ρ(w(S∗
I′)−w(N(v)))+w(N(v)) = ρw(S∗
I′)−(ρ−1)w(N(v)). (4.4)
Of course, we take the best solution S among S∗∪N(v) and S1. Then, a
convex combination of equations (4.3) and (4.4) leads to:
w(S) ≤2ρ −1
ρ
w(S∗
I′).
The results follows since Min Vertex Cover is well known to be approximable
within ratio 2.
□
cRestriction of Max Weighted Sat when all clauses contain exactly three literals.

Complexity and Approximation in Reoptimization
111
To conclude this section, we point out that these results can be general-
ized when several vertices are inserted. Indeed, if a constant number k > 1
of vertices are added, one can reach the same ratio with similar arguments
by considering all the 2k possible subsets of new vertices in order to ﬁnd
the ones that will belong to the new optimum solution. This brute force
algorithm is still very fast for small constant k, which is the case in the
reoptimization setting with slight modiﬁcations of the instance.
4.3.1.2. Unweighted problems
In the previous subsection, we considered the general cases where vertices
(or clauses) have a weight.
It is well known that all the problems we
focused on are already NP-hard in the unweighted case, i.e. when all ver-
tices/clauses receive weight 1. In this (very common) case, the previous
approximation results on reoptimization can be easily improved. Indeed,
since only one vertex is inserted, the initial optimum solution has an abso-
lute error of at most one on the ﬁnal instance, i.e.:
|S∗| ≥|S∗
I′| −1.
Then, in some sense we don’t really need to reoptimize since S∗is
already a very good solution on the ﬁnal instance (note also that since
the reoptimization problem is NP-hard, we cannot get rid of the constant
−1). Dealing with approximation ratio, we derive from this remark, with
a standard technique, the following result:
Theorem 4.4. Under a vertex insertion, reoptimizing any unweighted
problem in Hered admits a PTAS.
Proof.
Let ε > 0, and set k = ⌈1/ε⌉. We consider the following algo-
rithm:
(1) Test all the subsets of V of size at most k, and let S1 be the largest
one such that G[S1] satisﬁes the hereditary property;
(2) Output the largest solution S between S1 and S∗.
Then, if S∗
I′ has size at most 1/ε, we found it in step 1. Otherwise, |S∗
I′| ≥
1/ε and:
|S∗|
|S∗
I′| ≥|S∗
I′| −1
|S∗
I′|
≥1 −ε.
Of course, the algorithm is polynomial as long as ε is a constant.
□

112
G. Ausiello, V. Bonifaci, & B. Escoﬃer
In other words, the PTAS is derived from two properties: the absolute
error of 1, and the fact that problems considered are simple. Following [30],
a problem is called simple if, given any ﬁxed constant k, it is polynomial to
determine whether the optimum solution has value at most k (maximiza-
tion) or not.
This result easily extends to other simple problems, such as Min Vertex
Cover, for instance. It also generalizes when several (a constant number
of) vertices are inserted, instead of only 1.
However, it is interesting to notice that, for some other (unweighted)
problems, while the absolute error 1 still holds, we cannot derive a PTAS as
in Theorem 4.4 because they are not simple. One of the most famous such
problems is the Min Coloring problem. In this problem, given a graph G =
(V, E), one wishes to partition V into a minimum number of independent
sets (called colors) V1, . . . , Vk. When a new vertex is inserted, an absolute
error 1 can be easily achieved while reoptimizing.
Indeed, consider the
initial coloring and add a new color which contains only the newly inserted
vertex. Then this coloring has an absolute error of 1 since a coloring on the
ﬁnal graph cannot use fewer colors than an optimum coloring on the initial
instance.
However, deciding whether a graph can be colored with 3 colors is an
NP-hard problem. In other words, Min Coloring is not simple. We will
discuss the consequence of this fact in the section on hardness of reopti-
mization.
To conclude this section, we stress the fact that there exist, obviously,
many problems that do not involve weights and for which the initial opti-
mum solution cannot be directly transformed into a solution on the ﬁnal
instance with absolute error 1. Finding the longest cycle in a graph is such
a problem: adding a new vertex may change considerably the size of an
optimum solution.
4.3.1.3. Hardness of reoptimization
As mentioned earlier, the fact that we are interested in slight modiﬁcations
of an instance on which we have an optimum solution makes the problem
somehow simpler, but unfortunately does not generally allow a jump in
complexity. In other words, reoptimizing is generally NP-hard when the
underlying problem is NP-hard.
In some cases, the proof of NP-hardness is immediate. For instance,

Complexity and Approximation in Reoptimization
113
consider a graph problem where modiﬁcations consists of inserting a new
vertex. Suppose that we had an optimum reoptimization algorithm for this
problem. Then, starting from the empty graph, and adding the vertices one
by one, we could ﬁnd an optimum solution on any graph on n vertices by us-
ing iteratively n times the reoptimization algorithm. Hence, the underlying
problem would be polynomial. In conclusion, the reoptimization version is
also NP-hard when the underlying problem is NP-hard. This argument is
also valid for other problems under other kinds of modiﬁcations. Actually,
it is valid as soon as, for any instance I, there is a polynomial-time solvable
instance I′ (the empty graph in our example) that can be generated in poly-
nomial time and such that a polynomial number of modiﬁcations transform
I′ into I.
In other cases, the hardness does not directly follow from this argument,
and a usual polynomial time reduction has to be provided. This situation
occurs, for instance, in graph problems where the modiﬁcation consists of
deleting a vertex. As we will see later, such hardness proofs have been
given, for instance, for some vehicle routing problems (in short, VRP).
Let us now focus on the hardness of approximation in the reoptimization
setting. As we have seen in particular in Theorem 4.4, the knowledge of the
initial optimum solution may help considerably in ﬁnding an approximate
solution on the ﬁnal instance. In other words, it seems quite hard to prove a
lower bound on reoptimization. And in fact, few results have been obtained
so far.
One method is to transform the reduction used in the proof of NP-
hardness to get an inapproximability bound. Though more diﬃcult than
in the usual setting, such proofs have been provided for reoptimization
problems, in particular for VRP problems, mainly by introducing very large
distances (see Section 4.4).
Let us now go back to Min Coloring. As we have said, it is NP-hard to
determine whether a graph is colorable with 3 colors or not. In the usual
setting, this leads to an inapproximability bound of 4/3 −ε for any ε > 0.
Indeed, an approximation algorithm within ratio ρ = 4/3 −ε would allow
us to distinguish between 3-colorable graphs and graphs for which we need
at least 4 colors. Now, we can show that this result remains true for the
reoptimization of the problem:
Theorem 4.5. Under a vertex insertion, reoptimizing Min Coloring cannot
be approximated within a ratio 4/3 −ε, for any ε > 0.

114
G. Ausiello, V. Bonifaci, & B. Escoﬃer
Proof.
The proof is actually quite straightforward. Assume you have
such a reoptimization algorithm A within a ratio ρ = 4/3−ε. Let G = (V, E)
be a graph with V = {v1, · · · , vn}. We consider the subgraphs Gi of G
induced by Vi = {v1, v2, · · · , vi} (in particular Gn = G).
Suppose that
you have a 3-coloring of Gi, and insert vi+1. If Gi+1 is 3-colorable, then
A outputs a 3-coloring. Moreover, if Gi is not 3-colorable, then neither is
Gi+1. Hence, starting from the empty graph, and iteratively applying A,
we get a 3-coloring of Gi if and only if Gi is 3-colorable. Eventually, we are
able to determine whether G is 3-colorable or not.
□
This proof is based on the fact that Min Coloring is not simple (ac-
cording to the deﬁnition previously given). A similar argument, leading
to inapproximability results in reoptimization, can be applied to other non
simple problems (under other modiﬁcations).
It has been in particular
applied to a scheduling problem (see Section 4.3.2).
For other optimization problems however, such as MinTSP in the metric
case, ﬁnding a lower bound in approximability (if any!) seems a challenging
task.
Let us ﬁnally mention another kind of negative result. In the reopti-
mization setting, we look somehow for a possible stability when slight modi-
ﬁcations occur on the instance. We try to measure how much the knowledge
of a solution on the initial instance helps to solve the ﬁnal one. Hence, it
is natural to wonder whether one can ﬁnd a good solution in the “neigh-
borhood” of the initial optimum solution, or if one has to change almost
everything. Do neighboring instances have neighboring optimum/good so-
lutions? As an answer to these questions, several results show that, for
several problems, approximation algorithms that only “slightly” modify
the initial optimum solution cannot lead to good approximation ratios. For
instance, for reoptimizing MinTSP in the metric case, if you want a ratio
better than 3/2 (guaranteed by a simple heuristic), then you have to change
(on some instances) a signiﬁcant part of your initial solution [5]. This kind
of result, weaker than an inapproximability bound, provides information on
the stability under modiﬁcations and lower bounds on classes of algorithms.
4.3.2. Results on some particular problems
In the previous section, we gave some general considerations on the reop-
timization of NP-hard optimization problems. The results that have been
presented follow, using simple methods, from the structural properties of

Complexity and Approximation in Reoptimization
115
the problem dealt with and/or from known approximation results. We now
focus on particular problems for which speciﬁc methods have been devised,
and brieﬂy mention, without proofs, the main results obtained so far. We
concentrate on the Min Steiner Tree problem, on a scheduling problem, and
on the Max Knapsack problem. Vehicle routing problems, which concen-
trated a large attention in reoptimization, deserve, in our opinion, a full
section (Section 4.4), in which we also provide some of the most interesting
proofs in the literature together with a few new results.
4.3.2.1. Min Steiner Tree
The Min Steiner Tree problem is a generalization of the Min Spanning Tree
problem where only a subset of vertices (called terminal vertices) have to
be spanned. Formally, we are given a graph G = (V, E), a non-negative
distance d(e) for any e ∈E, and a subset R ⊆V of terminal vertices.
The goal is to connect the terminal vertices with a minimum global dis-
tance, i.e. to ﬁnd a tree T ⊆E that spans all vertices in R and minimizes
d(T ) = P
e∈T d(e). It is generally assumed that the graph is complete, and
the distance function is metric (i.e. d(x, y) + d(y, z) ≥d(x, z) for any ver-
tices x, y, z): indeed, the general problem reduces to this case by initially
computing shortest paths between pairs of vertices.
Min Steiner Tree is one of the most famous network design optimization
problems. It is NP-hard, and has been studied intensively from an approx-
imation viewpoint (see [18] for a survey on these results). The best known
ratio obtained so far is 1 + ln(3)/2 ≃1.55 [31].
Reoptimization versions of this problem have been studied with modi-
ﬁcations on the vertex set [9, 13]. In Escoﬃer et al. [13], the modiﬁcation
consists of the insertion of a new vertex. The authors study the cases where
the new vertex is terminal or non-terminal.
Theorem 4.6 ([13]). When a new vertex is inserted (either terminal or
not), then reoptimizing the Min Steiner Tree problem can be approximated
within ratio 3/2.

116
G. Ausiello, V. Bonifaci, & B. Escoﬃer
Moreover, the result has been generalized to the case in which several
vertices are inserted. Interestingly, when p non-terminal vertices are in-
serted, then reoptimizing the problem is still 3/2-approximable (but the
running time grows very fast with p). On the other hand, when terminal
vertices are added, the obtained ratio decreases (but the running time re-
mains very low). The strategies consist, roughly speaking, of merging the
initial optimum solution with Steiner trees computed on the set of new
vertices and/or terminal vertices. The authors tackle also the case where
a vertex is removed from the vertex set, and provide a lower bound for a
particular class of algorithms.
B¨ockenhauer et al. [9] consider a diﬀerent instance modiﬁcation. Rather
than inserting/deleting a vertex, the authors consider the case where the
status of a vertex changes: either a terminal vertex becomes non-terminal,
or vice versa. The obtained ratio is also 3/2.
Theorem 4.7 ([9]). When the status (terminal / non-terminal) of a ver-
tex changes, then reoptimizing the Min Steiner Tree problem can be approx-
imated within ratio 3/2.
Moreover, they exhibit a case where this ratio can be improved. When
all the distances between vertices are in {1, 2, · · · , r}, for a ﬁxed constant
r, then reoptimizing Min Steiner Tree (when changing the status of one
vertex) is still NP-hard but admits a PTAS.
Note that in both cases (changing the status of a vertex or adding a
new vertex), no inapproximability results have been achieved, and this is
an interesting open question.
4.3.2.2. Scheduling
Due to practical motivations, it is not surprising that scheduling problems
received attention dealing with the reconstruction of a solution (often called
rescheduling) after an instance modiﬁcation, such as a machine breakdown,
an increase of a job processing time, etc. Several works have been proposed
to provide a sensitivity analysis of these problems under such modiﬁca-
tions. A typical question is to determine under which modiﬁcations and/or
conditions the initial schedule remains optimal. We refer the reader to the
comprehensive article [20] where the main results achieved in this ﬁeld are
presented.

Complexity and Approximation in Reoptimization
117
Dealing with the reoptimization setting we develop in this chapter,
Sch¨aﬀter [34] proposes interesting results on a problem of scheduling with
forbidden sets. In this problem, we have a set of jobs V = {v1, · · · , vn},
each job having a processing time. The jobs can be scheduled in parallel
(the number of machines is unbounded), but there is a set of constraints
on these parallel schedules: A constraint is a set F ⊆V of jobs that cannot
be scheduled in parallel (all of them at the same time). Then, given a set
F = {F1, · · · , Fk} of constraints, the goal is to ﬁnd a schedule that respects
each constraint and that minimizes the latest completion time (makespan).
Many situations can be modeled this way, such as the m-Machine Prob-
lem (for ﬁxed m), hence the problem is NP-complete (and even hard to
approximate).
Sch¨aﬀter considers reoptimization when either a new constraint F is
added to F, or a constraint Fi ∈F disappears. Using reductions from the
Set Splitting problem and from the Min Coloring problem, he achieves the
following inapproximability results:
Theorem 4.8 ([34]). If P ̸= NP, for any ε > 0, reoptimizing the schedul-
ing with forbidden sets problem is inapproximable within ratio 3/2−ε under
a constraint insertion, and inapproximable within ratio 4/3−ε under a con-
straint deletion.
Under a constraint insertion Sch¨aﬀter also provides a reoptimization
strategy that achieves approximation ratio 3/2, thus matching the lower
bound of Theorem 4.8. It consists of a simple local modiﬁcation of the
initial scheduling, by shifting one task (at the end of the schedule) in order
to ensure that the new constraint is satisﬁed.
4.3.2.3. Max Knapsack
In the Max Knapsack problem, we are given a set of n objects O =
{o1, . . . , on}, and a capacity B. Each object has a weight wi and a value
vi. The goal is to choose a subset O′ of objects that maximizes the global
value P
oi∈O′ vi but that respects the capacity constraint P
oi∈O′ wi ≤B.
This problem is (weakly) NP-hard, but admits an FPTAS [23].
Obviously, the reoptimization version admits an FPTAS too.
Thus,
Archetti et al. [2] are interested in using classical approximation algorithms
for Max Knapsack to derive reoptimization algorithms with better approx-
imation ratios but with the same running time. The modiﬁcations consid-
ered consist of the insertion of a new object in the instance.

118
G. Ausiello, V. Bonifaci, & B. Escoﬃer
Though not being a graph problem, it is easy to see that the Max
Knapsack problem satisﬁes the required properties of heritability given in
Section 4.3.1 (paragraph on hereditary problems). Hence, the reoptimiza-
tion version is 1/2-approximable in constant time; moreover, if we have
a ρ-approximation algorithm, then the reoptimization strategy presented
in Section 4.3.1 has ratio
1
2−ρ [2]. Besides, Archetti et al. [2] show that
this bound is tight for several classical approximation algorithms for Max
Knapsack.
Finally, studying the issue of sensitivity presented earlier, they show
that any reoptimization algorithm that does not consider objects discarded
by the initial optimum solution cannot have ratio better than 1/2.
4.4. Reoptimization of Vehicle Routing Problems
In this section we survey several results concerning the reoptimization of
vehicle routing problems under diﬀerent kinds of perturbations. In particu-
lar, we focus on several variants of the Traveling Salesman Problem (TSP),
which we deﬁne below.
The TSP is a well-known combinatorial optimization problem that has
been the subject of extensive studies – here we only refer the interested
reader to the monographs by Lawler et al. [26] and Gutin and Punnen [19].
The TSP has been used since the inception of combinatorial optimization
as a testbed for experimenting a whole array of algorithmic paradigms and
techniques, so it is just natural to also consider it from the point of view of
reoptimization.
Deﬁnition 4.7. An instance In of the Traveling Salesman Problem is given
by the distance between every pair of n nodes in the form of an n×n matrix
d, where d(i, j) ∈Z+ for all 1 ≤i, j ≤n. A feasible solution for In is a
tour, that is, a directed cycle spanning the node set N := {1, 2, . . ., n}.
Notice that we have not deﬁned an objective function yet; so far we
have only speciﬁed the structure of instances and feasible solutions. There
are several possibilities for the objective function and each of them gives
rise to a diﬀerent optimization problem. We need a few deﬁnitions. The
weight of a tour T is the quantity w(T ) := P
(i,j)∈T d(i, j). The latency of
a node i ∈N with respect to a given tour T is the total distance along the
cycle T from node 1 to node i. The latency of T , denoted by ℓ(T ), is the
sum of the latencies of the nodes of T .

Complexity and Approximation in Reoptimization
119
Table 4.1.
Best known results on the approximability of the standard and
reoptimization versions of vehicle routing problems (AR = approximation ra-
tio, Π+ = vertex insertion, Π−= vertex deletion, Π± = distance variation).
Problem Π
AR(Π)
Ref.
AR(Π+)
AR(Π−)AR(Π±)
Ref.
Min TSP
unbounded [33]
unb.
unb.
unb.
[5, 8]
Min MTSP
1.5
[11]
1.34
-
1.4
[1, 9]
Min ATSP
O(log n)
[15]
2
2
-
this work
Max TSP
0.6
[25]
0.66 −O(n−1)
-
-
this work
Max MTSP
0.875
[21]
1 −O(n−1/2)
-
-
[5]
MLP
3.59
[10]
3
-
-
this work
The matrix d obeys the triangle inequality if for all i, j, k ∈N we have
d(i, j) ≤d(i, k)+ d(k, j). The matrix d is said to be a metric if it obeys the
triangle inequality and d(i, j) = d(j, i) for all i, j ∈N.
In the rest of the section we will consider the following problems:
(1) Minimum Traveling Salesman Problem (Min TSP): ﬁnd a tour of min-
imum weight;
(2) Minimum Metric TSP (Min MTSP): restriction of Min TSP to the case
when d is a metric;
(3) Minimum Asymmetric TSP (Min ATSP): restriction of Min TSP to
the case when d obeys the triangle inequality;
(4) Maximum TSP (Max TSP): ﬁnd a tour of maximum weight;
(5) Maximum Metric TSP (Max MTSP): restriction of Max TSP to the
case when d is a metric;
(6) Minimum Latency Problem (MLP): ﬁnd a tour of minimum latency; d
is assumed to be a metric.
TSP-like problems other than those above have also been considered in
the literature from the point of view of reoptimization; in particular, see
B¨ockenhauer et al. [8] for a hardness result on the TSP with deadlines.
Given a vehicle routing problem Π from the above list, we will consider
the following reoptimization variants, each corresponding to a diﬀerent type
of perturbation of the instance: insertion of a node (Π+), deletion of a node
(Π−), and variation of a single entry of the matrix d (Π±).
In the following, we will sometimes refer to the initial problem Π as
the static problem. In Table 4.1 we summarize the approximability results
known for the static and reoptimization versions of the problems above
under these types of perturbations.

120
G. Ausiello, V. Bonifaci, & B. Escoﬃer
Some simple solution methods are common to several of the problems
we study in this section. We deﬁne here two such methods; they will be
used in the remainder of the section.
Algorithm 1 (Nearest Insertion). Given an instance In+1 and a tour
T on the set {1, . . ., n}, ﬁnd a node i∗∈argmin1≤i≤n d(i, n+1). Obtain the
solution by inserting node n + 1 either immediately before or immediately
after i∗in the tour (depending on which of these two solutions is best).
Algorithm 2 (Best Insertion). Given an instance In+1 and a tour T on
the set {1, . . ., n}, ﬁnd a pair (i∗, j∗) ∈argmin(i,j)∈T d(i, n + 1) + d(n +
1, j) −d(i, j). Obtain the solution by inserting node n + 1 between i∗and
j∗in the tour.
4.4.1. The Minimum Traveling Salesman Problem
4.4.1.1. The general case
We start by considering the Min TSP. It is well known that in the standard
setting the problem is very hard to approximate in the sense that it can-
not be approximated within any factor that is polynomial in the number
of nodes [33]. It turns out that the same result also holds for the reopti-
mization versions of the problem, which shows that in this particular case
the extra information available through the optimal solution to the original
instance does not help at all.
Theorem 4.9 ([5, 8]). Let p be a polynomial. Then each of Min TSP+,
Min TSP−, and Min TSP± is not 2p(n)-approximable, unless P=NP.
Proof.
We only give the proof for Min TSP−; the other proofs follow a
similar approach. We use the so-called gap technique from Sahni and Gon-
zales [33]. Consider the following problem, Restricted Hamiltonian Cycle
(RHC): Given an undirected graph G = (V, E) and a Hamiltonian path P
between two nodes a and b in G, determine whether there exists a Hamilto-
nian cycle in G. This problem is known to be NP-complete [28]. We prove
the claim of the theorem by showing that any approximation algorithm for
Min TSP−with ratio 2p(n) can be used to solve RHC in polynomial time.
Consider an instance of RHC, that is, a graph G = (V, E) on n nodes,
two nodes a, b ∈V and a Hamiltonian path P from a to b. Without loss
of generality we can assume that V = {1, . . . , n}. We can construct in
polynomial time the following TSP instance In+1 on node set {1, . . . , n, n+
1}:

Complexity and Approximation in Reoptimization
121
- d(i, j) = 1 if (i, j) ∈E;
- d(n + 1, a) = d(b, n + 1) = 1;
- all other entries of the matrix d have value 2p(n) · n + 1.
Since all entries are at least 1, the tour T ∗
n+1 := P ∪{(b, n + 1), (n + 1, a)}
is an optimum solution of In+1, with weight w(T ∗
n+1) = n + 1.
Thus,
(In+1, T ∗
n+1) is an instance of Min TSP−. Let T ∗
n be an optimum solution
of instance In. Then w(T ∗
n) = n if and only if G has a Hamiltonian cycle.
Finally, a 2p(n)-approximation algorithm for Min TSP−allows us to decide
whether w(T ∗
n) = n.
□
4.4.1.2. Minimum Metric TSP
In the previous section we have seen that no constant-factor approximation
algorithm exists for reoptimizing the Minimum TSP in its full generality.
To obtain such a result, we are forced to restrict the problem somehow.
A very interesting case for many applications is when the matrix d is a
metric, that is, the Min MTSP. This problem admits a 3/2-approximation
algorithm, due to Christoﬁdes [11], and it is currently open whether this
factor can be improved. Interestingly, it turns out that the reoptimization
version Min MTSP+ is (at least if one considers the currently best known
algorithms) easier than the static problem: It allows a 4/3-approximation –
although, again, we do not know whether even this factor may be improved
via a more sophisticated approach.
Theorem 4.10 ([5]). Min MTSP+ is approximable within ratio 4/3.
Proof.
The algorithm used to prove the upper bound is a simple combi-
nation of Nearest Insertion and of the well-known algorithm by Christoﬁdes
[11]; namely, both algorithms are executed and the solution returned is the
one having the lower weight.
Consider an optimum solution T ∗
n+1 of the ﬁnal instance In+1, and the
solution T ∗
n available for the initial instance In. Let i and j be the two
neighbors of vertex n + 1 in T ∗
n+1, and let T1 be the tour obtained from
T ∗
n with the Nearest Insertion rule. Furthermore, let v∗be the vertex in
{1, . . . , n} whose distance to n + 1 is the smallest.
Using the triangle inequality, we easily get w(T1) ≤w(T ∗
n+1)+2d(v∗, n+
1) where, by deﬁnition of v∗, d(v∗, n + 1) = min{d(k, n + 1) : k = 1, . . . , n}.
Thus
w(T1) ≤w(T ∗
n+1) + 2 max(d(i, n + 1), d(j, n + 1)).
(4.5)

122
G. Ausiello, V. Bonifaci, & B. Escoﬃer
Now consider the algorithm of Christoﬁdes applied on In+1. This gives
a tour T2 of length at most (1/2)w(T ∗
n+1) + MST(In+1), where MST(In+1)
is the weight of a minimum spanning tree on In+1. Note that MST(In+1) ≤
w(T ∗
n+1) −max(d(i, n + 1), d(j, n + 1)). Hence
w(T2) ≤3
2w(T ∗
n+1) −max(d(i, n + 1), d(j, n + 1)).
(4.6)
The result now follows by combining equations (4.5) and (4.6), because
the weight of the solution given by the algorithm is min(w(T1), w(T2)) ≤
(1/3)w(T1) + (2/3)w(T2) ≤(4/3)w(T ∗
n+1).
□
The above result can be generalized to the case when more than a
single vertex is added in the perturbed instance. Let Min MTSP+k be the
corresponding problem when k vertices are added. Then it is possible to
give the following result, which gives a trade-oﬀbetween the number of
added vertices and the quality of the approximation guarantee.
Theorem 4.11 ([5]). For any k ≥1, Min MTSP+k is approximable
within ratio 3/2 −1/(4k + 2).
Reoptimization under variation of a single entry of the distance ma-
trix (that is, problem Min MTSP±) has been considered by B¨ocken-
hauer et al. [9].
Theorem 4.12 ([9]). Min MTSP± is approximable within ratio 7/5.
4.4.1.3. Minimum Asymmetric TSP
The Minimum Asymmetric Traveling Salesman Problem is another variant
of the TSP that is of interest for applications, as it generalizes the Metric
TSP. Unfortunately, in the static case there seems to be a qualitative diﬀer-
ence with respect to the approximability of Minimum Metric TSP: While in
the latter case a constant approximation is possible, for Min ATSP the best
known algorithms give an approximation ratio of Θ(log n). The ﬁrst such
algorithm was described by Frieze et al. [17] and has an approximation guar-
antee of log2 n. The currently best algorithm is due to Feige and Singh [15]
and gives approximation (2/3) log2 n. The existence of a constant approxi-
mation for Min ATSP is an important open problem.
Turning now to reoptimization, there exists a non-negligible gap be-
tween the approximability of the static version and of the reoptimiza-

Complexity and Approximation in Reoptimization
123
tion version.
In fact, reoptimization drastically simpliﬁes the picture:
Min ATSP+ is approximable within ratio 2, as we proceed to show.
Theorem 4.13. Min ATSP+ is approximable within ratio 2.
Proof.
The algorithm used to establish the upper bound is extremely
simple: just add the new vertex between an arbitrarily chosen pair of con-
secutive vertices in the old optimal tour. Let T be the tour obtained by
inserting node n+1 between two consecutive nodes i and j in T ∗
n. We have:
w(T ) = w(T ∗
n) + d(i, n + 1) + d(n + 1, j) −d(i, j).
By triangle inequality, d(n + 1, j) ≤d(n + 1, i) + d(i, j). Hence
w(T ) ≤w(T ∗
n) + d(i, n + 1) + d(n + 1, i).
Again by triangle inequality, w(T ∗
n) ≤w(T ∗
n+1), and d(i, n+1)+d(n+1, i) ≤
w(T ∗
n+1), which concludes the proof.
□
We remark that the above upper bound of 2 on the approximation ratio
is tight, even if we use Best Insertion instead of inserting the new vertex
between an arbitrarily chosen pair of consecutive vertices.
Theorem 4.14. Min ATSP−is approximable within ratio 2.
Proof.
The obvious idea is to skip the deleted node in the new tour,
while visiting the remaining nodes in the same order. Thus, if i and j are
respectively the nodes preceding and following n + 1 in the tour T ∗
n+1, we
obtain a tour T such that
w(T ) = w(T ∗
n+1) + d(i, j) −d(i, n + 1) −d(n + 1, j).
(4.7)
Consider an optimum solution T ∗
n of the modiﬁed instance In, and the node
l that is consecutive to i in this solution. Since inserting n+1 between i and
l would yield a feasible solution to In+1, we get, using triangle inequality:
w(T ∗
n+1) ≤w(T ∗
n) + d(i, n + 1) + d(n + 1, l) −d(i, l)
≤w(T ∗
n) + d(i, n + 1) + d(n + 1, i).
By substituting in (4.7) and using triangle inequality again,
w(T ) ≤w(T ∗
n) + d(i, j) + d(j, i).
Hence, w(T ) ≤2w(T ∗
n).
□

124
G. Ausiello, V. Bonifaci, & B. Escoﬃer
4.4.2. The Maximum Traveling Salesman Problem
4.4.2.1. Maximum TSP
While the typical applications of the Minimum TSP are in vehicle rout-
ing and transportation problems, the Maximum TSP has applications to
DNA sequencing and data compression [25]. Like the Minimum TSP, the
Maximum TSP is also NP-hard, but diﬀerently from what happens for
the Minimum TSP, it is approximable within a constant factor even when
the distance matrix can be completely arbitrary. In the static setting, the
best known result for Max TSP is a 0.6-approximation algorithm due to
Kosaraju et al. [25]. Once again, the knowledge of an optimum solution to
the initial instance is useful, as the reoptimization problem under insertion
of a vertex can be approximated within a ratio of 0.66 (for large enough n),
as we show next.
Theorem 4.15. Max TSP+ is approximable within ratio (2/3) · (1 −1/n).
Proof.
Let i and j be such that (i, n + 1) and (n + 1, j) belong to T ∗
n+1.
The algorithm is the following:
(1) Apply Best Insertion to T ∗
n to get a tour T1;
(2) Find a maximum cycle cover C = (C0, . . . , Cl) on In+1 such that:
(a) (i, n + 1) and (n + 1, j) belong to C0;
(b) |C0| ≥4;
(3) Remove the minimum-weight arc of each cycle of C and patch the paths
obtained to get a tour T2;
(4) Select the best solution between T1 and T2.
Note that Step 2 can be implemented in polynomial time as follows: We
replace d(i, n + 1) and d(n + 1, j) by a large weight M, and d(j, i) by −M
(we do not know i and j, but we can try each possible pair of vertices and
return the best tour constructed by the algorithm). Hence, this cycle cover
will contain (i, n + 1) and (n + 1, j) but not (j, i), meaning that the cycle
containing n + 1 will have at least 4 vertices.
Let a := d(i, n + 1) + d(n + 1, j). Clearly, w(T ∗
n+1) ≤w(T ∗
n) + a. Now,
by inserting n + 1 in each possible position, we get
w(T1) ≥(1 −1/n)w(T ∗
n) ≥(1 −1/n)(w(T ∗
n+1) −a).
Since C0 has size at least 4, the minimum-weight arc of C0 has cost at
most (w(C0) −a)/2. Since each cycle has size at least 2, we get a tour T2

Complexity and Approximation in Reoptimization
125
of value:
w(T2) ≥w(C) −w(C0) −a
2
−w(C) −w(C0)
2
= w(C) + a
2
≥w(T ∗
n+1) + a
2
.
Combining the two bounds for T1 and T2, we get a solution which is
(2/3) · (1 −1/n)-approximate.
□
The above upper bound can be improved to 0.8 when the distance ma-
trix is known to be symmetric [5].
4.4.2.2. Maximum Metric TSP
The usual Maximum TSP problem does not admit a polynomial-time ap-
proximation scheme, that is, there exists a constant c such that it is NP-
hard to approximate the problem within a factor better than c. This result
extends also to the Maximum Metric TSP [29]. The best known approxi-
mation for the Maximum Metric TSP is a randomized algorithm with an
approximation guarantee of 7/8 [21].
By contrast, in the reoptimization of Max MTSP under insertion of a
vertex, the Best Insertion algorithm turns out to be a very good strategy:
It is asymptotically optimum. In particular, the following holds:
Theorem 4.16 ([5]). Max MTSP+ is approximable within ratio 1 −
O(n−1/2).
Using the above result one can easily prove that Max MTSP+ admits
a polynomial-time approximation scheme: If the desired approximation
guarantee is 1 −ǫ, for some ǫ > 0, just solve by enumeration the instances
with O(1/ǫ2) nodes, and use the result above for the other instances.
4.4.3. The Minimum Latency Problem
Although superﬁcially similar to the Minimum Metric TSP, the Minimum
Latency Problem appears to be more diﬃcult to solve. For example, in
the special case when the metric is induced by a weighted tree, the MLP is
NP-hard [35] while the Metric TSP is trivial. One of the diﬃculties in the
MLP is that local changes in the input can inﬂuence the global shape of the
optimum solution. Thus, it is interesting to notice that despite this fact,
reoptimization still helps. In fact, the best known approximation so far for
the static version of the MLP gives a factor of 3.59 and is achieved via a

126
G. Ausiello, V. Bonifaci, & B. Escoﬃer
sophisticated algorithm due to Chaudhuri et al. [10], while it is possible
to give a very simple 3-approximation for MLP+, as we show in the next
theorem.
Theorem 4.17. MLP+ is approximable within ratio 3.
Proof.
We consider the Insert Last algorithm that inserts the new node
n + 1 at the “end” of the tour, that is, just before node 1. Without loss
of generality, let T ∗
n = {(1, 2), (2, 3), . . ., (n −1, n)} be the optimal tour for
the initial instance In (that is, the kth node to be visited is k). Let T ∗
n+1 be
the optimal tour for the modiﬁed instance In+1. Clearly ℓ(T ∗
n+1) ≥ℓ(T ∗
n)
since relaxing the condition that node n + 1 must be visited cannot raise
the overall latency.
The quantity ℓ(T ∗
n) can be expressed as Pn
i=1 ti, where for i = 1, . . . , n,
ti = Pi−1
j=1 d(j, j + 1) can be interpreted as the “time” at which node i is
ﬁrst visited in the tour T ∗
n.
In the solution constructed by Insert Last, the time at which each node
i ̸= n + 1 is visited is the same as in the original tour (ti), while tn+1 =
tn+d(n, n+1). The latency of the solution is thus Pn+1
i=1 ti = Pn
i=1 ti+tn+
d(n, n + 1) ≤2ℓ(T ∗
n) + ℓ(T ∗
n+1) ≤3ℓ(T ∗
n+1), where we have used ℓ(T ∗
n+1) ≥
d(n, n + 1) (any feasible tour must include a subpath from n to n + 1 or
vice versa).
□
4.5. Concluding Remarks
In this chapter we have seen how the reoptimization model can often be
applied to NP-hard combinatorial problems in order to obtain algorithms
with approximation guarantees that improve upon the trivial approach of
computing an approximate solution from scratch.
Apart from designing algorithms with good approximation guarantees
for reoptimization problems – and from obtaining sharper negative results
– there are some general open directions in the area. One is to investigate
the more general issue of maintaining an approximate solution under input
modiﬁcations.
In our model we assumed that an optimal solution was
available for the instance prior to the modiﬁcation, but it is natural to
relax this constraint by assuming only an approximate solution instead. In
some cases the analysis of the reoptimization algorithm can be carried out
in a similar way even with such a relaxed assumption, but this needs not
be always true.

Complexity and Approximation in Reoptimization
127
Another general question is that of studying the interplay between run-
ning time, approximation guarantee, and amount of data perturbation. If
we devote enough running time (for example, exponential time for prob-
lems in NPO) to the solution of an instance, we can ﬁnd an optimal solution
independently of the amount of perturbation. On the other hand we saw
that for many problems it is possible to ﬁnd in polynomial time an almost
optimal solution for any slightly perturbed instance. One could expect that
there might be a general trade-oﬀbetween the amount of data perturbation
and the running time needed the reconstruct a solution of a given quality.
It would be interesting to identify problems for which such trade-oﬀs are
possible.
References
[1] C. Archetti, L. Bertazzi, and M. G. Speranza, Reoptimizing the traveling
salesman problem, Networks. 42(3), 154–159, (2003).
[2] C. Archetti, L. Bertazzi, and M. G. Speranza. Reoptimizing the 0–1 knap-
sack problem. Technical Report 267, Department of Quantitative Methods,
University of Brescia, (2006).
[3] T. Asano, K. Hori, T. Ono, and T. Hirata. A theoretical framework of hy-
brid approaches to MAX SAT. In Proc. 8th Int. Symp. on Algorithms and
Computation, pp. 153–162, (1997).
[4] G. Ausiello, P. Crescenzi, G. Gambosi, V. Kann, A. Marchetti-Spaccamela,
and M. Protasi, Complexity and approximation – Combinatorial optimiza-
tion problems and their approximability properties, Springer, Berlin, (1999).
[5] G. Ausiello, B. Escoﬃer, J. Monnot, and V. T. Paschos. Reoptimization of
minimum and maximum traveling salesman’s tours. In Proc. 10th Scandina-
vian Workshop on Algorithm Theory, pp. 196–207, (2006).
[6] M. Bartusch, R. M¨ohring, and F. J. Radermacher, Scheduling project net-
works with resource constraints and time windows, Ann. Oper. Res.. 16,
201–240, (1988).
[7] M. Bartusch, R. M¨ohring, and F. J. Radermacher, A conceptional outline
of a DSS for scheduling problems in the building industry, Decision Support
Systems. 5, 321–344, (1989).
[8] H.-J. B¨ockenhauer, L. Forlizzi, J. Hromkovic, J. Kneis, J. Kupke, G. Proietti,
and P. Widmayer. Reusing optimal TSP solutions for locally modiﬁed input
instances. In Proc. 4th IFIP Int. Conf. on Theoretical Computer Science,
pp. 251–270, (2006).
[9] H.-J. B¨ockenhauer, J. Hromkovic, T. M¨omke, and P. Widmayer. On the
hardness of reoptimization. In Proc. 34th Conf. on Current Trends in Theory
and Practice of Computer Science, pp. 50–65, (2008).
[10] K. Chaudhuri, B. Godfrey, S. Rao, and K. Talwar. Paths, trees, and mini-
mum latency tours. In Proc. 44th Symp. on Foundations of Computer Sci-

128
G. Ausiello, V. Bonifaci, & B. Escoﬃer
ence, pp. 36–45, (2003).
[11] N. Christoﬁdes. Worst-case analysis of a new heuristic for the travelling
salesman problem. Technical Report 388, Graduate School of Industrial Ad-
ministration, Carnegie-Mellon University, Pittsburgh, PA, (1976).
[12] D. Eppstein, Z. Galil, G. F. Italiano, and A. Nissenzweig, Sparsiﬁcation-
a technique for speeding up dynamic graph algorithms, J. ACM. 44(5),
669–696, (1997).
[13] B. Escoﬃer, M. Milanic, and V. T. Paschos, Simple and fast reoptimiza-
tions for the Steiner tree problem, Cahier du LAMSADE 245, LAMSADE,
Universit´e Paris-Dauphine, (2007).
[14] S. Even and H. Gazit, Updating distances in dynamic graphs, Methods Oper.
Res. 49, 371–387, (1985).
[15] U. Feige and M. Singh. Improved approximation ratios for traveling sales-
person tours and paths in directed graphs. In Proc. 10th Int. Workshop on
Approximation, Randomization, and Combinatorial Optimization, pp. 104–
118, (2007).
[16] G. N. Frederickson, Data structures for on-line updating of minimum span-
ning trees, with applications, SIAM J. Comput.. 14(4), 781–798, (1985).
[17] A. M. Frieze, G. Galbiati, and F. Maﬃoli, On the worst-case performance of
some algorithms for the asymmetric traveling salesman problem, Networks.
12(1), 23–39, (1982).
[18] C. Gr¨opl, S. Hougardy, T. Nierhof, and H. Pr¨omel. Approximation algo-
rithms for the Steiner tree problem in graphs. In eds. D.-Z. Du and X. Cheng,
Steiner Trees in Industry, pp. 235–279. Kluwer Academic Publishers, Dor-
drecht, (2000).
[19] G. Gutin and A. P. Punnen, Eds., The Traveling Salesman Problem and its
Variations. Kluwer, Dordrecht, (2002).
[20] N. G. Hall and M. E. Posner, Sensitivity analysis for scheduling problems,
J. Sched.. 7(1), 49–83, (2004).
[21] R. Hassin and S. Rubinstein, A 7/8-approximation algorithm for metric Max
TSP, Inform. Process. Lett.. 81(5), 247–251, (2002).
[22] M. R. Henzinger and V. King, Maintaining minimum spanning forests in
dynamic graphs, SIAM J. Comput.. 31(2), 367–374, (2001).
[23] O. H. Ibarra and C. E. Kim, Fast approximation algorithms for the knapsack
and sum of subset problems, J. ACM. 22(4), 463–468, (1975).
[24] D. S. Johnson, Approximation algorithms for combinatorial problems, J.
Comput. Systems Sci.. 9, 256–278, (1974).
[25] S. R. Kosaraju, J. K. Park, and C. Stein. Long tours and short superstrings.
In Proc. 35th Symp. on Foundations of Computer Science, pp. 166–177,
(1994).
[26] E. L. Lawler, J. K. Lenstra, A. Rinnoy Kan, and D. B. Shymois, Eds., The
Traveling Salesman Problem: A Guided Tour of Combinatorial Optimiza-
tion. Wiley, Chichester, (1985).
[27] J. M. Lewis and M. Yannakakis, The node-deletion problem for hereditary
properties is NP-complete, J. Comput. Systems Sci.. 20(2), 219–230, (1980).
[28] C. H. Papadimitriou and K. Steiglitz, On the complexity of local search for

Complexity and Approximation in Reoptimization
129
the traveling salesman problem, SIAM J. Comput.. 6(1), 76–83, (1977).
[29] C. H. Papadimitriou and M. Yannakakis, The traveling salesman problem
with distances one and two, Math.Oper. Res.. 18(1), 1–11, (1993).
[30] A. Paz and S. Moran, Non-deterministic polynomial optimization problems
and their approximations, Theoret. Comput. Sci.. 15, 251–277, (1981).
[31] G. Robins and A. Zelikovsky, Tighter bounds for graph Steiner tree approx-
imation, SIAM J. Discrete Math.. 19(1), 122–134, (2005).
[32] H. Rohnert. A dynamization of the all-pairs least cost problem. In Proc. 2nd
Symp. on Theoretical Aspects of Computer Science, pp. 279–286, (1985).
[33] S. Sahni and T. F. Gonzalez, P-complete approximation problems, J. ACM.
23(3), 555–565, (1976).
[34] M. W. Sch¨aﬀter, Scheduling with forbidden sets, Discrete Appl. Math.. 72
(1-2), 155–166, (1997).
[35] R. Sitters. The minimum latency problem is NP-hard for weighted trees. In
Proc. 9th Integer Programming and Combinatorial Optimization Conf., pp.
230–239, (2002).
[36] V. V. Vazirani, Approximation Algorithms. Springer, Berlin, (2001).
[37] D. Zuckerman, Linear degree extractors and the inapproximability of max
clique and chromatic number, Theory Comput.. 3(1), 103–128, (2007).

This page intentionally left blank
This page intentionally left blank

Chapter 5
Deﬁnability in the Real Universe
S. Barry Cooper ∗
Department of Pure Mathematics
University of Leeds
Leeds LS2 9JT, UK
E-mail: S.B.Cooper@leeds.ac.uk
Logic has its origins in basic questions about the nature of the real world
and how we describe it. This chapter seeks to bring out the physical and
epistemological relevance of some of the more recent technical work in
logic and computability theory.
Contents
5.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
5.2
Computability versus Descriptions . . . . . . . . . . . . . . . . . . . . . . . . 133
5.3
Turing’s Model and Incomputability . . . . . . . . . . . . . . . . . . . . . . . 133
5.4
The Real Universe as Discipline Problem
. . . . . . . . . . . . . . . . . . . . 134
5.5
A Dissenting Voice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
5.6
The Quantum Challenge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
5.7
Schr¨odinger’s Lost States, and the Many-Worlds Interpretation . . . . . . . . 139
5.8
Back in the One World . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
5.9
The Challenge from Emergence . . . . . . . . . . . . . . . . . . . . . . . . . . 142
5.10 A Test for Emergence
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
5.11 Deﬁnability the Key Concept . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
5.12 The Challenge of Modelling Mentality . . . . . . . . . . . . . . . . . . . . . . 150
5.13 Connectionist Models to the Rescue? . . . . . . . . . . . . . . . . . . . . . . . 153
5.14 Deﬁnability in What Structure? . . . . . . . . . . . . . . . . . . . . . . . . . . 156
5.15 The Turing Landscape, Causality and Emergence . . . . . . . . . . . . . . . . . 157
5.16 An Informational Universe, and Hartley Rogers’ Programme
. . . . . . . . . 159
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
∗Chapter based on an invited talk at Logic Colloquium 2009, Soﬁa, Bulgaria, August,
2009. Research supported by U.K. EPSRC grant No. GR /S28730/01, and by a Royal
Society International Collaborative Grant.
131

132
S. B. Cooper
5.1. Introduction
Logic has an impressive history of addressing very basic questions about
the nature of the world we live in. At the same time, it has clariﬁed con-
cepts and informal ideas about the world, and gone on to develop sophis-
ticated technical frameworks within which these can be discussed. Much
of this work is little known or understood by non-specialists, and the sig-
niﬁcance of it largely ignored. While notions such as set, proof and con-
sistency have become part of our culture, other very natural abstractions
such as that of deﬁnability are unfamiliar and disconcerting, even to work-
ing mathematicians. The widespread interest in G¨odel’s [46, 47] incom-
pleteness results and their frequent application, often in questionable ways,
shows both the potential for logicians to say something important about
the world, while at the same time illustrating the limitations of what has
been achieved so far. This article seeks to bring out the relevance of some
of the more recent technical work in logic and computability theory. Ba-
sic questions addressed include: How do scientists represent and establish
control over information about the universe? How does the universe it-
self exercise control over its own development? And more feasibly: How
can we reﬂect that control via our scientiﬁc and mathematical representa-
tions?
Deﬁnability – what we can describe in terms of what we are given in a
particular language – is a key notion. As Hans Reichenbach (Hilary Putnam
is perhaps his best-known student) found in the 1920s onwards, formalising
deﬁnability in the real world comes into its own when we need to clarify and
better understand the content of a hard-to-grasp description of reality, such
as Einstein’s theory of general relativity. Reichenbach’s seminal work [78]
on axiomatising relativity has become an ongoing project, carried forward
today by Istvan Nemeti, Hajnal Andreka and their co-workers (see, for ex-
ample, Andr´eka, Madar´asz, N´emeti and Sz´ekely [2]). One can think of such
work as paralleling the positive developments that models of computation
enabled during the early days of computer science, bringing a surer grip
on practical computation. But computability theory also gave an overview
of what can be computed in principle, with corresponding technical devel-
opments apparently unrelated to applications. The real-world relevance of
most of this theory remains conjectural.
The capture of natural notions of describability and real-world robust-
ness via the precisely formulated ones of deﬁnability and invariance also
brings a corresponding development of theory, which can be applied in

Deﬁnability in the Real Universe
133
diﬀerent mathematical contexts. Such an application does not just bring
interesting theorems, which one just adds to the existing body of theory
with conjectural relevance. It ﬁlls out the explanatory framework to a point
where it can be better assessed for power and validity. And it is this which
is further sketched out below. The basic ingredients are the notions of de-
ﬁnability and invariance, and a mathematical context which best describes
the scientiﬁc description of familiar causal structure.
5.2. Computability versus Descriptions
In the modern world, scientists look for theories that enable predictions,
and, if possible, predictions of a computational character. Everyone else
lives with less constrained descriptions of what is happening, and is likely
to happen. Albert Einstein [38] might have expressed the view in 1950 that:
When we say that we understand a group of natural phenomena, we
mean that we have found a constructive theory which embraces them.
But in everyday life people commonly use informal language to describe
expectations of the real world from which constructive or computational
content is not even attempted. And there is a deﬁnite mismatch between
the scientist’s drive to extend the reach of his or her methodology, and the
widespread sense of an intrusion of algorithmic thinking into areas where it
is not valid. A recent example is the controversy around Richard Dawkins’
book [32], The God Delusion. This dichotomy has some basis in theorems
from logic (such as G¨odel’s incompleteness theorems): but the basis is more
one for argument and confusion than anything more consensual. Things
were not always so.
If one goes back before the time of Isaac Newton, before the scientiﬁc
era, informal descriptions of the nature of reality were the common currency
of those trying to reason about the world. This might even impinge on
mathematics – as when the Pythagoreans wrestled with the ontology of
irrational numbers.
Calculation had a quite speciﬁc and limited role in
society.
5.3. Turing’s Model and Incomputability
In 1936, Turing [100] modelled what he understood of how a then human
“computer” (generally a young woman) might perform calculations – lay-
ing down rules that were very restrictive in a practical sense, but which

134
S. B. Cooper
enabled, as he plausibly argued, all that might be achieved with apparently
more powerful computational actions. Just as the Turing machine’s primi-
tive actions (observing, moving, writing) were the key to modelling complex
computations, so the Turing machine itself provided a route to the mod-
elling of complex natural processes within structures which are discretely
(or at least countably) presented. In this sense, it seemed we now had a way
of making concrete the Laplacian model of science which had been with us
in some form or other ever since the signiﬁcance of what Newton had done
became clear.
But the techniques for presenting a comprehensive range of computing
machines gave us the universal Turing machine, so detaching computations
from their material embodiments: and – a more uncomfortable surprise
– by adding a quantiﬁer to the perfectly down-to-earth description of the
universal machine we get (and Turing [100] proved it) an incomputable
object, the halting set of the machine. In retrospect, this becomes a vivid
indication of how natural language has both an important real-world role,
and quickly outstrips our computational reach. The need then becomes to
track down material counterpart to the simple mathematical schema which
give rise to incomputability. Success provides a link to a rich body of theory
and opens a Pandora’s box of new perceptions about the failings of science
and the nature of the real universe.
5.4. The Real Universe as Discipline Problem
The Laplacian model has a deeply ingrained hold on the rational mind. For
a bromeliad-like late ﬂowering of the paradigm we tend to think of Hilbert
and his assertion of very general expectations for axiomatic mathematics.
Or of the state of physics before quantum mechanics.
The problem is
that modelling the universe is deﬁnitely not an algorithmic process, and
that is why intelligent, educated people can believe very diﬀerent things,
even in science.
Even in mathematics.
So for many, the mathematical
phase-transition from computability to incomputability, which a quantiﬁer
provides, is banned from the real world (see for example Cotogno [24]).
However simple the mathematical route to incomputability, when looking
out at the natural world, the trick is to hold the eyeglass to an unseeing
eye. The global aspect of causality so familiar in mathematical structures
is denied a connection with reality, in any shape or form.
For a whole
community, the discovery of incomputability made the real universe a real
discipline problem. When Martin Davis [30] says:

Deﬁnability in the Real Universe
135
The great success of modern computers as all-purpose algorithm-
executing engines embodying Turing’s universal computer in physical
form, makes it extremely plausible that the abstract theory of com-
putability gives the correct answer to the question, ‘What is a compu-
tation?’, and, by itself, makes the existence of any more general form of
computation extremely doubtful.
we have been in the habit of agreeing, in a mathematical setting. But in
the context of a general examination of hypercomputational propositions
(whatever the validity of the selected examples) it gives the deﬁnite im-
pression of a defensive response to an uncompleted paradigm change. For
convenience, we call this response [31] – that ‘there is no such discipline as
hypercomputation’ - Davis’ Thesis.
The universal Turing machine freed us from the need actually embody
the machines needed to host diﬀerent computational tasks. The importance
of this for building programmable computers was immediately recognised by
John von Neuman, and played a key role in the early history of the computer
(see Davis [29]). The notion of a virtual machine is a logical extension of this
tradition, which has found widespread favour amongst computer scientists
and philosophers of a functionalist turn of mind – for instance, there is the
Sloman and Chrisley [89] proposition for releasing consciousness from the
philosophical inconvenience of embodiment (see also Torrance, Clowes and
Chrisley [99]). Such attempts to tame nature are protected by a dominant
paradigm, but there is plenty of dissatisfaction with them based on respect
for the complex physicality of what we see.
5.5. A Dissenting Voice . . .
Back in 1970, Georg Kreisel considered one of the simplest physical situa-
tions presenting mathematical predictive problems. Contained within the
mathematics one detects uncompleted inﬁnities of the kind necessary for
incomputability to have any signiﬁcance for the real world. In a footnote to
Kreisel [56] he proposed a collision problem related to the 3-body problem,
which might result in ‘an analog computation of a non-recursive function’.
Even though Kreisel’s view was built on many hours of deep thought
about extensions of the Church–Turing thesis to the material universe –
much of this embodied in Odifreddi’s 20-page discussion of the Church–
Turing thesis in his book [69] on Classical Recursion Theory – it is not
backed up by any proof of of the inadequacy of the Turing model built on
a precise description of the collision problem.

136
S. B. Cooper
This failure has become a familiar one, what has been described as a
failure to ﬁnd ‘natural’ examples of incomputability other than those com-
putably equivalent to the halting problem for a universal Turing machine
– with even that not considered very natural by the mainstream mathe-
matician. One requirement of a ‘natural’ incomputable set is that it be
computably enumerable, like the set of solutions of a diophantine equation,
or the set of natural numbers n such that there exists a block of precisely
n 7s in the decimal expansion of the real number π – or like the halting
set of a given Turing machine. The problem is that given a computably
enumerable set of numbers, there are essentially two ways of knowing its
incomputability. One way is to have designed the set oneself to have comple-
ment diﬀerent to any other set on a standard list of computably enumerable
sets. Without working relative to some other incomputable set, one just
gets canonical sets computably equivalent to the halting set of the universal
Turing machine. Otherwise the set one built has no known robustness, no
deﬁnable character one can recognise it by once it is built. The other way
of knowing a particular computably enumerable set to be incomputable is
to be able to compute one of the sets built via way one from the given set.
But only the canonical sets have been found so far to work in this way. So
it is known that there is a whole rich universe of computably inequivalent
computably enumerable sets – but the only individual ones recognisably
so are computably equivalent to the halting problem. Kreisel’s failure is
not so signiﬁcant when one accepts that an arbitrary set picked from na-
ture in some way is very unlikely to be a mathematically canonical object.
It seems quite feasible that there is a mathematical theorem waiting to
be proved, explaining why there is no accessible procedure for verifying
incomputability in nature.
Since Kreisel’s example, there have been other striking instances of in-
ﬁnities in nature with the potential for hosting incomputability. In Oﬀto
Inﬁnity in Finite Time Donald Saari and JeﬀXia [86] describe how one can
even derive singularities arising from the behaviour of ﬁve bodies moving
under the inﬂuence of the familiar Newtonian inverse square law.
There is a range of more complex examples which are hard to ﬁt into
the standard Turing model, ones with more real-world relevance. There is
the persistence of problems of predictability in a number of contexts. There
is quantum uncertainty, constrained by computable probabilities, but host-
ing what looks very much like randomness; there are apparently emergent
phenomena in many environments; and chaotic causal environments giving
rise to strange attractors; and one has relativity and singularities (black

Deﬁnability in the Real Universe
137
holes), whose singular aspects can host incomputability. Specially inter-
esting is the renewed interest in analog and hybrid computing machines,
leading Jan van Leeuwen and Jiri Wiedermann [105] to observe that ‘. . . the
classical Turing paradigm may no longer be fully appropriate to capture all
features of present-day computing.’ And – see later – there is mentality,
consciousness and the observed shortcomings of the mathematical models
of these.
The disinterested observer of Martin Davis’ eﬀorts to keep nature con-
tained within the Turing/Laplacian model might keep in mind the well-
known comment of Arthur C. Clarke [16] (Clarke’s First Law) that:
When a distinguished but elderly scientist states that something is pos-
sible, he is almost certainly right.
When he states that something is
impossible, he is very probably wrong.
In what follows we look in more detail at three key challenges to the
attachment of Davis, and of a whole community, to the Turing model in
the form of Davis’ thesis.
There is a reason for this. At ﬁrst sight, it may seem unimportant to
know whether we have computational or predictive diﬃculties due to mere
complexity of a real-world computational task, or because of its actual in-
computability. And if there is no distinguishable diﬀerence between the two
possibilities, surely it cannot matter which pertains. Well, no. Attached
to two diﬀerent mathematical characterisations one would expect diﬀerent
mathematical theories. And there is a rich and well-developed theory of in-
computability. This mathematics may well constrain and give global form
to the real world which it underlies. And these constraints and structur-
ings may be very signiﬁcant for our experience and understanding of the
universe and our place in it.
5.6. The Quantum Challenge
In the early days of quantum computing, there was some good news for
Davis’ thesis from one of its most prominent supporters. David Deutsch
was one of the originators of the standard model of quantum computa-
tion. In his seminal 1985 article [33] ‘Quantum Theory, the Church-Turing
Principle and the Universal Quantum Computer’ in the Proceedings of the
Royal Society of London, he introduced the notion of a ‘universal quantum
computer’, and described how it might exploit quantum parallelism to com-
pute more eﬃciently than a classical Turing machine. But Deutsch is quite

138
S. B. Cooper
clear that real computers based on this model would not compute anything
not computable classically by a Turing machine.
And, of course, there
are many other instances of successful reductions of ‘natural examples’ of
nature-based computational procedures to the Turing model.
But like Martin Davis, Deutsch [35] is keen to take things further – a lot
further – attempting a reduction of human mentality to the Turing model
in a way even Turing in his most constructive frame of mind might have
had misgivings about:
I am sure we will have [conscious computers], I expect they will be purely
classical and I expect that it will be a long time in the future. Signiﬁcant
advances in our philosophical understanding of what consciousness is,
will be needed.
Be this as it may, there are aspects of the underlying physics which are
not fully used in setting up the standard model for quantum computing. It
is true that measurements do play a role in a quantum computation, but in
a tamed guise. This is how Andrew Hodges explains it, in his article What
would Alan Turing have done after 1954? in the Teuscher volume [98]:
Von Neumann’s axioms distinguished the U (unitary evolution) and R
(reduction) rules of quantum mechanics. Now, quantum computing so
far (in the work of Feynman, Deutsch, Shor, etc.) is based on the U
process and so computable. It has not made serious use of the R process:
the unpredictable element that comes in with reduction, measurement
or collapse of the wave function.
The point being that measurements in the quantum context are intrusive,
with outcomes governed by computable probabilities, but with the mapping
out of what goes on within those probabilities giving the appearance of ran-
domness. There are well-established formalisations of the intuitive notion
of randomness, largely coincident and a large body of mathematical theory
built on these (see, for example, Chaitin [15], Downey and Hirschfeldt [36],
Nies [67]). A basic feature of the theory is the fact that randomness im-
plies incomputability (but not the converse). Calude and Svozil [14] have
extracted a suitable mathematical model of quantum randomness, built
upon assumptions generally acceptable to the physicists.
Analysing the
computability-theoretic properties of the model, they are able to show that
quantum randomness does exhibit incomputability. But, interestingly, they
are unable as yet to conﬁrm that quantum randomness is mathematically
random.

Deﬁnability in the Real Universe
139
But quantum mechanics does not just present one of the toughest chal-
lenges to Davis’ thesis. It also presents the observer with a long-standing
challenge to its own realism. Interpretations of the theory generally fail
to satisfy everyone, and the currently most widely accepted interpretations
contain what must be considered metaphysical assumptions. When we have
assembled the key ingredients, we will be in a position to argue that the sort
of fundamental thinking needed to rescue the theory from such assumptions
is based on some very basic mathematics.
5.7. Schr¨odinger’s Lost States, and the Many-Worlds Inter-
pretation
One way of describing the quantum world is via the Schr¨odinger wave equa-
tion. What Hodges refers to above are the processes for change of the wave
equation describing the quantum state of a physical system. On the one
hand, one has deterministic continuous evolution via Schr¨odinger’s equa-
tion, involving superpositions of basis states. On the other, one has proba-
bilistic non-local discontinuous change due to measurement. With this, one
observes a jump to a single basis state. The interpretive question then is:
Where do the other states go?
Writing with hindsight: If the physicists knew enough logic, they would
have been able to make a good guess. And if the logicians had been focused
enough on the foundations of quantum mechanics they might have been able
to tell them.
As it is, physics became a little weirder around 1956. The backdrop to
this is the sad and strange life-story of Hugh Everett III and his family,
through which strode the formidable John Wheeler, Everett’s ﬁnal thesis
advisor, and Bryce DeWitt, who in 1970 coined the term ‘Many-Worlds’
for Everett’s neglected and belittled idea: an idea whose day came too late
to help the Everett family, now only survived by the son Mark who relives
parts of the tragic story via an autobiography [42] and appropriately left
ﬁeld confessional creations as leader of the Eels rock band.
Many-Worlds, with a little reworking, did away with the need to explain
the transition from many superposed quantum states to the ‘quasi-classical’
uniqueness we see around us.
The multiplicity survives and permeates
micro- to macro-reality, via a decohering bushy branching of alternative
histories, with us relegated to our own self-contained branch. Max Tegmark
has organised the multiplying variations on the Many-Worlds theme into
hierarchical levels of ‘multiverses’, from modest to more radical proposals,

140
S. B. Cooper
with even the underlying mathematics and the consequent laws of physics
individuating at Level IV. Of course, if one does not bother any more to
explain why our universe works so interestingly, one needs the ‘anthropic
principle’ on which to base our experience of the world – ‘We’re here because
we’re here because we’re here because we’re here . . . ’, as they sang during
the Great War, marching towards the trenches.
The attraction of this
picture derives from the drive for a coherent overview, and the lack of a
better one. As David Deutsch put it in The Fabric of Reality [34, p.48]:
. . . understanding the multiverse is a precondition for understanding re-
ality as best we can. Nor is this said in a spirit of grim determination to
seek the truth no matter how unpalatable it may be . . . It is, on the con-
trary, because the resulting world-view is so much more integrated, and
makes more sense in so many ways, than any previous world-view, and
certainly more than the cynical pragmatism which too often nowadays
serves as surrogate for a world-view amongst scientists.
Here is a very diﬀerent view of the multiverse from the distinguished
South African mathematician George Ellis [40, p.198], one-time collabora-
tor of Stephen Hawking:
The issue of what is to be regarded as an ensemble of ‘all possible’
universes is unclear, it can be manipulated to produce any result you
want . . . The argument that this inﬁnite ensemble actually exists can
be claimed to have a certain explanatory economy (Tegmark 1993),
although others would claim that Occam’s razor has been completely
abandoned in favour of a proﬂigate excess of existential multiplicity, ex-
travagantly hypothesized in order to explain the one universe that we do
know exists.
The way out of this foundational crisis, as with previous ones in mathe-
matics and science, is to adopt a more constructive approach. In this way,
one can combine the attractions of Tegmark’s [96] Mathematical Universe
Hypothesis (MUH) with the discipline one gets from the mathematics of
what can be built from very small beginnings.
5.8. Back in the One World . . .
A constructive approach is not only a key to clarifying the interpretive
problem. Eliminating the redundancy of parallel universes, and the reliance
on the anthropic principle, also entails the tackling of the unsatisfactory
arbitrariness of various aspects of the standard model. The exact values
of the constants of nature, subatomic structure, the geometry of space –

Deﬁnability in the Real Universe
141
all confront the standard model of particle physics with a foundational
problem.
Alan Guth, inventor of the ‘cosmic inﬂation’ needed to make
sense of our picture of the early universe, asks [48]:
If the creation of the universe can be described as a quantum process,
we would be left with one deep mystery of existence: What is it that
determined the laws of physics?
And Peter Woit, in his recent book [106] Not Even Wrong – The Failure of
String Theory and the Continuing Challenge to Unify the Laws of Physics,
comments on the arbitrary constants one needs to give the right values to
get the standard model to behave properly:
One way of thinking about what is unsatisfactory about the standard
model is that it leaves seventeen non-trivial numbers still to be explained,
. . .
Even though the exact number of constants undetermined by theory, but
needing special ﬁne-tuning to make the standard model ﬁt with observa-
tion, does vary, even one is too many. This dissatisfaction with aspects of
the standard model goes back to Einstein. Quoting from Einstein’s Auto-
biographical Notes [39, p.63]:
. . . I would like to state a theorem which at present can not be based upon
anything more than upon a faith in the simplicity, i.e. intelligibility, of
nature . . . nature is so constituted that it is possible logically to lay down
such strongly determined laws that within these laws only rationally
completely determined constants occur (not constants, therefore, whose
numerical value could be changed without destroying the theory) . . .
What is needed is mathematics which does more than express mecha-
nistic relationships between basic entities. One needs theory expressed in
language strong enough to encapsulate not just relations on the material
world, but relations on such relations – relations which entail qualiﬁcations
sophisticated enough to determine all aspects of the our universe, including
the laws of nature themselves. Or, as Roger Penrose terms it [70, pp. 106–
107], we need to capture Strong Determinism, whereby:
. . . all the complication, variety and apparent randomness that we see all
about us, as well as the precise physical laws, are all exact and unam-
biguous consequences of one single coherent mathematical structure.
The article [13] of Calude, Campbell, Svozil and Stefanescu on Strong deter-
minism vs. computability contains a useful discussion of the computability-
theoretic ramiﬁcations of strong determinism.

142
S. B. Cooper
In the next section we examine some more approachable phenomena
than those at the quantum level. Even though the challenge these present
to Davis’ Thesis is less obvious than that of quantum uncertainty, they do
point us in the direction of the mathematics needed to make sense of strong
determinism.
5.9. The Challenge from Emergence
The waves on the seashore, the clouds scudding across the sky, the com-
plexity of the Mandelbrot set – observing these, one is made aware of limits
on what we can practically compute. The underlying rules governing them
are known, but that is not enough. When we talk about the problem of
‘seeing the wood for the trees’ we are approaching the gap between micro
and macro events from another direction. Either way, there are commonly
encountered situations in which either reduction, or seeing the ‘big picture’,
entails more than a computation.
Although an interest in such things goes back to Poincar´e – we already
mentioned the 3-body problem – it was the second half of the twentieth
century saw the growth of chaos theory, and a greater of awareness of
the generation of informational complexity via simple rules, accompanied
by the emergence of new regularities. The most mundane and apparently
uncomplicated situations could provide examples, such as Robert Shaw’s
[87] strange attractor arising from an appropriately paced dripping tap.
And inhospitable as turbulent ﬂuids might appear, there too higher order
formations might emerge and be subject to mathematical description, as
demonstrated by David Ruelle (see Ruelle [85]) another early pioneer in the
area. Schematic metaphors for such examples are provided by the cellular
automaton (CA) model, and famously by John Conway’s Game of Life.
Here is the musician Brian Eno [41] talking in relation to how his creative
work on ‘generative music’ was inﬂuenced by ‘Life’:
These are terribly simple rules and you would think it probably couldn’t
produce anything very interesting. Conway spent apparently about a
year ﬁnessing these simple rules. . . . He found that those were all the
rules you needed to produce something that appeared life-like.
What I have over here, if you can now go to this Mac computer, please.
I have a little group of live squares up there. When I hit go I hope they
are going to start behaving according to those rules. There they go. I’m
sure a lot of you have seen this before. What’s interesting about this is
that so much happens. The rules are very, very simple, but this little
population here will reconﬁgure itself, form beautiful patterns, collapse,

Deﬁnability in the Real Universe
143
open up again, do all sorts of things. It will have little pieces that wander
around, like this one over here. Little things that never stop blinking, like
these ones. What is very interesting is that this is extremely sensitive to
the conditions in which you started. If I had drawn it one dot diﬀerent
it would have had a totally diﬀerent history. This is I think counter-
intuitive. One’s intuition doesn’t lead you to believe that something like
this would happen.
Margaret Boden and Ernest Edmonds [7] make a case for generative art,
emergent from automata-like computer environments, really qualifying as
art. While computer pioneer Konrad Zuse was impressed enough by the
potentialities of cellular automata to suggest [107] that the physics of the
universe might be CA computable.
An especially useful key to a general mathematical understanding of
such phenomena is the well-known link between emergent structures in
nature, and familiar mathematical objects, such as the Mandelbrot and
Julia sets. These mathematical metaphors for real-world complexity and
associated patterns have caught the attention of many – such as Stephen
Smale [6] and Roger Penrose – as a way of getting a better grip on the
computability/complexity of emergent phenomena.
Here is Penrose [71]
describing his fascination with the Mandelbrot set:
Now we witnessed . . . a certain extraordinarily complicated looking set,
namely the Mandelbrot set. Although the rules which provide its deﬁni-
tion are surprisingly simple, the set itself exhibits an endless variety of
highly elaborate structures.
As a mathematical analogue of emergence in nature, what are the dis-
tinctive mathematical characteristics of the Mandelbrot set? It is derived
from a simple polynomial formula over the complex numbers, via the ad-
dition of a couple of quantiﬁers.
In fact, with a little extra work, the
quantiﬁers can be reduced to just one. This gives the deﬁnition the aspect
of a familiar object from classical computability theory – namely, a Π0
1 set.
Which is just the level at which we might not be surprised to encounter
incomputability. But we have the added complication of working with real
(via complex) numbers rather than just the natural numbers. This creates
room for a certain amount of controversy around the use of the BSS model
of real computation (see Blum, Cucker, Shub and Smale [6]) to show the
incomputability of the Mandelbrot set and most Julia sets. The 2009 book
by Mark Braverman and Michael Yampolsky [9] on Computability of Julia
Sets is a reliable guide to recent results in the area, including those using
the more mainstream computable analysis model of real computation. The

144
S. B. Cooper
situation is not simple, and the computability of the Mandelbrot set, as of
now, is still an open question.
What is useful, in this context, is that these examples both connect
with emergence in nature, and share logical form with well-known objects
which transcend the standard Turing model. As such, they point to the role
of extended language in a real context taking us beyond models which are
purely mechanistic. And hence give us a route to mathematically capturing
the origins of emergence in nature, and to extending our understanding of
how nature computes.
We can now view the halting set of a universal
Turing machine as an emergent phenomenon, despite it not being as pretty
visually as our Mandelbrot and Julia examples.
One might object that there is no evidence that quantiﬁers and other
globally deﬁned operations have any existence in nature beyond the minds
of logicians. But how does nature know anything about any logical con-
struct? The basic logical operations derive their basic status from their as-
sociation with elementary algorithmic relationships over information. Con-
junction signiﬁes an appropriate and very simple merging of information,
of the kind commonly occurring in nature. Existential quantiﬁcation ex-
presses projection, analogous to a natural object throwing a shadow on a
bright sunny day. And if a determined supporter of Davis’ Thesis plays at
God, and isolates a computational environment with the aim of bringing
it within the Turing model, then the result is the delivery of an identity
to that environment, the creating a natural entity – like a human being,
perhaps – with undeniable naturally emergent global attributes.
There are earlier, less schematic approaches to the mathematics of emer-
gence, ones which ﬁt well with the picture so far.
It often happens that when one gets interested in a particular aspect of
computability, one ﬁnds Alan Turing was there before us. Back in the 1950s,
Turing proposed a simple reaction–diﬀusion system describing chemical re-
actions and diﬀusion to account for morphogenesis, i.e. the development
of form and shape in biological systems. One can ﬁnd a full account of
the background to Turing’s seminal intervention in the ﬁeld at Jonathan
Swinton’s well-documented webpage [95] on Alan Turing and morphogene-
sis. One of Turing’s main achievements was to come up with mathematical
descriptions – diﬀerential equations – governing such phenomena as Fi-
bonacci phyllotaxis: the surprising showing of Fibonacci progressions in
such things as the criss-crossing spirals of a sunﬂower head. As Jonathan
Swinton describes:

Deﬁnability in the Real Universe
145
In his reaction-diﬀusion system [Turing] had the ﬁrst and one of the most
compelling models mathematical biology has devised for the creation
process. In his formulation of the Hypothesis of Geometrical Phyllotaxis
he expressed simple rules adequate for the appearance of Fibonacci pat-
tern. In his last, unﬁnished work he was searching for plausible reasons
why those rules might hold, and it seems only in this that he did not
succeed. It would take many decades before others, unaware of his full
progress, would retrace his steps and ﬁnally pass them in pursuit of a
rather beautiful theory.
Most of Turing’s work in this area was unpublished in his lifetime, only
appearing in 1992 in the Collected Works [103]. Later work, coming to
fruition just after Turing died, was carried forward by his student Bernard
Richards, appearing in his thesis [79]. See Richards [80] for an interesting
account of Richards’ time working with Turing.
The ﬁeld of synergetics, founded by the German physicist Hermann
Haken, provides another mathematical approach to emergence. Synergetics
is a multi-disciplinary approach to the study of the origins and evolution of
macroscopic patterns and spacio-temporal structures in interactive systems.
An important feature of synergetics for our purposes is its focus on self-
organisational processes in science and the humanities, particularly that of
autopoiesis. An instance of an autopoietic system is a biological cell, and
is distinguished by being suﬃciently autonomous and operationally closed,
to recognisably self-reproduce.
A particularly celebrated example of the technical eﬀectiveness of the
theory is Ilya Prigogine’s achievement of the Nobel Prize for Chemistry
in 1977 for his development of dissipative structure theory and its appli-
cation to thermodynamic systems far from equilibrium, with subsequent
consequences for self-organising systems. Nonlinearity and irreversibility
are associated key aspects of the processes modelled in this context.
See Michael Bushev’s comprehensive review of the ﬁeld in his book [12]
Synergetics – Chaos, Order, Self-Organization. Klaus Mainzer’s book [61]
on Thinking in Complexity: The Computational Dynamics of Matter, Mind,
and Mankind puts synergetics in a wider context, and mentions such things
as synergetic computers.
The emphasis of the synergetists on self-organisation in relation to the
emergence of order from chaos is important in switching attention from the
surprise highlighted by so many accounts of emergence, to the autonomy
and internal organisation intrinsic to the phenomenon.
People like Pri-
gogine found within synergetics, as did Turing for morphogenesis, precise

146
S. B. Cooper
descriptions of previously mysteriously emergent order.
5.10. A Test for Emergence
There is a problem with the big claims made for emergence in many diﬀerent
contexts. Which is that, like with ‘life’, nobody has a good deﬁnition of
it. Sometimes, this does matter. Apart from which, history is littered with
instances of vague concepts clariﬁed by science, with huge beneﬁts to our
understanding of the world and to the progress of science and technology.
The clariﬁcation of what we mean by a computation, and the subsequent
development of the computer and computer science is a specially relevant
example here. Ronald C. Arkin, in his book [3, p.105] Behaviour-Based
Robotics, summarises the problem as it relates to emergence:
Emergence is often invoked in an almost mystical sense regarding the
capabilities of behavior-based systems.
Emergent behavior implies a
holistic capability where the sum is considerably greater than its parts.
It is true that what occurs in a behavior-based system is often a surprise
to the system’s designer, but does the surprise come because of a short-
coming of the analysis of the constituent behavioral building blocks and
their coordination, or because of something else?
There is a salutary warning from the history of British Emergentists,
who had their heyday in the early 1920s – Brian McLaughlin’s book [64].
The notion of emergence has been found to be a useful concept from at
least the time of John Stuart Mill, back in the nineteenth century. The
emergentists of the 1920s used the concept to explain the irreducibility
of the ‘special sciences’, postulating a hierarchy with physics at the bot-
tom, followed by chemistry, biology, social science etc.
The emergence
was seen, anticipating modern thinking, as being irreversible, imposing the
irreducibility of say biology to quantum theory. Of course the British emer-
gentists experienced their heyday before the great quantum discoveries of
the late 1920s, and as described in McLaughlin [64], this was in a sense their
undoing. One of the leading ﬁgures of the movement was the Cambridge
philosopher C. D. Broad, described by Graham Farmelo in his biography
of Paul Dirac [43, p.39] as being, in 1920, ‘one of the most talented young
philosophers working in Britain’. In many ways a precursor of the current
philosophers arguing for the explanatory role of emergence in the philosophy
of mind, Charlie Broad was alive to the latest scientiﬁc developments, lec-
turing to the young Paul Dirac on Einstein’s new theory of relativity while
they were both at Bristol. But here is Broad writing in 1925 [10, p.59]

Deﬁnability in the Real Universe
147
about the ‘emergence’ of salt crystals:
. . . the characteristic behaviour of the whole . . . could not, even in theory,
be deduced from the most complete knowledge of the behaviour of its
components . . . This . . . is what I understand by the ‘Theory of Emer-
gence’.
I cannot give a conclusive example of it, since it is a matter
of controversy whether it actually applies to anything . . . I will merely
remark that, so far as I know at present, the characteristic behaviour of
Common Salt cannot be deduced from the most complete knowledge of
the properties of Sodium in isolation; or of Chlorine in isolation; or of
other compounds of Sodium, . . .
The date 1925 is signiﬁcant of course. It was in the years following that
Dirac and others developed the quantum mechanics which would explain
much of chemistry in terms of locally described interactions between sub-
atomic particles. The reputation of the emergentists, for whom such ex-
amples had been basic to their argument for the far-reaching relevance of
emergence, never quite recovered.
For Ronald, Sipper and Capcarr`ere in 1999, Turing’s approach to pin-
ning down intelligence in machines suggested a test for emergence. Part
of the thinking would have been that emergence, like intelligence, is some-
thing we as observers think we can recognise; while the complexity of what
we are looking for resists observer-independent analysis. The lesson is to
police the observer’s evaluation process, laying down some optimal rules for
a human observer. Of course, the Turing Test is specially appropriate to
its task, our own experience of human intelligence making us well qualiﬁed
to evaluate the putative machine version. Anyway, the Emergence Test
of Ronald, Sipper and Capcarr`ere [83] for emergence being present in a
system, modelled on the Turing Test, had the following three ingredients:
(1) Design: The system has been constructed by the designer, by describ-
ing local elementary interactions between components (e.g. artiﬁcial
creatures and elements of the environment) in a language L1.
(2) Observation: The observer is fully aware of the design, but describes
global behaviours and properties of the running system, over a period
of time, using a language L2.
(3) Surprise: The language of design L1 and the language of observation
L2 are distinct, and the causal link between the elementary interactions
programmed in L1 and the behaviours observed in L2 is non-obvious
to the observer – who therefore experiences surprise. In other words,
there is a cognitive dissonance between the observer’s mental image of

148
S. B. Cooper
the system’s design stated in L1 and his contemporaneous observation
of the system’s behaviour stated in L2.
Much of what we have here is what one would expect, extracting the
basic elements of the previous discussion, and expressing it from the point
of view of the assumed observer. But an ingredient which should be noted is
the formal distinction between the language L1 of the design and that of the
observer, namely L2. This ﬁts in with our earlier mathematical examples:
the halting set of a universal Turing machine, and the Mandelbrot set,
where the new language is got by adding a quantiﬁer – far from a minor
augmentation of the language, as any logician knows. And it points to the
importance of the language used to describe the phenomena, an emphasis
underying the next section.
5.11. Deﬁnability the Key Concept
We have noticed that it is often possible to get descriptions of emergent
properties in terms of the elementary actions from which they arise. For
example, this is what Turing did for the role of Fibonacci numbers in re-
lation to the sunﬂower etc. This is not unexpected, it is characteristic of
what science does. And in mathematics, it is well known that complicated
descriptions may take us beyond what is computable. This could be seen
as a potential source of surprise in emergence.
But one can turn this viewpoint around, and get something more basic.
There is an intuition that entities do not just generate descriptions of the
rules governing them: they actually exist because of, and according to
mathematical laws. And that for entities that we can be aware of, these
will be mathematical laws which are susceptible to description. That it is
the describability that is key to their observability. But that the existence of
such descriptions is not enough to ensure we can access them, even though
they have algorithmic content which provides the stuﬀof observation.
It is hard to for one to say anything new. In this case Leibniz was there
before us, essentially with his Principle of Suﬃcient Reason. According to
Leibniz [60] in 1714:
. . . there can be found no fact that is true or existent, or any true propo-
sition, without there being a suﬃcient reason for its being so and not
otherwise, although we cannot know these reasons in most cases.
Taking this a little further – natural phenomena not only generate descrip-
tions, but arise and derive form from them.
And this connects with a

Deﬁnability in the Real Universe
149
useful abstraction – that of mathematical deﬁnability, or, more generally,
invariance under the automorphisms of the appropriate structure. So giving
precision to our experience of emergence as a potentially non-algorithmic
determinant of events.
This is a familiar idea in the mathematical context. The relevance of
deﬁnability for the real world is implicitly present in Hans Reichenbach’s
work [78] on the axiomatisation of relativity. It was, of course, Alfred Tarski
who gave a precise logical form to the notion of deﬁnability. Since then
logicians have worked within many diﬀerent mathematical structures, suc-
ceeding in showing that diﬀerent operations and relations are non-trivially
deﬁnable, or in some cases undeﬁnable, in terms of given features of the
structure. Another familiar feature of mathematical structures is the rela-
tionship between deﬁnability within the structure and the decidability of its
theory (see Marker [62]), giving substance to the intuition that knowledge
of the world is so hard to capture, because so much can be observed and
described. Tarski’s proof of decidability of the real numbers, contrasting
with the undecidability of arithmetic, ﬁts with the fact that one cannot
even deﬁne the integers in the structure of the real numbers.
Unfortunately, outside of logic, and certainly outside of mathematics,
the usefulness of deﬁnability remains little understood. And the idea that
features of the real world may actually be undeﬁnable is, like that of in-
computability, a recent and unassimilated addition to our way of looking
at things.
At times, deﬁnability or its breakdown comes disguised within quite
familiar phenomena. In science, particularly in basic physics, symmetries
play an important role. One might be surprised at this, wondering where
all these often beautiful and surprising symmetries come from.
Maybe
designed by some higher power? In the context of a mathematics in which
undeﬁnability and nontrivial automorphisms of mathematical structures
is a common feature, such symmetries lose their unexpectedness. When
Murray Gell-Mann demonstrated the relevance of SU(3) group symmetries
to the quark model for classifying of elementary particles, it was based
on lapses in deﬁnability of the strong nuclear force in relation to quarks
of diﬀering ﬂavour. The automorphisms of which such symmetries are an
expression give a clear route from fundamental mathematical structures and
their automorphism groups to far-reaching macro-symmetries in nature. If
one accepts that such basic attributes as position can be subject to failures
of deﬁnability, one is close to restoring realism to various basic sub-atomic
phenomena.

150
S. B. Cooper
One further observation: identifying emergent phenomena with material
expressions of deﬁnable relations suggests an accompanying robustness of
such phenomena. One would expect the mathematical characterisation to
strip away much of the mystery which has made emergence so attractive to
theologically inclined philosophers of mind, such as Samuel Alexander [1,
p.14]:
The argument is that mind has certain speciﬁc characters to which there
is or even can be no neural counterpart . . . Mind is, according to our
interpretation of the facts, an ‘emergent’ from life, and life an emergent
from a lower physico-chemical level of existence.
And further [1, p.428]:
In the hierarchy of qualities the next higher quality to the highest at-
tained is deity. God is the whole universe engaged in process towards the
emergence of this new quality, and religion is the sentiment in us that
we are drawn towards him, and caught in the movement of the world to
a higher level of existence.
In contrast, here is Martin Nowak, Director of the Program for Evolu-
tionary Dynamics at Harvard University, writing in the collection [11] What
We Believe But Cannot Prove, describing the sort of robustness we would
expect:
I believe the following aspects of evolution to be true, without knowing
how to turn them into (respectable) research topics.
Important steps in evolution are robust. Multicellularity evolved at least
ten times. There are several independent origins of eusociality. There
were a number of lineages leading from primates to humans.
If our
ancestors had not evolved language, somebody else would have.
What is meant by robustness here is that there is mathematical content
which enables the process to be captured and moved between diﬀerent
platforms; though it says nothing about the relevance of embodiment or the
viability of virtual machines hostable by canonical machines. We return to
this later. On the other hand, it gives us a handle on representability of
emergent phenomena, a key aspect of intelligent computation.
5.12. The Challenge of Modelling Mentality
Probably the toughest environment in which to road-test the general math-
ematical framework we have associated with emergence is that of human
mental activity. What about the surprise ingredient of the Emergence Test?

Deﬁnability in the Real Universe
151
Mathematical thinking provides an environment in which major in-
gredients – Turing called them intuition and ingenuity, others might call
them creativity and reason – are easier to clearly separate.
A classical
source of information and analysis of such thinking is the French mathe-
matician Jacques Hadamard’s The Psychology of Invention in the Math-
ematical Field [49], based on personal accounts supplied by distinguished
informants such as Poincar´e, Einstein and Polya. Hadamard was particu-
larly struck by Poincar´e’s thinking, including a 1908 address of his to the
French Psychological Society in Paris on the topic of Mathematical Cre-
ation. Hadamard followed Poincar´e and Einstein in giving an important
role to unconscious thought processes, and their independence of the role
of language and mechanical reasoning. This is Hadamard’s account, built
on that of Poincar´e [73], of Poincar´e’s experience of struggling with a prob-
lem:
At ﬁrst Poincar´e attacked [a problem] vainly for a fortnight, attempting
to prove there could not be any such function . . . [quoting Poincar´e]:
“Having reached Coutances, we entered an omnibus to go some place or
other. At the moment when I put my foot on the step, the idea came to
me, without anything in my former thoughts seeming to have paved the
way for it . . . I did not verify the idea . . . I went on with a conversation
already commenced, but I felt a perfect certainty. On my return to Caen,
for conscience sake, I veriﬁed the result at my leisure.”
This experience will be familiar to most research mathematicians – the
period of incubation, the failure of systematic reasoning and the surprise
element in the ﬁnal discovery of the solution: a surprise that may, over a
lifetime, lose some of its bite with repetition and familiarity, but which one
is still compelled to recognise as being mysterious and worthy of surprise.
Anyway, the important third part of the Emergence Test is satisﬁed here.
Perhaps even more striking is the fact that Poincar´e’s solution had that
robustness we looked for earlier: the solution came packaged and mentally
represented in a form which enabled it to be carried home and unpacked
intact when back home. Poincar´e just carried on with his conversation on
the bus, his friend presumably unaware of the remarkable thoughts coursing
through the mathematician’s mind.
Another such incident emphasises the lack of uniqueness and the spe-
cial character of such incidents – Jacques Hadamard [49] quoting Poincar´e
again:

152
S. B. Cooper
“Then I turned my attention to the study of some arithmetical questions
apparently without much success . . . Disgusted with my failure, I went
to spend a few days at the seaside and thought of something else. One
morning, walking on the bluﬀ, the idea came to me, with just the same
characteristics of brevity, suddenness and immediate certainty, that the
arithmetic transformations of indeﬁnite ternary quadratic forms were
identical with those of non-Euclidian geometry.”
What about the design, and the observer’s awareness of the design?
Here we have a large body of work , most notably from neuro-scientists and
philosophers, and an increasingly detailed knowledge of the workings of the
brain. What remains in question – even accepting the brain as the design
(not as simple as we would like!) – is the exact nature of the connection
between the design and the emergent level of mental activity. This is an
area where the philosophers pay an important role in clarifying problems
and solutions, while working through consequences and consistencies.
The key notion, providing a kind of workspace for working through alter-
natives, is that of supervenience. According to Jaegwon Kim [53, pp.14–15],
supervenience:
. . . represents the idea that mentality is at bottom physically based, and
that there is no free-ﬂoating mentality unanchored in the physical nature
of objects and events in which it is manifested.
There are various formulations. This one is from the online Stanford En-
cyclopedia of Philosophy:
A set of properties A supervenes upon another set B just in case no two
things can diﬀer with respect to A-properties without also diﬀering with
respect to their B-properties.
So in this context, it is the mental properties which are thought to supervene
on the neuro-physical properties. All we need to know is are the details of
how this supervenience takes place. And what throws up diﬃculties is our
own intimate experience of the outcomes of this supervenience.
One of the main problems relating to supervenience is the so-called
‘problem of mental causation’, the old problem which undermined the
Cartesian conception of mind–body dualism. The persistent question is:
How can mentality have a causal role in a world that is fundamentally
physical?
Another unavoidable problem is that of ‘overdetermination’ –
the problem of phenomena having both mental and physical causes. For a
pithy expression of the problem, here is Kim [54] again:

Deﬁnability in the Real Universe
153
. . . the problem of mental causation is solvable only if mentality is phys-
ically reducible; however, phenomenal consciousness resists physical re-
duction, putting its causal eﬃcacy in peril.
It is not possible here, and not even useful, to go into the intricacies
of the philosophical debates which rage on. But it is important to take
on board the lesson that a crude mechanical connection between mental
activity and the workings of the brain will not do the job. Mathemati-
cal modelling is needed to clarify the mess, but has to meet very tough
demands.
5.13. Connectionist Models to the Rescue?
Synaptic interactions are basic to the workings of the brain, and connection-
ist models based on these are the ﬁrst hope. And there is optimism about
such models from such leading ﬁgures in the ﬁeld as Paul Smolensky [90],
recipient of the 2005 David E. Rumelhart Prize:
There is a reasonable chance that connectionist models will lead to the
development of new somewhat-general-purpose self-programming, mas-
sively parallel analog computers, and a new theory of analog parallel
computation: they may possibly even challenge the strong construal of
Church’s Thesis as the claim that the class of well-deﬁned computations
is exhausted by those of Turing machines.
And it is true that connectionist models have come a long way since Turing’s
1948 discussion [102] of ‘unorganised machines’, and McCulloch and Pitts’
1943 early paper [65] on neural nets. (Once again, Turing was there at the
beginning, see Teuscher’s book [97] on Turing’s Connectionism.)
But is that all there is?
For Steven Pinker [72] ‘. . . neural networks
alone cannot do the job’. And focusing on our elusive higher functionality,
and the way in which mental images are recycled and incorporated in new
mental processes, he points to a ‘kind of mental fecundity called recursion’:
We humans can take an entire proposition and give it a role in some
larger proposition. Then we can take the larger proposition and embed
it in a still-larger one. Not only did the baby eat the slug, but the father
saw the baby eat the slug, and I wonder whether the father saw the baby
eat the slug, the father knows that I wonder whether he saw the baby eat
the slug, and I can guess that the father knows that I wonder whether
he saw the baby eat the slug, and so on.

154
S. B. Cooper
Is this really something new?
Neural nets can handle recursions of
various kinds. They can exhibit imaging and representational capabilities.
They can learn.
The problem seems to be with modelling the holistic
aspects of brain functionalism. It is hard to envisage a model at the level
of neural networks which successfully represent and communicate its own
global informational structures.
Neural nets do have many of the basic
ingredients of what one observes in brain functionality, but the level of
developed synergy of the ingredients one ﬁnds in the brain does seem to
occupy a diﬀerent world. There seems to be a dependency on an evolved
embodiment which goes against the classical universal machine paradigm.
We develop these comments in more detail later in this section.
For the mathematician, deﬁnability is the key to representation. As
previously mentioned, the language functions by representing basic modes
of using the informational content of the structure over which the language
is being interpreted. Very basic language corresponds to classical compu-
tational relationships, and is local in import. If we extend the language,
for instance, by allowing quantiﬁcation, it still conveys information about
an algorithmic procedure for accessing information. The new element is
that the information accessed may now be emergent, spread across a range
of regions of the organism, its representation very much dependent on the
material embodiment and with the information accessed via ﬁnitary compu-
tational procedures which also depend on the particular embodiment. One
can observe this preoccupation with the details of the embodiment in the
work of the neuro-scientist Antonio Damasio. One sees this in the follow-
ing description from Damasio’s book, The Feeling Of What Happens, of the
kind of mental recursions Steven Pinker was referring to above [25, p.170]:
As the brain forms images of an object – such as a face, a melody, a
toothache, the memory of an event – and as the images of the object
aﬀect the state of the organism, yet another level of brain structure
creates a swift nonverbal account of the events that are taking place
in the varied brain regions activated as a consequence of the object-
organism interaction. The mapping of the object-related consequences
occurs in ﬁrst-order neural maps representing the proto-self and object;
the account of the causal relationship between object and organism can
only be captured in second-order neural maps. . . . one might say that
the swift, second-order nonverbal account narrates a story: that of the
organism caught in the act of representing its own changing state as it
goes about representing something else.

Deﬁnability in the Real Universe
155
Here we see the pointers to the elements working against the classical in-
dependence of the computational content from its material host. We may
have a mathematical precision to the presentation of the process. But the
presentation of the basic information has to deal with emergence of a pos-
sibly incomputable mathematical character, and so has to be dependent on
the material instantiation. And the classical computation relative to such
information, implicit in the quotations from Pinker and Damasio, will need
to work relative to these material instantiations. The mathematics sets up
a precise and enabling ﬁling system, telling the brain how to work hierarchi-
cally through emergent informational levels, within an architecture evolved
over millions of years.
There is some recognition of this scenario in the current interest in the
evolution of hardware – see, for example, Hornby, Sekanina and Haddow
[52]. We tend to agree with Steven Rose [84]:
Computers are designed, minds have evolved.
Deep Blue could beat
Kasparov at a game demanding cognitive strategies, but ask it to escape
from a predator, ﬁnd food or a mate, and negotiate the complex inter-
actions of social life outside the chessboard or express emotion when it
lost a game, and it couldn’t even leave the launchpad. Yet these are
the skills that human survival depends on, the products of 3bn years of
trial-and-error evolution.
From a computer scientist’s perspective, we are grappling with the design of
a cyber-physical system (CPS). And as Edward Lee from Berkeley describes
[59]:
To realize the full potential of CPS, we will have to rebuild computing
and networking abstractions. These abstractions will have to embrace
physical dynamics and computation in a uniﬁed way.
In Lee [58], he argues for ‘a new systems science that is jointly physical and
computational’.
Within such a context, connectionist models with their close relation-
ship to synaptic interactions, and availability for ad hoc experimentation,
do seem to have a useful role. But there are good reasons for looking for
a more fundamental mathematical model with which to express the ‘de-
sign’ on which to base a deﬁnable emergence. The chief reason is the need
for a general enough mathematical framework, capable of housing diﬀer-
ent computationally complex frameworks. Although the human brain is an
important example, it is but one part of a rich and heterogeneous compu-
tational universe, reﬂecting in its workings many elements of that larger

156
S. B. Cooper
context. The history of mathematics has led us to look for abstractions
which capture a range of related structures, and which are capable of the-
oretical development informed by intuitions from diﬀerent sources, which
become applicable in many diﬀerent situations. And which provide basic
understanding to take us beyond the particularities of individual examples.
5.14. Deﬁnability in What Structure?
In looking for the mathematics to express the design, we need to take
account of the needs of physics as well as those of mentality or biology.
In his The Trouble With Physics [91], Lee Smolin points to a number of
deﬁciencies of the standard model, and also of popular proposals such as
those of string theory for ﬁlling its gaps. And in successfully modelling the
physical universe, Smolin declares [91, p.241]:
. . . causality itself is fundamental.
Referring to ‘early champions of the role of causality’ such as Roger Pen-
rose, Rafael Sorkin (the inventor of causal sets), Fay Dowker and Fotini
Markopoulou, Smolin goes on to explain [91, p.242]:
It is not only the case that the spacetime geometry determines what the
causal relations are. This can be turned around: Causal relations can
determine the spacetime geometry . . .
It’s easy to talk about space or spacetime emerging from something more
fundamental, but those who have tried to develop the idea have found
it diﬃcult to realize in practice. . . . We now believe they failed because
they ignored the role that causality plays in spacetime.
These days,
many of us working on quantum gravity believe that causality itself is
fundamental – and is thus meaningful even at a level where the notion
of space has disappeared.
So, when we have translated ‘causality’ into something meaningful, and the
model based on it has been put in place – the hoped-for prize is a theory
in which even the background character of the universe is determined by
its own basic structure. In such a scenario, not only would one be able
to do away with the need for exotic multiverse proposals, patched with
inﬂationary theories and anthropic metaphysics. But, for instance, one can
describe a proper basis for the variation of natural laws near a mathematical
singularity, and so provide a mathematical foundation for the reinstatement
of the philosophically more satisfying cyclical universe as an alternative to

Deﬁnability in the Real Universe
157
the inﬂationary Big Bang hypothesis – see Paul Steinhardt and Neil Turok’s
book [94] for a well worked out proposal based on superstring theory.
5.15. The Turing Landscape, Causality and Emergence . . .
If there is one ﬁeld in which ‘causality’ can be said to be fundamental, it
is that of computability. Although the sooner we can translate the term
into something more precise, the better. ‘Causality’, despite its everyday
usefulness, on closer inspection is fraught with diﬃculties, as John Earman
[37, p.5] nicely points out:
. . . the most venerable of all the philosophical deﬁnitions [of determin-
ism] holds that the world is deterministic just in case every event has a
cause. The most immediate objection to this approach is that it seeks
to explain a vague concept – determinism – in terms of a truly obscure
one – causation.
Historically, one recognised the presence of a causal relationship when a
clear mechanical interaction was observed. But Earman’s book makes us
aware of the subtleties beyond this at all stages of history. The success of
science in revealing such interactions underlying mathematically signalled
causality – even for Newton’s gravitational ‘action at a distance’ – has
encouraged us to think in terms of mathematical relationships being the
essence of causality. Philosophically problematic as this may be in general,
there are enough mathematical accompaniments to basic laws of nature
to enable us to extract a suitably general mathematical model of physical
causality, and to use this to improve our understanding of more compli-
cated (apparent) causal relationships. The classical paradigm is still Isaac
Newton’s formulation of a mathematically complete formulation of his laws
of motion, suﬃcient to predict an impressive range of planetary motions.
Schematically, logicians at least have no problem representing Newto-
nian transitions between mathematically well-deﬁned states of a pair of
particles at diﬀerent times as the Turing reduction of one real to another,
via a partial computable (p.c.)
functional describing what Newton said
would happen to the pair of particles. The functional expresses the com-
putational and continuous nature of the transition. One can successfully
use the functional to approximate, to any degree of accuracy, a particular
transition.
This type of model, using partial computable functionals extracted from
Turing’s [101] notion of oracle Turing machine, is very generally applica-

158
S. B. Cooper
ble to basic laws of nature. However, it is well known that instances of a
basic law can be composed so as to get much more problematic mathemat-
ical relationships, relationships which have a claim to be causal. We have
mentioned cases above – for instance those related to the 3-body problem,
or strange attractors emergent from complex conﬂuences of applications of
basic laws. See recent work Beggs, Costa, Loﬀand Tucker [4], Beggs and
Tucker [5] concerning the modelling of physical interactions as computa-
tion relative to oracles, and incomputability from mathematical thought
experiments based on Newtonian laws.
The technical details of the extended Turing model, providing a model
of computable content of structures based on p.c. functionals over the reals,
can be found in Cooper [19]. One can also ﬁnd there details of how Emil
Post [75] used this model to deﬁne the degrees of unsolvability – now known
as the Turing degrees – as a classiﬁcation of reals in terms of their relative
computability. The resulting structure has turned out to be a very rich
one, with a high degree of structural pathology. At a time when primarily
mathematical motivations dominated the ﬁeld – known for many years
as a branch of mathematical logic called recursive function theory – this
pathology was something of a disappointment.
Subsequently, as we see
below, this pathology became the basis of a powerful expressive language,
delivering a the sort of richness of deﬁnable relations which qualify the
structure for an important real-world modelling role.
Dominant as this Turing model is, and widely accepted to have a canon-
ical role, there are more general types of relative computation. Classically,
allowing non-deterministic Turing computations relative to well-behaved
oracles gives one nothing new. But in the real world one often has to cope
with data which is imperfect, or provided in real time, with delivery of com-
putations required in real time. There is an argument that the correspond-
ing generalisation is the ‘real’ relative computability. There are equivalent
formalisations – in terms of enumeration reducibility between sets of data,
due to Friedberg and Rogers [45], or (see Myhill [66]), in terms of relative
computability of partial functions (extending earlier notions of Kleene and
Davis). The corresponding extended structure provides an interesting and
informative context for the better known Turing degrees – see, for exam-
ple, Soskova and Cooper [93]. The Bulgarian research school, including D.
Skordev, I. Soskov, A. Soskova, A. Ditchev, H. Ganchev, M. Soskova and
others has played a special role in the development of the research area.
The universe we would like to model is one in which we can describe
global relations in terms of local structure – so capturing the emergence of

Deﬁnability in the Real Universe
159
large-scale formations, and giving formal content to the intuition that such
emergent higher structures ‘supervene’ on the computationally more basic
local relationships.
Mathematically, there appears to be strong explanatory power in the
formal modelling of this scenario as deﬁnability over a structure based on
reducibilities closely allied to Turing functionals: or more generally, freeing
the model from an explicit dependence on language, as invariance under
automorphisms of the Turing structure. In the next section, we focus on
the standard Turing model, although the evidence is that similar outcomes
would be provided by the related models we have mentioned.
5.16. An Informational Universe, and Hartley Rogers’ Pro-
gramme
Back in 1967, the same year that Hartley Rogers’ inﬂuential book Theory
of Recursive Functions and Eﬀective Computability appeared, a paper [81],
based on an earlier talk of Rogers, appeared in the proceedings volume
of the 1965 Logic Colloquium in Leicester.
This short article initiated
a research agenda which has held and increased its interest over a more
than 40 year period. Essentially, Hartley Rogers’ Programme concerns the
fundamental problem of characterising the Turing invariant relations.
The intuition is that these invariant relations are key to pinning down
how basic laws and entities emerge as mathematical constraints on causal
structure: where the richness of the Turing structure discovered so far be-
comes the raw material for a multitude of non-trivially deﬁnable relations.
There is an interesting relationship here between the mathematics and the
use of the anthropic principle in physics to explain why the universe is as
it is. It is well known that the development of the complex development
we see around us is dependent on a subtle balance of natural laws and as-
sociated constants. One would like the mathematics to explain why this
balance is more than an accidental feature of one of a multitude, perhaps
inﬁnitely many, randomly occurring universes. What the Turing universe
delivers is a rich infrastructure of invariant relations, providing a basis for
a correspondingly rich material instantiation, complete with emergent laws
and constants, a provision of strong determinism, and a globally originat-
ing causality equipped with non-localism – though all in a very schematic
framework. Of course, echoing Smolin, it is the underlying scheme that is
currently missing. We have a lot of detailed information, but the skeleton
holding it all together is absent.

160
S. B. Cooper
However, the computability theorists have their own ‘skeleton in the
cupboard’. The modelling potential of the extended Turing model depends
on it giving some explanation of such well-established features as quan-
tum uncertainty, and certain experimentally veriﬁed uncertainties relating
to human mentality. And there is a widely believed mathematical conjec-
ture which would rob the Turing model of basic credentials for modelling
observable uncertainty.
The Bi-Interpretability Conjecture, arising from Leo Harrington’s famil-
iarity with the model theoretic notion of bi-interpretability, can be roughly
described as asserting that:
The Turing deﬁnable relations are exactly those with information content
describable in second-order arithmetic.
Moreover, given any description of information content in second-order
arithmetic, one has a way of reading oﬀthe computability-theoretic def-
inition in the Turing universe. Actually, a full statement of the conjec-
ture would be in terms of ‘interpreting’ one structure in another, a kind
of poor-man’s isomorphism. Seminal work on formalising the global ver-
sion of the conjecture, and proving partial versions of it complete with key
consequences and equivalences, were due to Theodore Slaman and Hugh
Woodin. See Slaman’s 1990 International Congress of Mathematicians ar-
ticle [88] for a still-useful introduction to the conjecture and its associated
research project.
An unfortunate consequence of the conjecture being conﬁrmed would
be the well-known rigidity of the structure second-order arithmetic being
carried over to the Turing universe. The breakdown of deﬁnability we see
in the real world would lose its model. However, work over the years makes
this increasingly unlikely.
See Nies, Shore and Slaman [68] for further development of the requisite
coding techniques in the local context, with the establishment of a number
of local deﬁnability results. See Cooper [18, 22] for work in the other direc-
tion, both at the global and local levels. What is so promising here is the
likelihood of the ﬁnal establishment of a subtle balance between invariance
and non-invariance, with the sort of non-trivial automorphisms needed to
deliver a credible basis for the various symmetries, and uncertainties pe-
culiar to mentality and basic physics: along with the provision via partial
versions of bi-interpretability of an appropriate model for the emergence
of the more reassuring ‘quasi-classical’ world from out of quantum uncer-
tainty, and of other far-reaching consequences bringing such philosophical

Deﬁnability in the Real Universe
161
concepts as epistemological relativism under a better level of control.
To summarise: What we propose is that this most cartesian of re-
search areas, classical computability theory, regain the real-world signiﬁ-
cance it was born out of in the 1930s. And that it structure the informa-
tional world of science in a radical and revealing way. The main features of
this informational world, and its modelling of the basic causal structure of
the universe would be:
• A universe described in terms of reals . . .
• With basic natural laws modelled by computable relations between
reals.
• Emergence described in terms of deﬁnability/invariance over the result-
ing structure . . .
• With failures of deﬁnable information content modelling mental phe-
nomena, quantum ambiguity, etc. . . .
• Which gives rise to new levels of computable structure . . .
• And a familiarly fragmented scientiﬁc enterprise.
As an illustration of the explanatory power of the model, we return to
the problem of mental causation. Here is William Hasker, writing in The
Emergent Self [50, p. 175], and trying to reconcile the automomy of the
diﬀerent levels:
The “levels” involved are levels of organisation and integration, and the
downward inﬂuence means that the behaviour of “lower” levels – that
is, of the components of which the “higher-level” structure consists – is
diﬀerent than it would otherwise be, because of the inﬂuence of the new
property that emerges in consequence of the higher-level organization.
The mathematical model, making perfect sense of this, treats the brain
and its emergent mentality as an organic whole. In so doing, it replaces the
simple everyday picture of what a causal relationship is with a more subtle
conﬂuence of mathematical relationships. Within this conﬂuence, one may
for diﬀerent purposes or necessities adopt diﬀerent assessment of what the
relevant causal relationships are. For us, thinking about this article, we
regard the mentality hosting our thoughts to provide the signiﬁcant causal
structure. Though we know full well that all this mental activity is emer-
gent from an autonomous brain, modelled with some validity via a neural
network.
So one might regard causality as a misleading concept in this context.
Recognisable ‘causality’ occurs at diﬀerent levels of the model, connected

162
S. B. Cooper
by relative deﬁnability. And the causality at diﬀerent levels in the form of
relations with identiﬁable algorithmic content, this content at higher levels
being emergent. The diverse levels form a unity, with the ‘causal’ structure
observed at one level reﬂected at other levels – with the possibility of non-
algorithmic ‘feedback’ between levels. The incomputability involved in the
transition between levels makes the supervenience involved have a non-
reductive character.
References
[1] S. Alexander, Space, Time, and Deity: Giﬀord Lectures at Glasgow, 1916–
1918. vol. 2, Macmillan, London, (1920).
[2] H. Andr´eka, J. X. Madar´asz, I. N´emeti and G. Sz´ekely, Axiomatizing rela-
tivistic dynamics without conservation postulates, Studia Logica. 89, 163–
186, (2008).
[3] R. C. Arkin, Behaviour-Based Robotics. MIT Press, (1998).
[4] E. J. Beggs, J. F. Costa, B. Loﬀand J. V. Tucker, Computational com-
plexity with experiments as oracles, Proc. R. Soc. Ser. A. pp. 2777–2801,
(2008).
[5] E. J. Beggs and J. V. Tucker, Experimental computation of real numbers
by newtonian machines, Proc. R. Soc. Ser. A. pp. 1541–1561, (2007).
[6] L. Blum, F. Cucker, M. Shub and S. Smale, Complexity and Real Compu-
tation. Springer, (1997).
[7] M. A. Boden and E. Edmonds, What is generative art?, Digital Creativity.
20, 21–46, (2009).
[8] L. Bombelli, J. Lee, D. Meyer and R. D. Sorkin, Spacetime as a causal set,
Phys. Rev. Lett. 59, 521–524, (1987).
[9] M. Braverman and M. Yampolsky, Computability of Julia Sets. vol. 23,
Algorithms and Computation in Mathematics, Springer, (2009).
[10] C. D. Broad, The Mind and its Place in Nature. Kegan-Paul, London, New
York, (1925).
[11] J. Brockman, Ed., What We Believe but Cannot Prove: Today’s Leading
Thinkers on Science in the Age of Certainty. Harper Perennial, New York,
(2006).
[12] M. Bushev, Synergetics – Chaos, Order, Self-Organization. World Scien-
tiﬁc, Singapore, (1994).
[13] C. Calude, D. I. Campbell, K. Svozil, and D. Stefanescu. Strong deter-
minism vs. computability. In eds. W. Depauli-Schimanovich, E. Koehler
and F. Stadler, The Foundational Debate, Complexity and Constructivity
in Mathematics and Physics, pp. 115–131. Kluwer, Dordrecht, (1995).
[14] C. S. Calude and K. Svozil, Quantum randomness and value indeﬁniteness,
Advanced Science Letters. 1, 165–168, (2008).
[15] G. J. Chaitin, Algorithmic Information Theory. Cambridge University
Press, Cambridge, (1987).

Deﬁnability in the Real Universe
163
[16] A. C. Clarke. Hazards of prophecy: The failure of imagination. In Proﬁles
of the Future. Gollancz, London, (1962).
[17] S. B. Cooper. Clockwork or Turing U/universe? – Remarks on causal de-
terminism and computability. In eds. S. B. Cooper and J. K. Truss, Models
and Computability, vol. 259, London Mathematical Society Lecture Notes
Series, pp. 63–116. Cambridge University Press, Cambridge, New York,
Melbourne, (1999).
[18] S. B. Cooper, Upper cones as automorphism bases, Siberian Adv. Math. 9,
1–61, (1999).
[19] S. B. Cooper, Computability Theory. Chapman & Hall/CRC, Boca Raton,
London, New York, Washington, (2004).
[20] S. B. Cooper, Deﬁnability as hypercomputational eﬀect, Appl. Math. Com-
put. pp. 72–82, (2006).
[21] S. B. Cooper. Computability and emergence. In eds. D. M. Gabbay, S. Gon-
charov and M. Zakharyaschev, Mathematical Problems from Applied Logic
I. Logics for the XXIst Century, vol. 4, Springer International Mathemati-
cal Series, pp. 193–231. Springer, New York, (2006).
[22] S. B. Cooper. The limits of local Turing deﬁnability. In preparation.
[23] S. B. Cooper and P. Odifreddi. Incomputability in nature. In eds. S. Cooper
and S. Goncharov, Computability and Models, pp. 137–160. Kluwer Aca-
demic/Plenum, New York, Boston, Dordrecht, London, Moscow, (2003).
[24] P. Cotogno, A brief critique of pure hypercomputation, Mind and Machines.
19, 391–405, (2009).
[25] A. R. Damasio, The Feeling of What Happens: Body and Emotion in the
Making of Consciousness. Harcourt Brace, New York, (1999).
[26] M. Davis, Arithmetical problems and recursively enumerable predicates.
(abstract), J. Symbolic Logic. 15(1), 77–78, (1950).
[27] M. Davis, Arithmetical problems and recursively enumerable predicates, J.
Symbolic Logic. 18(1), 33–41, (1953).
[28] M. Davis, Ed., Solvability, Provability, Deﬁnability: The Collected Works
of Emil L. Post. Birkh¨auser, Boston, Basel, Berlin, (1994).
[29] M. Davis, The Universal Computer: The Road from Leibniz to Turing.
W. W. Norton, New York, London, (2000).
[30] M. Davis. The myth of hypercomputation. In ed. C. Teuscher, Alan Turing:
Life and Legacy of a Great Thinker, pp. 195–211. Springer-Verlag, Berlin,
Heidelberg, (2004).
[31] M. Davis, Why there is no such discipline as hypercomputation, Appl.
Math. Comput. 178, 4–7, (2006).
[32] R. Dawkins, The God Delusion. Bantam Press, London, (2006).
[33] D. Deutsch, Quantum Theory, the Church-Turing Principle and the Univer-
sal Quantum Computer, Proc. R. Soc. Lond. Ser. A. 400, 97–117, (1985).
[34] D. Deutsch, The Fabric of Reality. Allen Lane, London, (1997).
[35] D.
Deutsch.
Questions and answers with David Deutsch.
Available
at
http:www.newscientist.
com/article/dn10691-readers-q-amp-with-david-deutsch-.html. [Ac-
cessed 21 December 2006].

164
S. B. Cooper
[36] R. Downey and D. Hirschfeldt, Algorithmic Randomness and Complexity.
Springer, New York, (2010).
[37] J. Earman, A Primer On Determinism. D. Reidel/Kluwer, Dordrecht,
(1986).
[38] A. Einstein, Out of My Later Years. Philosophical Library, New York,
(1950).
[39] A. Einstein. Autobiographical notes. In ed. P. Schilpp, Albert Einstein:
Philosopher-Scientist. Open Court Publishing, Chicago, (1969).
[40] G. Ellis. The unique nature of cosmology. In eds. A. Ashtekar, R. S. Cohen,
D. Howard, J. Renn and A. Shimony, Revisiting the Foundations of Rela-
tivistic Physics: Festschrift in Honor of John Stachel. Kluwer, Dordrecht,
(1996).
[41] B. Eno, Generative music: evolving metaphors, in my opinion, is what
artists do, Motion Magazine (7 July 1996).
[42] M. O. Everett, Things the Grandchildren Should Know. Little, Brown &
Company, London, (2008).
[43] G. Farmelo, The Strangest Man – The Hidden Life of Paul Dirac, Quantum
Genius. Faber & Faber, London, (2009).
[44] D. Friedan, A tentative theory of large distance physics, J. High Energy
Phys. 10, 063, (2003).
[45] R. M. Friedberg and H. Rogers, Jr., reducibility and completeness for sets
of integers, Z. Math. Logik Grundlag. Math. 5, 117–125, (1959).
[46] K. G¨odel, ¨Uber formal unentscheidbare S¨atze der Principia Mathematica
und verwandter Systeme. I, Monatsch Math. Phys. 38, 173–178, (1931).
(English trans. in Davis [1965, 4–38], and in van Heijenoort [1967, 592–
616]).
[47] K. G¨odel, On undecidable propositions of formal mathematical systems.
Notes by S. C. Kleene and J. B. Rosser on lectures at the Institute for
Advanced Study, Princeton, New Jersey, pp. 30. (1934). (Reprinted in Davis
[1965, pp. 39–74]).
[48] A. H. Guth, The Inﬂationary Universe – The Quest for a New Theory of
Cosmic Origins. Addison-Wesley, Reading, (1997).
[49] J. Hadamard, The Psychology of Invention in the Mathematical Field.
Princeton University Press, Princeton, (1945).
[50] W. Hasker, The Emergent Self. Cornell University Press, Ithaca, (1999).
[51] A. Hodges, Alan Turing: The Enigma. Vintage, London, Melbourne, Jo-
hannesburg, (1992).
[52] G. S. Hornby, L. Sekanina and P. C. Haddow. Evolvable systems: From
biology to hardware. In Proc. 8th International Conference on Evolvable
Systems, ICES 2008, Prague, Czech Republic, September 21-24, 2008,
Springer, Berlin, (2008).
[53] J. Kim, Mind in a Physical World. MIT Press, Boston, (1998).
[54] J. Kim, Physicalism, or Something Near Enough. Princeton University
Press, Princeton, (2005).
[55] G. Kreisel. Mathematical logic: What has it done for the philosophy of
mathematics? In ed. R. Schoenman, Bertrand Russell, Philosopher of the

Deﬁnability in the Real Universe
165
Century. Allen and Unwin, London, (1967).
[56] G. Kreisel. Church’s Thesis: a kind of reducibility axiom for constructive
mathematics. In eds. A. Kino, J. Myhill and R. E. Vesley, Intuitionism and
proof theory: Proceedings of the Summer Conference at Buﬀalo N.Y. 1968,
pp. 121–150. North-Holland, Amsterdam, London, (1970).
[57] T. S. Kuhn, The Structure of Scientiﬁc Revolutions. University of Chicago
Press, Chicago, London, (1996), 3rd edition.
[58] E. A. Lee. Cyber-physical systems – are computing foundations adequate?
Position Paper for NSF Workshop on Cyber-Physical Systems: Research
Motivation, Techniques and Roadmap, October 16–17, 2006, Austin, Texas.
[59] E. A. Lee. Cyber physical systems: Design challenges. In 11th IEEE Sym-
posium on Object Oriented Real-Time Distributed Computing (ISORC), pp.
363–369, (2008).
[60] G. W. Leibniz, La Monadologie, 1714. (English translation by G. M. Ross,
Cambridge University Press, Cambridge, (1999)).
[61] K. Mainzer, Thinking in Complexity:
The Computational Dynamics of
Matter, Mind, and Mankind. Springer, (1994). 5th revised edn. 2007.
[62] D. Marker, Model theory and exponentiation, Notices Amer. Math. Soc.
pp. 753–759, (1966).
[63] Y. Matiyasevich, Hilbert’s tenth problem. MIT Press, Boston, (1993).
[64] B. P. McLaughlin. The Rise and Fall of British Emergentism. In eds.
A. Beckermann, H. Flohr and J. Kim, Emergence or Reduction?
– Es-
says on the Prospects of Nonreductive Physicalism, pp. 49–93. de Gruyter,
Berlin, (1992). (Reprinted in Emergence: Contemporary Readings in Phi-
losophy and Science (M. A. Bedau and P. Humphreys, eds.), MIT Press,
Boston, London, 2008, pp. 19–59).
[65] W. McCulloch and W. Pitts, A logical calculus of the ideas immanent in
nervous activity, Bull. Math. Biophys. 5, 115–133, (1943).
[66] J. Myhill, A note on degrees of partial functions, Proc. Amer. Math. Soc.
12, 519–521, (1961).
[67] A. Nies, Computability and Randomness. Oxford University Press, Oxford
(2009).
[68] A. Nies, R. A. Shore and T. A. Slaman, Interpretability and deﬁnability
in the recursively enumerable degrees, Proc. London Math. Soc. 77(3),
241–291, (1998).
[69] P. Odifreddi, Classical Recursion Theory. North-Holland/Elsevier, Amster-
dam, New York, Oxford, Tokyo, (1989).
[70] R. Penrose. Quantum physics and conscious thought. In eds. B. J. Hiley
and F. D. Peat, Quantum Implications: Essays in honour of David Bohm,
pp. 105–120. Routledge & Kegan Paul, London, New York, (1987).
[71] R. Penrose, The Emperor’s New Mind. Oxford University Press, Oxford,
(1994).
[72] S. Pinker, How the Mind Works. W.W. Norton, New York, (1997).
[73] H. Poincar´e, Science and method. Dover Publications, New York, (1952).
[74] E. L. Post, Recursively enumerable sets of positive integers and their de-
cision problems, Bull. Amer. Math. Soc. 50, 461–494, (1944). (Reprinted

166
S. B. Cooper
in E. L. Post, Solvability, Provability, Deﬁnability: The Collected Works of
Emil L. Post, pp. 284–316).
[75] E. L. Post, Degrees of recursive unsolvability: preliminary report. (ab-
stract), Bull. Amer. Math. Soc. 54, 641–642, (1948).
[76] E. L. Post. Absolutely unsolvable problems and relatively undecidable
propositions – account of an anticipation. In ed. Davis, The Undecidable,
pp. 340–433. Raven Press, New York, (1965). (Reprinted in E. L. Post,
Solvability, Provability, Deﬁnability: The Collected Works of Emil L. Post,
pp. 375–441).
[77] H. Putnam, Trial and error predicates and the solution to a problem of
mostowski, J. Symbolic Logic. 30, 49–57, (1965).
[78] H. Reichenbach, Axiomatik der relativistischen Raum-Zeit-Lehre. 1924.
(English Translation: Axiomatization of the Theory of Relativity. Univer-
sity of California Press, California, (1969).
[79] B. Richards. Morphogenesis of Radiolaria. MSc Thesis Manchester Univer-
sity, (1954).
[80] B. Richards, Turing, Richards and morphogenesis, The Rutherford Jour-
nal. 1. Available at http://www.rutherfordjournal.org/article010109.
html [Accessed December 2005].
[81] J. H. Rogers. Some problems of deﬁnability in recursive function theory.
In ed. J. N. Crossley, Sets, Models and Recursion Theory, Proceedings of
the Summer School in Mathematical Logic and Tenth Logic Colloquium
Leicester, August–September, 1965, pp. 183–201.
[82] J. H. Rogers. Theory of recursive functions and eﬀective computability.
McGraw-Hill, New York, (1967). (Reprinted by MIT Press, Boston, Lon-
don, 1987).
[83] E. M. A. Ronald, M. Sipper, and M. S. Capcarr`ere, Design, observation,
surprise! a test of emergence, Artif. Life. 5, 225–239, (1999).
[84] S. Rose. Guardian book review of kluge: the haphazard construction of the
human mind by Gary Marcus, (31 May 2008).
[85] D. Ruelle, Chance and Chaos. Princeton University Press, Princeton,
(1993).
[86] D. G. Saari and Z. Xia, Oﬀto inﬁnity in ﬁnite time, Notices Amer. Math.
Soc. 5, 538–546, (1995).
[87] R. Shaw, The Dripping Faucet As a Model Chaotic System. Science Frontier
Express Series, Aerial Press, California, (1984).
[88] T. A. Slaman. Degree structures. In Proc. Intl. Cong. Math., Kyoto 1990,
pp. 303–316, Springer-Verlag, Tokyo, (1991).
[89] A. Sloman and R. Chrisley, Virtual machines and consciousness, Journal
of Consciousness Studies. 10, 133–72, (2003).
[90] P. Smolensky, On the proper treatment of connectionism, Behav. Brain
Sci. 11, 1–74, (1988).
[91] L. Smolin, The Trouble With Physics: The Rise of String Theory, the Fall
of Science and What Comes Next. Allen Lane/Houghton Miﬄin, London,
New York, (2006).
[92] R. I. Soare, Recursively Enumerable Sets and Degrees. Springer-Verlag, New

Deﬁnability in the Real Universe
167
York, (1987).
[93] M. I. Soskova and S. B. Cooper, How enumeration reducibility yields ex-
tended harrington non-splitting, J. Symbolic Logic. 73, 634–655, (2008).
[94] P. J. Steinhardt and N. Turok, Endless Universe: Beyond the Big Bang.
Doubleday, New York, (2007).
[95] J. Swinton. Alan Turing and morphogenesis. Online at www.swintons.net/
jonathan/turing.htm.
[96] M. Tegmark, The mathematical universe, Found. Phys. 38, 101–50, (2008).
[97] C. Teuscher, Turing’s Connectionism – An Investigation of Neural Network
Architectures. Springer-Verlag, Berlin, Heidelberg, (2002).
[98] C. Teuscher, Ed., Alan Turing:
Life and Legacy of a Great Thinker.
Springer-Verlag, Berlin, Heidelberg, (2004).
[99] S. Torrance, R. Clowes, and R. Chrisley, Machine Consciousness: Em-
bodiment and Imagination. (Special Issue of the Journal of Consciousness
Studies, 2007).
[100] A. M. Turing, On computable numbers, with an application to the
entscheidungsproblem, Proc. London Math. Soc. 42, 230–265, (1936–37).
(Reprinted in A. M. Turing, Collected Works: Mathematical Logic, pp. 18–
53).
[101] A. M. Turing, Systems of logic based on ordinals, Proc. London Math.
Soc. 45, 161–228, (1939). (Reprinted in A. M. Turing, Collected Works:
Mathematical Logic, pp. 81–148).
[102] A. M. Turing. Intelligent machinery. In Machine Intelligence 5, pp. 3–23.
Edinburgh University Press, Edinburgh, (1969). (Reprinted in A. M. Tur-
ing, Collected Works: Mechanical Intelligence, (D. C. Ince, ed.) North-
Holland, Amsterdam, New York, Oxford, Tokyo, 1992, pp. 107–127).
[103] A. M. Turing, Collected Works of A. M. Turing: Morphogenesis ( T. Saun-
ders Ed.). North-Holland, Amsterdam, (1992).
[104] A. M. Turing, Collected Works of A. M. Turing: Mathematical Logic ( O.
Gandy and C. E. M. Yates Eds.). Elsevier, Amsterdam, New York, Oxford,
Tokyo, (1992).
[105] J. van Leeuwen and J. Wiedermann. The Turing machine paradigm in
contemporary computing. In Mathematics Unlimited – and Beyond. LNCS,
2000, (2001).
[106] P. Woit, Not Even Wrong: The Failure of String Theory and the Continuing
Challenge to Unify the Laws of Physics. Jonathan Cape, London, (2006).
[107] K. Zuse, Rechnender Raum. (Friedrich Vieweg & Sohn, Braunschweig).
(English trans.: Calculating Space, MIT Technical Translation AZT-70-
164-GEMIT, MIT (Proj. MAC), Boston, 1970).

This page intentionally left blank
This page intentionally left blank

Chapter 6
HF-Computability
Yuri L. Ershov∗, Vadim G. Puzarenko†, and Alexey I. Stukachev‡
Sobolev Institute of Mathematics,
Siberian Branch of the Russian Academy of Sciences,
Novosibirsk, 630090, Russia
Email: ∗ershov@math.nsc.ru, †vagrig@math.nsc.ru, ‡aistu@math.nsc.ru
We survey the results on HF-computability (computability on hereditar-
ily ﬁnite superstructures), an approach to abstract computability based
on the notion of Σ-deﬁnability in admissible sets.
Contents
6.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
6.2
HF-Logic
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
6.3
Σ-Subsets on Hereditarily Finite Superstructures . . . . . . . . . . . . . . . . 183
6.4
Reducibilities on Hereditarily Finite Superstructures . . . . . . . . . . . . . . 191
6.5
Descriptive Properties on Hereditarily Finite Superstructures . . . . . . . . . 194
6.6
Σ-Deﬁnability of Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
6.6.1
Σ-Deﬁnability on structures: general properties . . . . . . . . . . . . . 200
6.6.2
Σ-Deﬁnability on special structures . . . . . . . . . . . . . . . . . . . . 203
6.6.3
Special cases of Σ-deﬁnability . . . . . . . . . . . . . . . . . . . . . . . 211
6.7
Semilattices of Degrees of Presentability of Structures
. . . . . . . . . . . . . 216
6.8
Closely Related Approaches to Generalized Computability . . . . . . . . . . . 220
6.8.1
BSS-computability
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
6.8.2
Search computability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223
6.8.3
Montague computability . . . . . . . . . . . . . . . . . . . . . . . . . . 226
6.9
KPU. Examples of Admissible Structures . . . . . . . . . . . . . . . . . . . . 228
6.9.1
Elements of KPU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
6.9.2
Σ-subsets
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
6.9.3
Gandy’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
169

170
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
6.1. Introduction
The notion of computability in mathematics and technics has become a
subject of great interest and study. This is largely motivated by the rapid
development and use of computers (in both theory and practice). An evi-
dence of this fact is the successful realization of the European programme
“Computability in Europe” (CiE), one of the aims of which is the organi-
zation of annual conferences gathering together mathematicians, specialists
in computer science, biology, chemistry, and philosophy.
On the one hand, there is a generally accepted (absolute) theory of
computability for (partial) functions and predicates on natural numbers –
a classical computability theory. On the other hand, various proposals for
generalized theories of computability have been accumulated. Such general-
izations are motivated by a wish for a better understanding of the absolute
theory and expansion of the possibilities of application (understanding) of
computability notions to subjects (structures) far from natural numbers,
in particular, to uncountable structures (such as, e.g., the ﬁeld R of real
numbers).
Development of the classical computability theory raises the following
general methodological problem: How to “extend” the existing theory to a
wider class of objects. One of the (successful) approaches in this direction is
the theory of numberings [19, 35]. But this approach has strict cardinality
limitations, since numberings are deﬁned for countable collections of objects
only. Another approach is the theory of computability on admissible sets
of the form HF(A), for reasonably “simple” structures A.
Exactly this
approach is discussed in the present paper.
The development of the theory of admissible sets began with the gen-
eralization of computability on ordinals, initially on the ﬁrst nonrecursive
ordinal (metarecursive theory) (Kreisel and Sacks, see [82, 83, 134]), then on
arbitrary admissible (and other) ordinals (Kripke and Platek, see [84, 112]).
It was completed in the papers by Barwise when he introduced admissible
sets with urelements. The introduction of urelements would seem to be
a technical improvement; however, now we know that just such an ex-
tension of the notion of the admissible set led to the universal theory of
computability based on the notion of deﬁnability by formulas with (in a
broad sense) eﬀective semantics. Obviously, this theory generalizes nonde-
terministic computability unlike generalizations based on expansions of the
notion of (abstract) computing devices. Therefore, we can say that this
is a theory of constructively recognizable properties (predicates). Whereas

HF-Computability
171
the development of the classical theory of computability has shown that
study of computable functions is reasonable with the partial computable
functions only, the computability in arbitrary admissible sets shows that
computable (Σ-) predicates are a natural environment for the study of par-
tial computable (Σ-) functions. We can even say that the notion of the
computable (Σ-) predicate is more fundamental than that of the (partial)
computable function.
A general theory of admissible sets is a remarkable synthesis of the main
directions in modern mathematical logic – set theory (including its classical
section – descriptive set theory), model theory (inﬁnite languages), and
computability theory. The fundamental monograph of Barwise [11] is still
the main source of all the indicated aspects of the theory of admissible sets.
An intensive and profound study of the Turing reducibility on admissible
(and not only) ordinals can be found in the monograph of Sacks [134].
In the monograph of Barwise, the class of admissible sets of the form
HYP(A) is regarded as the class of “minimal” admissible sets, probably
because the author considered the admissible sets of the form HF(A) to be
too simple and trivial. The authors of the present paper think diﬀerent.
We believe that, for a better understanding of the general nature of
computability (constructive cognoscibility), one should develop the notion
of computability in admissible sets of the form HF(A) – the hereditarily
ﬁnite superstructure over a structure A, where A is either a model of a
reasonably “simple” theory or a model of classical subjects, e.g., such as
the ﬁeld R of real numbers. It should be noted that the notion of search
computability in an arbitrary structure A introduced in [105], as well as
the notion of abstract computability in the sense of [90], coincides (in ac-
cordance with [45]) with the notion of computability in the admissible set
HF(A).
In Section 6.8, we compare HF-computability with some other
closely related approaches to generalized computability, in particular, with
BSS-computability. Theoretical computer science also requires the super-
structures of such kind for the development of the theory of computability.
In [39] an approach called semantic programming, based on the use of ef-
fective semantics as a programming language is proposed.
6.2. HF-Logic
On the one hand, HF-logic (or the weak second order logic) is a powerful
tool to introduce the notion of ﬁniteness in ﬁrst order logic. On the other
hand, it enables us to deal with natural numbers and, therefore, to introduce

172
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
the notion of computability on arbitrary structures. By ω we denote the
set of natural numbers. Also, we will often identify ω with the set of all
natural ordinals. Let M be an arbitrary set. We construct the collection
of hereditarily ﬁnite sets over M as follows:
• HF0(M) = {∅};
• HFn+1(M) = Pω(M ∪HFn(M)) (here Pω(X) is the collection of all
ﬁnite subsets of X), n < ω;
• HF(M) = S
n<ω
HFn(M).
If M is a structure of some relation signature σ then one can deﬁne a
structure HF(M) of a signature σ ∪{U, ∅, ∈} (σ ∩{U, ∅, ∈} = ∅) on M ∪
HF(M) so that
• U HF(M) = M;
• P HF(M) = P M, P ∈σ;
• ∅HF(M) = ∅∈HF0(M);
• ∈HF(M)=∈⊆((M ∪HF(M)) × HF(M)).
We will consider structures of at most countable signatures only. Moreover,
in most cases we shall restrict our considerations to ﬁnite signatures. As in
set theory (e.g., in ZF), one can deﬁne natural ordinals and ﬁnite sequences
on HF(M).
Indeed, HF(M) is an admissible set and, therefore, we can
apply methods which are used in KPU (see Section 6.9). A hereditarily
ﬁnite superstructure can be considered as a structure, so we can apply usual
model theoretic methods for studying it. The problem of nonrealizability
of some type on hereditarily ﬁnite superstructures has a simple solution.
We consider the following collections of formulas:
θ0(x0) ⇌{∃distinct x1, . . . , xn((x1 ∈x0) ∧. . . (xn ∈x0)) | n < ω},
θ1(x0) ⇌{∃distinct x1, . . . , xn((x1 ∈x0) ∧. . . ∧(xn ∈xn−1))|n < ω}.
If θ0(x0) is satisﬁed on a then a has inﬁnitely many elements, i.e., it has
an inﬁnite width; if θ1(x0) is satisﬁed on a then a has an inﬁnite rank (in
absolute sense). Thus, no hereditarily ﬁnite superstructure realizes θ0(x0)
or θ1(x0). Indeed, it follows from deﬁnability of the cardinality operation
on hereditarily ﬁnite superstructures that θ0(x0) and θ1(x0) are realized or
not simultaneously.
Lemma 6.1. Let HF(M) be the hereditarily ﬁnite superstructure over M
and let T0 be its theory. If A is a structure of T0 on which θ0(x0) is not

HF-Computability
173
satisﬁed then A has the form HF(M′) for some structure M′ |= Th(M).
Conversely, no hereditarily ﬁnite superstructure satisﬁes θ0(x0).
Let T be a theory of signature σ.
By a type of T in σ we mean
a consistent (possibly incomplete) under T collection of formulas of the
same signature with some ﬁxed ﬁnite number of free variables.
A type
ξ(x0, x1, . . . , xk−1) is called principal under T if there exists a formula
ψ(x0, . . . , xk−1) such that T ⊢∀x0 . . . ∀xk−1(ψ →ϕ) for any ϕ ∈ξ. Other-
wise, this type is called nonprincipal.
Lemma 6.1 enables us to apply General Omitting Types Theorem
for constructing hereditarily ﬁnite superstructures with desired properties.
Namely,
Corollary 6.1. Let A be an arbitrary hereditarily ﬁnite superstructure in
some countable signature. Then for every countable collection S of non-
principal types of Th(A), there exists a hereditarily ﬁnite superstructure
HF(M′) |= Th(A) on which no type from S is satisﬁed.
Since M ≼N implies S(M) ⊆S(N), where S(M) is the collection of
types of Th(M) satisﬁed on M, the downwards L¨owenheim–Skolem Theo-
rem holds for hereditarily ﬁnite superstructures:
Proposition 6.1. If ℏ≼HF(M) then ℏhas the form HF(M′) for some
M′ ≼M.
In general, the upwards L¨owenheim–Skolem–Mal’cev Theorem does not
hold for hereditarily ﬁnite superstructures (see also Theorem 6.8). First we
deﬁne the following sequence of cardinals:
• ℶ0(ω) = ω;
• ℶα+1(ω) = 2ℶα(ω);
• ℶλ(ω) = S
γ<λ ℶγ(ω) if γ is limit.
Theorem 6.1. [11, 118] Let HF(M) be the hereditarily ﬁnite super-
structure over a structure M in some countable signature and let T =
Th(HF(M)) be its theory. Then the following statements are equivalent:
(1) for any inﬁnite cardinal β, there exists Mβ such that HF(Mβ) |= T
and card(Mβ) ⩾β;
(2) there exists M0 such that HF(M0) |= T and card(M0) = ℶω1(ω);
(3) there exists M0 such that HF(M0) |= T and there is an inﬁnite set
X ⊆dom(M0) of indiscernibles in some Skolem expansion of HF(M0);

174
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
(4) there exists a countable structure M0 such that HF(M0) |= T and there
is an inﬁnite set X ⊆dom(M0) of indiscernibles in some Skolem ex-
pansion of HF(M0).
To apply this theorem for complete diagrams of hereditarily ﬁnite super-
structures over countable structures, we infer the Elementary Extension
Theorem. It follows from the following Theorem that ℶω1(ω) is the Hanf
number for theories of hereditarily ﬁnite superstructures over countable
structures.
Theorem 6.2. [16, 118] For every ordinal α < ω1, there exists a structure
Mα in some ﬁnite signature such that card(M) = ℶα(ω) and it satisﬁes the
following conditions:
(1) HF(Mα) has no proper elementary extension of kind HF(M);
(2) for every M′, HF(Mα) ≡HF(M′) implies HF(M′) ⩽HF(Mα).
Now we consider the problem of realizability of types on hereditarily ﬁnite
superstructures.
To decide this problem, we apply one more Omitting
Types method. The language of hereditarily ﬁnite superstructures can be
considered as the language of ω-logic and a hereditarily ﬁnite superstructure
can be viewed as an ω-structure. In this case, ordinals of a hereditarily ﬁnite
superstructure play the role of naturals.
We describe the language of ω-logic. A signature σ corresponds to a
language Lω
σ which can be obtained from Lσ by adding one unary relation
symbol N and a collection {n | n < ω} of constant symbols. Assume that
N and n, n < ω, don’t occur in Lσ. Terms and formulas of Lω
σ are deﬁned
just as in ﬁrst order logic.
A structure A is called an ω-structure if {n | n < ω} ⊆|A|. If A is an
ω-structure of σ, then it can be expanded to Aω ⇌⟨A, N Aω, ⟨n : n < ω⟩⟩
so that N Aω = {n | n < ω}.
Let ϕ(x0, x1, . . . , xk−1) be a formula of
Lω
σ and a0, a1, . . . , ak−1 ∈A. Then suppose that A |= ϕ(a0, a1, . . . , ak−1)
if Aω |= ϕ(a0, a1, . . . , ak−1) in the usual sense whenever n and N(x) are
interpreted as n and “x ∈N Aω” respectively.
Let S be a collection of sentences of Lω
σ including {¬(m = n) | m ̸=
n} ∪{N(n) | n < ω}. Then S is called ω-consistent if it is consistent in
the usual sense and, for any formula ψ(x) of Lω
σ, if S ∪{∃x(N(x) ∧ψ(x))}
is consistent then so is S ∪{ψ(n)} for some n < ω.
The notion of ω-
consistency is not ﬁnitary, i.e., there are collections S of sentences that
every ﬁnite subset S0 ⊆S is ω-consistent but S is not.

HF-Computability
175
Let T be a theory of signature σ ∪⟨N, ⟨n | n < ω⟩⟩. The theory T is
called ω-complete if, for every formula ψ(x) in Lω
σ, T ⊢∀x(N(x) →ψ(x))
whenever T ⊢ψ(n), for every n < ω.
Given a set of sentences T , we write T |=ω ϕ if ϕ holds in all ω-structures
of T .
Let T be a collection of sentences of Lω
σ. A formula ϕ is a consequence
of T in ω-logic, written T ⊢ω ϕ, if ϕ is in the smallest set of formulas
containing T together with the axioms of ω-logic closed under the usual
rules and the ω-rule:
If T ⊢ω ϕ(n) for every n < ω then T ⊢ω ∀v(N(v) →ϕ(v)).
The following Existence Theorems for ω-logic holds:
Theorem 6.3. [111] If S is a countable ω-consistent collection of sentences
of ω-logic, then S has an ω-structure.
Theorem 6.4. (ω-completeness) Let σ be countable and let T be a set
of sentences of Lω
σ. If ϕ is a sentence of Lω
σ, then T |=ω ϕ iﬀT ⊢ω ϕ.
Now we turn to studying hereditarily ﬁnite superstructures. Let M be a
structure of σ and let HF(M) be the hereditarily ﬁnite superstructure over
M, σ∗= σ∪{U, ∅, ∈}. As it is noticed above, any formula Ψ(x0, . . . , xk−1),
k < ω, of Lω
σ∗is equivalent on HF(M) to some formula Ψ0(x0, . . . , xk−1) of
σ∗whenever N and {n | n < ω} are interpreted as the set of all ordinals and
deﬁnable representations of ordinals respectively. Thus, the Orey Theorem
sometimes enables us to construct a hereditarily ﬁnite superstructure on
which some ﬁxed type is satisﬁed.
In [115], syntactical characterizations of properties of countable cat-
egoricity and categoricity in HF-logic are given.
Recall that the theory
Th(HF(M)) of the hereditarily ﬁnite superstructure HF(M) over a count-
able structure M is called (countably) categorical in HF-logic if HF(M) ≡
HF(M′) implies HF(M) ∼= HF(M′), for every (countable) structure M′.
Hereinafter, ‘A ∼= B’ means that A and B are isomorphic where A and B
are structures. Using these characterizations we have the following:
Theorem 6.5. Let M be a countable structure of some countable signature.
Then Th(HF(M)) is countably categorical in HF-logic iﬀevery hereditarily
ﬁnite superstructure of it is an atomic structure.
Theorem 6.6. Let M be a countable structure in some countable signature.
Then Th(HF(M)) is categorical in HF-logic iﬀit is atomic and it has no
pair of hereditarily ﬁnite superstructures A0, A1 such that A0 ⪵A1.

176
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
It is clear that if M is a structure of (countably) categorical theory then
Th(HF(M)) is also (countably) categorical in HF–logic. We give examples
which demonstrate diﬀerences between these notions.
Examples 6.2.1.
(1) Let F be an algebraically closed ﬁeld of some ﬁnite degree of transcen-
dency. Then Th(HF(F)) is categorical in HF–logic.
(2) Let F be an algebraically closed ﬁeld of some inﬁnite degree of tran-
scendency. Then Th(HF(F)) is countably categorical but not categori-
cal in HF–logic. In particular, Th(HF(C)) is countably categorical but
not categorical in HF-logic where C is the ﬁeld of complex numbers.
Moreover, any two hereditarily ﬁnite superstructures over algebraically
closed ﬁelds with inﬁnite degrees of transcendency having the same
characteristic are elementarily equivalent.
(3) It is evident that Th(HF(N)) is categorical in HF-logic where N is the
standard model of arithmetic.
(4) Let Z be the set of integer numbers, 0 < n < ω, and let ⩽be the
lexicographic order on Zn.
Then Th(HF(⟨Zn, ⩽⟩)) is categorical in
HF–logic.
In [13], an example of a ﬁnitely generated semi-group is constructed which
demonstrates that the condition of a theory to be atomic in Theorem 6.6
is essential. Moreover, the following holds:
Proposition 6.2. Let M be a countable structure such that Th(HF(M))
is not atomic and has no pair of hereditarily ﬁnite superstructures A0, A1,
for which A0 ⪵A1. Then Th(HF(M)) has 2ℵ0 pairwise non-isomorphic
hereditarily ﬁnite superstructures and all of them are minimal structures.
The notion of interpretability of one structure in another is one of the key
notions in the Model Theory. For simplicity, we assume that signatures con-
sist of relations symbols only (otherwise, we can replace all the operations
by their graphs) and the equality is a signature relation.
Deﬁnition 6.1. Let M, N be structures of signatures σ0 and σ1 respec-
tively. We say that M is deﬁnable in N if there are
• a sequence of elements a = a0, . . . , an−1 from |N|, n < ω (hereinafter,
given a structure N, by |N| we denote its universe);
• a formula ψ(x0, . . . , xm−1, y0, . . . , yn−1) of σ1;
• a map ν from ψ(Nm, a) onto |M|;

HF-Computability
177
• a formula ψP (x1, . . . , x#(P ), y0, . . . , ym−1) of σ1, for every P ∈σ0 of
arity #(P); xk has length m and all variables in x1, . . . , x#(P ) are
distinct;
such that for any P ∈σ0 and b0, . . . , b#(P ) from ψ(Nm, a), we have:
M |= P(ν(b1), . . . , ν(b#(P ))) ⇔N |= ϕP (b1, . . . , b#(P ), a).
M and N are bideﬁnable if M and N are mutually deﬁnable.
Deﬁnition 6.2. Let K0, K1 be classes of structures of σ0, σ1 respectively.
We say that K0 is deﬁnable in K1 if there exists a single list S of formulas
of σ1 such that, for any M1 ∈K1, there is M0 ∈K0 deﬁnable in M1 via S;
for every M0 ∈K0, there is M1 ∈K1 in which M0 is deﬁnable via S. If K0
and K1 are mutually deﬁnable then we say that K0 and K1 are bideﬁnable.
From now to the end of this section, all the signatures considered below are
assumed to be ﬁnite. We consider now several examples of bideﬁnability of
structures and hereditarily ﬁnite superstructures. Indeed, it is important
that in all examples considered below, there exists a transformation of
formulas of weak second order to ones of ﬁrst order logic.
Deﬁnition 6.3. A language Lw
ω of weak second order logic consists of sym-
bols from L, new variables X1, ..., Xn, ..., and binary relation symbols ∈
and ⋐. Formulas of Lw
ω are constructed as usual from atomic ones includ-
ing atomic formulas of L and Xi ∈Xj, vi ⋐Xj, where vi is an individ-
ual variable of L.
To obtain a structure A in Lw
ω we interpret symbols
from L as before; X1, ..., Xn, ... are interpreted on HF(|A|) ∪|A| in the
following way: Xi ∈Xj if and only if Xi is an element from Xj and
rnk(Xj)=rnk(Xi) + 1; and v ⋐X if only if there are A1, ..., An ∈HF(|A|)
such that v ∈A1 ∈... ∈An ∈A and rnk(A1) = 1.
All the classes considered below have the following property.
Proposition 6.3. For any formula Φ(v0, ..., vn−1) ∈Lw
ω(K), there ex-
ists a formula Ψ(v0, ..., vn−1) ∈L(K) such that A |= Φ(a1, ..., an) iﬀ
A |= Ψ(a1, . . . , an), for every A ∈K and a1, ..., an ∈|A|.
1. ff–Classes.
Deﬁnition 6.4. [159] We say that a class of structures K admits elemen-
tary deﬁnability of ﬁnite functions (K is a ff–class) if there is Φ(x, y, z) ∈

178
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
L(K) such that, for any structure A ∈K and function f ⊂|A| × |A| whose
domain is ﬁnite, there exists a ∈|A| for which f(x) = y if and only if
A |= Φ(x, y, a).
We give now some examples of ff-classes [159].
Proposition 6.4. The class of existentially closed groups is an ff–class.
Proposition 6.5. The class of unintentionally closed semi-groups is an
ff–class.
The proof of the following results can be found in [159].
Proposition 6.6. Let µ : ω →L(K) be a G¨odel numbering of terms. There
exists a formula Φ(X, Y, z) ∈Lw
ω(K) satisﬁed on K-structure A if and only
if X is a number of a term τ(x1, ..., xk), Y is a sequence of the length k,
and z is the value of τ from Y in A.
Proposition 6.7. Let ν : ω →L(K) be a G¨odel numbering of Πn-formulas
with free variables contained in {v0, ..., vm−1}.
There exists a formula
Φ(X, v0, ..., vm−1) which is satisﬁed on K-structure A on a1, ..., am if and
only if X is a natural number and A satisﬁes ν(X) on a1, ..., am ∈|A|.
Corollary 6.2. Let K be an ff–class and let {Φi | i ∈I} be an arithmetical
collection of Πn-formulas of L(K) with free variables from {v0, ..., vm−1}.
Then there are formulas
Φ(v0, ..., vm−1), Ψ(v0, ..., vm−1)
such that for any K-structure A and a1, ..., am ∈|A|,
A |=
^
i∈I
Φi(a1, ..., am) iﬀA |= Φ(a1, ..., am)
and
A |=
_
i∈I
Φi(a1, ..., am) iﬀA |= Ψ(a1, ..., am).
2.
ε–Fragments. A structure A = ⟨A, ε⟩of signature {ε} is called an
ε-fragment if the following conditions hold:
1) regularity: for any non-empty subset A′ ⊆A, there exists a′ ∈A′
such that a′′εa′ is not satisﬁed, for every a′′ ∈A′.
Let Au ⇋{a|a ∈A, ∀a′ ∈A(¬(a′εa))}; then, by 1), Au ̸= ∅.

HF-Computability
179
2) extensionality: for any a0, a1 ∈A \ Au, we have
a0 = a1 ⇐⇒ˆa0 = ˆa1,
where ˆai ⇋{a|a ∈A, aεai}, i = 0, 1.
A structure of kind A∅⇋⟨A, a0, ε⟩is called a marked ε-fragment if
⟨A, ε⟩is an ε-fragment and a0 ∈Au; in this case, set A0 ⇋Au \ {a0}.
If A∅is a marked ε-fragment then one can deﬁne a correspondence
κ(= κA∅) : A →HF(A0) as follows:
κ(a) ⇋a if a ∈A0;
κ(a0) ⇋∅;
κ(a) ⇋{κ(a′)|a′ ∈A, a′εa} if a′ ∈A \ (A0 ∪{a0}).
A subset A′ ⊆A of a marked ε-fragment A∅is called dense if A′ ⊇A0,
where A0 ⇋{a|a ∈A, ∀a′ ∈A(a /∈a′)} \ {a0}.
Let A∅= ⟨A, a0, ε⟩be a marked ε-fragment and A′ ⊆A its dense subset.
We say that ⟨A∅, A′⟩codes κ(A∅, A′) ⇋{κ(a′)|a′ ∈A′} ∈HF(A0). In
this case, ⟨A∅, A′⟩is called a code.
Lemma 6.2. If ⟨A∅, A′⟩, ⟨B∅, B′⟩are codes and κ(A∅, A′) = κ(B∅, B′),
then A0 = B0 and there is a unique isomorphism ϕ : A∅→B∅such that
ϕ ↾A0 = idA0, ϕ(a0) = b0, and ϕ(A′) = B′. Conversely, if A0 = B0 and
there exists an isomorphism ϕ, then κ(A∅, A′) = κ(B∅, B′).
Lemma 6.3. If B is inﬁnite then, for any S ∈HF(B), there is a code
⟨A∅, A′⟩of S such that A ∈B.
Proof.
Let A0 ⇋sp(S) ⊆B where sp is the support function (see section
6.9.2). Also, let S∗⊆HF(B) be the least end subset of HF(B) containing
S∪{∅} as a subset. It is clear that S∗is ﬁnite and, therefore, S∗∈HF(B).
The set S∗can be deﬁned as follows: ˇs0 ⇋TC(s0) for every s0 ∈S \ A0;
ˇs0 ⇋{s0} if s0 ∈S ∩A0.
Then S∗⇋{∅} ∪
S
s0∈S
ˇs0 as desired.
Let
ρ : S∗→B be an injective map such that ρ(a) = a for any a ∈A0.
Suppose that A ⇋ρ(S∗) and a′εa ⇐⇒ρ−1(a′) ∈ρ−1(a) for any a, a′ ∈A;
then A∅⇋⟨A, ε, a0(= ρ(∅))⟩is a marked ε-fragment, A′ ⇋{ρ(s)|s ∈S}
is a dense subset of A∅and, as it could be easily checked, κ(A∅, A′) = S.
□
Theorem 6.7. If there is a coding of all ﬁnite binary relations on M then
HF(M) is deﬁnable in M.

180
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
3. Hereditarily listed superstructures.
Let M be an arbitrary set. We deﬁne the collection of hereditary lists
over M by induction on n < ω:
• HL0(M) = M ∪{∅};
• HLn+1(M) = HLn(M) ∪{⟨x, y⟩| x, y ∈HLn(M)};
• HL(M) = S
n<ω HLn(M).
Natural numbers are identiﬁed with the following elements from HL(M):
∅, ⟨∅, ∅⟩, ⟨⟨∅, ∅⟩, ∅⟩etc:
• 0 = ∅;
• n + 1 = ⟨n, ∅⟩;
• ω = {0, 1, 2, . . .}.
Every z ∈HL(M) corresponds to l(z) and r(z) inductively as follows:
l(∅) = r(∅) = ∅;
l(z) = r(z) = 1 if z ∈M;
l(z) = x, r(z) = y if z = ⟨x, y⟩.
Let M be a structure of some ﬁnite relation signature σ.
Then a
hereditarily listed superstructure HL(M) over M is a structure of signa-
ture σ ∪{l, r, ⟨·, ·⟩}, HL(M) its domain, such that l and r are deﬁned above
and symbols from σ are interpreted on M only as before. Then HF(M)
and HL(M) are bideﬁnable.
4. Admissible Structures.
Let A be an arbitrary admissible set (deﬁnition, examples, and basic
properties of such objects are given in section 6.9). Then one can construct
a directed graph ⟨|A|, R⟩without loops such that A and HF(⟨|A|, R⟩) are
bideﬁnable [122]. Moreover, this transformation preserves the semilattice
of Σ-degrees considered in 6.6.1, the semilattice of mΣ-degrees (see Section
6.4), and all descriptive set theoretical properties considered in Section 6.5
but quasiresolvability. However, it cannot be applied in studying T Σ- and
eΣ-degrees (see Section 6.4) and semilattices of degrees of presentability
(see Section 6.7).
We mention one more result which gives a natural example of bideﬁn-
ability between special admissible sets and hereditarily ﬁnite superstruc-
tures. Namely, it was proved in [144] that HY P(M) and HF(M) are Σ-
equivalent in case when M is a recursively saturated model of a regular
theory (in [9] it is proved that this Σ-equivalence is strong). For the deﬁ-
nition of Σ-deﬁnability we refer the reader to Section 6.6.

HF-Computability
181
In Examples 3 and 4, the property to be a Σ-subset is preserved under
certain interpretations. This enables us to transfer semantic approaches to
computability from one object to another.
Now we consider problems of deﬁnability of structures in hereditarily
ﬁnite superstructures. First we discuss model theoretic properties.
Deﬁnition 6.5. A structure M0 is called saturated enough if there exists
an ω-saturated structure M1 such that HF(M0) ≼HF(M1).
It is well known that any structure has some elementary ω-saturated exten-
sion [16]. However, there are structures which are not saturated enough.
The standard model of arithmetic and the ﬁeld of real numbers are exam-
ples of such structures. In [118], a series of structures of suﬃciently large
cardinality is given which are not saturated enough. We give a nice model
theoretic property of structures saturated enough.
Proposition 6.8. [31, 33] Let M0 and M1 be structures saturated enough.
If M0 ≡M1, then HF(M0) ≡HF(M1). If M0 ≼M1, then HF(M0) ≼
HF(M1).
The following variant of the L¨owenheim-Skolem-Mal’cev Theorem holds for
structures saturated enough.
Theorem 6.8.
[31, 33] Let T be a complete ω-stable or ω-categorical
theory, let M be a structure of T saturated enough, and let an uncountable
structure N be deﬁnable in HF(M). Then for any inﬁnite cardinals α and β
such that α ⩽card(N) ⩽β, there are structures Mα and Mβ of T saturated
enough such that Mα ≼M and Mα ≼Mβ. The structure Mα contains
all the parameters from |M| used in the deﬁnition of N in HF(M). If Nα
and Nβ are structures deﬁnable in HF(Mα) and HF(Mβ) respectively via
the same formulas and parameters as N in HF(M) then card(Nα) = α,
card(Nβ) = β.
If the theory T is categorical in some inﬁnite power, then Mβ from Theorem
6.8 can be chosen so that M ≼Mβ. The authors do not know whether Mβ
could be always chosen in such a way.
In the end of this section, we consider several examples of deﬁnability
of classical structures.
Deﬁnition 6.6. Let A be an admissible structure, let A be its universe,
and let S ⊆P(A). We say that S is deﬁnable in A if there are a sequence a

182
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
of elements from A and a formula ψ(x, y, z) such that S∪{∅} = {ψ(A, b, a) |
b ∈A}.
A criterion of deﬁnability of the ﬁeld R of real numbers in admissible sets
is contained in the following theorem.
Theorem 6.9. [117] Let A be an admissible set. Then R is deﬁnable in A
iﬀP(ω) is deﬁnable in A.
Corollary 6.3. Let T be a theory categorical in some inﬁnite cardinality
and M a structure of T. Then R is not deﬁnable in HF(M).
Corollary 6.4. [33] Let T be either the theory of dense linear orders, the
theory of algebraically closed ﬁelds, or the theory of inﬁnite sets in the empty
language. If M is a structure of T, then R is not deﬁnable in HF(M).
We give now one positive example of an application of this theorem.
Proposition 6.9. (Puzarenko) For any S ⊆P(ω), there is a linearly
ordered set LS such that S is deﬁnable in HF(LS).
Proof.
Let S ⊆P(ω). We assume that S ̸= ∅and ∅̸∈S.
We give now some method of coding of a set A ∈S. Fix a surjective
map f : ω + ω∗→A and deﬁne an A-block as follows:
• for any n ∈ω + ω∗, we take a linear ordering Ln, containing f(n) + 2
elements so that if n, m ∈ω + ω∗satisfy n < m and l0 ∈Ln, l1 ∈Lm,
then l0 < l1;
• for any n ∈ω + ω∗, we put Ln,n+1 isomorphic to the segment [0; 1] of
rational numbers between Ln and Ln+1;
• we also put linear orderings isomorphic to [0; 1] before L0, 0 ∈ω, and
after L0, 0 ∈ω∗.
Now we deﬁne a structure LS. First we ﬁx some surjective map g : 2ω(ω∗+
ω) →S. The domain of LS will have the following form:
• for every n ∈2ω(ω∗+ω), we take some g(n)-block Kn so that if n, m ∈
2ω(ω∗+ ω) satisfy n < m and l0 ∈Kn, l1 ∈Km, then l0 < l1;
• for every n ∈2ω(ω∗+ ω), we put a singleton Kn,n+1 between Kn and
Kn+1 (if a ∈Kn−1,n, b ∈Kn,n+1, then {a, b} is said to deﬁne the
n-block).
Now we show that S is deﬁnable in HF(LS). First we give several auxiliary
assumptions.

HF-Computability
183
⟨1⟩“a ∈Kn,n+1 for some n ∈2ω(ω∗+ ω)” is deﬁnable in LS by some
formula (denote this set as R). Indeed, a ∈R ⇔∃x∃y[(x < a < y)∧∀t((t <
x) →∃z(t < z < x)) ∧∀t((y < t) →∃z(y < z < t)) ∧¬∃z(x < z <
a) ∧¬∃z(a < z < y)].
⟨2⟩“{a, b} deﬁnes an n-block for some n ∈2ω(ω∗+ ω)” is deﬁnable
in LS by some formula (we denote this relation as Q, and the set g(n)
corresponding to it as Aa,b). Indeed, Q(a, b) ⇔[R(a) ∧R(b) ∧(a < b) ∧
¬∃t((a < t < b) ∧R(t))].
⟨3⟩The relation “n ∈Aa,b” from ⟨a, b⟩∈Q and n ∈ω is deﬁnable in
HF(LS) by some formula. Indeed, n ∈Aa,b ⇔[Q(a, b)∧∃x((card(x) = n+
2)∧∀y ∈x(a < y < b)∧∃u∃v∃f((f : ⟨n+4, <⟩
∼
→⟨x∪{u, v}, <⟩)∧(f(0) =
u) ∧(f(n + 3) = v) ∧∀m ∈n + 3((f(m) < f(m + 1)) ∧¬∃z(f(m) < z <
f(m + 1))) ∧∀t((t < u) →∃z(t < z < u)) ∧∀t((v < t) →∃z(v < z < t))))].
To ﬁnish the proof, it remains to note that S = {Aa,b | Q(a, b)}.
□
Applying Proposition 6.9 to P(ω) we have:
Corollary 6.5. There is a linearly ordered set L such that R is deﬁnable
in HF(L).
In comparison with the last result, R is not Σ-deﬁnable in HF(L), for
any linearly ordered set L (see Section 6.6.2).
Additional information about the HF-logic can be found in [12, 108,
109, 158, 159].
6.3. Σ-Subsets on Hereditarily Finite Superstructures
Here, by computability on hereditarily ﬁnite superstructures we mean Σ-
deﬁnability, and (generalized) computably enumerable sets are identiﬁed
with Σ-subsets.
The class of ∆0-formulas is the least one containing atomic formulas
which is closed under ∨, ∧, →, ¬ and restricted quantiﬁers ∀x ∈y and
∃x ∈y (∀x ∈yϕ and ∃x ∈yϕ are abbreviations for ∀x(x ∈y →ϕ) and
∃x(x ∈y ∧ϕ) respectively.
The class of Σ-formulas is the least one containing ∆0-formulas closed
under ∨, ∧, restricted quantiﬁers ∀x ∈y, ∃x ∈y, and ∃x.
A Σ1-formula is a formula of kind ∃uϕ0 where ϕ0 is ∆0-formula.
It follows from Σ-Reﬂection Principle [11] that any Σ-formula is equiv-
alent under KPU to some Σ1-formula.

184
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
A Σ-predicate is a relation deﬁnable by some Σ-formula (possibly with
parameters). A ∆-predicate is a Σ-predicate whose complement is also Σ.
A partial operation is called a (partial) Σ-function if its graph is Σ.
The following fact demonstrates that computability on hereditarily ﬁnite
superstructures is actually a generalization of the classical computability.
Proposition 6.10. [11, 33]
(1) There exists a one-to-one correspondence γ between HF(∅) and ω
which is a Σ-function on HF(∅).
(2) A ⊆ω is computably enumerable iﬀit is a Σ-subset of HF(∅).
(3) A ⊆ω is computably enumerable iﬀit is a Σ-subset of HF(N) (A can
be considered here as a subset of Ord(HF(N)) or as a subset of |N|).
Hereinafter, by N we denote the standard model of arithmetic.
In the study of computability on hereditarily ﬁnite superstructures, an
approach of deﬁning sets by inﬁnite computable formulas is actively used.
This method is proposed in [162].
Before stating the method we consider the problem of constructiviz-
ability of hereditarily ﬁnite superstructures. The basic notions from the
constructible model theory can be found in [37]. Recall that a sequence
{An}n∈ω of ﬁnite subsets of natural numbers is strongly computable if the
relation {⟨m, n⟩| m ∈An} and the function n 7→card(An) are computable.
Proposition 6.11. Let (M, ν) be a constructivizable structure. Then there
exists a constructivization ν0 of the hereditarily ﬁnite superstructure HF(M)
which satisﬁes the following conditions:
(1) ν ⩽ν0;
(2) there exists a strongly computable sequence {An}n∈ω of ﬁnite sets for
which ν0(n) = {ν0(k) | k ∈An};
(3) ν−1
0 (P) is computably enumerable, for every Σ-predicate P on HF(M);
(4) ν−1
0 (P) is computable, for every ∆-predicate P on HF(M).
Proof.
It is evident that a constructivization
ν0(n) =







∅
if n = 0;
ν(k)
if n = 2k + 1;
{ν0(k1) . . . , ν0(kl)}
if n = 2(2k1 + . . . + 2kl), k1 < . . . < kl;
has the desired properties.
□

HF-Computability
185
Indeed, 2 implies 3, 4, and, therefore, this enables us to translate ele-
ments of the hereditarily ﬁnite superstructure into ﬁnite objects on natural
numbers, in particular, we can transfer restricted quantiﬁers on hereditarily
ﬁnite superstructures into ones on the standard model of arithmetic.
Notice that there are constructivizations of hereditarily ﬁnite super-
structures HF(M) over any constructivizable structure M which do not
satisfy 2, 3, 4 from Proposition 6.3. To understand this, it suﬃces to code
ﬁnite sets by computable but not strongly computable indices.
The identical map on ω is a constructivization of N, so there exists
a constructivization of HF(N) which satisﬁes Proposition 6.3. From now
on we identify elements from |HF(N)| with their numbers under a ﬁxed
constructivization of HF(N) satisfying Proposition 6.3.
We assign every element κ ∈|HF(N)| a term tκ in signature {∅, {·}, ∪}
for which tκ(m) = κ for some sequence of pairwise distinct ur-variables m
containing all the elements from sp(κ) as follows ( n ∈ω is here number of
free variables in this term; if n = 0 then it has no free variable):
• tκ(u0, . . . , un−1) = ∅if κ = ∅;
• tκ(u0, . . . , un−1) = ui if κ = i ∈N;
• tκ(u0, . . . , un−1) = {tκ0(u0, . . . , un−1)} ∪{tκ1(u0, . . . , un−1)} ∪. . . ∪
{tκk(u0, . . . , un−1)} if κ = {κ0, κ1, . . . , κk} and κ0 < κ1 < . . . < κk,
k ∈ω \ {0}.
By Σ-recursion, it is easy to check that (κ, a) ∈|HF(N)|×|M|<ω 7→tκ(a) ∈
|HF(M)| will be a Σ-function on HF(M), for any structure M. Notice also
that the collection of permutation groups Sκ(⇌{π ∈S(sp(κ)) | tκ(u) =
tκ(πu)}) is strongly computable.
We say that κ0, κ1 ∈|HF(N)| are termally equivalent (and denote as
κ0 ∼κ1), if ⟨TC({κ0}), ∈, ∅, sp(κ0)⟩∼= ⟨TC({κ1}), ∈, ∅, sp(κ1)⟩. If κ0 ∼
κ1 then for any hereditarily ﬁnite superstructure, there are tuples u, v of
urelements such that HF(M) |= ∀u∀v(tκ0(u) ≈tκ1(v)). If, in addition,
we assume that elements of these tuples are distinct, then the converse
assumption is also true. We will write κ0e∈κ1 if there are κ′
0 ∼κ0 and
κ′
1 ∼κ1 that κ′
0 ∈κ′
1.
Remark 6.3.1. It is convenient to use “almost” single-valued representa-
tions, i.e., elements from |HF(N)| are chosen so that every element from the
hereditarily ﬁnite superstructure is in the range of some unique term with
some tuple of pairwise distinct urelements. Then the values of terms are de-
termined by some strongly computable sequence of groups of permutation

186
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
of urelements. This is important in studying such principles on hereditar-
ily ﬁnite superstructures as uniformization, reduction, the existence of a
universal function etc.
For convenience, we will use diﬀerent ur-variables u0, v0, u1, v1, . . . for
urelements only and common variables x0, y0, x1, y1, . . . for all elements to
the end of this section.
Lemma 6.4. For any ∆0-formula Φ from ur-variables in signature σ ∪
{U, ∅, ∈, ∪, { }}, one can eﬀectively construct ∃−and ∀−formulas Φ0 and
Φ1 respectively in signature σ that
HF(M) |= Φ ⇔M |= Φ0 ⇔M |= Φ1.
Moreover, if σ contains constants or FV(Φ) ̸= ∅then Φ0 can be chosen
quantiﬁer free.
Proof.
Let Φ be a formula in σ. We eﬀectively construct a quantiﬁer-free
formula Ψ of σ∪{⊤, ⊥} equivalent to it where ⊤and ⊥are logical constants
“true” and “false” respectively. We prove this assumption by induction on
the number of logical connectives. By an improper term in Φ we mean a
term which is maximal under inclusion occurring in Φ. We assume that
the implications do not occur in Φ, the negations appear before atomic
subformulas of Φ only, and all terms of {∅, ∪, { }} improper in Φ have the
form tκ(u) for some κ ∈|HF(N)| and tuple u with pairwise distinct ur-
variables. Also, all the restricted quantiﬁers appearing in Φ have the forms
∀x ∈. . . or ∃x ∈. . . where x is a common variable. We consider several
cases.
(1) Φ is atomic or the negation of atomic:
• if {U, ∅, ∈, ∪, { }} do not occur in Φ then Ψ = Φ;
• if Φ = U(tκ(u)) then Ψ = ⊤whenever tκ(u) is an ur-variable;
Ψ = ⊥, otherwise;
• if Φ = (tκ0(u) ≈tκ1(v)), then Ψ = W
π∈Sκ0 (u ≈π(v′)) (v′ satisﬁes
HF(N) |= (tκ0(v′) ≈tκ1(v))), whenever κ0 ∼κ1 and sp(κ0) ̸= ∅;
⊤, if κ0 ∼κ1 and sp(κ0) = ∅; otherwise, Ψ = ⊥;
• if Φ = (tκ0(u) ∈tκ1(v)) then Ψ is obtained by the previous rule
from W
κ2∈κ1(tκ0(u) ≈tκ2(v)) whenever κ0e∈κ1; Ψ = ⊥, otherwise;
• if Ψ is an atomic formula of σ ∪{U, ∅, ∈, ∪, { }} which is not con-
sidered above then we let Ψ = ⊥;
• ¬⊤and ¬⊥are replaced with ⊥and ⊤respectively;

HF-Computability
187
(2) if Φ = (Φ0 ∨Φ1) or Φ = (Φ0 ∧Φ1) then Ψ = (Ψ0 ∨Ψ1) or Ψ = (Ψ0 ∧Ψ1)
respectively;
(3) if Φ = ∀x ∈tκ(u)Φ0 then Ψ is obtained from V
κ′∈κ[Φ0]x
tκ′ (u) by the
previous rules (as usual, V ∅= ⊤);
(4) if Φ = ∃x ∈tκ(u)Φ0 then Ψ is obtained from W
κ′∈κ[Φ0]x
tκ′ (u) by the
previous rules (as usual, W ∅= ⊥).
To ﬁnish the proof, it suﬃces to replace ⊤and ⊥with some quantiﬁer-free
true and false formulas if such formulas exist; with formulas ∃u(u ≈u),
∀u(u ≈u), and ∃u¬(u ≈u), ∀u¬(u ≈u) respectively, otherwise.
□
Proposition 6.12. For every Σ1-formula Φ of σ ∪{U, ∅, ∈, ∪, { }} with
ur-variables, one can eﬀectively construct some computable disjunction Φ∗
of ∃-formulas of the signature σ so that
HF(M) |= Φ ⇔M |= Φ∗.
Proof.
We assume that any unrestricted quantiﬁer appearing in Φ acts
on a common variable. If Φ = ∃xΦ0(x, v) then Ψ = W
n<ω ∃uΦ0(tn(u), v).
This transformation is eﬀective. To ﬁnish the proof, it remains to apply
Lemma 6.4.
□
Thus, we have proved the following:
Theorem 6.10. Let σ be a ﬁnite relation signature. Then there exists a
computable sequence Am,n for which the following conditions hold:
(1) if Φ(x0, y0, . . . , yl−1) is a Σ-formula of σ∪{U, ∅, ∈} then AΦ,n consists
of ∃-formulas of σ;
(2) for any structure M of σ, A is deﬁnable in HF(M) by the Σ-formula
Φ(x0, s0, . . . , sl−1) with parameters s0, . . . , sl−1, l ⩾0 if and only if
A = {tn(u) | n ∈ω, M |= ϕ(u, s0, . . . , sl−1)) for some ϕ ∈AΦ,n}.
Moreover, an “almost” converse assumption holds:
Theorem 6.11. Let σ be a ﬁnite relation signature. For any computable
sequence {An}n∈ω in which every An consists of ∃-formulas of signature σ,
A = {tn(u) | n ∈ω, M |= f(n)(u, s0, . . . , sl−1))}
is a Σ-subset of HF(M) where M is a structure of σ. Moreover, a Σ-formula
deﬁning A is independent of a choice of M and can be eﬀectively found from
{An}n∈ω.

188
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
To establish this assumption, it suﬃces to show that the truth predicate
for Σ-formulas is Σ-deﬁnable.
Let HF(M) be the hereditarily ﬁnite superstructure over a structure
M of signature σ. By a Σ-operator we mean a map F : P(HF(M)) →
P(HF(M) ∪M) which is deﬁned in the following way, for every X ⊆
HF(M):
F(X) = {a | ∃b[⟨a, b⟩∈R ∧(b ⊆X)]}
for some Σ-predicate R.
The notion of Σ-operator generalizes the notion of enumeration oper-
ator. Like the enumeration operators, these operators have the following
properties:
continuity: x ∈F(X) ⇒∃Y ⊆X[card(Y ) < ω ∧x ∈F(Y )];
monotonicity: X1 ⊆X2 ⇒F(X1) ⊆F(X2).
Now we give a series of examples of Σ-operators. Let Φ(x, R+) be a
Σ-formula of σ ∪{R}, #(R) = 1, R ̸∈σ, in which R occurs positively.
Then for any X ⊆HF(M),
FΦ(X) = {a | (HF(M), X) |= Φ(a)}
is a Σ-operator.
By monotonicity, every Σ-operator has the least ﬁxed point, namely,
there is Y0 ⊆HF(M) such that F(Y0) = Y0 and ∀Y1 ⊆HF(M)[F(Y1) ⊆
Y1 ⇒Y0 ⊆Y1]. Let Γ0 ⇌∅; Γα+1 ⇌F(Γα); Γη ⇌S
β<η Γβ if η is limit;
then it is easy to check that Γ∗⇌S
α<card(HF(M))+ Γα will be the least
ﬁxed point of F.
Theorem 6.12. (Gandy) Let HF(M) be the hereditarily ﬁnite superstruc-
ture over M and F be a Σ-operator on HF(M). Then the least ﬁxed point
Γ∗of F is Σ on HF(M). Moreover, Γ∗= Γω.
It follows from the Gandy Theorem that for any structure M, HF(M)
has a universal Σ-predicate. Let K be a class of n-ary relations on HF(M).
A predicate P ⊆|HF(M)|n+1 is called universal for K if K = {{⟨b1, . . . , bn⟩|
⟨a, b1, . . . , bn⟩∈P} | a ∈|HF(M)|}. In particular, P is a universal Σ-
predicate if it is universal for the class of all n-ary Σ-predicates on HF(M);
a partial Σ-function f(y, x1, . . . , xn) is universal if its graph Γf is universal
for the class of graphs of all n-ary partial Σ-functions.

HF-Computability
189
Theorem 6.13. There exists a binary Σ-predicate TrΣ on HF(M) such
that for any Σ-formula Φ(x) and a ∈HF(M) ∪M,
⟨Φ, a⟩∈TrΣ ⇔HF(M) |= Φ(a).
Theorem
6.14. There
exists an
(n + 1)-ary
universal
Σ-predicate
T (e, x1, . . . , xn) on HF(M).
Notice that not all hereditarily ﬁnite superstructures have universal Σ-
functions [49, 101, 132, 162].
The collection of Σ-subsets of ω is one of the main computation invari-
ants of hereditarily ﬁnite superstructures.
Theorem 6.15. [101, 114, 133]
(1) For any admissible set A, the collection of ∆-subsets of ω is closed
under ⊕and downwards under T -reducibility.
(2) For any admissible set A, the collection of Σ-subsets of ω is closed
under ⊕and downwards under e-reducibility.
(3) For every T -ideal I, there exists a hereditarily ﬁnite superstructure on
which the class of T -degrees of ∆-subsets coincides with I.
(4) For every e-ideal I, there exists a hereditarily ﬁnite superstructure on
which the class of e-degrees of Σ-subsets coincides with I.
At the end of this section, we consider a series of examples of hereditarily
ﬁnite superstructures having universal Σ-functions.
Let HF(M) be the
hereditarily ﬁnite superstructure over a structure M of some ﬁnite relation
signature. A sequence of its subsets
A0 ⊆A1 ⊆. . . ⊆An ⊆An+1 ⊆. . . , n ∈ω
is called a Σ-resolution of HF(M) if the following hold:
(1) An is a transitive subset of HF(M), for any n ∈ω;
(2) S
n∈ω Aα = A;
(3) {⟨a, n⟩| n ∈ω, a ∈An} is Σ on HF(M).
Proposition 6.13. Let {An}n∈ω be a Σ-resolution of HF(M), let Φ(x) be a
Σ-formula with parameters m1, . . . , mk ∈|M|, k ∈ω, and let b ∈|HF(M)|.
Then HF(M) |= Φ(b) if and only if HF(M) ↾An |= Φ(b) for some n
satisfying {b, m1, . . . , mk} ⊆An.

190
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
A sequence Dn ⇌{a | a ∈HF(M), rk(a) ⩽n}, n ∈ω, is an example of
a nontrivial Σ-resolution of HF(M). A Σ-resolution {An}n∈ω of HF(M) is
called a quasiresolution if
TrΣ({An}n∈ω) ⇌{⟨n, Φ, a⟩| n ∈ω, a ∈An,
Φ(x) is a Σ −formula, HF(M) ↾An |= Φ(a)}
is ∆on HF(M).
Remark
6.3.2. If
{An}n∈ω
is
a
Σ-resolution
for
HF(M)
then
TrΣ({An}n∈ω) is always Σ on HF(M).
HF(M) is said to be quasiresolvable if HF(M) has at least one quasires-
olution.
If HF(M) is quasiresolvable then it satisﬁes reduction and has
a universal Σ-function [33, 36]. There exist hereditarily ﬁnite superstruc-
tures which are not quasiresolvable but satisfy reduction and have universal
Σ-functions [49].
By a canonical Σ-resolution of HF(M) we mean the following Σ-
resolution:
• B0 ⇌M = U(HF(M));
• Bn ⇌{tκ(m) | m ∈M n, κ ∈HFn(n)}, 0 < n < ω.
Proposition 6.14. For any Σ-formula Φ(u0, . . . , uk−1) and n ∈ω, one
can eﬀectively ﬁnd an ∃-formula of the signature of M so that
HF(M) ↾Bn |= Φ(m0, . . . , mk−1) ⇔M |= Φn(m0, . . . , mk−1),
for each m0, . . . , mk−1 ∈|M|.
Corollary 6.6. For every Σ-formula Φ(u0, . . . , uk−1) and m0, . . . , mk−1 ∈
|M|,
HF(M) |= Φ(m0, . . . , mk−1) ⇔M |=
_
n∈ω
Φn(m0, . . . , mk−1).
Proposition 6.15. The canonical Σ-resolution of HF(M) is a quasireso-
lution if and only if M is 1-decidable in HF(M), i.e.,
{⟨Φ, a⟩| Φ is ∃-formula, a ∈|M|<ω, M |= Φ(a)}
is ∆on HF(M).
We give one important corollary of Proposition 6.15.
Proposition 6.16. Let M be such that for any ∀-formula Φ(u) of the
signature of M, one can eﬀectively ﬁnd some ∃-formula Ψ(u) satisfying

HF-Computability
191
M |= ∀u(Φ(u) ↔Ψ(u)). Then the canonical Σ-resolution of HF(M) is a
quasiresolution.
Notice that if M satisﬁes the conditions of Proposition 6.16 then Th(M)
is model complete. In particular, these conditions are satisﬁed whenever
M is a structure of some regular theory T. Recall that T is regular if it is
decidable and model complete.
Proposition 6.17. [57] Let M be such that Th(M) is ω-categorical. Then
M is 1-decidable in HF(M) iﬀHF(M) is quasiresolvable.
A structure M is said to be quasiresolvable if HF(M) is quasiresolvable.
Theorem 6.16. [58] For any Ershov algebra A, the following conditions
are equivalent:
(1) A is quasiresolvable;
(2) A is 1-decidable in HF(A);
(3) A is the join of a non-atomic Ershov algebra and of a ﬁnite Boolean
algebra.
Theorem 6.17. [58] Let G be an abelian p-group and let R, D be its
reducible and its divisible parts respectively. The following conditions are
equivalent:
1) G is quasiresolvable;
2) if r(D) ⩾ω then R is ﬁnite; if r(D) < ω then R = R0 ⊕R1, where
R0 is ﬁnite and there is n ⩾0, for which R1 ∼= Cα
pn(Cα
p0 = 0), α ⩾ω (Cpn
is a cyclic group of order pn here).
6.4. Reducibilities on Hereditarily Finite Superstructures
In this section, we consider generalizations of classical reducibilities on
hereditarily ﬁnite superstructures. We recall some lattice-theoretic notions.
Deﬁnition 6.7. Let L = ⟨L, ⩽⟩be a partially ordered set.
• L is called an upper semilattice if any two elements a and b have a least
upper bound a ⊔b, i.e., for any a, b, c ∈L, we have: a ⩽a ⊔b, b ⩽a ⊔b
and (a ⩽c) ∧(b ⩽c) ⇒(a ⊔b ⩽c).
• An upper semilattice L is called distributive if for any a, b, c ∈L, there
are a0, b0 ∈L such that (c ⩽a⊔b) ⇒((a0 ⩽a)∧(b0 ⩽b)∧(c = a0⊔b0)).
• A non-empty subset I ⊆L is called an ideal of an upper semilattice L
if I satisﬁes the following conditions:

192
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
(1) a, b ∈I ⇒a ⊔b ∈I (it is closed under taking the least upper bound
operation);
(2) b ∈I, a ⩽b ⇒a ∈I (it is closed downwards under ⩽).
• a ∈L is the least (greatest) element if a ⩽b (b ⩽a), for every b ∈L.
Deﬁnition 6.8. Let HF(M) be the hereditarily ﬁnite superstructure over
M and B, C ⊆|HF(M)|.
• We say that B is mΣ-reducible to C, written B ⩽mΣ C, if there exists
a binary Σ-predicate R on HF(M) such that Pr1(R) = |HF(M)| and
⟨a, b⟩∈R ⇒((a ∈B) ↔(b ∈C)), for every a, b ∈|HF(M)|.
• We say that B is T Σ-reducible to C, written B ⩽T Σ C, if there
exist two binary Σ-operators Φ0 and Φ1 on HF(M) such that B =
Φ0(C, |HF(M)| \ C) and |HF(M)| \ B = Φ1(C, |HF(M)| \ C).
• We say that B is eΣ-reducible to C, written B ⩽eΣ C, if there exists a
Σ-operator Φ on HF(M) for which B = Φ(C).
• Let r ∈{mΣ, T Σ, eΣ}. We say that B and C are r-equivalent (B ≡r C)
if B ⩽r C and C ⩽r B.
• Let r ∈{mΣ, T Σ, eΣ}. A class w.r.t r-equivalence is called an r-degree.
We give some properties of these reducibilities:
(1) If HF(M) satisﬁes uniformization then the notion of mΣ-reducibility
can be formulated as in the classical case: B ⩽mΣ C if and only if
there exists a total Σ-function f such that a ∈B ⇔f(a) ∈C, for
every a ∈|HF(M)|.
(2) Let HF(S) be the hereditarily ﬁnite superstructure over an inﬁnite set
S. For any A ⊆ω, we deﬁne SA = {⟨n, a⟩| n ∈A; a = ⟨a0, . . . , an−1⟩∈
Sn; ai ̸= aj, 0 ⩽i < j < n} which is mΣ-equivalent to A. Then there
is no total Σ-function establishing mΣ-reducibility SA to A whenever
A is not computable.
The relations of mΣ-,
eΣ- and T Σ-reducibilities are preorders on
P(|HF(M)|) \ {∅, |HF(M)|} and, therefore, classes of corresponding de-
grees form partially ordered sets under the induced orderings. Moreover,
they are upper semilattices with least elements, namely, classes contain-
ing proper ∆-subsets of HF(M).
Note that [B] ⊔[C] = [B ⊕C] where
B ⊕C = (B × {0}) ∪(C × {1}).
By LmΣ(HF(M)), LT Σ(HF(M)), LeΣ(HF(M)) we denote upper semilat-
tices of classes of mΣ-, T Σ- and eΣ-degrees of proper subsets of HF(M)∪M
respectively. As it was shown in [114], the upper semilattice LmΣ(HF(M))

HF-Computability
193
is distributive, for every structure M. Furthermore, there exists a natural
isomorphism between LmΣ(HF(∅)), LT Σ(HF(∅)), LeΣ(HF(∅)) and upper
semilattices of m-,T -, e-degrees respectively.
Let M be an arbitrary structure and let r ∈{mΣ, T Σ, eΣ}.
Deﬁnition 6.9. A degree a ∈Lr(HF(M)) is called computably enumerable
if there exists a Σ-subset B ∈a of HF(M).
Deﬁnition 6.10. A degree a ∈Lr(A) is called deﬁnable if there exists a
deﬁnable subset B ∈a of HF(M).
Recall that a theory T is called c-simple [33] if it is ω-categorical, model
complete, decidable, and has a decidable set of complete formulas.
The following theorem describes relations between semilattices on hered-
itarily ﬁnite superstructures over structures of c-simple theories and classi-
cal ones:
Theorem 6.18. [113, 114] Let M be a structure of a c-simple theory
in some ﬁnite signature and ı the natural embedding HF(∅) into HF(M).
Then the following conditions hold:
(1) ı induces an isomorphism between the upper semilattices of computably
enumerable m-(T -) degrees and of computably enumerable mΣ-(T Σ-)
degrees;
(2) ı induces an isomorphism between the upper semilattices of deﬁnable
m-(T -,e-) degrees and of deﬁnable mΣ-(T Σ-,eΣ-) degrees;
(3) ı induces embedding of the upper semilattices of m-(T -,e-) degrees into
LmΣ(HF(M)) (LT Σ(HF(M)), LeΣ(HF(M))) as ideals.
If M is a countable structure of some c-simple theory then the semilattice
LmΣ(HF(M)) is described up to isomorphism:
Theorem 6.19. [124, 125] Let M be a countable structure of a c-simple
theory in some ﬁnite signature. Then the upper semilattices LmΣ(HF(M))
and Lm are isomorphic.
Additional information about generalized numberings and reducibilities
on admissible sets can be found in [5, 6, 33, 44, 52, 53, 116, 117, 121, 131,
160, 161, 163].

194
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
6.5. Descriptive Properties on Hereditarily Finite Super-
structures
As in the classical computability, the existence of a universal Σ-predicate
implies that the class of Σ-subsets is not closed under the complement
operation. To avoid this obstacle, properties from descriptive set theory are
sometimes applied. In this section, we discuss the problem of the existence
of hereditarily ﬁnite superstructures with respect to relations between such
properties. Recall the basic deﬁnitions.
Let A be a hereditarily ﬁnite superstructure and A its universe.
Deﬁnition 6.11.
(1) A is called recursively listed if there is a Σ-function f : ω →A with
ρf = A.
(2) A is called resolvable if there exists a Σ-function f : ω →A with
S
n∈ω f(n) = A. Such an f is called a resolution for A.
(3) Let C be a Σ-subset of A.
• A is projectible into C if there exists a Σ-function f with δf ⊆C
and ρf = A such that f −1(x) ∈A for every x ∈A.
• A is quasiprojectible into C if there exists a Σ-function f with δf ⊆C
and ρf = A.
Deﬁnition 6.12. We say that A satisﬁes
• reduction if, for any Σ-subsets B0 and B1, there are disjoint Σ-subsets
C0 ⊆B0 and C1 ⊆B1 such that C0 ∪C1 = B0 ∪B1.
• separation if, for any disjoint Σ-subsets B0 and B1, there is a ∆-subset
C such that B0 ⊆C ⊆A \ B1.
• extension if, for any partial Σ-function ϕ(x), there is a total Σ-function
f(x) such that Γϕ ⊆Γf.
• uniformization if, for any binary Σ-predicate R on A, there is a partial
Σ-function ϕ(x) with δϕ = Pr1(R) and Γϕ ⊆R.
The main merit of a recursively listed hereditarily ﬁnite superstructure is
the existence of an eﬀective function enumerating its range via natural num-
bers which enables us to transfer such principles from classical computabil-
ity as reduction, uniformization, the existence of a universal Σ-function
etc., [11]. Also, any inﬁnite Σ-subset C of A has an enumeration without
repetition, namely, a one-to-one Σ-function f with δf = ω and ρf = C.

HF-Computability
195
The notion of resolvable hereditarily ﬁnite superstructure is a generaliza-
tion of the notion of recursively listed hereditarily ﬁnite superstructure. As
for recursively listed hereditarily ﬁnite superstructures, in the study of the
properties of such structures, one can apply the method of constructing
Σ-subsets by using eﬀective approximations consisting of ﬁnite subsets. As
before, they satisfy reduction and have universal Σ-functions; however, in
general, uniformization does not hold on them. Moreover, the following is
true:
Proposition 6.18. Let HF(M) be resolvable. Then HF(M) is recursively
listed if and only if HF(M) satisﬁes uniformization.
An approach which avoids uniformization is to construct structures with a
small number of types and an inﬁnite set of indiscernibles.
Theorem 6.20. [57] If M is a structure of some countably categorical
theory then HF(M) does not satisfy uniformization.
Theorem 6.21. [9] If M is an ω-saturated structure of some uncountably
categorical theory then HF(M) does not satisfy uniformization.
E.g., if M is an algebraically closed ﬁeld with characteristic zero (in other
words, a structure of the theory of the ﬁeld of complex numbers), then
HF(M) does not satisfy uniformization, even if M is not ω-saturated. How-
ever, if N is a structure of the theory Th(ω, 0, s) of natural numbers with
zero and the successor relation, then HF(N) does not satisfy uniformiza-
tion iﬀN is ω-saturated; moreover, if N is not ω-saturated then HF(N) is
recursively listed.
The notion of projectibility is one more generalization of the notion of
recursively listed hereditarily ﬁnite superstructure. This deﬁnition was in-
troduced in [11]. Hereditarily ﬁnite superstructures quasiprojectible into
ω seem to be interesting; such structures have properties which look like
the corresponding ones on enumeration degrees. Further on, hereditarily
ﬁnite superstructures quasiprojectible into ω will be called simply quasipro-
jectible.
Example 6.1. Let A ⊆ω. We deﬁne a structure NA of signature {0, s, P}
as follows:
• |NA| ⇌ω ⊎{za | a ∈A}, whenever za1 ̸= za2 for a1 < a2 (hereinafter,
the symbol ⊎means the disjoint union);
• 0NA = 0 ∈ω; ⟨a, b⟩∈sNA ⇔({a, b} ⊆ω ∧b = a + 1);

196
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
• PNA ⇌{⟨a, za⟩| a ∈A}.
The class of structures {HF(NA) | A ⊆ω} consists of hereditarily ﬁnite
superstructures projectible into ω only. This class has a series of nice prop-
erties [49].
Now we give suﬃcient conditions of satisﬁability of properties from de-
scriptive set theory on admissible sets. As is said above, we have the fol-
lowing:
Theorem 6.22. [33, 36] If A is a quasiresolvable admissible set then A
satisﬁes reduction and has a universal Σ-function.
In section 6.6.3, a criterion for the satisﬁability of uniformization on hered-
itarily ﬁnite superstructures structures of kind HF(M), where Th(M) is
regular, is given (see also [142, 157]). In general, the uniformization prop-
erty does not hold even on hereditarily ﬁnite superstructures of this kind.
The following theorem gives us a description of hereditarily ﬁnite su-
perstructures with respect to relations between the properties considered
here [123].
Theorem 6.23. The following implications between the properties on
hereditarily ﬁnite superstructures hold:

HF-Computability
197
All the implications in the diagram are proper. Hereditarily ﬁnite su-
perstructures over computable structures can be found in (0–5, 9). There
is no such structure in (6–8).
Now we give examples of hereditarily ﬁnite superstructures over clas-
sical and (or) computable structures (if it is possible) which demonstrate
diﬀerences between the properties considered above.
Examples 6.5.1. The numbering of examples coincides with the correspond-
ing implications from Theorem 6.23.
0 One can take here the standard model of arithmetic.
1 Let R be the ﬁeld of real numbers. Then HF(R) satisﬁes uniformiza-
tion [142], however, for reasons of cardinality, this hereditarily ﬁnite
superstructure is not recursively listed.
Indeed, there are countable
hereditarily ﬁnite superstructures which satisfy uniformization but are
not recursively listed, e.g., HF(NΠ1
1) or a countable elementary sub-
structure of HF(R).
However, all the structures considered above are not computable.
Now we give an example of computable real closed ﬁeld R∗for
which HF(R∗) is not recursively listed but satisﬁes uniformization.
Let Q(a0, a1, . . . , an, . . .) be a purely transcendental extension of the
ordered ﬁeld of rational numbers such that all the elements from
Q(a0, . . . , an−1) are inﬁnitesimal w.r.t. an, n ∈ω. Then we set R∗
as the real closure of Q(a0, a1, . . . , an, . . .) [33]. Then it is computable
(even decidable) and HF(R∗) has the desired properties.
2 If M is a structure of some decidable, model complete, countably cate-
gorical theory then HF(M) is not resolvable, uniformization does not
hold on HF(M) but this hereditarily ﬁnite superstructure satisﬁes re-
duction and has a universal Σ-function. One can take here the set of
rational numbers with the natural order and a countable structure in
the empty language as M.
3 In [123], a series of examples of hereditarily ﬁnite superstructures in-
cluding computable ones are given, however, these structures are not
classical.
4 We deﬁne a structure M of signature {P, Q}, #(Q) = 2, as follows:
• P M and |M| \ P M are inﬁnite;

198
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
• QM is the graph of a one-to-one function from P M into |M| \ P M
such that (|M| \ P M) \ Pr2(QM) is inﬁnite.
Then HF(M) does not satisfy reduction but has a universal Σ-function.
Notice that Th(M) is decidable and countably categorical, and there-
fore the unique countable structure of the theory is computable (even
decidable).
5 There exists a Σ2-set A ⊆ω such that HF(NA) does not satisfy reduction
and separation, and has no universal Σ-function [49].
In [132], an example of hereditarily ﬁnite superstructure over a count-
able structure of some decidable countably categorical theory without
universal Σ-function is given. Furthermore, reduction and separation
does not hold on this hereditarily ﬁnite superstructure.
6 The hereditarily ﬁnite superstructure HF(NΣ1
1) satisﬁes separation but
does not satisfy extension. These conditions are satisﬁed on HF(G) for
some abelian group G [57]. To prove this, it suﬃces to apply methods
from [119].
7 In [119], examples of hereditarily ﬁnite superstructures satisfying exten-
sion are constructed. At this moment, examples of hereditarily ﬁnite
superstructures over classical structures have not been found.
8 A series of quasiprojectible hereditarily ﬁnite superstructures is given in
Example 6.1.
9 The hereditarily ﬁnite superstructure HF(NΣ1
1) has the desired proper-
ties.
Additional information about the properties considered above can be
found in [7, 57, 58, 60, 66, 94, 114, 122, 133, 162].
6.6. Σ-Deﬁnability of Structures
The theory of constructive (computable) models is one of the important
research areas of the classical computability theory, as well as of the model
theory. Because of the evident cardinality limitations, in the classical com-
putable model theory only countable structures are considered. The ap-
proach regarding generalized computability as Σ-deﬁnability in admissible
sets allows us to consider structures with arbitrary cardinality.
Heredi-
tarily ﬁnite superstructures are the “simplest” admissible sets, from the
set-theoretical point of view. Besides of this, Σ-deﬁnability in hereditary
ﬁnite superstructures is one of the natural approaches generalizing classical
computability theory on natural numbers to the case of computability over

HF-Computability
199
arbitrary structures.
Hence, for a structure M the following problems naturally arise:
• to describe the structures Σ-deﬁnable in HF(M);
• to describe the structures such that M is Σ-deﬁnable in their HF-
superstructures.
Let us formalize the problems stated above. Let M be a structure of a
ﬁnite predicate signature ⟨P1, . . . , Pk⟩, where each Pi is ni-ary, and let A
be an admissible set. To simplify the notations in this chapter, we write
M instead of |M|. The following notion is an eﬀectivization of the model-
theoretical notion of interpretability of one structure in another, and also a
natural generalization of the notion of constructivizability of a (countable)
structure on natural numbers.
Deﬁnition 6.13. [24, 33] M is Σ-deﬁnable in A if there exist Σ-formulas
Φ(x0, y), Ψ(x0, x1, y), Ψ∗(x0, x1, y), Φ1(x0, . . . , xn1−1, y),
Φ∗
1(x0, . . . , xn1−1, y), . . . , Φk(x0, . . . , xnk−1, y), Φ∗
k(x0, . . . , xnk−1, y),
such that for some parameter a ∈A, and letting
M0 ⇌ΦA(x0, a), η ⇌ΨA(x0, x1, a) ∩M 2
0
one has that M0 ̸= ∅and η is a congruence relation on the structure
M0 ⇌⟨M0, P M0
1
, . . . , P M0
k
⟩,
where P M0
i
⇌ΦA
i (x0, . . . , xni−1) ∩M ni
0
for all 1 ⩽i < k,
Ψ∗A(x0, x1, a) ∩M 2
0 = M 2
0 \ ΨA(x0, x1, a),
Φ∗A
i (x0, . . . , xni−1, a) ∩M ni
0
= M ni
0 \ ΦA
i (x0, . . . , xni−1)
for all 1 ⩽i < k, and the structure M is isomorphic to the quotient
structure M0⧸η.
Deﬁnition 6.14. M is A-constructivizable if there exists a map ν from |A|
onto |M| such that {⟨a0, a1, . . . , ani−1⟩| Pi(ν(a0), ν(a1), . . . , ν(ani−1))},
1 ⩽i ⩽k, and {⟨a, b⟩| ν(a) = ν(b)} are ∆on A.
Proposition 6.19. Let A be an admissible set and M a structure. Then
M is Σ-deﬁnable in A iﬀM is A-constructivizable.

200
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
Remark 6.1. Deﬁnition 6.13 can be naturally generalized to the case of
structures with inﬁnite computable signatures.
Namely, a structure M
with a computable predicate signature ⟨P0, P1, . . .⟩, where each Pi is ni-ary,
is called Σ-deﬁnable in A if there exists a computable sequence Φ(x0, y),
Ψ(x0, x1, y), Ψ∗(x0, x1, y), Φ0(x0, . . . , xn0−1, y), Φ∗
0(x0, . . . , xn0−1, y), . . .,
Φk(x0, . . . , xnk−1, y), Φ∗
k(x0, . . . , xnk−1, y), . . . of Σ-formulas and a param-
eter a ∈A, which forms a Σ-deﬁnition of M in A, in the sense of Deﬁnition
6.13.
For structures M and N, we denote by M ⩽Σ N the fact that M is
Σ-deﬁnable in HF(N). From the deﬁnition it follows that the relation ⩽Σ
is reﬂexive and transitive. We now look at the general properties of this
relation, regarding it as a kind of eﬀective reducibility on structures.
6.6.1. Σ-Deﬁnability on structures: general properties
For any inﬁnite cardinal α, we denote by Kα the class of structures having
a ﬁnite signature and with cardinality less than or equal to α.
As usual, preordering ⩽Σ generates on Kα a relation of Σ-equivalence:
A ≡Σ B if A ⩽Σ B and B ⩽Σ A.
Classes of Σ-equivalence are called
degrees of Σ-deﬁnability, or Σ-degrees. The poset
SΣ(α) = ⟨Kα/ ≡Σ, ⩽Σ⟩
is an upper semilattice with the least element, which is the degree consisting
of computable structures.
We denote the Σ-degree of a structure A by
[A]Σ. The notion of Σ-degree of a structure is invariant from the choice
of a semilattice SΣ(α), because all inﬁnite structures of the same Σ-degree
have the same cardinality. For any structures A, B ∈Kα, [A]Σ ∨[B]Σ =
[(A, B)]Σ, where (A, B) is a pair of A and B in the model-theoretical sense.
For a structure A ∈Kα and inﬁnite cardinals β ⩽α, γ ⩾α, the sets
Iβ(A) = {[B]Σ | B ∈Kβ, B ⩽Σ A}, Fγ(A) = {[B]Σ | B ∈Kγ, A ⩽Σ B}
are, correspondingly, an ideal in SΣ(β) (principal for β = α) and a ﬁlter
in SΣ(γ) (principal for any γ ⩾α). The sets Fγ(A) in semilattices SΣ(γ)
are natural analogues of the spectrum of a structure A. The sets Iβ(A) in
semilattices SΣ(β) consist of Σ-degrees of structures Σ-presentable over A.
A presentation of a structure M in an admissible set A is any structure
C which is isomorphic to M and whose domain C is a subset of A (the
relation = is treated as a congruence relation on C, and it may diﬀer from

HF-Computability
201
the standard equality relation C).
In what follows, we will identify the
presentation C (more precisely, its atomic diagram) with some subset of A,
ﬁxing a G¨odel numbering of atomic formulas of the signature σM.
Deﬁnition 6.15. A problem of presentability of a structure M in A is the
set Pr(M, A) consisting of all possible presentations of M in A.
Denote by M the set Pr(M, HF(∅)) of presentations of M in the least
admissible set.
Since Σ-deﬁnability in HF(∅) is equivalent to classical computability on
natural numbers, we get the following:
Proposition 6.20. Let M be a countable structure.
The following are
equivalent:
1) M is constructivizable;
2) M is Σ-deﬁnable in HF(∅).
Moreover, there exist natural embeddings of the semilattices D of Tur-
ing degrees and De of degrees of enumerability of sets of natural numbers
into the semilattice SΣ(ω) (and hence into any semilattice SΣ(α)) via the
mappings i : D →SΣ(ω) and j : De →SΣ(ω) deﬁned below. These def-
initions show that the notion of Σ-degree of a structure, which is total,
i.e., deﬁned for any structure, no matter countable or not, is a natural
generalization of the (partial) notion of a degree of a countable structure,
introduced in [127]. Also, we get that the semilattices SΣ(α) extend in a
natural way the semilattices D and De.
Deﬁnition 6.16. Let M be a countable structure. We say that M has
a degree (e-degree) if there exists the least degree in the set of T -degrees
(e-degrees) of all possible presentations of M on natural numbers.
Using the equivalence of “∀-recursiveness” and “∃-deﬁnability”, in the
sense of [85] and [104] (see also [4] and [3]), we get:
Theorem 6.24. [150] For a countable structure M, the following are equiv-
alent:
1) M has a degree (e-degree);
2) there exists a presentation C ∈M which is a ∆-subset (Σ-subset) of
HF(M).

202
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
We deﬁne mappings i : D →SΣ(ω) and j : De →SΣ(ω) in the following
way: for every degree a ∈D, put
i(a) = [Ma]Σ, where Ma is any structure having degree a.
Similarly, for every e-degree b ∈De, put
j(b) = [Mb]Σ, where Mb is any structure having e-degree b.
Lemma 6.5. The mappings i and j are well deﬁned: For any (e-)degree
a there are structures having (e-)degree a.
Moreover, for any countable
structures M and N, if M has (e-)degree a and M ≡Σ N, then N also has
(e-)degree a.
Note, however, that the property of having a (e-)degree is not closed down-
wards w.r.t. ⩽Σ.
Deﬁnition 6.17. [152, 153] For a structure A, a jump of the Σ-degree
[A]Σ (in the semilattice SΣ(card(A))) is the Σ-degree of the structure
A′ = (HF(A), Σ-SatHF(A)),
where Σ-SatHF(A) denotes the satisﬁability relation for the set of Σ-formulas
in HF(A).
The deﬁnition of Σ-jump is correct: For any structures A and B, from
A ≡Σ B it follows that A′ ≡Σ B′. It seems to be an open problem whether
the inequality A <Σ A′ holds for every structure A.
Remark 6.2. In a similar way the jump operation was introduced in [10]
for the semilattice of s-degrees of countable structures. Also, in the same
way a notion of the jump of an admissible set with respect to various
eﬀective reducibilities was introduced in [96, 122]. One more deﬁnition of
the jump of a structure, closely related to the notion of Σ-jump, was given
in [91].
The jump operation for Σ-degrees agrees with the jump operations for
Turing and enumeration degrees w.r.t. the natural embeddings: If a struc-
ture A has a (e-)degree a, then the structure A′ has (e-)degree a′. Hence-
forth, we have the following:
Proposition 6.21. The mappings i : D →SΣ and j : De →SΣ are
embeddings preserving 0, ∨and the jump operation.

HF-Computability
203
The existence of an embedding of D in SΣ was ﬁrst noted in [59].
The jump inversion theorem from the classical computability theory can
also be generalized to the case of the semilattices of Σ-degrees of structures.
There is:
Theorem 6.25. [152, 153] Let A be a structure such that
i(0′) ⩽Σ A.
Then there exists a structure B such that
B′ ≡Σ A.
Remark 6.3. Relation of Σ-reducibility, being deﬁned on structures of ar-
bitrary cardinality, in the case of countable structures can be viewed as the
strongest reducibility in the hierarchy of eﬀective reducibilities on struc-
tures [150, 151] (see Section 6.7). One of the weak reducibilities in this
hierarchy is the Muchnik reducibility.
In [139, 140], the jump inversion
theorem for the semilattices of degrees of presentability of countable struc-
tures with respect to the Muchnik reducibility is proved. As a corollary of
Theorem 6.25, we get the jump inversion theorem for all known eﬀective
reducibilities on countable structures (see Section 6.7).
6.6.2. Σ-Deﬁnability on special structures
As has already been mentioned, cardinality boundaries are unavoidable in
the classical theory of computability (CTC). Numberings allow us to use
CTC for countable objects. Admissible sets of the form HF(M) can have an
arbitrary cardinality. Hence, the following question naturally arise: Does
there exists a “reasonably good” theory T such that the class of admissible
sets of the form HF(M), with M |= T , allows to extend, in some natural
way, the classical theory CTC to the case of objects with an arbitrary
cardinality?
Recall that a theory T of a ﬁnite signature is called regular [33] if it
is decidable and model complete. Recall also, that a theory T is called
c-simple (constructively simple) [33] if it is regular, ω-categorical, and has
a decidable set of the complete formulas.
Remark 6.4. In [33] such theories were called simple, but this terminology
was simultaneously used in the model theory for a diﬀerent notion.
In the deﬁnition of a c-simple theory, ω-categoricity gives the unique-
ness, up to an isomorphism, of a countable model of such theory. Model
completeness, decidability of a theory, and decidability of the set of its

204
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
complete formulas, guarantee the autostability of every constructivization
of this countable theory, i.e., the uniqueness of the “computability” on its
countable models.
Furthermore, if T is a c-simple theory, M0 and M1 are any models
of T (Mi |= T , i = 0, 1), then HF(M0) ≡HF(M1), since the models of
ω-categorical theories are saturated enough ([33]).
Henceforth, for a c-simple theory T , the class of admissible sets of the
form HF(M), M |= T , extends “uniformly” the classical theory of com-
putability for arbitrary inﬁnite cardinalities.
An example of a c-simple theory is the theory TE of inﬁnite structures
with the empty signature. But this theory is too “weak”, if we regard a
theory T being “strong” in case there are many uncountable structures Σ-
deﬁnable in HF(M), M |= T . The reason of the “weakness” of TE is the
following property: For an arbitrary set X and arbitrary permutation f on
X, f can be extended (in a unique way) to an automorphism f ∗of HF(X).
Another example of a c-simple theory is the theory TDLO of dense linear
orders (without endpoints). This theory seems to be quite reasonable candi-
date for a “correct extension of CTC for arbitrary cardinalities”. Below we
present two diﬀerent characterizations of the theories having uncountable
models which are Σ-deﬁnable in HF(L), L |= TDLO.
We now formalize a desired property of TDLO to be the “strongest” in
the class of c-simple theories.
Conjecture 6.1. [34] Suppose a theory T has an uncountable model which
is Σ-deﬁnable in HF(M), for some structure M with a c-simple theory.
Then T has an uncountable model which is Σ-deﬁnable in HF(L) for some
L |= TDLO.
It is an open question whether this conjecture is equivalent to the fol-
lowing one (which is its formal consequence).
Conjecture 6.2. Any c-simple theory has an uncountable model which is
Σ-deﬁnable in HF(L) for some L |= TDLO.
It is known that Conjecture 6.2 is true for rather a “rich” class of c-
simple theories (see Theorem 6.29 below).
Following [23, 32, 33], we present a characterization of the theories hav-
ing uncountable models which are Σ-deﬁnable in HF(L) for L |= TDLO.
The category ∗ω is deﬁned as follows: Its objects are the sets of the
form [n] ⇋{0, 1, . . ., n−1}, n ∈ω ([0] ⇋∅), and its morphisms are order-

HF-Computability
205
preserving embeddings. It should be noted that there is a unique morphism
from [0] into [n] for any n ∈ω.
Deﬁnition 6.18. By a ∗ω-spectrum we mean any functor S from the cat-
egory ∗ω into the category Mod∗
σ of structures (of some ﬁxed signature σ),
whose morphisms are all possible embeddings.
To deﬁne a ∗ω-spectrum S, it is necessary to give an inﬁnite sequence
M0, M1, . . . , Mn, . . ., n ∈ω, of structures of signature σ, and associate with
each order-preserving embeddings µ : [n] →[m] an embedding µ∗: Mn →
Mm so that, if µ0 : [n] →[m] and µ1 : [m] →[k], n ⩽m ⩽k ∈ω, are
morphisms of the category ∗ω, then (µ1µ0)∗= µ1∗µ0∗, and if µ : [n] →[n]
is the unique morphism from [n] into [n] (= id[n]), then µ∗= idMn : Mn →
Mn, n ∈ω.
If the ∗ω-spectrum S={Mn, µ∗|n ∈ω, µ ∈Mor∗ω} has been deﬁned,
then for any linearly ordered set L, it is possible to deﬁne the structure
ML(MS
L) as a direct limit lim
−−→
L0
M′
L0 of the spectrum
{M′
L0, ϕL0,L1 | L0 ⊆L1 ⊆L, L1 is ﬁnite},
where M′
L0 ⇋Mn, if L0 ⊆L is ﬁnite and |L0| = n, and the embedding
ϕL0,L1 : M′
L0 →M′
L1 is deﬁned for ﬁnite L0 ⊆L1(⊆L) as follows: If
L1 = {l0 < l1 < . . . < lm−1} and L0 = {li0 < li1 < . . . < lin−1} (in which
case 0 ⩽i0 < i1 < . . . < in−1 ⩽m) and µ : [n] →[m] is deﬁned as
µ(j) ⇋ij, j < n, then
ϕL0,L1 ⇋µ∗: M′
L0 = Mn →Mm = M′
L1.
If L ⊆L′ are linearly ordered sets, then the structure ML can be identiﬁed
with a substructure of ML′ in a natural way.
Any isomorphism between linearly ordered sets L and L′ induces an
isomorphism between ML and ML′. Also if L ⊆L′ are dense linear orders
without endpoints, then ML ≼ML′. As a corollary, if L and L′ are dense
linear orders without endpoints, then ML ≡ML′.
Let µ0 and µ1 be morphisms from [1] into [2] such that µ0(0) = 0 and
µ1(0) = 1. The condition
µ0∗̸= µ1∗
(∗)
is suﬃcient for |MS
L| ⩾|L| to hold for any linearly ordered set L.

206
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
Deﬁnition 6.19. A system of numberings νn : ω →Mn, n ∈ω, is called a
computable sequence of constructivization
(M0, ν0), (M1, ν1), . . . , (Mn, νn), . . . , n ∈ω,
if the following conditions hold (we assume that the signature σ of the
structures M0, M1, . . . is ﬁnite and without function symbols):
1) E ⇋{⟨n, m0, m1⟩|n, m0, m1 ∈ω, νn(m0) = νn(m1)} is a ∆-predicate
on ω;
2) NP ⇋{¯n = ⟨n0, n1, . . . , nk⟩|¯n ∈ωk+1, ⟨νn0(n1), . . . , νn0(nk)⟩∈P Mn0}
is a ∆-predicate on ω for any (k-ary) predicate symbol P ∈σ;
3) for any constant symbol c ∈σ there exists a Σ-function fc : ω →ω
such that cMn = νnfc(n).
Every morphism µ : [n] →[m] of the category ∗ω is uniquely deﬁned
by the number m and the subset µ([n]) ⊆[m]. This remark allows us to
deﬁne a one-to-one correspondence µ∗: ∆→Mor∗ω between the subset
∆⇋{n|n ∈ω, r(n) < 2l(n)} ⊆ω and the set Mor∗ω, provided that n ∈∆
is assumed to code the morphism µ : [k] →[l] such that l = l(n) and r(n)
is the number of the subset µ([k]) ⊆[l] = [l(n)] in some standard listing of
the ﬁnite subsets of ω. It is evident that ∆is a ∆-subset of ω.
Deﬁnition 6.20. Let S = {Mn, µ∗|n ∈ω, µ ∈Mor∗ω} be a ∗ω-spectrum.
By a constructivization of S we mean any computable sequence of construc-
tivizations
(M0, ν0), (M1, ν1), . . . , (Mn, νn), . . . , n ∈ω,
together with a Σ-function f : ∆× ω →ω such that, for any n, m, k ∈ω
and µ : [n] →[m] ∈Mor∗ω, if n∗∈∆is such that µ∗(n∗) = µ, then
µ∗νn(k) = νmf(n∗, k).
A ∗ω-spectrum S is called constructivizable if there exists a construc-
tivization for it.
Theorem 6.26. [33] Let L be a dense linear order without endpoints. A
theory T has an uncountable model Σ-deﬁnable in HF(L) if and only if there
exists a constructivizable ∗ω-spectrum S, satisfying condition (∗), and such
that MS
L |= T .
One of the important corollaries of this theorem is the ﬁrst part of the
following result, showing that the ﬁeld C of complex numbers is rather
“simple”. The second part shows that C is not “too simple”.

HF-Computability
207
Theorem 6.27. [33]
1) C is Σ-deﬁnable in HF(L) for any dense linear order L of size contin-
uum;
2) C is not Σ-deﬁnable in HF(S) for any structure S with empty signature.
A structure A is called locally constructivizable [33] if Th∃(A, a) is c.e.
for every a ∈A<ω. It is easy to verify that a structure A is locally con-
structivizable if and only if, for any a ∈A<ω, there exist a constructivizable
structure B and a tuple b ∈B<ω such that (A, a) ≡1 (B, b) (or, which is
the same, HF(A, a) ≡1 HF(B, b)). Symbol ≡α, here and further on, denotes
elementary equivalence w.r.t. the class of formulas with less than α groups
of alternating groups of quantiﬁers in the prenex normal form (0 ⩽α ⩽ω).
Henceforth, the next deﬁnition is a generalization of the notion of local
constructivizability.
Deﬁnition 6.21. [151] A structure A is called locally constructivizable of
level α (0 < α ⩽ω) if for any a ∈A<ω there exists a constructivizable
structure B and a tuple b ∈B<ω such that
HF(A, a) ≡α HF(B, b).
Local constructivizability of any level is preserved by Σ-deﬁnability.
There is:
Proposition 6.22. [151] Let A and B be such that A ⩽Σ B and B is
locally constructivizable of level α, 0 < α ⩽ω.
Then A is also locally
constructivizable of level α.
Any structure with a c-simple theory is saturated enough [33] and lo-
cally constructivizable of level ω.
Moreover, its countable “computable
simulation”, in the terminology from [89], is unique up to the computable
isomorphism.
The situation is diﬀerent in the case of regular theories:
There are structures with a regular theory, which are not locally construc-
tivizable even of level 1. For example, consider the ﬁelds R and Qp of real
and p-adic numbers.
Corollary 6.7. [33] For any linear order L, ﬁelds R and Qp are not Σ-
deﬁnable in HF(L).

208
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
In some cases there are more simple criteria, for a given theory, of the
existence of uncountable models Σ-deﬁnable in HF(L), L |= TDLO. We now
present such a criterion for c-simple theories.
The next deﬁnition is a generalization of the model-theoretical notions
of order and total indiscernibility.
Deﬁnition 6.22. For structures A, B and some k > 0, a set I ⊆Ak ∩B
is called a set of A-indiscernibles in B (with dimension k) if for any pair of
tuples i, i
′ ∈I<ω with the same length,
⟨A, i⟩≡⟨A, i
′⟩implies ⟨B, i⟩≡⟨B, i
′⟩.
Proposition 6.23. Suppose A is uncountable structure, structure B is sat-
urated enough and locally constructivizable of level ω, and let A ⩽Σ B.
There exist computable structures A0 and B0 such that A0 ≡A, B0 ≡B,
and there is an inﬁnite computable set of (B0, b0)-indiscernibles in A0 with
a dimension k, for some k > 0 and b0 ∈(B0)<ω.
For certain c-simple theories this necessary condition of Σ-deﬁnability of
uncountable models can be simpliﬁed (by assuming the dimension to equal
1), and turns out also to be suﬃcient. Namely, for theory TDLO of dense
linear orders without endpoints, and theory TE of inﬁnite structures with
empty signature, there is
Theorem 6.28. [145] Let T be a c-simple theory, and let A be any com-
putable model of T . Then
1) there exists an uncountable M |= T such that M ⩽Σ L, L |= TDLO, if
and only if there exists an inﬁnite computable set of order indiscernibles
in A (with dimension 1);
2) there exists an uncountable M |= T such that M ⩽Σ S, S |= TE, if and
only if there exists an inﬁnite computable set of total indiscernibles in
A (with dimension 1).
Remark 6.5. This result is not true in the case theory T is not c-simple.
For example, there exists a computable algebraically closed ﬁeld (with char-
acteristic 0) with an inﬁnite computable set of total indiscernibles (see [62]),
but there are no uncountable algebraically closed ﬁelds (with characteristic
0) Σ-deﬁnable in HF(S), S |= TE.
We now present some applications of Theorem 6.28.

HF-Computability
209
Deﬁnition 6.23. Let n ∈ω. A (ﬁrst-order) theory T is called n-discrete
if every ﬁnite type of T is uniquely determined by its n-subtypes.
A theory T is called discrete if it is n-discrete for some n ∈ω. If T
is n-discrete and has a ﬁnite number of n-types then T is ω-categorical
and submodel complete in some expansion by a ﬁnite number of deﬁnable
predicates. Any regular n-discrete theory with a ﬁnite number of n-types is
c-simple. Also, any submodel complete theory of a ﬁnite relational signature
is n-discrete with a ﬁnite number of n-types, for some n ∈ω, and any ω-
categorical submodel complete theory of a ﬁnite signature is n-discrete with
a ﬁnite number of n-types, for some n ∈ω.
A theory T is called sc-simple [154] if it is ω-categorical, submodel com-
plete, decidable, and has a decidable set of complete formulas. Henceforth,
a theory (of a ﬁnite signature) is sc-simple if it is c-simple and submodel
complete.
From the Ehrenfeucht–Mostowski Theorem we get
Proposition 6.24. [154] If T is a sc-simple theory of a ﬁnite signature
then, in any computable model of T , there exists an inﬁnite computable set
of order indiscernibles.
As a corollary of the above fact, we get
Theorem 6.29. [154] Let T be sc-simple theory of a ﬁnite signature. There
exists an uncountable model A of T such that A ⩽Σ L, L |= TDLO.
In the case of an inﬁnite signature there is a counterexample. Using a
construction from [63] together with Theorem 6.28, the following result was
proved in [145]:
Theorem 6.30. There is an sc-simple theory of an inﬁnite computable
signature, such that, for any uncountable A |= T and any L |= TDLO, we
have A ̸⩽Σ L.
We now present some examples of sc-simple theories. For a ω-categorical
theory T , by a Ryll-Nardzewski function of T we mean the function rT :
ω →ω deﬁned as follows: for any n ∈ω, rT (n) is the number of (complete)
n-types of theory T .
It is easy to check that, for any ω-categorical decidable theory T , the
following are equivalent:
1) T has a decidable set of complete formulas;
2) T has a decidable Ryll-Nardzewski function.

210
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
One of the methods for constructing ω-categorical theories is the Fra¨ıss´e
construction [46]. Let K be a class of ﬁnitely generated structures of some
ﬁxed signature. K is said to satisfy, respectively,
1) the hereditary property (K |= HP) if, for any A ∈K and B, B ⊆A
implies that B ∈K;
2) the joint embedding property (K |= JEP) if, for any A, B ∈K, there is
C ∈K such that there exist embeddings A ֒→C and B ֒→C;
3) amalgamation property (K |= AP) if, for any A, B, C ∈K and embed-
dings f1 : C ֒→A, f2 : C ֒→B, there are D ∈K and embeddings
g1 : A ֒→D, g2 : B ֒→D such that f1g1 = f2g2;
4) the property of uniform local ﬁniteness (K |= ULF) if there is a function
f : ω →ω such that, for any A ∈K with no more than n generators,
the cardinality of A is no more than f(n).
If a class K of ﬁnitely generated structures satisfy the properties
HP, JEP and AP, then there is a unique, up to the isomorphism, submodel
complete countable structure A, the class of ﬁnitely generated substructures
of which is equal to K, up to the isomorphism (see, for example, [46]). We
call such structure A a Fra¨ıss´e limit of K (denoted as A = limF K).
Theorem 6.31 (see [46]). Let K be a countable class of ﬁnitely gen-
erated structures of some ﬁxed ﬁnite signature, satisfying the properties
HP, JEP, AP, and ULF. Then limF K is ω-categorical.
We present some examples of sc-simple theories constructed via Fra¨ıss´e
limits (see [62, 63] for the details related to decidability).
Let FinGraph be the class of all ﬁnite symmetric graphs. It is easy to
check that this class satisﬁes the properties HP, JEP, AP, and ULF.
Deﬁnition 6.24. A symmetric graph A is called random if, for any ﬁnite
X, Y ⊆A such that X ∩Y = ∅, there is a vertex v ∈A \ (X ∪Y ) such that
v is adjacent with all vertexes from X and not with vertexes from Y .
Proposition 6.25 (see [46]). If A is the Fra¨ıss´e limit of the class
FinGraph then A is a random graph. Moreover, Th(A) is sc-simple.
Corollary 6.8. [154] There is an uncountable random graph A such that
A ⩽Σ L, L |= TDLO.

HF-Computability
211
Let σ be a ﬁnite predicate signature.
The class Fin(σ) of all ﬁnite
structures of signature σ satisﬁes the properties HP, JEP, AP, and ULF.
Deﬁnition 6.25. Let σ be a ﬁnite predicate signature. A random structure
Ran(σ) of signature σ is the Fra¨ıss´e limit of the class Fin(σ).
Corollary 6.9. [154] There is an uncountable structure A ≡Ran(σ) such
that A ⩽Σ L, L |= TDLO.
For other computability properties of Fra¨ıss´e limits we refer the reader
to [17].
6.6.3. Special cases of Σ-deﬁnability
In some cases, for structures A and B one can say more than just state
the fact that A ⩽Σ B. For example, it is obvious that HF(A) ⩽Σ A for
any A, but, in case of the standard model of arithmetic N, much stronger
result is true: HF(N) is Σ-deﬁnable within N, not using the elements of the
superstructure.
In particular, a natural additional restriction on Σ-deﬁnability of struc-
tures in admissible sets is the restriction on the rank of elements used in this
process. To describe the situation formally, we now give some deﬁnitions.
Fix some signature σ, and let P be an unary predicate symbol not in σ.
For any formula Φ of the signature σ ∪{∈}, with the bounded quantiﬁers
of the form ∀x ∈t and ∃x ∈t, we deﬁne by induction the relativization ΦP
of Φ by P:
– if Φ is an atomic formula, put ΦP = Φ;
– if Φ = (Φ1 ∗Φ2), ∗∈{∧, ∨, →}, put ΦP = (ΦP
1 ∗ΦP
2 );
– if Φ = ¬Ψ, put ΦP = ¬ΨP ;
– if Φ = (Qx ∈y)Ψ, Q ∈{∀, ∃}, put ΨP = (Qx ∈y)ΨP ;
– if Φ = ∃xΨ, put ΦP = ∃x(P(x) ∧ΨP);
– if Φ = ∀xΨ, put ΦP = ∀x(P(x) →ΨP ).
Let now A be an admissible set, B ⊆A be some transitive subset of A,
and Φ(x0, . . . , xn−1) be a formula of the signature σA. Deﬁne the set
(Φ(x0, . . . , xn−1))B = {⟨a0, . . . , an−1⟩∈An | ⟨A, B⟩|= ΦP (a0, . . . , an−1)}.
Deﬁnition 6.26. [146] Let A be an admissible set, B ⊆A be some
transitive subset of A. A structure of a computable predicate signature
⟨P0, P1, . . .⟩, where each Pi is ni-ary, is called Σ-deﬁnable in A inside B if
there exist a computable sequence
Φ(x0, y), Ψ(x0, x1, y), Ψ∗(x0, x1, y), Φ0(x0, . . . , xn0−1, y),

212
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
Φ∗
0(x0, . . . , xn0−1, y), . . . , Φk(x0, . . . , xnk−1, y), Φ∗
k(x0, . . . , xnk−1, y), . . .
of Σ-formulas of σA, and a parameter b ∈B, such that, for the sets
M0 ⇌ΦB(x0, b), M0 ⊆B, η ⇌ΨB(x0, x1, b) ∩M 2
0,
the following holds: M0 ̸= ∅, η is a congruence relation on the structure
M0 ⇌⟨M0, P M0
0
, . . . , P M0
k
, . . .⟩,
where P M0
k
⇌(Φk(x0, . . . , xnk−1))B ∩M nk
0 , k ∈ω,
(Ψ∗(x0, x1, a))B ∩M 2
0 = M 2
0 \ (Ψ(x0, x1, a))B,
(Φ∗
k(x0, . . . , xnk−1, a))B ∩M nk
0
= M nk
0
\ (Φk(x0, . . . , xnk−1))B
for any k ∈ω, and the quotient structure M is isomorphic to M0⧸η.
For an admissible set A and a subset B ⊆A, deﬁne the ordinal rnk(B)
as follows:
rnk(B) = sup{rnk(b)|b ∈B}.
Deﬁnition 6.27. [146] The rank of inner constructivizability of an admis-
sible set A is the ordinal
cr(A) = inf{rnk(B) | A is Σ-deﬁnable in A inside B}.
The next theorem gives the precise estimate for the rank of inner con-
structivizability of hereditarily ﬁnite superstructures. It can be viewed as
an eﬀective analogue of some results from [90] on deﬁnability in higher order
languages.
Theorem 6.32. [146] Let M be a structure of a computable signature.
1) If M is ﬁnite then cr(HF(M)) = ω.
2) If M is inﬁnite then cr(HF(M)) ⩽2.
As a corollary of Theorem 6.32 we get the following. For structures M,
N, and a natural number n ∈ω, we denote by M ⩽n
Σ N the fact that M is
Σ-deﬁnable in HF(N) inside the subset consisting of all elements with the
rank less or equal n. If N is an inﬁnite structure then
M ⩽n
Σ N if and only if M ⩽Σ N
for any M and any n ⩾2.
Typical examples of structures M with cr(HF(M)) = 2 are inﬁnite struc-
tures with the empty signature, dense linear orders, and, more interesting

HF-Computability
213
one, the structure ⟨ω, s⟩of natural numbers with the successor function.
This fact follows from the next proposition, taking into account the decid-
ability of ThWM(⟨ω, s⟩), where ThWM(M) is the weak monadic second-order
theory of M.
Proposition 6.26. [146] If ThWM(M) is decidable then cr(HF(M)) = 2.
An example of a structure M with cr(HF(M)) = 0 is, obviously, the
standard model of arithmetic. An example of a structure which hereditary
ﬁnite superstructure has rank of inner constructivizability 1 is the ﬁeld R
of real numbers. There is the following:
Proposition 6.27. [146] cr(HF(R)) = 1.
Another natural special type of a Σ-presentation of a structure M in
an admissible set A, s.t. M ⊆U(A), is a Σ-presentation preserving the
domain of a structure. For a signature σ and an ordinal n ⩽ω, we denote
by Formn(σ) the set of (ﬁnite ﬁrst-order) formulas of the signature σ,
which have a prenex normal form with no more than n alternating groups
of quantiﬁers.
We assume that, for any signature considered, some G¨odel numbering
⌈·⌉of its terms and formulas is ﬁxed.
Deﬁnition 6.28. Let M be a structure of a ﬁnite signature σ, A an admis-
sible set, and let M ⊆U(A). The structure M is n-decidable in A (n ⩽ω)
if
{⟨⌈ϕ⌉, m⟩| ϕ ∈Formn(σ), m ∈M <ω, M |= ϕ(m)}
is ∆-deﬁnable in A.
A structure M is computable in A if M is 0-decidable in A, and decidable
in A if M is ω-decidable in A.
Proposition 6.28. If Th(M) is regular then M is decidable in HF(M).
The decidability is rather a strong condition. For example, there is:
Proposition 6.29. A liner order L is 1-decidable in HF(L) if and only if
L is a sum of a ﬁnite number of dense linear orders and points.
A structure M of signature σ is n-complete [37] (n ⩽ω) if for any
formula ϕ(x) ∈Formn(σ) and for any m ∈M <ω such that M |= ϕ(m)

214
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
there exists a ∃-formula ψ(x) such that M |= ψ(m) and M |= ∀x(ψ(x) →
ϕ(x)). The following proposition follows immediately from the deﬁnitions.
Proposition 6.30.
1) Suppose M is n-decidable in HF(M) (n ⩽ω). Then M is n-complete
in some expansion of M by a ﬁnite number of constants.
2) Suppose M is n-complete and Th(M) is decidable.
Then M is n-
decidable in HF(M).
Suppose M is 1-decidable in HF(M). Then HF(M) is quasiresolvable,
and hence has a universal Σ-function and satisﬁes reduction, but not nec-
essarily uniformization.
Let M be a structure of signature σ and let signature σ∃-Skolem consist
of all symbols of σ and new functional symbols fϕ(x1, . . . , xn) for all ∃-
formulas ϕ(x0, x1, . . . , xn) of signature σ. The structure M′ of signature
σ∃-Skolem is called an ∃-Skolem expansion of M if M ′ = M, M ↾σ= M′ ↾σ,
and for any ∃-formula ϕ(x0, x1, . . . , xn) of signature σ
M′ |= ∀x1 . . . ∀xn(∃xϕ(x, x1, . . . , xn) →ϕ(fϕ(x1, . . . , xn), x1, . . . , xn)).
Theorem 6.33. [142] If HF(M) satisﬁes uniformization then some ∃-
Skolem expansion of M is computable in HF(M).
In some cases, this necessary condition is also suﬃcient.
Skolem expansion MS of a structure M is well deﬁned if for every
ϕ(x0, x1, . . . , xn) ∈Form(σ), every m ∈M n, and every permutation ρ
of the set {1, . . . , n},
M |= (ϕ(x0, m) ↔ϕ(x0, ρ(m))) implies MS |= (fϕ(m) = fϕ(ρ(m))),
where ρ(m) = ⟨mρ(1), . . . , mρ(n)⟩.
The next theorem is a reformulation (and correction) of the main result
from [142] (unfortunately, the property of well-deﬁnedness for Skolem ex-
pansions was not explicitly stated there, yet it was implicitly used in the
text).
Theorem 6.34. [142, 157] Suppose Th(M) is regular. Then HF(M) sat-
isﬁes uniformization if and only if some well-deﬁned ∃-Skolem expansion
MS of M is computable in HF(M).
Remark 6.6. As it was recently noted (see [157]), this theorem admits a
natural reformulation in terms of the s-reducibility on structures [10] and

HF-Computability
215
Proposition 6.31 can be viewed as a natural (and non-trivial) example of
s-equivalence.
One of the important corollaries of this criterion follows from the next
result.
Proposition 6.31. [142] There exist well-deﬁned Skolem expansions RS
and (Qp)S, of the ﬁelds R and Qp, respectively, such that RS and (Qp)S
are computable in HF(R) and HF(Qp), respectively.
Corollary 6.10. [142] Structures HF(R) and HF(Qp) satisfy uniformiza-
tion and have a universal Σ-function.
For
HF(R), the uniformization property and existence of a universal
Σ-function was independently proved in [141] and [66].
The role of parameters in the Σ-deﬁnition of a structure is rather impor-
tant. For example, as it is easy to see, any countable structure is Σ-deﬁnable
in HF(R), where R is the ﬁeld of real numbers. The case of Σ-deﬁnability
without parameters turned out to be more interesting, as it was shown
recently in [100].
Theorem 6.35. [100] Suppose a countable structure M is Σ-deﬁnable in
HF(R) without parameters. Then M has a hyperarithmetic presentation.
This estimate is precise, as follows from the next theorem:
Theorem 6.36. [100] For any δ < ωCK
1
there is a countable structure M
such that
1) M is Σ-deﬁnable in HF(R) without parameters;
2) for any H ⊆ω such that M has an H-computable presentation, holds
0(δ) ⩽T H.
In case we ﬁx some restrictions on the cardinality of the congruence
classes, the estimate of complexity becomes much lower.
Theorem 6.37. [100] Let M be a countable structure with a ﬁnite signa-
ture. The following are equivalent:
1) M is Σ-deﬁnable without parameters in HF(R), and all equivalence
classes are at least countable;
2) M is computable.

216
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
For other results on computability (Σ-deﬁnability) on the reals and on
some topological spaces, we refer the reader to [65–70, 99], and [71–80, 117].
6.7. Semilattices of Degrees of Presentability of Structures
Relation ⩽Σ of Σ-reducibility, being deﬁned on structures of arbitrary car-
dinality, in the case of countable structures can be viewed as the strongest
reducibility in the hierarchy of eﬀective reducibilities on structures, as it
was shown in [150, 151]. We overview brieﬂy some of the results in this
ﬁeld.
Let A be an admissible set. We deﬁne uniform reducibilities on fami-
lies of subsets of A, which are the direct generalizations of the Medvedev,
Muchnik, and Dyment reducibilities on mass problems. Let X, Y ⊆P(A).
Then,
(1) X is Medvedev reducible to Y (X ⩽Y) if there are binary Σ-operators
F0 and F1 such that, for all Y ∈Y, ⟨Y, A \ Y ⟩∈δc(F0) ∩δc(F1), and for
some X ∈X, X = F0(Y, A \ Y ) and A \ X = F1(Y, A \ Y );
(2) X is Dyment reducible to Y (X ⩽e Y) if there is a unary Σ-operator
F such that Y ∈δc(F) for all Y ∈Y, and F(Y) ⊆X;
(3) X is Muchnik reducible to Y (X ⩽w Y) if for every Y ∈Y there are
binary Σ-operators F0 and F1 such that ⟨Y, A \ Y ⟩∈δc(F0) ∩δc(F1), and
for some X ∈X, X = F0(Y, A \ Y ) and A \ X = F1(Y, A \ Y );
(4) X is weakly Dyment reducible to Y (X ⩽e Y) if there is a unary
Σ-operator F such that Y ∈δc(F) for every Y ∈Y, and F(Y ) ∈X.
For any admissible set A and for any r ∈{e, , w, ew} (here r = ‘
’ is
used to denote the Medvedev reducibility), we denote by Mr(A) the degree
structure ⟨P(P(A))/ ≡r, ⩽r⟩. We will write Mr instead of Mr(HF(∅)) for
brevity. All structures of the form Mr(A) are lattices with 0 and 1, and
M, Me, and Mw are isomorphic to the Medvedev, Dyment, and Muchnik
lattices, respectively.
For a countable structure M, we consider the following classes consisting
of structures that are eﬀectively reducible to M:
KΣ(M) = {N | N ⩽Σ M},
Ke(M) = {N | N ⩽e (M, ¯m) for some ¯m ∈M <ω},
K(M) = {N | N ⩽(M, ¯m) for some ¯m ∈M <ω},
Kew(M) = {N | N ⩽ew M},
Kw(M) = {N | N ⩽w M}.

HF-Computability
217
It is known [151] that for any structure M, the following inclusions hold:
KΣ(M) ⊆Ke(M) ⊆K(M) ⊆Kw(M),
and
Ke(M) ⊆Kew(M) ⊆Kw(M).
In general, all these inclusions are proper [48].
For any r ∈{e, , w, ew}, we deﬁne a relation ⩽r on Kω by setting
M ⩽r N iﬀKr(M) ⊆Kr(N) and letting Sr = ⟨Kω/ ≡r, ⩽r⟩be the structure
of degrees of presentability corresponding to this relation.
Theorem 6.38. For any r ∈{e, , w, ew}, the structure Sr is an upper
semilattice with 0, and the following embeddings (֒→) and homomorphisms
(→) hold:
D ֒→De ֒→SΣ →Se →S ֒→M.
As a corollary from this result and the Jump Inversion Theorem for the
semilattices of Σ-degrees we get:
Theorem 6.39. [152, 153] Let r be an eﬀective reducibility, i.e., r ∈
{e, , w, ew}. If A is a structure with
0′ ⩽r A then there exists a structure
B such that
B′ ≡r A.
This result can be generalized to the case of degrees of presentability of
structures in arbitrary admissible sets, see [156].
For arbitrary structures M and M′ with the same signature and any n ∈
ω, we denote by M ≡HF
n
M′ the fact that HF(M) ≡n HF(M′). It is clear
that for n < 2, M ≡HF
n
M′ if and only if M ≡n M′. In case n = 2, M ≡HF
2
M′ if and only if, for any computable sequence {ϕmn(xm, yn)|m, n ∈ω} of
quantiﬁer-free formulas of signature σM,
M′ |=
_
m∈ω
∃xm
^
n∈ω
∀ynϕmn(xm, yn)
if and only if the same sentence is true in M.
For arbitrary structures M and N, we denote by M ⩽∃N the fact
that, for any tuple m ∈M <ω, there exists a tuple n ∈N <ω such that
Th∃(M, m) ⩽e Th∃(N, n). In particular, if M is locally constructivizable
then M ⩽∃N for any structure N. As was noted in [33], if M ⩽Σ N and

218
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
N is locally constructivizable then M is also locally constructivizable. A
straightforward generalization of this fact is as follows: M ⩽Σ N implies
M ⩽∃N.
Deﬁnition 6.29. A structure M is uniformly locally constructivizable of
level n (1 < n ⩽ω) if there exists a constructivizable structure N for which
M ≼HF
n
N.
For instance, the structure ⟨ωCK
1
, ⩽⟩is uniformly locally constructiviz-
able of level ω since ⟨ωCK
1
, ⩽⟩≼HF ⟨ωCK
1
(1+η), ⩽⟩, where the last ordering
(known as the Harrison ordering) is constructivizable.
Proposition 6.32. If M ⩽Σ N and a structure N is (uniformly) locally
constructivizable of level n (1 < n ⩽ω), then M is also (uniformly) locally
constructivizable of level n.
The next proposition states that a class of locally constructivizable (of
level 1) countable structures is downward closed w.r.t. ⩽w, which is weakest
among the reducibilities under consideration.
Proposition 6.33. Let M and N be structures. Then N ⩽∃M if N ∈
Kw(M). In particular, if M is locally constructivizable, then every structure
N ∈Kw(M) is also locally constructivizable.
A pair (M, N) is locally constructivizable iﬀso are M and N; therefore,
a set of degrees generated by locally constructivizable structures is an ideal
in semilattices Sr, r ∈{Σ, e, , w, ew}. Classes of locally constructivizable
structures of level n, n > 1, however, are downward closed w.r.t. ⩽Σ only
(so they form initial segments in SΣ). For weaker reducibilities, this is not
the case. For example, we have:
Theorem 6.40. There exists a countable structure M0 which is locally
constructivizable of level 1 (strictly) and is such that M0 ⩽M for every
nonconstructivizable countable structure M.
Speciﬁcally, if M is locally
constructivizable of level n > 1 but is not constructivizable, then KΣ(M) ⊊
K(M).
The proof makes use of the result (obtained by T. Slaman [137], and,
independently, S. Wehner [164]) which states that there exists a structure
whose problem of presentability belongs to the least nonzero degree of the
Medvedev lattice (which, in particular, means that a semilattice S of de-
grees of presentability has a least nonzero element). Every such structure
is locally constructivizable. Namely, in [150] was proved the following:

HF-Computability
219
Theorem 6.41. There exist a countable structure M and a unary relation
P ⊆M for which (M, P) ≡M but (M, P) ̸⩽Σ M.
Theorem 6.41 is of interest in connection with the following result in [4]:
For any countable structure M, a relation P ⊆M n, n ∈ω, is Σ-deﬁnable
in HF(M) iﬀP C is C ↾σM-c.e. for every C ∈(M, P).
The next result from [150] gives some suﬃcient conditions for the equal-
ity of the principal ideals generated by a structure M with respect to dif-
ferent eﬀective reducibilities.
Theorem 6.42. If M has a degree then KΣ(M) = Ke(M) = K(M) =
Kw(M). If M has an e-degree then KΣ(M) = Ke(M) = Kew(M).
A natural (open) question is, Are these suﬃcient conditions also necessary?
For structures M and N with card(M) ⩽card(N), consider the class
K(M, N) = {M′ | Pr(M′, HF(N)) ⩽Pr((M, ¯m), HF(N)), ¯m ∈M <ω}.
Classes Ke(M, N), Kw(M, N), and Kew(M, N) are deﬁned similarly.
Proposition 6.34. Let M and N be countable structures and let N be a
structure of the empty signature, or dense linear order. Then KΣ(M) =
Ke(M, N) = K(M, N).
As a consequence, there exist natural isomorphisms between a semilat-
tice SΣ of degrees of Σ-deﬁnability and semilattices S(HF(N)) of degrees
of presentability, where N is a countable structure of the empty signature,
or dense linear order.
One more result on the equivalence of “∀-recursiveness” and “∃-
deﬁnability”, in the sense of [85] and [104] (see also [4] and [3]), is the
following:
Theorem 6.43. For any countable structures M and N and any relation
R ⊆HF(N), the following conditions are equivalent:
1) R ⩽eΣ C for every presentation C of M in the admissible set HF(N);
2) R is Σ-deﬁnable in HF(M, N).
Deﬁnition 6.30. Let M and N be countable structures. Structure M has
a degree (an e-degree) over structure N if there exists a least degree among
all T Σ-degrees (eΣ-degrees) of all possible presentations of M in HF(N).

220
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
An immediate consequence of 6.43 is a generalization of 6.24:
Theorem 6.44. Let M and N be countable structures. Then the conditions
below are equivalent:
1) M has a degree (an e-degree) over N;
2) some presentation C ⊆HF(N) of M is a ∆-subset (Σ-subset) in
HF(M, N).
Obviously, for M ⩽∃N, the structure M has a degree, and also an
e-degree, over N iﬀM ⩽Σ N. It is also clear that if M has a degree, and
also an e-degree, over N, and N ⩽Σ N′, then M has a degree, and also
an e-degree, over N′. Furthermore, we have for any countable structure
A, there exists a structure M which has a degree but is not Σ-deﬁnable in
HF(A).
As in the nonrelativized case, we have:
Theorem 6.45. Let M and N be countable structures. If M has a degree
over N, then KΣ(M, N) = Ke(M, N) = K(M, N). If M has an e-degree
over N, then KΣ(M, N) = Ke(M, N).
6.8. Closely
Related
Approaches
to
Generalized
Com-
putability
Now, we overview some of the approaches to the computability over abstract
structures, looking for the diﬀerences and similarities of a given approach
and the approach based on HF-computability.
6.8.1. BSS-computability
All results of this section are from [8], and we use the original terminology
from this paper, saying “recursive” instead of “computable”. The following
deﬁnition is a generalization of the main deﬁnition from [14]. Let M be a
structure of a ﬁnite signature σ.
Deﬁnition 6.31. A BSS-machine contains following:
1) a triple of positive integers ⟨m, n, k⟩, which are called input, work-
ing, and output dimensions, respectively, and are denoted by m=dimIM,
n=dimW M, and k=dimOM;
2) a ﬂow chart of a program.

HF-Computability
221
A ﬂow chart of a program is a connected directed graph having 4 types
of nodes, with each of which, either a tuple of terms or an atomic formula
of signature σ is associated.
(1) There exists a unique node without incoming edges. It has just one
outgoing edge and the associated tuple of terms
⟨t1(x1, . . . , xm), . . . , tn(x1, . . . , xm)⟩,
(1)
which is called an input node. Here m and n are the input and working
dimensions, respectively. We call this node an input node.
(2) There exists at least one node without outgoing edges.With each such
node we associate a tuple of terms
⟨t1(x1, . . . , xn), . . . , tk(x1, . . . , xn)⟩,
(2)
and we call it an output tuple. Here n and k are the working and output
dimensions, respectively. We call such nodes output nodes.
(3) A computation node has several incoming and one outgoing edge. As-
sociated with this node is a tuple of terms
⟨t1(x1, . . . , xn), . . . , tn(x1, . . . , xn)⟩,
(3)
where n is the working dimension.
(4) A branch node has several incoming and two outgoing edges. One of
the outgoing edges is labeled by “0”, the other by “1”. Associated with
this node is an atomic formula ϕ(x1, . . . , xn), where n is the working
dimension, in the signature σ.
Note that a ﬂow chart may have no computation and branch nodes.
Each term t(x1, . . . , xr) of signature σ deﬁnes a term function f : M r →
M as follows: f(m1, . . . , mr) = t(m1, . . . , mr) for m1, . . . , mr ∈M. Each
tuple of terms ⟨t1(x1, . . . , xr), . . . , ts(x1, . . . , xr)⟩deﬁnes a term function
f : M r →M s similarly.
We deﬁne an arbitrary BSS-machine S over a structure M. The sets
¯I = Am, ¯S = An, ¯O = Ak are called, respectively, input, working, and
output spaces.
Given any x ∈¯I, a BSS-machine does computations which either never
halt or halt and produce y ∈¯O. First, the machine sends x into an input
node, which computes the term function I(x) deﬁned by the associated
tuple of terms (1). The resulting value z = I(x) goes along the outgoing
edge to the next node. At a computation node, the term function g deﬁned

222
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
by the tuple (3) is applied to z, and g(z) is sent along the outgoing edge.
When z ∈¯S reaches (if ever) a branch node, the truth value of associated
formula ϕ(z) is computed. If ϕ(z) is true, the element z goes to the next
node along the edge labeled “1”; if not, it is sent along the edge labeled
“0”. At an output node, the element z ∈¯S is converted to y = O(z) of the
output space, where O is the term function deﬁned by the associated tuple
of terms (2), and the machine S halts and produces y ∈¯O. If the machine
never reaches some output node, we say that the result is undeﬁned.
If the machine S with input x ∈¯I outputs y, we write y = S(x).
The set
Ω(S, M) = {x ∈¯I| S halts on input x}
is called the halting set of a machine S in the structure M.
Deﬁnition 6.32. A function f : Ω→M k, Ω⊆M m, is said to be BSS-
computable if there exists a BSS-machine S such that Ω= Ω(S, M) and
f(x) = S(x) for all x ∈Ω.
Deﬁnition 6.33. A set X ⊆M n is called recursively enumerable over M
if and only if it is the domain of some BSS-computable function over M.
A set X ⊆HL(M) is called recursively enumerable (r.e.) if it is r.e. over
HL(M).
Deﬁnition 6.34. A set X ⊆M n is called recursive over M if X itself and
its complement M n \ X are r.e. over M. Recursive sets X ⊆HL(M) over
HL(M) are called recursive.
Deﬁnition 6.35. A set X ⊆M n is called an output set over M if X is the
range of some BSS-computable function over M. Output sets X ⊆HL(M)
over HL(M) are called (simply) output sets.
Lemma 6.6. Each recursive set over M is r.e. over M. Each r.e. set over
M is an output set over M.
Proposition 6.35. The following statements are valid:
1) each r.e. set X ⊆HL(M)n is the projection of some recursive set
over HL(M);
2) X ⊆HL(M)n is the output set over HL(M) if and only if X is the
projection of a recursive set over M.

HF-Computability
223
Theorem 6.46. Each recursively enumerable set X ⊆M n over HL(M) is
deﬁned in M by a formula of the form
_
i∈ω
ϕi(x1, . . . , xn),
where {ϕi | i ∈ω} is a recursive set of quantiﬁer-free formulas in the
signature σ. Conversely, each set X ⊆M n deﬁned by a formula
_
i∈ω
ϕi(x1, . . . , xn),
where {ϕi | i ∈ω} is a recursively enumerable set of quantiﬁer-free formulas
in the signature σ, is recursively enumerable over HL(M).
Theorem 6.47. Each output set X ⊆M n over HL(M) is deﬁned in M by
a formula of the form
_
i∈ω
(∃xi)ϕi(xi, y1, . . . , yn),
where {ϕi | i ∈ω} is a recursive set of quantiﬁer-free formulas in the
signature σ. Conversely, each set X ⊆M n deﬁned by a formula
_
i∈ω
(∃xi)ϕi(xi, y1, . . . , yn),
where {ϕi | i ∈ω} is a recursively enumerable set of quantiﬁer-free formulas
in the signature σ, is an output set over HL(M).
For other results on BSS-computability (and similar machine-style ap-
proaches), see [5–7] and [15].
6.8.2. Search computability
We recall some of the central notions of the theory introduced in [105, 106],
together with the relationships with Σ-deﬁnability established in [45].
Let M be a structure of a ﬁnite signature, and let HL(M) denote the
hereditarily listed superstructure over M.
The central notion is that of
a partial multi-valued function (p.m.f) from HL(M)k to the set of subsets
HL(M), where k < ω. We use the following notations (here u ∈HL(M)k):
• f(u) →z, if z ∈f(u) (we say that f(u) produces z);
• f(u) ↓, if f(u) ̸= ∅(we say that f(u) is deﬁned);
• f ⊆g, if ∀u(f(u) ⊆g(u));
• f = g, if (f ⊆g) ∧(g ⊆f);
• f(u) = z, if f(u) = {z}.

224
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
Substitution (superposition) of p.m.f. is deﬁned in the natural way:
f(x, g(x, y), y) →z ⇔∃u[(g(x, y) →u) ∧(f(x, u, y) →z)].
Simultaneous substitution is interpreted as a successful substitution.
In
particular,
[f(g(x), g(x)) →z] ⇔∃u∃v[(g(x) →u) ∧(g(x) →v) ∧(f(u, v) →z)],
so that (in eﬀect) a multi-valued term that occurs more than once in a
formula may have diﬀerent denotations for each of its occurrences.
A ν-operator is a nondetermined analogue of the minimization operator,
and is deﬁned as follows:
νy[g(y, x) →0] →z ⇔(g(z, x) →0).
Now, we consider the construction schemes for multi-valued functions.
Let ϕ = ϕ1, . . . , ϕl be a ﬁnite (possibly empty) list of p.m.f. on HL(M), ϕi
is ni-ary, 1 ⩽i ⩽l. In the schemes C0–C10, x ∈HL(M)n, y ∈HL(M)m
n, m ∈ω (possibly n = 0 or m = 0). We explain shortly the expressions in
the right parts.
C0. f(t1, . . . , tni, x) = ϕi(t1, . . . , tni),
⟨0, ni + n, i⟩
C1. f(x) = y
⟨1, n, y⟩
C2. f(y, x) = y
⟨2, n + 1⟩
C3. f(s, t, x) = ⟨s, t⟩
⟨3, n + 2⟩
C40. f(y, x) = l(y)
⟨4, n + 1, 0⟩
C41. f(y, x) = r(y)
⟨4, n + 1, 1⟩
C5. f(x) = g(h(x), x)
⟨5, n, g, h⟩
C6. f(y, x) = g(y, x), if y ∈M;
⟨6, n + 1, g, h⟩
f(⟨s, t⟩, x) = h(f(s, x), f(t, x), s, t, x)
C7. f(x) = g(xj+1, x1, . . . , xj, xj+2, . . . , xn)
⟨7, n, j, h⟩
C8. f(e, x, y) = {e}(x)
⟨8, n + m + 1, n⟩
C9. f(x) = νy[g(y, x) →0]
⟨9, n, g⟩.
All schemes, besides C8, were deﬁned previously. Schemes C0–C4 deﬁne
basic operations; C5, C7 corresponds to the superposition; C6 corresponds
to the primitive recursion; and C9 to the minimization. Scheme C8 corre-
sponds to the universal machine, with the expressions in the left playing
the role of function indices. More exactly,
C0′. If ϕi(t1, . . . , tni) →z, then {⟨0, ni + n, i⟩}(t1, . . . , tni, x) →z.
C1′. {⟨1, n, y⟩}(x) →y.
C2′. {⟨2, n + 1⟩}(y, x) →y.
C3′. {⟨3, n + 2⟩}(s, t, x) →⟨s, t⟩.

HF-Computability
225
C40
′. {⟨4, n + 1, 0⟩}(y, x) →l(y).
C41
′. {⟨4, n + 1, 1⟩}(y, x) →r(y).
C5′. If there exists a u such that {g}(x) →u and f(u, x) →z, then
{⟨5, n, g, h⟩}(x) →z.
C6′. If y ∈M and g(y, x) →z, then {⟨6, n + 1, g, h⟩}(y, x) →z;
if there exist u, v such that {⟨6, n + 1, g, h⟩}(s, x) →u, {⟨6, n +
1, g, h⟩}(t, x) →v and {h}(u, v, s, t, x) →z, then
{⟨6, n + 1, g, h⟩}(⟨s, t⟩, x) →z.
C7′. If {g}(xj+1, x1, . . . , xj, xj+2, . . . , xn) →z, then {⟨7, n, j, h⟩}(x) →z.
C8′. If {e}(x) →z, then {⟨8, n + m + 1, n⟩}(e, x, y) →z.
C9′. If {g}(y, x) →0, then {⟨9, n, g⟩}(x) →y.
A p.m.f. f is called search computable relative to ϕ, if it is constructed
with C0–C9, where C0 may contain functions from ϕ. A predicate R(u)
on HL(M) is called search computable relative to ϕ, if its characteristic
function is search computable relative to ϕ. A predicate R(u) on HL(M)
is called semi-search computable relative to ϕ, if there exists a search com-
putable (relative to ϕ) predicate R0(y, u) such that R(u) ⇔∃yR0(y, u).
If a structure M is deﬁned on the set M then (if not stated overwise), the
list ϕ consists exactly of characteristic functions of the signature predicates
of M.
Theorem 6.48. [45] Let M be a structure of a ﬁnite predicate signature,
and R be a relation on HL(M).
(1) R is semi-search computable on HL(M) if and only if R is a Σ-predicate
on HL(M);
(2) R is search computable on HL(M) if and only if R is a ∆-predicate on
HL(M).
In conclusion, we present an approach to relative computability of ab-
stract countable structures, introduced by I.N.Soskov in the framework of
search computability. Let us consider algebraic structures of the form
A=⟨U, N, =U, ̸=U, R1, . . . , Rn⟩,
where U is an inﬁnite countable set, N is the set of the natural numbers,
and Ri ⊆U ai ×Nbi, ai, bi ∈N, 1 ⩽i ⩽n, ai+bi ⩾1, are partial predicates,
which take only value true, whenever deﬁned.
We use the so called Moschovakis enrichment. Let U0 = U ∪{o}, where
o ̸∈U and let ⟨·, ·⟩be an injective binary function deﬁned on U0 with values
outside of U0. Let U ∗be the closure of U0 with respect to ⟨·, ·⟩.

226
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
Let R∗
i (s, z) be true if and only if Ri(s, z) is true, for any 1 ⩽i ⩽n and
(s, z) ∈U ai × Nbi. Also deﬁne partial predicates U, O and Π on the set
U ∗in the following way: U(s) is true if and only if s ∈U for each s ∈U ∗;
O(s) is true if and only if s=o for each s ∈U ∗; and Π(s, t, r) is true if and
only if s = ⟨t, r⟩for every s, t, r ∈U ∗.
By U, O and Π denote the complement predicates of U, O and Π, for
example U(s) is true if and only if U(s) is false for each s ∈U ∗. Moschovakis
enrichment of A (∗-structure of A) is
A∗=⟨U ∗, N, =U∗, ̸=U∗, U, U, O, O, Π, Π, R∗
1, . . . , R∗
n⟩.
We write (A∗, R) to denote the structure that is obtained by adding R to
A.
The predicate R ⊆U k×Nm is called SC-deﬁnable in A (write R ⩽SC A)
if and only if there exists a primitive recursive (m + 1)-ary function γ and
t1, . . . , tq ∈U such that for all (s, x) ∈U k × Nm the following equivalence
holds:
R(s, x) is true ⇐⇒∃n ∈N(ν(γ(n, x))(t, s) is true),
where ν is some G¨odel numeration of positive ∃-formulas.
Deﬁnition 6.36. For structures A = ⟨U, N, =U, ̸=U, RA
1 , . . . , RA
n ⟩and
B = ⟨U, N, =U, ̸=U, RB
1 , . . . , RB
n ⟩, A is said to be SC-reducible to B
(A ⩽SC B), if RA
i ⩽SC B for each 1 ⩽i ⩽n.
The relation ⩽SC is reﬂexive and transitive, and induces an equivalence
relation ≡SC in the class of all algebraic structure with the abstract sort U.
The respective equivalence classes are called s-degrees, and they form an
upper semilattice. For the results in this ﬁeld we refer the reader to [10, 140].
6.8.3. Montague computability
The results from this section describe one of the very ﬁrst generalizations
of computability theory over the natural numbers to the case of com-
putability over arbitrary structures.
It was presented by R. Montague
in [90] as an attempt to look at the computability theory as a part of
the model theory, considering computability as deﬁnability in higher or-
der logics. The connections with the search computability introduced by
Y.N. Moschovakis [104, 105], another one of the ﬁrst generalizations of
computability theory, are due to C. Gordon [45].

HF-Computability
227
Let A be a structure of a ﬁnite predicate signature ⟨R1, . . . , Rk⟩, where
each Ri is ni-ary, and let κ be a cardinal. Deﬁne
S0, κ =A,
Sn+1, κ = {x ⊂Sn, κ | card(x) < κ}.
Consider a language with relation symbols for the relations of A and
the membership symbol ∈and variables of type n to range over Sn, k.
Deﬁnition 6.37. S = S
n∈ω Sn, where Sn is deﬁned inductively:
S0 = A,
Sn+1 = {x | x is a ﬁnite subset of Sn}.
The elements of Sn are called objects of type n.
Deﬁnition 6.38. A system At = ⟨S, ∈, R1, . . . , Rk, R∗
1, . . . , R∗
k⟩is called a
t-extension of the system A, where R∗
i is the complement of Ri relative to
Ani.
Deﬁnition 6.39. The language Σt (for the structure At) has the following
symbols:
(a) For each n ∈ω, a countable sequence v0, n, v1, n, . . . , of variables of
type n;
(b) Relation symbols R1, . . . , Rk, R∗
1, . . . , R∗
k;
(c) The symbols ∧, ∨, ∀, ∃, ∈, (, ), and , .
The formulas of Σt are deﬁned inductively by:
(d) For i=1, . . ., k, if x1, . . . xni are type 0 variables then Ri(x1, . . . , xni)
and R∗
i (x1, . . . , xni) are formulas;
(e) If ϕ and ψ are formulas then (ϕ ∧ψ) and (ϕ ∨ψ) are formulas;
(f) If ϕ is a formula, x is a variable of type n and y is a variable of type
n + 1 then (∃x ∈y)ϕ, (∀x ∈y)ϕ and ∃xϕ are formulas.
(Notice that x ∈y is not a formula of Σt).
The interpretation of Σt in At is the obvious one with variables of type n
ranging over objects of type n.
The relations on A which are Σt deﬁnable in At are those which are
considered in [90] as analogs of the recursively enumerable relations.
Theorem 6.49. [45] Any Σt-relation on A is semi-search computable.

228
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
Theorem 6.50. [45] If the equality relation on A and its complement are
Σt-relations in A then any semi-search computable relation on A is a Σt-
relation.
6.9. KPU. Examples of Admissible Structures
Now we give some general information about admissible sets. As it is said
above, it can be used in the HF-computability because any hereditarily
ﬁnite superstructure is an admissible set.
6.9.1. Elements of KPU
Recall the axioms of Kripke-Platek Theory with Urelements (KPU). Let
σ be a signature which contains a binary symbol ∈and a unary symbol
U.
They are interpreted as the membership relation and as the set of
urelements respectively.
Extensionality ∀x∀y((¬U(x) ∧¬U(y)) →(∀z((z ∈x) ↔(z ∈y)) →(x ≈
y)));
Pair ∀x∀y∃z((x ∈z) ∧(y ∈z));
Union ∀x∃y(¬U(y) ∧∀z∀w(((z ∈x) ∧(w ∈z)) →(w ∈y)));
Urelements ∀x(U(x) →∀y¬(y ∈x));
Empty Set Existence ∃x(¬U(x) ∧∀y¬(y ∈x));
Foundation Scheme ∀z(∃xϕ(x, z)
→
∃x(ϕ(x, z) ∧∀y((y
∈
x)
→
¬ϕ(y, z)))), for any formula ϕ of σ in which y does not occur free.
It follows from Extensionality that a set without elements (i.e., an empty
set) is unique.
To formulate the remaining axioms, we need a deﬁnition of ∆0-formula:
Deﬁnition 6.40. The class of ∆0-formulas of signature σ is the least one
which contains atomic formulas and is closed under the following logical
connectives: →, ∨, ∧, ¬, ∀y ∈t, ∃y ∈t, where t is a term of σ and y
is a variable (as before, ∀y ∈t . . . and ∃y ∈t . . . are abbreviations for
∀y((y ∈t) →. . .) and ∃y((y ∈t) ∧. . .) respectively).
∆0 Separation Scheme ∀z∀x(¬U(x) →∃y(¬U(y)∧∀w((w ∈y) ↔((w ∈
x) ∧ϕ(w, z))))), for every ∆0-formula ϕ of the signature σ in which y
does not occur free;
∆0 Collection Scheme ∀z∀x(¬U(x) →(∀w ∈x∃yϕ(w, y, z) →∃u∀w ∈
x∃y ∈uϕ(w, y, z))), for every ∆0-formula ϕ of the signature σ in which
u does not occur free.

HF-Computability
229
It follows from these axioms that, for any elements x, y, there exist the
pair {x, y}, the ordered pair ⟨x, y⟩⇌{{x}, {x, y}}, the union S x, and the
results of the usual set theoretic operations x ∪y, x ∩y, x \ y.
Structures of the theory KPU are denoted as A, B, C, . . . (possibly
with indices); their domains are denoted as A, B, C, . . . respectively (with
corresponding indices). Given a structure A of KPU, elements from U(A)
are called urelements and elements from A \ U(A) are called sets.
The
axioms of KPU enables us to prove the existence of the Cartesian product
a × b for any sets a and b. A structure with operations and relations can
be given on the set of urelements.
The theory KPU can be considered as a fragment of the theory ZF
with urelements and, therefore, we can deﬁne the notions of a transitive
set as a set containing all its elements as subsets and that of an ordi-
nal as a transitive set consisting of transitive sets only. Notice that for
any set x there exists the transitive closure TC(x), i.e., the least tran-
sitive set under inclusion containing x as a subset.
Moreover, TC(x)
is a Σ-function.
By using foundation [11, 33] one can prove that ordi-
nals on structures of KPU are linearly ordered by the membership rela-
tion and every non-empty deﬁnable subset of ordinals has the least el-
ement.
A structure A of KPU is called an admissible set [33] if the
set Ord(A) of ordinals of the structure is well ordered under the mem-
bership relation.
Such a deﬁnition is more abstract than the deﬁnition
from [11] because it is closed under all isomorphic images. However, any
admissible set is isomorphic to some admissible set in the sense [11]. An
ordinal α is called admissible if Ord(A) = α, for some admissible set
A.
As it is said above, hereditarily ﬁnite superstructures are admissible
sets. We give now a series of other examples of admissible structures:
(1) Any standard model of ZF with urelements is an admissible set.
(2) Let κ be an inﬁnite cardinal and let M be a structure (possibly, empty)
of some signature τ. Then a structure Hκ(M) of τ ∪{U, ∈} with its
domain {a ∈VM | card(TC(a)) < κ}, where VM is the universe over
M(II.1 [11])), is an admissible set with Ord(Hκ(M)) = κ. Thus, any
inﬁnite cardinal is admissible.
(3) Let M be a structure.
Then there exists the least admissible
set HYP(M) under inclusion containing M as an element.
More-
over, its domain can be found constructively in any such admissi-
ble set, namely, there is a Σ-function L(a, α) that it coincides with

230
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
S
α∈Ord(HYP(M)) L(M, α) [11, 33].
Consider HYP(N) where N is the
standard model of arithmetic. Then Ord(HYP(N)) = ωCK
1
is the ﬁrst
non-constructible ordinal and the collections of ∆- and Σ-subsets are
exactly ∆1
1 and Π1
1 respectively. The properties of this admissible set
are studied in detail in [11].
(4) Given an admissible set A, {a ∈A | TC({a})∩U(A) = ∅} is the domain
of an admissible set which is called the pure part of A.
Generally,
admissible sets without urelements are said to be pure. As a corollary,
an ordinal α0 is admissible if and only if Lα0 = ⟨S
β<α0 L(∅, β), ∈⟩is
admissible. Admissible sets of such kind are called constructible.
Indeed, the pure part of any admissible set whose ordinal is ω coincides
with HF(∅), i.e., the least admissible set under inclusion(II.2.12 [11]).
Notice that if A is an admissible set over M then HF(M) is exactly
the closure of the set M of urelements together with {∅} under values of
set-theoretic terms {·} and ∪.
6.9.2. Σ-subsets
In comparison with classical computability, an eﬀectively presented relation
is the main object of study here, not a function. The main interest in these
relations lies in the method of deﬁning them, as well as in the general
absence of a universal eﬀective function.
The notions of Σ-formulas, Σ- and ∆-subsets, and Σ-functions on struc-
tures of KPU are deﬁned like these for hereditarily ﬁnite superstructures.
We give examples of basic ∆-predicates and Σ-functions used here:
• Ord(x) (x is an ordinal);
• Nat(x) (x is a natural number; we often denote the set of ﬁnite ordinals
in admissible sets as ω);
• TC(x) is the least transitive set containing x as a subset;
• sp(x) ⇌{y ∈TC(x) | U(y)} is the support of x;
• rk(x) = sup{rk(y) + 1 | y ∈x} is the rank of x.
As usual, ⟨x, y⟩⇌{{x}, {x, y}}, ⟨x⟩⇌x, ⟨x1, x2, . . . , xn−1, xn⟩⇌
⟨⟨x1, x2, . . . , xn−1⟩, xn⟩. As in the classical case, it suﬃces to consider sub-
sets of admissible sets only because the ordered pair operation is deﬁnable
by some ∆0-formula. Moreover, this formula is independent of choice of a
structure of KPU. We give now several equivalent deﬁnitions of Σ-subsets
in any structure of KPU.

HF-Computability
231
Proposition 6.36. Let A be a structure of KPU and let B ⊆A. Then the
following conditions are equivalent:
(i) B is a Σ-subset of A;
(ii) B is a Σ1-subset of A;
(iii) B = δF for some partial Σ-function F;
(iv) B = ρF for some partial Σ-function F;
(v) B = ∅or B = ρF for some total Σ-function F.
Proof.
(i) →(ii) follows from the Reﬂection Principle [11]. (ii) →(v)
Let B be a nonempty Σ1-subset and let ∃yϕ0(x, y) deﬁne B, where ϕ0 is a
∆0-formula. Take b0 ∈B and deﬁne a Σ-formula ψ(x, y) as follows:
(∃u∃v((x = ⟨u, v⟩) ∧((ϕ0(u, v) ∧(y = u)) ∨(¬ϕ0(u, v) ∧(y = b0))))∨
(¬(x is an ordered pair) ∧(y = b0))).
It is easy to check that a Σ-formula ψ(x, y) deﬁnes the graph of some total
function f with B = ρf. (v) →(iv) If B = ∅then a Σ-formula ¬(x = x)
deﬁnes the graph of nowhere converged function, in particular, the range
of it is empty. If B ̸= ∅, then it is evident that (iv) is true. (iv) →(i),
(iii) →(i) Let a Σ-formula φ(x, y) deﬁne the graph of F. Then ∃xφ(x, y)
and ∃yφ(x, y) deﬁne B in (iv) and (iii) respectively. (i) →(iii) Suppose
that B is deﬁnable by Σ-formula θ(x). Then (θ(x) ∧(x = y)) deﬁnes the
graph of some function f whose domain coincides with B.
□
An inﬁnite Σ-subset B of A needs not have total Σ-functions “enumer-
ating” it without repetitions, i.e., one-to-one correspondences from A onto
B. Several examples are given.
Examples 6.9.1.
(1) Any admissible set has always a countable ∆-subset ω ⊆Ord(A).
(2) If an admissible set A satisﬁes ω < Ord(A) then ω cannot be enu-
merated without repetitions via a total Σ-function, otherwise A ∈A,
by Σ-Replacement (I.4.6 [11]). Moreover, if a ∈A then a cannot be
enumerated without repetitions via a total Σ-function.
(3) There exists a hereditarily ﬁnite superstructure over a countable struc-
ture of some ﬁnite signature which has an inﬁnite Σ-subset B ⊆ω
such that any coinﬁnite Σ-subset of B is ﬁnite (theorem 2.1 [101]).
In particular, B cannot be enumerated without repetitions via a total
Σ-function or even a partial Σ-function with domain ω.

232
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
6.9.3. Gandy’s Theorem
An approximation by some strongly computable sequence of ﬁnite sets is
one of the universal methods of deﬁning computably enumerable sets in
classical computability. In general, this method cannot be applied in ad-
missible sets because Σ-subsets cannot be constructed by ordinal steps in
some admissible sets. However, nondeterministic analogues can be used
here if elements of a certain kind play the role of steps.
Deﬁnition 6.41. Let M, N be structures of some signature σ ⊇{∈}.
A structure N is called an end extension of M (we write M ⩽end N) if
{b | b ∈M a} = {b | b ∈N a} for each a ∈M.
If A is a structure of KPU in some relation signature and a ∈A is tran-
sitive then A ↾a ⩽end A. Any embedding of one structure into another
is extendible to some end extension, that is, given two structures M and
N such that M ⩽N, there is an embedding ı : HF(M) ֒→AN such that
ı(HF(M)) ⩽end AN, for every admissible set AN over N.
Since Σ-formulas are preserved under end extensions (I.8.4 [11]) we have:
Proposition 6.37.
(1) Let A be a structure of KPU in some relation signature, Φ(x) be a Σ-
formula in the signature with a parameter a0 ∈A, and b ∈A. Then
A |= Φ(b) if and only if A ↾c |= Φ(b) for some transitive set c ∈A,
{a0, b} ⊆c.
(2) Let HF(M) be a hereditarily ﬁnite superstructure in some relation
signature, Φ(x) be a Σ-formula in the signature with parameters
m0, . . . , mk−1 from M, and b ∈HF(M).
Then HF(M) |= Φ(b) if
and only if HF(M0) |= Φ(b) for some ﬁnite substructure M0 ⩽M,
{m0, . . . , mk−1} ∪sp(b) ⊆M0.
An important circumstance is that both the approximations are deﬁned by
some Σ-formulas which can be eﬀectively found from Φ. It is convenient to
use variations of proposed approaches in practice.
Now we describe Gandy’s method of construction of a Σ-predicate as
the least ﬁxed point of some Σ-operator. In section 6.3, this method was
deﬁned on hereditarily ﬁnite superstructures.
Let A be a structure of KPU. We deﬁne two topologies on P(A).
• The strong topology τs is deﬁned by an open basis consisting of sets of
kind Va ⇌{M | M ⊆A, a ⊆M}, a ∈A \ U(A).

HF-Computability
233
• The weak topology τw is deﬁned by an open pre-basis consisting of sets
of kind V{a}, a ∈A. In other words, sets of kind Va, where a ∈A\U(A)
is a ﬁnite set, form an open basis of this topology.
Note that these topologies coincide on hereditarily ﬁnite superstructures. A
continuous map F : ⟨P(A), τs⟩→⟨P(A), τw⟩is called a weakly continuous
operator. Every weakly continuous operator F is monotonic, i.e., M ⊆N ⊆
A ⇒F(M) ⊆F(N) and, therefore, it has the least ﬁxed point which can
be found in the following way: Γ0 ⇌∅; Γα+1 ⇌F(Γα); Γη ⇌S
β<η Γβ,
if η is limit; then, as it is easily checked, Γ∗⇌S
α<card(A)+ Γα is the least
ﬁxed point of F.
A weakly continuous operator F is called a Σ-operator if Γ∗
F ⇌{⟨a, b⟩|
a ∈A \ U(A), b ∈F(a)} is Σ on A.
Theorem 6.51. [Gandy] Let A be an admissible set and F be a Σ-operator
on A. Then the least ﬁxed point Γ∗of the operator F is a Σ-subset of A.
Moreover, Γ∗= ΓOrd(A).
We illustrate some applications of this theorem.
Let Ψ(x, P +) be a Σ-formula and FΨ(M) = {b | ⟨A, M⟩|= Ψ(b)},
for every subset M of an admissible set A. Then FΨ is a Σ-operator on A.
Thus, the Gandy Theorem can be viewed as a generalization of Σ-Recursion
Principles.
Proposition 6.38. Let A be an admissible structure over M.
Then
HF(M) is a Σ-subset of A.
Proof.
Let Ψ(x, P +) be
U(x) ∨∃y∃z(P(y) ∧P(z) ∧((x = {y}) ∨(x = y ∪z))).
□
Indeed, Σ- cannot be replaced by ∆- in 6.38(V.2.6 [11]). However, the
following holds:
Proposition 6.39. Let A be an admissible set. Then HF(∅) will be a
∆-subset of A, HF(∅) ⩽end A and hence every Σ-(∆-)predicate on HF(∅)
is Σ(∆) on A.
Proposition 6.40. Let A be an admissible set and let M be a ∆-(Σ-)subset
of A. Then {⟨n, a⟩| a ∈M n, n < ω} will be ∆(Σ) on A.
Proof.
Let Ψ0(x, y, P +) be
((y = 1) ∧(x ∈M)) ∨∃u∃v[(x = ⟨u, v⟩) ∧(v ∈M) ∧∃z(Nat(z) ∧(y =
z + 1) ∧(z > 0) ∧P(u, z))]

234
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
and let Ψ1(x, y, Q+) be
¬Nat(y)∨(y = 0)∨((y = 1)∧(x ̸∈M))∨∃z(Nat(z)∧(y = z +1)∧(z >
0) ∧∀u ∈TC(x)∀v ∈TC(x)(¬(x = ⟨u, v⟩) ∨Q(u, z) ∨(v ̸∈M))).
□
Corollary 6.11. Let A be an admissible set and let M be a ∆-(Σ-)subset
of A. Then M <ω ⇌S
n<ω M n is also a ∆-(Σ-)subset of A.
Gandy’s Theorem implies the existence of a universal Σ-predicate on any
admissible set. Let A be an admissible set and K a class of n-ary relations
on A. A predicate P ⊆An+1 is universal for K if K = {{⟨b1, . . . , bn⟩|
⟨a, b1, . . . , bn⟩∈P} | a ∈A}. In particular, P is a universal Σ-predicate
if it is universal for the class of all n-ary Σ-predicates on A; a partial Σ-
function f(y, x1, . . . , xn) is a universal Σ-function if its graph Γf is universal
for the class of graphs of all n-ary partial Σ-functions.
We identify formulas with their G¨odel numbers.
Theorem 6.52. There is a binary Σ-predicate TrΣ on A such that, for
every Σ-formula Φ(x) and a ∈A,
⟨Φ, a⟩∈TrΣ ⇔A |= Φ(a).
Theorem
6.53. There
exists
a
universal
(n + 1)-ary
Σ-predicate
T (e, x1, . . . , xn) on A.
As is mentioned above (see Sections 6.3, 6.5), there are admissible sets
without universal Σ-functions [49, 101, 132, 162].
Acknowledgements
The research was partially supported by the Russian Foundation for Basic
Research (grants 06-01-04002-NNIOa (joint with DFG), 08-01-00442a, and
09-01-12140oﬁm) and by the State Maintenance Program for the Leading
Scientiﬁc Schools of the Russian Federation (grants NSh-3606.2010.1, NSh-
3669.2010.1).
References
[1] Adamson, A. (1978). Admissible sets and the saturation of structures, Ann.
Math. Logic 14, 2, pp. 111–157.
[2] Adamson, A. (1980). Saturated srtuctures, unions of chains and preserva-
tion theorems, Ann. Math. Logic 18, 1/2, pp. 67–96.
[3] Ash, C. and Knight, J. F. (2000). Computable Structures and the Hyper-
arithmetical Hierarhy, North-Holland, Amsterdam–London.

HF-Computability
235
[4] Ash, C., Knight, J. F., Manasse, M., and Slaman, T. (1989) Generic copies
of countable structures, Ann. Pure Appl. Logic 42, pp. 195-205.
[5] Ashaev, I. V. (1995). Computability in ﬁelds (Russian), Current problems
od modern mathematics. Collection of scientiﬁc works, vol. 1, Novosibirck:
NII MIOO NGU, pp. 10–18.
[6] Ashaev, I. V. (1999). Priority method in generalized computability, De
Gruyter Series in Logic and its application 2, Walter de Gruyter, pp. 1–13.
[7] Ashaev, I. V. (2003). On the reduction and uniformization principles in
generalized computability (Russian), Vestn. Omsk. Univ. 3, pp. 12–14.
[8] Ashaev, I. V., Belyaev, V. Ya., and Myasnikov, A. G. (1993). Toward a
Generalized Computability Theory, Algebra and Logic 32, 4, pp. 183–205.
[9] Avdeev, R.(to appear). On admissible sets of kind HYP(M) over recursively
saturated structures.
[10] Baleva, V. (2006). The jump operation for structure degrees, Arch. Math.
Logic 45, pp. 249–265.
[11] Barwise, J. (1975).
Admissible Sets and Structures, Springer, Berlin–
Heidelberg–New York.
[12] Belyaev, V. Ya., and Tajtslin, M. A. (1979). On elementary properties of
existentially closed systems, Russ. Math. Surveys 34, 2, pp. 43–107.
[13] Belyaev, V. Ya., Lyutikova, E. E., and Remeslennikov, V. N. (1995). Cate-
goricity of Finitely Generated Algebraic Systems in HF-Logic, Algebra and
Logic 34, 1, pp. 6–17.
[14] Blum, L., Shub, M., and Smale, S. (1989). On a theory of computation and
complexity over the real numbers: Np-completeness, recursive functions
and universal machines, Bull. Amer. Math. Soc. 21, 1, pp. 1–46.
[15] Calvert, W. (to appear). On three notions of eﬀective computation over R,
Log. J. IGPL.
[16] Chang, C. C. and Keisler, H. J. (1973).
Model Theory, North-Holland,
Amsterdam–London.
[17] Csima, B. F., Harizanov, V. S., Miller, R., and Montalb´an, A. (to appear).
Computability of Fra¨ıss´e limits.
[18] Cooper, S. B. (2003). Computability Theory, Chapman Hall, London–New
York.
[19] Ershov, Yu. L. (1977). Numbering Theory, Nauka, Moscow.
[20] Ershov, Yu. L. (1980). Decidability Problems and Constructivizable Models,
Nauka, Moscow.
[21] Ershov, Yu. L. (1983). The principle of Σ-enumeration, Sov. Math. Dokl.
27, pp. 670–672.
[22] Ershov, Yu. L. (1983). Dynamic Logic over admissible sets, Sov. Math.
Dokl. 28, pp. 739–742.
[23] Ershov, Yu. L. (1985). Σ-predicates of ﬁnite types over an admissible set,
Algebra and Logic 24, pp. 327–351.
[24] Ershov, Yu. L. (1985). Σ-deﬁnability in admissible sets, Sov. Math. Dokl.
32, pp. 767–770.
[25] Ershov, Yu. L. (1986). fA-spaces, Algebra and Logic 25, pp. 336–343.
[26] Ershov, Yu. L. (1986). The language of Σ-expressons (Russian), Vychisl.

236
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
Sist. 114, pp. 3–10.
[27] Ershov, Yu. L. (1986). Σ-admissible sets (Russian), Vychisl. Sist. 114, pp.
35–39.
[28] Ershov, Yu. L. (1987). Generatability of admissible sets, Algebra and Logic
26, 5, pp. 346–361.
[29] Ershov, Yu. L. (1989). Each family of subsets of the urelements generates
an admissible set, Sib. Math. J. 30, 6, pp. 883–885.
[30] Ershov, Yu. L. (1990). Forcing in admissible sets, Algebra and Logic 29, 6,
pp. 424–430.
[31] Ershov, Yu. L. (1993). The L¨owenheim–Skolem–Mal’tsev theorem for de-
ﬁnable models (Russian), Vychisl. Sist. 148, pp. 9–17.
[32] Ershov, Yu. L. (1995). Deﬁnability in hereditarily ﬁnite manifolds, Dokl.
Math. 51, 1, pp. 8–10.
[33] Ershov, Yu. L. (1996). Deﬁnability and Computability, Consultants Bureau,
New York–London–Moscow.
[34] Ershov, Yu. L. (1998). Σ-deﬁnability of algebraic structures, in Handbook
of Recursive Mathematics, Elsevier, vol. 1, pp. 235–260.
[35] Ershov, Yu. L. (1999). Theory of numberings, in Handbook of Computabil-
ity, Stud. in Logic and Foundations of Mathematics, vol. 140, pp.473–511.
[36] Ershov, Yu. L. (2000). Deﬁnability and Computability, Ekonomika, Nauch.
Kniga, Moscow–Novosibirsk.
[37] Ershov,Yu. L. and Goncharov, S. S. (2000). Constructive Models, Consul-
tants Bureau, New York–London–Moscow.
[38] Ershov, Yu. L. and Palutin, E. A. (1987). Mathematical Logic, Mir Pub-
lishers, Moscow.
[39] Ershov, Yu. L., Goncharov, S. S., and Sviridenko, D. I. (1986). Semantic
programming, Inform. Processing 86, pp. 1093–1100.
[40] Friedman, H. (1969). Algorithmic procedures, generalized Turing algo-
rithms, and elementary recursion theory, in R.O. Gandy and C.E.M. Yates,
eds., Logic Colloquium 1969.
[41] Gandy, R. O. (1974). Inductive Deﬁnitions, Generalized Recursion Theory,
pp. 265–300.
[42] Goncharov, S. S. and Sviridenko, D. I. (1985). Σ-programming (Russian),
Vychisl. Sist. 107, pp. 3–29.
[43] Goncharov, S. S. and Sviridenko, D. I. (1987). Σ-programs and their se-
mantics (Russian), Vychisl. Sist. 120, pp. 24–52.
[44] Goncharov, S. S., Harizanov, V. S., Knight, J. F., Morozov, A. S., and
Romina, A. V. (2005). On automorphic tuples of elements in computable
models, Sib. Math. J. 46, 3, pp. 405–412.
[45] Gordon, C. (1970). Comparisons between some generalizations of recursion
theory, Compos. Math. 22, pp. 333–346.
[46] Hodges, W. (1993). Model Theory, Cambridge University Press, Cambridge.
[47] Kalimullin, I. S. (2006). The Dyment reducibility on the algebraic struc-
tures and on the families of subsets of ω, Logical Approaches to Computa-
tional Bariers, CiE2006, Report Series, Swansea, pp. 150–159.
[48] Kalimullin, I. S. (2009). Uniform reducibility of representability problems

HF-Computability
237
for algebraic structures, Sib. Math. J. 50, 2, pp. 265–271.
[49] Kalimullin, I. S. and Puzarenko, V. G. (2005). Computability principles on
admissible sets, Sib. Adv. Math. 15, 4, pp. 1–33.
[50] Kalimullin, I. S. and Puzarenko, V. G. (2009). Reducibility on families,
Algebra and Logic 48, 1, pp. 20–32.
[51] Kfoury, A. J., Stolboushkin, A. P., and Urzyczyn, P. (1989). Some open
questions in the theory of program schemes and dynamic logic, Russ. Math.
Surveys 44, 1, pp. 43–68.
[52] Khisamiev, A. N. (1996). Σ-enumeration and Σ-deﬁnability in HFM (Rus-
sian), Vychisl. Sist. 156, pp. 44–58.
[53] Khisamiev, A. N. (1997). Numberings and deﬁnability in the hereditarily
ﬁnite superstructure of a model, Sib. Adv. Math. 7, 3, pp. 63–74.
[Khisamiev1998] Khisamiev, A. N. (1998). On deﬁnability of a model in a hered-
itarily ﬁnite admissible set (Russian), Vychisl. Sist. 161, pp. 15–20.
[54] Khisamiev, A. N. (1998). Strong ∆1-deﬁnability of a model in an admissible
set, Sib. Math. J. 39, 1, pp. 168–175.
[55] Khisamiev, A. N. (1999). On resolvable and internally enumerable models
(Russian), Vychisl. Sist. 165, pp. 31–35.
[56] Khisamiev, A. N. (2000). The Intrinsic Enumerability of Linear Orders,
Algebra and Logic 39, 6, pp. 423–428.
[57] Khisamiev, A. N. (2001). Quasiresolvable Models and B-Models, Algebra
and Logic 40, 4, pp. 272–280.
[58] Khisamiev, A. N. (2004). Quasiresolvable Models, Algebra and Logic 43, 5,
pp. 346–354.
[59] Khisamiev, A. N. (2004). On the Ershov upper semilattice LE, Sib. Math.
J. 45, 1, pp. 173–187.
[60] Khisamiev, A. N. (2006). On Σ-subsets of naturals over abelian groups,
Sib. Math. J. 47, 3, pp. 574–583.
[61] Khisamiev, A. N. (to appear). Σ-bounded structures and universal Σ-
functions.
[62] Kierstead, H. A. and Remmel, J. B. (1983). Indiscernibles and decidable
models, J. Symbolic Logic 48, 1, pp. 21–32.
[63] Kierstead, H. A. and Remmel, J. B. (1985). Degrees of indiscernibles in
decidable models, Trans. Amer. Math. Soc. 289, 1, pp. 41–57.
[64] Kirpotina, N. A. (1993). Elementary equivalence in the language of list
superstructures, Sib. Adv. Math. 3, 4, pp. 46–52.
[65] Korovina, M. V. (1992). Generalised computability of real functions, Sib.
Adv. Math. 2, 4, pp. 1–18.
[66] Korovina, M. V. (1996). On the universal recursive function and on abstract
machines on real numbers with the list superstructure (Russian), Vychisl.
Sist. 156, pp. 24–43.
[67] Korovina, M. V. (2002). Fixed points on the real numbers without the
equality test, Electron. Notes Theor. Comput. Sci. 66, 1.
[68] Korovina, M. V. (2003). Computational aspects of Sigma-deﬁnability over
the real numbers without the equality test, in CSL, Lect. Notes Comput.
Sci. 2803, pp. 330–344.

238
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
[69] Korovina, M. V. (2003). Gandy’s theorem for abstract structures without
the equality test, in LPAR, Lect. Notes Comput. Sci. 2850, pp. 290–301.
[70] Korovina, M. V. (2003). Recent advances in S-deﬁnability over continu-
ous data types, in Ershov Memorial Conference, Lect. Notes Comput. Sci.
2890, pp. 238–247.
[71] Korovina, M. V. and Kudinov, O. V. (1996). A new approach to com-
putability of real-valued function (Russian), Vychisl. Sist. 156, pp. 3–23.
[72] Korovina, M. V. and Kudinov, O. V. (1998). Characteristic properties of
majorant-computability over the reals, in CSL, Lect. Notes Comput. Sci.
1584, pp. 188–203.
[73] Korovina, M. V. and Kudinov, O. V. (1998). New approach to computabil-
ity, Sib. Adv. Math. 8, 3, pp. 59–73.
[74] Korovina, M. V. and Kudinov, O. V. (1999). A logical approach to spec-
iﬁcation of hybrid systems, in Ershov Memorial Conference, Lect. Notes
Comput. Sci. 1755, pp. 10–16.
[75] Korovina, M. V. and Kudinov, O. V. (2000). Formalisation of computability
of operators and real-valued functionals via domain theory, in CCA, Lect.
Notes Comput. Sci. 2064, pp. 146–168.
[76] Korovina, M. V. and Kudinov, O. V. (2001). Semantic characterisations
of second-order computability over the real numbers, in CSL, Lect. Notes
Comput. Sci. 2142, pp. 160–172.
[77] Korovina, M. V. and Kudinov, O. V. (2001). Generalised computability
and applications to hybrid systems, in Ershov Memorial Conference, Lect.
Notes Comput. Sci. 2244, pp. 494–499.
[78] Korovina, M. V. and Kudinov, O. V. (2005). Towards computability of
higher type continuous data, in CiE2005, Lect. Notes Comput. Sci. 3526,
pp. 235–241.
[79] Korovina, M. V. and Kudinov, O. V. (2008). Eﬀectively enumerable topo-
logical spaces (Russian), Vestn. Novosib. Gos. Univ., Ser. Mat. Mech. In-
form. 8, 2, pp. 74–83.
[80] Korovina, M. V. and Kudinov, O. V. (2008). Basic principles of Σ-
deﬁnability and abstract computability, Bericht Nr. 08-01, Fachbereich
Mathematik, D-57068, Siegen.
[81] Korovina, M. V. and Vorobjov, N. (2004). Pfaﬃan hybrid systems, in CSL,
Lect. Notes Comput. Sci. 3210, pp. 430–441.
[82] Kreisel, G. (1971). Some reasons for generalizing recursion theory, in R.O.
Gandy and C.E.M. Yates eds., Logic Colloquium 69, pp. 139–198, North-
Holland, Amsterdam–London.
[83] Kreisel, G. and Sacks, G. E. (1965). Metarecursive sets, J. Symbolic Logic
30, pp. 318–338.
[84] Kripke, S. (1964). Transﬁnite recursion on admissible ordinals, I,II (ab-
stracts), J. Symbolic Logic 29, pp. 161–162.
[85] Lacombe,D. (1964). Deux g´en´eralizations de la notion de r´ecursivit´e rela-
tive, C. R. Acad. Sci., Paris 258, pp. 3410–3413.
[86] Levy, A. (1965). A hierarchy of formulas in set theory, Mem. Amer. Math.
Soc. 57.

HF-Computability
239
[87] Makkai, M. (1982). Admissible sets and inﬁnitary logic, in Handbook of
Mathematical Logic, ed. J. Barwise, North-Holland, Amsterdam–London,
pp. 233–281.
[88] Miller, R. (2007). Locally computable structures, in CiE2007, Lect. Notes
Comput. Sci. 4497, pp. 575–584.
[89] Miller, R. and Mulcahey, D. (2008). Perfect local computability and com-
putable simulations, in CiE2008, Lect. Notes Comput. Sci. 5028, pp. 388–
397.
[90] Montague, R. (1967). Recursion theory as a branch of model theory, in
Proceedings of the Third International Congress for Logic, Methodology and
Philosophy of Science, North-Holland, Amsterdam–London, pp. 63–86.
[91] Montalb´an, A. (2009). Notes on the jump of a structure, Mathematical
Theory and Computational Practice, pp. 372–378.
[92] Morozov, A. S. (1993). Functional trees and automorphisms of models,
Algebra and Logic 32, 1, pp. 28–38.
[93] Morozov, A. S. (1998). Groups of Σ-permutations of admissible ordinals,
Mathematisches Institut Universitaet Heidelberg, preprint 36, Heidelberg.
[94] Morozov, A. S. (2000). A Σ subset of natural numbers which is not enu-
merable by natural numbers, Sib. Math. J. 41, 6, pp. 1162–1165.
[95] Morozov, A. S. (2002). Presentability of groups of Σ-presentable permu-
taions over admissible sets, Algebra and Logic 41, 4, pp. 254–266.
[96] Morozov, A. S. (2004). On the relation of Σ-reducibility between admissible
sets, Sib. Math. J. 45, 3, pp. 522–535.
[97] Morozov, A. S. (2005). About the admissible predicates on admissible sets,
Sib. Math. J. 46, 4, pp. 668–674.
[98] Morozov, A. S. (2006). Elementary submodels of parametrizable models,
Sib. Math. J. 47, 3, pp. 491–504.
[99] Morozov, A. S. (2008). On the index sets of Σ-subsets of the real numbers,
Sib. Math. J. 49, 6, pp. 1078–1084.
[100] Morozov, A. S. and Korovina, M. V. (2008). Σ-deﬁnability of countable
structures over real numbers, complex numbers and quaternions, Algebra
and Logic 47, 3, pp. 193–209.
[101] Morozov, A. S. and Puzarenko, V. G. (2004). Σ-subsets of natural numbers,
Algebra and Logic 43, 3, pp. 162–178.
[102] Morozov, A. S. and Samokhvalov, K. F. (2002). On possible types of time in
generalized computability theory (Russian), Vychisl. Sist. 170, pp. 45–51.
[103] Moschovakis, Y. N. (1969). Axioms for computation theories – ﬁrst draft,
in R.O. Gandy and C.E.M. Yates, eds., Logic Colloquium 1969.
[104] Moschovakis, Y. N. (1969). Abstract computability and invariant deﬁnabil-
ity, J. Symbolic Log. 34, pp. 605–633.
[105] Moschovakis, Y. N. (1969). Abstract ﬁrst order computability I, Trans.
Amer. Math. Soc. 138, pp. 427–464.
[106] Moschovakis, Y. N. (1969). Abstract ﬁrst order computability II. Trans.
Amer. Math. Soc. 138, pp. 465–504.
[107] Moschovakis, Y. N. (1974). Elementary Induction on Abstract Structures,
North-Holland, Amsterdam–London.

240
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
[108] Myasnikov, A. G. and Remeslennikov, V. N. (1992). Weak second order
logic in group theory, Contemp. Math. 131, part 1, pp. 273–278.
[109] Myasnikov, A. G. and Remeslennikov, V. N. (1992). Admissible Sets in
Group Theory, Algebra and Logic 31, 4, pp. 248–261.
[110] Odifreddi,
P.
(1989).
Classical
Recursion
Theory,
North–Holland,
Amsterdam–London.
[111] Orey, S. (1956). On ω-consistency and related properties, J. Symbolic Log.
21, pp. 246–252.
[112] Platek, R. (1966). Foundations of recursion theory, Doctoral Dissertation
and Supplement, Stanford University, Stanford, CA.
[113] Puzarenko, V. G. (1999). On computability over models of decidable theo-
ries, Algebra and models theory 2, Novosibirsk, NSTU, pp. 94–103.
[114] Puzarenko, V. G. (2000). On computability over models of decidable theo-
ries, Algebra and Logic 39, 2, pp. 98–113.
[115] Puzarenko, V. G. (2002). On model theory in hereditarily ﬁnite superstruc-
tures, Algebra and Logic 41, 2, pp. 111–122.
[116] Puzarenko, V. G. (2002). Decidable computable A-numberings, Algebra and
Logic 41, 5, pp. 314–322.
[117] Puzarenko, V. G. (2003). Generalized numberings and deﬁnability of R in
admissible sets (Russian), Vestn. Novosib. Gos. Univ., Ser. Mat. Mech.
Inform. 2, 3, pp. 107–117.
[118] Puzarenko, V. G. (2004). The L¨owenheim–Skolem–Mal’tsev Theorem for
HF-structures, Algebra and Logic 43, 6, pp. 418–423.
[119] Puzarenko, V. G. (2005). Computability in special models, Sib. Math. J.
46, 1, pp. 148–165.
[120] Puzarenko, V. G. (2006). Deﬁnability of the ﬁeld of reals in admissible
sets, Logical Approaches to Computational Bariers, CiE2006, Report Se-
ries, Swansea, pp. 236–240.
[121] Puzarenko, V. G. (2008). On collection of all computable subsets on ad-
missible sets (Russian, English abstract), Sib. Elektron. Mat. Izv. 5, pp.
1–7.
[122] Puzarenko, V. G. (2009). About a certain reducibility on admissible sets,
Sib. Math. J. 50, 2, pp. 330–340.
[123] Puzarenko, V. G. (2010). Descriptive properties on admissible sets, Algebra
and Logic 49, 2, pp. 160–176.
[124] Puzarenko, V. G. (2010). On a semilattice of numberings, Sib. Adv. in
Math. 20, 2, pp. 128–154.
[125] Puzarenko, V. G. (2010). On a semilattice of numberings, II, Algebra and
Logic 49, 4.
[126] Ressayre, J. P. (1977). Models with compactness properties relative to an
admissible language, Ann. Math. Logic 11, 1, pp. 31–56.
[127] Richter, L. (1981). Degrees of structures, J. Symbolic Log. 46, pp. 723–731.
[128] Rogers, H. (1972). Theory of recursive functions and eﬀective computability,
McGraw-Hill Book Company, New York.
[129] Romina, A. V. (1998). Hyperarithmetical stability of Boolean algebras
(Russian), Vychisl. Sist. 161, pp. 21–27.

HF-Computability
241
[130] Romina, A. V. (2000). Autostability of hyperarithmetical models, Algebra
and Logic 39, 2, pp. 114–118.
[131] Romina,
A.
V.
(2000).
Deﬁnability
of
Boolean
algebras
in
HF-
superstructures, Algebra and Logic 39, 6, pp. 407–411.
[132] Rudnev, V. A. (1986). A universal recursive function on admissible sets,
Algebra and Logic 25, 4, pp. 267–273.
[133] Rudnev, V. A. (1988). Existence of an inseparable pair in the recursive
theory of admissible sets, Algebra and Logic 27, 1, pp. 33–39.
[134] Sacks, G. E. (1990). Higher Recursion Theory, Springer, Berlin–Heidelberg–
New York.
[135] Sazonov, V. Yu. and Sviridenko, D. I. (1986). Denotational semantics of
the language of Σ-expressions (Russian), Vychisl. Sist. 114, pp. 16–34.
[136] Schmerl, J. H. (1980). Decidability and ℵ0-categoricity of theories of par-
tially ordered sets, J. Symbolic Log. 45, pp. 585–611.
[137] Slaman, T. A. (1998). Relative to any non-recursive set, Proc. Amer. Math.
Soc. 126, pp. 2117–2122.
[138] Soskov, I. N. (2004). Degree spectra and co-spectra of structures, Ann.
Univ. Soﬁa 96, pp. 45–68.
[139] Soskova, A. A. (2007). A jump inversion theorem for the degree spectra, in
CiE2007, Lect. Notes Comput. Sci. 4497, pp. 716–726.
[140] Soskova, A. A. and Soskov, I. N. (2009). A jump inversion theorem for the
degree spectra, J. Logic Comput. 19, 1, pp. 199–215.
[141] Stukachev, A. I. (1996). Uniformization Theorem for HF(R) (Russian), Pro-
ceedings of the XXXIV International Scientiﬁc Student Conference ‘Student
i Nauchno-Tehnicheskij Progress: Matematica’, Novosibirsk, p. 83.
[142] Stukachev, A. I. (1997). Uniformization property in hereditary ﬁnite super-
structures, Sib. Adv. Math. 7, 1, pp. 123–132.
[143] Stukachev, A. I. (1998). Uniformization property in hereditary ﬁnite super-
structures (Russian), Vychisl. Sist. 161, pp. 3–14.
[144] Stukachev, A. I. (2002). Σ-admissible families over linear orders, Algebra
and Logic 41, 2, pp. 127–139.
[145] Stukachev, A. I. (2004). Σ-deﬁnability in hereditary ﬁnite superstructures
and pairs of models, Algebra and Logic 43, 4, pp. 258–270.
[146] Stukachev, A. I. (2005). On inner constructivizability of admissible sets
(Russian), Vestn. Novosib. Gos. Univ., Ser. Mat. Mech. Inform. 5, 1, pp.
69–76.
[147] Stukachev, A. I. (2005). Presentations of structures in admissible sets, in
CiE2005, Lect. Notes Comput. Sci. 3526, pp. 470–478.
[148] Stukachev, A. I. (2006). On mass problems of presentability, in TAMC2006,
Lect. Notes Comput. Sci. 3959, pp. 774–784.
[149] Stukachev, A. I. (2006). On inner constructivizability of admissible sets,
Logical Approaches to Computational Bariers, CiE2006, Report Series,
Swansea, pp. 261–267.
[150] Stukachev, A. I. (2007). Degrees of presentability of structures, I, Algebra
and Logic 46, 6, pp. 419–432.
[151] Stukachev, A. I. (2008). Degrees of presentability of structures, II, Algebra

242
Y. L. Ershov, V. G. Puzarenko, & A. I. Stukachev
and Logic 47, 1, pp. 65–74.
[152] Stukachev, A. I. (2009). A Jump Inversion Theorem for the semilattices of
Σ-degrees (Russian), Sib. Elektron. Mat. Izv. 6, pp. 182–190.
[153] Stukachev, A. I. (2010). A Jump Inversion Theorem for the semilattices of
Σ-degrees, Sib. Adv. Math. 20, 1, pp. 68–74.
[154] Stukachev, A. I. (2010). Σ-deﬁnability of uncountable structures of c-simple
theories, Sib. Math. J. 51, 3, pp. 515–524.
[155] Stukachev, A. I. (to appear). Σ-deﬁnability of uncountable structures of
c-simple theories, II.
[156] Stukachev, A. I. (to appear). Semilattices of Σ-degrees of structures.
[157] Stukachev, A. I. (to appear). Eﬀective model theory via the Σ-deﬁnability
approach.
[158] Tajtslin, M. A. (1979). Descriptions of algebraic systems in weak ω-logic
and program logic, Theory of nonregular curves in various geometric spaces,
Alma-Ata, pp. 91–98.
[159] Troﬁmov, M. Yu. (1975). Deﬁnability in algebraically closed systems, Al-
gebra and Logic 14, 3, pp. 198–202.
[160] Vajtsenavichyus, R. Yu. (1987). Recursive enumerations of recursive func-
tionals on recursively listed (RL) admissible sets (Russian, English ab-
stract), Mat. Logika Primen. 5, pp. 123–132.
[161] Vajtsenavichyus, R. Yu. (1989). On admissible sets with inner resolutions
(Russian, English abstract), Mat. Logika Primen. 6, pp. 9–20.
[162] Vajtsenavichyus, R. Yu. (1989). On necessary conditions for the existence
of a universal function on an admissible set (Russian, English abstract),
Mat. Logika Primen. 6, pp. 21–37.
[163] Vajtsenavichyus, R. Yu. (1990). Principal numerations of functionals on
admissible sets, Algebra and Logic 29, 4, pp. 262–279.
[164] Wehner, S. (1998). Enumerations, countable structures and Turing degrees,
Proc. Amer. Math. Soc. 126, pp. 2131–2139.

Chapter 7
The Mathematics of Computing between Logic and
Physics
Giuseppe Longo and Thierry Paul ∗
D´epartement d’Informatique UMR 8548 et CNRS
´Ecole Normale Sup´erieure
F 75730 Paris, France
Email: longo@di.ens.fr
D´epartement de Math´ematiques et Applications UMR 8553 et CNRS
´Ecole Normale Sup´erieure
Paris Cedex 05, France
Email: paul@dma.ens.fr
Do physical processes compute? And what is a computation? These
questions have gained a revival of interest in recent years due to new
technologies in physics, new ideas in computer sciences (for example
quantum computing, networks, non-deterministic algorithms), and new
concepts in logic. In this chapter we examine a few directions, as well
as the problems they bring to the surface.
Contents
7.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
7.2
Computability and Continuity
. . . . . . . . . . . . . . . . . . . . . . . . . . 245
7.3
Mathematical Computability and the Reality of Physics . . . . . . . . . . . . 249
7.4
From the Principle of Least Action to the Quantum Theory of Fields . . . . . 251
7.5
Chaotic Determinism and Predictability . . . . . . . . . . . . . . . . . . . . . 252
7.6
Return to Computability in Mathematics
. . . . . . . . . . . . . . . . . . . . 258
7.7
Non-determinism?
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
7.8
The Case of Quantum Mechanics . . . . . . . . . . . . . . . . . . . . . . . . . 264
7.9
Randomness, Between Unpredictability and Chaos . . . . . . . . . . . . . . . 267
7.10 General Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
∗This is a largely expanded version of a previous paper in French appeared in the pro-
ceedings of the LIGC colloquium, Cerisy, September 2006 (Joinet et al., eds), Hermann,
2009 (see http://www-philo.univ-paris1.fr/Joinet/ligc.html).
243

244
G. Longo & T. Paul
7.1. Introduction
Digital machines, by their extraordinary logical and computational capa-
bility, are changing the world. They are changing it with their power and
their originality, but also with the image of the world they reﬂect: they
help perform thousands of tasks and enable radically new ones, they are
an indispensable tool for scientiﬁc research, but they also project their own
mathematical structure upon the processes they are involved in.
The aim of this paper is to present several situations (in a non-
exhaustive and rather kaleidoscopic way) where a precise confrontation of
digital capacities with real settings in natural sciences is possible, and, in
particular, to show how, in these situations, the computer science’s concept
of computability has to be carefully handled and sometimes not pertinent.
Digital machines are not neutral, as they have a complex history, based
on several turning points in terms of the thinking which enabled their inven-
tion. They synthesize a vision and a science which is very profound. They
are “alphabetic” in the speciﬁc sense of the encoding of human language,
produced by a bagpipe over strings, by means of discrete and meaningless
letter-units, an incredible invention which dates back 5,000 years. They
are Cartesian in their software/hardware duality and in their reduction of
thought to the elementary and simple steps of arithmetic calculus. They
are logical by stemming from a logico-arithmetical framework, in the tradi-
tion of Frege and Hilbert, during the 1930s (“proofs are programs”). And
this by the ﬁnal remarkable invention, by G¨odel: the number-theoretic en-
coding of any alphabetic writing. For all of these reasons, they contribute
to a reading of nature based on the computable discrete, from the alphabet
to arithmetic, on a space–time framed within discrete topology, of which
the access and the measurement are exact, just like in digital databases.
We will see why confounding physics, despite its great “mathematicity”,
with computations and calculus, in any form whatsoever, seems a mistake
to us.
First, the idea that physics “reduces to solving” equations is an
erroneous idea. To be assured of this, one needs only to consider that a
great part of physics concerns variational problems in which the search of a
geodesic diﬀers greatly from the search for the solution to an equation. And
this, without mentioning the singular quantum situation, to be discussed
below, nor the life sciences, which are not very mathematized and for which
the notions of invariant and of the transformation which preserves it, central
to mathematics, are far from being “stabilized”.

The Mathematics of Computing between Logic and Physics
245
The new importance of digital machines, in particular in the natural
sciences, requires a thorough analysis of the relationship between computa-
tions and natural processes. We will focus here on the relationships between
computations and, among the physical processes, those which we consider
as “natural”, that is, those that occur somehow “independently” of hu-
man intervention (because a machine also produces, or even is, a physical
process, but it is a result of a human construction which is extremely orig-
inal and theoretically rich). We will then ask the question: Do physical
processes compute?
The paper is organized as follows: Section 2 is devoted to a topologi-
cal discussion of the link between computability and continuity. It leads
to Section 3 where mathematics, especially computational mathematics,
is confronted to physics endowed with its peculiar “reality” property. We
show in particular how physics deals with a lot of concepts which escape
from any sense of “calculus”. Section 4 gives an epistemological example of
a mathematical object which, with the evolution of physics, lost its compu-
tational ﬂavour after entering the game of modern physics. Sections 5, 6,
7, and 8 are somewhat the core of the paper. We ﬁrst discuss the concept
of predictability in the mirror of chaoticity in dynamical systems. Then we
come back to topological remarks and consider the problem of determin-
ism, a fashionable subject in computer sciences nowadays. We then look at
the case of quantum mechanics, also a subject which entered strongly into
computer sciences lately. Section 9 discusses the position of randomness
inside dynamical systems, and we end up with some ﬁnal remarks.
Let us mention once again that the scope of this paper is by no means
to present a general theory of non-adequacy of computer sciences in natural
philosophy, but rather to present warnings concerning a general temptation
of overusing computational ideas in physics and mathematics, given the
major role of computing in today’s science.
7.2. Computability and Continuity
The naive, and unfortunately highly widespread response to the question
above is that yes, everything can be seen in terms of alphanumeric in-
formation and its computational elaboration. This thesis, under diﬀerent
forms, is often called the “Physical Church Thesis”. So let’s return brieﬂy
to Church’s thesis in its original form, which is purely logico-mathematical
and in no way physical.

246
G. Longo & T. Paul
Church’s thesis, introduced in the 1930s after the functional equiva-
lence proofs of various formal systems for computability (and concerning
only computability over integers), is an extremely robust thesis: it ensures
that any ﬁnitistic formal system over integers (a Hilbertian-type logico-
formal system) computes at best the recursive functions, as deﬁned by
G¨odel, Kleene, Church, Turing.... This thesis, therefore, emerged within
the context of mathematical logic, as grounded on formal systems for arith-
metic/discrete computations: the lambda-calculus (Church, 1932), a sys-
tem for the functional encoding of logical deductions, and Turing’s Logical
Computing Machinea, were the motors of various equivalence proofsb.
The very ﬁrst question to ask is the following: If we broaden the formal
framework, what happens? For example, if we consider as basic support
for computation a set “greater” than the natural integers, is this invari-
ance of formalisms preserved? Of course, if we want to refer to continuous
(diﬀerentiable) physics-mathematics, an extension to consider may be the
following: What about the computational processing of these computable
“limit” numbers which are the computable real numbers? Are the vari-
ous formalisms for computability over real numbers equivalent, when they
are maximal? An aﬃrmative response could suggest a sort of Church the-
sis “extended” to this sort of computational “continuity”. Of course, the
computable reals are countably many, but they are dense in the “natural”
topology over Cantor’s reals, a crucial diﬀerence as we shall see.
With this question, we then begin to near physics, all the while re-
maining in a purely mathematical framework, because mathematics on the
continuum of real numbers constitutes a very broad ﬁeld of application to
physics, since Newton and Leibniz. In particular, it is within spatial and
often also temporal continuity that we represent dynamical systems, that
a1936: “A man provided with paper, pencil and rubber, and subject to a strict discipline,
is in eﬀect a Universal (Turing) Machine”, [31]. In fact, the reader/writer needs only to
know how to read/write 0 and 1 on an endless length of tape, then to move one notch to
the right or to the left, according to given instructions (write, erase, move right, move
left) to compute any formally computable function (see the next note).
bThe other deﬁnitions of computability are more “mathematical”:
they propose, in
diﬀerent ways, arithmetic function classes which contain the constant function 0, the
identity and the successor functions +1, and which are closed by composition, by
primitive recursion (in short: f(x + 1) = h(f(x), x)) and by minimalization (that is,
f(x) = miny[g(x, y) = 0]). It is a mathematically non obvious remark that by read-
ing/writing/moving 0s and 1s left and right on a tape it is possible to calculate all of
these functions: there lies the genius of Turing and the origin of the 0 and 1 machine
which will change the world.

The Mathematics of Computing between Logic and Physics
247
is, most mathematical models (in logical terms: mathematical formalisms)
for classical physics. This does not imply that the world is continuous, but
only that we have said many things thanks to continuous tools as very well
speciﬁed by Cantor (but his continuum is not the only possible one: Law-
vere and Bell, [6], say, proposed another without points, but one which is
unfortunately not richer for the moment in mathematical terms – although
some may hope to use it to better address the geometry of quantum physics;
so, let’s rest on Cantor for the time being).
Now, from this equivalence of formalisms, at the heart of Church’s the-
sis, there remains nothing regarding computability over real numbers: the
models proposed, in their original structure, are demonstrably diﬀerent, in
terms of computational expressiveness (the classes of deﬁned functions).
Today, it is possible to roughly group diﬀerent formal systems into four
main groups (however not exhaustive ones), in order to perform computa-
tions over real numbers:
- recursive analysis, which develops the approach to Turing’s computable
real numbers, or even the Turing Machine itself, by an inﬁnite extension
recently formalized by Weihrauch (two tapes, one which can encode a com-
putable real hence inﬁnite number, and the other which encodes the pro-
gram, see [35]; from the mathematical standpoint, the idea was ﬁrst devel-
oped by Lacombe and Grezgorzcyk, in 1955–57);
- the Blum, Shub, and Smale BSS model (an inﬁnite tape and a little
control system, see [7]);
- the Moore-type recursive real functions (deﬁned in a more mathemat-
ical manner: a few basic functions, and closure by composition, projection,
integration, and search for the zero, see [24]);
- diﬀerent forms of “analog” systems, among which threshold neurons,
the GPAC (General Purpose Analog Computer, attributable to Shannon,
[30], of which a ﬁrst idea preceded classical recursivity: V. Bush, M.I.T.,
1931, [10]).
Each of these systems has its own interest. Besides, they conﬁrm the
solidity of Church’s original thesis, since the restriction to integers of all
known models of computability over continua again produces classical re-
cursivity (or no more than that). What else could we say, concerning inclu-
sions, links, demonstrable passages, as for these formalisms for computabil-
ity on continua?
Of course, it is a matter of “relative” continuity: computable real num-
bers do not form a Cantor-type continuum, as we said; they are a denumer-
able set of measure 0. However, their “natural” (interval) topology is not

248
G. Longo & T. Paul
the discrete topology (and mathematicians know what “natural” means:
the discrete topology over Cantor reals is not natural; one does nothing
with it). This is the crucial mathematical diﬀerence of computations on
reals from computability over the isolated points of the countable discrete:
the natural topology is not the discrete topology, but the induced one, by
intervals.
The diﬀerence is crucial with regard to physical modelling for the fol-
lowing reasons. In physics, the (Cartesian) dimension of space is funda-
mental. By dimension we mean both the number of independent variables
in functions and their “physical meaning” (the dimension of energy, say,
is diﬀerent from that of force). Relativity and string theory, to use some
examples, make it into a constitutive issue, as for the dimension of space-
time; but also, the propagation of heat, or the mean ﬁeld theory, to remain
in classical physics, depends in an essential way upon the dimension under
consideration, see [3]. Now, computability over integers is “indiﬀerent” to
the Cartesian dimension: the expressivity of the machine does not change
by changing the dimensions of its databases, but only the polynomial eﬃ-
ciency. This is due to the computable isomorphism < ., . > between N 2 and
N. One may therefore deﬁne, without diﬃculty and for any discrete formal-
ism, the universal function U within the very class of computable functions
(that is, once the computable functions have been enumerated, (fi)i∈N,
function U(i, n) = fi(n) belongs to such class by the coding < ., . >).
These properties, quite interestingly, are a consequence of the rather
general fact that discrete topology does not force a dimension. In short,
in the discrete universe (the category of sets), any inﬁnite set (integers,
in particular) is isomorphic to all of its ﬁnite (Cartesian) products. But
when discrete topology is no longer “natural”, within a continuum, say,
with Euclidean (or real) topology, for example, the spaces having diﬀer-
ent dimensions are no longer isomorphic. We then say that the dimension
is a topological invariant, for topologies which derive from the interval of
physical measurement (Euclidean, typically).
A remarkable relationship
between geometry and physics: the metrics (and the topology induced) of
the sphere (or interval) indeed corresponds to the “natural” physical mea-
surement, that of the intervals, and it “forces” the dimension, a crucial
notion in physics. So here is a fundamental diﬀerence for continuous math-
ematics (and for computability over continua, would they be just dense):
any bijective encoding of spaces with diﬀerent dimensions is necessarily
non-continuous and, in order to deﬁne, typically, the universal function, it
is necessary to change dimension, hence to leave the given class.

The Mathematics of Computing between Logic and Physics
249
So let’s return to our question, which is, in our view, a rigorous way
to address the extensions of the Church thesis to the mathematics of
physics: Can we correlate diﬀerent formalisms for computability over a
continuum, these being adequate for physical systems and which, there-
fore, make the Cartesian dimension into a fundamental issue, even if they
are non-equivalent? There are no extensions today of the Church thesis
to computable continua and just partial answers are provided by many
authors: [9, 21] present an overview and recent results which, by the addi-
tion of functions and operators which are highly relevant from the physical
standpoint, enable us to establish inclusions under certain conditions, these
being rather informative links. On the basis of these works, we should arrive
at a notion of a “standard system” for computability over the set of com-
putable real numbers which represent a reasonable extension of Church’s
thesis to computable continuity (all “standard” systems would be equiva-
lent, modulo the fundamental issue of dimensions), and therefore also ﬁnd
an interesting link with the mathematics of physics.
However, for a large enough class, this standardization is not obvious
and we are far from having a Church-like equivalence between systems.
Moreover, it is clear that we remain, as in the case of the logico-formal
Church thesis, within mathematical formalismsc. And what about physical
processes?
7.3. Mathematical Computability and the Reality of Physics
Let’s ask a preliminary question to asking if nature computes: What could
nature actually compute? If we look at the object before looking at the
method, things may not be so simple.
Vladimir Arnol’d recalls in his
book [2] the formula attributed to Newton: “It is useful to solve diﬀer-
ential equations”. From another perspective, physics could very well be
expressed according to another formula, provided this time by Galileod.
cIn what concerns the extension of the Church thesis to computer networks and to
concurrent systems in general, systems which are perfectly discrete but distributed over
space–time, this being better understood by means of continuous tools, we refer to [1] and
to its introduction: in this text, it is noted that this thesis, in such a context, is not only
false, but also completely misleading (the processes are not input-output relationships
and their “computational path” – modulo homotopy, for instance – is the true issue of
interest).
d“La ﬁlosoﬁa scritta in questo grandissimo libro che continuamente ci sta aperto innanzi
agli occhi (io dico l’Universo) non si pu´o intendere se prima non s’impara a intender la
lingua, e conoscer i caratteri, nei quali `e scritto. Egli `e scritto in lingua matematica,
e i caratteri son triangoli, cerchi, ed altre ﬁgure geometriche, senza i quali mezzi `e

250
G. Longo & T. Paul
And from Galileo’s standpoint which is, however, far from being formal-
istic or number-theoretic but rather “geometric”, and which continues to
perceive “ﬁlosoﬁa” as an intermediary between ourselves and the world, the
question asked above could very well be natural.
Newton–Arnold’s view point seems more modern. However, it is now
necessary to observe that the importance of an equation, or more gener-
ally, of a mathematical conceptual structure used in physics is often more
important in abstracto than its numerical solutions. But let’s nevertheless
look at what happens upwards to this.
Is there something to solve, to compute?
The description of a physical phenomenon takes place within a frame-
work of “modelling”, that is, within a fundamentally “perturbational”
framework. The isolation of a phenomenon, its intrinsic comprehension,
supposes that we neglect its interaction with the rest of the world. But to
neglect does not mean to annihilate: the rest of the world exists and creates
perturbations at this isolation. From this point of view, a model must be
immersed in an “open set” of models.
The isolation of a concept upon which one is working, for instance,
results from the choice of a given scale. Neighboring scales are then sup-
posed to be either inaccessible (smaller scales), or processable by averaging
(larger scales). In both cases, they can inﬂuence the model and the equa-
tion which yields it.
Asking the question whether something which we
compute, physically, ﬁts into a framework of computability, in the classical
sense, commands having precautions at least.
In particular, are there equations and only equations?
A great part
of classical physics rests upon variational principles. The trajectory ap-
pears not only as the solution to an equation, but as a solution that is
chosen because it optimizes, extremizes a quantity (action). Of course, this
is equivalent to resolving equations (Euler–Lagrange), but this is only an
equivalence. Let’s recall that Feynman [14] preferred solutions to equations
for quantum mechanics. In this case, no more equations: all possible tra-
jectories (minimizing or not the action functional) are involved. This is
possible, but is so thanks to the functional integral, in an inﬁnite dimen-
sional space. And what about computability in this case?
impossibile a intenderne umanamente parola; senza questi `e un aggirarsi vanamente per
un oscuro laberinto.” (Il Saggiatore, 1623.)

The Mathematics of Computing between Logic and Physics
251
Let’s look at another example: quantum ﬁeld theory, a physical theory
which is not mathematically well founded yet, but which has been phenom-
enally successful in terms of precision, is based entirely on perturbative
calculations [26].
Thus it is obvious that, even without considering the lack of precision
of classical measurement, which we will address later on, the true situation
is somewhat fuzzy, largely perturbative, and hence that the problem of
computability in physics is multiple and complex.
Nevertheless let’s suppose that there actually are equations. And let’s
suppose that the true issue is really the solution, which is predictive. We will
then be compelled to remark that the situations where the solution’s values
are important are rare. A simple example: physicists like to draw curves,
even when a formula providing the solution is available. But what is left
of computability when the “result” is smoothed by the graphical process,
where only the general “trends” are important, not the exact values?
Let’s take a look at the dynamical systems provided by maps, the case
of the “baker’s map”, for instance. In principle, there is no mapping in
physics; there are ﬂows. A map appears when we compute a ﬂow at time 1
(which we will later iterate), but this ﬂow at time 1 is actually computed
from equations.
The Poincar´e ﬁrst recurrence map, and the dynamical
systems which followed, were invented as simpler tools, qualitatively and
quantitatively more manageable, but it would be wise to not identify them
too much with the initial systems.
In conclusion let us see whether it is possible to consider an isolated
equation in physics. As we observed, if equations come in families within
which (possibly continuous) parameters change, how must one apprehend
the problem of computability, so carefully deﬁned within a discrete and
countable space? Maybe nature does compute, but knowledge, our theory of
nature, fundamentally rests in huge, inﬁnite spaces (spaces of parametrized
equations, typically), which could very well escape any computationalistic
approach.
Let us examine carefully the example of the epistemological evolution
of the classical concept of “action”.
7.4. From the Principle of Least Action to the Quantum
Theory of Fields
The concept of diﬀerential equation is not the only one which provides a
way for computing dynamics in physics. As we mentioned, an alternative
approach consists in minimizing a certain functional (the action) among

252
G. Longo & T. Paul
diﬀerent candidates for the trajectory. More precisely to any path γ going
from an initial point to a ﬁnal one is associated a number, S(γ), and the
“true” trajectory, the one that the particle is going eﬀectively to follow,
is the one which provides the lowest (in fact any extremal) value of S(γ).
This principle of “least action” does not ask to solve an equation, it just
asks to evaluate the functional S at any possible path γ, and select the
extremal one. If it asks to compute something it doesn’t ask to compute a
ﬁnite number or set of numbers, it asks to evaluate a huge set of numbers,
and to ﬁnd the smallest.
As a matter of fact it is true that the principle of least action is, in
many situations at least, equivalent to the so-called Euler–Lagrange equa-
tions, therefore shown to be embedded in the operational setting.
But
the Feynman “path integral” formulation of quantum mechanics creates a
revival of this idea of evaluating instead of computing. The quantum am-
plitude of probability is obtained by summing expressions of the form ei S(γ)
ℏ
over all paths γ: the process of minimizing the action of the path disap-
peared completely. Here again this formalism is shown to be equivalent to
the Schr¨odinger equation, getting back once more to the operational level.
The situation drastically changes with quantum theory of ﬁelds, a mix-
ing of quantum mechanics and partial diﬀerential equations. This theory,
conceptual basis of our deep understanding of elementary particles, is a
generalization of quantum mechanics to inﬁnite dimension. The formalism
of quantum theory of ﬁelds is an extension of the “path integral” method to
the case where the “paths” γ sit in inﬁnite dimensional spaces. This is the
theory which provides nowadays the most accurate numerical agreement
with experimental data. It “lives” in an extremely huge space (the space of
inﬁnite dimensional paths), and has, up to now, no equivalent operational
setting. Once more we are very far from any form of (extended) Turing
computability. Of course computers were of deﬁnitive usefulness in quan-
tum theory of ﬁelds, as heavy computations were involved. But this was
inside a perturbative approach (see [26]), and not at a conceptual level, as
the conceptual frames radically diﬀer. The close analysis of this diﬀerence
is one of the enriching challenges (and the interest) of computing, today, in
physics.
7.5. Chaotic Determinism and Predictability
In what concerns the relationships between dynamical systems and their
capacity to predict physical evolutions, there is often a great confusion be-

The Mathematics of Computing between Logic and Physics
253
tween mathematics and physical processes.
The notion of deterministic
chaotic system is purely mathematical and is given, in a standard way, by
three formal properties (sensitivity to initial conditions, topological transi-
tivity, and density of periodic trajectories, see [12]). However, it is legiti-
mate to speak of a physical process and to say that it is deterministic (and
chaotic, if such is the case): what is meant by that is that it is possible,
or believed to be so, to write a system of equations, or even an evolution
function, which determines its evolution (in time or regarding the relevant
control parameter). Chaos pops out when the formal properties above are
realized in deterministic systems (yet, weaker forms of chaos are possible,
“mixing systems” for example, [12])
Unpredictability is then a property which arises at the interface between
physical and mathematical processes. One gives oneself a physical process
and a mathematical system, which is supposed to “model” it (a system of
equations, typically, or even an evolution function – an iterated system thus
a discrete-time system, within a continuous space). Then the process with
regard to the system (or even with regard to any reasonable system which
we consider to modelize the given process) is said to be unpredictable.
A physical process “as such” is not unpredictable: one must attempt to
state or even predict, usually by mathematical writing, for there to be
unpredictability. Likewise, a mathematical system is not unpredictable, as
such: it is written and, if fed values, it computes.
And this is where computability comes into play. It happens that any
“reasonable” mathematical system would be characterized by eﬀective writ-
ing: save a pathology (feeding a polynomial with non-computable coeﬃ-
cients, Chaitin’s Omega for instance!), we normally write evolution func-
tions which are computable (we will however see some counter-examples).
More speciﬁcally, any Cauchy problem (a very broad class of diﬀerential
equations) admits computable solutions (if solutions there are), in one of
the known systems for continuous computability. Interesting pathologies,
or counter-examples, do exist; for the moment, it suﬃces to mention some
solutions of the Poisson equation in [27], the boundary of a Julia set, in [5].
But the problem is not only there (not really there, as a matter of fact):
the choice of scale, of perturbative method, of phase space, (or of hidden
variables, or those which were explicitly or unconsciously excluded) shows
the constituted autonomy of mathematical language, because mathemat-
ics is constructed within a friction contingent to the world and then de-
taches from it by its symbolic autonomy. And this construction is a highly
non-computable historical decision, often an inﬁnitary transition towards

254
G. Longo & T. Paul
a limit concept. By this, mathematics is not arbitrary, but the result of a
constructed objectivity.
In summary, when we write a formalism, we give ourselves something
“computable” (grosso modo, because the diﬀerent continuous systems for
computability are not yet uniﬁed, as we recalled above) but this is ob-
tained by an historical choice or limit process, which singles out ﬁnitistic
symbolic construction from the world. So the fact of the computability of
an evolution function, which we suppose to be adequate regarding the de-
scription (modelling) of a physical system, is the evidence which we deduct
from its writing. The logistic function, for instance, see [12, 22], is a sim-
ple and important chaotic system; a computable bilinear function, with a
coeﬃcient k (well, only if one takes a non-computable k, a crazy choice,
it is not computable). A very famous variant of the logistic function is
also given by the “tent” function, a continuous but non-diﬀerentiable de-
formation which preserves many of its interesting properties. This function
modelizes, grosso modo, the movements of stretching and mixing of a piece
of dough by a baker who is a little stiﬀand repetitive in his movements.
These systems, as in the case of any formal writing, are eﬀective and are
in no way unpredictable, as such. We give them values (computable ones)
and they compute: within the limits of the available (ﬁnite) machine, they
produce outputs. However, any physical system which is considered to be
modelized (formalized) by one of these functions is unpredictable, even if
by one of their non-diﬀerentiable variants (an ago-antagonistic system –
chemical action–reaction oscillations, for example, or the baker’s transfor-
mation, in the diﬀerentiable or non-diﬀerentiable case of which we were
speaking). As soon as we give the result of a physical measurement, that
is, an interval, to the function in question, this interval is mixed and expo-
nentially widened, quickly preventing any prediction of the evolution. Of
course, the machine which computes these non-linear functions can also
help appreciate chaos:
1 - it provides images of “dense” trajectories (sequences of points) in
the deﬁnition domain;
2 - a diﬀerence (at the 16th decimal, for instance) in the numeric input
gives very diﬀerent values after few iterations (about 50 in our logistic cases,
see below).
However, if it is relaunched with the same initial values, in a discrete
context (and this is fundamental) it will always return the same trajectory
(sequence of numbers). The point is that, in discrete state machines, ac-
cess to data is exact: this is the crucial diﬀerence w.r. to access to the

The Mathematics of Computing between Logic and Physics
255
world by (classical) physical measure, which is given by the interval of
(approximated) measurement, by principle (there is at least the thermal
ﬂuctuation).
And there lies also the advantage of the discrete state machine, of which
the access to the database is exact: it iterates identically, because it is,
ﬁrstly, an iterating machine. Iteration founds G¨odel-type primitive recur-
sion, which is iteration and +1 in a register (see the note above). It enables
the portability of the software and hence its identical transferal and itera-
tion at will (and it works – without portability and iterability of software,
there would be no computing, nor market for software). You may launch a
program hundreds of times, thousands of times and it iterates.
Computer scientists are so good that they have been able to produce re-
liable and portable software (that is iterating identically) even for networks
of concurrent computers, embedded in continuous space–time, with no abso-
lute clock. Yet, the discrete data types allow this remarkable performance.
Note that identical iteration of a process is very rare in nature (fortunately,
otherwise we would still be with the universe of the origin or with the early
protozoans). We, humans, along our history, invented the discrete state
machines, which iterate. A remarkable human construction, in our space
of humanity, using the alphabet, Descartes dualism (software/hardware),
Hilbert’s systems, G¨odel’s numberings, Turing’s ideas. . . , and a lot of dis-
crete state physics. Computing, programs and alike are not “already there”
in nature. Unfortunately, some miss the point and do not appreciate the
originality nor the founding principles of computing and claim, for example,
that “sometimes they do not iterate”, like nature. Of course, there may
be hardware problems, but these are problems, usually (and easily) ﬁxed.
Instead, non-iteration, identically, is part of the principles of non-linear
dynamics, it is not “a problem”. Let alone life sciences where the main
invariant is. . . variability, even within “structural stability”, which is not
phenotypic identity.
But let’s go back to the interface mathematics/physics. The passage
from the physical process to the formal system is done by means of mea-
surement. If the only formalization/determination we have, or which we
consider to be relevant for a given process, is of the deterministic but chaotic
type, the (classical) physical measurement, which is always an interval (and
which we describe, in general, within a context of continuity) enables us to
only give an interval as input for the computation. And this has a further
fundamental connection with physics, that we already mentioned: the inter-
val topology yields the topological invariance of dimension, a fundamental

256
G. Longo & T. Paul
property of the continua of mathematical physics. Now, given that non-
linear dynamics are mixing (the extremes and the maximum and minimum
points of any interval are “mixed” at each step) and have an “exponential
drift” as Turing puts it, this is a nice way, Turing’s way, to say what we
observed: the interval of measurement soon occupies in a chaotic – mixing
– way an increasing part of space and it is impossible to further predict the
evolution of the physical process. If we were to use as input not an interval,
but a rounded value, this would obviously not help prediction: the result of
the computation may have nothing to do with the physical evolution – for
the logistic function, with k = 4, a rounded value at the 16th decimal makes
any physical process unpredictable approximately from the 50th iteration,
– this is calculated using the value of the Lyapounov exponent, [12].
To return to the baker’s dough, a very simple and common example,
it is a physical process determined by a demonstrably chaotic evolution
function, thus unpredictable. It is a mistake to say, as we sometimes hear,
that it is non-deterministic; it is unpredictably deterministic, which is quite
diﬀerent (the error, in this case, is exactly Laplace’s error, for whom deter-
mination should imply predictability). In physical terms, the forces at play
are all known; the “tent” function determines its evolution well, just as the
logistic determines that of the ago-antagonistic processes or as the equa-
tions of Newton–Laplace determine the evolution of Poincar´e’s three-body.
In classical physics everything is deterministic, even a toss of dice! But
sometimes, it is impossible to predict or calculate evolutions because of the
approximation of physical measurement in conjunction with the sensitiv-
ity to contour conditions, proper to the intended, modelling, mathematical
systems (or with the excess of relevant but hidden variables in the process:
Einstein hoped to transfer this very paradigm to quantum physics).
So, in general, the mathematical systems which we write are computable
and predictable, at the formal level; some of these systems, being chaotic,
refer to unpredictable physical processes. In principle, the latter, as such,
do not “compute”, in the sense of the Church thesis or of its continuous
versions. Let’s specify this point once more.
Computation is an issue of numbers, in fact of the (re-)writing of integer
numbers: lambda-calculus, Turing Machines, are actually a paradigm of it.
Now, to associate a number to a physical system, it is necessary to have
recourse to measurement, a challenge and major issue regarding principles
in physics, as has been realized since Poincar´e and Planck, extraneous to
the logic of arithmetic and, thus, largely forgotten by computationalists
(the world is a large “digital computer”). Classically, if we were to decide

The Mathematics of Computing between Logic and Physics
257
that a certain state of a physical process constitutes the input, and another
the output, and that we associate these states to measurement intervals
and if all we know of this process is mathematically unpredictable, then
it will be impossible, in general and after a suﬃcient amount of time (if
time acts as a control parameter), to compute or predict an output interval
from the input interval of the order of magnitude of the given physical
measurement. In short, if we launch a good old physical double pendulum, if
we manipulate a baker’s dough, it will be impossible to compute, within the
limits of measurement, its position after ﬁve or six oscillations or foldings,
although they may themselves be determined by two equations or by an
evolution function in which all is computable. So the double pendulum,
the stretched dough, as a physical machine/process, does not compute a
computable function. As for quantum mechanics, we will return to this
below.
But do they deﬁne a function, in the usual sense of a single-valued
relation? Because in the same initial (physical) conditions, they do not
generally iterate, and therefore do not even deﬁne a mathematical function
of an argument (which one?) within the initial interval of measurement,
that is a function which would always return the same value. In short, in
mathematics, f(x) = y, when x is not time, is f(x) = y also tomorrow;
while in chaos, even the intervals are not preserved. It would therefore be
necessary to parameter them across time according to a physical reference
system: at best they would deﬁne a function with multiple variables of
which one is the time of the chosen reference system. This makes them
rather useless as machines for deﬁning non-computable functions: they
cannot even be re-used, in time, to compute the same function, because at
each diﬀerent moment we would have diﬀerent values which are a priori
non-repeatable. And no one would buy them as “non-Turing” machines.
And here we are confronted once more with another common error: ex-
pecting that if the physical Church thesis were to be false, then the counter-
example should return a process which computes more than Turing. But
such is not the case. This is an error because a “wild” physical process (as
biologists would put it), in general, does not even deﬁne a function, that
is, a single-valued argument/value relation. The very idea that a process
could be reiterated suggests that it could be redone in the same (identical,
as within a discrete framework) initial conditions. And this, which is so
trivial (in both the English and French senses of the term) for a discrete
state machine, is unachievable in nature, except in very rare or artiﬁcial
cases, save the extension of the parameters to an additional temporal di-

258
G. Longo & T. Paul
mension which considers the counting of the experience performed. In what
concerns life phenomena, do not by any means try to make the halting of a
Turing Machine computed by a paramecium and the movements of its two
thousand cilia: quite upstream to computation, paramecia do not deﬁne
functions by their activities (between the paramecium and computation
there is the “wall” of measurement: how to measure, what to measure,
using which level of approximation?).
Quite thankfully, we have invented an alpha-numeric machine that is
not wild at all, but well domesticated and exact. It comes with its own
reference system and clock (hence the problem in concurrent networks,
where a spatiotemporal absolute is lacking). Thanks to its structure as a
discrete state machine, as Turing emphasized from the moment he produced
his inventione, this machine enables an access to the data and computations
and. . . it iterates, identically, when made to: there are the two reasons for
its strength. And even within computer networks, thanks to the discrete
aspect of databases, we manage to iterate processes, as we said, despite the
challenges entailed by concurrency within physical space–time.
7.6. Return to Computability in Mathematics
Let’s return to the issue of computability beyond the measurement which
we just addressed.
Mathematically, chaos is a long-time phenomenon: as for the sensitivity
to the initial conditions, it is the long-time asymptotic behavior which dif-
fers between chaos and integrability. What is the evolution of the baker’s
dough in the case of an inﬁnite number of iterations? Let’s be more speciﬁc
and look at the case of ergodicity, a property of chaos which is actually weak
(and non-characteristic). A system is ergodic when, for almost all points
(the “ergodic” ones), the temporal and spatial averages of any observable
coincide at the inﬁnite limit. This is a property “in measure” (measure
meant here in the mathematical sense) and it requires, in its “time” com-
ponent, an integration over an inﬁnite time.
Clearly, the question of computability of average up to time t for any
value of t makes sense, and has a clear answer in terms of properties of com-
putability of ordinary diﬀerential equations, but the passing to the limit
t →∞shifts us towards these limits of which it was questioned earlier
eOr shortly after: in 1936, it was nothing more than a logical machine, “a man in the
act of computing”; it is only after 1948 that Turing viewed it also as a physical process
– a discrete state one, as he called it in [32] and [33].

The Mathematics of Computing between Logic and Physics
259
and which we will return to now. In particular, the rate of (mathematical)
convergence will intervene in the answer to the ﬁrst question, and obtaining
information on the rate of this convergence is a very delicate problem es-
pecially in what concerns real, practical ﬂows, those which nature provides
us with.
One must nevertheless not forget the huge contribution of computer
science: the computer, however fundamentally non-chaotic, “shows” chaos
amazingly well, suggests it, presents it to our eyes in a very spectacular and
now completely indispensable way. And this by the (approximated) images
of the density of trajectories, by the very diﬀerent results in the change of
the 16th decimal or so etc. By developing turbulences of any sort in an
otherwise unfeasible way and showing them on a screen, a fantastic help to
scientiﬁc insight is achieved.
The passing to continuity
The passing from rational numbers to real numbers poses more problems
than it may seem: a quantum system in a ﬁnite volume is indeed represented
by a vector space of ﬁnite dimension. Yet, some caution is required; not only
must this space be bounded, but so must the momentum dimension, that is,
the phase space, of which the standard of measurement is Plank’s constant.
But the superposition principle immediately makes the number of states
inﬁnite (to the power of the continuum): this is precisely the “vectorial
aspect” of the theory. Quantum mechanics resides in vector spaces and the
“ﬁniteness” of space entails the ﬁniteness of the dimensions of these spaces,
not their cardinals. It is impossible, for a set value of the Planck constant, to
put anything but a ﬁnite number, d = V
ℏ, of independent vectors (states)
within a ﬁnite volume V , but thanks to (because of) the superposition
principle, it is in fact possible to put an inﬁnite number of vectors, as many
as there are points in Cd. This doesn’t mean of course that, for certain
deﬁnitions of information, the “quantity” of information could not remain
bounded as the system remains conﬁned in a ﬁnite volume, but this shows
the diﬀerence of the concepts of space in classical and quantum situations
(for a discussion of this discrete/continuous dichotomy see e.g. [25]).
One must then evoke the Rolls-Royce of mathematical physics: the the-
ory of partial diﬀerential equations (PDEs).
A PDE can be seen as an
ordinary diﬀerential equation in inﬁnite dimension, it is like a system of
ordinary diﬀerential equations, each of them labelled by a continuous pa-
rameter (by the way, it is precisely this aspect which the computer retains

260
G. Longo & T. Paul
before discretizing this continuous variable): each point in space “carries”
a dynamic variable of which the evolution depends on immediately (even
inﬁnitesimally) neighboring points. Contrary to ordinary diﬀerential equa-
tions which, in general, have a solution for all values of time, we can say
that a PDE has (still generally speaking, in the “hyperbolic” case) a limited
life span, in the sense that its solution can explode in a ﬁnite amount of
time. We therefore witness the emergence of two pitfalls: one passing to
inﬁnity for space, and one passage to “ﬁniteness” for time. This is another
example where the very notion of computability does not apply well to the
physico-mathematical phenomenon.
Let’s now ask ourselves why chaos was invented. The sensitivity to the
initial conditions has appeared as a negative result, preventing integrabil-
ity. The negation of integrability aims to be perceptible in a ﬁnite amount
of time (since integrability places us in front of eternity). But it is very dif-
ﬁcult to demonstrate that a system is not integrable. An alternative result
consists in looking for a totally inverse paradigm: instead of stability, one
looks at instability. The theory of chaos, an extreme and antipodic point
of integrability, oﬀers powerful and realistic results and shows, by this in-
version of paradigm and its qualitative (and negative, yet very informative)
fall-out, its limits with regard to computability.
7.7. Non-determinism?
In computer science, we often deﬁne non-functional relations as being “non-
deterministic”; in short, when we associate a number to a set. Let’s ﬁrst ex-
amine the case of so-called “non-deterministic” Turing Machines, of which
the transition functions have precisely this nature (from a value to a set of
values). Calling them non-deterministic may be reasonable, as an a priori
as long as we remain within logico-computational formalisms, but makes no
physico-mathematical sense. Is there an underlying physical process which
will associate to an input number a set or an element of the set in question?
Not necessarily. So, if deterministic (classical) means (potentially) deter-
mined by equations or evolution functions, a “non-deterministic” Turing
Machine is indeed determined by a function which associates an output set
to an input value (an issue of asymmetrical typing, nothing more).
If there is indeed a choice of value to be made among a set, quantum
physics could certainly propose one: it is legitimate to say that quantum
measurement, by giving probabilities within possible values, performs such
an operation. Can we use a classical process for the same association? Why

The Mathematics of Computing between Logic and Physics
261
not: we can take a physical double pendulum, determined by two equations
or the baker’s dough, of which the evolution is described by the “tent” func-
tion – so there is nothing more deterministic than these two objects and
their evolutions. We give them an input number; the evolution starts oﬀon
an interval of measurement which is roughly centered around this number,
but the result, which is unpredictable after a few iterations, can take a value
among all those within the space. This is what deterministic unpredictabil-
ity is. Yet, with a playful use of language (and a little bit of confusion),
computer scientists also say that this association (one value/one set) pro-
duces a non-functional relation and so consider it as non-deterministic. But
contextual clarity, necessary to the good relationship between mathematics
and physics, then disappears: all is grey and that which is not functional
(nor calculable) is the same, as there is no more diﬀerence between classical
unpredictable determination and quantum indetermination, typically.
In what concerns concurrent systems, the situation is more interest-
ing. Over the course of a process, which occurs within physical space–time,
choices are made among possible values, following the interaction with other
processes. In concrete machines, these choices can depend on classical, rel-
ativistic, quantum, or even human phenomena which intervene within a
network. In the ﬁrst two cases, everything is deterministic, although de-
scribed by non-singled-valued relations and although there may be classical
unpredictability (which value within the determined set? A lesser temporal
discrepancy can produce diﬀerent choices). In the other two cases (quantum
and “human”), the choice of value will be intrinsically non-deterministic,
but, in principle, for diﬀerent reasons (not being able to give an appropri-
ate physical name to the will of humans acting upon a network). In some
cases, authors in concurrency, by non-determinism, refer to a “do-not-care”
of the physical “determination”: whatever is your hardware and your (com-
patible) operating system or compiler, my program for the network must
work identically. A new concept of “non-determination” a very interesting
one, probably with no analogy in natural sciences (my soul doesn’t work
independently of my body, this was Descartes’ mistake, nor it is portable –
this would be a form of metempsychosis).
It would be preferable to introduce a notion of “indeterminacy” spe-
ciﬁc to computer science corresponding to the absence of univocity of the
input–output relation with choices, in particular that which can be found
in “multitasking”, in the concurrence of network processes, etc.

262
G. Longo & T. Paul
The discrete and the “myth” of continuity.
This loss of meaning of continuous physics can be found in Gandy’s
reﬂections on Church’s Thesis, for instance (he was one of the pioneers of the
physical Church thesis, [19]). He posits among other things a physical world
within which information is ﬁnite, because it is part of a ﬁnite universe.
So it is made to be discrete, all the while remaining within a classical
framework, and then deterministic chaos disappears, as happens with the
Turing Machine (Turing says this very clearly in [32], see also [23], and the
discussion on ﬁniteness in quantum mechanics in the preceding paragraph).
Firstly, the mathematical deﬁnitions of chaos use continuity (to repre-
sent the interval of measurement); they will lose their meaning when the
natural topology of space considered is discrete topology (we keep returning
to this, because it is important: the access to the measurement of the pro-
cess will then become exact, because isolated points are accessed exactly,
mathematically – another way to summarize all which we have just said).
Now Gandy does not appear to have followed his master Turing, the in-
ventor of the “Discrete State Machine” (which is theoretically predictable,
says Turing, [32], though it may be practically hard to predict – very long
programs), in the adventure of the continuity of non-linear dynamics (the-
oretically unpredictable, Turing remarks, this being their most interesting
property, [33], see [23] for a discussion).
As a matter of fact, Turing had a deep understanding of this issue in
the later years of his life, making a remarkable contribution to the devel-
opment of what he called “continuous systems” (the name which he gives
to the linear and non-linear models of morphogenesis, [33], and which he
already uses in [32] in contraposition to his machine). In fact, continuity is
currently the best tool we have for addressing classical determination. It is
the “myth” of an underlying or abstract space, a mathematical continuum,
which leads us to think that any classical trajectory is deterministic: it is
“ﬁliform” (widthless) and stems from a Euclid–Cantor point (dimension-
less, said Euclid). It is a “myth” in the sense of Greek mythology, because
it constructs knowledge, but is removed from the world. This limit, the
point, and Euclid’s widthless line are not given by measurement, our only
access to the physical world. The myth is at the asymptotic limit, like the
thermodynamic integral which gives us the irreversibility of diﬀusion at the
inﬁnite limit (that is, which demonstrates the second principle, by suppos-
ing an inﬁnity of trajectories for the molecules of a gas within a large, but
ﬁnite volume). The mythical (conceptual, if the reader prefers) limit makes

The Mathematics of Computing between Logic and Physics
263
us understand: how audacious this beginning of a science, this imagination
of the widthless line, of the point of no dimension. Without those limit
(inﬁnitary!) concepts, which are not in the world, there would have been
no theory of the measurement of surfaces: it is necessary to have “width-
less” edges and dimensionless points at the intersections of lines, in order
to propose a general theory of areas, the Greek extraordinary invention
(how thick should otherwise be the border of a triangle?). Myths, as the
invention of something “which is not there”, are necessary to enhance the-
ories, beginning with Euclid’s continuum, lines, points. . . ﬁniteness, as the
discrete of a naive and pre-scientiﬁc, pre-Greek perception, entails machine-
like stupidity.
In this context and since Einstein, we have gone further and have even
come to say that ﬁnite, for the universe, does not mean limited. Think of the
relativistic model of the Riemann sphere: it is ﬁnite but unlimited, contrary
to the notion of ﬁniteness as limitation to be found with Euclid (inﬁnite =
a-peiron = without limits). Why would the information on the Riemann
sphere be “ﬁnite” in such a model? Of which type of ﬁniteness would we
be speaking of? Euclidean ﬁniteness or modern unlimited ﬁniteness? Be
it relativistic or quantum, “ﬁniteness” contains inﬁnity, as unboundedness,
by measure.
Except for great thinkers such as Turing, logicians and computer scien-
tists tend to have a culture of the ﬁnite/discrete/Laplacian, as Turing said
of his machine, which is diﬃcult to escape. Its origin is the arithmetizing
perspective of Frege with regard to the “delirium” of Riemannian geome-
try, says he in 1884. But it is also in the philosophical incomprehension
of Hilbert, one of the great ﬁgures of mathematical physics, concerning
unpredictability, of even Poincar´e’s type of undecidability (it is impossi-
ble to calculate – decide – the position of three planets after a suﬃciently
long period of time), when he speaks of mathematics: 20 years later, he
will launch one decidability conjecture after the other, all of them being
false (Arithmetics, Choice, Continuum Hypothesis), despite the highly jus-
tiﬁed objections from Poincar´e (Mr Hilbert thinks of mathematics as a
sausage-making machine!). Poincar´e had already experimented with unde-
cidability, as unpredictability, though in the friction between mathematics
and physics (not of purely mathematical statements, Hilbert’s question).
However, this culture of predictable (and integrable!), of the determination
within a universe (a discrete, ﬁnite, and limited database), has given us
marvelous Laplacian machines. Let’s just make an eﬀort to better correlate
them to the world, today. A good practice, and theory, of modelling and of

264
G. Longo & T. Paul
networks, that of concurrency, impose them. They evolve within a space–
time which we understand better, for the moment, thanks to continuity.
Thankfully, there are also hybrid systems and continuous computability
which propose quite diﬀerent perspectives. And likewise for the work of
Girard which tries to enrich logic with concepts that are central to the
ﬁeld of the physico-mathematical: symmetries, operator algebra, quantum
non-commutativity.
But let’s return to quantum mechanics.
7.8. The Case of Quantum Mechanics
The quantum issue could at ﬁrst glance present a perfect symbiosis be-
tween the two preceding sections: we are dealing with a fundamentally
fundamental equation, Schr¨odinger’s equation, which derives from nothing,
which must be at the center of any fundamental process, and of which the
mathematization is perfect, depending on only a single parameter (actu-
ally, is the value of Planck’s constant a computable number?). Moreover,
“measurement” takes on a whole new dimension. The interval, as such, no
longer exists and intrinsic randomness is introduced.
Let’s now mention the importance, particularly in the ﬁeld of the physics
of elementary particles, of the role played by computers. The computation
of precise numeric values, for instance the calculation of the electron’s mag-
netic moment, and their literally “phenomenal” concordance with experi-
ence has doubtlessly had a crucial importance for the development of the
theory. And this precisely in the very ﬁeld where computers have become
irreplaceable: numeric computation. Associating a number to hundreds, to
thousands of Feynman diagrams is an operation beyond human capability
and which computer science bravely accomplishes.
The results provided by quantum physics are precise, and have a level
of precision which any other physical theory has yet to attain. They are
also discrete, meaning that the richness of continuity has been lost, and
that we are facing a (discrete) play of possibilities. Of course, what we are
actually measuring is a classical object, a classical trace (bubble chamber,
photographic plate, etc.)
with a quantum value. We are indeed at the
heart of the problem: a quantum measurement provides values belonging
to a discrete set (set of values speciﬁc to the Hamiltonian), hence a cer-
tain rigidity that is a source of stability and therefore of precision (those
of discrete topology). Seen from this angle, quantum “precision” seems
tautological in a way; we allow ourselves no leeway around discrete values

The Mathematics of Computing between Logic and Physics
265
which would enable us to extend into the voluptuousness of imprecision.
We could even say: let’s provide ourselves, once and for all, with all the
values speciﬁc to all the Hamiltonians of the world and we will have a ﬁeld
of “outputs” which is discrete in its very essence.
But this is precisely forgetting that the result of such measurement is
obtained upon a classical object from which the result of the measure is
accessible to us. The atomic spectral lines appear on a photographic plate.
Therefore the classical continuum is, a posteriori, the locus of the quan-
tum result, together with its virtues, harmful because prone to introduce
imprecision. And so, what the fact that quantum mechanics is incredibly
precise really means is that, during experiments, it leaves classical traces of
an extreme level of precision, practically exhibiting a discrete sub-structure
of the continuum.
And this is not tautological at all.
In addition to this discreteness, and precision, quantum mechanics has
caused some diﬃculties by conferring a random aspect to the result of
measurement. Let’s say right now that something had to happen, because
the principle of quantum superposition prohibits a direct access, beyond
measurement, to the quantum space of states (we do not “see” superposed
states, or entangled states); more accurately, we “look” at them, and they
must be looked at to be seen, by getting measured, they “de-superpose”
themselves, they de-entangle.
This random aspect immediately escapes
any computational system of. . . computability. No more determinism, no
more equations. Of course, it is possible to talk about statistics, and to
wonder whether these statistics are computable. We then return to the
non-deterministic algorithms of the preceding section, but with a diﬀerent
problem.
Quantum algorithms are a perfect illustration of this. Let’s recall that
a quantum algorithm consists in a quantum system evolving from an initial
piece of data having, in a way, a classical “input”. By principle of super-
position, entanglement, at the end of an evolution, has done its job and
the ﬁnal state is typically quantum, superposed in several states, of which
a single one contains the “output” sought. To get it, we then perform a
measurement that is supposed, by construction, to produce the good result
with a maximal probability.
What is Turing computable in all of this?
We can wonder regarding the ﬁrst part of the quantum evolution related
to quantum “equational” evolution modulo the remarks made at the end
of Section 7.6 concerning PDEs (Schr¨odinger’s equation is a PDE after all,

266
G. Longo & T. Paul
but a linear and not an hyperbolic one), and could possibly answer: yes,
this part of the quantum evolution is computable. But the last phase, that
of measurement, again escapes computational reduction: the random aspect
of measurement, let us rest assured, will never enable a quantum computer
to decode a credit card at the desired moment with certainty.
Quantum algorithms versus non-deterministic algorithms
It could be advisable to specify the important diﬀerence between quan-
tum and non-deterministic algorithms, a source, it appears, of many con-
fusions. Indeed, one could confuse two very diﬀerent “parallel” aspects.
A quantum algorithm, in a way, works well in parallel; computation
is fundamentally vectorial because of the very nature of quantum dynam-
ics. But the ﬁnal result, that which needs to be extracted from the ﬁnal
quantum state, is a single one of the components present within the latter.
The other components, the whole “ﬁnal state” vector, has no interest as
such: ﬁrstly because it is inaccessible, then because the other components
(other than the component containing the results) do not carry any infor-
mation related to the initial problem. So it is not an issue of dispersing the
information in order to parcel it out and hence increase the power of the
computation and then “patching the pieces back together”, in a way, but
rather of placing oneself within a space (a quantum space, and again, one
that has not yet been satisfactorily achieved experimentally) from which
one needs to suddenly return in order to ﬁnish the computation.
Because the essential is indeed there: the “computation”, the “process”
is ﬁnished only once the ultimate measurement is taken. It is this total pro-
cess which must be placed in the view of computability, and not the purely
quantum part which conveys no information. It is exactly the same idea
which is responsible for there being no “EPR paradox” because, although
we are acting from a distance upon the entangled vector, no information is
transmitted.
Let us mention also that logic based on the quantum mechanics
paradigm has been recently introduced by J.Y. Girard, without explicit mo-
tivation in the direction of quantum calculus [20]. We conclude by saying
that the randomness of quantum mechanics is intrinsic, it escapes compu-
tation. What about classical randomness?

The Mathematics of Computing between Logic and Physics
267
7.9. Randomness, Between Unpredictability and Chaos
In [4], classical randomness and deterministic unpredictability are identi-
ﬁed, from the point of view of mathematical physics. Randomness would
present itself, we observed, at the interface between mathematics (or,
more generally, between language) and physical processes. It must how-
ever not be ignored that, in certain probabilistic, purely mathematical
frameworks (measure theory), we can also speak of randomness, away
from physical processes.
By computation theoretic tools, Per Martin-
L¨of advanced, 40 years ago, a purely mathematical notion of random-
ness.
More speciﬁcally, one can, by means of computability, tell when
an inﬁnite sequence of integers (of 0s and 1s for example) is random,
without reference to an eventual physical generative process.
In short,
a random sequence is Martin-L¨of (ML) computable if it is “strongly” non-
computable, a deﬁnition which requires a little bit of work (see [29] for a
recent overview). In a sense, formal computability/predictability can tell
us when we leave its domain: this is like G¨odel who, in his proof of incom-
pleteness, never left the formal, and who was yet able to give a formula
which escapes the formal (which is formally unprovable, jointly to its nega-
tion).
Moreover, what interests us here, this purely mathematical random-
ness, is “at inﬁnity”, exactly like the randomness within chaotic classical
dynamics is asymptotic: a random Martin-L¨of sequence is inﬁnite (the ini-
tial segments are at best incompressible).
What can then be said of the relationship between this notion, purely
mathematical, and physics? From the statistical viewpoint, which was the
preoccupation of Martin-L¨of at the time, every thing is ﬁne: the distribu-
tion of the probabilities of a ML-random sequence, for a good probability
measurement, is that of the toss of a coin, to inﬁnity. But what about the
relationship to the physico-mathematical of dynamical systems? How can
one pass directly, by mathematical means, without reference to the physical
processes that the two approaches modelize, from ML-randomness to un-
predictable determinism (systems of equations or evolution functions)? We
can see possible correlations in the recent PhD theses by M. Hoyrup and
C. Rojas (in Longo’s team): the points and the trajectories within chaotic
systems are analyzed in terms of ML-randomness, all the while using suit-
able notions of measure, of mathematical entropy and Birkhoﬀergodicity.
In the two cases, those of sequences of integers and of continuous dynamics,
we work to inﬁnity.

268
G. Longo & T. Paul
Let’s be more precise. A dynamical system, as a purely mathematical
formalism for physics, is said to be “mixing” if the correlation of a given
pair of observables decreases at least polynomially with time. Like ergod-
icity, this is an asymptotic property of “disorder”, a weak form of chaos.
What was recently proved is that, in mixing dynamics, ergodic points co-
incide with ML-random ones (in fact for a slightly diﬀerent deﬁnition of
ML-randomness, due to Schnorr). Thus deterministic unpredictability, as
ergodicity in mixing dynamics, overlap with a strong form of undecidability,
that is algorithmic randomness. In other words, if we want to relate physical
processes to eﬀective computations, which is an issue of elaboration of num-
bers, we can, but, at the limit: all processes that are modeled by a some-
what chaotic system, produce non-computable, actually random, sequences,
within the mathematical system. Or, also, (strong) non-computability (as
algorithmic randomness) may be found in formal writings of the physical
world (dynamical systems are perfectly formalisable, of course). That is,
at the limit, we may say “no” to Laplace’s conjecture of predictability of
deterministic systems and, this, in terms of (a strong form of) undecidabil-
ity, `a la G¨odel. Predicting, in physics, is a matter of “saying” (pre-dicere,
to say in advance) by a formal language or system about a physical process
in ﬁnite time, as we said several times: by these results, instead, Poincar´e’s
ﬁnite unpredictability joins undecidability, asymptotically. In conclusion,
deterministic ergodic and mixing dynamics, which model “weakly chaotic”
physical processes, generate (highly) non-computable featuresf.
7.10. General Conclusions
The reader might have felt that the authors have a point of view “against”
a vision of nature that was too organized around computations.
Once
again computers have brought so much to science that it is not necessary
to recall the beneﬁt provided. It seems to us that this situation, where a
given viewpoint invades a whole ﬁeld of science, happened several times in
the past. An example is the case of mathematical analysis at the turn of
the last century, a period where many new objects in mathematics were
born, such as nowhere diﬀerentiable functions, Cantor sets, summation
methods of diverging series.
To focus on the latter let us quote Emile
Borel, in the introduction of his famous book on diverging series [8]. Borel
discusses the fact that analysis “`a la Cauchy”, based on convergent Taylor
expansions of analytic functions, although it brought a considerable amount
fSee [16–18], [15] and http://www.di.ens.fr/∼longo/ for ongoing work. Connections be-
tween algorithmic and quantum randomness are analyzed in [11].

The Mathematics of Computing between Logic and Physics
269
of progress in mathematics, ﬁxed also into rigidity a lot of non-rigorous
methods used by the geometers (in the sense of physicists) of the older time:
“This revolutiong was necessary: nevertheless one might ask if dropping
the less rigorous methods of the geometers (...) was good or not: (...) but
this period [of rigor] being passed, the study of former methods might be
wealthy...”.
Let’s see what we have done so far. We have reviewed certain aspects of
computation in physics and in mathematics. We have seen that many situ-
ations in physics, even classical physics, cause processes which are “beyond
computation” (in the sense of “calculus resolving equations”) to intervene.
We have also mentioned the calculatory contribution of computer science
and its essential role. Now, let’s not forget the importance as such of the
plurality of “visions” for understanding the natural sciences, a plurality
which has always existed in the sciences. The new perspective proposed
by the discrete, in great part due to the contribution of computer science,
is a conceptual and technical resource, which adds itself to the diﬀeren-
tiable physico-mathematical continuum, from Newton to Schr¨odinger (or
even consider, for example, the importance of computer modelling in biol-
ogy, to mention another discipline, [34]). On the other hand, the reduction
to a conceptual and mathematical dimension that is too “computational”
(in the excessively naive sense of the term) would, in our view, lead us to
sterile boredom, in which even the “nuances” of the post-Laplacian contin-
uum would be absent. Finally and in particular, within an “equational”
framework for the play between the continuum and the discrete, we have
discussed notions that appear to be fundamental to modern science, such as
those of determinism and of predictability, from where emerges the notion
of uncertainty. But let’s take a further look.
As compounded in [4], classical physical randomness is of an “epistemic”
nature, whereas that of quantum measurement is intrinsic or “objective”:
a distinction which should be solely an instrument of clarity, of conceptual
clarity if possible, and nothing more. By this we refer to several aspects
among which the one of interest to us is the following: classical random-
ness can be analyzed by means of diﬀerent methods. In short, it is possible
to address dice, the double pendulum, the baker’s dough, etc. in terms
of statistically random sequences and of probability distributions (central
limit theorem, etc.), but also by means of the mathematics of chaotic de-
gThe Cauchy and Abel rigorous vision of Analysis based on convergence of expansions
of Taylor series.

270
G. Longo & T. Paul
terminism (if we have the courage to write the several equations needed for
the movement of dice; it is easy for the double pendulum and the baker’s
dough). Some people, mainly in the ﬁeld of computer science as we have
seen, say that the toss of dice or that the baker’s dough (or even the three
bodies?)
are non-deterministic because, by using the approximation of
measurement, it is possible to associate several numeric outputs to an ex-
act input number and the same wording is used for computational non-
determinism. It is an abuse of language which ignores the speciﬁcations
brought by the broadening by Poincar´e of the ﬁeld of determination, which
includes classical randomness in the ﬁeld of chaotic determination (the non-
linearity of “continuous systems”, and the related “exponential drift”, says
Turing in 1952), and by the indetermination of quantum physics. This is
speciﬁc to the culture of the discrete, which is wonderful for our discrete
state machines, but which misses the 120 years of geometrization of physics
(geometry of dynamic and relativistic systems) and which fails to appreciate
the role of measurement (classical/quantum).
We thus see the apparition of three idealizations thanks to which we
could think it possible to discover and understand the world (classical).
1. The digital, discrete ideal which (possibly) shows nature as computing
and only as computing. Computing, iterating, and reiterating to inﬁnity
with a wonderful and misleading precision.
2. The ideal of continuous mathematics, where nature (mathematics)
solves equations. In itself, this vision is perfectly deterministic, the equa-
tions have solutions.
3. The ideal of the equation, for which nature divides itself into diﬀerent
scales, impenetrable to each other – for example the quantum world, the
classical one, hydrodynamics, celestial mechanics, cosmology etc.
These ideals (1,2,3) are placed in anti-chronological order: historically,
equations were the ﬁrst to appear, followed by their mathematical models,
and ﬁnally by their digital simulation.
To conclude, let’s look at the connections and anti-connections between
these three worldviews, these three tiers that we could compare to Girard’s
three basements. This would be the result of the present work.
At ﬁrst glance, we could easily go up from the third to the second and
then to the ﬁrst level. Continuous mathematics seem perfect for equations,
and digital approximation has become so commonplace that one must al-
most hide to criticize it. But the elevator does not work properly: between
the third and second levels, Poincar´e shakes things up (non-integrability
and sensitivity to the initial conditions, as it is, make diﬃcult the practi-

The Mathematics of Computing between Logic and Physics
271
cal idea of a trajectory within continua), and between the second and ﬁrst
levels we have lost, by climbing to the level of the discrete, a few aspects
that were important to continuity (the ﬂuctuations below the threshold of
discretization as well as the discrete blackness of milk). If we take the stairs
to go down, we get dizzy: lack of computational equivalence for the pass-
ing to computational continua (Section 2), and loss of reliability with the
introduction of the interval of imprecision when passing from the second to
the third levels. . .
And there is quantum mechanics with its intrinsic randomness. Ideal
3 is then shattered during measurement: no more equations. Of course,
physics can make do without individual measurement processes: we have
not (yet) experimentally observed the reduction of wave packets during
unique events, all we can observe are averages, statistics. But recent physics
pushes towards the study and observation of simple quantum physical sys-
tems which are always better at conducting the “gedenken Experiment”h of
the founding fathers [28], and in any case the reduction of the wave packet
during measurement is, we believe, a necessary component of quantum for-
malism, an axiom which makes it coherent.
This situation is not new in physics: we do not observe Newtonian me-
chanics in a mole of gas. And yet it is thanks to such mechanics that we can
reconstruct the dynamics of gases and thermodynamics. Mind though, this
reconstruction is the result of the passing to inﬁnity (the thermodynamic
integral) from a ﬁnite non-observable model.
Acknowledgements
We would like to thank Eug`ene Asarin, Olivier Bournez, Mathieu Hoyrup,
and Cristobal Rojas for their critical reading of the manuscript. The au-
thors’ papers may be downloaded from http://www.di.ens.fr/∼longo/ and
http://www.dma.ens.fr/∼paul/.
References
[1] L. Aceto, G. Longo, and B. V., eds., The diﬀerence between sequential and
concurrent computations, Math. Structures Comput. Sci. (Special issue). 13
(4–5), (2003).
[2] V. I. Arnol’d, Geometrical Methods in Ordinary Diﬀerential Equations.
Springer, Berlin, (1987).
hEPR paradox, Schr¨odinger’s cat for example.

272
G. Longo & T. Paul
[3] F. Bailly and G. Longo, Math´ematiques et sciences de la nature. La singu-
larit´e physique du vivant. Hermann, Paris, (2006). English translation: in
Imperial College Press/World Scientiﬁc, 2011.
[4] F. Bailly and G. Longo, Randomness and determination in the interplay
between the continuum and the discrete, Math. Structures Comput. Sci. 17
(2), 289–307, (2007).
[5] M. Baverman and M. Yampolski, (2005). Non-computable Julia sets.
Preprint. Available at http://www.math.toronto.edu/yampol/, [Accessed
October 2010].
[6] J. Bell, A Primer in Inﬁnitesimal Analysis. Cambridge University Press,
(1998).
[7] L. Blum, L. Cucker, M. Shub, and S. Smale, Complexity and Real Compu-
tation. Springer, Berlin, (1998).
[8] E. Borel, Le¸cons sur les s´eries divergentes. Gauthier-Villars, Paris, (1928).
[9] O. Bournez. Mod`eles continus. calculs. Habilitation DR, LORIA, Nancy,
(2006).
[10] V. Bush, The diﬀerential analyzer, J. Franklin Inst. 212(4), 447–488, (1931).
[11] C. Calude and M. Stay, From Heisenberg to G¨odel via Chaitin, Internat. J.
Theoret. Phys. 44(7), 1053–1065, (2005).
[12] R. L. Devaney, An Introduction to Chaotic Dynamical Systems. Addison-
Wesley, New York, (1989).
[13] G. Dowek. La forme physique de la th`ese de Church et la sensibilit´e aux
conditions initiales. In eds. J.-B. Joinet and Tron¸con, Ouvrir la logique
au monde. Philosophie et math´ematique de l’interaction, actes de l’´ecole
th´ematique interdisciplinaire “Logique, Sciences, Philosophie” (Cerisy-la-
Salle, 19-26 septembre 2006), Hermann, Paris, (2009).
[14] R. Feynman, Quantum mechanics and Path Integrals. McGrawth-Hill, New
York, (1965).
[15] P. Gacs, M. Hoyrup, and C. Rojas, Randomness on computable probability
spaces – A dynamical point of view, Theory Comput. Syst. (Special issue
STACS 09). (2010). doi: 10.1007/s00224-010-9263-x.
[16] S. Galatolo, M. Hoyrup, and C. Rojas, A constructive Borel–Cantelli
Lemma. Constructing orbits with required statistical properties, Theoret.
Comput. Sci. 410, 2207–2222, (2009).
[17] S. Galatolo, M. Hoyrup, and C. Rojas, Eﬀective symbolic dynamics, random
points, statistical behavior, complexity and entropy, Inform. and Comput.
208(1), 23–41, (2010).
[18] S. Galatolo, M. Hoyrup, and C. Rojas. Dynamics and abstract computabil-
ity: computing invariant measures. To appear in Disc. Cont. Dyn. Sys.,
(arXiv:0903.2385).
[19] R. Gandy. Church’s Thesis and the principles for mechanisms. In eds. J. Bar-
wise, J. Keisler, and K. Kunen, The Kleene Symposium. North–Holland,
(1980).
[20] J. Y. Girard, Le point aveugle. Hermann, Paris, (2007).
[21] E. Hainry. Mod`eles de calculs sur les r´eels. Th`ese. LORIA, Nancy, (2006).
[22] M. Hoyrup, A. Kolcak, and G. Longo, Computability and the morphological

The Mathematics of Computing between Logic and Physics
273
complexity of some dynamics on continuous domains, Theoret. Comput. Sci.
398(1–3), 170–182, (2008).
[23] G. Longo. Laplace, Turing and the “imitation game” impossible geometry:
randomness, determinism and programs in Turing’s test. In eds. R. Epstein,
G. Roberts, and G. Beber, Parsing the Turing Test, pp. 377–411. Springer,
Berlin, (2009).
[24] C. Moore, Recursion theory on the reals and continuous-time computation,
Theoret. Comput. Sci. 162, 23–44, (1996).
[25] T. Paul, Discrete-continuous and classical-quantum, Math. Structures Com-
put. Sci. 17, 177–183, (2007).
[26] T. Paul, On the status of perturbation theory, Math. Structures Comput.
Sci. 17, 277–288, (2007).
[27] M. B. Pour-El and J. I. Richards, Computability in Analysis and Physics.
Perspectives in mathematical logic, Springer, Berlin, (1989).
[28] J.-M. Raimond. Compl´ementarit´e, intrication, d´ecoh´erence: les exp´eriences
de pens´ees r´ealis´ees (conference). In Qu’est-ce qui est r´eel, ´Ecole Normale
Sup´erieure, (2005). Organizers:
C. Debru, and G. Longo, T. Paul and
G.Vivance. Available at: http://www.diffusion.ens.fr/index.php?res=
conf\&idconf=807, [Accessed October 2010].
[29] C. Rojas, Computability and information in models of randomness and
chaos, Math. Structures Comput. Sci. 18, 291–307, (2008).
[30] C. Shannon, Mathematical theory of the diﬀerential analyzer, J. Math. Phys.
20, 337–354, (1941).
[31] A. M. Turing. Intelligent machinery. In eds. B. Meltzer and D. Michie,
Machine Intelligence 5, pp. 3–23. Edinburgh University Press, Edinburgh,
(1969). National Physical Laboratory Report, 1948.
[32] A. M. Turing, Computing machines and intelligence, Mind. LIX(236), 433–
460, (1950).
[33] A. M. Turing, The chemical basis of morphogenesis, Phil. Trans. R. Soc.
London. B237, 37–72, (1952).
[34] F. Varenne, Du mod`ele `a la simulation informatique. Vrin, Paris, (2007).
[35] K. Weihrauch, Computable Analysis. Texts in Theoretical Computer Science,
Springer, Berlin, (2000).

This page intentionally left blank
This page intentionally left blank

Chapter 8
Liquid State Machines: Motivation, Theory, and
Applications
Wolfgang Maass
Institute for Theoretical Computer Science
Graz University of Technology
A-8010 Graz, Austria
E-mail: maass@igi.tugraz.at
The Liquid State Machine (LSM) has emerged as a computational model
that is more adequate than the Turing machine for describing compu-
tations in biological networks of neurons. Characteristic features of this
new model are (i) that it is a model for adaptive computational systems,
(ii) that it provides a method for employing randomly connected circuits,
or even “found” physical objects for meaningful computations, (iii) that
it provides a theoretical context where heterogeneous, rather than stereo-
typical, local gates, or processors increase the computational power of
a circuit, (iv) that it provides a method for multiplexing diﬀerent com-
putations (on a common input) within the same circuit. This chapter
reviews the motivation for this model, its theoretical background, and
current work on implementations of this model in innovative artiﬁcial
computing devices.
Contents
8.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
8.2
Why Turing Machines are Not Useful for Many Important Computational
Tasks
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
8.3
Formal Deﬁnition and Theory of Liquid State Machines . . . . . . . . . . . . 285
8.4
Applications
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
8.5
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
8.1. Introduction
The Liquid State Machine (LSM) had been proposed in [26] as a computa-
tional model that is more adequate for modelling computations in cortical
microcircuits than traditional models, such as Turing machines or attractor-
275

276
W. Maass
based models in dynamical systems. In contrast to these other models, the
LSM is a model for real-time computations on continuous streams of data
(such as spike trains, i.e., sequences of action potentials of neurons that
provide external inputs to a cortical microcircuit). In other words: both
inputs and outputs of an LSM are streams of data in continuous time.
These inputs and outputs are modelled mathematically as functions u(t)
and y(t) of continuous time. These functions are usually multi-dimensional
(see Fig. 8.1, Fig. 8.2, and Fig. 8.3), because they typically model spike
trains from many external neurons that provide inputs to the circuit, and
many diﬀerent “readouts” that extract output spike trains. Since an LSM
maps input streams u(·) onto output streams y(·) (rather than numbers or
bits onto numbers or bits), one usually says that it implements a functional
or operator (like a ﬁlter), although for a mathematician it simply imple-
ments a function from and onto objects of a higher type than numbers or
bits. A characteristic feature of such higher-type computational processing
is that the target value y(t) of the output stream at time t may depend on
the values u(s) of the input streams at many (potentially even inﬁnitely
many) preceding time points s.
Another fundamental diﬀerence between the LSM and other computa-
tional models is that the LSM is a model for an adaptive computing system.
Therefore its characteristic features only become apparent if one considers
it in the context of a learning framework. The LSM model is motivated by
the hypothesis that the learning capability of an information processing de-
vice is its most delicate aspect, and that the availability of suﬃciently many
training examples is a primary bottleneck for goal-directed (i.e., supervised
or reward-based) learning. Therefore its architecture is designed to make
the learning as fast and robust as possible. It delegates the primary load of
goal-directed learning to a single and seemingly trivial stage: the output, or
readout stage (see Fig. 8.4), which typically is a very simple computational
component. In models for biological information processing each readout
usually consists of just a single neuron, a projection neuron in the terminol-
ogy of neuroscience, which extracts information from a local microcircuit
and projects it to other microcircuits within the same or other brain areas.
It can be modelled by a linear gate, a perceptron (i.e., a linear gate with
a threshold), by a sigmoidal gate, or by a spiking neuron. The bulk of the
LSM (the “Liquid”) serves as pre-processor for such readout neuron, which
ampliﬁes the range of possible functions of the input streams u(t) that it
can learn. Such division of computational processing into Liquid and read-
out is actually quite eﬃcient, because the same Liquid can serve a large

Liquid State Machines: Motivation, Theory, and Applications
277
Figure 8.1.
Modelling a generic cortical microcircuit by an LSM. Template for a generic
cortical microcircuit based on data from [33], see [9, 10] for details. The width of arrows
indicates the product of connection probabilities and average strength (i.e., synaptic
weight) between excitatory (left hand side) and inhibitory (right hand side) neurons on
three cortical layers. Input stream 1 represents sensory inputs, input stream 2 represents
inputs from other cortical areas. Arrows toward the top and toward the bottom indicate
connections of projection neurons (“readouts”) on layer 2/3 and layer 5 to other cortical
microcircuits. In general these projection neurons also send axonal branches (collaterals)
back into the circuit.
number of diﬀerent readout neurons, that each learn to extract a diﬀerent
“summary” of information from the same Liquid. The need for extracting
diﬀerent summaries of information from a cortical microcircuit arises from
diﬀerent computational goals (such as the movement direction of objects
versus the identity of objects in the case where u(t) represents visual in-

278
W. Maass
Figure 8.2.
Hypothetical computational function of a generic cortical microcircuit in
the context of the LSM model. In general the projection neurons also provide feedback
back into the microcircuit (see Theorem 8.2 in Section 3).
puts) of diﬀerent projection targets of the projection neurons. Data from
neurophysiology show in fact that for natural stimuli the spike trains of
diﬀerent projection neurons from the same column tend to be only weakly
correlated. Thus the LSM is a model for multiplexing diverse computations
on a common input stream u(t) (see Fig. 8.1, Fig. 8.2, and Fig. 8.3).
One assumes that the Liquid is not adapted for a single computational
task (i.e., for a single readout neuron), but provides computational prepro-
cessing for a large range of possible tasks of diﬀerent readouts. It could also

Liquid State Machines: Motivation, Theory, and Applications
279
Figure 8.3.
Multi-tasking in real-time. Below the 4 input spike trains (shown at the top)
the target outputs (dashed curves) and actual outputs (solid curves) of 7 linear readout
neurons are shown in real-time (on the same time axis). Targets were to output every
30 ms the sum of the current ﬁring rates of input spike trains 1 and 2 during the preceding
30 ms (f1), the sum of the current ﬁring rates of input spike trains 3 and 4 during the
preceding 30 ms (f2), the sum of f1 and f2 in an earlier time interval [t-60 ms, t-30 ms]
(f3) and during the interval [t-150 ms, t] (f4), spike coincidences between inputs 1&3
(f5(t) is deﬁned as the number of spikes which are accompanied by a spike in the other
spike train within 5 ms during the interval [t-20 ms, t]), a simple nonlinear combination f6
(product) and a randomly chosen complex nonlinear combination f7 of earlier described
values. Since all readouts were linear units, these nonlinear combinations are computed
implicitly within the generic microcircuit model (consisting of 270 spiking neurons with
randomly chosen synaptic connections). The performance of the model is shown for test
spike inputs that had not been used for training (see [27] for details).
be adaptive, but by other learning algorithms than the readouts, for exam-
ple by unsupervised learning algorithms that are directed by the statistics
of the inputs u(t) to the Liquid.
The Liquid is in more abstract mod-
els a generic dynamical system – preferentially consisting of diverse rather

280
W. Maass
than uniform and stereotypical components (for reasons that will become
apparent below). In biological models (see Fig. 8.1, Fig. 8.2, Fig. 8.3) the
Liquid is typically a generic recurrently connected local network of neurons,
modelling for example a cortical column which spans all cortical layers and
has a diameter of about 0.5 mm. But it has been shown that also an ac-
tual physical Liquid (such as a bucket of water) may provide an important
computational preprocessing for subsequent linear readouts (see [7] for a
demonstration, and [8] for theoretical analysis). We refer to the input vec-
tor x(t) that a readout receives from a Liquid at a particular time point t as
the liquid state (of the Liquid) at this time point t (in terms of dynamical
systems theory, this liquid state is that component of the internal state of
the Liquid – viewed as a dynamical system – that is visible to some readout
unit). This notion is motivated by the observation that the LSM generalizes
the information processing capabilities of a ﬁnite state machine (which also
maps input functions onto output functions, although these are functions
of discrete time) from a ﬁnite to a continuous set of possible values, and
from discrete to continuous time. Hence the states x(t) of an LSM are more
“liquid” than those of a ﬁnite state machine.
Figure 8.4.
Structure of a Liquid State Machine (LSM) M, which transforms input
streams u(·) into output streams y(·).
LM denotes a Liquid (e.g., some dynamical
system), and the “liquid state” xM(t) ∈Rk is the input to the readout at time t. More
generally, xM(t) is that part of the current internal state of the Liquid that is “visible”
for the readout. Only one input and output channel are shown for simplicity.

Liquid State Machines: Motivation, Theory, and Applications
281
This architecture of a LSM, consisting of Liquid and readouts, makes
sense, because it turns out that in many contexts there exist common com-
putational preprocessing needs for many diﬀerent readouts with diﬀerent
computational goals. This can already be seen from the trivial fact that
computing all pairwise products of a set of input numbers (say: of all
components of a multi-dimensional input u(t′) for a ﬁxed time point t′)
gives any subsequent linear readout the virtual expressive power of any
quadratic computation on the original input u(t′). A pre-processor for a
linear readout is even more useful if it maps more generally any frequently
occurring (or salient) diﬀerent input streams u(·) onto linearly independent
liquid states x(t) [21], similarly as an RBF-kernel for Support Vector Ma-
chines. A remarkable aspect of this more general characterization of the
pre-processing task for a Liquid is that it does not require that it computes
precise products, or any other concrete nonlinear mathematical operation.
Any “found” analog computing device (it could even be very imprecise,
with mismatched transistors or other more easily found nonlinear opera-
tions in physical objects) consisting of suﬃciently diverse local processes,
tends to approximate this requirement quite well. A closer look shows that
the actual requirement on a Liquid is a bit more subtle, since one typically
only wants that the Liquid maps “saliently” diﬀerent input streams u(·)
onto linearly independent liquid states x(t), whereas noisy variations of the
“same” input stream should rather be mapped onto a lower dimensional
manifold of liquid states, see [20, 21] for details.
An at least equally important computational pre-processing task of a
Liquid is to provide all temporal integration of information that is needed by
the readouts. If the target value y(t) of a readout at time t depends not only
on the values of the input streams at the same time point t, but on a range of
input values u(s) for many diﬀerent time points s (say, if y(t) is the integral
over one component of u(s) for a certain interval [t−1, t]), then the Liquid
has to collect all required information from inputs at preceding time points
u(s), and present all this information simultaneously in the liquid state
x(t) at time point t (see Fig. 8.3 and Fig. 8.4). This is necessary, because
the readout stage has, by assumption, no temporal integration capability
of its own, i.e., it can only learn to carry out “static” computations that
map x(t) onto y(t). A readout does not even know what the current time
t is. It just learns a map f from input numbers to output numbers. Hence
it just learns a ﬁxed recoding (or projection) f from liquid states into
output values. This severe computational limitation of the readout of an
LSM is motivated by the fact, that learning a static map f is so much

282
W. Maass
simpler than learning a map from input streams to output streams. And
a primary goal of the LSM is to make the learning as fast and robust as
possible. Altogether, an essential prediction of LSM-theory for information
processing in cortical microcircuits is that they accumulate information over
time. This prediction has recently been veriﬁed for cortical microcircuits
in the primary visual cortex [28] and in the primary auditory cortex [18].
The advantage of choosing for a LSM the simplest possible learning de-
vice is twofold: Firstly, learning for a single readout neuron is fast, and
cannot get stuck in local minima (like backprop or EM). Secondly, the sim-
plicity of this learning device entails a superior – in fact, arguably optimal
– generalization capability of learned computational operations to new in-
puts streams. This is due to the fact that its VC-dimension (see [2] for a
review) is equal to the dimensionality of its input plus 1. This is the small-
est possible value of any nontrivial learning device with the same input
dimension.
It is a priori not clear that a Liquid can carry the highly nontrivial com-
putational burden of not only providing all desired nonlinear preprocessing
for linear readouts, but simultaneously also all temporal integration that
they might need in order to implement a particular mapping from input
streams u(·) onto output streams y(·). But there exist two basic mathemat-
ical results (see Theorems 8.1 and 8.2 in Section 8.3) which show that this
goal can in principle be achieved, or rather approximated, by a concrete
physical implementation of a Liquid which satisﬁes some rather general
property. A remarkable discovery, which had been achieved independently
and virtually simultaneously around 2001 by Herbert Jaeger [14], is that
there are surprisingly simple Liquids, i.e., generic preprocessors for a subse-
quent linear learning device, that work well independently of the concrete
computational tasks that are subsequentially learned by the learning de-
vice. In fact, naturally found materials and randomly connected circuits
tend to perform well as Liquids, which partially motivates the interest of
the LSM model both in the context of computations in the brain, and in
novel computing technologies.
Herbert Jaeger [14] had introduced the name Echo State Networks
(ESNs) for the largely equivalent version of the LSM that he had inde-
pendently discovered. He explored applications of randomly connected re-
current networks of sigmoidal neurons without noise as Liquids (in con-
trast to the biologically oriented LSM studies, that assume signiﬁcant in-
ternal noise in the Liquid) to complex time series prediction tasks, and
showed that they provide superior performance on common benchmark

Liquid State Machines: Motivation, Theory, and Applications
283
tasks.
The group of Benjamin Schrauwen (see [31, 32, 35, 36]) intro-
duced the term Reservoir Computing as a more general term for the in-
vestigation of LSMs, ESNs, and variations of these models.
A variety
of applications of these models can be found in a special issue of Neu-
ral Networks 2007 (see [15]).
All these groups are currently collaborat-
ing in the integrated EU-project ORGANIC (= Self-organized recurrent
neural learning for language processing) that investigates applications of
these models to speech understanding and reading of handwritten text (see
http://reservoir-computing.org). An industrial partner in this project,
the company PLANET (http://english.planet.de) had already good
success in applications of Reservoir Computing to automated high-speed
reading of hand-written postal addresses.
We will contrast these models and their computational use with that of
Turing machines in the next section. In Section 8.3 we will give a formal
deﬁnition of the LSM, and also some theoretical results on its computational
power. We will discuss applications of the LSM and ESN model to biology
and new computing devices in Section 8.4 (although the discussion of its
biological aspects will be very short in view of the recent review paper [5]
on this topic).
8.2. Why Turing Machines are Not Useful for Many Impor-
tant Computational Tasks
The computation of a Turing machine always begins in a designated initial
state q0, with the input x (some ﬁnite string of symbols from some ﬁnite
alphabet) written on some designated tape. The computation runs until a
halt-state is entered (the inscription y of some designated tape segment is
then interpreted as the result of the computation). This is a typical example
for an oﬄine computation (Fig. 8.5A), where the complete input x is avail-
able at the beginning of the computation, and no trace of this computation,
or of its result y, is left when the same Turing machine subsequently carries
out another computation for another input ˜x (starting again in state q0).
In contrast, the result of a typical computation in the neuronal system of
a biological organism, say the decision about the location y on the ground
where the left foot is going to be placed at the next step (while walking
or running), depends on several pieces of information: on information from
the visual system, from the vestibular system which supports balance con-
trol, from the muscles (proprioceptive feedback about their current state),
from short term memory (how well did the previous foot placement work?),

284
W. Maass
from long-term memory (how slippery is this path in the current weather
conditions?), from brain systems that have previously decided where to go
and at what speed, and on information from various other parts of the
neural system. In general these diverse pieces of information arrive at dif-
ferent points in time, and the computation of y has to start before the
last one has come in (see Fig. 8.5B). Furthermore, new information (e.g.,
visual information and proprioceptive feedback) arrives continuously, and
it is left up to the computational system how much of it can be integrated
into the computation of the position y of the next placement of the left
foot (obviously those organisms have a better chance to survive which also
can integrate later arriving information into the computation). Once the
computation of y is completed, the computation of the location y′ where
the right foot is subsequently placed is not a separate computation, that
starts again in some neutral initial state q0. Rather, it is likely to build on
pieces of inputs and results of subcomputations that had already been used
for the preceding computation of y.
The previously sketched computational task is a typical example for
an online computation (where input pieces arrive all the time, not in one
batch, see Fig. 8.5B). Furthermore it is an example for a real-time com-
putation, where one has a strict deadline by which the computation of
the output y has to be completed (otherwise a two-legged animal would
fall). In fact, in some critical situations (e.g., when a two-legged animal
stumbles, or hits an unexpected obstacle) a biological organism is forced
to apply an anytime algorithm, which tries to make optimal use of inter-
mediate results of computational processing that has occurred up to some
externally given time point t0 (such forced halt of the computation could
occur at“any time”). Diﬃculties in the control of walking for two-legged
robots have taught us how diﬃcult it is to design algorithms which can carry
out this seemingly simple computational task. In fact, this computational
problem is largely unsolved, and humanoid robots can only operate within
environments for which they have been provided with an accurate model.
This is perhaps surprising, since on the other hand current computers can
beat human champions in seemingly more demanding computational tasks,
such as winning a game of chess. One might argue that one reason, why
walking in a new terrain is currently a computationally less solved task,
is that computation theory and algorithm design have focused for several
decades on oﬄine computations, and have neglected seemingly mundane
computational tasks such as walking. This bias is understandable, because
evolution had much more time to develop a computational machinery for

Liquid State Machines: Motivation, Theory, and Applications
285
Figure 8.5.
Symbolic representation of oﬄine and online computations.
(A) In an
oﬄine computation all relevant input computations are available at the start of the
computation, and the algorithm may require substantial computation time until the
result becomes available. (B) In online computations additional pieces of information
arrive all the time. The most eﬃcient computational processing scheme integrates as
many preceding input pieces as possible into its output whenever an output demand
arises. In that sense computations by a LSM are optimally eﬃcient.
the control of human walking, and this computational machinery works so
well that we don’t even notice anymore how diﬃcult this computational
task is.
8.3. Formal Deﬁnition and Theory of Liquid State Machines
A computation machine M that carries out online computations typically
computes a function F that does not map input numbers or (ﬁnite) bit
strings onto output numbers or bit strings, but input streams onto output
streams. These input and output streams are usually encoded as functions
u : Z →Rn or u : R →Rn, where the argument t of u(t) is interpreted

286
W. Maass
as the (discrete or continuous) time point t when the information that is
encoded by u(t) ∈Rn becomes available. Hence such computational ma-
chine M computes a function of higher type (usually referred to as operator,
functional, or ﬁlter), that maps input functions u from some domain U onto
output functions y. For lack of a better term we will use the term “ﬁlter”
in this section, although ﬁlters are often associated with somewhat trivial
signal processing or preprossessing devices. However, one should not fall
into the trap of identifying the general term of a ﬁlter with special classes
of ﬁlters such as linear ﬁlters. Rather one should keep in mind that any
input to any organism is a function of time, and any motor output of an
organism is a function of time. Hence biological organisms compute ﬁlters.
The same holds true for any artiﬁcial behaving system, such as a robot.
We will only consider computational operations on functions of time
that are input-driven, in the sense that the output does not depend on any
absolute internal clock of the computational device. Filters that have this
property are called time invariant. Formally one says that a ﬁlter F is time
invariant if any temporal shift of the input function u(·) by some amount t0
causes a temporal shift of the output function by the same amount t0, i.e.,
(Fut0)(t) = (Fu)(t+t0) for all t, t0 ∈R, where ut0 is the function deﬁned by
ut0(t) := u(t+t0). Note that if the domain U of input functions u(·) is closed
under temporal shifts, then a time invariant ﬁlter F : U →RR is identiﬁed
uniquely by the values y(0) = (Fu)(0) of its output functions y(·) at time
0. In other words: in order to identify or characterize a time invariant ﬁlter
F we just have to observe its output values at time 0, while its input varies
over all functions u(·) ∈U. Hence one can replace in the mathematical
analysis such ﬁlter F by a functional, i.e., a simpler mathematical object
that maps input functions onto real values (rather than onto functions of
time).
Various theoretical models for analog computing are of little practical
use because they rely on hair-trigger decisions, for example they allow that
the output is 1 if the value of some real-valued input variable u is ≥0, and
0 otherwise. Another unrealistic aspect of some models for computation
on functions of time is that they automatically allow that the output of
the computation depends on the full inﬁnitely long history of the input
function u(·). Most practically relevant models for analog computation on
continuous input streams degrade gracefully under the inﬂuence of noise,
i.e., they have a fading memory. Fading memory is a continuity property
of ﬁlters F, which requires that for any input function u(·) ∈U the output
(Fu)(0) can be approximated by the outputs (Fv)(0) for any other input

Liquid State Machines: Motivation, Theory, and Applications
287
functions v(·) ∈U that approximate u(·) on a suﬃciently long time interval
[−T, 0] in the past.
Formally one deﬁnes that F : U →RR has fading
memory if for every u ∈U n and every ε > 0 there exist δ > 0 and T > 0
so that |(Fv)(0) −(Fu)(0)| < ε for all v ∈U with ∥u(t) −v(t)∥< δ for all
t ∈[−T, 0]. Informally, a ﬁlter F has fading memory if the most signiﬁcant
bits of its current output value (Fu)(0) depend just on the most signiﬁcant
bits of the values of its input function u(·) in some ﬁnite time interval
[−T, 0]. Thus, in order to compute the most signiﬁcant bits of (Fu)(0) it is
not necessary to know the precise value of the input function u(s) for any
time s, and it is also not necessary to have knowledge about values of u(·)
for more than a ﬁnite time interval back into the past.
The universe of time-invariant fading memory ﬁlters is quite large. It
contains all ﬁlters F that can be characterized by Volterra series, i.e., all
ﬁlters F whose output (Fu)(t) is given by a ﬁnite or inﬁnite sum (with
d = 0, 1, . . .) of terms of the form
∞
R
0
. . .
∞
R
0
hd(τ1, . . . , τd) · u(t −τ1) · . . . ·
u(t −τd)dτ1 . . . dτd, where some integral kernel hd is applied to products
of degree d of the input stream u(·) at various time points t −τi back in
the past. In fact, under some mild conditions on the domain U of input
streams the class of time invariant fading memory ﬁlters coincides with the
class of ﬁlters that can be characterized by Volterra series.
In spite of their complexity, all these ﬁlters can be uniformly approxi-
mated by the simple computational models M of the type shown in Fig. 8.4,
which had been introduced in [26]:
Theorem 8.1. (based on [3]; see Theorem 3.1 in [24] for a detailed proof).
Any ﬁlter F deﬁned by a Volterra series can be approximated with any
desired degree of precision by the simple computational model M shown in
Fig. 8.1 and Fig. 8.2.
• if there is a rich enough pool B of basis ﬁlters (time invariant, with fading
memory) from which the basis ﬁlters B1, . . . , Bk in the ﬁlterbank LM can
be chosen (B needs to have the pointwise separation property) and
• if there is a rich enough pool R from which the readout functions f can be
chosen (R needs to have the universal approximation property, i.e., any
continuous function on a compact domain can be uniformly approximated
by functions from R).
Deﬁnition 8.1. A class B of basis ﬁlters has the pointwise separation
property if there exists for any two input functions u(·), v(·) with u(s) ̸=
v(s) for some s ≤t a basis ﬁlter B ∈B with (Bu)(t) ̸= (Bv)(t).

288
W. Maass
It turns out that many real-world dynamical systems (even a pool of
water) satisfy (for some domain U of input streams) at least some weak
version of the pointwise separation property, where the outputs xM(t) of
the basis ﬁlters are replaced by some “visible” components of the state
vector of the dynamical system. In fact, many real-world dynamical systems
also satisfy approximately an interesting kernel propertya, which makes
it practically suﬃcient to use just a linear readout function f M.
This
is particularly important if LM is kept ﬁxed, and only the readout f M
is selected (or trained) in order to approximate some particular Volterra
series F. Reducing the adaptive part of M to the linear readout function
f M has the unique advantage that a learning algorithm that uses gradient
descent to minimize the approximation error of M cannot get stuck in local
minima of the mean-squared error. The resulting computational model can
be viewed as a generalization of a ﬁnite state machine to continuous time
and continuous (“liquid”) internal states xM(t). Hence it is called a Liquid
State Machine.
If the dynamical systems LM have fading memory, then only ﬁlters
with fading memory can be represented by the resulting LSMs. Hence they
cannot approximate arbitrary ﬁnite state machines (not even for the case
of discrete time and a ﬁnite range of values u(t)). It turns out that a large
jump in computational power occurs if one augments the computational
model from Fig. 8.4 by a feedback from a readout back into the circuit
(assume it enters the circuit like an input variable).
Theorem 8.2. [23]. There exists a large class Sn of dynamical systems
C with fading memory (described by systems of n ﬁrst order diﬀerential
equations) that acquire through feedback universal computational capabili-
ties for analog computing. More precisely: through a proper choice of a
(memoryless) feedback function K and readout h they can simulate any
given dynamical system of the form z(n) = G(z, z′, . . . , z(n−1)) + u with
a suﬃciently smooth function G (see Fig. 8.6). This holds in particular
aA kernel (in the sense of machine learning) is a nonlinear projection Q of n input
variables u1, . . . , un into some high-dimensional space. For example all products ui · uj
could be added as further components to the n-dimensional input vector < u1, . . . , un >.
Such nonlinear projection Q boosts the power of any linear readout f applied to Q(u).
For example in the case where Q(u) contains all products ui · uj, a subsequent linear
readout has the same expressive capability as quadratic readouts f applied to the original
input variables u1, . . . , un. More abstractly, Q should map all inputs u that need to be
separated by a readout onto a set of linearly independent vectors Q(u).

Liquid State Machines: Motivation, Theory, and Applications
289
for neural circuits C deﬁned by diﬀerential equations of the form x′
i(t) =
−λixi(t) + σ(Pn
j=1 aijxj(t)) + bi · σ(v(t)) (under some conditions on the
λi, aij, bi).
Figure 8.6.
Illustration of the notation and result of Theorem 8.2.
If one allows several feedbacks K, such dynamical systems C become
universal for nth order dynamical systems deﬁned by a system consisting
of a corresponding number of diﬀerential equations. Since such systems
of diﬀerential equations can simulate arbitrary Turing machines [4], these
dynamical systems C with a ﬁnite number of feedbacks become (according
to the Church–Turing thesis) also universal for digital computation.
Theorem 8.2 suggests that even quite simple neural circuits with feed-
back have, in principle, unlimited computational powerb.
This suggests
that the main problem of a biological organism becomes the selection (or
learning) of suitable feedback functions K and readout functions h. For
dynamical systems C that have a good kernel-property, already linear feed-
backs and readouts endow such dynamical systems with the capability to
emulate a fairly large range of other dynamical systems (or “analog com-
puters”).
Recent theoretical work has addressed methods for replacing supervised
training of readouts by reinforcement learning [22] (where readout neurons
explore autonomously diﬀerent settings of their weights, until they ﬁnd
some which yield outputs that are rewarded) and by completely unsuper-
vised learning (where not even rewards for successful outputs are available).
bOf course, in the presence of noise this computational power is reduced to that of a
ﬁnite state machine, see [23] for details.

290
W. Maass
It is shown in [19] that already the repeated occurrence of certain trajecto-
ries of liquid status enables a readout to classify such trajectories according
to the type of input which caused them. In this way a readout can for
example learn without supervision to classify (i.e., “understand”) spoken
digits. The theoretical basis for this result is that unsupervised slow feature
extraction approximates the discrimination capability of the Fisher Linear
Discriminant if the sequence of liquid states that occur during training
satisﬁes a certain statistical condition.
8.4. Applications
LSMs had been introduced in the process of searching for computational
models that can help us to understand the computations that are carried
out in a “cortical microcircuit” [25], i.e., in a local circuit of neurons in the
neocortex (say in a “cortical column”). This approach has turned out to
be quite successful, since it made it possible to carry out quite demanding
computations with circuits consisting of reasonably realistic models for bi-
ological neurons (“spiking neurons”) and biological synapses (“dynamical
synapses”). Note that in this model a large number of diﬀerent readout
neurons can learn to extract diﬀerent information from the same circuit.
One concrete benchmark task that has been considered was the classiﬁca-
tion (“recognition”) of spoken digits [12]. It turned out that already an
LSM where the “Liquid” consisted of a randomly connected circuit of just
135 spiking neurons performed quite well. In fact, it provided a nice exam-
ple for “anytime computations”, since the linear readout could be trained
eﬀectively to guess at “any time”, while a digit was spoken, the proper
classiﬁcation of the digit [26, 27]. More recently it has been shown that
with a suitable transformation of spoken digits into spike trains one can
achieve with this simple method the performance level of state-of-the-art
algorithms for speech recognition [36].
A number of recent neurobiological experiments in vivo has lead many
biologists to the conclusion that also for neural computation in larger neural
systems than cortical microcircuits a new computational model is needed
(see the recent review [30]). In this new model certain frequently occurring
trajectories of network states – rather than attractors to which they might
or might not converge – should become the main carriers of information
about external sensory stimuli. The review [5] examines to what extent the
LSM and related models satisfy the need for such new models for neural
computation.

Liquid State Machines: Motivation, Theory, and Applications
291
It has also been suggested [16] that LSMs might present a useful frame-
work for modeling computations in gene regulation networks. These net-
works also compute on time varying inputs (e.g., external signals) and
produce a multitude of time varying output signals (transcription rates of
genes). Furthermore these networks are composed of a very large number
of diverse subprocesses (transcription of transcription factors) that tend to
have each a somewhat diﬀerent temporal dynamics (see [1]). Hence they
exhibit characteristic features of a Liquid in the LSM model. Furthermore
there exist perceptron-like gene regulation processes that could serve as
readouts from such Liquids (see chapter 6 in [1]).
In the remainder of this section we will review a few applications of
the LSM model to the design of new artiﬁcial computing system. In [7] it
had been demonstrated that one can use a bucket of water as Liquid for a
physical implementation of the LSM model. Input streams were injected
via 8 motors into this Liquid and video-images of the surface of the water
were used as “liquid states” x(t). It was demonstrated in [7] that the pre-
viously mentioned classiﬁcation task of spoken digits could in principle also
be carried out with this – certainly very innovative – computing device.
But other potential technological applications of the LSM model have also
been considered. The article [32] describes an implementation of a LSM
in FPGAs (Field Programmable Gate Arrays). In the US a patent was
recently granted for a potential implementation of a LSM via nanoscale
molecular connections [29]. Furthermore work is in progress on implemen-
tations of LSMs in photonic computing, where networks of semiconductor
optical ampliﬁers serve as Liquid (see [35] for a review).
The exploration of potential engineering applications of the computa-
tional paradigm discussed in this article is simultaneously also carried out
for the closely related echo state networks (ESNs) [14], where one uses sim-
pler non-spiking models for neurons in the “Liquid”, and works with high
numerical precision in the simulation of the “Liquid” and the training of
linear readouts.
Research in recent years has produced quite encourag-
ing results regarding applications of ESNs and LSMs to problems in tele-
communication [14], robotics [11], reinforcement learning [6], natural lan-
guage understanding [34], as well as music-production and -perception [13].
8.5. Discussion
We have argued in this article that Turing machines are not well suited for
modeling computations in biological neural circuits, and proposed Liquid

292
W. Maass
state machines (LSMs) as a more adequate modeling framework. They are
designed to model real-time computations (as well as anytime computa-
tions) on continuous input streams. In fact, it is quite realistic that an
LSM can be trained to carry out the online computation task that we had
discussed in Section 8.2 (see [17] for a ﬁrst application to motor control). A
characteristic feature of practical implementations of the LSM model is that
its “program” consists of the weights w of a linear readout function. These
weights provide suitable targets for learning (while all other parameters of
the LSM can be ﬁxed in advance, based on the expected complexity and
precision requirement of the computational tasks that are to be learnt). It
makes a lot of sense (from the perspective of statistical learning theory) to
restrict learning to such weights w, since they have the unique advantage
that gradient descent with regard to some mean-square error function E(w)
cannot get stuck in local minima of this error function (since ∇wE(w) = 0
deﬁnes an aﬃne – hence connected – subspace of the weight space for a
linear learning device).
One can view these weights w of the linear readout of a LSM as an
analog to the code < M > of a Turing machine M that is simulated by a
universal Turing machine. This analogy makes the learning advantage of
LSMs clear, since there is no eﬃcient learning algorithm known which allows
us to learn the program < M > for a Turing machine M from examples for
correct input/output pairs of M. However the examples discussed in this
chapter show that an LSM can be trained quite eﬃciently to approximate
a particular map from input to output streams.
We have also shown in Theorem 8.2 that LSMs can overcome the lim-
itation of a fading memory if one allows feedback from readouts back into
the “Liquid”. Then not only all digital, but (in a well-deﬁned sense) also
all analog computers can be simulated by a ﬁxed LSM, provided that one
is allowed to vary the readout functions (including those that provide feed-
back). Hence these readout functions can be viewed as program for the sim-
ulated analog computers (note that all “readout functions” are just “static”
functions, i.e., maps from Rn into R, whereas the LSM itself maps input
streams onto output streams). In those practically relevant cases that have
been considered so far, these readout functions could often be chosen to
be linear. A satisfactory characterization of the computational power that
can be reached with linear readouts is still missing.
But obviously the
kernel-property of the underlying “Liquid” can boost the richness of the
class of analog computers that can be simulated by a ﬁxed LSM with linear
readouts.

Liquid State Machines: Motivation, Theory, and Applications
293
The theoretical analysis of computational properties of randomly con-
nected circuits and other potential “Liquids” is still in its infancy. We refer
to [8, 20, 21, 31, 37] for useful ﬁrst steps. The qualities that we expect
from the “Liquid” of an LSM are completely diﬀerent from those that one
expects from standard computing devices. One expects diversity (rather
than uniformity) of the responses of individual gates within a Liquid (see
Theorem 8.1), as well as diverse local dynamics instead of synchronized
local gate operations. Achieving such diversity is apparently easy to attain
by biological neural circuits and by new artiﬁcial circuits on the molecular
or atomic scale. It is obviously much easier to attain than an emulation
of precisely engineered and synchronized circuits of the type that we ﬁnd
in our current generation of digital computers. These only function prop-
erly if all local units are identical copies of a small number of template
units that respond in a stereotypical fashion. For a theoretician it is also
interesting to learn that sparse random connections within a recurrent cir-
cuit turn out to provide better computational capabilities to an LSM than
those connectivity graphs that have primarily been considered in earlier
theoretical studies, such as all-to-all connections (Hopﬁeld networks) or a
two-dimensional grid (which is commonly used for cellular automata). Al-
together one sees that the LSM and related models provide a wide range
of interesting new problems in computational theory, the chance to under-
stand biological computations, and new ideas for the invention of radically
diﬀerent artiﬁcial computing devices that exploit, rather than suppress,
inherent properties of diverse physical substances.
Acknowledgements
Partially supported by the Austrian Science Fund FWF, project P17229
and project S9102-N13, and by the European Union, project # FP6-015879
(FACETS), project FP7-216593 (SECO) and FP7-231267 (ORGANIC).
References
[1] U. Alon, An Introduction to Systems Biology: Design Principles of Biological
Circuits. Chapman & Hall, Netherlands, (2007).
[2] P. L. Bartlett and W. Maass. Vapnik-Chervonenkis dimension of neural nets.
In ed., M. A. Arbib, The Handbook of Brain Theory and Neural Networks,
pp. 1188–1192. MIT Press, Cambridge, 2nd edition, (2003).
[3] S. Boyd and L. O. Chua, Fading memory and the problem of approximat-

294
W. Maass
ing nonlinear oparators with Volterra series, IEEE Trans. on Circuits and
Systems. 32, 1150–1161, (1985).
[4] M. S. Branicky, Universal computation and other capabilities of hybrid and
continuous dynamical systems, Theoret. Comput. Sci. 138, 67–100, (1995).
[5] D. Buonomano and W. Maass, State-dependent computations: Spatiotem-
poral processing in cortical networks. Nature Reviews Neuroscience. 10(2),
113–125, (2009).
[6] K. Bush and C. Anderson. Modeling reward functions for incomplete state
representations via echo state networks. In Proceedings of the International
Joint Conference on Neural Networks, Montreal, Quebec, (2005).
[7] C. Fernando and S. Sojakka. Pattern recognition in a bucket: a real liquid
brain. In Proceedings of ECAL. Springer, Berlin–Heidelberg, (2003).
[8] S. Ganguli, D. Huh, and H. Sompolinsky, Memory traces in dynamical sys-
tems, Proc. Natl. Acad. Sci. USA. 105, 18970–18975, (2008).
[9] S. Haeusler and W. Maass, A statistical analysis of information processing
properties of lamina-speciﬁc cortical microcircuit models, Cereb. Cortex. 17
(1), 149–162, (2007).
[10] S. Haeusler, K. Schuch, and W. Maass, Motif distribution and computational
performance of two data-based cortical microcircuit templates, J. Physiology
– Paris. (2009). in press.
[11] J. Hertzberg, H. J¨ager, and F. Sch¨onherr. Learning to ground fact symbols in
behavior-based robot. In ed. F. van Harmelen ed., Proc. of the 15th European
Conference on Artiﬁcial Intelligence, pp. 708–712, IOS Press, Amsterdam,
(2002).
[12] J. J. Hopﬁeld and C. D. Brody, What is a moment? Transient synchrony
as a collective mechanism for spatio-temporal integration, Proc. Natl. Acad.
Sci. USA. 98(3), 1282–1287, (2001).
[13] H. Jaeger and D. Eck. Can’t get you out of my head: A connectionist model
of cyclic rehearsal. In eds., I. Wachsmuth and G. Knoblich, Modeling Com-
munication with Robots and Virtual Humans, (2008).
[14] H. Jaeger and H. Haas, Harnessing nonlinearity: predicting chaotic systems
and saving energy in wireless communication, Science. 304, 78–80, (2004).
[15] H. Jaeger, W. Maass, and J. Principe, Introduction to the special issue on
echo state networks and liquid state machines, Neural Networks. 20(3),
287–289, (2007).
[16] B. Jones, D. Stekel, J. Rowe, and C. Fernando, Is there a liquid state machine
in the bacterium escherichia coli?, Artif. Life. ALIFE’07, IEEE Symposium,
187–191, (2007).
[17] P. Joshi and W. Maass, Movement generation with circuits of spiking neu-
rons, Neural Comput. 17(8), 1715–1738, (2005).
[18] S. Klampﬂ, S. V. David, P. Yin, S.A. Shamma, and W. Maass, Integration
of stimulus history in information conveyed by neurons in primary auditory
cortex in response to tone sequences, 39th Annual Conference of the Society
for Neuroscience, Program 163.8, Poster T6. (2009).
[19] S. Klampﬂand W. Maass, A neuron can learn anytime classiﬁcation of
trajectories of network states without supervision, submitted for publication.

Liquid State Machines: Motivation, Theory, and Applications
295
(Feb. 2009).
[20] R. Legenstein and W. Maass. What makes a dynamical system computa-
tionally powerful?
In eds., S. Haykin, J. C. Principe, T. Sejnowski, and
J. McWhirter, New Directions in Statistical Signal Processing: From Sys-
tems to Brains, pp. 127–154. MIT Press, Cambridge, MA, (2007).
[21] R. Legenstein and W. Maass, Edge of chaos and prediction of computational
performance for neural microcircuit models, Neural Networks. 20(3), 323–
334, (2007).
[22] R. Legenstein, D. Pecevski, and W. Maass, A learning theory for reward-
modulated spike-timing-dependent plasticity with application to biofeed-
back, PLoS Computational Biology. 4(10), 1–27, (2008).
[23] W. Maass, P. Joshi, and E. D. Sontag, Computational aspects of feedback
in neural circuits, PLoS Computational Biology. 3(1), e165, 1–20, (2007).
[24] W. Maass and H. Markram, On the computational power of recurrent cir-
cuits of spiking neurons, J. Comput. System Sci.. 69(4), 593–616, (2004).
[25] W. Maass and H. Markram. Theory of the computational function of mi-
crocircuit dynamics. In eds. S. Grillner and A. M. Graybiel, The Interface
between Neurons and Global Brain Function, Dahlem Workshop Report 93,
pp. 371–390. MIT Press, (2006).
[26] W. Maass, T. Natschlaeger, and H. Markram, Real-time computing without
stable states: A new framework for neural computation based on perturba-
tions, Neural Comput. 14(11), 2531–2560, (2002).
[27] W. Maass, T. Natschlaeger, and H. Markram, Fading memory and kernel
properties of generic cortical microcircuit models, J. Physiology – Paris. 98
(4–6), 315–330, (2004).
[28] D.
Nikolic, S.
Haeusler, W. Singer, and W. Maass, Distributed fading
memory for stimulus properties in the primary visual cortex, PLoS Biology.
7(12), 1–19, (2009).
[29] A. Nugent, Physical neural network liquid state machine utilizing nanotech-
nology. (US-Patent 7 392 230 32, June 2008).
[30] M. Rabinovich, R. Huerta, and G. Laurent, Transient dynamics for neural
processing, Science. 321, 45–50, (2008).
[31] B. Schrauwen, L. Buesing, and R. Legenstein. On computational power and
the order-chaos phase transition in reservoir computing. In Proceeding of
NIPS 2008, Advances in Neural Information Processing Systems. MIT Press,
Cambridge, MA, (2009). In press.
[32] B. Schrauwen, M. D’Haene, D. Verstraeten, and D.Stroobandt, Compact
hardware liquid state machines on FPGA for real-time speech recognition,
Neural Networks. 21, 511–523, (2008).
[33] A. M. Thomson, D. C. West, Y. Wang, and A. P. Bannister, Synaptic con-
nections and small circuits involving excitatory and inhibitory neurons in
layers 2–5 of adult rat and cat neocortex: triple intracellular recordings and
biocytin labelling in vitro, Cereb. Cortex. 12(9), 936–953, (2002).
[34] M. Tong, A. Bickett, E. Christiansen, and G. Cotrell, Learning grammatical
structure with echo state networks, Neural Networks. 20(3), 424–432, (2007).
[35] K. Vandoorne, W. Dierckx, B. Schrauwen, D. Verstraeten, R. Baets, P. Bi-

296
W. Maass
enstman, and J. V. Campenhout, Toward optical signal processing using
photonic reservoir computing, Opt. Express. 16(15), 11182–11192, (2008).
[36] D. Verstraeten, B. Schrauwen, D. Stroobandt, and J. V. Campenhout, Iso-
lated word recognition with the liquid state machine: a case study., Inform.
Process. Lett. 95(6), 521–528, (2005).
[37] O. L. White, D. D. Lee, and H. Sompolinsky, Short-term memory in orthog-
onal neural networks, Phys. Rev. Letters. 92(14), 148102, (2004).

Chapter 9
Experiments on an Internal Approach to Typed
Algorithms in Analysis
Dag Normann
Department of Mathematics,
The University of Oslo,
Blindern, NO-0316 Oslo, Norway
E-mail: dnormann@math.uio.no
The chapter consists of four sections. First we discuss aspects of gener-
alized computability theory with a focus of how various approaches to
abstract computability theory relate to computational analysis. Empha-
sis is put on the distinction between internal and external algorithms.
Then we prove some old and some new results related to the typed hier-
archy of hereditarily total objects over complete and separable normed
vectorspaces, with the aim of carrying out the arguments within the
framework of Kuratowski limit spaces.
In the ﬁnal section we prove a topological consequence of an assump-
tion that the total continuous functions from one complete, separable
metric space to another is dense in the sense of domain theory. It turns
out that this assumption will have consequences for how the connected-
ness properties of the two metric spaces relate.
Contents
9.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298
9.1.1
Classical computability theory . . . . . . . . . . . . . . . . . . . . . . . 299
9.1.2
Generalizing computability theory
. . . . . . . . . . . . . . . . . . . . 299
9.1.3
Generalizing ﬁniteness
. . . . . . . . . . . . . . . . . . . . . . . . . . . 300
9.1.4
Computability at higher types . . . . . . . . . . . . . . . . . . . . . . . 302
9.2
Computational Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
9.2.1
Type two enumerability
. . . . . . . . . . . . . . . . . . . . . . . . . . 304
9.2.2
Domain representability
. . . . . . . . . . . . . . . . . . . . . . . . . . 304
9.2.3
Quotients of countably based spaces
. . . . . . . . . . . . . . . . . . . 306
9.2.4
A purely internal approach? . . . . . . . . . . . . . . . . . . . . . . . . 306
9.3
Some Typed Hierarchies of Limit Spaces . . . . . . . . . . . . . . . . . . . . . 308
9.3.1
Total versus partial functionals
. . . . . . . . . . . . . . . . . . . . . . 308
9.3.2
The problem with density
. . . . . . . . . . . . . . . . . . . . . . . . . 309
297

298
D. Normann
9.3.3
Probabilistic projections . . . . . . . . . . . . . . . . . . . . . . . . . . 310
9.4
Domain Representations and Density . . . . . . . . . . . . . . . . . . . . . . . 319
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326
9.1. Introduction
This chapter will consist of four sections. In Sections 1 and 2 we will survey
some of the history of generalized computability theory with the partial aim
of discussing the elements from generalized computability theory that may
be relevant for computational analysis.
One of the aims of this introductory part is to clarify the distinction
between internal and external approaches to computability over a mathe-
matical structure in general and over a structure appearing in analysis in
particular. The objective is, however, wider. On a general basis we will
discuss the motivations for generalizing computability theory.
In Section 3, we will investigate spaces of functionals of higher ﬁnite
types in the category of Kuratowski limit spaces, where the base types are
interpreted as complete and separable normed vector spaces. We prove a
new theorem about the topological embeddability of some of these hier-
archies into others, and give a proof of a density theorem not stated in
its present form elsewhere, but nevertheless provable using known methods
from domain theory. One important aspect of Section 3 is that we only
use concepts related to the limit space structure of the spaces at hand,
and no domain representation or other kinds of superstructure. What we
aim to learn from this is which tools may be available and needed in order
to study aspects of computability on such spaces without bringing in the
computational structure of representing spaces.
One observation we have made while this work was in progress, is that
when we try to restrict the means we can use in proofs, the results we
obtain are often slightly better. The reason is that we need to formulate
sharper theorems in order to carry out, for example, proofs by induction.
In contrast, the proofs often turn out to be simpler. As an example of
this observation, if we prove the density theorem for the Kleene–Kreisel
functionals in the traditional way, we simply get that there is a recursive
enumeration of a dense set of total functionals at every type, and to extract
further properties requires further work. If we prove the density theorem
in the setting of limit spaces, the proof is actually simpler and we get for
free how to approximate any functional by a sequence from this countable
dense subset, (see Normann [18]).
In Section 4 we consider the standard domain representation of the set
of continuous functions from one metric space to another. We show that

Experiments on an Internal Approach to Typed Algorithms in Analysis
299
if the total objects in the domain representation of X →Y is dense in the
underlying domain, then Y is what we call compactly saturated over X. This
result has no consequence for the rest of the paper, and is included partly
to prevent other researchers to look for strong density theorems based on
domain theory in a naive way, and partly because the concept of compactly
saturated may be of independent interest.
9.1.1. Classical computability theory
By classical computability theory we mean the study of the concept of com-
putability induced by Turing Machines on sets of words over a preﬁxed al-
phabet, or of any of the equivalent reformulations. Classical computability
theory is simple in the sense that the basic deﬁnitions are well understood,
but complex in the sense that it oﬀers deep results with occasionally very
hard proofs. Classical computability theory appears in many guises, the
authors’s favorites are via Kleene schemes giving an elegant proof of the
recursion theorem, and set recursion over the set HF of hereditarily ﬁnite
sets, as we consider HF to be the ultimate data-type (of ﬁnite data) inside
which all other genuine data-types live.
9.1.2. Generalizing computability theory
There are several reasons for generalizing computability theory. This was
discussed in depth by Kreisel [11], and anyone working with generalized
computability in any sense should consult [11]. One of the reasons suggested
by Kreisel is that we may ﬁnd applications to the rest of the mathematical
world and the world of science in general. Applications of metarecursion
theory to descriptive set theory will be an example of this. Another reason
is that we may learn something about the concepts used in computability
theory and which properties of these concepts we actually use by general-
izing them.
We will not give a complete historical survey of generalized computabil-
ity theory, but mention a few directions it has taken and how this may have
some impact on today’s research. As a simple example, let us consider the
set Q of rational numbers. We may view Q as constructed from N via Z or
we may view Q as a spontaneously given ﬁeld or even as an ordered ﬁeld.
In the latter case, it is well known that N is not deﬁnable over Q in the
sense of ﬁrst order logic. However, N is an inductively deﬁned substruc-
ture of Q, and then Q itself is an inductively deﬁnable substructure of Q.

300
D. Normann
Building Q from 0 and 1 and the algebraic operations as an inductively
deﬁned structure gives us the tools needed in order to perform induction,
selection, etc. In the case of Q we may even let the identity relation be
inductively deﬁned. If we accept positive induction and corresponding re-
cursion as basic elements of computability, it does not really matter if we
consider Q as constructed or given. What is to be considered as computable
or semicomputable over Q does not depend on how the elements of Q are
represented as data.
If we replace Q with its algebraic completion C(Q), i.e. we hereditarily
add solutions to all polynomial equations, the situation is diﬀerent. We of
course have an eﬀective enumeration of C(Q), i.e. a surjective map
ν : N →C(Q)
such that all algebraic operations on C(Q) have their computable counter-
parts over N. Given ν, we may even ﬁnd a computable function
sqrt : N →N
that represents a kind of square root on C(Q) in the following sense:
ν(sqrt(n)) · ν(sqrt(n)) = ν(n)
for all n ∈N. There is, however, no square root function deﬁnable over
C(Q), even if we accept higher order deﬁnitions. In order to have one we
need some kind of external representations of the objects of C(Q) and we
need to be allowed to compute on these external representations. It will of
course suﬃce to identify i = √−1, but the structure oﬀers no distinction
between i and −i. If we increase the ambition and aim at ﬁnding a function
solving polynomial equations in general, we know that we cannot hope to
do so from within.
This example illustrates in a nutshell our distinction between internal
and external concepts of computability; the internal concepts must grow
out of the structure at hand, while external concepts may be inherited from
computability over superstructures via, for example, enumerations, domain
representations, or in other ways. This distinction was ﬁrst made explicit in
Normann [15]. A similar distinction between abstract and concrete notions
of computations was discussed in Tucker and Zucker [26].
9.1.3. Generalizing ﬁniteness
The step from standard computability theory to computability in analysis
has to take the step from the discrete to the continuous, and the step

Experiments on an Internal Approach to Typed Algorithms in Analysis
301
from locally ﬁniteness to locally continuum, into account. One of the ways
computability theory was generalized was by assuming or axiomatizing that
certain inﬁnite sets share some of the properties of ﬁnite sets. Following
Kreisel [11] this helps us understand which of the properties ﬁnite sets
have that we actually make use of in, for example, degree theory.
The
question is if we have to make similar steps in order to make sense of
internal computational analysis.
The original example of this kind of generalization is metrarecursion
theory, or hyperarithmetical theory.
At ﬁrst, computable was replaced by ∆1
1 and semicomputable was re-
placed by Π1
1. This made a poor analogue of the classical theory. Then
one replaced ﬁnite with hyperarithmetic, computable with ∆1
1 on the set of
hyperarithmetical sets and semicomputable with Π1
1 on the set of hyper-
arithmetical sets.
This led in turn to α-recursion theory, β-recursion theory, computability
relative to higher type functionals, preferably normal ones, computability
over admissible structures, and to set recursion.
See Sacks [21] for an
introduction to this area, known as higher recursion theory.
The recent investigations of the so called hypercomputations, i.e. where
Turing Machines and Register Machines are allowed to work in transﬁnite
time and occasionally with transﬁnite memory stores, ﬁts well into this
tradition. We will not discuss possible motivations for this renewal of higher
recursion theory, but advise anyone wanting to enter the ﬁeld to use [11]
for the calibration of motives.
With several examples of generalized computability, one naturally
wanted to axiomatize the theory. It is worthwhile to consult the contri-
butions from Moschovakis [14] and Fenstad [6] in order to get two diﬀerent
perspectives on what a computation might be in a general setting.
The kind of generalizations we ﬁnd in higher computability theory are
too far from the classical Turing model to be of any relevance to questions
of internal computability in analysis, where we after all must have as a
requirement that there is at least one suitable digitalization of the data
at hand, and then that what is computable in an internal sense must also
be computable in the external sense. This is a soundness criterion for any
concept of computability.
We will use the expression Extended Computability Theory for the sit-
uation where our concepts try to capture genuine algorithms in a setting
going beyond the Turing world, but where we at least, through some kind
of digitalization, may reduce our concepts to the classical ones. This does

302
D. Normann
not mean that we believe that in all situations, using digitalization to deﬁne
the concept of computability is the best approach. We will return to this
discussion later.
9.1.4. Computability at higher types
One direction of generalized computability of interest to both logic and com-
puter science is the study of computations relative to continuous functionals
of higher types. The starting point was the equivalent constructions of the
typed hierarchy of hereditarily total continuous functionals by Kleene [9]
and Kreisel [10]. An extensive survey of what Kleene and Kreisel achieved,
and of the signiﬁcance of the related work of Scott [23, 24], Plotkin [20], and
Milner [13] is given in Normann [17]. Kleene and Kreisel worked with hered-
itarily total objects, i.e. with natural numbers, functions sending natural
numbers to natural numbers, continuous functionals sending such functions
to natural numbers, and so on. Kleene showed how his internal deﬁnition of
computations using the S1-S9 – schemes from Kleene [8] makes sense for the
continuous functionals. Kleene’s computations are essentially well-founded
trees, in most cases of the cardinality of the continuum. Kreisel [10] ob-
jected to Kleene’s concept for this reason, and preferred an external notion
essentially based on digitalization and Turing machines working on oracles.
The facts that all Kleene-computable functionals are Kreisel-computable,
and that all Kreisel-computable functionals of interest in [10] are Kleene-
computable, indicate that all applications of the continuous functionals one
had in mind in 1959 could be made using internal concepts. Of course, the
very deﬁnitions of the continuous functionals by the two authors involved
an element of digitalizability of the objects, and thus the external deﬁni-
tion of the computability of a continuous functional may seem the most
natural one. Later characterizations of this typed hierarchy makes internal
approaches to computations in higher types more natural, (see e.g. Nor-
mann [18]).
The Scott Model is a typed hierarchy of partial, continuous functionals,
given in the form of Scott domains. Since each domain in this hierarchy is
an eﬀective Scott domain, each domain accepts an external concept of com-
putability. The hierarchy is also the original domain for the denotational
semantics of LCF (Scott [23, 24]) and the equivalent PCF (Plotkin [20]).
We consider LCF and PCF as deﬁning internal concepts of computability
for the Scott hierarchy, but the inherited concepts for the classical Kleene-
Kreisel functionals must be considered to be external since it is based on

Experiments on an Internal Approach to Typed Algorithms in Analysis
303
a computability concept for a superstructure. When it comes to domain
representations in general, we will modify our views here to some extent
later.
Grilliot [7] showed that we sometimes, in a computable way, may decide
problems expressed with number quantiﬁers. Under certain circumstances
we may decide if a given functional F : NN →N is continuous with respect
to a given convergent sequence f = limn→∞fn from NN. We may actually
ﬁnd a term in G¨odel’s T accepting F, the sequence, its limit and a modulus
function for the sequence as inputs, and the output (when we use the full
typed hierarchy of all total functionals as the base for the denotational
semantics) will answer if F(f) = limn→∞F(fn) or not. In case of local
continuity, we may use µ-recursion to ﬁnd the modulus of the limit, and in
case of local discontinuity there is (uniformly) another T -term deﬁning the
functional 2E from the data at hand.
Here 2E is quantiﬁcation over N as the total functional of type 2:
2E(f) =
0 if ∀x ∈N(f(x) = 0)
1 if ∃x ∈N(f(x) > 0.
This must not be confused with the continuous existential quantiﬁer ∃ω
deﬁned by
∃ω(f) =
0 if
f(⊥) = 0
1 if ∃x ∈N(f(x) > 0.
We call the computational machinery originating from Grilliot [7] the
Grilliot Theory, and Grilliot theory shows that even internal concepts of
computability not aimed at generalizing what is considered to be ﬁnite to
some extent is strong enough to make quantiﬁcation over certain inﬁnite
sets computable in some sense. In [5] Escard´o explores another example of
such phenomena.
9.2. Computational Analysis
The term computational analysis covers the study of problems in math-
ematics and theoretical computer science where one is interested in the
computational content of phenomena in analysis. It is mainly an area for
foundational research, and not so practically oriented as numerical analysis.
One of the main motivations is to make computational analysis relate to
numerical analysis in the same way as classical computability theory relates
to the practical use of digital computers. With our terminology we may say

304
D. Normann
that computational analysis is classical computability theory extended to
structures appearing in analysis. This does not mean that we have to take
an external view on computational analysis and that there is only one valid
concept of computability in a given relevant context. There are at least
three levels on the scale from external to internal that will be of interest.
9.2.1. Type two enumerability
It is well known how we may extend classical computability theory to com-
putations relative to function oracles. Thus the structure (N, NN) accepts
a natural, internal concept of computability. In computational algebra it
is standard to tie a concept of computability to eﬀective enumerations of
the algebraic structure at hand. In analysis, the structures are mostly un-
countable, but often of the power of the continuum. Weihrauch suggested
that for many such structures, an eﬀective “enumeration” over a subset of
NN could be used instead. See Weihrauch [27] for the carrying out of this
approach.
Representing objects as elements of NN is essentially the one natural way
to “digitalize” the same objects, so borrowing concepts of computability
from a type two enumeration is a very external approach to computational
analysis. If the purpose is just to capture “in principle computable by a
digital computer in one way or another”, the T T E-approach is both sound
and natural. If the aim is to ﬁnd algorithms that in a natural way fall out
of the structure at hand, the T T E-approach may be of less help.
9.2.2. Domain representability
As an alternative to the T T E-approach by Weihrauch and others, repre-
sentations over eﬀective domains have been attempted as a foundation for
computational analysis. Among those initiating this approach we mention
Stoltenberg-Hansen and Tucker [25] and Edalat [2]. This approach is so gen-
eral that unless the domain in question is carefully chosen, the approach
is more or less as external as the T T E-approach. However, a carefully
chosen domain may capture a reasonable notion of “partial object” for the
structure at hand, like the objects in the Scott hierarchy does. If there is a
natural internal approach to computability for the extended set of partial
objects, then the derived notions for the original structure will be more
internal than if the T T E-approach is used.
If we go back to one of the origins of domain theory, Scott [23], the
motivation was to construct a structure that could provide denotational

Experiments on an Internal Approach to Typed Algorithms in Analysis
305
interpretations of programs or algorithmic terms of some sort. This in-
dicates that if we start with a mathematical structure that we for some
reason would like to consider as a data-type and then form a programming
language suitable for dealing with data of this kind (and not primarily with
digitalized representations of these data), then a cleverly chosen domain
representation, where the ﬁnitary objects of the domain actually represent
partial objects of the data-type in question, together with some internal
notion of computability on the representing domain reﬂecting the algebra
of the given data-type, may lead to a more ﬁne tuned and less external
approach to computability on the original data-type.
How can we judge if a domain representation is cleverly chosen, in the
sense of leading to more internal concepts than the T T E-approach? One
criterion is that if two ﬁnitary objects have extensions representing the same
original data-object, then they should have a joint extension representing
the same object. In an abstract way, this would mean that the domain
object directly approximates the data-objects, not just digitalized versions
of them. Another criterion will be that the algebra of the data-structure
has a natural extension to an algebra on the representing domain. This is,
for instance, the case for Escard´o’s Real PCF [3]. Actually, we will con-
sider real PCF as a purely internal way of deﬁning computable functions
from reals to reals, but slightly external if it is used to deﬁne, for example,
computable operators. The reason is that R is a substructure of its domain
representation, so when a real number is considered as an input of an algo-
rithm in Real PCF, it is really that number, and not some representative
for it, that is the input.
Now, why should we be interested in whether an approach is internal or
not, why not use the strongest concept of computability that makes sense
in a given context?
Our main reason is analogue to the reason why logicians should try to
prove theorems in weak systems, the weaker tools we use to obtain a result,
the more extra knowledge can be obtained from the process of obtaining the
result. We would like to claim that an internal approach to computability
in analysis will result in easy-to-use, high level, programming languages
for computing in analysis, but the development cannot support this claim
yet. The possibility of ﬁnding support for such a claim, together with basic
curiosity, is nevertheless the motivation behind trying to ﬁnd out what
internally based algorithms might look like.

306
D. Normann
9.2.3. Quotients of countably based spaces
There has been a renewed interest in the spaces that may have T T E rep-
resentations or domain representations, and in exploring the possible cate-
gories of such spaces without actually always doing it within domain theory
or over Baire space NN. qcb-spaces, quotients of countably based spaces,
forms an interesting category QCB of topological spaces. As a category,
QCB is at present too general to accept a uniform approach to internal com-
putability, but all spaces considered in this paper will be qcb-spaces or vari-
ous sorts of representations for them. This category originates from Menni
and Simpson [12], but was characterized as qcb-spaces by Schr¨oder [22],
who independently characterized them as the spaces with admissible T T E-
representations..
9.2.4. A purely internal approach?
As an example, let us consider the Banach-space l2 of functions f : N →R
such that
∞
X
i=0
(f(n))2 < ∞.
This is a normed vector space, and we may ask for the set of total and
partial functions
F : l2 →R
that may be considered to be computable.
Taking a strictly external point of view, we may construct admissible
representations of l2 and R over NN, and then consider those functions
F : l2 →R that can be lifted to partial computable functions ˆF : NN →NN.
The problem with this approach is that there is no natural structure on the
set of computable functions deﬁned this way that we can use for further
investigations.
Our approach will be quite the opposite.
We will see what can be
achieved accepting the internal structure (algebra, norm etc.)
as com-
putable, and then use general principles for creating new computable op-
erators from old ones. l2 is a separable space. If we let fn be the object in
l2 that takes the value 1 on n and 0 elsewhere, it is reasonable to consider
the sequence
{fn}n∈N

Experiments on an Internal Approach to Typed Algorithms in Analysis
307
as a part of the basis for deﬁning computability over l2. Clearly the set
of ﬁnite, rational linear combinations of the fn’s is dense in l2, and since
Q is inductively deﬁnable over R, there is a dense, internally computably
enumerable subset of l2. Moreover, all coordinate functions
n, f 7→f(n)
will be computable, since they can be calculated from fn as deﬁned above.
This again shows that the identity function, seen as a function from l2
to RN is computable. The inverse is not continuous, and should not be
computable.
In order to be able to deﬁne functions via some sort of recursive con-
structions, and at the same time make use of the fact that l2 is a topological
space, it is natural to include some natural limit process as basically com-
putable. Since we are just providing an example of how it can be done, and
not of how it has to be done, we suggest the principle developed below:
Deﬁnition 9.1.
a) Let ∆: R →[0, 1] be the projection of R to [0, 1] and for each n ∈N, let
∆n(x) = 2−n∆(2nx).
b) If u and v are distinct vectors in a normed vector space V like l2 and
n ∈N, we let
modn(u, v) = u + ∆n(||v −u||)
||v −u||
(v −u),
and we let modn(u, u) = u for all u.
c) We deﬁne modseq : V N →V N by recursion
– modseq({vn}n∈N)0 = v0
– modseq({vn}n∈N)k+1 = modk+1(modseq({vn}n∈N)k, vk+1).
We consider modn as computable uniformly in n since it is the single-valued
interpretation of the following nondeterministic algorithm:
If ||v −u|| < 2−n then modn(u, v) = u
AND
If ||v −u|| > 0 then modn(u, v) = u + ∆n(||v−u||)
||v−u||
(v −u).
The function modn(u, v) demonstrates that the 2−n-ball around u is a re-
tract of the full space, and the recursively deﬁned modseq then retracts all
sequences to a subset of uniformly converging Cauchy sequences.

308
D. Normann
The point is not that we propose to include general nondeterministic or
parallel algorithms like the one used in “computing” modn in a construc-
tion of internal computability principles for analysis, but that some basic
functions justiﬁable by the use of such or other principles may be included.
The danger is, as we learned from Escard´o, Hofmann, and Streicher [4],
that we may introduce an unwanted amount of nondeterministic processes
just by adding one basic function. They showed that including a contin-
uous extension of + to the domain representation of R into an otherwise
deterministic calculus, gives us the full power of the weak parallel or.
Remark 9.1. In this example, we have shown (the well known fact) that
for a normed vector space V , the space of Cauchy sequences converging
at least as fast as {2−n}n∈N is a retract of the space of all sequences, the
point being that we have used well known computable functions over R and
primitive recursion in combination with the internal algebra. We do not
consider the use of ∆n as being an example of external algorithms, since
we do not replace the data-objects in V with something else representing
them.
The important choice to make is which inﬁnite steps we may take in
describing internal algorithms. Our lesson from the Grilliot theory of func-
tionals in higher types will be that if we have a sequence with a known
modulus of convergence, then passing to the limit is in essence computable.
Thus, as an example, we propose to add the following principle to our
deﬁnition of internal computability over V :
LIM : V N →V
deﬁned by
LIM({vn}n∈N) = lim
k→∞{modseq({vn}n∈N)k}k∈N.
In the sequel, we are not going to propose a rigid deﬁnition of internally
computable analysis, but prove some nontrivial results using internal, in
some sense eﬀective, means only.
9.3. Some Typed Hierarchies of Limit Spaces
9.3.1. Total versus partial functionals
In this section we will consider typed hierarchies of total continuous func-
tionals where the base spaces are certain complete, separable metric spaces.
From the point of view of computational analysis it may be more natural to

Experiments on an Internal Approach to Typed Algorithms in Analysis
309
consider hereditarily partial functionals that in some way are continuous.
However, given eﬀective metric spaces as base spaces, it is a challenging
task to explore what we might mean by a functional of ﬁnite type that is
partial and hereditarily computable relative to an object of the base space.
This would involve ﬁnding the proper analogue of the sequential functionals
over N⊥for other base spaces than N. It is by no means obvious that if
a project like this is successfully carried out, then each hereditarily total
object we study in this paper will be represented by hereditarily relative
computable functionals.
Not ignoring the importance of partiality in computational analysis, our
starting point is that the structures we study are of independent interest,
and that it thus is of interest to ﬁnd internal approaches to computability
over these structures.
An eﬀective metric space is normally given as the completion of a com-
putable metric on N, and though we may consider spaces with additional
computational structure, the enumeration of the dense set and how it relates
to its completion will form one basis for how to compute internally. For
other separable topological spaces, an enumeration of a countable dense
subset and some additional structure relating the other elements to this
dense set will be a natural tool in an internal approach to computability.
In this section we will see how this infrastructure may be established for
some hierarchies of functionals.
9.3.2. The problem with density
All spaces we will consider in this section will be by default separable Haus-
dorﬀspaces, and they will be sequential spaces. The latter means that the
topology is the ﬁnest one with exactly the present set of convergent se-
quences with limits.
If X1, . . . , Xn are Polish spaces and
σ = σ(x1, . . . , xn)
is a type expression in the grammar
σ ::= x1 | · · · |xn | (σ →σ)
(where we will drop parentheses according to standard conventions) we may
interpret σ as a space σ(X1, . . . , Xn) using the category of Kuratowski limit
spaces.
Then we know that σ(X1, . . . , Xn) is a sequential, separable space. How-
ever, there is no general way of constructing a dense countable subset, even

310
D. Normann
when X1, . . . , Xn are eﬀective metric spaces. As a general problem, this
is related to understanding how the connectedness properties of the spaces
in question relate, and even how local connectedness of the domain space
relates to global connectedness of the image space. For a few cases, one has
used domain theory to obtain eﬀective density theorems. Indeed, in Sec-
tion 4 we will show that this method has major limitations unless combined
with some insight on the connectedness properties of the spaces involved.
9.3.3. Probabilistic projections
The rational numbers is a dense subset of the real numbers, so every real
can be approximated by a sequence of rationals. This fact is used in most
of the standard ways we represent reals as digitalized data objects. There
is, however no way we continuously in a real r may select a sequence of
rationals converging to r, since any such continuous selection must be con-
stant. It turns out that if we consider sequences of probability distributions
on Q with ﬁnite support instead of sequences of rationals, we may use the
sequences of probability distributions to many of the computational tasks
for which we initially would like to be able to select a convergent sequence
of rationals in a continuous way. In this section we will introduce the con-
cepts of probabilistic projections and probabilistic selection that has turned
out to be useful in this respect.
Deﬁnition 9.2. Let Y be a sequential space, let A = ∪n∈NAn be the union
of a family of ﬁnite subsets An in Y and let X ⊆Y be a subspace with
A ⊆X.
A probabilistic projection from Y to X will be a sequence of continuous
maps
y 7→µy,n,
where µy,n is a probability distribution on An, such that whenever x =
limn→∞xn, x ∈X and akn ∈An with µxn,n(akn) > 0 for each n ∈N, then
x = lim
n→∞akn.
Remark 9.2. It follows that A is dense in X.
Though our deﬁnition depends on A and its enumeration, we will only
require that there exists an A as above when we say that there is a proba-
bilistic projection from Y to X.

Experiments on an Internal Approach to Typed Algorithms in Analysis
311
Lemma 9.1. Let Y be a complete, separable metric space, A = ∪n∈NAn
an increasing union of ﬁnite subsets of Y and let X be the closure of A in
Y .
Then we may construct a probabilistic projection from Y to X.
Proof.
Let d be the metric on Y . For any y ∈Y , let d(y, An) be the
minimal distance from y to an element of An. This function is continuous
in y.
For u, v ∈R≥0 we let u ·−v = max{u −v, 0}.
This function is also continuous.
For each y ∈Y and a ∈An we let
µy,n(a) =
d(y, An) + 2−n ·−d(y, a)
P
b∈An[d(y, An) + 2−n ·−d(y, b)].
If d(y, An) = d(y, b), then
d(y, An) + 2−n ·−d(y, b) = 2−n > 0
so the denominator is positive. Thus µy,n(a) is well deﬁned.
Clearly 0 ≤µy,n(a) ≤1 and
X
a∈An
µy,n(a) = 1
by trivial calculation.
Thus µy,n is a probability distribution on An, and y 7→µy,n will be contin-
uous by construction.
It remains to prove that {An}n∈N and {y 7→µy,n}n∈N satisfy the re-
quirement of the deﬁnition.
Let x = limn→∞xn where x ∈X, each xn ∈Y and let bn ∈An such that
µxn,n(bn) > 0 for each n ∈N.
Let ǫ > 0. We will ﬁnd n0 such that if n ≥n0, then d(x, bn) < ǫ.
Let n0 satisfy the following requirements:
i) If n ≥n0 then d(x, xn) < ǫ
4.
ii) For some a ∈An0 we have that d(x, a) < ǫ
4.
iii) 2−n0 < ǫ
4.
Let n ≥n0.
Then d(x, An) < ǫ
4 by ii), so d(xn, An) < ǫ
2 by i).
Since µxn,n(bn) > 0, we have that
d(xn, bn) < ǫ
2 + 2−n < 3ǫ
4 .

312
D. Normann
Consequently, d(x, bn) < 3ǫ
4 + ǫ
4 = ǫ.
This ends the proof of the lemma.
□
We will prove a combined embedding and density theorem for hierar-
chies of limit spaces using normed vector spaces at base level. We need:
Lemma 9.2. For each n, let V be a complete, normed vector space, and
let v ∈V . For each n ∈N, let Xn ⊂V be ﬁnite, and assume that v =
limn→∞vn whenever vn ∈Xn for all n ∈N.
For each n, let µn be a probability distribution on Xn. Then
v = lim
n→∞
X
u∈Xn
µn(u) · u.
The proof is trivial.
Deﬁnition 9.3. Let X be a sequential separable Hausdorﬀspace.
We
say that X admits uniform probabilistic selection if there is a probabilistic
projection from X to X.
Deﬁnition 9.4. Let X be a metric space, and let x = limn→∞xn from X.
A probabilistic modulus of convergency for the sequence is a sequence
{νk}k∈N of probability distributions on N such that for all n, m and k
in N, if
νk(n) > 0
and n ≤m, then d(xn, x) < 2−k.
The proof of Lemma 9.1 is constructive in the following sense:
Observation 9.1. Let Y be a complete metric space, and let A = ∪n∈NAn
and X be as in Lemma 9.1.
Then, uniformly in k, we may compute a
function νk mapping x ∈X into a probability distribution νk(x) on N such
that for all n, m, k in N and all a ∈Am, if νk(x)(n) > 0, n ≤m and
µx,m(a) > 0 then d(a, x) < 2−k.
Proof.
That µx,m(a) > 0 simply means that
d(x, Am) + 2−m > d(x, a)
and this means that d(x, a) < 2−k whenever d(x, Am) < 2−(k+1) and m > k.
Let r ∈[1, ∞⟩and let r = m + λ where m ∈N and 0 ≤λ < 1.
Let
fx(r) = (1 −λ)d(x, Am) + λd(x, Am+1) + 1
r .

Experiments on an Internal Approach to Typed Algorithms in Analysis
313
Then fx is strictly decreasing with 0 as its limit value when r →∞, and
x, r 7→fx(r) is continuous. Let z = f −1
x (2−k).
Then z = n + ξ for some n ∈N and 0 ≤ξ < n.
Let νk(x)(n + 1) = 1 −ξ and νk(x)(n + 2) = ξ.
This does the trick.
□
In order to prove the combined density and embedding theorem, we
need to extend our pool of concepts.
Deﬁnition 9.5. Let X and Y be sequential separable Hausdorﬀspaces,
π : X →Y a topological embedding.
Let {An}n∈N be a family of ﬁnite subsets of X, and for each n ∈N, let
y 7→µy,n be a continuous map from Y to the set of probability distributions
on An.
a) We deﬁne the auxiliary equivalence relation ∼on Y by y ∼z when
∀n ∈N(µy,n = µz,n).
We will let X be a closed subset of Y extending the image π[X] such
that
∀y ∈X∃x ∈X(y ∼π(x)).
We call the sequence of maps y 7→µy,n a probabilistic projection with
respect to (X, π, X, Y ) if whenever y ∈X, x ∈X, y ∼π(x), y =
limn→∞yn and an ∈An such that µy,n(an) > 0 for each n ∈N, then
x = limn→∞an.
b) A control will be a continuous map y 7→hy : R≥0 →R≥0 such that
i) Each hy is strictly increasing.
ii) hy(0) = 0 for all y.
iii) If y ∈X then hy is bounded by 1
2.
iv) If y ̸∈X then hy is unbounded.
We may use the terminology and notation introduced in this deﬁnition
without explicit reference, when it is clear from the context that they apply.
Since X is Hausdorﬀ, if y ∈X there is a unique xy ∈X such that
y ∼π(xy). From now on, we will always assume that y 7→xy is continuous,
and we view this as a partial projection commuting with the embedding π.
We will apply these concepts to hierarchies of typed functionals, where
the base types will be separable, complete, normed vector spaces over R.

314
D. Normann
As an induction start, we will show that in the case of metric spaces, our
construction can be modiﬁed in order to satisfy all the extra properties.
So let X and Y be complete metric spaces, and let π : X →Y be isometric.
Then X = π[X] will be closed. Let A = ∪n∈NAn be as in the proof of
Lemma 9.1.
We modify the construction of the probability distributions to this new
situation, and we let
µy,n(a) =
dY (π[An], y) + 2−n ·−d(y, π(a))
P
b∈An dY (π[An], y) + 2−n ·−dY (y, π(b)).
We deﬁne the control
hy(r) = 1
2(1 −2−r) + r · dY (y, X).
It is easy, but tedious, to see that all properties are satisﬁed, partly based
on the proof of Lemma 9.1.
Now, in order to create an induction step, we will assume that X, Y ,
π : X →Y , {y 7→µy,n}n∈N, and y 7→hy satisfy that X and Y are
sequential Hausdorﬀspaces, π is a topological embedding, {y 7→µy,n}n∈N
is a corresponding probabilistic projection with control y 7→hy over X ⊆Y .
We will let {An}n∈N be the sequence of ﬁnite subsets of X supporting each
µy,n
Let U and V be normed, complete separable vector spaces such that U
is a closed subspace of V .
We aim to construct an embedding π+ of X →U into Y →V together
with a corresponding probability projection and control. To this end, let
v 7→δv,n be the probabilistic projection constructed above, when we see U
and V as metric spaces. Let B = ∪n∈NBn be the countable set used as the
basis for the construction of δv.n for v ∈V .
Our ﬁrst move will be to construct the embedding π+.
So let f : X →U and y ∈Y be given.
We will deﬁne π+(f)(y) separately for two cases.
Case 1. The control hy is bounded by 1
2.
Then let
π+(f)(y) = lim
n→∞
X
a∈An
µy,n(a) · f(a).
We will prove later that this is well deﬁned.
Case 2. The control hy is unbounded.

Experiments on an Internal Approach to Typed Algorithms in Analysis
315
Let zy = ny + λy be the unique real such that hy(zy) = 1, where ny ∈N
and 0 ≤λy < 1. y 7→zy is continuous when we are in this case. Let
π+(f)(y) = (1 −λy)
X
a∈Any
µy,ny · f(a) + λy
X
a∈Any+1
µy,ny+1(a) · f(a).
Claim 1. π+(f)(y) is well deﬁned.
Proof of Claim 1. This is only a problem in Case 1, where we have to
prove that the limit exists. In this case, y ∼π(x) for some x, and thus,
whenever {an}n∈N is a sequence from Q
n∈N An such that µy,n(an) > 0 for
each n, we have that x = limn→∞an, so f(x) = limn→∞f(an).
Then, using the compactness of Q
n∈N An, we see that
∀ǫ > 0∃n∀m ≥n∀a ∈Am(µy,m(a) > 0 ⇒d(f(x), f(a)) < ǫ).
Given ǫ > 0 and n as above, for m ≥n we have that
d(f(x), P
a∈Am µy,m(a) · f(a))
≤P
a∈Am d(µy,m(a) · f(x), µy,m(a) · f(a))
= P
a∈Am µy,m(a)d(f(x), f(a)) ≤ǫ,
and we are through, the limit is f(x).
Claim 2. π+ is continuous.
Proof of Claim 2. We have to prove that π+ is sequentially continuous,
so let f : X →U, fk : X →U for each k, y ∈Y and yk ∈Y for each k
such that
f = lim
k→∞fk
and
y = lim
k→∞yk.
We must show that π+(f)(y) = limk→∞π+(fk)(yk).
If y ̸∈X, then for suﬃciently large k we have that yk ̸∈X, and in
this case it is easily seen that the construction is continuous. It is actually
computable by construction.
So assume that y ∈X. Then by assumption, if ak ∈Ak with µyk,k(ak) >
0 for each k, then x = limk→∞ak.
Since f = limk→∞fk we have that
f(x) = lim
k→∞fk(ak)

316
D. Normann
under the same assumptions, where x ∈X is the unique object such that
π(x) ∼y. Then, using the same argument we used to show that π+(f)(y)
is well deﬁned for y ∈X, we have that
π+(f)(y) = f(x) = lim
k→∞
X
a∈Ak
µyk,k(a) · fk(a).
Since the sequences {yk}k∈N and {fk}k∈N are arbitrary, it also holds that
π+(f)(y) = lim
n→∞
X
a∈An
µykn,n(a) · fkn(a)
when n 7→kn is increasing and unbounded, but not necessarily strictly
increasing.
By this remark, it is suﬃcient to prove that
π+(f)(y) = lim
k→∞π+(fk)(yk)
for the two cases where all yk are in X and where none of them are in X.
In the ﬁrst case, we use that
π+(fk)(yk) = lim
n→∞
X
a∈An
µyk,n(a) · fk(a)
for each k. We let n1 be such that
d(
X
a∈Am
µy1,m(a) · f1(a), π+(f1)(y1)) < 1
2
for all m ≥n1.
Then we let n2 > n1 be such that
d(
X
a∈Am
µy2,m(a) · f2(a), π+(f2)(y2)) < 1
4
for all m ≥n2, and so on.
We then slow down the sequence {k}k∈N to the sequence {ki}i∈N by letting
it be 1 until i = n1, then letting it be 2 until i = n2 and so on. Then
π+(f)(y) = lim
i→∞
X
a∈Ai
µyki,i(a) · fki(a) = lim
k→∞π+(fk)(yk)
by construction.
In the second case, we just make use of the fact that
lim
k→∞zyk = ∞
and the result follows from the limit space property.

Experiments on an Internal Approach to Typed Algorithms in Analysis
317
This ends the construction of π+ and the proof of its continuity, i.e. the
proof of Claim 2.
Now, let X →U = {g : Y →V | ∀a ∈A(g(π(a)) ∈U)}.
Then of course ∀x ∈X(g(π(x)) ∈U) when g ∈X →U, and g may be
projected to
λx ∈Xg(π(x)) ∈X →U.
We must wait for the deﬁnition of the probabilistic projection before making
further sense of this.
Our control will be
hg(n+λ) = (1−λ)·
n
X
i=0
d(g(π(ai)), U)+λ·
n+1
X
i=0
d(g(π(ai)), U)+ 1
2(1−2−(n+λ))
when g : Y →V is continuous.
We will now construct the ﬁnite sets supporting the probabilistic pro-
jection and prove the required properties.
Recall that {An} and {Bn}n∈N are the supports of the probabilistic pro-
jections of Y to X and of V to U resp.
Let C∗
n = An →Bn, and let φ ∈C∗
n.
Let fφ : X →U be deﬁned by
fφ(x) =
X
a∈An
µπ(x),n(a) · φ(a).
Let Cn = {fφ | φ ∈C∗
n}.
Now we will deﬁne the probabilistic projection µ+:
Let g : Y →V and let fφ ∈C∗
n. Let
µ+
g,n(fφ) =
Y
a∈An
δg(π(a)),n(f(a)).
Since we construct µ+ using products of probability distributions, µ+
g,n is
itself a probability distribution.
Clearly, if g ∈X →U, then
g ∼π+(λx ∈X.g(π(x)))
since these two functions will be identical on X, and then in particular on
the π-image of A.
So assume that g ∈X →U and that g = limn→∞gn.

318
D. Normann
Assume further that µ+
gn,n(fφn) > 0 for each n.
We must show that
λx ∈X.g(π(x)) = lim
n→∞fφn.
Let x ∈X and x = limn→∞xn. We must show that
(∗)
g(π(x)) = lim
n→∞fφn(xn).
We have that
fφn(xn) =
X
a∈An
µπ(xn),n(a) · φn(a).
Let an ∈An for each n ∈N.
Then, since µ+
gn,n(fφn) > 0 we must have that
δgn(π(an)),n(φn(an)) > 0
since the product probability would be zero otherwise.
Now, let us restrict ourselves to the sequences {an}n∈N such that for all
n we have that µxn,n(an) > 0.
Then x = limn→∞an by assumption, so
g(π(x)) = lim
n→∞gn(π(an)).
But then g(π(x)) = limn→∞φn(an) since φn has positive gn(π(an))-
probability for each n.
Then we ﬁnally apply Lemma 9.2 to see that (∗) holds.
We have now established the base case and the induction step needed to
prove the following theorem:
Theorem 9.1. Let U1, . . . , Un be complete and separable normed vector
spaces that are subspaces of one space V . Let σ be a type term in the type
variables u1, . . . , un and let σ(U1, . . . , Un) be the canonical interpretation in
the category of limit spaces.
a) Each space σ(U1, . . . , Un) contains a dense countable set admitting prob-
abilistic selection.
b) There are topological embeddings of σ(U1, . . . , Un) into σ(V, . . . , V ) com-
muting with application and admitting probabilistic projections.
Remark 9.3. Adding some notational details, we might include N in the
set of base types. Then this theorem generalizes one of the theorems in [16].
In addition to be a generalization, the proof is carried out in the setting

Experiments on an Internal Approach to Typed Algorithms in Analysis
319
of limit spaces only, not using domain theory as we did in [16]. In many
respects, we view the method of proof as important as the result itself.
9.4. Domain Representations and Density
When one works with an external notion of computability, i.e. transfers
the notion from some representing structure, it is natural to try to estab-
lish results about how the representing structure relates to the space in
question. One example is representations by domains and density theo-
rems. In its simplest form, a density theorem states that the representing
objects are dense in the underlying domain. In this section we will show
that a density theorem for the standard domain representation of the set of
continuous functions from one separable metric space to another will have
strong implications.
There are certainly cases where we have an eﬀective enumeration of a
dense set, but where the canonical domain representation does not satisfy
density. One lesson to learn is that the internal approach to density implicit
in Section 3 may be as useful as using external approaches. By the way, all
constructions in this section must be considered as extensional.
Deﬁnition 9.6. Let X and Y be topological spaces.
We say that Y is compactly saturated over X if whenever C ⊆E are compact
subsets of X and g : C →Y is continuous, then g can be extended to a
continuous f : E →Y .
Remark 9.4. This property indicates that Y in some sense is globally as
connected as X will be locally. What this means more precisely remains
to be explored, but, for example, if there is a nontrivial path in X, then Y
will be path connected. Similar phenomena for higher dimensions indicate
that “local lack of multidimensional holes” in X implies the corresponding
global lack of holes in Y .
In this section we will show that if X and Y are two separable complete
metric spaces with domain representations DX and DY in the style of
Blanck [1], and the total objects are dense in the domain DX →DY , then
Y is compactly saturated over X.
We have to introduce some terminology:
Let ⟨X, dX⟩and ⟨Y, dY ⟩be the two spaces.
Let {ξX
k }k∈N and {ξY
l }l∈N be preﬁxed enumerations of dense subsets of X
and Y resp.

320
D. Normann
For r ∈Q+, let BX
k,r and BY
l,r be the open balls around ξX
k and ξY
l
resp.
with radius r. Let B
X
k,r and B
Y
l,r be the corresponding closed balls.
The ﬁnitary objects in the domain representation used by Blanck [1] will be
ﬁnite sets of such closed balls such that the distance between two centers
do not exceed the sum of the corresponding radii. Thus we use ﬁnite sets
of closed balls such that it is consistent that the intersection is nonempty.
One ﬁnite set {B1, . . . , Bn} is below another set {B′
1, . . . , B′
m} in the do-
main ordering if each B′
i is formally the subset of some Bj, formally by
comparing the radii and the distances between the centers.
The domains used are then the ideal completion of this ordering, and an
ideal represents an element x of X (or Y ) if x is an element of all closed
balls of the ideal, and any open ball around x contains at least all closed
ball in one of the elements of the ideal. The total ideals will be those rep-
resenting elements in X or Y , and an object in the domain DX →DY is
total if it maps total ideals to total ideals.
Theorem 9.2. With the terminology above, if the total objects are dense
in DX →DY , then Y is compactly saturated over X.
We will prove the theorem in several steps. Let C ⊆E and g : C →Y be
as in the deﬁnition of compactly saturated. The rough idea is to use the
density property to construct a sequence of continuous maps fn : X →Y
such that limn→∞fn(x) exists on E and will be a continuous extension of
g to E.
Let {BX
k }k∈N and {BY
l }l∈N be enumerations of the two chosen bases for
X and Y , using ik, rk and jl, sl to denote the index of the center and the
radius of each ball.
Throughout, we will let D = g[C], the image of C under g. D is a compact
subset of Y .
We will ﬁrst construct a set G of pairs of natural numbers such that
{⟨B
X
k , B
Y
l ⟩| ⟨k, l⟩∈G}
generates an ideal approximating g.
By recursion, we will deﬁne the ﬁnite set Gn and the real δn > 0.
We will refer to Gn and to δn in the main construction. In the construction
of the sequence of Gns, we will also deﬁne the auxiliary ∆n ⊆N, and some
other entities only needed in order to explain the recursion step.
Let G0 = ∅, δ0 = 1 and ∆0 = ∅.
Assume that Gn, δn and ∆n are constructed.

Experiments on an Internal Approach to Typed Algorithms in Analysis
321
First, let ∆n+1 ⊆N be a ﬁnite set such that {BY
l | l ∈∆n+1} is and open
covering of D and such that sl < 2−n whenever l ∈∆n+1.
Let Πn+1 = {g−1(B
Y
l ) | l ∈∆n+1}.
If A, B ∈Πn+1 and A ∩B = ∅, then dX(A, B) > 0, since the sets A and B
are closed subsets of C, and thus compact.
If A ∈Πn+1 and B = B
X
k for some ⟨k, l⟩∈Gn and ∀x ∈A(dX(x, ξX
ik ) > rk),
then
inf{dX(x, ξX
ik ) −rk | x ∈A} > 0.
This is because A is compact. We call the latter number the formal distance
from A to B
X
k .
Let πn+1 be the least of the distances between disjoint elements of Πn+1
and the formal distances between an element of Πn+1 and a closed ball B
X
k
for some ⟨k, l⟩∈Gn as above.
Let Γn+1 ⊂N be a ﬁnite set such that
If k ∈Γn+1, then rk < min{ πn+1
4
, δn
4 }.
If k ∈Γn+1, then BX
k ∩C ̸= ∅
{BX
k | k ∈Γn+1} is an open covering of C.
If k ∈Γn+1, then B
X
k ∩C ⊆g−1(B
Y
l ) for some l ∈∆n+1.
The compactness of C and the fact that {g−1(BY
l ) | l ∈∆n+1} is an open
covering of C ensures that there exists a set Γn+1 like this.
We now let ⟨k, l⟩∈Gn+1 if k ∈Γn+1, l ∈∆n+1 and B
X
k ∩C ⊆g−1(B
Y
l ).
We let
δn+1 = dX(C, X \
[
{BX
k | k ∈Γn+1}).
By construction, 0 < δn+1 ≤δn
4 .
Let G = ∪n∈NGn.
Let ˆGn = {⟨B
X
k , B
Y
l ⟩| ⟨k, l⟩∈Gn} and let ˆG = ∪n∈N ˆGn.
Claim 1. Each ˆGn is a consistent set.
Proof of Claim 1. Let ⟨k, l⟩and ⟨k′, l′⟩be in Gn such that
dX(ξX
ik , ξX
ik′ ) ≤rk + rk′.
This is the formal consistency requirement on {B
X
k , B
X
k′}.
Since B
X
k ∩C is nonempty and contained in g−1(B
Y
l ) ∈Πn+1 and B
X
k′ ∩C

322
D. Normann
is nonempty and contained in g−1(B
Y
l′ ), there is x ∈g−1(B
Y
l ) and x′ ∈
g−1(B
Y
l′ ) with
dX(x, x′) ≤2rk + 2rk′ < πn+1.
Then, by choice of πn+1, we have that
g−1(B
Y
l ) ∩g−1(B
Y
l′ ) ̸= ∅,
and
B
Y
l ∩B
Y
l′ ∩D ̸= ∅.
Then
dY (ξY
kl, ξY
kl′ ) ≤sl + sl′,
which is the consistency requirement for {B
Y
l , B
Y
l′ }.
Thus the right hand sides of two pairs in ˆGn are consistent when the left
hand sides are consistent. Thus ˆGn is consistent, and Claim 1 is proved.
Claim 2. ˆG is consistent.
Proof of Claim 2. Let ⟨B
X
k , B
Y
l ⟩∈ˆGn and ⟨B
X
k′, B
Y
l′ ⟩∈ˆGm with m < n
and assume that
dX(ξX
ik , ξX
ik′ ) ≤rk + rk′.
Then we can argue in analogy with the proof of Claim 1 that there will be
an
x ∈g−1(B
Y
l ) ∩B
X
k′.
Since x ∈g−1(B
Y
l ) and x ∈B
X
k′ ∩C ⊆g−1(B
Y
l′ ) we have that
B
Y
l ∩B
Y
l′ ̸= ∅,
so
dY (ξY
jl , ξY
jl′ ) ≤sl + sl′.
This ends the proof of Claim 2.
By construction, each ˆGn is an approximation to g where ˆGn “decides”
the value of g(x) up to a precision of 2−n. Thus ˆG will generate an ideal
representing g.
The reason why we use tiny left hand sides as well is that we want to
have some freedom in adjusting the construction of the extension f of g
close to C.

Experiments on an Internal Approach to Typed Algorithms in Analysis
323
We will now give the main construction. For each ﬁnitary p : DX →DY ,
i.e. ﬁnite consistent sets of pairs of closed balls, we let fp be a continuous,
total extension.
We will construct a sequence {pn}n∈N of ﬁnitary objects, and we will let
fn = fpn.
pn will satisfy that ∪i≤n ˆGn ⊑pn, which will ensure that we construct some
extension of g.
For each n, let
Cn = {x ∈X | dX(x, C) < δn}
and let En = E \ Cn. Let p0 = ∅and f0 = fp0.
Assume that pn and fn are constructed, with ∪i≤n ˆGi ⊆pn.
Let
Yn =
[
{fi[E] | i ≤n}.
Then Yn ⊆Y is a compact set.
First, let kn be minimal such that
Kn = {BY
l | l ≤kn ∧sl ≤2−n}
is an open covering of Yn. Clearly n ≤m ⇒kn ≤km.
Let Ln consist of all nonempty sets f −1
n (B
Y
l ) ∩En for l ≤kn. Let εn be
the least element in the set consisting of δn, all distances between disjoint
elements of Ln and all formal distances between disjoint elements of Ln
and sets B
X
k for some ⟨k, l⟩∈S
i≤n Gi.
Let mn be the least number such that
Mn = {BX
k | k ≤mn ∧rk < εn
4 }
contains an open covering of each A ∈Ln.
We then let pn+1 consist of ∪i≤n+1 ˆGi together with the set p′
n+1 of all
pairs ⟨B
X
k , B
Y
l ⟩such that l ≤kn, B
X
k ∈Mn and
B
X
k ∩f −1
n (B
Y
l ) ∩En ̸= ∅.
Claim 3. pn+1 is a consistent set.
Proof of Claim 3. We have to prove that p′
n+1 is consistent with itself,
with ˆGn+1 and with ∪i≤n ˆGi.
Let ⟨B
X
k , B
Y
l ⟩and ⟨B
X
k′, B
Y
l′ ⟩be elements of p′
n+1 such that
dX(ξX
ik , ξX
ik′ ) ≤rk + rk′.

324
D. Normann
Let x ∈B
X
k ∩f −1
n (B
Y
l ) ∩En and x′ ∈B
X
k′ ∩f −1
n (B
Y
l′ ) ∩En.
Then dX(x, x′) ≤2rk + 2rk′ < εn.
Thus f −n
n (B
Y
l ) ∩En and f −1
n (B
Y
l′ ) ∩En intersect, so B
Y
l ∩B
Y
l′ ̸= ∅. Then
dY (ξY
jl , ξY
jl′ ) ≤sl + sl′.
This shows that p′
n+1 is consistent.
Now, let ⟨B
X
k , B
Y
l ⟩∈ˆGn+1 and ⟨B
X
k′, B
Y
l′ ⟩∈p′
n+1.
Since B
X
k′ ∩C ̸= ∅and B
X
k′ ∩En ̸= ∅and they both have radii ≤εn
4 ≤δn
4
the set B
X
k and B
X
k′ must be formally disjoint, since we do not leap over
the half distance between C and En in any of these balls.
Finally, let ⟨B
X
k , B
Y
l ⟩∈ˆGi for some i ≤n and ⟨B
X
k′, B
Y
l′ ⟩∈p′
n+1, and
assume that
dX(ξX
ik , ξik′ ) ≤rk + rk′.
Now
A = f −1
n (B
Y
l′ ) ∩En ∈Ln,
and since the distance between ξX
ik and A is bounded by rk +2rk′ < rk +εn,
the formal distance between A and B
X
k is < εn Then A ∩B
X
k ̸= ∅.
Let x ∈A ∩B
X
k .
Since ⟨B
X
k , B
Y
l ⟩∈
ˆGi ⊆pn, we will have that f(x) ∈B
Y
l ∩B
Y
l′ , so
dY (ξY
jl , ξY
jl′ ) ≤sl + sl′.
This ends the proof of Claim 3.
Claim 4. Let ⟨B
X
k , B
Y
l ⟩∈pn and let m ≥n.
a) If ⟨B
X
k , B
Y
l ⟩∈∪i≤nGn then
B
X
k ⊆f −1
m (B
Y
l ).
b) If ⟨B
X
k , B
Y
l ⟩∈p′
n, then
B
X
k ∩En ⊆f −1
m (B
Y
l ).
Proof of Claim 4. a) is trivial since ⟨B
X
k , B
Y
l ⟩∈pm for m ≥n.
b) is proved by induction on m ≥n where the base case n = m is trivial.
So let x ∈B
X
k ∩En and assume as an induction hypothesis that fm(x) ∈B
Y
l
where l ≤kn.

Experiments on an Internal Approach to Typed Algorithms in Analysis
325
We will show that fm+1(x) ∈B
Y
l .
We have that l ≤km, so
f −1
m (B
Y
l ) ∩Em ∈Lm
with
x ∈f −1
m (B
Y
l ) ∩Em.
Then there will be a B
X
k′ ∈Mm such that x ∈BX
k′ .
Then ⟨B
X
k′, B
Y
l ⟩∈pm+1, and consequently fm+1(x) ∈B
Y
l .
This ends the proof of Claim 4.
Claim 5. For each x ∈E, limn→∞fn(x) exists.
Proof of Claim 5. We split the argument into two cases.
If x ∈C, then g(x) = limn→∞ˆGn(x) (in the sense of domains), and
ˆGn(x) ⊑fn(x) for each n, so
g(x) = lim
n→∞fn(x).
If x ∈E \ C, let ǫ > 0 be given. We choose n so large that 2−n < ǫ and
x ∈En.
Then fn(x) ∈Yn and we pick one BY
l ∈Kn such that fn(x) ∈BY
l .
Then x ∈f −1
n (B
Y
l ) ∩En ∈Ln and then there is a BX
k ∈Mn such that
x ∈BX
k .
By construction then
⟨B
X
k , B
Y
l ⟩∈p′
n+1.
By Claim 4b), fm(x) ∈B
Y
l for all m ≥n.
This shows that {fn(x)}n∈N is a Cauchy sequence, so the limit exists.
This ends the proof of Claim 5.
Let f(x) = limn→∞fn(x).
Claim 6. f is continuous on E.
Proof of Claim 6. Let x ∈E and ǫ > 0 be given.
If x ∈C, choose n so large that 2−n < ǫ.
By construction of ˆGn there will be a pair ⟨B
X
k , B
Y
l ⟩∈ˆGn+1 such that x
is in the interior of B
X
k .
By Claim 4a) we have that f(y) ∈B
Y
l whenever y ∈B
X
k .
Thus, if δ > 0 is so small that the open δ-ball around x is contained in B
X
k ,
and then dY (f(x), f(y)) ≤2−n < ǫ. This shows continuity in this case.

326
D. Normann
If x ∈E \ C we in addition choose n such that x ∈En.
We then use p′
n+1 to the same eﬀect as we used ˆGn+1 above, now applying
Claim 4b).
This ends the proof of Claim 6 and the theorem.
Concluding remarks
This chapter can be seen as part two of a trilogy, where [18] is the ﬁrst part.
The third part is still in preparation a. There we will use external methods
combined with the probabilistic approach in order to learn more about the
typed hierarchy of total functionals over separable complete metric spaces
in general.
Acknowledgements
I am grateful to the anonymous referee for helpful suggestions on the ex-
position, and for pointing out several typos in the original manuscript.
References
[1] J. Blanck, Domain representability of metric spaces, Ann. Pure Appl. Logic.
8, 225–247, (1997).
[2] A. Edalat and P. S¨underhauf, A domain-theoretic approach to real number
computation, Theoret. Comput. Sci. 210, 73–98, (1998).
[3] M. H. Escard´o, PCF extended with real numbers, Theoret. Comput. Sci.
162(1), 79–115, (1996).
[4] M. H. Escard´o, M. Hofmann, and T. Streicher, On the non-sequential na-
ture of the interval-domain model of exact real number computation, Math.
Structures Comput. Sci. 14(6), 803–817, (2004).
[5] M. H. Escard´o, Exhaustible sets in higher-type computation, Logical Meth-
ods in Computer Science. 4(3), paper 3, (2008).
[6] J. E. Fenstad, General Recursion Theory. An Axiomatic Approach. Springer-
Verlag, Berlin–Heidelberg, (1980).
[7] T. Grilliot, On eﬀectively discontinuous type-2 objects, J. Symbolic Logic.
36, 245–248, (1971).
[8] S. C. Kleene, Recursive functionals and quantiﬁers of ﬁnite types I, Trans.
Amer. Math. Soc. 91, 1–52, (1959).
[9] S. C. Kleene. Countable functionals. In ed., A. Heyting, Constructivity in
Mathematics, pp. 81–100. North-Holland, Amsterdam, (1959).
[10] G. Kreisel. Interpretation of analysis by means of functionals of ﬁnite type. In
ed. A. Heyting, Constructivity in Mathematics, pp. 101–128. North-Holland,
(1959).
aAdded in proof. The third part has now appeared in [19].

Experiments on an Internal Approach to Typed Algorithms in Analysis
327
[11] G. Kreisel. Some reasons for generalizing recursion theory. In eds. R. O.
Gandy and C. E. M. Yates, Logic Colloquium 1969, pp. 139–198. North-
Holland, Amsterdam, (1971).
[12] M. Menni and A. Simpson, The largest topological subcategory of countably-
based equilogical spaces, Electr. Notes Theor. Comput. Sci. (1999).
[13] R. Milner, Fully abstract models for typed λ-calculi, Theoret. Comput. Sci.
4, 1–22, (1977).
[14] Y. N. Moschovakis. Axioms for computation theories - ﬁrst draft. In eds.,
R. O. Gandy and C. E. M. Yates, Logic Colloquium 1969, pp. 199–255.
North-Holland, Amsterdam, (1971).
[15] D. Normann. External and internal algorithms on the continuous functionals.
In ed., G. Metakides, Patras Logic Symposion, pp. 137–144. North-Holland,
Amsterdam, (1982).
[16] D.
Normann,
Comparing
hierarchies
of
total
functionals,
Logical
Methods
in
Computer
Science.
1(2),
paper
4,
(2005).
Available
at:
http://www.lmcs-online.org/ojs/viewarticle.php?id=95&layout=
abstract [Accessed October 2010]
[17] D. Normann, Computing with functionals – computability theory or com-
puter science?, Bull. Symbolic Logic. 12(1), 43–59, (2006).
[18] D. Normann. Internal density theorems for hierarchies of continuous func-
tionals. In CiE 2008: Proceedings of the 4th conference on Computability in
Europe (Athens, Greece), pp. 467–475. Springer-Verlag, Berlin–Heidelberg,
(2008).
[19] D. Normann, A rich hierarchy of functionals of ﬁnite types, Logical Methods
in Computer Science. 5(3), paper 11, (2009).
[20] G. Plotkin, LCF considered as a programming language, Theoret. Comput.
Sci. 5, 223–255, (1977).
[21] G. E. Sacks, Higher Recursion Theory. Springer-Verlag, Berlin–Heidelberg,
(1990).
[22] M. Schr¨oder. Admissible representations of limit spaces. In eds., J. Blanck,
V. Brattka, P. Hertling, and K. Weihrauch, Computability and Complexity
in Analysis, vol. 237, pp. 369–388. Informatik Berichte, volume 237, (2000).
[23] D. Scott. A type-theoretical alternative to ISWIM, CUCH, OWHY. Unpub-
lished notes. Oxford, (1969).
[24] D. Scott, A type-theoretical alternative to ISWIM, CUCH, OWHY, Theoret.
Comput. Sci. 121, 411–440, (1993).
[25] V. Stoltenberg-Hansen and J. V. Tucker, Complete local rings as domains,
J. Symbolic Logic. 53, 603–624, (1988).
[26] J. V. Tucker and J. I. Zucker, Abstract versus concrete computation on
metric partial algebras, ACM Transactions on Computational Logic. 5, 611–
668, (2004).
[27] K. Weihrauch, Computable analysis. Texts in Theoretical Computer Science,
Springer Verlag, Berlin–Heidelberg, (2000).

This page intentionally left blank
This page intentionally left blank

Chapter 10
Recursive Functions: An Archeological Look
Piergiorgio Odifreddi
Dipartimento di Matematica
Universit`a degli Studi di Torino
10123, Torino, Italy
E-mail: piergiorgio.odifreddi@gmail.com
Contents
10.1 Types of Recursion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330
10.1.1 Iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330
10.1.2 Primitive recursion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
10.1.3 Primitive recursion with parameters
. . . . . . . . . . . . . . . . . . . 333
10.1.4 Course-of-value recursion . . . . . . . . . . . . . . . . . . . . . . . . . . 334
10.2 The First Recursion Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . 336
10.2.1 Diﬀerentiable functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 338
10.2.2 Contractions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
10.2.3 Continuous functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 340
10.3 The Second Recursion Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . 342
10.3.1 The diagonal method . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343
10.3.2 The diagonal
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
10.3.3 The switching function . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
10.3.4 Selfreference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348
First of all, a disclaimer. I am not a historian. My interest in the devel-
opment of Recursion Theory is not academic, but cultural. I want to know
if and how the basic ideas and methods used in a restricted area of Logic
derive from, or at least interact with, a wider mathematical and intellectual
experience. I can only oﬀer suggestions, not scholarly arguments, to those
who share my interest.
For convenience, I refer to my book Classical Recursion Theory (see [19,
20]), CRT for short, for unexplained notation, references, and background.
329

330
P. Odifreddi
10.1. Types of Recursion
The recursive functions take their name from the process of “recurrence” or
“recursion”, which in its most general numerical form consists in deﬁning
the value of a function by using other values of the same function. There
are many diﬀerent types of recursions, and among them the following are
perhaps the most basic:
10.1.1. Iteration
The simplest type of recursion occurs when a given function is iterated.
Technically, the n-th iteration of a function f is deﬁned as follows:
f (0)(x) = x
f (n+1)(x) = f(f (n)(x)).
The ﬁrst clause is needed to obtain f (1)(x) = f(x) from the second clause.
One of the earliest examples of iteration comes from the Rhind Papyrus,
written about 1700 B.C., which gives as Problem 79 the following:
In each of 7 houses are 7 cats; each cat kills 7 mice; each mouse would
have eaten 7 ears of spelt (wheat); each ear of spelt would have produced 7
hekat (half a peck) of grain. How much grain is saved by the 7 house cats?
The solution amounts to computing the sixth term of a geometrical pro-
gression with ﬁrst term 1 and multiplier 7, i.e. f (6)(7), with f(x) = 7x.
The papyrus gives not only the correct answer (16,807), but also the sum
of the ﬁrst ﬁve terms of the progression (19,607).
A similar use of a geometrical progression comes from a medieval story
about the origin of chess:
According to an old tale, the Grand Vizier Sissa Ben Dahir was granted
a boon for having invented chess for the Indian King, Shirham.
Sissa addressed the King: “Majesty, give me a grain of wheat to place
on the ﬁrst square of the board, and two grains of wheat to place on the
second square, and four grains of wheat to place on the third, and eight
grains of wheat to place on the fourth, and so on. Oh, King, let me cover
each of the 64 squares of the board.”
“And is that all you wish, Sissa, you fool?”
exclaimed the astonished
King.
“Oh, Sire,” Sissa replied, “I have asked for more wheat than you have in
your entire kingdom. Nay, for more wheat that there is in the whole world,
truly, for enough to cover the whole surface of the earth to the depth of
the twentieth part of a cubit.”a
aReported in Newman [18].

Recursive Functions: An Archeological Look
331
Some version of the story was known to Dante, since he refers to it in the
Paradiso (xxviii, 92–93) to describe the abundance of Heaven’s lights:
eran tante, che ’l numero loro
pi`u che ’l doppiar degli scacchi s’immilla.
They were so many, that their number
piles up faster than the chessboard doubling.
As in the previous Egyptian problem, the solution amounts to computing
the sum of the ﬁrst 64 terms of a geometrical progression with ﬁrst term 1
and multiplier 2, i.e.
1 + 2 + 22 + · · · + 263 = 264 −1
= 18, 446, 744, 073, 709, 551, 615.
Coming closer to our times, an interesting use of iteration was made
by Church [6] in the Lambda Calculus, which he had concocted as an al-
ternative foundation for mathematics based on the notion of function and
application, as opposed to set and membership. Church’s idea was to rep-
resent the natural number n in the Lambda Calculus as the binary operator
n that, when applied to the arguments f and x, produces the n-th iteration
f (n)(x).
Apparently unnoticed by Church, the same idea had been proposed
earlier by Wittgenstein [35], as follows:
6.02 And this is how we arrive at numbers. I give the following deﬁnitions
x = Ω0′x
Def.,
Ω′Ων ′x = Ων+1′ Def.
So, in accordance with these rules, which deal with signs, we write the
series
x,
Ω′x,
Ω′Ω′x,
Ω′Ω′Ω′x,
. . .
in the following way
Ω0′x,
Ω0+1′x,
Ω0+1+1′x,
. . .
[· · · ] And I give the following deﬁnitions
0 + 1 = 1 Def.,
0 + 1 + 1 = 2 Def.,
0 + 1 + 1 + 1 = 3 Def.,
(and so on)

332
P. Odifreddi
6.021 A number is the exponent of an operation.
Even earlier, Peano [23] had suggested the same idea:
Then, if b is an N, by aαb we want to indicate what is obtained by exe-
cuting the operation α on a, b times in a row. Hence, if a is a number,
a + b represents what is obtained by executing b times on a the operation
+, that is the successor of a of order b, i.e. the sum of a and b. [· · · ]
If a and b indicate two numbers, by their product a × b we will mean what
is obtained by executing b times on 0 the operation +a. [· · · ]
If a and b indicate two numbers, by ab we will mean what is obtained by
executing b times on 1 the operation ×a.
Thus Peano, like Church but unlike Wittgenstein, saw that the deﬁnition
of the numbers as iterators gives for free the representability of a number
of functions obtained by iteration.
10.1.2. Primitive recursion
Primitive recursion is a procedure that deﬁnes the value of a function at an
argument n by using its value at the previous argument n −1 (see CRT,
I.1.3).
Iteration is obviously a special case of primitive recursion, on the number
of iterations. And so is the predecessor function, deﬁned by
pd(n) =
0
if n = 0 or n = 1
pd(n −1) + 1 otherwise.
It is not immediate that the predecessor function can be reduced to an itera-
tion, and hence is representable in the Lambda Calculus. It was Kleene [11]
who saw how to do this, apparently during a visit to the dentist. Basically,
pd(n) is the second component of the n-th iteration of the function on pairs
deﬁned as
f((x, y)) = (x + 1, x),
started on (0, 0).
More generally, it is possible to prove that any primitive recursion can be
reduced to an iteration, in the presence of a coding and decoding mechanism
(see CRT, I.5.10). This implies that all primitive recursive functions are
actually representable in the Lambda Calculus, as proved by Kleene [12].

Recursive Functions: An Archeological Look
333
10.1.3. Primitive recursion with parameters
When deﬁning a function of many variables by primitive recursion, all vari-
ables except one are kept ﬁxed. Primitive recursion with parameters relaxes
this condition, and it allows substitutions for these variables. Although ap-
parently more general, this notion actually turns out to be reducible to the
usual primitive recursion (see CRT, VIII.8.3.a).
One ancient example of a primitive recursion with parameters is the
solution to the old problem known as the Towers of Hanoi or the Towers
of Brahma:
In the great temple of Benares, beneath the dome which marks the centre
of the world, rests a brass-plate in which are ﬁxed three diamond needles,
each a cubit high and as thick as the body of a bee. On one of these needles,
at the creation, God placed sixty-four disks of pure gold, the largest disk
resting on the brass plate, and the others getting smaller and smaller up to
the top one. This is the Tower of Brahma. Day and night unceasingly the
priests transfer the disks from one diamond needle to another according
to the ﬁxed and immutable laws of Brahma, which require that the priest
must not move more than one disk at a time and that he must place this
disk on a needle so that there is no smaller disk below it. When the sixty-
four disks shall have been thus transferred from the needle on which at the
creation God placed them to one of the other needles, tower, temple, and
Brahmins alike will crumble into dust, and with a thunderclap the world
will vanish.b
The natural recursive solution is the following: to move n disks from needle
A to needle C, ﬁrst move n−1 disks from needle A to needle B, then move
one disk from needle A to needle C, and then move n −1 disks from needle
B to needle C. More concisely:
move(n, A, C) = move(n −1, A, B) ∧move(1, A, C) ∧move(n −1, B, C).
Notice the use of move(n −1, A, B) and move(n −1, B, C), as opposed to
move(n −1, A, C), in the computation of move(n, A, C), which makes this
a primitive recursion with parameters (the value move(1, A, C) does not
count, being constant).
If we let f(n) be the number of moves needed for n disks provided by
the previous solution, then
f(1) = 0
f(n + 1) = 1 + 2f(n),
i.e.
f(n) = 1 + 2 + 22 + · · · + 2n−1 = 2n −1,
bReported in Rouse Ball [27].

334
P. Odifreddi
and it is known that this is the least possible number of moves needed
to solve the problem. In particular, according to the previous story, the
doomsday will be reached after 264−1 moves, i.e. the same number provided
by the chessboard problem. If one correct move is made every second, for
24 hours a day and 365 days a year, the time required for the completion
of the task would be of approximately 58 billion centuries.
10.1.4. Course-of-value recursion
When deﬁning by primitive recursion a function at a given argument, only
the value for the immediately preceeding argument can be used. Course-of-
value recursion relaxes this condition, and it allows the use of any number
of values for previous arguments. Although apparently more general, this
notion actually turns out to be reducible to the usual primitive recursion
(see CRT, I.7.1).
An early example of a course-of-value recursion was given by Leonardo
da Pisa, also called Fibonacci, in his Liber abaci, written in 1202 and revised
in 1228, when discussing the famous rabbit problem (paria coniculorum):
How many pairs of rabbits can be bred in one year from one pair?
A man has one pair of rabbits at a certain place entirely surrounded by a
wall. We wish to know how many pairs can be bred from it in one year, if
the nature of these rabbits is such that they breed every month one other
pair, and begin to breed in the second month after their birth. Let the ﬁrst
pair breed a pair in the ﬁrst month, then duplicate it and there will be 2
pairs in a month. From these pairs one, namely the ﬁrst, breeds a pair in
the second month, and thus there are 3 pairs in the second month. From
these in one month two will become pregnant, so that in the third month
2 pairs of rabbits will be born. Thus there are 5 pairs in this month. From
these in the same month 3 will be pregnant, so that in the fourth month
there will be 8 pairs. [· · · ]
In the margin Fibonacci writes the sequence
1,
2,
3,
5,
8,
13,
21,
34,
55,
89,
144,
233,
377
and continues:
You can see in the margin how we have done this, namely by combining
the ﬁrst number with the second, hence 1 and 2, and the second with the
third, and the third with the fourth . . . At last we combine the 10th with
the 11th, hence 144 and 233, and we have the sum of the above-mentioned
rabbits, namely 377, and in this way you can do it for the case of inﬁnite
numbers of months.

Recursive Functions: An Archeological Look
335
This provides the deﬁnition of the Fibonacci sequence:
f(0) = 0
f(1) = 1
f(n + 2) = f(n) + f(n + 1).
Notice the use of the two values f(n) and f(n + 1) in the deﬁnition of
f(n + 2), which makes this a course-of-value recursion.
The earliest record of a Fibonacci sequence is probably a set of weights
discovered a few decades ago in Turkey, going back to around 1200 B.C.
and arranged into a progression approximately equal to it (Petruso [24]).
The sequence was also known in Egypt and Crete (Preziosi [25]), and it
was used by the ancient and medieval Indians to deﬁne the metric laws of
sanscrit poetry (Singh [31]).
Double recursion
Primitive recursion can be used to deﬁne functions of many variables, but
only by keeping all but one of them ﬁxed. Double recursion relaxes this
condition, and it allows the recursion to happen on two variables instead of
only one. Although apparently more general, this notion actually turns out
to be reducible in many cases (but not all) to the usual primitive recursion
(see CRT, VIII.8.3.b and VIII.8.11).
The ﬁrst use of a double recursion was made around 220 B.C. by
Archimedes in his Sand Reckoner to solve the following problem:
There are some, King Gelon, who think that the number of the sand
is inﬁnite in multitude; and I mean the sand not only which exists about
Syracuse and the rest of Sicily, but also that which is found in every region
whether inhabited or uninhabited. Again there are some who, without
regarding it as inﬁnite, yet think that no number has been named which
is great enough to exceed this multitude. And it is clear that they who
hold this view, if they imagined a mass made up of sand in other respects
as large as the mass of the earth, including in it all the seas and the
hollows of the earth ﬁlled up to a height equal to that of the highest of the
mountains, would be many times further still from recognizing that any
number could be expressed which exceeded the multitude of the sand so
taken. But I will try to show you by means of geometrical proofs, which
you will be able to follow, that, of the numbers named by me and given
in the work which I sent to Zeuxippus,c some exceed not only the number
of the mass of sand equal in magnitude to the earth ﬁlled up in the way
described, but also that of a mass equal in magnitude to the universe.
To denote his large number, Archimedes ﬁxes a number a of units and
deﬁnes the number hn(x) by a double recursion, on the cycle x and the
cArchimedes is referring here to a work now lost.

336
P. Odifreddi
period n, as follows:
h0(x) = 1
hn+1(0) = hn(a)
hn+1(x + 1) = a · hn+1(x),
so that
hn(x) = (ax)n = axn.
Then he considers
ha(a) = (aa)a = a(a2)
for the particular value a = 108, i.e. a myriad myriads (the myriad, i.e.
10,000, was the largest number for which the Greeks had a proper name).
This takes him up to
(108)(1016) = 108·1016 ≈101017,
which he calls “a myriad myriads units of the myriad-myriadesimal order
of the myriad-myriadesimal period”. This number, consisting of 80 million
billions ciphers, remained the largest number used in mathematics until
Skewes [32], who needed 10101034
as a bound to the ﬁrst place where the
function π(x) −li(x) ﬁrst changes sign.
By an evaluation of the sizes of a grain of sand and of the then known
universe, Archimedes gets an estimate of 1063 for the number of grains of
sand needed to ﬁll the universe, well below the bound above. It may be
interesting to note that by using the values for the sizes of an electron (10−18
meters) and of the currently known universe (1035 light years), we get an
estimate of 10207 for the number of electrons needed to ﬁll the universe,
still well below the bound above.
Archimedes’ concludes his work as follows:
I conceive that these things, King Gelon, will appear incredible to the
great majority of people who have not studied mathematics, but that to
those who are conversant therewith and have given thought to the question
of the distances and sizes of the earth, the sun and moon and the whole
universe, the proof will carry conviction. And it was for this reason that
I thought the subject would not be inappropriate for your consideration.
10.2. The First Recursion Theorem
The so-called First Recursion Theorem (see CRT, II.3.15) provides a ba-
sic tool to compute values of functions which are solutions to recursive
equations, implicitly deﬁning functions by circular deﬁnitions involving the
function itself.

Recursive Functions: An Archeological Look
337
The procedure is similar to a classical method to compute approxima-
tions to real numbers which are solutions to algebraic equations, implicitly
deﬁning real numbers by circular deﬁnitions involving the number itself.
For example, consider the equation
x = 1 + 1
x·
Then x can be thought of as a ﬁxed point of the function
f(x) = 1 + 1
x,
in the sense that
x = f(x).
To make x explicit, we have at least two ways.
For example, we can transform the equation into the equivalent form
x2 −x −1 = 0,
and use the well-known formula for the solution to the second degree equa-
tion that was already known to the Babylonians around 2000 B.C., thus
getting
x = 1 ±
√
5
2
.
However, this works only for simple functions. Moreover, the solutions are
not circular anymore, but are still implicit (the radical
√
5 still needs to be
evaluated by other methods).
Alternatively, we can perform repeated substitutions of the right-hand
side for x, thus obtaining a continuous function of the kind introduced in
1572 by Raﬀaele Bombelli in his Algebra:
x = 1 + 1
x = 1 +
1
1 + 1
x
= · · · = 1 +
1
1 +
1
1+
1
1+···
.
The inﬁnite expression is built up as a limit of ﬁnite expressions, that
provide approximations to the solution. More precisely, if we write f(n+1)
f(n)
for the n-th approximation, then
f(n + 2)
f(n + 1) = 1 +
1
f(n+1)
f(n)
= f(n) + f(n + 1)
f(n + 1)
,
i.e.
f(n + 2) = f(n) + f(n + 1).

338
P. Odifreddi
In other words, f is simply the Fibonacci sequence, and the approximations
are given by the ratios of its successive terms:
2
1
3
2
5
3
8
5
13
8
21
13
· · · .
This iterative method is the same underlying the proof of the First
Recursion Theorem, and it has a long history.
10.2.1. Diﬀerentiable functions
An early appearance of the method is found in the Indian Sulvasutra, com-
posed between 600 and 200 B.C. To compute numerical approximations to
√
2, the following recursive algorithm is proposed.
A ﬁrst approximation is obtained by dissecting a rectangle of edges 1
and 2 (i.e. of area 2) into two squares of edge 1. One square is cut into two
rectangles of short edge 1
2, which are placed along the other square. The
square of edge 1 + 1
2 = 3
2 has an area that exceeds 2 by a small square of
edge 1
2, thus producing an error equal to 1
4.
A second approximation is obtained by subtracting from the square of
edge 3
2 giving the ﬁrst approximation the error, i.e. two rectangular stripes
of area
1
8 and short edge
1
8 · 2
3 =
1
12.
This produces a square of edge
3
2 −1
12 = 17
12, whose area diﬀers from 2 by a small square of edge
1
12, thus
producing an error equal to
1
144.
A third approximation is obtained by subtracting from the square of
edge
17
12 giving the second approximation the error, i.e. two rectangular
stripes of area
1
288 and short edge
1
288 · 12
17 =
1
408. This produces a square
of edge 17
12 −
1
408 = 577
408, which is the approximation to
√
2 given by the
Sulvasutra, and is correct to 5 decimal places.
The procedure can be iterated as follows: Given an approximation xn,
we produce a new approximation
xn+1 = xn −x2
n −2
2xn
,
where x2
n −2 is the error of the n-th approximation, x2
n−2
2
the area of each
of the two rectangular stripes, and x2
n−2
2xn
their short edge.
If we let f(x) = x2 −2, then f ′(x) = 2x and f(
√
2) = 0. The previous
recursive formula can thus be rewritten as
xn+1 = xn −f(xn)
f ′(xn)·

Recursive Functions: An Archeological Look
339
When generalized to any derivable functions, this becomes Newton’s for-
mula (1669) to approximate a zero of the given function by starting from
a point x0 suﬃciently close to a zero and having a nonzero derivative.
In the case of the f considered above, Newton’s formula can be obtained
directly by looking for an increment h such that
f(xn + h) = 0,
i.e.
(xn + h)2 −2 = x2
n + 2xnh + h2 −2 = 0.
By disregarding the quadratic term h2 (which is the reason for the persis-
tence of an error), we get
x2
n + 2xnh = 2,
i.e.
h = −x2
n −2
2xn
·
Similar proofs hold for any polynomial. In general, for an analytical func-
tion f the increment is obtained from Taylor’s formula (1715):
f(x + h) = f(x) + h
1!f ′(x) + h2
2! f ′′(x) + · · · + hn
n! f (n)(x) + · · · .
10.2.2. Contractions
When discussing the problem of consciousness, Royce [28] observed that an
individual must have an inﬁnite mental image of its own mind, since the
image must contain an image of the image, which must contain an image
of the image of the image, and so on.
Abstracting from the problem of consciousness, Royce presented a para-
doxical metaphor that caught the fancy of the writer Jorge Luis Borges, who
quoted it at least three times in his work with the following words:
Imagine a portion of the territory of England has been perfectly levelled,
and a cartographer traces a map of England. The work is perfect. There
is no particular of the territory of England, small as it can be, that has
not been recorded in the map. Everything has its own correspondence.
The map, then, must contain a map of the map, that must contain a map
of the map of the map, and so on to inﬁnity.

340
P. Odifreddi
The metaphor has been interpreted as a proof by contradiction that a per-
fect map is impossible, supporting the well-known aphorism of Korzyb-
ski [16]: “the map is not the territory”.
Actually, from a mathematical point of view a perfect map that contains
a copy of itself is not a contradiction, but rather a contraction, in the sense
that it deﬁnes a function f such that
|f(x) −f(y)| ≤c · |x −y|,
for some c such that 0 < c < 1. Banach [2] has proved that a contraction
on a complete metric space has a unique ﬁxed point, and the proof is a
typical iteration. Indeed, by induction,
|f (n+1)(x) −f (n)(x)| ≤cn · |f(x) −x|.
By the triangular inequality,
|f (n+m)(x) −f (n)(x)| ≤
X
i<m
|f (n+i+1)(x) −f (n+i)(x)|
≤(
X
i<m
cn+i) · |f(x) −x|.
Thus the sequence {f (n)(x)}n∈ω converges to a point x0, and hence so does
the sequence {f (n+1)(x)}n∈ω. Since f is continuous, the second sequence
also converges to f(x0), which must then be equal to x0. In other words,
x0 is a ﬁxed point of f. Moreover, if x1 is another ﬁxed point, then
|x0 −x1| = |f(x0) −f(x1)| ≤c · |x0 −x1|.
Since c < 1, it follows that x0 = x1, i.e. x0 is the unique ﬁxed point of f.
In the case of a perfect map, this means that there must be a point of
the territory that coincides with its image on the map. Thus a perfect map
is not the territory in general, but it is so in one (and only one) point.
10.2.3. Continuous functions
Banach’s result was obtained as an abstraction of the technique of suc-
cessive substitution developed in the xix Century by Liouville, Neumann,
and Volterra to ﬁnd solutions to integral equations, in which an unknown
function appears under an integral sign. A similar technique was used by
Peano [22] to ﬁnd solutions to systems of linear diﬀerential equations. In
both cases an appropriate contraction is determined by the usual continu-
ity and Lipschitz conditions, which ensure existence and uniqueness of the
solution.

Recursive Functions: An Archeological Look
341
An extension of Banach’s Fixed Point Theorem, for more special spaces
but more general maps, was obtained by Brouwer [4], who proved that a
continuous function of a convex compact subset of a Euclidean space on
itself has a ﬁxed point.
Brouwer’s original proof determined the existence of a ﬁxed point by
contradiction, without actually exhibiting it (this was quite ironical, due
to Brouwer’s costructive philosophy). In the special case of a closed disk,
Brouwer’s proof amounted to the following: If a continuous function of a
closed disk on itself had no ﬁxed point, every point would be moved to a
diﬀerent point. By extending the vector determined by an argument and its
image, we could associate to every point on the disk a point on the border.
This would determine an impossible continuous deformation of the whole
disk into the border.
However, a constructive version of Brouwer’s Fixed Point Theorem for
a continuous function on a closed square on itself can be obtained by the
iteration technique, as follows: Suppose there is no ﬁxed point on the bor-
der. Then the vector determined as above makes a complete turn while the
point moves around the border. Divide the square into four equal squares.
Either the vector vanishes on a point of the border on one of the squares,
thus determining a ﬁxed point of the given function, or there is at least one
square on which the vector makes a complete turn while the point moves
around the border, and the process can be started again. If no ﬁxed point
is found along the way, the process determines a sequence of telescopic
squares which uniquely identiﬁes a point. Since any neighborhood of the
point contains vectors in every direction, by continuity the vector ﬁeld must
vanish at it, i.e. the process determines a ﬁxed point.
In one dimension Brouwer’s Fixed Point Theorem becomes a version of
the Intermediate Value Theorem proved by Bolzano [3], according to which
a continuous function on a closed interval that takes values respectively
greater and smaller than c on the extremes of the interval, must take value
c at some point of the interval. In this case, an intermediate value can be
found by a bisection method similar to the above.
Even more abstract versions of Banach’s theorem than Brouwer’s were
obtained by Knaster [15] and Tarski [34], who proved the existence of ﬁxed
points for any monotone function on a complete lattice. Abian and Brown
[1] replaced complete lattices by chain-complete partial orderings, in which
every chain of elements has a least upper bound. In particular, a chain-
complete partial ordering has a least element ⊥, since the empty chain must
have a l.u.b.

342
P. Odifreddi
Given a monotone function f on a chain complete partial ordering,
consider the following transﬁnite sequence of elements:
x0 = ⊥
xα+1 = f(xα)
xβ = the l.u.b. of {f(xa)}α<β, if β is a limit ordinal.
Since f is monotone, this deﬁnes a chain, whose length cannot exceed the
maximal length of chains on the given partial ordering.
Then there is
a largest element xα0, otherwise the l.u.b. of the chain would be a larger
element. And f(xα0) = xα0, otherwise xα0 would not be the largest element
of the chain. Moreover, xα0 is the least ﬁxed point, because every element
of the chain is below any other ﬁxed point, by induction.
It thus follows that any monotone function on a chain complete partial
ordering has a least ﬁxed point. If, moreover, f is continuous (in the sense
of preserving l.u.b.s F), then the ﬁxed point is obtained in at most ω
iterations, because
f(xω) = f(
G
n∈ω
xn) =
G
n∈ω
f(xn) =
G
n∈ω
xn+1 = xω.
As an application, we can sketch a proof of the First Fixed Point Theo-
rem of Kleene [14]. Consider the chain complete partial ordering consisting
of the partial functions on the integers, ordered by inclusion. Since a re-
cursive functional is monotone and continuous, it has a least ﬁxed point xω
by the theorem. Moreover, the least ﬁxed point is recursive by the proof.
10.3. The Second Recursion Theorem
The so-called Second Recursion Theorem (see CRT, II.2.13) provides a ba-
sic tool to ﬁnd explicit solutions to recursive equations, implicitly deﬁning
programs of recursive functions by circular deﬁnitions involving the pro-
gram itself.
The procedure is the analogue of a classical method to ﬁnd explicit deﬁ-
nitions for functions implicitly deﬁned by recursive equations. For example,
consider the implicit deﬁnition of the Fibonacci sequence:
f(0) = 0
f(1) = 1
f(n + 2) = f(n) + f(n + 1).
To make f explicit, we can use De Moivre’s method (1718) of generating
functions, and let
F(x) = f(0) + f(1) · x + f(2) · x2 + · · · + f(n) · xn + · · · .

Recursive Functions: An Archeological Look
343
By computing
F(x) −F(x) · x −F(x) · x2
we notice that most terms cancel out, since they have null coeﬃcients of
the form f(n + 2) −f(n + 1) −f(n). We thus get
F(x) =
x
1 −x −x2 ·
By factoring the denominator, expanding the right-hand-side into a power
series, and comparing it term by term to F(x), we obtain the following
explicit description for f:
f(n) =
1
√
5
" 
1 +
√
5
2
!n
−
 
1 −
√
5
2
!n #
·
This result, which uses
1±
√
5
2
to express the Fibonacci sequence, is the
complement of the result proved above, which uses the Fibonacci sequence
to approximate 1+
√
5
2
·
Kronecker [17] generalized the previous example to show that every
linear recursive relation determines the coeﬃcients of a power series deﬁning
a rational function. Conversely, every rational function can be expressed
as a power series with coeﬃcients satisfying a linear recursive relation.
The Second Recursion Theorem serves a similar purpose, by turning
recursive programs which deﬁne functions by recursive calls, into programs
for the same functions without any recursive call.
10.3.1. The diagonal method
The proofs of the Second Recursion Theorem and its variants (see CRT,
II.2.10 and II.2.13) are elaborate and abstract forms of the diagonal method,
which can be considered the most pervasive tool of Recursion Theory. Its
essence is the following.
Given an inﬁnite matrix {aij}ij, we ﬁrst transform the elements ann on
the diagonal by means of a switching function d, thus obtaining d(ann). If
the switching function d is never the identity on the elements of the matrix,
then the transformed diagonal function is not a row of the matrix. More
precisely, it diﬀers on the n- th element from the n-th row.
Equivalently, if the transformed diagonal function is a row of the matrix,
e.g. the n-th, then the switching function d must be the identity on some
element of the matrix. More precisely, it leaves the n-th element of the n-th

344
P. Odifreddi
row unchanged. In this form, the diagonal method provides a ﬁxed point
of the function d.
10.3.2. The diagonal
The ﬁrst ingredient of the diagonal method is the consideration of the
elements on the diagonal of an appropriate matrix.
This was done in a nontrivial way already by Archimedes in the Sand
Reckoner discussed above, when stepping from the matrix {hn(x)}n,x to
the diagonal element ha(a).
In modern times, Du Bois Reymond has made a substantial use of diago-
nalization in his study of orders of inﬁnity, reported in Hardy [10]. Basically,
he deﬁnes an ordering based on domination (i.e. a function is greater than
another if it is above it for almost all arguments), and classiﬁes classes of
functions by means of skeletons of fast growing functions obtained by start-
ing with functions f greater than the identity, iterating at successor stages,
and diagonalizing at limit stages. More precisely, a function f such that
f(x) ≥x for almost all arguments deﬁnes the following skeleton:
f0(x) = f(x)
fα+1(x) = f (x)
α (x)
fα(x) = fαx(x),
where in the last clause α is the limit of the ascending sequence of the
ordinals αx (the deﬁnition obviously depends on the choice of the ascending
sequence.)
Today these skeletons have become standard in Complexity Theory, to
classify complexity classes such as the primitive recursive functions (see
CRT, VIII.8.10).
10.3.3. The switching function
The second ingredient of the diagonal method is the use of the switching
function on the elements of the diagonal.
This was ﬁrst done by Cantor [5], in his historical proof that the sets
of natural numbers are more than the numbers themselves. By considering
characteristic functions, the proof amounts to the observation that given a
sequence {fn}n∈ω of 0,1-valued functions, the function
d(x) = 1 −fx(x)
is 0,1-valued but not in the sequence, since it diﬀers from fn on the argu-
ment n. The switching function, true to its name, is here the function that
interchanges 0 and 1.

Recursive Functions: An Archeological Look
345
The same type of argument was used by Russell [29], to prove his cele-
brated paradox. This time we consider the set
R = {x : ¬(x ∈x)}.
Then
x ∈R ⇐⇒¬(x ∈x),
and thus
R ∈R ⇐⇒¬(R ∈R),
contradiction. The switching function is now the negation operator that
interchanges the truth values “true” and “false”.
Russell’s paradox was turned into a theorem by Curry [8], who proved
the existence of ﬁxed points for any λ-term in the Untyped Lambda Cal-
culus, according to the following correspondence:
Set Theory
Lambda Calculus
element
argument
set
term
membership
application
set formation {}
λ-abstraction
set equality
term equality
If the term N is supposed to correspond to negation, then the set R corre-
sponds to the term
C = λx. N(xx).
By the reduction rules of the Lambda Calculus,
Cx = N(xx),
and thus
CC = N(CC).
However, this is not a contradiction, but rather a proof that CC is a ﬁxed
point of N. In other words, in the Lambda Calculus there is no switching
function, in the sense of a term that always changes its arguments.
Curry’s Fixed Point Theorem is a version of the Recursion Theorems,
and together with the representability of the predecessor function quoted
above implies the representability of all recursive functions in the Lambda
Calculus, as proved by Kleene [12] (see CRT, I.6.6.c).

346
P. Odifreddi
10.3.4. Selfreference
In the last two arguments above, diagonalization takes the form of a self-
reference. Indeed, the conditions “x ∈x” in Russell’s paradox can be read
as: “x belongs to itself”. Similarly, the condition “xx” in Curry’s theorem
can be read as: “x applied to itself”.
Selfreference is obviously trivial in any language possessing the pronoun
“I”. The best known ancient reference is God’s own description in Exodus
(3.14): “I am that I am”. However, this kind of selfreference is somewhat
indirect, since the pronoun is a linguistic object that refers not to itself,
but to the person who is pronouncing it. A better example is a phrase that
talks of itself, for example: “This phrase consists of six words”.
The ﬁrst paradoxical selfreference was probably the Liar paradox, at-
tributed to Eubulides (iv Century B.C.) in the form: “I am lying”.
A
purely linguistic analogue is: “This phrase is false”.
It is not paradoxical, instead, for a Cretian such as Epimenides (vi
Century B.C.) to say: “All Cretians always lie”. This phrase cannot be
true, otherwise Epimenides would be a Cretian who is not always lying.
Then it must be false, i.e. some Cretian does not always lie. It does not
follow that such a Cretian is Epimenides. Nor would it follow, if he were,
that the phrase is one of his truths. So being, the following comment by St.
Paul in the Epistle to Titus (1.12) turns out to be even more cretin than it
looks at ﬁrst sight:
For there are many unruly and vain talkers and deceivers, specially they
of the circumcision: whose mouths must be stopped, who subvert whole
houses, teaching things which they ought not, for ﬁlthy lucre’s sake. One
of themselves, even a prophet of their own, said, “The Cretians are always
liars, evil beasts, slow bellies”. This witness is true.
The Liar paradox had counteless versions in history. In particular, the
original one-step selfreference was turned into a two-step one by Philip
Jourdain in 1913 (following Buridan of the xiv Century), as follows:
The following phrase is false.
The previous phrase is true.
Finite n-steps versions are obtained in a similar fashion. An inﬁnite dia-
bolical version, as the name suggests, has been proposed by Yablo [36, 37]:
All the following phrases are false.
All the following phrases are false.
. . .

Recursive Functions: An Archeological Look
347
Suppose the ﬁrst phrase is true. Then all the following ones are false, in
particular the second. Moreover, all the remaining phrases are false, and
hence the second one is true, contradiction. Then the ﬁrst phrase is false,
i.e. one of the following phrases is true, and a contradiction is reached as
for the ﬁrst. Thus the ﬁrst phrase is contradictory. Similarly, so are all the
remaining ones.
The turning point in these developments came with G¨odel [9], who made
an explicit reference to the Liar paradox in his paper.
His main result
can be stated as follows: Given any property P weakly representable in a
suﬃciently strong formal system for Arithmetic, there is a sentence saying
of itself that it has the property P (see CRT, p. I.165). For the proof,
consider an enumeration {ϕn}n∈ω of the formulas with one free variable,
the matrix
aij = the sentence “ϕj has the property expressed by ϕi”
and the switching function
d(ϕ) = the sentence “ϕ has the property P”.
Since P is weakly representable, the transformed diagonal sequence is still
a row of the matrix, up to provable equivalence. Thus there is a ϕ such
that d(ϕ) is provably equivalent to ϕ, i.e. ϕ says of itself that it has the
property P.
A ﬁrst consequence is that truth cannot be weakly representable in any
consistent and suﬃciently strong formal system for Arithmetic. Otherwise
so would be its negation, and the general result would give a contradictory
sentence asserting its own negation, as in the Liar paradox. The unrepre-
sentability of truth was obtained by G¨odel before his Incompleteness The-
orem, but he did not publish it. The result is thus usually attributed to
Tarski [33].
A second consequence is that, since provability is weakly representable
in any consistent and suﬃciently strong formal system for Arithmetic, the
general result gives a sentence asserting its own unprovability. From this
one can easily obtain all the epochal results of G¨odel [9], Rosser [26], and
Church [7] (see CRT, pp. I.166–169).
By the same type of argument we can also prove the Second Recursion
Theorem of Kleene [13], following Owings [21]. Given an eﬀective trans-
formation of programs f, consider an enumeration {ϕn}n∈ω of the partial
recursive unary functions, the matrix
aij = the function with program coded by ϕi(j)

348
P. Odifreddi
and the switching function
d(ϕe) = the function with program coded by f(e).
Since f is eﬀective, the transformed diagonal sequence is still a row of the
matrix. Thus there is an e such that d(ϕe) and ϕe are the same function.
Equivalently, the programs coded by e and f(e) compute the same function.
References
[1] S. Abian and A. B. Brown, A theorem on partially ordered sets with appli-
cations to ﬁxed-point theorems, Can. J. Math. 13, 78–83, (1961).
[2] S. Banach, Sur les operations dans les ensembles abstraits et leurs applica-
tions aux equations integrales, Fund. Math. 3, 7–33, (1922).
[3] B. Bolzano. Rein analytischer Beweise des Lehrsatzes, dass zwischen je zwey
Werthen, die ein entgegengesetzes Resultat gewhren, wenigstens eine reelen
Wurzel der Gleichen liege, Gottlieb Haase, Prague, (1817).
[4] L. Brouwer, ¨Uber Abbildungen von Mannigfaltigkeiten, Math. Ann. 71,
97–115, (1911/12).
[5] G. Cantor, ¨Uber eine Eigenschaft des Inbegriﬀes aller reellen algebraischen
Zahlen, J. Reine Angew. Math. 77, 258–262, (1874).
[6] A. Church, A set of postulates for the foundation of logic (second paper),
Ann. of Math. 34, 839–864, (1933).
[7] A. Church, A note on the Entscheidungsproblem, J. Symbolic Logic. 1,
40–41, (1936).
[8] H. B. Curry, The inconsistency of certain formal logics, J. Symbolic Logic.
7, 115–117, (1942).
[9] K. G¨odel, ¨Uber formal unentscheidbare S¨atze der Principia Mathematica
und verwandter Systeme I, Monatsh. Math. Phys. 38, 349–360, (1931).
[10] G. H. Hardy, Orders of inﬁnity. Cambridge University Press, Cambridge,
(1910).
[11] S. C. Kleene, A theory of positive integers in formal logic, Amer. J. Math.
57, 153–173, 219–244, (1935).
[12] S. C. Kleene, λ-deﬁnability and recursiveness, Duke Math. J. 2, 340–353,
(1936).
[13] S. C. Kleene, On notation for ordinal numbers, J. Symbolic Logic. 3, 150–
155, (1938).
[14] S. C. Kleene, Introduction to Metamathematics. Van Nostrand, New York,
(1952).
[15] B. Knaster, Un th´eor`eme sur les fonctions d’ensembles, Annales de la Soci´et´e
Polonaise de Math´ematiques. 6, 133–134, (1928).
[16] A. Korzybski, Science and Sanity. Science Press, Lancaster, (1941).
[17] L. Kronecker, Zur Theorie der Elimination einer Variablen aus zwei alge-
braischen Gleichungen, Monatsberichte der Kniglich Preussischen Akademie
der Wissenschaften, Berlin. pp. 535–600, (1881).

Recursive Functions: An Archeological Look
349
[18] J. Newman, The World of Mathematics. Simon and Schuster, New York,
(1956).
[19] P. Odifreddi, Classical Recursion Theory (Volume I). North-Holland, Ams-
terdam, (1989).
[20] P. Odifreddi, Classical Recursion Theory (Volume II). North-Holland, Am-
sterdam, (1999).
[21] J. C. Owings, Jr., Diagonalization and the recursion theorem, Notre Dame
J. Formal Logic. 14, 95–99, (1973).
[22] G. Peano, Int´egration par s´eries des ´equations diﬀ´erentielles lin´eaires, Math.
Ann. 32, 450–456, (1888).
[23] G. Peano, Sul concetto di numero, Rivista di Matematica. 1, 87–102, 256–
267, (1891).
[24] K. M. Petruso, Additive progressions in prehistoric mathematics: a conjec-
ture, Hist. Math. 12, 101–106, (1985).
[25] D. Preziosi, Minoan Architectural Design:
Formation and Signiﬁcation.
Mouton, Berlin, (1983).
[26] B. J. Rosser, Extensions of some theorems of G¨odel and Church, J. Symbolic
Logic. 1, 87–91, (1936).
[27] W. W. Rouse Ball, Mathematical Recreations and Essays. The MacMillan
Company, New York, (1905).
[28] J. Royce, The World and the Individual. The MacMillan Company, New
York, (1899).
[29] B. Russell, The principles of mathematics. Cambridge University Press,
Cambridge, (1903).
[30] Yu. A. Shashkin, Fixed Points. Amer. Math. Soc., (1991).
[31] P. Singh, The socalled Fibonacci numbers in Ancient and Medieval India,
Hist. Math. 12, 229–244, (1985).
[32] S. Skewes, On the diﬀerence π(x) −li(x), J. London Math. Soc. 8, 277–283,
(1933).
[33] A. Tarski, Der Wahrheitsbegriﬀin der formalisierten Sprachen, Studia Philo-
sophica. 1(261–405), (1936).
[34] A. Tarski, A lattice-theoretical ﬁxed-point theorem and its applications, Pa-
ciﬁc. J. Math. 5(285–309), (1955).
[35] L. Wittgenstein, Logisch-philosophische Abhandlung, Ann. Naturphil. 14,
185–262, (1921).
[36] S. Yablo, Truth and reﬂection, J. Philos. Logic. 14, 297–349, (1985).
[37] S. Yablo, Paradox without self-reference, Analysis. 53, 251–252, (1993).

This page intentionally left blank
This page intentionally left blank

Chapter 11
Reverse Mathematics and Well-ordering Principles
Michael Rathjen∗and Andreas Weiermann
Department of Pure Mathematics, University of Leeds
Leeds LS2 9JT, UK
E-mail: rathjen@maths.leeds.ac.uk
Vakgroep Zuivere Wiskunde en Computeralgebra, Ghent University
Krijgslaan 281 - Gebouw S22, B9000 Gent, Belgium
E-mail: Andreas.Weiermann@ugent.be
This chapter is concerned with generally Π1
2 sentences of the form “ if X
is well ordered then f(X) is well ordered”, where f is a standard proof
theoretic function from ordinals to ordinals. It has turned out that a
statement of this form is often equivalent to the existence of countable
coded ω-models for a particular theory Tf whose consistency can be
proved by means of a cut elimination theorem in inﬁnitary logic which
crucially involves the function f. To illustrate this theme, we shall fo-
cus on the well-known ϕ-function which ﬁgures prominently in so-called
predicative proof theory. However, the approach taken here lends it-
self to generalization in that the techniques we employ can be applied
to many other proof-theoretic functions associated with cut elimination
theorems. In this paper we show that the statement “ if X is well ordered
then ϕX0 is well ordered” is equivalent to ATR0. This was ﬁrst proved
by Friedman (see [7]) using recursion-theoretic and combinatorial meth-
ods. The proof given here is proof-theoretic, the main techniques being
Sch¨utte’s method of proof search (deduction chains) [15], generalized to
ω logic, and cut elimination for inﬁnitary ramiﬁed analysis.
∗Research of both authors was supported by Royal Society International Joint Projects
award 2006/R3. The ﬁrst author would like to thank the Swedish Collegium for Advanced
Study in Uppsala for providing an excellent research environment for the completion of
this paper.
351

352
M. Rathjen and A. Weiermann
Contents
11.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352
11.2 The Ordering ϕX0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 355
11.3 The Theory ATR0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356
11.4 Main Theorem
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357
11.4.1 Deduction chains in ω-logic
. . . . . . . . . . . . . . . . . . . . . . . . 357
11.4.2 The inﬁnitary calculus ∆1
1-CRQ
∞
. . . . . . . . . . . . . . . . . . . . . 360
11.5 Ramiﬁed Analysis RA∞
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
11.5.1 Finishing the proof of the main theorem . . . . . . . . . . . . . . . . . 367
11.6 Finishing the Proof of Theorem 11.1.3 . . . . . . . . . . . . . . . . . . . . . . 368
11.7 Prospectus
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369
11.1. Introduction
The larger project broached in this paper is to present a general proof-
theoretic machinery for investigating special kinds of Π1
2 statements about
well-orderings from a reverse mathematics point of view. These Π1
2 state-
ments are of the form
WOP(f)
“ if X is well ordered then f(X) is well ordered” (11.1)
where f is a standard proof-theoretic function from ordinals to ordinals.
There are by now several examples of functions f where the statement
WOP(f) has turned out to be equivalent to one of the theories of reverse
mathematics over a weak base theory (usually RCA0). The ﬁrst example
is due to Girard [9].
Theorem 11.1.1. (Girard, 1987) Let WO(X) express that X is a well
ordering. Over RCA0 the following are equivalent:
(i) Arithmetic Comprehension.
(ii) ∀X [WO(X) →WO(2X)].
Recently two new theorems appeared in preprints [7, 11]. These results give
characterizations of the form (11.1) for the theories ACA+
0 and ATR0,
respectively, in terms of familiar proof-theoretic functions. ACA+
0 denotes
the theory ACA0 augmented by an axiom asserting that for any set X the
ω-th jump in X exists while ATR0 asserts the existence of sets constructed
by transﬁnite iterations of arithmetical comprehension. α 7→εα denotes the
usual ε function while ϕ stands for the two-place Veblen function familiar
from predicative proof theory (cf. [15]). More detailed descriptions of ATR0

Reverse Mathematics and Well-ordering Principles
353
and the function X 7→ϕX0 will be given shortly. Deﬁnitions of the familiar
subsystems of reverse mathematics can be found in [17].
Theorem 11.1.2. (Montalban, Marcone, 2007) Over RCA0 the following
are equivalent:
(i) ACA+
0 .
(ii) ∀X [WO(X) →WO(εX)].
Theorem 11.1.3. (Friedman) Over RCA0 the following are equivalent:
(i) ATR0.
(ii) ∀X [WO(X) →WO(ϕX0)].
The proof of Theorem 11.1.3 uses rather sophisticated recursion-
theoretic results about linear orderings and is quite combinatorial. Theorem
11.1.3 builds on a result from [6] to the eﬀect that there is no arithmetic
sequence of degrees descending by ω-jumps. The latter result was then im-
proved by Steel [18] to descent by Turing jumps: If Q ⊆Pow(ω) × Pow(ω)
is arithmetic, then there is no sequence {An | n ∈ω} such that (a) for
every n, An+1 is the unique set such that Q(An, An+1), (b) for every n,
A′
n+1 ≤T An.
For a proof theorist, theorems 11.1.2 and 11.1.3 bear a striking resem-
blance to cut elimination theorems for inﬁnitary logics. This prompted the
ﬁrst author of this paper to look for proof-theoretic ways of proving these
results.
The hope was that this would also unearth a common pattern
behind them and possibly lead to more results of this kind. The project
commenced with [2], where a purely proof-theoretic proof of Theorem 11.1.2
was presented. In this paper we shall give a new proof of Theorem 11.1.3. It
is principally proof-theoretic, the main techniques being Sch¨utte’s method
of proof search (deduction chains) [15] and cut elimination for ramiﬁed
analysis. The general pattern, of which this paper provides a second ex-
ample, is that a statement WOP(f) is often equivalent to a familiar cut
elimination theorem for an inﬁnitary logic which in turn is equivalent to
the assertion that every set is contained in an ω-model of a certain theory
Tf.
To guide the reader through the paper we shall brieﬂy sketch the main
parts of the proof of Theorem 11.1.3, i.e., that (ii) implies (i). We start with
the observation that ATR0 can be axiomatized over ACA0 via a single sen-
tence of the form ∀X(WO(<X) →∀Z∃Y B0(X, Y, Z)) where B0(X, Y, Z)
is an arithmetical formula (cf. Lemma 11.3.2). Thus to verify ATR0 it

354
M. Rathjen and A. Weiermann
suﬃces to show that for every well-ordering <Q there exists an ω-model of
M of ACA0 which contains Q such that M |= ∀Z∃Y B0(Q, Y, Z). To ﬁnd
M we employ Sch¨utte’s method of proof search from [15, II§4], which he
used to prove the completeness theorem for ﬁrst order logic (cf. [15, Theo-
rem 5.7]). The method has to be extended to ω-logic, though. Rather than
working in the Sch¨utte calculus of positive and negative forms we work in a
Gentzen sequent calculus with ﬁnite sets of formulas, called sequents. Let
C be a sentence that axiomatizes arithmetic comprehension and let DQ(n)
be the formula n ∈Q if the latter formula is true and n /∈Q otherwise. The
main idea is to start with the sequent {¬∀Z∃Y B0(Q, Y, Z), ¬C, ¬DQ(0)}
and systematically apply the rules of ω-logic for the second order sequent
calculus backwards, giving rise to a tree of sequents DQ. One also has to
add the formula ¬DQ(n) to all sequents generated in this way after n steps.
There are two possible outcomes. If the tree DQ is not well-founded
then it contains an inﬁnite path P. Now deﬁne a set M via
(M)i = {n | n /∈Ui occurs in P}
and let M = (N; {(M)i | i ∈N}, +, ·, 0, 1, <). For a formula F, let F ∈P
mean that F occurs in P, i.e. F ∈Γ for some Γ ∈P. Let U0, U1, U2, . . . be
an enumeration of the free set variables. For the assignment Ui 7→(M)i
one can then show that F ∈P
⇒
M |= ¬F. Whence M is an ω-model of
ACA and M |= ∀Z∃Y B0(Q, Y, Z). Also note that (M)0 = Q, thus Q is in
M.
The other conceivable outcome is that DQ is well-founded, i.e. all paths
in DQ are ﬁnite, and thus every maximal path ends in a sequent which
contains a basic axiom. In other words DQ is a proof tree and the Kleene-
Brouwer ordering of this tree is some well-ordering τ.
The crucial step
to perform next consists in envisaging DQ as a skeleton of a proof tree in
inﬁnitary ramiﬁed analysis, dubbed RA∗in [15]. In actuality DQ can be
viewed as the skeleton of a proof of the empty sequent in RA∗. As we can
remove all cuts in this proof we end up with a cut free proof of the empty
sequent. But this is impossible, and therefore DQ cannot be well-founded.
To be able to carry out the removal of all cuts we have to enlist the help
of arithmetical transﬁnite induction, roughly up to the ordinal ϕτ0. Hence
this is the step where the principle ∀X [WO(X) →WO(ϕX0)] makes its
appearance in showing the direction (ii) ⇒(i) of Theorem 11.1.3.

Reverse Mathematics and Well-ordering Principles
355
11.2. The Ordering ϕX0
Via simple coding procedures, countable well-orderings, and functions on
them can be expressed in the language of second order arithmetic, L2.
Variables X, Y, Z, . . . are supposed to range over subsets of N. Using an
elementary injective pairing function ⟨, ⟩(e.g. ⟨n, m⟩:= (n + m)2 + n + 1),
every set X encodes a sequence of sets (X)i, where (X)i := {m | ⟨i, m⟩∈
X}. We also adopt from [17], II.2 the method of encoding a ﬁnite sequence
(n0, . . . , nk−1) of natural numbers as a single number ⟨n0, . . . , nk−1⟩.
Deﬁnition 11.2.1. Every set of natural numbers Q can be viewed as en-
coding a binary relation <Q on N via n <Q m iﬀ⟨n, m⟩∈Q. The ﬁeld of
Q, ﬂd(Q) is the set {n | ∃m [n <Q m ∨m <Q n]}.
We say that Q is a well-ordering if <Q is a well-ordering, that is <Q
is a linear ordering of its ﬁeld and every non-empty subset U of ﬂd(Q) has
a <Q-least element.
Deﬁnition 11.2.2. Let Q be a linear ordering with least element 0Q. Let
ϕua := ⟨0, ⟨u, a⟩⟩, H := {ϕua | u, a ∈N}, h(ϕua) = u and h(b) = 0Q if
b /∈H.
We introduce the ordering ϕQ0 by inductively deﬁning its ﬁeld ﬂd(ϕQ0)
and the ordering <ϕQ0:
(1) 0 ∈ﬂd(ϕQ0).
(2) 0 <ϕQ0 α if α ∈ﬂd(ϕQ0) and α ̸= 0.
(3) ϕuα ∈ﬂd(ϕQ0) if u ∈ﬂd(Q), α ∈ﬂd(ϕQ0) and h(α) ≤Q u.
(4) If α1, . . . , αn ∈ﬂd(ϕQ0) ∩H, n > 1 and αn ≤ϕQ0 . . . ≤ϕQ0 α1, then
α1 + . . . + αn ∈ﬂd(ϕQ0)
where α1 + . . . + αn := ⟨1, ⟨α1, . . . , αn⟩⟩.
(5) If α1 + . . . + αn, β1 + . . . + βm ∈ﬂd(ϕQ0), then
α1 + . . . + αn <ϕQ0 β1 + . . . + βm iﬀ
n < m ∧∀i ≤n αi = βi
or
∃i ≤min(n, m)[αi <ϕQ0 βi ∧∀j < i αj = βj].
(6) If α1 + . . . + αn ∈ﬂd(ϕQ0), ϕuβ ∈ﬂd(ϕQ0) and ϕuβ ≤ϕQ0 α1 then
ϕuβ <ϕQ0 α1 + . . . + αn.
(7) If α1 + . . . + αn ∈ﬂd(ϕQ0), ϕuβ ∈ﬂd(ϕQ0) and α1 <ϕQ0 ϕuβ then
α1 + . . . + αn <ϕQ0 ϕuβ.

356
M. Rathjen and A. Weiermann
(8) If ϕuα, ϕvβ ∈ﬂd(ϕQ0), then
ϕuα <ϕQ0 ϕvβ iﬀu <Q v ∧α <ϕQ0 ϕvβ
or
u = v ∧α <ϕQ0 β
or
v <Q u ∧ϕuα <ϕQ0 β.
Lemma 11.2.3. (RCA0)
(i) If Q is a linear ordering then so is ϕQ0.
(ii) ϕQ0 is elementary recursive in Q.
11.3. The Theory ATR0
Deﬁnition 11.3.1. Let A(u, Y ) be any formula. Deﬁne HA(X, Y ) to be
the formula which says that <X is a linear ordering and that Y is equal to
the set of pairs ⟨n, j⟩such that j is in the ﬁeld of <X and A(n, Y j) where
Y j = {⟨m, i⟩| i <X j ∧⟨m, i⟩∈Y }. Intuitively HA(X, Y ) says that Y is
the result of iterating A along <X.
ATR0 is the formal system in the language of second order arithmetic
whose axioms consist of ACA0 plus all instances of
∀X(WO(<X) →∃Y HA(X, Y ))
where A is arithmetical.
Lemma 11.3.2. ATR0 can be axiomatized over ACA0 via a single sen-
tence
∀X(WO(<X) →∀Z∃Y B0(X, Y, Z))
(11.2)
where B0(X, Y, Z) is of the form HA(X, Y ) for some arithmetical formula
A(u, Y, Z) with all free variables exhibited.
Proof.
This is a standard result. One could for instance take B0(X, Y, Z)
to mean that Y is obtained from Z by iterating the Turing jump operation
along <X starting with Z; so A(u, Y, Z) would actually be a Σ0
1 (complete)
formula. Another (shorter and citable) way of showing this is to use the
fact that ATR0 is equivalent over RCA0 to the statement that every two
well-orderings are comparable (see [17], Theorem V.6.8). The proof of the
latter statement in ATR0 just requires an instance HA of said form (see
the proof of [17, Lemma V.2.9]).
□

Reverse Mathematics and Well-ordering Principles
357
Deﬁnition 11.3.3. Let T be a theory in the language of second order
arithmetic, L2. A countable coded ω-model of T is a set W ⊆N, viewed as
encoding the L2-model
M = (N, S, +, ·, 0, 1, <)
with S = {(W)n | n ∈N} such that M |= T .
This deﬁnition can be made in RCA0 (see [17], Deﬁnition VII.2).
We write X ∈W if ∃n X = (W)n.
11.4. Main Theorem
The main result we want to prove is the following:
Theorem 11.4.1. RCA0 + ∀X [WO(X) →WO(ϕX0)] proves ATR0.
A central ingredient of the proof will be a method of proof search (de-
duction chains) pioneered by Sch¨utte [15].
11.4.1. Deduction chains in ω-logic
Deﬁnition 11.4.2.
(i) Let U0, U1, U2, . . . be an enumeration of the free set variables of L2.
For a closed term t, let t
N be its numerical value. We shall assume
that all predicate symbols of the language L2 are symbols for primitive
recursive relations.
L2 contains predicate symbols for the primitive
recursive relations of equality and inequality and possibly more (or
all) primitive recursive relations. If R is a predicate symbol in L2 we
denote by R
N the primitive recursive relation it stands for. If t1, . . . , tn
are closed terms the formula R(t1, . . . , tn) (¬R(t1, . . . , tn)) is said to be
true if R
N(t
N
1, . . . , t
N
n) is true (is false).
(ii) Henceforth a sequent will be a ﬁnite set of L2-formulas without free
number variables.
(iii) A sequent Γ is axiomatic if it satisﬁes at least one of the following
conditions:
(1) Γ contains a true literal, i.e.
a true formula of either form
R(t1, . . . , tn) or ¬R(t1, . . . , tn), where R is a predicate symbol in
L2 for a primitive recursive relation and t1, . . . , tn are closed terms.
(2) Γ contains formulas s ∈U and t /∈U for some set variable U and
terms s, t with s
N = t
N.

358
M. Rathjen and A. Weiermann
(iv) A sequent is reducible or a redex if it is not axiomatic and contains
a formula which is not a literal.
Deﬁnition 11.4.3. For Q ⊆N deﬁne
DQ(n) =
 ¯n ∈U0 if n ∈Q
¯n /∈U0 otherwise .
For the proof of Theorem 11.4.1 it is convenient to have a ﬁnite axiom-
atization of arithmetic comprehension.
Lemma 11.4.4. ACA0 can be axiomatized via a single Π1
2 sentence
∀X C(X).
Proof:
[17], Lemma VIII.1.5.
⊓⊔
Deﬁnition 11.4.5. Let <Q be a well-ordering. Let B(Ui) be the formula
∃Y B0(U0, Y, Ui) of Lemma 11.3.2.
A Q-deduction chain is a ﬁnite string
Γ0, Γ1, . . . , Γk
of sequents Γi constructed according to the following rules:
(i) Γ0 = ¬DQ(0), ¬B(U0), ¬C(U0).
(ii) Γi is not axiomatic for i < k.
(iii) If i < k and Γi is not reducible then
Γi+1 = Γi, ¬DQ(i + 1), ¬B(Ui+1), ¬C(Ui+1).
(iv) Every reducible Γi with i < k is of the form
Γ′
i, E, Γ′′
i
where E is not a literal and Γ′
i contains only literals.
E is said to be the redex of Γi.
Let i < k and Γi be reducible. Γi+1 is obtained from Γi = Γ′
i, E, Γ′′
i as
follows:
(1) If E ≡E0 ∨E1 then
Γi+1 = Γ′
i, E0, E1, Γ′′
i , ¬DQ(i + 1), ¬B(Ui+1), ¬C(Ui+1).
(2) If E ≡E0 ∧E1 then
Γi+1 = Γ′
i, Ej, Γ′′
i , ¬DQ(i + 1), ¬B(Ui+1), ¬C(Ui+1)
where j = 0 or j = 1.

Reverse Mathematics and Well-ordering Principles
359
(3) If E ≡∃x F(x) then
Γi+1 = Γ′
i, F( ¯m), Γ′′
i , ¬DQ(i + 1), ¬B(Ui+1), ¬C(Ui+1), E
where m is the ﬁrst number such that F( ¯m) does not occur in
Γ0, . . . , Γi.
(4) If E ≡∀x F(x) then
Γi+1 = Γ′
i, F( ¯m), Γ′′
i , ¬DQ(i + 1), ¬B(Ui+1), ¬C(Ui+1)
for some m.
(5) If E ≡∃X F(X) then
Γi+1 = Γ′
i, F(Um), Γ′′
i , ¬DQ(i + 1), ¬B(Ui+1), ¬C(Ui+1), E
where m is the ﬁrst number such that F(Um) does not occur in
Γ0, . . . , Γi.
(6) If E ≡∀X F(X) then
Γi+1 = Γ′
i, F(Um), Γ′′
i , ¬DQ(i + 1), ¬B(Ui+1), ¬C(Ui+1)
where m is the ﬁrst number such that m ̸= i + 1 and Um does not
occur in Γi.
The set of Q-deduction chains forms a tree DQ labeled with strings of
sequents. We will ﬁrst consider the case that DQ is not well-founded. Then
DQ contains an inﬁnite path P. Now deﬁne a set M via
(M)i = {t
N | t /∈Ui occurs in P}.
Set M = (N; {(M)i | i ∈N}, +, ·, 0, 1, <).
For a formula F, let F ∈P mean that F occurs in P, i.e. F ∈Γ for
some Γ ∈P.
Claim. Under the assignment Ui 7→(M)i we have
F ∈P
⇒
M |= ¬F.
(11.3)
The Claim will imply that M is an ω-model of ACA.
Also note that
(M)0 = Q, thus Q is in M. The proof of (11.3) follows by induction on
F using Lemma 11.4.6 below. The upshot of the foregoing is that we can
prove Theorem 11.4.1 under the assumption that DQ is ill-founded for all
sets Q ⊆N.
Lemma 11.4.6. Let Q be an arbitrary subset of N and DQ be the corre-
sponding deduction tree. Moreover, suppose DQ is not well-founded. Then
DQ has an inﬁnite path P. P has the following properties:

360
M. Rathjen and A. Weiermann
(1) P does not contain literals which are true in N.
(2) P does not contain formulas s ∈Ui and t /∈Ui for constant terms s
and t such that sN = tN.
(3) If P contains E0 ∨E1 then P contains E0 and E1.
(4) If P contains E0 ∧E1 then P contains E0 or E1.
(5) If P contains ∃xF(x) then P contains F(¯n) for all n.
(6) If P contains ∀xF(x) then P contains F(¯n) for some n.
(7) If P contains ∃XF(X) then P contains F(Um) for all m.
(8) If P contains ∀XF(X) then P contains F(Um) for some m.
(9) P contains ¬B(Um) for all m.
(10) P contains ¬C(Um) for all m.
(11) P contains ¬DQ(m) for all m.
Proof.
Standard.
□
Corollary 11.4.7. If DQ is ill-founded then there exists a countable coded
ω-model of ACA0 containing Q which satisﬁes ∀Z∃Y B0(Q, Y, Z).
The remainder of the paper will be devoted to ruling out the possibil-
ity that, whenever Q is a well-ordering, DQ can be a well-founded tree.
This is the place where cut elimination for the inﬁnitary proof system of
ramiﬁed analysis, RA∗(see [15], part C), enters the stage. In a nutshell,
the idea is that a well-founded DQ gives rise to a derivation of the empty
sequent (contradiction) in RA∗which can be ruled out by showing cut
elimination for RA∗using transﬁnite induction up to ϕX0, where X is a
well-ordering not much longer than Q. However, to simplify the technical
treatment we ﬁrst introduce an intermediate system ∆1
1-CRQ
∞based on
the ∆1
1-comprehension rule and the ω-rule. This theory basically coincides
with Sch¨utte’s system DA∗(see [15], part C). It is not diﬃcult to see that
a well-founded DQ can be viewed as a derivation of the empty sequent in
∆1
1-CRQ
∞. The last step towards reaching a contradiction consists in em-
bedding ∆1
1-CRQ
∞into RA∗. Here we can basically follow [15] Theorem
22.14.
11.4.2. The inﬁnitary calculus ∆1
1-CRQ
∞
In what follows we ﬁx Q ⊆N such that <Q is a well-ordering. In the
main, the system ∆1
1-CRQ
∞is obtained from ACA0 by adding the ∆1
1-
comprehension rule, the ω-rule and the basic diagram of Q. The language
of ∆1
1-CRQ
∞is the same as that of ACA0 but the notion of formula comes

Reverse Mathematics and Well-ordering Principles
361
enriched with set terms. Formulas and set terms are deﬁned simultane-
ously. Literals are formulas. Every set variable is a set term. If A(x) is a
formula without set quantiﬁers (i.e. arithmetical) then {x | A(x)} is a set
term. If P is a set term and t is a numerical term then t ∈P and t /∈P
are formulas. The other formation rules pertaining to ∧, ∨, ∀x, ∃x, ∀X, ∃X
are as per usual.
We will be working in a Tait-style formalization of the second order
arithmetic with formulas in negation normal form, i.e. negations only in
front of atomic formulas. Due to the ω-rule there is no need for formulas
with free numerical variables.
Thus all sequents below are assumed to
consist of formulas without free numerical variables.
Axioms of ∆1
1-CRQ
∞
(i) Γ, L where L is a true literal.
(ii) Γ, s ∈U, t /∈U where s
N = t
N.
(iii) Γ, s ∈U0 if s
N ∈Q.
(iv) Γ, s /∈U0 if s
N /∈Q.
Rules of ∆1
1-CRQ
∞
(∧) Γ, A
Γ, B
Γ, A ∧B
.
(∨)
Γ, Ai
Γ, A0 ∨A1
where i ∈{0, 1}.
(Cut) Γ, A
Γ, ¬A
Γ
.
(ω) Γ, F(¯n)
for all n
Γ, ∀xF(x)
.
(∃1)
Γ, F(t)
Γ, ∃xF(x) .
(∀2) Γ, F(P)
for all set terms P
Γ, ∀XF(X)
.
(∃2)
Γ, F(P)
Γ, ∃XF(X)
where P is a set term.

362
M. Rathjen and A. Weiermann
(∆1
1-CR) ∀x[∀Y A0(x, Y ) ↔∃Y A1(x, Y )]
Γ, ∃X∀x[x ∈X ↔∀Y A0(x, Y )]
with A0, A1 arithmetical.
(ST1)
Γ, A(t)
Γ, t ∈P
where P is the set term {x | A(x)}.
(ST2) Γ, ¬A(t)
Γ, t /∈P
where P is the set term {x | A(x)}.
∆1
1-CRQ
∞is a sequent calculus version of the system DA∗of [15, §20].
The language of DA∗, though, is based on the connectives ⊥, ∀, →while
∆1
1-CRQ
∞has the connectives ∧, ∨, ∀, ∃, ¬ and formulas are in negation
normal form, i.e. the negation sign appears only in front of atomic formulas.
The other main diﬀerence is that the deduction system of DA∗is the Sch¨utte
calculus of positive and negative forms whereas ∆1
1-CRQ
∞’s is the Gentzen
sequent calculus.
Lemma 11.4.8. We shall use ∆1
1-CRQ
∞
Γ to convey that the sequent
Γ is derivable in ∆1
1-CRQ
∞. Pivotal properties of ∆1
1-CRQ
∞we shall exploit
are the following:
(a) n ∈Q ⇒∆1
1-CRQ
∞
¯n ∈U0 .
(b) n /∈Q ⇒∆1
1-CRQ
∞
¯n /∈U0 .
(c) ∆1
1-CRQ
∞
WO(U0) .
(d) ∆1
1-CRQ
∞
∃Y HA(U0, Y ) for all arithmetical formulas A(u, Y ) hav-
ing no other free numerical variables than u.
Proof:
(a) and (b) are immediate by the axioms (iii) and (iv) of ∆1
1-CRQ
∞.
(c) follows by (outer) transﬁnite induction on <Q, crucially using the ω-
rule. This is standard but it seems to be a challenge to ﬁnd a reference. Via
the axioms (iii) and (iv), the role of Q is played in ∆1
1-CRQ
∞by the variable
U0. Writing s ∈Q and s <Q t for s ∈U0 and ⟨s, t⟩∈U0, respectively, we
would like to show that ∆1
1-CRQ
∞⊢∀X(ProgQ(X) →∀x x ∈X), where
ProgQ(U) stands for ∀x[∀y(y <Q x →y ∈U) →x ∈U]. It suﬃces to
show
∆1
1-CRQ
∞⊢¬ProgQ(U), ¯n ∈U
(11.4)
for all n for an arbitrary set variable U. To this end we proceed by induction
on Q. Inductively assume that ∆1
1-CRQ
∞⊢¬ProgQ(U), ¯m ∈U holds for
all m <Q n. If m <Q n is false then ⟨m, n⟩/∈Q and hence ∆1
1-CRQ
∞⊢

Reverse Mathematics and Well-ordering Principles
363
¬ ¯m <Q ¯n. As a result, ∆1
1-CRQ
∞⊢¬ProgQ(U), ¬ ¯m <Q ¯n, ¯m ∈U holds for
all m. Using (∨) inferences followed by an application of the ω-rule, we get
∆1
1-CRQ
∞⊢¬ProgQ(U), ∀y(y <Q ¯n →y ∈U). As ∆1
1-CRQ
∞⊢¯n /∈Q, ¯n ∈
Q, an inference (∨) (and weakening) yields
∆1
1-CRQ
∞⊢¬ProgQ(U), ∀y(y <Q ¯n →y ∈U) ∧¯n /∈Q, ¯n ∈Q.
Hence via (∃1) we arrive at
∆1
1-CRQ
∞⊢¬ProgQ(U), ∃x[∀y(y <Q ¯n →y ∈U) ∧x /∈Q], ¯n ∈Q,
which is the same as ∆1
1-CRQ
∞⊢¬ProgQ(U), ¯n ∈Q. Thus, by induction
on <Q, (11.4) follows.
(d) also follows by transﬁnite induction on <Q using ∆1
1-CR. A reference
will be provided in Lemma 11.4.10.
⊓⊔
We shall need to measure the length of the previous derivations. For (c)
and (d) the lengths of those derivations will be “longer” than Q, though not
“much longer”. Let τ be the ordinal giving the order-type of Q. It is easy
to cook up a new ordering Q∗in an elementary way from Q corresponding
to the ordinal ω2 + ω · τ + ω in such a way that RCA0 suﬃces to prove
WO(Q) →WO(Q∗) (see [9]). The rationale for the choice of ω2 +ω ·τ +ω
is that it gives us enough elbow room for calibrating the lengths of the
foregoing derivations.
From the standing assumption that Q is a well-ordering we get that Q∗
is a well-ordering, too.
Deﬁnition 11.4.9. If α is an element of the ﬁeld of <Q∗, we use the nota-
tion ∆1
1-CRQ
∞
α Γ to convey that the sequent Γ is deducible in ∆1
1-CRQ
∞
via a derivation of length ≤α.
More formally, this relation is deﬁned
by recursion on α as follows: ∆1
1-CRQ
∞
α Γ holds if either Γ is an ax-
iom of ∆1
1-CRQ
∞or Γ is the conclusion of a ∆1
1-CRQ
∞-inference with pre-
misses (Γi)i∈I such that for every i ∈I there exists βi <Q∗α with
∆1
1-CRQ
∞
βi Γi .
Lemma 11.4.10.
(1) ∆1
1-CRQ
∞
0 DQ(n) for all n with 0 being the least element of Q.
(2) ∆1
1-CRQ
∞
α C(U) for some α ∈ﬁeld(Q∗) and all free set variables
U.

364
M. Rathjen and A. Weiermann
(3) ∆1
1-CRQ
∞
β WO(U0) for some β ∈ﬁeld(Q∗).
(4) ∆1
1-CRQ
∞
γ ∃Y HA(U0, Y ) for some γ ∈ﬁeld(Q∗) for all arithmeti-
cal formulas A(u, Y ) having no other free numerical variables than u.
(5) ∆1
1-CRQ
∞
δ B(U) for some δ ∈ﬁeld(Q∗) and all free set variables U.
Proof:
(1) is an immediate consequence of Lemma 11.4.8 (a) and (b).
(2) follows since the rule (∃2) gives arithmetical comprehension. (3) and
(4) correspond to Lemma 11.4.8 (c) and (d), respectively. A detailed proof
of (4) amounts to basically the same as that of [15, §21 Lemma 14]. (5) is
an immediate consequence of (4).
⊓⊔
Recall that, by Corollary 11.4.7, there exists a countable coded ω-model
of ACA0 containing Q and satisfying ∀Z∃Y B0(Q, Y, Z) providing DQ is
ill-founded.
Now let us assume that Q is a well-ordering and that DQ
is well-founded.
Then DQ can be viewed as a deduction with hidden
cuts involving formulas of the shape ¬B(Ui+1), ¬C(Ui+1) and ¬DQ(i+1).
Note that by Lemma 11.4.10, ∆1
1-CRQ
∞
0 DQ(n) , ∆1
1-CRQ
∞
α C(U) , and
∆1
1-CRQ
∞
γ B(U) for some α, γ ∈ﬁeld(Q∗).
Thus if Γ is the sequent
attached to a node τ of DQ and (Γi)i∈I is an enumeration of the sequents
attached to the immediate successor nodes of τ in DQ then the transition
(Γi)i∈I
Γ
can be viewed as a combination of four inferences in ∆1
1-CRQ
∞,
the ﬁrst one being a logical inferences and the other three being cuts. By
interspersing DQ with cuts and adding three cuts with cut formulas ¬C(U0),
¬B(U0) and ¬DQ(0) at the bottom we obtain a derivation ˜DQ in ∆1
1-CRQ
∞
of the empty sequent. Since the preceding line of arguments can be done
in ACA0 we arrive at the following:
Corollary 11.4.11 (ACA0). If Q is a well-ordering and DQ is well-
founded then there is a derivation ˜DQ in ∆1
1-CRQ
∞of the empty sequent.
To ﬁnish the paper we thus have to show that the latter is impossible.
This we shall do by embedding ∆1
1-CRQ
∞into a system RA∞deﬁned below.
Note that an upper bound for the length of ˜DQ is provided by (α+γ+ρ)·4,
where ρ corresponds to the Kleene–Brouwer ordering on DQ.

Reverse Mathematics and Well-ordering Principles
365
11.5. Ramiﬁed Analysis RA∞
The theories RAρ are designed to capture G¨odel’s notion of constructibility
restricted to sets of natural numbers. They use ordinal indexed variables
Xα, Y α, Zα, . . . for α < ρ, with the intended meaning that level 0 variables
range over sets deﬁnable by numerical quantiﬁcation, and level α > 0 vari-
ables range over sets deﬁnable by numerical quantiﬁcation and level < α
set quantiﬁcation. The proof-theoretic ordinal of RAα is ϕα0. We are
interested in an inﬁnitary version of ramiﬁed analysis.
Deﬁnition 11.5.1. RA∞is basically the same system as RA∗in [15, §22].
One diﬀerence is that the language of RA∗is based on the connectives
⊥, ∀, →while RA∞has ∧, ∨, ∀, ∃, ¬ and formulas are in negation normal
form, i.e. the negation sign appears only in front of atomic formulas. The
other diﬀerence is that the deduction system of RA∗is the Sch¨utte calcu-
lus of positive and negative forms whereas RA∞’s is the Gentzen sequent
calculus.
The formulas of RA∞do not have free numerical variables. Literals are
formulas of the form R(t1, . . . , tn) and ¬R(t1, . . . , tn) with R being a sym-
bol for a primitive recursive relation and t1, . . . , tn being closed numerical
terms.
RA∞uses ordinal indexed free set variables U α, V α, W α, . . . and bound
set variables Xβ, Y β, Zβ, . . . with β > 0, where the ordinals are assumed to
be elements of some countable well-ordering R.
The set terms and formulas together with their levels are generated as
follows (cf. [15, §22]):
(1) Every literal is a formula of level 0.
(2) Every free set variable U α is a set term of level α.
(3) If P is a set term of level α and t is a numerical term, then t ∈P and
t /∈P are formulas of level α.
(4) If A and B are formulas of levels α and β, then A ∨B and A ∧B are
formulas of level max(α, β).
(5) If F(0) is a formula of level α, then ∀xF(x) and ∃xF(x) are formulas
of level α and {x | F(x)} is a set term of level α.
(6) If F(U β) is a formula of level α and β > 0, then ∀XβF(Xβ) is a formula
of level max(α, β).
Deﬁnition 11.5.2. The calculus RA∞
Q

366
M. Rathjen and A. Weiermann
Axioms
Γ, L where L is a true literal.
Γ, s ∈U α, t /∈U α where s
N = t
N.
Γ, s ∈U0 if s
N ∈Q.
Γ, s /∈U0 if s
N /∈Q.
Rules
(∧), (∨), (ω), numerical (∃) and (Cut) as per usual.
(∃α)
Γ, F(P)
Γ, ∃XαF(Xα)
P set term of level < α.
(∀α)
Γ, F(P)
for all set terms P of level < α
Γ, ∀XαF(Xα)
.
(ST1)
Γ, F(t)
Γ, t ∈{x | F(x)}
.
(ST2)
Γ, ¬F(t)
Γ, t /∈{x | F(x)}
.
Deﬁnition 11.5.3. The cut rank of a formula A in RA∞
Q , |A|, is deﬁned
as follows (cf. [15, §22]):
(1) |L| = 0 for arithmetical literals L.
(2) |t ∈U α| = |t /∈U α| = ω · α.
(3) |B0 ∧B1| = |B0 ∨B1| = max(|B0|, |B1|) + 1.
(4) |∀xB(x)| = |∃xB(x)| = |t ∈{x | B(x)}| = |t /∈{x | B(x)}| = |B(0)|+1.
(5) |∀XαA(Xα)| = |∃XαA(Xα)| = max(ω · γ, |A(U 0)| + 1)
where γ is the level of ∀XαA(Xα).
By recursion on α we deﬁne the relation RA∞
Q
α
ρ Γ as follows: RA∞
Q
α
ρ Γ
holds if either Γ is an axiom of RA∞
Q or Γ is the conclusion of an RA∞
Q -

Reverse Mathematics and Well-ordering Principles
367
inference with premisses (Γi)i∈I such that for every i ∈I there exists βi < α
with RA∞
Q
βi
ρ Γi and, moreover, if this inference is a cut with cut formula
A then |A| < ρ.
The following three statements are proved in [15] for the system RA∗.
It is routine to transfer them to RA∞
Q since cut-elimination in a Sch¨utte
calculus of positive and negative is closely related to cut-elimination in
sequent calculi. Moreover, the additional axioms pertaining to Q do not
impede the cut-elimination process.
Theorem 11.5.4 (Cut-elimination I).
RA∞
Q
α
η+1 Γ
⇒
RA∞
Q
ωα
η
Γ .
Proof.
Similar to [15, §22 Lemma 4].
□
Theorem 11.5.5 (Cut-elimination II).
RA∞
Q
α
ωρ Γ
⇒
RA∞
Q
ϕρα
0
Γ .
Proof.
Similar to [15, Theorem 22.7].
□
For a formula F of the language of ∆1
1-CRQ
∞let F σ be the result of
replacing every bound variable X by Xσ and every free set variable by a
set term of a level < σ. For Γ = {F1, . . . , Fn} let Γσ = {F σ
1 , . . . , F σ
n }.
Theorem 11.5.6 (Interpretation Theorem).
∆1
1-CRQ
∞
α Γ
⇒
RA∞
Q
ω·σ+ω+ω·α
ω·σ
Γσ
for all σ of the form ωα · β with β ̸= 0.
Proof.
This is basically the same as [15, Theorem 22.14].
□
There are diﬀerent ways of formalizing inﬁnite deductions in theories
like PA. We just mention [16] and [8].
11.5.1. Finishing the proof of the main theorem
Recall that in order to ﬁnish the proof of Theorem 11.4.1 we want to show
that DQ is not well-founded whenever Q is a well-ordering. By Corollary
11.4.11, if Q is a well-ordering and DQ is well-founded then there is a
derivation ˜DQ in ∆1
1-CRQ
∞of the empty sequent. By the Interpretation
Theorem 11.5.6 we would then get a derivation in RA∞
Q of the empty
sequent. Using the principle WO(X) →WO(ϕX0) we can then employ

368
M. Rathjen and A. Weiermann
the cut-elimination Theorem 11.5.5 to obtain a cut-free derivation of the
empty sequent in RA∞
Q . But this is impossible.
From Corollary 11.4.7 we can thus conclude that for every well-ordering
˜Q there exists a countable coded ω-model of ACA0 containing ˜Q and
satisfying ∀Z∃Y B0( ˜Q, Y, Z). From this we would like to infer that for every
well-ordering Q and every set Z0 there exists a set Y such that B0( ˜Q, Y, Z0).
We can do this by encoding Q and Z0 in a well-ordering ˜Q from which Q
and Z0 can be retrieved in any ω-model of ACA0 containing ˜Q. One way
of doing this is to deﬁne the new ordering ˜Q by letting
⟨n, m⟩< ˜
Q ⟨n′, m′⟩iﬀ[n = n′ = 0 ∧m < ˜
Q m′] ∨
[n = n′ = 1 ∧m, m′ ∈Z0 ∧m < m′] ∨
[n = 0 ∧n′ = 1 ∧m ∈ﬁeld(Q) ∧m′ ∈Z0].
Obviously ˜Q is a well-ordering, too, and any ω-model M of ACA0
containing ˜Q will contain Z0 as well. Moreover, M |= ∃Y B0( ˜Q, Z0) im-
plies M |= ∃Y B0(Q, Z0). Hence, in view of Lemma 11.3.2, we get ATR0,
thereby ﬁnishing the proof of Theorem 11.4.1.
11.6. Finishing the Proof of Theorem 11.1.3
One direction of Theorem 11.1.3 follows from Theorem 11.4.1. The other
direction is implicit in the proof of [15] Theorem 21.6.
11.7. Prospectus
The methodology exempliﬁed in the proof of Theorem 11.1.3 should
have many more applications. Every cut-elimination theorem in ordinal-
theoretic proof theory potentially encapsulates a theorem of type 11.1.3.
The ﬁrst author has looked at two more examples and sketched proofs
of the pertaining theorems. A familiar function from proof theory is the
Γ-function where α 7→Γα enumerates the ﬁxed points of the ϕ-function.
Since the proof of the next result has only been sketched we classify it as a
conjecture.a
Conjecture 11.7.1. Over RCA0 the following are equivalent:
(i) Every set X is contained in a countable coded ω-model of ATR0.
(ii) ∀X [WO(X) →WO(ΓX)].
aRecently this conjecture has been proved in [13].

Reverse Mathematics and Well-ordering Principles
369
The direction (i)⇒(ii) follows from [12, 4.13,4.16].
For an example from impredicative proof theory one would perhaps
ﬁrst turn to the ordinal representation system used for the ordinal anal-
ysis of the theory ID1 of non-iterated inductive deﬁnitions, which can be
expressed in terms of the θ-function (cf. [5]). ID1 has the same strength
as the subsystem of second order arithmetic based on bar induction, BI
(cf. [4, 5, 14]). In Simpson’s book the acronym used for BI is Π1
∞-TI0
(cf. [17, §VII.2]). In place of the function θ we prefer to work with sim-
pler ordinal representations based on the ψ-function introduced in [3] or
the ϑ-function of [14].
For deﬁniteness we refer to [14].
Given a well-
ordering X, the relativized versions ϑX and ψX of the ϑ-function and the
ψ-function, respectively, are obtained by adding all the ordinals from X to
the sets Cn(α, β) of [14, §1] and Cn(α) of [14, Deﬁnition 3.1] as initial seg-
ments, respectively. The resulting well-orderings ϑX(εΩ+1) and ψX(εΩ+1)
are equivalent owing to [14, Corollary 3.2].
Again, as the following statement has not been buttressed by a complete
proof we formulate it as a conjecture.
Conjecture 11.7.2. Over RCA0 the following are equivalent:
(i) Every set X is contained in a countable coded ω-model of BI.
(ii) ∀X [WO(X) →WO(ψX(εΩ+1))].
References
[1] B. Afshari. Proof-Theoretic Strengths of Hierarchies of Theories. PhD thesis,
University of Leeds, UK, (2008).
[2] B. Afshari and M. Rathjen, Reverse mathematics and well-ordering princi-
ples: a pilot study, Ann. Pure Appl. Logic. 160, 231–237, (2009).
[3] W. Buchholz, A new system of proof–theoretic ordinal functions, Ann. Pure
Appl. Logic. 32, 195–207.
[4] W. Buchholz and K. Sch¨utte, Proof Theory of Impredicative Subsystems of
Snalysis. Bibliopolis, Naples, (1988).
[5] W. Buchholz, S. Feferman, W. Pohlers, and W. Sieg, Iterated Inductive
Deﬁnitions and Subsystems of Analysis. Springer, Berlin, (1981).
[6] H. Friedman, Uniformly deﬁned descending sequences of degrees, J. Symbolic
Logic. 41, 363–367, (1976).
[7] H. Friedman, A. Montalban, and A. Weiermann. Phi function. (Draft),
(2007).
[8] H. Friedman and S. Sheard, Elementary descent recursion and proof theory,
Ann. Pure Appl. Logic. 71, 1–45, (1995).

370
M. Rathjen and A. Weiermann
[9] J.-Y. Girard, Proof Theory and Logical Complexity. vol. 1, Bibliopolis,
Napoli, (1987).
[10] J. L. Hirst, Reverse mathematics and ordinal exponentiation, Ann. Pure
Appl. Logic. 66, 1–18, (1994).
[11] A. Marcone and A. Montalban. The epsilon function for computability the-
orists. (Draft), (2007).
[12] M. Rathjen, The strength of Martin-L¨of type theory with a superuniverse.
part i, Arch. Math. Logic. 39, 1–39, (2000).
[13] M. Rathjen. ω-models and well-ordering principles. To appear in Founda-
tional Adventures, Proceedings in honor of Harvey Friedman’s 60th birth-
day.
[14] M. Rathjen and A. Weiermann, Proof–theoretic investigations on Kruskal’s
theorem, Ann. Pure Appl. Logic. 60, 49–88, (1993).
[15] K. Sch¨utte, Proof Theory. Springer-Verlag, Berlin, Heidelberg, (1977).
[16] H. Schwichtenberg. Proof theory: Some applications of cut-elimination. In
ed., J. Barwise, Handbook of Mathematical Logic, pp. 867–895. North Hol-
land, Amsterdam, (1977).
[17] S. G. Simpson, Subsystems of Second Order Arithmetic. Springer-Verlag,
Berlin, Heidelberg, (1999).
[18] J. Steel, Descending sequences of degrees, J. Symbolic Logic. 40, 59–61,
(1975).

Chapter 12
Discrete Transﬁnite Computation Models
Philip D. Welch
School of Mathematics,
University of Bristol,
Bristol, BS8 1TW, UK
E-mail: p.welch@bristol.ac.uk
Discrete computing models, such as that of the Turing machine or of
Register machines, can be allowed to run transﬁnitely if suitable limit
ordinal behavior is described. This chapter relates such models to classi-
cal accounts of higher type recursion theory, going back to Kleene. Using
such models as a yardstick, one can analyse more modern models, such
as computation in particular physical spacetimes, to give bounds on the
complexity of such forms of computation. Computation on ordinals and
set recursion are brieﬂy discussed.
Contents
12.1 Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372
12.1.1 The contents
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372
12.1.2 Argument . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373
12.2 Computation on Integers
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
12.2.1 Transcending the ﬁnite through stacking Turing machines
. . . . . . . 376
12.2.2 Allowing supertasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384
12.3 Computation on Reals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 392
12.3.1 ITTM computations on reals
. . . . . . . . . . . . . . . . . . . . . . . 395
12.4 Computation on Ordinals, and Ordinal Length Machines
. . . . . . . . . . . 398
12.4.1 Ordinal length tapes
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 399
12.4.2 Ordinal Register Machines . . . . . . . . . . . . . . . . . . . . . . . . . 402
12.5 Theoretical Machine Strength . . . . . . . . . . . . . . . . . . . . . . . . . . . 403
References
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 407
371

372
P. D. Welch
12.1. Introduction
12.1.1. The contents
In the past few years there has been a resurgence of interest in discrete mod-
els of computation that are allowed to act transﬁnitely. Such conceptual
machines act in simple steps or stages, and have as a paradigm the standard
Turing machine. This, during its progress moves one cell at a time, to the
left or the right along an unbounded tape that it is reading, and subse-
quently alters symbols, changes states and moves on. This paradigm has
been with us for 70 years, and for much of this chapter we shall consider
variants of such a device.
Our models will all be discrete acting computational digital models. We
shall consider how Turing and other computing machines could possibly
behave when allowed to perform supertasks (by which we mean that they
are allowed to complete an inﬁnite sequence of tasks or operations). Such
a machine is usually envisaged with an unbounded tape. If supertasks are
allowed then naturally the whole of that tape comes into play, and we can
imagine that tape already having some characteristic function written on it.
The machine can then act on that tape and is then essentially a computer
acting at a higher type, namely that of inﬁnite sequences of 0, 1s, in other
words, of real numbers.
Surprisingly, even if one restricts one’s model to, say, a register machine
model, where the registers are ﬁnite in number with natural number entries,
then simply deﬁned behaviour at transﬁnite limit stages of computation
lead to quite powerful decision procedures. This chapter will look at these as
well. Whereas at the ﬁnite level the power of Turing and register machines
is the same, at the transﬁnite level they diverge markedly.
We shall not deal here with any machine that is, broadly speaking, an
analog machine or computes in an analog fashion. Indeed apart from Sec-
tion 2.1 we shall not be entering into any discussion of physical viabilities,
feasibilities etc.
We thus do not wish to discuss various machine propos-
als that could be seen to fall under the rubric we are setting ourselves, in
that they seek to compute functions whilst being constructed to conform to
some ambient physical theory or constraint. We have in mind models such
as Davies [7], and the models of Beggs and Tucker [3] that attempt to com-
pute any set of natural numbers, by some kinematic-based device, and thus
do so within a fragment of Newtonian mechanics; nor do we consider the
interaction of standard machines with physically based ‘advice’ functions

Discrete Transﬁnite Computation Models
373
or oracles, such as is done in [2]. We also shall not particularly consider
classical quantum computation, as functions computed by such models are
also Turing computable.
Section 2.1 is somewhat of an exception, in that we do consider a partic-
ular construction in detail due to Etesi and N´emeti [12], and to Hogarth [21],
that allows Turing machines to be placed or arranged within particular
spacetimes to allow for the algorithmic decision of Π1 (and beyond) predi-
cates without supertask phenomena. We can calculate somewhat precisely,
the bounds to what can be computed in such models. We also recount the
observation from [56], that separability of the spacetime manifold puts a
universal countable bound on formal systems of computation within that
spacetime (under some mild assumptions).
A major lacuna is that we do not consider ﬁnite automata on inﬁnite
graphs, or in particular on inﬁnite binary trees. This would have ﬁtted well
in any discussion of discrete models, and is admittedly a serious omission.
Lastly, this chapter is not about computation with an algebraic or struc-
tural ﬂavour, and we include here, inter alia, the Blum, Shub, Smale model
of computation on the reals ([4]). Although we do want to consider com-
putation on the reals,
R is considered primarily as unordered Baire space,
or Cantor space, and there is not any other algebraic or structural feature
that distinguishes the models considered here.
12.1.2. Argument
In the 1960s and 1970s much research was undertaken deriving ultimately
from Kleene’s theory ([26], [29]) of recursion in higher types (Generalized
Recursion Theory, Kleene Recursion), and the pioneering work of Aczel,
Gandy, Moschovakis amongst others, that would lead to Spector classes, the
theory of inductive deﬁnitions, and the theory of admissible sets, (Barwise,
Kripke, Platek).
Our motivation is that we wish to revisit some of these older theories
and results and see how some recent activity in a class of models of compu-
tation ﬁts in the older picture. Some of these later models are no more than
familiar models with diﬀerent style of inputs (register machines on ordinals
say); others such as Inﬁnite Time Turing Machine of Hamkins and Kidder
([15]) are versions of the standard model adapted to enable larger compu-
tations to be performed by allowing transﬁnite sequences of operations or
stages; yet a third class simply consists of ‘standard computation’ placed
in an unconventional framework (Turing machines stacked up, or regarded

374
P. D. Welch
as inhabiting particular spacetimes). We want to see how these models ﬁt
in with our conceptions of recursion and computation formed in the earlier
period.
We emphasise the logico-mathematical part of this, in particular the
descriptive set theoretical descriptions. No apology is needed for this: to
understand the model is to understand what the model produces: If this
transcends that produced by ﬁnitary operations (in whatever form) then
we are obliged to consider the underlying set-theoretical fundamentals. We
consider further in Section 5 the connections of the computation models to
the theory of inductive deﬁnitions (either monotone or not), and to sub-
systems of second order arithmetic. We do not consider this an accurate
account on historical principles and we do not even claim to do justice to
the concepts and individuals involved, but are merely taking a snapshot,
as we rush past a fast-evolving subject.
12.2. Computation on Integers
We start ahistorically in terms of the published literature, but with a fact
that surely must have been known to early recursion theorists such as Post:
that allowing a Turing machine to at least run out indeﬁnitely allows for the
printing of the characteristic function not just of the halting problem (as a
complete Σ1-set) but of a ∆2-set. This has been called ‘truth in the limit’.
A Turing machine may answer any Π1-question, if it is allowed ω-many
stages: given a recursive predicate R(v0, v1) we may program a machine to
investigate in turn R(0, n), R(1, n), . . ., R(k, n) . . . in turn, and if for some
k ¬R(k, n), then we require it to halt with a ‘0’ for ‘no’ as output.
If
the machine does not halt, then were we able to ‘transcend time’ we could
look back and say that the machine veriﬁed ∀v0R(v0, n). If we assume the
machine has an output tape as well as a scratch tape, and if we assume the
output tape starts out with every cell having a ‘1’ written to it, we could
dovetail all the queries ?∀v0R(v0, n)? for each n, and have the machine
change a 1 to a 0 as soon as it veriﬁed that ∀v0R(v0, n) failed. Then after
ω many stages, if we still could look at the output tape, we’d have written
the characteristic function of the Π1 set A =df {n | ∀v0R(v0, n)}. If we
asked the question, Is A non-empty? this is a Σ2-query: ∃v1∀v0R(v0, v1)?
We cannot, in general, answer this, without allowing ourselves some further
inﬁnitary operation.
Putnam, much later, made the following deﬁnition:

Discrete Transﬁnite Computation Models
375
Deﬁnition 12.1. (Putnam [42]) P is a trial and error predicate if and
only if there is a general recursive function f such that for every x1, . . . , xn
P(x1, . . . , xn) ≡limy→∞f(x1, . . . , xn, y) = 1
¬P(x1, . . . , xn) ≡limy→∞f(x1, . . . , xn, y) = 0.
Putnam asked, and answered, the question as to the complexity in the
arithmetical hierarchy of such predicates: they are ∆2 = Σ2 ∩Π2 in the
arithmetical hierarchy. We obtain the truth of P(x1, . . . , xn) ‘in the limit’
as y −→∞.
If we imagine the recursive function f as being computed by a Tur-
ing machine M writing its 0/1 output to a particular cell C0 on its tape,
the clauses above amount to a prescription of M’s behaviour on any in-
put x1, . . . , xn that the contents of the cell C0, after computing in turn
f(x1, . . . , xn, 0), f(x1, . . . , xn, 1), . . . , f(x1, . . . , xn, y), . . ., ‘settles down’ as
y increases: it must be either eventually 1/0 depending.
We may thus
rephrase Putnam as:
P ⊂
Nn is a trial and error predicate if there is a Turing machine M0
so that
P(x1, . . . , xn) ⇐⇒the eventual value of M0’s output cell on input n is 1
¬P(x1, . . . , xn) ⇐⇒the eventual value of M0’s output cell on input n is 0.
Continuing with this model for a moment, one sees that if there is in
advance a ﬁxed bound on the number of alternations that M0 makes on
the output cell C0’s value, then that knowledge allows us to compute the
characteristic functions of predicates in particular levels of the diﬀerence
hierarchy of Σ1 sets.
Brieﬂy: we say that P(⃗x) is in the k’th level of
the diﬀerence hierarchy, if there are Σ1 sets Q0, . . . , Q2k−1 with P(⃗x) ↔
W
i≤k(Q2i−2(⃗x)∧¬Q2i−1(⃗x)); if we specify that M ′
0 may only write to the cell
C0 at most 2k+1 times, then M ′
0 may decide P(⃗x). Note that it is the ﬁxity
of the value k that determines the complexity within the class of Boolean
combinations that is capable of being decided by such an arrangement.
However even allowing k to be unbounded, is not quite suﬃcient.
The
following can be shown:
Fact. As long as the number of times that M ′
0 can change its mind
about the value of C0 is a recursive function, f(⃗x) say, of the input ⃗x, then
still such predicates do not exhaust ∆2. To put it another way, there cannot
be any recursive constraint on the number of alterations if the process is to
decide all ∆2 predicates.
There is the possibility of using the output of one Turing Machine as
input to another. For functions on integers, this could be regarded as just

376
P. D. Welch
composition of recursive functions. If we allow the output of a machine
after ω many stages, either as a truth-in-the-limit operation or otherwise
then we can display this as an inﬁnitary operation on an inﬁnite sequence
of 0s and 1s (or whatever the alphabet of the machine is). How one does
this, or under what preconditions one allows such models to be considered
depends on how fastidiously one takes exception to ‘supertasks’, the latter
being roughly deﬁned here as a process that at some stage has completed
inﬁnitely many subtasks.
We now consider various mechanisms for this.
12.2.1. Transcending the ﬁnite through stacking Turing ma-
chines
One obvious objection to an inﬁnitely running process is the ‘Thom-
son Lamp’ ( [52]) objection:
if a switch has been thrown at times
1
2, 2
3, 3
4, . . . ,
n
n+1, . . . at what position is it at, or what value does it have,
at time ‘1’? Similarly if a cell on the Turing machine tape has changed
value inﬁnitely often from 0 to 1 and back again at ﬁnite stages, what value
should we allot it at ‘time’ ω? Placing models in certain spacetimes neatly
sidesteps this puzzle.
12.2.1.1. General relativistic models:
Malament–Hogarth Space-
times
Pitowsky [40] gave an account of an attempt to deﬁne spacetimes in which
the eﬀect of inﬁnitely many computational tasks could be seen by an ob-
server Or in that spacetime. (By ‘spacetime’ we mean here a Hausdorﬀ,
paracompact, Riemannian manifold which is a solution to the Einsteinian
GR equations – we refer the reader to [18].) He used the example of the, at
the time, unresolved Fermat’s Last Theorem but we can consider any other
task that involves looking at a Π0
1 question: for example, the consistency of
the axioms of Peano Arithmetic, or Goldbach’s Conjecture, both of which
involve a simple universal quantiﬁer ∀n over a recursive predicate. Let us
take the latter: another observer Oq performs the tasks of checking that
each even number in turn is the sum of two primes. This they do along
their world-line γ1, the proper time of which is inﬁnite (as each calculation
takes some ﬁnite unit of time). If they ﬁnd a counterexample they send
a signal to Op travelling along her worldline γ2. The point of the exam-
ple is to arrange that the proper time of γ2 is ﬁnite, and has the whole of
γ1 in her chronological past.
As Earman and Norton [10] mention, there

Discrete Transﬁnite Computation Models
377
are problems with this account not least that along γ1 Op must undergo
unbounded acceleration. Since then more sophisticated spacetimes due to
Hogarth [21] and Etesi & N´emeti [12], have been devised. For the moment
we follow formally [10] to deﬁne:
Deﬁnition 12.2. M=(M, gab) is a Malament–Hogarth (MH) spacetime
just in case there is a time-like half-curve γ1 ⊂M and a point p ∈M such
that
R
γ1 dτ = ∞and γ1 ⊂I−(p) (where τ denotes proper time and I−(p)
the causal past of p).
This seemingly makes no reference to the word-line of the observer Op
travelling along their path γ2, but they point out that there will be in any
case such a future-directed timelike curve γ2 passing through a point q ∈
I−(p) to p such that R
γ2(q,p) dτ < ∞, with q chosen to lie in the causal future
of the past endpoint of γ1. The important point is that the whole of γ1 lies
in the chronological past of Op. As Hogarth showed in [21] such spacetimes
are not globally hyperbolic, thus ruling out many standard spacetimes (such
as Minkowski spacetime). (See [10] for a discussion on global hyperbolicity
and a family of Penrosian Causal Censorship Hypotheses in this context –
this is an interesting debate on how one might add extra axioms to GR to
limit the types of spacetimes permissible – but would take this chapter too
far oﬀcourse.)
To obtain a spacetime as above, they take Minkowski spacetime N0 =
(R4, ηab) and choose a scalar ﬁeld Ωwhich is everywhere equal to 1 out-
side of a compact set C, and which rapidly goes to +∞as the point r
is approached.
The point r is removed and the MH spacetime is then
N = (R4\{r}, gab), where gab = Ω2ηab. Ωand γ1 can be chosen so that γ1
is a timelike geodesic. This ‘toy’ spacetime is pictured on the left.
2
r
p
C
γ
γ2
1
1γ
r
C
p
γ
Figure 12.1.
A ‘toy’ MH spacetime. On the right Hogarth’s representation.

378
P. D. Welch
Earman and Norton discuss various possible spacetimes already in the
literature that conform to being MH: G¨odel spacetimes are MH but are
causally ‘vicious’;
anti-de Sitter spacetime is MH, but fails a strong en-
ergy condition; Reissner–Nordstrom spacetime meets this, but as in all MH
spacetimes there is divergent blue-shift of the signal to Op; further, of the
unbounded ampliﬁcation of signals that Op may have to receive, etc., etc.
Again this is beyond the terms of our discussion here, and apart from the
rotating Kerr black hole solution of Etesi & N´emeti [12] to which we shortly
turn, our aim is only to analyse the logico-mathematical possibilities inher-
ent in these models.
12.2.1.2. Etesi & N´emeti’s rotating black hole model
The authors consider an observer sent axially into the region containing
a rotating black hole of a certain size, and rotating at certain speeds – a
Kerr solution. The ﬁrst notable feature of such a black hole is that the
primary singularity is ring-formed around the axis of rotation (see [18]).
The observer, Op, is sent along the axis of rotation and receives signals
sent from a Turing machine that is orbiting forever around the black hole.
The machine is again looking for counterexamples, say, to a Π1-predicate
and will transmit one if it is found to Op. A clear desideratum for them is
Assumption 1 ‘No swamping’: it should not be the case that any part of
the machinery or any observer should have to transmit or receive inﬁnitely
many signals.
Initially, the orbiting machine and Op, should send and receive respec-
tively, a single signal: the witness to the failure of the Π1 predicate under
inspection. They further remark though (their Proposition 2) that in fact
the computational arrangement allows deciding queries ?n ∈R? for sets
R slightly more complicated than Π1 or Σ1: R can be taken as a union
of a Σ1 and a Π1 set for example. Indeed they indicate an argument (at
their Proposition 3), that if the machine-observer Om is allowed to send k
diﬀerent signals, (they take k = 2) then any k-fold Boolean combination
of Σ1 and Π1 sets R = T
i<k−1(Si ∪P i)
(with Si ∈Σ1 and P i ∈Π1)
can be decided. They ask how far in the arithmetical hierarchy this kind
of argument can be taken. The discussion above concerning ∆2 predicates
shows:
Theorem 12.1. [56] The relations R ⊆
N computable in the Etesi–N´emeti
model form a subclass of the ∆2 predicates of
N; this is a proper subclass
if and only if there is a ﬁxed ﬁnite bound on the number of signals sent to
the observer Op.

Discrete Transﬁnite Computation Models
379
We have seen (at the Fact above) that for a ∆2 predicate R there is
no recursive bound on the input n as to how many times the machine will
have to change its mind concerning whether n ∈R, and a fortiori no ﬁxed
in advance ﬁnite bound. Of course for checking whether any one n is in
R, ﬁnitely many signals will suﬃce; hence only if the architecture of the
experiment allows for potentially unboundedly many signals, then (and only
then) can ∆2 predicates be decided, still without breaking Assumption 1.
12.2.1.3. Hogarth’s arithmetically deciding spacetime regions
Hogarth names a ‘unit’ or ‘region’ of spacetime that is capable of deciding
a Π1 question as above an ‘SAD1 spacetime or region’, and as a shorthand
denotes it by the right hand diagram above at Fig. 12.1. Hogarth in [22],
(and in the later [23]) stacks up such regions to ﬁnite depths in order to
answer Πn queries.
If a spacetime contains a sequence ⃗O = ⟨Oj|j ≥0⟩of non-intersecting
open regions such that (1) for all j ≥0 Oj ⊆I−(Oj+1) and (2) there is a
point p ∈M such that ∀j ≥0 Oj ⊆I−(p) then ⃗O is said to form a past
temporal string or just string.
To decide membership in a Π2-deﬁnable
set of integers P(n) ≡∀a∃bQ(a, b, n) he then stacks up a string of regions
taking each Oj as a SAD1 region, each looking like the component of the
right of Fig. 12.1, with O0 being used to decide ∃bQ(0, b, n). If this fails a
signal is sent out to Op; but if this is successful, a signal is sent to O1 to
start to decide ∃bQ(1, b, n) etc. Ultimately, putting this all together, again
Op receives a signal if ¬P(n), or else knows after a ﬁnite interval that P(n).
It should be noted that
Assumption 2 The open regions Oj are disjoint
and still that no observer or part of the machinery of the system has to
send or receive inﬁnitely many signals (thus the ‘no swamping’ assumption
is kept). This whole region is then dubbed an ‘SAD2’ spacetime.
An ‘SADn+1’ spacetime is deﬁned accordingly as composed from an
inﬁnite string of (again disjoint) SADn regions On, again all in the past
of some point p. (Earman and Norton [11] show that an SAD1 spacetime
cannot decide Π2 statements, and Hogarth [23] follows this up with the
generalisation that SADj cannot decide Πj+1 statements.)
In Fig.
2.2
below, on the right is the underlying tree structure of an SAD3 region for
computing queries of the form ?n ∈A? for some Σ3 set A: each large circle
represents an SAD2 region (which in turn contains a string of inﬁnitely
many of the small circles – pictured by the terminal nodes of the tree

380
P. D. Welch
– representing the SAD1 regions) which can be used for computing the
answers to Σ2 queries. Correspondingly, in Fig. 12.2, if each On is a SADj
region then the diagram on the left is that of an SADj+1 region.
1
O
O2
O2
O
1
O
0
3
O
p
p
O0
Figure 12.2.
An SAD3 region as a past temporal string of SAD2 regions; and its tree
representation (right).
In Fig.12.2, each region On contains itself an ω sequence of SAD1 regions
which are shown in (the enlarged) circles of the tree.
We thus have that Πn+1 questions can be decided by allowing nested
stacks of suitable SAD regions to depth n (if we deﬁne the depth of the
simplest region in Fig. 12.1 as being 0). He then puts these altogether:
Deﬁnition 12.3. A spacetime (M, gab) is an arithmetic deciding (AD)
spacetime just when it admits a past temporal string of disjoint open regions
⃗O = ⟨Oj|j ≥0⟩with each Oj an SADj+1 region.
Of course there are many unresolved diﬃculties with this. There is a
recognition problem: how, for example, could one ever recognise an AD
spacetime region if such existed? Let alone one equipped with appropriate
ranks of Turing machines coordinated and ready to go?
We now see how to go beyond Hogarth and observe that there is really
no reason for us to stop at arithmetic. Hogarth has deﬁned regions SADn+1
containing stacked SADn subregions to a ﬁxed ﬁnite depth n. He thus has
used a subset of the class of ﬁnite path trees to label his regions. In the next
deﬁnition
N< N denotes the set of all ﬁnite sequences of natural numbers.
N
N denotes the set of all such inﬁnite sequences from
N to
N.
Deﬁnition
12.4. A
ﬁnite
path
tree
is
any
subtree
(T, <T⟩
of
eT = ⟨eT, < e
T ⟩= ⟨N< N, ⊇⟩where all branches under <T are of ﬁnite length.

Discrete Transﬁnite Computation Models
381
We assign ordinal ranks to the nodes of a ﬁnite path tree (which are
necessarily wellfounded) by recursion:
the rank of T is then the rank
of the empty sequence, (), the topmost node.
A tree is in general in-
ﬁnitely splitting (a given node sequence node u in
N< N may have in-
ﬁnitely many immediate one step extensions), even though all branches
are of ﬁnite length; hence ranks of nodes can in general be inﬁnite, but of
countable ordinal height (for an account of this and the following con-
text, see e.g. [44] Section 15.2).
Finite path trees in general can be
used to describe the construction of the Borel Sets on spaces such as
Nk × (N
N)l for any k, l < ω. A space, taken for simplicity as,
N ×
N
N
has a topology constructed from basic open sets typically of the form
U⟨s,p⟩=df {⟨s, x⟩∈
N ×
N
N | s ∈
N ∧∃k ∈
N(x ↾k = p)} where p ∈
N<N.
Deﬁnition 12.5. (The Borel Hierarchy). (i) X ⊆
N ×
N
N is in Σ0 and in
Π0 if it is a basic open set in the above topology; (ii) X ∈Πξ iﬀcX ∈Σξ;
(iii) X ∈Σξ iﬀX = S
n An where each An ∈Πξn for some ξn < ξ; a set X
is Borel if for some countable ordinal ξ X ∈Σξ.
It is well known that this hierarchy is built up progressively through
ω1 many stages (where ω1 is the ﬁrst uncountable cardinal), and then no
further sets are added (that is Σω1 = Πω1 = Σω1+1). Of particular interest
is the hyperarithmetical hierarchy which is in one sense the constructive
part of the Borel hierarchy. Here the construction of the Borel set is given
by a recursive ﬁnite path tree (meaning the tree T and its extension rela-
tion <T are given by computable functions) with a recursive assignment of
recursively open sets to the bottommost rank 0 nodes, that is to the leaves
of the tree.
Membership then in an hyperarithmetic set of integers (that
is taking l = 0 in the above) is given by testing a recursive protocol of
queries. Already one construal of Hogarth’s AD spacetime region is that
it is capable in the above notation of answering questions concerning some
unions of arithmetic sets, S ∈Σω.
Why ‘some’?
Because the descrip-
tion of the union S
n An must be given to us in an eﬀective, i.e. recursive
way. The upshot is that for any hyperarithmetic set H ⊆
N there could
be constructed a spacetime region SADH for which queries ?n ∈H? could
be answered. Such a region satisﬁes Assumptions 1 and 2 and consists of
SAD regions of smaller rank stacked according to the recursive ﬁnite path
tree description for the construction of H.
A discussion and the details of the above can be found in [56]. Can a
‘hyperarithmetically deciding spacetime’ by analogy with Hogarth’s AD de-
ciding spacetime be constructed? It can, if we can enumerate those Turing
programs that describe hyperarithmetic set building protocols.

382
P. D. Welch
Proposition 12.1. ([56]) If ⟨ei | i ∈
N⟩enumerates those indices of Turing
programs that construct in the above sense hyperarithmetic sets Sei, via
recursive trees, we may deﬁne a single MH ‘hyperarithmetically deciding’,
HYPD, spacetime region in which any query of the form ?n ∈Sei? can be
answered in ﬁnite time.
Here we piece together regions that are ‘Sei-deciding’ just as the AD-
deciding region is built. Given input ⟨i, n⟩to an initial control machine,
it activates Sei and asks if ?n ∈Sei? Of course this query will result in
subqueries activating regions of lower rank down the tree coded by ei which
are themselves Sej-deciding etc.
At this point the reader will, I think, object that the recognition prob-
lem has now got well out of hand: the collection of indices ⟨ei | i ∈
N⟩
enumerating hyperarithmetic set constructions is itself well beyond recur-
sive or arithmetic, forming as it does a Π1
1-complete set of integers. However
it is worth emphasising that no machine in this tree array is itself perform-
ing ‘supertasks’ (i.e. performing inﬁnitely many actions in its own proper
time), but if it issues a signal to another process, it does so only once af-
ter a ﬁnite amount of its own proper time. It is simply that the overall
tree no longer has a recursive description, and its ordinal rank is no longer
a recursively given ordinal. We have not violated our two core assump-
tions. However the point should be that anthropomorphic considerations
are being put aside and we are calculating what is feasible given the kind
of techniques Hogarth contemplates. We have here what might be called a
hyperarithmetic computer.
12.2.1.4. A universal constant upper bound for any computation
Nevertheless if we take this discussion to its logical conclusion, one might
ask, How far could one possibly go building regions of higher and higher
complexity without violating the core idea?
There is in any case a bound on the depth of any ﬁnite path tree to
which we can assign MH regions without violating Assumption 2.
Deﬁnition 12.6. Let M = (M, gab) be a spacetime. We deﬁne w(M) to
be the least ordinal η so that M contains no SAD region whose underlying
tree structure has ordinal rank η.
Note that 0 ≤w(M) ≤ω1.
Here a zero value w(M) implies that M
contains no SAD regions whatsoever, that is, is not MH; the upper bound

Discrete Transﬁnite Computation Models
383
is for the trivial reason that every ﬁnite path tree is a countable object and
so cannot have uncountable ordinal rank.
Proposition 12.2. ( [56]) For any spacetime M, w(M) < ω1.
Proof.
Assumption 2 says that for diﬀerent η the diﬀerent SADη com-
ponents must occupy disjoint open regions Oη of the manifold. However
the manifold is separable (which follows from paracompactness and being
Hausdorﬀ). Let X ⊂M be a countable dense subset of M. Then each
open region Oη of M contains members of X. As disjoint regions contain
diﬀering members of X there can only be countably many such regions
Oη ⊂M, and therefore a countable bound.
□
This is just the usual argument that separability of the real continuum
R implies that any family of disjoint intervals of
R must be countable.
Consequently if Mactual is our spacetime, (modelled using these basic as-
sumptions) then w(Mactual) is a constant giving an upper bound to the
complexity of MH regions, and so putative computations performable in
Mactual. Dropping either of the Hausdorﬀor paracompactness properties
from our list of properties of manifolds would seemingly result in unrecog-
nisable (in current terms) ‘spacetimes’. In short, although MH-spacetimes
allow, at the most generous, for a reorganisation of any countable length
computation (in some formalism, such as Turing machines) into one compu-
tation using trees of countable depth, this would be impossible for uncount-
ably long (or many) computations whose stages occupy discrete spacetime
regions. The same restriction would of course be true for any other system,
or arrangement, of computations and is nothing to do with Hogarth style
formalisations: this holds for any separable manifold and any generalised
computation that requires a disjoint region of spacetime for each step or
unit of computation. Somewhat more formally:
Proposition 12.3. Let M = (M, gab) be a spacetime.
Let F be some
formal mechanism of computation, such that each computation step of
the mechanism occupies a disjoint open neighbourhood of the manifold.
Then there is a countable upper bound w(M, F) to the lengths of the F-
computations in M.
The proposition is not a completely precise mathematical statement,
since we have not deﬁned ‘formal mechanism’, but the point we hope should
be clear. We have not speciﬁed ‘step’ or ‘unit’ but again this can mean a

384
P. D. Welch
Turing machine instruction step, or a cell unit. Anything that occupies a
discrete interval in spacetime, whether it be an MH-spacetime, (so as to
avoid supertask like phenomena), or in other spacetimes more generally
with supertasks envisaged: one cannot in advance arrange the formalism
to occupy uncountably many distinct open neighbourhoods.
Hence the
bound. If we are allowed to play God and are handed a separable manifold
and (a set of integers coding) a countable ordinal α, in advance, then indeed
we could cook up an MH manifold to accommodate computations of that
length (of proper time), using stacked Turing machines, or any other form
of computational model F. What we cannot have is one manifold M that
will work for our chosen F for all countable α.
12.2.2. Allowing supertasks
By means of using spacetime regions of a particular type the Etesi–N´emeti
and Hogarth models avoid considering any supertasks, where any observer
has performed inﬁnitely many tasks in his or her chronological past.
If
we relax this constraint we may ask of our computing machines what they
are capable of when given some well-deﬁned behaviour in the transﬁnite.
Amusingly even simple machines can perform a lot.
12.2.2.1. Punch-hole machines
We ﬁrst consider a simple kind of Turing machine. We envisage such a
machine as having a tape, inﬁnite in one direction, thus with a leftmost
starting cell, and a read/write head traversing the tape in the usual fashion.
The alphabet of the machine is simple: it consists of a blank and a ‘0’. The
latter we can think of as a hole that the machine punches. Thus the machine
can only write once, or punch a hole, in a cell; otherwise it ‘reads’ and moves
a cell left or right in the usual fashion. The program or transition table for
such a machine is simply that of an ordinary machine of this architecture.
We have to specify what happens at stage ω and subsequent stages.
There are several possibilities: but let us say that we simply allow the
machine to run for ω many stages, then consider what is on the tape (a
potentially inﬁnite sequence of holes and blanks) as input to be fed back
into the machine at its starting state again for the next ω many stages. We
thus reset the R/W head to ﬁrst leftmost cell, and let it run the program
afresh.
So, ignoring diﬃculties with ‘hanging chads’, such cells are usable once
only. One easily sees that in ω steps again ∆2, or trial-and-error predicates

Discrete Transﬁnite Computation Models
385
are decidable. One may simply arrange that any new calculation extends
beyond the scratch area of tape already used up. If one has a ∆2 predicate
P(v0) it is not hard to arrange this so that a machine will punch holes
(using additional blank gaps) on an output ‘sub-tape’ so that the correct
ﬁnal 0/1 value is recorded. Now we have allowed the possibility to reset the
head to its starting position, and let the machine continue running. We let
ourselves do and re-do this process, at every limit stage in time, pulling the
head back to the start position and letting it work on the accumulated tape-
full of punch-holes. Could we calculate more? For which predicates P(n)
of natural numbers n is there a machine of this kind that halts for a given n
with the correct P(n)\¬P(n) answer? These machines were ﬁrst considered
by Hamkins and Kidder but they discarded them as too weak, in favour
of the Inﬁnite Time Turing Machine to follow. Surprisingly perhaps, they
can still calculate quite a lot: we have the following observation (due to
S.D. Friedman and the author). Calling the above arrangement an ‘inﬁnite
punch tape machine’, it is not hard to demonstrate:
Proposition 12.4. (i) Precisely the arithmetical predicates are decidable
by inﬁnite punch tape machines; (ii) any computation either halts by, or is
in an inﬁnite loop, by time ω2.
12.2.2.2. Inﬁnite Time Register Machines (ITRMs)
Koepke and Miller [34] consider the following register machine model. MN
is a Shepherdson-Sturgis register machine (see [47], or as described in, e.g.
Cutland [6]).
MN has N registers Ri(i < N) each of which may con-
tain a natural number.
Suppose that the program under consideration
has instruction set ⃗I = I0, . . . , Iq. Let us say that at time t Ri contains
Ri(t) ∈
N, and that instruction I(t) is about to be performed. We adopt a
slightly more subtle behaviour than that for the punch-hole machines. We
consider the state list q0, q1, . . . , qp of the machine and at time λ where λ is
any limit ordinal, we say that the machine will next perform the instruction
numbered I(λ) =df lim infα−→λ I(α) where I(α) is the instruction number
about to be performed at time α. This formulation has the rather pleasant
eﬀect of placing the machine at time λ, at the start of the outermost nested
loop that it entered (if any) unboundedly often before time λ.
We have to assign register values, and here of course a register may have
changed value inﬁnitely often.
For i < N we set:

386
P. D. Welch
Ri(λ) =df lim infα→λ Ri(α) and if this is ﬁnite we set Ri(λ)= ¯Ri(λ). If
inﬁnite we set Ri(λ) = 0.
It is this ‘resetting’ of a register that gives the model its strength. We
may additionally consider such a machine to be able to consult an oracle:
thus there is an instruction, so that if Z ⊆
N, a register can be reset to 0
if Ri(α) ∈Z. Computations relative to an oracle Z can be regarded in this
manner as using the set Z as an input; the inﬁnite time available allows
all of Z to be consulted. We discuss the strength of this model below, but
again surprisingly complicated predicates can be calculated.
12.2.2.3. Inﬁnite Time Turing Machines (ITTMs)
This model, due to Hamkins and Kidder, awakened recent interest in trans-
ﬁnite computational models. It was designed in the 1990s but an account of
them only appeared in [15] much later. We give a computationally equiv-
alent version to that of their original model – and discuss the diﬀerences
afterwards.
We go back to the punch-hole machine described above, but we now
consider what to do if the machine is allowed to reuse cells. Clearly a cell
may then be reused inﬁnitely often and we must deﬁne a behaviour for it.
We consider Turing machines with an alphabet of just three letters: 0,1 and
B (for blank). We suppose that its standard program has states q0, . . . , qk.
The read/write head moves according to the description given by the usual
transition table, but that also uses the liminf of cell positions that it has
been reading at limit stages of time to calculate its position at a limit stage,
(if this liminf of the read/write head positions is inﬁnite at a limit stage,
then the head is set back by ﬁat to the starting cell C0). Further, we set
the state q(λ) at limit times to be the liminf of previous states. (This has
the same eﬀect of course of positioning the read/write head at outermost
loops as it did for ITRMs.)
If the cells of the machine are enumerated
⟨Ci | i ∈
N⟩with values at time ν denoted by ⟨Ci(ν) | i ∈
N⟩then we set
at limit time λ:
Ci(λ) = k ⇐⇒∃α < λ∀β < λ(α < β −→Ci(β) = k)for k ∈{0, 1,B};
Otherwise Ci is set to a ‘B’.
Thus if the machine has changed its mind unboundedly often below
λ about the cell value then, this is set to a blank – for ambiguity if you
will.
Programs, are simply standard Turing machine ones, and may be

Discrete Transﬁnite Computation Models
387
enumerated as ⟨Pe | e ∈
N⟩. If a particular program Pe halts, then we can
consider the contents of the tape the output of that machine. We may also
prime the tape with an inﬁnite string x from the alphabet, and consider
Pe(x) to be the computation of the e’th program on input x.
Such machines can decide Π1
1-predicates. We illustrate by means of the
complete Π1
1-predicate on integers: those e ∈
N so that the e’th (stan-
dard) recursive function, {e} = f, computes the characteristic function of a
wellorder of
N. Given input e the machine simulates the e’th standard Tur-
ing program and writes the output characteristic function on, say the cells
of the tape Ci where i ≡0(mod 3). The other cells are blank for scratch
work. This takes ω many stages. When this is complete, the machine then
checks the Π2-condition of this characteristic function f coding a discrete
linear ordering. (This is of the form ∀n∃mR(n, m, f) and R is recursive.
This can be veriﬁed in ω steps, by starting with n = 0, recording ‘0’ on
the scratch tape cells Ci where i ≡1(mod 3) , searching for an m, using
the scratch tape cells
Ci where i ≡2(mod 3), for auxiliary calculation,
then proceeding to n = 1 if successful, etc.) If this test is passed, we have
an order <e; we then need to test for wellorderedness. We wipe clean the
scratch tape area, and search for the <e’th least element of the ordering.
We may do this by simply guessing a least element on a scratch tape, and
then continually revising our guess <e-downwards each time we ﬁnd a lesser
one. If after ω many steps we did not ﬁnd such then we did not have a
wellorder, and we can output a 0; if after ω many steps we only changed
our minds ﬁnitely often, then we indeed located the <e-least element, say
it was 23, and we have it written concretely on the scratch tape. We now
proceed through the code function f and erase all mention of the element
23. This leaves us with a new code f ′ of a discrete linear order written
on the cells ⟨C3i | i ∈
N⟩, and we simply now repeat this process. There
are only two outcomes: either at some point we arrived at the situation
where the ‘current’ linear order is illfounded, and we discover this fact, by
descending through it inﬁnitely often looking for its least element, or else
we end up emptying out the C3i cells for i ∈
N completely: after looking
through this slice of the tape, and seeing it is empty (which takes a ﬁnal ω
many steps) we verify that it was truly wellfounded. If the order type of the
ordering was α then this has been achieved in, rather roughly, ω + ω.α + ω
many steps.
Once the reader has convinced themselves of this, it is not hard to
imagine programs that write out successfully on some slice of the scratch
tape (which we might as well call ‘output tape’) those ei with {ei} ∈WO.

388
P. D. Welch
Moreover, one can also imagine a machine coding the ordinal sum of all
the recursive ordinals α < ωck
1 and outputting a code for that, i.e. ωck
1 , on
the output tape. However as Hamkins and Lewis showed, and we shall see
later, this is only scratching the surface.
Suppose we denote by Pe(n) the e’th computation on integer input of
n, represented by an inﬁnite string of n 1s followed by an inﬁnite string of
0s. Several natural questions arise:
Q1 What is 0∇= {e|Pe(0) ↓}? (The halting problem on integers).
Q2 What are the halting times that arise? That is, if Pe(0) ↓halts in
α steps how large is α?
Q3 What are the decidable predicates? Where we say R(n) is
semi-
decidable if there is some e so that R(n) ↔Pe(n) ↓1, and is decidable if
both it and its complement are strongly semi-decidable.
Hamkins and Lewis [15] ﬁrst developed the theory of such machines,
using the analogy of the standard Turing machine as a source of the notion
of recursion: they note that there are versions of the Recursion Theorems,
and the Snm-Theorem for this notion of computation and there is a univer-
sal machine with a universal program. Much of the standard development
proceeds very smoothly but of course there are considerable diﬀerences: for
Turing machines the whole run of a halting computation, the snapshots of
the states and of tape’s contents etc. can be encoded by an single integer;
it is thus of the same type as the objects on which it operates. However for
ITTMs, computations Pe(n) on integer input, are in general a transﬁnite
sequence S = ⟨Sβ | β ≤α⟩of snapshots of the cell values ⟨Ci(β) | i < ω⟩
at each stage β ≤α. A computation is then an inﬁnite object and must be
coded in this context by a set of integers or a ‘real’ number. (One uses reals
that code wellorderings of length α + 1 and attaches by pairing functions
the snapshots to the nodes of the wellorder, together with any auxiliary
information such as machine state etc. along the way). Computations are
thus of diﬀerent types from the integer inputs. A central representation
of standard Turing machines comes via Kleene’s T -predicate, yielding a
canonical Normal Form Theorem. This theorem allows one to proceed ef-
fectively from e, and uniformly in n, from a halting computation of the form
Pe(n) ↓to a program e′ so that Pe′(n) ↓will halt, and moreover produce an
integer output which codes the whole course-of-computation that demon-
strates Pe(n) ↓. For such a notion to work in this new area we should need
the program Pe′ to be capable of producing the reals needed to code the
potentially transﬁnitely many steps in calculations such as that of Pe(n) ↓.
But are they capable of this? In short, Is every ordinal length of a halting

Discrete Transﬁnite Computation Models
389
computation on an integer input capable of being itself ‘written’ or being the
output of some other computation?
This must be true if we are to have a
hope of producing a Normal Form theorem. Hamkins and Lewis called the
halting time ordinals the clockable ordinals, and the question they asked is:
Is every clockable ordinal writable?
The answer turns out, thankfully, to be aﬃrmative, (it follows from the
λ, ζ, Σ-theorem below, [54]). We refer the reader not to the original papers,
but to [57] for a later but somewhat tidier account of this theorem and the
answers to the above three questions.
From this one gets the desired representation theorem (where Pe(n)
refers to ITTM computation).
Theorem 12.2. (Normal Form Theorem I) (Welch [55, 57]) ∀e∃e′∀n ∈
N
Pe(n) ↓−→(Pe′(n) ↓y where y ∈2
N codes a wellordered course-of-
computation sequence for Pe(x) ↓).
Moreover the map e −→e′ is eﬀective (in the usual Turing sense).
There is a higher type version obtained by relativising all the results
(now for λx, ζx etc.) above to real number inputs. Part (b) below is simply
a variant form stated to be reminiscent of the Kleene T -predicate. We let
ϕe be the (partial) function computed by Pe.
Corollary 12.1. (Normal Form Theorem II) (a) For any ITTM com-
putable function ϕe we can eﬀectively ﬁnd another ITTM computable func-
tion ϕe′ so that on any input x from 2
N, if ϕe(x) ↓then ϕe′(x) ↓y ∈2
N,
where y codes a wellordered computation sequence for ϕe(x). (b) There is
a universal predicate T1 which satisﬁes ∀e∀x:
Pe(x) ↓z
↔
∃y ∈2
N[T1(e, x, y) ∧Last(y) = z].
The eﬀectivity is again established in the same way, noting that the
input (whether n ∈
N or x ∈2
N) does not aﬀect the above description of
an algorithm in any dynamic way.
However the proof that all clockable ordinals are writable proceeds via
an analysis of how each single cell Ci behaves during the course of a compu-
tation Pe(n). In general cells may stabilize on some ﬁxed value, or forever
change value. The same is true for inﬁnite sub-segments of the ITTM tape.
Suppose we reserve cells Ci (i ≡2 mod 3) for ‘output’ then we say that
a real y ∈2
N is ‘eventually computable’ if there is an ITTM computation
Pe(n) – which is not required to halt – but which has y as the characteristic

390
P. D. Welch
function of the output tape from some point in time onwards. The notion
is then that a computation need not formally halt in order to ‘produce’ an
output: it is suﬃcient that the output tape segment be stable from some
point onwards. Hamkins and Lewis called an ordinal α eventually writable,
if there was an eventually computable yα ∈2
N coding α. Clearly we can
consider any halting computation a special case of an eventually stable one,
and thus if λ is the supremum of all writable ordinals, and ζ the supremum
of the eventually writable ordinals then λ < ζ. Evaluating λ, ζ turned out
to be tied up with calculating stabilisation points of cells Ci in the universal
machine calculations, and the following characterisation is possible.
Theorem 12.3. (The λ, ζ, Σ-theorem) (Welch [57]) (i) Any ITTM com-
putation Pe(n) on integers which halts, does so by time λ, the latter deﬁned
as the supremum of the writable ordinals;
(ii) any computation Pe(n) with eventually stable output tape, will stabilise
by time ζ the supremum of the eventually writable ordinals;
(iii) moreover ζ is the least ordinal so that there exists Σ > ζ with the
property that
Lζ ≺Σ2 LΣ;
(iv) then λ is the least ordinal satisfying:
Lλ ≺Σ1 Lζ.
We thus have a clear picture of the action of ITTM computations on
integers. The machines run using very constructive rules, even for the limit
stages, so their action is of course absolute to G¨odel’s constructible universe
L. As [15] had noted, if an ITTM machine has its hands on a real y coding
an ordinal α then there is a standard Turing machine program for using
that code to run a construction of the L-hierarchy ‘along’ that ordering
y, thereby producing a real code for the α’th level Lα. Hence the tie up
with L is natural. A further observation on the λ, ζ, Σ-Theorem is in order.
The machine limit rules of liminf can be expressed in a Σ2 way. If one
has two levels of the L hierarchy satisfying Lζ′ ≺Σ2 LΣ′ then running the
universal machine inside L it is pretty much immediate that the machine’s
snapshots at time ζ′ and Σ′ will be identical: this is what the elementarity
entails. The machine will then either have halted, or, as one can show, has
entered an eternally repeating loop (although the elementarity assumed is
suggestive of this, in fact the latter still has to be shown). It turns out the
pair (ζ, Σ) is the lexicographically least pair of ordinals where the universal
machine has identical snapshots, and ﬁrst enters an inﬁnite loop.

Discrete Transﬁnite Computation Models
391
What further seems to emerge from the proofs above, is that the pri-
mary notion here is not that of a ‘halted computation’ but of a ‘stable
computation’: there are computations of the form Pe(n) which do not for-
mally halt, but eventually have a settled output tape, and thereafter just
footle around for ever on their scratch tape areas. Halting is just a special
case of stabilising, and this is borne out by the fact that we cannot fully
analyse halting computations without analysing stabilising ones. Halting
can be expressed by a Σ1 statement in set theory (‘There exists a real y that
successfully codes the course of computation of Pe(n) with a last halting
state’); this is at the basis of the Σ1 characterisation of λ in the λ, ζ, Σ the-
orem as Lλ ≺Σ1 Lζ, once we have discovered ζ. We may further establish
theorems corresponding to those for halting computations.
The reader may have noticed that we seem to be avoiding discussion
of the obvious fact that ITTMs can work on inﬁnite input as well have
inﬁnite output: such computation is thus on one type up, on that of sets of
integers, or reals themselves, rather than merely on integers. Before we turn
to this we emphasise that Hamkins’ and Kidder’s original formulation of an
ITTM immediately visualised such capabilities: their machine was devised
as coming equipped with three inﬁnite tapes, for input, scratch and output.
A single read/write head surveyed a single cell from each of the three tapes
simultaneously and according to its state and program, would write from an
alphabet set of {0, 1}. At limit stages a cell Ci’s value was determined by
taking the limsup of the previous cell values (there was no Blank character);
the read/write head at limit stages would be brought back to the very ﬁrst
triplet of cells on the tapes, and the machine would enter a special ‘limit
state’ qL.
The diﬀerences between this arrangement and that sketched
above play no role in determining the classes of functions or sets computed
(either on integers or on reals, which we are coming to): they are the same
for either model. There are minor diﬀerences in calculating halting times,
and in precisely which classes of ordinals are clockable often by an obvious
factor of ω or so, but apart from these ﬁner details there are functionally no
diﬀerences between the models proposed. (This discussion does conceal one
remark, that in fact, a one tape machine with two symbols cannot produce
the same class of computable functions f :
R −→
R. However for functions
of type f :
R −→
N or f :
N −→
N a one tape two-alphabet machine turns
out to be suﬃcient. For the wider class curiously a third character – which
we have introduced here by the way of the Blank above – turns out to be
necessary. See [17] for a discussion of this somewhat technical point and
proofs of these results mentioned.)

392
P. D. Welch
12.3. Computation on Reals
Kleene developed an equational calculus for developing the notion of recur-
sion in a higher type object (see [30], [26], [29]). The relevant type here is
Type 2, the objects under consideration are functionals I :
N
N −→
N. This
generalised his earlier equational calculus for (standard) recursive functions
that used (characteristic functions for Type 1) oracles, I :
N −→
N. The
intuitive notion of a functional F being computable relative to I is that
we have some kind of machine that can take inputs in the form of (ﬁnite
sequences) of integers and reals, ⃗n, ⃗x, and which is connected to some ora-
cle/memory device that has access to the graph of I – itself a set of size the
continuum. As the domain of I is
N
N, the machine must compute a real x
to present to the oracle, which will return I(x). Thus an inﬁnite amount of
computation must be performed in some scratch/storage area before this
oracle query can be launched. A computation will thus in general be of
inﬁnite length, but is perhaps better thought of as given by an inﬁnite tree
where, for example, there may be inﬁnite branching nodes: below the call
for I(x) will be the prior individual computations for x(0), x(1), . . . . An
illfounded tree, that is one with an inﬁnite descending path, represents an
undeﬁned computation. There is some discussion of this in Rogers ([44], p.
406), where there is no oracle I discussed but where the allusion is to an
“ℵ0-mind’ capable of forming such generalised machine computations. A
crucial point is that a generalised computation step must only be allowed to
take previously, inductively, deﬁned generalised steps. The resulting notion
is ‘hyperarithmetic computability’. (See also here [28], [27].)
With the addition of the oracle I it can thus be loosely characterised
([24]) as a model of computation in which the computational device has a
(i) countably inﬁnite memory; and
(ii) an ability to manipulate (search through, write to) that memory in
ﬁnite time; and optionally
(iii) an ability to quiz an oracle I about that memory contents (in a
single step).
If the above is all done within the e’th program we call the above com-
putation {e}(⃗n, ⃗x, I) which again, may or may not halt.
The following
functional is essential for developing much of the regular theory of relative
recursiveness:
E(x) =
0 if ∃nx(n) = 0;
1 otherwise.

Discrete Transﬁnite Computation Models
393
The immediate import of this is that computation relative to the object
E is closed under existential number quantiﬁcation (for any I the class of re-
lations semi-recursive in I is closed under universal number quantiﬁcation).
A second eﬀect is that:
• If A is an arithmetical set of reals then A is recursive in E.
More important consequences follow: if I is any functional such that E
is recursive in I, then we have the full Ordinal Comparison Theorem for
stages of computation (see [39]) which is crucial for developing the theory
of relations semi-recursive in a Type-2 functional. By ‘relation’ in the next
theorem, we mean any predicate R(⃗n, ⃗x) ⊆
Nk × (N
N)l for k, l ∈
N. We
thus arrive at the notion of Kleene Recursion.
Theorem 12.4. (Kleene) The hyperarithmetic relations are precisely
those recursive in E.
The Π1
1 relations are precisely those semi-recursive in E.
If we are considering relative recursion of a set of reals A ⊆
R in a set of
reals B (which we may identify with its characteristic function oracle IB)
we may denote such:
x ∈A ≃{e}(x, B, E) ↓1
and say that ‘A is recursive in B’ if {e} gives a function total on inputs x,
and then one has appropriate versions of the above theorem relativised to
B. There is an appropriate notion of Kleene Degree:
Deﬁnition 12.7. (Kleene degrees) Let A, B ⊆
R; we say that
A ≤K B iﬀthere is an index e and a real y so that
for any x ∈
R (x ∈
/∈A ←→{e}(x, y, B, E) ↓1
0);
A is Kleene-semi-recursive in B iﬀthere is an index e and a real y so
that
for any x ∈
R (x ∈A ←→{e}(x, y, B, E) ↓1).
The presence of the ﬁxed real y ensures that the degree class of B con-
tains continuum many sets of reals A; moreover the degree of B, being thus
closed under continuous pre-images, forms a so-called Wadge degree. In
general a computation evolves its own tree structure as it grows, according
to its instruction set. But one can think of y as also contributing to some
part of the computational tree structure. In this case, as y is allowed to
vary, we see that 0K contains ∅,
R, and in fact consists of the Borel sets.
0′
K (the K-degree of a complete Kleene semi-recursive set of reals) contains
WO, the set of reals coding wellorders, and so a complete Π1
1 set of reals.
In fact it consists of all the co-analytic, so precisely the Π1
1, sets.

394
P. D. Welch
It is possible to give a set theoretical description of Kleene recursion
in a relation B and E. In what follows, ωB,y,x
1 ck
denotes the least ordinal
which does not have a real code recursive in (B, x, y); it turns out that
the wellfounded computation tree of a converging Kleene recusion will have
rank less than ωB,y,x
1 ck . This is the basis of the following characterisation: we
only need to look inside a model with enough ordinals – namely ωB,y,x
1 ck
– to
see whether the computation tree is wellfounded. Moreover, in admissibility
theory wellfoundedness of any relation inside a transitive admissible set is
actually a Σ1-notion. Here L∈, ˙X is the language of set theory augmented
by a predicate symbol ˙X – to be interpreted by B.
Lemma 12.1. A ≤K B iﬀthere are Σ1-formulae in L∈, ˙X ϕ1( ˙X, v0, v1),
ϕ2( ˙X, v0, v1), and there is y ∈
R, so that for any x ∈
R
x ∈A ⇐⇒LωB,y,x
1
[B, y, x] |= ϕ1[B, y, x]⇐⇒LωB,y,x
1
[B, y, x] |= ¬ϕ2[B, y, x].
Thus to determine whether x ∈A/x /∈A we perform Σ1-searches
through the least admissible set LωB,y,x
1
[B, y, x] relative to B containing
y, x.
As intimated equivalence with the former deﬁnition comes about
through the original (relativised) theorem of Kleene (Theorem 12.4) and
the theory of admissible sets (cf.
[1]).
The generalised theory of recursion in higher types was much investi-
gated and developed in the late 1960s and 1970s, with a history too rich
to go into here, with names such as Gandy, Moschovakis, Sacks, Grilliot,
Fenstad, Normann, Moldestad, Harrington prominent. The recursion rela-
tive to the single operator E is in one respect merely illustrative, being the
historical example from the earlier days and papers ([26], [29], [30]) of the
Kleene Equational Calculus. The reader may consult Hinman [20] for an
overall development of the theory, Fenstad [13] for an attempt to present
an axiomatic approach to general computation theories and the latter Part
D of Sacks [45] for the further development in relation to set recursion.
Mention must now be made of the connections to the theory of inductive
deﬁnitions and here more particularly to the theory of Spector classes. The
latter is a general unifying theory of deﬁnability developed by Moschovakis
in [39]. We consider here just pointclasses Γ ⊆
Nk×(N
N)l (for any k, l < ω)
and use the notation that ˘Γ = {¬R : R ∈Γ}. ∃
N, ∀
N represent natural
number quantiﬁers as opposed to ∃
N
N, ∀
N
N over elements of
N
N.
Deﬁnition 12.8. A Spector class of pointsets Γ ⊆
Nk × ( N
N)l for any
k, l, is a collection that is (i) closed under ∩, ∪, number quantiﬁcation: ∃
N,

Discrete Transﬁnite Computation Models
395
∀
N; closed under (standard) recursive substitutions, has a universal set U
indexing by
N all members of Γ and lastly has the Prewellordering property:
PW: For any P ∈Γ there is σ : P −→λ for some ordinal λ with the
property that there are relations: x ≤σ
0∈Γ, x ≤σ
1 y ∈˘Γ so that:
P(y) ⇒(∀x[P(x) ∧σ(x) ≤σ(y)] ⇐⇒x ≤σ
0 y ⇐⇒x ≤σ
1 y).
It would be impossible to give a full exposition of the import of Spector
pointclasses here, but suﬃce it to say that the deﬁnition above encapsulates
a fundamental unifying approach to the theory of inductive deﬁnability.
Familiar Spector pointclasses are Π1
1 and Σ1
2 but there are many others.
For Σ1
n or Π1
n the existence of the prewellordering property depends on the
surrounding set theory in which one works. We shall only be discussing
Spector pointclasses within ∆1
2 = Π1
2 ∩Σ1
2. The Kleene recursion theory
then throws up a canonical example of a Spector pointclass: the Kleene
semi-recursive (in E) sets are precisely the Π1
1 sets.
The type of formalism on the right-hand side equivalences of Lemma
12.1 in fact is also one way of deﬁning Spector classes within the ∆1
2 point-
class.
12.3.1. ITTM computations on reals
If we now return to the ITTM model we shall see that it ﬁts very nicely into
this overall general theory. We have a choice to make here. At Q3 above
we called the decidable predicates, those where a characteristic function of
the predicate could always be computed by a halting computation. It is
natural, particularly given the machine nature of the origins of the notion,
to think of halting as somehow fundamental, and therefore it is this that
should be used to characterise ‘decidability’. However here we are adopting
the position that the fundamental feature of the ITTMs is the Σ2 nature of
the limit rule for the cell values, and the concomitant phenomenon of their
having stabilised output without halting; it was indeed from this stabilising
and looping times, from ζ and Σ, that we could characterise the halting
times. The halting computations are for this purpose to be regarded as the
special sub-class of ‘fully stabilised’ computations: halting is just a special
kind of stabilisation (sic). This position is further strengthened when we
consider below its relation to previous notions of higher type recursion.
We stated the Normal Form Theorems in the stronger, halting, version,
as these would be more familiar to the reader, but there are equally well
Normal Form Theorems which are verbatim as above but with ↓replaced

396
P. D. Welch
by ↑throughout. The viewpoint here is that the strongly stabilising, i.e.
halting, computations should probably be thought to give rise to a notion
of strong decidability (and strong semi-decidability) whilst the stabilising
computations correspond to the notion of decidability and semi-decidability.
However most papers distinguish the ‘stabilising’ form, with the adverb
‘eventually’, used in the form: ‘eventually (semi)-decidable predicates’ or
adjectively as in ‘eventual ITTM degrees’ etc. This is established enough
that it would egregious to go against it here.
However for notions from higher type recursion theory, one says in gen-
eral that a class of ‘semi-decidable sets are those semi-recursive in a F’
where the latter F is some higher type functional. Then, for the appro-
priate F for ITTMs, actually ‘semi-recursive in F’ would correspond to
the stabilising behaviour rather than the halting one. This would also ac-
cord with the usage inherited from Kleene Recursion. We shall call here
then ‘ITTM-semi-recursive’ those predicates where membership facts can
be represented as the stable output of some program, and thus correspond-
ing to ‘eventually semi-decidable’ in the literature. (For diﬀerent classes
of machines such as the Σn-machines mentioned below, the notion of ‘out-
put’ becomes somewhat more rariﬁed, but these too one we would like
to think of as providing mathematical classes of sets that are generalised
(semi-)recursive in some way.)
It is a conceptually simple adjustment to have within an ITTM program
an oracle call that requests of some oracle B ⊆
R (here 2
N) whether the
current contents of the scratch tape, y ∈2
N, is an element of B, and
receive a 0/1 reply.
Thus computation relative to an oracle for sets of
reals is unproblematic. We again adopt the same notation that P B
e (x) ↓y
if the e’th machine with oracle B, on input x ∈2
N halts with output
y ∈2
N. Changing the arrow to P B
e (x) ↑y indicates that eventually y is
written to the output tape, and remains there unchanging from some point
on. (We have to have some other notation such as ‘P B
e (x) |’ for when the
computation diverges or is undeﬁned.)
We ﬁrst give the integer version.
Deﬁnition 12.9. (i) A set of integers x is ITTM-semi-recursive in a set y
if and only if:
∃e∀n ∈x [P y
e (n) ↑1 ←→n ∈x ] ;
(ii) A set of integers x is ITTM-recursive in a set y if and only if:
∃e∀n ∈x [P y
e (n) ↑1 ↔n ∈x ∧P y
e (n) ↑0 ↔n /∈x] .

Discrete Transﬁnite Computation Models
397
We may write x ⪯∞y for the reducibility ordering.
Equivalently: x is ITTM-recursive in y if both x and ¬x are ITTM-
semi-recursive in y (since if the latter holds it is easy to amalgamate the
two programs into a single program Pe with the eﬀect of the Deﬁnition.
The relation ⪯∞is in the class ∆1
2.
There is a natural prewellordering
that arises on computations Pe establishing membership in some set x: put
n ≺m if the computation Pe(n) ↑1 stabilises to an output of 1 before
that of Pe(m) ↑1 does. The relation ≺is itself ITTM-semi-recursive (think
of the universal machine that observes the simulated copies of computa-
tion sequences of Pe for various n – eventually it itself will stabilise into
seeing that Pe(n) stabilises before Pe(m)) and thus we can establish the
prewellordering property very easily.
There is a natural notion of complete ITTM-semi-recursive set of inte-
gers:
Deﬁnition 12.10. ˜x =df {e | Pe(0) ↑} – the complete set of stable indices.
The following tells us what this set is by way of a set theoretic charac-
terisation. We regard x ֌ ˜x as an analogy to the hyperjump operation.
Theorem 12.5. (Welch [54]) ˜x is (Turing-)recursively isomorphic to the
Σ2-theory of ⟨Lζx[x], ∈, x⟩. In particular ˜0 is recursively isomorphic to the
Σ2-theory of ⟨Lζ, ∈⟩.
This should be compared with Kleene’s result that his notation system
set O – a complete Π1
1 set of integers coding indices of wellfounded ﬁnite
path trees – is in fact (Turing-)recursively isomorphic to the Σ1-truth set
of ⟨Lωck
1 , ∈⟩. Indeed Klev has deﬁned in [31] an extension of Kleene’s O to
an O++, that mirrors exactly Kleene’s original deﬁnition as a tree (indeed
the tree is literally an extension of Kleene’s). By the above, it is thus to
the complete Σ2(Lζ) set what O is to Σ1(Lωck
1 ).
The following is the natural version for real computation:
Deﬁnition 12.11. A set of reals A is ITTM-semi-recursive in a set of reals
B if and only if:
∃e∀x ∈2
N 
P B
e (x) ↑1 ↔x ∈A

;
(ii) A set of reals A is ITTM-recursive in a set of reals B if and only if:
∃e∀x ∈2
N 
P B
e (x) ↑1 ↔x ∈A ∧P B
e (x) ↑0 ↔x /∈A

.

398
P. D. Welch
Deﬁnition 12.12. A ≤∞B iﬀfor some e ∈ω, for some y ∈
R : A is
ITTM-recursive in (y, B).
Notice in the above that we have included a parameter real y to ensure
the closure under continuous preimages as before.
This will ensure we
have Wadge pointclasses and that the ensuing notion of ≤∞-degree with
the degree ordering induced, will be wellfounded.
The structure of this
degree ordering is dependent on the ambient set theory – we shall not
go into this now, but under the assumption of ‘suﬃcient Determinacy’
(that of two-person perfect information games of suﬃcient complexity in
their payoﬀsets) we shall have that the degrees are wellordered; under
the assumption of V = L the ordering of ≤∞degrees is very diﬀerent,
and below the complete ≤∞-semi-recursive set of reals there are plenty
of ≤∞-incomparable sets (and hence Post’s problem has a rich positive
solution); whilst under ‘suﬃcient determinacy’ assumptions, there are no
intermediate degrees at all. This was to be expected, and serves only to
conﬁrm the position of the pointclass of ITTM-semi-recursive sets as one
within the totality of the Wadge ordering of all reasonable pointclasses of
sets of reals. See [55] for a further discussion and results.
By analogy with Kleene recursion we have:
Lemma 12.2. A ≤∞B iﬀthere are Σ2-formulae in L∈, ˙X ϕ1( ˙X, v0, v1),
ϕ2( ˙X, v0, v1) and y ∈
R, so that for all x ∈
R
x ∈A ⇐⇒LζB,y,x[B, y, x] |= ϕ1[B, y, x] ⇐⇒LζB,y,x[B, y, x] |= ¬ϕ2[B, y, x].
The lemma then identiﬁes structures in which we can look to ascertain
the outcomes of our ITTM computations relative to a set of reals B, say.
By way of analogy with ζ, the ordinal ζB,y,x is the least that is not ITTM-
(B, x, y)-recursive.
It is thus also least such that LζB,y,x[B, y, x] has a
proper Σ2-elementary end-extension.
12.4. Computation on Ordinals, and Ordinal Length Ma-
chines
In the 1970s the theory of α-recursion coming out of the meta-recursion
of the 1960s reached its highest stage of development.
The observation
that an enumeration of a Π1
1-complete set of integers was very naturally
eﬀected, not in ω, but in ωck
1
(the least non-recursive ordinal) steps led
to a discussion on the role of hyperarithmetic vis `a vis ﬁnite. In meta-
recursion the motivation was to have a generalisation of recursion theory

Discrete Transﬁnite Computation Models
399
where inﬁnitely long computations converged. Initially the emphasis had
been on using an analogy between ﬁnite/recursive/recursively enumerable
to yield a notion of meta-ﬁnite/meta-recursive/meta-r.e. In the latter the
integers would be replaced by recursive ordinals, and a meta-r.e. set was a
set of recursive ordinals whose indices formed a Π1
1 set. Meta-recursive sets
would be those that were both meta-r.e. and co-meta-r.e. The notion that
replaced ﬁniteness, was that of meta-ﬁniteness which was to be identiﬁed
with a set of ordinals together with a hyperarithmetic index set. In partic-
ular the domain of computation had now changed: instead of ω it would
become ωck
1 . (See, e.g., the discussion in [45] Part V for an account of this
development.) This was not the ﬁrst generalisation of recursion theory to
ordinals: Takeuti [51] had replaced ‘recursive enumerability’ by a scheme
equivalent to Σ1-deﬁnability and was the ﬁrst to generalise recursion theory
from natural numbers to ordinals. There were a number of developments
from Kleene’s equational calculus to include ordinal valued functions in
equations: Machover [38], Levy [37], Tugu´e [53], Kripke [36], Platek [41]
all had such calculi. The latter two involved what emerged as a primary
notion, that of an admissible ordinal with the concomitant axiomatisation
of admissible set theory as a fragment of full ZFC set theory. Platek had
the notion of an admissible set. From one perspective, it seems pointless
to split the distinction between an ‘equational calculus’ and an abstract
‘machine’ (if there is one to split). Platek, though, seems to have had in
mind, or at least the picture of, an ordinal register machine of some sorts,
which we shall turn to these later.
12.4.1. Ordinal length tapes
Since the Hamkins–Kidder machines can construct levels of the G¨odel L-
hierarchy up to a certain stage (below the level Σ alluded to above) it is a
natural generalisation to think up behaviours for machines with tape not
an ω sequence of cells, but longer. Indeed why not consider a sequence of
cells Cα for α any ordinal? Both Koepke and Dawson independently, and
at roughly around the same time, came up with the idea of ordinal length
tape machines, equipped with liminf rules to locate read/write heads and
instruction numbers within a program list. One allows the head to move
left, but again must specify if the head is over a limit cell Cλ what de-
fault action to do if the machine is asked to move left one cell. As sets
can be coded by sets of ordinals (assuming the Axiom of Choice) we have
some means of dealing with, or representing sets on tapes. If a machine

400
P. D. Welch
runs and produces a sequence of 0s and 1s on a tape, then again, if of
the right form, we can say that the machine is producing (codes for) sets.
We may label these machines as Ordinal Time Turing Machines (OTM).
Dawson [8] formulated an Axiom of Computability that states that every
set is computable, in that there is a program that produces (not necessar-
ily halting) at some point a code for that set. He then proves that the
computable sets form a transitive class satisfying the ZF axioms together
with AC. A condensation lemma on the elements appearing in a table of
a long computation then produces the Generalised Continuum Hypothesis.
As the construction of the machine and its action is completely absolute in
character, we can imagine the machine running inside G¨odel’s constructible
universe L, performing the same actions with the same outcomes. Since L
is the minimal transitive class model of ZF, then of course the machine is
producing precisely the construcible sets.
Koepke gave a detailed description in [32], [33] of the organisation of
such results, and whereas Dawson was considering codes for sets running
on an everlasting machine, Koepke considers halting computations starting
from an input tape with marks for ﬁnitely many ordinals. Koepke then
shows in detail that a Bounded Truth function for L is computable. He
then has:
Theorem 12.6. (Koepke [32]) A set x is computable from a ﬁnite set of
ordinal parameters if and only if it is a member of the constructible hierar-
chy.
He then proceeds to derive GCH again using this analysis. During the
1970s Silver produced a description of the constructible hierarchy using,
what came to be called ‘Silver Machines’. Silver’s motivation was to avoid
R.B. Jensen’s ‘ﬁne-structural’ description of L, which Jensen had used to
great eﬀect in establishing fundamental properties both of L, and of the
universe of all sets.
An account of Silver’s method is in [9], Part IX.
The ‘machine’ nature of the description is essentially that of an extremely
slowed production of constructible sets, and owes more to a desire to have
as simple as possible method of set construction, rather than a perspective
with a mechanical a ﬂavour. Silver convincingly made use of his theory by
producing a ﬁne-structure free proof of an important combinatorial princi-
ple of L called 2, due to Jensen. The ordinal length tape Turing machine
model held out hope that another diﬀerent proof of 2 might be possible
using the machine’s description. That hope has not been realised, and it
seems that despite the smoothness of set construction at successor steps,

Discrete Transﬁnite Computation Models
401
the inﬁnitary nature of the limit rule mitigates against certain construction
principles that seem common to most proofs of 2 to date, so maybe this
approach would seem diﬃcult.
Nevertheless, the description of the constructible sets, now adds a fur-
ther method of describing L besides the two originally due to G¨odel, and
to those of Jensen and Silver.
12.4.1.1. α-length tapes
Rather than take ON length tapes, it would be possible to consider compu-
tation using the above machines but with the length of tape, and perhaps
time, restricted to, say, suitable ordinals α, such as initial ordinals or car-
dinal numbers.
There would indeed be nothing against this: one could
produce, say, just the hereditarily countable members of L by allowing
only computations that took countable lengths of time. For restricting to
computations not of cardinal length, some closure considerations come into
eﬀect. In order to have eﬀective methods of combining even very elemen-
tary processes on sets, one should require that ordinals be suﬃciently closed
to enable this, and something such as closure under the primitive recursive
set functions (cf.
[9], p.100) would be suitable.
The notion of admissible ordinal stands out, not least because of the
development of α-recursion theory in the 1960s and 1970s. We have brieﬂy
mentioned the origins of this theory at the beginning of this section. The
motivation for its development was indeed a theoretical one: to lift from
N the theory of recursion to other domains. The closure of an admissible
ordinal was soon seen to result in a powerful theory of sets that when
axiomatised gives essentially a reduced form of ZF, with the scheme of
Replacement restricted to Σ1 instances, and that of Comprehension to ∆1.
An admissible set was then a model of this theory, and ⟨Lωck
1 , ∈⟩is the least
transitive model of this theory (if one includes the axiom of inﬁnity).
An
account of this development is contained in [45].
One could therefore simply restrict an ordinal length tape machine to
an admissible ordinal length α, and consider calculations of length at most
α in time.
Does one get back precisely the theory of α-recursion theory?
Does
‘computably enumerable’ correspond to α-r.e., and if so does the machine
approach give any new slant on the old results from the 1970s such as
the Sacks–Simpson theorem [46] that there are incomparable α-r.e. sets
neither (weakly) α-recursive in the other; or the Shore Splitting and Density

402
P. D. Welch
theorems [48], [49]? These are matters still under investigation. Dawson
([8]) has established for a notion of what he calls uniform α-computation
that indeed one has the Sacks–Simpson and Shore Density results.
12.4.2. Ordinal Register Machines
We now turn to full blooded ﬁnite register machines with the capability
of ordinal entries. Again, such machines are allowed to run transﬁnitely
using an ordinary register arrangement, and ﬁnite instruction set, with a
suitable liminf rules for register values and instruction numbers at limit
ordinal λ lengths of time. We have mentioned that one (unpublished by
Platek) approach yielded an equational calculus for ordinal recursion up
to ωck
1 , Siders and Koepke [35], consider register machines with a stack
and remarkably even a machine with ﬁnitely many registers allows one
to calculate a bounded truth predicate for L. One thus can represent L
both using Ordinal Register Machines (ORM) and Ordinal Time Turing
Machines (OTM).
As for the ITTMs one has notions of clockable ordinal (one for which an
ORM or OTM halts on, say, 0 input) and writable ordinal (one for which
a code can be written: this is easier to formulate for an OTM: a code can
be written literally on the tape; for an ORM one simply has the machine
halt with the ordinal in, say, the ﬁrst register). For both these notions it
is easier than for ITTMs to conclude that γ the supremum of the clockable
ordinals is that of the writable ordinals. In [16] it is explicitly shown how
to convert calculations from an ORM to an OTM and vice versa.
Using ordinal register machines with values up to the admissible ordinal
γ Hamkins and Miller have used priority arguments to produce a Friedberg–
Muchnik like solution to Post’s problem [16] for ORMs: they produce ORM-
enumerable but incomparable sets A, B ⊂γ that are below the appropriate
notion of jump.
Deﬁnition 12.13. Let Pe be the e’th ORM program, the (weak) jump is
the set
0♦= {e ∈
N | Pe(0) ↓}.
Although neither [16] nor [35] make the following characterisation, it
appears reasonable to argue that the ordinal γ in fact is recognisable by
set theorists as the ﬁrst Σ1-stable ordinal σ.
This is deﬁned to be the
least ordinal σ so that ⟨Lσ, ∈⟩≺Σ1 ⟨V, ∈⟩, that is, Lσ is an elementary
substructure of the universe of all sets, but only for Σ1 sentences expressible

Discrete Transﬁnite Computation Models
403
using parameters from Lσ. (See [20] p. 412 for an equivalent deﬁnition in
terms of ∞-partial recursive functions.)
Consequently if any ORM (or
OTM) halts on integer input (or indeed any input less than γ) then the
length of that computation must be also less than σ, as this halting assertion
is itself a simple Σ1-statement in the language of set theory. (Moreover
anything output by such a machine must also clearly be an ordinal less
than σ by the same reasoning.) Hence γ ≤σ. To see that σ ≤γ observe
that in the L hierarchy, new Σ1 sentences become true in Lδ for arbitrarily
large ordinals δ < γ. Now given a true Σ1 sentence in the language of set
theory, run an ORM (or OTM) program to search for that ordinal δ, and
then halt. This task must take more than δ (but also less than σ) steps.
Hence σ = γ. One then obtains:
Proposition 12.5. 0♦is recursively isomorphic to the Σ1-truth set of
⟨Lσ, ∈⟩.
One can compare this with the statement that the standard Turing
halting set is recursively isomorphic to the Σ1-truth set of ⟨Lω, ∈⟩where
Lω = HF the class of hereditarily ﬁnite sets. A similar result holds (with
the appropriate formulations) for OTMs for the same reasons.
12.5. Theoretical Machine Strength
We consider ﬁnally the theoretical strengths of the various types of mech-
anisms discussed here.
We have answered, in one fashion at least, the
capabilities of the machines in the Malament–Hogarth spacetimes, and the
Etesi–N´emeti model in particular. It is also clear that the ON-length tape
machines are full ZFC-machines that are capable of producing G¨odel’s con-
structible universe.
For the intermediate machine models we have mentioned, one could
simply be satisﬁed by seeing at which level of complexity the machines can
answer queries concerning predicates. One can however somewhat more
formally, formulate a theory in which the behaviour of the machine can be
represented, and one may then calibrate this theory, not necessarily proof
theoretically, but at least as a theory within other theories, for example as
a subsystem of second order analysis, much as is done in the Reverse Math-
ematics Program (see [50]). The discussion becomes somewhat technical,
but for the logician, interesting.
Towards analysing the ITTMs we ﬁrst look at connections to certain
kinds of quasi-inductive deﬁnitions that were deﬁned earlier, at least in one
form, by Burgess in [5].

404
P. D. Welch
Let Γ : P(ω) →P(ω) be any arithmetic operator (that is ‘n ∈Γ(X)’
is arithmetic; we emphasise that Γ need be neither monotone nor progres-
sive).
We deﬁne the following iterates of Γ : Γ0(X) = X; Γα+1(X) =
Γ(Γα(X)); Γλ(X) = lim infα→λ Γα(X) = ∪α<λ ∩λ>β>α Γβ(X).
Follow-
ing [5], we say that Y ⊆ω is arithmetically quasi-inductive if for some such
Γ, Y is (1-1) reducible toΓOn(∅). Any such deﬁnition has a least countable
ξ = ξ(Γ) with Γξ(∅) = ΓOn(∅). If we let ζ denote the supremum of all such
ξ(Γ), then we have that the ζ deﬁned here is none other than the ζ deﬁned
above relating to ITTMs. In fact the ITTMs give an example of a recursive
quasi-inductive operator that is complete for all arithmetic quasi-inductive
operators. (Think: a universal ITTM can be programmed to mimick any
arithmetic quasi-inductive operator.) Hence the same class of sets arises,
it turns out, if one restricts to simply recursive Γ.
For any such arithmetic quasi-inductive operator Γ let us now deﬁne
the repeat pair of Γ on a starting set X, as the lexicographically least pair
(ζ(Γ, X), Σ(Γ, X)) with Γζ(X) = ΓΣ(X).
Deﬁnition 12.14. AQI is the sentence:
‘For every arithmetic opera-
tor Γ, for every X ⊆
N, there is a wellordering W with a repeat pair
(ζ(Γ, X), Σ(Γ, X)) in Field(W)’. If an arithmetic operator Γ acting on X
has a repeat pair, we say that Γ converges (with input X).
Then AQI can be formulated in second order number theory, and essen-
tially is asserting that there are suﬃcient wellorderings for every operator
on every input set X to converge. One may ask:
Q: What is the strength of ACA0 + AQI?
(The choice of ACA0, arithmetical comprehension, as a base theory is
somewhat arbitrary.
We refer the reader to [50] in what follows for all
notions concerning these axiom systems, and determinacy hypotheses etc.)
We could have equivalently reformulated a version of AQI which mentioned
instead looping points of ITTMs, but this would turn out to be equivalent,
as we have intimated. Π1
3CA0 is suﬃcient to prove there are β-models of
ACA0 + AQI.
Theorem 12.7. ([58]) (i) Π1
3CA0, ACA0+AQI and Π1
2CA0 are in descending
order of strength in that each theory proves the existence of β-models of the
next.
More precisely, and in the same sense:
(ii) ∆1
3CA0+Σ0
3-Determinacy, ACA0 + AQI, and ∆1
3CA0 are similarly in
strictly descending order of strength.

Discrete Transﬁnite Computation Models
405
Determinacy makes an appearance here, since this theorem is the out-
come of an attempt to generalise the theorem of Solovay (see [25]) that
strategies for Σ0
2-games appear at the level σ1
1 of the L hierarchy, the closure
ordinal for Σ1
1-monotone inductive deﬁnitions. (In turn, as is well known,
strategies for Σ0
1-games appear at ω1 ck the closure ordinal for Π1
1-monotone
inductive deﬁnitions. We are thus trying to link AQIs, or ITTMs to strate-
gies for certain inﬁnite games.) Thus AQIs are close to, but not equivalent
to, Σ0
3-Determinacy. That they are stronger than Σ0
2-Determinacy, is be-
cause σ1
1 < ζ. Moreover, letting ‘Bool(Σ0
2)’ denote Boolean combinations of
Σ0
2 sets, the constructible rank of the height of the least β-model of Π1
2CA0
(as shown by M¨ollerfeld and Heinatsch [19]) where strategies for Bool(Σ0
2)
games are to be found, is less than ζ, and in fact is again a ‘writable’ ordinal
less than λ, in the sense of ITTMs. This shows that the assertion that any
ITTM halts or loops, is stronger than Bool(Σ0
2)-Determinacy.
That ∆1
3CA0 + AQI is stronger than ∆1
3CA0 in the above sense should
be plausible in that the universal ITTM on input ∅will go into a loop at
the ‘repeat pair’ ordinals ζ and Σ where Lζ ≺Σ2 LΣ. However it is easy to
see from this Σ2-extendability property that any such Lζ is a Σ2-admissible
set (where we now require the admissible set to additionally be a model of
Σ2-Replacement) and is also a union of such. The reals of such a model
then form a β-model of ∆1
3CA0.
Connections to ordinal analysis
The notion of ‘Σ2-extendibility’ of a model, that is of having a proper
Σ2-elementary end extension, would seem prima facie, to be connected to
any attempt to prove a generalisation of Rathjen’s ordinal analysis ([43]) of
Π1
2CA0 that could be lifted to Π1
3CA0. In the former proof, chains of arbi-
trary but ﬁnite length of Σ1-end extensions in the constructible hierarchy
of the form Lξ1 ≺Σ1 Lξ1 ≺Σ1 · · · ≺Σ1 Lξn are analysed.
(Note that the
least β-model of Π1
2CA0 consists of P(
N) ∩Lξω where ξω is the least ordi-
nal with Lξω a union of an inﬁnite tower of Σ1 substructures.) To analyse
Π1
3CA0 in a similar way would require lifting the ‘1’ above to ‘2’ and looking
at arbitrarily long chains of Σ2-extensions. It would seem then that any
ordinal analysis of Π1
3CA0 would ﬁrst have to go through an analysis of AQI,
the latter being but the very ﬁrst step in this linkage.
Σn- or ‘hypermachines.’
The notion of liminf is essentially a two quantiﬁer alternation: ‘there
exists a time such that for all later times...’.
It is possible to enquire
whether there are other types of limit rule that bring about diﬀerent notions
of computation, or diﬀerent classes of computable function. One attempt

406
P. D. Welch
to consider this question is a result of [54] which shows that, amongst all
possible Σ2-rules the liminf (or equivalently the limsup) rule is complete,
or the most general. This is entirely unsurprising: if the universal ITTM
machine can produce the constructible hierarchy up to LΣ, there is little
else for it to do. Further any other Σ2-rule would itself produce looping
behaviour between Lζ and LΣ.
One may thus broaden the enquiry and look for more complex rules.
It is possible to develop a Σ3-machine which incorporates a Σ3-limit rule
cf. [14]; the essential idea is that instead of taking a liminf along all or-
dinals one takes a liminf using only those ordinals that already bound
the reappearances of earlier (shifted) snapshots.
One thus has in some
sense a dynamic limit rule in that the behaviour at a limit rule depends
more formally on the tapes’ prior contents. One then has the analogous
result that a universal machine program would then have identical snap-
shots at the least pair (ζ(3), Σ(3)) where Lζ(3) ≺Σ3 LΣ(3)to mirror the
earlier λ-ζ-Σ theorem at Σ2. After Σ(3) it then returns to the previous
snapshot at ζ(3) and thereafter repeats forever. It is possible to gener-
alise this to higher quantiﬁcational levels Σn with the snapshot/looping
behaviour at the appropriate pair (ζ(n), Σ(n)) lexicographically least with
Lζ(n) ≺Σn LΣ(n). However showing these facts is more technical, and is
reliant more on the underlying set theory; it thus perhaps has decreasingly
less of an appeal to intuitions concerning machine computation. This is
explained in [14].
ITRMs on integers
The ITRMs of Miller and Koepke (12.2.2.2) with entries restricted to
natural numbers turn out to be pleasantly strong. It is possible show that
such machines are Π1
1-complete, in that for any Π1
1 set A there is a program
on an ITRM, that correctly accepts or rejects n depending on whether n is
or is not in A. It can thus, for example, decide for which indices e the e’th
(standard) Turing function {e} is the characteristic function of a wellorder
or not. Moreover it can be shown that the strength of the machine strictly
increases with the number N of registers. It is possible with 2N registers
to simulate an N register machine, whilst giving as output integer codes of
those programs on N registers that halt. A corollary is that there can be no
such universal machine. Here we let Pe,N denote the e’th ITRM program
for an N register machine.
Deﬁnition 12.15. Let ITRM be the axiom scheme that states for each
N ∈
N that halting sets for N-register machines exists:

Discrete Transﬁnite Computation Models
407
‘For any N ∈
N, KN =df {e|Pe,N(⃗0) ↓} exists’.
One then obtains (with RCA0 as the recursive comprehension scheme):
Theorem 12.8. RCA0 ⊢ITRM ←→Π1
1CA0.
Reverse mathematics has shown that a wealth of theorems can be proven
in the system Π1
1CA0.
As a sample we have the following, in which we
assume the ITRM is equipped with an oracle set Z ⊆
N (and a register
operation to query it):
Theorem 12.9. Let T ⊆{σ | σ ∈<N
N} be a set of sequences which form
a tree. Then if Z ⊆
N codes T (via some recursive coding), the perfect
kernel of T is ITRM-computable in the oracle Z.
(By the perfect kernal we mean the maximal subtree whose branches
form a perfect set, that is without isolated points.) Thus, as with much of
this kind of study, a seemingly simple model in fact turns out to be rather
powerful.
Acknowledgements
The author would like to gratefully acknowledge grants from the EPSRC
and the Templeton Foundation during the writing of this chapter. He would
also like to thank the Kurt G¨odel Research Center, Vienna for its hospitality
also during this period.
References
[1] K. J. Barwise, Admissible Sets and Structures. Perspectives in Mathematical
Logic, Springer Verlag, Berlin–Heidelberg, (1975).
[2] E. Beggs, J. F. Costa, B. Loﬀ, and J. V. Tucker. Oracles and advice as mea-
surement. In eds., C. S. Calude et al., Unconventional Computing, vol. 5204,
Lecture Notes in Computer Science, pp. 33–50. Springer, Berlin, (2008).
[3] E. Beggs and J. V. Tucker, Can Newtonian systems, bounded in space, time,
mass and energy compute all functions?, Theoret. Comput. Sci. 371, 4–19,
(2007).
[4] L. Blum, M. Shub, and S. Smale, On a theory of computation and complex-
ity over the real numbers, Notices Amer. Math. Soc. (N. S.). 21(1), 1–46,
(1989).
[5] J. P. Burgess, The truth is never simple, J. Symbolic Logic. 51(3), 663–681,
(1986).

408
P. D. Welch
[6] N. Cutland, Computability: an Introduction to Recursive Function Theory.
Cambridge University Press, Cambridge, 1980).
[7] E. B. Davies, Building inﬁnite machines, British J. Philos. Sci. 52(4), 671–
682, (2001).
[8] B. Dawson. Ordinal time Turing computation. PhD thesis, Bristol, (2009).
[9] K. Devlin, Constructibility. Perspectives in Mathematical Logic, Springer-
Verlag, Berlin–Heidelberg, (1984).
[10] J. Earman and J. D. Norton, Forever is a day: Supertasks in Pitowsky and
Malament–Hogarth spacetimes, Philos. Sci. 60, 22–42, (1993).
[11] J. Earman and J. D. Norton. Inﬁnite pains: the trouble with supertasks. In
eds., A. Morton and S. Stich, Benacerraf and his critics, vol. xi, Philosophers
and their critics. Blackwell, Oxford, (1996).
[12] G. Etesi and I. N´emeti, Non-Turing computations via Malament–Hogarth
space-times, Internat. J. Theoret. Phys. 41(2), 341–370, (2002).
[13] J. E. Fenstad, General Recursion Theory: an Axiomatic Approach. Perspec-
tives in Mathematical Logic, Springer, Berlin–Heidelberg–New York, (1980).
[14] S. D. Friedman and P. D. Welch, Hypermachines, to appear in the J. Sym-
bolic Logic. (2010).
[15] J. D. Hamkins and A. Lewis, Inﬁnite time Turing machines, J. Symbolic
Logic. 65(2), 567–604, (2000).
[16] J. D. Hamkins and R. Miller, Post’s problem for ordinal register machines:
an explicit approach, Ann. Pure Appl. Logic. 160(3), 302–309, (2009).
[17] J. D. Hamkins and D. Seabold, Inﬁnite time Turing machines with only one
tape, MLQ Math. Log. Q. 47(2), 271–287, (2001).
[18] S. W. Hawking and G. F. R. Ellis, The Large Scale Structure of Space-Time.
Cambridge University Press, Cambridge, (1973).
[19] C. Heinatsch and M. M¨ollerfeld. Determinacy in second order arithmetic.
In eds., S. Bold, B. L¨owe, T. R¨asch and J. van Bentham, Foundations of
the Formal Sciences V, Studies in Logic, pp. 143–155, College of London
Publications, (2007).
[20] P. Hinman, Recursion-Theoretic Hierarchies. ΩSeries in Mathematical
Logic, Springer, Berlin, (1978).
[21] M. Hogarth, Does general relativity allow an observer to view an eternity in
a ﬁnite time?, Found. Phys. Lett. 5(2), 173–181, (1992).
[22] M. Hogarth. Non-Turing computers and non-Turing computability. In PSA:
Proceedings of the Biennial Meeting of the Philosophy of Science Association
Vol. 1, pp. 126–138. (1994).
[23] M. Hogarth, Deciding arithmetic using SAD computers, British J. Philos.
Sci. 55, 681–691, (2004).
[24] K. Hrbacek and S. Simpson. On Kleene degrees of analytic sets. In eds.,
J. Barwise, H. J. Keisler and K. Kunen, Proceedings of the Kleene Sympo-
sium, Studies in Logic, pp. 347–352. North-Holland, Amsterdam, (1980).
[25] A. S. Kechris. On Spector classes. In eds., A. S. Kechris and Y. N.
Moschovakis, Cabal Seminar 76-77, vol. 689, Lecture Notes in Mathemat-
ics Series, pp. 245–278. Springer, Berlin, (1978).
[26] S. C. Kleene, Recursive quantiﬁers and functionals of ﬁnite type I, Trans.

Discrete Transﬁnite Computation Models
409
Amer. Math. Soc. 91, 1–52, (1959).
[27] S. C. Kleene. Turing-machine computable functionals of ﬁnite type I. In Pro-
ceedings 1960 Conference on Logic, Methodology and Philosopy of Science,
pp. 38–45. Stanford University Press, California, (1962).
[28] S. C. Kleene, Turing-machine computable functionals of ﬁnite type II, Proc.
Lond. Math. Soc. 12, 245–258, (1962).
[29] S. C. Kleene, Recursive quantiﬁers and functionals of ﬁnite type II, Trans.
Amer. Math. Soc. 108, 106–142, (1963).
[30] S. C. Kleene. Recursive functionals and quantiﬁers of ﬁnite types revisited.
In Generalized Recursion Theory II, Proceedings 2nd Scandinavian Logic
Symposium, Oslo, 1977, vol. 94, Studies in Logic and Foundations of Math-
ematics, pp. 185–222, North-Holland, Amsterdam, New York, (1978).
[31] A. Klev, Magister thesis, (August 2007).
[32] P. Koepke, Turing computation on ordinals, Bull. Symbolic Logic. 11, 377–
397, (2005).
[33] P. Koepke and M. Koerwien, Ordinal computations, Math. Structures Com-
put. Sci. 16(5), 867–884, (2006).
[34] P. Koepke and R. Miller. An enhanced theory of inﬁnite time register ma-
chines. In eds., A. Beckmann et al., Logic and the Theory of Algorithms,
vol. 5028, Springer Lecture Notes Computer Science, pp. 306–315. Springer,
Berlin, (2008).
[35] P. Koepke and R. Siders. Computing the recursive truth predicate on or-
dinal register machines. In eds. A. Beckmann et al., Logical Approaches to
Computational Barriers, Computer Science Report Series, p. 21. Swansea,
(2006).
[36] S. Kripke, Transﬁnite recursion on admissible ordinals I,II, J. Symbolic Logic.
29, 161–162, (1964).
[37] A. Levy, Transﬁnite computability (abstract), Notices Amer. Math. Society.
10, 286, (1963).
[38] M. Machover, The theory of transﬁnite recursion, Bull. Amer. Math. Soc.
67, 575–578, (1961).
[39] Y. N. Moschovakis, Elementary Induction on Abstract Structures. vol. 77,
Studies in Logic, North-Holland, Amsterdam, (1974).
[40] I. Pitowsky, The physical Church–Turing thesis and physical computational
complexity, Iyyun. 39, 81–99, (1990).
[41] R. Platek. Foundations of Recursion Theory. PhD thesis, Stanford, Califor-
nia, (1966).
[42] H. Putnam, Trial and error predicates and the solution to a problem of
Mostowski, J. Symbolic Logic. 30, 49–57, (1965).
[43] M. Rathjen, An ordinal analysis of parameter-free Π1
2 comprehension, Arch.
Math. Logic. 44(3), 263–362, (2005).
[44] H. Rogers, Jr., Theory of Recursive Functions and Eﬀective Computability.
McGraw-Hill, New York, (1967).
[45] G. E. Sacks, Higher Recursion Theory. Perspectives in Mathematical Logic,
Springer Verlag, Berlin–Heidelberg, (1990).
[46] G. E. Sacks and S. G. Simpson, The α-ﬁnite injury method, Ann. Math.

410
P. D. Welch
Logic. 4, 343–367, (1972).
[47] J. Shepherdson and H. Sturgis, Computability of recursive functionals, J.
ACM. 10, 217–255, (1963).
[48] R. A. Shore, Splitting an α recursively enumerable set, Trans. Amer. Math.
Soc. 204, 65–78, (1975).
[49] R. A. Shore, The recursively enumerable α-degrees are dense, Ann. Math.
Logic. 9, 123–155, (1976).
[50] S. G. Simpson, Subsystems of Second Order Arithmetic. Perspectives in
Mathematical Logic, Springer, Berlin, (1999).
[51] G. Takeuti, On the recursive functions of ordinal numbers, J. Math. Soc.
Japan. 12, 119–128, (1960).
[52] J. Thomson, Tasks and supertasks, Analysis. 15(1), 1–13, (1954-55).
[53] T. Tugu´e, On the partial recursive functions of ordinal numbers, J.. Math.
Soc. Japan. 16, 1–31, (1964).
[54] P. D. Welch, Eventually inﬁnite time Turing degrees: inﬁnite time decidable
reals, J. Symbolic Logic. 65(3), 1193–1203, (2000).
[55] P. D. Welch. Post’s and other problems in higher type supertasks. In eds.,
B. L¨owe, B. Piwinger and T. R¨asch, Classical and New Paradigms of Com-
putation and their Complexity hierarchies, Papers of the Conference Foun-
dations of the Formal Sciences III, vol. 23, Trends in logic, pp. 223–237.
Kluwer, Dordrecht, (2004).
[56] P. D. Welch, Turing Unbound: The extent of computations in Malament-
Hogarth spacetimes, British J. Philos. Sci. 15(4), 659–674, (2008).
[57] P. D. Welch, Characteristics of discrete transﬁnite Turing machine mod-
els: halting times, stabilization times, and normal form theorems, Theoret.
Comput. Sci. 410, 426–442, (2009).
[58] P. D. Welch, Weak systems of determinacy and arithmetical quasi-inductive
deﬁnitions, arXiv: 0905.4412, to appear in the J. Symbolic Logic. (2010).

