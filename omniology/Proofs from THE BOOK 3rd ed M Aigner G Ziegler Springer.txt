
Martin Aigner 
Giinter M. Ziegler 
Proofs from 
THE BOOK 
Third Edition 
With 250 Figures 
Including Illustrations 
by Karl H. Hofmann 
Springer 


Preface
Paul Erd˝os
Paul Erd˝os liked to talk about The Book, in which God maintains the perfect
proofs for mathematical theorems, following the dictum of G. H. Hardy that
there is no permanent place for ugly mathematics. Erd˝os also said that you
need not believe in God but, as a mathematician, you should believe in
The Book. A few years ago, we suggested to him to write up a ﬁrst (and
very modest) approximation to The Book. He was enthusiastic about the
idea and, characteristically, went to work immediately, ﬁlling page after
page with his suggestions. Our book was supposed to appear in March
1998 as a present to Erd˝os’ 85th birthday. With Paul’s unfortunate death
in the summer of 1997, he is not listed as a co-author. Instead this book is
dedicated to his memory.
“The Book”
We have no deﬁnition or characterization of what constitutes a proof from
The Book: all we offer here is the examples that we have selected, hop-
ing that our readers will share our enthusiasm about brilliant ideas, clever
insights and wonderful observations. We also hope that our readers will
enjoy this despite the imperfections of our exposition. The selection is to a
great extent inﬂuenced by Paul Erd˝os himself. A large number of the topics
were suggested by him, and many of the proofs trace directly back to him,
or were initiated by his supreme insight in asking the right question or in
making the right conjecture. So to a large extent this book reﬂects the views
of Paul Erd˝os as to what should be considered a proof from The Book.
A limiting factor for our selection of topics was that everything in this book
is supposed to be accessible to readers whose backgrounds include only
a modest amount of technique from undergraduate mathematics. A little
linear algebra, some basic analysis and number theory, and a healthy dollop
of elementary concepts and reasonings from discrete mathematics should
be sufﬁcient to understand and enjoy everything in this book.
We are extremely grateful to the many people who helped and supported
us with this project — among them the students of a seminar where we
discussed a preliminary version, to Benno Artmann, Stephan Brandt, Stefan
Felsner, Eli Goodman, Torsten Heldmann, and Hans Mielke. We thank
Margrit Barrett, Christian Bressler, Ewgenij Gawrilow, Elke Pose, and J¨org
Rambau for their technical help in composing this book. We are in great
debt to Tom Trotter who read the manuscript from ﬁrst to last page, to
Karl H. Hofmann for his wonderful drawings, and most of all to the late
great Paul Erd˝os himself.
Berlin, March 1998
Martin Aigner
 G¨unter M. Ziegler

Preface to the Second Edition 
The first edition of this book got a wonderful reception. Moreover, we re- 
ceived an unusual number of letters containing comments and corrections, 
some shortcuts, as well as interesting suggestions for alternative proois and 
new topics to treat. (While we are trying to record pelfect proofs, our 
exposition isn't.) 
The second edition gives us the opportunity to present this new version of 
our book: It contains three additional chapters, substantial revisions and 
new proofs in several others, as well as minor amendments and improve- 
ments, many of them based on the suggestions we received. It also misses 
one of the old chapters, about the "problem of the thirteen spheres," whose 
proof turned out to need details that we couldn't complete in a way that 
would make it brief and elegant. 
Thanks to all the readers who wrote and thus helped us - 
among them 
Stephan Brandt, Christian Elsholtz, Jurgen Elstrodt, Daniel Grieser, Roger 
Heath-Brown, Lee L. Keener, Christian Lebceuf, Hanfried Lenz, Nicolas 
Puech, John Scholes, Bernulf WeiBbach, and many others. Thanks again 
for help and support to Ruth Allewelt and Karl-Friedrich Koch at Springer 
Heidelberg, to Christoph Eyrich and Torsten Heldmann in Berlin, and to 
Karl H. Hofmann for some superb new drawings. 
Berlin, September 2000 
Martin Aigner . Giinter M. Ziegler 
Preface to the Third Edition 
We would never have dreamt, when preparing the first edition of this book 
in 1998, of the great success this project would have, with translations into 
many languages, enthusiastic responses from so many readers, and so many 
wonderful suggestions for improvements, additions, and new topics - 
that 
could keep us busy for years. 
So, this third edition offers two new chapters (on Euler's partition identities, 
and on card shuffling), three proofs of Euler's series appear in a separate 
chapter, and there is a number of other improvements, such as the Calkin- 
Wilf-Newman treatment of "enumerating the rationals." That's it, for now! 
We thank everyone who has supported this project during the last five 
years, and whose input has made a difference for this new edition. This 
includes David Bevan, Anders Bjorner, Dietrich Braess, John Cosgrave, 
Hubert Kalf, Gunter Pickert, Alistair Sinclair, and Herb Wilf. 
Berlin, July 2003 
Martin Aigner . Giinter M. Ziegler 

Table of Contents 
Number Theory 
1 
1 . Six proofs of the infinity of primes .............................. 3 
............................................ 
2 . Bertrand's postulate 
7 
................. 
3 . Binomial coefficients are (almost) never powers 
13 
4 . Representing numbers as sums of two squares ................... 17 
5 . Every finite division ring is a field .............................. 
23 
...................................... 
6 . Some irrational numbers 
27 
............................................. 
7 . Three times 7r2/6 
35 
Geometry 
43 
8 . Hilbert's third problem: decomposing polyhedra ................. 45 
9 . Lines in the plane and decompositions of graphs ................. 53 
............................................ 
10 . The slope problem 
59 
11 . Three applications of Euler's formula .......................... 65 
..................................... 
12 . Cauchy's rigidity theorem 
71 
........................................... 
13 . Touching simplices 
75 
14 . Every large point set has an obtuse angle ....................... 79 
.......................................... 
15 . Borsuk's conjecture 
85 
Analysis 
9 1 
16 . Sets. functions. and the continuum hypothesis ................... 93 
...................................... 
17 . In praise of inequalities 
109 
........................... 
18 . A theorem of Pdya on polynomials 
117 
......................... 
19 . On a lemma of Littlewood and Offord 
123 
.............................. 
20 . Cotangent and the Herglotz trick 
127 
..................................... 
21 . Buffon's needle problem 
133 

VIII 
Table of Contents 
Corn binatorics 
137 
............................. 
22 . Pigeon-hole and double counting 
139 
.......................... 
23 . Three famous theorems on finite sets 
151 
.............................................. 
24 . Shuffling cards 
157 
................................ 
25 . Lattice paths and determinants 
167 
...................... 
. 
26 Cayley's formula for the number of trees 
173 
.................................... 
27 . Completing Latin squares 
179 
.......................................... 
28 . The Dinitz problem 
185 
................................... 
29 . Identities versus bijections 
191 
Graph Theory 
197 
................................... 
30 . Five-coloring plane graphs 
199 
..................................... 
3 1 . How to guard a museum 
203 
....................................... 
32 . Turhn's graph theorem 
207 
............................... 
33 . Communicating without errors 
213 
.................................... 
34 . Of friends and politicians 
223 
.................. 
35 . Probability makes counting (sometimes) easy 
227 
About the Illustrations 
236 
Index 
237 

 
 
 
Number Theory 

Six proofs
of the inﬁnity of primes
Chapter 1
It is only natural that we start these notes with probably the oldest Book
Proof, usually attributed to Euclid. It shows that the sequence of primes
does not end.
 Euclid’s Proof.
For any ﬁnite set
fp

;
:
:
:
;
p
r
g of primes, consider
the number
n
=
p

p




p
r
+
. This
n has a prime divisor
p. But
p is
not one of the
p
i: otherwise
p would be a divisor of
n and of the product
p

p




p
r, and thus also of the difference
n
 p

p

:
:
:
p
r
=
, which
is impossible. So a ﬁnite set
fp

;
:
:
:
;
p
r
g cannot be the collection of all
prime numbers.

Before we continue let us ﬁx some notation.
N
=
f;
;
;
:
:
:
g is the set
of natural numbers,
Z
=
f:
:
:
;
 ;
 ;
0;
;
;
:
:
:
g the set of integers, and
P
=
f;
;
;
;
:
:
:
g the set of primes.
In the following, we will exhibit various other proofs (out of a much longer
list) which we hope the reader will like as much as we do. Although they
use different view-points, the following basic idea is common to all of them:
The natural numbers grow beyond all bounds, and every natural number
n

 has a prime divisor. These two facts taken together force
P to be
inﬁnite. The next three proofs are folklore, the ﬁfth proof was proposed by
Harry F¨urstenberg, while the last proof is due to Paul Erd˝os.
The second and the third proof use special well-known number sequences.
 Second Proof.
Suppose
P is ﬁnite and
p is the largest prime. We
consider the so-called Mersenne number

p
  and show that any prime
factor
q of

p
  is bigger than
p, which will yield the desired conclusion.
Let
q be a prime dividing

p
 , so we have

p


(mod
q
). Since
p is
Lagrange’s Theorem
If
G is a ﬁnite (multiplicative) group
and
U is a subgroup, then
jU
j
divides
jGj.
 Proof. Consider the binary rela-
tion
a

b
:
(
)
ba
 

U:
It follows from the group axioms
that
 is an equivalence relation.
The equivalence class containing an
element
a is precisely the coset
U
a
=
fxa
:
x

U
g:
Since clearly
jU
aj
=
jU
j, we ﬁnd
that
G decomposes into equivalence
classes, all of size
jU
j, and hence
that
jU
j divides
jGj.

In the special case when
U is a cyclic
subgroup
fa;
a

;
:
:
:
;
a
m
g we ﬁnd
that
m (the smallest positive inte-
ger such that
a
m
=
, called the
order of
a) divides the size
jGj of
the group.
prime, this means that the element
 has order
p in the multiplicative group
Z
q
n
f0g of the ﬁeld
Z
q. This group has
q
  elements. By Lagrange’s
theorem (see the box) we know that the order of every element divides the
size of the group, that is, we have
p
j
q
 , and hence
p
<
q.

 Third Proof. Next let us look at the Fermat numbers
F
n
=


n
+
 for
n
=
0;
;
;
:
:
:. We will show that any two Fermat numbers are relatively
prime; hence there must be inﬁnitely many primes. To this end, we verify
the recursion
n 
Y
k
=0
F
k
=
F
n
 
(n

);

4
Six proofs of the inﬁnity of primes
from which our assertion follows immediately. Indeed, if
m is a divisor of,
say,
F
k and
F
n
(k
<
n), then
m divides 2, and hence
m
=
 or
. But
m
=
 is impossible since all Fermat numbers are odd.
F
0
=

F

=

F

=

F

=

F

=

F

=


00
The ﬁrst few Fermat numbers
To prove the recursion we use induction on
n. For
n
=
 we have
F
0
=

and
F

 
=
. With induction we now conclude
n
Y
k
=0
F
k
=

n 
Y
k
=0
F
k

F
n
=
(F
n
 )F
n
=
=
(

n
 )(

n
+
)
=


n+
 
=
F
n+
 :

Now let us look at a proof that uses elementary calculus.
 Fourth Proof. Let

(x)
:=
#fp

x
:
p

Pg be the number of primes
that are less than or equal to the real number
x. We number the primes
P
=
fp

;
p

;
p

;
:
:
:
g in increasing order. Consider the natural logarithm
log
x, deﬁned as
log
x
=
R
x


t
dt.



n
Steps above the function
f
(t)
=

t
Now we compare the area below the graph of
f
(t)
=

t with an upper step
function. (See also the appendix on page 10 for this method.) Thus for
n

x
<
n
+
 we have
log
x


+


+


+
:
:
:
+

n
 
+

n

X

m
; where the sum extends over all
m

N which have
only prime divisors
p

x.
Since every such
m can be written in a unique way as a product of the form
Q
px
p
k
p, we see that the last sum is equal to
Y
pP
px

X
k
0

p
k

:
The inner sum is a geometric series with ratio

p, hence
log
x

Y
pP
px


 
p
=
Y
pP
px
p
p
 
=

(x)
Y
k
=
p
k
p
k
 
:
Now clearly
p
k

k
+
, and thus
p
k
p
k
 
=

+

p
k
 


+

k
=
k
+

k
;
and therefore
log
x


(x)
Y
k
=
k
+

k
=

(x)
+
:
Everybody knows that
log
x is not bounded, so we conclude that

(x) is
unbounded as well, and so there are inﬁnitely many primes.


Six proofs of the inﬁnity of primes
5
 Fifth Proof.
After analysis it’s topology now! Consider the following
curious topology on the set
Z of integers. For
a;
b

Z,
b
>
0 we set
N
a;b
=
fa
+
nb
:
n

Zg
:
Each set
N
a;b is a two-way inﬁnite arithmetic progression. Now call a set
O

Z open if either
O is empty, or if to every
a

O there exists some
b
>
0 with
N
a;b

O. Clearly, the union of open sets is open again. If
O

;
O
 are open, and
a

O

\
O
 with
N
a;b


O
 and
N
a;b


O
,
then
a

N
a;b

b


O

\
O
. So we conclude that any ﬁnite intersection
of open sets is again open. So, this family of open sets induces a bona ﬁde
topology on
Z.
Let us note two facts:
(A) Any non-empty open set is inﬁnite.
(B) Any set
N
a;b is closed as well.
Indeed, the ﬁrst fact follows from the deﬁnition. For the second we observe
N
a;b
=
Zn
b 
[
i=
N
a+i;b
;
which proves that
N
a;b is the complement of an open set and hence closed.
“Pitching ﬂat rocks, inﬁnitely”
So far the primes have not yet entered the picture — but here they come.
Since any number
n
=
;
  has a prime divisor
p, and hence is contained
in
N
0;p, we conclude
Z
n
f;
 g
=
[
pP
N
0;p
:
Now if
P were ﬁnite, then
S
pP
N
0;p would be a ﬁnite union of closed sets
(by (B)), and hence closed. Consequently,
f;
 g would be an open set,
in violation of (A).

 Sixth Proof.
Our ﬁnal proof goes a considerable step further and
demonstrates not only that there are inﬁnitely many primes, but also that
the series
P
pP

p diverges. The ﬁrst proof of this important result was
given by Euler (and is interesting in its own right), but our proof, devised
by Erd˝os, is of compelling beauty.
Let
p

;
p

;
p

;
:
:
: be the sequence of primes in increasing order, and
assume that
P
pP

p converges. Then there must be a natural number
k
such that
P
ik
+

p
i
<

. Let us call
p

;
:
:
:
;
p
k the small primes, and
p
k
+
;
p
k
+
;
:
:
: the big primes. For an arbitrary natural number
N we
therefore ﬁnd
X
ik
+
N
p
i
<
N

:
(1)

6
Six proofs of the inﬁnity of primes
Let
N
b be the number of positive integers
n

N which are divisible by at
least one big prime, and
N
s the number of positive integers
n

N which
have only small prime divisors. We are going to show that for a suitable
N
N
b
+
N
s
<
N
;
which will be our desired contradiction, since by deﬁnition
N
b
+
N
s would
have to be equal to
N.
To estimate
N
b note that
b
N
p
i
c counts the positive integers
n

N which
are multiples of
p
i. Hence by (1) we obtain
N
b

X
ik
+
j
N
p
i
k
<
N

:
(2)
Let us now look at
N
s. We write every
n

N which has only small prime
divisors in the form
n
=
a
n
b

n, where
a
n is the square-free part. Every
a
n
is thus a product of different small primes, and we conclude that there are
precisely

k different square-free parts. Furthermore, as
b
n

p
n

p
N,
we ﬁnd that there are at most
p
N different square parts, and so
N
s


k
p
N
:
Since (2) holds for any
N, it remains to ﬁnd a number
N with

k
p
N

N

or

k
+

p
N, and for this
N
=

k
+ will do.

References
[1] P. ERD ˝OS: ¨Uber die Reihe
P

p, Mathematica, Zutphen B 7 (1938), 1-2.
[2] L. EULER: Introductio in Analysin Inﬁnitorum, Tomus Primus, Lausanne
1748; Opera Omnia, Ser. 1, Vol. 90.
[3] H. F ¨URSTENBERG: On the inﬁnitude of primes, Amer. Math. Monthly 62
(1955), 353.

Bertrand's postulate 
Chapter 2 
We have seen that the sequence of prime numbers 2,3,5,7,. . . is infinite. 
To see that the size of its gaps is not bounded, let N := 2 . 3 . 5 . . . . . p 
denote the product of all prime numbers that are smaller than k + 2, and 
note that none of the k numbers 
is prime, since for 2 5 i < k + 1 we know that i has a prime factor that is 
smaller than k + 2, and this factor also divides N, and hence also N + i. 
With this recipe, we find, for example, for k = 10 that none of the ten 
numbers 
2312,2313,2314.. . . ,2321 
is prime. 
But there are also upper bounds for the gaps in the sequence of prime num- 
bers. A famous bound states that "the gap to the next prime cannot be larger 
than the number we start our search at." This is known as Bertrand's pos- 
tulate, since it was conjectured and verified empirically for n < 3 000 000 
by Joseph Bertrand. It was first proved for all n by Pafnuty Chebyshev in 
1850. A much simplcr proof was given by the Indian genius Ramanujan. 
Our Book Proof is by Paul Erdiis: it is taken from Erdiis' first published 
paper, which appeared in 1932, when Erd6s was 19. 
4 
Bertrand's postulate. 
For every n > 1, there is some prime number p with n < p 5 272. 
Proof. We will estimate the size of the binomial coefficient (2) 
care- 
fully enough to see that if it didn't have any prime factors in the range 
n < p < 271, then it would be "too small." Our argument is in five steps. 
(1) We first prove Bertrand's postulate for n < 4000. For this one does not 
need to check 4000 cases: it suffices (this is "Landau's trick") to check that 
is a sequence of prime numbers, where each is smaller than twice the previ- 
ous one. Hence every interval {y : n < y 5 2n), with n 5 4000, contains 
one of these 14 primcs. 
Joseph Bertrand 
Beweis eines Satzes von Tschebyschef. 
Vun P Enods ~n Budapest. 

8 
Bertrand's postulate 
Legendre's theorem 
The number n! contains the prime 
factor p exactly 
times. 
Proof. Exactly La] of the factors 
ofn! = 1.2.3.. . :naredivisibleby 
p, which accounts for 
p-factors. 
Next, 
of the factors of n! are 
even divisible by p2, which accounts 
for the next 151 prime factors p 
of n!, etc. 
0 
(2) Next we prove that np 
5 4"-' 
for all real x > 2, 
(1) 
PS" 
where our notation - 
here and in the following - 
is meant to imply that 
the product is taken over all prime numbers p 5 x. The proof that we 
present for this fact uses induction on the number of these primes. It is 
not from ErdBs' original paper, but it is also due to ErdBs (see the margin), 
and it is a true Book Proof. First we note that if q is the largest prime with 
q 5 x, then 
PS" 
p l q  
Thus it suffices to check (1) for the case where x = q is a prime number. For 
q = 2 we get "2 5 4," so we proceed to consider odd primes q = 2m + 1. 
(Here we may assume, by induction, that (1) is valid for all integers x in 
the set { 2 , 3 ,  . . . ,2m).) For q = 2m + 1 we split the product and compute 
All the pieces of this "one-line computation" are easy to see. In fact, 
holds by induction. The inequality 
(2m+l)! 
follows from the observation that ('",+') 
= 
is an integer, where 
the primes that we consider all are factors of the numerator (2m + I)!, but 
not of the denominator m! (m + I)!. Finally 
holds since 
are two (equal!) summands that appear in 
(3) From Legendre's theorem (see the box) we get that (2) 
= 
con- 
tains the prime factor p exactly 

Bertrand's vostulate 
9 
times. Here each summand is at most 1, since it satisfies 
and it is an integer. Furthermore the summands vanish whenever pk > 2n. 
Thus (t" 
contains p exactly 
times. Hence the largest power of p that divides (2) 
is not larger than 2n. 
In particular, primes p > 
appear at most once in (z) 
. 
Furthermore - 
and this, according to Erdas, is the key fact for his proof 
- 
primes p that satisfy 3n < p < n do not divide (2) 
at all! Indeed, 
3p > 271 implies (for n > 3, and hence p > 3) that p and 2p are the only 
multiples of p that appear as factors in the numerator of s, 
while we get 
two p-factors in the denominator. 
(4) Now we are ready to estimate (z). 
For n > 3, using an estimate from 
page 12 for the lower bound, we get 
and thus, since there are not more than fi 
primes p < fi, 
(5) Assume now that there is no prime p with n < p < 2n, so the second 
product in (2) is 1. Substituting (1) into (2) we get 
4" < 
- ( 2 n ) 1 + 6 4 $ n  
or 
4S" < 
- (2n)l+JZ;;, 
(3) 
which is false for n large enough! In fact, using a + 1 < 2" (which holds 
for all a > 2, by induction) we get 
and thus for n > 50 (and hence 18 < 2 f i )  we obtain from (3) and (4) 
This implies (2n)'l3 < 20, and thus n < 4000. 
Examples such as 
(;:) 
= 23 . 5' . 7 .  1 7 . 1 9 . 2 3  
(::) 
= 23 . 33 . 5' . 17. 19 . 2 3  
(;;) 
= a4 . 3' . 5  . 17. 1 9 . 2 3 . 2 9  
illustrate that "very small" prime factors 
p < 6 
can appear as higher powers 
in (?), '%mall3' primes with fi < 
p 5 $n appear at most once, while 
factors in the gap with $n < p < n 
don't appear at all. 

10 
Bertrand's ~ostulate 
One can extract even more from this type of estimates: From (2) one can 
derive with the same methods that 
n p 2 2 h n  for n 2 4000, 
n<pS2n 
and thus that there are at least 
1 
n 
log,, ( 2  +) 
= - 
30 log2 n + 1 
primes in the range between n and 2n. 
This is not that bad an estimate: the "true" number of primes in this range 
is roughly n/ log n. This follows from the "prime number theorem," which 
says that the limit 
# { p  < n : p is prime] 
lim 
n-a 
n/ log n 
exists, and equals 1. This famous result was first proved by Hadamard and 
de la VallCe-Poussin in 1896; Selberg and ErdBs found an elementary proof 
(without complex analysis tools, but still long and involved) in 1948. 
On the prime number theorem itself the final word, it seems, is still not in: 
for example a proof of the Riemann hypothesis (see page 41), one of the 
major unsolved open problems in mathematics, would also give a substan- 
tial improvement for the estimates of the prime number theorem. But also 
for Bertrand's postulate, one could expect dramatic improvements. In fact, 
the following is a famous unsolved problem: 
Is there always a prime between n2 and (n + 1)2 ? 
For additional information see [3, p. 191 and [4, pp. 248, 2571. 
Appendix: Some estimates 
Estimating via integrals 
There is a very simple-but-effective method of estimating sums by integrals 
(as already encountered on page 4). For estimating the harmonic numbers 
we draw the figure in the margin and derive from it 
by comparing the area below the graph o f f  (t) = 
( 1  < t < n) with 
area of the dark shaded rectangles, and 
the 

Bertrand's postulate 
11 
by comparing with the area of the large rectangles (including the lightly 
shaded parts). Taken together, this yields 
1 
l o g n +  - < Hn < logn + 1. 
n 
In particular, lim H, + co, and the order of growth of H, is given by 
n-00 
lirn &- = 1. But much better estimates are known (see [2]), such as 
,l+nc: 
'09 rL 
Here 0 ($) denotes a function f (n) 
1 
1 
1 
H,, = l o g n + y + - - - + -  
such that f (n) < c-$ holds for some 
2n 
12n2 
120n4 
constant c. 
where y = 0.5772 is "Euler's constant." 
Estimating factorials - 
Stirling's formula 
The same method applied to 
n 
log(n!) = log2+10g3+ ...+ logn = C l o g k  
k=2 
where the integral is easily computed: 
Thus we get a lower estimate on n! 
and at the same time an upper estimate 
Here a more careful analysis is needed to get the asymptotics of n!, as given 
Here f (n) -- g ( n )  means that 
And again there are more precise versions available, such as 
Estimating binomial coefficients 
Just from the definition of the binomial coefficients (:) 
as the number of 
k-subsets of an n-set, we know that the sequence (:), 
(y), . . . , (:) 
of 
binomial coefficients 

12 
Bertrand's postulate 
n 
sums to C (i) = 2n 
k=O 
1 
is symmetric: (:) 
= (nlk). 
1
1
 
1
2
 1 
1
3
3
1
 
From the functional equation (2) = 
(knl) one easily finds that for 
1
4
6
4
1
 
1 
5 
10 10 5 
1 
every n the binomial coefficients (i) form a sequence that is symmetric 
1 
6 
15 20 15 6 
1 
and unimodal: it increases towards the middle, so that the middle binomial 
1 
7 
21 35 35 21 7 
1 
coefficients are the largest ones in the sequence: 
Here 1x1 resp. [xl denotes the number x rounded down resp. rounded up 
to the nearest integer. 
From the asymptotic formulas for the factorials mentioned above one can 
obtain very precise estimates for the sizes of binomial coefficients. How- 
ever, we will only need very weak and simple estimates in this book, such 
as the following: (Z) < 2" for all k, while for n > 2 we have 
with equality only for n = 2. In particular, for n > 1, 
This holds since ( L $ 2 1 ) ,  a middle binomial coefficient, is the largest entry 
in the sequence (:) + ( f i )  , (y) , (;) 
, . . . , (nnl), whose sum is 2", and whose 
average is thus 5. 
On the other hand, we note the upper bound for binomial coefficients 
which is a reasonably good estimate for the "small" binomial coefficients 
at the tails of the sequence, when n is large (compared to k). 
References 
P. ERDBS: Beweis eines Satzes von TschebyscheJ Acta Sci. Math. (Szeged) 5 
(1930-32), 194-198. 
R. L. GRAHAM, 
D. E. KNUTH & 0. PATASHNIK: 
Concrete Mathematics. 
A Foundation for Computer Science, Addison-Wesley, Reading MA 1989. 
G. H. HARDY 
& E. M. WRIGHT: 
An Introduction to the Theory of Numbers, 
fifth edition, Oxford University Press 1979. 
P. RIBENBOIM: 
The New Book of Prime Number Records, Springer-Verlag, 
New York 1989. 

Binomial coefficients 
are (almost) never powers 
There is an epilogue to Bertrand's postulate which leads to a beautiful re- 
sult on binomial coefficients. In 1892 Sylvester strengthened Bertrand's 
postulate in the following way: 
Ifn 2 2k, then at least one of the numbers n, n - 1, . . . , n - k + 1 
has a prime divisor p greater than k. 
Note that for n = 2k we obtain precisely Bertrand's postulate. In 1934, 
ErdBs gave a short and elementary Book Proof of Sylvester's result, running 
along the lines of his proof of Bertrand's postulate. There is an equivalent 
way of stating Sylvester's theorem: 
The binomial coeficient 
always has a prime factor p > k. 
With this observation in mind, we turn to another one of ErdBs' jewels. 
When is (;) 
equal to a power m e ?  It is easy to see that there are infinitely 
many solutions for k = .t = 2, that is, of the equation (;) 
= m2. Indeed, 
if (;) 
is a square, then so is ((2n'",')2). To see this, set n(n - 1) = 2 m 2 .  
It follows that 
Chapter 3 
Beginning with (;) 
= 62 we thus obtain infinitely many solutions - 
the 
next one is (2y) = 2 0 4 ~ .  However, this does not yield all solutions. For 
example, (y) = 35' starts another series, as does ('6,s') 
= 1189'. For 
k = 3 it is known that (;) 
= m2 has the unique solution n = 50, m = 140. (7) = 1402 
But now we are at the end of the line. For k 2 4 and any l > 2 no solutions 
is the only solution for k = 3, e = 2 
exist, and this is what ErdBs proved by an ingenious argument. 
Theorem. The equation (;) 
= me has no integer solutions with 
t 2 2  a n d 4 _ < k < n - 4 .  

14 
Binomial coeficients are (almost) neverpowers 
Proof. Note first that we may assume n > 2k because of (2) = (rink). 
Suppose the theorem is false, and that (z) = me. The proof, by contra- 
diction, proceeds in the following four steps. 
(1) By Sylvester's theorem, there is a prime factor p of (z) greater than k ,  
hence pe divides n ( n  - 1) . . . (n - k + 1). Clearly, only one of the factors 
n - i can be a multiple of p (because of p > k), and we conclude pe I n - i, 
and therefore 
n > pe > ke > k2. 
(2) Consider any factor n - j of the numerator and write it in the form 
n - j = ajm:, where aj is not divisible by any nontrivial e-th power. We 
note by (1) that aj has only prime divisors less than or equal to k. We want 
to show next that ai # aj for i # j. Assume to the contrary that ai = aj 
for some i < j. Then mi 2 mj + 1 and 
which contradicts n > k2 from above. 
(3) Next we prove that the ai's are the integers 1.2,. . . , k in some order. 
(According to ErdBs, this is the crux of the proof.) Since we already know 
that they are all distinct, it suffices to prove that 
aoal . . . ak-1 
divides k!. 
Substituting n - j = a,m! into the equation (2) = me, we obtain 
Cancelling the common factors of mo . . . m k - 1  and m yields 
with gcd(u, v) = 1. It remains to show that v = 1. If not, then v con- 
tains a prime divisor p. Since gcd(u, v) = 1, p must be a prime divisor 
of aoal . . . ak-1 and hence is less than or equal to k. By the theorem of 
Legendre (see page 8) we know that k! contains p to the power xi,, 1s J. 
We now estimate the exponent of p in n(n - 1) . . . (n - Ic + 1). Let i be a 
positive integer, and let bl < b2 < . . . < b, be the multiples of pi among 
n, n - 1 , .  . . , n - k + 1. Then b, = bl + ( s  - l ) p i  and hence 
which im~lies 

Binomial coeflicients are (almost) never powers 
15 
So for each i the number of multiples of pi among n, . . . , n-k+1, and 
hence among the aj9s, is bounded by 1s J + 1. This implies that the expo- 
nent of p in aoal . . . ak-1 is at most 
with the reasoning that we used for Legendre's theorem in Chapter 2. The 
only difference is that this time the sum stops at i = C - 1, since the aj's 
contain no C-th powers. 
Taking both counts together, we find that the exponent of p in ve is at most 
and we have our desired contradiction, since ve is an !-th power. 
This suffices already to settle the case C = 2. Indeed, since k > 4 one of 
We see that our analysis so far agrees 
the ai's must be equal to 4, but the at's contain no squares. So let us now 
with (530) = l40', as 
assume that l > 3. 
50 = 2.5' 
49 = 1 .  72 
(4) Since k > 4, we must have ai, = 1, ai, = 2, a,, = 4 for some il, i2, i3, 
48 = 3.4' 
that is, 
e 
e 
e 
and 5 . 7 . 4  = 140. 
n -il = m,, n -  i2 = 2m2, n -  i3 = 4m3. 
We claim that (n - i2)2 # (n - il)(n - 23). If not, put b = n - i2 and 
n - il = b - x, n - ig = b + y, where 0 < 1x1, Iyl < k. Hence 
where x = y is plainly impossible. Now we have by part (1) 
which is absurd. 
So we have mz # mlm3, where we assume mi > mlm3 (the other case 
being analogous), and proceed to our last chains of inequalities. We obtain 
Since e 2 3 and n > ke > k3 > 6k, this yields 

16 
Binomial coefficients are (almost) never uowers 
Now since mi < d l e  < n113 we finally obtain 
or k3 > n. With this contradiction, the proof is complete. 
References 
[I] P. ERDOS: A theorem of Sylvester and Schul; J .  London Math. Soc. 9 (1934), 
282-288. 
[2] P. ERDOS: On a diophantine equation, J .  London Math. Soc. 26 (1951), 
176- 178. 
[3] J. J. SYLVESTER: 
On arithmetical series, Messenger of Math. 21 (1892), 1-19, 
87- 120; Collected Mathematical Papers Vol. 4, 19 12, 687-73 1. 

Representing numbers 
as sums of two squares 
P- 
Which numbers can be written as sums of two squares? 
This question is as old as number theory, and its solution is a classic in the 
field. The "hard" part of the solution is to see that every prime number of 
the form 4m + 1 is a sum of two squares. G. H. Hardy writes that this 
two square theorem of Fermat "is ranked, very justly, as one of the finest in 
arithmetic." Nevertheless, one of our Book Proofs below is quite recent. 
Let's start with some "warm-ups." First, we need to distinguish between 
the prime p = 2, the primes of the form p = 4m + 1, and the primes of 
the form p = 4m + 3. Every prime number belongs to exactly one of these 
three classes. At this point we may note (using a method ''2 la Euclid") that 
there are infinitely many primes of the form 4m + 3. In fact, if there were 
only finitely many, then we could take pk to be the largest prime of this 
form. Setting 
Nk := 2 2 . 3 . 5 . . . p k - 1  
(where pl = 2, pz = 3, pg = 5  , . . . denotes the sequence of all primes), 
we find that N k  is congruent to 3  (mod 4), so it must have a prime factor of 
the form 4m + 3, and this prime factor is larger than pk - 
contradiction. 
At the end of this chapter we will also derive that there are infinitely many 
primes of the other kind, p  = 4m + 1. 
Our first lemma is a special case of the famous "law of reciprocity": 
It characterizes the primes for which -1 is a square in the field Z, (which 
is reviewed in the box on the next page). 
Lemma 1. Forprimes p = 4m + 1 the equation s2 - -1 (modp) has two 
solutions s  E {1,2, . . ., p - l ) ,  for p  = 2 there is one such solution, while 
forprimes of the form p  = 4m + 3  there is no solution. 
H Proof. For p  = 2 take s = 1. For odd p, we construct the equivalence 
relation on { 1 , 2 ,  . . . , p - 1) that is generated by identifying every element 
with its additive inverse and with its multiplicative inverse in Z,. Thus the 
"general" equivalence classes will contain four elements 
{x, -x, z, 
-z} 
Chapter 4 
Pierre de Fermat 
since such a 4-element set contains both inverses for all its elements. How- 
ever, there are smaller equivalence classes if some of the four numbers are 
not distinct: 

18 
Representing numbers as sums of two squares 
0 x = -x is impossible for odd p. 
0 x = Z is equivalent to x2 = 1. This has two solutions, namely x = 1 
and x = p - 1, leading to the equivalence class (1, p - 1) of size 2. 
- 
x - -x is equivalent to x2 - -1. This equation may have no solution 
or two distinct solutions xo, p - xo: in this case the equivalence class 
is 1x0, P - xo). 
For p = 11 the partition is 
The set {1,2, . . . , p - 1) has p - 1 elements, and we have partitioned it into 
{lllo}. {‘49,6,5>, {3,8,4,7); 
quadruples (equivalence classes of size 4), plus one or two pairs (equiva- 
for p = 13 it is 
lence classes of size 2). For p - 1 = 4m + 2 we find that there is only the 
(1,121, {2,11,7.6}, (3, 10(1,12),o, 
9-41, 
one pair (1, p - I), the rest is quadruples, and thus s2 = - 1 (modp) has no 
(5.8): the pair {5,8} yields the two 
solution. For p - 1 = 4m there has to be the second pair, and this contains 
solutions of s2 = -1 mod 13. 
the two solutions of s2 = - 1 that we were looking for. 
0 
Prime fields 
If p is a prime, then the set Z, = {0,1, . . . , p - 1) with addition and 
multiplication defined "modulo p" forms a finite field. We will need 
the following simple properties: 
0 For x E Z,, x # 0, the additive inverse (for which we usually 
write-x)isgivenbyp-xE 
{1,2, . . . , p -  1). I f p >  2,thenx 
and -x are different elements of Z,. 
Each x E Zp\{O) has a unique multiplicative inverse 3 E Zp\{O), 
with XZ - 1 (mod p). 
The definition of primes implies that the map Z, -+ Z,, z H 
xz 
is injective for x # 0. Thus on the finite set Z,\{O) 
it must be 
surjective as well, and hence for each x there is a unique Z # 0 
with xZ = 1 (modp). 
0 The squares 02, 12, 2', . . . , h2 define different elements of Z,, for 
h = LgJ. 
This is since x2 = y2, or (x + y)(x - y) E 0, implies that x E y 
or that z = - y. The 1 + 151 elements 02, 12, . . . , h2 are called 
the squares in Z,. 
Addition and multiplication in &, 
At this point, let us note "on the fly" that for all primes there are solutions 
for x2 + y2 = -1 (modp). In fact, there are 151 + 1 distinct squares 
x2 in Z,, and there are 
+ 1 distinct numbers of the form -(1 + y2). 
These two sets of numbers are too large to be disjoint, since Z, has only p 
elements, and thus there must exist x and y with x2 = -(I + y2) (modp). 
Lemma 2. No number n = 4m + 3 is a sum of two squares. 
Proof. The square of any even number is ( 2 l ~ ) ~  
= 4k2 -- 0 (mod4), 
while squares of odd numbers yield (2k+ 1)2 = 4(k2 + k) + 1 = 1 (mod4). 
Thus any sum of two squares is congruent to 0 , l  or 2 (mod4). 
0 

Representing numbers as sums of two squares 
19 
This is enough evidence for us that the primes p = 4m + 3 are "bad." Thus, 
we proceed with "good" properties for primes of the form p = 4m + 1. On 
the way to the main theorem, the following is the key step. 
Proposition. Every prime of the form p = 4m + 1 is a sum of two squares, 
that is, it can be written a s p  = x2 + y2 for some natural numbers x, y E N. 
We shall present here two proofs of this result - 
both of them elegant and 
surprising. The first proof features a striking application of the "pigeon- 
hole principle" (which we have already used "on the fly" before Lemma 2; 
see Chapter 22 for more), as well as a clever move to arguments "modulo p" 
and back. The idea is due to the Norwegian number theorist Axel Thue. 
Proof. Consider the pairs (x', y') of integers with 0 < x', y' < fi, 
that 
is, x', y' E (0.1, . . . , [,,$I 
}. There are ( L,,$J 
+ 1)2 such pairs. Using the 
estimate 1x1 + 1 > x for x = fi, 
we see that we have more than p such 
pairs of integers. Thus for any s E Z, it is impossible that all the values 
1.' - sy' produced by the pairs (x', y') are distinct modulo p. That is, for 
every s there are two distinct pairs 
( X  , y ; (
X
 
y 
E 
with 
x1 - syl = 2'' 
Now we take differences: We have x' 
we define 
I 
I' 
x : =  Ix - x  
1 ,  
then we get 
(x, y) 
{0,1,. . . , LJiT1 l2 
- syl' (mod p). 
- x" -- s(yl - y") (mod p). Thus if 
with 
x - f s y ( m o d p ) .  
Also we know that not both x and y can be zero, because the pairs (x', y') 
and (x", u") are distinct. 
Now let s be a solution of s2 - -1 (modp), which exists by Lemma 1. 
Then x2 = s2 y2 = - y2 (modp), and so we have produced 
(x, y) E Z2 
with 
0 < x2 + y2 < 2p 
and 
x2 + y2 = 0 (modp). 
But p is the only number between 0 and 2p that is divisible by p. Thus 
x2 + y2 = p: done! 
0 
Our second proof for the proposition - also clearly a Book Proof - 
was discovered by Roger Heath-Brown in 1971 and appeared in 1984. 
(A condensed "one-sentence version" was given by Don Zagier.) It is so 
elementary that we don't even need to use Lemma 1. 
For p = 13, L f i ]  
= 3 we consider 
x', y' E {O,l, 2,3). For s = 5, the sum 
XI-sy' (mod 13) assumes the following 
values: 
4 
12 
2 
10 
5 
3 
11 
6 
Heath-Brown's argument features three linear involutions: a quite obvious 
one, a hidden one, and a trivial one that gives "the final blow." The second, 
unexpected, involution corresponds to some hidden structure on the set of 
integral solutions of the equation 4xy + z2 = p. 

20 
Representing numbers as sums of two squares 
Proof. We study the set 
This set is finite. Indeed, x > 1 and y > 1 implies y < 2 and x 5 $. So 
there are only finitely many possible values for x and y, and given x and y, 
there are at most two values for z. 
1. The first linear involution is given by 
that is, "interchange x and y, and negate z." This clearly maps S to itself, 
and it is an involution: Applied twice, it yields the identity. Also, f has 
no fixed points, since z = 0 would imply p = 4xy, which is impossible. 
Furthermore, f maps the solutions in 
T := { ( x ,  y, z )  E S : z > 0 )  
to the solutions in S\T, which satisfy z < 0. Also, f reverses the signs of 
x - y and of z, so it maps the solutions in 
U := { ( x , y , z )  E S :  ( x - y ) + z > O )  
to the solutions in S\U. 
For this we have to see that there is no solution 
with ( x -  y)+z = 0, but there is none since this would givep = 4xy+z2 = 
4xy + ( x  - y)2 = ( x  + Y ) ~ .  
What do we get from the study of f ?  The main observation is that since 
f maps the sets T and U to their complements, it also interchanges the 
elements in T\U 
with these in U\T. That is, there is the same number of 
solutions in U that are not in T as there are solutions in T that are not in U 
- 
so T and U have the same cardinality. 
2. The second involution that we study is an involution on the set U: 
g :  U - U ,  
(x,y,z)++ 
( x - y + z , y , 2 y - z ) .  
First we check that indeed this is a well-defined map: If ( x ,  y, z )  E U ,  then 
x - y + z > 0, y > 0 and 4(x - y + z)y + (2y - 2 ) 2  = 4xy + z2, so 
g(x, y, z )  E S. By ( x  - y + z )  - y + (2y - z )  = x > 0 we find that indeed 
g(x, Y, z )  E U. 
Also g is an involution: g(x, y, z )  = ( x  - y + z, y, 2y - z )  is mapped by g 
to ( ( x  - Y  + z )  - Y  + (2Y - ~ I , Y , ~ Y  - ( 2 ~  
- z ) )  = ( x , Y , ~ ) .  
And finally: g has exactly one fixed point: 
holds exactly if y = z: But then p = 4xy + y2 = (4x + y)y, which holds 
only for y = 1 = z,andx = 9. 
But if g is an involution on U that has exactly one fixed point, then the 
cardinality of U is odd. 

Representing numbers as sums of two squares 
2 1 
3. The third, trivial, involution that we study is the involution on T that 
interchanges x and ?I: 
This map is clearly well-defined, and an involution. We combine now our 
knowledge derived from the other two involutions: The cardinality of T is 
L 
equal to the cardinality of U ,  which is odd. But if h is an involution on 
(x, y, z) E T with x = y, that is, a solution of 
w 
a finite set of odd cardinality, then it has a $xed point: There is a point 
On a finite set of odd cardinality, every 
involution has at least one fixed point. 
Note that this proof yields more - 
the number of representations of p in 
the form p = x2 + ( 2 ~ ) '  is odd for all primes of the form p = 4m + 1. (The 
representation is actually unique, see [3].) Also note that both proofs are 
not effective: Try to find x and y for a ten digit prime! Efficient ways to find 
such representations as sums of two squares are discussed in [I] and [7]. 
The following theorem completely answers the question which started this 
chapter. 
Theorem. A natural number n can be represented as a sum of two squares 
if and only if every prime factor of the form p = 4m + 3 appears with an 
even exponent in the prime decomposition of n. 
Proof. Call a number n representable if it is a sum of two squares, that 
is, if n = x2 + y2 for some x, y E No. The theorem is a consequence of 
the following five facts. 
(1) 1 = 1' + 0' and 2 = 1' + 1' are representable. Every prime of the 
form p = 4m + 1 is representable. 
(2) The product of any two representable numbers n l  = xf + y: and n2 = 
x i  + y$ is representable: nln2 = ( ~ 1 x 2  + y l y ~ ) ~  
+ (xly2 - x ~ y 1 ) ~ .  
(3) If n is representable, n = x2 + y2, then also nz2 is representable, by 
nz2 = (xz)' + (yz)'. 
Facts (I), (2) and (3) together yield the "if" part of the theorem. 
(4) If p = 4m + 3 is a prime that divides a representable number n = 
x2 + y2, then p divides both x and y, and thus p2 divides n. In fact, if 
we had x $ 0 (modp), then we could find Z such that xl: - 1 (modp), 
multiply the equation x 2  + y2 = 0 by z2, and thus obtain 1 + y2Z2 = 
1 + ( ~ y ) '  - 0 (modp), which is impossible for p = 4m + 3 by 
Lemma 1. 
(5) If n is representable, and p = 4m + 3 divides n, then p2 divides n, 
and nlp2 is representable. This follows from (4), and completes the 
proof. 
0 

22 
Representing numbers as sums of two squares 
As a corollary, we obtain that there are infinitely many primes of the form 
p = 4m + 1. For this, we consider 
a number that is congruent to 1 (mod4). All its prime factors are larger 
than pk, and by fact (4) cf the previous proof, it has no prime factors of the 
form 4m + 3. Thus Mk has a prime factor of the form 4 m  + 1 that is larger 
than pk. 
Two remarks close our discussion: 
If a and b are two natural numbers that are relatively prime, then there are 
infinitely many primes of the form a m  + b (m E N) - 
this is a famous 
(and difficult) theorem of Dirichlet. More precisely, one can show that 
the number of primes p < x of the form p = a m  + b is described very 
accurately for large x by the function 
&, 
where p(x) denotes the 
number of b with 1 < b < a that are relatively prime to a. (This is 
a substantial refinement of the prime number theorem, which we had 
discussed on page 10.) 
This means that the primes for fixed a and varying b appear essentially 
at the same rate. Nevertheless, for example for a = 4 one can observe a 
rather subtle, but nevertheless noticable and persistent tendency towards 
"more" primes of the form 4m + 3: If you look for a large random x, then 
chances are that there are more primes p 5 x of the form p = 4m + 3 
than of the form p = 4m + 1. This effect is known as "Chebyshev's 
bias"; see Riesel [4] and Rubinstein and Sarnak [5]. 
References 
[I] F. W. CLARKE, 
W. N. EVERITT, 
L. L. LITTLEJOHN 
& S. J. R. VORSTER: 
H. J. S. Smith and the Fermat Two Squares Theorem, Amer. Math. Monthly 
106 (1999), 652-665. 
[2] D. R. HEATH-BROWN: 
Fermat's two squares theorem, Invariant (1984), 2-5. 
[3] I. NIVEN & H. S. ZUCKERMAN: 
An Introduction to the Theory of Numbers, 
Fifth edition, Wiley, New York 1972. 
[4] H. RIESEL: 
Prime Numbers and Computer Methods for Factorization, Second 
edition, Progress in Mathematics 126, Birkhauser, Boston MA 1994. 
[5] M. RUBINSTEIN 
& P. SARNAK: 
Chebyshev's bias, Experimental Mathematics 
3 (1994), 173-197. 
[6] A. THUE: Etpar antydninger ti1 en taltheoretisk metode, Kra. Vidensk. Selsk. 
Forh. 7 (1902), 57-75. 
[7] S. WAGON: Editor's corner: The Euclidean algorithm strikes again, Amer. 
Math. Monthly 97 (1990), 125-129. 
[8] D. ZAGIER: 
A one-sentence proof that every prime p = 1 (mod 4) is a sum of 
two squares, Amer. Math. Monthly 97 (1990), 144. 

Every finite division ring is a field 
Chapter 5 
Rings are important structures in modem algebra. If a ring R has a mul- 
tiplicative unit element 1 and every nonzero element has a multiplicative 
inverse, then R is called a division ring. So, all that is missing in R from 
being a field is the commutativity of multiplication. The best-known exam- 
ple of a non-commutative division ring is the ring of quaternions discovered 
by Hamilton. But, as the chapter title says, every such division ring must of 
necessity be infinite. If R is finite, then the axioms force the multiplication 
to be commutative. 
This result which is now a classic has caught the imagination of many math- 
ematicians, because, as Herstein writes: "It is so unexpectedly interrelating 
two seemingly unrelated things, the number of elements in a certain alge- 
braic system and the multiplication of that system." 
Theorem. Evely Jinite division ring R is commutative. 
Ernst Witt 
This beautiful theorem which is usually attributed to MacLagan Wedder- 
bum has been proved by many people using a variety of different ideas. 
Wedderburn himself gave three proofs in 1905, and another proof was given 
by Leonard E. Dickson in the same year. More proofs were later given by 
Emil Artin, Hans Zassenhaus, Nicolas Bourbaki, and many others. One 
proof stands out for its simplicity and elegance. It was found by Ernst Witt 
in 1931 and combines two elementary ideas towards a glorious finish. 
Proof. Our first ingredient comes from a blend of linear algebra and 
basic group theory. For an arbitrary element s E R, let C, be the set 
{ x  E R : xs = sx) of elements which commute with s; C, is called the 
centralizer of s. Clearly, C, contains 0 and 1 and is a sub-division ring 
of R. The center Z is the set of elements which commute with all elements 
of R, thus Z = nSER 
C,. In particular, all elements of Z commute, 0 and 1 
are in Z, and so 2 is a$niteJield. Let us set IZI = q. 
We can regard R and C, as vector spaces over the field Z and deduce that 
IRI = qn, where n is the dimension of the vector space R over Z, and 
similarly IC,[ = qns for suitable integers n, > 1. 
Now let us assume that R is not a field. This means that for some s E R 
the centralizer C, is not a11 of R, or, what is the same, n, < n. 
On the set R* := R\{O) we consider the relation 
r' w r 
: 
T' = x-'rx 
for some x E R* 

24 
Every finite division ring is a field 
It is easy to check that N is an equivalence relation. Let 
A, := { x - l s x  : x E R*) 
be the equivalence class containing s .  We note that IA,I = 1 precisely 
when s is in the center 2. So by our assumption, there are classes A, with 
/A,/ > 2. Consider now for s E R* the map f ,  : x - 
xklsx from R* 
onto A,. For x, y E R* we find 
for C,* := C,\{O), where C,*x = { z x  : z E C,* ) has size IC,* 1. Hence any 
element x-lsx is the image of precisely IC,*l = qna - 1 elements in R* 
under the map f,, and we deduce I R* I = I A, 1 I C,* 1. In particular, we note 
We know that the equivalence classes partition R*. We now group the 
central elements Z* together and denote by Al, . . . , At the equivalence 
classes containing more than one element. By our assumption we know 
t > 1. Since I R* I = I Z* I + c L = ~  IAk I, we have proved the so-called 
class formula 
where we have 1 < 
t R for all k. 
With (1) we have left abstract algebra and are back to the natural numbers. 
Next we claim that qnk - 1 I qn - 1 implies n k  I n. Indeed, write n = ank +r 
with 0 5 r < nk, then qnk - 1 1 qankf - 1 implies 
and thus qnk - 1 I q ( a - l ) n k + T  - 1, since qnk and qnk - 1 are relatively 
prime. Continuing in this way we find qnk - 1 I qT - 1 with 0 < r < nk, 
which is only possible for r = 0, that is, nk I n. In summary, we note 
n k  1 n for all k. 
(2) 
Now comes the second ingredient: the complex numbers @. Consider the 
polynomial xn - 1. Its roots in C are called the n-th roots of unity. Since 
An = 1, all these roots X have IXI = 1 and lie therefore on the unit circle of 
2 k x z  
the complex plane. In fact, they are precisely the numbers Xk = e
n
 
= 
c o s ( 2 k ~ l n )  + i s i n ( 2 k ~ / n ) ,  
0 5 k  5 n - 1 (see the box on the next 
page). Some of the roots X satisfy Ad = 1 for d < n; for example, the 
root X = -1 satisfies X2 = 1. For a root A, let d be the smallest positive 
exponent with Ad = 1, that is, d is the order of X in the group of the roots 
of unity. Then d I n, by Lagrange's theorem ("the order of every element of 

EveryJinite division ring is aJield 
25 
a group divides the order of the group" - 
see the box in Chapter 1). Note 
that there are roots of order n, such as XI = e?. 
Roots of unity 
Any complex number z = x + iy may be written in the "polar" form 
z = rezv = ~ ( c o s  
(P + i sin (P), 
where r = lzl = d
m
 
is the distance of z to the origin, and (P is 
the angle measured from the positive x-axis. The n-th roots of unity 
are therefore of the form 
since for all k 
We obtain these roots geometrically by inscribing a regular n-gon 
into the unit circle. Note that Xk = ck for all k, where < = e? . Thus 
the n-th roots of unity form a cyclic group {<, C2, . . . , Cnp1, Cn = 1) 
of order n. 
Now we group all roots of order d together and set 
X of order d 
Note that the definition of &(x) is independent of n. Since every root has 
some order d. we conclude that 
Here is the crucial observation: The coeficients of the polynomials &(x) 
are integers (that is, & ( x )  E Z[x] for all n), where in addition the constant 
coefficient is either 1 or -1. 
Let us carefully verify this claim. For n = 1 we have 1 as the only root, 
and so f#ll ( x )  = x - 1. Now we proceed by induction, where we assume 
~ ~ ( x )  
E Z[x] for all d < n, and that the constant coefficient of dd(x) is 1 
or -1. By (3), 
xn - 1 = P ( X )  f#ln(x) 
(4) 
e 
n-e 
where p(r) = x pjxJ, &(x) = x akxk, with po = 1 or po = -1. 
j=O 
k=O 
The roots of unity for n = 6 
Since -1 = poao, we see a0 E {I, -1). Suppose we already know that 
a". a l ,  . . . , ak-1 E Z. 
Computing the coefficient of xk on both sides of (4) 

26 
Every finite division ring is afield 
we find 
k 
By assumption, all ao, . . . , ak-1 (and all pj) are in Z. 
Thus poak and hence 
ak must also be integers, since po is 1 or -1. 
We are ready for the coup de grdce. Let n k  I n be one of the numbers 
appearing in (1). Then 
We conclude that in Z 
we have the divisibility relations 
Since (5) holds for all Ic, we deduce from the class formula (1) 
but this cannot be. Why? We know & ( x )  = n ( x  - A) where A runs 
through all roots of xn - 1 of order n. Let 1 = a + ib be one of those roots. 
By n > 1 (because of R # 2) 
we have 1 # 1, which implies that the real 
- 
part a is smaller than 1. Now I XI2 = a2 + b2 = 1, and hence 
> q2 - 2q + 1 
(because of a < 1) 
and so Iq - XI > q - 1 holds for all roots of order n. This implies 
which means that &(q) cannot be a divisor of q - 1, contradiction and end 
of proof. 
0 
References 
L. E. DICKSON: 
On jinite algebras, Nachrichten der Akad. Wissenschaften 
Gottingen Math.-Phys. Klasse (1905), 1-36; Collected Mathematical Papers 
Vol. 111, Chelsea Publ. Comp, The Bronx, NY 1975, 539-574. 
J. H. M. WEDDERBURN: 
A theorem onjinite algebras, Trans. Amer. Math. 
SOC. 6 (1905), 349-352. 
E. WITT: ~ b e r  
die Kommutativitat endlicher Schiej7corper; Abh. Math. Sem. 
Univ. Hamburg 8 (1931), 413. 

Some irrational numbers 
''IT is irrational" 
This was already conjectured by Aristotle, when he claimed that diameter 
and circumference of a circle are not commensurable. The first proof of 
this fundamental fact was given by Johann Heinrich Lambert in 1766. Our 
Book Proof is due to Ivan Niven, 1947: an extremely elegant one-page 
proof that needs only elementary calculus. Its idea is powerful, and quite 
a bit more can be derived from it, as was shown by Iwamoto and Koksma, 
respectively: 
r2 is irrational and 
e' is irrational for rational r # 0. 
Niven's method does, however, have its roots and predecessors: It can be 
traced back to the classical paper by Charles Hermite from 1873 which 
first established that e is transcendental, that is, that e is not a zero of a 
polynomial with rational coefficients. 
Before we treat r we will look at e and its powers, and see that these are 
irrational. This is much easier, and we thus also follow the historical order 
in the development of the results. 
To start with, it is rather easy to see (as did Fourier in 1815) that e = 
xk20 
$ is irrational. Indeed, if we had e = 
for integers a and b > 0, 
then we would get 
n!be = n!a 
for evep n 2 0. But this cannot be true, because on the right-hand side we 
have an integer, while the left-hand side with 
decomposes into an integral part 
1
1
 
bn! I + - + - + . . . + -  
( 
l! 
2! 
n! 
and a second part 
Chapter 6 
Charles Hermite 

28 
Some irrational numbers 
Geometric series 
For the infinite geometric series 
with q > 1 we clearly have 
q Q =  I + ; + $ +  
... = 1 + Q  
and thus , 
'gl 
JOURNAL DE MATHEMATIQOV, 
------- 
.---- 
..-----... 
SUR L'IRRATIONNALITI~ DU NOMBRE 
e =  1,7r8 ...; 
PA. d LIOUVILLE. 
On prouve dam ler elbments que le n o m h ~  
e ,  hase d a  laganthmes 
n6pbnens. n's pns une valenr rationnelle. On dernlt, ce me semble, 
a p t e x  que la mime mbthode prouve ausi que e ne peut par the ra- 
m e  d'ene equation du recond degre 
eodlic~enu ratmnnels, en wrrte 
yon ne put pas avoir a c + )  = c ,  Atant 
mer 
pontlfet b, '. 
des ennerr pos~afr ou dgattfs. En effet, a I'on iemplace dam celte 
equation c et I ou e-' par lean dbveloppematr dedurts de celw de c', 
puns .+on 
multiplie les d e w  membres par I 1 3 . n ,  an rrauvera 
aldment 
which is approximately k, so that for large n it certainly cannot be integral: 
It is larger than --& and smaller than k, as one can see from a comparison 
with a geometric series: 
Now one might be led to think that this simple multiply-by-n! trick is not 
even sufficient to show that e2 is irrational. This is a stronger statement: 
fi is an example of a number which is irrational, but whose square is not. 
From John Cosgrave we have learned that with two nice ideastobservations 
(let's call them "tricks") one can get two steps further nevertheless: Each of 
the tricks is sufficient to show that e2 is irrational, the combination of both 
of them even yields the same for e4. The first trick may be found in a one 
page paper by J. Liouville from 1840 - 
and the second one in a two page 
"addendum" which Liouville published on the next two journal pages. 
Why is e2 irrational? What can we derive from e2 = ;? 
According to 
Liouville we should write this as 
substitute the series 
*L 
" + l  
,-I 
= 
1
1
1
 1 
1 
l - - + - - - + - - - f  
1
2
 6 
24 
120 
"" 
rolt ponbf; ,I r & r a d e r t t p p o r e r n p ~ ~ ~ ~ ~  
b est < o  et n lmpa~rsl b -t 
> o ;  en prenanr de plus n we. grand, I'$aahon 
que nous venonr 
d'knre canduira des Ion & m e  ahrurdtte; car w n  prenner membm 
dtant erlentiellerneor porltlf et her pht, sera c a m p  entre o el ,, 
et ne pa"rr= pas ewe egal a ,I" 
entler ". Dome. etc 
and then multiply by n!, for a sufficiently large even n. Then we see that 
n!be is nearly integral: 
- 
Liouville's paper 
is an integer, and the rest 
is approximately A: It is larger than --& but smaller than A, as we have 
seen above. 
At the same time n!ae-I is nearly integral as well: Again we get a large 
integral part, and then a rest 

Some irrational numbers 
29 
and this is approximately (-I)"+' E. More precisely: for even n the rest is 
larger than - E, but smaller than 
But this cannot be true, since for large even n it would imply that n!aeP1 
is 
just a bit smaller than an integer, while n!be is a bit larger than an integer, 
so n!aepl = n!be cannot hold. 
0 
In order to show that e4 is irrational, we now courageously assume that 
e4 = f were rational, and write this as 
We could now try to multiply this by n! for some large n, and collect the 
non-integral summands, but this leads to nothing useful: The sum of the 
remaining terms on the left-hand side will be approximately b F ,  on the 
right side (-l)"+'a$, 
and both will be very large if n gets large. 
So one has to examine the situation a bit more carefully, and make two little 
adjustments to the strategy: First we will not take an arbitrary large n, but 
a large power of two, n = 2m; and secondly we will not multiply by n!, 
but by A. 
Then we need a little lemma, a special case of Legendre's 
theorem (see page 8): For any n > 1 the integer n! contains the prime 
factor 2 at most n - 1 times - 
with equality if (and only if) n is a power 
of tWO, 71 = 2m. 
This lemma is not hard to show: IF] of the factors of n! are even, 121 of 
them are divisible by 4, and so on. So if 2k is the largest power of two 
which satisfies 2k 5 n, then n! contains the prime factor 2 exactly 
times, with equality in both inequalities exactly if n = 2k. 
Let's get back to be2 = ~ e - ~ .  
We are looking at 
and substitute the series 
For r 5 n we get integral summands on both sides, namely 

30 
Some irrational numbers 
where for r > 0 the denominator r! contains the prime factor 2 at most 
r - 1 times, while n! contains it exactly n - 1 times. (So for r > 0 the 
summands are even.) 
And since n is even (we assume that n = 2"), the series that we get for 
r > n + l a r e  
These series will for large n be roughly $ resp. - %, as one sees again by 
comparison with geometric series. For large n = 2"Qhis means that the 
left-hand side of (1) is a bit larger than an integer, while the right-hand side 
is a bit smaller - 
contradiction! 
0 
So we know that e4 is irrational; to show that e3, e5 etc. are irrational as 
well, we need heavier machinery (that is, a bit of calculus), and a new idea 
- 
which essentially goes back to Charles Hermite, and for which the key 
is hidden in the following simple lemma. 
Lemma. For somejxed n > 1, let 
1 2n 
(i) The function f ( x )  is a polynomial of the form f ( x )  = - 
cixi, 
n! 
where the coeficients ci are integers. 
z=n 
(ii) For 0 < x < 1 we have 0 < f ( x )  < 5. 
(iii) The derivatives f ( k )  (0) and f ( k )  (1) are integers for all k > 0. 
Proof. Parts (i) and (ii) are clear. 
For (iii) note that by (i) the Ic-th derivative f ( k )  vanishes at x = 0 unless 
n < k < 2n, and in this range f("(0) = g c k  
n! 
is an integer. From f ( x )  = 
f (1 -2) we get f ( k ) ( x )  = (-l)"fk)(l -2) for all x, and hence f ("(1) = 
(-1)'" f("(0), which is an integer. 
0 
Theorem 1. er is irrational for every r E Q\{O). 
Proof. It suffices to show that es cannot be rational for a positive integer 
s t 
s (if ef were rational, then ( e i )  = eS would be rational, too). Assume 
The estimate n! > e(:)n yields an 
that es = % for integers a, b > 0, and let n be so large that n! > as2"+ l. 
explicit n that is "large enough." 
Put 
F ( x )  := s2n f ( x )  - sanpl 
f ' ( x )  + s
~
~
-
~
 
fl'(x) 
. . . + f(2n)(x), 
where f ( x )  is the function of the lemma. 

Some irrational numbers 
3 1 
F ( x )  may also be written as an infinite sum 
F ( x )  = s2" f ( x )  - sZn-' f l ( x )  + s
~
~
-
~
 
f U ( x )  7 . . . , 
since the higher derivatives f("(x), for k > 2n, vanish. From this we see 
that the polynomial F ( x )  satisfies the identity 
F1(x) = -s F ( x )  + s2"" 
f ( x ) .  
Thus differentiation yields 
d - 
[eSxF(x)] = seSxF(x) + eSx F1(x) = s2n+1esx f ( x )  
dx 
and hence 
This is an integer, since part (iii) of the lemma implies that F(0) and F ( l )  
are integers. However, part (ii) of the lemma yields estimates for the size 
of N from below and from above, 
which shows that N cannot be an integer: contradiction. 
Now that this trick was so successful, we use it once more. 
Theorem 2. .ir2 is irrational. 
Proof. Assume that -ir2 = 
for integers a, b > 0. We now use the 
polynomial 
F ( x )  := bn (szn 
f ( x )  - -irZnp2 f(')(x) + 7r2n-4 f ( l ) ( x )  7 . .  
. ), 
which satisfies F1I(x) = --ir2F(x) + bn-ir2n+2 
f (x). 
From part (iii) of the lemma we get that F(0) and F ( l )  are integers. 
.rr is not rational, but it does have "good 
Elementary differentiation rules yield 
approximations" by rationals - some 
d 
of these were known since antiquity: 
- 
[F1(x) 
sin n x  - n F ( x )  cos -irx] = (F1'(x) + r 2 F ( x ) )  sin -irx 
- 
7 = 3.142857142857 ... 
dx 
- 
- 
- bnT2n+2 
355 
= 3.141592920353 ... 
f ( x )  sin r x  
113 - 
= 3.141592653921 ... 
= -ir2an f ( x )  sin .irx, 
n = 3.141592653589 ... 
and thus we obtain 
an f ( x )  sin -irx dx = 
F1(x) sin n x  - F ( x )  cos -irx 
which is an integer. Furthermore N is positive since it is defined as the 

3 2 
Some irrational numbers 
integral of a function that is positive (except on the boundary). However, 
if we choose n so large that 
< 1, then from part (ii) of the lemma we 
obtain 
a contradiction. 
Here comes our final irrationality result. 
Theorem 3. For every odd integer n 2 3, the number 
1 
A(n) := - arccos (5) 
T 
is irrational. 
We will need this result for Hilbert's third problem (see Chapter 8) in the 
cases n = 3 and n = 9. For n = 2 and n = 4 we have A(2) = 
and 
A(4) = i, so the restriction to odd integers is essential. These values 
are easily derived by appealing to the diagram in the margin, in which the 
statement ''a arccos (&) is irrational" is equivalent to saying that the 
polygonal arc constructed from &, all of whose chords have the same 
length, never closes into itself. 
We leave it as an exercise for the reader to show that A(n) is rational only 
for n E {1,2,4). For that, distinguish the cases when n = 2T, and when n 
is not a power of 2. 
H Proof. We use the addition theorem 
from elementary trigonometry, which for cu = (k + 1)y and P = (k - l ) y  
yields 
cos (Ic + 1 ) y  = 2 coscp cos k y  - cos (k - 1)y. 
(2) 
For the angle y, = arccos (-$=I. 
which is defined by cos y, = 1 
and 
J;; 
0 < cp, 5 T ,  this yields representations of the form 
cos ky, 
= - 
A k 
J;;" 
where Ak is an integer that is not divisible by n, for all k > 0. In fact, 
we have such a representation for k = 0 , l  with A. = Al = 1, and by 
induction on k using (2) we get for k > 1 
Thus we obtain Ak+l = 2Ak - nAkPl. If n 2 3 is odd, and Ak is not 
divisible bv n. then we find that Ahl, cannot be divisible bv n. either. 

Some irrational numbers 
3 3 
is rational (with integers k ,  4 > 0). Then Pp,, = k~ yields 
A! 
&l = cos k7r = - 
fie 
Thus & = f 
Ae is an integer, with ! 2 2, and hence n 1 A'. With 
fil I At we find that n divides At, a contradiction. 
0 
References 
[ I ]  C. HERMITE: Sur la fonction exponentielle, Comptes rendus de 1'AcadCmie 
des Sciences (Paris) 77 (I 873), 18-24; (Euvres de Charles Hermite, Vol. 111, 
Gauthier-Villars, Paris 191 2, pp. 150- 18 1. 
(23 Y. IWAMOTO: A proof that r2 is irrational, J. Osaka Institute of Science and 
Technology 1 (1949), 147-148. 
[3] J. F. KOKSMA: On Niven's proof that r is irrational, Nieuw Archief voor 
Wiskunde (2) 23 (1949), 39. 
[4] J. LIOUVILLE: 
Sur 1 'irrationalite'du nombre e = 2,718 ..., Journal de MathC- 
matiques Pures et Appl. ( I )  5 ( 1  840), 192; Addition, 193.194. 
[5] I. NIVEN: A simple proof that r is irrational, Bulletin Amer. Math. Soc. 53 
(1947), 509. 

Three times n2/6 
Chapter 7 
We know that the infinite series 
$ does not converge. Indeed, in 
- 
Chapter 1 we have seen that even the series EpGp 
diverges. 
However, the sum of the reciprocals of the squares converges (although 
very slowly, as we will also see), and it produces an interesting value. 
P? 
Euler's series. 
1 
7r2 
C a  = - 
n2l 
6 '  
This is a classical, famous and important result by Leonhard Euler from 
1734. One of its key interpretations is that it yields the first non-trivial 
value C(2) of Riemann's zeta function (see the appendix on page 41). This 
value is irrational, as we have seen in Chapter 6. 
But not only the result has a prominent place in mathematics history, there 
are also a number of extremely elegant and clever proofs that have their 
history: For some of these the joy of discovery and rediscovery has been 
shared by many. In this chapter, we present three such proofs. 
Proof. The first proof appears as an exercise in William J. LeVeque's 
number theory textbook from 1956. But he says: "I haven't the slightest 
idea where that problem came from, but I'm pretty certain that it wasn't 
original with me." 
The proof consists in two different evaluations of the double integral 
For the first one, we expand & as a geometric series, decompose the 
summands as products, and integrate effortlessly: 
1
1
 
1
1
 

36 
Three times 7r2/6 
This evaluation also shows that the double integral (over a positive function 
with a pole at x = y = 1) is finite. Note that the computation is also easy 
and straightforward if we read it backwards - 
thus the evaluation of ((2) 
leads one to the double integral I. 
The second way to evaluate I comes from a change of coordinates: in the 
new coordinates given by u := 9 
and v := 
the domain of integra- 
tion is a square of side length i d ,  which we get from the old domain by 
first rotating it by 45" and then shrinking it by a factor of a. 
Substitution 
o f x = u - v a n d y = u + u y i e l d s  
To transform the integral, we have to replace dx dy by 2 du dv, to corn- 
~, 
~, 
~, 
1 
x 
pensate for the fact that our coordinate transformation reduces areas by a 
, ~ 
~ 
~ 
, 
\ 
1 
constant factor of 2 (which is the Jacobi determinant of the transformation; 
see the box on the next page). The new domain of integration, and the 
function to be integrated, are symmetric with respect to the u-axis, so we 
just need to compute two times (another factor of 2 arises here!) the inte- 
gral over the upper half domain, which we split into two parts in the most 
natural way: 
dx 
1 
x 
= - arctan - + C , this becomes 
a 
These integrals can be simplified and finally evaluated by substituting u = 
sin 0 resp. u = cos 0. But we proceed more directly, by computing that the 
derivative of g(u) := arctan (+) 
is gf (u) = m, 
JT-?L 
while the deriva- 
tive of h(u) := arctan (B) 
= arctan (m) 
is hf(u) = -I----- 
2 v'i=G' 
b 
So we may use J~~ 
fP(z) f (x)dx = [if 
( x ) ~ ] ,  = if (b)2 - if 
and get 

Three times n2 16 
37 
This proof extracted the value of Euler's series from an integral via a rather 
simple coordinate transformation. An ingenious proof of this type - 
with 
an entirely non-trivial coordinate transformation - 
was later discovered by 
Beukers, Calabi and Kolk. The point of departure for that proof is to split 
the sum 
$ into the even terms and the odd terms. Clearly the even 
terms $ + & + & + . . . = zk21 
& sum to 2((2), so the odd terms 
1
1
1
 
-Iz + + + . . . = Ck20 - 
make up three quarters of the total 
sum ((2). Thus Euler's series is equivalent to 
W Proof. As above, we may express this as a double integral, namely 
1
1
 
So we have to compute this integral J .  And for this Beukers, Calabi and 
Kolk proposed the new coordinates 
To compute the double integral, we may ignore the boundary of the domain, 
and consider x, y in the range 0 < x < 1 and 0 < y  < 1. Then u, 
v will lie 
in the triangle u > 0, v > 0, 
u + v < 7r/2. The coordinate transformation 
can be inverted explicitly, which leads one to the substitution 
sin u 
sin v 
x = -  
and 
= cosu. 
cos v 
It is easy to check that these formulas define a bijective coordinate transfor- 
mation between the interior of the unit square S = {(x, y )  : 0 5 x, 
y  < 1 )  
and the interior of the triangle T = {(u. v) : u, 
v > 0, u + v < n/2). 
Now we have to compute the Jacobi determinant of the coordinate transfor- 
mation, and magically it turns out to be 
sin2 u sin2 v 
cos w 
= 1 - x2y2. 
cos2 U 
cos2 u cos2 v 
But this means that the integral that we want to compute is transformed into 
J = 1 J ldudv. 
0 
0 
The Substitution Formula 
To compute a double integral 
s 
we may perform a substitution of 
variables 
x = x(u, v) y = Y(U, 
v), 
if the correspondence of (u, 
v) E T 
to (x, 
y) E S is bijective and contin- 
uously differentiable. Then I equals 
where - 
is the Jacobi determi- 
nant: 
which is just the area $ ($)' = $ of the triangle 2'. 
0 

3 8 
Three times .ir2 16 
Form = l , 2 , 3  this yields 
cot2 5 = ; 
cot2 ; 
+ cot2 
= 2 
cot2 $ + cot2 
+ cot2 
= 5 
Beautiful - 
even more so, as the same method of proof extends to the 
computation of C(2k) in terms of a 2k-dimensional integral, for all k 2 1. 
We refer to the original paper of Beuker, Calabi and Kolk [2], and to 
Chapter 20, where we'll achieve this on a different path, using the Herglotz 
trick and Euler's original approach. 
After these two proofs via coordinate transformation we can't resist the 
temptation to present another, entirely different and completely elementary 
proof for 
$ = $. It appears in a sequence of exercises in the 
problem book by the twin brothers Akiva and Isaak Yaglom, whose Russian 
original edition appeared in 1954. Versions of this beautiful proof were 
rediscovered and presented by F. Holme (1970), I. Papadimitriou (1973), 
and by Ransford (1982) who attributed it to John Scholes. 
Proof. The first step is to establish a remarkable relation between values 
of the (squared) cotangent function. Namely, for all m > 1 one has 
2 
2m(2m-1) 
cot (*) 
+ cot2 (*) 
+ . . . + cot2 (*) 
= 
. (1) 
To establish this. we start with the relation 
cos n x  + i sin nx = (cos x + i sin x)" 
and take its imaginary part, which is 
sin n x  = (7) sin x cosnP1 x - (;) 
sin3 x C O S ~ ~ - ~  
x I . . . 
(2) 
Now we let n = 2m + 1, while for x we will consider the m different 
values x = &, 
for r = 1'2,. . . , m. For each of these values we have 
n x  = r r ,  and thus sinnx = 0, while 0 < x < $ implies that for sinx we 
get m distinct positive values. 
In particular, we can divide (2) by sinn x, which yields 
that is, 
for each of the m distinct values of x. Thus for the polynomial of degree m 
we know m distinct roots 
a, 
= cot2 (&) 
for 
r = 1 , 2 , .  . . , m 
Hence the polynomial coincides with 

Three times 7r2 16 
39 
Comparison of the coefficients of tm-' in ~ ( t )  
now yields that the sum of 
Comparison of coefficients: 
the roots is 
If p ( t )  = c(t - a l )  . . . (t - a,), 
then the coefficient of t m - I  
is 
a l +  . . . +  a, = (';+') 
- 2m(2m-1) 
- 
-c(al + . . . + a,). 
("",'"I 
6 
' 
which proves (1). 
We also need a second identity, of the same type, 
for the cosecant function csc x = &. 
But 
2 
1 - cos2 x + sin2 x 
csc x = - 
- 
= cot2 x + 1, 
sin2 x 
sin2 x 
so we can derive (3) from (1) by adding m to both sides of the equation. 
Now the stage is set, and everything falls into place. We use that in the 
range 0 < y < 5 we have 
0 < sing < y < tany, 
and thus 
0 < cot y < ; < csc y, 
which implies 
Now we take this double inequality, apply it to each of the m distinct values 
of x, and add the results. Using (1) for the left-hand side, and (3) for the 
right-hand side, we obtain 
that is, 
Both the left-hand and the right-hand side converge to 
for m - 
co: 
end of proof. 
0 
O < a < b < c  
implies 
0 < ' < 1 < 1  
c
b
a
 
So how fast does C 5 converge to 7r2/6? For this we have to estimate the 
difference 
7r2 
C O 1  
CO 
1 
- - & =  
6 
C 2. 
n=l 
n=m+l 

40 
Three times r2 16 
This is very easy with the technique of "comparing with an integral" that 
we have reviewed already in the appendix to Chapter 2 (page 10). It yields 
for an upper bound and 
for a lower bound on the "remaining summands" - 
or even 
if you are willing to do a slightly more careful estimate, using that the 
function f (t) = & is convex. 
This means that our series does not converge too well; if we sum the first 
one thousand summands, then we expect an error in the third digit after 
the decimal point, while for the sum of the first one million summands, 
m = 1000000, we expect to get an error in the sixth decimal digit, and 
we do. However, then comes a big surprise: to an accuracy of 45 digits, 
So the sixth digit after the comma is wrong (too small by I), but the next 
six digits are right! And then one digit is wrong (too large by 5), then again 
five are correct. This surprising discovery is quite recent, due to Roy D. 
North from Colorado Springs, 1988. (In 1982, Martin R. Powell, a school 
teacher from Amersham, Bucks, England, failed to notice the full effect due 
to the insufficient computing power available at the time.) It is too strange 
to be purely coincidental . . . A look at the error term, which again to 45 
digits reads 
reveals that clearly there is a pattern. You might try to rewrite this last 
number as 
where the coefficients (1, - 2, i, 
0, - $, 0, &) of 
form the be- 
ginning of the sequence of Bernoulli numbers that we'll meet again in 
Chapter 20. We refer our readers to the article by Borwein, Borwein & 
Dilcher [3] for more such surprising "coincidences" - 
and for proofs. 

Three times n2/6 
4 1 
Appendix: The Riemann zeta function 
The Riemann zeta function ('(s) is defined for real s > 1 by 
Our estimates for Hn (see page 10) imply that the series for C(1) diverges, 
but for any real s > 1 it does converge. The zeta function has a canonical 
continuation to the entire complex plane (with one simple pole at s = I), 
which can be constructed using power series expansions. The resulting 
complex function is of utmost importance for the theory of prime numbers. 
Let us mention three diverse connections: 
(1) The remarkable identity 
is due to Euler. It encodes the basic fact that every natural number has a 
unique (!) decomposition into prime factors; using this, Euler's identity is 
a simple consequence of the geometric series expansion 
(2) The location of the complex zeros of the zeta function is the subject 
of the "Riemann hypothesis": one of the most famous and important unre- 
solved conjectures in all of mathematics. It claims that all the non-trivial 
zeros s E C of the zeta function satisfy Re(s) = i. (The zeta function 
vanishes at all the negative even integers, which are referred to as the 
"trivial zeros.") 
Very recently, Jeff Lagarias showed that, surprisingly, the Riemann hypo- 
thesis is equivalent to the following elementary statement: For all n > 1, 
with equality only for n = 1, where H, is again the n-th harmonic number. 
(3) It has been known for a long time that <(s) is a rational multiple of ns, 
and hence irrational, if s is an even integer s > 2; see Chapter 20. In 
contrast, the irrationality of i ( 3 )  was proved by Roger ApCry only in 1979. 
Despite considerable effort the picture is rather incomplete about [ ( s )  for 
the other odd integers, s = 2 t f l  > 5. Very recently, Keith Ball and Tanguy 
Rivoal proved that infinitely many of the values i(2t+ 1) are irrational. And 
indeed, although it is not known for any single odd value s > 5 that ('(s) 
is irrational, Wadim Zudilin has proved that at least one of the four values 
C(5), <(7), <(9), and ((11) is irrational. We refer to the beautiful survey by 
Fischler [4]. 

42 
Three times n2 16 
References 
[I] K. BALL & T. RIVOAL: Irrationalit6 d'une injnit6 de valeurs de la fonction 
zgta aux entiers impairs, Inventiones math. 146 (2001), 193-207. 
[2] F. BEUKERS, 
J. A. C. KOLK & E. CALABI: Sums of generalized harmonic 
series and volumes, Nieuw Archief voor Wiskunde (4) 11 (1993), 217-224. 
[3] J. M. BORWEIN, P. B. BORWEIN & K. DILCHER: Pi, Euler numbers, and 
asymptotic expansions, Amer. Math. Monthly 96 (1989), 68 1-687. 
[4] S. FISCHLER: Irrationalit6 de valeurs de zgta (d'aprks Ape'ry, Rivoal, . . . ), 
Bourbaki Seminar, No. 9 10, November 2002; to appear in AstCrisque; Preprint 
arXiv:math.NT/0303066,March 2003,45 pages. 
[5] J. C. LAGARIAS: 
An elementary problem equivalent to the Riemann hypo- 
thesis, Amer. Math. Monthly 109 (2002), 534-543. 
[6] W. J. LEVEQUE: Topics in Number Theory, Vol. I, Addison-Wesley, Reading 
MA 1956. 
[7] A. M. YAGLOM & I. M. YAGLOM: Challenging mathematicalproblems with 
elementary solutions, Vol. 11, Holden-Day, Inc., San Francisco, CA 1967. 
[8] W. ZUDILIN: Arithmetic of linear forms involving odd zeta values, Preprint, 
August 2001,42pages; arXiv:math.NT/O206176. 

 
 
 
Geometry 

Hilbert's third problem: 
decomposing polyhedra 
In his legendary address to the International Congress of Mathematicians 
at Paris in 1900 David Hilbert asked - 
as the third of his twenty-three 
problems - 
to specify 
"two tetrahedra of equal bases and equal altitudes which can in 
no way be split into congruent tetrahedra, and which cannot be 
combined with congruent tetrahedra to form two polyhedra which 
themselves could be split up into congruent tetrahedra." 
This problem can be traced back to two letters of Carl Friedrich Gauss 
from 1844 (published in Gauss' collected works in 1900). If tetrahedra of 
equal volume could be split into congruent pieces, then this would give one 
an "elementary" proof of Euclid's theorem XII.5 that pyramids with the 
same base and height have the same volume. It would thus provide an ele- 
mentary definition of the volume for polyhedra (that would not depend on 
analysis, and hence on continuity arguments). A similar statement is true 
in plane geometry: the Bolyai-Gerwien Theorem [I, Sect. 2.71 states that 
planar polygons are both equidecomposable (can be dissected into congru- 
ent triangles) and equicomplementable (can be made congruent by adding 
congruent triangles) if and only if they have the same area. 
Chapter 8 
David Hilbert 
The cross is equicomplementable with a 
square of the same area. 
u 
v 
In fact, they are even equidecomposable. 

46 
Hilbert's third problem: decomposing polyhedra 
Hilbert - 
as we can see from his wording of the problem - 
did expect that 
there is no analogous theorem in dimension 3, and he was right. In fact, the 
problem was completely solved by Hilbert's student Max Dehn in two pa- 
pers: the first one, exhibiting non-equidecomposable tetrahedra of equal 
base and height, appeared already in 1900, the second one, also covering 
equicomplementability, appeared in 1902. However, Dehn's papers are not 
easy to understand, and it takes effort to see whether Dehn did not fall into a 
subtle trap which ensnared others: a very-elegant-but-unfortunately-wrong 
proof was found by Bricard (in 1896!), by Meschkowski (1960), and prob- 
ably by others. Luckily, Dehn's proof was reworked and redone, and after 
combined efforts of V. F. Kagan (190311930), Hugo Hadwiger (1949154) 
and Vladimir G. Boltianskii, we now have a Book Proof - 
as follows. 
(The appendix to this chapter provides some basics about polyhedra.) 
(1) A little linear algebra 
For every finite set of real numbers M  = { m l ,  . . . , m k )  C R, 
we define 
V ( A l )  as the set of all linear combinations of numbers in M  with rational 
coefficients, that is, 
The first (trivial, but important) observation is that V ( M )  is a finite dimen- 
sional vector space over the field Q of rational numbers. In fact, V ( M )  is 
clearly closed under taking sums and under multiplication with rationals, 
and the field axioms for R make V ( M )  into a vector space. The dimension 
of V ( M )  is the size of any minimal generating set. Since M  generates 
V ( M )  by definition, we see that it contains a minimal generating set, and 
hence 
dimq V ( M )  5 k = IMI. 
In the following, we shall need and use Q-linearfunctions 
which we interpret as linear maps of Q-vector spaces. The key property is 
k 
that for every rational linear dependence Ci=, 
qimi = 0 with qi E Q ,  we 
must have c:=, 
qi f (mi) = f (0) = 0. Here is the simple lemma that gets 
things going. 
Lemma. For anyjnite subsets M  C M' of IR, the Q-vector space V ( M )  
is a subspace of the Q-vector space V ( M f ) .  Thus i f f  : V ( M )  --, Q is 
a Q-linear function, then f can be extended to a Q-linear function f' : 
V ( M f )  + Q so that f l ( m )  = f ( m )  for all m  E M. 
Proof. Any Q-linear function V ( M )  -+ Q is determined as soon as its 
values on a Q-basis of V ( M )  are fixed. Since every basis of V ( M )  can be 
extended to a basis of V ( M f ) ,  
the rest follows. 
0 

Hilbert 's third problem: decomposing polyhedra 
47 
(2) Dehn invariants 
For a 3-dimensional polyhedron P ,  let Alp denote the set of all angles 
between adjacent facets (dihedral angles), together with the number T. 
Thus for a cube C we get &Ic = ( 5 .  TI, while for an orthogonal prism Q 
over an equilateral triangle we get AIQ = { ;. $ , T ) . 
Given any finite set A1 i R that contains Alp, and any Q-linear function 
that satisfies f (T) = 0, we define the Dehn invariant of P (with respect 
to f )  to be the real number 
where the sum extends over all edges e of the polyhedron, !(e) denotes the 
length of e, and a(e) is the angle between the two facets that meet in e. 
MQ = { r  r , ~ }  
We will calculate various Dehn invariants later. For now just note that 
3 '  2 
f ($) = if (n) = 0 must hold for any such Q-linear function f ,  and 
thus 
D f ( C )  = 0, 
that is, the Dehn invariant of a cube is zero with respect to any f. 
(3) The Dehn-Hadwiger theorem 
As above we call two polyhedra P, Q equidecomposable if they can be 
decomposed into finite sets of polyhedra PI, . . . , P, and Q1, . . . , Q, such 
that Pi and Qi are congruent for all i (1 < i 5 n). Two polyhedra are 
equicomplementable if there are polyhedra PI;. . . , Pm and Q1,. . . , Q, 
so that the interiors of the Pi are disjoint from each other and from P, and 
similarly for the Qi and Q, such that Pi is-congruent to Qi for all i, and such 
t h a t P : =  P U P I U P ~ U .  .. UP,andQ:= 
Q U Q ~ U Q : , U  
. . .  UQmare 
equidecomposable. A theorem of Gerling from 1844 implies that it does not 
matter whether we admit reflections when considering congruences, or not. 
Clearly equidecomposable polyhedra are equicomplementable, but the con- 
verse is far from clear. The following theorem of Hadwiger (in the version 
of Boltianskii) provides our tool to find - 
as Hilbert proposed - 
tetrahedra 
of equal volume that are not equicomplementable, and thus not equidecom- 
posable. 
Theorem. Let P and Q be polyhedra with dihedral angles a1 , . . . , a, resp. 
J1. . . . . p, at their edges, and let A l  be a finite set of real numbers with 
I f f  : V(h.1) + Q is any Q-linear function with f ( T )  = 0 such that 
then P and Q are not equicomplementable. 

48 
Hilbert's third problem: decomposinn polyhedra 
Proof. The argument comes in two parts. 
(1) If a polyhedron P has a decomposition into finitely many polyhedral 
pieces PI, . . . P,, and if all the dihedral angles of the pieces PI,. . . , P, 
are contained in the set M ,  then for every Q-linear f : V ( M )  + Q, the 
Dehn invariants add up: 
For this, we associate a mass to any part of an edge of a polyhedron: if 
e' C e is a part of an edge e of P, then its mass will be 
its length times the f -value of its dihedral angle. 
Now if P is decomposed into PI, . . . , P,, consider the union of all the 
edges of the pieces Pi. Along the edges e' that are contained in edges of P, 
we see that the dihedral angles of the pieces add up to the dihedral angle 
of P at el, and hence the masses add up. 
At any other edge el' of one of the Pi's which is contained in the interior of 
a face of P or in the interior of P, the angles add up to T or to 27r, so the 
f -values of the angles in the pieces add up to f ( T )  = 0 resp. to f (27r) = 0. 
Thus for the sum of the masses we get the same value that we had attached 
to these edges for P in the first place, namely 0. 
(2) Assuming that P and Q are equicomplementable, we can enlarge M to a 
superset M' that also includes all the dihedral angles appearing in any of the 
pieces involved. M' is finite, since we only consider finite decompositions. 
Then our lemma above allows us to extend f to f' 
: V ( M 1 )  + Q, and 
hence part (1) yields an equation of the type 
where D f f  (P,) = D f f  (Qi) since Pi and Qi are congruent. Hence we 
conclude D f ( P )  = D (Q), a contradiction. 
0 
Example 1. For a regular tetrahedron To with edge lengths e, we calculate 
the dihedral angle from the sketch. The midpoint M of the base triangle 
divides the height AE of the base triangle by 1:2, and since lAEl = IDEl, 
we find cos a = i, and thus 
' J  
c 
Setting hl := {a, T )  we note that the ratio 
a 
1 
- - 
- - arccos & 
is irrational, according to Theorem 3 of Chapter 6 (taking n = 9). Thus 
the Q-vector space V ( M )  is 2-dimensional with basis M ,  and there is a 
Q-linear function f : V ( M )  + Q with 

Hilbert 's third problem: decomposing polyhedra 
49 
For this f we have 
and thus a regular tetrahedron cannot be equidecomposable or equicom- 
plernentable with a cube, since the Dehn invariant of a cube vanishes for 
any f. 
Example 2. Let TI be a tetrahedron spanned by three orthogonal edges 
AB, AC, AD of length u. This tetrahedron has three dihedral angles that 
are right angles, and three more dihedral angles of equal size cp, which we 
calculate from the sketch as 
l AEl - ;&u 
cosp = - 
- 
- 
- 1 
PEl 
+ f i J Z u  
&' 
It follows that 
1 
cp = arccos - 
For h.1 := {$, arccos l: 
T ) ,  the Q-vector space V ( M )  has dimension 2. 
"5 
In fact, ;.r and $ are linearly dependent, so V ( M )  = V ({ arccos -& , T ) )  , 
but there is no rational relation between arccos ' 
and n  - 
equivalently, 
v'3 
arccos -1- is irrational, as we proved in Chapter 6 (take n = 3 in Thm. 3). 
& 
Thus we may construct a Q-linear map f by setting 
f(n):=O and f(arccos'):=l, 
& 
from which we obtain f ( 5 )  = 0 and hence 
This proves that TI is not equidecomposable or equicomplementable with 
a cube C  of the same volume, since Df (C) = 0 holds for any f. 
Example 3. Finally, let T2 be a tetrahedron with three consecutive edges 
AB, BC and CD that are mutually orthogonal (an "orthoscheme") and of 
the same length u. 
We will not calculate the angles in such a tetrahedron (they are 5, ;, 
and a), but rather argue that - 
using the midpoints of edges and faces, 
and the center - 
a cube of edge length u can be decomposed into 6 tetra- 
hedra of this type (3 congruent copies, and 3 mirror images). 
A 
H 
All these congruent copies and mirror images have the same Dehn invari- 
ants, and hence for every suitable functional f we will obtain 
1 
Df (T2) = - Df (C) = 0 
6 
so all Dehn invariants of such a tetrahedron vanish! This solves Hilbert's 
third problem, since we have before constructed a different tetrahedron, T I ,  
with congruent bases and the same height, and with Df ( T I )  # 0. By 
the Dehn-Hadwiger theorem Tl and T2 are not equidecomposable, and not 
even equicomplementable. 

50 
Hilbert's third problem: decomposinn uolyhedra 
Some familiar polytopes: tetrahedron, 
cube and permutahedron 
Appendix: Polytopes and polyhedra 
A convexpolytope in Rd is the convex hull of a finite set S = {sl, 
. . . , s,), 
that is, a set of the form 
Polytopes are certainly familiar objects: prime examples are given by con- 
vex polygons (2-dimensional convex polytopes) and by convex polyhedra 
(3-dimensional convex polytopes). 
There are several types of polyhedra that generalize to higher dimensions 
in a natural way. For example, if the set S is affinely independent of 
cardinality d + 1, then conv(S) is a d-dimensional simplex (or d-.simplex). 
For d = 2 this yields a triangle, for d = 3 we obtain a tetrahedron. Simi- 
larly, squares and cubes are special cases of d-cubes, such as the unit d-cube 
given by C d  = [0, lld C Wd. 
General polytopes are defined as finite unions of convex polytopes. In this 
book non-convex polyhedra will appear in connection with Cauchy's rigid- 
ity theorem in Chapter 12, and non-convex polygons in connection with 
Pick's theorem in Chapter 11, and again when we discuss the art gallery 
theorem in Chapter 3 1. 
Convex polytopes can, equivalently, be defined as the bounded solution sets 
of finite systems of linear inequalities. Thus every convex polytope P 
Wd 
has a representation of the form 
for some matrix A E Rmxd and a vector b E Wm. In other words, P is 
the solution set of a system of m linear inequalities aTx < bi, where a? is 
the i-th row of A. Conversely, every bounded such solution set is a convex 
polytope, and can thus be represented as the convex hull of a finite set of 
points. 
For polygons and polyhedra, we have the familiar concepts of vertices, 
edges, and 2-faces. For higher-dimensional convex polytopes, we can de- 
fine their faces as follows: a face of P is a subset F C P of the form 
P n {x E Wd : aTx = b), where aTx < b is a linear inequality that is 
valid for all points x E P. 
All the faces of a polytope are themselves polytopes. The set V of vertices 
(0-dimensional faces) of a convex polytope is also the inclusion-minimal set 
such that conv(V) = P. Assuming that P C W d  is a d-dimensional convex 
polytope, the facets (the (d-1)-dimensional faces) determine a minimal set 
of hyperplanes and thus of halfspaces that contain P, and whose intersec- 
tion is P. In particular, this implies the following fact that we will need 
later: Let F be a facet of P, denote by HF the hyperplane it determines, 
and by H F ~  and HF the two closed half-spaces bounded by HF. Then one 
of these two halfspaces contains P (and the other one doesn't). 

Hilbert's third problem: decomposing polyhedra 
5 1 
The graph G(P) of the convex polytope P is given by the set V of ver- 
tices, and by the edge set E of I-dimensional faces. If P has dimension 3, 
then this graph is planar, and gives rise to the famous "Euler polyhedron 
formula" (see Chapter 1 1). 
Two polytopes P, PI C IRd are congruent if there is some length-preserving 
affine map that takes P to PI. Such a map may reverse the orientation 
of space, as does the reflection of P in a hyperplane, which takes P to 
a mirror image of P. They are combinatorially equivalent if there is a 
bijection from the faces of P to the faces of P I  that preserves dimension 
and inclusions between the faces. This notion of combinatorial equivalence 
is much weaker than congruence: for example, our figure shows a unit cube 
and a "skew" cube that are combinatorially equivalent (and thus we would 
call any one of them "a cube"), but they are certainly not congruent. 
A polytope (or a more general subset of Ktd) is called centrally symmetric 
if there is some point xo E lRd such that 
x o + x E P  
s o - X E P .  
In this situation we call xo the center of P. 
Combinatorially equivalent polytopes 
References 
[ I ]  V. G. BOLTIANSKII: 
Hilbert's Thirdproblem, V. H .  Winston & Sons (Halsted 
Press, John Wiley & Sons), Washington DC 1978. 
[2] M. DEHN: Ueber raumgleiche Polyeder; Nachrichten von der Konigl. 
Gesellschaft der Wissenschaften, Mathematisch-physikalische Klasse (1900), 
345-354. 
[3] M. DEHN: Ueber den Rauminhalf, Mathematische Annalen 55 (1902), 
465-478. 
[4] C. F. GAUSS: "Congruenz und Symrnetrie": Briefwechsel mit Gerling, 
pp. 240-249 in: Werke, Band VIII, Konigl. Gesellschaft der Wissenschaften 
zu Gottingen; B. G. Teubner, Leipzig 1900. 
[5] D. HILBERT: 
Mathematical Problems, Lecture delivered at the International 
Congress of Mathematicians at Paris in 1900, Bulletin Amer. Math. Soc. 8 
(1902), 437-479. 
[6] G. M. ZIEGLER: 
Lectures on Polytopes, Graduate Texts in Mathematics 152, 
Springer-Verlag, New York 199511998, 

Lines in the plane 
and decompositions of graphs 
Perhaps the best-known problem on configurations of lines was raised by 
Sylvester in 1893 in a column of mathematical problems. 
QUESTION8 FOR SOLUTION. 
11851. (Professor SYLFEBTEH.)-Prove that it is not poaaible to 
amngc any finite number of real point8 EO that a right line. through 
every two of them shall pas8 through 
third, unless they dl ke in the 
same right line. 
Whether Sylvester himself had a proof is in doubt, but a correct proof was 
given by Tibor Gallai [Griinwald] some 40 years later. Therefore the fol- 
lowing theorem is commonly attributed to Sylvester and Gallai. Subsequent 
to Gallai's proof several others appeared, but the following argument due 
to L. M. Kelly may be "simply the best." 
Theorem 1. In any conjguration of n points in the plane, not all on a line, 
there is a line which contains exactly two of the points. 
Proof. Let P be the given set of points and consider the set C of all lines 
which pass through at least two points of P. Among all pairs (P, e) with P 
not on !, choose a pair (Po, lo) such that Po has the smallest distance to lo, 
with Q being the point on to closest to Po (that is, on the line through Po 
vertical to to). 
Claim. This line lo does it! 
If not, then t o  contains at least three points of P, and thus two of them, say 
PI and Pz, lie on the same side of Q. Let us assume that PI lies between 
Q and Pz, where PI possibly coincides with Q. The figure on the right 
shows the configuration. It follows that the distance of PI to the line el 
determined by Po and P2 is smaller than the distance of Po to to, and this 
contradicts our choice for lo and Po. 
0 
In the proof we have used metric axioms (shortest distance) and order 
axioms (PI lies between Q and Pz) of the real plane. Do we really need 
these properties beyond the usual incidence axioms of points and lines? 
Well, some additional condition is required, as the famous Fano plane de- 
picted in the margin demonstrates. Here P = {1,2, . . . ,7) and L consists 
of the 7 three-point lines as indicated in the figure, including the "line" 
{4.5,6). Any two points determine a unique line, so the incidence axioms 
are satisfied, but there is no 2-point line. The Sylvester-Gallai theorem 
therefore shows that the Fano configuration cannot be embedded into the 
real plane such that the seven collinear triples lie on real lines: there must 
always be a "crooked" line. 
Chapter 9 
J. J. Sylvester 

54 
Lines in the plane, and decompositions of graphs 
However, it was shown by Coxeter that the order axioms will suffice for 
a proof of the Sylvester-Gallai theorem. Thus one can devise a proof that 
does not use any metric properties - 
see also the proof that we will give in 
Chapter 1 1, using Euler's formula. 
The Sylvester-Gallai theorem directly implies another famous result on 
points and lines in the plane, due to Paul Erdiis and Nicolaas G. de Bruijn. 
But in this case the resclt holds more generally for arbitrary point-line 
systems, as was observed already by Erdiis and de Bruijn. We will discuss 
the more general result in a moment. 
Theorem 2. Let P be a set of n > 3 points in the plane, not all on a line. 
Then the set C of lines passing through at least two points contains at least 
n lines. 
Proof. For n = 3 there is nothing to show. Now we proceed by induction 
on n. Let [PI = n + 1. By the previous theorem there exists a line lo E C 
containing exactly two points P and Q of P. Consider the set P' = P\{Q) 
and the set L' of lines determined by P'. If the points of P' do not all lie 
on a single line, then by induction IL'J 2 n and hence ICI 2 n + 1 because 
of the additional line to in C. If, on the other hand, the points in P' are all 
on a single line, then we have the "pencil" which results in precisely n + 1 
lines. 
0 
Now, as promised, here is the general result, which applies to much more 
general "incidence geometries." 
Theorem 3. Let X be a set of n 2 3 elements, and let A1,. . . ,A, be 
proper subsets of X ,  such that every pair of elements of X is contained in 
precisely one set Ai. Then m > n holds. 
Proof. The following proof, variously attributed to Motzkin or Conway, 
is almost one-line and truly inspired. For x E X let r, be the number of 
sets Ai containing x. (Note that 2 5 r, < m by the assumptions.) Now if 
x @ Ai, then r, 2 lAi 1 because the lAi 1 sets containing x and an element 
of A, must be distinct. Suppose m < n, then mlAil < nr, and thus 
m(n - IAil) > n(m - r,) for x $ Ai, and we find 
which is absurd. 
There is another very short proof for this theorem that uses linear algebra. 
Let B be the incidence matrix of ( X ;  A1,. . . , A,), that is, the rows in B 
are indexed by the elements of X, the columns by Al, . . . , A,, 
where 
Consider the product BBT. For x # x' we have (BBT),,, = 1, since x 

Lines in the plane, and decompositions of graphs 
55 
and x' are contained in precisely one set Ai, hence 
where r, is defined as above. Since the first matrix is positive definite (it has 
only positive eigenvalues) and the second matrix is positive semi-definite 
(it has the eigenvalues n and O), we deduce that BBT is positive definite 
and thus, in particular, invertible, implying rank(BBT) = n. It follows 
that the rank of the ( n  x m)-matrix B is at least n, and we conclude that 
indeed n < m, since the rank cannot exceed the number of columns. 
Let us go a little beyond and turn to graph theory. (We refer to the review of 
basic graph concepts in the appendix to this chapter.) A moment's thought 
shows that the following statement is really the same as Theorem 3: 
I f  we decompose a complete graph K, into m cliques different 
from K,, such that evely edge is in a unique clique, then m > n. 
Indeed, let X correspond to the vertex set of K, and the sets Ai to the 
vertex sets of the cliques, then the statements are identical. 
Our next task is to decompose K, into complete bipartite graphs such that 
again every edge is in exactly one of these graphs. There is an easy way to 
do this. Number the vertices {1,2, . . . , n). First take the complete bipartite 
graph joining 1 to all other vertices. Thus we obtain the graph K1,,-l 
which is called a star. Next join 2 to 3, . . . , n, resulting in a star Kl,,-2. 
Going on like this, we decompose K, into stars K1 ,,-I, 
Kl,,-2, . . . , K1, 1. 
This decomposition uses n - 1 complete bipartite graphs. Can we do better, 
that is, use fewer graphs? No, as the following result of Ron Graham and 
Henry 0. Pollak says: 
Theorem 4. 
I f  K, is decomposed into complete bipartite subgraphs 
H I ,  . . . , H,, 
then m > n - 1. 
The interesting thing is that, in contrast to the ErdBs-de Bruijn theorem, no 
combinatorial proof for this result is known! All of them use linear algebra 
in one way or another. Of the various more or less equivalent ideas let us 
look at the proof due to Tverberg, which may be the most transparent. 
Proof. Let the vertex set of K, be (1,. . . , n), and let L j ,  R j  be the 
defining vertex sets of the complete bipartite graph Hj, j = 1, . . . , m. 
To every vertex i we associate a variable xi. Since HI, . . . , H, decom- 
pose K,, we find 
A decomposition of Kg into 4 complete 
bipartite subgraphs 
Now suppose the theorem is false, m < n - 1. Then the system of linear 

56 
Lines in the plane, and decompositions of graphs 
A graph G with 7 vertices and 11 edges. 
It has one loop, one double edge and one 
triple edge. 
The complete graphs K, on n vertices 
and (;) 
edges 
The complete bipartite graphs K,,,, 
with m + n vertices and mn edges 
equations 
has fewer equations than variables, hence there exists a non-trivial solution 
cl.. . . ,cn. From(1) weinfer 
But this implies 
a contradiction, and the proof is complete. 
0 
Appendix: Basic graph concepts 
Graphs are among the most basic of all mathematical structures. Corre- 
spondingly, they have many different versions, representations, and incar- 
nations. Abstractly, a graph is a pair G = (V, E), where V is the set of 
vertices, E is the set of edges, and each edge e E E "connects" two ver- 
tices v, w E V. We consider only finite graphs, where V and E are finite. 
Usually, we deal with simple graphs: Then we do not admit loops, i. e., 
edges for which both ends coincide, and no multiple edges that have the 
same set of endvertices. Vertices of a graph are called adjacent or neighbors 
if they are the endvertices of an edge. A vertex and an edge are called 
incident if the edge has the vertex as an endvertex. 
Here is a little picture gallery of important (simple) graphs: 

Lines in the plane, and decompositions o f  graphs 
5 7 
u' 
The paths P, with n vertices 
Two graphs G = (V, E) and G' = (V'. E') are considered isomorphic if 
there are bijections V + V' and E -+ E' that preserve the incidences be- 
tween edges and their endvertices. (It is a major unsolved problem whether 
there is an efficient test to decide whether two given graphs are isomorphic.) 
This notion of isomorphism allows us to talk about the complete graph Kg 
on 5 vertices, etc. 
v 
is a subgraph of 
G' = (V', E') is a subgraph of G = (V, E )  if V' c \: E' c E, and every 
edge e E E' has the same endvertices in G' as in G. G' is an induced 
subgraph if, additionally, all edges of G that connect vertices of G' are also 
edges of GI. 
Many notions about graphs are quite intuitive: for example, a graph G 
is connected if every two distinct vertices are connected by a path in G, 
or equivalently, if G cannot be split into two nonempty subgraphs whose 
vertex sets are disjoint. 
We end this survey of basic graph concepts with a few more pieces of ter- 
minology: A clique in G is a complete subgraph. An independent set in G 
is an induced subgraph without edges, that is, a subset of the vertex set such 
that no two vertices are connected by an edge of G. A graph is a forest if it 
does not contain any cycles. A tree is a connected forest. Finally, a graph 
G = (V, E )  is bipartite if it is isomorphic to a subgraph of a complete bi- 
partite graph, that is, if its vertex set can be written as a union V = Vl U V2 
of two independent sets. 
References 
1 I] N. G. DE BRUIJN 
& P. ERDBS: On a combinatorial problem, Proc. Kon. Ned. 
Akad. Wetensch. 51 (1 948), 1277- 1279. 
121 H. S. M. COXETER: 
Aproblem of collinearpoints, Amer. Math. Monthly 55 
(1948), 26-28 (contains Kelly's proof). 
131 P. E R D ~ S :  
Problem 4065 - 
Three point collineariry, Amer. Math. Monthly 51 
(1944), 169- 17 1 (contains Gallai's proof). 
[4] R. L. GRAHAM 
& H. 0. POLLAK: 
On the addressing problem for loop switch- 
ing, Bell System Tech. J. 50 (197 l), 2495-25 19. 
1.51 J. J. SYLVESTER: 
Mathematical Question 11851, The Educational Times 46 
(1893), 156. 
161 H. TvERBERG: On the decomposition of K, into complete bipartite graphs, 
J. Graph Theory 6 (1982), 493-494. 

The slope problem 
Chapter 10 
Try for yourself - 
before you read much further - 
to construct config- 
urations of points in the plane that determine "relatively few" slopes. For 
this we assume, of course, that the n 2 3 points do not all lie on one line. 
Recall from Chapter 9 on "Lines in the plane" the theorem of Erdiis and de 
Bruijn: the n  points will determine at least n  different lines. But of course 
many of these lines may be parallel, and thus determine the same slope. 
n  = 3 
n  = 4 
n=5 
n=6 
n=7 
... 
3 slopes 
4 slopes 
4 slopes 
6 slopes 
6 slopes . . . 
n = 3  
n = 4  
n  = 5 
n=6 
n = 7  
. . . 
A little experimentation for small n will 
3 slopes 
4 slopes 
4 slopes 
6 slopes 
6 slopes 
. . . 
probably lead you to a sequence such as 
the two depicted here. 
After some attempts at finding configurations with fewer slopes you might 
conjecture - 
as Scott did in 1970 - 
the following theorem. 
Theorem. Ifn 2 3  points in the plane do not lie on one single line, 
then they determine at least n - 1 dzrerent slopes, where equality is 
possible only ifn is odd and n  2 5. 
Our examples above - 
the drawings represent the first few configurations 
in two infinite sequences of examples - 
show that the theorem as stated is 
best possible: for any odd n > 5 there is a configuration with n points that 
determines exactly n  - 1 different slopes, and for any other n  2 3 we have 
a configuration with exactly n slopes. 

60 
The sloue uroblem 
Three pretty sporadic examples from the 
Jamison-Hill catalogue 
However, the configurations that we have drawn above are by far not the 
only ones. For example, Jamison and Hill described four infinite families 
of configurations, each of them consisting of configurations with an odd 
number n of points that determine only n - 1 slopes ("slope-critical con- 
figurations"). Furthermore, they listed 102 "sporadic" examples that do not 
seem to fit into an infinite family, most of them found by extensive com- 
puter searches. 
Conventional wisdom might say that extremal problems tend to be very 
difficult to solve exactly if the extreme configurations are so diverse and 
irregular. Indeed, there is a lot that can be said about the structure of slope- 
critical configurations (see [2]), but a classification seems completely out 
of reach. However, the theorem above has a simple proof, which has two 
main ingredients: a reduction to an efficient combinatorial model due to 
Eli Goodman and Ricky Pollack, and a beautiful argument in this model by 
which Peter Ungar completed the proof in 1982. 
Proof. (1) First we notice that it suffices to show that every "even" set 
of n = 2m points in the plane ( m  > 2) determines at least n slopes. This 
is so since the case n = 3 is trivial, and for any set of n = 2m + 1 > 5 
points (not all on a line) we can find a subset of n - 1 = 2m points, not all 
on a line, which already determines n - 1 slopes. 
Thus for the following we consider a configuration of n = 2m points in the 
plane that determines t > 2 different slopes. 
This configuration of n = 6 points 
(2) The combinatorial model is obtained by constructing a periodic se- 
determines t = 6 different slopes. 
quence of permutations. For this we start with some direction in the plane 
that is not one of the configuration's slopes, and we number the points 
1, . . . , n in the order in which they appear in the 1-dimensional projection 
1 
3
4
5
 
6 
in this direction. Thus the permutation no = 123 ... n represents the order 
e
e
e
e
 
of the points for our starting direction. 
2 
Next let the direction perform a counterclockwise motion, and watch how 
- 
the projection and its permutation change. Changes in the order of the 
1
1
1
1
 
I 
projected points appear exactly when the direction passes over one of the 
$ $ $ U  
$ 
configuration's slopes. 
,
,
.
,
.
 
But the changes are far from random or arbitrary: By performing a 180" 
rotation of the direction, we obtain a sequence of permutations 
1
2
3
4
5
 
6 
Here a vertical starting direction yields 
T O  -+ 7rl 4 7r2 + . . . + n t - 1  + 7rt 
7ro = 123456. 
which has the following special properties: 
0 The sequence starts with TO = 123 ... n and ends with 7rt = n...321. 
0 The length t of the sequence is the number of slopes of the point con- 
figuration. 
0 In the course of the sequence, every pair i < j is switched exactly 
once. This means that on the way from no = 123 ... n to 7rt = n...321, 
only increasing substrings are reversed. 

The slope uroblem 
61 
0 Every move consists in the reversal of one or more disjoint increasing 
substrings (corresponding to the one or more lines that have the direc- 
tion which we pass at this point). 
Getting the sequence 
for our small example 
of permutations 
By continuing the circular motion around the configuration, one can view 
the sequence as a part of a two-way infinite, periodic sequence of permuta- 
tions 
where ~ i + t  is the reverse of ~i for all i, and thus ri+zt = ~i for all i E Z. 
We will show that every sequence with the above properties (and t > 2) 
must have length t > n. 
(3) The proof's key is to divide each permutation into a "left half" and a 
"right half" of equal size m = ;, 
and to count the letters that cross the 
imaginary barrier between the left half and the right half. 
Call 7ri + ~i+l a crossing move if one of the substrings it reverses does 
involve letters from both sides of the bamer. The crossing move has order 
265314 
d if it moves 2d letters across the bamer, that is, if the crossing string has !&/
\n 
exactly d letters on one side and at least d letters on the other side. Thus in 
2 
213564 
our example 
- 
.irz = 213:564 + 
265:314 = ~3 
A crossing move 
is a crossing move of order d = 2 (it moves 1 , 3 , 5 , 6  across the bamer, 
which we mark by ":"), 

62 
The slope problem 
A touching move 
An ordinary move 
is crossing of order d = 1, while for example 
is not a crossing move. 
In the course of the sequence TO + rl + . . . + rt, each of the letters 
1,2, . . . , n has to cross the barrier at least once. This implies that, if the 
orders of the c crossing moves are d l ,  d2, . . . , d,, then we have 
C 
2di = #{letters that cross the barrier} 2 n. 
i=l 
This also implies that we have at least two crossing moves, since a crossing 
move with 2di = n occurs only if all the points are on one line, i. e. for 
t = 1. Geometrically, a crossing move corresponds to the direction of a 
line of the configuration that has less than m points on each side. 
(4) A touching move is a move that reverses some string that is adjacent to 
the central bamer, but does not cross it. For example, 
is a touching move. Geometrically, a touching move corresponds to the 
slope of a line of the configuration that has exactly m points on one side, 
and hence at most m - 2 points on the other side. 
Moves that are neither touching nor crossing will be called ordinary moves. 
For this 
= 213:5% + 
213:5W = ~2 
is an example. So every move is either crossing, or touching, or ordinary, 
and we can use the letters T, C, 0 to denote the types of moves. C ( d )  will 
denote a crossing move of order d. Thus for our small example we get 
or even shorter we can record this sequence as T, 0, C ( 2 ) ,  0, T, C ( 1 ) .  
(5) To complete the proof, we need the following two facts: 
Between any two crossing moves, there is at least one touching 
move. 
Between any crossing move of order d and the next touching move, 
there are at least d - 1 ordinary moves. 
In fact, after a crossing move of order d the barrier is contained in a sym- 
metric decreasing substring of length 2d, with d letters on each side of the 
barrier. For the next crossing move the central barrier must be brought into 
an increasing substring of length at least 2. But only touching moves affect 
whether the barrier is in an increasing substring. This yields the first fact. 

The slope problem 
63 
For the second fact, note that with each ordinary move (reversing some 
increasing substrings) the decreasing 2d-string can get shortened by only 
one letter on each side. And, as long as the decreasing string has at least 4 
letters, a touching move is impossible. This yields the second fact. 
If we construct the sequence of permutations starting with the same initial 
projection but using a clockwise rotation, then we obtain the reversed se- 
quence of permutations. Thus the sequence that we do have recorded must 
also satisfy the opposite of our second fact, namely 
Between a touching move and the next crossing move, of order d, 
there are at least d - 1 ordinary moves. 
(6) The T-0-C-pattern of the infinite sequence of permutations, as derived 
in (2), is obtained by repeating over and over again the T-0-C-pattern of 
length t of the sequence T O  - 
. . . - 
~
t
.
 
Thus with the facts of (5) we 
see that in the infinite sequence of moves, each crossing move of order d is 
embedded into a T-0-C-pattern of the type 
of length 1 + (d - 1) + 1 + (d - 1) = 2d. 
In the infinite sequence, we may consider a finite segment of length t that 
starts with a touching move. This segment consists of substrings of the 
type (*), plus possibly extra inserted T's. This implies that its length t 
satisfies 
C 
which completes the proof. 
References 
[I] J. E. GOODMAN 
& R. POLLACK: 
A combinatorial perspective on some 
problems in geometry, Congressus Numerantium 32 ( 1  98 I), 383-394. 
[2] R. E. JAMISON & D. HILL: A catalogue of slope-critical con$gurations, 
Congressus Numerantium 40 (1983), 101-1 25. 
[3] P. R. SCOTT: On the sets of directions determined by n points, Amer. 
Math. Monthly 77 (1970), 502-505. 
[4] P. UNGAR: 2N noncollinear points determine at least 2N directions, J. 
Combinatorial Theory, Ser. A 33 (1982), 343-347. 

Three applications 
of Euler's formula 
Chapter 11 
.4 graph isplonar if it can be drawn in the plane W2 without crossing edges 
(or. equivalently, on the 2-dimensional sphere S2). We talk of aplane graph 
if such a drawing is already given and fixed. Any such drawing decomposes 
thc plane or spherc into a fnite number of connected regions, including 
the outer (unbounded) region, which are referred to as faces. Euler's for- 
mula exhibits a beautiful relation between the number of vertices, edges 
and faces that is valid for any plane graph. Euler mentioned this result for 
1 
the first time in a letter to his friend Goldbach in 1750, but he did not have 
a complete proof at the time. Among the many proofs of Euler's formula, 
we present a pretty and "self-dual" one that gets by without induction. It 
can be traced back to von Staudt's book "Geometrie der Lage" from 1847. 
7 
Euler's formula. If G is a connected plane graph with n vertices, 
e edges and f faces, then 
n - e +  f = 2. 
Proof. Let T c E be the edge set of a spanning tree for G, that is, of a 
minimal subgraph that connects all the vertices of G. This graph does not 
Leonhard Euler 
contain a cycle because of the minimality assumption. 
We now need the dual graph G* of G: to construct it, put a vertex into the 
interior of each face of G, and connect two such vertices of G* by edges that 
correspond to common boundary edges between the corresponding faces. If 
there are several common boundary edges, then we draw several connecting 
edges in the dual graph. (Thus G* may have multiple edges even if the 
original graph G is simple.) 
Consider the collection T* C E* of edges in the dual graph that corre- 
A plane graph G: n = 6, e = 10, f = 6 
sponds to edges in E\T. 
The edges in T* connect all the faces, since T 
does not have a cycle; but also T* does not contain a cycle, since otherwise 
it would separate some vertices of G inside the cycle from vertices outside 
*........... 
(and this cannot be, since T is a spanning subgraph, and the edges of T and 
a. 
of T* do not intersect). Thus T* is a spanning tree for G*. 
*.***. 
For every tree the number of vertices is one larger than the number of 
edges. To see this, choose one vertex as the root, and direct all edges 
"away from the root": this yields a bijection between the non-root ver- 
tices and the edges, by matching each edge with the vertex it points at. 
Applied to the tree T this yields n = eT + I, while for the tree T* it yields 
f = e p  + 1. Adding both equations we get n,+ f = (eT+l)+(eT*+l) = 
e + 2. 
Dual spanning trees in G and in G* 

66 
Three applications of Euler's formula 
The five platonic solids 
Here the degree is written next to each 
vertex. Counting the vertices of given 
degree yields n2 = 3, n s  = 0, n4 = 1, 
n s  = 2. 
The number of sides is written into each 
region. Counting the faces with a given 
number of sides yields fl = 1, f2 = 3, 
f4 = 1, f9 = 1, and f, = 0 otherwise. 
Euler's formula thus produces a strong numerical conclusion from a geo- 
metric-topological situation: the numbers of vertices, edges, and faces of a 
finite graph G satisfy n - e + f = 2 whenever the graph is or can be drawn 
in the plane or on a sphere. 
Many well-known and classical consequences can be derived from Euler's 
formula. Among them are the classification of the regular convex polyhedra 
(the platonic solids), thz fact that Kg and K3,3 are not planar (see below), 
and the five-color theorem that every planar map can be colored with at 
most five colors such that no two adjacent countries have the same color. 
But for this we have a much better proof, which does not even need Euler's 
formula - 
see Chapter 30. 
This chapter collects three other beautiful proofs that have Euler's formula 
at their core. The first two - 
a proof of the Sylvester-Gallai theorem, and 
a theorem on two-colored point configurations - 
use Euler's formula in 
clever combination with other arithmetic relationships between basic graph 
parameters. Let us first look at these parameters. 
The degree of a vertex is the number of edges that end in the vertex, where 
loops count double. Let ni denote the number of vertices of degree i in G. 
Counting the vertices according to their degrees, we obtain 
On the other hand, every edge has two ends, so it contributes 2 to the sum 
of all degrees, and we obtain 
You may interpret this identity as counting in two ways the ends of the 
edges, that is, the edge-vertex incidences. The average degree d of the 
vertices is therefore 
Next we count the faces of a plane graph according to their number of sides: 
a k-face is a face that is bounded by k edges (where an edge that on both 
sides borders the same region has to be counted twice!). Let fk be the 
number of Ic-faces. Counting all faces we find 
Counting the edges according to the faces of which they are sides, we get 
As before, we can interpret this as double-counting of edge-face incidences. 
Note that the average number of sides of faces is given by 

Three a~nlications o f  Euler's formula 
67 
Let us deduce from this - 
together with Euler's formula- 
quickly that the 
complete graph Kg and the complete bipartite graph K3,3 are not planar. 
5 
For a hypothetical plane drawing of K5 we calculate n = 5, e = (2) = 10, 
- 
thus f = e + 2 - n = 7 and f = 
= 
< 3. But if the average number 
of sides is smaller than 3, then the embedding would have a face with at 
most two sides, which cannot be. 
Similarly for K3.3 we get n = 6, e = 9, and f = e + 2 - n = 5, and thus 
- 
f = 2 = 
< 4, which cannot be since 
is simple and bipartite, so 
drawn with one crossing 
f all its cycles have length at least 4. 
It is no coincidence, of course, that the equations (3) and (4) for the f,'s look 
so similar to the equations ( I )  and (2) for the n,'s. They are transformed 
into each other by the dual graph construction G 4 G* explained above. 
From the double counting identities, we get the following important "local" 
consequences of Euler's formula. 
Proposition. Let G be any simple plane graph with n > 2 vertices. Then 
KW drawn with one crossing 
(A) G has a vertex of degree at most 5. 
(B) G has at most 3n - 6 edges. 
(C) Ifthe edges of G are mo-colored, then there is a vertex of G with at 
most two color-changes in the cyclic order of the edges around the 
vertex. 
1 Proof. For each of the three statements, we may assume that G is con- 
nected. 
(A) Every face has at least 3 sides (since G is simple), so (3) and (4) yield 
and thus 2e - 3 f > 0. 
Now if each vertex has degree at least 6, then (1) and (2) imply 
and thus 2e - 6 n  > 0, 
Taking both inequalities together, we get 
and thus e > n + f ,  contradicting Euler's formula. 
(B) As in the first step of part (A), we obtain 2e - 3 f > 0, and thus 
from Euler's formula. 

68 
Three applications of Euler's formula 
(C) Let c be the number of corners where color changes occur. Suppose the 
statement is false, then we have c 2 4 n  corners with color changes, since 
at every vertex there is an even number of changes. Now every face with 
2k or 2lc + 1 sides has at most 2k such corners, so we conclude that 
b 
Arrows point to the corners with color 
4n < c < 2 f 3 + 4 f 4 + 4 f 5 + 6 f  6 +6f7 + S f 8  +. . . 
changes. 
2 f 3 + 4 f 4 + 6 f 5 + 8 f 6 + 1 0 f 7 +  . . . 
- 
- 2(3f3 + 4f4 + 5 f5 + 6 f 6 + 7f7 +. . .) 
-4(f3 + f4 + f5 + f6 + f7 + . . .) 
= 4 e - 4 f  
using again (3) and (4). So we have e > n + f ,  again contradicting ~
~
formula. 
0 
1. The Sylvester-Gallai theorem, revisited 
It was first noted by Norman Steenrod, it seems, that part (A) of the propo- 
sition yields a strikingly simple proof of the Sylvester-Gallai theorem (see 
Chapter 9). 
The Sylvester-Gallai theorem. Given any set of n > 3  points in 
the plane, not all on one line, there is always a line that contains 
exactly two of the points. 
Proof. (Sylvester-Gallai via Euler) 
If we embed the plane R2 in R3 near the unit sphere S2 as indicated in 
our figure, then every point in R2 corresponds to a pair of antipodal points 
on S2, and the lines in IR2 correspond to great circles on S2. Thus the 
Sylvester-Gallai theorem amounts to the following: 
Given any set of n > 3  pairs of antipodalpoints on the sphere, not 
all on one great circle, there is always a great circle that contains 
exactly two of the antipodal pairs. 
Now we dualize, replacing each pair of antipodal points by the correspond- 
ing great circle on the sphere. That is, instead of points f 
v E S2 we 
consider the orthogonal circles given by C, := {x E S2 : (x, 
v) = 0). 
(This C, is the equator if we consider v as the north pole of the sphere.) 
Then the Sylvester-Gallai problem asks us to prove: 
Given any collection of n > 3  great circles on S2, not all of them 
passing through one point, there is always a point that is on exactly 
two of the great circles. 
But the arrangement of great circles yields a simple plane graph on S2, 
whose vertices are the intersection points of two of the great circles, which 
divide the great circles into edges. All the vertex degrees are even, and they 
are at least 4 - 
by construction. Thus part (A) of the proposition yields the 
existence of a vertex of degree 4. That's it! 
0 

Three applications of Euler's formula 
69 
2. Monochromatic lines 
The following proof of a "colorful" relative of the Sylvester-Gallai theorem 
is due to Don Chakerian. 
Theorem. Given any jinite conjiguration of "black" and "white " points 
in the plane, not all on one line, there is always a "monochromatic" line: 
a line that contains at least two points of one color and none of the othel: 
Proof. As for the Sylvester-Gallai problem, we transfer the problem to 
the unit sphere and dualize it there. So we must prove: 
Gi1,en any3nite collection of "black" arzd "white" great circles on 
the unit sphere, not all passing through one point, there is always 
an intersection point that lies either only on white great circles, or 
onlv on black great circles. 
Now the (positive) answer is clear from part (C) of the proposition, since 
in every vertex where great circles of different colors intersect, we always 
have at least 4 corners with sign changes. 
0 
3. Pick's theorem 
Pick's theorem from 1899 is a beautiful and surprising result in itself, but 
it is also a "classical" consequence of Euler's formula. For the following, 
call a convex polygon P C R2 elementary if its vertices are integral (that 
is, they lie in the lattice Z2), but if it does not contain any further lattice 
points. 
Lemma. Every elementary triangle A = conv{po, p, , p,) C R2 has area 
A(A) = i. 
P I +  P, -Po 
Proof. Both the parallelogram P with corners po, p, , p,, pl + p, - po 
e
o
e
 
and the lattice Z2 are symmetric with respect to the map 
P2 
a :  x - 
p 1 + p 2 - x ,  
which is the reflection with respect to the center of the segment from p, /: 
PI 
: 
to p,. Thus the parallelogram P = A U a(A) is elementary as well, and 
e
.
.
 
its integral translates tile the plane. Hence {p, - po,p2 - po) is a basis 
po 
of the lattice z2, it has determinant *l, P is a parallelogram of area 1, and 
A has area ,!j. (For an explanation of these terms see the box on the next 
page.) 
n e x e e
Theorem. The area of any (not necessarily convex) polygon Q C R2 with 
integral vertices is given by 
. . 
1 
A(&) = ntnt + - n b d  - 1, 
2 
where nint and n b d  are the numbers of integral points in the interior 
respectively on the boundary of Q. 
n,,t = 11, n b d  = 8, so A = 14 

70 
Three applications of Euler's formula 
Lattice bases 
A basis of Z2 is a pair of linearly independent vectors el, e2 such that 
I 
Z2 = (A lei + h e 2  : XI, X2 E Z). 
Let el = (;f) and e2 = (3, then the area of the parallelogram 
spanned by el and e2 is given by A(el, e2) = I det(el, ez)l = 
I det (::)I. 
If f 
= (:) 
and f 2  = (L) is another basis, then 
there exists an invertible Z-matrix Q with (ST t) = (: i) Q. Since 
QQP1 = (i y ) ,  and the determinants are integers, it follows that 
IdetQI = 1, and hence Idet(fl, f2)l = Idet(el,ez)l. Therefore 
all basis parallelograms have the same area 1, since A((:), (y)) = 1. 
Proof. Every such polygon can be triangulated using all the nint lattice 
points in the interior, and all the nbd lattice points on the boundary of Q. 
(This is not quite obvious, in particular if Q is not required to be convex, but 
the argument given in Chapter 3 1 on the art gallery problem proves this.) 
Now we interpret the triangulation as a plane graph, which subdivides the 
plane into one unbounded face plus f - 1 triangles of area i, so 
1 
4 Q )  = i(f - 1). 
Every triangle has three sides, where each of the etnt interior edges bounds 
two triangles, while the ebd boundary edges appear in one single triangle 
each. So 3(f - 1) = 2eint +ebd and thus f = 2(e - f)-ebd+3. Also, there 
is the same number of boundary edges and vertices, ebd = nbd. These two 
facts together with Euler's formula yield 
References 
[I] G. D. CHAKERIAN: 
Sylvester's problem on collinear points and a relative, 
Amer. Math. Monthly 77 (1970), 164-167. 
[2] G. PICK: 
Geometrisches zur Zahlenlehre, Sitzungsberichte Lotos (Prag), 
Natur-med. Verein fur Bohmen 19 (1899), 3 11-31!). 
[3] K. G. C. VON STAUDT: Geometrie der Luge, Verlag der Fr. Korn'schen 
Buchhandlung, Nurnberg 1847. 
[4] N. E. STEENROD: 
Solution 4065/Editorial Note, Amer. Math. Monthly 51 
(1944), 170-171. 

Cauchy's rigidity theorem 
A famous result that depends on Euler's formula (specifically, on part (C) 
of the proposition in the previous chapter) is Cauchy's rigidity theorem for 
3-dimensional polyhedra. 
For the notions of congruence and of combinatorial equivalence that are 
used in the following we refer to the appendix on polytopes and polyhedra 
in the chapter on Hilbert's third problem, see page 50. 
Theorem. If two 3-dimensional convex polyhedra P and P' are 
combinatorially equivalent with corresponding facets being congru- 
ent, then also the angles between corresponding pairs of adjacent 
facets are equal (and thus P is congruent to P'). 
The illustration in the margin shows two 3-dimensional polyhedra that are 
combinatorially equivalent, such that the corresponding faces are congru- 
ent. But they are not congruent, and only one of them is convex. Thus the 
assumption of convexity is essential for Cauchy's theorem! 
Proof. The following is essentially Cauchy's original proof. Assume 
that two convex polyhedra P and P' with congruent faces are given. We 
color the edges of P as follows: an edge is black (or "positive") if the 
corresponding interior angle between the two adjacent facets is larger in P' 
than in P; it is white (or "negative") if the corresponding angle is smaller 
in P' than in P. 
The black and the white edges of P together form a 2-colored plane graph 
on the surface of P, which by radial projection, assuming that the origin 
is in the interior of P, we may transfer to the surface of the unit sphere. 
If P and PI have unequal corresponding facet-angles, then the graph is 
nonempty. With part (C) of the proposition in the previous chapter we find 
that there is a vertex p that is adjacent to at least one black or white edge, 
such that there are at most two changes between black and white edges (in 
cyclic order). 
Now we intersect P with a small sphere S, (of radius E )  centered at the 
vertex p, and we intersect P' with a sphere S: of the same radius E centered 
at the corresponding vertex p'. In S, and SL we find convex spherical 
polygons Q and Q' such that corresponding arcs have the same lengths, 
because of the congruence of the facets of P and P', and since we have 
chosen the same radius E. 
Chapter 12 
Augustin Cauchy 

72 
Cauchy's rigidity theorem 
Now we mark by + the angles of Q for which the corresponding angle 
in Q' is larger, and by - the angles whose corresponding angle of Q' is 
smaller. That is, when moving from Q to Q' the + angles are "opened," 
-.--- 
the - angles are "closed," while all side lengths and the unmarked angles 
..--- 
stay constant. 
From our choice of p we know that some + or - sign occurs, and that in 
cyclic order there are at most two +I- changes. If only one type of signs 
occurs, then the lemma below directly gives a contradiction, saying that one 
edge must change its length. If both types of signs occur, then (since there 
are only two sign changes) there is a "separation line" that connects the 
midpoints of two edges and separates all the + signs from all the - signs. 
Again we get a contradiction from the lemma below, since the separation 
line cannot be both longer and shorter in Q' than in Q. 
0 
Cauchy's arm lemma. 
If Q and Q' are convex (planar or spherical) n-gons, labeled as in 
the$gure, 
- -  
such that qiqi+l = q,lql+l holds for the lengths o f  corresponding edges for 
1 < i < n - 1, and a, < a: holds,for the sizes of corresponding angles for 
2 5 i 5 n - 1, then the "missing" edge length satisjes 
with equality ifand only f a i  = a: holds for all i. 
It is interesting that Cauchy's original proof of the lemma was false: a con- 
tinuous motion that opens angles and keeps side-lengths fixed may destroy 
convexity - 
see the figure! On the other hand, both the lemma and its 
proof given here, from a letter by I. J. Schoenberg to S. K. Zaremba, are 
valid both for planar and for spherical polygons. 
Proof. We use induction on n. The case n = 3 is easy: If in a triangle 
we increase the angle y between two sides of fixed lengths a and b, then the 
length c of the opposite side also increases. Analytically, this follows from 
the cosine theorem 
in the planar case, and from the analogous result 
cos c = cos a cos b + sin a sin b cos y 
in spherical trigonometry. Here the lengths a, b, c are measured on the 
surface of a sphere of radius 1, and thus have values in the interval [O,T]. 

Cauchv's ripidin theorem 
7 3 
Now let n > 4. If for any i E ( 2 , .  . . , n - 1) we have ai = a:, then the 
corresponding vertex can be cut off by introducing the diagonal from qi_, 
to q,+, resp. from ql-, to qi+l, with qi-lqi+l = ~ i - ~ q : + ~ ,  
SO we are done 
by induction. Thus we may assume ui < a: for 2 < i < n - 1. 
Now we produce a new polygon Q* from Q by replacing a n  
1 by the 
largest possible angle a;-, 5 a;_, that keeps Q* convex. For this we 
replace q,, by qz, keeping all the other q,, edge lengths, and angles from Q. 
&,-' 
If indeed we can choose 
= oLpl keeping Q* convex, then we get 
d 
- - - 
Yl 
Pn 
qlql, < qlq; < qiqk, using the case n = 3 for the first step and induction 
Q*: ,/--?-y an- 1 
as above for the second. 
Otherwise after a nontrivial move that yields 
we "get stuck" in a situation where q2, ql and q: are collinear, with 
Now we compare this Q* with Q' and find 
by induction on n (ignoring the vertex ql resp. P:). Thus we obtain 
where (c) is just the triangle inequality, and all other relations have already 
been derived. 
0 
We have seen an example which shows that Cauchy's theorem is not true 
for non-convex polyhedra. The special feature of this example is, of course, 
that a non-continuous "flip" takes one polyhedron to the other, keeping the 
facets congruent while the dihedral angles "jump." One can ask for more: 
Could there be, for some non-convex polyhedron, a continuous 
deformation that would keep the facetsjat and congruent? 
It was conjectured that no triangulated surface, convex or not, admits such 
a motion. So, it was quite a surprise when in 1977 - 
more than 160 years 
after Cauchy's work - 
Robert Connelly presented counterexamples: closed 
triangulated spheres embedded in R3 (without self-intersections) that are 
flexible, with a continuous motion that keeps all the edge lengths constant, 
and thus keeps the triangular faces congruent. 

A beautiful example of a flexible sur- 
face constructed by Klaus Steffen: The 
dashed lines represent the non-convex 
edges in this "cut-out" paper model. 
Fold the normal lines as "mountains" 
and the dashed lines as "valleys." The 
edges in the model have lengths 5, 10, 
11. 12 and 17 units. 
The rigidity theory of surfaces has even more surprises in store: only very 
recently Connelly, Sabitov and Walz managed to prove that when any such 
flexing surface moves, the volume it encloses must be constant. Their proof 
is beautiful also in its use of algebraic machinery (outside the scope of 
this book). 
References 
[l] A. CAUCHY: 
Sur les polygones et les polyPdres, seconde mimoire, J .  ~ c o l e  
Polytechnique XVIe Cahier, Tome IX (1813), 87-98; (Euvres Compktes, IIe 
SCrie, Vol. 1, Paris 1905, 26-38. 
[2] R. CONNELLY: 
A counterexample to the rigidity conjecture forpolyhedra, Inst. 
Haut. Etud. Sci., Publ. Math. 47 (1978), 333-338. 
[3] R. CONNELLY: 
The rigidity ofpolyhedral surfaces, Mathematics Magazine 52 
(1979), 275-283. 
[4] R. CONNELLY, 
I. SABITOV & A. WALZ: The bellows conjecture, Beitrage 
zur Algebra und GeometrieIContributions to Algebra and Geometry 38 (1997), 
1-10, 
[S] J. SCHOENBERG 
& S.K. ZAREMBA: 
On Cauchy's lemma concerning convex 
74 
Cauchy 's rigidity theorem 
1 
polygons, Canadian J .  Math. 19 (1967), 1062-1071. 

Touching simplices 
Chapter 13 
How many d-dimensional simplices can be positioned in Rd 
so that 
they touch pairwise, that is, so that all their pairwise intersections 
are (d - 1)-dimensional? 
This is an old and very natural question. We shall call f (d) the answer to 
this problem, and record f  (1) = 2, which is trivial. For d = 2  the configu- 
ration of four triangles in the margin shows f (2) > 4. There is no similar 
configuration with five triangles, because from this the dual graph construc- 
tion, which for our example with four triangles yields a planar drawing 
of K4, would give a planar embedding of Kg, which is impossible (see 
page 67). Thus we have 
f (2) l 4 
f  ( 2 )  = 4. 
In three dimensions, f (3) > 8 is quite easy to see. For that we use the con- 
figuration of eight triangles depicted on the right. The four shaded triangles 
are joined to some point x below the "plane of drawing," which yields four 
tetrahedra that touch the plane from below. Similarly, the four white trian- 
gles are joined to some point y above the plane of drawing. So we obtain a 
configuration of eight touching tetrahedra in R3, that is, f  ( 3 )  2 8. 
In 1965, Baston wrote a book proving f (3) 5 9, and in 1991 it took Zaks 
another book to establish 
f (3) 2 8 
f ( 3 )  = 8. 
With f  (1) = 2, f ( 2 )  = 4 and f (3) = 8, it doesn't take much inspiration to 
arrive at the following conjecture, first posed by Bagemihl in 1956. 
Conjecture. The maximal number of painvise touching d-simplices in a 
configuration in IRd is 
f  ( d )  = 2d. 
The lower bound, f ( d )  > 2d. is easy to verify "if we do it right." This 
amounts to a heavy use of affine coordinate tranformations, and to an in- 
duction on the dimension that establishes the following stronger result, due 
to Joseph Zaks [4]. 
Theorem 1. For every d 2 2, there is a family of 2d pairwise touching 
d-simplices in Rd together with a transversal line that hits the interior of 
every single one of them. 
"Touching simplices" 

Touching simplices 
Proof. For d = 2 the family of four triangles that we had considered 
does have such a transversal line. Now consider any d-dimensional con- 
figuration of touching simplices that has a transversal line k'. Any nearby 
parallel line e' is a transversal line as well. If we choose t1 and e parallel 
and close enough, then each of the simplices contains an orthogonal 
(shortest) connecting interval between the two lines. Only a bounded part 
of the lines e and e1 is contained in the simplices of the configuration, and 
we may add two connecting segments outside the configuration, such that 
the rectangle spanned by the two outside connecting lines (that is, their con- 
vex hull) contains all the other connecting segments. Thus, we have placed 
a "ladder" such that each of the simplices of the configuration has one of 
the ladder's steps in its interior, while the four ends of the ladder are outside 
the configuration. 
Now the main step is that we perform an (affine) coordinate transformation 
that maps Rd to Rd, and takes the rectangle spanned by the ladder to the 
rectangle (half-square) as shown in the figure below, given by 
Thus the configuration of touching simplices C1 in Rd which we obtain 
has the XI-axis as a transversal line, and it is placed such that each of the 
simplices contains a segment 
in its interior (for some a with -1 < a < 0), while the origin 0 is outside 
all simplices. 
Now we produce a second copy C2 of this configuration by reflecting the 
first one in the hyperplane given by x l  = 2 2 .  This second configuration 
has the x2-axis as a transversal line, and each simplex contains a segment 
in its interior, with -1 < /3 < 0. But each segment S1 (a) intersects each 
segment S2(P), and thus the interior of each simplex of C1 intersects each 
simplex of C2 in its interior. Thus if we add a new (d + 1)-st coordinate 
xd+l, and take C to be 
then we get a configuration of touching (d + 1)-simplices in Rd+l. Fur- 
thermore, the antidiagonal 
A = {(x, -x, 0,. . . , o ) ~  
: x E R) C lRd 
intersects all segments S1 (a) and S2(p). We can "tilt" it a little, and obtain 
a line 
LE = ((2,-x:0 ;..., 0 , ~ x ) ~  
: x E R }  C Itdf1, 
which for all small enough E > 0 intersects all the simplices of C. This 
completes our induction step. 
0 

Touching simplices 
77 
In contrast to this exponential lower bound, tight upper bounds are harder 
to get. A naive inductive argument (considering all the facet hyperplanes in 
a touching configuration separately) yields only 
and this is quite far from the lower bound of Theorem 1. However, Micha 
Perles found the following "magical" proof for a much better bound. 
Theorem 2. For all d > 1, we have f (d) < 2d+1. 
Proof. Given a configuration of r touching d-simplices PI, P 2 ,  . . . , P, 
in IRd, first enumerate the different hyperplanes HI, Hz,. . . , H, spanned 
by facets of the Pi, and for each of them arbitrarily choose a positive 
side H:, 
and call the other side H, . 
For example, for the 2-dimensional configuration of r = 4 triangles depicted 
H~ 
on the right we find s = 6 hyperplanes (which are lines for d = 2). 
a 
From these data, we construct the B-matrix, an (r x s)-matrix with entries 
in {+I. -1,0), as follows: 
+ I  
ifPihasafacetinH,. andpi c H;, 
B.. .- 
- 1 if Pi has a facet in Hj, and P, c HJT, 
0 if P, does not have a facet in Hj. 
For example, the 2-dimensional configuration in the margin gives rise to 
the matrix 
Three properties of the B-matrix are worth recording. First, since every 
d-simplex has d + 1 facets, we find that every row of B has exactly d + 1 
nonzero entries, and thus has exactly s - (d + 1) zero entries. Secondly, we 
are dealing with a configuration of pairwise touching simplices, and thus 
for every pair of rows we find one column in which one row has a +I entry, 
while the entry in the other row is -1. That is, the rows are different even 
if we disregard their zero entries. Thirdly, the rows of B "represent" the 
simplices Pi, via 
Now we derive from B a new matrix C, in which every row of B is replaced 
by all the row vectors that one can generate from it by replacing all the zeros 
by either +1 or -1. Since each row of B has s - d - 1 zeros, and B has r 
rows, the matrix C has 2"-d-1 r rows. 

78 
Touchina simulices 
The first row of the C-matrix represents 
the shaded triangle, while the second 
row corresponds to an empty intersec- 
tion of the halfspaces. The point x leads 
to the vector 
that does not appear in the C-matrix 
For our example, this matrix C is a (32 x 6)-matrix that starts 
where the first eight rows of C are derived from the first row of B, the 
second eight rows come from the second row of B, etc. 
The point now is that all the rows of C are different: If two rows are derived 
from the same row of B, then they are different since their zeros have been 
replaced differently; if they are derived from different rows of B, then they 
differ no matter how the zeros have been replaced. But the rows of C are 
(f 1)-vectors of length s, and there are only 2" different such vectors. Thus 
since the rows of C are distinct, C can have at most 2" rows, that is, 
However, not all possible (51)-vectors appear in C, which yields a strict 
inequality 2"-"'r 
< 2", and thus r < 2d+1. To see this, we note that 
every row of C represents an intersection of halfspaces -just 
as for the 
rows of B before, via the formula (*). This intersection is a subset of the 
simplex Pi, which was given by the corresponding row of B. Let us take 
a point x E Rd that does not lie on any of the hyperplanes H j ,  and not in 
any of the simplices Pi. From this x we derive a (f1)-vector that records 
for each j whether x E H; or x E HJr. This (f1)-vector does not occur 
in C, because its halfspace intersection according to (*) contains x and thus 
is not contained in any simplex Pi. 
0 
References 
[l ] F. BAGEMIHL: 
A conjecture concerning neighboring tetrahedra, Amer. Math. 
Monthly 63 (1956) 328-329. 
[2] V. J. D. BASTON: 
Some Properties of Polyhedra in Euclidean Space, Perga- 
mon Press, Oxford 1965. 
[3] M. A. PERLES: At most 2d+1 neighborly simplices in E ~ ,  
Annals of Discrete 
Math. 20 (1984), 253-254. 
[4] J. ZAKS: Neighborly families of 2d d-simplices in E ~ ,  
Geometriae Dedicata 
11 (1981), 279-296. 
[5] J. ZAKS: NO Nine Neighborly Tetrahedra Exist, Memoirs Amer. Math. Soc. 
No. 447, Vol. 91, 1991. 

Every large point set 
has an obtuse angle 
Around 1950 Paul Erdiis conjectured that every set of more than 2"oints 
in Rqetermines at least one obtuse angle, that is, an angle that is strictly 
greater than ;. 
In other words, any set of points in IKd which only has acute 
angles (including right angles) has size at most 2d. This problem was posed 
as a "prize question" by the Dutch Mathematical Society - 
but solutions 
were received only for d = 2 and for d = 3. 
For d = 2 the problem is easy: The five points may determine a convex 
pentagon, which always has an obtuse angle (in fact, at least one angle of 
at least 108"). Otherwise we have one point contained in the convex hull 
of three others that form a triangle. But this point "sees" the three edges of 
the triangle in three angles that sum to 360°, so one of the angles is at least 
120". (The second case also includes situations where we have three points 
on a line, and thus a 180" angle.) 
Unrelated to this, Victor Klee asked a few years later - 
and Erdiis spread 
the question - 
how large a point set in lRd could be and still have the 
following "antipodality property": For any two points in the set there is a 
strip (bounded by two parallel hyperplanes) that contains the point set, and 
that has the two chosen points on different sides on the boundary. 
Then, in 1962, Ludwig Danzer and Branko Griinbaum solved both prob- 
lems in one stroke: They sandwiched both maximal sizes into a chain of 
inequalities, which starts and ends in 2d. Thus the answer is 2d both for 
Erdiis' and for Klee's problem. 
In the following, we consider (finite) sets S C lRd of points, their convex 
hulls conv(S), and general convex polytopes Q C lRd. (See the appendix 
on polytopes on page 50 for the basic concepts.) We assume that these sets 
have the full dimension d, that is, they are not contained in a hyperplane. 
Two convex sets touch if they have at least one boundary point in common, 
while their interiors do not intersect. For any set Q 
lRd and any vector 
s E EXd we denote by Q + s the image of Q under the translation that moves 
0 to s. Similarly, Q - s is the translate obtained by the map that moves s 
to the origin. 
Don't be intimidated: This chapter is an excursion into d-dimensional 
geometry, but the arguments in the following do not require any "high- 
dimensional intuition," since they all can be followed, visualized (and thus 
understood) in three dimensions, or even in the plane. Hence, our figures 
will illustrate the proof for d = 2 (where a "hyperplane" is just a line), and 
you could create your own pictures for d = 3 (where a "hyperplane" is 
a plane). 
Chapter 14 

80 
Every large point set has an obtuse angle 
Theorem 1. For every d, one has the following chain of inequalities: 
(1) 
2d < max{#SI S C Rd, 
<(si,s,,sk) < forevery {si,sj,sk) G S) 
< max #S 
( )  i 
(3) max #S i 
S C  
there 
lying 
Rd such that for any two points {si, ~
j
)
 
C S 
is a strip S(i, j )  that contains S, with si and sj 
in the parallel boundary hyperplanes of S(i, j )  
S g Rd such that the translates P - si, si E S, of 
the convex hull P := conv(S) intersect in a common 
point, but they only touch 
(4) 
< mnx {#s / S c Rd such that the translates Q + si of some d- 
- 
dimensional convex polytope Q C Rd touch painvise 
S 
Rd such that the translates Q* + si of some 
d-dimensional centrally symmetric convex polytope 
Q* 
EXd touch painvise 
H Proof. We have six claims (equalities and inequalities) to verify. Let's 
get going. 
(1) Take S := (0, lId to be the vertex set of the standard unit cube in Rd, 
and choose s,, sj, sk E S. By symmetry we may assume that sj = 0 is 
the zero vector. Hence the angle can be computed from 
which is clearly nonnegative. Thus S is a set with IS/ = 2d that has no 
obtuse angles. 
(2) If S contains no obtuse angles, then for any si, sj E S we may define 
Hi, + si and Hij + sj to be the parallel hyperplanes through si resp. sj that 
are orthogonal to the edge [si, sj]. Here Hij = { x  E Rd : ( x ,  s,-sj) = 0 )  
is the hyperplane through the origin that is orthogonal to the line through 
si and sj, and Htj + sj = { x  + sj : x E Hi,) is the translate of Htj 
that passes through sj, etc. Hence the strip between Hij + si and Hij + sj 
consists, besides si and sj, exactly of all the points x E Rd such that the 
angles ~ ( s i ,  
sj , x )  and <(sj, 
s i ,  x) are non-obtuse. Thus the strip contains 
all of S. 
Hi, + s, 
(3) P is contained in the halfspace of Hij + sj that contains si if and only 
if P - s, is contained in the halfspace of Hij that contains si - sj: A prop- 
erty "an object is contained in a halfspace" is not destroyed if we translate 
both the object and the halfspace by the same amount (namely by -sj). 
Similarly, P is contained in the halfspace of Hij + si that contains sj if 
and only if P - si is contained in the halfspace of Hij that contains sj - si. 
Putting both statements together, we find that the polytope P is contained 
in the strip between H,, + si and Hij + sj if and only if P - si and P - sj 
lie in different halfspaces with respect to the hyperplane Hij. 

Every large point set has an obtuse angle 
8 1 
This correspondence is illustrated by the sketch in the margin. 
Furthermore, from si E P = conv(S) we get that the origin 0 is contained 
in all the translates P - si (si E S). Thus we see that the sets P - si 
all intersect in 0, but they only touch: their interiors are pairwise disjoint, 
since they lie on opposite sides of the corresponding hyperplanes Hij. 
(4) This we get for free: "the translates must touch pairwise" is a weaker 
condition than "they intersect in a common point, but only touch." 
Similarly, we can relax the conditions by letting P be an arbitrary convex 
d-polytope in I W ~ .  
Furthermore, we may replace S by -S. 
(5) Here "2" 
is trivial, but that is not the interesting direction for us. We 
have to start with a configuration S c IRd and an arbitrary d-polytope 
Q 
IRd such that the translates Q + si (s, E S )  touch pairwise. The 
claim is that in this situation we can use 
instead of Q. But this is not hard to see: First, Q* is d-dimensional, convex, 
and centrally symmetric. One can check that Q* is a polytope (its vertices 
are of the form (q, -q,), for vertices q,, q j  of Q), but this is not important 
for us. 
Now we will show that Q + s, and Q + sj touch ifand only if Q* + si and 
Q* + sj touch. For this we note, in the footsteps of Minkowski, that 
(Q*+si) n (Q* + s,) # 0 
+ 3 q : , q y , q ; , q y ~ Q :  ~ ( q : - q ~ ) + s i = ~ ( q l , - q y ) + s j  
where in the third (and crucial) equivalence "u" 
we use that every q E Q 
can be written as q = $ ( q  + q) to get "+", and that Q is convex and thus 
1 T(qi + qy), ;(qj + q;) E Q to see "+". 
Thus the passage from Q to Q* (known as Minkowski symmetrization) pre- 
serves the property that two translates Q + s, and Q + sj intersect. That is, 
we have shown that for any convex set Q, two translates Q + si and Q + sj 
intersect if and only if the translates Q* + si and Q* + sj intersect. 
The following characterization shows that Minkowski symmetrization also 
preserves the property that two translates touch: 
Q + si and Q + s3 touch ifand only ifthey intersect, while Q + si 
and Q + sj + &(sj - s i )  do not intersect for any E > 0. 
(6) Assume that Q* + si and Q* + sj touch. For every intersection point 

82 
Even, large point set has an obtuse angle 
we have 
x - st E Q* and x - s j  E Q*, 
thus, since Q* is centrally symmetric, 
si - x = -(x - si) E Q*, 
and hence, since Q* is convex, 
1 
1 
z ( ~ i  
- ~ j )  
= 2 ((x - ~ j )  
+ ( ~ i  
- x)) E Q*. 
We conclude that (si + s,) is contained in Q* + sj for all i. Consequently, 
for P := conv(S) we get 
which implies that the sets Pj = a ( P  + sj) can only touch. 
Finally, the sets Pj are contained in P ,  because all the points si, sj and 
;(si + s j )  are in P, since P is convex. But the Pj are just smaller, scaled, 
translates of P ,  contained in P. The scaling factor is i, which implies that 
since we are dealing with d-dimensional sets. This means that at most 2d 
Scaling factor $, vol(P,) = ; V O ~ ( P )  
sets Pj fit into P, and hence SI < 2d. 
This completes our proof: the chain of inequalities is closed. 
. . .but that's not the end of the story. Danzer and Grunbaum asked the 
following natural question: 
What happens if one requires all angles to be acute rather than 
just non-obtuse, that is, fright angles are forbidden? 
They constructed configurations of 2d - 1 points in IR%ith 
only acute 
angles, conjecturing that this may be best possible. Griinbaum proved that 
this is indeed true for d < 3. But twenty-one years later, in 1983, Paul 
ErdBs and Zoltan Furedi showed that the conjecture is false - 
quite dra- 
matically, if the dimension is high! Their proof is a great example for the 
power of probabilistic arguments; see Chapter 35 for an introduction to the 
"probabilistic method." Our version of the proof uses a slight improvement 
in the choice of the parameters due to our reader David Bevan. 
Theorem 2. For every d 2 2. there is a set S i {O, 1)"f 
2 L$ 
points in IRd (vertices of the unit d-cube) that determine only acute angles. 
In particulal; in dimension d = 34 there is a set of 72 > 2.34 - 1 points 
with only acute angles. 
Proof. Set m := L$ 
( 2 I d j ,  and pick 3m vectors 
d3 
by choosing all their coordinates independently and randomly, to be either 
0 or 1, with probability 
for each alternative. (You may toss a perfect coin 
3,md times for this; however, if d is large you may get bored by this soon.) 

Evew laree voint set has an obtuse anale 
83 
We have seen above that all angles determined by 011-vectors are non- 
obtuse. Three vectors x ( i ) ,  x ( j ) ,  x ( k )  determine a right angle with apex 
x ( j )  if and only if the scalar product ( x ( i )  - x ( j ) ,  x ( k )  - x ( j ) )  vanishes, 
that is, if we have 
x(i)g - x ( j ) ,  = 0 or x(k), - x(j)g = 0 for each coordinate l. 
We call (i, j; k )  a bad triple if this happens. (If x ( i )  = x ( j )  or x ( j )  = 
x ( k ) ,  then the angle is not defined, but also then the triple ( 2 ,  j, k )  is 
certainly bad.) 
d 
The probability that one specific triple is bad is exactly (:) 
: Indeed, it 
will be good if and only if, for one of the d coordinates l, we get 
either 
x(i)e = x(l;)e = 0, x(j)e = 1, 
or 
x(i)e = x(k)e = 1. x(j)e = 0. 
This leaves us with six bad options out of eight equally likely ones, and a 
triple will be bad if and only if one of the bad options (with probability :) 
happens for each of the d coordinates. 
The number of triples we have to consider is 3(33m), since there are (33") 
sets of three vectors, and for each of them there are three choices for the 
apex. Of course the probabilities that the various triples are bad are not 
independent: but linearity of expectation (which is what you get by averag- 
ing over all possible selections; see the appendix) yields that the expected 
d 
number of bad triples is exactly 3 (33") (a) . This means - 
and this is the 
point where the probabilistic method shows its power - 
that there is some 
d 
choice of the 3m vectors such that there are at most 3(33") (a) bad triples, 
where 
by the choice of m. 
But if there are not more than 7n bad triples, then we can remove m of the 
3m vectors x ( i )  in such a way that the remaining 2m vectors don't contain 
a bad triple, that is, they determine acute angles only. 
0 
The "probabilistic construction" of a large set of O/l-points without right 
angles can be easily implemented, using a random number generator to "flip 
the coin." David Bevan has thus constructed a set of 31 points in dimension 
d = 15 that determines only acute angles. 
Appendix: Three tools from probability 
Here we gather three basic tools from discrete probability theory which 
will come up several times: random variables, linearity of expectation and 
Markov's inequality. 

84 
E v e n  larae ~ o i n t  
set has an obtuse anale 
Let (R, p) be a finite probability space, that is, 0 is a finite set andp = Prob 
is a map from R into the interval [0, I] with xWEn 
p(w) = 1. A random 
variable X on R is a mapping X : R + R. 
We define a probability space 
on the image set X ( R )  by setting p ( X  = x) := Ex(,)=, p(w). A simple 
example is an unblased dice (all p(w) = i) 
with X  = "the number on top 
when the dice is thrown." 
The expectation E X  of X  is the average to be expected, that is, 
Now suppose X and Y are two random variables on R, then the sum X  + Y 
is again a random variable, and we obtain 
Clearly, this can be extended to any finite linear combination of random 
variables - 
this is what is called the linearity of expectation. Note that it 
needs no assumption that the random variables have to be "independent" 
in any sense! 
Our third tool concerns random variables X which take only nonnegative 
values, shortly denoted X > 0. Let 
be the probability that X is at least as large as some a > 0. Then 
and we have proved Markov's inequality 
References 
[I] L. DANZER & B. GRUNBAUM: 
Uber zwei Probleme beziiglich konvexer 
Korper von P: Erdos und von I/: L. Klee, Math. Zeitschrift 79 (1962), 95-99. 
[2] P. E R D ~ S  
& Z. FUREDI: The greatest angle among n points in the 
d-dimensional Euclidean space, Annals of Discrete Math. 17 (1983), 275-283. 
[3] H. MINKOWSKI: 
Dichteste gitterfonnige Lugerung kongruenter Korpec 
Nachrichten Ges. Wiss. Gottingen, Math.-Phys. Klasse 1904, 31 1-355. 

Borsuk's conjecture 
Karol Borsuk's paper "Three theorems on the n-dimensional euclidean 
sphere" from 1933 is famous because it contained an important result 
(conjectured by Stanislaw Ulam) that is now known as the Borsuk-Ulam 
theorem: 
Every continuous map f : Sd 4 IKd maps two antipodal points of 
the sphere Sd to the same point in Ktd. 
The same paper is famous also because of a problem posed at its end, which 
became known as Borsuk's Conjecture: 
3 
Can every set S C IRd of bounded diameter diam(S) > 0 be 
partitioned into at most d + 1 sets of smaller diameter? 
Karol Borsuk 
The bound of d+ 1 is best possible: if S is a regular d-dimensional simplex, 
or just the set of its d + 1 vertices, then no part of a diameter-reducing 
partition can contain more than one of the simplex vertices. Iff (d) denotes 
the smallest number such that every bounded set S C EXd has a diameter- 
reducing partition into f (d) parts, then the example of a regular simplex 
establishes f ( d )  > d + 1. 
Borsuk's conjecture was proved for the case when S is a sphere (by Borsuk 
himself), for smooth bodies S (using the Borsuk-Ulam theorem), for d < 
3, . . .but the general conjecture remained open. The best available upper 
bound for f ( d )  was established by Oded Schramm, who showed that 
for all large enough d. This bound looks quite weak compared with the con- 
jecture "f ( d )  = d + l", but it suddenly seemed reasonable when Jeff Kahn 
and Gil Kalai dramatically disproved Borsuk's conjecture in 1993. Sixty 
years after Borsuk's paper, Kahn and Kalai proved that f ( d )  > ( 1 . 2 ) ~  
holds for large enough d. 
A Book version of the Kahn-Kalai proof was provided by A. Nilli: brief 
and self-contained, it yields an explicit counterexample to Borsuk's conjec- 
ture in dimension d = 946. We present here a modification of this proof, 
due to Andrei M. Raigorodskii and to Bernulf WeilSbach, which reduces 
the dimension to d = 561, and even to d = 560. The current "record" is 
d = 298, achieved by Aicke Hinrichs and Christian Richter in 2002. 
Chapter 15 
Any d-simplex can be split into d + 1 
pieces, each of smaller diameter. 

86 
Borsuk's conjecture 
Theorem. Let q = pm be a prime powel; n := 4q - 2, and d := (i) = 
(2q - 1)(4q - 3). Then there is a set S C {+I, -1Id ?f 2n-2 points in Ktd 
such that every partition of S, whose parts have smaller diameter than S, 
has at least 
2"-2 
q-2 c ("3 
2=0 
parts. For q = 9 this implies that the Borsuk conjecture is false in dimen- 
sion d = 561. Furthermore, f (d) > ( 1 . 2 ) ~  
holds for all large enough d. 
L 
1 
Proof. The construction of the set S proceeds in four steps. 
A. Nilli 
(1) Let q be a prime power, set n = 4q - 2, and let 
Q := {x E {+I, - l j n  : X I  = 1, #{i : xi = -I} is even . 1 
This Q is a set of 2n-2 vectors in Rn. We will see that (x, 
y) = 2 (mod4) 
holds for all vectors x, y E Q. We will call x, y nearly-orthogonal if 
1(x, y) 
1 = 2. We will prove that any subset Q' C Q which contains no 
nearly-orthogonal vectors must be "small": IQ'I i ~910" 
(2) From Q, we construct the set 
of 2n-2 symmetric (n x n)-matrices of rank 1. We interpret them as vectors 
with n2 components, R C Rn2. We will show that there are only acute 
angles between these vectors: they have positive scalar products, which are 
at least 4. Furthermore, if R' c R contains no two vectors with minimal 
q-2 
n-1 
scalar product 4, then IR'I is "small": (R'I < 
( 
). 
Vectors, matrices, and scalar products 
In our notation all vectors x, y, . . . are column vectors; the transposed 
vectors xT, 
yT, . . . are thus row vectors. The matrix product xxT is 
a matrix of rank 1, with ( x x ~ ) ~ ?  
= xixj. 
If x, y are column vectors, then their scalar product is 
We will also need scalar products for matrices X, 
Y E RnXn which 
can be interpreted as vectors of length n2, and thus their scalar 
product is 

Borsuk's conjecture 
87 
(3) From R, we obtain the set of points in R(;) whose coordinates are the 
subdiagonal entries of the corresponding matrices: 
S := { ( z x ~ ) ~ , ~  
: xxT E R}. 
Again, S consists of 2n-2 points. The maximal distance between these 
points is precisely obtained for the nearly-orthogonal vectors x, y E Q. 
We conclude that a subset S' c S of smaller diameter than S must be 
.'small": IS'I < 
(4) Estimates: From (3) we see that one needs at least 
parts in every diameter-reducing partition of S. Thus 
f ( d )  > max{g(q). d + 1 )  
for d = (29 - l ) ( 4 q  - 3). 
Therefore, whenever we have g(q) > (2q - 1)(4q - 3 )  + 1, then we have a 
counterexample to Borsuk's conjecture in dimension d = (29 - 1 )  (4q - 3). 
We will calculate below that g(9) > 562, which yields the counterexample 
in dimension d = 561, and that 
which yields the asymptotic bound f ( d )  > ( 1 . 2 ) ~  
for d large enough. 
Details for (1): We start with some harmless divisibility considerations. 
Lemma. The function P ( z )  := (;I:) is a polynomial of degree q - 2. It 
yields integer values for all integers z. The integer P ( z )  is divisible by p if 
and only i f z  is not congruent to 0 or 1 modulo q. 
Proof. For this we write the binomial coefficient as 
and compare the number of p-factors in the denominator and in the numer- 
ator. The denominator has the same number of p-factors as ( q  - 2)!, or as 
( q  - I ) ! ,  since q - 1 is not divisible by p. Indeed, by the claim in the margin 
we get an integer with the same number of p-factors if we take any product 
of q - 1 integers, one from each non-zero residue class modulo q. 
Now if z is congruent to 0 or 1 (mod q), then the numerator is also of this 
type: All factors in the product are from different residue classes, and the 
only classes that do not occur are the zero class (the multiples of q), and the 
class either of -1 or of +1, but neither +1 nor -1 is divisible by p. Thus 
denominator and numerator have the same number of p-factors, and hence 
the quotient is not divisible by p. 
Claim. If a s b $ 0 (mod q), then 
a and b have the same number of p- 
factors. 
Proof. We have a = b + spm, where 
b is not divisible by pm = q. So every 
power p%hat divides b satisfies k < rn, 
and thus it also divides a. The statement 
is symmetric in a and b. 
0 

88 
Borsuk's conjecture 
On the other hand, if z $ O , 1  (modq), then the numerator of (*) contains 
one factor that is divisible by q = pm. At the same time, the product has no 
factors from two adjacent nonzero residue classes: one of them represents 
numbers that have no p-factors at all, the other one has fewer p-factors 
than q = pm. Hence there are more p-factors in the numerator than in the 
denominator, and the quotient is divisible by p. 
0 
Now we consider an arbitrary subset Q' C Q that does not contain any 
nearly-orthogonal vectors. We want to establish that Q' must be "small." 
Claim I .  Ifx, y are distinct vectors from Q, then a ((x, y )  + 2) is 
an integer in the range 
Both x and y have an even number of (-1)-components, so the number of 
components in which x and y differ is even, too. Thus 
(x, y )  = (4q - 2) - 2#{i : xi # yi) - -2 (mod4) 
for all x ,  y E Q, that is, i ( ( x ,  y) + 2) is an integer. 
From x, y E {+I, -1)44-2 
we see that -(4q - 2) < (x, y )  < 4q - 2, 
that is, - (q - 1) < i ((2, y )  + 2) < q. The lower bound never holds with 
equality, since X I  = yl = 1 implies that x # - y. The upper bound holds 
with equality only if x = y. 
Claim 2. For any y E Q', the polynomial in n variables XI, . . . , x, 
of degree q - 2 given by 
satisfies that F,(x) is divisible by p for every x E Q1\{y), but 
not for x = y. 
The representation by a binomial coefficient shows that l?, (x) is an integer- 
valued polynomial. For x = y, we get F,(y) = 1. For x # y, the 
Lemma yields that F, (x) is not divisible by p if and only if i ((x, y )  + 2) is 
congruent to 0 or 1 (mod q). By Claim 1, this happens only if i ( ( x ,  y) + 2) 
is either 0 or 1, that is, if (x, y )  E (-2, +2). So x and y must be nearly- 
orthogonal for this, which contradicts the definition of Q'. 
Claim 3. The same is true for the polynomials F, (x) 
in the n - 1 
variables 2 2 ,  . . . , x, that are obtained as follows: Expand F, (x) 
into monomials and remove the variable XI, and reduce all higher 
powers of other variables, by substituting x l  = 1, and x: = 1 for 
i > 1. The polynomials F1, (x) have degree at most q - 2. 
The vectors x E Q C ($1, -1)" all satisfy x l  = 1 and xf = 1. Thus 
the substitutions do not change the values of the polynomials on the set Q. 
They also do not increase the degree, so F, (x) has degree at most q - 2. 

Borsuk's coniecture 
89 
Claim 4. There is no linear relation (with rational coeficients) 
between the polynomials & (x), 
that is, the polytzotnials 
(x), 
y E Q', 
are linearly independent over Q. 
In particular; they are 
distinct. 
Assume that there is a relation of the form EYE&, 
ayFy 
(x) 
= 0 such that 
not all coefficients a, are zero. After multiplication with a suitable scalar 
we may assume that all the coefficients are integers, but not all of them are 
divisible by p. But then for every y E Q' the evaluation at x := y yields 
that Q,F,(~) 
is divisible by p, and hence so is a,, since F,(y) 
is not. 
Claim 5. lQ'I is bounded by the number of squarefree monomials 
of degree at most q - 2 in r~ - 1 variables, which is ~ : z  
By construction the polynomials F, are squarefree: none of their mono- 
mials contains a variable with higher degree than 1. Thus each G ( x )  
is a 
linear combination of the squarefree monomials of degree at most q - 2 in 
the n - 1 variables x2, . . . , x,. Since the polynomials Fy 
(x) 
are linearly 
independent, their number (which is /QII) 
cannot be larger than the number 
of monomials in question. 
Details for (2): The first column of xxT is x. Thus for distinct x E Q 
we obtain distinct matrices Al(x) := xxT. We interpret these matrices as 
vectors of length n2 with components x,x, . A simple computation 
shows that the scalar product of M(X) 
and AP(y) is minimized if and only 
if x, 
y t Q are nearly-orthogonal. 
Details for (3): Let U(x) E {+l. -l)d denote the vector of all sub- 
diagonal entries of Al(x). Since M(x) = xxT is symmetric with diagonal 
values +l, we see that M(x) # M(y) implies U(x) # U(y). Further- 
more, 
4 I 
(M(x), 
~I(Y)) = 2(U(x), 
U(Y)) 
+ n, 
that is, 
M ( x )  = 
n 
Y 
2 -5 + 2. 
with equality if and only if x and y are nearly-orthogonal. Since all the vec- 
tors U(x) t S have the same length J(u(x). 
U(x)) = a, 
this means 
that the maximal distance between points U(x), 
U(y) i S is achieved 
exactly when x and y are nearly-orthogonal. 
Details for (4): For q = 9 we have g(9) = 758.31, which is greater than 
d + 1 = (324) + 1 = 562. 

90 
Borsuk's conjecture 
To obtain a general bound for large d, we use monotonicity and unimodality 
of the binomial coefficients and the estimates n! > e(:)" and n! < en(:)" 
(see the appendix to Chapter 2) and derive 
Thus we conclude 
From this, with 
d = ( 2 4 - 1 ) ( 4 q - 3 )  = 5 q 2 + ( q - 3 ) ( 3 q - 1 )  > 5q2 
f o r q 2 3 ,  
q = + 4- 
> fi, and 
(%)& > 1.2032, 
we get 
e  
f (d; > -(1.2032)& 
> ( 1 . 2 ) ~  for all large enoughd. 
0 
13d 
A counterexample of dimension 560 is obtained by noting that for q  = 9 the 
quotient g(q) = 758 is much larger than the dimension d(q) = 561. Thus 
one gets a counterexample for d = 560 by taking only the "three fourths" 
of the points in S that satisfy xzl + x 3 ~  
+ 2 3 2  = -1. 
Borsuk's conjecture is known to be true for d 
3, but it has not been 
verified for any larger dimension. In contrast to this, it is true up to d = 8 
if we restrict ourselves to subsets S C ( 1 ,  - l ) d ,  as constructed above 
(see [8]). In either case it is quite possible that counterexamples can be 
found in reasonably small dimensions. 
References 
K. BORSUK: 
Drei Satze uber die n-dimensionale euklidische Sphare, Funda- 
menta Math. 20 (1933), 177-190. 
A. HINRICHS & C. RICHTER: New sets with large Borsuk numbers, Prepnnt, 
February 2002, 10 pages; Discrete Math., to appear. 
J. KAHN & G. KALAI: A counterexample to Borsuk's conjecture, Bulletin 
Amer. Math. Soc. 29 (1993), 60-62. 
A. NILLI: On Borsuk's problem, in: "Jerusalem Combinatorics '93" (H. 
Barcelo and G. Kalai, eds.), Contemporary Mathematics 178, Amer. Math. 
SOC. 1994, 209-210. 
A. M. RAIGORODSKII: 
On the dimension in Borsuk'sproblem, Russian Math. 
Surveys (6) 52 (1997), 1324-1325. 
0. SCHRAMM: 
flluminating sets of constant width, Mathematika 35 (1988), 
180- 199. 
B. WEISSBACH: 
Sets with large Borsuk numbel; Beitrage zur Algebra und 
Geometrie/Contributions to Algebra and Geometry 41 (2000), 417-423. 
G. M. ZIEGLER: Coloring Hamming graphs, optimal binary codes, and the 
O/l-Borsuk problem in low dimensions, Lecture Notes in Computer Science 
2122, Springer-Verlag 2001, 164- 175. 

 
 
 
Analysis 

Sets, functions, 
and the continuum hypothesis 
Set theory, founded by Georg Cantor in the second half of the 19th cen- 
tury, has profoundly transformed mathematics. Modern day mathematics 
is unthinkable without the concept of a set, or as David Hilbert put it: "No- 
body will drive us from the paradise (of set theory) that Cantor has created 
for us." 
One of Cantor's basic concepts was the notion of the size or cardinality of 
a set A l ,  denoted by I A l l  For finite sets, this presents no difficulties: we 
just count the number of elements and say that hf is an n-set or has size n, 
if A4 contains precisely n elements. Thus two finite sets A4 and N have 
equal size, (MI = IN(, if they contain the same number of elements. 
To carry this notion of equal size over to infinite sets, we use the following 
suggestive thought experiment for finite sets. Suppose a number of people 
board a bus. When will we say that the number of people is the same as the 
number of available seats? Simple enough, we let all people sit down. If 
everyone finds a seat, and no seat remains empty, then and only then do the 
two sets (of the people and of the seats) agree in number. In other words, 
the two sizes are the same if there is a bijection of one set onto the other. 
This is then our definition: Two arbitrary sets A4 and N (finite or infinite) 
are said to be of equal size or cardinali~y, if and only if there exists a bi- 
jection from M onto N. Clearly, this notion of equal size is an equivalence 
relation, and we can thus associate a number, called cardinal number, to 
every class of equal-sized sets. For example, we obtain for finite sets the 
cardinal numbers 0,1,2,. 
. . , n ,  . . . where n stands for the class of n,-sets, 
and, in particular, 0 for the empty set 0. 
We further observe the obvious fact 
that a proper subset of a finite set M invariably has smaller size than M. 
The theory becomes very interesting (and highly non-intuitive) when we 
turn to infinite sets. Consider the set N = {1,2,3, . . .) of natural numbers. 
We call a set M countable if it can be put in one-to-one correspondence 
with N. In other words, A4 is countable if we can list the elements of M as 
ml, mz, m3, . . .. But now a strange phenomenon occurs. Suppose we add 
to N a new element x. Then N U  {x) is still countable, and hence has equal 
size with N! 
This fact is delightfully illustrated by "Hilbert's hotel." Suppose a hotel 
has countably many rooms, numbered 1,2,3, 
. . . with guest g, occupying 
room i; so the hotel is fully booked. Now a new guest x arrives asking 
for a room, whereupon the hotel manager tells him: Sorry, all rooms are 
taken. No problem, says the new arrival, just move guest gl to room 2, 
gz to room 3, g3 to room 4, and so on, and I will then take room 1. To the 
Chapter 16 
Georg Cantor 

94 
Sets, functions, and the continuum hvvothesis 
/ 
manager's surprise (he is not a mathematician) this works; he can still put 
up all guests plus the new arrival x! 
Now it is clear that he can also put up another guest y, and another one z, 
and so on. In particular, we note that, in contrast to finite sets, it may well 
happen that a proper subset of an injnite set M has the same size as M. In 
fact, as we will see, this is a characterization of infinity: A set is infinite if 
and only if it has the same size as some proper subset. 
Let us leave Hilbert's hotel and look at our familiar number sets. The set 
Z 
of integers is again countable, since we may enumerate Z in the form 
Z = (0, 1, -1'2, -2,3, -3,. . .). It may come more as a surprise that the 
rationals can be enumerated in a similar way. 
Theorem 1. The set Q of rational numbers is countable. 
Proof. By listing the set Q+ of positive rationals as suggested in the 
figure in the margin, but leaving out numbers already encountered, we see 
that Q+ is countable, and hence so is Q by listing O at the beginning and 
-' 
right after E. With this listing 
4 
Another way to interpret the figure is the following statement: 
The union of countably many countable sets Mn is again countable. 
Indeed, set Mn = {anl, an2, a,s, . . .) and list 
precisely as before. 
Let us contemplate Cantor's enumeration of the positive rationals a bit 
more. Looking at the figure we obtained the sequence 
and then had to strike out the duplicates such as $ = or 2 = i. 
But there is a listing that is even more elegant and systematic, and which 
contains no duplicates - 
found only quite recently by Neil Calkin and 
Herbert Wilf. Their new list starts as follows: 
Here the denominator of the n-th rational number equals the numerator of 
the (n + 1)-st number. In other words, the n-th fraction is b(n)/b(n + l ) ,  
where (b(n))n2, is a sequence that starts with 
This sequence has first been studied by a German mathematician, Moritz 
Abraham Stem, in a paper from 1858, and is has become known as "Stern's 
diatomic series." 

Sets, functions, and the continuum hypothesis 
95 
How do we obtain this sequence, and hence the Calkin-Wilf listing of the 
positive fractions? Consider the infinite binary tree in the margin. We 
immediately note its recursive rule: 
is on top of the tree, and 
every node 4 has two sons: the left son is & and the right son is y. 
3 
d h 
& h 
1 - 
3 - 
2 - 
3 - 
We can easily check the following four properties: 
then r and s are relatively prime. 
a 
a 
iB 
/a 
(1) All fractions in the tree are reduced, that is, if $ appears in the tree, 
1 4 
3 
5 
2 5 
3 
4 
This holds for the top +, and then we use induction downward. If r and s - 
1 
are relatively prime, then so are r and r + s, as well as s and r + s. 
i a  i a  i a  A /a ;a 
i a  i'a 
5 
" '  
(2) Every reduced fraction $ > 0 appears in the tree. 
We use induction on the sum r + s. The smallest value is r + s = 2, that 
is f = i, and this appears at the top. If r > s, then 7 appears in the tree 
by induction, and so we get : 
as its right son. Similarly, if r < s, then 2 
appears, which has $ as its left son. 
(3) Every reduced fraction appears exactly once. 
The argument is similar. If $ appears more than once, then r # s, since 
any node in the tree except the top is of the form & < 1 or 
> 1. But 
if r > s or r < s, then we argue by induction as before. 
Every positive rational appears therefore exactly once in our tree, and we 
may write them down listing the numbers level-by-level from left to right. 
This yields precisely the initial segment shown above. 
(4) The denominator of the n-th fraction in our list equals the numerator 
of the ( n  + 1)-st. 
This is certainly true for n = 0, or when the n-th fraction is a left son. 
Suppose the n-th number $ is a right son. If $ is at the right boundary, 
r-s 
then s = 1, and the successor lies at the left boundary and has numerator 1. 
S 
Finally, if 
is in the interior, and $ is the next fraction in our sequence, 
then : 
is the right son of 7, 
5 
is the left son of 6, 
and by induction 
h 
- 
'3 
the denominator of 7 is the numerator of A, 
SO we get s = r'. 
Well, this is nice, but there is even more to come. There are two natural 
questions: 
- Does the sequence (b(n))n2, have a "meaning"? That is, does b(n) 
count anything simple? 
- Given :, is there an easy way to determine the successor in the listing? 

96 
Sets, functions, and the continuum hypothesis 
To answer the first question, we work out that the node b(n)/b(n + 1 )  has 
the two sons b(2n + l ) / b ( 2 n  + 2 )  and b(2n + 2)/b(2n + 3). By the set-up 
of the tree we obtain the recursions 
b(2n + 1 )  = b ( n )  and 
b(2n + 2 )  = b(n) + b ( n  + 1). 
(1) 
With b(0) = 1 the sequence (b(n)),20 is completely determined by (I). 
So, is there a "nice" "known" sequence which obeys the same recursion? 
Yes, there is. We know that any number n can be uniquely written as a sum 
For 
h(6) = 3' with the hyper- 
of distinct powers of 2 - 
this is the usual binary representation of n. A 
binary representations 
hyper-binary representation of n is a representation of n a sum of powers 
6 = 4 + 2  
of 2, where every power 2k appears at most twice. Let h(n) be the number 
6 = 4 + 1 + 1  
of such representations for n. You are invited to check that the sequence 
6 = 2 + 2 + 1 + 1 .  
h ( n )  obeys the recursion (1), and this gives b ( n )  = h ( n )  for all n. 
Incidentally, we have proved a surprising fact: Let 
be a reduced fraction, 
there exists precisely one integer n with r = h(n) and s = h ( n  + 1). 
Let us look at the second question. We have in our tree 
r - 
_/a 
that is, with x := :, 
* 
5 
r+s 
s 
-/'a 
l+z 
x + ]  
1 
- 
5 
. . . 
In this tree all rows are equal, and they all display the Calkin-Wilf listing 
of the positive rationals (starting with an additional !). 

Sets, jitnctions, and the continuum hypothesis 
97 
So how does one get from one rational to the next? To answer this, we first 
record that for every rational x  its right son is x  + 1, the right grand-son is 
x + 2, so the k-fold right son is x  + k. Similarly, the left son of x is &, 
whose left son is A, 
and so on: The k-fold left son of x  is A. 
Now to find how to get from 
= x to the "next" rational f (x) in the 
listing, we have to analyze the situation depicted in the margin. In fact, if 
Y 
'+( 
y + l  
we consider any nonnegative rational number x in our infinite binary tree, 
then it is the k-fold right son of the left son of some rational y > 0  (for 
some k > 0), while f (x) is given as the k-fold left son of the right son of 
d 
the same y. Thus with the formulas for k-fold left sons and k-fold right 
\ 
i 
sons, we get 
x = -  
+ k ,  
\ 
d 
I + Y  
Y \ 
i 
- 
+ k 
~
+
1
 
as claimed in the figure in the margin. Here k = 1x1 is the integral part 
l + y  
l + k ( y + l )  
of x, while & = {x} is the fractional part. And from this we obtain 
Thus we have obtained a beautiful formula for the successor f (x) of x, 
found very recently by Moshe Newman: 
The function 
1  
x  - 
f(x) = 
1x1 + 1  - 
generates the Calkin- Wilf sequence 
- 
' H L H P , l , h , 2 , 3 , 1 , 4 , . . .  
1 
2 
1 
3 
2 
3 
1 
4 
3 
which contains every positive rational number exactly once. 
0 - 
The Calkin-Wilf-Newman way to enumerate the positive rationals has a 
number of additional remarkable properties. For example, one may ask for 
1 - 
a fast way to determine the n-th fraction in the sequence, say for n = lo6. 
Here it is: 
To find the n-th fraction in the Calkin-Wilf sequence, express n as a 
binary number n = (bkbk-1 ... bl b0)2, and then follow the path in the 
Calkin-Wilf tree that is determined by its digits, starting at 
= !. 
Here bi = 1  means "take the right son," that is, "add the denominator 
- 
1 ci'h - 
3 
2 - 
3 - 
to the numerator," while b, = 0  means "take the left son," that is, "add 
the numerator to the denominator." 
1
4
3
5
2
5
3
4
The figure in the margin shows the resulting path for n = 25 = (11001)2: 
So the 25th number in the Calkin-Wilf sequence is g. The reader could 
easily work out a similar scheme that computes for a given fraction 
(the 
- Pi /\ i\ A A 
- 
7 i\ i\ /\ 
binary representation of) its position n in the Calkin-Wilf sequence. 
5 
- . '  
5 

98 
Sets. functions. and the continuum hv~othesis 
Let us move on to the real numbers R. Are they still countable? No, they 
are not, and the means by which this is shown - 
Cantor's diagonalization 
method - 
is not only of fundamental importance for all of set theory, but 
certainly belongs into The Book as a rare stroke of genius. 
Theorem 2. The set R o f  real numbers is not countable. 
Proof. Any subset N of a countable set M = { m l ,  r n 2 ,  m3, . . .) is at 
most countable (that is, finite or countable). In fact, just list the elements 
of N as they appear in M. Accordingly, if we can find a subset of R which 
is not countable, then a fortiori R cannot be countable. The subset M 
of R we want to look at is the interval (0, I ]  of all positive real numbers r 
with 0 < r < 1. Suppose, to the contrary, that M is countable, and let 
h.1 = { r l ,  737-3,. . .) be a listing of M. We write r, as its unique infinite 
decimal expansion without an infinite sequence of zeros at the end: 
where a,, 
E {0,1, . . . , 9 )  for all n and i. For example, 0.7 = 0.6999 ... 
Consider now the doubly infinite array 
For every n, choose b, E (1, . . . ,8) different from a,,; 
clearly this can be 
done. Then b = O.bl b2b 3...bn... is a real number in our set M and hence 
must have an index, say b = rk. But this cannot be, since bk is different 
from akk. And this is the whole proof! 
Let us stay with the real numbers for a moment. We note that all four 
types of intervals (0, l ) ,  (0,1], 
[O, 1) and [O, I ]  have the same size. As an 
example, we verify that ( O , l ]  and ( 0 , l )  have equal cardinality. The map 
f : (0,1] ---t (0, I), x  w y defined by 
I 
3 Z - x  for 
; < x < 1 ,  
\ 
3 ,-x 
for i < x < i ,  
y := 
s - x  
3 
for 
+ < z < $ .  
\ 
'. 
: .'- 
2, does the job. Indeed, the map is bijective, since the range of y in the first line 
0 
1 
i s ~ < y < l , i n t h e s e c o n d l i n e ~ < y < ~ , i n t h e t h i r d l i n e ~ < y
A bijective f : (0,1] + (0. 1) 
and SO on. 

Sets, functions, and the continuum hypothesis 
99 
Next we find that any two intervals (of finite length > 0) have equal size 
by considering the central projection as in the figure. Even more is true: 
Every interval (of length > 0) has the same size as the whole real line R. 
To see this, look at the bent open interval ( 0 , l )  and project it onto R from 
the center S. 
So, in conclusion, any open, half-open, closed (finite or infinite) interval of 
length > 0 has the same size, and we denote this size by c, where c stands 
for continuum (a name sometimes used for the interval [0,1]). 
That finite and infinite intervals have the same size may come expected on 
second thought, but here is a fact that is downright counter-intuitive. 
Theorem 3. The set R2 of all ordered pairs of real numbers (that is, the 
real plane) has the same size as R. 
Proof. To see this, it suffices to prove that the set of all pairs (x, y), 
0 < x. y 5 1, can be mapped bijectively onto (0.11. The proof is again 
from The Book. Consider the pair (x, y) and write x ,  y in their unique 
non-terminating decimal expansion as in the following example: 
Note that we have separated the digits of x and y into groups by always 
going to the next nonzero digit, inclusive. Now we associate to (x, y) the 
number z E (O,1] by writing down the first x-group, after that the first 
y-group, then the second x-group, and so on. Thus, in our example, we 
obtain 
z = 0.3 009 01 2 2 05 007 1 08 0008 . . . 
Since neither x nor y exhibits only zeros from a certain point on, we find 
that the expression for z is again a non-terminating decimal expansion. 
Conversely, from the expansion of z we can immediately read off the 
preimage (x, y), and the map is bijective - 
end of proof. 
0 
As (x, y) H x + iy is a bijection from R2 onto the complex numbers C, 
we conclude that I@/ = /RI = c. Why is the result IR2 1 = lRl so unex- 
pected? Because it goes against our intuition of dimension. It says that the 
2-dimensional plane R2 (and, in general, by induction, the n-dimensional 
space R'" can be mapped bijectively onto the 1-dimensional line R. Thus 
dimension is not generally preserved by bijective maps. If, however, we 
require the map and its inverse to be continuous, then the dimension is pre- 
served, as was first shown by Luitzen Brouwer. 
Let us go a little further. So far, we have the notion of equal size. When 
will we say that M is at most as large as N? Mappings provide again the 
key. We say that the cardinal number m is less than or equal to n, if for 
sets hf and N with lhfl = m , I NI = n, there exists an injection from M 
into N. Clearly, the relation m < n is independent of the representative 
sets hf and N chosen. For finite sets this corresponds again to our intuitive 
notion: An m-set is at most as large as an n-set if and only if m < n. 

100 
Sets, functions, and the continuum hypothesis 
Now we are faced with a basic problem. We would certainly like to have 
that the usual laws concerning inequalities also hold for cardinal numbers. 
But is this true for infinite cardinals? In particular, is it true that m < n, 
n 5 m imply m = n? This is not at all obvious: We are given infinite 
N 
sets hl and N as well as maps f : M - 
N and g : N - 
M that 
are injective but not necessarily surjective. This suggests to construct a 
bijection by relating some elements m E M to f (m) E N ,  and some 
elements n E N to g(n) E M. But it is not clear whether the many 
possible choices can be made to "fit together." 
The affirmative answer is provided by the famous Schroder-Bernstein 
theorem, which Cantor announced in 1883. The first proofs were given 
by Friedrich Schroder and Felix Bernstein quite some time later. The fol- 
lowing proof appears in a little book by one of the twentieth century giants 
of set theory, Paul Cohen, who is famous for resolving the continuum 
hypothesis (which we will discuss below). 
"Schriider and Bernstein painting " 
Theorem 4. If each of two sets M and N can be mapped injectively into 
the other; then there is a bijection from M to N, that is, 1 MI = IN I. 
H Proof. We may certainly assume that M and N are disjoint - 
if not, 
then we just replace N by a new copy. 
Now f and g map back and forth between the elements of M and those 
of N. One way to bring this potentially confusing situation into perfect 
clarity and order is to align M U N into chains of elements: Take an arbi- 
trary element mo E M, say, and from this generate a chain of elements by 
applying f ,  then g, then f again, then g, and so on. The chain may close up 
(this is Case 1) if we reach mo again in this process, or it may continue with 
distinct elements indefinitely. (The first "duplicate" in the chain cannot be 
an element different from mo, by injectivity.) 
If the chain continues indefinitely, then we try to follow it backwards: 
From mo to g-l (mo) if mo is in the image of g, then to f -' 
(g-l (mo)) 
if g-l(mo) 
is in the image of f ,  and so on. Three more cases may arise 
here: The process of following the chain backwards may go on indefinitely 

Sets, functions, and the continuum hypothesis 
101 
(Case 2), it may stop in an element of A l  that does not lie in the image of g 
(Case 3), or it may stop in an element of N that does not lie in the image 
o f f  (Case 4). 
Thus A1 u N splits perfectly into four types of chains, whose elements 
we may label in such a way that a bijection is simply given by putting 
F : rn, ti nl. We verify this in the four cases separately: 
Case 1. Finite cycles on 2k + 2 distinct elements ( k  > 0) 
Case 2. Two-way infinite chains of distinct elements 
Case 3. The one-way infinite chains of distinct elements that start at the 
ele~nents mo E AI\g(N) 
Case 4. The one-way infinite chains of distinct elements that start at the 
elements no E N\ f ( A l )  
What about the other relations governing inequalities? As usual, we set 
m < n if m 5 n, but m # n. We have just seen that for any two cardinals 
m and n at most one of the three possibilities 
holds, and it follows from the theory of cardinal numbers that, in fact, pre- 
cisely one relation is true. (See the appendix to this chapter, Proposition 2.) 
Furthermore, the Schroder-Bernstein Theorem tells us that the relation < is 
transitive, that is, m < n and n < p imply m < p. Thus the cardinalities 
are arranged in linear order starting with the finite cardinals 0 , 1 , 2 , 3 , .  . .. 
Invoking the usual Zermelo-Fraenkel axiom system (in particular, the ax- 
iom of choice) we easily find that any infinite set Al contains a countable 
subset. In fact, A1 contains an element, say ml. The set M \ {m,) is not 
empty (since it is infinite) and hence contains an element rn2. Consider- 
ing A1 \ {ml, m2) we infer the existence of m y ,  and so on. So, the size 
of a countable set is the smallest inJinite cardinal, usually denoted by N o  
(pronounced "aleph zero"). 
"The smallest injnite cardinal" 

102 
Sets, functions, and the continuum hypothesis 
As a corollary to N o  5 m for any infinite cardinal m, we can immediately 
prove "Hilbert's hotel" for any infinite cardinal number m, that is, we have 
With this we have also proved a result 
1 M U {x)/ = jMj for any infinite set M. Indeed, M contains a subset 
announced earlier: 
N = {ml, m2, ms, . . .}. Now map x onto ml, ml onto m2, and so on, 
Evev 
set has the same size as 
keeping the elements of M\N 
fixed. This gives the desired bijection. 
some proper subset. 
As another consequence of the Schroder-Bernstein theorem we may prove 
that the set P(N) of all subsets of N has cardinality c. As noted above, it 
suffices to show that IP(N)\{izr)l = I(O,l] 1. An example of an injective 
map is 
while 
defines an injection in the other direction. 
Up to now we know the cardinal numbers O,1,2, . . . , No, and further that 
the cardinality c of IR is bigger than No. The passage from Q with 1Q1 = No 
to R with lIRl = c immediately suggests the next question: 
Is c = (IR( the next injinite cardinal number after No? 
Now, of course, we have the problem whether there is a next larger cardinal 
number, or in other words, whether N 1  has a meaning at all. It does - 
the 
proof for this is outlined in the appendix to this chapter. 
The statement c = N 1  became known as the continuum hypothesis. The 
question whether the continuum hypothesis is true presented for many 
decades one of the supreme challenges in all of mathematics. The answer, 
finally given by Kurt Godel and Paul Cohen, takes us to the limit of 
logical thought. They showed that the statement c = N 1  is independent 
of the Zermelo-Fraenkel axiom system, in the same way as the parallel 
axiom is independent of the other axioms of Euclidian geometry. There are 
models where c = N 1  holds, and there are other models of set theory where 
c # N 1  holds. 
In the light of this fact it is quite interesting to ask whether there are other 
conditions (from analysis, say) which are equivalent to the continuum 
hypothesis. Indeed, it is natural to ask for an analysis example, since his- 
torically the first substantial applications of Cantor's set theory occurred in 
analysis, specifically in complex function theory. In the following we want 
to present one such instance and its extremely elegant and simple solution 
by Paul ErdBs. In 1962, Wetzel asked the following question: 
I 
Let {fa) be a family of pairwise distinct analytic functions on the 
complex numbers such that for each z E @ the set of values { f,(z)} 
is at most countable (that is, it is eitherJinite or countable); let us 
call this property (Po). 
Does it then follow that the family itself is at most countable? 

Sets, functions, and the continuum hypothesis 
103 
Very shortly afterwards Erdos showed that, surprisingly, the answer de- 
pends on the continuum hypothesis. 
Theorem 5. Ifc > N1, then every family {f,) 
satisfying (Po) 
is countable. 
on the other hand, c = N1, then there exists some family {f,) 
with 
proper& (Po) 
which has size c. 
For the proof we need some basic facts on cardinal and ordinal numbers. 
For readers who are unfamiliar with these concepts, this chapter has an 
appendix where all the necessary results are collected. 
Proof of Theorem 5. Assume first c > N1. We shall show that for any 
family { f,) of size N1 of analytic functions there exists a complex number 
zo such that all N1 values f,(zo) are distinct. Consequently, if a family of 
functions satisfies (Po), 
then it must be countable. 
To see this, we make use of our knowledge of ordinal numbers. First, we 
well-order the family {f,) 
according to the initial ordinal number wl of N1. 
This means by Proposition 1 of the appendix that the index set runs through 
all ordinal numbers a which are smaller than wl. Next we show that the 
set of pairs (a? 
p), a < /3 < wl, has size N1. Since any P < wl is a 
countable ordinal, the set of pairs (a, 
P), a < /?J , is countable for every 
fixed P. Taking the union over all N1-many P, 
we find from Proposition 6 
of the appendix that the set of all pairs (a, 
P), a < 0, 
has size N1. 
Consider now for any pair a < P the set 
We claim that each set S(a, 
p) is countable. To verify this, consider the 
disks Ck of radius k = 1,2,3,. . . around the origin in the complex plane. 
If f, and fp agree on infinitely many points in some Ck, then fa and fo 
are identical by a well-known result on analytic functions. Hence fa and fo 
agree only in finitely many points in each Ck, and hence in at most count- 
ably many points altogether. Now we set S := Ua,a S(a, 
p). Again by 
Proposition 6, we find that S has size N1, as each set S(a, 
P) is countable. 
And here is the punch line: Because, as we know, @ has size c, and c is 
larger than N1 by assumption, there exists a complex number zo not in S, 
and for this zo all N1 values f,(zo) are distinct. 
Next we assume c = N1. Consider the set D C C of complex numbers 
p + i q  with rational real and imaginary part. Since for each p the set 
{p + i q  : q E Q) 
is countable, we find that D is countable. Furthermore, 
D is a dense set in C: 
Every open disk in the complex plane contains some 
point of D. Let {z, : 0 < a < w1) be a well-ordering of C. We shall 
now construct a family {fp 
: 0 < P < wl) of N1-many distinct analytic 
functions such that 
fo(za) E D whenever a: < p. 
(1) 
Any such family satisfies the condition (Po). 
Indeed, each point z E C has 
some index, say z = z,. Now, for all p > a, 
the values {f4(z,)) 
lie in 

104 
Sets, functions, and the continuum hypothesis 
"A legend talks about St. Augustin who, 
walking along the seashore and contem- 
plating injinitj, saw a child trying to 
empty the ocean with a small shell.. ." 
the countable set D. Since a is a countable ordinal number, the functions 
f p  with /? 5 a will contribute at most countably further values fp(z,), so 
that the set of all values { fp(z,)) is likewise at most countable. Hence, if 
we can construct a family { f ~ )  
satisfying (I), then the second part of the 
theorem is proved. 
The construction of { fp) is by transfinite induction. For fo we may take 
any analytic function, for example fo = constant. Suppose f p  has already 
been constructed for all ,6 < y. Since y is a countable ordinal, we may 
reorder { f p  : 0 < p < y )  into a sequence gl, g2,g~,. 
. .. The same re- 
ordering of {z, : 0 < u < y )  yields a sequence wl, w z ,  
W Q ,  . . .. We shall 
now construct a function f ,  satisfying for each n the conditions 
The second condition will ensure that all functions f ,  (0 < y < w l )  are 
distinct, and the first condition is just (I), implying (Po) by our previous 
argument. Notice that the condition f,(w,) 
# gn(w,) is once more a 
diagonalization argument. 
To construct f,, we write 
If y is a finite ordinal, then f ,  is a polynomial and hence analytic, and we 
can certainly choose numbers ~i such that (2) is satisfied. Now suppose y 
is a countable ordinal, then 
Note that the values of E, (m > n) have no influence on the value f,(w,), 
hence we may choose the E, step by step. If the sequence (E,) 
converges 
to 0 sufficiently fast, then (3) defines an analytic function. Finally, since 
D is a dense set, we may choose this sequence (E,) 
SO that f ,  meets the 
requirements of (2), and the proof is complete. 
0 
Appendix: On cardinal and ordinal numbers 
Let us first discuss the question whether to each cardinal number there ex- 
ists a next larger one. As a start we show that to every cardinal number m 
there always is a cardinal number n larger than m. To do this we employ 
again a version of Cantor's diagonalization method. 
Let M be a set, then we claim that the set P ( M )  of all subsets of M has 
larger size than M .  By letting m E M correspond to { m )  E P ( M ) ,  
we see that M can be mapped bijectively onto a subset of P ( M ) ,  which 
implies IM < IP(M)I by definition. It remains to show that P ( M )  can 
not be mapped bijectively onto a subset of M .  Suppose, on the contrary, 

Sets, ,functions, and the continuum hypothesis 
105 
p : N - 
P(Af) is a bijection of N 
bl onto P ( M ) .  Consider the 
subset U C N of all elements of N which are not contained in their image 
under p, that is, U = { m  E N : m # p ( m ) ) .  Since p is a bijection, there 
exists u E N with ~ ( u )  
= U. Now, either u E U or u @ U ,  but both 
alternatives are impossible! Indeed, if u E U ,  then u # p ( u )  = U by the 
definition of U ,  and if 7~ # U = p(u), then u E U ,  contradiction. 
Most likely, the reader has seen this argument before. It is the old barber 
riddle: "A barber is the man who shaves all men who do not shave them- 
selves. Does the barber shave himself?" 
To get further in the theory we introduce another great concept of Cantor's, 
ordered sets and ordinal numbers. A set Af is ordered by < if the relation 
< is transitive, and if for any two distinct elements a and b of A4 we either 
have a < b or b < a. For example, we can order W in the usual way accord- 
ing to magnitude, N = {1,2,3.4. . . .), but, of course, we can also order N 
the other way round, W = {. . . .4.3.2,1), or N = {1,3,5, . . . ,2,4,6, . . .) 
by listing first the odd numbers and then the even numbers. 
Here is the seminal concept. An ordered set hf is called well-ordered if 
every nonempty subset of h I  has a first element. Thus the first and third 
orderings of N above are well-orderings, but not the second ordering. The 
fundamental well-ordering theorem, implied by the axioms (including the 
axiom of choice), now states that every set hf admits a well-ordering. From 
now on, we only consider sets endowed with a well-ordering. 
Let us say that two well-ordered sets A I  and N are similar (or of the same 
order-~pe) 
if there exists a bijection p from bI on N which respects the 
ordering, that is, m <,, 
n implies p ( m )  <,,, 
p(n). Note that any ordered 
set which is similar to a well-ordered set is itself well-ordered. 
Similarity is obviously an equivalence relation, and we can thus speak of 
an ordinal number cr: belonging to a class of similar sets. For finite sets, 
any two orderings are similar well-orderings, and we use again the ordinal 
number n for the class of n-sets. Note that, by definition, two similar sets 
have the same cardinality. Hence it makes sense to speak of the cardinality 
1 0 1  
of an ordinal number a. Note further that any subset of a well-ordered 
set is also well-ordered under the induced ordering. 
As we did for cardinal numbers, we now compare ordinal numbers. Let M 
be a well-ordered set, m E Af, then Afm = {x E hf : x < m) is called the 
(initial) segment of A 1  determined by m; N is a segment of AT if N = Mm 
for some m. Thus, in particular, hfm is the empty set when m is the first 
element of bf. Now let p and u be the ordinal numbers of the well-ordered 
sets hI and N. We say that p is smaller than v, p < u, if M is similar 
to a segment of N. Again, we have the transitive law that p < u, v < 7r 
implies p < T ,  since under a similarity mapping a segment is mapped onto 
a segment. 
The well-ordered sets N = {1,2,3, . . .} 
and N = {1,3,5 ,..., 2,4,6 ,...} are 
not similar: the first ordering has only 
one element without an immediate pre- 
decessor, while the second one has two. 
The ordinal number of {1,2,3,. . .) 
is smaller than the ordinal number of 
{1,3,5,. . . ,2.4,6.. . .}. 
Clearly, for finite sets, m < n corresponds to the usual meaning. Let 
us denote by w the ordinal number of N = {1,2,3,4, . . .) ordered ac- 
cording to magnitude. By considering the segment 
we find n < w 
for any finite n. Next we see that w 5 cr: holds for any infinite ordinal 

106 
Sets, functions, and the continuum hypothesis 
number a. Indeed, if the infinite well-ordered set M has ordinal num- 
ber a, then 11.1 contains a first element m l ,  the set M\{ml) contains a 
first element mz, M\{ml, m z )  contains a first element ms. Continuing 
in this way, we produce the sequence ml < m2 < ms < . . . in M .  If 
M = { m l ,  mz, ms, . . .), then M is similar to N, and hence a = w. If, 
on the other hand, M\{ml, m2,. . .) is nonempty, then it contains a first 
element m ,  and we conclude that N is similar to the segment Mm, that is, 
w < a by definition. 
We now state (without the proofs, which are not difficult) three basic re- 
sults on ordinal numbers. The first says that any ordinal number p has a 
"standard" representative well-ordered set W,. 
Proposition 1. Let p be an ordinal number and denote by W, the set of 
ordinal numbers smaller than p. Then the following holds: 
(i) The elements of W, are painvise comparable. 
(ii) I f  we order W, according to magnitude, then W, is well-ordered and 
has ordinal number p. 
Proposition 2. Any two ordinal numbers p and u satisfy precisely one of 
the relations p < u, p = u, or p > u. 
Proposition 3. Every set of ordinal numbers (ordered according to 
magnitude) is well-ordered. 
After this excursion to ordinal numbers we come back to cardinal num- 
bers. Let m be a cardinal number, and denote by 0, the set of all ordinal 
numbers p with 1p1 = m. By Proposition 3 there is a smallest ordinal 
number wm in Om, 
which we call the initial ordinal number of m. As an 
example, w is the initial ordinal number of No. 
With these preparations we can now prove a basic result for this chapter. 
Proposition 4. For every cardinal number m there is a definite next larger 
cardinal numbec 
Proof. We already know that there is some larger cardinal number n. 
Consider now the set K of all cardinal numbers larger than m and at most 
as large as n. We associate to each p E K its initial ordinal number wp. 
Among these initial numbers there is a smallest (Proposition 3), and the 
corresponding cardinal number is then the smallest in K, and thus is the 
desired next larger cardinal number to m. 
0 
Proposition 5. Let the infinite set M have cardinality m, and let M be 
well-ordered according to the initial ordinal number w,. Then M has no 
last element. 
Proof. Indeed, if M had a last element m ,  then the segment Mm would 
have an ordinal number p < wm with IpI = m, contradicting the definition 
of wm. 
0 

Sets, functions, and the continuum hypothesis 
107 
What we finally need is a considerable strenghthening of the result that the 
union of countably many countable sets is again countable. In the following 
result we consider arbitrary families of countable sets. 
Proposition 6. Suppose {A,) is a family of size m of countable sets A,, 
where m is an injinite cardinal. Then the union U A, has size at most m. 
a 
Proof. We may assume that the sets A, are pairwise disjoint, since this 
can only increase the size of the union. Let M with 1 M 1 = m be the index 
set, and well-order it according to the initial ordinal number w,. 
We now 
replace each cu E hf by a countable set B, = { b , ~  = a, b,~, b,3, . . .), 
ordered according to w ,  and call the new set M. Then % is again well- 
ordered by setting b,, 
< bg, for ai < P and b,, < b,, 
for 2 < j. Let 13i be 
the ordinal number of hl. Since h.1 is a subset of hl, we have p < ,!i 
by an 
- 
earlier argument. If p = I*., then AP is similar to hl, and if p < j!i, then M 
- 
is similar to a segment of Af. Now, since the ordering w,,, of M has no last 
element (Proposition 3, we see that hf is in both cases similar to the union 
of countable sets Bg, and hence of the same cardinality. 
The rest is easy. Let p : U Bp - 
hf be a bijection, and suppose that 
p(Bp) = {al, cuz, as,. . .}. Replace each a, by A,z and consider the 
union U A,%. Since U A," is the union of countably many countable sets 
(and hence countable), we see that Bo has the same size as U A,$. In 
other words, there is a bijection from Ba to U 
for all p, and hence 
a bijection + from U Bp to U A,. 
But now $P-' gives the desired 
bijection from M to U A,, and thus I U A, I = m. 
0 
References 
[I] L. E. J. BROUWER: 
Beweis der Invarianz der Dimensionszahl, Math. Annalen 
70 (1911), 161-165. 
[2] N. CALKIN 
& H. WILF: Recounting the rationals, Amer. Math. Monthly 107 
(2000), 360-363. 
[3] P. COHEN: Set Theory and the Continuum Hypothesis, W. A. Benjamin, New 
York 1966. 
[4] P. ERDBS: An interpolation problem associated with the continuum hypo- 
thesis, Michigan Math. J. 11 (1964), 9-10. 
[5] E. KAMKE: 
Theory of Sets, Dover Books 1950. 
[6] M. A. STERN: Ueber eine zahlentheoretische Funktion, Journal fiir die reine 
und angewandte Mathematik 55 (1858), 193-220. 

In praise of inequalities 
Analysis abounds with inequalities, as witnessed for example by the famous 
book "Inequalities" by Hardy, Littlewood and P6lya. Let us single out two 
of the most basic inequalities with two applications each, and let us listen 
in to George Pdya, who was himself a champion of the Book Proof, about 
what he considers the most appropriate proofs. 
Our first inequality is variously attributed to Cauchy, Schwarz andlor to 
Buniakowski: 
Theorem I (Cauchy-Schwarz inequality) 
Let ( a .  b) be an inner product on a real vector space V (with the norm 
aI2 := ( a ,  a)). Then 
( a .  b)' I la121b12 
holds for all vectors a .  b E V ,  with equality if and only if a and b are 
linearly dependent. 
Proof. The following (folklore) proof is probably the shortest. Consider 
the quadratic function 
(xa + bI2 = x21a12 + 2x(a, b) + Ibl" 
in the variable x. We may assume a # 0. If b = Xa, then clearly 
( a ,  b)2 = la121b12. If, on the other hand, a and b are linearly independent, 
then Ixa + bI2 > 0 for all x, and thus the discriminant (a, b)2 - laI2 1 bI2 is 
less than 0. 
0 
Our second example is the inequality of the harmonic, geometric and 
arithmetic mean: 
Theorem I1 (Harmonic, geometric and arithmetic mean) 
Let a1 , . . . , a, be positive real numbers, then 
with equality in both cases if and only if all ai 's are equal. 
Proof. The following beautiful non-standard induction proof is attributed 
to Cauchy (see [7]). Let P(n) be the statement of the second inequality, 
written in the form 
Chapter 17 

110 
In praise of ine~ualities 
For n = 2, we have ala2 5 (%jQ)2 
(a1 - ~
2
)
~
 
> 0, which is true. 
Now we proceed in the following two steps: 
(A) P(n) + 
P(n - 1 )  
(B) P(n) and P(2) + P(2n) 
which will clearly imply the full result. 
n-l 
To prove (A), set A := C 5, 
then 
k = l  
n-1 
n-1 
n - l  
andhence 
a, 5 . ; - l  = (El") 
k=l 
n - 1  
For (B), we see 
The condition for equality is derived just as easily. 
The left-hand inequality, between the harmonic and the geometric mean, 
follows now by considering &, . . . , &. 
0 
Another Proof. Of the many other proofs of the arithmetic-geometric 
mean inequality (the monograph [2] lists more than 50), let us single out a 
particularly striking one by Alzer which is of recent date. As a matter of 
fact, this proof yields the stronger inequality 
for any positive numbers a1 , . . . , a,, pl , . . . , p, with C:=l pi = 1. Let us 
denote the expression on the left side by G, and on the right side by A. We 
may assume al 5 . . . 5 a,. Clearly al 5 G 5 a,, so there must exist 
some k with ak 5 G 5 ak+l. It follows that 
since all integrands are 2 0. Rewriting (1) we obtain 

In praise of inequalities 
1 1 1  
where the left-hand side equals 
while the right-hand side is 
We conclude 6 
- 1 2 0, which is A 2 G. In the case of equality, all 
integrals in (I) must be 0, which implies a1 = . . . = an = G. 
0 
Our first application is a beautiful result of Laguerre (see 171) concerning 
the location of roots of polynomials. 
Theorem 1. Suppose all roots of the polynomial xn +an- lxn-l + . . . +ao 
are real. Then the roots are contained in the interval with the endpoints 
Proof. Let y be one of the roots and yl, . . . , yn-1 the others. Then 
the polynomial is ( x  - y ) ( x  - y l )  . . . (x - yn-1). Thus by comparing 
coefficients 
and so 
n-1 
By Cauchy's inequality applied to ( y l ,  . . . , yn-1) and (1,. . . , l), 
Thus y (and hence all y,) lie between the two roots of the quadratic function, 
and these roots are our bounds. 
0 
For our second application we start from a well-known elementary property 
of a parabola. Consider the parabola described by f (z) = 1 - x2 between 
x = -1 and x = 1. We associate to f (z) the tangential triangle and the 
tangential rectangle as in the figure. 

112 
In praise of inequalities 
Mathematical Reviews 
$0, &..lo 
5 
J..L*I,. 
I.,. 
py. ,.I> 
-.a*-- *- 
*- . --m. 
>, ., *----?a 
A- 
Bnlh. P. and Grkwald, T. On p l m o d a b  with only d 
roots. Ann. of Math. 40, 537-548 (1939). [MF 933 
Es 6 
f(z) ein Polynm mit nur m l k n  Wurzeln. 
1(-1)=f(I)=O, 
o < l ( x ~ z l b ~  f " ~  
-1<z<I, 
vobd -1 <*<I, so dasp r die Stelle des Maximums w n  
I(=) im Intervall (-1, I) Weutet. Dann irt 
We find that the shaded area A = J'1, (1 -x2)dz is equal to $, and the areas 
T and R of the triangle and rectangle are both equal to 2. Thus 5 = % 
and R - 3 
A - 2 '  
In a beautiful paper, Paul Erdds and Tibor Gallai asked what happens 
when f ( x )  is an arbitrary n-th degree real polynomial with f ( x )  > 0 for 
1 
-1 < z < 1, and f (-1) = f (1) = 0. The area A is then J-, f (x)dx. Sup- 
pose that f ( x )  assumes in (-1,l) its maximum value at b, then R = 2 f (b). 
Computing the tangents at -1 and at 1, it is readily seen (see the box) 
that 
respectively T = 0 for f l ( l )  = fl(-1) = 0. 
The tangential triangle 
The area T of the tangential triangle is precisely yo, where (xo, yo) 
is the point of intersection of the two tangents. The equation of these 
tangents are y = f I(-l)(x + 1 )  and y = f ' ( l ) ( x  - I), hence 
I and thus 
In general, there are no nontrivial bounds for 5 and 2. To see this, take 
f ( x )  = 1 - x2". Then T = 2n, A = &, 
and thus 5 > n. Similarly, 
R = 2 and 2 = y, 
which approaches 1 with n to infinity. 
But, as Erdiis and Gallai showed, for polynomials which have only real 
roots such bounds do indeed exist. 
Theorem 2. Let f ( x )  be a real polynomial of degree n > 2 with only real 
roots, such that f ( x )  > 0 for -1 < x < 1 and f (-1) = f (1) = 0. Then 
and equality holds in both cases only for n = 2. 
Erdiis and Gallai established this result with an intricate induction proof. 
In the review of their paper, which appeared on the first page of the first 
issue of the Mathematical Reviews in 1940, George P6lya explained how 
the first inequality can also be proved by the inequality of the arithmetic 
and geometric mean - 
a beautiful example of a conscientious review and 
a Book Proof at the same time. 

In praise of inequalities 
113 
Proof of $T 5 A. Since f  ( x )  has only real roots, and none of them in 
the open interval (- 1 ,  I ) ,  it can be written - 
apart from a constant positive 
factor which cancels out in the end - 
in the form 
with a, > 1 ,  pj > 1. Hence 
By making the substitution x  - 
- x ,  we find that also 
and hence by the inequality of the arithmetic and the geometric mean (note 
that all factors are > 0) 
Let us compute f l ( l )  and f l ( - 1 ) .  (We may assume f l ( - 1 ) ,  f l ( l )  # 0, 
since otherwise T = 0 and the inequality $T 5 A becomes trivial.) By (3) 
we see 
and similarly 
Hence we conclude 

114 
In praise o f  ine~ualities 
Applying now the inequality of the harmonic and the geometric mean 
to - f ' ( 1 )  and f l ( l ) ,  we arrive by (2) at the conclusion 
which is what we wanted to show. By analyzing the case of equality in 
all our inequalities the reader can easily supply the last statement of the 
theorem. 
0 
The reader is invited to search for an equally inspired proof of the second 
inequality in Theorem 2. 
Well, analysis is inequalities after all, but here is an example from graph 
theory where the use of inequalities comes in quite unexpected. In Chap- 
ter 32 we will discuss Tur6n's theorem. In the simplest case it takes on the 
following form: 
Theorem 3. Suppose G is a graph on n vertices without triangles. Then G 
has at most $ edges, and equality holds only when n is even and G is the 
complete bipartite graph K,/2,,/2. 
First proof. This proof, using Cauchy's inequality, is due to Mantel. Let 
V = ( 1 , .  . . , n )  be the vertex set and E the edge set of G. By di we denote 
the degree of i, hence CiEV 
dt = 21EI (see page 143 in the chapter on 
double counting). Suppose ij is an edge. Since G has no triangles, we find 
di + d j  5 n since no vertex is a neighbor of both i and j. 
and hence with Cauchy's inequality applied to the vectors ( d l ,  . . . , d,) and 
( I , .  . . , I ) ,  
and the result follows. In the case of equality we find di = d j  for all 
i, j, and further di = 
(since di + d j  = n). Since G is triangle-free, 
G = Kn/2,n/2 
is immediately seen from this. 
0 

In praise of inequalities 
115 
Second proof. The following proof of Theorem 3, using the inequality 
of the arithmetic and the geometric mean, is a folklore Book Proof. Let a: 
be the size of a largest independent set A, and set P = n - a:. Since G is 
triangle-free, the neighbors of a vertex i form an independent set, and we 
infer di < a: for all i. 
of G according to their endvertices in B, we obtain I El 5 xiEB 
di. The 
The set B = V\A of size P meets every edge of G. Counting the edges , 
, 
di 
inequality of the arithmetic and geometric mean now yields 
and again the case of equality is easily dealt with. 
References 
[I] H. ALZER: A proof of the arithmetic mean-geometric mean inequality, Amer. 
Math. Monthly 103 (1996), 585. 
[2] P. S. BULLEN, 
D. S. MITRINOVICS 
& P. M. VASIC: Means and their In- 
equalities, Reidel, Dordrecht 1988. 
[3] P. E R D ~  
& T. GRUNWALD: 
On polynomials with only real roots, Annals 
Math. 40 (1939), 537-548. 
(41 G. H. HARDY, J. E. LITTLEWOOD 
& G. POLYA: Inequalities, Cambridge 
University Press, Cambridge 1952. 
[5] W. MANTEL: 
Problem 28, Wiskundige Opgaven 10 (1906), 60-61. 
[6] G. POLYA: Review of [3], Mathematical Reviews 1 (1940), 1. 
[7] G. POLYA & G. S Z E G ~ :  
Problems and Theorems in Analysis, Vol. I, Springer- 
Verlag, Berlin Heidelberg New York 1972178; Reprint 1998. 

A theorem of Polya on polynomials 
Chapter 18 
Among the many contributions of George Pdlya to analysis, the following 
has always been Erdiis' favorite, both for the surprising result and for the 
beauty of its proof. Suppose that 
is a complex polynomial of degree n > 1 with leading coefficient 1. Asso- 
ciate with f ( z )  the set 
c := { z  E C :  
If(z)l< 21, 
that is, C is the set of points which are mapped under f into the circle of 
radius 2 around the origin in the complex plane. So for n = 1 the domain C 
is just a circular disk of diameter 4. 
I3y an astoundingly simple argument, Pdlya revealed the following beauti- 
ful property of this set C: 
Take any line L in the complex plane and consider the orthogonal 
projection CL o f  the set C onto L. Then the total length of an-y such 
projection never exceeds 4. 
What do we mean by the total length of the projection CL being at most 4? 
We will see that CL is a finite union of disjoint intervals 11, . . . , It, and the 
condition means that !(Il) + . . . + [(I,) 5 4 , where [ ( I j )  is the usual 
length of an interval. 
Ely rotating the plane we see that it suffices to consider the case when L is 
the real axis of the complex plane. With these comments in mind, let us 
state Pdlya's result. 
Theorem 1. Let f ( z )  be a complex polynomial of degree at least I 
and 
leading coeflcient 1. Set C = { z  E C : I f  (z)l < 2 )  and let R be the 
orthogonal projection of C onto the real axis. Then there are intervals 
ll.. . . , It on the real line which together cover R and satisfl 
George Polya 
e ( h )  + . . . + [(It) 5 4. 
Clearly the bound of 4 in the theorem is attained for n = 1. To get more 
of a feeling for the problem let us look at the polynomial f ( z )  = z2 - 2, 
which also attains the bound of 4. If z  = x + i y  is a complex number, then 
.r is its orthogonal projection onto the real line. Hence 
R = {x E R : x + i y  E C for some y). 

118 
A theorem of Pdlya on polynomials 
and hence lx - ak I 5 lz - ck I for all k, that is, 
Pavnuty Chebyshev on a Soviet stamp 
from 1946 
The reader can easily prove that for f (z) = z2 - 2 we have x + iy E C if 
and only if 
(22 + y2)2 5 4(x2 - g2). 
It follows that x4 5 (x2 + y2)2 5 4x2, and thus x2 I 4, that is, 1x1 5 2. 
On the other hand, any z = x E R with 1x1 I 2 satisfies lz2 - 21 _< 2, and 
we find that R is precisely the interval [-2,2] of length 4. 
As a first step towards the proof write f ( z )  = (2-q) . . . (z-c,) 
with ck = 
arc + ibk, and consider the real polynomialp(x) = (x - a l )  . . . (x - a,). 
Let z = x + iy E C, then by the theorem of Pythagoras 
Thus we find that R is contained in the set P = {x E R : Ip(x)l 5 2), 
and if we can show that this latter set is covered by intervals of total length 
at most 4, then we are done. Accordingly, our main Theorem 1 will be a 
consequence of the following result. 
Theorem 2. Let p(x) be a real polynomial of degree n 2 1 with leading 
coeficient 1, and all roots real. Then the set P = {x E R : (p(x) ( 5 2) 
can be covered by intervals of total length at most 4. 
As P6lya shows in his paper [2], Theorem 2 is, in turn, a consequence 
of the following famous result due to Chebyshev. To make this chapter 
self-contained, we have included a proof in the appendix (following the 
beautiful exposition by P6lya and Szegii). 
Chebyshev's Theorem. 
Let p(x) be a real polynomial of degree n > 1 with leading coeficient 1. 
Then 
Let us first note the following immediate consequence. 
Corollary. Let p(x) be a real polynomial of degree n 2 1 with leading 
coeficient 1, and suppose that Jp(x)J 5 2 for all x in the interval [a, b]. 
Then b - a 5 4. 
H Proof. Consider the substitution y = &(x - a) - 1. This maps the 
2-interval [a, b] onto the y-interval [-I, 11. The corresponding polynomial 
4(y) = P ( ~ ( Y  
+ 1) + a) 
has leading coefficient (%)" 
and satisfies 

A theorem of Pdlva on uolvnomials 
119 
By Chebyshev's theorem we deduce 
b-a 
n 
1 
- 
b-a 
n 
2 > 1nax Ip(x)l > 
- 2(F& 
1 
a < x i b  
and thus b - a 5 4, as desired. 
0 
This corollary brings us already very close to the statement of Theorem 2. 
l-y/i, ; q = 3 . 2 0  - 
If the set P = { x  : Ip(x)/ 
2) is an interval, then the length of P is 
at most 4. The set p may, however, not be an interval, as in the example 
depicted here, where P consists of two intervals. 
What can we say about P? Since p(x) is a continuous function, we know 
at any rate that P is the union of disjoint closed intervals 1 1 ,  1 2 ,  . . ., and 
that p(x) assumes the value 2 or -2 at each endpoint of an interval I,. This 
implies that there are only finitely many intervals Ill . . . , It, since p(x) can 
assume any value only finitely often. 
For the polynomial p ( z )  = x2(x - 3) 
Pblya's wonderful idea was to construct another polynomial#(x) of degree 
we get 'P = [I-&, 1]~[1+&, = 33.1 
n, again with leading coefficient 1, such that p = { x  : I@(s)l < 2) is an 
interval of length at least [(I1) + . . . + [(It). The corollary then proves 
4(11) + . . . + [(It) < e(p) 5 4, and we are done. 
W Proof of Theorem 2. 
Consider p(x) = ( x  - al) . . . ( x  - a,) with 
P = { x  E R : lp(x) 
I < 2) = Il U . . . U It, where we arrange the intervals 
I, such that Il is the leftmost and It the rightmost interval. First we claim 
that any interval I, contains a root of p(x). We know that p(x) assumes the 
values 2 or -2 at the endpoints of I,. If one value is 2 and the other -2, 
then there is certainly a root in I,. So assume p(x) = 2 at both endpoints 
(the case -2 being analogous). Suppose b E I, is a point where p(x) 
assumes its minimum in I,. Then pl(b) = 0 and pll(b) 2 0. If pl'(b) = 0, 
then b is a multiple root of pl(x), and hence a root of p(x) by Fact 1 from 
the box on the next page. If, on the other hand, ~ " ( b )  
> 0, then we deduce 
p(b) < 0 from Fact 2 from the same box. Hence either p(b) = 0, and we 
have our root, or p(b) < 0, and we obtain a root in the interval from b to 
either endpoint of I, . 
Here is the final idea of the proof. Let 11, . . . , It be the intervals as before, 
and suppose the rightmost interval It contains m roots of p(x), counted 
with their multiplicities. If m = n, then It is the only interval (by what 
we just proved), and we are finished. So assume m < n, and let d be 
the distance between It-l and It as in the figure. Let bl, . . . , b, be the 
d 
roots of p(x) which lie in It and el, . . . en-, the remaining roots. We now 
. . .  
A 
write p(x) = q(x)r(x) where q(x) = ( z  - bl ) . . . ( x  - b,) 
and r ( x )  = 
I1 
I2 ' ' ' 
It-1 
It 
(.c - el) . . . ( x  - en-,), 
and set pl (x) = q(x + d)r(x). The polynomial 
pl ( x )  is again of degree n with leading coefficient 1. For x E I1 U .  . . UIt-1 
wehave Ix+d - b,l < 1x- biI foralli,andhencelq(x+d)I < Iq(x)l. It 
follows that 
lpl(x)l < lp(x)l I 
2 
for x E I1 U . . . U It-1. 
If, on the other hand, x E It, then we find Ir(x - d)i < Ir(x) 
1 and thus 
lp1(x - d)l = Iq(x)llr(x - d)l 5 Ip(x)l I 21 

120 
A theorem of Po'lya on polynomials 
which means that It - d c Pl = { x  : Ipl ( x )  
1 L 2 ) .  
In summary, we see that P1 contains Il U . . . U It_l U (It - d )  and hence has 
total length at least as large as P. Notice now that with the passage from 
p(x) to pl(x) the intervals 2;-1 and It - d merge into a single interval. 
We conclude that the intervals J1, . . . , J, of pl (z) making up Pl have total 
length at least e(I1) +. . . +e(It), and that the rightmost interval J, contains 
more than m roots of pl (x). Repeating this procedure at most t - 1 times, 
we finally arrive at a polynomial p(x) with 
= { x  : /$(x)I < 2 )  being an 
interval of length e(F) >. [(Il)+. . . [(I,), and the proof is complete. 
Two facts about polynomials with real roots 
Let p(x) be a non-constant polynomial with only real roots. 
Fact 1. Ifb is a multiple root of pl(x), then b is also a root of p(x). 
Proof. Let bl, . . . , b, be the roots of p(x) with multiplicities 
s1, . . . , s,, z;=l sj = n. From p(x) = ( x  - bj)S3 h(x) we infer 
that bj is a root of pl(x) if sj > 2, and the multiplicity of bj in pl(x) 
is sj - 1. Furthermore, there is a root of p'(x) between bl and b2, 
another root between b2 and bg, . . . , and one between b,-1 and b,, 
and all these roots must be single roots, since X,'=l (sj - 1) + (r - 1) 
counts already up to the degree n - 1 of pl(x). Consequently, the 
multiple roots of pl(x) can only occur among the roots of p(x). 
Fact 2. We have pl(x)' 2 p(x)p1I(x) for all x E R. 
Proof. If x = ai is a root of p(x), then there is nothing to show. 
Assume then x is not a root. The product rule of differentiation yields 
Differentiating this again we have 

A theorem o f  Pdlva on uolvnomials 
121 
Appendix: Chebyshev's theorem 
h 
Theorem. Let p(x) be a real polynomial of degree n > 1 with leading 
coeficient 1. Then 
1 
max Ip(x)l 2 3. 
-1<.<1 
Before we start, let us look at some examples where we have equality. The 
margin depicts the graphs of polynomials of degrees 1, 2 and 3, where we 
have equality in each case. Indeed, we will see that for every degree there 
is precisely one polynomial with equality in Chebyshev's theorem. 
Proof. Consider a real polynomial p(x) = xn + a,-lxn-' 
+ . . . + a 0  
with leading coefficient 1. Since we are interested in the range - 1 < x < 1, 
we set x = cos 8 and denote by g(9) := p(cos 29) the resulting polynomial 
The polynomials pl(x) = x, pz(x) = 
x2 - and p3(x) = x3 - :x achieve 
in cos 8, 
equality in Chebyshev's theorem. 
g(8) = (cost9)" + a,-l(cosd)n-l + . . . + ao. 
(1) 
The proof proceeds now in the following two steps which are both classical 
results and interesting in their own right. 
(A) We express g ( 6 )  as a so-called cosine polynomial, that is, a polynomial 
of the form 
g(B) = b, cos nd + b,-1 cos(n - l ) d  + . . . + bl cos 29 + bo 
(2) 
with bk E R, and show that its leading coefficient is b, = A. 
(B) Given any cosine polynomial h(6) of order n (meaning that A, is the 
highest nonvanishing coefficient) 
h(t9) = A, cosnd + A,-1 
cos(n - 1)t9 + . . . + Ao, 
(3) 
we show I A, I < max 1 h(t9) 1, which when applied to g(d) will then prove 
the theorem. 
Proof of (A). To pass from (1) to the representation (2), we have to ex- 
press all powers (cos 1 9 ) ~  as cosine polynomials. For example, the addition 
theorem for the cosine gives 
so that cos2 29 = i cos 2t9 + i. To do this for an arbitrary power (cos t9)k 
we go into the complex numbers, via the relation em = cos x + i sinx. 
The em are the complex numbers of absolute value 1 (see the box on com- 
plex unit roots on page 25). In particular, this yields 
ein29 = cos nd + i sin nd. 
(4) 
On the other hand, 

122 
A theorem of Pdlya on polynomials 
Equating the real parts in (4) and (5) we obtain by i4"' 
= - 1, i4e = 1 and 
sin2 19 = 1 - cos2 0 
We conclude that cos n6 is a polynomial in cos 6 ,  
cos n 6  = c,(cos 
+ cnPl (cos t9)n-1 + . . . + co. 
(7) 
From (6) we obtain for the highest coefficient 
Ck." (g) 
= 2n-1 holds for n > 0: 
Every subset of {1,2, . . . , n - I) yields 
cn = 
(:) +g 
( 4 t ~ 2 )  = 2n-1' 
an even sized subset of { l , 2 ,  . . . , n) if 
we add the element n "if needed." 
Now we turn our argument around. Assuming by induction that for k < n ,  
(cos 8)'" can be expressed as a cosine polynomial of order Ic, we infer from 
(7) that (cos6)" can be written as a cosine polynomial of order n with 
1 
leading coefficient b, = m. 
Proof of (B). Let h ( 6 )  be a cosine polynomial of order n as in (3), and 
assume without loss of generality A, > 0. Now we set m(79) := A, cos 7279 
and find 
m
)
 
= ( - l ) k X n  
for k = 0 , 1 , .  . . ,n. 
Suppose, for a proof by contradiction, that max 1 h ( 6 )  
1 < A,. 
Then 
is positive for even k and negative for odd k in the range O < k < n. We 
conclude that m ( d )  - h(d) has at least n roots in the interval [0, T ] .  But 
this cannot be since m(6) - h ( 6 )  is a cosine polynomial of order n - 1, 
which can be written in the form (1) and thus has at most n - 1 roots. 
The proof of (B) and thus of Chebyshev's theorem is complete. 
0 
The reader can now easily complete the analysis, showing that g,(6) := 
& cos n6 is the only cosine polynomial of order n with leading coeffi- 
cient 1 that achieves the equality max lg(79) I = &. 
The polynomials T,(x) = cosnd, x = cosd, are called the Chebyshev 
polynomials (of the first kind); thus &T,(x) 
is the unique monic poly- 
nomial of degree n where equality holds in Chebyshev's theorem. 
References 
P. L. CEBYCEV: 
Euvres, Vol. I, Acad. Imperiale des Sciences, St. Peters- 
burg 1899, pp. 387-469. 
G. POLYA: 
Beitrag zur Verallgemeinerung des Verzerrungssatzes auf mehgach 
zusamrnenhiingenden Gebieten, Sitzungsber. Preuss. Akad. Wiss. Berlin 
(1 928), 228-232; Collected Papers Vol. I, MIT Press 1974, 347-35 1. 
G. P ~ L Y A  
& G. SZEGO: Problems and Theorems in Analysis, Vol. II, Springer- 
Verlag, Berlin Heidelberg New York 1976; Reprint 1998. 

On a lemma 
Chapter 19 
of Littlewood and Offord 
In their work on the distribution of roots of algebraic equations, Littlewood 
and Offord proved in 1943 the following result: 
Let C A I ,  a2, . . . . a, be complex numbers with la, 1 > 1 for all i, and 
consider the 2" linear combinations x:=l &,a, with E, E (1, -1). 
Then the number of sums C:=l &,a, which lie in the interior of any 
circle of radius 1 is not greater than 
c 5 log n for some constant c > 0. 
fi 
A few years later Paul Erdiis improved this bound by removing the log n 
term, but what is more interesting, he showed that this is, in fact, a simple 
consequence of the theorem of Sperner (see page 15 1). 
To get a feeling for his argument, let us look at the case when all ai are 
real. We may assume that all ai are positive (by changing ai to -ai and ci 
to - ~ i  
whenever ai < 0). Now suppose that a set of combinations x Eiai 
lies in the interior of an interval of length 2. Let N = { 1 , 2 ,  . . . , n )  be the 
index set. For every 
Eiai we set I := (1: E N : E ,  = 1). Now if I 5 I' 
for two such sets, then we conclude that 
which is a contradiction. Hence the sets I form an antichain, and we 
Sperner's theorem. Any antichain of 
conclude from the theorem of Sperner that there are at most (ln72,) such 
subsets qf an n-set has size at most 
combinations. By Stirling's formula (see page I I )  we have 
( &, ). 
For n even and all a, = 1 we obtain (n72) combinations x:=l &,a, that 
sum to 0. Looking at the interval (-1.1) we thus find that the binomial 
number gives the e.xact bound. 
In the same paper Erdiis conjectured that ( l n ; 2 J )  was the right bound for 
complex numbers as well (he could only prove c2nn-1/2 for some c) and 
indeed that the same bound is valid for vectors al. . . . . a, with lazl > 1 in 
a real Hilbert space, when the circle of radius 1 is replaced by an open ball 
of radius 1. 

124 
On a lemma of Littlewood and Offord 
Erdiis was right, but it took twenty years until Gyula Katona and Daniel 
Kleitman independently came up with a proof for the complex numbers 
(or, what is the same, for the plane R2). Their proofs used explicitly the 
2-dimensionality of the plane, and it was not at all clear how they could be 
extended to cover finite dimensional real vector spaces. 
But then in 1970 Kleitman proved the full conjecture on Hilbert spaces 
with an argument of stunning simplicity. In fact, he proved even more. His 
argument is a prime example of what you can do when you find the right 
induction hypothesis. 
A word of comfort for all readers who are not familiar with the notion of 
a Hilbert space: We do not really need general Hilbert spaces. Since we 
only deal with finitely many vectors ai, it is enough to consider the real 
space Rd with the usual scalar product. Here is Kleitman's result. 
Theorem. 
Let a l , .  . . , a ,  be vectors in JRd, each of length 
at least 1, and let R1,. . . , Rk be k open regions of IRd, where 
Ix - yl < 2 for any x, y that lie in the same region Ri. 
Then the number of linear combinations xy=, &iai, ~i E ( 1 ,  -11, 
that can lie in the union Ui 
Ri of the regions is at most the sum of 
the k largest binomial coejicients ( y) . 
In particular; we get the bound (i$2,) for k = 1. 
Before turning to the proof note that the bound is exact for 
Indeed, for even n we obtain (ny2) sums equal to 0, 
sums equal to 
(-2)a, (,/k,) sums equal to 2a, and so on. Choosing balls of radius 1 
around 
we obtain 
sums lying in these k balls, and this is our promised expression, since the 
largest binomial coefficients are centered around the middle (see page 12). 
A similar reasoning works when n is odd. 
Proof. We may assume, without loss of generality, that the regions Ri 
are disjoint, and will do so from now on. The key to the proof is the recur- 
sion of the binomial coefficients, which tells us how the largest binomial 
coefficients of n and n - 1 are related. Set r = 1-1, 
s = 1-1, 
then (:), 
( T ; l ) ,  . . . , (:) 
are the k largest binomial coefficients for n. The 
recursion (I) = ("il) 
+ 
implies 

On a lemma of Littlewood and Offord 
125 
and an easy calculation shows that the first sum adds the k + 1 largest 
binomial coefficients 
and the second sum the largest k - 1. 
Kleitman's proof proceeds by induction on n, the case n = 1 being trivial. 
In the light of (1) we need only show for the induction step that the linear 
combinations of al, . . . , a, that lie in k disjoint regions can be mapped 
bijectively onto combinations of al, . . . , a,-1 that lie in k + 1 or k - 1 
regions. 
Claim. At least one of the translated regions Rj - a, is disjoint 
from all the translated regions R1 + a,, . . . , RI, + a,. 
To prove this, consider the hyperplane H = {x : (a,, x) = c} orthogonal 
to a,, which contains all translates R, + a, on the side that is given by 
(a,, x) > c, and which touches the closure of some region, say Rj + a,. 
Such a hyperplane exists since the regions are bounded. Now lx - yl < 2 
holds for any x E R, and y in the closure of Rj, since R, is open. We want 
to show that Rj - a, lies on the other side of H. Suppose, on the contrary, 
that (a,. x - a,) > c for some x E Rj, that is, (a,, x )  > la,I2 + c. 
Let y + a, be a point where H touches Rj + a,, then y is in the closure 
of R3, and (a,, y + a,) = c, that is, (a,, -y) = la,I2 - C. Hence 
and we infer from the Cauchy-Schwarz inequality 
and thus (with lan I > 1) we get 2 5 21a, 1 5 lx - y 1, a contradiction. 
The rest is easy. We classify the combinations 
Eiai which come to lie in 
R1 U . . . U Rk as follows. Into Class 1 we put all Cr=l Eiai with E~ = -1 
and all xy="=,Eiai 
with E ,  = 1 lying in Rj, and into Class 2 we throw 
in the remaining combinations Cy=l Eiai with E ,  = 1, not in R,. 
It 
follows that the combinations ~yct 
E,ai corresponding to Class 1 lie in 
the k + 1 disjoint regions R1 + a,, . . . , RI, + a, and Rj - a,, and the 
combinations ~7:: Ezai corresponding to Class 2 lie in the k - 1 disjoint 
regions R1 - a,, . . . , Rk - a, without Rj - a,. By induction, Class 1 con- 
tains at most ~ ~ = r p l  
(,;') 
combinations, while Class 2 contains at most 
(lL;') combinations - 
and by (1) this is the whole proof, straight 
from The Book. 
0 

126 
On a lemma ofLittlewood and Offord 
References 
[ I ]  P. ERDBS: On a lemma of Littlewood and Offord, Bulletin Amer. Math. Soc. 
51 (1945), 898-902. 
[2] G. KATONA: On a conjecture of Erd6s and u stronger form of Spemer's 
theorem, Studia Sci. Math. Hungar. 1 (1966), 59-63. 
[3] D. KLEITMAN: On a lemma of Littlewood and Offord on the distribution of 
certain sums, Math. Zeitschrift 90 (1965), 251 -259. 
[4] D. KLEITMAN: On a lemma of Littlewood and Offord on the distributions of 
linear combinations of vectors, Advances Math. 5 (1970). 155-157. 
[5] J. E. LITTLEWOOD 
& A. C. OFFORD: On the number of real roots of a 
random algebraic equation 111, Mat. USSR Sb. 12 (1943), 277-285. 

Cotangent and the Herglotz trick 
Chapter 20 
What is the most interesting formula involving elementary functions? In 
his beautiful article [2], whose exposition we closely follow, Jiirgen Elstrodt 
nominates as a first candidate the partial fraction expansion of the cotangent 
function: 
This elegant formula was proved by Euler in $178 of his Introductio in 
Analysin Infinitorurn from 1748 and it certainly counts among his finest 
achievements. We can also write it even more elegantly as 
N 
1 
 cot TX = 
lim C - 
N-9z 
(1) 
n=-N 
+ 
but one has to note that the evaluation of the sum znEZ 
is a bit 
dangerous, since the sum is only conditionally convergent, so its value I 
depends on the "right" order of summation. 
I 
We shall derive (1) by an argument of stunning simplicity which is 
Gustav Herglotz 
attributed to Gustav Herglotz - 
the "Herglotz trick." To get started, set 
N 
and let us try to derive enough common properties of these functions to see 
in the end that they must coincide.. . 
(A) 
The functions f and g are defined for all non-integral values and are 
continuous there. 
For the cotangent function f (x) = T cot TX = T-, 
this is clear (see 
the figure). For g(x), we first use the identity & + 
= -A 
to 
rewrite Euler's formula as 
Thus for (A) we have to prove that for every x 6 Z 
the series 
converges uniformly in a neighborhood of x. 
The function f (x) = T cot TX 

128 
Cotangent and the Herglotz trick 
Addition theorems: 
sin(x t y) = sin x cos y + cos x sin y 
cos(x + y) = cos x cosy - sin x sin y 
s n ( x + ) =  
cosx 
COS(X + ;) 
= - sinx 
sinx = 2sin$cosI 
cosx =cos2: -sin2 5 .  
For this, we don't get any problem with the first term, for n = 1, or with 
the terms with 2n - 1 < x2, since there is only a finite number of them. On 
the other hand, for n > 2 and 2n - 1 > x2, that is n2 - x2 > (n - 1)2 > 0, 
the summands are bounded by 
and this bound is not only true for x itself, but also for values in a neighbor- 
hood of x. Finally the fact that C & 
converges (to $, see page 35) 
provides the uniform convergence needed for the proof of (A). 
(B) 
Both f and g are periodic of period 1, that is, f (x + 1) = f (x) and 
g(x + 1) = g(x) hold for all x E R\Z. 
Since the cotangent has period T ,  we find that f has period 1 (see again the 
figure above). For g we argue as follows. Let 
then 
(C) Both f and g are odd functions, that is, we have f (-2) = - f (x) and 
g(-x) = -g(x) for all x E R\Z. 
The function f obviously has this property, and for g we just have to 
observe that g, (-x) = -gN (x). 
The final two facts constitute the Herglotz trick: First we show that f and g 
satisfy the same functional equation, and secondly that h := f - g can be 
continuously extended to all of R. 
(D) The two functions f and g satisfy the same functional equation: 
f ( 4 )  + f (T) 
= 2 f (x) and g(;) + g(q) 
= 2g(x). 
For f (x) this results from the addition theorems for the sine and cosine 
functions: 

Cotangent and the Herglotz trick 
129 
The functional equation for g follows from 
which in turn follows from 
Now let us look at 
We know by now that h is a continuous function on R\Z that satisfies the 
properties (B), (C), (D). What happens at the integral values? From the sine 
2 
4 
6 
and cosine series expansions, or by applying de 1'Hospital's rule twice, we 
cos x  = 1 - % + % - " i . . . 
F! 
find 
3
5
7
 
x cos x - sin x 
s i n x = x - " + " - L f  
... 
= 0, 
3! 
5 !  
7! 
x 
x+o 
x sinx 
and hence also 
lim (acot ax - J) = O. 
2-0 
x 
But since the last sum Cz=l a 
in (3) converges to 0 with x - 
0, we 
have in fact lim h(x) = 0, and thus by periodicity 
2-0 
lim h(x) = 0 
for all n E Z. 
x-n 
In summary, we have shown the following: 
(E) 
By setting h(x) := 0 for x E Z, 
h becomes a continuous function 
on all of R that shares the properties given in (B), (C) and (D). 
We are ready for the coup de grcice. Since h is a periodic continuous func- 
tion, it possesses a maximum m. Let xo be a point in [O,1] 
with h(xo) = m. 
It follows from (D) that 
and hence that h( y) = m. 
Iteration gives h(2) = m for all n, and hence 
h(0) = m by continuity. But h(0) = 0, and so m = 0, that is, h(x) L: 0 
for all x E R. As h(x) is an odd function, h(x) < 0 is impossible, hence 
h(x) = 0 for all x E R, 
and Euler's theorem is proved. 
0 
A great many corollaries can be derived from (I), the most famous of which 
concerns the values of Riemann's zeta function at even positive integers 
(see the Appendix to Chapter 6), 

130 
Cotangent and the Herglotz trick 
So to finish our story let us see how Euler - 
a few years later, in 1755 - 
treated the series (4). We start with formula (2). Multiplying (2) by x and 
setting y  = T X  we find for 1 y  1 < T :  
The last factor is the sum of a geometric series, hence 
W
W
 
y c o t y  = 1
-
2
~
~
(
$
)
~
~
 
n=l k=l 
and we have proved the remarkable result: 
For all k E N, 
the coeficient of y2k in the power series expansion of y cot y 
equals 
2 
O0 
[ y 2 k ]  y c o t y  = -- 
1 - 
2 
T
2
~
 a 
- --((2k). 
T~~ 
(5) 
n=l 
There is another, perhaps much more "canonical," way to obtain a series 
expansion of y  cot y. We know from analysis that e" = cosy + i sin y, and 
thus 
eZY + e-2Y 
eW - e-ZY 
cosy = 
2
'
 sin y  = 
2i 
' 
which yields 
We now substitute z = 2iy, and get 
z e Z + l  
Z 
Z 
y c o t y  = -- 
- - + -. 
2 e Z - 1  
2 
e z - 1  
(6) 
Thus all we need is a power series expansion of the function A; 
note 
that this function is defined and continuous on all of R (for z = 0 use the 
power series of the exponential function, or alternatively de 1'Hospital's 
rule, which yields the value 1). We write 
The coefficients B, are known as the Bernoulli numbers. The left-hand 
side of (6) is an even function (that is, f (2) = f (-z)), and thus we see that 
B,, 
= 0 for odd n > 3, while B1 = - corresponds to the term of $ in (6). 

Cotangent and the Herglotz trick 
131 
From 
we obtain by comparing coefficients for z n :  
We may compute the Bernoulli numbers recursively from (8). The value 
1 
n = 1 gives Bo = 1, n = 2 yields 2 + B1 = 0, that is B1 = -2, and 
SO on. 
Now we are almost done: The combination of (6) and (7) yields 
and out comes, with (5), Euler's formula for C(2I;): 
Looking at our table of the Bernoulli numbers, we thus obtain once again 
the sum 5 = 
from Chapter 6, and further 
The Bernoulli number Blo = 5 that gets us ((10) looks innocuous enough, 
69y6 
but the next value B 1 2  = - m, 
needed for <(12), contains the large prime 
factor 691 in the numerator. Euler had first computed some values ( ( 2 k )  
without noticing the connection to the Bernoulli numbers. Only the appear- 
ance of the strange prime 691 put him on the right track. 
Incidentally, since ((2I;) converges to 1 for k -4 m, equation (9) tells us 
that the numbers I B2k I grow very fast - 
something that is not clear from 
the first few values. 
In contrast to all this, one knows very little about the values of the Riemann 
zeta function at the odd integers k > 3: see Dage 41. 
IN DHPINIEND SUMdlIS S E U E l R  INFINtY 
131 
h. 
Quo rurcm valor harum (urnmarum clarius pdpick 
ar , plures hulufmod~ Scricmm f u m w  commo&ori mod0 
ap&s 
h c  adlidam. 
n o  
B 
Hoarfquc iftor Pctritamm iplius r Exponentcr arrificio alibi 
crpoacndo continuarc licuir, quod idco hic adjunxi, quod 
R s 
k k i  
1
2
3
 4 
5 6 7  8 
1 - L L O - ' 0 ' O - L  
2 6 
30 
42 
30 
Page 13 1 of Euler's 1748 "Introductio in 
The first few Bernoulli numbers 
- 
-
.
 
a
"
 
Analysin Infinitorum" 

132 
Cotangent and the Herglotz trick 
References 
[I] S. BOCHNER: Book review of "Gesammelte Schrijten" by Gustav Herglotz, 
Bulletin Amer. Math. Soc. 1 (1979), 1020-1022. 
[2] J. ELSTRODT: 
Partialbruchzerlegung des Kotangens, Herglotz-Trick und die 
WeierstraJsche stetige, nirgends differenzierbare Funktion, Math. Sernester- 
berichte 45 ( 1 998), 207-220. 
[3] L. EULER: Introductio in Analysin Injinitorum, Tomus Primus, Lausanne 
1748; Opera Ornnia, Ser. 1, Vol. 8. In English: Introduction to Analysis of 
the Injinite, Book I (translated by J. D. Blanton), Springer-Verlag. New York 
1988. 
[4] L. EULER: Institutiones calculi differentialis cum ejus usu in analysijnitorum 
ac doctrina serierum, Petersburg 1755; Opera Omnia, Ser. 1, Vol. 10. 

Buffon's needle problem 
Chapter 21 
A French nobleman, Georges Louis Leclerc, Comte de Buffon, posed the 
following problem in 1777: 
t 
Suppose that you drop a short needle on ruledpaper - 
what is then 
the probability that the needle comes to lie in a position where it 
I 
crosses one of the lines? 
The probability depends on the distance d between the lines of the ruled 
paper, and it depends on the length e of the needle that we drop - 
or 
rather it depends only on the ratio :. A short needle for our purpose is one 
of length e 5 d. In other words, a short needle is one that cannot cross 
two lines at the same time (and will come to touch two lines only with 
probability zero). The answer to Buffon's problem may come as a surprise: 
It involves the number T. 
Theorem ("Buffon's needle problem") 
Ifa short needle, of length e, is dropped on paper that is ruled with equally 
spaced lines of distance d 2 k then the probability that the needle comes 
to lie in a position where it crosses one of the lines is exactly 
The result means that from an experiment one can get approximate val- 
ues for T :  If you drop a needle N times, and get a positive answer (an 
intersection) in P cases, then $ should be approximately $:, 
that is, .rr 
should be approximated by F. The most extensive (and exhaustive) 
test was perhaps done by Lazzarini in 1901, who allegedly even built a 
machine in order to drop a stick 3408 times (with 5 = g). He found 
that it came to cross a line 1808 times, which yields the approximation 
.ir z 2 . 5 ZKB = 3.1415929 ...., which is correct to six digits of T ,  and 
6 1808 
much too good to be true! (The values that Lazzarini chose lead directly 
to the well-known approximation T z e; 
see page 3 1. This explains the 
more than suspicious choices of 3408 and i, 
where 
3408 is a multiple 
of 355. See [5] for a discussion of Lazzarini's hoax.) 
Le Comte de Buffon 
The needle problem can be solved by evaluating an integral. We will do that 
below, and by this method we will also solve the problem for a long needle. 
But the Book Proof, presented by E. Barbier in 1860, needs no integrals. 
It just drops a different needle . . . 

134 
Buffon's needle ~roblem 
If you drop any needle, short or long, then the expected number of crossings 
will be 
where pl is the probability that the needle will come to lie with exactly one 
crossing, p2 is the probability that we get exactly two crossings, ps is the 
probability for three crossings, etc. The probability that we get at least one 
crossing, which Buffon's problem asks for, is thus 
(Events where the needle comes to lie exactly on a line, or with an end- 
point on one of the lines, have probability zero - 
so they can be ignored 
throughout our discussion.) 
On the other hand, if the needle is short then the probability of more than 
one crossing is zero, p2 = p3 = . . . = 0, and thus we get E = p: The 
probability that we are looking for is just the expected number of crossings. 
This reformulation is extremely useful, because now we can use linearity of 
expectation (cf. page 84). Indeed, let us write E(t) for the expected number 
of crossings that will be produced by dropping a straight needle of length e. 
If this length is e = x + y, and we consider the "front part" of length x and 
the "back part" of length y of the needle separately, then we get 
since the crossings produced are always just those produced by the front 
part, plus those of the back part. 
By induction on n this "functional equation" implies that E(nx) = nE(x) 
for all n E N, 
and then that mE($x) = E(nl.$x) = E(n,x) = nE(x), 
so that E(rz) = rE ( x )  holds for all rational r 6 Q. 
Furthermore, E(x) 
is clearly monotone in x 2 0, from which we get that E(x) = cx for all 
x > 0, where c = E ( l )  is some constant. 
But what is the constant? 
For that we use needles of different shape. Indeed, let's drop a "polygonal" 
needle of total length !, which consists of straight pieces. Then the number 
of crossings it produces is (with probability 1) the sum of the numbers of 
crossings produced by its straight pieces. Hence, the expected number of 
crossings is again 
by linearity of expectation. (For that it is not even important whether the 
straight pieces are joined together in a rigid or in a flexible way!) 
The key to Barbier's solution of Buffon's needle problem is to consider a 
needle that is a perfect circle C of diameter d, which has length x = dr. 
Such a needle, if dropped onto ruled paper, produces exactly two inter- 
sections, always! 

Buffon's needle problem 
135 
The circle can be approximated by polygons. Just imagine that together 
with the circular needle C we are dropping an inscribed polygon P,, as 
well as a circumscribed polygon Pn. Every line that intersects P, will also 
intersect C, and if a line intersects C then it also hits Pn. Thus the expected 
numbers of intersections satisfy 
Now both Pn and Pn are polygons, so the number of crossings that we may 
expect is "c times length" for both of them, while for C it is 2, whence 
Both P, and Pn approximate C for n - 
x. 
In particular, 
lim e(Pn) = d n  = lim e(Pn), 
n-30 
n-30 
and thus for n - 
x 
we infer from (1) that 
c d n  < 2 < c d n .  
which gives c = : 
$. 
But we could also have done it by calculus! The trick to obtain an "easy" 
integral is to first consider the slope of the needle; let's say it drops to lie 
with an angle of a away from horizontal, where a will be in the range 
0 < u: < 5. (We will ignore the case where the needle comes to lie with 
negative slope, since that case is symmetric to the case of positive slope, and 
produces the same probability.) A needle that lies with angle a has height 
t sin a, and the probability that such a needle crosses one of the horizontal 
lines of distance d is 9. 
Thus we get the probability by averaging over 
the possible angles a, as 
r / z  e sin a 
2 e 
xl2 - -- 
2 e  
du: = - - [ - c o s ~ ~ ] ~  - 
n 
d 
n d 
7r d '  
0 
For a long needle, we get the same probability 
as long as l sin 0 < d, 
that is, in the range 0 < a < arcsin $. However, for larger angles u: the 
needle must cross a line, so the probability is 1. Hence we compute 
= 1+2(!(1-/<) 
71. d 
a r c s i n -  d ,  
1 
fore 
d. 
So the answer isn't that pretty for a longer needle, but it provides us with a 
nice exercise: Show ("just for safety") that the formula yields $ for e = d, 
that it is strictly increasing in e, and that it tends to 1 fore - 
m. 

136 
Buffon S needle problem 
References 
[I] E. BARBIER: 
Note sur le problbme de I'aiguille et le jeu du joint couvert, J. 
MathCmatiques Pures et AppliquCes (2) 5 (1860), 273-286. 
[2] L. BERGGREN, 
J. BORWEIN & P. BORWEIN, EDS.: Pi: A Source Book, 
Springer-Verlag, New York 1997. 
[3] G. L. LECLERC, COMTE DE BUFFON: Essai d'arithmt2ique morale, Ap- 
pendix to "Histoire naturelle gCnCrale et particulikre," Vol. 4, 1777. 
[4] D. A. KLAIN & G.-C. ROTA: Introduction to Geometric Probability, "Lezioni 
Lincee," Cambridge University Press 1997. 
[5] T. H. O'BEIRNE: Puzzles and Paradoxes, Oxford University Press, London 
1965. 
"Got a problem?" 

 
 
 
Combinatorics 

Pigeon-hole and double counting 
Chapter 22 
Some mathematical principles, such as the two in the title of this chapter, 
are so obvious that you might think they would only produce equally 
obvious results. 
To convince you that "It ain't necessarily so" we 
illustrate them with examples that were suggested by Paul Erdiis to be 
included in The Book. We will encounter instances of them also in later 
chapters. 
Pigeon-hole principle. 
I f  n objects are placed in r boxes, where r < n, then at least one of 
the boxes contains more than one object. 
P 
Well. this is indeed obvious, there is nothing to prove. In the language of 
mappings our principle reads as follows: Let N and R be two finite sets 
with 
IN1 = n > r = IRl, 
and let f : N - 
R be a mapping. Then there exists some a E R with 
1 f 
( a ) )  _> 2. We may even state a stronger inequality: There exists some 
"The pigeon-holes from a brrd's 
a E R with 
perspective" 
In fact, otherwise we would have ( f  -'(a)) < 
for all a, and hence 
n = C 1 f -'(a)\ < r 
= n, which cannot be. 
a t R  
1. Numbers 
Claim. Consider the numbers 1 , 2 , 3 ,  . . . ,2n, and take any n + 1 
of them. Then there are two among these n + 1 numbers which are 
relatively prime. 
This is again obvious. There must be two numbers which are only 1 apart, 
and hence relatively prime. 
But let us now turn the condition around. 
Claim. Suppose again A C { 1 , 2 ,  . . . ,2n) with IAl = n + 1. Then 
there are always two numbers in A such that one divides the other: 

140 
Pigeon-hole and double countinn 
This is not so clear. As ErdBs told us, he put this question to young Lajos 
PoSa during dinner, and when the meal was over, Lajos had the answer. It 
has remained one of Erdiis' favorite "initiation" questions to mathematics. 
The (affirmative) solution is provided by the pigeon-hole principle. Write 
Both results are no longer true if one 
every number a E A in the form a = 2", 
where m is an odd number 
replaces n f l  by n: For this consider 
between 1 and 2n - 1. Since there are n + 1 numbers in A, but only n 
the sets {2.4,6.. . . .2n), respectively 
different odd parts, therz must be two numbers in A with the same odd 
{n+l, n+2,. . . .2n). 
part. Hence one is a multiple of the other. 
0 
2. Sequences 
Here is another one of Erd6s' favorites, contained in a paper of Erdiis and 
Szekeres on Ramsey problems. 
Claim. In any sequence a l ,  aa, . . . , a,,+l 
of mn + 1 distinct real 
numbers, there exists an increasing subsequence 
of length m + 1, or a decreasing subsequence 
oflength n + 1, or both. 
This time the application of the pigeon-hole principle is not immediate. 
Associate to each ai the number ti which is the length of a longest increas- 
ing subsequence starting at ai. If ti 2 m + 1 for some i, then we have 
an increasing subsequence of length m + 1. Suppose then that ti 5 m for 
all i. The function f : ai 
ti mapping { a l , .  . . , a,,,+l) 
to (1,. . . , m) 
tells us by (1) that there is some s E (1,. . . , m )  such that f (a,) = s for 
mn - 
rn + 1 = n + 1 numbers ai. Let a,,, aj,, . . .,a,,+, (jl < . . . < &+I) 
be these numbers. Now look at two consecutive numbers aJZ, aj,,, . If 
aj, < a,,+, , then we would obtain an increasing subsequence of length 
The reader may have fun in proving that 
s starting at aj,,, , and consequently an increasing subsequence of length 
for 7nn numbers the statement remains 
s + 1 starting at a,, , which cannot be since f (a,? ) = s. We thus obtain a 
no longer true in general. 
decreasing subsequence aj, > aj, > . . . > aj,,, 
of length n + 1. 
0 
This simple-sounding result on monotone subsequences has a highly non- 
obvious consequence on the dimension of graphs. We don't need here the 
notion of dimension for general graphs, but only for complete graphs K,. 
It can be phrased in the following way. Let N = (1, . . . , n), n > 3, and 
consider m permutations T I ,  . . . , T, of N. We say that the permutations 
7rt represent K, if to every three distinct numbers i ,  j, k there exists a per- 
mutation 7r in which k comes after both i and j. The dimension of Kn is 
then the smallest m for which a representation T I ,  . . . , xm exists. 
As an example we have dim(K3) = 3 since any one of the three numbers 
must come last, as in TI = (1,2,3), 7r2 = (2,3, I ) ,  TTT~ 
= (3,1,2). What 

Pigeon-hole and double counting 
141 
about K4? Note first dim(K,) 5 dim(K,+l): just delete n + 1 in a 
representation of K,+l. So, dim(K4) > 3, and, in fact, dim(K4) = 3, by 
taking 
It is not quite so easy to prove dim(K5) = 4, but then, surprisingly, the 
dimension stays at 4 up to ,n = 12, while dini(Kly) = 5. So dim(K,) 
seems to be a pretty wild function. Well, it is not! With n going to infinity, 
dim(K, ) is, in fact, a very well-behaved function - 
and the key for finding 
a lower bound is the pigeon-hole principle. We claim 
Since, as we have seen, dim(K,) is a monotone function in n, it suffices to 
verify (2) for n = 2'" + 1, that is, we have to show that 
dim(K,) 2 p + 1 
for n = 2,' + 1 
Suppose, on the contrary, dim(K,) 5 p, and let TI, . . . , T, be representing 
permutations of N = {1,2, . . . -2'" + 1). Now we use our result on mono- 
tone subsequences p times. In .rrl there exists a monotone subsequence A1 
of length 22"-1 + 1 (it does not matter whether increasing or decreasing). 
Look at this set A1 in 
Using our result again, we find a monotone sub- 
sequence A2 of A1 in 7r2 of length 22p-2 + 1, and A2 is, of course, also 
monotone in TI. Continuing, we eventually find a subsequence A, of size 
220 + 1 = 3 which is monotone in all permutations ~
i
.
 
Let A, = (a, b, c), 
then either a < b < c or a > b > c in all n,. But this cannot be, since there 
must be a permutation where b comes after a and c. 
0 
The right asymptotic growth was provided by Joel Spencer (upper bound) 
and by Erdds, SzemerCdi and Trotter (lower bound): 
1 
dim(K,) 
= log, log, 71 + (- + o(1)) log, log, log2 n. 
2 
But this is not the whole story: Very recently, Morris and Hogten found 
a method which, in principle, establishes the precise value of dim(K,). 
Using their result and a computer one can obtain the values given in the 
margin. This is truly astounding! Just consider how many permutations of 
size 1422564 there are. How does one decide whether 7 or 8 of them are 
required to represent K1422564? 
3. Sums 
Paul Erdds attributes the following nice application of the pigeon-hole 
principle to Andrew VQzsonyi and Marta Sved: 
~ l : l 2 3  
5 6 7 8 9 1 0 1 1 1 2 4  
7r2:2 3  4 8 7 6 5 1 2 1 1 1 0  9  1 
T S : ~  
4 1 1 1 1 2  9 1 0  6 5 8 7 2  
~ 4 : 4  
1 2 1 0  9 1 2 1 1  7 8 5 6 3 
These four permutations represent K12 
Claim. Suppose we are given n integers a l ,  . . . , a,, which need 
not be distinct. Then there is alwa s a set of consecutive numbers 
2 
al;+l, ak+2? . . . , at whose sum Ci=k+l ai is a multiple of n. 

142 
Pigeon-hole and double counting 
For the proof we set N = { 0 , 1 , .  . . , n} and R = { 0 , 1 , .  . . , n - 1). Con- 
sider the map f : N + R, 
where f (m) is the remainder of a1 + . . . + a, 
upon division by n. Since IN1 = n + 1 > n = I RI, it follows that there are 
two sums a1 + . . . + a k ,  a1 + . . . + ae ( k  < t) with the same remainder, 
where the first sum may be the empty sum denoted by 0. It follows that 
has remainder 0 - 
end of proof. 
0 
Let us turn to the second principle: counting in two ways. By this we mean 
the following. 
Double counting. 
Suppose that we are given two Jinite sets R and C and a subset 
S C_ R x C. Whenever (p, q) E S, then we say p and q are incident. 
I f  rp denotes the number of elements that are incident to p E R, 
and c, denotes the number of elements that are incident to q E C, 
then 
Again, there is nothing to prove. The first sum classifies the pairs in S 
according to the first entry, while the second sum classifies the same pairs 
according to the second entry. 
There is a useful way to picture the set S. Consider the matrix A = (a,,), 
the incidence matrix of S, where the rows and columns of A are indexed 
by the elements of R and C, respectively, with 
With this set-up, r, is the sum of the p-th row of A and c, is the sum of the 
q-th column. Hence the first sum in (3) adds the entries of A (that is, counts 
the elements in S) by rows, and the second sum by columns. 
The following example should make this correspondence clear. Let R = 
C = { 1 , 2 , .  . . ,8), and set S = {(i, 
j )  : i divides j ) .  We then obtain the 
matrix in the margin, which only displays the 1's. 
4. Numbers again 
Look at the table on the left. The number of 1's in column j is precisely the 
number of divisors of j ;  let us denote this number by t ( j ) .  Let us ask how 

Pigeon-hole and double counting 
143 
large this number t ( j )  is on the average when j ranges from 1 to n. Thus, 
we ask for the quantity 
n 1 1 2 3 4 5 6  7 8 
The first few values of f(n) 
How large is f(n) for arbitrary n? At first glance, this seems hopeless. For 
prime numbers p we have t ( p )  = 2, while for 2k we obtain a large number 
t(2" = k + 1. So, t(n) is a wildly jumping function, and we surmise that 
the same is true for t(n). Wrong guess, the opposite is true! Counting in 
two ways provides an unexpected and simple answer. 
Consider the matrix A (as above) for the integers 1 up to n. Counting by 
columns we get 
t ( j ) .  How many 1's are in row i? Easy enough, the 
1's correspond to the multiples of i: li, 22,. . ., and the last multiple not 
exceeding n is 
i. Hence we obtain 
where the error in each summand, when passing from 
to y, is less 
than 1. Now the last sum is the 72-th harmonic number Hn, so we obtain 
Hn - 1 < f(n) < H,, and together with the estimates of H, on page 11 
this gives 
Thus we have proved the remarkable result that, while t(n) is totally erratic, 
the average f(n) behaves beautifully: It differs from log n by less than 1. 
5. Graphs 
Let G be a finite simple graph with vertex set V and edge set E. We have 
defined in Chapter 11 the degree d ( v )  of a vertex v as the number of edges 
which have v as an end-vertex. In the example of the figure, the vertices 
1.2.. . . . 7  have degrees 3,2,4,3,3,2,3, respectively. 
2 
Almost every book in graph theory starts with the following result (that we 
have already encountered in Chapters 1 1 and 17): 
3 
7 
For the proof consider S c V x E, where S is the set of pairs ( v ,  e )  such 
that 21 E V is an end-vertex of e E E. Counting S in two ways gives on the 
one hand C,,, d ( v ) ,  since every vertex contributes d ( v )  to the count, and 
on the other hand 2 / E 1, since every edge has two ends. 
0 
As simple as the result (4) appears, it has many important consequences, 
some of which will be discussed as we go along. We want to single out in 

144 
Pigeon-hole and double counting 
this section the following beautiful application to an extremal problem on 
graphs. Here is the problem: 
Suppose G = (V, E )  has n vertices and contains no cycle of 
length 4 (denoted by C4), that is, no subgraph f7f. How many 
edges can G have at most? 
As an example, the graph in the margin on 5 vertices contains no 4-cycle 
and has 6 edges. The reader may easily show that on 5 vertices the maximal 
number of edges is 6, and that this graph is indeed the only graph on 5 
vertices with 6 edges that has no 4-cycle. 
Let us tackle the general problem. Let G be a graph on n vertices without 
a 4-cycle. As above we denote by d(u) 
the degree of u. Now we count 
the following set S in two ways: S is the set of pairs (u, 
{v, w)) where 
u is adjacent to v and to w, 
with v # w. In other words, we count all 
occurrences of 
Summing over u, we find IS/ = EUEV 
(d(,")). 
On the other hand, 
every pair {v, w} has at most one common neighbor (by the C4-condition). 
Hence IS I < (i) , and we conclude 
Next (and this is quite typical for this sort of extremal problems) we 
apply the Cauchy-Schwarz inequality to the vectors (d(ul), 
. . . , d(u,)) 
and 
(1.1,. 
. . . 1), obtaining 
and hence by (5) 
Invoking (4) we find 
Solving the corresponding quadratic equation we thus obtain the following 
result of Istvan Reiman. 

Pigeon-hole and double counting 
145 
Theorem. Ifthe graph G on n vertices contains no 4-cycles, then 
For n = 5 this gives JEl 5 6, and the graph above shows that equality 
can hold. 
Counting in two ways has thus produced in an easy way an upper bound 
on the number of edges. But how good is the bound (6) in general? The 
following beautiful example 121 [3] [6] shows that it is almost sharp. As is 
often the case in such problems, finite geometry leads the way. 
In presenting the example we assume that the reader is familiar with the 
finite field Z, of integers modulo a prime p (see page 18). Consider the 
3-dimensional vector space X over Z,. 
We construct from X the fol- 
lowing graph G,. The vertices of G, are the one-dimensional subspaces 
[v] := spanZ,{v), 0 # v E X, and we connect two such subspaces 
(0,0> 1) 
[v], [w] by an edge if 
(v.w) = vlwl + U Z W 2  + U y W 3  = 0. 
Note that it does not matter which vector # 0 we take from the subspace. 
(l,O,l) 
( O > l >  1) 
In the language of geometry, the vertices are the points of the projective 
plane over Z,, and [w] is adjacent to [v] if w lies on the polar line of v. 
( L l ,  1) 
As an example, the graph G2 has no 4-cycle and contains 9 edges, which 
almost reaches the bound 10 given by (6). We want to show that this is true 
for any prime p. 
(1,0,0) A 
, 
(0,110) 
Let us first prove that G, satisfies the C4-condition. If [u] is a common 
The graph Gg: its vertices are all seven 
neighbor of [v] and [w], then u is a solution of the linear equations 
nonzero triples (x, y, 2). 
Since v and w are linearly independent, we infer that the solution space 
has dimension 1, and hence that the common neighbor [u] is unique. 
Next, we ask how many vertices G, has. It's double counting again. The 
space X contains p3 - 1 vectors # 0. Since every one-dimensional sub- 
space contains p - 1 vectors # 0, we infer that X has $ 
= =' + p + 1 
one-dimensional subspaces, that is, G, has n = p2 + p + 1 vertices. Simi- 
larly, any two-dimensional subspace contains p2 - 1 vectors # 0, and hence 
= p + 1 one-dimensional subspaces. 
P -  1 
It remains to determine the number of edges in G,, or, what is the same by 
(4), the degrees. By the construction of G,, the vertices adjacent to [u] are 
the solutions of the equation 
The solution space of (7) is a two-dimensional subspace, and hence there 
are p + 1 vertices adjacent to [u]. But beware, it may happen that u itself 
is a solution of (7). In this case there are only p vertices adjacent to [u]. 

146 
Pigeon-hole and double counting 
i 
0
1
1
1
0
0
0
 
1
0
1
0
1
0
0
 
1
1
0
0
0
1
0
 
A
=
1
0
0
1
0
0
1
 
0
1
0
0
1
0
1
 
0
0
1
0
0
1
1
 
0
0
0
1
1
1
0
 
The matrix for Gz 
In summary, we obtain the following result: If u lies on the conic given by 
x2 + y2 + z2 = 0, then d ( [ u ] )  = p, and, if not, then d ( [ u ] )  = p + 1. So it 
remains to find the number of one-dimensional subspaces on the conic 
Let us anticipate the result which we shall prove in a moment. 
Claim. There are precisely p2 solutions ( x ,  y, z )  of the equation 
x2 + y2 + z2 = 0, and hence (excepting the zero solution) precisely 
= p + 1 vertices in G, of degree p. 
P- 1 
With this, we complete our analysis of G,. There are p + 1 vertices of 
degree p, hence (p2 + p + 1 )  - ( p  + 1 )  = p2 vertices of degree p + 1. 
Using (4), we obtain 
Setting n = p2 + p + 1, the last equation reads 
and we see that this almost agrees with (6). 
Now to the proof of the claim. The following argument is a beautiful appli- 
cation of linear algebra involving symmetric matrices and their eigenvalues. 
We will encounter the same method in Chapter 34, which is no coincidence: 
both proofs are from the same paper by Erdas, Rknyi and S6s. 
We represent the one-dimensional subspaces of X as before by vectors 
vl, va, . . . , V ~ Z + , + ~ ,  
any two of which are linearly independent. Similarly, 
we may represent the two-dimensional subspaces by the same set of vec- 
tors, where the subspace corresponding to u = (ul ,212, us) is the set of so- 
lutions of the equation ulx+u2y $2132 = 0 as in (7). (Of course, this is just 
the duality principle of linear algebra.) Hence, by (7), a one-dimensional 
subspace, represented by v i ,  is contained in the two-dimensional subspace, 
represented by v i ,  if and only if (vi, v i )  = 0. 
Consider now the matrix A = ( a i j )  of size (p2+p+1) x ( ~ ~ + ~ + l ) ,  
defined 
as follows: The rows and columns of A correspond to vl, . . . , ~ , n + , + ~  
(we 
use the same numbering for rows and columns) with 
1 if (v,, v j )  = 0, 
aij := 
0 otherwise. 
A is thus a real symmetric matrix, and we have a,i = 1 if (vi, vi) = 0, that 
is, precisely when vi lies on the conic x2 + y2 + z2 = 0. Thus, all that 
remains to show is that 
trace A = p +  1. 

Pigeon-hole and double counting 
147 
From linear algebra we know that the trace equals the sum of the eigenval- 
ues. And here comes the trick: While A looks complicated, the matrix A2 
is easy to analyze. We note two facts: 
Any row of A contains precisely p + 1 1's. This implies that p + 1 is an 
eigenvalue of A, since A1 = ( p  + 1) 1, where 1 is the vector consisting 
of 1's. 
For any two distinct rows vi, v, there is exactly one column with a 1 in 
both rows (the column corresponding to the unique subspace spanned 
by vi, v,). 
Using these facts we find 
where I is the identity matrix and J is the all-ones-matrix. Now, J has 
the eigenvalue p2 + p + 1 (of multiplicity 1) and 0 (of multiplicity p2 + p). 
Hence A2 has the eigenvalues p2 + 2p + 1 = (p+ 1)2 of multiplicity 1 and p 
of multiplicity p2 +p. Since A is real and symmetric, hence diagonalizable, 
we find that A has the eigenvalue p + 1 or -(p + 1 )  and p2 + p eigenvalues 
*fi. 
From Fact 1 above, the first eigenvalue must be p + 1. Suppose 
that fi has multiplicity r, and -fi 
multiplicity s, then 
But now we are home: Since the trace is an integer, we must have r = s, 
so trace A = p + 1. 
0 
6. Sperner's Lemma 
In 19 1 1, Luitzen Brouwer published his famous fixed point theorem: 
Every continuous function f: Bn - 
Bn of an n-dimensional ball 
to itse2fhas a$xed point (a point x E Bn with f (x) = x). 
For dimension 1, that is for an interval, this follows easily from the inter- 
mediate value theorem, but for higher dimensions Brouwer's proof needed 
some sophisticated machinery. It was therefore quite a surprise when in 
1928 young Emanuel Sperner (he was 23 at the time) produced a simple 
combinatorial result from which both Brouwer's fixed point theorem and 
the invariance of the dimension under continuous bijective maps could be 
deduced. And what's more, Sperner's ingenious lemma is matched by an 
equally beautiful proof - 
it is just double counting. 

148 
Pigeon-hole and double counting 
We discuss Sperner's lemma, and Brouwer's theorem as a consequence, for 
the first interesting case, that of dimension n = 2. The reader should have 
no difficulty to extend the proofs to higher dimensions (by induction on the 
dimension). 
Sperner's Lemma. 
Suppose that some "big" triangle with vertices Vl, V2, V3 is triangulated 
(that is, decomposed into a jinite number of "small" triangles that fit to- 
gether edge-by-edge). 
Assume that the vertices in the triangulation get "colors" from the set 
{1,2,3) such that V, receives the color i (for each i), and only the col- 
ors i and j are used for vertices along the edge from V, to Vj (for i # j), 
1 
2 
2 
1 
while the interior vertices are colored arbitrarily with 1, 2 or 3. 
The triangles with three different colors 
Then in the triangulation there must be a small "tricolored" triangle, which 
are shaded 
has all three different vertex colors. 
Proof. We will prove a stronger statement: the number of tricolored 
triangles is not only nonzero, it is always odd. 
Consider the dual graph to the triangulation, but don't take all its edges 
3 
- 
only those which cross an edge that has endvertices with the (different) 
colors 1 and 2. Thus we get a "partial dual graph" which has degree 1 at all 
vertices that correspond to tricolored triangles, degree 2 for all triangles in 
which the two colors 1 and 2 appear, and degree 0 for triangles that do not 
have both colors 1 and 2. Thus only the tricolored triangles correspond to 
vertices of odd degree (of degree 1). 
However, the vertex of the dual graph which corresponds to the outside of 
the triangulation has odd degree: in fact, along the big edge from Vl to V2, 
1 
:
2
 
2 
,/ 
1 ' 
2 
there is an odd number of changes between 1 and 2. Thus an odd number 
: 
of edges of the partial dual graph crosses this big edge, while the other big 
- - 
- 
- - - - - -  - - - - '  edges cannot have both 1 and 2 occurring as colors. 
Now since the number of odd vertices in any finite graph is even (by equa- 
tion (4)), we find that the number of small triangles with three different 
colors (corresponding to odd inside vertices of our dual graph) is odd. 
With this lemma, it is easy to derive Brouwer's theorem. 
Proof of Brouwer's fixed point theorem (for n = 2). Let A be the tri- 
angle in R3 with vertices el = (1,0, 
o), e2 = (0,1, 
o), and e3 = (0,0,1). 
It suffices to prove that every continuous map f :  A - 
A has a fixed point, 
since A is homeomorphic to the two-dimensional ball B2. 
We use 6(7) to denote the maximal length of an edge in a triangulation 7 .  
One can easily construct an infinite sequence of triangulations TI, 
7 2 ,  . . . 
of A such that the sequence of maximal diameters 6(7k) converges to 0. 
Such a sequence can be obtained by explicit construction, or inductively, 
for example by taking 7k+1 
to be the barycentric subdivision of Tk. 
For each of these triangulations, we define a 3-coloring of their vertices v 
by setting X(v) := min{i : f (v), < vi), that is, X(v) is the smallest index i 
such that the i-th coordinate off (v) - v is negative. Assuming that f has 
no fixed point, this is well-defined. To see this, note that every v E A lies 

Pigeon-hole and double counting 
149 
in the plane xl + x2 + 2 3  = 1, hence xi vi = 1. So iff (v) # v, then at 
least one of the coordinates of f (v) - v must be negative (and at least one 
must be positive). 
Let us check that this coloring satisfies the assumptions of Sperner's lemma. 
First, the vertex ei must receive color i, since the only possible negative 
component of f (ei) - ei is the i-th component. Moreover, if v lies on the 
edge opposite to ei, then u, = 0, so the i-th component off (v) - v cannot 
be negative, and hence v does not get the color i. 
Spemer's lemma now tells us that in each triangulation Tk there is a tri- 
colored triangle {vk:' , vkZ2, 
v " ~ )  
with X(vk:') = i. The sequence of 
points ( v " ' ) ~ > ~  
need not converge, but since the simplex A is compact 
some subsequence has a limit point. After replacing the sequence of tri- 
angulations Tk by the corresponding subsequence (which for simplicity 
we also denote by '&) we can assume that (vkZ1)k 
converges to a point 
v E A. Now the distance of vkT2 
and vkz3 
from vkZ1 
is 
' at most the mesh 
length 6 ( 3 ) ,  which converges to 0. Thus the sequences (vk2) 
and ( v " ~ )  
converge to the same point v. 
But where is f (v)? We know that the first coordinate f (vkZ1) 
is smaller 
than that of vk" for all k. Now since f is continuous, we derive that the 
first coordinate off (v) is smaller or equal to that of v. The same reasoning 
works for the second and third coordinates. Thus none of the coordinates 
of f (v) - v is positive - 
and we have already seen that this contradicts 
the assumption f (v) # v. 
0 
References 
[ I ]  L. E. J. BROUWER: 
~ b e r  
Abbildungen von Mannigfaltigkeiten, Math. An- 
nalen 71 (1912), 97-1 15. 
[2] W. G. BROWN: 
On graphs that do not contain a Thomsen graph, Canadian 
Math. Bull. 9 (1966), 281-285. 
[3] P. ERDBS, A. RENYI & V. SOS: On a problem ofgraph theory, Studia Sci. 
Math. Hungar. 1 (1966), 215-235. 
[4] P. ERDBS & G. SZEKERES:A 
combinatorialproblem in geometry, Cornpositio 
Math. (1935). 463-470. 
[5] S. HOSTEN & W. D. MORRIS: The order dimension of the complete graph, 
Discrete Math. 201 (1999), 133- 139. 
[6] I. REIMAN: 
Uber ein Problem von K. Zurankiewicz, Acta Math. Acad. Sci. 
Hungar. 9 (1958), 269-273. 
[7] J. SPENCER: 
Minimal scrambling sets of simple orders, Acta Math. Acad. Sci. 
Hungar. 22 (197 l), 349-353. 
[8] E. SPERNER: 
Neuer Beweis fur die Invarianz der Dimensionszahl und des 
Gebietes, Abh. Math. Sern. Hamburg 6 (1928), 265-272. 
[9] W. T. TROTTER: 
Cornbinatorics and par ti all)^ Ordered Sets: Dimension 
Theory John Hopkins University Press, Baltimore and London 1992. 

Three famous theorems 
on finite sets 
Chapter 23 
In this chapter we are concerned with a basic theme of combinatorics: 
properties and sizes of special families 3 of subsets of a finite set N = 
{1,2, . . . . n}. We start with two results which are classics in the field: the 
theorems of Sperner and of Erdiis-KO-Rado. These two results have in com- 
mon that they were reproved many times and that each of them initiated a 
new field of combinatorial set theory. For both theorems, induction seems 
to be the natural method, but the arguments we are going to discuss are 
quite different and truly inspired. 
In 1928 Emanuel Sperner asked and answered the following question: Sup- 
pose we are given the set N = {1,2, . . . , n). Call a family 3 of subsets of 
N an antichain if no set of 3 contains another set of the family 3. What is 
the size of a largest antichain? Clearly, the family Fk of all k-sets satisfies 
the antichain property with lFkl = (z). Looking at the maximum of the 
binomial coefficients (see page 12) we conclude that there is an antichain 
of size (,T,;2J) 
= maxk (L) . Sperner's theorem now asserts that there are 
no larger ones. 
Theorem 1. The size of a largest antichain of an n-set is (L,72,). 
Emanuel Sperner 
Proof. Of the many proofs the following one, due to David Lubell, is 
probably the shortest and most elegant. Let 3 be an arbitrary antichain. 
Then we have to show 31 5 (,,y2,). 
The key to the proof is that we 
consider chains of subsets 0 = Co c C1 c C2 c . . . C C, = N, where 
JC, 
I = i for i = 0, . . . , n. How many chains are there? Clearly, we obtain 
a chain by adding one by one the elements of N, so there are just as many 
chains as there are permutations of N, namely n!. Next, for a set A E 3 
we ask how many of these chains contain A. Again this is easy. To get 
from 0 
to A we have to add the elements of A one by one, and then to pass 
from A to N we have to add the remaining elements. Thus if A contains k 
elements, then by considering all these pairs of chains linked together we 
see that there are precisely F!(n - k ) !  such chains. Note that no chain can 
pass through two different sets A and B of 3, since 3 is an antichain. 
To complete the proof, let mk be the number of k-sets in 3. Thus (31 = 
x;,O 
m k .  Then it follows from our discussion that the number of chains 
passing through some member of 3 is 
and this expression cannot exceed the number n! of all chains. Hence 

152 
Three famous theorems onJinite sets 
we conclude 
Replacing the denominators by the largest binomial coefficient, we there- 
fore obtain 
Check that the family of all ;-sets for 
1 
" 
n 
even n respectively the two families of 
5 1 
that is, 
(31 = Ernk 5 
all ?-sets 
and of all ?-sets, 
when 
( ~ n / 2 j )  
li=o 
k=o 
n is odd, are indeed the only antichains 
that achieve the maximum size! 
and the proof is complete. 
Our second result is of an entirely different nature. Again we consider the 
set N = (1. . . . , n). Call a family F o f  subsets an intersecting family if any 
two sets in 3 have at least one element in common. It is almost immediate 
that the size of a largest intersecting family is 2"-'. 
If A E F, then the 
complement A" = N\A has empty intersection with A and accordingly 
cannot be in F .  Hence we conclude that an intersecting family contains at 
most half the number 2" of all subsets, that is, IF/ < 2"-l. On the other 
hand, if we consider the family of all sets containing a fixed element, say 
the family .Fl of all sets containing 1, then clearly (31 
1 = 2"-l, and the 
problem is settled. 
But now let us ask the following question: How large can an intersecting 
family 3 be if all sets in F have the same size, say k ? Let us call such fami- 
lies intersecting klfamilies. To avoid trivialities, we assume n 2 2k since 
otherwise any two k-sets intersect, and there is nothing to prove. Taking 
up the above idea, we certainly obtain such a family .Fl by considering all 
k-sets containing a fixed element, say 1. Clearly, we obtain all sets in Fl 
by adding to 1 all (k - 1)-subsets of {2,3, . . . , n}, hence IF1 ( = (:I:). 
Can we do better? No - 
and this is the theorem of ErGs-KO-Rado. 
Theorem 2. The largest size of an intersecting F-family in an n-set is (:I:) 
when n 2 2k. 
point 
edge 
Paul Erdiis, Chao KO and Richard Rado found this result in 1938, but it 
was not published until 23 years later. Since then multitudes of proofs and 
variants have been given, but the following argument due to Gyula Katona 
is particularly elegant. 
Proof. The key to the proof is the following simple lemma, which at 
first sight seems to be totally unrelated to our problem. Consider a circle C 
divided by 72 points into n edges. Let an arc of length k consist of k + 1 
consecutive points and the k edges between them. 
Lemma. Let n 2 2k, and suppose we are given t distinct arcs All . . . , At 
of length k, such that any two arcs have an edge in common. Then t < k. 
A circle C for n = 6. The bold edges 
To prove the lemma, note first that any point of C is the endpoint of at most 
depict an arc of length 3. 
one arc. Indeed, if Ai, Aj had a common endpoint v, then they would have 

Three famous theorems onjinite sets 
153 
to start in different direction (since they are distinct). But then they cannot 
have an edge in common as n > 2k. Let us fix Al. Since any A, (i > 2) 
has an edge in common with Al, one of the endpoints of A, is an inner 
point of A1. Since these endpoints must be distinct as we have just seen, 
and since A1 contains k - 1 inner points, we conclude that there can be at 
most k - 1 further arcs, and thus at most k arcs altogether. 
0 
Now we proceed with the proof of the ErdBs-KO-Rado theorem. Let 3 be 
an intersecting k-family. Consider a circle C with n points and n edges as 
above. We take any cyclic permutation .ir = (al. a2, . . . . a,) and write the 
numbers n, clockwise next to the edges of C. Let us count the number of 
sets A E 3 which appear as k consecutive numbers on C. Since 3 is an 
intersecting family we see by our lemma that we get at most k such sets. 
Since this holds for any cyclic permutation, and since there are (n - l)! 
cyclic permutations, we produce in this way at most 
sets of 3 which appear as consecutive elements of some cyclic permutation. 
How often do we count a fixed set A E 3? Easy enough: A appears in T 
if the k elements of A appear consecutively in some order. Hence we have 
X! possibilities to write A consecutively, and (n - k)! ways to order the 
remaining elements. So we conclude that a fixed set A appears in precisely 
k!(n - k)! cyclic permutations, and hence that 
k(n - I)! - 
(n - I)! 
- 
I F '  
k!(n - k)! 
(k - l)!(n - 1 - (k - I))! = (;I;). 
Again we may ask whether the families containing a fixed element are the 
only intersecting k-families. This is certainly not true for n = 2k. For 
example, for n = 4 and k = 2 the family (1.21, {1,3), {2,3) also has 
size (:)- = 3. More generally, for n = 2k we get the maximal intersecting 
X-families, of size $ (;) 
= (;I:), by arbitrarily including one out of every 
pair of sets formed by a k-set A and its complement N\A. But for n > 2k p 
0 
the special families containing a fixed element are indeed the only ones. 
The reader is invited to try his hand at the proof. 
An intersecting family for n = 4, k = 2 
Finally, we turn to the third result which is arguably the most important 
basic theorem in finite set theory, the "marriage theorem" of Philip Hall 
proved in 1935. It opened the door to what is today called matching theory, 
with a wide variety of applications, some of which we shall see as we 
go along. 
Consider a finite set X and a collection Al. . . . . A, of subsets of X (which 
need not be distinct). Let us call a sequence 21, . . . , x, a system of distinct 
representatives of {Al. . . . , A,) if the x, are distinct elements of X, and 
if x, E A, for all i. Of course, such a system, abbreviated SDR, need not 
exist, for example when one of the sets A, is empty. The content of the 
theorem of Hall is the precise condition under which an SDR exists. 

154 
Three famous theorems on finite sets 
"A mass wedding" 
{B. C, D) is a critical family 
Before giving the result let us state the human interpretation which gave it 
the folklore name marriage theorem: Consider a set (1, . . . , n) of girls and 
a set X of boys. Whenever x E Ai, then girl i and boy z 
are inclined to 
get married, thus Ai is just the set of possible matches of girl i. An SDR 
represents then a mass-wedding where every girl marries a boy she likes. 
Back to sets, here is the statement of the result. 
Theorem 3. Let A1,. . . , A, be a collection of subsets of a jinite set X. 
Then there exists a system of distinct representatives if and only if the union 
of any m sets Ai contains at least m elements, for 1 < m < n. 
The condition is clearly necessary: If m sets Ai contain between them 
fewer than m elements, then these m sets can certainly not be represented 
by distinct elements. The surprising fact (resulting in the universal ap- 
plicability) is that this obvious condition is also sufficient. Hall's original 
proof was rather complicated, and subsequently many different proofs were 
given, of which the following one (due to Easterfield and rediscovered by 
Halmos and Vaughan) may be the most natural. 
Proof. We use induction on 11. For n = 1 there is nothing to prove. Let 
n > 1, and suppose {Al,. . . , A,) satisfies the condition of the theorem 
which we abbreviate by (H). Call a collection of e sets Ai with 1 5 e < n a 
critical family if its union has cardinality e. Now we distinguish two cases. 
Case I :  There is no critical family. 
Choose any element x E A,. Delete x from X and consider the collection 
A:, . . . , Ahpl with A', = Ai\{x). Since there is no critical family, we find 
that the union of any m sets A: contains at least m elements. Hence by 
induction on n there exists an SDR XI,. . . , xnpl of {A:, . . . , A;-,), 
and 
together with x, = x, this gives an SDR for the original collection. 
Case 2: There exists a critical family. 
After renumbering the sets we may assume that {Al, . . . , Ae) is a critical 
e 
family. Then Ui=, Ai = 2 with 1x1 = l. Since t < n, we infer the exis- 
tence of an SDR for Al, . . . , At by induction, that is, there is a numbering 
z l , .  . . .xe of 2 such that xi E Ai for all i < e. 
Consider now the remaining collection 
. . , A,, and take any nz of 
these sets. Since the union of A1, . . . , At and these m sets contains at least 
e + m elements by condition (H), we infer that the m sets contain at least 
m elements outside 2. In other words, condition (H) is satisfied for the 
family 
A ~ + ~ \ Z ,  
. . . , A ~ \ Z .  
- 
Induction now gives an SDR for Ae+l, . . . , A, that avoids X. Combin- 
ing it with XI,. . . , xe we obtain an SDR for all sets Ai. This completes 
the proof. 
0 

Three famous theorems on finite sets 
155 
As we mentioned, Hall's theorem was the beginning of the now vast field 
of matching theory [6]. Of the many variants and ramifications let us state 
one particularly appealing result which the reader is invited to prove for 
himself: 
Suppose the sets Al. . . . , A, all have size k 2 1 and suppose 
further that no element is contained in more than k sets. Then 
there exist k SDR's such that for any i the k representatives of Ai 
are distinct and thus togetherform the set A,. 
A beautiful result which should open new horizons on marriage possi- 
bilities. 
References 
[I] T. E. EASTERFIELD: 
A combinatorial algorithm, J .  London Math. Soc. 21 
( 1946), 2 19-226. 
[2] P. ERDOS, C. KO & R. RADO: Intersection theoremsJCorsystems offinite sets, 
Quart. J. Math. (Oxford), Ser. (2) 12 (1961), 313-320. 
[3] P. HALL: On representatives of subsets, J .  London Math. Soc. 10 (1935), 
26-30. 
[4] P. R. HALMOS & H. E. VAUGHAN: 
The marriage problem, Amer. J .  Math. 
72 (1950), 214-215. 
[5] G. KATONA: 
A simple proof of the Erd6s-KO-Rado theorem, J .  Combinatorial 
Theory, Ser. B 13 (1972), 183- 184. 
[6] L. LovAsz & M. D. PLUMMER: 
Matching Theory, AkadCmiai Kiad6, Bu- 
dapest 1986. 
[7] D. LUBELL: 
A short proof of Sperner's theorem, J. Combinatorial Theory 1 
(1966). 299. 
[8] E. SPERNER: Ein Satz iiber Untermengen einer endlichen Menge, Math. 
Zeitschrift 27 (1928), 544-548. 

Shuffling cards 
Chapter 24 
How often does one have to shufle a deck of cards until it is random? 
The analysis of random processes is a familiar duty in life ("How long does 
it take to get to the airport during rush-hour?") as well as in mathematics. 
Of course, getting meaningful answers to such problems heavily depends 
on formulating meaningful questions. For the card shuffling problem, this 
means that we have 
0 to specify the size of the deck (n = 52 cards, say), 
0 to say how we shuffle (we'll analyze top-in-at-random shuffles first, 
and then the more realistic and effective riffle shuffles), and finally 
0 to explain what we mean by "is random" or "is close to random." 
So our goal in this chapter is an analysis of the riffle shuffle, due to Edgar 
N. Gilbert and Claude Shannon (1955, unpublished) and Jim Reeds (1981, 
unpubli$hed), following the statistician David Aldous and the former ma- 
gician turned mathematician Persi Diaconis according to [I]. We will not 
reach the final precise result that 7 riffle shuffles are sufficient to get a deck 
of n = 52 cards very close to random, while 6 riffle shuffles do not suf- 
fice - 
but we will obtain an upper bound of 12, and we will see some 
extremely beautiful ideas on the way: the concepts of stopping rules and 
of "strong uniform time," the lemma that strong uniform time bounds the 
variation distance, Reeds' inversion lemma, and thus the interpretation of 
shuffling as "reversed sorting." In the end, everything will be reduced to 
two very classical combinatorial problems, namely the coupon collector 
and the birthday paradox. So let's start with these! 
The birthday paradox 
Take n random people - 
the participants of a class or seminar, say. What 
is the probability that they all have different birthdays? With the usual 
Persi Diaconis' business card as a magi- 
simplifying assumptions (365 days a year, no seasonal effects, no twins 
cian. Inalater interview he said: "If you 
present) the probability is 
say that you are a professor at Stanford 
people treat you respectfully. If you say 
n-1 
i 
that you invent magic tricks, they don't 
~ ( n )  
= n 
(I-=)' 
want to introduce you to their daughter." 
i=l 

158 
Shuffling cards 
where at the end we sum a geometric 
series (see page 28). 
which is smaller than 
for n = 23 (this is the "birthday paradox"!), less 
than 9 percent for n = 42, and exactly 0 for n > 365 (the "pigeon-hole 
principle," see Chapter 22). The formula is easy to see - 
if we take the 
persons in some fixed order: If the first i persons have distinct birthdays, 
then the probability that the (i + 1)-st person doesn't spoil the series is 
1 - &, since there are 365 - i birthdays left. 
Similarly, if n  balls are placed independently and randomly into K boxes, 
then the probability that no box gets more than one ball is 
The coupon collector 
Children buy photos of pop stars (or soccer stars) for their albums, but they 
buy them in little non-transparent envelopes, so they don't know which 
photo they will get. If there are n  different photos, what is the expected 
number of pictures a kid has to buy until he or she gets every motif at 
least once? 
Equivalently, if you randomly take balls from a bowl that contains n  dis- 
tinguishable balls, and if you put your ball back each time, and then again 
mix well, how often do you have to draw on average until you have drawn 
each ball at least once? 
If you already have drawn k distinct balls, then the probability not to get 
a new one in the next drawing is 5. So the probability to need exactly s 
drawings for the next new ball is (&)"-I (1 - 5). And thus the expected 
number of drawings for the next new ball is 
as we get from the series in the margin. So the expected number of drawings 
until we have drawn each of the n  different balls at least once is 
n-1 
1 
n 
n 
n  
n 
-+- 
+...+ - + - = nH, 
E nlogn, 
n  
n - 1  
k=O 
2 
1 
with the bounds on the size of harmonic numbers that we had obtained on 
page 11. So the answer to the coupon collector's problem is that we have 
to expect that roughly n  log n  drawings are necessary. 
The estimate that we need in the following is for the probability that you 
need significantly more than n  log n  trials. If V, denotes the number of 
drawings needed (this is the random variable whose expected value is 
E[V,] = n  log n), then for n  > 1 and c > 0, the probability that we 
need more than m := 
log n + en1 drawings is 
Prob [v, > m] < e-' 

Shuffling cards 
159 
Indeed, if Ai denotes the event that the ball i is not drawn in the first m 
drawings, then 
 rob [v, > m] = Prob [ U A,] 5 
 rob [A,] 
i 
i 
Now let's grab a deck of n cards. We number them 1 up to n in the or- 
der in which they come - 
so the card numbered "1" is at the top of the 
deck, while "n" is at the bottom. Let us denote from now on by 6, 
the 
set of all permutations of 1. . . . , n. Shuffling the deck amounts to the ap- 
plication of certain random permutations to the order of the cards. Ide- 
ally, this might mean that we apply an arbitrary permutation T E 6, to 
our starting order (1,2, . . . , n), each of them with the same probability 5. 
Thus, after doing this just once, we would have our deck of cards in order 
T = ( ~ ( l ) ,  
7r(2), . . . , ~ ( n ) ) ,  
and this would be a perfcct random order. But 
that's not what happens in real life. Rather, when shuffling only "certain" 
permutations occur, perhaps not all of them with the same probability, and 
this is repeated a "certain" number of times. After that, we expect or hope 
the deck to be at least "close to random." 
Top-in-at-random shuffles 
These are performed as follows: you take the top card from the deck, and 
insert it into the deck at one of the n distinct possible places, each of them 
with probability i. 
Thus one of the permutations 
is applied, 1 < i < n. After one such shuffle the deck doesn't look random, 
and indeed we expect to need lots of such shuffles until we reach that goal. 
A typical run of top-in-at-random shuffles may look as follows (for n = 5): 
A little calculus shows that (1 - i) 
" is 
an increasing function in n, which con- 
verges to l/e. So (1 - ;)" 
< + holds 
for all n 2 1. 
How should we measure "being close to random"? Probabilists have cooked 
up the "variation distance" as a rather unforgiving measure of randomness: 
We look at the probability distribution on the n! different orderings of our 
deck, or equivalently, on the n! different permutations a E 6, 
that yield 
the orderings. 

160 
Shufling cards 
Two examples are our starting distribution E, which is given by 
E(id) = 1, 
E(T) 
= 0 
otherwise, 
and the uniform distribution U given by 
The variation distance between two probability distributions Q1 and Q2 is 
now defined as 
By setting S := {T E 6, : QI(T) > Qa(n)) and using CT Qi(r) = 
C, Q2 ( T )  = 1 we can rewrite this as 
with Qi(S) := CTES 
Qi(n). Clearly we have 0 I 
1141 - Qzll I 1. 
In the following, "being close to random" will be interpreted as "having 
small variation distance from the uniform distribution." Here the distance 
between the starting distribution and the uniform distribution is very close 
to 1: 
llE-UIl 
= 1-5. 
After one top-in-at-random shuffle, this will not be much better: 
For card players, the question is not 
The probability distribution on 6, that we obtain by applying the top-in-at- 
"exactly how close to uniform is the 
randomshuffle k times will bedenoted by  TO^*? So how does I I T O ~ * ~ - U I I  
deck after a million rifle shufles?", but 
behave if k gets larger, that is, if we repeat the shuffling? And similarly for 
"is 7 shufles enough?" 
other types of shuffling? General theory (in particular, Markov chains on 
(Aldous & Diaconis [I]) 
finite groups; see e. g. Behrends [3]) implies that for large k the variation 
distance d(k) := ll~op*'" - Ulj goes to zero exponentially fast, but it does 
not yield the "cut-off" phenomenon that one observes in practice: After a 
certain number ko of shuffles "suddenly" d ( k )  goes to zero rather fast. Our 
margin displays a schematic sketch of the situation. 
I 
Strong uniform stopping rules 
The amazing idea of strong uniform stopping rules by Aldous and Diaconis 
captures the essential features. Imagine that the casino manager closely 
watches the shuffling process, analyzes the specific permutations that are 
applied to the deck in each step, and after a number of steps that depends on 
the permutations that he has seen calls "STOP!". So he has a stopping rule 
that ends the shuffling process. It depends only on the (random) shuffles 
that have already been applied. The stopping rule is strong uniform if the 
following condition holds for all k > 0: 
If the process is stopped after exactly k steps, then the resulting 
permutations of the deck have uniform distribution (exactly!). 

Shuffling cards 
161 
Let T be the number of steps that are performed until the stopping rule 
tells the manager to cry "STOP!"; so this is a random variable. Similarly, 
the ordering of the deck after k shuffles is given by a random variable XI, 
(with values in 6,). 
With this, the stopping rule is strong uniform if for all 
feasible values of Ic, 
1 
Prob[xk = 7r I T = k ]  = - for all .ir E 6, 
n! 
Three aspects make this interesting, useful, and remarkable: 
1. Strong uniform stopping rules exist: For many examples they are quite 
simple. 
2. Moreover, these can be analyzed: Trying to determine Prob[T > k] 
leads often to simple combinatorial problems. 
3. This yields effective upper bounds on the variation distances such as 
d ( k )  = J I T O ~ * ~  
- - 1 1 .  
For example, for the top-in-at-random shuffles a strong uniform stopping 
rule is 
"STOP after the original bottom card (labelled n) is first inserted 
back into the deck." 
Indeed, if we trace the card n during these shuffles, 
Relative probabilities 
The relative probability 
denotes the probability of the event 
A under the condition that B hap- 
pens. This is just the probability that 
both events happen, divided by the 
probability that B is true, that is, 
Tl 
T2 
we see that during the whole process the ordering of the cards below this 
card is completely uniform. So, after the card n rises to the top and then is 
inserted at random, the deck is uniformly distributed; we just don't know 
when precisely this happens (but the manager does). 
Now let Ti 
be the random variable which counts the number of shuffles that 
are performed until for the first time i cards lie below card n. So we have 
to determine the distribution of 
T = T l + ( T z - T l ) +  . . . + (  T7,-1-Tn-2)+(T-Tn-1). 
But each summand in this corresponds to a coupon collector's problem: 
T, - Ti-1 is the time until the top card is inserted at one of the i possible 
places below the card n. So it is also the time that the coupon collector 
takes from the (n - 2)-th coupon to the (n - i + 1)-st coupon. Let V, be 
the number of pictures bought until he has i different pictures. Then 
Vn = Vl+(Vz-Vl)+ . . . + (  Vn-~-Vn-z)+(Vn-Vn-l), 

162 
Shuffling cards 
and we have seen that Prob[Ti - T,-1 = j] = Prob[V,-i+l - Vn-i = j] 
for all i and j. Hence the coupon collector and the top-in-at-random shuffler 
perform equivalent sequences of independent random processes, just in the 
opposite order (for the coupon collector, it's hard at the end). Thus we know 
that the strong uniform stopping rule for the top-in-at-random shuffles takes 
more than k = [n log n + cnl steps with low probability: 
And this in turn means that after k = [n logn + C I L ]  top-in-at-random 
shuffles, our deck is "close to random," with 
due to the following simple but crucial lemma. 
Lemma. Let Q : 6, - 
R be any probability distribution that defines a 
shufling process Q*k with a strong uniform stopping rule whose stopping 
time is T .  Then for all k > 0, 
Proof. I f  X is a random variable with values in 6 , ,  with probability 
distribution Q, then we write Q ( S )  for the probability that X takes a value 
in S c 6 , .  Thus Q ( S )  = Prob[X E S ] ,  and in the case of the uniform 
distribution Q = U we get 
For every subset S C 6 , ,  we get the probability that after k steps our deck 
is ordered according to a permutation in S as 
Q * ~ ( s )  = Prob[Xk E S] 
= x P r o b [ X k  E S A T = j] + Prob[Xr: E S A T > k] 
jIk 
= x U ( S ) P r o b [ T  = j] + Prob[Xk E S I T  > k] .Prob[T > k] 
j l k  
= U ( S )  ( 1  - Prob[T > k ] )  + Prob[Xk E S I T > k] . Prob[T > k] 
= U(S) + (prob[Xk E S I T > k] - u(s)) 
. Prob[T > k]. 
This yields 
~Q*"s) - U(S)l 5 Prob[T > k] 
since 
Prob[Xk E S I T > k] - U(S) 
is a difference of two probabilities, so it has absolute value at most 1. 
This is the point where we have completed our analysis of the top-in-at- 
random shuffle: We have proved the following upper bound for the number 
of shuffles needed to get "close to random." 

Shuffling cards 
163 
Theorem 1. Let c > 0 and k := [n log n + cnl . Then after peiforming k 
top-in-at-random shuffles on a deck qf n cards, the variation distance,from 
the uniform distribution satisjies 
One can also verify that the variation distance d ( k )  stays large if we do 
significantly fewer than n log n top-in-at-random shuffles. The reason is 
that a smaller number of shuffles will not suffice to destroy the relative 
ordering on the lowest few cards in the deck. 
Of course, top-in-at-random shuffles are extremely ineffective - 
with the 
bounds of our theorem, we need roughly n log n -- 205 top-in-at random 
shuffles until a deck of n = 52 cards is mixed up well. Thus we now switch 
our attention to a much more interesting and realistic model of shuffling. 
Riffle shuffles 
This is what dealers do at the casino: They take the deck, split it into two 
parts, and these are then interleaved, for example by dropping cards from 
the bottoms of the two half-decks in some irregular pattern. 
Again a riffle shuffle performs a certain permutation on the cards in the 
deck, which we initially assume to be labelled from 1 to n, where 1 is the 
top card. The riffle shuffles correspond exactly to the permutations T E 6, 
such that the sequence 
consists of two interlaced increasing sequences (only for the identity per- 
mutation it is one increasing sequence), and that there are exactly 2n - n 
distinct riffle shuffles on a deck of n cards. 
In fact, if the pack is split such that the top t cards are taken into the right 
hand (0 < t < n) and the other n - t cards into the left hand, then there are 
(?) ways to interleave the two hands, all of which generate distinct permu- 
tations - 
except that for each t there is one possibility to obtain the identity 
permutation. 
A riffle shuffle 
Now it's not clear which probability distribution one should put on the riffle 
shuffles - 
there is no unique answer since amateurs and professional deal- 
ers would shuffle differently. However, the following model, developed 
first by Edgar N. Gilbert and Claude Shannon in 1955 (at the legendary 

164 
Shuflinn cards 
Bell Labs "Mathematics of Communication" department at the time), has 
several virtues: 
0 it is elegant, simple, and seems natural, 
0 it models quite well the way an amateur would perform riffle shuffles, 
a and we have a chance to analyze it. 
Here are three descriptions - 
all of them describe the same probability 
distribution Rif on 6,: 
1. Rif : 6, + R is defined by 
"G1 
if .ir = id, 
if .ir consists of two increasing sequences, 
otherwise. 
The inverse riffle shuffles correspond to 
the permutations .ir = ( ~ ( 1 ) .  
. . . . ~ ( n ) )  
that are increasing except for at most 
one "descent." (Only the identity per- 
mutation has no descent.) 
Cut off t cards from the deck with probability & (1)' take them into 
your right hand, and take the rest of the deck into your left hand. Now 
when you have r cards in the right hand and t in the left, "drop" the 
bottom card from your right hand with probability 5, 
and from your 
left hand with probability &. Repeat! 
An inverse shufle would take a subset of the cards in the deck, remove 
them from the deck, and place them on top of the remaining cards of 
the deck - 
while maintaining the relative order in both parts of the 
deck. Such a move is determined by the subset of the cards: Take all 
subsets with equal probability. 
Equivalently, assign a label "0" or "1" to each card, randomly and in- 
dependently with probabilities +, and move the cards labelled "0" to 
the top. 
It is easy so see that these descriptions yield the same probability distri- 
butions. For (1) * 
(3) just observe that we get the identity permutation 
whenever all the 0-cards are on top of all the cards that are assigned a 1. 
This defines the model. So how can we analyze it? How many riffle shuffles 
are needed to get close to random? We won't get the precise best-possible 
answer, but quite a good one, by combining three components: 
(1) We analyze inverse riffle shuffles instead, 
(2) we describe a strong uniform stopping rule for these, 
(3) and show that the key to its analysis is given by the birthday paradox! 
Theorem 2. After per$orming k rifle shufles on a deck of n cards, the 
variation distance from a uniform distribution satisjies 

Shufling cards 
165 
Proof. (1) We may indeed analyze inverse riffle shuffles and try to see 
how fast they get us from the starting distribution to (close to) uniform. 
These inverse shuffles correspond to the probability distribution that is given 
by Rif(.i;) := Rif(n-l). 
Now the fact that every permutation has its unique inverse, and the fact that 
U(T) = U(T-l), yield 
(This is Reeds' inversion lemma!) 
(2) In every inverse riffle shuffle, each card gets associated a digit 0 or 1: 
If we remember these digits - 
say we just write them onto the cards - 
then after k inverse riffle shuffles, each card has gotten an ordered string of 
k digits. Our stopping rule is: 
"STOP as soon as all cards have distinct strings." 
When this happens, the cards in the deck are sorted according to the binary 
numbers bkbkPl . . . b2bl, where b, is the bit that the card has picked up 
in the i-th inverse riffle shuffle. Since these bits are perfectly random and 
independent, this stopping rule is strong uniform! 
In the following example, for n = 5 cards, we need T = 3 inverse shuffles 
until we stop: 
(3) The expected time T taken by this stopping rule is distributed according 
to the birthday paradox, for K = 2k: We put two cards into the same box 
if they have the same label bkbkPl . . . b2bl E (0, lIk. SO there are K = 2k 
boxes, and the probability that some box gets more than one card ist 
and as we have seen this bounds the variation distance  if*^ - UU/I = 
U/IRZ*~ 
- UII. 
0 

Shuffling cards 
The variation distance after k riffle shuf- 
fles, according to [2] 
So how often do we have to shuffle? For large n we will need roughly 
k = 2 logz(n) shuffles. Indeed, setting k := 2 log,(cn) for some c > 1 we 
find (with a bit of calculus) that P[T > I;] -- 1 - c
h
 = &. 
Explicitly, for n = 52 cards the upper bound of Theorem 2 reads d(10) < 
0.73, d(12) < 0.28, d(14) 5 0.08 - 
so k = 12 should be "random 
enough" for all practical purposes. But we don't do 12 shuffles "in practice" 
- 
and they are not really necessary, as a more detailed analysis shows 
(with the results given in the margin). The analysis of riffle shuffles is part 
of a lively ongoing discussion about the right measure of what is "random 
enough." Diaconis [4] is a guide to recent developments. 
Indeed, does it matter? Yes, it does: Even after three good riffle shuffles a 
sorted deck of 52 cards looks quite random . . .but it isn't. Martin Gardner 
[5, Chapter 71 describes a number of striking card tricks that are based on 
the hidden order in such a deck! 
References 
D. ALDOUS & P. DIACONIS 
: Shufling cards and stopping times, Amer. Math. 
Monthly 93 (1986), 333-348. 
D. BAYER & P. DIACONIS: Trailing the dovetail shufJle to its lair, Annals 
Applied Probability 2 ( l992), 294-3 13. 
E. BEHRENDS: Introduction to Markov Chains, Vieweg, Braunschweigl 
Wiesbaden 2000. 
P. DIACONIS: 
Mathematical developments from the analysis of rifle shufling, 
in: "Groups, Combinatorics and Geometry. Durham 2001" (A. A. Ivanov, M. 
W. Liebeck and J. Saxl, eds.), World Scientific, Singapore 2003, pp. 73-97. 
M. GARDNER: 
Mathematical Magic Show, Knopf, New YorkIAllen & Unwin, 
London 1977. 
E. N. GILBERT: Theory of Shufling, Technical Memorandum, Bell Laborato- 
ries, Murray Hill NJ, 1955. 
Random enough? 

Lattice paths and determinants 
Chapter 25 
The essence of mathematics is proving theorems - 
and so, that is what 
mathematicians do: They prove theorems. But to tell the truth, what they 
really want to prove, once in their lifetime, is a Lemma, like the one by 
Fatou in analysis, the Lemma of Gauss in number theory, or the Burnside- 
Frobenius Lemma in combinatorics. 
Now what makes a mathematical statement a true Lemma? First, it should 
be applicable to a wide variety of instances, even seemingly unrelated prob- 
lems. Secondly, the statement should, once you have seen it, be completely 
obvious. The reaction of the reader might well be one of faint envy: Why 
haven't I noticed this before? And thirdly, on an esthetic level, the Lemma 
- 
including its proof - 
should be beautiful! 
In this chapter we look at one such marvelous piece of mathematical rea- 
soning, a counting lemma that first appeared in a paper by Bernt Lindstrom 
in 1972. Largely overlooked at the time, the result became an instant classic 
in 1985, when Ira Gessel and Gerard Viennot rediscovered it and demon- 
strated in a wonderful paper how the lemma could be successfully applied 
to a diversity of difficult combinatorial enumeration problems. 
The starting point is the usual permutation representation of the determinant 
of a matrix. Let h1 = (m,,) be a real n x n-matrix. Then 
where 5 runs through all permutations of {1,2, . . . , n), and the sign of 5 
is 1 or -1, depending on whether u is the product of an even or an odd 
number of transpositions. 
Now we pass to graphs, more precisely to weighteddirected bipartite graphs. A, 
Let the vertices Al, . . . , A, stand for the rows of M ,  and B1,. . . , B, for 
the columns. For each pair of i and j draw an arrow from A, to Bj and give 
mij 
it the weight m,, , as in the figure. 
In terms of this graph, the formula (1) has the following interpretation: 
mnn 
0 The left-hand side is the determinant of the path-matrix M, whose 
(i, j)-entry is the weight of the (unique) directed path from Ai to Bj. 
B1 
Bj 
B, 
0 The right-hand side is the weighted (signed) sum over all vertex-disjoint 
path systems from A = { A l , .  . . ,A,) to B = {B1,. . . , B,). Such a 
system P, is given by paths 

168 
Lattice paths and determinants 
and the weight of the path system 'P, is the product of the weights of 
the individual paths: 
In this interpretation formula (1) reads 
det h = x signa w(Pu) 
0 
An acyclic directed graph 
And what is the result of Gessel and Viennot? It is the natural generalization 
of (1) from bipartite to arbitrary graphs. It is precisely this step which 
makes the Lemma so widely applicable - 
and what's more, the proof is 
stupendously simple and elegant. 
Let us first collect the necessary concepts. We are given a finite acyclic 
directed graph G = (V, E), where acyclic means that there are no directed 
cycles in G. In particular, there are only finitely many directed paths 
between any two vertices A and B, where we include all trivial paths 
A + A of length 0. Every edge e carries a weight w(e). If P is a 
directed path from A to B, written shortly P : A 4 B, then we define 
the weight of P as 
w(P) := n u r ( r ) ,  
eEP 
which is defined to be w(P) = 1 if P is a path of length 0. 
Now let A = {Al, . . . ,A,) and B = {Bl, . . . , B,) be two sets of n 
vertices, where A and B need not be disjoint. To A and B we associate the 
path matrix hi' = (m,,) with 
A path system P from A to B consists of a permutation a together with n 
paths P, : A, + Bu(i), 
for i = 1,. . . ,n; we write sign P = signa . The 
weight of P is the product of the path weights 
which is the product of the weights of all the edges of the path system. 
Finally, we say that the path system P = (PI,. . . , P,) is vertex-disjoint if 
the paths of P are pairwise vertex-disjoint. 
Lemma. 
Let G = (V, E) be a Jinite weighted acyclic directed graph, 
A = {A1.. . . . A,) and B = {B1,. . . , B,) two n-sets ($vertices, and M 
the path matrix from A to B. Then 
P vertex-disjoint 
path system 

Lattice paths and determinants 
169 
Proof. A typical summand of det(A1) is sign a r n ~ , ( ~ j  
. . . rn,,(,), 
which can be written as 
Summing over a we immediately find from (2) that 
drt A I  = x s i g n  P w(P). 
P 
where P runs through all path systems from A to B (vertex-disjoint or not). 
Hence to arrive at (3), all we have to show is 
where N is the set of all path systems that are not vertex-disjoint. And this 
is accomplished by an argument of singular beauty. Namely, we exhibit an 
involution T : N 4 N (without fixed points) such that for P and TP 
~ ( T P )  = w(P) 
and 
signnP = -signP 
Clearly, this will imply (4) and thus the formula (3) of the Lemma. 
The involution T is defined in the most natural way. Let P E N with paths 
A,, 
4, 
Pi : Ai -+ 
B,(i). By definition, some pair of paths will intersect: 
0 Let io be the minimal index such that P,,, shares some vertex with 
another path. 
0 Let X be the first such common vertex on the path Pi,, . 
0 Let jo be the minimal index (jo > io) such that P,,, has the vertex X 
in common with P,, . 
Now we construct the new system TP = (Pi.. . . , PA) as follows: 
0 Set PL = Pk for all k # zo, jo. 
The new path P,, goes from A,, to X along P,,, and then continues 
to B,(,,,) along P,,,. Similarly, P;,] goes from A,,, to X along P,,, and 
continues to B,(,, along P,, . 
Clearly ~ ( n p )  
= P ,  since the index Lo, the vertex X, and the index jo are 
the same as before. In other words, applying T twice we switch back to 
the old paths P,. Next, since -irP and P use precisely the same edges, we 
certainly have w(-irP) = ZU(P). And finally, since the new permutation a' 
is obtained by multiplying a with the transposition (io, 
jo), we find that 
sign TP = -sign P , and that's it. 
0 
The Gessel-Viennot Lemma can be used to derive all basic properties of 
determinants, just by looking at appropriate graphs. Let us consider one 
particularly striking example, the formula of Binet-Cauchy, which gives a 
very useful generalization of the product rule for determinants. 

170 
Lattice paths and determinants 
Theorem. If P is an ( r  x s)-matrix and Q an ( s  x r)-matrix, r < s, then 
where P2 is the ( r  x r)-submatrix of P with column-set 2, and Q2 the 
( r  x r)-submatrix of Q with the corresponding rows Z. 
Proof. Let the bipartite graph on A and f? correspond to P as before, and 
similarly the bipartite graph on B and C to Q. Consider now the concate- 
nated graph as indicated in the figure on the left, and observe that the (i, j)- 
entry mij of the path matrix M from A to C is precisely mi:, = Ck 
p i k q k 3 ,  
thus A f  = PQ. 
Since the vertex-disjoint path systems from A to C in the concatenated 
graph correspond to pairs of systems from A to 2 resp. from 2 to C, the 
result follows immediately from the Lemma, by noting that sign (or) 
= 
(sign a )  (sign r). 
0 
The Lemma of Gessel-Viennot is also the source of a great number of re- 
sults that relate determinants to enumerative properties. The recipe is al- 
ways the same: Interpret the matrix M as a path matrix, and try to compute 
the right-hand side of (3). As an illustration we will consider the original 
problem studied by Gessel and Viennot, which led them to their Lemma: 
Suppose that al < az < . . . < a, and bl < ba < . . . < b, are two 
sets of natural numbers. We wish to compute the determinant of the 
matrix M = (mij), 
where mij is the binomial coeflcient (a". 
bj 
In other words, Gessel and Viennot were looking at the determinants of 
arbitrary square matrices of Pascal's triangle, such as the matrix 
given by the bold entries of Pascal's triangle, as displayed in the margin. 
As a preliminary step to the solution of the problem we recall a well-known 
result which connects binomial coefficients to lattice paths. Consider an 
a x b-lattice as in the margin. Then the number of paths from the lower 
left-hand corner to the upper right-hand comer, where the only steps that 
are allowed for the paths are up (North) and to the right (East), is (a:b). 
The proof of this is easy: each path consists of an arbitrary sequence of b 
"east" and a "north" steps, and thus it can be encoded by a sequence of the 
form NENEEEN, consisting of a+ b letters, a N's and b E's. The number of 
such strings is the number of ways to choose a positions of letters N from 
a total of a + b positions, which is (a:b) = (atb). 

Lattice paths and determinants 
171 
Now look at the figure to the right, where A, is placed at the point (0, -ai) 
and B, at ( b j ,  -bj). 
The number of paths from Ai to B, in this grid that use only steps to the 
north and east is, by what we just proved, ( b 3 + ( " ' p b ~ )  
b, 
) = (z;). In other 
words, the matrix of binomials A f  is precisely the path matrix from A to B 
in the directed lattice graph for which all edges have weight 1, and all edges 
are directed to go north or east. Hence to compute det AP we may apply 
the Gessel-Viennot Lemma. A moment's thought shows that every vertex- 
disjoint path system P from A to &? must consist of paths Pi : Ai -, B, for 
all i. Thus the only possible permutation is the identity, which has sign = 1, 
and we obtain the beautiful result 
det ((:;I) 
= # vertex-disjoint path systems from A to R. 
f
e
e
*
 
In particular, this implies the far from obvious fact that det M is always 
An ( 
nonnegative, since the right-hand side of the equality counts something. 
More precisely, one gets from the Gessel-Viennot Lemma that det M = 0 
if and only if a, < b, for some i. 
In our previous small example, 
3 (3 (3 
vertex-disjoint 
' 
path systems in 
4 
? 
(!? (3 
Lattice paths " 

172 
Lattice paths and determinants 
References 
[ I ]  I. M. GESSEL & G. VIENNOT: Binomial determinants, paths, and hook length 
formulae, Advances in Math. 58 ( 1985), 300-32 1. 
[2] B. LINDSTROM: On the vector representation of induced matroids, Bulletin 
London Math. Soc. 5 (1973), 85-90. 

Cayley's formula 
Chapter 26 
for the number of trees 
One of the most beautiful formulas in enumerative combinatorics concerns 
the number of labeled trees. Consider the set N = {1,2, . . . , n). How 
many different trees can we form on this vertex set? Let us denote this 
number by T,. Enumeration "by hand" yields TI = 1, T2 = 1, T3 = 3, 
T4 = 16, with the trees shown in the following table: 
Note that we consider labeled trees, that is, although there is only one tree 
of order 3 in the sense of graph isomorphism, there are 3 different labeled 
trees obtained by marking the inner vertex 1, 2 or 3. For n = 5 there are 
three non-isomorphic trees: 
For the first tree there are clearly 5 different labelings, and for the second 
and third there are 
= 60 labelings, so we obtain T5 = 125. This should 
be enough to conjecture T, = nnP2, 
and that is precisely Cayley's result. 
."eorem. 
mere are nn-2 diferent labeled trees on n vertices. 
\.-I- 
Arthur Cayley 
This beautiful formula yields to equally beautiful proofs, drawing on a 
variety of combinatorial and algebraic techniques. We will outline three 
of them before presenting the proof which is to date the most beautiful of 
them all. 

174 
Cavlev's formula for the number o f  trees 
T2 1 1  L 
The four trees of I2 
First proof (Bijection). The classical and most direct method is to find 
a bijection from the set of all trees on n vertices onto another set whose 
cardinality is known to be nn-2. Naturally, the set of all ordered sequences 
( a l ,  . . . , an-2) with 1 5 ai < n comes into mind. Thus we want to 
uniquely encode every tree T by a sequence (a1 . . . , a,-2). Such a code 
was found by Priifer and is contained in most books on graph theory. 
Here we want to discuss another bijection proof, due to Joyal, which is 
less known but of equal elegance and simplicity. For this, we consider not 
just trees t  on N = ( 1 ,  . . . , n} but trees together with two distinguished 
vertices, the left end 0 
and the right end 0, 
which may coincide. Let 
In = { ( t :  0, 
0)) 
be this new set; then, clearly, jTnl = n 2 ~ , .  
Our goal is thus to prove 17,) = nn. Now there is a set whose size is 
known to be nn, namely the set NN of all mappings from N into N. Thus 
our formula is proved if we can find a bijection from NN onto In. 
Let f : N - 
N be any map. We represent f as a directed graph Gf 
by 
drawing arrows from i to f (2). 
For example, the map 
is represented by the directed graph in the margin. 
Look at a component of Gf. 
Since there is precisely one edge emanating 
from each vertex, the component contains equally many vertices and edges, 
and hence precisely one directed cycle. Let M 2 N be the union of the 
vertex sets of these cycles. A moment's thought shows that M is the unique 
maximal subset of N such that the restriction o f f  onto M acts as a bijection 
a  
b 
. . .  
z 
on Al. Write f 1 
= 
such that the numbers 
a, b, . . . , z  in the first row appear in natural order. This gives us an ordering 
f ( a ) ,  f (b), . . . . f ( z )  of hl according to the second row. Now f (a) is our 
left end and f ( z )  is our right end. 
The tree t corresponding to the map f is now constructed as follows: Draw 
f ( a ) ,  . . . , f ( z )  in this order as a path from f (a) to f ( z ) ,  and fill in the 
remaining vertices as in Gf 
(deleting the arrows). 
In our example above we obtain M = {1,4,5,7,8, 9 )  
and thus the tree t depicted in the margin. 
It is immediate how to reverse this correspondence: Given a tree t ,  we look 
at the unique path P from the left end to the right end. This gives us the 
set M and the mapping f 1 M .  The remaining correspondences i 4 f (i) are 
then filled in according to the unique paths from i to P. 
0 

Cayley's formula for the number of trees 
175 
Second proof (Linear Algebra). We can think of T, as the number of 
spanning trees in the complete graph K,. Now let us look at an arbitrary 
connected simple graph G on V = (1.2, . . . , n), denoting by t(G) the 
number of spanning trees; thus Tn = t(K,). 
The following celebrated 
result is Kirchhoff's matrix-tree theorem (see [I]). Consider the incidence 
matrix B = (bZe) of G, whose rows are labeled by V, the columns by E, 
where we write b,, = 1 or 0 depending on whether i E e or z 6 
e. Note that 
(El 2 n - 1 since G is connected. In every column we replace one of the 
two 1's by - 1 in an arbitrary manner (this amounts to an orientation of G), 
and call the new matrix C. &I = CCT is then a symmetric (n x n)-matrix 
with the degrees d l ,  . . . , d, in the main diagonal. 
Proposition. We have t(G) = det &I,, for all z = 1, . . . , n, where Aft, 
results from A1 by deleting the z-th row and the i-th column. 
Proof. The key to the proof is the Binet-Cauchy theorem proved in the 
previous chapter: When P is an ( r  x s)-matrix and Q an (s x r)-matrix, 
r 5 s, then det(PQ) equals the sum of the products of determinants of 
corresponding ( r  x r)-submatrices, where "corresponding" means that we 
take the same indices for the r columns of P and the r rows of Q. 
For Al,, this means that 
det Af,, = EN 
det N det N~ = x N ( d e t  N ) ~ ,  
where N runs through all (n - 1) x ( n  - 1) submatrices of C\{row z). The 
n - 1 columns of N correspond to a subgraph of G with n - 1 edges on n 
vertices, and it remains to show that 
{ 
f 
1 if these edges span a tree 
det N = 
0 otherwise. 
Suppose the n - 1 edges do not span a tree. Then there exists a component 
which does not contain z. Since the corresponding rows of this component 
add to 0, we infer that they are linearly dependent, and hence det N = 0. 
Assume now that the columns of N span a tree. Then there is a ver- 
"A nonstandard method of counting 
tex 31 # z of degree 1; let el be the Incident edge. Deletlng 31, el we 
treer: Put a cat into each tree, walk your 
obtain a tree with n - 2 edges. Again there is a vertex j 2  # z of de- 
dog, and count how often he barks." 
gree 1 with incident edge e2. Continue in this way until 31, J Z ,  . . . , Jn-l 
and e l ,  ~
2
,
 
. . . , enFl with j, E e, are determined. Now permute the rows 
and columns to brmg 31, into the k-th row and el, into the k-th column. 
Since by construction 31, $!! 
ee for k < l, we see that the new matrix N' is 
lower triangular with all elements on the main diagonal equal to f 
1. Thus 
det N = f 
det N' = f 
1, and we are done. 
For the special case G = Kn we clearly obtain 
n - 1  
-1 
. . .  
- 1 
-1 
n - 1  
hit, = 
... 
) 
-1 
-1 
... n - 1  
and an easy computation shows det Mii = n7"'. 

176 
Cayley's formula for the number of trees 
1 Third proof (Recursion). Another classical method in enumerative 
combinatorics is to establish a recurrence relation and to solve it by 
induction. The following idea is essentially due to Riordan and RCnyi. 
To find the proper recursion, we consider a more general problem (which 
already appears in Cayley's paper). Let A be an arbitrary k-set of the 
vertices. By Tn.k 
we denote the number of (labeled) forests on {I,. . . , n )  
consisting of k trees where the vertices of A appear in different trees. 
Clearly, the set A does not matter, only the size k. Note that Tn,l 
= Tn. 
For example, T4.2 = 8 for A = {1,2) 
3
4
3
4
3
4
3
4
3
4
3
4
3
4
3
4
 
Consider such a forest F with A = {1,2,. . . , k ) ,  and suppose 1 is adja- 
cent to i vertices, as indicated in the margin. Deleting 1, the i neighbors 
together with 2, . . . , k yield one vertex each in the components of a forest 
k 
that consists of k - 1 + i trees. As we can (re)construct F by first fixing i, 
then choosing the i neighbors of 1 and then the forest F\1, this yields 
for all n > k > 1, where we set To,o 
= 1, T,,o = 0 for n > 0. Note that 
T0.o = 1 is necessary to ensure T,,, = 1. 
Proposition. We have 
T,,k = knn-"l 
and thus, in particular; 
Proof. By (I), and using induction, we find 

Cayley's formula for the number of trees 
177 
Fourth proof (Double Counting). The following marvelous idea due 
to Jim Pitman gives Cayley's formula and its generalization (2) without 
induction or bijection - 
it is just clever counting in two ways. 
A rooted forest on (1, . . . n )  is a forest together with a choice of a root in 
each component tree. Let Fn,k be the set of all rooted forests that consist 
of k rooted trees. Thus F n , ~  
is the set of all rooted trees. 
Note that 1Fn,l 1 = 'nT,, since in every tree there are n choices for the root. 
We now regard F,.k 
E F,,,, as a directed graph with all edges directed 
away from the roots. Say that a forest F contains another forest F' if F 
contains F' as directed graph. Clearly, if F properly contains F', then F 
has fewer components than F'. The figure shows two such forests with the 
roots on top. 
Here is the crucial idea. Call a sequence Fl, . . . , Fk of forests a rejnirzg 
sequence if Fi E FTL,, 
and Fi contains F,+l, for all i. 
Now let Fk be a fixed forest in Fn.k and denote 
by N(Ek) the number of rooted trees containing Fk, and 
by N*(Fk) the number of refining sequences ending in Fk. 
We count N*(Fk) in two ways, first by starting at a tree and secondly by 
starting at Fk. Suppose Fl E 3n,1 
contains Fk. Since we may delete 
the k - 1 edges of Fl\Fk in any possible order to get a refining sequence 
from Fl to Fk, we find 
Let us now start at the other end. To produce from Fk an FkP1 we have to 
add a directed edge, from any vertex a, to any of the k - 1 roots of the trees 
that do not contain a (see the figure on the right, where we pass from F3 
to F2 by adding the edge 3-7). 
Thus we have n(k - 1) choices. 
Similarly, for FkP1 we may produce a directed edge from any vertex b to 
any of the k - 2 roots of the trees not containing b. For this we have n(k - 2) 
choices. Continuing this way, we arrive at 
and out comes, with (3), the unexpectedly simple relation 
N ( F k )  = nk-' 
for any Fk E Fn,k. 
For k = n, Fn consists just of n isolated vertices. Hence N(F,) counts the 
number of all rooted trees, and we obtain l F n , ~  
1 = nn-l, and thus Cayley's 
formula. 
0 
But we get even more out of this proof. Formula (4) yields for k = n: 
#{refining sequences ( F I ,  F2, . . . , F,)) = nn-'(n - I)!. 
(5) 
Fz contains Fs 
For F k ~ 3 n , k ,  
let N**(Fk) denote the number of those refining sequences 
Fl. . . . . F, whose k-th term is Fk. Clearly this is N* (Fk) times the number 

178 
Cavlev's formula for the number o f  trees 
of ways to choose (Fk+l, . . . , F,). But this latter number is ( n  - k)! since 
we may delete the n - k edges of Fk in any possible way, and so 
N**(Fk) = N*(Fk)(n - k)! = nk-'(k - l ) ! ( n  - k)!. 
(6) 
Since this number does not depend on the choice of Fk, dividing (5) by (6) 
yields the number of rooted forests with k trees: 
As we may choose the k roots in (;) 
possible ways, we have reproved the 
formula T,,k = knn-lc-l without recourse to induction. 
Let us end with a historical note. Cayley's paper from 1889 was anticipated 
by Carl W. Borchardt (1 86O), and this fact was acknowledged by Cayley 
himself. An equivalent result appeared even earlier in a paper of James J. 
Sylvester (1857), see [2, Chapter 31. The novelty in Cayley's paper was 
the use of graph theory terms, and the theorem has been associated with his 
name ever since. 
References 
[I] M. AIGNER: 
Combinatorial Theory, Springer-Verlag, Berlin Heidelberg New 
York 1979; Reprint 1997. 
[2] N. L. BIGGS, E. K. LLOYD & R. J. WILSON: Graph Theory 1736-1936, 
Clarendon Press, Oxford 1976. 
[3] A. CAYLEY: 
A theorem on trees, Quart. J .  Pure Appl. Math. 23 (1889), 
376-378; Collected Mathematical Papers Vol. 13, Cambridge University Press 
1897, 26-28. 
[4] A. JOYAL: Une the'orie combinatoire des se'ries formelles, Advances in Math. 
42 (1981), 1-82. 
[s] J. PITMAN: 
Coalescent random forests, J. Combinatorial Theory, Ser. A 85 
(1999), 165-193. 
[6] H. PRUFER: 
Neuer Beweis eines Satzes iiber Permutationen, Archiv der Math. 
u. Physik (3) 27 (1918), 142-144. 
[7] A. RENYI: Some remarks on the theory of trees. MTA Mat. Kut. Inst. Kozl. 
(Publ. math. Inst. Hungar. Acad. Sci.) 4 (1959), 73-85; Selected Papers Vol. 2, 
AkadCmiai Kiad6, Budapest 1976, 363-374. 
[8] J. RIORDAN: 
Forests of labeled trees, J. Combinatorial Theory 5 (1968), 
90- 103. 

Completing Latin squares 
Some of the oldest combinatorial objects, whose study apparently goes 
back to ancient times, are the Latin squares. To obtain a Latin square, 
one has to fill the n2 cells of an (n x n)-square array with the numbers 
1.2, . . . , n so that that every number appears exactly once in every row and 
in every column. In other words, the rows and columns each represent per- 
mutations of the set (1, . . . , n). Let us call n the order of the Latin square. 
Here is the problem we want to discuss. Suppose someone started filling 
the cells with the numbers {1,2,. . . , n). At some point he stops and asks 
us to fill in the remaining cells so that we get a Latin square. When is this 
possible? In order to have a chance at all we must, of course, assume that 
at the start of our task any element appears at most once in every row and 
in every column. Let us give this situation a name. We speak of a partial 
Latin square of order n if some cells of an (n x n)-array are filled with 
numbers from the set (1, . . . , n )  such that every number appears at most 
once in every row and column. So the problem is: 
When can a partial Latin square be completed to a Latin square of 
the same order? 
Let us look at a few examples. Suppose the first n - 1 rows are filled and 
the last row is empty. Then we can easily fill in the last row. Just note that 
every element appears n - 1 times in the partial Latin square and hence is 
missing from exactly one column. Hence by writing each element below 
the column where it is missing we have completed the square correctly. 
Going to the other end, suppose only the first row is filled. Then it is again 
easy to complete the square by cyclically rotating the elements one step in 
each of the following rows. 
So, while in our first example the completion is forced, we have lots of 
possibilities in the second example. In general, the fewer cells are pre- 
filled, the more freedom we should have in completing the square. 
However, the margin displays an example of a partial square with only n 
cells filled which clearly cannot be completed, since there is no way to fill 
the upper right-hand corner without violating the row or column condition. 
I f  fewer than n cells are Jilled in an (n x n)-array, can one then 
always complete it to obtain a Latin square? 
Chapter 27 
A Latin square of order 4 
A cyclic Latin square 
A partial Latin square that cannot be 
completed 

180 
Completing Latin squares 
If we permute the lines of the above 
example cyclically, 
R + C - 
E + R, then we 
obtain the following line array and 
Latin square: 
This question was raised by Trevor Evans in 1960, and the assertion that 
a completion is always possible quickly became known as the Evans con- 
jecture. Of course, one would try induction, and this is what finally led 
to success. But Bohdan Smetaniuk's proof from 1981, which answered 
the question, is a beautiful example of just how subtle an induction proof 
may be needed in order to do such a job. And, what's more, the proof is 
constructive, it allows us to complete the Latin square explicitly from any 
initial partial configuration. 
Before proceeding to the proof let us take a closer look at Latin squares 
in general. We can alternatively view a Latin square as a (3 x n2)-array, 
called the line array of the Latin square. The figure to the left shows a Latin 
square of order 3 and its associated line array, where R, C and E stand for 
rows, columns and elements. 
The condition on the Latin square is equivalent to saying that in any two 
lines of the line array all n2 ordered pairs appear (and therefore each pair 
appears exactly once). Clearly, we may permute the symbols in each line 
arbitrarily (corresponding to permutations of rows, columns or elements) 
and still obtain a Latin square. But the condition on the (3 x n2)-array tells 
us more: There is no special role for the elements. We may also permute 
the lines of the array (as a whole) and still preserve the conditions on the 
line array and hence obtain a Latin square. 
Latin squares that are connected by any such permutation are called con- 
jugates. Here is the observation which will make the proof transparent: 
A partial Latin square obviously corresponds to a partial line array (every 
pair appears at most once in any two lines), and any conjugate of a partial 
Latin square is again a partial Latin square. In particular, a partial Latin 
square can be completed if and only if any conjugate can be completed Gust 
complete the conjugate and then reverse the permutation of the three lines). 
We will need two results, due to Herbert J. Ryser and to Charles C. Lindner, 
that were known prior to Smetaniuk's theorem. If a partial Latin square is 
of the form that the first r rows are completely filled and the remaining cells 
are empty, then we speak of an (r x n)-Latin rectangle. 
Lemma 1. Any (r x n)-Latin rectangle, r < n, can be extended to an 
( ( r  + 1 )  x n)-Latin rectangle and hence can be completed to a Latin square. 
Proof. We apply Hall's theorem (see Chapter 23). Let Aj be the set 
of numbers that do not appear in column j. An admissible (r + 1)-st row 
corresponds then precisely to a system of distinct representatives for the 
collection Al, . . . , A,. 
To prove the lemma we therefore have to verify 
Hall's condition (H). Every set Aj has size n - r ,  and every element is in 
precisely n - r sets Aj (since it appears r times in the rectangle). Any m 
of the sets Aj contain together m ( n  - r )  elements and therefore at least m 
different ones, which is just condition (H). 
0 
Lemma 2. Let P be a partial Latin square of order n with at most n - 1 
cellsJilled and at most 5 distinct elements, then P can be completed to a 
Latin square of order n. 

Comnletinp Latin sauares 
181 
4 Proof. We first transform the problem into a more convenient form. 
By the conjugacy principle discussed above, we may replace the condi- 
tion "at most 
distinct elements" by the condition that the entries appear 
in at most 
rows, and we may further assume that these rows are the top 
rows. So let the rows with filled cells be the rows 1 , 2 ,  . . . , r, with f, filled 
cells in row i, where r < 5 and C:=, f, < n - 1. By permuting the rows, 
we may assume that fl > f2 > . . . > f,. 
Now we complete the rows 
1. . . . , r step by step until we reach an (r x n)-rectangle which can then be 
extended to a Latin square by Lemma 1. 
Suppose we have already filled rows 1 , 2 ,  . . . . e - 1. In row e there are fe 
filled cells which we may assume to be at the end. The current situation is 
depicted in the figure, where the shaded part indicates the filled cells. 
The completion of row ! 
is performed by another application of Hall's 
theorem, but this time it is quite subtle. Let X be the set of elements that 
A situation for n = 8, with C = 3, f~ = 
do not appear in row e, thus 1x1 = n - fe, and for j = 1 , .  . . , n - fe 
f2 = f3 = 2, f4 = 1. The dark squares 
let A, denote the set of those elements in X which do not appear in 
represent the pre-filled cells, the lighter 
column j (neither above nor below row 1). Hence in order to complete 
ones show the cells that have been filled 
row 1 we must verify condition (H) for the collection Al, . . . , A,-f,. 
in the completion process. 
First we claim 
n -  f t - e + l  
> G l +  f ~ + ~ +  
...+ f,. 
(1 
The case ! 
= 1  is clear. Otherwise x,'=, 
fi < n, fl > . . . > f, and 
1 < e < r together imply 
Now either fe-l 2 2  (in which case (1 ) holds) or feP1 = 1. In the latter 
case, (1) reduces to n > 2(e - 1 )  + r - 1 + 1  = r + l - 1, which is true 
because of e < r 5 7. 
Let us now take m sets Aj, 1 < m < n - fe, and let B be their union. 
We must show lBI > m. Consider the number c of cells in the m columns 
corresponding to the A,'s which contain elements of X .  There are at most 
(e - l ) m  such cells above row ! 
and at most fE+, + . . . + fr below row e, 
and thus 
c 
( ! - l ) m + f e + , +  
. . . + f r  
On the other hand, each element x E X\B appears in each of the m 
columns, hence c 2 rn(lX1 - IBl), and therefore (with 1x1 = n - fg) 
It follows that I Bl > m if 
that is. if 

182 
Cornuletina Latin sauares 
Inequality (2) is true form = 1 and for m = n- fe-l+l by (I), and hence 
for all values m between 1 and n - fe - l + 1, since the left-hand side is 
a quadratic function in m with leading coefficient -1. The remaining case 
is m > n - fe - l + 1. Since any element x of X is contained in at most 
! 
- 1 + fe+l + . . . + f ,  rows, it can also appear in at most that many 
columns. Invoking (1) once more, we find that x is in one of the sets A,, so 
in this case B = X, 1 B1 = n - fe > m, and the proof is complete. 
Let us finally prove Smetaniuk's theorem. 
Theorem. Any partial Latin square of order n with at most n - 1 $filled 
cells can be completed to a Latin square of the same order: 
Proof. We use induction on n, the cases n 
2 being trivial. Thus we 
now study a partial Latin square of order n > 3 with at most n - 1 filled 
cells. With the notation used above these cells lie in r < n - 1 different 
rows numbered sl, . . . , s,, which contain f l ,  . . . , f, > 0 filled cells, with 
Elzl fi < fi - 1. By Lemma 2 we may assume that there are more than 
different elements; thus there is an element that appears only once: after 
renumbering and permutation of rows (if necessary) we may assume that 
the element n occurs only once, and this is in row sl. 
In the next step we want to permute the rows and columns of the partial 
Latin square such that after the permutations all the filled cells lie below 
the diagonal - 
except for the cell filled with n, which will end up on the 
diagonal. (The diagonal consists of the cells ( k ,  Ic) with 1 < k < n.) We 
achieve this as follows: First we permute row sl into the position f l .  By 
permutation of columns we move all the filled cells to the left, so that n 
occurs as the last element in its row, on the diagonal. Next we move row 
s2 into position 1 + f l  + f 2 ,  and again the filled cells as far to the left 
as possible. In general, for 1 < i < r we move the row si into position 
1 + f l  + f 2  + . . . + fi and the filled cells as far left as possible. This clearly 
gives the desired set-up. The drawing to the left shows an example, with 
n = 7: the rows sl = 2, s2 = 3, sj = 5 and s4 = 7 with fl = f 2  = 2 
and f3 = f4 = 1 are moved into the rows numbered 2, 5, 6 and 7, and the 
columns are permuted "to the left" so that in the end all entries except for 
the single 7 come to lie below the diagonal, which is marked by 0s. 
In order to be able to apply induction we now remove the entry n from 
the diagonal and ignore the first row and the last column (which do not 
not contain any filled cells): thus we are looking at a partial Latin square 
of order n - 1 with at most n - 2 filled cells, which by induction can be 
completed to a Latin square of order n - 1. The margin shows one (of 
many) completions of the partial Latin square that arises in our example. 
In the figure, the original entries are printed bold. They are already final, 
as are all the elements in shaded cells; some of the other entries will be 
changed in the following, in order to complete the Latin square of order n. 
In the next step we want to move the diagonal elements of the square to 
the last column and put entries n onto the diagonal in their place. How- 
ever, in general we cannot do this, since the diagonal elements need not 

Comuletina Latin sauares 
be distinct. Thus we proceed more carefully and perform successively, for 
k = 2 , 3 . .  . . , n - 1 (in this order), the following operation: 
Put the value n into the cell ( k ,  n ) .  This yields a correct partial Latin 
square. Now exchange the value x k  in the diagonal cell ( k ,  k )  with the 
tjalue n in the cell ( k ,  n )  in the last column. 
If the value x k  did not already occur in the last column, then our job for the 
current k is completed. After this, the current elements in the k-th column 
will not be changed any more. 
In our example this works without problems for k  = 2, 3 and 4, and the 
corresponding diagonal elements 3, 1 and 6 move to the last column. The 
following three figures show the corresponding operations. 
Now we have to treat the case in which there is already an element xk in 
the last column. In this case we proceed as follows: 
If there is already an element xk in a cell ( j ,  n )  with 2 < j  < k, then we 
exchange in row j  the element x k  in the n-th column with the element xk 
in the k-th column. Ifthe element x/k also occurs in a cell ( j l ,  n), then we 
also exchange the elements in the jl-th row that occur in the n-th and in the 
k-th columns, and so on. 
I f  we proceed like this there will never be two equal entries in a row. Our 
exchange process ensures that there also will never be two equal elements in 
a column. So we only have to verify that the exchange process between the 
k-th and the n-th column does not lead to an infinite loop. This can be seen 
from the following bipartite graph Gk: Its vertices correspond to the cells 
(i, k )  and ( j ,  n) with 2 < i, j  5 k  whose elements might be exchanged. 
There is an edge between ( i ,  k )  and ( j ,  n) if these two cells lie in the same 
row (that is, for i  = j), or if the cells before the exchange process contain 
the same element (which implies i  # j). In our sketch the edges for i  = j 
are dotted, the others are not. All vertices in Gk have degree 1 or 2. The 
cell ( k ,  n) corresponds to a vertex of degree 1; this vertex is the beginning 
of a path which leads to column k  on a horizontal edge, then possibly on a 
sloped edge back to column n, then horizontally back to column k and so 
on. It ends in column k  at a value that does not occur in column n. Thus the 
exchange operations will end at some point with a step where we move a 
new element into the last column. Then the work on column k  is completed, 
and the elements in the cells (i. k )  for i > 2 are fixed for good. 

184 
Completing Latin squares 
In our example the "exchange case" happens for k = 5: the element x5 = 3 
does already occur in the last column, so that entry has to be moved back 
to column k = 5. But the exchange element xk = 6 is not new either, it is 
exchanged by x: = 5, and this one is new. 
Finally, the exchange for k = 6 = n - 1 poses no problem, and after that 
the completion of the Latin square is unique: 
and the same occurs in general: We put an element n into the cell (n, n), 
and after that the first row can be completed by the missing elements of the 
respective columns (see Lemma I), and this completes the proof. In order 
to get explicitly a completion of the original partial Latin square of order n, 
we only have to reverse the element, row and column permutations of the 
first two steps of the proof. 
0 
References 
[l] T. EVANS: 
Embedding incomplete Latin squares, Amer. Math. Monthly 67 
(1960), 958-961. 
[2] C. C. LINDNER: 
On completing Latin rectangles, Canadian Math. Bulletin 13 
(1970), 65-68. 
[3] H. J. RY SER: 
A combinatorial theorem with an application to Latin rectangles, 
Proc. Amer. Math. Soc. 2 (1951), 550-552. 
[4] B. SMETANIUK: 
A new construction on Latin squares I: A proof of the Evans 
conjecture, Ars Combinatoria 11 (198 I), 155-172. 

The Dinitz problem 
Chapter 28 
The four-color problem was a main driving force for the development of 
graph theory as we know it today, and coloring is still a topic that many 
graph theorists like best. Here is a simple-sounding coloring problem, 
raised by Jeff Dinitz in 1978, which defied all attacks until its astonishingly 
simple solution by Fred Galvin fifteen years later. 
j 
1 
Consider n2 cells arranged in an (n x n)-square, and let (i, j )  de- 
note the cell in row i and column j. Suppose that for every cell (i, j )  
we are given a set C(i, 
j )  of n colors. 
Is it then always possible to color the whole array by picking for 
each cell (i, j )  a colorfrom its set C(i, 
j )  such that the colors in 
each row and each column are distinct? 
As a start consider the case when all color sets C(i, 
j )  are the same, say 
{1,2,. . . , n). Then the Dinitz problem reduces to the following task: Fill 
the ( n  x n)-square with the numbers 1,2, . . . , n in such a way that the 
numbers in any row and column are distinct. In other words, any such 
coloring corresponds to a Latin square, as discussed in the previous chapter. 
So, in this case, the answer to our question is "yes." 
Since this is so easy, why should it be so much harder in the general case 
when the set C := U,,, C(i, 
j) contains even more than n colors? The 
difficulty derives from the fact that not every color of C is available at each 
cell. For example, whereas in the Latin square case we can clearly choose 
an arbitrary permutation of the colors for the first row, this is not so anymore 
in the general problem. Already the case n = 2 illustrates this difficulty. 
{1,2) {2,3) 
Suppose we are given the color sets that are indicated in the figure. If we 
choose the colors 1 and 2 for the first row, then we are in trouble since we 
{1,3) {2,3) 
would then have to pick color 3 for both cells in the second row. 
Before we tackle the Dinitz problem, let us rephrase the situation in the 
language of graph theory. As usual we only consider graphs G = (V, E) 
without loops and multiple edges. Let x(G) denote the chromatic number 
of the graph, that is, the smallest number of colors that one can assign to 
the vertices such that adjacent vertices receive different colors. 
In other words, a coloring calls for a partition of V into classes (colored 
with the same color) such that there are no edges within a class. Calling 
a set A 
V independent if there are no edges within A, we infer that 
the chromatic number is the smallest number of independent sets which 
partition the vertex set V. 

186 
The Dinitz ~roblem
The graph S3 
In 1976 Vizing, and three years later ErdBs, Rubin, and Taylor, studied the 
following coloring variant which leads us straight to the Dinitz problem. 
Suppose in the graph G = (V, E) we are given a set C(v) of colors for 
each vertex v. A list coloring is a coloring c : V - 
UvEV C(v) where 
c(v) E C(v) for each v E V. The definition of the list chromatic number 
x,(G) should now be clear: It is the smallest number k such for any list 
of color sets C(v) with IC(v)l = k for all v E V there always exists a list 
coloring. Of course, we have x,(G) < IV/ (we never run out of colors). 
Since ordinary coloring is just the special case of list coloring when all sets 
C(v) are equal, we obtain for any graph G 
To get back to the Dinitz problem, consider the graph S, which has as 
vertex set the n2 cells of our (n x n)-array with two cells adjacent if and 
only if they are in the same row or column. 
Since any n cells in a row are pairwise adjacent we need at least n colors. 
Furthermore, any coloring with n colors corresponds to a Latin square, 
with the cells occupied by the same number forming a color class. Since 
Latin squares, as we have seen, exist, we infer x(S,) = n, and the Dinitz 
problem can now be succinctly stated as 
One might think that perhaps x(G) = xe (G) holds for any graph G, but 
this is a long shot from the truth. Consider the graph G = K2,$ The 
chromatic number is 2 since we may use one color for the two left vertices 
and the second color for the vertices on the right. But now suppose that we 
are given the color sets indicated in the figure. 
To color the left vertices we have the four possibilities 113,1/4,2/3 and 214, 
but any one of these pairs appears as a color set on the right-hand side, so 
a list coloring is not possible. Hence X, (G) > 3, and the reader may find 
it fun to prove x,(G) = 3 (there is no need to try out all possibilities!). 
Generalizing this example, it is not hard to find graphs G where x(G) = 2, 
but xt (G) is arbitrarily large! So the list coloring problem is not as easy as 
it looks at first glance. 
Back to the Dinitz problem. A significant step towards the solution was 
made by Jeanette Janssen in 1992 when she proved xe (3,) 5 n + 1, and 
the coup de grLice was delivered by Fred Galvin by ingeniously combining 
two results, both of which had long been known. We are going to discuss 
these two results and show then how they imply X, (S,) = n. 
First we fix some notation. Suppose v is a vertex of the graph G, then we 
denote as before by d(v) the degree of v. In our square graph Sn every 
vertex has degree 2n - 2, accounting for the n - 1 other vertices in the 
same row and in the same column. For a subset A C V we denote by GA 
the subgraph which has A as vertex set and which contains all edges of G 
between vertices of A. We call GA the subgraph induced by A, and say 
that H is an induced subgraph of G if H = GA for some A. 

The Dinitz problem 
187 
To state our first result we need directed graphs (? = (V, E), that is, graphs 
where every edge e has an orientation. The notation e  = (u, v )  means that 
there is an arc e, also denoted by u-v, 
whose initial vertex is u and whose 
terminal vertex is v. It then makes sense to speak of the outdegree d+(v) 
resp. the indegree d- (v), where d+(v) counts the number of edges with v as 
initial vertex, and similarly for d- (v) ; furthermore, d+ (v) + d (v) = d(v). 
When we write G, we mean the graph 
without the orientations. 
The following concept originated in the analysis of games and will play a 
crucial role in our discussion. 
Definition 1. Let e = (V, E )  be a directed graph. A kernel K 2 V is a 
subset of the vertices such that 
(i) K is independent in G, and 
(ii) for every u 6 
K there exists a vertex v E K with an edge u - 
v. 
Let us look at the example in the figure. The set {b, c, f )  constitutes a 
kernel, but the subgraph induced by {a, c, e )  does not have a kernel since 
the three edges cycle through the vertices. 
With all these preparations we are ready to state the first result. 
c 
Lemma 1. Let (? = (V, E) be a directed graph, and suppose that for each 
vertex v E V we have a color set C(v) that is larger than the outdegree, 
lC(v) I 2 d' 
(v) + 1. I f  every induced subgraph of (? possesses a kernel, 
d 
then there exists a list coloring of G with a colorfrom C(v) for each v. 
Proof. We proceed by induction on I V / .  For I V I = 1 there is nothing to 
prove. Choose a color c E C = UVEv C(71) and set 
By hypothesis, the induced subgraph GA(c) 
possesses a kernel K(c). Now 
we color all v E K(c) with the color c (this is possible since K(c) is 
independent), and delete K(c) from G and c from C. Let G' be the induced 
subgraph of G on V\K(c) with C1(v) = C(v)\c as the new list of color 
sets. Notice that for each v E A(c)\K(c), the outdegree d f  (v) is decreased 
by at least 1 (due to condition (ii) of a kernel). So d f  (v) + 1 < (C1(v) 
1 still 
holds in 2. The same condition also holds for the vertices outside A(c), 
since in this case the color sets C(v) remain unchanged. The new graph G' 
contains fewer vertices than G, and we are done by induction. 
0 
The method of attack for the Dinitz problem is now obvious: We have to 
find an orientation of the graph S, with outdegrees d+(v) < n - 1 for all v 
and which ensures the existence of a kernel for all induced subgraphs. This 
is accomplished by our second result. 
Again we need a few preparations. Recall (from Chapter 9) that a bipartite 
graph G = ( X  U Y. E )  is a graph with the following property: The vertex 
set V is split into two parts X and Y such that every edge has one endvertex 
in X and the other in Y. In other words, the bipartite graphs are precisely 
those which can be colored with two colors (one for X and one for Y). 

188 
The Dinitz uroblem 
Now we come to an important concept, "stable matchings," with a down- 
to-earth interpretation. A matching M in a bipartite graph G = ( X  U Y, E )  
is a set of edges such that no two edges in M have a common endvertex. In 
Y 
the displayed graph the edges drawn in bold lines constitute a matching. 
Consider X to be a set of men and Y a set of women and interpret uv E E 
to mean that u and v might marry. A matching is then a mass-wedding with 
no person committing bigamy. For our purposes we need a more refined 
(and more realistic?) version of a matching, suggested by David Gale and 
Lloyd S. Shapley. Clearly, in real life every person has preferences, and 
A bipartite graph with a matching 
this is what we add to the set-up. In G = ( X  U Y, E )  we assume that for 
every u E X U Y there is a ranking of the set N(v) of vertices adjacent 
to u, N(u) = {zl > z z  > . . . > z ~ ( ~ ) } .  
Thus zl is the top choice for v, 
followed by z z ,  and so on. 
Definition 2. A matching M of G = ( X  U Y, E )  is called stable if the 
following condition holds: Whenever uv E E\M, 
7 1  E X ,  v E Y ,  then 
either u y  E M with y > v in N ( u )  or xu E M with x > u in N(v), 
or both. 
In our real life interpretation a set of marriages is stable if it never happens 
that u and v are not married but u prefers v to his partner (if he has one at 
all) and v prefers u to her mate (if she has one at all), which would clearly 
be an unstable situation. 
Before proving our second result let us take a look at the following example: 
The bold edges constitute a stable 
matching. 
In each priority list, the 
choice leading to a stable matching is 
printed bold. 
Notice that in this example there is a unique largest matching M with four 
edges, M = {aC, bB, cD, dA), but M is not stable (consider cA). 
Lemma 2. A stable matching always exists. 
Proof. Consider the following algorithm. In the first stage all men 
u E X propose to their top choice. If a girl receives more than one pro- 
posal she picks the one she likes best and keeps him on a string, and if she 
receives just one proposal she keeps that one on a string. The remaining 
men are rejected and form the reservoir R. In the second stage all men in R 
propose to their next choice. The women compare the proposals (together 
with the one on the string, if there is one), pick their favorite and put him 
on the string. The rest is rejected and forms the new set R. Now the men 
in R propose to their next choice, and so on. A man who has proposed to 
his last choice and is again rejected drops out from further consideration 
(as well as from the reservoir). Clearly, after some time the reservoir R is 
empty, and at this point the algorithm stops. 

The Dinitz nroblem 
189 
Claim. When the algorithm stops, then the men on the strings 
together with the corresponding girls form a stable matching. 
Notice first that the men on the string of a particular girl move there in 
increasing preference (of the girl) since at each stage the girl compares 
the new proposals with the present mate and then picks the new favorite. 
Hence if uv E E but uv $! 
M, then either u never proposed to v in 
which case he found a better mate before he even got around to v, im- 
plying uy E M with y > v in N(u), or u proposed to u but was rejected, 
implying xu E M with x > u in N(v). But this is exactly the condition of 
a stable matching. 
0 
Putting Lemmas 1 and 2 together, we now get Galvin's solution of the 
Dinitz problem. 
Theorem. We have X ,  (S,) = n for all n. 
Proof. As before we denote the vertices of S, by (i, j), 1 5 i, j < n. 
Thus (i. j) and (r, s) are adjacent if and only if i = r or j = s. Take 
any Latin square L with letters from {1,2,. . . , n) and denote by L(i, j) 
the entry in cell (i, j). Next make S, into a directed graph gn by orienting 
the horizontal edges (i. j) - 
(i, j') if L(i, j) < L(i, j') and the vertical 
edges (i, j) - 
(i', j) if L(i, j) > L(il, j). Thus, horizontally we orient 
from the smaller to the larger element, and vertically the other way around. 
(In the margin we have an example for n = 3.) 
Notice that we obtain d+(i, j )  = n - 1 for all (i, j). In fact, if L(i, j) = k ,  
then n - k cells in row i contain an entry larger than k, and k - 1 cells in 
column j have an entry smaller than k. 
By Lemma 1 it remains to show that every induced subgraph of 3, pos- 
sesses a kernel. Consider a subset A C V, and let X be the set of rows 
of L, and Y the set of its columns. Associate to A the bipartite graph 
G = (X U Y ,  A), where every (i, j) E A is represented by the edge ij with 
i E X, j E Y .  In the example in the margin the cells of A are shaded. 
The orientation on S, naturally induces a ranking on the neighborhoods in 
+ 
G = ( X  u Y ,  A) by setting j' > j in N(i) if (i, j) - 
(i, j') in S, respec- 
tively i' > i in N ( j )  if (i, j) - 
(i', j). By Lemma 2, G = (X U Y ,  A) 
possesses a stable matching M. This M ,  viewed as a subset of A, is our 
desired kernel! To see why, note first that AT is independent in A since as 
edges in G = (X U Y ,  A) they do not share an endvertex i or j. Secondly, 
if (i, j )  E A\M, then by the definition of a stable matching there either 
exists ( i ,  j') E M with j' > j or (i', j) E M with i' > i, which for 3, 
means (i, j) - 
(i, j') E M or (i, j) - 
(i', j) E M ,  and the proof 
is complete. 
0 
To end the story let us go a little beyond. The reader may have noticed that 
the graph S, arises from a bipartite graph by a simple construction. Take 
the complete bipartite graph, denoted by K,,,, 
with 1x1 = IYI = n, and 
all edges between X and Y. If we consider the edges of K,,, as vertices 

190 
The Dinitz problem 
Construction of a line graph 
of a new graph, joining two such vertices if and only if as edges in K,,, 
they have a common endvertex, then we clearly obtain the square graph S,. 
Let us say that S, is the line graph of K,,,. 
Now this same construction 
can be performed on any graph G with the resulting graph called the line 
graph L(G) of G. 
In general, call H a line graph if H = L(G) for some graph G. Of course, 
not every graph is a line graph, an example being the graph K2,4 that we 
considered earlier, and for this graph we have seen x(K2,4) < xe (K2,4). 
But what if H is a line graph? By adapting the proof of our theorem it can 
easily be shown that x(H) = xe ( H )  holds whenever H is the line graph of 
a bipartite graph, and the method may well go some way in verifying the 
supreme conjecture in this field: 
Does x ( H )  = xe ( H )  hold for every line graph H? 
Very little is known about this conjecture, and things look hard - 
but after 
all, so did the Dinitz problem twenty years ago. 
References 
[I] P. ERDBS, A. L. RUBIN & H. TAYLOR: 
Choosability in graphs, Proc. West 
Coast Conference on Combinatorics, Graph Theory and Computing, Congres- 
sus Numerantium 26 (1979), 125-157. 
[2] D. GALE & L. S. SHAPLEY: 
College admissions and the stability of marriage, 
Amer. Math. Monthly 69 (1962), 9-15. 
[3] F. CALVIN: 
The list chromatic index of a bipartite multigraph, J .  Combinato- 
rial Theory, Ser. B 63 (1995), 153-158. 
[4] J. C. M. JANSSEN: 
The Dinitz problem solved for rectangles, Bulletin Amer. 
Math. Soc. 29 (1993), 243-249. 
[ S ]  V. G. VIZING: 
Coloring the vertices of a graph in prescribed colours (in Rus- 
sian), Metody Diskret. Analiz. 101 (1976), 3-10. 

Identities versus bijections 
Chapter 29 
Consider the infinite product ( I  + x )  (1 + x2) (1 + x3) (1 + x4) . . . and 
expand it in the usual way into a series Enro anxn by grouping together 
those products that yield the same power xn. By inspection we find for the 
first terms 
So we have e. g. a6 = 4, a7 = 5, and we (rightfully) suspect that a, goes 
to infinity with n -+ x. 
Looking at the equally simple product (1 - x )  (1 - x2) (1 - x3)(1 - x4) . . . 
something unexpected happens. Expanding this product we obtain 
It seems that all coefficients are equal to 1, -1 or 0. But is this true? And 
if so, what is the pattern? 
Infinite sums and products and their convergence have played a central role 
in analysis since the invention of the calculus, and contributions to the 
subject have been made by some of the greatest names in the field, from 
Leonhard Euler to Srinivasa Ramanujan. 
In explaining identities such as (1) and (Z), however, we disregard conver- 
gence questions - 
we simply manipulate the coefficients. In the language 
of the trade we deal with "formal" power series and products. In this frame- 
work we are going to show how combinatorial arguments lead to elegant 
proofs of seemingly difficult identities. 
Our basic notion is that of a partition of a natural number. We call any sum 
A :  n = A1+A2+. ..+At 
with A 1 > A 2 >  ...2 
A t > l  
a partition of n. P ( n )  shall be the set of all partitions of n, with p(n) := 
I P(n)l, where we set p(0) = 1. 
What have partitions got to do with our problem? Well, consider the 
following product of infinitely many series: 
5  = 5 
5 = 4 + l  
5 = 3 + 2  
5 = 3 + 1 + 1  
5 = 2 + 2 + 1  
5 = 2 + 1 + 1 + 1  
5 = l + l + l + l + l .  
The partitions counted by p(5) = 7 
where the k-th factor is (1 + xk + x2k + x3k + . . . ). What is the coefficient 
of xn when we expand this product into a series Enro a,xn ? A moment's 

192 
Identities versus bijections 
thought should convince you that this is just the number of ways to write n  
as a sum 
So the coefficient is nothing else but the number p(n) of partitions of n. 
Since the geometric series 1  + xk + x2' + . . . equals &, 
we have proved 
our first identity: 
What's more, we see from our analysis that the factor 
accounts for 
the contribution of k to a partition of n. Thus, if we leave out & from 
the product on the left side of (4), then k does not appear in any partition 
on the right side. As an example we immediately obtain 
6 = l + l + l + l + l + l  
where p,(n) is the number of partitions of n  all of whose summands are 
Partitions of 6  into odd parts: p0(6) = 4 
odd, and the analogous statement holds when all summands are even. 
By now it should be clear what the n-th coefficient in the infinite product 
nk,, 
(1 + z k )  will be. Since we take from any factor in (3) either 1  or xk, 
this means that we consider only those partitions where any summand k 
appears at most once. In other words, our original product (1) is expanded 
into 
7 = 7  
7 = 6 + l  
7 = 5 + 2  
7 = 4 + 3  
7 = 4 + 2 + 1 .  
The partitions of 7  into odd resp. distinct 
parts: p0(7) = pd(7) = 5. 
where pd(n) is the number of partitions of n  into distinct summands. 
Now the method of formal series displays its full power. Since 1 - x2 = 
(1 - x)(1 + x )  we may write 
since all factors 1  - x2i with even exponent cancel out. So, the infinite 
products in (5) and (6) are the same, and hence also the series, and we 
obtain the beautiful result 
po (n) = pd ( n )  
for all n > 0. 
(7) 
Such a striking equality demands a simple proof by bijection -at 
least that 
is the point of view of any combinatorialist. 

Identities versus bijections 
193 
Problem. Let P,(n) and Pd(n) be the partitions of n into odd and into 
distinct summands, respectively: Find a bijection from P,(n) onto Pd(n)! 
Several bijections are known, but the following one due to J. W. L. Glaisher 
( 1907) is perhaps the neatest. Let X be a partition of n into odd parts. We 
collect equal summands and have 
n = 
X 1 +  ...+ X I  +X2+...+X2 + . . .  + A t + . . . + &  
- - - 
n1 
n2 
n t 
For example, 
= n l . X 1 + n 2 . X 2 +  . . . +  nt.Xt. 
X : 25 = 5+5+5+3+3+l+l+l+l 
NOW we write nl = 2m1 + 2m2 + . . . + 2mr in its binary representation 
is maPpedb~ 4 to 
and similarly for the other ni. The new partition A' of n is then 
A' : 25 = (2+1)5 + (2)3 + (4)l 
= 1 0 + 5 + 6 + 4  
A ' :  n=2m1X1 +2mzX1 +...+2mrX1 + 2 k 1 ~ 2 + . . .  
. 
= 1 0 + 6 + 5 + 4 .  
We have to check that A' is in Pd(n), and that 4 : X ti A' is indeed a 
bijection. Both claims are easy to verify: If 2"Xi = 2 b ~ j  
then 2" = 2b 
We write 
since X i  and X j  are odd, and so Xi = A,. Hence A' is in Pd(n). Conversely, 
A' : 3 0 = 1 2 + 6 + 5 + 4 + 3  
when n = p1 + p2 + . . . + p, is a partition into distinct summands, then ,, 30 =4(3+1) + 2(3) + 1(5+3) 
we reverse the bijection by collecting all pi with the same highest power 
= (1)5 + (4+2+1)3 + (4)l 
of 2, and write down the odd parts with the proper multiplicity. The margin 
and obtain as 
the 
displays an example. 
X : 3 0 = 5 + 3 + 3 + 3 + 3 + 3 + 3 +  
3 + l + l + l + l  
Manipulating formal products has thus led to the equality p,(n) = pd(n) 
into odd summands. 
for partitions which we then verified via a bijection. Now we turn this 
around, give a bijection proof for partitions and deduce an identity. This 
time our goal is to identify the pattern in the expansion (2). 
~ o o k  
at 
4, 
1 - - 22 + x5 + x7 - d 2  - d5 + 222 + 226 - 235 - 240 + . . . . 
The exponents (apart from 0) seem to come in pairs, and taking the expo- 
nents of the first power in each pair gives the sequence 
J' = 1 A7 
1 
5 
12 
22 35 
51 70 
... 
well-known to Euler. These are the pentagonal numbers f ( j ) ,  whose name 
is suggested by the figure in the margin. 
3j2-j 
We easily compute f ( j )  = 
and f ( j )  = 
for the other num- 
ber of each pair. In summary, we conjecture, as Euler has done, that the 
following formula should hold. 
Pentagonal numbers 

194 
Identities versus bijections 
Euler proved this remarkable theorem by calculations with formal series, 
but we give a bijection proof from The Book. First of all, we notice by (4) 
that the product nk,, ( 1  -xk) is precisely the inverse of our partition series 
- 
Cn>,,~(n)xn. 
- 
Hence setting nk,, 
- (1 - x k )  =: Cnlo 
c(n)xn, we find 
Comparing coefficients this means that c(n) is the unique sequence with 
c(0) = 1  and 
n C c(k)p(n - k )  = O 
for all n 2 1. 
(9) 
k=O 
03 
3? 
+3 
Writing the right-hand of (8) as C ( - 1 ) J x ~ ,  
we have to show that 
3 = - m  
( 0  otherwise 
gives this unique sequence. Setting b ( j )  = 
for j  E Z 
and substituting 
these values into (9), our conjecture takes on the simple form 
C p(n - b ( j ) )  = 
p(n - b ( j ) )  
for all n, 
3 even 
j odd 
where of course we only consider j  with b ( j )  < n. So the stage is set: We 
have to find a bijection 
Again several bijections have been suggested, but the following construc- 
tion by David Bressoud and Doron Zeilberger is astonishingly simple. We 
just give the definition of 4 (which is, in fact, an involution), and invite the 
reader to verify the easy details. 
For X : X I  + . . . + At E P ( n  - b ( j ) )  set 
As an example consider n = 15, j = 2, 
so b(2) = 7. The partition 3 + 2 + 2 + 1 
( t + 3 j - l ) + ( X 1 - 1 ) +  . . . + (  A t - 1 )  
i f t + 3 j L X 1 ,  
in P(15 - b(2)) = P(8) 
is mapped to 
d(X) := 
9+2+l+l, which is in P(15-b(1)) 
= 
(X2+1)+ . . . + (  & + 1 ) + 1 + . .  - 
+ 1  
i f t + 3 j < X l ,  
P(13). 
XI -t-3j-1 
where we leave out possible 0's. One finds that in the first case $(A) is in 
P ( n  - b(j - I ) ) ,  and in the second case in P ( n  - b(j + 1)). 
This was beautiful, and we can get even more out of it. We already know 
that 

Identities versus bijections 
195 
As experienced formal series manipulators we notice that the introduction 
of the new variable y yields 
where pd,,(n) counts the partitions of n into precisely m distinct sum- 
mands. With y = -1 this yields 
An example for n = 10: 
where Ed (n) is the number of partitions of n into an even number of distinct 
10 = 6 + 4 
parts, and Od (n) is the number of partitions into an odd number. And here 
10 = 4  + 3  + 2 + 1 
is the punchline. Comparing (10) to Euler's expansion in (8) we infer the 
and 
beautiful result 
10 = 10 
1 0 = 7 + 2 + 1  
( 1 for n = 
when j 2 0 is even, 
1 0 = 6 + 3 + 1  
&(a) - Od(n) = 
-1 
for n = 
when j > 1 is odd, 
I 
1 0 = 5 + 4 + 1  
1 0 = 5 + 3 + 2 ,  
( 0 otherwise. 
so Ed(l0) = Od(lO) = 5. 
This is, of course, just the beginning of a longer and still ongoing story. The 
theory of infinite products is replete with unexpected indentities, and with 
their bijective counterparts. The most famous examples are the so-called 
Rogers-Ramanujan identities, named after Leonard Rogers and Srinivasa 
Ramanujan, in which the number 5 plays a mysterious role: 
1 
- 
- 
xn 
n ,, - x S k - l ) ( l  - x5k-1) 
k > l  
(I -$)(I - x 2 ) .  . . (1 - xn) 
nz0 
1 
xn2+n 
- 
11 (1 - ~5k-3)(1 - x5k-2) 
C (1 - x ) ( l  - X 2 ) .  - .  (1 - X n )  . 
- .  
B 
k > l  
n>O 
- 
- 
Srinivasa Ramanujan 
The reader is invited to translate them into the following partition identities 
first noted by Percy MacMahon: 
0 
0 
All 
Let f ( n )  be the number of partitions of n all of whose summands are 
of the form 5k + 1 or 5k + 4, and g(n) the number of partitions whose 
summands differ by at least 2. Then f ( n )  = g (n). 
Let ~ ( n )  
be the number of partitions of n all of whose summands are 
of the form 5k + 2 or 5k + 3, and ~ ( n )  
the number of partitions whose 
parts differ by at least 2 and which do not contain 1. Then r ( n )  = s(n). 
known formal series proofs of the Rogers-Ramanuian identities are 
- 
quite involved, and for a long time bijection proofs of f ( n )  = g(n) and 
of r(n) = s(n) seemed elusive. Such proofs were eventually given 1981 
by Adriano Garsia and Stephen Milne. Their bijections are, however, very 
complicated - 
Book proofs are not yet in sight. 

196 
Identities versus bijections 
References 
[I] G. E. ANDREWS: 
The Theory of Partitions, Encyclopedia of Mathematics and 
its Applications, Vol. 2, Addison-Wesley, Reading MA 1976. 
[2] D. BRESSOUD & D. ZEILBERGER: 
Bijecting Euler's partitions-recurrence, 
Amer. Math. Monthly 92 (1985), 54-55. 
[3] A. GARSIA & S. MILNE: A Rogers-Ramanujan bijection, J .  Combinatorial 
Theory, Ser. A 31 (1981), 289-339. 
[4] S. RAMANUJAN: 
Proof of certain identities in combinatory analysis, Proc. 
Cambridge Phil. Soc. 19 (1919), 214-216. 
[5] L. J. ROGERS: Second memoir on the expansion of certain injinite products, 
Proc. London Math. Soc. 25 (1894), 318-343. 

 
 
 
Graph Theory 

Five-coloring plane graphs 
Chapter 30 
Plane graphs and their colorings have been the subject of intensive research 
since the beginnings of graph theory because of their connection to the four- 
color problem. As stated originally the four-color problem asked whether it 
is always possible to color the regions of a plane map with four colors such 
that regions which share a common boundary (and not just a point) receive 
different colors. The figure on the right shows that coloring the regions of a 
map is really the same task as coloring the vertices of a plane graph. As in 
Chapter 11 (page 65) place a vertex in the interior of each region (including 
the outer region) and connect two such vertices belonging to neighboring 
regions by an edge through the common boundary. 
The resulting graph G, the dual graph of the map M ,  is then a plane graph, 
and coloring the vertices of G in the usual sense is the same as coloring 
the regions of M. So we may as well concentrate on vertex-coloring plane 
graphs and will do so from now on. Note that we may assume that G has 
The dual graph of a map 
no loops or multiple edges, since these are irrelevant for coloring. 
In the long and arduous history of attacks to prove the four-color theorem 
many attempts came close, but what finally succeeded in the Appel-Haken 
proof of 1976 and also in the recent proof of Robertson, Sanders, Seymour 
and Thomas 1997 was a combination of very old ideas (dating back to the 
19th century) and the very new calculating powers of modern-day comput- 
ers. Twenty-five years after the original proof, the situation is still basically 
the same, no proof from The Book is in sight. 
So let us be more modest and ask whether there is a neat proof that every 
plane graph can be 5-colored. A proof of this five-color theorem had al- 
ready been given by Heawood at the turn of the century. The basic tool for 
his proof (and indeed also for the four-color theorem) was Euler's formula 
(see Chapter 1 I). Clearly, when coloring a graph G we may assume that G 
is connected since we may color the connected pieces separately. A plane 
graph divides the plane into a set R of regions (including the exterior re- 
gion). Euler's formula states that for plane connected graphs G = (V, E) 
we always have 
IVI - IEI + IRI = 2. 
As a warm-up, let us see how Euler's formula may be applied to prove 
that every plane graph G is 6-colorable. We proceed by induction on the 
 hi^ plane graph has 8 vertices, 
number n of vertices. For small values of n (in particular, for n < 6) this 
13 edges and 7 regions, 
is obvious. 

200 
Five-coloring plane graphs 
From part (A) of the proposition on page 67 we know that G has a vertex v 
of degree at most 5. Delete 11 and all edges incident with v. The resulting 
graph G' = G\u is a plane graph on n - 1 vertices. By induction, it can be 
6-colored. Since 11 has at most 5 neighbors in G, at most 5 colors are used 
for these neighbors in the coloring of GI. So we can extend any 6-coloring 
of GI to a 6-coloring of G by assigning a color to v which is not used for 
any of its neighbors in the coloring of GI. Thus G is indeed 6-colorable. 
Now let us look at the list chromatic number of plane graphs, as discussed in 
the previous chapter on the Dinitz problem. Clearly, our 6-coloring method 
works for lists of colors as well (again we never run out of colors), so 
xe (G) < 6 holds for any plane graph G. Erdiis, Rubin and Taylor conjec- 
tured in 1979 that every plane graph has list chromatic number at most 5, 
and further that there are plane graphs G with ,ye (G) > 4. They were 
right on both counts. Margit Voigt was the first to construct an example 
of a plane graph G with X, (G) = 5 (her example had 238 vertices) and 
around the same time Carsten Thomassen gave a truly stunning proof of 
the 5-list coloring conjecture. His proof is a telling example of what you 
can do when you find the right induction hypothesis. It does not use Euler's 
formula at all! 
Theorem. All planar graphs G can be 5-list colored: 
xe(G) 5 5. 
Proof. First note that adding edges can only increase the chromatic num- 
ber. In other words, when H is a subgraph of G, then x,(H) < xe(G) 
certainly holds. Hence we may assume that G is connected and that all 
the bounded faces of an embedding have triangles as boundaries. Let us 
call such a graph near-triangulated. The validity of the theorem for near- 
triangulated graphs will establish the statement for all plane graphs. 
The trick of the proof is to show the following stronger statement (which 
allows us to use induction): 
A near-triangulated plane graph 
Let G = (V, E) be a near-triangulated graph, and let B be the 
cycle bounding the outer region. We make the following assump- 
tions on the color sets C(u), v E V: 
(1) Two adjacent vertices x, y of B are already colored with 
(different) colors a and /3. 
(2) lC(v) I > 3 for all other vertices v qf B. 
(3) IC(v)l > 5  for all vertices v in the interior: 
Then the coloring of x, y can be extended to a proper coloring of G 
by choosing co1or.s from the lists. In particular; xe (G) < 5. 

Five-colorinn plane nrauhs 
20 1 
For 1V = 3 this is obvious, since for the only uncolored vertex v we have 
IC(t1) I > 3, so there is a color available. Now we proceed by induction. 
Case I: Suppose B has a chord, that is, an edge not in B that joins two 
vertices u:u E B. The subgraph G1 which is bounded by B1 U {uv} 
and contains x, y, u and v is near-triangulated and therefore has a 5-list 
coloring by induction. Suppose in this coloring the vertices u and v receive 
the colors y and 6. Now we look at the bottom part G2 bounded by B2 and 
ILU. Regarding u, 
v as pre-colored, we see that the induction hypotheses 
are also satisfied for G2. Hence G2 can be 5-list colored with the available 
colors, and thus the same is true for G. 
Case 2: Suppose B has no chord. Let vo be the vertex on the other side of 
the a-colored vertex x on B, and let x, vl, . . . , vt, w be the neighbors of vo. 
Since G is near-triangulated we have the situation shown in the figure. 
Construct the near-triangulated graph G' = G\uo by deleting from G the 
vertex 'uo and all edges emanating from vo. This G' has as outer boundary 
B' = (B\vo) U {vl , . . . , vt }. Since IC(vo) 
1 > 3 by assumption (2) there 
exist two colors y, 
6 in C(vo) different from a. Now we replace every 
color set C(v,) by C(v,)\{y, 61, 
keeping the original color sets for all other 
vertices in GI. Then G' clearly satisfies all assumptions and is thus 5-list 
colorable by induction. Choosing y or b for vo, different from the color 
of w, we can extend the list coloring of G' to all of G. 
0 
So, the 5-list color theorem is proved, but the story is not quite over. A 
stronger conjecture claimed that the list-chromatic number of a plane graph 
G is at most 1 more than the ordinary chromatic number: 
Is xe (G) 5 x(G) + 1 for every plane graph G ? 
Since x(G) 5 4 by the four-color theorem, we have three cases: 
Case I: x(G) = 2 * x, (G) < 3 
Case 11: x(G) = 3 ==+ xt (G) 1 
4 
Case 111: x(G) = 4 ==+ X, (G) 5 5. 
Thomassen's result settles Case 111, and Case I was proved by an ingenious 
(and much more sophisticated) argument by Alon and Tarsi. Furthermore, 
there are plane graphs G with x(G) = 2 and x,(G) = 3, for example 
the graph K2,4 that we considered in the preceding chapter on the Dinitz 
problem. 
{a, 
But what about Case II? Here the conjecture fails: this was first shown 
by Margit Voigt for a graph that was earlier constructed by Shai Gutner. 
His graph on 130 vertices can be obtained as follows. First we look at 
the "double octahedron" (see the figure), which is clearly 3-colorable. Let 
(U E {5.6,7,8} and p E {9,10,11,12), and consider the lists that are given 
{P, 2,3, 
in the figure. You are invited to check that with these lists a coloring is not 
possible. Now take 16 copies of this graph, and identify all top vertices and 
all bottom vertices. This yields a graph on 16 . 8  + 2 = 130 vertices which 
P 

202 
Five-coloring plane graphs 
is still plane and 3-colorable. We assign {5,6,7,8) to the top vertex and 
{9,10, 11, 12) to the bottom vertex, with the inner lists corresponding to 
the 16 pairs (a. p), a E {5,6,7,8), /? E {9,10,11,12). For every choice 
of a and 0 we thus obtain a subgraph as in the figure, and so a list coloring 
of the big graph is not possible. 
By modifying another one of Gutner's examples, Voigt and Wirth came up 
with an even smaller plane graph with 75 vertices and x = 3, X ,  = 5, which 
in addition uses only the minimal number of 5 colors in the combined lists. 
The current record is 63 vertices. 
References 
[I] N. ALON & M. TARSI: Colorings and orientations qf graphs, Combinatorica 
12 (l992), 125-134. 
[2] P. ERDBS, A. L. RUBIN & H. TAYLOR: Choosability in graphs, Proc. West 
Coast Conference on Combinatorics, Graph Theory and Computing, Congres- 
sus Numerantium 26 (1979), 125-157. 
[3] S. GUTNER: 
The complexity ofplanar graph choosability, Discrete Math. 159 
( 1 996), 1 19- 130. 
[4] N. ROBERTSON, 
D. P. SANDERS, 
P. SEYMOUR 
& R. THOMAS: The four- 
colour theorem, J. Combinatorial Theory, Ser. B 70 (1997), 2-44. 
[5] C. THOMASSEN: 
Every planar graph is 5-choosable, J .  Combinatorial Theory, 
Ser. B 62 (1 994), 180- 18 1. 
[6] M. VOIGT: List colorings of planar graphs, Discrete Math. 120 (1993), 
215-219. 
[7] M. VOIGT & B. WIRTH: On 3-colorable non-4-choosable planar graphs, 
J .  Graph Theory 24 (1997), 233-235. 

How to guard a museum 
Here is an appealing problem which was raised by Victor Klee in 1973. 
Suppose the manager of a museum wants to make sure that at all times 
every point of the museum is watched by a guard. The guards are stationed 
at fixed posts, but they are able to turn around. How many guards are 
needed? 
We picture the walls of the museum as a polygon consisting of n sides. 
Of course, if the polygon is convex, then one guard is enough. In fact, the 
guard may be stationed at any point of the museum. But, in general, the 
walls of the museum may have the shape of any closed polygon. 
Consider a comb-shaped museum with n = 3m walls, as depicted on the 
right. It is easy to see that this requires at least m = 5 guards. In fact, 
there are n walls. Now notice that the point 1 can only be observed by a 
guard stationed in the shaded triangle containing 1, and similarly for the 
other points 2,3, . . . . m,. Since all these triangles are disjoint we conclude 
that at least m guards are needed. But m guards are also enough, since they 
can be placed at the top lines of the triangles. By cutting off one or two 
walls at the end, we conclude that for any n there is an n-walled museum 
which requires 13 J guards. 
Chapter 31 
A convex exhibition hall 

204 
How to guard a museum 
A museum with n = 12 walls 
A triangulation of the museum 
Schonhardt's polyhedron: The interior 
dihedral angles at the edges AB', BC' 
and CA' are greater than 180'. 
The following result states that this is the worst case. 
Theorem. For any museum with n walls, 151 guards sufice. 
This "art gallery theorem" was first proved by VaSek Chvital by a clever 
argument, but here is a proof due to Steve Fisk that is truly beautiful. 
Proof. First of all, let us draw n - 3 non-crossing diagonals between 
corners of the walls until the interior is triangulated. For example, we can 
draw 9 diagonals in the museum depicted in the margin to produce a trian- 
gulation. It does not matter which triangulation we choose, any one will do. 
Now think of the new figure as a plane graph with the corners as vertices 
and the walls and diagonals as edges. 
Claim. This graph is 3-colorable. 
For n = 3 there is nothing to prove. Now for n > 3 pick any two vertices 
u and v which are connected by a diagonal. This diagonal will split the 
graph into two smaller triangulated graphs both containing the edge uv. By 
induction we may color each part with 3 colors where we may choose color 
1 for u and color 2 for v in each coloring. Pasting the colorings together 
yields a 3-coloring of the whole graph. 
The rest is easy. Since there are n vertices, at least one of the color classes, 
say the vertices colored 1, contains at most 
vertices, and this is where 
we place the guards. Since every triangle contains a vertex of color 1 we in- 
fer that every triangle is guarded, and hence so is the whole museum. 
The astute reader may have noticed a subtle point in our reasoning. Does 
a triangulation always exist? Probably everybody's first reaction is: Obvi- 
ously, yes! Well, it does exist, but this is not completely obvious, and, 
in fact, the natural generalization to three dimensions (partitioning into 
tetrahedra) is false! This may be seen from Schonhardt's polyhedron, de- 
picted on the left. It is obtained from a triangular prism by rotating the 
top triangle, so that each of the quadrilateral faces breaks into two triangles 
with a non-convex edge. Try to triangulate this polyhedron! You will notice 
that any tetrahedron that contains the bottom triangle must contain one of 
the three top vertices: but the resulting tetrahedron will not be contained in 
Schonhardt's polyhedron. So there is no triangulation without an additional 
vertex. 
To prove that a triangulation exists in the case of a planar non-convex 
polygon, we proceed by induction on the number n of vertices. For n = 3 
the polygon is a triangle, and there is nothing to prove. Let n 2 4. To 
use induction, all we have to produce is one diagonal which will split the 
polygon P into two smaller parts, such that a triangulation of the polygon 
can be pasted together from triangulations of the parts. 
Call a vertex A convex if the interior angle at the vertex is less than 180". 
Since the sum of the interior angles of P is (n - 2)180°, there must be a 

How to guard a museum 
205 
convex vertex A. In fact, there must be at least three of them: In essence 
this is an application of the pigeonhole principle! Or you may consider the 
convex hull of the polygon, and note that all its vertices are convex also for 
the original polygon. 
Now look at the two neighboring vertices B and C of A. If the segment 
BC lies entirely in P, then this is our diagonal. If not, the triangle A B C  
contains other vertices. Slide BC towards A until it hits the last vertex Z 
in ABC'. Now A Z  is within P, and we have a diagonal. 
A 
There are many variants to the art gallery theorem. For example, we may 
only want to guard the walls (which is, after all, where the paintings hang), 
or the guards are all stationed at vertices. A particularly nice (unsolved) 
variant goes as follows: 
Suppose each guard may patrol one wall of the museum, so he 
walks along his wall and sees anything that can be seen from any 
point along this wall. 
How many "wall guards" do we then need to keep control? 
Godfried Toussaint constructed the example of a museum displayed here 
which shows that 171 guards may be necessary. 
This polygon has 28 sides (and, in general, 4nz sides), and the reader is in- 
vited to check that rn wall-guards are needed. It is conjectured that, except 
for some small values of n, this number is also sufficient, but a proof, let 
alone a Book Proof, is still missing. 
References 
[I] V. CHVATAL: 
A combinatorial theorem in plane geometry, J .  Combinatorial 
Theory, Ser. B 18 (1975), 39-41. 
[2] S. FISK: A short proof of Chvatal's watchman theorem, J .  Combinatorial 
Theory, Ser. B 24 (1978), 374. 
[3] J. O'ROURKE: Art Gallery Theorems and Algorithms, Oxford University 
Press 1987. 
[4] E. SCHONHARDT: 
Uber die Zerlegung von Dreieckspolyedern in Tetraedel; 
Math. Annalen 98 (1928), 309-312. 

206 
How to guard a museum 
"Museum guards" 
(A 3-dimensional art-gallery problem) 

Turan's graph theorem 
Chapter 32 
One of the fundamental results in graph theory is the theorem of Tur6n 
from 1941, which initiated extremal graph theory. Turin's theorem was 
rediscovered many times with various different proofs. We will discuss five 
of them and let the reader decide which one belongs in The Book. 
Let us fix some notation. We consider simple graphs G on the vertex set 
V = ('111, . . . ,flu,) and edge set E. If vi and vj are neighbors, then we 
write vi 11,. E E. A p-clique in G is a complete subgraph of G on p vertices, 
denoted by K,. Paul Turrin posed the following question: 
Suppose G is a simple graph that does not contain a p-clique. 
What is the largest number of edges that G can have? 
We readily obtain examples of such graphs by dividing V into p- 1 pairwise 
disjoint subsets V = Vl 
U . . . U V,-l, 1% 
1 = n,i, n = n, 1 +. . . + n,-1, 
joining two vertices if and only if they lie in distinct sets V,, V, . We denote 
the resulting graph by K n l , . . . r n p ~ l  
; it has 
nin.j edges. We obtain a 
maximal number of edges among such graphs with given n if we divide 
the numbers ni as evenly as possible, that is, if Ini - nj ( < 1 for all i, j. 
Indeed, suppose nl > 722 + 2. By shifting one vertex from Vl to V2, we 
obtain Knl-l,nz+l ,.... n,_l which contains (nl - l)(n2 + 1 )  - nln2 = 
121 - n2 - 1 > 1 more edges than Knl.n2 
..... n p - l .  Let us call the graphs 
K,, .....,, p - l  with 1n.i - nj I 5 1 the Tura'n graphs. In particular, if p - 1 
divides n, then we may choose ni = 5 
for all i, obtaining 
The graph K 2 . 2 , 3  
edges. Turin's theorem now states that this number is an upper bound for 
the edge-number of any graph on n vertices without a p-clique. 
Theorem. If a graph G = (V. E) on n vertices has no p-clique, p > 2, 
then 
For p = 2 this is trivial. In the first interesting case p = 3 the theorem states 
that a triangle-free graph on n vertices contains at most 5 edges. Proofs 
of this special case were known prior to Turin's result. Two elegant proofs 
using inequalities are contained in Chapter 17. 

208 
Turdn's graph theorem 
Let us turn to the general case. The first two proofs use induction and are 
due to Turin and to ErdBs, respectively. 
First proof. We use induction on n. One easily computes that (1) is true 
for n < p. Let G be a graph on V = {vl, . . . , v,) without p-cliques with 
a maximal number of edges, where n > p. G certainly contains (p - 1)- 
cliques, since otherwise we could add edges. Let A be a (p - 1)-clique, and 
set B := V\A. 
A contains (Pi1) 
edges, and we now estimate the edge-number eB in B 
and the edge-number eA,B between A and B. By induction, we have e~ < 
1 , 
(1 - L) 
(n - p + I ) ~ .  
Since G has no p-clique, every vj E B is adjacent 
P- 1 
to at most p - 2 vertices in A, and we obtain eA,B I 
(p - 2)(n - p + 1). 
Altogether, this yields 
which is precisely (1 - L)$. 
P- 1 
Second proof. 
This proof makes use of the structure of the Turin 
graphs. Let vm E V be a vertex of maximal degree d, = maxllj~, 
dj. 
Denote by S the set of neighbors of v,, IS1 = dm, and set T := V\S. As 
G contains no p-clique, and v, is adjacent to all vertices of S ,  we note that 
S contains no (p - 1)-clique. 
We now construct the following graph H on V (see the figure). H corre- 
sponds to G on S and contains all edges between S and T, but no edges 
within T. In other words, T is an independent set in H, and we con- 
clude that H has again no p-cliques. Let d(, be the degree of vj in H. 
If vj E S ,  then we certainly have di > dj by the construction of H, and 
for vj E T, we see di = IS1 = dm > dj by the choice of v,. 
We in- 
fer IE(H)I > I El, and find that among all graphs with a maximal number 
of edges, there must be one of the form of H. By induction, the graph 
induced by S has at most as many edges as a suitable graph Knl,,,,rnpp2
on S .  So IEl < IE(H)I < E(K, ,,..., np_,) with n,_l = ITI, which im- 
plies (1). 
0 
The next two proofs are of a totally different nature, using a maximizing 
argument and ideas from probability theory. They are due to Motzkin and 
Straus and to Alon and Spencer, respectively. 
Third proof. Consider a probability distribution w = (wl , . . . , w,) 
on the vertices, that is, an assignment of values wi > 0 to the vertices with 
Cy=, wi = 1. Our goal is to maximize the function 
f (w) = C wiwj. 
Suppose w is any distribution, and let vi and vj be a pair of non-adjacent 
vertices with positive weights wi, 
wj. Let si be the sum of the weights of 

Turan's graph theorem 
209 
all vertices adjacent to u,, and define s, similarly for uj, where we may 
assume that si > s f .  Now we move the weight from vj to vi, that is, the 
new weight of vi is wi + wj, while the weight of vj drops to 0. For the new 
new distribution w' we find 
f ( w f )  = f ( w )  +wjs, -wjsj 2 f ( w ) .  
We repeat this (reducing the number of vertices with a positive weight by 
one in each step) until there are no non-adjacent vertices of positive weight 
anymore. Thus we conclude that there is an optimal distribution whose 
c ' ~ o v i n g  
weights7s 
nonzero weights are concentrated on a clique, say on a k-clique. Now if, 
say, wl > w2 > 0, then choose E with 0 < E < wl - u12 and change wl 
to wl - E and w2 to w2 + E. The new distribution w' satisfies f (w') = 
f ( w )  + e(wl - w z )  - c2 > f (w), and we infer that the maximal value of 
f ( w )  is attained for 'wi = 
on a k-clique and wi = 0 otherwise. Since a 
k ( k - 1 )  
k-clique contains --i-- edges, we obtain 
Since this expression is increasing in k, the best we can do is to set k = p- 1 
(since G has no p-cliques). So we conclude 
for any distribution w .  In particular, this inequality holds for the uniform 
distribution given by wi = 
for all i. Thus we find 
which is precisely (1). 
0 
1 
Fourth proof. This time we use some concepts from probability theory. 
Let G be an arbitrary graph on the vertex set V = {vl, . . . , v,). Denote the 
degree of vi by di, and write w(G) for the number of vertices in a largest 
clique, called the clique number of G. 
" 
1 
Claim. We have w(G) > - 
n - d, 
2 = 1  
We choose a random permutation .ir = ulu2.. . vn of the vertex set V, 
where each permutation is supposed to appear with the same probability 
5, and then consider the following set C,. We put ui into C, if and only 
if vi is adjacent to all vj (j < i )  preceding v,. By definition, C, is a 
clique in G. Let X = IC, I be the corresponding random variable. We have 
X = C'"=, Xi, where X ,  is the indicator random variable of the vertex vi, 
that is, Xi = 1 or Xi = 0 depending on whether vi E C, or vi @ C,. Note 
that zl, belongs to C, with respect to the permutation viva . . . v, if and only 
if vi appears before all n - 1 - d, vertices which are not adjacent to vi, or 
in other words, if vi is thejir.st among vi and its n - 1 - di non-neighbors. 
The probability that this happens is h, 
hence E X i  = A. 

210 
Turan 's ~ r a a h  
theorem 
Thus by linearity of expectation (see page 84) we obtain 
Consequently, there must be a clique of at least that size, and this was our 
claim. To deduce Turin's theorem from the claim we use the Cauchy- 
Schwarz inequality from Chapter 17, 
1 
Set a, = J-, 
bi = =, 
then aibi = 1, and so 
At this point we apply the hypothesis w(G) 5 p - 1 of Turin's theorem. 
Using also CY=cld, 
= 21 El from the chapter on double counting, inequal- 
ity (2) leads to 
n2 5 (P - l ) ( n 2  - 21El)l 
and this is equivalent to Turin's inequality. 
Now we are ready for the last proof, which may be the most beautiful of 
them all. Its origin is not clear; we got it from Stephan Brandt, who heard 
it in Oberwolfach. It may be "folklore" graph theory. It yields in one stroke 
that the Turin graph is in fact the unique example with a maximal number 
of edges. It may be noted that both proofs 1 and 2 also imply this stronger 
result. 
Fifth proof. Let G be a graph on n vertices without a p-clique and with 
a maximal number of edges. 
Claim. G does not contain three vertices ul V .  w such that vw E E, 
but ILV @ E, UUI @ E. 
V 
0 u 
Suppose otherwise, and consider the following cases. 
Case I :  d(u) < d(v) or d(u) < d(w). 
We may suppose that d(u) < d(v). Then we duplicate v, that is, we create 
a new vertex v' which has exactly the same neighbors as v (but vv' is not 
an edge), delete u, and keep the rest unchanged. 
The new graph G' has again no p-clique, and for the number of edges we 
find 
IE(G0 I 
= IE(G) 
I + d(v) - 4 ~ )  
> IE(G)I 1 
a contradiction. 

Tura'n 's arauh theorem 
21 1 
. . 
Case 2: d(u) > d(v) and d(u) 2 d(w). 
;.-;' w  
Duplicate u twice and delete v  and us (as illustrated in the margin). Again, 
the new graph G' has no p-clique, and we compute (the - 1 results from the 
v .:.' 
, . 
edge vw): 
..: 
. . 
U 
U' 
U" 
IE(G1) 
1 
= IE(G) 
1 + 2d(u) - (d(v) + d(w) - 1 )  > IE(G) I. 
0' 
So we have a contradiction once more. 
A moment's thought shows that the claim we have proved is equivalent to 
the statement that 
u - t 1  :U u t l @ E ( G )  
defines an equivalence relation. Thus G  is a complete multipartite graph, 
G  = Kn ,, . . , n p p  
and we are finished. 
0 
References 
[I] M. AIGNER: Turan's graph theorem, Amer. Math. Monthly 102 (1995), 
808-8 16. 
[2] N. ALON & J. SPENCER: 
The Probabilistic Method, Wiley Interscience 1992. 
[3] P. ERDBS: On the graph theorem of Turan (in Hungarian), Math. Fiz. Lapok 
21 (I 970), 249-25 1. 
[4] T. S. MOTZKIN & E. G. STRAUS: Maxima for graphs and a new proof of a 
theorem of Turhn, Canad. J .  Math. 17 (1965), 533-540. 
[5] P. TURAN: On an extremal problem in graph theory, Math. Fiz. Lapok 48 
(1941). 436-452. 
"Larger weights to move " 

Communicating without errors 
In 1956, Claude Shannon, the founder of information theory, posed the 
following very interesting question: 
Suppose we want to transmit messages across a channel (where 
some symbols may be distorted) to a receiver: What is the maximum 
rate of transmission such that the receiver may recover the original 
message without errors? 
Let us see what Shannon meant by "channel" and "rate of transmission." 
We are given a set V of symbols, and a message is just a string of symbols 
from V. We model the channel as a graph G = (V, E), where V is the set 
of symbols, and E the set of edges between unreliable pairs of symbols, 
that is, symbols which may be confused during transmission. For example, 
communicating over a phone in everyday language, we connnect the sym- 
bols B and P by an edge since the receiver may not be able to distinguish 
them. Let us call G the confusion graph. 
The 5-cycle C5 will play a prominent role in our discussion. In this exam- 
ple, 1 and 2 may be confused, but not 1 and 3, etc. Ideally we would like 
to use all 5 symbols for transmission, but since we want to communicate 
error-free we can - 
if we only send single symbols - 
use only one let- 
ter from each pair that might be confused. Thus for the 5-cycle we can use 
only two different letters (any two that are not connected by an edge). In the 
language of information theory, this means that for the 5-cycle we achieve 
an information rate of log2 2 = 1 (instead of the maximal log, 5 z 232). 
It is clear that in this model, for an arbitrary graph G = (V, E), the best 
we can do is to transmit symbols from a largest independent set. Thus the 
information rate, when sending single symbols, is log2 a(G), where a(G) 
is the independence number of G. 
Let us see whether we can increase the information rate by using larger 
strings in place of single symbols. Suppose we want to transmit strings of 
length 2. The strings ulu2 and vlv, can only be confused if one of the 
following three cases holds: 
0 ul = vl and u2 can be confused with vz, 
0 uz = v2 and u l  can be confused with vl, or 
0 ul # vl can be confused and u2 # v2 can be confused. 
Chapter 33 
Claude Shannon 
In graph-theoretic terms this amounts to considering the product G1 x G2 
of two graphs G1 = (V*, E l )  and G2 = (Vi, E2). G1 x G2 has the vertex 

214 
Communicating without errors 
set Vl x V2 = {(ul,u2) : u1 E V1,u2 E V2), with (ul,u2) # ( v I , u ~ )  
connected by an edge if and only if ui = vi or U , V ~  E E for i = 1,2. The 
confusion graph for strings of length 2 is thus G2 = G x G, the product of 
the confusion graph G for single symbols with itself. The information rate 
of strings of length 2 per symbol is then given by 
Now, of course, we may use strings of any length n. The n-th confusion 
graph Gn = G x G x . . . x G has vertex set Vn = ((211,. . . , u,) : ui E V) 
with ( u l , .  . . . un) # (ul,. . . u,) being connected by an edge if ui = vi or 
uivi E E for all i. The rate of information per symbol determined by 
strings of length n is 
What can we say about a(Gn)? Here is a first observation. Let U c V 
be a largest independent set in G, IUI = a. The an vertices in Gn of the 
form (ul, 
. . . , u,), ui E U for all i, clearly form an independent set in Gn. 
Hence 
and therefore 
meaning that we never decrease the information rate by using longer strings 
instead of single symbols. This, by the way, is a basic idea of coding theory: 
By encoding symbols into longer strings we can make error-free communi- 
cation more efficient. 
Disregarding the logarithm we thus arrive at Shannon's fundamental 
definition: The zero-error capacity of a graph G is given by 
O(G) := sup "Ja(G"), 
n > l  
and Shannon's problem was to compute @(G), and in particular 0(C5). 
Let us look at C5. SO far we know a(C5) = 2 < O(Cg). Looking at 
the 5-cycle as depicted earlier, or at the product Cg x Cg as drawn on the 
left, we see that the set ((1, I), (2,3), (3,5), (4,2), (5,4)) is independent 
in C52. Thus we have a(C5') > 5. Since an independent set can contain 
only two vertices from any two consecutive rows we see that a(C:) 
= 5. 
Hence, by using strings of length 2 we have increased the lower bound for 
' 
the capacity to 0(C5) > &. 
So far we have no upper bounds for the capacity. To obtain such bounds 
we again follow Shannon's original ideas. First we need the dual definition 
of an independent set. We recall that a subset C C V is a clique if any 
The graph Cs x C5 
two vertices of C are joined by an edge. Thus the vertices form trivial 

Cornmunicatin~ without errors 
215 
cliques of size 1, the edges are the cliques of size 2, the triangles are cliques 
of size 3, and so on. Let C be the set of cliques in G. Consider an arbitrary 
probability distribution x = (x, : v E V) on the set of vertices, that 
is, x,, 2 0 and EVE" 
x, = 1. TO every distribution x we associate the 
"maximal value of a clique" 
h(x) = man C x,. 
C t C  U E C  
and finally we set 
X(G) = min X(x) = min man x 
x,. 
x 
x c t c  
uEC 
To be precise we should use inf instead of min, but the minimum exists 
because X(x) is continuous on the compact set of all distributions. 
Consider now an independent set U C V of maximal size a(G) = a .  
Associated to U we define the distribution x u  = (xu : v E V) by setting 
x, = d if v E U and x, = 0 otherwise. Since any clique contains at most 
one vertex from U ,  we infer X(xu) = i, 
and thus by the definition of X(G) 
What Shannon observed is that X(G)-l is, in fact, an upper bound for all 
?j'm, 
and hence also for O(G). In order to prove this it suffices to 
show that for graphs G, H 
holds, since this will imply X(Gn) = X(G)" and hence 
a(Gn) L: 
X(G")-' = X(G)-n 
?j'm 
5 A(G)-I. 
To prove (1) we make use of the duality theorem of linear programming 
(see [I]) and get 
X(G) = rnin max 
x, = man min 
yc, 
x C E C  
$I v E V  
vEC 
C3v 
where the right-hand side runs through all probability distributions y = 
(y, : C E C) on C. 
Consider G x H, and let x and x1 be distributions which achieve the 
minima, X(x) = X(G), X(xl) = X(H). In the vertex set of G x H we 
assign the value q,,,) 
= x,xh to the vertex (u, v). Since C(,,,) z(,,,) = 
x, xu x, 
x; = 1, we obtain a distribution. Next we observe that the max- 
imal cliques in G x H are of the form C x D = {(u, v) : u E C, v E D )  
where C and D are cliques in G and H, respectively. Hence we obtain 
- man x x, x 
x: = h(G)X(H) 
C x D  uEC 
,ED 

216 
Communicating without errors 
The LovBsz umbrella 
by the definition of X(G x H). In the same way the converse inequality 
X(G x H) > X(G)X(H) is shown by using the dual expression for X(G) 
in (2). In summary we can state: 
for any graph G. 
Let us apply our findings to the 5-cycle and, more generally, to the 
m-cycle C,,. 
By using the uniform distribution (k, 
. . . , A) on the 
vertices, we obtain X(C,) 
5 $, since any clique contains at most two 
vertices. Similarly, choosing $ for the edges and 0 for the vertices, we have 
X(C,) 
2 & by the dual expression in (2). We conclude that X(C,) 
= 
and therefore 
- 
for all rn. Now, if m is even, then clearly a(C,) 
= 
and thus also 
@(em) = y. For odd m, however, we have a(C,) = 9. 
For m = 3, 
C3 is a clique, and so is every product CF, implying a(C3) = 0(C3) = 1. 
So, the first interesting case is the 5-cycle, where we know up to now 
Using his linear programming approach (and some other ideas) Shannon 
was able to compute the capacity of many graphs and, in particular, of all 
graphs with five or fewer vertices - 
with the single exception of C5, where 
he could not go beyond the bounds in (3). This is where things stood for 
more than 20 years until Lisz16 Lovisz showed by an astonishingly simple 
argument that indeed 0(C5) = &. A seemingly very difficult combina- 
torial problem was provided with an unexpected and elegant solution. 
Lovisz' main new idea was to represent the vertices v of the graph by 
real vectors of length 1 such that any two vectors which belong to non- 
adjacent vertices in G are orthogonal. Let us call such a set of vectors 
an orthonormal representation of G. Clearly, such a representation always 
exists: just take the unit vectors (1,0,. . . , o ) ~ ,  
(0,1,0,. . . , o ) ~ ,  
. . . , 
(O,O,. . . , l)T of dimension m = IVI. 
For the graph C5 we may obtain an orthonormal representation in R3 by 
considering an "umbrella" with five ribs vl, . . . , v5 of unit length. Now 
open the umbrella (with tip at the origin) to the point where the angles 
between alternate ribs are 90". 
Lovisz then went on to show that the height h of the umbrella, that is, the 
distance between 0 and S, provides the bound 
A simple calculation yields h2 = 2; 
see the box on the next page. From 
4 5  
this 0(C5) < & follows, and therefore 0(C5) = &. 

Communicatin~ without errors 
217 
Let us see how LovAsz proceeded to prove the inequality (4). (His results 
were, in fact, much more general.) Consider the usual inner product 
(x, 
Y )  = XlYl + . . . + XsYs 
of two vectors x = (xl,. 
. . , x,), y = (yl,. 
. . , ys) in Rs. 
Then 1xI2 = 
(x, x )  = x: + . . . + x: is the square of the length 1x1 of x, and the angle y 
between x and y is given by 
Thus (x, 
y) = 0 if and only if x and y are orthogonal. 
Pentagons and the golden section 
Tradition has it that a rectangle was considered aesthetically pleasing 
if, after cutting off a square of length a, the remaining rectangle had 
the same shape as the original one. The side lengths a, b  of such a 
rectangle must satisfy 
= &. Setting r := 
for the ratio, we 
1 
obtain r = 
or r2 - r - 1 = 0. Solving the quadratic equation 
l + f i  
yields the golden section r = 
= 1.6180. 
Consider now a regular pentagon of side length a, and let d be the 
length of its diagonals. It was already known to Euclid (Book XIII,8) 
that 
= r, and that the intersection point of two diagonals divides 
the diagonals in the golden section. 
Here is Euclid's Book Proof. Since the total angle sum of the pen- 
tagon is 37r, the angle at any vertex equals %. It follows that 
QABE = ;, 
since ABE is an isosceles triangle. This, in turn, 
implies QAMB = F, and we conclude that the triangles ABC and 
A M B  are similar. The quadrilateral C M E D  is a rhombus since op- 
posing sides are parallel (look at the angles), and so 1 MCl = a and 
thus lAMl = d - a. By the similarity of ABC and AMB we con- 
There is more to come. For the distance s of a vertex to the center of 
the pentagon S ,  the reader is invited to prove the relation s2 = & 
(note that BS cuts the diagonal AC at a right angle and halves it). 
To finish our excursion into geometry, consider now the umbrella 
with the regular pentagon on top. Since alternate ribs (of length 1) 
form a right angle, the theorem of Pythagoras gives us d = 4, and 
hence s2 = & = -$$, . SO, with Pythagoras again, we find for the 
height h = lOSl our promised result 
b - a  

2 18 
Communicatin,e without errors 
Now we head for an upper bound "O (G) 
5 a~ l" for the Shannon capacity 
of any graph G that has an especially "nice" orthonormal representation. 
For this let T = {v('), . . . , v(")) be an orthonormal representation 
of G in Rs, where v ( ~ )  
corresponds to the vertex vi. We assume in 
addition that all the vectors v(~) 
have the same angle (# 90") with the 
vector u := &(v(') + . . . + v(")), or equivalently that the inner product 
has the same value a, # 0 for all i. Let us call this value a, the constant 
of the representation T. For the Lovisz umbrella that represents Cs the 
+ 
condition (v(~), 
u) = aT certainly holds, for u = 0s. 
Now we proceed in the following three steps. 
(A) Consider a probability distribution x = (xl, 
. . . , x,) on V and set 
and 
pT(G) := inf p(x) 
x 
Let U be a largest independent set in G with IUI = a, and define xu = 
(21,. 
. . , x,) 
with xi = $ if vi E U and xi = 0 otherwise. Since all 
vectors v(" have unit length and (v(~), = 0 for any two non-adjacent 
vertices, we infer 
Thus we have pT (G) 
< wl, and therefore 
(B) Next we compute pT (G). 
We need the Cauchy-Schwarz inequality 
(a, bj2 5 laI2 1bI2 
for vectors a, b E RS. 
Applied to a = xlv(') + . . . + z,v(") 
and b = u, 
the inequality yields 
By our assumption that (v(~), 
u) = a, for all i, we have 
for any distribution x. Thus, in particular, this has to hold for the uniform 
distribution (6, 
. . . , A), which implies 1uI2 = a,. Hence (5) reduces to 

Communicatinp without errors 
219 
On the other hand, for x = (k, . . . , $) we obtain 
and so we have proved 
P ~ ( ~ )  
= OT' 
In summary, we have established the inequality 
for any orthonormal respresentation T with constant aT . 
(C) To extend this inequality to O(G), 
we proceed as before. Consider 
again the product G x H of two graphs. Let G and H have orthonormal 
representations R and S in R' 
and Rs, 
respectively, with constants aR 
and as. Let v = ( ~ 1 , .  
. . . ur) be a vector in R and w = (wl, 
. . . , w,) 
be 
a vector in S. To the vertex in G x H corresponding to the pair (v, w )  
we 
associate the vector 
It is immediately checked that R x S := {vwT : v E R, 
w E S )  is an 
orthonormal representation of G x H with constant a R a s  Hence by (6) 
we obtain 
/lRxS(G 
= P ~ ( ~ ) P ~ ( ~ ) '  
For Gn = G x . . . x G and the representation T with constant aT this 
means 
pTn (Gn) 
= pT(GIn = 0; 
and by (7) we obtain 
Taking all things together we have thus completed Lovlsz' argument: 
Theorem. Whenever T = {v(l), . . . , dm)) 
is an orthonormal 
representation of G with constant isT, then 
1 
O(G) 5 -. 
(8) 
f
f
~
 
Looking at the Lovlsz umbrella, we have u = (0,O, h=&)T 
and hence 
45 
a = (v('),u) 
= h2 = 1 
which yields 0(C5) 
5 A. Thus Shannon's 
45' 
"Umbrellas wlrh$ve ribs" 
problem is solved. 

220 
Communicatinn without errors 
Let us carry our discussion a little further. We see from (8) that the larger aT 
is for a representation of G, the better a bound for O(G) we will get. Here 
is a method that gives us an orthonormal representation for any graph G. 
To G = (V, E) we associate the adjacency matrix A = (aij), which is 
defined as follows: Let V = {v',. . . , u,}, then we set 
1 if 
E E 
aij := 
0 otherwise. 
The adjacency matrix for the 5-cycle C5 
A is a real symmetric matrix with 0's in the main diagonal. 
Now we need two facts from linear algebra. First, as a symmetric matrix, 
A has m real eigenvalues A1 > A2 > . . . > A,, 
(some of which may 
be equal), and the sum of the eigenvalues equals the sum of the diagonal 
entries of A, that is, 0. Hence the smallest eigenvalue must be negative 
(except in the trivial case when G has no edges). Let p = I A,, 
/ = -A, 
be 
the absolute value of the smallest eigenvalue, and consider the matrix 
where I denotes the ( m  x m)-identity matrix. This M has the eigenvalues 
1 + > 1 + $ > . . . > 1 + 9 
= 0. NOW we quote the second result (the 
P 
principal axis theorem of linear algebra): If M = (rn,j) is a real symmetric 
matrix with all eigenvalues > 0, then there are vectors ~ ( ' 1 ,  . . . , v(") E Rs 
for s = rank(M), such that 
In particular, for M = I + ;A we obtain 
( v ,  v
)
 = r n  
Z Z  - 
- 1 
for a11 i 
Since aij = 0 whenever vivj $! E, we see that the vectors v('), . . . , v(") 
form indeed an orthonormal representation of G. 
Let us, finally, apply this construction to the m-cycles Cm for odd m 2 5. 
Here one easily computes p = IAmi, 1 = 2 cos 5 (see the box). Every 
row of the adjacency matrix contains two I 's, implying that every row of 
the matrix M sums to 1 + $. For the representation {v('), . . . , ~
(
~
1
)
 
this 
means 
and hence 
1 
( v ( ~ ) ,  
U )  = -(I 
m + (cos 2 ) - l )  = . 
for all i. We can therefore apply our main result (8) and conclude 
rn 
(for rn > 5 odd). 

Communicating without errors 
22 1 
Notice that because of cos $ < 1 the bound (9) is better than the bound 
O(Cm) 
5 
we found before. Note further cos 
= 5 ,  where r = 
is the golden section. Hence for r n  = 5 we again obtain 
The orthonormal representation given by this construction is, of course, 
precisely the "Lovisz umbrella." 
And what about C7, 
C9, and the other odd cycles? By considering a(Ck), For example, for m = 7 all we know is 
a(C%) 
and other small powers the lower bound 
5 O(Cm) 
can cer- m 
5 o ( C 7 )  5 
7 
tainly be increased, but for no odd m > 7 do the best known lower bounds 
1 + (cos $)-I ' 
agree with the upper bound given in (8). So, twenty years after Lovasz' 
which is 3.2141 5 Q(C7) 5 3.3177. 
marvelous proof of 0(C5) 
= &, these problems remain open and are 
considered very difficult - 
but after all we had this situation before. 
The eigenvalues of C, 
Look at the adjacency matrix A of the cycle Cm. To find the eigen- 
values (and eigenvectors) we use the m-th roots of unity. These are 
given by 1, <, C2, . . . , Cm-' for C = e? - 
see the box on page 25. 
Let X = Ck be any of these roots, then we claim that 
(1, A, X2, . . . , 
is an eigenvector of A to the eigenvalue X + 
A-l. In fact, by the set-up of A we find 
Since the vectors (1, A,. . . , Am-') 
are independent (they form a so- 
called Vandermonde matrix) we conclude that for odd m 
are all the eigenvalues of A. Now the cosine is a decreasing function, 
is the smallest eigenvalue of A. 

Cornmunicatinn without errors 
References 
[ 11 V. CHVATAL: Linear Programming, Freeman, New York 1983. 
[2] W. HAEMERS: Eigenvalue methods, in: "Packing and Covering in Combina- 
torics" (A. Schrijver, ed.), Math. Centre Tracts 106 (1979), 15-38. 
[3] L. LOVASZ: On the Shannon capacity of a graph, IEEE Trans. Information 
Theory 25 (1979), 1-7. 
[4] C. E. SHANNON: 
The zero-error capacity of a noisy channel, IRE Trans. 
Information Theory 3 (1 956), 3- 15. 

Of friends and politicians 
Chapter 34 
It is not known who first raised the following problem or who gave it its 
human touch. Here it is: 
Suppose in a group of people we have the situation that any pair of 
persons have precisely one common friend. Then there is always a 
person (the "politician ") who is everybody 'sfriend. 
In the mathematical jargon this is called the friendship theorem. 
Before tackling the proof let us rephrase the problem in graph-theoretic 
terms. We interpret the people as the set of vertices V and join two vertices 
by an edge if the corresponding people are friends. We tacitly assume that 
friendship is always two-ways, that is, if u is a friend of v, then v is also 
a friend of u, 
and further that nobody is his or her own friend. Thus the 
theorem takes on the following form: 
Theorem. Suppose that G is ajnite graph in which any two vertices have 
precisely one common neighbor. Then there is a vertex which is adjacent to 
all other vertices. 
Note that there are finite graphs with this property; see the figure, where u 
is the politician. However, these "windmill graphs" also turn out to be the 
only graphs with the desired property. Indeed, it is not hard to verify that in 
the presence of a politician only the windmill graphs are possible. 
Surprisingly, the friendship theorem does not hold for infinite graphs! 
Indeed, for an inductive construction of a counterexample one may start for 
example with a 5-cycle, and repeatedly add common neighbors for all pairs 
of vertices in the graph that don't have one, yet. This leads to a (countably) 
infinite friendship graph without a politician. 
Several proofs of the friendship theorem exist, but the first proof, given by 
Paul Erdiis, Alfred Renyi and Vera S6s, is still the most accomplished. 
"A politician's smile" 
A windmill graph 
Proof. Suppose the assertion is false, and G is a counterexample, that is, 
no vertex of G is adjacent to all other vertices. To derive a contradiction we 
proceed in two steps. The first part is combinatorics, and the second part is 
linear algebra. 
(1) We claim that G is a regular graph, that is, d(u) = d(v) for any u, 
v E V. 
Note first that the condition of the theorem implies that there are no cycles 
of length 4 in G. Let us call this the C4-condition. 

224 
O f  friends and politicians 
We first prove that any two non-adjacent vertices u and v have equal degree 
d ( u )  = d(z1). Suppose d ( u )  = Ic, where wl, . . . , ulk are the neighbors of u. 
Exactly one of the w,, say w2, is adjacent to v, and w2 adjacent to exactly 
one of the other 7u,'s, say wl, so that we have the situation of the figure to 
fi 
the left. The vertex v has with wl the common neighbor w2, and with w, 
(z 2 2 )  a common neighbor z, (i > 2). By the C4-condition, all these z, 
must be distinct. We conc!ude d(v) > k = d(u), and thus d(u) = d(v) = k 
by symmetry. 
To finish the proof of (I), observe that any vertex different from w2 is not 
adjacent to either u or v, and hence has degree k, by what we already 
23 . . .  
proved. But since w2 also has a non-neighbor, it has degree k as well, 
2 k 
and thus G is k-regular. 
Summing over the degrees of the Ic neighbors of u we get k2. Since 
every vertex (except IL) has exactly one common neighbor with u, we have 
counted every vertex once, except for u, which was counted k times. So 
the total number of vertices of G is 
(2) The rest of the proof is a beautiful application of some standard results 
of linear algebra. Note first that k must be greater than 2, since for k 5 2 
only G = K1 and G = K3 are possible by ( I ) ,  both of which are trivial 
windmill graphs. Consider the adjacency matrix A = (ai,), 
as defined on 
page 220. By part (I), any row has exactly k l's, and by the condition of 
the theorem, for any two rows there is exactly one column where they both 
have a 1. Note further that the main diagonal consists of 0's. Hence we 
have 
A2 = 
... 1 
k 
where I is the identity matrix, and J the matrix of all 1's. It is immediately 
checked that J has the eigenvalues n (of multiplicity 1) and 0 (of multi- 
plicity n - 1). It follows that A2 has the eigenvalues k - 1 + n = k2 
(of multiplicity 1) and Ic - 1 (of multiplicity n - 1). 
Since A is symmetric and hence diagonalizable, we conclude that A has 
the eigenvalues k (of multiplicity 1) and i m .  
Suppose r of the 
eigenvalues are equal to 
and s of them are equal to --, 
with 
r + s = n - 1. Now we are almost home. Since the sum of the eigenvalues 
of A equals the trace (which is 0), we find 
and, in particular, r # s, and 

O f  friends and voliticians 
225 
Now if the square root fi 
of a natural number m is rational, then it is an 
integer! An elegant proof for this was presented by Dedekind in 1858: Let 
no be the smallest natural number with n o f i  E N. If fi 
@ N, 
then there 
exists e E N with 0 < fi 
- e < 1. Setting nl := no(+ 
- t), we find 
nl E W and nl f i  = n o ( 6  - e ) J m  = nom - e(nOV%) 
E N. With 
nl < no this yields a contradiction to the choice of no. 
Returning to our equation, let us set h = 
E N, 
then 
Since h divides h2 + 1 and h2, we find that h must be equal to 1, and 
thus k = 2, which we have already excluded. So we have arrived at a 
contradiction, and the proof is complete. 
0 
However, the story is not quite over. Let us rephrase our theorem in the 
following way: Suppose G is a graph with the property that between any 
two vertices there is exactly one path of length 2. Clearly, this is an equiv- 
alent formulation of the friendship condition. Our theorem then says that 
the only such graphs are the windmill graphs. But what if we consider 
paths of length more than 2? A conjecture of Anton Kotzig asserts that the 
analogous situation is impossible. 
Kotzig's Conjecture. Let e > 2. Then there are no$nite graphs with the 
property that between any two vertices there is precisely one path of 
length P. 
Kotzig himself verified his conjecture for e < 8. In [3] his conjecture 
is proved up to t! = 20, and A. Kostochka has told us recently that it is 
now verified for all ! < 33. A general proof, however, seems to be out of 
reach . . . 
References 
[I] P. E R D ~ S ,  
A. RENYI & V. SOS: On a problem of graph theory, Studia Sci. 
Math. 1 (1966). 215-235. 
[2] A. KOTZIG: 
Regularly k-path connected graphs, Congressus Numerantium 40 
(1983), 137-141. 
[3] A. KOSTOCHKA: 
The nonexistence of certain generalized friendship graphs, 
in: "Cornbinatorics" (Eger, 1987), Colloq. Math. Soc. Jhnos Bolyai 52, North- 
Holland, Amsterdam 1988, 341-356. 

Probability makes counting 
(sometimes) easy 
Just as we started this book with the first papers of Paul ErdBs in num- 
ber theory, we close it by discussing what will possibly be considered his 
most lasting legacy - 
the introduction, together with Alfred RCnyi, of the 
probabilistic method. Stated in the simplest way it says: 
a in a given set of objects, the probability that an object does not 
have a certain property is less than 1, then there must exist an object 
with this property. 
Thus we have an existence result. It may be (and often is) very difficult to 
find this object, but we know that it exists. We present here three examples 
(of increasing sophistication) of this probabilistic method due to Erdiis, and 
end with a particularly elegant recent application. 
As a warm-up, consider a family 3 of subsets A,, all of size d 2 2, of a 
finite ground-set X. We say that 3 is 2-colorable if there exists a coloring 
of X with two colors such that in every set A, both colors appear. It is 
immediate that not every family can be colored in this way. As an example, 
take all subsets of size d of a (2d - 1)-set X. Then no matter how we 
2-color X, there must be d elements which are colored alike. On the other 
hand, it is equally clear that every subfamily of a 2-colorable family of 
d-sets is itself 2-colorable. Hence we are interested in the smallest number 
m = m(d) for which a family with m sets exists which is not 2-colorable. 
Phrased differently, m(d) is the largest number which guarantees that 
every family with less than m(d) sets is 2-colorable. 
Theorem 1. Every family of at most 2d-1 d-sets is 2-colorable, that is, 
m(d) > 2d-1. 
W Proof. Suppose 3 is a family of d-sets with at most 2"' 
sets. Color X 
randomly with two colors, all colorings being equally likely. For each set 
A E .F let EA be the event that all elements of A are colored alike. Since 
there are precisely two such colorings, we have 
and hence with m = 131 < 2d-1 (note that the events EA are not disjoint) 
Chapter 35 
We conclude that there exists some 2-coloring of X without a unicolored 
d-set from 3, and this is just our condition of 2-colorability. 
0 

228 
Probability makes counting (sometimes) easy 
3 
An upper bound for m(d), roughly equal to d22d, was also established by 
ErdBs, again using the probabilistic method, this time taking random sets 
and a fixed coloring. As for exact values, only the first two m(2) = 3, 
m(3) = 7 are known. Of course, m(2) = 3 is realized by the graph K3, 
while the Fano configuration yields m(3) < 7. Here 3 consists of the seven 
3-sets of the figure (including the circle set {4,5,6)). The reader may find 
it fun to show that 3 needs 3 colors. To prove that all families of six 3-sets 
are 2-colorable, and hence m(3) = 7, requires a little more care. 
1 
2 
Our next example is the classic in the field - 
Ramsey numbers. Consider 
6 
the complete graph KN on N vertices. We say that KN has property (m, n) 
if, no matter how we color the edges of KN red and blue, there is always a 
complete subgraph on m vertices with all edges colored red or a complete 
subgraph on n vertices with all edges colored blue. It is clear that if KN 
has property (m, n), then so does every K, with s > N. So, as in the first 
example, we ask for the smallest number N (if it exists) with this property 
- 
and this is the Ramsey number R(m, n). 
As a start, we certainly have R(m, 2) = m because either all of the edges 
of K, are red or there is a blue edge, resulting in a blue K2. By symmetry, 
we have R(2. n )  = n. Now, suppose R ( m  - 1, n) and R(m, n - 1) exist. 
We then prove that R(m, n) exists and that 
edges 
21 
.... 
......... 
...... 
. . .  
. . 
. . 
. . 
B 
Suppose N = R ( m  - 1, n )  + R(m, n - I), and consider an arbitrary red- 
blue coloring of K N .  For a vertex v, let A be the set of vertices joined to v 
by a red edge, and B the vertices joined by a blue edge. 
Since lAl + 1B1 = N - 1, we find that either IAl > R ( m  - 1 , n )  or 
I B( > R(m, n - 1). Suppose IAl 2 R ( m  - 1, n), the other case being 
analogous. Then by the definition of R ( m  - 1, n), there either exists in A a 
subset AR of size m - 1 all of whose edges are colored red which together 
with v yields a red K,, 
or there is a subset A, 
of size n with all edges 
colored blue. We infer that KN satisfies the (m, n)-property and Claim (1) 
follows. 
Combining (1) with the starting values R(m, 2) = m and R(2, n) = n, we 
obtain from the familiar recursion for binomial coefficients 
and, in particular 
Now what we are really interested in is a lower bound for R(k, k). This 
amounts to proving for an as-large-as-possible N < R(k, k) that there 
exists a coloring of the edges such that no red or blue Kk results. And this 
is where the probabilistic method comes into play. 

Probability makes countinn (sometimes) easy 
229 
Theorem 2. For all k > 2, the following lower bound holds for the Ramsey 
numbers: 
R(k:k) 2 2 s .  
. 
. 
. 
* 
______.....,_______ 
L _ _ _ _ _ _ _ _ _ _ _  
H Proof. We have R ( 2  2) = 2. o
m
 
(2) we know 3 
3) 5 6, and the 
. , / b l u e ,  ,,,, 1 
.. : 
. ,, 
pentagon colored as in the figure shows R(3,3) = 6. 
;. .. . 
,' .' * 
Now let us assume k > 4. Suppose N < 24, and consider all red-blue 
I 
,+- .. 
, .' 
colorings, where we color each edge independently red or blue with proba- 
... *. 
N 
bility +. Thus all colorings are equally likely with probability 2-( 2 1. Let A 
be a k t  of vertices of size k. The probability of the event A, that the edges 
in A are all colored red is then 2-(:). 
Hence it follows that the probability 
pR for some k-set to be colored all red is bounded by 
p, 
=  rob( U A,) 
5 
Prob(A,) 
= (T) 2 4 3 .  
IA/=k 
IAl=k 
Now with N < 2g and k > 4, using (y) 5 & for k > 2 (see page 12), 
we have 
Hence p, 
< $, and by symmetry pB < 
for the probability of some 
k vertices with all edges between them colored blue. We conclude that 
pR + pR < 1 for N < 24, so there must be a coloring with no red or 
blue Kk, which means that KN does not have property (k, k). 
0 
Of course, there is quite a gap between the lower and the upper bound for 
R(k, k). Still, as simple as this Book Proof is, no lower bound with a better 
exponent has been found for general k in the more than 50 years since 
Erdiis' result. In fact, no one has been able to prove a lower bound of the 
form R(k, k) > 2($+'lk nor an upper bound of the form R(k, k) < 2(2-E)" 
for a fixed E > 0. 
Our third result is another beautiful illustration of the probabilistic method. 
Consider a graph G on n vertices and its chromatic number x ( G )  If x(G) 
is high, that is, if we need many colors, then we might suspect that G 
contains a large complete subgraph. However, this is far from the truth. 
Already in the fourties Blanche Descartes constructed graphs with arbitrar- 
ily high chromatic number and no triangles, that is, with every cycle having 
length at least 4, and so did several others (see the box on the next page). 
However, in these examples there were many cycles of length 4. Can we do 
even better? Can we stipulate that there are no cycles of small length and 
still have arbitrarily high chromatic number? Yes we can! To make matters 
precise, let us call the length of a shortest cycle in G the girth y(G) of G; 
then we have the following theorem, first proved by Paul Erdiis. 

230 
Probability makes counting (sometimes) easy 
Triangle-free graphs with high chromatic number 
Here is a sequence of triangle-free graphs GB, G4, . . . with 
Start with G3 = C5, the 5-cycle; thus x(G3) = 3. Suppose we have 
already constructed G, on the vertex set V. The new graph Gn+l has 
the vertex set V U V' U { z ) ,  where the vertices v' E V' correspond 
bijectively to v E V, and z is a single other vertex. The edges of 
G,+l fall into 3 classes: First, we take all edges of G,; secondly 
every vertex v' is joined to precisely the neighbors of v in G,; thirdly 
z is joined to all v' E V'. Hence from Gg = C5 we obtain as Gq the 
so-called Mycielski graph. 
Clearly, G,+1 is again triangle-free. To prove x(G,+l) = n + 1 we 
use induction on n. Take any n-coloring of G, and consider a color 
class C. There must exist a vertex v E C which is adjacent to at 
least one vertex of every other color class; otherwise we could dis- 
tribute the vertices of C onto the n - 1 other color classes, resulting 
in x(G,) 5 n - 1. But now it is clear that v' (the vertex in V' cor- 
responding to v) must receive the same color as v in this n-coloring. 
So, all n colors appear in V', and we need a new color for z. 
Constructing the Mycielski graph 
Theorem 3. For every k > 2, there exists a graph G with chromatic 
number x(G) > k andgirth y(G) > k. 
The strategy is similar to that of the previous proofs: We consider a cer- 
tain probability space on graphs and go on to show that the probability for 
x(G) 5 k is smaller than i, and similarly the probability for y(G) < k 
is smaller than i. Consequently, there must exist a graph with the desired 
properties. 
Proof. Let V = {vl, va, . . . , v,) be the vertex set, and p a fixed num- 
ber between 0 and 1, to be carefully chosen later. Our probability space 
G(n, p) consists of all graphs on V where the individual edges appear with 
probability p, independently of each other. In other words, we are talking 
about a Bernoulli experiment where we throw in each edge with proba- 
bility p. As an example, the probability Prob(K,) for the complete graph 
is Prob(K,) = p(;). In general, we have Prob(H) = pm (1 - p)(;)-m 
if 
the graph H on V has precisely m edges. 
Let us first look at the chromatic number x ( G )  By a = a(G) we denote 
the independence number, that is, the size of a largest independent set in G. 
Since in a coloring with x = x(G) colors all color classes are independent 
(and hence of size 5 a), we infer xa 2 n. Therefore if a is small as 
compared to n, then x must be large, which is what we want. 
Suppose 2 < r 5 n. The probability that a fixed r-set in V is independent 

Probability makes counting (sometimes) easy 
23 1 
is (1 - p) (;I, 
and we conclude by the same argument as in Theorem 2 
since 1 - p < e-" for all p. 
Given any fixed k > 0 we now choose p := n- A, and proceed to show 
that for n large enough, 
Indeed, since n h  grows faster than log n, we have n h  > 6k log n 
for large enough n, and thus p > 6k%. 
For I- := [$-I 
this gives 
pr > 3 log n, and thus 
which converges to 0 as n goes to infinity. Hence (3) holds for all n > nl. 
Now we look at the second parameter, y(G). For the given k we want to 
show that there are not too many cycles of length 5 k. Let i be between 3 
and k, and A C V a fixed i-set. The number of possible i-cycles on A is 
clearly the number of cyclic permutations of A divided by 2 (since we may 
traverse the cycle in either direction), and thus equal to v. 
The total 
number of possible i-cycles is therefore ('2") v, 
and every such cycle C 
appears with probability pi. Let X be the random variable which counts the 
number of cycles of length 5 k. In order to estimate X we use two simple 
but beautiful tools. The first is linearity of expectation, and the second is 
Markov's inequality for nonnegative random variables, which says 
where E X  is the expected value of X .  See the appendix to Chapter 14 for 
both tools. 
Let Xc be the indicator random variable of the cycle C of, say, length i. 
That is, we set X c  = 1 or 0 depending on whether C appears in the graph 
or not; hence E X c  = pY 
Since X counts the number of all cycles of 
length < k we have X = C Xc, and hence by linearity 
1 
where the last inequality holds because of n p  = n"+' > 1. Applying now 
Markov's inequality with a = ;, 
we obtain 

232 
Probability makes counting (sometimes) easy 
Since the right-hand side goes to 0 with n going to infinity, we infer that 
p(X > :) 
< $ forn > nz. 
Now we are almost home. Our analysis tells us that for n > max(nl, n2) 
there exists a graph H on n vertices with a(H) < $ and fewer than 5 
cycles of length < k. Delete one vertex from each of these cycles, and 
let G be the resulting graph. Then y(G) > k holds at any rate. Since G 
contains more than 2 vertices and satisfies a ( G )  5 a ( H )  < &, we find 
and the proof is finished. 
0 
Explicit constructions of graphs with high girth and chromatic number (of 
huge size) are known. (In contrast, one does not know how to construct 
redhlue colorings with no large monochromatic cliques, whose existence 
is given by Theorem 2.) What remains striking about the ErdBs proof is 
that it proves the existence of relatively small graphs with high chromatic 
number and girth. 
To end our excursion into the probabilistic world let us discuss an important 
result in geometric graph theory (which again goes back to Paul ErdBs) 
whose stunning Book Proof is of very recent vintage. 
Consider a simple graph G = G(V, E) with n vertices and m edges. We 
want to embed G into the plane just as we did for planar graphs. Now, we 
know from Chapter 11 - 
as a consequence of Euler's formula - 
that a 
simple planar graph G has at most 3n - 6 edges. Hence if m is greater 
than 3n - 6, there must be crossings of edges. The crossing number cr(G) 
is then naturally defined: It is the smallest number of crossings among all 
drawings of G, where crossings of more than two edges in one point are 
not allowed. Thus cr(G) = 0 if and only if G is planar. 
In such a minimal drawing the following three situations are ruled out: 
0 No edge can cross itself. 
0 Edges with a common endvertex cannot cross. 
0 No two edges cross twice. 
This is because in either of these cases, we can construct a different drawing 
of the same graph with fewer crossings, using the operations that are indi- 
cated in our figure. So, from now on we assume that any drawing observes 
these rules. 
Suppose that G is drawn in the plane with cr(G) crossings. We can im- 
mediately derive a lower bound on the number of crossings. Consider the 
following graph H: The vertices of H are those of G together with all 
crossing points, and the edges are all pieces of the original edges as we go 
along from crossing point to crossing point. 
The new graph H is now plane and simple (this follows from our three 
assumptions!). The number of vertices in H is n + cr(G) and the number 

Probabilitv makes counting (sometimes) easv 
233 
of edges is m + 2cr(G), since every new vertex has degree 4. Invoking the 
bound on the number of edges for plane graphs we thus find 
that is, 
cr(G) > m - 3n + 6 
As an example, for the complete graph K6 we compute 
f
l
~
cr(K6) 2 15 - 18 + 6 = 3 
and, in fact, there is an drawing with just 3 crossings. 
The bound (4) is good enough when m is linear in n, but when m is larger 
compared to n, then the picture changes, and this is our theorem. 
Theorem 4. Let G be a simple graph with n vertices and m edges, where 
rn > 4n. Then 
The history of this result, called the crossing lemma, is quite interesting. 
It was conjectured by Erdiis and Guy in 1973 (with & replaced by some 
constant c). The first proofs were given by Leighton in 1982 (with 
in- 
stead of &) and independently by Ajtai, Chvital, Newborn and SzemerCdi. 
The crossing lemma was hardly known (in fact, many people thought of it 
as a conjecture long after the original proofs), until Lisz16 SzCkely demon- 
strated its usefulness in a beautiful paper, applying it to a variety of hitherto 
hard geometric extremal problems. The proof which we now present arose 
from e-mail conversations between Bernard Chazelle, Micha Sharir and 
Emo Welzl, and it belongs without doubt in The Book. 
Proof. Consider a minimal drawing of G, and let p be a number between 
0 and 1 (to be chosen later). Now we generate a subgraph of G, by selecting 
the vertices of G to lie in the subgraph with probability p, independently 
from each other. The induced subgraph that we obtain that way will be 
called G,. 
Let n,, m,, X, be the random variables counting the number of vertices, 
of edges, and of crossings in G,. Since cr(G) - m + 3n > 0 holds by (4) 
for any graph, we certainly have 
Now we proceed to compute the individual expectations E(n,p), 
E(m,) and 
E(X,). Clearly, E(n,) = pn and E(m,) = p2m, since an edge appears 
in G, if and only if both its endvertices do. And finally, E(X,) = p4cr(G), 
since a crossing is present in G, if and only if all four (distinct!) vertices 
involved are there. 

234 
Probability makes counting (sometimes) easy 
By linearity of expectation we thus find 
which is 
Here comes the punch line: Set p := $ (which is at most 1 by our assump- 
tion), then (5) becomes 
and this is it. 
Paul ErdBs would have loved to see this proof. 
References 
[I] M. AJTAI, V. CHVATAL, M. NEWBORN & E. SZEMEREDI: 
Crossingfree 
subgraphs, Annals of Discrete Math. 12 (1982), 9-12. 
[2] N. ALON & J. SPENCER: 
The Probabilistic Method, Second edition, Wiley- 
Interscience 2000. 
[3] P. ERDBS: Some remarks on the theory of graphs, Bulletin Amer. Math. Soc. 
53 (1947), 292-294. 
[4] P. ERDBS: Graph theory andprobability, Canadian J .  Math. 11 (1959), 34-38. 
[5] P. ERDBS: On a combinatorial problem I, Nordisk Math. Tidskrift 11 (1963), 
5-10. 
[6] P. E R D ~ S  
& R. K. GUY: Crossing number problems, Amer. Math. Monthly 
80 (1973), 52-58. 
[7] P. E R D ~ S  
& A. R ~ N Y I :  
On the evolution of random graphs, Magyar Tud. 
Akad. Mat. Kut. Int. Kozl. 5 (1960), 17-61. 
[8] T. LEIGHTON: Complexity Issues in VLSI, MIT Press, Cambridge MA 1983. 
[9] L. A. SZEKELY: Crossing numbers and hard Erd6s problems in discrete 
geometry, Combinatorics, Probability, and Computing 6 (1997), 353-358. 

Index
..'y"h"~,«,,"""""lhM
......,... ,1><00""'" I!X
...........y ......... !!U
"';><<nO '·<flo·"," ~
..,~"".. I~I
..,"'.....·""'
IIH
..,pli<ry'
::t><
•• =t<~""'.""
....."'" """""",~ ~"'".... I.~
11<
110 ............ ·10. 1.10
1I<r>,
·,I'"",,LoI<.7
"'''''
~.l.I~1
1l'
.c_hyf,."'"... It.'I.17S
"'
""rtIo:i<... 1l
",,,,,,,,I<it""".']. Ihl
"'n.....11"""""',,·IS7
II."",~",""F"'..... Il.I
Iln..~
·•10.>«11'0.. ..."....... 1'1
Huff
-"'" I"'_on. I "
C.I~'''\''-,Ir...... ~S
<..~,....._,.9j
<oril'O>l;'y. ~l. 1m
C_h(..... 1<"',
7~
C."h)·. ri~",,) ,h<>
)1
C"",·h).S<h~..,,~,,)·. I!"'
C.)I<y".h......L>..l1l
........ !j
«nOr..." ....!l
......,..1) ') on......, ! I
'''''•. 1'1
,.......... ~IJ
C1Irbj>J>n 1"~1
1,- I ~l
C1Irbj
~
""'
II ~
d..",. r'
I.. ~.
<lOp. S7. ;>In. )1.
,tOp "",""",.::0-'
~"''''._
,).""
!!7
,,·,_...."
1)· """"
, I
" .._,
",,0,,;.,..... N
,,"''''''
",,,,,,;1< ~'''fIh. ~
"""J'I<I< ""fIh. ~
"""f'k.• I"'iJ........ 117
""'.'.",r'" !Il
"..,"*'... SI
" ......"<>1.'1
<to",,",",". '1'1
" ......'",h)l""h""... ID!
..."""I".).....,u
" ...., "'''<'. :I"
..."'''' 1".).......1. I~ I
" ...._. ~J
«"1"" «~",,".',1"'_.... ISK
<til.-,.) r....I). I~
<"",,", !<'rnmo.1.ll
<",,,,,., ...n....~.lJ~
,....... :Ill
,·y<lt. S1
{·,,,,ool"
,~lJ
(',.1'"" ~'
I....
.....,.".. ..
Ilri><>
·..,""'.~1
I"".-I
~.,...""'...,....1
......... IOJ
....'\<nn,..-,.lh1
~,"'_1..,1<.•7
~,,,,,,,,,,,,,.'I'I
~,...n,".. ,..." ~r""". 1-11)
I~""I 1'"\01>1<",
I~)
~i"""""""IK7
~i"",
,,~. !J
110..""'« "... "1
<lu>I~~."'.I'I'I
«lr< "'" Ir_I*>. ~
Nf"'~ "1'.)I1<01.,... :on
<I<"",,"'} ,,~u.", t.'I
«f"'1 ",.. ~.l

"",,~.,..orl<m<"""'" ~lllo.""'" ~l
"f"....,~
"'~Jb<dolo.~'
f-""l.·I(,~I("", ""'''''... I~l
E.""" 11<'1,,,,,,,,,,,("",,,,,...~
I:ol<t., "''''~ J,
"'",,1
,
110
<>('«1
""
(
..,.~."-'
r
j(I
l'<r1nooI ""~, J
ij.,,,, Ikkl. ~J
ij.,,,,'" 'J'''''''' III
(,........ ~7
1""""'fIo
""..".
I~I
',_
_""... 1'1'1
fri<""""r""'''''''' ~!.l
,.....,...,.."'
1\1'1
C"',"'I.V
lrnun.>.1.7
I"..ld.!l'
"""""""'."'.~17
IC""",.~
r'"l'" ......,... 1'1'1
I'""",·of. po.'j."",."
....-.,...1<",,,,
11>1
....-.,..."'
10
1lnj:.".'n',".1!7
II,,,,,,,," ",,,,, r"....,"'~l
.,,,,,,.o,""'l "'1IfN"........ ""
,,,,,l<l<n«"""-;, l.I. «!
,..nl<-no. ~
,
'".1~7
,
..,..-.l<................ llJ. :.10
'''''''I''''.''''' ""- '7. l"-l
,..........-.l .......c"""', '7. Il'/\
'-..1""".1l1'1
,.,i.,,,""."",... '*1
,.....".",-.1..""",. lUI>
,••,.",.-u.; f.""ly.
1~2
'm·.......... : ..
lIT"'''' ""","",,:7
'~IC"""'."
1""'_,
I......IN It..... I1J
l""l;'"'p", ""'..... ~
I...,. """'11<. fill)
I.<o<i
IN. I&.I
1.ou~
h'I
1M','" ""'
70
I..,~.. ,...
,.7
'-<t<.......·.'
"'.1
I".. ~'>J>I>. '\OIl
"",".my... ..,,""',.."'" 1I-l.1J->
I", , ...._"' ..""",. Il'/\
I", ,..>l<""'s- IIIII.:'OJ
I'''l<>o"".{)ff,.d 1",.,111..... I:J
."",lIt
1'~N """",,II., 2111
",,,'.1,,,' ,110."",." 21.
u ..~,,,,·,, '""f""I"I.1I-l
........,.. ""'...... Il.I
"...'1,,,,,.11'"
....,i,,,.-.... l.""
........_ll« Ihr;""
17'
"......,
~
"".""',1, ,J,,"1"o.1Ii,...... '"
...,n.;,,~."
.........~.... ,..J
,,",f"r*al~lIt
""'..,,"' 1"",iI>. llll
",,',,,''', r~!Jt1
....·
,.I:ooalrl_ rc
.no
.....-l,-~
'f'.... ,·...,
lIIt
.......Rt-.I~'
""'lI.........'"
Nn,."",,', I...·'.... *J
,*""", ...~k. N
' ''''''''.... ':.
"'
, • ~'"'" <1<_
~
,
..-d ""- '0'
••";..1""";"'.105
,.,roo
1l<1'fC'<'lI....., :111
.>UIdq:
f~7
1'""'" I
," .......... IN
1'"""
).,
1"'i"
_n~I"'
""".IJ

I"'h·....,;" 101
1""•...-.. ............. 1~3
""hOdi< fOfl<l>O&, 1Z~
Pi<l', '."""'''. fR
pi,....-...... ~ipk. ll'l
......... ,""". b.l
JlI:- 'I'Of'h. b.l. .'l1O
_"""Ii,....;,....'"
FI'~)""', SO
1"~)l1«lmoI.~" W
1"'i)..,......~i'I"n1fi"••. III, I:!O
I"'i)"""'. lY
rn.... li<loI.lli
p;""'_~.J.7
"'".....-.._
10
rn
h~"'
,ZZ7
1'I'
ldj' <li>Uiloa
ltlli
l'I''''''';boj' ""'
!I-l
1"'.......'01',.-
:13
1"'".....".< pl,
,.~
Ram"l oumlo<,.n_
-""" ,,,,jah!o.lIO
..... orlml""i,..... llJ
"";0'0',"'''''''''''''. IJ7
II.."""",,,,. f"......... 1
"tl\,,,....fII<,.IM
R<'l<"·Il_JlIIli.lrnoi,,,,,. I~
n._for<".ln
n••,o!",,0"y.:5
"'·l.o<rn
1!!l
S<"'
'I"~j_
)J.l
S<1loi\tIn'·1\mo,',,,o ,""'
100
"",m,'Il <lIRh, 157
,i
,<"I'll. SI>
~
SO
~",."."'.~J
'~'I'< """"""" 5~
."..... oI',,""'·,""........ _w
Spmo«\ 1<......... 107
S"""",,\ ,,,",,,","" "I
.........,.I~
,,;obI< .....h'o'. Illll
..... ~)
.51«.\ J;••,....'" """"'. ""
S."hllJ·' 1"",,,,1.1. II
""""'.f"'...... IhO
"""""".'1
'""",",~,' ............ 17
Sjl''''''',''''''""m.IJ
Sjl,·""",.o.I'" ",","m. lJ. l>lI
,) ..... ,,f<Ii";",,"'I'IT'<_;,.... 1).1
1Ml$<..,.1 ",,","'",1<, III
...."'
P<. III
.'I'";0
,.mJum ""'fII<... 159
"""'h;o, ,,~~.7'
~"".'1
.....,1<·1"'" "..01">, :.10
r",w,·,...-"l'!>"""""... !OJ
r U<irl """". :>01
,..., "lW" ............. 17
.""",11&. n.
••,""...... 1)
.... J~.,.)
,......... .s.I.s..
''C'I1<.",,«<.M.IH 1811
"""""',-.;0."' J"'Ih ,)....... '01
,,,I..... 7~
~",j./l'NJi",,"·l<\l~,107
~<II.or<Ii:TN,
H~
~<II·_"·f'_"'·Il"
~,n.lmill I'....... Zl.l

