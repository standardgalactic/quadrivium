Topics In Analysis
Kuttler
December 18, 2006

2

Contents
I
Review Of Advanced Calculus
15
1
Set Theory
17
1.1
Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
1.2
The Schroder Bernstein Theorem . . . . . . . . . . . . . . . . . . . .
20
1.3
Equivalence Relations
. . . . . . . . . . . . . . . . . . . . . . . . . .
23
1.4
Partially Ordered Sets . . . . . . . . . . . . . . . . . . . . . . . . . .
24
2
Continuous Functions Of One Variable
25
2.1
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
2.2
Theorems About Continuous Functions
. . . . . . . . . . . . . . . .
27
3
The Riemann Stieltjes Integral
33
3.1
Upper And Lower Riemann Stieltjes Sums . . . . . . . . . . . . . . .
33
3.2
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.3
Functions Of Riemann Integrable Functions . . . . . . . . . . . . . .
38
3.4
Properties Of The Integral . . . . . . . . . . . . . . . . . . . . . . . .
41
3.5
Fundamental Theorem Of Calculus . . . . . . . . . . . . . . . . . . .
45
3.6
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
4
Some Important Linear Algebra
51
4.1
Algebra in Fn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
4.2
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
4.3
Subspaces Spans And Bases . . . . . . . . . . . . . . . . . . . . . . .
55
4.4
An Application To Matrices . . . . . . . . . . . . . . . . . . . . . . .
59
4.5
The Mathematical Theory Of Determinants . . . . . . . . . . . . . .
61
4.6
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
74
4.7
The Cayley Hamilton Theorem . . . . . . . . . . . . . . . . . . . . .
74
4.8
An Identity Of Cauchy . . . . . . . . . . . . . . . . . . . . . . . . . .
76
4.9
Block Multiplication Of Matrices . . . . . . . . . . . . . . . . . . . .
77
4.10 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
4.11 Shur’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
4.12 The Right Polar Decomposition . . . . . . . . . . . . . . . . . . . . .
87
3

4
CONTENTS
5
Multi-variable Calculus
91
5.1
Continuous Functions
. . . . . . . . . . . . . . . . . . . . . . . . . .
91
5.1.1
Distance In Fn . . . . . . . . . . . . . . . . . . . . . . . . . .
91
5.2
Open And Closed Sets . . . . . . . . . . . . . . . . . . . . . . . . . .
94
5.3
Continuous Functions
. . . . . . . . . . . . . . . . . . . . . . . . . .
96
5.3.1
Suﬃcient Conditions For Continuity . . . . . . . . . . . . . .
96
5.4
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
97
5.5
Limits Of A Function
. . . . . . . . . . . . . . . . . . . . . . . . . .
98
5.6
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
5.7
The Limit Of A Sequence . . . . . . . . . . . . . . . . . . . . . . . . 102
5.7.1
Sequences And Completeness . . . . . . . . . . . . . . . . . . 104
5.7.2
Continuity And The Limit Of A Sequence . . . . . . . . . . . 105
5.8
Properties Of Continuous Functions
. . . . . . . . . . . . . . . . . . 106
5.9
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
5.10 Proofs Of Theorems
. . . . . . . . . . . . . . . . . . . . . . . . . . . 107
5.11 The Space L (Fn, Fm)
. . . . . . . . . . . . . . . . . . . . . . . . . . 112
5.11.1 The Operator Norm . . . . . . . . . . . . . . . . . . . . . . . 112
5.12 The Frechet Derivative . . . . . . . . . . . . . . . . . . . . . . . . . . 114
5.13 C1 Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
5.14 Ck Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
5.15 Mixed Partial Derivatives . . . . . . . . . . . . . . . . . . . . . . . . 123
5.16 Implicit Function Theorem
. . . . . . . . . . . . . . . . . . . . . . . 125
5.16.1 More Continuous Partial Derivatives . . . . . . . . . . . . . . 129
5.17 The Method Of Lagrange Multipliers . . . . . . . . . . . . . . . . . . 130
6
Metric Spaces And General Topological Spaces
133
6.1
Metric Space
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
6.2
Compactness In Metric Space . . . . . . . . . . . . . . . . . . . . . . 135
6.3
Some Applications Of Compactness . . . . . . . . . . . . . . . . . . . 139
6.4
Ascoli Arzela Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . 140
6.5
The Tietze Extension Theorem . . . . . . . . . . . . . . . . . . . . . 144
6.6
General Topological Spaces
. . . . . . . . . . . . . . . . . . . . . . . 147
6.7
Connected Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152
7
Weierstrass Approximation Theorem
157
7.1
The Bernstein Polynomials
. . . . . . . . . . . . . . . . . . . . . . . 157
7.2
Stone Weierstrass Theorem
. . . . . . . . . . . . . . . . . . . . . . . 161
7.2.1
The Case Of Compact Sets . . . . . . . . . . . . . . . . . . . 161
7.2.2
The Case Of Locally Compact Sets . . . . . . . . . . . . . . . 164
7.2.3
The Case Of Complex Valued Functions . . . . . . . . . . . . 165
7.3
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166

CONTENTS
5
II
Real And Abstract Analysis
169
8
Abstract Measure And Integration
171
8.1
σ Algebras . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
8.2
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
8.3
The Abstract Lebesgue Integral . . . . . . . . . . . . . . . . . . . . . 183
8.3.1
Preliminary Observations . . . . . . . . . . . . . . . . . . . . 183
8.3.2
Deﬁnition Of The Lebesgue Integral For Nonnegative Mea-
surable Functions . . . . . . . . . . . . . . . . . . . . . . . . . 185
8.3.3
The Lebesgue Integral For Nonnegative Simple Functions . . 187
8.3.4
Simple Functions And Measurable Functions
. . . . . . . . . 190
8.3.5
The Monotone Convergence Theorem
. . . . . . . . . . . . . 192
8.3.6
Other Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . 193
8.3.7
Fatou’s Lemma . . . . . . . . . . . . . . . . . . . . . . . . . . 194
8.3.8
The Righteous Algebraic Desires Of The Lebesgue Integral
. 196
8.4
The Space L1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
8.5
Vitali Convergence Theorem . . . . . . . . . . . . . . . . . . . . . . . 203
8.6
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
9
The Construction Of Measures
209
9.1
Outer Measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
9.2
Regular Measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
9.3
Urysohn’s lemma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216
9.4
Positive Linear Functionals
. . . . . . . . . . . . . . . . . . . . . . . 221
9.5
One Dimensional Lebesgue Measure
. . . . . . . . . . . . . . . . . . 231
9.6
The Distribution Function . . . . . . . . . . . . . . . . . . . . . . . . 231
9.7
Product Measures
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
9.8
Alternative Treatment Of Product Measure . . . . . . . . . . . . . . 245
9.8.1
Monotone Classes And Algebras
. . . . . . . . . . . . . . . . 245
9.8.2
Product Measure . . . . . . . . . . . . . . . . . . . . . . . . . 248
9.9
Completion Of Measures . . . . . . . . . . . . . . . . . . . . . . . . . 253
9.10 Another Version Of Product Measures . . . . . . . . . . . . . . . . . 257
9.10.1 General Theory . . . . . . . . . . . . . . . . . . . . . . . . . . 257
9.10.2 Completion Of Product Measure Spaces . . . . . . . . . . . . 261
9.11 Disturbing Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
9.12 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265
10 Lebesgue Measure
267
10.1 Basic Properties
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
10.2 The Vitali Covering Theorem . . . . . . . . . . . . . . . . . . . . . . 271
10.3 The Vitali Covering Theorem (Elementary Version) . . . . . . . . . . 273
10.4 Vitali Coverings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276
10.5 Change Of Variables For Linear Maps . . . . . . . . . . . . . . . . . 279
10.6 Change Of Variables For C1 Functions . . . . . . . . . . . . . . . . . 283
10.7 Mappings Which Are Not One To One . . . . . . . . . . . . . . . . . 289

6
CONTENTS
10.8 Lebesgue Measure And Iterated Integrals
. . . . . . . . . . . . . . . 290
10.9 Spherical Coordinates In Many Dimensions . . . . . . . . . . . . . . 292
10.10The Brouwer Fixed Point Theorem . . . . . . . . . . . . . . . . . . . 294
10.11The Brouwer Fixed Point Theorem Another Proof
. . . . . . . . . . 298
11 Some Extension Theorems
303
11.1 Caratheodory Extension Theorem
. . . . . . . . . . . . . . . . . . . 303
11.2 The TychonoﬀTheorem . . . . . . . . . . . . . . . . . . . . . . . . . 305
11.3 Kolmogorov Extension Theorem
. . . . . . . . . . . . . . . . . . . . 308
11.4 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313
12 The Lp Spaces
315
12.1 Basic Inequalities And Properties . . . . . . . . . . . . . . . . . . . . 315
12.2 Density Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . 323
12.3 Separability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
12.4 Continuity Of Translation . . . . . . . . . . . . . . . . . . . . . . . . 327
12.5 Molliﬁers And Density Of Smooth Functions
. . . . . . . . . . . . . 328
12.6 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
13 Banach Spaces
337
13.1 Theorems Based On Baire Category
. . . . . . . . . . . . . . . . . . 337
13.1.1 Baire Category Theorem . . . . . . . . . . . . . . . . . . . . . 337
13.1.2 Uniform Boundedness Theorem . . . . . . . . . . . . . . . . . 341
13.1.3 Open Mapping Theorem . . . . . . . . . . . . . . . . . . . . . 342
13.1.4 Closed Graph Theorem
. . . . . . . . . . . . . . . . . . . . . 344
13.2 Hahn Banach Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . 346
13.3 Weak And Weak ∗Topologies . . . . . . . . . . . . . . . . . . . . . . 354
13.3.1 Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . 354
13.3.2 Banach Alaoglu Theorem . . . . . . . . . . . . . . . . . . . . 355
13.3.3 Eberlein Smulian Theorem
. . . . . . . . . . . . . . . . . . . 357
13.4 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360
14 Hilbert Spaces
365
14.1 Basic Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
14.2 Approximations In Hilbert Space . . . . . . . . . . . . . . . . . . . . 371
14.3 The M¨untz Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
14.4 Orthonormal Sets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
14.5 Fourier Series, An Example . . . . . . . . . . . . . . . . . . . . . . . 380
14.6 Compact Operators
. . . . . . . . . . . . . . . . . . . . . . . . . . . 382
14.6.1 Compact Operators In Hilbert Space . . . . . . . . . . . . . . 382
14.6.2 Nuclear Operators . . . . . . . . . . . . . . . . . . . . . . . . 387
14.6.3 Hilbert Schmidt Operators
. . . . . . . . . . . . . . . . . . . 390
14.7 Compact Operators In Banach Space . . . . . . . . . . . . . . . . . . 394
14.8 The Fredholm Alternative . . . . . . . . . . . . . . . . . . . . . . . . 396

CONTENTS
7
15 Representation Theorems
399
15.1 Radon Nikodym Theorem . . . . . . . . . . . . . . . . . . . . . . . . 399
15.2 Vector Measures
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
15.3 Representation Theorems For The Dual Space Of Lp . . . . . . . . . 412
15.4 The Dual Space Of C (X) . . . . . . . . . . . . . . . . . . . . . . . . 420
15.5 The Dual Space Of C0(X) . . . . . . . . . . . . . . . . . . . . . . . . 422
15.6 More Attractive Formulations . . . . . . . . . . . . . . . . . . . . . . 424
15.7 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 425
16 Integrals And Derivatives
429
16.1 The Fundamental Theorem Of Calculus . . . . . . . . . . . . . . . . 429
16.2 Absolutely Continuous Functions . . . . . . . . . . . . . . . . . . . . 434
16.3 Diﬀerentiation Of Measures With Respect To Lebesgue Measure
. . 439
16.4 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
17 HausdorﬀMeasure
449
17.1 Deﬁnition Of HausdorﬀMeasures . . . . . . . . . . . . . . . . . . . . 449
17.1.1 Properties Of HausdorﬀMeasure . . . . . . . . . . . . . . . . 450
17.1.2 Hn And mn . . . . . . . . . . . . . . . . . . . . . . . . . . . . 453
17.1.3 A Formula For α (n) . . . . . . . . . . . . . . . . . . . . . . . 456
17.1.4 HausdorﬀMeasure And Linear Transformations . . . . . . . . 458
17.2 The Area Formula
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 460
17.2.1 Preliminary Results
. . . . . . . . . . . . . . . . . . . . . . . 460
17.2.2 The Area Formula . . . . . . . . . . . . . . . . . . . . . . . . 468
17.3 The Area Formula Alternate Version . . . . . . . . . . . . . . . . . . 471
17.3.1 Preliminary Results
. . . . . . . . . . . . . . . . . . . . . . . 471
17.3.2 The Area Formula . . . . . . . . . . . . . . . . . . . . . . . . 478
17.4 The Divergence Theorem
. . . . . . . . . . . . . . . . . . . . . . . . 480
18 Diﬀerentiation With Respect To General Radon Measures
495
18.1 Besicovitch Covering Theorem
. . . . . . . . . . . . . . . . . . . . . 495
18.2 Fundamental Theorem Of Calculus For Radon Measures . . . . . . . 500
18.3 Slicing Measures
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 504
18.4 Vitali Coverings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 509
18.5 Diﬀerentiation Of Radon Measures . . . . . . . . . . . . . . . . . . . 512
18.6 The Radon Nikodym Theorem For Radon Measures
. . . . . . . . . 515
19 Fourier Transforms
517
19.1 An Algebra Of Special Functions . . . . . . . . . . . . . . . . . . . . 517
19.2 Fourier Transforms Of Functions In G
. . . . . . . . . . . . . . . . . 518
19.3 Fourier Transforms Of Just About Anything . . . . . . . . . . . . . . 521
19.3.1 Fourier Transforms Of Functions In L1 (Rn) . . . . . . . . . . 525
19.3.2 Fourier Transforms Of Functions In L2 (Rn) . . . . . . . . . . 528
19.3.3 The Schwartz Class
. . . . . . . . . . . . . . . . . . . . . . . 532
19.3.4 Convolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 534
19.4 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 536

8
CONTENTS
20 Fourier Analysis In Rn An Introduction
541
20.1 The Marcinkiewicz Interpolation Theorem . . . . . . . . . . . . . . . 541
20.2 The Calderon Zygmund Decomposition
. . . . . . . . . . . . . . . . 544
20.3 Mihlin’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 546
20.4 Singular Integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 559
20.5 Helmholtz Decompositions . . . . . . . . . . . . . . . . . . . . . . . . 569
21 The Bochner Integral
577
21.1 Strong And Weak Measurability
. . . . . . . . . . . . . . . . . . . . 577
21.2 The Bochner Integral . . . . . . . . . . . . . . . . . . . . . . . . . . . 585
21.2.1 Deﬁnition And Basic Properties
. . . . . . . . . . . . . . . . 585
21.2.2 Taking A Closed Operator Out Of The Integral . . . . . . . . 589
21.3 Operator Valued Functions
. . . . . . . . . . . . . . . . . . . . . . . 594
21.3.1 Review Of Hilbert Schmidt Theorem . . . . . . . . . . . . . . 596
21.3.2 Measurable Compact Operators . . . . . . . . . . . . . . . . . 600
21.4 Fubini’s Theorem For Bochner Integrals . . . . . . . . . . . . . . . . 600
21.5 The Spaces Lp (Ω; X)
. . . . . . . . . . . . . . . . . . . . . . . . . . 603
21.6 Measurable Representatives . . . . . . . . . . . . . . . . . . . . . . . 610
21.7 Vector Measures
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 612
21.8 The Riesz Representation Theorem . . . . . . . . . . . . . . . . . . . 617
21.9 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 621
III
Complex Analysis
623
22 The Complex Numbers
625
22.1 The Extended Complex Plane . . . . . . . . . . . . . . . . . . . . . . 627
22.2 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 628
23 Riemann Stieltjes Integrals
629
23.1 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 639
24 Fundamentals Of Complex Analysis
641
24.1 Analytic Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 641
24.1.1 Cauchy Riemann Equations . . . . . . . . . . . . . . . . . . . 643
24.1.2 An Important Example
. . . . . . . . . . . . . . . . . . . . . 645
24.2 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 646
24.3 Cauchy’s Formula For A Disk . . . . . . . . . . . . . . . . . . . . . . 647
24.4 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 654
24.5 Zeros Of An Analytic Function . . . . . . . . . . . . . . . . . . . . . 657
24.6 Liouville’s Theorem
. . . . . . . . . . . . . . . . . . . . . . . . . . . 659
24.7 The General Cauchy Integral Formula . . . . . . . . . . . . . . . . . 660
24.7.1 The Cauchy Goursat Theorem
. . . . . . . . . . . . . . . . . 660
24.7.2 A Redundant Assumption . . . . . . . . . . . . . . . . . . . . 663
24.7.3 Classiﬁcation Of Isolated Singularities . . . . . . . . . . . . . 664
24.7.4 The Cauchy Integral Formula . . . . . . . . . . . . . . . . . . 667

CONTENTS
9
24.7.5 An Example Of A Cycle . . . . . . . . . . . . . . . . . . . . . 674
24.8 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 678
25 The Open Mapping Theorem
681
25.1 A Local Representation
. . . . . . . . . . . . . . . . . . . . . . . . . 681
25.2 Branches Of The Logarithm . . . . . . . . . . . . . . . . . . . . . . . 683
25.3 Maximum Modulus Theorem
. . . . . . . . . . . . . . . . . . . . . . 685
25.4 Extensions Of Maximum Modulus Theorem . . . . . . . . . . . . . . 687
25.4.1 Phragmˆen Lindel¨of Theorem
. . . . . . . . . . . . . . . . . . 687
25.4.2 Hadamard Three Circles Theorem
. . . . . . . . . . . . . . . 689
25.4.3 Schwarz’s Lemma . . . . . . . . . . . . . . . . . . . . . . . . . 690
25.4.4 One To One Analytic Maps On The Unit Ball
. . . . . . . . 691
25.5 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 692
25.6 Counting Zeros . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 694
25.7 An Application To Linear Algebra
. . . . . . . . . . . . . . . . . . . 698
25.8 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 702
26 Residues
705
26.1 Rouche’s Theorem And The Argument Principle . . . . . . . . . . . 708
26.1.1 Argument Principle
. . . . . . . . . . . . . . . . . . . . . . . 708
26.1.2 Rouche’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . 711
26.1.3 A Diﬀerent Formulation . . . . . . . . . . . . . . . . . . . . . 712
26.2 Singularities And The Laurent Series . . . . . . . . . . . . . . . . . . 713
26.2.1 What Is An Annulus? . . . . . . . . . . . . . . . . . . . . . . 713
26.2.2 The Laurent Series . . . . . . . . . . . . . . . . . . . . . . . . 716
26.2.3 Contour Integrals And Evaluation Of Integrals . . . . . . . . 720
26.3 The Spectral Radius Of A Bounded Linear Transformation
. . . . . 729
26.4 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 731
27 Complex Mappings
735
27.1 Conformal Maps
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 735
27.2 Fractional Linear Transformations
. . . . . . . . . . . . . . . . . . . 736
27.2.1 Circles And Lines
. . . . . . . . . . . . . . . . . . . . . . . . 736
27.2.2 Three Points To Three Points . . . . . . . . . . . . . . . . . . 738
27.3 Riemann Mapping Theorem . . . . . . . . . . . . . . . . . . . . . . . 739
27.3.1 Montel’s Theorem
. . . . . . . . . . . . . . . . . . . . . . . . 740
27.3.2 Regions With Square Root Property . . . . . . . . . . . . . . 742
27.4 Analytic Continuation . . . . . . . . . . . . . . . . . . . . . . . . . . 746
27.4.1 Regular And Singular Points
. . . . . . . . . . . . . . . . . . 746
27.4.2 Continuation Along A Curve . . . . . . . . . . . . . . . . . . 748
27.5 The Picard Theorems
. . . . . . . . . . . . . . . . . . . . . . . . . . 749
27.5.1 Two Competing Lemmas
. . . . . . . . . . . . . . . . . . . . 751
27.5.2 The Little Picard Theorem
. . . . . . . . . . . . . . . . . . . 754
27.5.3 Schottky’s Theorem
. . . . . . . . . . . . . . . . . . . . . . . 755
27.5.4 A Brief Review . . . . . . . . . . . . . . . . . . . . . . . . . . 759

10
CONTENTS
27.5.5 Montel’s Theorem
. . . . . . . . . . . . . . . . . . . . . . . . 761
27.5.6 The Great Big Picard Theorem . . . . . . . . . . . . . . . . . 762
27.6 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 764
28 Approximation By Rational Functions
767
28.1 Runge’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 767
28.1.1 Approximation With Rational Functions . . . . . . . . . . . . 767
28.1.2 Moving The Poles And Keeping The Approximation . . . . . 769
28.1.3 Merten’s Theorem. . . . . . . . . . . . . . . . . . . . . . . . . 769
28.1.4 Runge’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . 774
28.2 The Mittag-Leﬄer Theorem . . . . . . . . . . . . . . . . . . . . . . . 776
28.2.1 A Proof From Runge’s Theorem
. . . . . . . . . . . . . . . . 776
28.2.2 A Direct Proof Without Runge’s Theorem . . . . . . . . . . . 778
28.2.3 Functions Meromorphic On bC . . . . . . . . . . . . . . . . . . 780
28.2.4 A Great And Glorious Theorem About Simply Connected
Regions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 780
28.3 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 784
29 Inﬁnite Products
785
29.1 Analytic Function With Prescribed Zeros
. . . . . . . . . . . . . . . 789
29.2 Factoring A Given Analytic Function . . . . . . . . . . . . . . . . . . 794
29.2.1 Factoring Some Special Analytic Functions
. . . . . . . . . . 796
29.3 The Existence Of An Analytic Function With Given Values . . . . . 798
29.4 Jensen’s Formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 802
29.5 Blaschke Products
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 805
29.5.1 The M¨untz-Szasz Theorem Again . . . . . . . . . . . . . . . . 808
29.6 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 810
30 Elliptic Functions
819
30.1 Periodic Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 820
30.1.1 The Unimodular Transformations . . . . . . . . . . . . . . . . 824
30.1.2 The Search For An Elliptic Function . . . . . . . . . . . . . . 827
30.1.3 The Diﬀerential Equation Satisﬁed By ℘. . . . . . . . . . . . 830
30.1.4 A Modular Function . . . . . . . . . . . . . . . . . . . . . . . 832
30.1.5 A Formula For λ . . . . . . . . . . . . . . . . . . . . . . . . . 838
30.1.6 Mapping Properties Of λ
. . . . . . . . . . . . . . . . . . . . 840
30.1.7 A Short Review And Summary . . . . . . . . . . . . . . . . . 848
30.2 The Picard Theorem Again . . . . . . . . . . . . . . . . . . . . . . . 852
30.3 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 853
IV
Stochastic Processes, An Introduction
855
31 Random Variables And Basic Probability
857
31.1 The Characteristic Function . . . . . . . . . . . . . . . . . . . . . . . 860
31.2 Conditional Probability
. . . . . . . . . . . . . . . . . . . . . . . . . 861

CONTENTS
11
31.3 The Multivariate Normal Distribution . . . . . . . . . . . . . . . . . 867
31.4 The Central Limit Theorem . . . . . . . . . . . . . . . . . . . . . . . 875
31.5 Brownian Motion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 881
32 Conditional Expectation And Martingales
893
32.1 Conditional Expectation . . . . . . . . . . . . . . . . . . . . . . . . . 893
32.2 Discrete Martingales . . . . . . . . . . . . . . . . . . . . . . . . . . . 896
33 Filtrations And Martingales
903
33.1 Continuous Martingales . . . . . . . . . . . . . . . . . . . . . . . . . 910
33.2 Doob’s Martingale Estimate . . . . . . . . . . . . . . . . . . . . . . . 915
34 The Itˆo Integral
917
34.1 Properties Of The Itˆo Integral . . . . . . . . . . . . . . . . . . . . . . 925
35 Stochastic Processes
933
35.1 An Important Filtration . . . . . . . . . . . . . . . . . . . . . . . . . 933
35.2 Itˆo Processes
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 936
35.3 Some Representation Theorems . . . . . . . . . . . . . . . . . . . . . 948
35.4 Stochastic Diﬀerential Equations . . . . . . . . . . . . . . . . . . . . 960
35.4.1 Gronwall’s Inequality
. . . . . . . . . . . . . . . . . . . . . . 960
35.4.2 Review Of Itˆo Integrals And A Filtration
. . . . . . . . . . . 961
35.4.3 A Function Space . . . . . . . . . . . . . . . . . . . . . . . . . 963
35.4.4 An Extension Of The Itˆo Integral . . . . . . . . . . . . . . . . 964
35.4.5 A Vector Valued Deterministic Integral
. . . . . . . . . . . . 965
35.4.6 The Existence And Uniqueness Theorem . . . . . . . . . . . . 968
35.4.7 Some Simple Examples
. . . . . . . . . . . . . . . . . . . . . 972
35.5 A Diﬀerent Proof Of Existence And Uniqueness . . . . . . . . . . . . 975
35.5.1 Gronwall’s Inequality
. . . . . . . . . . . . . . . . . . . . . . 975
35.5.2 Review Of Itˆo Integrals
. . . . . . . . . . . . . . . . . . . . . 976
35.5.3 The Existence And Uniqueness Theorem . . . . . . . . . . . . 978
35.5.4 Some Simple Examples
. . . . . . . . . . . . . . . . . . . . . 982
36 Probability In Inﬁnite Dimensions
987
36.1 Expected Value Covariance And Correlation . . . . . . . . . . . . . . 987
36.2 Independence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 990
36.3 Conditional Expectation . . . . . . . . . . . . . . . . . . . . . . . . . 996
36.4 Probability Measures And Tightness . . . . . . . . . . . . . . . . . . 1000
36.5 A Major Existence And Convergence Theorem
. . . . . . . . . . . . 1007
36.6 Characteristic Functions . . . . . . . . . . . . . . . . . . . . . . . . . 1014
36.7 Convolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1019
36.8 The Multivariate Normal Distribution . . . . . . . . . . . . . . . . . 1024
36.9 Gaussian Measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1031
36.9.1 Deﬁnitions And Basic Properties . . . . . . . . . . . . . . . . 1031
36.10Gaussian Measures For A Separable Hilbert Space
. . . . . . . . . . 1033
36.11Abstract Wiener Spaces . . . . . . . . . . . . . . . . . . . . . . . . . 1036

12
CONTENTS
36.12White Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1046
36.13Existence Of Abstract Wiener Spaces
. . . . . . . . . . . . . . . . . 1050
36.14Fernique’s Theorem
. . . . . . . . . . . . . . . . . . . . . . . . . . . 1055
36.15Reproducing Kernels . . . . . . . . . . . . . . . . . . . . . . . . . . . 1061
36.16Reproducing Kernels And White Noise . . . . . . . . . . . . . . . . . 1071
V
Sobolev Spaces
1077
37 Weak Derivatives
1079
37.1 Weak ∗Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . 1079
37.2 Test Functions And Weak Derivatives
. . . . . . . . . . . . . . . . . 1080
37.3 Weak Derivatives In Lp
loc . . . . . . . . . . . . . . . . . . . . . . . . . 1084
37.4 Morrey’s Inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1087
37.5 Rademacher’s Theorem
. . . . . . . . . . . . . . . . . . . . . . . . . 1090
37.6 Change Of Variables Formula Lipschitz Maps . . . . . . . . . . . . . 1093
38 The Area And Coarea Formulas
1103
38.1 The Area Formula Again
. . . . . . . . . . . . . . . . . . . . . . . . 1103
38.2 Mappings That Are Not One To One . . . . . . . . . . . . . . . . . . 1106
38.3 The Coarea Formula . . . . . . . . . . . . . . . . . . . . . . . . . . . 1110
38.4 A Nonlinear Fubini’s Theorem
. . . . . . . . . . . . . . . . . . . . . 1121
39 Integration On Manifolds
1123
39.1 Partitions Of Unity . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1123
39.2 Integration On Manifolds
. . . . . . . . . . . . . . . . . . . . . . . . 1127
39.3 Comparison With Hn
. . . . . . . . . . . . . . . . . . . . . . . . . . 1133
40 Basic Theory Of Sobolev Spaces
1135
40.1 Embedding Theorems For W m,p (Rn) . . . . . . . . . . . . . . . . . . 1144
40.2 An Extension Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . 1157
40.3 General Embedding Theorems . . . . . . . . . . . . . . . . . . . . . . 1165
40.4 More Extension Theorems . . . . . . . . . . . . . . . . . . . . . . . . 1168
41 Sobolev Spaces Based On L2
1173
41.1 Fourier Transform Techniques . . . . . . . . . . . . . . . . . . . . . . 1173
41.2 Fractional Order Spaces . . . . . . . . . . . . . . . . . . . . . . . . . 1178
41.3 Embedding Theorems
. . . . . . . . . . . . . . . . . . . . . . . . . . 1186
41.4 The Trace On The Boundary Of A Half Space
. . . . . . . . . . . . 1188
41.5 Sobolev Spaces On Manifolds . . . . . . . . . . . . . . . . . . . . . . 1195
41.5.1 General Theory . . . . . . . . . . . . . . . . . . . . . . . . . . 1195
41.5.2 The Trace On The Boundary . . . . . . . . . . . . . . . . . . 1200
42 Weak Solutions
1205
42.1 The Lax Milgram Theorem
. . . . . . . . . . . . . . . . . . . . . . . 1205

CONTENTS
13
43 Korn’s Inequality
1211
43.1 A Fundamental Inequality . . . . . . . . . . . . . . . . . . . . . . . . 1211
43.2 Korn’s Inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1217
44 Elliptic Regularity And Nirenberg Diﬀerences
1219
44.1 The Case Of A Half Space . . . . . . . . . . . . . . . . . . . . . . . . 1219
44.2 The Case Of Bounded Open Sets . . . . . . . . . . . . . . . . . . . . 1229
45 Interpolation In Banach Space
1239
45.1 An Assortment Of Important Theorems . . . . . . . . . . . . . . . . 1239
45.1.1 Weak Vector Valued Derivatives
. . . . . . . . . . . . . . . . 1239
45.1.2 Some Imbedding Theorems . . . . . . . . . . . . . . . . . . . 1249
45.2 The K Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1254
45.3 The J Method
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1259
45.4 Duality And Interpolation . . . . . . . . . . . . . . . . . . . . . . . . 1265
46 Trace Spaces
1275
46.1 Deﬁnition And Basic Theory Of Trace Spaces . . . . . . . . . . . . . 1275
46.2 Equivalence Of Trace And Interpolation Spaces . . . . . . . . . . . . 1281
47 Traces Of Sobolev Spaces And Fractional Order Spaces
1289
47.1 Traces Of Sobolev Spaces On The Boundary Of A Half Space . . . . 1289
47.2 A Right Inverse For The Trace For A Half Space . . . . . . . . . . . 1292
47.3 Fractional Order Sobolev Spaces
. . . . . . . . . . . . . . . . . . . . 1294
48 Sobolev Spaces On Manifolds
1299
48.1 Basic Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1299
48.2 The Trace On The Boundary Of An Open Set . . . . . . . . . . . . . 1301
A The HausdorﬀMaximal Theorem
1305
A.1 Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1309
Copyright c⃝2004,

14
CONTENTS

Part I
Review Of Advanced
Calculus
15


Set Theory
1.1
Basic Deﬁnitions
A set is a collection of things called elements of the set. For example, the set of
integers, the collection of signed whole numbers such as 1,2,-4, etc. This set whose
existence will be assumed is denoted by Z. Other sets could be the set of people in
a family or the set of donuts in a display case at the store. Sometimes parentheses,
{ } specify a set by listing the things which are in the set between the parentheses.
For example the set of integers between -1 and 2, including these numbers could
be denoted as {−1, 0, 1, 2}. The notation signifying x is an element of a set S, is
written as x ∈S. Thus, 1 ∈{−1, 0, 1, 2, 3}. Here are some axioms about sets.
Axioms are statements which are accepted, not proved.
1. Two sets are equal if and only if they have the same elements.
2. To every set, A, and to every condition S (x) there corresponds a set, B, whose
elements are exactly those elements x of A for which S (x) holds.
3. For every collection of sets there exists a set that contains all the elements
that belong to at least one set of the given collection.
4. The Cartesian product of a nonempty family of nonempty sets is nonempty.
5. If A is a set there exists a set, P (A) such that P (A) is the set of all subsets
of A. This is called the power set.
These axioms are referred to as the axiom of extension, axiom of speciﬁcation,
axiom of unions, axiom of choice, and axiom of powers respectively.
It seems fairly clear you should want to believe in the axiom of extension. It is
merely saying, for example, that {1, 2, 3} = {2, 3, 1} since these two sets have the
same elements in them. Similarly, it would seem you should be able to specify a
new set from a given set using some “condition” which can be used as a test to
determine whether the element in question is in the set. For example, the set of all
integers which are multiples of 2. This set could be speciﬁed as follows.
{x ∈Z : x = 2y for some y ∈Z} .
17

18
SET THEORY
In this notation, the colon is read as “such that” and in this case the condition is
being a multiple of 2.
Another example of political interest, could be the set of all judges who are not
judicial activists. I think you can see this last is not a very precise condition since
there is no way to determine to everyone’s satisfaction whether a given judge is an
activist. Also, just because something is grammatically correct does not mean it
makes any sense. For example consider the following nonsense.
S = {x ∈set of dogs : it is colder in the mountains than in the winter} .
So what is a condition?
We will leave these sorts of considerations and assume our conditions make sense.
The axiom of unions states that for any collection of sets, there is a set consisting
of all the elements in each of the sets in the collection. Of course this is also open to
further consideration. What is a collection? Maybe it would be better to say “set
of sets” or, given a set whose elements are sets there exists a set whose elements
consist of exactly those things which are elements of at least one of these sets. If S
is such a set whose elements are sets,
∪{A : A ∈S} or ∪S
signify this union.
Something is in the Cartesian product of a set or “family” of sets if it consists
of a single thing taken from each set in the family. Thus (1, 2, 3) ∈{1, 4, .2} ×
{1, 2, 7}×{4, 3, 7, 9} because it consists of exactly one element from each of the sets
which are separated by ×. Also, this is the notation for the Cartesian product of
ﬁnitely many sets. If S is a set whose elements are sets,
Y
A∈S
A
signiﬁes the Cartesian product.
The Cartesian product is the set of choice functions, a choice function being a
function which selects exactly one element of each set of S. You may think the axiom
of choice, stating that the Cartesian product of a nonempty family of nonempty sets
is nonempty, is innocuous but there was a time when many mathematicians were
ready to throw it out because it implies things which are very hard to believe, things
which never happen without the axiom of choice.
A is a subset of B, written A ⊆B, if every element of A is also an element of
B. This can also be written as B ⊇A. A is a proper subset of B, written A ⊂B
or B ⊃A if A is a subset of B but A is not equal to B, A ̸= B. A ∩B denotes the
intersection of the two sets, A and B and it means the set of elements of A which
are also elements of B. The axiom of speciﬁcation shows this is a set. The empty
set is the set which has no elements in it, denoted as ∅. A ∪B denotes the union
of the two sets, A and B and it means the set of all elements which are in either of
the sets. It is a set because of the axiom of unions.

1.1.
BASIC DEFINITIONS
19
The complement of a set, (the set of things which are not in the given set ) must
be taken with respect to a given set called the universal set which is a set which
contains the one whose complement is being taken. Thus, the complement of A,
denoted as AC ( or more precisely as X \ A) is a set obtained from using the axiom
of speciﬁcation to write
AC ≡{x ∈X : x /∈A}
The symbol /∈means: “is not an element of”. Note the axiom of speciﬁcation takes
place relative to a given set. Without this universal set it makes no sense to use
the axiom of speciﬁcation to obtain the complement.
Words such as “all” or “there exists” are called quantiﬁers and they must be
understood relative to some given set. For example, the set of all integers larger
than 3. Or there exists an integer larger than 7. Such statements have to do with a
given set, in this case the integers. Failure to have a reference set when quantiﬁers
are used turns out to be illogical even though such usage may be grammatically
correct. Quantiﬁers are used often enough that there are symbols for them. The
symbol ∀is read as “for all” or “for every” and the symbol ∃is read as “there
exists”. Thus ∀∀∃∃could mean for every upside down A there exists a backwards
E.
DeMorgan’s laws are very useful in mathematics. Let S be a set of sets each of
which is contained in some universal set, U. Then
∪
©
AC : A ∈S
ª
= (∩{A : A ∈S})C
and
∩
©
AC : A ∈S
ª
= (∪{A : A ∈S})C .
These laws follow directly from the deﬁnitions. Also following directly from the
deﬁnitions are:
Let S be a set of sets then
B ∪∪{A : A ∈S} = ∪{B ∪A : A ∈S} .
and: Let S be a set of sets show
B ∩∪{A : A ∈S} = ∪{B ∩A : A ∈S} .
Unfortunately, there is no single universal set which can be used for all sets.
Here is why: Suppose there were. Call it S. Then you could consider A the set
of all elements of S which are not elements of themselves, this from the axiom of
speciﬁcation. If A is an element of itself, then it fails to qualify for inclusion in A.
Therefore, it must not be an element of itself. However, if this is so, it qualiﬁes for
inclusion in A so it is an element of itself and so this can’t be true either. Thus
the most basic of conditions you could imagine, that of being an element of, is
meaningless and so allowing such a set causes the whole theory to be meaningless.
The solution is to not allow a universal set. As mentioned by Halmos in Naive
set theory, “Nothing contains everything”. Always beware of statements involving
quantiﬁers wherever they occur, even this one.

20
SET THEORY
1.2
The Schroder Bernstein Theorem
It is very important to be able to compare the size of sets in a rational way. The
most useful theorem in this context is the Schroder Bernstein theorem which is the
main result to be presented in this section. The Cartesian product is discussed
above. The next deﬁnition reviews this and deﬁnes the concept of a function.
Deﬁnition 1.1 Let X and Y be sets.
X × Y ≡{(x, y) : x ∈X and y ∈Y }
A relation is deﬁned to be a subset of X × Y . A function, f, also called a mapping,
is a relation which has the property that if (x, y) and (x, y1) are both elements of
the f, then y = y1. The domain of f is deﬁned as
D (f) ≡{x : (x, y) ∈f} ,
written as f : D (f) →Y .
It is probably safe to say that most people do not think of functions as a type
of relation which is a subset of the Cartesian product of two sets. A function is like
a machine which takes inputs, x and makes them into a unique output, f (x). Of
course, that is what the above deﬁnition says with more precision. An ordered pair,
(x, y) which is an element of the function or mapping has an input, x and a unique
output, y,denoted as f (x) while the name of the function is f. “mapping” is often
a noun meaning function. However, it also is a verb as in “f is mapping A to B
”. That which a function is thought of as doing is also referred to using the word
“maps” as in: f maps X to Y . However, a set of functions may be called a set of
maps so this word might also be used as the plural of a noun. There is no help for
it. You just have to suﬀer with this nonsense.
The following theorem which is interesting for its own sake will be used to prove
the Schroder Bernstein theorem.
Theorem 1.2 Let f : X →Y and g : Y →X be two functions. Then there exist
sets A, B, C, D, such that
A ∪B = X, C ∪D = Y, A ∩B = ∅, C ∩D = ∅,
f (A) = C, g (D) = B.
The following picture illustrates the conclusion of this theorem.
B = g(D)
A
-

D
C = f(A)
Y
X
f
g

1.2.
THE SCHRODER BERNSTEIN THEOREM
21
Proof: Consider the empty set, ∅⊆X. If y ∈Y \ f (∅), then g (y) /∈∅because
∅has no elements. Also, if A, B, C, and D are as described above, A also would
have this same property that the empty set has. However, A is probably larger.
Therefore, say A0 ⊆X satisﬁes P if whenever y ∈Y \ f (A0) , g (y) /∈A0.
A ≡{A0 ⊆X : A0 satisﬁes P}.
Let A = ∪A. If y ∈Y \ f (A), then for each A0 ∈A, y ∈Y \ f (A0) and so
g (y) /∈A0. Since g (y) /∈A0 for all A0 ∈A, it follows g (y) /∈A. Hence A satisﬁes
P and is the largest subset of X which does so. Now deﬁne
C ≡f (A) , D ≡Y \ C, B ≡X \ A.
It only remains to verify that g (D) = B.
Suppose x ∈B = X \ A. Then A ∪{x} does not satisfy P and so there exists
y ∈Y \ f (A ∪{x}) ⊆D such that g (y) ∈A ∪{x} . But y /∈f (A) and so since A
satisﬁes P, it follows g (y) /∈A. Hence g (y) = x and so x ∈g (D) and this proves
the theorem.
Theorem 1.3 (Schroder Bernstein) If f : X →Y and g : Y →X are one to one,
then there exists h : X →Y which is one to one and onto.
Proof: Let A, B, C, D be the sets of Theorem1.2 and deﬁne
h (x) ≡
½ f (x)
if x ∈A
g−1 (x) if x ∈B
Then h is the desired one to one and onto mapping.
Recall that the Cartesian product may be considered as the collection of choice
functions.
Deﬁnition 1.4 Let I be a set and let Xi be a set for each i ∈I.
f is a choice
function written as
f ∈
Y
i∈I
Xi
if f (i) ∈Xi for each i ∈I.
The axiom of choice says that if Xi ̸= ∅for each i ∈I, for I a set, then
Y
i∈I
Xi ̸= ∅.
Sometimes the two functions, f and g are onto but not one to one. It turns out
that with the axiom of choice, a similar conclusion to the above may be obtained.
Corollary 1.5 If f : X →Y is onto and g : Y →X is onto, then there exists
h : X →Y which is one to one and onto.

22
SET THEORY
Proof: For each y ∈Y , f −1 (y) ≡{x ∈X : f (x) = y} ̸= ∅. Therefore, by the
axiom of choice, there exists f −1
0
∈Q
y∈Y f −1 (y) which is the same as saying that
for each y ∈Y , f −1
0
(y) ∈f −1 (y). Similarly, there exists g−1
0
(x) ∈g−1 (x) for all
x ∈X. Then f −1
0
is one to one because if f −1
0
(y1) = f −1
0
(y2), then
y1 = f
¡
f −1
0
(y1)
¢
= f
¡
f −1
0
(y2)
¢
= y2.
Similarly g−1
0
is one to one. Therefore, by the Schroder Bernstein theorem, there
exists h : X →Y which is one to one and onto.
Deﬁnition 1.6 A set S, is ﬁnite if there exists a natural number n and a map θ
which maps {1, · · ·, n} one to one and onto S. S is inﬁnite if it is not ﬁnite. A
set S, is called countable if there exists a map θ mapping N one to one and onto
S.(When θ maps a set A to a set B, this will be written as θ : A →B in the future.)
Here N ≡{1, 2, · · ·}, the natural numbers. S is at most countable if there exists a
map θ : N →S which is onto.
The property of being at most countable is often referred to as being countable
because the question of interest is normally whether one can list all elements of the
set, designating a ﬁrst, second, third etc. in such a way as to give each element of
the set a natural number. The possibility that a single element of the set may be
counted more than once is often not important.
Theorem 1.7 If X and Y are both at most countable, then X × Y is also at most
countable. If either X or Y is countable, then X × Y is also countable.
Proof: It is given that there exists a mapping η : N →X which is onto. Deﬁne
η (i) ≡xi and consider X as the set {x1, x2, x3, · · ·}. Similarly, consider Y as the
set {y1, y2, y3, · · ·}. It follows the elements of X × Y are included in the following
rectangular array.
(x1, y1)
(x1, y2)
(x1, y3)
· · ·
←Those which have x1 in ﬁrst slot.
(x2, y1)
(x2, y2)
(x2, y3)
· · ·
←Those which have x2 in ﬁrst slot.
(x3, y1)
(x3, y2)
(x3, y3)
· · ·
←Those which have x3 in ﬁrst slot.
...
...
...
...
.
Follow a path through this array as follows.
(x1, y1)
→
(x1, y2)
(x1, y3)
→
↙
↗
(x2, y1)
(x2, y2)
↓
↗
(x3, y1)
Thus the ﬁrst element of X × Y is (x1, y1), the second element of X × Y is (x1, y2),
the third element of X × Y is (x2, y1) etc. This assigns a number from N to each
element of X × Y. Thus X × Y is at most countable.

1.3.
EQUIVALENCE RELATIONS
23
It remains to show the last claim. Suppose without loss of generality that X
is countable. Then there exists α : N →X which is one to one and onto. Let
β : X × Y →N be deﬁned by β ((x, y)) ≡α−1 (x). Thus β is onto N. By the ﬁrst
part there exists a function from N onto X × Y . Therefore, by Corollary 1.5, there
exists a one to one and onto mapping from X × Y to N. This proves the theorem.
Theorem 1.8 If X and Y are at most countable, then X ∪Y is at most countable.
If either X or Y are countable, then X ∪Y is countable.
Proof: As in the preceding theorem,
X = {x1, x2, x3, · · ·}
and
Y = {y1, y2, y3, · · ·} .
Consider the following array consisting of X ∪Y and path through it.
x1
→
x2
x3
→
↙
↗
y1
→
y2
Thus the ﬁrst element of X ∪Y is x1, the second is x2 the third is y1 the fourth is
y2 etc.
Consider the second claim. By the ﬁrst part, there is a map from N onto X ×Y .
Suppose without loss of generality that X is countable and α : N →X is one to one
and onto. Then deﬁne β (y) ≡1, for all y ∈Y ,and β (x) ≡α−1 (x). Thus, β maps
X × Y onto N and this shows there exist two onto maps, one mapping X ∪Y onto
N and the other mapping N onto X ∪Y . Then Corollary 1.5 yields the conclusion.
This proves the theorem.
1.3
Equivalence Relations
There are many ways to compare elements of a set other than to say two elements
are equal or the same. For example, in the set of people let two people be equiv-
alent if they have the same weight. This would not be saying they were the same
person, just that they weighed the same. Often such relations involve considering
one characteristic of the elements of a set and then saying the two elements are
equivalent if they are the same as far as the given characteristic is concerned.
Deﬁnition 1.9 Let S be a set. ∼is an equivalence relation on S if it satisﬁes the
following axioms.
1. x ∼x
for all x ∈S. (Reﬂexive)
2. If x ∼y then y ∼x. (Symmetric)
3. If x ∼y and y ∼z, then x ∼z. (Transitive)

24
SET THEORY
Deﬁnition 1.10 [x] denotes the set of all elements of S which are equivalent to x
and [x] is called the equivalence class determined by x or just the equivalence class
of x.
With the above deﬁnition one can prove the following simple theorem.
Theorem 1.11 Let ∼be an equivalence class deﬁned on a set, S and let H denote
the set of equivalence classes. Then if [x] and [y] are two of these equivalence classes,
either x ∼y and [x] = [y] or it is not true that x ∼y and [x] ∩[y] = ∅.
1.4
Partially Ordered Sets
Deﬁnition 1.12 Let F
be a nonempty set. F is called a partially ordered set if
there is a relation, denoted here by ≤, such that
x ≤x for all x ∈F.
If x ≤y and y ≤z then x ≤z.
C ⊆F is said to be a chain if every two elements of C are related. This means that
if x, y ∈C, then either x ≤y or y ≤x. Sometimes a chain is called a totally ordered
set. C is said to be a maximal chain if whenever D is a chain containing C, D = C.
The most common example of a partially ordered set is the power set of a given
set with ⊆being the relation. It is also helpful to visualize partially ordered sets
as trees.
Two points on the tree are related if they are on the same branch of
the tree and one is higher than the other. Thus two points on diﬀerent branches
would not be related although they might both be larger than some point on the
trunk. You might think of many other things which are best considered as partially
ordered sets. Think of food for example. You might ﬁnd it diﬃcult to determine
which of two favorite pies you like better although you may be able to say very
easily that you would prefer either pie to a dish of lard topped with whipped cream
and mustard. The following theorem is equivalent to the axiom of choice. For a
discussion of this, see the appendix on the subject.
Theorem 1.13 (HausdorﬀMaximal Principle) Let F
be a nonempty partially
ordered set. Then there exists a maximal chain.

Continuous Functions Of
One Variable
There is a theorem about the integral of a continuous function which requires the
notion of uniform continuity. This is discussed in this section. Consider the function
f (x) = 1
x for x ∈(0, 1) . This is a continuous function because, it is continuous at
every point of (0, 1) . However, for a given ε > 0, the δ needed in the ε, δ deﬁnition of
continuity becomes very small as x gets close to 0. The notion of uniform continuity
involves being able to choose a single δ which works on the whole domain of f. Here
is the deﬁnition.
Deﬁnition 2.1 Let f : D ⊆R →R be a function. Then f is uniformly continuous
if for every ε > 0, there exists a δ depending only on ε such that if |x −y| < δ
then |f (x) −f (y)| < ε.
It is an amazing fact that under certain conditions continuity implies uniform
continuity.
Deﬁnition 2.2 A set, K ⊆R is sequentially compact if whenever {an} ⊆K is a
sequence, there exists a subsequence, {ank} such that this subsequence converges to
a point of K.
The following theorem is part of the Heine Borel theorem.
Theorem 2.3 Every closed interval, [a, b] is sequentially compact.
Proof: Let {xn} ⊆[a, b] ≡I0. Consider the two intervals
£
a, a+b
2
¤
and
£ a+b
2 , b
¤
each of which has length (b −a) /2. At least one of these intervals contains xn for
inﬁnitely many values of n. Call this interval I1. Now do for I1 what was done for I0.
Split it in half and let I2 be the interval which contains xn for inﬁnitely many values
of n. Continue this way obtaining a sequence of nested intervals I0 ⊇I1 ⊇I2 ⊇I3···
where the length of In is (b −a) /2n. Now pick n1 such that xn1 ∈I1, n2 such that
n2 > n1 and xn2 ∈I2, n3 such that n3 > n2 and xn3 ∈I3, etc. (This can be done
because in each case the intervals contained xn for inﬁnitely many values of n.) By
25

26
CONTINUOUS FUNCTIONS OF ONE VARIABLE
the nested interval lemma there exists a point, c contained in all these intervals.
Furthermore,
|xnk −c| < (b −a) 2−k
and so limk→∞xnk = c ∈[a, b] . This proves the theorem.
Theorem 2.4 Let f : K →R be continuous where K is a sequentially compact set
in R. Then f is uniformly continuous on K.
Proof: If this is not true, there exists ε > 0 such that for every δ > 0 there exists
a pair of points, xδ and yδ such that even though |xδ −yδ| < δ, |f (xδ) −f (yδ)| ≥ε.
Taking a succession of values for δ equal to 1, 1/2, 1/3, ···, and letting the exceptional
pair of points for δ = 1/n be denoted by xn and yn,
|xn −yn| < 1
n, |f (xn) −f (yn)| ≥ε.
Now since K is sequentially compact, there exists a subsequence, {xnk} such that
xnk →z ∈K. Now nk ≥k and so
|xnk −ynk| < 1
k .
Consequently, ynk →z also. ( xnk is like a person walking toward a certain point
and ynk is like a dog on a leash which is constantly getting shorter. Obviously ynk
must also move toward the point also. You should give a precise proof of what is
needed here.) By continuity of f
0 = |f (z) −f (z)| = lim
k→∞|f (xnk) −f (ynk)| ≥ε,
an obvious contradiction. Therefore, the theorem must be true.
The following corollary follows from this theorem and Theorem 2.3.
Corollary 2.5 Suppose I is a closed interval, I = [a, b] and f : I →R is continu-
ous. Then f is uniformly continuous.
2.1
Exercises
1. A function, f : D ⊆R →R is Lipschitz continuous or just Lipschitz for short
if there exists a constant, K such that
|f (x) −f (y)| ≤K |x −y|
for all x, y ∈D. Show every Lipschitz function is uniformly continuous.
2. If |xn −yn| →0 and xn →z, show that yn →z also.
3. Consider f : (1, ∞) →R given by f (x) = 1
x. Show f is uniformly continuous
even though the set on which f is deﬁned is not sequentially compact.

2.2.
THEOREMS ABOUT CONTINUOUS FUNCTIONS
27
4. If f is uniformly continuous, does it follow that |f| is also uniformly continu-
ous? If |f| is uniformly continuous does it follow that f is uniformly continu-
ous? Answer the same questions with “uniformly continuous” replaced with
“continuous”. Explain why.
2.2
Theorems About Continuous Functions
In this section, proofs of some theorems which have not been proved yet are given.
Theorem 2.6 The following assertions are valid
1. The function, af + bg is continuous at x when f, g are continuous at x
∈D (f) ∩D (g) and a, b ∈R.
2. If and f and g are each real valued functions continuous at x, then
fg is
continuous at x. If, in addition to this, g (x) ̸= 0, then f/g is continuous at
x.
3. If f is continuous at x, f (x) ∈D (g) ⊆R, and g is continuous at f (x) ,then
g ◦f is continuous at x.
4. The function f : R →R, given by f (x) = |x| is continuous.
Proof:
First consider 1.)
Let ε > 0 be given.
By assumption, there exist
δ1 > 0 such that whenever |x −y| < δ1, it follows |f (x) −f (y)| <
ε
2(|a|+|b|+1) and
there exists δ2 > 0 such that whenever |x −y| < δ2, it follows that |g (x) −g (y)| <
ε
2(|a|+|b|+1). Then let 0 < δ ≤min (δ1, δ2) . If |x −y| < δ, then everything happens
at once. Therefore, using the triangle inequality
|af (x) + bf (x) −(ag (y) + bg (y))|
≤|a| |f (x) −f (y)| + |b| |g (x) −g (y)|
< |a|
µ
ε
2 (|a| + |b| + 1)
¶
+ |b|
µ
ε
2 (|a| + |b| + 1)
¶
< ε.
Now consider 2.) There exists δ1 > 0 such that if |y −x| < δ1, then
|f (x) −f (y)| < 1.
Therefore, for such y,
|f (y)| < 1 + |f (x)| .
It follows that for such y,
|fg (x) −fg (y)| ≤|f (x) g (x) −g (x) f (y)| + |g (x) f (y) −f (y) g (y)|

28
CONTINUOUS FUNCTIONS OF ONE VARIABLE
≤|g (x)| |f (x) −f (y)| + |f (y)| |g (x) −g (y)|
≤(1 + |g (x)| + |f (y)|) [|g (x) −g (y)| + |f (x) −f (y)|] .
Now let ε > 0 be given. There exists δ2 such that if |x −y| < δ2, then
|g (x) −g (y)| <
ε
2 (1 + |g (x)| + |f (y)|),
and there exists δ3 such that if |x−y| < δ3, then
|f (x) −f (y)| <
ε
2 (1 + |g (x)| + |f (y)|)
Now let 0 < δ ≤min (δ1, δ2, δ3) . Then if |x−y| < δ, all the above hold at once and
so
|fg (x) −fg (y)| ≤
(1 + |g (x)| + |f (y)|) [|g (x) −g (y)| + |f (x) −f (y)|]
< (1 + |g (x)| + |f (y)|)
µ
ε
2 (1 + |g (x)| + |f (y)|) +
ε
2 (1 + |g (x)| + |f (y)|)
¶
= ε.
This proves the ﬁrst part of 2.) To obtain the second part, let δ1 be as described
above and let δ0 > 0 be such that for |x−y| < δ0,
|g (x) −g (y)| < |g (x)| /2
and so by the triangle inequality,
−|g (x)| /2 ≤|g (y)| −|g (x)| ≤|g (x)| /2
which implies |g (y)| ≥|g (x)| /2, and |g (y)| < 3 |g (x)| /2.
Then if |x−y| < min (δ0, δ1) ,
¯¯¯¯
f (x)
g (x) −f (y)
g (y)
¯¯¯¯ =
¯¯¯¯
f (x) g (y) −f (y) g (x)
g (x) g (y)
¯¯¯¯
≤|f (x) g (y) −f (y) g (x)|
³
|g(x)|2
2
´
= 2 |f (x) g (y) −f (y) g (x)|
|g (x)|2
≤
2
|g (x)|2 [|f (x) g (y) −f (y) g (y) + f (y) g (y) −f (y) g (x)|]
≤
2
|g (x)|2 [|g (y)| |f (x) −f (y)| + |f (y)| |g (y) −g (x)|]
≤
2
|g (x)|2
·3
2 |g (x)| |f (x) −f (y)| + (1 + |f (x)|) |g (y) −g (x)|
¸
≤
2
|g (x)|2 (1 + 2 |f (x)| + 2 |g (x)|) [|f (x) −f (y)| + |g (y) −g (x)|]
≡M [|f (x) −f (y)| + |g (y) −g (x)|]

2.2.
THEOREMS ABOUT CONTINUOUS FUNCTIONS
29
where M is deﬁned by
M ≡
2
|g (x)|2 (1 + 2 |f (x)| + 2 |g (x)|)
Now let δ2 be such that if |x−y| < δ2, then
|f (x) −f (y)| < ε
2M −1
and let δ3 be such that if |x−y| < δ3, then
|g (y) −g (x)| < ε
2M −1.
Then if 0 < δ ≤min (δ0, δ1, δ2, δ3) , and |x−y| < δ, everything holds and
¯¯¯¯
f (x)
g (x) −f (y)
g (y)
¯¯¯¯ ≤M [|f (x) −f (y)| + |g (y) −g (x)|]
< M
hε
2M −1 + ε
2M −1i
= ε.
This completes the proof of the second part of 2.)
Note that in these proofs no eﬀort is made to ﬁnd some sort of “best” δ. The
problem is one which has a yes or a no answer. Either is it or it is not continuous.
Now consider 3.). If f is continuous at x, f (x) ∈D (g) ⊆Rp, and g is continuous
at f (x) ,then g ◦f is continuous at x. Let ε > 0 be given. Then there exists η > 0
such that if |y−f (x)| < η and y ∈D (g) , it follows that |g (y) −g (f (x))| < ε. From
continuity of f at x, there exists δ > 0 such that if |x−z| < δ and z ∈D (f) , then
|f (z) −f (x)| < η. Then if |x−z| < δ and z ∈D (g ◦f) ⊆D (f) , all the above hold
and so
|g (f (z)) −g (f (x))| < ε.
This proves part 3.)
To verify part 4.), let ε > 0 be given and let δ = ε. Then if |x−y| < δ, the
triangle inequality implies
|f (x) −f (y)| = ||x| −|y||
≤|x−y| < δ = ε.
This proves part 4.) and completes the proof of the theorem.
Next here is a proof of the intermediate value theorem.
Theorem 2.7 Suppose f : [a, b] →R is continuous and suppose f (a) < c < f (b) .
Then there exists x ∈(a, b) such that f (x) = c.
Proof: Let d =
a+b
2
and consider the intervals [a, d] and [d, b] . If f (d) ≥c,
then on [a, d] , the function is ≤c at one end point and ≥c at the other. On the
other hand, if f (d) ≤c, then on [d, b] f ≥0 at one end point and ≤0 at the

30
CONTINUOUS FUNCTIONS OF ONE VARIABLE
other. Pick the interval on which f has values which are at least as large as c and
values no larger than c. Now consider that interval, divide it in half as was done for
the original interval and argue that on one of these smaller intervals, the function
has values at least as large as c and values no larger than c. Continue in this way.
Next apply the nested interval lemma to get x in all these intervals. In the nth
interval, let xn, yn be elements of this interval such that f (xn) ≤c, f (yn) ≥c.
Now |xn −x| ≤(b −a) 2−n and |yn −x| ≤(b −a) 2−n and so xn →x and yn →x.
Therefore,
f (x) −c = lim
n→∞(f (xn) −c) ≤0
while
f (x) −c = lim
n→∞(f (yn) −c) ≥0.
Consequently f (x) = c and this proves the theorem.
Lemma 2.8 Let φ : [a, b] →R be a continuous function and suppose φ is 1 −1 on
(a, b). Then φ is either strictly increasing or strictly decreasing on [a, b] .
Proof: First it is shown that φ is either strictly increasing or strictly decreasing
on (a, b) .
If φ is not strictly decreasing on (a, b), then there exists x1 < y1, x1, y1 ∈(a, b)
such that
(φ (y1) −φ (x1)) (y1 −x1) > 0.
If for some other pair of points, x2 < y2 with x2, y2 ∈(a, b) , the above inequality
does not hold, then since φ is 1 −1,
(φ (y2) −φ (x2)) (y2 −x2) < 0.
Let xt ≡tx1 + (1 −t) x2 and yt ≡ty1 + (1 −t) y2. Then xt < yt for all t ∈[0, 1]
because
tx1 ≤ty1 and (1 −t) x2 ≤(1 −t) y2
with strict inequality holding for at least one of these inequalities since not both t
and (1 −t) can equal zero. Now deﬁne
h (t) ≡(φ (yt) −φ (xt)) (yt −xt) .
Since h is continuous and h (0) < 0, while h (1) > 0, there exists t ∈(0, 1) such
that h (t) = 0. Therefore, both xt and yt are points of (a, b) and φ (yt) −φ (xt) = 0
contradicting the assumption that φ is one to one. It follows φ is either strictly
increasing or strictly decreasing on (a, b) .
This property of being either strictly increasing or strictly decreasing on (a, b)
carries over to [a, b] by the continuity of φ. Suppose φ is strictly increasing on (a, b) ,
a similar argument holding for φ strictly decreasing on (a, b) . If x > a, then pick
y ∈(a, x) and from the above, φ (y) < φ (x) . Now by continuity of φ at a,
φ (a) = lim
x→a+ φ (z) ≤φ (y) < φ (x) .
Therefore, φ (a) < φ (x) whenever x ∈(a, b) . Similarly φ (b) > φ (x) for all x ∈(a, b).
This proves the lemma.

2.2.
THEOREMS ABOUT CONTINUOUS FUNCTIONS
31
Corollary 2.9 Let f : (a, b) →R be one to one and continuous. Then f (a, b) is
an open interval, (c, d) and f −1 : (c, d) →(a, b) is continuous.
Proof: Since f is either strictly increasing or strictly decreasing, it follows that
f (a, b) is an open interval, (c, d) . Assume f is decreasing.
Now let x ∈(a, b).
Why is f −1 is continuous at f (x)? Since f is decreasing, if f (x) < f (y) , then
y ≡f −1 (f (y)) < x ≡f −1 (f (x)) and so f −1 is also decreasing. Let ε > 0 be given.
Let ε > η > 0 and (x −η, x + η) ⊆(a, b) . Then f (x) ∈(f (x + η) , f (x −η)) . Let
δ = min (f (x) −f (x + η) , f (x −η) −f (x)) . Then if
|f (z) −f (x)| < δ,
it follows
z ≡f −1 (f (z)) ∈(x −η, x + η) ⊆(x −ε, x + ε)
so
¯¯f −1 (f (z)) −x
¯¯ =
¯¯f −1 (f (z)) −f −1 (f (x))
¯¯ < ε.
This proves the theorem in the case where f is strictly decreasing. The case where
f is increasing is similar.

32
CONTINUOUS FUNCTIONS OF ONE VARIABLE

The Riemann Stieltjes
Integral
The integral originated in attempts to ﬁnd areas of various shapes and the ideas
involved in ﬁnding integrals are much older than the ideas related to ﬁnding deriva-
tives. In fact, Archimedes1 was ﬁnding areas of various curved shapes about 250
B.C. using the main ideas of the integral. What is presented here is a generaliza-
tion of these ideas. The main interest is in the Riemann integral but if it is easy to
generalize to the so called Stieltjes integral in which the length of an interval, [x, y]
is replaced with an expression of the form F (y) −F (x) where F is an increasing
function, then the generalization is given. However, there is much more that can
be written about Stieltjes integrals than what is presented here. A good source for
this is the book by Apostol, [3].
3.1
Upper And Lower Riemann Stieltjes Sums
The Riemann integral pertains to bounded functions which are deﬁned on a bounded
interval. Let [a, b] be a closed interval. A set of points in [a, b], {x0, · · ·, xn} is a
partition if
a = x0 < x1 < · · · < xn = b.
Such partitions are denoted by P or Q. For f a bounded function deﬁned on [a, b] ,
let
Mi (f) ≡sup{f (x) : x ∈[xi−1, xi]},
mi (f) ≡inf{f (x) : x ∈[xi−1, xi]}.
1Archimedes 287-212 B.C. found areas of curved regions by stuﬃng them with simple shapes
which he knew the area of and taking a limit. He also made fundamental contributions to physics.
The story is told about how he determined that a gold smith had cheated the king by giving him
a crown which was not solid gold as had been claimed. He did this by ﬁnding the amount of water
displaced by the crown and comparing with the amount of water it should have displaced if it had
been solid gold.
33

34
THE RIEMANN STIELTJES INTEGRAL
Deﬁnition 3.1 Let F be an increasing function deﬁned on [a, b] and let ∆Fi ≡
F (xi) −F (xi−1) . Then deﬁne upper and lower sums as
U (f, P) ≡
n
X
i=1
Mi (f) ∆Fi and L (f, P) ≡
n
X
i=1
mi (f) ∆Fi
respectively. The numbers, Mi (f) and mi (f) , are well deﬁned real numbers because
f is assumed to be bounded and R is complete. Thus the set S = {f (x) : x ∈
[xi−1, xi]} is bounded above and below.
In the following picture, the sum of the areas of the rectangles in the picture on
the left is a lower sum for the function in the picture and the sum of the areas of the
rectangles in the picture on the right is an upper sum for the same function which
uses the same partition. In these pictures the function, F is given by F (x) = x and
these are the ordinary upper and lower sums from calculus.
y = f(x)
x0
x1
x2
x3
x0
x1
x2
x3
What happens when you add in more points in a partition?
The following
pictures illustrate in the context of the above example. In this example a single
additional point, labeled z has been added in.
y = f(x)
x0
x1
x2
x3
z
x0
x1
x2
x3
z
Note how the lower sum got larger by the amount of the area in the shaded
rectangle and the upper sum got smaller by the amount in the rectangle shaded by
dots. In general this is the way it works and this is shown in the following lemma.
Lemma 3.2 If P ⊆Q then
U (f, Q) ≤U (f, P) , and L (f, P) ≤L (f, Q) .

3.1.
UPPER AND LOWER RIEMANN STIELTJES SUMS
35
Proof: This is veriﬁed by adding in one point at a time. Thus let
P = {x0, · · ·, xn}
and let
Q = {x0, · · ·, xk, y, xk+1, · · ·, xn}.
Thus exactly one point, y, is added between xk and xk+1. Now the term in the
upper sum which corresponds to the interval [xk, xk+1] in U (f, P) is
sup {f (x) : x ∈[xk, xk+1]} (F (xk+1) −F (xk))
(3.1)
and the term which corresponds to the interval [xk, xk+1] in U (f, Q) is
sup {f (x) : x ∈[xk, y]} (F (y) −F (xk))
+ sup {f (x) : x ∈[y, xk+1]} (F (xk+1) −F (y))
≡M1 (F (y) −F (xk)) + M2 (F (xk+1) −F (y))
(3.2)
All the other terms in the two sums coincide. Now sup {f (x) : x ∈[xk, xk+1]} ≥
max (M1, M2) and so the expression in 3.2 is no larger than
sup {f (x) : x ∈[xk, xk+1]} (F (xk+1) −F (y))
+ sup {f (x) : x ∈[xk, xk+1]} (F (y) −F (xk))
= sup {f (x) : x ∈[xk, xk+1]} (F (xk+1) −F (xk)) ,
the term corresponding to the interval, [xk, xk+1] and U (f, P) . This proves the
ﬁrst part of the lemma pertaining to upper sums because if Q ⊇P, one can obtain
Q from P by adding in one point at a time and each time a point is added, the
corresponding upper sum either gets smaller or stays the same. The second part
about lower sums is similar and is left as an exercise.
Lemma 3.3 If P and Q are two partitions, then
L (f, P) ≤U (f, Q) .
Proof: By Lemma 3.2,
L (f, P) ≤L (f, P ∪Q) ≤U (f, P ∪Q) ≤U (f, Q) .
Deﬁnition 3.4
I ≡inf{U (f, Q) where Q is a partition}
I ≡sup{L (f, P) where P is a partition}.
Note that I and I are well deﬁned real numbers.

36
THE RIEMANN STIELTJES INTEGRAL
Theorem 3.5 I ≤I.
Proof: From Lemma 3.3,
I = sup{L (f, P) where P is a partition} ≤U (f, Q)
because U (f, Q) is an upper bound to the set of all lower sums and so it is no
smaller than the least upper bound. Therefore, since Q is arbitrary,
I = sup{L (f, P) where P is a partition}
≤inf{U (f, Q) where Q is a partition} ≡I
where the inequality holds because it was just shown that I is a lower bound to the
set of all upper sums and so it is no larger than the greatest lower bound of this
set. This proves the theorem.
Deﬁnition 3.6 A bounded function f is Riemann Stieltjes integrable, written as
f ∈R ([a, b])
if
I = I
and in this case,
Z b
a
f (x) dF ≡I = I.
When F (x) = x, the integral is called the Riemann integral and is written as
Z b
a
f (x) dx.
Thus, in words, the Riemann integral is the unique number which lies between
all upper sums and all lower sums if there is such a unique number.
Recall the following Proposition which comes from the deﬁnitions.
Proposition 3.7 Let S be a nonempty set and suppose sup (S) exists. Then for
every δ > 0,
S ∩(sup (S) −δ, sup (S)] ̸= ∅.
If inf (S) exists, then for every δ > 0,
S ∩[inf (S) , inf (S) + δ) ̸= ∅.
This proposition implies the following theorem which is used to determine the
question of Riemann Stieltjes integrability.
Theorem 3.8 A bounded function f is Riemann integrable if and only if for all
ε > 0, there exists a partition P such that
U (f, P) −L (f, P)
< ε.
(3.3)

3.2.
EXERCISES
37
Proof: First assume f is Riemann integrable. Then let P and Q be two parti-
tions such that
U (f, Q) < I + ε/2, L (f, P) > I −ε/2.
Then since I = I,
U (f, Q ∪P) −L (f, P ∪Q) ≤U (f, Q) −L (f, P) < I + ε/2 −(I −ε/2) = ε.
Now suppose that for all ε > 0 there exists a partition such that 3.3 holds. Then
for given ε and partition P corresponding to ε
I −I ≤U (f, P) −L (f, P) ≤ε.
Since ε is arbitrary, this shows I = I and this proves the theorem.
The condition described in the theorem is called the Riemann criterion .
Not all bounded functions are Riemann integrable. For example, let F (x) = x
and
f (x) ≡
½ 1 if x ∈Q
0 if x ∈R \ Q
(3.4)
Then if [a, b] = [0, 1] all upper sums for f equal 1 while all lower sums for f equal
0. Therefore the Riemann criterion is violated for ε = 1/2.
3.2
Exercises
1. Prove the second half of Lemma 3.2 about lower sums.
2. Verify that for f given in 3.4, the lower sums on the interval [0, 1] are all equal
to zero while the upper sums are all equal to one.
3. Let f (x) = 1 + x2 for x ∈[−1, 3] and let P =
©
−1, −1
3, 0, 1
2, 1, 2
ª
. Find
U (f, P) and L (f, P) for F (x) = x and for F (x) = x3.
4. Show that if f ∈R ([a, b]) for F (x) = x, there exists a partition, {x0, · · ·, xn}
such that for any zk ∈[xk, xk+1] ,
¯¯¯¯¯
Z b
a
f (x) dx −
n
X
k=1
f (zk) (xk −xk−1)
¯¯¯¯¯ < ε
This sum, Pn
k=1 f (zk) (xk −xk−1) , is called a Riemann sum and this exercise
shows that the Riemann integral can always be approximated by a Riemann
sum. For the general Riemann Stieltjes case, does anything change?
5. Let P =
©
1, 1 1
4, 1 1
2, 1 3
4, 2
ª
and F (x) = x. Find upper and lower sums for the
function, f (x) = 1
x using this partition. What does this tell you about ln (2)?
6. If f ∈R ([a, b]) with F (x) = x and f is changed at ﬁnitely many points,
show the new function is also in R ([a, b]) . Is this still true for the general case
where F is only assumed to be an increasing function? Explain.

38
THE RIEMANN STIELTJES INTEGRAL
7. In the case where F (x) = x, deﬁne a “left sum” as
n
X
k=1
f (xk−1) (xk −xk−1)
and a “right sum”,
n
X
k=1
f (xk) (xk −xk−1) .
Also suppose that all partitions have the property that xk −xk−1 equals a
constant, (b −a) /n so the points in the partition are equally spaced, and
deﬁne the integral to be the number these right and left sums get close to as
n gets larger and larger. Show that for f given in 3.4,
R x
0 f (t) dt = 1 if x is
rational and
R x
0 f (t) dt = 0 if x is irrational. It turns out that the correct
answer should always equal zero for that function, regardless of whether x is
rational. This is shown when the Lebesgue integral is studied. This illustrates
why this method of deﬁning the integral in terms of left and right sums is total
nonsense. Show that even though this is the case, it makes no diﬀerence if f
is continuous.
3.3
Functions Of Riemann Integrable Functions
It is often necessary to consider functions of Riemann integrable functions and a
natural question is whether these are Riemann integrable. The following theorem
gives a partial answer to this question. This is not the most general theorem which
will relate to this question but it will be enough for the needs of this book.
Theorem 3.9 Let f, g be bounded functions and let
f ([a, b]) ⊆[c1, d1] , g ([a, b]) ⊆[c2, d2] .
Let H : [c1, d1] × [c2, d2] →R satisfy,
|H (a1, b1) −H (a2, b2)| ≤K [|a1 −a2| + |b1 −b2|]
for some constant K. Then if f, g ∈R ([a, b]) it follows that H ◦(f, g) ∈R ([a, b]) .
Proof: In the following claim, Mi (h) and mi (h) have the meanings assigned
above with respect to some partition of [a, b] for the function, h.
Claim: The following inequality holds.
|Mi (H ◦(f, g)) −mi (H ◦(f, g))| ≤
K [|Mi (f) −mi (f)| + |Mi (g) −mi (g)|] .
Proof of the claim: By the above proposition, there exist x1, x2 ∈[xi−1, xi]
be such that
H (f (x1) , g (x1)) + η > Mi (H ◦(f, g)) ,

3.3.
FUNCTIONS OF RIEMANN INTEGRABLE FUNCTIONS
39
and
H (f (x2) , g (x2)) −η < mi (H ◦(f, g)) .
Then
|Mi (H ◦(f, g)) −mi (H ◦(f, g))|
< 2η + |H (f (x1) , g (x1)) −H (f (x2) , g (x2))|
< 2η + K [|f (x1) −f (x2)| + |g (x1) −g (x2)|]
≤2η + K [|Mi (f) −mi (f)| + |Mi (g) −mi (g)|] .
Since η > 0 is arbitrary, this proves the claim.
Now continuing with the proof of the theorem, let P be such that
n
X
i=1
(Mi (f) −mi (f)) ∆Fi <
ε
2K ,
n
X
i=1
(Mi (g) −mi (g)) ∆Fi <
ε
2K .
Then from the claim,
n
X
i=1
(Mi (H ◦(f, g)) −mi (H ◦(f, g))) ∆Fi
<
n
X
i=1
K [|Mi (f) −mi (f)| + |Mi (g) −mi (g)|] ∆Fi < ε.
Since ε > 0 is arbitrary, this shows H ◦(f, g) satisﬁes the Riemann criterion and
hence H ◦(f, g) is Riemann integrable as claimed. This proves the theorem.
This theorem implies that if f, g are Riemann Stieltjes integrable, then so is
af + bg, |f| , f 2, along with inﬁnitely many other such continuous combinations of
Riemann Stieltjes integrable functions. For example, to see that |f| is Riemann
integrable, let H (a, b) = |a| . Clearly this function satisﬁes the conditions of the
above theorem and so |f| = H (f, f) ∈R ([a, b]) as claimed. The following theorem
gives an example of many functions which are Riemann integrable.
Theorem 3.10 Let f : [a, b] →R be either increasing or decreasing on [a, b] and
suppose F is continuous. Then f ∈R ([a, b]) .
Proof: Let ε > 0 be given and let
xi = a + i
µb −a
n
¶
, i = 0, · · ·, n.
Since F is continuous, it follows from Corollary 2.5 on Page 26 that it is uniformly
continuous. Therefore, if n is large enough, then for all i,
F (xi) −F (xi−1) <
ε
f (b) −f (a) + 1

40
THE RIEMANN STIELTJES INTEGRAL
Then since f is increasing,
U (f, P) −L (f, P) =
n
X
i=1
(f (xi) −f (xi−1)) (F (xi) −F (xi−1))
≤
ε
f (b) −f (a) + 1
n
X
i=1
(f (xi) −f (xi−1))
=
ε
f (b) −f (a) + 1 (f (b) −f (a)) < ε.
Thus the Riemann criterion is satisﬁed and so the function is Riemann Stieltjes
integrable. The proof for decreasing f is similar.
Corollary 3.11 Let [a, b] be a bounded closed interval and let φ : [a, b] →R be
Lipschitz continuous and suppose F is continuous. Then φ ∈R ([a, b]) . Recall that
a function, φ, is Lipschitz continuous if there is a constant, K, such that for all
x, y,
|φ (x) −φ (y)| < K |x −y| .
Proof: Let f (x) = x. Then by Theorem 3.10, f is Riemann Stieltjes integrable.
Let H (a, b) ≡φ (a). Then by Theorem 3.9 H ◦(f, f) = φ ◦f = φ is also Riemann
Stieltjes integrable. This proves the corollary.
In fact, it is enough to assume φ is continuous, although this is harder. This
is the content of the next theorem which is where the diﬃcult theorems about
continuity and uniform continuity are used. This is the main result on the existence
of the Riemann Stieltjes integral for this book.
Theorem 3.12 Suppose f : [a, b] →R is continuous and F is just an increasing
function deﬁned on [a, b]. Then f ∈R ([a, b]) .
Proof: By Corollary 2.5 on Page 26, f is uniformly continuous on [a, b] . There-
fore, if ε > 0 is given, there exists a δ > 0 such that if |xi −xi−1| < δ, then
Mi −mi <
ε
F (b)−F (a)+1. Let
P ≡{x0, · · ·, xn}
be a partition with |xi −xi−1| < δ. Then
U (f, P) −L (f, P)
<
n
X
i=1
(Mi −mi) (F (xi) −F (xi−1))
<
ε
F (b) −F (a) + 1 (F (b) −F (a)) < ε.
By the Riemann criterion, f ∈R ([a, b]) . This proves the theorem.

3.4.
PROPERTIES OF THE INTEGRAL
41
3.4
Properties Of The Integral
The integral has many important algebraic properties. First here is a simple lemma.
Lemma 3.13 Let S be a nonempty set which is bounded above and below. Then if
−S ≡{−x : x ∈S} ,
sup (−S) = −inf (S)
(3.5)
and
inf (−S) = −sup (S) .
(3.6)
Proof: Consider 3.5. Let x ∈S. Then −x ≤sup (−S) and so x ≥−sup (−S) . If
follows that −sup (−S) is a lower bound for S and therefore, −sup (−S) ≤inf (S) .
This implies sup (−S) ≥−inf (S) . Now let −x ∈−S. Then x ∈S and so x ≥inf (S)
which implies −x ≤−inf (S) . Therefore, −inf (S) is an upper bound for −S and
so −inf (S) ≥sup (−S) . This shows 3.5. Formula 3.6 is similar and is left as an
exercise.
In particular, the above lemma implies that for Mi (f) and mi (f) deﬁned above
Mi (−f) = −mi (f) , and mi (−f) = −Mi (f) .
Lemma 3.14 If f ∈R ([a, b]) then −f ∈R ([a, b]) and
−
Z b
a
f (x) dF =
Z b
a
−f (x) dF.
Proof: The ﬁrst part of the conclusion of this lemma follows from Theorem 3.10
since the function φ (y) ≡−y is Lipschitz continuous. Now choose P such that
Z b
a
−f (x) dF −L (−f, P) < ε.
Then since mi (−f) = −Mi (f) ,
ε >
Z b
a
−f (x) dF −
n
X
i=1
mi (−f) ∆Fi =
Z b
a
−f (x) dF +
n
X
i=1
Mi (f) ∆Fi
which implies
ε >
Z b
a
−f (x) dF +
n
X
i=1
Mi (f) ∆Fi ≥
Z b
a
−f (x) dF +
Z b
a
f (x) dF.
Thus, since ε is arbitrary,
Z b
a
−f (x) dF ≤−
Z b
a
f (x) dF
whenever f ∈R ([a, b]) . It follows
Z b
a
−f (x) dF ≤−
Z b
a
f (x) dF = −
Z b
a
−(−f (x)) dF ≤
Z b
a
−f (x) dF
and this proves the lemma.

42
THE RIEMANN STIELTJES INTEGRAL
Theorem 3.15 The integral is linear,
Z b
a
(αf + βg) (x) dF = α
Z b
a
f (x) dF + β
Z b
a
g (x) dF.
whenever f, g ∈R ([a, b]) and α, β ∈R.
Proof: First note that by Theorem 3.9, αf + βg ∈R ([a, b]) . To begin with,
consider the claim that if f, g ∈R ([a, b]) then
Z b
a
(f + g) (x) dF =
Z b
a
f (x) dF +
Z b
a
g (x) dF.
(3.7)
Let P1,Q1 be such that
U (f, Q1) −L (f, Q1) < ε/2, U (g, P1) −L (g, P1) < ε/2.
Then letting P ≡P1 ∪Q1, Lemma 3.2 implies
U (f, P) −L (f, P) < ε/2, and U (g, P) −U (g, P) < ε/2.
Next note that
mi (f + g) ≥mi (f) + mi (g) , Mi (f + g) ≤Mi (f) + Mi (g) .
Therefore,
L (g + f, P) ≥L (f, P) + L (g, P) , U (g + f, P) ≤U (f, P) + U (g, P) .
For this partition,
Z b
a
(f + g) (x) dF ∈[L (f + g, P) , U (f + g, P)]
⊆[L (f, P) + L (g, P) , U (f, P) + U (g, P)]
and
Z b
a
f (x) dF +
Z b
a
g (x) dF ∈[L (f, P) + L (g, P) , U (f, P) + U (g, P)] .
Therefore,
¯¯¯¯¯
Z b
a
(f + g) (x) dF −
ÃZ b
a
f (x) dF +
Z b
a
g (x) dF
!¯¯¯¯¯ ≤
U (f, P) + U (g, P) −(L (f, P) + L (g, P)) < ε/2 + ε/2 = ε.
This proves 3.7 since ε is arbitrary.

3.4.
PROPERTIES OF THE INTEGRAL
43
It remains to show that
α
Z b
a
f (x) dF =
Z b
a
αf (x) dF.
Suppose ﬁrst that α ≥0. Then
Z b
a
αf (x) dF ≡sup{L (αf, P) : P is a partition} =
α sup{L (f, P) : P is a partition} ≡α
Z b
a
f (x) dF.
If α < 0, then this and Lemma 3.14 imply
Z b
a
αf (x) dF =
Z b
a
(−α) (−f (x)) dF
= (−α)
Z b
a
(−f (x)) dF = α
Z b
a
f (x) dF.
This proves the theorem.
In the next theorem, suppose F is deﬁned on [a, b] ∪[b, c] .
Theorem 3.16 If f ∈R ([a, b]) and f ∈R ([b, c]) , then f ∈R ([a, c]) and
Z c
a
f (x) dF =
Z b
a
f (x) dF +
Z c
b
f (x) dF.
(3.8)
Proof: Let P1 be a partition of [a, b] and P2 be a partition of [b, c] such that
U (f, Pi) −L (f, Pi) < ε/2, i = 1, 2.
Let P ≡P1 ∪P2. Then P is a partition of [a, c] and
U (f, P) −L (f, P)
= U (f, P1) −L (f, P1) + U (f, P2) −L (f, P2) < ε/2 + ε/2 = ε.
(3.9)
Thus, f ∈R ([a, c]) by the Riemann criterion and also for this partition,
Z b
a
f (x) dF +
Z c
b
f (x) dF ∈[L (f, P1) + L (f, P2) , U (f, P1) + U (f, P2)]
= [L (f, P) , U (f, P)]
and
Z c
a
f (x) dF ∈[L (f, P) , U (f, P)] .
Hence by 3.9,
¯¯¯¯¯
Z c
a
f (x) dF −
ÃZ b
a
f (x) dF +
Z c
b
f (x) dF
!¯¯¯¯¯ < U (f, P) −L (f, P) < ε
which shows that since ε is arbitrary, 3.8 holds. This proves the theorem.

44
THE RIEMANN STIELTJES INTEGRAL
Corollary 3.17 Let F be continuous and let [a, b] be a closed and bounded interval
and suppose that
a = y1 < y2 · ·· < yl = b
and that f is a bounded function deﬁned on [a, b] which has the property that f is
either increasing on [yj, yj+1] or decreasing on [yj, yj+1] for j = 1, · · ·, l −1. Then
f ∈R ([a, b]) .
Proof: This follows from Theorem 3.16 and Theorem 3.10.
The symbol,
R b
a f (x) dF
when a > b has not yet been deﬁned.
Deﬁnition 3.18 Let [a, b] be an interval and let f ∈R ([a, b]) . Then
Z a
b
f (x) dF ≡−
Z b
a
f (x) dF.
Note that with this deﬁnition,
Z a
a
f (x) dF = −
Z a
a
f (x) dF
and so
Z a
a
f (x) dF = 0.
Theorem 3.19 Assuming all the integrals make sense,
Z b
a
f (x) dF +
Z c
b
f (x) dF =
Z c
a
f (x) dF.
Proof: This follows from Theorem 3.16 and Deﬁnition 3.18. For example, as-
sume
c ∈(a, b) .
Then from Theorem 3.16,
Z c
a
f (x) dF +
Z b
c
f (x) dF =
Z b
a
f (x) dF
and so by Deﬁnition 3.18,
Z c
a
f (x) dF =
Z b
a
f (x) dF −
Z b
c
f (x) dF
=
Z b
a
f (x) dF +
Z c
b
f (x) dF.
The other cases are similar.

3.5.
FUNDAMENTAL THEOREM OF CALCULUS
45
The following properties of the integral have either been established or they
follow quickly from what has been shown so far.
If f ∈R ([a, b]) then if c ∈[a, b] , f ∈R ([a, c]) ,
(3.10)
Z b
a
α dF = α (F (b) −F (a)) ,
(3.11)
Z b
a
(αf + βg) (x) dF = α
Z b
a
f (x) dF + β
Z b
a
g (x) dF,
(3.12)
Z b
a
f (x) dF +
Z c
b
f (x) dF =
Z c
a
f (x) dF,
(3.13)
Z b
a
f (x) dF ≥0 if f (x) ≥0 and a < b,
(3.14)
¯¯¯¯¯
Z b
a
f (x) dF
¯¯¯¯¯ ≤
¯¯¯¯¯
Z b
a
|f (x)| dF
¯¯¯¯¯ .
(3.15)
The only one of these claims which may not be completely obvious is the last one.
To show this one, note that
|f (x)| −f (x) ≥0, |f (x)| + f (x) ≥0.
Therefore, by 3.14 and 3.12, if a < b,
Z b
a
|f (x)| dF ≥
Z b
a
f (x) dF
and
Z b
a
|f (x)| dF ≥−
Z b
a
f (x) dF.
Therefore,
Z b
a
|f (x)| dF ≥
¯¯¯¯¯
Z b
a
f (x) dF
¯¯¯¯¯ .
If b < a then the above inequality holds with a and b switched. This implies 3.15.
3.5
Fundamental Theorem Of Calculus
In this section F (x) = x so things are specialized to the ordinary Riemann integral.
With these properties, it is easy to prove the fundamental theorem of calculus2.
2This theorem is why Newton and Liebnitz are credited with inventing calculus. The integral
had been around for thousands of years and the derivative was by their time well known. However
the connection between these two ideas had not been fully made although Newton’s predecessor,
Isaac Barrow had made some progress in this direction.

46
THE RIEMANN STIELTJES INTEGRAL
Let f ∈R ([a, b]) . Then by 3.10 f ∈R ([a, x]) for each x ∈[a, b] . The ﬁrst version
of the fundamental theorem of calculus is a statement about the derivative of the
function
x →
Z x
a
f (t) dt.
Theorem 3.20 Let f ∈R ([a, b]) and let
F (x) ≡
Z x
a
f (t) dt.
Then if f is continuous at x ∈(a, b) ,
F ′ (x) = f (x) .
Proof: Let x ∈(a, b) be a point of continuity of f and let h be small enough
that x + h ∈[a, b] . Then by using 3.13,
h−1 (F (x + h) −F (x)) = h−1
Z x+h
x
f (t) dt.
Also, using 3.11,
f (x) = h−1
Z x+h
x
f (x) dt.
Therefore, by 3.15,
¯¯h−1 (F (x + h) −F (x)) −f (x)
¯¯ =
¯¯¯¯¯h−1
Z x+h
x
(f (t) −f (x)) dt
¯¯¯¯¯
≤
¯¯¯¯¯h−1
Z x+h
x
|f (t) −f (x)| dt
¯¯¯¯¯ .
Let ε > 0 and let δ > 0 be small enough that if |t −x| < δ, then
|f (t) −f (x)| < ε.
Therefore, if |h| < δ, the above inequality and 3.11 shows that
¯¯h−1 (F (x + h) −F (x)) −f (x)
¯¯ ≤|h|−1 ε |h| = ε.
Since ε > 0 is arbitrary, this shows
lim
h→0 h−1 (F (x + h) −F (x)) = f (x)
and this proves the theorem.
Note this gives existence for the initial value problem,
F ′ (x) = f (x) , F (a) = 0

3.5.
FUNDAMENTAL THEOREM OF CALCULUS
47
whenever f is Riemann integrable and continuous.3
The next theorem is also called the fundamental theorem of calculus.
Theorem 3.21 Let f ∈R ([a, b]) and suppose there exists an antiderivative for
f, G, such that
G′ (x) = f (x)
for every point of (a, b) and G is continuous on [a, b] . Then
Z b
a
f (x) dx = G (b) −G (a) .
(3.16)
Proof: Let P = {x0, · · ·, xn} be a partition satisfying
U (f, P) −L (f, P) < ε.
Then
G (b) −G (a) = G (xn) −G (x0)
=
n
X
i=1
G (xi) −G (xi−1) .
By the mean value theorem,
G (b) −G (a) =
n
X
i=1
G′ (zi) (xi −xi−1)
=
n
X
i=1
f (zi) ∆xi
where zi is some point in [xi−1, xi] . It follows, since the above sum lies between the
upper and lower sums, that
G (b) −G (a) ∈[L (f, P) , U (f, P)] ,
and also
Z b
a
f (x) dx ∈[L (f, P) , U (f, P)] .
Therefore,
¯¯¯¯¯G (b) −G (a) −
Z b
a
f (x) dx
¯¯¯¯¯ < U (f, P) −L (f, P) < ε.
Since ε > 0 is arbitrary, 3.16 holds. This proves the theorem.
3Of course it was proved that if f is continuous on a closed interval, [a, b] , then f ∈R ([a, b])
but this is a hard theorem using the diﬃcult result about uniform continuity.

48
THE RIEMANN STIELTJES INTEGRAL
The following notation is often used in this context. Suppose F is an antideriva-
tive of f as just described with F continuous on [a, b] and F ′ = f on (a, b) . Then
Z b
a
f (x) dx = F (b) −F (a) ≡F (x) |b
a.
Deﬁnition 3.22 Let f be a bounded function deﬁned on a closed interval [a, b] and
let P ≡{x0, ···, xn} be a partition of the interval. Suppose zi ∈[xi−1, xi] is chosen.
Then the sum
n
X
i=1
f (zi) (xi −xi−1)
is known as a Riemann sum. Also,
||P|| ≡max {|xi −xi−1| : i = 1, · · ·, n} .
Proposition 3.23 Suppose f ∈R ([a, b]) . Then there exists a partition, P ≡
{x0, · · ·, xn} with the property that for any choice of zk ∈[xk−1, xk] ,
¯¯¯¯¯
Z b
a
f (x) dx −
n
X
k=1
f (zk) (xk −xk−1)
¯¯¯¯¯ < ε.
Proof: Choose P such that U (f, P) −L (f, P) < ε and then both
R b
a f (x) dx
and Pn
k=1 f (zk) (xk −xk−1) are contained in [L (f, P) , U (f, P)] and so the claimed
inequality must hold. This proves the proposition.
It is signiﬁcant because it gives a way of approximating the integral.
The deﬁnition of Riemann integrability given in this chapter is also called Dar-
boux integrability and the integral deﬁned as the unique number which lies between
all upper sums and all lower sums which is given in this chapter is called the Dar-
boux integral . The deﬁnition of the Riemann integral in terms of Riemann sums
is given next.
Deﬁnition 3.24 A bounded function, f deﬁned on [a, b] is said to be Riemann
integrable if there exists a number, I with the property that for every ε > 0, there
exists δ > 0 such that if
P ≡{x0, x1, · · ·, xn}
is any partition having ||P|| < δ, and zi ∈[xi−1, xi] ,
¯¯¯¯¯I −
n
X
i=1
f (zi) (xi −xi−1)
¯¯¯¯¯ < ε.
The number
R b
a f (x) dx is deﬁned as I.
Thus, there are two deﬁnitions of the Riemann integral. It turns out they are
equivalent which is the following theorem of of Darboux.

3.6.
EXERCISES
49
Theorem 3.25 A bounded function deﬁned on [a, b] is Riemann integrable in the
sense of Deﬁnition 3.24 if and only if it is integrable in the sense of Darboux.
Furthermore the two integrals coincide.
The proof of this theorem is left for the exercises in Problems 10 - 12. It isn’t
essential that you understand this theorem so if it does not interest you, leave it
out. Note that it implies that given a Riemann integrable function f in either sense,
it can be approximated by Riemann sums whenever ||P|| is suﬃciently small. Both
versions of the integral are obsolete but entirely adequate for most applications and
as a point of departure for a more up to date and satisfactory integral. The reason
for using the Darboux approach to the integral is that all the existence theorems
are easier to prove in this context.
3.6
Exercises
1. Let F (x) =
R x3
x2
t5+7
t7+87t6+1 dt. Find F ′ (x) .
2. Let F (x) =
R x
2
1
1+t4 dt. Sketch a graph of F and explain why it looks the way
it does.
3. Let a and b be positive numbers and consider the function,
F (x) =
Z ax
0
1
a2 + t2 dt +
Z a/x
b
1
a2 + t2 dt.
Show that F is a constant.
4. Solve the following initial value problem from ordinary diﬀerential equations
which is to ﬁnd a function y such that
y′ (x) =
x7 + 1
x6 + 97x5 + 7, y (10) = 5.
5. If F, G ∈
R
f (x) dx for all x ∈R, show F (x) = G (x) + C for some constant,
C. Use this to give a diﬀerent proof of the fundamental theorem of calculus
which has for its conclusion
R b
a f (t) dt = G (b) −G (a) where G′ (x) = f (x) .
6. Suppose f is Riemann integrable on [a, b] and continuous. (In fact continuous
implies Riemann integrable.) Show there exists c ∈(a, b) such that
f (c) =
1
b −a
Z b
a
f (x) dx.
Hint: You might consider the function F (x) ≡
R x
a f (t) dt and use the mean
value theorem for derivatives and the fundamental theorem of calculus.

50
THE RIEMANN STIELTJES INTEGRAL
7. Suppose f and g are continuous functions on [a, b] and that g (x) ̸= 0 on (a, b) .
Show there exists c ∈(a, b) such that
f (c)
Z b
a
g (x) dx =
Z b
a
f (x) g (x) dx.
Hint: Deﬁne F (x) ≡
R x
a f (t) g (t) dt and let G (x) ≡
R x
a g (t) dt. Then use
the Cauchy mean value theorem on these two functions.
8. Consider the function
f (x) ≡
½
sin
¡ 1
x
¢
if x ̸= 0
0 if x = 0
.
Is f Riemann integrable? Explain why or why not.
9. Prove the second part of Theorem 3.10 about decreasing functions.
10. Suppose f is a bounded function deﬁned on [a, b] and |f (x)| < M for all
x ∈[a, b] . Now let Q be a partition having n points, {x∗
0, · · ·, x∗
n} and let P
be any other partition. Show that
|U (f, P) −L (f, P)| ≤2Mn ||P|| + |U (f, Q) −L (f, Q)| .
Hint: Write the sum for U (f, P)−L (f, P) and split this sum into two sums,
the sum of terms for which [xi−1, xi] contains at least one point of Q, and
terms for which [xi−1, xi] does not contain any points of Q. In the latter case,
[xi−1, xi] must be contained in some interval,
£
x∗
k−1, x∗
k
¤
. Therefore, the sum
of these terms should be no larger than |U (f, Q) −L (f, Q)| .
11. ↑If ε > 0 is given and f is a Darboux integrable function deﬁned on [a, b],
show there exists δ > 0 such that whenever ||P|| < δ, then
|U (f, P) −L (f, P)| < ε.
12. ↑Prove Theorem 3.25.

Some Important Linear
Algebra
This chapter contains some important linear algebra as distinguished from that
which is normally presented in undergraduate courses consisting mainly of uninter-
esting things you can do with row operations.
The notation, Cn refers to the collection of ordered lists of n complex numbers.
Since every real number is also a complex number, this simply generalizes the usual
notion of Rn, the collection of all ordered lists of n real numbers. In order to avoid
worrying about whether it is real or complex numbers which are being referred to,
the symbol F will be used. If it is not clear, always pick C.
Deﬁnition 4.1 Deﬁne
Fn ≡{(x1, · · ·, xn) : xj ∈F for j = 1, · · ·, n} .
(x1, · · ·, xn) = (y1, · · ·, yn) if and only if for all j = 1, · · ·, n, xj = yj. When
(x1, · · ·, xn) ∈Fn,
it is conventional to denote (x1, · · ·, xn) by the single bold face letter, x. The num-
bers, xj are called the coordinates. The set
{(0, · · ·, 0, t, 0, · · ·, 0) : t ∈F}
for t in the ith slot is called the ith coordinate axis. The point 0 ≡(0, · · ·, 0) is
called the origin.
Thus (1, 2, 4i) ∈F3 and (2, 1, 4i) ∈F3 but (1, 2, 4i) ̸= (2, 1, 4i) because, even
though the same numbers are involved, they don’t match up. In particular, the
ﬁrst entries are not equal.
The geometric signiﬁcance of Rn for n ≤3 has been encountered already in
calculus or in precalculus. Here is a short review. First consider the case when
n = 1. Then from the deﬁnition, R1 = R. Recall that R is identiﬁed with the
points of
a line. Look at the number line again. Observe that this amounts to
51

52
SOME IMPORTANT LINEAR ALGEBRA
identifying a point on this line with a real number. In other words a real number
determines where you are on this line. Now suppose n = 2 and consider two lines
which intersect each other at right angles as shown in the following picture.
2
6
· (2, 6)
−8
3
·
(−8, 3)
Notice how you can identify a point shown in the plane with the ordered pair,
(2, 6) . You go to the right a distance of 2 and then up a distance of 6. Similarly,
you can identify another point in the plane with the ordered pair (−8, 3) . Go to
the left a distance of 8 and then up a distance of 3. The reason you go to the left
is that there is a −sign on the eight.
From this reasoning, every ordered pair
determines a unique point in the plane. Conversely, taking a point in the plane,
you could draw two lines through the point, one vertical and the other horizontal
and determine unique points, x1 on the horizontal line in the above picture and x2
on the vertical line in the above picture, such that the point of interest is identiﬁed
with the ordered pair, (x1, x2) . In short, points in the plane can be identiﬁed with
ordered pairs similar to the way that points on the real line are identiﬁed with
real numbers. Now suppose n = 3. As just explained, the ﬁrst two coordinates
determine a point in a plane. Letting the third component determine how far up
or down you go, depending on whether this number is positive or negative, this
determines a point in space. Thus, (1, 4, −5) would mean to determine the point
in the plane that goes with (1, 4) and then to go below this plane a distance of 5
to obtain a unique point in space. You see that the ordered triples correspond to
points in space just as the ordered pairs correspond to points in a plane and single
real numbers correspond to points on a line.
You can’t stop here and say that you are only interested in n ≤3. What if you
were interested in the motion of two objects? You would need three coordinates
to describe where the ﬁrst object is and you would need another three coordinates
to describe where the other object is located. Therefore, you would need to be
considering R6. If the two objects moved around, you would need a time coordinate
as well. As another example, consider a hot object which is cooling and suppose
you want the temperature of this object. How many coordinates would be needed?
You would need one for the temperature, three for the position of the point in the
object and one more for the time.
Thus you would need to be considering R5.
Many other examples can be given. Sometimes n is very large. This is often the
case in applications to business when they are trying to maximize proﬁt subject
to constraints. It also occurs in numerical analysis when people try to solve hard
problems on a computer.

4.1.
ALGEBRA IN FN
53
There are other ways to identify points in space with three numbers but the one
presented is the most basic. In this case, the coordinates are known as Cartesian
coordinates after Descartes1 who invented this idea in the ﬁrst half of the seven-
teenth century. I will often not bother to draw a distinction between the point in n
dimensional space and its Cartesian coordinates.
The geometric signiﬁcance of Cn for n > 1 is not available because each copy of
C corresponds to the plane or R2.
4.1
Algebra in Fn
There are two algebraic operations done with elements of Fn. One is addition and
the other is multiplication by numbers, called scalars. In the case of Cn the scalars
are complex numbers while in the case of Rn the only allowed scalars are real
numbers. Thus, the scalars always come from F in either case.
Deﬁnition 4.2 If x ∈Fn and a ∈F, also called a scalar, then ax ∈Fn is deﬁned
by
ax = a (x1, · · ·, xn) ≡(ax1, · · ·, axn) .
(4.1)
This is known as scalar multiplication. If x, y ∈Fn then x + y ∈Fn and is deﬁned
by
x + y = (x1, · · ·, xn) + (y1, · · ·, yn)
≡(x1 + y1, · · ·, xn + yn)
(4.2)
With this deﬁnition, the algebraic properties satisfy the conclusions of the fol-
lowing theorem.
Theorem 4.3 For v, w ∈Fn and α, β scalars, (real numbers), the following hold.
v + w = w + v,
(4.3)
the commutative law of addition,
(v + w) + z = v+ (w + z) ,
(4.4)
the associative law for addition,
v + 0 = v,
(4.5)
the existence of an additive identity,
v+ (−v) = 0,
(4.6)
1Ren´e Descartes 1596-1650 is often credited with inventing analytic geometry although it seems
the ideas were actually known much earlier. He was interested in many diﬀerent subjects, physi-
ology, chemistry, and physics being some of them. He also wrote a large book in which he tried to
explain the book of Genesis scientiﬁcally. Descartes ended up dying in Sweden.

54
SOME IMPORTANT LINEAR ALGEBRA
the existence of an additive inverse, Also
α (v + w) = αv+αw,
(4.7)
(α + β) v =αv+βv,
(4.8)
α (βv) = αβ (v) ,
(4.9)
1v = v.
(4.10)
In the above 0 = (0, · · ·, 0).
You should verify these properties all hold. For example, consider 4.7
α (v + w) = α (v1 + w1, · · ·, vn + wn)
= (α (v1 + w1) , · · ·, α (vn + wn))
= (αv1 + αw1, · · ·, αvn + αwn)
= (αv1, · · ·, αvn) + (αw1, · · ·, αwn)
= αv + αw.
As usual subtraction is deﬁned as x −y ≡x+ (−y) .
4.2
Exercises
1. Verify all the properties 4.3-4.10.
2. Compute 5 (1, 2 + 3i, 3, −2) + 6 (2 −i, 1, −2, 7) .
3. Draw a picture of the points in R2 which are determined by the following
ordered pairs.
(a) (1, 2)
(b) (−2, −2)
(c) (−2, 3)
(d) (2, −5)
4. Does it make sense to write (1, 2) + (2, 3, 1)? Explain.
5. Draw a picture of the points in R3 which are determined by the following
ordered triples.
(a) (1, 2, 0)
(b) (−2, −2, 1)
(c) (−2, 3, −2)

4.3.
SUBSPACES SPANS AND BASES
55
4.3
Subspaces Spans And Bases
Deﬁnition 4.4 Let {x1, · · ·, xp} be vectors in Fn. A linear combination is any ex-
pression of the form
p
X
i=1
cixi
where the ci are scalars.
The set of all linear combinations of these vectors is
called span (x1, · · ·, xn) . If V ⊆Fn, then V is called a subspace if whenever α, β
are scalars and u and v are vectors of V, it follows αu + βv ∈V . That is, it is
“closed under the algebraic operations of vector addition and scalar multiplication”.
A linear combination of vectors is said to be trivial if all the scalars in the linear
combination equal zero. A set of vectors is said to be linearly independent if the
only linear combination of these vectors which equals the zero vector is the trivial
linear combination. Thus {x1, · · ·, xn} is called linearly independent if whenever
p
X
k=1
ckxk = 0
it follows that all the scalars, ck equal zero. A set of vectors, {x1, · · ·, xp} , is called
linearly dependent if it is not linearly independent. Thus the set of vectors is linearly
dependent if there exist scalars, ci, i = 1, ···, n, not all zero such that Pp
k=1 ckxk = 0.
Lemma 4.5 A set of vectors {x1, · · ·, xp} is linearly independent if and only if
none of the vectors can be obtained as a linear combination of the others.
Proof: Suppose ﬁrst that {x1, · · ·, xp} is linearly independent. If
xk =
X
j̸=k
cjxj,
then
0 = 1xk +
X
j̸=k
(−cj) xj,
a nontrivial linear combination, contrary to assumption. This shows that if the
set is linearly independent, then none of the vectors is a linear combination of the
others.
Now suppose no vector is a linear combination of the others. Is {x1, · · ·, xp}
linearly independent? If it is not there exist scalars, ci, not all zero such that
p
X
i=1
cixi = 0.
Say ck ̸= 0. Then you can solve for xk as
xk =
X
j̸=k
(−cj) /ckxj

56
SOME IMPORTANT LINEAR ALGEBRA
contrary to assumption. This proves the lemma.
The following is called the exchange theorem.
Theorem 4.6 (Exchange Theorem) Let {x1, · · ·, xr} be a linearly independent set
of vectors such that each xi is in span(y1, · · ·, ys) . Then r ≤s.
Proof:
Deﬁne span{y1, · · ·, ys} ≡V, it follows there exist scalars, c1, · · ·, cs
such that
x1 =
s
X
i=1
ciyi.
(4.11)
Not all of these scalars can equal zero because if this were the case, it would follow
that x1 = 0 and so {x1, · · ·, xr} would not be linearly independent.
Indeed, if
x1 = 0, 1x1 + Pr
i=2 0xi = x1 = 0 and so there would exist a nontrivial linear
combination of the vectors {x1, · · ·, xr} which equals zero.
Say ck ̸= 0. Then solve (4.11) for yk and obtain
yk ∈span

x1,
s-1 vectors here
z
}|
{
y1, · · ·, yk−1, yk+1, · · ·, ys

.
Deﬁne {z1, · · ·, zs−1} by
{z1, · · ·, zs−1} ≡{y1, · · ·, yk−1, yk+1, · · ·, ys}
Therefore, span {x1, z1, · · ·, zs−1} = V because if v ∈V, there exist constants c1, · ·
·, cs such that
v =
s−1
X
i=1
cizi + csyk.
Now replace the yk in the above with a linear combination of the vectors,
{x1, z1, · · ·, zs−1}
to obtain
v ∈span {x1, z1, · · ·, zs−1} .
The vector yk, in the list {y1, · · ·, ys} , has now been replaced with the vector x1
and the resulting modiﬁed list of vectors has the same span as the original list of
vectors, {y1, · · ·, ys} .
Now suppose that r > s and that
span (x1, · · ·, xl, z1, · · ·, zp) = V
where the vectors, z1, ···, zp are each taken from the set, {y1, · · ·, ys} and l +p = s.
This has now been done for l = 1 above. Then since r > s, it follows that l ≤s < r

4.3.
SUBSPACES SPANS AND BASES
57
and so l + 1 ≤r. Therefore, xl+1 is a vector not in the list, {x1, · · ·, xl} and since
span {x1, · · ·, xl, z1, · · ·, zp} = V, there exist scalars, ci and dj such that
xl+1 =
l
X
i=1
cixi +
p
X
j=1
djzj.
(4.12)
Now not all the dj can equal zero because if this were so, it would follow that
{x1, · · ·, xr} would be a linearly dependent set because one of the vectors would
equal a linear combination of the others. Therefore, (4.12) can be solved for one of
the zi, say zk, in terms of xl+1 and the other zi and just as in the above argument,
replace that zi with xl+1 to obtain
span

x1, · · ·xl, xl+1,
p-1 vectors here
z
}|
{
z1, · · ·zk−1, zk+1, · · ·, zp

= V.
Continue this way, eventually obtaining
span (x1, · · ·, xs) = V.
But then xr ∈span (x1, · · ·, xs) contrary to the assumption that {x1, · · ·, xr} is
linearly independent. Therefore, r ≤s as claimed.
Deﬁnition 4.7 A ﬁnite set of vectors, {x1, · · ·, xr} is a basis for Fn if
span (x1, · · ·, xr) = Fn
and {x1, · · ·, xr} is linearly independent.
Corollary 4.8 Let {x1, · · ·, xr} and {y1, · · ·, ys} be two bases2 of Fn. Then r =
s = n.
Proof: From the exchange theorem, r ≤s and s ≤r. Now note the vectors,
ei =
1 is in the ith slot
z
}|
{
(0, · · ·, 0, 1, 0 · ··, 0)
for i = 1, 2, · · ·, n are a basis for Fn. This proves the corollary.
Lemma 4.9 Let {v1, · · ·, vr} be a set of vectors. Then V ≡span (v1, · · ·, vr) is a
subspace.
2This is the plural form of basis. We could say basiss but it would involve an inordinate amount
of hissing as in “The sixth shiek’s sixth sheep is sick”. This is the reason that bases is used instead
of basiss.

58
SOME IMPORTANT LINEAR ALGEBRA
Proof: Suppose α, β are two scalars and let Pr
k=1 ckvk and Pr
k=1 dkvk are two
elements of V. What about
α
r
X
k=1
ckvk + β
r
X
k=1
dkvk?
Is it also in V ?
α
r
X
k=1
ckvk + β
r
X
k=1
dkvk =
r
X
k=1
(αck + βdk) vk ∈V
so the answer is yes. This proves the lemma.
Deﬁnition 4.10 A ﬁnite set of vectors, {x1, · · ·, xr} is a basis for a subspace, V
of Fn if span (x1, · · ·, xr) = V and {x1, · · ·, xr} is linearly independent.
Corollary 4.11 Let {x1, · · ·, xr} and {y1, · · ·, ys} be two bases for V . Then r = s.
Proof: From the exchange theorem, r ≤s and s ≤r. Therefore, this proves
the corollary.
Deﬁnition 4.12 Let V be a subspace of Fn. Then dim (V ) read as the dimension
of V is the number of vectors in a basis.
Of course you should wonder right now whether an arbitrary subspace even has
a basis. In fact it does and this is in the next theorem. First, here is an interesting
lemma.
Lemma 4.13 Suppose v /∈span (u1, · · ·, uk) and {u1, · · ·, uk} is linearly indepen-
dent. Then {u1, · · ·, uk, v} is also linearly independent.
Proof: Suppose Pk
i=1 ciui + dv = 0. It is required to verify that each ci = 0
and that d = 0. But if d ̸= 0, then you can solve for v as a linear combination of
the vectors, {u1, · · ·, uk},
v = −
k
X
i=1
³ci
d
´
ui
contrary to assumption. Therefore, d = 0. But then Pk
i=1 ciui = 0 and the linear
independence of {u1, · · ·, uk} implies each ci = 0 also. This proves the lemma.
Theorem 4.14 Let V be a nonzero subspace of Fn. Then V has a basis.
Proof: Let v1 ∈V where v1 ̸= 0. If span {v1} = V, stop. {v1} is a basis for V .
Otherwise, there exists v2 ∈V which is not in span {v1} . By Lemma 4.13 {v1, v2}
is a linearly independent set of vectors. If span {v1, v2} = V stop, {v1, v2} is a basis
for V. If span {v1, v2} ̸= V, then there exists v3 /∈span {v1, v2} and {v1, v2, v3} is
a larger linearly independent set of vectors. Continuing this way, the process must
stop before n + 1 steps because if not, it would be possible to obtain n + 1 linearly
independent vectors contrary to the exchange theorem. This proves the theorem.
In words the following corollary states that any linearly independent set of vec-
tors can be enlarged to form a basis.

4.4.
AN APPLICATION TO MATRICES
59
Corollary 4.15 Let V be a subspace of Fn and let {v1, · · ·, vr} be a linearly inde-
pendent set of vectors in V . Then either it is a basis for V or there exist vectors,
vr+1, · · ·, vs such that {v1, · · ·, vr, vr+1, · · ·, vs} is a basis for V.
Proof: This follows immediately from the proof of Theorem 31.23.
You do
exactly the same argument except you start with {v1, · · ·, vr} rather than {v1}.
It is also true that any spanning set of vectors can be restricted to obtain a
basis.
Theorem 4.16 Let V be a subspace of Fn and suppose span (u1 · ··, up) = V
where the ui are nonzero vectors. Then there exist vectors, {v1 · ··, vr} such that
{v1 · ··, vr} ⊆{u1 · ··, up} and {v1 · ··, vr} is a basis for V .
Proof: Let r be the smallest positive integer with the property that for some
set, {v1 · ··, vr} ⊆{u1 · ··, up} ,
span (v1 · ··, vr) = V.
Then r ≤p and it must be the case that {v1 · ··, vr} is linearly independent because
if it were not so, one of the vectors, say vk would be a linear combination of the
others. But then you could delete this vector from {v1 · ··, vr} and the resulting list
of r −1 vectors would still span V contrary to the deﬁnition of r. This proves the
theorem.
4.4
An Application To Matrices
The following is a theorem of major signiﬁcance.
Theorem 4.17 Suppose A is an n × n matrix. Then A is one to one if and only
if A is onto. Also, if B is an n × n matrix and AB = I, then it follows BA = I.
Proof: First suppose A is one to one. Consider the vectors, {Ae1, · · ·, Aen}
where ek is the column vector which is all zeros except for a 1 in the kth position.
This set of vectors is linearly independent because if
n
X
k=1
ckAek = 0,
then since A is linear,
A
Ã n
X
k=1
ckek
!
= 0
and since A is one to one, it follows
n
X
k=1
ckek = 03

60
SOME IMPORTANT LINEAR ALGEBRA
which implies each ck = 0. Therefore, {Ae1, · · ·, Aen} must be a basis for Fn because
if not there would exist a vector, y /∈span (Ae1, · · ·, Aen) and then by Lemma 4.13,
{Ae1, · · ·, Aen, y} would be an independent set of vectors having n+1 vectors in it,
contrary to the exchange theorem. It follows that for y ∈Fn there exist constants,
ci such that
y =
n
X
k=1
ckAek = A
Ã n
X
k=1
ckek
!
showing that, since y was arbitrary, A is onto.
Next suppose A is onto. This means the span of the columns of A equals Fn. If
these columns are not linearly independent, then by Lemma 4.5 on Page 55, one of
the columns is a linear combination of the others and so the span of the columns of
A equals the span of the n −1 other columns. This violates the exchange theorem
because {e1, · · ·, en} would be a linearly independent set of vectors contained in the
span of only n −1 vectors. Therefore, the columns of A must be independent and
this equivalent to saying that Ax = 0 if and only if x = 0. This implies A is one to
one because if Ax = Ay, then A (x −y) = 0 and so x −y = 0.
Now suppose AB = I. Why is BA = I? Since AB = I it follows B is one to
one since otherwise, there would exist, x ̸= 0 such that Bx = 0 and then ABx =
A0 = 0 ̸= Ix. Therefore, from what was just shown, B is also onto. In addition to
this, A must be one to one because if Ay = 0, then y = Bx for some x and then
x = ABx = Ay = 0 showing y = 0. Now from what is given to be so, it follows
(AB) A = A and so using the associative law for matrix multiplication,
A (BA) −A = A (BA −I) = 0.
But this means (BA −I) x = 0 for all x since otherwise, A would not be one to
one. Hence BA = I as claimed. This proves the theorem.
This theorem shows that if an n×n matrix, B acts like an inverse when multiplied
on one side of A it follows that B = A−1and it will act like an inverse on both sides
of A.
The conclusion of this theorem pertains to square matrices only. For example,
let
A =


1
0
0
1
1
0

, B =
µ
1
0
0
1
1
−1
¶
(4.13)
Then
BA =
µ
1
0
0
1
¶
but
AB =


1
0
0
1
1
−1
1
0
0

.

4.5.
THE MATHEMATICAL THEORY OF DETERMINANTS
61
4.5
The Mathematical Theory Of Determinants
It is assumed the reader is familiar with matrices. However, the topic of determi-
nants is often neglected in linear algebra books these days. Therefore, I will give a
fairly quick and grubby treatment of this topic which includes all the main results.
Two books which give a good introduction to determinants are Apostol [3] and
Rudin [44]. A recent book which also has a good introduction is Baker [7]
Let (i1, · · ·, in) be an ordered list of numbers from {1, · · ·, n} . This means the
order is important so (1, 2, 3) and (2, 1, 3) are diﬀerent.
The following Lemma will be essential in the deﬁnition of the determinant.
Lemma 4.18 There exists a unique function, sgnn which maps each list of n num-
bers from {1, · · ·, n} to one of the three numbers, 0, 1, or −1 which also has the
following properties.
sgnn (1, · · ·, n) = 1
(4.14)
sgnn (i1, · · ·, p, · · ·, q, · · ·, in) = −sgnn (i1, · · ·, q, · · ·, p, · · ·, in)
(4.15)
In words, the second property states that if two of the numbers are switched, the
value of the function is multiplied by −1. Also, in the case where n > 1 and
{i1, · · ·, in} = {1, · · ·, n} so that every number from {1, · · ·, n} appears in the ordered
list, (i1, · · ·, in) ,
sgnn (i1, · · ·, iθ−1, n, iθ+1, · · ·, in) ≡
(−1)n−θ sgnn−1 (i1, · · ·, iθ−1, iθ+1, · · ·, in)
(4.16)
where n = iθ in the ordered list, (i1, · · ·, in) .
Proof: To begin with, it is necessary to show the existence of such a func-
tion. This is clearly true if n = 1. Deﬁne sgn1 (1) ≡1 and observe that it works.
No switching is possible.
In the case where n = 2, it is also clearly true.
Let
sgn2 (1, 2) = 1 and sgn2 (2, 1) = 0 while sgn2 (2, 2) = sgn2 (1, 1) = 0 and verify it
works. Assuming such a function exists for n, sgnn+1 will be deﬁned in terms of
sgnn . If there are any repeated numbers in (i1, · · ·, in+1) , sgnn+1 (i1, · · ·, in+1) ≡0.
If there are no repeats, then n + 1 appears somewhere in the ordered list.
Let
θ be the position of the number n + 1 in the list. Thus, the list is of the form
(i1, · · ·, iθ−1, n + 1, iθ+1, · · ·, in+1) . From 4.16 it must be that
sgnn+1 (i1, · · ·, iθ−1, n + 1, iθ+1, · · ·, in+1) ≡
(−1)n+1−θ sgnn (i1, · · ·, iθ−1, iθ+1, · · ·, in+1) .
It is necessary to verify this satisﬁes 4.14 and 4.15 with n replaced with n + 1. The
ﬁrst of these is obviously true because
sgnn+1 (1, · · ·, n, n + 1) ≡(−1)n+1−(n+1) sgnn (1, · · ·, n) = 1.

62
SOME IMPORTANT LINEAR ALGEBRA
If there are repeated numbers in (i1, · · ·, in+1) , then it is obvious 4.15 holds because
both sides would equal zero from the above deﬁnition. It remains to verify 4.15 in
the case where there are no numbers repeated in (i1, · · ·, in+1) . Consider
sgnn+1
³
i1, · · ·,
rp, · · ·,
sq, · · ·, in+1
´
,
where the r above the p indicates the number, p is in the rth position and the s
above the q indicates that the number, q is in the sth position. Suppose ﬁrst that
r < θ < s. Then
sgnn+1
µ
i1, · · ·,
rp, · · ·,
θ
n + 1, · · ·,
sq, · · ·, in+1
¶
≡
(−1)n+1−θ sgnn
³
i1, · · ·,
rp, · · ·,
s−1
q , · · ·, in+1
´
while
sgnn+1
µ
i1, · · ·,
rq, · · ·,
θ
n + 1, · · ·,
sp, · · ·, in+1
¶
=
(−1)n+1−θ sgnn
³
i1, · · ·,
rq, · · ·,
s−1
p , · · ·, in+1
´
and so, by induction, a switch of p and q introduces a minus sign in the result.
Similarly, if θ > s or if θ < r it also follows that 4.15 holds. The interesting case
is when θ = r or θ = s. Consider the case where θ = r and note the other case is
entirely similar.
sgnn+1
³
i1, · · ·,
r
n + 1, · · ·,
sq, · · ·, in+1
´
=
(−1)n+1−r sgnn
³
i1, · · ·,
s−1
q , · · ·, in+1
´
(4.17)
while
sgnn+1
³
i1, · · ·,
rq, · · ·,
s
n + 1, · · ·, in+1
´
=
(−1)n+1−s sgnn
³
i1, · · ·,
rq, · · ·, in+1
´
.
(4.18)
By making s −1 −r switches, move the q which is in the s −1th position in 4.17 to
the rth position in 4.18. By induction, each of these switches introduces a factor of
−1 and so
sgnn
³
i1, · · ·,
s−1
q , · · ·, in+1
´
= (−1)s−1−r sgnn
³
i1, · · ·,
rq, · · ·, in+1
´
.
Therefore,
sgnn+1
³
i1, · · ·,
r
n + 1, · · ·,
sq, · · ·, in+1
´
=
(−1)n+1−r sgnn
³
i1, · · ·,
s−1
q , · · ·, in+1
´

4.5.
THE MATHEMATICAL THEORY OF DETERMINANTS
63
= (−1)n+1−r (−1)s−1−r sgnn
³
i1, · · ·,
rq, · · ·, in+1
´
=
(−1)n+s sgnn
³
i1, · · ·,
rq, · · ·, in+1
´
=
(−1)2s−1 (−1)n+1−s sgnn
³
i1, · · ·,
rq, · · ·, in+1
´
= −sgnn+1
³
i1, · · ·,
rq, · · ·,
s
n + 1, · · ·, in+1
´
.
This proves the existence of the desired function.
To see this function is unique, note that you can obtain any ordered list of
distinct numbers from a sequence of switches. If there exist two functions, f and
g both satisfying 4.14 and 4.15, you could start with f (1, · · ·, n) = g (1, · · ·, n)
and applying the same sequence of switches, eventually arrive at f (i1, · · ·, in) =
g (i1, · · ·, in) . If any numbers are repeated, then 4.15 gives both functions are equal
to zero for that ordered list. This proves the lemma.
In what follows sgn will often be used rather than sgnn because the context
supplies the appropriate n.
Deﬁnition 4.19 Let f be a real valued function which has the set of ordered lists
of numbers from {1, · · ·, n} as its domain. Deﬁne
X
(k1,···,kn)
f (k1 · · · kn)
to be the sum of all the
f (k1 · · · kn)
for all possible choices of ordered lists
(k1, · · ·, kn)
of numbers of
{1, · · ·, n} .
For example,
X
(k1,k2)
f (k1, k2) = f (1, 2) + f (2, 1) + f (1, 1) + f (2, 2) .
Deﬁnition 4.20 Let (aij) = A denote an n × n matrix. The determinant of A,
denoted by det (A) is deﬁned by
det (A) ≡
X
(k1,···,kn)
sgn (k1, · · ·, kn) a1k1 · · · ankn
where the sum is taken over all ordered lists of numbers from {1, · · ·, n}. Note it
suﬃces to take the sum over only those ordered lists in which there are no repeats
because if there are, sgn (k1, · · ·, kn) = 0 and so that term contributes 0 to the sum.

64
SOME IMPORTANT LINEAR ALGEBRA
Let A be an n × n matrix, A = (aij) and let (r1, · · ·, rn) denote an ordered list
of n numbers from {1, · · ·, n}. Let A (r1, · · ·, rn) denote the matrix whose kth row
is the rk row of the matrix, A. Thus
det (A (r1, · · ·, rn)) =
X
(k1,···,kn)
sgn (k1, · · ·, kn) ar1k1 · · · arnkn
(4.19)
and
A (1, · · ·, n) = A.
Proposition 4.21 Let
(r1, · · ·, rn)
be an ordered list of numbers from {1, · · ·, n}. Then
sgn (r1, · · ·, rn) det (A)
=
X
(k1,···,kn)
sgn (k1, · · ·, kn) ar1k1 · · · arnkn
(4.20)
=
det (A (r1, · · ·, rn)) .
(4.21)
Proof: Let (1, · · ·, n) = (1, · · ·, r, · · ·s, · · ·, n) so r < s.
det (A (1, · · ·, r, · · ·, s, · · ·, n)) =
(4.22)
X
(k1,···,kn)
sgn (k1, · · ·, kr, · · ·, ks, · · ·, kn) a1k1 · · · arkr · · · asks · · · ankn,
and renaming the variables, calling ks, kr and kr, ks, this equals
=
X
(k1,···,kn)
sgn (k1, · · ·, ks, · · ·, kr, · · ·, kn) a1k1 · · · arks · · · askr · · · ankn
=
X
(k1,···,kn)
−sgn

k1, · · ·,
These got switched
z
}|
{
kr, · · ·, ks
, · · ·, kn

a1k1 · · · askr · · · arks · · · ankn
= −det (A (1, · · ·, s, · · ·, r, · · ·, n)) .
(4.23)
Consequently,
det (A (1, · · ·, s, · · ·, r, · · ·, n)) =
−det (A (1, · · ·, r, · · ·, s, · · ·, n)) = −det (A)
Now letting A (1, · · ·, s, · · ·, r, · · ·, n) play the role of A, and continuing in this way,
switching pairs of numbers,
det (A (r1, · · ·, rn)) = (−1)p det (A)

4.5.
THE MATHEMATICAL THEORY OF DETERMINANTS
65
where it took p switches to obtain(r1, · · ·, rn) from (1, · · ·, n). By Lemma 4.18, this
implies
det (A (r1, · · ·, rn)) = (−1)p det (A) = sgn (r1, · · ·, rn) det (A)
and proves the proposition in the case when there are no repeated numbers in the
ordered list, (r1, · · ·, rn). However, if there is a repeat, say the rth row equals the
sth row, then the reasoning of 4.22 -4.23 shows that A (r1, · · ·, rn) = 0 and also
sgn (r1, · · ·, rn) = 0 so the formula holds in this case also.
Observation 4.22 There are n! ordered lists of distinct numbers from {1, · · ·, n} .
To see this, consider n slots placed in order. There are n choices for the ﬁrst
slot. For each of these choices, there are n −1 choices for the second. Thus there
are n (n −1) ways to ﬁll the ﬁrst two slots. Then for each of these ways there are
n −2 choices left for the third slot. Continuing this way, there are n! ordered lists
of distinct numbers from {1, · · ·, n} as stated in the observation.
With the above, it is possible to give a more symmetric description of the de-
terminant from which it will follow that det (A) = det
¡
AT ¢
.
Corollary 4.23 The following formula for det (A) is valid.
det (A) = 1
n!·
X
(r1,···,rn)
X
(k1,···,kn)
sgn (r1, · · ·, rn) sgn (k1, · · ·, kn) ar1k1 · · · arnkn.
(4.24)
And also det
¡
AT ¢
= det (A) where AT is the transpose of A.
(Recall that for
AT =
¡
aT
ij
¢
, aT
ij = aji.)
Proof: From Proposition 4.21, if the ri are distinct,
det (A) =
X
(k1,···,kn)
sgn (r1, · · ·, rn) sgn (k1, · · ·, kn) ar1k1 · · · arnkn.
Summing over all ordered lists, (r1, · · ·, rn) where the ri are distinct, (If the ri are
not distinct, sgn (r1, · · ·, rn) = 0 and so there is no contribution to the sum.)
n! det (A) =
X
(r1,···,rn)
X
(k1,···,kn)
sgn (r1, · · ·, rn) sgn (k1, · · ·, kn) ar1k1 · · · arnkn.
This proves the corollary since the formula gives the same number for A as it does
for AT .

66
SOME IMPORTANT LINEAR ALGEBRA
Corollary 4.24 If two rows or two columns in an n×n matrix, A, are switched, the
determinant of the resulting matrix equals (−1) times the determinant of the original
matrix. If A is an n × n matrix in which two rows are equal or two columns are
equal then det (A) = 0. Suppose the ith row of A equals (xa1 + yb1, · · ·, xan + ybn).
Then
det (A) = x det (A1) + y det (A2)
where the ith row of A1 is (a1, · · ·, an) and the ith row of A2 is (b1, · · ·, bn) , all
other rows of A1 and A2 coinciding with those of A. In other words, det is a linear
function of each row A. The same is true with the word “row” replaced with the
word “column”.
Proof: By Proposition 4.21 when two rows are switched, the determinant of the
resulting matrix is (−1) times the determinant of the original matrix. By Corollary
4.23 the same holds for columns because the columns of the matrix equal the rows
of the transposed matrix. Thus if A1 is the matrix obtained from A by switching
two columns,
det (A) = det
¡
AT ¢
= −det
¡
AT
1
¢
= −det (A1) .
If A has two equal columns or two equal rows, then switching them results in the
same matrix. Therefore, det (A) = −det (A) and so det (A) = 0.
It remains to verify the last assertion.
det (A) ≡
X
(k1,···,kn)
sgn (k1, · · ·, kn) a1k1 · · · (xaki + ybki) · · · ankn
= x
X
(k1,···,kn)
sgn (k1, · · ·, kn) a1k1 · · · aki · · · ankn
+y
X
(k1,···,kn)
sgn (k1, · · ·, kn) a1k1 · · · bki · · · ankn
≡x det (A1) + y det (A2) .
The same is true of columns because det
¡
AT ¢
= det (A) and the rows of AT are
the columns of A.
Deﬁnition 4.25 A vector, w, is a linear combination of the vectors {v1, · · ·, vr} if
there exists scalars, c1, · · ·cr such that w = Pr
k=1 ckvk. This is the same as saying
w ∈span {v1, · · ·, vr} .
The following corollary is also of great use.
Corollary 4.26 Suppose A is an n × n matrix and some column (row) is a linear
combination of r other columns (rows). Then det (A) = 0.

4.5.
THE MATHEMATICAL THEORY OF DETERMINANTS
67
Proof: Let A =
¡
a1
· · ·
an
¢
be the columns of A and suppose the condition
that one column is a linear combination of r of the others is satisﬁed. Then by using
Corollary 4.24 you may rearrange the columns to have the nth column a linear
combination of the ﬁrst r columns. Thus an = Pr
k=1 ckak and so
det (A) = det
¡
a1
· · ·
ar
· · ·
an−1
Pr
k=1 ckak
¢
.
By Corollary 4.24
det (A) =
r
X
k=1
ck det
¡
a1
· · ·
ar
· · ·
an−1
ak
¢
= 0.
The case for rows follows from the fact that det (A) = det
¡
AT ¢
. This proves the
corollary.
Recall the following deﬁnition of matrix multiplication.
Deﬁnition 4.27 If A and B are n × n matrices, A = (aij) and B = (bij), AB =
(cij) where
cij ≡
n
X
k=1
aikbkj.
One of the most important rules about determinants is that the determinant of
a product equals the product of the determinants.
Theorem 4.28 Let A and B be n × n matrices. Then
det (AB) = det (A) det (B) .
Proof: Let cij be the ijth entry of AB. Then by Proposition 4.21,
det (AB) =
X
(k1,···,kn)
sgn (k1, · · ·, kn) c1k1 · · · cnkn
=
X
(k1,···,kn)
sgn (k1, · · ·, kn)
ÃX
r1
a1r1br1k1
!
· · ·
ÃX
rn
anrnbrnkn
!
=
X
(r1···,rn)
X
(k1,···,kn)
sgn (k1, · · ·, kn) br1k1 · · · brnkn (a1r1 · · · anrn)
=
X
(r1···,rn)
sgn (r1 · · · rn) a1r1 · · · anrn det (B) = det (A) det (B) .
This proves the theorem.

68
SOME IMPORTANT LINEAR ALGEBRA
Lemma 4.29 Suppose a matrix is of the form
M =
µ A
∗
0
a
¶
(4.25)
or
M =
µ
A
0
∗
a
¶
(4.26)
where a is a number and A is an (n −1) × (n −1) matrix and ∗denotes either a
column or a row having length n −1 and the 0 denotes either a column or a row of
length n −1 consisting entirely of zeros. Then
det (M) = a det (A) .
Proof: Denote M by (mij) . Thus in the ﬁrst case, mnn = a and mni = 0 if
i ̸= n while in the second case, mnn = a and min = 0 if i ̸= n. From the deﬁnition
of the determinant,
det (M) ≡
X
(k1,···,kn)
sgnn (k1, · · ·, kn) m1k1 · · · mnkn
Letting θ denote the position of n in the ordered list, (k1, · · ·, kn) then using the
earlier conventions used to prove Lemma 4.18, det (M) equals
X
(k1,···,kn)
(−1)n−θ sgnn−1
µ
k1, · · ·, kθ−1,
θ
kθ+1, · · ·,
n−1
kn
¶
m1k1 · · · mnkn
Now suppose 4.26. Then if kn ̸= n, the term involving mnkn in the above expression
equals zero. Therefore, the only terms which survive are those for which θ = n or
in other words, those for which kn = n. Therefore, the above expression reduces to
a
X
(k1,···,kn−1)
sgnn−1 (k1, · · ·kn−1) m1k1 · · · m(n−1)kn−1 = a det (A) .
To get the assertion in the situation of 4.25 use Corollary 4.23 and 4.26 to write
det (M) = det
¡
M T ¢
= det
µµ
AT
0
∗
a
¶¶
= a det
¡
AT ¢
= a det (A) .
This proves the lemma.
In terms of the theory of determinants, arguably the most important idea is
that of Laplace expansion along a row or a column. This will follow from the above
deﬁnition of a determinant.
Deﬁnition 4.30 Let A = (aij) be an n × n matrix. Then a new matrix called
the cofactor matrix, cof (A) is deﬁned by cof (A) = (cij) where to obtain cij delete
the ith row and the jth column of A, take the determinant of the (n −1) × (n −1)
matrix which results, (This is called the ijth minor of A. ) and then multiply this
number by (−1)i+j. To make the formulas easier to remember, cof (A)ij will denote
the ijth entry of the cofactor matrix.

4.5.
THE MATHEMATICAL THEORY OF DETERMINANTS
69
The following is the main result. Earlier this was given as a deﬁnition and the
outrageous totally unjustiﬁed assertion was made that the same number would be
obtained by expanding the determinant along any row or column. The following
theorem proves this assertion.
Theorem 4.31 Let A be an n × n matrix where n ≥2. Then
det (A) =
n
X
j=1
aij cof (A)ij =
n
X
i=1
aij cof (A)ij .
(4.27)
The ﬁrst formula consists of expanding the determinant along the ith row and the
second expands the determinant along the jth column.
Proof: Let (ai1, · · ·, ain) be the ith row of A. Let Bj be the matrix obtained
from A by leaving every row the same except the ith row which in Bj equals
(0, · · ·, 0, aij, 0, · · ·, 0) . Then by Corollary 4.24,
det (A) =
n
X
j=1
det (Bj)
Denote by Aij the (n −1) × (n −1) matrix obtained by deleting the ith row and
the jth column of A. Thus cof (A)ij ≡(−1)i+j det
¡
Aij¢
. At this point, recall that
from Proposition 4.21, when two rows or two columns in a matrix, M, are switched,
this results in multiplying the determinant of the old matrix by −1 to get the
determinant of the new matrix. Therefore, by Lemma 4.29,
det (Bj)
=
(−1)n−j (−1)n−i det
µµ
Aij
∗
0
aij
¶¶
=
(−1)i+j det
µµ
Aij
∗
0
aij
¶¶
= aij cof (A)ij .
Therefore,
det (A) =
n
X
j=1
aij cof (A)ij
which is the formula for expanding det (A) along the ith row. Also,
det (A)
=
det
¡
AT ¢
=
n
X
j=1
aT
ij cof
¡
AT ¢
ij
=
n
X
j=1
aji cof (A)ji
which is the formula for expanding det (A) along the ith column. This proves the
theorem.
Note that this gives an easy way to write a formula for the inverse of an n × n
matrix.

70
SOME IMPORTANT LINEAR ALGEBRA
Theorem 4.32 A−1 exists if and only if det(A) ̸= 0. If det(A) ̸= 0, then A−1 =
¡
a−1
ij
¢
where
a−1
ij = det(A)−1 cof (A)ji
for cof (A)ij the ijth cofactor of A.
Proof: By Theorem 4.31 and letting (air) = A, if det (A) ̸= 0,
n
X
i=1
air cof (A)ir det(A)−1 = det(A) det(A)−1 = 1.
Now consider
n
X
i=1
air cof (A)ik det(A)−1
when k ̸= r. Replace the kth column with the rth column to obtain a matrix, Bk
whose determinant equals zero by Corollary 4.24. However, expanding this matrix
along the kth column yields
0 = det (Bk) det (A)−1 =
n
X
i=1
air cof (A)ik det (A)−1
Summarizing,
n
X
i=1
air cof (A)ik det (A)−1 = δrk.
Using the other formula in Theorem 4.31, and similar reasoning,
n
X
j=1
arj cof (A)kj det (A)−1 = δrk
This proves that if det (A) ̸= 0, then A−1 exists with A−1 =
¡
a−1
ij
¢
, where
a−1
ij = cof (A)ji det (A)−1 .
Now suppose A−1 exists. Then by Theorem 4.28,
1 = det (I) = det
¡
AA−1¢
= det (A) det
¡
A−1¢
so det (A) ̸= 0. This proves the theorem.
The next corollary points out that if an n × n matrix, A has a right or a left
inverse, then it has an inverse.
Corollary 4.33 Let A be an n×n matrix and suppose there exists an n×n matrix,
B such that BA = I. Then A−1 exists and A−1 = B. Also, if there exists C an
n × n matrix such that AC = I, then A−1 exists and A−1 = C.

4.5.
THE MATHEMATICAL THEORY OF DETERMINANTS
71
Proof: Since BA = I, Theorem 4.28 implies
det B det A = 1
and so det A ̸= 0. Therefore from Theorem 4.32, A−1 exists. Therefore,
A−1 = (BA) A−1 = B
¡
AA−1¢
= BI = B.
The case where CA = I is handled similarly.
The conclusion of this corollary is that left inverses, right inverses and inverses
are all the same in the context of n × n matrices.
Theorem 4.32 says that to ﬁnd the inverse, take the transpose of the cofactor
matrix and divide by the determinant.
The transpose of the cofactor matrix is
called the adjugate or sometimes the classical adjoint of the matrix A. It is an
abomination to call it the adjoint although you do sometimes see it referred to in
this way. In words, A−1 is equal to one over the determinant of A times the adjugate
matrix of A.
In case you are solving a system of equations, Ax = y for x, it follows that if
A−1 exists,
x =
¡
A−1A
¢
x = A−1 (Ax) = A−1y
thus solving the system. Now in the case that A−1 exists, there is a formula for
A−1 given above. Using this formula,
xi =
n
X
j=1
a−1
ij yj =
n
X
j=1
1
det (A) cof (A)ji yj.
By the formula for the expansion of a determinant along a column,
xi =
1
det (A) det



∗
· · ·
y1
· · ·
∗
...
...
...
∗
· · ·
yn
· · ·
∗


,
where here the ith column of A is replaced with the column vector, (y1 · · · ·, yn)T ,
and the determinant of this modiﬁed matrix is taken and divided by det (A). This
formula is known as Cramer’s rule.
Deﬁnition 4.34 A matrix M, is upper triangular if Mij = 0 whenever i > j. Thus
such a matrix equals zero below the main diagonal, the entries of the form Mii as
shown.






∗
∗
· · ·
∗
0
∗
...
...
...
...
...
∗
0
· · ·
0
∗






A lower triangular matrix is deﬁned similarly as a matrix for which all entries above
the main diagonal are equal to zero.

72
SOME IMPORTANT LINEAR ALGEBRA
With this deﬁnition, here is a simple corollary of Theorem 4.31.
Corollary 4.35 Let M be an upper (lower) triangular matrix. Then det (M) is
obtained by taking the product of the entries on the main diagonal.
Deﬁnition 4.36 A submatrix of a matrix A is the rectangular array of numbers
obtained by deleting some rows and columns of A. Let A be an m × n matrix. The
determinant rank of the matrix equals r where r is the largest number such that
some r × r submatrix of A has a non zero determinant. The row rank is deﬁned
to be the dimension of the span of the rows. The column rank is deﬁned to be the
dimension of the span of the columns.
Theorem 4.37 If A has determinant rank, r, then there exist r rows of the matrix
such that every other row is a linear combination of these r rows.
Proof: Suppose the determinant rank of A = (aij) equals r. If rows and columns
are interchanged, the determinant rank of the modiﬁed matrix is unchanged. Thus
rows and columns can be interchanged to produce an r × r matrix in the upper left
corner of the matrix which has non zero determinant. Now consider the r+1×r+1
matrix, M,





a11
· · ·
a1r
a1p
...
...
...
ar1
· · ·
arr
arp
al1
· · ·
alr
alp





where C will denote the r × r matrix in the upper left corner which has non zero
determinant. I claim det (M) = 0.
There are two cases to consider in verifying this claim. First, suppose p > r.
Then the claim follows from the assumption that A has determinant rank r. On the
other hand, if p < r, then the determinant is zero because there are two identical
columns. Expand the determinant along the last column and divide by det (C) to
obtain
alp = −
r
X
i=1
cof (M)ip
det (C) aip.
Now note that cof (M)ip does not depend on p. Therefore the above sum is of the
form
alp =
r
X
i=1
miaip
which shows the lth row is a linear combination of the ﬁrst r rows of A. Since l is
arbitrary, this proves the theorem.
Corollary 4.38 The determinant rank equals the row rank.

4.5.
THE MATHEMATICAL THEORY OF DETERMINANTS
73
Proof: From Theorem 4.37, the row rank is no larger than the determinant
rank. Could the row rank be smaller than the determinant rank? If so, there exist
p rows for p < r such that the span of these p rows equals the row space. But this
implies that the r × r submatrix whose determinant is nonzero also has row rank
no larger than p which is impossible if its determinant is to be nonzero because at
least one row is a linear combination of the others.
Corollary 4.39 If A has determinant rank, r, then there exist r columns of the
matrix such that every other column is a linear combination of these r columns.
Also the column rank equals the determinant rank.
Proof: This follows from the above by considering AT . The rows of AT are the
columns of A and the determinant rank of AT and A are the same. Therefore, from
Corollary 4.38, column rank of A = row rank of AT = determinant rank of AT =
determinant rank of A.
The following theorem is of fundamental importance and ties together many of
the ideas presented above.
Theorem 4.40 Let A be an n × n matrix. Then the following are equivalent.
1. det (A) = 0.
2. A, AT are not one to one.
3. A is not onto.
Proof: Suppose det (A) = 0.
Then the determinant rank of A = r < n.
Therefore, there exist r columns such that every other column is a linear com-
bination of these columns by Theorem 4.37.
In particular, it follows that for
some m, the mth column is a linear combination of all the others. Thus letting
A =
¡ a1
· · ·
am
· · ·
an
¢
where the columns are denoted by ai, there exists
scalars, αi such that
am =
X
k̸=m
αkak.
Now consider the column vector, x ≡
¡
α1
· · ·
−1
· · ·
αn
¢T . Then
Ax = −am +
X
k̸=m
αkak = 0.
Since also A0 = 0, it follows A is not one to one. Similarly, AT is not one to one
by the same argument applied to AT . This veriﬁes that 1.) implies 2.).
Now suppose 2.). Then since AT is not one to one, it follows there exists x ̸= 0
such that
AT x = 0.
Taking the transpose of both sides yields
xT A = 0

74
SOME IMPORTANT LINEAR ALGEBRA
where the 0 is a 1 × n matrix or row vector. Now if Ay = x, then
|x|2 = xT (Ay) =
¡
xT A
¢
y = 0y = 0
contrary to x ̸= 0. Consequently there can be no y such that Ay = x and so A is
not onto. This shows that 2.) implies 3.).
Finally, suppose 3.).
If 1.) does not hold, then det (A) ̸= 0 but then from
Theorem 4.32 A−1 exists and so for every y ∈Fn there exists a unique x ∈Fn such
that Ax = y. In fact x = A−1y. Thus A would be onto contrary to 3.). This shows
3.) implies 1.) and proves the theorem.
Corollary 4.41 Let A be an n × n matrix. Then the following are equivalent.
1. det(A) ̸= 0.
2. A and AT are one to one.
3. A is onto.
Proof: This follows immediately from the above theorem.
4.6
Exercises
1. Let m < n and let A be an m × n matrix. Show that A is not one to one.
Hint: Consider the n × n matrix, A1 which is of the form
A1 ≡
µ
A
0
¶
where the 0 denotes an (n −m) × n matrix of zeros. Thus det A1 = 0 and so
A1 is not one to one. Now observe that A1x is the vector,
A1x =
µ
Ax
0
¶
which equals zero if and only if Ax = 0.
4.7
The Cayley Hamilton Theorem
Deﬁnition 4.42 Let A be an n×n matrix. The characteristic polynomial is deﬁned
as
pA (t) ≡det (tI −A)
and the solutions to pA (t) = 0 are called eigenvalues. For A a matrix and p (t) =
tn + an−1tn−1 + · · · + a1t + a0, denote by p (A) the matrix deﬁned by
p (A) ≡An + an−1An−1 + · · · + a1A + a0I.
The explanation for the last term is that A0 is interpreted as I, the identity matrix.

4.7.
THE CAYLEY HAMILTON THEOREM
75
The Cayley Hamilton theorem states that every matrix satisﬁes its characteristic
equation, that equation deﬁned by PA (t) = 0. It is one of the most important
theorems in linear algebra. The following lemma will help with its proof.
Lemma 4.43 Suppose for all |λ| large enough,
A0 + A1λ + · · · + Amλm = 0,
where the Ai are n × n matrices. Then each Ai = 0.
Proof: Multiply by λ−m to obtain
A0λ−m + A1λ−m+1 + · · · + Am−1λ−1 + Am = 0.
Now let |λ| →∞to obtain Am = 0. With this, multiply by λ to obtain
A0λ−m+1 + A1λ−m+2 + · · · + Am−1 = 0.
Now let |λ| →∞to obtain Am−1 = 0. Continue multiplying by λ and letting
λ →∞to obtain that all the Ai = 0. This proves the lemma.
With the lemma, here is a simple corollary.
Corollary 4.44 Let Ai and Bi be n × n matrices and suppose
A0 + A1λ + · · · + Amλm = B0 + B1λ + · · · + Bmλm
for all |λ| large enough. Then Ai = Bi for all i. Consequently if λ is replaced by
any n × n matrix, the two sides will be equal. That is, for C any n × n matrix,
A0 + A1C + · · · + AmCm = B0 + B1C + · · · + BmCm.
Proof: Subtract and use the result of the lemma.
With this preparation, here is a relatively easy proof of the Cayley Hamilton
theorem.
Theorem 4.45 Let A be an n × n matrix and let p (λ) ≡det (λI −A) be the
characteristic polynomial. Then p (A) = 0.
Proof: Let C (λ) equal the transpose of the cofactor matrix of (λI −A) for |λ|
large. (If |λ| is large enough, then λ cannot be in the ﬁnite list of eigenvalues of A
and so for such λ, (λI −A)−1 exists.) Therefore, by Theorem 4.32
C (λ) = p (λ) (λI −A)−1 .
Note that each entry in C (λ) is a polynomial in λ having degree no more than n−1.
Therefore, collecting the terms,
C (λ) = C0 + C1λ + · · · + Cn−1λn−1

76
SOME IMPORTANT LINEAR ALGEBRA
for Cj some n × n matrix. It follows that for all |λ| large enough,
(A −λI)
¡
C0 + C1λ + · · · + Cn−1λn−1¢
= p (λ) I
and so Corollary 4.44 may be used. It follows the matrix coeﬃcients corresponding
to equal powers of λ are equal on both sides of this equation. Therefore, if λ is
replaced with A, the two sides will be equal. Thus
0 = (A −A)
¡
C0 + C1A + · · · + Cn−1An−1¢
= p (A) I = p (A) .
This proves the Cayley Hamilton theorem.
4.8
An Identity Of Cauchy
There is a very interesting identity for determinants due to Cauchy.
Theorem 4.46 The following identity holds.
Y
i,j
(ai + bj)
¯¯¯¯¯¯¯
1
a1+b1
· · ·
1
a1+bn
...
...
1
an+b1
· · ·
1
an+bn
¯¯¯¯¯¯¯
=
Y
j<i
(ai −aj) (bi −bj) .
(4.28)
Proof: What is the exponent of a2 on the right? It occurs in (a2 −a1) and in
(am −a2) for m > 2. Therefore, there are exactly n −1 factors which contain a2.
Therefore, a2 has an exponent of n −1. Similarly, each ak is raised to the n −1
power and the same holds for the bk as well. Therefore, the right side of 4.28 is of
the form
can−1
1
an−1
2
· · · an−1
n
bn−1
1
· · · bn−1
n
where c is some constant. Now consider the left side of 4.28.
This is of the form
1
n!
Y
i,j
(ai + bj)
X
i1···in,j1,···jn
sgn (i1 · · · in) sgn (j1 · · · jn) ·
1
ai1 + bj1
1
ai2 + bj2
· · ·
1
ain + bjn
.
For a given i1 · · · in, j1, · · ·jn, let
S (i1 · · · in, j1, · · ·jn) ≡{(i1, j1) , (i2, j2) · ··, (in, jn)} .
This equals
1
n!
X
i1···in,j1,···jn
sgn (i1 · · · in) sgn (j1 · · · jn)
Y
(i,j)/∈{(i1,j1),(i2,j2)···,(in,jn)}
(ai + bj)

4.9.
BLOCK MULTIPLICATION OF MATRICES
77
where you can assume the ik are all distinct and the jk are also all distinct because
otherwise sgn will produce a 0. Therefore, in
Y
(i,j)/∈{(i1,j1),(i2,j2)···,(in,jn)}
(ai + bj) ,
there are exactly n −1 factors which contain ak for each k and similarly, there are
exactly n −1 factors which contain bk for each k. Therefore, the left side of 4.28 is
of the form
dan−1
1
an−1
2
· · · an−1
n
bn−1
1
· · · bn−1
n
and it remains to verify that c = d. Using the properties of determinants, the left
side of 4.28 is of the form
Y
i̸=j
(ai + bj)
¯¯¯¯¯¯¯¯¯
1
a1+b1
a1+b2
· · ·
a1+b1
a1+bn
a2+b2
a2+b1
1
· · ·
a2+b2
a2+bn
...
...
...
...
an+bn
an+b1
an+bn
an+b2
· · ·
1
¯¯¯¯¯¯¯¯¯
Let ak →−bk. Then this converges to Q
i̸=j (−bi + bj) . The right side of 4.28
converges to
Y
j<i
(−bi + bj) (bi −bj) =
Y
i̸=j
(−bi + bj) .
Therefore, d = c and this proves the identity.
4.9
Block Multiplication Of Matrices
Suppose A is a matrix of the form



A11
· · ·
A1m
...
...
...
Ar1
· · ·
Arm



(4.29)
where Aij is a si ×pj matrix where si does not depend on j and pj does not depend
on i. Such a matrix is called a block matrix. Let n = P
j pj and k = P
i si so A
is an k × n matrix. What is Ax where x ∈Fn? From the process of multiplying a
matrix times a vector, the following lemma follows.
Lemma 4.47 Let A be an m × n block matrix as in 4.29 and let x ∈Fn. Then Ax
is of the form
Ax =



P
j A1jxj
...
P
j Arjxj



where x = (x1, · · ·, xm)T and xi ∈Fpi.

78
SOME IMPORTANT LINEAR ALGEBRA
Suppose also that B is a l × k block matrix of the form



B11
· · ·
B1p
...
...
...
Bm1
· · ·
Bmp



(4.30)
and that for all i, j, it makes sense to multiply BisAsj for all s ∈{1, · · ·, m}. (That
is the two matrices are conformable.) and that for each s, BisAsj is the same size
so that it makes sense to write P
s BisAsj.
Theorem 4.48 Let B be an l ×k block matrix as in 4.30 and let A be a k ×n block
matrix as in 4.29 such that Bis is conformable with Asj and each product, BisAsj
is of the same size so they can be added. Then BA is a l × n block matrix having
rp blocks such that the ijth block is of the form
X
s
BisAsj.
(4.31)
Proof: Let Bis be a qi ×ps matrix and Asj be a ps ×rj matrix. Also let x ∈Fn
and let x = (x1, · · ·, xm)T and xi ∈Fri so it makes sense to multiply Asjxj. Then
from the associative law of matrix multiplication and Lemma 4.47 applied twice,
(BA) x = B (Ax)
=



B11
· · ·
B1p
...
...
...
Bm1
· · ·
Bmp






P
j A1jxj
...
P
j Arjxj



=



P
s
P
j B1sAsjxj
...
P
s
P
j BmsAsjxj


=



P
j (P
s B1sAsj) xj
...
P
j (P
s BmsAsj) xj


.
By Lemma 4.47, this shows that (BA) x equals the block matrix whose ijth entry is
given by 4.31 times x. Since x is an arbitrary vector in Fn, this proves the theorem.
The message of this theorem is that you can formally multiply block matrices as
though the blocks were numbers. You just have to pay attention to the preservation
of order.
This simple idea of block multiplication turns out to be very useful later. For now
here is an interesting and signiﬁcant application. In this theorem, pM (t) denotes
the polynomial, det (tI −M) . Thus the zeros of this polynomial are the eigenvalues
of the matrix, M.
Theorem 4.49 Let A be an m×n matrix and let B be an n×m matrix for m ≤n.
Then
pBA (t) = tn−mpAB (t) ,
so the eigenvalues of BA and AB are the same including multiplicities except that
BA has n −m extra zero eigenvalues.

4.10.
EXERCISES
79
Proof: Use block multiplication to write
µ
AB
0
B
0
¶ µ
I
A
0
I
¶
=
µ
AB
ABA
B
BA
¶
µ
I
A
0
I
¶ µ
0
0
B
BA
¶
=
µ
AB
ABA
B
BA
¶
.
Therefore,
µ
I
A
0
I
¶−1 µ
AB
0
B
0
¶ µ
I
A
0
I
¶
=
µ
0
0
B
BA
¶
By Problem 11 of Page 80, it follows that
µ
0
0
B
BA
¶
and
µ
AB
0
B
0
¶
have the
same characteristic polynomials. Therefore, noting that BA is an n × n matrix and
AB is an m × m matrix,
tm det (tI −BA) = tn det (tI −AB)
and so det (tI −BA) = pBA (t) = tn−m det (tI −AB) = tn−mpAB (t) . This proves
the theorem.
4.10
Exercises
1. Show that matrix multiplication is associative. That is, (AB) C = A (BC) .
2. Show the inverse of a matrix, if it exists, is unique. Thus if AB = BA = I,
then B = A−1.
3. In the proof of Theorem 4.32 it was claimed that det (I) = 1. Here I = (δij) .
Prove this assertion. Also prove Corollary 4.35.
4. Let v1, ···, vn be vectors in Fn and let M (v1, · · ·, vn) denote the matrix whose
ith column equals vi. Deﬁne
d (v1, · · ·, vn) ≡det (M (v1, · · ·, vn)) .
Prove that d is linear in each variable, (multilinear), that
d (v1, · · ·, vi, · · ·, vj, · · ·, vn) = −d (v1, · · ·, vj, · · ·, vi, · · ·, vn) ,
(4.32)
and
d (e1, · · ·, en) = 1
(4.33)
where here ej is the vector in Fn which has a zero in every position except
the jth position in which it has a one.
5. Suppose f : Fn × · · · × Fn →F satisﬁes 4.32 and 4.33 and is linear in each
variable. Show that f = d.

80
SOME IMPORTANT LINEAR ALGEBRA
6. Show that if you replace a row (column) of an n×n matrix A with itself added
to some multiple of another row (column) then the new matrix has the same
determinant as the original one.
7. If A = (aij) , show det (A) = P
(k1,···,kn) sgn (k1, · · ·, kn) ak11 · · · aknn.
8. Use the result of Problem 6 to evaluate by hand the determinant
det




1
2
3
2
−6
3
2
3
5
2
2
3
3
4
6
4



.
9. Find the inverse if it exists of the matrix,


et
cos t
sin t
et
−sin t
cos t
et
−cos t
−sin t

.
10. Let Ly = y(n)+an−1 (x) y(n−1)+···+a1 (x) y′+a0 (x) y where the ai are given
continuous functions deﬁned on a closed interval, (a, b) and y is some function
which has n derivatives so it makes sense to write Ly. Suppose Lyk = 0 for
k = 1, 2, · · ·, n. The Wronskian of these functions, yi is deﬁned as
W (y1, · · ·, yn) (x) ≡det





y1 (x)
· · ·
yn (x)
y′
1 (x)
· · ·
y′
n (x)
...
...
y(n−1)
1
(x)
· · ·
y(n−1)
n
(x)





Show that for W (x) = W (y1, · · ·, yn) (x) to save space,
W ′ (x) = det





y1 (x)
· · ·
yn (x)
y′
1 (x)
· · ·
y′
n (x)
...
...
y(n)
1
(x)
· · ·
y(n)
n
(x)




.
Now use the diﬀerential equation, Ly = 0 which is satisﬁed by each of these
functions, yi and properties of determinants presented above to verify that
W ′ +an−1 (x) W = 0. Give an explicit solution of this linear diﬀerential equa-
tion, Abel’s formula, and use your answer to verify that the Wronskian of
these solutions to the equation, Ly = 0 either vanishes identically on (a, b) or
never.
11. Two n × n matrices, A and B, are similar if B = S−1AS for some invertible
n × n matrix, S. Show that if two matrices are similar, they have the same
characteristic polynomials.

4.11.
SHUR’S THEOREM
81
12. Suppose the characteristic polynomial of an n × n matrix, A is of the form
tn + an−1tn−1 + · · · + a1t + a0
and that a0 ̸= 0. Find a formula A−1 in terms of powers of the matrix, A.
Show that A−1 exists if and only if a0 ̸= 0.
13. In constitutive modeling of the stress and strain tensors, one sometimes con-
siders sums of the form P∞
k=0 akAk where A is a 3×3 matrix. Show using
the Cayley Hamilton theorem that if such a thing makes any sense, you can
always obtain it as a ﬁnite sum having no more than n terms.
4.11
Shur’s Theorem
Every matrix is related to an upper triangular matrix in a particularly signiﬁcant
way. This is Shur’s theorem and it is the most important theorem in the spectral
theory of matrices.
Lemma 4.50 Let
{x1, · · ·, xn}
be a basis for Fn. Then there exists an orthonormal basis for Fn,
{u1, · · ·, un}
which has the property that for each k ≤n,
span (x1, · · ·, xk) = span (u1, · · ·, uk) .
Proof: Let {x1, · · ·, xn} be a basis for Fn. Let u1 ≡x1/ |x1| . Thus for k = 1,
span (u1) = span (x1) and {u1} is an orthonormal set. Now suppose for some k < n,
u1, · · ·, uk have been chosen such that (uj · ul) = δjl and span (x1, · · ·, xk) =
span (u1, · · ·, uk). Then deﬁne
uk+1 ≡
xk+1 −Pk
j=1 (xk+1 · uj) uj
¯¯¯xk+1 −Pk
j=1 (xk+1 · uj) uj
¯¯¯
,
(4.34)
where the denominator is not equal to zero because the xj form a basis and so
xk+1 /∈span (x1, · · ·, xk) = span (u1, · · ·, uk)
Thus by induction,
uk+1 ∈span (u1, · · ·, uk, xk+1) = span (x1, · · ·, xk, xk+1) .
Also, xk+1 ∈span (u1, · · ·, uk, uk+1) which is seen easily by solving 4.34 for xk+1
and it follows
span (x1, · · ·, xk, xk+1) = span (u1, · · ·, uk, uk+1) .

82
SOME IMPORTANT LINEAR ALGEBRA
If l ≤k,
(uk+1 · ul)
=
C

(xk+1 · ul) −
k
X
j=1
(xk+1 · uj) (uj · ul)


=
C

(xk+1 · ul) −
k
X
j=1
(xk+1 · uj) δlj


=
C ((xk+1 · ul) −(xk+1 · ul)) = 0.
The vectors, {uj}n
j=1 , generated in this way are therefore an orthonormal basis
because each vector has unit length.
The process by which these vectors were generated is called the Gram Schmidt
process. Recall the following deﬁnition.
Deﬁnition 4.51 An n × n matrix, U, is unitary if UU ∗= I = U ∗U where U ∗is
deﬁned to be the transpose of the conjugate of U.
Theorem 4.52 Let A be an n × n matrix. Then there exists a unitary matrix, U
such that
U ∗AU = T,
(4.35)
where T is an upper triangular matrix having the eigenvalues of A on the main
diagonal listed according to multiplicity as roots of the characteristic equation.
Proof:
Let v1 be a unit eigenvector for A . Then there exists λ1 such that
Av1 = λ1v1, |v1| = 1.
Extend {v1} to a basis and then use Lemma 4.50 to obtain {v1, · · ·, vn}, an or-
thonormal basis in Fn. Let U0 be a matrix whose ith column is vi. Then from the
above, it follows U0 is unitary. Then U ∗
0 AU0 is of the form





λ1
∗
· · ·
∗
0
...
A1
0





where A1 is an n −1 × n −1 matrix. Repeat the process for the matrix, A1 above.
There exists a unitary matrix eU1 such that eU ∗
1 A1 eU1 is of the form





λ2
∗
· · ·
∗
0
...
A2
0




.

4.11.
SHUR’S THEOREM
83
Now let U1 be the n × n matrix of the form
µ 1
0
0
eU1
¶
.
This is also a unitary matrix because by block multiplication,
µ 1
0
0
eU1
¶∗µ 1
0
0
eU1
¶
=
µ 1
0
0
eU ∗
1
¶ µ 1
0
0
eU1
¶
=
µ 1
0
0
eU ∗
1 eU1
¶
=
µ
1
0
0
I
¶
Then using block multiplication, U ∗
1 U ∗
0 AU0U1 is of the form







λ1
∗
∗
· · ·
∗
0
λ2
∗
· · ·
∗
0
0
...
...
A2
0
0







where A2 is an n −2 × n −2 matrix. Continuing in this way, there exists a unitary
matrix, U given as the product of the Ui in the above construction such that
U ∗AU = T
where T is some upper triangular matrix. Since the matrix is upper triangular, the
characteristic equation is Qn
i=1 (λ −λi) where the λi are the diagonal entries of T.
Therefore, the λi are the eigenvalues.
What if A is a real matrix and you only want to consider real unitary matrices?
Theorem 4.53 Let A be a real n × n matrix. Then there exists a real unitary
matrix, Q and a matrix T of the form
T =



P1
· · ·
∗
...
...
0
Pr



(4.36)
where Pi equals either a real 1 × 1 matrix or Pi equals a real 2 × 2 matrix having
two complex eigenvalues of A such that QT AQ = T. The matrix, T is called the real
Schur form of the matrix A.
Proof: Suppose
Av1 = λ1v1, |v1| = 1
where λ1 is real. Then let {v1, · · ·, vn} be an orthonormal basis of vectors in Rn.
Let Q0 be a matrix whose ith column is vi. Then Q∗
0AQ0 is of the form





λ1
∗
· · ·
∗
0
...
A1
0






84
SOME IMPORTANT LINEAR ALGEBRA
where A1 is a real n −1 × n −1 matrix. This is just like the proof of Theorem 4.52
up to this point.
Now in case λ1 = α + iβ, it follows since A is real that v1 = z1 + iw1 and
that v1 = z1 −iw1 is an eigenvector for the eigenvalue, α −iβ. Here z1 and w1
are real vectors. It is clear that {z1, w1} is an independent set of vectors in Rn.
Indeed,{v1, v1} is an independent set and it follows span (v1, v1) = span (z1, w1) .
Now using the Gram Schmidt theorem in Rn, there exists {u1, u2} , an orthonormal
set of real vectors such that span (u1, u2) = span (v1, v1) . Now let {u1, u2, · · ·, un}
be an orthonormal basis in Rn and let Q0 be a unitary matrix whose ith column
is ui. Then Auj are both in span (u1, u2) for j = 1, 2 and so uT
k Auj = 0 whenever
k ≥3. It follows that Q∗
0AQ0 is of the form







∗
∗
· · ·
∗
∗
∗
0
...
A1
0







where A1 is now an n −2 × n −2 matrix. In this case, ﬁnd eQ1 an n −2 × n −2
matrix to put A1 in an appropriate form as above and come up with A2 either an
n −4 × n −4 matrix or an n −3 × n −3 matrix. Then the only other diﬀerence is
to let
Q1 =







1
0
0
· · ·
0
0
1
0
· · ·
0
0
0
...
...
eQ1
0
0







thus putting a 2 × 2 identity matrix in the upper left corner rather than a one.
Repeating this process with the above modiﬁcation for the case of a complex eigen-
value leads eventually to 4.36 where Q is the product of real unitary matrices Qi
above. Finally,
λI −T =



λI1 −P1
· · ·
∗
...
...
0
λIr −Pr



where Ik is the 2 × 2 identity matrix in the case that Pk is 2 × 2 and is the num-
ber 1 in the case where Pk is a 1 × 1 matrix. Now, it follows that det (λI −T) =
Qr
k=1 det (λIk −Pk) . Therefore, λ is an eigenvalue of T if and only if it is an eigen-
value of some Pk. This proves the theorem since the eigenvalues of T are the same
as those of A because they have the same characteristic polynomial due to the
similarity of A and T.
Deﬁnition 4.54 When a linear transformation, A, mapping a linear space, V to
V has a basis of eigenvectors, the linear transformation is called non defective.

4.11.
SHUR’S THEOREM
85
Otherwise it is called defective. An n×n matrix, A, is called normal if AA∗= A∗A.
An important class of normal matrices is that of the Hermitian or self adjoint
matrices. An n × n matrix, A is self adjoint or Hermitian if A = A∗.
The next lemma is the basis for concluding that every normal matrix is unitarily
similar to a diagonal matrix.
Lemma 4.55 If T is upper triangular and normal, then T is a diagonal matrix.
Proof: Since T is normal, T ∗T = TT ∗. Writing this in terms of components
and using the description of the adjoint as the transpose of the conjugate, yields
the following for the ikth entry of T ∗T = TT ∗.
X
j
tijt∗
jk =
X
j
tijtkj =
X
j
t∗
ijtjk =
X
j
tjitjk.
Now use the fact that T is upper triangular and let i = k = 1 to obtain the following
from the above.
X
j
|t1j|2 =
X
j
|tj1|2 = |t11|2
You see, tj1 = 0 unless j = 1 due to the assumption that T is upper triangular.
This shows T is of the form





∗
0
· · ·
0
0
∗
· · ·
∗
...
...
...
...
0
· · ·
0
∗




.
Now do the same thing only this time take i = k = 2 and use the result just
established. Thus, from the above,
X
j
|t2j|2 =
X
j
|tj2|2 = |t22|2 ,
showing that t2j = 0 if j > 2 which means T has the form







∗
0
0
· · ·
0
0
∗
0
· · ·
0
0
0
∗
· · ·
∗
...
...
...
...
...
0
0
0
0
∗







.
Next let i = k = 3 and obtain that T looks like a diagonal matrix in so far as the
ﬁrst 3 rows and columns are concerned. Continuing in this way it follows T is a
diagonal matrix.
Theorem 4.56 Let A be a normal matrix. Then there exists a unitary matrix, U
such that U ∗AU is a diagonal matrix.

86
SOME IMPORTANT LINEAR ALGEBRA
Proof: From Theorem 4.52 there exists a unitary matrix, U such that U ∗AU
equals an upper triangular matrix. The theorem is now proved if it is shown that
the property of being normal is preserved under unitary similarity transformations.
That is, verify that if A is normal and if B = U ∗AU, then B is also normal. But
this is easy.
B∗B
=
U ∗A∗UU ∗AU = U ∗A∗AU
=
U ∗AA∗U = U ∗AUU ∗A∗U = BB∗.
Therefore, U ∗AU is a normal and upper triangular matrix and by Lemma 4.55 it
must be a diagonal matrix. This proves the theorem.
Corollary 4.57 If A is Hermitian, then all the eigenvalues of A are real and there
exists an orthonormal basis of eigenvectors.
Proof: Since A is normal, there exists unitary, U such that U ∗AU = D, a
diagonal matrix whose diagonal entries are the eigenvalues of A. Therefore, D∗=
U ∗A∗U = U ∗AU = D showing D is real.
Finally, let
U =
¡
u1
u2
· · ·
un
¢
where the ui denote the columns of U and
D =



λ1
0
...
0
λn



The equation, U ∗AU = D implies
AU
=
¡
Au1
Au2
· · ·
Aun
¢
=
UD =
¡
λ1u1
λ2u2
· · ·
λnun
¢
where the entries denote the columns of AU and UD respectively. Therefore, Aui =
λiui and since the matrix is unitary, the ijth entry of U ∗U equals δij and so
δij = uT
i uj = uT
i uj = ui · uj.
This proves the corollary because it shows the vectors {ui} form an orthonormal
basis.
Corollary 4.58 If A is a real symmetric matrix, then A is Hermitian and there
exists a real unitary matrix, U such that U T AU = D where D is a diagonal matrix.
Proof: This follows from Theorem 4.53 and Corollary 4.57.

4.12.
THE RIGHT POLAR DECOMPOSITION
87
4.12
The Right Polar Decomposition
This is on the right polar decomposition.
Theorem 4.59 Let F be an m × n matrix where m ≥n. Then there exists an
m × n matrix R and a n × n matrix U such that
F = RU, U = U ∗,
all eigenvalues of U are non negative,
U 2 = F ∗F, R∗R = I,
and |Rx| = |x|.
Proof: (F ∗F)∗= F ∗F and so F ∗F is self adjoint. Also,
(F ∗Fx, x) = (Fx, Fx) ≥0.
Therefore, all eigenvalues of F ∗F must be nonnegative because if F ∗Fx = λx for
x ̸= 0,
0 ≤(Fx, Fx) = (F ∗Fx, x) = (λx, x) = λ |x|2 .
From linear algebra, there exists Q such that Q∗Q = I and F ∗F = Q∗DQ where
D is a diagonal matrix of the form



λ1
· · ·
0
...
...
...
0
· · ·
λn



where each λi ≥0. Therefore, you can consider
D1/2 ≡



λ1/2
1
· · ·
0
...
...
...
0
· · ·
λ1/2
n


≡












µ1
· · ·
· · ·
· · ·
· · ·
0
0
...
v
...
µr
...
...
0
...
...
...
...
0
· · ·
· · ·
· · ·
· · ·
0












(4.37)
where the µi are the positive eigenvalues of D1/2.
Let U ≡Q∗D1/2Q. This matrix is the square root of F ∗F because
³
Q∗D1/2Q
´ ³
Q∗D1/2Q
´
= Q∗D1/2D1/2Q = Q∗DQ = F ∗F
It is self adjoint because
¡
Q∗D1/2Q
¢∗= Q∗D1/2Q∗∗= Q∗D1/2Q.

88
SOME IMPORTANT LINEAR ALGEBRA
Let {x1, · · ·, xr} be an orthogonal set of eigenvectors such that Uxi = µixi and
normalize so that
{µ1x1, · · ·, µrxr} = {Ux1, · · ·, Uxr}
is an orthonormal set of vectors. By 4.37 it follows rank (U) = r and so
{Ux1, · · ·, Uxr}
is also an orthonormal basis for U (Fn).
Then {Fxr, · · ·, Fxr} is also an orthonormal set of vectors in Fm because
(Fxi, Fxj) = (F ∗Fxi, xj) =
¡
U 2xi, xj
¢
= (Uxi, Uxj) = δij.
Let
{Ux1, · · ·, Uxr, yr+1, · · ·, yn}
be an orthonormal basis for Fn and let
{Fxr, · · ·, Fxr, zr+1, · · ·, zn, · · ·, zm}
be an orthonormal basis for Fm. Then a typical vector of Fn is of the form
r
X
k=1
akUxk +
n
X
j=r+1
bjyj.
Deﬁne
R


r
X
k=1
akUxk +
n
X
j=r+1
bjyj

≡
r
X
k=1
akFxk +
n
X
j=r+1
bjzj
Then since
{Ux1, · · ·, Uxr, yr+1, · · ·, yn}
and
{Fxr, · · ·, Fxr, zr+1, · · ·, zn, · · ·, zm}
are orthonormal,
¯¯¯¯¯¯
R


r
X
k=1
akUxk +
n
X
j=r+1
bjyj


¯¯¯¯¯¯
2
=
¯¯¯¯¯¯
r
X
k=1
akFxk +
n
X
j=r+1
bjzj
¯¯¯¯¯¯
2
=
r
X
k=1
|ak|2 +
n
X
j=r+1
|bj|2
=
¯¯¯¯¯¯
r
X
k=1
akUxk +
n
X
j=r+1
bjyj
¯¯¯¯¯¯
2
.
Therefore, R preserves distances.

4.12.
THE RIGHT POLAR DECOMPOSITION
89
Letting x ∈Fn,
Ux =
r
X
k=1
akUxk
(4.38)
for some unique choice of scalars, ak because {Ux1, · · ·, Uxr} is a basis for U (Fn).
Therefore,
RUx = R
Ã r
X
k=1
akUxk
!
≡
r
X
k=1
akFxk = F
Ã r
X
k=1
akxk
!
.
Is F (Pr
k=1 akxk) = F (x)? Using 4.38,
F ∗F
Ã r
X
k=1
akxk −x
!
=
U 2
Ã r
X
k=1
akxk −x
!
=
r
X
k=1
akµ2
kxk −U (Ux)
=
r
X
k=1
akµ2
kxk −U
Ã r
X
k=1
akUxk
!
=
r
X
k=1
akµ2
kxk −U
Ã r
X
k=1
akµkxk
!
= 0.
Therefore,
¯¯¯¯¯F
Ã r
X
k=1
akxk −x
!¯¯¯¯¯
2
=
Ã
F
Ã r
X
k=1
akxk −x
!
, F
Ã r
X
k=1
akxk −x
!!
=
Ã
F ∗F
Ã r
X
k=1
akxk −x
!
,
Ã r
X
k=1
akxk −x
!!
= 0
and so F (Pr
k=1 akxk) = F (x) as hoped. Thus RU = F on Fn.
Since R preserves distances,
|x|2 + |y|2 + 2 (x, y) = |x + y|2 = |R (x + y)|2
= |x|2 + |y|2 + 2 (Rx,Ry).
Therefore,
(x, y) = (R∗Rx, y)
for all x, y and so R∗R = I as claimed. This proves the theorem.

90
SOME IMPORTANT LINEAR ALGEBRA

Multi-variable Calculus
5.1
Continuous Functions
In what follows, F will denote either R or C. It turns out it is more eﬃcient to not
make a distinction. However, the main interest is in R so if you like, you can think
R whenever you see F.
5.1.1
Distance In Fn
It is necessary to give a generalization of the dot product for vectors in Cn. This
deﬁnition reduces to the usual one in the case the components of the vector are real.
Deﬁnition 5.1 Let x, y ∈Cn. Thus x = (x1, · · ·, xn) where each xk ∈C and a
similar formula holding for y. Then the dot product of these two vectors is deﬁned
to be
x · y ≡
X
j
xjyj ≡x1y1 + · · · + xnyn.
Notice how you put the conjugate on the entries of the vector, y. It makes no
diﬀerence if the vectors happen to be real vectors but with complex vectors you
must do it this way. The reason for this is that when you take the dot product of a
vector with itself, you want to get the square of the length of the vector, a positive
number.
Placing the conjugate on the components of y in the above deﬁnition
assures this will take place. Thus
x · x =
X
j
xjxj =
X
j
|xj|2 ≥0.
If you didn’t place a conjugate as in the above deﬁnition, things wouldn’t work out
correctly. For example,
(1 + i)2 + 22 = 4 + 2i
and this is not a positive number.
The following properties of the dot product follow immediately from the deﬁni-
tion and you should verify each of them.
Properties of the dot product:
91

92
MULTI-VARIABLE CALCULUS
1. u · v = v · u.
2. If a, b are numbers and u, v, z are vectors then (au + bv) · z = a (u · z) +
b (v · z) .
3. u · u ≥0 and it equals 0 if and only if u = 0.
The norm is deﬁned in the usual way.
Deﬁnition 5.2 For x ∈Cn,
|x| ≡
Ã n
X
k=1
|xk|2
!1/2
= (x · x)1/2
Here is a fundamental inequality called the Cauchy Schwarz inequality which
is stated here in Cn. First here is a simple lemma.
Lemma 5.3 If z ∈C there exists θ ∈C such that θz = |z| and |θ| = 1.
Proof: Let θ = 1 if z = 0 and otherwise, let θ =
z
|z|. Recall that for z =
x + iy, z = x −iy and zz = |z|2.
Theorem 5.4 (Cauchy Schwarz)The following inequality holds for xi and yi ∈C.
|(x · y)| =
¯¯¯¯¯
n
X
i=1
xiyi
¯¯¯¯¯ ≤
Ã n
X
i=1
|xi|2
!1/2 Ã n
X
i=1
|yi|2
!1/2
= |x| |y|
(5.1)
Proof: Let θ ∈C such that |θ| = 1 and
θ
n
X
i=1
xiyi =
¯¯¯¯¯
n
X
i=1
xiyi
¯¯¯¯¯
Thus
θ
n
X
i=1
xiyi =
n
X
i=1
xi
¡
θyi
¢
=
¯¯¯¯¯
n
X
i=1
xiyi
¯¯¯¯¯ .
Consider p (t) ≡Pn
i=1
¡
xi + tθyi
¢ ³
xi + tθyi
´
where t ∈R.
0
≤
p (t) =
n
X
i=1
|xi|2 + 2t Re
Ã
θ
n
X
i=1
xiyi
!
+ t2
n
X
i=1
|yi|2
=
|x|2 + 2t
¯¯¯¯¯
n
X
i=1
xiyi
¯¯¯¯¯ + t2 |y|2

5.1.
CONTINUOUS FUNCTIONS
93
If |y| = 0 then 5.1 is obviously true because both sides equal zero.
Therefore,
assume |y| ̸= 0 and then p (t) is a polynomial of degree two whose graph opens
up. Therefore, it either has no zeroes, two zeros or one repeated zero. If it has two
zeros, the above inequality must be violated because in this case the graph must
dip below the x axis. Therefore, it either has no zeros or exactly one. From the
quadratic formula this happens exactly when
4
¯¯¯¯¯
n
X
i=1
xiyi
¯¯¯¯¯
2
−4 |x|2 |y|2 ≤0
and so
¯¯¯¯¯
n
X
i=1
xiyi
¯¯¯¯¯ ≤|x| |y|
as claimed. This proves the inequality.
By analogy to the case of Rn, length or magnitude of vectors in Cn can be
deﬁned.
Deﬁnition 5.5 Let z ∈Cn. Then |z| ≡(z · z)1/2. Also numbers in F will often be
referred to as scalars.
Theorem 5.6 For length deﬁned in Deﬁnition 5.5, the following hold.
|z| ≥0 and |z| = 0 if and only if z = 0
(5.2)
If α is a scalar, |αz| = |α| |z|
(5.3)
|z + w| ≤|z| + |w| .
(5.4)
Proof: The ﬁrst two claims are left as exercises. To establish the third,
|z + w|2
=
(z + w, z + w)
=
z · z + w · w + w · z + z · w
=
|z|2 + |w|2 + 2 Re w · z
≤
|z|2 + |w|2 + 2 |w · z|
≤
|z|2 + |w|2 + 2 |w| |z| = (|z| + |w|)2 .
The main diﬀerence between Cn and Rn is that the scalars are complex numbers.
Deﬁnition 5.7 Suppose you have a vector space, V and for z, w ∈V and α a scalar
a norm is a way of measuring distance or magnitude which satisﬁes the properties
5.2 - 5.4. Thus a norm is something which does the following.
||z|| ≥0 and ||z|| = 0 if and only if z = 0
(5.5)
If α is a scalar, ||αz|| = |α| ||z||
(5.6)
||z + w|| ≤||z|| + ||w|| .
(5.7)
Here is is understood that for all z ∈V, ||z|| ∈[0, ∞).
Note that |·| provides a norm on Fn from the above.

94
MULTI-VARIABLE CALCULUS
5.2
Open And Closed Sets
Eventually, one must consider functions which are deﬁned on subsets of Fn and
their properties. The next deﬁnition will end up being quite important. It describe
a type of subset of Fn with the property that if x is in this set, then so is y whenever
y is close enough to x.
Deﬁnition 5.8 Let U ⊆Fn. U is an open set if whenever x ∈U, there exists
r > 0 such that B (x, r) ⊆U. More generally, if U is any subset of Fn, x ∈U is
an interior point of U if there exists r > 0 such that x ∈B (x, r) ⊆U. In other
words U is an open set exactly when every point of U is an interior point of U.
If there is something called an open set, surely there should be something called
a closed set and here is the deﬁnition of one.
Deﬁnition 5.9 A subset, C, of Fn is called a closed set if Fn \ C is an open set.
They symbol, Fn \ C denotes everything in Fn which is not in C. It is also called
the complement of C. The symbol, SC is a short way of writing Fn \ S.
To illustrate this deﬁnition, consider the following picture.
qx
U
B(x, r)
You see in this picture how the edges are dotted. This is because an open set,
can not include the edges or the set would fail to be open. For example, consider
what would happen if you picked a point out on the edge of U in the above picture.
Every open ball centered at that point would have in it some points which are
outside U. Therefore, such a point would violate the above deﬁnition. You also see
the edges of B (x, r) dotted suggesting that B (x, r) ought to be an open set. This
is intuitively clear but does require a proof. This will be done in the next theorem
and will give examples of open sets. Also, you can see that if x is close to the edge
of U, you might have to take r to be very small.
It is roughly the case that open sets don’t have their skins while closed sets do.
Here is a picture of a closed set, C.

5.2.
OPEN AND CLOSED SETS
95
B(x, r)
x
q
C
Note that x /∈C and since Fn \ C is open, there exists a ball, B (x, r) contained
entirely in Fn \ C. If you look at Fn \ C, what would be its skin? It can’t be in
Fn \C and so it must be in C. This is a rough heuristic explanation of what is going
on with these deﬁnitions. Also note that Fn and ∅are both open and closed. Here
is why. If x ∈∅, then there must be a ball centered at x which is also contained in
∅. This must be considered to be true because there is nothing in ∅so there can be
no example to show it false1. Therefore, from the deﬁnition, it follows ∅is open.
It is also closed because if x /∈∅, then B (x, 1) is also contained in Fn \ ∅= Fn.
Therefore, ∅is both open and closed. From this, it follows Fn is also both open and
closed.
Theorem 5.10 Let x ∈Fn and let r ≥0. Then B (x, r) is an open set. Also,
D (x, r) ≡{y ∈Fn : |y −x| ≤r}
is a closed set.
Proof: Suppose y ∈B (x,r) . It is necessary to show there exists r1 > 0 such
that B (y, r1) ⊆B (x, r) . Deﬁne r1 ≡r −|x −y| . Then if |z −y| < r1, it follows
from the above triangle inequality that
|z −x|
=
|z −y + y −x|
≤
|z −y| + |y −x|
<
r1 + |y −x| = r −|x −y| + |y −x| = r.
Note that if r = 0 then B (x, r) = ∅, the empty set. This is because if y ∈Fn,
|x −y| ≥0 and so y /∈B (x, 0) . Since ∅has no points in it, it must be open because
1To a mathematician, the statment: Whenever a pig is born with wings it can ﬂy must be taken
as true. We do not consider biological or aerodynamic considerations in such statements. There
is no such thing as a winged pig and therefore, all winged pigs must be superb ﬂyers since there
can be no example of one which is not. On the other hand we would also consider the statement:
Whenever a pig is born with wings it can’t possibly ﬂy, as equally true. The point is, you can say
anything you want about the elements of the empty set and no one can gainsay your statement.
Therefore, such statements are considered as true by default. You may say this is a very strange
way of thinking about truth and ultimately this is because mathematics is not about truth. It is
more about consistency and logic.

96
MULTI-VARIABLE CALCULUS
every point in it, (There are none.) satisﬁes the desired property of being an interior
point.
Now suppose y /∈D (x, r) . Then |x −y| > r and deﬁning δ ≡|x −y| −r, it
follows that if z ∈B (y, δ) , then by the triangle inequality,
|x −z|
≥
|x −y| −|y −z| > |x −y| −δ
=
|x −y| −(|x −y| −r) = r
and this shows that B (y, δ) ⊆Fn \ D (x, r) . Since y was an arbitrary point in
Fn \ D (x, r) , it follows Fn \ D (x, r) is an open set which shows from the deﬁnition
that D (x, r) is a closed set as claimed.
A picture which is descriptive of the conclusion of the above theorem which also
implies the manner of proof is the following.
y
x
q
q
6
-
r
r1
B(x, r)
y
x
q
q
6
-
r
r1
D(x, r)
5.3
Continuous Functions
With the above deﬁnition of the norm in Fp, it becomes possible to deﬁne continuity.
Deﬁnition 5.11 A function f : D (f) ⊆Fp →Fq is continuous at x ∈D (f) if for
each ε > 0 there exists δ > 0 such that whenever y ∈D (f) and
|y −x| < δ
it follows that
|f (x) −f (y)| < ε.
f is continuous if it is continuous at every point of D (f) .
Note the total similarity to the scalar valued case.
5.3.1
Suﬃcient Conditions For Continuity
The next theorem is a fundamental result which will allow us to worry less about
the ε δ deﬁnition of continuity.
Theorem 5.12 The following assertions are valid.
1. The function, af + bg is continuous at x whenever f, g are continuous at x
∈D (f) ∩D (g) and a, b ∈F.

5.4.
EXERCISES
97
2. If f is continuous at x, f (x) ∈D (g) ⊆Fp, and g is continuous at f (x) ,then
g ◦f is continuous at x.
3. If f = (f1, · · ·, fq) : D (f) →Fq, then f is continuous if and only if each fk is
a continuous F valued function.
4. The function f : Fp →F, given by f (x) = |x| is continuous.
The proof of this theorem is in the last section of this chapter. Its conclusions
are not surprising. For example the ﬁrst claim says that (af + bg) (y) is close to
(af + bg) (x) when y is close to x provided the same can be said about f and g.
For the second claim, if y is close to x, f (x) is close to f (y) and so by continuity
of g at f (x), g (f (y)) is close to g (f (x)) . To see the third claim is likely, note that
closeness in Fp is the same as closeness in each coordinate. The fourth claim is
immediate from the triangle inequality.
For functions deﬁned on Fn, there is a notion of polynomial just as there is for
functions deﬁned on R.
Deﬁnition 5.13 Let α be an n dimensional multi-index. This means
α = (α1, · · ·, αn)
where each αi is a natural number or zero. Also, let
|α| ≡
n
X
i=1
|αi|
The symbol, xα,means
xα ≡xα1
1 xα2
2 · · · xαn
3 .
An n dimensional polynomial of degree m is a function of the form
p (x) =
X
|α|≤m
dαxα.
where the dα are complex or real numbers.
The above theorem implies that polynomials are all continuous.
5.4
Exercises
1. Let f (t) = (t, sin t) . Show f is continuous at every point t.
2. Suppose |f (x) −f (y)| ≤K |x −y| where K is a constant. Show that f is
everywhere continuous.
Functions satisfying such an inequality are called
Lipschitz functions.
3. Suppose |f (x) −f (y)| ≤K |x −y|α where K is a constant and α ∈(0, 1).
Show that f is everywhere continuous.

98
MULTI-VARIABLE CALCULUS
4. Suppose f : F3 →F is given by f (x) = 3x1x2 + 2x2
3. Use Theorem 5.12 to
verify that f is continuous. Hint: You should ﬁrst verify that the function,
πk : F3 →F given by πk (x) = xk is a continuous function.
5. Generalize the previous problem to the case where f : Fq →F is a polynomial.
6. State and prove a theorem which involves quotients of functions encountered
in the previous problem.
5.5
Limits Of A Function
As in the case of scalar valued functions of one variable, a concept closely related to
continuity is that of the limit of a function. The notion of limit of a function makes
sense at points, x, which are limit points of D (f) and this concept is deﬁned next.
Deﬁnition 5.14 Let A ⊆Fm be a set. A point, x, is a limit point of A if B (x, r)
contains inﬁnitely many points of A for every r > 0.
Deﬁnition 5.15 Let f : D (f) ⊆Fp →Fq be a function and let x be a limit point
of D (f) . Then
lim
y→x f (y) = L
if and only if the following condition holds. For all ε > 0 there exists δ > 0 such
that if
0 < |y −x| < δ, and y ∈D (f)
then,
|L −f (y)| < ε.
Theorem 5.16 If limy→x f (y) = L and limy→x f (y) = L1, then L = L1.
Proof: Let ε > 0 be given. There exists δ > 0 such that if 0 < |y −x| < δ and
y ∈D (f) , then
|f (y) −L| < ε, |f (y) −L1| < ε.
Pick such a y. There exists one because x is a limit point of D (f) . Then
|L −L1| ≤|L −f (y)| + |f (y) −L1| < ε + ε = 2ε.
Since ε > 0 was arbitrary, this shows L = L1.
As in the case of functions of one variable, one can deﬁne what it means for
limy→x f (x) = ±∞.
Deﬁnition 5.17 If f (x) ∈F, limy→x f (x) = ∞if for every number l, there exists
δ > 0 such that whenever |y −x| < δ and y ∈D (f) , then f (x) > l.
The following theorem is just like the one variable version presented earlier.

5.5.
LIMITS OF A FUNCTION
99
Theorem 5.18 Suppose limy→x f (y) = L and limy→x g (y) = K where K, L ∈Fq.
Then if a, b ∈F,
lim
y→x (af (y) + bg (y)) = aL + bK,
(5.8)
lim
y→x f · g (y) = LK
(5.9)
and if g is scalar valued with limy→x g (y) = K ̸= 0,
lim
y→x f (y) g (y) = LK.
(5.10)
Also, if h is a continuous function deﬁned near L, then
lim
y→x h ◦f (y) = h (L) .
(5.11)
Suppose limy→x f (y) = L. If |f (y) −b| ≤r for all y suﬃciently close to x, then
|L −b| ≤r also.
Proof: The proof of 5.8 is left for you. It is like a corresponding theorem for
continuous functions. Now 5.9is to be veriﬁed. Let ε > 0 be given. Then by the
triangle inequality,
|f · g (y) −L · K| ≤|fg (y) −f (y) · K| + |f (y) · K −L · K|
≤|f (y)| |g (y) −K| + |K| |f (y) −L| .
There exists δ1 such that if 0 < |y −x| < δ1 and y ∈D (f) , then
|f (y) −L| < 1,
and so for such y, the triangle inequality implies, |f (y)| < 1 + |L| . Therefore, for
0 < |y −x| < δ1,
|f · g (y) −L · K| ≤(1 + |K| + |L|) [|g (y) −K| + |f (y) −L|] .
(5.12)
Now let 0 < δ2 be such that if y ∈D (f) and 0 < |x −y| < δ2,
|f (y) −L| <
ε
2 (1 + |K| + |L|), |g (y) −K| <
ε
2 (1 + |K| + |L|).
Then letting 0 < δ ≤min (δ1, δ2) , it follows from 5.12 that
|f · g (y) −L · K| < ε
and this proves 5.9.
The proof of 5.10 is left to you.
Consider 5.11. Since h is continuous near L, it follows that for ε > 0 given,
there exists η > 0 such that if |y −L| < η, then
|h (y) −h (L)| < ε

100
MULTI-VARIABLE CALCULUS
Now since limy→x f (y) = L, there exists δ > 0 such that if 0 < |y −x| < δ, then
|f (y) −L| < η.
Therefore, if 0 < |y −x| < δ,
|h (f (y)) −h (L)| < ε.
It only remains to verify the last assertion. Assume |f (y) −b| ≤r for all y
close enough to x. It is required to show that |L −b| ≤r. If this is not true, then
|L −b| > r. Consider B (L, |L −b| −r) . Since L is the limit of f, it follows f (y) ∈
B (L, |L −b| −r) whenever y ∈D (f) is close enough to x. Thus, by the triangle
inequality,
|f (y) −L| < |L −b| −r
and so
r
<
|L −b| −|f (y) −L| ≤||b −L| −|f (y) −L||
≤
|b −f (y)| ,
a contradiction to the assumption that |b −f (y)| ≤r.
Theorem 5.19 For f : D (f) →Fq and x ∈D (f) a limit point of D (f) , f is
continuous at x if and only if
lim
y→x f (y) = f (x) .
Proof: First suppose f is continuous at x a limit point of D (f) . Then for
every ε > 0 there exists δ > 0 such that if |y −x| < δ and y ∈D (f) , then
|f (x) −f (y)| < ε. In particular, this holds if 0 < |x −y| < δ and this is just the
deﬁnition of the limit. Hence f (x) = limy→x f (y) .
Next suppose x is a limit point of D (f) and limy→x f (y) = f (x) . This means
that if ε > 0 there exists δ > 0 such that for 0 < |x −y| < δ and y ∈D (f) , it follows
|f (y) −f (x)| < ε. However, if y = x, then |f (y) −f (x)| = |f (x) −f (x)| = 0 and
so whenever y ∈D (f) and |x −y| < δ, it follows |f (x) −f (y)| < ε, showing f is
continuous at x.
The following theorem is important.
Theorem 5.20 Suppose f : D (f) →Fq. Then for x a limit point of D (f) ,
lim
y→x f (y) = L
(5.13)
if and only if
lim
y→x fk (y) = Lk
(5.14)
where f (y) ≡(f1 (y) , · · ·, fp (y)) and L ≡(L1, · · ·, Lp) .

5.5.
LIMITS OF A FUNCTION
101
Proof: Suppose 5.13. Then letting ε > 0 be given there exists δ > 0 such that
if 0 < |y −x| < δ, it follows
|fk (y) −Lk| ≤|f (y) −L| < ε
which veriﬁes 5.14.
Now suppose 5.14 holds. Then letting ε > 0 be given, there exists δk such that
if 0 < |y −x| < δk, then
|fk (y) −Lk| <
ε
√p.
Let 0 < δ < min (δ1, · · ·, δp) . Then if 0 < |y −x| < δ, it follows
|f (y) −L|
=
Ã p
X
k=1
|fk (y) −Lk|2
!1/2
<
Ã p
X
k=1
ε2
p
!1/2
= ε.
This proves the theorem.
This theorem shows it suﬃces to consider the components of a vector valued
function when computing the limit.
Example 5.21 Find lim(x,y)→(3,1)
³
x2−9
x−3 , y
´
.
It is clear that lim(x,y)→(3,1)
x2−9
x−3 = 6 and lim(x,y)→(3,1) y = 1. Therefore, this
limit equals (6, 1) .
Example 5.22 Find lim(x,y)→(0,0)
xy
x2+y2 .
First of all observe the domain of the function is F2 \ {(0, 0)} , every point in F2
except the origin. Therefore, (0, 0) is a limit point of the domain of the function
so it might make sense to take a limit. However, just as in the case of a function
of one variable, the limit may not exist. In fact, this is the case here. To see this,
take points on the line y = 0. At these points, the value of the function equals 0.
Now consider points on the line y = x where the value of the function equals 1/2.
Since arbitrarily close to (0, 0) there are points where the function equals 1/2 and
points where the function has the value 0, it follows there can be no limit. Just
take ε = 1/10 for example. You can’t be within 1/10 of 1/2 and also within 1/10
of 0 at the same time.
Note it is necessary to rely on the deﬁnition of the limit much more than in the
case of a function of one variable and it is the case there are no easy ways to do
limit problems for functions of more than one variable. It is what it is and you will
not deal with these concepts without agony.

102
MULTI-VARIABLE CALCULUS
5.6
Exercises
1. Find the following limits if possible
(a) lim(x,y)→(0,0)
x2−y2
x2+y2
(b) lim(x,y)→(0,0)
x(x2−y2)
(x2+y2)
(c) lim(x,y)→(0,0) (x2−y4)
2
(x2+y4)2 Hint: Consider along y = 0 and along x = y2.
(d) lim(x,y)→(0,0) x sin
³
1
x2+y2
´
(e) The limit as (x, y) →(1, 2) of the expression
−2yx2 + 8yx + 34y + 3y3 −18y2 + 6x2 −13x −20 −xy2 −x3
−y2 + 4y −5 −x2 + 2x
.
Hint: It might help to write this in terms of the variables (s, t) =
(x −1, y −2) .
2. In the deﬁnition of limit, why must x be a limit point of D (f)? Hint: If x
were not a limit point of D (f), show there exists δ > 0 such that B (x, δ)
contains no points of D (f) other than possibly x itself. Argue that 33.3 is a
limit and that so is 22 and 7 and 11. In other words the concept is totally
worthless.
5.7
The Limit Of A Sequence
As in the case of real numbers, one can consider the limit of a sequence of points
in Fp.
Deﬁnition 5.23 A sequence {an}∞
n=1 converges to a, and write
lim
n→∞an = a or an →a
if and only if for every ε > 0 there exists nε such that whenever n ≥nε ,
|an−a| < ε.
In words the deﬁnition says that given any measure of closeness, ε, the terms
of the sequence are eventually all this close to a. There is absolutely no diﬀerence
between this and the deﬁnition for sequences of numbers other than here bold face
is used to indicate an and a are points in Fp.
Theorem 5.24 If limn→∞an = a and limn→∞an = a1 then a1 = a.

5.7.
THE LIMIT OF A SEQUENCE
103
Proof: Suppose a1 ̸= a. Then let 0 < ε < |a1−a| /2 in the deﬁnition of the limit.
It follows there exists nε such that if n ≥nε, then |an−a| < ε and |an−a1| < ε.
Therefore, for such n,
|a1−a|
≤
|a1−an| + |an−a|
<
ε + ε < |a1−a| /2 + |a1−a| /2 = |a1−a| ,
a contradiction.
As in the case of a vector valued function, it suﬃces to consider the components.
This is the content of the next theorem.
Theorem 5.25 Let an =
¡
an
1, · · ·, an
p
¢
∈Fp. Then limn→∞an = a ≡(a1, · · ·, ap)
if and only if for each k = 1, · · ·, p,
lim
n→∞an
k = ak.
(5.15)
Proof: First suppose limn→∞an = a. Then given ε > 0 there exists nε such
that if n > nε, then
|an
k −ak| ≤|an −a| < ε
which establishes 5.15.
Now suppose 5.15 holds for each k. Then letting ε > 0 be given there exist nk
such that if n > nk,
|an
k −ak| < ε/√p.
Therefore, letting nε > max (n1, · · ·, np) , it follows that for n > nε,
|an −a| =
Ã n
X
k=1
|an
k −ak|2
!1/2
<
Ã n
X
k=1
ε2
p
!1/2
= ε,
showing that limn→∞an = a. This proves the theorem.
Example 5.26 Let an =
³
1
n2+1, 1
n sin (n) ,
n2+3
3n2+5n
´
.
It suﬃces to consider the limits of the components according to the following
theorem. Thus the limit is (0, 0, 1/3) .
Theorem 5.27 Suppose {an} and {bn} are sequences and that
lim
n→∞an = a and lim
n→∞bn = b.
Also suppose x and y are numbers in F. Then
lim
n→∞xan + ybn = xa + yb
(5.16)
lim
n→∞an · bn = a · b
(5.17)
If bn ∈F, then
anbn →ab.

104
MULTI-VARIABLE CALCULUS
Proof: The ﬁrst of these claims is left for you to do. To do the second, let ε > 0
be given and choose n1 such that if n ≥n1 then
|an−a| < 1.
Then for such n, the triangle inequality and Cauchy Schwarz inequality imply
|an · bn−a · b|
≤
|an · bn−an · b| + |an · b −a · b|
≤
|an| |bn−b| + |b| |an−a|
≤
(|a| + 1) |bn−b| + |b| |an−a| .
Now let n2 be large enough that for n ≥n2,
|bn−b| <
ε
2 (|a| + 1), and |an−a| <
ε
2 (|b| + 1).
Such a number exists because of the deﬁnition of limit. Therefore, let
nε > max (n1, n2) .
For n ≥nε,
|an · bn−a · b|
≤
(|a| + 1) |bn−b| + |b| |an−a|
<
(|a| + 1)
ε
2 (|a| + 1) + |b|
ε
2 (|b| + 1) ≤ε.
This proves 5.16. The proof of 5.17 is entirely similar and is left for you.
5.7.1
Sequences And Completeness
Recall the deﬁnition of a Cauchy sequence.
Deﬁnition 5.28 {an} is a Cauchy sequence if for all ε > 0, there exists nε such
that whenever n, m ≥nε,
|an−am| < ε.
A sequence is Cauchy means the terms are “bunching up to each other” as m, n
get large.
Theorem 5.29 Let {an}∞
n=1 be a Cauchy sequence in Fp. Then there exists a
unique a ∈Fp such that an →a.
Proof: Let an =
¡
an
1, · · ·, an
p
¢
. Then
|an
k −am
k | ≤|an −am|
which shows for each k = 1, · · ·, p, it follows {an
k}∞
n=1 is a Cauchy sequence in F.
This requires that both the real and imaginary parts of an
k are Cauchy sequences
in R which means the real and imaginary parts converge in R. This shows {an
k}∞
n=1

5.7.
THE LIMIT OF A SEQUENCE
105
must converge to some ak. That is limn→∞an
k = ak. Letting a = (a1, · · ·, ap) , it
follows from Theorem 5.25 that
lim
n→∞an = a.
This proves the theorem.
Theorem 5.30 The set of terms in a Cauchy sequence in Fp is bounded in the
sense that for all n, |an| < M for some M < ∞.
Proof: Let ε = 1 in the deﬁnition of a Cauchy sequence and let n > n1. Then
from the deﬁnition,
|an−an1| < 1.
It follows that for all n > n1,
|an| < 1 + |an1| .
Therefore, for all n,
|an| ≤1 + |an1| +
n1
X
k=1
|ak| .
This proves the theorem.
Theorem 5.31 If a sequence {an} in Fp converges, then the sequence is a Cauchy
sequence.
Proof: Let ε > 0 be given and suppose an→a. Then from the deﬁnition of
convergence, there exists nε such that if n > nε, it follows that
|an−a| < ε
2
Therefore, if m, n ≥nε + 1, it follows that
|an−am| ≤|an−a| + |a −am| < ε
2 + ε
2 = ε
showing that, since ε > 0 is arbitrary, {an} is a Cauchy sequence.
5.7.2
Continuity And The Limit Of A Sequence
Just as in the case of a function of one variable, there is a very useful way of thinking
of continuity in terms of limits of sequences found in the following theorem. In
words, it says a function is continuous if it takes convergent sequences to convergent
sequences whenever possible.
Theorem 5.32 A function f : D (f) →Fq is continuous at x ∈D (f) if and only
if, whenever xn→x with xn ∈D (f) , it follows f (xn) →f (x) .

106
MULTI-VARIABLE CALCULUS
Proof: Suppose ﬁrst that f is continuous at x and let xn→x. Let ε > 0 be given.
By continuity, there exists δ > 0 such that if |y −x| < δ, then |f (x) −f (y)| < ε.
However, there exists nδ such that if n ≥nδ, then |xn−x| < δ and so for all n this
large,
|f (x) −f (xn)| < ε
which shows f (xn) →f (x) .
Now suppose the condition about taking convergent sequences to convergent
sequences holds at x. Suppose f fails to be continuous at x. Then there exists ε > 0
and xn ∈D (f) such that |x −xn| < 1
n , yet
|f (x) −f (xn)| ≥ε.
But this is clearly a contradiction because, although xn→x, f (xn) fails to converge
to f (x) . It follows f must be continuous after all. This proves the theorem.
5.8
Properties Of Continuous Functions
Functions of p variables have many of the same properties as functions of one
variable. First there is a version of the extreme value theorem generalizing the one
dimensional case.
Theorem 5.33 Let C be closed and bounded and let f : C →R be continuous.
Then f achieves its maximum and its minimum on C. This means there exist,
x1, x2 ∈C such that for all x ∈C,
f (x1) ≤f (x) ≤f (x2) .
There is also the long technical theorem about sums and products of continuous
functions. These theorems are proved in the next section.
Theorem 5.34 The following assertions are valid
1. The function, af + bg is continuous at x when f, g are continuous at x ∈
D (f) ∩D (g) and a, b ∈F.
2. If and f and g are each F valued functions continuous at x, then
fg is
continuous at x. If, in addition to this, g (x) ̸= 0, then f/g is continuous at
x.
3. If f is continuous at x, f (x) ∈D (g) ⊆Fp, and g is continuous at f (x) ,then
g ◦f is continuous at x.
4. If f = (f1, · · ·, fq) : D (f) →Fq, then f is continuous if and only if each fk is
a continuous F valued function.
5. The function f : Fp →F, given by f (x) = |x| is continuous.

5.9.
EXERCISES
107
5.9
Exercises
1. f : D ⊆Fp →Fq is Lipschitz continuous or just Lipschitz for short if there
exists a constant, K such that
|f (x) −f (y)| ≤K |x −y|
for all x, y ∈D. Show every Lipschitz function is uniformly continuous which
means that given ε > 0 there exists δ > 0 independent of x such that if
|x −y| < δ, then |f (x) −f (y)| < ε.
2. If f is uniformly continuous, does it follow that |f| is also uniformly continu-
ous? If |f| is uniformly continuous does it follow that f is uniformly continu-
ous? Answer the same questions with “uniformly continuous” replaced with
“continuous”. Explain why.
5.10
Proofs Of Theorems
This section contains the proofs of the theorems which were just stated without
proof.
Theorem 5.35 The following assertions are valid
1. The function, af + bg is continuous at x when f, g are continuous at x ∈
D (f) ∩D (g) and a, b ∈F.
2. If and f and g are each F valued functions continuous at x, then
fg is
continuous at x. If, in addition to this, g (x) ̸= 0, then f/g is continuous at
x.
3. If f is continuous at x, f (x) ∈D (g) ⊆Fp, and g is continuous at f (x) ,then
g ◦f is continuous at x.
4. If f = (f1, · · ·, fq) : D (f) →Fq, then f is continuous if and only if each fk is
a continuous F valued function.
5. The function f : Fp →F, given by f (x) = |x| is continuous.
Proof: Begin with 1.) Let ε > 0 be given. By assumption, there exist δ1 > 0
such that whenever |x −y| < δ1, it follows |f (x) −f (y)| <
ε
2(|a|+|b|+1) and there
exists δ2 > 0 such that whenever |x −y| < δ2, it follows that |g (x) −g (y)| <
ε
2(|a|+|b|+1). Then let 0 < δ ≤min (δ1, δ2) . If |x −y| < δ, then everything happens
at once. Therefore, using the triangle inequality
|af (x) + bf (x) −(ag (y) + bg (y))|

108
MULTI-VARIABLE CALCULUS
≤|a| |f (x) −f (y)| + |b| |g (x) −g (y)|
< |a|
µ
ε
2 (|a| + |b| + 1)
¶
+ |b|
µ
ε
2 (|a| + |b| + 1)
¶
< ε.
Now begin on 2.) There exists δ1 > 0 such that if |y −x| < δ1, then
|f (x) −f (y)| < 1.
Therefore, for such y,
|f (y)| < 1 + |f (x)| .
It follows that for such y,
|fg (x) −fg (y)| ≤|f (x) g (x) −g (x) f (y)| + |g (x) f (y) −f (y) g (y)|
≤|g (x)| |f (x) −f (y)| + |f (y)| |g (x) −g (y)|
≤(1 + |g (x)| + |f (y)|) [|g (x) −g (y)| + |f (x) −f (y)|] .
Now let ε > 0 be given. There exists δ2 such that if |x −y| < δ2, then
|g (x) −g (y)| <
ε
2 (1 + |g (x)| + |f (y)|),
and there exists δ3 such that if |x −y| < δ3, then
|f (x) −f (y)| <
ε
2 (1 + |g (x)| + |f (y)|)
Now let 0 < δ ≤min (δ1, δ2, δ3) . Then if |x −y| < δ, all the above hold at once and
|fg (x) −fg (y)| ≤
(1 + |g (x)| + |f (y)|) [|g (x) −g (y)| + |f (x) −f (y)|]
< (1 + |g (x)| + |f (y)|)
µ
ε
2 (1 + |g (x)| + |f (y)|) +
ε
2 (1 + |g (x)| + |f (y)|)
¶
= ε.
This proves the ﬁrst part of 2.) To obtain the second part, let δ1 be as described
above and let δ0 > 0 be such that for |x −y| < δ0,
|g (x) −g (y)| < |g (x)| /2
and so by the triangle inequality,
−|g (x)| /2 ≤|g (y)| −|g (x)| ≤|g (x)| /2
which implies |g (y)| ≥|g (x)| /2, and |g (y)| < 3 |g (x)| /2.

5.10.
PROOFS OF THEOREMS
109
Then if |x −y| < min (δ0, δ1) ,
¯¯¯¯
f (x)
g (x) −f (y)
g (y)
¯¯¯¯ =
¯¯¯¯
f (x) g (y) −f (y) g (x)
g (x) g (y)
¯¯¯¯
≤|f (x) g (y) −f (y) g (x)|
³
|g(x)|2
2
´
= 2 |f (x) g (y) −f (y) g (x)|
|g (x)|2
≤
2
|g (x)|2 [|f (x) g (y) −f (y) g (y) + f (y) g (y) −f (y) g (x)|]
≤
2
|g (x)|2 [|g (y)| |f (x) −f (y)| + |f (y)| |g (y) −g (x)|]
≤
2
|g (x)|2
·3
2 |g (x)| |f (x) −f (y)| + (1 + |f (x)|) |g (y) −g (x)|
¸
≤
2
|g (x)|2 (1 + 2 |f (x)| + 2 |g (x)|) [|f (x) −f (y)| + |g (y) −g (x)|]
≡M [|f (x) −f (y)| + |g (y) −g (x)|]
where
M ≡
2
|g (x)|2 (1 + 2 |f (x)| + 2 |g (x)|)
Now let δ2 be such that if |x −y| < δ2, then
|f (x) −f (y)| < ε
2M −1
and let δ3 be such that if |x −y| < δ3, then
|g (y) −g (x)| < ε
2M −1.
Then if 0 < δ ≤min (δ0, δ1, δ2, δ3) , and |x −y| < δ, everything holds and
¯¯¯¯
f (x)
g (x) −f (y)
g (y)
¯¯¯¯ ≤M [|f (x) −f (y)| + |g (y) −g (x)|]
< M
hε
2M −1 + ε
2M −1i
= ε.
This completes the proof of the second part of 2.) Note that in these proofs no
eﬀort is made to ﬁnd some sort of “best” δ. The problem is one which has a yes or
a no answer. Either it is or it is not continuous.
Now begin on 3.). If f is continuous at x, f (x) ∈D (g) ⊆Fp, and g is continuous
at f (x) ,then g ◦f is continuous at x. Let ε > 0 be given. Then there exists η > 0

110
MULTI-VARIABLE CALCULUS
such that if |y −f (x)| < η and y ∈D (g) , it follows that |g (y) −g (f (x))| < ε. It
follows from continuity of f at x that there exists δ > 0 such that if |x −z| < δ and
z ∈D (f) , then |f (z) −f (x)| < η. Then if |x −z| < δ and z ∈D (g ◦f) ⊆D (f) ,
all the above hold and so
|g (f (z)) −g (f (x))| < ε.
This proves part 3.)
Part 4.) says: If f = (f1, · · ·, fq) : D (f) →Fq, then f is continuous if and only
if each fk is a continuous F valued function. Then
|fk (x) −fk (y)| ≤|f (x) −f (y)|
≡
Ã q
X
i=1
|fi (x) −fi (y)|2
!1/2
≤
q
X
i=1
|fi (x) −fi (y)| .
(5.18)
Suppose ﬁrst that f is continuous at x. Then there exists δ > 0 such that if |x −y| <
δ, then |f (x) −f (y)| < ε. The ﬁrst part of the above inequality then shows that for
each k = 1, · · ·, q, |fk (x) −fk (y)| < ε. This shows the only if part. Now suppose
each function, fk is continuous. Then if ε > 0 is given, there exists δk > 0 such
that whenever |x −y| < δk
|fk (x) −fk (y)| < ε/q.
Now let 0 < δ ≤min (δ1, · · ·, δq) . For |x −y| < δ, the above inequality holds for all
k and so the last part of 5.18 implies
|f (x) −f (y)| ≤
q
X
i=1
|fi (x) −fi (y)|
<
q
X
i=1
ε
q = ε.
This proves part 4.)
To verify part 5.), let ε > 0 be given and let δ = ε. Then if |x −y| < δ, the
triangle inequality implies
|f (x) −f (y)| = ||x| −|y||
≤|x −y| < δ = ε.
This proves part 5.) and completes the proof of the theorem.
Here is a multidimensional version of the nested interval lemma.
The following deﬁnition is similar to that given earlier. It deﬁnes what is meant
by a sequentially compact set in Fp.

5.10.
PROOFS OF THEOREMS
111
Deﬁnition 5.36 A set, K ⊆Fp is sequentially compact if and only if whenever
{xn}∞
n=1 is a sequence of points in K, there exists a point, x ∈K and a subsequence,
{xnk}∞
k=1 such that xnk →x.
It turns out the sequentially compact sets in Fpare exactly those which are closed
and bounded. Only half of this result will be needed in this book and this is proved
next. First note that C can be considered as R2. Therefore, Cp may be considered
as R2p.
Theorem 5.37 Let C ⊆Fp be closed and bounded. Then C is sequentially compact.
Proof: Let {an} ⊆C.
Then let an =
¡
an
1, · · ·, an
p
¢
. It follows the real and
imaginary parts of the terms of the sequence,
©
an
j
ª∞
n=1 are each contained in some
suﬃciently large closed bounded interval. By Theorem 2.3 on Page 25, there is a
subsequence of the sequence of real parts of
©
an
j
ª∞
n=1 which converges. Also there
is a further subsequence of the imaginary parts of
©
an
j
ª∞
n=1 which converges. Thus
there is a subsequence, nk with the property that ank
j
converges to a point, aj ∈F.
Taking further subsequences, one obtains the existence of a subsequence, still called
nk such that for each r = 1, · · ·, p, ank
r
converges to a point, ar ∈F as k →∞.
Therefore, letting a ≡(a1, · · ·, ap) , limk→∞ank = a. Since C is closed, it follows
a ∈C. This proves the theorem.
Here is a proof of the extreme value theorem.
Theorem 5.38 Let C be closed and bounded and let f : C →R be continuous.
Then f achieves its maximum and its minimum on C. This means there exist,
x1, x2 ∈C such that for all x ∈C,
f (x1) ≤f (x) ≤f (x2) .
Proof: Let M = sup {f (x) : x ∈C} . Recall this means +∞if f is not bounded
above and it equals the least upper bound of these values of f if f is bounded above.
Then there exists a sequence, {xn} such that f (xn) →M. Since C is sequentially
compact, there exists a subsequence, xnk, and a point, x ∈C such that xnk →x.
But then since f is continuous at x, it follows from Theorem 5.32 on Page 105
that f (x) = limk→∞f (xnk) = M. This proves f achieves its maximum and also
shows its maximum is less than ∞. Let x2 = x. The case of a minimum is handled
similarly.
Recall that a function is uniformly continuous if the following deﬁnition holds.
Deﬁnition 5.39 Let f : D (f) →Fq. Then f is uniformly continuous if for every
ε > 0 there exists δ > 0 such that whenever |x −y| < δ, it follows |f (x) −f (y)| < ε.
Theorem 5.40 Let f :C →Fq be continuous where C is a closed and bounded set
in Fp. Then f is uniformly continuous on C.
Proof: If this is not so, there exists ε > 0 and pairs of points, xn and yn satisfy-
ing |xn −yn| < 1/n but |f (xn) −f (yn)| ≥ε. Since C is sequentially compact, there

112
MULTI-VARIABLE CALCULUS
exists x ∈C and a subsequence, {xnk} satisfying xnk →x. But |xnk −ynk| < 1/k
and so ynk →x also. Therefore, from Theorem 5.32 on Page 105,
ε ≤lim
k→∞|f (xnk) −f (ynk)| = |f (x) −f (x)| = 0,
a contradiction. This proves the theorem.
5.11
The Space L (Fn, Fm)
Deﬁnition 5.41 The symbol, L (Fn, Fm) will denote the set of linear transforma-
tions mapping Fn to Fm. Thus L ∈L (Fn, Fm) means that for α, β scalars and x, y
vectors in Fn,
L (αx + βy) = αL (x) + βL (y) .
It is convenient to give a norm for the elements of L (Fn, Fm) . This will allow
the consideration of questions such as whether a function having values in this space
of linear transformations is continuous.
5.11.1
The Operator Norm
How do you measure the distance between linear transformations deﬁned on Fn? It
turns out there are many ways to do this but I will give the most common one here.
Deﬁnition 5.42 L (Fn, Fm) denotes the space of linear transformations mapping
Fn to Fm. For A ∈L (Fn, Fm) , the operator norm is deﬁned by
||A|| ≡max {|Ax|Fm : |x|Fn ≤1} < ∞.
Theorem 5.43 Denote by |·| the norm on either Fn or Fm. Then L (Fn, Fm) with
this operator norm is a complete normed linear space of dimension nm with
||Ax|| ≤||A|| |x| .
Here Completeness means that every Cauchy sequence converges.
Proof: It is necessary to show the norm deﬁned on L (Fn, Fm) really is a norm.
This means it is necessary to verify
||A|| ≥0 and equals zero if and only if A = 0.
For α a scalar,
||αA|| = |α| ||A|| ,
and for A, B ∈L (Fn, Fm) ,
||A + B|| ≤||A|| + ||B||

5.11.
THE SPACE L
¡
FN, FM¢
113
The ﬁrst two properties are obvious but you should verify them. It remains to verify
the norm is well deﬁned and also to verify the triangle inequality above. First if
|x| ≤1, and (Aij) is the matrix of the linear transformation with respect to the
usual basis vectors, then
||A||
=
max



ÃX
i
|(Ax)i|2
!1/2
: |x| ≤1



=
max










X
i
¯¯¯¯¯¯
X
j
Aijxj
¯¯¯¯¯¯
2


1/2
: |x| ≤1







which is a ﬁnite number by the extreme value theorem.
It is clear that a basis for L (Fn, Fm) consists of linear transformations whose
matrices are of the form Eij where Eij consists of the m×n matrix having all zeros
except for a 1 in the ijth position. In eﬀect, this considers L (Fn, Fm) as Fnm. Think
of the m × n matrix as a long vector folded up.
If x ̸= 0,
|Ax| 1
|x| =
¯¯¯¯A x
|x|
¯¯¯¯ ≤||A||
(5.19)
It only remains to verify completeness. Suppose then that {Ak} is a Cauchy
sequence in L (Fn, Fm) . Then from 5.19 {Akx} is a Cauchy sequence for each x ∈Fn.
This follows because
|Akx −Alx| ≤||Ak −Al|| |x|
which converges to 0 as k, l →∞. Therefore, by completeness of Fm, there exists
Ax, the name of the thing to which the sequence, {Akx} converges such that
lim
k→∞Akx = Ax.
Then A is linear because
A (ax + by)
≡
lim
k→∞Ak (ax + by)
=
lim
k→∞(aAkx + bAky)
=
a lim
k→∞Akx + b lim
k→∞Aky
=
aAx + bAy.
By the ﬁrst part of this argument, ||A|| < ∞and so A ∈L (Fn, Fm) . This proves
the theorem.
Proposition 5.44 Let A (x) ∈L (Fn, Fm) for each x ∈U ⊆Fp. Then letting
(Aij (x)) denote the matrix of A (x) with respect to the standard basis, it follows
Aij is continuous at x for each i, j if and only if for all ε > 0, there exists a δ > 0
such that if |x −y| < δ, then ||A (x) −A (y)|| < ε. That is, A is a continuous
function having values in L (Fn, Fm) at x.

114
MULTI-VARIABLE CALCULUS
Proof: Suppose ﬁrst the second condition holds. Then from the material on
linear transformations,
|Aij (x) −Aij (y)|
=
|ei · (A (x) −A (y)) ej|
≤
|ei| |(A (x) −A (y)) ej|
≤
||A (x) −A (y)|| .
Therefore, the second condition implies the ﬁrst.
Now suppose the ﬁrst condition holds. That is each Aij is continuous at x. Let
|v| ≤1.
|(A (x) −A (y)) (v)|
=



X
i
¯¯¯¯¯¯
X
j
(Aij (x) −Aij (y)) vj
¯¯¯¯¯¯
2


1/2
(5.20)
≤



X
i

X
j
|Aij (x) −Aij (y)| |vj|


2


1/2
.
By continuity of each Aij, there exists a δ > 0 such that for each i, j
|Aij (x) −Aij (y)| <
ε
n√m
whenever |x −y| < δ. Then from 5.20, if |x −y| < δ,
|(A (x) −A (y)) (v)|
<



X
i

X
j
ε
n√m |v|


2


1/2
≤



X
i

X
j
ε
n√m


2


1/2
= ε
This proves the proposition.
5.12
The Frechet Derivative
Let U be an open set in Fn, and let f : U →Fm be a function.
Deﬁnition 5.45 A function g is o (v) if
lim
|v|→0
g (v)
|v|
= 0
(5.21)

5.12.
THE FRECHET DERIVATIVE
115
A function f : U →Fm is diﬀerentiable at x ∈U if there exists a linear transfor-
mation L ∈L (Fn, Fm) such that
f (x + v) = f (x) + Lv + o (v)
This linear transformation L is the deﬁnition of Df (x). This derivative is often
called the Frechet derivative. .
Usually no harm is occasioned by thinking of this linear transformation as its
matrix taken with respect to the usual basis vectors.
The deﬁnition 5.21 means that the error,
f (x + v) −f (x) −Lv
converges to 0 faster than |v|. Thus the above deﬁnition is equivalent to saying
lim
|v|→0
|f (x + v) −f (x) −Lv|
|v|
= 0
(5.22)
or equivalently,
lim
y→x
|f (y) −f (x) −Df (x) (y −x)|
|y −x|
= 0.
(5.23)
Now it is clear this is just a generalization of the notion of the derivative of a
function of one variable because in this more specialized situation,
lim
|v|→0
|f (x + v) −f (x) −f ′ (x) v|
|v|
= 0,
due to the deﬁnition which says
f ′ (x) = lim
v→0
f (x + v) −f (x)
v
.
For functions of n variables, you can’t deﬁne the derivative as the limit of a diﬀerence
quotient like you can for a function of one variable because you can’t divide by a
vector. That is why there is a need for a more general deﬁnition.
The term o (v) is notation that is descriptive of the behavior in 5.21 and it is
only this behavior that is of interest. Thus, if t and k are constants,
o (v) = o (v) + o (v) , o (tv) = o (v) , ko (v) = o (v)
and other similar observations hold.
The sloppiness built in to this notation is
useful because it ignores details which are not important. It may help to think of
o (v) as an adjective describing what is left over after approximating f (x + v) by
f (x) + Df (x) v.
Theorem 5.46 The derivative is well deﬁned.

116
MULTI-VARIABLE CALCULUS
Proof: First note that for a ﬁxed vector, v, o (tv) = o (t). Now suppose both
L1 and L2 work in the above deﬁnition. Then let v be any vector and let t be a
real scalar which is chosen small enough that tv + x ∈U. Then
f (x + tv) = f (x) + L1tv + o (tv) , f (x + tv) = f (x) + L2tv + o (tv) .
Therefore, subtracting these two yields (L2 −L1) (tv) = o (tv) = o (t).
There-
fore, dividing by t yields (L2 −L1) (v) =
o(t)
t . Now let t →0 to conclude that
(L2 −L1) (v) = 0. Since this is true for all v, it follows L2 = L1. This proves the
theorem.
Lemma 5.47 Let f be diﬀerentiable at x. Then f is continuous at x and in fact,
there exists K > 0 such that whenever |v| is small enough,
|f (x + v) −f (x)| ≤K |v|
Proof: From the deﬁnition of the derivative, f (x + v)−f (x) = Df (x) v+o (v).
Let |v| be small enough that o(|v|)
|v|
< 1 so that |o (v)| ≤|v|. Then for such v,
|f (x + v) −f (x)|
≤
|Df (x) v| + |v|
≤
(|Df (x)| + 1) |v|
This proves the lemma with K = |Df (x)| + 1.
Theorem 5.48 (The chain rule) Let U and V be open sets, U ⊆Fn and V ⊆
Fm. Suppose f : U →V is diﬀerentiable at x ∈U and suppose g : V →Fq is
diﬀerentiable at f (x) ∈V . Then g ◦f is diﬀerentiable at x and
D (g ◦f) (x) = D (g (f (x))) D (f (x)) .
Proof: This follows from a computation. Let B (x,r) ⊆U and let r also be small
enough that for |v| ≤r, it follows that f (x + v) ∈V . Such an r exists because f is
continuous at x. For |v| < r, the deﬁnition of diﬀerentiability of g and f implies
g (f (x + v)) −g (f (x)) =
Dg (f (x)) (f (x + v) −f (x)) + o (f (x + v) −f (x))
=
Dg (f (x)) [Df (x) v + o (v)] + o (f (x + v) −f (x))
=
D (g (f (x))) D (f (x)) v + o (v) + o (f (x + v) −f (x)) .
(5.24)
It remains to show o (f (x + v) −f (x)) = o (v).
By Lemma 5.47, with K given there, letting ε > 0, it follows that for |v| small
enough,
|o (f (x + v) −f (x))| ≤(ε/K) |f (x + v) −f (x)| ≤(ε/K) K |v| = ε |v| .

5.12.
THE FRECHET DERIVATIVE
117
Since ε > 0 is arbitrary, this shows o (f (x + v) −f (x)) = o (v) because whenever
|v| is small enough,
|o (f (x + v) −f (x))|
|v|
≤ε.
By 5.24, this shows
g (f (x + v)) −g (f (x)) = D (g (f (x))) D (f (x)) v + o (v)
which proves the theorem.
The derivative is a linear transformation.
What is the matrix of this linear
transformation taken with respect to the usual basis vectors? Let ei denote the
vector of Fn which has a one in the ith entry and zeroes elsewhere. Then the matrix
of the linear transformation is the matrix whose ith column is Df (x) ei. What is
this? Let t ∈R such that |t| is suﬃciently small.
f (x + tei) −f (x)
=
Df (x) tei + o (tei)
=
Df (x) tei + o (t) .
Then dividing by t and taking a limit,
Df (x) ei = lim
t→0
f (x + tei) −f (x)
t
≡∂f
∂xi
(x) .
Thus the matrix of Df (x) with respect to the usual basis vectors is the matrix of
the form



f1,x1 (x)
f1,x2 (x)
· · ·
f1,xn (x)
...
...
...
fm,x1 (x)
fm,x2 (x)
· · ·
fm,xn (x)


.
As mentioned before, there is no harm in referring to this matrix as Df (x) but it
may also be referred to as Jf (x) .
This is summarized in the following theorem.
Theorem 5.49 Let f : Fn →Fm and suppose f is diﬀerentiable at x. Then all the
partial derivatives ∂fi(x)
∂xj
exist and if Jf (x) is the matrix of the linear transformation
with respect to the standard basis vectors, then the ijth entry is given by fi,j or
∂fi
∂xj (x).
What if all the partial derivatives of f exist? Does it follow that f is diﬀeren-
tiable? Consider the following function.
f (x, y) =
½
xy
x2+y2 if (x, y) ̸= (0, 0)
0 if (x, y) = (0, 0)
.
Then from the deﬁnition of partial derivatives,
lim
h→0
f (h, 0) −f (0, 0)
h
= lim
h→0
0 −0
h
= 0

118
MULTI-VARIABLE CALCULUS
and
lim
h→0
f (0, h) −f (0, 0)
h
= lim
h→0
0 −0
h
= 0
However f is not even continuous at (0, 0) which may be seen by considering the
behavior of the function along the line y = x and along the line x = 0. By Lemma
5.47 this implies f is not diﬀerentiable. Therefore, it is necessary to consider the
correct deﬁnition of the derivative given above if you want to get a notion which
generalizes the concept of the derivative of a function of one variable in such a way
as to preserve continuity whenever the function is diﬀerentiable.
5.13
C1 Functions
However, there are theorems which can be used to get diﬀerentiability of a function
based on existence of the partial derivatives.
Deﬁnition 5.50 When all the partial derivatives exist and are continuous the func-
tion is called a C1 function.
Because of Proposition 5.44 on Page 113 and Theorem 5.49 which identiﬁes the
entries of Jf with the partial derivatives, the following deﬁnition is equivalent to
the above.
Deﬁnition 5.51 Let U ⊆Fn be an open set. Then f : U →Fm is C1 (U) if f is
diﬀerentiable and the mapping
x →Df (x) ,
is continuous as a function from U to L (Fn, Fm).
The following is an important abstract generalization of the familiar concept of
partial derivative.
Deﬁnition 5.52 Let g : U ⊆Fn × Fm →Fq, where U is an open set in Fn × Fm.
Denote an element of Fn × Fm by (x, y) where x ∈Fn and y ∈Fm. Then the map
x →g (x, y) is a function from the open set in X,
{x : (x, y) ∈U}
to Fq. When this map is diﬀerentiable, its derivative is denoted by
D1g (x, y) , or sometimes by Dxg (x, y) .
Thus,
g (x + v, y) −g (x, y) = D1g (x, y) v + o (v) .
A similar deﬁnition holds for the symbol Dyg or D2g. The special case seen in
beginning calculus courses is where g : U →Fq and
gxi (x) ≡∂g (x)
∂xi
≡lim
h→0
g (x + hei) −g (x)
h
.

5.13.
C1 FUNCTIONS
119
The following theorem will be very useful in much of what follows. It is a version
of the mean value theorem.
Theorem 5.53 Suppose U is an open subset of Fn and f : U →Fm
has the
property that Df (x) exists for all x in U and that, x+t (y −x) ∈U for all t ∈[0, 1].
(The line segment joining the two points lies in U.) Suppose also that for all points
on this line segment,
||Df (x+t (y −x))|| ≤M.
Then
|f (y) −f (x)| ≤M |y −x| .
Proof: Let
S ≡{t ∈[0, 1] : for all s ∈[0, t] ,
|f (x + s (y −x)) −f (x)| ≤(M + ε) s |y −x|} .
Then 0 ∈S and by continuity of f, it follows that if t ≡sup S, then t ∈S and if
t < 1,
|f (x + t (y −x)) −f (x)| = (M + ε) t |y −x| .
(5.25)
If t < 1, then there exists a sequence of positive numbers, {hk}∞
k=1 converging to 0
such that
|f (x + (t + hk) (y −x)) −f (x)| > (M + ε) (t + hk) |y −x|
which implies that
|f (x + (t + hk) (y −x)) −f (x + t (y −x))|
+ |f (x + t (y −x)) −f (x)| > (M + ε) (t + hk) |y −x| .
By 5.25, this inequality implies
|f (x + (t + hk) (y −x)) −f (x + t (y −x))| > (M + ε) hk |y −x|
which yields upon dividing by hk and taking the limit as hk →0,
|Df (x + t (y −x)) (y −x)| ≥(M + ε) |y −x| .
Now by the deﬁnition of the norm of a linear operator,
M |y −x|
≥
||Df (x + t (y −x))|| |y −x|
≥
|Df (x + t (y −x)) (y −x)| ≥(M + ε) |y −x| ,
a contradiction. Therefore, t = 1 and so
|f (x + (y −x)) −f (x)| ≤(M + ε) |y −x| .
Since ε > 0 is arbitrary, this proves the theorem.
The next theorem proves that if the partial derivatives exist and are continuous,
then the function is diﬀerentiable.

120
MULTI-VARIABLE CALCULUS
Theorem 5.54 Let g : U ⊆Fn × Fm →Fq. Then g is C1 (U) if and only if D1g
and D2g both exist and are continuous on U. In this case,
Dg (x, y) (u, v) = D1g (x, y) u+D2g (x, y) v.
Proof: Suppose ﬁrst that g ∈C1 (U). Then if (x, y) ∈U,
g (x + u, y) −g (x, y) = Dg (x, y) (u, 0) + o (u) .
Therefore, D1g (x, y) u =Dg (x, y) (u, 0). Then
|(D1g (x, y) −D1g (x′, y′)) (u)| =
|(Dg (x, y) −Dg (x′, y′)) (u, 0)| ≤
||Dg (x, y) −Dg (x′, y′)|| |(u, 0)| .
Therefore,
|D1g (x, y) −D1g (x′, y′)| ≤||Dg (x, y) −Dg (x′, y′)|| .
A similar argument applies for D2g and this proves the continuity of the function,
(x, y) →Dig (x, y) for i = 1, 2. The formula follows from
Dg (x, y) (u, v)
=
Dg (x, y) (u, 0) + Dg (x, y) (0, v)
≡
D1g (x, y) u+D2g (x, y) v.
Now suppose D1g (x, y) and D2g (x, y) exist and are continuous.
g (x + u, y + v) −g (x, y) = g (x + u, y + v) −g (x, y + v)
+g (x, y + v) −g (x, y)
= g (x + u, y) −g (x, y) + g (x, y + v) −g (x, y) +
[g (x + u, y + v) −g (x + u, y) −(g (x, y + v) −g (x, y))]
= D1g (x, y) u + D2g (x, y) v + o (v) + o (u) +
[g (x + u, y + v) −g (x + u, y) −(g (x, y + v) −g (x, y))] .
(5.26)
Let h (x, u) ≡g (x + u, y + v) −g (x + u, y). Then the expression in [
] is of the
form,
h (x, u) −h (x, 0) .
Also
D2h (x, u) = D1g (x + u, y + v) −D1g (x + u, y)
and so, by continuity of (x, y) →D1g (x, y),
||D2h (x, u)|| < ε

5.13.
C1 FUNCTIONS
121
whenever ||(u, v)|| is small enough. By Theorem 5.53 on Page 119, there exists
δ > 0 such that if ||(u, v)|| < δ, the norm of the last term in 5.26 satisﬁes the
inequality,
||g (x + u, y + v) −g (x + u, y) −(g (x, y + v) −g (x, y))|| < ε ||u|| .
(5.27)
Therefore, this term is o ((u, v)). It follows from 5.27 and 5.26 that
g (x + u, y + v) =
g (x, y) + D1g (x, y) u + D2g (x, y) v+o (u) + o (v) + o ((u, v))
= g (x, y) + D1g (x, y) u + D2g (x, y) v + o ((u, v))
Showing that Dg (x, y) exists and is given by
Dg (x, y) (u, v) = D1g (x, y) u + D2g (x, y) v.
The continuity of (x, y) →Dg (x, y) follows from the continuity of (x, y) →
Dig (x, y). This proves the theorem.
Not surprisingly, it can be generalized to many more factors.
Deﬁnition 5.55 Let g : U ⊆Qn
i=1 Fri →Fq, where U is an open set. Then the
map xi →g (x) is a function from the open set in Fri,
{xi : x ∈U}
to Fq. When this map is diﬀerentiable, its derivative is denoted by Dig (x). To aid
in the notation, for v ∈Xi, let θiv ∈Qn
i=1 Fri be the vector (0, · · ·, v, · · ·, 0) where
the v is in the ith slot and for v ∈Qn
i=1 Fri, let vi denote the entry in the ith slot of
v. Thus by saying xi →g (x) is diﬀerentiable is meant that for v ∈Xi suﬃciently
small,
g (x + θiv) −g (x) = Dig (x) v + o (v) .
Here is a generalization of Theorem 5.54.
Theorem 5.56 Let g, U, Qn
i=1 Fri, be given as in Deﬁnition 5.55. Then g is C1 (U)
if and only if Dig exists and is continuous on U for each i. In this case,
Dg (x) (v) =
X
k
Dkg (x) vk
(5.28)
Proof: The only if part of the proof is left for you. Suppose then that Dig
exists and is continuous for each i. Note that Pk
j=1 θjvj = (v1, · · ·, vk, 0, · · ·, 0).
Thus Pn
j=1 θjvj = v and deﬁne P0
j=1 θjvj ≡0. Therefore,
g (x + v) −g (x) =
n
X
k=1

g

x+
k
X
j=1
θjvj

−g

x +
k−1
X
j=1
θjvj




(5.29)

122
MULTI-VARIABLE CALCULUS
Consider the terms in this sum.
g

x+
k
X
j=1
θjvj

−g

x +
k−1
X
j=1
θjvj

= g (x+θkvk) −g (x) +
(5.30)

g

x+
k
X
j=1
θjvj

−g (x+θkvk)

−

g

x +
k−1
X
j=1
θjvj

−g (x)


(5.31)
and the expression in 5.31 is of the form h (vk) −h (0) where for small w ∈Frk,
h (w) ≡g

x+
k−1
X
j=1
θjvj + θkw

−g (x + θkw) .
Therefore,
Dh (w) = Dkg

x+
k−1
X
j=1
θjvj + θkw

−Dkg (x + θkw)
and by continuity, ||Dh (w)|| < ε provided |v| is small enough.
Therefore, by
Theorem 5.53, whenever |v| is small enough, |h (θkvk) −h (0)| ≤ε |θkvk| ≤ε |v|
which shows that since ε is arbitrary, the expression in 5.31 is o (v). Now in 5.30
g (x+θkvk)−g (x) = Dkg (x) vk +o (vk) = Dkg (x) vk +o (v). Therefore, referring
to 5.29,
g (x + v) −g (x) =
n
X
k=1
Dkg (x) vk + o (v)
which shows Dg exists and equals the formula given in 5.28.
The way this is usually used is in the following corollary, a case of Theorem 5.56
obtained by letting Frj = F in the above theorem.
Corollary 5.57 Let U be an open subset of Fn and let f :U →Fm be C1 in the sense
that all the partial derivatives of f exist and are continuous. Then f is diﬀerentiable
and
f (x + v) = f (x) +
n
X
k=1
∂f
∂xk
(x) vk + o (v) .
5.14
Ck Functions
Recall the notation for partial derivatives in the following deﬁnition.
Deﬁnition 5.58 Let g : U →Fn. Then
gxk (x) ≡∂g
∂xk
(x) ≡lim
h→0
g (x + hek) −g (x)
h

5.15.
MIXED PARTIAL DERIVATIVES
123
Higher order partial derivatives are deﬁned in the usual way.
gxkxl (x) ≡
∂2g
∂xl∂xk
(x)
and so forth.
To deal with higher order partial derivatives in a systematic way, here is a useful
deﬁnition.
Deﬁnition 5.59 α = (α1, · · ·, αn) for α1 · · · αn positive integers is called a multi-
index. For α a multi-index, |α| ≡α1 + · · · + αn and if x ∈Fn,
x = (x1, · · ·, xn),
and f a function, deﬁne
xα ≡xα1
1 xα2
2 · · · xαn
n , Dαf(x) ≡
∂|α|f(x)
∂xα1
1 ∂xα2
2 · · · ∂xαn
n
.
The following is the deﬁnition of what is meant by a Ck function.
Deﬁnition 5.60 Let U be an open subset of Fn and let f : U →Fm. Then for k a
nonnegative integer, f is Ck if for every |α| ≤k, Dαf exists and is continuous.
5.15
Mixed Partial Derivatives
Under certain conditions the mixed partial derivatives will always be equal.
This astonishing fact is due to Euler in 1734.
Theorem 5.61 Suppose f : U ⊆F2 →R where U is an open set on which fx, fy,
fxy and fyx exist. Then if fxy and fyx are continuous at the point (x, y) ∈U, it
follows
fxy (x, y) = fyx (x, y) .
Proof: Since U is open, there exists r > 0 such that B ((x, y) , r) ⊆U. Now let
|t| , |s| < r/2, t, s real numbers and consider
∆(s, t) ≡1
st{
h(t)
z
}|
{
f (x + t, y + s) −f (x + t, y) −
h(0)
z
}|
{
(f (x, y + s) −f (x, y))}.
(5.32)
Note that (x + t, y + s) ∈U because
|(x + t, y + s) −(x, y)|
=
|(t, s)| =
¡
t2 + s2¢1/2
≤
µr2
4 + r2
4
¶1/2
=
r
√
2 < r.

124
MULTI-VARIABLE CALCULUS
As implied above, h (t) ≡f (x + t, y + s) −f (x + t, y). Therefore, by the mean
value theorem from calculus and the (one variable) chain rule,
∆(s, t)
=
1
st (h (t) −h (0)) = 1
sth′ (αt) t
=
1
s (fx (x + αt, y + s) −fx (x + αt, y))
for some α ∈(0, 1) . Applying the mean value theorem again,
∆(s, t) = fxy (x + αt, y + βs)
where α, β ∈(0, 1).
If the terms f (x + t, y) and f (x, y + s) are interchanged in 5.32, ∆(s, t) is un-
changed and the above argument shows there exist γ, δ ∈(0, 1) such that
∆(s, t) = fyx (x + γt, y + δs) .
Letting (s, t) →(0, 0) and using the continuity of fxy and fyx at (x, y) ,
lim
(s,t)→(0,0) ∆(s, t) = fxy (x, y) = fyx (x, y) .
This proves the theorem.
The following is obtained from the above by simply ﬁxing all the variables except
for the two of interest.
Corollary 5.62 Suppose U is an open subset of Fn and f : U →R has the property
that for two indices, k, l, fxk, fxl, fxlxk, and fxkxl exist on U and fxkxl and fxlxk
are both continuous at x ∈U. Then fxkxl (x) = fxlxk (x) .
By considering the real and imaginary parts of f in the case where f has values
in F you obtain the following corollary.
Corollary 5.63 Suppose U is an open subset of Fn and f : U →F has the property
that for two indices, k, l, fxk, fxl, fxlxk, and fxkxl exist on U and fxkxl and fxlxk
are both continuous at x ∈U. Then fxkxl (x) = fxlxk (x) .
Finally, by considering the components of f you get the following generalization.
Corollary 5.64 Suppose U is an open subset of Fn and f : U →F mhas the
property that for two indices, k, l, fxk, fxl, fxlxk, and fxkxl exist on U and fxkxl and
fxlxk are both continuous at x ∈U. Then fxkxl (x) = fxlxk (x) .
It is necessary to assume the mixed partial derivatives are continuous in order
to assert they are equal. The following is a well known example [5].
Example 5.65 Let
f (x, y) =
(
xy(x2−y2)
x2+y2
if (x, y) ̸= (0, 0)
0 if (x, y) = (0, 0)

5.16.
IMPLICIT FUNCTION THEOREM
125
From the deﬁnition of partial derivatives it follows immediately that fx (0, 0) =
fy (0, 0) = 0. Using the standard rules of diﬀerentiation, for (x, y) ̸= (0, 0) ,
fx = y x4 −y4 + 4x2y2
(x2 + y2)2
, fy = xx4 −y4 −4x2y2
(x2 + y2)2
Now
fxy (0, 0)
≡
lim
y→0
fx (0, y) −fx (0, 0)
y
=
lim
y→0
−y4
(y2)2 = −1
while
fyx (0, 0)
≡
lim
x→0
fy (x, 0) −fy (0, 0)
x
=
lim
x→0
x4
(x2)2 = 1
showing that although the mixed partial derivatives do exist at (0, 0) , they are not
equal there.
5.16
Implicit Function Theorem
The implicit function theorem is one of the greatest theorems in mathematics. There
are many versions of this theorem. However, I will give a very simple proof valid in
ﬁnite dimensional spaces.
Theorem 5.66 (implicit function theorem) Suppose U is an open set in Rn × Rm.
Let f : U →Rn be in C1 (U) and suppose
f (x0, y0) = 0, D1f (x0, y0)−1 ∈L (Rn, Rn) .
(5.33)
Then there exist positive constants, δ, η, such that for every y ∈B (y0, η) there
exists a unique x (y) ∈B (x0, δ) such that
f (x (y) , y) = 0.
(5.34)
Furthermore, the mapping, y →x (y) is in C1 (B (y0, η)).
Proof: Let
f (x, y) =





f1 (x, y)
f2 (x, y)
...
fn (x, y)




.

126
MULTI-VARIABLE CALCULUS
Deﬁne for
¡
x1, · · ·, xn¢
∈B (x0, δ)
n and y ∈B (y0, η) the following matrix.
J
¡
x1, · · ·, xn, y
¢
≡



f1,x1
¡
x1, y
¢
· · ·
f1,xn
¡
x1, y
¢
...
...
fn,x1 (xn, y)
· · ·
fn,xn (xn, y)


.
Then by the assumption of continuity of all the partial derivatives, there exists
δ0 > 0 and η0 > 0 such that if δ < δ0 and η < η0, it follows that for all
¡
x1, · · ·, xn¢
∈
B (x0, δ)
n and y ∈B (y0, η) ,
det
¡
J
¡
x1, · · ·, xn, y
¢¢
> r > 0.
(5.35)
and B (x0, δ0)× B (y0, η0) ⊆U. Pick y ∈B (y0, η) and suppose there exist x, z ∈
B (x0, δ) such that f (x, y) = f (z, y) = 0. Consider fi and let
h (t) ≡fi (x + t (z −x) , y) .
Then h (1) = h (0) and so by the mean value theorem, h′ (ti) = 0 for some ti ∈(0, 1) .
Therefore, from the chain rule and for this value of ti,
h′ (ti) = Dfi (x + ti (z −x) , y) (z −x) = 0.
(5.36)
Then denote by xi the vector, x + ti (z −x) . It follows from 5.36 that
J
¡
x1, · · ·, xn, y
¢
(z −x) = 0
and so from 5.35 z −x = 0. Now it will be shown that if η is chosen suﬃciently
small, then for all y ∈B (y0, η) , there exists a unique x (y) ∈B (x0, δ) such that
f (x (y) , y) = 0.
Claim: If η is small enough, then the function, hy (x) ≡|f (x, y)|2 achieves its
minimum value on B (x0, δ) at a point of B (x0, δ) .
Proof of claim: Suppose this is not the case. Then there exists a sequence
ηk →0 and for some yk having |yk−y0| < ηk, the minimum of hyk occurs on a point
of the boundary of B (x0, δ), xk such that |x0−xk| = δ. Now taking a subsequence,
still denoted by k, it can be assumed that xk →x with |x −x0| = δ and yk →y0.
Let ε > 0. Then for k large enough, hyk (x0) < ε because f (x0, y0) = 0. Therefore,
from the deﬁnition of xk, hyk (xk) < ε. Passing to the limit yields hy0 (x) ≤ε. Since
ε > 0 is arbitrary, it follows that hy0 (x) = 0 which contradicts the ﬁrst part of the
argument in which it was shown that for y ∈B (y0, η) there is at most one point, x
of B (x0, δ) where f (x, y) = 0. Here two have been obtained, x0 and x. This proves
the claim.
Choose η < η0 and also small enough that the above claim holds and let x (y)
denote a point of B (x0, δ) at which the minimum of hy on B (x0, δ) is achieved.
Since x (y) is an interior point, you can consider hy (x (y) + tv) for |t| small and
conclude this function of t has a zero derivative at t = 0. Thus
Dhy (x (y)) v = 0 = 2f (x (y) , y)T D1f (x (y) , y) v

5.16.
IMPLICIT FUNCTION THEOREM
127
for every vector v.
But from 5.35 and the fact that v is arbitrary, it follows
f (x (y) , y) = 0. This proves the existence of the function y →x (y) such that
f (x (y) , y) = 0 for all y ∈B (y0, η) .
It remains to verify this function is a C1 function. To do this, let y1 and y2 be
points of B (y0, η) . Then as before, consider the ith component of f and consider
the same argument using the mean value theorem to write
0 = fi (x (y1) , y1) −fi (x (y2) , y2)
= fi (x (y1) , y1) −fi (x (y2) , y1) + fi (x (y2) , y1) −fi (x (y2) , y2)
= D1fi
¡
xi, y1
¢
(x (y1) −x (y2)) + D2fi
¡
x (y2) , yi¢
(y1 −y2) .
Therefore,
J
¡
x1, · · ·, xn, y1
¢
(x (y1) −x (y2)) = −M (y1 −y2)
(5.37)
where M is the matrix whose ith row is D2fi
¡
x (y2) , yi¢
. Then from 5.35 there
exists a constant, C independent of the choice of y ∈B (y0, η) such that
¯¯¯
¯¯¯J
¡
x1, · · ·, xn, y
¢−1¯¯¯
¯¯¯ < C
whenever
¡
x1, · · ·, xn¢
∈B (x0, δ)
n. By continuity of the partial derivatives of f it
also follows there exists a constant, C1 such that ||D2fi (x, y)|| < C1 whenever,
(x, y) ∈B (x0, δ) × B (y0, η) . Hence ||M|| must also be bounded independent of
the choice of y1 and y2 in B (y0, η) . From 5.37, it follows there exists a constant,
C such that for all y1, y2 in B (y0, η) ,
|x (y1) −x (y2)| ≤C |y1 −y2| .
(5.38)
It follows as in the proof of the chain rule that
o (x (y + v) −x (y)) = o (v) .
(5.39)
Now let y ∈B (y0, η) and let |v| be suﬃciently small that y + v ∈B (y0, η) .
Then
0
=
f (x (y + v) , y + v) −f (x (y) , y)
=
f (x (y + v) , y + v) −f (x (y + v) , y) + f (x (y + v) , y) −f (x (y) , y)
= D2f (x (y + v) , y) v + D1f (x (y) , y) (x (y + v) −x (y)) + o (|x (y + v) −x (y)|)
=
D2f (x (y) , y) v + D1f (x (y) , y) (x (y + v) −x (y)) +
o (|x (y + v) −x (y)|) + (D2f (x (y + v) , y) v−D2f (x (y) , y) v)
=
D2f (x (y) , y) v + D1f (x (y) , y) (x (y + v) −x (y)) + o (v) .
Therefore,
x (y + v) −x (y) = −D1f (x (y) , y)−1 D2f (x (y) , y) v + o (v)

128
MULTI-VARIABLE CALCULUS
which shows that Dx (y) = −D1f (x (y) , y)−1 D2f (x (y) , y) and y →Dx (y) is
continuous. This proves the theorem.
In practice, how do you verify the condition, D1f (x0, y0)−1 ∈L (Fn, Fn)?
f (x, y) =



f1 (x1, · · ·, xn, y1, · · ·, yn)
...
fn (x1, · · ·, xn, y1, · · ·, yn)


.
The matrix of the linear transformation, D1f (x0, y0) is then




∂f1(x1,···,xn,y1,···,yn)
∂x1
· · ·
∂f1(x1,···,xn,y1,···,yn)
∂xn
...
...
∂fn(x1,···,xn,y1,···,yn)
∂x1
· · ·
∂fn(x1,···,xn,y1,···,yn)
∂xn




and from linear algebra, D1f (x0, y0)−1 ∈L (Fn, Fn) exactly when the above matrix
has an inverse. In other words when
det




∂f1(x1,···,xn,y1,···,yn)
∂x1
· · ·
∂f1(x1,···,xn,y1,···,yn)
∂xn
...
...
∂fn(x1,···,xn,y1,···,yn)
∂x1
· · ·
∂fn(x1,···,xn,y1,···,yn)
∂xn



̸= 0
at (x0, y0). The above determinant is important enough that it is given special
notation. Letting z = f (x, y) , the above determinant is often written as
∂(z1, · · ·, zn)
∂(x1, · · ·, xn).
Of course you can replace R with F in the above by applying the above to the
situation in which each F is replaced with R2.
Corollary 5.67 (implicit function theorem) Suppose U is an open set in Fn × Fm.
Let f : U →Fn be in C1 (U) and suppose
f (x0, y0) = 0, D1f (x0, y0)−1 ∈L (Fn, Fn) .
(5.40)
Then there exist positive constants, δ, η, such that for every y ∈B (y0, η) there
exists a unique x (y) ∈B (x0, δ) such that
f (x (y) , y) = 0.
(5.41)
Furthermore, the mapping, y →x (y) is in C1 (B (y0, η)).
The next theorem is a very important special case of the implicit function the-
orem known as the inverse function theorem.
Actually one can also obtain the
implicit function theorem from the inverse function theorem. It is done this way in
[36] and in [3].

5.16.
IMPLICIT FUNCTION THEOREM
129
Theorem 5.68 (inverse function theorem) Let x0 ∈U ⊆Fn and let f : U →Fn .
Suppose
f is C1 (U) ,
and Df(x0)−1 ∈L(Fn, Fn).
(5.42)
Then there exist open sets, W, and V such that
x0 ∈W ⊆U,
(5.43)
f : W →V is one to one and onto,
(5.44)
f −1 is C1.
(5.45)
Proof: Apply the implicit function theorem to the function
F (x, y) ≡f (x) −y
where y0 ≡f (x0). Thus the function y →x (y) deﬁned in that theorem is f −1.
Now let
W ≡B (x0, δ) ∩f −1 (B (y0, η))
and
V ≡B (y0, η) .
This proves the theorem.
5.16.1
More Continuous Partial Derivatives
Corollary 5.67 will now be improved slightly. If f is Ck, it follows that the function
which is implicitly deﬁned is also in Ck, not just C1. Since the inverse function
theorem comes as a case of the implicit function theorem, this shows that the
inverse function also inherits the property of being Ck.
Theorem 5.69 (implicit function theorem) Suppose U is an open set in Fn × Fm.
Let f : U →Fn be in Ck (U) and suppose
f (x0, y0) = 0, D1f (x0, y0)−1 ∈L (Fn, Fn) .
(5.46)
Then there exist positive constants, δ, η, such that for every y ∈B (y0, η) there
exists a unique x (y) ∈B (x0, δ) such that
f (x (y) , y) = 0.
(5.47)
Furthermore, the mapping, y →x (y) is in Ck (B (y0, η)).
Proof: From Corollary 5.67 y →x (y) is C1. It remains to show it is Ck for
k > 1 assuming that f is Ck. From 5.47
∂x
∂yl = −D1 (x, y)−1 ∂f
∂yl .

130
MULTI-VARIABLE CALCULUS
Thus the following formula holds for q = 1 and |α| = q.
Dαx (y) =
X
|β|≤q
Mβ (x, y) Dβf (x, y)
(5.48)
where Mβ is a matrix whose entries are diﬀerentiable functions of Dγ (x) for |γ| < q
and Dτf (x, y) for |τ| ≤q. This follows easily from the description of D1 (x, y)−1 in
terms of the cofactor matrix and the determinant of D1 (x, y). Suppose 5.48 holds
for |α| = q < k. Then by induction, this yields x is Cq. Then
∂Dαx (y)
∂yp
=
X
|β|≤|α|
∂Mβ (x, y)
∂yp
Dβf (x, y) + Mβ (x, y) ∂Dβf (x, y)
∂yp
.
By the chain rule ∂Mβ(x,y)
∂yp
is a matrix whose entries are diﬀerentiable functions of
Dτf (x, y) for |τ| ≤q+1 and Dγ (x) for |γ| < q+1. It follows since yp was arbitrary
that for any |α| = q + 1, a formula like 5.48 holds with q being replaced by q + 1.
By induction, x is Ck. This proves the theorem.
As a simple corollary this yields an improved version of the inverse function
theorem.
Theorem 5.70 (inverse function theorem) Let x0 ∈U ⊆Fn and let f : U →Fn .
Suppose for k a positive integer,
f is Ck (U) ,
and Df(x0)−1 ∈L(Fn, Fn).
(5.49)
Then there exist open sets, W, and V such that
x0 ∈W ⊆U,
(5.50)
f : W →V is one to one and onto,
(5.51)
f −1 is Ck.
(5.52)
5.17
The Method Of Lagrange Multipliers
As an application of the implicit function theorem, consider the method of Lagrange
multipliers from calculus. Recall the problem is to maximize or minimize a function
subject to equality constraints. Let f : U →R be a C1 function where U ⊆Rn and
let
gi (x) = 0, i = 1, · · ·, m
(5.53)
be a collection of equality constraints with m < n. Now consider the system of
nonlinear equations
f (x)
=
a
gi (x)
=
0, i = 1, · · ·, m.

5.17.
THE METHOD OF LAGRANGE MULTIPLIERS
131
x0 is a local maximum if f (x0) ≥f (x) for all x near x0 which also satisﬁes the
constraints 5.53. A local minimum is deﬁned similarly. Let F : U × R →Rm+1 be
deﬁned by
F (x,a) ≡





f (x) −a
g1 (x)
...
gm (x)




.
(5.54)
Now consider the m + 1 × n Jacobian matrix,





fx1 (x0)
· · ·
fxn (x0)
g1x1 (x0)
· · ·
g1xn (x0)
...
...
gmx1 (x0)
· · ·
gmxn (x0)




.
If this matrix has rank m + 1 then some m + 1 × m + 1 submatrix has nonzero
determinant. It follows from the implicit function theorem that there exist m + 1
variables, xi1, · · ·, xim+1 such that the system
F (x,a) = 0
(5.55)
speciﬁes these m + 1 variables as a function of the remaining n −(m + 1) variables
and a in an open set of Rn−m. Thus there is a solution (x,a) to 5.55 for some x
close to x0 whenever a is in some open interval. Therefore, x0 cannot be either a
local minimum or a local maximum. It follows that if x0 is either a local maximum
or a local minimum, then the above matrix must have rank less than m + 1 which
requires the rows to be linearly dependent. Thus, there exist m scalars,
λ1, · · ·, λm,
and a scalar µ, not all zero such that
µ



fx1 (x0)
...
fxn (x0)


= λ1



g1x1 (x0)
...
g1xn (x0)


+ · · · + λm



gmx1 (x0)
...
gmxn (x0)


.
(5.56)
If the column vectors



g1x1 (x0)
...
g1xn (x0)


, · · ·



gmx1 (x0)
...
gmxn (x0)



(5.57)
are linearly independent, then, µ ̸= 0 and dividing by µ yields an expression of the
form



fx1 (x0)
...
fxn (x0)


= λ1



g1x1 (x0)
...
g1xn (x0)


+ · · · + λm



gmx1 (x0)
...
gmxn (x0)



(5.58)

132
MULTI-VARIABLE CALCULUS
at every point x0 which is either a local maximum or a local minimum. This proves
the following theorem.
Theorem 5.71 Let U be an open subset of Rn and let f : U →R be a C1 function.
Then if x0 ∈U is either a local maximum or local minimum of f subject to the
constraints 5.53, then 5.56 must hold for some scalars µ, λ1, · · ·, λm not all equal to
zero. If the vectors in 5.57 are linearly independent, it follows that an equation of
the form 5.58 holds.

Metric Spaces And General
Topological Spaces
6.1
Metric Space
Deﬁnition 6.1 A metric space is a set, X and a function d : X × X →[0, ∞)
which satisﬁes the following properties.
d (x, y) = d (y, x)
d (x, y) ≥0 and d (x, y) = 0 if and only if x = y
d (x, y) ≤d (x, z) + d (z, y) .
You can check that Rn and Cn are metric spaces with d (x, y) = |x −y| . How-
ever, there are many others. The deﬁnitions of open and closed sets are the same
for a metric space as they are for Rn.
Deﬁnition 6.2 A set, U in a metric space is open if whenever x ∈U, there exists
r > 0 such that B (x, r) ⊆U. As before, B (x, r) ≡{y : d (x, y) < r} . Closed sets are
those whose complements are open. A point p is a limit point of a set, S if for every
r > 0, B (p, r) contains inﬁnitely many points of S. A sequence, {xn} converges to
a point x if for every ε > 0 there exists N such that if n ≥N, then d (x, xn) < ε.
{xn} is a Cauchy sequence if for every ε > 0 there exists N such that if m, n ≥N,
then d (xn, xm) < ε.
Lemma 6.3 In a metric space, X every ball, B (x, r) is open. A set is closed if
and only if it contains all its limit points. If p is a limit point of S, then there exists
a sequence of distinct points of S, {xn} such that limn→∞xn = p.
Proof: Let z ∈B (x, r). Let δ = r −d (x, z) . Then if w ∈B (z, δ) ,
d (w, x) ≤d (x, z) + d (z, w) < d (x, z) + r −d (x, z) = r.
Therefore, B (z, δ) ⊆B (x, r) and this shows B (x, r) is open.
The properties of balls are presented in the following theorem.
133

134
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
Theorem 6.4 Suppose (X, d) is a metric space.
Then the sets {B(x, r) : r >
0, x ∈X} satisfy
∪{B(x, r) : r > 0, x ∈X} = X
(6.1)
If p ∈B (x, r1) ∩B (z, r2), there exists r > 0 such that
B (p, r) ⊆B (x, r1) ∩B (z, r2) .
(6.2)
Proof:
Observe that the union of these balls includes the whole space, X so
6.1 is obvious. Consider 6.2. Let p ∈B (x, r1) ∩B (z, r2). Consider
r ≡min (r1 −d (x, p) , r2 −d (z, p))
and suppose y ∈B (p, r). Then
d (y, x) ≤d (y, p) + d (p, x) < r1 −d (x, p) + d (x, p) = r1
and so B (p, r) ⊆B (x, r1). By similar reasoning, B (p, r) ⊆B (z, r2). This proves
the theorem.
Let K be a closed set. This means KC ≡X \ K is an open set. Let p be a
limit point of K. If p ∈KC, then since KC is open, there exists B (p, r) ⊆KC. But
this contradicts p being a limit point because there are no points of K in this ball.
Hence all limit points of K must be in K.
Suppose next that K contains its limit points.
Is KC open?
Let p ∈KC.
Then p is not a limit point of K. Therefore, there exists B (p, r) which contains at
most ﬁnitely many points of K. Since p /∈K, it follows that by making r smaller if
necessary, B (p, r) contains no points of K. That is B (p, r) ⊆KC showing KC is
open. Therefore, K is closed.
Suppose now that p is a limit point of S. Let x1 ∈(S \ {p})∩B (p, 1) . If x1, ···, xk
have been chosen, let
rk+1 ≡min
½
d (p, xi) , i = 1, · · ·, k,
1
k + 1
¾
.
Let xk+1 ∈(S \ {p}) ∩B (p, rk+1) . This proves the lemma.
Lemma 6.5 If {xn} is a Cauchy sequence in a metric space, X and if some subse-
quence, {xnk} converges to x, then {xn} converges to x. Also if a sequence converges,
then it is a Cauchy sequence.
Proof: Note ﬁrst that nk ≥k because in a subsequence, the indices, n1, n2, ··· are
strictly increasing. Let ε > 0 be given and let N be such that for k > N, d (x, xnk) <
ε/2 and for m, n ≥N, d (xm, xn) < ε/2. Pick k > n. Then if n > N,
d (xn, x) ≤d (xn, xnk) + d (xnk, x) < ε
2 + ε
2 = ε.
Finally, suppose limn→∞xn = x. Then there exists N such that if n > N, then
d (xn, x) < ε/2. it follows that for m, n > N,
d (xn, xm) ≤d (xn, x) + d (x, xm) < ε
2 + ε
2 = ε.

6.2.
COMPACTNESS IN METRIC SPACE
135
This proves the lemma.
A useful idea is the idea of distance from a point to a set.
Deﬁnition 6.6 Let (X, d) be a metric space and let S be a nonempty set in X.
Then
dist (x, S) ≡inf {d (x, y) : y ∈S} .
The following lemma is the fundamental result.
Lemma 6.7 The function, x →dist (x, S) is continuous and in fact satisﬁes
|dist (x, S) −dist (y, S)| ≤d (x, y) .
Proof: Suppose dist (x, y) is as least as large as dist (y, S). Then pick z ∈S
such that d (y, z) ≤dist (y, S) + ε. Then
|dist (x, S) −dist (y, S)|
=
dist (x, S) −dist (y, S)
≤
d (x, z) −(d (y, z) −ε)
=
d (x, z) −d (y, z) + ε
≤
d (x, y) + d (y, z) −d (y, z) + ε
=
d (x, y) + ε.
Since ε > 0 is arbitrary, this proves the lemma.
6.2
Compactness In Metric Space
Many existence theorems in analysis depend on some set being compact. Therefore,
it is important to be able to identify compact sets. The purpose of this section is
to describe compact sets in a metric space.
Deﬁnition 6.8 Let A be a subset of X. A is compact if whenever A is contained
in the union of a set of open sets, there exists ﬁnitely many of these open sets whose
union contains A.
(Every open cover admits a ﬁnite subcover.) A is “sequen-
tially compact” means every sequence has a convergent subsequence converging to
an element of A.
In a metric space compact is not the same as closed and bounded!
Example 6.9 Let X be any inﬁnite set and deﬁne d (x, y) = 1 if x ̸= y while
d (x, y) = 0 if x = y.
You should verify the details that this is a metric space because it satisﬁes the
axioms of a metric. The set X
is closed and bounded because its complement is
∅which is clearly open because every point of ∅is an interior point. (There are
none.) Also X is bounded because X = B (x, 2). However, X is clearly not compact
because
©
B
¡
x, 1
2
¢
: x ∈X
ª
is a collection of open sets whose union contains X but

136
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
since they are all disjoint and nonempty, there is no ﬁnite subset of these whose
union contains X. In fact B
¡
x, 1
2
¢
= {x}.
From this example it is clear something more than closed and bounded is needed.
If you are not familiar with the issues just discussed, ignore them and continue.
Deﬁnition 6.10 In any metric space, a set E is totally bounded if for every ε > 0
there exists a ﬁnite set of points {x1, · · ·, xn} such that
E ⊆∪n
i=1B (xi, ε).
This ﬁnite set of points is called an ε net.
The following proposition tells which sets in a metric space are compact. First
here is an interesting lemma.
Lemma 6.11 Let X be a metric space and suppose D is a countable dense subset
of X. In other words, it is being assumed X is a separable metric space. Consider
the open sets of the form B (d, r) where r is a positive rational number and d ∈D.
Denote this countable collection of open sets by B. Then every open set is the union
of sets of B. Furthermore, if C is any collection of open sets, there exists a countable
subset, {Un} ⊆C such that ∪nUn = ∪C.
Proof: Let U be an open set and let x ∈U. Let B (x, δ) ⊆U. Then by density of
D, there exists d ∈D∩B (x, δ/4) . Now pick r ∈Q∩(δ/4, 3δ/4) and consider B (d, r) .
Clearly, B (d, r) contains the point x because r > δ/4. Is B (d, r) ⊆B (x, δ)? if so,
this proves the lemma because x was an arbitrary point of U. Suppose z ∈B (d, r) .
Then
d (z, x) ≤d (z, d) + d (d, x) < r + δ
4 < 3δ
4 + δ
4 = δ
Now let C be any collection of open sets. Each set in this collection is the union
of countably many sets of B. Let B′ denote the sets of B which are contained in
some set of C. Thus ∪B′ = ∪C. Then for each B ∈B′, pick UB ∈C such that
B ⊆UB. Then {UB : B ∈B′} is a countable collection of sets of C whose union
equals ∪C. Therefore, this proves the lemma.
Proposition 6.12 Let (X, d) be a metric space. Then the following are equivalent.
(X, d) is compact,
(6.3)
(X, d) is sequentially compact,
(6.4)
(X, d) is complete and totally bounded.
(6.5)
Proof: Suppose 6.3 and let {xk} be a sequence. Suppose {xk} has no convergent
subsequence. If this is so, then by Lemma 6.3, {xk} has no limit point and no value
of the sequence is repeated more than ﬁnitely many times. Thus the set
Cn = ∪{xk : k ≥n}

6.2.
COMPACTNESS IN METRIC SPACE
137
is a closed set because it has no limit points and if
Un = CC
n ,
then
X = ∪∞
n=1Un
but there is no ﬁnite subcovering, because no value of the sequence is repeated more
than ﬁnitely many times. This contradicts compactness of (X, d). This shows 6.3
implies 6.4.
Now suppose 6.4 and let {xn} be a Cauchy sequence. Is {xn} convergent? By
sequential compactness xnk →x for some subsequence. By Lemma 6.5 it follows
that {xn} also converges to x showing that (X, d) is complete.
If (X, d) is not
totally bounded, then there exists ε > 0 for which there is no ε net. Hence there
exists a sequence {xk} with d (xk, xl) ≥ε for all l ̸= k.
By Lemma 6.5 again,
this contradicts 6.4 because no subsequence can be a Cauchy sequence and so no
subsequence can converge. This shows 6.4 implies 6.5.
Now suppose 6.5. What about 6.4? Let {pn} be a sequence and let {xn
i }mn
i=1 be
a 2−n net for n = 1, 2, · · ·. Let
Bn ≡B
¡
xn
in, 2−n¢
be such that Bn contains pk for inﬁnitely many values of k and Bn ∩Bn+1 ̸= ∅.
To do this, suppose Bn contains pk for inﬁnitely many values of k. Then one of
the sets which intersect Bn, B
¡
xn+1
i
, 2−(n+1)¢
must contain pk for inﬁnitely many
values of k because all these indices of points from {pn} contained in Bn must be
accounted for in one of ﬁnitely many sets, B
¡
xn+1
i
, 2−(n+1)¢
. Thus there exists a
strictly increasing sequence of integers, nk such that
pnk ∈Bk.
Then if k ≥l,
d (pnk, pnl)
≤
k−1
X
i=l
d
¡
pni+1, pni
¢
<
k−1
X
i=l
2−(i−1) < 2−(l−2).
Consequently {pnk} is a Cauchy sequence. Hence it converges because the metric
space is complete. This proves 6.4.
Now suppose 6.4 and 6.5 which have now been shown to be equivalent. Let Dn
be a n−1 net for n = 1, 2, · · · and let
D = ∪∞
n=1Dn.
Thus D is a countable dense subset of (X, d).

138
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
Now let C be any set of open sets such that ∪C ⊇X. By Lemma 6.11, there
exists a countable subset of C,
eC = {Un}∞
n=1
such that ∪eC = ∪C. If C admits no ﬁnite subcover, then neither does eC and there ex-
ists pn ∈X \∪n
k=1Uk. Then since X is sequentially compact, there is a subsequence
{pnk} such that {pnk} converges. Say
p = lim
k→∞pnk.
All but ﬁnitely many points of {pnk} are in X \ ∪n
k=1Uk. Therefore p ∈X \ ∪n
k=1Uk
for each n. Hence
p /∈∪∞
k=1Uk
contradicting the construction of {Un}∞
n=1 which required that ∪∞
n=1Un ⊇X. Hence
X is compact. This proves the proposition.
Consider Rn. In this setting totally bounded and bounded are the same. This
will yield a proof of the Heine Borel theorem from advanced calculus.
Lemma 6.13 A subset of Rn is totally bounded if and only if it is bounded.
Proof: Let A be totally bounded. Is it bounded? Let x1, · · ·, xp be a 1 net for
A. Now consider the ball B (0, r + 1) where r > max (|xi| : i = 1, · · ·, p) . If z ∈A,
then z ∈B (xj, 1) for some j and so by the triangle inequality,
|z −0| ≤|z −xj| + |xj| < 1 + r.
Thus A ⊆B (0,r + 1) and so A is bounded.
Now suppose A is bounded and suppose A is not totally bounded. Then there
exists ε > 0 such that there is no ε net for A. Therefore, there exists a sequence of
points {ai} with |ai −aj| ≥ε if i ̸= j. Since A is bounded, there exists r > 0 such
that
A ⊆[−r, r)n.
(x ∈[−r, r)n means xi ∈[−r, r) for each i.) Now deﬁne S to be all cubes of the form
n
Y
k=1
[ak, bk)
where
ak = −r + i2−pr, bk = −r + (i + 1) 2−pr,
for i ∈{0, 1, · · ·, 2p+1 −1}. Thus S is a collection of
¡
2p+1¢n non overlapping cubes
whose union equals [−r, r)n and whose diameters are all equal to 2−pr√n. Now
choose p large enough that the diameter of these cubes is less than ε. This yields a
contradiction because one of the cubes must contain inﬁnitely many points of {ai}.
This proves the lemma.
The next theorem is called the Heine Borel theorem and it characterizes the
compact sets in Rn.

6.3.
SOME APPLICATIONS OF COMPACTNESS
139
Theorem 6.14 A subset of Rn is compact if and only if it is closed and bounded.
Proof: Since a set in Rn is totally bounded if and only if it is bounded, this
theorem follows from Proposition 6.12 and the observation that a subset of Rn is
closed if and only if it is complete. This proves the theorem.
6.3
Some Applications Of Compactness
The following corollary is an important existence theorem which depends on com-
pactness.
Corollary 6.15 Let X be a compact metric space and let f : X →R be continuous.
Then max {f (x) : x ∈X} and min {f (x) : x ∈X} both exist.
Proof: First it is shown f (X) is compact. Suppose C is a set of open sets whose
union contains f (X). Then since f is continuous f −1 (U) is open for all U ∈C.
Therefore,
©
f −1 (U) : U ∈C
ª
is a collection of open sets whose union contains X.
Since X is compact, it follows ﬁnitely many of these,
©
f −1 (U1) , · · ·, f −1 (Up)
ª
contains X in their union. Therefore, f (X) ⊆∪p
k=1Uk showing f (X) is compact
as claimed.
Now since f (X) is compact, Theorem 6.14 implies f (X) is closed and bounded.
Therefore, it contains its inf and its sup. Thus f achieves both a maximum and a
minimum.
Deﬁnition 6.16 Let X, Y be metric spaces and f : X →Y a function.
f is
uniformly continuous if for all ε > 0 there exists δ > 0 such that whenever x1 and
x2 are two points of X satisfying d (x1, x2) < δ, it follows that d (f (x1) , f (x2)) < ε.
A very important theorem is the following.
Theorem 6.17 Suppose f : X →Y is continuous and X is compact. Then f is
uniformly continuous.
Proof: Suppose this is not true and that f is continuous but not uniformly
continuous. Then there exists ε > 0 such that for all δ > 0 there exist points,
pδ and qδ such that d (pδ, qδ) < δ and yet d (f (pδ) , f (qδ)) ≥ε. Let pn and qn
be the points which go with δ = 1/n. By Proposition 6.12 {pn} has a convergent
subsequence, {pnk} converging to a point, x ∈X. Since d (pn, qn) < 1
n, it follows
that qnk →x also. Therefore,
ε ≤d (f (pnk) , f (qnk)) ≤d (f (pnk) , f (x)) + d (f (x) , f (qnk))
but by continuity of f, both d (f (pnk) , f (x)) and d (f (x) , f (qnk)) converge to 0
as k →∞contradicting the above inequality. This proves the theorem.
Another important property of compact sets in a metric space concerns the ﬁnite
intersection property.

140
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
Deﬁnition 6.18 If every ﬁnite subset of a collection of sets has nonempty inter-
section, the collection has the ﬁnite intersection property.
Theorem 6.19 Suppose F is a collection of compact sets in a metric space, X
which has the ﬁnite intersection property. Then there exists a point in their inter-
section. (∩F ̸= ∅).
Proof: If this were not so, ∪
©
F C : F ∈F
ª
= X and so, in particular, picking
some F0 ∈F,
©
F C : F ∈F
ª
would be an open cover of F0. Since F0 is compact,
some ﬁnite subcover, F C
1 , · · ·, F C
m exists. But then F0 ⊆∪m
k=1F C
k
which means
∩∞
k=0Fk = ∅, contrary to the ﬁnite intersection property.
Theorem 6.20 Let Xi be a compact metric space with metric di. Then Qm
i=1 Xi is
also a compact metric space with respect to the metric, d (x, y) ≡maxi (di (xi, yi)).
Proof: This is most easily seen from sequential compactness.
Let
©
xkª∞
k=1
be a sequence of points in Qm
i=1 Xi.
Consider the ith component of xk, xk
i .
It
follows
©
xk
i
ª
is a sequence of points in Xi and so it has a convergent subsequence.
Compactness of X1 implies there exists a subsequence of xk, denoted by
©
xk1ª
such
that
lim
k1→∞xk1
1 →x1 ∈X1.
Now there exists a further subsequence, denoted by
©
xk2ª
such that in addition to
this, xk2
2 →x2 ∈X2. After taking m such subsequences, there exists a subsequence,
©
xlª
such that liml→∞xl
i = xi ∈Xi for each i. Therefore, letting x ≡(x1, · · ·, xm),
xl →x in Qm
i=1 Xi. This proves the theorem.
6.4
Ascoli Arzela Theorem
Deﬁnition 6.21 Let (X, d) be a complete metric space. Then it is said to be locally
compact if B (x, r) is compact for each r > 0.
Thus if you have a locally compact metric space, then if {an} is a bounded
sequence, it must have a convergent subsequence.
Let K be a compact subset of Rn and consider the continuous functions which
have values in a locally compact metric space, (X, d) where d denotes the metric on
X. Denote this space as C (K, X) .
Deﬁnition 6.22 For f, g ∈C (K, X) , where K is a compact subset of Rn and X
is a locally compact complete metric space deﬁne
ρK (f, g) ≡sup {d (f (x) , g (x)) : x ∈K} .
Then ρK provides a distance which makes C (K, X) into a metric space.
The Ascoli Arzela theorem is a major result which tells which subsets of C (K, X)
are sequentially compact.

6.4.
ASCOLI ARZELA THEOREM
141
Deﬁnition 6.23 Let A ⊆C (K, X) for K a compact subset of Rn. Then A is said
to be uniformly equicontinuous if for every ε > 0 there exists a δ > 0 such that
whenever x, y ∈K with |x −y| < δ and f ∈A,
d (f (x) , f (y)) < ε.
The set, A is said to be uniformly bounded if for some M < ∞, and a ∈X,
f (x) ∈B (a, M)
for all f ∈A and x ∈K.
Uniform equicontinuity is like saying that the whole set of functions, A, is uni-
formly continuous on K uniformly for f ∈A. The version of the Ascoli Arzela
theorem I will present here is the following.
Theorem 6.24 Suppose K is a nonempty compact subset of Rn and A ⊆C (K, X)
is uniformly bounded and uniformly equicontinuous. Then if {fk} ⊆A, there exists
a function, f ∈C (K, X) and a subsequence, fkl such that
lim
l→∞ρK (fkl, f) = 0.
To give a proof of this theorem, I will ﬁrst prove some lemmas.
Lemma 6.25 If K is a compact subset of Rn, then there exists D ≡{xk}∞
k=1 ⊆K
such that D is dense in K. Also, for every ε > 0 there exists a ﬁnite set of points,
{x1, · · ·, xm} ⊆K, called an ε net such that
∪m
i=1B (xi, ε) ⊇K.
Proof: For m ∈N, pick xm
1 ∈K. If every point of K is within 1/m of xm
1 , stop.
Otherwise, pick
xm
2 ∈K \ B (xm
1 , 1/m) .
If every point of K contained in B (xm
1 , 1/m) ∪B (xm
2 , 1/m) , stop. Otherwise, pick
xm
3 ∈K \ (B (xm
1 , 1/m) ∪B (xm
2 , 1/m)) .
If every point of K is contained in B (xm
1 , 1/m) ∪B (xm
2 , 1/m) ∪B (xm
3 , 1/m) , stop.
Otherwise, pick
xm
4 ∈K \ (B (xm
1 , 1/m) ∪B (xm
2 , 1/m) ∪B (xm
3 , 1/m))
Continue this way until the process stops, say at N (m).
It must stop because
if it didn’t, there would be a convergent subsequence due to the compactness of
K. Ultimately all terms of this convergent subsequence would be closer than 1/m,
violating the manner in which they are chosen. Then D = ∪∞
m=1 ∪N(m)
k=1
{xm
k } . This
is countable because it is a countable union of countable sets. If y ∈K and ε > 0,
then for some m, 2/m < ε and so B (y, ε) must contain some point of {xm
k } since
otherwise, the process stopped too soon. You could have picked y. This proves the
lemma.

142
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
Lemma 6.26 Suppose D is deﬁned above and {gm} is a sequence of functions of
A having the property that for every xk ∈D,
lim
m→∞gm (xk) exists.
Then there exists g ∈C (K, X) such that
lim
m→∞ρ (gm, g) = 0.
Proof: Deﬁne g ﬁrst on D.
g (xk) ≡lim
m→∞gm (xk) .
Next I show that {gm} converges at every point of K. Let x ∈K and let ε > 0 be
given. Choose xk such that for all f ∈A,
d (f (xk) , f (x)) < ε
3.
I can do this by the equicontinuity. Now if p, q are large enough, say p, q ≥M,
d (gp (xk) , gq (xk)) < ε
3.
Therefore, for p, q ≥M,
d (gp (x) , gq (x))
≤
d (gp (x) , gp (xk)) + d (gp (xk) , gq (xk)) + d (gq (xk) , gq (x))
<
ε
3 + ε
3 + ε
3 = ε
It follows that {gm (x)} is a Cauchy sequence having values X. Therefore, it con-
verges. Let g (x) be the name of the thing it converges to.
Let ε > 0 be given and pick δ > 0 such that whenever x, y ∈K and |x −y| < δ,
it follows d (f (x) , f (y)) < ε
3 for all f ∈A. Now let {x1, · · ·, xm} be a δ net for K
as in Lemma 6.25. Since there are only ﬁnitely many points in this δ net, it follows
that there exists N such that for all p, q ≥N,
d (gq (xi) , gp (xi)) < ε
3
for all {x1, · · ·, xm} · Therefore, for arbitrary x ∈K, pick xi ∈{x1, · · ·, xm} such
that |xi −x| < δ. Then
d (gq (x) , gp (x))
≤
d (gq (x) , gq (xi)) + d (gq (xi) , gp (xi)) + d (gp (xi) , gp (x))
<
ε
3 + ε
3 + ε
3 = ε.
Since N does not depend on the choice of x, it follows this sequence {gm} is uni-
formly Cauchy. That is, for every ε > 0, there exists N such that if p, q ≥N,
then
ρ (gp, gq) < ε.

6.4.
ASCOLI ARZELA THEOREM
143
Next, I need to verify that the function, g is a continuous function. Let N be
large enough that whenever p, q ≥N, the above holds. Then for all x ∈K,
d (g (x) , gp (x)) ≤ε
3
(6.6)
whenever p ≥N. This follows from observing that for p, q ≥N,
d (gq (x) , gp (x)) < ε
3
and then taking the limit as q →∞to obtain 6.6. In passing to the limit, you can
use the following simple claim.
Claim: In a metric space, if an →a, then d (an, b) →d (a, b) .
Proof of the claim: You note that by the triangle inequality, d (an, b) −
d (a, b) ≤d (an, a) and d (a, b) −d (an, b) ≤d (an, a) and so
|d (an, b) −d (a, b)| ≤d (an, a) .
Now let p satisfy 6.6 for all x whenever p > N. Also pick δ > 0 such that if
|x −y| < δ, then
d (gp (x) , gp (y)) < ε
3.
Then if |x −y| < δ,
d (g (x) , g (y))
≤
d (g (x) , gp (x)) + d (gp (x) , gp (y)) + d (gp (y) , g (y))
<
ε
3 + ε
3 + ε
3 = ε.
Since ε was arbitrary, this shows that g is continuous.
It only remains to verify that ρ (g, gk) →0. But this follows from 6.6. This
proves the lemma.
With these lemmas, it is time to prove Theorem 6.24.
Proof of Theorem 6.24: Let D = {xk} be the countable dense set of K
gauranteed by Lemma 6.25 and let
{(1, 1) , (1, 2) , (1, 3) , (1, 4) , (1, 5) , · · ·}
be a subsequence of N such that
lim
k→∞f(1,k) (x1) exists.
This is where the local compactness of X is being used. Now let
{(2, 1) , (2, 2) , (2, 3) , (2, 4) , (2, 5) , · · ·}
be a subsequence of
{(1, 1) , (1, 2) , (1, 3) , (1, 4) , (1, 5) , · · ·}

144
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
which has the property that
lim
k→∞f(2,k) (x2) exists.
Thus it is also the case that
f(2,k) (x1) converges to
lim
k→∞f(1,k) (x1) .
because every subsequence of a convergent sequence converges to the same thing as
the convergent sequence. Continue this way and consider the array
f(1,1), f(1,2), f(1,3), f(1,4), · · · converges at x1
f(2,1), f(2,2), f(2,3), f(2,4) · · · converges at x1 and x2
f(3,1), f(3,2), f(3,3), f(3,4) · · · converges at x1, x2, and x3
...
Now let gk ≡f(k,k). Thus gk is ultimately a subsequence of
©
f(m,k)
ª
whenever
k > m and therefore, {gk} converges at each point of D. By Lemma 6.26 it follows
there exists g ∈C (K) such that
lim
k→∞ρ (g, gk) = 0.
This proves the Ascoli Arzela theorem.
Actually there is an if and only if version of it but the most useful case is what
is presented here. The process used to get the subsequence in the proof is called
the Cantor diagonalization procedure.
6.5
The Tietze Extension Theorem
It turns out that if H is a closed subset of a metric space, (X, d) and if f : H →[a, b]
is continuous, then there exists g deﬁned on all of X such that g = f on H and g
is continuous. This is called the Tietze extension theorem. First it is well to recall
continuity in the context of metric space.
Deﬁnition 6.27 Let (X, d) be a metric space and suppose f : X →Y is a function
where (Y, ρ) is also a metric space. For example, Y = R. Then f is continuous at
x ∈X if for every ε > 0 there exists δ > 0 such that ρ (f (x) , f (z)) < ε whenever
d (x, z) < δ. As is usual in such deﬁnitions, f is said to be continuous if it is
continuous at every point of X.
The following lemma gives an important example of a continuous real valued
function deﬁned on a metric space, (X, d) .
Lemma 6.28 Let (X, d) be a metric space and let S ⊆X be a nonempty subset.
Deﬁne
dist (x, S) ≡inf {d (x, y) : y ∈S} .

6.5.
THE TIETZE EXTENSION THEOREM
145
Then x →dist (x, S) is a continuous function satisfying the inequality,
|dist (x, S) −dist (y, S)| ≤d (x, y) .
(6.7)
Proof: The continuity of x →dist (x, S) is obvious if the inequality 6.7 is estab-
lished. So let x, y ∈X. Without loss of generality, assume dist (x, S) ≥dist (y, S)
and pick z ∈S such that d (y, z) −ε < dist (y, S) . Then
|dist (x, S) −dist (y, S)|
=
dist (x, S) −dist (y, S) ≤d (x, z) −(d (y, z) −ε)
≤
d (z, y) + d (x, y) −d (y, z) + ε = d (x, y) + ε.
Since ε is arbitrary, this proves 6.7.
Lemma 6.29 Let H, K be two nonempty disjoint closed subsets of a metric space,
(X, d) . Then there exists a continuous function, g : X →[−1, 1] such that g (H) =
−1/3, g (K) = 1/3, g (X) ⊆[−1/3, 1/3] .
Proof: Let
f (x) ≡
dist (x, H)
dist (x, H) + dist (x, K).
The denominator is never equal to zero because if dist (x, H) = 0, then x ∈H
becasue H is closed. (To see this, pick hk ∈B (x, 1/k) ∩H. Then hk →x and
since H is closed, x ∈H.) Similarly, if dist (x, K) = 0, then x ∈K and so the
denominator is never zero as claimed. Hence, by Lemma 6.28, f is continuous and
from its deﬁnition, f = 0 on H and f = 1 on K. Now let g (x) ≡2
3
¡
h (x) −1
2
¢
.
Then g has the desired properties.
Deﬁnition 6.30 For f a real or complex valued bounded continuous function de-
ﬁned on a metric space, M
||f||M ≡sup {|f (x)| : x ∈M} .
Lemma 6.31 Suppose M is a closed set in X where (X, d) is a metric space and
suppose f : M →[−1, 1] is continuous at every point of M. Then there exists a
function, g which is deﬁned and continuous on all of X such that ||f −g||M < 2
3.
Proof:
Let H = f −1 ([−1, −1/3]) , K = f −1 ([1/3, 1]) . Thus H and K are
disjoint closed subsets of M. Suppose ﬁrst H, K are both nonempty.
Then by
Lemma 6.29 there exists g such that g is a continuous function deﬁned on all of X
and g (H) = −1/3, g (K) = 1/3, and g (X) ⊆[−1/3, 1/3] . It follows ||f −g||M <
2/3. If H = ∅, then f has all its values in [−1/3, 1] and so letting g ≡1/3, the
desired condition is obtained. If K = ∅, let g ≡−1/3. This proves the lemma.
Lemma 6.32 Suppose M is a closed set in X where (X, d) is a metric space and
suppose f : M →[−1, 1] is continuous at every point of M. Then there exists a
function, g which is deﬁned and continuous on all of X such that g = f on M and
g has its values in [−1, 1] .

146
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
Proof: Let g1 be such that g1 (X) ⊆[−1/3, 1/3] and ||f −g1||M ≤2
3. Suppose
g1, · · ·, gm have been chosen such that gj (X) ⊆[−1/3, 1/3] and
¯¯¯¯¯
¯¯¯¯¯f −
m
X
i=1
µ2
3
¶i−1
gi
¯¯¯¯¯
¯¯¯¯¯
M
<
µ2
3
¶m
.
(6.8)
Then
¯¯¯¯¯
¯¯¯¯¯
µ3
2
¶m Ã
f −
m
X
i=1
µ2
3
¶i−1
gi
!¯¯¯¯¯
¯¯¯¯¯
M
≤1
and so
¡ 3
2
¢m ³
f −Pm
i=1
¡ 2
3
¢i−1 gi
´
can play the role of f in the ﬁrst step of the
proof. Therefore, there exists gm+1 deﬁned and continuous on all of X such that
its values are in [−1/3, 1/3] and
¯¯¯¯¯
¯¯¯¯¯
µ3
2
¶m Ã
f −
m
X
i=1
µ2
3
¶i−1
gi
!
−gm+1
¯¯¯¯¯
¯¯¯¯¯
M
≤2
3.
Hence
¯¯¯¯¯
¯¯¯¯¯
Ã
f −
m
X
i=1
µ2
3
¶i−1
gi
!
−
µ2
3
¶m
gm+1
¯¯¯¯¯
¯¯¯¯¯
M
≤
µ2
3
¶m+1
.
It follows there exists a sequence, {gi} such that each has its values in [−1/3, 1/3]
and for every m 6.8 holds. Then let
g (x) ≡
∞
X
i=1
µ2
3
¶i−1
gi (x) .
It follows
|g (x)| ≤
¯¯¯¯¯
∞
X
i=1
µ2
3
¶i−1
gi (x)
¯¯¯¯¯ ≤
m
X
i=1
µ2
3
¶i−1 1
3 ≤1
and since convergence is uniform, g must be continuous. The estimate 6.8 implies
f = g on M.
The following is the Tietze extension theorem.
Theorem 6.33 Let M be a closed nonempty subset of a metric space (X, d) and
let f : M →[a, b] is continuous at every point of M. Then there exists a function,
g continuous on all of X which coincides with f on M such that g (X) ⊆[a, b] .
Proof: Let f1 (x) = 1 +
2
b−a (f (x) −b) . Then f1 satisﬁes the conditions of
Lemma 6.32 and so there exists g1 : X →[−1, 1] such that g is continuous on X
and equals f1 on M. Let g (x) = (g1 (x) −1)
¡ b−a
2
¢
+ b. This works.

6.6.
GENERAL TOPOLOGICAL SPACES
147
6.6
General Topological Spaces
It turns out that metric spaces are not suﬃciently general for some applications.
This section is a brief introduction to general topology. In making this generaliza-
tion, the properties of balls which are the conclusion of Theorem 6.4 on Page 134
are stated as axioms for a subset of the power set of a given set which will be known
as a basis for the topology. More can be found in [35] and the references listed
there.
Deﬁnition 6.34 Let X be a nonempty set and suppose B ⊆P (X). Then B is a
basis for a topology if it satisﬁes the following axioms.
1.) Whenever p ∈A ∩B for A, B ∈B, it follows there exists C ∈B such that
p ∈C ⊆A ∩B.
2.) ∪B = X.
Then a subset, U, of X is an open set if for every point, x ∈U, there exists
B ∈B such that x ∈B ⊆U. Thus the open sets are exactly those which can be
obtained as a union of sets of B. Denote these subsets of X by the symbol τ and
refer to τ as the topology or the set of open sets.
Note that this is simply the analog of saying a set is open exactly when every
point is an interior point.
Proposition 6.35 Let X be a set and let B be a basis for a topology as deﬁned
above and let τ be the set of open sets determined by B. Then
∅∈τ, X ∈τ,
(6.9)
If C ⊆τ, then ∪C ∈τ
(6.10)
If A, B ∈τ, then A ∩B ∈τ.
(6.11)
Proof: If p ∈∅then there exists B ∈B such that p ∈B ⊆∅because there are
no points in ∅. Therefore, ∅∈τ. Now if p ∈X, then by part 2.) of Deﬁnition 6.34
p ∈B ⊆X for some B ∈B and so X ∈τ.
If C ⊆τ, and if p ∈∪C, then there exists a set, B ∈C such that p ∈B.
However, B is itself a union of sets from B and so there exists C ∈B such that
p ∈C ⊆B ⊆∪C. This veriﬁes 6.10.
Finally, if A, B ∈τ and p ∈A ∩B, then since A and B are themselves unions
of sets of B, it follows there exists A1, B1 ∈B such that A1 ⊆A, B1 ⊆B, and
p ∈A1 ∩B1. Therefore, by 1.) of Deﬁnition 6.34 there exists C ∈B such that
p ∈C ⊆A1 ∩B1 ⊆A ∩B, showing that A ∩B ∈τ as claimed. Of course if
A ∩B = ∅, then A ∩B ∈τ. This proves the proposition.
Deﬁnition 6.36 A set X together with such a collection of its subsets satisfying
6.9-6.11 is called a topological space. τ is called the topology or set of open sets of
X.

148
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
Deﬁnition 6.37 A topological space is said to be Hausdorﬀif whenever p and q
are distinct points of X, there exist disjoint open sets U, V such that p ∈U, q ∈V .
In other words points can be separated with open sets.
Hausdorﬀ
·p
U
·q
V
Deﬁnition 6.38 A subset of a topological space is said to be closed if its comple-
ment is open. Let p be a point of X and let E ⊆X. Then p is said to be a limit
point of E if every open set containing p contains a point of E distinct from p.
Note that if the topological space is Hausdorﬀ, then this deﬁnition is equivalent
to requiring that every open set containing p contains inﬁnitely many points from
E. Why?
Theorem 6.39 A subset, E, of X is closed if and only if it contains all its limit
points.
Proof: Suppose ﬁrst that E is closed and let x be a limit point of E. Is x ∈E?
If x /∈E, then EC is an open set containing x which contains no points of E, a
contradiction. Thus x ∈E.
Now suppose E contains all its limit points. Is the complement of E open? If
x ∈EC, then x is not a limit point of E because E has all its limit points and so
there exists an open set, U containing x such that U contains no point of E other
than x. Since x /∈E, it follows that x ∈U ⊆EC which implies EC is an open set
because this shows EC is the union of open sets.
Theorem 6.40 If (X, τ) is a Hausdorﬀspace and if p ∈X, then {p} is a closed
set.
Proof: If x ̸= p, there exist open sets U and V such that x ∈U, p ∈V and
U ∩V = ∅. Therefore, {p}C is an open set so {p} is closed.
Note that the Hausdorﬀaxiom was stronger than needed in order to draw the
conclusion of the last theorem. In fact it would have been enough to assume that
if x ̸= y, then there exists an open set containing x which does not intersect y.
Deﬁnition 6.41 A topological space (X, τ) is said to be regular if whenever C is
a closed set and p is a point not in C, there exist disjoint open sets U and V such
that p ∈U, C ⊆V . Thus a closed set can be separated from a point not in the
closed set by two disjoint open sets.

6.6.
GENERAL TOPOLOGICAL SPACES
149
Regular
·p
U
C
V
Deﬁnition 6.42 The topological space, (X, τ) is said to be normal if whenever C
and K are disjoint closed sets, there exist disjoint open sets U and V such that
C ⊆U, K ⊆V . Thus any two disjoint closed sets can be separated with open sets.
Normal
C
U
K
V
Deﬁnition 6.43 Let E be a subset of X. E is deﬁned to be the smallest closed set
containing E.
Lemma 6.44 The above deﬁnition is well deﬁned.
Proof: Let C denote all the closed sets which contain E. Then C is nonempty
because X ∈C.
(∩{A : A ∈C})C = ∪
©
AC : A ∈C
ª
,
an open set which shows that ∩C is a closed set and is the smallest closed set which
contains E.
Theorem 6.45 E = E ∪{limit points of E}.
Proof: Let x ∈E and suppose that x /∈E. If x is not a limit point either, then
there exists an open set, U,containing x which does not intersect E. But then U C
is a closed set which contains E which does not contain x, contrary to the deﬁnition
that E is the intersection of all closed sets containing E. Therefore, x must be a
limit point of E after all.
Now E ⊆E so suppose x is a limit point of E. Is x ∈E? If H is a closed set
containing E, which does not contain x, then HC is an open set containing x which
contains no points of E other than x negating the assumption that x is a limit point
of E.
The following is the deﬁnition of continuity in terms of general topological spaces.
It is really just a generalization of the ε - δ deﬁnition of continuity given in calculus.
Deﬁnition 6.46 Let (X, τ) and (Y, η) be two topological spaces and let f : X →Y .
f is continuous at x ∈X if whenever V is an open set of Y containing f(x), there
exists an open set U ∈τ such that x ∈U and f(U) ⊆V .
f is continuous if
f −1(V ) ∈τ whenever V ∈η.

150
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
You should prove the following.
Proposition 6.47 In the situation of Deﬁnition 6.46 f is continuous if and only
if f is continuous at every point of X.
Deﬁnition 6.48 Let (Xi, τ i) be topological spaces. Qn
i=1 Xi is the Cartesian prod-
uct. Deﬁne a product topology as follows. Let B = Qn
i=1 Ai where Ai ∈τ i. Then B
is a basis for the product topology.
Theorem 6.49 The set B of Deﬁnition 6.48 is a basis for a topology.
Proof: Suppose x ∈Qn
i=1 Ai∩Qn
i=1 Bi where Ai and Bi are open sets. Say
x = (x1, · · ·, xn) .
Then xi ∈Ai ∩Bi for each i. Therefore, x ∈Qn
i=1 Ai ∩Bi ∈B and Qn
i=1 Ai ∩Bi ⊆
Qn
i=1 Ai.
The deﬁnition of compactness is also considered for a general topological space.
This is given next.
Deﬁnition 6.50 A subset, E, of a topological space (X, τ) is said to be compact if
whenever C ⊆τ and E ⊆∪C, there exists a ﬁnite subset of C, {U1 · · · Un}, such that
E ⊆∪n
i=1Ui. (Every open covering admits a ﬁnite subcovering.) E is precompact if
E is compact. A topological space is called locally compact if it has a basis B, with
the property that B is compact for each B ∈B.
A useful construction when dealing with locally compact Hausdorﬀspaces is the
notion of the one point compactiﬁcation of the space.
Deﬁnition 6.51 Suppose (X, τ) is a locally compact Hausdorﬀspace.
Then let
e
X ≡X ∪{∞} where ∞is just the name of some point which is not in X which is
called the point at inﬁnity. A basis for the topology eτ for e
X is
τ ∪
©
KC where K is a compact subset of X
ª
.
The complement is taken with respect to e
X and so the open sets, KC are basic open
sets which contain ∞.
The reason this is called a compactiﬁcation is contained in the next lemma.
Lemma 6.52 If (X, τ) is a locally compact Hausdorﬀspace, then
³
e
X, eτ
´
is a com-
pact Hausdorﬀspace.
Proof: Since (X, τ) is a locally compact Hausdorﬀspace, it follows
³
e
X, eτ
´
is
a Hausdorﬀtopological space. The only case which needs checking is the one of
p ∈X and ∞. Since (X, τ) is locally compact, there exists an open set of τ, U
having compact closure which contains p. Then p ∈U and ∞∈U
C and these are

6.6.
GENERAL TOPOLOGICAL SPACES
151
disjoint open sets containing the points, p and ∞respectively. Now let C be an
open cover of e
X with sets from eτ. Then ∞must be in some set, U∞from C, which
must contain a set of the form KC where K is a compact subset of X. Then there
exist sets from C, U1, · · ·, Ur which cover K. Therefore, a ﬁnite subcover of e
X is
U1, · · ·, Ur, U∞.
In general topological spaces there may be no concept of “bounded”. Even if
there is, closed and bounded is not necessarily the same as compactness. However,
in any Hausdorﬀspace every compact set must be a closed set.
Theorem 6.53 If (X, τ) is a Hausdorﬀspace, then every compact subset must also
be a closed set.
Proof: Suppose p /∈K. For each x ∈X, there exist open sets, Ux and Vx such
that
x ∈Ux, p ∈Vx,
and
Ux ∩Vx = ∅.
If K is assumed to be compact, there are ﬁnitely many of these sets, Ux1, · · ·, Uxm
which cover K. Then let V ≡∩m
i=1Vxi. It follows that V is an open set containing
p which has empty intersection with each of the Uxi. Consequently, V contains no
points of K and is therefore not a limit point of K. This proves the theorem.
Deﬁnition 6.54 If every ﬁnite subset of a collection of sets has nonempty inter-
section, the collection has the ﬁnite intersection property.
Theorem 6.55 Let K be a set whose elements are compact subsets of a Hausdorﬀ
topological space, (X, τ).
Suppose K has the ﬁnite intersection property.
Then
∅̸= ∩K.
Proof: Suppose to the contrary that ∅= ∩K. Then consider
C ≡
©
KC : K ∈K
ª
.
It follows C is an open cover of K0 where K0 is any particular element of K. But
then there are ﬁnitely many K ∈K, K1, · · ·, Kr such that K0 ⊆∪r
i=1KC
i
implying
that ∩r
i=0Ki = ∅, contradicting the ﬁnite intersection property.
Lemma 6.56 Let (X, τ) be a topological space and let B be a basis for τ. Then K
is compact if and only if every open cover of basic open sets admits a ﬁnite subcover.
Proof: Suppose ﬁrst that X is compact. Then if C is an open cover consisting
of basic open sets, it follows it admits a ﬁnite subcover because these are open sets
in C.
Next suppose that every basic open cover admits a ﬁnite subcover and let C be
an open cover of X. Then deﬁne eC to be the collection of basic open sets which are
contained in some set of C. It follows eC is a basic open cover of X and so it admits

152
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
a ﬁnite subcover, {U1, · · ·, Up}. Now each Ui is contained in an open set of C. Let
Oi be a set of C which contains Ui. Then {O1, · · ·, Op} is an open cover of X. This
proves the lemma.
In fact, much more can be said than Lemma 6.56. However, this is all which I
will present here.
6.7
Connected Sets
Stated informally, connected sets are those which are in one piece. More precisely,
Deﬁnition 6.57 A set, S in a general topological space is separated if there exist
sets, A, B such that
S = A ∪B, A, B ̸= ∅, and A ∩B = B ∩A = ∅.
In this case, the sets A and B are said to separate S. A set is connected if it is not
separated.
One of the most important theorems about connected sets is the following.
Theorem 6.58 Suppose U and V are connected sets having nonempty intersection.
Then U ∪V is also connected.
Proof: Suppose U ∪V = A ∪B where A ∩B = B ∩A = ∅. Consider the sets,
A ∩U and B ∪U. Since
(A ∩U) ∩(B ∩U) = (A ∩U) ∩
¡
B ∩U
¢
= ∅,
It follows one of these sets must be empty since otherwise, U would be separated.
It follows that U is contained in either A or B. Similarly, V must be contained in
either A or B. Since U and V have nonempty intersection, it follows that both V
and U are contained in one of the sets, A, B. Therefore, the other must be empty
and this shows U ∪V cannot be separated and is therefore, connected.
The intersection of connected sets is not necessarily connected as is shown by
the following picture.
U
V

6.7.
CONNECTED SETS
153
Theorem 6.59 Let f : X →Y be continuous where X and Y are topological spaces
and X is connected. Then f (X) is also connected.
Proof: To do this you show f (X) is not separated. Suppose to the contrary
that f (X) = A∪B where A and B separate f (X) . Then consider the sets, f −1 (A)
and f −1 (B) . If z ∈f −1 (B) , then f (z) ∈B and so f (z) is not a limit point of
A. Therefore, there exists an open set, U containing f (z) such that U ∩A = ∅.
But then, the continuity of f implies that f −1 (U) is an open set containing z such
that f −1 (U)∩f −1 (A) = ∅. Therefore, f −1 (B) contains no limit points of f −1 (A) .
Similar reasoning implies f −1 (A) contains no limit points of f −1 (B). It follows
that X is separated by f −1 (A) and f −1 (B) , contradicting the assumption that X
was connected.
An arbitrary set can be written as a union of maximal connected sets called
connected components. This is the concept of the next deﬁnition.
Deﬁnition 6.60 Let S be a set and let p ∈S. Denote by Cp the union of all
connected subsets of S which contain p. This is called the connected component
determined by p.
Theorem 6.61 Let Cp be a connected component of a set S in a general topological
space. Then Cp is a connected set and if Cp ∩Cq ̸= ∅, then Cp = Cq.
Proof: Let C denote the connected subsets of S which contain p. If Cp = A ∪B
where
A ∩B = B ∩A = ∅,
then p is in one of A or B. Suppose without loss of generality p ∈A. Then every
set of C must also be contained in A also since otherwise, as in Theorem 6.58, the
set would be separated. But this implies B is empty. Therefore, Cp is connected.
From this, and Theorem 6.58, the second assertion of the theorem is proved.
This shows the connected components of a set are equivalence classes and par-
tition the set.
A set, I is an interval in R if and only if whenever x, y ∈I then (x, y) ⊆I. The
following theorem is about the connected sets in R.
Theorem 6.62 A set, C in R is connected if and only if C is an interval.
Proof: Let C be connected. If C consists of a single point, p, there is nothing
to prove. The interval is just [p, p] . Suppose p < q and p, q ∈C. You need to show
(p, q) ⊆C. If
x ∈(p, q) \ C
let C ∩(−∞, x) ≡A, and C ∩(x, ∞) ≡B. Then C = A ∪B and the sets, A and B
separate C contrary to the assumption that C is connected.
Conversely, let I be an interval. Suppose I is separated by A and B. Pick x ∈A
and y ∈B. Suppose without loss of generality that x < y. Now deﬁne the set,
S ≡{t ∈[x, y] : [x, t] ⊆A}

154
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES
and let l be the least upper bound of S. Then l ∈A so l /∈B which implies l ∈A.
But if l /∈B, then for some δ > 0,
(l, l + δ) ∩B = ∅
contradicting the deﬁnition of l as an upper bound for S. Therefore, l ∈B which
implies l /∈A after all, a contradiction. It follows I must be connected.
The following theorem is a very useful description of the open sets in R.
Theorem 6.63 Let U be an open set in R. Then there exist countably many dis-
joint open sets, {(ai, bi)}∞
i=1 such that U = ∪∞
i=1 (ai, bi) .
Proof: Let p ∈U and let z ∈Cp, the connected component determined by p.
Since U is open, there exists, δ > 0 such that (z −δ, z + δ) ⊆U. It follows from
Theorem 6.58 that
(z −δ, z + δ) ⊆Cp.
This shows Cp is open. By Theorem 6.62, this shows Cp is an open interval, (a, b)
where a, b ∈[−∞, ∞] . There are therefore at most countably many of these con-
nected components because each must contain a rational number and the rational
numbers are countable. Denote by {(ai, bi)}∞
i=1 the set of these connected compo-
nents. This proves the theorem.
Deﬁnition 6.64 A topological space, E is arcwise connected if for any two points,
p, q ∈E, there exists a closed interval, [a, b] and a continuous function, γ : [a, b] →E
such that γ (a) = p and γ (b) = q. E is locally connected if it has a basis of connected
open sets. E is locally arcwise connected if it has a basis of arcwise connected open
sets.
An example of an arcwise connected topological space would be the any subset
of Rn which is the continuous image of an interval. Locally connected is not the
same as connected. A well known example is the following.
½µ
x, sin 1
x
¶
: x ∈(0, 1]
¾
∪{(0, y) : y ∈[−1, 1]}
(6.12)
You can verify that this set of points considered as a metric space with the metric
from R2 is not locally connected or arcwise connected but is connected.
Proposition 6.65 If a topological space is arcwise connected, then it is connected.
Proof:
Let X be an arcwise connected space and suppose it is separated.
Then X = A ∪B where A, B are two separated sets. Pick p ∈A and q ∈B.
Since X is given to be arcwise connected, there must exist a continuous function
γ : [a, b] →X such that γ (a) = p and γ (b) = q. But then we would have γ ([a, b]) =
(γ ([a, b]) ∩A) ∪(γ ([a, b]) ∩B) and the two sets, γ ([a, b]) ∩A and γ ([a, b]) ∩B are
separated thus showing that γ ([a, b]) is separated and contradicting Theorem 6.62
and Theorem 6.59. It follows that X must be connected as claimed.

6.7.
CONNECTED SETS
155
Theorem 6.66 Let U be an open subset of a locally arcwise connected topological
space, X. Then U is arcwise connected if and only if U if connected. Also the
connected components of an open set in such a space are open sets, hence arcwise
connected.
Proof: By Proposition 6.65 it is only necessary to verify that if U is connected
and open in the context of this theorem, then U is arcwise connected. Pick p ∈U.
Say x ∈U satisﬁes P if there exists a continuous function, γ : [a, b] →U such that
γ (a) = p and γ (b) = x.
A ≡{x ∈U such that x satisﬁes P.}
If x ∈A, there exists, according to the assumption that X is locally arcwise con-
nected, an open set, V, containing x and contained in U which is arcwise connected.
Thus letting y ∈V, there exist intervals, [a, b] and [c, d] and continuous functions
having values in U, γ, η such that γ (a) = p, γ (b) = x, η (c) = x, and η (d) = y.
Then let γ1 : [a, b + d −c] →U be deﬁned as
γ1 (t) ≡
½
γ (t) if t ∈[a, b]
η (t) if t ∈[b, b + d −c]
Then it is clear that γ1 is a continuous function mapping p to y and showing that
V ⊆A. Therefore, A is open. A ̸= ∅because there is an open set, V containing p
which is contained in U and is arcwise connected.
Now consider B ≡U \ A. This is also open. If B is not open, there exists a
point z ∈B such that every open set containing z is not contained in B. Therefore,
letting V be one of the basic open sets chosen such that z ∈V ⊆U, there exist
points of A contained in V. But then, a repeat of the above argument shows z ∈A
also. Hence B is open and so if B ̸= ∅, then U = B ∪A and so U is separated by
the two sets, B and A contradicting the assumption that U is connected.
It remains to verify the connected components are open. Let z ∈Cp where Cp
is the connected component determined by p. Then picking V an arcwise connected
open set which contains z and is contained in U, Cp ∪V is connected and contained
in U and so it must also be contained in Cp. This proves the theorem.
As an application, consider the following corollary.
Corollary 6.67 Let f : Ω→Z
be continuous where Ωis a connected open set.
Then f must be a constant.
Proof: Suppose not. Then it achieves two diﬀerent values, k and l ̸= k. Then
Ω= f −1 (l) ∪f −1 ({m ∈Z : m ̸= l}) and these are disjoint nonempty open sets
which separate Ω. To see they are open, note
f −1 ({m ∈Z : m ̸= l}) = f −1
µ
∪m̸=l
µ
m −1
6, n + 1
6
¶¶
which is the inverse image of an open set.

156
METRIC SPACES AND GENERAL TOPOLOGICAL SPACES

Weierstrass Approximation
Theorem
7.1
The Bernstein Polynomials
This short chapter is on the important Weierstrass approximation theorem. It is
about approximating an arbitrary continuous function uniformly by a polynomial.
It will be assumed only that f has values in C and that all scalars are in C. First
here is some notation.
Deﬁnition 7.1 α = (α1, ···, αn) for α1···αn positive integers is called a multi-index.
For α a multi-index, |α| ≡α1 + · · · + αn and if x ∈Rn,
x = (x1, · · ·, xn) ,
and f a function, deﬁne
xα ≡xα1
1 xα2
2 · · · xαn
n .
A polynomial in n variables of degree m is a function of the form
p (x) =
X
|α|≤m
aαxα.
Here α is a multi-index as just described.
The following estimate will be the basis for the Weierstrass approximation the-
orem. It is actually a statement about the variance of a binomial random variable.
Lemma 7.2 The following estimate holds for x ∈[0, 1].
m
X
k=0
µm
k
¶
(k −mx)2 xk (1 −x)m−k ≤1
4m
157

158
WEIERSTRASS APPROXIMATION THEOREM
Proof: By the Binomial theorem,
m
X
k=0
µm
k
¶ ¡
etx
¢k (1 −x)m−k =
¡
1 −x + etx
¢m .
(7.1)
Diﬀerentiating both sides with respect to t and then evaluating at t = 0 yields
m
X
k=0
µm
k
¶
kxk (1 −x)m−k = mx.
Now doing two derivatives of 7.1 with respect to t yields
Pm
k=0
¡m
k
¢
k2 (etx)k (1 −x)m−k = m (m −1) (1 −x + etx)m−2 e2tx2
+m (1 −x + etx)m−1 xet.
Evaluating this at t = 0,
m
X
k=0
µm
k
¶
k2 (x)k (1 −x)m−k = m (m −1) x2 + mx.
Therefore,
m
X
k=0
µm
k
¶
(k −mx)2 xk (1 −x)m−k
=
m (m −1) x2 + mx −2m2x2 + m2x2
=
m
¡
x −x2¢
≤1
4m.
This proves the lemma.
Now for x = (x1, · · ·, xn) ∈[0, 1]n consider the polynomial,
pm (x) ≡
m
X
k1=1
· · ·
m
X
kn=1
µm
k1
¶µm
k2
¶
· · ·
µm
kn
¶
xk1
1 (1 −x1)m−k1 xk2
2 (1 −x2)m−k2
· · · xkn
n (1 −xn)m−kn f
µk1
m , · · ·, kn
m
¶
.
(7.2)
Also deﬁne if I is a set in Rn
||h||I ≡sup {|h (x)| : x ∈I} .
Thus pm converges uniformly to f on a set, I if
lim
m→∞||pm −f||I = 0.
Also to simplify the notation, let k = (k1, · · ·, kn) where each ki ∈[0, m],
k
m ≡
¡ k1
m , · · ·, kn
m
¢
, and let
µm
k
¶
≡
µm
k1
¶µm
k2
¶
· · ·
µm
kn
¶
.

7.1.
THE BERNSTEIN POLYNOMIALS
159
Also deﬁne
||k||∞≡max {ki, i = 1, 2, · · ·, n}
xk (1 −x)m−k ≡xk1
1 (1 −x1)m−k1 xk2
2 (1 −x2)m−k2 · · · xkn
n (1 −xn)m−kn .
Thus in terms of this notation,
pm (x) =
X
||k||∞≤m
µm
k
¶
xk (1 −x)m−k f
µ k
m
¶
Lemma 7.3 For x ∈[0, 1]n , f a continuous function deﬁned on [0, 1]n , and pm
given in 7.2, pm converges uniformly to f on [0, 1]n as m →∞.
Proof: The function, f is uniformly continuous because it is continuous on a
compact set. Therefore, there exists δ > 0 such that if |x −y| < δ, then
|f (x) −f (y)| < ε.
Denote by G the set of k such that (ki −mxi)2 < η2m2 for each i where η = δ/√n.
Note this condition is equivalent to saying that for each i,
¯¯ ki
m −xi
¯¯ < η. By the
binomial theorem,
X
||k||∞≤m
µm
k
¶
xk (1 −x)m−k = 1
and so for x ∈[0, 1]n ,
|pm (x) −f (x)| ≤
X
||k||∞≤m
µm
k
¶
xk (1 −x)m−k
¯¯¯¯f
µ k
m
¶
−f (x)
¯¯¯¯
≤
X
k∈G
µm
k
¶
xk (1 −x)m−k
¯¯¯¯f
µ k
m
¶
−f (x)
¯¯¯¯
+
X
k∈GC
µm
k
¶
xk (1 −x)m−k
¯¯¯¯f
µ k
m
¶
−f (x)
¯¯¯¯
(7.3)
Now for k ∈G it follows that for each i
¯¯¯¯
ki
m −xi
¯¯¯¯ <
δ
√n
(7.4)
and so
¯¯f
¡ k
m
¢
−f (x)
¯¯ < ε because the above implies
¯¯ k
m −x
¯¯ < δ. Therefore, the
ﬁrst sum on the right in 7.3 is no larger than
X
k∈G
µm
k
¶
xk (1 −x)m−k ε ≤
X
||k||∞≤m
µm
k
¶
xk (1 −x)m−k ε = ε.

160
WEIERSTRASS APPROXIMATION THEOREM
Letting M ≥max {|f (x)| : x ∈[0, 1]n} it follows
|pm (x) −f (x)|
≤
ε + 2M
X
k∈GC
µm
k
¶
xk (1 −x)m−k
≤
ε + 2M
µ
1
η2m2
¶n X
k∈GC
µm
k
¶
n
Y
j=1
(kj −mxj)2 xk (1 −x)m−k
≤
ε + 2M
µ
1
η2m2
¶n
X
||k||∞≤m
µm
k
¶
n
Y
j=1
(kj −mxj)2 xk (1 −x)m−k
because on GC,
(kj −mxj)2
η2m2
< 1, j = 1, · · ·, n.
Now by Lemma 7.2,
|pm (x) −f (x)| ≤ε + 2M
µ
1
η2m2
¶n ³m
4
´n
.
Therefore, since the right side does not depend on x, it follows
lim sup
m→∞||pm −f||[0,1]n ≤ε
and since ε is arbitrary, this shows limm→∞||pm −f||[0,1]n = 0. This proves the
lemma.
The following is not surprising.
Lemma 7.4 Let f be a continuous function deﬁned on [−M, M]n . Then there ex-
ists a sequence of polynomials, {pm} converging uniformly to f on [−M, M]n.
Proof: Let h (t) = −M + 2Mt so h : [0, 1] →[−M, M] and let h (t) ≡
(h (t1) , · · ·, h (tn)) . Therefore, f ◦h is a continuous function deﬁned on [0, 1]n .
From Lemma 7.3 there exists a polynomial, p (t) such that ||pm −f ◦h||[0,1]n < 1
m.
Now for x ∈[−M, M]n , h−1 (x) =
¡
h−1 (x1) , · · ·, h−1 (xn)
¢
and so
¯¯¯¯pm ◦h−1 −f
¯¯¯¯
[−M,M]n = ||pm −f ◦h||[0,1]n < 1
m.
But h−1 (x) =
x
2M + 1
2 and so pm is still a polynomial. This proves the lemma.
The classical version of the Weierstrass approximation theorem involved showing
that a continuous function of one variable deﬁned on a closed and bounded interval
is the uniform limit of a sequence of polynomials. This is certainly included as a
special case of the above. Now recall the Tietze extension theorem found on Page
146. In the general version about to be presented, the set on which f is deﬁned is
just a compact subset of Rn, not the Cartesian product of intervals. For convenience
here is the Tietze extension theorem.

7.2.
STONE WEIERSTRASS THEOREM
161
Theorem 7.5 Let M be a closed nonempty subset of a metric space (X, d) and let
f : M →[a, b] is continuous at every point of M. Then there exists a function, g
continuous on all of X which coincides with f on M such that g (X) ⊆[a, b] .
The Weierstrass approximation theorem follows.
Theorem 7.6 Let K be a compact set in Rn and let f be a continuous function de-
ﬁned on K. Then there exists a sequence of polynomials {pm} converging uniformly
to f on K.
Proof: Choose M large enough that K ⊆[−M, M]n and let ef denote a contin-
uous function deﬁned on all of [−M, M]n such that ef = f on K. Such an extension
exists by the Tietze extension theorem, Theorem 7.5 applied to the real and imagi-
nary parts of f. By Lemma 7.4 there exists a sequence of polynomials, {pm} deﬁned
on [−M, M]n such that
¯¯¯
¯¯¯ ef −pm
¯¯¯
¯¯¯
[−M,M]n →0. Therefore,
¯¯¯
¯¯¯ ef −pm
¯¯¯
¯¯¯
K →0 also.
This proves the theorem.
7.2
Stone Weierstrass Theorem
7.2.1
The Case Of Compact Sets
There is a profound generalization of the Weierstrass approximation theorem due
to Stone.
Deﬁnition 7.7 A is an algebra of functions if A is a vector space and if whenever
f, g ∈A then fg ∈A.
To begin with assume that the ﬁeld of scalars is R. This will be generalized
later. Theorem 7.6 implies the following very special case.
Corollary 7.8 The polynomials are dense in C ([a, b]).
The next result is the key to the profound generalization of the Weierstrass
theorem due to Stone in which an interval will be replaced by a compact or locally
compact set and polynomials will be replaced with elements of an algebra satisfying
certain axioms.
Corollary 7.9 On the interval [−M, M], there exist polynomials pn such that
pn (0) = 0
and
lim
n→∞||pn −|·|||∞= 0.
Proof: By Corollary 7.8 there exists a sequence of polynomials, {˜pn} such that
˜pn →|·| uniformly. Then let pn (t) ≡˜pn (t) −˜pn (0) . This proves the corollary.

162
WEIERSTRASS APPROXIMATION THEOREM
Deﬁnition 7.10 An algebra of functions, A deﬁned on A, annihilates no point of
A if for all x ∈A, there exists g ∈A such that g (x) ̸= 0. The algebra separates
points if whenever x1 ̸= x2, then there exists g ∈A such that g (x1) ̸= g (x2).
The following generalization is known as the Stone Weierstrass approximation
theorem.
Theorem 7.11 Let A be a compact topological space and let A ⊆C (A; R) be an
algebra of functions which separates points and annihilates no point. Then A is
dense in C (A; R).
Proof: First here is a lemma.
Lemma 7.12 Let c1 and c2 be two real numbers and let x1 ̸= x2 be two points of
A. Then there exists a function fx1x2 such that
fx1x2 (x1) = c1, fx1x2 (x2) = c2.
Proof of the lemma: Let g ∈A satisfy
g (x1) ̸= g (x2).
Such a g exists because the algebra separates points. Since the algebra annihilates
no point, there exist functions h and k such that
h (x1) ̸= 0, k (x2) ̸= 0.
Then let
u ≡gh −g (x2) h, v ≡gk −g (x1) k.
It follows that u (x1) ̸= 0 and u (x2) = 0 while v (x2) ̸= 0 and v (x1) = 0. Let
fx1x2 ≡
c1u
u (x1) +
c2v
v (x2).
This proves the lemma. Now continue the proof of Theorem 7.11.
First note that A satisﬁes the same axioms as A but in addition to these axioms,
A is closed. The closure of A is taken with respect to the usual norm on C (A),
||f||∞≡max {|f (x)| : x ∈A} .
Suppose f ∈A and suppose M is large enough that
||f||∞< M.
Using Corollary 7.9, let pn be a sequence of polynomials such that
||pn −|·|||∞→0, pn (0) = 0.

7.2.
STONE WEIERSTRASS THEOREM
163
It follows that pn ◦f ∈A and so |f| ∈A whenever f ∈A. Also note that
max (f, g) = |f −g| + (f + g)
2
min (f, g) = (f + g) −|f −g|
2
.
Therefore, this shows that if f, g ∈A then
max (f, g) , min (f, g) ∈A.
By induction, if fi, i = 1, 2, · · ·, m are in A then
max (fi, i = 1, 2, · · ·, m) , min (fi, i = 1, 2, · · ·, m) ∈A.
Now let h ∈C (A; R) and let x ∈A. Use Lemma 7.12 to obtain fxy, a function
of A which agrees with h at x and y. Letting ε > 0, there exists an open set U (y)
containing y such that
fxy (z) > h (z) −ε if z ∈U(y).
Since A is compact, let U (y1) , · · ·, U (yl) cover A. Let
fx ≡max (fxy1, fxy2, · · ·, fxyl).
Then fx ∈A and
fx (z) > h (z) −ε
for all z ∈A and fx (x) = h (x). This implies that for each x ∈A there exists an
open set V (x) containing x such that for z ∈V (x),
fx (z) < h (z) + ε.
Let V (x1) , · · ·, V (xm) cover A and let
f ≡min (fx1, · · ·, fxm).
Therefore,
f (z) < h (z) + ε
for all z ∈A and since fx (z) > h (z) −ε for all z ∈A, it follows
f (z) > h (z) −ε
also and so
|f (z) −h (z)| < ε
for all z. Since ε is arbitrary, this shows h ∈A and proves A = C (A; R). This
proves the theorem.

164
WEIERSTRASS APPROXIMATION THEOREM
7.2.2
The Case Of Locally Compact Sets
Deﬁnition 7.13 Let (X, τ) be a locally compact Hausdorﬀspace. C0 (X) denotes
the space of real or complex valued continuous functions deﬁned on X with the
property that if f ∈C0 (X) , then for each ε > 0 there exists a compact set K such
that |f (x)| < ε for all x /∈K. Deﬁne
||f||∞= sup {|f (x)| : x ∈X}.
Lemma 7.14 For (X, τ) a locally compact Hausdorﬀspace with the above norm,
C0 (X) is a complete space.
Proof: Let
³
e
X, eτ
´
be the one point compactiﬁcation described in Lemma 6.52.
D ≡
n
f ∈C
³
e
X
´
: f (∞) = 0
o
.
Then D is a closed subspace of C
³
e
X
´
. For f ∈C0 (X) ,
ef (x) ≡
½ f (x) if x ∈X
0 if x = ∞
and let θ : C0 (X) →D be given by θf = ef. Then θ is one to one and onto and also
satisﬁes ||f||∞= ||θf||∞. Now D is complete because it is a closed subspace of a
complete space and so C0 (X) with ||·||∞is also complete. This proves the lemma.
The above refers to functions which have values in C but the same proof works
for functions which have values in any complete normed linear space.
In the case where the functions in C0 (X) all have real values, I will denote the
resulting space by C0 (X; R) with similar meanings in other cases.
With this lemma, the generalization of the Stone Weierstrass theorem to locally
compact sets is as follows.
Theorem 7.15 Let A be an algebra of functions in C0 (X; R) where (X, τ) is a
locally compact Hausdorﬀspace which separates the points and annihilates no point.
Then A is dense in C0 (X; R).
Proof: Let
³
e
X, eτ
´
be the one point compactiﬁcation as described in Lemma
6.52. Let e
A denote all ﬁnite linear combinations of the form
( n
X
i=1
ci efi + c0 : f ∈A, ci ∈R
)
where for f ∈C0 (X; R) ,
ef (x) ≡
½
f (x) if x ∈X
0 if x = ∞
.

7.2.
STONE WEIERSTRASS THEOREM
165
Then e
A is obviously an algebra of functions in C
³
e
X; R
´
. It separates points because
this is true of A. Similarly, it annihilates no point because of the inclusion of c0 an
arbitrary element of R in the deﬁnition above. Therefore from Theorem 7.11, e
A is
dense in C
³
e
X; R
´
. Letting f ∈C0 (X; R) , it follows ef ∈C
³
e
X; R
´
and so there
exists a sequence {hn} ⊆e
A such that hn converges uniformly to ef. Now hn is of
the form Pn
i=1 cn
i f
f n
i + cn
0 and since ef (∞) = 0, you can take each cn
0 = 0 and so
this has shown the existence of a sequence of functions in A such that it converges
uniformly to f. This proves the theorem.
7.2.3
The Case Of Complex Valued Functions
What about the general case where C0 (X) consists of complex valued functions
and the ﬁeld of scalars is C rather than R? The following is the version of the Stone
Weierstrass theorem which applies to this case. You have to assume that for f ∈A
it follows f ∈A. Such an algebra is called self adjoint.
Theorem 7.16 Suppose A is an algebra of functions in C0 (X) , where X is a
locally compact Hausdorﬀspace, which separates the points, annihilates no point,
and has the property that if f ∈A, then f ∈A. Then A is dense in C0 (X).
Proof: Let Re A ≡{Re f : f ∈A}, Im A ≡{Im f : f ∈A}. First I will show
that A = Re A + i Im A = Im A + i Re A. Let f ∈A. Then
f = 1
2
¡
f + f
¢
+ 1
2
¡
f −f
¢
= Re f + i Im f ∈Re A + i Im A
and so A ⊆Re A + i Im A. Also
f = 1
2i
¡
if + if
¢
−i
2
³
if + (if)
´
= Im (if) + i Re (if) ∈Im A + i Re A
This proves one half of the desired equality. Now suppose h ∈Re A + i Im A. Then
h = Re g1 +i Im g2 where gi ∈A. Then since Re g1 = 1
2 (g1 + g1) , it follows Re g1 ∈
A. Similarly Im g2 ∈A. Therefore, h ∈A. The case where h ∈Im A + i Re A is
similar. This establishes the desired equality.
Now Re A and Im A are both real algebras. I will show this now. First consider
Im A.
It is obvious this is a real vector space.
It only remains to verify that
the product of two functions in Im A is in Im A. Note that from the ﬁrst part,
Re A, Im A are both subsets of A because, for example, if u ∈Im A then u + 0 ∈
Im A + i Re A = A.
Therefore, if v, w ∈Im A, both iv and w are in A and so
Im (ivw) = vw and ivw ∈A. Similarly, Re A is an algebra.
Both Re A and Im A must separate the points. Here is why: If x1 ̸= x2, then
there exists f ∈A such that f (x1) ̸= f (x2) . If Im f (x1) ̸= Im f (x2) , this shows
there is a function in Im A, Im f which separates these two points. If Im f fails
to separate the two points, then Re f must separate the points and so you could
consider Im (if) to get a function in Im A which separates these points. This shows
Im A separates the points. Similarly Re A separates the points.

166
WEIERSTRASS APPROXIMATION THEOREM
Neither Re A nor Im A annihilate any point. This is easy to see because if x
is a point there exists f ∈A such that f (x) ̸= 0. Thus either Re f (x) ̸= 0 or
Im f (x) ̸= 0. If Im f (x) ̸= 0, this shows this point is not annihilated by Im A.
If Im f (x) = 0, consider Im (if) (x) = Re f (x) ̸= 0. Similarly, Re A does not
annihilate any point.
It follows from Theorem 7.15 that Re A and Im A are dense in the real valued
functions of C0 (X). Let f ∈C0 (X) . Then there exists {hn} ⊆Re A and {gn} ⊆
Im A such that hn →Re f uniformly and gn →Im f uniformly. Therefore, hn +
ign ∈A and it converges to f uniformly. This proves the theorem.
7.3
Exercises
1. Let (X, τ) , (Y, η) be topological spaces and let A ⊆X be compact. Then if
f : X →Y is continuous, show that f (A) is also compact.
2. ↑In the context of Problem 1, suppose R = Y where the usual topology is
placed on R. Show f achieves its maximum and minimum on A.
3. Let V be an open set in Rn. Show there is an increasing sequence of compact
sets, Km, such that V = ∪∞
m=1Km. Hint: Let
Cm ≡
½
x ∈Rn : dist
¡
x,V C¢
≥1
m
¾
where
dist (x,S) ≡inf {|y −x| such that y ∈S}.
Consider Km ≡Cm ∩B (0,m).
4. Let B (X; Rn) be the space of functions f, mapping X to Rn such that
sup{|f (x)| : x ∈X} < ∞.
Show B (X; Rn) is a complete normed linear space if
||f|| ≡sup{|f (x)| : x ∈X}.
5. Let α ∈[0, 1]. Deﬁne, for X a compact subset of Rp,
Cα (X; Rn) ≡{f ∈C (X; Rn) : ρα (f) + ||f|| ≡||f||α < ∞}
where
||f|| ≡sup{|f (x)| : x ∈X}
and
ρα (f) ≡sup{|f (x) −f (y)|
|x −y|α
: x, y ∈X, x ̸= y}.
Show that (Cα (X; Rn) , ||·||α) is a complete normed linear space.

7.3.
EXERCISES
167
6. Let {fn}∞
n=1 ⊆Cα (X; Rn) where X is a compact subset of Rp and suppose
||fn||α ≤M
for all n. Show there exists a subsequence, nk, such that fnk converges in
C (X; Rn). The given sequence is called precompact when this happens. (This
also shows the embedding of Cα (X; Rn) into C (X; Rn) is a compact embed-
ding.)
7. Use the general Stone Weierstrass approximation theorem to prove Theorem
7.6.
8. Let (X, d) be a metric space where d is a bounded metric. Let C denote the
collection of closed subsets of X. For A, B ∈C, deﬁne
ρ (A, B) ≡inf {δ > 0 : Aδ ⊇B and Bδ ⊇A}
where for a set S,
Sδ ≡{x : dist (x, S) ≡inf {d (x, s) : s ∈S} ≤δ} .
Show x →dist (x, S) is continuous and that therefore, Sδ is a closed set
containing S. Also show that ρ is a metric on C. This is called the Hausdorﬀ
metric.
9. ↑Suppose (X, d) is a compact metric space. Show (C, ρ) is a complete met-
ric space.
Hint:
Show ﬁrst that if Wn ↓W where Wn is closed, then
ρ (Wn, W) →0. Now let {An} be a Cauchy sequence in C. Then if ε > 0
there exists N such that when m, n ≥N, then ρ (An, Am) < ε. Therefore, for
each n ≥N,
(An)ε ⊇∪∞
k=nAk.
Let A ≡∩∞
n=1∪∞
k=nAk. By the ﬁrst part, there exists N1 > N such that for
n ≥N1,
ρ
¡
∪∞
k=nAk, A
¢
< ε, and (An)ε ⊇∪∞
k=nAk.
Therefore, for such n, Aε ⊇Wn ⊇An and (Wn)ε ⊇(An)ε ⊇A because
(An)ε ⊇∪∞
k=nAk ⊇A.
10. ↑Let X be a compact metric space. Show (C, ρ) is compact. Hint: Let Dn
be a 2−n net for X. Let Kn denote ﬁnite unions of sets of the form B (p, 2−n)
where p ∈Dn. Show Kn is a 2−(n−1) net for (C, ρ) .

168
WEIERSTRASS APPROXIMATION THEOREM

Part II
Real And Abstract Analysis
169


Abstract Measure And
Integration
8.1
σ Algebras
This chapter is on the basics of measure theory and integration. A measure is a real
valued mapping from some subset of the power set of a given set which has values
in [0, ∞]. Many apparently diﬀerent things can be considered as measures and also
there is an integral deﬁned. By discussing this in terms of axioms and in a very
abstract setting, many diﬀerent topics can be considered in terms of one general
theory. For example, it will turn out that sums are included as an integral of this
sort. So is the usual integral as well as things which are often thought of as being
in between sums and integrals.
Let Ωbe a set and let F be a collection of subsets of Ωsatisfying
∅∈F, Ω∈F,
(8.1)
E ∈F implies EC ≡Ω\ E ∈F,
If {En}∞
n=1 ⊆F, then ∪∞
n=1 En ∈F.
(8.2)
Deﬁnition 8.1 A collection of subsets of a set, Ω, satisfying Formulas 8.1-8.2 is
called a σ algebra.
As an example, let Ωbe any set and let F = P(Ω), the set of all subsets of Ω
(power set). This obviously satisﬁes Formulas 8.1-8.2.
Lemma 8.2 Let C be a set whose elements are σ algebras of subsets of Ω. Then
∩C is a σ algebra also.
Be sure to verify this lemma. It follows immediately from the above deﬁnitions
but it is important for you to check the details.
Example 8.3 Let τ denote the collection of all open sets in Rnand let σ (τ) ≡
intersection of all σ algebras that contain τ. σ (τ) is called the σ algebra of Borel
sets . In general, for a collection of sets, Σ, σ (Σ) is the smallest σ algebra which
contains Σ.
171

172
ABSTRACT MEASURE AND INTEGRATION
This is a very important σ algebra and it will be referred to frequently as the
Borel sets. Attempts to describe a typical Borel set are more trouble than they are
worth and it is not easy to do so. Rather, one uses the deﬁnition just given in the
example. Note, however, that all countable intersections of open sets and countable
unions of closed sets are Borel sets. Such sets are called Gδ and Fσ respectively.
Deﬁnition 8.4 Let F
be a σ algebra of sets of Ωand let µ : F →[0, ∞]. µ is
called a measure if
µ(
∞
[
i=1
Ei) =
∞
X
i=1
µ(Ei)
(8.3)
whenever the Ei are disjoint sets of F.
The triple, (Ω, F, µ) is called a measure
space and the elements of F are called the measurable sets. (Ω, F, µ) is a ﬁnite
measure space when µ (Ω) < ∞.
The following theorem is the basis for most of what is done in the theory of
measure and integration. It is a very simple result which follows directly from the
above deﬁnition.
Theorem 8.5 Let {Em}∞
m=1 be a sequence of measurable sets in a measure space
(Ω, F, µ). Then if · · ·En ⊆En+1 ⊆En+2 ⊆· · ·,
µ(∪∞
i=1Ei) = lim
n→∞µ(En)
(8.4)
and if · · ·En ⊇En+1 ⊇En+2 ⊇· · · and µ(E1) < ∞, then
µ(∩∞
i=1Ei) = lim
n→∞µ(En).
(8.5)
Stated more succinctly, Ek ↑E implies µ (Ek) ↑µ (E) and Ek ↓E with µ (E1) < ∞
implies µ (Ek) ↓µ (E).
Proof: First note that ∩∞
i=1Ei = (∪∞
i=1EC
i )C ∈F so ∩∞
i=1Ei is measurable.
Also note that for A and B sets of F, A \ B ≡
¡
AC ∪B
¢C ∈F. To show 8.4, note
that 8.4 is obviously true if µ(Ek) = ∞for any k. Therefore, assume µ(Ek) < ∞
for all k. Thus
µ(Ek+1 \ Ek) + µ(Ek) = µ(Ek+1)
and so
µ(Ek+1 \ Ek) = µ(Ek+1) −µ(Ek).
Also,
∞
[
k=1
Ek = E1 ∪
∞
[
k=1
(Ek+1 \ Ek)
and the sets in the above union are disjoint. Hence by 8.3,
µ(∪∞
i=1Ei) = µ(E1) +
∞
X
k=1
µ(Ek+1 \ Ek) = µ(E1)

8.1.
σ ALGEBRAS
173
+
∞
X
k=1
µ(Ek+1) −µ(Ek)
= µ(E1) + lim
n→∞
n
X
k=1
µ(Ek+1) −µ(Ek) = lim
n→∞µ(En+1).
This shows part 8.4.
To verify 8.5,
µ(E1) = µ(∩∞
i=1Ei) + µ(E1 \ ∩∞
i=1Ei)
since µ(E1) < ∞, it follows µ(∩∞
i=1Ei) < ∞. Also, E1 \ ∩n
i=1Ei ↑E1 \ ∩∞
i=1Ei and
so by 8.4,
µ(E1) −µ(∩∞
i=1Ei) = µ(E1 \ ∩∞
i=1Ei) = lim
n→∞µ(E1 \ ∩n
i=1Ei)
= µ(E1) −lim
n→∞µ(∩n
i=1Ei) = µ(E1) −lim
n→∞µ(En),
Hence, subtracting µ (E1) from both sides,
lim
n→∞µ(En) = µ(∩∞
i=1Ei).
This proves the theorem.
It is convenient to allow functions to take the value +∞. You should think of
+∞, usually referred to as ∞as something out at the right end of the real line and
its only importance is the notion of sequences converging to it. xn →∞exactly
when for all l ∈R, there exists N such that if n ≥N, then
xn > l.
This is what it means for a sequence to converge to ∞. Don’t think of ∞as a
number. It is just a convenient symbol which allows the consideration of some limit
operations more simply. Similar considerations apply to −∞but this value is not
of very great interest. In fact the set of most interest is the complex numbers or
some vector space. Therefore, this topic is not considered.
Lemma 8.6 Let f : Ω→(−∞, ∞] where F is a σ algebra of subsets of Ω. Then
the following are equivalent.
f −1((d, ∞]) ∈F for all ﬁnite d,
f −1((−∞, d)) ∈F for all ﬁnite d,
f −1([d, ∞]) ∈F for all ﬁnite d,
f −1((−∞, d]) ∈F for all ﬁnite d,
f −1 ((a, b)) ∈F for all a < b, −∞< a < b < ∞.

174
ABSTRACT MEASURE AND INTEGRATION
Proof: First note that the ﬁrst and the third are equivalent. To see this, observe
f −1([d, ∞]) = ∩∞
n=1f −1((d −1/n, ∞]),
and so if the ﬁrst condition holds, then so does the third.
f −1((d, ∞]) = ∪∞
n=1f −1([d + 1/n, ∞]),
and so if the third condition holds, so does the ﬁrst.
Similarly, the second and fourth conditions are equivalent. Now
f −1((−∞, d]) = (f −1((d, ∞]))C
so the ﬁrst and fourth conditions are equivalent. Thus the ﬁrst four conditions are
equivalent and if any of them hold, then for −∞< a < b < ∞,
f −1((a, b)) = f −1((−∞, b)) ∩f −1((a, ∞]) ∈F.
Finally, if the last condition holds,
f −1 ([d, ∞]) =
¡
∪∞
k=1f −1 ((−k + d, d))
¢C ∈F
and so the third condition holds. Therefore, all ﬁve conditions are equivalent. This
proves the lemma.
This lemma allows for the following deﬁnition of a measurable function having
values in (−∞, ∞].
Deﬁnition 8.7 Let (Ω, F, µ) be a measure space and let f : Ω→(−∞, ∞]. Then
f is said to be measurable if any of the equivalent conditions of Lemma 8.6 hold.
When the σ algebra, F equals the Borel σ algebra, B, the function is called Borel
measurable. More generally, if f : Ω→X where X is a topological space, f is said
to be measurable if f −1 (U) ∈F whenever U is open.
Theorem 8.8 Let fn and f be functions mapping Ωto (−∞, ∞] where F is a σ al-
gebra of measurable sets of Ω. Then if fn is measurable, and f(ω) = limn→∞fn(ω),
it follows that f is also measurable. (Pointwise limits of measurable functions are
measurable.)
Proof:
First is is shown f −1 ((a, b)) ∈F.
Let Vm ≡
¡
a + 1
m, b −1
m
¢
and
V m =
£
a + 1
m, b −1
m
¤
. Then for all m, Vm ⊆(a, b) and
(a, b) = ∪∞
m=1Vm = ∪∞
m=1V m.
Note that Vm ̸= ∅for all m large enough. Since f is the pointwise limit of fn,
f −1(Vm) ⊆{ω : fk(ω) ∈Vm for all k large enough} ⊆f −1(V m).
You should note that the expression in the middle is of the form
∪∞
n=1 ∩∞
k=n f −1
k (Vm).

8.1.
σ ALGEBRAS
175
Therefore,
f −1((a, b)) = ∪∞
m=1f −1(Vm) ⊆∪∞
m=1 ∪∞
n=1 ∩∞
k=nf −1
k (Vm)
⊆∪∞
m=1f −1(V m) = f −1((a, b)).
It follows f −1((a, b)) ∈F because it equals the expression in the middle which is
measurable. This shows f is measurable.
The following theorem considers the case of functions which have values in a
metric space. Its proof is similar to the proof of the above.
Theorem 8.9 Let {fn} be a sequence of measurable functions mapping Ωto (X, d)
where (X, d) is a metric space and (Ω, F) is a measure space. Suppose also that
f (ω) = limn→∞fn (ω) for all ω. Then f is also a measurable function.
Proof: It is required to show f −1 (U) is measurable for all U open. Let
Vm ≡
½
x ∈U : dist
¡
x, U C¢
> 1
m
¾
.
Thus
Vm ⊆
½
x ∈U : dist
¡
x, U C¢
≥1
m
¾
and Vm ⊆Vm ⊆Vm+1 and ∪mVm = U. Then since Vm is open,
f −1 (Vm) = ∪∞
n=1 ∩∞
k=n f −1
k
(Vm)
and so
f −1 (U)
=
∪∞
m=1f −1 (Vm)
=
∪∞
m=1 ∪∞
n=1 ∩∞
k=nf −1
k
(Vm)
⊆
∪∞
m=1f −1 ¡
Vm
¢
= f −1 (U)
which shows f −1 (U) is measurable.
Now here is a simple observation.
Observation 8.10 Let f : Ω→X where X is some topological space. Suppose
f (ω) =
m
X
k=1
xkXAk (ω)
where each xk ∈X and the Ak are disjoint measurable sets. (Such functions are
often referred to as simple functions.) Then f is measurable.
Proof: Letting U be open, f −1 (U) = ∪{Ak : xk ∈U} , a ﬁnite union of mea-
surable sets.
There is also a very interesting theorem due to Kuratowski [34] which is pre-
sented next.

176
ABSTRACT MEASURE AND INTEGRATION
Theorem 8.11 Let E be a compact metric space and let (Ω, F) be a measure space.
Suppose ψ : E × Ω→R has the property that x →ψ (x, ω) is continuous and
ω →ψ (x, ω) is measurable.
Then there exists a measurable function, f having
values in E such that
ψ (f (ω) , ω) = sup
x∈E
ψ (x, ω) .
Furthermore, ω →ψ (f (ω) , ω) is measurable.
Proof: Let C1 be a 2−1 net of E. Suppose C1, ···, Cm have been chosen such that
Ck is a 2−k net and Ci+1 ⊇Ci for all i. Then consider E\∪
©
B
¡
x, 2−(m+1)¢
: x ∈Cm
ª
.
If this set is empty, let Cm+1 = Cm. If it is nonempty, let {yi}r
i=1 be a 2−(m+1) net
for this compact set. Then let Cm+1 = Cm ∪{yi}r
i=1 . It follows {Cm}∞
m=1 satisﬁes
Cm is a 2−m net and Cm ⊆Cm+1.
Let
©
x1
k
ªm(1)
k=1 equal C1. Let
A1
1 ≡
½
ω : ψ
¡
x1
1, ω
¢
= max
k
ψ
¡
x1
k, ω
¢¾
For ω ∈A1
1, deﬁne s1 (ω) ≡x1
1. Next let
A1
2 ≡
½
ω /∈A1
1 : ψ
¡
x1
2, ω
¢
= max
k
ψ
¡
x1
k, ω
¢¾
and let s1 (ω) ≡x1
2 on A1
2. Continue in this way to obtain a simple function, s1
such that
ψ (s1 (ω) , ω) = max {ψ (x, ω) : x ∈C1}
and s1 has values in C1.
Suppose s1 (ω) , s2 (ω) , · · ·, sm (ω) are simple functions with the property that if
m > 1,
|sk (ω) −sk+1 (ω)|
<
2−k,
ψ (sk (ω) , ω)
=
max {ψ (x, ω) : x ∈Ck}
sk has values in Ck
for each k + 1 ≤m, only the second and third assertions holding if m = 1. Letting
Cm = {xk}N
k=1 , it follows sm (ω) is of the form
sm (ω) =
N
X
k=1
xkXAk (ω) , Ai ∩Aj = ∅.
(8.6)
Denote by {y1i}n1
i=1 those points of Cm+1 which are contained in B (x1, 2−m) . Let-
ting Ak play the role of Ωin the ﬁrst step in which s1 was constructed, for each
ω ∈A1 let sm+1 (ω) be a simple function which has one of the values y1i and satisﬁes
ψ (sm+1 (ω) , ω) = max
i≤n1 ψ (y1i, ω)

8.1.
σ ALGEBRAS
177
for each ω ∈A1. Next let {y2i}n2
i=1 be those points of Cm+1 diﬀerent than {y1i}n1
i=1
which are contained in B (x2, 2−m). Then deﬁne sm+1 (ω) on A2 to have values
taken from {y2i}n2
i=1 and
ψ (sm+1 (ω) , ω) = max
i≤n2 ψ (y2i, ω)
for each ω ∈A2. Continuing this way deﬁnes sm+1 on all of Ωand it satisﬁes
|sm (ω) −sm+1 (ω)| < 2−m for all ω ∈Ω
(8.7)
It remains to verify
ψ (sm+1 (ω) , ω) = max {ψ (x, ω) : x ∈Cm+1} .
(8.8)
To see this is so, pick ω ∈Ω. Let
max {ψ (x, ω) : x ∈Cm+1} = ψ (yj, ω)
(8.9)
where yj ∈Cm+1 and out of all the balls B (xl, 2−m) , the ﬁrst one which contains
yj is B (xk, 2−m). Then by the construction, sm+1 (ω) = yj. This and 8.9 veriﬁes
8.8.
From 8.7 it follows sm (ω) converges uniformly on Ωto a measurable function,
f (ω) . Then from the construction, ψ (f (ω) , ω) ≥ψ (sm (ω) , ω) for all m and ω.
Now pick ω ∈Ωand let z be such that ψ (z, ω) = maxx∈E ψ (x, ω). Letting yk →z
where yk ∈Ck, it follows from continuity of ψ in the ﬁrst argument that
max
x∈E ψ (x, ω)
=
ψ (z, ω) = lim
k→∞ψ (yk, ω)
≤
lim
m→∞ψ (sm (ω) , ω) = ψ (f (ω) , ω) ≤max
x∈E ψ (x, ω) .
To show ω →ψ (f (ω) , ω) is measurable, note that since E is compact, there exists
a countable dense subset, D. Then using continuity of ψ in the ﬁrst argument,
ψ (f (ω) , ω)
=
sup
x∈E
ψ (x, ω)
=
sup
x∈D
ψ (x, ω)
which equals a measurable function of ω because D is countable. This proves the
theorem.
Theorem 8.12 Let B consist of open cubes of the form
Qx ≡
n
Y
i=1
(xi −δ, xi + δ)
where δ is a positive rational number and x ∈Qn. Then every open set in Rn can be
written as a countable union of open cubes from B. Furthermore, B is a countable
set.

178
ABSTRACT MEASURE AND INTEGRATION
Proof: Let U be an open set and let y ∈U. Since U is open, B (y, r) ⊆U for
some r > 0 and it can be assumed r/√n ∈Q. Let
x ∈B
µ
y,
r
10√n
¶
∩Qn
and consider the cube, Qx ∈B deﬁned by
Qx ≡
n
Y
i=1
(xi −δ, xi + δ)
where δ = r/4√n. The following picture is roughly illustrative of what is taking
place.
qy
qx
Qx
B(y, r)
Then the diameter of Qx equals
Ã
n
µ
r
2√n
¶2!1/2
= r
2
and so, if z ∈Qx, then
|z −y|
≤
|z −x| + |x −y|
<
r
2 + r
2 = r.
Consequently, Qx ⊆U. Now also,
Ã n
X
i=1
(xi −yi)2
!1/2
<
r
10√n
and so it follows that for each i,
|xi −yi| <
r
4√n

8.1.
σ ALGEBRAS
179
since otherwise the above inequality would not hold. Therefore, y ∈Qx ⊆U. Now
let BU denote those sets of B which are contained in U. Then ∪BU = U.
To see B is countable, note there are countably many choices for x and countably
many choices for δ. This proves the theorem.
Recall that g : Rn →R is continuous means g−1 (open set) = an open set. In
particular g−1 ((a, b)) must be an open set.
Theorem 8.13 Let fi : Ω→R for i = 1, · · ·, n be measurable functions and let
g : Rn →R be continuous where f ≡(f1 ···fn)T . Then g◦f is a measurable function
from Ωto R.
Proof: First it is shown
(g ◦f)−1 ((a, b)) ∈F.
Now (g ◦f)−1 ((a, b)) = f −1 ¡
g−1 ((a, b))
¢
and since g is continuous, it follows that
g−1 ((a, b)) is an open set which is denoted as U for convenience. Now by Theorem
8.12 above, it follows there are countably many open cubes, {Qk} such that
U = ∪∞
k=1Qk
where each Qk is a cube of the form
Qk =
n
Y
i=1
(xi −δ, xi + δ) .
Now
f −1
Ã n
Y
i=1
(xi −δ, xi + δ)
!
= ∩n
i=1f −1
i
((xi −δ, xi + δ)) ∈F
and so
(g ◦f)−1 ((a, b))
=
f −1 ¡
g−1 ((a, b))
¢
= f −1 (U)
=
f −1 (∪∞
k=1Qk) = ∪∞
k=1f −1 (Qk) ∈F.
This proves the theorem.
Corollary 8.14 Sums, products, and linear combinations of measurable functions
are measurable.
Proof: To see the product of two measurable functions is measurable, let
g (x, y) = xy, a continuous function deﬁned on R2. Thus if you have two mea-
surable functions, f1 and f2 deﬁned on Ω,
g ◦(f1, f2) (ω) = f1 (ω) f2 (ω)
and so ω →f1 (ω) f2 (ω) is measurable. Similarly you can show the sum of two
measurable functions is measurable by considering g (x, y) = x + y and you can

180
ABSTRACT MEASURE AND INTEGRATION
show a linear combination of two measurable functions is measurable by considering
g (x, y) = ax + by. More than two functions can also be considered as well.
The message of this corollary is that starting with measurable real valued func-
tions you can combine them in pretty much any way you want and you end up with
a measurable function.
Here is some notation which will be used whenever convenient.
Deﬁnition 8.15 Let f : Ω→[−∞, ∞]. Deﬁne
[α < f] ≡{ω ∈Ω: f (ω) > α} ≡f −1 ((α, ∞])
with obvious modiﬁcations for the symbols [α ≤f] , [α ≥f] , [α ≥f ≥β], etc.
Deﬁnition 8.16 For a set E,
XE(ω) =
½ 1 if ω ∈E,
0 if ω /∈E.
This is called the characteristic function of E.
Sometimes this is called the
indicator function which I think is better terminology since the term characteristic
function has another meaning. Note that this “indicates” whether a point, ω is
contained in E. It is exactly when the function has the value 1.
Theorem 8.17 (Egoroﬀ) Let (Ω, F, µ) be a ﬁnite measure space,
(µ(Ω) < ∞)
and let fn, f be complex valued functions such that Re fn, Im fn are all measurable
and
lim
n→∞fn(ω) = f(ω)
for all ω /∈E where µ(E) = 0. Then for every ε > 0, there exists a set,
F ⊇E, µ(F) < ε,
such that fn converges uniformly to f on F C.
Proof: First suppose E = ∅so that convergence is pointwise everywhere. It
follows then that Re f and Im f are pointwise limits of measurable functions and
are therefore measurable. Let Ekm = {ω ∈Ω: |fn(ω) −f(ω)| ≥1/m for some
n > k}. Note that
|fn (ω) −f (ω)| =
q
(Re fn (ω) −Re f (ω))2 + (Im fn (ω) −Im f (ω))2
and so, By Theorem 8.13,
·
|fn −f| ≥1
m
¸

8.1.
σ ALGEBRAS
181
is measurable. Hence Ekm is measurable because
Ekm = ∪∞
n=k+1
·
|fn −f| ≥1
m
¸
.
For ﬁxed m, ∩∞
k=1Ekm = ∅because fn converges to f . Therefore, if ω ∈Ωthere
exists k such that if n > k, |fn (ω) −f (ω)| <
1
m which means ω /∈Ekm. Note also
that
Ekm ⊇E(k+1)m.
Since µ(E1m) < ∞, Theorem 8.5 on Page 172 implies
0 = µ(∩∞
k=1Ekm) = lim
k→∞µ(Ekm).
Let k(m) be chosen such that µ(Ek(m)m) < ε2−m and let
F =
∞
[
m=1
Ek(m)m.
Then µ(F) < ε because
µ (F) ≤
∞
X
m=1
µ
¡
Ek(m)m
¢
<
∞
X
m=1
ε2−m = ε
Now let η > 0 be given and pick m0 such that m−1
0
< η. If ω ∈F C, then
ω ∈
∞
\
m=1
EC
k(m)m.
Hence ω ∈EC
k(m0)m0 so
|fn(ω) −f(ω)| < 1/m0 < η
for all n > k(m0). This holds for all ω ∈F Cand so fn converges uniformly to f on
F C.
Now if E ̸= ∅, consider {XECfn}∞
n=1 . Each XECfn has real and imaginary
parts measurable and the sequence converges pointwise to XEf everywhere. There-
fore, from the ﬁrst part, there exists a set of measure less than ε, F such that on
F C, {XECfn} converges uniformly to XECf. Therefore, on (E ∪F)C , {fn} con-
verges uniformly to f. This proves the theorem.
Finally here is a comment about notation.
Deﬁnition 8.18 Something happens for µ a.e. ω said as µ almost everywhere, if
there exists a set E with µ(E) = 0 and the thing takes place for all ω /∈E. Thus
f(ω) = g(ω) a.e. if f(ω) = g(ω) for all ω /∈E where µ(E) = 0. A measure space,
(Ω, F, µ) is σ ﬁnite if there exist measurable sets, Ωn such that µ (Ωn) < ∞and
Ω= ∪∞
n=1Ωn.

182
ABSTRACT MEASURE AND INTEGRATION
8.2
Exercises
1. Let Ω= N ={1, 2, · · ·}. Let F = P(N) and let µ(S) = number of elements in
S. Thus µ({1}) = 1 = µ({2}), µ({1, 2}) = 2, etc. Show (Ω, F, µ) is a measure
space. It is called counting measure. What functions are measurable in this
case?
2. Let Ωbe any uncountable set and let F = {A ⊆Ω: either A or AC is
countable}. Let µ(A) = 1 if A is uncountable and µ(A) = 0 if A is countable.
Show (Ω, F, µ) is a measure space. This is a well known bad example.
3. Let F be a σ algebra of subsets of Ωand suppose F has inﬁnitely many
elements. Show that F is uncountable. Hint: You might try to show there
exists a countable sequence of disjoint sets of F, {Ai}. It might be easiest to
verify this by contradiction if it doesn’t exist rather than a direct construction.
Once this has been done, you can deﬁne a map, θ, from P (N) into F which
is one to one by θ (S) = ∪i∈SAi. Then argue P (N) is uncountable and so F
is also uncountable.
4. Prove Lemma 8.2.
5. g is Borel measurable if whenever U is open, g−1(U) is Borel. Let f : Ω→Rn
and let g : Rn →R and F is a σ algebra of sets of Ω. Suppose f is measurable
and g is Borel measurable.
Show g ◦f is measurable.
To say g is Borel
measurable means g−1 (open set) = (Borel set) where a Borel set is one of
those sets in the smallest σ algebra containing the open sets of Rn. See Lemma
8.2. Hint: You should show, using Theorem 8.12 that f −1 (open set) ∈F.
Now let
S ≡
©
E ⊆Rn : f −1 (E) ∈F
ª
By what you just showed, S contains the open sets. Now verify S is a σ
algebra. Argue that from the deﬁnition of the Borel sets, it follows S contains
the Borel sets.
6. Let (Ω, F) be a measure space and suppose f : Ω→C. Then f is said to be
mesurable if
f −1 (open set) ∈F.
Show f is measurable if and only if Re f and Im f are measurable real-valued
functions. Thus it suﬃces to deﬁne a complex valued function to be mea-
surable if the real and imaginary parts are measurable. Hint: Argue that
f −1 (((a, b) + i (c, d))) = (Re f)−1 ((a, b)) ∩(Im f)−1 ((c, d)) . Then use Theo-
rem 8.12 to verify that if Re f and Im f are measurable, it follows f is. Con-
versely, argue that (Re f)−1 ((a, b)) = f −1 ((a, b) + iR) with a similar formula
holding for Im f.
7. Let (Ω, F, µ) be a measure space. Deﬁne µ : P(Ω) →[0, ∞] by
µ(A) = inf{µ(B) : B ⊇A, B ∈F}.

8.3.
THE ABSTRACT LEBESGUE INTEGRAL
183
Show µ satisﬁes
µ(∅)
=
0, if A ⊆B, µ(A) ≤µ(B),
µ(∪∞
i=1Ai)
≤
∞
X
i=1
µ(Ai), µ (A) = µ (A) if A ∈F.
If µ satisﬁes these conditions, it is called an outer measure. This shows every
measure determines an outer measure on the power set.
8. Let {Ei} be a sequence of measurable sets with the property that
∞
X
i=1
µ(Ei) < ∞.
Let S = {ω ∈Ωsuch that ω ∈Ei for inﬁnitely many values of i}. Show
µ(S) = 0 and S is measurable. This is part of the Borel Cantelli lemma.
Hint: Write S in terms of intersections and unions. Something is in S means
that for every n there exists k > n such that it is in Ek. Remember the tail
of a convergent series is small.
9. ↑Let fn, f be measurable functions. fn converges in measure if
lim
n→∞µ(x ∈Ω: |f(x) −fn(x)| ≥ε) = 0
for each ﬁxed ε > 0. Prove the theorem of F. Riesz. If fn converges to f
in measure, then there exists a subsequence {fnk} which converges to f a.e.
Hint: Choose n1 such that
µ(x : |f(x) −fn1(x)| ≥1) < 1/2.
Choose n2 > n1 such that
µ(x : |f(x) −fn2(x)| ≥1/2) < 1/22,
n3 > n2 such that
µ(x : |f(x) −fn3(x)| ≥1/3) < 1/23,
etc. Now consider what it means for fnk(x) to fail to converge to f(x). Then
use Problem 8.
8.3
The Abstract Lebesgue Integral
8.3.1
Preliminary Observations
This section is on the Lebesgue integral and the major convergence theorems which
are the reason for studying it. In all that follows µ will be a measure deﬁned on a

184
ABSTRACT MEASURE AND INTEGRATION
σ algebra F of subsets of Ω. 0 · ∞= 0 is always deﬁned to equal zero. This is a
meaningless expression and so it can be deﬁned arbitrarily but a little thought will
soon demonstrate that this is the right deﬁnition in the context of measure theory.
To see this, consider the zero function deﬁned on R. What should the integral of
this function equal? Obviously, by an analogy with the Riemann integral, it should
equal zero. Formally, it is zero times the length of the set or inﬁnity. This is why
this convention will be used.
Lemma 8.19 Let f (a, b) ∈[−∞, ∞] for a ∈A and b ∈B where A, B are sets.
Then
sup
a∈A
sup
b∈B
f (a, b) = sup
b∈B
sup
a∈A
f (a, b) .
Proof: Note that for all a, b, f (a, b) ≤supb∈B supa∈A f (a, b) and therefore, for
all a,
sup
b∈B
f (a, b) ≤sup
b∈B
sup
a∈A
f (a, b) .
Therefore,
sup
a∈A
sup
b∈B
f (a, b) ≤sup
b∈B
sup
a∈A
f (a, b) .
Repeating the same argument interchanging a and b, gives the conclusion of the
lemma.
Lemma 8.20 If {An} is an increasing sequence in [−∞, ∞], then sup {An} =
limn→∞An.
The following lemma is useful also and this is a good place to put it. First
{bj}∞
j=1 is an enumeration of the aij if
∪∞
j=1 {bj} = ∪i,j {aij} .
In other words, the countable set, {aij}∞
i,j=1 is listed as b1, b2, · · ·.
Lemma 8.21 Let aij ≥0. Then P∞
i=1
P∞
j=1 aij = P∞
j=1
P∞
i=1 aij. Also if {bj}∞
j=1
is any enumeration of the aij, then P∞
j=1 bj = P∞
i=1
P∞
j=1 aij.
Proof: First note there is no trouble in deﬁning these sums because the aij are
all nonnegative. If a sum diverges, it only diverges to ∞and so ∞is written as the
answer.
∞
X
j=1
∞
X
i=1
aij ≥sup
n
∞
X
j=1
n
X
i=1
aij = sup
n
lim
m→∞
m
X
j=1
n
X
i=1
aij
= sup
n
lim
m→∞
n
X
i=1
m
X
j=1
aij = sup
n
n
X
i=1
∞
X
j=1
aij =
∞
X
i=1
∞
X
j=1
aij.
(8.10)
Interchanging the i and j in the above argument the ﬁrst part of the lemma is
proved.

8.3.
THE ABSTRACT LEBESGUE INTEGRAL
185
Finally, note that for all p,
p
X
j=1
bj ≤
∞
X
i=1
∞
X
j=1
aij
and so P∞
j=1 bj ≤P∞
i=1
P∞
j=1 aij. Now let m, n > 1 be given. Then
m
X
i=1
n
X
j=1
aij ≤
p
X
j=1
bj
where p is chosen large enough that {b1, · · ·, bp} ⊇{aij : i ≤m and j ≤n} . There-
fore, since such a p exists for any choice of m, n,it follows that for any m, n,
m
X
i=1
n
X
j=1
aij ≤
∞
X
j=1
bj.
Therefore, taking the limit as n →∞,
m
X
i=1
∞
X
j=1
aij ≤
∞
X
j=1
bj
and ﬁnally, taking the limit as m →∞,
∞
X
i=1
∞
X
j=1
aij ≤
∞
X
j=1
bj
proving the lemma.
8.3.2
Deﬁnition Of The Lebesgue Integral For Nonnegative
Measurable Functions
The following picture illustrates the idea used to deﬁne the Lebesgue integral to be
like the area under a curve.
h
2h
3h
hµ([h < f])
hµ([2h < f])
hµ([3h < f])
You can see that by following the procedure illustrated in the picture and letting
h get smaller, you would expect to obtain better approximations to the area under

186
ABSTRACT MEASURE AND INTEGRATION
the curve1 although all these approximations would likely be too small. Therefore,
deﬁne
Z
fdµ ≡sup
h>0
∞
X
i=1
hµ ([ih < f])
Lemma 8.22 The following inequality holds.
∞
X
i=1
hµ ([ih < f]) ≤
∞
X
i=1
h
2 µ
µ·
ih
2 < f
¸¶
.
Also, it suﬃces to consider only h smaller than a given positive number in the above
deﬁnition of the integral.
Proof:
Let N ∈N.
2N
X
i=1
h
2 µ
µ·
ih
2 < f
¸¶
=
2N
X
i=1
h
2 µ ([ih < 2f])
=
N
X
i=1
h
2 µ ([(2i −1) h < 2f]) +
N
X
i=1
h
2 µ ([(2i) h < 2f])
=
N
X
i=1
h
2 µ
µ·(2i −1)
2
h < f
¸¶
+
N
X
i=1
h
2 µ ([ih < f])
≥
N
X
i=1
h
2 µ ([ih < f]) +
N
X
i=1
h
2 µ ([ih < f]) =
N
X
i=1
hµ ([ih < f]) .
Now letting N →∞yields the claim of the lemma.
To verify the last claim, suppose M <
R
fdµ and let δ > 0 be given. Then there
exists h > 0 such that
M <
∞
X
i=1
hµ ([ih < f]) ≤
Z
fdµ.
By the ﬁrst part of this lemma,
M <
∞
X
i=1
h
2 µ
µ·
ih
2 < f
¸¶
≤
Z
fdµ
1Note the diﬀerence between this picture and the one usually drawn in calculus courses where
the little rectangles are upright rather than on their sides. This illustrates a fundamental philo-
sophical diﬀerence between the Riemann and the Lebesgue integrals. With the Riemann integral
intervals are measured. With the Lebesgue integral, it is inverse images of intervals which are
measured.

8.3.
THE ABSTRACT LEBESGUE INTEGRAL
187
and continuing to apply the ﬁrst part,
M <
∞
X
i=1
h
2n µ
µ·
i h
2n < f
¸¶
≤
Z
fdµ.
Choose n large enough that h/2n < δ. It follows
M < sup
δ>h>0
∞
X
i=1
hµ ([ih < f]) ≤
Z
fdµ.
Since M is arbitrary, this proves the last claim.
8.3.3
The Lebesgue Integral For Nonnegative Simple Func-
tions
Deﬁnition 8.23 A function, s, is called simple if it is a measurable real valued
function and has only ﬁnitely many values. These values will never be ±∞. Thus
a simple function is one which may be written in the form
s (ω) =
n
X
i=1
ciXEi (ω)
where the sets, Ei are disjoint and measurable. s takes the value ci at Ei.
Note that by taking the union of some of the Ei in the above deﬁnition, you
can assume that the numbers, ci are the distinct values of s. Simple functions are
important because it will turn out to be very easy to take their integrals as shown
in the following lemma.
Lemma 8.24 Let s (ω) = Pp
i=1 aiXEi (ω) be a nonnegative simple function with
the ai the distinct non zero values of s. Then
Z
sdµ =
p
X
i=1
aiµ (Ei) .
(8.11)
Also, for any nonnegative measurable function, f, if λ ≥0, then
Z
λfdµ = λ
Z
fdµ.
(8.12)
Proof: Consider 8.11 ﬁrst. Without loss of generality, you can assume 0 < a1 <
a2 < · · · < ap and that µ (Ei) < ∞. Let ε > 0 be given and let
δ1
p
X
i=1
µ (Ei) < ε.

188
ABSTRACT MEASURE AND INTEGRATION
Pick δ < δ1 such that for h < δ it is also true that
h < 1
2 min (a1, a2 −a1, a3 −a2, · · ·, an −an−1) .
Then for 0 < h < δ
∞
X
k=1
hµ ([s > kh])
=
∞
X
k=1
h
∞
X
i=k
µ ([ih < s ≤(i + 1) h])
=
∞
X
i=1
i
X
k=1
hµ ([ih < s ≤(i + 1) h])
=
∞
X
i=1
ihµ ([ih < s ≤(i + 1) h]) .
(8.13)
Because of the choice of h there exist positive integers, ik such that i1 < i2 < ···, < ip
and
i1h
<
a1 ≤(i1 + 1) h < · · · < i2h < a2 <
<
(i2 + 1) h < · · · < iph < ap ≤(ip + 1) h
Then in the sum of 8.13 the only terms which are nonzero are those for which
i ∈{i1, i2 · ··, ip}. From the above, you see that
µ ([ikh < s ≤(ik + 1) h]) = µ (Ek) .
Therefore,
∞
X
k=1
hµ ([s > kh]) =
p
X
k=1
ikhµ (Ek) .
It follows that for all h this small,
0
<
p
X
k=1
akµ (Ek) −
∞
X
k=1
hµ ([s > kh])
=
p
X
k=1
akµ (Ek) −
p
X
k=1
ikhµ (Ek) ≤h
p
X
k=1
µ (Ek) < ε.
Taking the inf for h this small and using Lemma 8.22,
0
≤
p
X
k=1
akµ (Ek) −sup
δ>h>0
∞
X
k=1
hµ ([s > kh])
=
p
X
k=1
akµ (Ek) −
Z
sdµ ≤ε.
Since ε > 0 is arbitrary, this proves the ﬁrst part.

8.3.
THE ABSTRACT LEBESGUE INTEGRAL
189
To verify 8.12 Note the formula is obvious if λ = 0 because then [ih < λf] = ∅
for all i > 0. Assume λ > 0. Then
Z
λfdµ
≡
sup
h>0
∞
X
i=1
hµ ([ih < λf])
=
sup
h>0
∞
X
i=1
hµ ([ih/λ < f])
=
sup
h>0
λ
∞
X
i=1
(h/λ) µ ([i (h/λ) < f])
=
λ
Z
fdµ.
This proves the lemma.
Lemma 8.25 Let the nonnegative simple function, s be deﬁned as
s (ω) =
n
X
i=1
ciXEi (ω)
where the ci are not necessarily distinct but the Ei are disjoint. It follows that
Z
s =
n
X
i=1
ciµ (Ei) .
Proof: Let the values of s be {a1, · · ·, am}. Therefore, since the Ei are disjoint,
each ai equal to one of the cj. Let Ai ≡∪{Ej : cj = ai}. Then from Lemma 8.24
it follows that
Z
s
=
m
X
i=1
aiµ (Ai) =
m
X
i=1
ai
X
{j:cj=ai}
µ (Ej)
=
m
X
i=1
X
{j:cj=ai}
cjµ (Ej) =
n
X
i=1
ciµ (Ei) .
This proves the lemma.
Note that
R
s could equal +∞if µ (Ak) = ∞and ak > 0 for some k, but
R
s is
well deﬁned because s ≥0. Recall that 0 · ∞= 0.
Lemma 8.26 If a, b ≥0 and if s and t are nonnegative simple functions, then
Z
as + bt = a
Z
s + b
Z
t.

190
ABSTRACT MEASURE AND INTEGRATION
Proof: Let
s(ω) =
n
X
i=1
αiXAi(ω), t(ω) =
m
X
i=1
βjXBj(ω)
where αi are the distinct values of s and the βj are the distinct values of t. Clearly
as + bt is a nonnegative simple function because it is measurable and has ﬁnitely
many values. Also,
(as + bt)(ω) =
m
X
j=1
n
X
i=1
(aαi + bβj)XAi∩Bj(ω)
where the sets Ai ∩Bj are disjoint. By Lemma 8.25,
Z
as + bt
=
m
X
j=1
n
X
i=1
(aαi + bβj)µ(Ai ∩Bj)
=
a
n
X
i=1
αiµ(Ai) + b
m
X
j=1
βjµ(Bj)
=
a
Z
s + b
Z
t.
This proves the lemma.
8.3.4
Simple Functions And Measurable Functions
There is a fundamental theorem about the relationship of simple functions to mea-
surable functions given in the next theorem.
Theorem 8.27 Let f ≥0 be measurable. Then there exists a sequence of nonneg-
ative simple functions {sn} satisfying
0 ≤sn(ω)
(8.14)
· · · sn(ω) ≤sn+1(ω) · ··
f(ω) = lim
n→∞sn(ω) for all ω ∈Ω.
(8.15)
If f is bounded the convergence is actually uniform.
Proof: Letting I ≡{ω : f (ω) = ∞} , deﬁne
tn(ω) =
2n
X
k=0
k
nX[k/n≤f<(k+1)/n](ω) + nXI(ω).
Then tn(ω) ≤f(ω) for all ω and limn→∞tn(ω) = f(ω) for all ω. This is because
tn (ω) = n for ω ∈I and if f (ω) ∈[0, 2n+1
n
), then
0 ≤f (ω) −tn (ω) ≤1
n.
(8.16)

8.3.
THE ABSTRACT LEBESGUE INTEGRAL
191
Thus whenever ω /∈I, the above inequality will hold for all n large enough. Let
s1 = t1, s2 = max (t1, t2) , s3 = max (t1, t2, t3) , · · ·.
Then the sequence {sn} satisﬁes 8.14-8.15.
To verify the last claim, note that in this case the term nXI(ω) is not present.
Therefore, for all n large enough, 8.16 holds for all ω. Thus the convergence is
uniform. This proves the theorem.
Although it is not needed here, there is a similar theorem which applies to
measurable functions which have values in a separable metric space. In this context,
a simple function is one which is of the form
m
X
k=1
xkXEk (ω)
where the Ek are disjoint measurable sets and the xk are in X.
Theorem 8.28 Let (Ω, F) be a measure space and let f : Ω→X where (X, d) is a
separable metric space. Then f be a measurable function if and only if there exists
a sequence of simple functions,{fn} such that for each ω ∈Ωand n ∈N,
d (fn (ω) , f (ω)) ≥d (fn+1 (ω) , f (ω))
(8.17)
and
lim
n→∞d (fn (ω) , f (ω)) = 0.
(8.18)
Proof: Let D = {xk}∞
k=1 be a countable dense subset of X. First suppose f is
measurable. Then since in a metric space every open set is the countable intersection
of closed sets, it follows f −1 (closed set) ∈F. Now let Dn = {xk}n
k=1 . Let
A1 ≡
½
ω : d (x1, f (ω)) = min
k≤n d (xk, f (ω))
¾
That is, A1 are those ω such that f (ω) is approximated best out of Dn by x1.
Why is this a measurable set?
It is because ω →d (x, f (ω)) is a real valued
measurable function, being the composition of a continuous function, y →d (x, y)
and a measurable function, ω →f (ω) . Next let
A2 ≡
½
ω /∈A1 : d (x2, f (ω)) = min
k≤n d (xk, f (ω))
¾
and continue in this manner obtaining disjoint measurable sets, {Ak}n
k=1 such that
for ω ∈Ak the best approximation to f (ω) from Dn is xk. Then
fn (ω) ≡
n
X
k=1
xkXAk (ω) .

192
ABSTRACT MEASURE AND INTEGRATION
Note
min
k≤n+1 d (xk, f (ω)) ≤min
k≤n d (xk, f (ω))
and so this veriﬁes 8.17. It remains to verify 8.18.
Let ε > 0 be given and pick ω ∈Ω. Then there exists xn ∈D such that
d (xn, f (ω)) < ε. It follows from the construction that d (fn (ω) , f (ω)) ≤d (xn, f (ω)) <
ε. This proves the ﬁrst half.
Now suppose the existence of the sequence of simple functions as described
above.
Each fn is a measurable function because f −1
n
(U) = ∪{Ak : xk ∈U}.
Therefore, the conclusion that f is measurable follows from Theorem 8.9 on Page
175.
8.3.5
The Monotone Convergence Theorem
The following is called the monotone convergence theorem. This theorem and re-
lated convergence theorems are the reason for using the Lebesgue integral.
Theorem 8.29 (Monotone Convergence theorem) Let f have values in [0, ∞] and
suppose {fn} is a sequence of nonnegative measurable functions having values in
[0, ∞] and satisfying
lim
n→∞fn(ω) = f(ω) for each ω.
· · ·fn(ω) ≤fn+1(ω) · ··
Then f is measurable and
Z
fdµ = lim
n→∞
Z
fndµ.
Proof: From Lemmas 8.19 and 8.20,
Z
fdµ
≡
sup
h>0
∞
X
i=1
hµ ([ih < f])
=
sup
h>0
sup
k
k
X
i=1
hµ ([ih < f])
=
sup
h>0
sup
k
sup
m
k
X
i=1
hµ ([ih < fm])
=
sup
m sup
h>0
∞
X
i=1
hµ ([ih < fm])
≡
sup
m
Z
fmdµ
=
lim
m→∞
Z
fmdµ.

8.3.
THE ABSTRACT LEBESGUE INTEGRAL
193
The third equality follows from the observation that
lim
m→∞µ ([ih < fm]) = µ ([ih < f])
which follows from Theorem 8.5 since the sets, [ih < fm] are increasing in m and
their union equals [ih < f]. This proves the theorem.
To illustrate what goes wrong without the Lebesgue integral, consider the fol-
lowing example.
Example 8.30 Let {rn} denote the rational numbers in [0, 1] and let
fn (t) ≡
½ 1 if t /∈{r1, · · ·, rn}
0 otherwise
Then fn (t) ↑f (t) where f is the function which is one on the rationals and zero
on the irrationals. Each fn is Riemann integrable (why?) but f is not Riemann
integrable. Therefore, you can’t write
R
fdx = limn→∞
R
fndx.
A meta-mathematical observation related to this type of example is this. If you
can choose your functions, you don’t need the Lebesgue integral. The Riemann
integral is just ﬁne. It is when you can’t choose your functions and they come to
you as pointwise limits that you really need the superior Lebesgue integral or at
least something more general than the Riemann integral. The Riemann integral
is entirely adequate for evaluating the seemingly endless lists of boring problems
found in calculus books.
8.3.6
Other Deﬁnitions
To review and summarize the above, if f ≥0 is measurable,
Z
fdµ ≡sup
h>0
∞
X
i=1
hµ ([f > ih])
(8.19)
another way to get the same thing for
R
fdµ is to take an increasing sequence of
nonnegative simple functions, {sn} with sn (ω) →f (ω) and then by monotone
convergence theorem,
Z
fdµ = lim
n→∞
Z
sn
where if sn (ω) = Pm
j=1 ciXEi (ω) ,
Z
sndµ =
m
X
i=1
cim (Ei) .
Similarly this also shows that for such nonnegative measurable function,
Z
fdµ = sup
½Z
s : 0 ≤s ≤f, s simple
¾

194
ABSTRACT MEASURE AND INTEGRATION
which is the usual way of deﬁning the Lebesgue integral for nonnegative simple
functions in most books. I have done it diﬀerently because this approach led to an
easier proof of the Monotone convergence theorem. Here is an equivalent deﬁnition
of the integral. The fact it is well deﬁned has been discussed above.
Deﬁnition 8.31 For s a nonnegative simple function,
s (ω) =
n
X
k=1
ckXEk (ω) ,
Z
s =
n
X
k=1
ckµ (Ek) .
For f a nonnegative measurable function,
Z
fdµ = sup
½Z
s : 0 ≤s ≤f, s simple
¾
.
8.3.7
Fatou’s Lemma
Sometimes the limit of a sequence does not exist.
There are two more general
notions known as lim sup and lim inf which do always exist in some sense. These
notions are dependent on the following lemma.
Lemma 8.32 Let {an} be an increasing (decreasing) sequence in [−∞, ∞] . Then
limn→∞an exists.
Proof: Suppose ﬁrst {an} is increasing. Recall this means an ≤an+1 for all n.
If the sequence is bounded above, then it has a least upper bound and so an →a
where a is its least upper bound. If the sequence is not bounded above, then for
every l ∈R, it follows l is not an upper bound and so eventually, an > l. But this
is what is meant by an →∞. The situation for decreasing sequences is completely
similar.
Now take any sequence, {an} ⊆[−∞, ∞] and consider the sequence {An} where
An ≡inf {ak : k ≥n} .
Then as n increases, the set of numbers whose inf is being taken is getting smaller.
Therefore, An is an increasing sequence and so it must converge. Similarly, if Bn ≡
sup {ak : k ≥n} , it follows Bn is decreasing and so {Bn} also must converge. With
this preparation, the following deﬁnition can be given.
Deﬁnition 8.33 Let {an} be a sequence of points in [−∞, ∞] . Then deﬁne
lim inf
n→∞an ≡lim
n→∞inf {ak : k ≥n}
and
lim sup
n→∞an ≡lim
n→∞sup {ak : k ≥n}
In the case of functions having values in [−∞, ∞] ,
³
lim inf
n→∞fn
´
(ω) ≡lim inf
n→∞(fn (ω)) .
A similar deﬁnition applies to lim supn→∞fn.

8.3.
THE ABSTRACT LEBESGUE INTEGRAL
195
Lemma 8.34 Let {an} be a sequence in [−∞, ∞] . Then limn→∞an exists if and
only if
lim inf
n→∞an = lim sup
n→∞an
and in this case, the limit equals the common value of these two numbers.
Proof: Suppose ﬁrst limn→∞an = a ∈R. Then, letting ε > 0 be given, an ∈
(a −ε, a + ε) for all n large enough, say n ≥N. Therefore, both inf {ak : k ≥n}
and sup {ak : k ≥n} are contained in [a −ε, a + ε] whenever n ≥N. It follows
lim supn→∞an and lim infn→∞an are both in [a −ε, a + ε] , showing
¯¯¯¯lim inf
n→∞an −lim sup
n→∞an
¯¯¯¯ < 2ε.
Since ε is arbitrary, the two must be equal and they both must equal a. Next suppose
limn→∞an = ∞. Then if l ∈R, there exists N such that for n ≥N,
l ≤an
and therefore, for such n,
l ≤inf {ak : k ≥n} ≤sup {ak : k ≥n}
and this shows, since l is arbitrary that
lim inf
n→∞an = lim sup
n→∞an = ∞.
The case for −∞is similar.
Conversely, suppose lim infn→∞an = lim supn→∞an = a. Suppose ﬁrst that
a ∈R. Then, letting ε > 0 be given, there exists N such that if n ≥N,
sup {ak : k ≥n} −inf {ak : k ≥n} < ε
therefore, if k, m > N, and ak > am,
|ak −am| = ak −am ≤sup {ak : k ≥n} −inf {ak : k ≥n} < ε
showing that {an} is a Cauchy sequence. Therefore, it converges to a ∈R, and
as in the ﬁrst part, the lim inf and lim sup both equal a. If lim infn→∞an =
lim supn→∞an = ∞, then given l ∈R, there exists N such that for n ≥N,
inf
n>N an > l.
Therefore, limn→∞an = ∞. The case for −∞is similar. This proves the lemma.
The next theorem, known as Fatou’s lemma is another important theorem which
justiﬁes the use of the Lebesgue integral.

196
ABSTRACT MEASURE AND INTEGRATION
Theorem 8.35 (Fatou’s lemma) Let fn be a nonnegative measurable function with
values in [0, ∞]. Let g(ω) = lim infn→∞fn(ω). Then g is measurable and
Z
gdµ ≤lim inf
n→∞
Z
fndµ.
In other words,
Z ³
lim inf
n→∞fn
´
dµ ≤lim inf
n→∞
Z
fndµ
Proof: Let gn(ω) = inf{fk(ω) : k ≥n}. Then
g−1
n ([a, ∞]) = ∩∞
k=nf −1
k ([a, ∞]) ∈F.
Thus gn is measurable by Lemma 8.6 on Page 173. Also g(ω) = limn→∞gn(ω) so
g is measurable because it is the pointwise limit of measurable functions. Now the
functions gn form an increasing sequence of nonnegative measurable functions so
the monotone convergence theorem applies. This yields
Z
gdµ = lim
n→∞
Z
gndµ ≤lim inf
n→∞
Z
fndµ.
The last inequality holding because
Z
gndµ ≤
Z
fndµ.
(Note that it is not known whether limn→∞
R
fndµ exists.) This proves the Theo-
rem.
8.3.8
The Righteous Algebraic Desires Of The Lebesgue In-
tegral
The monotone convergence theorem shows the integral wants to be linear. This is
the essential content of the next theorem.
Theorem 8.36 Let f, g be nonnegative measurable functions and let a, b be non-
negative numbers. Then
Z
(af + bg) dµ = a
Z
fdµ + b
Z
gdµ.
(8.20)
Proof:
By Theorem 8.27 on Page 190 there exist sequences of nonnegative
simple functions, sn →f and tn →g. Then by the monotone convergence theorem
and Lemma 8.26,
Z
(af + bg) dµ
=
lim
n→∞
Z
asn + btndµ
=
lim
n→∞
µ
a
Z
sndµ + b
Z
tndµ
¶
=
a
Z
fdµ + b
Z
gdµ.

8.4.
THE SPACE L1
197
As long as you are allowing functions to take the value +∞, you cannot consider
something like f + (−g) and so you can’t very well expect a satisfactory statement
about the integral being linear until you restrict yourself to functions which have
values in a vector space. This is discussed next.
8.4
The Space L1
The functions considered here have values in C, a vector space.
Deﬁnition 8.37 Let (Ω, S, µ) be a measure space and suppose f : Ω→C. Then f
is said to be measurable if both Re f and Im f are measurable real valued functions.
Deﬁnition 8.38 A complex simple function will be a function which is of the form
s (ω) =
n
X
k=1
ckXEk (ω)
where ck ∈C and µ (Ek) < ∞. For s a complex simple function as above, deﬁne
I (s) ≡
n
X
k=1
ckµ (Ek) .
Lemma 8.39 The deﬁnition, 8.38 is well deﬁned. Furthermore, I is linear on the
vector space of complex simple functions. Also the triangle inequality holds,
|I (s)| ≤I (|s|) .
Proof: Suppose Pn
k=1 ckXEk (ω) = 0. Does it follow that P
k ckµ (Ek) = 0?
The supposition implies
n
X
k=1
Re ckXEk (ω) = 0,
n
X
k=1
Im ckXEk (ω) = 0.
(8.21)
Choose λ large and positive so that λ + Re ck ≥0. Then adding P
k λXEk to both
sides of the ﬁrst equation above,
n
X
k=1
(λ + Re ck) XEk (ω) =
n
X
k=1
λXEk
and by Lemma 8.26 on Page 189, it follows upon taking
R
of both sides that
n
X
k=1
(λ + Re ck) µ (Ek) =
n
X
k=1
λµ (Ek)

198
ABSTRACT MEASURE AND INTEGRATION
which implies Pn
k=1 Re ckµ (Ek) = 0.
Similarly, Pn
k=1 Im ckµ (Ek) = 0 and so
Pn
k=1 ckµ (Ek) = 0. Thus if
X
j
cjXEj =
X
k
dkXFk
then P
j cjXEj + P
k (−dk) XFk = 0 and so the result just established veriﬁes
P
j cjµ (Ej) −P
k dkµ (Fk) = 0 which proves I is well deﬁned.
That I is linear is now obvious. It only remains to verify the triangle inequality.
Let s be a simple function,
s =
X
j
cjXEj
Then pick θ ∈C such that θI (s) = |I (s)| and |θ| = 1. Then from the triangle
inequality for sums of complex numbers,
|I (s)|
=
θI (s) = I (θs) =
X
j
θcjµ (Ej)
=
¯¯¯¯¯¯
X
j
θcjµ (Ej)
¯¯¯¯¯¯
≤
X
j
|θcj| µ (Ej) = I (|s|) .
This proves the lemma.
With this lemma, the following is the deﬁnition of L1 (Ω) .
Deﬁnition 8.40 f ∈L1(Ω) means there exists a sequence of complex simple func-
tions, {sn} such that
sn (ω) →f (ω) for all ω ∈Ω
limm,n→∞I (|sn −sm|) = limn,m→∞
R
|sn −sm| dµ = 0
(8.22)
Then
I (f) ≡lim
n→∞I (sn) .
(8.23)
Lemma 8.41 Deﬁnition 8.40 is well deﬁned.
Proof: There are several things which need to be veriﬁed. First suppose 8.22.
Then by Lemma 8.39
|I (sn) −I (sm)| = |I (sn −sm)| ≤I (|sn −sm|)
and for m, n large enough this last is given to be small so {I (sn)} is a Cauchy
sequence in C and so it converges. This veriﬁes the limit in 8.23 at least exists. It
remains to consider another sequence {tn} having the same properties as {sn} and

8.4.
THE SPACE L1
199
verifying I (f) determined by this other sequence is the same. By Lemma 8.39 and
Fatou’s lemma, Theorem 8.35 on Page 196,
|I (sn) −I (tn)|
≤
I (|sn −tn|) =
Z
|sn −tn| dµ
≤
Z
|sn −f| + |f −tn| dµ
≤
lim inf
k→∞
Z
|sn −sk| dµ + lim inf
k→∞
Z
|tn −tk| dµ < ε
whenever n is large enough. Since ε is arbitrary, this shows the limit from using
the tn is the same as the limit from using sn. This proves the lemma.
What if f has values in [0, ∞)? Earlier
R
fdµ was deﬁned for such functions and
now I (f) has been deﬁned. Are they the same? If so, I can be regarded as an
extension of
R
dµ to a larger class of functions.
Lemma 8.42 Suppose f has values in [0, ∞) and f ∈L1 (Ω) . Then f is measurable
and
I (f) =
Z
fdµ.
Proof: Since f is the pointwise limit of a sequence of complex simple func-
tions, {sn} having the properties described in Deﬁnition 8.40, it follows f (ω) =
limn→∞Re sn (ω) and so f is measurable. Also
Z ¯¯¯(Re sn)+ −(Re sm)+¯¯¯ dµ ≤
Z
|Re sn −Re sm| dµ ≤
Z
|sn −sm| dµ
where x+ ≡1
2 (|x| + x) , the positive part of the real number, x. 2Thus there is no
loss of generality in assuming {sn} is a sequence of complex simple functions having
values in [0, ∞). Then since for such complex simple functions, I (s) =
R
sdµ,
¯¯¯¯I (f) −
Z
fdµ
¯¯¯¯ ≤|I (f) −I (sn)| +
¯¯¯¯
Z
sndµ −
Z
fdµ
¯¯¯¯ < ε +
Z
|sn −f| dµ
whenever n is large enough. But by Fatou’s lemma, Theorem 8.35 on Page 196, the
last term is no larger than
lim inf
k→∞
Z
|sn −sk| dµ < ε
whenever n is large enough.
Since ε is arbitrary, this shows I (f) =
R
fdµ as
claimed.
As explained above, I can be regarded as an extension of
R
dµ so from now on,
the usual symbol,
R
dµ will be used. It is now easy to verify
R
dµ is linear on L1 (Ω) .
2The negative part of the real number x is deﬁned to be x−≡1
2 (|x| −x) . Thus |x| = x+ + x−
and x = x+ −x−. .

200
ABSTRACT MEASURE AND INTEGRATION
Theorem 8.43
R
dµ is linear on L1 (Ω) and L1 (Ω) is a complex vector space. If
f ∈L1 (Ω) , then Re f, Im f, and |f| are all in L1 (Ω) . Furthermore, for f ∈L1 (Ω) ,
Z
fdµ =
Z
(Re f)+ dµ −
Z
(Re f)−dµ + i
µZ
(Im f)+ dµ −
Z
(Im f)−dµ
¶
Also the triangle inequality holds,
¯¯¯¯
Z
fdµ
¯¯¯¯ ≤
Z
|f| dµ
Proof: First it is necessary to verify that L1 (Ω) is really a vector space because
it makes no sense to speak of linear maps without having these maps deﬁned on
a vector space. Let f, g be in L1 (Ω) and let a, b ∈C. Then let {sn} and {tn}
be sequences of complex simple functions associated with f and g respectively as
described in Deﬁnition 8.40. Consider {asn + btn} , another sequence of complex
simple functions. Then asn (ω) + btn (ω) →af (ω) + bg (ω) for each ω. Also, from
Lemma 8.39
Z
|asn + btn −(asm + btm)| dµ ≤|a|
Z
|sn −sm| dµ + |b|
Z
|tn −tm| dµ
and the sum of the two terms on the right converge to zero as m, n →∞. Thus
af + bg ∈L1 (Ω) . Also
Z
(af + bg) dµ
=
lim
n→∞
Z
(asn + btn) dµ
=
lim
n→∞
µ
a
Z
sndµ + b
Z
tndµ
¶
=
a lim
n→∞
Z
sndµ + b lim
n→∞
Z
tndµ
=
a
Z
fdµ + b
Z
gdµ.
If {sn} is a sequence of complex simple functions described in Deﬁnition 8.40
corresponding to f, then {|sn|} is a sequence of complex simple functions satisfying
the conditions of Deﬁnition 8.40 corresponding to |f| . This is because |sn (ω)| →
|f (ω)| and
Z
||sn| −|sm|| dµ ≤
Z
|sm −sn| dµ
with this last expression converging to 0 as m, n →∞. Thus |f| ∈L1 (Ω). Also, by
similar reasoning, {Re sn} and {Im sn} correspond to Re f and Im f respectively in
the manner described by Deﬁnition 8.40 showing that Re f and Im f are in L1 (Ω).
Now (Re f)+ = 1
2 (|Re f| + Re f) and (Re f)−= 1
2 (|Re f| −Re f) so both of these
functions are in L1 (Ω) . Similar formulas establish that (Im f)+ and (Im f)−are in
L1 (Ω) .

8.4.
THE SPACE L1
201
The formula follows from the observation that
f = (Re f)+ −(Re f)−+ i
³
(Im f)+ −(Im f)−´
and the fact shown ﬁrst that
R
dµ is linear.
To verify the triangle inequality, let {sn} be complex simple functions for f as
in Deﬁnition 8.40. Then
¯¯¯¯
Z
fdµ
¯¯¯¯ = lim
n→∞
¯¯¯¯
Z
sndµ
¯¯¯¯ ≤lim
n→∞
Z
|sn| dµ =
Z
|f| dµ.
This proves the theorem.
The following description of L1 (Ω) is the version most often used because it is
easy to verify the conditions for it.
Corollary 8.44 Let (Ω, S, µ) be a measure space and let f : Ω→C. Then f ∈
L1 (Ω) if and only if f is measurable and
R
|f| dµ < ∞.
Proof: Suppose f ∈L1 (Ω) . Then from Deﬁnition 8.40, it follows both real and
imaginary parts of f are measurable. Just take real and imaginary parts of sn and
observe the real and imaginary parts of f are limits of the real and imaginary parts
of sn respectively. By Theorem 8.43 this shows the only if part.
The more interesting part is the if part. Suppose then that f is measurable and
R
|f| dµ < ∞. Suppose ﬁrst that f has values in [0, ∞). It is necessary to obtain the
sequence of complex simple functions. By Theorem 8.27, there exists a sequence of
nonnegative simple functions, {sn} such that sn (ω) ↑f (ω). Then by the monotone
convergence theorem,
lim
n→∞
Z
(2f −(f −sn)) dµ =
Z
2fdµ
and so
lim
n→∞
Z
(f −sn) dµ = 0.
Letting m be large enough, it follows
R
(f −sm) dµ < ε and so if n > m
Z
|sm −sn| dµ ≤
Z
|f −sm| dµ < ε.
Therefore, f ∈L1 (Ω) because {sn} is a suitable sequence.
The general case follows from considering positive and negative parts of real and
imaginary parts of f. These are each measurable and nonnegative and their integral
is ﬁnite so each is in L1 (Ω) by what was just shown. Thus
f = Re f + −Re f −+ i
¡
Im f + −Im f −¢
and so f ∈L1 (Ω). This proves the corollary.

202
ABSTRACT MEASURE AND INTEGRATION
Theorem 8.45 (Dominated Convergence theorem) Let fn ∈L1(Ω) and suppose
f(ω) = lim
n→∞fn(ω),
and there exists a measurable function g, with values in [0, ∞],3 such that
|fn(ω)| ≤g(ω) and
Z
g(ω)dµ < ∞.
Then f ∈L1(Ω) and
Z
fdµ = lim
n→∞
Z
fndµ.
Proof: f is measurable by Theorem 8.8. Since |f| ≤g, it follows that
f ∈L1(Ω) and |f −fn| ≤2g.
By Fatou’s lemma (Theorem 8.35),
Z
2gdµ
≤
lim inf
n→∞
Z
2g −|f −fn|dµ
=
Z
2gdµ −lim sup
n→∞
Z
|f −fn|dµ.
Subtracting
R
2gdµ,
0 ≤−lim sup
n→∞
Z
|f −fn|dµ.
Hence
0
≥
lim sup
n→∞(
Z
|f −fn|dµ) ≥lim sup
n→∞|
Z
fdµ −
Z
fndµ|
≥
lim inf
n→∞|
Z
fdµ −
Z
fndµ| ≥0.
This proves the theorem by Lemma 8.34 on Page 195 because the lim sup and lim inf
are equal.
Corollary 8.46 Suppose fn ∈L1 (Ω) and f (ω) = limn→∞fn (ω) . Suppose also
there exist measurable functions, gn, g with values in [0, ∞] such that
lim
n→∞
Z
gndµ =
Z
gdµ,
gn (ω) →g (ω) µ a.e. and both
R
gndµ and
R
gdµ are ﬁnite. Also suppose |fn (ω)| ≤
gn (ω) . Then
lim
n→∞
Z
|f −fn| dµ = 0.
3Note that, since g is allowed to have the value ∞, it is not known that g ∈L1 (Ω) .

8.5.
VITALI CONVERGENCE THEOREM
203
Proof: It is just like the above. This time g + gn −|f −fn| ≥0 and so by
Fatou’s lemma,
Z
2gdµ −lim sup
n→∞
Z
|f −fn| dµ =
lim inf
n→∞
Z
(gn + g) −lim sup
n→∞
Z
|f −fn| dµ
=
lim inf
n→∞
Z
((gn + g) −|f −fn|) dµ ≥
Z
2gdµ
and so −lim supn→∞
R
|f −fn| dµ ≥0.
Deﬁnition 8.47 Let E be a measurable subset of Ω.
Z
E
fdµ ≡
Z
fXEdµ.
If L1(E) is written, the σ algebra is deﬁned as
{E ∩A : A ∈F}
and the measure is µ restricted to this smaller σ algebra. Clearly, if f ∈L1(Ω),
then
fXE ∈L1(E)
and if f ∈L1(E), then letting ˜f
be the 0 extension of f oﬀof E, it follows ˜f
∈L1(Ω).
8.5
Vitali Convergence Theorem
The Vitali convergence theorem is a convergence theorem which in the case of a
ﬁnite measure space is superior to the dominated convergence theorem.
Deﬁnition 8.48 Let (Ω, F, µ) be a measure space and let S ⊆L1(Ω). S is uni-
formly integrable if for every ε > 0 there exists δ > 0 such that for all f ∈S
|
Z
E
fdµ| < ε whenever µ(E) < δ.
Lemma 8.49 If S is uniformly integrable, then |S| ≡{|f| : f ∈S} is uniformly
integrable. Also S is uniformly integrable if S is ﬁnite.
Proof: Let ε > 0 be given and suppose S is uniformly integrable. First suppose
the functions are real valued. Let δ be such that if µ (E) < δ, then
¯¯¯¯
Z
E
fdµ
¯¯¯¯ < ε
2

204
ABSTRACT MEASURE AND INTEGRATION
for all f ∈S. Let µ (E) < δ. Then if f ∈S,
Z
E
|f| dµ
≤
Z
E∩[f≤0]
(−f) dµ +
Z
E∩[f>0]
fdµ
=
¯¯¯¯¯
Z
E∩[f≤0]
fdµ
¯¯¯¯¯ +
¯¯¯¯¯
Z
E∩[f>0]
fdµ
¯¯¯¯¯
<
ε
2 + ε
2 = ε.
In general, if S is a uniformly integrable set of complex valued functions, the in-
equalities,
¯¯¯¯
Z
E
Re fdµ
¯¯¯¯ ≤
¯¯¯¯
Z
E
fdµ
¯¯¯¯ ,
¯¯¯¯
Z
E
Im fdµ
¯¯¯¯ ≤
¯¯¯¯
Z
E
fdµ
¯¯¯¯ ,
imply Re S ≡{Re f : f ∈S} and Im S ≡{Im f : f ∈S} are also uniformly inte-
grable. Therefore, applying the above result for real valued functions to these sets
of functions, it follows |S| is uniformly integrable also.
For the last part, is suﬃces to verify a single function in L1 (Ω) is uniformly
integrable. To do so, note that from the dominated convergence theorem,
lim
R→∞
Z
[|f|>R]
|f| dµ = 0.
Let ε > 0 be given and choose R large enough that
R
[|f|>R] |f| dµ < ε
2. Now let
µ (E) <
ε
2R. Then
Z
E
|f| dµ
=
Z
E∩[|f|≤R]
|f| dµ +
Z
E∩[|f|>R]
|f| dµ
<
Rµ (E) + ε
2 < ε
2 + ε
2 = ε.
This proves the lemma.
The following theorem is Vitali’s convergence theorem.
Theorem 8.50 Let {fn} be a uniformly integrable set of complex valued functions,
µ(Ω) < ∞, and
fn(x) →f(x)
a.e.
where f is a measurable complex valued
function. Then f ∈L1 (Ω) and
lim
n→∞
Z
Ω
|fn −f|dµ = 0.
(8.24)
Proof: First it will be shown that f ∈L1 (Ω). By uniform integrability, there
exists δ > 0 such that if µ (E) < δ, then
Z
E
|fn| dµ < 1

8.6.
EXERCISES
205
for all n. By Egoroﬀ’s theorem, there exists a set, E of measure less than δ such
that on EC, {fn} converges uniformly. Therefore, for p large enough, and n > p,
Z
EC |fp −fn| dµ < 1
which implies
Z
EC |fn| dµ < 1 +
Z
Ω
|fp| dµ.
Then since there are only ﬁnitely many functions, fn with n ≤p, there exists a
constant, M1 such that for all n,
Z
EC |fn| dµ < M1.
But also,
Z
Ω
|fm| dµ
=
Z
EC |fm| dµ +
Z
E
|fm|
≤
M1 + 1 ≡M.
Therefore, by Fatou’s lemma,
Z
Ω
|f| dµ ≤lim inf
n→∞
Z
|fn| dµ ≤M,
showing that f ∈L1 as hoped.
Now S∪{f} is uniformly integrable so there exists δ1 > 0 such that if µ (E) < δ1,
then
R
E |g| dµ < ε/3 for all g ∈S ∪{f}. By Egoroﬀ’s theorem, there exists a set,
F with µ (F) < δ1 such that fn converges uniformly to f on F C. Therefore, there
exists N such that if n > N, then
Z
F C |f −fn| dµ < ε
3.
It follows that for n > N,
Z
Ω
|f −fn| dµ
≤
Z
F C |f −fn| dµ +
Z
F
|f| dµ +
Z
F
|fn| dµ
<
ε
3 + ε
3 + ε
3 = ε,
which veriﬁes 8.24.
8.6
Exercises
1. Let Ω= N = {1, 2, · · ·} and µ(S) = number of elements in S. If
f : Ω→C
what is meant by
R
fdµ? Which functions are in L1(Ω)? Which functions are
measurable?

206
ABSTRACT MEASURE AND INTEGRATION
2. Show that for f ≥0 and measurable,
R
fdµ ≡limh→0+
P∞
i=1 hµ ([ih < f]).
3. For the measure space of Problem 1, give an example of a sequence of nonneg-
ative measurable functions {fn} converging pointwise to a function f, such
that inequality is obtained in Fatou’s lemma.
4. Fill in all the details of the proof of Lemma 8.49.
5. Let Pn
i=1 ciXEi (ω) = s (ω) be a nonnegative simple function for which the ci
are the distinct nonzero values. Show with the aid of the monotone conver-
gence theorem that the two deﬁnitions of the Lebesgue integral given in the
chapter are equivalent.
6. Suppose (Ω, µ) is a ﬁnite measure space and S ⊆L1 (Ω). Show S is uniformly
integrable and bounded in L1 (Ω) if there exists an increasing function h which
satisﬁes
lim
t→∞
h (t)
t
= ∞, sup
½Z
Ω
h (|f|) dµ : f ∈S
¾
< ∞.
S is bounded if there is some number, M such that
Z
|f| dµ ≤M
for all f ∈S.
7. Let {an}, {bn} be sequences in [−∞, ∞] and a ∈R. Show
lim inf
n→∞(a −an) = a −lim sup
n→∞an.
This was used in the proof of the Dominated convergence theorem. Also show
lim sup
n→∞(−an) = −lim inf
n→∞(an)
lim sup
n→∞(an + bn) ≤lim sup
n→∞an + lim sup
n→∞bn
provided no sum is of the form ∞−∞. Also show strict inequality can hold
in the inequality. State and prove corresponding statements for lim inf.
8. Let (Ω, F, µ) be a measure space and suppose f, g : Ω→(−∞, ∞] are mea-
surable. Prove the sets
{ω : f(ω) < g(ω)} and {ω : f(ω) = g(ω)}
are measurable. Hint: The easy way to do this is to write
{ω : f(ω) < g(ω)} = ∪r∈Q [f < r] ∩[g > r] .
Note that l (x, y) = x −y is not continuous on (−∞, ∞] so the obvious idea
doesn’t work.

8.6.
EXERCISES
207
9. Let {fn} be a sequence of real or complex valued measurable functions. Let
S = {ω : {fn(ω)} converges}.
Show S is measurable. Hint: You might try to exhibit the set where fn
converges in terms of countable unions and intersections using the deﬁnition
of a Cauchy sequence.
10. Let (Ω, S, µ) be a measure space and let f be a nonnegative measurable func-
tion deﬁned on Ω. Also let φ : [0, ∞) →[0, ∞) be strictly increasing and
have a continuous derivative and φ (0) = 0. Suppose f is bounded and that
0 ≤φ (f (ω)) ≤M for some number, M. Show that
Z
Ω
φ (f) dµ =
Z ∞
0
φ′ (s) µ ([s < f]) ds,
where the integral on the right is the ordinary improper Riemann integral.
Hint: First note that s →φ′ (s) µ ([s < f]) is Riemann integrable because φ′
is continuous and s →µ ([s < f]) is a nonincreasing function, hence Riemann
integrable.
From the second description of the Lebesgue integral and the
assumption that φ (f (ω)) ≤M, argue that for [M/h] the greatest integer less
than M/h,
Z
Ω
φ (f) dµ
=
sup
h>0
[M/h]
X
i=1
hµ ([ih < φ (f)])
=
sup
h>0
[M/h]
X
i=1
hµ
¡£
φ−1 (ih) < f
¤¢
=
sup
h>0
[M/h]
X
i=1
h∆i
∆i
µ
¡£
φ−1 (ih) < f
¤¢
where ∆i =
¡
φ−1 (ih) −φ−1 ((i −1) h)
¢
. Now use the mean value theorem to
write
∆i
=
¡
φ−1¢′ (ti) h
=
1
φ′ ¡
φ−1 (ti)
¢h
for some ti between (i −1) h and ih. Therefore, the right side is of the form
sup
h
[M/h]
X
i=1
φ′ ¡
φ−1 (ti)
¢
∆iµ
¡£
φ−1 (ih) < f
¤¢
where φ−1 (ti) ∈
¡
φ−1 ((i −1) h) , φ−1 (ih)
¢
. Argue that if ti were replaced
with ih, this would be a Riemann sum for the Riemann integral
Z φ−1(M)
0
φ′ (t) µ ([t < f]) dt =
Z ∞
0
φ′ (t) µ ([t < f]) dt.

208
ABSTRACT MEASURE AND INTEGRATION
11. Let (Ω, F, µ) be a measure space and suppose fn converges uniformly to f
and that fn is in L1(Ω). When is
lim
n→∞
Z
fndµ =
Z
fdµ?
12. Suppose un(t) is a diﬀerentiable function for t ∈(a, b) and suppose that for
t ∈(a, b),
|un(t)|, |u′
n(t)| < Kn
where P∞
n=1 Kn < ∞. Show
(
∞
X
n=1
un(t))′ =
∞
X
n=1
u′
n(t).
Hint: This is an exercise in the use of the dominated convergence theorem
and the mean value theorem.
13. Show that {P∞
i=1 2−nµ ([i2−n < f])} for f a nonnegative measurable function
is an increasing sequence. Could you deﬁne
Z
fdµ ≡lim
n→∞
∞
X
i=1
2−nµ
¡£
i2−n < f
¤¢
and would it be equivalent to the above deﬁnitions of the Lebesgue integral?
14. Suppose {fn} is a sequence of nonnegative measurable functions deﬁned on a
measure space, (Ω, S, µ). Show that
Z
∞
X
k=1
fkdµ =
∞
X
k=1
Z
fkdµ.
Hint: Use the monotone convergence theorem along with the fact the integral
is linear.

The Construction Of
Measures
9.1
Outer Measures
What are some examples of measure spaces? In this chapter, a general procedure
is discussed called the method of outer measures. It is due to Caratheodory (1918).
This approach shows how to obtain measure spaces starting with an outer mea-
sure. This will then be used to construct measures determined by positive linear
functionals.
Deﬁnition 9.1 Let Ωbe a nonempty set and let µ : P(Ω) →[0, ∞] satisfy
µ(∅) = 0,
If A ⊆B, then µ(A) ≤µ(B),
µ(∪∞
i=1Ei) ≤
∞
X
i=1
µ(Ei).
Such a function is called an outer measure. For E ⊆Ω, E is µ measurable if for
all S ⊆Ω,
µ(S) = µ(S \ E) + µ(S ∩E).
(9.1)
To help in remembering 9.1, think of a measurable set, E, as a process which
divides a given set into two pieces, the part in E and the part not in E as in
9.1. In the Bible, there are four incidents recorded in which a process of division
resulted in more stuﬀthan was originally present.1
Measurable sets are exactly
11 Kings 17, 2 Kings 4, Mathew 14, and Mathew 15 all contain such descriptions. The stuﬀ
involved was either oil, bread, ﬂour or ﬁsh. In mathematics such things have also been done with
sets. In the book by Bruckner Bruckner and Thompson there is an interesting discussion of the
Banach Tarski paradox which says it is possible to divide a ball in R3 into ﬁve disjoint pieces and
assemble the pieces to form two disjoint balls of the same size as the ﬁrst. The details can be
found in: The Banach Tarski Paradox by Wagon, Cambridge University press. 1985. It is known
that all such examples must involve the axiom of choice.
209

210
THE CONSTRUCTION OF MEASURES
those for which no such miracle occurs. You might think of the measurable sets as
the nonmiraculous sets. The idea is to show that they form a σ algebra on which
the outer measure, µ is a measure.
First here is a deﬁnition and a lemma.
Deﬁnition 9.2 (µ⌊S)(A) ≡µ(S ∩A) for all A ⊆Ω. Thus µ⌊S is the name of a
new outer measure, called µ restricted to S.
The next lemma indicates that the property of measurability is not lost by
considering this restricted measure.
Lemma 9.3 If A is µ measurable, then A is µ⌊S measurable.
Proof: Suppose A is µ measurable. It is desired to to show that for all T ⊆Ω,
(µ⌊S)(T) = (µ⌊S)(T ∩A) + (µ⌊S)(T \ A).
Thus it is desired to show
µ(S ∩T) = µ(T ∩A ∩S) + µ(T ∩S ∩AC).
(9.2)
But 9.2 holds because A is µ measurable. Apply Deﬁnition 9.1 to S ∩T instead of
S.
If A is µ⌊S measurable, it does not follow that A is µ measurable. Indeed, if
you believe in the existence of non measurable sets, you could let A = S for such a
µ non measurable set and verify that S is µ⌊S measurable.
The next theorem is the main result on outer measures. It is a very general
result which applies whenever one has an outer measure on the power set of any
set. This theorem will be referred to as Caratheodory’s procedure in the rest of the
book.
Theorem 9.4 The collection of µ measurable sets, S, forms a σ algebra and
If Fi ∈S, Fi ∩Fj = ∅, then µ(∪∞
i=1Fi) =
∞
X
i=1
µ(Fi).
(9.3)
If · · ·Fn ⊆Fn+1 ⊆· · ·, then if F = ∪∞
n=1Fn and Fn ∈S, it follows that
µ(F) = lim
n→∞µ(Fn).
(9.4)
If · · ·Fn ⊇Fn+1 ⊇· · ·, and if F = ∩∞
n=1Fn for Fn ∈S then if µ(F1) < ∞,
µ(F) = lim
n→∞µ(Fn).
(9.5)
Also, (S, µ) is complete. By this it is meant that if F ∈S and if E ⊆Ωwith
µ(E \ F) + µ(F \ E) = 0, then E ∈S.

9.1.
OUTER MEASURES
211
Proof: First note that ∅and Ωare obviously in S. Now suppose A, B ∈S. I
will show A \ B ≡A ∩BC is in S. To do so, consider the following picture.
S T AC T BC
S T AC T B
S T A T B
S T A T BC
A
B
S
Since µ is subadditive,
µ (S) ≤µ
¡
S ∩A ∩BC¢
+ µ (A ∩B ∩S) + µ
¡
S ∩B ∩AC¢
+ µ
¡
S ∩AC ∩BC¢
.
Now using A, B ∈S,
µ (S)
≤
µ
¡
S ∩A ∩BC¢
+ µ (S ∩A ∩B) + µ
¡
S ∩B ∩AC¢
+ µ
¡
S ∩AC ∩BC¢
=
µ (S ∩A) + µ
¡
S ∩AC¢
= µ (S)
It follows equality holds in the above. Now observe using the picture if you like that
(A ∩B ∩S) ∪
¡
S ∩B ∩AC¢
∪
¡
S ∩AC ∩BC¢
= S \ (A \ B)
and therefore,
µ (S)
=
µ
¡
S ∩A ∩BC¢
+ µ (A ∩B ∩S) + µ
¡
S ∩B ∩AC¢
+ µ
¡
S ∩AC ∩BC¢
≥
µ (S ∩(A \ B)) + µ (S \ (A \ B)) .
Therefore, since S is arbitrary, this shows A \ B ∈S.
Since Ω∈S, this shows that A ∈S if and only if AC ∈S. Now if A, B ∈S,
A ∪B = (AC ∩BC)C = (AC \ B)C ∈S. By induction, if A1, · · ·, An ∈S, then so is
∪n
i=1Ai. If A, B ∈S, with A ∩B = ∅,
µ(A ∪B) = µ((A ∪B) ∩A) + µ((A ∪B) \ A) = µ(A) + µ(B).

212
THE CONSTRUCTION OF MEASURES
By induction, if Ai ∩Aj = ∅and Ai ∈S, µ(∪n
i=1Ai) = Pn
i=1 µ(Ai).
Now let A = ∪∞
i=1Ai where Ai ∩Aj = ∅for i ̸= j.
∞
X
i=1
µ(Ai) ≥µ(A) ≥µ(∪n
i=1Ai) =
n
X
i=1
µ(Ai).
Since this holds for all n, you can take the limit as n →∞and conclude,
∞
X
i=1
µ(Ai) = µ(A)
which establishes 9.3. Part 9.4 follows from part 9.3 just as in the proof of Theorem
8.5 on Page 172. That is, letting F0 ≡∅, use part 9.3 to write
µ (F)
=
µ (∪∞
k=1 (Fk \ Fk−1)) =
∞
X
k=1
µ (Fk \ Fk−1)
=
lim
n→∞
n
X
k=1
(µ (Fk) −µ (Fk−1)) = lim
n→∞µ (Fn) .
In order to establish 9.5, let the Fn be as given there. Then, since (F1 \ Fn)
increases to (F1 \ F), 9.4 implies
lim
n→∞(µ (F1) −µ (Fn)) = µ (F1 \ F) .
Now µ (F1 \ F) + µ (F) ≥µ (F1) and so µ (F1 \ F) ≥µ (F1) −µ (F). Hence
lim
n→∞(µ (F1) −µ (Fn)) = µ (F1 \ F) ≥µ (F1) −µ (F)
which implies
lim
n→∞µ (Fn) ≤µ (F) .
But since F ⊆Fn,
µ (F) ≤lim
n→∞µ (Fn)
and this establishes 9.5. Note that it was assumed µ (F1) < ∞because µ (F1) was
subtracted from both sides.
It remains to show S is closed under countable unions. Recall that if A ∈S, then
AC ∈S and S is closed under ﬁnite unions. Let Ai ∈S, A = ∪∞
i=1Ai, Bn = ∪n
i=1Ai.
Then
µ(S)
=
µ(S ∩Bn) + µ(S \ Bn)
(9.6)
=
(µ⌊S)(Bn) + (µ⌊S)(BC
n ).
By Lemma 9.3 Bn is (µ⌊S) measurable and so is BC
n .
I want to show µ(S) ≥
µ(S \ A) + µ(S ∩A). If µ(S) = ∞, there is nothing to prove. Assume µ(S) < ∞.

9.1.
OUTER MEASURES
213
Then apply Parts 9.5 and 9.4 to the outer measure, µ⌊S in 9.6 and let n →∞.
Thus
Bn ↑A, BC
n ↓AC
and this yields µ(S) = (µ⌊S)(A) + (µ⌊S)(AC) = µ(S ∩A) + µ(S \ A).
Therefore A ∈S and this proves Parts 9.3, 9.4, and 9.5. It remains to prove the
last assertion about the measure being complete.
Let F ∈S and let µ(E \ F) + µ(F \ E) = 0. Consider the following picture.
E
F
S
Then referring to this picture and using F ∈S,
µ(S)
≤
µ(S ∩E) + µ(S \ E)
≤
µ (S ∩E ∩F) + µ ((S ∩E) \ F) + µ (S \ F) + µ (F \ E)
≤
µ (S ∩F) + µ (E \ F) + µ (S \ F) + µ (F \ E)
=
µ (S ∩F) + µ (S \ F) = µ (S)
Hence µ(S) = µ(S ∩E)+µ(S \E) and so E ∈S. This shows that (S, µ) is complete
and proves the theorem.
Completeness usually occurs in the following form. E ⊆F ∈S and µ (F) = 0.
Then E ∈S.
Where do outer measures come from? One way to obtain an outer measure is
to start with a measure µ, deﬁned on a σ algebra of sets, S, and use the following
deﬁnition of the outer measure induced by the measure.
Deﬁnition 9.5 Let µ be a measure deﬁned on a σ algebra of sets, S ⊆P (Ω). Then
the outer measure induced by µ, denoted by µ is deﬁned on P (Ω) as
µ(E) = inf{µ(F) : F ∈S and F ⊇E}.
A measure space, (S, Ω, µ) is σ ﬁnite if there exist measurable sets, Ωi with µ (Ωi) <
∞and Ω= ∪∞
i=1Ωi.
You should prove the following lemma.
Lemma 9.6 If (S, Ω, µ) is σ ﬁnite then there exist disjoint measurable sets, {Bn}
such that µ (Bn) < ∞and ∪∞
n=1Bn = Ω.
The following lemma deals with the outer measure generated by a measure
which is σ ﬁnite. It says that if the given measure is σ ﬁnite and complete then no
new measurable sets are gained by going to the induced outer measure and then
considering the measurable sets in the sense of Caratheodory.

214
THE CONSTRUCTION OF MEASURES
Lemma 9.7
Let (Ω, S, µ) be any measure space and let µ : P(Ω) →[0, ∞] be the
outer measure induced by µ. Then µ is an outer measure as claimed and if S is the
set of µ measurable sets in the sense of Caratheodory, then S ⊇S and µ = µ on S.
Furthermore, if µ is σ ﬁnite and (Ω, S, µ) is complete, then S = S.
Proof: It is easy to see that µ is an outer measure. Let E ∈S. The plan is to
show E ∈S and µ(E) = µ(E). To show this, let S ⊆Ωand then show
µ(S) ≥µ(S ∩E) + µ(S \ E).
(9.7)
This will verify that E ∈S. If µ(S) = ∞, there is nothing to prove, so assume
µ(S) < ∞. Thus there exists T ∈S, T ⊇S, and
µ(S)
>
µ(T) −ε = µ(T ∩E) + µ(T \ E) −ε
≥
µ(T ∩E) + µ(T \ E) −ε
≥
µ(S ∩E) + µ(S \ E) −ε.
Since ε is arbitrary, this proves 9.7 and veriﬁes S ⊆S. Now if E ∈S and V ⊇E
with V ∈S, µ(E) ≤µ(V ). Hence, taking inf, µ(E) ≤µ(E). But also µ(E) ≥µ(E)
since E ∈S and E ⊇E. Hence
µ(E) ≤µ(E) ≤µ(E).
Next consider the claim about not getting any new sets from the outer measure
in the case the measure space is σ ﬁnite and complete.
Claim 1: If E, D ∈S, and µ(E \ D) = 0, then if D ⊆F ⊆E, it follows F ∈S.
Proof of claim 1:
F \ D ⊆E \ D ∈S,
and E\D is a set of measure zero. Therefore, since (Ω, S, µ)
is complete, F \D ∈S
and so
F = D ∪(F \ D) ∈S.
Claim 2: Suppose F ∈S and µ (F) < ∞. Then F ∈S.
Proof of the claim 2: From the deﬁnition of µ, it follows there exists E ∈S
such that E ⊇F and µ (E) = µ (F) . Therefore,
µ (E) = µ (E \ F) + µ (F)
so
µ (E \ F) = 0.
(9.8)
Similarly, there exists D1 ∈S such that
D1 ⊆E, D1 ⊇(E \ F) , µ (D1) = µ (E \ F) .
and
µ (D1 \ (E \ F)) = 0.
(9.9)

9.2.
REGULAR MEASURES
215
E
F
D1
D
Now let D = E \ D1. It follows D ⊆F because if x ∈D, then x ∈E but
x /∈(E \ F) and so x ∈F. Also F \ D = D1 \ (E \ F) because both sides equal
D1 ∩F \ E.
Then from 9.8 and 9.9,
µ (E \ D)
≤
µ (E \ F) + µ (F \ D)
=
µ (E \ F) + µ (D1 \ (E \ F)) = 0.
By Claim 1, it follows F ∈S. This proves Claim 2.
Now since (Ω, S,µ) is σ ﬁnite, there are sets of S, {Bn}∞
n=1 such that µ (Bn) <
∞, ∪nBn = Ω. Then F ∩Bn ∈S by Claim 2. Therefore, F = ∪∞
n=1F ∩Bn ∈S and
so S =S. This proves the lemma.
9.2
Regular Measures
Usually Ωis not just a set. It is also a topological space. It is very important to
consider how the measure is related to this topology.
Deﬁnition 9.8 Let µ be a measure on a σ algebra S, of subsets of Ω, where (Ω, τ)
is a topological space. µ is a Borel measure if S contains all Borel sets. µ is called
outer regular if µ is Borel and for all E ∈S,
µ(E) = inf{µ(V ) : V is open and V ⊇E}.
µ is called inner regular if µ is Borel and
µ(E) = sup{µ(K) : K ⊆E, and K is compact}.
If the measure is both outer and inner regular, it is called regular.
It will be assumed in what follows that (Ω, τ) is a locally compact Hausdorﬀ
space. This means it is Hausdorﬀ: If p, q ∈Ωsuch that p ̸= q, there exist open

216
THE CONSTRUCTION OF MEASURES
sets, Up and Uq containing p and q respectively such that Up ∩Uq = ∅and Locally
compact: There exists a basis of open sets for the topology, B such that for each
U ∈B, U is compact. Recall B is a basis for the topology if ∪B = Ωand if every
open set in τ is the union of sets of B.
Also recall a Hausdorﬀspace is normal if
whenever H and C are two closed sets, there exist disjoint open sets, UH and UC
containing H and C respectively. A regular space is one which has the property
that if p is a point not in H, a closed set, then there exist disjoint open sets, Up and
UH containing p and H respectively.
9.3
Urysohn’s lemma
Urysohn’s lemma which characterizes normal spaces is a very important result which
is useful in general topology and in the construction of measures. Because it is
somewhat technical a proof is given for the part which is needed.
Theorem 9.9 (Urysohn) Let (X, τ) be normal and let H ⊆U where H is closed
and U is open. Then there exists g : X →[0, 1] such that g is continuous, g (x) = 1
on H and g (x) = 0 if x /∈U.
Proof: Let D ≡{rn}∞
n=1 be the rational numbers in (0, 1). Choose Vr1 an open
set such that
H ⊆Vr1 ⊆V r1 ⊆U.
This can be done by applying the assumption that X is normal to the disjoint closed
sets, H and U C, to obtain open sets V and W with
H ⊆V, U C ⊆W, and V ∩W = ∅.
Then
H ⊆V ⊆V , V ∩U C = ∅
and so let Vr1 = V .
Suppose Vr1, · · ·, Vrk have been chosen and list the rational numbers r1, · · ·, rk
in order,
rl1 < rl2 < · · · < rlk for {l1, · · ·, lk} = {1, · · ·, k}.
If rk+1 > rlk then letting p = rlk, let Vrk+1 satisfy
V p ⊆Vrk+1 ⊆V rk+1 ⊆U.
If rk+1 ∈(rli, rli+1), let p = rli and let q = rli+1. Then let Vrk+1 satisfy
V p ⊆Vrk+1 ⊆V rk+1 ⊆Vq.
If rk+1 < rl1, let p = rl1 and let Vrk+1 satisfy
H ⊆Vrk+1 ⊆V rk+1 ⊆Vp.

9.3.
URYSOHN’S LEMMA
217
Thus there exist open sets Vr for each r ∈Q ∩(0, 1) with the property that if
r < s,
H ⊆Vr ⊆V r ⊆Vs ⊆V s ⊆U.
Now let
f (x) = inf{t ∈D : x ∈Vt}, f (x) ≡1 if x /∈
[
t∈D
Vt.
I claim f is continuous.
f −1 ([0, a)) = ∪{Vt : t < a, t ∈D},
an open set.
Next consider x ∈f −1 ([0, a]) so f (x) ≤a. If t > a, then x ∈Vt because if not,
then
inf{t ∈D : x ∈Vt} > a.
Thus
f −1 ([0, a]) = ∩{Vt : t > a} = ∩{V t : t > a}
which is a closed set. If a = 1, f −1 ([0, 1]) = f −1 ([0, a]) = X. Therefore,
f −1 ((a, 1]) = X \ f −1 ([0, a]) = open set.
It follows f is continuous. Clearly f (x) = 0 on H. If x ∈U C, then x /∈Vt for any
t ∈D so f (x) = 1 on U C. Let g (x) = 1 −f (x). This proves the theorem.
In any metric space there is a much easier proof of the conclusion of Urysohn’s
lemma which applies.
Lemma 9.10 Let S be a nonempty subset of a metric space, (X, d) . Deﬁne
f (x) ≡dist (x, S) ≡inf {d (x, y) : y ∈S} .
Then f is continuous.
Proof:
Consider |f (x) −f (x1)|and suppose without loss of generality that
f (x1) ≥f (x) . Then choose y ∈S such that f (x) + ε > d (x, y) . Then
|f (x1) −f (x)|
=
f (x1) −f (x) ≤f (x1) −d (x, y) + ε
≤
d (x1, y) −d (x, y) + ε
≤
d (x, x1) + d (x, y) −d (x, y) + ε
=
d (x1, x) + ε.
Since ε is arbitrary, it follows that |f (x1) −f (x)| ≤d (x1, x) and this proves the
lemma.
Theorem 9.11 (Urysohn’s lemma for metric space) Let H be a closed subset of
an open set, U in a metric space, (X, d) . Then there exists a continuous function,
g : X →[0, 1] such that g (x) = 1 for all x ∈H and g (x) = 0 for all x /∈U.

218
THE CONSTRUCTION OF MEASURES
Proof: If x /∈C, a closed set, then dist (x, C) > 0 because if not, there would
exist a sequence of points of C converging to x and it would follow that x ∈C.
Therefore, dist (x, H) + dist
¡
x, U C¢
> 0 for all x ∈X. Now deﬁne a continuous
function, g as
g (x) ≡
dist
¡
x, U C¢
dist (x, H) + dist (x, U C).
It is easy to see this veriﬁes the conclusions of the theorem and this proves the
theorem.
Theorem 9.12 Every compact Hausdorﬀspace is normal.
Proof: First it is shown that X, is regular. Let H be a closed set and let p /∈H.
Then for each h ∈H, there exists an open set Uh containing p and an open set Vh
containing h such that Uh ∩Vh = ∅. Since H must be compact, it follows there
are ﬁnitely many of the sets Vh, Vh1 · · · Vhn such that H ⊆∪n
i=1Vhi. Then letting
U = ∩n
i=1Uhi and V = ∪n
i=1Vhi, it follows that p ∈U, H ∈V and U ∩V = ∅. Thus
X is regular as claimed.
Next let K and H be disjoint nonempty closed sets.Using regularity of X, for
every k ∈K, there exists an open set Uk containing k and an open set Vk containing
H such that these two open sets have empty intersection. Thus H∩U k = ∅. Finitely
many of the Uk, Uk1, ···, Ukp cover K and so ∪p
i=1U ki is a closed set which has empty
intersection with H. Therefore, K ⊆∪p
i=1Uki and H ⊆
¡
∪p
i=1U ki
¢C. This proves
the theorem.
A useful construction when dealing with locally compact Hausdorﬀspaces is the
notion of the one point compactiﬁcation of the space discussed earler. However, it
is reviewed here for the sake of convenience or in case you have not read the earlier
treatment.
Deﬁnition 9.13 Suppose (X, τ) is a locally compact Hausdorﬀspace.
Then let
e
X ≡X ∪{∞} where ∞is just the name of some point which is not in X which is
called the point at inﬁnity. A basis for the topology eτ for e
X is
τ ∪
©
KC where K is a compact subset of X
ª
.
The complement is taken with respect to e
X and so the open sets, KC are basic open
sets which contain ∞.
The reason this is called a compactiﬁcation is contained in the next lemma.
Lemma 9.14 If (X, τ) is a locally compact Hausdorﬀspace, then
³
e
X, eτ
´
is a com-
pact Hausdorﬀspace.
Proof: Since (X, τ) is a locally compact Hausdorﬀspace, it follows
³
e
X, eτ
´
is
a Hausdorﬀtopological space. The only case which needs checking is the one of
p ∈X and ∞. Since (X, τ) is locally compact, there exists an open set of τ, U

9.3.
URYSOHN’S LEMMA
219
having compact closure which contains p. Then p ∈U and ∞∈U
C and these are
disjoint open sets containing the points, p and ∞respectively. Now let C be an
open cover of e
X with sets from eτ. Then ∞must be in some set, U∞from C, which
must contain a set of the form KC where K is a compact subset of X. Then there
exist sets from C, U1, · · ·, Ur which cover K. Therefore, a ﬁnite subcover of e
X is
U1, · · ·, Ur, U∞.
Theorem 9.15 Let X be a locally compact Hausdorﬀspace, and let K be a compact
subset of the open set V . Then there exists a continuous function, f : X →[0, 1],
such that f equals 1 on K and {x : f (x) ̸= 0} ≡spt (f) is a compact subset of V .
Proof: Let e
X be the space just described. Then K and V are respectively
closed and open in eτ. By Theorem 9.12 there exist open sets in eτ, U, and W such
that K ⊆U, ∞∈V C ⊆W, and U ∩W = U ∩(W \ {∞}) = ∅. Thus W \ {∞} is
an open set in the original topological space which contains V C, U is an open set in
the original topological space which contains K, and W \ {∞} and U are disjoint.
Now for each x ∈K, let Ux be a basic open set whose closure is compact and
such that
x ∈Ux ⊆U.
Thus Ux must have empty intersection with V C because the open set, W \ {∞}
contains no points of Ux. Since K is compact, there are ﬁnitely many of these sets,
Ux1, Ux2, · · ·, Uxn which cover K. Now let H ≡∪n
i=1Uxi.
Claim: H = ∪n
i=1Uxi
Proof of claim: Suppose p ∈H. If p /∈∪n
i=1Uxi then if follows p /∈Uxi
for
each i. Therefore, there exists an open set, Ri containing p such that Ri contains
no other points of Uxi. Therefore, R ≡∩n
i=1Ri is an open set containing p which
contains no other points of ∪n
i=1Uxi = W, a contradiction. Therefore, H ⊆∪n
i=1Uxi.
On the other hand, if p ∈Uxi then p is obviously in H so this proves the claim.
From the claim, K ⊆H ⊆H ⊆V and H is compact because it is the ﬁnite
union of compact sets. Repeating the same argument, there exists an open set, I
such that H ⊆I ⊆I ⊆V with I compact. Now
¡
I, τ I
¢
is a compact topological
space where τ I is the topology which is obtained by taking intersections of open
sets in X with I. Therefore, by Urysohn’s lemma, there exists f : I →[0, 1] such
that f is continuous at every point of I and also f (K) = 1 while f
¡
I \ H
¢
= 0.
Extending f to equal 0 on I
C, it follows that f is continuous on X, has values in
[0, 1] , and satisﬁes f (K) = 1 and spt (f) is a compact subset contained in I ⊆V.
This proves the theorem.
In fact, the conclusion of the above theorem could be used to prove that the
topological space is locally compact. However, this is not needed here.
Deﬁnition 9.16 Deﬁne spt(f) (support of f) to be the closure of the set {x :
f(x) ̸= 0}. If V is an open set, Cc(V ) will be the set of continuous functions f,
deﬁned on Ωhaving spt(f) ⊆V . Thus in Theorem 9.15, f ∈Cc(V ).

220
THE CONSTRUCTION OF MEASURES
Deﬁnition 9.17 If K is a compact subset of an open set, V , then K ≺φ ≺V if
φ ∈Cc(V ), φ(K) = {1}, φ(Ω) ⊆[0, 1],
where Ωdenotes the whole topological space considered. Also for φ ∈Cc(Ω), K ≺φ
if
φ(Ω) ⊆[0, 1] and φ(K) = 1.
and φ ≺V if
φ(Ω) ⊆[0, 1] and spt(φ) ⊆V.
Theorem 9.18 (Partition of unity) Let K be a compact subset of a locally compact
Hausdorﬀtopological space satisfying Theorem 9.15 and suppose
K ⊆V = ∪n
i=1Vi, Vi open.
Then there exist ψi ≺Vi with
n
X
i=1
ψi(x) = 1
for all x ∈K.
Proof: Let K1 = K \ ∪n
i=2Vi. Thus K1 is compact and K1 ⊆V1. Let K1 ⊆
W1 ⊆W 1 ⊆V1 with W 1compact. To obtain W1, use Theorem 9.15 to get f such
that K1 ≺f ≺V1 and let W1 ≡{x : f (x) ̸= 0} . Thus W1, V2, · · ·Vn covers K and
W 1 ⊆V1. Let K2 = K \ (∪n
i=3Vi ∪W1). Then K2 is compact and K2 ⊆V2. Let
K2 ⊆W2 ⊆W 2 ⊆V2 W 2 compact. Continue this way ﬁnally obtaining W1, ···, Wn,
K ⊆W1 ∪· · · ∪Wn, and W i ⊆Vi W i compact. Now let W i ⊆Ui ⊆U i ⊆Vi , U i
compact.
Wi
Ui Vi
By Theorem 9.15, let U i ≺φi ≺Vi, ∪n
i=1W i ≺γ ≺∪n
i=1Ui. Deﬁne
ψi(x) =
½ γ(x)φi(x)/ Pn
j=1 φj(x) if Pn
j=1 φj(x) ̸= 0,
0 if Pn
j=1 φj(x) = 0.
If x is such that Pn
j=1 φj(x) = 0, then x /∈∪n
i=1U i. Consequently γ(y) = 0 for
all y near x and so ψi(y) = 0 for all y near x. Hence ψi is continuous at such x.
If Pn
j=1 φj(x) ̸= 0, this situation persists near x and so ψi is continuous at such
points. Therefore ψi is continuous. If x ∈K, then γ(x) = 1 and so Pn
j=1 ψj(x) = 1.
Clearly 0 ≤ψi (x) ≤1 and spt(ψj) ⊆Vj. This proves the theorem.
The following corollary won’t be needed immediately but is of considerable in-
terest later.

9.4.
POSITIVE LINEAR FUNCTIONALS
221
Corollary 9.19 If H is a compact subset of Vi, there exists a partition of unity
such that ψi (x) = 1 for all x ∈H in addition to the conclusion of Theorem 9.18.
Proof: Keep Vi the same but replace Vj with f
Vj ≡Vj \ H. Now in the proof
above, applied to this modiﬁed collection of open sets, if j ̸= i, φj (x) = 0 whenever
x ∈H. Therefore, ψi (x) = 1 on H.
9.4
Positive Linear Functionals
Deﬁnition 9.20 Let (Ω, τ) be a topological space.
L : Cc(Ω) →C is called a
positive linear functional if L is linear,
L(af1 + bf2) = aLf1 + bLf2,
and if Lf ≥0 whenever f ≥0.
Theorem 9.21 (Riesz representation theorem) Let (Ω, τ) be a locally compact Haus-
dorﬀspace and let L be a positive linear functional on Cc(Ω). Then there exists a
σ algebra S containing the Borel sets and a unique measure µ, deﬁned on S, such
that
µ is complete,
(9.10)
µ(K)
<
∞for all K compact,
(9.11)
µ(F) = sup{µ(K) : K ⊆F, K compact},
for all F open and for all F ∈S with µ(F) < ∞,
µ(F) = inf{µ(V ) : V ⊇F, V open}
for all F ∈S, and
Z
fdµ = Lf
for all f ∈Cc(Ω).
(9.12)
The plan is to deﬁne an outer measure and then to show that it, together with the
σ algebra of sets measurable in the sense of Caratheodory, satisﬁes the conclusions
of the theorem. Always, K will be a compact set and V will be an open set.
Deﬁnition 9.22 µ(V ) ≡sup{Lf : f ≺V } for V open, µ(∅) = 0. µ(E) ≡
inf{µ(V ) : V ⊇E} for arbitrary sets E.
Lemma 9.23 µ is a well-deﬁned outer measure.
Proof: First it is necessary to verify µ is well deﬁned because there are two
descriptions of it on open sets. Suppose then that µ1 (V ) ≡inf{µ(U) : U ⊇V
and U is open}. It is required to verify that µ1 (V ) = µ (V ) where µ is given as
sup{Lf : f ≺V }. If U ⊇V, then µ (U) ≥µ (V ) directly from the deﬁnition. Hence

222
THE CONSTRUCTION OF MEASURES
from the deﬁnition of µ1, it follows µ1 (V ) ≥µ (V ) . On the other hand, V ⊇V and
so µ1 (V ) ≤µ (V ) . This veriﬁes µ is well deﬁned.
It remains to show that µ is an outer measure. Let V = ∪∞
i=1Vi and let f ≺V .
Then spt(f) ⊆∪n
i=1Vi for some n. Let ψi ≺Vi, Pn
i=1 ψi = 1 on spt(f).
Lf =
n
X
i=1
L(fψi) ≤
n
X
i=1
µ(Vi) ≤
∞
X
i=1
µ(Vi).
Hence
µ(V ) ≤
∞
X
i=1
µ(Vi)
since f ≺V is arbitrary. Now let E = ∪∞
i=1Ei. Is µ(E) ≤P∞
i=1 µ(Ei)? Without
loss of generality, it can be assumed µ(Ei) < ∞for each i since if not so, there is
nothing to prove. Let Vi ⊇Ei with µ(Ei) + ε2−i > µ(Vi).
µ(E) ≤µ(∪∞
i=1Vi) ≤
∞
X
i=1
µ(Vi) ≤ε +
∞
X
i=1
µ(Ei).
Since ε was arbitrary, µ(E) ≤P∞
i=1 µ(Ei) which proves the lemma.
Lemma 9.24 Let K be compact, g ≥0, g ∈Cc(Ω), and g = 1 on K.
Then
µ(K) ≤Lg. Also µ(K) < ∞whenever K is compact.
Proof: Let α ∈(0, 1) and Vα = {x : g(x) > α} so Vα ⊇K and let h ≺Vα.
g > α
Vα
K
Then h ≤1 on Vα while gα−1 ≥1 on Vα and so gα−1 ≥h which implies
L(gα−1) ≥Lh and that therefore, since L is linear,
Lg ≥αLh.
Since h ≺Vα is arbitrary, and K ⊆Vα,
Lg ≥αµ (Vα) ≥αµ (K) .
Letting α ↑1 yields Lg ≥µ(K). This proves the ﬁrst part of the lemma. The
second assertion follows from this and Theorem 9.15. If K is given, let
K ≺g ≺Ω
and so from what was just shown, µ (K) ≤Lg < ∞. This proves the lemma.

9.4.
POSITIVE LINEAR FUNCTIONALS
223
Lemma 9.25 If A and B are disjoint compact subsets of Ω, then µ(A ∪B) =
µ(A) + µ(B).
Proof: By Theorem 9.15, there exists h ∈Cc (Ω) such that A ≺h ≺BC. Let
U1 = h−1(( 1
2, 1]), V1 = h−1([0, 1
2)). Then A ⊆U1, B ⊆V1 and U1 ∩V1 = ∅.
B
V1
A
U1
From Lemma 9.24 µ(A ∪B) < ∞and so there exists an open set, W such that
W ⊇A ∪B, µ (A ∪B) + ε > µ (W) .
Now let U = U1 ∩W and V = V1 ∩W. Then
U ⊇A, V ⊇B, U ∩V = ∅, and µ(A ∪B) + ε ≥µ (W) ≥µ(U ∪V ).
Let A ≺f ≺U, B ≺g ≺V . Then by Lemma 9.24,
µ(A ∪B) + ε ≥µ(U ∪V ) ≥L(f + g) = Lf + Lg ≥µ(A) + µ(B).
Since ε > 0 is arbitrary, this proves the lemma.
From Lemma 9.24 the following lemma is obtained.
Lemma 9.26 Let f ∈Cc(Ω), f(Ω) ⊆[0, 1]. Then µ(spt(f)) ≥Lf. Also, every
open set, V satisﬁes
µ (V ) = sup {µ (K) : K ⊆V } .
Proof: Let V ⊇spt(f) and let spt(f) ≺g ≺V . Then Lf ≤Lg ≤µ(V ) because
f ≤g. Since this holds for all V ⊇spt(f), Lf ≤µ(spt(f)) by deﬁnition of µ.
V
spt(f)
Finally, let V be open and let l < µ (V ) . Then from the deﬁnition of µ, there
exists f ≺V such that L (f) > l. Therefore, l < µ (spt (f)) ≤µ (V ) and so this
shows the claim about inner regularity of the measure on an open set.
Lemma 9.27 If K is compact there exists V open, V ⊇K, such that µ(V \ K) ≤
ε. If V is open with µ(V ) < ∞, then there exists a compact set, K ⊆V with
µ(V \ K) ≤ε.

224
THE CONSTRUCTION OF MEASURES
Proof: Let K be compact. Then from the deﬁnition of µ, there exists an open
set U, with µ(U) < ∞and U ⊇K. Suppose for every open set, V , containing
K, µ(V \ K) > ε.
Then there exists f ≺U \ K with Lf > ε.
Consequently,
µ((f)) > Lf > ε. Let K1 = spt(f) and repeat the construction with U \ K1 in
place of U.
U
K1
K
K2
K3
Continuing in this way yields a sequence of disjoint compact sets, K, K1, · · ·
contained in U such that µ(Ki) > ε. By Lemma 9.25
µ(U) ≥µ(K ∪∪r
i=1Ki) = µ(K) +
r
X
i=1
µ(Ki) ≥rε
for all r, contradicting µ(U) < ∞. This demonstrates the ﬁrst part of the lemma.
To show the second part, employ a similar construction. Suppose µ(V \ K) > ε
for all K ⊆V . Then µ(V ) > ε so there exists f ≺V with Lf > ε. Let K1 = spt(f)
so µ(spt(f)) > ε. If K1 · · · Kn, disjoint, compact subsets of V have been chosen,
there must exist g ≺(V \ ∪n
i=1Ki) be such that Lg > ε. Hence µ(spt(g)) > ε. Let
Kn+1 = spt(g). In this way there exists a sequence of disjoint compact subsets of
V , {Ki} with µ(Ki) > ε. Thus for any m, K1 · · · Km are all contained in V and
are disjoint and compact. By Lemma 9.25
µ(V ) ≥µ(∪m
i=1Ki) =
m
X
i=1
µ(Ki) > mε
for all m, a contradiction to µ(V ) < ∞. This proves the second part.
Lemma 9.28 Let S be the σ algebra of µ measurable sets in the sense of Carath-
eodory. Then S ⊇Borel sets and µ is inner regular on every open set and for every
E ∈S with µ(E) < ∞.
Proof: Deﬁne
S1 = {E ⊆Ω: E ∩K ∈S}
for all compact K.

9.4.
POSITIVE LINEAR FUNCTIONALS
225
Let C be a compact set. The idea is to show that C ∈S. From this it will follow
that the closed sets are in S1 because if C is only closed, C ∩K is compact. Hence
C ∩K = (C ∩K) ∩K ∈S. The steps are to ﬁrst show the compact sets are in
S and this implies the closed sets are in S1. Then you show S1 is a σ algebra and
so it contains the Borel sets. Finally, it is shown that S1 = S and then the inner
regularity conclusion is established.
Let V be an open set with µ (V ) < ∞. I will show that
µ (V ) ≥µ(V \ C) + µ(V ∩C).
By Lemma 9.27, there exists an open set U containing C and a compact subset of
V , K, such that µ(V \ K) < ε and µ (U \ C) < ε.
U
C
V
K
Then by Lemma 9.25,
µ(V )
≥
µ(K) ≥µ((K \ U) ∪(K ∩C))
=
µ(K \ U) + µ(K ∩C)
≥
µ(V \ C) + µ(V ∩C) −3ε
Since ε is arbitrary,
µ(V ) = µ(V \ C) + µ(V ∩C)
(9.13)
whenever C is compact and V is open. (If µ (V ) = ∞, it is obvious that µ (V ) ≥
µ(V \ C) + µ(V ∩C) and it is always the case that µ (V ) ≤µ (V \ C) + µ (V ∩C) .)
Of course 9.13 is exactly what needs to be shown for arbitrary S in place of V .
It suﬃces to consider only S having µ (S) < ∞. If S ⊆Ω, with µ(S) < ∞, let
V ⊇S, µ(S) + ε > µ(V ). Then from what was just shown, if C is compact,
ε + µ(S)
>
µ(V ) = µ(V \ C) + µ(V ∩C)
≥
µ(S \ C) + µ(S ∩C).
Since ε is arbitrary, this shows the compact sets are in S. As discussed above, this
veriﬁes the closed sets are in S1.
Therefore, S1 contains the closed sets and S contains the compact sets. There-
fore, if E ∈S and K is a compact set, it follows K ∩E ∈S and so S1 ⊇S.
To see that S1 is closed with respect to taking complements, let E ∈S1.
K = (EC ∩K) ∪(E ∩K).

226
THE CONSTRUCTION OF MEASURES
Then from the fact, just established, that the compact sets are in S,
EC ∩K = K \ (E ∩K) ∈S.
Similarly S1 is closed under countable unions. Thus S1 is a σ algebra which contains
the Borel sets since it contains the closed sets.
The next task is to show S1 = S. Let E ∈S1 and let V be an open set with
µ(V ) < ∞and choose K ⊆V such that µ(V \ K) < ε. Then since E ∈S1, it
follows E ∩K ∈S and
µ(V )
=
µ(V \ (K ∩E)) + µ(V ∩(K ∩E))
≥
µ(V \ E) + µ(V ∩E) −ε
because
µ (V ∩(K ∩E)) +
<ε
z
}|
{
µ (V \ K) ≥µ (V ∩E)
Since ε is arbitrary,
µ(V ) = µ(V \ E) + µ(V ∩E).
Now let S ⊆Ω. If µ(S) = ∞, then µ(S) = µ(S ∩E) + µ(S \ E). If µ(S) < ∞, let
V ⊇S, µ(S) + ε ≥µ(V ).
Then
µ(S) + ε ≥µ(V ) = µ(V \ E) + µ(V ∩E) ≥µ(S \ E) + µ(S ∩E).
Since ε is arbitrary, this shows that E ∈S and so S1 = S. Thus S ⊇Borel sets as
claimed.
From Lemma 9.26 and the deﬁnition of µ it follows µ is inner regular on all
open sets. It remains to show that µ(F) = sup{µ(K) : K ⊆F} for all F ∈S with
µ(F) < ∞. It might help to refer to the following crude picture to keep things
straight.
F
K
K ∩V C
U
V
In this picture the shaded area is V.
Let U be an open set, U ⊇F, µ(U) < ∞. Let V be open, V ⊇U \ F, and
µ(V \ (U \ F)) < ε. This can be obtained because µ is a measure on S. Thus from
outer regularity there exists V ⊇U \ F such that µ (U \ F) + ε > µ (V ) . Then
µ (V \ (U \ F)) + µ (U \ F) = µ (V )

9.4.
POSITIVE LINEAR FUNCTIONALS
227
and so
µ (V \ (U \ F)) = µ (V ) −µ (U \ F) < ε.
Also,
V \ (U \ F)
=
V ∩
¡
U ∩F C¢C
=
V ∩
£
U C ∪F
¤
=
(V ∩F) ∪
¡
V ∩U C¢
⊇
V ∩F
and so
µ(V ∩F) ≤µ (V \ (U \ F)) < ε.
Since V ⊇U ∩F C, V C ⊆U C ∪F so U ∩V C ⊆U ∩F = F. Hence U ∩V C is a
subset of F. Now let K ⊆U, µ(U \ K) < ε. Thus K ∩V C is a compact subset of
F and
µ(F)
=
µ(V ∩F) + µ(F \ V )
<
ε + µ(F \ V ) ≤ε + µ(U ∩V C) ≤2ε + µ(K ∩V C).
Since ε is arbitrary, this proves the second part of the lemma. Formula 9.11 of this
theorem was established earlier.
It remains to show µ satisﬁes 9.12.
Lemma 9.29
R
fdµ = Lf for all f ∈Cc(Ω).
Proof: Let f ∈Cc(Ω), f real-valued, and suppose f(Ω) ⊆[a, b]. Choose t0 < a
and let t0 < t1 < · · · < tn = b, ti −ti−1 < ε. Let
Ei = f −1((ti−1, ti]) ∩spt(f).
(9.14)
Note that ∪n
i=1Ei is a closed set and in fact
∪n
i=1 Ei = spt(f)
(9.15)
since Ω= ∪n
i=1f −1((ti−1, ti]). Let Vi ⊇Ei, Vi is open and let Vi satisfy
f (x) < ti + ε for all x ∈Vi,
(9.16)
µ(Vi \ Ei) < ε/n.
By Theorem 9.18 there exists hi ∈Cc(Ω) such that
hi ≺Vi,
n
X
i=1
hi(x) = 1 on spt(f).
Now note that for each i,
f(x)hi(x) ≤hi(x)(ti + ε).

228
THE CONSTRUCTION OF MEASURES
(If x ∈Vi, this follows from 9.16. If x /∈Vi both sides equal 0.) Therefore,
Lf
=
L(
n
X
i=1
fhi) ≤L(
n
X
i=1
hi(ti + ε))
=
n
X
i=1
(ti + ε)L(hi)
=
n
X
i=1
(|t0| + ti + ε)L(hi) −|t0|L
Ã n
X
i=1
hi
!
.
Now note that |t0| + ti + ε ≥0 and so from the deﬁnition of µ and Lemma 9.24,
this is no larger than
n
X
i=1
(|t0| + ti + ε)µ(Vi) −|t0|µ(spt(f))
≤
n
X
i=1
(|t0| + ti + ε)(µ(Ei) + ε/n) −|t0|µ(spt(f))
≤|t0|
n
X
i=1
µ(Ei) + |t0|ε +
n
X
i=1
tiµ(Ei) + ε(|t0| + |b|)
+ε
n
X
i=1
µ(Ei) + ε2 −|t0|µ(spt(f)).
From 9.15 and 9.14, the ﬁrst and last terms cancel. Therefore this is no larger than
(2|t0| + |b| + µ(spt(f)) + ε)ε +
n
X
i=1
ti−1µ(Ei) + εµ(spt(f))
≤
Z
fdµ + (2|t0| + |b| + 2µ(spt(f)) + ε)ε.
Since ε > 0 is arbitrary,
Lf ≤
Z
fdµ
(9.17)
for all f ∈Cc(Ω), f real. Hence equality holds in 9.17 because L(−f) ≤−
R
fdµ
so L(f) ≥
R
fdµ. Thus Lf =
R
fdµ for all f ∈Cc(Ω). Just apply the result for
real functions to the real and imaginary parts of f. This proves the Lemma.
This gives the existence part of the Riesz representation theorem.
It only remains to prove uniqueness. Suppose both µ1 and µ2 are measures on
S satisfying the conclusions of the theorem. Then if K is compact and V ⊇K, let
K ≺f ≺V . Then
µ1(K) ≤
Z
fdµ1 = Lf =
Z
fdµ2 ≤µ2(V ).

9.4.
POSITIVE LINEAR FUNCTIONALS
229
Thus µ1(K) ≤µ2(K) for all K. Similarly, the inequality can be reversed and so it
follows the two measures are equal on compact sets. By the assumption of inner
regularity on open sets, the two measures are also equal on all open sets. By outer
regularity, they are equal on all sets of S. This proves the theorem.
An important example of a locally compact Hausdorﬀspace is any metric space
in which the closures of balls are compact. For example, Rn with the usual metric
is an example of this. Not surprisingly, more can be said in this important special
case.
Theorem 9.30 Let (Ω, τ) be a metric space in which the closures of the balls are
compact and let L be a positive linear functional deﬁned on Cc (Ω) . Then there
exists a measure representing the positive linear functional which satisﬁes all the
conclusions of Theorem 9.15 and in addition the property that µ is regular. The
same conclusion follows if (Ω, τ) is a compact Hausdorﬀspace.
Theorem 9.31 Let (Ω, τ) be a metric space in which the closures of the balls are
compact and let L be a positive linear functional deﬁned on Cc (Ω) . Then there
exists a measure representing the positive linear functional which satisﬁes all the
conclusions of Theorem 9.15 and in addition the property that µ is regular. The
same conclusion follows if (Ω, τ) is a compact Hausdorﬀspace.
Proof: Let µ and S be as described in Theorem 9.21. The outer regularity
comes automatically as a conclusion of Theorem 9.21. It remains to verify inner
regularity. Let F ∈S and let l < k < µ (F) . Now let z ∈Ωand Ωn = B (z, n)
for
n ∈N. Thus F ∩Ωn ↑F. It follows that for n large enough,
k < µ (F ∩Ωn) ≤µ (F) .
Since µ (F ∩Ωn) < ∞it follows there exists a compact set, K such that K ⊆
F ∩Ωn ⊆F and
l < µ (K) ≤µ (F) .
This proves inner regularity. In case (Ω, τ) is a compact Hausdorﬀspace, the con-
clusion of inner regularity follows from Theorem 9.21. This proves the theorem.
The proof of the above yields the following corollary.
Corollary 9.32 Let (Ω, τ) be a locally compact Hausdorﬀspace and suppose µ
deﬁned on a σ algebra, S represents the positive linear functional L where L is
deﬁned on Cc (Ω) in the sense of Theorem 9.15. Suppose also that there exist Ωn ∈S
such that Ω= ∪∞
n=1Ωn and µ (Ωn) < ∞. Then µ is regular.
The following is on the uniqueness of the σ algebra in some cases.
Deﬁnition 9.33 Let (Ω, τ) be a locally compact Hausdorﬀspace and let L be a
positive linear functional deﬁned on Cc (Ω) such that the complete measure deﬁned
by the Riesz representation theorem for positive linear functionals is inner regular.
Then this is called a Radon measure.
Thus a Radon measure is complete, and
regular.

230
THE CONSTRUCTION OF MEASURES
Corollary 9.34 Let (Ω, τ) be a locally compact Hausdorﬀspace which is also σ
compact meaning
Ω= ∪∞
n=1Ωn, Ωn is compact,
and let L be a positive linear functional deﬁned on Cc (Ω) . Then if (µ1, S1) , and
(µ2, S2) are two Radon measures, together with their σ algebras which represent L
then the two σ algebras are equal and the two measures are equal.
Proof: Suppose (µ1, S1) and (µ2, S2) both work.
It will be shown the two
measures are equal on every compact set. Let K be compact and let V be an open
set containing K. Then let K ≺f ≺V. Then
µ1 (K) =
Z
K
dµ1 ≤
Z
fdµ1 = L (f) =
Z
fdµ2 ≤µ2 (V ) .
Therefore, taking the inﬁmum over all V containing K implies µ1 (K) ≤µ2 (K) .
Reversing the argument shows µ1 (K) = µ2 (K) . This also implies the two measures
are equal on all open sets because they are both inner regular on open sets. It is
being assumed the two measures are regular. Now let F ∈S1 with µ1 (F) < ∞.
Then there exist sets, H, G such that H ⊆F ⊆G such that H is the countable
union of compact sets and G is a countable intersection of open sets such that
µ1 (G) = µ1 (H) which implies µ1 (G \ H) = 0. Now G \ H can be written as the
countable intersection of sets of the form Vk \Kk where Vk is open, µ1 (Vk) < ∞and
Kk is compact. From what was just shown, µ2 (Vk \ Kk) = µ1 (Vk \ Kk) so it follows
µ2 (G \ H) = 0 also. Since µ2 is complete, and G and H are in S2, it follows F ∈S2
and µ2 (F) = µ1 (F) . Now for arbitrary F possibly having µ1 (F) = ∞, consider
F ∩Ωn. From what was just shown, this set is in S2 and µ2 (F ∩Ωn) = µ1 (F ∩Ωn).
Taking the union of these F ∩Ωn gives F ∈S2 and also µ1 (F) = µ2 (F) . This shows
S1 ⊆S2. Similarly, S2 ⊆S1.
The following lemma is often useful.
Lemma 9.35 Let (Ω, F, µ) be a measure space where Ωis a metric space having
closed balls compact or more generally a topological space. Suppose µ is a Radon
measure and f is measurable with respect to F. Then there exists a Borel measurable
function, g, such that g = f a.e.
Proof: Assume without loss of generality that f ≥0. Then let sn ↑f pointwise.
Say
sn (ω) =
Pn
X
k=1
cn
kXEn
k (ω)
where En
k ∈F. By the outer regularity of µ, there exists a Borel set, F n
k ⊇En
k such
that µ (F n
k ) = µ (En
k ). In fact F n
k can be assumed to be a Gδ set. Let
tn (ω) ≡
Pn
X
k=1
cn
kXF n
k (ω) .

9.5.
ONE DIMENSIONAL LEBESGUE MEASURE
231
Then tn is Borel measurable and tn (ω) = sn (ω) for all ω /∈Nn where Nn ∈F is
a set of measure zero. Now let N ≡∪∞
n=1Nn. Then N is a set of measure zero
and if ω /∈N, then tn (ω) →f (ω). Let N ′ ⊇N where N ′ is a Borel set and
µ (N ′) = 0. Then tnX(N′)C converges pointwise to a Borel measurable function, g,
and g (ω) = f (ω) for all ω /∈N ′. Therefore, g = f a.e. and this proves the lemma.
9.5
One Dimensional Lebesgue Measure
To obtain one dimensional Lebesgue measure, you use the positive linear functional
L given by
Lf =
Z
f (x) dx
whenever f ∈Cc (R) . Lebesgue measure, denoted by m is the measure obtained
from the Riesz representation theorem such that
Z
fdm = Lf =
Z
f (x) dx.
From this it is easy to verify that
m ([a, b]) = m ((a, b)) = b −a.
(9.18)
This will be done in general a little later but for now, consider the following picture
of functions, f k and gk converging pointwise as k →∞to X[a,b].
a + 1/k
@
@
R
a
£
£
£
£
1
B
B
B
B
b −1/k
¡
¡
ª
b
f k
a −1/k
@
@@
R
a
£
£
£
£
1
B
B
B
B
b
b + 1/k
¡
¡
ª
gk
Then
µ
b −a −2
k
¶
≤
Z
f kdx =
Z
f kdm ≤m ((a, b)) ≤m ([a, b])
=
Z
X[a,b]dm ≤
Z
gkdm =
Z
gkdx ≤
µ
b −a + 2
k
¶
.
From this the claim in 9.18 follows.
9.6
The Distribution Function
There is an interesting connection between the Lebesgue integral of a nonnegative
function with something called the distribution function.

232
THE CONSTRUCTION OF MEASURES
Deﬁnition 9.36 Let f ≥0 and suppose f is measurable. The distribution function
is the function deﬁned by
t →µ ([t < f]) .
Lemma 9.37 If {fn} is an increasing sequence of functions converging pointwise
to f then
µ ([f > t]) = lim
n→∞µ ([fn > t])
Proof: The sets, [fn > t] are increasing and their union is [f > t] because if
f (ω) > t, then for all n large enough, fn (ω) > t also. Therefore, from Theorem 8.5
on Page 172 the desired conclusion follows.
Lemma 9.38 Suppose s ≥0 is a measurable simple function,
s (ω) ≡
n
X
k=1
akXEk (ω)
where the ak are the distinct nonzero values of s, a1 < a2 < · · · < an. Suppose φ is
a C1 function deﬁned on [0, ∞) which has the property that φ (0) = 0, φ′ (t) > 0 for
all t. Then
Z ∞
0
φ′ (t) µ ([s > t]) dm =
Z
φ (s) dµ.
Proof: First note that if µ (Ek) = ∞for any k then both sides equal ∞and
so without loss of generality, assume µ (Ek) < ∞for all k. Letting a0 ≡0, the left
side equals
n
X
k=1
Z ak
ak−1
φ′ (t) µ ([s > t]) dm
=
n
X
k=1
Z ak
ak−1
φ′ (t)
n
X
i=k
µ (Ei) dm
=
n
X
k=1
n
X
i=k
µ (Ei)
Z ak
ak−1
φ′ (t) dm
=
n
X
k=1
n
X
i=k
µ (Ei) (φ (ak) −φ (ak−1))
=
n
X
i=1
µ (Ei)
i
X
k=1
(φ (ak) −φ (ak−1))
=
n
X
i=1
µ (Ei) φ (ai) =
Z
φ (s) dµ.
This proves the lemma.
With this lemma the next theorem which is the main result follows easily.
Theorem 9.39 Let f ≥0 be measurable and let φ be a C1 function deﬁned on
[0, ∞) which satisﬁes φ′ (t) > 0 for all t > 0 and φ (0) = 0. Then
Z
φ (f) dµ =
Z ∞
0
φ′ (t) µ ([f > t]) dt.

9.7.
PRODUCT MEASURES
233
Proof: By Theorem 8.27 on Page 190 there exists an increasing sequence of
nonnegative simple functions, {sn} which converges pointwise to f. By the monotone
convergence theorem and Lemma 9.37,
Z
φ (f) dµ
=
lim
n→∞
Z
φ (sn) dµ = lim
n→∞
Z ∞
0
φ′ (t) µ ([sn > t]) dm
=
Z ∞
0
φ′ (t) µ ([f > t]) dm
This proves the theorem.
9.7
Product Measures
Let (X, S, µ) and (Y, T , ν) be two complete measure spaces. In this section consider
the problem of deﬁning a product measure, µ × ν which is deﬁned on a σ algebra of
sets of X × Y such that (µ × ν) (E × F) = µ (E) ν (F) whenever E ∈S and F ∈T .
I found the following approach to product measures in [20] and they say they got
it from [22].
Deﬁnition 9.40 Let R denote the set of countable unions of sets of the form A×B,
where A ∈S and B ∈T
(Sets of the form A × B are referred to as measurable
rectangles) and also let
ρ (A × B) = µ (A) ν (B)
(9.19)
More generally, deﬁne
ρ (E) ≡
Z Z
XE (x, y) dµdν
(9.20)
whenever E is such that
x →XE (x, y) is µ measurable for all y
(9.21)
and
y →
Z
XE (x, y) dµ is ν measurable.
(9.22)
Note that if E = A × B as above, then
Z Z
XE (x, y) dµdν
=
Z Z
XA×B (x, y) dµdν
=
Z Z
XA (x) XB (y) dµdν = µ (A) ν (B) = ρ (E)
and so there is no contradiction between 9.20 and 9.19.
The ﬁrst goal is to show that for Q ∈R, 9.21 and 9.22 both hold. That is,
x →XQ (x, y) is µ measurable for all y and y →
R
XQ (x, y) dµ is ν measurable.
This is done so that it is possible to speak of ρ (Q) . The following lemma will be
the fundamental result which will make this possible. First here is a picture.

234
THE CONSTRUCTION OF MEASURES
C
D
A
B
Lemma 9.41 Given C × D and {Ai × Bi}n
i=1 , there exist ﬁnitely many disjoint
rectangles, {C′
i × D′
i}p
i=1 such that none of these sets intersect any of the Ai × Bi,
each set is contained in C × D and
(∪n
i=1Ai × Bi) ∪(∪p
k=1C′
k × D′
k) = (C × D) ∪(∪n
i=1Ai × Bi) .
Proof: From the above picture, you see that
(C × D) \ (A1 × B1) = C × (D \ B1) ∪(C \ A1) × (D ∩B1)
and these last two sets are disjoint, have empty intersection with A1 × B1, and
(C × (D \ B1) ∪(C \ A1) × (D ∩B1)) ∪(∪n
i=1Ai × Bi) = (C × D) ∪(∪n
i=1Ai × Bi)
Now suppose disjoint sets,
n
eCi × eDi
om
i=1 have been obtained, each being a subset
of C × D such that
(∪n
i=1Ai × Bi) ∪
³
∪m
k=1 eCk × eDk
´
= (∪n
i=1Ai × Bi) ∪(C × D)
and for all k, eCk × eDk has empty intersection with each set of {Ai × Bi}p
i=1 . Then
using the same procedure, replace each of eCk × eDk with ﬁnitely many disjoint
rectangles such that none of these intersect Ap+1 ×Bp+1 while preserving the union
of all the sets involved. The process stops when you have gotten to n. This proves
the lemma.
Lemma 9.42 If Q = ∪∞
i=1Ai × Bi ∈R, then there exist disjoint sets, of the form
A′
i × B′
i such that Q = ∪∞
i=1A′
i × B′
i, each A′
i × B′
i is a subset of some Ai × Bi, and
A′
i ∈S while B′
i ∈T . Also, the intersection of ﬁnitely many sets of R is a set of
R. For ρ deﬁned in 9.20, it follows that 9.21 and 9.22 hold for any element of R.
Furthermore,
ρ (Q) =
X
i
µ (A′
i) ν (B′
i) =
X
i
ρ (A′
i × B′
i) .
Proof: Let Q be given as above. Let A′
1 × B′
1 = A1 × B1. By Lemma 9.41, it
is possible to replace A2 × B2 with ﬁnitely many disjoint rectangles, {A′
i × B′
i}m2
i=2
such that none of these rectangles intersect A′
1 × B′
1, each is a subset of A2 × B2,
and
∪∞
i=1Ai × Bi = (∪m2
i=1A′
i × B′
i) ∪(∪∞
k=3Ak × Bk)

9.7.
PRODUCT MEASURES
235
Now suppose disjoint rectangles, {A′
i × B′
i}mp
i=1 have been obtained such that each
rectangle is a subset of Ak × Bk for some k ≤p and
∪∞
i=1Ai × Bi =
¡
∪mp
i=1A′
i × B′
i
¢
∪
¡
∪∞
k=p+1Ak × Bk
¢
.
By Lemma 9.41 again, there exist disjoint rectangles {A′
i × B′
i}mp+1
i=mp+1 such that
each is contained in Ap+1 × Bp+1, none have intersection with any of {A′
i × B′
i}mp
i=1
and
∪∞
i=1Ai × Bi =
¡
∪mp+1
i=1 A′
i × B′
i
¢
∪
¡
∪∞
k=p+2Ak × Bk
¢
.
Note that no change is made in {A′
i × B′
i}mp
i=1 . Continuing this way proves the
existence of the desired sequence of disjoint rectangles, each of which is a subset of
at least one of the original rectangles and such that
Q = ∪∞
i=1A′
i × B′
i.
It remains to verify x →XQ (x, y) is µ measurable for all y and
y →
Z
XQ (x, y) dµ
is ν measurable whenever Q ∈R. Let Q ≡∪∞
i=1Ai × Bi ∈R. Then by the ﬁrst
part of this lemma, there exists {A′
i × B′
i}∞
i=1 such that the sets are disjoint and
∪∞
i=1A′
i × B′
i = Q. Therefore, since the sets are disjoint,
XQ (x, y) =
∞
X
i=1
XA′
i×B′
i (x, y) =
∞
X
i=1
XA′
i (x) XB′
i (y) .
It follows x →XQ (x, y) is measurable. Now by the monotone convergence theorem,
Z
XQ (x, y) dµ
=
Z
∞
X
i=1
XA′
i (x) XB′
i (y) dµ
=
∞
X
i=1
XB′
i (y)
Z
XA′
i (x) dµ
=
∞
X
i=1
XB′
i (y) µ (A′
i) .
It follows y →
R
XQ (x, y) dµ is measurable and so by the monotone convergence
theorem again,
Z Z
XQ (x, y) dµdν
=
Z
∞
X
i=1
XB′
i (y) µ (A′
i) dν
=
∞
X
i=1
Z
XB′
i (y) µ (A′
i) dν
=
∞
X
i=1
ν (B′
i) µ (A′
i) .
(9.23)

236
THE CONSTRUCTION OF MEASURES
This shows the measurability conditions, 9.21 and 9.22 hold for Q ∈R and also
establishes the formula for ρ (Q) , 9.23.
If ∪iAi × Bi and ∪jCj × Dj are two sets of R, then their intersection is
∪i ∪j (Ai ∩Cj) × (Bi ∩Dj)
a countable union of measurable rectangles. Thus ﬁnite intersections of sets of R
are in R. This proves the lemma.
Now note that from the deﬁnition of R if you have a sequence of elements of R
then their union is also in R. The next lemma will enable the deﬁnition of an outer
measure.
Lemma 9.43 Suppose {Ri}∞
i=1 is a sequence of sets of R then
ρ (∪∞
i=1Ri) ≤
∞
X
i=1
ρ (Ri) .
Proof: Let Ri = ∪∞
j=1Ai
j × Bi
j. Using Lemma 9.42, let {A′
m × B′
m}∞
m=1 be a
sequence of disjoint rectangles each of which is contained in some Ai
j × Bi
j for some
i, j such that
∪∞
i=1Ri = ∪∞
m=1A′
m × B′
m.
Now deﬁne
Si ≡
©
m : A′
m × B′
m ⊆Ai
j × Bi
j for some j
ª
.
It is not important to consider whether some m might be in more than one Si. The
important thing to notice is that
∪m∈SiA′
m × B′
m ⊆∪∞
j=1Ai
j × Bi
j = Ri.
Then by Lemma 9.42,
ρ (∪∞
i=1Ri)
=
X
m
ρ (A′
m × B′
m)
≤
∞
X
i=1
X
m∈Si
ρ (A′
m × B′
m)
≤
∞
X
i=1
ρ (∪m∈SiA′
m × B′
m) ≤
∞
X
i=1
ρ (Ri) .
This proves the lemma.
So far, there is no measure and no σ algebra. However, the next step is to deﬁne
an outer measure which will lead to a measure on a σ algebra of measurable sets
from the Caratheodory procedure. When this is done, it will be shown that this
measure can be computed using ρ which implies the important Fubini theorem.
Now it is possible to deﬁne an outer measure.

9.7.
PRODUCT MEASURES
237
Deﬁnition 9.44 For S ⊆X × Y, deﬁne
(µ × ν) (S) ≡inf {ρ (R) : S ⊆R, R ∈R} .
(9.24)
The following proposition is interesting but is not needed in the development
which follows. It gives a diﬀerent description of (µ × ν) .
Proposition 9.45 (µ × ν) (S) = inf {P∞
i=1 µ (Ai) ν (Bi) : S ⊆∪∞
i=1Ai × Bi}
Proof: Let λ (S) ≡inf {P∞
i=1 µ (Ai) ν (Bi) : S ⊆∪∞
i=1Ai × Bi} . Suppose S ⊆
∪∞
i=1Ai × Bi ≡Q ∈R. Then by Lemma 9.42, Q = ∪iA′
i × B′
i where these rectan-
gles are disjoint. Thus by this lemma, ρ (Q) = P∞
i=1 µ (A′
i) ν (B′
i) ≥λ (S) and so
λ (S) ≤(µ × ν) (S) . If λ (S) = ∞, this shows λ (S) = (µ × ν) (S) . Suppose then
that λ (S) < ∞and λ (S) + ε > P∞
i=1 µ (Ai) ν (Bi) where Q = ∪∞
i=1Ai × Bi ⊇S.
Then by Lemma 9.42 again, ∪∞
i=1Ai×Bi = ∪∞
i=1A′
i×B′
i where the primed rectangles
are disjoint, each is a subset of some Ai × Bi and so
λ (S) + ε ≥
∞
X
i=1
µ (Ai) ν (Bi) ≥
∞
X
i=1
µ (A′
i) ν (B′
i) = ρ (Q) ≥(µ × ν) (S) .
Since ε is arbitrary, this shows λ (S) ≥(µ × ν) (S) and this proves the proposition.
Lemma 9.46 µ × ν is an outer measure on X × Y and for R ∈R
(µ × ν) (R) = ρ (R) .
(9.25)
Proof: First consider 9.25. Since R ⊇R, it follows ρ (R) ≥(µ × ν) (R) . On the
other hand, if Q ∈R and Q ⊇R, then ρ (Q) ≥ρ (R) and so, taking the inﬁmum
on the left yields (µ × ν) (R) ≥ρ (R) . This shows 9.25.
It is necessary to show that if S ⊆T, then
(µ × ν) (S) ≤(µ × ν) (T) ,
(9.26)
(µ × ν) (∪∞
i=1Si) ≤
∞
X
i=1
(µ × ν) (Si) .
(9.27)
To do this, note that 9.26 is obvious. To verify 9.27, note that it is obvious if
(µ × ν) (Si) = ∞for any i. Therefore, assume (µ × ν) (Si) < ∞. Then letting ε > 0
be given, there exist Ri ∈R such that
(µ × ν) (Si) + ε
2i > ρ (Ri) , Ri ⊇Si.

238
THE CONSTRUCTION OF MEASURES
Then by Lemma 9.43, 9.25, and the observation that ∪∞
i=1Ri ∈R,
(µ × ν) (∪∞
i=1Si)
≤
(µ × ν) (∪∞
i=1Ri)
=
ρ (∪∞
i=1Ri) ≤
∞
X
i=1
ρ (Ri)
≤
∞
X
i=1
³
(µ × ν) (Si) + ε
2i
´
=
Ã ∞
X
i=1
(µ × ν) (Si)
!
+ ε.
Since ε is arbitrary, this proves the lemma.
By Caratheodory’s procedure, it follows there is a σ algebra of subsets of X ×Y,
denoted here by S × T such that (µ × ν) is a complete measure on this σ algebra.
The ﬁrst thing to note is that every rectangle is in this σ algebra.
Lemma 9.47 Every rectangle is (µ × ν) measurable.
Proof: Let S ⊆X × Y. The following inequality must be established.
(µ × ν) (S) ≥(µ × ν) (S ∩(A × B)) + (µ × ν) (S \ (A × B)) .
(9.28)
The following claim will be used to establish this inequality.
Claim: Let P, A × B ∈R. Then
ρ (P ∩(A × B)) + ρ (P \ (A × B)) = ρ (P) .
Proof of the claim: From Lemma 9.42, P = ∪∞
i=1A′
i × B′
i where the A′
i × B′
i
are disjoint. Therefore,
P ∩(A × B) =
∞
[
i=1
(A ∩A′
i) × (B ∩B′
i)
while
P \ (A × B) =
∞
[
i=1
(A′
i \ A) × B′
i ∪
∞
[
i=1
(A ∩A′
i) × (B′
i \ B) .
Since all of the sets in the above unions are disjoint,
ρ (P ∩(A × B)) + ρ (P \ (A × B)) =
Z Z
∞
X
i=1
X(A∩A′
i) (x) XB∩B′
i (y) dµdν +
Z Z
∞
X
i=1
X(A′
i\A) (x) XB′
i (y) dµdν
+
Z Z
∞
X
i=1
XA∩A′
i (x) XB′
i\B (y) dµdν

9.7.
PRODUCT MEASURES
239
=
∞
X
i=1
µ (A ∩A′
i) ν (B ∩B′
i) + µ (A′
i \ A) ν (B′
i) + µ (A ∩A′
i) ν (B′
i \ B)
=
∞
X
i=1
µ (A ∩A′
i) ν (B′
i) + µ (A′
i \ A) ν (B′
i) =
∞
X
i=1
µ (A′
i) ν (B′
i) = ρ (P) .
This proves the claim.
Now continuing to verify 9.28, without loss of generality, (µ × ν) (S) can be
assumed ﬁnite. Let P ⊇S for P ∈R and
(µ × ν) (S) + ε > ρ (P) .
Then from the claim,
(µ × ν) (S) + ε
>
ρ (P) = ρ (P ∩(A × B)) + ρ (P \ (A × B))
≥
(µ × ν) (S ∩(A × B)) + (µ × ν) (S \ (A × B)) .
Since ε > 0 this shows A × B is µ × ν measurable as claimed.
Lemma 9.48 Let R1 be deﬁned as the set of all countable intersections of sets of
R. Then if S ⊆X × Y, there exists R ∈R1 for which it makes sense to write ρ (R)
because 9.21 and 9.22 hold such that
(µ × ν) (S) = ρ (R) .
(9.29)
Also, every element of R1 is µ × ν measurable.
Proof: Consider 9.29. Let S ⊆X × Y. If (µ × ν) (S) = ∞, let R = X × Y and
it follows ρ (X × Y ) = ∞= (µ × ν) (S) . Assume then that (µ × ν) (S) < ∞.
Therefore, there exists Pn ∈R such that Pn ⊇S and
(µ × ν) (S) ≤ρ (Pn) < (µ × ν) (S) + 1/n.
(9.30)
Let Qn = ∩n
i=1Pi ∈R. Deﬁne
P ≡∩∞
i=1Qi ⊇S.
Then 9.30 holds with Qn in place of Pn. It is clear that
x →XP (x, y) is µ measurable
because this function is the pointwise limit of functions for which this is so. It
remains to consider whether y →
R
XP (x, y) dµ is ν measurable.
First observe
Qn ⊇Qn+1, XQi ≤XPi, and
ρ (Q1) = ρ (P1) =
Z Z
XP1 (x, y) dµdν < ∞.
(9.31)

240
THE CONSTRUCTION OF MEASURES
Therefore, there exists a set of ν measure 0, N, such that if y /∈N, then
Z
XP1 (x, y) dµ < ∞.
It follows from the dominated convergence theorem that
lim
n→∞XNC (y)
Z
XQn (x, y) dµ = XNC (y)
Z
XP (x, y) dµ
and so
y →XNC (y)
Z
XP (x, y) dµ
is also measurable. By completeness of ν,
y →
Z
XP (x, y) dµ
must also be ν measurable and so it makes sense to write
Z Z
XP (x, y) dµdν
for every P ∈R1. Also, by the dominated convergence theorem,
Z Z
XP (x, y) dµdν
=
Z
XNC (y)
Z
XP (x, y) dµdν
=
lim
n→∞
Z
XN C (y)
Z
XQn (x, y) dµdν
=
lim
n→∞
Z Z
XQn (x, y) dµdν
=
lim
n→∞ρ (Qn) ∈[(µ × ν) (S) , (µ × ν) (S) + 1/n]
for all n. Therefore,
ρ (P) ≡
Z Z
XP (x, y) dµdν = (µ × ν) (S) .
The sets of R1 are µ × ν measurable because these sets are countable intersec-
tions of countable unions of rectangles and Lemma 9.47 veriﬁes the rectangles are
µ × ν measurable. This proves the Lemma.
The following theorem is the main result.
Theorem 9.49 Let E ⊆X ×Y be µ × ν measurable and suppose (µ × ν) (E) < ∞.
Then
x →XE (x, y) is µ measurable a.e. y.
Modifying XE on a set of measure zero, it is possible to write
Z
XE (x, y) dµ.

9.7.
PRODUCT MEASURES
241
The function,
y →
Z
XE (x, y) dµ
is ν measurable and
(µ × ν) (E) =
Z Z
XE (x, y) dµdν.
Similarly,
(µ × ν) (E) =
Z Z
XE (x, y) dνdµ.
Proof: By Lemma 9.48, there exists R ∈R1 such that
ρ (R) = (µ × ν) (E) , R ⊇E.
Therefore, since R is µ × ν measurable and ρ (R) = (µ × ν) (R), it follows
(µ × ν) (R \ E) = 0.
By Lemma 9.48 again, there exists P ⊇R \ E with P ∈R1 and
ρ (P) = (µ × ν) (R \ E) = 0.
Thus
Z Z
XP (x, y) dµdν = 0.
(9.32)
Since P ∈R1 Lemma 9.48 implies x →XP (x, y) is µ measurable and it follows
from the above there exists a set of ν measure zero, N such that if y /∈N, then
R
XP (x, y) dµ = 0. Therefore, by completeness of ν,
x →XN C (y) XR\E (x, y)
is µ measurable and
Z
XN C (y) XR\E (x, y) dµ = 0.
(9.33)
Now also
XN C (y) XR (x, y) = XN C (y) XR\E (x, y) + XN C (y) XE (x, y)
(9.34)
and this shows that
x →XN C (y) XE (x, y)
is µ measurable because it is the diﬀerence of two functions with this property.
Then by 9.33 it follows
Z
XNC (y) XE (x, y) dµ =
Z
XN C (y) XR (x, y) dµ.

242
THE CONSTRUCTION OF MEASURES
The right side of this equation equals a ν measurable function and so the left side
which equals it is also a ν measurable function. It follows from completeness of ν
that y →
R
XE (x, y) dµ is ν measurable because for y outside of a set of ν measure
zero, N it equals
R
XR (x, y) dµ. Therefore,
Z Z
XE (x, y) dµdν
=
Z Z
XN C (y) XE (x, y) dµdν
=
Z Z
XN C (y) XR (x, y) dµdν
=
Z Z
XR (x, y) dµdν
=
ρ (R) = (µ × ν) (E) .
In all the above there would be no change in writing dνdµ instead of dµdν. The
same result would be obtained. This proves the theorem.
Now let f : X × Y →[0, ∞] be µ × ν measurable and
Z
fd (µ × ν) < ∞.
(9.35)
Let s (x, y) ≡Pm
i=1 ciXEi (x, y) be a nonnegative simple function with ci being the
nonzero values of s and suppose
0 ≤s ≤f.
Then from the above theorem,
Z
sd (µ × ν) =
Z Z
sdµdν
In which
Z
sdµ =
Z
XNC (y) sdµ
for N a set of ν measure zero such that y →
R
XNC (y) sdµ is ν measurable. This
follows because 9.35 implies (µ × ν) (Ei) < ∞. Now let sn ↑f where sn is a non-
negative simple function and
Z
snd (µ × ν) =
Z Z
XN C
n (y) sn (x, y) dµdν
where
y →
Z
XN C
n (y) sn (x, y) dµ
is ν measurable. Then let N ≡∪∞
n=1Nn. It follows N is a set of ν measure zero.
Thus
Z
snd (µ × ν) =
Z Z
XN C (y) sn (x, y) dµdν

9.7.
PRODUCT MEASURES
243
and letting n →∞, the monotone convergence theorem implies
Z
fd (µ × ν)
=
Z Z
XNC (y) f (x, y) dµdν
=
Z Z
f (x, y) dµdν
because of completeness of the measures, µ and ν. This proves Fubini’s theorem.
Theorem 9.50 (Fubini) Let (X, S, µ) and (Y, T , ν) be complete measure spaces
and let
(µ × ν) (E) ≡inf
½Z Z
XR (x, y) dµdν : E ⊆R ∈R
¾
2
where Ai ∈S and Bi ∈T .
Then µ × ν is an outer measure on the subsets of
X × Y and the σ algebra of µ × ν measurable sets, S × T , contains all measurable
rectangles. If f ≥0 is a µ × ν measurable function satisfying
Z
X×Y
fd (µ × ν) < ∞,
(9.36)
then
Z
X×Y
fd (µ × ν) =
Z
Y
Z
X
fdµdν,
where the iterated integral on the right makes sense because for ν a.e. y, x →f (x, y)
is µ measurable and y →
R
f (x, y) dµ is ν measurable. Similarly,
Z
X×Y
fd (µ × ν) =
Z
X
Z
Y
fdνdµ.
In the case where (X, S, µ) and (Y, T , ν) are both σ ﬁnite, it is not necessary to
assume 9.36.
Corollary 9.51 (Fubini) Let (X, S, µ) and (Y, T , ν) be complete measure spaces
such that (X, S, µ) and (Y, T , ν) are both σ ﬁnite and let
(µ × ν) (E) ≡inf
½Z Z
XR (x, y) dµdν : E ⊆R ∈R
¾
where Ai ∈S and Bi ∈T .
Then µ × ν is an outer measure. If f ≥0 is a µ × ν
measurable function then
Z
X×Y
fd (µ × ν) =
Z
Y
Z
X
fdµdν,
2Recall this is the same as
inf
( ∞
X
i=1
µ (Ai) ν (Bi) : E ⊆∪∞
i=1Ai × Bi
)
in which the Ai and Bi are measurable.

244
THE CONSTRUCTION OF MEASURES
where the iterated integral on the right makes sense because for ν a.e. y, x →f (x, y)
is µ measurable and y →
R
f (x, y) dµ is ν measurable. Similarly,
Z
X×Y
fd (µ × ν) =
Z
X
Z
Y
fdνdµ.
Proof: Let ∪∞
n=1Xn = X and ∪∞
n=1Yn = Y where Xn ∈S, Yn ∈T , Xn ⊆
Xn+1, Yn ⊆Yn+1 for all n and µ (Xn) < ∞, ν (Yn) < ∞. From Theorem 9.50
applied to Xn, Yn and fm ≡min (f, m) ,
Z
Xn×Yn
fmd (µ × ν) =
Z
Yn
Z
Xn
fmdµdν
Now take m →∞and use the monotone convergence theorem to obtain
Z
Xn×Yn
fd (µ × ν) =
Z
Yn
Z
Xn
fdµdν.
Then use the monotone convergence theorem again letting n →∞to obtain the
desired conclusion. The argument for the other order of integration is similar.
Corollary 9.52 If f ∈L1 (X × Y ) , then
Z
fd (µ × ν) =
Z Z
f (x, y) dµdν =
Z Z
f (x, y) dνdµ.
If µ and ν are σ ﬁnite, then if f is µ × ν measurable having complex values and
either
R R
|f| dµdν < ∞or
R R
|f| dνdµ < ∞, then
R
|f| d (µ × ν) < ∞so f ∈
L1 (X × Y ) .
Proof: Without loss of generality, it can be assumed that f has real values.
Then
f = |f| + f −(|f| −f)
2
and both f + ≡|f|+f
2
and f −≡|f|−f
2
are nonnegative and are less than |f|. There-
fore,
R
gd (µ × ν) < ∞for g = f + and g = f −so the above theorem applies and
Z
fd (µ × ν)
≡
Z
f +d (µ × ν) −
Z
f −d (µ × ν)
=
Z Z
f +dµdν −
Z Z
f −dµdν
=
Z Z
fdµdν.
It remains to verify the last claim. Suppose s is a simple function,
s (x, y) ≡
m
X
i=1
ciXEi ≤|f| (x, y)

9.8.
ALTERNATIVE TREATMENT OF PRODUCT MEASURE
245
where the ci are the nonzero values of s. Then
sXRn ≤|f| XRn
where Rn ≡Xn × Yn where Xn ↑X and Yn ↑Y with µ (Xn) < ∞and ν (Yn) < ∞.
It follows, since the nonzero values of sXRn are achieved on sets of ﬁnite measure,
Z
sXRnd (µ × ν) =
Z Z
sXRndµdν.
Letting n →∞and applying the monotone convergence theorem, this yields
Z
sd (µ × ν) =
Z Z
sdµdν.
(9.37)
Now let sn ↑|f| where sn is a nonnegative simple function. From 9.37,
Z
snd (µ × ν) =
Z Z
sndµdν.
Letting n →∞and using the monotone convergence theorem, yields
Z
|f| d (µ × ν) =
Z Z
|f| dµdν < ∞
9.8
Alternative Treatment Of Product Measure
9.8.1
Monotone Classes And Algebras
Measures are deﬁned on σ algebras which are closed under countable unions. It is
for this reason that the theory of measure and integration is so useful in dealing
with limits of sequences. However, there is a more basic notion which involves only
ﬁnite unions and diﬀerences.
Deﬁnition 9.53 A is said to be an algebra of subsets of a set, Z if Z ∈A, ∅∈A,
and when E, F ∈A, E ∪F and E \ F are both in A.
It is important to note that if A is an algebra, then it is also closed under ﬁnite
intersections. This is because E ∩F = (EC ∪F C)C ∈A since EC = Z \ E ∈A and
F C = Z \ F ∈A. Note that every σ algebra is an algebra but not the other way
around.
Something satisfying the above deﬁnition is called an algebra because union is
like addition, the set diﬀerence is like subtraction and intersection is like multipli-
cation. Furthermore, only ﬁnitely many operations are done at a time and so there
is nothing like a limit involved.
How can you recognize an algebra when you see one? The answer to this question
is the purpose of the following lemma.

246
THE CONSTRUCTION OF MEASURES
Lemma 9.54 Suppose R and E are subsets of P(Z)3 such that E is deﬁned as the
set of all ﬁnite disjoint unions of sets of R. Suppose also
∅, Z ∈R
A ∩B ∈R whenever A, B ∈R,
A \ B ∈E
whenever A, B ∈R.
Then E is an algebra of sets of Z.
Proof: Note ﬁrst that if A ∈R, then AC ∈E because AC = Z \ A.
Now suppose that E1and E2 are in E,
E1 = ∪m
i=1Ri, E2 = ∪n
j=1Rj
where the Ri are disjoint sets in R and the Rj are disjoint sets in R. Then
E1 ∩E2 = ∪m
i=1 ∪n
j=1 Ri ∩Rj
which is clearly an element of E because no two of the sets in the union can intersect
and by assumption they are all in R. Thus by induction, ﬁnite intersections of sets
of E are in E. Consider the diﬀerence of two elements of E next.
If E = ∪n
i=1Ri ∈E,
EC = ∩n
i=1RC
i = ﬁnite intersection of sets of E
which was just shown to be in E. Now, if E1, E2 ∈E,
E1 \ E2 = E1 ∩EC
2 ∈E
from what was just shown about ﬁnite intersections.
Finally consider ﬁnite unions of sets of E. Let E1 and E2 be sets of E. Then
E1 ∪E2 = (E1 \ E2) ∪E2 ∈E
because E1 \ E2 consists of a ﬁnite disjoint union of sets of R and these sets must
be disjoint from the sets of R whose union yields E2 because (E1 \ E2) ∩E2 = ∅.
This proves the lemma.
The following corollary is particularly helpful in verifying the conditions of the
above lemma.
Corollary 9.55 Let (Z1, R1, E1) and (Z2, R2, E2) be as described in Lemma 9.54.
Then (Z1 × Z2, R, E) also satisﬁes the conditions of Lemma 9.54 if R is deﬁned as
R ≡{R1 × R2 : Ri ∈Ri}
and
E ≡{ ﬁnite disjoint unions of sets of R}.
Consequently, E is an algebra of sets.
3Set of all subsets of Z

9.8.
ALTERNATIVE TREATMENT OF PRODUCT MEASURE
247
Proof: It is clear ∅, Z1 × Z2 ∈R. Let A × B and C × D be two elements of R.
A × B ∩C × D = A ∩C × B ∩D ∈R
by assumption.
A × B \ (C × D) =
A ×
∈E2
z }| {
(B \ D) ∪
∈E1
z }| {
(A \ C) ×
∈R2
z
}|
{
(D ∩B)
= (A × Q) ∪(P × R)
where Q ∈E2, P ∈E1, and R ∈R2.
A
B
C
D
Since A × Q and P × R do not intersect, it follows the above expression is in E
because each of these terms are. This proves the corollary.
Deﬁnition 9.56 M ⊆P(Z) is called a monotone class if
a.) · · ·En ⊇En+1 · ··, E = ∩∞
n=1En, and En ∈M, then E ∈M.
b.) · · ·En ⊆En+1 · ··, E = ∪∞
n=1En, and En ∈M, then E ∈M.
(In simpler notation, En ↓E and En ∈M implies E ∈M. En ↑E and En ∈M
implies E ∈M.)
Theorem 9.57 (Monotone Class theorem) Let A be an algebra of subsets of Z and
let M be a monotone class containing A. Then M ⊇σ(A), the smallest σ-algebra
containing A.
Proof: Consider all monotone classes which contain A, and take their inter-
section. The result is still a monotone class which contains A and is therefore the
smallest monotone class containing A. Therefore, assume without loss of general-
ity that M is the smallest monotone class containing A because if it is shown the
smallest monotone class containing A contains σ (A), then the given monotone class
does also. To avoid more notation, let M denote this smallest monotone class.
The plan is to show M is a σ-algebra. It will then follow M ⊇σ(A) because
σ (A) is deﬁned as the intersection of all σ algebras which contain A. For A ∈A,
deﬁne
MA ≡{B ∈M such that A ∪B ∈M}.
Clearly MA is a monotone class containing A. Hence MA ⊇M because M is
the smallest such monotone class.
But by construction, MA ⊆M.
Therefore,

248
THE CONSTRUCTION OF MEASURES
M = MA. This shows that A ∪B ∈M whenever A ∈A and B ∈M. Now pick
B ∈M and deﬁne
MB ≡{D ∈M such that D ∪B ∈M}.
It was just shown that A ⊆MB. It is clear that MB is a monotone class. Thus
by a similar argument, MB = M and it follows that D ∪B ∈M whenever D ∈M
and B ∈M. This shows M is closed under ﬁnite unions.
Next consider the diference of two sets. Let A ∈A
MA ≡{B ∈M such that B \ A and A \ B ∈M}.
Then MA, is a monotone class containing A. As before, M = MA. Thus B \ A
and A \ B are both in M whenever A ∈A and B ∈M. Now pick A ∈M and
consider
MA ≡{B ∈M such that B \ A and A \ B ∈M}.
It was just shown MA contains A. Now MA is a monotone class and so MA = M
as before.
Thus M is both a monotone class and an algebra.
Hence, if E ∈M then
Z \ E ∈M. Next consider the question of whether M is a σ-algebra. If Ei ∈M
and Fn = ∪n
i=1Ei, then Fn ∈M and Fn ↑∪∞
i=1Ei. Since M is a monotone class,
∪∞
i=1Ei ∈M and so M is a σ-algebra. This proves the theorem.
9.8.2
Product Measure
Deﬁnition 9.58 Let (X, S, µ) and (Y, F, λ) be two measure spaces. A measurable
rectangle is a set A×B ⊆X ×Y where A ∈S and B ∈F. An elementary set will be
any subset of X ×Y which is a ﬁnite union of disjoint measurable rectangles. S ×F
will denote the smallest σ algebra of sets in P(X × Y ) containing all elementary
sets.
Example 9.59 It follows from Lemma 9.54 or more easily from Corollary 9.55
that the elementary sets form an algebra.
Deﬁnition 9.60 Let E ⊆X × Y,
Ex = {y ∈Y : (x, y) ∈E},
Ey = {x ∈X : (x, y) ∈E}.
These are called the x and y sections.

9.8.
ALTERNATIVE TREATMENT OF PRODUCT MEASURE
249
x
X
Y
Ex
Theorem 9.61 If E ∈S × F, then Ex ∈F and Ey ∈S for all x ∈X and y ∈Y .
Proof: Let
M = {E ⊆S × F such that for all x ∈X,
Ex ∈F,
and for all y ∈Y, Ey ∈S.}
Then M contains all measurable rectangles. If Ei ∈M,
(∪∞
i=1Ei)x = ∪∞
i=1(Ei)x ∈F.
Similarly,
(∪∞
i=1Ei)y = ∪∞
i=1Ey
i ∈S.
It follows M is closed under countable unions.
If E ∈M,
¡
EC¢
x = (Ex)C ∈F.
Similarly,
¡
EC¢y ∈S. Thus M is closed under complementation. Therefore M is a
σ-algebra containing the elementary sets. Hence, M ⊇S × Fbecause S × F is the
smallest σ algebra containing these elementary sets. But M ⊆S × Fby deﬁnition
and so M = S × F. This proves the theorem.
It follows from Lemma 9.54 that the elementary sets form an algebra because
clearly the intersection of two measurable rectangles is a measurable rectangle and
(A × B) \ (A0 × B0) = (A \ A0) × B ∪(A ∩A0) × (B \ B0),
an elementary set.
Theorem 9.62 If (X, S, µ) and (Y, F, λ) are both ﬁnite measure spaces (µ(X),
λ(Y ) < ∞), then for every E ∈S × F,
a.) x →λ(Ex) is µ measurable, y →µ(Ey) is λ measurable
b.)
R
X λ(Ex)dµ =
R
Y µ(Ey)dλ.

250
THE CONSTRUCTION OF MEASURES
Proof: Let
M = {E ∈S × F such that both a.) and b.) hold} .
Since µ and λ are both ﬁnite, the monotone convergence and dominated convergence
theorems imply M is a monotone class.
Next I will argue M contains the elementary sets. Let
E = ∪n
i=1Ai × Bi
where the measurable rectangles, Ai × Bi are disjoint. Then
λ (Ex)
=
Z
Y
XE (x, y) dλ =
Z
Y
n
X
i=1
XAi×Bi (x, y) dλ
=
n
X
i=1
Z
Y
XAi×Bi (x, y) dλ =
n
X
i=1
XAi (x) λ (Bi)
which is clearly µ measurable. Furthermore,
Z
X
λ (Ex) dµ =
Z
X
n
X
i=1
XAi (x) λ (Bi) dµ =
n
X
i=1
µ (Ai) λ (Bi) .
Similarly,
Z
Y
µ (Ey) dλ =
n
X
i=1
µ (Ai) λ (Bi)
and y →µ (Ey) is λ measurable and this shows M contains the algebra of elemen-
tary sets. By the monotone class theorem, M = S × F. This proves the theorem.
One can easily extend this theorem to the case where the measure spaces are σ
ﬁnite.
Theorem 9.63 If (X, S, µ) and (Y, F, λ) are both σ ﬁnite measure spaces, then for
every E ∈S × F,
a.) x →λ(Ex) is µ measurable, y →µ(Ey) is λ measurable.
b.)
R
X λ(Ex)dµ =
R
Y µ(Ey)dλ.
Proof: Let X = ∪∞
n=1Xn, Y = ∪∞
n=1Yn where,
Xn ⊆Xn+1, Yn ⊆Yn+1, µ (Xn) < ∞, λ(Yn) < ∞.
Let
Sn = {A ∩Xn : A ∈S}, Fn = {B ∩Yn : B ∈F}.
Thus (Xn, Sn, µ) and (Yn, Fn, λ) are both ﬁnite measure spaces.
Claim: If E ∈S × F, then E ∩(Xn × Yn) ∈Sn × Fn.
Proof: Let
Mn = {E ∈S × F : E ∩(Xn × Yn) ∈Sn × Fn} .

9.8.
ALTERNATIVE TREATMENT OF PRODUCT MEASURE
251
Clearly Mn contains the algebra of elementary sets. It is also clear that Mn is a
monotone class. Thus Mn = S × F.
Now let E ∈S × F. By Theorem 9.62,
Z
Xn
λ((E ∩(Xn × Yn))x)dµ =
Z
Yn
µ((E ∩(Xn × Yn))y)dλ
(9.38)
where the integrands are measurable. Also
(E ∩(Xn × Yn))x = ∅
if x /∈Xn and a similar observation holds for the second integrand in 9.38 if y /∈Yn.
Therefore,
Z
X
λ((E ∩(Xn × Yn))x)dµ
=
Z
Xn
λ((E ∩(Xn × Yn))x)dµ
=
Z
Yn
µ((E ∩(Xn × Yn))y)dλ
=
Z
Y
µ((E ∩(Xn × Yn))y)dλ.
Then letting n →∞, the monotone convergence theorem implies b.)
and the
measurability assertions of a.) are valid because
λ (Ex)
=
lim
n→∞λ((E ∩(Xn × Yn))x)
µ (Ey)
=
lim
n→∞µ((E ∩(Xn × Yn))y).
This proves the theorem.
This theorem makes it possible to deﬁne product measure.
Deﬁnition 9.64 For E ∈S × F and (X, S, µ), (Y, F, λ) σ ﬁnite, (µ × λ)(E) ≡
R
X λ(Ex)dµ =
R
Y µ(Ey)dλ.
This deﬁnition is well deﬁned because of Theorem 9.63.
Theorem 9.65 If A ∈S, B ∈F, then (µ × λ)(A × B) = µ(A)λ(B), and µ × λ is
a measure on S × F called product measure.
Proof: The ﬁrst assertion about the measure of a measurable rectangle was
established above. Now suppose {Ei}∞
i=1 is a disjoint collection of sets of S × F.
Then using the monotone convergence theorem along with the observation that

252
THE CONSTRUCTION OF MEASURES
(Ei)x ∩(Ej)x = ∅,
(µ × λ) (∪∞
i=1Ei)
=
Z
X
λ((∪∞
i=1Ei)x)dµ
=
Z
X
λ (∪∞
i=1 (Ei)x) dµ =
Z
X
∞
X
i=1
λ ((Ei)x) dµ
=
∞
X
i=1
Z
X
λ ((Ei)x) dµ
=
∞
X
i=1
(µ × λ) (Ei)
This proves the theorem.
The next theorem is one of several theorems due to Fubini and Tonelli. These
theorems all have to do with interchanging the order of integration in a multiple
integral.
Theorem 9.66 Let f : X × Y →[0, ∞] be measurable with respect to S × F and
suppose µ and λ are σ ﬁnite. Then
Z
X×Y
fd(µ × λ) =
Z
X
Z
Y
f(x, y)dλdµ =
Z
Y
Z
X
f(x, y)dµdλ
(9.39)
and all integrals make sense.
Proof: For E ∈S × F,
Z
Y
XE(x, y)dλ = λ(Ex),
Z
X
XE(x, y)dµ = µ(Ey).
Thus from Deﬁnition 9.64, 9.39 holds if f = XE. It follows that 9.39 holds for
every nonnegative simple function. By Theorem 8.27 on Page 190, there exists an
increasing sequence, {fn}, of simple functions converging pointwise to f. Then
Z
Y
f(x, y)dλ = lim
n→∞
Z
Y
fn(x, y)dλ,
Z
X
f(x, y)dµ = lim
n→∞
Z
X
fn(x, y)dµ.
This follows from the monotone convergence theorem. Since
x →
Z
Y
fn(x, y)dλ
is measurable with respect to S, it follows that x →
R
Y f(x, y)dλ is also measurable
with respect to S. A similar conclusion can be drawn about y →
R
X f(x, y)dµ. Thus
the two iterated integrals make sense. Since 9.39 holds for fn, another application
of the Monotone Convergence theorem shows 9.39 holds for f.
This proves the
theorem.

9.9.
COMPLETION OF MEASURES
253
Corollary 9.67 Let f : X×Y →C be S × F measurable. Suppose either
R
X
R
Y |f| dλdµ
or
R
Y
R
X |f| dµdλ < ∞. Then f ∈L1(X × Y, µ × λ) and
Z
X×Y
fd(µ × λ) =
Z
X
Z
Y
fdλdµ =
Z
Y
Z
X
fdµdλ
(9.40)
with all integrals making sense.
Proof: Suppose ﬁrst that f is real valued.
Apply Theorem 9.66 to f +and
f −. 9.40 follows from observing that f = f + −f −; and that all integrals are ﬁnite.
If f is complex valued, consider real and imaginary parts. This proves the corollary.
Suppose f is product measurable. From the above discussion, and breaking f
down into a sum of positive and negative parts of real and imaginary parts and then
using Theorem 8.27 on Page 190 on approximation by simple functions, it follows
that whenever f is S × F measurable, x →f (x, y) is µ measurable, y →f (x, y) is
λ measurable.
9.9
Completion Of Measures
Suppose (Ω, F, µ) is a measure space. Then it is always possible to enlarge the σ
algebra and deﬁne a new measure µ on this larger σ algebra such that
¡
Ω, F, µ
¢
is
a complete measure space. Recall this means that if N ⊆N ′ ∈F and µ (N ′) = 0,
then N ∈F. The following theorem is the main result. The new measure space is
called the completion of the measure space.
Theorem 9.68 Let (Ω, F, µ) be a σ ﬁnite measure space.
Then there exists a
unique measure space,
¡
Ω, F, µ
¢
satisfying
1.
¡
Ω, F, µ
¢
is a complete measure space.
2. µ = µ on F
3. F ⊇F
4. For every E ∈F there exists G ∈F such that G ⊇E and µ (G) = µ (E) .
5. For every E ∈F there exists F ∈F such that F ⊆E and µ (F) = µ (E) .
Also for every E ∈F there exist sets G, F ∈F such that G ⊇E ⊇F and
µ (G \ F) = µ (G \ F) = 0
(9.41)
Proof:
First consider the claim about uniqueness.
Suppose (Ω, F1, ν1) and
(Ω, F2, ν2) both work and let E ∈F1. Also let µ (Ωn) < ∞, · · ·Ωn ⊆Ωn+1 · ··, and
∪∞
n=1Ωn = Ω. Deﬁne En ≡E ∩Ωn. Then pick Gn ⊇En ⊇Fn such that µ (Gn) =

254
THE CONSTRUCTION OF MEASURES
µ (Fn) = ν1 (En). It follows µ (Gn \ Fn) = 0. Then letting G = ∪nGn, F ≡∪nFn,
it follows G ⊇E ⊇F and
µ (G \ F)
≤
µ (∪n (Gn \ Fn))
≤
X
n
µ (Gn \ Fn) = 0.
It follows that ν2 (G \ F) = 0 also. Now E \ F ⊆G \ F and since (Ω, F2, ν2) is
complete, it follows E \ F ∈F2. Since F ∈F2, it follows E = (E \ F) ∪F ∈F2.
Thus F1 ⊆F2. Similarly F2 ⊆F1. Now it only remains to verify ν1 = ν2. Thus let
E ∈F1 = F2 and let G and F be as just described. Since νi = µ on F,
µ (F)
≤
ν1 (E)
=
ν1 (E \ F) + ν1 (F)
≤
ν1 (G \ F) + ν1 (F)
=
ν1 (F) = µ (F)
Similarly ν2 (E) = µ (F) . This proves uniqueness. The construction has also veriﬁed
9.41.
Next deﬁne an outer measure, µ on P (Ω) as follows. For S ⊆Ω,
µ (S) ≡inf {µ (E) : E ∈F} .
Then it is clear µ is increasing. It only remains to verify µ is subadditive. Then let
S = ∪∞
i=1Si. If any µ (Si) = ∞, there is nothing to prove so suppose µ (Si) < ∞for
each i. Then there exist Ei ∈F such that Ei ⊇Si and
µ (Si) + ε/2i > µ (Ei) .
Then
µ (S)
=
µ (∪iSi)
≤
µ (∪iEi) ≤
X
i
µ (Ei)
≤
X
i
¡
µ (Si) + ε/2i¢
=
X
i
µ (Si) + ε.
Since ε is arbitrary, this veriﬁes µ is subadditive and is an outer measure as claimed.
Denote by F the σ algebra of measurable sets in the sense of Caratheodory.
Then it follows from the Caratheodory procedure, Theorem 9.4, on Page 210 that
¡
Ω, F, µ
¢
is a complete measure space. This veriﬁes 1.
Now let E ∈F. Then from the deﬁnition of µ, it follows
µ (E) ≡inf {µ (F) : F ∈F and F ⊇E} ≤µ (E) .
If F ⊇E and F ∈F, then µ (F) ≥µ (E) and so µ (E) is a lower bound for all such
µ (F) which shows that
µ (E) ≡inf {µ (F) : F ∈F and F ⊇E} ≥µ (E) .

9.9.
COMPLETION OF MEASURES
255
This veriﬁes 2.
Next consider 3. Let E ∈F and let S be a set. I must show
µ (S) ≥µ (S \ E) + µ (S ∩E) .
If µ (S) = ∞there is nothing to show. Therefore, suppose µ (S) < ∞. Then from
the deﬁnition of µ there exists G ⊇S such that G ∈F and µ (G) = µ (S) . Then
from the deﬁnition of µ,
µ (S)
≤
µ (S \ E) + µ (S ∩E)
≤
µ (G \ E) + µ (G ∩E)
=
µ (G) = µ (S)
This veriﬁes 3.
Claim 4 comes by the deﬁnition of µ as used above. The only other case is when
µ (S) = ∞. However, in this case, you can let G = Ω.
It only remains to verify 5. Let the Ωn be as described above and let E ∈F
such that E ⊆Ωn. By 4 there exists H ∈F such that H ⊆Ωn, H ⊇Ωn \ E, and
µ (H) = µ (Ωn \ E) .
(9.42)
Then let F ≡Ωn ∩HC. It follows F ⊆E and
E \ F
=
E ∩F C = E ∩
¡
H ∪ΩC
n
¢
=
E ∩H = H \ (Ωn \ E)
Hence from 9.42
µ (E \ F) = µ (H \ (Ωn \ E)) = 0.
It follows
µ (E) = µ (F) = µ (F) .
In the case where E ∈F is arbitrary, not necessarily contained in some Ωn, it
follows from what was just shown that there exists Fn ∈F such that Fn ⊆E ∩Ωn
and
µ (Fn) = µ (E ∩Ωn) .
Letting F ≡∪nFn
µ (E \ F) ≤µ (∪n (E ∩Ωn \ Fn)) ≤
X
n
µ (E ∩Ωn \ Fn) = 0.
Therefore, µ (E) = µ (F) and this proves 5. This proves the theorem.
Now here is an interesting theorem about complete measure spaces.
Theorem 9.69 Let (Ω, F, µ) be a complete measure space and let f ≤g ≤h be
functions having values in [0, ∞] . Suppose also that f (ω) = h (ω) a.e. ω and that
f and h are measurable. Then g is also measurable. If
¡
Ω, F, µ
¢
is the completion

256
THE CONSTRUCTION OF MEASURES
of a σ ﬁnite measure space (Ω, F, µ) as described above in Theorem 9.68 then if f
is measurable with respect to F
having values in [0, ∞] , it follows there exists g
measurable with respect to F , g ≤f, and a set N ∈F with µ (N) = 0 and g = f
on N C. There also exists h measurable with respect to F such that h ≥f, and a
set of measure zero, M ∈F such that f = h on M C.
Proof: Let α ∈R.
[f > α] ⊆[g > α] ⊆[h > α]
Thus
[g > α] = [f > α] ∪([g > α] \ [f > α])
and [g > α] \ [f > α] is a measurable set because it is a subset of the set of measure
zero,
[h > α] \ [f > α] .
Now consider the last assertion. By Theorem 8.27 on Page 190 there exists an
increasing sequence of nonnegative simple functions, {sn} measurable with respect
to F which converges pointwise to f. Letting
sn (ω) =
mn
X
k=1
cn
kXEn
k (ω)
(9.43)
be one of these simple functions, it follows from Theorem 9.68 there exist sets,
F n
k ∈F such that F n
k ⊆En
k and µ (F n
k ) = µ (En
k ) . Then let
tn (ω) ≡
mn
X
k=1
cn
kXF n
k (ω) .
Thus tn = sn oﬀa set of measure zero, Nn ∈F, tn ≤sn. Let N ′ ≡∪nNn. Then by
Theorem 9.68 again, there exists N ∈F such that N ⊇N ′ and µ (N) = 0. Consider
the simple functions,
s′
n (ω) ≡tn (ω) XN C (ω) .
It is an increasing sequence so let g (ω) = limn→∞sn′ (ω) . It follows g is mesurable
with respect to F and equals f oﬀN.
Finally, to obtain the function, h ≥f, in 9.43 use Theorem 9.68 to obtain the
existence of F n
k ∈F such that F n
k ⊇En
k and µ (F n
k ) = µ (En
k ). Then let
tn (ω) ≡
mn
X
k=1
cn
kXF n
k (ω) .
Thus tn = sn oﬀa set of measure zero, Mn ∈F, tn ≥sn, and tn is measurable with
respect to F. Then deﬁne
s′
n = max
k≤n tn.
It follows s′
n is an increasing sequence of F measurable nonnegative simple functions.
Since each s′
n ≥sn, it follows that if h (ω) = limn→∞s′
n (ω) ,then h (ω) ≥f (ω) .
Also if h (ω) > f (ω) , then ω ∈∪nMn ≡M ′, a set of F having measure zero. By
Theorem 9.68, there exists M ⊇M ′ such that M ∈F and µ (M) = 0. It follows
h = f oﬀM. This proves the theorem.

9.10.
ANOTHER VERSION OF PRODUCT MEASURES
257
9.10
Another Version Of Product Measures
9.10.1
General Theory
Given two ﬁnite measure spaces, (X, F, µ) and (Y, S, ν) , there is a way to deﬁne a
σ algebra of subsets of X × Y , denoted by F × S and a measure, denoted by µ × ν
deﬁned on this σ algebra such that
µ × ν (A × B) = µ (A) λ (B)
whenever A ∈F and B ∈S. This is naturally related to the concept of iterated
integrals similar to what is used in calculus to evaluate a multiple integral. The
approach is based on something called a π system, [15].
Deﬁnition 9.70 Let (X, F, µ) and (Y, S, ν) be two measure spaces. A measurable
rectangle is a set of the form A × B where A ∈F and B ∈S.
Deﬁnition 9.71 Let Ωbe a set and let K be a collection of subsets of Ω. Then K
is called a π system if ∅∈K and whenever A, B ∈K, it follows A ∩B ∈K.
Obviously an example of a π system is the set of measurable rectangles because
A × B ∩A′ × B′ = (A ∩A′) × (B ∩B′) .
The following is the fundamental lemma which shows these π systems are useful.
Lemma 9.72 Let K be a π system of subsets of Ω, a set. Also let G be a collection
of subsets of Ωwhich satisﬁes the following three properties.
1. K ⊆G
2. If A ∈G, then AC ∈G
3. If {Ai}∞
i=1 is a sequence of disjoint sets from G then ∪∞
i=1Ai ∈G.
Then G ⊇σ (K) , where σ (K) is the smallest σ algebra which contains K.
Proof: First note that if
H ≡{G : 1 - 3 all hold}
then ∩H yields a collection of sets which also satisﬁes 1 - 3. Therefore, I will assume
in the argument that G is the smallest collection satisfying 1 - 3. Let A ∈K and
deﬁne
GA ≡{B ∈G : A ∩B ∈G} .
I want to show GA satisﬁes 1 - 3 because then it must equal G since G is the smallest
collection of subsets of Ωwhich satisﬁes 1 - 3. This will give the conclusion that for
A ∈K and B ∈G, A ∩B ∈G. This information will then be used to show that if

258
THE CONSTRUCTION OF MEASURES
A, B ∈G then A ∩B ∈G. From this it will follow very easily that G is a σ algebra
which will imply it contains σ (K). Now here are the details of the argument.
Since K is given to be a π system, K ⊆GA. Property 3 is obvious because if
{Bi} is a sequence of disjoint sets in GA, then
A ∩∪∞
i=1Bi = ∪∞
i=1A ∩Bi ∈G
because A ∩Bi ∈G and the property 3 of G.
It remains to verify Property 2 so let B ∈GA. I need to verify that BC ∈GA.
In other words, I need to show that A ∩BC ∈G. However,
A ∩BC =
¡
AC ∪(A ∩B)
¢C ∈G
Here is why. Since B ∈GA, A ∩B ∈G and since A ∈K ⊆G it follows AC ∈G. It
follows the union of the disjoint sets, AC and (A ∩B) is in G and then from 2 the
complement of their union is in G. Thus GA satisﬁes 1 - 3 and this implies since G is
the smallest such, that GA ⊇G. However, GA is constructed as a subset of G. This
proves that for every B ∈G and A ∈K, A ∩B ∈G. Now pick B ∈G and consider
GB ≡{A ∈G : A ∩B ∈G} .
I just proved K ⊆GB. The other arguments are identical to show GB satisﬁes 1 - 3
and is therefore equal to G. This shows that whenever A, B ∈G it follows A∩B ∈G.
This implies G is a σ algebra. To show this, all that is left is to verify G is closed
under countable unions because then it follows G is a σ algebra. Let {Ai} ⊆G.
Then let A′
1 = A1 and
A′
n+1
≡
An+1 \ (∪n
i=1Ai)
=
An+1 ∩
¡
∩n
i=1AC
i
¢
=
∩n
i=1
¡
An+1 ∩AC
i
¢
∈G
because ﬁnite intersections of sets of G are in G. Since the A′
i are disjoint, it follows
∪∞
i=1Ai = ∪∞
i=1A′
i ∈G
Therefore, G ⊇σ (K) and this proves the Lemma.
With this lemma, it is easy to deﬁne product measure.
Let (X, F, µ) and (Y, S, ν) be two ﬁnite measure spaces. Deﬁne K to be the set
of measurable rectangles, A × B, A ∈F and B ∈S. Let
G ≡
½
E ⊆X × Y :
Z
Y
Z
X
XEdµdν =
Z
X
Z
Y
XEdνdµ
¾
(9.44)
where in the above, part of the requirement is for all integrals to make sense.
Then K ⊆G. This is obvious.

9.10.
ANOTHER VERSION OF PRODUCT MEASURES
259
Next I want to show that if E ∈G then EC ∈G. Observe XEC = 1 −XE and so
Z
Y
Z
X
XECdµdν
=
Z
Y
Z
X
(1 −XE) dµdν
=
Z
X
Z
Y
(1 −XE) dνdµ
=
Z
X
Z
Y
XECdνdµ
which shows that if E ∈G, then EC ∈G.
Next I want to show G is closed under countable unions of disjoint sets of G. Let
{Ai} be a sequence of disjoint sets from G. Then
Z
Y
Z
X
X∪∞
i=1Aidµdν
=
Z
Y
Z
X
∞
X
i=1
XAidµdν
=
Z
Y
∞
X
i=1
Z
X
XAidµdν
=
∞
X
i=1
Z
Y
Z
X
XAidµdν
=
∞
X
i=1
Z
X
Z
Y
XAidνdµ
=
Z
X
∞
X
i=1
Z
Y
XAidνdµ
=
Z
X
Z
Y
∞
X
i=1
XAidνdµ
=
Z
X
Z
Y
X∪∞
i=1Aidνdµ,
(9.45)
the interchanges between the summation and the integral depending on the mono-
tone convergence theorem.
Thus G is closed with respect to countable disjoint
unions.
From Lemma 9.72, G ⊇σ (K) . Also the computation in 9.45 implies that on
σ (K) one can deﬁne a measure, denoted by µ × ν and that for every E ∈σ (K) ,
(µ × ν) (E) =
Z
Y
Z
X
XEdµdν =
Z
X
Z
Y
XEdνdµ.
(9.46)
Now here is Fubini’s theorem.
Theorem 9.73 Let f : X ×Y →[0, ∞] be measurable with respect to the σ algebra,
σ (K) just deﬁned and let µ × ν be the product measure of 9.46 where µ and ν are
ﬁnite measures on (X, F) and (Y, S) respectively. Then
Z
X×Y
fd (µ × ν) =
Z
Y
Z
X
fdµdν =
Z
X
Z
Y
fdνdµ.

260
THE CONSTRUCTION OF MEASURES
Proof: Let {sn} be an increasing sequence of σ (K) measurable simple functions
which converges pointwise to f. The above equation holds for sn in place of f from
what was shown above. The ﬁnal result follows from passing to the limit and using
the monotone convergence theorem. This proves the theorem.
The symbol, F × S denotes σ (K).
Of course one can generalize right away to measures which are only σ ﬁnite.
Theorem 9.74 Let f : X ×Y →[0, ∞] be measurable with respect to the σ algebra,
σ (K) just deﬁned and let µ × ν be the product measure of 9.46 where µ and ν are
σ ﬁnite measures on (X, F) and (Y, S) respectively. Then
Z
X×Y
fd (µ × ν) =
Z
Y
Z
X
fdµdν =
Z
X
Z
Y
fdνdµ.
Proof: Since the measures are σ ﬁnite, there exist increasing sequences of sets,
{Xn} and {Yn} such that µ (Xn) < ∞and µ (Yn) < ∞. Then µ and ν restricted
to Xn and Yn respectively are ﬁnite. Then from Theorem 9.73,
Z
Yn
Z
Xn
fdµdν =
Z
Xn
Z
Yn
fdνdµ
Passing to the limit yields
Z
Y
Z
X
fdµdν =
Z
X
Z
Y
fdνdµ
whenever f is as above. In particular, you could take f = XE where E ∈F × S
and deﬁne
(µ × ν) (E) ≡
Z
Y
Z
X
XEdµdν =
Z
X
Z
Y
XEdνdµ.
Then just as in the proof of Theorem 9.73, the conclusion of this theorem is obtained.
This proves the theorem.
It is also useful to note that all the above holds for Qn
i=1 Xi in place of X × Y.
You would simply modify the deﬁnition of G in 9.44 including all permutations for
the iterated integrals and for K you would use sets of the form Qn
i=1 Ai where Ai
is measurable. Everything goes through exactly as above. Thus the following is
obtained.
Theorem 9.75 Let {(Xi, Fi, µi)}n
i=1 be σ ﬁnite measure spaces and let Qn
i=1 Fi de-
note the smallest σ algebra which contains the measurable boxes of the form Qn
i=1 Ai
where Ai ∈Fi. Then there exists a measure, λ deﬁned on Qn
i=1 Fi such that if
f : Qn
i=1 Xi →[0, ∞] is Qn
i=1 Fi measurable, and (i1, · · ·, in) is any permutation of
(1, · · ·, n) , then
Z
fdλ =
Z
Xin
· · ·
Z
Xi1
fdµi1 · · · dµin

9.10.
ANOTHER VERSION OF PRODUCT MEASURES
261
9.10.2
Completion Of Product Measure Spaces
Using Theorem 9.69 it is easy to give a generalization to yield a theorem for the
completion of product spaces.
Theorem 9.76 Let {(Xi, Fi, µi)}n
i=1 be σ ﬁnite measure spaces and let Qn
i=1 Fi de-
note the smallest σ algebra which contains the measurable boxes of the form Qn
i=1 Ai
where Ai ∈Fi. Then there exists a measure, λ deﬁned on Qn
i=1 Fi such that if
f : Qn
i=1 Xi →[0, ∞] is Qn
i=1 Fi measurable, and (i1, · · ·, in) is any permutation of
(1, · · ·, n) , then
Z
fdλ =
Z
Xin
· · ·
Z
Xi1
fdµi1 · · · dµin
Let
³Qn
i=1 Xi, Qn
i=1 Fi, λ
´
denote the completion of this product measure space and
let
f :
n
Y
i=1
Xi →[0, ∞]
be Qn
i=1 Fi measurable. Then there exists N ∈Qn
i=1 Fi such that λ (N) = 0 and a
nonnegative function, f1 measurable with respect to Qn
i=1 Fi
such that f1 = f oﬀ
N and if (i1, · · ·, in) is any permutation of (1, · · ·, n) , then
Z
fdλ =
Z
Xin
· · ·
Z
Xi1
f1dµi1 · · · dµin.
Furthermore, f1 may be chosen to satisfy either f1 ≤f or f1 ≥f.
Proof: This follows immediately from Theorem 9.75 and Theorem 9.69. By the
second theorem, there exists a function f1 ≥f such that f1 = f for all (x1, · · ·, xn) /∈
N, a set of Qn
i=1 Fi having measure zero. Then by Theorem 9.68 and Theorem 9.75
Z
fdλ =
Z
f1dλ =
Z
Xin
· · ·
Z
Xi1
f1dµi1 · · · dµin.
To get f1 ≤f, just use that part of Theorem 9.69.
Since f1 = f oﬀa set of measure zero, I will dispense with the subscript. Also
it is customary to write
λ = µ1 × · · · × µn
and
λ = µ1 × · · · × µn.
Thus in more standard notation, one writes
Z
fd (µ1 × · · · × µn) =
Z
Xin
· · ·
Z
Xi1
fdµi1 · · · dµin
This theorem is often referred to as Fubini’s theorem. The next theorem is also
called this.

262
THE CONSTRUCTION OF MEASURES
Corollary 9.77 Suppose f ∈L1 ³Qn
i=1 Xi, Qn
i=1 Fi, µ1 × · · · × µn
´
where each Xi
is a σ ﬁnite measure space. Then if (i1, · · ·, in) is any permutation of (1, · · ·, n) , it
follows
Z
fd (µ1 × · · · × µn) =
Z
Xin
· · ·
Z
Xi1
fdµi1 · · · dµin.
Proof: Just apply Theorem 9.76 to the positive and negative parts of the real
and imaginary parts of f. This proves the theorem.
Here is another easy corollary.
Corollary 9.78 Suppose in the situation of Corollary 9.77, f = f1 oﬀN, a set of
Qn
i=1 Fi having µ1 × · · · × µn measure zero and that f1 is a complex valued function
measurable with respect to Qn
i=1 Fi.
Suppose also that for some permutation of
(1, 2, · · ·, n) , (j1, · · ·, jn)
Z
Xjn
· · ·
Z
Xj1
|f1| dµj1 · · · dµjn < ∞.
Then
f ∈L1
Ã n
Y
i=1
Xi,
n
Y
i=1
Fi, µ1 × · · · × µn
!
and the conclusion of Corollary 9.77 holds.
Proof: Since |f1| is Qn
i=1 Fi measurable, it follows from Theorem 9.75 that
∞
>
Z
Xjn
· · ·
Z
Xj1
|f1| dµj1 · · · dµjn
=
Z
|f1| d (µ1 × · · · × µn)
=
Z
|f1| d (µ1 × · · · × µn)
=
Z
|f| d (µ1 × · · · × µn) .
Thus f ∈L1 ³Qn
i=1 Xi, Qn
i=1 Fi, µ1 × · · · × µn
´
as claimed and the rest follows from
Corollary 9.77. This proves the corollary.
The following lemma is also useful.
Lemma 9.79 Let (X, F, µ) and (Y, S, ν) be σ ﬁnite complete measure spaces and
suppose f ≥0 is F × S measurable. Then for a.e. x,
y →f (x, y)
is S measurable. Similarly for a.e. y,
x →f (x, y)
is F measurable.

9.11.
DISTURBING EXAMPLES
263
Proof: By Theorem 9.69, there exist F × S measurable functions, g and h and
a set, N ∈F × S of µ × λ measure zero such that g ≤f ≤h and for (x, y) /∈N, it
follows that g (x, y) = h (x, y) . Then
Z
X
Z
Y
gdνdµ =
Z
X
Z
Y
hdνdµ
and so for a.e. x,
Z
Y
gdν =
Z
Y
hdν.
Then it follows that for these values of x, g (x, y) = h (x, y) and so by Theorem 9.69
again and the assumption that (Y, S, ν) is complete, y →f (x, y) is S measurable.
The other claim is similar. This proves the lemma.
9.11
Disturbing Examples
There are examples which help to deﬁne what can be expected of product measures
and Fubini type theorems.
Three such examples are given in Rudin [45].
The
theorems given above are more general than those in this reference but the same
examples are still useful for showing that the hypotheses of the above theorems are
all necessary.
Example 9.80 Let {an} be an increasing sequence of numbers in (0, 1) which
converges to 1. Let gn ∈Cc (an, an+1) such that
R
gndx = 1. Now for (x, y) ∈
[0, 1) × [0, 1) deﬁne
f (x, y) ≡
∞
X
k=1
gn (y) (gn (x) −gn+1 (x)) .
Note this is actually a ﬁnite sum for each such (x, y) . Therefore, this is a continuous
function on [0, 1) × [0, 1). Now for a ﬁxed y,
Z 1
0
f (x, y) dx =
∞
X
k=1
gn (y)
Z 1
0
(gn (x) −gn+1 (x)) dx = 0
showing that
R 1
0
R 1
0 f (x, y) dxdy =
R 1
0 0dy = 0. Next ﬁx x.
Z 1
0
f (x, y) dy =
∞
X
k=1
(gn (x) −gn+1 (x))
Z 1
0
gn (y) dy = g1 (x) .
Hence
R 1
0
R 1
0 f (x, y) dydx =
R 1
0 g1 (x) dx = 1. The iterated integrals are not equal.
Note the function, g is not nonnegative even though it is measurable. In addition,
neither
R 1
0
R 1
0 |f (x, y)| dxdy nor
R 1
0
R 1
0 |f (x, y)| dydx is ﬁnite and so you can’t apply
Corollary 9.52.
The problem here is the function is not nonnegative and is not
absolutely integrable.

264
THE CONSTRUCTION OF MEASURES
Example 9.81 This time let µ = m, Lebesgue measure on [0, 1] and let ν be count-
ing measure on [0, 1] , in this case, the σ algebra is P ([0, 1]) . Let l denote the line
segment in [0, 1] × [0, 1] which goes from (0, 0) to (1, 1).
Thus l = (x, x) where
x ∈[0, 1] . Consider the outer measure of l in m × ν. Let l ⊆∪kAk × Bk where Ak
is Lebesgue measurable and Bk is a subset of [0, 1] . Let B ≡{k ∈N : ν (Bk) = ∞} .
If m (∪k∈BAk) has measure zero, then there are uncountably many points of [0, 1]
outside of ∪k∈BAk. For p one of these points, (p, p) ∈Ai ×Bi and i /∈B. Thus each
of these points is in ∪i/∈BBi, a countable set because these Bi are each ﬁnite. But
this is a contradiction because there need to be uncountably many of these points as
just indicated. Thus m (Ak) > 0 for some k ∈B and so m × ν (Ak × Bk) = ∞. It
follows m × ν (l) = ∞and so l is m × ν measurable. Thus
R
Xl (x, y) d m × ν = ∞
and so you cannot apply Fubini’s theorem, Theorem 9.50. Since ν is not σ ﬁnite,
you cannot apply the corollary to this theorem either. Thus there is no contradiction
to the above theorems in the following observation.
Z Z
Xl (x, y) dνdm =
Z
1dm = 1,
Z Z
Xl (x, y) dmdν =
Z
0dν = 0.
The problem here is that you have neither
R
fd m × ν < ∞not σ ﬁnite measure
spaces.
The next example is far more exotic. It concerns the case where both iterated
integrals make perfect sense but are unequal. In 1877 Cantor conjectured that the
cardinality of the real numbers is the next size of inﬁnity after countable inﬁnity.
This hypothesis is called the continuum hypothesis and it has never been proved
or disproved4. Assuming this continuum hypothesis will provide the basis for the
following example. It is due to Sierpinski.
Example 9.82 Let X be an uncountable set.
It follows from the well ordering
theorem which says every set can be well ordered which is presented in the ap-
pendix that X can be well ordered. Let ω ∈X be the ﬁrst element of X which is
preceded by uncountably many points of X. Let Ωdenote {x ∈X : x < ω} . Then
Ωis uncountable but there is no smaller uncountable set.
Thus by the contin-
uum hypothesis, there exists a one to one and onto mapping, j which maps [0, 1]
onto Ω. Thus, for x ∈[0, 1] , j (x) is preceeded by countably many points.
Let
Q ≡
n
(x, y) ∈[0, 1]2 : j (x) < j (y)
o
and let f (x, y) = XQ (x, y) . Then
Z 1
0
f (x, y) dy = 1,
Z 1
0
f (x, y) dx = 0
In each case, the integrals make sense. In the ﬁrst, for ﬁxed x, f (x, y) = 1 for all
but countably many y so the function of y is Borel measurable. In the second where
4In 1940 it was shown by Godel that the continuum hypothesis cannot be disproved. In 1963 it
was shown by Cohen that the continuum hypothesis cannot be proved. These assertions are based
on the axiom of choice and the Zermelo Frankel axioms of set theory. This topic is far outside the
scope of this book and this is only a hopefully interesting historical observation.

9.12.
EXERCISES
265
y is ﬁxed, f (x, y) = 0 for all but countably many x. Thus
Z 1
0
Z 1
0
f (x, y) dydx = 1,
Z 1
0
Z 1
0
f (x, y) dxdy = 0.
The problem here must be that f is not m × m measurable.
9.12
Exercises
1. Let Ω= N, the natural numbers and let d (p, q) = |p −q|, the usual dis-
tance in R. Show that (Ω, d) the closures of the balls are compact. Now let
Λf ≡P∞
k=1 f (k) whenever f ∈Cc (Ω). Show this is a well deﬁned positive
linear functional on the space Cc (Ω). Describe the measure of the Riesz rep-
resentation theorem which results from this positive linear functional. What
if Λ (f) = f (1)? What measure would result from this functional? Which
functions are measurable?
2. Verify that µ deﬁned in Lemma 9.7 is an outer measure.
3. Let F : R →R be increasing and right continuous. Let Λf ≡
R
fdF where
the integral is the Riemann Stieltjes integral of f. Show the measure µ from
the Riesz representation theorem satisﬁes
µ ([a, b])
=
F (b) −F (a−) , µ ((a, b]) = F (b) −F (a) ,
µ ([a, a])
=
F (a) −F (a−) .
4. Let Ωbe a metric space with the closed balls compact and suppose µ is a
measure deﬁned on the Borel sets of Ωwhich is ﬁnite on compact sets. Show
there exists a unique Radon measure, µ which equals µ on the Borel sets.
5. ↑Random vectors are measurable functions, X, mapping a probability space,
(Ω, P, F) to Rn. Thus X (ω) ∈Rn for each ω ∈Ωand P is a probability
measure deﬁned on the sets of F, a σ algebra of subsets of Ω. For E a Borel
set in Rn, deﬁne
µ (E) ≡P
¡
X−1 (E)
¢
≡probability that X ∈E.
Show this is a well deﬁned measure on the Borel sets of Rn and use Problem 4
to obtain a Radon measure, λX deﬁned on a σ algebra of sets of Rn including
the Borel sets such that for E a Borel set, λX (E) =Probability that (X ∈E).
6. Suppose X and Y are metric spaces having compact closed balls. Show
(X × Y, dX×Y )
is also a metric space which has the closures of balls compact. Here
dX×Y ((x1, y1) , (x2, y2)) ≡max (d (x1, x2) , d (y1, y2)) .

266
THE CONSTRUCTION OF MEASURES
Let
A ≡{E × F : E is a Borel set in X, F is a Borel set in Y } .
Show σ (A), the smallest σ algebra containing A contains the Borel sets. Hint:
Show every open set in a metric space which has closed balls compact can be
obtained as a countable union of compact sets. Next show this implies every
open set can be obtained as a countable union of open sets of the form U × V
where U is open in X and V is open in Y .
7. Suppose (Ω, S, µ) is a measure space which may not be complete. Could you
obtain a complete measure space,
¡
Ω, S, µ1
¢
by simply letting S consist of all
sets of the form E where there exists F ∈S such that (F \ E) ∪(E \ F) ⊆N
for some N ∈S which has measure zero and then let µ (E) = µ1 (F)?
8. If µ and ν are Radon measures deﬁned on Rn and Rm respectively, show
µ × ν is also a radon measure on Rn+m. Hint: Show the µ × ν measurable
sets include the open sets using the observation that every open set in Rn+m
is the countable union of sets of the form U × V where U and V are open in
Rn and Rm respectively. Next verify outer regularity by considering A × B
for A, B measurable. Argue sets of R deﬁned above have the property that
they can be approximated in measure from above by open sets. Then verify
the same is true of sets of R1. Finally conclude using an appropriate lemma
that µ × ν is inner regular as well.
9. Let (Ω, S, µ) be a σ ﬁnite measure space and let f : Ω→[0, ∞) be measurable.
Deﬁne
A ≡{(x, y) : y < f (x)}
Verify that A is µ × m measurable. Show that
Z
fdµ =
Z Z
XA (x, y) dµdm =
Z
XAdµ × m.

Lebesgue Measure
10.1
Basic Properties
Deﬁnition 10.1 Deﬁne the following positive linear functional for f ∈Cc (Rn) .
Λf ≡
Z ∞
−∞
· · ·
Z ∞
−∞
f (x) dx1 · · · dxn.
Then the measure representing this functional is Lebesgue measure.
The following lemma will help in understanding Lebesgue measure.
Lemma 10.2 Every open set in Rn is the countable disjoint union of half open
boxes of the form
n
Y
i=1
(ai, ai + 2−k]
where ai = l2−k for some integers, l, k. The sides of these boxes are of equal length.
One could also have half open boxes of the form
n
Y
i=1
[ai, ai + 2−k)
and the conclusion would be unchanged.
Proof: Let
Ck = {All half open boxes
n
Y
i=1
(ai, ai + 2−k] where
ai = l2−k for some integer l.}
Thus Ck consists of a countable disjoint collection of boxes whose union is Rn. This
is sometimes called a tiling of Rn. Think of tiles on the ﬂoor of a bathroom and
267

268
LEBESGUE MEASURE
you will get the idea. Note that each box has diameter no larger than 2−k√n. This
is because if
x, y ∈
n
Y
i=1
(ai, ai + 2−k],
then |xi −yi| ≤2−k. Therefore,
|x −y| ≤
Ã n
X
i=1
¡
2−k¢2
!1/2
= 2−k√n.
Let U be open and let B1 ≡all sets of C1 which are contained in U. If B1, · · ·, Bk
have been chosen, Bk+1 ≡all sets of Ck+1 contained in
U \ ∪
¡
∪k
i=1Bi
¢
.
Let B∞= ∪∞
i=1Bi. In fact ∪B∞= U. Clearly ∪B∞⊆U because every box of every
Bi is contained in U. If p ∈U, let k be the smallest integer such that p is contained
in a box from Ck which is also a subset of U. Thus
p ∈∪Bk ⊆∪B∞.
Hence B∞is the desired countable disjoint collection of half open boxes whose union
is U. The last assertion about the other type of half open rectangle is obvious. This
proves the lemma.
Now what does Lebesgue measure do to a rectangle, Qn
i=1(ai, bi]?
Lemma 10.3 Let R = Qn
i=1[ai, bi], R0 = Qn
i=1(ai, bi). Then
mn (R0) = mn (R) =
n
Y
i=1
(bi −ai).
Proof: Let k be large enough that
ai + 1/k < bi −1/k
for i = 1, · · ·, n and consider functions gk
i and f k
i having the following graphs.
ai + 1
k
@
@
R
ai
£
£
££
1
B
B
BB
bi −1
k
¡
¡
ª
bi
f k
i
ai −1
k
@
@
@
R
ai
£
£
££
1
B
B
BB
bi
bi + 1
k
¡
¡
ª
gk
i
Let
gk(x) =
n
Y
i=1
gk
i (xi), f k(x) =
n
Y
i=1
f k
i (xi).

10.1.
BASIC PROPERTIES
269
Then by elementary calculus along with the deﬁnition of Λ,
n
Y
i=1
(bi −ai + 2/k) ≥Λgk =
Z
gkdmn ≥mn(R) ≥mn(R0)
≥
Z
f kdmn = Λf k ≥
n
Y
i=1
(bi −ai −2/k).
Letting k →∞, it follows that
mn(R) = mn(R0) =
n
Y
i=1
(bi −ai).
This proves the lemma.
Lemma 10.4 Let U be an open or closed set. Then mn (U) = mn (x + U) .
Proof: By Lemma 10.2 there is a sequence of disjoint half open rectangles,
{Ri} such that ∪iRi = U. Therefore, x + U = ∪i (x + Ri) and the x + Ri are also
disjoint rectangles which are identical to the Ri but translated. From Lemma 10.3,
mn (U) = P
i mn (Ri) = P
i mn (x + Ri) = mn (x + U) .
It remains to verify the lemma for a closed set. Let H be a closed bounded set
ﬁrst. Then H ⊆B (0,R) for some R large enough. First note that x+H is a closed
set. Thus
mn (B (x, R))
=
mn (x + H) + mn ((B (0, R) + x) \ (x + H))
=
mn (x + H) + mn ((B (0, R) \ H) + x)
=
mn (x + H) + mn ((B (0, R) \ H))
=
mn (B (0, R)) −mn (H) + mn (x + H)
=
mn (B (x, R)) −mn (H) + mn (x + H)
the last equality because of the ﬁrst part of the lemma which implies mn (B (x, R)) =
mn (B (0, R)) . Therefore, mn (x + H) = mn (H) as claimed. If H is not bounded,
consider Hm ≡B (0, m) ∩H. Then mn (x + Hm) = mn (Hm) . Passing to the limit
as m →∞yields the result in general.
Theorem 10.5 Lebesgue measure is translation invariant. That is
mn (E) = mn (x + E)
for all E Lebesgue measurable.
Proof: Suppose mn (E) < ∞. By regularity of the measure, there exist sets
G, H such that G is a countable intersection of open sets, H is a countable union
of compact sets, mn (G \ H) = 0, and G ⊇E ⊇H. Now mn (G) = mn (G + x) and

270
LEBESGUE MEASURE
mn (H) = mn (H + x) which follows from Lemma 10.4 applied to the sets which
are either intersected to form G or unioned to form H. Now
x + H ⊆x + E ⊆x + G
and both x+H and x+G are measurable because they are either countable unions
or countable intersections of measurable sets. Furthermore,
mn (x + G \ x + H) = mn (x + G) −mn (x + H) = mn (G) −mn (H) = 0
and so by completeness of the measure, x + E is measurable. It follows
mn (E)
=
mn (H) = mn (x + H) ≤mn (x + E)
≤
mn (x + G) = mn (G) = mn (E) .
If mn (E) is not necessarily less than ∞, consider Em ≡B (0, m) ∩E. Then
mn (Em) = mn (Em + x) by the above. Letting m →∞it follows mn (Em) =
mn (Em + x). This proves the theorem.
Corollary 10.6 Let D be an n×n diagonal matrix and let U be an open set. Then
mn (DU) = |det (D)| mn (U) .
Proof:
If any of the diagonal entries of D equals 0 there is nothing to prove
because then both sides equal zero. Therefore, it can be assumed none are equal
to zero.
Suppose these diagonal entries are k1, · · ·, kn. From Lemma 10.2 there
exist half open boxes, {Ri} having all sides equal such that U = ∪iRi. Suppose
one of these is Ri = Qn
j=1(aj, bj], where bj −aj = li. Then DRi = Qn
j=1 Ij where
Ij = (kjaj, kjbj] if kj > 0 and Ij = [kjbj, kjaj) if kj < 0. Then the rectangles, DRi
are disjoint because D is one to one and their union is DU. Also,
mn (DRi) =
n
Y
j=1
|kj| li = |det D| mn (Ri) .
Therefore,
mn (DU) =
∞
X
i=1
mn (DRi) = |det (D)|
∞
X
i=1
mn (Ri) = |det (D)| mn (U) .
and this proves the corollary.
From this the following corollary is obtained.
Corollary 10.7 Let M > 0. Then mn (B (a, Mr)) = M nmn (B (0, r)) .
Proof: By Lemma 10.4 there is no loss of generality in taking a = 0. Let D be
the diagonal matrix which has M in every entry of the main diagonal so |det (D)| =
M n.
Note that DB (0, r) = B (0, Mr) . By Corollary 10.6 mn (B (0, Mr)) =
mn (DB (0, r)) = M nmn (B (0, r)) .

10.2.
THE VITALI COVERING THEOREM
271
There are many norms on Rn. Other common examples are
||x||∞≡max {|xk| : x = (x1, · · ·, xn)}
or
||x||p ≡
Ã n
X
i=1
|xi|p
!1/p
.
With ||·|| any norm for Rn you can deﬁne a corresponding ball in terms of this
norm.
B (a, r) ≡{x ∈Rn such that ||x −a|| < r}
It follows from general considerations involving metric spaces presented earlier that
these balls are open sets. Therefore, Corollary 10.7 has an obvious generalization.
Corollary 10.8 Let ||·|| be a norm on Rn. Then for M > 0, mn (B (a, Mr)) =
M nmn (B (0, r)) where these balls are deﬁned in terms of the norm ||·||.
10.2
The Vitali Covering Theorem
The Vitali covering theorem is concerned with the situation in which a set is con-
tained in the union of balls. You can imagine that it might be very hard to get
disjoint balls from this collection of balls which would cover the given set. How-
ever, it is possible to get disjoint balls from this collection of balls which have the
property that if each ball is enlarged appropriately, the resulting enlarged balls do
cover the set. When this result is established, it is used to prove another form of
this theorem in which the disjoint balls do not cover the set but they only miss a
set of measure zero.
Recall the Hausdorﬀmaximal principle, Theorem 1.13 on Page 24 which is
proved to be equivalent to the axiom of choice in the appendix. For convenience,
here it is:
Theorem 10.9 (HausdorﬀMaximal Principle) Let F
be a nonempty partially
ordered set. Then there exists a maximal chain.
I will use this Hausdorﬀmaximal principle to give a very short and elegant proof
of the Vitali covering theorem. This follows the treatment in Evans and Gariepy
[20] which they got from another book. I am not sure who ﬁrst did it this way but
it is very nice because it is so short. In the following lemma and theorem, the balls
will be either open or closed and determined by some norm on Rn. When pictures
are drawn, I shall draw them as though the norm is the usual norm but the results
are unchanged for any norm. Also, I will write (in this section only) B (a, r) to
indicate a set which satisﬁes
{x ∈Rn : ||x −a|| < r} ⊆B (a, r) ⊆{x ∈Rn : ||x −a|| ≤r}
and bB (a, r) to indicate the usual ball but with radius 5 times as large,
{x ∈Rn : ||x −a|| < 5r} .

272
LEBESGUE MEASURE
Lemma 10.10
Let ||·|| be a norm on Rn and let F be a collection of balls deter-
mined by this norm. Suppose
∞> M ≡sup{r : B(p, r) ∈F} > 0
and k ∈(0, ∞) . Then there exists G ⊆F such that
if B(p, r) ∈G then r > k,
(10.1)
if B1, B2 ∈G then B1 ∩B2 = ∅,
(10.2)
G is maximal with respect to 10.1 and 10.2.
Note that if there is no ball of F which has radius larger than k then G = ∅.
Proof: Let H = {B ⊆F such that 10.1 and 10.2 hold}. If there are no balls
with radius larger than k then H = ∅and you let G =∅. In the other case, H ̸= ∅
because there exists B(p, r) ∈F with r > k. In this case, partially order H by set
inclusion and use the Hausdorﬀmaximal principle (see the appendix on set theory)
to let C be a maximal chain in H. Clearly ∪C satisﬁes 10.1 and 10.2 because if B1
and B2 are two balls from ∪C
then since C
is a chain, it follows there is some
element of C, B such that both B1 and B2 are elements of B and B satisﬁes 10.1 and
10.2. If ∪C is not maximal with respect to these two properties, then C was not a
maximal chain because then there would exist B ⊋∪C, that is, B contains C as a
proper subset and {C, B} would be a strictly larger chain in H. Let G = ∪C.
Theorem 10.11
(Vitali) Let F be a collection of balls and let
A ≡∪{B : B ∈F}.
Suppose
∞> M ≡sup{r : B(p, r) ∈F} > 0.
Then there exists G ⊆F such that G consists of disjoint balls and
A ⊆∪{ bB : B ∈G}.
Proof: Using Lemma 10.10, there exists G1 ⊆F ≡F0 which satisﬁes
B(p, r) ∈G1 implies r > M
2 ,
(10.3)
B1, B2 ∈G1 implies B1 ∩B2 = ∅,
(10.4)
G1 is maximal with respect to 10.3, and 10.4.
Suppose G1, · · ·, Gm have been chosen, m ≥1. Let
Fm ≡{B ∈F : B ⊆Rn \ ∪{G1 ∪· · · ∪Gm}}.

10.3.
THE VITALI COVERING THEOREM (ELEMENTARY VERSION)
273
Using Lemma 10.10, there exists Gm+1 ⊆Fm such that
B(p, r) ∈Gm+1 implies r >
M
2m+1 ,
(10.5)
B1, B2 ∈Gm+1 implies B1 ∩B2 = ∅,
(10.6)
Gm+1 is a maximal subset of Fm with respect to 10.5 and 10.6.
Note it might be the case that Gm+1 = ∅which happens if Fm = ∅. Deﬁne
G ≡∪∞
k=1Gk.
Thus G is a collection of disjoint balls in F. I must show { bB : B ∈G} covers A.
Let x ∈B(p, r) ∈F and let
M
2m < r ≤
M
2m−1 .
Then B (p, r) must intersect some set, B (p0, r0) ∈G1 ∪· · · ∪Gm since otherwise,
Gm would fail to be maximal. Then r0 > M
2m because all balls in G1 ∪···∪Gm satisfy
this inequality.
r0
p0
?
r p.x
Then for x ∈B (p, r) , the following chain of inequalities holds because r ≤
M
2m−1
and r0 > M
2m
|x −p0|
≤
|x −p| + |p −p0| ≤r + r0 + r
≤
2M
2m−1 + r0 = 4M
2m + r0 < 5r0.
Thus B (p, r) ⊆bB (p0, r0) and this proves the theorem.
10.3
The Vitali Covering Theorem (Elementary
Version)
The proof given here is from Basic Analysis [35]. It ﬁrst considers the case of open
balls and then generalizes to balls which may be neither open nor closed or closed.
Lemma 10.12
Let F
be a countable collection of balls satisfying
∞> M ≡sup{r : B(p, r) ∈F} > 0
and let k ∈(0, ∞) . Then there exists G ⊆F such that
If B(p, r) ∈G then r > k,
(10.7)
If B1, B2 ∈G then B1 ∩B2 = ∅,
(10.8)
G is maximal with respect to 10.7 and 10.8.
(10.9)

274
LEBESGUE MEASURE
Proof: If no ball of F has radius larger than k, let G = ∅. Assume therefore, that
some balls have radius larger than k. Let F ≡{Bi}∞
i=1. Now let Bn1 be the ﬁrst ball
in the list which has radius greater than k. If every ball having radius larger than k
intersects this one, then stop. The maximal set is just Bn1. Otherwise, let Bn2 be
the next ball having radius larger than k which is disjoint from Bn1. Continue this
way obtaining {Bni}∞
i=1, a ﬁnite or inﬁnite sequence of disjoint balls having radius
larger than k. Then let G ≡{Bni}. To see that G is maximal with respect to 10.7
and 10.8, suppose B ∈F, B has radius larger than k, and G ∪{B} satisﬁes 10.7
and 10.8. Then at some point in the process, B would have been chosen because it
would be the ball of radius larger than k which has the smallest index. Therefore,
B ∈G and this shows G is maximal with respect to 10.7 and 10.8.
For the next lemma, for an open ball, B = B (x, r) , denote by eB the open ball,
B (x, 4r) .
Lemma 10.13
Let F
be a collection of open balls, and let
A ≡∪{B : B ∈F} .
Suppose
∞> M ≡sup {r : B(p, r) ∈F} > 0.
Then there exists G ⊆F such that G consists of disjoint balls and
A ⊆∪{ eB : B ∈G}.
Proof: Without loss of generality assume F is countable. This is because there
is a countable subset of F, F′ such that ∪F′ = A. To see this, consider the set
of balls having rational radii and centers having all components rational. This is a
countable set of balls and you should verify that every open set is the union of balls
of this form. Therefore, you can consider the subset of this set of balls consisting of
those which are contained in some open set of F, G so ∪G = A and use the axiom
of choice to deﬁne a subset of F consisting of a single set from F containing each
set of G. Then this is F′ . The union of these sets equals A . Then consider F′
instead of F. Therefore, assume at the outset F is countable. By Lemma 10.12,
there exists G1 ⊆F which satisﬁes 10.7, 10.8, and 10.9 with k = 2M
3 .
Suppose G1, · · ·, Gm−1 have been chosen for m ≥2. Let
Fm = {B ∈F : B ⊆Rn \
union of the balls in these Gj
z
}|
{
∪{G1 ∪· · · ∪Gm−1}
}
and using Lemma 10.12, let Gm be a maximal collection of disjoint balls from Fm
with the property that each ball has radius larger than
¡ 2
3
¢m M. Let G ≡∪∞
k=1Gk.
Let x ∈B (p, r) ∈F. Choose m such that
µ2
3
¶m
M < r ≤
µ2
3
¶m−1
M

10.3.
THE VITALI COVERING THEOREM (ELEMENTARY VERSION)
275
Then B (p, r) must have nonempty intersection with some ball from G1 ∪· · · ∪Gm
because if it didn’t, then Gm would fail to be maximal. Denote by B (p0, r0) a ball
in G1 ∪· · · ∪Gm which has nonempty intersection with B (p, r) . Thus
r0 >
µ2
3
¶m
M.
Consider the picture, in which w ∈B (p0, r0) ∩B (p, r) .
w·
 r0
p0
?
r
p
·x
Then
|x −p0|
≤
|x −p| + |p −w| +
<r0
z
}|
{
|w −p0|
<
r + r + r0 ≤2
< 3
2 r0
z
}|
{
µ2
3
¶m−1
M + r0
<
2
µ3
2
¶
r0 + r0 = 4r0.
This proves the lemma since it shows B (p, r) ⊆B (p0, 4r0) .
With this Lemma consider a version of the Vitali covering theorem in which
the balls do not have to be open.
A ball centered at x of radius r will denote
something which contains the open ball, B (x, r) and is contained in the closed ball,
B (x, r). Thus the balls could be open or they could contain some but not all of
their boundary points.
Deﬁnition 10.14 Let B be a ball centered at x having radius r. Denote by bB the
open ball, B (x, 5r).
Theorem 10.15 (Vitali) Let F
be a collection of balls, and let
A ≡∪{B : B ∈F} .
Suppose
∞> M ≡sup {r : B(p, r) ∈F} > 0.
Then there exists G ⊆F such that G consists of disjoint balls and
A ⊆∪{ bB : B ∈G}.
Proof: For B one of these balls, say B (x, r) ⊇B ⊇B (x, r), denote by B1, the
ball B
¡
x, 5r
4
¢
. Let F1 ≡{B1 : B ∈F} and let A1 denote the union of the balls in
F1. Apply Lemma 10.13 to F1 to obtain
A1 ⊆∪{f
B1 : B1 ∈G1}

276
LEBESGUE MEASURE
where G1 consists of disjoint balls from F1. Now let G ≡{B ∈F : B1 ∈G1}. Thus
G consists of disjoint balls from F because they are contained in the disjoint open
balls, G1. Then
A ⊆A1 ⊆∪{f
B1 : B1 ∈G1} = ∪{ bB : B ∈G}
because for B1 = B
¡
x, 5r
4
¢
, it follows f
B1 = B (x, 5r) = bB. This proves the theorem.
10.4
Vitali Coverings
There is another version of the Vitali covering theorem which is also of great impor-
tance. In this one, balls from the original set of balls almost cover the set,leaving
out only a set of measure zero. It is like packing a truck with stuﬀ. You keep trying
to ﬁll in the holes with smaller and smaller things so as to not waste space. It is
remarkable that you can avoid wasting any space at all when you are dealing with
balls of any sort provided you can use arbitrarily small balls.
Deﬁnition 10.16 Let F
be a collection of balls that cover a set, E, which have
the property that if x ∈E and ε > 0, then there exists B ∈F, diameter of B < ε
and x ∈B. Such a collection covers E in the sense of Vitali.
In the following covering theorem, mn denotes the outer measure determined by
n dimensional Lebesgue measure.
Theorem 10.17 Let E ⊆Rn and suppose 0 < mn(E) < ∞where mn is the
outer measure determined by mn, n dimensional Lebesgue measure, and let F be
a collection of closed balls of bounded radii such that F covers E in the sense of
Vitali. Then there exists a countable collection of disjoint balls from F, {Bj}∞
j=1,
such that mn(E \ ∪∞
j=1Bj) = 0.
Proof: From the deﬁnition of outer measure there exists a Lebesgue measurable
set, E1 ⊇E such that mn (E1) = mn (E). Now by outer regularity of Lebesgue
measure, there exists U, an open set which satisﬁes
mn(E1) > (1 −10−n)mn(U), U ⊇E1.
E1
U

10.4.
VITALI COVERINGS
277
Each point of E is contained in balls of F of arbitrarily small radii and so
there exists a covering of E with balls of F which are themselves contained in U.
Therefore, by the Vitali covering theorem, there exist disjoint balls, {Bi}∞
i=1 ⊆F
such that
E ⊆∪∞
j=1 bBj, Bj ⊆U.
Therefore,
mn (E1)
=
mn (E) ≤mn
³
∪∞
j=1 bBj
´
≤
X
j
mn
³
bBj
´
=
5n X
j
mn (Bj) = 5nmn
¡
∪∞
j=1Bj
¢
Then
mn(E1) > (1 −10−n)mn(U)
≥(1 −10−n)[mn(E1 \ ∪∞
j=1Bj) + mn(∪∞
j=1Bj)]
≥(1 −10−n)[mn(E1 \ ∪∞
j=1Bj) + 5−n
=mn(E1)
z }| {
mn(E) ].
and so
¡
1 −
¡
1 −10−n¢
5−n¢
mn (E1) ≥(1 −10−n)mn(E1 \ ∪∞
j=1Bj)
which implies
mn(E1 \ ∪∞
j=1Bj) ≤(1 −(1 −10−n) 5−n)
(1 −10−n)
mn (E1)
Now a short computation shows
0 < (1 −(1 −10−n) 5−n)
(1 −10−n)
< 1
Hence, denoting by θn a number such that
(1 −(1 −10−n) 5−n)
(1 −10−n)
< θn < 1,
mn
¡
E \ ∪∞
j=1Bj
¢
≤mn(E1 \ ∪∞
j=1Bj) < θnmn (E1) = θnmn (E)
Now pick N1 large enough that
θnmn(E) ≥mn(E1 \ ∪N1
j=1Bj) ≥mn(E \ ∪N1
j=1Bj)
(10.10)
Let F1 = {B ∈F : Bj ∩B = ∅, j = 1, · · ·, N1}. If E \ ∪N1
j=1Bj = ∅, then F1 = ∅
and
mn
³
E \ ∪N1
j=1Bj
´
= 0

278
LEBESGUE MEASURE
Therefore, in this case let Bk = ∅for all k > N1. Consider the case where
E \ ∪N1
j=1Bj ̸= ∅.
In this case, F1 ̸= ∅and covers E \ ∪N1
j=1Bj in the sense of Vitali. Repeat the same
argument, letting E \ ∪N1
j=1Bj play the role of E and letting U \ ∪N1
j=1 Bj play the
role of U. (You pick a diﬀerent E1 whose measure equals the outer measure of
E \ ∪N1
j=1Bj.) Then choosing Bj for j = N1 + 1, · · ·, N2 as in the above argument,
θnmn(E \ ∪N1
j=1Bj) ≥mn(E \ ∪N2
j=1Bj)
and so from 10.10,
θ2
nmn(E) ≥mn(E \ ∪N2
j=1Bj).
Continuing this way
θk
nmn(E) ≥mn
³
E \ ∪Nk
j=1Bj
´
.
If it is ever the case that E \ ∪Nk
j=1Bj = ∅, then, as in the above argument,
mn
³
E \ ∪Nk
j=1Bj
´
= 0.
Otherwise, the process continues and
mn
¡
E \ ∪∞
j=1Bj
¢
≤mn
³
E \ ∪Nk
j=1Bj
´
≤θk
nmn (E)
for every k ∈N. Therefore, the conclusion holds in this case also. This proves the
Theorem.
There is an obvious corollary which removes the assumption that 0 < mn(E).
Corollary 10.18 Let E ⊆Rn and suppose mn(E) < ∞where mn is the outer
measure determined by mn, n dimensional Lebesgue measure, and let F, be a col-
lection of closed balls of bounded radii such that F covers E in the sense of Vitali.
Then there exists a countable collection of disjoint balls from F, {Bj}∞
j=1, such that
mn(E \ ∪∞
j=1Bj) = 0.
Proof: If 0 = mn(E) you simply pick any ball from F for your collection of
disjoint balls.
It is also not hard to remove the assumption that mn (E) < ∞.
Corollary 10.19 Let E ⊆Rn and let F, be a collection of closed balls of bounded
radii such that F covers E in the sense of Vitali. Then there exists a countable
collection of disjoint balls from F, {Bj}∞
j=1, such that mn(E \ ∪∞
j=1Bj) = 0.
Proof: Let Rm ≡(−m, m)n be the open rectangle having sides of length 2m
which is centered at 0 and let R0 = ∅. Let Hm ≡Rm \ Rm. Since both Rm
and Rm have the same measure, (2m)n , it follows mn (Hm) = 0. Now for all
k ∈N, Rk ⊆Rk ⊆Rk+1. Consider the disjoint open sets, Uk ≡Rk+1 \ Rk. Thus

10.5.
CHANGE OF VARIABLES FOR LINEAR MAPS
279
Rn = ∪∞
k=0Uk ∪N where N is a set of measure zero equal to the union of the Hk.
Let Fk denote those balls of F which are contained in Uk and let Ek ≡Uk ∩E.
Then from Theorem 10.17, there exists a sequence of disjoint balls, Dk ≡
©
Bk
i
ª∞
i=1
of Fk such that mn(Ek \ ∪∞
j=1Bk
j ) = 0. Letting {Bi}∞
i=1 be an enumeration of all
the balls of ∪kDk, it follows that
mn(E \ ∪∞
j=1Bj) ≤mn (N) +
∞
X
k=1
mn(Ek \ ∪∞
j=1Bk
j ) = 0.
Also, you don’t have to assume the balls are closed.
Corollary 10.20 Let E ⊆Rn and let F, be a collection of open balls of bounded
radii such that F covers E in the sense of Vitali. Then there exists a countable
collection of disjoint balls from F, {Bj}∞
j=1, such that mn(E \ ∪∞
j=1Bj) = 0.
Proof: Let F be the collection of closures of balls in F. Then F covers E in
the sense of Vitali and so from Corollary 10.19 there exists a sequence of disjoint
closed balls from F satisfying mn
¡
E \ ∪∞
i=1Bi
¢
= 0. Now boundaries of the balls,
Bi have measure zero and so {Bi} is a sequence of disjoint open balls satisfying
mn (E \ ∪∞
i=1Bi) = 0. The reason for this is that
(E \ ∪∞
i=1Bi) \
¡
E \ ∪∞
i=1Bi
¢
⊆∪∞
i=1Bi \ ∪∞
i=1Bi ⊆∪∞
i=1Bi \ Bi,
a set of measure zero. Therefore,
E \ ∪∞
i=1Bi ⊆
¡
E \ ∪∞
i=1Bi
¢
∪
¡
∪∞
i=1Bi \ Bi
¢
and so
mn (E \ ∪∞
i=1Bi)
≤
mn
¡
E \ ∪∞
i=1Bi
¢
+ mn
¡
∪∞
i=1Bi \ Bi
¢
=
mn
¡
E \ ∪∞
i=1Bi
¢
= 0.
This implies you can ﬁll up an open set with balls which cover the open set in
the sense of Vitali.
Corollary 10.21 Let U ⊆Rn be an open set and let F be a collection of closed or
even open balls of bounded radii contained in U such that F covers U in the sense
of Vitali. Then there exists a countable collection of disjoint balls from F, {Bj}∞
j=1,
such that mn(U \ ∪∞
j=1Bj) = 0.
10.5
Change Of Variables For Linear Maps
To begin with certain kinds of functions map measurable sets to measurable sets.
It will be assumed that U is an open set in Rn and that h : U →Rn satisﬁes
Dh (x) exists for all x ∈U,
(10.11)

280
LEBESGUE MEASURE
Lemma 10.22 Let h satisfy 10.11. If T ⊆U and mn (T) = 0, then mn (h (T)) =
0.
Proof: Let
Tk ≡{x ∈T : ||Dh (x)|| < k}
and let ε > 0 be given.
Now by outer regularity, there exists an open set, V ,
containing Tk which is contained in U such that mn (V ) < ε. Let x ∈Tk. Then by
diﬀerentiability,
h (x + v) = h (x) + Dh (x) v + o (v)
and so there exist arbitrarily small rx < 1 such that B (x,5rx) ⊆V and whenever
|v| ≤rx, |o (v)| < k |v| . Thus
h (B (x, rx)) ⊆B (h (x) , 2krx) .
From the Vitali covering theorem there exists a countable disjoint sequence of
these sets, {B (xi, ri)}∞
i=1 such that {B (xi, 5ri)}∞
i=1 =
n
c
Bi
o∞
i=1 covers Tk Then
letting mn denote the outer measure determined by mn,
mn (h (Tk)) ≤mn
³
h
³
∪∞
i=1 bBi
´´
≤
∞
X
i=1
mn
³
h
³
bBi
´´
≤
∞
X
i=1
mn (B (h (xi) , 2krxi))
=
∞
X
i=1
mn (B (xi, 2krxi)) = (2k)n
∞
X
i=1
mn (B (xi, rxi))
≤
(2k)n mn (V ) ≤(2k)n ε.
Since ε > 0 is arbitrary, this shows mn (h (Tk)) = 0. Now
mn (h (T)) = lim
k→∞mn (h (Tk)) = 0.
This proves the lemma.
Lemma 10.23 Let h satisfy 10.11. If S is a Lebesgue measurable subset of U, then
h (S) is Lebesgue measurable.
Proof: Let Sk = S ∩B (0, k) , k ∈N. By inner regularity of Lebesgue measure,
there exists a set, F, which is the countable union of compact sets and a set T with
mn (T) = 0 such that
F ∪T = Sk.
Then h (F) ⊆h (Sk) ⊆h (F) ∪h (T). By continuity of h, h (F) is a countable
union of compact sets and so it is Borel. By Lemma 10.22, mn (h (T)) = 0 and so
h (Sk) is Lebesgue measurable because of completeness of Lebesgue measure. Now
h (S) = ∪∞
k=1h (Sk) and so it is also true that h (S) is Lebesgue measurable. This
proves the lemma.
In particular, this proves the following corollary.

10.5.
CHANGE OF VARIABLES FOR LINEAR MAPS
281
Corollary 10.24 Suppose A is an n×n matrix. Then if S is a Lebesgue measurable
set, it follows AS is also a Lebesgue measurable set.
Lemma 10.25 Let R be unitary (R∗R = RR∗= I) and let V be a an open or
closed set. Then mn (RV ) = mn (V ) .
Proof: First assume V is a bounded open set. By Corollary 10.21 there is a
disjoint sequence of closed balls, {Bi} such that U = ∪∞
i=1Bi∪N where mn (N) = 0.
Denote by xi the center of Bi and let ri be the radius of Bi. Then by Lemma 10.22
mn (RV ) = P∞
i=1 mn (RBi) . Now by invariance of translation of Lebesgue measure,
this equals P∞
i=1 mn (RBi −Rxi) = P∞
i=1 mn (RB (0, ri)) . Since R is unitary, it
preserves all distances and so RB (0, ri) = B (0, ri) and therefore,
mn (RV ) =
∞
X
i=1
mn (B (0, ri)) =
∞
X
i=1
mn (Bi) = mn (V ) .
This proves the lemma in the case that V is bounded. Suppose now that V
is just
an open set. Let Vk = V ∩B (0, k) . Then mn (RVk) = mn (Vk) . Letting k →∞,
this yields the desired conclusion. This proves the lemma in the case that V is open.
Suppose now that H is a closed and bounded set. Let B (0,R) ⊇H. Then letting
B = B (0, R) for short,
mn (RH)
=
mn (RB) −mn (R (B \ H))
=
mn (B) −mn (B \ H) = mn (H) .
In general, let Hm = H ∩B (0,m). Then from what was just shown, mn (RHm) =
mn (Hm) . Now let m →∞to get the conclusion of the lemma in general. This
proves the lemma.
Lemma 10.26 Let E be Lebesgue measurable set in Rn and let R be unitary. Then
mn (RE) = mn (E) .
Proof: First suppose E is bounded. Then there exist sets, G and H such that
H ⊆E ⊆G and H is the countable union of closed sets while G is the countable
intersection of open sets such that mn (G \ H) = 0. By Lemma 10.25 applied to
these sets whose union or intersection equals H or G respectively, it follows
mn (RG) = mn (G) = mn (H) = mn (RH) .
Therefore,
mn (H) = mn (RH) ≤mn (RE) ≤mn (RG) = mn (G) = mn (E) = mn (H) .
In the general case, let Em = E ∩B (0, m) and apply what was just shown and let
m →∞.
Lemma 10.27 Let V be an open or closed set in Rn and let A be an n × n matrix.
Then mn (AV ) = |det (A)| mn (V ).

282
LEBESGUE MEASURE
Proof: Let RU be the right polar decomposition (Theorem 4.59 on Page 87) of
A and let V be an open set. Then from Lemma 10.26,
mn (AV ) = mn (RUV ) = mn (UV ) .
Now U = Q∗DQ where D is a diagonal matrix such that |det (D)| = |det (A)| and
Q is unitary. Therefore,
mn (AV ) = mn (Q∗DQV ) = mn (DQV ) .
Now QV is an open set and so by Corollary 10.6 on Page 270 and Lemma 10.25,
mn (AV ) = |det (D)| mn (QV ) = |det (D)| mn (V ) = |det (A)| mn (V ) .
This proves the lemma in case V is open.
Now let H be a closed set which is also bounded. First suppose det (A) = 0.
Then letting V be an open set containing H,
mn (AH) ≤mn (AV ) = |det (A)| mn (V ) = 0
which shows the desired equation is obvious in the case where det (A) = 0. Therefore,
assume A is one to one. Since H is bounded, H ⊆B (0, R) for some R > 0. Then
letting B = B (0, R) for short,
mn (AH)
=
mn (AB) −mn (A (B \ H))
=
|det (A)| mn (B) −|det (A)| mn (B \ H) = |det (A)| mn (H) .
If H is not bounded, apply the result just obtained to Hm ≡H ∩B (0, m) and then
let m →∞.
With this preparation, the main result is the following theorem.
Theorem 10.28 Let E be Lebesgue measurable set in Rn and let A be an n × n
matrix. Then mn (AE) = |det (A)| mn (E) .
Proof: First suppose E is bounded. Then there exist sets, G and H such that
H ⊆E ⊆G and H is the countable union of closed sets while G is the countable
intersection of open sets such that mn (G \ H) = 0. By Lemma 10.27 applied to
these sets whose union or intersection equals H or G respectively, it follows
mn (AG) = |det (A)| mn (G) = |det (A)| mn (H) = mn (AH) .
Therefore,
|det (A)| mn (E)
=
|det (A)| mn (H) = mn (AH) ≤mn (AE)
≤
mn (AG) = |det (A)| mn (G) = |det (A)| mn (E) .
In the general case, let Em = E ∩B (0, m) and apply what was just shown and let
m →∞.

10.6.
CHANGE OF VARIABLES FOR C1 FUNCTIONS
283
10.6
Change Of Variables For C1 Functions
In this section theorems are proved which generalize the above to C1 functions.
More general versions can be seen in Kuttler [35], Kuttler [36], and Rudin [45].
There is also a very diﬀerent approach to this theorem given in [35]. The more
general version in [35] follows [45] and both are based on the Brouwer ﬁxed point
theorem and a very clever lemma presented in Rudin [45]. This same approach will
be used later in this book to prove a diﬀerent sort of change of variables theorem
in which the functions are only Lipschitz. The proof will be based on a sequence of
easy lemmas.
Lemma 10.29 Let U and V be bounded open sets in Rn and let h, h−1 be C1
functions such that h (U) = V. Also let f ∈Cc (V ) . Then
Z
V
f (y) dy =
Z
U
f (h (x)) |det (Dh (x))| dx
Proof: Let x ∈U. By the assumption that h and h−1 are C1,
h (x + v) −h (x)
=
Dh (x) v + o (v)
=
Dh (x)
¡
v + Dh−1 (h (x)) o (v)
¢
=
Dh (x) (v + o (v))
and so if r > 0 is small enough then B (x, r) is contained in U and
h (B (x, r)) −h (x) = h (x+B (0,r)) −h (x) ⊆Dh (x) (B (0, (1 + ε) r)) .
(10.12)
Making r still smaller if necessary, one can also obtain
|f (y) −f (h (x))| < ε
(10.13)
for any y ∈h (B (x, r)) and
|f (h (x1)) |det (Dh (x1))| −f (h (x)) |det (Dh (x))|| < ε
(10.14)
whenever x1 ∈B (x, r) . The collection of such balls is a Vitali cover of U. By
Corollary 10.21 there is a sequence of disjoint closed balls {Bi} such that U =
∪∞
i=1Bi ∪N where mn (N) = 0. Denote by xi the center of Bi and ri the radius.
Then by Lemma 10.22, the monotone convergence theorem, and 10.12 - 10.14,
R
V f (y) dy = P∞
i=1
R
h(Bi) f (y) dy
≤εmn (V ) + P∞
i=1
R
h(Bi) f (h (xi)) dy
≤εmn (V ) + P∞
i=1 f (h (xi)) mn (h (Bi))
≤εmn (V ) + P∞
i=1 f (h (xi)) mn (Dh (xi) (B (0, (1 + ε) ri)))
= εmn (V ) + (1 + ε)n P∞
i=1
R
Bi f (h (xi)) |det (Dh (xi))| dx
≤εmn (V ) + (1 + ε)n P∞
i=1
³R
Bi f (h (x)) |det (Dh (x))| dx + εmn (Bi)
´
≤εmn (V ) + (1 + ε)n P∞
i=1
R
Bi f (h (x)) |det (Dh (x))| dx + (1 + ε)n εmn (U)
= εmn (V ) + (1 + ε)n R
U f (h (x)) |det (Dh (x))| dx + (1 + ε)n εmn (U)

284
LEBESGUE MEASURE
Since ε > 0 is arbitrary, this shows
Z
V
f (y) dy ≤
Z
U
f (h (x)) |det (Dh (x))| dx
(10.15)
whenever f ∈Cc (V ) . Now x →f (h (x)) |det (Dh (x))| is in Cc (U) and so using the
same argument with U and V switching roles and replacing h with h−1,
Z
U
f (h (x)) |det (Dh (x))| dx
≤
Z
V
f
¡
h
¡
h−1 (y)
¢¢ ¯¯det
¡
Dh
¡
h−1 (y)
¢¢¯¯ ¯¯det
¡
Dh−1 (y)
¢¯¯ dy
=
Z
V
f (y) dy
by the chain rule. This with 10.15 proves the lemma.
Corollary 10.30 Let U and V be open sets in Rn and let h, h−1 be C1 functions
such that h (U) = V. Also let f ∈Cc (V ) . Then
Z
V
f (y) dy =
Z
U
f (h (x)) |det (Dh (x))| dx
Proof: Choose m large enough that spt (f) ⊆B (0,m) ∩V ≡Vm. Then let
h−1 (Vm) = Um. From Lemma 10.29,
Z
V
f (y) dy
=
Z
Vm
f (y) dy =
Z
Um
f (h (x)) |det (Dh (x))| dx
=
Z
U
f (h (x)) |det (Dh (x))| dx.
This proves the corollary.
Corollary 10.31 Let U and V be open sets in Rn and let h, h−1 be C1 functions
such that h (U) = V. Also let E ⊆V be measurable. Then
Z
V
XE (y) dy =
Z
U
XE (h (x)) |det (Dh (x))| dx.
Proof: Let Em = E ∩Vm where Vm and Um are as in Corollary 10.30. By
regularity of the measure there exist sets, Kk, Gk such that Kk ⊆Em ⊆Gk, Gk
is open, Kk is compact, and mn (Gk \ Kk) < 2−k.
Let Kk ≺fk ≺Gk. Then
fk (y) →XEm (y) a.e.
because if y is such that convergence fails, it must be
the case that y is in Gk \ Kk inﬁnitely often and P
k mn (Gk \ Kk) < ∞. Let
N = ∩m ∪∞
k=m Gk \ Kk, the set of y which is in inﬁnitely many of the Gk \ Kk.
Then fk (h (x)) must converge to XE (h (x)) for all x /∈h−1 (N) , a set of measure
zero by Lemma 10.22. By Corollary 10.30
Z
Vm
fk (y) dy =
Z
Um
fk (h (x)) |det (Dh (x))| dx.

10.6.
CHANGE OF VARIABLES FOR C1 FUNCTIONS
285
By the dominated convergence theorem using a dominating function, XVm in the
integral on the left and XUm |det (Dh)| on the right,
Z
Vm
XEm (y) dy =
Z
Um
XEm (h (x)) |det (Dh (x))| dx.
Therefore,
Z
V
XEm (y) dy
=
Z
Vm
XEm (y) dy =
Z
Um
XEm (h (x)) |det (Dh (x))| dx
=
Z
U
XEm (h (x)) |det (Dh (x))| dx
Let m →∞and use the monotone convergence theorem to obtain the conclusion
of the corollary.
With this corollary, the main theorem follows.
Theorem 10.32 Let U and V be open sets in Rn and let h, h−1 be C1 functions
such that h (U) = V. Then if g is a nonnegative Lebesgue measurable function,
Z
V
g (y) dy =
Z
U
g (h (x)) |det (Dh (x))| dx.
(10.16)
Proof: From Corollary 10.31, 10.16 holds for any nonnegative simple function
in place of g. In general, let {sk} be an increasing sequence of simple functions
which converges to g pointwise. Then from the monotone convergence theorem
Z
V
g (y) dy
=
lim
k→∞
Z
V
skdy = lim
k→∞
Z
U
sk (h (x)) |det (Dh (x))| dx
=
Z
U
g (h (x)) |det (Dh (x))| dx.
This proves the theorem.
This is a pretty good theorem but it isn’t too hard to generalize it. In particular,
it is not necessary to assume h−1 is C1.
Lemma 10.33 Suppose V is an n −1 dimensional subspace of Rn and K is a
compact subset of V . Then letting
Kε ≡∪x∈KB (x,ε) = K + B (0, ε) ,
it follows that
mn (Kε) ≤2nε (diam (K) + ε)n−1 .
Proof: Let an orthonormal basis for V be {v1, · · ·, vn−1} and let
{v1, · · ·, vn−1, vn}

286
LEBESGUE MEASURE
be an orthonormal basis for Rn. Now deﬁne a linear transformation, Q by Qvi = ei.
Thus QQ∗= Q∗Q = I and Q preserves all distances because
¯¯¯¯¯Q
X
i
aiei
¯¯¯¯¯
2
=
¯¯¯¯¯
X
i
aivi
¯¯¯¯¯
2
=
X
i
|ai|2 =
¯¯¯¯¯
X
i
aiei
¯¯¯¯¯
2
.
Letting k0 ∈K, it follows K ⊆B (k0, diam (K)) and so,
QK ⊆Bn−1 (Qk0, diam (QK)) = Bn−1 (Qk0, diam (K))
where Bn−1 refers to the ball taken with respect to the usual norm in Rn−1. Every
point of Kε is within ε of some point of K and so it follows that every point of QKε
is within ε of some point of QK. Therefore,
QKε ⊆Bn−1 (Qk0, diam (QK) + ε) × (−ε, ε) ,
To see this, let x ∈QKε. Then there exists k ∈QK such that |k −x| < ε. There-
fore, |(x1, · · ·, xn−1) −(k1, · · ·, kn−1)| < ε and |xn −kn| < ε and so x is contained
in the set on the right in the above inclusion because kn = 0. However, the measure
of the set on the right is smaller than
[2 (diam (QK) + ε)]n−1 (2ε) = 2n [(diam (K) + ε)]n−1 ε.
This proves the lemma.
Note this is a very sloppy estimate. You can certainly do much better but this
estimate is suﬃcient to prove Sard’s lemma which follows.
Deﬁnition 10.34 In any metric space, if x is a point of the metric space and S is
a nonempty subset,
dist (x,S) ≡inf {d (x, s) : s ∈S} .
More generally, if T, S are two nonempty sets,
dist (S, T) ≡inf {d (t, s) : s ∈S, t ∈T} .
Lemma 10.35 The function x →dist (x,S) is continuous.
Proof: Let x, y be given. Suppose dist (x, S) ≥dist (y, S) and pick s ∈S such
that dist (y, S) + ε ≥d (y, s) . Then
0
≤
dist (x, S) −dist (y, S) ≤dist (x, S) −(d (y, s) −ε)
≤
d (x, s) −d (y, s) + ε ≤d (x, y) + d (y, s) −d (y, s) + ε = d (x, y) + ε.
Since ε > 0 is arbitrary, this shows |dist (x, S) −dist (y, S)| ≤d (x, y) . This proves
the lemma.
Lemma 10.36 Let h be a C1 function deﬁned on an open set, U and let K be a
compact subset of U. Then if ε > 0 is given, there exits r1 > 0 such that if |v| ≤r1,
then for all x ∈K,
|h (x + v) −h (x) −Dh (x) v| < ε |v| .

10.6.
CHANGE OF VARIABLES FOR C1 FUNCTIONS
287
Proof: Let 0 < δ < dist
¡
K, U C¢
. Such a positive number exists because if there
exists a sequence of points in K, {kk} and points in U C, {sk} such that |kk −sk| →
0, then you could take a subsequence, still denoted by k such that kk →k ∈K and
then sk →k also. But U C is closed so k ∈K ∩U C, a contradiction. Then
|h (x + v) −h (x) −Dh (x) v|
|v|
≤
¯¯¯
R 1
0 Dh (x + tv) vdt −Dh (x) v
¯¯¯
|v|
≤
R 1
0 |Dh (x + tv) v −Dh (x) v| dt
|v|
.
Now from uniform continuity of Dh on the compact set, {x : dist (x,K) ≤δ} it
follows there exists r1 < δ such that if |v| ≤r1, then ||Dh (x + tv) −Dh (x)|| < ε
for every x ∈K. From the above formula, it follows that if |v| ≤r1,
|h (x + v) −h (x) −Dh (x) v|
|v|
≤
R 1
0 |Dh (x + tv) v −Dh (x) v| dt
|v|
<
R 1
0 ε |v| dt
|v|
= ε.
This proves the lemma.
A diﬀerent proof of the following is in [35]. See also [36].
Lemma 10.37 (Sard) Let U be an open set in Rn and let h : U →Rn be C1. Let
Z ≡{x ∈U : det Dh (x) = 0} .
Then mn (h (Z)) = 0.
Proof: Let {Uk}∞
k=1 be an increasing sequence of open sets whose closures are
compact and whose union equals U and let Zk ≡Z ∩Uk. To obtain such a sequence,
let Uk =
©
x ∈U : dist
¡
x,U C¢
< 1
k
ª
∩B (0, k) . First it is shown that h (Zk) has
measure zero. Let W be an open set contained in Uk+1 which contains Zk and
satisﬁes
mn (Zk) + ε > mn (W)
where here and elsewhere, ε < 1. Let
r = dist
¡
Uk, U C
k+1
¢
and let r1 > 0 be a constant as in Lemma 10.36 such that whenever x ∈Uk and
0 < |v| ≤r1,
|h (x + v) −h (x) −Dh (x) v| < ε |v| .
(10.17)
Now the closures of balls which are contained in W and which have the property
that their diameters are less than r1 yield a Vitali covering of W. Therefore, by
Corollary 10.21 there is a disjoint sequence of these closed balls,
n
eBi
o
such that
W = ∪∞
i=1 eBi ∪N

288
LEBESGUE MEASURE
where N is a set of measure zero. Denote by {Bi} those closed balls in this sequence
which have nonempty intersection with Zk, let di be the diameter of Bi, and let zi
be a point in Bi ∩Zk. Since zi ∈Zk, it follows Dh (zi) B (0,di) = Di where Di is
contained in a subspace, V which has dimension n −1 and the diameter of Di is no
larger than 2Ckdi where
Ck ≥max {||Dh (x)|| : x ∈Zk}
Then by 10.17, if z ∈Bi,
h (z) −h (zi) ∈Di + B (0, εdi) ⊆Di + B (0,εdi) .
Thus
h (Bi) ⊆h (zi) + Di + B (0,εdi)
By Lemma 10.33
mn (h (Bi))
≤
2n (2Ckdi + εdi)n−1 εdi
≤
dn
i
³
2n [2Ck + ε]n−1´
ε
≤
Cn,kmn (Bi) ε.
Therefore, by Lemma 10.22
mn (h (Zk))
≤
mn (W) =
X
i
mn (h (Bi)) ≤Cn,kε
X
i
mn (Bi)
≤
εCn,kmn (W) ≤εCn,k (mn (Zk) + ε)
Since ε is arbitrary, this shows mn (h (Zk)) = 0 and so 0 = limk→∞mn (h (Zk)) =
mn (h (Z)).
With this important lemma, here is a generalization of Theorem 10.32.
Theorem 10.38 Let U be an open set and let h be a 1−1, C1 function with values
in Rn. Then if g is a nonnegative Lebesgue measurable function,
Z
h(U)
g (y) dy =
Z
U
g (h (x)) |det (Dh (x))| dx.
(10.18)
Proof: Let Z = {x : det (Dh (x)) = 0} . Then by the inverse function theorem,
h−1 is C1 on h (U \ Z) and h (U \ Z) is an open set. Therefore, from Lemma 10.37
and Theorem 10.32,
Z
h(U)
g (y) dy
=
Z
h(U\Z)
g (y) dy =
Z
U\Z
g (h (x)) |det (Dh (x))| dx
=
Z
U
g (h (x)) |det (Dh (x))| dx.
This proves the theorem.
Of course the next generalization considers the case when h is not even one to
one.

10.7.
MAPPINGS WHICH ARE NOT ONE TO ONE
289
10.7
Mappings Which Are Not One To One
Now suppose h is only C1, not necessarily one to one. For
U+ ≡{x ∈U : |det Dh (x)| > 0}
and Z the set where |det Dh (x)| = 0, Lemma 10.37 implies mn(h(Z)) = 0. For
x ∈U+, the inverse function theorem implies there exists an open set Bx such that
x ∈Bx ⊆U+, h is one to one on Bx.
Let {Bi} be a countable subset of {Bx}x∈U+ such that U+ = ∪∞
i=1Bi.
Let
E1 = B1. If E1, · · ·, Ek have been chosen, Ek+1 = Bk+1 \ ∪k
i=1Ei. Thus
∪∞
i=1Ei = U+, h is one to one on Ei, Ei ∩Ej = ∅,
and each Ei is a Borel set contained in the open set Bi. Now deﬁne
n(y) ≡
∞
X
i=1
Xh(Ei)(y) + Xh(Z)(y).
The set, h (Ei) , h (Z) are measurable by Lemma 10.23. Thus n (·) is measurable.
Lemma 10.39
Let F ⊆h(U) be measurable. Then
Z
h(U)
n(y)XF (y)dy =
Z
U
XF (h(x))| det Dh(x)|dx.
Proof: Using Lemma 10.37 and the Monotone Convergence Theorem or Fubini’s
Theorem,
Z
h(U)
n(y)XF (y)dy
=
Z
h(U)



∞
X
i=1
Xh(Ei)(y) +
mn(h(Z))=0
z
}|
{
Xh(Z)(y)


XF (y)dy
=
∞
X
i=1
Z
h(U)
Xh(Ei)(y)XF (y)dy
=
∞
X
i=1
Z
h(Bi)
Xh(Ei)(y)XF (y)dy
=
∞
X
i=1
Z
Bi
XEi(x)XF (h(x))| det Dh(x)|dx
=
∞
X
i=1
Z
U
XEi(x)XF (h(x))| det Dh(x)|dx
=
Z
U
∞
X
i=1
XEi(x)XF (h(x))| det Dh(x)|dx

290
LEBESGUE MEASURE
=
Z
U+
XF (h(x))| det Dh(x)|dx =
Z
U
XF (h(x))| det Dh(x)|dx.
This proves the lemma.
Deﬁnition 10.40
For y ∈h(U), deﬁne a function, #, according to the formula
#(y) ≡number of elements in h−1(y).
Observe that
#(y) = n(y)
a.e.
(10.19)
because n(y) = #(y) if y /∈h(Z), a set of measure 0. Therefore, # is a measurable
function.
Theorem 10.41
Let g ≥0, g measurable, and let h be C1(U). Then
Z
h(U)
#(y)g(y)dy =
Z
U
g(h(x))| det Dh(x)|dx.
(10.20)
Proof: From 10.19 and Lemma 10.39, 10.20 holds for all g, a nonnegative simple
function. Approximating an arbitrary measurable nonnegative function, g, with an
increasing pointwise convergent sequence of simple functions and using the mono-
tone convergence theorem, yields 10.20 for an arbitrary nonnegative measurable
function, g. This proves the theorem.
10.8
Lebesgue Measure And Iterated Integrals
The following is the main result.
Theorem 10.42 Let f ≥0 and suppose f is a Lebesgue measurable function de-
ﬁned on Rn and
R
Rn fdmn < ∞. Then
Z
Rn fdmn =
Z
Rk
Z
Rn−k fdmn−kdmk.
This will be accomplished by Fubini’s theorem, Theorem 9.50 and the following
lemma.
Lemma 10.43 mk × mn−k = mn on the mn measurable sets.
Proof: First of all, let R = Qn
i=1(ai, bi] be a measurable rectangle and let
Rk = Qk
i=1(ai, bi], Rn−k = Qn
i=k+1(ai, bi]. Then by Fubini’s theorem,
Z
XRd (mk × mn−k)
=
Z
Rk
Z
Rn−k XRkXRn−kdmkdmn−k
=
Z
Rk XRkdmk
Z
Rn−k XRn−kdmn−k
=
Z
XRdmn

10.8.
LEBESGUE MEASURE AND ITERATED INTEGRALS
291
and so mk × mn−k
and mn agree on every half open rectangle. By Lemma 10.2
these two measures agree on every open set.
Now if K is a compact set, then
K = ∩∞
k=1Uk where Uk is the open set, K + B
¡
0, 1
k
¢
. Another way of saying this
is Uk ≡
©
x : dist (x,K) < 1
k
ª
which is obviously open because x →dist (x,K) is a
continuous function. Since K is the countable intersection of these decreasing open
sets, each of which has ﬁnite measure with respect to either of the two measures,
it follows that mk × mn−k and mn agree on all the compact sets. Now let E be
a bounded Lebesgue measurable set.
Then there are sets, H and G such that
H is a countable union of compact sets, G a countable intersection of open sets,
H ⊆E ⊆G, and mn (G \ H) = 0. Then from what was just shown about compact
and open sets, the two measures agree on G and on H. Therefore,
mn (H)
=
mk × mn−k (H) ≤mk × mn−k (E)
≤
mk × mn−k (G) = mn (E) = mn (H)
By completeness of the measure space for mk × mn−k, it follows E is mk × mn−k
measurable and
mk × mn−k (E) = mn (E) .
This proves the lemma.
You could also show that the two σ algebras are the same. However, this is not
needed for the lemma or the theorem.
Proof of Theorem 10.42: By the lemma and Fubini’s theorem, Theorem 9.50,
Z
Rn fdmn =
Z
Rn fd (mk × mn−k) =
Z
Rk
Z
Rn−k fdmn−kdmk.
Corollary 10.44 Let f be a nonnegative real valued measurable function. Then
Z
Rn fdmn =
Z
Rk
Z
Rn−k fdmn−kdmk.
Proof: Let Sp ≡{x ∈Rn : 0 ≤f (x) ≤p} ∩B (0, p) . Then
R
Rn fXSpdmn < ∞.
Therefore, from Theorem 10.42,
Z
Rn fXSpdmn =
Z
Rk
Z
Rn−k XSpfdmn−kdmk.
Now let p →∞and use the Monotone convergence theorem and the Fubini Theorem
9.50 on Page 243.
Not surprisingly, the following corollary follows from this.
Corollary 10.45 Let f ∈L1 (Rn) where the measure is mn.
Then
Z
Rn fdmn =
Z
Rk
Z
Rn−k fdmn−kdmk.
Proof: Apply Corollary 10.44 to the postive and negative parts of the real and
imaginary parts of f.

292
LEBESGUE MEASURE
10.9
Spherical Coordinates In Many Dimensions
Sometimes there is a need to deal with spherical coordinates in more than three
dimensions. In this section, this concept is deﬁned and formulas are derived for
these coordinate systems. Recall polar coordinates are of the form
y1 = ρ cos θ
y2 = ρ sin θ
where ρ > 0 and θ ∈[0, 2π). Here I am writing ρ in place of r to emphasize a pattern
which is about to emerge. I will consider polar coordinates as spherical coordinates
in two dimensions.
I will also simply refer to such coordinate systems as polar
coordinates regardless of the dimension. This is also the reason I am writing y1 and
y2 instead of the more usual x and y. Now consider what happens when you go to
three dimensions. The situation is depicted in the following picture.
φ1





ρ
r(x1, x2, x3)
R2
R
From this picture, you see that y3 = ρ cos φ1. Also the distance between (y1, y2)
and (0, 0) is ρ sin (φ1) . Therefore, using polar coordinates to write (y1, y2) in terms
of θ and this distance,
y1 = ρ sin φ1 cos θ,
y2 = ρ sin φ1 sin θ,
y3 = ρ cos φ1.
where φ1 ∈[0, π] . What was done is to replace ρ with ρ sin φ1 and then to add in
y3 = ρ cos φ1. Having done this, there is no reason to stop with three dimensions.
Consider the following picture:
φ2





ρ
r(x1, x2, x3, x4)
R3
R
From this picture, you see that y4 = ρ cos φ2. Also the distance between (y1, y2, y3)
and (0, 0, 0) is ρ sin (φ2) . Therefore, using polar coordinates to write (y1, y2, y3) in

10.9.
SPHERICAL COORDINATES IN MANY DIMENSIONS
293
terms of θ, φ1, and this distance,
y1 = ρ sin φ2 sin φ1 cos θ,
y2 = ρ sin φ2 sin φ1 sin θ,
y3 = ρ sin φ2 cos φ1,
y4 = ρ cos φ2
where φ2 ∈[0, π] .
Continuing this way, given spherical coordinates in Rn, to get the spherical
coordinates in Rn+1, you let yn+1 = ρ cos φn−1 and then replace every occurance of
ρ with ρ sin φn−1 to obtain y1 · · · yn in terms of φ1, φ2, · · ·, φn−1,θ, and ρ.
It is always the case that ρ measures the distance from the point in Rn to the
origin in Rn, 0. Each φi ∈[0, π] , and θ ∈[0, 2π). It can be shown using math
induction that these coordinates map Qn−2
i=1 [0, π] × [0, 2π) × (0, ∞) one to one onto
Rn \ {0} .
Theorem 10.46 Let y = h (φ, θ, ρ) be the spherical coordinate transformations in
Rn. Then letting A = Qn−2
i=1 [0, π] × [0, 2π), it follows h maps A × (0, ∞) one to one
onto Rn \ {0} . Also |det Dh (φ, θ, ρ)| will always be of the form
|det Dh (φ, θ, ρ)| = ρn−1Φ (φ, θ) .
(10.21)
where Φ is a continuous function of φ and θ.1 Furthermore whenever f is Lebesgue
measurable and nonnegative,
Z
Rn f (y) dy =
Z ∞
0
ρn−1
Z
A
f (h (φ, θ, ρ)) Φ (φ, θ) dφ dθdρ
(10.22)
where here dφ dθ denotes dmn−1 on A. The same formula holds if f ∈L1 (Rn) .
Proof: Formula 10.21 is obvious from the deﬁnition of the spherical coordinates.
The ﬁrst claim is also clear from the deﬁnition and math induction. It remains to
verify 10.22. Let A0 ≡Qn−2
i=1 (0, π)×(0, 2π) . Then it is clear that (A \ A0)×(0, ∞) ≡
N is a set of measure zero in Rn. Therefore, from Lemma 10.22 it follows h (N)
is also a set of measure zero. Therefore, using the change of variables theorem,
Corollary 10.44, and Sard’s lemma,
Z
Rn f (y) dy
=
Z
Rn\{0}
f (y) dy =
Z
Rn\({0}∪h(N))
f (y) dy
=
Z
A0×(0,∞)
f (h (φ, θ, ρ)) ρn−1Φ (φ, θ) dmn
=
Z
XA×(0,∞) (φ, θ, ρ) f (h (φ, θ, ρ)) ρn−1Φ (φ, θ) dmn
=
Z ∞
0
ρn−1
µZ
A
f (h (φ, θ, ρ)) Φ (φ, θ) dφ dθ
¶
dρ.
1Actually it is only a function of the ﬁrst but this is not important in what follows.

294
LEBESGUE MEASURE
Now the claim about f ∈L1 follows routinely from considering the positive and
negative parts of the real and imaginary parts of f in the usual way. This proves
the theorem.
Notation 10.47 Often this is written diﬀerently. Note that from the spherical co-
ordinate formulas, f (h (φ, θ, ρ)) = f (ρω) where |ω| = 1. Letting Sn−1 denote the
unit sphere, {ω ∈Rn : |ω| = 1} , the inside integral in the above formula is some-
times written as
Z
Sn−1 f (ρω) dσ
where σ is a measure on Sn−1. See [35] for another description of this measure.
It isn’t an important issue here. Later in the book when integration on manifolds
is discussed, more general considerations will be dealt with. Either 10.22 or the
formula
Z ∞
0
ρn−1
µZ
Sn−1 f (ρω) dσ
¶
dρ
will be referred to as polar coordinates and is very useful in establishing estimates.
Here σ
¡
Sn−1¢
≡
R
A Φ (φ, θ) dφ dθ.
Example 10.48 For what values of s is the integral
R
B(0,R)
³
1 + |x|2´s
dy bounded
independent of R? Here B (0, R) is the ball, {x ∈Rn : |x| ≤R} .
I think you can see immediately that s must be negative but exactly how neg-
ative? It turns out it depends on n and using polar coordinates, you can ﬁnd just
exactly what is needed. From the polar coordinats formula above,
Z
B(0,R)
³
1 + |x|2´s
dy
=
Z R
0
Z
Sn−1
¡
1 + ρ2¢s ρn−1dσdρ
=
Cn
Z R
0
¡
1 + ρ2¢s ρn−1dρ
Now the very hard problem has been reduced to considering an easy one variable
problem of ﬁnding when
Z R
0
ρn−1 ¡
1 + ρ2¢s dρ
is bounded independent of R. You need 2s + (n −1) < −1 so you need s < −n/2.
10.10
The Brouwer Fixed Point Theorem
This seems to be a good place to present a short proof of one of the most important
of all ﬁxed point theorems.
There are many approaches to this but one of the
easiest and shortest I have ever seen is the one in Dunford and Schwartz [18]. This
is what is presented here. In Evans [21] there is a diﬀerent proof which depends on

10.10.
THE BROUWER FIXED POINT THEOREM
295
integration theory. A good reference for an introduction to various kinds of ﬁxed
point theorems is the book by Smart [48]. This book also gives an entirely diﬀerent
approach to the Brouwer ﬁxed point theorem.
The proof given here is based on the following lemma. Recall that the mixed
partial derivatives of a C2 function are equal. In the following lemma, and elsewhere,
a comma followed by an index indicates the partial derivative with respect to the
indicated variable. Thus, f,j will mean
∂f
∂xj . Also, write Dg for the Jacobian matrix
which is the matrix of Dg taken with respect to the usual basis vectors in Rn. Recall
that for A an n × n matrix, cof (A)ij is the determinant of the matrix which results
from deleting the ith row and the jth column and multiplying by (−1)i+j.
Lemma 10.49 Let g : U →Rn be C2 where U is an open subset of Rn. Then
n
X
j=1
cof (Dg)ij,j = 0,
where here (Dg)ij ≡gi,j ≡∂gi
∂xj . Also, cof (Dg)ij = ∂det(Dg)
∂gi,j
.
Proof: From the cofactor expansion theorem,
det (Dg) =
n
X
i=1
gi,j cof (Dg)ij
and so
∂det (Dg)
∂gi,j
= cof (Dg)ij
(10.23)
which shows the last claim of the lemma. Also
δkj det (Dg) =
X
i
gi,k (cof (Dg))ij
(10.24)
because if k ̸= j this is just the cofactor expansion of the determinant of a matrix
in which the kth and jth columns are equal. Diﬀerentiate 10.24 with respect to xj
and sum on j. This yields
X
r,s,j
δkj
∂(det Dg)
∂gr,s
gr,sj =
X
ij
gi,kj (cof (Dg))ij +
X
ij
gi,k cof (Dg)ij,j .
Hence, using δkj = 0 if j ̸= k and 10.23,
X
rs
(cof (Dg))rs gr,sk =
X
rs
gr,ks (cof (Dg))rs +
X
ij
gi,kcof (Dg)ij,j .
Subtracting the ﬁrst sum on the right from both sides and using the equality of
mixed partials,
X
i
gi,k

X
j
(cof (Dg))ij,j

= 0.

296
LEBESGUE MEASURE
If det (gi,k) ̸= 0 so that (gi,k) is invertible, this shows P
j (cof (Dg))ij,j = 0. If
det (Dg) = 0, let
gk = g + εkI
where εk →0 and det (Dg + εkI) ≡det (Dgk) ̸= 0. Then
X
j
(cof (Dg))ij,j = lim
k→∞
X
j
(cof (Dgk))ij,j = 0
and this proves the lemma.
To prove the Brouwer ﬁxed point theorem, ﬁrst consider a version of it valid for
C2 mappings. This is the following lemma.
Lemma 10.50 Let Br = B (0,r) and suppose g is a C2 function deﬁned on Rn
which maps Br to Br. Then g (x) = x for some x ∈Br.
Proof: Suppose not. Then |g (x) −x| must be bounded away from zero on Br.
Let a (x) be the larger of the two roots of the equation,
|x+a (x) (x −g (x))|2 = r2.
(10.25)
Thus
a (x) =
−(x, (x −g (x))) +
r
(x, (x −g (x)))2 +
³
r2 −|x|2´
|x −g (x)|2
|x −g (x)|2
(10.26)
The expression under the square root sign is always nonnegative and it follows
from the formula that a (x) ≥0. Therefore, (x, (x −g (x))) ≥0 for all x ∈Br.
The reason for this is that a (x) is the larger zero of a polynomial of the form
p (z) = |x|2 + z2 |x −g (x)|2 −2z (x, x −g (x)) and from the formula above, it is
nonnegative. −2 (x, x −g (x)) is the slope of the tangent line to p (z) at z = 0. If
x ̸= 0, then |x|2 > 0 and so this slope needs to be negative for the larger of the two
zeros to be positive. If x = 0, then (x, x −g (x)) = 0.
Now deﬁne for t ∈[0, 1],
f (t, x) ≡x+ta (x) (x −g (x)) .
The important properties of f (t, x) and a (x) are that
a (x) = 0 if |x| = r.
(10.27)
and
|f (t, x)| = r for all |x| = r
(10.28)
These properties follow immediately from 10.26 and the above observation that for
x ∈Br, it follows (x, (x −g (x))) ≥0.
Also from 10.26, a is a C2 function near Br. This is obvious from 10.26 as long
as |x| < r. However, even if |x| = r it is still true. To show this, it suﬃces to verify

10.10.
THE BROUWER FIXED POINT THEOREM
297
the expression under the square root sign is positive. If this expression were not
positive for some |x| = r, then (x, (x −g (x))) = 0. Then also, since g (x) ̸= x,
¯¯¯¯
g (x) + x
2
¯¯¯¯ < r
and so
r2 >
µ
x,g (x) + x
2
¶
= 1
2 (x, g (x)) + r2
2 = |x|2
2
+ r2
2 = r2,
a contradiction. Therefore, the expression under the square root in 10.26 is always
positive near Br and so a is a C2 function near Br as claimed because the square
root function is C2 away from zero.
Now deﬁne
I (t) ≡
Z
Br
det (D2f (t, x)) dx.
Then
I (0) =
Z
Br
dx = mn (Br) > 0.
(10.29)
Using the dominated convergence theorem one can diﬀerentiate I (t) as follows.
I′ (t)
=
Z
Br
X
ij
∂det (D2f (t, x))
∂fi,j
∂fi,j
∂t dx
=
Z
Br
X
ij
cof (D2f)ij
∂(a (x) (xi −gi (x)))
∂xj
dx.
Now from 10.27 a (x) = 0 when |x| = r and so integration by parts and Lemma
10.49 yields
I′ (t)
=
Z
Br
X
ij
cof (D2f)ij
∂(a (x) (xi −gi (x)))
∂xj
dx
=
−
Z
Br
X
ij
cof (D2f)ij,j a (x) (xi −gi (x)) dx = 0.
Therefore, I (1) = I (0). However, from 10.25 it follows that for t = 1,
X
i
fifi = r2
and so, P
i fi,jfi = 0 which implies since |f (1, x)| = r by 10.25, that det (fi,j) =
det (D2f (1, x)) = 0 and so I (1) = 0, a contradiction to 10.29 since I (1) = I (0).
This proves the lemma.
The following theorem is the Brouwer ﬁxed point theorem for a ball.
Theorem 10.51 Let Br be the above closed ball and let f : Br →Br be continuous.
Then there exists x ∈Br such that f (x) = x.

298
LEBESGUE MEASURE
Proof: Let fk (x) ≡
f(x)
1+k−1 . Thus ||fk −f|| <
r
1+k where
||h|| ≡max {|h (x)| : x ∈Br} .
Using the Weierstrass approximation theorem, there exists a polynomial gk such
that ||gk −fk|| <
r
k+1. Then if x ∈Br, it follows
|gk (x)|
≤
|gk (x) −fk (x)| + |fk (x)|
<
r
1 + k +
kr
1 + k = r
and so gk maps Br to Br. By Lemma 10.50 each of these gk has a ﬁxed point, xk
such that gk (xk) = xk. The sequence of points, {xk} is contained in the compact
set, Br and so there exists a convergent subsequence still denoted by {xk} which
converges to a point, x ∈Br. Then
|f (x) −x|
≤
|f (x) −fk (x)| + |fk (x) −fk (xk)| +
¯¯¯¯¯¯
fk (xk) −
=xk
z }| {
gk (xk)
¯¯¯¯¯¯
+ |xk −x|
≤
r
1 + k + |f (x) −f (xk)| +
r
1 + k + |xk −x| .
Now let k →∞in the right side to conclude f (x) = x. This proves the theorem.
It is not surprising that the ball does not need to be centered at 0.
Corollary 10.52 Let f : B (a, r) →B (a, r) be continuous. Then there exists x ∈
B (a, r) such that f (x) = x.
Proof: Let g : Br →Br be deﬁned by g (y) ≡f (y + a) −a. Then g is a
continuous map from Br to Br. Therefore, there exists y ∈Br such that g (y) = y.
Therefore, f (y + a) −a = y and so letting x = y + a, f also has a ﬁxed point as
claimed.
10.11
The Brouwer Fixed Point Theorem Another
Proof
This proof is also based on Lemma 10.49. I found this proof of the Brouwer ﬁxed
point theorem or one close to it in Evans [21]. It is even shorter than the proof just
presented. I think it might be easier to remember also. It is also based on Lemma
10.49 which is stated next for convenience.
Lemma 10.53 Let g : U →Rn be C2 where U is an open subset of Rn. Then
n
X
j=1
cof (Dg)ij,j = 0,
where here (Dg)ij ≡gi,j ≡∂gi
∂xj . Also, cof (Dg)ij = ∂det(Dg)
∂gi,j
.

10.11.
THE BROUWER FIXED POINT THEOREM ANOTHER PROOF
299
Deﬁnition 10.54 Let h be a function deﬁned on an open set, U ⊆Rn. Then
h ∈Ck ¡
U
¢
if there exists a function g deﬁned on an open set, W containng U such
that g = h on U and g is Ck (W) .
Lemma 10.55 There does not exist h ∈C2 ³
B (0, R)
´
such that h :B (0, R) →
∂B (0, R) which also has the property that h (x) = x for all x ∈∂B (0, R) . Such a
function is called a retraction.
Proof: Suppose such an h exists. Let λ ∈[0, 1] and let pλ (x) ≡x+λ (h (x) −x) .
This function, pλ is a homotopy of the identity map and the retraction, h. Let
I (λ) ≡
Z
B(0,R)
det (Dpλ (x)) dx.
Then using the dominated convergence theorem,
I′ (λ)
=
Z
B(0,R)
X
i.j
∂det (Dpλ (x))
∂pλi,j
∂pλij (x)
∂λ
=
Z
B(0,R)
X
i
X
j
∂det (Dpλ (x))
∂pλi,j
(hi (x) −xi),j dx
=
Z
B(0,R)
X
i
X
j
cof (Dpλ (x))ij (hi (x) −xi),j dx
Now by assumption, hi (x) = xi on ∂B (0, R) and so one can integrate by parts and
write
I′ (λ) = −
X
i
Z
B(0,R)
X
j
cof (Dpλ (x))ij,j (hi (x) −xi) dx = 0.
Therefore, I (λ) equals a constant. However,
I (0) = mn (B (0, R)) > 0
but
I (1) =
Z
B(0,1)
det (Dh (x)) dmn =
Z
∂B(0,1)
# (y) dmn = 0
because from polar coordinates or other elementary reasoning, mn (∂B (0, 1)) = 0.
This proves the lemma.
The following is the Brouwer ﬁxed point theorem for C2 maps.
Lemma 10.56 If h ∈C2 ³
B (0, R)
´
and h : B (0, R) →B (0, R), then h has a
ﬁxed point, x such that h (x) = x.
Proof: Suppose the lemma is not true. Then for all x, |x −h (x)| ̸= 0. Then
deﬁne
g (x) = h (x) + x −h (x)
|x −h (x)|t (x)

300
LEBESGUE MEASURE
where t (x) is nonnegative and is chosen such that g (x) ∈∂B (0, R) . This mapping
is illustrated in the following picture.
tf(x)
t
x
¡
¡
¡
¡
t
g(x)
If x →t (x) is C2 near B (0, R), it will follow g is a C2 retraction onto ∂B (0, R)
contrary to Lemma 10.55. Thus t (x) is the nonnegative solution to
H (x, t) = |h (x)|2 + 2
µ
h (x) , x −h (x)
|x −h (x)|
¶
t + t2 = R2
(10.30)
Then
Ht (x, t) = 2
µ
h (x) , x −h (x)
|x −h (x)|
¶
+ 2t.
If this is nonzero for all x near B (0, R), it follows from the implicit function theorem
that t is a C2 function of x. Then from 10.30
2t
=
−2
µ
h (x) , x −h (x)
|x −h (x)|
¶
±
s
4
µ
h (x) , x −h (x)
|x −h (x)|
¶2
−4
³
|h (x)|2 −R2
´
and so
Ht (x, t)
=
2t + 2
µ
h (x) , x −h (x)
|x −h (x)|
¶
=
±
s
4
³
R2 −|h (x)|2´
+ 4
µ
h (x) , x −h (x)
|x −h (x)|
¶2
If |h (x)| < R, this is nonzero. If |h (x)| = R, then it is still nonzero unless
(h (x) , x −h (x)) = 0.
But this cannot happen because the angle between h (x) and x −h (x) cannot be
π/2. Alternatively, if the above equals zero, you would need
(h (x) , x) = |h (x)|2 = R2
which cannot happen unless x = h (x) which is assumed not to happen. Therefore,
x →t (x) is C2 near B (0, R) and so g (x) given above contradicts Lemma 10.55.
This proves the lemma.
Now it is easy to prove the Brouwer ﬁxed point theorem.

10.11.
THE BROUWER FIXED POINT THEOREM ANOTHER PROOF
301
Theorem 10.57 Let f : B (0, R) →B (0, R) be continuous. Then f has a ﬁxed
point.
Proof: If this is not so, there exists ε > 0 such that for all x ∈B (0, R),
|x −f (x)| > ε.
By the Weierstrass approximation theorem, there exists h, a polynomial such that
max
n
|h (x) −f (x)| : x ∈B (0, R)
o
< ε
2.
Then for all x ∈B (0, R),
|x −h (x)| ≥|x −f (x)| −|h (x) −f (x)| > ε −ε
2 = ε
2
contradicting Lemma 10.56. This proves the theorem.

302
LEBESGUE MEASURE

Some Extension Theorems
11.1
Caratheodory Extension Theorem
The Caratheodory extension theorem is a fundamental result which makes possible
the consideration of measures on inﬁnite products among other things. The idea is
that if a ﬁnite measure deﬁned only on an algebra is trying to be a measure, then
in fact it can be extended to a measure.
Deﬁnition 11.1 Let E be an algebra of sets of Ωand let µ0 be a ﬁnite measure on
E. This means µ0 is ﬁnitely additive and if Ei, E are sets of E with the Ei disjoint
and
E = ∪∞
i=1Ei,
then
µ0 (E) =
∞
X
i=1
µ (Ei)
while µ0 (Ω) < ∞.
In this deﬁnition, µ0 is trying to be a measure and acts like one whenever pos-
sible. Under these conditions, µ0 can be extended uniquely to a complete measure,
µ, deﬁned on a σ algebra of sets containing E such that µ agrees with µ0 on E. The
following is the main result.
Theorem 11.2 Let µ0 be a measure on an algebra of sets, E, which satisﬁes
µ0 (Ω) < ∞. Then there exists a complete measure space (Ω, S, µ) such that
µ (E) = µ0 (E)
for all E ∈E. Also if ν is any such measure which agrees with µ0 on E, then ν = µ
on σ (E), the σ algebra generated by E.
Proof: Deﬁne an outer measure as follows.
µ (S) ≡inf
( ∞
X
i=1
µ0 (Ei) : S ⊆∪∞
i=1Ei, Ei ∈E
)
303

304
SOME EXTENSION THEOREMS
Claim 1: µ is an outer measure.
Proof of Claim 1: Let S ⊆∪∞
i=1Si and let Si ⊆∪∞
j=1Eij, where
µ (Si) + ε
2i ≥
∞
X
j=1
µ (Eij) .
Then
µ (S) ≤
X
i
X
j
µ (Eij) =
X
i
³
µ (Si) + ε
2i
´
=
X
i
µ (Si) + ε.
Since ε is arbitrary, this shows µ is an outer measure as claimed.
By the Caratheodory procedure, there exists a unique σ algebra, S, consisting
of the µ measurable sets such that
(Ω, S, µ)
is a complete measure space. It remains to show µ extends µ0.
Claim 2: If S is the σ algebra of µ measurable sets, S ⊇E and µ = µ0 on E.
Proof of Claim 2:
First observe that if A ∈E, then µ (A) ≤µ0 (A) by
deﬁnition. Letting
µ (A) + ε >
∞
X
i=1
µ0 (Ei) , ∪∞
i=1Ei⊇A, Ei ∈E,
it follows
µ (A) + ε >
∞
X
i=1
µ0 (Ei ∩A) ≥µ0 (A)
since A = ∪∞
i=1Ei ∩A. Therefore, µ = µ0 on E.
Consider the assertion that E ⊆S. Let A ∈E and let S ⊆Ωbe any set. There
exist sets {Ei} ⊆E such that ∪∞
i=1Ei ⊇S but
µ (S) + ε >
∞
X
i=1
µ (Ei) .
Then
µ (S) ≤µ (S ∩A) + µ (S \ A)
≤µ (∪∞
i=1Ei \ A) + µ (∪∞
i=1 (Ei ∩A))
≤
∞
X
i=1
µ (Ei\A) +
∞
X
i=1
µ (Ei ∩A) =
∞
X
i=1
µ (Ei) < µ (S) + ε.
Since ε is arbitrary, this shows A ∈S.
This has proved the existence part of the theorem. To verify uniqueness, Let
M ≡{E ∈σ (E) : µ (E) = ν (E)} .
Then M is given to contain E and is obviously a monotone class. Therefore by
Theorem 9.57 on monotone classes, M = σ (E) and this proves the lemma.
The following lemma is also very signiﬁcant.

11.2.
THE TYCHONOFF THEOREM
305
Lemma 11.3 Let M be a metric space with the closed balls compact and suppose
µ is a measure deﬁned on the Borel sets of M which is ﬁnite on compact sets.
Then there exists a unique Radon measure, µ which equals µ on the Borel sets. In
particular µ must be both inner and outer regular on all Borel sets.
Proof: Deﬁne a positive linear functional, Λ (f) =
R
fdµ. Let µ be the Radon
measure which comes from the Riesz representation theorem for positive linear
functionals. Thus for all f continuous,
Z
fdµ =
Z
fdµ.
If V is an open set, let {fn} be a sequence of continuous functions which is increasing
and converges to XV pointwise. Then applying the monotone convergence theorem,
Z
XV dµ = µ (V ) =
Z
XV dµ = µ (V )
and so the two measures coincide on all open sets. Every compact set is a countable
intersection of open sets and so the two measures coincide on all compact sets. Now
let B (a, n) be a ball of radius n and let E be a Borel set contained in this ball.
Then by regularity of µ there exist sets F, G such that G is a countable intersection
of open sets and F is a countable union of compact sets such that F ⊆E ⊆G and
µ (G \ F) = 0. Now µ (G) = µ (G) and µ (F) = µ (F) . Thus
µ (G \ F) + µ (F)
=
µ (G)
=
µ (G) = µ (G \ F) + µ (F)
and so µ (G \ F) = µ (G \ F) . It follows
µ (E) = µ (F) = µ (F) = µ (G) = µ (E) .
If E is an arbitrary Borel set, then
µ (E ∩B (a, n)) = µ (E ∩B (a, n))
and letting n →∞, this yields µ (E) = µ (E) .
11.2
The TychonoﬀTheorem
Sometimes it is necessary to consider inﬁnite Cartesian products of topological
spaces. When you have ﬁnitely many topological spaces in the product and each is
compact, it can be shown that the Cartesian product is compact with the product
topology. It turns out that the same thing holds for inﬁnite products but you have
to be careful how you deﬁne the topology. The ﬁrst thing likely to come to mind
by analogy with ﬁnite products is not the right way to do it.
First recall the Hausdorﬀmaximal principle.

306
SOME EXTENSION THEOREMS
Theorem 11.4 (Hausdorﬀmaximal principle) Let F be a nonempty partially or-
dered set. Then there exists a maximal chain.
The main tool in the study of products of compact topological spaces is the
Alexander subbasis theorem which is presented next. Recall a set is compact if
every basic open cover admits a ﬁnite subcover. This was pretty easy to prove.
However, there is a much smaller set of open sets called a subbasis which has this
property. The proof of this result is much harder.
Deﬁnition 11.5 S ⊆τ is called a subbasis for the topology τ if the set B of ﬁnite
intersections of sets of S is a basis for the topology, τ.
Theorem 11.6 Let (X, τ) be a topological space and let S ⊆τ be a subbasis for
τ. Then if H ⊆X, H is compact if and only if every open cover of H consisting
entirely of sets of S admits a ﬁnite subcover.
Proof: The only if part is obvious because the subasic sets are themselves open.
By Lemma 6.56 on Page 6.56, if every basic open cover admits a ﬁnite subcover
then the set in question is compact. Suppose then that H is a subset of X having
the property that subbasic open covers admit ﬁnite subcovers.
Is H compact?
Assume this is not so. Then what was just observed about basic covers implies
there exists a basic open cover of H, O, which admits no ﬁnite subcover. Let F be
deﬁned as
{O : O is a basic open cover of H which admits no ﬁnite subcover}.
The assumption is that F is nonempty. Partially order F by set inclusion and use
the Hausdorﬀmaximal principle to obtain a maximal chain, C, of such open covers
and let
D = ∪C.
If D admits a ﬁnite subcover, then since C is a chain and the ﬁnite subcover has only
ﬁnitely many sets, some element of C would also admit a ﬁnite subcover, contrary
to the deﬁnition of F. Therefore, D admits no ﬁnite subcover. If D′ ⫌D and D′
is a basic open cover of H, then D′ has a ﬁnite subcover of H since otherwise, C
would fail to be a maximal chain, being properly contained in C∪{D′}. Every set
of D is of the form
U = ∩m
i=1Bi, Bi ∈S
because they are all basic open sets. If it is the case that for all U ∈D one of the
Bi is found in D, then replace each such U with the subbasic set from D containing
it. But then this would be a subbasic open cover of H which by assumption would
admit a ﬁnite subcover contrary to the properties of D. Therefore, one of the sets
of D, denoted by U, has the property that
U = ∩m
i=1Bi, Bi ∈S

11.2.
THE TYCHONOFF THEOREM
307
and no Bi is in D. Thus D ∪{Bi} admits a ﬁnite subcover, for each of the above
Bi because it is strictly larger than D. Let this ﬁnite subcover corresponding to Bi
be denoted by
V i
1 , · · ·, V i
mi, Bi
Consider
{U, V i
j , j = 1, · · ·, mi, i = 1, · · ·, m}.
If p ∈H \ ∪{V i
j }, then p ∈Bi for each i and so p ∈U. This is therefore a ﬁnite
subcover of D contradicting the properties of D. Therefore, F must be empty and
by Lemma 6.56, this proves the theorem.
Let I be a set and suppose for each i ∈I, (Xi, τ i) is a nonempty topological
space. The Cartesian product of the Xi, denoted by Q
i∈I Xi, consists of the set
of all choice functions deﬁned on I which select a single element of each Xi. Thus
f ∈Q
i∈I Xi means for every i ∈I, f (i) ∈Xi. The axiom of choice says Q
i∈I Xi
is nonempty. Let
Pj (A) =
Y
i∈I
Bi
where Bi = Xi if i ̸= j and Bj = A. A subbasis for a topology on the product
space consists of all sets Pj (A) where A ∈τ j. (These sets have an open set from
the topology of Xj in the jth slot and the whole space in the other slots.) Thus a
basis consists of ﬁnite intersections of these sets. Note that the intersection of two
of these basic sets is another basic set and their union yields Q
i∈I Xi. Therefore,
they satisfy the condition needed for a collection of sets to serve as a basis for a
topology. This topology is called the product topology and is denoted by Q τ i.
It is tempting to deﬁne a basis for a topology to be sets of the form Q
i∈I Ai
where Ai is open in Xi. This is not the same thing at all. Note that the basis just
described has at most ﬁnitely many slots ﬁlled with an open set which is not the
whole space. The thing just mentioned in which every slot may be ﬁlled by a proper
open set is called the box topology and there exist people who are interested in it.
The Alexander subbasis theorem is used to prove the Tychonoﬀtheorem which
says that if each Xi is a compact topological space, then in the product topology,
Q
i∈I Xi is also compact.
Theorem 11.7 If (Xiτ i) is compact, then so is (Q
i∈I Xi, Q τ i).
Proof: By the Alexander subbasis theorem, the theorem will be proved if every
subbasic open cover admits a ﬁnite subcover. Therefore, let O be a subbasic open
cover of Q
i∈I Xi. Let
Oj = {Q ∈O : Q = Pj (A) for some A ∈τ j}.
Thus Oj consists of those sets of O which have a possibly proper subset of Xi only
in the slot i = j. Let
πjOj = {A : Pj (A) ∈Oj}.
Thus πjOj picks out those proper open subsets of Xj which occur in Oj.

308
SOME EXTENSION THEOREMS
If no πjOj covers Xj, then by the axiom of choice, there exists
f ∈
Y
i∈I
Xi \ ∪πiOi
Therefore, f (j) /∈∪πjOj for each j ∈I.
Now f is a point of Q
i∈I Xi and so
f ∈Pk (A) ∈O for some k. However, this is a contradiction it was shown that f (k)
is not an element of A. (A is one of the sets whose union makes up ∪πkOk.) This
contradiction shows that for some j, πjOj covers Xj. Thus
Xj = ∪πjOj
and so by compactness of Xj, there exist A1, · · ·, Am, sets in τ j such that Xj ⊆
∪m
i=1Ai and Pj (Ai) ∈O. Therefore, {Pj (Ai)}m
i=1 covers Q
i∈I Xi. By the Alexander
subbasis theorem this proves Q
i∈I Xi is compact.
11.3
Kolmogorov Extension Theorem
Here Mt will be a metric space in which the closed balls are compact. (The case
of interest is Rn but it is easier to write M.) Thus it is also a locally compact
Hausdorﬀspace. I will denote a totally ordered index set, and the interest will
be in building a measure on the product space, Q
t∈I Mt. The example of interest
for I is [0, ∞) but all that I will use is that I is totally ordered. By well ordering
principle, you can always put an order on the index set. Also, I will denote M ′
t as
the one point compactiﬁcation of Mt.
Let J ⊆I. Then if E ≡Q
t∈I Et, deﬁne
γJE ≡
Y
t∈I
Ft
where
Ft =
½
Et if t ∈J
M ′
t if t /∈J
Thus γJE leaves alone Et for t ∈J and changes the other Et into M ′
t. If γJE = E,
then this means Et = M ′
t for all t /∈J. Also deﬁne for J a subset of I,
πJx ≡
Y
t∈J
xt
so πJ is a continuous mapping from Q
t∈I M ′
t to Q
t∈J M ′
t.
πJE ≡
Y
t∈J
Et.

11.3.
KOLMOGOROV EXTENSION THEOREM
309
Deﬁnition 11.8 Now deﬁne for J a ﬁnite subset of I,
RJ
≡
(
E =
Y
t∈I
Et : γJE = E, Et a Borel set in M ′
t
)
R
≡
∪{RJ : J ⊆I, and J ﬁnite}
Thus R consists of those sets of Q
t∈I M ′
t for which every slot is ﬁlled with M ′
except for a ﬁnite set, J ⊆I where the slots are ﬁlled with a Borel set, Et. Deﬁne
E as ﬁnite disjoint unions of sets of R.
In fact E is an algebra of sets.
Lemma 11.9 The sets, E
deﬁned above form an algebra of sets of Q
t∈I M ′
t.
Proof: Clearly ∅and Q
t∈I M ′
t are both in E. Suppose A, B ∈R. Then for
some ﬁnite set, J,
γJA = A, γJB = B.
Then
γJ (A \ B) = A \ B ∈E,γJ (A ∩B) = A ∩B ∈R.
By Lemma 9.54 on Page 246 this shows E is an algebra.
Here is a lemma which is useful although fussy.
Lemma 11.10 Let J be a ﬁnite subset of I. Then U is a Borel set in Q
t∈J Mt if
and only if there exists a Borel set, U′ in Q
t∈J M ′
t such that U = U′ ∩Q
t∈J Mt.
Proof:
First suppose Borel is replaced with open.
If U is an open set in
Q
t∈J Mt, then it is open in Q
t∈J M ′
t from the deﬁnition of the open sets of Q
t∈J M ′
t
which consist of open sets of Q
t∈J Mt along with complements of compact sets which
have the point ∞added in. Thus you can let U′ = U in this case. Next suppose
U = U′∩Q
t∈J Mt where U′ is open in Q
t∈J M ′
t. I need show U is open in Q
t∈J Mt.
Letting x ∈U, it follows xt ̸= ∞for each t. It follows from U′ open in Q
t∈J M ′
t
that xt ∈V ′
t where V ′
t is open in M ′
t and
x ∈
Y
t∈J
V ′
t ⊆U′
Letting Vt = V ′
t \ {∞} , it follows Vt is open in Mt and
x ∈
Y
t∈J
Vt ⊆U′ ∩
Y
t∈J
Mt.
This shows that U is an open set in Q
t∈J Mt. Now let
G ≡
(
F Borel in
Y
t∈J
M ′
t such that F ∩
Y
t∈J
Mt is Borel in
Y
t∈J
Mt
)

310
SOME EXTENSION THEOREMS
then from what was just shown G contains the open sets. It is also clearly a σ
algebra. Hence G equals the Borel sets of Q
t∈J M ′
t .
It only remains to verify that any Borel set in Q
t∈J Mt is the intersection of a
Borel set of Q
t∈J M ′
t with Q
t∈J Mt. Let
H ≡
(
F Borel in
Y
t∈J
Mt such that F = F′ ∩
Y
t∈J
Mt, F′ Borel in
Y
t∈J
M ′
t
)
From the ﬁrst part of the argument, H contains the open sets.
Now let {Fn}
be a sequence in H. Thus Fn = F′
n ∩Q
t∈J Mt where F′
n is Borel in Q
t∈J M ′
t.
Then ∪nFn = ∪nF′
n ∩Q
t∈J Mt and ∪nF′
n is Borel in Q
t∈J M ′
t. Thus H is closed
under countable intersections.
Next let F ∈H and F = F′ ∩Q
t∈J Mt.
Then
F′C ≡Q
t∈J M ′
t \ F′ is Borel in Q
t∈J M ′
t and
¡Q
t∈J Mt \ F
¢
= F′C ∩Q
t∈J Mt.
Thus H is a σ algebra containing the open sets and so H equals the Borel sets in
Q
t∈J Mt. This proves this wretched little lemma.
With this preparation here is the Kolmogorov extension theorem. In the state-
ment and proof of the theorem, Fi, Gi, and Ei will denote Borel sets. Any list of
indices from I will always be assumed to be taken in order. Thus, if J ⊆I and
J = (t1, · · ·, tn) , it will always be assumed t1 < t2 < · · · < tn.
Theorem 11.11 (Kolmogorov extension theorem) For each ﬁnite set
J = (t1, · · ·, tn) ⊆I,
suppose there exists a Borel probability measure, νJ = νt1···tn deﬁned on the Borel
sets of Q
t∈J Mt such that if
(t1, · · ·, tn) ⊆(s1, · · ·, sp) ,
then
νt1···tn (Ft1 × · · · × Ftn) = νs1···sp
¡
Gs1 × · · · × Gsp
¢
(11.1)
where if si = tj, then Gsi = Ftj and if si is not equal to any of the indices, tk,
then Gsi = Msi. Then there exists a probability space, (Ω, P, F) and measurable
functions, Xt : Ω→Mt for each t ∈I such that for each (t1 · · · tn) ⊆I,
νt1···tn (Ft1 × · · · × Ftn) = P ([Xt1 ∈Ft1] ∩· · · ∩[Xtn ∈Ftn]) .
(11.2)
Proof: First of all, note that for J ﬁnite, Q
t∈J Mt is a metric space in which
the closures of the balls are compact. Therefore, by Lemma 11.3 νt1···tn is both
inner and outer regular. Also, it is convenient to extend each νt1···tn to the Borel
sets of Q
t∈J M ′
t where M ′
t is the one point compactiﬁcation of Mt as follows. For
F a Borel set of Q
t∈J M ′
t,
νt1···tn (F) ≡νt1···tn
Ã
F ∩
Y
t∈J
Mt
!
.

11.3.
KOLMOGOROV EXTENSION THEOREM
311
By Lemma 11.10 this is well deﬁned.
Letting E be the algebra of sets deﬁned in Deﬁnition 11.8 and suppose E = E1 ∪
E2 ∪· · · ∪Em where γJkEk = Ek. Thus E ∈E. Let
¡
tk
1 · · · tk
mk
¢
= Jk. Then letting
J = (s1, · · ·, sp) ⊇∪m
k=1Jk
deﬁne
P0 (E) ≡
m
X
k=1
νs1···sp
³
Gk
s1 × · · · × Gk
sp
´
where Gk
si = Ek
tk
j in case si = tk
j and M ′
si otherwise. By 11.1 this is well deﬁned
and equals
m
X
k=1
νtk
1···tk
mk
³
Ek
tk
1 × · · · × Ek
tk
mk
´
.
P0 is clearly ﬁnitely additive because the νJ are measures and one can pick J as
large as desired. Also, from the deﬁnition,
P0
ÃY
t∈I
M ′
t
!
= νt1
¡
M ′
t1
¢
= 1.
Next I will show P0 is a ﬁnite measure on E. From this it is only a matter of using
the Caratheodory extension theorem.
Claim: If En ↓∅, then P0 (En) ↓0.
Proof of the claim: If not, there exists a sequence such that although En ↓
∅, P0 (En) ↓ε > 0. Since each of the νs1···sm is inner regular, there exists a compact
set, Kn ⊆πJ (En) for suitably large J such that if Kn′ ⊆Q
t∈I M ′
t is deﬁned by
γJ (Kn′) = Kn′ and πJ (Kn′) = Kn and P0 (En \ Kn′) < ε/2n+1. (Less precisely,
you get Kn′ by ﬁlling in all the slots other than in J with the appropriate M ′
t.)
Thus by Tychonoﬀ’s theorem, Kn′ is compact. The interesting thing about these
Kn′ is they have the ﬁnite intersection property. Here is why.
ε
≤
P0
¡
∩m
k=1Kk′¢
+ P0
¡
Em \ ∩m
k=1Kk′¢
≤
P0
¡
∩m
k=1Kk′¢
+ P0
¡
∪m
k=1Ek \ Kk′¢
<
P0
¡
∩m
k=1Kk′¢
+
∞
X
k=1
ε
2k+1 < P0
¡
∩m
k=1Kk′¢
+ ε
and so P0
¡
∩m
k=1Kk′¢
> 0. Now this yields a contradiction because this ﬁnite inter-
section property implies the intersection of all the Kn′ is nonempty contradicting
En ↓∅since each Kn′ is contained in En.
With the claim, it follows P0 is a measure on E. Here is why: If E = ∪∞
k=1Ek
where E, Ek ∈E, then (E \ ∪n
k=1Ek) ↓∅and so
P0 (∪n
k=1Ek) →P0 (E) .
Hence if the Ek are disjoint, P0 (∪n
k=1Ek) = Pn
k=1 P0 (Ek) →P0 (E) .

312
SOME EXTENSION THEOREMS
Now to conclude the proof, apply the Caratheodory extension theorem to obtain
P a probability measure which extends P0 to σ (E) the sigma algebra generated by
E. Let S ≡
©
E ∩Q
t∈I Mt : E ∈σ (E)
ª
. It follows
¡Q
t∈I Mt, S, P
¢
is a probability
measure space with the property that when γJ (E) = E for J = (t1 · · · tn) a ﬁnite
subset of I, P (E) = P0 (E) = νt1···tn (Et1 × · · · × Etn) .
For the last part, let
¡Q
t∈I Mt, S, P
¢
be the probability space and for x ∈
Q
t∈I Mt let Xt (x) = xt, the tth entry of x. (xt = πtx). It follows Xt is measurable
because if U is open in Mt, then X−1
t
(U) has a U in the tth slot and Ms everywhere
else for s ̸= t so this is actually in E. Also, letting (t1 · · · tn) be a ﬁnite subset of I
and Ft1, · · ·, Ftn be Borel sets in Mt1 · · · Mtn respectively,
P ([Xt1 ∈Ft1] ∩[Xt2 ∈Ft2] ∩· · · ∩[Xtn ∈Ftn]) =
P ((Xt1, Xt2, · · ·, Xtn) ∈Ft1 × · · · × Ftn) = P (Ft1 × · · · × Ftn)
= νt1···tn (Ft1 × · · · × Ftn)
This proves the theorem.
As a special case, you can obtain a version of product measure for possibly
inﬁnitely many factors. Suppose in the context of the above theorem that νt is a
probability measure deﬁned on the Borel sets of Mt and let the measures, νt1···tn
be deﬁned on the Borel sets of Qn
i=1 Mti by
νt1···tn (E) ≡(νt1 × · · · × νtn) (E) .
Then these measures satisfy the necessary consistency condition and so the Kol-
mogorov extension theorem given above can be applied to obtain a measure, P
deﬁned on a
¡Q
t∈I Mt, F
¢
and measurable functions Xs : Q
t∈I Mt →Ms such that
for Fti a Borel set in Mti,
P
Ã
(Xt1, · · ·, Xtn) ∈
n
Y
i=1
Fti
!
= νt1···tn (Ft1 × · · · × Ftn)
= νt1 (Ft1) · · · νtn (Ftn) .
(11.3)
In particular, P (Xt ∈Ft) = νt (Ft) . Then P in the resulting probability space,
ÃY
t∈I
Mt, F, P
!
will be denoted as Q
t∈I νt. This proves the following theorem which describes an
inﬁnite product measure.
Theorem 11.12 Let Mt for t ∈I be given as in Theorem 11.11 and let νt be a
Borel probability measure deﬁned on the Borel sets of Mt. Then there exists a mea-
sure, P and a σ algebra F ⊆P (Q
t Mt) containing the algebra deﬁned in Deﬁnition
11.8 such that (Q
t Mt, F, P) is a probability space satisfying 11.3 whenever each
Fti is a Borel set of Mti. This probability measure is sometimes denoted as Q
t νt.

11.4.
EXERCISES
313
11.4
Exercises
1. Let (X, S, µ) and (Y, F, λ) be two ﬁnite measure spaces. A subset of X × Y
is called a measurable rectangle if it is of the form A × B where A ∈S and
B ∈F. A subset of X × Y is called an elementary set if it is a ﬁnite disjoint
union of measurable rectangles. Denote this set of functions by E. Show that
E is an algebra of sets.
2. ↑For A ∈σ (E) , the smallest σ algebra containing E, show that x →XA (x, y)
is µ measurable and that
y →
Z
XA (x, y) dµ
is λ measurable. Show similar assertions hold for y →XA (x, y) and
x →
Z
XA (x, y) dλ
and that
Z Z
XA (x, y) dµdλ =
Z Z
XA (x, y) dλdµ.
(11.4)
Hint: Let M ≡{A ∈σ (E) : 11.4 holds} along with all relevant measurability
assertions. Show M contains E and is a monotone class. Then apply the
Theorem 9.57.
3. ↑For A ∈σ (E) deﬁne (µ × λ) (A) ≡
R R
XA (x, y) dµdλ. Show that (µ × λ) is
a measur on σ (E) and that whenever f ≥0 is measurable with respect to
σ (E) ,
Z
X×Y
fd (µ × λ) =
Z Z
f (x, y) dµdλ =
Z Z
f (x, y) dλdµ.
This is a common approach to Fubini’s theorem.
4. ↑Generalize the above version of Fubini’s theorem to the case where the mea-
sure spaces are only σ ﬁnite.
5. ↑Suppose now that µ and λ are both complete σ ﬁnite measures. Let (µ × λ)
denote the completion of this measure.
Let the larger measure space be
³
X × Y, σ (E), (µ × λ)
´
. Thus if E ∈σ (E), it follows there exists a set A ∈
σ (E) such that E ∪N = A where (µ × λ) (N) = 0. Now argue that for λ
a.e. y, x →XN (x, y) is measurable because it is equal to zero µ a.e. and µ is
complete. Therefore,
Z Z
XN (x, y) dµdλ

314
SOME EXTENSION THEOREMS
makes sense and equals zero. Use to argue that for λ a.e. y, x →XE (x, y)
is µ measurable and equals
R
XA (x, y) dµ. Then by completeness of λ, y →
R
XE (x, y) dµ is λ measurable and
Z Z
XA (x, y) dµdλ =
Z Z
XE (x, y) dµdλ = (µ × λ) (E) .
Similarly
Z Z
XE (x, y) dλdµ = (µ × λ) (E) .
Use this to give a generalization of the above Fubini theorem. Prove that if f
is measurable with respect to the σ algebra, σ (E) and nonnegative, then
Z
X×Y
fd(µ × λ) =
Z Z
f (x, y) dµdλ =
Z Z
f (x, y) dλdµ
where the iterated integrals make sense.

The Lp Spaces
12.1
Basic Inequalities And Properties
One of the main applications of the Lebesgue integral is to the study of various
sorts of functions space. These are vector spaces whose elements are functions of
various types. One of the most important examples of a function space is the space
of measurable functions whose absolute values are pth power integrable where p ≥1.
These spaces, referred to as Lp spaces, are very useful in applications. In the chapter
(Ω, S, µ) will be a measure space.
Deﬁnition 12.1 Let 1 ≤p < ∞. Deﬁne
Lp(Ω) ≡{f : f is measurable and
Z
Ω
|f(ω)|pdµ < ∞}
In terms of the distribution function,
Lp (Ω) = {f : f is measurable and
Z ∞
0
ptp−1µ ([|f| > t]) dt < ∞}
For each p > 1 deﬁne q by
1
p + 1
q = 1.
Often one uses p′ instead of q in this context.
Lp (Ω) is a vector space and has a norm. This is similar to the situation for Rn
but the proof requires the following fundamental inequality. .
Theorem 12.2 (Holder’s inequality) If f and g are measurable functions, then if
p > 1,
Z
|f| |g| dµ ≤
µZ
|f|pdµ
¶ 1
p µZ
|g|qdµ
¶ 1
q
.
(12.1)
Proof: First here is a proof of Young’s inequality .
Lemma 12.3 If
p > 1, and 0 ≤a, b then ab ≤ap
p + bq
q .
315

316
THE LP SPACES
Proof: Consider the following picture:
b
a
x
t
x = tp−1
t = xq−1
From this picture, the sum of the area between the x axis and the curve added to
the area between the t axis and the curve is at least as large as ab. Using beginning
calculus, this is equivalent to the following inequality.
ab ≤
Z a
0
tp−1dt +
Z b
0
xq−1dx = ap
p + bq
q .
The above picture represents the situation which occurs when p > 2 because the
graph of the function is concave up. If 2 ≥p > 1 the graph would be concave down
or a straight line. You should verify that the same argument holds in these cases
just as well. In fact, the only thing which matters in the above inequality is that
the function x = tp−1 be strictly increasing.
Note equality occurs when ap = bq.
Here is an alternate proof.
Lemma 12.4 For a, b ≥0,
ab ≤ap
p + bq
q
and equality occurs when if and only if ap = bq.
Proof: If b = 0, the inequality is obvious. Fix b > 0 and consider
f (a) ≡ap
p + bq
q −ab.
Then f ′ (a) = ap−1 −b. This is negative when a < b1/(p−1) and is positive when
a > b1/(p−1). Therefore, f has a minimum when a = b1/(p−1). In other words, when
ap = bp/(p−1) = bq since 1/p + 1/q = 1. Thus the minimum value of f is
bq
p + bq
q −b1/(p−1)b = bq −bq = 0.
It follows f ≥0 and this yields the desired inequality.
Proof of Holder’s inequality: If either
R
|f|pdµ or
R
|g|pdµ equals ∞, the
inequality 12.1 is obviously valid because ∞≥anything.
If either
R
|f|pdµ or

12.1.
BASIC INEQUALITIES AND PROPERTIES
317
R
|g|pdµ equals 0, then f = 0 a.e. or that g = 0 a.e. and so in this case the left side
of the inequality equals 0 and so the inequality is therefore true. Therefore assume
both
R
|f|pdµ and
R
|g|pdµ are less than ∞and not equal to 0. Let
µZ
|f|pdµ
¶1/p
= I (f)
and let
¡R
|g|pdµ
¢1/q = I (g). Then using the lemma,
Z
|f|
I (f)
|g|
I (g) dµ ≤1
p
Z
|f|p
I (f)p dµ + 1
q
Z
|g|q
I (g)q dµ = 1.
Hence,
Z
|f| |g| dµ ≤I (f) I (g) =
µZ
|f|pdµ
¶1/p µZ
|g|qdµ
¶1/q
.
This proves Holder’s inequality.
The following lemma will be needed.
Lemma 12.5 Suppose x, y ∈C. Then
|x + y|p ≤2p−1 (|x|p + |y|p) .
Proof: The function f (t) = tp is concave up for t ≥0 because p > 1. Therefore,
the secant line joining two points on the graph of this function must lie above the
graph of the function. This is illustrated in the following picture.
¡
¡
¡
¡
¡¡
|x|
|y|
m
(|x| + |y|)/2 = m
Now as shown above,
µ|x| + |y|
2
¶p
≤|x|p + |y|p
2
which implies
|x + y|p ≤(|x| + |y|)p ≤2p−1 (|x|p + |y|p)
and this proves the lemma.
Note that if y = φ (x) is any function for which the graph of φ is concave up,
you could get a similar inequality by the same argument.

318
THE LP SPACES
Corollary 12.6 (Minkowski inequality) Let 1 ≤p < ∞. Then
µZ
|f + g|p dµ
¶1/p
≤
µZ
|f|p dµ
¶1/p
+
µZ
|g|p dµ
¶1/p
.
(12.2)
Proof: If p = 1, this is obvious because it is just the triangle inequality. Let
p > 1. Without loss of generality, assume
µZ
|f|p dµ
¶1/p
+
µZ
|g|p dµ
¶1/p
< ∞
and
¡R
|f + g|p dµ
¢1/p ̸= 0 or there is nothing to prove. Therefore, using the above
lemma,
Z
|f + g|pdµ ≤2p−1
µZ
|f|p + |g|pdµ
¶
< ∞.
Now |f (ω) + g (ω)|p ≤|f (ω) + g (ω)|p−1 (|f (ω)| + |g (ω)|). Also, it follows from the
deﬁnition of p and q that p −1 = p
q . Therefore, using this and Holder’s inequality,
Z
|f + g|pdµ ≤
Z
|f + g|p−1|f|dµ +
Z
|f + g|p−1|g|dµ
=
Z
|f + g|
p
q |f|dµ +
Z
|f + g|
p
q |g|dµ
≤
(
Z
|f + g|pdµ)
1
q (
Z
|f|pdµ)
1
p + (
Z
|f + g|pdµ)
1
q (
Z
|g|pdµ)
1
p.
Dividing both sides by (
R
|f + g|pdµ)
1
q yields 12.2. This proves the corollary.
The following follows immediately from the above.
Corollary 12.7 Let fi ∈Lp (Ω) for i = 1, 2, · · ·, n. Then
ÃZ ¯¯¯¯¯
n
X
i=1
fi
¯¯¯¯¯
p
dµ
!1/p
≤
n
X
i=1
µZ
|fi|p
¶1/p
.
This shows that if f, g ∈Lp, then f + g ∈Lp. Also, it is clear that if a is a
constant and f ∈Lp, then af ∈Lp because
Z
|af|p dµ = |a|p
Z
|f|p dµ < ∞.
Thus Lp is a vector space and
a.)
¡R
|f|p dµ
¢1/p ≥0,
¡R
|f|p dµ
¢1/p = 0 if and only if f = 0 a.e.

12.1.
BASIC INEQUALITIES AND PROPERTIES
319
b.)
¡R
|af|p dµ
¢1/p = |a|
¡R
|f|p dµ
¢1/p if a is a scalar.
c.)
¡R
|f + g|p dµ
¢1/p ≤
¡R
|f|p dµ
¢1/p +
¡R
|g|p dµ
¢1/p.
f →
¡R
|f|p dµ
¢1/p would deﬁne a norm if
¡R
|f|p dµ
¢1/p = 0 implied f = 0.
Unfortunately, this is not so because if f = 0 a.e.
but is nonzero on a set of
measure zero,
¡R
|f|p dµ
¢1/p = 0 and this is not allowed. However, all the other
properties of a norm are available and so a little thing like a set of measure zero
will not prevent the consideration of Lp as a normed vector space if two functions
in Lp which diﬀer only on a set of measure zero are considered the same. That is,
an element of Lp is really an equivalence class of functions where two functions are
equivalent if they are equal a.e. With this convention, here is a deﬁnition.
Deﬁnition 12.8 Let f ∈Lp (Ω). Deﬁne
||f||p ≡||f||Lp ≡
µZ
|f|p dµ
¶1/p
.
Then with this deﬁnition and using the convention that elements in Lp are
considered to be the same if they diﬀer only on a set of measure zero, || ||p is a
norm on Lp (Ω) because if ||f||p = 0 then f = 0 a.e. and so f is considered to be
the zero function because it diﬀers from 0 only on a set of measure zero.
The following is an important deﬁnition.
Deﬁnition 12.9 A complete normed linear space is called a Banach1 space.
Lp is a Banach space. This is the next big theorem.
Theorem 12.10 The following hold for Lp(Ω)
a.) Lp(Ω) is complete.
b.) If {fn} is a Cauchy sequence in Lp(Ω), then there exists f ∈Lp (Ω) and a
subsequence which converges a.e. to f ∈Lp(Ω), and ||fn −f||p →0.
Proof: Let {fn} be a Cauchy sequence in Lp(Ω). This means that for every
ε > 0 there exists N such that if n, m ≥N, then ||fn −fm||p < ε. Now select a
subsequence as follows. Let n1 be such that ||fn −fm||p < 2−1 whenever n, m ≥n1.
1These spaces are named after Stefan Banach, 1892-1945. Banach spaces are the basic item of
study in the subject of functional analysis and will be considered later in this book.
There is a recent biography of Banach, R. Katu˙za, The Life of Stefan Banach, (A. Kostant and
W. Woyczy´nski, translators and editors) Birkhauser, Boston (1996). More information on Banach
can also be found in a recent short article written by Douglas Henderson who is in the department
of chemistry and biochemistry at BYU.
Banach was born in Austria, worked in Poland and died in the Ukraine but never moved. This
is because borders kept changing. There is a rumor that he died in a German concentration camp
which is apparently not true. It seems he died after the war of lung cancer.
He was an interesting character. He hated taking examinations so much that he did not receive
his undergraduate university degree. Nevertheless, he did become a professor of mathematics due
to his important research. He and some friends would meet in a cafe called the Scottish cafe where
they wrote on the marble table tops until Banach’s wife supplied them with a notebook which
became the ”Scotish notebook” and was eventually published.

320
THE LP SPACES
Let n2 be such that n2 > n1 and ||fn−fm||p < 2−2 whenever n, m ≥n2. If n1, ···, nk
have been chosen, let nk+1 > nk and whenever n, m ≥nk+1, ||fn −fm||p < 2−(k+1).
The subsequence just mentioned is {fnk}. Thus, ||fnk −fnk+1||p < 2−k. Let
gk+1 = fnk+1 −fnk.
Then by the corollary to Minkowski’s inequality,
∞>
∞
X
k=1
||gk+1||p ≥
m
X
k=1
||gk+1||p ≥
¯¯¯¯¯
¯¯¯¯¯
m
X
k=1
|gk+1|
¯¯¯¯¯
¯¯¯¯¯
p
for all m. It follows that
Z Ã m
X
k=1
|gk+1|
!p
dµ ≤
Ã ∞
X
k=1
||gk+1||p
!p
< ∞
(12.3)
for all m and so the monotone convergence theorem implies that the sum up to m
in 12.3 can be replaced by a sum up to ∞. Thus,
Z Ã ∞
X
k=1
|gk+1|
!p
dµ < ∞
which requires
∞
X
k=1
|gk+1(x)| < ∞a.e. x.
Therefore, P∞
k=1 gk+1(x) converges for a.e. x because the functions have values in
a complete space, C, and this shows the partial sums form a Cauchy sequence. Now
let x be such that this sum is ﬁnite. Then deﬁne
f(x) ≡fn1(x) +
∞
X
k=1
gk+1(x)= lim
m→∞fnm (x)
since Pm
k=1 gk+1(x) = fnm+1(x) −fn1(x). Therefore there exists a set, E having
measure zero such that
lim
k→∞fnk(x) = f(x)
for all x /∈E. Redeﬁne fnk to equal 0 on E and let f(x) = 0 for x ∈E. It then
follows that limk→∞fnk(x) = f(x) for all x. By Fatou’s lemma, and the Minkowski
inequality,
||f −fnk||p =
µZ
|f −fnk|p dµ
¶1/p
≤
lim inf
m→∞
µZ
|fnm −fnk|p dµ
¶1/p
= lim inf
m→∞||fnm −fnk||p ≤

12.1.
BASIC INEQUALITIES AND PROPERTIES
321
lim inf
m→∞
m−1
X
j=k
¯¯¯¯fnj+1 −fnj
¯¯¯¯
p ≤
∞
X
i=k
¯¯¯¯fni+1 −fni
¯¯¯¯
p ≤2−(k−1).
(12.4)
Therefore, f ∈Lp(Ω) because
||f||p ≤||f −fnk||p + ||fnk||p < ∞,
and limk→∞||fnk −f||p = 0. This proves b.).
This has shown fnk converges to f in Lp (Ω). It follows the original Cauchy
sequence also converges to f in Lp (Ω). This is a general fact that if a subsequence
of a Cauchy sequence converges, then so does the original Cauchy sequence. You
should give a proof of this. This proves the theorem.
In working with the Lp spaces, the following inequality also known as Minkowski’s
inequality is very useful. It is similar to the Minkowski inequality for sums. To see
this, replace the integral,
R
X with a ﬁnite summation sign and you will see the usual
Minkowski inequality or rather the version of it given in Corollary 12.7.
To prove this theorem ﬁrst consider a special case of it in which technical con-
siderations which shed no light on the proof are excluded.
Lemma 12.11 Let (X, S, µ) and (Y, F, λ) be ﬁnite complete measure spaces and
let f be µ × λ measurable and uniformly bounded. Then the following inequality is
valid for p ≥1.
Z
X
µZ
Y
|f(x, y)|p dλ
¶ 1
p
dµ ≥
µZ
Y
(
Z
X
|f(x, y)| dµ)pdλ
¶ 1
p
.
(12.5)
Proof: Since f is bounded and µ (X) , λ (X) < ∞,
µZ
Y
(
Z
X
|f(x, y)|dµ)pdλ
¶ 1
p
< ∞.
Let
J(y) =
Z
X
|f(x, y)|dµ.
Note there is no problem in writing this for a.e. y because f is product measurable.
Then by Fubini’s theorem,
Z
Y
µZ
X
|f(x, y)|dµ
¶p
dλ
=
Z
Y
J(y)p−1
Z
X
|f(x, y)|dµ dλ
=
Z
X
Z
Y
J(y)p−1|f(x, y)|dλ dµ

322
THE LP SPACES
Now apply Holder’s inequality in the last integral above and recall p −1 = p
q . This
yields
Z
Y
µZ
X
|f(x, y)|dµ
¶p
dλ
≤
Z
X
µZ
Y
J(y)pdλ
¶ 1
q µZ
Y
|f(x, y)|pdλ
¶ 1
p
dµ
=
µZ
Y
J(y)pdλ
¶ 1
q Z
X
µZ
Y
|f(x, y)|pdλ
¶ 1
p
dµ
=
µZ
Y
(
Z
X
|f(x, y)|dµ)pdλ
¶ 1
q Z
X
µZ
Y
|f(x, y)|pdλ
¶ 1
p
dµ.
(12.6)
Therefore, dividing both sides by the ﬁrst factor in the above expression,
µZ
Y
µZ
X
|f(x, y)|dµ
¶p
dλ
¶ 1
p
≤
Z
X
µZ
Y
|f(x, y)|pdλ
¶ 1
p
dµ.
(12.7)
Note that 12.7 holds even if the ﬁrst factor of 12.6 equals zero. This proves the
lemma.
Now consider the case where f is not assumed to be bounded and where the
measure spaces are σ ﬁnite.
Theorem 12.12 Let (X, S, µ) and (Y, F, λ) be σ-ﬁnite measure spaces and let f
be product measurable. Then the following inequality is valid for p ≥1.
Z
X
µZ
Y
|f(x, y)|p dλ
¶ 1
p
dµ ≥
µZ
Y
(
Z
X
|f(x, y)| dµ)pdλ
¶ 1
p
.
(12.8)
Proof: Since the two measure spaces are σ ﬁnite, there exist measurable sets,
Xm and Yk such that Xm ⊆Xm+1 for all m, Yk ⊆Yk+1 for all k, and µ (Xm) , λ (Yk) <
∞. Now deﬁne
fn (x, y) ≡
½
f (x, y) if |f (x, y)| ≤n
n if |f (x, y)| > n.
Thus fn is uniformly bounded and product measurable. By the above lemma,
Z
Xm
µZ
Yk
|fn(x, y)|p dλ
¶ 1
p
dµ ≥
µZ
Yk
(
Z
Xm
|fn(x, y)| dµ)pdλ
¶ 1
p
.
(12.9)
Now observe that |fn (x, y)| increases in n and the pointwise limit is |f (x, y)|. There-
fore, using the monotone convergence theorem in 12.9 yields the same inequality
with f replacing fn. Next let k →∞and use the monotone convergence theorem
again to replace Yk with Y . Finally let m →∞in what is left to obtain 12.8. This
proves the theorem.

12.2.
DENSITY CONSIDERATIONS
323
Note that the proof of this theorem depends on two manipulations, the inter-
change of the order of integration and Holder’s inequality. Note that there is nothing
to check in the case of double sums. Thus if aij ≥0, it is always the case that

X
j
ÃX
i
aij
!p

1/p
≤
X
i

X
j
ap
ij


1/p
because the integrals in this case are just sums and (i, j) →aij is measurable.
The Lp spaces have many important properties.
12.2
Density Considerations
Theorem 12.13 Let p ≥1 and let (Ω, S, µ) be a measure space. Then the simple
functions are dense in Lp (Ω).
Proof: Recall that a function, f, having values in R can be written in the form
f = f + −f −where
f + = max (0, f) , f −= max (0, −f) .
Therefore, an arbitrary complex valued function, f is of the form
f = Re f + −Re f −+ i
¡
Im f + −Im f −¢
.
If each of these nonnegative functions is approximated by a simple function, it
follows f is also approximated by a simple function. Therefore, there is no loss of
generality in assuming at the outset that f ≥0.
Since f is measurable, Theorem 8.27 implies there is an increasing sequence of
simple functions, {sn}, converging pointwise to f(x). Now
|f(x) −sn(x)| ≤|f(x)|.
By the Dominated Convergence theorem,
0 = lim
n→∞
Z
|f(x) −sn(x)|pdµ.
Thus simple functions are dense in Lp.
Recall that for Ωa topological space, Cc(Ω) is the space of continuous functions
with compact support in Ω. Also recall the following deﬁnition.
Deﬁnition 12.14 Let (Ω, S, µ) be a measure space and suppose (Ω, τ) is also a
topological space. Then (Ω, S, µ) is called a regular measure space if the σ algebra
of Borel sets is contained in S and for all E ∈S,
µ(E) = inf{µ(V ) : V ⊇E and V open}

324
THE LP SPACES
and if µ (E) < ∞,
µ(E) = sup{µ(K) : K ⊆E and K is compact }
and µ (K) < ∞for any compact set, K.
For example Lebesgue measure is an example of such a measure.
Lemma 12.15 Let Ωbe a metric space in which the closed balls are compact and
let K be a compact subset of V , an open set. Then there exists a continuous function
f : Ω→[0, 1] such that f(x) = 1 for all x ∈K and spt(f) is a compact subset of
V . That is, K ≺f ≺V.
Proof: Let K ⊆W ⊆W ⊆V and W is compact.
To obtain this list of
inclusions consider a point in K, x, and take B (x, rx) a ball containing x such that
B (x, rx) is a compact subset of V . Next use the fact that K is compact to obtain
the existence of a list, {B (xi, rxi/2)}m
i=1 which covers K. Then let
W ≡∪m
i=1B
³
xi, rxi
2
´
.
It follows since this is a ﬁnite union that
W = ∪m
i=1B
³
xi, rxi
2
´
and so W, being a ﬁnite union of compact sets is itself a compact set. Also, from
the construction
W ⊆∪m
i=1B (xi, rxi) .
Deﬁne f by
f(x) =
dist(x, W C)
dist(x, K) + dist(x, W C).
It is clear that f is continuous if the denominator is always nonzero. But this is
clear because if x ∈W C there must be a ball B (x, r) such that this ball does not
intersect K. Otherwise, x would be a limit point of K and since K is closed, x ∈K.
However, x /∈K because K ⊆W.
It is not necessary to be in a metric space to do this. You can accomplish the
same thing using Urysohn’s lemma.
Theorem 12.16 Let (Ω, S, µ) be a regular measure space as in Deﬁnition 12.14
where the conclusion of Lemma 12.15 holds. Then Cc(Ω) is dense in Lp(Ω).
Proof: First consider a measurable set, E where µ (E) < ∞. Let K ⊆E ⊆V
where µ (V \ K) < ε. Now let K ≺h ≺V. Then
Z
|h −XE|p dµ ≤
Z
X p
V \Kdµ = µ (V \ K) < ε.

12.3.
SEPARABILITY
325
It follows that for each s a simple function in Lp (Ω) , there exists h ∈Cc (Ω) such
that ||s −h||p < ε. This is because if
s(x) =
m
X
i=1
ciXEi(x)
is a simple function in Lp where the ci are the distinct nonzero values of s each
µ (Ei) < ∞since otherwise s /∈Lp due to the inequality
Z
|s|p dµ ≥|ci|p µ (Ei) .
By Theorem 12.13, simple functions are dense in Lp (Ω) ,and so this proves the
Theorem.
12.3
Separability
Theorem 12.17 For p ≥1 and µ a Radon measure, Lp(Rn, µ) is separable. Recall
this means there exists a countable set, D, such that if f ∈Lp(Rn, µ) and ε > 0,
there exists g ∈D such that ||f −g||p < ε.
Proof: Let Q be all functions of the form cX[a,b) where
[a, b) ≡[a1, b1) × [a2, b2) × · · · × [an, bn),
and both ai, bi are rational, while c has rational real and imaginary parts. Let D be
the set of all ﬁnite sums of functions in Q. Thus, D is countable. In fact D is dense in
Lp(Rn, µ). To prove this it is necessary to show that for every f ∈Lp(Rn, µ), there
exists an element of D, s such that ||s −f||p < ε. If it can be shown that for every
g ∈Cc (Rn) there exists h ∈D such that ||g −h||p < ε, then this will suﬃce because
if f ∈Lp (Rn) is arbitrary, Theorem 12.16 implies there exists g ∈Cc (Rn) such
that ||f −g||p ≤ε
2 and then there would exist h ∈Cc (Rn) such that ||h −g||p < ε
2.
By the triangle inequality,
||f −h||p ≤||h −g||p + ||g −f||p < ε.
Therefore, assume at the outset that f ∈Cc (Rn).
Let Pm consist of all sets of the form [a, b) ≡Qn
i=1[ai, bi) where ai = j2−mand
bi = (j + 1)2−m for j an integer. Thus Pm consists of a tiling of Rn into half open
rectangles having diameters 2−mn
1
2 . There are countably many of these rectangles;
so, let Pm = {[ai, bi)}∞
i=1 and Rn = ∪∞
i=1[ai, bi). Let cm
i be complex numbers with
rational real and imaginary parts satisfying
|f(ai) −cm
i | < 2−m,
|cm
i | ≤|f(ai)|.
(12.10)

326
THE LP SPACES
Let
sm(x) =
∞
X
i=1
cm
i X[ai,bi) (x) .
Since f(ai) = 0 except for ﬁnitely many values of i, the above is a ﬁnite sum. Then
12.10 implies sm ∈D. If sm converges uniformly to f then it follows ||sm −f||p →0
because |sm| ≤|f| and so
||sm −f||p
=
µZ
|sm −f|p dµ
¶1/p
=
ÃZ
spt(f)
|sm −f|p dµ
!1/p
≤
[εmn (spt (f))]1/p
whenever m is large enough.
Since f ∈Cc (Rn) it follows that f is uniformly continuous and so given ε > 0
there exists δ > 0 such that if |x −y| < δ, |f (x) −f (y)| < ε/2. Now let m be large
enough that every box in Pm has diameter less than δ and also that 2−m < ε/2.
Then if [ai, bi) is one of these boxes of Pm, and x ∈[ai, bi),
|f (x) −f (ai)| < ε/2
and
|f (ai) −cm
i | < 2−m < ε/2.
Therefore, using the triangle inequality, it follows that
|f (x) −cm
i | = |sm (x) −f (x)| < ε
and since x is arbitrary, this establishes uniform convergence.
This proves the
theorem.
Here is an easier proof if you know the Weierstrass approximation theorem.
Theorem 12.18 For p ≥1 and µ a Radon measure, Lp(Rn, µ) is separable. Recall
this means there exists a countable set, D, such that if f ∈Lp(Rn, µ) and ε > 0,
there exists g ∈D such that ||f −g||p < ε.
Proof: Let P denote the set of all polynomials which have rational coeﬃcients.
Then P is countable. Let τ k ∈Cc ((−(k + 1) , (k + 1))n) such that [−k, k]n ≺τ k ≺
(−(k + 1) , (k + 1))n . Let Dk denote the functions which are of the form, pτ k where
p ∈P. Thus Dk is also countable. Let D ≡∪∞
k=1Dk. It follows each function in D is
in Cc (Rn) and so it in Lp (Rn, µ). Let f ∈Lp (Rn, µ). By regularity of µ there exists
g ∈Cc (Rn) such that ||f −g||Lp(Rn,µ) < ε
3. Let k be such that spt (g) ⊆(−k, k)n .
Now by the Weierstrass approximation theorem there exists a polynomial q such
that
||g −q||[−(k+1),k+1]n
≡
sup {|g (x) −q (x)| : x ∈[−(k + 1) , (k + 1)]n}
<
ε
3µ ((−(k + 1) , k + 1)n).

12.4.
CONTINUITY OF TRANSLATION
327
It follows
||g −τ kq||[−(k+1),k+1]n
=
||τ kg −τ kq||[−(k+1),k+1]n
<
ε
3µ ((−(k + 1) , k + 1)n).
Without loss of generality, it can be assumed this polynomial has all rational coef-
ﬁcients. Therefore, τ kq ∈D.
||g −τ kq||p
Lp(Rn)
=
Z
(−(k+1),k+1)n |g (x) −τ k (x) q (x)|p dµ
≤
µ
ε
3µ ((−(k + 1) , k + 1)n)
¶p
µ ((−(k + 1) , k + 1)n)
<
³ε
3
´p
.
It follows
||f −τ kq||Lp(Rn,µ) ≤||f −g||Lp(Rn,µ) + ||g −τ kq||p
Lp(Rn,µ) < ε
3 + ε
3 < ε.
This proves the theorem.
Corollary 12.19 Let Ωbe any µ measurable subset of Rn and let µ be a Radon
measure. Then Lp(Ω, µ) is separable. Here
the σ algebra of measurable sets will
consist of all intersections of measurable sets with Ωand the measure will be µ
restricted to these sets.
Proof: Let eD be the restrictions of D to Ω. If f ∈Lp(Ω), let F be the zero
extension of f to all of Rn. Let ε > 0 be given. By Theorem 12.17 or 12.18 there
exists s ∈D such that ||F −s||p < ε. Thus
||s −f||Lp(Ω,µ) ≤||s −F||Lp(Rn,µ) < ε
and so the countable set eD is dense in Lp(Ω).
12.4
Continuity Of Translation
Deﬁnition 12.20 Let f be a function deﬁned on U ⊆Rn and let w ∈Rn. Then
fw will be the function deﬁned on w + U by
fw(x) = f(x −w).
Theorem 12.21 (Continuity of translation in Lp) Let f ∈Lp(Rn) with the mea-
sure being Lebesgue measure. Then
lim
||w||→0 ||fw −f||p = 0.

328
THE LP SPACES
Proof: Let ε > 0 be given and let g ∈Cc(Rn) with ||g −f||p <
ε
3.
Since
Lebesgue measure is translation invariant (mn(w + E) = mn(E)),
||gw −fw||p = ||g −f||p < ε
3.
You can see this from looking at simple functions and passing to the limit or you
could use the change of variables formula to verify it.
Therefore
||f −fw||p
≤
||f −g||p + ||g −gw||p + ||gw −fw||
<
2ε
3 + ||g −gw||p.
(12.11)
But lim|w|→0 gw(x) = g(x) uniformly in x because g is uniformly continuous. Now
let B be a large ball containing spt (g) and let δ1 be small enough that B (x, δ) ⊆B
whenever x ∈spt (g). If ε > 0 is given there exists δ < δ1 such that if |w| < δ, it
follows that |g (x −w) −g (x)| < ε/3
³
1 + mn (B)1/p´
. Therefore,
||g −gw||p
=
µZ
B
|g (x) −g (x −w)|p dmn
¶1/p
≤
ε
mn (B)1/p
3
³
1 + mn (B)1/p´ < ε
3.
Therefore, whenever |w| < δ, it follows ||g−gw||p < ε
3 and so from 12.11 ||f−fw||p <
ε. This proves the theorem.
Part of the argument of this theorem is signiﬁcant enough to be stated as a
corollary.
Corollary 12.22 Suppose g ∈Cc (Rn) and µ is a Radon measure on Rn. Then
lim
w→0 ||g −gw||p = 0.
Proof: The proof of this follows from the last part of the above argument simply
replacing mn with µ. Translation invariance of the measure is not needed to draw
this conclusion because of uniform continuity of g.
12.5
Molliﬁers And Density Of Smooth Functions
Deﬁnition 12.23 Let U be an open subset of Rn. C∞
c (U) is the vector space of all
inﬁnitely diﬀerentiable functions which equal zero for all x outside of some compact
set contained in U. Similarly, Cm
c (U) is the vector space of all functions which are
m times continuously diﬀerentiable and whose support is a compact subset of U.

12.5.
MOLLIFIERS AND DENSITY OF SMOOTH FUNCTIONS
329
Example 12.24 Let U = B (z, 2r)
ψ (x) =



exp
·³
|x −z|2 −r2´−1¸
if |x −z| < r,
0 if |x −z| ≥r.
Then a little work shows ψ ∈C∞
c (U). The following also is easily obtained.
Lemma 12.25 Let U be any open set. Then C∞
c (U) ̸= ∅.
Proof: Pick z ∈U and let r be small enough that B (z, 2r) ⊆U. Then let
ψ ∈C∞
c (B (z, 2r)) ⊆C∞
c (U) be the function of the above example.
Deﬁnition 12.26 Let U = {x ∈Rn : |x| < 1}. A sequence {ψm} ⊆C∞
c (U) is
called a molliﬁer (sometimes an approximate identity) if
ψm(x) ≥0, ψm(x) = 0, if |x| ≥1
m,
and
R
ψm(x) = 1. Sometimes it may be written as {ψε} where ψε satisﬁes the above
conditions except ψε (x) = 0 if |x| ≥ε. In other words, ε takes the place of 1/m
and in everything that follows ε →0 instead of m →∞.
As before,
R
f(x, y)dµ(y) will mean x is ﬁxed and the function y →f(x, y)
is being integrated. To make the notation more familiar, dx is written instead of
dmn(x).
Example 12.27 Let
ψ ∈C∞
c (B(0, 1)) (B(0, 1) = {x : |x| < 1})
with ψ(x) ≥0 and
R
ψdm = 1. Let ψm(x) = cmψ(mx) where cm is chosen in such
a way that
R
ψmdm = 1. By the change of variables theorem cm = mn.
Deﬁnition 12.28 A function, f, is said to be in L1
loc(Rn, µ) if f is µ measurable
and if |f|XK ∈L1(Rn, µ) for every compact set, K. Here µ is a Radon measure
on Rn. Usually µ = mn, Lebesgue measure. When this is so, write L1
loc(Rn) or
Lp(Rn), etc. If f ∈L1
loc(Rn, µ), and g ∈Cc(Rn),
f ∗g(x) ≡
Z
f(y)g(x −y)dµ.
The following lemma will be useful in what follows. It says that one of these very
unregular functions in L1
loc (Rn, µ) is smoothed out by convolving with a molliﬁer.
Lemma 12.29 Let f ∈L1
loc(Rn, µ), and g ∈C∞
c (Rn). Then f ∗g is an inﬁnitely
diﬀerentiable function. Here µ is a Radon measure on Rn.

330
THE LP SPACES
Proof: Consider the diﬀerence quotient for calculating a partial derivative of
f ∗g.
f ∗g (x + tej) −f ∗g (x)
t
=
Z
f(y)g(x + tej −y) −g (x −y)
t
dµ (y) .
Using the fact that g ∈C∞
c (Rn), the quotient,
g(x + tej −y) −g (x −y)
t
,
is uniformly bounded. To see this easily, use Theorem 5.53 on Page 119 to get the
existence of a constant, M depending on
max {||Dg (x)|| : x ∈Rn}
such that
|g(x + tej −y) −g (x −y)| ≤M |t|
for any choice of x and y. Therefore, there exists a dominating function for the
integrand of the above integral which is of the form C |f (y)| XK where K is a
compact set containing the support of g.
It follows the limit of the diﬀerence
quotient above passes inside the integral as t →0 and
∂
∂xj
(f ∗g) (x) =
Z
f(y) ∂
∂xj
g (x −y) dµ (y) .
Now letting
∂
∂xj g play the role of g in the above argument, partial derivatives of all
orders exist. This proves the lemma.
Theorem 12.30 Let K be a compact subset of an open set, U. Then there exists
a function, h ∈C∞
c (U), such that h(x) = 1 for all x ∈K and h(x) ∈[0, 1] for all
x.
Proof: Let r > 0 be small enough that K + B(0, 3r) ⊆U.
The symbol,
K + B(0, 3r) means
{k + x : k ∈K and x ∈B (0, 3r)} .
Thus this is simply a way to write
∪{B (k, 3r) : k ∈K} .
Think of it as fattening up the set, K. Let Kr = K + B(0, r). A picture of what is
happening follows.
K
Kr U
Consider XKr ∗ψmwhere ψmis a molliﬁer.
Let m be so large that
1
m < r.
Then from the deﬁnition of what is meant by a convolution, and using that ψm has

12.5.
MOLLIFIERS AND DENSITY OF SMOOTH FUNCTIONS
331
support in B
¡
0, 1
m
¢
, XKr ∗ψm = 1 on K and that its support is in K + B (0, 3r).
Now using Lemma 12.29, XKr ∗ψm is also inﬁnitely diﬀerentiable. Therefore, let
h = XKr ∗ψm.
The following corollary will be used later.
Corollary 12.31 Let K be a compact set in Rn and let {Ui}∞
i=1 be an open cover
of K. Then there exist functions, ψk ∈C∞
c (Ui) such that ψi ≺Ui and
∞
X
i=1
ψi (x) = 1.
If K1 is a compact subset of U1 there exist such functions such that also ψ1 (x) = 1
for all x ∈K1.
Proof: This follows from a repeat of the proof of Theorem 9.18 on Page 220,
replacing the lemma used in that proof with Theorem 12.30.
Theorem 12.32 For each p ≥1, C∞
c (Rn) is dense in Lp(Rn). Here the measure
is Lebesgue measure.
Proof: Let f ∈Lp(Rn) and let ε > 0 be given. Choose g ∈Cc(Rn) such that
||f −g||p < ε
2. This can be done by using Theorem 12.16. Now let
gm (x) = g ∗ψm (x) ≡
Z
g (x −y) ψm (y) dmn (y) =
Z
g (y) ψm (x −y) dmn (y)
where {ψm} is a molliﬁer. It follows from Lemma 12.29 gm ∈C∞
c (Rn). It vanishes
if x /∈spt(g) + B(0, 1
m).
||g −gm||p
=
µZ
|g(x) −
Z
g(x −y)ψm(y)dmn(y)|pdmn(x)
¶ 1
p
≤
µZ
(
Z
|g(x) −g(x −y)|ψm(y)dmn(y))pdmn(x)
¶ 1
p
≤
Z µZ
|g(x) −g(x −y)|pdmn(x)
¶ 1
p
ψm(y)dmn(y)
=
Z
B(0, 1
m )
||g −gy||pψm(y)dmn(y) < ε
2
whenever m is large enough. This follows from Corollary 12.22. Theorem 12.12 was
used to obtain the third inequality. There is no measurability problem because the
function
(x, y) →|g(x) −g(x −y)|ψm(y)
is continuous. Thus when m is large enough,
||f −gm||p ≤||f −g||p + ||g −gm||p < ε
2 + ε
2 = ε.

332
THE LP SPACES
This proves the theorem.
This is a very remarkable result. Functions in Lp (Rn) don’t need to be continu-
ous anywhere and yet every such function is very close in the Lp norm to one which
is inﬁnitely diﬀerentiable having compact support.
Another thing should probably be mentioned. If you have had a course in com-
plex analysis, you may be wondering whether these inﬁnitely diﬀerentiable functions
having compact support have anything to do with analytic functions which also have
inﬁnitely many derivatives. The answer is no! Recall that if an analytic function
has a limit point in the set of zeros then it is identically equal to zero. Thus these
functions in C∞
c (Rn) are not analytic. This is a strictly real analysis phenomenon
and has absolutely nothing to do with the theory of functions of a complex variable.
12.6
Exercises
1. Let E be a Lebesgue measurable set in R. Suppose m(E) > 0. Consider the
set
E −E = {x −y : x ∈E, y ∈E}.
Show that E −E contains an interval. Hint: Let
f(x) =
Z
XE(t)XE(x + t)dt.
Note f is continuous at 0 and f(0) > 0 and use continuity of translation in
Lp.
2. Establish the inequality ||fg||r ≤||f||p ||g||q whenever 1
r = 1
p + 1
q.
3. Let (Ω, S, µ) be counting measure on N. Thus Ω= N and S = P (N) with
µ (S) = number of things in S. Let 1 ≤p ≤q. Show that in this case,
L1 (N) ⊆Lp (N) ⊆Lq (N) .
Hint: This is real easy if you consider what
R
Ωfdµ equals. How are the
norms related?
4. Consider the function, f (x, y) = xp−1
py + yq−1
qx
for x, y > 0 and 1
p + 1
q = 1. Show
directly that f (x, y) ≥1 for all such x, y and show this implies xy ≤xp
p + yq
q .
5. Give an example of a sequence of functions in Lp (R) which converges to zero
in Lp but does not converge pointwise to 0. Does this contradict the proof of
the theorem that Lp is complete?
6. Let K be a bounded subset of Lp (Rn) and suppose that there exists G such
that G is compact with
Z
Rn\G
|u (x)|p dx < εp

12.6.
EXERCISES
333
and for all ε > 0, there exist a δ > 0 and such that if |h| < δ, then
Z
|u (x + h) −u (x)|p dx < εp
for all u ∈K. Show that K is precompact in Lp (Rn). Hint: Let φk be a
molliﬁer and consider
Kk ≡{u ∗φk : u ∈K} .
Verify the conditions of the Ascoli Arzela theorem for these functions deﬁned
on G and show there is an ε net for each ε > 0. Can you modify this to let
an arbitrary open set take the place of Rn?
7. Let (Ω, d) be a metric space and suppose also that (Ω, S, µ) is a regular mea-
sure space such that µ (Ω) < ∞and let f ∈L1 (Ω) where f has complex
values. Show that for every ε > 0, there exists an open set of measure less
than ε, denoted here by V and a continuous function, g deﬁned on Ωsuch
that f = g on V C. Thus, aside from a set of small measure, f is continuous.
If |f (ω)| ≤M, show that it can be assumed that |g (ω)| ≤M. This is called
Lusin’s theorem. Hint: Use Theorems 12.16 and 12.10 to obtain a sequence
of functions in Cc (Ω) , {gn} which converges pointwise a.e. to f and then use
Egoroﬀ’s theorem to obtain a small set, W of measure less than ε/2 such that
convergence is uniform on W C. Now let F be a closed subset of W C such
that µ
¡
W C \ F
¢
< ε/2. Let V = F C. Thus µ (V ) < ε and on F = V C,
the convergence of {gn} is uniform showing that the restriction of f to V C is
continuous. Now use the Tietze extension theorem.
8. Let φm ∈C∞
c (Rn), φm (x) ≥0,and
R
Rn φm(y)dy = 1 with
lim
m→∞sup {|x| : x ∈spt (φm)} = 0.
Show if f ∈Lp(Rn), limm→∞f ∗φm = f in Lp(Rn).
9. Let φ : R →R be convex. This means
φ(λx + (1 −λ)y) ≤λφ(x) + (1 −λ)φ(y)
whenever λ ∈[0, 1]. Verify that if x < y < z, then φ(y)−φ(x)
y−x
≤
φ(z)−φ(y)
z−y
and that
φ(z)−φ(x)
z−x
≤
φ(z)−φ(y)
z−y
.
Show if s ∈R there exists λ such that
φ(s) ≤φ(t) + λ(s −t) for all t. Show that if φ is convex, then φ is continuous.
10. ↑Prove Jensen’s inequality. If φ : R →R is convex, µ(Ω) = 1, and f : Ω→R
is in L1(Ω), then φ(
R
Ωf du) ≤
R
Ωφ(f)dµ. Hint: Let s =
R
Ωf dµ and use
Problem 9.
11. Let 1
p + 1
p′ = 1, p > 1, let f ∈Lp(R), g ∈Lp′(R). Show f ∗g is uniformly
continuous on R and |(f ∗g)(x)| ≤||f||Lp||g||Lp′. Hint: You need to consider
why f ∗g exists and then this follows from the deﬁnition of convolution and
continuity of translation in Lp.

334
THE LP SPACES
12. B(p, q) =
R 1
0 xp−1(1 −x)q−1dx, Γ(p) =
R ∞
0
e−ttp−1dt for p, q > 0. The ﬁrst
of these is called the beta function, while the second is the gamma function.
Show a.) Γ(p + 1) = pΓ(p);
b.) Γ(p)Γ(q) = B(p, q)Γ(p + q).
13. Let f ∈Cc(0, ∞) and deﬁne F(x) = 1
x
R x
0 f(t)dt. Show
||F||Lp(0,∞) ≤
p
p −1||f||Lp(0,∞) whenever p > 1.
Hint: Argue there is no loss of generality in assuming f ≥0 and then assume
this is so. Integrate
R ∞
0
|F(x)|pdx by parts as follows:
Z ∞
0
F pdx =
show = 0
z }| {
xF p|∞
0
−p
Z ∞
0
xF p−1F ′dx.
Now show xF ′ = f −F and use this in the last integral.
Complete the
argument by using Holder’s inequality and p −1 = p/q.
14. ↑Now suppose f ∈Lp(0, ∞), p > 1, and f not necessarily in Cc(0, ∞). Show
that F(x) = 1
x
R x
0 f(t)dt still makes sense for each x > 0. Show the inequality
of Problem 13 is still valid. This inequality is called Hardy’s inequality. Hint:
To show this, use the above inequality along with the density of Cc (0, ∞) in
Lp (0, ∞).
15. Suppose f, g ≥0. When does equality hold in Holder’s inequality?
16. Prove Vitali’s Convergence theorem: Let {fn} be uniformly integrable and
complex valued, µ(Ω) < ∞, fn(x) →f(x) a.e. where f is measurable. Then
f ∈L1 and limn→∞
R
Ω|fn −f|dµ = 0. Hint: Use Egoroﬀ’s theorem to show
{fn} is a Cauchy sequence in L1 (Ω). This yields a diﬀerent and easier proof
than what was done earlier. See Theorem 8.50 on Page 204.
17. ↑Show the Vitali Convergence theorem implies the Dominated Convergence
theorem for ﬁnite measure spaces but there exist examples where the Vitali
convergence theorem works and the dominated convergence theorem does not.
18. ↑Suppose µ(Ω) < ∞, {fn} ⊆L1(Ω), and
Z
Ω
h (|fn|) dµ < C
for all n where h is a continuous, nonnegative function satisfying
lim
t→∞
h (t)
t
= ∞.
Show {fn} is uniformly integrable. In applications, this often occurs in the
form of a bound on ||fn||p.

12.6.
EXERCISES
335
19. ↑Sometimes, especially in books on probability, a diﬀerent deﬁnition of uni-
form integrability is used than that presented here. A set of functions, S,
deﬁned on a ﬁnite measure space, (Ω, S, µ) is said to be uniformly integrable
if for all ε > 0 there exists α > 0 such that for all f ∈S,
Z
[|f|≥α]
|f| dµ ≤ε.
Show that this deﬁnition is equivalent to the deﬁnition of uniform integrability
given earlier in Deﬁnition 8.48 on Page 203 with the addition of the condition
that there is a constant, C < ∞such that
Z
|f| dµ ≤C
for all f ∈S.
20. f ∈L∞(Ω, µ) if there exists a set of measure zero, E, and a constant C < ∞
such that |f(x)| ≤C for all x /∈E.
||f||∞≡inf{C : |f(x)| ≤C a.e.}.
Show || ||∞is a norm on L∞(Ω, µ) provided f and g are identiﬁed if f(x) =
g(x) a.e. Show L∞(Ω, µ) is complete. Hint: You might want to show that
[|f| > ||f||∞] has measure zero so ||f||∞is the smallest number at least as
large as |f (x)| for a.e. x. Thus ||f||∞is one of the constants, C in the above.
21. Suppose f ∈L∞∩L1. Show limp→∞||f||Lp = ||f||∞. Hint:
(||f||∞−ε)p µ ([|f| > ||f||∞−ε]) ≤
Z
[|f|>||f||∞−ε]
|f|p dµ ≤
Z
|f|p dµ =
Z
|f|p−1 |f| dµ ≤||f||p−1
∞
Z
|f| dµ.
Now raise both ends to the 1/p power and take lim inf and lim sup as p →∞.
You should get ||f||∞−ε ≤lim inf ||f||p ≤lim sup ||f||p ≤||f||∞
22. Suppose µ(Ω) < ∞. Show that if 1 ≤p < q, then Lq(Ω) ⊆Lp(Ω). Hint Use
Holder’s inequality.
23. Show L1(R) ⊈L2(R) and L2(R) ⊈L1(R) if Lebesgue measure is used. Hint:
Consider 1/√x and 1/x.
24. Suppose that θ ∈[0, 1] and r, s, q > 0 with
1
q = θ
r + 1 −θ
s
.

336
THE LP SPACES
show that
(
Z
|f|qdµ)1/q ≤((
Z
|f|rdµ)1/r)θ((
Z
|f|sdµ)1/s)1−θ.
If q, r, s ≥1 this says that
||f||q ≤||f||θ
r||f||1−θ
s
.
Using this, show that
ln
³
||f||q
´
≤θ ln (||f||r) + (1 −θ) ln (||f||s) .
Hint:
Z
|f|qdµ =
Z
|f|qθ|f|q(1−θ)dµ.
Now note that 1 = θq
r + q(1−θ)
s
and use Holder’s inequality.
25. Suppose f is a function in L1 (R) and f is inﬁnitely diﬀerentiable. Is f ′ ∈
L1 (R)?
Hint: What if φ ∈C∞
c (0, 1) and f (x) = φ (2n (x −n)) for x ∈
(n, n + 1) , f (x) = 0 if x < 0?

Banach Spaces
13.1
Theorems Based On Baire Category
13.1.1
Baire Category Theorem
Some examples of Banach spaces that have been discussed up to now are Rn, Cn,
and Lp (Ω). Theorems about general Banach spaces are proved in this chapter.
The main theorems to be presented here are the uniform boundedness theorem, the
open mapping theorem, the closed graph theorem, and the Hahn Banach Theorem.
The ﬁrst three of these theorems come from the Baire category theorem which is
about to be presented. They are topological in nature. The Hahn Banach theorem
has nothing to do with topology. Banach spaces are all normed linear spaces and as
such, they are all metric spaces because a normed linear space may be considered
as a metric space with d (x, y) ≡||x −y||. You can check that this satisﬁes all the
axioms of a metric. As usual, if every Cauchy sequence converges, the metric space
is called complete.
Deﬁnition 13.1 A complete normed linear space is called a Banach space.
The following remarkable result is called the Baire category theorem. To get an
idea of its meaning, imagine you draw a line in the plane. The complement of this
line is an open set and is dense because every point, even those on the line, are limit
points of this open set. Now draw another line. The complement of the two lines
is still open and dense. Keep drawing lines and looking at the complements of the
union of these lines. You always have an open set which is dense. Now what if there
were countably many lines? The Baire category theorem implies the complement
of the union of these lines is dense. In particular it is nonempty. Thus you cannot
write the plane as a countable union of lines. This is a rather rough description of
this very important theorem. The precise statement and proof follow.
Theorem 13.2 Let (X, d) be a complete metric space and let {Un}∞
n=1 be a se-
quence of open subsets of X satisfying Un = X (Un is dense). Then D ≡∩∞
n=1Un
is a dense subset of X.
337

338
BANACH SPACES
Proof: Let p ∈X and let r0 > 0. I need to show D ∩B(p, r0) ̸= ∅. Since U1 is
dense, there exists p1 ∈U1 ∩B(p, r0), an open set. Let p1 ∈B(p1, r1) ⊆B(p1, r1) ⊆
U1 ∩B(p, r0) and r1 < 2−1. This is possible because U1 ∩B (p, r0) is an open set
and so there exists r1 such that B (p1, 2r1) ⊆U1 ∩B (p, r0). But
B (p1, r1) ⊆B (p1, r1) ⊆B (p1, 2r1)
because B (p1, r1) = {x ∈X : d (x, p) ≤r1}. (Why?)
 r0 p
p1·
There exists p2 ∈U2 ∩B(p1, r1) because U2 is dense. Let
p2 ∈B(p2, r2) ⊆B(p2, r2) ⊆U2 ∩B(p1, r1) ⊆U1 ∩U2 ∩B(p, r0).
and let r2 < 2−2. Continue in this way. Thus
rn < 2−n,
B(pn, rn) ⊆U1 ∩U2 ∩... ∩Un ∩B(p, r0),
B(pn, rn) ⊆B(pn−1, rn−1).
The sequence, {pn} is a Cauchy sequence because all terms of {pk} for k ≥n
are contained in B (pn, rn), a set whose diameter is no larger than 2−n. Since X is
complete, there exists p∞such that
lim
n→∞pn = p∞.
Since all but ﬁnitely many terms of {pn} are in B(pm, rm), it follows that p∞∈
B(pm, rm) for each m. Therefore,
p∞∈∩∞
m=1B(pm, rm) ⊆∩∞
i=1Ui ∩B(p, r0).
This proves the theorem.
The following corollary is also called the Baire category theorem.
Corollary 13.3 Let X be a complete metric space and suppose X = ∪∞
i=1Fi where
each Fi is a closed set. Then for some i, interior Fi ̸= ∅.
Proof: If all Fi has empty interior, then F C
i
would be a dense open set. There-
fore, from Theorem 13.2, it would follow that
∅= (∪∞
i=1Fi)C = ∩∞
i=1F C
i
̸= ∅.

13.1.
THEOREMS BASED ON BAIRE CATEGORY
339
The set D of Theorem 13.2 is called a Gδ set because it is the countable inter-
section of open sets. Thus D is a dense Gδ set.
Recall that a norm satisﬁes:
a.) ||x|| ≥0, ||x|| = 0 if and only if x = 0.
b.) ||x + y|| ≤||x|| + ||y||.
c.) ||cx|| = |c| ||x|| if c is a scalar and x ∈X.
From the deﬁnition of continuity, it follows easily that a function is continuous
if
lim
n→∞xn = x
implies
lim
n→∞f(xn) = f(x).
Theorem 13.4 Let X and Y be two normed linear spaces and let L : X →Y be
linear (L(ax + by) = aL(x) + bL(y) for a, b scalars and x, y ∈X). The following
are equivalent
a.) L is continuous at 0
b.) L is continuous
c.)
There exists K > 0 such that ||Lx||Y ≤K ||x||X for all x ∈X (L is
bounded).
Proof: a.)⇒b.) Let xn →x. It is necessary to show that Lxn →Lx. But
(xn −x) →0 and so from continuity at 0, it follows
L (xn −x) = Lxn −Lx →0
so Lxn →Lx. This shows a.) implies b.).
b.)⇒c.) Since L is continuous, L is continuous at 0. Hence ||Lx||Y < 1 whenever
||x||X ≤δ for some δ. Therefore, suppressing the subscript on the || ||,
||L
µ δx
||x||
¶
|| ≤1.
Hence
||Lx|| ≤1
δ ||x||.
c.)⇒a.) follows from the inequality given in c.).
Deﬁnition 13.5 Let L : X →Y be linear and continuous where X and Y are
normed linear spaces. Denote the set of all such continuous linear maps by L(X, Y )
and deﬁne
||L|| = sup{||Lx|| : ||x|| ≤1}.
(13.1)
This is called the operator norm.

340
BANACH SPACES
Note that from Theorem 13.4 ||L|| is well deﬁned because of part c.) of that
Theorem.
The next lemma follows immediately from the deﬁnition of the norm and the
assumption that L is linear.
Lemma 13.6 With ||L|| deﬁned in 13.1, L(X, Y ) is a normed linear space. Also
||Lx|| ≤||L|| ||x||.
Proof: Let x ̸= 0 then x/ ||x|| has norm equal to 1 and so
¯¯¯¯
¯¯¯¯L
µ x
||x||
¶¯¯¯¯
¯¯¯¯ ≤||L|| .
Therefore, multiplying both sides by ||x||, ||Lx|| ≤||L|| ||x||. This is obviously a
linear space. It remains to verify the operator norm really is a norm. First of all,
if ||L|| = 0, then Lx = 0 for all ||x|| ≤1. It follows that for any x ̸= 0, 0 = L
³
x
||x||
´
and so Lx = 0. Therefore, L = 0. Also, if c is a scalar,
||cL|| = sup
||x||≤1
||cL (x)|| = |c| sup
||x||≤1
||Lx|| = |c| ||L|| .
It remains to verify the triangle inequality. Let L, M ∈L (X, Y ) .
||L + M||
≡
sup
||x||≤1
||(L + M) (x)|| ≤sup
||x||≤1
(||Lx|| + ||Mx||)
≤
sup
||x||≤1
||Lx|| + sup
||x||≤1
||Mx|| = ||L|| + ||M|| .
This shows the operator norm is really a norm as hoped. This proves the lemma.
For example, consider the space of linear transformations deﬁned on Rn having
values in Rm. The fact the transformation is linear automatically imparts conti-
nuity to it. You should give a proof of this fact. Recall that every such linear
transformation can be realized in terms of matrix multiplication.
Thus, in ﬁnite dimensions the algebraic condition that an operator is linear is
suﬃcient to imply the topological condition that the operator is continuous. The
situation is not so simple in inﬁnite dimensional spaces such as C (X; Rn). This
explains the imposition of the topological condition of continuity as a criterion for
membership in L (X, Y ) in addition to the algebraic condition of linearity.
Theorem 13.7 If Y is a Banach space, then L(X, Y ) is also a Banach space.
Proof: Let {Ln} be a Cauchy sequence in L(X, Y ) and let x ∈X.
||Lnx −Lmx|| ≤||x|| ||Ln −Lm||.
Thus {Lnx} is a Cauchy sequence. Let
Lx = lim
n→∞Lnx.

13.1.
THEOREMS BASED ON BAIRE CATEGORY
341
Then, clearly, L is linear because if x1, x2 are in X, and a, b are scalars, then
L (ax1 + bx2)
=
lim
n→∞Ln (ax1 + bx2)
=
lim
n→∞(aLnx1 + bLnx2)
=
aLx1 + bLx2.
Also L is continuous. To see this, note that {||Ln||} is a Cauchy sequence of real
numbers because |||Ln|| −||Lm||| ≤||Ln−Lm||. Hence there exists K > sup{||Ln|| :
n ∈N}. Thus, if x ∈X,
||Lx|| = lim
n→∞||Lnx|| ≤K||x||.
This proves the theorem.
13.1.2
Uniform Boundedness Theorem
The next big result is sometimes called the Uniform Boundedness theorem, or the
Banach-Steinhaus theorem. This is a very surprising theorem which implies that for
a collection of bounded linear operators, if they are bounded pointwise, then they are
also bounded uniformly. As an example of a situation in which pointwise bounded
does not imply uniformly bounded, consider the functions fα (x) ≡X(α,1) (x) x−1
for α ∈(0, 1). Clearly each function is bounded and the collection of functions is
bounded at each point of (0, 1), but there is no bound for all these functions taken
together. One problem is that (0, 1) is not a Banach space. Therefore, the functions
cannot be linear.
Theorem 13.8 Let X be a Banach space and let Y be a normed linear space. Let
{Lα}α∈Λ be a collection of elements of L(X, Y ). Then one of the following happens.
a.) sup{||Lα|| : α ∈Λ} < ∞
b.) There exists a dense Gδ set, D, such that for all x ∈D,
sup{||Lαx|| α ∈Λ} = ∞.
Proof: For each n ∈N, deﬁne
Un = {x ∈X : sup{||Lαx|| : α ∈Λ} > n}.
Then Un is an open set because if x ∈Un, then there exists α ∈Λ such that
||Lαx|| > n
But then, since Lα is continuous, this situation persists for all y suﬃciently close
to x, say for all y ∈B (x, δ). Then B (x, δ) ⊆Un which shows Un is open.
Case b.) is obtained from Theorem 13.2 if each Un is dense.
The other case is that for some n, Un is not dense. If this occurs, there exists
x0 and r > 0 such that for all x ∈B(x0, r), ||Lαx|| ≤n for all α. Now if y ∈

342
BANACH SPACES
B(0, r), x0 + y ∈B(x0, r). Consequently, for all such y, ||Lα(x0 + y)|| ≤n. This
implies that for all α ∈Λ and ||y|| < r,
||Lαy|| ≤n + ||Lα(x0)|| ≤2n.
Therefore, if ||y|| ≤1,
¯¯¯¯ r
2y
¯¯¯¯ < r and so for all α,
||Lα
³r
2y
´
|| ≤2n.
Now multiplying by r/2 it follows that whenever ||y|| ≤1, ||Lα (y)|| ≤4n/r. Hence
case a.) holds.
13.1.3
Open Mapping Theorem
Another remarkable theorem which depends on the Baire category theorem is the
open mapping theorem.
Unlike Theorem 13.8 it requires both X and Y to be
Banach spaces.
Theorem 13.9 Let X and Y be Banach spaces, let L ∈L(X, Y ), and suppose L
is onto. Then L maps open sets onto open sets.
To aid in the proof, here is a lemma.
Lemma 13.10 Let a and b be positive constants and suppose
B(0, a) ⊆L(B(0, b)).
Then
L(B(0, b)) ⊆L(B(0, 2b)).
Proof of Lemma 13.10: Let y ∈L(B(0, b)). There exists x1 ∈B(0, b) such
that ||y −Lx1|| < a
2. Now this implies
2y −2Lx1 ∈B(0, a) ⊆L(B(0, b)).
Thus 2y −2Lx1 ∈L(B(0, b)) just like y was. Therefore, there exists x2 ∈B(0, b)
such that ||2y −2Lx1 −Lx2|| < a/2. Hence ||4y −4Lx1 −2Lx2|| < a, and there
exists x3 ∈B (0, b) such that ||4y −4Lx1 −2Lx2 −Lx3|| < a/2. Continuing in this
way, there exist x1, x2, x3, x4, ... in B(0, b) such that
||2ny −
n
X
i=1
2n−(i−1)L(xi)|| < a
which implies
||y −
n
X
i=1
2−(i−1)L(xi)|| = ||y −L
Ã n
X
i=1
2−(i−1)(xi)
!
|| < 2−na
(13.2)

13.1.
THEOREMS BASED ON BAIRE CATEGORY
343
Now consider the partial sums of the series, P∞
i=1 2−(i−1)xi.
||
n
X
i=m
2−(i−1)xi|| ≤b
∞
X
i=m
2−(i−1) = b 2−m+2.
Therefore, these partial sums form a Cauchy sequence and so since X is complete,
there exists x = P∞
i=1 2−(i−1)xi. Letting n →∞in 13.2 yields ||y −Lx|| = 0. Now
||x|| = lim
n→∞||
n
X
i=1
2−(i−1)xi||
≤lim
n→∞
n
X
i=1
2−(i−1)||xi|| < lim
n→∞
n
X
i=1
2−(i−1)b = 2b.
This proves the lemma.
Proof of Theorem 13.9: Y = ∪∞
n=1L(B(0, n)). By Corollary 13.3, the set,
L(B(0, n0)) has nonempty interior for some n0. Thus B(y, r) ⊆L(B(0, n0)) for
some y and some r > 0. Since L is linear B(−y, r) ⊆L(B(0, n0)) also. Here is
why. If z ∈B(−y, r), then −z ∈B(y, r) and so there exists xn ∈B (0, n0) such
that Lxn →−z. Therefore, L (−xn) →z and −xn ∈B (0, n0) also. Therefore
z ∈L(B(0, n0)). Then it follows that
B(0, r)
⊆
B(y, r) + B(−y, r)
≡
{y1 + y2 : y1 ∈B (y, r) and y2 ∈B (−y, r)}
⊆
L(B(0, 2n0))
The reason for the last inclusion is that from the above, if y1 ∈B (y, r) and y2 ∈
B (−y, r), there exists xn, zn ∈B (0, n0) such that
Lxn →y1, Lzn →y2.
Therefore,
||xn + zn|| ≤2n0
and so (y1 + y2) ∈L(B(0, 2n0)).
By Lemma 13.10, L(B(0, 2n0)) ⊆L(B(0, 4n0)) which shows
B(0, r) ⊆L(B(0, 4n0)).
Letting a = r(4n0)−1, it follows, since L is linear, that B(0, a) ⊆L(B(0, 1)). It
follows since L is linear,
L(B(0, r)) ⊇B(0, ar).
(13.3)
Now let U be open in X and let x + B(0, r) = B(x, r) ⊆U. Using 13.3,
L(U) ⊇L(x + B(0, r))
= Lx + L(B(0, r)) ⊇Lx + B(0, ar) = B(Lx, ar).

344
BANACH SPACES
Hence
Lx ∈B(Lx, ar) ⊆L(U).
which shows that every point, Lx ∈LU, is an interior point of LU and so LU is
open. This proves the theorem.
This theorem is surprising because it implies that if |·| and ||·|| are two norms
with respect to which a vector space X is a Banach space such that |·| ≤K ||·||,
then there exists a constant k, such that ||·|| ≤k |·| . This can be useful because
sometimes it is not clear how to compute k when all that is needed is its existence.
To see the open mapping theorem implies this, consider the identity map id x = x.
Then id : (X, ||·||) →(X, |·|) is continuous and onto. Hence id is an open map which
implies id−1 is continuous. Theorem 13.4 gives the existence of the constant k.
13.1.4
Closed Graph Theorem
Deﬁnition 13.11 Let f : D →E.
The set of all ordered pairs of the form
{(x, f(x)) : x ∈D} is called the graph of f.
Deﬁnition 13.12 If X and Y are normed linear spaces, make X×Y into a normed
linear space by using the norm ||(x, y)|| = max (||x||, ||y||) along with component-
wise addition and scalar multiplication. Thus a(x, y) + b(z, w) ≡(ax + bz, ay + bw).
There are other ways to give a norm for X × Y . For example, you could deﬁne
||(x, y)|| = ||x|| + ||y||
Lemma 13.13 The norm deﬁned in Deﬁnition 13.12 on X × Y along with the
deﬁnition of addition and scalar multiplication given there make X × Y into a
normed linear space.
Proof: The only axiom for a norm which is not obvious is the triangle inequality.
Therefore, consider
||(x1, y1) + (x2, y2)||
=
||(x1 + x2, y1 + y2)||
=
max (||x1 + x2|| , ||y1 + y2||)
≤
max (||x1|| + ||x2|| , ||y1|| + ||y2||)
≤
max (||x1|| , ||y1||) + max (||x2|| , ||y2||)
=
||(x1, y1)|| + ||(x2, y2)|| .
It is obvious X × Y is a vector space from the above deﬁnition. This proves the
lemma.
Lemma 13.14 If X and Y are Banach spaces, then X × Y with the norm and
vector space operations deﬁned in Deﬁnition 13.12 is also a Banach space.

13.1.
THEOREMS BASED ON BAIRE CATEGORY
345
Proof: The only thing left to check is that the space is complete. But this
follows from the simple observation that {(xn, yn)} is a Cauchy sequence in X × Y
if and only if {xn} and {yn} are Cauchy sequences in X and Y respectively. Thus
if {(xn, yn)} is a Cauchy sequence in X ×Y , it follows there exist x and y such that
xn →x and yn →y. But then from the deﬁnition of the norm, (xn, yn) →(x, y).
Lemma 13.15 Every closed subspace of a Banach space is a Banach space.
Proof: If F ⊆X where X is a Banach space and {xn} is a Cauchy sequence
in F, then since X is complete, there exists a unique x ∈X such that xn →x.
However this means x ∈F = F since F is closed.
Deﬁnition 13.16 Let X and Y be Banach spaces and let D ⊆X be a subspace. A
linear map L : D →Y is said to be closed if its graph is a closed subspace of X ×Y .
Equivalently, L is closed if xn →x and Lxn →y implies x ∈D and y = Lx.
Note the distinction between closed and continuous. If the operator is closed
the assertion that y = Lx only follows if it is known that the sequence {Lxn}
converges. In the case of a continuous operator, the convergence of {Lxn} follows
from the assumption that xn →x. It is not always the case that a mapping which
is closed is necessarily continuous. Consider the function f (x) = tan (x) if x is not
an odd multiple of π
2 and f (x) ≡0 at every odd multiple of π
2 . Then the graph
is closed and the function is deﬁned on R but it clearly fails to be continuous. Of
course this function is not linear. You could also consider the map,
d
dx :
©
y ∈C1 ([0, 1]) : y (0) = 0
ª
≡D →C ([0, 1]) .
where the norm is the uniform norm on C ([0, 1]) , ||y||∞. If y ∈D, then
y (x) =
Z x
0
y′ (t) dt.
Therefore, if dyn
dx →f ∈C ([0, 1]) and if yn →y in C ([0, 1]) it follows that
yn (x)
=
R x
0
dyn(t)
dx
dt
↓
↓
y (x)
=
R x
0 f (t) dt
and so by the fundamental theorem of calculus f (x) = y′ (x) and so the mapping
is closed. It is obviously not continuous because it takes y (x) and y (x)+ 1
n sin (nx)
to two functions which are far from each other even though these two functions are
very close in C ([0, 1]). Furthermore, it is not deﬁned on the whole space, C ([0, 1]).
The next theorem, the closed graph theorem, gives conditions under which closed
implies continuous.
Theorem 13.17 Let X and Y be Banach spaces and suppose L : X →Y is closed
and linear. Then L is continuous.

346
BANACH SPACES
Proof: Let G be the graph of L. G = {(x, Lx) : x ∈X}. By Lemma 13.15
it follows that G is a Banach space. Deﬁne P : G →X by P(x, Lx) = x. P maps
the Banach space G onto the Banach space X and is continuous and linear. By the
open mapping theorem, P maps open sets onto open sets. Since P is also one to
one, this says that P −1 is continuous. Thus ||P −1x|| ≤K||x||. Hence
||Lx|| ≤max (||x||, ||Lx||) ≤K||x||
By Theorem 13.4 on Page 339, this shows L is continuous and proves the theorem.
The following corollary is quite useful. It shows how to obtain a new norm on
the domain of a closed operator such that the domain with this new norm becomes
a Banach space.
Corollary 13.18 Let L : D ⊆X →Y where X, Y are a Banach spaces, and L is
a closed operator. Then deﬁne a new norm on D by
||x||D ≡||x||X + ||Lx||Y .
Then D with this new norm is a Banach space.
Proof: If {xn} is a Cauchy sequence in D with this new norm, it follows both
{xn} and {Lxn} are Cauchy sequences and therefore, they converge. Since L is
closed, xn →x and Lxn →Lx for some x ∈D. Thus ||xn −x||D →0.
13.2
Hahn Banach Theorem
The closed graph, open mapping, and uniform boundedness theorems are the three
major topological theorems in functional analysis. The other major theorem is the
Hahn-Banach theorem which has nothing to do with topology. Before presenting
this theorem, here are some preliminaries about partially ordered sets.
Deﬁnition 13.19 Let F
be a nonempty set. F is called a partially ordered set if
there is a relation, denoted here by ≤, such that
x ≤x for all x ∈F.
If x ≤y and y ≤z then x ≤z.
C ⊆F is said to be a chain if every two elements of C are related. This means that
if x, y ∈C, then either x ≤y or y ≤x. Sometimes a chain is called a totally ordered
set. C is said to be a maximal chain if whenever D is a chain containing C, D = C.
The most common example of a partially ordered set is the power set of a given
set with ⊆being the relation. It is also helpful to visualize partially ordered sets
as trees.
Two points on the tree are related if they are on the same branch of
the tree and one is higher than the other. Thus two points on diﬀerent branches
would not be related although they might both be larger than some point on the

13.2.
HAHN BANACH THEOREM
347
trunk. You might think of many other things which are best considered as partially
ordered sets. Think of food for example. You might ﬁnd it diﬃcult to determine
which of two favorite pies you like better although you may be able to say very
easily that you would prefer either pie to a dish of lard topped with whipped cream
and mustard. The following theorem is equivalent to the axiom of choice. For a
discussion of this, see the appendix on the subject.
Theorem 13.20 (HausdorﬀMaximal Principle) Let F
be a nonempty partially
ordered set. Then there exists a maximal chain.
Deﬁnition 13.21 Let X be a real vector space ρ : X →R is called a gauge function
if
ρ(x + y) ≤ρ(x) + ρ(y),
ρ(ax) = aρ(x) if a ≥0.
(13.4)
Suppose M is a subspace of X and z /∈M. Suppose also that f is a linear
real-valued function having the property that f(x) ≤ρ(x) for all x ∈M. Consider
the problem of extending f to M ⊕Rz such that if F is the extended function,
F(y) ≤ρ(y) for all y ∈M ⊕Rz and F is linear. Since F is to be linear, it suﬃces
to determine how to deﬁne F(z). Letting a > 0, it is required to deﬁne F (z) such
that the following hold for all x, y ∈M.
f(x)
z }| {
F (x) + aF (z) = F(x + az) ≤ρ(x + az),
f(y)
z }| {
F (y) −aF (z) = F(y −az) ≤ρ(y −az).
(13.5)
Now if these inequalities hold for all y/a, they hold for all y because M is given to
be a subspace. Therefore, multiplying by a−1 13.4 implies that what is needed is
to choose F (z) such that for all x, y ∈M,
f(x) + F(z) ≤ρ(x + z), f(y) −ρ(y −z) ≤F(z)
and that if F (z) can be chosen in this way, this will satisfy 13.5 for all x, y and the
problem of extending f will be solved. Hence it is necessary to choose F(z) such
that for all x, y ∈M
f(y) −ρ(y −z) ≤F(z) ≤ρ(x + z) −f(x).
(13.6)
Is there any such number between f(y) −ρ(y −z) and ρ(x + z) −f(x) for every
pair x, y ∈M? This is where f(x) ≤ρ(x) on M and that f is linear is used.
For x, y ∈M,
ρ(x + z) −f(x) −[f(y) −ρ(y −z)]
= ρ(x + z) + ρ(y −z) −(f(x) + f(y))
≥ρ(x + y) −f(x + y) ≥0.

348
BANACH SPACES
Therefore there exists a number between
sup {f(y) −ρ(y −z) : y ∈M}
and
inf {ρ(x + z) −f(x) : x ∈M}
Choose F(z) to satisfy 13.6. This has proved the following lemma.
Lemma 13.22 Let M be a subspace of X, a real linear space, and let ρ be a gauge
function on X. Suppose f : M →R is linear, z /∈M, and f (x) ≤ρ (x) for all
x ∈M. Then f can be extended to M ⊕Rz such that, if F is the extended function,
F is linear and F(x) ≤ρ(x) for all x ∈M ⊕Rz.
With this lemma, the Hahn Banach theorem can be proved.
Theorem 13.23 (Hahn Banach theorem) Let X be a real vector space, let M be a
subspace of X, let f : M →R be linear, let ρ be a gauge function on X, and suppose
f(x) ≤ρ(x) for all x ∈M. Then there exists a linear function, F : X →R, such
that
a.) F(x) = f(x) for all x ∈M
b.) F(x) ≤ρ(x) for all x ∈X.
Proof: Let F = {(V, g) : V ⊇M, V is a subspace of X, g : V →R is linear,
g(x) = f(x) for all x ∈M, and g(x) ≤ρ(x) for x ∈V }. Then (M, f) ∈F so F ̸= ∅.
Deﬁne a partial order by the following rule.
(V, g) ≤(W, h)
means
V ⊆W and h(x) = g(x) if x ∈V.
By Theorem 13.20, there exists a maximal chain, C ⊆F. Let Y = ∪{V : (V, g) ∈C}
and let h : Y →R be deﬁned by h(x) = g(x) where x ∈V and (V, g) ∈C. This
is well deﬁned because if x ∈V1 and V2 where (V1, g1) and (V2, g2) are both in the
chain, then since C is a chain, the two element related. Therefore, g1 (x) = g2 (x).
Also h is linear because if ax + by ∈Y , then x ∈V1 and y ∈V2 where (V1, g1)
and (V2, g2) are elements of C. Therefore, letting V denote the larger of the two Vi,
and g be the function that goes with V , it follows ax + by ∈V where (V, g) ∈C.
Therefore,
h (ax + by)
=
g (ax + by)
=
ag (x) + bg (y)
=
ah (x) + bh (y) .
Also, h(x) = g (x) ≤ρ(x) for any x ∈Y because for such x, x ∈V where (V, g) ∈C.
Is Y = X? If not, there exists z ∈X \ Y and there exists an extension of h to
Y ⊕Rz using Lemma 13.22. Letting h denote this extended function, contradicts

13.2.
HAHN BANACH THEOREM
349
the maximality of C. Indeed, C ∪{
¡
Y ⊕Rz, h
¢
} would be a longer chain. This
proves the Hahn Banach theorem.
This is the original version of the theorem. There is also a version of this theorem
for complex vector spaces which is based on a trick.
Corollary 13.24 (Hahn Banach) Let M be a subspace of a complex normed linear
space, X, and suppose f : M →C is linear and satisﬁes |f(x)| ≤K||x|| for all
x ∈M.
Then there exists a linear function, F, deﬁned on all of X such that
F(x) = f(x) for all x ∈M and |F(x)| ≤K||x|| for all x.
Proof: First note f(x) = Re f(x) + i Im f (x) and so
Re f(ix) + i Im f(ix) = f(ix) = if(x) = i Re f(x) −Im f(x).
Therefore, Im f(x) = −Re f(ix), and
f(x) = Re f(x) −i Re f(ix).
This is important because it shows it is only necessary to consider Re f in under-
standing f. Now it happens that Re f is linear with respect to real scalars so the
above version of the Hahn Banach theorem applies. This is shown next.
If c is a real scalar
Re f(cx) −i Re f(icx) = cf(x) = c Re f(x) −ic Re f(ix).
Thus Re f(cx) = c Re f(x). Also,
Re f(x + y) −i Re f(i (x + y))
=
f(x + y)
=
f (x) + f (y)
= Re f(x) −i Re f(ix) + Re f(y) −i Re f(iy).
Equating real parts, Re f(x + y) = Re f(x) + Re f(y). Thus Re f is linear with
respect to real scalars as hoped.
Consider X as a real vector space and let ρ(x) ≡K||x||. Then for all x ∈M,
| Re f(x)| ≤|f (x)| ≤K||x|| = ρ(x).
From Theorem 13.23, Re f may be extended to a function, h which satisﬁes
h(ax + by)
=
ah(x) + bh(y) if a, b ∈R
h(x)
≤
K||x|| for all x ∈X.
Actually, |h (x)| ≤K ||x|| . The reason for this is that h (−x) = −h (x) ≤K ||−x|| =
K ||x|| and therefore, h (x) ≥−K ||x||. Let
F(x) ≡h(x) −ih(ix).

350
BANACH SPACES
By arguments similar to the above, F is linear.
F (ix)
=
h (ix) −ih (−x)
=
ih (x) + h (ix)
=
i (h (x) −ih (ix)) = iF (x) .
If c is a real scalar,
F (cx)
=
h(cx) −ih(icx)
=
ch (x) −cih (ix) = cF (x)
Now
F (x + y)
=
h(x + y) −ih(i (x + y))
=
h (x) + h (y) −ih (ix) −ih (iy)
=
F (x) + F (y) .
Thus
F ((a + ib) x)
=
F (ax) + F (ibx)
=
aF (x) + ibF (x)
=
(a + ib) F (x) .
This shows F is linear as claimed.
Now wF(x) = |F(x)| for some |w| = 1. Therefore
|F(x)|
=
wF(x) = h(wx) −
must equal zero
z }| {
ih(iwx)
= h(wx)
=
|h(wx)| ≤K||wx|| = K ||x|| .
This proves the corollary.
Deﬁnition 13.25 Let X be a Banach space. Denote by X′ the space of continuous
linear functions which map X to the ﬁeld of scalars.
Thus X′ = L(X, F). By
Theorem 13.7 on Page 340, X′ is a Banach space. Remember with the norm deﬁned
on L (X, F),
||f|| = sup{|f(x)| : ||x|| ≤1}
X′ is called the dual space.
Deﬁnition 13.26 Let X and Y be Banach spaces and suppose L ∈L(X, Y ). Then
deﬁne the adjoint map in L(Y ′, X′), denoted by L∗, by
L∗y∗(x) ≡y∗(Lx)
for all y∗∈Y ′.

13.2.
HAHN BANACH THEOREM
351
The following diagram is a good one to help remember this deﬁnition.
X′
L∗
←
Y ′
X
→
L
Y
This is a generalization of the adjoint of a linear transformation on an inner
product space. Recall
(Ax, y) = (x, A∗y)
What is being done here is to generalize this algebraic concept to arbitrary Banach
spaces.
There are some issues which need to be discussed relative to the above
deﬁnition. First of all, it must be shown that L∗y∗∈X′. Also, it will be useful to
have the following lemma which is a useful application of the Hahn Banach theorem.
Lemma 13.27 Let X be a normed linear space and let x ∈X. Then there exists
x∗∈X′ such that ||x∗|| = 1 and x∗(x) = ||x||.
Proof: Let f : Fx →F be deﬁned by f(αx) = α||x||. Then for y = αx ∈Fx,
|f (y)| = |f (αx)| = |α| ||x|| = |y| .
By the Hahn Banach theorem, there exists x∗∈X′ such that x∗(αx) = f(αx) and
||x∗|| ≤1. Since x∗(x) = ||x|| it follows that ||x∗|| = 1 because
||x∗|| ≥
¯¯¯¯x∗
µ x
||x||
¶¯¯¯¯ = ||x||
||x|| = 1.
This proves the lemma.
Theorem 13.28 Let L ∈L(X, Y ) where X and Y are Banach spaces. Then
a.) L∗∈L(Y ′, X′) as claimed and ||L∗|| = ||L||.
b.) If L maps one to one onto a closed subspace of Y , then L∗is onto.
c.) If L maps onto a dense subset of Y , then L∗is one to one.
Proof: It is routine to verify L∗y∗and L∗are both linear. This follows imme-
diately from the deﬁnition. As usual, the interesting thing concerns continuity.
||L∗y∗|| = sup
||x||≤1
|L∗y∗(x)| = sup
||x||≤1
|y∗(Lx)| ≤||y∗|| ||L|| .
Thus L∗is continuous as claimed and ||L∗|| ≤||L|| .
By Lemma 13.27, there exists y∗
x ∈Y ′ such that ||y∗
x|| = 1 and y∗
x (Lx) =
||Lx|| .Therefore,
||L∗||
=
sup
||y∗||≤1
||L∗y∗|| =
sup
||y∗||≤1
sup
||x||≤1
|L∗y∗(x)|
=
sup
||y∗||≤1
sup
||x||≤1
|y∗(Lx)| = sup
||x||≤1
sup
||y∗||≤1
|y∗(Lx)|
≥
sup
||x||≤1
|y∗
x (Lx)| = sup
||x||≤1
||Lx|| = ||L||

352
BANACH SPACES
showing that ||L∗|| ≥||L|| and this shows part a.).
If L is one to one and onto a closed subset of Y , then L (X) being a closed
subspace of a Banach space, is itself a Banach space and so the open mapping
theorem implies L−1 : L(X) →X is continuous. Hence
||x|| = ||L−1Lx|| ≤
¯¯¯¯L−1¯¯¯¯ ||Lx||
Now let x∗∈X′ be given. Deﬁne f ∈L(L(X), C) by f(Lx) = x∗(x). The function,
f is well deﬁned because if Lx1 = Lx2, then since L is one to one, it follows x1 = x2
and so f (L (x1)) = x∗(x1) = x∗(x2) = f (L (x1)). Also, f is linear because
f (aL (x1) + bL (x2))
=
f (L (ax1 + bx2))
≡
x∗(ax1 + bx2)
=
ax∗(x1) + bx∗(x2)
=
af (L (x1)) + bf (L (x2)) .
In addition to this,
|f(Lx)| = |x∗(x)| ≤||x∗|| ||x|| ≤||x∗||
¯¯¯¯L−1¯¯¯¯ ||Lx||
and so the norm of f on L (X) is no larger than ||x∗||
¯¯¯¯L−1¯¯¯¯. By the Hahn Banach
theorem, there exists an extension of f to an element y∗∈Y ′ such that ||y∗|| ≤
||x∗||
¯¯¯¯L−1¯¯¯¯. Then
L∗y∗(x) = y∗(Lx) = f(Lx) = x∗(x)
so L∗y∗= x∗because this holds for all x. Since x∗was arbitrary, this shows L∗is
onto and proves b.).
Consider the last assertion. Suppose L∗y∗= 0. Is y∗= 0? In other words
is y∗(y) = 0 for all y ∈Y ? Pick y ∈Y . Since L (X) is dense in Y, there exists
a sequence, {Lxn} such that Lxn →y. But then by continuity of y∗, y∗(y) =
limn→∞y∗(Lxn) = limn→∞L∗y∗(xn) = 0. Since y∗(y) = 0 for all y, this implies
y∗= 0 and so L∗is one to one.
Corollary 13.29 Suppose X and Y are Banach spaces, L ∈L(X, Y ), and L is one
to one and onto. Then L∗is also one to one and onto.
There exists a natural mapping, called the James map from a normed linear
space, X, to the dual of the dual space which is described in the following deﬁnition.
Deﬁnition 13.30 Deﬁne J : X →X′′ by J(x)(x∗) = x∗(x).
Theorem 13.31 The map, J, has the following properties.
a.) J is one to one and linear.
b.) ||Jx|| = ||x|| and ||J|| = 1.
c.) J(X) is a closed subspace of X′′ if X is complete.
Also if x∗∈X′,
||x∗|| = sup {|x∗∗(x∗)| : ||x∗∗|| ≤1, x∗∗∈X′′} .

13.2.
HAHN BANACH THEOREM
353
Proof:
J (ax + by) (x∗)
≡
x∗(ax + by)
=
ax∗(x) + bx∗(y)
=
(aJ (x) + bJ (y)) (x∗) .
Since this holds for all x∗∈X′, it follows that
J (ax + by) = aJ (x) + bJ (y)
and so J is linear.
If Jx = 0, then by Lemma 13.27 there exists x∗such that
x∗(x) = ||x|| and ||x∗|| = 1. Then
0 = J(x)(x∗) = x∗(x) = ||x||.
This shows a.).
To show b.), let x ∈X and use Lemma 13.27 to obtain x∗∈X′ such that
x∗(x) = ||x|| with ||x∗|| = 1. Then
||x||
≥
sup{|y∗(x)| : ||y∗|| ≤1}
=
sup{|J(x)(y∗)| : ||y∗|| ≤1} = ||Jx||
≥
|J(x)(x∗)| = |x∗(x)| = ||x||
Therefore, ||Jx|| = ||x|| as claimed. Therefore,
||J|| = sup{||Jx|| : ||x|| ≤1} = sup{||x|| : ||x|| ≤1} = 1.
This shows b.).
To verify c.), use b.). If Jxn →y∗∗∈X′′ then by b.), xn is a Cauchy sequence
converging to some x ∈X because
||xn −xm|| = ||Jxn −Jxm||
and {Jxn} is a Cauchy sequence. Then Jx = limn→∞Jxn = y∗∗.
Finally, to show the assertion about the norm of x∗, use what was just shown
applied to the James map from X′ to X′′′ still referred to as J.
||x∗|| = sup {|x∗(x)| : ||x|| ≤1} = sup {|J (x) (x∗)| : ||Jx|| ≤1}
≤sup {|x∗∗(x∗)| : ||x∗∗|| ≤1} = sup {|J (x∗) (x∗∗)| : ||x∗∗|| ≤1}
≡||Jx∗|| = ||x∗||.
This proves the theorem.
Deﬁnition 13.32 When J maps X onto X′′, X is called reﬂexive.
It happens the Lp spaces are reﬂexive whenever p > 1. This is shown later.

354
BANACH SPACES
13.3
Weak And Weak ∗Topologies
13.3.1
Basic Deﬁnitions
Let X be a Banach space and let X′ be its dual space.1 For A′ a ﬁnite subset of
X′, denote by ρA′ the function deﬁned on X
ρA′ (x) ≡max
x∗∈A′ |x∗(x)|
(13.7)
and also let BA′ (x, r) be deﬁned by
BA′ (x, r) ≡{y ∈X : ρA′ (y −x) < r}
(13.8)
Then certain things are obvious. First of all, if a ∈F and x, y ∈X,
ρA′ (x + y)
≤
ρA′ (x) + ρA′ (y) ,
ρA′ (ax)
=
|a| ρA′ (x) .
Similarly, letting A be a ﬁnite subset of X, denote by ρA the function deﬁned
on X′
ρA (x∗) ≡max
x∈A |x∗(x)|
(13.9)
and let BA (x∗, r) be deﬁned by
BA (x∗, r) ≡{y∗∈X′ : ρA (y∗−x∗) < r} .
(13.10)
It is also clear that
ρA (x∗+ y∗)
≤
ρ (x∗) + ρA (y∗) ,
ρA (ax∗)
=
|a| ρA (x∗) .
Lemma 13.33 The sets, BA′ (x, r) where A′ is a ﬁnite subset of X′ and x ∈X
form a basis for a topology on X known as the weak topology. The sets BA (x∗, r)
where A is a ﬁnite subset of X and x∗∈X′ form a basis for a topology on X′
known as the weak ∗topology.
Proof: The two assertions are very similar. I will verify the one for the weak
topology. The union of these sets, BA′ (x, r) for x ∈X and r > 0 is all of X. Now
suppose z is contained in the intersection of two of these sets. Say
z ∈BA′ (x, r) ∩BA′
1 (x1, r1)
Then let C′ = A′ ∪A′
1 and let
0 < δ ≤min
³
r −ρA′ (z −x) , r1 −ρA′
1 (z −x1)
´
.
1Actually, all this works in much more general settings than this.

13.3.
WEAK AND WEAK ∗TOPOLOGIES
355
Consider y ∈BC′ (z, δ) . Then
r −ρA′ (z −x) ≥δ > ρC′ (y −z) ≥ρA′ (y −z)
and so
r > ρA′ (y −z) + ρA′ (z −x) ≥ρA′ (y −x)
which shows y ∈BA′ (x, r) . Similar reasoning shows y ∈BA′
1 (x1, r1) and so
BC′ (z, δ) ⊆BA′ (x, r) ∩BA′
1 (x1, r1) .
Therefore, the weak topology consists of the union of all sets of the form BA (x, r).
13.3.2
Banach Alaoglu Theorem
Why does anyone care about these topologies? The short answer is that in the
weak ∗topology, closed unit ball in X′ is compact. This is not true in the normal
topology. This wonderful result is the Banach Alaoglu theorem. First recall the
notion of the product topology, and the Tychonoﬀtheorem, Theorem 11.7 on Page
307 which are stated here for convenience.
Deﬁnition 13.34 Let I be a set and suppose for each i ∈I, (Xi, τ i) is a nonempty
topological space. The Cartesian product of the Xi, denoted by Q
i∈I Xi, consists
of the set of all choice functions deﬁned on I which select a single element of each
Xi. Thus f ∈Q
i∈I Xi means for every i ∈I, f (i) ∈Xi. The axiom of choice says
Q
i∈I Xi is nonempty. Let
Pj (A) =
Y
i∈I
Bi
where Bi = Xi if i ̸= j and Bj = A. A subbasis for a topology on the product
space consists of all sets Pj (A) where A ∈τ j. (These sets have an open set from
the topology of Xj in the jth slot and the whole space in the other slots.) Thus a
basis consists of ﬁnite intersections of these sets. Note that the intersection of two
of these basic sets is another basic set and their union yields Q
i∈I Xi. Therefore,
they satisfy the condition needed for a collection of sets to serve as a basis for a
topology. This topology is called the product topology and is denoted by Q τ i.
Theorem 13.35 If (Xi, τ i) is compact, then so is (Q
i∈I Xi, Q τ i).
The Banach Alaoglu theorem is as follows.
Theorem 13.36 Let B′ be the closed unit ball in X′. Then B′ is compact in the
weak ∗topology.
Proof: By the Tychonoﬀtheorem, Theorem 13.35
P ≡
Y
x∈X
B (0, ||x||)

356
BANACH SPACES
is compact in the product topology where the topology on B (0, ||x||) is the usual
topology of F. Recall P is the set of functions which map a point, x ∈X to a point
in B (0, ||x||). Therefore, B′ ⊆P. Also the basic open sets in the weak ∗topology
on B′ are obtained as the intersection of basic open sets in the product topology
of P to B′ and so it suﬃces to show B′ is a closed subset of P. Suppose then that
f ∈P \ B′. It follows f cannot be linear. There are two ways this can happen. One
way is that for some x, y
f (x + y) ̸= f (x) + f (y)
for some x, y ∈X. However, if g is close enough to f at the three points, x + y, x,
and y, the above inequality will hold for g in place of f. In other words there is a
basic open set containing f such that for all g in this basic open set, g /∈B′. A
similar consideration applies in case f (λx) ̸= λf (x) for some scalar, λ and x. Since
P \ B′ is open, it follows B′ is a closed subset of P and is therefore, compact. This
proves the theorem.
Sometimes one can consider the weak ∗topology in terms of a metric space.
Theorem 13.37 If K ⊆X′ is compact in the weak ∗topology and X is separable
then there exists a metric, d, on K such that if τ d is the topology on K induced by
d and if τ is the topology on K induced by the weak ∗topology of X′, then τ = τ d.
Thus one can consider K with the weak ∗topology as a metric space.
Proof: Let D = {xn} be the dense countable subset. The metric is
d (f, g) ≡
∞
X
n=1
2−n
ρxn (f −g)
1 + ρxn (f −g)
where ρxn (f) = |f (xn)|. Clearly d (f, g) = d (g, f) ≥0. If d (f, g) = 0, then this
requires f (xn) = g (xn) for all xn ∈D. Since f and g are continuous and D is
dense, this requires that f (x) = g (x) for all x. It is routine to verify the triangle
inequality from the easy to establish inequality,
x
1 + x +
y
1 + y ≥
x + y
1 + x + y ,
valid whenever x, y ≥0. Therefore this is a metric. Now for each n
g →
ρxn (f −g)
1 + ρxn (f −g)
is a continuous function from (K, τ) to [0, ∞) and also the above sum deﬁning d
converges uniformly. It follows
g →d (f, g)
is continuous. Therefore, the ball with respect to d,
Bd (f, r) ≡{g ∈K : d (g, f) < r}

13.3.
WEAK AND WEAK ∗TOPOLOGIES
357
is open in τ which implies τ d ⊆τ.
Now suppose U ∈τ. Then K \ U is closed in K. Hence, K \ U is compact in τ
because it is a closed subset of the compact set K. It follows that K \ U is compact
with respect to τ d because τ d ⊆τ. But (K, τ d) is a Hausdorﬀspace and so K \ U
must be closed with respect to τ d. This implies U ∈τ d. Thus τ ⊆τ d and this
proves τ = τ d. This proves the theorem.
The fact that this set with the weak ∗
topology can be considered a metric
space is very signiﬁcant because if a point is a limit point in a metric space, one
can extract a convergent sequence.
Corollary 13.38 If X is separable and K ⊆X′ is compact in the weak ∗topology,
then K is sequentially compact.
That is, if {fn}∞
n=1 ⊆K, then there exists a
subsequence fnk and f ∈K such that for all x ∈X,
lim
k→∞fnk (x) = f (x).
Proof: By Theorem 13.37, K is a metric space for the metric described there
and it is compact.
Therefore by the characterization of compact metric spaces,
Proposition 6.12 on Page 136, K is sequentially compact. This proves the corollary.
13.3.3
Eberlein Smulian Theorem
Next consider the weak topology. The most interesting results have to do with a
reﬂexive Banach space. The following lemma ties together the weak and weak ∗
topologies in the case of a reﬂexive Banach space.
Lemma 13.39 Let J : X →X′′ be the James map
Jx (f) ≡f (x)
and let X be reﬂexive so that J is onto. Then J is a homeomorphism of (X, weak topology)
and (X′′, weak ∗topology).This means J is one to one, onto, and both J and J−1
are continuous.
Proof: Let f ∈X′ and let
Bf (x, r) ≡{y : |f (x) −f (y)| < r}.
Thus Bf (x, r) is a subbasic set for the weak topology on X. Now by the deﬁnition
of J,
y ∈Bf (x, r) if and only if |Jy (f) −Jx (f)| < r
if and only if Jy ∈Bf (Jx, r) ≡
{y∗∗∈X′′ : |y∗∗(f) −J (x) (f)| < r},
a subbasic set for the weak ∗topology on X′′. Since J−1 and J are one to one and
onto and map subbasic sets to subbasic sets, it follows that J is a homeomorphism.
This proves the Lemma.
The following is an easy corollary.

358
BANACH SPACES
Corollary 13.40 If X is a reﬂexive Banach space, then the closed unit ball is
weakly compact.
Proof: Let B be the closed unit ball. Then B = J−1 (B∗∗) where B∗∗is the
unit ball in X′′ which is compact in the weak ∗topology. Therefore B is weakly
compact because J−1 is continuous.
Corollary 13.41 Let X be a reﬂexive Banach space. If K ⊆X is compact in the
weak topology and X′ is separable then there exists a metric d, on K such that if
τ d is the topology on K induced by d and if τ is the topology on K induced by the
weak topology of X, then τ = τ d. Thus one can consider K with the weak topology
as a metric space.
Proof:
This follows from Theorem 13.37 and Lemma 13.39.
Lemma 13.39
implies J (K) is compact in X′′. Then since X′ is separable, there is a metric, d′′
on J (K) which delivers the weak ∗topology. Let d (x, y) ≡d′′ (Jx, Jy) . Then
(K, τ d)
J→(J (K) , τ d′′)
id
→(J (K) , τ weak ∗)
J−1
→(K, τ weak)
and all the maps are homeomorphisms.
Next is the Eberlein Smulian theorem which states that a Banach space is re-
ﬂexive if and only if the closed unit ball is weakly sequentially compact. Actually,
only half the theorem is proved here, the more useful only if part. The book by
Yoshida [52] has the complete theorem discussed. First here is an interesting lemma
for its own sake.
Lemma 13.42 A closed subspace of a reﬂexive Banach space is reﬂexive.
Proof: Let Y be the closed subspace of the reﬂexive space, X. Consider the
following diagram
Y ′′
i∗∗1-1
→
X′′
Y ′
i∗onto
←
X′
Y
i→
X
This diagram follows from Theorem 13.28 on Page 351, the theorem on adjoints.
Now let y∗∗∈Y ′′. Then i∗∗y∗∗= JX (y) because X is reﬂexive. I want to show
that y ∈Y . If it is not in Y then since Y is closed, there exists x∗∈X′ such that
x∗(y) ̸= 0 but x∗(Y ) = 0. Then i∗x∗= 0. Hence
0 = y∗∗(i∗x∗) = i∗∗y∗∗(x∗) = J (y) (x∗) = x∗(y) ̸= 0,
a contradiction. Hence y ∈Y . Letting JY denote the James map from Y to Y ′′
and x∗∈X′,
y∗∗(i∗x∗)
=
i∗∗y∗∗(x∗) = JX (y) (x∗)
=
x∗(y) = x∗(iy) = i∗x∗(y) = JY (y) (i∗x∗)
Since i∗is onto, this shows y∗∗= JY (y) and this proves the lemma.

13.3.
WEAK AND WEAK ∗TOPOLOGIES
359
Theorem 13.43 (Eberlein Smulian) The closed unit ball in a reﬂexive Banach
space X, is weakly sequentially compact.
By this is meant that if {xn} is con-
tained in the closed unit ball, there exists a subsequence, {xnk} and x ∈X such that
for all x∗∈X′,
x∗(xnk) →x∗(x) .
Proof: Let {xn} ⊆B ≡B (0, 1). Let Y be the closure of the linear span of
{xn}. Thus Y is a separable. It is reﬂexive because it is a closed subspace of a
reﬂexive space so the above lemma applies. By the Banach Alaoglu theorem, the
closed unit ball B∗in Y ′ is weak ∗compact. Also by Theorem 13.37, B∗is a metric
space with a suitable metric. Thus B∗is complete and totally bounded with respect
to this metric and it follows that B∗with the weak ∗topology is separable. This
implies Y ′ is also separable in the weak ∗topology. To see this, let {y∗
n} ≡D be a
weak ∗dense set in B∗and let y∗∈Y ′. Let p be a large enough positive rational
number that y∗/p ∈B∗. Then if A is any ﬁnite set from Y, there exists y∗
n ∈D such
that ρA (y∗/p −y∗
n) < ε
p. It follows py∗
n ∈BA (y∗, ε) showing that rational multiples
of D are weak ∗dense in Y ′. Since Y is reﬂexive, the weak and weak ∗topologies on
Y ′ coincide and so Y ′ is weakly separable. Since Y ′ is separable, Corollary 13.38
implies B∗∗, the closed unit ball in Y ′′ is weak ∗sequentially compact. Then by
Lemma 13.39 B, the unit ball in Y , is weakly sequentially compact. It follows there
exists a subsequence xnk, of the sequence {xn} and a point x ∈Y , such that for all
f ∈Y ′,
f (xnk) →f (x).
Now if x∗∈X′, and i is the inclusion map of Y into X,
x∗(xnk) = i∗x∗(xnk) →i∗x∗(x) = x∗(x).
which shows xnk converges weakly and this shows the unit ball in X is weakly
sequentially compact.
Corollary 13.44 Let {xn} be any bounded sequence in a reﬂexive Banach space,
X. Then there exists x ∈X and a subsequence, {xnk} such that for all x∗∈X′,
lim
k→∞x∗(xnk) = x∗(x)
Proof:
If a subsequence, xnk has ||xnk|| →0, then the conclusion follows.
Simply let x = 0. Suppose then that ||xn|| is bounded away from 0.
That is,
||xn|| ∈[δ, C]. Take a subsequence such that ||xnk|| →a. Then consider xnk/ ||xnk||.
By the Eberlein Smulian theorem, this subsequence has a further subsequence,
xnkj /
¯¯¯
¯¯¯xnkj
¯¯¯
¯¯¯ which converges weakly to x ∈B where B is the closed unit ball.
It follows from routine considerations that xnkj →ax weakly.
This proves the
corollary.

360
BANACH SPACES
13.4
Exercises
1. Is N a Gδ set? What about Q? What about a countable dense subset of a
complete metric space?
2. ↑Let f : R →C be a function. Deﬁne the oscillation of a function in B (x, r)
by ωrf(x) = sup{|f(z) −f(y)| : y, z ∈B(x, r)}. Deﬁne the oscillation of the
function at the point, x by ωf(x) = limr→0 ωrf(x). Show f is continuous
at x if and only if ωf(x) = 0.
Then show the set of points where f is
continuous is a Gδ set (try Un = {x : ωf(x) <
1
n}).
Does there exist a
function continuous at only the rational numbers? Does there exist a function
continuous at every irrational and discontinuous elsewhere? Hint: Suppose
D is any countable set, D = {di}∞
i=1, and deﬁne the function, fn (x) to equal
zero for every x /∈{d1, · · ·, dn} and 2−n for x in this ﬁnite set. Then consider
g (x) ≡P∞
n=1 fn (x). Show that this series converges uniformly.
3. Let f ∈C([0, 1]) and suppose f ′(x) exists. Show there exists a constant, K,
such that |f(x) −f(y)| ≤K|x −y| for all y ∈[0, 1]. Let Un = {f ∈C([0, 1])
such that for each x ∈[0, 1] there exists y ∈[0, 1] such that |f(x) −f(y)| >
n|x−y|}. Show that Un is open and dense in C([0, 1]) where for f ∈C ([0, 1]),
||f|| ≡sup {|f (x)| : x ∈[0, 1]} .
Show that ∩nUn is a dense Gδ set of nowhere diﬀerentiable continuous func-
tions.
Thus every continuous function is uniformly close to one which is
nowhere diﬀerentiable.
4. ↑Suppose f (x) = P∞
k=1 uk (x) where the convergence is uniform and each uk
is a polynomial. Is it reasonable to conclude that f ′ (x) = P∞
k=1 u′
k (x)? The
answer is no. Use Problem 3 and the Weierstrass approximation theorem do
show this.
5. Let X be a normed linear space. We say A ⊆X is “weakly bounded” if for
each x∗∈X′, sup{|x∗(x)| : x ∈A} < ∞, while A is bounded if sup{||x|| : x ∈
A} < ∞. Show A is weakly bounded if and only if it is bounded.
6. Let X and Y be two Banach spaces. Deﬁne the norm
|||(x, y)||| ≡||x||X + ||y||Y .
Show this is a norm on X × Y which is equivalent to the norm given in the
chapter for X × Y . Can you do the same for the norm deﬁned for p > 1 by
|(x, y)| ≡(||x||p
X + ||y||p
Y )1/p?
7. Let f be a 2π periodic locally integrable function on R. The Fourier series for
f is given by
∞
X
k=−∞
akeikx ≡lim
n→∞
n
X
k=−n
akeikx ≡lim
n→∞Snf (x)

13.4.
EXERCISES
361
where
ak = 1
2π
Z π
−π
e−ikxf (x) dx.
Show
Snf (x) =
Z π
−π
Dn (x −y) f (y) dy
where
Dn(t) = sin((n + 1
2)t)
2π sin( t
2)
.
Verify that
R π
−π Dn (t) dt = 1. Also show that if g ∈L1 (R) , then
lim
a→∞
Z
R
g (x) sin (ax) dx = 0.
This last is called the Riemann Lebesgue lemma. Hint: For the last part,
assume ﬁrst that g ∈C∞
c (R) and integrate by parts. Then exploit density of
the set of functions in L1 (R).
8. ↑It turns out that the Fourier series sometimes converges to the function point-
wise. Suppose f is 2π periodic and Holder continuous. That is |f (x) −f (y)| ≤
K |x −y|θ where θ ∈(0, 1]. Show that if f is like this, then the Fourier series
converges to f at every point. Next modify your argument to show that if
at every point, x, |f (x+) −f (y)| ≤K |x −y|θ for y close enough to x and
larger than x and |f (x−) −f (y)| ≤K |x −y|θ for every y close enough to x
and smaller than x, then Snf (x) →f(x+)+f(x−)
2
, the midpoint of the jump
of the function. Hint: Use Problem 7.
9. ↑Let Y = {f such that f is continuous, deﬁned on R, and 2π periodic}. Deﬁne
||f||Y = sup{|f(x)| : x ∈[−π, π]}. Show that (Y, || ||Y ) is a Banach space. Let
x ∈R and deﬁne Ln(f) = Snf(x). Show Ln ∈Y ′ but limn→∞||Ln|| = ∞.
Show that for each x ∈R, there exists a dense Gδ subset of Y such that for f
in this set, |Snf(x)| is unbounded. Finally, show there is a dense Gδ subset of
Y having the property that |Snf(x)| is unbounded on the rational numbers.
Hint: To do the ﬁrst part, let f(y) approximate sgn(Dn(x−y)). Here sgn r =
1 if r > 0, −1 if r < 0 and 0 if r = 0. This rules out one possibility of the
uniform boundedness principle. After this, show the countable intersection of
dense Gδ sets must also be a dense Gδ set.
10. Let α ∈(0, 1]. Deﬁne, for X a compact subset of Rp,
Cα (X; Rn) ≡{f ∈C (X; Rn) : ρα (f) + ||f|| ≡||f||α < ∞}
where
||f|| ≡sup{|f (x)| : x ∈X}

362
BANACH SPACES
and
ρα (f) ≡sup{|f (x) −f (y)|
|x −y|α
: x, y ∈X, x ̸= y}.
Show that (Cα (X; Rn) , ||·||α) is a complete normed linear space.
This is
called a Holder space. What would this space consist of if α > 1?
11. ↑Now recall Problem 10 about the Holder spaces.
Let X be the Holder
functions which are periodic of period 2π. Deﬁne Lnf (x) = Snf (x) where
Ln : X →Y for Y given in Problem 9. Show ||Ln|| is bounded independent
of n. Conclude that Lnf →f in Y for all f ∈X. In other words, for the
Holder continuous and 2π periodic functions, the Fourier series converges to
the function uniformly. Hint: Lnf (x) is given by
Lnf (x) =
Z π
−π
Dn (y) f (x −y) dy
where f (x −y) = f (x) + g (x, y) where |g (x, y)| ≤C |y|α. Use the fact the
Dirichlet kernel integrates to one to write
¯¯¯¯
Z π
−π
Dn (y) f (x −y) dy
¯¯¯¯ ≤
=|f(x)|
z
}|
{
¯¯¯¯
Z π
−π
Dn (y) f (x) dy
¯¯¯¯
+C
¯¯¯¯
Z π
−π
sin
µµ
n + 1
2
¶
y
¶
(g (x, y) / sin (y/2)) dy
¯¯¯¯
Show the functions, y →g (x, y) / sin (y/2) are bounded in L1 independent of
x and get a uniform bound on ||Ln||. Now use a similar argument to show
{Lnf} is equicontinuous in addition to being uniformly bounded.
If Lnf
fails to converge to f uniformly, then there exists ε > 0 and a subsequence,
nk such that ||Lnkf −f||∞≥ε where this is the norm in Y or equivalently
the sup norm on [−π, π]. By the Arzela Ascoli theorem, there is a further
subsequence, Lnkl f which converges uniformly on [−π, π]. But by Problem 8
Lnf (x) →f (x).
12. Let X be a normed linear space and let M be a convex open set containing
0. Deﬁne
ρ(x) = inf{t > 0 : x
t ∈M}.
Show ρ is a gauge function deﬁned on X. This particular example is called a
Minkowski functional. It is of fundamental importance in the study of locally
convex topological vector spaces. A set, M, is convex if λx + (1 −λ)y ∈M
whenever λ ∈[0, 1] and x, y ∈M.
13. ↑The Hahn Banach theorem can be used to establish separation theorems. Let
M be an open convex set containing 0. Let x /∈M. Show there exists x∗∈X′
such that Re x∗(x) ≥1 > Re x∗(y) for all y ∈M. Hint: If y ∈M, ρ(y) < 1.

13.4.
EXERCISES
363
Show this. If x /∈M, ρ(x) ≥1. Try f(αx) = αρ(x) for α ∈R. Then extend
f to the whole space using the Hahn Banach theorem and call the result F,
show F is continuous, then ﬁx it so F is the real part of x∗∈X′.
14. A Banach space is said to be strictly convex if whenever ||x|| = ||y|| and x ̸= y,
then
¯¯¯¯
¯¯¯¯
x + y
2
¯¯¯¯
¯¯¯¯ < ||x||.
F : X →X′ is said to be a duality map if it satisﬁes the following: a.)
||F(x)|| = ||x||. b.) F(x)(x) = ||x||2. Show that if X′ is strictly convex, then
such a duality map exists. The duality map is an attempt to duplicate some
of the features of the Riesz map in Hilbert space which is discussed in the
chapter on Hilbert space. Hint: For an arbitrary Banach space, let
F (x) ≡
n
x∗: ||x∗|| ≤||x|| and x∗(x) = ||x||2o
Show F (x) ̸= ∅by using the Hahn Banach theorem on f(αx) = α||x||2.
Next show F (x) is closed and convex.
Finally show that you can replace
the inequality in the deﬁnition of F (x) with an equal sign. Now use strict
convexity to show there is only one element in F (x).
15. Prove the following theorem which is an improved version of the open mapping
theorem, [17]. Let X and Y be Banach spaces and let A ∈L (X, Y ). Then
the following are equivalent.
AX = Y,
A is an open map.
There exists a constant M such that for every y ∈Y , there exists x ∈X with
y = Ax and
||x|| ≤M ||y||.
Note this gives the equivalence between A being onto and A being an open
map. The open mapping theorem says that if A is onto then it is open.
16. Suppose D ⊆X and D is dense in X. Suppose L : D →Y is linear and
||Lx|| ≤K||x|| for all x ∈D. Show there is a unique extension of L, eL, deﬁned
on all of X with ||eLx|| ≤K||x|| and eL is linear. You do not get uniqueness
when you use the Hahn Banach theorem. Therefore, in the situation of this
problem, it is better to use this result.
17. ↑A Banach space is uniformly convex if whenever ||xn||, ||yn|| ≤1 and
||xn + yn|| →2, it follows that ||xn −yn|| →0.
Show uniform convexity
implies strict convexity (See Problem 14). Hint: Suppose it is not strictly
convex. Then there exist ||x|| and ||y|| both equal to 1 and
¯¯¯¯ xn+yn
2
¯¯¯¯ = 1
consider xn ≡x and yn ≡y, and use the conditions for uniform convexity to
get a contradiction. It can be shown that Lp is uniformly convex whenever
∞> p > 1. See Hewitt and Stromberg [26] or Ray [43].

364
BANACH SPACES
18. Show that a closed subspace of a reﬂexive Banach space is reﬂexive. Hint:
The proof of this is an exercise in the use of the Hahn Banach theorem. Let
Y be the closed subspace of the reﬂexive space X and let y∗∗∈Y ′′. Then
i∗∗y∗∗∈X′′ and so i∗∗y∗∗= Jx for some x ∈X because X is reﬂexive.
Now argue that x ∈Y as follows. If x /∈Y , then there exists x∗such that
x∗(Y ) = 0 but x∗(x) ̸= 0. Thus, i∗x∗= 0. Use this to get a contradiction.
When you know that x = y ∈Y , the Hahn Banach theorem implies i∗is onto
Y ′ and for all x∗∈X′,
y∗∗(i∗x∗) = i∗∗y∗∗(x∗) = Jx (x∗) = x∗(x) = x∗(iy) = i∗x∗(y).
19. We say that xn converges weakly to x if for every x∗∈X′, x∗(xn) →x∗(x).
xn ⇀x denotes weak convergence. Show that if ||xn −x|| →0, then xn ⇀x.
20. ↑Show that if X is uniformly convex, then if xn ⇀x and ||xn|| →||x||, it
follows ||xn−x|| →0. Hint: Use Lemma 13.27 to obtain f ∈X′ with ||f|| = 1
and f(x) = ||x||.
See Problem 17 for the deﬁnition of uniform convexity.
Now by the weak convergence, you can argue that if x ̸= 0, f (xn/ ||xn||) →
f (x/ ||x||). You also might try to show this in the special case where ||xn|| =
||x|| = 1.
21. Suppose L ∈L (X, Y ) and M ∈L (Y, Z). Show ML ∈L (X, Z) and that
(ML)∗= L∗M ∗.
22. Let X and Y be Banach spaces and suppose f ∈L (X, Y ) is compact. Recall
this means that if B is a bounded set in X, then f (B) has compact closure
in Y. Show that f ∗is also a compact map. Hint: Take a bounded subset of
Y ′, S. You need to show f ∗(S) is totally bounded. You might consider using
the Ascoli Arzela theorem on the functions of S applied to f (B) where B is
the closed unit ball in X.

Hilbert Spaces
14.1
Basic Theory
Deﬁnition 14.1 Let X be a vector space. An inner product is a mapping from
X × X to C if X is complex and from X × X to R if X is real, denoted by (x, y)
which satisﬁes the following.
(x, x) ≥0, (x, x) = 0 if and only if x = 0,
(14.1)
(x, y) = (y, x).
(14.2)
For a, b ∈C and x, y, z ∈X,
(ax + by, z) = a(x, z) + b(y, z).
(14.3)
Note that 14.2 and 14.3 imply (x, ay + bz) = a(x, y) + b(x, z). Such a vector space
is called an inner product space.
The Cauchy Schwarz inequality is fundamental for the study of inner product
spaces.
Theorem 14.2 (Cauchy Schwarz) In any inner product space
|(x, y)| ≤||x|| ||y||.
Proof: Let ω ∈C, |ω| = 1, and ω(x, y) = |(x, y)| = Re(x, yω). Let
F(t) = (x + tyω, x + tωy).
If y = 0 there is nothing to prove because
(x, 0) = (x, 0 + 0) = (x, 0) + (x, 0)
and so (x, 0) = 0. Thus, it can be assumed y ̸= 0. Then from the axioms of the
inner product,
F(t) = ||x||2 + 2t Re(x, ωy) + t2||y||2 ≥0.
365

366
HILBERT SPACES
This yields
||x||2 + 2t|(x, y)| + t2||y||2 ≥0.
Since this inequality holds for all t ∈R, it follows from the quadratic formula that
4|(x, y)|2 −4||x||2||y||2 ≤0.
This yields the conclusion and proves the theorem.
Proposition 14.3 For an inner product space, ||x|| ≡(x, x)1/2 does specify a
norm.
Proof: All the axioms are obvious except the triangle inequality. To verify this,
||x + y||2
≡
(x + y, x + y) ≡||x||2 + ||y||2 + 2 Re (x, y)
≤
||x||2 + ||y||2 + 2 |(x, y)|
≤
||x||2 + ||y||2 + 2 ||x|| ||y|| = (||x|| + ||y||)2.
The following lemma is called the parallelogram identity.
Lemma 14.4 In an inner product space,
||x + y||2 + ||x −y||2 = 2||x||2 + 2||y||2.
The proof, a straightforward application of the inner product axioms, is left to
the reader.
Lemma 14.5 For x ∈H, an inner product space,
||x|| = sup
||y||≤1
|(x, y)|
(14.4)
Proof: By the Cauchy Schwarz inequality, if x ̸= 0,
||x|| ≥sup
||y||≤1
|(x, y)| ≥
µ
x,
x
||x||
¶
= ||x|| .
It is obvious that 14.4 holds in the case that x = 0.
Deﬁnition 14.6 A Hilbert space is an inner product space which is complete. Thus
a Hilbert space is a Banach space in which the norm comes from an inner product
as described above.
In Hilbert space, one can deﬁne a projection map onto closed convex nonempty
sets.
Deﬁnition 14.7 A set, K, is convex if whenever λ ∈[0, 1] and x, y ∈K, λx+(1−
λ)y ∈K.

14.1.
BASIC THEORY
367
Theorem 14.8 Let K be a closed convex nonempty subset of a Hilbert space, H,
and let x ∈H. Then there exists a unique point Px ∈K such that ||Px −x|| ≤
||y −x|| for all y ∈K.
Proof: Consider uniqueness. Suppose that z1 and z2 are two elements of K
such that for i = 1, 2,
||zi −x|| ≤||y −x||
(14.5)
for all y ∈K. Also, note that since K is convex,
z1 + z2
2
∈K.
Therefore, by the parallelogram identity,
||z1 −x||2
≤
||z1 + z2
2
−x||2 = ||z1 −x
2
+ z2 −x
2
||2
=
2(||z1 −x
2
||2 + ||z2 −x
2
||2) −||z1 −z2
2
||2
=
1
2 ||z1 −x||2 + 1
2 ||z2 −x||2 −||z1 −z2
2
||2
≤
||z1 −x||2 −||z1 −z2
2
||2,
where the last inequality holds because of 14.5 letting zi = z2 and y = z1. Hence
z1 = z2 and this shows uniqueness.
Now let λ = inf{||x −y|| : y ∈K} and let yn be a minimizing sequence. This
means {yn} ⊆K satisﬁes limn→∞||x −yn|| = λ. Now the following follows from
properties of the norm.
||yn −x + ym −x||2 = 4(||yn + ym
2
−x||2)
Then by the parallelogram identity, and convexity of K, yn+ym
2
∈K, and so
|| (yn −x) −(ym −x) ||2
=
2(||yn −x||2 + ||ym −x||2) −
=||yn−x+ym−x||2
z
}|
{
4(||yn + ym
2
−x||2)
≤
2(||yn −x||2 + ||ym −x||2) −4λ2.
Since ||x −yn|| →λ, this shows {yn −x} is a Cauchy sequence. Thus also {yn} is
a Cauchy sequence. Since H is complete, yn →y for some y ∈H which must be in
K because K is closed. Therefore
||x −y|| = lim
n→∞||x −yn|| = λ.
Let Px = y.

368
HILBERT SPACES
Corollary 14.9 Let K be a closed, convex, nonempty subset of a Hilbert space, H,
and let x ∈H. Then for z ∈K, z = Px if and only if
Re(x −z, y −z) ≤0
(14.6)
for all y ∈K.
Before proving this, consider what it says in the case where the Hilbert space is
Rn.
-
X
X
X
y
K
y
θ
x
z
Condition 14.6 says the angle, θ, shown in the diagram is always obtuse. Re-
member from calculus, the sign of x · y is the same as the sign of the cosine of the
included angle between x and y. Thus, in ﬁnite dimensions, the conclusion of this
corollary says that z = Px exactly when the angle of the indicated angle is obtuse.
Surely the picture suggests this is reasonable.
The inequality 14.6 is an example of a variational inequality and this corollary
characterizes the projection of x onto K as the solution of this variational inequality.
Proof of Corollary:
Let z ∈K and let y ∈K also. Since K is convex, it
follows that if t ∈[0, 1],
z + t(y −z) = (1 −t) z + ty ∈K.
Furthermore, every point of K can be written in this way. (Let t = 1 and y ∈K.)
Therefore, z = Px if and only if for all y ∈K and t ∈[0, 1],
||x −(z + t(y −z))||2 = ||(x −z) −t(y −z)||2 ≥||x −z||2
for all t ∈[0, 1] and y ∈K if and only if for all t ∈[0, 1] and y ∈K
||x −z||2 + t2 ||y −z||2 −2t Re (x −z, y −z) ≥||x −z||2
If and only if for all t ∈[0, 1],
t2 ||y −z||2 −2t Re (x −z, y −z) ≥0.
(14.7)
Now this is equivalent to 14.7 holding for all t ∈(0, 1). Therefore, dividing by
t ∈(0, 1) , 14.7 is equivalent to
t ||y −z||2 −2 Re (x −z, y −z) ≥0
for all t ∈(0, 1) which is equivalent to 14.6. This proves the corollary.

14.1.
BASIC THEORY
369
Corollary 14.10 Let K be a nonempty convex closed subset of a Hilbert space, H.
Then the projection map, P is continuous. In fact,
|Px −Py| ≤|x −y| .
Proof: Let x, x′ ∈H. Then by Corollary 14.9,
Re (x′ −Px′, Px −Px′) ≤0, Re (x −Px, Px′ −Px) ≤0
Hence
0
≤
Re (x −Px, Px −Px′) −Re (x′ −Px′, Px −Px′)
=
Re (x −x′, Px −Px′) −|Px −Px′|2
and so
|Px −Px′|2 ≤|x −x′| |Px −Px′| .
This proves the corollary.
The next corollary is a more general form for the Brouwer ﬁxed point theorem.
Corollary 14.11 Let f : K →K where K is a convex compact subset of Rn. Then
f has a ﬁxed point.
Proof:
Let K ⊆B (0, R) and let P be the projection map onto K. Then
consider the map f ◦P which maps B (0, R) to B (0, R) and is continuous. By the
Brouwer ﬁxed point theorem for balls, this map has a ﬁxed point. Thus there exists
x such that
f ◦P (x) = x
Now the equation also requires x ∈K and so P (x) = x. Hence f (x) = x.
Deﬁnition 14.12 Let H be a vector space and let U and V be subspaces. U ⊕V =
H if every element of H can be written as a sum of an element of U and an element
of V in a unique way.
The case where the closed convex set is a closed subspace is of special importance
and in this case the above corollary implies the following.
Corollary 14.13 Let K be a closed subspace of a Hilbert space, H, and let x ∈H.
Then for z ∈K, z = Px if and only if
(x −z, y) = 0
(14.8)
for all y ∈K. Furthermore, H = K ⊕K⊥where
K⊥≡{x ∈H : (x, k) = 0 for all k ∈K}
and
||x||2 = ||x −Px||2 + ||Px||2 .
(14.9)

370
HILBERT SPACES
Proof: Since K is a subspace, the condition 14.6 implies Re(x −z, y) ≤0
for all y ∈K. Replacing y with −y, it follows Re(x −z, −y) ≤0 which implies
Re(x −z, y) ≥0 for all y. Therefore, Re(x −z, y) = 0 for all y ∈K. Now let
|α| = 1 and α (x −z, y) = |(x −z, y)|. Since K is a subspace, it follows αy ∈K for
all y ∈K. Therefore,
0 = Re(x −z, αy) = (x −z, αy) = α (x −z, y) = |(x −z, y)|.
This shows that z = Px, if and only if 14.8.
For x ∈H, x = x −Px + Px and from what was just shown, x −Px ∈K⊥
and Px ∈K. This shows that K⊥+ K = H. Is there only one way to write
a given element of H as a sum of a vector in K with a vector in K⊥? Suppose
y + z = y1 + z1 where z, z1 ∈K⊥and y, y1 ∈K. Then (y −y1) = (z1 −z) and
so from what was just shown, (y −y1, y −y1) = (y −y1, z1 −z) = 0 which shows
y1 = y and consequently z1 = z. Finally, letting z = Px,
||x||2
=
(x −z + z, x −z + z) = ||x −z||2 + (x −z, z) + (z, x −z) + ||z||2
=
||x −z||2 + ||z||2
This proves the corollary.
The following theorem is called the Riesz representation theorem for the dual of
a Hilbert space. If z ∈H then deﬁne an element f ∈H′ by the rule (x, z) ≡f (x). It
follows from the Cauchy Schwarz inequality and the properties of the inner product
that f ∈H′. The Riesz representation theorem says that all elements of H′ are of
this form.
Theorem 14.14 Let H be a Hilbert space and let f ∈H′. Then there exists a
unique z ∈H such that
f (x) = (x, z)
(14.10)
for all x ∈H.
Proof: Letting y, w ∈H the assumption that f is linear implies
f (yf(w) −f(y)w) = f (w) f (y) −f (y) f (w) = 0
which shows that yf(w)−f(y)w ∈f −1 (0), which is a closed subspace of H since f is
continuous. If f −1 (0) = H, then f is the zero map and z = 0 is the unique element
of H which satisﬁes 14.10. If f −1 (0) ̸= H, pick u /∈f −1 (0) and let w ≡u−Pu ̸= 0.
Thus Corollary 14.13 implies (y, w) = 0 for all y ∈f −1 (0). In particular, let y =
xf(w) −f(x)w where x ∈H is arbitrary. Therefore,
0 = (f(w)x −f(x)w, w) = f(w)(x, w) −f(x)||w||2.
Thus, solving for f (x) and using the properties of the inner product,
f(x) = (x, f(w)w
||w||2 )

14.2.
APPROXIMATIONS IN HILBERT SPACE
371
Let z = f(w)w/||w||2. This proves the existence of z. If f (x) = (x, zi) i = 1, 2,
for all x ∈H, then for all x ∈H, then (x, z1 −z2) = 0 which implies, upon taking
x = z1 −z2 that z1 = z2. This proves the theorem.
If R : H →H′ is deﬁned by Rx (y) ≡(y, x) , the Riesz representation theorem
above states this map is onto. This map is called the Riesz map. It is routine to
show R is linear and |Rx| = |x|.
14.2
Approximations In Hilbert Space
The Gram Schmidt process applies in any Hilbert space.
Theorem 14.15 Let {x1, · · ·, xn} be a basis for M a subspace of H a Hilbert space.
Then there exists an orthonormal basis for M, {u1, · · ·, un} which has the property
that for each k ≤n, span(x1, · · ·, xk) = span (u1, · · ·, uk) . Also if {x1, · · ·, xn} ⊆H,
then
span (x1, · · ·, xn)
is a closed subspace.
Proof: Let {x1, · · ·, xn} be a basis for M. Let u1 ≡x1/ |x1| . Thus for k = 1,
span (u1) = span (x1) and {u1} is an orthonormal set.
Now suppose for some
k < n, u1, ···, uk have been chosen such that (uj · ul) = δjl and span (x1, · · ·, xk) =
span (u1, · · ·, uk). Then deﬁne
uk+1 ≡
xk+1 −Pk
j=1 (xk+1 · uj) uj
¯¯¯xk+1 −Pk
j=1 (xk+1 · uj) uj
¯¯¯
,
(14.11)
where the denominator is not equal to zero because the xj form a basis and so
xk+1 /∈span (x1, · · ·, xk) = span (u1, · · ·, uk)
Thus by induction,
uk+1 ∈span (u1, · · ·, uk, xk+1) = span (x1, · · ·, xk, xk+1) .
Also, xk+1 ∈span (u1, · · ·, uk, uk+1) which is seen easily by solving 14.11 for xk+1
and it follows
span (x1, · · ·, xk, xk+1) = span (u1, · · ·, uk, uk+1) .
If l ≤k,
(uk+1 · ul)
=
C

(xk+1 · ul) −
k
X
j=1
(xk+1 · uj) (uj · ul)


=
C

(xk+1 · ul) −
k
X
j=1
(xk+1 · uj) δlj


=
C ((xk+1 · ul) −(xk+1 · ul)) = 0.

372
HILBERT SPACES
The vectors, {uj}n
j=1 , generated in this way are therefore an orthonormal basis
because each vector has unit length.
Consider the second claim about ﬁnite dimensional subspaces. Without loss of
generality, assume {x1, · · ·, xn} is linearly independent. If it is not, delete vectors un-
til a linearly independent set is obtained. Then by the ﬁrst part, span (x1, · · ·, xn) =
span (u1, · · ·, un) ≡M where the ui are an orthonormal set of vectors. Suppose
{yk} ⊆M and yk →y ∈H. Is y ∈M? Let
yk ≡
n
X
j=1
ck
j uj
Then let ck ≡
¡
ck
1, · · ·, ck
n
¢T . Then
¯¯ck −cl¯¯2
≡
n
X
j=1
¯¯ck
j −cl
j
¯¯2 =


n
X
j=1
¡
ck
j −cl
j
¢
uj,
n
X
j=1
¡
ck
j −cl
j
¢
uj


=
||yk −yl||2
which shows
©
ckª
is a Cauchy sequence in Fn and so it converges to c ∈Fn. Thus
y = lim
k→∞yk = lim
k→∞
n
X
j=1
ck
j uj =
n
X
j=1
cjuj ∈M.
This completes the proof.
Theorem 14.16 Let M be the span of {u1, · · ·, un} in a Hilbert space, H and let
y ∈H. Then Py is given by
Py =
n
X
k=1
(y, uk) uk
(14.12)
and the distance is given by
v
u
u
t|y|2 −
n
X
k=1
|(y, uk)|2.
(14.13)
Proof:
Ã
y −
n
X
k=1
(y, uk) uk, up
!
=
(y, up) −
n
X
k=1
(y, uk) (uk, up)
=
(y, up) −(y, up) = 0
It follows that
Ã
y −
n
X
k=1
(y, uk) uk, u
!
= 0

14.2.
APPROXIMATIONS IN HILBERT SPACE
373
for all u ∈M and so by Corollary 14.13 this veriﬁes 14.12.
The square of the distance, d is given by
d2
=
Ã
y −
n
X
k=1
(y, uk) uk, y −
n
X
k=1
(y, uk) uk
!
=
|y|2 −2
n
X
k=1
|(y, uk)|2 +
n
X
k=1
|(y, uk)|2
and this shows 14.13.
What if the subspace is the span of vectors which are not orthonormal? There
is a very interesting formula for the distance between a point of a Hilbert space and
a ﬁnite dimensional subspace spanned by an arbitrary basis.
Deﬁnition 14.17 Let {x1, · · ·, xn} ⊆H, a Hilbert space. Deﬁne
G (x1, · · ·, xn) ≡



(x1, x1)
· · ·
(x1, xn)
...
...
(xn, x1)
· · ·
(xn, xn)



(14.14)
Thus the ijth entry of this matrix is (xi, xj). This is sometimes called the Gram
matrix. Also deﬁne G (x1, · · ·, xn) as the determinant of this matrix, also called the
Gram determinant.
G (x1, · · ·, xn) ≡
¯¯¯¯¯¯¯
(x1, x1)
· · ·
(x1, xn)
...
...
(xn, x1)
· · ·
(xn, xn)
¯¯¯¯¯¯¯
(14.15)
The theorem is the following.
Theorem 14.18 Let M = span (x1, · · ·, xn) ⊆H, a Real Hilbert space where
{x1, · · ·, xn} is a basis and let y ∈H. Then letting d be the distance from y to
M,
d2 = G (x1, · · ·, xn, y)
G (x1, · · ·, xn) .
(14.16)
Proof: By Theorem 14.15 M is a closed subspace of H. Let Pn
k=1 αkxk be the
element of M which is closest to y. Then by Corollary 14.13,
Ã
y −
n
X
k=1
αkxk, xp
!
= 0
for each p = 1, 2, · · ·, n. This yields the system of equations,
(y, xp) =
n
X
k=1
(xp, xk) αk, p = 1, 2, · · ·, n
(14.17)

374
HILBERT SPACES
Also by Corollary 14.13,
||y||2 =
d2
z
}|
{
¯¯¯¯¯
¯¯¯¯¯y −
n
X
k=1
αkxk
¯¯¯¯¯
¯¯¯¯¯
2
+
¯¯¯¯¯
¯¯¯¯¯
n
X
k=1
αkxk
¯¯¯¯¯
¯¯¯¯¯
2
and so, using 14.17,
||y||2
=
d2 +
X
j
ÃX
k
αk (xk, xj)
!
αj
=
d2 +
X
j
(y, xj) αj
(14.18)
≡
d2 + yT
x α
(14.19)
in which
yT
x ≡((y, x1) , · · ·, (y, xn)) , αT ≡(α1, · · ·, αn) .
Then 14.17 and 14.18 imply the following system
µ G (x1, · · ·, xn)
0
yT
x
1
¶ µ
α
d2
¶
=
µ
yx
||y||2
¶
By Cramer’s rule,
d2
=
det
µ G (x1, · · ·, xn)
yx
yT
x
||y||2
¶
det
µ G (x1, · · ·, xn)
0
yT
x
1
¶
=
det
µ G (x1, · · ·, xn)
yx
yT
x
||y||2
¶
det (G (x1, · · ·, xn))
=
det (G (x1, · · ·, xn, y))
det (G (x1, · · ·, xn))
= G (x1, · · ·, xn, y)
G (x1, · · ·, xn)
and this proves the theorem.
14.3
The M¨untz Theorem
Recall the polynomials are dense in C ([0, 1]) . This is a consequence of the Weier-
strass approximation theorem. Now consider ﬁnite linear combinations of the func-
tions, tpk where {p0, p1, p2, · · ·} is a sequence of nonnegative real numbers, p0 ≡0.
The M¨untz theorem says this set, S of ﬁnite linear combinations is dense in C ([0, 1])
exactly when P∞
k=1
1
pk = ∞. There are two versions of this theorem, one for density
of S in L2 (0, 1) and one for C ([0, 1]) . The presentation follows Cheney [14].

14.3.
THE M ¨UNTZ THEOREM
375
Recall the Cauchy identity presented earlier, Theorem 4.46 on Page 76 which is
stated here for convenience.
Theorem 14.19 The following identity holds.
Y
i,j
(ai + bj)
¯¯¯¯¯¯¯
1
a1+b1
· · ·
1
a1+bn
...
...
1
an+b1
· · ·
1
an+bn
¯¯¯¯¯¯¯
=
Y
j<i
(ai −aj) (bi −bj) .
(14.20)
Lemma 14.20 Let m, p1, ···, pn be distinct real numbers larger than −1/2. Thus the
functions, fm (x) ≡xm, fpj (x) ≡xpj are all in L2 (0, 1). Let M = span (fp1, · · ·, fpn) .
Then the L2 distance, d between fm and M is
d =
1
√2m + 1
n
Y
j=1
|m −pj|
m + pj + 1
Proof: By Theorem 14.18
d2 = G (fp1, · · ·, fpn, fm)
G (fp1, · · ·, fpn)
.
¡
fpi, fpj
¢
=
Z 1
0
xpixpjdx =
1
1 + pi + pj
Therefore,
d2 =
¯¯¯¯¯¯¯¯¯¯¯¯
1
1+p1+p1
1
1+p1+p2
· · ·
1
1+p1+pn
1
1+m+p1
1
1+p2+p1
1
1+p2+p2
· · ·
1
1+p2+pn
1
1+m+p2
...
...
...
...
1
1+pn+p1
1
1+pn+p2
· · ·
1
1+pn+pn
1
1+pn+m
1
1+m+p1
1
1+m+p2
· · ·
1
1+m+pn
1
1+m+m
¯¯¯¯¯¯¯¯¯¯¯¯
¯¯¯¯¯¯¯¯¯
1
1+p1+p1
1
1+p1+p2
· · ·
1
1+p1+pn
1
1+p2+p1
1
1+p2+p2
· · ·
1
1+p2+pn
...
...
...
1
1+pn+p1
1
1+pn+p2
· · ·
1
1+pn+pn
¯¯¯¯¯¯¯¯¯
Now from the Cauchy identity, letting ai = pi + 1
2 and bj = 1
2 + pj with pn+1 = m,
the numerator of the above equals
Q
j<i≤n+1 (pi −pj) (pi −pj)
Q
i,j≤n+1 (pi + pj + 1)
=
Qn
k=1 (m −pk)2 Q
j<i≤n (pi −pj)2
Qn
i=1 (m + pi + 1) Qn
j=1 (m + pj + 1) Q
i,j≤n (pi + pj + 1) (2m + 1)
=
Qn
k=1 (m −pk)2 Q
j<i≤n (pi −pj)2
Qn
i=1 (m + pi + 1)2 Q
i,j≤n (pi + pj + 1) (2m + 1)

376
HILBERT SPACES
while the denominator equals
Q
j<i≤n (pi −pj)2
Q
i,j≤n (pi + pj + 1)
Therefore,
d2
=
µ
Qn
k=1(m−pk)2 Q
j<i≤n(pi−pj)2
Qn
i=1(m+pi+1)2 Q
i,j≤n(pi+pj+1)(2m+1)
¶
³ Q
j<i≤n(pi−pj)2
Q
i,j≤n(pi+pj+1)
´
=
Qn
k=1 (m −pk)2
Qn
i=1 (m + pi + 1)2 (2m + 1)
which shows
d =
1
√2m + 1
n
Y
k=1
|m −pk|
m + pk + 1.
and this proves the lemma.
The following lemma relates an inﬁnite sum to a product. First consider the
graph of ln (1 −x) for x ∈
£
0, 1
2
¤
. Here is a rough sketch with two lines, y = −x
which lies above the graph of ln (1 −x) and y = −2x which lies below.
@
@
@
@
@
A
A
A
A
A
A
A
A
A
A
1
2
Lemma 14.21 Let an ̸= 1, an > 0, and limn→∞an = 0. Then
∞
Y
k=1
(1 −an) ≡lim
n→∞
n
Y
k=1
(1 −an) = 0
if and only if
∞
X
n=1
an = +∞.
Proof:Without loss of generality, you can assume an < 1/2 because the two
conditions are determined by the values of an for n large. By the above sketch the

14.3.
THE M ¨UNTZ THEOREM
377
following is obtained.
ln
n
Y
k=1
(1 −ak) =
n
X
k=1
ln (1 −ak) ∈
"
−2
n
X
k=1
ak, −
n
X
k=1
ak
#
.
Therefore,
e−2 Pn
k=1 ak ≤
n
Y
k=1
(1 −ak) ≤e−Pn
k=1 ak
The conclusion follows.
The following is M¨untz’s ﬁrst theorem.
Theorem 14.22 Let {pn} be a sequence of real numbers larger than −1/2 such that
limn→∞pn = ∞. Let S denote the set of ﬁnite linear combinations of the functions,
{xp1, xp2, · · ·} . Then S is dense in L2 (0, 1) if and only if
∞
X
i=1
1
pi
= ∞.
Proof: The polynomials are dense in L2 (0, 1) and so S is dense in L2 (0, 1) if
and only if for every ε > 0 there exists a function f from S such that for each
integer m ≥0,
³R 1
0 |f (x) −xm|2 dx
´1/2
< ε.
This happens if and only if for
all n large enough, the distance in L2 (0, 1) between the function, x →xm and
span (xp1, xp2, · · ·, xpn) is less than ε. However, from Lemma 14.20 this distance
equals
1
√2m + 1
n
Y
k=1
|m −pk|
m + pk + 1
=
1
√2m + 1
n
Y
k=1
1 −
µ
1 −
|m −pk|
m + pk + 1
¶
Thus S is dense if and only if
∞
Y
k=1
µ
1 −
µ
1 −
|m −pk|
m + pk + 1
¶¶
= 0
which, by Lemma 14.21, happens if and only if
∞
X
k=1
µ
1 −
|m −pk|
m + pk + 1
¶
= +∞
But this sum equals
∞
X
k=1
µm + pk + 1 −|m −pk|
m + pk + 1
¶

378
HILBERT SPACES
which has the same convergence properties as P 1
pk by the limit comparison test.
This proves the theorem.
The following is M¨untz’s second theorem.
Theorem 14.23 Let S be ﬁnite linear combinations of {1, xp1, xp2, · · ·} where pj ≥
1 and limn→∞pn = ∞. Then S is dense in C ([0, 1]) if and only if P∞
k=1
1
pk = ∞.
Proof: If S is dense in C ([0, 1]) then S must also be dense in L2 (0, 1) and so
by Theorem 14.22 P∞
k=1
1
pk = ∞.
Suppose then that P∞
k=1
1
pk = ∞so that by Theorem 14.22, S is dense in
L2 (0, 1) . The theorem will be proved if it is shown that for all m a nonnegative
integer,
max {|xm −f (x)| : x ∈[0, 1]} < ε
for some f ∈S. This is true if m = 0 because 1 ∈S. Suppose then that m > 0. Let
S′ denote ﬁnite linear combinations of the functions
©
xp1−1, xp2−1, · · ·
ª
.
These functions are also dense in L2 (0, 1) because P
1
pk−1 = ∞by the limit com-
parison test. Then by Theorem 14.22 there exists f ∈S′ such that
µZ 1
0
¯¯f (x) −mxm−1¯¯2 dx
¶1/2
< ε.
Thus F (x) ≡
R x
0 f (t) dt ∈S and
|F (x) −xm|
=
¯¯¯¯
Z x
0
¡
f (t) −mtm−1¢
dt
¯¯¯¯
≤
Z x
0
¯¯f (t) −mtm−1¯¯ dt
≤
µZ 1
0
¯¯f (t) −mtm−1¯¯2 dt
¶1/2 µZ 1
0
dx
¶1/2
<
ε
and this proves the theorem.
14.4
Orthonormal Sets
The concept of an orthonormal set of vectors is a generalization of the notion of the
standard basis vectors of Rn or Cn.
Deﬁnition 14.24 Let H be a Hilbert space. S ⊆H is called an orthonormal set if
||x|| = 1 for all x ∈S and (x, y) = 0 if x, y ∈S and x ̸= y. For any set, D,
D⊥≡{x ∈H : (x, d) = 0 for all d ∈D} .
If S is a set, span (S) is the set of all ﬁnite linear combinations of vectors from S.

14.4.
ORTHONORMAL SETS
379
You should verify that D⊥is always a closed subspace of H.
Theorem 14.25 In any separable Hilbert space, H, there exists a countable or-
thonormal set, S = {xi} such that the span of these vectors is dense in H. Further-
more, if span (S) is dense, then for x ∈H,
x =
∞
X
i=1
(x, xi) xi ≡lim
n→∞
n
X
i=1
(x, xi) xi.
(14.21)
Proof:
Let F denote the collection of all orthonormal subsets of H.
F is
nonempty because {x} ∈F where ||x|| = 1. The set, F is a partially ordered set
with the order given by set inclusion. By the Hausdorﬀmaximal theorem, there
exists a maximal chain, C in F. Then let S ≡∪C. It follows S must be a maximal
orthonormal set of vectors. Why? It remains to verify that S is countable span (S)
is dense, and the condition, 14.21 holds. To see S is countable note that if x, y ∈S,
then
||x −y||2 = ||x||2 + ||y||2 −2 Re (x, y) = ||x||2 + ||y||2 = 2.
Therefore, the open sets, B
¡
x, 1
2
¢
for x ∈S are disjoint and cover S. Since H is
assumed to be separable, there exists a point from a countable dense set in each of
these disjoint balls showing there can only be countably many of the balls and that
consequently, S is countable as claimed.
It remains to verify 14.21 and that span (S) is dense. If span (S) is not dense,
then span (S) is a closed proper subspace of H and letting y /∈span (S),
z ≡
y −Py
||y −Py|| ∈span (S)⊥.
But then S ∪{z} would be a larger orthonormal set of vectors contradicting the
maximality of S.
It remains to verify 14.21. Let S = {xi}∞
i=1 and consider the problem of choosing
the constants, ck in such a way as to minimize the expression
¯¯¯¯¯
¯¯¯¯¯x −
n
X
k=1
ckxk
¯¯¯¯¯
¯¯¯¯¯
2
=
||x||2 +
n
X
k=1
|ck|2 −
n
X
k=1
ck (x, xk) −
n
X
k=1
ck(x, xk).
This equals
||x||2 +
n
X
k=1
|ck −(x, xk)|2 −
n
X
k=1
|(x, xk)|2
and therefore, this minimum is achieved when ck = (x, xk) and equals
||x||2 −
n
X
k=1
|(x, xk)|2

380
HILBERT SPACES
Now since span (S) is dense, there exists n large enough that for some choice of
constants, ck,
¯¯¯¯¯
¯¯¯¯¯x −
n
X
k=1
ckxk
¯¯¯¯¯
¯¯¯¯¯
2
< ε.
However, from what was just shown,
¯¯¯¯¯
¯¯¯¯¯x −
n
X
i=1
(x, xi) xi
¯¯¯¯¯
¯¯¯¯¯
2
≤
¯¯¯¯¯
¯¯¯¯¯x −
n
X
k=1
ckxk
¯¯¯¯¯
¯¯¯¯¯
2
< ε
showing that limn→∞
Pn
i=1 (x, xi) xi = x as claimed. This proves the theorem.
The proof of this theorem contains the following corollary.
Corollary 14.26 Let S be any orthonormal set of vectors and let
{x1, · · ·, xn} ⊆S.
Then if x ∈H
¯¯¯¯¯
¯¯¯¯¯x −
n
X
k=1
ckxk
¯¯¯¯¯
¯¯¯¯¯
2
≥
¯¯¯¯¯
¯¯¯¯¯x −
n
X
i=1
(x, xi) xi
¯¯¯¯¯
¯¯¯¯¯
2
for all choices of constants, ck. In addition to this, Bessel’s inequality
||x||2 ≥
n
X
k=1
|(x, xk)|2 .
If S is countable and span (S) is dense, then letting {xi}∞
i=1 = S, 14.21 follows.
14.5
Fourier Series, An Example
In this section consider the Hilbert space, L2 (0, 2π) with the inner product,
(f, g) ≡
Z 2π
0
fgdm.
This is a Hilbert space because of the theorem which states the Lp spaces are com-
plete, Theorem 12.10 on Page 319. An example of an orthonormal set of functions
in L2 (0, 2π) is
φn (x) ≡
1
√
2π einx
for n an integer. Is it true that the span of these functions is dense in L2 (0, 2π)?
Theorem 14.27 Let S = {φn}n∈Z. Then span (S) is dense in L2 (0, 2π).

14.5.
FOURIER SERIES, AN EXAMPLE
381
Proof: By regularity of Lebesgue measure, it follows from Theorem 12.16 that
Cc (0, 2π) is dense in L2 (0, 2π) . Therefore, it suﬃces to show that for g ∈Cc (0, 2π) ,
then for every ε > 0 there exists h ∈span (S) such that ||g −h||L2(0,2π) < ε.
Let T denote the points of C which are of the form eit for t ∈R. Let A denote
the algebra of functions consisting of polynomials in z and 1/z for z ∈T. Thus a
typical such function would be one of the form
m
X
k=−m
ckzk
for m chosen large enough.
This algebra separates the points of T because it
contains the function, p (z) = z. It annihilates no point of t because it contains
the constant function 1. Furthermore, it has the property that for f ∈A, f ∈A.
By the Stone Weierstrass approximation theorem, Theorem 7.16 on Page 165, A is
dense in C (T) . Now for g ∈Cc (0, 2π) , extend g to all of R to be 2π periodic. Then
letting G
¡
eit¢
≡g (t) , it follows G is well deﬁned and continuous on T. Therefore,
there exists H ∈A such that for all t ∈R,
¯¯H
¡
eit¢
−G
¡
eit¢¯¯ < ε2/2π.
Thus H
¡
eit¢
is of the form
H
¡
eit¢
=
m
X
k=−m
ck
¡
eit¢k =
m
X
k=−m
ckeikt ∈span (S) .
Let h (t) = Pm
k=−m ckeikt. Then
µZ 2π
0
|g −h|2 dx
¶1/2
≤
µZ 2π
0
max {|g (t) −h (t)| : t ∈[0, 2π]} dx
¶1/2
=
µZ 2π
0
max
©¯¯G
¡
eit¢
−H
¡
eit¢¯¯ : t ∈[0, 2π]
ª
dx
¶1/2
<
µZ 2π
0
ε2
2π
¶1/2
= ε.
This proves the theorem.
Corollary 14.28 For f ∈L2 (0, 2π) ,
lim
m→∞
¯¯¯¯¯
¯¯¯¯¯f −
m
X
k=−m
(f, φk) φk
¯¯¯¯¯
¯¯¯¯¯
L2(0,2π)
Proof: This follows from Theorem 14.25 on Page 379.

382
HILBERT SPACES
14.6
Compact Operators
14.6.1
Compact Operators In Hilbert Space
Deﬁnition 14.29 Let A ∈L (H, H) where H is a Hilbert space. Then |(Ax, y)| ≤
||A|| ||x|| ||y|| and so the map, x →(Ax, y) is continuous and linear. By the Riesz
representation theorem, there exists a unique element of H, denoted by A∗y such
that
(Ax, y) = (x, A∗y) .
It is clear y →A∗y is linear and continuous. A∗is called the adjoint of A. A is a
self adjoint operator if A = A∗. Thus for a self adjoint operator, (Ax, y) = (x, Ay)
for all x, y ∈H. A is a compact operator if whenever {xk} is a bounded sequence,
there exists a convergent subsequence of {Axk}. Equivalently, A maps bounded sets
to sets whose closures are compact.
The big result is called the Hilbert Schmidt theorem. It is a generalization to
arbitrary Hilbert spaces of standard ﬁnite dimensional results having to do with
diagonalizing a symmetric matrix. There is another statement and proof of this
theorem around Page 598.
Theorem 14.30 Let A be a compact self adjoint operator deﬁned on a Hilbert
space, H. Then there exists a countable set of eigenvalues, {λi} and an orthonormal
set of eigenvectors, ui satisfying
λi is real, |λn| ≥|λn+1| , Aui = λiui,
(14.22)
and either
lim
n→∞λn = 0,
(14.23)
or for some n,
span (u1, · · ·, un) = H.
(14.24)
In any case,
span ({ui}∞
i=1) is dense in A (H) .
(14.25)
and for all x ∈H,
Ax =
∞
X
k=1
λk (x, uk) uk.
(14.26)
This sequence of eigenvectors and eigenvalues also satisﬁes
|λn| = ||An|| ,
(14.27)
and
An : Hn →Hn.
(14.28)
where H ≡H1 and Hn ≡{u1, · · ·, un−1}⊥and An is the restriction of A to Hn.

14.6.
COMPACT OPERATORS
383
Proof:
If A = 0 then pick u ∈H with ||u|| = 1 and let λ1 = 0.
Since
A (H) = 0 it follows the span of u is dense in A (H) and this proves the theorem in
this uninteresting case.
Assume from now on A ̸= 0. Let λ1 be real and λ2
1 ≡||A||2. From the deﬁnition
of ||A|| there exists xn, ||xn|| = 1, and ||Axn|| →||A|| = |λ1|. Now it is clear that
A2 is also a compact self adjoint operator. Consider
¡¡
λ2
1 −A2¢
xn, xn
¢
= λ2
1 −||Axn||2 →0.
Since A is compact, there exists a subsequence of {xn} still denoted by {xn} such
that Axn converges to some element of H. Thus since λ2
1 −A2 satisﬁes
¡¡
λ2
1 −A2¢
y, y
¢
≥0
in addition to being self adjoint, it follows x, y →
¡¡
λ2
1 −A2¢
x, y
¢
satisﬁes all the
axioms for an inner product except for the one which says that (z, z) = 0 only if
z = 0. Therefore, the Cauchy Schwarz inequality may be used to write
¯¯¡¡
λ2
1 −A2¢
xn, y
¢¯¯
≤
¡¡
λ2
1 −A2¢
y, y
¢1/2 ¡¡
λ2
1 −A2¢
xn, xn
¢1/2
≤
en ||y|| .
where en →0 as n →∞. Therefore, taking the sup over all ||y|| ≤1,
lim
n→∞
¯¯¯¯¡
λ2
1 −A2¢
xn
¯¯¯¯ = 0.
Since A2xn converges, it follows since λ1 ̸= 0 that {xn} is a Cauchy sequence
converging to x with ||x|| = 1. Therefore, A2xn →A2x and so
¯¯¯¯¡
λ2
1 −A2¢
x
¯¯¯¯ = 0.
Now
(λ1I −A) (λ1I + A) x = (λ1I + A) (λ1I −A) x = 0.
If (λ1I −A) x = 0, let u1 ≡x. If (λ1I −A) x = y ̸= 0, let u1 ≡
y
||y||.
Suppose {u1, · · ·, un} is such that Auk = λkuk and |λk| ≥|λk+1|, |λk| = ||Ak||
and Ak : Hk →Hk for k ≤n. If
span (u1, · · ·, un) = H
this yields the conclusion of the theorem in the situation of 14.24. Therefore, assume
the span of these vectors is always a proper subspace of H. It is shown next that
An+1 : Hn+1 →Hn+1. Let
y ∈Hn+1 ≡{u1, · · ·, un}⊥
Then for k ≤n
(Ay, uk) = (y, Auk) = λk (y, uk) = 0,

384
HILBERT SPACES
showing An+1 : Hn+1 →Hn+1 as claimed. There are two cases. Either λn = 0 or it
is not. In the case where λn = 0 it follows An = 0. Every element of H is the sum
of one in span (u1, · · ·, un) and one in span (u1, · · ·, un)⊥. (note span (u1, · · ·, un)
is a closed subspace.) Thus, if x ∈H, x = y + z where y ∈span (u1, · · ·, un) and
z ∈span (u1, · · ·, un)⊥and Az = 0. Say y = Pn
j=1 cjuj. Then
Ax
=
Ay =
n
X
j=1
cjAuj
=
n
X
j=1
cjλjuj ∈span (u1, · · ·, un) .
The conclusion of the theorem holds in this case because the above equation holds
if with ci = (x, ui).
Now consider the case where λn ̸= 0. In this case repeat the above argument
used to ﬁnd un+1 and λn+1 for the operator, An+1. This yields un+1 ∈Hn+1 ≡
{u1, · · ·, un}⊥such that
||un+1|| = 1, ||Aun+1|| = |λn+1| = ||An+1|| ≤||An|| = |λn|
and if it is ever the case that λn = 0, it follows from the above argument that the
conclusion of the theorem is obtained.
I claim limn→∞λn = 0. If this were not so, then for some ε > 0, 0 < ε =
limn→∞|λn| but then
||Aun −Aum||2
=
||λnun −λmum||2
=
|λn|2 + |λm|2 ≥2ε2
and so there would not exist a convergent subsequence of {Auk}∞
k=1 contrary to the
assumption that A is compact. This veriﬁes the claim that limn→∞λn = 0.
It remains to verify that span ({ui}) is dense in A (H). If w ∈span ({ui})⊥then
w ∈Hn for all n and so for all n,
||Aw|| ≤||An|| ||w|| ≤|λn| ||w|| .
Therefore, Aw = 0. Now every vector from H can be written as a sum of one from
span ({ui})⊥= span ({ui})
⊥
and one from span ({ui}). Therefore, if x ∈H, x = y + w where y ∈span ({ui})
and w ∈span ({ui})
⊥. It follows Aw = 0. Also, since y ∈span ({ui}), there exist
constants, ck and n such that
¯¯¯¯¯
¯¯¯¯¯y −
n
X
k=1
ckuk
¯¯¯¯¯
¯¯¯¯¯ < ε.

14.6.
COMPACT OPERATORS
385
Therefore, from Corollary 14.26,
¯¯¯¯¯
¯¯¯¯¯y −
n
X
k=1
(y, uk) uk
¯¯¯¯¯
¯¯¯¯¯ =
¯¯¯¯¯
¯¯¯¯¯y −
n
X
k=1
(x, uk) uk
¯¯¯¯¯
¯¯¯¯¯ < ε.
Therefore,
||A|| ε
>
¯¯¯¯¯
¯¯¯¯¯A
Ã
y −
n
X
k=1
(x, uk) uk
!¯¯¯¯¯
¯¯¯¯¯
=
¯¯¯¯¯
¯¯¯¯¯Ax −
n
X
k=1
(x, uk) λkuk
¯¯¯¯¯
¯¯¯¯¯ .
Since ε is arbitrary, this shows span ({ui}) is dense in A (H) and also implies 14.26.
This proves the theorem.
Deﬁne v ⊗u ∈L (H, H) by
v ⊗u (x) = (x, u) v,
then 14.26 is of the form
A =
∞
X
k=1
λkuk ⊗uk
This is the content of the following corollary.
Corollary 14.31 The main conclusion of the above theorem can be written as
A =
∞
X
k=1
λkuk ⊗uk
where the convergence of the partial sums takes place in the operator norm.
Proof: Using 14.26
¯¯¯¯¯
ÃÃ
A −
n
X
k=1
λkuk ⊗uk
!
x, y
!¯¯¯¯¯
=
¯¯¯¯¯
Ã
Ax −
n
X
k=1
λk (x, uk) uk, y
!¯¯¯¯¯
=
¯¯¯¯¯
Ã ∞
X
k=n
λk (x, uk) uk, y
!¯¯¯¯¯
=
¯¯¯¯¯
∞
X
k=n
λk (x, uk) (uk, y)
¯¯¯¯¯
≤
|λn|
Ã ∞
X
k=n
|(x, uk)|2
!1/2 Ã ∞
X
k=n
|(y, uk)|2
!1/2
≤
|λn| ||x|| ||y||

386
HILBERT SPACES
It follows
¯¯¯¯¯
¯¯¯¯¯
Ã
A −
n
X
k=1
λkuk ⊗uk
!
(x)
¯¯¯¯¯
¯¯¯¯¯ ≤|λn| ||x||
and this proves the corollary.
Corollary 14.32 Let A be a compact self adjoint operator deﬁned on a separable
Hilbert space, H. Then there exists a countable set of eigenvalues, {λi} and an
orthonormal set of eigenvectors, vi satisfying
Avi = λivi, ||vi|| = 1,
(14.29)
span ({vi}∞
i=1) is dense in H.
(14.30)
Furthermore, if λi ̸= 0, the space, Vλi ≡{x ∈H : Ax = λix} is ﬁnite dimensional.
Proof: In the proof of the above theorem, let W ≡span ({ui})
⊥. By Theorem
14.25, there is an orthonormal set of vectors, {wi}∞
i=1 whose span is dense in W.
As shown in the proof of the above theorem, Aw = 0 for all w ∈W. Let {vi}∞
i=1 =
{ui}∞
i=1 ∪{wi}∞
i=1.
It remains to verify the space, Vλi, is ﬁnite dimensional.
First observe that
A : Vλi →Vλi. Since A is continuous, it follows that A : Vλi →Vλi. Thus A is a
compact self adjoint operator on Vλi and by Theorem 14.30, 14.24 holds because
the only eigenvalue is λi. This proves the corollary.
Note the last claim of this corollary holds independent of the separability of H.
This proves the corollary.
Suppose λ /∈{λn} and λ ̸= 0. Then the above formula for A, 14.26, yields an
interesting formula for (A −λI)−1. Note ﬁrst that since limn→∞λn = 0, it follows
that λ2
n/ (λn −λ)2 must be bounded, say by a positive constant, M.
Corollary 14.33 Let A be a compact self adjoint operator and let λ /∈{λn}∞
n=1
and λ ̸= 0 where the λn are the eigenvalues of A. Then
(A −λI)−1 x = −1
λx + 1
λ
∞
X
k=1
λk
λk −λ (x, uk) uk.
(14.31)
Proof: Let m < n. Then since the {uk} form an orthonormal set,
¯¯¯¯¯
n
X
k=m
λk
λk −λ (x, uk) uk
¯¯¯¯¯
=
Ã
n
X
k=m
µ
λk
λk −λ
¶2
|(x, uk)|2
!1/2
(14.32)
≤
M
Ã
n
X
k=m
|(x, uk)|2
!1/2
.
But from Bessel’s inequality,
∞
X
k=1
|(x, uk)|2 ≤||x||2

14.6.
COMPACT OPERATORS
387
and so for m large enough, the ﬁrst term in 14.32 is smaller than ε. This shows
the inﬁnite series in 14.31 converges. It is now routine to verify that the formula in
14.31 is the inverse.
14.6.2
Nuclear Operators
Deﬁnition 14.34 A self adjoint operator A ∈L (H, H) for H a separable Hilbert
space is called a nuclear operator if for some complete orthonormal set, {ek} ,
∞
X
k=1
|(Aek, ek)| < ∞
To begin with here is an interesting lemma.
Lemma 14.35 Suppose {An} is a sequence of compact operators in L (X, Y ) for
two Banach spaces, X and Y and suppose A ∈L (X, Y ) and
lim
n→∞||A −An|| = 0.
Then A is also compact.
Proof: Let B be a bounded set in X such that ||b|| ≤C for all b ∈B. I need to
verify AB is totally bounded. Suppose then it is not. Then there exists ε > 0 and
a sequence, {Abi} where bi ∈B and
||Abi −Abj|| ≥ε
whenever i ̸= j. Then let n be large enough that
||A −An|| ≤
ε
4C .
Then
||Anbi −Anbj||
=
||Abi −Abj + (An −A) bi −(An −A) bj||
≥
||Abi −Abj|| −||(An −A) bi|| −||(An −A) bj||
≥
||Abi −Abj|| −ε
4C C −ε
4C C ≥ε
2,
a contradiction to An being compact. This proves the lemma.
Then one can prove the following lemma.
In this lemma, A ≥0 will mean
(Ax, x) ≥0.
Lemma 14.36 Let A ≥0 be a nuclear operator deﬁned on a separable Hilbert
space, H. Then A is compact and also, whenever {ek} is a complete orthonormal
set,
A =
∞
X
j=1
∞
X
i=1
(Aei, ej) ei ⊗ej.

388
HILBERT SPACES
Proof: First consider the formula. Since A is given to be continuous,
Ax = A


∞
X
j=1
(x, ej) ej

=
∞
X
j=1
(x, ej) Aej,
the series converging because
x =
∞
X
j=1
(x, ej) ej
Then also since A is self adjoint,
∞
X
j=1
∞
X
i=1
(Aei, ej) ei ⊗ej (x)
≡
∞
X
j=1
∞
X
i=1
(Aei, ej) (x, ej) ei
=
∞
X
j=1
(x, ej)
∞
X
i=1
(Aei, ej) ei
=
∞
X
j=1
(x, ej)
∞
X
i=1
(Aej, ei) ei
=
∞
X
j=1
(x, ej) Aej
Next consider the claim that A is compact. Let CA ≡
³P∞
j=1 |(Aej, ej)|
´1/2
.
Let An be deﬁned by
An ≡
∞
X
j=1
n
X
i=1
(Aei, ej) (ei ⊗ej) .
Then An has values in span (e1, · · ·, en) and so it must be a compact operator
because bounded sets in a ﬁnite dimensional space must be precompact. Then
|(Ax −Anx, y)|
=
¯¯¯¯¯¯
∞
X
j=1
∞
X
i=n+1
(Aeiej) (y, ej) (ei, x)
¯¯¯¯¯¯
=
¯¯¯¯¯¯
∞
X
j=1
(y, ej)
∞
X
i=n+1
(Aeiej) (ei, x)
¯¯¯¯¯¯

14.6.
COMPACT OPERATORS
389
≤
¯¯¯¯¯¯
∞
X
j=1
|(y, ej)| (Aej, ej)1/2
∞
X
i=n+1
(Aeiei)1/2 |(ei, x)|
¯¯¯¯¯¯
≤


∞
X
j=1
|(y, ej)|2


1/2 

∞
X
j=1
|(Aej, ej)|


1/2
·
Ã
∞
X
i=n+1
|(x, ei)|2
!1/2 Ã
∞
X
i=n+1
|(Aeiei)|
!1/2
≤
|y| |x| CA
Ã
∞
X
i=n+1
|(Aei, ei)|
!1/2
and this shows that if n is suﬃciently large,
|((A −An) x, y)| ≤ε |x| |y| .
Therefore,
lim
n→∞||A −An|| = 0
and so A is the limit in operator norm of ﬁnite rank bounded linear operators, each
of which is compact. Therefore, A is also compact.
Deﬁnition 14.37 The trace of a nuclear operator A ∈L (H, H) such that A ≥0
is deﬁned to equal
∞
X
k=1
(Aek, ek)
where {ek} is an orthonormal basis for the Hilbert space, H.
Theorem 14.38 Deﬁnition 14.37 is well deﬁned and equals P∞
j=1 λj where the λj
are the eigenvalues of A.
Proof: Suppose {uk} is some other orthonormal basis. Then
ek =
∞
X
j=1
uj (ek, uj)
By Lemma 14.36 A is compact and so
A =
∞
X
k=1
λkuk ⊗uk

390
HILBERT SPACES
where the uk are the orthonormal eigenvectors of A which form a complete or-
thonormal set. Then
∞
X
k=1
(Aek, ek)
=
∞
X
k=1

A


∞
X
j=1
uj (ek, uj)

,
∞
X
j=1
uj (ek, uj)


=
∞
X
k=1
X
ij
(Auj, ui) (ek, uj) (ui, ek)
=
∞
X
k=1
∞
X
j=1
(Auj, uj) |(ek, uj)|2
=
∞
X
j=1
(Auj, uj)
∞
X
k=1
|(ek, uj)|2 =
∞
X
j=1
(Auj, uj) |uj|2
=
∞
X
j=1
(Auj, uj) =
∞
X
j=1
λj
and this proves the theorem.
This is just like it is for a matrix. Recall the trace of a matrix is the sum of the
eigenvalues.
It is also easy to see that in any separable Hilbert space, there exist nuclear
operators. Let P∞
k=1 |λk| < ∞. Then let {ek} be a complete orthonormal set of
vectors. Let
A ≡
∞
X
k=1
λkek ⊗ek.
It is not too hard to verify this works.
Much more can be said about nuclear operators.
14.6.3
Hilbert Schmidt Operators
Deﬁnition 14.39 Let H and G be two separable Hilbert spaces and let T map H
to G be linear. Then T is called a Hilbert Schmidt operator if there exists some
orthonormal basis for H, {ej} such that
X
j
||Tej||2 < ∞.
The collection of all such linear maps will be denoted by L2 (H, G) .
Theorem 14.40 L2 (H, G) ⊆L (H, G) and L2 (H, G) is a separable Hilbert space
with norm given by
||T||L2 ≡
ÃX
k
||Tek||2
!1/2

14.6.
COMPACT OPERATORS
391
where {ek} is some orthonormal basis for H. Also L2 (H, G) ⊆L (H, G) and
||T|| ≤||T||L2 .
(14.33)
All Hilbert Schmidt opearators are compact. Also for X ∈H and Y ∈G, X ⊗Y ∈
L2 (H, G) and
||X ⊗Y ||L2 = ||X||H ||Y ||G
(14.34)
Proof: First consider the norm. I need to verify the norm does not depend on
the choice of orthonormal basis. Let {fk} be an orthonormal basis for G. Then for
{ek} an orthonormal basis for H,
X
k
||Tek||2
=
X
k
X
j
|(Tek, fj)|2 =
X
k
X
j
|(ek, T ∗fj)|2
=
X
j
X
k
|(ek, T ∗fj)|2 =
X
j
||T ∗fj||2 .
The same result would be obtained for any other orthonormal basis
©
e′
j
ª
and this
shows the norm is at least well deﬁned. It is clear this does indeed satisfy the axioms
of a norm.
Next I want to show L2 (H, G) ⊆L (H, G) and ||T|| ≤||T||L2. Pick an orthonor-
mal basis for H, {ek} and an orthonormal basis for G, {fk}. Then letting
x =
n
X
k=1
xkek,
Tx = T
Ã n
X
k=1
xkek
!
=
n
X
k=1
xkT (ek)

392
HILBERT SPACES
where xk ≡(x, ek). Therefore using Minkowski’s inequality,
||Tx||
=
Ã ∞
X
k=1
|(Tx, fk)|2
!1/2
=



∞
X
k=1
¯¯¯¯¯¯


n
X
j=1
xjTej, fk


¯¯¯¯¯¯
2


1/2
=



∞
X
k=1
¯¯¯¯¯¯
n
X
j=1
(xjTej, ek)
¯¯¯¯¯¯
2


1/2
≤
n
X
j=1
Ã ∞
X
k=1
|(xjTej, ek)|2
!1/2
≤
X
j
|xj|
ÃX
k
|(Tej, ek)|2
!1/2
=
X
j
|xj| ||Tej|| ≤


n
X
j=1
|xj|2


1/2
||T||L2
=
||x|| ||T||L2
Therefore, since ﬁnite sums of the form Pn
k=1 xkek are dense in H, it follows T ∈
L (H, G) and ||T|| ≤||T||L2 and this proves the above claims.
It only remains to verify L2 (H, G) is a separable Hilbert space. It is clear it is
an inner product space because you only have to pick an orthonormal basis, {ek}
and deﬁne the inner product as
(S, T) ≡
X
k
(Sek, Tek) .
The only remaining issue is the completeness. Suppose then that {Tn} is a Cauchy
sequence in L2 (H, G) . Then from 14.33 {Tn} is a Cauchy sequence in L (H, G) and
so there exists a unique T such that limn→∞||Tn −T|| = 0. Then it only remains
to verify T ∈L2 (H, G) . But by Fatou’s lemma,
X
k
||Tek||2
≤
lim inf
n→∞
X
k
||Tnek||2
=
lim inf
n→∞||Tn||2
L2 < ∞.
All that remains is to verify L2 (H, G) is separable and these Hilbert Schmidt
operators are compact. I will show an orthonormal basis for L2 (H, G) is {fj ⊗ek}

14.6.
COMPACT OPERATORS
393
where {fk} is an orthonormal basis for G and {ek} is an orthonormal basis for H.
Here, for f ∈G and e ∈H,
f ⊗e (x) ≡(x, e) f.
I need to show fj ⊗ek ∈L2 (H, G) and that it is an orthonormal basis for
L2 (H, G) as claimed.
X
k
||fj ⊗ei (ek)||2 =
X
k
||fjδik||2 = ||fj||2 = 1 < ∞
so each of these operators is in L2 (H, G). Next I show they are orthonormal.
(fj ⊗ek, fs ⊗er)
=
X
p
(fj ⊗ek (ep) , fs ⊗er (ep))
=
X
p
δrpδkp (fj, fs) =
X
p
δrpδkpδjs
If j = s and k = r this reduces to 1. Otherwise, this gives 0. Thus these operators
are orthonormal. Now let T ∈L2 (H, G). Consider
Tn ≡
n
X
i=1
n
X
j=1
(Tei, fj) fj ⊗ei
Then
Tnek
=
n
X
i=1
n
X
j=1
(Tei, fj) (ek, ei) fj
=
n
X
j=1
(Tek, fj) fj
It follows
||Tnek|| ≤||Tek||
and
lim
n→∞Tnek = Tek.
Therefore, from the dominated convergence theorem,
lim
n→∞||T −Tn||2
L2 ≡lim
n→∞
X
k
||(T −Tn) ek||2 = 0.
Therefore, the linear combinations of the fj ⊗ei are dense in L2 (H, G) and this
proves completeness.
This also shows L2 (H, G) is separable. From 14.33 it also shows that every
T ∈L2 (H, G) is the limit in the operator norm of a sequence of compact operators.
This follows because each of the fj ⊗ei is easily seen to be a compact operator.

394
HILBERT SPACES
(This follows because each of the fj ⊗ei is easily seen to be a compact operator
because if xm →x weakly, then
fj ⊗ei (xm) = (xm, ei) fj →(x, ei) fj = fj ⊗ei (x)
and since if {xm} is any bounded sequence, there exists a subsequence, {xnk} which
converges weakly and by the above, fj ⊗ei (xnk) →fj ⊗ei (x) showing bounded
sets are mapped to precompact sets.) Therefore, each T ∈L2 (H, G) must also be
a compact operator. Here is why.
Let B be a bounded set in which ||x|| < M for all x ∈B and consider TB. I
need to show TB is totally bounded. Let ε > 0 be given. Then let ||Tm −T|| <
ε
3M
where Tm is a compact operator like those described above and let {Tmxj}N
j=1 be
an ε/3 net for Tm (B) . Then
||Txj −Tmxj|| < ε
3
and so letting x ∈B, pick xj such that ||Tmx −Tmxj|| < ε/3. Then
||Tx −Txj||
≤
||Tx −Tmx|| + ||Tmx −Tmxj|| + ||Tmxj −Txj||
<
ε
3 + ε
3 + ε
3 = ε
showing {Txj}N
j=1 is an ε net for TB.
Finally, consider 14.34. Let {ek} be an orthonormal basis for H and consider
the following computation which establishes which establishes this equation.
||Y ⊗X||2
L2
≡
∞
X
k=1
||Y ⊗X (ek)||2
=
∞
X
k=1
||(ek, X) Y ||2
=
||Y ||2
G
∞
X
k=1
|(ek, X)|2
=
||Y ||2
G ||X||2
H < ∞.
(14.35)
This proves the theorem.
14.7
Compact Operators In Banach Space
In general for A ∈L (X, Y ) the following deﬁnition holds.
Deﬁnition 14.41 Let A ∈L (X, Y ) . Then A is compact if whenever B ⊆X is a
bounded set, AB is precompact. Equivalently, if {xn} is a bounded sequence in X,
then {Axn} has a subsequence which converges in Y.

14.7.
COMPACT OPERATORS IN BANACH SPACE
395
An important result is the following theorem about the adjoint of a compact
operator.
Theorem 14.42 Let A ∈L (X, Y ) be compact. Then the adjoint operator, A∗∈
L (Y ′, X′) is also compact.
Proof: Let {y∗
n} be a bounded sequence in Y ′. Let B be the closure of the
unit ball in X. Then AB is precompact. Then it is clear that the functions {y∗
n}
are equicontinuous and uniformly bounded on the compact set, A (B). By the As-
coli Arzela theorem, there is a subsequence
©
y∗
nk
ª
which converges uniformly to a
continuous function, f on A (B). Now deﬁne g on AX by
g (Ax) = ||x|| f
µ
A
µ x
||x||
¶¶
, g (A0) = 0.
Thus for x1, x2 ̸= 0, and a, b scalars,
g (aAx1 + bAx2)
≡
||ax1 + bx2|| f
µA (ax1 + bx2)
||ax1 + bx2||
¶
≡
lim
k→∞||ax1 + bx2|| y∗
nk
µA (ax1 + bx2)
||ax1 + bx2||
¶
=
lim
k→∞ay∗
nk (Ax1) + by∗
nk (Ax2)
=
a lim
k→∞||x1|| y∗
nk
µ Ax1
||x1||
¶
+ b lim
k→∞||x2|| y∗
nk
µ Ax2
||x2||
¶
=
a ||x1|| f
µ Ax1
||x1||
¶
+ b ||x2|| f
µ Ax2
||x2||
¶
≡
ag (Ax1) + bg (Ax2)
showing that g is linear on AX. Also
|g (Ax)| = lim
k→∞
¯¯¯¯||x|| y∗
nk
µ
A
µ x
||x||
¶¶¯¯¯¯ ≤C ||x||
¯¯¯¯
¯¯¯¯A
µ x
||x||
¶¯¯¯¯
¯¯¯¯ = C ||Ax||
and so by the Hahn Banach theorem, there exists y∗extending g to all of Y having
the same operator norm.
y∗(Ax) = lim
k→∞||x|| y∗
nk
µ
A
µ x
||x||
¶¶
= lim
k→∞y∗
nk (Ax)
Thus A∗y∗
nk (x) →A∗y∗(x) for every x. In addition to this, for x ∈B,
¯¯¯¯A∗y∗(x) −A∗y∗
nk (x)
¯¯¯¯
=
¯¯¯¯y∗(Ax) −y∗
nk (Ax)
¯¯¯¯
=
¯¯¯¯g (Ax) −y∗
nk (Ax)
¯¯¯¯
=
¯¯¯¯
¯¯¯¯||x|| f
µ
A
µ x
||x||
¶¶
−||x|| y∗
nk
µ Ax
||x||
¶¯¯¯¯
¯¯¯¯
≤
¯¯¯¯
¯¯¯¯f
µ
A
µ x
||x||
¶¶
−y∗
nk
µ Ax
||x||
¶¯¯¯¯
¯¯¯¯

396
HILBERT SPACES
and this is uniformly small for large k due to the uniform convergence of y∗
nk to f
on A (B). Therefore,
¯¯¯¯A∗y∗−A∗y∗
nk
¯¯¯¯ →0.
14.8
The Fredholm Alternative
Recall that if A is an n × n matrix and if the only solution to the system, Ax = 0
is x = 0 then for any y ∈Rn it follows that there exists a unique solution to the
system Ax = y. This holds because the ﬁrst condition implies A is one to one and
therefore, A−1 exists. Of course things are much harder in a general Banach space.
Here is a simple example for a Hilbert space.
Example 14.43 Let L2 (N; µ) = H where µ is counting measure. Thus an element
of H is a sequence, a = {ai}∞
i=1 having the property that
||a||H ≡
Ã ∞
X
k=1
|ak|2
!1/2
< ∞.
Deﬁne A : H →H by
Aa ≡b ≡{0, a1, a2, · · ·} .
Thus A slides the sequence to the right and puts a zero in the ﬁrst slot. Clearly A is
one to one and linear but it cannot be onto because it fails to yield e1 ≡{1, 0, 0, · · ·}.
Notwithstanding the above example, there are theorems which are like the linear
algebra theorem mentioned above which hold in an arbitrary Banach spaces in the
case where the operator is compact. To begin with here is an interesting lemma.
Lemma 14.44 Suppose A ∈L (X, X) is compact for X
a Banach space. Then
(I −A) (X) is a closed subspace of X.
Proof: Suppose (I −A) xn →y. Let
αn ≡dist (xn, ker (I −A))
and let zn ∈ker (I −A) be such that
αn ≤||xn −zn|| ≤
µ
1 + 1
n
¶
αn.
Thus (I −A) (xn −zn) →y because (I −A) zn = 0.
Case 1: {xn −zn} has a bounded subsequence.
If this is so, the compactness of A implies there exists a subsequence, still denoted
by n such that {A (xn −zn)}∞
n=1 is a Cauchy sequence. Since (I −A) (xn −zn) →y,
this implies {(xn −zn)} is also a Cauchy sequence converging to a point, x ∈X.
Then, taking the limit as n →∞, (I −A) x = y and so y ∈(I −A) (X).
Case 2: limn→∞||xn −zn|| = ∞. I will show this case cannot occur.

14.8.
THE FREDHOLM ALTERNATIVE
397
In this case, let wn ≡
xn−zn
||xn−zn||.
Thus (I −A) wn →0 and wn is bounded.
Therefore, there exists a subsequence, still denoted by n such that {Awn} is a
Cauchy sequence. Now it follows
Awn −Awm + en −em = wn −wm
where ek →0 as k →∞. This implies {wn} is a Cauchy sequence which must
converge to some w∞∈X. Therefore, (I −A) w∞= 0 and so w∞∈ker (I −A).
However, this is impossible because of the following argument. If z ∈ker (I −A),
||wn −z||
=
1
||xn −zn|| ||xn −zn −||xn −zn|| z||
≥
1
||xn −zn||αn ≥
αn
¡
1 + 1
n
¢
αn
=
n
n + 1.
Taking the limit, ||w∞−z|| ≥1. Since z ∈ker (I −A) is arbitrary, this shows
dist (w∞, ker (I −A)) ≥1.
Since Case 2 does not occur, this proves the lemma.
Theorem 14.45 Let A ∈L (X, X) be a compact operator and let f ∈X. Then
there exists a solution, x, to
x −Ax = f
(14.36)
if and only if
x∗(f) = 0
(14.37)
for all x∗∈ker (I −A∗) .
Proof: Suppose x is a solution to 14.36 and let x∗∈ker (I −A∗). Then
x∗(f) = x∗((I −A) (x)) = ((I −A∗) x∗) (x) = 0.
Next suppose x∗(f) = 0 for all x∗∈ker (I −A∗) . I will show there exists x
solving 14.36. By Lemma 14.44, (I −A) (X) is a closed subspace of X. Is f ∈
(I −A) (X)? If not, then by the Hahn Banach theorem, there exists x∗∈X′ such
that x∗(f) ̸= 0 but x∗((I −A) (x)) = 0 for all x ∈X. However last statement says
nothing more nor less than (I −A∗) x∗= 0. This is a contradiction because for such
x∗, it is given that x∗(f) = 0. This proves the theorem.
The following corollary is called the Fredholm alternative.
Corollary 14.46 Let A ∈L (X, X) be a compact operator. Then there exists a
solution to the equation
x −Ax = f
(14.38)
for all f ∈X if and only if (I −A∗) is one to one on X′.

398
HILBERT SPACES
Proof: Suppose (I −A∗) is one to one ﬁrst. Then if x∗−A∗x∗= 0 it follows
x∗= 0 and so for any f ∈X, x∗(f) = 0 for all x∗∈ker (I −A∗) . By 14.45 there
exists a solution to (I −A) x = f.
Now suppose there exists a solution, x, to (I −A) x = f for every f ∈X. If
(I −A∗) x∗= 0, then for every x ∈X,
(I −A∗) x∗(x) = x∗((I −A) (x)) = 0
Since (I −A) is onto, this shows x∗= 0 and so (I −A∗) is one to one as claimed.
This proves the corollary.
The following is just an easier version of the above.
Corollary 14.47 In the case where X is a Hilbert space, the conclusions of Corol-
lary 14.46, Theorem 14.45, and Lemma 14.44 remain true if H′ is replaced by H
and the adjoint is understood in the usual manner for Hilbert space. That is
(Ax, y)H = (x, A∗y)H

Representation Theorems
15.1
Radon Nikodym Theorem
This chapter is on various representation theorems. The ﬁrst theorem, the Radon
Nikodym Theorem, is a representation theorem for one measure in terms of an-
other. The approach given here is due to Von Neumann and depends on the Riesz
representation theorem for Hilbert space, Theorem 14.14 on Page 370.
Deﬁnition 15.1 Let µ and λ be two measures deﬁned on a σ-algebra, S, of subsets
of a set, Ω.
λ is absolutely continuous with respect to µ,written as λ ≪µ, if
λ(E) = 0 whenever µ(E) = 0.
It is not hard to think of examples which should be like this.
For example,
suppose one measure is volume and the other is mass. If the volume of something
is zero, it is reasonable to expect the mass of it should also be equal to zero. In
this case, there is a function called the density which is integrated over volume to
obtain mass. The Radon Nikodym theorem is an abstract version of this notion.
Essentially, it gives the existence of the density function.
Theorem 15.2 (Radon Nikodym) Let λ and µ be ﬁnite measures deﬁned on a σ-
algebra, S, of subsets of Ω. Suppose λ ≪µ. Then there exists a unique f ∈L1(Ω, µ)
such that f(x) ≥0 and
λ(E) =
Z
E
f dµ.
If it is not necessarily the case that λ ≪µ, there are two measures, λ⊥and λ|| such
that λ = λ⊥+ λ||, λ|| ≪µ and there exists a set of µ measure zero, N such that for
all E measurable, λ⊥(E) = λ (E ∩N) = λ⊥(E ∩N) . In this case the two mesures,
λ⊥and λ|| are unique and the representation of λ = λ⊥+ λ|| is called the Lebesgue
decomposition of λ. The measure λ|| is the absolutely continuous part of λ and λ⊥
is called the singular part of λ.
Proof: Let Λ : L2(Ω, µ + λ) →C be deﬁned by
Λg =
Z
Ω
g dλ.
399

400
REPRESENTATION THEOREMS
By Holder’s inequality,
|Λg| ≤
µZ
Ω
12dλ
¶1/2 µZ
Ω
|g|2 d (λ + µ)
¶1/2
= λ (Ω)1/2 ||g||2
where ||g||2 is the L2 norm of g taken with respect to µ + λ. Therefore, since Λ
is bounded, it follows from Theorem 13.4 on Page 339 that Λ ∈(L2(Ω, µ + λ))′,
the dual space L2(Ω, µ + λ). By the Riesz representation theorem in Hilbert space,
Theorem 14.14, there exists a unique h ∈L2(Ω, µ + λ) with
Λg =
Z
Ω
g dλ =
Z
Ω
hgd(µ + λ).
(15.1)
The plan is to show h is real and nonnegative at least a.e. Therefore, consider the
set where Im h is positive.
E = {x ∈Ω: Im h(x) > 0} ,
Now let g = XE and use 15.1 to get
λ(E) =
Z
E
(Re h + i Im h)d(µ + λ).
(15.2)
Since the left side of 15.2 is real, this shows
0
=
Z
E
(Im h) d(µ + λ)
≥
Z
En
(Im h) d(µ + λ)
≥
1
n (µ + λ) (En)
where
En ≡
½
x : Im h (x) ≥1
n
¾
Thus (µ + λ) (En) = 0 and since E = ∪∞
n=1En, it follows (µ + λ) (E) = 0. A similar
argument shows that for
E = {x ∈Ω: Im h (x) < 0},
(µ + λ)(E) = 0. Thus there is no loss of generality in assuming h is real-valued.
The next task is to show h is nonnegative. This is done in the same manner as
above. Deﬁne the set where it is negative and then show this set has measure zero.
Let E ≡{x : h(x) < 0} and let En ≡{x : h(x) < −1
n}. Then let g = XEn. Since
E = ∪nEn, it follows that if (µ + λ) (E) > 0 then this is also true for (µ + λ) (En)
for all n large enough. Then from 15.2
λ(En) =
Z
En
h d(µ + λ) ≤−(1/n) (µ + λ) (En) < 0,

15.1.
RADON NIKODYM THEOREM
401
a contradiction. Thus it can be assumed h ≥0.
At this point the argument splits into two cases.
Case Where λ ≪µ.
In this case, h < 1. Let E = [h ≥1] and let g = XE. Then
λ(E) =
Z
E
h d(µ + λ) ≥µ(E) + λ(E).
Therefore µ(E) = 0. Since λ ≪µ, it follows that λ(E) = 0 also. Thus it can be
assumed
0 ≤h(x) < 1
for all x.
From 15.1, whenever g ∈L2(Ω, µ + λ),
Z
Ω
g(1 −h)dλ =
Z
Ω
hgdµ.
(15.3)
Now let E be a measurable set and deﬁne
g(x) ≡
n
X
i=0
hi(x)XE(x)
in 15.3. This yields
Z
E
(1 −hn+1(x))dλ =
Z
E
n+1
X
i=1
hi(x)dµ.
(15.4)
Let f(x) = P∞
i=1 hi(x) and use the Monotone Convergence theorem in 15.4 to let
n →∞and conclude
λ(E) =
Z
E
f dµ.
f ∈L1(Ω, µ) because λ is ﬁnite.
The function, f is unique µ a.e. because, if g is another function which also
serves to represent λ, consider for each n ∈N the set,
En ≡
·
f −g > 1
n
¸
and conclude that
0 =
Z
En
(f −g) dµ ≥1
nµ (En) .
Therefore, µ (En) = 0. It follows that
µ ([f −g > 0]) ≤
∞
X
n=1
µ (En) = 0

402
REPRESENTATION THEOREMS
Similarly, the set where g is larger than f has measure zero.
This proves the
theorem.
Case where it is not necessarily true that λ ≪µ.
In this case, let N = [h ≥1] and let g = XN. Then
λ(N) =
Z
N
h d(µ + λ) ≥µ(N) + λ(N).
and so µ (N) = 0 and so µ (E) = µ
¡
E ∩N C¢
. Now deﬁne a measure, λ⊥by
λ⊥(E) ≡λ (E ∩N)
so
λ⊥(E ∩N) ≡λ (E ∩N ∩N) = λ (E ∩N) ≡λ⊥(E)
and let λ|| ≡λ −λ⊥. Thus,
λ|| (E) = λ (E) −λ⊥(E) ≡λ (E) −λ (E ∩N) = λ
¡
E ∩N C¢
.
Suppose now that λ|| (E) > 0. It follows from the ﬁrst part of the proof that since
h < 1 on N C
0
<
λ|| (E) = λ
¡
E ∩N C¢
=
Z
E∩N C h d(µ + λ)
<
µ
¡
E ∩N C¢
+ λ
¡
E ∩N C¢
= µ (E) + λ|| (E)
which shows that µ (E) > 0. Thus if µ (E) = 0 it follows λ|| (E) = 0 and so λ|| ≪µ.
It only remains to verify the two measures λ⊥and λ|| are unique. Suppose then
that ν1 and ν2 play the roles of λ⊥and λ|| respectively. Let N1 play the role of N
in the deﬁnition of ν1 and let g1 play the role of g for ν2. I will show that g = g1 µ
a.e. Let Ek ≡[g1 −g > 1/k] for k ∈N. Then on observing that λ⊥−ν1 = ν2 −λ||
0
=
(λ⊥−ν1)
³
En ∩(N1 ∪N)C´
=
Z
En∩(N1∪N)C (g1 −g) dµ
≥
1
k µ
³
Ek ∩(N1 ∪N)C´
= 1
k µ (Ek) .
and so µ (Ek) = 0. Therefore, µ ([g1 −g > 0]) = 0 because [g1 −g > 0] = ∪∞
k=1Ek.
It follows g1 ≤g µ a.e. Similarly, g ≥g1 µ a.e. Therefore, ν2 = λ|| and so λ⊥= ν1
also. This proves the theorem.
The f in the theorem for the absolutely continuous case is sometimes denoted
by dλ
dµ and is called the Radon Nikodym derivative.
The next corollary is a useful generalization to σ ﬁnite measure spaces.
Corollary 15.3 Suppose λ ≪µ and there exist sets Sn ∈S with
Sn ∩Sm = ∅, ∪∞
n=1Sn = Ω,

15.1.
RADON NIKODYM THEOREM
403
and λ(Sn), µ(Sn) < ∞. Then there exists f ≥0, where f is µ measurable, and
λ(E) =
Z
E
f dµ
for all E ∈S. The function f is µ + λ a.e. unique.
Proof: Deﬁne the σ algebra of subsets of Sn,
Sn ≡{E ∩Sn : E ∈S}.
Then both λ, and µ are ﬁnite measures on Sn, and λ ≪µ. Thus, by Theorem 15.2,
there exists a nonnegative Sn measurable function fn,with λ(E) =
R
E fndµ for all
E ∈Sn. Deﬁne f(x) = fn(x) for x ∈Sn. Since the Sn are disjoint and their union
is all of Ω, this deﬁnes f on all of Ω. The function, f is measurable because
f −1((a, ∞]) = ∪∞
n=1f −1
n ((a, ∞]) ∈S.
Also, for E ∈S,
λ(E)
=
∞
X
n=1
λ(E ∩Sn) =
∞
X
n=1
Z
XE∩Sn(x)fn(x)dµ
=
∞
X
n=1
Z
XE∩Sn(x)f(x)dµ
By the monotone convergence theorem
∞
X
n=1
Z
XE∩Sn(x)f(x)dµ
=
lim
N→∞
N
X
n=1
Z
XE∩Sn(x)f(x)dµ
=
lim
N→∞
Z
N
X
n=1
XE∩Sn(x)f(x)dµ
=
Z
∞
X
n=1
XE∩Sn(x)f(x)dµ =
Z
E
f dµ.
This proves the existence part of the corollary.
To see f is unique, suppose f1 and f2 both work and consider for n ∈N
Ek ≡
·
f1 −f2 > 1
k
¸
.
Then
0 = λ(Ek ∩Sn) −λ(Ek ∩Sn) =
Z
Ek∩Sn
f1(x) −f2(x)dµ.
Hence µ(Ek ∩Sn) = 0 for all n so
µ(Ek) = lim
n→∞µ(E ∩Sn) = 0.

404
REPRESENTATION THEOREMS
Hence µ([f1 −f2 > 0]) ≤P∞
k=1 µ (Ek) = 0. Therefore, λ ([f1 −f2 > 0]) = 0 also.
Similarly
(µ + λ) ([f1 −f2 < 0]) = 0.
This version of the Radon Nikodym theorem will suﬃce for most applications,
but more general versions are available.
To see one of these, one can read the
treatment in Hewitt and Stromberg [26]. This involves the notion of decomposable
measure spaces, a generalization of σ ﬁnite.
Not surprisingly, there is a simple generalization of the Lebesgue decomposition
part of Theorem 15.2.
Corollary 15.4 Let (Ω, S) be a set with a σ algebra of sets. Suppose λ and µ are
two measures deﬁned on the sets of S and suppose there exists a sequence of disjoint
sets of S, {Ωi}∞
i=1 such that λ (Ωi) , µ (Ωi) < ∞. Then there is a set of µ measure
zero, N and measures λ⊥and λ|| such that
λ⊥+ λ|| = λ, λ|| ≪µ, λ⊥(E) = λ (E ∩N) = λ⊥(E ∩N) .
Proof: Let Si ≡{E ∩Ωi : E ∈S} and for E ∈Si, let λi (E) = λ (E) and
µi (E) = µ (E) . Then by Theorem 15.2 there exist unique measures λi
⊥and λi
||
such that λi = λi
⊥+ λi
||, a set of µi measure zero, Ni ∈Si such that for all E ∈Si,
λi
⊥(E) = λi (E ∩Ni) and λi
|| ≪µi. Deﬁne for E ∈S
λ⊥(E) ≡
X
i
λi
⊥(E ∩Ωi) , λ|| (E) ≡
X
i
λi
|| (E ∩Ωi) , N ≡∪iNi.
First observe that λ⊥and λ|| are measures.
λ⊥
¡
∪∞
j=1Ej
¢
≡
X
i
λi
⊥
¡
∪∞
j=1Ej ∩Ωi
¢
=
X
i
X
j
λi
⊥(Ej ∩Ωi)
=
X
j
X
i
λi
⊥(Ej ∩Ωi) =
X
j
X
i
λ (Ej ∩Ωi ∩Ni)
=
X
j
X
i
λi
⊥(Ej ∩Ωi) =
X
j
λ⊥(Ej) .
The argument for λ|| is similar. Now
µ (N) =
X
i
µ (N ∩Ωi) =
X
i
µi (Ni) = 0
and
λ⊥(E)
≡
X
i
λi
⊥(E ∩Ωi) =
X
i
λi (E ∩Ωi ∩Ni)
=
X
i
λ (E ∩Ωi ∩N) = λ (E ∩N) .

15.2.
VECTOR MEASURES
405
Also if µ (E) = 0, then µi (E ∩Ωi) = 0 and so λi
|| (E ∩Ωi) = 0. Therefore,
λ|| (E) =
X
i
λi
|| (E ∩Ωi) = 0.
The decomposition is unique because of the uniqueness of the λi
|| and λi
⊥and the
observation that some other decomposition must coincide with the given one on the
Ωi.
15.2
Vector Measures
The next topic will use the Radon Nikodym theorem. It is the topic of vector and
complex measures. The main interest is in complex measures although a vector
measure can have values in any topological vector space. Whole books have been
written on this subject. See for example the book by Diestal and Uhl [16] titled
Vector measures.
Deﬁnition 15.5 Let (V, ||·||) be a normed linear space and let (Ω, S) be a measure
space. A function µ : S →V is a vector measure if µ is countably additive. That
is, if {Ei}∞
i=1 is a sequence of disjoint sets of S,
µ(∪∞
i=1Ei) =
∞
X
i=1
µ(Ei).
Note that it makes sense to take ﬁnite sums because it is given that µ has
values in a vector space in which vectors can be summed. In the above, µ (Ei) is a
vector. It might be a point in Rn or in any other vector space. In many of the most
important applications, it is a vector in some sort of function space which may be
inﬁnite dimensional. The inﬁnite sum has the usual meaning. That is
∞
X
i=1
µ(Ei) = lim
n→∞
n
X
i=1
µ(Ei)
where the limit takes place relative to the norm on V .
Deﬁnition 15.6 Let (Ω, S) be a measure space and let µ be a vector measure deﬁned
on S. A subset, π(E), of S is called a partition of E if π(E) consists of ﬁnitely
many disjoint sets of S and ∪π(E) = E. Let
|µ|(E) = sup{
X
F ∈π(E)
||µ(F)|| : π(E) is a partition of E}.
|µ| is called the total variation of µ.
The next theorem may seem a little surprising. It states that, if ﬁnite, the total
variation is a nonnegative measure.

406
REPRESENTATION THEOREMS
Theorem 15.7 If |µ|(Ω) < ∞, then |µ| is a measure on S.
Even if |µ| (Ω) =
∞, |µ| (∪∞
i=1Ei) ≤P∞
i=1 |µ| (Ei) . That is |µ| is subadditive and |µ| (A) ≤|µ| (B)
whenever A, B ∈S with A ⊆B.
Proof: Consider the last claim. Let a < |µ| (A) and let π (A) be a partition of
A such that
a <
X
F ∈π(A)
||µ (F)|| .
Then π (A) ∪{B \ A} is a partition of B and
|µ| (B) ≥
X
F ∈π(A)
||µ (F)|| + ||µ (B \ A)|| > a.
Since this is true for all such a, it follows |µ| (B) ≥|µ| (A) as claimed.
Let {Ej}∞
j=1 be a sequence of disjoint sets of S and let E∞= ∪∞
j=1Ej. Then
letting a < |µ| (E∞) , it follows from the deﬁnition of total variation there exists a
partition of E∞, π(E∞) = {A1, · · ·, An} such that
a <
n
X
i=1
||µ(Ai)||.
Also,
Ai = ∪∞
j=1Ai ∩Ej
and so by the triangle inequality, ||µ(Ai)|| ≤P∞
j=1 ||µ(Ai ∩Ej)||. Therefore, by the
above, and either Fubini’s theorem or Lemma 8.21 on Page 184
a
<
n
X
i=1
≥||µ(Ai)||
z
}|
{
∞
X
j=1
||µ(Ai ∩Ej)||
=
∞
X
j=1
n
X
i=1
||µ(Ai ∩Ej)||
≤
∞
X
j=1
|µ|(Ej)
because {Ai ∩Ej}n
i=1 is a partition of Ej.
Since a is arbitrary, this shows
|µ|(∪∞
j=1Ej) ≤
∞
X
j=1
|µ|(Ej).
If the sets, Ej are not disjoint, let F1 = E1 and if Fn has been chosen, let Fn+1 ≡
En+1 \ ∪n
i=1Ei. Thus the sets, Fi are disjoint and ∪∞
i=1Fi = ∪∞
i=1Ei. Therefore,
|µ|
¡
∪∞
j=1Ej
¢
= |µ|
¡
∪∞
j=1Fj
¢
≤
∞
X
j=1
|µ| (Fj) ≤
∞
X
j=1
|µ| (Ej)

15.2.
VECTOR MEASURES
407
and proves |µ| is always subadditive as claimed regarless of whether |µ| (Ω) < ∞.
Now suppose |µ| (Ω) < ∞and let E1 and E2 be sets of S such that E1 ∩E2 = ∅
and let {Ai
1 · · · Ai
ni} = π(Ei), a partition of Ei which is chosen such that
|µ| (Ei) −ε <
ni
X
j=1
||µ(Ai
j)|| i = 1, 2.
Such a partition exists because of the deﬁnition of the total variation. Consider the
sets which are contained in either of π (E1) or π (E2) , it follows this collection of
sets is a partition of E1 ∪E2 denoted by π(E1 ∪E2). Then by the above inequality
and the deﬁnition of total variation,
|µ|(E1 ∪E2) ≥
X
F ∈π(E1∪E2)
||µ(F)|| > |µ| (E1) + |µ| (E2) −2ε,
which shows that since ε > 0 was arbitrary,
|µ|(E1 ∪E2) ≥|µ|(E1) + |µ|(E2).
(15.5)
Then 15.5 implies that whenever the Ei are disjoint, |µ|(∪n
j=1Ej) ≥Pn
j=1 |µ|(Ej).
Therefore,
∞
X
j=1
|µ|(Ej) ≥|µ|(∪∞
j=1Ej) ≥|µ|(∪n
j=1Ej) ≥
n
X
j=1
|µ|(Ej).
Since n is arbitrary,
|µ|(∪∞
j=1Ej) =
∞
X
j=1
|µ|(Ej)
which shows that |µ| is a measure as claimed. This proves the theorem.
In the case that µ is a complex measure, it is always the case that |µ| (Ω) < ∞.
Theorem 15.8 Suppose µ is a complex measure on (Ω, S) where S is a σ algebra
of subsets of Ω. That is, whenever, {Ei} is a sequence of disjoint sets of S,
µ (∪∞
i=1Ei) =
∞
X
i=1
µ (Ei) .
Then |µ| (Ω) < ∞.
Proof: First here is a claim.
Claim: Suppose |µ| (E) = ∞. Then there are subsets of E, A and B such that
E = A ∪B, |µ (A)| , |µ (B)| > 1 and |µ| (B) = ∞.
Proof of the claim: From the deﬁnition of |µ| , there exists a partition of
E, π (E) such that
X
F ∈π(E)
|µ (F)| > 20 (1 + |µ (E)|) .
(15.6)

408
REPRESENTATION THEOREMS
Here 20 is just a nice sized number. No eﬀort is made to be delicate in this argument.
Also note that µ (E) ∈C because it is given that µ is a complex measure. Consider
the following picture consisting of two lines in the complex plane having slopes 1
and -1 which intersect at the origin, dividing the complex plane into four closed
sets, R1, R2, R3, and R4 as shown.
¡
¡
¡
¡
¡
¡
¡
¡
¡¡
@
@
@
@
@
@
@
@
@@
R1
R2
R3
R4
Let πi consist of those sets, A of π (E) for which µ (A) ∈Ri. Thus, some sets,
A of π (E) could be in two of the πi if µ (A) is on one of the intersecting lines. This
is not important. The thing which is important is that if µ (A) ∈R1 or R3, then
√
2
2 |µ (A)| ≤|Re (µ (A))| and if µ (A) ∈R2 or R4 then
√
2
2 |µ (A)| ≤|Im (µ (A))| and
Re (z) has the same sign for z in R1 and R3 while Im (z) has the same sign for z in
R2 or R4. Then by 15.6, it follows that for some i,
X
F ∈πi
|µ (F)| > 5 (1 + |µ (E)|) .
(15.7)
Suppose i equals 1 or 3. A similar argument using the imaginary part applies if i
equals 2 or 4. Then,
¯¯¯¯¯
X
F ∈πi
µ (F)
¯¯¯¯¯
≥
¯¯¯¯¯
X
F ∈πi
Re (µ (F))
¯¯¯¯¯ =
X
F ∈πi
|Re (µ (F))|
≥
√
2
2
X
F ∈πi
|µ (F)| > 5
√
2
2 (1 + |µ (E)|) .
Now letting C be the union of the sets in πi,
|µ (C)| =
¯¯¯¯¯
X
F ∈πi
µ (F)
¯¯¯¯¯ > 5
2 (1 + |µ (E)|) > 1.
(15.8)
Deﬁne D ≡E \ C.

15.2.
VECTOR MEASURES
409
E
C
Then µ (C) + µ (E \ C) = µ (E) and so
5
2 (1 + |µ (E)|)
<
|µ (C)| = |µ (E) −µ (E \ C)|
=
|µ (E) −µ (D)| ≤|µ (E)| + |µ (D)|
and so
1 < 5
2 + 3
2 |µ (E)| < |µ (D)| .
Now since |µ| (E) = ∞, it follows from Theorem 15.8 that ∞= |µ| (E) ≤|µ| (C) +
|µ| (D) and so either |µ| (C) = ∞or |µ| (D) = ∞. If |µ| (C) = ∞, let B = C and
A = D. Otherwise, let B = D and A = C. This proves the claim.
Now suppose |µ| (Ω) = ∞. Then from the claim, there exist A1 and B1 such that
|µ| (B1) = ∞, |µ (B1)| , |µ (A1)| > 1, and A1 ∪B1 = Ω. Let B1 ≡Ω\A play the same
role as Ωand obtain A2, B2 ⊆B1 such that |µ| (B2) = ∞, |µ (B2)| , |µ (A2)| > 1,
and A2 ∪B2 = B1. Continue in this way to obtain a sequence of disjoint sets, {Ai}
such that |µ (Ai)| > 1. Then since µ is a measure,
µ (∪∞
i=1Ai) =
∞
X
i=1
µ (Ai)
but this is impossible because limi→∞µ (Ai) ̸= 0. This proves the theorem.
Theorem 15.9 Let (Ω, S) be a measure space and let λ : S →C be a complex
vector measure. Thus |λ|(Ω) < ∞. Let µ : S →[0, µ(Ω)] be a ﬁnite measure such
that λ ≪µ. Then there exists a unique f ∈L1(Ω) such that for all E ∈S,
Z
E
fdµ = λ(E).
Proof: It is clear that Re λ and Im λ are real-valued vector measures on S.
Since |λ|(Ω) < ∞, it follows easily that | Re λ|(Ω) and | Im λ|(Ω) < ∞. This is clear
because
|λ (E)| ≥|Re λ (E)| , |Im λ (E)| .

410
REPRESENTATION THEOREMS
Therefore, each of
| Re λ| + Re λ
2
, | Re λ| −Re(λ)
2
, | Im λ| + Im λ
2
, and | Im λ| −Im(λ)
2
are ﬁnite measures on S. It is also clear that each of these ﬁnite measures are abso-
lutely continuous with respect to µ and so there exist unique nonnegative functions
in L1(Ω), f1, f2, g1, g2 such that for all E ∈S,
1
2(| Re λ| + Re λ)(E)
=
Z
E
f1dµ,
1
2(| Re λ| −Re λ)(E)
=
Z
E
f2dµ,
1
2(| Im λ| + Im λ)(E)
=
Z
E
g1dµ,
1
2(| Im λ| −Im λ)(E)
=
Z
E
g2dµ.
Now let f = f1 −f2 + i(g1 −g2).
The following corollary is about representing a vector measure in terms of its
total variation. It is like representing a complex number in the form reiθ. The proof
requires the following lemma.
Lemma 15.10 Suppose (Ω, S, µ) is a measure space and f is a function in L1(Ω, µ)
with the property that
|
Z
E
f dµ| ≤µ(E)
for all E ∈S. Then |f| ≤1 a.e.
Proof of the lemma: Consider the following picture.

1
(0, 0)
.
p
B(p, r)
where B(p, r) ∩B(0, 1) = ∅. Let E = f −1(B(p, r)). In fact µ (E) = 0. If µ(E) ̸= 0
then
¯¯¯¯
1
µ(E)
Z
E
f dµ −p
¯¯¯¯
=
¯¯¯¯
1
µ(E)
Z
E
(f −p)dµ
¯¯¯¯
≤
1
µ(E)
Z
E
|f −p|dµ < r
because on E, |f (x) −p| < r. Hence
|
1
µ(E)
Z
E
fdµ| > 1

15.2.
VECTOR MEASURES
411
because it is closer to p than r. (Refer to the picture.) However, this contradicts the
assumption of the lemma. It follows µ(E) = 0. Since the set of complex numbers,
z such that |z| > 1 is an open set, it equals the union of countably many balls,
{Bi}∞
i=1 . Therefore,
µ
¡
f −1({z ∈C : |z| > 1}
¢
=
µ
¡
∪∞
k=1f −1 (Bk)
¢
≤
∞
X
k=1
µ
¡
f −1 (Bk)
¢
= 0.
Thus |f(x)| ≤1 a.e. as claimed. This proves the lemma.
Corollary 15.11 Let λ be a complex vector measure with |λ|(Ω) < ∞1 Then there
exists a unique f ∈L1(Ω) such that λ(E) =
R
E fd|λ|. Furthermore, |f| = 1 for |λ|
a.e. This is called the polar decomposition of λ.
Proof: First note that λ ≪|λ| and so such an L1 function exists and is unique.
It is required to show |f| = 1 a.e. If |λ|(E) ̸= 0,
¯¯¯¯
λ(E)
|λ|(E)
¯¯¯¯ =
¯¯¯¯
1
|λ|(E)
Z
E
f d|λ|
¯¯¯¯ ≤1.
Therefore by Lemma 15.10, |f| ≤1, |λ| a.e. Now let
En =
·
|f| ≤1 −1
n
¸
.
Let {F1, · · ·, Fm} be a partition of En. Then
m
X
i=1
|λ (Fi)|
=
m
X
i=1
¯¯¯¯
Z
Fi
fd |λ|
¯¯¯¯ ≤
m
X
i=1
Z
Fi
|f| d |λ|
≤
m
X
i=1
Z
Fi
µ
1 −1
n
¶
d |λ| =
m
X
i=1
µ
1 −1
n
¶
|λ| (Fi)
=
|λ| (En)
µ
1 −1
n
¶
.
Then taking the supremum over all partitions,
|λ| (En) ≤
µ
1 −1
n
¶
|λ| (En)
which shows |λ| (En) = 0. Hence |λ| ([|f| < 1]) = 0 because [|f| < 1] = ∪∞
n=1En.This
proves Corollary 15.11.
1As proved above, the assumption that |λ| (Ω) < ∞is redundant.

412
REPRESENTATION THEOREMS
Corollary 15.12 Suppose (Ω, S) is a measure space and µ is a ﬁnite nonnegative
measure on S. Then for h ∈L1 (µ) , deﬁne a complex measure, λ by
λ (E) ≡
Z
E
hdµ.
Then
|λ| (E) =
Z
E
|h| dµ.
Furthermore, |h| = gh where gd |λ| is the polar decomposition of λ,
λ (E) =
Z
E
gd |λ|
Proof: From Corollary 15.11 there exists g such that |g| = 1, |λ| a.e. and for
all E ∈S
λ (E) =
Z
E
gd |λ| =
Z
E
hdµ.
Let sn be a sequence of simple functions converging pointwise to g. Then from the
above,
Z
E
gsnd |λ| =
Z
E
snhdµ.
Passing to the limit using the dominated convergence theorem,
Z
E
d |λ| =
Z
E
ghdµ.
It follows gh ≥0 a.e. and |g| = 1. Therefore, |h| = |gh| = gh. It follows from the
above, that
|λ| (E) =
Z
E
d |λ| =
Z
E
ghdµ =
Z
E
d |λ| =
Z
E
|h| dµ
and this proves the corollary.
15.3
Representation Theorems For The Dual Space
Of Lp
Recall the concept of the dual space of a Banach space in the Chapter on Banach
space starting on Page 337. The next topic deals with the dual space of Lp for p ≥1
in the case where the measure space is σ ﬁnite or ﬁnite. In what follows q = ∞if
p = 1 and otherwise, 1
p + 1
q = 1.
Theorem 15.13 (Riesz representation theorem) Let p > 1 and let (Ω, S, µ) be a
ﬁnite measure space. If Λ ∈(Lp(Ω))′, then there exists a unique h ∈Lq(Ω) ( 1
p + 1
q =
1) such that
Λf =
Z
Ω
hfdµ.
This function satisﬁes ||h||q = ||Λ|| where ||Λ|| is the operator norm of Λ.

15.3.
REPRESENTATION THEOREMS FOR THE DUAL SPACE OF LP
413
Proof: (Uniqueness) If h1 and h2 both represent Λ, consider
f = |h1 −h2|q−2(h1 −h2),
where h denotes complex conjugation. By Holder’s inequality, it is easy to see that
f ∈Lp(Ω). Thus
0 = Λf −Λf =
Z
h1|h1 −h2|q−2(h1 −h2) −h2|h1 −h2|q−2(h1 −h2)dµ
=
Z
|h1 −h2|qdµ.
Therefore h1 = h2 and this proves uniqueness.
Now let λ(E) = Λ(XE). Since this is a ﬁnite measure space XE is an element
of Lp (Ω) and so it makes sense to write Λ (XE). In fact λ is a complex measure
having ﬁnite total variation. Let A1, · · ·, An be a partition of Ω.
|ΛXAi| = wi(ΛXAi) = Λ(wiXAi)
for some wi ∈C, |wi| = 1. Thus
n
X
i=1
|λ(Ai)| =
n
X
i=1
|Λ(XAi)| = Λ(
n
X
i=1
wiXAi)
≤||Λ||(
Z
|
n
X
i=1
wiXAi|pdµ)
1
p = ||Λ||(
Z
Ω
dµ)
1
p = ||Λ||µ(Ω)
1
p.
This is because if x ∈Ω, x is contained in exactly one of the Ai and so the absolute
value of the sum in the ﬁrst integral above is equal to 1. Therefore |λ|(Ω) < ∞
because this was an arbitrary partition. Also, if {Ei}∞
i=1 is a sequence of disjoint
sets of S, let
Fn = ∪n
i=1Ei, F = ∪∞
i=1Ei.
Then by the Dominated Convergence theorem,
||XFn −XF ||p →0.
Therefore, by continuity of Λ,
λ(F) = Λ(XF ) = lim
n→∞Λ(XFn) = lim
n→∞
n
X
k=1
Λ(XEk) =
∞
X
k=1
λ(Ek).
This shows λ is a complex measure with |λ| ﬁnite.
It is also clear from the deﬁnition of λ that λ ≪µ. Therefore, by the Radon
Nikodym theorem, there exists h ∈L1(Ω) with
λ(E) =
Z
E
hdµ = Λ(XE).

414
REPRESENTATION THEOREMS
Actually h ∈Lq and satisﬁes the other conditions above. Let s = Pm
i=1 ciXEi be a
simple function. Then since Λ is linear,
Λ(s) =
m
X
i=1
ciΛ(XEi) =
m
X
i=1
ci
Z
Ei
hdµ =
Z
hsdµ.
(15.9)
Claim: If f is uniformly bounded and measurable, then
Λ (f) =
Z
hfdµ.
Proof of claim: Since f is bounded and measurable, there exists a sequence of
simple functions, {sn} which converges to f pointwise and in Lp (Ω). This follows
from Theorem 8.27 on Page 190 upon breaking f up into positive and negative parts
of real and complex parts. In fact this theorem gives uniform convergence. Then
Λ (f) = lim
n→∞Λ (sn) = lim
n→∞
Z
hsndµ =
Z
hfdµ,
the ﬁrst equality holding because of continuity of Λ, the second following from 15.9
and the third holding by the dominated convergence theorem.
This is a very nice formula but it still has not been shown that h ∈Lq (Ω).
Let En = {x : |h(x)| ≤n}. Thus |hXEn| ≤n. Then
|hXEn|q−2(hXEn) ∈Lp(Ω).
By the claim, it follows that
||hXEn||q
q =
Z
h|hXEn|q−2(hXEn)dµ = Λ(|hXEn|q−2(hXEn))
≤||Λ||
¯¯¯¯|hXEn|q−2(hXEn)
¯¯¯¯
p = ||Λ|| ||hXEn||
q
pq,
the last equality holding because q −1 = q/p and so
µZ ¯¯|hXEn|q−2(hXEn)
¯¯p dµ
¶1/p
=
µZ ³
|hXEn|q/p´p
dµ
¶1/p
=
||hXEn||
q
pq
Therefore, since q −q
p = 1, it follows that
||hXEn||q ≤||Λ||.
Letting n →∞, the Monotone Convergence theorem implies
||h||q ≤||Λ||.
(15.10)

15.3.
REPRESENTATION THEOREMS FOR THE DUAL SPACE OF LP
415
Now that h has been shown to be in Lq(Ω), it follows from 15.9 and the density
of the simple functions, Theorem 12.13 on Page 323, that
Λf =
Z
hfdµ
for all f ∈Lp(Ω).
It only remains to verify the last claim.
||Λ|| = sup{
Z
hf : ||f||p ≤1} ≤||h||q ≤||Λ||
by 15.10, and Holder’s inequality. This proves the theorem.
To represent elements of the dual space of L1(Ω), another Banach space is
needed.
Deﬁnition 15.14 Let (Ω, S, µ) be a measure space. L∞(Ω) is the vector space of
measurable functions such that for some M > 0, |f(x)| ≤M for all x outside of
some set of measure zero (|f(x)| ≤M a.e.). Deﬁne f = g when f(x) = g(x) a.e.
and ||f||∞≡inf{M : |f(x)| ≤M a.e.}.
Theorem 15.15 L∞(Ω) is a Banach space.
Proof: It is clear that L∞(Ω) is a vector space. Is || ||∞a norm?
Claim: If f ∈L∞(Ω), then |f (x)| ≤||f||∞a.e.
Proof of the claim:
©
x : |f (x)| ≥||f||∞+ n−1ª
≡En is a set of measure zero
according to the deﬁnition of ||f||∞. Furthermore, {x : |f (x)| > ||f||∞} = ∪nEn
and so it is also a set of measure zero. This veriﬁes the claim.
Now if ||f||∞= 0 it follows that f (x) = 0 a.e. Also if f, g ∈L∞(Ω),
|f (x) + g (x)| ≤|f (x)| + |g (x)| ≤||f||∞+ ||g||∞
a.e. and so ||f||∞+ ||g||∞serves as one of the constants, M in the deﬁnition of
||f + g||∞. Therefore,
||f + g||∞≤||f||∞+ ||g||∞.
Next let c be a number. Then |cf (x)| = |c| |f (x)| ≤|c| ||f||∞and so ||cf||∞≤
|c| ||f||∞. Therefore since c is arbitrary, ||f||∞= ||c (1/c) f||∞≤
¯¯ 1
c
¯¯ ||cf||∞which
implies |c| ||f||∞≤||cf||∞. Thus || ||∞is a norm as claimed.
To verify completeness, let {fn} be a Cauchy sequence in L∞(Ω) and use the
above claim to get the existence of a set of measure zero, Enm such that for all
x /∈Enm,
|fn(x) −fm(x)| ≤||fn −fm||∞
Let E = ∪n,mEnm. Thus µ(E) = 0 and for each x /∈E, {fn(x)}∞
n=1 is a Cauchy
sequence in C. Let
f(x) =
½
0 if x ∈E
limn→∞fn(x) if x /∈E
= lim
n→∞XEC(x)fn(x).

416
REPRESENTATION THEOREMS
Then f is clearly measurable because it is the limit of measurable functions. If
Fn = {x : |fn(x)| > ||fn||∞}
and F = ∪∞
n=1Fn, it follows µ(F) = 0 and that for x /∈F ∪E,
|f(x)| ≤lim inf
n→∞|fn(x)| ≤lim inf
n→∞||fn||∞< ∞
because {||fn||∞} is a Cauchy sequence. (|||fn||∞−||fm||∞| ≤||fn −fm||∞by the
triangle inequality.) Thus f ∈L∞(Ω). Let n be large enough that whenever m > n,
||fm −fn||∞< ε.
Then, if x /∈E,
|f(x) −fn(x)|
=
lim
m→∞|fm(x) −fn(x)|
≤
lim
m→∞inf ||fm −fn||∞< ε.
Hence ||f −fn||∞< ε for all n large enough. This proves the theorem.
The next theorem is the Riesz representation theorem for
¡
L1 (Ω)
¢′.
Theorem 15.16 (Riesz representation theorem) Let (Ω, S, µ) be a ﬁnite measure
space. If Λ ∈(L1(Ω))′, then there exists a unique h ∈L∞(Ω) such that
Λ(f) =
Z
Ω
hf dµ
for all f ∈L1(Ω). If h is the function in L∞(Ω) representing Λ ∈(L1(Ω))′, then
||h||∞= ||Λ||.
Proof: Just as in the proof of Theorem 15.13, there exists a unique h ∈L1(Ω)
such that for all simple functions, s,
Λ(s) =
Z
hs dµ.
(15.11)
To show h ∈L∞(Ω), let ε > 0 be given and let
E = {x : |h(x)| ≥||Λ|| + ε}.
Let |k| = 1 and hk = |h|. Since the measure space is ﬁnite, k ∈L1(Ω). As in
Theorem 15.13 let {sn} be a sequence of simple functions converging to k in L1(Ω),
and pointwise. It follows from the construction in Theorem 8.27 on Page 190 that
it can be assumed |sn| ≤1. Therefore
Λ(kXE) = lim
n→∞Λ(snXE) = lim
n→∞
Z
E
hsndµ =
Z
E
hkdµ

15.3.
REPRESENTATION THEOREMS FOR THE DUAL SPACE OF LP
417
where the last equality holds by the Dominated Convergence theorem. Therefore,
||Λ||µ(E)
≥
|Λ(kXE)| = |
Z
Ω
hkXEdµ| =
Z
E
|h|dµ
≥
(||Λ|| + ε)µ(E).
It follows that µ(E) = 0. Since ε > 0 was arbitrary, ||Λ|| ≥||h||∞. It was shown
that h ∈L∞(Ω), the density of the simple functions in L1 (Ω) and 15.11 imply
Λf =
Z
Ω
hfdµ , ||Λ|| ≥||h||∞.
(15.12)
This proves the existence part of the theorem. To verify uniqueness, suppose h1
and h2 both represent Λ and let f ∈L1(Ω) be such that |f| ≤1 and f(h1 −h2) =
|h1 −h2|. Then
0 = Λf −Λf =
Z
(h1 −h2)fdµ =
Z
|h1 −h2|dµ.
Thus h1 = h2. Finally,
||Λ|| = sup{|
Z
hfdµ| : ||f||1 ≤1} ≤||h||∞≤||Λ||
by 15.12.
Next these results are extended to the σ ﬁnite case.
Lemma 15.17 Let (Ω, S, µ) be a measure space and suppose there exists a measur-
able function, r such that r (x) > 0 for all x, there exists M such that |r (x)| < M
for all x, and
R
rdµ < ∞. Then for
Λ ∈(Lp(Ω, µ))′, p ≥1,
there exists a unique h ∈Lp′(Ω, µ), L∞(Ω, µ) if p = 1 such that
Λf =
Z
hfdµ.
Also ||h|| = ||Λ||. (||h|| = ||h||p′ if p > 1, ||h||∞if p = 1). Here
1
p + 1
p′ = 1.
Proof: Deﬁne a new measure eµ, according to the rule
eµ (E) ≡
Z
E
rdµ.
(15.13)
Thus eµ is a ﬁnite measure on S. Now deﬁne a mapping, η : Lp(Ω, µ) →Lp(Ω, eµ) by
ηf = r−1
p f.

418
REPRESENTATION THEOREMS
Then
||ηf||p
Lp(eµ) =
Z ¯¯¯r−1
p f
¯¯¯
p
rdµ = ||f||p
Lp(µ)
and so η is one to one and in fact preserves norms. I claim that also η is onto. To
see this, let g ∈Lp(Ω, eµ) and consider the function, r
1
p g. Then
Z ¯¯¯r
1
p g
¯¯¯
p
dµ =
Z
|g|p rdµ =
Z
|g|p deµ < ∞
Thus r
1
p g ∈Lp (Ω, µ) and η
³
r
1
p g
´
= g showing that η is onto as claimed. Thus
η is one to one, onto, and preserves norms. Consider the diagram below which is
descriptive of the situation in which η∗must be one to one and onto.
h, Lp′ (eµ)
Lp (eµ)′ , eΛ
η∗
→
Lp (µ)′ , Λ
Lp (eµ)
η
←
Lp (µ)
Then for Λ ∈Lp (µ)′ , there exists a unique eΛ ∈Lp (eµ)′ such that η∗eΛ = Λ,
¯¯¯
¯¯¯eΛ
¯¯¯
¯¯¯ =
||Λ|| . By the Riesz representation theorem for ﬁnite measure spaces, there exists
a unique h ∈Lp′ (eµ) which represents eΛ in the manner described in the Riesz
representation theorem. Thus ||h||Lp′(eµ) =
¯¯¯
¯¯¯eΛ
¯¯¯
¯¯¯ = ||Λ|| and for all f ∈Lp (µ) ,
Λ (f)
=
η∗eΛ (f) ≡eΛ (ηf) =
Z
h (ηf) deµ =
Z
rh
³
f −1
p f
´
dµ
=
Z
r
1
p′ hfdµ.
Now
Z ¯¯¯r
1
p′ h
¯¯¯
p′
dµ =
Z
|h|p′
rdµ = ||h||p′
Lp′(eµ) < ∞.
Thus
¯¯¯
¯¯¯r
1
p′ h
¯¯¯
¯¯¯
Lp′(µ) = ||h||Lp′(eµ) =
¯¯¯
¯¯¯eΛ
¯¯¯
¯¯¯ = ||Λ|| and represents Λ in the appropriate
way. If p = 1, then 1/p′ ≡0. This proves the Lemma.
A situation in which the conditions of the lemma are satisﬁed is the case where
the measure space is σ ﬁnite. In fact, you should show this is the only case in which
the conditions of the above lemma hold.
Theorem 15.18 (Riesz representation theorem) Let (Ω, S, µ) be σ ﬁnite and let
Λ ∈(Lp(Ω, µ))′, p ≥1.
Then there exists a unique h ∈Lq(Ω, µ), L∞(Ω, µ) if p = 1 such that
Λf =
Z
hfdµ.

15.3.
REPRESENTATION THEOREMS FOR THE DUAL SPACE OF LP
419
Also ||h|| = ||Λ||. (||h|| = ||h||q if p > 1, ||h||∞if p = 1). Here
1
p + 1
q = 1.
Proof: Let {Ωn} be a sequence of disjoint elements of S having the property
that
0 < µ(Ωn) < ∞, ∪∞
n=1Ωn = Ω.
Deﬁne
r(x) =
∞
X
n=1
1
n2 XΩn(x) µ(Ωn)−1, eµ(E) =
Z
E
rdµ.
Thus
Z
Ω
rdµ = eµ(Ω) =
∞
X
n=1
1
n2 < ∞
so eµ is a ﬁnite measure. The above lemma gives the existence part of the conclusion
of the theorem. Uniqueness is done as before.
With the Riesz representation theorem, it is easy to show that
Lp(Ω), p > 1
is a reﬂexive Banach space. Recall Deﬁnition 13.32 on Page 353 for the deﬁnition.
Theorem 15.19 For (Ω, S, µ) a σ ﬁnite measure space and p > 1, Lp(Ω) is reﬂex-
ive.
Proof: Let δr : (Lr(Ω))′ →Lr′(Ω) be deﬁned for 1
r + 1
r′ = 1 by
Z
(δrΛ)g dµ = Λg
for all g ∈Lr(Ω). From Theorem 15.18 δr is one to one, onto, continuous and linear.
By the open map theorem, δ−1
r
is also one to one, onto, and continuous (δrΛ equals
the representor of Λ). Thus δ∗
r is also one to one, onto, and continuous by Corollary
13.29. Now observe that J = δ∗
p ◦δ−1
q . To see this, let z∗∈(Lq)′, y∗∈(Lp)′,
δ∗
p ◦δ−1
q (δqz∗)(y∗)
=
(δ∗
pz∗)(y∗)
=
z∗(δpy∗)
=
Z
(δqz∗)(δpy∗)dµ,
J(δqz∗)(y∗)
=
y∗(δqz∗)
=
Z
(δpy∗)(δqz∗)dµ.
Therefore δ∗
p ◦δ−1
q
= J on δq(Lq)′ = Lp. But the two δ maps are onto and so J is
also onto.

420
REPRESENTATION THEOREMS
15.4
The Dual Space Of C (X)
Consider the dual space of C(X) where X is a compact Hausdorﬀspace. It will
turn out to be a space of measures. To show this, the following lemma will be
convenient.
Lemma 15.20 Suppose λ is a mapping which is deﬁned on the positive continuous
functions deﬁned on X, some topological space which satisﬁes
λ (af + bg) = aλ (f) + bλ (g)
(15.14)
whenever a, b ≥0 and f, g ≥0. Then there exists a unique extension of λ to all of
C (X), Λ such that whenever f, g ∈C (X) and a, b ∈C, it follows
Λ (af + bg) = aΛ (f) + bΛ (g) .
Proof: Let C(X; R) be the real-valued functions in C(X) and deﬁne
ΛR(f) = λf + −λf −
for f ∈C(X; R). Use the identity
(f1 + f2)+ + f −
1 + f −
2 = f +
1 + f +
2 + (f1 + f2)−
and 15.14 to write
λ(f1 + f2)+ −λ(f1 + f2)−= λf +
1 −λf −
1 + λf +
2 −λf −
2 ,
it follows that ΛR(f1 + f2) = ΛR(f1) + ΛR(f2). To show that ΛR is linear, it is
necessary to verify that ΛR(cf) = cΛR(f) for all c ∈R. But
(cf)± = cf ±,
if c ≥0 while
(cf)+ = −c(f)−,
if c < 0 and
(cf)−= (−c)f +,
if c < 0. Thus, if c < 0,
ΛR(cf) = λ(cf)+ −λ(cf)−= λ
¡
(−c) f −¢
−λ
¡
(−c)f +¢
= −cλ(f −) + cλ(f +) = c(λ(f +) −λ(f −)) = cΛR (f) .
A similar formula holds more easily if c ≥0. Now let
Λf = ΛR(Re f) + iΛR(Im f)

15.4.
THE DUAL SPACE OF C (X)
421
for arbitrary f ∈C(X). This is linear as desired. It is obvious that Λ (f + g) =
Λ (f) + Λ (g) from the fact that taking the real and imaginary parts are linear
operations. The only thing to check is whether you can factor out a complex scalar.
Λ ((a + ib) f) = Λ (af) + Λ (ibf)
≡ΛR (a Re f) + iΛR (a Im f) + ΛR (−b Im f) + iΛR (b Re f)
because ibf = ib Re f −b Im f and so Re (ibf) = −b Im f and Im (ibf) = b Re f.
Therefore, the above equals
=
(a + ib) ΛR (Re f) + i (a + ib) ΛR (Im f)
=
(a + ib) (ΛR (Re f) + iΛR (Im f)) = (a + ib) Λf
The extension is obviously unique. This proves the lemma.
Let L ∈C(X)′.
Also denote by C+(X) the set of nonnegative continuous
functions deﬁned on X. Deﬁne for f ∈C+(X)
λ(f) = sup{|Lg| : |g| ≤f}.
Note that λ(f) < ∞because |Lg| ≤||L|| ||g|| ≤||L|| ||f|| for |g| ≤f. Then the
following lemma is important.
Lemma 15.21 If c ≥0, λ(cf) = cλ(f), f1 ≤f2 implies λf1 ≤λf2, and
λ(f1 + f2) = λ(f1) + λ(f2).
Proof: The ﬁrst two assertions are easy to see so consider the third.
Let
|gj| ≤fj and let egj = eiθjgj where θj is chosen such that eiθjLgj = |Lgj|. Thus
Legj = |Lgj|. Then
|eg1 + eg2| ≤f1 + f2.
Hence
|Lg1| + |Lg2| = Leg1 + Leg2 =
L(eg1 + eg2) = |L(eg1 + eg2)| ≤λ(f1 + f2).
(15.15)
Choose g1 and g2 such that |Lgi| + ε > λ(fi). Then 15.15 shows
λ(f1) + λ(f2) −2ε ≤λ(f1 + f2).
Since ε > 0 is arbitrary, it follows that
λ(f1) + λ(f2) ≤λ(f1 + f2).
(15.16)
Now let |g| ≤f1 + f2, |Lg| ≥λ(f1 + f2) −ε. Let
hi (x) =
(
fi(x)g(x)
f1(x)+f2(x) if f1 (x) + f2 (x) > 0,
0 if f1 (x) + f2 (x) = 0.

422
REPRESENTATION THEOREMS
Then hi is continuous and h1(x) + h2(x) = g(x), |hi| ≤fi. Therefore,
−ε + λ(f1 + f2)
≤
|Lg| ≤|Lh1 + Lh2| ≤|Lh1| + |Lh2|
≤
λ(f1) + λ(f2).
Since ε > 0 is arbitrary, this shows with 15.16 that
λ(f1 + f2) ≤λ(f1) + λ(f2) ≤λ(f1 + f2)
which proves the lemma.
Let Λ be deﬁned in Lemma 15.20. Then Λ is linear by this lemma. Also, if
f ≥0,
Λf = ΛRf = λ (f) ≥0.
Therefore, Λ is a positive linear functional on C(X) (= Cc(X) since X is compact).
By Theorem 9.21 on Page 221, there exists a unique Radon measure µ such that
Λf =
Z
X
f dµ
for all f ∈C(X). Thus Λ(1) = µ(X). What follows is the Riesz representation
theorem for C(X)′.
Theorem 15.22 Let L ∈(C(X))′. Then there exists a Radon measure µ and a
function σ ∈L∞(X, µ) such that
L(f) =
Z
X
f σ dµ.
Proof: Let f ∈C(X). Then there exists a unique Radon measure µ such that
|Lf| ≤Λ(|f|) =
Z
X
|f|dµ = ||f||1.
Since µ is a Radon measure, C(X) is dense in L1(X, µ).
Therefore L extends
uniquely to an element of (L1(X, µ))′. By the Riesz representation theorem for L1,
there exists a unique σ ∈L∞(X, µ) such that
Lf =
Z
X
f σ dµ
for all f ∈C(X).
15.5
The Dual Space Of C0(X)
It is possible to give a simple generalization of the above theorem. For X a locally
compact Hausdorﬀspace, e
X denotes the one point compactiﬁcation of X. Thus,
e
X = X ∪{∞} and the topology of e
X consists of the usual topology of X along

15.5.
THE DUAL SPACE OF C0(X)
423
with all complements of compact sets which are deﬁned as the open sets containing
∞. Also C0 (X) will denote the space of continuous functions, f, deﬁned on X
such that in the topology of e
X, limx→∞f (x) = 0. For this space of functions,
||f||0 ≡sup {|f (x)| : x ∈X} is a norm which makes this into a Banach space.
Then the generalization is the following corollary.
Corollary 15.23 Let L ∈(C0 (X))′ where X is a locally compact Hausdorﬀspace.
Then there exists σ ∈L∞(X, µ) for µ a ﬁnite Radon measure such that for all
f ∈C0 (X),
L (f) =
Z
X
fσdµ.
Proof: Let
eD ≡
n
f ∈C
³
e
X
´
: f (∞) = 0
o
.
Thus eD is a closed subspace of the Banach space C
³
e
X
´
. Let θ : C0 (X) →eD be
deﬁned by
θf (x) =
½
f (x) if x ∈X,
0 if x = ∞.
Then θ is an isometry of C0 (X) and eD. (||θu|| = ||u|| .)The following diagram is
obtained.
C0 (X)′
θ∗
←
³
eD
´′
i∗
←
C
³
e
X
´′
C0 (X)
→
θ
eD
→
i
C
³
e
X
´
By the Hahn Banach theorem, there exists L1 ∈C
³
e
X
´′
such that θ∗i∗L1 = L.
Now apply Theorem 15.22 to get the existence of a ﬁnite Radon measure, µ1, on e
X
and a function σ ∈L∞³
e
X, µ1
´
, such that
L1g =
Z
e
X
gσdµ1.
Letting the σ algebra of µ1 measurable sets be denoted by S1, deﬁne
S ≡{E \ {∞} : E ∈S1}
and let µ be the restriction of µ1 to S. If f ∈C0 (X),
Lf = θ∗i∗L1f ≡L1iθf = L1θf =
Z
e
X
θfσdµ1 =
Z
X
fσdµ.
This proves the corollary.

424
REPRESENTATION THEOREMS
15.6
More Attractive Formulations
In this section, Corollary 15.23 will be reﬁned and placed in an arguably more
attractive form.
The measures involved will always be complex Borel measures
deﬁned on a σ algebra of subsets of X, a locally compact Hausdorﬀspace.
Deﬁnition 15.24 Let λ be a complex measure.
Then
R
fdλ ≡
R
fhd |λ| where
hd |λ| is the polar decomposition of λ described above. The complex measure, λ is
called regular if |λ| is regular.
The following lemma says that the diﬀerence of regular complex measures is also
regular.
Lemma 15.25 Suppose λi, i = 1, 2 is a complex Borel measure with total variation
ﬁnite2 deﬁned on X, a locally compact Hausdorf space. Then λ1 −λ2 is also a
regular measure on the Borel sets.
Proof:
Let E be a Borel set. That way it is in the σ algebras associated
with both λi. Then by regularity of λi, there exist K and V compact and open
respectively such that K ⊆E ⊆V and |λi| (V \ K) < ε/2. Therefore,
X
A∈π(V \K)
|(λ1 −λ2) (A)|
=
X
A∈π(V \K)
|λ1 (A) −λ2 (A)|
≤
X
A∈π(V \K)
|λ1 (A)| + |λ2 (A)|
≤
|λ1| (V \ K) + |λ2| (V \ K) < ε.
Therefore, |λ1 −λ2| (V \ K) ≤ε and this shows λ1 −λ2 is regular as claimed.
Theorem 15.26 Let L ∈C0 (X)′ Then there exists a unique complex measure, λ
with |λ| regular and Borel, such that for all f ∈C0 (X) ,
L (f) =
Z
X
fdλ.
Furthermore, ||L|| = |λ| (X) .
Proof: By Corollary 15.23 there exists σ ∈L∞(X, µ) where µ is a Radon
measure such that for all f ∈C0 (X) ,
L (f) =
Z
X
fσdµ.
Let a complex Borel measure, λ be given by
λ (E) ≡
Z
E
σdµ.
2Recall this is automatic for a complex measure.

15.7.
EXERCISES
425
This is a well deﬁned complex measure because µ is a ﬁnite measure. By Corollary
15.12
|λ| (E) =
Z
E
|σ| dµ
(15.17)
and σ = g |σ| where gd |λ| is the polar decomposition for λ. Therefore, for f ∈
C0 (X) ,
L (f) =
Z
X
fσdµ =
Z
X
fg |σ| dµ =
Z
X
fgd |λ| ≡
Z
X
fdλ.
(15.18)
From 15.17 and the regularity of µ, it follows that |λ| is also regular.
What of the claim about ||L||? By the regularity of |λ| , it follows that C0 (X) (In
fact, Cc (X)) is dense in L1 (X, |λ|). Since |λ| is ﬁnite, g ∈L1 (X, |λ|). Therefore,
there exists a sequence of functions in C0 (X) , {fn} such that fn →g in L1 (X, |λ|).
Therefore, there exists a subsequence, still denoted by {fn} such that fn (x) →g (x)
|λ| a.e. also. But since |g (x)| = 1 a.e. it follows that hn (x) ≡
fn(x)
|fn(x)|+ 1
n also
converges pointwise |λ| a.e. Then from the dominated convergence theorem and
15.18
||L|| ≥lim
n→∞
Z
X
hngd |λ| = |λ| (X) .
Also, if ||f||C0(X) ≤1, then
|L (f)| =
¯¯¯¯
Z
X
fgd |λ|
¯¯¯¯ ≤
Z
X
|f| d |λ| ≤|λ| (X) ||f||C0(X)
and so ||L|| ≤|λ| (X) . This proves everything but uniqueness.
Suppose λ and λ1 both work. Then for all f ∈C0 (X) ,
0 =
Z
X
fd (λ −λ1) =
Z
X
fhd |λ −λ1|
where hd |λ −λ1| is the polar decomposition for λ −λ1. By Lemma 15.25 λ −λ1 is
regular and so, as above, there exists {fn} such that |fn| ≤1 and fn →h pointwise.
Therefore,
R
X d |λ −λ1| = 0 so λ = λ1. This proves the theorem.
15.7
Exercises
1. Suppose µ is a vector measure having values in Rn or Cn. Can you show that
|µ| must be ﬁnite? Hint: You might deﬁne for each ei, one of the standard ba-
sis vectors, the real or complex measure, µei given by µei (E) ≡ei·µ (E) . Why
would this approach not yield anything for an inﬁnite dimensional normed lin-
ear space in place of Rn?
2. The Riesz representation theorem of the Lp spaces can be used to prove a
very interesting inequality. Let r, p, q ∈(1, ∞) satisfy
1
r = 1
p + 1
q −1.

426
REPRESENTATION THEOREMS
Then
1
q = 1 + 1
r −1
p > 1
r
and so r > q. Let θ ∈(0, 1) be chosen so that θr = q. Then also we have
1
r =





1/p+1/p′=1
z }| {
1 −1
p′




+ 1
q −1 = 1
q −1
p′
and so
θ
q = 1
q −1
p′
which implies p′ (1 −θ) = q. Now let f ∈Lp (Rn) , g ∈Lq (Rn) , f, g ≥0.
Justify the steps in the following argument using what was just shown that
θr = q and p′ (1 −θ) = q. Let
h ∈Lr′ (Rn) .
µ1
r + 1
r′ = 1
¶
Z
f ∗g (x) |h (x)| dx =
Z Z
f (y) g (x −y) |h (x)| dxdy.
≤
Z Z
|f (y)| |g (x −y)|θ |g (x −y)|1−θ |h (x)| dydx
≤
Z µZ ³
|g (x −y)|1−θ |h (x)|
´r′
dx
¶1/r′
·
µZ ³
|f (y)| |g (x −y)|θ´r
dx
¶1/r
dy
≤
"Z µZ ³
|g (x −y)|1−θ |h (x)|
´r′
dx
¶p′/r′
dy
#1/p′
·
"Z µZ ³
|f (y)| |g (x −y)|θ´r
dx
¶p/r
dy
#1/p
≤
"Z µZ ³
|g (x −y)|1−θ |h (x)|
´p′
dy
¶r′/p′
dx
#1/r′
·
"Z
|f (y)|p
µZ
|g (x −y)|θr dx
¶p/r
dy
#1/p

15.7.
EXERCISES
427
=
"Z
|h (x)|r′ µZ
|g (x −y)|(1−θ)p′
dy
¶r′/p′
dx
#1/r′
||g||q/r
q
||f||p
= ||g||q/r
q
||g||q/p′
q
||f||p ||h||r′ = ||g||q ||f||p ||h||r′ .
(15.19)
Young’s inequality says that
||f ∗g||r ≤||g||q ||f||p .
(15.20)
Therefore ||f ∗g||r ≤||g||q ||f||p. How does this inequality follow from the
above computation? Does 15.19 continue to hold if r, p, q are only assumed to
be in [1, ∞]? Explain. Does 15.20 hold even if r, p, and q are only assumed to
lie in [1, ∞]?
3. Show that in a reﬂexive Banach space, weak and weak ∗convergence are the
same.
4. Suppose (Ω, µ, S) is a ﬁnite measure space and that {fn} is a sequence of
functions which converge weakly to 0 in Lp (Ω). Suppose also that fn (x) →0
a.e. Show that then fn →0 in Lp−ε (Ω) for every p > ε > 0.
5. Give an example of a sequence of functions in L∞(−π, π) which converges
weak ∗to zero but which does not converge pointwise a.e. to zero.

428
REPRESENTATION THEOREMS

Integrals And Derivatives
16.1
The Fundamental Theorem Of Calculus
The version of the fundamental theorem of calculus found in Calculus has already
been referred to frequently. It says that if f is a Riemann integrable function, the
function
x →
Z x
a
f (t) dt,
has a derivative at every point where f is continuous. It is natural to ask what occurs
for f in L1. It is an amazing fact that the same result is obtained asside from a set of
measure zero even though f, being only in L1 may fail to be continuous anywhere.
Proofs of this result are based on some form of the Vitali covering theorem presented
above. In what follows, the measure space is (Rn, S, m) where m is n-dimensional
Lebesgue measure although the same theorems can be proved for arbitrary Radon
measures [36]. To save notation, m is written in place of mn.
By Lemma 9.7 on Page 214 and the completeness of m, the Lebesgue measurable
sets are exactly those measurable in the sense of Caratheodory. Also, to save on
notation m is also the name of the outer measure deﬁned on all of P(Rn) which is
determined by mn. Recall
B(p, r) = {x : |x −p| < r}.
(16.1)
Also deﬁne the following.
If B = B(p, r), then bB = B(p, 5r).
(16.2)
The ﬁrst version of the Vitali covering theorem presented above will now be used
to establish the fundamental theorem of calculus. The space of locally integrable
functions is the most general one for which the maximal function deﬁned below
makes sense.
Deﬁnition 16.1
f ∈L1
loc(Rn) means fXB(0,R) ∈L1(Rn) for all R > 0.
For
f ∈L1
loc(Rn), the Hardy Littlewood Maximal Function, Mf, is deﬁned by
Mf(x) ≡sup
r>0
1
m(B(x, r))
Z
B(x,r)
|f(y)|dy.
429

430
INTEGRALS AND DERIVATIVES
Theorem 16.2
If f ∈L1(Rn), then for α > 0,
m([Mf > α]) ≤5n
α ||f||1.
(Here and elsewhere, [Mf > α] ≡{x ∈Rn : Mf(x) > α} with other occurrences of
[ ] being deﬁned similarly.)
Proof: Let S ≡[Mf > α]. For x ∈S, choose rx > 0 with
1
m(B(x, rx))
Z
B(x,rx)
|f| dm > α.
The rx are all bounded because
m(B(x, rx)) < 1
α
Z
B(x,rx)
|f| dm < 1
α||f||1.
By the Vitali covering theorem, there are disjoint balls B(xi, ri) such that
S ⊆∪∞
i=1B(xi, 5ri)
and
1
m(B(xi, ri))
Z
B(xi,ri)
|f| dm > α.
Therefore
m(S)
≤
∞
X
i=1
m(B(xi, 5ri)) = 5n
∞
X
i=1
m(B(xi, ri))
≤
5n
α
∞
X
i=1
Z
B(xi,ri)
|f| dm
≤
5n
α
Z
Rn |f| dm,
the last inequality being valid because the balls B(xi, ri) are disjoint. This proves
the theorem.
Note that at this point it is unknown whether S is measurable. This is why
m(S) and not m (S) is written.
The following is the fundamental theorem of calculus from elementary calculus.
Lemma 16.3 Suppose g is a continuous function. Then for all x,
lim
r→0
1
m(B(x, r))
Z
B(x,r)
g(y)dy = g(x).

16.1.
THE FUNDAMENTAL THEOREM OF CALCULUS
431
Proof: Note that
g (x) =
1
m(B(x, r))
Z
B(x,r)
g (x) dy
and so
¯¯¯¯¯g (x) −
1
m(B(x, r))
Z
B(x,r)
g(y)dy
¯¯¯¯¯
=
¯¯¯¯¯
1
m(B(x, r))
Z
B(x,r)
(g(y) −g (x)) dy
¯¯¯¯¯
≤
1
m(B(x, r))
Z
B(x,r)
|g(y) −g (x)| dy.
Now by continuity of g at x, there exists r > 0 such that if |x −y| < r, |g (y) −g (x)| <
ε. For such r, the last expression is less than
1
m(B(x, r))
Z
B(x,r)
εdy < ε.
This proves the lemma.
Deﬁnition 16.4 Let f ∈L1 ¡
Rk, m
¢
. A point, x ∈Rk is said to be a Lebesgue
point if
lim sup
r→0
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| dm = 0.
Note that if x is a Lebesgue point, then
lim
r→0
1
m (B (x, r))
Z
B(x,r)
f (y) dm = f (x) .
and so the symmetric derivative exists at all Lebesgue points.
Theorem 16.5
(Fundamental Theorem of Calculus) Let f ∈L1(Rk). Then there
exists a set of measure 0, N, such that if x /∈N, then
lim
r→0
1
m(B(x, r))
Z
B(x,r)
|f(y) −f(x)|dy = 0.
Proof: Let λ > 0 and let ε > 0. By density of Cc
¡
Rk¢
in L1 ¡
Rk, m
¢
there exists
g ∈Cc
¡
Rk¢
such that ||g −f||L1(Rk) < ε. Now since g is continuous,
lim sup
r→0
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| dm
=
lim sup
r→0
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| dm
−lim
r→0
1
m (B (x, r))
Z
B(x,r)
|g (y) −g (x)| dm

432
INTEGRALS AND DERIVATIVES
=
lim sup
r→0
Ã
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| −|g (y) −g (x)| dm
!
≤
lim sup
r→0
Ã
1
m (B (x, r))
Z
B(x,r)
||f (y) −f (x)| −|g (y) −g (x)|| dm
!
≤
lim sup
r→0
Ã
1
m (B (x, r))
Z
B(x,r)
|f (y) −g (y) −(f (x) −g (x))| dm
!
≤
lim sup
r→0
Ã
1
m (B (x, r))
Z
B(x,r)
|f (y) −g (y)| dm
!
+ |f (x) −g (x)|
≤
M ([f −g]) (x) + |f (x) −g (x)| .
Therefore,
"
x : lim sup
r→0
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| dm > λ
#
⊆
·
M ([f −g]) > λ
2
¸
∪
·
|f −g| > λ
2
¸
Now
ε
>
Z
|f −g| dm ≥
Z
[|f−g|> λ
2 ]
|f −g| dm
≥
λ
2 m
µ·
|f −g| > λ
2
¸¶
This along with the weak estimate of Theorem 16.2 implies
m
Ã"
x : lim sup
r→0
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| dm > λ
#!
<
µ 2
λ5k + 2
λ
¶
||f −g||L1(Rk)
<
µ 2
λ5k + 2
λ
¶
ε.
Since ε > 0 is arbitrary, it follows
mn
Ã"
x : lim sup
r→0
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| dm > λ
#!
= 0.
Now let
N =
"
x : lim sup
r→0
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| dm > 0
#

16.1.
THE FUNDAMENTAL THEOREM OF CALCULUS
433
and
Nn =
"
x : lim sup
r→0
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| dm > 1
n
#
It was just shown that m (Nn) = 0. Also, N = ∪∞
n=1Nn. Therefore, m (N) = 0 also.
It follows that for x /∈N,
lim sup
r→0
1
m (B (x, r))
Z
B(x,r)
|f (y) −f (x)| dm = 0
and this proves a.e. point is a Lebesgue point.
Of course it is suﬃcient to assume f is only in L1
loc
¡
Rk¢
.
Corollary 16.6 (Fundamental Theorem of Calculus) Let f ∈L1
loc(Rk). Then there
exists a set of measure 0, N, such that if x /∈N, then
lim
r→0
1
m(B(x, r))
Z
B(x,r)
|f(y) −f(x)|dy = 0.
Proof: Consider B (0, n) where n is a positive integer. Then fn ≡fXB(0,n) ∈
L1 ¡
Rk¢
and so there exists a set of measure 0, Nn such that if x ∈B (0, n) \ Nn,
then
lim
r→0
1
m(B(x, r))
Z
B(x,r)
|fn(y) −fn(x)|dy
=
lim
r→0
1
m(B(x, r))
Z
B(x,r)
|f(y) −f(x)|dy = 0.
Let N = ∪∞
n=1Nn. Then if x /∈N, the above equation holds.
Corollary 16.7
If f ∈L1
loc(Rn), then
lim
r→0
1
m(B(x, r))
Z
B(x,r)
f(y)dy = f(x) a.e. x.
(16.3)
Proof:
¯¯¯¯¯
1
m(B(x, r))
Z
B(x,r)
f(y)dy −f(x)
¯¯¯¯¯
≤
1
m(B(x, r))
Z
B(x,r)
|f(y) −f(x)| dy
and the last integral converges to 0 a.e. x.
Deﬁnition 16.8
For N the set of Theorem 16.5 or Corollary 16.6, N C is called
the Lebesgue set or the set of Lebesgue points.
The next corollary is a one dimensional version of what was just presented.

434
INTEGRALS AND DERIVATIVES
Corollary 16.9
Let f ∈L1(R) and let
F(x) =
Z x
−∞
f(t)dt.
Then for a.e. x, F ′(x) = f(x).
Proof: For h > 0
1
h
Z x+h
x
|f(y) −f(x)|dy ≤2( 1
2h)
Z x+h
x−h
|f(y) −f(x)|dy
By Theorem 16.5, this converges to 0 a.e. Similarly
1
h
Z x
x−h
|f(y) −f(x)|dy
converges to 0 a.e. x.
¯¯¯¯
F(x + h) −F(x)
h
−f(x)
¯¯¯¯ ≤1
h
Z x+h
x
|f(y) −f(x)|dy
(16.4)
and
¯¯¯¯
F(x) −F(x −h)
h
−f(x)
¯¯¯¯ ≤1
h
Z x
x−h
|f(y) −f(x)|dy.
(16.5)
Now the expression on the right in 16.4 and 16.5 converges to zero for a.e.
x.
Therefore, by 16.4, for a.e. x the derivative from the right exists and equals f (x)
while from 16.5 the derivative from the left exists and equals f (x) a.e. It follows
lim
h→0
F(x + h) −F(x)
h
= f(x) a.e. x
This proves the corollary.
16.2
Absolutely Continuous Functions
Deﬁnition 16.10 Let [a, b] be a closed and bounded interval and let f : [a, b] →R.
Then f is said to be absolutely continuous if for every ε > 0 there exists δ > 0 such
that if Pm
i=1 |yi −xi| < δ, then Pm
i=1 |f (yi) −f (xi)| < ε.
Deﬁnition 16.11 A ﬁnite subset, P of [a, b] is called a partition of [x, y] ⊆[a, b] if
P = {x0, x1, · · ·, xn} where
x = x0 < x1 < · · ·, < xn = y.
For f : [a, b] →R and P = {x0, x1, · · ·, xn} deﬁne
VP [x, y] ≡
n
X
i=1
|f (xi) −f (xi−1)| .

16.2.
ABSOLUTELY CONTINUOUS FUNCTIONS
435
Denoting by P [x, y] the set of all partitions of [x, y] deﬁne
V [x, y] ≡
sup
P ∈P[x,y]
VP [x, y] .
For simplicity, V [a, x] will be denoted by V (x) . It is called the total variation of
the function, f.
There are some simple facts about the total variation of an absolutely continuous
function, f which are contained in the next lemma.
Lemma 16.12 Let f be an absolutely continuous function deﬁned on [a, b] and
let V be its total variation function as described above. Then V is an increasing
bounded function. Also if
P and Q are two partitions of [x, y] with P ⊆Q, then
VP [x, y] ≤VQ [x, y] and if [x, y] ⊆[z, w] ,
V [x, y] ≤V [z, w]
(16.6)
If P = {x0, x1, · · ·, xn} is a partition of [x, y] , then
V [x, y] =
n
X
i=1
V [xi, xi−1] .
(16.7)
Also if y > x,
V (y) −V (x) ≥|f (y) −f (x)|
(16.8)
and the function, x →V (x) −f (x) is increasing. The total variation function, V
is absolutely continuous.
Proof: The claim that V is increasing is obvious as is the next claim about
P ⊆Q leading to VP [x, y] ≤VQ [x, y] . To verify this, simply add in one point
at a time and verify that from the triangle inequality, the sum involved gets no
smaller. The claim that V is increasing consistent with set inclusion of intervals is
also clearly true and follows directly from the deﬁnition.
Now let t < V [x, y] where P0 = {x0, x1, · · ·, xn} is a partition of [x, y] . There
exists a partition, P of [x, y] such that t < VP [x, y] . Without loss of generality it
can be assumed that {x0, x1, · · ·, xn} ⊆P since if not, you can simply add in the
points of P0 and the resulting sum for the total variation will get no smaller. Let
Pi be those points of P which are contained in [xi−1, xi] . Then
t < Vp [x, y] =
n
X
i=1
VPi [xi−1, xi] ≤
n
X
i=1
V [xi−1, xi] .
Since t < V [x, y] is arbitrary,
V [x, y] ≤
n
X
i=1
V [xi, xi−1]
(16.9)

436
INTEGRALS AND DERIVATIVES
Note that 16.9 does not depend on f being absolutely continuous. Suppose now
that f is absolutely continuous. Let δ correspond to ε = 1. Then if [x, y] is an
interval of length no larger than δ, the deﬁnition of absolute continuity implies
V [x, y] < 1.
Then from 16.9
V [a, nδ] ≤
n
X
i=1
V [a + (i −1) δ, a + iδ] <
n
X
i=1
1 = n.
Thus V is bounded on [a, b]. Now let Pi be a partition of [xi−1, xi] such that
VPi [xi−1, xi] > V [xi−1, xi] −ε
n
Then letting P = ∪Pi,
−ε +
n
X
i=1
V [xi−1, xi] <
n
X
i=1
VPi [xi−1, xi] = VP [x, y] ≤V [x, y] .
Since ε is arbitrary, 16.7 follows from this and 16.9.
Now let x < y
V (y) −f (y) −(V (x) −f (x))
=
V (y) −V (x) −(f (y) −f (x))
≥
V (y) −V (x) −|f (y) −f (x)| ≥0.
It only remains to verify that V is absolutely continuous.
Let ε > 0 be given and let δ correspond to ε/2 in the deﬁnition of absolute conti-
nuity applied to f. Suppose Pn
i=1 |yi −xi| < δ and consider Pn
i=1 |V (yi) −V (xi)|.
By 16.9 this last equals Pn
i=1 V [xi, yi] . Now let Pi be a partition of [xi, yi] such
that VPi [xi, yi] +
ε
2n > V [xi, yi] . Then by the deﬁnition of absolute continuity,
n
X
i=1
|V (yi) −V (xi)|
=
n
X
i=1
V [xi, yi]
≤
n
X
i=1
VPi [xi, yi] + η < ε/2 + ε/2 = ε.
and shows V is absolutely continuous as claimed.
Lemma 16.13 Suppose f : [a, b] →R is absolutely continuous and increasing.
Then f ′ exists a.e., is in L1 ([a, b]) , and
f (x) = f (a) +
Z x
a
f ′ (t) dt.

16.2.
ABSOLUTELY CONTINUOUS FUNCTIONS
437
Proof: Deﬁne L, a positive linear functional on C ([a, b]) by
Lg ≡
Z b
a
gdf
where this integral is the Riemann Stieltjes integral with respect to the integrating
function, f. By the Riesz representation theorem for positive linear functionals,
there exists a unique Radon measure, µ such that Lg =
R
gdµ. Now consider the
following picture for gn ∈C ([a, b]) in which gn equals 1 for x between x + 1/n and
y.
¥
¥
¥
¥
¥
¥
¥
¥
D
D
D
D
D
D
D
D
x
y + 1/n
x + 1/n
y
Then gn (t) →X(x,y] (t) pointwise. Therefore, by the dominated convergence
theorem,
µ ((x, y]) = lim
n→∞
Z
gndµ.
However,
µ
f (y) −f
µ
x + 1
n
¶¶
≤
Z
gndµ =
Z b
a
gndf ≤
µ
f
µ
y + 1
n
¶
−f (y)
¶
+
µ
f (y) −f
µ
x + 1
n
¶¶
+
µ
f
µ
x + 1
n
¶
−f (x)
¶
and so as n →∞the continuity of f implies
µ ((x, y]) = f (y) −f (x) .
Similarly, µ (x, y) = f (y) −f (y) and µ ([x, y]) = f (y) −f (x) , the argument used
to establish this being very similar to the above. It follows in particular that
f (x) −f (a) =
Z
[a,x]
dµ.
Note that up till now, no referrence has been made to the absolute continuity of f.
Any increasing continuous function would be ﬁne.

438
INTEGRALS AND DERIVATIVES
Now if E is a Borel set such that m (E) = 0, Then the outer regularity of m
implies there exists an open set, V containing E such that m (V ) < δ where δ
corresponds to ε in the deﬁnition of absolute continuity of f. Then letting {Ik} be
the connected components of V it follows E ⊆∪∞
k=1Ik with P
k m (Ik) = m (V ) < δ.
Therefore, from absolute continuity of f, it follows that for Ik = (ak, bk) and each
n
µ (∪n
k=1Ik) =
n
X
k=1
µ (Ik) =
n
X
k=1
|f (bk) −f (ak)| < ε
and so letting n →∞,
µ (E) ≤µ (V ) =
∞
X
k=1
|f (bk) −f (ak)| ≤ε.
Since ε is arbitrary, it follows µ (E) = 0. Therefore, µ ≪m and so by the Radon
Nikodym theorem there exists a unique h ∈L1 ([a, b]) such that
µ (E) =
Z
E
hdm.
In particular,
µ ([a, x]) = f (x) −f (a) =
Z
[a,x]
hdm.
From the fundamental theorem of calculus f ′ (x) = h (x) at every Lebesgue point
of h. Therefore, writing in usual notation,
f (x) = f (a) +
Z x
a
f ′ (t) dt
as claimed. This proves the lemma.
With the above lemmas, the following is the main theorem about absolutely
continuous functions.
Theorem 16.14 Let f : [a, b] →R be absolutely continuous if and only if f ′ (x)
exists a.e., f ′ ∈L1 ([a, b]) and
f (x) = f (a) +
Z x
a
f ′ (t) dt.
Proof: Suppose ﬁrst that f is absolutely continuous. By Lemma 16.12 the total
variation function, V is absolutely continuous and f (x) = V (x) −(V (x) −f (x))
where both V and V −f are increasing and absolutely continuous. By Lemma 16.13
f (x) −f (a)
=
V (x) −V (a) −[(V (x) −f (x)) −(V (a) −f (a))]
=
Z x
a
V ′ (t) dt −
Z x
a
(V −f)′ (t) dt.

16.3. DIFFERENTIATION OF MEASURES WITH RESPECT TO LEBESGUE MEASURE439
Now f ′ exists and is in L1 becasue f = V −(V −f) and V and V −f have derivatives
in L1. Therefore, (V −f)′ = V ′ −f ′ and so the above reduces to
f (x) −f (a) =
Z x
a
f ′ (t) dt.
This proves one half of the theorem.
Now suppose f ′ ∈L1 and f (x) = f (a) +
R x
a f ′ (t) dt. It is necessary to verify
that f is absolutely continuous. But this follows easily from Lemma 8.49 on Page
203 which implies that a single function, f ′ is uniformly integrable. This lemma
implies that if P
i |yi −xi| is suﬃciently small then
X
i
¯¯¯¯
Z yi
xi
f ′ (t) dt
¯¯¯¯ =
X
i
|f (yi) −f (xi)| < ε.
16.3
Diﬀerentiation Of Measures With Respect To
Lebesgue Measure
Recall the Vitali covering theorem in Corollary 10.20 on Page 279.
Corollary 16.15 Let E ⊆Rn and let F, be a collection of open balls of bounded
radii such that F covers E in the sense of Vitali. Then there exists a countable
collection of disjoint balls from F, {Bj}∞
j=1, such that m(E \ ∪∞
j=1Bj) = 0.
Deﬁnition 16.16 Let µ be a Radon mesure deﬁned on Rn. Then
dµ
dm (x) ≡lim
r→0
µ (B (x, r))
m (B (x, r))
whenever this limit exists.
It turns out this limit exists for m a.e. x. To verify this here is another deﬁnition.
Deﬁnition 16.17 Let f (r) be a function having values in [−∞, ∞] . Then
lim sup
r→0+
f (r)
≡
lim
r→0 (sup {f (t) : t ∈[0, r]})
lim inf
r→0+ f (r)
≡
lim
r→0 (inf {f (t) : t ∈[0, r]})
This is well deﬁned because the function r →inf {f (t) : t ∈[0, r]} is increasing and
r →sup {f (t) : t ∈[0, r]} is decreasing. Also note that limr→0+ f (r) exists if and
only if
lim sup
r→0+
f (r) = lim inf
r→0+ f (r)
and if this happens
lim
r→0+ f (r) = lim inf
r→0+ f (r) = lim sup
r→0+
f (r) .

440
INTEGRALS AND DERIVATIVES
The claims made in the above deﬁnition follow immediately from the deﬁnition
of what is meant by a limit in [−∞, ∞] and are left for the reader.
Theorem 16.18 Let µ be a Borel measure on Rn then
dµ
dm (x) exists in [−∞, ∞]
m a.e.
Proof:Let p < q and let p, q be rational numbers. Deﬁne
Npq (M)
≡
½
x ∈Rn such that lim sup
r→0+
µ (B (x, r))
m (B (x, r)) > q
> p > lim inf
r→0+
µ (B (x, r))
m (B (x, r))
¾
∩B (0, M) ,
Npq
≡
½
x ∈Rn such that lim sup
r→0+
µ (B (x, r))
m (B (x, r)) > q
> p > lim inf
r→0+
µ (B (x, r))
m (B (x, r))
¾
,
N
≡
½
x ∈Rn such that lim sup
r→0+
µ (B (x, r))
m (B (x, r)) >
lim inf
r→0+
µ (B (x, r))
m (B (x, r))
¾
.
I will show m (Npq (M)) = 0. Use outer regularity to obtain an open set, V con-
taining Npq (M) such that
m (Npq (M)) + ε > m (V ) .
From the deﬁnition of Npq (M) , it follows that for each x ∈Npq (M) there exist
arbitrarily small r > 0 such that
µ (B (x, r))
m (B (x, r)) < p.
Only consider those r which are small enough to be contained in B (0, M) so that
the collection of such balls has bounded radii. This is a Vitali cover of Npq (M) and
so by Corollary 16.15 there exists a sequence of disjoint balls of this sort, {Bi}∞
i=1
such that
µ (Bi) < pm (Bi) , m (Npq (M) \ ∪∞
i=1Bi) = 0.
(16.10)
Now for x ∈Npq (M) ∩(∪∞
i=1Bi) (most of Npq (M)), there exist arbitrarily small
balls, B (x, r) , such that B (x, r) is contained in some set of {Bi}∞
i=1 and
µ (B (x, r))
m (B (x, r)) > q.
This is a Vitali cover of Npq (M)∩(∪∞
i=1Bi) and so there exists a sequence of disjoint
balls of this sort,
©
B′
j
ª∞
j=1 such that
m
¡
(Npq (M) ∩(∪∞
i=1Bi)) \ ∪∞
j=1B′
j
¢
= 0, µ
¡
B′
j
¢
> qm
¡
B′
j
¢
.
(16.11)

16.3. DIFFERENTIATION OF MEASURES WITH RESPECT TO LEBESGUE MEASURE441
It follows from 16.10 and 16.11 that
m (Npq (M)) ≤m ((Npq (M) ∩(∪∞
i=1Bi))) ≤m
¡
∪∞
j=1B′
j
¢
(16.12)
Therefore,
X
j
µ
¡
B′
j
¢
>
q
X
j
m
¡
B′
j
¢
≥qm (Npq (M) ∩(∪iBi)) = qm (Npq (M))
≥
pm (Npq (M)) ≥p (m (V ) −ε) ≥p
X
i
m (Bi) −pε
≥
X
i
µ (Bi) −pε ≥
X
j
µ
¡
B′
j
¢
−pε.
It follows
pε ≥(q −p) m (Npq (M))
Since ε is arbitrary, m (Npq (M)) = 0. Now Npq ⊆∪∞
M=1Npq (M) and so m (Npq) =
0. Now
N = ∪p.q∈QNpq
and since this is a countable union of sets of measure zero, m (N) = 0 also. This
proves the theorem.
From Theorem 15.8 on Page 407 it follows that if µ is a complex measure then
|µ| is a ﬁnite measure. This makes possible the following deﬁnition.
Deﬁnition 16.19 Let µ be a real measure. Deﬁne the following measures. For E
a measurable set,
µ+ (E)
≡
1
2 (|µ| + µ) (E) ,
µ−(E)
≡
1
2 (|µ| −µ) (E) .
These are measures thanks to Theorem 15.7 on Page 406 and µ+ −µ−= µ. These
measures have values in [0, ∞). They are called the positive and negative parts of µ
respectively. For µ a complex measure, deﬁne Re µ and Im µ by
Re µ (E)
≡
1
2
³
µ (E) + µ (E)
´
Im µ (E)
≡
1
2i
³
µ (E) −µ (E)
´
Then Re µ and Im µ are both real measures. Thus for µ a complex measure,
µ
=
Re µ+ −Re µ−+ i
¡
Im µ+ −Im µ−¢
=
ν1 −ν1 + i (ν3 −ν4)
where each νi is a real measure having values in [0, ∞).

442
INTEGRALS AND DERIVATIVES
Then there is an obvious corollary to Theorem 16.18.
Corollary 16.20 Let µ be a complex Borel measure on Rn. Then
dµ
dm (x) exists
a.e.
Proof: Letting νi be deﬁned in Deﬁnition 16.19. By Theorem 16.18, for m a.e.
x, dνi
dm (x) exists. This proves the corollary because µ is just a ﬁnite sum of these
νi.
Theorem 15.2 on Page 399, the Radon Nikodym theorem, implies that if you have
two ﬁnite measures, µ and λ, you can write λ as the sum of a measure absolutely
continuous with respect to µ and one which is singular to µ in a unique way. The
next topic is related to this. It has to do with the diﬀerentiation of a measure which
is singular with respect to Lebesgue measure.
Theorem 16.21 Let µ be a Radon measure on Rn and suppose there exists a µ
measurable set, N such that for all Borel sets, E, µ (E) = µ (E ∩N) where m (N) =
0. Then
dµ
dm (x) = 0 m a.e.
Proof: For k ∈N, let
Bk (M)
≡
½
x ∈N C : lim sup
r→0+
µ (B (x, r))
m (B (x, r)) > 1
k
¾
∩B (0,M) ,
Bk
≡
½
x ∈N C : lim sup
r→0+
µ (B (x, r))
m (B (x, r)) > 1
k
¾
,
B
≡
½
x ∈N C : lim sup
r→0+
µ (B (x, r))
m (B (x, r)) > 0
¾
.
Let ε > 0. Since µ is regular, there exists H, a compact set such that H ⊆
N ∩B (0, M) and
µ (N ∩B (0, M) \ H) < ε.
B(0, M)
N ∩B(0, M)
H
Bi
Bk(M)

16.3. DIFFERENTIATION OF MEASURES WITH RESPECT TO LEBESGUE MEASURE443
For each x ∈Bk (M) , there exist arbitrarily small r > 0 such that B (x, r) ⊆
B (0, M) \ H and
µ (B (x, r))
m (B (x, r)) > 1
k .
(16.13)
Two such balls are illustrated in the above picture. This is a Vitali cover of Bk (M)
and so there exists a sequence of disjoint balls of this sort, {Bi}∞
i=1 such that
m (Bk (M) \ ∪iBi) = 0. Therefore,
m (Bk (M))
≤
m (Bk (M) ∩(∪iBi)) ≤
X
i
m (Bi) ≤k
X
i
µ (Bi)
=
k
X
i
µ (Bi ∩N) = k
X
i
µ (Bi ∩N ∩B (0, M))
≤
kµ (N ∩B (0, M) \ H) < εk
Since ε was arbitrary, this shows m (Bk (M)) = 0.
Therefore,
m (Bk) ≤
∞
X
M=1
m (Bk (M)) = 0
and m (B) ≤P
k m (Bk) = 0. Since m (N) = 0, this proves the theorem.
It is easy to obtain a diﬀerent version of the above theorem. This is done with
the aid of the following lemma.
Lemma 16.22 Suppose µ is a Borel measure on Rn having values in [0, ∞). Then
there exists a Radon measure, µ1 such that µ1 = µ on all Borel sets.
Proof: By assumption, µ (Rn) < ∞and so it is possible to deﬁne a positive
linear functional, L on Cc (Rn) by
Lf ≡
Z
fdµ.
By the Riesz representation theorem for positive linear functionals of this sort, there
exists a unique Radon measure, µ1 such that for all f ∈Cc (Rn) ,
Z
fdµ1 = Lf =
Z
fdµ.
Now let V be an open set and let Kk ≡
©
x ∈V : dist
¡
x, V C¢
≤1/k
ª
∩B (0,k).
Then {Kk} is an incresing sequence of compact sets whose union is V. Let Kk ≺fk
≺V. Then fk (x) →XV (x) for every x. Therefore,
µ1 (V ) = lim
k→∞
Z
fkdµ1 = lim
k→∞
Z
fkdµ = µ (V )
and so µ = µ1 on open sets. Now if K is a compact set, let
Vk ≡{x ∈Rn : dist (x, K) < 1/k} .

444
INTEGRALS AND DERIVATIVES
Then Vk is an open set and ∩kVk = K. Letting K ≺fk ≺Vk, it follows that
fk (x) →XK (x) for all x ∈Rn. Therefore, by the dominated convergence theorem
with a dominating function, XRn
µ1 (K) = lim
k→∞
Z
fkdµ1 = lim
k→∞
Z
fkdµ = µ (K)
and so µ and µ1 are equal on all compact sets. It follows µ = µ1 on all countable
unions of compact sets and countable intersections of open sets.
Now let E be a Borel set. By regularity of µ1, there exist sets, H and G such
that H is the countable union of an increasing sequence of compact sets, G is the
countable intersection of a decreasing sequence of open sets, H ⊆E ⊆G, and
µ1 (H) = µ1 (G) = µ1 (E) . Therefore,
µ1 (H) = µ (H) ≤µ (E) ≤µ (G) = µ1 (G) = µ1 (E) = µ1 (H) .
therefore, µ (E) = µ1 (E) and this proves the lemma.
Corollary 16.23 Suppose µ is a complex Borel measure deﬁned on Rn for which
there exists a µ measurable set, N such that for all Borel sets, E, µ (E) = µ (E ∩N)
where m (N) = 0. Then
dµ
dm (x) = 0 m a.e.
Proof: Each of Re µ+, Re µ−, Im µ+, and Im µ−are real measures having values
in [0, ∞) and so by Lemma 16.22 each is a Radon measure having the same property
that µ has in terms of being supported on a set of m measure zero. Therefore, for
ν equal to any of these,
dν
dm (x) = 0 m a.e. This proves the corollary.
16.4
Exercises
1. Suppose A and B are sets of positive Lebesgue measure in Rn. Show that
A −B must contain B (c, ε) for some c ∈Rn and ε > 0.
A −B ≡{a −b : a ∈A and b ∈B} .
Hint: First assume both sets are bounded. This creates no loss of generality.
Next there exist a0 ∈A, b0 ∈B and δ > 0 such that
Z
B(a0,δ)
XA (t) dt > 3
4m (B (a0, δ)) ,
Z
B(b0,δ)
XB (t) dt > 3
4m (B (b0, δ)) .
Now explain why this implies
m (A −a0 ∩B (0,δ)) > 3
4m (B (0, δ))
and
m (B −b0 ∩B (0,δ)) > 3
4m (B (0, δ)) .

16.4.
EXERCISES
445
Explain why
m ((A −a0) ∩(B −b0)) > 1
2m (B (0, δ)) > 0.
Let
f (x) ≡
Z
XA−a0 (x + t) XB−b0 (t) dt.
Explain why f (0) > 0. Next explain why f is continuous and why f (x) > 0
for all x ∈B (0, ε) for some ε > 0. Thus if |x| < ε, there exists t such that
x + t ∈A −a0 and t ∈B −b0. Subtract these.
2. Show Mf is Borel measurable by verifying that [Mf > λ] ≡Eλ is actually
an open set. Hint: If x ∈Eλ then for some r,
R
B(x,r) |f| dm > λm (B (x, r)) .
Then for δ a small enough positive number,
R
B(x,r) |f| dm > λm (B (x, r + 2δ)) .
Now pick y ∈B (x, δ) and argue that B (y, δ + r) ⊇B (x, r) . Therefore show
that,
Z
B(y,δ+r)
|f| dm >
Z
B(x,r)
|f| dm > λB (x, r + 2δ) ≥λm (B (y, r + δ)) .
Thus B (x, δ) ⊆Eλ.
3. Consider the following nested sequence of compact sets, {Pn}.Let P1 = [0, 1],
P2 =
£
0, 1
3
¤
∪
£ 2
3, 1
¤
, etc. To go from Pn to Pn+1, delete the open interval
which is the middle third of each closed interval in Pn. Let P = ∩∞
n=1Pn.
By the ﬁnite intersection property of compact sets, P ̸= ∅. Show m(P) = 0.
If you feel ambitious also show there is a one to one onto mapping of [0, 1]
to P. The set P is called the Cantor set. Thus, although P has measure
zero, it has the same number of points in it as [0, 1] in the sense that there
is a one to one and onto mapping from one to the other. Hint: There are
various ways of doing this last part but the most enlightenment is obtained
by exploiting the topological properties of the Cantor set rather than some
silly representation in terms of sums of powers of two and three. All you need
to do is use the Schroder Bernstein theorem and show there is an onto map
from the Cantor set to [0, 1]. If you do this right and remember the theorems
about characterizations of compact metric spaces, Proposition 6.12 on Page
136, you may get a pretty good idea why every compact metric space is the
continuous image of the Cantor set.
4. Consider the sequence of functions deﬁned in the following way. Let f1 (x) = x
on [0, 1]. To get from fn to fn+1, let fn+1 = fn on all intervals where fn is
constant.
If fn is nonconstant on [a, b], let fn+1(a) = fn(a), fn+1(b) =
fn(b), fn+1 is piecewise linear and equal to 1
2(fn(a) + fn(b)) on the middle
third of [a, b]. Sketch a few of these and you will see the pattern. The process
of modifying a nonconstant section of the graph of this function is illustrated
in the following picture.

446
INTEGRALS AND DERIVATIVES
¡
¡
¡




Show {fn} converges uniformly on [0, 1]. If f(x) = limn→∞fn(x), show that
f(0) = 0, f(1) = 1, f is continuous, and f ′(x) = 0 for all x /∈P where P is
the Cantor set of Problem 3. This function is called the Cantor function.It is
a very important example to remember. Note it has derivative equal to zero
a.e. and yet it succeeds in climbing from 0 to 1. Explain why this interesting
function is not absolutely continuous although it is continuous. Hint: This
isn’t too hard if you focus on getting a careful estimate on the diﬀerence
between two successive functions in the list considering only a typical small
interval in which the change takes place. The above picture should be helpful.
5. A function, f : [a, b] →R is Lipschitz if |f (x) −f (y)| ≤K |x −y| . Show
that every Lipschitz function is absolutely continuous. Thus every Lipschitz
function is diﬀerentiable a.e., f ′ ∈L1, and f (y) −f (x) =
R y
x f ′ (t) dt.
6. Suppose f, g are both absolutely continuous on [a, b] . Show the product of
these functions is also absolutely continuous. Explain why (fg)′ = f ′g + g′f
and show the usual integration by parts formula
f (b) g (b) −f (a) g (a) −
Z b
a
fg′dt =
Z b
a
f ′gdt.
7. In Problem 4 f ′ failed to give the expected result for
R b
a f ′dx 1 but at least
f ′ ∈L1. Suppose f ′ exists for f a continuous function deﬁned on [a, b] . Does
it follow that f ′ is measurable? Can you conclude f ′ ∈L1 ([a, b])?
8. A sequence of sets, {Ei} containing the point x is said to shrink to x nicely
if there exists a sequence of positive numbers, {ri} and a positive constant, α
such that ri →0 and
m (Ei) ≥αm (B (x, ri)) , Ei ⊆B (x, ri) .
Show the above theorems about diﬀerentiation of measures with respect to
Lebesgue measure all have a version valid for Ei replacing B (x, r) .
9. Suppose F (x) =
R x
a f (t) dt. Using the concept of nicely shrinking sets in
Problem 8 show F ′ (x) = f (x) a.e.
10. A random variable, X is a measurable real valued function deﬁned on a mea-
sure space, (Ω, S, P) where P is just a measure with P (Ω) = 1 called a
probability measure. The distribution function for X is the function, F (x) ≡
P ([X ≤x]) in words, F (x) is the probability that X has values no larger than
x. Show that F is a right continuous increasing function with the property
that limx→−∞F (x) = 0 and limx→∞F (x) = 1.
1In this example, you only know that f′ exists a.e.

16.4.
EXERCISES
447
11. Suppose F is an increasing right continuous function.
(a) Show that Lf ≡
R b
a fdF is a well deﬁned positive linear functional on
Cc (R) where here [a, b] is a closed interval containing the support of
f ∈Cc (R) .
(b) Using the Riesz representation theorem for positive linear functionals on
Cc (R) , let µ denote the Radon measure determined by L. Show that
µ ((a, b]) = F (b) −F (a) and µ ({b}) = F (b) −F (b−) where F (b−) ≡
limx→b−F (x) .
(c) Review Corollary 15.4 on Page 404 at this point. Show that the condi-
tions of this corollary hold for µ and m. Consider µ⊥+ µ||, the Lebesgue
decomposition of µ where µ|| ≪m and there exists a set of m measure
zero, N such that µ⊥(E) = µ⊥(E ∩N) . Show µ ((0, x]) = µ⊥((0, x]) +
R x
0 h (t) dt for some h ∈L1 (m) . Using Theorem 16.21 show h (x) = F ′ (x)
m a.e. Explain why F (x) = F (0) + S (x) +
R x
0 F ′ (t) dt for some func-
tion, S (x) which is increasing but has S′ (x) = 0 a.e. Note this shows
in particular that a right continuous increasing function has a derivative
a.e.
12. Suppose now that G is just an increasing function deﬁned on R. Show that
G′ (x) exists a.e. Hint: You can mimic the proof of Theorem 16.18. The Dini
derivates are deﬁned as
D+G (x)
≡
lim inf
h→0+
G (x + h) −G (x)
h
,
D+G (x)
≡
lim sup
h→0+
G (x + h) −G (x)
h
D−G (x)
≡
lim inf
h→0+
G (x) −G (x −h)
h
,
D−G (x)
≡
lim sup
h→0+
G (x) −G (x −h)
h
.
When D+G (x) = D+G (x) the derivative from the right exists and when
D−G (x) = D−G (x) , then the derivative from the left exists. Let (a, b) be an
open interval and let
Npq ≡
©
x ∈(a, b) : D+G (x) > q > p > D+G (x)
ª
.
Let V ⊆(a, b) be an open set containing Npq such that n (V ) < m (Npq) + ε.
Show using a Vitali covering theorem there is a disjoint sequence of intervals
contained in V , {(xi, xi + hi)}∞
i=1 such that
G (xi + hi) −G (xi)
hi
< p.

448
INTEGRALS AND DERIVATIVES
Next show there is a disjoint sequence of intervals
©¡
x′
i, x′
j + h′
j
¢ª∞
j=1 such
that each of these is contained in one of the former intervals and
G
¡
x′
j + h′
j
¢
−G
¡
x′
j
¢
h′
j
> q,
X
j
h′
j ≥m (Npq) .
Then
qm (Npq)
≤
q
X
j
h′
j ≤
X
j
G
¡
x′
j + h′
j
¢
−G
¡
x′
j
¢
≤
X
i
G (xi + hi) −G (xi)
≤
p
X
i
hi ≤pm (V ) ≤p (m (Npq) + ε) .
Since ε was arbitrary, this shows m (Npq) = 0. Taking a union of all Npq
for p, q rational, shows the derivative from the right exists a.e. Do a similar
argument to show the derivative from the left exists a.e. and then show the
derivative from the left equals the derivative from the right a.e. using a simlar
argument. Thus G′ (x) exists on (a, b) a.e. and so it exists a.e. on R because
(a, b) was arbitrary.

HausdorﬀMeasure
17.1
Deﬁnition Of HausdorﬀMeasures
This chapter is on Hausdorﬀmeasures. First I will discuss some outer measures. In
all that is done here, α (n) will be the volume of the ball in Rn which has radius 1.
Deﬁnition 17.1 For a set, E, denote by r (E) the number which is half the diam-
eter of E. Thus
r (E) ≡1
2 sup {|x −y| : x, y ∈E} ≡1
2 diam (E)
Let E ⊆Rn.
Hs
δ(E) ≡inf{
∞
X
j=1
β(s)(r (Cj))s : E ⊆∪∞
j=1Cj, diam(Cj) ≤δ}
Hs(E) ≡lim
δ→0 Hs
δ(E).
In the above deﬁnition, β (s) is an appropriate positive constant depending on
s. Later I will tell what this constant is but it is not important for now.
Lemma 17.2 Hs and Hs
δ are outer measures.
Proof: It is clear that Hs(∅) = 0 and if A ⊆B, then Hs(A) ≤Hs(B) with
similar assertions valid for Hs
δ. Suppose E = ∪∞
i=1Ei and Hs
δ(Ei) < ∞for each i.
Let {Ci
j}∞
j=1 be a covering of Ei with
∞
X
j=1
β(s)(r(Ci
j))s −ε/2i < Hs
δ(Ei)
449

450
HAUSDORFF MEASURE
and diam(Ci
j) ≤δ. Then
Hs
δ(E)
≤
∞
X
i=1
∞
X
j=1
β(s)(r(Ci
j))s
≤
∞
X
i=1
Hs
δ(Ei) + ε/2i
≤
ε +
∞
X
i=1
Hs
δ(Ei).
It follows that since ε > 0 is arbitrary,
Hs
δ(E) ≤
∞
X
i=1
Hs
δ(Ei)
which shows Hs
δ is an outer measure. Now notice that Hs
δ(E) is increasing as δ →0.
Picking a sequence δk decreasing to 0, the monotone convergence theorem implies
Hs(E) ≤
∞
X
i=1
Hs(Ei).
This proves the lemma.
The outer measure Hs is called s dimensional Hausdorﬀmeasure when restricted
to the σ algebra of Hs measurable sets.
Next I will show the σ algebra of Hs measurable sets includes the Borel sets.
This is done by the following very interesting condition known as Caratheodory’s
criterion.
17.1.1
Properties Of HausdorﬀMeasure
Deﬁnition 17.3 For two sets, A, B in a metric space, we deﬁne
dist (A, B) ≡inf {d (x, y) : x ∈A, y ∈B} .
Theorem 17.4 Let µ be an outer measure on the subsets of (X, d), a metric space.
If
µ(A ∪B) = µ(A) + µ(B)
whenever dist(A, B) > 0, then the σ algebra of measurable sets contains the Borel
sets.
Proof: It suﬃces to show that closed sets are in S, the σ-algebra of measurable
sets, because then the open sets are also in S and consequently S contains the Borel
sets. Let K be closed and let S be a subset of Ω. Is µ(S) ≥µ(S ∩K) + µ(S \ K)?
It suﬃces to assume µ(S) < ∞. Let
Kn ≡{x : dist(x, K) ≤1
n}

17.1.
DEFINITION OF HAUSDORFF MEASURES
451
By Lemma 6.7 on Page 135, x →dist (x, K) is continuous and so Kn is closed. By
the assumption of the theorem,
µ(S) ≥µ((S ∩K) ∪(S \ Kn)) = µ(S ∩K) + µ(S \ Kn)
(17.1)
since S ∩K and S \ Kn are a positive distance apart. Now
µ(S \ Kn) ≤µ(S \ K) ≤µ(S \ Kn) + µ((Kn \ K) ∩S).
(17.2)
If limn→∞µ((Kn \ K) ∩S) = 0 then the theorem will be proved because this limit
along with 17.2 implies limn→∞µ (S \ Kn) = µ (S \ K) and then taking a limit in
17.1, µ(S) ≥µ(S ∩K) + µ(S \ K) as desired. Therefore, it suﬃces to establish this
limit.
Since K is closed, a point, x /∈K must be at a positive distance from K and so
Kn \ K = ∪∞
k=nKk \ Kk+1.
Therefore
µ(S ∩(Kn \ K)) ≤
∞
X
k=n
µ(S ∩(Kk \ Kk+1)).
(17.3)
If
∞
X
k=1
µ(S ∩(Kk \ Kk+1)) < ∞,
(17.4)
then µ(S ∩(Kn \ K)) →0 because it is dominated by the tail of a convergent series
so it suﬃces to show 17.4.
M
X
k=1
µ(S ∩(Kk \ Kk+1)) =
X
k even, k≤M
µ(S ∩(Kk \ Kk+1)) +
X
k odd, k≤M
µ(S ∩(Kk \ Kk+1)).
(17.5)
By the construction, the distance between any pair of sets, S ∩(Kk \ Kk+1) for
diﬀerent even values of k is positive and the distance between any pair of sets,
S ∩(Kk \ Kk+1) for diﬀerent odd values of k is positive. Therefore,
X
k even, k≤M
µ(S ∩(Kk \ Kk+1)) +
X
k odd, k≤M
µ(S ∩(Kk \ Kk+1)) ≤
µ(
[
k even
S ∩(Kk \ Kk+1)) + µ(
[
k odd
S ∩(Kk \ Kk+1)) ≤2µ (S) < ∞
and so for all M, PM
k=1 µ(S ∩(Kk \ Kk+1)) ≤2µ (S) showing 17.4 and proving the
theorem.
With the above theorem, the following theorem is easy to obtain. This property
is sometimes called Borel regularity.

452
HAUSDORFF MEASURE
Theorem 17.5 The σ algebra of Hs measurable sets contains the Borel sets and
Hs has the property that for all E ⊆Rn, there exists a Borel set F ⊇E such that
Hs(F) = Hs(E).
Proof: Let dist(A, B) = 2δ0 > 0. Is it the case that
Hs(A) + Hs(B) = Hs(A ∪B)?
This is what is needed to use Caratheodory’s criterion.
Let {Cj}∞
j=1be a covering of A ∪B such that diam(Cj) ≤δ < δ0 for each j and
Hs
δ(A ∪B) + ε >
∞
X
j=1
β(s)(r (Cj))s.
Thus
Hs
δ(A ∪B˙) + ε >
X
j∈J1
β(s)(r (Cj))s +
X
j∈J2
β(s)(r (Cj))s
where
J1 = {j : Cj ∩A ̸= ∅}, J2 = {j : Cj ∩B ̸= ∅}.
Recall dist(A, B) = 2δ0, J1 ∩J2 = ∅. It follows
Hs
δ(A ∪B) + ε > Hs
δ(A) + Hs
δ(B).
Letting δ →0, and noting ε > 0 was arbitrary, yields
Hs(A ∪B) ≥Hs(A) + Hs(B).
Equality holds because Hs is an outer measure. By Caratheodory’s criterion, Hs is
a Borel measure.
To verify the second assertion, note ﬁrst there is no loss of generality in letting
Hs (E) < ∞. Let
E ⊆∪∞
j=1Cj, diam(Cj) < δ,
and
Hs
δ(E) + δ >
∞
X
j=1
β(s)(r (Cj))s.
Let
Fδ = ∪∞
j=1Cj.
Thus Fδ ⊇E and
Hs
δ(E)
≤
Hs
δ(Fδ) ≤
∞
X
j=1
β(s)(r
¡
Cj
¢
)s
=
∞
X
j=1
β(s)(r (Cj))s < δ + Hs
δ(E).

17.1.
DEFINITION OF HAUSDORFF MEASURES
453
Let δk →0 and let F = ∩∞
k=1Fδk. Then F ⊇E and
Hs
δk(E) ≤Hs
δk(F) ≤Hs
δk(Fδ) ≤δk + Hs
δk(E).
Letting k →∞,
Hs(E) ≤Hs(F) ≤Hs(E)
and this proves the theorem.
A measure satisfying the conclusion of Theorem 17.5 is sometimes called a Borel
regular measure.
17.1.2
Hn And mn
Next I will compare Hn and mn. To do this, recall the following covering theorem
which is a summary of Corollaries 10.20 and 10.19 found on Page 279.
Theorem 17.6 Let E ⊆Rn and let F, be a collection of balls of bounded radii
such that F covers E in the sense of Vitali. Then there exists a countable collection
of disjoint balls from F, {Bj}∞
j=1, such that mn(E \ ∪∞
j=1Bj) = 0.
Lemma 17.7 There exists a constant, k such that Hn (E) ≤kmn (E) for all E
Borel. Also, if Q0 ≡[0, 1)n, the unit cube, then Hn ([0, 1)n) > 0.
Proof:
First let U be an open set and letting δ > 0, consider all balls, B
contained in U which have diameters less than δ. This is a Vitali covering of U and
therefore by Theorem 17.6, there exists {Bi} , a sequence of disjoint balls of radii
less than δ contained in U such that ∪∞
i=1Bi diﬀers from U by a set of Lebesgue
measure zero. Let α (n) be the Lebesgue measure of the unit ball in Rn. Then
Hn
δ (U)
≤
∞
X
i=1
β (n) r (Bi)n = β (n)
α (n)
∞
X
i=1
α (n) r (Bi)n
=
β (n)
α (n)
∞
X
i=1
mn (Bi) = β (n)
α (n)mn (U) ≡kmn (U) .
Now letting E be Borel, it follows from the outer regularity of mn there exists
a decreasing sequence of open sets, {Vi} containing E such such that mn (Vi) →
mn (E) . Then from the above,
Hn
δ (E) ≤lim
i→∞Hn
δ (Vi) ≤lim
i→∞kmn (Vi) = kmn (E) .
Since δ > 0 is arbitrary, it follows that also
Hn (E) ≤kmn (E) .
This proves the ﬁrst part of the lemma.
To verify the second part, note that it is obvious Hn
δ and Hn are translation
invariant because diameters of sets do not change when translated. Therefore, if

454
HAUSDORFF MEASURE
Hn ([0, 1)n) = 0, it follows Hn (Rn) = 0 because Rn is the countable union of
translates of Q0 ≡[0, 1)n. Since each Hn
δ is no larger than Hn, the same must hold
for Hn
δ . Therefore, there exists a sequence of sets, {Ci} each having diameter less
than δ such that
1 >
∞
X
i=1
β (n) r (Ci)n .
Now let Bi be a ball having radius equal to diam (Ci) = 2r (Ci) which contains Ci.
It follows
mn (Bi) = α (n) 2nr (Ci)n = α (n) 2n
β (n) β (n) r (Ci)n
which implies
1 >
∞
X
i=1
β (n) r (Ci)n =
∞
X
i=1
β (n)
α (n) 2n mn (Bi) = ∞,
a contradiction. This proves the lemma.
Theorem 17.8 If β (n) ≡α (n) , then Hn = mn on all Lebesgue measurable sets.
Proof: First I will show Hn is a positive multiple of mn. Let
k = mn (Q0)
Hn (Q0)
I will show kHn (E) = mn (E). When this is done, it will follow that by adjusting
β (n) the multiple can be taken to be 1. I will only need to show that the right
value for β (n) is α (n). Recall Lemma 10.2 on Page 267 which is listed here for
convenience.
Lemma 17.9 Every open set in Rn is the countable disjoint union of half open
boxes of the form
n
Y
i=1
(ai, ai + 2−k]
where ai = l2−k for some integers, l, k. The sides of these boxes are of equal length.
One could also have half open boxes of the form
n
Y
i=1
[ai, ai + 2−k)
and the conclusion would be unchanged.
Let Q = Qn
i=1[ai, ai + 2−k) be one of the half open boxes just mentioned in the
above lemma. By translation invariance, of Hn and mn
¡
2k¢n Hn (Q) = Hn (Q0) = 1
k mn (Q0) = 1
k
¡
2k¢n mn (Q) .

17.1.
DEFINITION OF HAUSDORFF MEASURES
455
Therefore, kHn (Q) = mn (Q) . It follows from Lemma 10.2 on Page 267 stated
above that kHn (U) = mn (U) for all open sets.
It follows immediately, since
every compact set is the countable intersection of open sets that kHn = mn on
compact sets. Therefore, they are also equal on all closed sets because every closed
set is the countable union of compact sets. Now let F be an arbitrary Lebesgue
measurable set. I will show that F is Hn measurable and that kHn (F) = mn (F).
Let Fl = B (0, l) ∩F. Then there exists H a countable union of compact sets and
G a countable intersection of open sets such that
H ⊆Fl ⊆G
(17.6)
and
mn (G \ H) = kHn (G \ H) = 0.
(17.7)
To do this, let {Gi} be a decreasing sequence of bounded open sets containing Fl
and let {Hi} be an increasing sequence of compact sets contained in Fl such that
kHn (Gi \ Hi) = mn (Gi \ Hi) < 2−i
Then letting G = ∩iGi and H = ∪iHi this establishes 17.6 and 17.7. Then by
completeness of Hn it follows Fl is Hn measurable and
kHn (Fl) = kHn (H) = mn (H) = mn (Fl) .
Now taking l →∞, it follows F is Hn measurable and kHn (F) = mn (F). There-
fore, adjusting β (n) it can be assumed the constant, k is 1.
It only remains to show that the proper determination of β (n) is α (n). By the
Vitali covering theorem, there exists a sequence of disjoint balls, {Bi} such that
B (0, 1) = (∪∞
i=1Bi) ∪N where mn (N) = 0. Then Hn
δ (N) = 0 can be concluded
because Hn
δ ≤Hnand Hn (N) = 0. Therefore,
Hn
δ (B (0, 1))
=
Hn
δ (∪iBi) ≤
∞
X
i=1
β (n) r (Bi)n
=
β (n)
α (n)
∞
X
i=1
α (n) r (Bi)n = β (n)
α (n)
∞
X
i=1
mn (Bi)
=
β (n)
α (n)mn (∪iBi) = β (n)
α (n)mn (B (0, 1)) = β (n)
α (n)Hn (B (0, 1))
Taking the limit as δ →0,
Hn (B (0, 1)) ≤β (n)
α (n)Hn (B (0, 1))
and so α (n) ≤β (n) .

456
HAUSDORFF MEASURE
Also
Hn (B (0, 1))
≥
Hn
δ (B (0, 1)) = Hn
δ (∪iBi) =
∞
X
i=1
Hn
δ (Bi)
≥
∞
X
i=1
β (n) r (Bi)n = β (n)
α (n)
∞
X
i=1
α (n) r (Bi)n
=
β (n)
α (n)
∞
X
i=1
mn (Bi) = β (n)
α (n)mn (B (0, 1))
=
β (n)
α (n)Hn (B (0, 1))
which shows α (n) ≥β (n) and so the two are equal. This proves the theorem.
This gives another way to think of Lebesgue measure which is a particularly nice
way because it is coordinate free, depending only on the notion of distance.
For s < n, note that Hs is not a Radon measure because it will not generally be
ﬁnite on compact sets. For example, let n = 2 and consider H1(L) where L is a line
segment joining (0, 0) to (1, 0). Then H1(L) is no smaller than H1(L) when L is
considered a subset of R1, n = 1. Thus by what was just shown, H1(L) ≥1. Hence
H1([0, 1] × [0, 1]) = ∞. The situation is this: L is a one-dimensional object inside
R2 and H1 is giving a one-dimensional measure of this object. In fact, Hausdorﬀ
measures can make such heuristic remarks as these precise. Deﬁne the Hausdorﬀ
dimension of a set, A, as
dim(A) = inf{s : Hs(A) = 0}
17.1.3
A Formula For α (n)
What is α(n)? Recall the gamma function which makes sense for all p > 0.
Γ (p) ≡
Z ∞
0
e−ttp−1dt.
Lemma 17.10 The following identities hold.
pΓ(p) = Γ(p + 1),
Γ(p)Γ(q) =
µZ 1
0
xp−1(1 −x)q−1dx
¶
Γ(p + q),
Γ
µ1
2
¶
= √π
Proof: Using integration by parts,
Γ (p + 1)
=
Z ∞
0
e−ttpdt = −e−ttp|∞
0 + p
Z ∞
0
e−ttp−1dt
=
pΓ (p)

17.1.
DEFINITION OF HAUSDORFF MEASURES
457
Next
Γ (p) Γ (q)
=
Z ∞
0
e−ttp−1dt
Z ∞
0
e−ssq−1ds
=
Z ∞
0
Z ∞
0
e−(t+s)tp−1sq−1dtds
=
Z ∞
0
Z ∞
s
e−u (u −s)p−1 sq−1duds
=
Z ∞
0
Z u
0
e−u (u −s)p−1 sq−1dsdu
=
Z ∞
0
Z 1
0
e−u (u −ux)p−1 (ux)q−1 udxdu
=
Z ∞
0
Z 1
0
e−uup+q−1 (1 −x)p−1 xq−1dxdu
=
Γ (p + q)
µZ 1
0
xp−1(1 −x)q−1dx
¶
.
It remains to ﬁnd Γ
¡ 1
2
¢
.
Γ
µ1
2
¶
=
Z ∞
0
e−tt−1/2dt =
Z ∞
0
e−u2 1
u2udu = 2
Z ∞
0
e−u2du
Now
µZ ∞
0
e−x2dx
¶2
=
Z ∞
0
e−x2dx
Z ∞
0
e−y2dy =
Z ∞
0
Z ∞
0
e−(x2+y2)dxdy
=
Z ∞
0
Z π/2
0
e−r2rdθdr = 1
4π
and so
Γ
µ1
2
¶
= 2
Z ∞
0
e−u2du = √π
This proves the lemma.
Next let n be a positive integer.
Theorem 17.11 α(n) = πn/2(Γ(n/2 + 1))−1 where Γ(s) is the gamma function
Γ(s) =
Z ∞
0
e−tts−1dt.
Proof: First let n = 1.
Γ(3
2) = 1
2Γ
µ1
2
¶
=
√π
2 .

458
HAUSDORFF MEASURE
Thus
π1/2(Γ(1/2 + 1))−1 =
2
√π
√π = 2 = α (1) .
and this shows the theorem is true if n = 1.
Assume the theorem is true for n and let Bn+1 be the unit ball in Rn+1. Then
by the result in Rn,
mn+1(Bn+1) =
Z 1
−1
α(n)(1 −x2
n+1)n/2dxn+1
= 2α(n)
Z 1
0
(1 −t2)n/2dt.
Doing an integration by parts and using Lemma 17.10
=
2α(n)n
Z 1
0
t2(1 −t2)(n−2)/2dt
=
2α(n)n1
2
Z 1
0
u1/2(1 −u)n/2−1du
=
nα(n)
Z 1
0
u3/2−1(1 −u)n/2−1du
=
nα(n)Γ(3/2)Γ(n/2)(Γ((n + 3)/2))−1
=
nπn/2(Γ(n/2 + 1))−1(Γ((n + 3)/2))−1Γ(3/2)Γ(n/2)
=
nπn/2(Γ(n/2)(n/2))−1(Γ((n + 1)/2 + 1))−1Γ(3/2)Γ(n/2)
=
2πn/2Γ(3/2)(Γ((n + 1)/2 + 1))−1
=
π(n+1)/2(Γ((n + 1)/2 + 1))−1.
This proves the theorem.
From now on, in the deﬁnition of Hausdorﬀmeasure, it will always be the case
that β (s) = α (s) . As shown above, this is the right thing to have β (s) equal to if s
is a positive integer because this yields the important result that Hausdorﬀmeasure
is the same as Lebesgue measure. Note the formula, πs/2(Γ(s/2+1))−1 makes sense
for any s ≥0.
17.1.4
HausdorﬀMeasure And Linear Transformations
Hausdorﬀmeasure makes possible a uniﬁed development of n dimensional area.
As in the case of Lebesgue measure, the ﬁrst step in this is to understand basic
considerations related to linear transformations. Recall that for L ∈L
¡
Rk, Rl¢
, L∗
is deﬁned by
(Lu, v) = (u, L∗v) .
Also recall Theorem 4.59 on Page 87 which is stated here for convenience. This
theorem says you can write a linear transformation as the composition of two linear
transformations, one which preserves length and the other which distorts. The one

17.1.
DEFINITION OF HAUSDORFF MEASURES
459
which distorts is the one which will have a nontrivial interaction with Hausdorﬀ
measure while the one which preserves lengths does not change Hausdorﬀmeasure.
These ideas are behind the following theorems and lemmas.
Theorem 17.12 Let F be an n × m matrix where m ≥n. Then there exists an
m × n matrix R and a n × n matrix U such that
F = RU, U = U ∗,
all eigenvalues of U are non negative,
U 2 = F ∗F, R∗R = I,
and |Rx| = |x|.
Lemma 17.13 Let R ∈L(Rn, Rm), n ≤m, and R∗R = I. Then if A ⊆Rn,
Hn(RA) = Hn(A).
In fact, if P : Rn →Rm satisﬁes |Px −Py| = |x −y| , then
Hn (PA) = Hn (A) .
Proof: Note that
|R(x −y)|2= (R (x −y) , R (x −y)) = (R∗R (x −y) , x −y) = |x −y|2
Thus R preserves lengths.
Now let P be an arbitrary mapping which preserves lengths and let A be
bounded, P(A) ⊆∪∞
j=1Cj, diam(Cj) ≤δ, and
Hn
δ (PA) + ε >
∞
X
j=1
α(n)(r(Cj))n.
Since P preserves lengths, it follows P is one to one on P (Rn) and P −1 also preserves
lengths on P (Rn) . Replacing each Cj with Cj ∩(PA),
Hn
δ (PA) + ε
>
∞
X
j=1
α(n)r(Cj ∩(PA))n
=
∞
X
j=1
α(n)r
¡
P −1 (Cj ∩(PA))
¢n
≥
Hn
δ (A).
Thus Hn
δ (PA) ≥Hn
δ (A).
Now let A ⊆∪∞
j=1Cj, diam(Cj) ≤δ, and
Hn
δ (A) + ε ≥
∞
X
j=1
α(n) (r (Cj))n

460
HAUSDORFF MEASURE
Then
Hn
δ (A) + ε
≥
∞
X
j=1
α(n) (r (Cj))n
=
∞
X
j=1
α(n) (r (PCj))n
≥
Hn
δ (PA).
Hence Hn
δ (PA) = Hn
δ (A).
Letting δ →0 yields the desired conclusion in the
case where A is bounded.
For the general case, let Ar = A ∩B (0, r).
Then
Hn(PAr) = Hn(Ar). Now let r →∞. This proves the lemma.
Lemma 17.14 Let F ∈L(Rn, Rm), n ≤m, and let F = RU where R and U are
described in Theorem 4.59 on Page 87. Then if A ⊆Rn is Lebesgue measurable,
Hn(FA) = det(U)mn(A).
Proof: Using Theorem 10.28 on Page 282 and Theorem 17.8,
Hn(FA) = Hn(RUA)
= Hn(UA) = mn(UA) = det(U)mn(A).
Deﬁnition 17.15 Deﬁne J to equal det(U). Thus
J = det((F ∗F)1/2) = (det(F ∗F))1/2.
17.2
The Area Formula
17.2.1
Preliminary Results
It was shown in Lemma 17.14 that
Hn(FA) = det(U)mn(A)
where F = RU with R preserving distances and U a symmetric matrix having
all positive eigenvalues.
The area formula gives a generalization of this simple
relationship to the case where F is replaced by a nonlinear mapping, h. It contains
as a special case the earlier change of variables formula. There are two parts to this
development. The ﬁrst part is to generalize Lemma 17.14 to the case of nonlinear
maps. When this is done, the area formula can be presented.
In this section, U will be an open set in Rn on which h is deﬁned and A ⊆U
will be a Lebesgue measurable set. Assume m ≥n and
h : U →Rm is continuous,
(17.8)

17.2.
THE AREA FORMULA
461
Dh (x) exists for all x ∈A,
(17.9)
Also assume that for every x ∈A, there exists Rx and Lx such that for all y, z ∈
B (x, Rx) ,
|h (z) −h (y)| ≤Lx |x −y|
(17.10)
This last condition is weaker than saying h is Lipschitz. Instead, it is an assumption
that h is locally Lipshitz, the Lipschitz constant depending on the point considered.
An interesting case in which this would hold would be when h is diﬀerentiable on
U and ||Dh (x)|| is uniformly bounded near each point x. Actually, it is the case
that 17.10 will suﬃce to obtain 17.9 on all but a subset of measure zero of A but
this has not been shown yet. Also, the condition 17.8 is redundant because you
can simply replace U with the union of the sets B (x, Rx) for x ∈A. I think it
is easiest to retain this condition because diﬀerentiability is deﬁned for functions
whose domains are open sets. To make this more formal, here is a deﬁnition.
Deﬁnition 17.16 Let h be deﬁned in some open set containing a set, A. Then h
is locally Lipschitz on A if for every x ∈A there exits Rx > 0 and a constant, Lx
such that whenever y, z ∈B (x, Rx) ,
|h (z) −h (y)| ≤Lx |z −y| .
Lemma 17.17 If T ⊆A and mn (T) = 0, then Hn (h (T)) = 0.
Proof: Let
Tk ≡{x ∈T : ||Dh (x)|| < k} .
Thus T = ∪kTk. I will show h (Tk) has Hn measure zero and then it will follow
that
h (T) = ∪∞
k=1h (Tk)
must also have measure zero.
Let ε > 0 be given. By outer regularity, there exists an open set, V , containing
Tk which is contained in U such that mn (V ) <
ε
kn6n . For x ∈Tk it follows from
diﬀerentiability,
h (x + v) = h (x) + Dh (x) v + o (v)
and so whenever rx is small enough, B (x,5rx) ⊆V and whenever |v| < 5rx, |o (v)| <
krx. Therefore, if |v| < 5rx,
Dh (x) v + o (v) ∈B (0, 5krx) + B (0,krx) ⊆B (0, 6krx)
and so
h (B (x, 5rx)) ⊆B (h (x) , 6krx).
Letting δ > 0 be given, the Vitali covering theorem implies there exists a sequence
of disjoint balls {Bi}, Bi = B (xi, rxi), which are contained in V such that the
sequence of enlarged balls,
n
bBi
o
, having the same center but 5 times the radius,
covers Tk and 6krxi < δ. Then
Hn
δ (h (Tk)) ≤Hn
δ
³
h
³
∪∞
i=1 bBi
´´

462
HAUSDORFF MEASURE
≤
∞
X
i=1
Hn
δ
³
h
³
bBi
´´
≤
∞
X
i=1
Hn
δ (B (h (xi) , 6krxi))
≤
∞
X
i=1
α (n) (6krxi)n = (6k)n
∞
X
i=1
α (n) rn
xi
=
(6k)n
∞
X
i=1
mn (B (xi, rxi))
≤
(6k)n mn (V ) ≤(6k)n
ε
kn6n = ε.
Since ε > 0 is arbitrary, this shows Hn
δ (h (Tk)) = 0. Since δ is arbitrary, this implies
Hn (h (Tk)) = 0. Now
Hn (h (T)) = lim
k→∞Hn (h (Tk)) = 0.
This proves the lemma.
Lemma 17.18 If S is a Lebesgue measurable subset of A, then h (S) is Hn mea-
surable.
Proof: Let Sk = S ∩B (0, k) , k ∈N. By inner regularity of Lebesgue measure,
there exists a set, F, which is the countable union of compact sets and a set T with
mn (T) = 0 such that
F ∪T = Sk.
Then h (F) ⊆h (Sk) ⊆h (F)∪h (T). By continuity of h, h (F) is a countable union
of compact sets and so it is Borel. By Lemma 17.17, Hn (h (T)) = 0 and so h (Sk)
is Hn measurable because of completeness of Hausdorﬀmeasure, which comes from
Hn being obtained from an outer measure. Now h (S) = ∪∞
k=1h (Sk) and so it is
also true that h (S) is Hn measurable. This proves the lemma.
The following lemma, depending on the Brouwer ﬁxed point theorem and found
in Rudin [45], will be important for the following arguments. The idea is that if a
continuous function mapping a ball in Rk to Rk doesn’t move any point very much,
then the image of the ball must contain a slightly smaller ball.
Lemma 17.19 Let B = B (0, r), a ball in Rk and let F : B →Rk be continuous
and suppose for some ε < 1,
|F (v) −v| < εr
(17.11)
for all v ∈B. Then
F (B) ⊇B (0, r (1 −ε)) .
Proof: Suppose a ∈B (0, r (1 −ε)) \ F (B) .
I claim that a ̸= F (v) for all v ∈B. Here is why. By assumption, if F (v) = a,
then |v| = r and so
|F (v) −v| = |a −v| ≥|v| −|a| > r −r (1 −ε) = rε,

17.2.
THE AREA FORMULA
463
a contradiction to 17.11.
Now letting G :B →B, be deﬁned by
G (v) ≡r (a −F (v))
|a −F (v)| ,
it follows G is continuous. Then by the Brouwer ﬁxed point theorem, G (v) = v for
some v ∈B. Using the formula for G, it follows |v| = r. Taking the inner product
with v,
(G (v) , v)
=
|v|2 = r2 =
r
|a −F (v)| (a −F (v) , v)
=
r
|a −F (v)| (a −v + v −F (v) , v)
=
r
|a −F (v)| [(a −v, v) + (v −F (v) , v)]
=
r
|a −F (v)|
h
(a, v) −|v|2 + (v −F (v) , v)
i
≤
r
|a −F (v)|
£
r2 (1 −ε) −r2+r2ε
¤
= 0,
a contradiction to |v| = r. Therefore, B (0, r (1 −ε)) \ F (B) = ∅and this proves
the lemma.
By Theorem 4.59 on Page 87, when Dh (x) exists,
Dh (x) = R (x) U (x)
where (U (x) u, v) = (U (x) v, u) , (U (x) u, u) ≥0 and R∗R = I.
Lemma 17.20 In this situation, |R∗u| ≤|u|.
Proof: First note that
(u−RR∗u,RR∗u)
=
(u,RR∗u) −|RR∗u|2
=
|R∗u|2 −|R∗u|2 = 0,
and so
|u|2
=
|u−RR∗u+RR∗u|2
=
|u−RR∗u|2 + |RR∗u|2
=
|u−RR∗u|2 + |R∗u|2.
This proves the lemma.
Lemma 17.21 If |Px −Py| ≤L |x −y| , then for E a set,
Hn (PE) ≤LnHn (E) .

464
HAUSDORFF MEASURE
Proof: Without loss of generality, assume Hn (E) < ∞. Let δ > 0 and let
{Ci}∞
i=1 be a covering of E such that diam (Ci) ≤δ for each i and
∞
X
i=1
α (n) r (Ci)n ≤Hn
δ (E) + ε.
Then {PCi}∞
i=1 is a covering of PE such that diam (PCi) ≤Lδ. Therefore,
Hn
Lδ (PE)
≤
∞
X
i=1
α (n) r (PCi)n
≤
Ln
∞
X
i=1
α (n) r (Ci)n ≤LnHn
δ (E) + Lnε
≤
Hn (E) + ε.
Letting δ →0,
Hn (PE) ≤LnHn (E) + Lnε
and since ε > 0 is arbitrary, this proves the Lemma.
Then the following corollary follows from Lemma 17.20.
Corollary 17.22 Let T ⊆Rm. Then
Hn (T) ≥Hn (RR∗T) = Hn (R∗T).
Deﬁnition 17.23 Let E be a Lebesgue measurable set. x ∈E is a point of density
if
lim
r→0
mn(E ∩B(x, r))
mn(B(x, r))
= 1.
Recall that from the fundamental theorem of calculus applied to XE almost
every point of E is a point of density.
Lemma 17.24 Let x ∈A be a point where U (x)−1 exists. Then if ε ∈(0, 1) the
following hold for all r small enough.
h (B (x, r)) ⊆h (x) + R (x) U (x) B (0, r (1 + ε)),
(17.12)
Hn (h (B (x,r))) ≤mn (U (x) B (0, r (1 + ε))).
(17.13)
R∗(x) h (B (x, r)) ⊇R∗(x) h (x) + U (x) B (0, r (1 −ε)),
(17.14)
Hn (h (B (x,r))) ≥mn (U (x) B (0, r (1 −ε))),
(17.15)
If x is also a point of density of A, then
lim
r→0
Hn (h (B (x, r) ∩A))
Hn (h (B (x, r)))
= 1.
(17.16)

17.2.
THE AREA FORMULA
465
Proof: Since Dh (x) exists,
h (x + v) = h (x) + Dh (x) v+o (|v|).
(17.17)
Consequently, when r is small enough, 17.12 holds.
Using the fact R (x) preserves all distances, and Theorem 17.8 which says Hn =
mn on the Borel sets of Rn implies,
Hn (h (B (x,r))) ≤Hn (R (x) U (x) B (0, r (1 + ε)))
= Hn (U (x) B (0, r (1 + ε))) = mn (U (x) B (0, r (1 + ε)))
which shows 17.13.
From 17.17,
R∗(x) h (x + v) = R∗(x) h (x) + U (x) (v+o (|v|)).
Thus, from the assumption that U (x)−1 exists and letting F (v) be given by
F (v) ≡U (x)−1 R∗(x) h (x + v) −U (x)−1 R∗(x) h (x)
(17.18)
It follows
F (v) −v = o (|v|)
and so Lemma 17.19 implies that for all r small enough,
F (B (0, r))
≡
U (x)−1 R∗(x) h (x+B (0,r)) −U (x)−1 R∗(x) h (x)
⊇
B (0, (1 −ε) r).
Therefore,
R∗(x) h (B (x,r)) ⊇R∗(x) h (x) + U (x) B (0, (1 −ε) r)
which proves 17.14. Therefore,
R (x) R∗(x) h (B (x, r)) ⊇
R (x) R∗(x) h (x) + R (x) U (x) B (0, r (1 −ε)).
From Lemma 17.22, this implies
Hn (h (B (x,r)))
≥
Hn (R∗(x) h (B (x, r)))
=
Hn (R (x) R∗(x) h (B (x, r)))
≥Hn (R (x) U (x) B (0, r (1 −ε)))
= Hn (U (x) B (0, r (1 −ε))) = mn (U (x) B (0, r (1 −ε)))
which shows 17.15.

466
HAUSDORFF MEASURE
Now suppose that x is also a point of density of A. Then whenever r is small
enough,
mn (A ∩B (x, r))
mn (B (x, r))
> 1 −ε.
Consequently, for such r,
1
=
mn (A ∩B (x, r))
mn (B (x, r))
+ mn (B (x,r) \ A)
mn (B (x, r))
>
1 −ε + mn (B (x,r) \ A)
α (n) rn
and so
mn (B (x,r) \ A) < εα (n) rn.
(17.19)
Also,
h (B (x, r) ∩A) ∪h (B (x, r) \ A) = h (B (x, r))
and so
Hn (h (B (x, r) ∩A)) + Hn (h (B (x, r) \ A))
≥
Hn (h (B (x, r)))
Then also letting r also be smaller than Rx mentioned in 17.10, it follows from
Lemmas 17.21, 17.18, and 17.19, 17.14 that
1
≥
Hn (h (B (x, r) ∩A))
Hn (h (B (x, r)))
≥
Hn (h (B (x, r))) −Hn (h (B (x,r) \ A))
Hn (h (B (x, r)))
≥
1 −
Ln
xmn (B (x,r) \ A)
Hn (R∗(x) h (B (x, r)))
≥
1 −
Ln
xmn (B (x,r) \ A)
mn (U (x) B (0, r (1 −ε)))
≥
1 −
Ln
xεα (n) rn
det (U (x)) α (n) rn (1 −ε)n
=
1 −g (ε)
where limε→0 g (ε) = 0. Since ε is arbitrary, this proves 17.16.
The next theorem is the generalization of Lemma 17.14 to nonlinear maps.
Theorem 17.25 Let h : U →Rm where U is an open set in Rn for n ≤m and
suppose h is locally Lipschitz at every point of a Lebesgue measurable subset, A of
U. Also suppose that for every x ∈A, Dh (x) exists. Then for x ∈A,
J (x) = lim
r→0
Hn (h (B (x, r)))
mn (B (x,r))
,
(17.20)
where J (x) ≡det (U (x)) = det
¡
Dh (x)∗Dh (x)
¢1/2.

17.2.
THE AREA FORMULA
467
Proof:
Suppose ﬁrst that U (x)−1 exists. Using 17.15, 17.13 and the change
of variables formula for linear maps,
J (x) (1 −ε)n
=
mn (U (x) B (0,r (1 −ε)))
mn (B (x, r))
≤Hn (h(B (x, r)))
mn (B (x, r))
≤
mn (U (x) B (0,r (1 + ε)))
mn (B (x, r))
= J (x) (1 + ε)n
whenever r is small enough. It follows that since ε > 0 is arbitrary, 17.20 holds.
Now suppose U (x)−1 does not exist. The ﬁrst part shows that the conclusion
of the theorem holds when J (x) ̸= 0. I will apply this to a modiﬁed function. Let
k : Rn →Rm × Rn
be deﬁned as
k (x) ≡
µ h (x)
εx
¶
.
Then
Dk (x)∗Dk (x) = Dh (x)∗Dh (x) + ε2In
and so
Jk (x)2
≡
det
¡
Dh (x)∗Dh (x) + ε2In
¢
=
det
¡
Q∗DQ + ε2In
¢
where D is a diagonal matrix having the nonnegative eigenvalues of Dh (x)∗Dh (x)
down the main diagonal. Thus, since one of these eigenvalues equals 0, letting λ2
i
denote the ith eigenvalue, there exists a constant, C independent of ε such that
0 < Jk (x)2 =
n
Y
i=1
¡
λ2
i + ε2¢
≤C2ε2.
(17.21)
Therefore, what was just shown applies to k.
Let
T ≡
n
(h (w) , 0)T : w ∈B (x,r)
o
,
Tε
≡
n
(h (w) , εw)T : w ∈B (x,r)
o
≡
k (B (x,r)),
then
T = PTε
where P is the projection map deﬁned by
P
µ
x
y
¶
≡
µ
x
0
¶
.

468
HAUSDORFF MEASURE
Since P decreases distances, it follows from Lemma 17.21
Hn (h (B (x,r)))
=
Hn (T) = Hn (PTε)
≤
Hn (Tε) = Hn (k (B (x,r))) .
It follows from 17.21 and the ﬁrst part of the proof applied to k that
Cε
≥
Jk (x) = lim
r→0
Hn (k (B (x, r)))
mn (B (x,r))
≥
lim sup
r→0
Hn (h (B (x, r)))
mn (B (x,r))
.
Since ε is arbitrary, this establishes 17.20 in the case where U (x)−1 does not exist
and completes the proof of the theorem.
Deﬁne the following set for future reference.
S ≡{x ∈A : U (x)−1 does not exist}
(17.22)
17.2.2
The Area Formula
Assume h : A →Rm is one to one in addition to 17.8 - 17.10. Since h is one to one,
Lemma 17.18 implies one can deﬁne a measure, ν, on the σ−algebra of Lebesgue
measurable sets as follows.
ν (E) ≡Hn (h (E ∩A)).
By Lemma 17.18, this is a measure and ν ≪m.
Therefore by the corollary
to the Radon Nikodym theorem, Corollary 15.3 on Page 402, there exists f ∈
L1
loc (Rn) , f ≥0, f (x) = 0 if x /∈A, and
ν (E) =
Z
E
fdm =
Z
A∩E
fdm.
What is f? I will show that f (x) = J (x) = det (U (x)) a.e. Deﬁne
E ≡{x ∈A : x is not a point of density of A} ∪
{x ∈A : x is not a Lebesgue point of f}.
Then E is a set of measure zero and if x ∈(A \ E), Lemma 17.24 and Theorem
17.25 imply
f (x)
=
lim
r→0
1
mn (B (x,r))
Z
B(x,r)
f (y) dm
=
lim
r→0
Hn (h (B (x,r) ∩A))
mn (B (x,r))
=
lim
r→0
Hn (h (B (x,r) ∩A))
Hn (h (B (x,r)))
Hn (h (B (x,r)))
mn (B (x,r))
=
J (x).

17.2.
THE AREA FORMULA
469
Therefore, f (x) = J (x) a.e., whenever x ∈A \ E.
Now let F be a Borel set in Rm. Recall this implies F is Hn measurable. Then
Z
h(A)
XF (y) dHn
=
Z
XF ∩h(A) (y) dHn
=
Hn ¡
h
¡
h−1 (F) ∩A
¢¢
=
ν
¡
h−1 (F)
¢
=
Z
XA∩h−1(F ) (x) J (x) dm
=
Z
A
XF (h (x)) J (x) dm.
(17.23)
Note there are no measurability questions in the above formula because h−1 (F) is
a Borel set due to the continuity of h. The Borel measurability of J (x) also follows
from the observation that h is continuous and therefore, the partial derivatives are
Borel measurable, being the limit of continuous functions.
Then J (x) is just a
continuous function of these partial derivatives. However, things are not so clear
if E is only assumed Hn measurable. Is there a similar formula for F only Hn
measurable?
First consider the case where E is only Hn measurable but
Hn (E ∩h (A)) = 0.
By Theorem 17.5 on Page 452, there exists a Borel set F ⊇E ∩h (A) such that
Hn (F) = Hn (E ∩h (A)) = 0.
Then from 17.23,
XA∩h−1(F ) (x) J (x) = 0 a.e.
But
0 ≤XA∩h−1(E) (x) J (x) ≤XA∩h−1(F ) (x) J (x)
(17.24)
which shows the two functions in 17.24 are equal a.e. Therefore XA∩h−1(E) (x) J (x)
is Lebesgue measurable and so from 17.23,
0 =
Z
XE∩h(A) (y) dHn =
Z
XF ∩h(A) (y) dHn
=
Z
XA∩h−1(F ) (x) J (x) dmn =
Z
XA∩h−1(E) (x) J (x) dmn,
(17.25)
which shows 17.23 holds in this case where
Hn (E ∩h (A)) = 0.
Now let AR ≡A ∩B (0,R) where R is large enough that AR ̸= ∅and let E
be Hn measurable. By Theorem 17.5, there exists F ⊇E ∩h (AR) such that F is
Borel and
Hn (F \ (E ∩h (AR))) = 0.
(17.26)

470
HAUSDORFF MEASURE
Then
(E ∩h (AR)) ∪(F \ (E ∩h (AR)) ∩h (AR)) = F ∩h (AR)
and so
XAR∩h−1(F )J = XAR∩h−1(E)J + XAR∩h−1(F \(E∩h(AR)))J
where from 17.26 and 17.25, the second function on the right of the equal sign is
Lebesgue measurable and equals zero a.e. Therefore, the ﬁrst function on the right
of the equal sign is also Lebesgue measurable and equals the function on the left
a.e. Thus,
Z
XE∩h(AR) (y) dHn =
Z
XF ∩h(AR) (y) dHn
=
Z
XAR∩h−1(F ) (x) J (x) dmn =
Z
XAR∩h−1(E) (x) J (x) dmn.
(17.27)
Letting R →∞yields 17.27 with A replacing AR and the function
x →XAR∩h−1(E) (x) J (x)
is Lebesgue measurable. Writing this in a more familiar form yields
Z
h(A)
XE (y) dHn =
Z
A
XE (h (x)) J (x) dmn.
(17.28)
From this, it follows that if s is a nonnegative Hn measurable simple function, 17.28
continues to be valid with s in place of XE. Then approximating an arbitrary non-
negative Hn measurable function, g, by an increasing sequence of simple functions,
it follows that 17.28 holds with g in place of XE and there are no measurability
problems because x →g (h (x)) J (x) is Lebesgue measurable. This proves the area
formula.
Theorem 17.26 Let g : h (A) →[0, ∞] be Hn measurable where h is a continuous
function and A is a Lebesgue measurable set which satisﬁes 17.8 - 17.10. That is,
U is an open set in Rn on which h is deﬁned and A ⊆U is a Lebesgue measurable
set, m ≥n, and
h : A →Rm is continuous,
(17.29)
Dh (x) exists for all x ∈A,
(17.30)
Also assume that for every x ∈A, there exists Rx and Lx such that for all y, z ∈
B (x, Rx) ,
|h (z) −h (y)| ≤Lx |x −y|
(17.31)
Then
x →(g ◦h) (x) J (x)
is Lebesgue measurable and
Z
h(A)
g (y) dHn =
Z
A
g (h (x)) J (x) dm
where J (x) = det (U (x)) = det
¡
Dh (x)∗Dh (x)
¢1/2.

17.3.
THE AREA FORMULA ALTERNATE VERSION
471
17.3
The Area Formula Alternate Version
17.3.1
Preliminary Results
It was shown in Lemma 17.14 that
Hn(FA) = det(U)mn(A)
where F = RU with R preserving distances and U a symmetric matrix having
all positive eigenvalues.
The area formula gives a generalization of this simple
relationship to the case where F is replaced by a nonlinear mapping, h. It contains
as a special case the earlier change of variables formula. There are two parts to this
development. The ﬁrst part is to generalize Lemma 17.14 to the case of nonlinear
maps. When this is done, the area formula can be presented.
In this section, U will be an open set in Rn on which h is deﬁned and A ⊆U
will be a Lebesgue measurable set. Assume m ≥n and
h : U →Rm is continuous,
(17.32)
Dh (x) exists for all x ∈A,
(17.33)
Hn (h (U \ A)) = 0
(17.34)
These conditions are diﬀerent than the ones considered earlier. Here no Lipschitz
assumption is needed on h. In this sense, these conditions are more general than
those considered earlier. However, they are not really more general because of 17.34
which says that A is essentially an open set. This was not necessary earlier. The area
formula which results from the above conditions is a generalization of the change
of variables formula given in Rudin [45] and the proof is essentially the same as the
proof given in this book with modiﬁcations to account for the Hausdorﬀmeasure.
Lemma 17.27 If T ⊆A and mn (T) = 0, then Hn (h (T)) = 0.
Proof: Let
Tk ≡{x ∈T : ||Dh (x)|| < k} .
Thus T = ∪kTk. I will show h (Tk) has Hn measure zero and then it will follow
that
h (T) = ∪∞
k=1h (Tk)
must also have measure zero.
Let ε > 0 be given. By outer regularity, there exists an open set, V , containing
Tk which is contained in U such that mn (V ) <
ε
kn6n . For x ∈Tk it follows from
diﬀerentiability,
h (x + v) = h (x) + Dh (x) v + o (v)
and so whenever rx is small enough, B (x,5rx) ⊆V and whenever |v| < 5rx, |o (v)| <
krx. Therefore, if |v| < 5rx,
Dh (x) v + o (v) ∈B (0, 5krx) + B (0,krx) ⊆B (0, 6krx)

472
HAUSDORFF MEASURE
and so
h (B (x, 5rx)) ⊆B (h (x) , 6krx).
Letting δ > 0 be given, the Vitali covering theorem implies there exists a sequence
of disjoint balls {Bi}, Bi = B (xi, rxi), which are contained in V such that the
sequence of enlarged balls,
n
bBi
o
, having the same center but 5 times the radius,
covers Tk and 6krxi < δ. Then
Hn
δ (h (Tk)) ≤Hn
δ
³
h
³
∪∞
i=1 bBi
´´
≤
∞
X
i=1
Hn
δ
³
h
³
bBi
´´
≤
∞
X
i=1
Hn
δ (B (h (xi) , 6krxi))
≤
∞
X
i=1
α (n) (6krxi)n = (6k)n
∞
X
i=1
α (n) rn
xi
=
(6k)n
∞
X
i=1
mn (B (xi, rxi))
≤
(6k)n mn (V ) ≤(6k)n
ε
kn6n = ε.
Since ε > 0 is arbitrary, this shows Hn
δ (h (Tk)) = 0. Since δ is arbitrary, this implies
Hn (h (Tk)) = 0. Now
Hn (h (T)) = lim
k→∞Hn (h (Tk)) = 0.
This proves the lemma.
Lemma 17.28 If S is a Lebesgue measurable subset of A, then h (S) is Hn mea-
surable.
Proof: Let Sk = S ∩B (0, k) , k ∈N. By inner regularity of Lebesgue measure,
there exists a set, F, which is the countable union of compact sets and a set T with
mn (T) = 0 such that
F ∪T = Sk.
Then h (F) ⊆h (Sk) ⊆h (F)∪h (T). By continuity of h, h (F) is a countable union
of compact sets and so it is Borel. By Lemma 17.27, Hn (h (T)) = 0 and so h (Sk)
is Hn measurable because of completeness of Hausdorﬀmeasure, which comes from
Hn being obtained from an outer measure. Now h (S) = ∪∞
k=1h (Sk) and so it is
also true that h (S) is Hn measurable. This proves the lemma.
The following lemma, depending on the Brouwer ﬁxed point theorem and found
in Rudin [45], will be important for the following arguments. The idea is that if a
continuous function mapping a ball in Rk to Rk doesn’t move any point very much,
then the image of the ball must contain a slightly smaller ball.

17.3.
THE AREA FORMULA ALTERNATE VERSION
473
Lemma 17.29 Let B = B (0, r), a ball in Rk and let F : B →Rk be continuous
and suppose for some ε < 1,
|F (v) −v| < εr
(17.35)
for all v ∈B. Then
F (B) ⊇B (0, r (1 −ε)) .
Proof: Suppose a ∈B (0, r (1 −ε)) \ F (B) .
I claim that a ̸= F (v) for all v ∈B. Here is why. By assumption, if F (v) = a,
then |v| = r and so
|F (v) −v| = |a −v| ≥|v| −|a| > r −r (1 −ε) = rε,
a contradiction to 17.35.
Now letting G :B →B, be deﬁned by
G (v) ≡r (a −F (v))
|a −F (v)| ,
it follows G is continuous. Then by the Brouwer ﬁxed point theorem, G (v) = v for
some v ∈B. Using the formula for G, it follows |v| = r. Taking the inner product
with v,
(G (v) , v)
=
|v|2 = r2 =
r
|a −F (v)| (a −F (v) , v)
=
r
|a −F (v)| (a −v + v −F (v) , v)
=
r
|a −F (v)| [(a −v, v) + (v −F (v) , v)]
=
r
|a −F (v)|
h
(a, v) −|v|2 + (v −F (v) , v)
i
≤
r
|a −F (v)|
£
r2 (1 −ε) −r2+r2ε
¤
= 0,
a contradiction to |v| = r. Therefore, B (0, r (1 −ε)) \ F (B) = ∅and this proves
the lemma.
By Theorem 4.59 on Page 87, when Dh (x) exists,
Dh (x) = R (x) U (x)
where (U (x) u, v) = (U (x) v, u) , (U (x) u, u) ≥0 and R∗R = I.
Lemma 17.30 In this situation, |R∗u| ≤|u|.
Proof: First note that
(u−RR∗u,RR∗u)
=
(u,RR∗u) −|RR∗u|2
=
|R∗u|2 −|R∗u|2 = 0,

474
HAUSDORFF MEASURE
and so
|u|2
=
|u−RR∗u+RR∗u|2
=
|u−RR∗u|2 + |RR∗u|2
=
|u−RR∗u|2 + |R∗u|2.
This proves the lemma.
Lemma 17.31 If |Px −Py| ≤L |x −y| , then for E a set,
Hn (PE) ≤LnHn (E) .
Proof: Without loss of generality, assume Hn (E) < ∞. Let δ > 0 and let
{Ci}∞
i=1 be a covering of E such that diam (Ci) ≤δ for each i and
∞
X
i=1
α (n) r (Ci)n ≤Hn
δ (E) + ε.
Then {PCi}∞
i=1 is a covering of PE such that diam (PCi) ≤Lδ. Therefore,
Hn
Lδ (PE)
≤
∞
X
i=1
α (n) r (PCi)n
≤
Ln
∞
X
i=1
α (n) r (Ci)n ≤LnHn
δ (E) + Lnε
≤
Hn (E) + ε.
Letting δ →0,
Hn (PE) ≤LnHn (E) + Lnε
and since ε > 0 is arbitrary, this proves the Lemma.
Then the following corollary follows from Lemma 17.30.
Corollary 17.32 Let T ⊆Rm. Then
Hn (T) ≥Hn (RR∗T) = Hn (R∗T).
Deﬁnition 17.33 Let E be a Lebesgue measurable set. x ∈E is a point of density
if
lim
r→0
mn(E ∩B(x, r))
mn(B(x, r))
= 1.
Recall that from the fundamental theorem of calculus applied to XE almost
every point of E is a point of density.

17.3.
THE AREA FORMULA ALTERNATE VERSION
475
Lemma 17.34 Let x ∈A be a point where U (x)−1 exists. Then if ε ∈(0, 1) the
following hold for all r small enough.
h (B (x, r)) ⊆h (x) + R (x) U (x) B (0, r (1 + ε)),
(17.36)
Hn (h (B (x,r))) ≤mn (U (x) B (0, r (1 + ε))).
(17.37)
R∗(x) h (B (x, r)) ⊇R∗(x) h (x) + U (x) B (0, r (1 −ε)),
(17.38)
Hn (h (B (x,r))) ≥mn (U (x) B (0, r (1 −ε))),
(17.39)
If x is a point of A, then
lim
r→0
Hn (h (B (x, r) ∩A))
Hn (h (B (x, r)))
= 1.
(17.40)
Proof: Since Dh (x) exists,
h (x + v) = h (x) + Dh (x) v+o (|v|).
(17.41)
Consequently, when r is small enough, 17.36 holds.
Using the fact R (x) preserves all distances, and Theorem 17.8 which says Hn =
mn on the Borel sets of Rn,this implies,
Hn (h (B (x,r))) ≤Hn (R (x) U (x) B (0, r (1 + ε)))
= Hn (U (x) B (0, r (1 + ε))) = mn (U (x) B (0, r (1 + ε)))
which shows 17.37.
From 17.41,
R∗(x) h (x + v) = R∗(x) h (x) + U (x) (v+o (|v|)).
Thus, from the assumption that U (x)−1 exists and letting F (v) be given by
F (v) ≡U (x)−1 R∗(x) h (x + v) −U (x)−1 R∗(x) h (x)
(17.42)
Since h is continuous near A, it follows
F (v) −v = o (|v|)
and so Lemma 17.29 implies that for all r small enough,
F (B (0, r))
≡
U (x)−1 R∗(x) h (x+B (0,r)) −U (x)−1 R∗(x) h (x)
⊇
B (0, (1 −ε) r).
Therefore,
R∗(x) h (B (x,r)) ⊇R∗(x) h (x) + U (x) B (0, (1 −ε) r)

476
HAUSDORFF MEASURE
which proves 17.38. Therefore,
R (x) R∗(x) h (B (x, r)) ⊇
R (x) R∗(x) h (x) + R (x) U (x) B (0, r (1 −ε)).
From Lemma 17.32, this implies
Hn (h (B (x,r)))
≥
Hn (R∗(x) h (B (x, r)))
=
Hn (R (x) R∗(x) h (B (x, r)))
≥Hn (R (x) U (x) B (0, r (1 −ε)))
= Hn (U (x) B (0, r (1 −ε))) = mn (U (x) B (0, r (1 −ε)))
which shows 17.39.
Let x ∈A. Choosing r small enough that B (x, r) ⊆U,
h (B (x, r) ∩A) ∪h (B (x, r) \ A) = h (B (x, r))
and so
Hn (h (B (x, r) ∩A)) + Hn (h (B (x, r) \ A))
≥
Hn (h (B (x, r)))
Now by assumption 17.34, Hn (h (B (x, r) \ A)) = 0 and so for all r small enough,
Hn (h (B (x, r) ∩A)) = Hn (h (B (x, r))) .
This establishes 17.40.
The next theorem is the generalization of Lemma 17.14 to nonlinear maps.
Theorem 17.35 Let h : U →Rm where U is an open set in Rn, n ≤m, h is
continuous on U, h is diﬀerentiable on A ⊆U, and Hn (U \ A) = 0. Then for
x ∈A,
J (x) = lim
r→0
Hn (h (B (x, r)))
mn (B (x,r))
,
(17.43)
where J (x) ≡det (U (x)) = det
¡
Dh (x)∗Dh (x)
¢1/2.
Proof:
Suppose ﬁrst that U (x)−1 exists. Using 17.39, 17.37 and the change
of variables formula for linear maps,
J (x) (1 −ε)n
=
mn (U (x) B (0,r (1 −ε)))
mn (B (x, r))
≤Hn (h(B (x, r)))
mn (B (x, r))
≤
mn (U (x) B (0,r (1 + ε)))
mn (B (x, r))
= J (x) (1 + ε)n

17.3.
THE AREA FORMULA ALTERNATE VERSION
477
whenever r is small enough. It follows that since ε > 0 is arbitrary, 17.43 holds.
Now suppose U (x)−1 does not exist. The ﬁrst part shows that the conclusion
of the theorem holds when J (x) ̸= 0. I will apply this to a modiﬁed function. Let
k : Rn →Rm × Rn
be deﬁned as
k (x) ≡
µ
h (x)
εx
¶
.
Then
Dk (x)∗Dk (x) = Dh (x)∗Dh (x) + ε2In
and so
Jk (x)2
≡
det
¡
Dh (x)∗Dh (x) + ε2In
¢
=
det
¡
Q∗DQ + ε2In
¢
where D is a diagonal matrix having the nonnegative eigenvalues of Dh (x)∗Dh (x)
down the main diagonal. Thus, since one of these eigenvalues equals 0, letting λ2
i
denote the ith eigenvalue, there exists a constant, C independent of ε such that
0 < Jk (x)2 =
n
Y
i=1
¡
λ2
i + ε2¢
≤C2ε2.
(17.44)
Therefore, what was just shown applies to k.
Let
T ≡
n
(h (w) , 0)T : w ∈B (x,r)
o
,
Tε
≡
n
(h (w) , εw)T : w ∈B (x,r)
o
≡
k (B (x,r)),
then
T = PTε
where P is the projection map deﬁned by
P
µ
x
y
¶
≡
µ
x
0
¶
.
Since P decreases distances, it follows from Lemma 17.31
Hn (h (B (x,r)))
=
Hn (T) = Hn (PTε)
≤
Hn (Tε) = Hn (k (B (x,r))) .

478
HAUSDORFF MEASURE
It follows from 17.44 and the ﬁrst part of the proof applied to k that
Cε
≥
Jk (x) = lim
r→0
Hn (k (B (x, r)))
mn (B (x,r))
≥
lim sup
r→0
Hn (h (B (x, r)))
mn (B (x,r))
.
Since ε is arbitrary, this establishes 17.43 in the case where U (x)−1 does not exist
and completes the proof of the theorem.
17.3.2
The Area Formula
Assume h : A →Rm is one to one in addition to 17.32 - 17.34. Since h is one to
one on A, Lemma 17.28 implies one can deﬁne a measure, ν, on the σ−algebra of
Lebesgue measurable sets as follows.
ν (E) ≡Hn (h (E ∩A)).
By Lemma 17.28, this is a measure and ν ≪m.
Therefore by the corollary
to the Radon Nikodym theorem, Corollary 15.3 on Page 402, there exists f ∈
L1
loc (Rn) , f ≥0, f (x) = 0 if x /∈A, and
ν (E) =
Z
E
fdmn =
Z
A∩E
fdmn.
What is f? I will show that f (x) = J (x) = det (U (x)) a.e. Let x be a Lebesgue
point of f. Then by Lemma 17.34 and Theorem 17.35
f (x)
=
lim
r→0
1
mn (B (x,r))
Z
B(x,r)
f (y) dm
=
lim
r→0
Hn (h (B (x,r) ∩A))
mn (B (x,r))
=
lim
r→0
Hn (h (B (x,r) ∩A))
Hn (h (B (x,r)))
Hn (h (B (x,r)))
mn (B (x,r))
=
J (x).
Therefore, f (x) = J (x) a.e., whenever x is a Lebesgue point of f.
Now let F be a Borel set in Rm. Recall this implies F is Hn measurable. Then
Z
h(A)
XF (y) dHn
=
Z
XF ∩h(A) (y) dHn
=
Hn ¡
h
¡
h−1 (F) ∩A
¢¢
=
ν
¡
h−1 (F)
¢
=
Z
XA∩h−1(F ) (x) J (x) dmn
=
Z
A
XF (h (x)) J (x) dmn.
(17.45)

17.3.
THE AREA FORMULA ALTERNATE VERSION
479
Note there are no measurability questions in the above formula because h−1 (F) is
a Borel set due to the continuity of h. The Borel measurability of J (x) also follows
from the observation that h is continuous and therefore, the partial derivatives are
Borel measurable, being the limit of continuous functions.
Then J (x) is just a
continuous function of these partial derivatives. However, things are not so clear
if E is only assumed Hn measurable. Is there a similar formula for F only Hn
measurable?
First consider the case where E is only Hn measurable but
Hn (E ∩h (A)) = 0.
By Theorem 17.5 on Page 452, there exists a Borel set F ⊇E ∩h (A) such that
Hn (F) = Hn (E ∩h (A)) = 0.
Then from 17.45,
XA∩h−1(F ) (x) J (x) = 0 a.e.
But
0 ≤XA∩h−1(E) (x) J (x) ≤XA∩h−1(F ) (x) J (x)
(17.46)
which shows the two functions in 17.46 are equal a.e. Therefore XA∩h−1(E) (x) J (x)
is Lebesgue measurable and so from 17.45,
0 =
Z
XE∩h(A) (y) dHn =
Z
XF ∩h(A) (y) dHn
=
Z
XA∩h−1(F ) (x) J (x) dmn =
Z
XA∩h−1(E) (x) J (x) dmn,
(17.47)
which shows 17.45 holds in this case where
Hn (E ∩h (A)) = 0.
Now let AR ≡A ∩B (0,R) where R is large enough that AR ̸= ∅and let E
be Hn measurable. By Theorem 17.5, there exists F ⊇E ∩h (AR) such that F is
Borel and
Hn (F \ (E ∩h (AR))) = 0.
(17.48)
Then
(E ∩h (AR)) ∪(F \ (E ∩h (AR)) ∩h (AR)) = F ∩h (AR)
and so
XAR∩h−1(F )J = XAR∩h−1(E)J + XAR∩h−1(F \(E∩h(AR)))J
where from 17.48 and 17.47, the second function on the right of the equal sign is
Lebesgue measurable and equals zero a.e. Therefore, the ﬁrst function on the right
of the equal sign is also Lebesgue measurable and equals the function on the left
a.e. Thus,
Z
XE∩h(AR) (y) dHn =
Z
XF ∩h(AR) (y) dHn

480
HAUSDORFF MEASURE
=
Z
XAR∩h−1(F ) (x) J (x) dmn =
Z
XAR∩h−1(E) (x) J (x) dmn.
(17.49)
Letting R →∞yields 17.49 with A replacing AR and the function
x →XAR∩h−1(E) (x) J (x)
is Lebesgue measurable. Writing this in a more familiar form yields
Z
h(A)
XE (y) dHn =
Z
A
XE (h (x)) J (x) dmn.
(17.50)
From this, it follows that if s is a nonnegative Hn measurable simple function, 17.50
continues to be valid with s in place of XE. Then approximating an arbitrary non-
negative Hn measurable function, g, by an increasing sequence of simple functions,
it follows that 17.50 holds with g in place of XE and there are no measurability
problems because x →g (h (x)) J (x) is Lebesgue measurable. This proves the area
formula.
Theorem 17.36 Let g : h (A) →[0, ∞] be Hn measurable where h is a continuous
function and A is a Lebesgue measurable set which satisﬁes 17.32 - 17.34. That
is, U is an open set in Rn on which h is deﬁned and continuous and A ⊆U is a
Lebesgue measurable set, m ≥n, and
h : U →Rm is continuous, h one to one on A,
(17.51)
Dh (x) exists for all x ∈A,
(17.52)
Hn (U \ A) = 0,
(17.53)
Then
x →(g ◦h) (x) J (x)
is Lebesgue measurable and
Z
h(A)
g (y) dHn =
Z
A
g (h (x)) J (x) dm
where J (x) = det (U (x)) = det
¡
Dh (x)∗Dh (x)
¢1/2.
17.4
The Divergence Theorem
As an important application of the area formula I will give a general version of the
divergence theorem. It will always be assumed n ≥2. Actually it is not necessary to
make this assumption but what results in the case where n = 1 is nothing more than
the fundamental theorem of calculus and the considerations necessary to draw this
conclusion seem unneccessarily tedious. You have to consider H0, zero dimensional
Hausdorﬀmeasure. It is left as an exercise but I will not present it.
It will be convenient to have some lemmas and theorems in hand before beginning
the proof. First recall the Tietze extension theorem on Page 146. It is stated next
for convenience.

17.4.
THE DIVERGENCE THEOREM
481
Theorem 17.37 Let M be a closed nonempty subset of a metric space (X, d) and
let f : M →[a, b] be continuous at every point of M. Then there exists a function,
g continuous on all of X which coincides with f on M such that g (X) ⊆[a, b] .
The next topic needed is the concept of an inﬁnitely diﬀerentiable partition of
unity.
Deﬁnition 17.38 Let C be a set whose elements are subsets of Rn.1 Then C is
said to be locally ﬁnite if for every x ∈Rn, there exists an open set, Ux containing
x such that Ux has nonempty intersection with only ﬁnitely many sets of C.
Lemma 17.39 Let C be a set whose elements are open subsets of Rn and suppose
∪C ⊇H, a closed set. Then there exists a countable list of open sets, {Ui}∞
i=1 such
that each Ui is bounded, each Ui is a subset of some set of C, and ∪∞
i=1Ui ⊇H.
Proof: Let Wk ≡B (0, k) , W0 = W−1 = ∅. For each x ∈H ∩Wk there exists
an open set, Ux such that Ux is a subset of some set of C and Ux ⊆Wk+1 \ Wk−1.
Then since H ∩Wk is compact, there exist ﬁnitely many of these sets,
©
U k
i
ªm(k)
i=1
whose union contains H ∩Wk. If H ∩Wk = ∅, let m (k) = 0 and there are no such
sets obtained.The desired countable list of open sets is ∪∞
k=1
©
U k
i
ªm(k)
i=1 . Each open
set in this list is bounded. Furthermore, if x ∈Rn, then x ∈Wk where k is the
ﬁrst positive integer with x ∈Wk. Then Wk \Wk−1 is an open set containing x and
this open set can have nonempty intersection only with with a set of
©
U k
i
ªm(k)
i=1 ∪
©
U k−1
i
ªm(k−1)
i=1
, a ﬁnite list of sets. Therefore, ∪∞
k=1
©
U k
i
ªm(k)
i=1
is locally ﬁnite.
The set, {Ui}∞
i=1 is said to be a locally ﬁnite cover of H. The following lemma
gives some important reasons why a locally ﬁnite list of sets is so signiﬁcant. First
of all consider the rational numbers, {ri}∞
i=1 each rational number is a closed set.
Q = {ri}∞
i=1 = ∪∞
i=1{ri} ̸= ∪∞
i=1 {ri} = R
The set of rational numbers is deﬁnitely not locally ﬁnite.
Lemma 17.40 Let C be locally ﬁnite. Then
∪C = ∪
©
H : H ∈C
ª
.
Next suppose the elements of C are open sets and that for each U ∈C, there exists a
diﬀerentiable function, ψU having spt (ψU) ⊆U. Then you can deﬁne the following
ﬁnite sum for each x ∈Rn
f (x) ≡
X
{ψU (x) : x ∈U ∈C} .
Furthermore, f is also a diﬀerentiable function2 and
Df (x) =
X
{DψU (x) : x ∈U ∈C} .
1The deﬁnition applies with no change to a general topological space in place of Rn.
2If each ψU were only continuous, one could conclude f is continuous. Here the main interest
is diﬀerentiable.

482
HAUSDORFF MEASURE
Proof: Let p be a limit point of ∪C and let W be an open set which intersects
only ﬁnitely many sets of C. Then p must be a limit point of one of these sets. It
follows p ∈∪
©
H : H ∈C
ª
and so ∪C ⊆∪
©
H : H ∈C
ª
. The inclusion in the other
direction is obvious.
Now consider the second assertion. Letting x ∈Rn, there exists an open set, W
intersecting only ﬁnitely many open sets of C, U1, U2, · · ·, Um. Then for all y ∈W,
f (y) =
m
X
i=1
ψUi (y)
and so the desired result is obvious. It merely says that a ﬁnite sum of diﬀerentiable
functions is diﬀerentiable. Recall the following deﬁnition.
Deﬁnition 17.41 Let K be a closed subset of an open set, U. K ≺f ≺U if f is
continuous, has values in [0, 1] , equals 1 on K, and has compact support contained
in U.
Lemma 17.42 Let U be a bounded open set and let K be a closed subset of U. Then
there exist an open set, W, such that W ⊆W ⊆U and a function, f ∈C∞
c (U)
such that K ≺f ≺U.
Proof: The set, K is compact so is at a positive distance from U C. Let
W ≡
©
x : dist (x, K) < 3−1 dist
¡
K, U C¢ª
.
Also let
W1 ≡
©
x : dist (x, K) < 2−1 dist
¡
K, U C¢ª
Then it is clear
K ⊆W ⊆W ⊆W1 ⊆W1 ⊆U
Now consider the function,
h (x) ≡
dist
¡
x, W C
1
¢
dist
¡
x, W C
1
¢
+ dist
¡
x, W
¢
Since W is compact it is at a positive distance from W C
1 and so h is a well deﬁned
continuous function which has compact support contained in W 1, equals 1 on W,
and has values in [0, 1] . Now let φk be a molliﬁer. Letting
k−1 < min
¡
dist
¡
K, W C¢
, 2−1 dist
¡
W 1, U C¢¢
,
it follows that for such k,the function, h ∗φk ∈C∞
c (U) , has values in [0, 1] , and
equals 1 on K. Let f = h ∗φk.
The above lemma is used repeatedly in the following.

17.4.
THE DIVERGENCE THEOREM
483
Lemma 17.43 Let K be a closed set and let {Vi}∞
i=1 be a locally ﬁnite list of
bounded open sets whose union contains K.
Then there exist functions, ψi ∈
C∞
c (Vi) such that for all x ∈K,
1 =
∞
X
i=1
ψi (x)
and the function f (x) given by
f (x) =
∞
X
i=1
ψi (x)
is in C∞(Rn) .
Proof: Let K1 = K \ ∪∞
i=2Vi. Thus K1 is compact because K1 ⊆V1. Let
K1 ⊆W1 ⊆W 1 ⊆V1
Thus W1, V2, ···, Vn covers K and W 1 ⊆V1. Suppose W1, ···, Wr have been deﬁned
such that Wi ⊆Vi for each i, and W1, · · ·, Wr, Vr+1, · · ·, Vn covers K. Then let
Kr+1 ≡K \ (
¡
∪∞
i=r+2Vi
¢
∪
¡
∪r
j=1Wj
¢
).
It follows Kr+1 is compact because Kr+1 ⊆Vr+1. Let Wr+1 satisfy
Kr+1 ⊆Wr+1 ⊆W r+1 ⊆Vr+1
Continuing this way deﬁnes a sequence of open sets, {Wi}∞
i=1 with the property
Wi ⊆Vi, K ⊆∪∞
i=1Wi.
Note {Wi}∞
i=1 is locally ﬁnite because the original list, {Vi}∞
i=1 was locally ﬁnite.
Now let Ui be open sets which satisfy
W i ⊆Ui ⊆U i ⊆Vi.
Similarly, {Ui}∞
i=1 is locally ﬁnite.
Wi
Ui
Vi
Since the set, {Wi}∞
i=1 is locally ﬁnite, it follows ∪∞
i=1Wi = ∪∞
i=1Wi and so it
is possible to deﬁne φi and γ, inﬁnitely diﬀerentiable functions having compact
support such that
U i ≺φi ≺Vi, ∪∞
i=1W i ≺γ ≺∪∞
i=1Ui.

484
HAUSDORFF MEASURE
Now deﬁne
ψi(x) =
½ γ(x)φi(x)/ P∞
j=1 φj(x) if P∞
j=1 φj(x) ̸= 0,
0 if P∞
j=1 φj(x) = 0.
If x is such that P∞
j=1 φj(x) = 0, then x /∈∪∞
i=1Ui because φi equals one on Ui.
Consequently γ (y) = 0 for all y near x thanks to the fact that ∪∞
i=1Ui is closed
and so ψi(y) = 0 for all y near x. Hence ψi is inﬁnitely diﬀerentiable at such x. If
P∞
j=1 φj(x) ̸= 0, this situation persists near x because each φj is continuous and so
ψi is inﬁnitely diﬀerentiable at such points also thanks to Lemma 17.40. Therefore
ψi is inﬁnitely diﬀerentiable. If x ∈K, then γ (x) = 1 and so P∞
j=1 ψj(x) = 1.
Clearly 0 ≤ψi (x) ≤1 and spt(ψj) ⊆Vj. This proves the theorem.
The functions, {ψi} are called a C∞partition of unity.
The method of proof of this lemma easily implies the following useful corollary.
Corollary 17.44 If H is a compact subset of Vi for some Vi there exists a partition
of unity such that ψi (x) = 1 for all x ∈H in addition to the conclusion of Lemma
39.6.
Proof: Keep Vi the same but replace Vj with f
Vj ≡Vj \ H. Now in the proof
above, applied to this modiﬁed collection of open sets, if j ̸= i, φj (x) = 0 whenever
x ∈H. Therefore, ψi (x) = 1 on H.
Lemma 17.45 Let Ωbe a metric space with the closed balls compact and suppose
µ is a measure deﬁned on the Borel sets of Ωwhich is ﬁnite on compact sets.
Then there exists a unique Radon measure, µ which equals µ on the Borel sets. In
particular µ must be both inner and outer regular on all Borel sets.
Proof: Deﬁne a positive linear functional, Λ (f) =
R
fdµ. Let µ be the Radon
measure which comes from the Riesz representation theorem for positive linear
functionals. Thus for all f continuous,
Z
fdµ =
Z
fdµ.
If V is an open set, let {fn} be a sequence of continuous functions which is increasing
and converges to XV pointwise. Then applying the monotone convergence theorem,
Z
XV dµ = µ (V ) =
Z
XV dµ = µ (V )
and so the two measures coincide on all open sets. Every compact set is a countable
intersection of open sets and so the two measures coincide on all compact sets. Now
let B (a, n) be a ball of radius n and let E be a Borel set contained in this ball.
Then by regularity of µ there exist sets F, G such that G is a countable intersection
of open sets and F is a countable union of compact sets such that F ⊆E ⊆G and
µ (G \ F) = 0. Now µ (G) = µ (G) and µ (F) = µ (F) . Thus
µ (G \ F) + µ (F)
=
µ (G)
=
µ (G) = µ (G \ F) + µ (F)

17.4.
THE DIVERGENCE THEOREM
485
and so µ (G \ F) = µ (G \ F) . Thus
µ (E) = µ (F) = µ (F) = µ (G) = µ (E) .
If E is an arbitrary Borel set, then
µ (E ∩B (a, n)) = µ (E ∩B (a, n))
and letting n →∞, this yields µ (E) = µ (E) .
One more lemma will be useful.
Lemma 17.46 Let V be a bounded open set and let X be the closed subspace of
C
¡
V
¢
, the space of continuous functions deﬁned on V , which is given by the fol-
lowing.
X = {u ∈C
¡
V
¢
: u (x) = 0 on ∂V }.
Then C∞
c (V ) is dense in X with respect to the norm given by
||u|| = max
©
|u (x)| : x ∈V
ª
Proof: Let O ⊆O ⊆W ⊆W ⊆V be such that dist
¡
O, V C¢
< η and let
ψδ (·) be a molliﬁer. Let u ∈X and consider XW u ∗ψδ. Let ε > 0 be given and
let η be small enough that |u (x) | < ε/2 whenever x ∈V \ O. Then if δ is small
enough |XW u ∗ψδ (x) −u (x) | < ε for all x ∈O and XW u ∗ψδ is in C∞
c (V ). For
x ∈V \ O, |XW u ∗ψδ (x) | ≤ε/2 and so for such x,
|XW u ∗ψδ (x) −u (x) | ≤ε.
This proves the lemma since ε was arbitrary.
Deﬁnition 17.47 A bounded open set, U ⊆Rn is said to have a Lipschitz boundary
and to lie on one side of its boundary if the following conditions hold. There exist
open boxes, Q1, · · ·, QN ,
Qi =
n
Y
j=1
¡
ai
j, bi
j
¢
such that ∂U ≡U \ U is contained in their union. Also, for each Qi, there exists k
and a Lipschitz function, gi such that U ∩Qi is of the form


x : (x1, · · ·, xk−1, xk+1, · · ·, xn) ∈
k−1
Y
j=1
¡
ai
j, bi
j
¢
×
n
Y
j=k+1
¡
ai
j, bi
j
¢
and ai
k < xk < gi (x1, · · ·, xk−1, xk+1, · · ·, xn)


(17.54)

486
HAUSDORFF MEASURE
or else of the form


x : (x1, · · ·, xk−1, xk+1, · · ·, xn) ∈
k−1
Y
j=1
¡
ai
j, bi
j
¢
×
n
Y
j=k+1
¡
ai
j, bi
j
¢
and gi (x1, · · ·, xk−1, xk+1, · · ·, xn) < xk < bi
j


. (17.55)
The function, gi has a derivative on Ai ⊆Qk−1
j=1
¡
ai
j, bi
j
¢
× Qn
j=k+1
¡
ai
j, bi
j
¢
where
mn−1


k−1
Y
j=1
¡
ai
j, bi
j
¢
×
n
Y
j=k+1
¡
ai
j, bi
j
¢
\ Ai

= 0.
Also, there exists an open set, Q0 such that Q0 ⊆Q0 ⊆U and U ⊆Q0∪Q1∪···∪QN.
Note that since there are only ﬁnitely many Qi and each gi is Lipschitz, it follows
from an application of Lemma 17.21 that Hn−1 (∂U) < ∞. Also from Lemma 17.45
Hn−1 is inner and outer regular on ∂U.
Lemma 17.48 Suppose U is a bounded open set as described above. Then there
exists a unique function in L∞¡
∂U, Hn−1¢n , n (y) for y ∈∂U such that |n (y)| =
1, n is Hn−1 measurable, (meaning each component of n is Hn−1 measurable) and
for every w ∈Rn satisfying |w| = 1, and for every f ∈C1
c (Rn) ,
lim
t→0
Z
U
f (x + tw) −f (x)
t
dx =
Z
∂U
f (n · w) dHn−1
Proof: Let U ⊆V ⊆V ⊆∪N
i=0Qi and let {ψi}N
i=0 be a C∞partition of unity
on V such that spt (ψi) ⊆Qi. Then for all t small enough and x ∈U,
f (x + tw) −f (x)
t
= 1
t
N
X
i=0
ψif (x + tw) −ψif (x) .
Thus using the dominated convergence theorem,
lim
t→0
Z
U
f (x + tw) −f (x)
t
dx
=
lim
t→0
Z
U
Ã
1
t
N
X
i=0
ψif (x + tw) −ψif (x)
!
dx
=
Z
U
N
X
i=0
n
X
j=1
Dj (ψif (x)) wjdx

17.4.
THE DIVERGENCE THEOREM
487
=
Z
U
n
X
j=1
Dj (ψ0f (x)) wjdx +
N
X
i=1
Z
U
n
X
j=1
Dj (ψif (x)) wjdx
(17.56)
Since spt (ψ0) ⊆Q0, it follows the ﬁrst term in the above equals zero. In the second
term, ﬁx i. Without loss of generality, suppose the k in the above deﬁnition equals
n and 17.54 holds. This just makes things a little easier to write. Thus gi is a
function of
(x1, · · ·, xn−1) ∈
n−1
Y
j=1
¡
ai
j, bi
j
¢
≡Bi
Then
Z
U
n
X
j=1
Dj (ψif (x)) wjdx
=
Z
Bi
Z gi(x1,···,xn−1)
ain
n
X
j=1
Dj (ψif (x)) wjdxndx1 · · · dxn−1
=
Z
Bi
Z gi(x1,···,xn−1)
−∞
n
X
j=1
Dj (ψif (x)) wjdxndx1 · · · dxn−1
Letting xn = y + gi (x1, · · ·, xn−1) and changing the variable, this equals
=
Z
Bi
Z 0
−∞
n
X
j=1
Dj (ψif (x1, · · ·, xn−1, y + gi (x1, · · ·, xn−1))) ·
wjdydx1 · · · dxn−1
=
Z
Ai
Z 0
−∞
n
X
j=1
Dj (ψif (x1, · · ·, xn−1, y + gi (x1, · · ·, xn−1))) ·
wjdydx1 · · · dxn−1
=
Z
Ai
Z 0
−∞
n−1
X
j=1
∂
∂xj
(ψif (x1, · · ·, xn−1, y + gi (x1, · · ·, xn−1))) wj −
Dn (ψif) (x1, · · ·, xn−1, y + gi (x1, · · ·, xn−1)) ·
gi,j (x1, · · ·, xn−1) wjdydx1 · · · dxn−1
+
Z
Ai
Z 0
−∞
Dn (ψif (x1, · · ·, xn−1, y + gi (x1, · · ·, xn−1))) ·
(17.57)
wndydx1 · · · dxn−1
Consider the term
Z
Ai
Z 0
−∞
n−1
X
j=1
∂
∂xj
(ψif (x1, · · ·, xn−1, y + gi (x1, · · ·, xn−1))) ·
wjdydx1 · · · dxn−1.

488
HAUSDORFF MEASURE
This equals
Z
Bi
Z 0
−∞
n−1
X
j=1
∂
∂xj
(ψif (x1, · · ·, xn−1, y + gi (x1, · · ·, xn−1))) ·
wjdydx1 · · · dxn−1,
and now interchanging the order of integration and using the fact that spt (ψi) ⊆Qi,
it follows this term equals zero. (The reason this is valid is that
xj →ψif (x1, · · ·, xn−1, y + gi (x1, · · ·, xn−1))
is the composition of Lipschitz functions and is therefore Lipschitz. Therefore, this
function is absolutely continuous and can be recovered by integrating its derivative.)
Then, changing the variable back to xn it follows 17.57 reduces to
=
Z
Ai
Z gi(x1,···,xn−1)
−∞
−Dn (ψif) (x1, · · ·, xn−1, xn) ·
gi,j (x1, · · ·, xn−1) wjdxndx1 · · · dxn−1
(17.58)
+
Z
Ai
Z gi(x1,···,xn−1)
−∞
Dn (ψif (x1, · · ·, xn−1, xn)) wndxndx1 · · · dxn−1
(17.59)
Doing the integrals, this reduces further to
Z
Ai
(ψif) (x1, · · ·, xn−1, xn) Ni (x1, · · ·, xn−1, gi (x1, · · ·, xn−1)) · wdmn−1 (17.60)
where Ni (x1, · · ·, xn−1, gi (x1, · · ·, xn−1)) is given by
(−gi,1 (x1, · · ·, xn−1) , −gi,2 (x1, · · ·, xn−1) , · · ·, −gi,n−1 (x1, · · ·, xn−1) , 1) . (17.61)
At this point I need a technical lemma which will allow the use of the area formula.
The part of the boundary of U which is contained in Qi is the image of the map,
hi (x1, · · ·, xn−1) given by (x1, · · ·, xn−1, gi (x1, · · ·, xn−1)) for (x1, · · ·, xn−1) ∈Ai.
I need a formula for
det
¡
Dhi (x1, · · ·, xn−1)∗Dhi (x1, · · ·, xn−1)
¢1/2 .
To avoid interupting the argument, I will state the lemma here and prove it later.
Lemma 17.49
det
¡
Dhi (x1, · · ·, xn−1)∗Dhi (x1, · · ·, xn−1)
¢1/2
=
v
u
u
t1 +
n−1
X
j−1
gi,j (x1, · · ·, xn−1)2 ≡Ji (x1, · · ·, xn−1) .

17.4.
THE DIVERGENCE THEOREM
489
For
y = (x1, · · ·, xn−1, gi (x1, · · ·, xn−1)) ∈∂U ∩Qi
deﬁne It follows if n is deﬁned by
ni (y) =
1
Ji (x1, · · ·, xn−1)Ni (y)
it follows from the description of Ji (x1, · · ·, xn−1) given in the above lemma, that
ni is a unit vector. All components of ni are continuous functions of limits of con-
tinuous functions. Therefore, ni is Borel measurable and so it is Hn−1 measurable.
Now 17.60 reduces to
Z
Ai
(ψif) (x1, · · ·, xn−1, gi (x1, · · ·, xn−1)) ×
ni (x1, · · ·, xn−1, gi (x1, · · ·, xn−1)) · wJi (x1, · · ·, xn−1) dmn−1.
By the area formula this equals
Z
h(Ai)
ψif (y) ni (y) · wdHn−1.
Now by Lemma 17.21 and the equality of mn−1 and Hn−1 on Rn−1, the above
integral equals
Z
∂U∩Qi
ψif (y) ni (y) · wdHn−1 =
Z
∂U
ψif (y) ni (y) · wdHn−1.
Returning to 17.56 similar arguments apply to the other terms and therefore,
lim
t→0
Z
U
f (x + tw) −f (x)
t
dmn
=
N
X
i=1
Z
∂U
ψif (y) ni (y) · wdHn−1
=
Z
∂U
f (y)
N
X
i=1
ψi (y) ni (y) · wdHn−1
=
Z
∂U
f (y) n (y) · wdHn−1
(17.62)
Then let n (y) ≡PN
i=1 ψi (y) ni (y) .
I need to show ﬁrst there is no other n which satisﬁes 17.62 and then I need
to show that |n (y)| = 1. Note that it is clear |n (y)| ≤1 because each ni is a
unit vector and this is just a convex combination of these.
Suppose then that
n1 ∈L∞¡
∂U, Hn−1¢
also works in 17.62. Then for all f ∈C1
c (Rn) ,
Z
∂U
f (y) n (y) · wdHn−1 =
Z
∂U
f (y) n1 (y) · wdHn−1.

490
HAUSDORFF MEASURE
Suppose h ∈C (∂U) . Then by the Tietze extension theorem, there exists f ∈
Cc (Rn) such that the restriction of f to ∂U equals h. Now by Lemma 17.46 applied
to a bounded open set containing the support of f, there exists a sequence {fm} of
functions in C1
c (Rn) converging uniformly to f. Therefore,
Z
∂U
h (y) n (y) · wdHn−1
=
lim
m→∞
Z
∂U
fm (y) n (y) · wdHn−1
=
lim
m→∞
Z
∂U
fm (y) ni (y) · wdHn−1
=
Z
∂U
h (y) ni (y) · wdHn−1.
Now Hn−1 is a Radon measure on ∂U and so the continuous functions on ∂U
are dense in L1 ¡
∂U, Hn−1¢
. It follows n · w = ni · w a.e.
Now let {wm}∞
m=1
be a countable dense subset of the unit sphere.
From what was just shown,
n · wm= ni · wm except for a set of measure zero, Nm. Letting N = ∪mNm, it
follows that for y /∈N, n (y) ·wm= ni (y) · wm for all m. Since the set is dense, it
follows n (y) ·w = ni (y) · w for all y /∈N and for all w a unit vector. Therefore,
n (y) = ni (y) for all y /∈N and this shows n is unique. In particular, although it
appears to depend on the partition of unity {ψi} from its deﬁnition, this is not the
case.
It only remains to verify |n (y)| = 1 a.e. I will do this by showing how to compute
n. In particular, I will show that n = ni a.e. on ∂U ∩Qi. Let W ⊆W ⊆Qi ∩∂U
where W is open in ∂U. Let O be an open set such that O ∩∂U = W and O ⊆Qi.
Using Corollary 17.44 there exists a C∞partition of unity {ψm} such that ψi = 1
on O. Therefore, if m ̸= i, ψm = 0 on O. Then if f ∈C1
c (O) ,
Z
W
fw · ndHn−1
=
Z
∂U
fw · ndHn−1 =
Z
U
∇f · wdmn
=
Z
U
∇(ψif) · wdmn
which by the ﬁrst part of the argument given above equals
Z
W
ψifni · wdHn−1 =
Z
W
fw · nidHn−1.
Thus for all f ∈C1
c (O) ,
Z
W
fw · ndHn−1 =
Z
W
fw · nidHn−1
(17.63)

17.4.
THE DIVERGENCE THEOREM
491
Since C1
c (O) is dense in Cc (O) , the above equation is also true for all f ∈Cc (O).
Now letting h ∈Cc (W) , the Tietze extension theorem implies there exists f1 ∈
C
¡
O
¢
whose restriction to W equals h. Let f be deﬁned by
f1 (x)
dist
¡
x, OC¢
dist (x, spt (h)) + dist (x, OC) = f (x) .
Then f = h on W and so this has shown that for all h ∈Cc (W) , 17.63 holds
for h in place of f. But as observed earlier, Hn−1 is outer and inner regular on
∂U and so Cc (W) is dense in L1 ¡
W, Hn−1¢
which implies w · n (y) = w · ni (y)
for a.e. y. Considering a countable dense subset of the unit sphere as above, this
implies n (y) = ni (y) a.e. y. This proves |n (y)| = 1 a.e. and in fact n (y) can be
computed by using the formula for ni (y). This proves the lemma.
It remains to prove Lemma 17.49.
Proof of Lemma 17.49: Let h (x) = (x1, · · ·, xn−1, g (x1, · · ·, xn−1))T
Dh (x) =





1
0
...
...
...
0
1
g,x1
· · ·
g,xn−1





Therefore,
J (x) =
¡
det
¡
Dh (x)∗Dh (x)
¢¢1/2.
Therefore, J (x) is the square root of the determinant of the following n×n matrix.





1 + (g,x1)2
g,x1g,x2
· · ·
g,x1g,xn−1
g,x2g,x1
1 + (g,x2)2
· · ·
g,x2g,xn−1
...
...
...
g,xn−1g,x1
g,xn−1g,x2
· · ·
1 + (g,xn−1)2




.
(17.64)
I need to show the determinant of the above matrix equals
1 +
n−1
X
i=1
(g,xi (x))2 .
This is implied by the following claim. To simplify the notation I will replace n −1
with n.
Claim: Let a1, · · ·, an be real numbers and let A (a1, · · ·, an) be the matrix
which has 1 + a2
i in the iith slot and aiaj in the ijth slot when i ̸= j. Then
det A = 1 +
n
X
i=1
a2
i.

492
HAUSDORFF MEASURE
Proof of the claim: The matrix, A (a1, · · ·, an) is of the form
A (a1, · · ·, an) =





1 + a2
1
a1a2
· · ·
a1an
a1a2
1 + a2
2
a2an
...
...
...
a1an
a2an
· · ·
1 + a2
n





Now consider the product of a matrix and its transpose, BT B below.







1
0
· · ·
0
a1
0
1
0
a2
...
...
...
0
1
an
−a1
−a2
· · ·
−an
1














1
0
· · ·
0
−a1
0
1
0
−a2
...
...
...
0
1
−an
a1
a2
· · ·
an
1







(17.65)
This product equals a matrix of the form
µ A (a1, · · ·, an)
0
0
1 + Pn
i=1 a2
i
¶
Therefore,
¡
1 + Pn
i=1 a2
i
¢
det (A (a1, · · ·, an)) = det (B)2 = det
¡
BT ¢2 . However,
using row operations,
det BT
=
det







1
0
· · ·
0
a1
0
1
0
a2
...
...
...
0
1
an
0
0
· · ·
0
1 + Pn
i=1 a2
i







=
1 +
n
X
i=1
a2
i
and therefore,
Ã
1 +
n
X
i=1
a2
i
!
det (A (a1, · · ·, an)) =
Ã
1 +
n
X
i=1
a2
i
!2
which shows det (A (a1, · · ·, an)) =
¡
1 + Pn
i=1 a2
i
¢
. This proves the claim.
Now the above lemma implies the divergence theorem.
Theorem 17.50 Let U be a bounded open set with a Lipschitz boundary which lies
on one side of its boundary. Then if f ∈C1
c (Rn) ,
Z
U
f,k (x) dmn =
Z
∂U
fnkdHn−1
(17.66)

17.4.
THE DIVERGENCE THEOREM
493
where n = (n1, · · ·, nn) is the Hn−1 measurable unit vector of Lemma 17.48. Also,
if F is a vector ﬁeld such that each component is in C1
c (Rn) , then
Z
U
∇· F (x) dmn =
Z
∂U
F · ndHn−1.
(17.67)
Proof: To obtain 17.66 apply Lemma 17.48 to w = ek. Then to obtain 17.67
from this,
Z
U
∇· F (x) dmn
=
n
X
j=1
Z
U
Fj,jdmn =
n
X
j=1
Z
∂U
FjnjdHn−1
=
Z
∂U
n
X
j=1
FjnjdHn−1 =
Z
∂U
F · ndHn−1.
This proves the theorem.
What is the geometric signiﬁcance of the vector, n? Recall that in the part of
the boundary contained in Qi, this vector points in the same direction as the vector
Ni (x1, · · ·, xn−1, gi (x1, · · ·, xn−1))
given by
(−gi,1 (x1, · · ·, xn−1) , −gi,2 (x1, · · ·, xn−1) , · · ·, −gi,n−1 (x1, · · ·, xn−1) , 1) (17.68)
in the case where k = n. This vector is the gradient of the function,
xn −gi (x1, · · ·, xn−1)
and so is perpendicular to the level surface given by
xn −gi (x1, · · ·, xn−1) = 0
in the case where gi is C1. It also points away from U so the vector n is the unit
outer normal. The other cases work similarly.
The divergence theorem is valid in situations more general than for Lipschitz
boundaries. What you need is essentially the ability to say that the functions, gi
above can be diﬀerentiated a.e. and more importantly that these functions can be
recovered by integrating their partial derivatives. In other words, you need absolute
continuity in each variable. Later in the chapter on weak derivatives, examples of
such functions which are more general than Lipschitz functions will be discussed.
However, the Lipschitz functions are pretty general and will suﬃce for now.

494
HAUSDORFF MEASURE

Diﬀerentiation With Respect
To General Radon Measures
This is a brief chapter on certain important topics on the diﬀerentiation theory
for general Radon measures. For diﬀerent proofs and some results which are not
discussed here, a good source is [20] which is where I ﬁrst read some of these things.
18.1
Besicovitch Covering Theorem
The fundamental theorem of calculus presented above for Lebesgue measures can
be generalized to arbitrary Radon measures. It turns out that the same approach
works if a diﬀerent covering theorem is employed instead of the Vitali theorem. This
covering theorem is the Besicovitch covering theorem of this section. It is necessary
because for a general Radon measure µ, it is no longer the case that the measure
is translation invariant. This implies there is no way to estimate µ
³
bB
´
in terms of
µ (B) and thus the Vitali covering theorem is of no use. In the Besicovitch covering
theorem the balls in the covering are not enlarged as they are in the Vitali theorem.
In this theorem they can also be either open or closed or neither open nor closed.
The balls can also be taken with respect to any norm on Rn. The notation, B (x,r)
in the above argument will denote any set which satisﬁes
{y : ||y −x|| < r} ⊆B (x, r) ⊆{y : ||y −x|| < r}
and the norm, ||·|| is just some norm on Rn. The following picture is a distorted
picture of the situation described in the following lemma.
495

496
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
r
0
r y
r x
Lemma 18.1 Let 10 ≤rx ≤ry and suppose B (x, rx) and B (y, ry) both have
nonempty intersection with B (0, 1) but neither of these balls contains 0. Suppose
also that
||x −y|| ≥ry
so that neither ball contains both centers in its interior. Then
¯¯¯¯
¯¯¯¯
x
||x|| −
y
||y||
¯¯¯¯
¯¯¯¯ ≥4
5.
Proof: By hypothesis,
||x|| ≥rx ≥||x|| −1, ||y|| ≥ry ≥||y|| −1.
Then
¯¯¯¯
¯¯¯¯
x
||x|| −
y
||y||
¯¯¯¯
¯¯¯¯ =
¯¯¯¯
¯¯¯¯
x ||y|| −||x|| y
||x|| ||y||
¯¯¯¯
¯¯¯¯
=
¯¯¯¯
¯¯¯¯
x ||y|| −y ||y|| + y ||y|| −||x|| y
||x|| ||y||
¯¯¯¯
¯¯¯¯
≥||x −y||
||x||
−|||y|| −||x|||
||x||
(18.1)
Now there are two cases.
First suppose ||y|| ≥||x|| . Then the above is larger than
≥
ry
||x|| −||y||
||x|| + 1 ≥ry
||x|| −(ry + 1)
||x||
+ 1
=
1 −
1
||x|| ≥1 −1
rx
≥1 −1
10 = 9
10.

18.1.
BESICOVITCH COVERING THEOREM
497
Next suppose ||x|| ≥||y|| . Then 18.1 is at least as large as
ry
||x|| −||x|| −||y||
||x||
=
ry
||x|| −1 + ||y||
||x||
≥
2ry
||x|| −1 ≥
2ry
rx + 1 −1
≥
2rx
rx + 1 −1 ≥
20
10 + 1 −1
=
. 818 18
This proves the lemma.
Lemma 18.2 There exists Ln depending on dimension, n, such that for {xk}m
k=1
distinct points on ∂B (0, 1) , if m ≥Ln, then the distance between some pair of
points of {xk}m
k=1 is less than 4/5.
Proof:
Let {zj}Ln−1
j=1
be a 1/3 net on ∂B (0, 1) . Then for m ≥Ln, if {xk}m
k=1
is a set of m distinct points on ∂B (0, 1) , there must exist xi and xj for i ̸= j such
that both xi and xj are contained in some B (zk, 1/3) . This follows from the pigeon
hole principle. There are more xi than there are B (zk, 1/3) and so one of these
must have more than one xk in it. But then
||xi −xj|| ≤||xi −zk|| + ||zk −xj|| ≤2
3 < 4
5
This proves the lemma.
Corollary 18.3 Let B0 = B (0,1) and let Bj = B (xj, rj) for j = 1, · · ·, K such
that rj ≥10, 0 /∈Bj for all j > 0, Bj ∩B0 ̸= ∅, and for all i ̸= j,
||xi −xj|| ≥max (ri, rj) .
That is, no Bj contains two centers in its interior. Then K ≤Ln, the constant of
the above lemma.
Proof: By Lemma 18.2, if K > Ln, there exist two of the centers, xi and xj
such that
¯¯¯
¯¯¯
xi
||xi|| −
xj
||xj||
¯¯¯
¯¯¯ < 4/5. By Lemma 18.1, ||xi −xj|| < max (ri, rj) contrary
to the assumptions of the corollary. Hence K ≤Ln as claimed.
Theorem 18.4 There exists a constant Nn, depending only on n with the following
property. If F is any collection of nonempty balls in Rn with
sup {diam (B) : B ∈F} < D < ∞
and if A is the set of centers of the balls in F, then there exist subsets of F, G1, · · ·,
GNn, such that each Gi is a countable collection of disjoint balls from F and
A ⊆∪Nn
i=1 {B : B ∈Gi}.

498
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
Lemma 18.5 In the situation of Theorem 18.4, suppose the set of centers A is
bounded. Then there exists a sequence of balls from F, {Bj}J
j=1 where J ≤∞such
that
r (B1) ≥3
4 sup {r (B) : B ∈F}
(18.2)
and if
Am ≡A \ (∪m
i=1Bi) ̸= ∅,
(18.3)
then
r (Bm+1) ≥3
4 sup {r : B (a, r) ∈F, a ∈Am} .
(18.4)
Letting Bj = B (aj, rj) , this sequence satisﬁes
A ⊆∪J
i=1Bi, r (Bk) ≤4
3r (Bj) for j < k, {B (aj, rj/3)}J
j=1 are disjoint.
(18.5)
Proof: Pick B1 satisfying 18.2. If B1, · · ·, Bm have been chosen, and Am is
given in 18.3, then if it equals ∅, it follows A ⊆∪m
i=1Bi. Set J = m. If Am ̸= ∅,
pick Bm+1 to satisfy 18.4. This deﬁnes the desired sequence. It remains to verify
the claims in 18.5. Consider the second claim. Letting A0 ≡A, Ak ⊆Aj−1 and so
sup {r : B (a, r) ∈F, a ∈Aj−1} ≥rk.
Hence rj ≥(3/4) rk. This proves the second claim of 18.5.
Consider the third claim of 18.5. Suppose to the contrary that x ∈B (aj, rj/3)∩
B (ai, ri/3) where i < j. Then
||ai −aj||
≤
||ai −x|| + ||x −aj||
<
1
3 (ri + rj) ≤1
3
µ
ri + 4
3ri
¶
=
7
9ri < ri
contrary to the construction which requires aj /∈B (ai, ri).
Finally consider the ﬁrst claim of 18.5. It is true if J < ∞. This follows from
the construction. If J = ∞, then since A is bounded and the balls, B (aj, rj/3) are
disjoint, it must be the case that limi→∞ri = 0. Suppose J = ∞so that Am ̸= ∅
for all m. If a0 fails to be covered, then a0 ∈Ak for all k. Let a0 ∈B (a0, r0) ∈F
for some ball B (a0, r0) . Then for i large enough, ri <
1
10r0 and so since a0 ∈Ai−1,
3
4r0 ≤3
4 sup {r : B (a, r) ∈F, a ∈Ai−1} ≤ri < 1
10r0,
a contradiction. This proves the lemma.
Lemma 18.6 There exists a constant Mn depending only on n such that for each
1 ≤k ≤J, Mn exceeds the number of sets Bj for j < k which have nonempty
intersection with Bk.

18.1.
BESICOVITCH COVERING THEOREM
499
Proof: These sets Bj which intersect Bk are of two types. Either they have
large radius, rj > 10rk, or they have small radius, rj ≤10rk. In this argument let
card (S) denote the number of elements in the set S. Deﬁne for ﬁxed k,
I ≡{j : 1 ≤j < k, Bj ∩Bk ̸= ∅, rj ≤10rk},
K ≡{j : 1 ≤j < k, Bj ∩Bk ̸= ∅, rj > 10rk}.
Claim 1: B
¡
aj, rj
3
¢
⊆B (ak, 15rk) for j ∈I.
Proof: Let j ∈I. Then Bj ∩Bk ̸= ∅and rj ≤10rk. Now if
x ∈B
³
aj, rj
3
´
,
then since rj ≤10rk,
||x −ak||
≤
||x −aj|| + ||aj −ak|| ≤rj
3 + rj + rk =
4
3rj + rk
≤
4
3 (10rk) + rk = 43
3 rk < 15rk.
Therefore, B
¡
aj, rj
3
¢
⊆B (ak, 15rk).
Claim 2: card (I) ≤60n.
Proof: Recall r (Bk) ≤4
3r (Bj) . Then letting α (n) rn be the Lebesgue measure
of the n dimensional ball of radius r, (Note this α (n) depends on the norm used.)
α (n) 15nrn
k
≡
mn (B (ak, 15rk)) ≥
X
j∈I
mn
³
B
³
aj, rj
3
´´
=
X
j∈I
α (n)
³rj
3
´n
≥
X
j∈I
α (n)
³rk
4
´n µ
since rk ≤4
3rj
¶
=
card (I) α (n)
³rk
4
´n
and so it follows card (I) ≤60n as claimed.
Claim 3: card (K) ≤Ln where Ln is the constant of Corollary 18.3.
Proof: Consider {Bj : j ∈K} and Bk. Let f (x) ≡r−1
k
(x −xk) . Then f (Bk) =
B (0, 1) and
f (Bj) = r−1
k B (xj −xk, rj) = B
µxj −xk
rk
, rj/rk
¶
.
Then rj/rk ≥10 because j ∈K. None of the balls, f (Bj) contain 0 but all these
balls intersect B (0, 1) and as just noted, each of these balls has radius ≥10 and
none of them contains two centers on its interior. By Corollary 18.3, it follows there
are no more than Ln of them. This proves the claim. A constant which will satisfy
the desired conditions is
Mn ≡Ln + 60n + 1.
This completes the proof of Lemma 18.6.

500
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
Next subdivide the balls {Bi}J
i=1 into Mn subsets G1, · · ·, GMn each of which
consists of disjoint balls.
This is done in the following way.
Let B1 ∈G1.
If
B1, · · ·, Bk have each been assigned to one of the sets G1, · · ·, GMn, let Bk+1 ∈Gr
where r is the smallest index having the property that Bk+1 does not intersect any
of the balls already in Gr. There must exist such an index r ∈{1, · · ·, Mn} because
otherwise Bk+1 ∩Bj ̸= ∅for at least Mn values of j < k + 1 contradicting Lemma
18.6. By Lemma 18.5
A ⊆∪Mn
i=1 {B : B ∈Gi} = ∪J
j=1Bj.
This proves Theorem 18.4 in the case where A is bounded.
To complete the proof of this theorem, the restriction that A is bounded must
be removed. Deﬁne
Al ≡A ∩{x ∈Rn : 10 (l −1) D ≤||x|| < 10lD} , l = 1, 2, · · ·
and
Fl = {B (a,r) : B (a,r) ∈F and a ∈Al}.
Then since D is an upper bound for all the diameters of these balls,
(∪Fl) ∩(∪Fm) = ∅
(18.6)
whenever m ≥l + 2. Therefore, applying what was just shown to the pair (Al, Fl),
there exist subsets of Fl, Gl
1 · · · Gl
Mn such that each Gl
i is a countable collection of
disjoint balls of Fl ⊆F and
Al ⊆∪Mn
i=1
©
B : B ∈Gl
i
ª
.
Now let Gj ≡∪∞
l=1G2l−1
j
for 1 ≤j ≤Mn and for 1 ≤j ≤Mn, let Gj+Mn ≡∪∞
l=1G2l
j .
Thus, letting Nn ≡2Mn,
A = ∪∞
l=1A2l ∪∪∞
l=1A2l−1 ⊆∪Nn
j=1 {B : B ∈Gj}
and by 18.6, each Gj is a countable set of disjoint balls of F.
This proves the
Besicovitch covering theorem.
18.2
Fundamental Theorem Of Calculus For Radon
Measures
In this section the Besicovitch covering theorem will be used to give a generalization
of the Lebesgue diﬀerentiation theorem to general Radon measures. In what follows,
µ will be a Radon measure,
Z ≡{x ∈Rn : µ (B (x,r)) = 0 for some r > 0},
Z
B(x,r)
−
fdµ ≡
½ 0 if x ∈Z,
1
µ(B(x,r))
R
B(x,r) fdµ if x /∈Z,

18.2.
FUNDAMENTAL THEOREM OF CALCULUS FOR RADON MEASURES 501
and the maximal function Mf : Rn →[0, ∞] is given by
Mf (x) ≡sup
r≤1
Z
B(x,r)
−
|f| dµ.
Lemma 18.7 Z is measurable and µ (Z) = 0.
Proof: For each x ∈Z, there exists a ball B (x,r) with µ (B (x,r)) = 0. Let C
be the collection of these balls. Since Rn has a countable basis, a countable subset,
eC, of C also covers Z. Let
eC = {Bi}∞
i=1 .
Then letting µ denote the outer measure determined by µ,
µ (Z) ≤
∞
X
i=1
µ (Bi) =
∞
X
i=1
µ (Bi) = 0
Therefore, Z is measurable and has measure zero as claimed.
Theorem 18.8 Let µ be a Radon measure and let f ∈L1 (Rn, µ). Then
lim
r→0
Z
B(x,r)
−
|f (y) −f (x)| dµ (y) = 0
for µ a.e. x ∈Rn.
Proof: First consider the following claim which is a weak type estimate of the
same sort used when diﬀerentiating with respect to Lebesgue measure.
Claim 1:
µ ([Mf > ε]) ≤Nnε−1 ||f||1
Proof: First note A ∩Z = ∅. For each x ∈A there exists a ball Bx = B (x,rx)
with rx ≤1 and
µ (Bx)−1
Z
B(x,rx)
|f| dµ > ε.
Let F be this collection of balls so that A is the set of centers of balls of F. By the
Besicovitch covering theorem,
A ⊆∪Nn
i=1 {B : B ∈Gi}
where Gi is a collection of disjoint balls of F. Now for some i,
µ (A) /Nn ≤µ (∪{B : B ∈Gi})
because if this is not so, then
µ (A) ≤
Nn
X
i=1
µ (∪{B : B ∈Gi}) <
Nn
X
i=1
µ (A)
Nn
= µ (A),

502
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
a contradiction. Therefore for this i,
µ (A)
Nn
≤
µ (∪{B : B ∈Gi}) =
X
B∈Gi
µ (B) ≤
X
B∈Gi
ε−1
Z
B
|f| dµ
≤
ε−1
Z
Rn |f| dµ = ε−1 ||f||1 .
This shows Claim 1.
Claim 2: If g is any continuous function deﬁned on Rn, then
lim
r→0
Z
B(x,r)
−
|g (y) −g (x)| dµ (y) = 0
and if x /∈Z,
lim
r→0
1
µ (B (x,r))
Z
B(x,r)
g (y) dµ (y) = g (x).
(18.7)
Proof: If x ∈Z there is nothing to prove. If x /∈Z, then since g is continuous
at x, whenever r is small enough,
Z
B(x,r)
−
|g (y) −g (x)| dµ (y)
=
1
µ (B (x,r))
Z
B(x,r)
|g (y) −g (x)| dµ (y)
≤
1
µ (B (x,r))
Z
B(x,r)
ε dµ (y) = ε.
18.7 follows from the above and the triangle inequality. This proves the claim.
Now let g ∈Cc (Rn) and x /∈Z.
Then from the above observations about
continuous functions,
µ
Ã"
x : lim sup
r→0
Z
B(x,r)
−
|f (y) −f (x)| dµ (y) > ε
#!
(18.8)
≤
µ
Ã"
x : lim sup
r→0
Z
B(x,r)
−
|f (y) −g (y)| dµ (y) > ε
2
#!
+µ
³h
x : |g (x) −f (x)| > ε
2
i´
.
≤µ
³h
M (f −g) > ε
2
i´
+ µ
³h
|f −g| > ε
2
i´
(18.9)
Now
Z
[|f−g|> ε
2]
|f −g| dµ ≥ε
2µ
³h
|f −g| > ε
2
i´

18.2.
FUNDAMENTAL THEOREM OF CALCULUS FOR RADON MEASURES 503
and so from Claim 1 18.9 and hence 18.8 is dominated by
µ2
ε + Nn
ε
¶
||f −g||L1(Rn,µ) .
But by regularity of Radon measures, Cc (Rn) is dense in L1 (Rn, µ) and so since g
in the above is arbitrary, this shows 18.8 equals 0. Now
µ
Ã"
x : lim sup
r→0
Z
B(x,r)
−
|f (y) −f (x)| dµ (y) > 0
#!
=
µ
Ã
∪∞
m=1
Ã"
x : lim sup
r→0
Z
B(x,r)
−
|f (y) −f (x)| dµ (y) > 1
m
#!!
≤
∞
X
m=1
µ
Ã"
x : lim sup
r→0
Z
B(x,r)
−
|f (y) −f (x)| dµ (y) > 1
m
#!
= 0.
By Lemma 18.7 the set Z is a set of measure zero and so if
x /∈
"
lim sup
r→0
Z
B(·,r)
−
|f (y) −f (·)| dµ (y) > 0
#
∪Z
the above has shown
0
≤
lim inf
r→0
Z
B(x,r)
−
|f (y) −f (x)| dµ (y)
≤
lim sup
r→0
Z
B(x,r)
−
|f (y) −f (x)| dµ (y) = 0
which proves the theorem.
The following corollary is the main result referred to as the Lebesgue Besicovitch
Diﬀerentiation theorem.
Corollary 18.9 If f ∈L1
loc (Rn, µ),
lim
r→0
Z
B(x,r)
−
|f (y) −f (x)| dµ (y) = 0 µ a.e. x.
(18.10)
Proof: If f is replaced by fXB(0,k) then the conclusion 18.10 holds for all x /∈Fk
where Fk is a set of µ measure 0. Letting k = 1, 2, · · ·, and F ≡∪∞
k=1Fk, it follows
that F is a set of measure zero and for any x /∈F, and k ∈{1, 2, · · ·}, 18.10 holds
if f is replaced by fXB(0,k). Picking any such x, and letting k > |x| + 1, this shows
lim
r→0
Z
B(x,r)
−
|f (y) −f (x)| dµ (y)
= lim
r→0
Z
B(x,r)
−
¯¯fXB(0,k) (y) −fXB(0,k) (x)
¯¯ dµ (y) = 0.
This proves the corollary.

504
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
18.3
Slicing Measures
Let µ be a ﬁnite Radon measure. I will show here that a formula of the following
form holds.
µ (F) =
Z
F
dµ =
Z
Rn
Z
Rm XF (x, y) dνx (y) dα (x)
where α (E) = µ (E × Rm). When this is done, the measures, νx, are called slicing
measures and this shows that an integral with respect to µ can be written as an
iterated integral in terms of the measure α and the slicing measures, νx. This is
like going backwards in the construction of product measure. One starts with a
measure, µ, deﬁned on the Cartesian product and produces α and an inﬁnite family
of slicing measures from it whereas in the construction of product measure, one
starts with two measures and obtains a new measure on a σ algebra of subsets of
the Cartesian product of two spaces. First here are two technical lemmas.
Lemma 18.10 The space Cc (Rm) with the norm
||f|| ≡sup {|f (y)| : y ∈Rm}
is separable.
Proof: Let Dl consist of all functions which are of the form
X
|α|≤N
aαyα ³
dist
³
y,B (0,l + 1)C´´nα
where aα ∈Q, α is a multi-index, and nα is a positive integer. Then Dl is countable,
separates the points of B (0,l) and annihilates no point of B (0,l). By the Stone
Weierstrass theorem Dl is dense in the space C
³
B (0,l)
´
and so ∪{Dl : l ∈N} is a
countable dense subset of Cc (Rm).
From the regularity of Radon measures, the following lemma follows.
Lemma 18.11 If µ and ν are two Radon measures deﬁned on σ algebras, Sµ and
Sν, of subsets of Rn and if µ (V ) = ν (V ) for all V open, then µ = ν and Sµ = Sν.
Proof: Every compact set is a countable intersection of open sets so the two
measures agree on every compact set. Hence it is routine that the two measures
agree on every Gδ and Fσ set. (Recall Gδ sets are countable intersections of open
sets and Fσ sets are countable unions of closed sets.) Now suppose E ∈Sν is a
bounded set. Then by regularity of ν there exists G a Gδ set and F, an Fσ set
such that F ⊆E ⊆G and ν (G \ F) = 0. Then it is also true that µ (G \ F) = 0.
Hence E = F ∪(E \ F) and E \ F is a subset of G \ F, a set of µ measure zero. By
completeness of µ, it follows E ∈Sµ and
µ (E) = µ (F) = ν (F) = ν (E) .
If E ∈Sν not necessarily bounded, let Em = E ∩B (0, m) and then Em ∈Sµ and
µ (Em) = ν (Em) . Letting m →∞, E ∈Sµ and µ (E) = ν (E) . Similarly, Sµ ⊆Sν
and the two measures are equal on Sµ.
The main result in the section is the following theorem.

18.3.
SLICING MEASURES
505
Theorem 18.12 Let µ be a ﬁnite Radon measure on Rn+m deﬁned on a σ algebra,
F. Then there exists a unique ﬁnite Radon measure, α, deﬁned on a σ algebra, S,
of sets of Rn which satisﬁes
α (E) = µ (E × Rm)
(18.11)
for all E Borel.
There also exists a Borel set of α measure zero, N, such that
for each x /∈N, there exists a Radon probability measure νx such that if f is a
nonnegative µ measurable function or a µ measurable function in L1 (µ),
y →f (x, y) is νx measurable α a.e.
x →
Z
Rm f (x, y) dνx (y) is α measurable
(18.12)
and
Z
Rn+m f (x, y) dµ =
Z
Rn
µZ
Rm f (x, y) dνx (y)
¶
dα (x).
(18.13)
If bνx is any other collection of Radon measures satisfying 18.12 and 18.13, then
bνx = νx for α a.e. x.
Proof: First consider the uniqueness of α. Suppose α1 is another Radon measure
satisfying 18.11. Then in particular, α1 and α agree on open sets and so the two
measures are the same by Lemma 18.11.
To establish the existence of α, deﬁne α0 on Borel sets by
α0 (E) = µ (E × Rm).
Thus α0 is a ﬁnite Borel measure and so it is ﬁnite on compact sets. Lemma 11.3
on Page 11.3 implies the existence of the Radon measure α extending α0.
Next consider the uniqueness of νx. Suppose νx and bνx satisfy all conclusions
of the theorem with exceptional sets denoted by N and b
N respectively.
Then,
enlarging N and b
N, one may also assume, using Lemma 18.7, that for x /∈N ∪b
N,
α (B (x,r)) > 0 whenever r > 0. Now let
A =
m
Y
i=1
(ai, bi]
where ai and bi are rational. Thus there are countably many such sets. Then from
the conclusion of the theorem, if x0 /∈N ∪b
N,
1
α (B (x0, r))
Z
B(x0,r)
Z
Rm XA (y) dνx (y) dα
=
1
α (B (x0, r))
Z
B(x0,r)
Z
Rm XA (y) dbνx (y) dα,

506
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
and by the Lebesgue Besicovitch Diﬀerentiation theorem, there exists a set of α
measure zero, EA, such that if x0 /∈EA ∪N ∪b
N, then the limit in the above exists
as r →0 and yields
νx0 (A) = bνx0 (A).
Letting E denote the union of all the sets EA for A as described above, it follows
that E is a set of measure zero and if x0 /∈E ∪N ∪b
N then νx0 (A) = bνx0 (A) for
all such sets A. But every open set can be written as a disjoint union of sets of this
form and so for all such x0, νx0 (V ) = bνx0 (V ) for all V open. By Lemma 18.11
this shows the two measures are equal and proves the uniqueness assertion for νx.
It remains to show the existence of the measures νx. This will be done with the aid
of the following lemma. The idea is to deﬁne a positive linear functional which will
yield the desired measure, νx and this lemma will help in making this deﬁnition.
Lemma 18.13 There exists a set N of α measure 0, independent of f ∈Cc (Rn+m)
such that if x /∈N, α (B (x,r)) > 0 for all r > 0 and
lim
r→0
1
α (B (x,r))
Z
B(x,r)×Rm fdµ = gf (x)
where gf is a α measurable function with the property that
Z
Rn gf (x) dα =
Z
Rn×Rm fdµ.
Proof: Let f ∈Cc (Rn+m) and let
ηf (E) ≡
Z
E×Rm fdµ.
Then ηf is a ﬁnite measure deﬁned on the Borel sets with ηf ≪α. By the Radon
Nikodym theorem, there exists a Borel measurable function egf such that for all
Borel E,
ηf (E) ≡
Z
E×Rm fdµ =
Z
E
egfdα.
(18.14)
By the theory of diﬀerentiation for Radon measures, there exists a set of α measure
zero, Nf such that if x /∈Nf, then α (B (x,r)) > 0 for all r > 0 and
lim
r→0
1
α (B (x,r))
Z
B(x,r)×Rm fdµ = lim
r→0
Z
B(x,r)
−
egfdα = egf (x).
Let D be a countable dense subset of Cc (Rn+m) and let
N ≡∪{Nf : f ∈D}.
Then if f ∈Cc (Rn+m) is arbitrary, and x /∈N, referring to 18.14, it follows there
exists g ∈D close enough to f such that for all r1, r2,
¯¯¯¯¯
1
α (B (x,r1))
Z
B(x,r1)×Rm fdµ −
1
α (B (x,r2))
Z
B(x,r2)×Rm fdµ
¯¯¯¯¯ <

18.3.
SLICING MEASURES
507
ε
2 +
¯¯¯¯¯
1
α (B (x,r1))
Z
B(x,r1)×Rm gdµ −
1
α (B (x,r2))
Z
B(x,r2)×Rm gdµ
¯¯¯¯¯
Therefore, taking ri small enough, the right side is less than ε. Since ε is arbitrary,
this shows the limit as r →0 exists. Deﬁne this limit which exists for all f ∈
Cc (Rn+m) and x /∈N as gf (x). By the ﬁrst part of the argument, gf (x) = egf (x)
a.e. Thus, gf (x) is α measurable because it equals a Borel measurable function α
a.e. The ﬁnal formula follows from
Z
Rn gf (x) dα =
Z
Rn egf (x) dα ≡ηf (Rn) ≡
Z
Rn×Rm fdµ.
This proves the lemma.
Continuing with the proof of the theorem, let x /∈N and let f (z, y) ≡ψ (z) φ (y)
where ψ and φ are continuous functions with compact support in Rn and Rm re-
spectively. Suppose ﬁrst that ψ (x) = 1. Then deﬁne a positive linear functional
Lxφ ≡lim
r→0
1
α (B (x,r))
Z
B(x,r)×Rm ψ (z) φ (y) dµ (z, y).
This functional may appear to depend on the choice of ψ satisfying ψ (x) = 1 but
this is not the case because all such ψ′s used in the deﬁnition of Lx are continuous.
Let νx be the Radon measure representing Lx.
Thus replacing an arbitrary
ψ ∈Cc (Rn) with
ψ
ψ(x), in the case when ψ (x) ̸= 0,
ψ (x) Lx (φ)
=
ψ (x)
Z
Rm φ (y) dνx (y)
=
lim
r→0
ψ (x)
α (B (x,r))
Z
B(x,r)×Rm
ψ
ψ (x)φdµ
=
lim
r→0
1
α (B (x,r))
Z
B(x,r)×Rm ψφdµ
By Lemma 18.13,
Z
Rn
Z
Rm ψφdνxdα =
Z
Rn gψφdα =
Z
Rn×Rm ψφdµ.
Letting ψk, φk increase to 1 pointwise, the monotone convergence theorem implies
Z
Rn νx (Rm) dα =
Z
Rn×Rm dµ = µ (Rn × Rm) < ∞
(18.15)
showing that x →νx (Rm) is a function in L1 (α). In particular, this function is
ﬁnite α a.e. Summarizing, the above has shown that whenever ψ ∈Cc (Rn) and
φ ∈Cc (Rm)
Z
Rn
Z
Rm ψφdνxdα =
Z
Rn×Rm ψφdµ.
(18.16)

508
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
Also νx is a ﬁnite measure α a.e. and νx and α are Radon measures.
Next it is shown that ψφ can be replaced by XE where E is an arbitrary µ
measurable set. To do so, let
R1 ≡
n
Y
i=1
(ai, bi], R2 ≡
m
Y
i=1
(ci, di]
(18.17)
and let ψk be a sequence of functions in Cc (Rn) which is bounded, piecewise linear
in each variable, and converging pointwise to XR1. Also let φk be a similar sequence
converging pointwise to XR2. Then by the dominated convergence theorem,
Z
Rn×Rm XR1 (x) XR2 (y) dµ = lim
k→∞
Z
Rn×Rm ψk (x) φk (y) dµ
= lim
k→∞
Z
Rn ψk (x)
µZ
Rm φk (y) dνx
¶
dα.
(18.18)
Since νx is ﬁnite α a.e., it follows that for α a.e. x,
lim
k→∞
Z
Rm φk (y) dνx =
Z
Rm XR2 (y) dνx.
Since the φk are uniformly bounded, 18.15 implies the existence of a dominating
function for the integrand in 18.18. Therefore, one can take the limit inside the
integrals and obtain
Z
Rn×Rm XR1 (x) XR2 (y) dµ =
Z
Rn
Z
Rm XR1 (x) XR2 (y) dνxdα
Every open set, V in Rn+m is a countable disjoint union of such half open rectangles
and so the monotone convergence theorem implies for all V open in Rn+m,
Z
Rn×Rm XV dµ =
Z
Rn
Z
Rm XV dνxdα.
(18.19)
Since every compact set is the countable intersection of open sets, the above for-
mula holds for V replaced with K where K is compact. Then it follows from the
dominated convergence and monotone convergence theorems that whenever H is
either a Gδ (countable intersection of open sets) or a Fσ (countable union of closed
sets)
Z
Rn×Rm XHdµ =
Z
Rn
Z
Rm XHdνxdα.
Now let E be µ measurable. Using the regularity of µ there exists F, G such that
F is Fσ, G is Gδ, µ (G \ F) = 0, and F ⊆E ⊆G. Also a routine application of the
dominated convergence theorem and 18.19 shows
Z
Rn×Rm X(G\F )dµ =
Z
Rn
Z
Rm X(G\F )dνxdα

18.4.
VITALI COVERINGS
509
and (G \ F)x ≡{y : (x, y) ∈G \ F} is νx measurable for α a.e. x, wherever νx is a
ﬁnite measure, and for α a.e. x, νx (G \ F)x = 0. Therefore, for α a.e. x, Ex is νx
measurable because Ex = Fx + Sx where Sx ⊆(G \ F)x , a set of νx measure zero
and Fx is an Fσ set which is measurable because νx is a Radon measure coming as
it does from a positive linear functional. Therefore,
Z
Rn×Rm XEdµ
=
Z
Rn×Rm XF dµ =
Z
Rn
Z
Rm XF dνxdα
=
Z
Rn
Z
Rm XEdνxdα.
(18.20)
It follows from 18.20 that one can replace XE with an arbitrary nonnegative µ
measurable simple function, s. Letting f be a nonnegative µ measurable function,
it follows there is an increasing sequence of nonnegative simple functions converging
to f pointwise and so by the monotone convergence theorem,
Z
Rn×Rm fdµ =
Z
Rn
Z
Rm fdνxdα
where y →f (x, y) is νx measurable for α a.e. x and x →
R
Rm fdνx is α measurable
so the iterated integral makes sense.
To see νx is a probability measure for a.e. x,
1
α (B (x, r))
Z
B(x,r)
Z
Rm dνxdα
=
1
α (B (x, r))µ (B (x, r) × Rm) = 1
and so, using the fundamental theorem of calculus it follows that upon passing to
a limit as r →0, it follows that for α a.e. x
νx (Rm) =
Z
Rm dνx = 1
Due to the regularity of the measures, all sets of measure zero may be taken to be
Borel. In the case of f ∈L1 (µ) , one applies the above to the positive and negative
parts of the real and imaginary parts. This proves the theorem.
18.4
Vitali Coverings
There is another covering theorem which may also be referred to as the Besicovitch
covering theorem. As before, the balls can be taken with respect to any norm on
Rn. At ﬁrst, the balls will be closed but this assumption will be removed.
Deﬁnition 18.14 A collection of balls, F covers a set, E in the sense of Vitali if
whenever x ∈E and ε > 0, there exists a ball B ∈F
whose center is x having
diameter less than ε.

510
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
I will give a proof of the following theorem.
Theorem 18.15 Let µ be a Radon measure on Rn and let E be a set with µ (E) <
∞. Where µ is the outer measure determined by µ. Suppose F is a collection of
closed balls which cover E in the sense of Vitali. Then there exists a sequence of
disjoint balls, {Bi} ⊆F such that
µ
¡
E \ ∪∞
j=1Bj
¢
= 0.
Proof: Let Nn be the constant of the Besicovitch covering theorem. Choose
r > 0 such that
(1 −r)−1
µ
1 −
1
2Nn + 2
¶
≡λ < 1.
If µ (E) = 0, there is nothing to prove so assume µ (E) > 0. Let U1 be an open
set containing E with (1 −r) µ (U1) < µ (E) and 2µ (E) > µ (U1) , and let F1 be
those sets of F which are contained in U1 whose centers are in E. Thus F1 is also
a Vitali cover of E. Now by the Besicovitch covering theorem proved earlier, there
exist balls, B, of F1 such that
E ⊆∪Nn
i=1 {B : B ∈Gi}
where Gi consists of a collection of disjoint balls of F1. Therefore,
µ (E) ≤
Nn
X
i=1
X
B∈Gi
µ (B)
and so, for some i ≤Nn,
(Nn + 1)
X
B∈Gi
µ (B) > µ (E) .
It follows there exists a ﬁnite set of balls of Gi, {B1, · · ·, Bm1} such that
(Nn + 1)
m1
X
i=1
µ (Bi) > µ (E)
(18.21)
and so
(2Nn + 2)
m1
X
i=1
µ (Bi) > 2µ (E) > µ (U1) .
Since 2µ (E) ≥µ (U1) , 18.21 implies
µ (U1)
2N2 + 2 ≤2µ (E)
2N2 + 2 = µ (E)
N2 + 1 <
m1
X
i=1
µ (Bi) .
Also U1 was chosen such that (1 −r) µ (U1) < µ (E) , and so
λµ (E) ≥λ (1 −r) µ (U1) =
µ
1 −
1
2Nn + 2
¶
µ (U1)

18.4.
VITALI COVERINGS
511
≥µ (U1) −
m1
X
i=1
µ (Bi) = µ (U1) −µ
¡
∪m1
j=1Bj
¢
= µ
¡
U1 \ ∪m1
j=1Bj
¢
≥µ
¡
E \ ∪m1
j=1Bj
¢
.
Since the balls are closed, you can consider the sets of F which have empty intersec-
tion with ∪m1
j=1Bj and this new collection of sets will be a Vitali cover of E\∪m1
j=1Bj.
Letting this collection of balls play the role of F in the above argument and letting
E \ ∪m1
j=1Bj play the role of E, repeat the above argument and obtain disjoint sets
of F,
{Bm1+1, · · ·, Bm2} ,
such that
λµ
¡
E \ ∪m1
j=1Bj
¢
> µ
¡¡
E \ ∪m1
j=1Bj
¢
\ ∪m2
j=m1+1Bj
¢
= µ
¡
E \ ∪m2
j=1Bj
¢
,
and so
λ2µ (E) > µ
¡
E \ ∪m2
j=1Bj
¢
.
Continuing in this way, yields a sequence of disjoint balls {Bi} contained in F and
µ
¡
E \ ∪∞
j=1Bj
¢
≤µ
¡
E \ ∪mk
j=1Bj
¢
< λkµ (E )
for all k. Therefore, µ
¡
E \ ∪∞
j=1Bj
¢
= 0 and this proves the Theorem.
It is not necessary to assume µ (E) < ∞.
Corollary 18.16 Let µ be a Radon measure on Rn. Letting µ be the outer measure
determined by µ, suppose F is a collection of closed balls which cover E in the sense
of Vitali. Then there exists a sequence of disjoint balls, {Bi} ⊆F such that
µ
¡
E \ ∪∞
j=1Bj
¢
= 0.
Proof: Since µ is a Radon measure it is ﬁnite on compact sets. Therefore,
there are at most countably many numbers, {bi}∞
i=1 such that µ (∂B (0, bi)) > 0. It
follows there exists an increasing sequence of positive numbers, {ri}∞
i=1 such that
limi→∞ri = ∞and µ (∂B (0, ri)) = 0. Now let
D1
≡
{x : ||x|| < r1} , D2 ≡{x : r1 < ||x|| < r2} ,
· · ·, Dm
≡
{x : rm−1 < ||x|| < rm} , · · ·.
Let Fm denote those closed balls of F which are contained in Dm. Then letting
Em denote E ∩Dm, Fm is a Vitali cover of Em, µ (Em) < ∞, and so by Theorem
18.15, there exists a countable sequence of balls from Fm
©
Bm
j
ª∞
j=1 , such that
µ
¡
Em \ ∪∞
j=1Bm
j
¢
= 0. Then consider the countable collection of balls,
©
Bm
j
ª∞
j,m=1 .
µ
¡
E \ ∪∞
m=1 ∪∞
j=1 Bm
j
¢
≤
µ
¡
∪∞
j=1∂B (0, ri)
¢
+
+
∞
X
m=1
µ
¡
Em \ ∪∞
j=1Bm
j
¢
=
0

512
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
This proves the corollary.
You don’t need to assume the balls are closed. In fact, the balls can be open
closed or anything in between and the same conclusion can be drawn.
Corollary 18.17 Let µ be a Radon measure on Rn. Letting µ be the outer measure
determined by µ, suppose F is a collection of balls which cover E in the sense
of Vitali, open closed or neither. Then there exists a sequence of disjoint balls,
{Bi} ⊆F such that
µ
¡
E \ ∪∞
j=1Bj
¢
= 0.
Proof: Let x ∈E. Thus x is the center of arbitrarily small balls from F. Since
µ is a Radon measure, at most countably many radii, r of these balls can have
the property that µ (∂B (0, r)) = 0. Let F′ denote the closures of the balls of F,
B (x, r) with the property that µ (∂B (x, r)) = 0. Since for each x ∈E there are only
countably many exceptions, F′ is still a Vitali cover of E. Therefore, by Corollary
18.16 there is a disjoint sequence of these balls of F′,
©
Bi
ª∞
i=1 for which
µ
¡
E \ ∪∞
j=1Bj
¢
= 0
However, since their boundaries have µ measure zero, it follows
µ
¡
E \ ∪∞
j=1Bj
¢
= 0.
This proves the corollary.
18.5
Diﬀerentiation Of Radon Measures
This section is a generalization of earlier material in which a measure was diﬀer-
entiated with respect to Lebesgue measure. Here an arbitrary Radon measure will
be diﬀerentiated with respect to another arbitrary Radon measure. In this sec-
tion, B (x, r) will denote a ball with center x and radius r. Also, let λ and µ be
Radon measures and as above, Z will denote a µ measure zero set oﬀof which
µ (B (x, r)) > 0 for all r > 0.
Deﬁnition 18.18 For x /∈Z, deﬁne the upper and lower symmetric derivatives as
Dµλ (x) ≡lim sup
r→0
λ (B (x, r))
µ (B (x, r)), Dµλ (x) ≡lim inf
r→0
λ (B (x, r))
µ (B (x, r)).
respectively. Also deﬁne
Dµλ (x) ≡Dµλ (x) = Dµλ (x)
in the case when both the upper and lower derivatives are equal.

18.5.
DIFFERENTIATION OF RADON MEASURES
513
Lemma 18.19 Let λ and µ be Radon measures.
If A is a bounded subset of
©
x /∈Z : Dµλ (x) ≥a
ª
, then
λ (A) ≥aµ (A)
and if A is a bounded subset of
©
x /∈Z : Dµλ (x) ≤a
ª
, then
λ (A) ≤aµ (A)
Proof: Suppose ﬁrst that A is a bounded subset of
©
x /∈Z : Dµλ (x) ≥a
ª
, let
ε > 0, and let V be a bounded open set with V ⊇A and λ (V ) −ε < λ (A) , µ (V ) −
ε < µ (A) . Then if
x ∈A,
λ (B (x, r))
µ (B (x, r)) > a −ε, B (x, r) ⊆V,
for inﬁnitely many values of r which are arbitrarily small. Thus the collection of
such balls constitutes a Vitali cover for A. By Corollary 18.17 there is a disjoint
sequence of these balls {Bi} such that
µ (A \ ∪∞
i=1Bi) = 0.
(18.22)
Therefore,
(a −ε)
∞
X
i=1
µ (Bi) <
∞
X
i=1
λ (Bi) ≤λ (V ) < ε + λ (A)
and so
a
∞
X
i=1
µ (Bi)
≤
ε + εµ (V ) + λ (A)
≤
ε + ε (µ (A) + ε) + λ (A)
(18.23)
Now
µ (A \ ∪∞
i=1Bi) + µ (∪∞
i=1Bi) ≥µ (A)
and so by 18.22 and the fact the Bi are disjoint,
aµ (A)
≤
aµ (∪∞
i=1Bi) = a
∞
X
i=1
µ (Bi)
≤
ε + ε (µ (A) + ε) + λ (A) .
(18.24)
Hence aµ (A) ≤λ (A) since ε > 0 was arbitrary.
Now suppose A is a bounded subset of
©
x /∈Z : Dµλ (x) ≤a
ª
and let V be a
bounded open set containing A with µ (V ) −ε < µ (A) . Then if x ∈A,
λ (B (x, r))
µ (B (x, r)) < a + ε, B (x, r) ⊆V

514
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
for values of r which are arbitrarily small. Therefore, by Corollary 18.17 again,
there exists a disjoint sequence of these balls, {Bi} satisfying this time,
λ (A \ ∪∞
i=1Bi) = 0.
Then by arguments similar to the above,
λ (A) ≤
∞
X
i=1
λ (Bi) < (a + ε) µ (V ) < (a + ε) (µ (A) + ε) .
Since ε was arbitrary, this proves the lemma.
Theorem 18.20 There exists a set of measure zero, N containing Z such that
for x /∈N, Dµλ (x) exists and also XN C (·) Dµλ (·) is a µ measurable function.
Furthermore, Dµλ (x) < ∞µ a.e.
Proof: First I show Dµλ (x) exists a.e. Let 0 ≤a < b < ∞and let A be any
bounded subset of
N (a, b) ≡
©
x /∈Z : Dµλ (x) > b > a > Dµλ (x)
ª
.
By Lemma 18.19,
aµ (A) ≥λ (A) ≥bµ (A)
and so µ (A) = 0 and A is µ measurable. It follows µ (N (a, b)) = 0 because
µ (N (a, b)) ≤
∞
X
m=1
µ (N (a, b) ∩B (0, m)) = 0.
Deﬁne
N0 ≡
©
x /∈Z : Dµλ (x) > Dµλ (x)
ª
.
Thus µ (N0) = 0 because
N0 ⊆∪{N (a, b) : 0 ≤a < b, and a, b ∈Q}
Therefore, N0 is also µ measurable and has µ measure zero. Letting N ≡N0 ∪Z, it
follows Dµλ (x) exists on N C. It remains to verify XN C (·) Dµλ (·) is ﬁnite a.e. and
is µ measurable.
Let
I = {x : Dµλ (x) = ∞} .
Then by Lemma 18.19
λ (I ∩B (0, m)) ≥aµ (I ∩B (0, m))
for all a and since λ is ﬁnite on bounded sets, the above implies µ (I ∩B (0, m)) = 0
for each m which implies that I is µ measurable and has µ measure zero since
I = ∪∞
m=1Im.

18.6.
THE RADON NIKODYM THEOREM FOR RADON MEASURES
515
Letting η be an arbitrary Radon measure, let r > 0, and suppose η (∂B (x, r)) =
0. (Since η is ﬁnite on every ball, there are only countably many r such that
η (∂B (x, r)) > 0.) and let V be an open set containing B (x, r). Then whenever
y is close enough to x, it follows that B (y, r) is also a subset of V. Since V is an
arbitrary open set containing B (x, r), it follows
η (B (x, r)) = η
³
B (x, r)
´
≥lim sup
y→x η (B (y, r))
and so y →η (B (y, r)) an upper semicontinuous real valued function of x, one
which satisﬁes
f (x) ≥lim sup
n→∞f (xn)
whenever xn →x. Now it is routine to verify that a function f is upper semicon-
tinuous if and only if f −1 ([−∞, a)) is open for all a ∈R. Therefore, f −1 ([−∞, a))
is a Borel set for all a ∈R and so f is Borel measurable by Lemma 8.6. Now the
measurability of XNC (·) Dµλ (·) follows from
XNC (x) Dµλ (x) = lim
ri→0
λ (B (x, ri))
µ (B (x, ri))XNC (x)
where ri is such that ∂B (x, ri) has µ and λ measure zero.
18.6
The Radon Nikodym Theorem For Radon Mea-
sures
The above theory can be used to give an alternate treatment of the Radon Nikodym
theorem which exhibits the Radon Nikodym derivative as a speciﬁc limit.
Theorem 18.21 Let λ and µ be Radon measures and suppose λ ≪µ. Then for all
E a µ measurable set,
λ (E) =
Z
E
(Dµλ) dµ.
Proof:
Let t > 1 and let E be a µ measurable set which is bounded and a
subset of N C where N is the exceptional set of µ measure zero in Theorem 18.20
oﬀof which µ (B (x,r)) > 0 for all r > 0 and Dµλ (x) exists. Consider
Em ≡E ∩
©
x ∈N C : tm ≤Dµλ (x) < tm+1ª
for m ∈Z, the integers. First note that
E ∩
©
x ∈N C : Dµλ (x) = 0
ª
has λ measure zero because by Lemma 18.19,
λ
¡
E ∩
©
x ∈N C : Dµλ (x) = 0
ª¢
≤aµ (E )

516
DIFFERENTIATION WITH RESPECT TO GENERAL RADON MEASURES
for all a > 0 and µ (E ) is ﬁnite due to the assumption that E is bounded and µ is
a Radon measure. Therefore, by Lemma 18.19,
λ (E) =
X
m∈Z
λ (Em) ≤
X
m∈Z
tm+1µ (Em) = t
X
m∈Z
tmµ (Em)
≤t
X
m∈Z
Z
Em
Dµλ (x) dµ = t
Z
E
Dµλ (x) dµ.
Also by this same lemma,
λ (E) =
X
m∈Z
λ (Em) ≥
X
m∈Z
tmµ (Em) = t−1 X
m∈Z
tm+1µ (Em)
≥t−1 X
m∈Z
Z
Em
Dµλ (x) dµ = t−1
Z
E
Dµλ (x) dµ.
Thus,
t
Z
E
Dµλ (x) dµ ≥λ (E) ≥t−1
Z
E
Dµλ (x) dµ
and letting t →1, it follows
λ (E) =
Z
E
Dµλ (x) dµ.
(18.25)
Now if E is an arbitrary measurable set, contained in N C, this formula holds with
E replaced with E ∩B (0,k) . Letting k →∞and using the monotone convergence
theorem, the above formula holds for all E ⊆N C. Since N is a set of µ measure
zero, it follows N is also a set of λ measure zero due to the assumption of absolute
continuity. Therefore 18.25 continues to hold for arbitrary µ measurable sets, E.
This proves the theorem.

Fourier Transforms
19.1
An Algebra Of Special Functions
First recall the following deﬁnition of a polynomial.
Deﬁnition 19.1 α = (α1, · · ·, αn) for α1 · · · αn positive integers is called a multi-
index. For α a multi-index, |α| ≡α1 + · · · + αn and if x ∈Rn,
x = (x1, · · ·, xn) ,
and f a function, deﬁne
xα ≡xα1
1 xα2
2 · · · xαn
n .
A polynomial in n variables of degree m is a function of the form
p (x) =
X
|α|≤m
aαxα.
Here α is a multi-index as just described and aα ∈C. Also deﬁne for α = (α1, ···, αn)
a multi-index
Dαf (x) ≡
∂|α|f
∂xα1
1 ∂xα2
2 · · · ∂xαn
n
.
Deﬁnition 19.2 Deﬁne G1 to be the functions of the form p (x) e−a|x|2 where a > 0
and p (x) is a polynomial. Let G be all ﬁnite sums of functions in G1. Thus G is an
algebra of functions which has the property that if f ∈G then f ∈G.
It is always assumed, unless stated otherwise that the measure will be Lebesgue
measure.
Lemma 19.3 G is dense in C0 (Rn) with respect to the norm,
||f||∞≡sup {|f (x)| : x ∈Rn}
517

518
FOURIER TRANSFORMS
Proof: By the Weierstrass approximation theorem, it suﬃces to show G sep-
arates the points and annihilates no point. It was already observed in the above
deﬁnition that f ∈G whenever f ∈G. If y1 ̸= y2 suppose ﬁrst that |y1| ̸= |y2| .
Then in this case, you can let f (x) ≡e−|x|2 and f ∈G and f (y1) ̸= f (y2). If
|y1| = |y2| , then suppose y1k ̸= y2k. This must happen for some k because y1 ̸= y2.
Then let f (x) ≡xke−|x|2.
Thus G separates points. Now e−|x|2 is never equal to
zero and so G annihilates no point of Rn. This proves the lemma.
These functions are clearly quite specialized. Therefore, the following theorem
is somewhat surprising.
Theorem 19.4 For each p ≥1, p < ∞, G is dense in Lp (Rn).
Proof: Let f ∈Lp (Rn) . Then there exists g ∈Cc (Rn) such that ||f −g||p < ε.
Now let b > 0 be large enough that
Z
Rn
³
e−b|x|2´p
dx < εp.
Then x →g (x) eb|x|2 is in Cc (Rn) ⊆C0 (Rn) . Therefore, from Lemma 19.3 there
exists ψ ∈G such that
¯¯¯
¯¯¯geb|·|2 −ψ
¯¯¯
¯¯¯
∞< 1
Therefore, letting φ (x) ≡e−b|x|2ψ (x) it follows that φ ∈G and for all x ∈Rn,
|g (x) −φ (x)| < e−b|x|2
Therefore,
µZ
Rn |g (x) −φ (x)|p dx
¶1/p
≤
µZ
Rn
³
e−b|x|2´p
dx
¶1/p
< ε.
It follows
||f −φ||p ≤||f −g||p + ||g −φ||p < 2ε.
Since ε > 0 is arbitrary, this proves the theorem.
The following lemma is also interesting even if it is obvious.
Lemma 19.5 For ψ ∈G , p a polynomial, and α, β multiindices, Dαψ ∈G and
pψ ∈G. Also
sup{|xβDαψ(x)| : x ∈Rn} < ∞
19.2
Fourier Transforms Of Functions In G
Deﬁnition 19.6 For ψ ∈G Deﬁne the Fourier transform, F and the inverse
Fourier transform, F −1 by
Fψ(t) ≡(2π)−n/2
Z
Rn e−it·xψ(x)dx,

19.2.
FOURIER TRANSFORMS OF FUNCTIONS IN G
519
F −1ψ(t) ≡(2π)−n/2
Z
Rn eit·xψ(x)dx.
where t · x ≡Pn
i=1 tixi.Note there is no problem with this deﬁnition because ψ is in
L1 (Rn) and therefore,
¯¯eit·xψ(x)
¯¯ ≤|ψ(x)| ,
an integrable function.
One reason for using the functions, G is that it is very easy to compute the
Fourier transform of these functions. The ﬁrst thing to do is to verify F and F −1
map G to G and that F −1 ◦F (ψ) = ψ.
Lemma 19.7 The following formulas are true
Z
R
e−c(x+it)2dx =
Z
R
e−c(x−it)2dx =
√π
√c ,
(19.1)
Z
Rn e−c(x+it)·(x+it)dx =
Z
Rn e−c(x−it)·(x−it)dx =
µ√π
√c
¶n
,
(19.2)
Z
R
e−ct2e−istdt =
Z
R
e−ct2eistdt = e−s2
4c
√π
√c ,
(19.3)
Z
Rn e−c|t|2e−is·tdt =
Z
Rn e−c|t|2eis·tdt = e−|s|2
4c
µ√π
√c
¶n
.
(19.4)
Proof: Consider the ﬁrst one. Simple manipulations yield
H (t) ≡
Z
R
e−c(x+it)2dx = ect2 Z
R
e−cx2 cos (2cxt) dx.
Now using the dominated convergence theorem to justify passing derivatives inside
the integral where necessary and using integration by parts,
H′ (t)
=
2ctect2 Z
R
e−cx2 cos (2cxt) dx −ect2 Z
R
e−cx2 sin (2cxt) 2xcdx
=
2ctH (t) −ect22ct
Z
R
e−cx2 cos (2cxt) dx = 2ct (H (t) −H (t)) = 0
and so H (t) = H (0) =
R
R e−cx2dx ≡I. Thus
I2 =
Z
R2 e−c(x2+y2)dxdy =
Z ∞
0
Z 2π
0
e−cr2rdθdr = π
c .
Therefore, I = √π/√c. Since the sign of t is unimportant, this proves 19.1. This
also proves 19.2 after writing as iterated integrals.

520
FOURIER TRANSFORMS
Consider 19.3.
Z
R
e−ct2eistdt
=
Z
R
e
−c
³
t2−ist
c +( is
2c)
2´
e−s2
4c dt
=
e−s2
4c
Z
R
e−c(t−is
2c)
2
dt = e−s2
4c
√π
√c .
Changing the variable t →−t gives the other part of 19.3.
Finally 19.4 follows from using iterated integrals.
With these formulas, it is easy to verify F, F −1 map G to G and F ◦F −1 =
F −1 ◦F = id.
Theorem 19.8 Each of F and F −1 map G to G.
Also F −1 ◦F (ψ) = ψ and
F ◦F −1 (ψ) = ψ.
Proof: The ﬁrst claim will be shown if it is shown that Fψ ∈G for ψ (x) =
xαe−b|x|2 because an arbitrary function of G is a ﬁnite sum of scalar multiples of
functions such as ψ. Using Lemma 19.7,
Fψ (t)
≡
µ 1
2π
¶n/2 Z
Rn e−it·xxαe−b|x|2dx
=
µ 1
2π
¶n/2
(i)−|α| Dα
t
µZ
Rn e−it·xe−b|x|2dx
¶
=
µ 1
2π
¶n/2
(i)−|α| Dα
t
µ
e−|t|2
2b
µ√π
√
b
¶n¶
and this is clearly in G because it equals a polynomial times e−|t|2
2b . It remains
to verify the other assertion. As in the ﬁrst case, it suﬃces to consider ψ (x) =
xαe−b|x|2. Using Lemma 19.7 and ordinary integration by parts on the iterated
integrals,
R
Rn e−c|t|2eis·tdt = e−|s|2
2c
³ √π
√c
´n
,
F −1 ◦F (ψ) (s)
≡
µ 1
2π
¶n/2 Z
Rn eis·t
µ 1
2π
¶n/2 Z
Rn e−it·xxαe−b|x|2dxdt
=
µ 1
2π
¶n Z
Rn eis·t (−i)−|α| Dα
t
µZ
Rn e−it·xe−b|x|2dxdt
¶
=
µ 1
2π
¶n/2 Z
Rn eis·t
µ 1
2π
¶n/2
(−i)−|α| Dα
t
µ
e−|t|2
4b
µ√π
√
b
¶n¶
dt

19.3.
FOURIER TRANSFORMS OF JUST ABOUT ANYTHING
521
=
µ 1
2π
¶n µ√π
√
b
¶n
(−i)−|α|
Z
Rn eis·tDα
t
µ
e−|t|2
4b
¶
dt
=
µ 1
2π
¶n µ√π
√
b
¶n
(−i)−|α| (−1)|α| sα (i)|α|
Z
Rn eis·te−|t|2
4b dt
=
µ 1
2π
¶n µ√π
√
b
¶n
sα
Z
Rn eis·te−|t|2
4b dt
=
µ 1
2π
¶n µ√π
√
b
¶n
sαe−
|s|2
4(1/(4b))
Ã
√π
p
1/ (4b)
!n
=
µ 1
2π
¶n µ√π
√
b
¶n
sαe−b|s|2 ³√π2
√
b
´n
= sαe−b|s|2 = ψ (s) .
This little computation proves the theorem. The other case is entirely similar.
19.3
Fourier Transforms Of Just About Anything
Deﬁnition 19.9 Let G∗denote the vector space of linear functions deﬁned on G
which have values in C. Thus T ∈G∗means T : G →C and T is linear,
T (aψ + bφ) = aT (ψ) + bT (φ) for all a, b ∈C,
ψ, φ ∈G
Let ψ ∈G. Then deﬁne Tψ ∈G∗by
Tψ (φ) ≡
Z
Rn ψ (x) φ (x) dx
Lemma 19.10 The following is obtained for all φ, ψ ∈G.
TF ψ (φ) = Tψ (Fφ) , TF −1ψ (φ) = Tψ
¡
F −1φ
¢
Also if ψ ∈G and Tψ = 0, then ψ = 0.
Proof:
TF ψ (φ)
≡
Z
Rn Fψ (t) φ (t) dt
=
Z
Rn
µ 1
2π
¶n/2 Z
Rn e−it·xψ(x)dxφ (t) dt
=
Z
Rn ψ(x)
µ 1
2π
¶n/2 Z
Rn e−it·xφ (t) dtdx
=
Z
Rn ψ(x)Fφ (x) dx ≡Tψ (Fφ)
The other claim is similar.

522
FOURIER TRANSFORMS
Suppose now Tψ = 0. Then
Z
Rn ψφdx = 0
for all φ ∈G. Therefore, this is true for φ = ψ and so ψ = 0. This proves the lemma.
From now on regard G ⊆G∗and for ψ ∈G write ψ (φ) instead of Tψ (φ) . It was
just shown that with this interpretation1,
Fψ (φ) = ψ (F (φ)) , F −1ψ (φ) = ψ
¡
F −1φ
¢
.
This lemma suggests a way to deﬁne the Fourier transform of something in G∗.
Deﬁnition 19.11 For T ∈G∗, deﬁne FT, F −1T ∈G∗by
FT (φ) ≡T (Fφ) , F −1T (φ) ≡T
¡
F −1φ
¢
Lemma 19.12 F and F −1 are both one to one, onto, and are inverses of each
other.
Proof: First note F and F −1 are both linear. This follows directly from the
deﬁnition. Suppose now FT = 0. Then FT (φ) = T (Fφ) = 0 for all φ ∈G. But F
and F −1 map G onto G because if ψ ∈G, then ψ = F
¡
F −1 (ψ)
¢
. Therefore, T = 0
and so F is one to one. Similarly F −1 is one to one. Now
F −1 (FT) (φ) ≡(FT)
¡
F −1φ
¢
≡T
¡
F
¡
F −1 (φ)
¢¢
= Tφ.
Therefore, F −1 ◦F (T) = T. Similarly, F ◦F −1 (T) = T. Thus both F and F −1 are
one to one and onto and are inverses of each other as suggested by the notation.
This proves the lemma.
Probably the most interesting things in G∗are functions of various kinds. The
following lemma has to do with this situation.
Lemma 19.13 If f ∈L1
loc (Rn) and
R
Rn fφdx = 0 for all φ ∈Cc (Rn), then f =
0 a.e.
Proof: First suppose f ≥0. Let
E ≡{x :f (x) ≥r}, ER ≡E ∩B (0,R).
Let Km be an increasing sequence of compact sets and let Vm be a decreasing
sequence of open sets satisfying
Km ⊆ER ⊆Vm, mn (Vm) ≤mn (Km) + 2−m, V1 ⊆B (0,R) .
1This is not all that diﬀerent from what was done with the derivative. Remember when you
consider the derivative of a function of one variable, in elementary courses you think of it as a
number but thinking of it as a linear transformation acting on R is better because this leads to
the concept of a derivative which generalizes to functions of many variables. So it is here. You
can think of ψ ∈G as simply an element of G but it is better to think of it as an element of G∗as
just described.

19.3.
FOURIER TRANSFORMS OF JUST ABOUT ANYTHING
523
Therefore,
mn (Vm \ Km) ≤2−m.
Let
φm ∈Cc (Vm) , Km ≺φm ≺Vm.
Then φm (x) →XER (x) a.e. because the set where φm (x) fails to converge to this
set is contained in the set of all x which are in inﬁnitely many of the sets Vm \ Km.
This set has measure zero because
∞
X
m=1
mn (Vm \ Km) < ∞
and so, by the dominated convergence theorem,
0 = lim
m→∞
Z
Rn fφmdx = lim
m→∞
Z
V1
fφmdx =
Z
ER
fdx ≥rm (ER).
Thus, mn (ER) = 0 and therefore mn (E) = limR→∞mn (ER) = 0. Since r > 0 is
arbitrary, it follows
mn ([f > 0]) = ∪∞
k=1mn
¡£
f > k−1¤¢
= 0.
Now suppose f has values in R. Let E+ = [f ≥0] and E−= [f < 0] . Thus
these are two measurable sets. As in the ﬁrst part, let Km and Vm be sequences
of compact and open sets such that Km ⊆E+ ∩B (0, R) ⊆Vm ⊆B (0, R) and let
Km ≺φm ≺Vm with mn (Vm \ Km) < 2−m. Thus φm ∈Cc (Rn) and the sequence
converges pointwise to XE+∩B(0,R). Then by the dominated convergence theorem,
if ψ is any function in Cc (Rn)
0 =
Z
fφmψdmn →
Z
fψXE+∩B(0,R)dmn.
Hence, letting R →∞,
Z
fψXE+dmn =
Z
f+ψdmn = 0
Since ψ is arbitrary, the ﬁrst part of the argument applies to f+ and implies f+ = 0.
Similarly f−= 0. Finally, if f is complcx valued, the assumptions mean
Z
Re (f) φdmn = 0,
Z
Im (f) φdmn = 0
for all φ ∈Cc (Rn) and so both Re (f) , Im (f) equal zero a.e.
This proves the
lemma.
Corollary 19.14 Let f ∈L1 (Rn) and suppose
Z
Rn f (x) φ (x) dx = 0
for all φ ∈G. Then f = 0 a.e.

524
FOURIER TRANSFORMS
Proof: Let ψ ∈Cc (Rn) . Then by the Stone Weierstrass approximation theo-
rem, there exists a sequence of functions, {φk} ⊆G such that φk →ψ uniformly.
Then by the dominated convergence theorem,
Z
fψdx = lim
k→∞
Z
fφkdx = 0.
By Lemma 19.13 f = 0.
The next theorem is the main result of this sort.
Theorem 19.15 Let f ∈Lp (Rn) , p ≥1, or suppose f is measurable and has
polynomial growth,
|f (x)| ≤K
³
1 + |x|2´m
for some m ∈N. Then if
Z
fψdx = 0
for all ψ ∈G then it follows f = 0.
Proof: The case where f ∈L1 (Rn) was dealt with in Corollary 19.14. Suppose
f ∈Lp (Rn) for p > 1. Then by Holder’s inequality and the density of G in Lp′ (Rn) ,
it follows that
R
fgdx = 0 for all g ∈Lp′ (Rn) . By the Riesz representation theorem,
f = 0.
It remains to consider the case where f has polynomial growth.
Thus x →
f (x) e−|x|2 ∈L1 (Rn) . Therefore, for all ψ ∈G,
0 =
Z
f (x) e−|x|2ψ (x) dx
because e−|x|2ψ (x) ∈G. Therefore, by the ﬁrst part, f (x) e−|x|2 = 0 a.e.
The following theorem shows that you can consider most functions you are likely
to encounter as elements of G∗.
Theorem 19.16 Let f be a measurable function with polynomial growth,
|f (x)| ≤C
³
1 + |x|2´N
for some N,
or let f ∈Lp (Rn) for some p ∈[1, ∞]. Then f ∈G∗if
f (φ) ≡
Z
fφdx.
Proof: Let f have polynomial growth ﬁrst. Then the above integral is clearly
well deﬁned and so in this case, f ∈G∗.
Next suppose f ∈Lp (Rn) with ∞> p ≥1. Then it is clear again that the
above integral is well deﬁned because of the fact that φ is a sum of polynomials

19.3.
FOURIER TRANSFORMS OF JUST ABOUT ANYTHING
525
times exponentials of the form e−c|x|2 and these are in Lp′ (Rn). Also φ →f (φ) is
clearly linear in both cases. This proves the theorem.
This has shown that for nearly any reasonable function, you can deﬁne its Fourier
transform as described above. Also you should note that G∗includes C0 (Rn)′ , the
space of complex measures whose total variation are Radon measures. It is especially
interesting when the Fourier transform yields another function of some sort.
19.3.1
Fourier Transforms Of Functions In L1 (Rn)
First suppose f ∈L1 (Rn) .
Theorem 19.17 Let f ∈L1 (Rn) . Then Ff (φ) =
R
Rn gφdt where
g (t) =
µ 1
2π
¶n/2 Z
Rn e−it·xf (x) dx
and F −1f (φ) =
R
Rn gφdt where g (t) =
¡ 1
2π
¢n/2 R
Rn eit·xf (x) dx. In short,
Ff(t) ≡(2π)−n/2
Z
Rn e−it·xf(x)dx,
F −1f(t) ≡(2π)−n/2
Z
Rn eit·xf(x)dx.
Proof: From the deﬁnition and Fubini’s theorem,
Ff (φ)
≡
Z
Rn f (t) Fφ (t) dt =
Z
Rn f (t)
µ 1
2π
¶n/2 Z
Rn e−it·xφ (x) dxdt
=
Z
Rn
Ãµ 1
2π
¶n/2 Z
Rn f (t) e−it·xdt
!
φ (x) dx.
Since φ ∈G is arbitrary, it follows from Theorem 19.15 that Ff (x) is given by the
claimed formula. The case of F −1 is identical.
Here are interesting properties of these Fourier transforms of functions in L1.
Theorem 19.18 If f ∈L1 (Rn) and ||fk −f||1 →0, then Ffk and F −1fk converge
uniformly to Ff and F −1f respectively. If f ∈L1 (Rn), then F −1f and Ff are
both continuous and bounded. Also,
lim
|x|→∞F −1f(x) =
lim
|x|→∞Ff(x) = 0.
(19.5)
Furthermore, for f ∈L1 (Rn) both Ff and F −1f are uniformly continuous.

526
FOURIER TRANSFORMS
Proof: The ﬁrst claim follows from the following inequality.
|Ffk (t) −Ff (t)|
≤
(2π)−n/2
Z
Rn
¯¯e−it·xfk(x) −e−it·xf(x)
¯¯ dx
=
(2π)−n/2
Z
Rn |fk (x) −f (x)| dx
=
(2π)−n/2 ||f −fk||1 .
which a similar argument holding for F −1.
Now consider the second claim of the theorem.
|Ff (t) −Ff (t′)| ≤(2π)−n/2
Z
Rn
¯¯¯e−it·x −e−it′·x¯¯¯ |f(x)| dx
The integrand is bounded by 2 |f (x)|, a function in L1 (Rn) and converges to 0 as
t′ →t and so the dominated convergence theorem implies Ff is continuous. To see
Ff (t) is uniformly bounded,
|Ff (t)| ≤(2π)−n/2
Z
Rn |f(x)| dx < ∞.
A similar argument gives the same conclusions for F −1.
It remains to verify 19.5 and the claim that Ff and F −1f are uniformly contin-
uous.
|Ff (t)| ≤
¯¯¯¯(2π)−n/2
Z
Rn e−it·xf(x)dx
¯¯¯¯
Now let ε > 0 be given and let g ∈C∞
c (Rn) such that (2π)−n/2 ||g −f||1 < ε/2.
Then
|Ff (t)|
≤
(2π)−n/2
Z
Rn |f(x) −g (x)| dx
+
¯¯¯¯(2π)−n/2
Z
Rn e−it·xg(x)dx
¯¯¯¯
≤
ε/2 +
¯¯¯¯(2π)−n/2
Z
Rn e−it·xg(x)dx
¯¯¯¯ .
Now integrating by parts, it follows that for ||t||∞≡max {|tj| : j = 1, · · ·, n} > 0
|Ff (t)| ≤ε/2 + (2π)−n/2
¯¯¯¯¯¯
1
||t||∞
Z
Rn
n
X
j=1
¯¯¯¯
∂g (x)
∂xj
¯¯¯¯ dx
¯¯¯¯¯¯
(19.6)
and this last expression converges to zero as ||t||∞→∞. The reason for this is that
if tj ̸= 0, integration by parts with respect to xj gives
(2π)−n/2
Z
Rn e−it·xg(x)dx = (2π)−n/2
1
−itj
Z
Rn e−it·x ∂g (x)
∂xj
dx.

19.3.
FOURIER TRANSFORMS OF JUST ABOUT ANYTHING
527
Therefore, choose the j for which ||t||∞= |tj| and the result of 19.6 holds. There-
fore, from 19.6, if ||t||∞is large enough, |Ff (t)| < ε. Similarly, lim||t||→∞F −1 (t) =
0. Consider the claim about uniform continuity. Let ε > 0 be given. Then there
exists R such that if ||t||∞> R, then |Ff (t)| < ε
2. Since Ff is continuous, it is
uniformly continuous on the compact set, [−R −1, R + 1]n. Therefore, there exists
δ1 such that if ||t −t′||∞< δ1 for t′, t ∈[−R −1, R + 1]n, then
|Ff (t) −Ff (t′)| < ε/2.
(19.7)
Now let 0 < δ < min (δ1, 1) and suppose ||t −t′||∞< δ. If both t, t′ are contained
in [−R, R]n, then 19.7 holds. If t ∈[−R, R]n and t′ /∈[−R, R]n, then both are
contained in [−R −1, R + 1]n and so this veriﬁes 19.7 in this case. The other case
is that neither point is in [−R, R]n and in this case,
|Ff (t) −Ff (t′)|
≤
|Ff (t)| + |Ff (t′)|
<
ε
2 + ε
2 = ε.
This proves the theorem.
There is a very interesting relation between the Fourier transform and convolu-
tions.
Theorem 19.19 Let f, g ∈L1(Rn). Then f∗g ∈L1 and F(f∗g) = (2π)n/2 FfFg.
Proof: Consider
Z
Rn
Z
Rn |f (x −y) g (y)| dydx.
The function, (x, y) →|f (x −y) g (y)| is Lebesgue measurable and so by Fubini’s
theorem,
Z
Rn
Z
Rn |f (x −y) g (y)| dydx
=
Z
Rn
Z
Rn |f (x −y) g (y)| dxdy
=
||f||1 ||g||1 < ∞.
It follows that for a.e. x,
R
Rn |f (x −y) g (y)| dy < ∞and for each of these values
of x, it follows that
R
Rn f (x −y) g (y) dy exists and equals a function of x which is
in L1 (Rn) , f ∗g (x). Now
F(f ∗g) (t)
≡
(2π)−n/2
Z
Rn e−it·xf ∗g (x) dx
=
(2π)−n/2
Z
Rn e−it·x
Z
Rn f (x −y) g (y) dydx
=
(2π)−n/2
Z
Rn e−it·yg (y)
Z
Rn e−it·(x−y)f (x −y) dxdy
=
(2π)n/2 Ff (t) Fg (t) .
There are many other considerations involving Fourier transforms of functions
in L1 (Rn).

528
FOURIER TRANSFORMS
19.3.2
Fourier Transforms Of Functions In L2 (Rn)
Consider Ff and F −1f for f ∈L2(Rn). First note that the formula given for Ff
and F −1f when f ∈L1 (Rn) will not work for f ∈L2(Rn) unless f is also in L1(Rn).
Recall that a + ib = a −ib.
Theorem 19.20 For φ ∈G, ||Fφ||2 = ||F −1φ||2 = ||φ||2.
Proof: First note that for ψ ∈G,
F(ψ) = F −1(ψ) , F −1(ψ) = F(ψ).
(19.8)
This follows from the deﬁnition. For example,
Fψ (t)
=
(2π)−n/2
Z
Rn e−it·xψ (x) dx
=
(2π)−n/2
Z
Rn eit·xψ (x) dx
Let φ, ψ ∈G. It was shown above that
Z
Rn(Fφ)ψ(t)dt =
Z
Rn φ(Fψ)dx.
Similarly,
Z
Rn φ(F −1ψ)dx =
Z
Rn(F −1φ)ψdt.
(19.9)
Now, 19.8 - 19.9 imply
Z
Rn |φ|2dx
=
Z
Rn φF −1(Fφ)dx
=
Z
Rn φF(Fφ)dx
=
Z
Rn Fφ(Fφ)dx
=
Z
Rn |Fφ|2dx.
Similarly
||φ||2 = ||F −1φ||2.
This proves the theorem.
Lemma 19.21 Let f ∈L2 (Rn) and let φk →f in L2 (Rn) where φk ∈G. (Such
a sequence exists because of density of G in L2 (Rn).) Then Ff and F −1f are both
in L2 (Rn) and the following limits take place in L2.
lim
k→∞F (φk) = F (f) , lim
k→∞F −1 (φk) = F −1 (f) .

19.3.
FOURIER TRANSFORMS OF JUST ABOUT ANYTHING
529
Proof: Let ψ ∈G be given. Then
Ff (ψ)
≡
f (Fψ) ≡
Z
Rn f (x) Fψ (x) dx
=
lim
k→∞
Z
Rn φk (x) Fψ (x) dx = lim
k→∞
Z
Rn Fφk (x) ψ (x) dx.
Also by Theorem 19.20 {Fφk}∞
k=1 is Cauchy in L2 (Rn) and so it converges to some
h ∈L2 (Rn). Therefore, from the above,
Ff (ψ) =
Z
Rn h (x) ψ (x)
which shows that F (f) ∈L2 (Rn) and h = F (f) . The case of F −1 is entirely
similar. This proves the lemma.
Since Ff and F −1f are in L2 (Rn) , this also proves the following theorem.
Theorem 19.22 If f ∈L2(Rn), Ff and F −1f are the unique elements of L2 (Rn)
such that for all φ ∈G,
Z
Rn Ff(x)φ(x)dx =
Z
Rn f(x)Fφ(x)dx,
(19.10)
Z
Rn F −1f(x)φ(x)dx =
Z
Rn f(x)F −1φ(x)dx.
(19.11)
Theorem 19.23 (Plancherel)
||f||2 = ||Ff||2 = ||F −1f||2.
(19.12)
Proof: Use the density of G in L2 (Rn) to obtain a sequence, {φk} converging
to f in L2 (Rn). Then by Lemma 19.21
||Ff||2 = lim
k→∞||Fφk||2 = lim
k→∞||φk||2 = ||f||2 .
Similarly,
||f||2 = ||F −1f||2.
This proves the theorem.
The following corollary is a simple generalization of this. To prove this corollary,
use the following simple lemma which comes as a consequence of the Cauchy Schwarz
inequality.
Lemma 19.24 Suppose fk →f in L2 (Rn) and gk →g in L2 (Rn). Then
lim
k→∞
Z
Rn fkgkdx =
Z
Rn fgdx

530
FOURIER TRANSFORMS
Proof:
¯¯¯¯
Z
Rn fkgkdx −
Z
Rn fgdx
¯¯¯¯ ≤
¯¯¯¯
Z
Rn fkgkdx −
Z
Rn fkgdx
¯¯¯¯ +
¯¯¯¯
Z
Rn fkgdx −
Z
Rn fgdx
¯¯¯¯
≤||fk||2 ||g −gk||2 + ||g||2 ||fk −f||2 .
Now ||fk||2 is a Cauchy sequence and so it is bounded independent of k. Therefore,
the above expression is smaller than ε whenever k is large enough. This proves the
lemma.
Corollary 19.25 For f, g ∈L2(Rn),
Z
Rn fgdx =
Z
Rn Ff Fgdx =
Z
Rn F −1f F −1gdx.
Proof: First note the above formula is obvious if f, g ∈G. To see this, note
Z
Rn Ff Fgdx
=
Z
Rn Ff (x)
1
(2π)n/2
Z
Rn e−ix·tg (t) dtdx
=
Z
Rn
1
(2π)n/2
Z
Rn eix·tFf (x) dxg (t)dt
=
Z
Rn
¡
F −1 ◦F
¢
f (t) g (t)dt
=
Z
Rn f (t) g (t)dt.
The formula with F −1 is exactly similar.
Now to verify the corollary, let φk →f in L2 (Rn) and let ψk →g in L2 (Rn).
Then by Lemma 19.21
Z
Rn Ff Fgdx
=
lim
k→∞
Z
Rn Fφk Fψkdx
=
lim
k→∞
Z
Rn φkψkdx
=
Z
Rn fgdx
A similar argument holds for F −1.This proves the corollary.
How does one compute Ff and F −1f ?
Theorem 19.26 For f ∈L2(Rn), let fr = fXEr where Er is a bounded measurable
set with Er ↑Rn. Then the following limits hold in L2 (Rn) .
Ff = lim
r→∞Ffr , F −1f = lim
r→∞F −1fr.

19.3.
FOURIER TRANSFORMS OF JUST ABOUT ANYTHING
531
Proof: ||f −fr||2 →0 and so ||Ff −Ffr||2 →0 and ||F −1f −F −1fr||2 →0 by
Plancherel’s Theorem. This proves the theorem.
What are Ffr and F −1fr? Let φ ∈G
Z
Rn Ffrφdx
=
Z
Rn frFφdx
=
(2π)−n
2
Z
Rn
Z
Rn fr(x)e−ix·yφ(y)dydx
=
Z
Rn[(2π)−n
2
Z
Rn fr(x)e−ix·ydx]φ(y)dy.
Since this holds for all φ ∈G, a dense subset of L2(Rn), it follows that
Ffr(y) = (2π)−n
2
Z
Rn fr(x)e−ix·ydx.
Similarly
F −1fr(y) = (2π)−n
2
Z
Rn fr(x)eix·ydx.
This shows that to take the Fourier transform of a function in L2 (Rn), it suﬃces
to take the limit as r →∞in L2 (Rn) of (2π)−n
2 R
Rn fr(x)e−ix·ydx.
A similar
procedure works for the inverse Fourier transform.
Note this reduces to the earlier deﬁnition in case f ∈L1 (Rn). Now consider the
convolution of a function in L2 with one in L1.
Theorem 19.27 Let h ∈L2 (Rn) and let f ∈L1 (Rn). Then h ∗f ∈L2 (Rn),
F −1 (h ∗f) = (2π)n/2 F −1hF −1f,
F (h ∗f) = (2π)n/2 FhFf,
and
||h ∗f||2 ≤||h||2 ||f||1 .
(19.13)
Proof: An application of Minkowski’s inequality yields
ÃZ
Rn
µZ
Rn |h (x −y)| |f (y)| dy
¶2
dx
!1/2
≤||f||1 ||h||2 .
(19.14)
Hence
R
|h (x −y)| |f (y)| dy < ∞a.e. x and
x →
Z
h (x −y) f (y) dy
is in L2 (Rn). Let Er ↑Rn, m (Er) < ∞. Thus,
hr ≡XErh ∈L2 (Rn) ∩L1 (Rn),

532
FOURIER TRANSFORMS
and letting φ ∈G,
Z
F (hr ∗f) (φ) dx
≡
Z
(hr ∗f) (Fφ) dx
=
(2π)−n/2
Z Z Z
hr (x −y) f (y) e−ix·tφ (t) dtdydx
=
(2π)−n/2
Z Z µZ
hr (x −y) e−i(x−y)·tdx
¶
f (y) e−iy·tdyφ (t) dt
=
Z
(2π)n/2 Fhr (t) Ff (t) φ (t) dt.
Since φ is arbitrary and G is dense in L2 (Rn),
F (hr ∗f) = (2π)n/2 FhrFf.
Now by Minkowski’s Inequality, hr ∗f →h ∗f in L2 (Rn) and also it is clear that
hr →h in L2 (Rn) ; so, by Plancherel’s theorem, you may take the limit in the above
and conclude
F (h ∗f) = (2π)n/2 FhFf.
The assertion for F −1 is similar and 19.13 follows from 19.14.
19.3.3
The Schwartz Class
The problem with G is that it does not contain C∞
c (Rn). I have used it in presenting
the Fourier transform because the functions in G have a very speciﬁc form which
made some technical details work out easier than in any other approach I have
seen. The Schwartz class is a larger class of functions which does contain C∞
c (Rn)
and also has the same nice properties as G. The functions in the Schwartz class
are inﬁnitely diﬀerentiable and they vanish very rapidly as |x| →∞along with all
their partial derivatives. This is the description of these functions, not a speciﬁc
form involving polynomials times e−α|x|2. To describe this precisely requires some
notation.
Deﬁnition 19.28 f ∈S, the Schwartz class, if f ∈C∞(Rn) and for all positive
integers N,
ρN(f) < ∞
where
ρN(f) = sup{(1 + |x|2)N|Dαf(x)| : x ∈Rn , |α| ≤N}.
Thus f ∈S if and only if f ∈C∞(Rn) and
sup{|xβDαf(x)| : x ∈Rn} < ∞
(19.15)
for all multi indices α and β.

19.3.
FOURIER TRANSFORMS OF JUST ABOUT ANYTHING
533
Also note that if f ∈S, then p(f) ∈S for any polynomial, p with p(0) = 0 and
that
S ⊆Lp(Rn) ∩L∞(Rn)
for any p ≥1. To see this assertion about the p (f), it suﬃces to consider the case
of the product of two elements of the Schwartz class. If f, g ∈S, then Dα (fg) is
a ﬁnite sum of derivatives of f times derivatives of g. Therefore, ρN (fg) < ∞for
all N. You may wonder about examples of things in S. Clearly any function in
C∞
c (Rn) is in S. However there are other functions in S. For example e−|x|2 is in
S as you can verify for yourself and so is any function from G. Note also that the
density of Cc (Rn) in Lp (Rn) shows that S is dense in Lp (Rn) for every p.
Recall the Fourier transform of a function in L1 (Rn) is given by
Ff(t) ≡(2π)−n/2
Z
Rn e−it·xf(x)dx.
Therefore, this gives the Fourier transform for f ∈S. The nice property which S
has in common with G is that the Fourier transform and its inverse map S one to
one onto S. This means I could have presented the whole of the above theory as
well as what follows in terms of S and its algebraic dual, S∗rather than in terms
of G and G∗. However, it is more technical. Nevertheless, letting S play the role
of G in the above is convenient in certain applications because it is easier to reduce
to S than G. I will make use of this simple observation whenever it will simplify a
presentation. The fundamental result which makes it possible is the following.
Theorem 19.29 If f ∈S, then Ff and F −1f are also in S.
Proof: To begin with, let α = ej = (0, 0, · · ·, 1, 0, · · ·, 0), the 1 in the jth slot.
F −1f(t + hej) −F −1f(t)
h
= (2π)−n/2
Z
Rn eit·xf(x)(eihxj −1
h
)dx.
(19.16)
Consider the integrand in 19.16.
¯¯¯¯eit·xf(x)(eihxj −1
h
)
¯¯¯¯
=
|f (x)|
¯¯¯¯(ei(h/2)xj −e−i(h/2)xj
h
)
¯¯¯¯
=
|f (x)|
¯¯¯¯
i sin ((h/2) xj)
(h/2)
¯¯¯¯
≤
|f (x)| |xj|
and this is a function in L1(Rn) because f ∈S.
Therefore by the Dominated
Convergence Theorem,
∂F −1f(t)
∂tj
=
(2π)−n/2
Z
Rn eit·xixjf(x)dx
=
i(2π)−n/2
Z
Rn eit·xxejf(x)dx.

534
FOURIER TRANSFORMS
Now xejf(x) ∈S and so one can continue in this way and take derivatives indeﬁ-
nitely. Thus F −1f ∈C∞(Rn) and from the above argument,
DαF −1f(t) =(2π)−n/2
Z
Rn eit·x(ix)αf(x)dx.
To complete showing F −1f ∈S,
tβDαF −1f(t) =(2π)−n/2
Z
Rn eit·xtβ(ix)af(x)dx.
Integrate this integral by parts to get
tβDαF −1f(t) =(2π)−n/2
Z
Rn i|β|eit·xDβ((ix)af(x))dx.
(19.17)
Here is how this is done.
Z
R
eitjxjt
βj
j (ix)αf(x)dxj
=
eitjxj
itj
t
βj
j (ix)αf(x) |∞
−∞+
i
Z
R
eitjxjt
βj−1
j
Dej((ix)αf(x))dxj
where the boundary term vanishes because f ∈S. Returning to 19.17, use the fact
that |eia| = 1 to conclude
|tβDαF −1f(t)| ≤C
Z
Rn |Dβ((ix)af(x))|dx < ∞.
It follows F −1f ∈S. Similarly Ff ∈S whenever f ∈S.
Theorem 19.30 Let ψ ∈S. Then (F ◦F −1)(ψ) = ψ and (F −1 ◦F)(ψ) = ψ
whenever ψ ∈S. Also F and F −1 map S one to one and onto S.
Proof: The ﬁrst claim follows from the fact that F and F −1 are inverses of each
other which was established above. For the second, let ψ ∈S. Then ψ = F
¡
F −1ψ
¢
.
Thus F maps S onto S. If Fψ = 0, then do F −1 to both sides to conclude ψ = 0.
Thus F is one to one and onto. Similarly, F −1 is one to one and onto.
Note the above equations involving F and F −1 hold pointwise everywhere be-
cause Fψ and F −1ψ are continuous.
19.3.4
Convolution
To begin with it is necessary to discuss the meaning of φf where f ∈G∗and φ ∈G.
What should it mean? First suppose f ∈Lp (Rn) or measurable with polynomial
growth.
Then φf also has these properties.
Hence, it should be the case that
φf (ψ) =
R
Rn φfψdx =
R
Rn f (φψ) dx. This motivates the following deﬁnition.

19.3.
FOURIER TRANSFORMS OF JUST ABOUT ANYTHING
535
Deﬁnition 19.31 Let T ∈G∗and let φ ∈G. Then φT ≡Tφ ∈G∗will be deﬁned
by
φT (ψ) ≡T (φψ) .
The next topic is that of convolution. It was just shown that
F (f ∗φ) = (2π)n/2 FφFf, F −1 (f ∗φ) = (2π)n/2 F −1φF −1f
whenever f ∈L2 (Rn) and φ ∈G so the same deﬁnition is retained in the general
case because it makes perfect sense and agrees with the earlier deﬁnition.
Deﬁnition 19.32 Let f ∈G∗and let φ ∈G. Then deﬁne the convolution of f with
an element of G as follows.
f ∗φ ≡(2π)n/2 F −1 (FφFf) ∈G∗
There is an obvious question. With this deﬁnition, is it true that F −1 (f ∗φ) =
(2π)n/2 F −1φF −1f as it was earlier?
Theorem 19.33 Let f ∈G∗and let φ ∈G.
F (f ∗φ) = (2π)n/2 FφFf,
(19.18)
F −1 (f ∗φ) = (2π)n/2 F −1φF −1f.
(19.19)
Proof: Note that 19.18 follows from Deﬁnition 19.32 and both assertions hold
for f ∈G. Consider 19.19. Here is a simple formula involving a pair of functions in
G.
¡
ψ ∗F −1F −1φ
¢
(x)
=
µZ Z Z
ψ (x −y) eiy·y1eiy1·zφ (z) dzdy1dy
¶
(2π)n
=
µZ Z Z
ψ (x −y) e−iy·˜y1e−i˜y1·zφ (z) dzd˜y1dy
¶
(2π)n
=
(ψ ∗FFφ) (x) .
Now for ψ ∈G,
(2π)n/2 F
¡
F −1φF −1f
¢
(ψ) ≡(2π)n/2 ¡
F −1φF −1f
¢
(Fψ) ≡
(2π)n/2 F −1f
¡
F −1φFψ
¢
≡(2π)n/2 f
¡
F −1 ¡
F −1φFψ
¢¢
=
f
³
(2π)n/2 F −1 ¡¡
FF −1F −1φ
¢
(Fψ)
¢´
≡
f
¡
ψ ∗F −1F −1φ
¢
= f (ψ ∗FFφ)
(19.20)

536
FOURIER TRANSFORMS
Also
(2π)n/2 F −1 (FφFf) (ψ) ≡(2π)n/2 (FφFf)
¡
F −1ψ
¢
≡
(2π)n/2 Ff
¡
FφF −1ψ
¢
≡(2π)n/2 f
¡
F
¡
FφF −1ψ
¢¢
=
= f
³
F
³
(2π)n/2 ¡
FφF −1ψ
¢´´
= f
³
F
³
(2π)n/2 ¡
F −1FFφF −1ψ
¢´´
= f
¡
F
¡
F −1 (FFφ ∗ψ)
¢¢
f (FFφ ∗ψ) = f (ψ ∗FFφ) .
(19.21)
The last line follows from the following.
Z
FFφ (x −y) ψ (y) dy
=
Z
Fφ (x −y) Fψ (y) dy
=
Z
Fψ (x −y) Fφ (y) dy
=
Z
ψ (x −y) FFφ (y) dy.
From 19.21 and 19.20 , since ψ was arbitrary,
(2π)n/2 F
¡
F −1φF −1f
¢
= (2π)n/2 F −1 (FφFf) ≡f ∗φ
which shows 19.19.
19.4
Exercises
1. For f ∈L1 (Rn), show that if F −1f ∈L1 or Ff ∈L1, then f equals a
continuous bounded function a.e.
2. Suppose f, g ∈L1(R) and Ff = Fg. Show f = g a.e.
3. Show that if f ∈L1 (Rn) , then lim|x|→∞Ff (x) = 0.
4. ↑Suppose f ∗f = f or f ∗f = 0 and f ∈L1(R). Show f = 0.
5. For this problem deﬁne
R ∞
a f (t) dt ≡limr→∞
R r
a f (t) dt. Note this coincides
with the Lebesgue integral when f ∈L1 (a, ∞). Show
(a)
R ∞
0
sin(u)
u
du = π
2
(b) limr→∞
R ∞
δ
sin(ru)
u
du = 0 whenever δ > 0.
(c) If f ∈L1 (R), then limr→∞
R
R sin (ru) f (u) du = 0.
Hint: For the ﬁrst two, use
1
u =
R ∞
0
e−utdt and apply Fubini’s theorem to
R R
0 sin u
R
R e−utdtdu. For the last part, ﬁrst establish it for f ∈C∞
c (R) and
then use the density of this set in L1 (R) to obtain the result. This is sometimes
called the Riemann Lebesgue lemma.

19.4.
EXERCISES
537
6. ↑Suppose that g ∈L1 (R) and that at some x > 0, g is locally Holder contin-
uous from the right and from the left. This means
lim
r→0+ g (x + r) ≡g (x+)
exists,
lim
r→0+ g (x −r) ≡g (x−)
exists and there exist constants K, δ > 0 and r ∈(0, 1] such that for |x −y| <
δ,
|g (x+) −g (y)| < K |x −y|r
for y > x and
|g (x−) −g (y)| < K |x −y|r
for y < x. Show that under these conditions,
lim
r→∞
2
π
Z ∞
0
sin (ur)
u
µg (x −u) + g (x + u)
2
¶
du
= g (x+) + g (x−)
2
.
7. ↑Let g ∈L1 (R) and suppose g is locally Holder continuous from the right
and from the left at x. Show that then
lim
R→∞
1
2π
Z R
−R
eixt
Z ∞
−∞
e−ityg (y) dydt = g (x+) + g (x−)
2
.
This is very interesting. If g ∈L2 (R), this shows F −1 (Fg) (x) = g(x+)+g(x−)
2
,
the midpoint of the jump in g at the point, x.
In particular, if g ∈G,
F −1 (Fg) = g. Hint: Show the left side of the above equation reduces to
2
π
Z ∞
0
sin (ur)
u
µg (x −u) + g (x + u)
2
¶
du
and then use Problem 6 to obtain the result.
8. ↑A measurable function g deﬁned on (0, ∞) has exponential growth if |g (t)| ≤
Ceηt for some η. For Re (s) > η, deﬁne the Laplace Transform by
Lg (s) ≡
Z ∞
0
e−sug (u) du.
Assume that g has exponential growth as above and is Holder continuous from
the right and from the left at t. Pick γ > η.
Show that
lim
R→∞
1
2π
Z R
−R
eγteiytLg (γ + iy) dy = g (t+) + g (t−)
2
.

538
FOURIER TRANSFORMS
This formula is sometimes written in the form
1
2πi
Z γ+i∞
γ−i∞
estLg (s) ds
and is called the complex inversion integral for Laplace transforms. It can be
used to ﬁnd inverse Laplace transforms. Hint:
1
2π
Z R
−R
eγteiytLg (γ + iy) dy =
1
2π
Z R
−R
eγteiyt
Z ∞
0
e−(γ+iy)ug (u) dudy.
Now use Fubini’s theorem and do the integral from −R to R to get this equal
to
eγt
π
Z ∞
−∞
e−γug (u) sin (R (t −u))
t −u
du
where g is the zero extension of g oﬀ[0, ∞). Then this equals
eγt
π
Z ∞
−∞
e−γ(t−u)g (t −u) sin (Ru)
u
du
which equals
2eγt
π
Z ∞
0
g (t −u) e−γ(t−u) + g (t + u) e−γ(t+u)
2
sin (Ru)
u
du
and then apply the result of Problem 6.
9. Suppose f ∈S. Show F(fxj)(t) = itjFf(t).
10. Let f ∈S and let k be a positive integer.
||f||k,2 ≡(||f||2
2 +
X
|α|≤k
||Dαf||2
2)1/2.
One could also deﬁne
|||f|||k,2 ≡(
Z
Rn |Ff(x)|2(1 + |x|2)kdx)1/2.
Show both || ||k,2 and ||| |||k,2 are norms on S and that they are equivalent.
These are Sobolev space norms. For which values of k does the second norm
make sense? How about the ﬁrst norm?
11. ↑Deﬁne Hk(Rn), k ≥0 by f ∈L2(Rn) such that
(
Z
|Ff(x)|2(1 + |x|2)kdx)
1
2 < ∞,

19.4.
EXERCISES
539
|||f|||k,2 ≡(
Z
|Ff(x)|2(1 + |x|2)kdx)
1
2.
Show Hk(Rn) is a Banach space, and that if k is a positive integer, Hk(Rn)
={ f ∈L2(Rn) : there exists {uj} ⊆G with ||uj −f||2 →0 and {uj} is a
Cauchy sequence in || ||k,2 of Problem 10}. This is one way to deﬁne Sobolev
Spaces.
Hint: One way to do the second part of this is to deﬁne a new
measure, µ by
µ (E) ≡
Z
E
³
1 + |x|2´k
dx.
Then show µ is a Radon measure and show there exists {gm} such that gm ∈G
and gm →Ff in L2(µ). Thus gm = Ffm, fm ∈G because F maps G onto G.
Then by Problem 10, {fm } is Cauchy in the norm || ||k,2.
12. ↑If 2k > n, show that if f ∈Hk(Rn), then f equals a bounded continuous
function a.e. Hint: Show that for k this large, Ff ∈L1(Rn), and then use
Problem 1. To do this, write
|Ff(x)| = |Ff(x)|(1 + |x|2)
k
2 (1 + |x|2)
−k
2 ,
So
Z
|Ff(x)|dx =
Z
|Ff(x)|(1 + |x|2)
k
2 (1 + |x|2)
−k
2 dx.
Use the Cauchy Schwarz inequality. This is an example of a Sobolev imbedding
Theorem.
13. Let u ∈G. Then Fu ∈G and so, in particular, it makes sense to form the
integral,
Z
R
Fu (x′, xn) dxn
where (x′, xn) = x ∈Rn.
For u ∈G, deﬁne γu (x′) ≡u (x′, 0).
Find a
constant such that F (γu) (x′) equals this constant times the above integral.
Hint: By the dominated convergence theorem
Z
R
Fu (x′, xn) dxn = lim
ε→0
Z
R
e−(εxn)2Fu (x′, xn) dxn.
Now use the deﬁnition of the Fourier transform and Fubini’s theorem as re-
quired in order to obtain the desired relationship.
14. Recall the Fourier series of a function in L2 (−π, π) converges to the func-
tion in L2 (−π, π).
Prove a similar theorem with L2 (−π, π) replaced by
L2 (−mπ, mπ) and the functions
n
(2π)−(1/2) einxo
n∈Z

540
FOURIER TRANSFORMS
used in the Fourier series replaced with
n
(2mπ)−(1/2) ei n
m xo
n∈Z
Now suppose f is a function in L2 (R) satisfying Ff (t) = 0 if |t| > mπ. Show
that if this is so, then
f (x) = 1
π
X
n∈Z
f
µ−n
m
¶ sin (π (mx + n))
mx + n
.
Here m is a positive integer. This is sometimes called the Shannon sampling
theorem.Hint: First note that since Ff ∈L2 and is zero oﬀa ﬁnite interval,
it follows Ff ∈L1. Also
f (t) =
1
√
2π
Z mπ
−mπ
eitxFf (x) dx
and you can conclude from this that f has all derivatives and they are all
bounded. Thus f is a very nice function. You can replace Ff with its Fourier
series. Then consider carefully the Fourier coeﬃcient of Ff. Argue it equals
f
¡ −n
m
¢
or at least an appropriate constant times this. When you get this the
rest will fall quickly into place if you use Ff is zero oﬀ[−mπ, mπ].

Fourier Analysis In Rn An
Introduction
The purpose of this chapter is to present some of the most important theorems
on Fourier analysis in Rn.
These theorems are the Marcinkiewicz interpolation
theorem, the Calderon Zygmund decomposition, and Mihlin’s theorem. They are
all fundamental results whose proofs depend on the methods of real analysis.
20.1
The Marcinkiewicz Interpolation Theorem
Let (Ω, µ, S) be a measure space.
Deﬁnition 20.1 Lp (Ω) + L1 (Ω) will denote the space of measurable functions, f,
such that f is the sum of a function in Lp (Ω) and L1 (Ω). Also, if T : Lp (Ω) +
L1 (Ω) →space of measurable functions, T is subadditive if
|T (f + g) (x)| ≤|Tf (x)| + |Tg (x)|.
T is of type (p, p) if there exists a constant independent of f ∈Lp (Ω) such that
||Tf||p ≤A ∥f∥p, f ∈Lp (Ω).
T is weak type (p, p) if there exists a constant A independent of f such that
µ ([x : |Tf (x)| > α]) ≤
µA
α ||f||p
¶p
, f ∈Lp (Ω).
The following lemma involves writing a function as a sum of a functions whose
values are small and one whose values are large.
Lemma 20.2 If p ∈[1, r], then Lp (Ω) ⊆L1 (Ω) + Lr (Ω).
Proof: Let λ > 0 and let f ∈Lp (Ω)
f1 (x) ≡
½
f (x) if |f (x)| ≤λ
0 if |f (x)| > λ
, f2 (x) ≡
½
f (x) if |f (x)| > λ
0 if |f (x)| ≤λ
.
541

542
FOURIER ANALYSIS IN RN AN INTRODUCTION
Thus f (x) = f1 (x) + f2 (x).
Z
|f1 (x)|r dµ =
Z
[|f|≤λ]
|f (x)|r dµ ≤λr−p
Z
[|f|≤λ]
|f (x)|p dµ < ∞.
Therefore, f1 ∈Lr (Ω).
Z
|f2 (x)| dµ =
Z
[|f|>λ]
|f (x)| dµ ≤µ [|f| > λ]1/p′ µZ
|f|p dµ
¶1/p
< ∞.
This proves the lemma since f = f1 + f2, f1 ∈Lr and f2 ∈L1.
For f a function having nonnegative real values, α →µ ([f > α]) is called the
distribution function.
Lemma 20.3 Let φ (0) = 0, φ is strictly increasing, and C1. Let f : Ω→[0, ∞)
be measurable. Then
Z
Ω
(φ ◦f) dµ =
Z ∞
0
φ′ (α) µ [f > α] dα.
(20.1)
Proof: First suppose
f =
m
X
i=1
aiXEi
where ai > 0 and the ai are all distinct nonzero values of f, the sets, Ei being
disjoint. Thus,
Z
Ω
(φ ◦f) dµ =
m
X
i=1
φ (ai) µ (Ei).
Suppose without loss of generality a1 < a2 < · · · < am. Observe
α →µ ([f > α])
is constant on the intervals [0, a1), [a1, a2), · · ·. For example, on [ai, ai+1), this func-
tion has the value
m
X
j=i+1
µ (Ej).
The function equals zero on [am, ∞). Therefore,
α →φ′ (α) µ ([|f| > α])

20.1.
THE MARCINKIEWICZ INTERPOLATION THEOREM
543
is Lebesgue measurable and letting a0 = 0, the second integral in 20.1 equals
Z ∞
0
φ′ (α) µ ([f > α]) dα
=
m
X
i=1
Z ai
ai−1
φ′ (α) µ ([f > α]) dα
=
m
X
i=1
m
X
j=i
µ (Ej)
Z ai
ai−1
φ′ (α) dα
=
m
X
j=1
j
X
i=1
µ (Ej) (φ (ai) −φ (ai−1))
=
m
X
j=1
µ (Ej) φ (aj) =
Z
Ω
(φ ◦f) dµ
and so this establishes 20.1 in the case when f is a nonnegative simple function.
Since every measurable nonnegative function may be written as the pointwise limit
of such simple functions, the desired result will follow by the Monotone convergence
theorem and the next claim.
Claim: If fn ↑f, then for each α > 0,
µ ([f > α]) = lim
n→∞µ ([fn > α]).
Proof of the claim: [fn > α] ↑[f > α] because if f (x) > α then for large
enough n, fn (x) > α and so
µ ([fn > α]) ↑µ ([f > α]).
This proves the lemma. (Note the importance of the strict inequality in [f > α] in
proving the claim.)
The next theorem is the main result in this section. It is called the Marcinkiewicz
interpolation theorem.
Theorem 20.4 Let (Ω, µ, S) be a σ ﬁnite measure space, 1 < r < ∞, and let
T : L1 (Ω) + Lr (Ω) →space of measurable functions
be subadditive, weak (r, r), and weak (1, 1).
Then T is of type (p, p) for every
p ∈(1, r) and
||Tf||p ≤Ap ||f||p
where the constant Ap depends only on p and the constants in the deﬁnition of weak
(1, 1) and weak (r, r).
Proof: Let α > 0 and let f1 and f2 be deﬁned as in Lemma 20.2,
f1 (x) ≡
½
f (x) if |f (x)| ≤α
0 if |f (x)| > α
, f2 (x) ≡
½
f (x) if |f (x)| > α
0 if |f (x)| ≤α
.

544
FOURIER ANALYSIS IN RN AN INTRODUCTION
Thus f = f1 + f2 where f1 ∈Lr and f2 ∈L1. Since T is subadditive ,
[|Tf| > α] ⊆[|Tf1| > α/2] ∪[|Tf2| > α/2] .
Let p ∈(1, r). By Lemma 20.3,
Z
|Tf|p dµ ≤p
Z ∞
0
αp−1µ ([|Tf1| > α/2]) dα+
+p
Z ∞
0
αp−1µ ([|Tf2| > α/2]) dα.
Therefore, since T is weak (1, 1) and weak (r, r),
Z
|Tf|p dµ ≤p
Z ∞
0
αp−1
µ2Ar
α
||f1||r
¶r
dα + p
Z ∞
0
αp−1 2A1
α
||f2||1 dα.
(20.2)
Therefore, the right side of 20.2 equals
p (2Ar)r
Z ∞
0
αp−1−r
Z
Ω
|f1|r dµdα + 2A1p
Z ∞
0
αp−2
Z
Ω
|f2| dµdα =
p (2Ar)r
Z
Ω
Z ∞
0
αp−1−r |f1|r dαdµ + 2A1p
Z
Ω
Z ∞
0
αp−2 |f2| dαdµ.
Now f1 (x) = 0 unless |f1 (x)| ≤α and f2 (x) = 0 unless |f2 (x)| > α so this equals
p (2Ar)r
Z
Ω
|f (x)|r
Z ∞
|f(x)|
αp−1−rdαdµ + 2A1p
Z
Ω
|f (x)|
Z |f(x)|
0
αp−2dαdµ
which equals
2rAr
rp
r −p
Z
Ω
|f (x)|p dµ + 2pA1
p −1
Z
Ω
|f (x)|p dµ
≤max
µ2rAr
rp
r −p , 2pA1
p −1
¶
||f||p
Lp(Ω)
and this proves the theorem.
20.2
The Calderon Zygmund Decomposition
For a given nonnegative integrable function, Rn can be decomposed into a set where
the function is small and a set which is the union of disjoint cubes on which the
average of the function is under some control. The measure in this section will
always be Lebesgue measure on Rn. This theorem depends on the Lebesgue theory
of diﬀerentiation.

20.2.
THE CALDERON ZYGMUND DECOMPOSITION
545
Theorem 20.5 Let f ≥0,
R
fdx < ∞, and let α be a positive constant. Then
there exist sets F and Ωsuch that
Rn = F ∪Ω, F ∩Ω= ∅
(20.3)
f (x) ≤α a.e. on F
(20.4)
Ω= ∪∞
k=1Qk where the interiors of the cubes are disjoint and for each cube, Qk,
α <
1
m (Qk)
Z
Qk
f (x) dx ≤2nα.
(20.5)
Proof: Let S0 be a tiling of Rn into cubes having sides of length M where M
is chosen large enough that if Q is one of these cubes, then
1
m (Q)
Z
Q
fdm ≤α.
(20.6)
Suppose S0, · · ·, Sm have been chosen. To get Sm+1, replace each cube of Sm by
the 2n cubes obtained by bisecting the sides. Then Sm+1 consists of exactly those
cubes of Sm for which 20.6 holds and let Tm+1 consist of the bisected cubes from
Sm for which 20.6 does not hold. Now deﬁne
F ≡{x : x is contained in some cube from Sm for all m} ,
Ω≡Rn \ F = ∪∞
m=1 ∪{Q : Q ∈Tm}
Note that the cubes from Tm have pair wise disjoint interiors and also the interiors
of cubes from Tm have empty intersections with the interiors of cubes of Tk if k ̸= m.
Let x be a point of Ωand let x be in a cube of Tm such that m is the ﬁrst index
for which this happens. Let Q be the cube in Sm−1 containing x and let Q∗be the
cube in the bisection of Q which contains x. Therefore 20.6 does not hold for Q∗.
Thus
α <
1
m (Q∗)
Z
Q∗fdx ≤m (Q)
m (Q∗)
≤α
z
}|
{
1
m (Q)
Z
Q
fdx ≤2nα
which shows Ωis the union of cubes having disjoint interiors for which 20.5 holds.
Now a.e. point of F is a Lebesgue point of f. Let x be such a point of F and
suppose x ∈Qk for Qk ∈Sk. Let dk ≡diameter of Qk. Thus dk →0.
1
m (Qk)
Z
Qk
|f (y) −f (x)| dy ≤
1
m (Qk)
Z
B(x,dk)
|f (y) −f (x)| dy
= m (B (x,dk))
m (Qk)
1
m (B (x,dk))
Z
B(x,dk)
|f (x) −f (y)| dy
≤Kn
1
m (B (x,dk))
Z
B(x,dk)
|f (x) −f (y)| dy

546
FOURIER ANALYSIS IN RN AN INTRODUCTION
where Kn is a constant which depends on n and measures the ratio of the volume of
a ball with diamiter 2d and a cube with diameter d. The last expression converges
to 0 because x is a Lebesgue point. Hence
f (x) = lim
k→∞
1
m (Qk)
Z
Qk
f (y) dy ≤α
and this shows f (x) ≤α a.e. on F. This proves the theorem.
20.3
Mihlin’s Theorem
In this section, the Marcinkiewicz interpolation theorem and Calderon Zygmund
decomposition will be used to establish a remarkable theorem of Mihlin, a general-
ization of Plancherel’s theorem to the Lp spaces. It is of fundamental importance
in the study of elliptic partial diﬀerential equations and can also be used to give
proofs for the theory of singular integrals. Mihlin’s theorem involves a conclusion
which is of the form
¯¯¯¯F −1ρ ∗φ
¯¯¯¯
p ≤Ap ||φ||p
(20.7)
for p > 1 and φ ∈G. Thus F −1ρ∗extends to a continuous linear map deﬁned on Lp
because of the density of G. It is proved by showing various weak type estimates
and then applying the Marcinkiewicz Interpolation Theorem to get an estimate like
the above.
Recall that by Corollary 19.27, if f ∈L2 (Rn) and if φ ∈G, then f ∗φ ∈L2 (Rn)
and
F (f ∗φ) (x) = (2π)n/2 Fφ (x) Ff (x).
The next lemma is essentially a weak (1, 1) estimate. The inequality 20.7 is estab-
lished under the condition, 20.8 and then it is shown there exist conditions which
are easier to verify which imply condition 20.8. I think the approach used here is
due to Hormander [29] and is found in Berg and Lofstrom [8]. For many more ref-
erences and generalizations, you might look in Triebel [50]. A diﬀerent proof based
on singular integrals is in Stein [49]. Functions, ρ which yield an inequality of the
sort in 20.7 are called Lp multipliers.
Lemma 20.6 Suppose ρ ∈L∞(Rn) ∩L2 (Rn) and suppose also there exists a con-
stant C1 such that
Z
|x|≥2|y|
¯¯F −1ρ (x −y) −F −1ρ (x)
¯¯ dx ≤C1.
(20.8)
Then there exists a constant A depending only on C1, ||ρ||∞, and n such that
m
¡£
x :
¯¯F −1ρ∗φ (x)
¯¯ > α
¤¢
≤A
α ||φ||1
for all φ ∈G.

20.3.
MIHLIN’S THEOREM
547
Proof: Let φ ∈G and use the Calderon decomposition to write Rn = E ∪Ω
where Ωis a union of cubes, {Qi} with disjoint interiors such that
αm (Qi) ≤
Z
Qi
|φ (x)| dx ≤2nαm (Qi) , |φ (x)| ≤α a.e. on E.
(20.9)
The proof is accomplished by writing φ as the sum of a good function and
a bad function and establishing a similar weak inequality for these two functions
separately. Then this information is used to obtain the desired conclusion.
g (x) =
½ φ (x) if x ∈E
1
m(Qi)
R
Qi φ (x) dx if x ∈Qi ⊆Ω, g (x) + b (x) = φ (x).
(20.10)
ThusZ
Qi
b (x) dx
=
Z
Qi
(φ (x) −g (x)) dx =
Z
Qi
φ (x) dx −
Z
Qi
φ (x) dx = 0,(20.11)
b (x)
=
0 if x /∈Ω.
(20.12)
Claim:
||g||2
2 ≤α (1 + 4n) ||φ||1 , ||g||1 ≤||φ||1.
(20.13)
Proof of claim:
||g||2
2 = ||g||2
L2(E) + ||g||2
L2(Ω).
Thus
||g||2
L2(Ω)
=
X
i
Z
Qi
|g (x)|2 dx
≤
X
i
Z
Qi
µ
1
m (Qi)
Z
Qi
|φ (y)| dy
¶2
dx
≤
X
i
Z
Qi
(2nα)2 dx ≤4nα2 X
i
m (Qi)
≤
4nα2 1
α
X
i
Z
Qi
|φ (x)| dx ≤4nα ||φ||1.
||g||2
L2(E) =
Z
E
|φ (x)|2 dx ≤α
Z
E
|φ (x)| dx = α ||φ||1.
Now consider the second of the inequalities in 20.13.
||g||1
=
Z
E
|g (x)| dx +
Z
Ω
|g (x)| dx
=
Z
E
|φ (x)| dx +
X
i
Z
Qi
|g| dx
≤
Z
E
|φ (x)| dx +
X
i
Z
Qi
1
m (Qi)
Z
Qi
|φ (x)| dm (x) dm
=
Z
E
|φ (x)| dx +
X
i
Z
Qi
|φ (x)| dm (x) = ||φ||1

548
FOURIER ANALYSIS IN RN AN INTRODUCTION
This proves the claim. From the claim, it follows that b ∈L2 (Rn) ∩L1 (Rn) .
Because of 20.13, g ∈L1 (Rn) and so F −1ρ ∗g ∈L2 (Rn).
(Since ρ ∈L2,
it follows F −1ρ ∈L2 and so this convolution is indeed in L2.) By Plancherel’s
theorem,
¯¯¯¯F −1ρ ∗g
¯¯¯¯
2 =
¯¯¯¯F
¡
F −1ρ ∗g
¢¯¯¯¯
2.
By Corollary 19.27 on Page 531, the expression on the right equals
(2π)n/2 ||ρFg||2
and so
¯¯¯¯F −1ρ ∗g
¯¯¯¯
2 = (2π)n/2 ||ρFg||2 ≤Cn ||ρ||∞||g||2.
From this and 20.13
m
¡£¯¯F −1ρ ∗g
¯¯ ≥α/2
¤¢
≤Cn ||ρ||2
∞
α2
α (1 + 4n) ||φ||1 = Cnα−1 ||φ||1.
(20.14)
This is what is wanted so far as g is concerned. Next it is required to estimate
m
¡£¯¯F −1ρ ∗b
¯¯ ≥α/2
¤¢
.
If Q is one of the cubes whose union is Ω, let Q∗be the cube with the same
center as Q but whose sides are 2√n times as long.
Qi
Q∗
i
yi
r
Let
Ω∗≡∪∞
i=1Q∗
i
and let
E∗≡Rn \ Ω∗.
Thus E∗⊆E. Let x ∈E∗. Then because of 20.11,
Z
Qi
F −1ρ (x −y) b (y) dy
=
Z
Qi
£
F −1ρ (x −y) −F −1ρ (x −yi)
¤
b (y) dy,
(20.15)
where yi is the center of Qi. Consequently if the sides of Qi have length 2t/√n,
20.15 implies
Z
E∗
¯¯¯¯
Z
Qi
F −1ρ (x −y) b (y) dy
¯¯¯¯ dx ≤
(20.16)

20.3.
MIHLIN’S THEOREM
549
Z
E∗
Z
Qi
¯¯F −1ρ (x −y) −F −1ρ (x −yi)
¯¯ |b (y)| dydx
=
Z
Qi
Z
E∗
¯¯F −1ρ (x −y) −F −1ρ (x −yi)
¯¯ dx |b (y)| dy
(20.17)
≤
Z
Qi
Z
|x−yi|≥2t
¯¯F −1ρ (x −y) −F −1ρ (x −yi)
¯¯ dx |b (y)| dy
(20.18)
since if x ∈E∗, then |x −yi| ≥2t. Now for y ∈Qi,
|y −yi| ≤


n
X
j=1
µ t
√n
¶2


1/2
= t.
From 20.8 and the change of variables u = x −yi 20.16 - 20.18 imply
Z
E∗
¯¯¯¯
Z
Qi
F −1ρ (x −y) b (y) dy
¯¯¯¯ dx ≤C1
Z
Qi
|b (y)| dy.
(20.19)
Now from 20.19, and the fact that b = 0 oﬀΩ,
Z
E∗
¯¯F −1ρ ∗b (x)
¯¯ dx
=
Z
E∗
¯¯¯¯
Z
Rn F −1ρ (x −y) b (y) dy
¯¯¯¯ dx
=
Z
E∗
¯¯¯¯¯
∞
X
i=1
Z
Qi
F −1ρ (x −y) b (y) dy
¯¯¯¯¯ dx
≤
Z
E∗
∞
X
i=1
¯¯¯¯
Z
Qi
F −1ρ (x −y) b (y) dy
¯¯¯¯ dx
=
∞
X
i=1
Z
E∗
¯¯¯¯
Z
Qi
F −1ρ (x −y) b (y) dy
¯¯¯¯ dx
≤
∞
X
i=1
C1
Z
Qi
|b (y)| dy = C1 ||b||1.
Thus, by 20.13,
Z
E∗
¯¯F −1ρ ∗b (x)
¯¯ dx
≤
C1 ||b||1
≤
C1 [||φ||1 + ||g||1]
≤
C1 [||φ||1 + ||φ||1]
≤
2C1 ||φ||1 .
Consequently,
m
³h¯¯F −1ρ ∗b
¯¯ ≥α
2
i
∩E∗´
≤4C1
α ||φ||1 .

550
FOURIER ANALYSIS IN RN AN INTRODUCTION
From 20.10, 20.14, and 20.9,
m
£¯¯F −1ρ ∗φ
¯¯ > α
¤
≤m
h¯¯F −1ρ ∗g
¯¯ ≥α
2
i
+ m
h¯¯F −1ρ ∗b
¯¯ ≥α
2
i
≤Cn
α ||φ||1 + m
³h¯¯F −1ρ ∗b
¯¯ ≥α
2
i
∩E∗´
+ m (Ω∗)
≤Cn
α ||φ||1 + 4C1
α ||φ||1 + Cnm (Ω) ≤A
α ||φ||1
because
m (Ω) ≤α−1 ||φ||1
by 20.9. This proves the lemma.
The next lemma extends this lemma by giving a weak (2, 2) estimate and a (2, 2)
estimate.
Lemma 20.7 Suppose ρ ∈L∞(Rn) ∩L2 (Rn) and suppose also that there exists a
constant C1 such that
Z
|x|>2|y|
¯¯F −1ρ (x −y) −F −1ρ (x)
¯¯ dx ≤C1.
(20.20)
Then F −1ρ∗maps L1 (Rn) + L2 (Rn) to measurable functions and there exists a
constant A depending only on C1, n, ||ρ||∞such that
m
¡£¯¯F −1ρ ∗f
¯¯ > α
¤¢
≤A||f||1
α
if f ∈L1 (Rn),
(20.21)
m
¡£¯¯F −1ρ ∗f
¯¯ > α
¤¢
≤
µ
A||f||2
α
¶2
if f ∈L2 (Rn).
(20.22)
Thus, F −1ρ∗is weak type (1, 1) and weak type (2, 2). Also
¯¯¯¯F −1ρ ∗f
¯¯¯¯
2 ≤A ||f||2 if f ∈L2 (Rn).
(20.23)
Proof: By Plancherel’s theorem F −1ρ is in L2 (Rn). If f ∈L1 (Rn), then by
Minkowski’s inequality,
F −1ρ ∗f ∈L2 (Rn) .
Now let g ∈L2 (Rn). By Holder’s inequality,
Z ¯¯F −1ρ (x −y)
¯¯ |g (y)| dy ≤
µZ ¯¯F −1ρ (x −y)
¯¯2 dy
¶1/2 µZ
|g (y)|2 dy
¶1/2
< ∞
and so the following is well deﬁned a.e.
F −1ρ ∗g (x) ≡
Z
F −1ρ (x −y) g (y) dy

20.3.
MIHLIN’S THEOREM
551
also,
¯¯F −1ρ ∗g (x) −F −1ρ ∗g (x′)
¯¯
≤
Z ¯¯F −1ρ (x −y) −F −1ρ (x′ −y)
¯¯ |g (y)| dy
≤
¯¯¯¯F −1ρ −F −1ρx′−x
¯¯¯¯ ||g||l2
and by continuity of translation in L2 (Rn), this shows x →F −1ρ ∗g (x) is continu-
ous. Therefore, F −1ρ∗maps L1 (Rn)+L2 (Rn) to the space of measurable functions.
(Continuous functions are measurable.) It is clear that F −1ρ∗is subadditive.
If φ ∈G, Plancherel’s theorem implies as before,
¯¯¯¯F −1ρ ∗φ
¯¯¯¯
2 =
¯¯¯¯F
¡
F −1ρ ∗φ
¢¯¯¯¯
2 =
(2π)n/2 ||ρFφ||2 ≤(2π)n/2 ||ρ||∞||φ||2 .
(20.24)
Now let f ∈L2 (Rn) and let φk ∈G, with
||φk −f||2 →0.
Then by Holder’s inequality,
Z
F −1ρ (x −y) f (y) dy = lim
k→∞
Z
F −1ρ (x −y) φk (y) dy
and so by Fatou’s lemma, Plancherel’s theorem, and 20.24,
¯¯¯¯F −1ρ ∗f
¯¯¯¯
2 =
ÃZ ¯¯¯¯
Z
F −1ρ (x −y) f (y) dy
¯¯¯¯
2
dx
!1/2
≤
≤lim inf
k→∞
ÃZ ¯¯¯¯
Z
F −1ρ (x −y) φk (y) dy
¯¯¯¯
2
dx
!1/2
= lim inf
k→∞
¯¯¯¯F −1ρ ∗φk
¯¯¯¯
2
≤||ρ||∞(2π)n/2 lim inf
k→∞||φk||2 = ||ρ||∞(2π)n/2 ||f||2 .
Thus, 20.23 holds with A = ||ρ||∞(2π)n/2. Consequently,
A ||f||2 ≥
ÃZ
[|F −1ρ∗f|>α]
¯¯F −1ρ ∗f (x)
¯¯2 dx
!1/2
≥αm
¡£¯¯F −1ρ ∗f
¯¯ > α
¤¢1/2
and so 20.22 follows.
It remains to prove 20.21 which holds for all f ∈G
by Lemma 20.6.
Let
f ∈L1 (Rn) and let φk →f in L1 (Rn) , φk ∈G. Without loss of generality, assume
that both f and F −1ρ are Borel measurable. Therefore, by Minkowski’s inequality,
and Plancherel’s theorem,
¯¯¯¯F −1ρ ∗φk −F −1ρ ∗f
¯¯¯¯
2

552
FOURIER ANALYSIS IN RN AN INTRODUCTION
≤
ÃZ ¯¯¯¯
Z
F −1ρ (x −y) (φk (y) −f (y)) dy
¯¯¯¯
2
dx
!1/2
≤
||φk −f||1 ||ρ||2
which shows that F −1ρ ∗φk converges to F −1ρ ∗f in L2 (Rn). Therefore, there
exists a subsequence such that the convergence is pointwise a.e. Then, denoting the
subsequence by k,
X[|F −1ρ∗f|>α] (x) ≤lim inf
k→∞X[|F −1ρ∗φk|>α] (x) a.e. x.
Thus by Lemma 20.6 and Fatou’s lemma, there exists a constant, A, depending on
C1, n, and ||ρ||∞such that
m
¡£¯¯F −1ρ ∗f
¯¯ > α
¤¢
≤
lim inf
k→∞m
¡£¯¯F −1ρ ∗φk
¯¯ > α
¤¢
≤
lim inf
k→∞A||φk||1
α
= A||f||1
α
.
This shows 20.21 and proves the lemma.
Theorem 20.8 Let ρ ∈L2 (Rn) ∩L∞(Rn) and suppose
Z
|x|≥2|y|
¯¯F −1ρ (x −y) −F −1ρ (x)
¯¯ dx ≤C1.
Then for each p ∈(1, ∞), there exists a constant, Ap, depending only on
p, n, ||ρ||∞,
and C1 such that for all φ ∈G,
¯¯¯¯F −1ρ ∗φ
¯¯¯¯
p ≤Ap ||φ||p .
Proof: From Lemma 20.7, F −1ρ∗is weak (1, 1), weak (2, 2), and maps
L1 (Rn) + L2 (Rn)
to measurable functions. Therefore, by the Marcinkiewicz interpolation theorem,
there exists a constant Ap depending only on p, C1, n, and ||ρ||∞for p ∈(1, 2], such
that for f ∈Lp (Rn), and p ∈(1, 2],
¯¯¯¯F −1ρ ∗f
¯¯¯¯
p ≤Ap ||f||p .
Thus the theorem is proved for these values of p. Now suppose p > 2. Then p′ < 2
where
1
p + 1
p′ = 1.

20.3.
MIHLIN’S THEOREM
553
By Plancherel’s theorem and Theorem 19.33,
Z
F −1ρ ∗φ (x) ψ (x) dx
=
(2π)n/2
Z
ρ (x) Fφ (x) Fψ (x) dx
=
Z
F
¡
F −1ρ ∗ψ
¢
Fφdx
=
Z ¡
F −1ρ ∗ψ
¢
(φ) dx.
Thus by the case for p ∈(1, 2) and Holder’s inequality,
¯¯¯¯
Z
F −1ρ ∗φ (x) ψ (x) dx
¯¯¯¯
=
¯¯¯¯
Z ¡
F −1ρ ∗ψ
¢
(φ) dx
¯¯¯¯
≤
¯¯¯¯F −1ρ ∗ψ
¯¯¯¯
p′ ||φ||p
≤
Ap′ ||ψ||p′ ||φ||p .
Letting Lψ ≡
R
F −1ρ ∗φ (x) ψ (x) dx, this shows L ∈Lp′ (Rn)′ and ||L||(Lp′)
′ ≤
Ap′ ||φ||pwhich implies by the Riesz representation theorem that F −1ρ∗φ represents
L and
||L||(Lp′)
′ =
¯¯¯¯F −1ρ ∗φ
¯¯¯¯
Lp ≤Ap′ ||φ||p
Since p′ = p/ (p −1), this proves the theorem.
It is possible to give veriﬁable conditions on ρ which imply 20.20. The condition
on ρ which is presented here is the existence of a constant, C0 such that
C0 ≥sup{|x||α| |Dαρ (x)| : |α| ≤L, x ∈Rn \ {0}}, L > n/2.
(20.25)
ρ ∈CL (Rn \ {0}) where L is an integer.
Here α is a multi-index and |α| = Pn
i=1 αi. The condition says roughly that ρ
is pretty smooth away from 0 and all the partial derivatives vanish pretty fast as
|x| →∞. Also recall the notation
xα ≡xα1
1 · · · xαn
n
where α = (α1 · · · αn). For more general conditions, see [29].
Lemma 20.9 Let 20.25 hold and suppose ψ ∈C∞
c (Rn \ {0}).
Then for each
α, |α| ≤L, there exists a constant C ≡C (α, n, ψ) independent of k such that
sup
x ∈Rn |x||α| ¯¯Dα ¡
ρ (x) ψ
¡
2kx
¢¢¯¯ ≤CC0.
Proof:
|x||α| ¯¯Dα ¡
ρ (x) ψ
¡
2kx
¢¢¯¯ ≤|x||α|
X
β+γ=α
¯¯Dβρ (x)
¯¯ 2k|γ| ¯¯Dγψ
¡
2kx
¢¯¯

554
FOURIER ANALYSIS IN RN AN INTRODUCTION
=
X
β+γ=α
|x||β| ¯¯Dβρ (x)
¯¯ ¯¯2kx
¯¯|γ| ¯¯Dγψ
¡
2kx
¢¯¯
≤C0C (α, n)
X
|γ|≤|α|
sup{|z||γ| |Dγψ (z)| : z ∈Rn} = C0C (α, n, ψ)
and this proves the lemma.
Lemma 20.10 There exists
φ ∈C∞
c
¡£
x :4−1 < |x| < 4
¤¢
, φ (x) ≥0,
and
∞
X
k=−∞
φ
¡
2kx
¢
= 1
for each x ̸= 0.
Proof: Let
ψ ≥0, ψ = 1 on
£
2−1 ≤|x| ≤2
¤
,
spt (ψ) ⊆
£
4−1 < |x| < 4
¤
.
Consider
g (x) =
∞
X
k=−∞
ψ
¡
2kx
¢
.
Then for each x, only ﬁnitely many terms are not equal to 0. Also, g (x) > 0 for
all x ̸= 0. To verify this last claim, note that for some k an integer, |x| ∈
£
2l, 2l+2¤
.
Therefore, choose k an integer such that 2k |x| ∈
£
2−1, 2
¤
. For example, let k =
−l −1. This works because 2k |x| ∈
£
2l2k, 2l+22k¤
=
£
2l−l−1, 2l+2−l−1¤
=
£
2−1, 2
¤
.
Therefore, for this value of k, ψ
¡
2kx
¢
= 1 so g (x) > 0.
Now notice that
g (2rx) =
∞
X
k=−∞
ψ
¡
2k2rx
¢
=
∞
X
k=−∞
ψ
¡
2kx
¢
= g (x).
Let φ (x) ≡ψ (x) g (x)−1. Then
∞
X
k=−∞
φ
¡
2kx
¢
=
∞
X
k=−∞
ψ
¡
2kx
¢
g (2kx) = g (x)−1
∞
X
k=−∞
ψ
¡
2kx
¢
= 1
for each x ̸= 0. This proves the lemma.
Now deﬁne
ρm (x) ≡
m
X
k=−m
ρ (x) φ
¡
2kx
¢
, γk (x) ≡ρ (x) φ
¡
2kx
¢
.

20.3.
MIHLIN’S THEOREM
555
Let t > 0 and let |y| ≤t. Consider the problem of estimating
Z
|x|≥2t
¯¯F −1γk (x −y) −F −1γk (x)
¯¯ dx.
(20.26)
In the following estimates, C (a, b, · · ·, d) will denote a generic constant depending
only on the indicated objects, a, b, · · ·, d. For the ﬁrst estimate, note that since
|y| ≤t, 20.26 is no larger than
2
Z
|x|≥t
¯¯F −1γk (x)
¯¯ dx = 2
Z
|x|≥t
¯¯F −1γk (x)
¯¯ |x|−L |x|L dx
≤2
ÃZ
|x|≥t
|x|−2L dx
!1/2 ÃZ
|x|≥t
|x|2L ¯¯F −1γk (x)
¯¯2 dx
!1/2
Using spherical coordinates and Plancherel’s theorem,
≤C (n, L) tn/2−L ³R
|x|2L ¯¯F −1γk (x)
¯¯2 dx
´1/2
≤C (n, L) tn/2−L ³R Pn
j=1 |xj|2L ¯¯F −1γk (x)
¯¯2 dx
´1/2
≤C (n, L) tn/2−L ³Pn
j=1
R ¯¯F −1DL
j γk (x)
¯¯2 dx
´1/2
= C (n, L) tn/2−L ³Pn
j=1
R
Sk
¯¯DL
j γk (x)
¯¯2 dx
´1/2
(20.27)
where
Sk ≡
£
x :2−2−k < |x| < 22−k¤
,
(20.28)
a set containing the support of γk. Now from the deﬁnition of γk,
¯¯DL
j γk (z)
¯¯ =
¯¯DL
j
¡
ρ (z) φ
¡
2kz
¢¢¯¯.
By Lemma 20.9, this is no larger than
C (L, n, φ) C0 |z|−L.
(20.29)
It follows, using polar coordinates, that the last expression in 20.27 is no larger than
C (n, L, φ, C0) tn/2−L
µZ
Sk
|z|−2L dz
¶1/2
≤C (n, L, φ, C0) tn/2−L·
(20.30)
ÃZ 22−k
2−2−k ρn−1−2Ldρ
!1/2
≤C (n, L, φ, C0) tn/2−L2k(L−n/2).
Now estimate 20.26 in another way. The support of γk is in Sk, a bounded set,
and so F −1γk is diﬀerentiable. Therefore,
Z
|x|≥2t
¯¯F −1γk (x −y) −F −1γk (x)
¯¯ dx =

556
FOURIER ANALYSIS IN RN AN INTRODUCTION
Z
|x|≥2t
¯¯¯¯¯¯
Z 1
0
n
X
j=1
DjF −1γk (x−sy) yjds
¯¯¯¯¯¯
dx
≤
t
Z
|x|≥2t
Z 1
0
n
X
j=1
¯¯DjF −1γk (x−sy)
¯¯ dsdx
≤
t
Z
n
X
j=1
¯¯DjF −1γk (x)
¯¯ dx
≤
t
n
X
j=1
µZ ³
1 +
¯¯2−kx
¯¯2´−L
dx
¶1/2
·
µZ ³
1 +
¯¯2−kx
¯¯2´L ¯¯DjF −1γk (x)
¯¯2 dx
¶1/2
≤C (n, L) t2kn/2
n
X
j=1
µZ ³
1 +
¯¯2−kx
¯¯2´L ¯¯DjF −1γk (x)
¯¯2 dx
¶1/2
.
(20.31)
Now consider the jth term in the last sum in 20.31.
R ³
1 +
¯¯2−kx
¯¯2´L ¯¯DjF −1γk (x)
¯¯2 dx ≤
C (n, L)
R P
|α|≤L 2−2k|α|x2α ¯¯DjF −1γk (x)
¯¯2 dx
= C (n, L) P
|α|≤L 2−2k|α| R
x2α ¯¯F −1 (πjγk) (x)
¯¯2 dx
(20.32)
where πj (z) ≡zj. This last assertion follows from
Dj
Z
e−ix·yγk (y) dy =
Z
(−i) e−ix·yyjγk (y) dy.
Therefore, a similar computation and Plancherel’s theorem implies 20.32 equals
= C (n, L)
X
|α|≤L
2−2k|α|
Z ¯¯F −1Dα (πjγk) (x)
¯¯2 dx
= C (n, L)
X
|α|≤L
2−2k|α|
Z
Sk
|Dα (zjγk (z))|2 dz
(20.33)
where Sk is given in 20.28. Now
|Dα (zjγk (z))|
=
2−k ¯¯Dα ¡
ρ (z) zj2kφ
¡
2kz
¢¢¯¯
=
2−k ¯¯Dα ¡
ρ (z) ψj
¡
2kz
¢¢¯¯

20.3.
MIHLIN’S THEOREM
557
where ψj (z) ≡zjφ (z). By Lemma 20.9, this is dominated by
2−kC (α, n, φ, j, C0) |z|−|α| .
Therefore, 20.33 is dominated by
C (L, n, φ, j, C0)
X
|α|≤L
2−2k|α|
Z
Sk
2−2k |z|−2|α| dz
≤
C (L, n, φ, j, C0)
X
|α|≤L
2−2k|α|2−2k ¡
2−2−k¢(−2|α|) ¡
22−k¢n
≤
C (L, n, φ, j, C0)
X
|α|≤L
2−kn−2k
≤C (L, n, φ, j, C0) 2−kn2−2k.
It follows that 20.31 is no larger than
C (L, n, φ, C0) t2kn/22−kn/22−k = C (L, n, φ, C0) t2−k.
(20.34)
It follows from 20.34 and 20.30 that if |y| ≤t,
Z
|x|≥2t
¯¯F −1γk (x −y) −F −1γk (x)
¯¯ dx ≤
C (L, n, φ, C0) min
³
t2−k,
¡
2−kt
¢n/2−L´
.
With this inequality, the next lemma which is the desired result can be obtained.
Lemma 20.11 There exists a constant depending only on the indicated objects,
C1 = C (L, n, φ, C0) such that when |y| ≤t,
Z
|x|≥2t
¯¯F −1ρ (x −y) −F −1ρ (x)
¯¯ dx ≤C1
Z
|x|≥2t
¯¯F −1ρm (x −y) −F −1ρm (x)
¯¯ dx ≤C1.
(20.35)
Proof: F −1ρ = limm→∞F −1ρm in L2 (Rn). Let mk →∞be such that conver-
gence is pointwise a.e. Then if |y| ≤t, Fatou’s lemma implies
Z
|x|≥2t
¯¯F −1ρ (x −y) −F −1ρ (x)
¯¯ dx ≤
lim inf
l→∞
Z
|x|≥2t
¯¯F −1ρml (x −y) −F −1ρml (x)
¯¯ dx

558
FOURIER ANALYSIS IN RN AN INTRODUCTION
≤lim inf
l→∞
ml
X
k=−ml
Z
|x|≥2t
¯¯F −1γk (x −y) −F −1γk (x)
¯¯ dx
≤C (L, n, φ, C0)
∞
X
k=−∞
min
³
t2−k,
¡
2−kt
¢n/2−L´
.
(20.36)
Now consider the sum in 20.36,
∞
X
k=−∞
min
³
t2−k,
¡
2−kt
¢n/2−L´
.
(20.37)
t2j = min
³
t2j,
¡
2jt
¢n/2−L´
exactly when t2j ≤1.
This occurs if and only if
j ≤−ln (t) / ln (2). Therefore 20.37 is no larger than
X
j≤−ln(t)/ ln(2)
2jt +
X
j≥−ln(t)/ ln(2)
¡
2jt
¢n/2−L .
Letting a = L −n/2, this equals
t
X
k≥ln(t)/ ln(2)
2−k + t−α
X
j≥−ln(t)/ ln(2)
¡
2−a¢j
≤
2t
µ1
2
¶ln(t)/ ln(2)
+ t−a
µ 1
2a
¶−ln(t)/ ln(2)
=
2t
µ1
2
¶log2(t)
+ t−a
µ 1
2a
¶−log2(t)
=
2 + 1 = 3.
Similarly, 20.35 holds. This proves the lemma.
Now it is possible to prove Mihlin’s theorem.
Theorem 20.12 (Mihlin’s theorem) Suppose ρ satisﬁes
C0 ≥sup{|x||α| |Dαρ (x)| : |α| ≤L, x ∈Rn \ {0}},
where L is an integer greater than n/2 and ρ ∈CL (Rn \ {0}). Then for every
p > 1, there exists a constant Ap depending only on p, C0, φ, n, and L, such that
for all ψ ∈G,
¯¯¯¯F −1ρ ∗ψ
¯¯¯¯
p ≤Ap ||ψ||p.
Proof: Since ρm satisﬁes 20.35, and is obviously in L2 (Rn)∩L∞(Rn), Theorem
20.8 implies there exists a constant Ap depending only on p, n, ||ρm||∞, and C1 such
that for all ψ ∈G and p ∈(1, ∞),
¯¯¯¯F −1ρm ∗ψ
¯¯¯¯
p ≤Ap ||ψ||p.

20.4.
SINGULAR INTEGRALS
559
Now ||ρm||∞≤||ρ||∞because
|ρm (x)| ≤|ρ (x)|
m
X
k=−m
φ
¡
2kx
¢
≤|ρ (x)|.
(20.38)
Therefore, since C1 = C1 (L, n, φ, C0) and C0 ≥||ρ||∞,
¯¯¯¯F −1ρm ∗ψ
¯¯¯¯
p ≤Ap (L, n, φ, C0, p) ||ψ||p .
In particular, Ap does not depend on m.
Now, by 20.38, the observation that
ρ ∈L∞(Rn), limm→∞ρm (y) = ρ (y) and the dominated convergence theorem, it
follows that for θ ∈G.
¯¯¡
F −1ρ ∗ψ
¢
(θ)
¯¯ ≡
¯¯¯¯(2π)n/2
Z
ρ (x) Fψ (x) F −1θ (x) dx
¯¯¯¯
= lim
m→∞
¯¯¡
F −1ρm ∗ψ
¢
(θ)
¯¯ ≤lim
m→∞sup
¯¯¯¯F −1ρm ∗ψ
¯¯¯¯
p ||θ||p′
≤Ap (L, n, φ, C0, p) ||ψ||p ||θ||p′ .
Hence F −1ρ ∗ψ ∈Lp (Rn) and
¯¯¯¯F −1ρ ∗ψ
¯¯¯¯
p ≤Ap ||ψ||p. This proves the theorem.
20.4
Singular Integrals
If K ∈L1 (Rn) then when p > 1,
||K ∗f||p ≤||f||p .
It turns out that some meaning can be assigned to K ∗f for some functions K
which are not in L1. This involves assuming a certain form for K and exploiting
cancellation. The resulting theory of singular integrals is very useful. To illustrate,
an application will be given to the Helmholtz decomposition of vector ﬁelds in the
next section. Like Mihlin’s theorem, the theory presented here rests on Theorem
20.8, restated here for convenience.
Theorem 20.13 Let ρ ∈L2 (Rn) ∩L∞(Rn) and suppose
Z
|x|≥2|y|
¯¯F −1ρ (x −y) −F −1ρ (x)
¯¯ dx ≤C1.
Then for each p ∈(1, ∞), there exists a constant, Ap, depending only on
p, n, ||ρ||∞,
and C1 such that for all φ ∈G,
¯¯¯¯F −1ρ ∗φ
¯¯¯¯
p ≤Ap ||φ||p .

560
FOURIER ANALYSIS IN RN AN INTRODUCTION
Lemma 20.14 Suppose
K ∈L2 (Rn) , ||FK||∞≤B < ∞,
(20.39)
and
Z
|x|>2|y|
|K (x −y) −K (x)| dx ≤B.
Then for all p > 1, there exists a constant, A (p, n, B), depending only on the
indicated quantities such that
||K ∗f||p ≤A (p, n, B) ||f||p
for all f ∈G.
Proof: Let FK = ρ so F −1ρ = K. Then from 20.39 ρ ∈L2 (Rn) ∩L∞(Rn)
and K = F −1ρ. By Theorem 20.8 listed above,
||K ∗f||p =
¯¯¯¯F −1ρ ∗f
¯¯¯¯
p ≤A (p, n, B) ||f||p
for all f ∈G. This proves the lemma.
The next lemma provides a situation in which the above conditions hold.
Lemma 20.15 Suppose
|K (x)| ≤B |x|−n ,
(20.40)
Z
a<|x|<b
K (x) dx = 0,
(20.41)
Z
|x|>2|y|
|K (x −y) −K (x)| dx ≤B.
(20.42)
Deﬁne
Kε (x) =
½
K (x) if |x| ≥ε,
0 if |x| < ε.
(20.43)
Then there exists a constant C (n) such that
Z
|x|>2|y|
|Kε (x −y) −Kε (x)| dx ≤C (n) B
(20.44)
and
||FKε||∞≤C (n) B.
(20.45)
Proof: In the argument, C (n) will denote a generic constant depending only on
n. Consider 20.44 ﬁrst. The integral is broken up according to whether |x| , |x −y| >
ε.
|x|
> ε
> ε
< ε
< ε
|x −y|
> ε
< ε
< ε
> ε

20.4.
SINGULAR INTEGRALS
561
R
|x|≥2|y| |Kε (x −y) −Kε (x)| dx =
R
|x|≥2|y|,|x−y|>ε,|x|<ε
|Kε (x −y) −Kε (x)| dx+
+
R
|x|≥2|y|,|x−y|<ε,|x|≥ε
|Kε (x −y) −Kε (x)| dx+
R
|x|≥2|y|,|x−y|>ε,|x|>ε
|Kε (x −y) −Kε (x)| dx+
+
R
|x|≥2|y|,|x−y|<ε,|x|<ε
|Kε (x −y) −Kε (x)| dx.
(20.46)
Now consider the terms in the above expression. The last integral in 20.46 equals 0
from the deﬁnition of Kε. The third integral on the right is no larger than B by the
deﬁnition of Kε and 20.42. Consider the second integral on the right. This integral
is no larger than
Z
|x|≥2|y|,|x|≥ε,|x−y|<ε
B |x|−n dx.
Now |x| ≤|y| + ε ≤|x| /2 + ε and so |x| < 2ε. Thus this is no larger than
Z
ε≤|x|≤2ε
B |x|−n dx = B
Z
Sn−1
Z 2ε
ε
ρn−1 1
ρn dρdσ ≤BC (n) ln 2 = C (n) B.
It remains to estimate the ﬁrst integral on the right in 20.46.
This integral is
bounded by
Z
|x|≥2|y|,|x−y|>ε,|x|<ε
B |x −y|−n dx
In the integral above, |x| < ε and so |x −y|−|y| < ε. Therefore, |x −y| < ε+|y| <
ε + |x| /2 < ε + ε/2 = (3/2) ε. Hence ε ≤|x −y| ≤(3/2) |x −y|. Therefore, the
above integral is no larger than
Z (3/2)ε
ε
B |z|−n dz = B
Z
Sn−1
Z (3/2)ε
ε
ρ−1dρdσ = BC (n) ln (3/2) .
This establishes 20.44.
Now it remains to show 20.45, a statement about the Fourier transforms of Kε.
Fix ε and let y ̸= 0 also be given.
KεR (y) ≡
½
Kε (y) if |y| < R,
0 if |y| ≥R
where R >
3π
|y|. (The 3 here isn’t important. It just needs to be larger than 1.)
Then
|FKεR (y)| ≤
¯¯¯¯¯¯¯
Z
0<|x|<3π|y|−1
Kε (x) e−ix·ydx
¯¯¯¯¯¯¯
+
¯¯¯¯¯¯¯
Z
3π|y|−1<|x|≤R
Kε (x) e−ix·ydx
¯¯¯¯¯¯¯

562
FOURIER ANALYSIS IN RN AN INTRODUCTION
= A + B.
(20.47)
Consider A. By 20.41
Z
ε<|x|<3π|y|−1
Kε (x) dx = 0
and so
A =
¯¯¯¯¯¯¯
Z
ε<|x|<3π|y|−1
Kε (x)
¡
e−ix·y −1
¢
dx
¯¯¯¯¯¯¯
Now
¯¯e−ix·y −1
¯¯ = |2 −2 cos (x · y)|1/2 ≤2 |x · y| ≤2 |x| |y|
so, using polar coordinates, this expression is no larger than
2B
Z
ε<|x|<3π|y|−1
|x|−n |x| |y| dx ≤C (n) B |y|
Z 3π/|y|
ε
dρ ≤BC (n).
Next, consider B. This estimate is based on the trick which follows. Let
z ≡yπ/ |y|2
so that
|z| = π/ |y| , z · y =π.
Then
R
3π|y|−1<|x|≤R
Kε (x) e−ix·ydx = 1
2
R
3π|y|−1<|x|≤R
Kε (x) e−ix·ydx
−1
2
R
3π|y|−1<|x|≤R
Kε (x) e−i(x+z)·ydx.
(20.48)
Here is why. Note in the second of these integrals,
−1
2
Z
3π|y|−1<|x|≤R
Kε (x) e−i(x+z)·ydx
=
−1
2
Z
3π|y|−1<|x|≤R
Kε (x) e−ix·ye−iz·ydx
=
−1
2
Z
3π|y|−1<|x|≤R
Kε (x) e−ix·ye−iπdx
=
1
2
Z
3π|y|−1<|x|≤R
Kε (x) e−ix·ydx.

20.4.
SINGULAR INTEGRALS
563
Then changing the variables in 20.48,,
Z
3π|y|−1<|x|≤R
Kε (x) e−ix·ydx
=
1
2
Z
3π|y|−1<|x|≤R
Kε (x) e−ix·ydx
−1
2
Z
3π|y|−1<|x−z|≤R
Kε (x −z) e−ix·ydx.
Thus
R
3π|y|−1<|x|≤R
Kε (x) e−ix·ydx =
1
2
R
|x|≤R
Kε (x) e−ix·ydx −1
2
R
|x−z|≤R
Kε (x −z) e−ix·ydx
+ 1
2
R
|x−z|≤3π|y|−1
Kε (x −z) e−ix·ydx −1
2
R
|x|≤3π|y|−1
Kε (x) e−ix·ydx.
(20.49)
Since |z| = π/ |y|, it follows |z| =
π
|y| < 3π
|y| < R and so the following picture
describes the situation. In this picture, the radius of each ball equals either R or
3π |y|−1 and each integral above is taken over one of the two balls in the picture,
either the one centered at 0 or the one centered at z.
0
z
t
t
To begin with, consider the integrals which involve Kε (x −z).
R
|x−z|≤R
Kε (x −z) e−ix·ydx
=
R
|x|≤R
Kε (x −z) e−ix·ydx
−
R
|x−z|>R,|x|<R
Kε (x −z) e−ix·ydx
+
R
|x−z|<R,|x|>R
Kε (x −z) e−ix·ydx.
(20.50)

564
FOURIER ANALYSIS IN RN AN INTRODUCTION
Look at the picture. Similarly,
R
|x−z|≤3π|y|−1
Kε (x −z) e−ix·ydx
=
R
|x|≤3π|y|−1
Kε (x −z) e−ix·ydx
−
R
|x−z|>3π|y|−1,|x|<3π|y|−1
Kε (x −z) e−ix·ydx+
R
|x−z|<3π|y|−1,|x|>3π|y|−1
Kε (x −z) e−ix·ydx.
(20.51)
The last integral in 20.50 is taken over a set that is contained in
B (0,R + |z|) \ B (0,R)
illustrated in the following picture as the region between the small ball centered at
0 and the big ball which surrounds the two small balls
0
z
t
t
and so this integral is dominated by
B
µ
1
(R −|z|)n
¶
α (n) ((R + |z|)n −Rn),
an expression which converges to 0 as R →∞. Similarly, the second integral on
the right in 20.50 converges to zero as R →∞. Now consider the last two integrals
in 20.51. Letting 3π |y|−1 play the role of R and using |z| = π/ |y|, these are each
dominated by an expression of the form
B


1
³
3π |y|−1 −|z|
´n

α (n)
³³
3π |y|−1 + |z|
´n
−
³
3π |y|−1´n´
=
B


1
³
3π |y|−1 −π |y|−1´n

α (n) ·
³³
3π |y|−1 + π |y|−1´n
−
³
3π |y|−1´n´

20.4.
SINGULAR INTEGRALS
565
= α (n) B |y|n
(2π)n
1
|y|n ((4π)n −(3π)n) = C (n) B.
Returning to 20.49, the terms involving x −y have now been estimated. Thus,
collecting the terms which have not yet been estimated along with those that have,
B =
¯¯¯¯¯¯¯
Z
3π|y|−1<|x|≤R
Kε (x) e−ix·ydx
¯¯¯¯¯¯¯
≤1
2
¯¯¯¯¯¯¯
Z
|x|<R
Kε (x) e−ix·ydx −
Z
|x|<R
Kε (x −z) e−ix·ydx
+
Z
|x|<3π|y|−1
Kε (x −z) e−ix·ydx −
Z
|x|<3π|y|−1
Kε (x) e−ix·ydx
¯¯¯¯¯¯¯
+C (n) B + g (R)
where g (R) →0 as R →∞. Using |z| = π/ |y| again,
B ≤1
2
Z
3|z|<|x|<R
|Kε (x) −Kε (x −z)| dx + C (n) B + g (R).
But the integral in the above is dominated by C (n) B by 20.44 which was established
earlier. Therefore, from 20.47,
|FKεR| ≤C (n) B + g (R)
where g (R) →0.
Now KεR →Kε in L2 (Rn) because
||KεR −Kε||L2(Rn)
≤
B
Z
|x|>R
1
|x|2n dx
=
B
Z
Sn−1
Z ∞
R
1
ρn+1 dρdσ,
which converges to 0 as R →∞and so FKεR →FKε in L2 (Rn) by Plancherel’s
theorem.
Therefore, by taking a subsequence, still denoted by R, FKεR (y) →
FKε (y) a.e. which shows
|FKε (y)| ≤C (n) B a.e.
This proves the lemma.
Corollary 20.16 Suppose 20.40 - 20.42 hold. Then if g ∈C1
c (Rn), Kε∗g converges
uniformly and in Lp (Rn) as ε →0.

566
FOURIER ANALYSIS IN RN AN INTRODUCTION
Proof:
Kε ∗g (x) ≡
Z
Kε (y) g (x −y) dy.
Let 0 < η < ε. Then since g ∈C1
c (Rn) , there exists a constant, K such that
K |u −v| ≥|g (u) −g (v)| for all u, v ∈Rn.
|Kε ∗g (x) −Kη ∗g (x)|
≤
BK
Z
η<|y|<ε
1
|y|n |y| dy
=
BK
Z
Sn−1
Z ε
η
dρdσ = Cn |ε −η| .
This proves the corollary.
Theorem 20.17 Suppose 20.40 - 20.42. Then for Kε given by 20.43 and p > 1,
there exists a constant A (p, n, B) such that for all f ∈Lp (Rn),
||Kε ∗f||p ≤A (p, n, B) ||f||p .
(20.52)
Also, for each f ∈Lp (Rn),
Tf ≡lim
ε→0 Kε ∗f
(20.53)
exists in Lp (Rn) and for all f ∈Lp (Rn),
||Tf||p ≤A (p, n, B) ||f||p .
(20.54)
Thus T is a linear and continuous map deﬁned on Lp (Rn) for each p > 1.
Proof: From 20.40 it follows Kε ∈Lp′ (Rn) ∩L2 (Rn) where, as usual, 1/p +
1/p′ = 1. By continuity of translation in Lp′ (Rn), x →Kε ∗f (x) is a continuous
function.By Lemma 20.15, ||FKε||∞≤C (n) B for all ε. Therefore, by Lemma
20.14,
||Kε ∗g||p ≤A (p, n, B) ||g||p
for all g ∈G. Now let f ∈Lp (Rn) and gk →f in Lp (Rn) where gk ∈G. Then
|Kε ∗f (x) −Kε ∗gk (x)|
≤
Z
|Kε (x −y)| |gk (y) −f (y)| dy
≤
||Kε||p′ ||gk −f||p
which shows that Kε ∗gk (x) →Kε ∗f (x) pointwise and so by Fatou’s lemma,
||Kε ∗f||p
≤
lim inf
k→∞||Kε ∗gk||p ≤lim inf
k→∞A (p, n, B) ||gk||p
=
A (p, n, B) ||f||p .
This veriﬁes 20.52.
To verify 20.53, let δ > 0 be given and let
f ∈Lp (Rn) , g ∈C∞
c (Rn) .

20.4.
SINGULAR INTEGRALS
567
||Kε ∗f −Kη ∗f||p
≤
||Kε ∗(f −g)||p + ||Kε ∗g −Kη ∗g||p
+ ||Kη ∗(f −g)||p
≤2A (p, n, B) ||f −g||p + ||Kε ∗g −Kη ∗g||p .
Choose g such that 2A (p, n, B) ||f −g||p ≤δ/2. Then if ε, η are small enough,
Corollary 20.16 implies the last term is also less than δ/2. Thus, limε→0 Kε ∗f
exists in Lp (Rn). Let Tf be the element of Lp (Rn) to which it converges. Then
20.54 follows and T is obviously linear because
T (af + bg)
=
lim
ε→0 Kε ∗(af + bg) = lim
ε→0 (aKε ∗f + bKε ∗g)
=
aTf + bTg.
This proves the theorem.
When do conditions 20.40-20.42 hold? It turns out this happens for K given by
the following.
K (x) ≡Ω(x)
|x|n ,
(20.55)
where
Ω(λx) = Ω(x) for all λ > 0,
(20.56)
Ωis Lipschitz on Sn−1,
Z
Sn−1 Ω(x) dσ = 0.
(20.57)
Theorem 20.18 For K given by 20.55 - 20.57, it follows there exists a constant
B such that
|K (x)| ≤B |x|−n,
(20.58)
Z
a<|x|<b
K (x) dx = 0,
(20.59)
Z
|x|>2|y|
|K (x −y) −K (x)| dx ≤B.
(20.60)
Consequently, the conclusions of Theorem 20.17 hold also.
Proof:
20.58 is obvious. To verify 20.59,
Z
a<|x|<b
K (x) dx
=
Z b
a
Z
Sn−1
Ω(ρw)
ρn
ρn−1dσdρ
=
Z b
a
1
ρ
Z
Sn−1 Ω(w) dσdρ = 0.
It remains to show 20.60.
K (x −y) −K (x)
=
|x −y|−n
µ
Ω
µ x −y
|x −y|
¶
−Ω
µ x
|x|
¶¶
+Ω(x)
µ
1
|x −y|n −
1
|x|n
¶
(20.61)

568
FOURIER ANALYSIS IN RN AN INTRODUCTION
where 20.56 was used to write Ω
³
z
|z|
´
= Ω(z). The ﬁrst group of terms in 20.61 is
dominated by
|x −y|−n Lip (Ω)
¯¯¯¯
x −y
|x −y| −x
|x|
¯¯¯¯
and an estimate is required for |x| > 2 |y|. Since |x| > 2 |y|,
|x −y|−n ≤(|x| −|y|)−n ≤2n
|x|n .
Also
¯¯¯¯
x −y
|x −y| −x
|x|
¯¯¯¯ =
¯¯¯¯
(x −y) |x| −x |x −y|
|x| |x −y|
¯¯¯¯
≤
¯¯¯¯
(x −y) |x| −x |x −y|
|x| (|x| −|y|)
¯¯¯¯ ≤
¯¯¯¯
(x −y) |x| −x |x −y|
|x| (|x| /2)
¯¯¯¯
=
2
|x|2 |x |x| −y |x| −x |x −y|| =
2
|x|2 |x (|x| −|x −y|) −y |x||
≤
2
|x|2 |x| ||x| −|x −y|| + |y| |x| ≤
2
|x|2 (|x| |x−(x −y)| + |y| |x|)
≤
4
|x|2 |x| |y| = 4|y|
|x|.
Therefore,
Z
|x|>2|y|
|x −y|−n
¯¯¯¯Ω
µ x −y
|x −y|
¶
−Ω
µ x
|x|
¶¯¯¯¯ dx
≤4 (2n)
Z
|x|>2|y|
1
|x|n
|y|
|x|dx Lip (Ω)
= C (n, Lip Ω)
Z
|x|>2|y|
|y|
|x|n+1 dx
= C (n, Lip Ω)
Z
|u|>2
1
|u|n+1 du.
(20.62)
It remains to consider the second group of terms in 20.61 when |x| > 2 |y|.
¯¯¯¯
1
|x −y|n −
1
|x|n
¯¯¯¯ =
¯¯¯¯
|x|n −|x −y|n
|x −y|n |x|n
¯¯¯¯
≤
2n
|x|2n ||x|n −|x −y|n|
≤
2n
|x|2n |y|
h
|x|n−1 + |x|n−2 |x −y| +
· · · + |x| |x −y|n−2 + |x −y|n−1i

20.5.
HELMHOLTZ DECOMPOSITIONS
569
≤2n |y| C (n) |x|n−1
|x|2n
= C (n) 2n |y|
|x|n+1
.
Thus
Z
|x|>2|y|
¯¯¯¯Ω(x)
µ
1
|x −y|n −
1
|x|n
¶¯¯¯¯ dx
≤
C (n)
Z
|x|>2|y|
|y|
|x|n+1 dx
≤C (n)
Z
|u|>2
1
|u|n+1 du.
(20.63)
From 20.62 and 20.63,
Z
|x|>2|y|
|K (x −y) −K (x)| dx ≤C (n, Lip Ω).
This proves the theorem.
20.5
Helmholtz Decompositions
It turns out that every vector ﬁeld which has its components in Lp can be written
as a sum of a gradient and a vector ﬁeld which has zero divergence. This is a very
remarkable result, especially when applied to vector ﬁelds which are only in Lp.
Recall that for u a function of n variables, ∆u = Pn
i=1
∂2u
∂x2
i .
Deﬁnition 20.19 Deﬁne
Φ (y) ≡
(
−1
a1 ln |y| , if n = 2,
1
(n−2)an−1 |y|2−n , if n > 2.
where ak denotes the area of the unit sphere, Sk.
Then it is routine to verify ∆Φ = 0 away from 0. In fact, if n > 2,
Φ,ii (y) = Cn
"
1
|y|n −n
y2
i
|y|n+2
#
, Φ,ij (y) = Cn
yiyj
|y|n+2 ,
(20.64)
while if n = 2,
Φ,22 (y) = C2
y2
1 −y2
2
(y2
1 + y2
2)2 , Φ,11 (y) = C2
y2
2 −y2
1
(y2
1 + y2
2)2 ,
Φ,ij (y) = C2
y1y2
(y2
1 + y2
2)2 .
Also,
∇Φ (y) =
−y
an−1 |y|n .
(20.65)
In the above the subscripts following a comma denote partial derivatives.

570
FOURIER ANALYSIS IN RN AN INTRODUCTION
Lemma 20.20 For n ≥2
Φ,ij (y) = Ωij (y)
|y|n
where
Ωij is Lipschitz continuous on Sn−1,
(20.66)
Ωij (λy) = Ωij (y),
(20.67)
for all λ > 0, and
Z
Sn−1 Ωij (y) dσ = 0.
(20.68)
Proof:
Proof: The case n = 2 is left to the reader. 20.66 and 20.67 are obvious from
the above descriptions. It remains to verify 20.68. If n ≥3 and i ̸= j, then this
formula is also clear from 20.64. Thus consider the case when n ≥3 and i = j. By
symmetry,
I ≡
Z
Sn−1 1 −ny2
i dσ =
Z
Sn−1 1 −ny2
j dσ.
Hence
nI
=
n
X
i=1
Z
Sn−1 1 −ny2
i dσ =
Z
Sn−1
Ã
n −n
X
i
y2
i
!
dσ
=
Z
Sn−1 (n −n) dσ = 0.
This proves the lemma.
Let U be a bounded open set locally on one side of its boundary having Lipschitz
boundary so the divergence theorem holds and let B = B (0,R) where
B ⊇U −U ≡{x −y : x ∈U, y ∈U}
Let f ∈C∞
c (U) and deﬁne for x ∈U,
u (x) ≡
Z
B
Φ (y) f (x −y) dy =
Z
U
Φ (x −y) f (y) dy.
Let h (y) = f (x −y) . Then since Φ is in L1 (B),
∆u (x) =
Z
B
Φ (y) ∆f (x −y) dy =
Z
B
Φ (y) ∆h (y) dy
=
Z
B\B(0,ε)
∇· (∇h (y) Φ (y)) −∇Φ (y) · ∇h (y) dy
+
Z
B(0,ε)
Φ (y) ∆h (y) dy.

20.5.
HELMHOLTZ DECOMPOSITIONS
571
The last term converges to 0 as ε →0 because Φ is in L1 and ∆h is bounded. Since
spt (h) ⊆B, the divergence theorem implies
∆u (x) = −
Z
∂B(0,ε)
Φ (y) ∇h (y)·ndσ−
Z
B\B(0,ε)
∇Φ (y)·∇h (y) dy+e (ε) (20.69)
where here and below, e (ε) →0 as ε →0. The ﬁrst term in 20.69 converges to 0
as ε →0 because
¯¯¯¯¯
Z
∂B(0,ε)
Φ (y) ∇h (y) · ndσ
¯¯¯¯¯ ≤
½
Cnh
1
εn−2 εn−1 = Cnhε if n > 2
Ch (ln ε) ε if n = 2
and since ∆Φ (y) = 0,
∇Φ (y) · ∇h (y) = ∇· (∇Φ (y) h (y)).
Consequently
∆u (x) = −
Z
B\B(0,ε)
∇· (∇Φ (y) h (y)) dy + e (ε).
Thus, by the divergence theorem, 20.65, and the deﬁnition of h above,
∆u (x)
=
Z
∂B(0,ε)
f (x −y) ∇Φ (y) · ndσ + e (ε)
=
Z
∂B(0,ε)
f (x −y)
µ
−
y
an−1 |y|n
¶
·
µ
−y
|y|
¶
dσ + e (ε)
=
−
ÃZ
∂B(0,ε)
f (x −y) dσ (y)
!
1
an−1εn−1 + e (ε).
Letting ε →0,
−∆u (x) = f (x).
This proves the following lemma.
Lemma 20.21 Let U be a bounded open set in Rn with Lipschitz boundary and let
B ⊇U −U where B = B (0,R). Let f ∈C∞
c (U). Then for x ∈U,
Z
B
Φ (y) f (x −y) dy =
Z
U
Φ (x −y) f (y) dy,
and it follows that if u is given by one of the above formulas, then for all x ∈U,
−∆u (x) = f (x).
Theorem 20.22 Let f ∈Lp (U). Then there exists u ∈Lp (U) whose weak deriva-
tives are also in Lp (U) such that in the sense of weak derivatives,
−∆u = f.

572
FOURIER ANALYSIS IN RN AN INTRODUCTION
It is given by
u (x) =
Z
B
Φ (y) ef (x −y) dy =
Z
U
Φ (x −y) f (y) dy
(20.70)
where ef denotes the zero extension of f oﬀof U.
Proof: Let f ∈Lp (U) and let fk ∈C∞
c (U) , ||fk −f||Lp(U) →0, and let uk be
given by 20.70 with fk in place of f. Then by Minkowski’s inequality,
||u −uk||Lp(U)
=
µZ
U
µZ
B
Φ (y)
¯¯¯ ef (x −y) −fk (x −y)
¯¯¯ dy
¶p
dx
¶1/p
≤
ÃZ
B
|Φ (y)|
µZ
U
¯¯¯ ef (x −y) −fk (x −y)
¯¯¯
p
dx
¶1/p
dy
!
≤
Z
B
|Φ (y)| dy ||f −fk||Lp(U) = C (B) ||f −fk||Lp(U)
and so uk →u in Lp (U). Also
uk,i (x) =
Z
U
Φ,i (x −y) fk (y) dy =
Z
B
fk (x −y) Φ,i (y) dy.
Now let
wi ≡
Z
B
ef (x −y) Φ,i (y) dy.
(20.71)
and since Φ,i ∈L1 (B), it follows from Minkowski’s inequality that
||uk,i −wi||Lp(U)
≤
µZ
U
µZ
B
¯¯¯fk (x −y) −ef (x −y)
¯¯¯ |Φ,i (y)| dy
¶p
dx
¶1/p
≤
Z
B
|Φ,i (y)|
µZ
U
¯¯¯fk (x −y) −ef (x −y)
¯¯¯
p
dx
¶1/p
dy
≤
C (B) ||fk −f||Lp(U)
and so uk,i →wi in Lp (U).
Now let φ ∈C∞
c (U). Then
Z
U
wiφdx = −lim
k→∞
Z
U
ukφ,idx = −
Z
U
uφ,idx.
Thus u,i = wi ∈Lp (Rn) and so if φ ∈C∞
c (U),
Z
U
fφdx = lim
k→∞
Z
U
fkφdx = lim
k→∞
Z
U
∇uk · ∇φdx =
Z
U
∇u · ∇φdx
and so −∆u = f as claimed. This proves the theorem.

20.5.
HELMHOLTZ DECOMPOSITIONS
573
One could also ask whether the second weak partial derivatives of u are in
Lp (U). This is where the theory singular integrals is used. Recall from 20.70 and
20.71 along with the argument of the above lemma, that if u is given by 20.70, then
u,i is given by 20.71 which equals
Z
U
Φ,i (x −y) f (y) dy.
Lemma 20.23 Let f ∈Lp (U) and let
wi (x) ≡
Z
U
Φ,i (x −y) f (y) dy.
Then wi,j ∈Lp (U) for each j = 1 · · · n and the map f →wi,j is continuous and
linear on Lp (U).
Proof: First let f ∈C∞
c (U). For such f,
wi (x)
=
Z
U
Φ,i (x −y) f (y) dy =
Z
Rn Φ,i (x −y) f (y) dy
=
Z
Rn Φ,i (y) f (x −y) dy =
Z
B
Φ,i (y) f (x −y) dy
and
wi,j (x)
=
Z
B
Φ,i (y) f,j (x −y) dy
=
Z
B\B(0,ε)
Φ,i (y) f,j (x −y) dy +
Z
B(0,ε)
Φ,i (y) f,j (x −y) dy.
The second term converges to 0 because f,j is bounded and by 20.65, Φ,i ∈L1
loc.
Thus
wi,j (x)
=
Z
B\B(0,ε)
Φ,i (y) f,j (x −y) dy + e (ε)
=
Z
B\B(0,ε)
−(Φ,i (y) f (x −y)),j + Φ,ij (y) f (x −y) dy + e (ε)
where e (ε) →0 as ε →0. Using the divergence theorem, this yields
wi,j (x) =
Z
∂B(0,ε)
Φ,i (y) f (x −y) njdσ +
Z
B\B(0,ε)
Φ,ij (y) f (x −y) dy + e (ε).
Consider the ﬁrst term on the right. This term equals, after letting y = εz,
εn−1
Z
∂B(0,1)
Φ,i (εz) f (x−εz) njdσ
=
Cnεn−1
Z
∂B(0,1)
ε1−nzizjf (x−εz) dσ (z)
=
Cn
Z
∂B(0,1)
zizjf (x−εz) dσ (z)

574
FOURIER ANALYSIS IN RN AN INTRODUCTION
and this converges to 0 if i ̸= j and it converges to
Cnf (x)
Z
∂B(0,1)
z2
i dσ (z)
if i = j. Thus
wi,j (x) = Cnδijf (x) +
Z
B\B(0,ε)
Φ,ij (y) f (x −y) dy + e (ε).
Letting
Φε
ij ≡
½
0 if |y| < ε,
Φ,ij (y) if |y| ≥ε,
it follows
wi,j (x) = Cnδijf (x) + Φε
ij ∗ef (x) + e (ε) .
By the theory of singular integrals, there exists a continuous linear map, Kij ∈
L (Lp (Rn) , Lp (Rn)) such that
Kijf ≡lim
ε→0 Φε
ij ∗f.
Therefore, letting ε →0,
wi,j = Cnδijf + Kij ef
whenever f ∈C∞
c (U).
Now let f ∈Lp (U), let
||fk −f||Lp(U) →0,
where fk ∈C∞
c (U), and let
wk
i (x) =
Z
U
Φ,i (x −y) fk (y) dy.
Then it follows as before that wk
i →wi in Lp (U) and
wk
i,j = Cnδijfk + Kij efk.
Now let φ ∈C∞
c (U).
wi,j (φ)
≡
−
Z
U
wiφ,jdx = −lim
k→∞
Z
U
wk
i φ,jdx
=
lim
k→∞
Z
U
wk
i,jφdx = lim
k→∞
Z
U
³
Cnδij efk + Kij efk
´
φdx
=
Z
U
³
Cnδij ef + Kij ef
´
φdx.
It follows
wi,j = Cnδij ef + Kij ef
and this proves the lemma.

20.5.
HELMHOLTZ DECOMPOSITIONS
575
Corollary 20.24 In the situation of Theorem 20.22, all weak derivatives of u of
order 2 are in Lp (U) and also f →u,ij is a continuous map.
Proof:
u,i (x) =
Z
U
Φ,i (x −y) f (y) dy
and so u,ij ∈Lp (U) and f →u,ij is continuous by Lemma 20.23.
With this preparation, it is possible to consider the Helmholtz decomposition.
Let F ∈Lp (U; Rn) and deﬁne
φ (x) ≡
Z
U
∇Φ (x −y) · F (y) dy.
(20.72)
Then by Lemma 20.23,
φ,j = Cn eFj +
X
i
Kij eFi ∈Lp (Rn)
and the mapping F →∇φ is continuous from Lp (U; Rn) to Lp (U; Rn).
Now suppose F ∈C∞
c (U; Rn). Then
φ (x)
=
Z
U
n
X
i=1
−∂
∂yi (Φ (x −y) Fi (y)) + Φ (x −y) ∇· F (y) dy
=
Z
U
Φ (x −y) ∇· F (y) dy
and so by Lemma 20.21,
∇· ∇φ = ∆φ = −∇· F.
This continues to hold in the sense of weak derivatives if F is only in Lp (U; Rn)
because by Minkowski’s inequality and 20.72 the map F →φ is continuous. Also
note that for F ∈C∞
c (U; Rn),
φ (x) =
Z
B
Φ (y) ∇· F (x −y) dy.
Next deﬁne π : Lp (U; Rn) →Lp (U; Rn) by
πF = −∇φ, φ (x) =
Z
U
∇Φ (x −y) · F (y) dy.
It was already shown that π is continuous, linear, and ∇· πF =∇· F. It is also true
that π is a projection. To see this, let F ∈C∞
c (U; Rn). Then for B large enough,
π2F (x)
=
−∇
Z
B
Φ (z) ∇· πF (x −z) dz
=
−∇
Z
B
Φ (z) ∇· ∇
Z
B
Φ (w) ∇· F (x −z −w) dwdz
=
−∇
Z
B
Φ (z) ∇· F (x −z) dz = πF (x).

576
FOURIER ANALYSIS IN RN AN INTRODUCTION
Since π is continuous and C∞
c (U; Rn) is dense in Lp (U; Rn), π2F =πF for all F ∈
Lp (U; Rn). This proves the following theorem which is the Helmholtz decomposi-
tion.
Theorem 20.25 There exists a continuous projection
π : Lp (U; Rn) →Lp (U; Rn)
such that πF is a gradient and
∇· (F−πF) = 0
in the sense of weak derivatives.
Note this theorem shows that any Lp vector ﬁeld is the sum of a gradient and a
part which is divergence free. F = F−πF+πF.

The Bochner Integral
21.1
Strong And Weak Measurability
In this chapter (Ω, S,µ) will be a σ ﬁnite measure space and X will be a Banach
space which contains the values of either a function or a measure. The Banach
space will be either a real or a complex Banach space but the ﬁeld of scalars does
not matter and so it is denoted by F with the understanding that F = C unless
otherwise stated. The theory presented here includes the case where X = Rn or
Cn but it does not include the situation where f could have values in a space like
[0, ∞]. To begin with here is a deﬁnition.
Deﬁnition 21.1 A function, x : Ω→X, for X a Banach space, is a simple
function if it is of the form
x (s) =
n
X
i=1
aiXBi (s)
where Bi ∈S and µ (Bi) < ∞for each i. A function x from Ωto X is said to be
strongly measurable if there exists a sequence of simple functions {xn} converging
pointwise to x. The function x is said to be weakly measurable if, for each f ∈X′,
f ◦x
is a scalar valued measurable function.
Earlier, a function was measurable if inverse images of open sets were measur-
able. Something similar holds here. The diﬀerence is that another condition needs
to hold.
Theorem 21.2 x is strongly measurable if and only if x−1 (U) is measurable for
all U open in X and x (Ω) is separable.
Proof: Suppose ﬁrst x−1 (U) is measurable for all U open in X and x (Ω)
is separable.
Let {an}∞
n=1 be the dense subset of x (Ω).
It follows x−1 (B) is
measurable for all B Borel because
{B : x−1 (B) is measurable}
577

578
THE BOCHNER INTEGRAL
is a σ algebra containing the open sets. Let
U n
k ≡{z ∈X : ||z −ak|| ≤min{||z −al||n
l=1}}.
In words, U m
k is the set of points of X which are as close to ak as they are to any
of the al for l ≤n.
Bn
k ≡x−1 (U n
k ) , Dn
k ≡Bn
k \
¡
∪k−1
i=1 Bn
i
¢
, Dn
1 ≡Bn
1 ,
and
xn (s) ≡
n
X
k=1
akXDn
k (s).
Thus xn (s) is a closest approximation to x (s) from {ak}n
k=1 and so xn (s) →x (s)
because {an}∞
n=1 is dense in x (Ω). Furthermore, xn is measurable because each Dn
k
is measurable.
Since (Ω, S, µ) is σ ﬁnite, there exists Ωn ↑Ωwith µ (Ωn) < ∞. Let
yn (s) ≡XΩn (s) xn (s).
Then yn (s) →x (s) for each s because for any s, s ∈Ωn if n is large enough. Also
yn is a simple function because it equals 0 oﬀa set of ﬁnite measure.
Now suppose that x is strongly measurable.
Then some sequence of simple
functions, {xn}, converges pointwise to x. Then x−1
n (W) is measurable for every
open set W because it is just a ﬁnite union of measurable sets. Thus, x−1
n (W) is
measurable for every Borel set W. This follows by considering
©
W : x−1
n (W) is measurable
ª
and observing this is a σ algebra which contains the open sets. Since X is a metric
space, it follows that if U is an open set in X , there exists a sequence of open sets,
{Vn} which satisﬁes
V n ⊆U, V n ⊆Vn+1, U = ∪∞
n=1Vn.
Then
x−1 (Vm) ⊆
[
n<∞
\
k≥n
x−1
k
(Vm) ⊆x−1 ¡
V m
¢
.
This implies
x−1 (U) =
[
m<∞
x−1 (Vm)
⊆
[
m<∞
[
n<∞
\
k≥n
x−1
k
(Vm) ⊆
[
m<∞
x−1 ¡
V m
¢
⊆x−1 (U).
Since
x−1 (U) =
[
m<∞
[
n<∞
\
k≥n
x−1
k
(Vm),

21.1.
STRONG AND WEAK MEASURABILITY
579
it follows that x−1 (U) is measurable for every open U. It remains to show x (Ω) is
separable. Let
D ≡all values of the simple functions xn
which converge to x pointwise. Then D is clearly countable and dense in D, a set
which contains x (Ω).
Claim: x (Ω) is separable.
Proof of claim: For n ∈N, let Bn ≡
©
B (d, r) : 0 < r < 1
n, r rational, d ∈D
ª
.
Thus Bn is countable. Let z ∈D. Consider B
¡
z, 1
n
¢
. Then there exists d ∈D ∩
B
¡
z, 1
3n
¢
. Now pick r ∈Q ∩
¡ 1
3n, 1
n
¢
so that B (d, r) ∈Bn. Now z ∈B (d, r) and so
this shows that x (Ω) ⊆D ⊆∪Bn for each n. Now let B′
n denote those sets of Bn
which have nonempty intersection with x (Ω) . Say B′
n = {Bn
k }∞
n,k=1 . By the axiom
of choice, there exists xn
k ∈Bn
k ∩x (Ω) . Then if z ∈x (Ω) , z is contained in some set
of B′
n which also contains a point of {xn
k}∞
n,k=1 . Therefore, z is at least as close as
2/n to some point of {xn
k}∞
n,k=1 which shows {xn
k}∞
n,k=1 is a countable dense subset
of x (Ω) . Therefore x (Ω) is separable. This proves the theorem.
The last part also shows that a subset of a separable metric space is also sepa-
rable. Therefore, the following simple corollary is obtained.
Corollary 21.3 If X is a separable Banach space then x is strongly measurable if
and only if x−1 (U) is measurable for all U open in X.
The next lemma is interesting for its own sake. Roughly it says that if a Banach
space is separable, then the unit ball in the dual space is weak ∗separable. This
will be used to prove Pettis’s theorem, one of the major theorems in this subject
which relates weak measurability to strong measurability.
Lemma 21.4 If X is a separable Banach space with B′ the closed unit ball in X′,
then there exists a sequence {fn}∞
n=1 ≡D′ ⊆B′ with the property that for every
x ∈X,
||x|| = sup
f∈D′ |f (x)|
Proof: Let {ak} be a countable dense set in X and consider the mapping
φn : B′ →Fn
given by
φn (f) ≡(f (a1) , · · ·, f (an)) .
Then φn (B′) is contained in a compact subset of Fn because |f (ak)| ≤||ak|| .
Therefore, there exists a countable dense subset of φn (B′) , {φn (f n
k )}∞
k=1 . Let D′
n ≡
{f n
k }∞
k=1 . Let
D′ ≡∪∞
k=1D′
k.
It remains to show this works. Letting x ∈X and ε > 0 be given, there exists am
such that ||am −x|| < ε. Then by the usual argument involving the Hahn Banach

580
THE BOCHNER INTEGRAL
theorem, there exists fx ∈B′ such that ||x|| = fx (x) . Letting n > m, let g ∈B′ be
one of the f n
k with {φn (f n
k )}∞
k=1 a dense subset of φn (B′) such that
|g (am) −fx (am)| < ε.
Then
||x||
=
|fx (x)| = |fx (am) + fx (x) −fx (am)|
≤
|fx (am)| + ε ≤|g (am)| + 2ε ≤|g (x)| + 3ε
and so since ε > 0 is arbitrary,
||x|| ≤sup
g∈D′ |g (x)| ≤||x||
and this proves the lemma.
The next theorem is one of the most important results in the subject. It is due
to Pettis and appeared in 1938.
Theorem 21.5 If x has values in a separable Banach space, X, and if x is weakly
measurable, then x is strongly measurable.
Proof:
It is necessary to show x−1 (U) is measurable whenever U is open.
Since every open set is a countable union of balls, it suﬃces to show x−1 (B (a, r))
is measurable for any ball, B (a, r) . Since every open ball is the countable union of
closed balls, it suﬃces to verify x−1 ³
B (a, r)
´
is measurable. From Lemma 21.4
x−1 ³
B (a, r)
´
=
{s : ||x (s) −a|| ≤r}
=
(
s : sup
f∈D′ |f (x (s) −a)| ≤r
)
=
∩f∈D′ {s : |f (x (s) −a)| ≤r}
=
∩f∈D′ {s : |f (x (s)) −f (a)| ≤r}
=
∩f∈D′ (f ◦x)−1 B (f (a) , r)
which equals a countable union of measurable sets because it is assumed that f ◦x
is measurable for all f ∈X′. This proves the theorem.
The same method of proof yields the following interesting corollary.
Corollary 21.6 Let X be a separable Banach space and let B (X) denote the σ
algebra of Borel sets. Then B (X) = F where F is the smallest σ algebra of subsets
of X which has the property that every function, x∗∈X′ is F measurable.
Proof: First I need to show F contains open balls because then F will contain
the open sets, since every open set is a countable union of open balls, which will
imply F ⊇B (X). As noted above, it suﬃces to verify F contains the closed balls

21.1.
STRONG AND WEAK MEASURABILITY
581
because every open ball is a countable union of closed balls.
Let D′ be those
functionals in B′ deﬁned in Lemma 21.4. Then
{x : ||x −a|| ≤r}
=
½
x : sup
x∗∈D′ |x∗(x −a)| ≤r
¾
=
∩x∗∈D′ {x : |x∗(x −a)| ≤r}
=
∩x∗∈D′ {x : |x∗(x) −x∗(a)| ≤r}
=
∩x∗∈D′x∗−1 ³
B (x∗(a) , r)
´
which is measurable because this is a countable intersection of measurable sets.
Thus F contains open sets so F ⊇B (X) .
To show the other direction for the inclusion, note that each x∗is B (X) mea-
surable because x∗−1 (open set) = open set. Therefore, B (X) is a σ algebra with
respect to which each x∗is measurable and F is the smallest of these so B (X) ⊇F.
This proves the corollary.
It is important to verify the limit of strongly measurable functions is itself
strongly measurable.
This happens under very general conditions.
Suppose X
is any separable metric space and let τ denote the open sets of X. Then it is routine
to see that
τ has a countable basis, B.
(21.1)
Whenever U ∈B, there exists a sequence of open sets, {Vm}∞
m=1, such that
· · · Vm ⊆V m ⊆Vm+1 ⊆· · · , U =
∞
[
m=1
Vm.
(21.2)
Theorem 21.7 Let fn and f be functions mapping Ωto X where F is a σ algebra
of measurable sets of Ωand (X, τ) is a topological space satisfying 21.1 - 21.2. Then
if fn is measurable, and f(ω) = limn→∞fn(ω), it follows that f is also measurable.
(Pointwise limits of measurable functions are measurable.)
Proof: Let B be the countable basis of 21.1 and let U ∈B. Let {Vm} be the
sequence of 21.2. Since f is the pointwise limit of fn,
f −1(Vm) ⊆{ω : fk(ω) ∈Vm for all k large enough} ⊆f −1(Vm).
Therefore,
f −1(U) = ∪∞
m=1f −1(Vm) ⊆∪∞
m=1 ∪∞
n=1 ∩∞
k=nf −1
k (Vm)
⊆∪∞
m=1f −1(Vm) = f −1(U).
It follows f −1(U) ∈F because it equals the expression in the middle which is
measurable. Now let W ∈τ. Since B is countable, W = ∪∞
n=1Un for some sets
Un ∈B. Hence
f −1(W) = ∪∞
n=1f −1(Un) ∈F.
This proves the theorem.

582
THE BOCHNER INTEGRAL
Corollary 21.8 x is strongly measurable if and only if x (Ω) is separable and x is
weakly measurable.
Proof: Strong measurability clearly implies weak measurability. If xn (s) →
x (s) where xn is simple, then f (xn (s)) →f (x (s)) for all f ∈X′. Hence f ◦x
is measurable by Theorem 21.7 because it is the limit of a sequence of measurable
functions. Let D denote the set of all values of xn. Then D is a separable set
containing x (Ω). Thus D is a separable metric space. Therefore x (Ω) is separable
also by the last part of the proof of Theorem 21.2.
Now suppose D is a countable dense subset of x (Ω) and x is weakly measurable.
Let Z be the subset consisting of all ﬁnite linear combinations of D with the scalars
coming from the set of rational points of F. Thus, Z is countable. Letting Y = Z,
Y is a separable Banach space containing x (Ω). If f ∈Y ′, f can be extended to an
element of X′ by the Hahn Banach theorem. Therefore, x is a weakly measurable
Y valued function. Now use Theorem 21.5 to conclude x is strongly measurable.
This proves the corollary.
Weakly measurable as deﬁned above means s →x∗(x (s)) is measurable for
every x∗∈X′. The next lemma ties this to the usual version of measurability in
which a function is measurable when inverse images of open sets are measurable.
Lemma 21.9 Let X be a Banach space and let x : (Ω, F) →K ⊆X where K is
weakly compact and X′ is separable. Then x is weakly measurable if and only if
x−1 (U) ∈F whenever U is a weakly open set.
Proof: By Corollary 13.41 on Page 358, there exists a metric d, such that the
metric space topology with respect to d coincides with the weak topology. Since
K is compact, it follows that K is also separable. Hence it is completely separable
and so there exists a countable basis of open sets, B for the weak topology on K. It
follows that if U is any weakly open set, covered by basic sets of the form BA (x, r)
where A is a ﬁnite subset of X′, there exists a countable collection of these sets of
the form BA (x, r) which covers U.
Suppose now that x is weakly measurable. To show x−1 (U) ∈F whenever U
is weakly open, it suﬃces to verify x−1 (BA (z, r)) ∈F for any set, BA (z, r) . Let
A = {x∗
1, · · ·, x∗
m} . Then
x−1 (BA (z, r))
=
{s ∈Ω: ρA (x (s) −z) < r}
≡
½
s ∈Ω: max
x∗∈A |x∗(x (s) −z)| < r
¾
=
∪m
i=1 {s ∈Ω: |x∗
i (x (s) −z)| < r}
=
∪m
i=1 {s ∈Ω: |x∗
i (x (s)) −x∗
i (z)| < r}
which is measurable because each x∗
i ◦x is given to be measurable.
Next suppose x−1 (U) ∈F whenever U is weakly open. Then in particular this
holds when U = Bx∗(z, r) for arbitrary x∗. Hence
{s ∈Ω: x (s) ∈Bx∗(z, r)} ∈F.

21.1.
STRONG AND WEAK MEASURABILITY
583
But this says the same as
{s ∈Ω: |x∗(x (s)) −x∗(z)| < r} ∈F
Since x∗(z) can be a completely arbitrary element of F, it follows x∗◦x is an F
valued measurable function. In other words, x is weakly measurable according to
the former deﬁnition. This proves the lemma.
One can also deﬁne weak ∗measurability and prove a theorem just like the
Pettis theorem above. The next lemma is the analogue of Lemma 21.4.
Lemma 21.10 Let B be the closed unit ball in X. If X′ is separable, there exists
a sequence {xm}∞
m=1 ≡D ⊆B with the property that for all y∗∈X′,
||y∗|| = sup
x∈D
|y∗(x)| .
Proof:
Let
{x∗
k}∞
k=1
be the dense subspace of X′. Deﬁne φn : B →Fn by
φn (x) ≡(x∗
1 (x) , · · ·, x∗
n (x)).
Then |x∗
k (x)| ≤||x∗
k|| and so φn (B) is contained in a compact subset of Fn.
Therefore, there exists a countable set, Dn ⊆B such that φn (Dn) is dense in
φn (B) . Let
D ≡∪∞
n=1Dn.
It remains to verify this works. Let y∗∈X′. Then there exists y such that
|y∗(y)| > ||y∗|| −ε.
By density, there exists one of the x∗
k from the countable dense subset of X′ such
that also
|x∗
k (y)| > ||y∗|| −ε, ||x∗
k −y∗|| < ε.
Now x∗
k (y) ∈φk (B) and so there exists x ∈Dk ⊆D such that
|x∗
k (x)| > ||y∗|| −ε.
Then since ||x∗
k −y∗|| < ε, this implies
|y∗(x)| ≥||y∗|| −2ε.
Since ε > 0 is arbitrary,
||y∗|| ≤sup
x∈D
|y∗(x)| ≤||y∗||
and this proves the lemma.
The next theorem is another version of the Pettis theorem.
First here is a
deﬁnition.

584
THE BOCHNER INTEGRAL
Deﬁnition 21.11 A function y having values in X′ is weak ∗measurable, when
for each x ∈X, y (·) (x) is a measurable scalar valued function.
Theorem 21.12 If X′ is separable and y : Ω→X′ is weak ∗measurable, then y
is strongly measurable.
Proof:
It is necessary to show y−1 (B (a∗, r)) is measurable. This will suﬃce
because the separability of X′ implies every open set is the countable union of such
balls of the form B (a∗, r). It also suﬃces to verify inverse images of closed balls
are measurable because every open ball is the countable union of closed balls. From
Lemma 21.10,
y−1 ³
B (a∗, r)
´
=
{s : ||y (s) −a∗|| ≤r}
=
½
s : sup
x∈D
|(y (s) −a∗) (x)| ≤r
¾
=
½
s : sup
x∈D
|y (s) (x) −a∗(x)| ≤r
¾
=
∩x∈Dy (·) (x)−1 ³
B (a∗(x) , r)
´
which is a countable intersection of measurable sets by hypothesis. This proves the
theorem.
The following are interesting consequences of the theory developed so far and
are of interest independent of the theory of integration of vector valued functions.
Theorem 21.13 If X′ is separable, then so is X.
Proof:
Let D = {xm} ⊆B, the unit ball of X, be the sequence promised
by Lemma 21.10. Let V be all ﬁnite linear combinations of elements of {xm} with
rational scalars. Thus V is a separable subspace of X. The claim is that V = X.
If not, there exists
x0 ∈X \ V .
But by the Hahn Banach theorem there exists x∗
0 ∈X′ satisfying x∗
0 (x0) ̸= 0, but
x∗
0 (v) = 0 for every v ∈V . Hence
||x∗
0|| = sup
x∈D
|x∗
0 (x)| = 0,
a contradiction. This proves the theorem.
Corollary 21.14 If X is reﬂexive, then X is separable if and only if X′ is separa-
ble.
Proof: From the above theorem, if X′ is separable, then so is X. Now suppose
X is separable with a dense subset equal to D. Then since X is reﬂexive, J (D) is
dense in X′′ where J is the James map satisfying Jx (x∗) ≡x∗(x) . Then since X′′
is separable, it follows from the above theorem that X′ is also separable.

21.2.
THE BOCHNER INTEGRAL
585
21.2
The Bochner Integral
21.2.1
Deﬁnition And Basic Properties
Deﬁnition 21.15 Let ak ∈X, a Banach space and let
x (s) =
n
X
k=1
akXEk (s)
(21.3)
where for each k, Ek is measurable and µ (Ek) < ∞. Then deﬁne
Z
Ω
x (s) dµ ≡
n
X
k=1
akµ (Ek).
Proposition 21.16 Deﬁnition 21.15 is well deﬁned.
Proof: It suﬃces to verify that if
n
X
k=1
akXEk (s) = 0,
then
n
X
k=1
akµ (Ek) = 0.
Let f ∈X′. Then
f
Ã n
X
k=1
akXEk (s)
!
=
n
X
k=1
f (ak) XEk (s) = 0
and, therefore,
0 =
Z
Ω
Ã n
X
k=1
f (ak) XEk (s)
!
dµ =
n
X
k=1
f (ak) µ (Ek) = f
Ã n
X
k=1
akµ (Ek)
!
.
Since f ∈X′ is arbitrary, and X′ separates the points of X, it follows that
n
X
k=1
akµ (Ek) = 0
as claimed. This proves the proposition.
It follows easily from this proposition that
R
Ωdµ is well deﬁned and linear on
simple functions.

586
THE BOCHNER INTEGRAL
Deﬁnition 21.17 A strongly measurable function x is Bochner integrable if there
exists a sequence of simple functions xn converging to x pointwise and satisfying
Z
Ω
||xn (s) −xm (s)|| dµ →0 as m, n →∞.
(21.4)
If x is Bochner integrable, deﬁne
Z
Ω
x (s) dµ ≡lim
n→∞
Z
Ω
xn (s) dµ.
(21.5)
Theorem 21.18 The Bochner integral is well deﬁned and if x is Bochner integrable
and f ∈X′,
f
µZ
Ω
x (s) dµ
¶
=
Z
Ω
f (x (s)) dµ
(21.6)
and
¯¯¯¯
¯¯¯¯
Z
Ω
x (s) dµ
¯¯¯¯
¯¯¯¯ ≤
Z
Ω
||x (s)|| dµ.
(21.7)
Also, the Bochner integral is linear. That is, if a, b are scalars and x, y are two
Bochner integrable functions, then
Z
Ω
(ax (s) + by (s)) dµ = a
Z
Ω
x (s) dµ + b
Z
Ω
y (s) dµ
(21.8)
Proof: First it is shown that the triangle inequality holds on simple functions
and that the limit in 21.5 exists. Thus, if x is given by 21.3 with the Ek disjoint,
¯¯¯¯
¯¯¯¯
Z
Ω
x (s) dµ
¯¯¯¯
¯¯¯¯
=
¯¯¯¯¯
¯¯¯¯¯
Z
Ω
n
X
k=1
akXEk (s) dµ
¯¯¯¯¯
¯¯¯¯¯ =
¯¯¯¯¯
¯¯¯¯¯
n
X
k=1
akµ (Ek)
¯¯¯¯¯
¯¯¯¯¯
≤
n
X
k=1
||ak|| µ (Ek) =
Z
Ω
n
X
k=1
||ak|| XEk (s) dµ =
Z
Ω
||x (s)|| dµ
which shows the triangle inequality holds on simple functions. This implies
¯¯¯¯
¯¯¯¯
Z
Ω
xn (s) dµ −
Z
Ω
xm (s) dµ
¯¯¯¯
¯¯¯¯
=
¯¯¯¯
¯¯¯¯
Z
Ω
(xn (s) −xm (s)) dµ
¯¯¯¯
¯¯¯¯
≤
Z
Ω
||xn (s) −xm (s)|| dµ
which veriﬁes the existence of the limit in 21.5. This completes the ﬁrst part of the
argument.

21.2.
THE BOCHNER INTEGRAL
587
Next it is shown the integral does not depend on the choice of the sequence
satisfying 21.4 so that the integral is well deﬁned. Suppose yn, xn both satisfy 21.4
and converge to x pointwise. By Fatou’s lemma,
¯¯¯¯
¯¯¯¯
Z
Ω
yndµ −
Z
Ω
xmdµ
¯¯¯¯
¯¯¯¯ ≤
Z
Ω
||yn −x|| dµ +
Z
Ω
||x −xm|| dµ
≤lim inf
k→∞
Z
Ω
||yn −yk|| dµ + lim inf
k→∞
Z
Ω
||xk −xm||
≤ε/2 + ε/2
if m and n are chosen large enough. Since ε is arbitrary, this shows the limit is the
same for both sequences and demonstrates the Bochner integral is well deﬁned.
It remains to verify the triangle inequality on Bochner integral functions and
the claim about passing a continuous linear functional inside the integral. Let x be
Bochner integrable and let xn be a sequence which satisﬁes the conditions of the
deﬁnition. Deﬁne
yn (s) ≡
½
xn (s) if ||xn (s)|| ≤2 ||x (s)||,
0 if ||xn (s)|| > 2 ||x (s)||.
(21.9)
If x (s) = 0 then yn (s) = 0 for all n. If ||x (s)|| > 0 then for all n large enough,
yn (s) = xn (s).
Thus, yn (s) →x (s) and
||yn (s)|| ≤2 ||x (s)||.
(21.10)
By Fatou’s lemma,
Z
Ω
||x|| dµ ≤lim inf
n→∞
Z
Ω
||xn|| dµ.
(21.11)
Also from 21.4 and the triangle inequality on simple functions,
©R
Ω||xn|| dµ
ª∞
n=1 is
a Cauchy sequence and so it must be bounded. Therefore, by 21.10, 21.11, and the
dominated convergence theorem,
0 =
lim
n,m→∞
Z
Ω
||yn −ym|| dµ
(21.12)
and it follows xn can be replaced with yn in Deﬁnition 21.17.
From Deﬁnition 21.15,
f
µZ
Ω
yndµ
¶
=
Z
Ω
f (yn) dµ.
Thus,
f
µZ
Ω
xdµ
¶
= lim
n→∞f
µZ
Ω
yndµ
¶
= lim
n→∞
Z
Ω
f (yn) dµ =
Z
Ω
f (x) dµ,

588
THE BOCHNER INTEGRAL
the last equation holding from the dominated convergence theorem and 21.10 and
21.11. This shows 21.6. To verify 21.7,
¯¯¯¯
¯¯¯¯
Z
Ω
x (s) dµ
¯¯¯¯
¯¯¯¯ = lim
n→∞
¯¯¯¯
¯¯¯¯
Z
Ω
yn (s) dµ
¯¯¯¯
¯¯¯¯
≤lim
n→∞
Z
Ω
||yn (s)|| dµ =
Z
Ω
||x (s)|| dµ
where the last equation follows from the dominated convergence theorem and 21.10,
21.11.
It remains to verify 21.8. Let f ∈X′. Then from 21.6
f
µZ
Ω
(ax (s) + by (s)) dµ
¶
=
Z
Ω
(af (x (s)) + bf (y (s))) dµ
=
a
Z
Ω
f (x (s)) dµ + b
Z
Ω
f (y (s)) dµ
=
f
µ
a
Z
Ω
x (s) dµ + b
Z
Ω
y (s) dµ
¶
.
Since X′ separates the points of X,it follows
Z
Ω
(ax (s) + by (s)) dµ = a
Z
Ω
x (s) dµ + b
Z
Ω
y (s) dµ
and this proves 21.8. This proves the theorem.
Theorem 21.19 An X valued function, x, is Bochner integrable if and only if x
is strongly measurable and
Z
Ω
||x (s)|| dµ < ∞.
(21.13)
In this case there exists a sequence of simple functions {yn} satisfying 21.4, yn (s)
converging pointwise to x (s),
||yn (s)|| ≤2 ||x (s)||
(21.14)
and
lim
n→∞
Z
Ω
||x (s) −yn (s)|| dµ = 0.
(21.15)
Proof: Suppose x is strongly measurable and condition 21.13 holds. Since x is
strongly measurable, there exists a sequence of simple functions, {xn} converging
pointwise to x. As before, let
yn (s) =
½
xn (s) if ||xn (s)|| ≤2 ||x (s)||,
0 if ||xn (s)|| > 2 ||x (s)||.
(21.16)

21.2.
THE BOCHNER INTEGRAL
589
Then 21.14 holds for yn and yn (s) →x (s) . Also
0 =
lim
m,n→∞
Z
Ω
||yn (s) −ym (s)|| dµ
since otherwise, there would exist ε > 0 and Nε →∞as ε →0 and nε, mε > Nε
such that
Z
Ω
||ynε (s) −ymε (s)|| dµ ≥ε.
But then taking a limit as ε →0 and using the dominated convergence theorem
and 21.14 and 21.13, this would imply 0 ≥ε. Therefore, x is Bochner integrable.
21.15 follows from the dominated convergence theorem and 21.14.
Now suppose x is Bochner integrable. Then it is strongly measurable and there
exists a sequence of simple functions {xn} such that xn (s) converges pointwise to
x and
lim
m,n→∞
Z
Ω
||xn (s) −xm (s)|| dµ = 0.
Therefore, as before, since
©R
Ωxndµ
ª∞
n=1 is a Cauchy sequence, it follows
½Z
Ω
||xn|| dµ
¾∞
n=1
is also a Cauchy sequence because
¯¯¯¯
Z
Ω
||xn|| dµ −
Z
Ω
||xm|| dµ
¯¯¯¯
≤
Z
Ω
|||xn|| −||xm||| dµ
≤
Z
Ω
||xn −xm|| dµ.
Thus
Z
Ω
||x|| dµ ≤lim inf
n→∞
Z
Ω
||xn|| dµ < ∞
Using 21.16 it follows yn satisﬁes 21.14, converges pointwise to x and then from the
dominated convergence theorem 21.15 holds. This proves the theorem.
21.2.2
Taking A Closed Operator Out Of The Integral
Now let X and Y be separable Banach spaces and suppose A : D (A) ⊆X →Y be
a closed operator. Recall this means that the graph of A,
G (A) ≡{(x, Ax) : x ∈D (A)}
is a closed subset of X × Y with respect to the product topology obtained from the
norm
||(x, y)|| = max (||x|| , ||y||) .

590
THE BOCHNER INTEGRAL
Thus also G (A) is a separable Banach space with the above norm. You can also
consider D (A) as a separable Banach space having the norm
||x||D(A) ≡max (||x|| , ||Ax||)
(21.17)
which is isometric to G (A) with the mapping, θx ≡(x, Ax) .
Lemma 21.20 A closed subspace of a reﬂexive Banach space is reﬂexive.
Proof: Consider the following diagram in which Y is a closed subspace of the
reﬂexive space, X.
Y ′′
i∗∗1-1
→
X′′
Y ′
i∗onto
←
X′
Y
i→
X
This diagram follows from theorems on adjoints presented earlier.
Now let y∗∗∈Y ′′. Then i∗∗y∗∗= Jy because X is reﬂexive. I want to show
that y ∈Y . If it is not in Y then there exists x∗∈X′ such that x∗(y) ̸= 0 but
x∗(Y ) = 0. Then i∗x∗= 0. Hence
0 = y∗∗(i∗x∗) = i∗∗y∗∗(x∗) = J (y) (x∗) = x∗(y) ̸= 0,
a contradiction. Hence y ∈Y . Since i∗is onto, I want to show that for all x∗∈X′,
i∗x∗(y) = y∗∗(i∗x∗)
because this will imply y∗∗= JY (y) where JY is the James map from Y to Y ′.
However, the above is equivalent to the following holding for all x∗∈X′.
i∗x∗(y) = JY (y) (i∗x∗) = i∗∗JY (y) (x∗) = i∗∗y∗∗(x∗)
Since i∗∗is onto, it follows JY (y) = y∗∗and this proves it.
Lemma 21.21 Suppose V and W are reﬂexive Banach spaces and that V is a
dense subset of W in the topology of W. Then i∗W ′ is a dense subset of V ′ where
here i is the inclusion map of V into W.
Proof: First note that i∗is one to one. If i∗w∗= 0 for w∗∈W ′, then this
means that for all v ∈V,
i∗w (v) = w∗(v) = 0
and since V is dense in W, this shows w∗= 0.
Consider the following diagram
V ′′
i∗∗
→
W ′′
V ′
i∗
←
W ′
V
i→
W

21.2.
THE BOCHNER INTEGRAL
591
in which i is the inclusion map. Next suppose i∗W ′ is not dense in V ′. Then there
exists v∗∗∈V ′′ such that v∗∗̸= 0 but v∗∗(i∗W ′) = 0. It follows from V being
reﬂexive, that v∗∗= Jv0 where J is the James map from V to V ′′for some v0 ∈V .
Thus for every w∗W ′,
0
=
v∗∗(i∗w∗) = i∗∗v∗∗(w∗)
=
i∗∗Jv0 (w∗) = Jv0 (i∗w∗)
=
i∗w∗(v0) = w∗(v0)
and since W ′ separates the points of W, it follows v0 = 0 which contradicts v∗∗̸= 0.
This proves the lemma.
Note that in the proof, only V reﬂexive was used.
This lemma implies an easy corollary.
Corollary 21.22 Let E and F be reﬂexive Banach spaces and let A be a closed
operator, A : D (A) ⊆E →F. Suppose also that D (A) is dense in E. Then making
D (A) into a Banach space by using the above graph norm given in 21.17, it follows
that D (A) is a Banach space and i∗E′ is a dense subspace of D (A)′ .
Proof: First note that E × F is a reﬂexive Banach space and G (A) is a closed
subspace of E × F so it is also a reﬂexive Banach space. Now D (A) is isometric to
G (A) and so it follows D (A) is a dense subspace of E which is reﬂexive. Therefore,
from Lemma 21.21 the conclusion follows.
With this preparation, here is another interesting theorem. This one is about
taking outside the integral a closed linear operator as opposed to a continuous linear
operator.
Theorem 21.23 Let X, Y be separable Banach spaces and let A : D (A) ⊆X →Y
be a closed operator where D (A) is a dense subset of X. Suppose also that i∗X′ is
a dense subspace of D (A)′ where D (A) is a Banach space having the graph norm
described in 21.17. Suppose that (Ω, F, µ) is a σ ﬁnite measure space and x : Ω→X
is strongly measurable and it happens that x (s) ∈D (A) for all s ∈Ω. Then x is
strongly measurable as a mapping into D (A). Also Ax is strongly measurable as a
map into Y and if
Z
Ω
||x (s)|| dµ,
Z
Ω
||Ax (s)|| dµ < ∞,
(21.18)
then
Z
Ω
x (s) dµ ∈D (A)
(21.19)
and
A
Z
Ω
x (s) dµ =
Z
Ω
Ax (s) dµ.
(21.20)
Proof: First of all, consider the assertion that x is strongly measurable into
D (A) . Letting f ∈D (A)′ be given, there exists a sequence, {gn} ⊆i∗X′ such that
gn →f in D (A)′ . Therefore,
s →gn (x (s))

592
THE BOCHNER INTEGRAL
is measurable by assumption and
gn (x (s)) →f (x (s))
which shows that s →f (x (s)) is measurable. By the Pettis theorem, it follows
s →x (s)
is strongly measurable as a map into D (A).
It follows from Theorem 21.19 there exists a sequence of simple functions, {xn}
of the form
xn (s) =
mn
X
k=1
an
kXEn
k (s) , xn (s) ∈D (A) ,
which converges strongly and pointwise to x (s) in D (A). Thus
xn (s) →x (s) , Axn (s) →Ax (s) ,
which shows s →Ax (s) is stongly measurable in Y as claimed.
It remains to verify the assertions about the integral. 21.18 implies x is Bochner
integrable as a function having values in D (A) with the norm on D (A) described
above. Therefore, by Theorem 21.19 there exists a sequence of simple functions
{yn} having values in D (A) ,
lim
m,n→∞
Z
Ω
||yn −ym||D(A) dµ = 0,
yn (s) converging pointwise to x (s),
||yn (s)||D(A) ≤2 ||x (s)||D(A)
and
lim
n→∞
Z
Ω
||x (s) −yn (s)||D(A) ds = 0.
Therefore,
Z
Ω
yn (s) dµ ∈D (A) ,
Z
Ω
yn (s) dµ →
Z
Ω
x (s) dµ in X,
and since yn is a simple function and A is linear,
A
Z
Ω
yn (s) dµ =
Z
Ω
Ayn (s) dµ →
Z
Ω
Ax (s) dµ in Y.
It follows, since A is a closed operator, that
Z
Ω
x (s) dµ ∈D (A)
and
A
Z
Ω
x (s) dµ =
Z
Ω
Ax (s) dµ.
This proves the theorem.
Here is another version of this theorem which has diﬀerent hypotheses.

21.2.
THE BOCHNER INTEGRAL
593
Theorem 21.24 Let X and Y be separable Banach spaces and let A : D (A) ⊆
X →Y be a closed operator. Also let (Ω, F, µ) be a σ ﬁnite measure space and let
x : Ω→X be Bochner integrable such that x (s) ∈D (A) for all s. Also suppose Ax
is Bochner integrable. Then
Z
Axdµ = A
Z
xdµ
and
R
xdµ ∈D (A).
Proof: Consider the graph of A,
G (A) ≡{(x, Ax) : x ∈D (A)} ⊆X × Y.
Then since A is closed, G (A) is a closed separable Banach space with the norm
||(x, y)|| ≡max (||x|| , ||y||) . Therefore, for g∗∈G (A)′ , one can apply the Hahn Ba-
nach theorem and obtain (x∗, y∗) ∈(X × Y )′ such that g∗(x, Ax) = (x∗(x) , y∗(Ax)) .
Now it follows from the assumptions that s →(x∗(x (s)) , y∗(Ax (s))) is mea-
surable with values in G (A) . It is also separably valued because this is true of
G (A) . By the Pettis theorem, s →(x (s) , A (x (s))) must be strongly measurable.
Also
R
||x (s)|| + ||A (x (s))|| dµ < ∞by assumption and so there exists a sequence
of simple functions having values in G (A) , {(xn (s) , Axn (s))} which converges to
(x (s) , A (s)) pointwise such that
R
||(xn, Axn) −(x, Ax)|| dµ →0 in G (A) . Now
for simple functions is it routine to verify that
Z
(xn, Axn) dµ
=
µZ
xndµ,
Z
Axndµ
¶
=
µZ
xndµ, A
Z
xndµ
¶
Also
¯¯¯¯
¯¯¯¯
Z
xndµ −
Z
xdµ
¯¯¯¯
¯¯¯¯
≤
Z
||xn −x|| dµ
≤
Z
||(xn, Axn) −(x, Ax)|| dµ
which converges to 0. Also
¯¯¯¯
¯¯¯¯
Z
Axndµ −
Z
Axdµ
¯¯¯¯
¯¯¯¯
=
¯¯¯¯
¯¯¯¯A
Z
xndµ −
Z
Axdµ
¯¯¯¯
¯¯¯¯
≤
Z
||Axn −Ax|| dµ
≤
Z
||(xn, Axn) −(x, Ax)|| dµ
and this converges to 0. Therefore,
R
xndµ →
R
xdµ and A
R
xndµ →
R
Axdµ.
Since each
R
xndµ ∈D (A) , and A is
closed, this implies
R
xdµ ∈D (A) and
A
R
xdµ =
R
Axdµ. This proves the theorem.

594
THE BOCHNER INTEGRAL
21.3
Operator Valued Functions
Consider the case where A (s) ∈L (X, Y ) for X and Y separable Banach spaces.
With the operator norm L (X, Y ) is a Banach space and so if A is strongly mea-
surable, the Bochner integral can be deﬁned as before. However, it is also possible
to deﬁne the Bochner integral of such operator valued functions for more general
situations. In this section, (Ω, F, µ) will be a σ ﬁnite measure space as usual.
Lemma 21.25 Let x ∈X and suppose A is strongly measurable. Then
s →A (s) x
is strongly measurable as a map into Y.
Proof: Since A is assumed to be strongly measurable, it is the pointwise limit
of simple functions of the form
An (s) ≡
mn
X
k=1
An
kXEn
k (s)
where An
k is in L (X, Y ). It follows An (s) x →A (s) x for each s and so, since s →
An (s) x is a simple Y valued function, s →A (s) x must be strongly measurable.
Deﬁnition 21.26 Suppose A (s) ∈L (X, Y ) for each s ∈Ωwhere X, Y are sepa-
rable Banach spaces. Suppose also that for each x ∈X,
s →A (s) x is strongly measurable
(21.21)
and there exists C such that for each x ∈X,
Z
Ω
||A (s) x|| dµ < C ||x||
(21.22)
Then
R
ΩA (s) dµ ∈L (X, Y ) is deﬁned by the following formula.
µZ
Ω
A (s) dµ
¶
(x) ≡
Z
Ω
A (s) xdµ
(21.23)
Lemma 21.27 The above deﬁnition is well deﬁned. Furthermore, if 21.21 holds
then s →||A (s)|| is measurable and if 21.22 holds, then
¯¯¯¯
¯¯¯¯
Z
Ω
A (s) dµ
¯¯¯¯
¯¯¯¯ ≤
Z
Ω
||A (s)|| dµ.
Proof: It is clear that in case s →A (s) x is measurable for all x ∈X there
exists a unique Ψ ∈L (X, Y ) such that
Ψ (x) =
Z
Ω
A (s) xdµ.

21.3.
OPERATOR VALUED FUNCTIONS
595
This is because x →
R
ΩA (s) xdµ is linear and continuous. Thus Ψ =
R
ΩA (s) dµ
and the deﬁnition is well deﬁned.
Now consider the assertion about s →||A (s)||. Let D′ ⊆B′ the closed unit ball
in Y ′ be such that D′ is countable and
||y|| = sup
y∗∈D′ |y∗(y)| .
Also let D be a countable dense subset of B, the unit ball of X. Then
{s : ||A (s)|| > α}
=
½
s : sup
x∈D
||A (s) x|| > α
¾
=
∪x∈D {s : ||A (s) x|| > α}
=
∪x∈D (∪y∗∈D′ {|y∗(A (s) x)| > α})
and this is measurable because s →A (s) x is strongly, hence weakly measurable.
Now suppose 21.22 holds. Then for all x,
Z
Ω
||A (s) x|| dµ < C ||x|| .
It follows that for ||x|| ≤1,
¯¯¯¯
¯¯¯¯
µZ
Ω
A (s) dµ
¶
(x)
¯¯¯¯
¯¯¯¯
=
¯¯¯¯
¯¯¯¯
Z
Ω
A (s) xdµ
¯¯¯¯
¯¯¯¯
≤
Z
Ω
||A (s) x|| dµ
≤
Z
Ω
||A (s)|| dµ
and so
¯¯¯¯
¯¯¯¯
Z
Ω
A (s) dµ
¯¯¯¯
¯¯¯¯ ≤
Z
Ω
||A (s)|| dµ.
This proves the lemma.
Now it is interesting to consider the case where A (s) ∈L (H, H) where s →
A (s) x is strongly measurable and A (s) is compact and self adjoint. Recall the
Kuratowski measurable selection theorem, Theorem 8.11 on Page 176 listed here
for convenience.
Theorem 21.28 Let E be a compact metric space and let (Ω, F) be a measure
space. Suppose ψ : E × Ω→R has the property that x →ψ (x, ω) is continuous
and ω →ψ (x, ω) is measurable. Then there exists a measurable function, f having
values in E such that
ψ (f (ω) , ω) = sup
x∈E
ψ (x, ω) .
Furthermore, ω →ψ (f (ω) , ω) is measurable.

596
THE BOCHNER INTEGRAL
21.3.1
Review Of Hilbert Schmidt Theorem
Here I will give a proof of the Hilbert Schmidt theorem which will generalize to a
result about measurable operators. Recall the following.
Deﬁnition 21.29 Deﬁne v ⊗u ∈L (H, H) by
v ⊗u (x) = (x, u) v.
A ∈L (H, H) is a compact operator if whenever {xk} is a bounded sequence, there
exists a convergent subsequence of {Axk}. Equivalently, A maps bounded sets to
sets whose closures are compact or to use other terminology, A maps bounded sets
to sets which are precompact.
Lemma 21.30 Let H be a separable Hilbert space and suppose A ∈L (H, H) is a
compact operator. Let B denote the closed unit ball in H. Then A is continuous as
a map from B with the weak topology into H with the strong topology. For u, v ∈H,
v ⊗u : H →H is a compact operator. If A is self adjoint and compact, the function
x →(Ax, x)
is continuous on B with respect to the weak topology on B. The function,
x →(v ⊗u (x) , x)
is continuous and the operator u ⊗u is self adjoint.
Proof: Since H is separable, it follows from Corollary 13.41 on Page 358 that
B can be considered as a metric space.
Therefore, showing continuity reduces
to showing convergent sequences are taken to convergent sequences. Let xn →x
weakly in B. Suppose Axndoes not converge to Ax. Then there exists a subsequence,
still denoted by {xn} such that
||Axn −Ax|| ≥ε > 0
(21.24)
for all n. Then since A maps bounded sets to compact sets, there is a further sub-
sequence, still denoted by {xn} such that Axn converges to some y ∈H. Therefore,
(y, w)
=
lim
n→∞(Axn, w) = lim
n→∞(xn, A∗w)
=
(x, A∗w) = (Ax, w)
which shows Ax = y since w is arbitrary. However, this contradicts 21.24.
Next consider the claim about v ⊗u. Letting {xn} be a bounded sequence,
v ⊗u (xn) = (xn, u) v.
There exists a weakly convergent subsequence of {xn} say {xnk} converging weakly
to x ∈H. Therefore,
||v ⊗u (xnk) −v ⊗u (x)|| = ||(xnk, u) −(x, u)|| ||v||

21.3.
OPERATOR VALUED FUNCTIONS
597
which converges to 0. Thus v ⊗u is compact as claimed. It takes bounded sets to
precompact sets.
To verify the assertion about x →(Ax, x), let xn →x weakly. Then
|(Axn, xn) −(Ax, x)|
≤
|(Axn, xn) −(Ax, xn)| + |(Ax, xn) −(Ax, x)|
≤
|(Axn, xn) −(Ax, xn)| + |(Axn, x) −(Ax, x)|
≤
||Axn −Ax|| ||xn|| + ||Axn −Ax|| ||x|| ≤2 ||Axn −Ax||
which converges to 0.
|(v ⊗u (xn) , xn) −(v ⊗u (x) , x)|
=
|(xn, u) (v, xn) −(x, u) (v, x)|
and this converges to 0 by weak convergence. It follows from the deﬁnition that
u ⊗u is self adjoint. This proves the lemma.
Observation 21.31 Note that if A is any self adjoint operator,
(Ax, x) = (x, Ax) = (Ax, x) .
so (Ax, x) is real valued.
Lemma 21.32 Let A ∈L (H, H) and suppose it is self adjoint and compact. Let
B denote the closed unit ball in H. Let e ∈B be such that
|(Ae, e)| = max
x∈B |(Ax, x)| .
Then letting λ = (Ae, e) , it follows Ae = λe. If λ ̸= 0, then ||e|| = 1 and if λ = 0,
it can be assumed e = 0 so it is still the case Ae = λe.
Proof: From the above observation, (Ax, x) is always real and since A is com-
pact, |(Ax, x)| achieves a maximum at e. It remains to verify e is an eigenvector.
Note that ||e|| = 1 whenever λ ̸= 0 since otherwise |(Ae, e)| could be made larger
by replacing e with e/ ||e||.
Suppose λ = (Ae, e) > 0. Then it is easy to verify that λI −A is a nonnegative
(((λI −A) x, x) ≥0 for all x.) and self adjoint operator. Therefore, the Cauchy
Schwarz inequality can be applied to write
((λI −A) e, x) ≤((λI −A) e, e)1/2 ((λI −A) x, x)1/2 = 0
Since this is true for all x it follows Ae = λe.
Next suppose λ = (Ae, e) < 0. Then −λ = (−Ae, e) and the previous result can
be applied to −A and −λ. Thus −λe = −Ae and so Ae = λe.
Finally consider the case where λ = 0. Then 0 = (A0, 0) and so it suﬃces to
take e = 0 as claimed. This proves the lemma.
With these lemmas here is a major theorem, the Hilbert Schmidt theorem.

598
THE BOCHNER INTEGRAL
Theorem 21.33 Let A ∈L (H, H) be a compact self adjoint operator on a Hilbert
space. Then there exist real numbers {λk}∞
k=1 and vectors {ek}∞
k=1 such that
||ek||
=
1 if λk ̸= 0,
||ek||
=
0 if λk = 0,
(ek, ej)H = 0 if k ̸= j,
Aek = λkek,
|λn| ≥|λn+1| for all n,
lim
n→∞λn = 0,
lim
n→∞
¯¯¯¯¯
¯¯¯¯¯A −
n
X
k=1
λk (ek ⊗ek)
¯¯¯¯¯
¯¯¯¯¯
L(H,H)
= 0.
(21.25)
Proof: This is done by considering a sequence of compact self adjoint operators,
A, A1, A2, · · ·. Here is how these are deﬁned. Using Lemma 21.32 let e1, λ1 be given
by that lemma such that
|(Ae1, e1)| = max
x∈B |(Ax, x)| , λ1 = (Ae1, e1) .
Then by that lemma, Ae1 = λ1e1 and ||e1|| = 1 if λ1 ̸= 0 while e1 = 0 if λ1 = 0.
If An has been obtained, use Lemma 21.32 to obtain en+1 and λn+1 such that
|(Anen+1, en+1)| = max
x∈B |(Anx, x)| , λn+1 = (Anen+1, en+1) .
By that lemma again, Anen+1 = λn+1en+1 and ||en+1|| = 1 if λn+1 ̸= 0 while
en+1 = 0 if λn+1 = 0. Then
An+1 ≡An −λn+1en+1 ⊗en+1
Thus
An = A −
n
X
k=1
λkek ⊗ek.
(21.26)
Claim 1: If k < n + 1 then (en+1, ek) = 0. Also Aek = λkek for all k.
Proof of claim: From the above,
λn+1en+1 = Anen+1 = Aen+1 −
n
X
k=1
λk (en+1, ek) ek.
If λn+1 = 0, then (en+1, ek) = 0 because en+1 = 0. If λn+1 ̸= 0, then from the
above and an induction hypothesis
λn+1 (en+1, ej)
=
(Aen+1, ej) −
n
X
k=1
λk (en+1, ek) (ek, ej)
=
(en+1, Aej) −
n
X
k=1
λk (en+1, ek) (ek, ej)
=
λj (en+1, ej) −λj (en+1, ej) = 0.

21.3.
OPERATOR VALUED FUNCTIONS
599
To verify the second part of this claim,
λn+1en+1 = Anen+1 = Aen+1 −
n
X
k=1
λkek (en+1, ek) = Aen+1
This proves the claim.
Claim 2: |λn| ≥|λn+1| .
Proof of claim: From 21.26 and the deﬁnition of An and ek ⊗ek,
λn+1
=
(Anen+1, en+1)
=
(An−1en+1, en+1) −λn |(en, en+1)|2
=
(An−1en+1, en+1)
By the previous claim. Therefore,
|λn+1| = |(An−1en+1, en+1)| ≤|(An−1en, en)| = |λn|
by the deﬁnition of |λn|. (en makes |(An−1x, x)| as large as possible, not necessarily
en+1.)
Claim 3:limn→∞λn = 0.
Proof of claim: If for some n, λn = 0, then λk = 0 for all k > n by claim 2.
Assume then that λk ̸= 0 for any k. Then if limk→∞|λk| = ε > 0, contrary to the
claim, ||ek|| = 1 for all k and
||Aen −Aem||2
=
||λnen −λmem||2
=
λ2
n + λ2
m ≥2ε2
which shows there is no Cauchy subsequence of {Aen}∞
n=1 , which contradicts the
compactness of A. This proves the claim.
Claim 4: ||An|| →0
Proof of claim: Let x, y ∈B
|λn+1|
≥
¯¯¯¯
µ
An
x + y
2
, x + y
2
¶¯¯¯¯
=
¯¯¯¯
1
4 (Anx, x) + 1
4 (Any, y) + 1
2 (Anx, y)
¯¯¯¯
≥
1
2 |(Anx, y)| −1
4 |(Anx, x) + (Any, y)|
≥
1
2 |(Anx, y)| −1
4 (|(Anx, x)| + |(Any, y)|)
≥
1
2 |(Anx, y)| −1
2 |λn+1|
and so
3 |λn+1| ≥|(Anx, y)| .
It follows ||An|| ≤3 |λn+1| . This proves the claim.
By 21.26 this proves 21.25 and completes the proof.

600
THE BOCHNER INTEGRAL
21.3.2
Measurable Compact Operators
Here the operators will be of the form A (s) where s ∈Ωand s →A (s) x is strongly
measurable and A (s) is a compact operator in L (H, H).
Theorem 21.34 Let A (s) ∈L (H, H) be a compact self adjoint operator and H is
a separable Hilbert space such that s →A (s) x is strongly measurable. Then there
exist real numbers {λk (s)}∞
k=1 and vectors {ek (s)}∞
k=1 such that
||ek (s)||
=
1 if λk ̸= 0,
||ek (s)||
=
0 if λk = 0,
(ek (s) , ej (s))H = 0 if k ̸= j,
A (s) ek (s) = λk (s) ek (s) ,
|λn (s)| ≥|λn+1 (s)| for all n,
lim
n→∞λn (s) = 0,
lim
n→∞
¯¯¯¯¯
¯¯¯¯¯A (s) −
n
X
k=1
λk (s) (ek (s) ⊗ek (s))
¯¯¯¯¯
¯¯¯¯¯
L(H,H)
= 0.
The function s →λj (s) is measurable and s →ej (s) is strongly measurable.
Proof: It is simply a repeat of the above proof of the Hilbert Schmidt theorem
except at every step when the ek and λk are deﬁned, you use the Kuratowski mea-
surable selection theorem, Theorem 21.28 on Page 595 to obtain λk (s) is measurable
and that s →ek (s) is also measurable.
When you consider maxx∈B |(An (s) x, x)| , let ψ (x, s) = |(An (s) x, x)| . Then
ψ is continuous in x by Lemma 21.30 on Page 596 and it is measurable in s by
assumption. Therefore, by the Kuratowski theorem, ek (s) is measurable in the sense
that inverse images of weakly open sets in B are measurable. However, by Lemma
21.9 on Page 582 this is the same as weakly measurable. Since H is separable, this
implies s →ek (s) is also strongly measurable. The measurability of λk and ek is
the only new thing here and so this completes the proof.
21.4
Fubini’s Theorem For Bochner Integrals
Now suppose (Ω1, F, µ) and (Ω2, S, λ) are two σ ﬁnite measure spaces.
Recall
the notion of product measure. There was a σ algebra, denoted by F × S which
is the smallest σ algebra containing the elementary sets, (ﬁnite disjoint unions of
measurable rectangles) and a measure, denoted by µ × λ deﬁned on this σ algebra
such that for E ∈F × S,
s1 →λ (Es1) , (Es1 ≡{s2 : (s1, s2) ∈E})

21.4.
FUBINI’S THEOREM FOR BOCHNER INTEGRALS
601
is µ measurable and
s2 →µ (Es2) , (Es2 ≡{s1 : (s1, s2) ∈E})
is λ measurable. In terms of nonnegative functions which are F × S measurable,
s1
→
f (s1, s2) is µ measurable,
s2
→
f (s1, s2) is λ measurable,
s1
→
Z
Ω2
f (s1, s2) dλ is µ measurable,
s2
→
Z
Ω1
f (s1, s2) dµ is λ measurable,
and the conclusion of Fubini’s theorem holds.
Z
Ω1×Ω2
fd (µ × λ)
=
Z
Ω1
Z
Ω2
f (s1, s2) dλdµ
=
Z
Ω2
Z
Ω1
f (s1, s2) dµdλ.
The following theorem is the version of Fubini’s theorem valid for Bochner integrable
functions.
Theorem 21.35 Let f : Ω1 × Ω2 →X be strongly measurable with respect to µ × λ
and suppose
Z
Ω1×Ω2
||f (s1, s2)|| d (µ × λ) < ∞.
(21.27)
Then there exist a set of µ measure zero, N and a set of λ measure zero, M such
that the following formula holds with all integrals making sense.
Z
Ω1×Ω2
f (s1, s2) d (µ × λ)
=
Z
Ω1
Z
Ω2
f (s1, s2) XN (s1) dλdµ
=
Z
Ω2
Z
Ω1
f (s1, s2) XM (s2) dµdλ.
Proof: First note that from 21.27 and the usual Fubini theorem for nonnegative
valued functions,
Z
Ω1×Ω2
||f (s1, s2)|| d (µ × λ) =
Z
Ω1
Z
Ω2
||f (s1, s2)|| dλdµ
and so
Z
Ω2
||f (s1, s2)|| dλ < ∞
(21.28)
for µ a.e. s1. Say for all s1 /∈N where µ (N) = 0.

602
THE BOCHNER INTEGRAL
Let φ ∈X′. Then φ ◦f is F × S measurable and
Z
Ω1×Ω2
|φ ◦f (s1, s2)| d (µ × λ)
≤
Z
Ω1×Ω2
||φ|| ||f (s1, s2)|| d (µ × λ) < ∞
and so from the usual Fubini theorem for complex valued functions,
Z
Ω1×Ω2
φ ◦f (s1, s2) d (µ × λ) =
Z
Ω1
Z
Ω2
φ ◦f (s1, s2) dλdµ.
(21.29)
Now also if you ﬁx s2, it follows from the deﬁnition of strongly measurable and the
properties of product measure mentioned above that
s1 →f (s1, s2)
is strongly measurable. Also, by 21.28
Z
Ω2
||f (s1, s2)|| dλ < ∞
for s1 /∈N.
Therefore, by Theorem 21.19 s2 →f (s1, s2) XN C (s1) is Bochner
integrable. By 21.29 and 21.6
Z
Ω1×Ω2
φ ◦f (s1, s2) d (µ × λ)
=
Z
Ω1
Z
Ω2
φ ◦f (s1, s2) dλdµ
=
Z
Ω1
Z
Ω2
φ (f (s1, s2) XN C (s1)) dλdµ
=
Z
Ω1
φ
µZ
Ω2
f (s1, s2) XN C (s1) dλ
¶
dµ.
(21.30)
Each iterated integral makes sense and
s1
→
Z
Ω2
φ (f (s1, s2) XN C (s1)) dλ
=
φ
µZ
Ω2
f (s1, s2) XNC (s1) dλ
¶
(21.31)
is µ measurable because
(s1, s2)
→
φ (f (s1, s2) XNC (s1))
=
φ (f (s1, s2)) XN C (s1)

21.5.
THE SPACES LP (Ω; X)
603
is product measurable. Now consider the function,
s1 →
Z
Ω2
f (s1, s2) XN C (s1) dλ.
(21.32)
I want to show this is also Bochner integrable with respect to µ so I can factor
out φ once again. It’s measurability follows from the Pettis theorem and the above
observation 21.31. Also,
Z
Ω1
¯¯¯¯
¯¯¯¯
Z
Ω2
f (s1, s2) XNC (s1) dλ
¯¯¯¯
¯¯¯¯ dµ
≤
Z
Ω1
Z
Ω2
||f (s1, s2)|| dλdµ
=
Z
Ω1×Ω2
||f (s1, s2)|| d (µ × λ) < ∞.
Therefore, the function in 21.32 is indeed Bochner integrable and so in 21.30 the φ
can be taken outside the last integral. Thus,
φ
µZ
Ω1×Ω2
f (s1, s2) d (µ × λ)
¶
=
Z
Ω1×Ω2
φ ◦f (s1, s2) d (µ × λ)
=
Z
Ω1
Z
Ω2
φ ◦f (s1, s2) dλdµ
=
Z
Ω1
φ
µZ
Ω2
f (s1, s2) XN C (s1) dλ
¶
dµ
=
φ
µZ
Ω1
Z
Ω2
f (s1, s2) XN C (s1) dλdµ
¶
.
Since X′ separates the points,
Z
Ω1×Ω2
f (s1, s2) d (µ × λ) =
Z
Ω1
Z
Ω2
f (s1, s2) XN C (s1) dλdµ.
The other formula follows from similar reasoning. This proves the theorem.
21.5
The Spaces Lp (Ω; X)
Deﬁnition 21.36 x ∈Lp (Ω; X) for p ∈[1, ∞) if x is strongly measurable and
Z
Ω
||x (s)||p dµ < ∞
Also
||x||Lp(Ω;X) ≡||x||p ≡
µZ
Ω
||x (s)||p dµ
¶1/p
.
(21.33)

604
THE BOCHNER INTEGRAL
As in the case of scalar valued functions, two functions in Lp (Ω; X) are consid-
ered equal if they are equal a.e. With this convention, and using the same arguments
found in the presentation of scalar valued functions it is clear that Lp (Ω; X) is a
normed linear space with the norm given by 21.33. In fact, Lp (Ω; X) is a Banach
space. This is the main contribution of the next theorem.
Lemma 21.37 If xn is a Cauchy sequence in Lp (Ω; X) satisfying
∞
X
n=1
||xn+1 −xn||p < ∞,
then there exists x ∈Lp (Ω; X) such that xn (s) →x (s) a.e. and
||x −xn||p →0.
Proof: Let
gN (s) ≡
N
X
n=1
||xn+1 (s) −xn (s)||X
Then by the triangle inequality,
µZ
Ω
gN (s)p dµ
¶1/p
≤
N
X
n=1
µZ
Ω
||xn+1 (s) −xn (s)||p dµ
¶1/p
≤
∞
X
n=1
||xn+1 −xn||p < ∞.
Let
g (s) = lim
N→∞gN (s) =
∞
X
n=1
||xn+1 (s) −xn (s)||X .
By the monotone convergence theorem,
µZ
Ω
g (s)p dµ
¶1/p
= lim
N→∞
µZ
Ω
gN (s)p dµ
¶1/p
< ∞.
Therefore, there exists a set of measure 0, E, such that for s /∈E, g (s) < ∞. Hence,
for s /∈E,
lim
N→∞xN+1 (s)
exists because
xN+1 (s) = xN+1 (s) −x1 (s) + x1 (s) =
N
X
n=1
(xn+1 (s) −xn (s)) + x1 (s).

21.5.
THE SPACES LP (Ω; X)
605
Thus, if N > M, and s is a point where g (s) < ∞,
||xN+1 (s) −xM+1 (s)||X
≤
N
X
n=M+1
||xn+1 (s) −xn (s)||X
≤
∞
X
n=M+1
||xn+1 (s) −xn (s)||X
which shows that {xN+1 (s)}∞
N=1 is a Cauchy sequence. Now let
x (s) ≡
½
limN→∞xN (s) if s /∈E,
0 if s ∈E.
By Theorem 21.2, xn (Ω) is separable for each n. Therefore, x (Ω) is also separable.
Also, if f ∈X′, then
f (x (s)) = lim
N→∞f (xN (s))
if s /∈E and f (x (s)) = 0 if s ∈E. Therefore, f ◦x is measurable because it is the
limit of the measurable functions,
f ◦xNXEC.
Since x is weakly measurable and x (Ω) is separable, Corollary 21.8 shows that x is
strongly measurable. By Fatou’s lemma,
Z
Ω
||x (s) −xN (s)||p dµ ≤lim inf
M→∞
Z
Ω
||xM (s) −xN (s)||p dµ.
But if N and M are large enough with M > N,
µZ
Ω
||xM (s) −xN (s)||p dµ
¶1/p
≤
M
X
n=N
||xn+1 −xn||p
≤
∞
X
n=N
||xn+1 −xn||p < ε
and this shows, since ε is arbitrary, that
lim
N→∞
Z
Ω
||x (s) −xN (s)||p dµ = 0.
It remains to show x ∈Lp (Ω; X). This follows from the above and the triangle
inequality. Thus, for N large enough,
µZ
Ω
||x (s)||p dµ
¶1/p

606
THE BOCHNER INTEGRAL
≤
µZ
Ω
||xN (s)||p dµ
¶1/p
+
µZ
Ω
||x (s) −xN (s)||p dµ
¶1/p
≤
µZ
Ω
||xN (s)||p dµ
¶1/p
+ ε < ∞.
This proves the lemma.
Theorem 21.38 Lp (Ω; X) is complete. Also every Cauchy sequence has a subse-
quence which converges pointwise.
Proof: If {xn} is Cauchy in Lp (Ω; X), extract a subsequence {xnk} satisfying
¯¯¯¯xnk+1 −xnk
¯¯¯¯
p ≤2−k
and apply Lemma 21.37. The pointwise convergence of this subsequence was estab-
lished in the proof of this lemma. This proves the theorem because if a subsequence
of a Cauchy sequence converges, then the Cauchy sequence must also converge.
Observation 21.39 If the measure space is Lebesgue measure then you have conti-
nuity of translation in Lp (Rn; X) in the usual way. More generally, for µ a Radon
measure on Ωa locally compact Hausdorﬀspace, Cc (Ω; X) is dense in Lp (Ω; X) .
Here Cc (Ω; X) is the space of continuous X valued functions which have compact
support in Ω. The proof of this little observation follows immediately from approx-
imating with simple functions and then applying the appropriate considerations to
the simple functions.
Clearly Fatou’s lemma and the monotone convergence theorem make no sense
for functions with values in a Banach space but the dominated convergence theorem
holds in this setting.
Theorem 21.40 If x is strongly measurable and xn (s) →x (s) a.e. with
||xn (s)|| ≤g (s) a.e.
where g ∈L1 (Ω), then x is Bochner integrable and
Z
Ω
x (s) dµ = lim
n→∞
Z
Ω
xn (s) dµ.
Proof: ||xn (s) −x (s)|| ≤2g (s) a.e. so by the usual dominated convergence
theorem,
0 = lim
n→∞
Z
Ω
||xn (s) −x (s)|| dµ.
Also,
Z
Ω
||xn (s) −xm (s)|| dµ

21.5.
THE SPACES LP (Ω; X)
607
≤
Z
Ω
||xn (s) −x (s)|| dµ +
Z
Ω
||xm (s) −x (s)|| dµ,
and so {xn} is a Cauchy sequence in L1 (Ω; X). Therefore, by Theorem 21.38, there
exists y ∈L1 (Ω; X) and a subsequence xn′ satisfying
xn′ (s) →y (s) a.e. and in L1 (Ω; X).
But x (s) = limn′→∞xn′ (s) a.e. and so x (s) = y (s) a.e. Hence
Z
Ω
||x (s)|| dµ =
Z
Ω
||y (s)|| dµ < ∞
which shows that x is Bochner integrable. Finally, since the integral is linear,
¯¯¯¯
¯¯¯¯
Z
Ω
x (s) dµ −
Z
Ω
xn (s) dµ
¯¯¯¯
¯¯¯¯
=
¯¯¯¯
¯¯¯¯
Z
Ω
(x (s) −xn (s)) dµ
¯¯¯¯
¯¯¯¯
≤
Z
Ω
||xn (s) −x (s)|| dµ,
and this last integral converges to 0. This proves the theorem.
The following theorem is interesting.
Theorem 21.41 Let 1 ≤p < ∞and let p < r ≤∞. Then Lr ([0, T] , X) is a Borel
subset of Lp ([0, T] ; X). Letting C ([0, T] ; X) denote the functions having values in
X which are continuous, C ([0, T] ; X) is also a Borel subset of Lp ([0, T] ; X) . Here
the measure is ordinary one dimensional Lebesgue measure on [0, T].
Proof: First consider the claim about Lr ([0, T] ; X). Let
BM ≡
n
x ∈Lp ([0, T] ; X) : ||x||Lr([0,T ];X) ≤M
o
.
Then BM is a closed subset of Lp ([0, T] ; X) . Here is why. If {xn} is a sequence
of elements of BM and xn →x in Lp ([0, T] ; X) , then passing to a subsequence,
still denoted by xn, it can be assumed xn (s) →x (s) a.e. Hence Fatou’s lemma can
be applied to conclude
Z T
0
||x (s)||r ds ≤lim inf
n→∞
Z T
0
||xn (s)||r ds ≤M r < ∞.
Now ∪∞
M=1BM = Lr ([0, T] ; X) . Note this did not depend on the measure space
used. It would have been equally valid on any measure space.
Consider now C ([0, T] ; X) . The norm on this space is the usual norm, ||·||∞.
The argument above shows ||·||∞is a Borel measurable function on Lp ([0, T] ; X) .
This is because BM ≡{x ∈Lp ([0, T] ; X) : ||x||∞≤M} is a closed, hence Borel sub-
set of Lp ([0, T] ; X). Now let θ ∈L (Lp ([0, T] ; X) , Lp (R; X)) such that θ (x (t)) =
x (t) for all t ∈[0, T] and also θ ∈L (C ([0, T] ; X) , BC (R; X)) where BC (R; X)
denotes the bounded continuous functions with a norm given by
||x|| ≡sup
t∈R
||x (t)|| ,

608
THE BOCHNER INTEGRAL
and θx has compact support.
For example, you could deﬁne
ex (t) ≡







x (t) if t ∈[0, T]
x (2T −t) if t ∈[T, 2T]
x (−t) if t ∈[−T, 0]
0 if t /∈[−T, 2T]
and let Φ ∈C∞
c (−T, 2T) such that Φ (t) = 1 for t ∈[0, T]. Then you could let
θx (t) ≡Φ (t) ex (t) .
Then let {φn} be a molliﬁer and deﬁne
ψnx (t) ≡φn ∗θx (t) .
It follows ψnx is uniformly continuous because
||ψnx (t) −ψnx (t′)||X
≤
Z
R
|φn (t′ −s) −φn (t −s)| ||θx (s)||X ds
≤
C ||x||p
µZ
R
|φn (t′ −s) −φn (t −s)|p′
ds
¶1/p′
Also for x ∈C ([0, T] ; X) , it follows from usual molliﬁer arguments that
||ψnx −x||L∞([0,T ];X) →0.
Here is why. For t ∈[0, T] ,
||ψnx (t) −x (t)||X
≤
Z
R
φn (s) ||θx (t −s) −θx (t)|| ds
≤
Cθ
Z 1/n
−1/n
φn (s) dsε = Cθε
provided n is large enough due to the compact support and consequent uniform
continuity of θx.
If ||ψnx −x||L∞([0,T ];X) →0, then {ψnx} must be a Cauchy sequence in C ([0, T] ; X)
and this requires that x equals a continuous function a.e. Thus C ([0, T] ; X) con-
sists exactly of those functions, x of Lp ([0, T] ; X) such that ||ψnx −x||∞→0. It
follows
C ([0, T] ; X) =
∩∞
n=1 ∪∞
m=1 ∩∞
k=m
½
x ∈Lp ([0, T] ; X) : ||ψkx −x||∞≤1
n
¾
.
(21.34)
It only remains to show
S ≡{x ∈Lp ([0, T] ; X) : ||ψkx −x||∞≤α}

21.5.
THE SPACES LP (Ω; X)
609
is a Borel set. Suppose then that xn ∈S and xn →x in Lp ([0, T] ; X). Then there
exists a subsequence, still denoted by n such that xn →x pointwise a.e. as well as
in Lp. There exists a set of measure 0 such that for all n, and t not in this set,
||ψkxn (t) −xn (t)||
≡
¯¯¯¯¯
¯¯¯¯¯
Z 1/k
−1/k
φk (s) (θxn (t −s)) ds −xn (t)
¯¯¯¯¯
¯¯¯¯¯ ≤α
xn (t)
→
x (t) .
Then
||ψkxn (t) −xn (t) −(ψkx (t) −x (t))||
≤
||xn (t) −x (t)||X +
¯¯¯¯¯
¯¯¯¯¯
Z 1/k
−1/k
φk (s) (θxn (t −s) −θx (t −s)) ds
¯¯¯¯¯
¯¯¯¯¯
≤
||xn (t) −x (t)||X + Ck,θ ||xn −x||Lp(0,T ;X)
which converges to 0 as n →∞. It follows that for a.e. t,
||ψkx (t) −x (t)|| ≤α.
Thus S is closed and so the set in 21.34 is a Borel set. This proves the theorem.
As in the scalar case, the following lemma holds in this more general context.
Lemma 21.42 Let (Ω, µ) be a regular measure space where Ωis a locally compact
Hausdorﬀspace. Then Cc (Ω; X) the space of continuous functions having compact
support and values in X is dense in Lp (0, T; X) for all p ∈[0, ∞). For any σ ﬁnite
measure space, the simple functions are dense in Lp (0, T; X) .
Proof: First is it shown the simple functions are dense in Lp (0, T; X) . Let
f ∈Lp (0, T; X) and let {xn} denote a sequence of simple functions which converge
to f pointwise which also have the property that
||xn (s)|| ≤2 ||f (s)||
Then
Z
Ω
||xn (s) −f (s)||p dµ →0
from the dominated convergence theorem. Therefore, the simple functions are in-
deed dense in Lp (0, T; X) .
Next suppose (Ω, µ) is a regular measure space. If x (s) ≡P
i aiXEi (s) is a
simple function, then by regularity, there exist compact sets, Ki and open sets, Vi
such that Ki ⊆Ei ⊆Vi and µ (Vi \ Ki)1/p < ε/ P
i ||ai|| . Let Ki ≺hi ≺Vi. Then
consider
X
i
aihi ∈Cc (Ω) .

610
THE BOCHNER INTEGRAL
By the triangle inequality,
ÃZ
Ω
¯¯¯¯¯
¯¯¯¯¯
X
i
aihi (s) −aiXEi (s)
¯¯¯¯¯
¯¯¯¯¯
p
dµ
!1/p
≤
X
i
µZ
Ω
||ai (hi (s) −XEi (s))||p dµ
¶1/p
≤
X
i
µZ
Ω
||ai||p |hi (s) −XEi (s)|p dµ
¶1/p
≤
X
i
||ai||
ÃZ
Vi\Ki
dµ
!1/p
≤
X
i
||ai|| µ (Vi \ Ki)1/p < ε
Since ε is arbitrary, this and the ﬁrst part of the lemma shows Cc (Ω; X) is dense
in Lp (Ω; X) .
21.6
Measurable Representatives
In this section consider the special case where X = L1 (B, ν) where (B, F,ν) is a σ
ﬁnite measure space and x ∈L1 (Ω; X). Thus for each s ∈Ω, x (s) ∈L1 (B, ν). In
general, the map
(s, t) →x (s) (t)
will not be measurable, but one can obtain a measurable representative. This is
important because it allows the use of Fubini’s theorem on the measurable repre-
sentative.
By Theorem 21.19, there exists a sequence of simple functions, {xn}, of the form
xn (s) =
m
X
k=1
akXEk (s)
(21.35)
where ak ∈L1 (B, ν) which satisfy the conditions of Deﬁnition 21.17 and
||xn −x||1 →0.
(21.36)
Because of the form of xn given in 21.35, if
xn (s, t) ≡xn (s) (t),
then xn is measurable.
Z
Ω
Z
B
|xn (s, t) −xm (s, t)| dνdµ ≤
Z
Ω
Z
B
|xn (s, t) −x (s) (t)| dνdµ

21.6.
MEASURABLE REPRESENTATIVES
611
+
Z
Ω
Z
B
|xm (s, t) −x (s) (t)| dνdµ.
(21.37)
It follows from 21.37 and 21.36 that {xn} is a Cauchy sequence in L1 (Ω× B).
Therefore, there exists y ∈L1 (Ω× B) and a subsequence of {xn}, still denoted by
{xn}, such that
lim
n→∞xn (s, t) = y (s, t) a.e.
and
lim
n→∞||xn −y||1 = 0.
It follows that
Z
Ω
Z
B
|y (s, t) −x (s) (t)| dνdµ
≤
Z
Ω
Z
B
|y (s, t) −xn (s, t)| dνdµ
(21.38)
+
Z
Ω
Z
B
|x (s) (t) −xn (s, t)| dνdµ.
Since limn→∞||xn −x||1 = 0, it follows from 21.38 that y = x in L1 (Ω; X) . Thus,
for a.e. s,
y (s, ·) = x (s) in X = L1 (B).
Now
R
Ωx (s) dµ ∈X = L1 (B, ν) so it makes sense to ask for
¡R
Ωx (s) dµ
¢
(t), at
least a.e. To ﬁnd what this is, note
¯¯¯¯
¯¯¯¯
Z
Ω
xn (s) dµ −
Z
Ω
x (s) dµ
¯¯¯¯
¯¯¯¯
X
≤
Z
Ω
||xn (s) −x (s)||X dµ.
Therefore, since the right side converges to 0,
lim
n→∞
¯¯¯¯
¯¯¯¯
Z
Ω
xn (s) dµ −
Z
Ω
x (s) dµ
¯¯¯¯
¯¯¯¯
X
=
lim
n→∞
Z
B
¯¯¯¯
µZ
Ω
xn (s) dµ
¶
(t) −
µZ
Ω
x (s) dµ
¶
(t)
¯¯¯¯ dν = 0.
But
µZ
Ω
xn (s) dµ
¶
(t) =
Z
Ω
xn (s, t) dµ a.e. t.
Therefore
lim
n→∞
Z
B
¯¯¯¯
Z
Ω
xn (s, t) dµ −
µZ
Ω
x (s) dµ
¶
(t)
¯¯¯¯ dν = 0.
(21.39)
Also, since xn →y in L1 (Ω× B),
0 = lim
n→∞
Z
B
Z
Ω
|xn (s, t) −y (s, t)| dµdν ≥
lim
n→∞
Z
B
¯¯¯¯
Z
Ω
xn (s, t) dµ −
Z
Ω
y (s, t) dµ
¯¯¯¯ dν.
(21.40)

612
THE BOCHNER INTEGRAL
From 21.39 and 21.40
Z
Ω
y (s, t) dµ =
µZ
Ω
x (s) dµ
¶
(t) a.e. t.
This proves the following theorem.
Theorem 21.43 Let X = L1 (B) where (B, F, ν) is a σ ﬁnite measure space and
let x ∈L1 (Ω; X). Then there exists a measurable representative, y ∈L1 (Ω× B),
such that
x (s) = y (s, ·) a.e. s in Ω,
and
Z
Ω
y (s, t) dµ =
µZ
Ω
x (s) dµ
¶
(t) a.e. t.
21.7
Vector Measures
There is also a concept of vector measures.
Deﬁnition 21.44 Let (Ω, S) be a set and a σ algebra of subsets of Ω. A mapping
F : S →X
is said to be a vector measure if
F (∪∞
i=1Ei) =
∞
X
i=1
F (Ei)
whenever {Ei}∞
i=1 is a sequence of disjoint elements of S. For F a vector measure,
|F| (A) ≡sup{
X
F ∈π(A)
||µ (F)|| : π (A) is a partition of A}.
This is the same deﬁnition that was given in the case where F would have values
in C, the only diﬀerence being the fact that now F has values in a general Banach
space X as the vector space of values of the vector measure. Recall that a partition
of A is a ﬁnite set, {F1, · · ·, Fm} ⊆S such that ∪m
i=1Fi = A. The same theorem
about |F| proved in the case of complex valued measures holds in this context with
the same proof. For completeness, it is included here.
Theorem 21.45 If |F| (Ω) < ∞, then |F| is a measure on S.
Proof: Let E1 and E2 be sets of S such that E1 ∩E2 = ∅and let {Ai
1 ···Ai
ni} =
π(Ei), a partition of Ei which is chosen such that
|F|(Ei) −ε <
ni
X
j=1
||F(Ai
j)|| i = 1, 2.

21.7.
VECTOR MEASURES
613
Consider the sets which are contained in either of π (E1) or π (E2) , it follows this
collection of sets is a partition of E1 ∪E2 which is denoted here by π(E1 ∪E2).
Then by the above inequality and the deﬁnition of total variation,
|F|(E1 ∪E2) ≥
X
F ∈π(E1∪E2)
||F(F)|| > |F|(E1) + |F|(E2) −2ε,
which shows that since ε > 0 was arbitrary,
|F|(E1 ∪E2) ≥|F|(E1) + |F|(E2).
(21.41)
Let {Ej}∞
j=1 be a sequence of disjoint sets of S and let E∞= ∪∞
j=1Ej. Then by the
deﬁnition of total variation there exists a partition of E∞, π(E∞) = {A1, · · ·, An}
such that
|F|(E∞) −ε <
n
X
i=1
||F(Ai)||.
Also,
Ai = ∪∞
j=1Ai ∩Ej
and so by the triangle inequality, ||F(Ai)|| ≤P∞
j=1 ||F(Ai ∩Ej)||. Therefore, by
the above,
|F|(E∞) −ε
<
n
X
i=1
≥||F (Ai)||
z
}|
{
∞
X
j=1
||F(Ai ∩Ej)||
=
∞
X
j=1
n
X
i=1
||F(Ai ∩Ej)||
≤
∞
X
j=1
|F|(Ej)
because {Ai ∩Ej}n
i=1 is a partition of Ej.
Since ε > 0 is arbitrary, this shows
|F|(∪∞
j=1Ej) ≤
∞
X
j=1
|F|(Ej).
Also, 21.41 implies that whenever the Ei are disjoint, |F|(∪n
j=1Ej) ≥Pn
j=1 |F|(Ej).
Therefore,
∞
X
j=1
|F|(Ej) ≥|F|(∪∞
j=1Ej) ≥|F|(∪n
j=1Ej) ≥
n
X
j=1
|F|(Ej).
Since n is arbitrary,
|F|(∪∞
j=1Ej) =
∞
X
j=1
|F|(Ej)
which shows that |F| is a measure as claimed. This proves the theorem.

614
THE BOCHNER INTEGRAL
Deﬁnition 21.46 A Banach space is said to have the Radon Nikodym property if
whenever
(Ω, S, µ) is a ﬁnite measure space
F : S →X is a vector measure with |F| (Ω) < ∞
F ≪µ
then one may conclude there exists g ∈L1 (Ω; X) such that
F (E) =
Z
E
g (s) dµ
for all E ∈S.
Some Banach spaces have the Radon Nikodym property and some don’t. No
attempt is made to give a complete answer to the question of which Banach spaces
have this property but the next theorem gives examples of many spaces which do.
Theorem 21.47 Suppose X′ is a separable dual space. Then X′ has the Radon
Nikodym property.
Proof: Let F ≪µ and let |F| (Ω) < ∞for F : S →X′, a vector measure. Pick
x ∈X and consider the map
E →F (E) (x)
for E ∈S. This deﬁnes a complex measure which is absolutely continuous with
respect to |F|.
Therefore, by the Radon Nikodym theorem, there exists fx ∈
L1 (Ω, |F|) such that
F (E) (x) =
Z
E
fx (s) d |F|.
(21.42)
Claim: |fx (s)| ≤||x|| for |F| a.e. s.
Proof of claim: Consider the closed ball in F, B (0, ||x||) and let B ≡B (p, r)
be an open ball contained in its complement. Let f −1
x
(B) ≡E ∈S. I want to
argue that |F| (E) = 0 so suppose |F| (E) > 0. then
|F| (E) ||x|| ≥||F (E)|| ||x|| ≥|F (E) (x)|
and so from 21.42,
1
|F| (E)
¯¯¯¯
Z
E
fx (s) d |F|
¯¯¯¯ ≤||x|| .
(21.43)
But on E, |fx (s) −p| < r and so
¯¯¯¯
1
|F| (E)
Z
E
fx (s) d |F| −p
¯¯¯¯ < r
which contradicts 21.43 because B (p, r) was given to have empty intersection with
B (0, ||x||). Therefore, |F| (E) = 0 as hoped. Now F \ B (0, ||x||) can be covered by
countably many such balls and so |F|
³
F \ B (0, ||x||)
´
= 0.

21.7.
VECTOR MEASURES
615
Denote the exceptional set of measure zero by Nx. By Theorem 21.13, X is
separable. Letting D be a dense, countable subset of X, deﬁne
N1 ≡∪x∈DNx.
Thus
|F| (N1) = 0.
For any E ∈S, x, y ∈D, and a, b ∈F,
Z
E
fax+by (s) d |F| = F (E) (ax + by) = aF (E) (x) + bF (E) (y)
=
Z
E
(afx (s) + bfy (s)) d |F|.
(21.44)
Since 21.44 holds for all E ∈S, it follows
fax+by (s) = afx (s) + bfy (s)
for |F| a.e. s and x, y ∈D. Let ˜D consist of all ﬁnite linear combinations of the
form Pm
i=1 aixi where ai is a rational point of F and xi ∈D. If
m
X
i=1
aixi ∈˜D,
the above argument implies
fPm
i=1 aixi (s) =
m
X
i=1
aifxi (s) a.e.
Since ˜D is countable, there exists a set, N2, with
|F| (N2) = 0
such that for s /∈N2,
fPm
i=1 aixi (s) =
m
X
i=1
aifxi (s)
(21.45)
whenever Pm
i=1 aixi ∈˜D. Let
N = N1 ∪N2
and let
˜hx (s) ≡XNC (s) fx (s)
for all x ∈˜D. Now for x ∈X deﬁne
hx (s) ≡lim
x′→x{˜hx′ (s) : x′ ∈˜D}.

616
THE BOCHNER INTEGRAL
This is well deﬁned because if x′ and y′ are elements of ˜D, the above claim and
21.45 imply
¯¯¯˜hx′ (s) −˜hy′ (s)
¯¯¯ =
¯¯¯˜h(x′−y′) (s)
¯¯¯ ≤||x′ −y′||.
Using 21.45, the dominated convergence theorem may be applied to conclude that
for xn →x, with xn ∈˜D,
Z
E
hx (s) d |F| = lim
n→∞
Z
E
˜hxn (s) d |F| = lim
n→∞F (E) (xn) = F (E) (x).
(21.46)
It follows from the density of ˜D that for all x, y ∈X and a, b ∈F,
|hx (s)| ≤||x|| , hax+by (s) = ahx (s) + bhy (s),
(21.47)
for all s because if s ∈N, both sides of the equation in 21.47 equal 0.
Let θ (s) be given by
θ (s) (x) = hx (s).
By 21.47 it follows that θ (s) ∈X′ for each s. Also
θ (s) (x) = hx (s) ∈L1 (Ω)
so θ (·) is weak ∗measurable. Since X′ is separable, Theorem 21.12 implies that θ
is strongly measurable. Furthermore, by 21.47,
||θ (s)|| ≡sup
||x||≤1
|θ (s) (x)| ≤sup
||x||≤1
|hx (s)| ≤1.
Therefore,
Z
Ω
||θ (s)|| d |F| < ∞
so θ ∈L1 (Ω; X′). By 21.6, if E ∈S,
Z
E
hx (s) d |F| =
Z
E
θ (s) (x) d |F| =
µZ
E
θ (s) d |F|
¶
(x).
(21.48)
From 21.46 and 21.48,
µZ
E
θ (s) d |F|
¶
(x) = F (E) (x)
for all x ∈X and therefore,
Z
E
θ (s) d |F| = F (E).
Finally, since F ≪µ, |F| ≪µ also and so there exists k ∈L1 (Ω) such that
|F| (E) =
Z
E
k (s) dµ

21.8.
THE RIESZ REPRESENTATION THEOREM
617
for all E ∈S, by the Radon Nikodym Theorem. It follows
F (E) =
Z
E
θ (s) d |F| =
Z
E
θ (s) k (s) dµ.
Letting g (s) = θ (s) k (s), this has proved the theorem.
Corollary 21.48 Any separable reﬂexive Banach space has the Radon Nikodym
property.
It is not necessary to assume separability in the above corollary. For the proof
of a more general result, consult Vector Measures by Diestal and Uhl, [16].
21.8
The Riesz Representation Theorem
The Riesz representation theorem for the spaces Lp (Ω; X) holds under certain con-
ditions. The proof follows the proofs given earlier for scalar valued functions.
Deﬁnition 21.49 If X and Y are two Banach spaces, X is isometric to Y if there
exists θ ∈L (X, Y ) such that
||θx||Y = ||x||X .
This will be written as X ∼= Y . The map θ is called an isometry.
The next theorem says that Lp′ (Ω; X′) is always isometric to a subspace of
(Lp (Ω; X))′ for any Banach space, X.
Theorem 21.50 Let X be any Banach space and let (Ω, S, µ) be a ﬁnite measure
space. Let p ≥1 and let 1/p + 1/p′ = 1.(If p = 1, p′ ≡∞.) Then Lp′ (Ω; X′) is
isometric to a subspace of (Lp (Ω; X))′.
Also, for g ∈Lp′ (Ω; X′),
sup
||f||p≤1
¯¯¯¯
Z
Ω
g (s) (f (s)) dµ
¯¯¯¯ = ||g||p′ .
Proof: First observe that for f ∈Lp (Ω; X) and g ∈Lp′ (Ω; X′),
s →g (s) (f (s))
is a function in L1 (Ω).
(To obtain measurability, write f as a limit of simple
functions. Holder’s inequality then yields the function is in L1 (Ω).) Deﬁne
θ : Lp′ (Ω; X′) →(Lp (Ω; X))′
by
θg (f) ≡
Z
Ω
g (s) (f (s)) dµ.

618
THE BOCHNER INTEGRAL
Holder’s inequality implies
||θg|| ≤||g||p′
(21.49)
and it is also clear that θ is linear. Next it is required to show
||θg|| = ||g||.
This will ﬁrst be veriﬁed for simple functions. Let
g (s) =
m
X
i=1
ciXEi (s)
where ci ∈X′, the Ei are disjoint and
∪m
i=1Ei = Ω.
Then ||g|| ∈Lp′ (Ω).
Let ε > 0 be given.
By the scalar Riesz representation
theorem, there exists h ∈Lp (Ω) such that ||h||p = 1 and
Z
Ω
||g (s)||X′ h (s) dµ ≥||g||Lp′(Ω;X′) −ε.
Now let di be chosen such that
ci (di) ≥||ci||X′ −ε/ ||h||L1(Ω)
and ||di||X ≤1. Let
f (s) ≡
m
X
i=1
dih (s) XEi (s).
Thus f ∈Lp (Ω; X) and ||f||Lp(Ω;X) ≤1. This follows from
||f||p
p
=
Z
Ω
m
X
i=1
||di||p
X |h (s)|p XEi (s) dµ
=
m
X
i=1
µZ
Ei
|h (s)p| dµ
¶
||di||p
X ≤
Z
Ω
|h|p dµ = 1.
Also
||θg|| ≥|θg (f)| =
¯¯¯¯
Z
Ω
g (s) (f (s)) dµ
¯¯¯¯ ≥
¯¯¯¯¯
Z
Ω
m
X
i=1
³
||ci||X′ −ε/ ||h||L1(Ω)
´
h (s) XEi (s) dµ
¯¯¯¯¯
≥
¯¯¯¯
Z
Ω
||g (s)||X′ h (s) dµ
¯¯¯¯ −ε
¯¯¯¯
Z
Ω
h (s) / ||h||L1(Ω) dµ
¯¯¯¯
≥||g||Lp′(Ω;X′) −2ε.

21.8.
THE RIESZ REPRESENTATION THEOREM
619
Since ε was arbitrary,
||θg|| ≥||g||
(21.50)
and from 21.49 this shows equality holds in 21.50 whenever g is a simple function.
In general, let g ∈Lp′ (Ω; X′) and let gn be a sequence of simple functions
converging to g in Lp′ (Ω; X′). Then
||θg|| = lim
n→∞||θgn|| = lim
n→∞||gn|| = ||g||.
This proves the theorem and shows θ is the desired isometry.
Theorem 21.51 If X is a Banach space and X′ has the Radon Nikodym property,
then if (Ω, S, µ) is a ﬁnite measure space,
(Lp (Ω; X))′ ∼= Lp′ (Ω; X′)
and in fact the mapping θ of Theorem 21.50 is onto.
Proof: Let l ∈(Lp (Ω; X))′ and deﬁne F (E) ∈X′ by
F (E) (x) ≡l (XE (·) x).
Lemma 21.52 F deﬁned above is a vector measure with values in X′ and |F| (Ω) <
∞.
Proof of the lemma: Clearly F (E) is linear. Also
||F (E)|| = sup
||x||≤1
||F (E) (x)||
≤||l|| sup
||x||≤1
||XE (·) x||Lp(Ω;X) ≤||l|| µ (E)1/p.
Let {Ei}∞
i=1 be a sequence of disjoint elements of S and let E = ∪n<∞En.
¯¯¯¯¯F (E) (x) −
n
X
k=1
F (Ek) (x)
¯¯¯¯¯
=
¯¯¯¯¯l (XE (·) x) −
n
X
i=1
l (XEi (·) x)
¯¯¯¯¯
(21.51)
≤
||l||
¯¯¯¯¯
¯¯¯¯¯XE (·) x −
n
X
i=1
XEi (·) x
¯¯¯¯¯
¯¯¯¯¯
Lp(Ω;X)
≤
||l|| µ
Ã [
k>n
Ek
!1/p
||x||.
Since µ (Ω) < ∞,
lim
n→∞µ
Ã [
k>n
Ek
!1/p
= 0

620
THE BOCHNER INTEGRAL
and so inequality 21.51 shows that
lim
n→∞
¯¯¯¯¯
¯¯¯¯¯F (E) −
n
X
k=1
F (Ek)
¯¯¯¯¯
¯¯¯¯¯
X′
= 0.
To show |F| (Ω) < ∞, let ε > 0 be given, let {H1, · · ·, Hn} be a partition of Ω,
and let ||xi|| ≤1 be chosen in such a way that
F (Hi) (xi) > ||F (Hi)|| −ε/n.
Thus
−ε +
n
X
i=1
||F (Hi)|| <
n
X
i=1
l (XHi (·) xi) ≤||l||
¯¯¯¯¯
¯¯¯¯¯
n
X
i=1
XHi (·) xi
¯¯¯¯¯
¯¯¯¯¯
Lp(Ω;X)
≤||l||
ÃZ
Ω
n
X
i=1
XHi (s) dµ
!1/p
= ||l|| µ (Ω)1/p.
Since ε > 0 was arbitrary,
n
X
i=1
||F (Hi)|| < ||l|| µ (Ω)1/p.
Since the partition was arbitrary, this shows |F| (Ω) ≤||l|| µ (Ω)1/p and this proves
the lemma.
Continuing with the proof of Theorem 21.51, note that
F ≪µ.
Since X′ has the Radon Nikodym property, there exists g ∈L1 (Ω; X′) such that
F (E) =
Z
E
g (s) dµ.
Also, from the deﬁnition of F (E) ,
l
Ã n
X
i=1
xiXEi (·)
!
=
n
X
i=1
l (XEi (·) xi)
=
n
X
i=1
F (Ei) (xi) =
n
X
i=1
Z
Ei
g (s) (xi) dµ.
(21.52)
It follows from 21.52 that whenever h is a simple function,
l (h) =
Z
Ω
g (s) (h (s)) dµ.
(21.53)

21.9.
EXERCISES
621
Let
Gn ≡{s : ||g (s)||X′ ≤n}
and let
j : Lp (Gn; X) →Lp (Ω; X)
be given by
jh (s) =
½
h (s) if s ∈Gn,
0 if s /∈Gn.
Letting h be a simple function in Lp (Gn; X),
j∗l (h) = l (jh) =
Z
Gn
g (s) (h (s)) dµ.
(21.54)
Since the simple functions are dense in Lp (Gn; X), and g ∈Lp′ (Gn; X′), it follows
21.54 holds for all h ∈Lp (Gn; X). By Theorem 21.50,
||g||Lp′(Gn;X′) = ||j∗l||(Lp(Gn;X))′ ≤||l||(Lp(Ω;X))′ .
By the monotone convergence theorem,
||g||Lp′(Ω;X′) = lim
n→∞||g||Lp′(Gn;X′) ≤||l||(Lp(Ω;X))′ .
Therefore g ∈Lp′ (Ω; X′) and since simple functions are dense in Lp (Ω; X), 21.53
holds for all h ∈Lp (Ω; X) . Thus l = θg and the theorem is proved because, by
Theorem 21.50, ||l|| = ||g|| and the mapping θ is onto because l was arbitrary.
Corollary 21.53 If X′ is separable, then
(Lp (Ω; X))′ ∼= Lp′ (Ω; X′).
Corollary 21.54 If X is separable and reﬂexive, then
(Lp (Ω; X))′ ∼= Lp′ (Ω; X′).
Corollary 21.55 If X is separable and reﬂexive, then if p ∈(1, ∞) , then Lp (Ω; X)
is reﬂexive.
Proof: This is just like the scalar valued case.
21.9
Exercises
1. Show L1 (R) is not reﬂexive. Hint: L1 (R) is separable. What about L∞(R)?
2. If f ∈L1 (Rn; X) for X a Banach space, does the usual fundamental theorem
of calculus work?
That is, can you say limr→0
1
m(B(x,r))
R
B(x,r) f (t) dm =
f (x) a.e.?
3. Does the Vitali convergence theorem hold for Bochner integrable functions?
If so, give a statement of the appropriate theorem and a proof.

622
THE BOCHNER INTEGRAL

Part III
Complex Analysis
623


The Complex Numbers
The reader is presumed familiar with the algebraic properties of complex numbers,
including the operation of conjugation. Here a short review of the distance in C is
presented.
The length of a complex number, referred to as the modulus of z and denoted
by |z| is given by
|z| ≡
¡
x2 + y2¢1/2 = (zz)1/2 ,
Then C is a metric space with the distance between two complex numbers, z and
w deﬁned as
d (z, w) ≡|z −w| .
This metric on C is the same as the usual metric of R2. A sequence, zn →z if and
only if xn →x in R and yn →y in R where z = x + iy and zn = xn + iyn. For
example if zn =
n
n+1 + i 1
n, then zn →1 + 0i = 1.
Deﬁnition 22.1 A sequence of complex numbers, {zn} is a Cauchy sequence if for
every ε > 0 there exists N such that n, m > N implies |zn −zm| < ε.
This is the usual deﬁnition of Cauchy sequence. There are no new ideas here.
Proposition 22.2 The complex numbers with the norm just mentioned forms a
complete normed linear space.
Proof: Let {zn} be a Cauchy sequence of complex numbers with zn = xn +iyn.
Then {xn} and {yn} are Cauchy sequences of real numbers and so they converge
to real numbers, x and y respectively. Thus zn = xn + iyn →x + iy. C is a linear
space with the ﬁeld of scalars equal to C. It only remains to verify that | | satisﬁes
the axioms of a norm which are:
|z + w| ≤|z| + |w|
|z| ≥0 for all z
|z| = 0 if and only if z = 0
|αz| = |α| |z| .
625

626
THE COMPLEX NUMBERS
The only one of these axioms of a norm which is not completely obvious is the ﬁrst
one, the triangle inequality. Let z = x + iy and w = u + iv
|z + w|2
=
(z + w) (z + w) = |z|2 + |w|2 + 2 Re (zw)
≤
|z|2 + |w|2 + 2 |(zw)| = (|z| + |w|)2
and this veriﬁes the triangle inequality.
Deﬁnition 22.3 An inﬁnite sum of complex numbers is deﬁned as the limit of the
sequence of partial sums. Thus,
∞
X
k=1
ak ≡lim
n→∞
n
X
k=1
ak.
Just as in the case of sums of real numbers, an inﬁnite sum converges if and
only if the sequence of partial sums is a Cauchy sequence.
From now on, when f is a function of a complex variable, it will be assumed that
f has values in X, a complex Banach space. Usually in complex analysis courses,
f has values in C but there are many important theorems which don’t require this
so I will leave it fairly general for a while. Later the functions will have values in
C. If you are only interested in this case, think C whenever you see X.
Deﬁnition 22.4 A sequence of functions of a complex variable, {fn} converges
uniformly to a function, g for z ∈S if for every ε > 0 there exists Nε such that if
n > Nε, then
||fn (z) −g (z)|| < ε
for all z ∈S. The inﬁnite sum P∞
k=1 fn converges uniformly on S if the partial
sums converge uniformly on S. Here ||·|| refers to the norm in X, the Banach space
in which f has its values.
The following proposition is also a routine application of the above deﬁnition.
Neither the deﬁnition nor this proposition say anything new.
Proposition 22.5 A sequence of functions, {fn} deﬁned on a set S, converges
uniformly to some function, g if and only if for all ε > 0 there exists Nε such that
whenever m, n > Nε,
||fn −fm||∞< ε.
Here ||f||∞≡sup {||f (z)|| : z ∈S} .
Just as in the case of functions of a real variable, one of the important theorems
is the Weierstrass M test. Again, there is nothing new here. It is just a review of
earlier material.
Theorem 22.6 Let {fn} be a sequence of complex valued functions deﬁned on S ⊆
C. Suppose there exists Mn such that ||fn||∞< Mn and P Mn converges. Then
P fn converges uniformly on S.

22.1.
THE EXTENDED COMPLEX PLANE
627
Proof: Let z ∈S. Then letting m < n
¯¯¯¯¯
¯¯¯¯¯
n
X
k=1
fk (z) −
m
X
k=1
fk (z)
¯¯¯¯¯
¯¯¯¯¯ ≤
n
X
k=m+1
||fk (z)|| ≤
∞
X
k=m+1
Mk < ε
whenever m is large enough. Therefore, the sequence of partial sums is uniformly
Cauchy on S and therefore, converges uniformly to P∞
k=1 fk (z) on S.
22.1
The Extended Complex Plane
The set of complex numbers has already been considered along with the topology of
C which is nothing but the topology of R2. Thus, for zn = xn +iyn, zn →z ≡x+iy
if and only if xn →x and yn →y. The norm in C is given by
|x + iy| ≡((x + iy) (x −iy))1/2 =
¡
x2 + y2¢1/2
which is just the usual norm in R2 identifying (x, y) with x + iy. Therefore, C is
a complete metric space topologically like R2 and so the Heine Borel theorem that
compact sets are those which are closed and bounded is valid.
Thus, as far as
topology is concerned, there is nothing new about C.
The extended complex plane, denoted by bC , consists of the complex plane, C
along with another point not in C known as ∞. For example, ∞could be any point
in R3. A sequence of complex numbers, zn, converges to ∞if, whenever K is a
compact set in C, there exists a number, N such that for all n > N, zn /∈K. Since
compact sets in C are closed and bounded, this is equivalent to saying that for all
R > 0, there exists N such that if n > N, then zn /∈B (0, R) which is the same as
saying limn→∞|zn| = ∞where this last symbol has the same meaning as it does in
calculus.
A geometric way of understanding this in terms of more familiar objects involves
a concept known as the Riemann sphere.
Consider the unit sphere, S2 given by (z −1)2 + y2 + x2 = 1. Deﬁne a map
from the complex plane to the surface of this sphere as follows.
Extend a line
from the point, p in the complex plane to the point (0, 0, 2) on the top of this
sphere and let θ (p) denote the point of this sphere which the line intersects. Deﬁne
θ (∞) ≡(0, 0, 2).
s
s
s
(0, 0, 2)
(0, 0, 1)
s
@
@
@
@
@
@@
p
θ(p)
C

628
THE COMPLEX NUMBERS
Then θ−1 is sometimes called sterographic projection. The mapping θ is clearly
continuous because it takes converging sequences, to converging sequences. Fur-
thermore, it is clear that θ−1 is also continuous. In terms of the extended complex
plane, bC, a sequence, zn converges to ∞if and only if θzn converges to (0, 0, 2) and
a sequence, zn converges to z ∈C if and only if θ (zn) →θ (z) .
In fact this makes it easy to deﬁne a metric on bC.
Deﬁnition 22.7 Let z, w ∈bC including possibly w = ∞. Then let d (x, w) ≡
|θ (z) −θ (w)| where this last distance is the usual distance measured in R3.
Theorem 22.8
³
bC, d
´
is a compact, hence complete metric space.
Proof: Suppose {zn} is a sequence in bC. This means {θ (zn)} is a sequence in
S2 which is compact. Therefore, there exists a subsequence, {θznk} and a point,
z ∈S2 such that θznk →θz in S2 which implies immediately that d (znk, z) →0.
A compact metric space must be complete.
22.2
Exercises
1. Prove the root test for series of complex numbers.
If ak ∈C and r ≡
lim supn→∞|an|1/n then
∞
X
k=0
ak



converges absolutely if r < 1
diverges if r > 1
test fails if r = 1.
2. Does limn→∞n
¡ 2+i
3
¢n exist? Tell why and ﬁnd the limit if it does exist.
3. Let A0 = 0 and let An ≡Pn
k=1 ak if n > 0. Prove the partial summation
formula,
q
X
k=p
akbk = Aqbq −Ap−1bp +
q−1
X
k=p
Ak (bk −bk+1) .
Now using this formula, suppose {bn} is a sequence of real numbers which
converges to 0 and is decreasing.
Determine those values of ω such that
|ω| = 1 and P∞
k=1 bkωk converges.
4. Let f : U ⊆C →C be given by f (x + iy) = u (x, y) + iv (x, y) . Show f is
continuous on U if and only if u : U →R and v : U →R are both continuous.

Riemann Stieltjes Integrals
In the theory of functions of a complex variable, the most important results are those
involving contour integration. I will base this on the notion of Riemann Stieltjes
integrals as in [13], [39], and [27]. The Riemann Stieltjes integral is a generalization
of the usual Riemann integral and requires the concept of a function of bounded
variation.
Deﬁnition 23.1 Let γ : [a, b] →C be a function. Then γ is of bounded variation
if
sup
( n
X
i=1
|γ (ti) −γ (ti−1)| : a = t0 < · · · < tn = b
)
≡V (γ, [a, b]) < ∞
where the sums are taken over all possible lists, {a = t0 < · · · < tn = b} .
The idea is that it makes sense to talk of the length of the curve γ ([a, b]) , deﬁned
as V (γ, [a, b]) . For this reason, in the case that γ is continuous, such an image of a
bounded variation function is called a rectiﬁable curve.
Deﬁnition 23.2 Let γ : [a, b] →C be of bounded variation and let f : [a, b] →X.
Letting P ≡{t0, · · ·, tn} where a = t0 < t1 < · · · < tn = b, deﬁne
||P|| ≡max {|tj −tj−1| : j = 1, · · ·, n}
and the Riemann Steiltjes sum by
S (P) ≡
n
X
j=1
f (γ (τ j)) (γ (tj) −γ (tj−1))
where τ j ∈[tj−1, tj] . (Note this notation is a little sloppy because it does not identify
the speciﬁc point, τ j used. It is understood that this point is arbitrary.) Deﬁne
R
γ fdγ as the unique number which satisﬁes the following condition. For all ε > 0
there exists a δ > 0 such that if ||P|| ≤δ, then
¯¯¯¯
Z
γ
fdγ −S (P)
¯¯¯¯ < ε.
629

630
RIEMANN STIELTJES INTEGRALS
Sometimes this is written as
Z
γ
fdγ ≡
lim
||P||→0 S (P) .
The set of points in the curve, γ ([a, b]) will be denoted sometimes by γ∗.
Then γ∗is a set of points in C and as t moves from a to b, γ (t) moves from
γ (a) to γ (b) . Thus γ∗has a ﬁrst point and a last point. If φ : [c, d] →[a, b] is
a continuous nondecreasing function, then γ ◦φ : [c, d] →C is also of bounded
variation and yields the same set of points in C with the same ﬁrst and last points.
Theorem 23.3 Let φ and γ be as just described. Then assuming that
Z
γ
fdγ
exists, so does
Z
γ◦φ
fd (γ ◦φ)
and
Z
γ
fdγ =
Z
γ◦φ
fd (γ ◦φ) .
(23.1)
Proof: There exists δ > 0 such that if P is a partition of [a, b] such that ||P|| < δ,
then
¯¯¯¯
Z
γ
fdγ −S (P)
¯¯¯¯ < ε.
By continuity of φ, there exists σ > 0 such that if Q is a partition of [c, d] with
||Q|| < σ, Q = {s0, · · ·, sn} , then |φ (sj) −φ (sj−1)| < δ. Thus letting P denote the
points in [a, b] given by φ (sj) for sj ∈Q, it follows that ||P|| < δ and so
¯¯¯¯¯¯
Z
γ
fdγ −
n
X
j=1
f (γ (φ (τ j))) (γ (φ (sj)) −γ (φ (sj−1)))
¯¯¯¯¯¯
< ε
where τ j ∈[sj−1, sj] . Therefore, from the deﬁnition 23.1 holds and
Z
γ◦φ
fd (γ ◦φ)
exists.
This theorem shows that
R
γ fdγ is independent of the particular γ used in its
computation to the extent that if φ is any nondecreasing function from another
interval, [c, d] , mapping to [a, b] , then the same value is obtained by replacing γ
with γ ◦φ.
The fundamental result in this subject is the following theorem.

631
Theorem 23.4 Let f : γ∗→X be continuous and let γ : [a, b] →C be continuous
and of bounded variation. Then
R
γ fdγ exists. Also letting δm > 0 be such that
|t −s| < δm implies ||f (γ (t)) −f (γ (s))|| < 1
m,
¯¯¯¯
Z
γ
fdγ −S (P)
¯¯¯¯ ≤2V (γ, [a, b])
m
whenever ||P|| < δm.
Proof: The function, f ◦γ , is uniformly continuous because it is deﬁned on
a compact set. Therefore, there exists a decreasing sequence of positive numbers,
{δm} such that if |s −t| < δm, then
|f (γ (t)) −f (γ (s))| < 1
m.
Let
Fm ≡{S (P) : ||P|| < δm}.
Thus Fm is a closed set. (The symbol, S (P) in the above deﬁnition, means to
include all sums corresponding to P for any choice of τ j.) It is shown that
diam (Fm) ≤2V (γ, [a, b])
m
(23.2)
and then it will follow there exists a unique point, I ∈∩∞
m=1Fm.
This is because
X is complete. It will then follow I =
R
γ f (t) dγ (t) . To verify 23.2, it suﬃces to
verify that whenever P and Q are partitions satisfying ||P|| < δm and ||Q|| < δm,
|S (P) −S (Q)| ≤2
mV (γ, [a, b]) .
(23.3)
Suppose ||P|| < δm and Q ⊇P. Then also ||Q|| < δm. To begin with, suppose
that P ≡{t0, · · ·, tp, · · ·, tn} and Q ≡{t0, · · ·, tp−1, t∗, tp, · · ·, tn} . Thus Q contains
only one more point than P. Letting S (Q) and S (P) be Riemann Steiltjes sums,
S (Q) ≡
p−1
X
j=1
f (γ (σj)) (γ (tj) −γ (tj−1)) + f (γ (σ∗)) (γ (t∗) −γ (tp−1))
+f (γ (σ∗)) (γ (tp) −γ (t∗)) +
n
X
j=p+1
f (γ (σj)) (γ (tj) −γ (tj−1)) ,
S (P) ≡
p−1
X
j=1
f (γ (τ j)) (γ (tj) −γ (tj−1)) +
=f(γ(τ p))(γ(tp)−γ(tp−1))
z
}|
{
f (γ (τ p)) (γ (t∗) −γ (tp−1)) + f (γ (τ p)) (γ (tp) −γ (t∗))

632
RIEMANN STIELTJES INTEGRALS
+
n
X
j=p+1
f (γ (τ j)) (γ (tj) −γ (tj−1)) .
Therefore,
|S (P) −S (Q)| ≤
p−1
X
j=1
1
m |γ (tj) −γ (tj−1)| + 1
m |γ (t∗) −γ (tp−1)| +
1
m |γ (tp) −γ (t∗)| +
n
X
j=p+1
1
m |γ (tj) −γ (tj−1)| ≤1
mV (γ, [a, b]) .
(23.4)
Clearly the extreme inequalities would be valid in 23.4 if Q had more than one
extra point. You simply do the above trick more than one time. Let S (P) and
S (Q) be Riemann Steiltjes sums for which ||P|| and ||Q|| are less than δm and let
R ≡P ∪Q. Then from what was just observed,
|S (P) −S (Q)| ≤|S (P) −S (R)| + |S (R) −S (Q)| ≤2
mV (γ, [a, b]) .
and this shows 23.3 which proves 23.2. Therefore, there exists a unique complex
number, I ∈∩∞
m=1Fm which satisﬁes the deﬁnition of
R
γ fdγ. This proves the
theorem.
The following theorem follows easily from the above deﬁnitions and theorem.
Theorem 23.5 Let f ∈C (γ∗) and let γ : [a, b] →C be of bounded variation and
continuous. Let
M ≥max {||f ◦γ (t)|| : t ∈[a, b]} .
(23.5)
Then
¯¯¯¯
¯¯¯¯
Z
γ
fdγ
¯¯¯¯
¯¯¯¯ ≤MV (γ, [a, b]) .
(23.6)
Also if {fn} is a sequence of functions of C (γ∗) which is converging uniformly to
the function, f on γ∗, then
lim
n→∞
Z
γ
fndγ =
Z
γ
fdγ.
(23.7)
Proof: Let 23.5 hold. From the proof of the above theorem, when ||P|| < δm,
¯¯¯¯
¯¯¯¯
Z
γ
fdγ −S (P)
¯¯¯¯
¯¯¯¯ ≤2
mV (γ, [a, b])
and so
¯¯¯¯
¯¯¯¯
Z
γ
fdγ
¯¯¯¯
¯¯¯¯ ≤||S (P)|| + 2
mV (γ, [a, b])

633
≤
n
X
j=1
M |γ (tj) −γ (tj−1)| + 2
mV (γ, [a, b])
≤
MV (γ, [a, b]) + 2
mV (γ, [a, b]) .
This proves 23.6 since m is arbitrary. To verify 23.7 use the above inequality to
write
¯¯¯¯
¯¯¯¯
Z
γ
fdγ −
Z
γ
fndγ
¯¯¯¯
¯¯¯¯ =
¯¯¯¯
¯¯¯¯
Z
γ
(f −fn) dγ (t)
¯¯¯¯
¯¯¯¯
≤max {||f ◦γ (t) −fn ◦γ (t)|| : t ∈[a, b]} V (γ, [a, b]) .
Since the convergence is assumed to be uniform, this proves 23.7.
It turns out to be much easier to evaluate such integrals in the case where γ is
also C1 ([a, b]) . The following theorem about approximation will be very useful but
ﬁrst here is an easy lemma.
Lemma 23.6 Let γ : [a, b] →C be in C1 ([a, b]) . Then V (γ, [a, b]) < ∞so γ is of
bounded variation.
Proof: This follows from the following
n
X
j=1
|γ (tj) −γ (tj−1)|
=
n
X
j=1
¯¯¯¯¯
Z tj
tj−1
γ′ (s) ds
¯¯¯¯¯
≤
n
X
j=1
Z tj
tj−1
|γ′ (s)| ds
≤
n
X
j=1
Z tj
tj−1
||γ′||∞ds
=
||γ′||∞(b −a) .
Therefore it follows V (γ, [a, b]) ≤||γ′||∞(b −a) . Here ||γ||∞= max {|γ (t)| : t ∈[a, b]}.
Theorem 23.7 Let γ : [a, b] →C be continuous and of bounded variation. Let
Ωbe an open set containing γ∗and let f : Ω× K →X be continuous for K a
compact set in C, and let ε > 0 be given. Then there exists η : [a, b] →C such that
η (a) = γ (a) , γ (b) = η (b) , η ∈C1 ([a, b]) , and
||γ −η|| < ε,
(23.8)
¯¯¯¯
Z
γ
f (·, z) dγ −
Z
η
f (·, z) dη
¯¯¯¯ < ε,
(23.9)
V (η, [a, b]) ≤V (γ, [a, b]) ,
(23.10)
where ||γ −η|| ≡max {|γ (t) −η (t)| : t ∈[a, b]} .

634
RIEMANN STIELTJES INTEGRALS
Proof: Extend γ to be deﬁned on all R according to γ (t) = γ (a) if t < a and
γ (t) = γ (b) if t > b. Now deﬁne
γh (t) ≡1
2h
Z t+
2h
(b−a) (t−a)
−2h+t+
2h
(b−a) (t−a)
γ (s) ds.
where the integral is deﬁned in the obvious way. That is,
Z b
a
α (t) + iβ (t) dt ≡
Z b
a
α (t) dt + i
Z b
a
β (t) dt.
Therefore,
γh (b) = 1
2h
Z b+2h
b
γ (s) ds = γ (b) ,
γh (a) = 1
2h
Z a
a−2h
γ (s) ds = γ (a) .
Also, because of continuity of γ and the fundamental theorem of calculus,
γ′
h (t) = 1
2h
½
γ
µ
t +
2h
b −a (t −a)
¶ µ
1 +
2h
b −a
¶
−
γ
µ
−2h + t +
2h
b −a (t −a)
¶ µ
1 +
2h
b −a
¶¾
and so γh ∈C1 ([a, b]) . The following lemma is signiﬁcant.
Lemma 23.8 V (γh, [a, b]) ≤V (γ, [a, b]) .
Proof: Let a = t0 < t1 < · · · < tn = b. Then using the deﬁnition of γh and
changing the variables to make all integrals over [0, 2h] ,
n
X
j=1
|γh (tj) −γh (tj−1)| =
n
X
j=1
¯¯¯¯¯
1
2h
Z 2h
0
·
γ
µ
s −2h + tj +
2h
b −a (tj −a)
¶
−
γ
µ
s −2h + tj−1 +
2h
b −a (tj−1 −a)
¶¸¯¯¯¯
≤1
2h
Z 2h
0
n
X
j=1
¯¯¯¯γ
µ
s −2h + tj +
2h
b −a (tj −a)
¶
−
γ
µ
s −2h + tj−1 +
2h
b −a (tj−1 −a)
¶¯¯¯¯ ds.

635
For a given s ∈[0, 2h] , the points, s −2h + tj +
2h
b−a (tj −a) for j = 1, · · ·, n form
an increasing list of points in the interval [a −2h, b + 2h] and so the integrand is
bounded above by V (γ, [a −2h, b + 2h]) = V (γ, [a, b]) . It follows
n
X
j=1
|γh (tj) −γh (tj−1)| ≤V (γ, [a, b])
which proves the lemma.
With this lemma the proof of the theorem can be completed without too much
trouble. Let H be an open set containing γ∗such that H is a compact subset of Ω.
Let 0 < ε < dist
¡
γ∗, HC¢
. Then there exists δ1 such that if h < δ1, then for all t,
|γ (t) −γh (t)|
≤
1
2h
Z t+
2h
(b−a) (t−a)
−2h+t+
2h
(b−a) (t−a)
|γ (s) −γ (t)| ds
<
1
2h
Z t+
2h
(b−a) (t−a)
−2h+t+
2h
(b−a) (t−a)
εds = ε
(23.11)
due to the uniform continuity of γ. This proves 23.8.
From 23.2 and the above lemma, there exists δ2 such that if ||P|| < δ2, then for
all z ∈K,
¯¯¯¯
¯¯¯¯
Z
γ
f (·, z) dγ (t) −S (P)
¯¯¯¯
¯¯¯¯ < ε
3,
¯¯¯¯¯
¯¯¯¯¯
Z
γh
f (·, z) dγh (t) −Sh (P)
¯¯¯¯¯
¯¯¯¯¯ < ε
3
for all h. Here S (P) is a Riemann Steiltjes sum of the form
n
X
i=1
f (γ (τ i) , z) (γ (ti) −γ (ti−1))
and Sh (P) is a similar Riemann Steiltjes sum taken with respect to γh instead of
γ. Because of 23.11 γh (t) has values in H ⊆Ω. Therefore, ﬁx the partition, P, and
choose h small enough that in addition to this, the following inequality is valid for
all z ∈K.
|S (P) −Sh (P)| < ε
3
This is possible because of 23.11 and the uniform continuity of f on H × K. It
follows
¯¯¯¯¯
¯¯¯¯¯
Z
γ
f (·, z) dγ (t) −
Z
γh
f (·, z) dγh (t)
¯¯¯¯¯
¯¯¯¯¯ ≤
¯¯¯¯
¯¯¯¯
Z
γ
f (·, z) dγ (t) −S (P)
¯¯¯¯
¯¯¯¯ + ||S (P) −Sh (P)||
+
¯¯¯¯¯
¯¯¯¯¯Sh (P) −
Z
γh
f (·, z) dγh (t)
¯¯¯¯¯
¯¯¯¯¯ < ε.

636
RIEMANN STIELTJES INTEGRALS
Formula 23.10 follows from the lemma. This proves the theorem.
Of course the same result is obtained without the explicit dependence of f on z.
This is a very useful theorem because if γ is C1 ([a, b]) , it is easy to calculate
R
γ fdγ and the above theorem allows a reduction to the case where γ is C1. The
next theorem shows how easy it is to compute these integrals in the case where γ is
C1. First note that if f is continuous and γ ∈C1 ([a, b]) , then by Lemma 23.6 and
the fundamental existence theorem, Theorem 23.4,
R
γ fdγ exists.
Theorem 23.9 If f : γ∗→X is continuous and γ : [a, b] →C is in C1 ([a, b]) ,
then
Z
γ
fdγ =
Z b
a
f (γ (t)) γ′ (t) dt.
(23.12)
Proof: Let P be a partition of [a, b], P = {t0, · · ·, tn} and ||P|| is small enough
that whenever |t −s| < ||P|| ,
|f (γ (t)) −f (γ (s))| < ε
(23.13)
and
¯¯¯¯¯¯
¯¯¯¯¯¯
Z
γ
fdγ −
n
X
j=1
f (γ (τ j)) (γ (tj) −γ (tj−1))
¯¯¯¯¯¯
¯¯¯¯¯¯
< ε.
Now
n
X
j=1
f (γ (τ j)) (γ (tj) −γ (tj−1)) =
Z b
a
n
X
j=1
f (γ (τ j)) X[tj−1,tj] (s) γ′ (s) ds
where here
X[a,b] (s) ≡
½
1 if s ∈[a, b]
0 if s /∈[a, b] .
Also,
Z b
a
f (γ (s)) γ′ (s) ds =
Z b
a
n
X
j=1
f (γ (s)) X[tj−1,tj] (s) γ′ (s) ds
and thanks to 23.13,
¯¯¯¯¯¯¯¯¯¯¯
¯¯¯¯¯¯¯¯¯¯¯
=Pn
j=1 f(γ(τ j))(γ(tj)−γ(tj−1))
z
}|
{
Z b
a
n
X
j=1
f (γ (τ j)) X[tj−1,tj] (s) γ′ (s) ds −
=
R b
a f(γ(s))γ′(s)ds
z
}|
{
Z b
a
n
X
j=1
f (γ (s)) X[tj−1,tj] (s) γ′ (s) ds
¯¯¯¯¯¯¯¯¯¯¯
¯¯¯¯¯¯¯¯¯¯¯
≤
n
X
j=1
Z tj
tj−1
||f (γ (τ j)) −f (γ (s))|| |γ′ (s)| ds ≤||γ′||∞
X
j
ε (tj −tj−1)
=
ε ||γ′||∞(b −a) .

637
It follows that
¯¯¯¯¯
¯¯¯¯¯
Z
γ
fdγ −
Z b
a
f (γ (s)) γ′ (s) ds
¯¯¯¯¯
¯¯¯¯¯ ≤
¯¯¯¯¯¯
¯¯¯¯¯¯
Z
γ
fdγ −
n
X
j=1
f (γ (τ j)) (γ (tj) −γ (tj−1))
¯¯¯¯¯¯
¯¯¯¯¯¯
+
¯¯¯¯¯¯
¯¯¯¯¯¯
n
X
j=1
f (γ (τ j)) (γ (tj) −γ (tj−1)) −
Z b
a
f (γ (s)) γ′ (s) ds
¯¯¯¯¯¯
¯¯¯¯¯¯
≤ε ||γ′||∞(b −a) + ε.
Since ε is arbitrary, this veriﬁes 23.12.
Deﬁnition 23.10 Let Ωbe an open subset of C and let γ : [a, b] →Ωbe a contin-
uous function with bounded variation f : Ω→X be a continuous function. Then
the following notation is more customary.
Z
γ
f (z) dz ≡
Z
γ
fdγ.
The expression,
R
γ f (z) dz, is called a contour integral and γ is referred to as the
contour. A function f : Ω→X for Ωan open set in C has a primitive if there
exists a function, F, the primitive, such that F ′ (z) = f (z) . Thus F is just an
antiderivative. Also if γk : [ak, bk] →C is continuous and of bounded variation, for
k = 1, · · ·, m and γk (bk) = γk+1 (ak) , deﬁne
Z
Pm
k=1 γk
f (z) dz ≡
m
X
k=1
Z
γk
f (z) dz.
(23.14)
In addition to this, for γ : [a, b] →C, deﬁne −γ : [a, b] →C by −γ (t) ≡
γ (b + a −t) . Thus γ simply traces out the points of γ∗in the opposite order.
The following lemma is useful and follows quickly from Theorem 23.3.
Lemma 23.11 In the above deﬁnition, there exists a continuous bounded vari-
ation function, γ deﬁned on some closed interval, [c, d] , such that γ ([c, d]) =
∪m
k=1γk ([ak, bk]) and γ (c) = γ1 (a1) while γ (d) = γm (bm) . Furthermore,
Z
γ
f (z) dz =
m
X
k=1
Z
γk
f (z) dz.
If γ : [a, b] →C is of bounded variation and continuous, then
Z
γ
f (z) dz = −
Z
−γ
f (z) dz.
Re stating Theorem 23.7 with the new notation in the above deﬁnition,

638
RIEMANN STIELTJES INTEGRALS
Theorem 23.12 Let K be a compact set in C and let f : Ω×K →X be continuous
for Ωan open set in C. Also let γ : [a, b] →Ωbe continuous with bounded variation.
Then if r > 0 is given, there exists η : [a, b] →Ωsuch that η (a) = γ (a) , η (b) =
γ (b) , η is C1 ([a, b]) , and
¯¯¯¯
Z
γ
f (z, w) dz −
Z
η
f (z, w) dz
¯¯¯¯ < r, ||η −γ|| < r.
It will be very important to consider which functions have primitives. It turns
out, it is not enough for f to be continuous in order to possess a primitive. This is
in stark contrast to the situation for functions of a real variable in which the funda-
mental theorem of calculus will deliver a primitive for any continuous function. The
reason for the interest in such functions is the following theorem and its corollary.
Theorem 23.13 Let γ : [a, b] →C be continuous and of bounded variation. Also
suppose F ′ (z) = f (z) for all z ∈Ω, an open set containing γ∗and f is continuous
on Ω. Then
Z
γ
f (z) dz = F (γ (b)) −F (γ (a)) .
Proof: By Theorem 23.12 there exists η ∈C1 ([a, b]) such that γ (a) = η (a) ,
and γ (b) = η (b) such that
¯¯¯¯
¯¯¯¯
Z
γ
f (z) dz −
Z
η
f (z) dz
¯¯¯¯
¯¯¯¯ < ε.
Then since η is in C1 ([a, b]) ,
Z
η
f (z) dz
=
Z b
a
f (η (t)) η′ (t) dt =
Z b
a
dF (η (t))
dt
dt
=
F (η (b)) −F (η (a)) = F (γ (b)) −F (γ (a)) .
Therefore,
¯¯¯¯
¯¯¯¯(F (γ (b)) −F (γ (a))) −
Z
γ
f (z) dz
¯¯¯¯
¯¯¯¯ < ε
and since ε > 0 is arbitrary, this proves the theorem.
Corollary 23.14 If γ : [a, b] →C is continuous, has bounded variation, is a closed
curve, γ (a) = γ (b) , and γ∗⊆Ωwhere Ωis an open set on which F ′ (z) = f (z) ,
then
Z
γ
f (z) dz = 0.

23.1.
EXERCISES
639
23.1
Exercises
1. Let γ : [a, b] →R be increasing. Show V (γ, [a, b]) = γ (b) −γ (a) .
2. Suppose γ : [a, b] →C satisﬁes a Lipschitz condition, |γ (t) −γ (s)| ≤K |s −t| .
Show γ is of bounded variation and that V (γ, [a, b]) ≤K |b −a| .
3. γ : [c0, cm] →C is piecewise smooth if there exist numbers, ck, k = 1, · ·
·, m such that c0 < c1 < · · · < cm−1 < cm such that γ is continuous and
γ : [ck, ck+1] →C is C1. Show that such piecewise smooth functions are of
bounded variation and give an estimate for V (γ, [c0, cm]) .
4. Let γ : [0, 2π] →C be given by γ (t) = r (cos mt + i sin mt) for m an integer.
Find
R
γ
dz
z .
5. Show that if γ : [a, b] →C then there exists an increasing function h : [0, 1] →
[a, b] such that γ ◦h ([0, 1]) = γ∗.
6. Let γ : [a, b] →C be an arbitrary continuous curve having bounded variation
and let f, g have continuous derivatives on some open set containing γ∗. Prove
the usual integration by parts formula.
Z
γ
fg′dz = f (γ (b)) g (γ (b)) −f (γ (a)) g (γ (a)) −
Z
γ
f ′gdz.
7. Let f (z) ≡|z|−(1/2) e−i θ
2 where z = |z| eiθ. This function is called the principle
branch of z−(1/2). Find
R
γ f (z) dz where γ is the semicircle in the upper half
plane which goes from (1, 0) to (−1, 0) in the counter clockwise direction. Next
do the integral in which γ goes in the clockwise direction along the semicircle
in the lower half plane.
8. Prove an open set, U is connected if and only if for every two points in U,
there exists a C1 curve having values in U which joins them.
9. Let P, Q be two partitions of [a, b] with P ⊆Q. Each of these partitions can
be used to form an approximation to V (γ, [a, b]) as described above. Recall
the total variation was the supremum of sums of a certain form determined by
a partition. How is the sum associated with P related to the sum associated
with Q? Explain.
10. Consider the curve,
γ (t) =
½
t + it2 sin
¡ 1
t
¢
if t ∈(0, 1]
0 if t = 0
.
Is γ a continuous curve having bounded variation? What if the t2 is replaced
with t? Is the resulting curve continuous? Is it a bounded variation curve?
11. Suppose γ : [a, b] →R is given by γ (t) = t. What is
R
γ f (t) dγ? Explain.

640
RIEMANN STIELTJES INTEGRALS

Fundamentals Of Complex
Analysis
24.1
Analytic Functions
Deﬁnition 24.1 Let Ωbe an open set in C and let f : Ω→X. Then f is analytic
on Ωif for every z ∈Ω,
lim
h→0
f (z + h) −f (z)
h
≡f ′ (z)
exists and is a continuous function of z ∈Ω. Here h ∈C.
Note that if f is analytic, it must be the case that f is continuous. It is more
common to not include the requirement that f ′ is continuous but it is shown later
that the continuity of f ′ follows.
What are some examples of analytic functions? In the case where X = C, the
simplest example is any polynomial. Thus
p (z) ≡
n
X
k=0
akzk
is an analytic function and
p′ (z) =
n
X
k=1
akkzk−1.
More generally, power series are analytic. This will be shown soon but ﬁrst here is
an important deﬁnition and a convergence theorem called the root test.
Deﬁnition 24.2 Let {ak} be a sequence in X. Then P∞
k=1 ak ≡limn→∞
Pn
k=1 ak
whenever this limit exists. When the limit exists, the series is said to converge.
641

642
FUNDAMENTALS OF COMPLEX ANALYSIS
Theorem 24.3 Consider P∞
k=1 ak and let ρ ≡lim supk→∞||ak||1/k . Then if ρ < 1,
the series converges absolutely and if ρ > 1 the series diverges spectacularly in the
sense that limk→∞ak ̸= 0. If ρ = 1 the test fails. Also P∞
k=1 ak (z −a)k converges
on some disk B (a, R) . It converges absolutely if |z −a| < R and uniformly on
B (a, r1) whenever r1 < R. The function f (z) = P∞
k=1 ak (z −a)k is continuous on
B (a, R) .
Proof: Suppose ρ < 1. Then there exists r ∈(ρ, 1) . Therefore, ||ak|| ≤rk for
all k large enough and so by a comparison test, P
k ||ak|| converges because the
partial sums are bounded above. Therefore, the partial sums of the original series
form a Cauchy sequence in X and so they also converge due to completeness of X.
Now suppose ρ > 1. Then letting ρ > r > 1, it follows ||ak||1/k ≥r inﬁnitely
often. Thus ||ak|| ≥rk inﬁnitely often. Thus there exists a subsequence for which
||ank|| converges to ∞. Therefore, the series cannot converge.
Now consider P∞
k=1 ak (z −a)k. This series converges absolutely if
lim sup
k→∞
||ak||1/k |z −a| < 1
which is the same as saying |z −a| < 1/ρ where ρ ≡lim supk→∞||ak||1/k. Let
R = 1/ρ.
Now suppose r1 < R. Consider |z −a| ≤r1. Then for such z,
||ak|| |z −a|k ≤||ak|| rk
1
and
lim sup
k→∞
¡
||ak|| rk
1
¢1/k = lim sup
k→∞
||ak||1/k r1 = r1
R < 1
so P
k ||ak|| rk
1 converges. By the Weierstrass M test, P∞
k=1 ak (z −a)k converges
uniformly for |z −a| ≤r1. Therefore, f is continuous on B (a, R) as claimed because
it is the uniform limit of continuous functions, the partial sums of the inﬁnite series.
What if ρ = 0? In this case,
lim sup
k→∞
||ak||1/k |z −a| = 0 · |z −a| = 0
and so R = ∞and the series, P ||ak|| |z −a|k converges everywhere.
What if ρ = ∞? Then in this case, the series converges only at z = a because if
z ̸= a,
lim sup
k→∞
||ak||1/k |z −a| = ∞.
Theorem 24.4 Let f (z) ≡P∞
k=1 ak (z −a)k be given in Theorem 24.3 where R >
0. Then f is analytic on B (a, R) . So are all its derivatives.

24.1.
ANALYTIC FUNCTIONS
643
Proof: Consider g (z) = P∞
k=2 akk (z −a)k−1 on B (a, R) where R = ρ−1 as
above. Let r1 < r < R. Then letting |z −a| < r1 and h < r −r1,
¯¯¯¯
¯¯¯¯
f (z + h) −f (z)
h
−g (z)
¯¯¯¯
¯¯¯¯
≤
∞
X
k=2
||ak||
¯¯¯¯¯
(z + h −a)k −(z −a)k
h
−k (z −a)k−1
¯¯¯¯¯
≤
∞
X
k=2
||ak||
¯¯¯¯¯
1
h
Ã k
X
i=0
µk
i
¶
(z −a)k−i hi −(z −a)k
!
−k (z −a)k−1
¯¯¯¯¯
=
∞
X
k=2
||ak||
¯¯¯¯¯
1
h
Ã k
X
i=1
µk
i
¶
(z −a)k−i hi
!
−k (z −a)k−1
¯¯¯¯¯
≤
∞
X
k=2
||ak||
¯¯¯¯¯
Ã k
X
i=2
µk
i
¶
(z −a)k−i hi−1
!¯¯¯¯¯
≤
|h|
∞
X
k=2
||ak||
Ãk−2
X
i=0
µ k
i + 2
¶
|z −a|k−2−i |h|i
!
=
|h|
∞
X
k=2
||ak||
Ãk−2
X
i=0
µk −2
i
¶
k (k −1)
(i + 2) (i + 1) |z −a|k−2−i |h|i
!
≤
|h|
∞
X
k=2
||ak|| k (k −1)
2
Ãk−2
X
i=0
µk −2
i
¶
|z −a|k−2−i |h|i
!
=
|h|
∞
X
k=2
||ak|| k (k −1)
2
(|z −a| + |h|)k−2 < |h|
∞
X
k=2
||ak|| k (k −1)
2
rk−2.
Then
lim sup
k→∞
µ
||ak|| k (k −1)
2
rk−2
¶1/k
= ρr < 1
and so
¯¯¯¯
¯¯¯¯
f (z + h) −f (z)
h
−g (z)
¯¯¯¯
¯¯¯¯ ≤C |h| .
therefore, g (z) = f ′ (z) . Now by Theorem 24.3 it also follows that f ′ is continuous.
Since r1 < R was arbitrary, this shows that f ′ (z) is given by the diﬀerentiated
series above for |z −a| < R. Now a repeat of the argument shows all the derivatives
of f exist and are continuous on B (a, R).
24.1.1
Cauchy Riemann Equations
Next consider the very important Cauchy Riemann equations which give conditions
under which complex valued functions of a complex variable are analytic.

644
FUNDAMENTALS OF COMPLEX ANALYSIS
Theorem 24.5 Let Ωbe an open subset of C and let f : Ω→C be a function,
such that for z = x + iy ∈Ω,
f (z) = u (x, y) + iv (x, y) .
Then f is analytic if and only if u, v are C1 (Ω) and
∂u
∂x = ∂v
∂y , ∂u
∂y = −∂v
∂x.
Furthermore,
f ′ (z) = ∂u
∂x (x, y) + i∂v
∂x (x, y) .
Proof: Suppose f is analytic ﬁrst. Then letting t ∈R,
f ′ (z) = lim
t→0
f (z + t) −f (z)
t
=
lim
t→0
µu (x + t, y) + iv (x + t, y)
t
−u (x, y) + iv (x, y)
t
¶
= ∂u (x, y)
∂x
+ i∂v (x, y)
∂x
.
But also
f ′ (z) = lim
t→0
f (z + it) −f (z)
it
=
lim
t→0
µu (x, y + t) + iv (x, y + t)
it
−u (x, y) + iv (x, y)
it
¶
1
i
µ∂u (x, y)
∂y
+ i∂v (x, y)
∂y
¶
= ∂v (x, y)
∂y
−i∂u (x, y)
∂y
.
This veriﬁes the Cauchy Riemann equations. We are assuming that z →f ′ (z) is
continuous. Therefore, the partial derivatives of u and v are also continuous. To see
this, note that from the formulas for f ′ (z) given above, and letting z1 = x1 + iy1
¯¯¯¯
∂v (x, y)
∂y
−∂v (x1, y1)
∂y
¯¯¯¯ ≤|f ′ (z) −f ′ (z1)| ,
showing that (x, y) →∂v(x,y)
∂y
is continuous since (x1, y1) →(x, y) if and only if
z1 →z. The other cases are similar.
Now suppose the Cauchy Riemann equations hold and the functions, u and v
are C1 (Ω) . Then letting h = h1 + ih2,
f (z + h) −f (z) = u (x + h1, y + h2)

24.1.
ANALYTIC FUNCTIONS
645
+iv (x + h1, y + h2) −(u (x, y) + iv (x, y))
We know u and v are both diﬀerentiable and so
f (z + h) −f (z) = ∂u
∂x (x, y) h1 + ∂u
∂y (x, y) h2+
i
µ∂v
∂x (x, y) h1 + ∂v
∂y (x, y) h2
¶
+ o (h) .
Dividing by h and using the Cauchy Riemann equations,
f (z + h) −f (z)
h
=
∂u
∂x (x, y) h1 + i ∂v
∂y (x, y) h2
h
+
i ∂v
∂x (x, y) h1 + ∂u
∂y (x, y) h2
h
+ o (h)
h
= ∂u
∂x (x, y) h1 + ih2
h
+ i∂v
∂x (x, y) h1 + ih2
h
+ o (h)
h
Taking the limit as h →0,
f ′ (z) = ∂u
∂x (x, y) + i∂v
∂x (x, y) .
It follows from this formula and the assumption that u, v are C1 (Ω) that f ′ is
continuous.
It is routine to verify that all the usual rules of derivatives hold for analytic
functions. In particular, the product rule, the chain rule, and quotient rule.
24.1.2
An Important Example
An important example of an analytic function is ez ≡exp (z) ≡ex (cos y + i sin y)
where z = x + iy. You can verify that this function satisﬁes the Cauchy Riemann
equations and that all the partial derivatives are continuous. Also from the above
discussion, (ez)′ = ex cos (y) + iex sin y = ez. Later I will show that ez is given by
the usual power series. An important property of this function is that it can be
used to parameterize the circle centered at z0 having radius r.
Lemma 24.6 Let γ denote the closed curve which is a circle of radius r centered
at z0. Then a parameterization this curve is γ (t) = z0 + reit where t ∈[0, 2π] .
Proof: |γ (t) −z0|2 =
¯¯reitre−it¯¯ = r2. Also, you can see from the deﬁnition of
the sine and cosine that the point described in this way moves counter clockwise
over this circle.

646
FUNDAMENTALS OF COMPLEX ANALYSIS
24.2
Exercises
1. Verify all the usual rules of diﬀerentiation including the product and chain
rules.
2. Suppose f and f ′ : U →C are analytic and f (z) = u (x, y) + iv (x, y) .
Verify uxx + uyy = 0 and vxx + vyy = 0. This partial diﬀerential equation
satisﬁed by the real and imaginary parts of an analytic function is called
Laplace’s equation. We say these functions satisfying Laplace’s equation are
harmonic functions. If u is a harmonic function deﬁned on B (0, r) show that
v (x, y) ≡
R y
0 ux (x, t) dt −
R x
0 uy (t, 0) dt is such that u + iv is analytic.
3. Let f : U →C be analytic and f (z) = u (x, y) + iv (x, y) . Show u, v and uv
are all harmonic although it can happen that u2 is not. Recall that a function,
w is harmonic if wxx + wyy = 0.
4. Deﬁne a function f (z) ≡z ≡x −iy where z = x + iy. Is f analytic?
5. If f (z) = u (x, y) + iv (x, y) and f is analytic, verify that
det
µ
ux
uy
vx
vy
¶
= |f ′ (z)|2 .
6. Show that if u (x, y) + iv (x, y) = f (z) is analytic, then ∇u · ∇v = 0. Recall
∇u (x, y) = ⟨ux (x, y) , uy (x, y)⟩.
7. Show that every polynomial is analytic.
8. If γ (t) = x (t)+iy (t) is a C1 curve having values in U, an open set of C, and if
f : U →C is analytic, we can consider f ◦γ, another C1 curve having values in
C. Also, γ′ (t) and (f ◦γ)′ (t) are complex numbers so these can be considered
as vectors in R2 as follows. The complex number, x + iy corresponds to the
vector, ⟨x, y⟩. Suppose that γ and η are two such C1 curves having values in
U and that γ (t0) = η (s0) = z and suppose that f : U →C is analytic. Show
that the angle between (f ◦γ)′ (t0) and (f ◦η)′ (s0) is the same as the angle
between γ′ (t0) and η′ (s0) assuming that f ′ (z) ̸= 0. Thus analytic mappings
preserve angles at points where the derivative is nonzero.
Such mappings
are called isogonal. . Hint: To make this easy to show, ﬁrst observe that
⟨x, y⟩· ⟨a, b⟩= 1
2 (zw + zw) where z = x + iy and w = a + ib.
9. Analytic functions are even better than what is described in Problem 8. In
addition to preserving angles, they also preserve orientation. To verify this
show that if z = x + iy and w = a + ib are two complex numbers, then
⟨x, y, 0⟩and ⟨a, b, 0⟩are two vectors in R3. Recall that the cross product,
⟨x, y, 0⟩× ⟨a, b, 0⟩, yields a vector normal to the two given vectors such that
the triple, ⟨x, y, 0⟩, ⟨a, b, 0⟩, and ⟨x, y, 0⟩× ⟨a, b, 0⟩satisﬁes the right hand rule

24.3.
CAUCHY’S FORMULA FOR A DISK
647
and has magnitude equal to the product of the sine of the included angle
times the product of the two norms of the vectors. In this case, the cross
product either points in the direction of the positive z axis or in the direction
of the negative z axis. Thus, either the vectors ⟨x, y, 0⟩, ⟨a, b, 0⟩, k form a right
handed system or the vectors ⟨a, b, 0⟩, ⟨x, y, 0⟩, k form a right handed system.
These are the two possible orientations. Show that in the situation of Problem
8 the orientation of γ′ (t0) , η′ (s0) , k is the same as the orientation of the
vectors (f ◦γ)′ (t0) , (f ◦η)′ (s0) , k. Such mappings are called conformal. If f
is analytic and f ′ (z) ̸= 0, then we know from this problem and the above that
f is a conformal map. Hint: You can do this by verifying that (f ◦γ)′ (t0) ×
(f ◦η)′ (s0) = |f ′ (γ (t0))|2 γ′ (t0) × η′ (s0). To make the veriﬁcation easier,
you might ﬁrst establish the following simple formula for the cross product
where here x + iy = z and a + ib = w.
(x, y, 0) × (a, b, 0) = Re (ziw) k.
10. Write the Cauchy Riemann equations in terms of polar coordinates. Recall
the polar coordinates are given by
x = r cos θ, y = r sin θ.
This means, letting u (x, y) = u (r, θ) , v (x, y) = v (r, θ) , write the Cauchy Rie-
mann equations in terms of r and θ. You should eventually show the Cauchy
Riemann equations are equivalent to
∂u
∂r = 1
r
∂v
∂θ ,
∂v
∂r = −1
r
∂u
∂θ
11. Show that a real valued analytic function must be constant.
24.3
Cauchy’s Formula For A Disk
The Cauchy integral formula is the most important theorem in complex analysis.
It will be established for a disk in this chapter and later will be generalized to
much more general situations but the version given here will suﬃce to prove many
interesting theorems needed in the later development of the theory. The following
are some advanced calculus results.
Lemma 24.7 Let f : [a, b] →C. Then f ′ (t) exists if and only if Re f ′ (t) and
Im f ′ (t) exist. Furthermore,
f ′ (t) = Re f ′ (t) + i Im f ′ (t) .
Proof: The if part of the equivalence is obvious.
Now suppose f ′ (t) exists. Let both t and t + h be contained in [a, b]
¯¯¯¯
Re f (t + h) −Re f (t)
h
−Re (f ′ (t))
¯¯¯¯ ≤
¯¯¯¯
f (t + h) −f (t)
h
−f ′ (t)
¯¯¯¯

648
FUNDAMENTALS OF COMPLEX ANALYSIS
and this converges to zero as h →0. Therefore, Re f ′ (t) = Re (f ′ (t)) . Similarly,
Im f ′ (t) = Im (f ′ (t)) .
Lemma 24.8 If g : [a, b] →C and g is continuous on [a, b] and diﬀerentiable on
(a, b) with g′ (t) = 0, then g (t) is a constant.
Proof: From the above lemma, you can apply the mean value theorem to the
real and imaginary parts of g.
Applying the above lemma to the components yields the following lemma.
Lemma 24.9 If g : [a, b] →Cn = X and g is continuous on [a, b] and diﬀerentiable
on (a, b) with g′ (t) = 0, then g (t) is a constant.
If you want to have X be a complex Banach space, the result is still true.
Lemma 24.10 If g : [a, b] →X and g is continuous on [a, b] and diﬀerentiable on
(a, b) with g′ (t) = 0, then g (t) is a constant.
Proof: Let Λ ∈X′. Then Λg : [a, b] →C . Therefore, from Lemma 24.8, for each
Λ ∈X′, Λg (s) = Λg (t) and since X′ separates the points, it follows g (s) = g (t) so
g is constant.
Lemma 24.11 Let φ : [a, b] × [c, d] →R be continuous and let
g (t) ≡
Z b
a
φ (s, t) ds.
(24.1)
Then g is continuous. If ∂φ
∂t exists and is continuous on [a, b] × [c, d] , then
g′ (t) =
Z b
a
∂φ (s, t)
∂t
ds.
(24.2)
Proof: The ﬁrst claim follows from the uniform continuity of φ on [a, b]×[c, d] ,
which uniform continuity results from the set being compact. To establish 24.2, let
t and t + h be contained in [c, d] and form, using the mean value theorem,
g (t + h) −g (t)
h
=
1
h
Z b
a
[φ (s, t + h) −φ (s, t)] ds
=
1
h
Z b
a
∂φ (s, t + θh)
∂t
hds
=
Z b
a
∂φ (s, t + θh)
∂t
ds,
where θ may depend on s but is some number between 0 and 1. Then by the uniform
continuity of ∂φ
∂t , it follows that 24.2 holds.

24.3.
CAUCHY’S FORMULA FOR A DISK
649
Corollary 24.12 Let φ : [a, b] × [c, d] →C be continuous and let
g (t) ≡
Z b
a
φ (s, t) ds.
(24.3)
Then g is continuous. If ∂φ
∂t exists and is continuous on [a, b] × [c, d] , then
g′ (t) =
Z b
a
∂φ (s, t)
∂t
ds.
(24.4)
Proof: Apply Lemma 24.11 to the real and imaginary parts of φ.
Applying the above corollary to the components, you can also have the same
result for φ having values in Cn.
Corollary 24.13 Let φ : [a, b] × [c, d] →Cn be continuous and let
g (t) ≡
Z b
a
φ (s, t) ds.
(24.5)
Then g is continuous. If ∂φ
∂t exists and is continuous on [a, b] × [c, d] , then
g′ (t) =
Z b
a
∂φ (s, t)
∂t
ds.
(24.6)
If you want to consider φ having values in X, a complex Banach space a similar
result holds.
Corollary 24.14 Let φ : [a, b] × [c, d] →X be continuous and let
g (t) ≡
Z b
a
φ (s, t) ds.
(24.7)
Then g is continuous. If ∂φ
∂t exists and is continuous on [a, b] × [c, d] , then
g′ (t) =
Z b
a
∂φ (s, t)
∂t
ds.
(24.8)
Proof: Let Λ ∈X′. Then Λφ : [a, b] × [c, d] →C is continuous and ∂Λφ
∂t
exists
and is continuous on [a, b] × [c, d] . Therefore, from 24.8,
Λ (g′ (t)) = (Λg)′ (t) =
Z b
a
∂Λφ (s, t)
∂t
ds = Λ
Z b
a
∂φ (s, t)
∂t
ds
and since X′ separates the points, it follows 24.8 holds.
The following is Cauchy’s integral formula for a disk.

650
FUNDAMENTALS OF COMPLEX ANALYSIS
Theorem 24.15 Let f : Ω→X be analytic on the open set, Ωand let
B (z0, r) ⊆Ω.
Let γ (t) ≡z0 + reit for t ∈[0, 2π] . Then if z ∈B (z0, r) ,
f (z) =
1
2πi
Z
γ
f (w)
w −z dw.
(24.9)
Proof: Consider for α ∈[0, 1] ,
g (α) ≡
Z 2π
0
f
¡
z + α
¡
z0 + reit −z
¢¢
reit + z0 −z
rieitdt.
If α equals one, this reduces to the integral in 24.9. The idea is to show g is a
constant and that g (0) = f (z) 2πi. First consider the claim about g (0) .
g (0)
=
µZ 2π
0
reit
reit + z0 −z dt
¶
if (z)
=
if (z)
µZ 2π
0
1
1 −z−z0
reit
dt
¶
=
if (z)
Z 2π
0
∞
X
n=0
r−ne−int (z −z0)n dt
because
¯¯ z−z0
reit
¯¯ < 1. Since this sum converges uniformly you can interchange the
sum and the integral to obtain
g (0)
=
if (z)
∞
X
n=0
r−n (z −z0)n
Z 2π
0
e−intdt
=
2πif (z)
because
R 2π
0
e−intdt = 0 if n > 0.
Next consider the claim that g is constant. By Corollary 24.13, for α ∈(0, 1) ,
g′ (α)
=
Z 2π
0
f ′ ¡
z + α
¡
z0 + reit −z
¢¢ ¡
reit + z0 −z
¢
reit + z0 −z
rieitdt
=
Z 2π
0
f ′ ¡
z + α
¡
z0 + reit −z
¢¢
rieitdt
=
Z 2π
0
d
dt
µ
f
¡
z + α
¡
z0 + reit −z
¢¢ 1
α
¶
dt
=
f
¡
z + α
¡
z0 + rei2π −z
¢¢ 1
α −f
¡
z + α
¡
z0 + re0 −z
¢¢ 1
α = 0.
Now g is continuous on [0, 1] and g′ (t) = 0 on (0, 1) so by Lemma 24.9, g equals a
constant. This constant can only be g (0) = 2πif (z) . Thus,
g (1) =
Z
γ
f (w)
w −z dw = g (0) = 2πif (z) .

24.3.
CAUCHY’S FORMULA FOR A DISK
651
This proves the theorem.
This is a very signiﬁcant theorem. A few applications are given next.
Theorem 24.16 Let f : Ω→X be analytic where Ωis an open set in C. Then f
has inﬁnitely many derivatives on Ω. Furthermore, for all z ∈B (z0, r) ,
f (n) (z) = n!
2πi
Z
γ
f (w)
(w −z)n+1 dw
(24.10)
where γ (t) ≡z0 + reit, t ∈[0, 2π] for r small enough that B (z0, r) ⊆Ω.
Proof:
Let z ∈B (z0, r) ⊆Ωand let B (z0, r) ⊆Ω. Then, letting γ (t) ≡
z0 + reit, t ∈[0, 2π] , and h small enough,
f (z) =
1
2πi
Z
γ
f (w)
w −z dw, f (z + h) =
1
2πi
Z
γ
f (w)
w −z −hdw
Now
1
w −z −h −
1
w −z =
h
(−w + z + h) (−w + z)
and so
f (z + h) −f (z)
h
=
1
2πhi
Z
γ
hf (w)
(−w + z + h) (−w + z)dw
=
1
2πi
Z
γ
f (w)
(−w + z + h) (−w + z)dw.
Now for all h suﬃciently small, there exists a constant C independent of such h
such that
¯¯¯¯
1
(−w + z + h) (−w + z) −
1
(−w + z) (−w + z)
¯¯¯¯
=
¯¯¯¯¯
h
(w −z −h) (w −z)2
¯¯¯¯¯ ≤C |h|
and so, the integrand converges uniformly as h →0 to
=
f (w)
(w −z)2
Therefore, the limit as h →0 may be taken inside the integral to obtain
f ′ (z) =
1
2πi
Z
γ
f (w)
(w −z)2 dw.
Continuing in this way, yields 24.10.
This is a very remarkable result. It shows the existence of one continuous deriva-
tive implies the existence of all derivatives, in contrast to the theory of functions of
a real variable. Actually, more than what is stated in the theorem was shown. The
above proof establishes the following corollary.

652
FUNDAMENTALS OF COMPLEX ANALYSIS
Corollary 24.17 Suppose f is continuous on ∂B (z0, r) and suppose that for all
z ∈B (z0, r) ,
f (z) =
1
2πi
Z
γ
f (w)
w −z dw,
where γ (t) ≡z0 + reit, t ∈[0, 2π] . Then f is analytic on B (z0, r) and in fact has
inﬁnitely many derivatives on B (z0, r) .
Another application is the following lemma.
Lemma 24.18 Let γ (t) = z0 + reit, for t ∈[0, 2π], suppose fn →f uniformly on
B (z0, r), and suppose
fn (z) =
1
2πi
Z
γ
fn (w)
w −z dw
(24.11)
for z ∈B (z0, r) . Then
f (z) =
1
2πi
Z
γ
f (w)
w −z dw,
(24.12)
implying that f is analytic on B (z0, r) .
Proof: From 24.11 and the uniform convergence of fn to f on γ ([0, 2π]) , the
integrals in 24.11 converge to
1
2πi
Z
γ
f (w)
w −z dw.
Therefore, the formula 24.12 follows.
Uniform convergence on a closed disk of the analytic functions implies the target
function is also analytic. This is amazing. Think of the Weierstrass approximation
theorem for polynomials. You can obtain a continuous nowhere diﬀerentiable func-
tion as the uniform limit of polynomials.
The conclusions of the following proposition have all been obtained earlier in
Theorem 24.4 but they can be obtained more easily if you use the above theorem
and lemmas.
Proposition 24.19 Let {an} denote a sequence in X. Then there exists R ∈[0, ∞]
such that
∞
X
k=0
ak (z −z0)k
converges absolutely if |z −z0| < R, diverges if |z −z0| > R and converges uniformly
on B (z0, r) for all r < R. Furthermore, if R > 0, the function,
f (z) ≡
∞
X
k=0
ak (z −z0)k
is analytic on B (z0, R) .

24.3.
CAUCHY’S FORMULA FOR A DISK
653
Proof: The assertions about absolute convergence are routine from the root test
if
R ≡
µ
lim sup
n→∞|an|1/n
¶−1
with R = ∞if the quantity in parenthesis equals zero. The root test can be used
to verify absolute convergence which then implies convergence by completeness of
X.
The assertion about uniform convergence follows from the Weierstrass M test
and Mn ≡|an| rn. ( P∞
n=0 |an| rn < ∞by the root test). It only remains to verify
the assertion about f (z) being analytic in the case where R > 0.
Let 0 < r < R and deﬁne fn (z) ≡Pn
k=0 ak (z −z0)k . Then fn is a polynomial
and so it is analytic. Thus, by the Cauchy integral formula above,
fn (z) =
1
2πi
Z
γ
fn (w)
w −z dw
where γ (t) = z0 + reit, for t ∈[0, 2π] . By Lemma 24.18 and the ﬁrst part of this
proposition involving uniform convergence,
f (z) =
1
2πi
Z
γ
f (w)
w −z dw.
Therefore, f is analytic on B (z0, r) by Corollary 24.17. Since r < R is arbitrary,
this shows f is analytic on B (z0, R) .
This proposition shows that all functions having values in X which are given as
power series are analytic on their circle of convergence, the set of complex numbers,
z, such that |z −z0| < R. In fact, every analytic function can be realized as a power
series.
Theorem 24.20 If f : Ω→X is analytic and if B (z0, r) ⊆Ω, then
f (z) =
∞
X
n=0
an (z −z0)n
(24.13)
for all |z −z0| < r. Furthermore,
an = f (n) (z0)
n!
.
(24.14)
Proof: Consider |z −z0| < r and let γ (t) = z0 + reit, t ∈[0, 2π] . Then for
w ∈γ ([0, 2π]) ,
¯¯¯¯
z −z0
w −z0
¯¯¯¯ < 1

654
FUNDAMENTALS OF COMPLEX ANALYSIS
and so, by the Cauchy integral formula,
f (z)
=
1
2πi
Z
γ
f (w)
w −z dw
=
1
2πi
Z
γ
f (w)
(w −z0)
³
1 −z−z0
w−z0
´dw
=
1
2πi
Z
γ
f (w)
(w −z0)
∞
X
n=0
µ z −z0
w −z0
¶n
dw.
Since the series converges uniformly, you can interchange the integral and the sum
to obtain
f (z)
=
∞
X
n=0
Ã
1
2πi
Z
γ
f (w)
(w −z0)n+1
!
(z −z0)n
≡
∞
X
n=0
an (z −z0)n
By Theorem 24.16, 24.14 holds.
Note that this also implies that if a function is analytic on an open set, then all
of its derivatives are also analytic. This follows from Theorem 24.4 which says that
a function given by a power series has all derivatives on the disk of convergence.
24.4
Exercises
1. Show that if |ek| ≤ε, then
¯¯P∞
k=m ek
¡
rk −rk+1¢¯¯ < ε if 0 ≤r < 1. Hint:
Let |θ| = 1 and verify that
θ
∞
X
k=m
ek
¡
rk −rk+1¢
=
¯¯¯¯¯
∞
X
k=m
ek
¡
rk −rk+1¢
¯¯¯¯¯ =
∞
X
k=m
Re (θek)
¡
rk −rk+1¢
where −ε < Re (θek) < ε.
2. Abel’s theorem says that if P∞
n=0 an (z −a)n has radius of convergence equal
to 1 and if A = P∞
n=0 an, then limr→1−
P∞
n=0 anrn = A. Hint:
Show
P∞
k=0 akrk = P∞
k=0 Ak
¡
rk −rk+1¢
where Ak denotes the kth partial sum
of P aj. Thus
∞
X
k=0
akrk =
∞
X
k=m+1
Ak
¡
rk −rk+1¢
+
m
X
k=0
Ak
¡
rk −rk+1¢
,
where |Ak −A| < ε for all k ≥m. In the ﬁrst sum, write Ak = A+ek and use
Problem 1. Use this theorem to verify that arctan (1) = P∞
k=0 (−1)k
1
2k+1.

24.4.
EXERCISES
655
3. Find the integrals using the Cauchy integral formula.
(a)
R
γ
sin z
z−i dz where γ (t) = 2eit : t ∈[0, 2π] .
(b)
R
γ
1
z−adz where γ (t) = a + reit : t ∈[0, 2π]
(c)
R
γ
cos z
z2 dz where γ (t) = eit : t ∈[0, 2π]
(d)
R
γ
log(z)
zn dz where γ (t) = 1 + 1
2eit : t ∈[0, 2π] and n = 0, 1, 2. In this
problem, log (z) ≡ln |z| + i arg (z) where arg (z) ∈(−π, π) and z =
|z| ei arg(z). Thus elog(z) = z and log (z)′ = 1
z.
4. Let γ (t) = 4eit : t ∈[0, 2π] and ﬁnd
R
γ
z2+4
z(z2+1)dz.
5. Suppose f (z) = P∞
n=0 anzn for all |z| < R. Show that then
1
2π
Z 2π
0
¯¯f
¡
reiθ¢¯¯2 dθ =
∞
X
n=0
|an|2 r2n
for all r ∈[0, R). Hint: Let
fn (z) ≡
n
X
k=0
akzk,
show
1
2π
Z 2π
0
¯¯fn
¡
reiθ¢¯¯2 dθ =
n
X
k=0
|ak|2 r2k
and then take limits as n →∞using uniform convergence.
6. The Cauchy integral formula, marvelous as it is, can actually be improved
upon. The Cauchy integral formula involves representing f by the values of
f on the boundary of the disk, B (a, r) . It is possible to represent f by using
only the values of Re f on the boundary. This leads to the Schwarz formula .
Supply the details in the following outline.
Suppose f is analytic on |z| < R and
f (z) =
∞
X
n=0
anzn
(24.15)
with the series converging uniformly on |z| = R. Then letting |w| = R,
2u (w) = f (w) + f (w)
and so
2u (w) =
∞
X
k=0
akwk +
∞
X
k=0
ak (w)k .
(24.16)

656
FUNDAMENTALS OF COMPLEX ANALYSIS
Now letting γ (t) = Reit, t ∈[0, 2π]
Z
γ
2u (w)
w
dw
=
(a0 + a0)
Z
γ
1
wdw
=
2πi (a0 + a0) .
Thus, multiplying 24.16 by w−1,
1
πi
Z
γ
u (w)
w
dw = a0 + a0.
Now multiply 24.16 by w−(n+1) and integrate again to obtain
an = 1
πi
Z
γ
u (w)
wn+1 dw.
Using these formulas for an in 24.15, we can interchange the sum and the
integral (Why can we do this?) to write the following for |z| < R.
f (z)
=
1
πi
Z
γ
1
z
∞
X
k=0
³ z
w
´k+1
u (w) dw −a0
=
1
πi
Z
γ
u (w)
w −z dw −a0,
which is the Schwarz formula. Now Re a0 =
1
2πi
R
γ
u(w)
w dw and a0 = Re a0 −
i Im a0. Therefore, we can also write the Schwarz formula as
f (z) =
1
2πi
Z
γ
u (w) (w + z)
(w −z) w
dw + i Im a0.
(24.17)
7. Take the real parts of the second form of the Schwarz formula to derive the
Poisson formula for a disk,
u
¡
reiα¢
= 1
2π
Z 2π
0
u
¡
Reiθ¢ ¡
R2 −r2¢
R2 + r2 −2Rr cos (θ −α)dθ.
(24.18)
8. Suppose that u (w) is a given real continuous function deﬁned on ∂B (0, R)
and deﬁne f (z) for |z| < R by 24.17. Show that f, so deﬁned is analytic.
Explain why u given in 24.18 is harmonic. Show that
lim
r→R−u
¡
reiα¢
= u
¡
Reiα¢
.
Thus u is a harmonic function which approaches a given function on the
boundary and is therefore, a solution to the Dirichlet problem.

24.5.
ZEROS OF AN ANALYTIC FUNCTION
657
9. Suppose f (z) = P∞
k=0 ak (z −z0)k for all |z −z0| < R. Show that f ′ (z) =
P∞
k=0 akk (z −z0)k−1 for all |z −z0| < R. Hint: Let fn (z) be a partial sum
of f. Show that f ′
n converges uniformly to some function, g on |z −z0| ≤r
for any r < R. Now use the Cauchy integral formula for a function and its
derivative to identify g with f ′.
10. Use Problem 9 to ﬁnd the exact value of P∞
k=0 k2 ¡ 1
3
¢k .
11. Prove the binomial formula,
(1 + z)α =
∞
X
n=0
µα
n
¶
zn
where
µα
n
¶
≡α · · · (α −n + 1)
n!
.
Can this be used to give a proof of the binomial formula,
(a + b)n =
n
X
k=0
µn
k
¶
an−kbk?
Explain.
12. Suppose f is analytic on B (z0, r) and continuous on B (z0, r) and |f (z)| ≤M
on B (z0, r). Show that then
¯¯f (n) (a)
¯¯ ≤Mn!
rn .
24.5
Zeros Of An Analytic Function
In this section we give a very surprising property of analytic functions which is in
stark contrast to what takes place for functions of a real variable.
Deﬁnition 24.21 A region is a connected open set.
It turns out the zeros of an analytic function which is not constant on some
region cannot have a limit point. This is also a good time to deﬁne the order of a
zero.
Deﬁnition 24.22 Suppose f is an analytic function deﬁned near a point, α where
f (α) = 0. Thus α is a zero of the function, f. The zero is of order m if f (z) =
(z −α)m g (z) where g is an analytic function which is not equal to zero at α.
Theorem 24.23 Let Ωbe a connected open set (region) and let f : Ω→X be
analytic. Then the following are equivalent.
1. f (z) = 0 for all z ∈Ω
2. There exists z0 ∈Ωsuch that f (n) (z0) = 0 for all n.

658
FUNDAMENTALS OF COMPLEX ANALYSIS
3. There exists z0 ∈Ωwhich is a limit point of the set,
Z ≡{z ∈Ω: f (z) = 0} .
Proof: It is clear the ﬁrst condition implies the second two. Suppose the third
holds. Then for z near z0
f (z) =
∞
X
n=k
f (n) (z0)
n!
(z −z0)n
where k ≥1 since z0 is a zero of f. Suppose k < ∞. Then,
f (z) = (z −z0)k g (z)
where g (z0) ̸= 0. Letting zn →z0 where zn ∈Z, zn ̸= z0, it follows
0 = (zn −z0)k g (zn)
which implies g (zn) = 0. Then by continuity of g, we see that g (z0) = 0 also,
contrary to the choice of k. Therefore, k cannot be less than ∞and so z0 is a point
satisfying the second condition.
Now suppose the second condition and let
S ≡
n
z ∈Ω: f (n) (z) = 0 for all n
o
.
It is clear that S is a closed set which by assumption is nonempty. However, this
set is also open. To see this, let z ∈S. Then for all w close enough to z,
f (w) =
∞
X
k=0
f (k) (z)
k!
(w −z)k = 0.
Thus f is identically equal to zero near z ∈S. Therefore, all points near z are
contained in S also, showing that S is an open set. Now Ω= S ∪(Ω\ S) , the union
of two disjoint open sets, S being nonempty. It follows the other open set, Ω\ S,
must be empty because Ωis connected. Therefore, the ﬁrst condition is veriﬁed.
This proves the theorem. (See the following diagram.)
1.)
↙↗
↘
2.)
←−
3.)
Note how radically diﬀerent this is from the theory of functions of a real variable.
Consider, for example the function
f (x) ≡
½
x2 sin
¡ 1
x
¢
if x ̸= 0
0 if x = 0

24.6.
LIOUVILLE’S THEOREM
659
which has a derivative for all x ∈R and for which 0 is a limit point of the set, Z,
even though f is not identically equal to zero.
Here is a very important application called Euler’s formula. Recall that
ez ≡ex (cos (y) + i sin (y))
(24.19)
Is it also true that ez = P∞
k=0
zk
k! ?
Theorem 24.24 (Euler’s Formula) Let z = x + iy. Then
ez =
∞
X
k=0
zk
k! .
Proof: It was already observed that ez given by 24.19 is analytic. So is exp (z) ≡
P∞
k=0
zk
k! . In fact the power series converges for all z ∈C. Furthermore the two
functions, ez and exp (z) agree on the real line which is a set which contains a limit
point. Therefore, they agree for all values of z ∈C.
This formula shows the famous two identities,
eiπ = −1 and e2πi = 1.
24.6
Liouville’s Theorem
The following theorem pertains to functions which are analytic on all of C, “entire”
functions.
Deﬁnition 24.25 A function, f : C →C or more generally, f : C →X is entire
means it is analytic on C.
Theorem 24.26 (Liouville’s theorem) If f is a bounded entire function having
values in X, then f is a constant.
Proof: Since f is entire, pick any z ∈C and write
f ′ (z) =
1
2πi
Z
γR
f (w)
(w −z)2 dw
where γR (t) = z + Reit for t ∈[0, 2π] . Therefore,
||f ′ (z)|| ≤C 1
R
where C is some constant depending on
the assumed bound on f. Since R is
arbitrary, let R →∞to obtain f ′ (z) = 0 for any z ∈C. It follows from this that f
is constant for if zj j = 1, 2 are two complex numbers, let h (t) = f (z1 + t (z2 −z1))
for t ∈[0, 1] . Then h′ (t) = f ′ (z1 + t (z2 −z1)) (z2 −z1) = 0. By Lemmas 24.8 -
24.10 h is a constant on [0, 1] which implies f (z1) = f (z2) .

660
FUNDAMENTALS OF COMPLEX ANALYSIS
With Liouville’s theorem it becomes possible to give an easy proof of the fun-
damental theorem of algebra. It is ironic that all the best proofs of this theorem
in algebra come from the subjects of analysis or topology. Out of all the proofs
that have been given of this very important theorem, the following one based on
Liouville’s theorem is the easiest.
Theorem 24.27 (Fundamental theorem of Algebra) Let
p (z) = zn + an−1zn−1 + · · · + a1z + a0
be a polynomial where n ≥1 and each coeﬃcient is a complex number. Then there
exists z0 ∈C such that p (z0) = 0.
Proof: Suppose not. Then p (z)−1 is an entire function. Also
|p (z)| ≥|z|n −
³
|an−1| |z|n−1 + · · · + |a1| |z| + |a0|
´
and so lim|z|→∞|p (z)| = ∞which implies lim|z|→∞
¯¯¯p (z)−1¯¯¯ = 0. It follows that,
since p (z)−1 is bounded for z in any bounded set, we must have that p (z)−1 is a
bounded entire function. But then it must be constant. However since p (z)−1 →0
as |z| →∞, this constant can only be 0. However,
1
p(z) is never equal to zero. This
proves the theorem.
24.7
The General Cauchy Integral Formula
24.7.1
The Cauchy Goursat Theorem
This section gives a fundamental theorem which is essential to the development
which follows and is closely related to the question of when a function has a
primitive. First of all, if you have two points in C, z1 and z2, you can consider
γ (t) ≡z1 + t (z2 −z1) for t ∈[0, 1] to obtain a continuous bounded variation curve
from z1 to z2. More generally, if z1, · · ·, zm are points in C you can obtain a contin-
uous bounded variation curve from z1 to zm which consists of ﬁrst going from z1 to
z2 and then from z2 to z3 and so on, till in the end one goes from zm−1 to zm. We
denote this piecewise linear curve as γ (z1, · · ·, zm) . Now let T be a triangle with
vertices z1, z2 and z3 encountered in the counter clockwise direction as shown.
¡
¡
¡
¡
¡@
@
@
@
@
z1
z2
z3
Denote by
R
∂T f (z) dz, the expression,
R
γ(z1,z2,z3,z1) f (z) dz. Consider the fol-

24.7.
THE GENERAL CAUCHY INTEGRAL FORMULA
661
lowing picture.
¡
¡
¡
¡
¡
¡
¡
¡
¡
-
@
@
@
@
@
@
@
@
@
¡
¡
¡
ª
¡
¡
¡
ª
-
T
T 1
1
T 1
2
T 1
3
T 1
4
@
@
@
I
@
@
@
I
¡
¡
ª

-
@@
R
¡¡

@
@
I
@
@
@
@
@¡
¡
¡
¡
¡
z1
z2
z3
By Lemma 23.11
Z
∂T
f (z) dz =
4
X
k=1
Z
∂T 1
k
f (z) dz.
(24.20)
On the “inside lines” the integrals cancel as claimed in Lemma 23.11 because there
are two integrals going in opposite directions for each of these inside lines.
Theorem 24.28 (Cauchy Goursat) Let f : Ω→X have the property that f ′ (z)
exists for all z ∈Ωand let T be a triangle contained in Ω. Then
Z
∂T
f (w) dw = 0.
Proof: Suppose not. Then
¯¯¯¯
¯¯¯¯
Z
∂T
f (w) dw
¯¯¯¯
¯¯¯¯ = α ̸= 0.
From 24.20 it follows
α ≤
4
X
k=1
¯¯¯¯¯
¯¯¯¯¯
Z
∂T 1
k
f (w) dw
¯¯¯¯¯
¯¯¯¯¯
and so for at least one of these T 1
k , denoted from now on as T1,
¯¯¯¯
¯¯¯¯
Z
∂T1
f (w) dw
¯¯¯¯
¯¯¯¯ ≥α
4 .
Now let T1 play the same role as T, subdivide as in the above picture, and obtain
T2 such that
¯¯¯¯
¯¯¯¯
Z
∂T2
f (w) dw
¯¯¯¯
¯¯¯¯ ≥α
42 .
Continue in this way, obtaining a sequence of triangles,
Tk ⊇Tk+1, diam (Tk) ≤diam (T) 2−k,
and
¯¯¯¯
¯¯¯¯
Z
∂Tk
f (w) dw
¯¯¯¯
¯¯¯¯ ≥α
4k .

662
FUNDAMENTALS OF COMPLEX ANALYSIS
Then let z ∈∩∞
k=1Tk and note that by assumption, f ′ (z) exists. Therefore, for all
k large enough,
Z
∂Tk
f (w) dw =
Z
∂Tk
f (z) + f ′ (z) (w −z) + g (w) dw
where ||g (w)|| < ε |w −z| . Now observe that w →f (z) + f ′ (z) (w −z) has a
primitive, namely,
F (w) = f (z) w + f ′ (z) (w −z)2 /2.
Therefore, by Corollary 23.14.
Z
∂Tk
f (w) dw =
Z
∂Tk
g (w) dw.
From the deﬁnition, of the integral,
α
4k
≤
¯¯¯¯
¯¯¯¯
Z
∂Tk
g (w) dw
¯¯¯¯
¯¯¯¯ ≤ε diam (Tk) (length of ∂Tk)
≤
ε2−k (length of T) diam (T) 2−k,
and so
α ≤ε (length of T) diam (T) .
Since ε is arbitrary, this shows α = 0, a contradiction. Thus
R
∂T f (w) dw = 0 as
claimed.
This fundamental result yields the following important theorem.
Theorem 24.29 (Morera1) Let Ωbe an open set and let f ′ (z) exist for all z ∈Ω.
Let D ≡B (z0, r) ⊆Ω. Then there exists ε > 0 such that f has a primitive on
B (z0, r + ε).
Proof: Choose ε > 0 small enough that B (z0, r + ε) ⊆Ω. Then for w ∈
B (z0, r + ε) , deﬁne
F (w) ≡
Z
γ(z0,w)
f (u) du.
Then by the Cauchy Goursat theorem, and w ∈B (z0, r + ε) , it follows that for |h|
small enough,
F (w + h) −F (w)
h
= 1
h
Z
γ(w,w+h)
f (u) du
= 1
h
Z 1
0
f (w + th) hdt =
Z 1
0
f (w + th) dt
which converges to f (w) due to the continuity of f at w. This proves the theorem.
The following is a slight generalization of the above theorem which is also referred
to as Morera’s theorem.
1Giancinto Morera 1856-1909. This theorem or one like it dates from around 1886

24.7.
THE GENERAL CAUCHY INTEGRAL FORMULA
663
Corollary 24.30 Let Ωbe an open set and suppose that whenever
γ (z1, z2, z3, z1)
is a closed curve bounding a triangle T, which is contained in Ω, and f is a contin-
uous function deﬁned on Ω, it follows that
Z
γ(z1,z2,z3,z1)
f (z) dz = 0,
then f is analytic on Ω.
Proof: As in the proof of Morera’s theorem, let B (z0, r) ⊆Ωand use the given
condition to construct a primitive, F for f on B (z0, r) . Then F is analytic and so
by Theorem 24.16, it follows that F and hence f have inﬁnitely many derivatives,
implying that f is analytic on B (z0, r) . Since z0 is arbitrary, this shows f is analytic
on Ω.
24.7.2
A Redundant Assumption
Earlier in the deﬁnition of analytic, it was assumed the derivative is continuous.
This assumption is redundant.
Theorem 24.31 Let Ωbe an open set in C and suppose f : Ω→X has the property
that f ′ (z) exists for each z ∈Ω. Then f is analytic on Ω.
Proof: Let z0 ∈Ωand let B (z0, r) ⊆Ω. By Morera’s theorem f has a prim-
itive, F on B (z0, r) . It follows that F is analytic because it has a derivative, f,
and this derivative is continuous. Therefore, by Theorem 24.16 F has inﬁnitely
many derivatives on B (z0, r) implying that f also has inﬁnitely many derivatives
on B (z0, r) . Thus f is analytic as claimed.
It follows a function is analytic on an open set, Ωif and only if f ′ (z) exists for
z ∈Ω. This is because it was just shown the derivative, if it exists, is automatically
continuous.
The same proof used to prove Theorem 24.29 implies the following corollary.
Corollary 24.32 Let Ωbe a convex open set and suppose that f ′ (z) exists for all
z ∈Ω. Then f has a primitive on Ω.
Note that this implies that if Ωis a convex open set on which f ′ (z) exists and
if γ : [a, b] →Ωis a closed, continuous curve having bounded variation, then letting
F be a primitive of f Theorem 23.13 implies
Z
γ
f (z) dz = F (γ (b)) −F (γ (a)) = 0.

664
FUNDAMENTALS OF COMPLEX ANALYSIS
Notice how diﬀerent this is from the situation of a function of a real variable! It
is possible for a function of a real variable to have a derivative everywhere and yet
the derivative can be discontinuous. A simple example is the following.
f (x) ≡
½
x2 sin
¡ 1
x
¢
if x ̸= 0
0 if x = 0
.
Then f ′ (x) exists for all x ∈R. Indeed, if x ̸= 0, the derivative equals 2x sin 1
x−cos 1
x
which has no limit as x →0. However, from the deﬁnition of the derivative of a
function of one variable, f ′ (0) = 0.
24.7.3
Classiﬁcation Of Isolated Singularities
First some notation.
Deﬁnition 24.33 Let B′ (a, r) ≡{z ∈C such that 0 < |z −a| < r}. Thus this is
the usual ball without the center. A function is said to have an isolated singularity
at the point a ∈C if f is analytic on B′ (a, r) for some r > 0.
It turns out isolated singularities can be neatly classiﬁed into three types, re-
movable singularities, poles, and essential singularities. The next theorem deals
with the case of a removable singularity.
Deﬁnition 24.34 An isolated singularity of f is said to be removable if there exists
an analytic function, g analytic at a and near a such that f = g at all points near
a.
Theorem 24.35 Let f : B′ (a, r) →X be analytic. Thus f has an isolated singu-
larity at a. Suppose also that
lim
z→a f (z) (z −a) = 0.
Then there exists a unique analytic function, g : B (a, r) →X such that g = f on
B′ (a, r) . Thus the singularity at a is removable.
Proof: Let h (z) ≡(z −a)2 f (z) , h (a) ≡0. Then h is analytic on B (a, r)
because it is easy to see that h′ (a) = 0. It follows h is given by a power series,
h (z) =
∞
X
k=2
ak (z −a)k
where a0 = a1 = 0 because of the observation above that h′ (a) = h (a) = 0. It
follows that for |z −a| > 0
f (z) =
∞
X
k=2
ak (z −a)k−2 ≡g (z) .
This proves the theorem.
What of the other case where the singularity is not removable? This situation
is dealt with by the amazing Casorati Weierstrass theorem.

24.7.
THE GENERAL CAUCHY INTEGRAL FORMULA
665
Theorem 24.36 (Casorati Weierstrass) Let a be an isolated singularity and sup-
pose for some r > 0, f (B′ (a, r)) is not dense in C. Then either a is a removable
singularity or there exist ﬁnitely many b1, · · ·, bM for some ﬁnite number, M such
that for z near a,
f (z) = g (z) +
M
X
k=1
bk
(z −a)k
(24.21)
where g (z) is analytic near a.
Proof: Suppose B (z0, δ) has no points of f (B′ (a, r)) . Such a ball must exist if
f (B′ (a, r)) is not dense. Then for z ∈B′ (a, r) , |f (z) −z0| ≥δ > 0. It follows from
Theorem 24.35 that
1
f(z)−z0 has a removable singularity at a. Hence, there exists h
an analytic function such that for z near a,
h (z) =
1
f (z) −z0
.
(24.22)
There are two cases. First suppose h (a) = 0. Then P∞
k=1 ak (z −a)k =
1
f(z)−z0
for z near a. If all the ak = 0, this would be a contradiction because then the left
side would equal zero for z near a but the right side could not equal zero. Therefore,
there is a ﬁrst m such that am ̸= 0. Hence there exists an analytic function, k (z)
which is not equal to zero in some ball, B (a, ε) such that
k (z) (z −a)m =
1
f (z) −z0
.
Hence, taking both sides to the −1 power,
f (z) −z0 =
1
(z −a)m
∞
X
k=0
bk (z −a)k
and so 24.21 holds.
The other case is that h (a) ̸= 0. In this case, raise both sides of 24.22 to the −1
power and obtain
f (z) −z0 = h (z)−1 ,
a function analytic near a. Therefore, the singularity is removable. This proves the
theorem.
This theorem is the basis for the following deﬁnition which classiﬁes isolated
singularities.
Deﬁnition 24.37 Let a be an isolated singularity of a complex valued function, f.
When 24.21 holds for z near a, then a is called a pole. The order of the pole in
24.21 is M. If for every r > 0, f (B′ (a, r)) is dense in C then a is called an essential
singularity.
In terms of the above deﬁnition, isolated singularities are either removable, a
pole, or essential. There are no other possibilities.

666
FUNDAMENTALS OF COMPLEX ANALYSIS
Theorem 24.38 Suppose f : Ω→C has an isolated singularity at a ∈Ω. Then a
is a pole if and only if
lim
z→a d (f (z) , ∞) = 0
in bC.
Proof: Suppose ﬁrst f has a pole at a. Then by deﬁnition, f (z) = g (z) +
PM
k=1
bk
(z−a)k for z near a where g is analytic. Then
|f (z)|
≥
|bM|
|z −a|M −|g (z)| −
M−1
X
k=1
|bk|
|z −a|k
=
1
|z −a|M
Ã
|bM| −
Ã
|g (z)| |z −a|M +
M−1
X
k=1
|bk| |z −a|M−k
!!
.
Now limz→a
³
|g (z)| |z −a|M + PM−1
k=1 |bk| |z −a|M−k´
= 0 and so the above in-
equality proves limz→a |f (z)| = ∞. Referring to the diagram on Page 628, you see
this is the same as saying
lim
z→a |θf (z) −(0, 0, 2)| = lim
z→a |θf (z) −θ (∞)| = lim
z→a d (f (z) , ∞) = 0
Conversely, suppose limz→a d (f (z) , ∞) = 0. Then from the diagram on Page
628, it follows limz→a |f (z)| = ∞and in particular, a cannot be either removable or
an essential singularity by the Casorati Weierstrass theorem, Theorem 24.36. The
only case remaining is that a is a pole. This proves the theorem.
Deﬁnition 24.39 Let f : Ω→C where Ωis an open subset of C. Then f is called
meromorphic if all singularities are isolated and are either poles or removable and
this set of singularities has no limit point. It is convenient to regard meromorphic
functions as having values in bC where if a is a pole, f (a) ≡∞. From now on, this
will be assumed when a meromorphic function is being considered.
The usefulness of the above convention about f (a) ≡∞at a pole is made clear
in the following theorem.
Theorem 24.40 Let Ωbe an open subset of C and let f : Ω→bC be meromorphic.
Then f is continuous with respect to the metric, d on bC.
Proof: Let zn →z where z ∈Ω. Then if z is a pole, it follows from Theorem
24.38 that
d (f (zn) , ∞) ≡d (f (zn) , f (z)) →0.
If z is not a pole, then f (zn) →f (z) in C which implies |θ (f (zn)) −θ (f (z))| =
d (f (zn) , f (z)) →0. Recall that θ is continuous on C.

24.7.
THE GENERAL CAUCHY INTEGRAL FORMULA
667
24.7.4
The Cauchy Integral Formula
This section presents the general version of the Cauchy integral formula valid for
arbitrary closed rectiﬁable curves. The key idea in this development is the notion
of the winding number. This is the number also called the index, deﬁned in the
following theorem. This winding number, along with the earlier results, especially
Liouville’s theorem, yields an extremely general Cauchy integral formula.
Deﬁnition 24.41 Let γ : [a, b] →C and suppose z /∈γ∗. The winding number,
n (γ, z) is deﬁned by
n (γ, z) ≡
1
2πi
Z
γ
dw
w −z .
The main interest is in the case where γ is
closed curve.
However, the same
notation will be used for any such curve.
Theorem 24.42 Let γ : [a, b] →C be continuous and have bounded variation with
γ (a) = γ (b) . Also suppose that z /∈γ∗. Deﬁne
n (γ, z) ≡
1
2πi
Z
γ
dw
w −z .
(24.23)
Then n (γ, ·) is continuous and integer valued. Furthermore, there exists a sequence,
ηk : [a, b] →C such that ηk is C1 ([a, b]) ,
||ηk −γ|| < 1
k , ηk (a) = ηk (b) = γ (a) = γ (b) ,
and n (ηk, z) = n (γ, z) for all k large enough. Also n (γ, ·) is constant on every
connected component of C\γ∗and equals zero on the unbounded component of C\γ∗.
Proof: First consider the assertion about continuity.
|n (γ, z) −n (γ, z1)|
≤
C
¯¯¯¯
Z
γ
µ
1
w −z −
1
w −z1
¶
dw
¯¯¯¯
≤
eC (Length of γ) |z1 −z|
whenever z1 is close enough to z. This proves the continuity assertion. Note this
did not depend on γ being closed.
Next it is shown that for a closed curve the winding number equals an integer.
To do so, use Theorem 23.12 to obtain ηk, a function in C1 ([a, b]) such that z /∈
ηk ([a, b]) for all k large enough, ηk (x) = γ (x) for x = a, b, and
¯¯¯¯¯
1
2πi
Z
γ
dw
w −z −
1
2πi
Z
ηk
dw
w −z
¯¯¯¯¯ < 1
k , ||ηk −γ|| < 1
k .
It is shown that each of
1
2πi
R
ηk
dw
w−z is an integer. To simplify the notation, write η
instead of ηk.
Z
η
dw
w −z =
Z b
a
η′ (s) ds
η (s) −z .

668
FUNDAMENTALS OF COMPLEX ANALYSIS
Deﬁne
g (t) ≡
Z t
a
η′ (s) ds
η (s) −z .
(24.24)
Then
³
e−g(t) (η (t) −z)
´′
=
e−g(t)η′ (t) −e−g(t)g′ (t) (η (t) −z)
=
e−g(t)η′ (t) −e−g(t)η′ (t) = 0.
It follows that e−g(t) (η (t) −z) equals a constant. In particular, using the fact that
η (a) = η (b) ,
e−g(b) (η (b) −z) = e−g(a) (η (a) −z) = (η (a) −z) = (η (b) −z)
and so e−g(b) = 1. This happens if and only if −g (b) = 2mπi for some integer m.
Therefore, 24.24 implies
2mπi =
Z b
a
η′ (s) ds
η (s) −z =
Z
η
dw
w −z .
Therefore,
1
2πi
R
ηk
dw
w−z is a sequence of integers converging to
1
2πi
R
γ
dw
w−z ≡n (γ, z)
and so n (γ, z) must also be an integer and n (ηk, z) = n (γ, z) for all k large enough.
Since n (γ, ·) is continuous and integer valued, it follows from Corollary 6.67 on
Page 155 that it must be constant on every connected component of C\γ∗. It is clear
that n (γ, z) equals zero on the unbounded component because from the formula,
lim
z→∞|n (γ, z)| ≤lim
z→∞V (γ, [a, b])
µ
1
|z| −c
¶
where c ≥max {|w| : w ∈γ∗} .This proves the theorem.
Corollary 24.43 Suppose γ : [a, b] →C is a continuous bounded variation curve
and n (γ, z) is an integer where z /∈γ∗. Then γ (a) = γ (b) . Also z →n (γ, z) for
z /∈γ∗is continuous.
Proof: Letting η be a C1 curve for which η (a) = γ (a) and η (b) = γ (b) and
which is close enough to γ that n (η, z) = n (γ, z) , the argument is similar to the
above. Let
g (t) ≡
Z t
a
η′ (s) ds
η (s) −z .
(24.25)
Then
³
e−g(t) (η (t) −z)
´′
=
e−g(t)η′ (t) −e−g(t)g′ (t) (η (t) −z)
=
e−g(t)η′ (t) −e−g(t)η′ (t) = 0.
Hence
e−g(t) (η (t) −z) = c ̸= 0.
(24.26)

24.7.
THE GENERAL CAUCHY INTEGRAL FORMULA
669
By assumption
g (b) =
Z
η
1
w −z dw = 2πim
for some integer, m. Therefore, from 24.26
1 = e2πmi = η (b) −z
c
.
Thus c = η (b) −z and letting t = a in 24.26,
1 = η (a) −z
η (b) −z
which shows η (a) = η (b) . This proves the corollary since the assertion about con-
tinuity was already observed.
It is a good idea to consider a simple case to get an idea of what the winding
number is measuring. To do so, consider γ : [a, b] →C such that γ is continuous,
closed and bounded variation. Suppose also that γ is one to one on (a, b) . Such a
curve is called a simple closed curve. It can be shown that such a simple closed curve
divides the plane into exactly two components, an “inside” bounded component and
an “outside” unbounded component. This is called the Jordan Curve theorem or
the Jordan separation theorem. This is a diﬃcult theorem which requires some
very hard topology such as homology theory or degree theory. It won’t be used
here beyond making reference to it. For now, it suﬃces to simply assume that γ
is such that this result holds. This will usually be obvious anyway. Also suppose
that it is possible to change the parameter to be in [0, 2π] , in such a way that
γ (t) + λ
¡
z + reit −γ (t)
¢
−z ̸= 0 for all t ∈[0, 2π] and λ ∈[0, 1] . (As t goes
from 0 to 2π the point γ (t) traces the curve γ ([0, 2π]) in the counter clockwise
direction.) Suppose z ∈D, the inside of the simple closed curve and consider the
curve δ (t) = z+reit for t ∈[0, 2π] where r is chosen small enough that B (z, r) ⊆D.
Then it happens that n (δ, z) = n (γ, z) .
Proposition 24.44 Under the above conditions,
n (δ, z) = n (γ, z)
and n (δ, z) = 1.
Proof: By changing the parameter, assume that [a, b] = [0, 2π] . From Theorem
24.42 it suﬃces to assume also that γ is C1. Deﬁne hλ (t) ≡γ (t)+λ
¡
z + reit −γ (t)
¢
for λ ∈[0, 1] . (This function is called a homotopy of the curves γ and δ.) Note that
for each λ ∈[0, 1] , t →hλ (t) is a closed C1 curve. Also,
1
2πi
Z
hλ
1
w −z dw =
1
2πi
Z 2π
0
γ′ (t) + λ
¡
rieit −γ′ (t)
¢
γ (t) + λ (z + reit −γ (t)) −z dt.

670
FUNDAMENTALS OF COMPLEX ANALYSIS
This number is an integer and it is routine to verify that it is a continuous function
of λ. When λ = 0 it equals n (γ, z) and when λ = 1 it equals n (δ, z). Therefore,
n (δ, z) = n (γ, z) . It only remains to compute n (δ, z) .
n (δ, z) =
1
2πi
Z 2π
0
rieit
reit dt = 1.
This proves the proposition.
Now if γ was not one to one but caused the point, γ (t) to travel around γ∗twice,
you could modify the above argument to have the parameter interval, [0, 4π] and
still ﬁnd n (δ, z) = n (γ, z) only this time, n (δ, z) = 2. Thus the winding number
is just what its name suggests. It measures the number of times the curve winds
around the point. One might ask why bother with the winding number if this is
all it does. The reason is that the notion of counting the number of times a curve
winds around a point is rather vague. The winding number is precise. It is also the
natural thing to consider in the general Cauchy integral formula presented below.
Consider a situation typiﬁed by the following picture in which Ωis the open set
between the dotted curves and γj are closed rectiﬁable curves in Ω.
-
γ1
γ2

γ3

U
The following theorem is the general Cauchy integral formula.
Deﬁnition 24.45 Let {γk}n
k=1 be continuous oriented curves having bounded vari-
ation. Then this is called a cycle if whenever, z /∈∪n
k=1γ∗
k, Pn
k=1 n (γk, z) is an
integer.
By Theorem 24.42 if each γk is a closed curve, then {γk}n
k=1 is a cycle.
Theorem 24.46 Let Ωbe an open subset of the plane and let f : Ω→X be
analytic. If γk : [ak, bk] →Ω, k = 1, · · ·, m are continuous curves having bounded
variation such that for all z /∈∪m
k=1γk ([ak, bk])
m
X
k=1
n (γk, z) equals an integer
and for all z /∈Ω,
m
X
k=1
n (γk, z) = 0.

24.7.
THE GENERAL CAUCHY INTEGRAL FORMULA
671
Then for all z ∈Ω\ ∪m
k=1γk ([ak, bk]) ,
f (z)
m
X
k=1
n (γk, z) =
m
X
k=1
1
2πi
Z
γk
f (w)
w −z dw.
Proof:
Let φ be deﬁned on Ω× Ωby
φ (z, w) ≡
½
f(w)−f(z)
w−z
if w ̸= z
f ′ (z) if w = z
.
Then φ is analytic as a function of both z and w and is continuous in Ω× Ω. This
is easily seen using Theorem 24.35. Consider the case of w →φ (z, w) .
lim
w→z (w −z) (φ (z, w) −φ (z, z)) = lim
w→z
µf (w) −f (z)
w −z
−f ′ (z)
¶
= 0.
Thus w →φ (z, w) has a removable singularity at z. The case of z →φ (z, w) is
similar.
Deﬁne
h (z) ≡
1
2πi
m
X
k=1
Z
γk
φ (z, w) dw.
Is h is analytic on Ω? To show this is the case, verify
Z
∂T
h (z) dz = 0
for every triangle, T, contained in Ωand apply Corollary 24.30. To do this, use
Theorem 23.12 to obtain for each k, a sequence of functions, ηkn ∈C1 ([ak, bk])
such that
ηkn (x) = γk (x) for x ∈{ak, bk}
and
ηkn ([ak, bk]) ⊆Ω, ||ηkn −γk|| < 1
n,
¯¯¯¯¯
¯¯¯¯¯
Z
ηkn
φ (z, w) dw −
Z
γk
φ (z, w) dw
¯¯¯¯¯
¯¯¯¯¯ < 1
n,
(24.27)
for all z ∈T. Then applying Fubini’s theorem,
Z
∂T
Z
ηkn
φ (z, w) dwdz =
Z
ηkn
Z
∂T
φ (z, w) dzdw = 0
because φ is given to be analytic. By 24.27,
Z
∂T
Z
γk
φ (z, w) dwdz = lim
n→∞
Z
∂T
Z
ηkn
φ (z, w) dwdz = 0
and so h is analytic on Ωas claimed.

672
FUNDAMENTALS OF COMPLEX ANALYSIS
Now let H denote the set,
H ≡
(
z ∈C\ ∪m
k=1 γk ([ak, bk]) :
m
X
k=1
n (γk, z) = 0
)
.
H is an open set because z →Pm
k=1 n (γk, z) is integer valued by assumption and
continuous. Deﬁne
g (z) ≡
(
h (z) if z ∈Ω
1
2πi
Pm
k=1
R
γk
f(w)
w−z dw if z ∈H
.
(24.28)
Why is g (z) well deﬁned? For z ∈Ω∩H, z /∈∪m
k=1γk ([ak, bk]) and so
g (z)
=
1
2πi
m
X
k=1
Z
γk
φ (z, w) dw =
1
2πi
m
X
k=1
Z
γk
f (w) −f (z)
w −z
dw
=
1
2πi
m
X
k=1
Z
γk
f (w)
w −z dw −
1
2πi
m
X
k=1
Z
γk
f (z)
w −z dw
=
1
2πi
m
X
k=1
Z
γk
f (w)
w −z dw
because z ∈H. This shows g (z) is well deﬁned. Also, g is analytic on Ωbecause
it equals h there. It is routine to verify that g is analytic on H also because of
the second line of 24.28.
By assumption, ΩC ⊆H because it is assumed that
P
k n (γk, z) = 0 for z /∈Ωand so Ω∪H = C showing that g is an entire function.
Now note that Pm
k=1 n (γk, z) = 0 for all z contained in the unbounded compo-
nent of C\∪m
k=1 γk ([ak, bk]) which component contains B (0, r)C for r large enough.
It follows that for |z| > r, it must be the case that z ∈H and so for such z, the
bottom description of g (z) found in 24.28 is valid. Therefore, it follows
lim
|z|→∞||g (z)|| = 0
and so g is bounded and entire. By Liouville’s theorem, g is a constant. Hence,
from the above equation, the constant can only equal zero.
For z ∈Ω\ ∪m
k=1γk ([ak, bk]) ,
0 = h (z) =
1
2πi
m
X
k=1
Z
γk
φ (z, w) dw =
1
2πi
m
X
k=1
Z
γk
f (w) −f (z)
w −z
dw =
1
2πi
m
X
k=1
Z
γk
f (w)
w −z dw −f (z)
m
X
k=1
n (γk, z) .
This proves the theorem.

24.7.
THE GENERAL CAUCHY INTEGRAL FORMULA
673
Corollary 24.47 Let Ωbe an open set and let γk : [ak, bk] →Ω, k = 1, · · ·, m, be
closed, continuous and of bounded variation. Suppose also that
m
X
k=1
n (γk, z) = 0
for all z /∈Ω. Then if f : Ω→C is analytic,
m
X
k=1
Z
γk
f (w) dw = 0.
Proof: This follows from Theorem 24.46 as follows. Let
g (w) = f (w) (w −z)
where z ∈Ω\ ∪m
k=1γk ([ak, bk]) . Then by this theorem,
0 = 0
m
X
k=1
n (γk, z) = g (z)
m
X
k=1
n (γk, z) =
m
X
k=1
1
2πi
Z
γk
g (w)
w −z dw =
1
2πi
m
X
k=1
Z
γk
f (w) dw.
Another simple corollary to the above theorem is Cauchy’s theorem for a simply
connected region.
Deﬁnition 24.48 An open set, Ω⊆C is a region if it is open and connected. A
region, Ωis simply connected if bC \Ωis connected where bC is the extended complex
plane. In the future, the term simply connected open set will be an open set which
is connected and bC \Ωis connected .
Corollary 24.49 Let γ : [a, b] →Ωbe a continuous closed curve of bounded vari-
ation where Ωis a simply connected region in C and let f : Ω→X be analytic.
Then
Z
γ
f (w) dw = 0.
Proof:
Let D denote the unbounded component of bC\γ∗. Thus ∞∈bC\γ∗.
Then the connected set, bC \ Ωis contained in D since every point of bC \ Ωmust be
in some component of bC\γ∗and ∞is contained in both bC\Ωand D. Thus D must
be the component that contains bC \ Ω. It follows that n (γ, ·) must be constant on
bC \ Ω, its value being its value on D. However, for z ∈D,
n (γ, z) =
1
2πi
Z
γ
1
w −z dw

674
FUNDAMENTALS OF COMPLEX ANALYSIS
and so lim|z|→∞n (γ, z) = 0 showing n (γ, z) = 0 on D. Therefore this veriﬁes the
hypothesis of Theorem 24.46. Let z ∈Ω∩D and deﬁne
g (w) ≡f (w) (w −z) .
Thus g is analytic on Ωand by Theorem 24.46,
0 = n (z, γ) g (z) =
1
2πi
Z
γ
g (w)
w −z dw =
1
2πi
Z
γ
f (w) dw.
This proves the corollary.
The following is a very signiﬁcant result which will be used later.
Corollary 24.50 Suppose Ωis a simply connected open set and f : Ω→X is
analytic. Then f has a primitive, F, on Ω. Recall this means there exists F such
that F ′ (z) = f (z) for all z ∈Ω.
Proof: Pick a point, z0 ∈Ωand let V denote those points, z of Ωfor which
there exists a curve, γ : [a, b] →Ωsuch that γ is continuous, of bounded variation,
γ (a) = z0, and γ (b) = z. Then it is easy to verify that V is both open and closed
in Ωand therefore, V = Ωbecause Ωis connected. Denote by γz0,z such a curve
from z0 to z and deﬁne
F (z) ≡
Z
γz0,z
f (w) dw.
Then F is well deﬁned because if γj, j = 1, 2 are two such curves, it follows from
Corollary 24.49 that
Z
γ1
f (w) dw +
Z
−γ2
f (w) dw = 0,
implying that
Z
γ1
f (w) dw =
Z
γ2
f (w) dw.
Now this function, F is a primitive because, thanks to Corollary 24.49
(F (z + h) −F (z)) h−1
=
1
h
Z
γz,z+h
f (w) dw
=
1
h
Z 1
0
f (z + th) hdt
and so, taking the limit as h →0, F ′ (z) = f (z) .
24.7.5
An Example Of A Cycle
The next theorem deals with the existence of a cycle with nice properties. Basically,
you go around the compact subset of an open set with suitable contours while staying
in the open set. The method involves the following simple concept.

24.7.
THE GENERAL CAUCHY INTEGRAL FORMULA
675
Deﬁnition 24.51 A tiling of R2 = C is the union of inﬁnitely many equally spaced
vertical and horizontal lines. You can think of the small squares which result as
tiles. To tile the plane or R2 = C means to consider such a union of horizontal and
vertical lines. It is like graph paper. See the picture below for a representation of
part of a tiling of C.
Theorem 24.52 Let K be a compact subset of an open set, Ω. Then there exist
continuous, closed, bounded variation oriented curves {Γj}m
j=1 for which Γ∗
j ∩K = ∅
for each j, Γ∗
j ⊆Ω, and for all p ∈K,
m
X
k=1
n (Γk, p) = 1.
while for all z /∈Ω
m
X
k=1
n (Γk, z) = 0.
Proof: Let δ = dist
¡
K, ΩC¢
. Since K is compact, δ > 0. Now tile the plane
with squares, each of which has diameter less than δ/2.
K
K
Ω

676
FUNDAMENTALS OF COMPLEX ANALYSIS
Let S denote the set of all the closed squares in this tiling which have nonempty
intersection with K.Thus, all the squares of S are contained in Ω. First suppose p is
a point of K which is in the interior of one of these squares in the tiling. Denote by
∂Sk the boundary of Sk one of the squares in S, oriented in the counter clockwise
direction and Sm denote the square of S which contains the point, p in its interior.
Let the edges of the square, Sj be
n
γj
k
o4
k=1.
Thus a short computation shows
n (∂Sm, p) = 1 but n (∂Sj, p) = 0 for all j ̸= m. The reason for this is that for
z in Sj, the values {z −p : z ∈Sj} lie in an open square, Q which is located at a
positive distance from 0. Then bC \ Q is connected and 1/ (z −p) is analytic on Q.
It follows from Corollary 24.50 that this function has a primitive on Q and so
Z
∂Sj
1
z −pdz = 0.
Similarly, if z /∈Ω, n (∂Sj, z) = 0. On the other hand, a direct computation will
verify that n (p, ∂Sm) = 1. Thus 1 = P
j,k n
³
p, γj
k
´
= P
Sj∈S n (p, ∂Sj) and if
z /∈Ω, 0 = P
j,k n
³
z, γj
k
´
= P
Sj∈S n (z, ∂Sj) .
If γj∗
k
coincides with γl∗
l , then the contour integrals taken over this edge are
taken in opposite directions and so the edge the two squares have in common can
be deleted without changing P
j,k n
³
z, γj
k
´
for any z not on any of the lines in the
tiling. For example, see the picture,
6
?
6


?
-
-
6

-
?
From the construction, if any of the γj∗
k contains a point of K then this point is
on one of the four edges of Sj and at this point, there is at least one edge of some
Sl which also contains this point. As just discussed, this shared edge can be deleted
without changing P
i,j n
³
z, γj
k
´
. Delete the edges of the Sk which intersect K but
not the endpoints of these edges. That is, delete the open edges. When this is done,
delete all isolated points. Let the resulting oriented curves be denoted by {γk}m
k=1 .
Note that you might have γ∗
k = γ∗
l . The construction is illustrated in the following
picture.

24.7.
THE GENERAL CAUCHY INTEGRAL FORMULA
677
6
?
-

-
?
6
?
K
K
Ω
Then as explained above, Pm
k=1 n (p, γk) = 1. It remains to prove the claim
about the closed curves.
Each orientation on an edge corresponds to a direction of motion over that
edge. Call such a motion over the edge a route. Initially, every vertex, (corner of
a square in S) has the property there are the same number of routes to and from
that vertex. When an open edge whose closure contains a point of K is deleted,
every vertex either remains unchanged as to the number of routes to and from that
vertex or it loses both a route away and a route to. Thus the property of having the
same number of routes to and from each vertex is preserved by deleting these open
edges.. The isolated points which result lose all routes to and from. It follows that
upon removing the isolated points you can begin at any of the remaining vertices
and follow the routes leading out from this and successive vertices according to
orientation and eventually return to that end. Otherwise, there would be a vertex
which would have only one route leading to it which does not happen. Now if you
have used all the routes out of this vertex, pick another vertex and do the same
process. Otherwise, pick an unused route out of the vertex and follow it to return.
Continue this way till all routes are used exactly once, resulting in closed oriented
curves, Γk. Then
X
k
n (Γk, p) =
X
j
n (γk, p) = 1.
In case p ∈K is on some line of the tiling, it is not on any of the Γk because
Γ∗
k ∩K = ∅and so the continuity of z →n (Γk, z) yields the desired result in this
case also. This proves the lemma.

678
FUNDAMENTALS OF COMPLEX ANALYSIS
24.8
Exercises
1. If U is simply connected, f is analytic on U and f has no zeros in U, show
there exists an analytic function, F, deﬁned on U such that eF = f.
2. Let f be deﬁned and analytic near the point a ∈C. Show that then f (z) =
P∞
k=0 bk (z −a)k whenever |z −a| < R where R is the distance between a and
the nearest point where f fails to have a derivative. The number R, is called
the radius of convergence and the power series is said to be expanded about
a.
3. Find the radius of convergence of the function
1
1+z2 expanded about a = 2.
Note there is nothing wrong with the function,
1
1+x2 when considered as a
function of a real variable, x for any value of x. However, if you insist on using
power series, you ﬁnd there is a limitation on the values of x for which the
power series converges due to the presence in the complex plane of a point, i,
where the function fails to have a derivative.
4. Suppose f is analytic on all of C and satisﬁes |f (z)| < A + B |z|1/2 . Show f
is constant.
5. What if you deﬁned an open set, U to be simply connected if C\U is connected.
Would it amount to the same thing? Hint: Consider the outside of B (0, 1) .
6. Let γ (t) = eit : t ∈[0, 2π] . Find
R
γ
1
zn dz for n = 1, 2, · · ·.
7. Show i
R 2π
0
(2 cos θ)2n dθ =
R
γ
¡
z + 1
z
¢2n ¡ 1
z
¢
dz where γ (t) = eit : t ∈[0, 2π] .
Then evaluate this integral using the binomial theorem and the previous prob-
lem.
8. Suppose that for some constants a, b ̸= 0, a, b ∈R, f (z + ib) = f (z) for all
z ∈C and f (z + a) = f (z) for all z ∈C. If f is analytic, show that f must
be constant. Can you generalize this? Hint: This uses Liouville’s theorem.
9. Suppose f (z) = u (x, y) + iv (x, y) is analytic for z ∈U, an open set. Let
g (z) = u∗(x, y) + iv∗(x, y) where
µ
u∗
v∗
¶
= Q
µ
u
v
¶
where Q is a unitary matrix.
That is QQ∗= Q∗Q = I. When will g be
analytic?
10. Suppose f is analytic on an open set, U, except for γ∗⊂U where γ is a one
to one continuous function having bounded variation, but it is known that f
is continuous on γ∗. Show that in fact f is analytic on γ∗also. Hint: Pick a
point on γ∗, say γ (t0) and suppose for now that t0 ∈(a, b) . Pick r > 0 such
that B = B (γ (t0) , r) ⊆U. Then show there exists t1 < t0 and t2 > t0 such

24.8.
EXERCISES
679
that γ ([t1, t2]) ⊆B and γ (ti) /∈B. Thus γ ([t1, t2]) is a path across B going
through the center of B which divides B into two open sets, B1, and B2 along
with γ∗. Let the boundary of Bk consist of γ ([t1, t2]) and a circular arc, Ck.
Now letting z ∈Bk, the line integral of f(w)
w−z over γ∗in two diﬀerent directions
cancels. Therefore, if z ∈Bk, you can argue that f (z) =
1
2πi
R
C
f(w)
w−z dw. By
continuity, this continues to hold for z ∈γ ((t1, t2)) . Therefore, f must be
analytic on γ ((t1, t1)) also. This shows that f must be analytic on γ ((a, b)) .
To get the endpoints, simply extend γ to have the same properties but deﬁned
on [a −ε, b + ε] and repeat the above argument or else do this at the beginning
and note that you get [a, b] ⊆(a −ε, b + ε) .
11. Let U be an open set contained in the upper half plane and suppose that
there are ﬁnitely many line segments on the x axis which are contained in
the boundary of U. Now suppose that f is deﬁned, real, and continuous on
these line segments and is deﬁned and analytic on U. Now let eU denote the
reﬂection of U across the x axis. Show that it is possible to extend f to a
function, g deﬁned on all of
W ≡eU ∪U ∪{the line segments mentioned earlier}
such that g is analytic in W. Hint: For z ∈eU, the reﬂection of U across the
x axis, let g (z) ≡f (z). Show that g is analytic on eU ∪U and continuous on
the line segments. Then use Problem 10 or Morera’s theorem to argue that
g is analytic on the line segments also. The result of this problem is know as
the Schwarz reﬂection principle.
12. Show that rotations and translations of analytic functions yield analytic func-
tions and use this observation to generalize the Schwarz reﬂection principle
to situations in which the line segments are part of a line which is not the x
axis. Thus, give a version which involves reﬂection about an arbitrary line.

680
FUNDAMENTALS OF COMPLEX ANALYSIS

The Open Mapping Theorem
25.1
A Local Representation
The open mapping theorem, is an even more surprising result than the theorem
about the zeros of an analytic function.
The following proof of this important
theorem uses an interesting local representation of the analytic function.
Theorem 25.1 (Open mapping theorem) Let Ωbe a region in C and suppose f :
Ω→C is analytic. Then f (Ω) is either a point or a region. In the case where f (Ω)
is a region, it follows that for each z0 ∈Ω, there exists an open set, V containing
z0 and m ∈N such that for all z ∈V,
f (z) = f (z0) + φ (z)m
(25.1)
where φ : V →B (0, δ) is one to one, analytic and onto, φ (z0) = 0, φ′ (z) ̸= 0 on
V and φ−1 analytic on B (0, δ) . If f is one to one then m = 1 for each z0 and
f −1 : f (Ω) →Ωis analytic.
Proof: Suppose f (Ω) is not a point. Then if z0 ∈Ωit follows there exists r > 0
such that f (z) ̸= f (z0) for all z ∈B (z0, r) \ {z0} . Otherwise, z0 would be a limit
point of the set,
{z ∈Ω: f (z) −f (z0) = 0}
which would imply from Theorem 24.23 that f (z) = f (z0) for all z ∈Ω. Therefore,
making r smaller if necessary and using the power series of f,
f (z) = f (z0) + (z −z0)m g (z) (
?=
³
(z −z0) g (z)1/m´m
)
for all z ∈B (z0, r) , where g (z) ̸= 0 on B (z0, r) . As implied in the above formula,
one wonders if you can take the mth root of g (z) .
g′
g is an analytic function on B (z0, r) and so by Corollary 24.32 it has a primitive
on B (z0, r) , h. Therefore by the product rule and the chain rule,
¡
ge−h¢′ = 0 and
so there exists a constant, C = ea+ib such that on B (z0, r) ,
ge−h = ea+ib.
681

682
THE OPEN MAPPING THEOREM
Therefore,
g (z) = eh(z)+a+ib
and so, modifying h by adding in the constant, a + ib, g (z) = eh(z) where h′ (z) =
g′(z)
g(z) on B (z0, r) . Letting
φ (z) = (z −z0) e
h(z)
m
implies formula 25.1 is valid on B (z0, r) . Now
φ′ (z0) = e
h(z0)
m
̸= 0.
Shrinking r if necessary you can assume φ′ (z) ̸= 0 on B (z0, r). Is there an open
set, V contained in B (z0, r) such that φ maps V onto B (0, δ) for some δ > 0?
Let φ (z) = u (x, y) + iv (x, y) where z = x + iy. Consider the mapping
µ
x
y
¶
→
µ
u (x, y)
v (x, y)
¶
where u, v are C1 because φ is given to be analytic. The Jacobian of this map at
(x, y) ∈B (z0, r) is
¯¯¯¯
ux (x, y)
uy (x, y)
vx (x, y)
vy (x, y)
¯¯¯¯ =
¯¯¯¯
ux (x, y)
−vx (x, y)
vx (x, y)
ux (x, y)
¯¯¯¯
= ux (x, y)2 + vx (x, y)2 =
¯¯φ′ (z)
¯¯2 ̸= 0.
This follows from a use of the Cauchy Riemann equations. Also
µ
u (x0, y0)
v (x0, y0)
¶
=
µ
0
0
¶
Therefore, by the inverse function theorem there exists an open set, V, containing
z0 and δ > 0 such that (u, v)T maps V one to one onto B (0, δ) . Thus φ is one to
one onto B (0, δ) as claimed. Applying the same argument to other points, z of V
and using the fact that φ′ (z) ̸= 0 at these points, it follows φ maps open sets to
open sets. In other words, φ−1 is continuous.
It also follows that φm maps V onto B (0, δm) . Therefore, the formula 25.1
implies that f maps the open set, V, containing z0 to an open set. This shows f (Ω)
is an open set because z0 was arbitrary. It is connected because f is continuous and
Ωis connected. Thus f (Ω) is a region. It remains to verify that φ−1 is analytic on
B (0, δ) . Since φ−1 is continuous,
lim
φ(z1)→φ(z)
φ−1 (φ (z1)) −φ−1 (φ (z))
φ (z1) −φ (z)
= lim
z1→z
z1 −z
φ (z1) −φ (z) =
1
φ′ (z).
Therefore, φ−1 is analytic as claimed.

25.2.
BRANCHES OF THE LOGARITHM
683
It only remains to verify the assertion about the case where f is one to one. If
m > 1, then e
2πi
m ̸= 1 and so for z1 ∈V,
e
2πi
m φ (z1) ̸= φ (z1) .
(25.2)
But e
2πi
m φ (z1) ∈B (0, δ) and so there exists z2 ̸= z1(since φ is one to one) such that
φ (z2) = e
2πi
m φ (z1) . But then
φ (z2)m =
³
e
2πi
m φ (z1)
´m
= φ (z1)m
implying f (z2) = f (z1) contradicting the assumption that f is one to one. Thus
m = 1 and f ′ (z) = φ′ (z) ̸= 0 on V. Since f maps open sets to open sets, it follows
that f −1 is continuous and so
¡
f −1¢′ (f (z))
=
lim
f(z1)→f(z)
f −1 (f (z1)) −f −1 (f (z))
f (z1) −f (z)
=
lim
z1→z
z1 −z
f (z1) −f (z) =
1
f ′ (z).
This proves the theorem.
One does not have to look very far to ﬁnd that this sort of thing does not hold
for functions mapping R to R. Take for example, the function f (x) = x2. Then
f (R) is neither a point nor a region. In fact f (R) fails to be open.
Corollary 25.2 Suppose in the situation of Theorem 25.1 m > 1 for the local
representation of f given in this theorem.
Then there exists δ > 0 such that if
w ∈B (f (z0) , δ) = f (V ) for V an open set containing z0, then f −1 (w) consists of
m distinct points in V. (f is m to one on V )
Proof: Let w ∈B (f (z0) , δ) . Then w = f (bz) where bz ∈V. Thus f (bz) =
f (z0) + φ (bz)m . Consider the m distinct numbers,
n
e
2kπi
m φ (bz)
om
k=1 . Then each of
these numbers is in B (0, δ) and so since φ maps V one to one onto B (0, δ) , there
are m distinct numbers in V , {zk}m
k=1 such that φ (zk) = e
2kπi
m φ (bz). Then
f (zk)
=
f (z0) + φ (zk)m = f (z0) +
³
e
2kπi
m φ (bz)
´m
=
f (z0) + e2kπiφ (bz)m = f (z0) + φ (bz)m = f (bz) = w
This proves the corollary.
25.2
Branches Of The Logarithm
The argument used in to prove the next theorem was used in the proof of the open
mapping theorem.
It is a very important result and deserves to be stated as a
theorem.

684
THE OPEN MAPPING THEOREM
Theorem 25.3 Let Ωbe a simply connected region and suppose f : Ω→C is
analytic and nonzero on Ω. Then there exists an analytic function, g such that
eg(z) = f (z) for all z ∈Ω.
Proof: The function, f ′/f is analytic on Ωand so by Corollary 24.50 there is
a primitive for f ′/f, denoted as g1. Then
¡
e−g1f
¢′ = −f ′
f e−g1f + e−g1f ′ = 0
and so since Ωis connected, it follows e−g1f equals a constant, ea+ib. Therefore,
f (z) = eg1(z)+a+ib. Deﬁne g (z) ≡g1 (z) + a + ib.
The function, g in the above theorem is called a branch of the logarithm of f
and is written as log (f (z)).
Deﬁnition 25.4 Let ρ be a ray starting at 0. Thus ρ is a straight line of inﬁnite
length extending in one direction with its initial point at 0.
A special case of the above theorem is the following.
Theorem 25.5 Let ρ be a ray starting at 0. Then there exists an analytic function,
L (z) deﬁned on C \ ρ such that
eL(z) = z.
This function, L is called a branch of the logarithm. This branch of the logarithm
satisﬁes the usual formula for logarithms, L (zw) = L (z) + L (w) provided zw /∈ρ.
Proof: C \ ρ is a simply connected region because its complement with respect
to bC is connected. Furthermore, the function, f (z) = z is not equal to zero on
C \ ρ. Therefore, by Theorem 25.3 there exists an analytic function L (z) such that
eL(z) = f (z) = z. Now consider the problem of ﬁnding a description of L (z). Each
z ∈C \ ρ can be written in a unique way in the form
z = |z| ei argθ(z)
where argθ (z) is the angle in (θ, θ + 2π) associated with z. (You could of course
have considered this to be the angle in (θ −2π, θ) associated with z or in inﬁnitely
many other open intervals of length 2π. The description of the log is not unique.)
Then letting L (z) = a + ib
z = |z| ei argθ(z) = eL(z) = eaeib
and so you can let L (z) = ln |z| + i argθ (z) .
Does L (z) satisfy the usual properties of the logarithm? That is, for z, w ∈C\ρ,
is L (zw) = L (z)+L (w)? This follows from the usual rules of exponents. You know
ez+w = ezew. (You can verify this directly or you can reduce to the case where z, w
are real. If z is a ﬁxed real number, then the equation holds for all real w. Therefore,
it must also hold for all complex w because the real line contains a limit point. Now

25.3.
MAXIMUM MODULUS THEOREM
685
for this ﬁxed w, the equation holds for all z real. Therefore, by similar reasoning,
it holds for all complex z.)
Now suppose z, w ∈C \ ρ and zw /∈ρ. Then
eL(zw) = zw, eL(z)+L(w) = eL(z)eL(w) = zw
and so L (zw) = L (z) + L (w) as claimed. This proves the theorem.
In the case where the ray is the negative real axis, it is called the principal
branch of the logarithm. Thus arg (z) is a number between −π and π.
Deﬁnition 25.6 Let log denote the branch of the logarithm which corresponds to
the ray for θ = π. That is, the ray is the negative real axis. Sometimes this is called
the principal branch of the logarithm.
25.3
Maximum Modulus Theorem
Here is another very signiﬁcant theorem known as the maximum modulus theorem
which follows immediately from the open mapping theorem.
Theorem 25.7 (maximum modulus theorem) Let Ωbe a bounded region and let
f : Ω→C be analytic and f : Ω→C continuous. Then if z ∈Ω,
|f (z)| ≤max {|f (w)| : w ∈∂Ω} .
(25.3)
If equality is achieved for any z ∈Ω, then f is a constant.
Proof: Suppose f is not a constant. Then f (Ω) is a region and so if z ∈Ω,
there exists r > 0 such that B (f (z) , r) ⊆f (Ω) . It follows there exists z1 ∈Ω
with |f (z1)| > |f (z)| . Hence max
©
|f (w)| : w ∈Ω
ª
is not achieved at any interior
point of Ω. Therefore, the point at which the maximum is achieved must lie on the
boundary of Ωand so
max {|f (w)| : w ∈∂Ω} = max
©
|f (w)| : w ∈Ω
ª
> |f (z)|
for all z ∈Ωor else f is a constant. This proves the theorem.
You can remove the assumption that Ωis bounded and give a slightly diﬀerent
version.
Theorem 25.8 Let f : Ω→C be analytic on a region, Ωand suppose B (a, r) ⊆Ω.
Then
|f (a)| ≤max
©¯¯f
¡
a + reiθ¢¯¯ : θ ∈[0, 2π]
ª
.
Equality occurs for some r > 0 and a ∈Ωif and only if f is constant in Ωhence
equality occurs for all such a, r.

686
THE OPEN MAPPING THEOREM
Proof: The claimed inequality holds by Theorem 25.7. Suppose equality in the
above is achieved for some B (a, r) ⊆Ω. Then by Theorem 25.7 f is equal to a
constant, w on B (a, r) . Therefore, the function, f (·) −w has a zero set which has
a limit point in Ωand so by Theorem 24.23 f (z) = w for all z ∈Ω.
Conversely, if f is constant, then the equality in the above inequality is achieved
for all B (a, r) ⊆Ω.
Next is yet another version of the maximum modulus principle which is in Con-
way [13]. Let Ωbe an open set.
Deﬁnition 25.9 Deﬁne ∂∞Ωto equal ∂Ωin the case where Ωis bounded and
∂Ω∪{∞} in the case where Ωis not bounded.
Deﬁnition 25.10 Let f be a complex valued function deﬁned on a set S ⊆C and
let a be a limit point of S.
lim sup
z→a |f (z)| ≡lim
r→0 {sup |f (w)| : w ∈B′ (a, r) ∩S} .
The limit exists because {sup |f (w)| : w ∈B′ (a, r) ∩S} is decreasing in r. In case
a = ∞,
lim sup
z→∞|f (z)| ≡lim
r→∞{sup |f (w)| : |w| > r, w ∈S}
Note that if lim supz→a |f (z)| ≤M and δ > 0, then there exists r > 0 such that
if z ∈B′ (a, r) ∩S, then |f (z)| < M + δ. If a = ∞, there exists r > 0 such that if
|z| > r and z ∈S, then |f (z)| < M + δ.
Theorem 25.11 Let Ωbe an open set in C and let f : Ω→C be analytic. Suppose
also that for every a ∈∂∞Ω,
lim sup
z→a |f (z)| ≤M < ∞.
Then in fact |f (z)| ≤M for all z ∈Ω.
Proof: Let δ > 0 and let H ≡{z ∈Ω: |f (z)| > M + δ} . Suppose H ̸= ∅.
Then H is an open subset of Ω. I claim that H is actually bounded.
If Ωis
bounded, there is nothing to show so assume Ωis unbounded. Then the condition
involving the lim sup implies there exists r > 0 such that if |z| > r and z ∈Ω, then
|f (z)| ≤M + δ/2. It follows H is contained in B (0, r) and so it is bounded. Now
consider the components of Ω. One of these components contains points from H.
Let this component be denoted as V and let HV ≡H ∩V. Thus HV is a bounded
open subset of V. Let U be a component of HV . First suppose U ⊆V . In this
case, it follows that on ∂U, |f (z)| = M + δ and so by Theorem 25.7 |f (z)| ≤M + δ
for all z ∈U contradicting the deﬁnition of H. Next suppose ∂U contains a point
of ∂V, a. Then in this case, a violates the condition on lim sup . Either way you
get a contradiction. Hence H = ∅as claimed. Since δ > 0 is arbitrary, this shows
|f (z)| ≤M.

25.4.
EXTENSIONS OF MAXIMUM MODULUS THEOREM
687
25.4
Extensions Of Maximum Modulus Theorem
25.4.1
Phragmˆen Lindel¨of Theorem
This theorem is an extension of Theorem 25.11. It uses a growth condition near the
extended boundary to conclude that f is bounded. I will present the version found
in Conway [13]. It seems to be more of a method than an actual theorem. There
are several versions of it.
Theorem 25.12 Let Ωbe a simply connected region in C and suppose f is ana-
lytic on Ω. Also suppose there exists a function, φ which is nonzero and uniformly
bounded on Ω. Let M be a positive number.
Now suppose ∂∞Ω= A ∪B such
that for every a ∈A, lim supz→a |f (z)| ≤M and for every b ∈B, and η > 0,
lim supz→b |f (z)| |φ (z)|η ≤M. Then |f (z)| ≤M for all z ∈Ω.
Proof: By Theorem 25.3 there exists log (φ (z)) analytic on Ω. Now deﬁne
g (z) ≡exp (η log (φ (z))) so that g (z) = φ (z)η . Now also
|g (z)| = |exp (η log (φ (z)))| = |exp (η ln |φ (z)|)| = |φ (z)|η .
Let m ≥|φ (z)| for all z ∈Ω. Deﬁne F (z) ≡f (z) g (z) m−η. Thus F is analytic
and for b ∈B,
lim sup
z→b
|F (z)| = lim sup
z→b
|f (z)| |φ (z)|η m−η ≤Mm−η
while for a ∈A,
lim sup
z→a |F (z)| ≤M.
Therefore, for α ∈∂∞Ω, lim supz→α |F (z)| ≤max (M, Mη−η) and so by Theorem
25.11, |f (z)| ≤
³
mη
|φ(z)|η
´
max (M, Mη−η) . Now let η →0 to obtain |f (z)| ≤M.
In applications, it is often the case that B = {∞}.
Now here is an interesting case of this theorem. It involves a particular form for
Ω, in this case Ω=
©
z ∈C : |arg (z)| <
π
2a
ª
where a ≥1
2.
Ω
Then ∂Ωequals the two slanted lines. Also on Ωyou can deﬁne a logarithm,
log (z) = ln |z| + i arg (z) where arg (z) is the angle associated with z between −π

688
THE OPEN MAPPING THEOREM
and π. Therefore, if c is a real number you can deﬁne zc for such z in the usual way:
zc
≡
exp (c log (z)) = exp (c [ln |z| + i arg (z)])
=
|z|c exp (ic arg (z)) = |z|c (cos (c arg (z)) + i sin (c arg (z))) .
If |c| < a, then |c arg (z)| < π
2 and so cos (c arg (z)) > 0. Therefore, for such c,
|exp (−(zc))|
=
|exp (−|z|c (cos (c arg (z)) + i sin (c arg (z))))|
=
|exp (−|z|c (cos (c arg (z))))|
which is bounded since cos (c arg (z)) > 0.
Corollary 25.13 Let Ω=
©
z ∈C : |arg (z)| <
π
2a
ª
where a ≥1
2 and suppose f is
analytic on Ωand satisﬁes lim supz→a |f (z)| ≤M on ∂Ωand suppose there are
positive constants, P, b where b < a and
|f (z)| ≤P exp
³
|z|b´
for all |z| large enough. Then |f (z)| ≤M for all z ∈Ω.
Proof: Let b < c < a and let φ (z) ≡exp (−(zc)) . Then as discussed above,
φ (z) ̸= 0 on Ωand |φ (z)| is bounded on Ω. Now
|φ (z)|η = |exp (−|z|c η (cos (c arg (z))))|
lim sup
z→∞|f (z)| |φ (z)|η ≤lim sup
z→∞
P exp
³
|z|b´
|exp (|z|c η (cos (c arg (z))))| = 0 ≤M
and so by Theorem 25.12 |f (z)| ≤M.
The following is another interesting case. This case is presented in Rudin [45]
Corollary 25.14 Let Ωbe the open set consisting of {z ∈C : a < Re z < b} and
suppose f is analytic on Ω, continuous on Ω, and bounded on Ω. Suppose also that
f (z) ≤1 on the two lines Re z = a and Re z = b. Then |f (z)| ≤1 for all z ∈Ω.
Proof: This time let φ (z) =
1
1+z−a. Thus |φ (z)| ≤1 because Re (z −a) > 0 and
φ (z) ̸= 0 for all z ∈Ω. Also, lim supz→∞|φ (z)|η = 0 for every η > 0. Therefore, if a
is a point of the sides of Ω, lim supz→a |f (z)| ≤1 while lim supz→∞|f (z)| |φ (z)|η =
0 ≤1 and so by Theorem 25.12, |f (z)| ≤1 on Ω.
This corollary yields an interesting conclusion.
Corollary 25.15 Let Ωbe the open set consisting of {z ∈C : a < Re z < b} and
suppose f is analytic on Ω, continuous on Ω, and bounded on Ω. Deﬁne
M (x) ≡sup {|f (z)| : Re z = x}
Then for x ∈(a, b).
M (x) ≤M (a)
b−x
b−a M (b)
x−a
b−a .

25.4.
EXTENSIONS OF MAXIMUM MODULUS THEOREM
689
Proof: Let ε > 0 and deﬁne
g (z) ≡(M (a) + ε)
b−z
b−a (M (b) + ε)
z−a
b−a
where for M > 0 and z ∈C, M z ≡exp (z ln (M)) . Thus g ̸= 0 and so f/g is
analytic on Ωand continuous on Ω. Also on the left side,
¯¯¯¯
f (a + iy)
g (a + iy)
¯¯¯¯ =
¯¯¯¯¯
f (a + iy)
(M (a) + ε)
b−a−iy
b−a
¯¯¯¯¯ =
¯¯¯¯¯
f (a + iy)
(M (a) + ε)
b−a
b−a
¯¯¯¯¯ ≤1
while on the right side a similar computation shows
¯¯¯ f
g
¯¯¯ ≤1 also. Therefore, by
Corollary 25.14 |f/g| ≤1 on Ω. Therefore, letting x + iy = z,
|f (z)| ≤
¯¯¯(M (a) + ε)
b−z
b−a (M (b) + ε)
z−a
b−a
¯¯¯ =
¯¯¯(M (a) + ε)
b−x
b−a (M (b) + ε)
x−a
b−a
¯¯¯
and so
M (x) ≤(M (a) + ε)
b−x
b−a (M (b) + ε)
x−a
b−a .
Since ε > 0 is arbitrary, it yields the conclusion of the corollary.
Another way of saying this is that x →ln (M (x)) is a convex function.
This corollary has an interesting application known as the Hadamard three cir-
cles theorem.
25.4.2
Hadamard Three Circles Theorem
Let 0 < R1 < R2 and suppose f is analytic on {z ∈C : R1 < |z| < R2} . Then letting
R1 < a < b < R2, note that g (z) ≡exp (z) maps the strip {z ∈C : ln a < Re z < b}
onto {z ∈C : a < |z| < b} and that in fact, g maps the line ln r + iy onto the circle
reiθ. Now let M (x) be deﬁned as above and m be deﬁned by
m (r) ≡max
θ
¯¯f
¡
reiθ¢¯¯ .
Then for a < r < b, Corollary 25.15 implies
m (r)
=
sup
y
¯¯f
¡
eln r+iy¢¯¯ = M (ln r) ≤M (ln a)
ln b−ln r
ln b−ln a M (ln b)
ln r−ln a
ln b−ln a
=
m (a)ln(b/r)/ ln(b/a) m (b)ln(r/a)/ ln(b/a)
and so
m (r)ln(b/a) ≤m (a)ln(b/r) m (b)ln(r/a) .
Taking logarithms, this yields
ln
µ b
a
¶
ln (m (r)) ≤ln
µb
r
¶
ln (m (a)) + ln
³r
a
´
ln (m (b))
which says the same as r →ln (m (r)) is a convex function of ln r.
The next example, also in Rudin [45] is very dramatic. An unbelievably weak
assumption is made on the growth of the function and still you get a uniform bound
in the conclusion.

690
THE OPEN MAPPING THEOREM
Corollary 25.16 Let Ω=
©
z ∈C : |Im (z)| < π
2
ª
. Suppose f is analytic on Ω,
continuous on Ω, and there exist constants, α < 1 and A < ∞such that
|f (z)| ≤exp (A exp (α |x|)) for z = x + iy
and
¯¯¯f
³
x ± iπ
2
´¯¯¯ ≤1
for all x ∈R. Then |f (z)| ≤1 on Ω.
Proof: This time let φ (z) = [exp (A exp (βz)) exp (A exp (−βz))]−1 where α <
β < 1. Then φ (z) ̸= 0 on Ωand for η > 0
|φ (z)|η =
1
|exp (ηA exp (βz)) exp (ηA exp (−βz))|
Now
exp (ηA exp (βz)) exp (ηA exp (−βz))
=
exp (ηA (exp (βz) + exp (−βz)))
=
exp
£
ηA
¡
cos (βy)
¡
eβx + e−βx¢
+ i sin (βy)
¡
eβx −e−βx¢¢¤
and so
|φ (z)|η =
1
exp [ηA (cos (βy) (eβx + e−βx))]
Now cos βy > 0 because β < 1 and |y| < π
2 . Therefore,
lim sup
z→∞|f (z)| |φ (z)|η ≤0 ≤1
and so by Theorem 25.12, |f (z)| ≤1.
25.4.3
Schwarz’s Lemma
This interesting lemma comes from the maximum modulus theorem. It will be used
later as part of the proof of the Riemann mapping theorem.
Lemma 25.17 Suppose F : B (0, 1) →B (0, 1) , F is analytic, and F (0) = 0. Then
for all z ∈B (0, 1) ,
|F (z)| ≤|z| ,
(25.4)
and
|F ′ (0)| ≤1.
(25.5)
If equality holds in 25.5 then there exists λ ∈C with |λ| = 1 and
F (z) = λz.
(25.6)

25.4.
EXTENSIONS OF MAXIMUM MODULUS THEOREM
691
Proof:
First note that by assumption, F (z) /z has a removable singularity at
0 if its value at 0 is deﬁned to be F ′ (0) . By the maximum modulus theorem, if
|z| < r < 1,
¯¯¯¯
F (z)
z
¯¯¯¯ ≤max
t∈[0,2π]
¯¯F
¡
reit¢¯¯
r
≤1
r .
Then letting r →1,
¯¯¯¯
F (z)
z
¯¯¯¯ ≤1
this shows 25.4 and it also veriﬁes 25.5 on taking the limit as z →0. If equality
holds in 25.5, then |F (z) /z| achieves a maximum at an interior point so F (z) /z
equals a constant, λ by the maximum modulus theorem. Since F (z) = λz, it follows
F ′ (0) = λ and so |λ| = 1.
Rudin [45] gives a memorable description of what this lemma says. It says that
if an analytic function maps the unit ball to itself, keeping 0 ﬁxed, then it must do
one of two things, either be a rotation or move all points closer to 0. (This second
part follows in case |F ′ (0)| < 1 because in this case, you must have |F (z)| ̸= |z|
and so by 25.4, |F (z)| < |z|)
25.4.4
One To One Analytic Maps On The Unit Ball
The transformation in the next lemma is of fundamental importance.
Lemma 25.18 Let α ∈B (0, 1) and deﬁne
φα (z) ≡z −α
1 −αz .
Then φα : B (0, 1) →B (0, 1) , φα : ∂B (0, 1) →∂B (0, 1) , and is one to one and
onto. Also φ−α = φ−1
α . Also
φ′
α (0) = 1 −|α|2 , φ′ (α) =
1
1 −|α|2 .
Proof: First of all, for |z| < 1/ |α| ,
φα ◦φ−α (z) ≡
³
z+α
1+αz
´
−α
1 −α
³
z+α
1+αz
´ = z
after a few computations. If I show that φα maps B (0, 1) to B (0, 1) for all |α| < 1,
this will have shown that φα is one to one and onto B (0, 1).
Consider
¯¯φα
¡
eiθ¢¯¯ . This yields
¯¯¯¯
eiθ −α
1 −αeiθ
¯¯¯¯ =
¯¯¯¯
1 −αe−iθ
1 −αeiθ
¯¯¯¯ = 1

692
THE OPEN MAPPING THEOREM
where the ﬁrst equality is obtained by multiplying by
¯¯e−iθ¯¯ = 1. Therefore, φα maps
∂B (0, 1) one to one and onto ∂B (0, 1) . Now notice that φα is analytic on B (0, 1)
because the only singularity, a pole is at z = 1/α.
By the maximum modulus
theorem, it follows
|φα (z)| < 1
whenever |z| < 1. The same is true of φ−α.
It only remains to verify the assertions about the derivatives. Long division
gives φα (z) = (−α)−1 +
³
−α+(α)−1
1−αz
´
and so
φ′
α (z)
=
(−1) (1 −αz)−2 ³
−α + (α)−1´
(−α)
=
α (1 −αz)−2 ³
−α + (α)−1´
=
(1 −αz)−2 ³
−|α|2 + 1
´
Hence the two formulas follow. This proves the lemma.
One reason these mappings are so important is the following theorem.
Theorem 25.19 Suppose f is an analytic function deﬁned on B (0, 1) and f maps
B (0, 1) one to one and onto B (0, 1) . Then there exists θ such that
f (z) = eiθφα (z)
for some α ∈B (0, 1) .
Proof: Let f (α) = 0. Then h (z) ≡f ◦φ−α (z) maps B (0, 1) one to one and
onto B (0, 1) and has the property that h (0) = 0. Therefore, by the Schwarz lemma,
|h (z)| ≤|z| .
but it is also the case that h−1 (0) = 0 and h−1 maps B (0, 1) to B (0, 1). Therefore,
the same inequality holds for h−1. Therefore,
|z| =
¯¯h−1 (h (z))
¯¯ ≤|h (z)|
and so |h (z)| = |z| . By the Schwarz lemma again, h (z) ≡f
¡
φ−α (z)
¢
= eiθz.
Letting z = φα, you get f (z) = eiθφα (z).
25.5
Exercises
1. Consider the function, g (z) = z−i
z+i. Show this is analytic on the upper half
plane, P+ and maps the upper half plane one to one and onto B (0, 1). Hint:
First show g maps the real axis to ∂B (0, 1) . This is really easy because you
end up looking at a complex number divided by its conjugate. Thus |g (z)| = 1
for z on ∂(P+) . Now show that lim supz→∞|g (z)| = 1. Then apply a version
of the maximum modulus theorem. You might note that g (z) = 1+ −2i
z+i. This
will show |g (z)| ≤1. Next pick w ∈B (0, 1) and solve g (z) = w. You just
have to show there exists a unique solution and its imaginary part is positive.

25.5.
EXERCISES
693
2. Does there exist an entire function f which maps C onto the upper half plane?
3. Letting g be the function of Problem 1 show that
¡
g−1¢′ (0) = 2. Also note
that g−1 (0) = i. Now suppose f is an analytic function deﬁned on the upper
half plane which has the property that |f (z)| ≤1 and f (i) = β where |β| < 1.
Find an upper bound to |f ′ (i)| . Also ﬁnd all functions, f which satisfy the
condition, f (i) = β, |f (z)| ≤1, and achieve this maximum value. Hint: You
could consider the function, h (z) ≡φβ ◦f ◦g−1 (z) and check the conditions
for the Schwarz lemma for this function, h.
4. This and the next two problems follow a presentation of an interesting topic
in Rudin [45]. Let φα be given in Lemma 25.18. Suppose f is an analytic
function deﬁned on B (0, 1) which satisﬁes |f (z)| ≤1. Suppose also there are
α, β ∈B (0, 1) and it is required f (α) = β. If f is such a function, show
that |f ′ (α)| ≤1−|β|2
1−|α|2 . Hint: To show this consider g = φβ ◦f ◦φ−α. Show
g (0) = 0 and |g (z)| ≤1 on B (0, 1) . Now use Lemma 25.17.
5. In Problem 4 show there exists a function, f analytic on B (0, 1) such that
f (α) = β, |f (z)| ≤0, and |f ′ (α)| = 1−|β|2
1−|α|2 . Hint: You do this by choosing
g in the above problem such that equality holds in Lemma 25.17. Thus you
need g (z) = λz where |λ| = 1 and solve g = φβ ◦f ◦φ−α for f.
6. Suppose that f : B (0, 1) →B (0, 1) and that f is analytic, one to one, and
onto with f (α) = 0. Show there exists λ, |λ| = 1 such that f (z) = λφα (z) .
This gives a diﬀerent way to look at Theorem 25.19. Hint: Let g = f −1.
Then g′ (0) f ′ (α) = 1. However, f (α) = 0 and g (0) = α. From Problem
4 with β = 0, you can conclude an inequality for |f ′ (α)| and another one
for |g′ (0)| . Then use the fact that the product of these two equals 1 which
comes from the chain rule to conclude that equality must take place. Now use
Problem 5 to obtain the form of f.
7. In Corollary 25.16 show that it is essential that α < 1. That is, show there
exists an example where the conclusion is not satisﬁed with a slightly weaker
growth condition. Hint: Consider exp (exp (z)) .
8. Suppose {fn} is a sequence of functions which are analytic on Ω, a bounded
region such that each fn is also continuous on Ω. Suppose that {fn} converges
uniformly on ∂Ω. Show that then {fn} converges uniformly on Ωand that the
function to which the sequence converges is analytic on Ωand continuous on
Ω.
9. Suppose Ωis a bounded region and there exists a point z0 ∈Ωsuch that
|f (z0)| = min
©
|f (z)| : z ∈Ω
ª
. Can you conclude f must equal a constant?
10. Suppose f is continuous on B (a, r) and analytic on B (a, r) and that f is not
constant. Suppose also |f (z)| = C ̸= 0 for all |z −a| = r. Show that there
exists α ∈B (a, r) such that f (α) = 0. Hint: If not, consider f/C and C/f.
Both would be analytic on B (a, r) and are equal to 1 on the boundary.

694
THE OPEN MAPPING THEOREM
11. Suppose f is analytic on B (0, 1) but for every a ∈∂B (0, 1) , limz→a |f (z)| =
∞. Show there exists a sequence, {zn} ⊆B (0, 1) such that limn→∞|zn| = 1
and f (zn) = 0.
25.6
Counting Zeros
The above proof of the open mapping theorem relies on the very important inverse
function theorem from real analysis. There are other approaches to this important
theorem which do not rely on the big theorems from real analysis and are more
oriented toward the use of the Cauchy integral formula and specialized techniques
from complex analysis. One of these approaches is given next which involves the
notion of “counting zeros”. The next theorem is the one about counting zeros. It
will also be used later in the proof of the Riemann mapping theorem.
Theorem 25.20 Let Ωbe an open set in C and let γ : [a, b] →Ωbe closed, con-
tinuous, bounded variation, and n (γ, z) = 0 for all z /∈Ω. Suppose also that f
is analytic on Ωhaving zeros a1, · · ·, am where the zeros are repeated according to
multiplicity, and suppose that none of these zeros are on γ∗. Then
1
2πi
Z
γ
f ′ (z)
f (z) dz =
m
X
k=1
n (γ, ak) .
Proof: Let f (z) = Qm
j=1 (z −aj) g (z) where g (z) ̸= 0 on Ω. Hence
f ′ (z)
f (z) =
m
X
j=1
1
z −aj
+ g′ (z)
g (z)
and so
1
2πi
Z
γ
f ′ (z)
f (z) dz =
m
X
j=1
n (γ, aj) +
1
2πi
Z
γ
g′ (z)
g (z) dz.
But the function, z →g′(z)
g(z) is analytic and so by Corollary 24.47, the last integral
in the above expression equals 0. Therefore, this proves the theorem.
The following picture is descriptive of the situation described in the next theo-
rem.
Ω
f
q
γ
a1
q
qa2
a3q
f(γ([a, b]))
αq
Theorem 25.21 Let Ωbe a region, let γ : [a, b] →Ωbe closed continuous, and
bounded variation such that n (γ, z) = 0 for all z /∈Ω. Also suppose f : Ω→C

25.6.
COUNTING ZEROS
695
is analytic and that α /∈f (γ∗) . Then f ◦γ : [a, b] →C is continuous, closed,
and bounded variation. Also suppose {a1, · · ·, am} = f −1 (α) where these points are
counted according to their multiplicities as zeros of the function f −α Then
n (f ◦γ, α) =
m
X
k=1
n (γ, ak) .
Proof: It is clear that f ◦γ is continuous. It only remains to verify that it is of
bounded variation. Suppose ﬁrst that γ∗⊆B ⊆B ⊆Ωwhere B is a ball. Then
|f (γ (t)) −f (γ (s))| =
¯¯¯¯
Z 1
0
f ′ (γ (s) + λ (γ (t) −γ (s))) (γ (t) −γ (s)) dλ
¯¯¯¯
≤
C |γ (t) −γ (s)|
where C ≥max
©
|f ′ (z)| : z ∈B
ª
. Hence, in this case,
V (f ◦γ, [a, b]) ≤CV (γ, [a, b]) .
Now let ε denote the distance between γ∗and C \ Ω. Since γ∗is compact, ε > 0.
By uniform continuity there exists δ =
b−a
p
for p a positive integer such that if
|s −t| < δ, then |γ (s) −γ (t)| < ε
2. Then
γ ([t, t + δ]) ⊆B
³
γ (t) , ε
2
´
⊆Ω.
Let C ≥max
n
|f ′ (z)| : z ∈∪p
j=1B
¡
γ (tj) , ε
2
¢o
where tj ≡j
p (b −a) + a. Then from
what was just shown,
V (f ◦γ, [a, b])
≤
p−1
X
j=0
V (f ◦γ, [tj, tj+1])
≤
C
p−1
X
j=0
V (γ, [tj, tj+1]) < ∞
showing that f ◦γ is bounded variation as claimed. Now from Theorem 24.42 there
exists η ∈C1 ([a, b]) such that
η (a) = γ (a) = γ (b) = η (b) , η ([a, b]) ⊆Ω,
and
n (η, ak) = n (γ, ak) , n (f ◦γ, α) = n (f ◦η, α)
(25.7)
for k = 1, · · ·, m. Then
n (f ◦γ, α) = n (f ◦η, α)

696
THE OPEN MAPPING THEOREM
=
1
2πi
Z
f◦η
dw
w −α
=
1
2πi
Z b
a
f ′ (η (t))
f (η (t)) −αη′ (t) dt
=
1
2πi
Z
η
f ′ (z)
f (z) −αdz
=
m
X
k=1
n (η, ak)
By Theorem 25.20. By 25.7, this equals Pm
k=1 n (γ, ak) which proves the theorem.
The next theorem is incredible and is very interesting for its own sake. The
following picture is descriptive of the situation of this theorem.
f
q
t a
t a1
t a2
t a3
t a4
B(a, ϵ)
sz s α
B(α, δ)
Theorem 25.22 Let f : B (a, R) →C be analytic and let
f (z) −α = (z −a)m g (z) , ∞> m ≥1
where g (z) ̸= 0 in B (a, R) . (f (z) −α has a zero of order m at z = a.) Then there
exist ε, δ > 0 with the property that for each z satisfying 0 < |z −α| < δ, there exist
points,
{a1, · · ·, am} ⊆B (a, ε) ,
such that
f −1 (z) ∩B (a, ε) = {a1, · · ·, am}
and each ak is a zero of order 1 for the function f (·) −z.
Proof: By Theorem 24.23 f is not constant on B (a, R) because it has a zero
of order m. Therefore, using this theorem again, there exists ε > 0 such that
B (a, 2ε) ⊆B (a, R) and there are no solutions to the equation f (z) −α = 0 for
z ∈B (a, 2ε) except a. Also assume ε is small enough that for 0 < |z −a| ≤2ε,
f ′ (z) ̸= 0. This can be done since otherwise, a would be a limit point of a sequence
of points, zn, having f ′ (zn) = 0 which would imply, by Theorem 24.23 that f ′ = 0
on B (a, R) , contradicting the assumption that f −α has a zero of order m and is
therefore not constant. Thus the situation is described by the following picture.

25.6.
COUNTING ZEROS
697
f −α ̸= 0
f ′ ̸= 0
2ε
s
¡
¡
¡
¡
ª
Now pick γ (t) = a + εeit, t ∈[0, 2π] . Then α /∈f (γ∗) so there exists δ > 0 with
B (α, δ) ∩f (γ∗) = ∅.
(25.8)
Therefore, B (α, δ) is contained on one component of C \ f (γ ([0, 2π])) . Therefore,
n (f ◦γ, α) = n (f ◦γ, z) for all z ∈B (α, δ) . Now consider f restricted to B (a, 2ε) .
For z ∈B (α, δ) , f −1 (z) must consist of a ﬁnite set of points because f ′ (w) ̸= 0
for all w in B (a, 2ε) \ {a} implying that the zeros of f (·) −z in B (a, 2ε) have no
limit point. Since B (a, 2ε) is compact, this means there are only ﬁnitely many. By
Theorem 25.21,
n (f ◦γ, z) =
p
X
k=1
n (γ, ak)
(25.9)
where {a1, · · ·, ap} = f −1 (z) . Each point, ak of f −1 (z) is either inside the circle
traced out by γ, yielding n (γ, ak) = 1, or it is outside this circle yielding n (γ, ak) =
0 because of 25.8. It follows the sum in 25.9 reduces to the number of points of
f −1 (z) which are contained in B (a, ε) . Thus, letting those points in f −1 (z) which
are contained in B (a, ε) be denoted by {a1, · · ·, ar}
n (f ◦γ, α) = n (f ◦γ, z) = r.
Also, by Theorem 25.20, m = n (f ◦γ, α) because a is a zero of f −α of order m.
Therefore, for z ∈B (α, δ)
m = n (f ◦γ, α) = n (f ◦γ, z) = r
It is required to show r = m, the order of the zero of f −α. Therefore, r = m. Each
of these ak is a zero of order 1 of the function f (·) −z because f ′ (ak) ̸= 0. This
proves the theorem.
This is a very fascinating result partly because it implies that for values of f
near a value, α, at which f (·) −α has a zero of order m for m > 1, the inverse
image of these values includes at least m points, not just one. Thus the topological
properties of the inverse image changes radically. This theorem also shows that
f (B (a, ε)) ⊇B (α, δ) .
Theorem 25.23 (open mapping theorem)
Let Ωbe a region and f : Ω→C
be analytic. Then f (Ω) is either a point or a region. If f is one to one, then
f −1 : f (Ω) →Ωis analytic.

698
THE OPEN MAPPING THEOREM
Proof: If f is not constant, then for every α ∈f (Ω) , it follows from Theorem
24.23 that f (·) −α has a zero of order m < ∞and so from Theorem 25.22 for each
a ∈Ωthere exist ε, δ > 0 such that f (B (a, ε)) ⊇B (α, δ) which clearly implies
that f maps open sets to open sets. Therefore, f (Ω) is open, connected because f
is continuous. If f is one to one, Theorem 25.22 implies that for every α ∈f (Ω)
the zero of f (·) −α is of order 1. Otherwise, that theorem implies that for z near
α, there are m points which f maps to z contradicting the assumption that f is one
to one. Therefore, f ′ (z) ̸= 0 and since f −1 is continuous, due to f being an open
map, it follows
¡
f −1¢′ (f (z))
=
lim
f(z1)→f(z)
f −1 (f (z1)) −f −1 (f (z))
f (z1) −f (z)
=
lim
z1→z
z1 −z
f (z1) −f (z) =
1
f ′ (z).
This proves the theorem.
25.7
An Application To Linear Algebra
Gerschgorin’s theorem gives a convenient way to estimate eigenvalues of a matrix
from easy to obtain information.
For A an n × n matrix, denote by σ (A) the
collection of all eigenvalues of A.
Theorem 25.24 Let A be an n × n matrix.
Consider the n Gerschgorin discs
deﬁned as
Di ≡


λ ∈C : |λ −aii| ≤
X
j̸=i
|aij|


.
Then every eigenvalue is contained in some Gerschgorin disc.
This theorem says to add up the absolute values of the entries of the ith row
which are oﬀthe main diagonal and form the disc centered at aii having this radius.
The union of these discs contains σ (A) .
Proof: Suppose Ax = λx where x ̸= 0. Then for A = (aij)
X
j̸=i
aijxj = (λ −aii) xi.
Therefore, if we pick k such that |xk| ≥|xj| for all xj, it follows that |xk| ̸= 0 since
|x| ̸= 0 and
|xk|
X
j̸=k
|akj| ≥
X
j̸=k
|akj| |xj| ≥|λ −akk| |xk| .
Now dividing by |xk| we see that λ is contained in the kth Gerschgorin disc.

25.7.
AN APPLICATION TO LINEAR ALGEBRA
699
More can be said using the theory about counting zeros. To begin with the
distance between two n × n matrices, A = (aij) and B = (bij) as follows.
||A −B||2 ≡
X
ij
|aij −bij|2 .
Thus two matrices are close if and only if their corresponding entries are close.
Let A be an n × n matrix. Recall the eigenvalues of A are given by the zeros
of the polynomial, pA (z) = det (zI −A) where I is the n × n identity. Then small
changes in A will produce small changes in pA (z) and p′
A (z) . Let γk denote a very
small closed circle which winds around zk, one of the eigenvalues of A, in the counter
clockwise direction so that n (γk, zk) = 1. This circle is to enclose only zk and is
to have no other eigenvalue on it. Then apply Theorem 25.20. According to this
theorem
1
2πi
Z
γ
p′
A (z)
pA (z)dz
is always an integer equal to the multiplicity of zk as a root of pA (t) . Therefore,
small changes in A result in no change to the above contour integral because it
must be an integer and small changes in A result in small changes in the integral.
Therefore whenever every entry of the matrix B is close enough to the corresponding
entry of the matrix A, the two matrices have the same number of zeros inside γk
under the usual convention that zeros are to be counted according to multiplicity. By
making the radius of the small circle equal to ε where ε is less than the minimum
distance between any two distinct eigenvalues of A, this shows that if B is close
enough to A, every eigenvalue of B is closer than ε to some eigenvalue of A. The
next theorem is about continuous dependence of eigenvalues.
Theorem 25.25 If λ is an eigenvalue of A, then if ||B −A|| is small enough, some
eigenvalue of B will be within ε of λ.
Consider the situation that A (t) is an n × n matrix and that t →A (t) is
continuous for t ∈[0, 1] .
Lemma 25.26 Let λ (t) ∈σ (A (t)) for t < 1 and let Σt = ∪s≥tσ (A (s)) . Also let
Kt be the connected component of λ (t) in Σt. Then there exists η > 0 such that
Kt ∩σ (A (s)) ̸= ∅for all s ∈[t, t + η] .
Proof: Denote by D (λ (t) , δ) the disc centered at λ (t) having radius δ > 0,
with other occurrences of this notation being deﬁned similarly. Thus
D (λ (t) , δ) ≡{z ∈C : |λ (t) −z| ≤δ} .
Suppose δ > 0 is small enough that λ (t) is the only element of σ (A (t)) contained
in D (λ (t) , δ) and that pA(t) has no zeroes on the boundary of this disc. Then by
continuity, and the above discussion and theorem, there exists η > 0, t+η < 1, such
that for s ∈[t, t + η] , pA(s) also has no zeroes on the boundary of this disc and that

700
THE OPEN MAPPING THEOREM
A (s) has the same number of eigenvalues, counted according to multiplicity, in the
disc as A (t) . Thus σ (A (s)) ∩D (λ (t) , δ) ̸= ∅for all s ∈[t, t + η] . Now let
H =
[
s∈[t,t+η]
σ (A (s)) ∩D (λ (t) , δ) .
I will show H is connected. Suppose not. Then H = P ∪Q where P, Q are separated
and λ (t) ∈P. Let
s0 ≡inf {s : λ (s) ∈Q for some λ (s) ∈σ (A (s))} .
There exists λ (s0) ∈σ (A (s0)) ∩D (λ (t) , δ) . If λ (s0) /∈Q, then from the above
discussion there are
λ (s) ∈σ (A (s)) ∩Q
for s > s0 arbitrarily close to λ (s0) . Therefore, λ (s0) ∈Q which shows that s0 > t
because λ (t) is the only element of σ (A (t)) in D (λ (t) , δ) and λ (t) ∈P. Now let
sn ↑s0. Then λ (sn) ∈P for any
λ (sn) ∈σ (A (sn)) ∩D (λ (t) , δ)
and from the above discussion, for some choice of sn →s0, λ (sn) →λ (s0) which
contradicts P and Q separated and nonempty. Since P is nonempty, this shows
Q = ∅. Therefore, H is connected as claimed. But Kt ⊇H and so Kt∩σ (A (s)) ̸= ∅
for all s ∈[t, t + η] . This proves the lemma.
The following is the necessary theorem.
Theorem 25.27 Suppose A (t) is an n×n matrix and that t →A (t) is continuous
for t ∈[0, 1] . Let λ (0) ∈σ (A (0)) and deﬁne Σ ≡∪t∈[0,1]σ (A (t)) . Let Kλ(0) = K0
denote the connected component of λ (0) in Σ. Then K0 ∩σ (A (t)) ̸= ∅for all
t ∈[0, 1] .
Proof: Let S ≡{t ∈[0, 1] : K0 ∩σ (A (s)) ̸= ∅for all s ∈[0, t]} . Then 0 ∈S.
Let t0 = sup (S) . Say σ (A (t0)) = λ1 (t0) , · · ·, λr (t0) . I claim at least one of these
is a limit point of K0 and consequently must be in K0 which will show that S
has a last point. Why is this claim true? Let sn ↑t0 so sn ∈S. Now let the discs,
D (λi (t0) , δ) , i = 1, ···, r be disjoint with pA(t0) having no zeroes on γi the boundary
of D (λi (t0) , δ) . Then for n large enough it follows from Theorem 25.20 and the
discussion following it that σ (A (sn)) is contained in ∪r
i=1D (λi (t0) , δ). Therefore,
K0 ∩(σ (A (t0)) + D (0, δ)) ̸= ∅for all δ small enough. This requires at least one of
the λi (t0) to be in K0. Therefore, t0 ∈S and S has a last point.
Now by Lemma 25.26, if t0 < 1, then K0∪Kt would be a strictly larger connected
set containing λ (0) . (The reason this would be strictly larger is that K0∩σ (A (s)) =
∅for some s ∈(t, t + η) while Kt ∩σ (A (s)) ̸= ∅for all s ∈[t, t + η].) Therefore,
t0 = 1 and this proves the theorem.
The following is an interesting corollary of the Gerschgorin theorem.

25.7.
AN APPLICATION TO LINEAR ALGEBRA
701
Corollary 25.28 Suppose one of the Gerschgorin discs, Di is disjoint from the
union of the others. Then Di contains an eigenvalue of A. Also, if there are n
disjoint Gerschgorin discs, then each one contains an eigenvalue of A.
Proof: Denote by A (t) the matrix
¡
at
ij
¢
where if i ̸= j, at
ij = taij and at
ii = aii.
Thus to get A (t) we multiply all non diagonal terms by t. Let t ∈[0, 1] . Then
A (0) = diag (a11, · · ·, ann) and A (1) = A. Furthermore, the map, t →A (t) is
continuous. Denote by Dt
j the Gerschgorin disc obtained from the jth row for the
matrix, A (t). Then it is clear that Dt
j ⊆Dj the jth Gerschgorin disc for A. Then
aii is the eigenvalue for A (0) which is contained in the disc, consisting of the single
point aii which is contained in Di. Letting K be the connected component in Σ for
Σ deﬁned in Theorem 25.27 which is determined by aii, it follows by Gerschgorin’s
theorem that K ∩σ (A (t)) ⊆∪n
j=1Dt
j ⊆∪n
j=1Dj = Di ∪(∪j̸=iDj) and also, since
K is connected, there are no points of K in both Di and (∪j̸=iDj) . Since at least
one point of K is in Di,(aii) it follows all of K must be contained in Di. Now by
Theorem 25.27 this shows there are points of K ∩σ (A) in Di. The last assertion
follows immediately.
Actually, this can be improved slightly. It involves the following lemma.
Lemma 25.29 In the situation of Theorem 25.27 suppose λ (0) = K0 ∩σ (A (0))
and that λ (0) is a simple root of the characteristic equation of A (0). Then for all
t ∈[0, 1] ,
σ (A (t)) ∩K0 = λ (t)
where λ (t) is a simple root of the characteristic equation of A (t) .
Proof: Let S ≡
{t ∈[0, 1] : K0 ∩σ (A (s)) = λ (s) , a simple eigenvalue for all s ∈[0, t]} .
Then 0 ∈S so it is nonempty. Let t0 = sup (S) and suppose λ1 ̸= λ2 are two
elements of σ (A (t0)) ∩K0. Then choosing η > 0 small enough, and letting Di be
disjoint discs containing λi respectively, similar arguments to those of Lemma 25.26
imply
Hi ≡∪s∈[t0−η,t0]σ (A (s)) ∩Di
is a connected and nonempty set for i = 1, 2 which would require that Hi ⊆K0.
But then there would be two diﬀerent eigenvalues of A (s) contained in K0, contrary
to the deﬁnition of t0. Therefore, there is at most one eigenvalue, λ (t0) ∈K0 ∩
σ (A (t0)) . The possibility that it could be a repeated root of the characteristic
equation must be ruled out. Suppose then that λ (t0) is a repeated root of the
characteristic equation. As before, choose a small disc, D centered at λ (t0) and η
small enough that
H ≡∪s∈[t0−η,t0]σ (A (s)) ∩D
is a nonempty connected set containing either multiple eigenvalues of A (s) or else a
single repeated root to the characteristic equation of A (s) . But since H is connected
and contains λ (t0) it must be contained in K0 which contradicts the condition for

702
THE OPEN MAPPING THEOREM
s ∈S for all these s ∈[t0 −η, t0] . Therefore, t0 ∈S as hoped. If t0 < 1, there exists
a small disc centered at λ (t0) and η > 0 such that for all s ∈[t0, t0 + η] , A (s) has
only simple eigenvalues in D and the only eigenvalues of A (s) which could be in K0
are in D. (This last assertion follows from noting that λ (t0) is the only eigenvalue
of A (t0) in K0 and so the others are at a positive distance from K0. For s close
enough to t0, the eigenvalues of A (s) are either close to these eigenvalues of A (t0)
at a positive distance from K0 or they are close to the eigenvalue, λ (t0) in which
case it can be assumed they are in D.) But this shows that t0 is not really an upper
bound to S. Therefore, t0 = 1 and the lemma is proved.
With this lemma, the conclusion of the above corollary can be improved.
Corollary 25.30 Suppose one of the Gerschgorin discs, Di is disjoint from the
union of the others. Then Di contains exactly one eigenvalue of A and this eigen-
value is a simple root to the characteristic polynomial of A.
Proof: In the proof of Corollary 25.28, ﬁrst note that aii is a simple root of A (0)
since otherwise the ith Gerschgorin disc would not be disjoint from the others. Also,
K, the connected component determined by aii must be contained in Di because it
is connected and by Gerschgorin’s theorem above, K ∩σ (A (t)) must be contained
in the union of the Gerschgorin discs. Since all the other eigenvalues of A (0) , the
ajj, are outside Di, it follows that K ∩σ (A (0)) = aii. Therefore, by Lemma 25.29,
K ∩σ (A (1)) = K ∩σ (A) consists of a single simple eigenvalue. This proves the
corollary.
Example 25.31 Consider the matrix,


5
1
0
1
1
1
0
1
0


The Gerschgorin discs are D (5, 1) , D (1, 2) , and D (0, 1) . Then D (5, 1) is dis-
joint from the other discs. Therefore, there should be an eigenvalue in D (5, 1) .
The actual eigenvalues are not easy to ﬁnd. They are the roots of the characteristic
equation, t3 −6t2 + 3t + 5 = 0. The numerical values of these are −. 669 66, 1. 423 1,
and 5. 246 55, verifying the predictions of Gerschgorin’s theorem.
25.8
Exercises
1. Use Theorem 25.20 to give an alternate proof of the fundamental theorem
of algebra. Hint: Take a contour of the form γr = reit where t ∈[0, 2π] .
Consider
R
γr
p′(z)
p(z) dz and consider the limit as r →∞.
2. Let M be an n × n matrix. Recall that the eigenvalues of M are given by the
zeros of the polynomial, pM (z) = det (M −zI) where I is the n × n identity.
Formulate a theorem which describes how the eigenvalues depend on small

25.8.
EXERCISES
703
changes in M. Hint: You could deﬁne a norm on the space of n × n matrices
as ||M|| ≡tr (MM ∗)1/2 where M ∗is the conjugate transpose of M. Thus
||M|| =

X
j,k
|Mjk|2


1/2
.
Argue that small changes will produce small changes in pM (z) . Then apply
Theorem 25.20 using γk a very small circle surrounding zk, the kth eigenvalue.
3. Suppose that two analytic functions deﬁned on a region are equal on some
set, S which contains a limit point. (Recall p is a limit point of S if every
open set which contains p, also contains inﬁnitely many points of S. ) Show
the two functions coincide. We deﬁned ez ≡ex (cos y + i sin y) earlier and we
showed that ez, deﬁned this way was analytic on C. Is there any other way
to deﬁne ez on all of C such that the function coincides with ex on the real
axis?
4. You know various identities for real valued functions. For example cosh2 x −
sinh2 x = 1. If you deﬁne cosh z ≡ez+e−z
2
and sinh z ≡ez−e−z
2
, does it follow
that
cosh2 z −sinh2 z = 1
for all z ∈C? What about
sin (z + w) = sin z cos w + cos z sin w?
Can you verify these sorts of identities just from your knowledge about what
happens for real arguments?
5. Was it necessary that U be a region in Theorem 24.23?
Would the same
conclusion hold if U were only assumed to be an open set? Why? What
about the open mapping theorem? Would it hold if U were not a region?
6. Let f : U →C be analytic and one to one. Show that f ′ (z) ̸= 0 for all z ∈U.
Does this hold for a function of a real variable?
7. We say a real valued function, u is subharmonic if uxx+uyy ≥0. Show that if u
is subharmonic on a bounded region, (open connected set) U, and continuous
on U and u ≤m on ∂U, then u ≤m on U. Hint: If not, u achieves its
maximum at (x0, y0) ∈U. Let u (x0, y0) > m + δ where δ > 0. Now consider
uε (x, y) = εx2 + u (x, y) where ε is small enough that 0 < εx2 < δ for all
(x, y) ∈U. Show that uε also achieves its maximum at some point of U and
that therefore, uεxx + uεyy ≤0 at that point implying that uxx + uyy ≤−ε,
a contradiction.
8. If u is harmonic on some region, U, show that u coincides locally with the
real part of an analytic function and that therefore, u has inﬁnitely many

704
THE OPEN MAPPING THEOREM
derivatives on U. Hint:
Consider the case where 0 ∈U. You can always
reduce to this case by a suitable translation. Now let B (0, r) ⊆U and use
the Schwarz formula to obtain an analytic function whose real part coincides
with u on ∂B (0, r) . Then use Problem 7.
9. Show the solution to the Dirichlet problem of Problem 8 on Page 656 is unique.
You need to formulate this precisely and then prove uniqueness.

Residues
Deﬁnition 26.1 The residue of f at an isolated singularity α which is a pole,
written res (f, α) is the coeﬃcient of (z −α)−1 where
f (z) = g (z) +
m
X
k=1
bk
(z −α)k .
Thus res (f, α) = b1 in the above.
At this point, recall Corollary 24.47 which is stated here for convenience.
Corollary 26.2 Let Ωbe an open set and let γk : [ak, bk] →Ω, k = 1, · · ·, m, be
closed, continuous and of bounded variation. Suppose also that
m
X
k=1
n (γk, z) = 0
for all z /∈Ω. Then if f : Ω→C is analytic,
m
X
k=1
Z
γk
f (w) dw = 0.
The following theorem is called the residue theorem. Note the resemblance to
Corollary 24.47.
Theorem 26.3 Let Ωbe an open set and let γk : [ak, bk] →Ω, k = 1, · · ·, m, be
closed, continuous and of bounded variation. Suppose also that
m
X
k=1
n (γk, z) = 0
for all z /∈Ω. Then if f : Ω→bC is meromorphic such that no γ∗
k contains any poles
of f,
1
2πi
m
X
k=1
Z
γk
f (w) dw =
X
α∈A
res (f, α)
m
X
k=1
n (γk, α)
(26.1)
705

706
RESIDUES
where here A denotes the set of poles of f in Ω. The sum on the right is a ﬁnite
sum.
Proof: First note that there are at most ﬁnitely many α which are not in
the unbounded component of C \ ∪m
k=1γk ([ak, bk]) . Thus there exists a ﬁnite set,
{α1, · · ·, αN} ⊆A such that these are the only possibilities for which Pn
k=1 n (γk, α)
might not equal zero. Therefore, 26.1 reduces to
1
2πi
m
X
k=1
Z
γk
f (w) dw =
N
X
j=1
res (f, αj)
n
X
k=1
n (γk, αj)
and it is this last equation which is established. Near αj,
f (z) = gj (z) +
mj
X
r=1
bj
r
(z −αj)r ≡gj (z) + Qj (z) .
where gj is analytic at and near αj. Now deﬁne
G (z) ≡f (z) −
N
X
j=1
Qj (z) .
It follows that G (z) has a removable singularity at each αj. Therefore, by Corollary
24.47,
0 =
m
X
k=1
Z
γk
G (z) dz =
m
X
k=1
Z
γk
f (z) dz −
N
X
j=1
m
X
k=1
Z
γk
Qj (z) dz.
Now
m
X
k=1
Z
γk
Qj (z) dz
=
m
X
k=1
Z
γk
Ã
bj
1
(z −αj) +
mj
X
r=2
bj
r
(z −αj)r
!
dz
=
m
X
k=1
Z
γk
bj
1
(z −αj)dz ≡
m
X
k=1
n (γk, αj) res (f, αj) (2πi) .
Therefore,
m
X
k=1
Z
γk
f (z) dz
=
N
X
j=1
m
X
k=1
Z
γk
Qj (z) dz
=
N
X
j=1
m
X
k=1
n (γk, αj) res (f, αj) (2πi)
=
2πi
N
X
j=1
res (f, αj)
m
X
k=1
n (γk, αj)
=
(2πi)
X
α∈A
res (f, α)
m
X
k=1
n (γk, α)

707
which proves the theorem.
The following is an important example. This example can also be done by real
variable methods and there are some who think that real variable methods are
always to be preferred to complex variable methods. However, I will use the above
theorem to work this example.
Example 26.4 Find limR→∞
R R
−R
sin(x)
x
dx
Things are easier if you write it as
lim
R→∞
1
i
ÃZ −R−1
−R
eix
x dx +
Z R
R−1
eix
x dx
!
.
This gives the same answer because cos (x) /x is odd. Consider the following contour
in which the orientation involves counterclockwise motion exactly once around.
−R
R
−R−1
R−1
Denote by γR−1 the little circle and γR the big one. Then on the inside of this
contour there are no singularities of eiz/z and it is contained in an open set with
the property that the winding number with respect to this contour about any point
not in the open set equals zero. By Theorem 24.22
1
i
ÃZ −R−1
−R
eix
x dx +
Z
γR−1
eiz
z dz +
Z R
R−1
eix
x dx +
Z
γR
eiz
z dz
!
= 0
(26.2)
Now
¯¯¯¯¯
Z
γR
eiz
z dz
¯¯¯¯¯ =
¯¯¯¯
Z π
0
eR(i cos θ−sin θ)idθ
¯¯¯¯ ≤
Z π
0
e−R sin θdθ
and this last integral converges to 0 by the dominated convergence theorem. Now
consider the other circle. By the dominated convergence theorem again,
Z
γR−1
eiz
z dz =
Z 0
π
eR−1(i cos θ−sin θ)idθ →−iπ

708
RESIDUES
as R →∞. Then passing to the limit in 26.2,
lim
R→∞
Z R
−R
sin (x)
x
dx
=
lim
R→∞
1
i
ÃZ −R−1
−R
eix
x dx +
Z R
R−1
eix
x dx
!
=
lim
R→∞
1
i
Ã
−
Z
γR−1
eiz
z dz −
Z
γR
eiz
z dz
!
= −1
i (−iπ) = π.
Example 26.5 Find limR→∞
R R
−R eixt sin x
x dx. Note this is essentially ﬁnding the
inverse Fourier transform of the function, sin (x) /x.
This equals
lim
R→∞
Z R
−R
(cos (xt) + i sin (xt)) sin (x)
x
dx
=
lim
R→∞
Z R
−R
cos (xt) sin (x)
x
dx
=
lim
R→∞
Z R
−R
cos (xt) sin (x)
x
dx
=
lim
R→∞
1
2
Z R
−R
sin (x (t + 1)) + sin (x (1 −t))
x
dx
Let t ̸= 1, −1. Then changing variables yields
lim
R→∞
Ã
1
2
Z R(1+t)
−R(1+t)
sin (u)
u
du + 1
2
Z R(1−t)
−R(1−t)
sin (u)
u
du
!
.
In case |t| < 1 Example 26.4 implies this limit is π. However, if t > 1 the limit
equals 0 and this is also the case if t < −1. Summarizing,
lim
R→∞
Z R
−R
eixt sin x
x
dx =
½
π if |t| < 1
0 if |t| > 1
.
26.1
Rouche’s Theorem And The Argument Prin-
ciple
26.1.1
Argument Principle
A simple closed curve is just one which is homeomorphic to the unit circle. The
Jordan Curve theorem states that every simple closed curve in the plane divides
the plane into exactly two connected components, one bounded and the other un-
bounded. This is a very hard theorem to prove. However, in most applications the

26.1.
ROUCHE’S THEOREM AND THE ARGUMENT PRINCIPLE
709
conclusion is obvious. Nevertheless, to avoid using this big topological result and
to attain some extra generality, I will state the following theorem in terms of the
winding number to avoid using it. This theorem is called the argument principle.
First recall that f has a zero of order m at α if f (z) = g (z) (z −α)m where g is
an analytic function which is not equal to zero at α. This is equivalent to having
f (z) = P∞
k=m ak (z −α)k for z near α where am ̸= 0. Also recall that f has a pole
of order m at α if for z near α, f (z) is of the form
f (z) = h (z) +
m
X
k=1
bk
(z −α)k
(26.3)
where bm ̸= 0 and h is a function analytic near α.
Theorem 26.6 (argument principle) Let f be meromorphic in Ω. Also suppose γ∗
is a closed bounded variation curve containing none of the poles or zeros of f with
the property that for all z /∈Ω, n (γ, z) = 0 and for all z ∈Ω, n (γ, z) either equals 0
or 1. Now let {p1, · · ·, pm} and {z1, · · ·, zn} be respectively the poles and zeros for
which the winding number of γ about these points equals 1. Let zk be a zero of order
rk and let pk be a pole of order lk. Then
1
2πi
Z
γ
f ′ (z)
f (z) dz =
n
X
k=1
rk −
m
X
k=1
lk
Proof: This theorem follows from computing the residues of f ′/f. It has residues
at poles and zeros. I will do this now. First suppose f has a pole of order p at α.
Then f has the form given in 26.3. Therefore,
f ′ (z)
f (z)
=
h′ (z) −Pp
k=1
kbk
(z−α)k+1
h (z) + Pp
k=1
bk
(z−α)k
=
h′ (z) (z −α)p −Pp−1
k=1 kbk (z −α)−k−1+p −
pbp
(z−α)
h (z) (z −α)p + Pp−1
k=1 bk (z −α)p−k + bp
This is of the form
=
bp
s (z) + bp
r (z) −
pbp
(z−α)
bp
=
bp
s (z) + bp
µr (z)
bp
−
p
(z −α)
¶
where s (α) = r (α) = 0. From this, it is clear res (f ′/f, α) = −p, the order of the
pole.
Next suppose f has a zero of order p at α. Then
f ′ (z)
f (z) =
P∞
k=p akk (z −α)k−1
P∞
k=p ak (z −α)k
=
P∞
k=p akk (z −α)k−1−p
P∞
k=p ak (z −α)k−p
and from this it is clear res (f ′/f) = p, the order of the zero. The conclusion of this
theorem now follows from Theorem 26.3.

710
RESIDUES
One can also generalize the theorem to the case where there are many closed
curves involved. This is proved in the same way as the above.
Theorem 26.7 (argument principle) Let f be meromorphic in Ωand let γk :
[ak, bk] →Ω, k = 1, · · ·, m, be closed, continuous and of bounded variation. Suppose
also that
m
X
k=1
n (γk, z) = 0
and for all z /∈Ωand for z ∈Ω, Pm
k=1 n (γk, z) either equals 0 or 1. Now let
{p1, · · ·, pm} and {z1, · · ·, zn} be respectively the poles and zeros for which the above
sum of winding numbers equals 1. Let zk be a zero of order rk and let pk be a pole
of order lk. Then
1
2πi
Z
γ
f ′ (z)
f (z) dz =
n
X
k=1
rk −
m
X
k=1
lk
There is also a simple extension of this important principle which I found in
[27].
Theorem 26.8 (argument principle) Let f be meromorphic in Ω. Also suppose γ∗
is a closed bounded variation curve with the property that for all z /∈Ω, n (γ, z) = 0
and for all z ∈Ω, n (γ, z) either equals 0 or 1. Now let {p1, · · ·, pm} and {z1, · · ·, zn}
be respectively the poles and zeros for which the winding number of γ about these
points equals 1 listed according to multiplicity. Thus if there is a pole of order m
there will be this value repeated m times in the list for the poles. Also let g (z) be
an analytic function. Then
1
2πi
Z
γ
g (z) f ′ (z)
f (z) dz =
n
X
k=1
g (zk) −
m
X
k=1
g (pk)
Proof: This theorem follows from computing the residues of g (f ′/f) . It has
residues at poles and zeros. I will do this now. First suppose f has a pole of order
m at α. Then f has the form given in 26.3. Therefore,
g (z) f ′ (z)
f (z)
=
g (z)
³
h′ (z) −Pm
k=1
kbk
(z−α)k+1
´
h (z) + Pm
k=1
bk
(z−α)k
=
g (z)
h′ (z) (z −α)m −Pm−1
k=1 kbk (z −α)−k−1+m −
mbm
(z−α)
h (z) (z −α)m + Pm−1
k=1 bk (z −α)m−k + bm
From this, it is clear res (g (f ′/f) , α) = −mg (α) , where m is the order of the pole.
Thus α would have been listed m times in the list of poles. Hence the residue at
this point is equivalent to adding −g (α) m times.

26.1.
ROUCHE’S THEOREM AND THE ARGUMENT PRINCIPLE
711
Next suppose f has a zero of order m at α. Then
g (z) f ′ (z)
f (z) = g (z)
P∞
k=m akk (z −α)k−1
P∞
k=m ak (z −α)k
= g (z)
P∞
k=m akk (z −α)k−1−m
P∞
k=m ak (z −α)k−m
and from this it is clear res (g (f ′/f)) = g (α) m, where m is the order of the zero.
The conclusion of this theorem now follows from the residue theorem, Theorem
26.3.
The way people usually apply these theorems is to suppose γ∗is a simple closed
bounded variation curve, often a circle. Thus it has an inside and an outside, the
outside being the unbounded component of C\γ∗. The orientation of the curve is
such that you go around it once in the counterclockwise direction. Then letting rk
and lk be as described, the conclusion of the theorem follows. In applications, this
is likely the way it will be.
26.1.2
Rouche’s Theorem
With the argument principle, it is possible to prove Rouche’s theorem . In the
argument principle, denote by Zf the quantity Pm
k=1 rk and by Pf the quantity
Pn
k=1 lk. Thus Zf is the number of zeros of f counted according to the order of the
zero with a similar deﬁnition holding for Pf. Thus the conclusion of the argument
principle is.
1
2πi
Z
γ
f ′ (z)
f (z) dz = Zf −Pf
Rouche’s theorem allows the comparison of Zh −Ph for h = f, g. It is a wonderful
and amazing result.
Theorem 26.9 (Rouche’s theorem)Let f, g be meromorphic in an open set Ω. Also
suppose γ∗is a closed bounded variation curve with the property that for all z /∈
Ω, n (γ, z) = 0, no zeros or poles are on γ∗, and for all z ∈Ω, n (γ, z) either equals 0
or 1. Let Zf and Pf denote respectively the numbers of zeros and poles of f, which
have the property that the winding number equals 1, counted according to order, with
Zg and Pg being deﬁned similarly. Also suppose that for z ∈γ∗
|f (z) + g (z)| < |f (z)| + |g (z)| .
(26.4)
Then
Zf −Pf = Zg −Pg.
Proof: From the hypotheses,
¯¯¯¯1 + f (z)
g (z)
¯¯¯¯ < 1 +
¯¯¯¯
f (z)
g (z)
¯¯¯¯
which shows that for all z ∈γ∗,
f (z)
g (z) ∈C \ [0, ∞).

712
RESIDUES
Letting l denote a branch of the logarithm deﬁned on C \ [0, ∞), it follows that
l
³
f(z)
g(z)
´
is a primitive for the function,
(f/g)′
(f/g) = f ′
f −g′
g .
Therefore, by the argument principle,
0
=
1
2πi
Z
γ
(f/g)′
(f/g) dz =
1
2πi
Z
γ
µf ′
f −g′
g
¶
dz
=
Zf −Pf −(Zg −Pg) .
This proves the theorem.
Often another condition other than 26.4 is used.
Corollary 26.10 In the situation of Theorem 26.9 change 26.4 to the condition,
|f (z) −g (z)| < |f (z)|
for z ∈γ∗. Then the conclusion is the same.
Proof: The new condition implies
¯¯¯1 −g
f (z)
¯¯¯ <
¯¯¯ g(z)
f(z)
¯¯¯ on γ∗. Therefore, g(z)
f(z) /∈
(−∞, 0] and so you can do the same argument with a branch of the logarithm.
26.1.3
A Diﬀerent Formulation
In [47] I found this modiﬁcation for Rouche’s theorem concerned with the counting
of zeros of analytic functions. This is a very useful form of Rouche’s theorem because
it makes no mention of a contour.
Theorem 26.11 Let Ωbe a bounded open set and suppose f, g are continuous on Ω
and analytic on Ω. Also suppose |f (z)| < |g (z)| on ∂Ω. Then g and f + g have the
same number of zeros in Ωprovided each zero is counted according to multiplicity.
Proof: Let K =
©
z ∈Ω: |f (z)| ≥|g (z)|
ª
. Then letting λ ∈[0, 1] , if z /∈K,
then |f (z)| < |g (z)| and so
0 < |g (z)| −|f (z)| ≤|g (z)| −λ |f (z)| ≤|g (z) + λf (z)|
which shows that all zeros of g + λf are contained in K which must be a compact
subset of Ωdue to the assumption that |f (z)| < |g (z)| on ∂Ω. By Theorem 24.52 on
Page 675 there exists a cycle, {γk}n
k=1 such that ∪n
k=1γ∗
k ⊆Ω\K, Pn
k=1 n (γk, z) = 1
for every z ∈K and Pn
k=1 n (γk, z) = 0 for all z /∈Ω. Then as above, it follows
from the residue theorem or more directly, Theorem 26.7,
n
X
k=1
1
2πi
Z
γk
λf ′ (z) + g′ (z)
λf (z) + g (z) dz =
p
X
j=1
mj

26.2.
SINGULARITIES AND THE LAURENT SERIES
713
where mj is the order of the jth zero of λf + g in K, hence in Ω. However,
λ →
n
X
k=1
1
2πi
Z
γk
λf ′ (z) + g′ (z)
λf (z) + g (z) dz
is integer valued and continuous so it gives the same value when λ = 0 as when
λ = 1. When λ = 0 this gives the number of zeros of g in Ωand when λ = 1 it is
the number of zeros of f + g. This proves the theorem.
Here is another formulation of this theorem.
Corollary 26.12 Let Ωbe a bounded open set and suppose f, g are continuous on
Ωand analytic on Ω. Also suppose |f (z) −g (z)| < |g (z)| on ∂Ω. Then f and
g have the same number of zeros in Ωprovided each zero is counted according to
multiplicity.
Proof: You let f −g play the role of f in Theorem 26.11. Thus f −g + g = f
and g have the same number of zeros. Alternatively, you can give a proof of this
directly as follows.
Let K = {z ∈Ω: |f (z) −g (z)| ≥|g (z)|} . Then if g (z) + λ (f (z) −g (z)) = 0
it follows
0
=
|g (z) + λ (f (z) −g (z))| ≥|g (z)| −λ |f (z) −g (z)|
≥
|g (z)| −|f (z) −g (z)|
and so z ∈K. Thus all zeros of g (z) + λ (f (z) −g (z)) are contained in K. By
Theorem 24.52 on Page 675 there exists a cycle, {γk}n
k=1 such that ∪n
k=1γ∗
k ⊆
Ω\ K, Pn
k=1 n (γk, z) = 1 for every z ∈K and Pn
k=1 n (γk, z) = 0 for all z /∈Ω.
Then by Theorem 26.7,
n
X
k=1
1
2πi
Z
γk
λ (f ′ (z) −g′ (z)) + g′ (z)
λ (f (z) −g (z)) + g (z) dz =
p
X
j=1
mj
where mj is the order of the jth zero of λ (f −g) + g in K, hence in Ω. The left
side is continuous as a function of λ and so the number of zeros of g corresponding
to λ = 0 equals the number of zeros of f corresponding to λ = 1. This proves the
corollary.
26.2
Singularities And The Laurent Series
26.2.1
What Is An Annulus?
In general, when you consider singularities, isolated or not, the fundamental tool
is the Laurent series.
This series is important for many other reasons also.
In
particular, it is fundamental to the spectral theory of various operators in functional
analysis and is one way to obtain relationships between algebraic and analytical

714
RESIDUES
conditions essential in various convergence theorems. A Laurent series lives on an
annulus. In all this f has values in X where X is a complex Banach space. If you
like, let X = C.
Deﬁnition 26.13 Deﬁne ann (a, R1, R2) ≡{z : R1 < |z −a| < R2} .
Thus ann (a, 0, R) would denote the punctured ball, B (a, R) \ {0} and when
R1 > 0, the annulus looks like the following.
r a
The annulus is the stuﬀbetween the two circles.
Here is an important lemma which is concerned with the situation described in
the following picture.
q a
qz
q a
qz
Lemma 26.14 Let γr (t) ≡a + reit for t ∈[0, 2π] and let |z −a| < r. Then
n (γr, z) = 1. If |z −a| > r, then n (γr, z) = 0.
Proof: For the ﬁrst claim, consider for t ∈[0, 1] ,
f (t) ≡n (γr, a + t (z −a)) .
Then from properties of the winding number derived earlier, f (t) ∈Z, f is continu-
ous, and f (0) = 1. Therefore, f (t) = 1 for all t ∈[0, 1] . This proves the ﬁrst claim
because f (1) = n (γr, z) .
For the second claim,
n (γr, z)
=
1
2πi
Z
γr
1
w −z dw
=
1
2πi
Z
γr
1
w −a −(z −a)dw
=
1
2πi
−1
z −a
Z
γr
1
1 −
³
w−a
z−a
´dw
=
−1
2πi (z −a)
Z
γr
∞
X
k=0
µw −a
z −a
¶k
dw.

26.2.
SINGULARITIES AND THE LAURENT SERIES
715
The series converges uniformly for w ∈γr because
¯¯¯¯
w −a
z −a
¯¯¯¯ =
r
r + c
for some c > 0 due to the assumption that |z −a| > r. Therefore, the sum and the
integral can be interchanged to give
n (γr, z) =
−1
2πi (z −a)
∞
X
k=0
Z
γr
µw −a
z −a
¶k
dw = 0
because w →
³
w−a
z−a
´k
has an antiderivative. This proves the lemma.
Now consider the following picture which pertains to the next lemma.
γr
r a
Lemma 26.15 Let g be analytic on ann (a, R1, R2) . Then if γr (t) ≡a + reit for
t ∈[0, 2π] and r ∈(R1, R2) , then
R
γr g (z) dz is independent of r.
Proof: Let R1 < r1 < r2 < R2 and denote by −γr (t) the curve, −γr (t) ≡
a + rei(2π−t) for t ∈[0, 2π] . Then if z ∈B (a, R1), Lemma 26.14 implies both
n
¡
γr2, z
¢
and n
¡
γr1, z
¢
= 1 and so
n
¡
−γr1, z
¢
+ n
¡
γr2, z
¢
= −1 + 1 = 0.
Also if z /∈B (a, R2) , then Lemma 26.14 implies n
³
γrj, z
´
= 0 for j = 1, 2.
Therefore, whenever z /∈ann (a, R1, R2) , the sum of the winding numbers equals
zero. Therefore, by Theorem 24.46 applied to the function, f (w) = g (z) (w −z)
and z ∈ann (a, R1, R2) \ ∪2
j=1γrj ([0, 2π]) ,
f (z)
¡
n
¡
γr2, z
¢
+ n
¡
−γr1, z
¢¢
= 0
¡
n
¡
γr2, z
¢
+ n
¡
−γr1, z
¢¢
=
1
2πi
Z
γr2
g (w) (w −z)
w −z
dw −
1
2πi
Z
γr1
g (w) (w −z)
w −z
dw
=
1
2πi
Z
γr2
g (w) dw −
1
2πi
Z
γr1
g (w) dw
which proves the desired result.

716
RESIDUES
26.2.2
The Laurent Series
The Laurent series is like a power series except it allows for negative exponents.
First here is a deﬁnition of what is meant by the convergence of such a series.
Deﬁnition 26.16 P∞
n=−∞an (z −a)n converges if both the series,
∞
X
n=0
an (z −a)n and
∞
X
n=1
a−n (z −a)−n
converge. When this is the case, the symbol, P∞
n=−∞an (z −a)n is deﬁned as
∞
X
n=0
an (z −a)n +
∞
X
n=1
a−n (z −a)−n .
Lemma 26.17 Suppose
f (z) =
∞
X
n=−∞
an (z −a)n
for all |z −a| ∈(R1, R2) . Then both P∞
n=0 an (z −a)n and P∞
n=1 a−n (z −a)−n
converge absolutely and uniformly on {z : r1 ≤|z −a| ≤r2} for any r1 < r2 satis-
fying R1 < r1 < r2 < R2.
Proof: Let R1 < |w −a| = r1 −δ < r1. Then P∞
n=1 a−n (w −a)−n converges
and so
lim
n→∞|a−n| |w −a|−n = lim
n→∞|a−n| (r1 −δ)−n = 0
which implies that for all n suﬃciently large,
|a−n| (r1 −δ)−n < 1.
Therefore,
∞
X
n=1
|a−n| |z −a|−n =
∞
X
n=1
|a−n| (r1 −δ)−n (r1 −δ)n |z −a|−n .
Now for |z −a| ≥r1,
|z −a|−n ≤1
rn
1
and so for all suﬃciently large n
|a−n| |z −a|−n ≤(r1 −δ)n
rn
1
.
Therefore, by the Weierstrass M test, the series, P∞
n=1 a−n (z −a)−n converges
absolutely and uniformly on the set
{z ∈C : |z −a| ≥r1} .

26.2.
SINGULARITIES AND THE LAURENT SERIES
717
Similar reasoning shows the series, P∞
n=0 an (z −a)n converges uniformly on the set
{z ∈C : |z −a| ≤r2} .
This proves the Lemma.
Theorem 26.18 Let f be analytic on ann (a, R1, R2) . Then there exist numbers,
an ∈C such that for all z ∈ann (a, R1, R2) ,
f (z) =
∞
X
n=−∞
an (z −a)n ,
(26.5)
where the series converges absolutely and uniformly on ann (a, r1, r2) whenever R1 <
r1 < r2 < R2. Also
an =
1
2πi
Z
γ
f (w)
(w −a)n+1 dw
(26.6)
where γ (t) = a + reit, t ∈[0, 2π] for any r ∈(R1, R2) . Furthermore the series is
unique in the sense that if 26.5 holds for z ∈ann (a, R1, R2) , then an is given in
26.6.
Proof: Let R1 < r1 < r2 < R2 and deﬁne γ1 (t) ≡a + (r1 −ε) eit and γ2 (t) ≡
a+(r2 + ε) eit for t ∈[0, 2π] and ε chosen small enough that R1 < r1 −ε < r2 +ε <
R2.
q a
zq
γ1
γ2
Then using Lemma 26.14, if z /∈ann (a, R1, R2) then
n (−γ1, z) + n (γ2, z) = 0
and if z ∈ann (a, r1, r2) ,
n (−γ1, z) + n (γ2, z) = 1.

718
RESIDUES
Therefore, by Theorem 24.46, for z ∈ann (a, r1, r2)
f (z)
=
1
2πi
"Z
−γ1
f (w)
w −z dw +
Z
γ2
f (w)
w −z dw
#
=
1
2πi


Z
γ1
f (w)
(z −a)
h
1 −w−a
z−a
idw +
Z
γ2
f (w)
(w −a)
h
1 −z−a
w−a
idw


=
1
2πi
Z
γ2
f (w)
w −a
∞
X
n=0
µ z −a
w −a
¶n
dw+
1
2πi
Z
γ1
f (w)
(z −a)
∞
X
n=0
µw −a
z −a
¶n
dw.
(26.7)
From the formula 26.7, it follows that for z ∈ann (a, r1, r2), the terms in the ﬁrst
sum are bounded by an expression of the form C
³
r2
r2+ε
´n
while those in the second
are bounded by one of the form C
³
r1−ε
r1
´n
and so by the Weierstrass M test, the
convergence is uniform and so the integrals and the sums in the above formula may
be interchanged and after renaming the variable of summation, this yields
f (z) =
∞
X
n=0
Ã
1
2πi
Z
γ2
f (w)
(w −a)n+1 dw
!
(z −a)n +
−1
X
n=−∞
Ã
1
2πi
Z
γ1
f (w)
(w −a)n+1
!
(z −a)n .
(26.8)
Therefore, by Lemma 26.15, for any r ∈(R1, R2) ,
f (z) =
∞
X
n=0
Ã
1
2πi
Z
γr
f (w)
(w −a)n+1 dw
!
(z −a)n +
−1
X
n=−∞
Ã
1
2πi
Z
γr
f (w)
(w −a)n+1
!
(z −a)n .
(26.9)
and so
f (z) =
∞
X
n=−∞
Ã
1
2πi
Z
γr
f (w)
(w −a)n+1 dw
!
(z −a)n .
where r ∈(R1, R2) is arbitrary. This proves the existence part of the theorem. It
remains to characterize an.
If f (z) = P∞
n=−∞an (z −a)n on ann (a, R1, R2) let
fn (z) ≡
n
X
k=−n
ak (z −a)k .
(26.10)

26.2.
SINGULARITIES AND THE LAURENT SERIES
719
This function is analytic in ann (a, R1, R2) and so from the above argument,
fn (z) =
∞
X
k=−∞
Ã
1
2πi
Z
γr
fn (w)
(w −a)k+1 dw
!
(z −a)k .
(26.11)
Also if k > n or if k < −n,
Ã
1
2πi
Z
γr
fn (w)
(w −a)k+1 dw
!
= 0.
and so
fn (z) =
n
X
k=−n
Ã
1
2πi
Z
γr
fn (w)
(w −a)k+1 dw
!
(z −a)k
which implies from 26.10 that for each k ∈[−n, n] ,
1
2πi
Z
γr
fn (w)
(w −a)k+1 dw = ak
However, from the uniform convergence of the series,
∞
X
n=0
an (w −a)n
and
∞
X
n=1
a−n (w −a)−n
ensured by Lemma 26.17 which allows the interchange of sums and integrals, if
k ∈[−n, n] ,
1
2πi
Z
γr
f (w)
(w −a)k+1 dw
=
1
2πi
Z
γr
P∞
m=0 am (w −a)m + P∞
m=1 a−m (w −a)−m
(w −a)k+1
dw
=
∞
X
m=0
am
1
2πi
Z
γr
(w −a)m−(k+1) dw
+
∞
X
m=1
a−m
Z
γr
(w −a)−m−(k+1) dw
=
n
X
m=0
am
1
2πi
Z
γr
(w −a)m−(k+1) dw
+
n
X
m=1
a−m
Z
γr
(w −a)−m−(k+1) dw
=
1
2πi
Z
γr
fn (w)
(w −a)k+1 dw

720
RESIDUES
because if l > n or l < −n,
Z
γr
al (w −a)l
(w −a)k+1 dw = 0
for all k ∈[−n, n] . Therefore,
ak =
1
2πi
Z
γr
f (w)
(w −a)k+1 dw
and so this establishes uniqueness. This proves the theorem.
26.2.3
Contour Integrals And Evaluation Of Integrals
Here are some examples of hard integrals which can be evaluated by using residues.
This will be done by integrating over various closed curves having bounded variation.
Example 26.19 The ﬁrst example we consider is the following integral.
Z ∞
−∞
1
1 + x4 dx
One could imagine evaluating this integral by the method of partial fractions
and it should work out by that method. However, we will consider the evaluation
of this integral by the method of residues instead. To do so, consider the following
picture.
x
y
Let γr (t) = reit, t ∈[0, π] and let σr (t) = t : t ∈[−r, r] . Thus γr parameterizes
the top curve and σr parameterizes the straight line from −r to r along the x
axis. Denoting by Γr the closed curve traced out by these two, we see from simple
estimates that
lim
r→∞
Z
γr
1
1 + z4 dz = 0.

26.2.
SINGULARITIES AND THE LAURENT SERIES
721
This follows from the following estimate.
¯¯¯¯¯
Z
γr
1
1 + z4 dz
¯¯¯¯¯ ≤
1
r4 −1πr.
Therefore,
Z ∞
−∞
1
1 + x4 dx = lim
r→∞
Z
Γr
1
1 + z4 dz.
We compute
R
Γr
1
1+z4 dz using the method of residues.
The only residues of the
integrand are located at points, z where 1 + z4 = 0. These points are
z
=
−1
2
√
2 −1
2i
√
2, z = 1
2
√
2 −1
2i
√
2,
z
=
1
2
√
2 + 1
2i
√
2, z = −1
2
√
2 + 1
2i
√
2
and it is only the last two which are found in the inside of Γr. Therefore, we need
to calculate the residues at these points. Clearly this function has a pole of order
one at each of these points and so we may calculate the residue at α in this list by
evaluating
lim
z→α (z −α)
1
1 + z4
Thus
Res
µ
f, 1
2
√
2 + 1
2i
√
2
¶
=
lim
z→1
2
√
2+ 1
2 i
√
2
µ
z −
µ1
2
√
2 + 1
2i
√
2
¶¶
1
1 + z4
=
−1
8
√
2 −1
8i
√
2
Similarly we may ﬁnd the other residue in the same way
Res
µ
f, −1
2
√
2 + 1
2i
√
2
¶
=
lim
z→−1
2
√
2+ 1
2 i
√
2
µ
z −
µ
−1
2
√
2 + 1
2i
√
2
¶¶
1
1 + z4
=
−1
8i
√
2 + 1
8
√
2.
Therefore,
Z
Γr
1
1 + z4 dz
=
2πi
µ
−1
8i
√
2 + 1
8
√
2 +
µ
−1
8
√
2 −1
8i
√
2
¶¶
=
1
2π
√
2.

722
RESIDUES
Thus, taking the limit we obtain 1
2π
√
2 =
R ∞
−∞
1
1+x4 dx.
Obviously many diﬀerent variations of this are possible. The main idea being
that the integral over the semicircle converges to zero as r →∞.
Sometimes we don’t blow up the curves and take limits. Sometimes the problem
of interest reduces directly to a complex integral over a closed curve. Here is an
example of this.
Example 26.20 The integral is
Z π
0
cos θ
2 + cos θdθ
This integrand is even and so it equals
1
2
Z π
−π
cos θ
2 + cos θdθ.
For z on the unit circle, z = eiθ, z =
1
z and therefore, cos θ = 1
2
¡
z + 1
z
¢
. Thus
dz = ieiθdθ and so dθ =
dz
iz . Note this is proceeding formally to get a complex
integral which reduces to the one of interest. It follows that a complex integral
which reduces to the one desired is
1
2i
Z
γ
1
2
¡
z + 1
z
¢
2 + 1
2
¡
z + 1
z
¢ dz
z = 1
2i
Z
γ
z2 + 1
z (4z + z2 + 1)dz
where γ is the unit circle. Now the integrand has poles of order 1 at those points
where z
¡
4z + z2 + 1
¢
= 0. These points are
0, −2 +
√
3, −2 −
√
3.
Only the ﬁrst two are inside the unit circle. It is also clear the function has simple
poles at these points. Therefore,
Res (f, 0) = lim
z→0 z
µ
z2 + 1
z (4z + z2 + 1)
¶
= 1.
Res
³
f, −2 +
√
3
´
=
lim
z→−2+
√
3
³
z −
³
−2 +
√
3
´´
z2 + 1
z (4z + z2 + 1) = −2
3
√
3.
It follows
Z π
0
cos θ
2 + cos θdθ
=
1
2i
Z
γ
z2 + 1
z (4z + z2 + 1)dz
=
1
2i2πi
µ
1 −2
3
√
3
¶
=
π
µ
1 −2
3
√
3
¶
.

26.2.
SINGULARITIES AND THE LAURENT SERIES
723
Other rational functions of the trig functions will work out by this method also.
Sometimes you have to be clever about which version of an analytic function
that reduces to a real function you should use. The following is such an example.
Example 26.21 The integral here is
Z ∞
0
ln x
1 + x4 dx.
The same curve used in the integral involving sin x
x
earlier will create problems
with the log since the usual version of the log is not deﬁned on the negative real
axis. This does not need to be of concern however. Simply use another branch of
the logarithm. Leave out the ray from 0 along the negative y axis and use Theorem
25.5 to deﬁne L (z) on this set. Thus L (z) = ln |z|+i arg1 (z) where arg1 (z) will be
the angle, θ, between −π
2 and 3π
2 such that z = |z| eiθ. Now the only singularities
contained in this curve are
1
2
√
2 + 1
2i
√
2, −1
2
√
2 + 1
2i
√
2
and the integrand, f has simple poles at these points. Thus using the same proce-
dure as in the other examples,
Res
µ
f, 1
2
√
2 + 1
2i
√
2
¶
=
1
32
√
2π −1
32i
√
2π
and
Res
µ
f, −1
2
√
2 + 1
2i
√
2
¶
=
3
32
√
2π + 3
32i
√
2π.
Consider the integral along the small semicircle of radius r. This reduces to
Z 0
π
ln |r| + it
1 + (reit)4
¡
rieit¢
dt
which clearly converges to zero as r →0 because r ln r →0. Therefore, taking the
limit as r →0,
Z
large semicircle
L (z)
1 + z4 dz + lim
r→0+
Z −r
−R
ln (−t) + iπ
1 + t4
dt+
lim
r→0+
Z R
r
ln t
1 + t4 dt = 2πi
µ 3
32
√
2π + 3
32i
√
2π + 1
32
√
2π −1
32i
√
2π
¶
.

724
RESIDUES
Observing that
R
large semicircle
L(z)
1+z4 dz →0 as R →∞,
e (R) + 2 lim
r→0+
Z R
r
ln t
1 + t4 dt + iπ
Z 0
−∞
1
1 + t4 dt =
µ
−1
8 + 1
4i
¶
π2√
2
where e (R) →0 as R →∞. From an earlier example this becomes
e (R) + 2 lim
r→0+
Z R
r
ln t
1 + t4 dt + iπ
Ã√
2
4 π
!
=
µ
−1
8 + 1
4i
¶
π2√
2.
Now letting r →0+ and R →∞,
2
Z ∞
0
ln t
1 + t4 dt
=
µ
−1
8 + 1
4i
¶
π2√
2 −iπ
Ã√
2
4 π
!
=
−1
8
√
2π2,
and so
Z ∞
0
ln t
1 + t4 dt = −1
16
√
2π2,
which is probably not the ﬁrst thing you would thing of. You might try to imagine
how this could be obtained using elementary techniques.
The next example illustrates the use of what is referred to as a branch cut. It
includes many examples.
Example 26.22 Mellin transformations are of the form
Z ∞
0
f (x) xα dx
x .
Sometimes it is possible to evaluate such a transform in terms of the constant, α.
Assume f is an analytic function except at isolated singularities, none of which
are on (0, ∞) . Also assume that f has the growth conditions,
|f (z)| ≤C
|z|b , b > α
for all large |z| and assume that
|f (z)| ≤C′
|z|b1 , b1 < α
for all |z| suﬃciently small. It turns out there exists an explicit formula for this
Mellin transformation under these conditions. Consider the following contour.

26.2.
SINGULARITIES AND THE LAURENT SERIES
725

−R
-

In this contour the small semicircle in the center has radius ε which will converge
to 0. Denote by γR the large circular path which starts at the upper edge of the
slot and continues to the lower edge. Denote by γε the small semicircular contour
and denote by γεR+ the straight part of the contour from 0 to R which provides
the top edge of the slot. Finally denote by γεR−the straight part of the contour
from R to 0 which provides the bottom edge of the slot. The interesting aspect of
this problem is the deﬁnition of f (z) zα−1. Let
zα−1 ≡e(ln|z|+i arg(z))(α−1) = e(α−1) log(z)
where arg (z) is the angle of z in (0, 2π) . Thus you use a branch of the logarithm
which is deﬁned on C\(0, ∞) . Then it is routine to verify from the assumed estimates
that
lim
R→∞
Z
γR
f (z) zα−1dz = 0
and
lim
ε→0+
Z
γε
f (z) zα−1dz = 0.
Also, it is routine to verify
lim
ε→0+
Z
γεR+
f (z) zα−1dz =
Z R
0
f (x) xα−1dx
and
lim
ε→0+
Z
γεR−
f (z) zα−1dz = −ei2π(α−1)
Z R
0
f (x) xα−1dx.

726
RESIDUES
Therefore, letting ΣR denote the sum of the residues of f (z) zα−1 which are con-
tained in the disk of radius R except for the possible residue at 0,
e (R) +
³
1 −ei2π(α−1)´ Z R
0
f (x) xα−1dx = 2πiΣR
where e (R) →0 as R →∞. Now letting R →∞,
lim
R→∞
Z R
0
f (x) xα−1dx =
2πi
1 −ei2π(α−1) Σ = πe−πiα
sin (πα)Σ
where Σ denotes the sum of all the residues of f (z) zα−1 except for the residue at
0.
The next example is similar to the one on the Mellin transform. In fact it is
a Mellin transform but is worked out independently of the above to emphasize a
slightly more informal technique related to the contour.
Example 26.23
R ∞
0
xp−1
1+x dx, p ∈(0, 1) .
Since the exponent of x in the numerator is larger than −1. The integral does
converge. However, the techniques of real analysis don’t tell us what it converges
to. The contour to be used is as follows: From (ε, 0) to (r, 0) along the x axis and
then from (r, 0) to (r, 0) counter clockwise along the circle of radius r, then from
(r, 0) to (ε, 0) along the x axis and from (ε, 0) to (ε, 0) , clockwise along the circle
of radius ε. You should draw a picture of this contour. The interesting thing about
this is that zp−1 cannot be deﬁned all the way around 0. Therefore, use a branch of
zp−1 corresponding to the branch of the logarithm obtained by deleting the positive
x axis. Thus
zp−1 = e(ln|z|+iA(z))(p−1)
where z = |z| eiA(z) and A (z) ∈(0, 2π) . Along the integral which goes in the positive
direction on the x axis, let A (z) = 0 while on the one which goes in the negative
direction, take A (z) = 2π. This is the appropriate choice obtained by replacing the
line from (ε, 0) to (r, 0) with two lines having a small gap joined by a circle of radius
ε and then taking a limit as the gap closes. You should verify that the two integrals
taken along the circles of radius ε and r converge to 0 as ε →0 and as r →∞.
Therefore, taking the limit,
Z ∞
0
xp−1
1 + xdx +
Z 0
∞
xp−1
1 + x
³
e2πi(p−1)´
dx = 2πi Res (f, −1) .
Calculating the residue of the integrand at −1, and simplifying the above expression,
³
1 −e2πi(p−1)´ Z ∞
0
xp−1
1 + xdx = 2πie(p−1)iπ.
Upon simpliﬁcation
Z ∞
0
xp−1
1 + xdx =
π
sin pπ .

26.2.
SINGULARITIES AND THE LAURENT SERIES
727
Example 26.24 The Fresnel integrals are
Z ∞
0
cos
¡
x2¢
dx,
Z ∞
0
sin
¡
x2¢
dx.
To evaluate these integrals consider f (z) = eiz2 on the curve which goes from
the origin to the point r on the x axis and from this point to the point r
³
1+i
√
2
´
along a circle of radius r, and from there back to the origin as illustrated in the
following picture.
x
y
@
¡
Thus the curve to integrate over is shaped like a slice of pie. Denote by γr the
curved part. Since f is analytic,
0
=
Z
γr
eiz2dz +
Z r
0
eix2dx −
Z r
0
e
i
³
t
³
1+i
√
2
´´2 µ1 + i
√
2
¶
dt
=
Z
γr
eiz2dz +
Z r
0
eix2dx −
Z r
0
e−t2 µ1 + i
√
2
¶
dt
=
Z
γr
eiz2dz +
Z r
0
eix2dx −
√π
2
µ1 + i
√
2
¶
+ e (r)
where e (r) →0 as r →∞. Here we used the fact that
R ∞
0
e−t2dt =
√π
2 . Now
consider the ﬁrst of these integrals.
¯¯¯¯¯
Z
γr
eiz2dz
¯¯¯¯¯
=
¯¯¯¯¯
Z
π
4
0
ei(reit)
2
rieitdt
¯¯¯¯¯
≤
r
Z
π
4
0
e−r2 sin 2tdt
=
r
2
Z 1
0
e−r2u
√
1 −u2 du
≤r
2
Z r−(3/2)
0
1
√
1 −u2 du + r
2
µZ 1
0
1
√
1 −u2
¶
e−(r1/2)

728
RESIDUES
which converges to zero as r →∞. Therefore, taking the limit as r →∞,
√π
2
µ1 + i
√
2
¶
=
Z ∞
0
eix2dx
and so
Z ∞
0
sin x2dx =
√π
2
√
2 =
Z ∞
0
cos x2dx.
The following example is one of the most interesting. By an auspicious choice
of the contour it is possible to obtain a very interesting formula for cot πz known
as the Mittag- Leﬄer expansion of cot πz.
Example 26.25 Let γN be the contour which goes from −N −1
2 −Ni horizontally
to N + 1
2 −Ni and from there, vertically to N + 1
2 + Ni and then horizontally
to −N −1
2 + Ni
and ﬁnally vertically to −N −1
2 −Ni. Thus the contour is a
large rectangle and the direction of integration is in the counter clockwise direction.
Consider the following integral.
IN ≡
Z
γN
π cos πz
sin πz (α2 −z2)dz
where α ∈R is not an integer. This will be used to verify the formula of Mittag
Leﬄer,
1
α2 +
∞
X
n=1
2
α2 −n2 = π cot πα
α
.
(26.12)
You should verify that cot πz is bounded on this contour and that therefore,
IN →0 as N →∞. Now you compute the residues of the integrand at ±α and
at n where |n| < N + 1
2 for n an integer. These are the only singularities of the
integrand in this contour and therefore, you can evaluate IN by using these. It is
left as an exercise to calculate these residues and ﬁnd that the residue at ±α is
−π cos πα
2α sin πα
while the residue at n is
1
α2 −n2 .
Therefore,
0 = lim
N→∞IN = lim
N→∞2πi
"
N
X
n=−N
1
α2 −n2 −π cot πα
α
#
which establishes the following formula of Mittag Leﬄer.
lim
N→∞
N
X
n=−N
1
α2 −n2 = π cot πα
α
.
Writing this in a slightly nicer form, yields 26.12.

26.3. THE SPECTRAL RADIUS OF A BOUNDED LINEAR TRANSFORMATION729
26.3
The Spectral Radius Of A Bounded Linear
Transformation
As a very important application of the theory of Laurent series, I will give a short
description of the spectral radius.
This is a fundamental result which must be
understood in order to prove convergence of various important numerical methods
such as the Gauss Seidel or Jacobi methods.
Deﬁnition 26.26 Let X be a complex Banach space and let A ∈L (X, X) . Then
r (A) ≡
n
λ ∈C : (λI −A)−1 ∈L (X, X)
o
This is called the resolvent set. The spectrum of A, denoted by σ (A) is deﬁned as
all the complex numbers which are not in the resolvent set. Thus
σ (A) ≡C \ r (A)
Lemma 26.27 λ ∈r (A) if and only if λI −A is one to one and onto X. Also if
|λ| > ||A|| , then λ ∈σ (A). If the Neumann series,
1
λ
∞
X
k=0
µA
λ
¶k
converges, then
1
λ
∞
X
k=0
µA
λ
¶k
= (λI −A)−1 .
Proof: Note that to be in r (A) , λI −A must be one to one and map X onto
X since otherwise, (λI −A)−1 /∈L (X, X) .
By the open mapping theorem, if these two algebraic conditions hold, then
(λI −A)−1 is continuous and so this proves the ﬁrst part of the lemma.
Now
suppose |λ| > ||A|| . Consider the Neumann series
1
λ
∞
X
k=0
µA
λ
¶k
.
By the root test, Theorem 24.3 on Page 642 this series converges to an element
of L (X, X) denoted here by B. Now suppose the series converges. Letting Bn ≡
1
λ
Pn
k=0
¡ A
λ
¢k ,
(λI −A) Bn
=
Bn (λI −A) =
n
X
k=0
µA
λ
¶k
−
n
X
k=0
µA
λ
¶k+1
=
I −
µA
λ
¶n+1
→I

730
RESIDUES
as n →∞because the convergence of the series requires the nth term to converge
to 0. Therefore,
(λI −A) B = B (λI −A) = I
which shows λI −A is both one to one and onto and the Neumann series converges
to (λI −A)−1 . This proves the lemma.
This lemma also shows that σ (A) is bounded. In fact, σ (A) is closed.
Lemma 26.28 r (A) is open. In fact, if λ ∈r (A) and |µ −λ| <
¯¯¯
¯¯¯(λI −A)−1¯¯¯
¯¯¯
−1
,
then µ ∈r (A).
Proof: First note
(µI −A)
=
³
I −(λ −µ) (λI −A)−1´
(λI −A)
(26.13)
=
(λI −A)
³
I −(λ −µ) (λI −A)−1´
(26.14)
Also from the assumption about |λ −µ| ,
¯¯¯
¯¯¯(λ −µ) (λI −A)−1¯¯¯
¯¯¯ ≤|λ −µ|
¯¯¯
¯¯¯(λI −A)−1¯¯¯
¯¯¯ < 1
and so by the root test,
∞
X
k=0
³
(λ −µ) (λI −A)−1´k
converges to an element of L (X, X) . As in Lemma 26.27,
∞
X
k=0
³
(λ −µ) (λI −A)−1´k
=
³
I −(λ −µ) (λI −A)−1´−1
.
Therefore, from 26.13,
(µI −A)−1 = (λI −A)−1 ³
I −(λ −µ) (λI −A)−1´−1
.
This proves the lemma.
Corollary 26.29 σ (A) is a compact set.
Proof: Lemma 26.27 shows σ (A) is bounded and Lemma 26.28 shows it is
closed.
Deﬁnition 26.30 The spectral radius, denoted by ρ (A) is deﬁned by
ρ (A) ≡max {|λ| : λ ∈σ (A)} .
Since σ (A) is compact, this maximum exists. Note from Lemma 26.27, ρ (A) ≤
||A||.

26.4.
EXERCISES
731
There is a simple formula for the spectral radius.
Lemma 26.31 If |λ| > ρ (A) , then the Neumann series,
1
λ
∞
X
k=0
µA
λ
¶k
converges.
Proof: This follows directly from Theorem 26.18 on Page 717 and the obser-
vation above that 1
λ
P∞
k=0
¡ A
λ
¢k = (λI −A)−1 for all |λ| > ||A||. Thus the analytic
function, λ →(λI −A)−1 has a Laurent expansion on |λ| > ρ (A) by Theorem 26.18
and it must coincide with 1
λ
P∞
k=0
¡ A
λ
¢k on |λ| > ||A|| so the Laurent expansion of
λ →(λI −A)−1 must equal 1
λ
P∞
k=0
¡ A
λ
¢k on |λ| > ρ (A) . This proves the lemma.
The theorem on the spectral radius follows. It is due to Gelfand.
Theorem 26.32 ρ (A) = limn→∞||An||1/n.
Proof: If
|λ| < lim sup
n→∞||An||1/n
then by the root test, the Neumann series does not converge and so by Lemma
26.31 |λ| ≤ρ (A) . Thus
ρ (A) ≥lim sup
n→∞||An||1/n .
Now let p be a positive integer. Then λ ∈σ (A) implies λp ∈σ (Ap) because
λpI −Ap
=
(λI −A)
¡
λp−1 + λp−2A + · · · + Ap−1¢
=
¡
λp−1 + λp−2A + · · · + Ap−1¢
(λI −A)
It follows from Lemma 26.27 applied to Apthat for λ ∈σ (A) , |λp| ≤||Ap|| and so
|λ| ≤||Ap||1/p . Therefore, ρ (A) ≤||Ap||1/p and since p is arbitrary,
lim inf
p→∞||Ap||1/p ≥ρ (A) ≥lim sup
n→∞||An||1/n .
This proves the theorem.
26.4
Exercises
1. Example 26.19 found the integral of a rational function of a certain sort. The
technique used in this example typically works for rational functions of the
form
f(x)
g(x) where deg (g (x)) ≥deg f (x) + 2 provided the rational function
has no poles on the real axis.
State and prove a theorem based on these
observations.

732
RESIDUES
2. Fill in the missing details of Example 26.25 about IN →0. Note how important
it was that the contour was chosen just right for this to happen. Also verify
the claims about the residues.
3. Suppose f has a pole of order m at z = a. Deﬁne g (z) by
g (z) = (z −a)m f (z) .
Show
Res (f, a) =
1
(m −1)!g(m−1) (a) .
Hint: Use the Laurent series.
4. Give a proof of Theorem 26.6. Hint: Let p be a pole. Show that near p, a
pole of order m,
f ′ (z)
f (z) =
−m + P∞
k=1 bk (z −p)k
(z −p) + P∞
k=2 ck (z −p)k
Show that Res (f, p) = −m. Carry out a similar procedure for the zeros.
5. Use Rouche’s theorem to prove the fundamental theorem of algebra which
says that if p (z) = zn + an−1zn−1 · · · +a1z + a0, then p has n zeros in C.
Hint: Let q (z) = −zn and let γ be a large circle, γ (t) = reit for r suﬃciently
large.
6. Consider the two polynomials z5 +3z2 −1 and z5 +3z2. Show that on |z| = 1,
the conditions for Rouche’s theorem hold. Now use Rouche’s theorem to verify
that z5 + 3z2 −1 must have two zeros in |z| < 1.
7. Consider the polynomial, z11 + 7z5 + 3z2 −17. Use Rouche’s theorem to ﬁnd
a bound on the zeros of this polynomial. In other words, ﬁnd r such that if z
is a zero of the polynomial, |z| < r. Try to make r fairly small if possible.
8. Verify that
R ∞
0
e−t2dt =
√π
2 . Hint: Use polar coordinates.
9. Use the contour described in Example 26.19 to compute the exact values of
the following improper integrals.
(a)
R ∞
−∞
x
(x2+4x+13)2 dx
(b)
R ∞
0
x2
(x2+a2)2 dx
(c)
R ∞
−∞
dx
(x2+a2)(x2+b2), a, b > 0
10. Evaluate the following improper integrals.
(a)
R ∞
0
cos ax
(x2+b2)2 dx

26.4.
EXERCISES
733
(b)
R ∞
0
x sin x
(x2+a2)2 dx
11. Find the Cauchy principle value of the integral
Z ∞
−∞
sin x
(x2 + 1) (x −1)dx
deﬁned as
lim
ε→0+
µZ 1−ε
−∞
sin x
(x2 + 1) (x −1)dx +
Z ∞
1+ε
sin x
(x2 + 1) (x −1)dx
¶
.
12. Find a formula for the integral
R ∞
−∞
dx
(1+x2)n+1 where n is a nonnegative integer.
13. Find
R ∞
−∞
sin2 x
x2 dx.
14. If m < n for m and n integers, show
Z ∞
0
x2m
1 + x2n dx = π
2n
1
sin
¡ 2m+1
2n π
¢.
15. Find
R ∞
−∞
1
(1+x4)2 dx.
16. Find
R ∞
0
ln(x)
1+x2 dx = 0.
17. Suppose f has an isolated singularity at α. Show the singularity is essential
if and only if the principal part of the Laurent series of f has inﬁnitely many
terms. That is, show f (z) = P∞
k=0 ak (z −α)k+P∞
k=1
bk
(z−α)k where inﬁnitely
many of the bk are nonzero.
18. Suppose Ωis a bounded open set and fn is analytic on Ωand continuous on
Ω. Suppose also that fn →f uniformly on Ωand that f ̸= 0 on ∂Ω. Show
that for all n large enough, fn and f have the same number of zeros on Ω
provided the zeros are counted according to multiplicity.

734
RESIDUES

Complex Mappings
27.1
Conformal Maps
If γ (t) = x (t) + iy (t) is a C1 curve having values in U, an open set of C, and
if f : U →C is analytic, consider f ◦γ, another C1 curve having values in C.
Also, γ′ (t) and (f ◦γ)′ (t) are complex numbers so these can be considered as
vectors in R2 as follows. The complex number, x + iy corresponds to the vector,
(x, y) . Suppose that γ and η are two such C1 curves having values in U and that
γ (t0) = η (s0) = z and suppose that f : U →C is analytic. What can be said about
the angle between (f ◦γ)′ (t0) and (f ◦η)′ (s0)? It turns out this angle is the same
as the angle between γ′ (t0) and η′ (s0) assuming that f ′ (z) ̸= 0. To see this, note
(x, y) · (a, b) = 1
2 (zw + zw) where z = x + iy and w = a + ib. Therefore, letting θ
be the cosine between the two vectors, (f ◦γ)′ (t0) and (f ◦η)′ (s0) , it follows from
calculus that
cos θ
=
(f ◦γ)′ (t0) · (f ◦η)′ (s0)
¯¯(f ◦η)′ (s0)
¯¯ ¯¯(f ◦γ)′ (t0)
¯¯
=
1
2
f ′ (γ (t0)) γ′ (t0) f ′ (η (s0))η′ (s0) + f ′ (γ (t0)) γ′ (t0)f ′ (η (s0)) η′ (s0)
|f ′ (γ (t0))| |f ′ (η (s0))|
=
1
2
f ′ (z) f ′ (z)γ′ (t0) η′ (s0) + f ′ (z)f ′ (z) γ′ (t0)η′ (s0)
|f ′ (z)| |f ′ (z)|
=
1
2
γ′ (t0) η′ (s0) + η′ (s0) γ′ (t0)
1
which equals the angle between the vectors, γ′ (t0) and η′ (t0) . Thus analytic map-
pings preserve angles at points where the derivative is nonzero. Such mappings are
called isogonal. .
Actually, they also preserve orientations. If z = x + iy and w = a + ib are two
complex numbers, then (x, y, 0) and (a, b, 0) are two vectors in R3. Recall that the
cross product, (x, y, 0) × (a, b, 0) , yields a vector normal to the two given vectors
such that the triple, (x, y, 0) , (a, b, 0) , and (x, y, 0)×(a, b, 0) satisﬁes the right hand
735

736
COMPLEX MAPPINGS
rule and has magnitude equal to the product of the sine of the included angle times
the product of the two norms of the vectors. In this case, the cross product will
produce a vector which is a multiple of k, the unit vector in the direction of the z
axis. In fact, you can verify by computing both sides that, letting z = x + iy and
w = a + ib,
(x, y, 0) × (a, b, 0) = Re (ziw) k.
Therefore, in the above situation,
(f ◦γ)′ (t0) × (f ◦η)′ (s0)
=
Re
³
f ′ (γ (t0)) γ′ (t0) if ′ (η (s0))η′ (s0)
´
k
=
|f ′ (z)|2 Re
³
γ′ (t0) iη′ (s0)
´
k
which shows that the orientation of γ′ (t0), η′ (s0) is the same as the orientation of
(f ◦γ)′ (t0) , (f ◦η)′ (s0). Mappings which preserve both orientation and angles are
called conformal mappings and this has shown that analytic functions are conformal
mappings if the derivative does not vanish.
27.2
Fractional Linear Transformations
27.2.1
Circles And Lines
These mappings map lines and circles to either lines or circles.
Deﬁnition 27.1 A fractional linear transformation is a function of the form
f (z) = az + b
cz + d
(27.1)
where ad −bc ̸= 0.
Note that if c = 0, this reduces to a linear transformation (a/d) z+(b/d) . Special
cases of these are deﬁned as follows.
dilations: z →δz, δ ̸= 0, inversions: z →1
z ,
translations: z →z + ρ.
The next lemma is the key to understanding fractional linear transformations.
Lemma 27.2 The fractional linear transformation, 27.1 can be written as a ﬁnite
composition of dilations, inversions, and translations.
Proof: Let
S1 (z) = z + d
c , S2 (z) = 1
z , S3 (z) = (bc −ad)
c2
z

27.2.
FRACTIONAL LINEAR TRANSFORMATIONS
737
and
S4 (z) = z + a
c
in the case where c ̸= 0. Then f (z) given in 27.1 is of the form
f (z) = S4 ◦S3 ◦S2 ◦S1.
Here is why.
S2 (S1 (z)) = S2
µ
z + d
c
¶
≡
1
z + d
c
=
c
zc + d.
Now consider
S3
µ
c
zc + d
¶
≡(bc −ad)
c2
µ
c
zc + d
¶
=
bc −ad
c (zc + d).
Finally, consider
S4
µ bc −ad
c (zc + d)
¶
≡
bc −ad
c (zc + d) + a
c = b + az
zc + d.
In case that c = 0, f (z) = a
dz + b
d which is a translation composed with a dilation.
Because of the assumption that ad −bc ̸= 0, it follows that since c = 0, both a and
d ̸= 0. This proves the lemma.
This lemma implies the following corollary.
Corollary 27.3 Fractional linear transformations map circles and lines to circles
or lines.
Proof: It is obvious that dilations and translations map circles to circles and
lines to lines. What of inversions? If inversions have this property, the above lemma
implies a general fractional linear transformation has this property as well.
Note that all circles and lines may be put in the form
α
¡
x2 + y2¢
−2ax −2by = r2 −
¡
a2 + b2¢
where α = 1 gives a circle centered at (a, b) with radius r and α = 0 gives a line. In
terms of complex variables you may therefore consider all possible circles and lines
in the form
αzz + βz + βz + γ = 0,
(27.2)
To see this let β = β1 + iβ2 where β1 ≡−a and β2 ≡b. Note that even if α is not
0 or 1 the expression still corresponds to either a circle or a line because you can
divide by α if α ̸= 0. Now I verify that replacing z with 1
z results in an expression
of the form in 27.2. Thus, let w = 1
z where z satisﬁes 27.2. Then
¡
α + βw + βw + γww
¢
= 1
zz
¡
αzz + βz + βz + γ
¢
= 0

738
COMPLEX MAPPINGS
and so w also satisﬁes a relation like 27.2. One simply switches α with γ and β
with β. Note the situation is slightly diﬀerent than with dilations and translations.
In the case of an inversion, a circle becomes either a line or a circle and similarly, a
line becomes either a circle or a line. This proves the corollary.
The next example is quite important.
Example 27.4 Consider the fractional linear transformation, w = z−i
z+i.
First consider what this mapping does to the points of the form z = x + i0.
Substituting into the expression for w,
w = x −i
x + i = x2 −1 −2xi
x2 + 1
,
a point on the unit circle. Thus this transformation maps the real axis to the unit
circle.
The upper half plane is composed of points of the form x + iy where y > 0.
Substituting in to the transformation,
w = x + i (y −1)
x + i (y + 1),
which is seen to be a point on the interior of the unit disk because |y −1| < |y + 1|
which implies |x + i (y + 1)| > |x + i (y −1)|. Therefore, this transformation maps
the upper half plane to the interior of the unit disk.
One might wonder whether the mapping is one to one and onto. The mapping
is clearly one to one because it has an inverse, z = −i w+1
w−1 for all w in the interior
of the unit disk. Also, a short computation veriﬁes that z so deﬁned is in the upper
half plane. Therefore, this transformation maps {z ∈C such that Im z > 0} one to
one and onto the unit disk {z ∈C such that |z| < 1} .
A fancy way to do part of this is to use Theorem 25.11. lim supz→a
¯¯¯ z−i
z+i
¯¯¯ ≤1
whenever a is the real axis or ∞. Therefore,
¯¯¯ z−i
z+i
¯¯¯ ≤1. This is a little shorter.
27.2.2
Three Points To Three Points
There is a simple procedure for determining fractional linear transformations which
map a given set of three points to another set of three points. The problem is as
follows: There are three distinct points in the extended complex plane, z1, z2, and
z3 and it is desired to ﬁnd a fractional linear transformation such that zi →wi
for i = 1, 2, 3 where here w1, w2, and w3 are three distinct points in the extended
complex plane. Then the procedure says that to ﬁnd the desired fractional linear
transformation solve the following equation for w.
w −w1
w −w3
· w2 −w3
w2 −w1
= z −z1
z −z3
· z2 −z3
z2 −z1

27.3.
RIEMANN MAPPING THEOREM
739
The result will be a fractional linear transformation with the desired properties.
If any of the points equals ∞, then the quotient containing this point should be
adjusted.
Why should this procedure work? Here is a heuristic argument to indicate why
you would expect this to happen rather than a rigorous proof. The reader may
want to tighten the argument to give a proof. First suppose z = z1. Then the right
side equals zero and so the left side also must equal zero. However, this requires
w = w1. Next suppose z = z2. Then the right side equals 1. To get a 1 on the left,
you need w = w2. Finally suppose z = z3. Then the right side involves division by
0. To get the same bad behavior, on the left, you need w = w3.
Example 27.5 Let Im ξ > 0 and consider the fractional linear transformation
which takes ξ to 0, ξ to ∞and 0 to ξ/ξ, .
The equation for w is
w −0
w −
¡
ξ/ξ
¢ = z −ξ
z −0 · ξ −0
ξ −ξ
After some computations,
w = z −ξ
z −ξ .
Note that this has the property that x−ξ
x−ξ is always a point on the unit circle because
it is a complex number divided by its conjugate. Therefore, this fractional linear
transformation maps the real line to the unit circle. It also takes the point, ξ to
0 and so it must map the upper half plane to the unit disk. You can verify the
mapping is onto as well.
Example 27.6 Let z1 = 0, z2 = 1, and z3 = 2 and let w1 = 0, w2 = i, and w3 = 2i.
Then the equation to solve is
w
w −2i · −i
i =
z
z −2 · −1
1
Solving this yields w = iz which clearly works.
27.3
Riemann Mapping Theorem
From the open mapping theorem analytic functions map regions to other regions or
else to single points. The Riemann mapping theorem states that for every simply
connected region, Ωwhich is not equal to all of C there exists an analytic function,
f such that f (Ω) = B (0, 1) and in addition to this, f is one to one. The proof
involves several ideas which have been developed up to now. The proof is based on
the following important theorem, a case of Montel’s theorem. Before, beginning,
note that the Riemann mapping theorem is a classic example of a major existence

740
COMPLEX MAPPINGS
theorem. In mathematics there are two sorts of questions, those related to whether
something exists and those involving methods for ﬁnding it. The real questions are
often related to questions of existence. There is a long and involved history for
proofs of this theorem. The ﬁrst proofs were based on the Dirichlet principle and
turned out to be incorrect, thanks to Weierstrass who pointed out the errors. For
more on the history of this theorem, see Hille [27].
The following theorem is really wonderful. It is about the existence of a subse-
quence having certain salubrious properties. It is this wonderful result which will
give the existence of the mapping desired. The other parts of the argument are
technical details to set things up and use this theorem.
27.3.1
Montel’s Theorem
Theorem 27.7 Let Ωbe an open set in C and let F denote a set of analytic
functions mapping Ωto B (0, M) ⊆C. Then there exists a sequence of functions
from F, {fn}∞
n=1 and an analytic function, f such that f (k)
n
converges uniformly to
f (k) on every compact subset of Ω.
Proof: First note there exists a sequence of compact sets, Kn such that Kn ⊆
int Kn+1 ⊆Ωfor all n where here int K denotes the interior of the set K, the
union of all open sets contained in K and ∪∞
n=1Kn = Ω. In fact, you can verify
that B (0, n) ∩
©
z ∈Ω: dist
¡
z, ΩC¢
≤1
n
ª
works for Kn. Then there exist positive
numbers, δn such that if z ∈Kn, then B (z, δn) ⊆int Kn+1. Now denote by Fn
the set of restrictions of functions of F to Kn. Then let z ∈Kn and let γ (t) ≡
z + δneit, t ∈[0, 2π] . It follows that for z1 ∈B (z, δn) , and f ∈F,
|f (z) −f (z1)|
=
¯¯¯¯
1
2πi
Z
γ
f (w)
µ
1
w −z −
1
w −z1
¶
dw
¯¯¯¯
≤
1
2π
¯¯¯¯
Z
γ
f (w)
z −z1
(w −z) (w −z1)dw
¯¯¯¯
Letting |z1 −z| < δn
2 ,
|f (z) −f (z1)|
≤
M
2π 2πδn
|z −z1|
δ2
n/2
≤
2M |z −z1|
δn
.
It follows that Fn is equicontinuous and uniformly bounded so by the Arzela Ascoli
theorem there exists a sequence, {fnk}∞
k=1 ⊆F which converges uniformly on Kn.
Let {f1k}∞
k=1 converge uniformly on K1. Then use the Arzela Ascoli theorem applied
to this sequence to get a subsequence, denoted by {f2k}∞
k=1 which also converges
uniformly on K2. Continue in this way to obtain {fnk}∞
k=1 which converges uni-
formly on K1, · · ·, Kn. Now the sequence {fnn}∞
n=m is a subsequence of {fmk} ∞
k=1
and so it converges uniformly on Km for all m. Denoting fnn by fn for short, this

27.3.
RIEMANN MAPPING THEOREM
741
is the sequence of functions promised by the theorem. It is clear {fn}∞
n=1 converges
uniformly on every compact subset of Ωbecause every such set is contained in Km
for all m large enough. Let f (z) be the point to which fn (z) converges. Then f
is a continuous function deﬁned on Ω. Is f is analytic? Yes it is by Lemma 24.18.
Alternatively, you could let T ⊆Ωbe a triangle. Then
Z
∂T
f (z) dz = lim
n→∞
Z
∂T
fn (z) dz = 0.
Therefore, by Morera’s theorem, f is analytic.
As for the uniform convergence of the derivatives of f, recall Theorem 24.52
about the existence of a cycle.
Let K be a compact subset of int (Kn) and let
{γk}m
k=1 be closed oriented curves contained in
int (Kn) \ K
such that Pm
k=1 n (γk, z) = 1 for every z ∈K.
Also let η denote the distance
between ∪jγ∗
j and K. Then for z ∈K,
¯¯¯f (k) (z) −f (k)
n
(z)
¯¯¯
=
¯¯¯¯¯¯
k!
2πi
m
X
j=1
Z
γj
f (w) −fn (w)
(w −z)k+1
dw
¯¯¯¯¯¯
≤
k!
2π ||fk −f||Kn
m
X
j=1
(length of γk)
1
ηk+1 .
where here ||fk −f||Kn ≡sup {|fk (z) −f (z)| : z ∈Kn} . Thus you get uniform
convergence of the derivatives.
Since the family, F satisﬁes the conclusion of Theorem 27.7 it is known as a
normal family of functions. More generally,
Deﬁnition 27.8 Let F denote a collection of functions which are analytic on Ω, a
region. Then F is normal if every sequence contained in F has a subsequence which
converges uniformly on compact subsets of Ω.
The following result is about a certain class of fractional linear transformations.
Recall Lemma 25.18 which is listed here for convenience.
Lemma 27.9 For α ∈B (0, 1) , let
φα (z) ≡z −α
1 −αz .
Then φα maps B (0, 1) one to one and onto B (0, 1), φ−1
α
= φ−α, and
φ′
α (α) =
1
1 −|α|2 .

742
COMPLEX MAPPINGS
The next lemma, known as Schwarz’s lemma is interesting for its own sake but
will also be an important part of the proof of the Riemann mapping theorem. It
was stated and proved earlier but for convenience it is given again here.
Lemma 27.10 Suppose F : B (0, 1) →B (0, 1) , F is analytic, and F (0) = 0. Then
for all z ∈B (0, 1) ,
|F (z)| ≤|z| ,
(27.3)
and
|F ′ (0)| ≤1.
(27.4)
If equality holds in 27.4 then there exists λ ∈C with |λ| = 1 and
F (z) = λz.
(27.5)
Proof: First note that by assumption, F (z) /z has a removable singularity at
0 if its value at 0 is deﬁned to be F ′ (0) . By the maximum modulus theorem, if
|z| < r < 1,
¯¯¯¯
F (z)
z
¯¯¯¯ ≤max
t∈[0,2π]
¯¯F
¡
reit¢¯¯
r
≤1
r .
Then letting r →1,
¯¯¯¯
F (z)
z
¯¯¯¯ ≤1
this shows 27.3 and it also veriﬁes 27.4 on taking the limit as z →0. If equality
holds in 27.4, then |F (z) /z| achieves a maximum at an interior point so F (z) /z
equals a constant, λ by the maximum modulus theorem. Since F (z) = λz, it follows
F ′ (0) = λ and so |λ| = 1. This proves the lemma.
Deﬁnition 27.11 A region, Ωhas the square root property if whenever f, 1
f : Ω→
C are both analytic1, it follows there exists φ : Ω→C such that φ is analytic and
f (z) = φ2 (z) .
The next theorem will turn out to be equivalent to the Riemann mapping the-
orem.
27.3.2
Regions With Square Root Property
Theorem 27.12 Let Ω̸= C for Ωa region and suppose Ωhas the square root
property. Then for z0 ∈Ωthere exists h : Ω→B (0, 1) such that h is one to one,
onto, analytic, and h (z0) = 0.
Proof: Deﬁne F to be the set of functions, f such that f : Ω→B (0, 1) is one
to one and analytic. The ﬁrst task is to show F is nonempty. Then, using Montel’s
theorem it will be shown there is a function in F, h, such that |h′ (z0)| ≥
¯¯ψ′ (z0)
¯¯
1This implies f has no zero on Ω.

27.3.
RIEMANN MAPPING THEOREM
743
for all ψ ∈F. When this has been done it will be shown that h is actually onto.
This will prove the theorem.
Claim 1: F is nonempty.
Proof of Claim 1: Since Ω̸= C it follows there exists ξ /∈Ω. Then it follows
z −ξ and
1
z−ξ are both analytic on Ω.
Since Ωhas the square root property,
there exists an analytic function, φ : Ω→C such that φ2 (z) = z −ξ for all
z ∈Ω, φ (z) = √z −ξ. Since z −ξ is not constant, neither is φ and it follows
from the open mapping theorem that φ (Ω) is a region. Note also that φ is one
to one because if φ (z1) = φ (z2) , then you can square both sides and conclude
z1 −ξ = z2 −ξ implying z1 = z2.
Now pick a ∈φ (Ω) . Thus √za −ξ = a. I claim there exists a positive lower
bound to
¯¯√z −ξ + a
¯¯ for z ∈Ω. If not, there exists a sequence, {zn} ⊆Ωsuch
that
p
zn −ξ + a =
p
zn −ξ +
p
za −ξ ≡εn →0.
Then
p
zn −ξ =
³
εn −
p
za −ξ
´
(27.6)
and squaring both sides,
zn −ξ = ε2
n + za −ξ −2εn
p
za −ξ.
Consequently, (zn −za) = ε2
n −2εn
√za −ξ which converges to 0. Taking the limit
in 27.6, it follows 2√za −ξ = 0 and so ξ = za, a contradiction to ξ /∈Ω. Choose
r > 0 such that for all z ∈Ω,
¯¯√z −ξ + a
¯¯ > r > 0. Then consider
ψ (z) ≡
r
√z −ξ + a.
(27.7)
This is one to one, analytic, and maps Ωinto B (0, 1) (
¯¯√z −ξ + a
¯¯ > r). Thus F
is not empty and this proves the claim.
Claim 2: Let z0 ∈Ω. There exists a ﬁnite positive real number, η, deﬁned by
η ≡sup
©¯¯ψ′ (z0)
¯¯ : ψ ∈F
ª
(27.8)
and an analytic function, h ∈F such that |h′ (z0)| = η. Furthermore, h (z0) = 0.
Proof of Claim 2: First you show η < ∞. Let γ (t) = z0 + reit for t ∈[0, 2π]
and r is small enough that B (z0, r) ⊆Ω. Then for ψ ∈F, the Cauchy integral
formula for the derivative implies
ψ′ (z0) =
1
2πi
Z
γ
ψ (w)
(w −z0)2 dw
and so
¯¯ψ′ (z0)
¯¯ ≤(1/2π) 2πr
¡
1/r2¢
= 1/r. Therefore, η < ∞as desired. For ψ
deﬁned above in 27.7
ψ′ (z0) =
−rφ′ (z0)
(φ (z0) + a)2 = −r (1/2)
¡√z0 −ξ
¢−1
(φ (z0) + a)2
̸= 0.

744
COMPLEX MAPPINGS
Therefore, η > 0. It remains to verify the existence of the function, h.
By Theorem 27.7, there exists a sequence, {ψn}, of functions in F and an
analytic function, h, such that
¯¯ψ′
n (z0)
¯¯ →η
(27.9)
and
ψn →h, ψ′
n →h′,
(27.10)
uniformly on all compact subsets of Ω. It follows
|h′ (z0)| = lim
n→∞
¯¯ψ′
n (z0)
¯¯ = η
(27.11)
and for all z ∈Ω,
|h (z)| = lim
n→∞|ψn (z)| ≤1.
(27.12)
By 27.11, h is not a constant. Therefore, in fact, |h (z)| < 1 for all z ∈Ωin
27.12 by the open mapping theorem.
Next it must be shown that h is one to one in order to conclude h ∈F. Pick
z1 ∈Ωand suppose z2 is another point of Ω. Since the zeros of h −h (z1) have no
limit point, there exists a circular contour bounding a circle which contains z2 but
not z1 such that γ∗contains no zeros of h −h (z1).
t
z1
?

6
γ
t
z2
Using the theorem on counting zeros, Theorem 25.20, and the fact that ψn is
one to one,
0
=
lim
n→∞
1
2πi
Z
γ
ψ′
n (w)
ψn (w) −ψn (z1)dw
=
1
2πi
Z
γ
h′ (w)
h (w) −h (z1)dw,
which shows that h−h (z1) has no zeros in B (z2, r) . In particular z2 is not a zero of
h −h (z1) . This shows that h is one to one since z2 ̸= z1 was arbitrary. Therefore,
h ∈F. It only remains to verify that h (z0) = 0.
If h (z0) ̸= 0,consider φh(z0) ◦h where φα is the fractional linear transformation
deﬁned in Lemma 27.9. By this lemma it follows φh(z0) ◦h ∈F. Now using the

27.3.
RIEMANN MAPPING THEOREM
745
chain rule,
¯¯¯¯
³
φh(z0) ◦h
´′
(z0)
¯¯¯¯
=
¯¯¯φ′
h(z0) (h (z0))
¯¯¯ |h′ (z0)|
=
¯¯¯¯¯
1
1 −|h (z0)|2
¯¯¯¯¯ |h′ (z0)|
=
¯¯¯¯¯
1
1 −|h (z0)|2
¯¯¯¯¯ η > η
Contradicting the deﬁnition of η. This proves Claim 2.
Claim 3: The function, h just obtained maps Ωonto B (0, 1).
Proof of Claim 3: To show h is onto, use the fractional linear transformation
of Lemma 27.9. Suppose h is not onto. Then there exists α ∈B (0, 1)\h (Ω) . Then
0 ̸= φα ◦h (z) for all z ∈Ωbecause
φα ◦h (z) = h (z) −α
1 −αh (z)
and it is assumed α /∈h (Ω) . Therefore, since Ωhas the square root property, you
can consider an analytic function z →
p
φα ◦h (z). This function is one to one
because both φα and h are. Also, the values of this function are in B (0, 1) by
Lemma 27.9 so it is in F.
Now let
ψ ≡φ√
φα◦h(z0) ◦
p
φα ◦h.
(27.13)
Thus
ψ (z0) = φ√
φα◦h(z0) ◦
p
φα ◦h (z0) = 0
and ψ is a one to one mapping of Ωinto B (0, 1) so ψ is also in F. Therefore,
¯¯ψ′ (z0)
¯¯ ≤η,
¯¯¯¯
³p
φα ◦h
´′
(z0)
¯¯¯¯ ≤η.
(27.14)
Deﬁne s (w) ≡w2. Then using Lemma 27.9, in particular, the description of φ−1
α
=
φ−α, you can solve 27.13 for h to obtain
h (z)
=
φ−α ◦s ◦φ−√
φα◦h(z0) ◦ψ
=


≡F
z
}|
{
φ−α ◦s ◦φ−√
φα◦h(z0) ◦ψ

(z)
=
(F ◦ψ) (z)
(27.15)
Now
F (0) = φ−α ◦s ◦φ−√
φα◦h(z0) (0) = φ−1
α (φα ◦h (z0)) = h (z0) = 0

746
COMPLEX MAPPINGS
and F maps B (0, 1) into B (0, 1). Also, F is not one to one because it maps B (0, 1)
to B (0, 1) and has s in its deﬁnition. Thus there exists z1 ∈B (0, 1) such that
φ−√
φα◦h(z0) (z1) = −1
2 and another point z2 ∈B (0, 1) such that φ−√
φα◦h(z0) (z2) =
1
2. However, thanks to s, F (z1) = F (z2).
Since F (0) = h (z0) = 0, you can apply the Schwarz lemma to F. Since F is
not one to one, it can’t be true that F (z) = λz for |λ| = 1 and so by the Schwarz
lemma it must be the case that |F ′ (0)| < 1. But this implies from 27.15 and 27.14
that
η
=
|h′ (z0)| = |F ′ (ψ (z0))|
¯¯ψ′ (z0)
¯¯
=
|F ′ (0)|
¯¯ψ′ (z0)
¯¯ <
¯¯ψ′ (z0)
¯¯ ≤η,
a contradiction. This proves the theorem.
The following lemma yields the usual form of the Riemann mapping theorem.
Lemma 27.13 Let Ωbe a simply connected region with Ω̸= C. Then Ωhas the
square root property.
Proof: Let f and
1
f both be analytic on Ω. Then f ′
f is analytic on Ωso by
Corollary 24.50, there exists eF, analytic on Ωsuch that eF ′ =
f ′
f
on Ω. Then
³
fe−e
F ´′
= 0 and so f (z) = Ce e
F = ea+ibe e
F . Now let F = eF + a + ib. Then F is
still a primitive of f ′/f and f (z) = eF (z). Now let φ (z) ≡e
1
2 F (z). Then φ is the
desired square root and so Ωhas the square root property.
Corollary 27.14 (Riemann mapping theorem) Let Ωbe a simply connected region
with Ω̸= C and let z0 ∈Ω. Then there exists a function, f : Ω→B (0, 1) such
that f is one to one, analytic, and onto with f (z0) = 0. Furthermore, f −1 is also
analytic.
Proof: From Theorem 27.12 and Lemma 27.13 there exists a function, f : Ω→
B (0, 1) which is one to one, onto, and analytic such that f (z0) = 0. The assertion
that f −1 is analytic follows from the open mapping theorem.
27.4
Analytic Continuation
27.4.1
Regular And Singular Points
Given a function which is analytic on some set, can you extend it to an analytic
function deﬁned on a larger set? Sometimes you can do this. It was done in the
proof of the Cauchy integral formula. There are also reﬂection theorems like those
discussed in the exercises starting with Problem 10 on Page 678. Here I will give a
systematic way of extending an analytic function to a larger set. I will emphasize
simply connected regions. The subject of analytic continuation is much larger than
the introduction given here. A good source for much more on this is found in Alfors

27.4.
ANALYTIC CONTINUATION
747
[2]. The approach given here is suggested by Rudin [45] and avoids many of the
standard technicalities.
Deﬁnition 27.15 Let f be analytic on B (a, r) and let β ∈∂B (a, r) . Then β is
called a regular point of f if there exists some δ > 0 and a function, g analytic on
B (β, δ) such that g = f on B (β, δ) ∩B (a, r) . Those points of ∂B (a, r) which are
not regular are called singular.
r a
rβ
Theorem 27.16 Suppose f is analytic on B (a, r) and the power series
f (z) =
∞
X
k=0
ak (z −a)k
has radius of convergence r. Then there exists a singular point on ∂B (a, r).
Proof: If not, then for every z ∈∂B (a, r) there exists δz > 0 and gz analytic
on B (z, δz) such that gz = f on B (z, δz) ∩B (a, r) . Since ∂B (a, r) is compact,
there exist z1, ···, zn, points in ∂B (a, r) such that {B (zk, δzk)}n
k=1 covers ∂B (a, r) .
Now deﬁne
g (z) ≡
½
f (z) if z ∈B (a, r)
gzk (z) if z ∈B (zk, δzk)
Is this well deﬁned? If z ∈B (zi, δzi) ∩B
¡
zj, δzj
¢
, is gzi (z) = gzj (z)? Consider the
following picture representing this situation.
You see that if z ∈B (zi, δzi) ∩B
¡
zj, δzj
¢
then I ≡B (zi, δzi) ∩B
¡
zj, δzj
¢
∩
B (a, r) is a nonempty open set. Both gzi and gzj equal f on I. Therefore, they
must be equal on B (zi, δzi) ∩B
¡
zj, δzj
¢
because I has a limit point. Therefore,
g is well deﬁned and analytic on an open set containing B (a, r). Since g agrees

748
COMPLEX MAPPINGS
with f on B (a, r) , the power series for g is the same as the power series for f and
converges on a ball which is larger than B (a, r) contrary to the assumption that the
radius of convergence of the above power series equals r. This proves the theorem.
27.4.2
Continuation Along A Curve
Next I will describe what is meant by continuation along a curve. The following
deﬁnition is standard and is found in Rudin [45].
Deﬁnition 27.17 A function element is an ordered pair, (f, D) where D is an open
ball and f is analytic on D. (f0, D0) and (f1, D1) are direct continuations of each
other if D1 ∩D0 ̸= ∅and f0 = f1 on D1 ∩D0. In this case I will write (f0, D0) ∼
(f1, D1) . A chain is a ﬁnite sequence, of disks, {D0, · · ·, Dn} such that Di−1 ∩Di ̸=
∅. If (f0, D0) is a given function element and there exist function elements, (fi, Di)
such that {D0, · · ·, Dn} is a chain and (fj−1, Dj−1) ∼(fj, Dj) then (fn, Dn) is
called the analytic continuation of (f0, D0) along the chain {D0, · · ·, Dn}.
Now
suppose γ is an oriented curve with parameter interval [a, b] and there exists a chain,
{D0, · · ·, Dn} such that γ∗⊆∪n
k=1Dk, γ (a) is the center of D0, γ (b) is the center
of Dn, and there is an increasing list of numbers in [a, b] , a = s0 < s1 · ·· < sn = b
such that γ ([si, si+1]) ⊆Di and (fn, Dn) is an analytic continuation of (f0, D0)
along the chain. Then (fn, Dn) is called an analytic continuation of (f0, D0) along
the curve γ. (γ will always be a continuous curve. Nothing more is needed. )
In the above situation it does not follow that if Dn ∩D0 ̸= ∅, that fn = f0! How-
ever, there are some cases where this will happen. This is the monodromy theorem
which follows. This is as far as I will go on the subject of analytic continuation. For
more on this subject including a development of the concept of Riemann surfaces,
see Alfors [2].
Lemma 27.18 Suppose (f, B (0, r)) for r < 1 is a function element and (f, B (0, r))
can be analytically continued along every curve in B (0, 1) that starts at 0. Then
there exists an analytic function, g deﬁned on B (0, 1) such that g = f on B (0, r) .
Proof: Let
R
=
sup{r1 ≥r such that there exists gr1
analytic on B (0, r1) which agrees with f on B (0, r) .}
Deﬁne gR (z) ≡gr1 (z) where |z| < r1. This is well deﬁned because if you use r1
and r2, both gr1 and gr2 agree with f on B (0, r), a set with a limit point and so
the two functions agree at every point in both B (0, r1) and B (0, r2). Thus gR is
analytic on B (0, R) . If R < 1, then by the assumption there are no singular points
on B (0, R) and so Theorem 27.16 implies the radius of convergence of the power
series for gR is larger than R contradicting the choice of R. Therefore, R = 1 and
this proves the lemma. Let g = gR.
The following theorem is the main result in this subject, the monodromy theo-
rem.

27.5.
THE PICARD THEOREMS
749
Theorem 27.19 Let Ωbe a simply connected proper subset of C and suppose
(f, B (a, r)) is a function element with B (a, r) ⊆Ω. Suppose also that this function
element can be analytically continued along every curve through a. Then there exists
G analytic on Ωsuch that G agrees with f on B (a, r).
Proof: By the Riemann mapping theorem, there exists h : Ω→B (0, 1) which
is analytic, one to one and onto such that f (a) = 0. Since h is an open map, there
exists δ > 0 such that
B (0, δ) ⊆h (B (a, r)) .
It follows f ◦h−1 can be analytically continued along every curve through 0. By
Lemma 27.18 there exists g analytic on B (0, 1) which agrees with f ◦h−1 on B (0, δ).
Deﬁne G (z) ≡g (h (z)) . For z = h−1 (w) , it follows G
¡
h−1 (w)
¢
= g (w) . If w ∈
B (0, δ) , then G
¡
h−1 (w)
¢
= f ◦h−1 (w) and so G = f on h−1 (B (0, δ)) , an open
set contained in B (a, r). Therefore, G = f on B (a, r) because h−1 (B (0, δ)) has a
limit point. This proves the theorem.
Actually, you sometimes want to consider the case where Ω= C. This requires
a small modiﬁcation to obtain from the above theorem.
Corollary 27.20 Suppose (f, B (a, r)) is a function element with B (a, r) ⊆C.
Suppose also that this function element can be analytically continued along every
curve through a. Then there exists G analytic on C such that G agrees with f on
B (a, r).
Proof: Let Ω1 ≡{z ∈C : a + it : t > a} and Ω2 ≡{z ∈C : a −it : t > a} . Here
is a picture of Ω1.
Ω1
a
r
A picture of Ω2 is similar except the line extends down from the boundary of
B (a, r).
Thus B (a, r) ⊆Ωi and Ωi is simply connected and proper. By Theorem 27.19
there exist analytic functions, Gi analytic on Ωi such that Gi = f on B (a, r). Thus
G1 = G2 on B (a, r) , a set with a limit point. Therefore, G1 = G2 on Ω1 ∩Ω2. Now
let G (z) = Gi (z) where z ∈Ωi. This is well deﬁned and analytic on C. This proves
the corollary.
27.5
The Picard Theorems
The Picard theorem says that if f is an entire function and there are two complex
numbers not contained in f (C) , then f is constant. This is certainly one of the
most amazing things which could be imagined.
However, this is only the little

750
COMPLEX MAPPINGS
Picard theorem. The big Picard theorem is even more incredible. This one asserts
that to be non constant the entire function must take every value of C but two
inﬁnitely many times! I will begin with the little Picard theorem. The method of
proof I will use is the one found in Saks and Zygmund [47], Conway [13] and Hille
[27]. This is not the way Picard did it in 1879. That approach is very diﬀerent and
is presented at the end of the material on elliptic functions. This approach is much
more recent dating it appears from around 1924.
Lemma 27.21 Let f be analytic on a region containing B (0, r) and suppose
|f ′ (0)| = b > 0, f (0) = 0,
and |f (z)| ≤M for all z ∈B (0, r). Then f (B (0, r)) ⊇B
³
0, r2b2
6M
´
.
Proof: By assumption,
f (z) =
∞
X
k=0
akzk, |z| ≤r.
(27.16)
Then by the Cauchy integral formula for the derivative,
ak =
1
2πi
Z
∂B(0,r)
f (w)
wk+1 dw
where the integral is in the counter clockwise direction. Therefore,
|ak| ≤1
2π
Z 2π
0
¯¯f
¡
reiθ¢¯¯
rk
dθ ≤M
rk .
In particular, br ≤M. Therefore, from 27.16
|f (z)|
≥
b |z| −
∞
X
k=2
M
rk |z|k = b |z| −
M
³
|z|
r
´2
1 −|z|
r
=
b |z| −
M |z|2
r2 −r |z|
Suppose |z| = r2b
4M < r. Then this is no larger than
1
4b2r2
3M −br
M (4M −br) ≥1
4b2r2
3M −M
M (4M −M) = r2b2
6M .
Let |w| < r2b
4M . Then for |z| = r2b
4M and the above,
|w| = |(f (z) −w) −f (z)| < r2b
4M ≤|f (z)|
and so by Rouche’s theorem, z →f (z)−w and z →f (z) have the same number of
zeros in B
³
0, r2b
4M
´
. But f has at least one zero in this ball and so this shows there
exists at least one z ∈B
³
0, r2b
4M
´
such that f (z) −w = 0. This proves the lemma.

27.5.
THE PICARD THEOREMS
751
27.5.1
Two Competing Lemmas
Lemma 27.21 is a really nice lemma but there is something even better, Bloch’s
lemma.
This lemma does not depend on the bound of f.
Like the above two
lemmas it is interesting for its own sake and in addition is the key to a fairly short
proof of Picard’s theorem. It features the number
1
24. The best constant is not
currently known.
Lemma 27.22 Let f be analytic on an open set containing B (0, R) and suppose
|f ′ (0)| > 0. Then there exists a ∈B (0, R) such that
f (B (0, R)) ⊇B
µ
f (a) , |f ′ (0)| R
24
¶
.
Proof: Let K (ρ) ≡max {|f ′ (z)| : |z| = ρ} . For simplicity, let Cρ ≡{z : |z| = ρ}.
Claim: K is continuous from the left.
Proof of claim: Let zρ ∈Cρ such that |f ′ (zρ)| = K (ρ) . Then by the maximum
modulus theorem, if λ ∈(0, 1) ,
|f ′ (λzρ)| ≤K (λρ) ≤K (ρ) = |f ′ (zρ)| .
Letting λ →1 yields the claim.
Let ρ0 be the largest such that (R −ρ0) K (ρ0) = R |f ′ (0)| . (Note (R −0) K (0) =
R |f ′ (0)| .) Thus ρ0 < R because (R −R) K (R) = 0. Let |a| = ρ0 such that
|f ′ (a)| = K (ρ0). Thus
|f ′ (a)| (R −ρ0) = |f ′ (0)| R
(27.17)
Now let r = R−ρ0
2
. From 27.17,
|f ′ (a)| r = 1
2 |f ′ (0)| R, B (a, r) ⊆B (0, ρ0 + r) ⊆B (0, R) .
(27.18)
r
0
ra

752
COMPLEX MAPPINGS
Therefore, if z ∈B (a, r) , it follows from the maximum modulus theorem and
the deﬁnition of ρ0 that
|f ′ (z)|
≤
K (ρ0 + r) <
R |f ′ (0)|
R −ρ0 −r = 2R |f ′ (0)|
R −ρ0
=
2R |f ′ (0)|
2r
= R |f ′ (0)|
r
(27.19)
Let g (z) = f (a + z) −f (a) where z ∈B (0, r) . Then |g′ (0)| = |f ′ (a)| > 0 and
for z ∈B (0, r),
|g (z)| ≤
¯¯¯¯¯
Z
γ(a,z)
g′ (w) dw
¯¯¯¯¯ ≤|z −a| R |f ′ (0)|
r
= R |f ′ (0)| .
By Lemma 27.21 and 27.18,
g (B (0, r))
⊇
B
Ã
0, r2 |f ′ (a)|2
6R |f ′ (0)|
!
=
B
Ã
0, r2 ¡ 1
2r |f ′ (0)| R
¢2
6R |f ′ (0)|
!
= B
µ
0, |f ′ (0)| R
24
¶
Now g (B (0, r)) = f (B (a, r)) −f (a) and so this implies
f (B (0, R)) ⊇f (B (a, r)) ⊇B
µ
f (a) , |f ′ (0)| R
24
¶
.
This proves the lemma.
Here is a slightly more general version which allows the center of the open set
to be arbitrary.
Lemma 27.23 Let f be analytic on an open set containing B (z0, R) and suppose
|f ′ (z0)| > 0. Then there exists a ∈B (z0, R) such that
f (B (z0, R)) ⊇B
µ
f (a) , |f ′ (z0)| R
24
¶
.
Proof: You look at g (z) ≡f (z0 + z) −f (z0) for z ∈B (0, R) . Then g′ (0) =
f ′ (z0) and so by Lemma 27.22 there exists a1 ∈B (0, R) such that
g (B (0, R)) ⊇B
µ
g (a1) , |f ′ (z0)| R
24
¶
.
Now g (B (0, R)) = f (B (z0, R)) −f (z0) and g (a1) = f (a) −f (z0) for some a ∈
B (z0, R) and so
f (B (z0, R)) −f (z0)
⊇
B
µ
g (a1) , |f ′ (z0)| R
24
¶
=
B
µ
f (a) −f (z0) , |f ′ (z0)| R
24
¶

27.5.
THE PICARD THEOREMS
753
which implies
f (B (z0, R)) ⊇B
µ
f (a) , |f ′ (z0)| R
24
¶
as claimed. This proves the lemma.
No attempt was made to ﬁnd the best number to multiply by R |f ′ (z0)|. A
discussion of this is given in Conway [13]. See also [27]. Much larger numbers than
1/24 are available and there is a conjecture due to Alfors about the best value. The
conjecture is that 1/24 can be replaced with
Γ
¡ 1
3
¢
Γ
¡ 11
12
¢
¡
1 +
√
3
¢1/2 Γ
¡ 1
4
¢ ≈. 471 86
You can see there is quite a gap between the constant for which this lemma is proved
above and what is thought to be the best constant.
Bloch’s lemma above gives the existence of a ball of a certain size inside the
image of a ball. By contrast the next lemma leads to conditions under which the
values of a function do not contain a ball of certain radius. It concerns analytic
functions which do not achieve the values 0 and 1.
Lemma 27.24 Let F denote the set of functions, f deﬁned on Ω, a simply con-
nected region which do not achieve the values 0 and 1. Then for each such function,
it is possible to deﬁne a function analytic on Ω, H (z) by the formula
H (z) ≡log
"r
log (f (z))
2πi
−
r
log (f (z))
2πi
−1
#
.
There exists a constant C independent of f ∈F such that H (Ω) does not contain
any ball of radius C.
Proof: Let f ∈F. Then since f does not take the value 0, there exists g1 a
primitive of f ′/f. Thus
d
dz
¡
e−g1f
¢
= 0
so there exists a, b such that f (z) e−g1(z) = ea+bi. Letting g (z) = g1 (z) + a + ib, it
follows eg(z) = f (z). Let log (f (z)) = g (z). Then for n ∈Z, the integers,
log (f (z))
2πi
, log (f (z))
2πi
−1 ̸= n
because if equality held, then f (z) = 1 which does not happen. It follows log(f(z))
2πi
and log(f(z))
2πi
−1 are never equal to zero. Therefore, using the same reasoning, you
can deﬁne a logarithm of these two quantities and therefore, a square root. Hence
there exists a function analytic on Ω,
r
log (f (z))
2πi
−
r
log (f (z))
2πi
−1.
(27.20)

754
COMPLEX MAPPINGS
For n a positive integer, this function cannot equal √n ± √n −1 because if it did,
then
Ãr
log (f (z))
2πi
−
r
log (f (z))
2πi
−1
!
= √n ±
√
n −1
(27.21)
and you could take reciprocals of both sides to obtain
Ãr
log (f (z))
2πi
+
r
log (f (z))
2πi
−1
!
= √n ∓
√
n −1.
(27.22)
Then adding 27.21 and 27.22
2
r
log (f (z))
2πi
= 2√n
which contradicts the above observation that log(f(z))
2πi
is not equal to an integer.
Also, the function of 27.20 is never equal to zero. Therefore, you can deﬁne the
logarithm of this function also. It follows
H (z) ≡log
Ãr
log (f (z))
2πi
−
r
log (f (z))
2πi
−1
!
̸= ln
¡√n ±
√
n −1
¢
+ 2mπi
where m is an arbitrary integer and n is a positive integer. Now
lim
n→∞ln
¡√n +
√
n −1
¢
= ∞
and limn→∞ln
¡√n −√n −1
¢
= −∞and so C is covered by rectangles having
vertices at points ln
¡√n ± √n −1
¢
+ 2mπi as described above.
Each of these
rectangles has height equal to 2π and a short computation shows their widths are
bounded. Therefore, there exists C independent of f ∈F such that C is larger
than the diameter of all these rectangles. Hence H (Ω) cannot contain any ball of
radius larger than C.
27.5.2
The Little Picard Theorem
Now here is the little Picard theorem. It is easy to prove from the above.
Theorem 27.25 If h is an entire function which omits two values then h is a
constant.
Proof: Suppose the two values omitted are a and b and that h is not constant.
Let f (z) = (h (z) −a) / (b −a). Then f omits the two values 0 and 1. Let H be
deﬁned in Lemma 27.24. Then H (z) is clearly not of the form az+b because then it
would have values equal to the vertices ln
¡√n ± √n −1
¢
+2mπi or else be constant
neither of which happen if h is not constant. Therefore, by Liouville’s theorem, H′
must be unbounded. Pick ξ such that |H′ (ξ)| > 24C where C is such that H (C)

27.5.
THE PICARD THEOREMS
755
contains no balls of radius larger than C. But by Lemma 27.23 H (B (ξ, 1)) must
contain a ball of radius |H′(ξ)|
24
> 24C
24
= C, a contradiction. This proves Picard’s
theorem.
The following is another formulation of this theorem.
Corollary 27.26 If f is a meromophic function deﬁned on C which omits three
distinct values, a, b, c, then f is a constant.
Proof: Let φ (z) ≡z−a
z−c
b−c
b−a. Then φ (c) = ∞, φ (a) = 0, and φ (b) = 1. Now
consider the function, h = φ ◦f. Then h misses the three points ∞, 0, and 1. Since
h is meromorphic and does not have ∞in its values, it must actually be analytic.
Thus h is an entire function which misses the two values 0 and 1. Therefore, h is
constant by Theorem 27.25.
27.5.3
Schottky’s Theorem
Lemma 27.27 Let f be analytic on an open set containing B (0, R) and suppose
that f does not take on either of the two values 0 or 1. Also suppose |f (0)| ≤β.
Then letting θ ∈(0, 1) , it follows
|f (z)| ≤M (β, θ)
for all z ∈B (0, θR) , where M (β, θ) is a function of only the two variables β, θ.
(In particular, there is no dependence on R.)
Proof: Consider the function, H (z) used in Lemma 27.24 given by
H (z) ≡log
Ãr
log (f (z))
2πi
−
r
log (f (z))
2πi
−1
!
.
(27.23)
You notice there are two explicit uses of logarithms. Consider ﬁrst the logarithm
inside the radicals. Choose this logarithm such that
log (f (0)) = ln |f (0)| + i arg (f (0)) , arg (f (0)) ∈(−π, π].
(27.24)
You can do this because
elog(f(0)) = f (0) = eln|f(0)|eiα = eln|f(0)|+iα
and by replacing α with α + 2mπ for a suitable integer, m it follows the above
equation still holds. Therefore, you can assume 27.24. Similar reasoning applies to
the logarithm on the outside of the parenthesis. It can be assumed H (0) equals
ln
¯¯¯¯¯
r
log (f (0))
2πi
−
r
log (f (0))
2πi
−1
¯¯¯¯¯ + i arg
Ãr
log (f (0))
2πi
−
r
log (f (0))
2πi
−1
!
(27.25)

756
COMPLEX MAPPINGS
where the imaginary part is no larger than π in absolute value.
Now if ξ ∈B (0, R) is a point where H′ (ξ) ̸= 0, then by Lemma 27.22
H (B (ξ, R −|ξ|)) ⊇B
µ
H (a) , |H′ (ξ)| (R −|ξ|)
24
¶
where a is some point in B (ξ, R −|ξ|). But by Lemma 27.24 H (B (ξ, R −|ξ|))
contains no balls of radius C where C depended only on the maximum diameters of
those rectangles having vertices ln
¡√n ± √n −1
¢
+ 2mπi for n a positive integer
and m an integer. Therefore,
|H′ (ξ)| (R −|ξ|)
24
< C
and consequently
|H′ (ξ)| <
24C
R −|ξ|.
Even if H′ (ξ) = 0, this inequality still holds. Therefore, if z ∈B (0, R) and γ (0, z)
is the straight segment from 0 to z,
|H (z) −H (0)|
=
¯¯¯¯¯
Z
γ(0,z)
H′ (w) dw
¯¯¯¯¯ =
¯¯¯¯
Z 1
0
H′ (tz) zdt
¯¯¯¯
≤
Z 1
0
|H′ (tz) z| dt ≤
Z 1
0
24C
R −t |z| |z| dt
=
24C ln
µ
R
R −|z|
¶
.
Therefore, for z ∈∂B (0, θR) ,
|H (z)| ≤|H (0)| + 24C ln
µ
1
1 −θ
¶
.
(27.26)
By the maximum modulus theorem, the above inequality holds for all |z| < θR also.
Next I will use 27.23 to get an inequality for |f (z)| in terms of |H (z)|. From
27.23,
H (z) = log
Ãr
log (f (z))
2πi
−
r
log (f (z))
2πi
−1
!
and so
2H (z)
=
log
Ãr
log (f (z))
2πi
−
r
log (f (z))
2πi
−1
!2
−2H (z)
=
log
Ãr
log (f (z))
2πi
−
r
log (f (z))
2πi
−1
!−2
=
log
Ãr
log (f (z))
2πi
+
r
log (f (z))
2πi
−1
!2

27.5.
THE PICARD THEOREMS
757
Therefore,
Ãr
log (f (z))
2πi
+
r
log (f (z))
2πi
−1
!2
+
Ãr
log (f (z))
2πi
−
r
log (f (z))
2πi
−1
!2
=
exp (2H (z)) + exp (−2H (z))
and
µlog (f (z))
πi
−1
¶
= 1
2 (exp (2H (z)) + exp (−2H (z))) .
Thus
log (f (z)) = πi + πi
2 (exp (2H (z)) + exp (−2H (z)))
which shows
|f (z)|
=
¯¯¯¯exp
·πi
2 (exp (2H (z)) + exp (−2H (z)))
¸¯¯¯¯
≤
exp
¯¯¯¯
πi
2 (exp (2H (z)) + exp (−2H (z)))
¯¯¯¯
≤
exp
¯¯¯π
2 (|exp (2H (z))| + |exp (−2H (z))|)
¯¯¯
≤
exp
¯¯¯π
2 (exp (2 |H (z)|) + exp (|−2H (z)|))
¯¯¯
=
exp (π exp 2 |H (z)|) .
Now from 27.26 this is dominated by
exp
µ
π exp 2
µ
|H (0)| + 24C ln
µ
1
1 −θ
¶¶¶
=
exp
µ
π exp (2 |H (0)|) exp
µ
48C ln
µ
1
1 −θ
¶¶¶
(27.27)
Consider exp (2 |H (0)|). I want to obtain an inequality for this which involves
β. This is where I will use the convention about the logarithms discussed above.
From 27.25,
2 |H (0)| = 2
¯¯¯¯¯log
Ãr
log (f (0))
2πi
−
r
log (f (0))
2πi
−1
!¯¯¯¯¯

758
COMPLEX MAPPINGS
≤
2


Ã
ln
¯¯¯¯¯
r
log (f (0))
2πi
−
r
log (f (0))
2πi
−1
¯¯¯¯¯
!2
+ π2


1/2
≤
2


¯¯¯¯¯ln
Ã¯¯¯¯¯
r
log (f (0))
2πi
¯¯¯¯¯ +
¯¯¯¯¯
r
log (f (0))
2πi
−1
¯¯¯¯¯
!¯¯¯¯¯
2
+ π2


1/2
≤
2
¯¯¯¯¯ln
Ã¯¯¯¯¯
r
log (f (0))
2πi
¯¯¯¯¯ +
¯¯¯¯¯
r
log (f (0))
2πi
−1
¯¯¯¯¯
!¯¯¯¯¯ + 2π
≤
ln
µ
2
µ¯¯¯¯
log (f (0))
2πi
¯¯¯¯ +
¯¯¯¯
log (f (0))
2πi
−1
¯¯¯¯
¶¶
+ 2π
=
ln
µµ¯¯¯¯
log (f (0))
πi
¯¯¯¯ +
¯¯¯¯
log (f (0))
πi
−2
¯¯¯¯
¶¶
+ 2π
(27.28)
Consider
¯¯¯ log(f(0))
πi
¯¯¯
log (f (0))
πi
= −ln |f (0)|
π
i + arg (f (0))
π
and so
¯¯¯¯
log (f (0))
πi
¯¯¯¯
=
Ã¯¯¯¯
ln |f (0)|
π
¯¯¯¯
2
+
µarg (f (0))
π
¶2!1/2
≤
Ã¯¯¯¯
ln β
π
¯¯¯¯
2
+
³π
π
´2
!1/2
=
Ã¯¯¯¯
ln β
π
¯¯¯¯
2
+ 1
!1/2
.
Similarly,
¯¯¯¯
log (f (0))
πi
−2
¯¯¯¯
≤
Ã¯¯¯¯
ln β
π
¯¯¯¯
2
+ (2 + 1)2
!1/2
=
Ã¯¯¯¯
ln β
π
¯¯¯¯
2
+ 9
!1/2
It follows from 27.28 that
2 |H (0)| ≤ln

2
Ã¯¯¯¯
ln β
π
¯¯¯¯
2
+ 9
!1/2
+ 2π.
Hence from 27.27
|f (z)| ≤

27.5.
THE PICARD THEOREMS
759
exp

π exp

ln

2
Ã¯¯¯¯
ln β
π
¯¯¯¯
2
+ 9
!1/2
+ 2π

exp
µ
48C ln
µ
1
1 −θ
¶¶

and so, letting M (β, θ) be given by the above expression on the right, the lemma
is proved.
The following theorem will be referred to as Schottky’s theorem. It looks just
like the above lemma except it is only assumed that f is analytic on B (0, R) rather
than on an open set containing B (0, R). Also, the case of an arbitrary center is
included along with arbitrary points which are not attained as values of the function.
Theorem 27.28 Let f be analytic on B (z0, R) and suppose that f does not take
on either of the two distinct values a or b. Also suppose |f (z0)| ≤β. Then letting
θ ∈(0, 1) , it follows
|f (z)| ≤M (a, b, β, θ)
for all z ∈B (z0, θR) , where M (a, b, β, θ) is a function of only the variables β, θ,a, b.
(In particular, there is no dependence on R.)
Proof: First you can reduce to the case where the two values are 0 and 1 by
considering
h (z) ≡f (z) −a
b −a
.
If there exists an estimate of the desired sort for h, then there exists such an estimate
for f. Of course here the function, M would depend on a and b. Therefore, there is
no loss of generality in assuming the points which are missed are 0 and 1.
Apply Lemma 27.27 to B (0, R1) for the function, g (z) ≡f (z0 + z) and R1 < R.
Then if β ≥|f (z0)| = |g (0)| , it follows |g (z)| = |f (z0 + z)| ≤M (β, θ) for every
z ∈B (0, θR1) . Now let θ ∈(0, 1) and choose R1 < R large enough that θR = θ1R1
where θ1 ∈(0, 1) . Then if |z −z0| < θR, it follows
|f (z)| ≤M (β, θ1) .
Now let R1 →R so θ1 →θ.
27.5.4
A Brief Review
First recall the deﬁnition of the metric on bC. For convenience it is listed here again.
Consider the unit sphere, S2 given by (z −1)2 +y2 +x2 = 1. Deﬁne a map from the
complex plane to the surface of this sphere as follows. Extend a line from the point,
p in the complex plane to the point (0, 0, 2) on the top of this sphere and let θ (p)
denote the point of this sphere which the line intersects. Deﬁne θ (∞) ≡(0, 0, 2).

760
COMPLEX MAPPINGS
s
s
s
(0, 0, 2)
(0, 0, 1)
s
@
@
@
@
@
@@
p
θ(p)
C
Then θ−1 is sometimes called sterographic projection. The mapping θ is clearly
continuous because it takes converging sequences, to converging sequences. Fur-
thermore, it is clear that θ−1 is also continuous. In terms of the extended complex
plane, bC, a sequence, zn converges to ∞if and only if θzn converges to (0, 0, 2) and
a sequence, zn converges to z ∈C if and only if θ (zn) →θ (z) .
In fact this makes it easy to deﬁne a metric on bC.
Deﬁnition 27.29 Let z, w ∈bC. Then let d (x, y) ≡|θ (z) −θ (w)| where this last
distance is the usual distance measured in R3.
Theorem 27.30
³
bC, d
´
is a compact, hence complete metric space.
Proof: Suppose {zn} is a sequence in bC. This means {θ (zn)} is a sequence in
S2 which is compact. Therefore, there exists a subsequence, {θznk} and a point,
z ∈S2 such that θznk →θz in S2 which implies immediately that d (znk, z) →0.
A compact metric space must be complete.
Also recall the interesting fact that meromorphic functions are continuous with
values in bC which is reviewed here for convenience. It came from the theory of
classiﬁcation of isolated singularities.
Theorem 27.31 Let Ωbe an open subset of C and let f : Ω→bC be meromorphic.
Then f is continuous with respect to the metric, d on bC.
Proof: Let zn →z where z ∈Ω. Then if z is a pole, it follows from Theorem
24.38 that
d (f (zn) , ∞) ≡d (f (zn) , f (z)) →0.
If z is not a pole, then f (zn) →f (z) in C which implies |θ (f (zn)) −θ (f (z))| =
d (f (zn) , f (z)) →0. Recall that θ is continuous on C.
The fundamental result behind all the theory about to be presented is the Ascoli
Arzela theorem also listed here for convenience.
Deﬁnition 27.32 Let (X, d) be a complete metric space.
Then it is said to be
locally compact if B (x, r) is compact for each r > 0.
Thus if you have a locally compact metric space, then if {an} is a bounded
sequence, it must have a convergent subsequence.
Let K be a compact subset of Rn and consider the continuous functions which
have values in a locally compact metric space, (X, d) where d denotes the metric on
X. Denote this space as C (K, X) .

27.5.
THE PICARD THEOREMS
761
Deﬁnition 27.33 For f, g ∈C (K, X) , where K is a compact subset of Rn and X
is a locally compact complete metric space deﬁne
ρK (f, g) ≡sup {d (f (x) , g (x)) : x ∈K} .
The Ascoli Arzela theorem, Theorem 6.24 is a major result which tells which
subsets of C (K, X) are sequentially compact.
Deﬁnition 27.34 Let A ⊆C (K, X) for K a compact subset of Rn. Then A is
said to be uniformly equicontinuous if for every ε > 0 there exists a δ > 0 such that
whenever x, y ∈K with |x −y| < δ and f ∈A,
d (f (x) , f (y)) < ε.
The set, A is said to be uniformly bounded if for some M < ∞, and a ∈X,
f (x) ∈B (a, M)
for all f ∈A and x ∈K.
The Ascoli Arzela theorem follows.
Theorem 27.35 Suppose K is a nonempty compact subset of Rn and A ⊆C (K, X) ,
is uniformly bounded and uniformly equicontinuous where X is a locally compact
complete metric space. Then if {fk} ⊆A, there exists a function, f ∈C (K, X) and
a subsequence, fkl such that
lim
l→∞ρK (fkl, f) = 0.
In the cases of interest here, X = bC with the metric deﬁned above.
27.5.5
Montel’s Theorem
The following lemma is another version of Montel’s theorem. It is this which will
make possible a proof of the big Picard theorem.
Lemma 27.36 Let Ωbe a region and let F be a set of functions analytic on Ω
none of which achieve the two distinct values, a and b. If {fn} ⊆F then one of the
following hold: Either there exists a function, f analytic on Ωand a subsequence,
{fnk} such that for any compact subset, K of Ω,
lim
k→∞||fnk −f||K,∞= 0.
(27.29)
or there exists a subsequence {fnk} such that for all compact subsets K,
lim
k→∞ρK (fnk, ∞) = 0.
(27.30)

762
COMPLEX MAPPINGS
Proof: Let B (z0, 2R) ⊆Ω. There are two cases to consider. The ﬁrst case is
that there exists a subsequence, nk such that {fnk (z0)} is bounded. The second
case is that limn→∞|fnk (z0)| = ∞.
Consider the ﬁrst case. By Theorem 27.28 {fnk (z)} is uniformly bounded on
B (z0, R) because by this theorem, and letting θ = 1/2 applied to B (z0, 2R) , it fol-
lows |fnk (z)| ≤M
¡
a, b, 1
2, β
¢
where β is an upper bound to the numbers, |fnk (z0)|.
The Cauchy integral formula implies the existence of a uniform bound on the
©
f ′
nk
ª
which implies the functions are equicontinuous and uniformly bounded. Therefore,
by the Ascoli Arzela theorem there exists a further subsequence which converges
uniformly on B (z0, R) to a function, f analytic on B (z0, R). Thus denoting this
subsequence by {fnk} to save on notation,
lim
k→∞||fnk −f||B(z0,R),∞= 0.
(27.31)
Consider the second case.
In this case, it follows {1/fn (z0)} is bounded on
B (z0, R) and so by the same argument just given {1/fn (z)} is uniformly bounded
on B (z0, R).
Therefore, a subsequence converges uniformly on B (z0, R). But
{1/fn (z)} converges to 0 and so this requires that {1/fn (z)} must converge uni-
formly to 0. Therefore,
lim
k→∞ρB(z0,R) (fnk, ∞) = 0.
(27.32)
Now let {Dk} denote a countable set of closed balls, Dk = B (zk, Rk) such that
B (zk, 2Rk) ⊆Ωand ∪∞
k=1 int (Dk) = Ω. Using a Cantor diagonal process, there
exists a subsequence, {fnk} of {fn} such that for each Dj, one of the above two
alternatives holds. That is, either
lim
k→∞||fnk −gj||Dj,∞= 0
(27.33)
or,
lim
k→∞ρDj (fnk, ∞) .
(27.34)
Let A = {∪int (Dj) : 27.33 holds} , B = {∪int (Dj) : 27.34 holds} . Note that the
balls whose union is A cannot intersect any of the balls whose union is B. Therefore,
one of A or B must be empty since otherwise, Ωwould not be connected.
If K is any compact subset of Ω, it follows K must be a subset of some ﬁnite
collection of the Dj. Therefore, one of the alternatives in the lemma must hold.
That the limit function, f must be analytic follows easily in the same way as the
proof in Theorem 27.7 on Page 740. You could also use Morera’s theorem. This
proves the lemma.
27.5.6
The Great Big Picard Theorem
The next theorem is the main result which the above lemmas lead to. It is the Big
Picard theorem, also called the Great Picard theorem.Recall B′ (a, r) is the deleted
ball consisting of all the points of the ball except the center.

27.5.
THE PICARD THEOREMS
763
Theorem 27.37 Suppose f has an isolated essential singularity at 0. Then for
every R > 0, and β ∈C, f −1 (β)∩B′ (0, R) is an inﬁnite set except for one possible
exceptional β.
Proof: Suppose this is not true. Then there exists R1 > 0 and two points, α
and β such that f −1 (β) ∩B′ (0, R1) and f −1 (α) ∩B′ (0, R1) are both ﬁnite sets.
Then shrinking R1 and calling the result R, there exists B (0, R) such that
f −1 (β) ∩B′ (0, R) = ∅, f −1 (α) ∩B′ (0, R) = ∅.
Now let A0 denote the annulus
©
z ∈C : R
22 < |z| < 3R
22
ª
and let An denote the
annulus
©
z ∈C :
R
22+n < |z| <
3R
22+n
ª
. The reason for the 3 is to insure that An ∩
An+1 ̸= ∅. This follows from the observation that 3R/22+1+n > R/22+n. Now
deﬁne a set of functions on A0 as follows:
fn (z) ≡f
³ z
2n
´
.
By the choice of R, this set of functions missed the two points α and β. Therefore, by
Lemma 27.36 there exists a subsequence such that one of the two options presented
there holds.
First suppose limk→∞||fnk −f||K,∞= 0 for all K a compact subset of A0 and
f is analytic on A0. In particular, this happens for γ0 the circular contour having
radius R/2. Thus fnk must be bounded on this contour. But this says the same
thing as f (z/2nk) is bounded for |z| = R/2, this holding for each k = 1, 2, ···. Thus
there exists a constant, M such that on each of a shrinking sequence of concentric
circles whose radii converge to 0, |f (z)| ≤M. By the maximum modulus theorem,
|f (z)| ≤M at every point between successive circles in this sequence. Therefore,
|f (z)| ≤M in B′ (0, R) contradicting the Weierstrass Casorati theorem.
The other option which might hold from Lemma 27.36 is that limk→∞ρK (fnk, ∞) =
0 for all K compact subset of A0. Since f has an essential singularity at 0 the zeros
of f in B (0, R) are isolated. Therefore, for all k large enough, fnk has no zeros for
|z| < 3R/22. This is because the values of fnk are the values of f on Ank, a small
anulus which avoids all the zeros of f whenever k is large enough. Only consider k
this large. Then use the above argument on the analytic functions 1/fnk. By the as-
sumption that limk→∞ρK (fnk, ∞) = 0, it follows limk→∞||1/fnk −0||K,∞= 0 and
so as above, there exists a shrinking sequence of concentric circles whose radii con-
verge to 0 and a constant, M such that for z on any of these circles, |1/f (z)| ≤M.
This implies that on some deleted ball, B′ (0, r) where r ≤R, |f (z)| ≥1/M which
again violates the Weierstrass Casorati theorem. This proves the theorem.
As a simple corollary, here is what this remarkable theorem says about entire
functions.
Corollary 27.38 Suppose f is entire and nonconstant and not a polynomial. Then
f assumes every complex value inﬁnitely many times with the possible exception of
one.

764
COMPLEX MAPPINGS
Proof: Since f is entire, f (z) = P∞
n=0 anzn. Deﬁne for z ̸= 0,
g (z) ≡f
µ1
z
¶
=
∞
X
n=0
an
µ1
z
¶n
.
Thus 0 is an isolated essential singular point of g. By the big Picard theorem,
Theorem 27.37 it follows g takes every complex number but possibly one an inﬁnite
number of times. This proves the corollary.
Note the diﬀerence between this and the little Picard theorem which says that
an entire function which is not constant must achieve every value but two.
27.6
Exercises
1. Prove that in Theorem 27.7 it suﬃces to assume F is uniformly bounded on
each compact subset of Ω.
2. Find conditions on a, b, c, d such that the fractional linear transformation,
az+b
cz+d maps the upper half plane onto the upper half plane.
3. Let D be a simply connected region which is a proper subset of C. Does there
exist an entire function, f which maps C onto D? Why or why not?
4. Verify the conclusion of Theorem 27.7 involving the higher order derivatives.
5. What if Ω= C? Does there exist an analytic function, f mapping Ωone to
one and onto B (0, 1)? Explain why or why not. Was Ω̸= C used in the proof
of the Riemann mapping theorem?
6. Verify that |φα (z)| = 1 if |z| = 1. Apply the maximum modulus theorem to
conclude that |φα (z)| ≤1 for all |z| < 1.
7. Suppose that |f (z)| ≤1 for |z| = 1 and f (α) = 0 for |α| < 1. Show that
|f (z)| ≤|φα (z)| for all z ∈B (0, 1) . Hint: Consider f(z)(1−αz)
z−α
which has a
removable singularity at α. Show the modulus of this function is bounded by
1 on |z| = 1. Then apply the maximum modulus theorem.
8. Let U and V be open subsets of C and suppose u : U →R is harmonic while
h is an analytic map which takes V one to one onto U. Show that u ◦h is
harmonic on V .
9. Show that for a harmonic function, u deﬁned on B (0, R) , there exists an
analytic function, h = u + iv where
v (x, y) ≡
Z y
0
ux (x, t) dt −
Z x
0
uy (t, 0) dt.

27.6.
EXERCISES
765
10. Suppose Ωis a simply connected region and u is a real valued function deﬁned
on Ωsuch that u is harmonic. Show there exists an analytic function, f such
that u = Re f. Show this is not true if Ωis not a simply connected region.
Hint: You might use the Riemann mapping theorem and Problems 8 and
9.
For the second part it might be good to try something like u (x, y) =
ln
¡
x2 + y2¢
on the annulus 1 < |z| < 2.
11. Show that w = 1+z
1−z maps {z ∈C : Im z > 0 and |z| < 1} to the ﬁrst quadrant,
{z = x + iy : x, y > 0} .
12. Let f (z) = az+b
cz+d and let g (z) = a1z+b1
c1z+d1 . Show that f ◦g (z) equals the quotient
of two expressions, the numerator being the top entry in the vector
µ
a
b
c
d
¶ µ
a1
b1
c1
d1
¶ µ
z
1
¶
and the denominator being the bottom entry. Show that if you deﬁne
φ
µµ
a
b
c
d
¶¶
≡az + b
cz + d,
then φ (AB) = φ (A) ◦φ (B) . Find an easy way to ﬁnd the inverse of f (z) =
az+b
cz+d and give a condition on the a, b, c, d which insures this function has an
inverse.
13. The modular group2 is the set of fractional linear transformations, az+b
cz+d such
that a, b, c, d are integers and ad −bc = 1. Using Problem 12 or brute force
show this modular group is really a group with the group operation being
composition. Also show the inverse of az+b
cz+d is
dz−b
−cz+a.
14. Let Ωbe a region and suppose f is analytic on Ωand that the functions fn
are also analytic on Ωand converge to f uniformly on compact subsets of Ω.
Suppose f is one to one. Can it be concluded that for an arbitrary compact
set, K ⊆Ωthat fn is one to one for all n large enough?
15. The Vitali theorem says that if Ωis a region and {fn} is a uniformly bounded
sequence of functions which converges pointwise on a set, S ⊆Ωwhich has a
limit point in Ω, then in fact, {fn} must converge uniformly on compact sub-
sets of Ωto an analytic function. Prove this theorem. Hint: If the sequence
fails to converge, show you can get two diﬀerent subsequences converging uni-
formly on compact sets to diﬀerent functions. Then argue these two functions
coincide on S.
16. Does there exist a function analytic on B (0, 1) which maps B (0, 1)
onto
B′ (0, 1) , the open unit ball in which 0 has been deleted?
2This is the terminology used in Rudin’s book Real and Complex Analysis.

766
COMPLEX MAPPINGS

Approximation By Rational
Functions
28.1
Runge’s Theorem
Consider the function, 1
z = f (z) for z deﬁned on Ω≡B (0, 1) \ {0} = B′ (0, 1) .
Clearly f is analytic on Ω. Suppose you could approximate f uniformly by poly-
nomials on ann
¡
0, 1
2, 3
4
¢
, a compact subset of Ω. Then, there would exist a suit-
able polynomial p (z) , such that
¯¯¯ 1
2πi
R
γ f (z) −p (z) dz
¯¯¯ <
1
10 where here γ is a
circle of radius
2
3. However, this is impossible because
1
2πi
R
γ f (z) dz = 1 while
1
2πi
R
γ p (z) dz = 0. This shows you can’t expect to be able to uniformly approxi-
mate analytic functions on compact sets using polynomials. This is just horrible!
In real variables, you can approximate any continuous function on a compact
set with a polynomial. However, that is just the way it is. It turns out that the
ability to approximate an analytic function on Ωwith polynomials is dependent on
Ωbeing simply connected.
All these theorems work for f having values in a complex Banach space. How-
ever, I will present them in the context of functions which have values in C. The
changes necessary to obtain the extra generality are very minor.
Deﬁnition 28.1 Approximation will be taken with respect to the following norm.
||f −g||K,∞≡sup {||f (z) −g (z)|| : z ∈K}
28.1.1
Approximation With Rational Functions
It turns out you can approximate analytic functions by rational functions, quotients
of polynomials. The resulting theorem is one of the most profound theorems in
complex analysis. The basic idea is simple. The Riemann sums for the Cauchy
integral formula are rational functions. The idea used to implement this observation
is that if you have a compact subset, K of an open set, Ωthere exists a cycle
composed of closed oriented curves
©
γj
ªn
j=1 which are contained in Ω\K such that
767

768
APPROXIMATION BY RATIONAL FUNCTIONS
for every z ∈K, Pn
k=1 n (γk, z) = 1. One more ingredient is needed and this is a
theorem which lets you keep the approximation but move the poles.
To begin with, consider the part about the cycle of closed oriented curves. Recall
Theorem 24.52 which is stated for convenience.
Theorem 28.2 Let K be a compact subset of an open set, Ω. Then there exist
continuous, closed, bounded variation oriented curves
©
γj
ªm
j=1 for which γ∗
j ∩K = ∅
for each j, γ∗
j ⊆Ω, and for all p ∈K,
m
X
k=1
n (p, γk) = 1.
and
m
X
k=1
n (z, γk) = 0
for all z /∈Ω.
This theorem implies the following.
Theorem 28.3 Let K ⊆Ωwhere K is compact and Ωis open. Then there exist
oriented closed curves, γk such that γ∗
k ∩K = ∅but γ∗
k ⊆Ω, such that for all z ∈K,
f (z) =
1
2πi
p
X
k=1
Z
γk
f (w)
w −z dw.
(28.1)
Proof: This follows from Theorem 24.52 and the Cauchy integral formula. As
shown in the proof, you can assume the γk are linear mappings but this is not
important.
Next I will show how the Cauchy integral formula leads to approximation by
rational functions, quotients of polynomials.
Lemma 28.4 Let K be a compact subset of an open set, Ωand let f be analytic
on Ω. Then there exists a rational function, Q whose poles are not in K such that
||Q −f||K,∞< ε.
Proof: By Theorem 28.3 there are oriented curves, γk described there such that
for all z ∈K,
f (z) =
1
2πi
p
X
k=1
Z
γk
f (w)
w −z dw.
(28.2)
Deﬁning g (w, z) ≡
f(w)
w−z for (w, z) ∈∪p
k=1γ∗
k × K, it follows since the distance
between K and ∪kγ∗
k is positive that g is uniformly continuous and so there exists
a δ > 0 such that if ||P|| < δ, then for all z ∈K,
¯¯¯¯¯¯
f (z) −
1
2πi
p
X
k=1
n
X
j=1
f (γk (τ j)) (γk (ti) −γk (ti−1))
γk (τ j) −z
¯¯¯¯¯¯
< ε
2.

28.1.
RUNGE’S THEOREM
769
The complicated expression is obtained by replacing each integral in 28.2 with a
Riemann sum. Simplifying the appearance of this, it follows there exists a rational
function of the form
R (z) =
M
X
k=1
Ak
wk −z
where the wk are elements of components of C \ K and Ak are complex numbers or
in the case where f has values in X, these would be elements of X such that
||R −f||K,∞< ε
2.
This proves the lemma.
28.1.2
Moving The Poles And Keeping The Approximation
Lemma 28.4 is a nice lemma but needs reﬁning. In this lemma, the Riemann sum
handed you the poles. It is much better if you can pick the poles. The following
theorem from advanced calculus, called Merten’s theorem, will be used
28.1.3
Merten’s Theorem.
Theorem 28.5 Suppose P∞
i=r ai and P∞
j=r bj both converge absolutely1. Then
Ã ∞
X
i=r
ai
! 

∞
X
j=r
bj

=
∞
X
n=r
cn
where
cn =
n
X
k=r
akbn−k+r.
Proof: Let pnk = 1 if r ≤k ≤n and pnk = 0 if k > n. Then
cn =
∞
X
k=r
pnkakbn−k+r.
1Actually, it is only necessary to assume one of the series converges and the other converges
absolutely. This is known as Merten’s theorem and may be read in the 1974 book by Apostol
listed in the bibliography.

770
APPROXIMATION BY RATIONAL FUNCTIONS
Also,
∞
X
k=r
∞
X
n=r
pnk |ak| |bn−k+r|
=
∞
X
k=r
|ak|
∞
X
n=r
pnk |bn−k+r|
=
∞
X
k=r
|ak|
∞
X
n=k
|bn−k+r|
=
∞
X
k=r
|ak|
∞
X
n=k
¯¯bn−(k−r)
¯¯
=
∞
X
k=r
|ak|
∞
X
m=r
|bm| < ∞.
Therefore,
∞
X
n=r
cn
=
∞
X
n=r
n
X
k=r
akbn−k+r =
∞
X
n=r
∞
X
k=r
pnkakbn−k+r
=
∞
X
k=r
ak
∞
X
n=r
pnkbn−k+r =
∞
X
k=r
ak
∞
X
n=k
bn−k+r
=
∞
X
k=r
ak
∞
X
m=r
bm
and this proves the theorem.
It follows that P∞
n=r cn converges absolutely. Also, you can see by induction that
you can multiply any number of absolutely convergent series together and obtain a
series which is absolutely convergent. Next, here are some similar results related to
Merten’s theorem.
Lemma 28.6 Let P∞
n=0 an (z) and P∞
n=0 bn (z) be two convergent series for z ∈K
which satisfy the conditions of the Weierstrass M test. Thus there exist positive
constants, An and Bn such that |an (z)| ≤An, |bn (z)| ≤Bn for all z ∈K and
P∞
n=0 An < ∞, P∞
n=0 Bn < ∞. Then deﬁning the Cauchy product,
cn (z) ≡
n
X
k−0
an−k (z) bk (z) ,
it follows P∞
n=0 cn (z) also converges absolutely and uniformly on K because cn (z)
satisﬁes the conditions of the Weierstrass M test. Therefore,
∞
X
n=0
cn (z) =
Ã ∞
X
k=0
ak (z)
! Ã ∞
X
n=0
bn (z)
!
.
(28.3)
Proof:
|cn (z)| ≤
n
X
k=0
|an−k (z)| |bk (z)| ≤
n
X
k=0
An−kBk.

28.1.
RUNGE’S THEOREM
771
Also,
∞
X
n=0
n
X
k=0
An−kBk
=
∞
X
k=0
∞
X
n=k
An−kBk
=
∞
X
k=0
Bk
∞
X
n=0
An < ∞.
The claim of 28.3 follows from Merten’s theorem. This proves the lemma.
Corollary 28.7 Let P be a polynomial and let P∞
n=0 an (z) converge uniformly and
absolutely on K such that the an satisfy the conditions of the Weierstrass M test.
Then there exists a series for P (P∞
n=0 an (z)) , P∞
n=0 cn (z) , which also converges
absolutely and uniformly for z ∈K because cn (z) also satisﬁes the conditions of the
Weierstrass M test.
The following picture is descriptive of the following lemma. This lemma says
that if you have a rational function with one pole oﬀa compact set, then you can
approximate on the compact set with another rational function which has a diﬀerent
pole.
V
u
u
a
b
K
Lemma 28.8 Let R be a rational function which has a pole only at a ∈V, a
component of C \ K where K is a compact set. Suppose b ∈V. Then for ε > 0
given, there exists a rational function, Q, having a pole only at b such that
||R −Q||K,∞< ε.
(28.4)
If it happens that V is unbounded, then there exists a polynomial, P such that
||R −P||K,∞< ε.
(28.5)
Proof: Say that b ∈V satisﬁes P if for all ε > 0 there exists a rational function,
Qb, having a pole only at b such that
||R −Qb||K,∞< ε
Now deﬁne a set,
S ≡{b ∈V : b satisﬁes P } .

772
APPROXIMATION BY RATIONAL FUNCTIONS
Observe that S ̸= ∅because a ∈S.
I claim S is open. Suppose b1 ∈S. Then there exists a δ > 0 such that
¯¯¯¯
b1 −b
z −b
¯¯¯¯ < 1
2
(28.6)
for all z ∈K whenever b ∈B (b1, δ) . In fact, it suﬃces to take |b −b1| < dist (b1, K) /4
because then
¯¯¯¯
b1 −b
z −b
¯¯¯¯
<
¯¯¯¯
dist (b1, K) /4
z −b
¯¯¯¯ ≤
dist (b1, K) /4
|z −b1| −|b1 −b|
≤
dist (b1, K) /4
dist (b1, K) −dist (b1, K) /4 ≤1
3 < 1
2.
Since b1 satisﬁes P, there exists a rational function Qb1 with the desired prop-
erties. It is shown next that you can approximate Qb1 with Qb thus yielding an
approximation to R by the use of the triangle inequality,
||R −Qb1||K,∞+ ||Qb1 −Qb||K,∞≥||R −Qb||K,∞.
Since Qb1 has poles only at b1, it follows it is a sum of functions of the form
αn
(z−b1)n . Therefore, it suﬃces to consider the terms of Qb1 or that Qb1 is of the
special form
Qb1 (z) =
1
(z −b1)n .
However,
1
(z −b1)n =
1
(z −b)n ³
1 −b1−b
z−b
´n
Now from the choice of b1, the series
∞
X
k=0
µb1 −b
z −b
¶k
=
1
³
1 −b1−b
z−b
´
converges absolutely independent of the choice of z ∈K because
¯¯¯¯¯
µb1 −b
z −b
¶k¯¯¯¯¯ < 1
2k .
By Corollary 28.7 the same is true of the series for
1
(1−b1−b
z−b )
n . Thus a suitable partial
sum can be made uniformly on K as close as desired to
1
(z−b1)n . This shows that b
satisﬁes P whenever b is close enough to b1 verifying that S is open.
Next it is shown S is closed in V. Let bn ∈S and suppose bn →b ∈V. Then
since bn ∈S, there exists a rational function, Qbn such that
||Qbn −R||K,∞< ε
2.

28.1.
RUNGE’S THEOREM
773
Then for all n large enough,
1
2 dist (b, K) ≥|bn −b|
and so for all n large enough,
¯¯¯¯
b −bn
z −bn
¯¯¯¯ < 1
2,
for all z ∈K. Pick such a bn. As before, it suﬃces to assume Qbn, is of the form
1
(z−bn)n . Then
Qbn (z) =
1
(z −bn)n =
1
(z −b)n ³
1 −bn−b
z−b
´n
and because of the estimate, there exists M such that for all z ∈K
¯¯¯¯¯¯
1
³
1 −bn−b
z−b
´n −
M
X
k=0
ak
µbn −b
z −b
¶k
¯¯¯¯¯¯
< ε (dist (b, K))n
2
.
(28.7)
Therefore, for all z ∈K
¯¯¯¯¯Qbn (z) −
1
(z −b)n
M
X
k=0
ak
µbn −b
z −b
¶k¯¯¯¯¯
=
¯¯¯¯¯¯
1
(z −b)n ³
1 −bn−b
z−b
´n −
1
(z −b)n
M
X
k=0
ak
µbn −b
z −b
¶k
¯¯¯¯¯¯
≤
ε (dist (b, K))n
2
1
dist (b, K)n
=
ε
2
and so, letting Qb (z) =
1
(z−b)n
PM
k=0 ak
³
bn−b
z−b
´k
,
||R −Qb||K,∞
≤
||R −Qbn||K,∞+ ||Qbn −Qb||K,∞
<
ε
2 + ε
2 = ε
showing that b ∈S. Since S is both open and closed in V it follows that, since
S ̸= ∅, S = V . Otherwise V would fail to be connected.
It remains to consider the case where V is unbounded. Pick b ∈V large enough
that
¯¯¯z
b
¯¯¯ < 1
2
(28.8)
for all z ∈K. From what was just shown, there exists a rational function, Qb having
a pole only at b such that ||Qb −R||K,∞< ε
2. It suﬃces to assume that Qb is of the

774
APPROXIMATION BY RATIONAL FUNCTIONS
form
Qb (z)
=
p (z)
(z −b)n = p (z) (−1)n 1
bn
1
¡
1 −z
b
¢n
=
p (z) (−1)n 1
bn
Ã ∞
X
k=0
³z
b
´k
!n
Then by an application of Corollary 28.7 there exists a partial sum of the power
series for Qb which is uniformly close to Qb on K. Therefore, you can approximate
Qb and therefore also R uniformly on K by a polynomial consisting of a partial sum
of the above inﬁnite sum. This proves the theorem.
If f is a polynomial, then f has a pole at ∞. This will be discussed more later.
28.1.4
Runge’s Theorem
Now what follows is the ﬁrst form of Runge’s theorem.
Theorem 28.9 Let K be a compact subset of an open set, Ωand let {bj} be a
set which consists of one point from each component of bC \ K. Let f be analytic
on Ω. Then for each ε > 0, there exists a rational function, Q whose poles are all
contained in the set, {bj} such that
||Q −f||K,∞< ε.
(28.9)
If bC \ K has only one component, then Q may be taken to be a polynomial.
Proof: By Lemma 28.4 there exists a rational function of the form
R (z) =
M
X
k=1
Ak
wk −z
where the wk are elements of components of C \ K and Ak are complex numbers
such that
||R −f||K,∞< ε
2.
Consider the rational function, Rk (z) ≡
Ak
wk−z where wk ∈Vj, one of the com-
ponents of C \ K, the given point of Vj being bj. By Lemma 28.8, there exists
a function, Qk which is either a rational function having its only pole at bj or a
polynomial, depending on whether Vj is bounded such that
||Rk −Qk||K,∞<
ε
2M .
Letting Q (z) ≡PM
k=1 Qk (z) ,
||R −Q||K,∞< ε
2.

28.1.
RUNGE’S THEOREM
775
It follows
||f −Q||K,∞≤||f −R||K,∞+ ||R −Q||K,∞< ε.
In the case of only one component of C \ K, this component is the unbounded
component and so you can take Q to be a polynomial. This proves the theorem.
The next version of Runge’s theorem concerns the case where the given points
are contained in bC \ Ωfor Ωan open set rather than a compact set. Note that here
there could be uncountably many components of bC \ Ωbecause the components are
no longer open sets. An easy example of this phenomenon in one dimension is where
Ω= [0, 1] \ P for P the Cantor set. Then you can show that R \ Ωhas uncountably
many components. Nevertheless, Runge’s theorem will follow from Theorem 28.9
with the aid of the following interesting lemma.
Lemma 28.10 Let Ωbe an open set in C. Then there exists a sequence of compact
sets, {Kn} such that
Ω= ∪∞
k=1Kn, · · ·, Kn ⊆int Kn+1 · ··,
(28.10)
and for any K ⊆Ω,
K ⊆Kn,
(28.11)
for all n suﬃciently large, and every component of bC \ Kn contains a component of
bC \ Ω.
Proof: Let
Vn ≡{z : |z| > n} ∪
[
z /∈Ω
B
µ
z, 1
n
¶
.
Thus {z : |z| > n} contains the point, ∞. Now let
Kn ≡bC \ Vn = C \ Vn ⊆Ω.
You should verify that 28.10 and 28.11 hold. It remains to show that every compo-
nent of bC\Kn contains a component of bC\Ω. Let D be a component of bC\Kn ≡Vn.
If ∞/∈D, then D contains no point of {z : |z| > n} because this set is connected
and D is a component.
(If it did contain a point of this set, it would have to
contain the whole set.) Therefore, D ⊆S
z /∈Ω
B
¡
z, 1
n
¢
and so D contains some point
of B
¡
z, 1
n
¢
for some z /∈Ω. Therefore, since this ball is connected, it follows D must
contain the whole ball and consequently D contains some point of ΩC. (The point
z at the center of the ball will do.) Since D contains z /∈Ω, it must contain the
component, Hz, determined by this point. The reason for this is that
Hz ⊆bC \ Ω⊆bC \ Kn
and Hz is connected.
Therefore, Hz can only have points in one component of
bC \ Kn. Since it has a point in D, it must therefore, be totally contained in D. This
veriﬁes the desired condition in the case where ∞/∈D.

776
APPROXIMATION BY RATIONAL FUNCTIONS
Now suppose that ∞∈D. ∞/∈Ωbecause Ωis given to be a set in C. Letting
H∞denote the component of bC \ Ωdetermined by ∞, it follows both D and H∞
contain ∞. Therefore, the connected set, H∞cannot have any points in another
component of bC \ Kn and it is a set which is contained in bC \ Kn so it must be
contained in D. This proves the lemma.
The following picture is a very simple example of the sort of thing considered
by Runge’s theorem. The picture is of a region which has a couple of holes.
sa1
sa2
Ω
However, there could be many more holes than two. In fact, there could be
inﬁnitely many. Nor does it follow that the components of the complement of Ωneed
to have any interior points. Therefore, the picture is certainly not representative.
Theorem 28.11 (Runge) Let Ωbe an open set, and let A be a set which has one
point in each component of bC \ Ωand let f be analytic on Ω. Then there exists a
sequence of rational functions, {Rn} having poles only in A such that Rn converges
uniformly to f on compact subsets of Ω.
Proof: Let Kn be the compact sets of Lemma 28.10 where each component of
bC\Kn contains a component of bC\Ω. It follows each component of bC\Kn contains
a point of A. Therefore, by Theorem 28.9 there exists Rn a rational function with
poles only in A such that
||Rn −f||Kn,∞< 1
n.
It follows, since a given compact set, K is a subset of Kn for all n large enough,
that Rn →f uniformly on K. This proves the theorem.
Corollary 28.12 Let Ωbe simply connected and f analytic on Ω. Then there exists
a sequence of polynomials, {pn} such that pn →f uniformly on compact sets of Ω.
Proof: By deﬁnition of what is meant by simply connected, bC \ Ωis connected
and so there are no bounded components of bC\Ω. Therefore, in the proof of Theorem
28.11 when you use Theorem 28.9, you can always have Rn be a polynomial by
Lemma 28.8.
28.2
The Mittag-Leﬄer Theorem
28.2.1
A Proof From Runge’s Theorem
This theorem is fairly easy to prove once you have Theorem 28.9.
Given a set of
complex numbers, does there exist a meromorphic function having its poles equal

28.2.
THE MITTAG-LEFFLER THEOREM
777
to this set of numbers? The Mittag-Leﬄer theorem provides a very satisfactory
answer to this question. Actually, it says somewhat more. You can specify, not just
the location of the pole but also the kind of singularity the meromorphic function
is to have at that pole.
Theorem 28.13 Let P ≡{zk}∞
k=1 be a set of points in an open subset of C, Ω.
Suppose also that P ⊆Ω⊆C. For each zk, denote by Sk (z) a function of the form
Sk (z) =
mk
X
j=1
ak
j
(z −zk)j .
Then there exists a meromorphic function, Q deﬁned on Ωsuch that the poles of
Q are the points, {zk}∞
k=1 and the singular part of the Laurent expansion of Q at
zk equals Sk (z) . In other words, for z near zk, Q (z) = gk (z) + Sk (z) for some
function, gk analytic near zk.
Proof: Let {Kn} denote the sequence of compact sets described in Lemma
28.10. Thus ∪∞
n=1Kn = Ω, Kn ⊆int (Kn+1) ⊆Kn+1 · ··, and the components of
bC\Kn contain the components of bC\Ω. Renumbering if necessary, you can assume
each Kn ̸= ∅. Also let K0 = ∅. Let Pm ≡P ∩(Km \ Km−1) and consider the
rational function, Rm deﬁned by
Rm (z) ≡
X
zk∈Km\Km−1
Sk (z) .
Since each Km is compact, it follows Pm is ﬁnite and so the above really is a
rational function. Now for m > 1,this rational function is analytic on some open
set containing Km−1. There exists a set of points, A one point in each component
of bC\Ω. Consider bC\Km−1. Each of its components contains a component of bC\Ω
and so for each of these components of bC \ Km−1, there exists a point of A which
is contained in it. Denote the resulting set of points by A′. By Theorem 28.9 there
exists a rational function, Qm whose poles are all contained in the set, A′ ⊆ΩC
such that
||Rm −Qm||Km−1,∞< 1
2m .
The meromorphic function is
Q (z) ≡R1 (z) +
∞
X
k=2
(Rk (z) −Qk (z)) .
It remains to verify this function works. First consider K1. Then on K1, the above
sum converges uniformly. Furthermore, the terms of the sum are analytic in some
open set containing K1. Therefore, the inﬁnite sum is analytic on this open set and
so for z ∈K1 The function, f is the sum of a rational function, R1, having poles at

778
APPROXIMATION BY RATIONAL FUNCTIONS
P1 with the speciﬁed singular terms and an analytic function. Therefore, Q works
on K1. Now consider Km for m > 1. Then
Q (z) = R1 (z) +
m+1
X
k=2
(Rk (z) −Qk (z)) +
∞
X
k=m+2
(Rk (z) −Qk (z)) .
As before, the inﬁnite sum converges uniformly on Km+1 and hence on some open
set, O containing Km.
Therefore, this inﬁnite sum equals a function which is
analytic on O. Also,
R1 (z) +
m+1
X
k=2
(Rk (z) −Qk (z))
is a rational function having poles at ∪m
k=1Pk with the speciﬁed singularities because
the poles of each Qk are not in Ω. It follows this function is meromorphic because
it is analytic except for the points in P. It also has the property of retaining the
speciﬁed singular behavior.
28.2.2
A Direct Proof Without Runge’s Theorem
There is a direct proof of this important theorem which is not dependent on Runge’s
theorem in the case where Ω= C. I think it is arguably easier to understand and
the Mittag-Leﬄer theorem is very important so I will give this proof here.
Theorem 28.14 Let P ≡{zk}∞
k=1 be a set of points in C which satisﬁes limn→∞|zn| =
∞. For each zk, denote by Sk (z) a polynomial in
1
z−zk which is of the form
Sk (z) =
mk
X
j=1
ak
j
(z −zk)j .
Then there exists a meromorphic function, Q deﬁned on C such that the poles of Q
are the points, {zk}∞
k=1 and the singular part of the Laurent expansion of Q at zk
equals Sk (z) . In other words, for z near zk,
Q (z) = gk (z) + Sk (z)
for some function, gk analytic in some open set containing zk.
Proof: First consider the case where none of the zk = 0. Letting
Kk ≡{z : |z| ≤|zk| /2} ,
there exists a power series for
1
z−zk which converges uniformly and absolutely on
this set. Here is why:
1
z −zk
=
Ã
−1
1 −z
zk
!
1
zk
= −1
zk
∞
X
l=0
µ z
zk
¶l

28.2.
THE MITTAG-LEFFLER THEOREM
779
and the Weierstrass M test can be applied because
¯¯¯¯
z
zk
¯¯¯¯ < 1
2
on this set. Therefore, by Corollary 28.7, Sk (z) , being a polynomial in
1
z−zk , has
a power series which converges uniformly to Sk (z) on Kk. Therefore, there exists a
polynomial, Pk (z) such that
||Pk −Sk||B(0,|zk|/2),∞< 1
2k .
Let
Q (z) ≡
∞
X
k=1
(Sk (z) −Pk (z)) .
(28.12)
Consider z ∈Km and let N be large enough that if k > N, then |zk| > 2 |z|
Q (z) =
N
X
k=1
(Sk (z) −Pk (z)) +
∞
X
k=N+1
(Sk (z) −Pk (z)) .
On Km, the second sum converges uniformly to a function analytic on int (Km)
(interior of Km) while the ﬁrst is a rational function having poles at z1, · · ·, zN.
Since any compact set is contained in Km for large enough m, this shows Q (z) is
meromorphic as claimed and has poles with the given singularities.
Now consider the case where the poles are at {zk}∞
k=0 with z0 = 0. Everything
is similar in this case. Let
Q (z) ≡S0 (z) +
∞
X
k=1
(Sk (z) −Pk (z)) .
The series converges uniformly on every compact set because of the assumption
that limn→∞|zn| = ∞which implies that any compact set is contained in Kk for
k large enough. Choose N such that z ∈int(KN) and zn /∈KN for all n ≥N + 1.
Then
Q (z) = S0 (z) +
N
X
k=1
(Sk (z) −Pk (z)) +
∞
X
k=N+1
(Sk (z) −Pk (z)) .
The last sum is analytic on int(KN) because each function in the sum is analytic due
to the fact that none of its poles are in KN. Also, S0 (z)+PN
k=1 (Sk (z) −Pk (z)) is
a ﬁnite sum of rational functions so it is a rational function and Pk is a polynomial
so zm is a pole of this function with the correct singularity whenever zm ∈int (KN).

780
APPROXIMATION BY RATIONAL FUNCTIONS
28.2.3
Functions Meromorphic On bC
Sometimes it is useful to think of isolated singular points at ∞.
Deﬁnition 28.15 Suppose f is analytic on {z ∈C : |z| > r} . Then f is said to
have a removable singularity at ∞if the function, g (z) ≡f
¡ 1
z
¢
has a removable
singularity at 0. f is said to have a pole at ∞if the function, g (z) = f
¡ 1
z
¢
has a
pole at 0. Then f is said to be meromorphic on bC if all its singularities are isolated
and either poles or removable.
So what is f like for these cases? First suppose f has a removable singularity
at ∞. Then zg (z) converges to 0 as z →0. It follows g (z) must be analytic near
0 and so can be given as a power series. Thus f (z) is of the form f (z) = g
¡ 1
z
¢
=
P∞
n=0 an
¡ 1
z
¢n . Next suppose f has a pole at ∞. This means g (z) has a pole at 0 so
g (z) is of the form g (z) = Pm
k=1
bk
zk +h (z) where h (z) is analytic near 0. Thus in the
case of a pole at ∞, f (z) is of the form f (z) = g
¡ 1
z
¢
= Pm
k=1 bkzk +P∞
n=0 an
¡ 1
z
¢n.
It turns out that the functions which are meromorphic on bC are all rational
functions. To see this suppose f is meromorphic on bC and note that there exists
r > 0 such that f (z) is analytic for |z| > r. This is required if ∞is to be isolated.
Therefore, there are only ﬁnitely many poles of f for |z| ≤r, {a1, · · ·, am} , because
by assumption, these poles are isolated and this is a compact set. Let the singular
part of f at ak be denoted by Sk (z) . Then f (z) −Pm
k=1 Sk (z) is analytic on all of
C. Therefore, it is bounded on |z| ≤r. In one case, f has a removable singularity at
∞. In this case, f is bounded as z →∞and P
k Sk also converges to 0 as z →∞.
Therefore, by Liouville’s theorem, f (z) −Pm
k=1 Sk (z) equals a constant and so
f −P
k Sk is a constant. Thus f is a rational function. In the other case that f has
a pole at ∞, f (z)−Pm
k=1 Sk (z)−Pm
k=1 bkzk = P∞
n=0 an
¡ 1
z
¢n −Pm
k=1 Sk (z) . Now
f (z) −Pm
k=1 Sk (z) −Pm
k=1 bkzk is analytic on C and so is bounded on |z| ≤r. But
now P∞
n=0 an
¡ 1
z
¢n −Pm
k=1 Sk (z) converges to 0 as z →∞and so by Liouville’s
theorem, f (z) −Pm
k=1 Sk (z) −Pm
k=1 bkzk must equal a constant and again, f (z)
equals a rational function.
28.2.4
A Great And Glorious Theorem About Simply Con-
nected Regions
Here is given a laundry list of properties which are equivalent to an open set being
simply connected. Recall Deﬁnition 24.48 on Page 673 which said that an open
set, Ωis simply connected means bC \ Ωis connected. Recall also that this is not
the same thing at all as saying C \ Ωis connected. Consider the outside of a disk
for example. I will continue to use this deﬁnition for simply connected because it
is the most convenient one for complex analysis. However, there are many other
equivalent conditions. First here is an interesting lemma which is interesting for
its own sake. Recall n (p, γ) means the winding number of γ about p. Now recall
Theorem 24.52 implies the following lemma in which BC is playing the role of Ωin
Theorem 24.52.

28.2.
THE MITTAG-LEFFLER THEOREM
781
Lemma 28.16 Let K be a compact subset of BC, the complement of a closed set.
Then there exist continuous, closed, bounded variation oriented curves {Γj}m
j=1 for
which Γ∗
j ∩K = ∅for each j, Γ∗
j ⊆Ω, and for all p ∈K,
m
X
k=1
n (Γk, p) = 1.
while for all z ∈B
m
X
k=1
n (Γk, z) = 0.
Deﬁnition 28.17 Let γ be a closed curve in an open set, Ω, γ : [a, b] →Ω. Then
γ is said to be homotopic to a point, p in Ωif there exists a continuous function,
H : [0, 1]×[a, b] →Ωsuch that H (0, t) = p, H (α, a) = H (α, b) , and H (1, t) = γ (t) .
This function, H is called a homotopy.
Lemma 28.18 Suppose γ is a closed continuous bounded variation curve in an
open set, Ωwhich is homotopic to a point. Then if a /∈Ω, it follows n (a, γ) = 0.
Proof: Let H be the homotopy described above. The problem with this is
that it is not known that H (α, ·) is of bounded variation. There is no reason it
should be. Therefore, it might not make sense to take the integral which deﬁnes
the winding number. There are various ways around this. Extend H as follows.
H (α, t) = H (α, a) for t < a, H (α, t) = H (α, b) for t > b. Let ε > 0.
Hε (α, t) ≡1
2ε
Z t+
2ε
(b−a) (t−a)
−2ε+t+
2ε
(b−a) (t−a)
H (α, s) ds, Hε (0, t) = p.
Thus Hε (α, ·) is a closed curve which has bounded variation and when α = 1, this
converges to γ uniformly on [a, b]. Therefore, for ε small enough, n (a, Hε (1, ·)) =
n (a, γ) because they are both integers and as ε →0, n (a, Hε (1, ·)) →n (a, γ) . Also,
Hε (α, t) →H (α, t) uniformly on [0, 1] × [a, b] because of uniform continuity of H.
Therefore, for small enough ε, you can also assume Hε (α, t) ∈Ωfor all α, t. Now
α →n (a, Hε (α, ·)) is continuous. Hence it must be constant because the winding
number is integer valued. But
lim
α→0
1
2πi
Z
Hε(α,·)
1
z −adz = 0
because the length of Hε (α, ·) converges to 0 and the integrand is bounded because
a /∈Ω. Therefore, the constant can only equal 0. This proves the lemma.
Now it is time for the great and glorious theorem on simply connected regions.
The following equivalence of properties is taken from Rudin [45]. There is a slightly
diﬀerent list in Conway [13] and a shorter list in Ash [6].
Theorem 28.19 The following are equivalent for an open set, Ω.

782
APPROXIMATION BY RATIONAL FUNCTIONS
1. Ωis homeomorphic to the unit disk, B (0, 1) .
2. Every closed curve contained in Ωis homotopic to a point in Ω.
3. If z /∈Ω, and if γ is a closed bounded variation continuous curve in Ω, then
n (γ, z) = 0.
4. Ωis simply connected, (bC \ Ωis connected and Ωis connected. )
5. Every function analytic on Ωcan be uniformly approximated by polynomials
on compact subsets.
6. For every f analytic on Ωand every closed continuous bounded variation
curve, γ,
Z
γ
f (z) dz = 0.
7. Every function analytic on Ωhas a primitive on Ω.
8. If f, 1/f are both analytic on Ω, then there exists an analytic, g on Ωsuch
that f = exp (g) .
9. If f, 1/f are both analytic on Ω, then there exists φ analytic on Ωsuch that
f = φ2.
Proof: 1⇒2. Assume 1 and let γ be a closed curve in Ω. Let h be the homeo-
morphism, h : B (0, 1) →Ω. Let H (α, t) = h
¡
α
¡
h−1γ (t)
¢¢
. This works.
2⇒3 This is Lemma 28.18.
3⇒4. Suppose 3 but 4 fails to hold. Then if bC \ Ωis not connected, there exist
disjoint nonempty sets, A and B such that A ∩B = A ∩B = ∅. It follows each
of these sets must be closed because neither can have a limit point in Ωnor in
the other. Also, one and only one of them contains ∞. Let this set be B. Thus
A is a closed set which must also be bounded.
Otherwise, there would exist a
sequence of points in A, {an} such that limn→∞an = ∞which would contradict
the requirement that no limit points of A can be in B. Therefore, A is a compact
set contained in the open set, BC ≡{z ∈C : z /∈B} . Pick p ∈A. By Lemma 28.16
there exist continuous bounded variation closed curves {Γk}m
k=1 which are contained
in BC, do not intersect A and such that
1 =
m
X
k=1
n (p, Γk)
However, if these curves do not intersect A and they also do not intersect B then
they must be all contained in Ω. Since p /∈Ω, it follows by 3 that for each k,
n (p, Γk) = 0, a contradiction.
4⇒5 This is Corollary 28.12 on Page 776.

28.2.
THE MITTAG-LEFFLER THEOREM
783
5⇒6 Every polynomial has a primitive and so the integral over any closed
bounded variation curve of a polynomial equals 0. Let f be analytic on Ω. Then let
{fn} be a sequence of polynomials converging uniformly to f on γ∗. Then
0 = lim
n→∞
Z
γ
fn (z) dz =
Z
γ
f (z) dz.
6⇒7 Pick z0 ∈Ω. Letting γ (z0, z) be a bounded variation continuous curve
joining z0 to z in Ω, you deﬁne a primitive for f as follows.
F (z) =
Z
γ(z0,z)
f (w) dw.
This is well deﬁned by 6 and is easily seen to be a primitive. You just write the
diﬀerence quotient and take a limit using 6.
lim
w→0
F (z + w) −F (z)
w
=
lim
w→0
1
w
ÃZ
γ(z0,z+w)
f (u) du −
Z
γ(z0,z)
f (u) du
!
=
lim
w→0
1
w
Z
γ(z,z+w)
f (u) du
=
lim
w→0
1
w
Z 1
0
f (z + tw) wdt = f (z) .
7⇒8 Suppose then that f, 1/f are both analytic. Then f ′/f is analytic and so
it has a primitive by 7. Let this primitive be g1. Then
¡
e−g1f
¢′
=
e−g1 (−g′
1) f + e−g1f ′
=
−e−g1
µf ′
f
¶
f + e−g1f ′ = 0.
Therefore, since Ωis connected, it follows e−g1f must equal a constant. (Why?)
Let the constant be ea+ibi. Then f (z) = eg1(z)ea+ib. Therefore, you let g (z) =
g1 (z) + a + ib.
8⇒9 Suppose then that f, 1/f are both analytic on Ω. Then by 8 f (z) = eg(z).
Let φ (z) ≡eg(z)/2.
9⇒1 There are two cases.
First suppose Ω= C.
This satisﬁes condition 9
because if f, 1/f are both analytic, then the same argument involved in 8⇒9 gives
the existence of a square root. A homeomorphism is h (z) ≡
z
√
1+|z|2 . It obviously
maps onto B (0, 1) and is continuous. To see it is 1 - 1 consider the case of z1
and z2 having diﬀerent arguments. Then h (z1) ̸= h (z2) . If z2 = tz1 for a positive
t ̸= 1, then it is also clear h (z1) ̸= h (z2) . To show h−1 is continuous, note that if
you have an open set in C and a point in this open set, you can get a small open
set containing this point by allowing the modulus and the argument to lie in some
open interval. Reasoning this way, you can verify h maps open sets to open sets. In
the case where Ω̸= C, there exists a one to one analytic map which maps Ωonto
B (0, 1) by the Riemann mapping theorem. This proves the theorem.

784
APPROXIMATION BY RATIONAL FUNCTIONS
28.3
Exercises
1. Let a ∈C.
Show there exists a sequence of polynomials, {pn} such that
pn (a) = 1 but pn (z) →0 for all z ̸= a.
2. Let l be a line in C. Show there exists a sequence of polynomials {pn} such
that pn (z) →1 on one side of this line and pn (z) →−1 on the other side of
the line. Hint: The complement of this line is simply connected.
3. Suppose Ωis a simply connected region, f is analytic on Ω, f ̸= 0 on Ω, and
n ∈N. Show that there exists an analytic function, g such that g (z)n = f (z)
for all z ∈Ω. That is, you can take the nth root of f (z) . If Ωis a region
which contains 0, is it possible to ﬁnd g (z) such that g is analytic on Ωand
g (z)2 = z?
4. Suppose Ωis a region (connected open set) and f is an analytic function
deﬁned on Ωsuch that f (z) ̸= 0 for any z ∈Ω. Suppose also that for every
positive integer, n there exists an analytic function, gn deﬁned on Ωsuch that
gn
n (z) = f (z) . Show that then it is possible to deﬁne an analytic function, L
on f (Ω) such that eL(f(z)) = f (z) for all z ∈Ω.
5. You know that φ (z) ≡z−i
z+i maps the upper half plane onto the unit ball. Its
inverse, ψ (z) = i 1+z
1−z maps the unit ball onto the upper half plane. Also for z
in the upper half plane, you can deﬁne a square root as follows. If z = |z| eiθ
where θ ∈(0, π) , let z1/2 ≡|z|1/2 eiθ/2 so the square root maps the upper half
plane to the ﬁrst quadrant. Now consider
z →exp
Ã
−i log
·
i
µ1 + z
1 −z
¶¸1/2!
.
(28.13)
Show this is an analytic function which maps the unit ball onto an annulus.
Is it possible to ﬁnd a one to one analytic map which does this?

Inﬁnite Products
The Mittag-Leﬄer theorem gives existence of a meromorphic function which has
speciﬁed singular part at various poles. It would be interesting to do something
similar to zeros of an analytic function. That is, given the order of the zero at
various points, does there exist an analytic function which has these points as zeros
with the speciﬁed orders? You know that if you have the zeros of the polynomial,
you can factor it.
Can you do something similar with analytic functions which
are just limits of polynomials? These questions involve the concept of an inﬁnite
product.
Deﬁnition 29.1 Q∞
n=1 (1 + un) ≡limn→∞
Qn
k=1 (1 + uk) whenever this limit ex-
ists. If un = un (z) for z ∈H, we say the inﬁnite product converges uniformly on
H if the partial products, Qn
k=1 (1 + uk (z)) converge uniformly on H.
The main theorem is the following.
Theorem 29.2 Let H ⊆C and suppose that P∞
n=1 |un (z)| converges uniformly on
H where un (z) bounded on H. Then
P (z) ≡
∞
Y
n=1
(1 + un (z))
converges uniformly on H. If (n1, n2, · · ·) is any permutation of (1, 2, · · ·) , then for
all z ∈H,
P (z) =
∞
Y
k=1
(1 + unk (z))
and P has a zero at z0 if and only if un (z0) = −1 for some n.
785

786
INFINITE PRODUCTS
Proof: First a simple estimate:
n
Y
k=m
(1 + |uk (z)|)
=
exp
Ã
ln
Ã
n
Y
k=m
(1 + |uk (z)|)
!!
= exp
Ã
n
X
k=m
ln (1 + |uk (z)|)
!
≤
exp
Ã ∞
X
k=m
|uk (z)|
!
< e
for all z ∈H provided m is large enough. Since P∞
k=1 |uk (z)| converges uniformly
on H, |uk (z)| < 1
2 for all z ∈H provided k is large enough. Thus you can take
log (1 + uk (z)) . Pick N0 such that for n > m ≥N0,
|um (z)| < 1
2,
n
Y
k=m
(1 + |uk (z)|) < e.
(29.1)
Now having picked N0, the assumption the un are bounded on H implies there
exists a constant, C, independent of z ∈H such that for all z ∈H,
N0
Y
k=1
(1 + |uk (z)|) < C.
(29.2)
Let N0 < M < N. Then
¯¯¯¯¯
N
Y
k=1
(1 + uk (z)) −
M
Y
k=1
(1 + uk (z))
¯¯¯¯¯
≤
N0
Y
k=1
(1 + |uk (z)|)
¯¯¯¯¯
N
Y
k=N0+1
(1 + uk (z)) −
M
Y
k=N0+1
(1 + uk (z))
¯¯¯¯¯
≤
C
¯¯¯¯¯
N
Y
k=N0+1
(1 + uk (z)) −
M
Y
k=N0+1
(1 + uk (z))
¯¯¯¯¯
≤
C
Ã
M
Y
k=N0+1
(1 + |uk (z)|)
! ¯¯¯¯¯
N
Y
k=M+1
(1 + uk (z)) −1
¯¯¯¯¯
≤
Ce
¯¯¯¯¯
N
Y
k=M+1
(1 + |uk (z)|) −1
¯¯¯¯¯ .

787
Since 1 ≤QN
k=M+1 (1 + |uk (z)|) ≤e, it follows the term on the far right is domi-
nated by
Ce2
¯¯¯¯¯ln
Ã
N
Y
k=M+1
(1 + |uk (z)|)
!
−ln 1
¯¯¯¯¯
≤
Ce2
N
X
k=M+1
ln (1 + |uk (z)|)
≤
Ce2
N
X
k=M+1
|uk (z)| < ε
uniformly in z ∈H provided M is large enough. This follows from the simple obser-
vation that if 1 < x < e, then x−1 ≤e (ln x −ln 1). Therefore, {Qm
k=1 (1 + uk (z))}∞
m=1
is uniformly Cauchy on H and therefore, converges uniformly on H. Let P (z) denote
the function it converges to.
What about the permutations? Let {n1, n2, · · ·} be a permutation of the indices.
Let ε > 0 be given and let N0 be such that if n > N0,
¯¯¯¯¯
n
Y
k=1
(1 + uk (z)) −P (z)
¯¯¯¯¯ < ε
for all z ∈H. Let {1, 2, · · ·, n} ⊆
©
n1, n2, · · ·, np(n)
ª
where p (n) is an increasing
sequence. Then from 29.1 and 29.2,
¯¯¯¯¯¯
P (z) −
p(n)
Y
k=1
(1 + unk (z))
¯¯¯¯¯¯
≤
¯¯¯¯¯P (z) −
n
Y
k=1
(1 + uk (z))
¯¯¯¯¯ +
¯¯¯¯¯¯
n
Y
k=1
(1 + uk (z)) −
p(n)
Y
k=1
(1 + unk (z))
¯¯¯¯¯¯
≤
ε +
¯¯¯¯¯¯
n
Y
k=1
(1 + uk (z)) −
p(n)
Y
k=1
(1 + unk (z))
¯¯¯¯¯¯
≤
ε +
¯¯¯¯¯
n
Y
k=1
(1 + |uk (z)|)
¯¯¯¯¯
¯¯¯¯¯1 −
Y
nk>n
(1 + unk (z))
¯¯¯¯¯
≤
ε +
¯¯¯¯¯
N0
Y
k=1
(1 + |uk (z)|)
¯¯¯¯¯
¯¯¯¯¯
n
Y
k=N0+1
(1 + |uk (z)|)
¯¯¯¯¯
¯¯¯¯¯1 −
Y
nk>n
(1 + unk (z))
¯¯¯¯¯
≤
ε + Ce
¯¯¯¯¯
Y
nk>n
(1 + |unk (z)|) −1
¯¯¯¯¯ ≤ε + Ce
¯¯¯¯¯¯
M(p(n))
Y
k=n+1
(1 + |unk (z)|) −1
¯¯¯¯¯¯

788
INFINITE PRODUCTS
where M (p (n)) is the largest index in the permuted list,
©
n1, n2, · · ·, np(n)
ª
. then
from 29.1, this last term is dominated by
ε + Ce2
¯¯¯¯¯¯
ln


M(p(n))
Y
k=n+1
(1 + |unk (z)|)

−ln 1
¯¯¯¯¯¯
≤
ε + Ce2
∞
X
k=n+1
ln (1 + |unk|) ≤ε + Ce2
∞
X
k=n+1
|unk| < 2ε
for all n large enough uniformly in z ∈H. Therefore,
¯¯¯P (z) −Qp(n)
k=1 (1 + unk (z))
¯¯¯ <
2ε whenever n is large enough. This proves the part about the permutation.
It remains to verify the assertion about the points, z0, where P (z0) = 0. Obvi-
ously, if un (z0) = −1, then P (z0) = 0. Suppose then that P (z0) = 0 and M > N0.
Then
¯¯¯¯¯
M
Y
k=1
(1 + uk (z0))
¯¯¯¯¯ =
¯¯¯¯¯
M
Y
k=1
(1 + uk (z0)) −
∞
Y
k=1
(1 + uk (z0))
¯¯¯¯¯
≤
¯¯¯¯¯
M
Y
k=1
(1 + uk (z0))
¯¯¯¯¯
¯¯¯¯¯1 −
∞
Y
k=M+1
(1 + uk (z0))
¯¯¯¯¯
≤
¯¯¯¯¯
M
Y
k=1
(1 + uk (z0))
¯¯¯¯¯
¯¯¯¯¯
∞
Y
k=M+1
(1 + |uk (z0)|) −1
¯¯¯¯¯
≤
e
¯¯¯¯¯
M
Y
k=1
(1 + uk (z0))
¯¯¯¯¯
¯¯¯¯¯ln
∞
Y
k=M+1
(1 + |uk (z0)|) −ln 1
¯¯¯¯¯
≤
e
Ã
∞
X
k=M+1
ln (1 + |uk (z)|)
! ¯¯¯¯¯
M
Y
k=1
(1 + uk (z0))
¯¯¯¯¯
≤
e
∞
X
k=M+1
|uk (z)|
¯¯¯¯¯
M
Y
k=1
(1 + uk (z0))
¯¯¯¯¯
≤
1
2
¯¯¯¯¯
M
Y
k=1
(1 + uk (z0))
¯¯¯¯¯
whenever M is large enough. Therefore, for such M,
M
Y
k=1
(1 + uk (z0)) = 0
and so uk (z0) = −1 for some k ≤M. This proves the theorem.

29.1.
ANALYTIC FUNCTION WITH PRESCRIBED ZEROS
789
29.1
Analytic Function With Prescribed Zeros
Suppose you are given complex numbers, {zn} and you want to ﬁnd an analytic
function, f such that these numbers are the zeros of f. How can you do it? The
problem is easy if there are only ﬁnitely many of these zeros, {z1, z2, · · ·, zm} . You
just write (z −z1) (z −z2) · · · (z −zm) . Now if none of the zk = 0 you could
also write it at Qm
k=1
³
1 −z
zk
´
and this might have a better chance of success in
the case of inﬁnitely many prescribed zeros. However, you would need to verify
something like P∞
n=1
¯¯¯ z
zn
¯¯¯ < ∞which might not be so. The way around this is to
adjust the product, making it Q∞
k=1
³
1 −z
zk
´
egk(z) where gk (z) is some analytic
function. Recall also that for |x| < 1, ln
³
(1 −x)−1´
= P∞
n=1
xn
n . If you had x/xn
small and real, then 1 = (1 −x/xn) exp
³
ln
³
(1 −x/xn)−1´´
and Q∞
k=1 1 of course
converges but loses all the information about zeros. However, this is why it is not
too unreasonable to consider factors of the form
µ
1 −z
zk
¶
e
Ppk
k=1
³
z
zk
´k 1
k
where pk is suitably chosen.
First here are some estimates.
Lemma 29.3 For z ∈C,
|ez −1| ≤|z| e|z|,
(29.3)
and if |z| ≤1/2,
¯¯¯¯¯
∞
X
k=m
zk
k
¯¯¯¯¯ ≤1
m
|z|m
1 −|z| ≤2
m |z|m ≤1
m
1
2m−1 .
(29.4)
Proof: Consider 29.3.
|ez −1| =
¯¯¯¯¯
∞
X
k=1
zk
k!
¯¯¯¯¯ ≤
∞
X
k=1
|z|k
k! = e|z| −1 ≤|z| e|z|
the last inequality holding by the mean value theorem. Now consider 29.4.
¯¯¯¯¯
∞
X
k=m
zk
k
¯¯¯¯¯
≤
∞
X
k=m
|z|k
k
≤1
m
∞
X
k=m
|z|k
=
1
m
|z|m
1 −|z| ≤2
m |z|m ≤1
m
1
2m−1 .
This proves the lemma.
The functions, Ep in the next deﬁnition are called the elementary factors.

790
INFINITE PRODUCTS
Deﬁnition 29.4 Let E0 (z) ≡1 −z and for p ≥1,
Ep (z) ≡(1 −z) exp
µ
z + z2
2 + · · · + zp
p
¶
In terms of this new symbol, here is another estimate. A sharper inequality is
available in Rudin [45] but it is more diﬃcult to obtain.
Corollary 29.5 For Ep deﬁned above and |z| ≤1/2,
|Ep (z) −1| ≤3 |z|p+1 .
Proof:
From elementary calculus, ln (1 −x) = −P∞
n=1
xn
n
for all |x| < 1.
Therefore, for |z| < 1,
log (1 −z) = −
∞
X
n=1
zn
n , log
³
(1 −z)−1´
=
∞
X
n=1
zn
n ,
because the function log (1 −z) and the analytic function, −P∞
n=1
zn
n both are
equal to ln (1 −x) on the real line segment (−1, 1) , a set which has a limit point.
Therefore, using Lemma 29.3,
|Ep (z) −1|
=
¯¯¯¯(1 −z) exp
µ
z + z2
2 + · · · + zp
p
¶
−1
¯¯¯¯
=
¯¯¯¯¯(1 −z) exp
Ã
log
³
(1 −z)−1´
−
∞
X
n=p+1
zn
n
!
−1
¯¯¯¯¯
=
¯¯¯¯¯exp
Ã
−
∞
X
n=p+1
zn
n
!
−1
¯¯¯¯¯
≤
¯¯¯¯¯−
∞
X
n=p+1
zn
n
¯¯¯¯¯ e|−P∞
n=p+1
zn
n |
≤
1
p + 1 · 2 · e1/(p+1) |z|p+1 . ≤3 |z|p+1
This proves the corollary.
With this estimate, it is easy to prove the Weierstrass product formula.
Theorem 29.6 Let {zn} be a sequence of nonzero complex numbers which have no
limit point in C and let {pn} be a sequence of nonnegative integers such that
∞
X
n=1
µ R
|zn|
¶pn+1
< ∞
(29.5)

29.1.
ANALYTIC FUNCTION WITH PRESCRIBED ZEROS
791
for all R ∈R. Then
P (z) ≡
∞
Y
n=1
Epn
µ z
zn
¶
is analytic on C and has a zero at each point, zn and at no others. If w occurs m
times in {zn} , then P has a zero of order m at w.
Proof: Since {zn} has no limit point, it follows limn→∞|zn| = ∞. Therefore,
if pn = n −1 the condition, 29.5 holds for this choice of pn. Now by Theorem 29.2,
the inﬁnite product in this theorem will converge uniformly on |z| ≤R if the same
is true of the sum,
∞
X
n=1
¯¯¯¯Epn
µ z
zn
¶
−1
¯¯¯¯ .
(29.6)
But by Corollary 29.5 the nth term of this sum satisﬁes
¯¯¯¯Epn
µ z
zn
¶
−1
¯¯¯¯ ≤3
¯¯¯¯
z
zn
¯¯¯¯
pn+1
.
Since |zn| →∞, there exists N such that for n > N, |zn| > 2R. Therefore, for
|z| < R and letting 0 < a = min {|zn| : n ≤N} ,
∞
X
n=1
¯¯¯¯Epn
µ z
zn
¶
−1
¯¯¯¯
≤
3
N
X
n=1
¯¯¯¯
R
a
¯¯¯¯
pn+1
+3
∞
X
n=N
µ R
2R
¶pn+1
<
∞.
By the Weierstrass M test, the series in 29.6 converges uniformly for |z| < R and so
the same is true of the inﬁnite product. It follows from Lemma 24.18 on Page 652
that P (z) is analytic on |z| < R because it is a uniform limit of analytic functions.
Also by Theorem 29.2 the zeros of the analytic P (z) are exactly the points,
{zn} , listed according to multiplicity. That is, if zn is a zero of order m, then if it
is listed m times in the formula for P (z) , then it is a zero of order m for P. This
proves the theorem.
The following corollary is an easy consequence and includes the case where there
is a zero at 0.
Corollary 29.7 Let {zn} be a sequence of nonzero complex numbers which have
no limit point and let {pn} be a sequence of nonnegative integers such that
∞
X
n=1
µ r
|zn|
¶1+pn
< ∞
(29.7)
for all r ∈R. Then
P (z) ≡zm
∞
Y
n=1
Epn
µ z
zn
¶

792
INFINITE PRODUCTS
is analytic Ωand has a zero at each point, zn and at no others along with a zero of
order m at 0. If w occurs m times in {zn} , then P has a zero of order m at w.
The above theory can be generalized to include the case of an arbitrary open
set. First, here is a lemma.
Lemma 29.8 Let Ωbe an open set. Also let {zn} be a sequence of points in Ω
which is bounded and which has no point repeated more than ﬁnitely many times
such that {zn} has no limit point in Ω. Then there exist {wn} ⊆∂Ωsuch that
limn→∞|zn −wn| = 0.
Proof: Since ∂Ωis closed, there exists wn ∈∂Ωsuch that dist (zn, ∂Ω) =
|zn −wn| . Now if there is a subsequence, {znk} such that |znk −wnk| ≥ε for all k,
then {znk} must possess a limit point because it is a bounded inﬁnite set of points.
However, this limit point can only be in Ωbecause {znk} is bounded away from ∂Ω.
This is a contradiction. Therefore, limn→∞|zn −wn| = 0. This proves the lemma.
Corollary 29.9 Let {zn} be a sequence of complex numbers contained in Ω, an
open subset of C which has no limit point in Ω. Suppose each zn is repeated no more
than ﬁnitely many times. Then there exists a function f which is analytic on Ω
whose zeros are exactly {zn} . If w ∈{zn} and w is listed m times, then w is a zero
of order m of f.
Proof:
There is nothing to prove if {zn} is ﬁnite.
You just let f (z) =
Qm
j=1 (z −zj) where {zn} = {z1, · · ·, zm}.
Pick w ∈Ω\ {zn}∞
n=1 and let h (z) ≡
1
z−w. Since w is not a limit point of {zn} ,
there exists r > 0 such that B (w, r) contains no points of {zn} . Let Ω1 ≡Ω\ {w}.
Now h is not constant and so h (Ω1) is an open set by the open mapping theorem.
In fact, h maps each component of Ωto a region. |zn −w| > r
for all zn and
so |h (zn)| < r−1. Thus the sequence, {h (zn)} is a bounded sequence in the open
set h (Ω1) . It has no limit point in h (Ω1) because this is true of {zn} and Ω1.
By Lemma 29.8 there exist wn ∈∂(h (Ω1)) such that limn→∞|wn −h (zn)| = 0.
Consider for z ∈Ω1
f (z) ≡
∞
Y
n=1
En
µh (zn) −wn
h (z) −wn
¶
.
(29.8)
Letting K be a compact subset of Ω1, h (K) is a compact subset of h (Ω1) and so if
z ∈K, then |h (z) −wn| is bounded below by a positive constant. Therefore, there
exists N large enough that for all z ∈K and n ≥N,
¯¯¯¯
h (zn) −wn
h (z) −wn
¯¯¯¯ < 1
2
and so by Corollary 29.5, for all z ∈K and n ≥N,
¯¯¯¯En
µh (zn) −wn
h (z) −wn
¶
−1
¯¯¯¯ ≤3
µ1
2
¶n
.
(29.9)

29.1.
ANALYTIC FUNCTION WITH PRESCRIBED ZEROS
793
Therefore,
∞
X
n=1
¯¯¯¯En
µh (zn) −wn
h (z) −wn
¶
−1
¯¯¯¯
converges uniformly for z ∈K. This implies Q∞
n=1 En
³
h(zn)−wn
h(z)−wn
´
also converges
uniformly for z ∈K by Theorem 29.2. Since K is arbitrary, this shows f deﬁned
in 29.8 is analytic on Ω1.
Also if zn is listed m times so it is a zero of multiplicity m and wn is the point
from ∂(h (Ω1)) closest to h (zn) , then there are m factors in 29.8 which are of the
form
En
µh (zn) −wn
h (z) −wn
¶
=
µ
1 −h (zn) −wn
h (z) −wn
¶
egn(z)
=
µh (z) −h (zn)
h (z) −wn
¶
egn(z)
=
zn −z
(z −w) (zn −w)
µ
1
h (z) −wn
¶
egn(z)
=
(z −zn) Gn (z)
(29.10)
where Gn is an analytic function which is not zero at and near zn. Therefore, f has
a zero of order m at zn. This proves the theorem except for the point, w which has
been left out of Ω1. It is necessary to show f is analytic at this point also and right
now, f is not even deﬁned at w.
The {wn} are bounded because {h (zn)} is bounded and limn→∞|wn −h (zn)| =
0 which implies |wn −h (zn)| ≤C for some constant, C. Therefore, there exists
δ > 0 such that if z ∈B′ (w, δ) , then for all n,
¯¯¯¯¯¯
h (zn) −w
³
1
z−w
´
−wn
¯¯¯¯¯¯
=
¯¯¯¯
h (zn) −wn
h (z) −wn
¯¯¯¯ < 1
2.
Thus 29.9 holds for all z ∈B′ (w, δ) and n so by Theorem 29.2, the inﬁnite product
in 29.8 converges uniformly on B′ (w, δ) . This implies f is bounded in B′ (w, δ) and
so w is a removable singularity and f can be extended to w such that the result is
analytic. It only remains to verify f (w) ̸= 0. After all, this would not do because
it would be another zero other than those in the given list. By 29.10, a partial
product is of the form
N
Y
n=1
µh (z) −h (zn)
h (z) −wn
¶
egn(z)
(29.11)
where
gn (z) ≡
Ã
h (zn) −wn
h (z) −wn
+ 1
2
µh (zn) −wn
h (z) −wn
¶2
+ · · · + 1
n
µh (zn) −wn
h (z) −wn
¶n!

794
INFINITE PRODUCTS
Each of the quotients in the deﬁnition of gn (z) converges to 0 as z →w
and so
the partial product of 29.11 converges to 1 as z →w because
³
h(z)−h(zn)
h(z)−wn
´
→1 as
z →w.
If f (w) = 0, then if z is close enough to w, it follows |f (z)| < 1
2. Also, by the
uniform convergence on B′ (w, δ) , it follows that for some N, the partial product
up to N must also be less than 1/2 in absolute value for all z close enough to w
and as noted above, this does not occur because such partial products converge to
1 as z →w. Hence f (w) ̸= 0. This proves the corollary.
Recall the deﬁnition of a meromorphic function on Page 666. It was a function
which is analytic everywhere except at a countable set of isolated points at which
the function has a pole. It is clear that the quotient of two analytic functions yields
a meromorphic function but is this the only way it can happen?
Theorem 29.10 Suppose Q is a meromorphic function on an open set, Ω. Then
there exist analytic functions on Ω, f (z) and g (z) such that Q (z) = f (z) /g (z) for
all z not in the set of poles of Q.
Proof: Let Q have a pole of order m (z) at z. Then by Corollary 29.9 there
exists an analytic function, g which has a zero of order m (z) at every z ∈Ω. It
follows gQ has a removable singularity at the poles of Q. Therefore, there is an
analytic function, f such that f (z) = g (z) Q (z) . This proves the theorem.
Corollary 29.11 Suppose Ωis a region and Q is a meromorphic function deﬁned
on Ωsuch that the set, {z ∈Ω: Q (z) = c} has a limit point in Ω. Then Q (z) = c
for all z ∈Ω.
Proof: From Theorem 29.10 there are analytic functions, f, g such that Q = f
g .
Therefore, the zero set of the function, f (z) −cg (z) has a limit point in Ωand so
f (z) −cg (z) = 0 for all z ∈Ω. This proves the corollary.
29.2
Factoring A Given Analytic Function
The next theorem is the Weierstrass factorization theorem which can be used to
factor a given analytic function f. If f has a zero of order m when z = 0, then you
could factor out a zm and from there consider the factorization of what remains
when you have factored out the zm. Therefore, the following is the main thing of
interest.
Theorem 29.12 Let f be analytic on C, f (0) ̸= 0, and let the zeros of f, be
{zk} ,listed according to order. (Thus if z is a zero of order m, it will be listed m
times in the list, {zk} .) Choosing nonnegative integers, pn such that for all r > 0,
∞
X
n=1
µ r
|zn|
¶pn+1
< ∞,

29.2.
FACTORING A GIVEN ANALYTIC FUNCTION
795
There exists an entire function, g such that
f (z) = eg(z)
∞
Y
n=1
Epn
µ z
zn
¶
.
(29.12)
Note that eg(z) ̸= 0 for any z and this is the interesting thing about this function.
Proof: {zn} cannot have a limit point because if there were a limit point of this
sequence, it would follow from Theorem 24.23 that f (z) = 0 for all z, contradicting
the hypothesis that f (0) ̸= 0. Hence limn→∞|zn| = ∞and so
∞
X
n=1
µ r
|zn|
¶1+n−1
=
∞
X
n=1
µ r
|zn|
¶n
< ∞
by the root test. Therefore, by Theorem 29.6
P (z) =
∞
Y
n=1
Epn
µ z
zn
¶
a function analytic on C by picking pn = n −1 or perhaps some other choice. (
pn = n −1 works but there might be another choice that would work.) Then f/P
has only removable singularities in C and no zeros thanks to Theorem 29.6. Thus,
letting h (z) = f (z) /P (z) , Corollary 24.50 implies that h′/h has a primitive, eg.
Then
³
he−eg´′
= 0
and so
h (z) = ea+ibeeg(z)
for some constants, a, b. Therefore, letting g (z) = eg (z) + a + ib, h (z) = eg(z) and
thus 29.12 holds. This proves the theorem.
Corollary 29.13 Let f be analytic on C, f has a zero of order m at 0, and let the
other zeros of f be {zk} , listed according to order. (Thus if z is a zero of order l,
it will be listed l times in the list, {zk} .) Also let
∞
X
n=1
µ r
|zn|
¶1+pn
< ∞
(29.13)
for any choice of r > 0. Then there exists an entire function, g such that
f (z) = zmeg(z)
∞
Y
n=1
Epn
µ z
zn
¶
.
(29.14)
Proof: Since f has a zero of order m at 0, it follows from Theorem 24.23 that
{zk} cannot have a limit point in C and so you can apply Theorem 29.12 to the
function, f (z) /zm which has a removable singularity at 0. This proves the corollary.

796
INFINITE PRODUCTS
29.2.1
Factoring Some Special Analytic Functions
Factoring a polynomial is in general a hard task. It is true it is easy to prove the
factors exist but ﬁnding them is another matter. Corollary 29.13 gives the existence
of factors of a certain form but it does not tell how to ﬁnd them. This should not
be surprising. You can’t expect things to get easier when you go from polynomials
to analytic functions. Nevertheless, it is possible to factor some popular analytic
functions. These factorizations are based on the following Mitag-Leﬄer expansions.
By an auspicious choice of the contour and the method of residues it is possible to
obtain a very interesting formula for cot πz .
Example 29.14 Let γN be the contour which goes from −N −1
2 −Ni horizontally
to N + 1
2 −Ni and from there, vertically to N + 1
2 + Ni and then horizontally
to −N −1
2 + Ni
and ﬁnally vertically to −N −1
2 −Ni. Thus the contour is a
large rectangle and the direction of integration is in the counter clockwise direction.
Consider the integral
IN ≡
Z
γN
π cos πz
sin πz (α2 −z2)dz
where α ∈R is not an integer. This will be used to verify the formula of Mittag-
Leﬄer,
1
α +
∞
X
n=1
2α
α2 −n2 = π cot πα.
(29.15)
First you show that cot πz is bounded on this contour. This is easy using the
formula for cot (z) = eiz+e−iz
eiz−e−iz . Therefore, IN →0 as N →∞because the integrand
is of order 1/N 2 while the diameter of γN is of order N. Next you compute the
residues of the integrand at ±α and at n where |n| < N + 1
2 for n an integer. These
are the only singularities of the integrand in this contour and therefore, using the
residue theorem, you can evaluate IN by using these.
You can calculate these
residues and ﬁnd that the residue at ±α is
−π cos πα
2α sin πα
while the residue at n is
1
α2 −n2 .
Therefore
0 = lim
N→∞IN = lim
N→∞2πi
"
N
X
n=−N
1
α2 −n2 −π cot πα
α
#
which establishes the following formula of Mittag Leﬄer.
lim
N→∞
N
X
n=−N
1
α2 −n2 = π cot πα
α
.

29.2.
FACTORING A GIVEN ANALYTIC FUNCTION
797
Writing this in a slightly nicer form, you obtain 29.15.
This is a very interesting formula. This will be used to factor sin (πz) . The
zeros of this function are at the integers. Therefore, considering 29.13 you can pick
pn = 1 in the Weierstrass factorization formula. Therefore, by Corollary 29.13 there
exists an analytic function g (z) such that
sin (πz) = zeg(z)
∞
Y
n=1
µ
1 −z
zn
¶
ez/zn
(29.16)
where the zn are the nonzero integers. Remember you can permute the factors in
these products. Therefore, this can be written more conveniently as
sin (πz) = zeg(z)
∞
Y
n=1
µ
1 −
³ z
n
´2¶
and it is necessary to ﬁnd g (z) . Diﬀerentiating both sides of 29.16
π cos (πz)
=
eg(z)
∞
Y
n=1
µ
1 −
³ z
n
´2¶
+ zg′ (z) eg(z)
∞
Y
n=1
µ
1 −
³ z
n
´2¶
+zeg(z)
∞
X
n=1
−
µ2z
n2
¶ Y
k̸=n
µ
1 −
³z
k
´2¶
Now divide both sides by sin (πz) to obtain
π cot (πz)
=
1
z + g′ (z) −
∞
X
n=1
2z/n2
(1 −z2/n2)
=
1
z + g′ (z) +
∞
X
n=1
2z
z2 −n2 .
By 29.15, this yields g′ (z) = 0 for z not an integer and so g (z) = c, a constant. So
far this yields
sin (πz) = zec
∞
Y
n=1
µ
1 −
³ z
n
´2¶
and it only remains to ﬁnd c. Divide both sides by πz and take a limit as z →0.
Using the power series of sin (πz) , this yields
1 = ec
π
and so c = ln π. Therefore,
sin (πz) = zπ
∞
Y
n=1
µ
1 −
³ z
n
´2¶
.
(29.17)

798
INFINITE PRODUCTS
Example 29.15 Find an interesting formula for tan (πz) .
This is easy to obtain from the formula for cot (πz) .
cot
µ
π
µ
z + 1
2
¶¶
= −tan πz
for z real and therefore, this formula holds for z complex also. Therefore, for z + 1
2
not an integer
π cot
µ
π
µ
z + 1
2
¶¶
=
2
2z + 1 +
∞
X
n=1
2z + 1
¡ 2z+1
2
¢2 −n2
29.3
The Existence Of An Analytic Function With
Given Values
The Weierstrass product formula, Theorem 29.6, along with the Mittag-Leﬄer the-
orem, Theorem 28.13 can be used to obtain an analytic function which has given
values on a countable set of points, having no limit point. This is clearly an amazing
result and indicates how potent these theorems are. In fact, you can show that it
isn’t just the values of the function which may be speciﬁed at the points in this
countable set of points but the derivatives up to any ﬁnite order.
Theorem 29.16 Let P ≡{zk}∞
k=1 be a set of points in C,which has no limit point.
For each zk, consider
mk
X
j=0
ak
j (z −zk)j .
(29.18)
Then there exists an analytic function deﬁned on C such that the Taylor series of
f at zk has the ﬁrst mk terms given by 29.18.1
Proof: By the Weierstrass product theorem, Theorem 29.6, there exists an
analytic function, f deﬁned on all of Ωsuch that f has a zero of order mk + 1 at
zk. Consider this zk Thus for z near zk,
f (z) =
∞
X
j=mk+1
cj (z −zk)j
where cmk+1 ̸= 0. You choose b1, b2, · · ·, bmk+1 such that
f (z)
Ãmk+1
X
l=1
bl
(z −zk)k
!
=
mk
X
j=0
ak
j (z −zk)j +
∞
X
k=mk+1
ck
j (z −zk)j .
1This says you can specify the ﬁrst mk derivatives of the function at the point zk.

29.3.
THE EXISTENCE OF AN ANALYTIC FUNCTION WITH GIVEN VALUES799
Thus you need
mk+1
X
l=1
∞
X
j=mk+1
cjbl (z −zk)j−l =
mk
X
r=0
ak
r (z −zk)r + Higher order terms.
It follows you need to solve the following system of equations for b1, · · ·, bmk+1.
cmk+1bmk+1 = ak
0
cmk+2bmk+1 + cmk+1bmk = ak
1
cmk+3bmk+1 + cmk+2bmk + cmk+1bmk−1 = ak
2
...
cmk+mk+1bmk+1 + cmk+mkbmk + · · · + cmk+1b1 = ak
mk
Since cmk+1 ̸= 0, it follows there exists a unique solution to the above system.
You ﬁrst solve for bmk+1 in the top. Then, having found it, you go to the next
and use cmk+1 ̸= 0 again to ﬁnd bmk and continue in this manner.
Let Sk (z)
be determined in this manner for each zk. By the Mittag-Leﬄer theorem, there
exists a Meromorphic function, g such that g has exactly the singularities, Sk (z) .
Therefore, f (z) g (z) has removable singularities at each zk and for z near zk, the
ﬁrst mk terms of fg are as prescribed. This proves the theorem.
Corollary 29.17 Let P ≡{zk}∞
k=1 be a set of points in Ω, an open set such that
P has no limit points in Ω. For each zk, consider
mk
X
j=0
ak
j (z −zk)j .
(29.19)
Then there exists an analytic function deﬁned on Ωsuch that the Taylor series of
f at zk has the ﬁrst mk terms given by 29.19.
Proof: The proof is identical to the above except you use the versions of the
Mittag-Leﬄer theorem and Weierstrass product which pertain to open sets.
Deﬁnition 29.18 Denote by H (Ω) the analytic functions deﬁned on Ω, an open
subset of C. Then H (Ω) is a commutative ring2 with the usual operations of addition
and multiplication. A set, I ⊆H (Ω) is called a ﬁnitely generated ideal of the ring
if I is of the form
( n
X
k=1
gkfk : fk ∈H (Ω) for k = 1, 2, · · ·, n
)
where g1, ···, gn are given functions in H (Ω). This ideal is also denoted as [g1, · · ·, gn]
and is called the ideal generated by the functions, {g1, · · ·, gn}.
Since there are
ﬁnitely many of these functions it is called a ﬁnitely generated ideal. A principal
ideal is one which is generated by a single function. An example of such a thing is
[1] = H (Ω) .
2It is not a ﬁeld because you can’t divide two analytic functions and get another one.

800
INFINITE PRODUCTS
Then there is the following interesting theorem.
Theorem 29.19 Every ﬁnitely generated ideal in H (Ω) for Ωa connected open set
(region) is a principal ideal.
Proof: Let I = [g1, · · ·, gn] be a ﬁnitely generated ideal as described above.
Then if any of the functions has no zeros, this ideal would consist of H (Ω) because
then g−1
i
∈H (Ω) and so 1 ∈I. It follows all the functions have zeros. If any of the
functions has a zero of inﬁnite order, then the function equals zero on Ωbecause Ω
is connected and can be deleted from the list. Similarly, if the zeros of any of these
functions have a limit point in Ω, then the function equals zero and can be deleted
from the list. Thus, without loss of generality, all zeros are of ﬁnite order and there
are no limit points of the zeros in Ω. Let m (gi, z) denote the order of the zero of
gi at z. If gi has no zero at z, then m (gi, z) = 0.
I claim that if no point of Ωis a zero of all the gi, then the conclusion of the
theorem is true and in fact [g1, · · ·, gn] = [1] = H (Ω) . The claim is obvious if n = 1
because this assumption that no point is a zero of all the functions implies g ̸= 0
and so g−1 is analytic. Hence 1 ∈[g1] . Suppose it is true for n −1 and consider
[g1, · · ·, gn] where no point of Ωis a zero of all the gi. Even though this may be true
of {g1, · · ·, gn} , it may not be true of {g1, · · ·, gn−1} . By Corollary 29.9 there exists
φ, a function analytic on Ωsuch that m (φ, z) = min {m (gi, z) , i = 1, 2, · · ·, n −1} .
Thus the functions {g1/φ, · · ·, gn−1/φ} .are all analytic. Could they all equal zero
at some point, z? If so, pick i where m (φ, z) = m (gi, z) . Thus gi/φ is not equal to
zero at z after all and so these functions are analytic there is no point of Ωwhich
is a zero of all of them. By induction, [g1/φ, · · ·, gn−1/φ] = H (Ω). (Also there are
no new zeros obtained in this way.)
Now this means there exist functions fi ∈H (Ω) such that
n
X
i=1
fi
µgi
φ
¶
= 1
and so φ = Pn
i=1 figi. Therefore, [φ] ⊆[g1, · · ·, gn−1] . On the other hand, if
Pn−1
k=1 hkgk ∈[g1, · · ·, gn−1] you could deﬁne h ≡Pn−1
k=1 hk (gk/φ ) , an analytic
function with the property that hφ = Pn−1
k=1 hkgk which shows [φ] = [g1, · · ·, gn−1].
Therefore,
[g1, · · ·, gn] = [φ, gn]
Now φ has no zeros in common with gn because the zeros of φ are contained in the
set of zeros for g1, · · ·, gn−1. Now consider a zero, α of φ. It is not a zero of gn and
so near α, these functions have the form
φ (z) =
∞
X
k=m
ak (z −α)k , gn (z) =
∞
X
k=0
bk (z −α)k , b0 ̸= 0.
I want to determine coeﬃcients for an analytic function, h such that
m (1 −hgn, α) ≥m (φ, α) .
(29.20)

29.3.
THE EXISTENCE OF AN ANALYTIC FUNCTION WITH GIVEN VALUES801
Let
h (z) =
∞
X
k=0
ck (z −α)k
and the ck must be determined. Using Merten’s theorem, the power series for 1−hgn
is of the form
1 −b0c0 −
∞
X
j=1
Ã j
X
r=0
bj−rcr
!
(z −α)j .
First determine c0 such that 1 −c0b0 = 0. This is no problem because b0 ̸= 0. Next
you need to get the coeﬃcients of (z −α) to equal zero. This requires
b1c0 + b0c1 = 0.
Again, there is no problem because b0 ̸= 0. In fact, c1 = (−b1c0/b0) . Next consider
the second order terms if m ≥2.
b2c0 + b1c1 + b0c2 = 0
Again there is no problem in solving, this time for c2 because b0 ̸= 0. Continuing this
way, you see that in every step, the ck which needs to be solved for is multiplied by
b0 ̸= 0. Therefore, by Corollary 29.9 there exists an analytic function, h satisfying
29.20. Therefore, (1 −hgn) /φ has a removable singularity at every zero of φ and
so may be considered an analytic function. Therefore,
1 = 1 −hgn
φ
φ + hgn ∈[φ, gn] = [g1 · · · gn]
which shows [g1 · · · gn] = H (Ω) = [1] . It follows the claim is established.
Now suppose {g1 · · · gn} are just elements of H (Ω) . As explained above, it can
be assumed they all have zeros of ﬁnite order and the zeros have no limit point
in Ωsince if these occur, you can delete the function from the list. By Corollary
29.9 there exists φ ∈H (Ω) such that m (φ, z) ≤min {m (gi, z) : i = 1, · · ·, n} . Then
gk/φ has a removable singularity at each zero of gk and so can be regarded as an
analytic function. Also, as before, there is no point which is a zero of each gk/φ and
so by the ﬁrst part of this argument, [g1/φ · · · gn/φ] = H (Ω) . As in the ﬁrst part
of the argument, this implies [g1 · · · gn] = [φ] which proves the theorem. [g1 · · · gn]
is a principal ideal as claimed.
The following corollary follows from the above theorem.
You don’t need to
assume Ωis connected.
Corollary 29.20 Every ﬁnitely generated ideal in H (Ω) for Ωan open set is a
principal ideal.
Proof: Let [g1, · · ·, gn] be a ﬁnitely generated ideal in H (Ω) . Let {Uk} be the
components of Ω. Then applying the above to each component, there exists hk ∈
H (Uk) such that restricting each gi to Uk, [g1, · · ·, gn] = [hk] . Then let h (z) = hk (z)
for z ∈Uk. This is an analytic function which works.

802
INFINITE PRODUCTS
29.4
Jensen’s Formula
This interesting formula relates the zeros of an analytic function to an integral. The
proof given here follows Alfors, [2]. First, here is a technical lemma.
Lemma 29.21
Z π
−π
ln
¯¯1 −eiθ¯¯ dθ = 0.
Proof: First note that the only problem with the integrand occurs when θ = 0.
However, this is an integrable singularity so the integral will end up making sense.
Letting z = eiθ, you could get the above integral as a limit as ε →0 of the following
contour integral where γε is the contour shown in the following picture with the
radius of the big circle equal to 1 and the radius of the little circle equal to ε..
Z
γε
ln |1 −z|
iz
dz.
s
1
s
On the indicated contour, 1−z lies in the half plane Re z > 0 and so log (1 −z) =
ln |1 −z| + i arg (1 −z). The above integral equals
Z
γε
log (1 −z)
iz
dz −
Z
γε
arg (1 −z)
z
dz
The ﬁrst of these integrals equals zero because the integrand has a removable sin-
gularity at 0. The second equals
i
Z −ηε
−π
arg
¡
1 −eiθ¢
dθ + i
Z π
ηε
arg
¡
1 −eiθ¢
dθ
+εi
Z −π
−π
2 −λε
θdθ + εi
Z
π
2 −λε
π
θdθ
where ηε, λε →0 as ε →0. The last two terms converge to 0 as ε →0 while the
ﬁrst two add to zero. To see this, change the variable in the ﬁrst integral and then
recall that when you multiply complex numbers you add the arguments. Thus you
end up integrating arg (real valued function) which equals zero.
In this material on Jensen’s equation, ε will denote a small positive number. Its
value is not important as long as it is positive. Therefore, it may change from place

29.4.
JENSEN’S FORMULA
803
to place. Now suppose f is analytic on B (0, r + ε) , and f has no zeros on B (0, r).
Then you can deﬁne a branch of the logarithm which makes sense for complex
numbers near f (z) . Thus z →log (f (z)) is analytic on B (0, r + ε). Therefore, its
real part, u (x, y) ≡ln |f (x + iy)| must be harmonic. Consider the following lemma.
Lemma 29.22 Let u be harmonic on B (0, r + ε) . Then
u (0) = 1
2π
Z π
−π
u
¡
reiθ¢
dθ.
Proof:
For a harmonic function, u deﬁned on B (0, r + ε) , there exists an
analytic function, h = u + iv where
v (x, y) ≡
Z y
0
ux (x, t) dt −
Z x
0
uy (t, 0) dt.
By the Cauchy integral theorem,
h (0) =
1
2πi
Z
γr
h (z)
z
dz = 1
2π
Z π
−π
h
¡
reiθ¢
dθ.
Therefore, considering the real part of h,
u (0) = 1
2π
Z π
−π
u
¡
reiθ¢
dθ.
This proves the lemma.
Now this shows the following corollary.
Corollary 29.23 Suppose f is analytic on B (0, r + ε) and has no zeros on B (0, r).
Then
ln |f (0)| = 1
2π
Z π
−π
ln
¯¯f
¡
reiθ¢¯¯
(29.21)
What if f has some zeros on |z| = r but none on B (0, r)? It turns out 29.21
is still valid. Suppose the zeros are at
©
reiθkªm
k=1 , listed according to multiplicity.
Then let
g (z) =
f (z)
Qm
k=1 (z −reiθk).

804
INFINITE PRODUCTS
It follows g is analytic on B (0, r + ε) but has no zeros in B (0, r). Then 29.21 holds
for g in place of f. Thus
ln |f (0)| −
m
X
k=1
ln |r|
=
1
2π
Z π
−π
ln
¯¯f
¡
reiθ¢¯¯ dθ −1
2π
Z π
−π
m
X
k=1
ln
¯¯reiθ −reiθk¯¯ dθ
=
1
2π
Z π
−π
ln
¯¯f
¡
reiθ¢¯¯ dθ −1
2π
Z π
−π
m
X
k=1
ln
¯¯eiθ −eiθk¯¯ dθ −
m
X
k=1
ln |r|
=
1
2π
Z π
−π
ln
¯¯f
¡
reiθ¢¯¯ dθ −1
2π
Z π
−π
m
X
k=1
ln
¯¯eiθ −1
¯¯ dθ −
m
X
k=1
ln |r|
Therefore, 29.21 will continue to hold exactly when
1
2π
R π
−π
Pm
k=1 ln
¯¯eiθ −1
¯¯ dθ = 0.
But this is the content of Lemma 29.21. This proves the following lemma.
Lemma 29.24 Suppose f is analytic on B (0, r + ε) and has no zeros on B (0, r) .
Then
ln |f (0)| = 1
2π
Z π
−π
ln
¯¯f
¡
reiθ¢¯¯
(29.22)
With this preparation, it is now not too hard to prove Jensen’s formula. Suppose
there are n zeros of f in B (0, r) , {ak}n
k=1, listed according to multiplicity, none equal
to zero. Let
F (z) ≡f (z)
n
Y
i=1
r2 −aiz
r (z −ai).
Then F is analytic on B (0, r + ε) and has no zeros in B (0, r) . The reason for this
is that f (z) / Qn
i=1 r (z −ai) has no zeros there and r2 −aiz cannot equal zero if
|z| < r because if this expression equals zero, then
|z| = r2
|ai| > r.
The other interesting thing about F (z) is that when z = reiθ,
F
¡
reiθ¢
=
f
¡
reiθ¢
n
Y
i=1
r2 −aireiθ
r (reiθ −ai)
=
f
¡
reiθ¢
n
Y
i=1
r −aieiθ
(reiθ −ai) = f
¡
reiθ¢
eiθ
n
Y
i=1
re−iθ −ai
reiθ −ai
so
¯¯F
¡
reiθ¢¯¯ =
¯¯f
¡
reiθ¢¯¯.

29.5.
BLASCHKE PRODUCTS
805
Theorem 29.25 Let f be analytic on B (0, r + ε) and suppose f (0) ̸= 0. If the
zeros of f in B (0, r) are {ak}n
k=1, listed according to multiplicity, then
ln |f (0)| = −
n
X
i=1
ln
µ r
|ai|
¶
+ 1
2π
Z 2π
0
ln
¯¯f
¡
reiθ¢¯¯ dθ.
Proof: From the above discussion and Lemma 29.24,
ln |F (0)| = 1
2π
Z π
−π
ln
¯¯f
¡
reiθ¢¯¯ dθ
But F (0) = f (0) Qn
i=1
r
ai and so ln |F (0)| = ln |f (0)| + Pn
i=1 ln
¯¯¯ r
ai
¯¯¯ . Therefore,
ln |f (0)| = −
n
X
i=1
ln
¯¯¯¯
r
ai
¯¯¯¯ + 1
2π
Z 2π
0
ln
¯¯f
¡
reiθ¢¯¯ dθ
as claimed.
Written in terms of exponentials this is
|f (0)|
n
Y
k=1
¯¯¯¯
r
ak
¯¯¯¯ = exp
µ 1
2π
Z 2π
0
ln
¯¯f
¡
reiθ¢¯¯ dθ
¶
.
29.5
Blaschke Products
The Blaschke3 product is a way to produce a function which is bounded and analytic
on B (0, 1) which also has given zeros in B (0, 1) . The interesting thing here is
that there may be inﬁnitely many of these zeros. Thus, unlike the above case of
Jensen’s inequality, the function is not analytic on B (0, 1). Recall for purposes of
comparison, Liouville’s theorem which says bounded entire functions are constant.
The Blaschke product gives examples of bounded functions on B (0, 1) which are
deﬁnitely not constant.
Theorem 29.26 Let {αn} be a sequence of nonzero points in B (0, 1) with the
property that
∞
X
n=1
(1 −|αn|) < ∞.
Then for k ≥0, an integer
B (z) ≡zk
∞
Y
k=1
αn −z
1 −αnz
|αn|
αn
is a bounded function which is analytic on B (0, 1) which has zeros only at 0 if k > 0
and at the αn.
3Wilhelm Blaschke, 1915

806
INFINITE PRODUCTS
Proof: From Theorem 29.2 the above product will converge uniformly on B (0, r)
for r < 1 to an analytic function if
∞
X
k=1
¯¯¯¯
αn −z
1 −αnz
|αn|
αn
−1
¯¯¯¯
converges uniformly on B (0, r) . But for |z| < r,
¯¯¯¯
αn −z
1 −αnz
|αn|
αn
−1
¯¯¯¯
=
¯¯¯¯
αn −z
1 −αnz
|αn|
αn
−αn (1 −αnz)
αn (1 −αnz)
¯¯¯¯
=
¯¯¯¯¯
|αn| αn −|αn| z −αn + |αn|2 z
(1 −αnz) αn
¯¯¯¯¯
=
¯¯¯¯¯
|αn| αn −αn −|αn| z + |αn|2 z
(1 −αnz) αn
¯¯¯¯¯
=
||αn| −1|
¯¯¯¯
αn + z |αn|
(1 −αnz) αn
¯¯¯¯
=
||αn| −1|
¯¯¯¯
1 + z (|αn| /αn)
(1 −αnz)
¯¯¯¯
≤
||αn| −1|
¯¯¯¯
1 + |z|
1 −|z|
¯¯¯¯ ≤||αn| −1|
¯¯¯¯
1 + r
1 −r
¯¯¯¯
and so the assumption on the sum gives uniform convergence of the product on
B (0, r) to an analytic function. Since r < 1 is arbitrary, this shows B (z) is analytic
on B (0, 1) and has the speciﬁed zeros because the only place the factors equal zero
are at the αn or 0.
Now consider the factors in the product. The claim is that they are all no larger
in absolute value than 1.
This is very easy to see from the maximum modulus
theorem. Let |α| < 1 and φ (z) =
α−z
1−αz. Then φ is analytic near B (0, 1) because its
only pole is 1/α. Consider z = eiθ. Then
¯¯φ
¡
eiθ¢¯¯ =
¯¯¯¯
α −eiθ
1 −αeiθ
¯¯¯¯ =
¯¯¯¯
1 −αe−iθ
1 −αeiθ
¯¯¯¯ = 1.
Thus the modulus of φ (z) equals 1 on ∂B (0, 1) . Therefore, by the maximum mod-
ulus theorem, |φ (z)| < 1 if |z| < 1. This proves the claim that the terms in the
product are no larger than 1 and shows the function determined by the Blaschke
product is bounded. This proves the theorem.
Note in the conditions for this theorem the one for the sum, P∞
n=1 (1 −|αn|) <
∞. The Blaschke product gives an analytic function, whose absolute value is bounded
by 1 and which has the αn as zeros. What if you had a bounded function, analytic
on B (0, 1) which had zeros at {αk}? Could you conclude the condition on the sum?

29.5.
BLASCHKE PRODUCTS
807
The answer is yes. In fact, you can get by with less than the assumption that f is
bounded but this will not be presented here. See Rudin [45]. This theorem is an
exciting use of Jensen’s equation.
Theorem 29.27 Suppose f is an analytic function on B (0, 1) , f (0) ̸= 0, and
|f (z)| ≤M for all z ∈B (0, 1) . Suppose also that the zeros of f are {αk}∞
k=1 ,
listed according to multiplicity. Then P∞
k=1 (1 −|αk|) < ∞.
Proof: If there are only ﬁnitely many zeros, there is nothing to prove so assume
there are inﬁnitely many. Also let the zeros be listed such that |αn| ≤|αn+1|··· Let
n (r) denote the number of zeros in B (0, r) . By Jensen’s formula,
ln |f (0)| +
n(r)
X
i=1
ln r −ln |αi| = 1
2π
Z 2π
0
ln
¯¯f
¡
reiθ¢¯¯ dθ ≤ln (M) .
Therefore, by the mean value theorem,
n(r)
X
i=1
1
r (r −|αi|) ≤
n(r)
X
i=1
ln r −ln |αi| ≤ln (M) −ln |f (0)|
As r →1−, n (r) →∞, and so an application of Fatous lemma yields
∞
X
i=1
(1 −|αi|) ≤lim inf
r→1−
n(r)
X
i=1
1
r (r −|αi|) ≤ln (M) −ln |f (0)| .
This proves the theorem.
You don’t need the assumption that f (0) ̸= 0.
Corollary 29.28 Suppose f is an analytic function on B (0, 1) and |f (z)| ≤M
for all z ∈B (0, 1) . Suppose also that the nonzero zeros4 of f are {αk}∞
k=1 , listed
according to multiplicity. Then P∞
k=1 (1 −|αk|) < ∞.
Proof:
Suppose f has a zero of order m at 0.
Then consider the analytic
function, g (z) ≡f (z) /zm which has the same zeros except for 0. The argument
goes the same way except here you use g instead of f and only consider r > r0 > 0.
4This is a fun thing to say: nonzero zeros.

808
INFINITE PRODUCTS
Thus from Jensen’s equation,
ln |g (0)| +
n(r)
X
i=1
ln r −ln |αi|
=
1
2π
Z 2π
0
ln
¯¯g
¡
reiθ¢¯¯ dθ
=
1
2π
Z 2π
0
ln
¯¯f
¡
reiθ¢¯¯ dθ −1
2π
Z 2π
0
m ln (r)
≤
M + 1
2π
Z 2π
0
m ln
¡
r−1¢
≤
M + m ln
µ 1
r0
¶
.
Now the rest of the argument is the same.
An interesting restatement yields the following amazing result.
Corollary 29.29 Suppose f is analytic and bounded on B (0, 1) having zeros {αn} .
Then if P∞
k=1 (1 −|αn|) = ∞, it follows f is identically equal to zero.
29.5.1
The M¨untz-Szasz Theorem Again
Corollary 29.29 makes possible an easy proof of a remarkable theorem named above
which yields a wonderful generalization of the Weierstrass approximation theorem.
In what follows b > 0. The Weierstrass approximation theorem states that linear
combinations of 1, t, t2, t3, · · · (polynomials) are dense in C ([0, b]) . Let λ1 < λ2 <
λ3 < · · · be an increasing list of positive real numbers. This theorem tells when
linear combinations of 1, tλ1, tλ2, · · · are dense in C ([0, b]). The proof which follows
is like the one given in Rudin [45]. There is a much longer one in Cheney [14] which
discusses more aspects of the subject. See also Page 377 where the version given in
Cheney is presented. This other approach is much more elementary and does not
depend in any way on the theory of functions of a complex variable. There are those
of us who automatically prefer real variable techniques. Nevertheless, this proof by
Rudin is a very nice and insightful application of the preceding material. Cheney
refers to the theorem as the second M¨untz theorem. I guess Szasz must also have
been involved.
Theorem 29.30 Let λ1 < λ2 < λ3 < · · · be an increasing list of positive real
numbers and let a > 0. If
∞
X
n=1
1
λn
= ∞,
(29.23)
then linear combinations of 1, tλ1, tλ2, · · ·
are dense in C ([0, b]).

29.5.
BLASCHKE PRODUCTS
809
Proof: Let X denote the closure of linear combinations of
©
1, tλ1, tλ2, · · ·
ª
in
C ([0, b]) . If X ̸= C ([0, b]) , then letting f ∈C ([0, b]) \ X, deﬁne Λ ∈C ([0, b])′ as
follows. First let Λ0 : X + Cf be given by Λ0 (g + αf) = α ||f||∞. Then
sup
||g+αf||≤1
|Λ0 (g + αf)|
=
sup
||g+αf||≤1
|α| ||f||∞
=
sup
||g/α+f||≤
1
|α|
|α| ||f||∞
=
sup
||g+f||≤
1
|α|
|α| ||f||∞
Now dist (f, X) > 0 because X is closed. Therefore, there exists a lower bound,
η > 0 to ||g + f|| for g ∈X. Therefore, the above is no larger than
sup
|α|≤1
η
|α| ||f||∞=
µ1
η
¶
||f||∞
which shows that ||Λ0|| ≤
³
1
η
´
||f||∞. By the Hahn Banach theorem Λ0 can be
extended to Λ ∈C ([0, b])′ which has the property that Λ (X) = 0 but Λ (f) =
||f|| ̸= 0. By the Weierstrass approximation theorem, Theorem 7.6 or one of its
cases, there exists a polynomial, p such that Λ (p) ̸= 0. Therefore, if it can be
shown that whenever Λ (X) = 0, it is the case that Λ (p) = 0 for all polynomials, it
must be the case that X is dense in C ([0, b]).
By the Riesz representation theorem the elements of C ([0, b])′ are complex mea-
sures. Suppose then that for µ a complex measure it follows that for all tλk,
Z
[0,b]
tλkdµ = 0.
I want to show that then
Z
[0,b]
tkdµ = 0
for all positive integers. It suﬃces to modify µ is necessary to have µ ({0}) = 0 since
this will not change any of the above integrals. Let µ1 (E) = µ (E ∩(0, b]) and use
µ1. I will continue using the symbol, µ.
For Re (z) > 0, deﬁne
F (z) ≡
Z
[0,b]
tzdµ =
Z
(0,b]
tzdµ
The function tz = exp (z ln (t)) is analytic. I claim that F (z) is also analytic for
Re z > 0. Apply Morea’s theorem. Let T be a triangle in Re z > 0. Then
Z
∂T
F (z) dz =
Z
∂T
Z
(0,b]
e(z ln(t))ξd |µ| dz

810
INFINITE PRODUCTS
Now
R
∂T can be split into three integrals over intervals of R and so this integral is es-
sentially a Lebesgue integral taken with respect to Lebesgue measure. Furthermore,
e(z ln(t)) is a continuous function of the two variables and ξ is a function of only the
one variable, t. Thus the integrand is product measurable. The iterated integral is
also absolutely integrable because
¯¯e(z ln(t))¯¯ ≤ex ln t ≤ex ln b where x + iy = z and
x is given to be positive. Thus the integrand is actually bounded. Therefore, you
can apply Fubini’s theorem and write
Z
∂T
F (z) dz
=
Z
∂T
Z
(0,b]
e(z ln(t))ξd |µ| dz
=
Z
(0,b]
ξ
Z
∂T
e(z ln(t))dzd |µ| = 0.
By Morea’s theorem, F is analytic on Re z > 0 which is given to have zeros at the
λk.
Now let φ (z) = 1+z
1−z. Then φ maps B (0, 1) one to one onto Re z > 0. To see this
let 0 < r < 1.
φ
¡
reiθ¢
= 1 + reiθ
1 −reiθ = 1 −r2 + i2r sin θ
1 + r2 −2r cos θ
and so Re φ
¡
reiθ¢
> 0. Now the inverse of φ is φ−1 (z) = z−1
z+1. For Re z > 0,
¯¯φ−1 (z)
¯¯2 = z −1
z + 1 · z −1
z + 1 = |z|2 −2 Re z + 1
|z|2 + 2 Re z + 1
< 1.
Consider F ◦φ, an analytic function deﬁned on B (0, 1). This function is given to
have zeros at zn where φ (zn) = 1+zn
1−zn = λn. This reduces to zn = −1+λn
1+λn . Now
1 −|zn| ≥
c
1 + λn
for a positive constant, c. It is given that P
1
λn = ∞. so it follows P (1 −|zn|) = ∞
also. Therefore, by Corollary 29.29, F ◦φ = 0. It follows F = 0 also. In particular,
F (k) for k a positive integer equals zero. This has shown that if Λ ∈C ([0, b])′ and
Λ sends 1 and all the tλn to 0, then Λ sends 1 and all tk for k a positive integer to
zero. As explained above, X is dense in C ((0, b]) .
The converse of this theorem is also true and is proved in Rudin [45].
29.6
Exercises
1. Suppose f is an entire function with f (0) = 1. Let
M (r) = max {|f (z)| : |z| = r} .
Use Jensen’s equation to establish the following inequality.
M (2r) ≥2n(r)
where n (r) is the number of zeros of f in B (0, r).

29.6.
EXERCISES
811
2. The version of the Blaschke product presented above is that found in most
complex variable texts.
However, there is another one in [37].
Instead of
αn−z
1−αnz
|αn|
αn you use
αn −z
1
αn −z
Prove a version of Theorem 29.26 using this modiﬁcation.
3. The Weierstrass approximation theorem holds for polynomials of n variables
on any compact subset of Rn. Give a multidimensional version of the M¨untz-
Szasz theorem which will generalize the Weierstrass approximation theorem
for n dimensions.
You might just pick a compact subset of Rn in which
all components are positive.
You have to do something like this because
otherwise, tλ might not be deﬁned.
4. Show cos (πz) = Q∞
k=1
³
1 −
4z2
(2k−1)2
´
.
5. Recall sin (πz) = zπ Q∞
n=1
³
1 −
¡ z
n
¢2´
. Use this to derive Wallis product,
π
2 = Q∞
k=1
4k2
(2k−1)(2k+1).
6. The order of an entire function, f is deﬁned as
inf
n
a ≥0 : |f (z)| ≤e|z|a for all large enough |z|
o
If no such a exists, the function is said to be of inﬁnite order. Show the order
of an entire function is also equal to lim supr→∞
ln(ln(M(r)))
ln(r)
where M (r) ≡
max {|f (z)| : |z| = r}.
7. Suppose Ωis a simply connected region and let f be meromorphic on Ω.
Suppose also that the set, S ≡{z ∈Ω: f (z) = c} has a limit point in Ω. Can
you conclude f (z) = c for all z ∈Ω?
8. This and the next collection of problems are dealing with the gamma function.
Show that
¯¯¯
³
1 + z
n
´
e
−z
n −1
¯¯¯ ≤C (z)
n2
and therefore,
∞
X
n=1
¯¯¯
³
1 + z
n
´
e
−z
n −1
¯¯¯ < ∞
with the convergence uniform on compact sets.
9. ↑Show Q∞
n=1
¡
1 + z
n
¢
e
−z
n converges to an analytic function on C which has
zeros only at the negative integers and that therefore,
∞
Y
n=1
³
1 + z
n
´−1
e
z
n

812
INFINITE PRODUCTS
is a meromorphic function (Analytic except for poles) having simple poles at
the negative integers.
10. ↑Show there exists γ such that if
Γ (z) ≡e−γz
z
∞
Y
n=1
³
1 + z
n
´−1
e
z
n ,
then Γ (1) = 1. Thus Γ is a meromorphic function having simple poles at the
negative integers. Hint: Q∞
n=1 (1 + n) e−1/n = c = eγ.
11. ↑Now show that
γ = lim
n→∞
" n
X
k=1
1
k −ln n
#
12. ↑Justify the following argument leading to Gauss’s formula
Γ (z) = lim
n→∞
Ã n
Y
k=1
µ
k
k + z
¶
e
z
k
!
e−γz
z
=
lim
n→∞
µ
n!
(1 + z) (2 + z) · · · (n + z)ez(
Pn
k=1
1
k)
¶ e−γz
z
=
lim
n→∞
n!
(1 + z) (2 + z) · · · (n + z)ez(
Pn
k=1
1
k)e−z[
Pn
k=1
1
k −ln n]
=
lim
n→∞
n!nz
(1 + z) (2 + z) · · · (n + z).
13. ↑Verify from the Gauss formula above that Γ (z + 1) = Γ (z) z and that for n
a nonnegative integer, Γ (n + 1) = n!.
14. ↑The usual deﬁnition of the gamma function for positive x is
Γ1 (x) ≡
Z ∞
0
e−ttx−1dt.
Show
¡
1 −t
n
¢n ≤e−t for t ∈[0, n] . Then show
Z n
0
µ
1 −t
n
¶n
tx−1dt =
n!nx
x (x + 1) · · · (x + n).
Use the ﬁrst part to conclude that
Γ1 (x) = lim
n→∞
n!nx
x (x + 1) · · · (x + n) = Γ (x) .
Hint: To show
¡
1 −t
n
¢n ≤e−t for t ∈[0, n] , verify this is equivalent to
showing (1 −u)n ≤e−nu for u ∈[0, 1].

29.6.
EXERCISES
813
15. ↑Show Γ (z) =
R ∞
0
e−ttz−1dt. whenever Re z > 0. Hint: You have already
shown that this is true for positive real numbers.
Verify this formula for
Re z > 0 yields an analytic function.
16. ↑Show Γ
¡ 1
2
¢
= √π. Then ﬁnd Γ
¡ 5
2
¢
.
17. Show that
R ∞
−∞e
−s2
2 ds =
√
2π. Hint: Denote this integral by I and observe
that I2 =
R
R2 e−(x2+y2)/2dxdy. Then change variables to polar coordinates,
x = r cos (θ), y = r sin θ.
18. ↑Now that you know what the gamma function is, consider in the formula
for Γ (α + 1) the following change of variables. t = α + α1/2s. Then in terms
of the new variable, s, the formula for Γ (α + 1) is
e−ααα+ 1
2
Z ∞
−√α
e−√αs
µ
1 +
s
√α
¶α
ds
= e−ααα+ 1
2
Z ∞
−√α
e
α
h
ln
³
1+
s
√α
´
−
s
√α
i
ds
Show the integrand converges to e−s2
2 . Show that then
lim
α→∞
Γ (α + 1)
e−ααα+(1/2) =
Z ∞
−∞
e
−s2
2 ds =
√
2π.
Hint: You will need to obtain a dominating function for the integral so that
you can use the dominated convergence theorem. You might try considering
s ∈(−√α, √α) ﬁrst and consider something like e1−(s2/4) on this interval.
Then look for another function for s > √α. This formula is known as Stirling’s
formula.
19. This and the next several problems develop the zeta function and give a
relation between the zeta and the gamma function. Deﬁne for 0 < r < 2π
Ir (z)
≡
Z 2π
0
e(z−1)(ln r+iθ)
ereiθ −1
ireiθdθ +
Z ∞
r
e(z−1)(ln t+2πi)
et −1
dt (29.24)
+
Z r
∞
e(z−1) ln t
et −1 dt
Show that Ir is an entire function. The reason 0 < r < 2π is that this prevents
ereiθ −1 from equaling zero. The above is just a precise description of the
contour integral,
R
γ
wz−1
ew−1dw where γ is the contour shown below.

814
INFINITE PRODUCTS
-


-
?
in which on the integrals along the real line, the argument is diﬀerent in going
from r to ∞than it is in going from ∞to r. Now I have not deﬁned such
contour integrals over contours which have inﬁnite length and so have chosen
to simply write out explicitly what is involved. You have to work with these
integrals given above anyway but the contour integral just mentioned is the
motivation for them. Hint: You may want to use convergence theorems from
real analysis if it makes this more convenient but you might not have to.
20. ↑In the context of Problem 19 deﬁne for small δ > 0
Irδ (z) ≡
Z
γr,δ
wz−1
ew −1dw
where γrδ is shown below.
-


-
?
2δ
s¡
¡
¡

r
x
Show that limδ→0 Irδ (z) = Ir (z) . Hint:
Use the dominated convergence
theorem if it makes this go easier. This is not a hard problem if you use these
theorems but you can probably do it without them with more work.
21. ↑In the context of Problem 20 show that for r1 < r, Irδ (z) −Ir1δ (z) is a
contour integral,
Z
γr,r1,δ
wz−1
ew −1dw
where the oriented contour is shown below.

29.6.
EXERCISES
815

-
?
-

6
γr,r1,δ
In this contour integral, wz−1 denotes e(z−1) log(w) where log (w) = ln |w| +
i arg (w) for arg (w) ∈(0, 2π) . Explain why this integral equals zero. From
Problem 20 it follows that Ir = Ir1. Therefore, you can deﬁne an entire func-
tion, I (z) ≡Ir (z) for all r positive but suﬃciently small. Hint: Remember
the Cauchy integral formula for analytic functions deﬁned on simply connected
regions. You could argue there is a simply connected region containing γr,r1,δ.
22. ↑In case Re z > 1, you can get an interesting formula for I (z) by taking the
limit as r →0. Recall that
Ir (z)
≡
Z 2π
0
e(z−1)(ln r+iθ)
ereiθ −1
ireiθdθ +
Z ∞
r
e(z−1)(ln t+2πi)
et −1
dt (29.25)
+
Z r
∞
e(z−1) ln t
et −1 dt
and now it is desired to take a limit in the case where Re z > 1. Show the ﬁrst
integral above converges to 0 as r →0. Next argue the sum of the two last
integrals converges to
³
e(z−1)2πi −1
´ Z ∞
0
e(z−1) ln(t)
et −1
dt.
Thus
I (z) =
¡
ez2πi −1
¢ Z ∞
0
e(z−1) ln(t)
et −1
dt
(29.26)
when Re z > 1.
23. ↑So what does all this have to do with the zeta function and the gamma
function? The zeta function is deﬁned for Re z > 1 by
∞
X
n=1
1
nz ≡ζ (z) .
By Problem 15, whenever Re z > 0,
Γ (z) =
Z ∞
0
e−ttz−1dt.

816
INFINITE PRODUCTS
Change the variable and conclude
Γ (z) 1
nz =
Z ∞
0
e−nssz−1ds.
Therefore, for Re z > 1,
ζ (z) Γ (z) =
∞
X
n=1
Z ∞
0
e−nssz−1ds.
Now show that you can interchange the order of the sum and the integral.
This is possibly most easily done by using Fubini’s theorem.
Show that
P∞
n=1
R ∞
0
¯¯e−nssz−1¯¯ ds < ∞and then use Fubini’s theorem.
I think you
could do it other ways though. It is possible to do it without any reference to
Lebesgue integration. Thus
ζ (z) Γ (z)
=
Z ∞
0
sz−1
∞
X
n=1
e−nsds
=
Z ∞
0
sz−1e−s
1 −e−s ds =
Z ∞
0
sz−1
es −1ds
By 29.26,
I (z)
=
¡
ez2πi −1
¢ Z ∞
0
e(z−1) ln(t)
et −1
dt
=
¡
ez2πi −1
¢
ζ (z) Γ (z)
=
¡
e2πiz −1
¢
ζ (z) Γ (z)
whenever Re z > 1.
24. ↑Now show there exists an entire function, h (z) such that
ζ (z) =
1
z −1 + h (z)
for Re z > 1. Conclude ζ (z) extends to a meromorphic function deﬁned on
all of C which has a simple pole at z = 1, namely, the right side of the above
formula. Hint: Use Problem 10 to observe that Γ (z) is never equal to zero
but has simple poles at every nonnegative integer. Then for Re z > 1,
ζ (z) ≡
I (z)
(e2πiz −1) Γ (z).
By 29.26 ζ has no poles for Re z > 1. The right side of the above equation is
deﬁned for all z. There are no poles except possibly when z is a nonnegative
integer. However, these points are not poles either because of Problem 10
which states that Γ has simple poles at these points thus cancelling the simple

29.6.
EXERCISES
817
zeros of
¡
e2πiz −1
¢
. The only remaining possibility for a pole for ζ is at z = 1.
Show it has a simple pole at this point. You can use the formula for I (z)
I (z)
≡
Z 2π
0
e(z−1)(ln r+iθ)
ereiθ −1
ireiθdθ +
Z ∞
r
e(z−1)(ln t+2πi)
et −1
dt (29.27)
+
Z r
∞
e(z−1) ln t
et −1 dt
Thus I (1) is given by
I (1) ≡
Z 2π
0
1
ereiθ −1ireiθdθ +
Z ∞
r
1
et −1dt +
Z r
∞
1
et −1dt
=
R
γr
dw
ew−1 where γr is the circle of radius r. This contour integral equals 2πi
by the residue theorem. Therefore,
I (z)
(e2πiz −1) Γ (z) =
1
z −1 + h (z)
where h (z) is an entire function. People worry a lot about where the zeros of
ζ are located. In particular, the zeros for Re z ∈(0, 1) are of special interest.
The Riemann hypothesis says they are all on the line Re z = 1/2. This is a
good problem for you to do next.
25. There is an important relation between prime numbers and the zeta function
due to Euler. Let {pn}∞
n=1 be the prime numbers. Then for Re z > 1,
∞
Y
n=1
1
1 −p−z
n
= ζ (z) .
To see this, consider a partial product.
N
Y
n=1
1
1 −p−z
n
=
N
Y
n=1
∞
X
jn=1
µ 1
pzn
¶jn
.
Let SN denote all positive integers which use only p1, · · ·, pN in their prime
factorization. Then the above equals P
n∈SN
1
nz . Letting N →∞and using
the fact that Re z > 1 so that the order in which you sum is not important (See
Theorem 30.1 or recall advanced calculus. ) you obtain the desired equation.
Show P∞
n=1
1
pn = ∞.

818
INFINITE PRODUCTS

Elliptic Functions
This chapter is to give a short introduction to elliptic functions. There is much
more available. There are books written on elliptic functions. What I am presenting
here follows Alfors [2] although the material is found in many books on complex
analysis. Hille, [27] has a much more extensive treatment than what I will attempt
here. There are also many references and historical notes available in the book by
Hille. Another good source for more having much the same emphasis as what is
presented here is in the book by Saks and Zygmund [47]. This is a very interesting
subject because it has considerable overlap with algebra.
Before beginning, recall that an absolutely convergent series can be summed in
any order and you always get the same answer. The easy way to see this is to think
of the series as a Lebesgue integral with respect to counting measure and apply
convergence theorems as needed.
The following theorem provides the necessary
results.
Theorem 30.1 Suppose P∞
n=1 |an| < ∞and let θ, φ : N →N be one to one and
onto mappings. Then P∞
n=1 aφ(n) and P∞
n=1 aθ(n) both converge and the two sums
are equal.
Proof: By the monotone convergence theorem,
∞
X
n=1
|an| = lim
n→∞
n
X
k=1
¯¯aφ(k)
¯¯ = lim
n→∞
n
X
k=1
¯¯aθ(k)
¯¯
but these last two equal P∞
k=1
¯¯aφ(k)
¯¯ and P∞
k=1
¯¯aθ(k)
¯¯ respectively.
Therefore,
P∞
k=1 aθ(k) and P∞
k=1 aφ(k) exist (n →aθ(n) is in L1 with respect to counting
measure.)
It remains to show the two are equal.
There exists M such that if
n > M then
∞
X
k=n+1
¯¯aθ(k)
¯¯ < ε,
∞
X
k=n+1
¯¯aφ(k)
¯¯ < ε
¯¯¯¯¯
∞
X
k=1
aφ(k) −
n
X
k=1
aφ(k)
¯¯¯¯¯ < ε,
¯¯¯¯¯
∞
X
k=1
aθ(k) −
n
X
k=1
aθ(k)
¯¯¯¯¯ < ε
819

820
ELLIPTIC FUNCTIONS
Pick such an n denoted by n1. Then pick n2 > n1 > M such that
{θ (1) , · · ·, θ (n1)} ⊆{φ (1) , · · ·, φ (n2)} .
Then
n2
X
k=1
aφ(k) =
n1
X
k=1
aθ(k) +
X
φ(k)/∈{θ(1),···,θ(n1)}
aφ(k).
Therefore,
¯¯¯¯¯
n2
X
k=1
aφ(k) −
n1
X
k=1
aθ(k)
¯¯¯¯¯ =
¯¯¯¯¯¯
X
φ(k)/∈{θ(1),···,θ(n1)},k≤n2
aφ(k)
¯¯¯¯¯¯
Now all of these φ (k) in the last sum are contained in {θ (n1 + 1) , · · ·} and so the
last sum above is dominated by
≤
∞
X
k=n1+1
¯¯aθ(k)
¯¯ < ε.
Therefore,
¯¯¯¯¯
∞
X
k=1
aφ(k) −
∞
X
k=1
aθ(k)
¯¯¯¯¯
≤
¯¯¯¯¯
∞
X
k=1
aφ(k) −
n2
X
k=1
aφ(k)
¯¯¯¯¯
+
¯¯¯¯¯
n2
X
k=1
aφ(k) −
n1
X
k=1
aθ(k)
¯¯¯¯¯
+
¯¯¯¯¯
n1
X
k=1
aθ(k) −
∞
X
k=1
aθ(k)
¯¯¯¯¯
<
ε + ε + ε = 3ε
and since ε is arbitrary, it follows P∞
k=1 aφ(k) = P∞
k=1 aθ(k) as claimed. This proves
the theorem.
30.1
Periodic Functions
Deﬁnition 30.2 A function deﬁned on C is said to be periodic if there exists w
such that f (z + w) = f (z) for all z ∈C. Denote by M the set of all periods. Thus
if w1, w2 ∈M and a, b ∈Z, then aw1 + bw2 ∈M. For this reason M is called the
module of periods.1In all which follows it is assumed f is meromorphic.
Theorem 30.3 Let f be a meromorphic function and let M be the module of peri-
ods. Then if M has a limit point, then f equals a constant. If this does not happen
then either there exists w1 ∈M such that Zw1 = M or there exist w1, w2 ∈M such
that M = {aw1 + bw2 : a, b ∈Z} and w1/w2 is not real. Also if τ = w2/w1,
|τ| ≥1, −1
2 ≤Re τ ≤1
2.
1A module is like a vector space except instead of a ﬁeld of scalars, you have a ring of scalars.

30.1.
PERIODIC FUNCTIONS
821
Proof: Suppose f is meromorphic and M has a limit point, w0. By Theorem
29.10 on Page 794 there exist analytic functions, p, q such that f (z) = p(z)
q(z). Now
pick z0 such that z0 is not a pole of f. Then letting wn →w0 where {wn} ⊆M,
f (z0 + wn) = f (z0) . Therefore, p (z0 + wn) = f (z0) q (z0 + wn) and so the analytic
function, p (z) −f (z0) q (z) has a zero set which has a limit point. Therefore, this
function is identically equal to zero because of Theorem 24.23 on Page 657. Thus
f equals a constant as claimed.
This has shown that if f is not constant, then M is discreet. Therefore, there
exists w1 ∈M such that |w1| = min {|w| : w ∈M}. Suppose ﬁrst that every element
of M is a real multiple of w1. Thus, if w ∈M, it follows there exists a real number,
x such that w = xw1. Then there exist positive integers, k, k + 1 such that k ≤x <
k +1. If x > k, then w −kw1 = (x −k) w1 is a period having smaller absolute value
than |w1| which would be a contradiction. Hence, x = k and so M = Zw1.
Now suppose there exists w2 ∈M which is not a real multiple of w1.
You
can let w2 be the element of M having this property which has smallest absolute
value. Now let w ∈M. Since w1 and w2 point in diﬀerent directions, it follows
w = xw1 +yw2 for some real numbers, x, y. Let |m −x| ≤1
2 and |n −y| ≤1
2 where
m, n are integers. Therefore,
w = mw1 + nw2 + (x −m) w1 + (y −n) w2
and so
w −mw1 −nw2 = (x −m) w1 + (y −n) w2
(30.1)
Now since w2/w1 /∈R,
|(x −m) w1 + (y −n) w2|
<
|(x −m) w1| + |(y −n) w2|
=
1
2 |w1| + 1
2 |w2| .
Therefore, from 30.1,
|w −mw1 −nw2|
=
|(x −m) w1 + (y −n) w2|
<
1
2 |w1| + 1
2 |w2| ≤|w2|
and so the period, w −mw1 −nw2 cannot be a non real multiple of w1 because w2
is the one which has smallest absolute value and this period has smaller absolute
value than w2. Therefore, the ratio w −mw1 −nw2/w1 must be a real number, x.
Thus
w −mw1 −nw2 = xw1
Since w1 has minimal absolute value of all periods, it follows |x| ≥1. Let k ≤x <
k + 1 for some integer, k. If x > k, then
w −mw1 −nw2 −kw1 = (x −k) w1
which would contradict the choice of w1 as being the period having minimal absolute
value because the expression on the left in the above is a period and it equals

822
ELLIPTIC FUNCTIONS
something which has absolute value less than |w1|. Therefore, x = k and w is an
integer linear combination of w1 and w2. It only remains to verify the claim about
τ.
From the construction, |w1| ≤|w2| and |w2| ≤|w1 −w2| , |w2| ≤|w1 + w2| .
Therefore,
|τ| ≥1, |τ| ≤|1 −τ| , |τ| ≤|1 + τ| .
The last two of these inequalities imply −1/2 ≤Re τ ≤1/2.
This proves the theorem.
Deﬁnition 30.4 For f a meromorphic function which has the last of the above
alternatives holding in which M = {aw1 + bw2 : a, b ∈Z} , the function, f is called
elliptic. This is also called doubly periodic.
Theorem 30.5 Suppose f is an elliptic function which has no poles. Then f is
constant.
Proof: Since f has no poles it is analytic. Now consider the parallelograms
determined by the vertices, mw1 +nw2 for m, n ∈Z. By periodicity of f it must be
bounded because its values are identical on each of these parallelograms. Therefore,
it equals a constant by Liouville’s theorem.
Deﬁnition 30.6 Deﬁne Pa to be the parallelogram determined by the points
a + mw1 + nw2, a + (m + 1) w1 + nw2, a + mw1 + (n + 1) w2,
a + (m + 1) w1 + (n + 1) w2
Such Pa will be referred to as a period parallelogram. The sum of the orders of
the poles in a period parallelogram which contains no poles or zeros of f on its
boundary is called the order of the function. This is well deﬁned because of the
periodic property of f.
Theorem 30.7 The sum of the residues of any elliptic function, f equals zero on
every Pa if a is chosen so that there are no poles on ∂Pa.
Proof: Choose a such that there are no poles of f on the boundary of Pa. By
periodicity,
Z
∂Pa
f (z) dz = 0
because the integrals over opposite sides of the parallelogram cancel out because
the values of f are the same on these sides and the orientations are opposite. It
follows from the residue theorem that the sum of the residues in Pa equals 0.
Theorem 30.8 Let Pa be a period parallelogram for a nonconstant elliptic function,
f which has order equal to m. Then f assumes every value in f (Pa) exactly m
times.

30.1.
PERIODIC FUNCTIONS
823
Proof: Let c ∈f (Pa) and consider Pa′ such that f −1 (c) ∩Pa′ = f −1 (c) ∩Pa
and Pa′ contains the same poles and zeros of f −c as Pa but Pa′ has no zeros of
f (z) −c or poles of f on its boundary. Thus f ′ (z) / (f (z) −c) is also an elliptic
function and so Theorem 30.7 applies. Consider
1
2πi
Z
∂Pa′
f ′ (z)
f (z) −cdz.
By the argument principle, this equals Nz−Np where Nz equals the number of zeros
of f (z)−c and Np equals the number of the poles of f (z). From Theorem 30.7 this
must equal zero because it is the sum of the residues of f ′/ (f −c) and so Nz = Np.
Now Np equals the number of poles in Pa counted according to multiplicity.
There is an even better theorem than this one.
Theorem 30.9 Let f be a non constant elliptic function and suppose it has poles
p1, · · ·, pm and zeros, z1, · · ·, zm in Pα, listed according to multiplicity where ∂Pα
contains no poles or zeros of f. Then Pm
k=1 zk −Pm
k=1 pk ∈M, the module of
periods.
Proof: You can assume ∂Pa contains no poles or zeros of f because if it did,
then you could consider a slightly shifted period parallelogram, Pa′ which contains
no new zeros and poles but which has all the old ones but no poles or zeros on its
boundary. By Theorem 26.8 on Page 710
1
2πi
Z
∂Pa
z f ′ (z)
f (z) dz =
m
X
k=1
zk −
m
X
k=1
pk.
(30.2)
Denoting by γ (z, w) the straight oriented line segment from z to w,
Z
∂Pa
z f ′ (z)
f (z) dz
=
Z
γ(a,a+w1)
z f ′ (z)
f (z) dz +
Z
γ(a+w1+w2,a+w2)
z f ′ (z)
f (z) dz
+
Z
γ(a+w1,a+w2+w1)
z f ′ (z)
f (z) dz +
Z
γ(a+w2,a)
z f ′ (z)
f (z) dz
=
Z
γ(a,a+w1)
(z −(z + w2)) f ′ (z)
f (z) dz
+
Z
γ(a,a+w2)
(z −(z + w1)) f ′ (z)
f (z) dz
Now near these line segments f ′(z)
f(z) is analytic and so there exists a primitive, gwi (z)
on γ (a, a + wi) by Corollary 24.32 on Page 663 which satisﬁes egwi(z) = f (z).
Therefore,
= −w2 (gw1 (a + w1) −gw1 (a)) −w1 (gw2 (a + w2) −gw2 (a)) .

824
ELLIPTIC FUNCTIONS
Now by periodicity of f it follows f (a + w1) = f (a) = f (a + w2) . Hence
gwi (a + w1) −gwi (a) = 2mπi
for some integer, m because
egwi(a+wi) −egwi(a) = f (a + wi) −f (a) = 0.
Therefore, from 30.2, there exist integers, k, l such that
1
2πi
Z
∂Pa
z f ′ (z)
f (z) dz
=
1
2πi [−w2 (gw1 (a + w1) −gw1 (a)) −w1 (gw2 (a + w2) −gw2 (a))]
=
1
2πi [−w2 (2kπi) −w1 (2lπi)]
=
−w2k −w1l ∈M.
From 30.2 it follows
m
X
k=1
zk −
m
X
k=1
pk ∈M.
This proves the theorem.
Hille says this relation is due to Liouville. There is also a simple corollary which
follows from the above theorem applied to the elliptic function, f (z) −c.
Corollary 30.10 Let f be a non constant elliptic function and suppose the func-
tion, f (z) −c has poles p1, · · ·, pm and zeros, z1, · · ·, zm on Pα, listed according to
multiplicity where ∂Pα contains no poles or zeros of f (z) −c. Then Pm
k=1 zk −
Pm
k=1 pk ∈M, the module of periods.
30.1.1
The Unimodular Transformations
Deﬁnition 30.11 Suppose f is a nonconstant elliptic function and the module of
periods is of the form {aw1 + bw2} where a, b are integers and w1/w2 is not real.
Then by analogy with linear algebra, {w1, w2} is referred to as a basis. The uni-
modular transformations will refer to matrices of the form
µ
a
b
c
d
¶
where all entries are integers and
ad −bc = ±1.
These linear transformations are also called the modular group.
The following is an interesting lemma which ties matrices with the fractional
linear transformations.

30.1.
PERIODIC FUNCTIONS
825
Lemma 30.12 Deﬁne
φ
µµ
a
b
c
d
¶¶
≡az + b
cz + d.
Then
φ (AB) = φ (A) ◦φ (B) ,
(30.3)
φ (A) (z) = z if and only if
A = cI
where I is the identity matrix and c ̸= 0. Also if f (z) = az+b
cz+d, then f −1 (z) exists
if and only if ad −cb ̸= 0. Furthermore it is easy to ﬁnd f −1.
Proof: The equation in 30.3 is just a simple computation. Now suppose φ (A) (z) =
z. Then letting A =
µ
a
b
c
d
¶
, this requires
az + b = z (cz + d)
and so az + b = cz2 + dz. Since this is to hold for all z it follows c = 0 = b and
a = d. The other direction is obvious.
Consider the claim about the existence of an inverse.
Let ad −cb ̸= 0 for
f (z) = az+b
cz+d. Then
f (z) = φ
µµ
a
b
c
d
¶¶
It follows
µ a
b
c
d
¶−1
exists and equals
1
ad−bc
µ
d
−b
−c
a
¶
. Therefore,
z
=
φ (I) (z) = φ
µµ a
b
c
d
¶ µ
1
ad −bc
µ
d
−b
−c
a
¶¶¶
(z)
=
φ
µµ
a
b
c
d
¶¶
◦φ
µµ
1
ad −bc
µ
d
−b
−c
a
¶¶¶
(z)
=
f ◦f −1 (z)
which shows f −1 exists and it is easy to ﬁnd.
Next suppose f −1 exists. I need to verify the condition ad −cb ̸= 0. If f −1
exists, then from the process used to ﬁnd it, you see that it must be a fractional
linear transformation. Letting A =
µ
a
b
c
d
¶
so φ (A) = f, it follows there exists
a matrix B such that
φ (BA) (z) = φ (B) ◦φ (A) (z) = z.
However, it was shown that this implies BA is a nonzero multiple of I which requires
that A−1 must exist. Hence the condition must hold.

826
ELLIPTIC FUNCTIONS
Theorem 30.13 If f is a nonconstant elliptic function with a basis {w1, w2} for
the module of periods, then {w′
1, w′
2} is another basis, if and only if there exists a
unimodular transformation,
µ
a
b
c
d
¶
= A such that
µ
w′
1
w′
2
¶
=
µ
a
b
c
d
¶ µ
w1
w2
¶
.
(30.4)
Proof: Since {w1, w2} is a basis, there exist integers, a, b, c, d such that 30.4
holds. It remains to show the transformation determined by the matrix is unimod-
ular. Taking conjugates,
µ
w′
1
w′
2
¶
=
µ
a
b
c
d
¶ µ
w1
w2
¶
.
Therefore,
µ w′
1
w′
1
w′
2
w′
2
¶
=
µ a
b
c
d
¶ µ w1
w1
w2
w2
¶
Now since {w′
1, w′
2} is also given to be a basis, there exits another matrix having
all integer entries,
µ
e
f
g
h
¶
such that
µ
w1
w2
¶
=
µ
e
f
g
h
¶ µ
w′
1
w′
2
¶
and
µ
w1
w2
¶
=
µ
e
f
g
h
¶ µ
w′
1
w′
2
¶
.
Therefore,
µ
w′
1
w′
1
w′
2
w′
2
¶
=
µ
a
b
c
d
¶ µ
e
f
g
h
¶ µ
w′
1
w′
1
w′
2
w′
2
¶
.
However, since w′
1/w′
2 is not real, it is routine to verify that
det
µ w′
1
w′
1
w′
2
w′
2
¶
̸= 0.
Therefore,
µ
1
0
0
1
¶
=
µ
a
b
c
d
¶ µ
e
f
g
h
¶
and so det
µ
a
b
c
d
¶
det
µ
e
f
g
h
¶
= 1. But the two matrices have all integer
entries and so both determinants must equal either 1 or −1.
Next suppose
µ
w′
1
w′
2
¶
=
µ
a
b
c
d
¶ µ
w1
w2
¶
(30.5)

30.1.
PERIODIC FUNCTIONS
827
where
µ a
b
c
d
¶
is unimodular. I need to verify that {w′
1, w′
2} is a basis. If w ∈M,
there exist integers, m, n such that
w = mw1 + nw2 =
¡
m
n
¢ µ
w1
w2
¶
From 30.5
±
µ
d
−b
−c
a
¶ µ w′
1
w′
2
¶
=
µ w1
w2
¶
and so
w = ±
¡
m
n
¢ µ
d
−b
−c
a
¶ µ w′
1
w′
2
¶
which is an integer linear combination of {w′
1, w′
2} . It only remains to verify that
w′
1/w′
2 is not real.
Claim: Let w1 and w2 be nonzero complex numbers. Then w2/w1 is not real
if and only if
w1w2 −w1w2 = det
µ
w1
w1
w2
w2
¶
̸= 0
Proof of the claim: Let λ = w2/w1. Then
w1w2 −w1w2 = λw1w1 −w1λw1 =
¡
λ −λ
¢
|w1|2
Thus the ratio is not real if and only if
¡
λ −λ
¢
̸= 0 if and only if w1w2 −w1w2 ̸= 0.
Now to verify w′
2/w′
1 is not real,
det
µ
w′
1
w′
1
w′
2
w′
2
¶
=
det
µµ
a
b
c
d
¶ µ
w1
w1
w2
w2
¶¶
=
± det
µ
w1
w1
w2
w2
¶
̸= 0
This proves the theorem.
30.1.2
The Search For An Elliptic Function
By Theorem 30.5 and 30.7 if you want to ﬁnd a nonconstant elliptic function it must
fail to be analytic and also have either no terms in its Laurent expansion which are
of the form b1 (z −a)−1 or else these terms must cancel out. It is simplest to look
for a function which simply does not have them. Weierstrass looked for a function
of the form
℘(z) ≡1
z2 +
X
w̸=0
Ã
1
(z −w)2 −1
w2
!
(30.6)

828
ELLIPTIC FUNCTIONS
where w consists of all numbers of the form aw1 + bw2 for a, b integers. Sometimes
people write this as ℘(z, w1, w2) to emphasize its dependence on the periods, w1
and w2 but I won’t do so. It is understood there exist these periods, which are
given. This is a reasonable thing to try. Suppose you formally diﬀerentiate the
right side. Never mind whether this is justiﬁed for now. This yields
℘′ (z) = −2
z3 −
X
w̸=0
−2
(z −w)3 =
X
w
−2
(z −w)3
which is clearly periodic having both periods w1 and w2. Therefore, ℘(z + w1) −
℘(z) and ℘(z + w2) −℘(z) are both constants, c1 and c2 respectively. The reason
for this is that since ℘′ is periodic with periods w1 and w2, it follows ℘′ (z + wi) −
℘′ (z) = 0 as long as z is not a period. From 30.6 you can see right away that
℘(z) = ℘(−z)
Indeed
℘(−z)
=
1
z2 +
X
w̸=0
Ã
1
(−z −w)2 −1
w2
!
=
1
z2 +
X
w̸=0
Ã
1
(−z + w)2 −1
w2
!
= ℘(z) .
and so
c1
=
℘
³
−w1
2 + w1
´
−℘
³
−w1
2
´
=
℘
³w1
2
´
−℘
³
−w1
2
´
= 0
which shows the constant for ℘(z + w1) −℘(z) must equal zero.
Similarly the
constant for ℘(z + w2) −℘(z) also equals zero. Thus ℘is periodic having the two
periods w1, w2.
Of course to justify this, you need to consider whether the series of 30.6 con-
verges. Consider the terms of the series.
¯¯¯¯¯
1
(z −w)2 −1
w2
¯¯¯¯¯ = |z|
¯¯¯¯¯
2w −z
(z −w)2 w2
¯¯¯¯¯
If |w| > 2 |z| , this can be estimated more. For such w,
¯¯¯¯¯
1
(z −w)2 −1
w2
¯¯¯¯¯
=
|z|
¯¯¯¯¯
2w −z
(z −w)2 w2
¯¯¯¯¯ ≤|z|
(5/2) |w|
|w|2 (|w| −|z|)2
≤
|z|
(5/2) |w|
|w|2 ((1/2) |w|)2 = |z| 10
|w|3 .

30.1.
PERIODIC FUNCTIONS
829
It follows the series in 30.6 converges uniformly and absolutely on every compact
set, K provided P
w̸=0
1
|w|3 converges. This question is considered next.
Claim: There exists a positive number, k such that for all pairs of integers,
m, n, not both equal to zero,
|mw1 + nw2|
|m| + |n|
≥k > 0.
Proof of claim: If not, there exists mk and nk such that
lim
k→∞
mk
|mk| + |nk|w1 +
nk
|mk| + |nk|w2 = 0
However,
³
mk
|mk|+|nk|,
nk
|mk|+|nk|
´
is a bounded sequence in R2 and so, taking a sub-
sequence, still denoted by k, you can have
µ
mk
|mk| + |nk|,
nk
|mk| + |nk|
¶
→(x, y) ∈R2
and so there are real numbers, x, y such that xw1 + yw2 = 0 contrary to the
assumption that w2/w1 is not equal to a real number. This proves the claim.
Now from the claim,
X
w̸=0
1
|w|3
=
X
(m,n)̸=(0,0)
1
|mw1 + nw2|3 ≤
X
(m,n)̸=(0,0)
1
k3 (|m| + |n|)3
=
1
k3
∞
X
j=1
X
|m|+|n|=j
1
(|m| + |n|)3 = 1
k3
∞
X
j=1
4j
j3 < ∞.
Now consider the series in 30.6. Letting z ∈B (0, R) ,
℘(z)
≡
1
z2 +
X
w̸=0,|w|≤R
Ã
1
(z −w)2 −1
w2
!
+
X
w̸=0,|w|>R
Ã
1
(z −w)2 −1
w2
!
and the last series converges uniformly on B (0, R) to an analytic function. Thus ℘is
a meromorphic function and also the argument given above involving diﬀerentiation
of the series termwise is valid. Thus ℘is an elliptic function as claimed. This is
called the Weierstrass ℘function. This has proved the following theorem.
Theorem 30.14 The function ℘deﬁned above is an example of an elliptic function.
On any compact set, ℘equals a rational function added to a series which is uniformly
and absolutely convergent on the compact set.

830
ELLIPTIC FUNCTIONS
30.1.3
The Diﬀerential Equation Satisﬁed By ℘
For z not a pole,
℘′ (z) = −2
z3 −
X
w̸=0
2
(z −w)3
Also since there are no poles of order 1 you can obtain a primitive for ℘, −ζ.2
To do so, recall
℘(z) ≡1
z2 +
X
w̸=0
Ã
1
(z −w)2 −1
w2
!
where for |z| < R this is the sum of a rational function with a uniformly convergent
series. Therefore, you can take the integral along any path, γ (0, z) from 0 to z
which misses the poles of ℘. By the uniform convergence of the above integral, you
can interchange the sum with the integral and obtain
ζ (z) = 1
z +
X
w̸=0
1
z −w + z
w2 + 1
w
(30.7)
This function is odd. Here is why.
ζ (−z) = 1
−z +
X
w̸=0
1
−z −w −z
w2 + 1
w
while
−ζ (z)
=
1
−z +
X
w̸=0
−1
z −w −z
w2 −1
w
=
1
−z +
X
w̸=0
−1
z + w −z
w2 + 1
w.
Now consider 30.7. It will be used to ﬁnd the Laurent expansion about the origin
for ζ which will then be diﬀerentiated to obtain the Laurent expansion for ℘at the
origin. Since w ̸= 0 and the interest is for z near 0 so |z| < |w| ,
1
z −w + z
w2 + 1
w
=
z
w2 + 1
w −1
w
1
1 −z
w
=
z
w2 + 1
w −1
w
∞
X
k=0
³ z
w
´k
=
−1
w
∞
X
k=2
³ z
w
´k
2I don’t know why it is traditional to refer to this antiderivative as −ζ rather than ζ but I
am following the convention.
I think it is to minimize the number of minus signs in the next
expression.

30.1.
PERIODIC FUNCTIONS
831
From 30.7
ζ (z)
=
1
z +
X
w̸=0
Ã
−
∞
X
k=2
zk
wk+1
!
=
1
z −
∞
X
k=2
X
w̸=0
zk
wk+1 = 1
z −
∞
X
k=2
X
w̸=0
z2k−1
w2k
because the sum over odd powers must be zero because for each w ̸= 0, there exists
−w ̸= 0 such that the two terms
z2k
w2k+1 and
z2k
(−w)2k+1 cancel each other. Hence
ζ (z) = 1
z −
∞
X
k=2
Gkz2k−1
where Gk = P
w̸=0
1
w2k . Now with this,
−ζ′ (z)
=
℘(z) = 1
z2 +
∞
X
k=2
Gk (2k −1) z2k−2
=
1
z2 + 3G2z2 + 5G3z4 + · · ·
Therefore,
℘′ (z) = −2
z3 + 6G2z + 20G3z3 + · · ·
℘′ (z)2
=
4
z6 −24G2
z2
−80G3 + · · ·
4℘(z)3
=
4
µ 1
z2 + 3G2z2 + 5G3z4 · ··
¶3
=
4
z6 + 36
z2 G2 + 60G3 + · · ·
and ﬁnally
60G2℘(z) = 60G2
z2
+ 0 + · · ·
where in the above, the positive powers of z are not listed explicitly. Therefore,
℘′ (z)2 −4℘(z)3 + 60G2℘(z) + 140G3 =
∞
X
n=1
anzn
In deriving the equation it was assumed |z| < |w| for all w = aw1+bw2 where a, b are
integers not both zero. The left side of the above equation is periodic with respect
to w1 and w2 where w2/w1 is not a real number. The only possible poles of the
left side are at 0, w1, w2, and w1 +w2, the vertices of the parallelogram determined
by w1 and w2. This follows from the original formula for ℘(z) . However, the above

832
ELLIPTIC FUNCTIONS
equation shows the left side has no pole at 0. Since the left side is periodic with
periods w1 and w2, it follows it has no pole at the other vertices of this parallelogram
either. Therefore, the left side is periodic and has no poles. Consequently, it equals
a constant by Theorem 30.5. But the right side of the above equation shows this
constant is 0 because this side equals zero when z = 0. Therefore, ℘satisﬁes the
diﬀerential equation,
℘′ (z)2 −4℘(z)3 + 60G2℘(z) + 140G3 = 0.
It is traditional to deﬁne 60G2 ≡g2 and 140G3 ≡g3. Then in terms of these new
quantities the diﬀerential equation is
℘′ (z)2 = 4℘(z)3 −g2℘(z) −g3.
Suppose e1, e2 and e3 are zeros of the polynomial 4w3 −g2w −g3 = 0. Then the
above equation can be written in the form
℘′ (z)2 = 4 (℘(z) −e1) (℘(z) −e2) (℘(z) −e3) .
(30.8)
30.1.4
A Modular Function
The next task is to ﬁnd the ei in 30.8. First recall that ℘is an even function. That
is ℘(−z) = ℘(z). This follows from 30.6 which is listed here for convenience.
℘(z) ≡1
z2 +
X
w̸=0
Ã
1
(z −w)2 −1
w2
!
(30.9)
Thus
℘(−z)
=
1
z2 +
X
w̸=0
Ã
1
(−z −w)2 −1
w2
!
=
1
z2 +
X
w̸=0
Ã
1
(−z + w)2 −1
w2
!
= ℘(z) .
Therefore, ℘(w1 −z) = ℘(z −w1) = ℘(z) and so −℘′ (w1 −z) = ℘′ (z) . Letting
z = w1/2, it follows ℘′ (w1/2) = 0. Similarly, ℘′ (w2/2) = 0 and ℘′ ((w1 + w2) /2) =
0. Therefore, from 30.8
0 = 4 (℘(w1/2) −e1) (℘(w1/2) −e2) (℘(w1/2) −e3) .
It follows one of the ei must equal ℘(w1/2) . Similarly, one of the ei must equal
℘(w2/2) and one must equal ℘((w1 + w2) /2).
Lemma 30.15
The numbers, ℘(w1/2) , ℘(w2/2) , and ℘((w1 + w2) /2) are dis-
tinct.

30.1.
PERIODIC FUNCTIONS
833
Proof: Choose Pa, a period parallelogram which contains the pole 0, and the
points w1/2, w2/2, and (w1 + w2) /2 but no other pole of ℘(z) . Also ∂P ∗
a does not
contain any zeros of the elliptic function, z →℘(z) −℘(w1/2). This can be done
by shifting P0 slightly because the poles are only at the points aw1 + bw2 for a, b
integers and the zeros of ℘(z) −℘(w1/2) are discreet.
0
s
w1
w2s
s
s
w1 + w2


£
£
£
£
£
£
££


£
£
£
£
£
£
££
a s

£
£
£
£
£
£
£
£


£
£
£
£
£
£
£
£
If ℘(w2/2) = ℘(w1/2) , then ℘(z)−℘(w1/2) has two zeros, w2/2 and w1/2 and
since the pole at 0 is of order 2, this is the order of ℘(z) −℘(w1/2) on Pa hence by
Theorem 30.8 on Page 822 these are the only zeros of this function on Pa. It follows
by Corollary 30.10 on Page 824 which says the sum of the zeros minus the sum of
the poles is in M, w1
2 + w2
2 ∈M. Thus there exist integers, a, b such that
w1 + w2
2
= aw1 + bw2
which implies (2a −1) w1 + (2b −1) w2 = 0 contradicting w2/w1 not being real.
Similar reasoning applies to the other pairs of points in {w1/2, w2/2, (w1 + w2) /2} .
For example, consider (w1 + w2) /2 and choose Pa such that its boundary contains
no zeros of the elliptic function, z →℘(z) −℘((w1 + w2) /2) and Pa contains no
poles of ℘on its interior other than 0. Then if ℘(w2/2) = ℘((w1 + w2) /2) , it
follows from Theorem 30.8 on Page 822 w2/2 and (w1 + w2) /2 are the only two
zeros of ℘(z) −℘((w1 + w2) /2) on Pa and by Corollary 30.10 on Page 824
w1 + w1 + w2
2
= aw1 + bw2 ∈M
for some integers a, b which leads to the same contradiction as before about w1/w2
not being real. The other cases are similar. This proves the lemma.
Lemma 30.15 proves the ei are distinct. Number the ei such that
e1 = ℘(w1/2) , e2 = ℘(w2/2)
and
e3 = ℘((w1 + w2) /2) .
To summarize, it has been shown that for complex numbers, w1 and w2 with
w2/w1 not real, an elliptic function, ℘has been deﬁned. Denote this function as

834
ELLIPTIC FUNCTIONS
℘(z) = ℘(z, w1, w2) . This in turn determined numbers, ei as described above. Thus
these numbers depend on w1 and w2 and as described above,
e1 (w1, w2)
=
℘
³w1
2 , w1, w2
´
, e2 (w1, w2) = ℘
³w2
2 , w1, w2
´
e3 (w1, w2)
=
℘
µw1 + w2
2
, w1, w2
¶
.
Therefore, using the formula for ℘, 30.9,
℘(z) ≡1
z2 +
X
w̸=0
Ã
1
(z −w)2 −1
w2
!
you see that if the two periods w1 and w2 are replaced with tw1 and tw2 respectively,
then
ei (tw1, tw2) = t−2ei (w1, w2) .
Let τ denote the complex number which equals the ratio, w2/w1 which was assumed
in all this to not be real. Then
ei (w1, w2) = w−2
1 ei (1, τ)
Now deﬁne the function, λ (τ)
λ (τ) ≡e3 (1, τ) −e2 (1, τ)
e1 (1, τ) −e2 (1, τ)
µ
= e3 (w1, w2) −e2 (w1, w2)
e1 (w1, w2) −e2 (w1, w2)
¶
.
(30.10)
This function is meromorphic for Im τ > 0 or for Im τ < 0. However, since the
denominator is never equal to zero the function must actually be analytic on both
the upper half plane and the lower half plane. It never is equal to 0 because e3 ̸= e2
and it never equals 1 because e3 ̸= e1. This is stated as an observation.
Observation 30.16 The function, λ (τ) is analytic for τ in the upper half plane
and never assumes the values 0 and 1.
This is a very interesting function. Consider what happens when
µ
w′
1
w′
2
¶
=
µ
a
b
c
d
¶ µ
w1
w2
¶
and the matrix is unimodular. By Theorem 30.13 on Page 826 {w′
1, w′
2} is just an-
other basis for the same module of periods. Therefore, ℘(z, w1, w2) = ℘(z, w′
1, w′
2)
because both are deﬁned as sums over the same values of w, just in diﬀerent order
which does not matter because of the absolute convergence of the sums on compact
subsets of C. Since ℘is unchanged, it follows ℘′ (z) is also unchanged and so the
numbers, ei are also the same. However, they might be permuted in which case
the function λ (τ) deﬁned above would change. What would it take for λ (τ) to
not change? In other words, for which unimodular transformations will λ be left

30.1.
PERIODIC FUNCTIONS
835
unchanged? This happens if and only if no permuting takes place for the ei. This
occurs if ℘
¡ w1
2
¢
= ℘
³
w′
1
2
´
and ℘
¡ w2
2
¢
= ℘
³
w′
2
2
´
. If
w′
1
2 −w1
2 ∈M, w′
2
2 −w2
2 ∈M
then ℘
¡ w1
2
¢
= ℘
³
w′
1
2
´
and so e1 will be unchanged and similarly for e2 and e3.
This occurs exactly when
1
2 ((a −1) w1 + bw2) ∈M, 1
2 (cw1 + (d −1) w2) ∈M.
This happens if a and d are odd and if b and c are even. Of course the stylish way
to say this is
a ≡1 mod 2, d ≡1 mod 2, b ≡0 mod 2, c ≡0 mod 2.
(30.11)
This has shown that for unimodular transformations satisfying 30.11 λ is unchanged.
Letting τ be deﬁned as above,
τ ′ = w′
2
w′
1
≡cw1 + dw2
aw1 + bw2
= c + dτ
a + bτ .
Thus for unimodular transformations,
µ
a
b
c
d
¶
satisfying 30.11, or more suc-
cinctly,
µ
a
b
c
d
¶
∼
µ
1
0
0
1
¶
mod 2
(30.12)
it follows that
λ
µc + dτ
a + bτ
¶
= λ (τ) .
(30.13)
Furthermore, this is the only way this can happen.
Lemma 30.17 λ (τ) = λ (τ ′) if and only if
τ ′ = aτ + b
cτ + d
where 30.12 holds.
Proof: It only remains to verify that if ℘(w′
1/2) = ℘(w1/2) then it is necessary
that
w′
1
2 −w1
2 ∈M
with a similar requirement for w2 and w′
2. If w′
1
2 −w1
2 /∈M, then there exist integers,
m, n such that
−w′
1
2
+ mw1 + nw2

836
ELLIPTIC FUNCTIONS
is in the interior of P0, the period parallelogram whose vertices are 0, w1, w1 + w2,
and w2. Therefore, it is possible to choose small a such that Pa contains the pole,
0, w1
2 , and −w′
1
2
+ mw1 + nw2 but no other poles of ℘and in addition, ∂P ∗
a contains
no zeros of z →℘(z) −℘
¡ w1
2
¢
. Then the order of this elliptic function is 2. By
assumption, and the fact that ℘is even,
℘
µ−w′
1
2
+ mw1 + nw2
¶
= ℘
µ−w′
1
2
¶
= ℘
µw′
1
2
¶
= ℘
³w1
2
´
.
It follows both −w′
1
2
+ mw1 + nw2 and w1
2
are zeros of ℘(z) −℘
¡ w1
2
¢
and so by
Theorem 30.8 on Page 822 these are the only two zeros of this function in Pa.
Therefore, from Corollary 30.10 on Page 824
w1
2 −w′
1
2 + mw1 + nw2 ∈M
which shows w1
2 −w′
1
2 ∈M. This completes the proof of the lemma.
Note the condition in the lemma is equivalent to the condition 30.13 because
you can relabel the coeﬃcients. The message of either version is that the coeﬃcient
of τ in the numerator and denominator is odd while the constant in the numerator
and denominator is even.
Next,
µ
1
0
2
1
¶
∼
µ
1
0
0
1
¶
mod 2 and therefore,
λ
µ2 + τ
1
¶
= λ (τ + 2) = λ (τ) .
(30.14)
Thus λ is periodic of period 2.
Thus λ leaves invariant a certain subgroup of the unimodular group. According
to the next deﬁnition, λ is an example of something called a modular function.
Deﬁnition 30.18 When an analytic or meromorphic function is invariant under
a group of linear transformations, it is called an automorphic function. A function
which is automorphic with respect to a subgroup of the modular group is called a
modular function or an elliptic modular function.
Now consider what happens for some other unimodular matrices which are not
congruent to the identity mod 2. This will yield other functional equations for λ
in addition to the fact that λ is periodic of period 2. As before, these functional
equations come about because ℘is unchanged when you change the basis for M,
the module of periods. In particular, consider the unimodular matrices
µ 1
0
1
1
¶
,
µ 0
1
1
0
¶
.
(30.15)
Consider the ﬁrst of these. Thus
µ
w′
1
w′
2
¶
=
µ
w1
w1 + w2
¶

30.1.
PERIODIC FUNCTIONS
837
Hence τ ′ = w′
2/w′
1 = (w1 + w2) /w1 = 1 + τ. Then from the deﬁnition of λ,
λ (τ ′)
=
λ (1 + τ)
=
℘
³
w′
1+w′
2
2
´
−℘
³
w′
2
2
´
℘
³
w′
1
2
´
−℘
³
w′
2
2
´
=
℘
¡ w1+w2+w1
2
¢
−℘
¡ w1+w2
2
¢
℘
¡ w1
2
¢
−℘
¡ w1+w2
2
¢
=
℘
¡ w2
2 + w1
¢
−℘
¡ w1+w2
2
¢
℘
¡ w1
2
¢
−℘
¡ w1+w2
2
¢
=
℘
¡ w2
2
¢
−℘
¡ w1+w2
2
¢
℘
¡ w1
2
¢
−℘
¡ w1+w2
2
¢
=
−℘
¡ w1+w2
2
¢
−℘
¡ w2
2
¢
℘
¡ w1
2
¢
−℘
¡ w1+w2
2
¢
=
−
℘
¡ w1+w2
2
¢
−℘
¡ w2
2
¢
℘
¡ w1
2
¢
−℘
¡ w2
2
¢
+ ℘
¡ w2
2
¢
−℘
¡ w1+w2
2
¢
=
−
µ
℘(
w1+w2
2
)−℘(
w2
2 )
℘(
w1
2 )−℘(
w2
2 )
¶
1 +
µ
℘(
w2
2 )−℘(
w1+w2
2
)
℘(
w1
2 )−℘(
w2
2 )
¶
=
µ
℘(
w1+w2
2
)−℘(
w2
2 )
℘(
w1
2 )−℘(
w2
2 )
¶
µ
℘(
w1+w2
2
)−℘(
w2
2 )
℘(
w1
2 )−℘(
w2
2 )
¶
−1
=
λ (τ)
λ (τ) −1.
(30.16)
Summarizing the important feature of the above,
λ (1 + τ) =
λ (τ)
λ (τ) −1.
(30.17)

838
ELLIPTIC FUNCTIONS
Next consider the other unimodular matrix in 30.15. In this case w′
1 = w2 and
w′
2 = w1. Therefore, τ ′ = w′
2/w′
1 = w1/w2 = 1/τ. Then
λ (τ ′)
=
λ (1/τ)
=
℘
³
w′
1+w′
2
2
´
−℘
³
w′
2
2
´
℘
³
w′
1
2
´
−℘
³
w′
2
2
´
=
℘
¡ w1+w2
2
¢
−℘
¡ w1
2
¢
℘
¡ w2
2
¢
−℘
¡ w1
2
¢
=
e3 −e1
e2 −e1
= −e3 −e2 + e2 −e1
e1 −e2
=
−(λ (τ) −1) = −λ (τ) + 1.
(30.18)
You could try other unimodular matrices and attempt to ﬁnd other functional
equations if you like but this much will suﬃce here.
30.1.5
A Formula For λ
Recall the formula of Mittag-Leﬄer for cot (πα) given in 29.15. For convenience,
here it is.
1
α +
∞
X
n=1
2α
α2 −n2 = π cot πα.
As explained in the derivation of this formula it can also be written as
∞
X
n=−∞
α
α2 −n2 = π cot πα.
Diﬀerentiating both sides yields
π2 csc2 (πα)
=
∞
X
n=−∞
α2 + n2
(α2 −n2)2
=
∞
X
n=−∞
(α + n)2 −2αn
(α + n)2 (α −n)2
=
∞
X
n=−∞
(α + n)2
(α + n)2 (α −n)2 −
=0
z
}|
{
∞
X
n=−∞
2αn
(α2 −n2)2
=
∞
X
n=−∞
1
(α −n)2 .
(30.19)
Now this formula can be used to obtain a formula for λ (τ) . As pointed out
above, λ depends only on the ratio w2/w1 and so it suﬃces to take w1 = 1 and

30.1.
PERIODIC FUNCTIONS
839
w2 = τ. Thus
λ (τ) = ℘
¡ 1+τ
2
¢
−℘
¡ τ
2
¢
℘
¡ 1
2
¢
−℘
¡ τ
2
¢ .
(30.20)
From the original formula for ℘,
℘
µ1 + τ
2
¶
−℘
³τ
2
´
=
1
¡ 1+τ
2
¢2 −
1
¡ τ
2
¢2 +
X
(k,m)̸=(0,0)
1
¡
k −1
2 +
¡
m −1
2
¢
τ
¢2 −
1
¡
k +
¡
m −1
2
¢
τ
¢2
=
X
(k,m)∈Z2
1
¡
k −1
2 +
¡
m −1
2
¢
τ
¢2 −
1
¡
k +
¡
m −1
2
¢
τ
¢2
=
X
(k,m)∈Z2
1
¡
k −1
2 +
¡
m −1
2
¢
τ
¢2 −
1
¡
k +
¡
m −1
2
¢
τ
¢2
=
X
(k,m)∈Z2
1
¡
k −1
2 +
¡
−m −1
2
¢
τ
¢2 −
1
¡
k +
¡
−m −1
2
¢
τ
¢2
=
X
(k,m)∈Z2
1
¡ 1
2 +
¡
m + 1
2
¢
τ −k
¢2 −
1
¡¡
m + 1
2
¢
τ −k
¢2 .
(30.21)
Similarly,
℘
µ1
2
¶
−℘
³τ
2
´
=
1
¡ 1
2
¢2 −
1
¡ τ
2
¢2 +
X
(k,m)̸=(0,0)
1
¡
k −1
2 + mτ
¢2 −
1
¡
k +
¡
m −1
2
¢
τ
¢2
=
X
(k,m)∈Z2
1
¡
k −1
2 + mτ
¢2 −
1
¡
k +
¡
m −1
2
¢
τ
¢2
=
X
(k,m)∈Z2
1
¡
k −1
2 −mτ
¢2 −
1
¡
k +
¡
−m −1
2
¢
τ
¢2
=
X
(k,m)∈Z2
1
¡ 1
2 + mτ −k
¢2 −
1
¡¡
m + 1
2
¢
τ −k
¢2 .
(30.22)
Now use 30.19 to sum these over k. This yields,
℘
µ1 + τ
2
¶
−℘
³τ
2
´
=
X
m
π2
sin2 ¡
π
¡ 1
2 +
¡
m + 1
2
¢
τ
¢¢ −
π2
sin2 ¡
π
¡
m + 1
2
¢
τ
¢
=
X
m
π2
cos2 ¡
π
¡
m + 1
2
¢
τ
¢ −
π2
sin2 ¡
π
¡
m + 1
2
¢
τ
¢

840
ELLIPTIC FUNCTIONS
and
℘
µ1
2
¶
−℘
³τ
2
´
=
X
m
π2
sin2 ¡
π
¡ 1
2 + mτ
¢¢ −
π2
sin2 ¡
π
¡
m + 1
2
¢
τ
¢
=
X
m
π2
cos2 (πmτ) −
π2
sin2 ¡
π
¡
m + 1
2
¢
τ
¢.
The following interesting formula for λ results.
λ (τ) =
P
m
1
cos2(π(m+ 1
2)τ) −
1
sin2(π(m+ 1
2)τ)
P
m
1
cos2(πmτ) −
1
sin2(π(m+ 1
2)τ)
.
(30.23)
From this it is obvious λ (−τ) = λ (τ) . Therefore, from 30.18,
−λ (τ) + 1 = λ
µ1
τ
¶
= λ
µ−1
τ
¶
(30.24)
(It is good to recall that λ has been deﬁned for τ /∈R.)
30.1.6
Mapping Properties Of λ
The two functional equations, 30.24 and 30.17 along with some other properties pre-
sented above are of fundamental importance. For convenience, they are summarized
here in the following lemma.
Lemma 30.19 The following functional equations hold for λ.
λ (1 + τ) =
λ (τ)
λ (τ) −1, 1 = λ (τ) + λ
µ−1
τ
¶
(30.25)
λ (τ + 2) = λ (τ) ,
(30.26)
λ (z) = λ (w) if and only if there exists a unimodular matrix,
µ
a
b
c
d
¶
∼
µ
1
0
0
1
¶
mod 2
such that
w = az + b
cz + d
(30.27)
Consider the following picture.
Ω
C
l2
l1
r
1
r
1
2

30.1.
PERIODIC FUNCTIONS
841
In this picture, l1 is the y axis and l2 is the line, x = 1 while C is the top half of
the circle centered at
¡ 1
2, 0
¢
which has radius 1/2. Note the above formula implies
λ has real values on l1 which are between 0 and 1. This is because 30.23 implies
λ (ib)
=
P
m
1
cos2(π(m+ 1
2)ib) −
1
sin2(π(m+ 1
2)ib)
P
m
1
cos2(πmib) −
1
sin2(π(m+ 1
2)ib)
=
P
m
1
cosh2(π(m+ 1
2)b) +
1
sinh2(π(m+ 1
2)b)
P
m
1
cosh2(πmb) +
1
sinh2(π(m+ 1
2)b)
∈(0, 1) .
(30.28)
This follows from the observation that
cos (ix) = cosh (x) , sin (ix) = i sinh (x) .
Thus it is clear from 30.28 that limb→0+ λ (ib) = 1.
Next I need to consider the behavior of λ (τ) as Im (τ) →∞. From 30.23 listed
here for convenience,
λ (τ) =
P
m
1
cos2(π(m+ 1
2)τ) −
1
sin2(π(m+ 1
2)τ)
P
m
1
cos2(πmτ) −
1
sin2(π(m+ 1
2)τ)
,
(30.29)
it follows
λ (τ)
=
1
cos2(π(−1
2)τ) −
1
sin2(π(−1
2)τ) +
1
cos2(π 1
2 τ) −
1
sin2(π 1
2 τ) + A (τ)
1 + B (τ)
=
2
cos2(π( 1
2)τ) −
2
sin2(π( 1
2)τ) + A (τ)
1 + B (τ)
(30.30)
Where A (τ) , B (τ) →0 as Im (τ) →∞. I took out the m = 0 term involving
1/ cos2 (πmτ) in the denominator and the m = −1 and m = 0 terms in the nu-
merator of 30.29. In fact, e−iπ(a+ib)A (a + ib) , e−iπ(a+ib)B (a + ib) converge to zero
uniformly in a as b →∞.
Lemma 30.20 For A, B deﬁned in 30.30, e−iπ(a+ib)C (a + ib) →0 uniformly in a
for C = A, B.
Proof: From 30.23,
e−iπτA (τ) =
X
m̸=0
m̸=−1
e−iπτ
cos2 ¡
π
¡
m + 1
2
¢
τ
¢ −
e−iπτ
sin2 ¡
π
¡
m + 1
2
¢
τ
¢
Now let τ = a + ib. Then letting αm = π
¡
m + 1
2
¢
,
cos (αma + iαmb)
=
cos (αma) cosh (αmb) −i sinh (αmb) sin (αma)
sin (αma + iαmb)
=
sin (αma) cosh (αmb) + i cos (αma) sinh (αmb)

842
ELLIPTIC FUNCTIONS
Therefore,
¯¯cos2 (αma + iαmb)
¯¯
=
cos2 (αma) cosh2 (αmb) + sinh2 (αmb) sin2 (αma)
≥
sinh2 (αmb) .
Similarly,
¯¯sin2 (αma + iαmb)
¯¯
=
sin2 (αma) cosh2 (αmb) + cos2 (αma) sinh2 (αmb)
≥
sinh2 (αmb) .
It follows that for τ = a + ib and b large
¯¯e−iπτA (τ)
¯¯
≤
X
m̸=0
m̸=−1
2eπb
sinh2 ¡
π
¡
m + 1
2
¢
b
¢
≤
∞
X
m=1
2eπb
sinh2 ¡
π
¡
m + 1
2
¢
b
¢ +
−2
X
m=−∞
2eπb
sinh2 ¡
π
¡
m + 1
2
¢
b
¢
=
2
∞
X
m=1
2eπb
sinh2 ¡
π
¡
m + 1
2
¢
b
¢ = 4
∞
X
m=1
eπb
sinh2 ¡
π
¡
m + 1
2
¢
b
¢
Now a short computation shows
eπb
sinh2(π(m+1+ 1
2)b)
eπb
sinh2(π(m+ 1
2)b)
= sinh2 ¡
π
¡
m + 1
2
¢
b
¢
sinh2 ¡
π
¡
m + 3
2
¢
b
¢ ≤
1
e3πb .
Therefore, for τ = a + ib,
¯¯e−iπτA (τ)
¯¯
≤
4
eπb
sinh
¡ 3πb
2
¢
∞
X
m=1
µ 1
e3πb
¶m
≤
4
eπb
sinh
¡ 3πb
2
¢
1/e3πb
1 −(1/e3πb)
which converges to zero as b →∞. Similar reasoning will establish the claim about
B (τ) . This proves the lemma.
Lemma 30.21 limb→∞λ (a + ib) e−iπ(a+ib) = 16 uniformly in a ∈R.
Proof: From 30.30 and Lemma 30.20, this lemma will be proved if it is shown
lim
b→∞
Ã
2
cos2 ¡
π
¡ 1
2
¢
(a + ib)
¢ −
2
sin2 ¡
π
¡ 1
2
¢
(a + ib)
¢
!
e−iπ(a+ib) = 16

30.1.
PERIODIC FUNCTIONS
843
uniformly in a ∈R. Let τ = a + ib to simplify the notation.
Then the above
expression equals
Ã
8
¡
ei π
2 τ + e−i π
2 τ¢2 +
8
¡
ei π
2 τ −e−i π
2 τ¢2
!
e−iπτ
=
Ã
8eiπτ
(eiπτ + 1)2 +
8eiπτ
(eiπτ −1)2
!
e−iπτ
=
8
(eiπτ + 1)2 +
8
(eiπτ −1)2
=
16 1 + e2πiτ
(1 −e2πiτ)2 .
Now
¯¯¯¯¯
1 + e2πiτ
(1 −e2πiτ)2 −1
¯¯¯¯¯
=
¯¯¯¯¯
1 + e2πiτ
(1 −e2πiτ)2 −
¡
1 −e2πiτ¢2
(1 −e2πiτ)2
¯¯¯¯¯
≤
¯¯3e2πiτ −e4πiτ¯¯
(1 −e−2πb)2
≤3e−2πb + e−4πb
(1 −e−2πb)2
and this estimate proves the lemma.
Corollary 30.22 limb→∞λ (a + ib) = 0 uniformly in a ∈R. Also λ (ib) for b > 0
is real and is between 0 and 1, λ is real on the line, l2 and on the curve, C and
limb→0+ λ (1 + ib) = −∞.
Proof: From Lemma 30.21,
¯¯¯λ (a + ib) e−iπ(a+ib) −16
¯¯¯ < 1
for all a provided b is large enough. Therefore, for such b,
|λ (a + ib)| ≤17e−πb.
30.28 proves the assertion about λ (−bi) real.
By the ﬁrst part, limb→∞|λ (ib)| = 0. Now from 30.24
lim
b→0+ λ (ib) = lim
b→0+
µ
1 −λ
µ−1
ib
¶¶
= lim
b→0+
µ
1 −λ
µ i
b
¶¶
= 1.
(30.31)
by Corollary 30.22.
Next consider the behavior of λ on line l2 in the above picture. From 30.17 and
30.28,
λ (1 + ib) =
λ (ib)
λ (ib) −1 < 0

844
ELLIPTIC FUNCTIONS
and so as b →0+ in the above, λ (1 + ib) →−∞.
It is left as an exercise to show that the map τ →1 −1
τ maps l2 onto the curve,
C. Therefore, by 30.25, for τ ∈l2,
λ
µ
1 −1
τ
¶
=
λ
¡ −1
τ
¢
λ
¡ −1
τ
¢
−1
(30.32)
=
1 −λ (τ)
(1 −λ (τ)) −1 = λ (τ) −1
λ (τ)
∈R
(30.33)
It follows λ is real on the boundary of Ωin the above picture. This proves the
corollary.
Now, following Alfors [2], cut oﬀΩby considering the horizontal line segment,
z = a + ib0 where b0 is very large and positive and a ∈[0, 1] . Also cut Ωoﬀ
by the images of this horizontal line, under the transformations z =
1
τ and z =
1−1
τ . These are arcs of circles because the two transformations are fractional linear
transformations. It is left as an exercise for you to verify these arcs are situated as
shown in the following picture. The important thing to notice is that for b0 large the
points of these circles are close to the origin and (1, 0) respectively. The following
picture is a summary of what has been obtained so far on the mapping by λ.
:
z
-
?
6

real small positive
near 1 and real
C2
C1
large, real, negative
small, real, negative
z = a + ib0
Ω
C
l2
l1
r
1
r
1
2
In the picture, the descriptions are of λ acting on points of the indicated bound-
ary of Ω. Consider the oriented contour which results from λ (z) as z moves ﬁrst up
l2 as indicated, then along the line z = a + ib and then down l1 and then along C1
to C and along C till C2 and then along C2 to l2. As indicated in the picture, this
involves going from a large negative real number to a small negative real number
and then over a smooth curve which stays small to a real positive number and from
there to a real number near 1. λ (z) stays fairly near 1 on C1 provided b0 is large
so that the circle, C1 has very small radius. Then along C, λ (z) is real until it hits
C2. What about the behavior of λ on C2? For z ∈C2, it follows from the deﬁnition
of C2 that z = 1 −1
τ where τ is on the line, a + ib0. Therefore, by Lemma 30.21,

30.1.
PERIODIC FUNCTIONS
845
30.17, and 30.24
λ (z)
=
λ
µ
1 −1
τ
¶
=
λ
¡ −1
τ
¢
λ
¡ −1
τ
¢
−1 =
λ
¡ 1
τ
¢
λ
¡ 1
τ
¢
−1
=
1 −λ (τ)
(1 −λ (τ)) −1 = λ (τ) −1
λ (τ)
= 1 −
1
λ (τ)
which is approximately equal to
1 −
1
16eiπ(a+ib0) = 1 −eπb0e−iaπ
16
.
These points are essentially on a large half circle in the upper half plane which has
radius approximately eπb0
16 .
Now let w ∈C with Im (w) ̸= 0. Then for b0 large enough, the motion over the
boundary of the truncated region indicated in the above picture results in λ tracing
out a large simple closed curve oriented in the counter clockwise direction which
includes w on its interior if Im (w) > 0 but which excludes w if Im (w) < 0.
Theorem 30.23 Let Ωbe the domain described above. Then λ maps Ωone to one
and onto the upper half plane of C, {z ∈C such that Im (z) > 0} . Also, the line
λ (l1) = (0, 1) , λ (l2) = (−∞, 0) , and λ (C) = (1, ∞).
Proof: Let Im (w) > 0 and denote by γ the oriented contour described above
and illustrated in the above picture. Then the winding number of λ ◦γ about w
equals 1. Thus
1
2πi
Z
λ◦γ
1
z −wdz = 1.
But, splitting the contour integrals into l2,the top line, l1, C1, C, and C2 and chang-
ing variables on each of these, yields
1 =
1
2πi
Z
γ
λ′ (z)
λ (z) −wdz
and by the theorem on counting zeros, Theorem 25.20 on Page 694, the function,
z →λ (z) −w has exactly one zero inside the truncated Ω. However, this shows
this function has exactly one zero inside Ωbecause b0 was arbitrary as long as it
is suﬃciently large. Since w was an arbitrary element of the upper half plane, this
veriﬁes the ﬁrst assertion of the theorem. The remaining claims follow from the
above description of λ, in particular the estimate for λ on C2. This proves the
theorem.
Note also that the argument in the above proof shows that if Im (w) < 0, then
w is not in λ (Ω) . However, if you consider the reﬂection of Ωabout the y axis,
then it will follow that λ maps this set one to one onto the lower half plane. The
argument will make signiﬁcant use of Theorem 25.22 on Page 696 which is stated
here for convenience.

846
ELLIPTIC FUNCTIONS
Theorem 30.24 Let f : B (a, R) →C be analytic and let
f (z) −α = (z −a)m g (z) , ∞> m ≥1
where g (z) ̸= 0 in B (a, R) . (f (z) −α has a zero of order m at z = a.) Then there
exist ε, δ > 0 with the property that for each z satisfying 0 < |z −α| < δ, there exist
points,
{a1, · · ·, am} ⊆B (a, ε) ,
such that
f −1 (z) ∩B (a, ε) = {a1, · · ·, am}
and each ak is a zero of order 1 for the function f (·) −z.
Corollary 30.25 Let Ωbe the region above. Consider the set of points, Q = Ω∪
Ω′ \ {0, 1} described by the following picture.
Ω′
r
−1
Ω
C
l2
l1
r
1
r
1
2
Then λ (Q) = C\ {0, 1} . Also λ′ (z) ̸= 0 for every z in ∪∞
k=−∞(Q + 2k) ≡H.
Proof: By Theorem 30.23, this will be proved if it can be shown that λ (Ω′) =
{z ∈C : Im (z) < 0} . Consider λ1 deﬁned on Ω′ by
λ1 (x + iy) ≡λ (−x + iy).
Claim: λ1 is analytic.
Proof of the claim: You just verify the Cauchy Riemann equations. Letting
λ (x + iy) = u (x, y) + iv (x, y) ,
λ1 (x + iy)
=
u (−x, y) −iv (−x, y)
≡
u1 (x, y) + iv (x, y) .
Then u1x (x, y) = −ux (−x, y) and v1y (x, y) = −vy (−x, y) = −ux (−x, y) since
λ is analytic.
Thus u1x = v1y.
Next, u1y (x, y) = uy (−x, y) and v1x (x, y) =
vx (−x, y) = −uy (−x, y) and so u1y = −vx.
Now recall that on l1, λ takes real values. Therefore, λ1 = λ on l1, a set with
a limit point. It follows λ = λ1 on Ω′ ∪Ω. By Theorem 30.23 λ maps Ωone to
one onto the upper half plane. Therefore, from the deﬁnition of λ1 = λ, it follows
λ maps Ω′ one to one onto the lower half plane as claimed. This has shown that λ

30.1.
PERIODIC FUNCTIONS
847
is one to one on Ω∪Ω′. This also veriﬁes from Theorem 25.22 on Page 696 that
λ′ ̸= 0 on Ω∪Ω′.
Now consider the lines l2 and C. If λ′ (z) = 0 for z ∈l2, a contradiction can
be obtained. Pick such a point. If λ′ (z) = 0, then z is a zero of order m ≥2 of
the function, λ −λ (z) . Then by Theorem 25.22 there exist δ, ε > 0 such that if
w ∈B (λ (z) , δ) , then λ−1 (w) ∩B (z, ε) contains at least m points.
Ω′
r
−1
Ω
C
l2
l1
r
1
r
1
2
z1r
B(z, ε)
z
r
r
λ(z1)
B(λ(z), δ)
λ(z)
r
In particular, for z1 ∈Ω∩B (z, ε) suﬃciently close to z, λ (z1) ∈B (λ (z) , δ)
and so the function λ −λ (z1) has at least two distinct zeros. These zeros must be
in B (z, ε) ∩Ωbecause λ (z1) has positive imaginary part and the points on l2 are
mapped by λ to a real number while the points of B (z, ε) \ Ωare mapped by λ to
the lower half plane thanks to the relation, λ (z + 2) = λ (z) . This contradicts λ
one to one on Ω. Therefore, λ′ ̸= 0 on l2. Consider C. Points on C are of the form
1 −1
τ where τ ∈l2. Therefore, using 30.33,
λ
µ
1 −1
τ
¶
= λ (τ) −1
λ (τ)
.
Taking the derivative of both sides,
λ′
µ
1 −1
τ
¶ µ 1
τ 2
¶
= λ′ (τ)
λ (τ)2 ̸= 0.
Since λ is periodic of period 2 it follows λ′ (z) ̸= 0 for all z ∈∪∞
k=−∞(Q + 2k) .
Lemma 30.26 If Im (τ) > 0 then there exists a unimodular
µ
a
b
c
d
¶
such that
c + dτ
a + bτ

848
ELLIPTIC FUNCTIONS
is contained in the interior of Q. In fact,
¯¯¯ c+dτ
a+bτ
¯¯¯ ≥1 and
−1/2 ≤Re
µc + dτ
a + bτ
¶
≤1/2.
Proof: Letting a basis for the module of periods of ℘be {1, τ} , it follows from
Theorem 30.3 on Page 820 that there exists a basis for the same module of periods,
{w′
1, w′
2} with the property that for τ ′ = w′
2/w′
1
|τ ′| ≥1, −1
2 ≤Re τ ′ ≤1
2.
Since this is a basis for the same module of periods, there exists a unimodular
matrix,
µ
a
b
c
d
¶
such that
µ
w′
1
w′
2
¶
=
µ
a
b
c
d
¶ µ
1
τ
¶
.
Hence,
τ ′ = w′
2
w′
1
= c + dτ
a + bτ .
Thus τ ′ is in the interior of H. In fact, it is on the interior of Ω′ ∪Ω≡Q.
0
s
s
1
1/2
−1
−1/2
τ
′ s
30.1.7
A Short Review And Summary
With this lemma, it is easy to extend Corollary 30.25. First, a simple observation
and review is a good idea. Recall that when you change the basis for the module
of periods, the Weierstrass ℘function does not change and so the set of ei used in
deﬁning λ also do not change. Letting the new basis be {w′
1, w′
2} , it was shown
that
µ
w′
1
w′
2
¶
=
µ
a
b
c
d
¶ µ
w1
w2
¶

30.1.
PERIODIC FUNCTIONS
849
for some unimodular transformation,
µ a
b
c
d
¶
. Letting τ = w2/w1 and τ ′ =
w′
2/w′
1
τ ′ = c + dτ
a + bτ ≡φ (τ)
Now as discussed earlier
λ (τ ′)
=
λ (φ (τ)) ≡
℘
³
w′
1+w′
2
2
´
−℘
³
w′
2
2
´
℘
³
w′
1
2
´
−℘
³
w′
2
2
´
=
℘
³
1+τ ′
2
´
−℘
³
τ ′
2
´
℘
¡ 1
2
¢
−℘
¡ τ ′
2
¢
These numbers in the above fraction must be the same as ℘
¡ 1+τ
2
¢
, ℘
¡ τ
2
¢
, and
℘
¡ 1
2
¢
but they might occur diﬀerently. This is because ℘does not change and these
numbers are the zeros of a polynomial having coeﬃcients involving only numbers
and ℘(z) . It could happen for example that ℘
³
1+τ ′
2
´
= ℘
¡ τ
2
¢
in which case this
would change the value of λ. In eﬀect, you can keep track of all possibilities by
simply permuting the ei in the formula for λ (τ) given by e3−e2
e1−e2 . Thus consider the
following permutation table.
1
2
3
2
3
1
3
1
2
2
1
3
1
3
2
3
2
1
.
Corresponding to this list of 6 permutations, all possible formulas for λ (φ (τ))
can be obtained as follows. Letting τ ′ = φ (τ) where φ is a unimodular matrix
corresponding to a change of basis,
λ (τ ′) = e3 −e2
e1 −e2
= λ (τ)
(30.34)
λ (τ ′) = e1 −e3
e2 −e3
= e3 −e2 + e2 −e1
e3 −e2
= 1 −
1
λ (τ) = λ (τ) −1
λ (τ)
(30.35)
λ (τ ′)
=
e2 −e1
e3 −e1
= −
·e3 −e2 −(e1 −e2)
e1 −e2
¸−1
=
−[λ (τ) −1]−1 =
1
1 −λ (τ)
(30.36)
λ (τ ′)
=
e3 −e1
e2 −e1
= −
·e3 −e2 −(e1 −e2)
e1 −e2
¸
=
−[λ (τ) −1] = 1 −λ (τ)
(30.37)

850
ELLIPTIC FUNCTIONS
λ (τ ′) = e2 −e3
e1 −e3
=
e3 −e2
e3 −e2 −(e1 −e2) =
1
1 −
1
λ(τ)
=
λ (τ)
λ (τ) −1
(30.38)
λ (τ ′) = e1 −e3
e3 −e2
=
1
λ (τ)
(30.39)
Corollary 30.27 λ′ (τ) ̸= 0 for all τ in the upper half plane, denoted by P+.
Proof: Let τ ∈P+. By Lemma 30.26 there exists φ a unimodular transforma-
tion and τ ′ in the interior of Q such that τ ′ = φ (τ). Now from the deﬁnition of λ in
terms of the ei, there is at worst a permutation of the ei and so it might be the case
that λ (φ (τ)) ̸= λ (τ) but it is the case that λ (φ (τ)) = ξ (λ (τ)) where ξ′ (z) ̸= 0.
Here ξ is one of the functions determined by 30.34 - 30.39. (Since λ (τ) /∈{0, 1} ,
ξ′ (λ (z)) ̸= 0. This follows from the above possibilities for ξ listed above in 30.34 -
30.39.) All the possibilities are ξ (z) =
z, z −1
z
,
1
1 −z , 1 −z,
z
z −1, 1
z
and these are the same as the possibilities for ξ−1. Therefore, λ′ (φ (τ)) φ′ (τ) =
ξ′ (λ (τ)) λ′ (τ) and so λ′ (τ) ̸= 0 as claimed.
Now I will present a lemma which is of major signiﬁcance. It depends on the
remarkable mapping properties of the modular function and the monodromy theo-
rem from analytic continuation. A review of the monodromy theorem will be listed
here for convenience. First recall the deﬁnition of the concept of function elements
and analytic continuation.
Deﬁnition 30.28 A function element is an ordered pair, (f, D) where D is an open
ball and f is analytic on D. (f0, D0) and (f1, D1) are direct continuations of each
other if D1 ∩D0 ̸= ∅and f0 = f1 on D1 ∩D0. In this case I will write (f0, D0) ∼
(f1, D1) . A chain is a ﬁnite sequence, of disks, {D0, · · ·, Dn} such that Di−1 ∩Di ̸=
∅. If (f0, D0) is a given function element and there exist function elements, (fi, Di)
such that {D0, · · ·, Dn} is a chain and (fj−1, Dj−1) ∼(fj, Dj) then (fn, Dn) is
called the analytic continuation of (f0, D0) along the chain {D0, · · ·, Dn}.
Now
suppose γ is an oriented curve with parameter interval [a, b] and there exists a chain,
{D0, · · ·, Dn} such that γ∗⊆∪n
k=1Dk, γ (a) is the center of D0, γ (b) is the center
of Dn, and there is an increasing list of numbers in [a, b] , a = s0 < s1 · ·· < sn = b
such that γ ([si, si+1]) ⊆Di and (fn, Dn) is an analytic continuation of (f0, D0)
along the chain. Then (fn, Dn) is called an analytic continuation of (f0, D0) along
the curve γ. (γ will always be a continuous curve. Nothing more is needed. )
Then the main theorem is the monodromy theorem listed next, Theorem 27.19
and its corollary on Page 749.
Theorem 30.29 Let Ωbe a simply connected subset of C and suppose (f, B (a, r))
is a function element with B (a, r) ⊆Ω. Suppose also that this function element can
be analytically continued along every curve through a. Then there exists G analytic
on Ωsuch that G agrees with f on B (a, r).

30.1.
PERIODIC FUNCTIONS
851
Here is the lemma.
Lemma 30.30 Let λ be the modular function deﬁned on P+ the upper half plane.
Let V be a simply connected region in C and let f : V →C\ {0, 1} be analytic
and nonconstant. Then there exists an analytic function, g : V →P+ such that
λ ◦g = f.
Proof: Let a ∈V and choose r0 small enough that f (B (a, r0)) contains neither
0 nor 1. You need only let B (a, r0) ⊆V . Now there exists a unique point in Q, τ 0
such that λ (τ 0) = f (a).
By Corollary 30.25, λ′ (τ 0) ̸= 0 and so by the open
mapping theorem, Theorem 25.22 on Page 696, There exists B (τ 0, R0) ⊆P+ such
that λ is one to one on B (τ 0, R0) and has a continuous inverse. Then picking r0
still smaller, it can be assumed f (B (a, r0)) ⊆λ (B (τ 0, R0)). Thus there exists
a local inverse for λ, λ−1
0
deﬁned on f (B (a, r0)) having values in B (τ 0, R0) ∩
λ−1 (f (B (a, r0))). Then deﬁning g0 ≡λ−1
0
◦f, (g0, B (a, r0)) is a function element.
I need to show this can be continued along every curve starting at a in such a way
that each function in each function element has values in P+.
Let γ : [α, β] →V be a continuous curve starting at a, (γ (α) = a) and sup-
pose that if t < T there exists a nonnegative integer m and a function element
(gm, B (γ (t) , rm)) which is an analytic continuation of (g0, B (a, r0)) along γ where
gm (γ (t)) ∈P+ and each function in every function element for j ≤m has values
in P+. Thus for some small T > 0 this has been achieved.
Then consider f (γ (T)) ∈C\ {0, 1} . As in the ﬁrst part of the argument, there
exists a unique τ T ∈Q such that λ (τ T ) = f (γ (T)) and for r small enough there is
an analytic local inverse, λ−1
T
between f (B (γ (T) , r)) and λ−1 (f (B (γ (T) , r))) ∩
B (τ T , RT ) ⊆P+ for some RT > 0. By the assumption that the analytic continua-
tion can be carried out for t < T, there exists {t0, · · ·, tm = t} and function elements
(gj, B (γ (tj) , rj)) , j = 0, · · ·, m as just described with gj (γ (tj)) ∈P+, λ ◦gj = f
on B (γ (tj) , rj) such that for t ∈[tm, T] , γ (t) ∈B (γ (T) , r). Let
I = B (γ (tm) , rm) ∩B (γ (T) , r) .
Then since λ−1
T
is a local inverse, it follows for all z ∈I
λ (gm (z)) = f (z) = λ
¡
λ−1
T
◦f (z)
¢
Pick z0 ∈I . Then by Lemma 30.19 on Page 840 there exists a unimodular mapping
of the form
φ (z) = az + b
cz + d
where
µ
a
b
c
d
¶
∼
µ
1
0
0
1
¶
mod 2
such that
gm (z0) = φ
¡
λ−1
T
◦f (z0)
¢
.

852
ELLIPTIC FUNCTIONS
Since both gm (z0) and φ
¡
λ−1
T
◦f (z0)
¢
are in the upper half plane, it follows ad −
cb = 1 and φ maps the upper half plane to the upper half plane. Note the pole of
φ is real and all the sets being considered are contained in the upper half plane so
φ is analytic where it needs to be.
Claim: For all z ∈I,
gm (z) = φ ◦λ−1
T
◦f (z) .
(30.40)
Proof: For z = z0 the equation holds. Let
A =
©
z ∈I : gm (z) = φ
¡
λ−1
T
◦f (z)
¢ª
.
Thus z0 ∈I. If z ∈I and if w is close enough to z, then w ∈I also and so both
sides of 30.40 with w in place of z are in λ−1
m (f (I)) . But by construction, λ is one
to one on this set and since λ is invariant with respect to φ,
λ (gm (w)) = λ
¡
λ−1
T
◦f (w)
¢
= λ
¡
φ ◦λ−1
T
◦f (w)
¢
and consequently, w ∈A. This shows A is open. But A is also closed in I because
the functions are continuous. Therefore, A = I and so 30.40 is obtained.
Letting f (z) ∈f (B (γ (T)) , r) ,
λ
¡
φ
¡
λ−1
T (f (z))
¢¢
= λ
¡
λ−1
T (f (z))
¢
= f (z)
and so φ ◦λ−1
T
is a local inverse for λ on f (B (γ (T)) , r) . Let the new function
element be



gm+1
z
}|
{
φ ◦λ−1
T
◦f, B (γ (T) , r)


. This has shown the initial function element
can be continued along every curve through a.
By the monodromy theorem, there exists g analytic on V such that g has values
in P+ and g = g0 on B (a, r0) . By the construction, it also follows λ ◦g = f. This
last claim is easy to see because λ ◦g = f on B (a, r0) , a set with a limit point so
the equation holds for all z ∈V . This proves the lemma.
30.2
The Picard Theorem Again
Having done all this work on the modular function which is important for its own
sake, there is an easy proof of the Picard theorem. In fact, this is the way Picard
did it in 1879. I will state it slightly diﬀerently since it is no trouble to do so, [27].
Theorem 30.31 Let f be meromorphic on C and suppose f misses three distinct
points, a, b, c. Then f is a constant function.
Proof: Let φ (z) ≡z−a
z−c
b−c
b−a. Then φ (c) = ∞, φ (a) = 0, and φ (b) = 1. Now
consider the function, h = φ ◦f. Then h misses the three points ∞, 0, and 1. Since
h is meromorphic and does not have ∞in its values, it must actually be analytic.

30.3.
EXERCISES
853
Thus h is an entire function which misses the two values 0 and 1. If h is not constant,
then by Lemma 30.30 there exists a function, g analytic on C which has values in
the upper half plane, P+ such that λ ◦g = h. However, g must be a constant
because there exists ψ an analytic map on the upper half plane which maps the
upper half plane to B (0, 1) . You can use the Riemann mapping theorem or more
simply, ψ (z) = z−i
z+i. Thus ψ ◦g equals a constant by Liouville’s theorem. Hence
g is a constant and so h must also be a constant because λ (g (z)) = h (z) . This
proves f is a constant also. This proves the theorem.
30.3
Exercises
1. Show the set of modular transformations is a group. Also show those modular
transformations which are congruent mod 2 to the identity as described above
is a subgroup.
2. Suppose f is an elliptic function with period module M. If {w1, w2} and
{w′
1, w′
2} are two bases, show that the resulting period parallelograms resulting
from the two bases have the same area.
3. Given a module of periods with basis {w1, w2} and letting a typical element
of this module be denoted by w as described above, consider the product
σ (z) ≡z
Y
w̸=0
³
1 −z
w
´
e(z/w)+ 1
2 (z/w)2.
Show this product converges uniformly on compact sets, is an entire function,
and satisﬁes
σ′ (z) /σ (z) = ζ (z)
where ζ (z) was deﬁned above as a primitive of ℘(z) and is given by
ζ (z) = 1
z +
X
w̸=0
1
z −w + z
w2 + 1
w.
4. Show ζ (z + wi) = ζ (z) + ηi where ηi is a constant.
5. Let Pa be the parallelogram shown in the following picture.
0
s
w1
w2s
s


£
£
£
£
£
£
£
£


£
£
£
£
£
£
££
a s

£
£
£
£
£
£
£
£


£
£
£
£
£
£
£
£

854
ELLIPTIC FUNCTIONS
Show that
1
2πi
R
∂Pa ζ (z) dz = 1 where the contour is taken once around the
parallelogram in the counter clockwise direction. Next evaluate this contour
integral directly to obtain Legendre’s relation,
η1w2 −η2w1 = 2πi.
6. For σ deﬁned in Problem 3, 4 explain the following steps. For j = 1, 2
σ′ (z + wj)
σ (z + wj) = ζ (z + wj) = ζ (z) + ηj = σ′ (z)
σ (z) + ηj
Therefore, there exists a constant, Cj such that
σ (z + wj) = Cjσ (z) eηjz.
Next show σ is an odd function, (σ (−z) = −σ (z)) and then let z = −wj/2
to ﬁnd Cj = −e
ηj wj
2
and so
σ (z + wj) = −σ (z) eηj(z+
wj
2 ).
(30.41)
7. Show any even elliptic function, f with periods w1 and w2 for which 0 is
neither a pole nor a zero can be expressed in the form
f (0)
n
Y
k=1
℘(z) −℘(ak)
℘(z) −℘(bk)
where C is some constant. Here ℘is the Weierstrass function which comes
from the two periods, w1 and w2. Hint: You might consider the above func-
tion in terms of the poles and zeros on a period parallelogram and recall that
an entire function which is elliptic is a constant.
8. Suppose f is any elliptic function with {w1, w2} a basis for the module of
periods.
Using Theorem 30.9 and 30.41 show that there exists constants
a1, · · ·, an and b1, · · ·, bn such that for some constant C,
f (z) = C
n
Y
k=1
σ (z −ak)
σ (z −bk) .
Hint: You might try something like this: By Theorem 30.9, it follows that if
{αk} are the zeros and {bk} the poles in an appropriate period parallelogram,
P αk −P bk equals a period. Replace αk with ak such that P ak −P bk = 0.
Then use 30.41 to show that the given formula for f is bi periodic. Anyway,
you try to arrange things such that the given formula has the same poles as
f. Remember an entire elliptic function equals a constant.
9. Show that the map τ →1 −1
τ maps l2 onto the curve, C in the above picture
on the mapping properties of λ.
10. Modify the proof of Theorem 30.23 to show that λ (Ω)∩{z ∈C : Im (z) < 0} =
∅.

Part IV
Stochastic Processes, An
Introduction
855


Random Variables And Basic
Probability
Caution: This material on probability and stochastic processes may be half baked
in places. I have not yet rewritten it several times. This is not to say that nothing
else is half baked. However, the probability is higher here.
Recall Lemma 11.3 on Page 305 which is stated here for convenience.
Lemma 31.1 Let M be a metric space with the closed balls compact and suppose
λ is a measure deﬁned on the Borel sets of M which is ﬁnite on compact sets.
Then there exists a unique Radon measure, λ which equals λ on the Borel sets. In
particular λ must be both inner and outer regular on all Borel sets.
Also recall from earlier the following fundamental result which is called the Borel
Cantelli lemma.
Lemma 31.2 Let (Ω, F, λ) be a measure space and let {Ai} be a sequence of mea-
surable sets satisfying
∞
X
i=1
λ (Ai) < ∞.
Then letting S denote the set of ω ∈Ωwhich are in inﬁnitely many Ai, it follows
S is a measurable set and λ (S) = 0.
Proof: S = ∩∞
k=1 ∪∞
m=k Am. Therefore, S is measurable and also
λ (S) ≤λ (∪∞
m=kAm) ≤
∞
X
m=k
λ (Ak)
and this converges to 0 as k →∞because of the convergence of the series. This
proves the lemma.
Deﬁnition 31.3 A probability space is a measure space, (Ω, F, P) where P is a
measure satisfying P (Ω) = 1. A random vector is a measurable function, X : Ω→
Rp. This might also be called a random variable. Deﬁne the following σ algebra.
HX ≡
©
X−1 (E) : E is Borel in Rpª
857

858
RANDOM VARIABLES AND BASIC PROBABILITY
Thus HX ⊆F. This is also often written as σ (X). For E a Borel set in Rp deﬁne
λX (E) ≡P
¡
X−1 (E)
¢
.
This is called the distribution of the random variable, X. If
Z
Ω
|X (ω)| dP < ∞
then deﬁne
E (X) ≡
Z
Ω
XdP
where the integral is deﬁned in the obvious way componentwise.
Lemma 31.4 For X a random vector deﬁned above, λX is inner and outer regular,
Borel, and its completion is a Radon measure and λX (Rp) = 1. Furthermore, if h
is any bounded Borel measurable function,
Z
Ω
h (X (ω)) dP =
Z
Rp h (x) dλX.
Proof: The assertions about λX follow from Lemma 11.3 on Page 305 listed
above. It remains to verify the formula involving the integrals. Suppose ﬁrst
h (x) = cXE (x)
where E is a Borel set in Rp. Then the left side equals
Z
Ω
cXE (X (ω)) dP =
Z
[X∈E]
cdP = cλX (E)
The right side equals
Z
Rp cXE (x) dλX = cλX (E) .
Similarly, if h is any Borel simple function, the same result will hold. For an arbi-
trary bounded Borel function, h, there exists a sequence of Borel simple functions,
{sn} converging to h. Hence, by the dominated convergence theorem,
Z
Ω
h (X (ω)) dP = lim
n→∞
Z
Ω
sn (X (ω)) dP = lim
n→∞
Z
sn (x) dλX =
Z
Rp h (x) dλX.
This proves the lemma.
Obviously, h could also be vector valued and Borel measurable and the same
argument would work or else you could simply consider the component functions of
h.

859
Deﬁnition 31.5 A ﬁnite set of random vectors, {Xk}n
k=1 is independent if when-
ever Fk ∈HXk (σ (Xk)),
P (∩n
k=1Fk) =
n
Y
k=1
P (Fk) .
More generally, if {Fi}i∈I is any set of σ algebras, they are said to be independent
if whenever Aik ∈Fik for k = 1, 2, · · ·, m, then
P (∩m
k=1Aik) =
m
Y
k=1
P (Aik) .
Lemma 31.6 If {Xk}r
k=1 are independent and if gk is a Borel measurable function,
then {gk (Xk)}n
k=1 is also independent. Furthermore, if the random variables have
values in R and they are all bounded, then
E
Ã r
Y
i=1
Xi
!
=
r
Y
i=1
E (Xi) .
Proof: First consider the claim about {gk (Xk)}r
k=1. Letting O be an open set
in R,
(gk ◦Xk)−1 (O) = X−1
k
¡
g−1
k
(O)
¢
= X−1
k
(Borel set) ∈HXk.
It follows (gk ◦Xk)−1 (E) is in HXk whenever E is Borel. Thus Hgk◦Xk ⊆HXk and
this proves the ﬁrst part of the lemma.
Now let
©
si
n
ª∞
n=1 be a bounded sequence of simple functions measurable in HXi
which converges to Xi uniformly. (Since Xi is bounded, such a sequence exists by
breaking Xi into positive and negative parts and using Theorem 8.27 on Page 190.)
Say
si
n (ω) =
mn
X
k=1
cn,i
k XEn,i
k
(ω)
where the Ek are disjoint elements of HXi and some might be empty. This is for
convenience in keeping the same index on the top of the sum. Then since all the
random variables are bounded, there is no problem about existence of any of the

860
RANDOM VARIABLES AND BASIC PROBABILITY
above. Then from the assumption that the Xi are independent,
E
Ã r
Y
i=1
Xi
!
=
Z
Ω
r
Y
i=1
Xi (ω) dP = lim
n→∞
Z
Ω
r
Y
i=1
si
n (ω) dP
=
lim
n→∞
Z
Ω
r
Y
i=1
mn
X
k=1
cn,i
k XEn,i
k
(ω) dP
=
lim
n→∞
Z
Ω
X
k1,k2,···,kr
cn,1
k1 cn,2
k2 · · · cn,r
kr XEn,1
k1 XEn,2
k2 · · · XEn,r
kr dP
=
lim
n→∞
X
k1,k2,···,kr
Z
Ω
cn,1
k1 cn,2
k2 · · · cn,r
kr XEn,1
k1 XEn,2
k2 · · · XEn,r
kr dP
=
lim
n→∞
X
k1,k2,···,kr
cn,1
k1 cn,2
k2 · · · cn,r
kr
r
Y
i=1
P
³
En,i
ki
´
=
lim
n→∞
r
Y
i=1
Z
Ω
si
n (ω) dP =
r
Y
i=1
E (Xi) .
This proves the lemma.
31.1
The Characteristic Function
Deﬁnition 31.7 Let X be a random variable as above. The characteristic function
is
φX (t) ≡E
¡
eit·X¢
≡
Z
Ω
eit·X(ω)dP =
Z
Rp eit·xdλX
the last equation holding by Lemma 31.4.
Recall the following fundamental lemma and deﬁnition, Lemma 19.12 on Page
522.
Deﬁnition 31.8 For T ∈G∗, deﬁne FT, F −1T ∈G∗by
FT (φ) ≡T (Fφ) , F −1T (φ) ≡T
¡
F −1φ
¢
Lemma 31.9 F and F −1 are both one to one, onto, and are inverses of each other.
The main result on characteristic functions is the following.
Theorem 31.10 Let X and Y be random vectors with values in Rp and suppose
E
¡
eit·X¢
= E
¡
eit·Y¢
for all t ∈Rp. Then λX = λY.

31.2.
CONDITIONAL PROBABILITY
861
Proof: For ψ ∈G, let λX (ψ) ≡
R
Rp ψdλX and λY (ψ) ≡
R
Rp ψdλY . Thus both
λX and λY are in G∗. Then letting ψ ∈G and using Fubini’s theorem,
Z
Rp
Z
Rp eit·yψ (t) dtdλY
=
Z
Rp
Z
Rp eit·ydλYψ (t) dt
=
Z
Rp E
¡
eit·Y¢
ψ (t) dt
=
Z
Rp E
¡
eit·X¢
ψ (t) dt
=
Z
Rp
Z
Rp eit·xdλXψ (t) dt
=
Z
Rp
Z
Rp eit·xψ (t) dtdλX.
Thus λY
¡
F −1ψ
¢
= λX
¡
F −1ψ
¢
. Since ψ ∈G is arbitrary and F −1 is onto, this
implies λX = λY in G∗. But G is dense in C0 (Rp) and so λX = λY as measures.
This proves the theorem.
31.2
Conditional Probability
Here I will consider the concept of conditional probability depending on the theory
of diﬀerentiation of general Radon measures and leading to the Doob Dynkin lemma.
If X, Y are two random vectors deﬁned on a probability space having values
in Rp1 and Rp2 respectively, and if E is a Borel set in the appropriate space, then
(X, Y) is a random vector with values in Rp1 ×Rp2 and λ(X,Y) (E × Rp2) = λX (E),
λ(X,Y) (Rp1 × E) = λY (E). Thus, by Theorem 18.12 on Page 505, there exist
probability measures, denoted here by λX|y and λY|x, such that whenever E is a
Borel set in Rp1 × Rp2,
Z
Rp1×Rp2
XEdλ(X,Y) =
Z
Rp1
Z
Rp2
XEdλY|xdλX,
and
Z
Rp1×Rp2
XEdλ(X,Y) =
Z
Rp2
Z
Rp1
XEdλX|ydλY.
Deﬁnition 31.11 Let X and Y be two random vectors deﬁned on a probability
space. The conditional probability measure of Y given X is the measure λY|x in the
above. Similarly the conditional probability measure of X given Y is the measure
λX|y.
More generally, one can use the theory of slicing measures to consider any ﬁnite
list of random vectors, {Xi}, deﬁned on a probability space with Xi ∈Rpi, and
write the following for E a Borel set in Qn
i=1 Rpi.
Z
Rp1×···×Rpn
XEdλ(X1,···,Xn) =
Z
Rp1
Z
Rp2×···×Rpn
XEdλ(X2,···,Xn)|x1dλX1

862
RANDOM VARIABLES AND BASIC PROBABILITY
=
Z
Rp1
Z
Rp2
Z
Rp3×···×Rpn
XEdλ(X3,···,Xn)|x1x2dλX2|x1dλX1
...
=
Z
Rp1
· · ·
Z
Rpn
XEdλXn|x1x2···xn−1dλXn−1|x1···xn−2 · · · dλX2|x1dλX1.
(31.1)
Obviously, this could have been done in any order in the iterated integrals by
simply modifying the “given” variables, those occurring after the symbol |, to be
those which have been integrated in an outer level of the iterated integral.
Deﬁnition 31.12 Let {X1, · · ·, Xn} be random vectors deﬁned on a probability
space having values in Fp1, ···, Fpn respectively. The random vectors are independent
if for every E a Borel set in Fp1 × · · · × Fpn,
Z
Rp1×···×Rpn
XEdλ(X1,···,Xn)
=
Z
Rp1
· · ·
Z
Rpn
XEdλXndλXn−1 · · · dλX2dλX1
(31.2)
and the iterated integration may be taken in any order. If A is any set of random
vectors deﬁned on a probability space, A is independent if any ﬁnite set of random
vectors from A is independent.
Thus, the random vectors are independent exactly when the dependence on the
givens in 31.1 can be dropped.
Does this amount to the same thing as discussed earlier?
These two ran-
dom vectors, X, Y were independent if whenever A ∈HX (σ (X)) and B ∈HY,
P (A ∩B) = P (A) P (B) . Suppose the above deﬁnition and A and B as described.
Let A = X−1 (E) and B = Y−1 (F) . Then
P (A ∩B)
=
P ((X, Y) ∈E × F)
=
Z
Rp1×Rp2
XE (x) XF (y) dλ(X,Y)
=
Z
Rp1
Z
Rp2
XE (x) XF (y) dλY|xdλX
=
Z
Rp1
Z
Rp2
XE (x) XF (y) dλYdλX
=
λX (E) λY (F) = P (A) P (B)
Next suppose P (A ∩B) = P (A) P (B) where A ∈HX and B ∈HY, A = X−1 (E)
and B = Y−1 (F) . Can it be asserted λX|y = λX? In this case, for all E Borel in

31.2.
CONDITIONAL PROBABILITY
863
Rp1 and F Borel in Rp2,
Z
Rp1
Z
Rp2
XE (x) XF (y) dλYdλX
=
P (A) P (B) = P (A ∩B)
=
Z
Rp1×Rp2
XE (x) XF (y) dλ(X,Y)
=
Z
Rp1
Z
Rp2
XE (x) XF (y) dλY|xdλX
and so, by uniqueness of the slicing measures, dλY|x = dλY. A similar argument
shows dλX|y = dλX. Thus this amounts to the same thing discussed earlier.
Proposition 31.13 Equations 31.2 and 31.1 hold with XE replaced by any non-
negative Borel measurable function and for any bounded continuous function.
Proof: The two equations hold for simple functions in place of XE and so an
application of the monotone convergence theorem applied to an increasing sequence
of simple functions converging pointwise to a given nonnegative Borel measurable
function yields the conclusion of the proposition in the case of the nonnegative
Borel function. For a bounded continuous function, one can apply the result just
established to the positive and negative parts of the real and imaginary parts of the
function.
Lemma 31.14 Let X1, ···, Xn be random vectors with values in Rp1, ···, Rpn respec-
tively and let g : Rp1 × · · · × Rpn →Rk be Borel measurable. Then g (X1, · · ·, Xn)
is a random vector with values in Rk and if h : Rk →[0, ∞), then
Z
Rk h (y) dλg(X1,···,Xn) (y) =
Z
Rp1×···×Rpn
h (g (x1, · · ·, xn)) dλ(X1,···,Xn).
(31.3)
If Xi is a random vector with values in Rpi, i = 1, 2, · · · and if gi : Rpi →Rki,
where gi is Borel measurable, then the random vectors gi (Xi) are also independent
whenever the Xi are independent.
Proof: First let E be a Borel set in Rk. From the deﬁnition,
Z
Rk XEdλg(X1,···,Xn)
=
Z
Rp1×···×Rpn
Xg−1(E)dλ(X1,···,Xn)
=
Z
Rp1×···×Rpn
XE (g (x1, · · ·, xn)) dλ(X1,···,Xn).
This proves 31.3 in the case when h is XE. To prove it in the general case, approx-
imate the nonnegative Borel measurable function with simple functions for which
the formula is true, and use the monotone convergence theorem.

864
RANDOM VARIABLES AND BASIC PROBABILITY
It remains to prove the last assertion that functions of independent random
vectors are also independent random vectors. Let E be a Borel set in Rk1 ×···×Rkn.
Then for
πi (x1, · · ·, xn) ≡xi,
Z
Rk1×···×Rkn
XEdλ(g1(X1),···,gn(Xn))
≡
Z
Rp1×···×Rpn
XE ◦(g1 ◦π1, · · ·, gn ◦πn) dλ(X1,···,Xn)
=
Z
Rp1
· · ·
Z
Rpn
XE ◦(g1 ◦π1, · · ·, gn ◦πn) dλXn · · · dλX1
=
Z
Rk1
· · ·
Z
Rkn
XEdλgn(Xn) · · · dλg1(X1)
and this proves the last assertion.
Proposition 31.15 Let ν1, · · ·, νn be Radon probability measures deﬁned on Rp.
Then there exists a probability space and independent random vectors {X1, · · ·, Xn}
deﬁned on this probability space such that λXi = νi.
Proof: Let (Ω, S, P) ≡((Rp)n , S1 × · · · × Sn, ν1 × · · · × νn) where this is just
the product σ algebra and product measure which satisﬁes the following for mea-
surable rectangles.
(ν1 × · · · × νn)
Ã n
Y
i=1
Ei
!
=
n
Y
i=1
νi (Ei).
Now let Xi (x1, · · ·, xi, · · ·, xn) = xi. Then from the deﬁnition, if E is a Borel set
in Rp,
λXi (E) ≡P {Xi ∈E}
= (ν1 × · · · × νn) (Rp × · · · × E × · · · × Rp) = νi (E).
Let M consist of all Borel sets of (Rp)n such that
Z
Rp · · ·
Z
Rp XE (x1, · · ·, xn) dλX1 · · · dλXn =
Z
(Rp)n XEdλ(X1,···,Xn).
From what was just shown and the deﬁnition of (ν1 × · · · × νn) that M contains
all sets of the form Qn
i=1 Ei where each Ei ∈Borel sets of Rp.
Therefore, M
contains the algebra of all ﬁnite disjoint unions of such sets. It is also clear that
M is a monotone class and so by the theorem on monotone classes, M equals the
Borel sets. Therefore, the given random vectors are independent and this proves
the proposition.
The following Lemma was proved earlier in a diﬀerent way.

31.2.
CONDITIONAL PROBABILITY
865
Lemma 31.16 If {Xi}n
i=1 are independent random variables having values in R,
E
Ã n
Y
i=1
Xi
!
=
n
Y
i=1
E (Xi).
Proof: By Lemma 31.14 and denoting by P the product, Qn
i=1 Xi,
E
Ã n
Y
i=1
Xi
!
=
Z
R
zdλP (z) =
Z
R×R
n
Y
i=1
xidλ(X1,···,Xn)
=
Z
R
· · ·
Z
R
n
Y
i=1
xidλX1 · · · dλXn =
n
Y
i=1
E (Xi).
There is a way to tell if random vectors are independent by using their charac-
teristic functions.
Proposition 31.17 If X1 and X2 are random vectors having values in Rp1 and
Rp2 respectively, then the random vectors are independent if and only if
E
¡
eiP ¢
=
2
Y
j=1
E
¡
eitj·Xj¢
where P ≡P2
j=1 tj · Xj for tj ∈Rpj. More generally, if Xi is a random vector
having values in Rpi for i = 1, 2, · · ·, n, and if P = Pn
j=1 tj · Xj, then the random
vectors are independent if and only if
E
¡
eiP ¢
=
n
Y
j=1
E
¡
eitj·Xj¢
.
The proof of this proposition will depend on the following lemma.
Lemma 31.18 Let Y be a random vector with values in Rp and let f be bounded
and measurable with respect to the Radon measure, λY, and satisfy
Z
f (y) eit·ydλY = 0
for all t ∈Rp. Then f (y) = 0 for λY a.e. y.
Proof: The proof is just like the proof of Theorem 31.10 on Page 860 applied
to the measure, f (y) dλY. Thus
R
E f (y) dλY = 0 for all E Borel. Hence f (y) = 0
a.e.
Proof of the proposition: If the Xj are independent, the formula follows
from Lemma 31.16 and Lemma 31.14.
Now suppose the formula holds. Then
Z
Rp2
Z
Rp1
eit1·x1eit2·x2dλX1dλX2 = E
¡
eiP ¢

866
RANDOM VARIABLES AND BASIC PROBABILITY
=
Z
Rp2
Z
Rp1
eit1·x1eit2·x2dλX1|x2dλX2.
Now apply Lemma 31.18 to conclude that
Z
Rp1
eit1·x1dλX1 =
Z
Rp1
eit1·x1dλX1|x2
(31.4)
for λX2 a.e. x2, the exceptional set depending on t1. Therefore, taking the union of
all exceptional sets corresponding to t1 ∈Qp1, it follows by continuity and the domi-
nated convergence theorem that 31.4 holds for all t1 whenever x2 is not an element of
this exceptional set of measure zero. Therefore, for such x2, Theorem 31.10 applies
and it follows λX1|x2 = λX1 for λX2 a.e. x2. Hence, if E is a Borel set in Rp1 ×Rp2,
R
Rp1+p2 XEdλ(X1,X2) =
R
Rp2
R
Rp1 XEdλX1|x2dλX2 =
R
Rp2
R
Rp1 XEdλX1dλX2. A re-
peat of the above argument will give the iterated integral in the reverse order or
else one could apply Fubini’s theorem to obtain this. The proposition also holds if 2
is replaced with n and the argument is a longer version of what was just presented.
This proves the proposition.
With this preparation, it is time to present the Doob Dynkin lemma.I am not
entirely sure what the Doob Dynkin lemma says actually. What follows is a gener-
alization of what is identiﬁed as a special case of this lemma in [42]. I am not sure
I have the right generalization. However, it is a very interesting lemma regardless
of its name.
Lemma 31.19 Suppose X, Y1, Y2, ···, Yk are random vectors, X having values in
Rn and Yj having values in Rpj and
X, Yj ∈L1 (Ω) .
Suppose X is H(Y1,···,Yk) measurable. Thus
©
X−1 (E) : E Borel
ª
⊆


(Y1, · · ·, Yk)−1 (F) : F is Borel in
k
Y
j=1
Rpj



Then there exists a Borel function, g : Qk
j=1 Rpj →Rn such that
X = g (Y1, Y2, · · ·, Yk) .
Proof: For the sake of brevity, denote by Y the vector (Y1, · · ·, Yk) and by y
the vector (y1, · · ·, yk) and let Qk
j=1 Rpj ≡RP . For E a Borel set of Rn,
Z
Y−1(E)
XdP
=
Z
Rn×RP XRn×E (x, y) xdλ(X,Y)
=
Z
E
Z
Rn xdλX|ydλY.
(31.5)
Consider the function
y →
Z
Rn xdλX|y.

31.3.
THE MULTIVARIATE NORMAL DISTRIBUTION
867
Since dλY is a Radon measure having inner and outer regularity, it follows the
above function is equal to a Borel function for λY a.e. y. This function will be
denoted by g. Then from 31.5
Z
Y−1(E)
XdP
=
Z
E
g (y) dλY =
Z
RP XE (y) g (y) dλY
=
Z
Ω
XE (Y (ω)) g (Y (ω)) dP
=
Z
Y−1(E)
g (Y (ω)) dP
and since Y−1 (E) is an arbitrary element of HY, this shows that since X is HY
measurable,
X = E (X|HY) = g (Y) .
This proves the lemma.
Note also that as part of this argument, it is shown that if the symbol,
E (X|y1, · · ·, yk)
is deﬁned as the function g in the above, then for a.e. ω,
E
¡
X|H(Y1,Y2,···,Yk)
¢
(ω) = E (X|Y1 (ω) , Y2 (ω) , · · ·, Yk (ω))
which is a fairly attractive formula.
31.3
The Multivariate Normal Distribution
Deﬁnition 31.20 A random vector, X, with values in Rp has a multivariate nor-
mal distribution written as X ∼Np (m, Σ) if for all Borel E ⊆Rp,
λX (E) =
Z
Rp XE (x)
1
(2π)p/2 det (Σ)1/2 e
−1
2 (x−m)∗Σ−1(x−m)dx
for µ a given vector and Σ a given positive deﬁnite symmetric matrix.
Theorem 31.21 For X ∼Np (m, Σ) , m = E (X) and
Σ = E
¡
(X −m) (X −m)∗¢
.
Proof: Let R be an orthogonal transformation such that
RΣR∗= D = diag
¡
σ2
1, · · ·, σ2
p
¢
.

868
RANDOM VARIABLES AND BASIC PROBABILITY
Changing the variable by x −m = R∗y,
E (X)
≡
Z
Rp xe
−1
2 (x−m)∗Σ−1(x−m)dx
Ã
1
(2π)p/2 det (Σ)1/2
!
=
Z
Rp (R∗y + m) e−1
2 y∗D−1ydy
Ã
1
(2π)p/2 Qp
i=1 σi
!
=
m
Z
Rp e−1
2 y∗D−1ydy
Ã
1
(2π)p/2 Qp
i=1 σi
!
= m
by Fubini’s theorem and the easy to establish formula
1
√
2πσ
Z
R
e−y2
2σ2 dy = 1.
Next let M ≡E
¡
(X −m) (X −m)∗¢
. Thus, changing the variable as above by
x −m = R∗y
M
=
Z
Rp (x −m) (x −m)∗e
−1
2 (x−m)∗Σ−1(x−m)dx
Ã
1
(2π)p/2 det (Σ)1/2
!
=
R∗
Z
Rp yy∗e−1
2 y∗D−1ydy
Ã
1
(2π)p/2 Qp
i=1 σi
!
R
Therefore,
(RMR∗)ij =
Z
Rp yiyje−1
2 y∗D−1ydy
Ã
1
(2π)p/2 Qp
i=1 σi
!
= 0,
so; RMR∗is a diagonal matrix.
(RMR∗)ii =
Z
Rp y2
i e−1
2 y∗D−1ydy
Ã
1
(2π)p/2 Qp
i=1 σi
!
.
Using Fubini’s theorem and the easy to establish equations,
1
√
2πσ
Z
R
e−y2
2σ2 dy = 1,
1
√
2πσ
Z
R
y2e−y2
2σ2 dy = σ2,
it follows (RMR∗)ii = σ2
i . Hence RMR∗= D and so M = R∗DR = Σ. This
proves the theorem.
Theorem 31.22 Suppose X1 ∼Np (m1, Σ1) , X2 ∼Np (m2, Σ2) and the two ran-
dom vectors are independent. Then
X1 + X2 ∼Np (m1 + m2, Σ1 + Σ2).
(31.6)

31.3.
THE MULTIVARIATE NORMAL DISTRIBUTION
869
Also, if X ∼Np (m, Σ) then −X ∼Np (−m, Σ) . Furthermore, if X ∼Np (m, Σ)
then
E
¡
eit·X¢
= eit·me−1
2 t∗Σt
(31.7)
Also if a is a constant and X ∼Np (m, Σ) then aX ∼Np
¡
am, a2Σ
¢
.
Proof: Consider E
¡
eit·X¢
for X ∼Np (m, Σ).
E
¡
eit·X¢
≡
1
(2π)p/2 (det Σ)1/2
Z
Rp eit·xe−1
2 (x−m)∗Σ−1(x−m)dx.
Let R be an orthogonal transformation such that
RΣR∗= D = diag
¡
σ2
1, · · ·, σ2
p
¢
.
Then let R (x −m) = y. Then
E
¡
eit·X¢
=
1
(2π)p/2 Qp
i=1 σi
Z
Rp eit·(R∗y+m)e−1
2 y∗D−1ydx.
Therefore
E
¡
eit·X¢
=
1
(2π)p/2 Qp
i=1 σi
Z
Rp eis·(y+Rm)e−1
2 y∗D−1ydx
where s =Rt. This equals
eit·m
p
Y
i=1
µZ
R
eisiyie
−
1
2σ2
i
y2
i dyi
¶
1
√
2πσi
= eit·m
p
Y
i=1
µZ
R
eisiσiue−1
2 u2du
¶
1
√
2π
= eit·m
p
Y
i=1
e−1
2 s2
i σ2
i
1
√
2π
Z
R
e−1
2 (u−isiσi)2du
= eit·me−1
2
Pp
i=1 s2
i σ2
i = eit·me−1
2 t∗Σt
This proves 31.7.
Since X1 and X2 are independent, eit·X1 and eit·X2 are also independent. Hence
E
¡
eit·X1+X2¢
= E
¡
eit·X1¢
E
¡
eit·X2¢
.
Thus,
E
¡
eit·X1+X2¢
=
E
¡
eit·X1¢
E
¡
eit·X2¢
=
eit·m1e−1
2 t∗Σ1teit·m2e−1
2 t∗Σ2t
=
eit·(m1+m2)e−1
2 t∗(Σ1+Σ2)t

870
RANDOM VARIABLES AND BASIC PROBABILITY
which is the characteristic function of a random vector distributed as
Np (m1 + m2, Σ1 + Σ2).
Now it follows that X1 + X2 ∼Np (m1 + m2, Σ1 + Σ2) by Theorem 31.10. This
proves 31.6.
The assertion about −X is also easy to see because
E
³
eit·(−X)´
=
E
³
ei(−t)·X´
=
1
(2π)p/2 (det Σ)1/2
Z
Rp ei(−t)·xe−1
2 (x−m)∗Σ−1(x−m)dx
=
1
(2π)p/2 (det Σ)1/2
Z
Rp eit·xe−1
2 (x+m)∗Σ−1(x+m)dx
which is the characteristic function of a random variable which is N (−m, Σ) . The-
orem 31.10 again implies −X ∼N (−m, Σ) . Finally consider the last claim. You
apply what is known about X with t replaced with at and then massage things.
This gives the characteristic function for aX is given by
E (exp (it·aX)) = exp (it·am) exp
µ
−1
2t∗Σa2t
¶
which is the characteristic function of a normal random vector having mean am
and covariance a2Σ. This proves the theorem.
Following [42] a random vector has a generalized normal distribution if its char-
acteristic function is given as
eit·me−1
2 t∗Σt
(31.8)
where Σ is symmetric and has nonnegative eigenvalues. For a random real valued
variable, m is scalar and so is Σ so the characteristic function of such a generalized
normally distributed random variable is
eitµe−1
2 t2σ2
(31.9)
These generalized normal distributions do not require Σ to be invertible, only that
the eigenvalues by nonnegative. In one dimension this would correspond the charac-
teristic function of a dirac measure having point mass 1 at µ. In higher dimensions,
it could be a mixture of such things with more familiar things. I won’t try very hard
to distinguish between generalized normal distributions and normal distributions in
which the covariance matrix has all positive eigenvalues.
Here are some other interesting results about normal distributions found in [42].
The next theorem has to do with the question whether a random vector is normally
distributed in the above generalized sense.
Theorem 31.23 Let X = (X1, · · ·, Xp) where each Xi is a real valued random
variable. Then X is normally distributed in the above generalized sense if and only

31.3.
THE MULTIVARIATE NORMAL DISTRIBUTION
871
if every linear combination, Pp
j=1 aiXi is normally distributed. In this case the
mean of X is
m = (E (X1) , · · ·, E (Xp))
and the covariance matrix for X is
Σjk = E
¡
(Xj −mj) (Xk −mk)∗¢
.
Proof: Suppose ﬁrst X is normally distributed. Then its characteristic function
is of the form
φX (t) = E
¡
eit·X¢
= eit·me−1
2 t∗Σt.
Then letting a = (a1, · · ·, ap)
E
³
eit Pp
j=1 aiXi´
= E
¡
eita·X¢
= eita·me−1
2 a∗Σat2
which is the characteristic function of a normally distributed random variable with
mean a · m and variance σ2 = a∗Σa. This proves half of the theorem.
Next suppose Pp
j=1 ajXj = a · X is normally distributed with mean µ and
variance σ2 so that its characteristic function is given in 31.9. I will now relate µ and
σ2 to various quantities involving the Xj. Letting mj = E (Xj) , m = (m1, · · ·, mp)∗
µ
=
p
X
j=1
ajE (Xj) =
p
X
j=1
ajmj, σ2 = E





p
X
j=1
ajXj −
p
X
j=1
ajmj


2


=
E





p
X
j=1
aj (Xj −mj)


2

=
X
j,k
ajakE ((Xj −mj) (Xk −mk))
It follows the mean of the normally distributed random variable, a · X is
µ =
X
j
ajmj = a · m
and its variance is
σ2 = a∗E
¡
(X −m) (X −m)∗¢
a
Therefore,
E
¡
eita·X¢
= eitµe−1
2 t2σ2
= eita·me−1
2 t2a∗E((X−m)(X−m)∗)a.
Then letting s = ta this shows
E
¡
eis·X¢
=
eis·me−1
2 s∗E((X−m)(X−m)∗)s
=
eis·me−1
2 s∗Σs

872
RANDOM VARIABLES AND BASIC PROBABILITY
which is the characteristic function of a normally distributed random variable with
m given above and Σ given by
Σjk = E ((Xj −mj) (Xk −mk)) .
This proves the theorem.
Corollary 31.24 Let X = (X1, · · ·, Xp) , Y = (Y1, · · ·, Yp) where each Xi, Yi is a
real valued random variable. Suppose also that for every a ∈Rp, a · X and a · Y
are both normally distributed with the same mean and variance. Then X and Y are
both multivariate normal random vectors with the same mean and variance.
Proof: In the Proof of Theorem 31.23 the proof implies that the characteristic
functions of a · X and a · Y are both of the form
eitme−1
2 σ2t2.
Then as in the proof of that theorem, it must be the case that
m =
p
X
j=1
ajmj
where E (Xi) = mi = E (Yi) and
σ2
=
a∗E
¡
(X −m) (X −m)∗¢
a
=
a∗E
¡
(Y −m) (Y −m)∗¢
a
and this last equation must hold for every a. Therefore,
E
¡
(X −m) (X −m)∗¢
= E
¡
(Y −m) (Y −m)∗¢
≡Σ
and so the characteristic function of both X and Y is eis·me−1
2 s∗Σs as in the proof
of Theorem 31.23. This proves the corollary.
Theorem 31.25 Suppose X = (X1, · · ·, Xp) is normally distributed with mean m
and covariance Σ. Then if X1 is uncorrelated with any of the Xi, meaning
E ((X1 −m1) (Xj −mj)) = 0 for j > 1,
then X1 and (X2, · · ·, Xp) are both normally distributed and the two random vectors
are independent. Here mj ≡E (Xj) . More generally, if the covariance matrix is a
diagonal matrix, the random variables, {X1, · · ·, Xp} are linearly independent.
Proof: From Theorem 31.21
Σ = E
¡
(X −m) (X −m)∗¢
.

31.3.
THE MULTIVARIATE NORMAL DISTRIBUTION
873
Then by assumption,
Σ =
µ
σ2
1
0
0
Σp−1
¶
.
(31.10)
I need to verify that if E ∈HX1 (σ (X1)) and F ∈H(X2,···,Xp) (σ (X2, · · ·, Xp)),
then
P (E ∩F) = P (E) P (F) .
Let E = X−1
1
(A) and
F = (X2, · · ·, Xp)−1 (B)
where A and B are Borel sets in R and Rp−1 respectively. Thus I need to verify
that
P ([(X1, (X2, · · ·, Xp)) ∈(A, B)]) =
µ(X1,(X2,···,Xp)) (A × B) = µX1 (A) µ(X2,···,Xp) (B) .
(31.11)
Using 31.10, Fubini’s theorem, and deﬁnitions,
µ(X1,(X2,···,Xp)) (A × B) =
Z
Rp XA×B (x)
1
(2π)p/2 det (Σ)1/2 e
−1
2 (x−m)∗Σ−1(x−m)dx
=
Z
R
XA (x1)
Z
Rp−1 XB (X2, · · ·, Xp) ·
1
(2π)(p−1)/2 √
2π (σ2
1)1/2 det (Σp−1)1/2 e
−(x1−m1)2
2σ2
1
·
e
−1
2 (x′−m′)
∗Σ−1
p−1
³
x
′−m′´
dx′dx1
where x′ = (x2, · · ·, xp) and m′ = (m2, · · ·, mp) . Now this equals
Z
R
XA (x1)
1
p
2πσ2
1
e
−(x1−m1)2
2σ2
1
Z
B
1
(2π)(p−1)/2 det (Σp−1)1/2 ·
(31.12)
e
−1
2 (x′−m′)
∗Σ−1
p−1
³
x
′−m′´
dx′dx.
(31.13)
In case B = Rp−1, the inside integral equals 1 and
λX1 (A)
=
λ(X1,(X2,···,Xp))
¡
A × Rp−1¢
=
Z
R
XA (x1)
1
p
2πσ2
1
e
−(x1−m1)2
2σ2
1
dx1
which shows X1 is normally distributed as claimed. Similarly, letting A = R,
λ(X2,···,Xp) (B)
=
λ(X1,(X2,···,Xp)) (R × B)
=
Z
B
1
(2π)(p−1)/2 det (Σp−1)1/2 e
−1
2 (x′−m′)
∗Σ−1
p−1
³
x
′−m′´
dx′

874
RANDOM VARIABLES AND BASIC PROBABILITY
and (X2, · · ·, Xp) is also normally distributed with mean m′ and covariance Σp−1.
Now from 31.12, 31.11 follows. In case the covariance matrix is diagonal, the above
reasoning extends in an obvious way to prove the random variables, {X1, · · ·, Xp}
are independent.
However, another way to prove this is to use Proposition 31.17 on Page 865 and
consider the characteristic function. Let E (Xj) = mj and
P =
p
X
j=1
tjXj.
Then since X is normally distributed and the covariance is a diagonal,
D ≡



σ2
1
0
...
0
σ2
p



,
E
¡
eiP ¢
=
E
³
eit·(X−m)´
= eit·me−1
2 t∗Σt
=
exp


p
X
j=1
itjmj −1
2t2
jσ2
j


(31.14)
=
p
Y
j=1
exp
µ
itjmj −1
2t2
jσ2
j
¶
Also,
E
¡
eitjXj¢
=
E

exp

itjXj +
X
k̸=j
i0Xk




=
exp
µ
itjmj −1
2t2
jσ2
j
¶
With 31.14, this shows
E
¡
eiP ¢
=
p
Y
j=1
E
¡
eitjXj¢
which shows by Proposition 31.17 that the random variables,
{X1, · · ·, Xp}
are independent. This proves the theorem.

31.4.
THE CENTRAL LIMIT THEOREM
875
31.4
The Central Limit Theorem
The central limit theorem is one of the most marvelous theorems in mathematics.
It can be proved through the use of characteristic functions. Recall for x ∈Rp,
||x||∞≡max {|xj| , j = 1, · · ·, p} .
Also recall the deﬁnition of the distribution function for a random vector, X.
FX (x) ≡P (Xj ≤xj, j = 1, · · ·, p) .
Deﬁnition 31.26 Let {Xn} be random vectors with values in Rp. Then {λXn}∞
n=1
is called “tight” if for all ε > 0 there exists a compact set, Kε such that
λXn ([x /∈Kε]) < ε
for all λXn.
Lemma 31.27 If Xn, X are random vectors with values in Rpsuch that
lim
n→∞φXn (t) = φX (t)
for all t, then {λXn}∞
n=1 is tight.
Proof: Let ej be the jth standard unit basis vector.
¯¯¯¯
1
u
Z u
−u
¡
1 −φXn (tej)
¢
dt
¯¯¯¯
=
¯¯¯¯
1
u
Z u
−u
µ
1 −
Z
Rp eitxjdλXn
¶
dt
¯¯¯¯
=
¯¯¯¯
Z
Rp
1
u
Z u
−u
¡
1 −eitxj¢
dtdλXn (x)
¯¯¯¯
=
¯¯¯¯2
Z
Rp
µ
1 −sin (uxj)
uxj
¶
dλXn (x)
¯¯¯¯
≥
2
Z
[|xj|≥2
u]
µ
1 −
1
|uxj|
¶
dλXn (x)
≥
2
Z
[|xj|≥2
u]
µ
1 −
1
|u| (2/u)
¶
dλXn (x)
=
Z
[|xj|≥2
u]
1dλXn (x)
=
λXn
µ·
x : |xj| ≥2
u
¸¶
.
If ε > 0 is given, there exists r > 0 such that if u ≤r,
1
u
Z u
−u
(1 −φX (tej)) dt < ε/p

876
RANDOM VARIABLES AND BASIC PROBABILITY
for all j = 1, · · ·, p and so, by the dominated convergence theorem, the same is true
with φXn in place of φX provided n is large enough, say n ≥N (u). Thus, if u ≤r,
and n ≥N (u),
λXn
µ·
x : |xj| ≥2
u
¸¶
< ε/p
for all j ∈{1, · · ·, p}. It follows that for u ≤r and n ≥N (u) ,
λXn
µ·
x : ||x||∞≥2
u
¸¶
< ε.
This proves the lemma because there are only ﬁnitely many measures, λXn for
n < N (u) and the compact set can be enlarged ﬁnitely many times to obtain a
single compact set, Kε such that for all n, λXn ([x /∈Kε]) < ε. This proves the
lemma.
Lemma 31.28 If φXn (t) →φX (t) for all t, then whenever ψ ∈S,
λXn (ψ) ≡
Z
Rp ψ (y) dλXn (y) →
Z
Rp ψ (y) dλX (y) ≡λX (ψ)
as n →∞.
Proof: Recall that if X is any random vector, its characteristic function is given
by
φX (y) ≡
Z
Rp eiy·xdλX (x) .
Also remember the inverse Fourier transform. Letting ψ ∈S, the Schwartz class,
F −1 (λX) (ψ)
≡
λX
¡
F −1ψ
¢
≡
Z
Rp F −1ψdλX
=
1
(2π)p/2
Z
Rp
Z
Rp eiy·xψ (x) dxdλX (y)
=
1
(2π)p/2
Z
Rp ψ (x)
Z
Rp eiy·xdλX (y) dx
=
1
(2π)p/2
Z
Rp ψ (x) φX (x) dx
and so, considered as elements of S∗,
F −1 (λX) = φX (·) (2π)−(p/2) ∈L∞.
By the dominated convergence theorem
(2π)p/2 F −1 (λXn) (ψ)
≡
Z
Rp φXn (t) ψ (t) dt
→
Z
Rp φX (t) ψ (t) dt
=
(2π)p/2 F −1 (λX) (ψ)

31.4.
THE CENTRAL LIMIT THEOREM
877
whenever ψ ∈S. Thus
λXn (ψ)
=
FF −1λXn (ψ) ≡F −1λXn (Fψ) →F −1λX (Fψ)
≡
FF −1λX (ψ) = λX (ψ).
This proves the lemma.
Lemma 31.29 If φXn (t) →φX (t) , then if ψ is any bounded uniformly continuous
function,
lim
n→∞
Z
Rp ψdλXn =
Z
Rp ψdλX.
Proof: Let ε > 0 be given, let ψ be a bounded function in C∞(Rp). Now let
η ∈C∞
c (Qr) where Qr ≡[−r, r]p satisfy the additional requirement that η = 1 on
Qr/2 and η (x) ∈[0, 1] for all x. By Lemma 31.27 the set, {λXn}∞
n=1 , is tight and
so if ε > 0 is given, there exists r suﬃciently large such that for all n,
Z
[x/∈Qr/2]
|1 −η| |ψ| dλXn < ε
3,
and
Z
[x/∈Qr/2]
|1 −η| |ψ| dλX < ε
3.
Thus,
¯¯¯¯
Z
Rp ψdλXn −
Z
Rp ψdλX
¯¯¯¯ ≤
¯¯¯¯
Z
Rp ψdλXn −
Z
Rp ψηdλXn
¯¯¯¯ +
¯¯¯¯
Z
Rp ψηdλXn −
Z
Rp ψηdλX
¯¯¯¯ +
¯¯¯¯
Z
Rp ψηdλX −
Z
Rp ψdλX
¯¯¯¯
≤2ε
3 +
¯¯¯¯
Z
Rp ψηdλXn −
Z
Rp ψηdλX
¯¯¯¯ < ε
whenever n is large enough by Lemma 31.28 because ψη ∈S. This establishes the
conclusion of the lemma in the case where ψ is also inﬁnitely diﬀerentiable. To
consider the general case, let ψ only be uniformly continuous and let ψk = ψ ∗φk
where φk is a molliﬁer whose support is in (−(1/k) , (1/k))p. Then ψk converges
uniformly to ψ and so the desired conclusion follows for ψ after a routine estimate.
Deﬁnition 31.30 Let µ be a Radon measure on Rp. A Borel set, A, is a µ conti-
nuity set if µ (∂A) = 0 where ∂A ≡A \ interior (A).
The main result is the following continuity theorem. More can be said about
the equivalence of various criteria [9].
Theorem 31.31 If φXn (t) →φX (t) then λXn (A) →λX (A) whenever A is a λX
continuity set.

878
RANDOM VARIABLES AND BASIC PROBABILITY
Proof: First suppose K is a closed set and let
ψk (x) ≡(1 −k dist (x,K))+.
Thus, since K is closed limk→∞ψk (x) = XK (x). Choose k large enough that
Z
Rp ψkdλX ≤λX (K) + ε.
Then by Lemma 31.29, applied to the bounded uniformly continuous function ψk,
lim sup
n→∞λXn (K) ≤lim sup
n→∞
Z
ψkdλXn =
Z
ψkdλX ≤λX (K) + ε.
Since ε is arbitrary, this shows
lim sup
n→∞λXn (K) ≤λX (K)
for all K closed.
Next suppose V is open and let
ψk (x) = 1 −
³
1 −k dist
³
x, VC´´+
.
Thus ψk (x) ∈[0, 1] , ψk = 1 if dist
¡
x,V C¢
≥1/k, and ψk = 0 on V C. Since V is
open, it follows
lim
k→∞ψk (x) = XV (x).
Choose k large enough that
Z
ψkdλX ≥λX (V ) −ε.
Then by Lemma 31.29,
lim inf
n→∞λXn (V ) ≥lim inf
n→∞
Z
ψk (x) dλXn =
=
Z
ψk (x) dλX ≥λX (V ) −ε
and since ε is arbitrary,
lim inf
n→∞λXn (V ) ≥λX (V ).
Now let λX (∂A) = 0 for A a Borel set.
λX (interior (A))
≤
lim inf
n→∞λXn (interior (A)) ≤lim inf
n→∞λXn (A) ≤
lim sup
n→∞λXn (A)
≤
lim sup
n→∞λXn
¡
A
¢
≤λX
¡
A
¢
.

31.4.
THE CENTRAL LIMIT THEOREM
879
But λX (interior (A)) = λX
¡
A
¢
by assumption and so limn→∞λXn (A) = λX (A)
as claimed. This proves the theorem.
As an application of this theorem the following is a version of the central limit
theorem in the situation in which the limit distribution is multivariate normal. It
concerns a sequence of random vectors, {Xk}∞
k=1, which are identically distributed,
have ﬁnite mean m, and satisfy
sup
k
E
³
|Xk|2´
< ∞.
(31.15)
Theorem 31.32 Let {Xk}∞
k=1 be random vectors satisfying 31.15, which are in-
dependent and identically distributed with mean m and positive deﬁnite covariance
Σ ≡E
¡
(X −m) (X −m)∗¢
. Let
Zn ≡
n
X
j=1
Xj −m
√n
.
(31.16)
Then for Z ∼Np (0, Σ) ,
lim
n→∞FZn (x) = FZ (x)
(31.17)
for all x.
Proof: The characteristic function of Zn is given by
φZn (t) = E
µ
eit· Pn
j=1
Xj −µ
√n
¶
=
n
Y
j=1
E
µ
e
it·
³ Xj −µ
√n
´¶
.
By Taylor’s theorem,
eix = 1 + ix −eiθxx2
2
for some θ ∈[0, 1] which depends on x. Denoting Xj as X, this implies
e
it·
³
X−µ
√n
´
= 1 + it·X −m
√n
−eiθt· X−m
√n (t· (X −m))2
2n
where θ depends on X and t and is in [0, 1]. The above equals
1 + it·X −m
√n
−(t· (X −m))2
2n
+
³
1 −eiθt· X−m
√n
´ (t· (X −m))2
2n
.
Thus
φZn (t) =
n
Y
j=1
"
1 −E
Ã
(t· (X −m))2
2n
!

880
RANDOM VARIABLES AND BASIC PROBABILITY
+E
Ã³
1 −eiθt· X−m
√n
´ (t· (X −m))2
2n
!#
=
n
Y
j=1
·
1 −1
2nt∗Σt+ 1
2nE
³³
1 −eiθt· X−m
√n
´
(t· (X −m))2´¸
.
(31.18)
(Note (t· (X −m))2 = t∗(X −m) (X −m)∗t.) Now here is a simple inequality for
complex numbers whose moduli are no larger than one. I will give a proof of this
at the end. It follows easily by induction.
|z1 · · · zn −w1 · · · wn| ≤
n
X
k=1
|zk −wk|.
(31.19)
Also for each t, and all n large enough,
¯¯¯¯
1
2nE
³³
1 −eiθt· X−m
√n
´
(t· (X −m))2´¯¯¯¯ < 1.
Applying 31.19 to 31.18,
φZn (t) =
n
Y
j=1
µ
1 −1
2nt∗Σt
¶
+ en
where
|en|
≤
n
X
j=1
¯¯¯¯
1
2nE
³³
1 −eiθt· X−m
√n
´
(t· (X −m))2´¯¯¯¯
=
1
2
¯¯¯E
³³
1 −eiθt· X−m
√n
´
(t· (X −m))2´¯¯¯
which converges to 0 as n →∞by the Dominated Convergence theorem. Therefore,
lim
n→∞
¯¯¯¯φZn (t) −
µ
1 −t∗Σt
2n
¶n¯¯¯¯ = 0
and so
lim
n→∞φZn (t) = e−1
2 t∗Σt = φZ (t)
where Z ∼Np (0, Σ). Therefore, FZn (x) →FZ (x) for all x because Rx ≡Qp
k=1(−∞, xk]
is a set of λZ continuity due to the assumption that λZ ≪mp which is implied by
Z ∼Np (0, Σ). This proves the theorem.
Here is the proof of the little inequality used above. The inequality is obviously
true if n = 1. Assume it is true for n. Then since all the numbers have absolute
value no larger than one,
¯¯¯¯¯
n+1
Y
i=1
zi −
n+1
Y
i=1
wi
¯¯¯¯¯
≤
¯¯¯¯¯
n+1
Y
i=1
zi −zn+1
n
Y
i=1
wi
¯¯¯¯¯
+
¯¯¯¯¯zn+1
n
Y
i=1
wi −
n+1
Y
i=1
wi
¯¯¯¯¯

31.5.
BROWNIAN MOTION
881
≤
¯¯¯¯¯
n
Y
i=1
zi −
n
Y
i=1
wi
¯¯¯¯¯ + |zn+1 −wn+1|
≤
n+1
X
k=1
|zk −wk|
by induction.
Suppose X is a random vector with covariance Σ and mean m, and suppose also
that Σ−1 exists. Consider Σ−(1/2) (X −m) ≡Y. Then E (Y) = 0 and
E (YY∗)
=
E
³
Σ−(1/2) (X −m) (X∗−µ) Σ−(1/2)´
=
Σ−(1/2)E ((X −m) (X∗−µ)) Σ−(1/2) = I.
Thus Y has zero mean and covariance I. This implies the following corollary to
Theorem 31.32.
Corollary 31.33 Let independent identically distributed random variables,
{Xj}∞
j=1
have mean m and positive deﬁnite covariance Σ where Σ−1 exists. Then if
Zn ≡
n
X
j=1
Σ−(1/2) (Xj −µ)
√n
,
it follows that for Z ∼Np (0,I) ,
FZn (x) →FZ (x)
for all x.
31.5
Brownian Motion
Deﬁnition 31.34 A stochastic process is a set of random vectors, {Xt}t≥0.
Brownian motion is a special kind of stochastic process. I will construct it and
then summarize its properties.
First recall the Kolmogorov extension theorem listed next for convenience. In
this theorem, Mt was a metric space having closed balls compact and I was a totally
ordered index set. From now on Mt will equal Rn and the index set, I will be [0, ∞).
Theorem 31.35 (Kolmogorov extension theorem) For each ﬁnite set
J = (t1, · · ·, tn) ⊆I,

882
RANDOM VARIABLES AND BASIC PROBABILITY
suppose there exists a Borel probability measure, νJ = νt1···tn deﬁned on the Borel
sets of Q
t∈J Mt such that if
(t1, · · ·, tn) ⊆(s1, · · ·, sp) ,
then
νt1···tn (Ft1 × · · · × Ftn) = νs1···sp
¡
Gs1 × · · · × Gsp
¢
(31.20)
where if si = tj, then Gsi = Ftj and if si is not equal to any of the indices, tk,
then Gsi = M ′
si. Then there exists a probability space, (Ω, P, F) and measurable
functions, Xt : Ω→Mt for each t ∈I such that for each (t1 · · · tn) ⊆I,
νt1···tn (Ft1 × · · · × Ftn) = P ([Xt1 ∈Ft1] ∩· · · ∩[Xtn ∈Ftn]) .
(31.21)
Deﬁnition 31.36 For x, y ∈Rn and t > 0 deﬁne
p (t, x, y) ≡
1
(2πt)n/2 exp
Ã
−|y −x|2
2t
!
.
Then considered as a function of y this is a normal distribution with mean x and
covariance tI. In case t = 0 this is deﬁned to be the measure δx which is deﬁned by
δx (E) = 1 if x ∈E and 0 if x /∈E.
Now deﬁne for each increasing list (t1, t2, · · ·, tk) , a measure deﬁned as follows.
For F a Borel set in Rnk,
νt1t2···tk (F)
≡
Z
F
p (t1, x, y1) p (t2 −t1, y1, y2)
· · ·p (tk −tk−1, yk−1, yk) dy1dy2 · · · dyk.
(31.22)
Since
R
Rn p (s, x, y) dy = 1 whenever s ≥0, this shows the conditions of the Kol-
mogorov extension theorem are satisﬁed for these measures and therefore there
exists a probability space, (Ω, F, P) and measurable functions, Bt for each t ≥0
such that whenever the Fj are Borel sets,
νt1t2···tk (Ft1 × · · · × Ftk) = P ((Bt1, · · ·, Btk) ∈Ft1 × · · · × Ftk)
Lemma 31.37 Letting Z = (Bt1, · · ·, Btk) ∈Rnk it follows Z is normally dis-
tributed. Its mean is
¡
x
· · ·
x
¢
∈Rnk
and its covariance is the nk × nk matrix








t1In
t1In
t1In
· · ·
t1In
t1In
t2In
t2In
· · ·
t2In
t1In
t2In
...
...
...
...
...
...
t1In
t2In
· · ·
· · ·
tkIn








.

31.5.
BROWNIAN MOTION
883
Proof: To show this use Theorem 31.23. The components of Btj are indepen-
dent and normally distributed because Btj is distributed as y →p (tj, x, y) which
is deﬁned above. The oﬀdiagonal terms of the correlation matrix are zero and so
by Theorem 31.25 the components are independent and all normally distributed.
Denote by Btjr the rth component of Btj. Thus the mean of Btjr is xr and the
variance of Btjr is tj. Also a · Btj is normally distributed with mean P arxr. To
verify Z is normally distributed, it suﬃces to show that a · Z is normally distributed
for a = (a1, · · ·, ak). Consider the case where k = 2. Then Z has values in R2n. I
will directly calculate the characteristic function for Z in this case and then note
that a similar pattern will hold for larger k.
E (exp(iu · Z))
=
Z Z
p (t1, x, y1) p (t2 −t1, y1, y2) eiu1·y1eiu2·y2dy2dy1
=
Z
p (t1, x, y1) eiu1·y1
Z
p (t2 −t1, y1, y2) eiu2·y2dy2dy1
=
Z
p (t1, x, y1) eiu1·y1
µ
exp
µ
iu2 · y1 +
µ
−1
2 (u∗
2 (t2 −t1) Iu2)
¶¶¶
dy1
=
exp
µ
−1
2 (u∗
2 (t2 −t1) Iu2)
¶ Z
p (t1, x, y1) eiu1·y1 (exp (iu2 · y1)) dy1
=
exp
µ
−1
2 (u∗
2 (t2 −t1) Iu2)
¶ Z
p (t1, x, y1) ei(u1+u2)·y1dy1
=
exp
µ
−1
2 (u∗
2 (t2 −t1) Iu2)
¶
exp
µ
−1
2 (u1 + u2)∗t1I (u1 + u2)
¶
· exp (i (u1 + u2) · x)
=
exp
µ
−1
2
£
(u∗
2 (t2 −t1) Iu2) + (u1 + u2)∗t1I (u1 + u2)
¤¶
· exp (i (u1 + u2) · x) .
The expression (u∗
2 (t2 −t1) Iu2) + (u1 + u2)∗t1I (u1 + u2) equals
¡
u1
u2
¢ µ
t1I
t1I
t1I
t2I
¶ µ
u1
u2
¶
and the expression i (u1 + u2) · x equals
i
¡ u1
u2
¢
·
¡ x
x ¢
and so in the case that k = 2, this shows Z is normally distributed with mean
¡
x
x
¢
and covariance
µ
t1I
t1I
t1I
t2I
¶
.
The pattern continues in this way. In general the mean is
¡
x
· · ·
x
¢

884
RANDOM VARIABLES AND BASIC PROBABILITY
and the covariance is of the form








t1Ik
t1Ik
t1Ik
· · ·
t1Ik
t1Ik
t2Ik
t2Ik
· · ·
t2Ik
t1Ik
t2Ik
...
...
...
...
...
...
t1Ik
t2Ik
· · ·
· · ·
tkIk








This proves the lemma.
Continuing to follow [42],
E
³
|Bt −x|2´
=
n
X
r=1
E
³
(Btr −xr)2´
=
n
X
r=1
t = nt.
Then let s < t.
E
¡
(Bt −x)∗(Bs −x)
¢
=
Z Z
p (s, x, y1) p (t −s, y1, y2) (y1 −x) · (y2 −x) dy1dy2
=
Z
p (s, x, y1) (y1 −x) ·
Z
p (t −s, y1, y2) (y2 −x) dy2dy1
Consider the inner integral.
Z
p (t −s, y1, y2) (y2 −x) dy2
=
Z
p (t −s, y1, y2) ((y2 −y1) + (y1 −x)) dy2
=
Z
p (t −s, y1, y2) (y1 −x) dy2 = (y1 −x) .
Therefore,
E
¡
(Bt −x)∗(Bs −x)
¢
=
Z
p (s, x, y1) |y1 −x|2 dy1
=
E
³
|Bs −x|2´
= ns
Now for t ≥s,
E
³
|Bt −Bs|2´
=
E
³
|Bt −x|2 + |Bs −x|2 −2 (Bt −x) · (Bs −x)
´
=
nt + ns −2ns = n (t −s) .
Lemma 31.38 Bt has independent increments. This means if t1 < t2 < · · · < tk,
the random variables,
Bt1, Bt2 −Bt1, · · ·, Btk −Btk−1
are independent. In addition, these random variables are normally distributed.

31.5.
BROWNIAN MOTION
885
Proof: Bt1 is normal and so is each of the Btj. Also I claim that Btj −Btj−1
is normal with mean 0. I will show this next.
E
¡
exp
¡
iu·
¡
Btj −Btj−1
¢¢¢
= E
¡
exp
¡
iu · Btj
¢
exp
¡
−iu · Btj−1
¢¢
=
Z Z
p (tj−1, x, y1) p (tj −tj−1, y1, y2) exp (−iu · y1) exp (iu · y2) dy2dy1
=
Z
p (tj−1, x, y1) exp (−iu · y1)
Z
p (tj −tj−1, y1, y2) exp (iu · y2) dy2dy1
=
Z
p (tj−1, x, y1) exp (−iu · y1) exp (iu · y1) exp
µ
−1
2 (tj −tj−1) |u|2
¶
dy1
=
exp
µ
−1
2 (tj −tj−1) |u|2
¶
.
(31.23)
Therefore, Btj −Btj−1 is normal with covariance (tj −tj−1) I and mean 0.
Next let Z =
¡
Bt1, Bt2 −Bt1, · · ·, Btk −Btk−1
¢
. I need to verify Z is normally
distributed. Let u = (u1, · · ·, uk) .
E (exp (iu · Z)) = E
Ã
exp (iu1 · Bt1)
k
Y
r=2
exp
¡
iur ·
¡
Btr −Btr−1
¢¢
!
=
Z
Rn · · ·
Z
Rn p (t1, x, y1) p (t2 −t1, y1, y2) · · · p (tk −tk−1, yk−1, yk) ·
exp (iu1 · y1)
k
Y
r=2
exp (iur · (yr −yr−1)) dykdyk−1 · · · dy1.
The inside integral is
Z
p (tk −tk−1, yk−1, yk) exp (iuk · (yk −yk−1)) = exp
µ
−1
2 (tk −tk−1) |uk|2
¶
which has no y variables left so I can factor it out and then work on the next inside
integral which gives
exp
µ
−1
2 (tk−1 −tk−2) |uk−1|2
¶
which also can be factored out. Continuing this way eventually obtains
k
Y
j=1
exp
µ
−1
2 (tj −tj−1) |uk|2
¶ Z
p (t1, x, y1) exp (iu1 · y1) dy1
=
k
Y
j=1
exp
µ
−1
2 (tj −tj−1) |uk|2
¶
exp (iu1 · x) exp
µ
−1
2t1 |u1|2
¶
.

886
RANDOM VARIABLES AND BASIC PROBABILITY
Now let m = (x, 0, · · ·, 0) and let Σ be the matrix,
=





t1In
0
(t2 −t1) In
...
0
(tk −tk−1) In





Then the above reduces to
exp (iu · m) exp
µ
−1
2u∗Σu
¶
which shows that Z is normally distributed with covariance Σ and mean m. It also
shows that since the covariance matrix is diagonal, the component functions of Z
are independent. This proves the lemma.
Next I will consider an estimate for the Brownian motion. By 31.23 the charac-
teristic function for Bt −Bs and t > s is
E (exp (iu· (Bt −Bs))) = exp
µ
−1
2 (t −s) |u|2
¶
It follows upon taking a partial derivative with respect to uj
E (i (Btj −Bsj) exp (iu· (Bt −Bs)))
=
(−uj (t −s)) exp
µ
−1
2 (t −s) |u|2
¶
and then taking another partial derivative with respect to uj yields
E
³
−(Btj −Bsj)2 exp (iu· (Bt −Bs))
´
=
(−(t −s) −uj (t −s)) exp
µ
−1
2 (t −s) |u|2
¶
+ (−uj (t −s))2 exp
µ
−1
2 (t −s) |u|2
¶
This looks pretty good. Lets take another derivative with respect to uj
E
³
−i (Btj −Bsj)3 exp (iu· (Bt −Bs))
´
=
(−(t −s)) exp
µ
−1
2 (t −s) |u|2
¶
+ (−(t −s) −uj (t −s)) (−uj (t −s)) ·
exp
µ
−1
2 (t −s) |u|2
¶
2uj (t −s)2 exp
µ
−1
2 (t −s) |u|2
¶
+ (−uj (t −s))3 exp
µ
−1
2 (t −s) |u|2
¶

31.5.
BROWNIAN MOTION
887
Finally take yet another derivative with respect to uj and then let u = 0.
E
³
(Btj −Bsj)4´
= (t −s)2 + 2 (t −s)2 = 3 (t −s)2 .
This shows
E


n
X
j=1
(Btj −Bsj)4

= 3n (t −s)2 .
But also Pn
j=1 (Btj −Bsj)4 ≥(1/n) |Bt −Bs|2 and so
E
³
|Bt −Bs|4´
≤3n2 (t −s)2 .
(31.24)
With more work, you can show the 3n2 can be replaced with n (n + 2) but it is the
inequality which is of interest here.
Before going further here is an interesting elementary lemma.
Lemma 31.39 Let D be a dense subset of an interval, I = [0, T] and suppose
X : D →Rn satisﬁes
|X (d) −X (d′)| ≤C |d −d′|γ
for all d′, d ∈D. Then X extends uniquely to Y deﬁned on [0, T] such that
|Y (t) −Y (t′)| ≤C |t −t′|γ .
Proof: Let t ∈I and let dk →t where dk ∈D. Then {X (dk)} is a Cauchy
sequence because |X (dk) −X (dm)| ≤C |dk −dm|γ . Therefore, X (dk) converges.
The thing it converges to will be called Y (t) . Note this is well deﬁned, giving X (t)
if t ∈D. Also, if dk →t and d′
k →t, then |X (dk) −X (d′
k)| ≤C |dk −d′
k|γ and so
X (dk) and X (d′
k) converge to the same thing. Therefore, it makes sense to deﬁne
Y (t) ≡limd→t X (d). It only remains to verify the estimate. But letting |d −t| and
|d′ −t′| be small enough,
|Y (t) −Y (t′)|
=
|X (d) −X (d′)|
≤
C |d′ −d| + ε ≤C |t −t′| + 2ε.
Since ε is arbitrary, this proves the existence part of the lemma. Uniqueness follows
from observing that Y (t) must equal limd→t X (d). This proves the lemma.
The following is a very interesting theorem called the Kolmogorov ˇCentsov con-
tinuity theorem[33].
Theorem 31.40 Suppose Xt is a random vector for each t ∈[0, ∞). Suppose also
that for all T > 0 there exists a constant, C and positive numbers, α, β such that
E (|Xt −Xs|α) ≤C |t −s|1+β
(31.25)
Then there exist random vectors, Yt such that for a.e. ω, t →Yt (ω) is continuous
and P ([|Xt −Yt| > 0]) = 0.

888
RANDOM VARIABLES AND BASIC PROBABILITY
Proof: Let rm
j denote j
¡ T
2m
¢
where j ∈{0, 1, · · ·, 2m} . Also let Dm =
©
rm
j
ª2m
j=1
and D = ∪∞
m=1Dm. Consider the set,
[|Xt −Xs| > δ]
for k = 1, 2, · · ·. By 31.25,
P ([|Xt −Xs| > δ]) δα
≤
Z
[|Xt−Xs|>δ]
|Xt −Xs|α dP
≤
C |t −s|1+β .
(31.26)
Letting t = rk
j+1, s = rk
j ,and δ = 2−γk where
γ ∈
µ
0, β
α
¶
,
this yields
P
³h¯¯¯Xrk
j+1 −Xrk
j
¯¯¯ > 2−γki´
≤C2αγk ¡
T2−k¢1+β .
There are 2k of these diﬀerences and so letting
Ek =
h¯¯¯Xrk
j+1 −Xrk
j
¯¯¯
α
> 2−γk for all j
i
it follows
P (Ek) ≤C2αγk ¡
T2−k¢1+β 2k = C2k(αγ−β)T 1+β.
Since γ < β/α,
∞
X
k=1
P (Ek) ≤CT 1+β
∞
X
k=1
2k(αγ−β) < ∞
and so by the Borel Cantelli lemma, Lemma 31.2, there exists a set of measure
zero, E, such that if ω /∈E, then ω is in only ﬁnitely many Ek. In other words, for
ω /∈E, there exists N (ω) such that if k > N (ω) , then for each j,
¯¯¯Xrk
j+1 (ω) −Xrk
j (ω)
¯¯¯ ≤2−γk.
(31.27)
Claim: If n ≥N (ω) for ω /∈E and if d, d′ ∈Dm for m > n such that
|d −d′| < T2−n, then
|Xd′ (ω) −Xd (ω)| ≤2
m
X
j=n+1
2−γj.
Proof of the claim: Suppose d′ < d. Suppose ﬁrst m = n + 1. Then d =
(k + 1) T2−(n+1) and d′ = kT2−(n+1). Then from 31.27
|Xd′ (ω) −Xd (ω)| ≤2−γ(n+1) ≤2
n+1
X
j=n+1
2−γj.

31.5.
BROWNIAN MOTION
889
Suppose the claim is true for some m > n. Then let d, d′ ∈Dm+1 with |d −d′| <
T2−n. Let d′ ≤d′
1 ≤d1 ≤d where d1, d′
1 are in Dm and d′
1 is the smallest element
of Dm which is at least as large as d′ and d1 is the largest element of Dm which is
no larger than d. Then |d′ −d′
1| ≤T2−(m+1) and |d1 −d| ≤T2−(m+1) while all of
these are still in Dm+1 which contains Dm. Therefore, from 31.27 and induction,
|Xd′ (ω) −Xd (ω)|
≤
¯¯Xd′ (ω) −Xd′
1 (ω)
¯¯ +
¯¯Xd′
1 (ω) −Xd1 (ω)
¯¯ + |Xd1 (ω) −Xd (ω)|
≤
2 × 2−γ(m+1) + 2
m
X
j=n+1
2−γj = 2
m+1
X
j=n+1
2−γj
which proves the claim.
From this estimate, it follows that if d, d′ ∈D and |d −d′| < T2−n where
n ≥N (ω) , then d, d′ are both in some Dm where m > n and so
|Xd′ (ω) −Xd (ω)|
≤
2
m
X
j=n+1
2−γj ≤2
∞
X
j=n+1
2−γj
=
2
1 −2−γ
¡
2−γ¢n+1 .
(31.28)
Now let d, d′ ∈D and suppose |d −d′| < T2−N(ω). Then let n ≥N (ω) such that
T2−(n+1) ≤|d −d′| < T2−n
Then from 31.28,
|Xd′ (ω) −Xd (ω)|
≤
2
T γ (1 −2−γ)
¡
T2−n+1¢γ
≤
2
T γ (1 −2−γ) (|d −d′|)γ
which shows t →Xt (ω) is Holder continuous on D.
By Lemma 31.39, one can deﬁne Yt (ω) to be the unique function which extends
d →Xd (ω) oﬀD for ω /∈E and let Yt (ω) = 0 if ω ∈E. Then ω →Yt (ω) is
measurable because it is the pointwise limit of measurable functions. It remains to
verify the claim that Yt (ω) = Xt (ω) a.e.
X[|Yt−Xt|>ε] (ω) ≤lim inf
d→t X[|Xd−Xt|>ε] (ω)
and so by Fatou’s theorem
P ([|Yt −Xt| > ε])
=
Z
X[|Yt−Xt|>ε] (ω) dP
≤
Z
lim inf
d→t X[|Xd−Xt|>ε] (ω) dP
≤
lim inf
d→t
Z
X[|Xd−Xt|>ε] (ω) dP
≤
lim inf
d→t
C
εα |d −t|1+β = 0.

890
RANDOM VARIABLES AND BASIC PROBABILITY
Therefore,
P ([|Yt −Xt| > 0])
=
P
µ
∪∞
k=1
·
|Yt −Xt| > 1
k
¸¶
≤
∞
X
k=1
P
µ·
|Yt −Xt| > 1
k
¸¶
= 0.
This proves the theorem.
Deﬁnition 31.41 Let Xt and Yt be random vectors for each t ∈[0, ∞). Then Yt
is said to be a version of Xt if there exists a set of measure zero, E such that for
ω /∈E, Xt (ω) = Yt (ω) a.e. ω for all t ∈[0, T).
In terms of this deﬁnition, the following corollary follows.
Corollary 31.42 Letting Bt be Brownian motion deﬁned above, Bt has a Holder
continuous version.
Proof: This follows from Theorem 31.40 and 31.24.
An important observation related to this corollary is the product measurability
of Brownian motion.
Corollary 31.43 Let B be the Borel sets on [0, T] and let F be the σ algebra for
the underlying probability space. Then there exists a set of measure zero, N ∈F
such that (t, ω) →XN (ω) Bt (ω) is B × F measurable.
Proof: Let N be the set of measure zero oﬀwhich t →Bt (ω) is continuous.
Letting tm
k = 2−mTk consider for ω /∈N
Bm
t (ω) ≡
2m
X
k=1
Btm
k (ω) X[tm
k−1,tm
k ) (t) .
Then this is a ﬁnite sum of B × F measurable functions and so Bm is itself B × F
measurable. Also, by continuity of t →Bt (ω) , it follows that limm→∞XN (ω) Bm
t (ω) =
XN (ω) Bt (ω) and this shows the result.
From now on, when Bt is referred to, it will mean XNBt so that (t, ω) →Bt (ω)
is product measurable and t →Bt (ω) will also be continuous.
Summary of properties of Brownian motion
The above development has proved the following theorem on Brownian motion.
Theorem 31.44 There exists a probability space, (Ω, F, P) and random vectors,
Bt for t ∈[0, ∞) which satisfy the following properties.
1. For Z = (Bt1, · · ·, Btk) ∈Rnk it follows Z is normally distributed. Its mean
is
¡
x
· · ·
x
¢
∈Rnk

31.5.
BROWNIAN MOTION
891
2. Bt has independent increments. This means if t1 < t2 < · · · < tk, the random
variables,
Bt1, Bt2 −Bt1, · · ·, Btk −Btk−1
are independent and normally distributed. Note this implies the kth compo-
nents must also be independent. Also Btj −Btj−1 is normal with covariance
(tj −tj−1) I and mean 0. In addition to this, the kth component of Bt is
normally distributed with density function
p (t, xk,y) ≡
1
(2πt)1/2 exp
Ã
−|y −xk|2
2t
!
This follows from the distribution of Bt which has a density function
p (t, x, y) ≡
1
(2πt)n/2 exp
Ã
−|y −x|2
2t
!
3. E
³
|Bt −Bs|4´
≤3n2 (t −s)2 , For t > s,
E
³
|Bt −Bs|2´
=
n (t −s) , E
¡
(Bt −x)∗(Bs −x)
¢
= ns
E (Bt −Bs)
=
0,
4. t →Bt (ω) is Holder continuous and (t, ω) →Bt (ω) is B × F measurable.

892
RANDOM VARIABLES AND BASIC PROBABILITY

Conditional Expectation And
Martingales
32.1
Conditional Expectation
Deﬁnition 32.1 Let (Ω, M, P) be a probability space and let S ⊆F be two σ
algebras contained in M. Let f be F measurable and in L1 (Ω). Then E (f|S) ,
called the conditional expectation of f with respect to S is deﬁned as follows:
E (f|S) is S measurable
For all E ∈S,
Z
E
E (f|S) dP =
Z
E
fdP
Lemma 32.2 The above is well deﬁned. Also, if S ⊆F then
E (X|S) = E (E (X|F) |S) .
(32.1)
If Z is bounded and measurable in F then
ZE (X|F) = E (ZX|F) .
(32.2)
Proof: Let a ﬁnite measure on S, µ be given by
µ (E) ≡
Z
E
fdP.
Then µ ≪P and so by the Radon Nikodym theorem, there exists a unique S
measurable function, E (f|S) such that
Z
E
fdP ≡µ (E) =
Z
E
E (f|S) dP
for all E ∈S.
893

894
CONDITIONAL EXPECTATION AND MARTINGALES
Let F ∈S. Then
Z
F
E (E (X|F) |S) dP
≡
Z
F
E (X|F) dP
≡
Z
F
XdP ≡
Z
F
E (X|S) dP
and so, by uniqueness, E (E (X|F) |S) = E (X|S). This shows 32.1.
To establish 32.2, note that if Z = XF where F ∈F,
Z
XF E (X|F) dP =
Z
XF XdP =
Z
E (XF X|F) dP
which shows 32.2 in the case where Z is the characteristic function of a set in F.
It follows this also holds for simple functions. Let {sn} be a sequence of simple
functions which converges uniformly to Z and let F ∈F. Then by what was just
shown,
Z
F
snE (X|F) dP =
Z
F
snXdP.
Then passing to the limit using the dominated convergence theorem, yields
Z
F
ZE (X|F) dP =
Z
F
ZXdP ≡
Z
F
E (ZX|F) dP.
Since this holds for every F ∈F, this shows 32.2.
The next major result is a generalization of Jensen’s inequality whose proof
depends on the following lemma about convex functions.
Lemma 32.3 Let I be an open interval on R and let φ be a convex function deﬁned
on I. Then there exists a sequence {(an, bn)} such that
φ (x) = sup {anx + bn, n = 1, · · ·} .
Proof: Let x ∈I and let t > x. Then by convexity of φ,
φ (x + λ (t −x)) −φ (x)
λ (t −x)
≤φ (x) (1 −λ) + λφ (t) −φ (x)
λ (t −x)
= φ (t) −φ (x)
t −x
.
Therefore t →φ(t)−φ(x)
t−x
is increasing if t > x. If t < x
φ (x + λ (t −x)) −φ (x)
λ (t −x)
≥φ (x) (1 −λ) + λφ (t) −φ (x)
λ (t −x)
= φ (t) −φ (x)
t −x

32.1.
CONDITIONAL EXPECTATION
895
and so t →φ(t)−φ(x)
t−x
is increasing for t ̸= x. Let
ax ≡inf
½φ (t) −φ (x)
t −x
: t > x
¾
.
Then if t1 < x, and t > x,
φ (t1) −φ (x)
t1 −x
≤ax ≤φ (t) −φ (x)
t −x
.
Thus for all t ∈I,
φ (t) ≥ax (t −x) + φ (x).
(32.3)
Pick t2 > x. Then for all t ∈(x, t2)
ax ≤φ (t) −φ (x)
t −x
≤φ (t2) −φ (x)
t2 −x
and so
ax (t −x) + φ (x) ≤φ (t) ≤
µφ (t2) −φ (x)
t2 −x
¶
(t −x) + φ (x).
(32.4)
Pick t3 < x. Then for t3 < t < x
ax ≥φ (t) −φ (x)
t −x
≥φ (t3) −φ (x)
t3 −x
and so
ax (t −x) + φ (x) ≤φ (t) ≤
µφ (t3) −φ (x)
t3 −x
¶
(t −x) + φ (x).
(32.5)
32.4 and 32.5 imply φ is continuous. Let
ψ (x) ≡sup {ar (x −r) + φ (r) : r ∈Q ∩I}.
Then ψ is convex on I so ψ is continuous. Also ψ (r) ≥φ (r) so by 32.3,
ψ (x) ≥φ (x) ≥sup {ar (x −r) + φ (r)} ≡ψ (x).
Thus ψ (x) = φ (x) and letting Q ∩I = {rn}, an = arn and bn = arnrn + φ (rn).
This proves the lemma.
Lemma 32.4 If X ≤Y, then E (X|S) ≤E (Y |S) a.e. Also
X →E (X|S)
is linear.

896
CONDITIONAL EXPECTATION AND MARTINGALES
Proof: Let A ∈S.
Z
A
E (X|S) dP ≡
Z
A
XdP
≤
Z
A
Y dP ≡
Z
A
E (Y |S) dP.
Hence E (X|S) ≤E (Y |S) a.e. as claimed. It is obvious X →E (X|S) is linear.
Theorem 32.5 (Jensen’s inequality)Let X (ω) ∈I and let φ : I →R be convex.
Suppose
E (|X|) , E (|φ (X)|) < ∞.
Then
φ (E (X|S)) ≤E (φ (X) |S).
Proof: Let φ (x) = sup {anx + bn}. Letting A ∈S,
1
P (A)
Z
A
E (X|S) dP =
1
P (A)
Z
A
XdP ∈I a.e.
whenever P (A) ̸= 0. Hence E (X|S) (ω) ∈I a.e. and so it makes sense to consider
φ (E (X|S)). Now
anE (X|S) + bn = E (anX + bn|S) ≤E (φ (X) |S).
Thus
sup {anE (X|S) + bn}
= φ (E (X|S)) ≤E (φ (X) |S) a.e.
which proves the theorem.
32.2
Discrete Martingales
Deﬁnition 32.6 Let Sk be an increasing sequence of σ algebras which are subsets
of S and Xk be a sequence of real-valued random variables with E (|Xk|) < ∞such
that Xk is Sk measurable. Then this sequence is called a martingale if
E (Xk+1|Sk) = Xk,
a submartingale if
E (Xk+1|Sk) ≥Xk,
and a supermartingale if
E (Xk+1|Sk) ≤Xk.
An upcrossing occurs when a sequence goes from a up to b. Thus it crosses the
interval, [a, b] in the up direction, hence upcrossing. More precisely,

32.2.
DISCRETE MARTINGALES
897
Deﬁnition 32.7 Let {xi}I
i=1 be any sequence of real numbers, I ≤∞.
Deﬁne
an increasing sequence of integers {mk} as follows.
m1 is the ﬁrst integer ≥1
such that xm1 ≤a, m2 is the ﬁrst integer larger than m1 such that xm2 ≥b, m3
is the ﬁrst integer larger than m2 such that xm3 ≤a, etc. Then each sequence,
©
xm2k−1, · · ·, xm2k
ª
, is called an upcrossing of [a, b].
Proposition 32.8 Let {Xi}n
i=1 be a ﬁnite sequence of real random variables deﬁned
on Ωwhere (Ω, S, P) is a probability space. Let U[a,b] (ω) denote the number of
upcrossings of Xi (ω) of the interval [a, b]. Then U[a,b] is a random variable.
Proof: Let X0 (ω) ≡a+1, let Y0 (ω) ≡0, and let Yk (ω) remain 0 for k = 0, ···, l
until Xl (ω) ≤a. When this happens (if ever), Yl+1 (ω) ≡1. Then let Yi (ω) remain
1 for i = l + 1, · · ·, r until Xr (ω) ≥b when Yr+1 (ω) ≡0. Let Yk (ω) remain 0 for
k ≥r + 1 until Xk (ω) ≤a when Yk (ω) ≡1 and continue in this way. Thus the
upcrossings of Xi (ω) are identiﬁed as unbroken strings of ones for Yk with a zero
at each end, with the possible exception of the last string of ones which may be
missing the zero at the upper end and may or may not be an upcrossing.
Note also that Y0 is measurable because it is identically equal to 0 and that if
Yk is measurable, then Yk+1 is measurable because the only change in going from
k to k + 1 is a change from 0 to 1 or from 1 to 0 on a measurable set determined
by Xk. Now let
Zk (ω) =
½
1 if Yk (ω) = 1 and Yk+1 (ω) = 0,
0 otherwise,
if k < n and
Zn (ω) =
½
1 if Yn (ω) = 1 and Xn (ω) ≥b,
0 otherwise.
Thus Zk (ω) = 1 exactly when an upcrossing has been completed and each Zi is a
random variable.
U[a,b] (ω) =
n
X
k=1
Zk (ω)
so U[a,b] is a random variable as claimed.
The following corollary collects some key observations found in the above con-
struction.
Corollary 32.9 U[a,b] (ω) ≤the number of unbroken strings of ones in the se-
quence, {Yk (ω)} there being at most one unbroken string of ones which produces no
upcrossing. Also
Yi (ω) = ψi
³
{Xj (ω)}i−1
j=1
´
,
(32.6)
where ψi is some function of the past values of Xj (ω).
Lemma 32.10 Let φ be a convex and increasing function and suppose
{(Xn, Sn)}

898
CONDITIONAL EXPECTATION AND MARTINGALES
is a submartingale. Then if E (|φ (Xn)|) < ∞, it follows
{(φ (Xn) , Sn)}
is also a submartingale.
Proof: It is given that E (Xn+1, Sn) ≥Xn and so
φ (Xn) ≤φ (E (Xn+1, Sn)) ≤E (φ (Xn+1) |Sn)
by Jensen’s inequality.
The following is called the upcrossing lemma.
Lemma 32.11 (upcrossing lemma) Let {(Xi, Si)}n
i=1 be a submartingale and let
U[a,b] (ω) be the number of upcrossings of [a, b]. Then
E
¡
U[a,b]
¢
≤E (|Xn|) + |a|
b −a
.
Proof: Let φ (x) ≡a + (x −a)+ so that φ is an increasing convex function
always at least as large as a. By Lemma 32.10 it follows that {(φ (Xk) , Sk)} is also
a submartingale.
φ (Xk+r) −φ (Xk) =
k+r
X
i=k+1
φ (Xi) −φ (Xi−1)
=
k+r
X
i=k+1
(φ (Xi) −φ (Xi−1)) Yi +
k+r
X
i=k+1
(φ (Xi) −φ (Xi−1)) (1 −Yi).
Observe that Yi is Si−1 measurable from its construction in Proposition 32.8, Yi
depending only on Xj for j < i. Therefore, letting
Ai ≡{ω : Yi (ω) = 0},
E
Ã k+r
X
i=k+1
(φ (Xi) −φ (Xi−1)) (1 −Yi)
!
=
k+r
X
i=k+1
Z
Ω
(φ (Xi) −φ (Xi−1)) (1 −Yi) dP
=
k+r
X
i=k+1
Z
Ai
(φ (Xi) −φ (Xi−1)) dP

32.2.
DISCRETE MARTINGALES
899
because if Yi = 1, (φ (Xi) −φ (Xi−1)) (1 −Yi) = 0. Continuing this chain of formu-
las, and using the fact that Ai is Si−1 measurable, it follows from the deﬁnition of
conditional expectation and the deﬁnition of a submartingale,
=
k+r
X
i=k+1
Z
Ai
E (φ (Xi) , Si−1) dP −
Z
Ai
φ (Xi−1) dP
≥
k+r
X
i=k+1
Z
Ai
φ (Xi−1) dP −
Z
Ai
φ (Xi−1) dP = 0.
(32.7)
Now let the unbroken strings of ones for {Yi (ω)} be
{k1, · · ·, k1 + r1} , {k2, · · ·, k2 + r2} , · · ·, {km, · · ·, km + rm}
(32.8)
where m = V (ω) ≡the number of unbroken strings of ones in the sequence {Yi (ω)}.
By Corollary 32.9 V (ω) ≥U[a,b] (ω).
φ (Xn (ω)) −φ (X1 (ω))
=
n
X
k=1
(φ (Xk (ω)) −φ (Xk−1 (ω))) Yk (ω)
+
n
X
k=1
(φ (Xk (ω)) −φ (Xk−1 (ω))) (1 −Yk (ω)).
The ﬁrst sum in the above reduces to summing over the unbroken strings of ones
because the terms in which Yi (ω) = 0 contribute nothing. implies
φ (Xn (ω)) −φ (X1 (ω))
≥U[a,b] (ω) (b −a) + 0+
n
X
k=1
(φ (Xk (ω)) −φ (Xk−1 (ω))) (1 −Yk (ω))
(32.9)
where the zero on the right side results from a string of ones which does not
produce an upcrossing.
It is here that it is important that φ (x) ≥a.
Such
a string begins with φ (Xk (ω)) = a and results in an expression of the form
φ (Xk+m (ω)) −φ (Xk (ω)) ≥0 since φ (Xk+m (ω)) ≥a. If Xk had not been re-
placed with φ (Xk) , it would have been possible for φ (Xk+m (ω)) to be less than a
and the zero in the above could have been a negative number This would have been
inconvenient.
Next take the expected value of both sides in 32.9. Using 32.7, this results in
E (φ (Xn) −φ (X1))
≥
(b −a) E
¡
U[a,b]
¢
+E
Ã n
X
k=1
(φ (Xk) −φ (Xk−1)) (1 −Yk)
!
≥
(b −a) E
¡
U[a,b]
¢

900
CONDITIONAL EXPECTATION AND MARTINGALES
and this proves the lemma.
The reason for this lemma is to prove the amazing submartingale convergence
theorem.
Theorem 32.12 (submartingale convergence theorem) Let
{(Xi, Si)}∞
i=1
be a submartingale with K ≡sup E (|Xn|) < ∞.
Then there exists a random
variable, X, such that E (|X|) ≤K and
lim
n→∞Xn (ω) = X (ω) a.e.
Proof: Let a, b ∈Q and let a < b. Let U n
[a,b] (ω) be the number of upcrossings
of {Xi (ω)}n
i=1. Then let
U[a,b] (ω) ≡lim
n→∞U n
[a,b] (ω) = number of upcrossings of {Xi} .
By the upcrossing lemma,
E
³
U n
[a,b]
´
≤E (|Xn|) + |a|
b −a
≤K + |a|
b −a
and so by the monotone convergence theorem,
E
¡
U[a,b]
¢
≤K + |a|
b −a
< ∞
which shows U[a,b] (ω) is ﬁnite a.e., for all ω /∈S[a,b] where P
¡
S[a,b]
¢
= 0. Deﬁne
S ≡∪
©
S[a,b] : a, b ∈Q, a < b
ª
.
Then P (S) = 0 and if ω /∈S, {Xk}∞
k=1 has only ﬁnitely many upcrossings of every
interval having rational endpoints. Thus, for ω /∈S,
lim sup
k→∞
Xk (ω)
=
lim inf
k→∞Xk (ω)
=
lim
k→∞Xk (ω) ≡X∞(ω) .
Letting X∞(ω) = 0 for ω ∈S, Fatou’s lemma implies
Z
Ω
|X∞| dP =
Z
Ω
lim inf
n→∞|Xn| dP ≤lim inf
n→∞
Z
Ω
|Xn| dP ≤K
and so this proves the theorem.
Another very interesting result about submartingales is the Doob submartingale
estimate.

32.2.
DISCRETE MARTINGALES
901
Theorem 32.13 Let {(Xi, Si)}∞
i=1 be a submartingale. Then
P
µ
max
1≤k≤n Xk ≥λ
¶
≤1
λ
Z
Ω
X+
n dP
Proof: Let
A1
≡
[X1 ≥λ] , A2 ≡[X2 ≥λ] \ A1,
· · ·, Ak
≡
[Xk ≥λ] \
¡
∪k−1
i=1 Ai
¢
· ··
Thus each Ak is Sk measurable, the Ak are disjoint, and their union equals [max1≤k≤n Xk ≥λ] .
Therefore from the deﬁnition of a submartingale and Jensen’s inequality,
P
µ
max
1≤k≤n Xk ≥λ
¶
=
n
X
k=1
P (Ak) ≤1
λ
n
X
k=1
Z
Ak
XkdP
≤
1
λ
n
X
k=1
Z
Ak
E (Xn|Sk) dP
≤
1
λ
n
X
k=1
Z
Ak
E (Xn|Sk)+ dP
≤
1
λ
n
X
k=1
Z
Ak
E
¡
X+
n |Sk
¢
dP
=
1
λ
n
X
k=1
Z
Ak
X+
n dP = 1
λ
Z
Ω
X+
n dP.
This proves the theorem.

902
CONDITIONAL EXPECTATION AND MARTINGALES

Filtrations And Martingales
Deﬁnition 33.1 Let (Ω, F, P) be a probability space. A ﬁltration is an increasing
collection of σ algebras contained in F, one for each t ∈R, {Ft}t∈R . Let f :
[0, ∞)×Ω→R be B × F measurable where B is the σ algebra of Borel sets. Then f
is said to be Ft adapted if for each t, f (t, ·) is Ft measurable. A function is called
an adapted step function if it is of the form
f (t, ω) =
∞
X
j=0
ej (ω) X[tj,tj+1) (t)
where ej is Ftj measurable and ∪∞
j=0[tj, tj+1) = R. Of course you can replace [0, ∞)
in the above with [0, T] and this is the case of most interest. Another convention
followed will be to assume that (Ω, Ft, P) is a complete measure space. Thus all sets
of measure zero from F are in Ft. If it is not complete, you simply replace it with
its completion. This goes for F as well.
The act of replacing the measure spaces with their completions is completely
harmless. The only important idea which needs consideration is that of indepen-
dence. Suppose the σ algebras, G and H are independent and you then consider
their completions. Will the new σ algebras also be independent?
Lemma 33.2 Suppose the σ algebras, G and H are independent and let G′ and H′
be the σ algebras of the completions. Then G′ and H′ are also independent.
Proof: Let E ∈G′ and F ∈H′. Then there exists A ⊇E, B ⊇F such that
A ∈G and B ∈H and P (A) = P (E) , P (F) = P (B) . It follows that
P (E ∩F) = P (A ∩B) = P (A) P (B) = P (E) P (F) .
This proves the lemma.
This rather simple lemma shows there is no diﬃculty in assuming that any
ﬁltration contains the sets of measure zero. Next is an important lemma about
approximation with simple adapted functions. It is based on the proof outlined in
[33] which they say is from [38].
903

904
FILTRATIONS AND MARTINGALES
Lemma 33.3 Let Ft be a ﬁltration as described above and suppose f is adapted,
B × F measurable, and uniformly bounded. Then there exists a sequence of uni-
formly bounded adapted step functions, fn such that
lim
n→∞P
ÃZ T
0
(f (t, ω) −fn (t, ω))2 dt > ε
!
= 0.
(33.1)
Also in this case, there is a subsequence, fnk
lim
k→∞
Z
Ω
Z T
0
(f (t, ω) −fnk (t, ω))2 dtdP = 0.
Proof: Extend f to equal 0 for t /∈[0, T] . Let tj = j2−n and let φn (t) denote
the step function which equals j2−n on the interval [j2−n, (j + 1) 2−n). It follows
easily that if s ≥0, then φn (t −s) + s ∈[t −2−n, t). Now let
fh (t) ≡f ∗ψh (t)
where ψh (t) equals 1/h on [0, h] and zero elsewhere. Thus
fh (t) =
Z
f (t −s) ψh (s) ds = 1
h
Z t
t−h
f (s) ds.
From now on, ω /∈E where E is the exceptional set of measure zero on which
R ∞
−∞f (t, ω)2 dt = ∞. Consider
Z T
0
Z 1
0
|f (φn (t −s) + s, ω) −f (t, ω)|2 dsdt.
Z T
0
Z 1
0
|f (φn (t −s) + s, ω) −f (t, ω)|2 dsdt ≤
3
ÃZ T
0
Z 1
0
|f (φn (t −s) + s, ω) −fh (φn (t −s) + s, ω)|2 dsdt
(33.2)
+
Z T
0
Z 1
0
|fh (φn (t −s) + s, ω) −fh (t, ω)|2 dsdt
(33.3)
+
Z T
0
Z 1
0
|fh (t, ω) −f (t, ω)|2 dsdt
!
(33.4)
Consider the term in 33.2. There are disjoint intervals such that φn (t −s) is con-
stant on these intervals. Therefore, the inside integral of this term must be of the
form
mn
X
k=1
Z
Ik
|f (ck + s, ω) −fh (ck + s, ω)|2 ds

905
where the intervals, Ik are disjoint, ck is of the form j2−n, and the union of these
intervals equals [0, 1]. Therefore, there are other disjoint intervals, Jk such that this
term equals
mn
X
k=1
Z
Jk
|f (s, ω) −fh (s, ω)|2 ds ≤
Z
R
|f (s, ω) −fh (s, ω)|2 ds
and this last converges to 0 by standard considerations as h →0. Of course the
necessary smallness of h will depend on ω. To see this is so, use Jensen’s inequality
to obtain the term of 33.2 is dominated by
Z T
0
Z
R
|f (s, ω) −fh (s, ω)|2 dsdt
=
T
Z
R
¯¯¯¯
Z
R
(f (s, ω) −f (s −r, ω)) ψh (r) dr
¯¯¯¯
2
ds
≤
T
Z
R
Z
R
|f (s, ω) −f (s −r, ω)|2 ψh (r) drds
≤
T
Z h
0
ψh (r)
Z
R
|f (s, ω) −f (s −r, ω)|2 dsdr
≤
T
Z h
0
ψh (r) εdr
by continuity of translation in L2 provided h is small enough.
Therefore, this
converges to 0 as h →0.
Next consider the term of 33.4
Z T
0
Z 1
0
|fh (t, ω) −f (t, ω)|2 dsdt
=
Z 1
0
Z T
0
|fh (t, ω) −f (t, ω)|2 dtds
=
Z T
0
|fh (t, ω) −f (t, ω)|2 dt
=
Z T
0
¯¯¯¯
Z
(f (t −s, ω) −f (t, ω)) ψh (s) ds
¯¯¯¯
2
dt
≤
Z T
0
Z
(f (t −s, ω) −f (t, ω))2 ψh (s) dsdt
≤
Z h
0
ψh (s)
Z
(f (t −s, ω) −f (t, ω))2 dtds
≤
Z h
0
ψh (s) εds = ε
whenever h is small enough due to continuity of translation in L2. Thus the terms
in 33.2 and 33.4 both converge to 0 as h →0.

906
FILTRATIONS AND MARTINGALES
Therefore, there exists small positive h such that
Z T
0
Z 1
0
|f (φn (t −s) + s, ω) −f (t, ω)|2 dsdt
≤
ε
2 + 3
Z T
0
Z 1
0
|fh (φn (t −s) + s, ω) −fh (t, ω)|2 dsdt
Letting M be the uniform bound on f, and using the fact that |φn (t −s) + s −t| <
2−n, it follows the above expression is dominated by
ε
2 + M
h 2−n < ε
provided n is chosen large enough. Therefore, this has shown
lim
n→∞
Z T
0
Z 1
0
|f (φn (t −s) + s, ω) −f (t, ω)|2 dsdt
=
lim
n→∞
Z 1
0
Z T
0
|f (φn (t −s) + s, ω) −f (t, ω)|2 dtds = 0.
Therefore, if ε > 0 is given, the above expression is less than ε provided n is large
enough, depending on ω. However, this requires that for some sn ∈[0, 1]
Z T
0
|f (φn (t −sn) + sn, ω) −f (t, ω)|2 dt < ε.
I have now shown that for every ω /∈E, the above expression holds for all n
suﬃciently large. Therefore,
lim
n→∞P
ÃZ T
0
|f (φn (t −sn) + sn, ω) −f (t, ω)|2 dt ≥ε
!
= 0.
Let fn (t, ω) = f (φn (t −sn) + sn, ω) . Then fn is clearly a bounded adapted step
function.
It only remains to verify the last claim. From 33.1 there exists a subsequence,
nk such that
P
ÃZ T
0
(fnk (t, ω) −f (t, ω))2 dt ≥2−k
!
≤2−k
Then letting Ak =
h
ω :
R T
0 (fnk (t, ω) −f (t, ω))2 dt ≥2−ki
it follows from the Borel
Cantelli lemma that a.e. ω is in only ﬁnitely many of these Ak. Therefore, for each
ω oﬀa set of measure zero E,
Z T
0
(fnk (t, ω) −f (t, ω))2 dt < 2−k

907
for all k large enough.
From the deﬁnition of these fnk given above, they are
uniformly bounded. Therefore, by the dominated convergence theorem,
lim
k→∞
Z
Ω
Z T
0
(fnk (t, ω) −f (t, ω))2 dtdP = 0.
This proves the theorem.
The following corollary is what is really desired. It removes the assumption that
f is uniformly bounded.
Corollary 33.4 Let Ft be a ﬁltration as described above and suppose f is adapted
and B × F measurable such that for a.e. ω,
Z T
0
f (t, ω)2 dt < ∞.
(33.5)
Then there exists a sequence of uniformly bounded adapted step functions, φn such
that
lim
n→∞P
ÃZ T
0
(f (t, ω) −φn (t, ω))2 dt > ε
!
= 0.
(33.6)
Thus
φn (t, ω) =
mn−1
X
j=0
en
j (ω) X[tn
j ,tn
j+1) (t)
where tn
0 = 0 and en
j is Ftn
j measurable. Furthermore, if f is in L2 ([0, T] × Ω) ,
there exists a subsequence
©
φnk
ª
such that
lim
k→∞
Z
Ω
Z T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dtdP = 0
Proof: Let fM be given by the following for M ∈N
fM (t, ω) =



M if f (t, ω) > M
f (t, ω) if f (t, ω) ∈[−M, M]
−M if f (t, ω) < −M
Then fM satisﬁes all the conditions of Lemma 33.3. Letting ε > 0 be given, it
follows there exists φM a uniformly bounded adapted step function such that
P
ÃZ T
0
(fM (t, ω) −φM (t, ω))2 dt > δ
4
!
< ε.
Also for large enough M,
P
ÃZ T
0
(f (t, ω) −fM (t, ω))2 dt > δ
4
!
< ε
(33.7)

908
FILTRATIONS AND MARTINGALES
This is because for E the set of measure zero such that 33.5 does not hold,
Ω\ E = ∪∞
M=1
"
ω :
Z T
0
(f (t, ω) −fM (t, ω))2 dt ≤δ
2
#
Therefore, picking M large enough that 33.7 holds,
P
ÃZ T
0
(f (t, ω) −φM (t, ω))2 dt > δ
!
≤
P
ÃZ T
0
2 (f (t, ω) −fM (t, ω))2 dt > δ
2
!
+P
ÃZ T
0
2 (fM (t, ω) −φM (t, ω))2 dt > δ
2
!
<
ε + ε = 2ε.
Since ε is arbitrary, this proves the ﬁrst part of the corollary.
Next suppose f ∈L2 ([0, T] × Ω) . By 33.7 there exists a subsequence, {fMk}
such that
P
ÃZ T
0
(f (t, ω) −fMk (t, ω))2 dt > 2−k
!
< 2−k
and so by the Borel Canelli lemma there exists a set of measure zero E such that
for ω /∈E and all k large enough,
Z T
0
(f (t, ω) −fMk (t, ω))2 dt ≤2−k.
Now by construction, |fMk| ≤|f| and so the dominated convergence theorem implies
lim
k→∞
ÃZ
Ω
Z T
0
(f (t, ω) −fMk (t, ω))2 dtdP
!1/2
= 0.
Therefore, there exists a subsequence, {Mk} such that
ÃZ
Ω
Z T
0
(f (t, ω) −fMk (t, ω))2 dtdP
!1/2
< 2−(¯k+1).
Then by Lemma 33.3 there exists an adapted bounded step function, φMk such that
ÃZ
Ω
Z T
0
¡
fMk (t, ω) −φMk (t, ω)
¢2 dtdP
!1/2
< 2−(¯k+1).
It follows
ÃZ
Ω
Z T
0
¡
f (t, ω) −φMk (t, ω)
¢2 dtdP
!1/2
< 2−k.

909
This proves the corollary.
The following corollary states things a little diﬀerently.
Corollary 33.5 Let Ft be a ﬁltration as described above and suppose f is adapted
and B × F measurable such that for a.e. ω,
Z T
0
f (t, ω)2 dt < ∞.
Then there exists a sequence of uniformly bounded adapted step functions, φn such
that
lim
n→∞P
ÃZ T
0
(f (t, ω) −φn (t, ω))2 dt ≤2−n
!
= 1.
Proof: By Corollary 33.4, there exists a sequence of bounded adapted step
functions, {φn} such that
lim
n→∞P
ÃZ T
0
(f (t, ω) −φn (t, ω))2 dt > ε
!
= 0.
Therefore, selecting a sequence of ε as ε = 2−k, there exists a subsequence, φnk
such that
P
ÃZ T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dt > 2−k
!
< 2−k.
From the Borel Cantelli lemma ω which is in inﬁnitely many of the sets
"
ω :
Z T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dt > 2−k
#
has measure zero. Therefore, for ω not in this set,
Z T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dt ≤2−k
for all k suﬃciently large and so
lim
k→∞P
ÃZ T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dt ≤2−k
!
= 1.
This proves the corollary.
Note that virtually no change in the argument would yield the above results
with the exponent p ≥1 replacing 2. I will use this fact whenever convenient.
Deﬁnition 33.6 Let {Bt} be one dimensional Brownian motion as described in
Theorem 31.44. Let Ft be the smallest σ algebra which is complete and contains all
sets of the form
(Bt1, · · ·, Btk)−1 (F1 × · · · × Fk)

910
FILTRATIONS AND MARTINGALES
for all ﬁnite increasing sequences t1, · · ·, tk such that 0 ≤t1 < t2 · ·· < tk ≤t and Fj
Borel. Thus Ft is a ﬁltration. Another way to say it is that Ft is the smallest σ al-
gebra contained in F which is complete and such that for every increasing sequence,
t1, · · ·, tk such that 0 ≤t1 < t2 · ·· < tk ≤t, it follows that (Bt1, · · ·, Btk) : Ω→Rn
is measurable with respect to Ft.
Recall Bt has independent increments. This is why the following lemma is so
signiﬁcant.
Lemma 33.7 Ft also equals the smallest σ algebra which is complete and contains
all sets of the form
¡
Bt1, Bt2 −Bt1, · · ·, Btk −Btk−1
¢−1 (F1 × · · · × Fk) .
In other words, one can consider instead the independent increments when deﬁning
Ft.
Proof: F′
t is the smallest σ algebra such that (Bt1, · · ·, Btk) is measurable for
every increasing sequence, t1, ···, tk such that 0 ≤t1 < t2··· < tk ≤t. The 0 function
is clearly measurable because 0−1 (E) = Ωif 0 ∈E and if 0 /∈E, 0−1 (E) = ∅.
Therefore, for every increasing sequence, as just described,
¡
0, −Bt1, · · ·, −Btk−1
¢
is Ft measurable. Therefore,
¡
Bt1, Bt2 −Bt1, · · ·, Btk −Btk−1
¢
is F′
t measurable.
Now suppose for all such increasing sequences,
¡
Bt1, Bt2 −Bt1, · · ·, Btk −Btk−1
¢
is
F′
t measurable. Then in particular,
(0, · · ·0, Bti, 0 · ··, 0)
must be F′
t measurable because Bti is. Therefore, adding in k of these, it follows
(Bt1, · · ·, Btk) is F′
t measurable. In other words, a σ algebra is measurable for all
(Bt1, Bt2, · · ·, Btk)
if and only if it is measurable for all sequences,
¡
Bt1, Bt2 −Bt1, · · ·, Btk −Btk−1
¢
Taking the completion, this proves the lemma.
33.1
Continuous Martingales
Deﬁnition 33.8 Let (Ω, M, P) be a probability space and let Mt be a ﬁltration.
Then a stochastic process, Mt, t ≥0 is called a martingale if
Mt is Mt measurable for all t ≥0
Mt ∈L1 (Ω) for all t ≥0
E (Ms|Mt) = Mt whenever s ≥t.

33.1.
CONTINUOUS MARTINGALES
911
Theorem 33.9 Brownian motion for S ≤t with respect to the ﬁltration described
above is a martingale.
Proof: First, Bt is Ft measurable. It is necessary to verify Bt is in L1 (Ω) . But
by Theorem 31.44
Z
Ω
|Bt (ω)| dP
≤
Z
Ω
|Bt (ω)|2 dP
≤
2
Z
Ω
|Bt −B0|2 dP + 2
Z
Ω
|B0|2
≤
2n (t −s) + 2
Z
Ω
|x|2 dP < ∞.
Next it must be shown that E (Bs|Ft) = Bt whenever s ≥t. Let F ∈Ft and let
s ≥t. Then
Z
F
E (Bs −Bt|Ft) dP
=
Z
(Bs−Bt) XF dP
=
Z
Ω
(Bs−Bt) dP
Z
Ω
XF dP = 0.
Hence
E (Bs|Ft)
=
E (Bs −Bt|Ft) + E (Bt|Ft)
=
0 + Bt
and this proves the theorem.
Lemma 33.10 Let Bt be real valued Brownian motion. Then B2
t −t is a martingale.
Proof: The idea is to exploit the fact the increments (Bs −Bt) for s > t are
independent of Ft. Thus you write things in terms of (Bs −Bt) . It is easy to see
that (Bs −Bt)2 −2B2
t +2BsBt = B2
s −B2
t . Therefore, using the fact that Brownian
motion is a martingale,
E
¡
B2
s −B2
t |Ft
¢
=
E
³
(Bs −Bt)2 −2B2
t + 2BsBt|Ft
´
=
E
³
(Bs −Bt)2 |Ft
´
+ E
¡
−2B2
t + 2BsBt|Ft
¢
=
E
³
(Bs −Bt)2 |Ft
´
−2B2
t + 2BtE (Bs|Ft)
=
E
³
(Bs −Bt)2 |Ft
´
−2B2
t + 2B2
t
=
E
³
(Bs −Bt)2 |Ft
´
Now for A ∈Ft,
Z
A
E
³
(Bs −Bt)2 |Ft
´
dP ≡
Z
A
(Bs −Bt)2 dP

912
FILTRATIONS AND MARTINGALES
=
Z
XAdP
Z
(Bs −Bt)2 dP =
Z
A
(s −t) dP.
Since this holds for all A ∈Ft, it follows E
³
(Bs −Bt)2 |Ft
´
= (s −t) and so
E
¡
B2
s −s|Ft
¢
=
E
¡
B2
s −B2
t |Ft
¢
+ B2
t −s
=
(s −t) + B2
t −s = B2
t −t.
Suppose Bt is one dimensional Brownian motion. Then the increments, Bs −Bt
for s > t are independent of Ft where Ft is the smallest complete σ algebra such
that (Bt1, · · ·, Btk) is measurable for every sequence 0 ≤t1 < t2 < · · · < tk ≤t.
Consider the problem of ﬁnding E ((Bs −Bt)m) for various values of m. It was
shown earlier that for m = 1, the answer is 0 and for m = 2, the answer is s −t.
By independence,
E
¡
eiBsu¢
= E
³
ei(Bs−Bt)u´
E
¡
eiBtu¢
.
Therefore, from the earlier observations about the characteristic function of normaly
distributed random variables and using the fact the mean of Bt is x and the variance
is t,
eiuxe−1
2 u2s
eiuxe−1
2 u2t = E
³
ei(Bs−Bt)u´
and so
E
³
ei(Bs−Bt)u´
= e−1
2 u2(s−t).
(33.8)
Therefore,
E
³
i (Bs −Bt) ei(Bs−Bt)u´
= u (t −s) e
1
2 u2(t−s)
E
³
−(Bs −Bt)2 ei(Bs−Bt)u´
=
e
1
2 u2(t−s)t −e
1
2 u2(t−s)s
+u2e
1
2 u2(t−s)t2 −2u2e
1
2 u2(t−s)ts
+u2e
1
2 u2(t−s)s2
(33.9)
E
³
−i (Bs −Bt)3 ei(Bs−Bt)u´
=
3ue
1
2 u2(t−s)t2 −6ue
1
2 u2(t−s)ts
+3ue
1
2 u2(t−s)s2 + u3e
1
2 u2(t−s)t3
−3u3e
1
2 u2(t−s)t2s + 3u3e
1
2 u2(t−s)ts2
−u3e
1
2 u2(t−s)s3
(33.10)

33.1.
CONTINUOUS MARTINGALES
913
E
³
(Bs −Bt)4 ei(Bs−Bt)u´
=
3e
1
2 u2(t−s)t2 + 6u2e
1
2 u2(t−s)t3
−18u2e
1
2 u2(t−s)t2s −6e
1
2 u2(t−s)ts
+18u2e
1
2 u2(t−s)ts2 + 3e
1
2 u2(t−s)s2
−6u2e
1
2 u2(t−s)s3 + u4e
1
2 u2(t−s)t4
−4u4e
1
2 u2(t−s)t3s + 6u4e
1
2 u2(t−s)t2s2
−4u4e
1
2 u2(t−s)ts3 + u4e
1
2 u2(t−s)s4
(33.11)
Now plug in u = 0 to get these expected values. Considering 33.9,
−E
³
(Bs −Bt)2´
= t −s
(33.12)
which was already noted. Next let u = 0 in 33.10 to obtain
−iE
³
(Bs −Bt)3´
= 0.
(33.13)
Finally, consider 33.11. This gives
E
³
(Bs −Bt)4´
=
3t2 −6ts + 3s2
=
3 (s −t)2 .
(33.14)
Clearly one could go on like this but this is enough for now. You might conjecture
that E ((Bs −Bt)m) = (m −1) (s −t)m/2 for m even and 0 for m odd. Lets simply
call it gm (s −t) for now.
Example 33.11 Find a martingale which involves B3
t .
It is the exploitation of the independence of the increments which is of signiﬁ-
cance. The idea is to write B3
s in terms of Bt and powers of increments, (Bs −Bt) .
To aid in doing this, just write the Taylor series expansion of the function s3. Thus
s3 = t3 +
¡
3t2¢
(s −t) + 3t (s −t)2 + (s −t)3 .
It follows
B3
s = B3
t + 3B2
t (Bs −Bt) + 3Bt (Bs −Bt)2 + (Bs −Bt)3 .
Then for s > t,
E
¡
B3
s|Ft
¢
= E
³
B3
t + 3B2
t (Bs −Bt) + 3Bt (Bs −Bt)2 + (Bs −Bt)3 |Ft
´
=
B3
t + B2
t E (Bs −Bt|Ft) + 3BtE
³
(Bs −Bt)2 |Ft
´
+ E
³
(Bs −Bt)3 |Ft
´
=
B3
t + 3BtE
³
(Bs −Bt)2 |Ft
´
+ E
³
(Bs −Bt)3 |Ft
´
(33.15)

914
FILTRATIONS AND MARTINGALES
Consider E ((Bs −Bt)m |Ft) . If A ∈Ft,then by independence,
Z
A
E ((Bs −Bt)m |Ft) dP
=
Z
A
(Bs −Bt)m dP
=
Z
XAdP
Z
(Bs −Bt)m dP
=
Z
A
gm (s −t) dP
which shows
gm (s −t) = E ((Bs −Bt)m |Ft) .
(33.16)
Then considering 33.15 in light of 33.12 and 33.13, this leads to
E
¡
B3
s|Ft
¢
= B3
t + 3 (s −t) Bt
It follows
E
¡
B3
s −3Bss|Ft
¢
=
B3
t + 3 (s −t) Bt −3sE (Bs|Ft)
=
B3
t + 3 (s −t) Bt −3sBt
=
B3
t −3tBt
This shows B3
t −3tBt is a martingale.
Of course you can keep going this way. Here is yet another example.
Lemma 33.12 B4
t −6tB2
t + 3t2 is a martingale.
Proof: The Taylor series for y4 −6ty2 +3t2 considered a function of y expanded
about x is
¡
x4 −6tx2 + 3t2¢
+
¡
−12tx + 4x3¢
(y −x)
+
¡
−6t + 6x2¢
(y −x)2 + 4x (y −x)3 + (y −x)4
and so B4
s −6sB2
s + 3s2 equals
¡
B4
t −6sB2
t + 3s2¢
+
¡
−12sBt + 4B3
t
¢
(Bs −Bt)
+
¡
−6s + 6B2
t
¢
(Bs −Bt)2 + 4Bt (Bs −Bt)3 + (Bs −Bt)4
Using 33.16 and taking conditional expectations using the formulas, 33.12 - 33.14,
E
¡
B4
s −6sB2
s + 3s2|Ft
¢
equals
¡
B4
t −6sB2
t + 3s2¢
+
¡
−6s + 6B2
t
¢
(s −t) + 3 (s −t)2
and this simpliﬁes to
B4
t −6B2
t t + 3t2
This proves the lemma.

33.2.
DOOB’S MARTINGALE ESTIMATE
915
33.2
Doob’s Martingale Estimate
The next big result is an important inequality involving martingales which is due
to Doob. First here is a simple lemma.
Lemma 33.13 Let {Mt} be a ﬁltration and let {Mt} be a real valued martingale
for t ∈[S, T] . Then for λ > 0 and any p ≥1, if At is a Mt measurable subset of
[|Mt| ≥λ] , then
P (At) ≤1
λp
Z
At
|MT |p dP.
Proof: From Jensen’s inequality,
λpP (At)
≤
Z
At
|Mt|p dP =
Z
At
|E (MT |Mt)|p dP
≤
Z
At
E (|MT |p |Mt) dP =
Z
At
|MT |p dP
and this proves the lemma.
The next theorem is the main result.
Theorem 33.14 Let {Mt} be a ﬁltration and let {Mt} be a real valued continuous1
martingale for t ∈[S, T] . Then for all λ > 0 and p ≥1,
P
Ã"
sup
t∈[S,T ]
|Mt| ≥λ
#!
≤1
λp
Z
Ω
|MT |p dP
Proof: Let S ≤tm
0 < tm
1 < · · · < tm
Nm = T where tm
j+1 −tm
j = (T −S) 2−m.
First consider m = 1.
At1
0 ≡
n
ω ∈Ω:
¯¯¯Mt1
0 (ω)
¯¯¯ ≥λ
o
, At1
1 ≡
n
ω ∈Ω:
¯¯¯Mt1
1 (ω)
¯¯¯ ≥λ
o
\ At1
0
At1
2 ≡
n
ω ∈Ω:
¯¯¯Mt1
2 (ω)
¯¯¯ ≥λ
o
\
³
At1
0 ∪At1
0
´
.
Do this type of construction for m = 2, 3, 4, · · · yielding disjoint sets,
n
Atm
j
o2m
j=0
whose union equals
∪t∈Dm [|Mt| ≥λ]
1t →Mt (ω) is continuous for a.e. ω.

916
FILTRATIONS AND MARTINGALES
where Dm =
©
tm
j
ª2m
j=0 . Thus Dm ⊆Dm+1. Then also, D ≡∪∞
m=1Dm is dense and
countable. From Lemma 33.13,
P (∪t∈Dm [|Mt| ≥λ])
=
2m
X
j=0
P
³
Atm
j
´
≤
1
λp
2m
X
j=0
Z
Atm
j
|MT |p dP
≤
1
λp
Z
Ω
|MT |p dP.
Let m →∞in the above to obtain
P (∪t∈D [|Mt| ≥λ]) ≤1
λp
Z
Ω
|MT |p dP.
(33.17)
From now on, assume that for a.e. ω ∈Ω, t →Mt (ω) is continuous. Then with
this assumption, the following claim holds.
Claim:For λ > ε > 0,
∪t∈D [|Mt| ≥λ −ε] ⊇
"
sup
t∈[S,T ]
|Mt| ≥λ
#
Proof of the claim: Suppose ω ∈
h
supt∈[S,T ] |Mt| ≥λ
i
. Then there exists s
such that |Ms (ω)| > λ −ε. By continuity, this situation persists for all t near to s.
In particular, it is true for some t ∈D. This proves the claim.
Letting P ′ denote the outer measure determined by P it follows from the claim
and 33.17 that
P ′
Ã"
sup
t∈[S,T ]
|Mt| ≥λ
#!
≤
P (∪t∈D [|Mt| ≥λ −ε])
≤
1
(λ −ε)p
Z
Ω
|MT |p dP.
Since ε is arbitrary, this shows
P ′
Ã"
sup
t∈[S,T ]
|Mt| ≥λ
#!
≤1
λp
Z
Ω
|MT |p dP.
It would be interesting to consider whether
h
supt∈[S,T ] |Mt| ≥λ
i
is measurable.
However, this follows from the continuity of t →Mt (ω) which implies
"
sup
t∈[S,T ]
|Mt| ≥λ
#
=
·
sup
t∈D
|Mt| ≥λ
¸
,
a measurable set due to countability of D. This proves the theorem.

The Itˆo Integral
In all this, Bt will be a martingale for the ﬁltration, Ht and the increments, Bs −Bt
will be independent of Ht for s > t. I will deﬁne the Itˆo integral on [0, T] where T
is arbitrary. In doing so, I will also deﬁne it on [0, t] . First the integral is deﬁned
on uniformly bounded adapted step functions. Let φ be such a function. Thus
φ (t, ω) =
n−1
X
j=0
φj (ω) X[tj,tj+1) (t) .
(34.1)
Then for t ∈[tk, tk+1),
Z t
0
φdB (ω) ≡
k−1
X
j=0
φj (ω)
¡
Btj+1 (ω) −Btj (ω)
¢
+ φk (ω) (Bt (ω) −Btk (ω)) . (34.2)
The veriﬁcation that this is well deﬁned and linear is essentially the same as it is
in the context of the Riemann integral from calculus. To show linearity on such
step functions, you simply take a common reﬁnement and if s is one of the new
partition points in [ti, ti+1), you replace the term φiX[ti,ti+1) (t) with the sum of the
two terms, φiX[ti,s) (t) + φiX[s,,ti+1) (t) .
Lemma 34.1 Let s > t and let φ be bounded and Ht measurable. Then
exp (φ (Bs −Bt)) exp
µ
−1
2φ2 (s −t)
¶
(34.3)
is a function in L1 (Ω) .
Proof: The given function is dominated by
h (ω) ≡exp (M |Bs −Bt|)
917

918
THE IT ˆO INTEGRAL
where |φ (ω)| < M. Then using the technique of the distribution function, Theorem
9.39 on Page 232,
Z
Ω
hdP
=
Z ∞
0
P (h > λ) dλ
=
Z ∞
0
P (exp (M |Bs −Bt|) > λ) dλ
≤
Z ∞
0
P
µ
|Bs −Bt| > ln (λ)
M
¶
dλ
=
Z ∞
1
P
µ
|Bs −Bt| > ln (λ)
M
¶
dλ
+
Z 1
0
P (|Bs −Bt| > nonpositive) dλ
=
1 +
2
p
2π (s −t)
Z ∞
1
Z ∞
ln(λ)/M
e−
x2
2(s−t) dxdλ
=
1 + C
Z ∞
0
Z eMx
1
e−
x2
2(s−t) dλdx ≤1 + C
Z ∞
0
e−
x2
2(s−t) eMxdx < ∞.
This proves the lemma.
Lemma 34.2 Let φ be a uniformly bounded adapted step function on [0, T] . Let
ξ (t) ≡exp
µZ t
0
φdB −1
2
Z t
0
φ2dr
¶
Then ξ (t) is a continuous Ht martingale.
Proof: That ξ (t) is continuous follows from the fact φ is bounded and the
continuity of Bt. It remains to verify it is a martingale. Let φ be given by 34.1 and
suppose tj ≤t < s < tj+1. Then
E (ξ (s) |Ht) = E
µξ (s)
ξ (t) ξ (t) |Ht
¶
= ξ (t) E
µξ (s)
ξ (t) |Ht
¶
.
(34.4)
From the deﬁnition of the integral on step functions given above and using the
assumption on t and s just mentioned, it follows this equals
ξ (t) E

exp
¡R s
0 φdB −1
2
R s
0 φ2dr
¢
exp
³R t
0 φdB −1
2
R t
0 φ2dr
´|Ht


=
ξ (t) E
µ
exp
¡
φj (Bs −Bt)
¢
exp
µ
−1
2φ2
j (s −t)
¶
|Ht
¶
.

919
Letting A be Ht measurable, it follows from independence of the increment, Bs−Bt
and Ht that
Z
A
E
µ
exp
¡
φj (Bs −Bt)
¢
exp
µ
−1
2φ2
j (s −t)
¶
|Ht
¶
dP
=
Z
Ω
XA exp
¡
φj (Bs −Bt)
¢
exp
µ
−1
2φ2
j (s −t)
¶
dP
=
Z
Ω
XAdP
Z
Ω
exp
¡
φj (Bs −Bt)
¢
exp
µ
−1
2φ2
j (s −t)
¶
dP.
(34.5)
Since φj is bounded and measurable in Htj, there exists a sequence of simple func-
tions, {αn} which converges to φj uniformly. Say
αn (ω) =
mn
X
i=1
ciXEi (ω)
where each Ei ∈Ht (In fact, Ei ∈Htj.). Then by the dominated convergence
theorem, or simply the boundedness of φj and the uniform convergence of αn to φj,
lim
n→∞
Z
Ω
exp (αn (Bs −Bt)) exp
µ
−1
2α2
n (s −t)
¶
dP
=
Z
Ω
exp
¡
φj (Bs −Bt)
¢
exp
µ
−1
2φ2
j (s −t)
¶
dP.
However, by independence of the increments again
Z
Ω
exp (αn (Bs −Bt)) exp
µ
−1
2α2
n (s −t)
¶
dP
=
mn
X
i=1
Z
Ei
exp (ci (Bs −Bt)) exp
µ
−1
2c2
i (s −t)
¶
dP
=
mn
X
i=1
Z
Ei
dP
Z
Ω
exp (ci (Bs −Bt)) exp
µ
−1
2c2
i (s −t)
¶
dP.
However,
Z
Ω
exp (ci (Bs −Bt)) exp
µ
−1
2c2
i (s −t)
¶
dP
=
Z
R
1
p
2π (s −t)
e−
x2
2(s−t) ecixe−1
2 c2
i (s−t)dx = 1
which follows from completing the square in the exponents and recognizing the inte-
grand as a normal distribution. Therefore, 34.5 reduces to
R
A dP and so E
³
ξ(s)
ξ(t) |Ht
´
=
1 which shows from 34.4 that
E (ξ (s) |Ht) = ξ (t) .

920
THE IT ˆO INTEGRAL
The next case is when s = tj+1 and t ∈(tj, tj+1) . The argument goes the same
way. In this case,
E
µξ (s)
ξ (t) |Ht
¶
=
E
¡
exp
¡
φj
¡
Btj+1 −Btj
¢
−φj
¡
Bt −Btj
¢¢
·
exp
µ
−1
2
¡
φ2
j (tj+1 −tj) −φ2
j (t −tj)
¢¶
|Ht
¶
= E
µ
exp
¡
φj
¡
Btj+1 −Bt
¢¢
exp
µ
−1
2φ2
j (tj+1 −t)
¶
|Ht
¶
.
Now it is just a repeat of the above argument to show this is 1.
All other cases follow easily from this. For example, suppose tj−1 ≤t < tj <
tj+1 ≤s < tj+2. Then from the two cases considered above,
E (ξ (s) |Ht)
=
E
¡
E
¡
E
¡
ξ (s) |Htj+1
¢
|Htj
¢
|Ht
¢
=
E
¡
E
¡
ξ (tj+1) |Htj
¢
|Ht
¢
=
E (ξ (tj) |Ht) = ξ (t) .
Continuing in this way shows ξ (t) is a martingale. This proves the lemma.
Note also that this shows
E (ξ (T)) = E (ξ (T) |H0) = ξ (0) = 1.
Now from Doob’s martingale estimate, Theorem 33.14,
P
µ
max
t∈[0,T ] ξ (t) ≥λ
¶
≤1
λE (ξ (T)) = 1
λ.
If φ were replaced by αφ and ξα were obtained by replacing φ with αφ, the same
estimate would follow. Thus
P
µ
max
t
µZ t
0
φdB −α
2
Z t
0
φ2ds
¶
> λ
¶
=
P
µ
max
t
µZ t
0
αφdB −1
2
Z t
0
(αφ)2 ds
¶
> αλ
¶
=
P
µ
max
t
µ
exp
µZ t
0
αφdB −1
2
Z t
0
(αφ)2 ds
¶¶
> eαλ
¶
=
P
³
max
t
(ξα (t)) > eαλ´
≤
1
eαλ E (ξα (T)) = e−αλ
(34.6)
Summarizing this gives the following very signiﬁcant inequality in which α, λ are
two arbitrary positive constants independent of φ.
P
µ
max
t
µZ t
0
φdB −α
2
Z t
0
φ2ds
¶
> λ
¶
≤e−αλ.
(34.7)
Now recall how adapted functions can be approximated by adapted step func-
tions. This was proved in Corollary 33.4 which is stated here for convenience.

921
Corollary 34.3 Let Ft be a ﬁltration and suppose f is adapted and B × F mea-
surable such that for a.e. ω,
Z T
0
f (t, ω)2 dt < ∞.
(34.8)
Then there exists a sequence of uniformly bounded adapted step functions, φn such
that
lim
n→∞P
ÃZ T
0
(f (t, ω) −φn (t, ω))2 dt > ε
!
= 0.
(34.9)
Thus
φn (t, ω) =
mn−1
X
j=0
en
j (ω) X[tn
j ,tn
j+1) (t)
where tn
0 = 0 and en
j is Ftn
j measurable. Furthermore, if f is in L2 ([0, T] × Ω) ,
there exists a subsequence
©
φnk
ª
such that
lim
k→∞
Z
Ω
Z T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dtdP = 0
From this corollary, the following fundamental lemma will make possible the
deﬁnition of the Itˆo integral. It pertains to the ﬁltration, Ht with respect to which
Bt is a martingale and such that for s > t, Bs −Bt is independent of Ht.
Lemma 34.4 Suppose f is Ht adapted and B × F measurable such that for a.e. ω,
Z T
0
f (t, ω)2 dt < ∞.
(34.10)
Then there exists a sequence of bounded adapted step functions, {φk} and a set of
measure zero, E, such that for ω /∈E,
Z T
0
(f (t, ω) −φk (t, ω))2 dt ≤2−k
for all k suﬃciently large (depending on ω /∈E). Also, for ω /∈E, there exists
K (ω) such that if k > l ≥K (ω) , then
Z T
0
(φk (s, ω) −φl (s, ω))2 ds < 2−(k−2).
Proof: By Corollary 33.4 stated above, there exists a subsequence, of the {φn}
mentioned in this corollary,
©
φnk
ª
such that
P
ÃZ T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dt > 2−k
!
< 2−k.

922
THE IT ˆO INTEGRAL
Now let Ak ≡
h
ω :
R T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dt > 2−ki
. Then from the above,
∞
X
k=1
P (Ak) < ∞
and so by the Borel Cantelli lemma, the set, E of points ω contained in inﬁnitely
many of the Ak has measure zero. Therefore, for ω /∈E, there exists K (ω) such
that for k > K (ω) , ω /∈Ak and so
Z T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dt ≤2−k
Denote φk = φnk.
For ω /∈E and l > k > K (ω) described above, and t ≤T,
Z t
0
(φk (s, ω) −φl (s, ω))2 ds
≤
2
Z t
0
(φk (s, ω) −f (s, ω))2 ds
+2
Z t
0
(f (s, ω) −φl (s, ω))2 ds
≤
2k−1 + 2l−1 ≤2k−2.
This proves the lemma.
Now recall the fundamental estimate, 34.7,
P
µ
max
t
µZ t
0
φdB −α
2
Z t
0
φ2ds
¶
> λ
¶
≤e−αλ.
(34.11)
which was valid for bounded adapted step functions, φ. This lemma makes possible
the following theorem which is the basis for the deﬁnition of the Itˆo integral.
Theorem 34.5 Suppose f is Ht adapted and B × F measurable such that for a.e.
ω,
Z T
0
f (t, ω)2 dt < ∞,
and let {φn} be a sequence of bounded adapted step functions such that oﬀa set of
measure zero E,
Z T
0
(f (t, ω) −φn (t, ω))2 dt ≤2−n
(34.12)
for all n suﬃciently large, the existence of such a sequence being provided by Lemma
34.4; then there exists a set of measure zero E, such that if ω /∈E, then
½Z t
0
φndB (ω)
¾
is uniformly Cauchy for t ∈[0, T]. Furthermore, if {ψn} is another sequence of
bounded adapted step functions satisfying 34.12, then for ω oﬀa set of measure
zero,
lim
n→∞
µ
max
t
¯¯¯¯
Z t
0
φndB (ω) −
Z t
0
ψndB (ω)
¯¯¯¯
¶
= 0.

923
Proof: By Lemma 34.4, for ω /∈E the exceptional set of measure zero, there
exists N (ω) such that if n > m ≥N (ω) ,
Z T
0
(φn (s, ω) −φm (s, ω))2 ds < 2−(m−2)
In the estimate 34.11 let
e−αλ = θ−m, α =
µ3
2
¶m−2
where θ > 1. Hence λ =
¡ 2
3
¢m−2 m ln θ. Thus for n > m ≥N (ω) ,
P
³
max
t
³R t
0 (φn −φm) dB −1
2
¡ 3
2
¢m−2 R t
0 (φn −φm)2 ds
´
>
¡ 2
3
¢m−2 m ln θ
´
< θ−m
By the Borel Cantelli lemma again, there exists a set of measure zero E containng
the earlier exceptional set such that for ω /∈E there exists N (ω) large enough that
for n > m ≥N (ω) ,
max
t
ÃZ t
0
(φn −φm) dB (ω) −1
2
µ3
2
¶m−2 Z t
0
(φn −φm)2 ds
!
≤
µ2
3
¶m−2
m ln θ
Z T
0
(φn −φm)2 ds < 2−(m−2).
Therefore for such ω,
max
t
ÃZ t
0
(φn −φm) dB (ω) −1
2
µ3
2
¶m−2
2−(m−2)
!
≤
µ2
3
¶m−2
m ln θ
and switching φn and φm,
max
t
ÃZ t
0
(φm −φn) dB (ω) −1
2
µ3
2
¶m−2
2−(m−2)
!
≤
µ2
3
¶m−2
m ln θ.
Therefore,
max
t
Ã¯¯¯¯
Z t
0
(φm −φn) dB (ω)
¯¯¯¯ ≤
µ2
3
¶m−2
m ln θ + 1
2
µ3
4
¶m−2!
.
It follows that for ω oﬀa set of measure zero,
nR t
0 φndB (ω)
o
is a Cauchy sequence.
Adjusting the above constants, there exists a constant, r < 1 and a positive con-
stant, C such that
max
t
µ¯¯¯¯
Z t
0
(φm −φn) dB (ω)
¯¯¯¯ ≤Crm
¶

924
THE IT ˆO INTEGRAL
whenever n > m and m large enough.
If {ψn} is another such sequence satisfying 34.12 then for n large enough,
Z T
0
(φn (s, ω) −ψn (s, ω))2 ds < 2−(n−2)
and so the same estimate yields, for all ω oﬀa set of measure zero,
max
t
µ¯¯¯¯
Z t
0
(ψn −φn) dB (ω)
¯¯¯¯ ≤Crn
¶
which shows that for ω oﬀa set of measure zero,
lim
n→∞
µ
max
t
¯¯¯¯
Z t
0
φndB (ω) −
Z t
0
ψndB (ω)
¯¯¯¯
¶
= 0.
This proves the theorem.
Note there is no loss of generality in starting the integral at 0. All the above
works with no change for integrals on the interval, [S, T] with no signiﬁcant change.
With this theorem the following deﬁnition and conclusion is well deﬁned.
Deﬁnition 34.6 Suppose f is Ht adapted and B × F measurable such that for
ω /∈E a set of measure zero,
Z T
S
f (t, ω)2 dt < ∞.
Then there exists a sequence of adapted bounded step functions, {φn} satisfying
Z T
S
(f (t, ω) −φn (t, ω))2 dt ≤2−n
for ω /∈E, a set of measure zero. Then for t ∈[S, T] , the Itˆo integral is deﬁned by
Z t
S
fdB (ω) = lim
n→∞
Z t
S
φndB (ω) .
Furthermore, for these ω, t →
R t
S fdB (ω) is continuous because by Theorem 34.5
the convergence of
R t
S φndB (ω) is uniform on [0, T].
Deﬁnition 34.7 Suppose f is Ht adapted and B × F measurable such that for a.e.
ω,
Z T
S
f (t, ω)2 dt < ∞.
I will denote such functions by saying they are in W (H) .

34.1.
PROPERTIES OF THE IT ˆO INTEGRAL
925
34.1
Properties Of The Itˆo Integral
Theorem 34.8 Let f, g ∈W (H) and let 0 ≤S ≤U ≤T. Then the following hold.
Z T
S
fdB =
Z U
S
fdB +
Z T
U
fdB
(34.13)
Z T
S
(af + bg) dB = a
Z T
S
fdB + b
Z T
S
fdB
(34.14)
Z T
S
fdB is HT measurable.
(34.15)
E
ÃZ T
S
fdB
!
= 0
(34.16)
if for some sequence of adapted step functions, {φn} ,
lim
n→∞E
ÃZ T
S
φndB
!
= E
ÃZ T
S
fdB
!
.
Proof: This holds essentially because it holds for any φ a step function. For
example, if
φ (t, ω) =
n
X
j=1
ej (ω) X[tj,tj+1) (t) ,
Then without loss of generality it can be assumed U is one of the tj say tk. Therefore,
Z T
S
φdB
=
k−1
X
j=1
ej (ω)
¡
Btj+1 (ω) −Btj (ω)
¢
+
n
X
j=k
ej (ω)
¡
Btj+1 (ω) −Btj (ω)
¢
=
Z U
S
φdB +
Z T
U
φdB
It follows 34.13 must hold in the limit. 34.14 is somewhat more obvious. Consider
34.16. Let φ be as above. Then recall that ej is Htj measurable and so
E


n
X
j=1
ej (ω)
¡
Btj+1 (ω) −Btj (ω)
¢


=
n
X
j=1
E (ej) E
¡
Btj+1 −Btj
¢
=
n
X
j=1
E (ej) 0 = 0
What is used here is the independence of the increments, Bs −Bt to Ht.

926
THE IT ˆO INTEGRAL
34.15 must also hold because if φ is as above,
R T
S φdB is HT measurable and
R T
S fdB is a pointwise a.e. limit of these.
The next theorem is called the Itˆo isometry.
It pertains to the case where
f ∈L2 ([S, T] × Ω) . Thus
Z
Ω
Z T
0
f (t, ω)2 dtdP < ∞
which says more than just
P
ÃZ T
0
f (t, ω)2 dt < ∞
!
= 1.
Recall Corollary 33.4 again.
Corollary 34.9 Let Ft be a ﬁltration and suppose f is adapted and B × F mea-
surable such that for a.e. ω,
Z T
0
f (t, ω)2 dt < ∞.
(34.17)
Then there exists a sequence of uniformly bounded adapted step functions, φn such
that
lim
n→∞P
ÃZ T
0
(f (t, ω) −φn (t, ω))2 dt > ε
!
= 0.
(34.18)
Thus
φn (t, ω) =
mn−1
X
j=0
en
j (ω) X[tn
j ,tn
j+1) (t)
where tn
0 = 0 and en
j is Ftn
j measurable. Furthermore, if f is in L2 ([0, T] × Ω) ,
there exists a subsequence
©
φnk
ª
such that
lim
k→∞
Z
Ω
Z T
0
¡
f (t, ω) −φnk (t, ω)
¢2 dtdP = 0
The following theorem is the Itˆo isometry.All of this is still in the context of the
ﬁltration, Ht with respect to which Bt is a martingale and the increments, Bs −Bt
are independent of Ht whenever s > t.
Theorem 34.10 Let f be Ht adapted and in L2 ([S, T] × Ω) . Then
¯¯¯¯¯
¯¯¯¯¯
Z T
S
fdB
¯¯¯¯¯
¯¯¯¯¯
L2(Ω)
= ||f||L2([0,T ]×Ω) .

34.1.
PROPERTIES OF THE IT ˆO INTEGRAL
927
Proof: First let φ (t, ω) = Pn−1
j=0 ej (ω) X[tj,tj+1) (t) be a uniformly bounded
adapted step function. Then
Z T
S
φdB =
n−1
X
j=0
ej
¡
Btj+1 −Btj
¢
.
Then
ÃZ T
S
φdB
!2
=
X
i,j
ej
¡
Btj+1 −Btj
¢
ei
¡
Bti+1 −Bti
¢
.
Consider these terms. First consider one in which i ̸= j, say
eiej
¡
Bti+1 −Bti
¢ ¡
Btj+1 −Btj
¢
.
By independence of the increments, it follows
Z
Ω
eiej
¡
Bti+1 −Bti
¢ ¡
Btj+1 −Btj
¢
dP
=
Z
Ω
eiej
¡
Bti+1 −Bti
¢
dP
Z
Ω
¡
Btj+1 −Btj
¢
dP = 0.
Therefore,
Z
Ω
ÃZ T
S
φdB
!2
dP
=
Z
Ω
n−1
X
j=0
e2
j
¡
Btj+1 −Btj
¢2 dP
=
n−1
X
j=0
Z
Ω
e2
j
¡
Btj+1 −Btj
¢2 dP
=
n−1
X
j=0
Z
Ω
e2
jdP
Z
Ω
¡
Btj+1 −Btj
¢2 dP
=
n−1
X
j=0
Z
Ω
e2
jdP (tj+1 −tj) dP =
Z
Ω
Z T
0
φ2dtdP.
This proves the Itˆo isometry on bounded adapted step functions.
By Corollary 33.4, there exists a sequence of adapted bounded step functions,
{φn} which converges to f in L2 ([S, T] × Ω) such that also
Z T
S
fdB (ω) = lim
n→∞
Z T
S
φndB (ω) a.e.
Therefore, from what was just shown
(Z T
S
φndB
)∞
n=1

928
THE IT ˆO INTEGRAL
is a Cauchy sequence in L2 (Ω) . Therefore, a subsequence of it converges a.e. How-
ever, this requires the thing to which it converges in L2 (Ω) must be
R T
S fdB (ω) .
Therefore,
¯¯¯¯¯
¯¯¯¯¯
Z T
S
fdB
¯¯¯¯¯
¯¯¯¯¯
L2(Ω)
=
lim
n→∞
¯¯¯¯¯
¯¯¯¯¯
Z T
S
φndB
¯¯¯¯¯
¯¯¯¯¯
=
lim
n→∞||φn||L2([S,T ]×Ω) = ||f||L2([S,T ]×Ω) .
This proves the theorem.
This theorem also gives another way to deﬁne the Itˆo integral when
f ∈L2 ([S, T] × Ω)
in addition to being in W (H).
Lemma 34.11 If f ∈W (H) and is in L2 ([S, T] × Ω) , let {φn} be any sequence
of bounded adapted step functions converging to f in L2 ([S, T] × Ω). Then
Z T
S
fdB = lim
n→∞
Z T
S
φndB
in L2 (Ω) .
Proof: This is immediate from the following.
¯¯¯¯¯
¯¯¯¯¯
Z T
S
fdB −
Z T
S
φndB
¯¯¯¯¯
¯¯¯¯¯
L2(Ω)
=
¯¯¯¯¯
¯¯¯¯¯
Z T
S
(f −φn) dB
¯¯¯¯¯
¯¯¯¯¯
L2(Ω)
=
||f −φn||L2([S,T ]×Ω)
which converges to 0.
Letting f ∈W (H) , one can consider the stochastic process
R t
S f (s, ω) dB (ω) .
From the construction of the Itˆo integral above, this is a continuous function of t for
a.e. ω. It turns out that if f is also in L2 ([S, T] × Ω) , then this stochastic process
is also an Ht martingale.
Theorem 34.12 I (t, ω) ≡
R t
S f (s, ω) dB (ω) is an Ht martingale if
f ∈L2 ([S, T] × Ω) .
Proof: Let
In (t, ω) =
Z t
S
φn (s, ω) dB (ω) .
where φn is a bounded adapted step function such that
Z t
S
fdB = lim
n→∞
Z t
S
φndB

34.1.
PROPERTIES OF THE IT ˆO INTEGRAL
929
in L2 (Ω) for each t ∈[S, T] and for ω not in a suitable set of measure zero,
I (t, ω) ≡
Z t
S
fdB (ω) = lim
n→∞
Z t
S
φndB (ω)
(34.19)
uniformly for t ∈[S, T] .
In fact, In (t, ω) is a martingale. Let s > t. Then
E (In (s, ω) |Ft) = E
µZ t
S
φndB +
Z s
t
φndB|Ft
¶
.
Now
R t
S φndB is measurable in Ft and so this reduces to
Z t
S
φndB + E


X
t≤tn
j <tn
j+1≤s
en
j
¡
Btj+1 −Btj
¢
|Ft

.
By Lemma 32.2,
=
Z t
S
φndB + E

E


X
t≤tn
j <tn
j+1≤s
en
j
¡
Btj+1 −Btj
¢
|Ftj

|Ft


=
Z t
S
φndB + E


X
t≤tn
j <tn
j+1≤s
E
¡
en
j
¡
Btj+1 −Btj
¢
|Ftj
¢
|Ft


=
Z t
S
φndB + E


X
t≤tn
j <tn
j+1≤s
en
j E
¡¡
Btj+1 −Btj
¢
|Ftj
¢
|Ft


=
Z t
S
φndB + E


X
t≤tn
j <tn
j+1≤s
en
j · 0|Ft

=
Z t
S
φndB = In (t, ω) .
Thus In (t, ω) is a martingale. Let s > t. Since In (r, ·) →I (r, ·) in L2 (Ω) for
each r, Jensen’s inequality implies
Z
Ω
|E (In (s, ω) |Ft) −E (I (s, ω) |Ft)| dP
≤
Z
Ω
E (|In (s, ω) −I (s, ω)| |Ft) dP
=
Z
Ω
|In (s, ω) −I (s, ω)| dP

930
THE IT ˆO INTEGRAL
which converges to 0. It follows that for F ∈Ft, and s > t,
Z
F
I (t, ω) dP
=
lim
k→∞
Z
F
In (t, ω) dP
=
lim
k→∞
Z
F
E (In (s, ω) |Ft) dP
=
Z
F
E (I (s, ω) |Ft) dP.
What about the measurability of I? This follows from the pointwise convergence
described in 34.19 the measurability of In and completness of the measure. This
proves the theorem.
Example 34.13 Find
R t
0 Bs (ω) dB (ω) assuming B0 (0) = 0.
Let φn (s, ω) = Pn
j=0 Btj (ω) X[tj,tj+1) (s) where |tj+1 −tj| is constant in j and
equals t/n. Then φn →Bs in L2 ([0, t] × Ω) and it is clear that φn is adapted.
Therefore,
Z T
S
φn (t, ω) dB (ω) →
Z T
S
Bt (ω) dB (ω)
in L2 (Ω) . But by deﬁnition,
Z T
S
φn (t, ω) dB (ω) =
n
X
j=0
Btj (ω)
¡
Btj+1 (ω) −Btj (ω)
¢
and a little algebra shows this equals
n
X
j=0
1
2
³
B2
tj+1 −B2
tj
´
−
n
X
j=0
1
2
¡
Btj+1 −Btj
¢2
=
1
2Bt (ω)2 −1
2
n
X
j=0
¡
Btj+1 −Btj
¢2 .
Now
Z
Ω
¯¯¯¯¯¯
n
X
j=0
¡
Btj+1 −Btj
¢2 −t
¯¯¯¯¯¯
2
dP
=
Z
Ω
X
i,j
¡
Btj+1 −Btj
¢2 ¡
Bti+1 −Bti
¢2 −2t
X
j
¡
Btj+1 −Btj
¢2 + t2dP
=
X
i,j
(tj+1 −tj) (ti+1 −ti) −2t
X
j
(tj+1 −tj) + t2 = t2 −2t2 + t2 = 0
and so
Z
Ω
¯¯¯¯¯¯
1
2Bt (ω)2 −1
2
n
X
j=0
¡
Btj+1 −Btj
¢2 −
µ1
2Bt (ω)2 −1
2t
¶¯¯¯¯¯¯
2
dP = 0

34.1.
PROPERTIES OF THE IT ˆO INTEGRAL
931
which shows
Z T
S
Bt (ω) dB (ω) = 1
2Bt (ω)2 −1
2t.
This is contrary to what any student would know; that from the symbols in-
volved,
Z T
S
Bt (ω) dBt (ω) = 1
2Bt (ω)2 −1
2B0 (ω)2 = 1
2Bt (ω)2 .
Here you get the extra term, −1
2t.

932
THE IT ˆO INTEGRAL

Stochastic Processes
35.1
An Important Filtration
Recall the theorem about Brownian motion which is listed here for convenience.
Theorem 35.1 There exists a probability space, (Ω, F, P) and random vectors, Bt
for t ∈[0, ∞) which satisfy the following properties.
1. For Z = (Bt1, · · ·, Btk) ∈Rnk it follows Z is normally distributed. Its mean
is
¡ x
· · ·
x ¢
∈Rnk
2. Bt has independent increments. This means if t1 < t2 < · · · < tk, the random
variables,
Bt1, Bt2 −Bt1, · · ·, Btk −Btk−1
are independent and normally distributed. Note this implies the kth compo-
nents must also be independent. Also Btj −Btj−1 is normal with covariance
(tj −tj−1) I and mean 0. In addition to this, the kth component of Bt is
normally distributed with density function
p (t, xk,y) ≡
1
(2πt)1/2 exp
Ã
−|y −xk|2
2t
!
This follows from the distribution of Bt which has a density function
p (t, x, y) ≡
1
(2πt)n/2 exp
Ã
−|y −x|2
2t
!
3. E
³
|Bt −Bs|4´
≤3n2 (t −s)2 , For t > s,
E
³
|Bt −Bs|2´
=
n (t −s) ,
E
¡
(Bt −x)∗(Bs −x)
¢
=
ns,
E (Bt −Bs)
=
0,
933

934
STOCHASTIC PROCESSES
4. t →Bt (ω) is Holder continuous.
Observation 35.2 Let Bt be n dimensional Brownian motion as discussed above.
Then considering the kth component of Bt, Bkt, it follows Bkt is one dimensional
Brownian motion. Letting Ht denote the completion of the smallest σ algebra con-
taining
(Bs1, · · ·, Bsk)−1 (B)
for all B a Borel set in Rnk for all sequences, 0 ≤s1 < s2 · ·· < sk ≤t, it follows
that for s > t, Bks −Bkt is independent of Ht . Also, from the fact discussed above
in Theorem 33.9 that Bt is a martingale, it follows the same is true of Bkt. Thus
all the above theory can be applied for this Ht and integrating with respect to one of
the components of n dimensional Brownian motion.
One other thing should be pointed out although it was mentioned above and
that is the distribution of Bs −Bt for s > t. The density for Bt as described above
is
1
(2πt)n/2 exp
Ã
−|y −x|2
2t
!
and so by Theorem 31.22 on Page 868
E
¡
eiu·Bt¢
= eiu·xe−1
2 u∗tIu.
Recall also from the above that Bs −Bt is independent to Bt. Therefore,
E
¡
eiu·Bs¢
=
E
³
eiu·Bteiu·(Bs−Bt)´
=
E
¡
eiu·Bt¢
E
³
eiu·(Bs−Bt)´
and so
E
³
eiu·(Bs−Bt)´
=
eiu·xe−1
2 u∗sIu
eiu·xe−1
2 u∗tIu
=
e−1
2 u∗(s−t)Iu.
This implies the following lemma.
Lemma 35.3 Let Bt = (B1t, · · ·, Bnt) be n dimensional Brownian motion. Then
for s > t, Bis −Bit and Bjs −Bjt are linearly independent if j ̸= i.
Proof: The covariance matrix of the distribution of Bs −Bt is (s −t) times the
identity and so the components of this vector are linearly independent.
Lemma 35.4 Letting Ht denote the completion of the smallest σ algebra containing
(Bs1, · · ·, Bsk)−1 (B)

35.1.
AN IMPORTANT FILTRATION
935
for all B a Borel set in Rnk for all sequences, 0 ≤s1 < s2 · ·· < sk ≤t as deﬁned
above, Ht is also equal to the completion of the smallest σ algebra containing
(Bs1, · · ·, Bsk)−1 (B)
for all B an open set in Rnk for all sequences, 0 ≤s1 < s2 · ·· < sk ≤t. In addition
to this, Ht is equal to the completion of the smallest σ algebra containing
(Bs1, · · ·, Bsk)−1 (B)
for all B an open set in Rnk for all sequences, 0 ≤s1 < s2 · ·· < sk ≤t such that
the sj are rational numbers.
Proof: The ﬁrst claim reducing to inverse images of open sets is not hard.
Deﬁne Gt to be the smallest σ algebra such that (Bs1, · · ·, Bsk)−1 (U) ∈Gt for U
open and 0 ≤s1 < s2 · ·· < sk ≤t. Now let
S(s1,···,sk) ≡
n
E Borel such that (Bs1, · · ·, Bsk)−1 (E) ∈Gt
o
Then S(s1,···,sk) contains the open sets and so it also contains the Borel sets because
it is a σ algebra. Hence Gt contains all sets of the form (Bs1, · · ·, Bsk)−1 (E) for all E
Borel and 0 ≤s1 < s2 ··· < sk ≤t. It follows Gt is the smallest σ algebra containing
the sets of the form (Bs1, · · ·, Bsk)−1 (B) for B Borel and so its completion equals
Ht.
The second claim is more interesting. In this claim, it suﬃces to consider ﬁ-
nite increasing sequences of rational numbers, rather than just ﬁnite increasing
sequences. Let 0 ≤s1 < s2 · ·· < sk ≤t and let 0 ≤tn
1 < tn
2 · ·· < tn
k ≤t be an
increasing sequence of rational numbers such that limn→∞tn
k = sk. It has been
proven that oﬀa set of measure zero, t →Bt (ω) is continuous. To simplify the
presentation, I will assume without loss of generality that this set of measure zero
is empty. If not, you could simply delete it and consider a slightly modiﬁed Ω.
Another way to see this is not a loss of generality is that Ht is complete and so
contains all subsets of sets of measure zero. Let O be an open set and let
O = ∪∞
m=1Om, · · ·Om ⊆Om ⊆Om+1 · ··
Then by continuity of t →Bt (ω) ,
(Bs1, · · ·, Bsk)−1 ¡
Om
¢
⊇
∪∞
l=1 ∩p≥l
³
Btp
1, · · ·, Btp
k
´−1
(Om)
⊇
(Bs1, · · ·, Bsk)−1 (Om)
It follows upon taking the union over all m,
(Bs1, · · ·, Bsk)−1 (O)
=
∪m (Bs1, · · ·, Bsk)−1 ¡
Om
¢
⊇
∪m ∪l ∩p≥l
³
Btp
1, · · ·, Btp
k
´−1
(Om)
⊇
∪m (Bs1, · · ·, Bsk)−1 (Om)
=
(Bs1, · · ·, Bsk)−1 (O)

936
STOCHASTIC PROCESSES
Thus
∪m ∪l ∩p≥l
³
Btp
1, · · ·, Btp
k
´−1
(Om) = (Bs1, · · ·, Bsk)−1 (O)
and so the smallest σ algebra containing (Bs1, · · ·, Bsk)−1 (B) for B open and 0 ≤
s1 < s2 · ·· < sk ≤t an arbitrary sequence of numbers is the same as the smallest
σ algebra containing (Bs1, · · ·, Bsk)−1 (B) for B open and 0 ≤s1 < s2 · ·· < sk ≤t
an increasing sequence of rational numbers.
35.2
Itˆo Processes
Let B = (B1, · · ·, Bn) be n dimensional Brownian motion and let Ht be the ﬁltration
deﬁned above. Thus Bk is a martingale with respect to Ht and the increments,
Bks −Bkt are independent of Ht whenever s > t. Let Xk for k = 1, 2, · · ·, m be a
stochastic process satisfying for t ∈[0, T] ,
Xkt −Xk0 =
Z t
0
uk (s, ω) ds +
n
X
l=1
Z t
0
vkl (s, ω) dBl.
(35.1)
Written in simpler form,
Xt −X0 =
Z t
0
u (s) ds +
Z t
0
V (s) dB
(35.2)
where V (s) is an m × n matrix. For now, assume uk and vkl are all Ht adapted
uniformly bounded step functions.
Also assume g is a C2 function deﬁned on R × Rm for which all partial deriva-
tives are uniformly bounded and let
©
tr
j
ªnr
j=0 be partitions of [0, T] such that for
∆(r) ≡supj
©
tr
j+1 −tr
j
ª
, limr→∞∆(r) = 0 and also all discontinuities of all the
step functions, vkl and uk are contained in
©
tr
j
ªnr
j=0 . Then suppressing the super-
script on tr
j for the sake of simpler notation,
g (T, XT ) −g (0, X0) =
nr−1
X
j=0
g
¡
tj+1, Xtj+1
¢
−g
¡
tj, Xtj
¢
=
nr−1
X
j=0
∂g
∂t
¡
tj, Xtj
¢
∆tj + D2g
¡
tj, Xtj
¢
∆Xtj
+ 1
2
µ∂2g
∂t2
¡
tj + θ∆tj, Xtj + θ∆Xtj
¢
∆t2
j
(35.3)
+D2
¡
D2g
¡
tj + θ∆tj, Xtj + θ∆Xtj
¢ ¡
∆Xtj
¢¢
∆Xtj
+ 2D2
µ∂g
∂t
¶ ¡
tj + θ∆tj, Xtj + θ∆Xtj
¢
∆tj∆Xtj
¶
.
(35.4)

35.2.
IT ˆO PROCESSES
937
Now from 35.2 and the assumptions that all discontinuities of all step functions are
in the partition, it follows the matrix, V and the vector, u must be of the form
V (s, ω) =
nr−1
X
j=0
V j (ω) X[tj,tj+1) (s) , u (s, ω) =
nr−1
X
j=0
uj (ω) V[tj,tj+1) (s)
It follows from 35.2 that
∆Xtj = uj∆tj + V j∆Btj
(35.5)
It follows from this that 35.3 - 35.4 can be written as
=
nr−1
X
j=0
∂g
∂t
¡
tj, Xtj
¢
∆tj + D2g
¡
tj, Xtj
¢ ¡
uj∆tj + V j∆Btj
¢
(35.6)
+1
2
µ∂2g
∂t2
¡
tj + θ∆tj, Xtj + θ∆Xtj
¢
∆t2
j
(35.7)
+2D2
µ∂g
∂t
¶ ¡
tj + θ∆tj, Xtj + θ∆Xtj
¢
∆tj
¡
uj∆tj + V j∆Btj
¢
(35.8)
+D2
¡
D2g
¡
tj + θ∆tj, Xtj + θ∆Xtj
¢ ¡
uj∆tj + V j∆Btj
¢¢
·
(35.9)
¡
uj∆tj + V j∆Btj
¢¢
.
(35.10)
Since ∆(r) →0 as r →∞, this simpliﬁes to an expression of the form
= e (r) +
nr−1
X
j=0
∂g
∂t
¡
tj, Xtj
¢
∆tj + D2g
¡
tj, Xtj
¢ ¡
uj∆tj + V j∆Btj
¢
+1
2
µ
2D2
µ∂g
∂t
¶ ¡
tj + θ∆tj, Xtj + θ∆Xtj
¢
V j∆tj∆Btj
+
¡
uj∆tj + V j∆Btj
¢T
H
¡
tj + θ∆tj, Xtj + θ∆Xtj
¢ ¡
uj∆tj + V j∆Btj
¢
(35.11)
where e (r) →0 as r →∞and H is the Hessian matrix of second partial derivatives
of g taken with respect to the x variables. The e (r) in the above is obtained by the
inclusion of all the terms which have a ∆t2
j in them. There are lots of other terms
which are of the form
nr−1
X
j=0
aj∆tj∆Bktj
where aj is bounded independent of r. In fact, all such terms can be included in

938
STOCHASTIC PROCESSES
e (r) oﬀa set of measure zero. I will show this now.
Z
Ω
¯¯¯¯¯¯
nr−1
X
j=0
aj∆tj∆Bktj
¯¯¯¯¯¯
dP
≤
C
Z
Ω
nr−1
X
j=0
∆tj
¯¯∆Bktj
¯¯ dP
≤
C
nr−1
X
j=0
∆tj
Z
Ω
¯¯∆Bktj
¯¯ dP
=
C
nr−1
X
j=0
∆tj
µZ
Ω
¯¯∆Bktj
¯¯2 dP
¶1/2
≤
C∆(r)1/2 T
which converges to 0. Therefore, there exists a set of measure zero oﬀwhich terms
of this form converge to 0 as r →∞upon taking a further subsequence if necessary.
Therefore, the above expression simpliﬁes further and yields
g (T, XT ) −g (0, X0) =
e (r) +
nr−1
X
j=0
∂g
∂t
¡
tj, Xtj
¢
∆tj + D2g
¡
tj, Xtj
¢ ¡
uj∆tj + V j∆Btj
¢
+
nr−1
X
j=0
1
2
³¡
V j∆Btj
¢T H
¡
tj + θ∆tj, Xtj + θ∆Xtj
¢ ¡
V j∆Btj
¢´
(35.12)
where e (r) →0 oﬀa set of measure zero. Consider the last term. This term is of
the form
nr−1
X
j=0
1
2
³¡
V j∆Btj
¢T H
¡
tj, Xtj
¢ ¡
V j∆Btj
¢´
+
nr−1
X
j=0
1
2·
(35.13)
³¡
V j∆Btj
¢T ¡
H
¡
tj + θ∆tj, Xtj + θ∆Xtj
¢
−H
¡
tj, Xtj
¢¢ ¡
V j∆Btj
¢´
.
(35.14)
Now the term in 35.14 is of the form
nr−1
X
j=0
∆BT
tjMr∆Btj
where Mr →0 as r →∞and is uniformly bounded. It follows that for a.e. ω, the
above expression converges to 0 and also
¯¯¯¯¯¯
nr−1
X
j=0
∆BT
tjMr∆Btj
¯¯¯¯¯¯
≤C
nr−1
X
j=0
¯¯∆Btj
¯¯2 .
(35.15)

35.2.
IT ˆO PROCESSES
939
Now by independence of the increments,
Z
Ω


nr−1
X
j=0
¯¯∆Btj
¯¯2


2
dP =
Z
Ω
X
i,j
¯¯∆Btj
¯¯2 |∆Bti|2 dP
=
X
i̸=j
Z
Ω
¯¯∆Btj
¯¯2 dP
Z
Ω
|∆Bti|2 dP +
nr−1
X
i=1
Z
Ω
¯¯∆Btj
¯¯4 dP
≤
X
i,j
(tj+1 −tj) (ti+1 −ti) +
nr−1
X
i=1
3n2 (tj+1 −tj)2
≤
T 2 + 3n2∆(r) T.
Thus



¯¯¯¯¯¯
nr−1
X
j=0
∆BT
tjMr∆Btj
¯¯¯¯¯¯



r
is uniformly integrable and so by the Vitali convergence theorem,
lim
r→∞
Z
Ω
¯¯¯¯¯¯
nr−1
X
j=0
∆BT
tjMr∆Btj
¯¯¯¯¯¯
dP = 0.
Passing to a further subsequence, 35.12 is of the form
g (T, XT ) −g (0, X0) =
e (r) +
nr−1
X
j=0
∂g
∂t
¡
tj, Xtj
¢
∆tj + D2g
¡
tj, Xtj
¢ ¡
uj∆tj + V j∆Btj
¢
+
nr−1
X
j=0
1
2
³
∆BT
tj
¡
V j¢T H
¡
tj, Xtj
¢
V j∆Btj
´
(35.16)
where for a.e. ω, e (r) →0. It remains to consider the last term in the above as
r →∞. Denote by Aj the symmetric matrix
¡
V j¢T H
¡
tj, Xtj
¢
V j
in the above. Note this is measurable in Htj.
Claim: Letting Aj =
¡
V j¢T H
¡
tj, Xtj
¢
V j, there exists a subsequence, r →∞
and a set of measure zero such that for ω not in this set of measure zero,
nr−1
X
j=0
³
∆BT
tjAj∆Btj
´
−
nr−1
X
j=0
tr
¡
Aj¢
∆tj →0.

940
STOCHASTIC PROCESSES
Proof of the claim:
Z
Ω


nr−1
X
j=0
³
∆BT
tjAj∆Btj
´
−
n−1
X
j=0
tr
¡
Aj¢
∆tj


2
dP
=
X
i,j
Z
Ω
³
∆BT
tjAj∆Btj −tr
¡
Aj¢
∆tj
´ ¡
∆BT
tiAi∆Bti −tr
¡
Ai¢
∆ti
¢
dP
(35.17)
Consider a term in which j > i. The integrand is of the form
∆BT
tjAj∆Btj∆BT
tiAi∆Bti −tr
¡
Ai¢
∆ti∆BT
tjAj∆Btj
−tr
¡
Aj¢
∆tj∆BT
tiAi∆Bti + tr
¡
Aj¢
∆tjtr
¡
Ai¢
∆ti
(35.18)
Consider the ﬁrst term.
Z
Ω
∆BT
tjAj∆Btj∆BT
tiAi∆BtidP
=
Z
Ω

X
α,β
∆BαtjAj
αβ∆Bβtj


ÃX
σ,τ
∆BσtiAi
στ∆Bτti
!
dP
=
X
α,β,σ,τ
Z
Ω
∆BαtjAj
αβ∆Bβtj∆BσtiAi
στ∆BτtidP
=
X
α,β,σ,τ
Z
Ω
∆Bαtj∆BβtjdP
Z
Ω
∆BσtiAj
αβAi
στ∆BτtidP
Therefore, using independence of the components of n dimensional Brownian motion
which independence results from the covariance matrix for the joint distribution
being diagonal along with the independence of increments in time, this reduces to
=
X
α,σ,τ
Z
Ω
∆B2
αtjdP
Z
Ω
Aj
αα∆BσtiAi
στ∆BτtidP
=
X
σ,τ
(tj+1 −tj)
Z
Ω
X
α
Aj
αα∆BσtiAi
στ∆BτtidP
=
(tj+1 −tj)
Z
Ω
tr
¡
Aj¢ X
σ,τ
∆BσtiAi
στ∆BτtidP
=
Z
Ω
∆tjtr
¡
Aj¢
∆BT
tiAi∆BtidP
which shows that this term in the case where j > i cancels with the third term of
35.18. Now consider the second term of 35.18 again in the case where j > i. This

35.2.
IT ˆO PROCESSES
941
yields
−
Z
Ω
tr
¡
Ai¢
∆ti∆BT
tjAj∆BtjdP
=
−
Z
Ω
tr
¡
Ai¢
∆ti
X
α,β
∆BαtjAj
αβ∆BβtjdP
= −
X
α,β
Z
Ω
∆Bαtj∆BβtjdP
Z
Ω
tr
¡
Ai¢
∆tiAj
αβdP
=
−
X
α
Z
Ω
∆B2
αtjdP
Z
Ω
tr
¡
Ai¢
∆tiAj
ααdP
=
−
Z
Ω
(∆tj) tr
¡
Ai¢
∆ti
X
α
Aj
ααdP
=
−
Z
Ω
(∆tj) tr
¡
Ai¢
∆titr
¡
Aj¢
dP
and so this second term cancels with the last term of 35.18. It follows the only
terms to consider in 35.17 are those for which j = i. Thus 35.17 is of the form
X
i
Z
Ω
³¡
∆BT
tiAi∆Bti
¢2 −2∆BT
tiAi∆Btitr
¡
Ai¢
∆ti +
¡
tr
¡
Ai¢
∆ti
¢2´
dP.
(35.19)
First consider the second term.
Z
Ω
∆BT
tiAi∆Btitr
¡
Ai¢
∆tidP
=
X
α,β
Z
Ω
∆BαtiAi
αβ∆Bβtitr
¡
Ai¢
∆tidP
=
X
α,β
Z
Ω
∆Bαti∆BβtidP
Z
Ω
Ai
αβtr
¡
Ai¢
∆tidP
=
X
α
Z
Ω
∆B2
αtidP
Z
Ω
Ai
ααtr
¡
Ai¢
∆tidP
=
∆ti
Z
Ω
ÃX
α
Ai
αα
!
tr
¡
Ai¢
∆tidP
=
Z
Ω
tr
¡
Ai¢2 ∆t2
i dP ≥0
It follows 35.17 is dominated above by
X
i
Z
Ω
³¡
∆BT
tiAi∆Bti
¢2 +
¡
tr
¡
Ai¢
∆ti
¢2´
dP

942
STOCHASTIC PROCESSES
Consider the ﬁrst term.
Z
Ω
¡
∆BT
tiAi∆Bti
¢2 dP
=
Z
Ω

X
α,β
∆BαtiAi
αβ∆Bβti


ÃX
σ,τ
∆BσtiAi
στ∆Bτti
!
dP
=
X
α,β,σ,τ
Z
Ω
∆BαtiAi
αβ∆Bβti∆BσtiAi
στ∆BτtidP
=
X
α,β,σ,τ
Z
Ω
Ai
αβAi
στdP
Z
Ω
∆Bαti∆Bβti∆Bσti∆BτtidP.
(35.20)
There are two ways in which the term of this sum will not equal zero. One way is
for α = β and σ = τ. In this situation, the above is dominated by
X
α,σ
Z
Ω
Ai
ααAi
σσdP
Z
Ω
∆B2
αti∆B2
σtidP
=
X
α̸=σ
Z
Ω
Ai
ααAi
σσdP∆t2
i +
X
α
Z
Ω
¡
Ai
αα
¢2 dP3 (∆ti)2
≤
X
α,σ
Z
Ω
Ai
ααAi
σσdP∆t2
i +
X
α
Z
Ω
¡
Ai
αα
¢2 dP3 (∆ti)2
=
Z
Ω
tr
¡
Ai¢2 dP∆t2
i + 3
Z
Ω
X
α
¡
Ai
αα
¢2 dP (∆ti)2
The other way in which the expression in 35.20 is not zero is for α = σ and β = τ.
If this happens, the expression is of the form
X
α,β
Z
Ω
Ai
αβAi
αβdP
Z
Ω
∆Bαti∆Bβti∆Bαti∆BβtidP
=
X
α,β
Z
Ω
Ai
αβAi
αβdP
Z
Ω
∆B2
αti∆B2
βtidP
=
X
α±β
Z
Ω
Ai
αβAi
αβdP
Z
Ω
∆B2
αtidP
Z
Ω
∆B2
βtidP
+
X
α
Z
Ω
¡
Ai
αα
¢2 dP3∆t2
i
=
X
α±β
Z
Ω
Ai
αβAi
αβdP∆t2
i +
X
α
Z
Ω
¡
Ai
αα
¢2 dP3∆t2
i .
Thus the expression in 35.20 is dominated by
C
nr−1
X
i=1
∆t2
i

35.2.
IT ˆO PROCESSES
943
which converges to 0 as r →∞. This proves the claim.
Now returning to 35.16 ﬁrst note that
lim
r→∞
nr−1
X
j=0
tr
¡
Aj¢
∆tj =
Z T
0
tr
¡
V T H (t, Xt) V
¢
dt.
Therefore, there exists a subsequence, still denoted by r and a set of measure zero
oﬀof which the last term of 35.16 converges to
1
2
Z T
0
tr
¡
V T H (t, Xt) V
¢
dt.
It follows that oﬀa set of measure zero, you can pass to the limit in 35.16 and
conclude
g (T, XT ) −g (0, X0) =
Z T
0
µ∂g
∂t (t, Xt) + D2g (t, Xt) u+1
2tr
¡
V T H (t, Xt) V
¢¶
dt
+
Z T
0
D2g (t, Xt) V dB
This lengthy computation has mostly proved the following lemma.
Lemma 35.5 Let Ht be the ﬁltration deﬁned above and let B be n dimensional
Brownian motion. Suppose Xt is a vector valued stochastic process for t ∈[0, T]
deﬁned by the following for a.e. ω
Xt −X0 =
Z t
0
u (s, ·) ds +
Z t
0
V (s, ·) dB
where all entries of u and
V are Ht adapted uniformly bounded step functions.
Then if g is a C2 function such that all partial derivatives are uniformly bounded,
then for all t ∈[0, T] ,
g (t, Xt) −g (0, X0) =
Z t
0
µ∂g
∂t (s, Xs) + D2g (s, Xs) u+1
2tr
¡
V T H (s, Xs) V
¢¶
ds
+
Z t
0
D2g (s, Xs) V dB
Proof:
Let {tk} be the rational numbers in [0, T] . The above computation
shows that for each tk, there exists a set of measure zero, Ek such that if ω /∈Ek,
then
g (tk, Xtk) −g (0, X0) =

944
STOCHASTIC PROCESSES
Z tk
0
µ∂g
∂t (s, Xs) + D2g (s, Xs) u+tr
¡
V T H (s, Xs) V
¢¶
ds
+
Z tk
0
D2g (s, Xs) V dB
Letting E = ∪∞
k=1Ek, it follows E has measure zero and the above formula holds for
all tk. By continuity the above must hold for all t ∈[0, T] . This proves the lemma.
Now let V (t, ω) and u (t, ω) will be B × F measurable, both u and V are Ht
adapted, and the components of V and u satisfy
P
ÃZ T
0
v2
ijds < ∞
!
= 1, P
ÃZ T
0
|uk| ds < ∞
!
= 1.
(35.21)
Deﬁnition 35.6 Xt is called an Itˆo process if for, u, V described above and a
measurable function, X0 such that
Xt −X0 =
Z t
0
u (s, ω) ds +
Z t
0
V (s, ω) dB.
Lemma 35.5 shows that if g is a C2 function deﬁned on R × Rm which has all
the second partial derivatives uniformly bounded, then if u and V have components
which are uniformly bounded adapted step functions, then g (t, X) is also an Itˆo
process as described in that lemma. The next step is to remove the assumption
that u and V are step functions.
Lemma 35.7 Let Ht be the ﬁltration deﬁned above and let B be n dimensional
Brownian motion. Suppose Xt is a vector valued stochastic process for t ∈[0, T]
deﬁned by the following for a.e. ω
Xt −X0 =
Z t
0
u (s, ·) ds +
Z t
0
V (s, ·) dB
(35.22)
where all entries of u and V are Ht adapted and satisfy 35.21. Then if g is a C2
function such that all second order partial derivatives are uniformly bounded, then
for all t ∈[0, T] ,
g (t, Xt) −g (0, X0) =
Z t
0
µ∂g
∂t (s, Xs) + D2g (s, Xs) u+1
2tr
¡
V T H (s, Xs) V
¢¶
ds
+
Z t
0
D2g (s, Xs) V dB
(35.23)
where H is the Hessian matrix of g whose ijth entry is
∂2g
∂xi∂xj
(s, Xs (ω)) .

35.2.
IT ˆO PROCESSES
945
Proof: From 35.21 there exist sequences,
©
ulª∞
l=1 and
©
V lª∞
l=1 such that the
entries of ul and V l are adapted step functions and in addition there is a set of
measure zero, E, such that if ω /∈E, then the components of ul and V l satisfy
Z T
0
¯¯ul
k −uk
¯¯ dt < 2−l,
Z T
0
¯¯vl
kj −vkj
¯¯2 dt < 2−l
(35.24)
for all l large enough, depending on ω of course. Then from 35.22 deﬁne
Xl
t −Xl
0 =
Z t
0
ul (s, ·) ds +
Z t
0
V l (s, ·) dB
and it follows that for ω /∈E, and all t ∈[0, T] ,
lim
l→∞Xl
t (ω) = Xt (ω) .
(35.25)
In addition to this, it follows from 35.24 it follows there is a subsequence such that
for ω /∈E,
V l (t, ω) →V (t, ω) , ul (t, ω) →u (t, ω) a.e. t.
By Lemma 35.5 for a.e. ω,
g
¡
t, Xl
t
¢
−g
¡
0, Xl
0
¢
=
Z t
0
µ∂g
∂t
¡
s, Xl
s
¢
+ D2g
¡
s, Xl
s
¢
ul+1
2tr
¡
V lT H
¡
s, Xl
s
¢
V l¢¶
ds
+
Z t
0
D2g
¡
s, Xl
s
¢
V ldB
(35.26)
for all t ∈[0, T] . Now 35.24 implies for each ω /∈E,
R T
0
¯¯¯¯V l¯¯¯¯2 dt is uniformly
bounded independent of l. Consider the third term.
Z T
0
¯¯tr
¡
V lT H
¡
s, Xl
s
¢
V l¢
−tr
¡
V T H (s, Xs) V
¢¯¯ dt
(35.27)
≤
Z T
0
¯¯tr
¡
V lT H
¡
s, Xl
s
¢
V l −V T H
¡
s, Xl
s
¢
V
¢¯¯ dt
+
Z T
0
¯¯tr
¡
V T ¡
H
¡
s, Xl
s
¢
−H (s, Xs)
¢
V
¢¯¯ dt
The second term in the above expression converges to 0 by the dominated conver-
gence theorem. It can be dominated by C
¯¯tr
¡
V T V
¢¯¯ , a function in L1 where here
C does not depend on l but on the uniform bound of the second derivatives of g.
Consider the ﬁrst term. The integrand is dominated by
¯¯tr
¡¡
V lT −V T ¢
HV l¢¯¯ +
¯¯tr
¡
V T H
¡
V l −V
¢¢¯¯

946
STOCHASTIC PROCESSES
The integral of both of these converges to 0. Consider the ﬁrst one.
Z T
0
¯¯tr
¡¡
V lT −V T ¢
HV l¢¯¯ dt
≤
C
Z T
0
¯¯¯¯V l −V
¯¯¯¯ ¯¯¯¯V l¯¯¯¯ dt
≤
C′
Z T
0
¯¯¯¯V l −V
¯¯¯¯2 dt
which converges to 0 as l →∞. This shows that for each t ∈[0, T] , one can pass
to the limit in the third term of 35.26 and eliminate the superscript, l. Passing to
the limit in the second term of 35.26 follows from 35.24 and the boundedness of
D2g
¡
s, Xl
s
¢
which results from the assumption that all the partial derivatives of g
are uniformly bounded. Passing to the limit in the ﬁrst term of 35.26 follows from
35.25. The last term involving dB is of the form
Z t
0
D2g
¡
s, Xl¢
V ldB =
X
j
Z t
0
¡
D2g
¡
s, Xl¢
V l¢
ij dBj.
Then from the deﬁnition of the Itˆo integral given above, there is a subsequence still
denoted by l such that for a.e. ω, the above converges uniformly in t to
X
j
Z t
0
(D2g (s, X) V )ij dBj
Thus for a dense subset of [0, T] , D, there exists an exceptional set of measure zero
such that 35.23 holds for all t ∈D. By continuity of the Ito integral, this continues
to hold for all t ∈[0, T] . This proves the lemma.
It remains to remove the assumption that the partial derivatives of g are bounded.
This results in the following theorem which is the main result.
Theorem 35.8 Let Ht be the ﬁltration deﬁned above and let B be n dimensional
Brownian motion. Suppose Xt is a vector valued stochastic process for t ∈[0, T]
deﬁned by the following for a.e. ω
Xt −X0 =
Z t
0
u (s, ·) ds +
Z t
0
V (s, ·) dB
(35.28)
where all entries of u and V are Ht adapted and satisfy 35.21. Then if g is a C2
function with values in Rp, it follows that for a.e. ω and for all t ∈[0, T] ,
gk (t, Xt) −gk (0, X0) =
Z t
0
µ∂gk
∂t (s, Xs) + D2gk (s, Xs) u+1
2tr
¡
V T Hk (s, Xs) V
¢¶
ds
+
Z t
0
D2gk (s, Xs) V dB
(35.29)

35.2.
IT ˆO PROCESSES
947
where Hk is the Hessian matrix of gk whose ijth entry is
∂2gk
∂xi∂xj
(s, Xs (ω)) .
Proof: There is no loss of generality in proving it only for the case where g has
values in R because you obtain the above formula by simply considering the kth
component of g. Assume then that g has values in R. Let ψN ∈C∞
c (B (0,2N))
such that ψN equals 1 on B (0, N) and ψN has values in [0, 1] . Then let gN ≡gψN.
Thus gN has uniformly bounded derivatives. By Lemma 35.7, there exists a set of
measure zero, EN such that for ω /∈EN, and all t ∈[0, T] ,
gN (t, Xt) −gN (0, X0) =
Z t
0
µ∂gN
∂t (s, Xs) + D2gN (s, Xs) u+1
2tr
¡
V T HN (s, Xs) V
¢¶
ds
+
Z t
0
D2gN (s, Xs) V dB
(35.30)
Let E = ∪∞
N=1EN. Then for ω /∈E, the above formula holds for all N. By continuity
of X, it follows that for all N large enough, the values of X (t, ω) are in B (0,N)
and so you can delete the subscript of N in the above. This proves the theorem.
How do people remember this? Letting Y (t, ω) ≡g (t, X (t, ω)) , 35.29 can be
considered formally as
dYk
=
µ∂gk
∂t (t, Xt) + D2gk (t, Xt) u+1
2tr
¡
V T Hk (t, Xt) V
¢¶
dt
+D2gk (t, Xt) dB
and 35.28 can be written as
dXt = udt + V dB.
I think this is not too bad but one can write an easier to remember formula which
reduces to this one,
dYk = ∂gk
∂t (t, Xt) dt + D2gk (t, Xt) dXt + 1
2dXT
t Hk (t, Xt) dXt
under the convention that dtdBk = 0, dt2 = 0, and, dBidBj = δijdt.
Example 35.9 Let g (t, x) = x2 and let Xt = Bt where B0 = 0.
In this case,
Yt = B2
t
and so
dYt = 2BtdBt + 1
2 · 2dB2
t

948
STOCHASTIC PROCESSES
and so
B2
t −0
=
2
Z t
0
BdB +
Z t
0
dt
=
2
Z t
0
BdB + t.
This yields
Z t
0
BdB = 1
2
¡
B2
t −t
¢
which was encountered earlier.
Example 35.10 Let g (t, x) = x3 and Xt = Bt, Yt = X3
t where B0 = 0.
Then
dYt
=
3X2
t dXt + 1
26XtdX2
t
=
3X2
t dBt + 3Bt
¡
dB2
t
¢
=
3B2
t dBt + 3Btdt
and so
B3
t = 3
µZ t
0
B2dB +
Z t
0
Bdt
¶
Example 35.11 Let Yt = tBt where Xt = Bt and where B0 = 0. Then
dYt
=
Btdt + tdBt + 1
20dB2
t
=
Btdt + tdBt
and so
Yt = tBt =
Z t
0
Bdt +
Z t
0
tdB
35.3
Some Representation Theorems
First recall the following important lemma, Lemma 35.4 on Page 934 which has to
do with the ﬁltrations described above involving n dimensional Brownian motion.
The most important part of this lemma is that one can consider only the increasing
lists of rational numbers rather than all increasing lists of real numbers in deﬁning
the ﬁltration. Here is the lemma.
Lemma 35.12 Letting Ht denote the completion of the smallest σ algebra contain-
ing
(Bs1, · · ·, Bsk)−1 (B)

35.3.
SOME REPRESENTATION THEOREMS
949
for all B a Borel set in Rnk for all sequences, 0 ≤s1 < s2 · ·· < sk ≤t as deﬁned
above, Ht is also equal to the completion of the smallest σ algebra containing
(Bs1, · · ·, Bsk)−1 (B)
for all B an open set in Rnk for all sequences, 0 ≤s1 < s2 · ·· < sk ≤t. In addition
to this, Ht is equal to the completion of the smallest σ algebra containing
(Bs1, · · ·, Bsk)−1 (B)
for all B an open set in Rnk for all sequences, 0 ≤s1 < s2 · ·· < sk ≤t such that
the sj are rational numbers.
Also recall the Doob Dynkin theorem, Theorem 31.19 on Page 866 which is
listed here.
Lemma 35.13 Suppose X, Y1, Y2, ···, Yk are random vectors, X having values in
Rn and Yj having values in Rpj and
X, Yj ∈L1 (Ω) .
Suppose X is H(Y1,···,Yk) measurable. Thus
©
X−1 (E) : E Borel
ª
⊆


(Y1, · · ·, Yk)−1 (F) : F is Borel in
k
Y
j=1
Rpj



Then there exists a Borel function, g : Qk
j=1 Rpj →Rn such that
X = g (Y) .
Also recall the submartingale convergence theorem, Theorem 32.12 on Page 900
reviewed below.
Theorem 35.14 (submartingale convergence theorem) Let
{(Xi, Si)}∞
i=1
be a submartingale with K ≡sup E (|Xn|) < ∞.
Then there exists a random
variable, X, such that E (|X|) ≤K and
lim
n→∞Xn (ω) = X (ω) a.e.
Also here is a generalization of the Itˆo isometry presented earlier.
Lemma 35.15 Let f be Ht adapted in the sense that every component is Ht adapted
and f ∈L2 (Ω; Rn). Here Ht is the ﬁltration deﬁned in Lemma 35.12. Then
¯¯¯¯¯
¯¯¯¯¯
Z T
0
f (s)T dB
¯¯¯¯¯
¯¯¯¯¯
L2(Ω)
= ||f||L2(Ω×[0,T ];Rn) .

950
STOCHASTIC PROCESSES
Proof: Let f an adapted bounded step function. Say
f (t) =
m−1
X
i=0
aiX[ti,ti+1) (t) .
Then
¯¯¯¯¯
¯¯¯¯¯
Z T
0
f (s)T dB
¯¯¯¯¯
¯¯¯¯¯
2
L2(Ω)
=
Z
Ω
X
i,j
aT
i
¡
Bti+1 −Bti
¢
aT
j
¡
Btj+1 −Btj
¢
dP
For a mixed term in which i ̸= j, this integrates to 0 by independence of the
increments. Thus this reduces to
Z
Ω
X
i
aT
i
¡
Bti+1 −Bti
¢
aT
i
¡
Bti+1 −Bti
¢
dP.
Next one uses the independence of the increments of diﬀerent components of n
dimensional Brownian motion. Thus the above equals
X
i
Z
Ω
X
r,s
air (∆Btir) ais (∆Btis) dP
=
X
i
Z
Ω
X
r
a2
ir (∆Btir)2 dP
=
X
i
Z
Ω
X
r
a2
irdP∆ti =
X
i
Z
Ω
|ai|2 dP∆ti
=
Z T
0
Z
Ω
|f|2 dPdt.
This proves the lemma for step functions. Now for f as given, let {fk}∞
k=1 be a
sequence of step functions for which
Z T
0
f T dB = lim
k→∞
Z T
0
f T
k dB a.e., ||fk −f||L2(Ω×[0,T ];Rn) →0.
Then by what was just shown,
nR T
0 f T
k dB
o
is Cauchy in L2 (Ω) . Therefore, it
converges in L2 (Ω) to some g ∈L2 (Ω) . A subsequence converges to g pointwise
which shows g =
R T
0 f T dB. Therefore,
¯¯¯¯¯
¯¯¯¯¯
Z T
0
f T dB
¯¯¯¯¯
¯¯¯¯¯
L2(Ω)
=
lim
k→∞
¯¯¯¯¯
¯¯¯¯¯
Z T
0
f T
k dB
¯¯¯¯¯
¯¯¯¯¯
L2(Ω)
=
lim
k→∞||fk||L2(Ω×[0,T ];Rn) = ||f||L2(Ω×[0,T ];Rn)

35.3.
SOME REPRESENTATION THEOREMS
951
and this proves this higher dimensional version of Itˆo’s isometry.
Now with these lemmas and theorem, it is possible to prove a really interesting
lemma about density of certain kinds of functions in L2 (Ω, HT , P) .
Lemma 35.16 Let Ht be the ﬁltration alluded to in Lemma 35.12 deﬁned in terms
of the n dimensional Brownian motion. Then random variables of the form
φ (Bt1, · · ·, Btk)
where t1 < t2 · ·· < tk is a ﬁnite increasing sequence of rational points in [0, T] and
φ ∈C∞
c
¡
Rk¢
are dense in L2 (Ω, HT , P). Here the set of random variables includes
all such ﬁnite increasing lists of rational points of [0, T].
Proof: Let g ∈L2 (Ω, HT , P) . Also let {tj}∞
j=1 be the rational points of [0, T] .
Now letting {s1, · · ·, sn} = {t1, · · ·, tn} such that s1 < s2 < · · · < sn, let Hn denote
the smallest σ algebra which contains
(Bs1, · · ·, Bsn)−1 (U)
for all U an open subset of Rn. By Lemma 35.12 HT must be the completion of
the σ algebra, ∪∞
n=1Hn and so g has a representative which is ∪∞
n=1Hn measurable.
Therefore, without loss of generality, one can assume g is ∪∞
n=1Hn measurable.
Now consider the martingale,
{E (gM|Hn)}∞
n=1
where
gM (ω) ≡



g (ω) if g (ω) ∈[−M, M]
M if g (ω) > M
−M if g (ω) < −M
and M is chosen large enough that
||g −gM||L2(Ω) < ε/4.
(35.31)
Now the terms of this martingale are uniformly bounded by M because
|E (gM|Hn)| ≤E (|gM| |Hn) ≤E (M|Hn) = M.
It follows the martingale is certainly bounded in L1 and so the martingale con-
vergence theorem stated above can be applied, and so there exists f measurable
in ∪∞
n=1Hn such that E (gM|Hn) (ω) →f (ω) a.e. Also |f (ω)| ≤M. Now letting
A ∈∪∞
n=1Hn, it follows from the dominated convergence theorem that
Z
A
fdP = lim
n→∞
Z
A
E (gM|Hn) dP =
Z
A
gMdP
Since A is an arbitrary set in ∪∞
n=1Hn, this shows f = gM. Also, the functions,
{E (gM|Hn)}∞
n=1 are uniformly bounded and so they are bounded in Lp (Ω, ∪∞
n=1Hn, P)

952
STOCHASTIC PROCESSES
for p > 2. Therefore, these functions are uniformly integrable and so by the Vitali
convergence theorem,
µZ
Ω
(gM −E (gM|Hn))2 dP
¶1/2
→0
as n →∞. It follows m can be chosen large enough that
||E (gM|Hm) −gM||L2(Ω) < ε/4.
(35.32)
Now by the Doob Dynkin lemma listed above, there exists a Borel measurable,
h : Rnm →R such that
E (gM|Hm) = h (Bt1, · · ·, Btm) a.e.
Of course h is not in C∞
c (Rnm) . Let λ(Bt1,···,Btm) be the distribution of the random
vector (Bt1, · · ·, Btm) . Thus λ(Bt1,···,Btm) is a Radon measure and so there exists
φ ∈Cc (Rnm) such that
µZ
Ω
|E (gM|Hm) −φ (Bt1, · · ·, Btm)|2 dP
¶1/2
=
µZ
Ω
|h (Bt1, · · ·, Btm) −φ (Bt1, · · ·, Btm)|2 dP
¶1/2
=
µZ
Rnm |h (x1, · · ·, xm) −φ (x1, · · ·, xm)|2 dλ(Bt1,···,Btm)
¶1/2
< ε/4.
By convolving with a molliﬁer, one can assume that φ ∈C∞
c (Rnm) also. It follows
from 35.31 and 35.32 that
||g −φ (Bt1, · · ·, Btm)||L2
≤
||g −gM||L2 + ||gM −E (gM|Hm)||L2
+ ||E (gM|Hm) −φ (Bt1, · · ·, Btm)||L2
≤
3
³ε
4
´
< ε
This proves the lemma.
In this lemma and the following theorems, HT continues to be the completion
of the smallest σ algebra which contains
(Bs1, · · ·, Bsk)−1 (B)
for all increasing sequences, s1 < · · · < sk and B a Borel set of Rnk.
Lemma 35.17 Let h (t) be a deterministic step function of the form
h (t) =
m−1
X
i=0
aiX[ti,ti+1).

35.3.
SOME REPRESENTATION THEOREMS
953
Then for h of this form, linear combinations of functions of the form
exp
ÃZ T
0
hT dB −1
2
Z T
0
h · hdt
!
(35.33)
are dense in L2 (Ω, HT , P) .
Proof: I will show in the process of the proof that functions of the form 35.33
are in L2 (Ω, P). If the conclusion of the lemma is not true, there exists nonzero
g ∈L2 (Ω, HT , P) such that
Z
Ω
g (ω) exp
ÃZ T
0
hT dB −1
2
Z T
0
h · hdt
!
dP
=
exp
Ã
−1
2
Z T
0
h · hdt
! Z
Ω
g (ω) exp
ÃZ T
0
hT dB
!
dP = 0
for all such h. Letting h be given as above,
Z T
0
hT dB
=
m−1
X
i=0
aT
i
¡
Bti+1 −Bti
¢
(35.34)
=
m
X
i=1
aT
i−1Bti −
m−1
X
i=0
aT
i Bti
=
m−1
X
i=1
¡
aT
i−1 −aT
i
¢
Bti + aT
0 Bt0 + aT
n−1Btn.
(35.35)
Also 35.34 shows exp
³R T
0 hT dB
´
is in L2 (Ω, P) . To see this recall the Bti+1 −Bti
are independent and the density of Bti+1 −Bti is
C (n, ∆ti) exp
Ã
−1
2
|x|2
(ti+1 −ti)
!
so
Z
Ω
Ã
exp
ÃZ T
0
hT dB
!!2
dP =
Z
Ω
exp
Ã
2
Z T
0
hT dB
!
dP

954
STOCHASTIC PROCESSES
=
Z
Ω
exp
Ãm−1
X
i=0
2aT
i
¡
Bti+1 −Bti
¢
!
dP
=
Z
Ω
m−1
Y
i=0
exp
¡
2aT
i
¡
Bti+1 −Bti
¢¢
dP
=
m−1
Y
i=0
Z
Ω
exp
¡
2aT
i
¡
Bti+1 −Bti
¢¢
dP
=
m−1
Y
i=0
Z
Rn C (n, ∆ti) exp
¡
2aT
i x
¢
exp
Ã
−1
2
|x|2
∆ti
!
dx < ∞
Choosing the ai appropriately in 35.35, the formula in 35.35 is of the form
m−1
X
i=0
yT
i Bti
where yi is an arbitrary vector in Rn. It follows that for all choices of yj ∈Rn,
Z
Ω
g (ω) exp


m−1
X
j=0
yT
j Btj (ω)

dP = 0.
Now the mapping
y = (y1, · · ·, ym) →
Z
Ω
g (ω) exp


m−1
X
j=0
yT
j Btj (ω)

dP
is analytic on Cmn and equals zero on Rnm so from standard complex variable the-
ory, this analytic function must equal zero on Cnm, not just on Rnm. In particular,
for all y = (y1, · · ·, ym) ∈Rnm,
Z
Ω
g (ω) exp


m−1
X
j=0
iyT
j Btj (ω)

dP = 0.
(35.36)
Now pick φ ∈C∞
c (Rn) . Thus φ is in the Schwartz class and from the theory of
Fourier transforms,
φ (x) =
1
(2π)mn/2
Z
Rmn eiy·xFφ (y) dy.
In particular,
φ
¡
Bt0 (ω) , · · ·, Btm−1 (ω)
¢
=
1
(2π)mn/2
Z
Rmn exp


m−1
X
j=0
iyT
j Btj (ω)

Fφ (y) dy.

35.3.
SOME REPRESENTATION THEOREMS
955
Therefore,
Z
Ω
g (ω) φ
¡
Bt0 (ω) , · · ·, Btm−1 (ω)
¢
dP
=
1
(2π)mn/2
Z
Ω
g (ω)
Z
Rmn exp


m−1
X
j=0
iyT
j Btj (ω)

Fφ (y) dydP
=
1
(2π)mn/2
Z
Rmn
Z
Ω
g (ω) exp


m−1
X
j=0
iyT
j Btj (ω)

dPFφ (y) dy
=
1
(2π)mn/2
Z
Rmn 0Fφ (y) dy = 0
which shows by Lemma 35.16 that g = 0 after all, contrary to assumption. This
proves the lemma.
Why such a funny lemma? It is because of the following computation which
depends on Itˆo’s formula. First lets review Itˆo’s formula. For
dXt = udt + V dB
where u is a vector and V a matrix, and Y = g (t, X) ,
dYk = ∂gk
∂t (t, Xt) dt + D2gk (t, Xt) dXt + 1
2dXT
t Hk (t, Xt) dXt
where dtdBk = 0, dt2 = 0, and, dBidBj = δijdt. In the above, Hk is the hessian
matrix of gk. Thus this reduces to
dYk
=
∂gk
∂t (t, Xt) dt + D2gk (t, Xt) (udt + V dB)
+1
2 (udt + V dB)T Hk (t, Xt) (udt + V dB)
=
µ∂gk
∂t (t, Xt) + D2gk (t, Xt) u + 1
2tr
¡
V T HkV
¢¶
dt + D2gk (t, Xt) V dB
In the above case, referring to 35.33, let
X =
Z t
0
hT dB −1
2
Z t
0
h · hdt
and g (x) = ex so Y = eX. Then in this case, g is a scalar valued function of one
variable and so the above formula reduces to
dY
=
µ
−1
2eX |h|2 + 1
2eXtr
³
hhT ´¶
dt + eXhT dB
=
µ
−1
2eX |h|2 + 1
2eX |h|2
¶
dt + eXhT dB
=
Y hT dB

956
STOCHASTIC PROCESSES
Hence
Y
=
Y0 +
Z t
0
Y hT dB
=
1 +
Z t
0
Y hT dB.
Now here is the interesting part of this formula.
E
µZ t
0
Y hT dB
¶
= 0
because the integrand is an adapted step function and E
¡
Btj+1 −Btj
¢
= 0. There-
fore, letting F = Y,
F = E (F) +
Z T
0
f (t, ω)T dB
(35.37)
It follows that for F ∈L2 (Ω, HT , P) of the special form described in Lemma 35.17,
there exists an adapted function in L2 (Ω; Rn), f such that 35.37 holds. Does such a
function f exist for all F ∈L2 (Ω, HT , P)? The answer is yes and this is the content
of the next theorem which is called the Itˆo representation theorem.
Theorem 35.18 Let F ∈L2 (Ω, HT , P) . Then there exists a unique Ht adapted
f ∈L2 (Ω× [0, T] ; Rn) such that
F = E (F) +
Z T
0
f (s, ω)T dB.
Proof: By Lemma 35.17, functions of the form
exp
ÃZ T
0
hT dB −1
2
Z T
0
h · hdt
!
where h is a vector valued deterministic step function of the sort described in this
lemma, are dense in L2 (Ω, HT , P). Given F ∈L2 (Ω, HT , P) , {Gk}∞
k=1 be functions
in the subspace of linear combinations of the above functions which converge to F in
L2 (Ω, HT , P). For each of these functions there exists fk an adapted step function
such that
Gk = E (Gk) +
Z T
0
fk (s, ω)T dB.

35.3.
SOME REPRESENTATION THEOREMS
957
Then from the Itˆo isometry, and the observation that E (Gk −Gl)2 →0 as k, l →∞
by the above deﬁnition of Gk in which the Gk converge to F in L2 (Ω) ,
0
=
lim
k,l→∞E
³
(Gk −Gl)2´
=
lim
k,l→∞E


Ã
E (Gk) +
Z T
0
fk (s, ω)T dB−
Ã
E (Gl) +
Z T
0
fl (s, ω)T dB
!!2

=
lim
k,l→∞
(
E (Gk −Gl)2 + 2E (Gk −Gl)
Z
Ω
Z T
0
(fk −fl)T dBdP
+
Z
Ω
ÃZ T
0
(fk −fl)T dB
!2
dP



=
lim
k,l→∞


E (Gk −Gl)2 +
Z
Ω
ÃZ T
0
(fk −fl)T dB
!2
dP



=
lim
k,l→∞
Z
Ω
ÃZ T
0
(fk −fl)T dB
!2
dP =
lim
k,l→∞||fk −fl||L2(Ω×[0,T ];Rn)
(35.38)
Going from the third to the fourth equations, is justiﬁed because
R
Ω
R T
0 (fk −fl)T dBdP =
0 thanks to the independence of the integrals and the fact fk −fl is an adapted step
function.
This shows {fk}∞
k=1 is a Cauchy sequence in L2 (Ω× [0, T] ; Rn) . It follows there
exists a subsequence and f ∈L2 (Ω× [0, T] ; Rn) such that fk converges to f point-
wise and in L2 (Ω× [0, T] ; Rn) with f B×HT measurable. Then by the Itˆo isometry
and the equation
Gk = E (Gk) +
Z T
0
fk (s, ω)T dB
you can pass to the limit as k →∞and obtain
F = E (F) +
Z T
0
f (s, ω)T dB
where f is adapted because of the pointwise convergence. Thus if N is the B × HT
measurable set of m × P measure zero, where convergence does not take place,
Z T
0
Z
Ω
XN (t, ω) dPdt = 0
and so for a.e. t,
R
ΩXNdP = 0 and so fk (t, ω) →f (t, ω) for a.e. ω except for t in a
set of measure zero. Now each fk (t, ·) is Ht measurable and since Ht is complete,
it follows f (t, ·) is also Ht measurable. Now redeﬁne f (t, ω) ≡0 for all t in this
exceptional set of measure zero. Then the resulting f must be Ht adapted. This
proves the existence part of this theorem.

958
STOCHASTIC PROCESSES
It remains to consider the uniqueness. Suppose then that
F = E (F) +
Z T
0
f (t, ω)T dB = E (F) +
Z T
0
f1 (t, ω)T dB.
Then
Z T
0
f (t, ω)T dB =
Z T
0
f1 (t, ω)T dB
and so
Z T
0
³
f (t, ω)T −f1 (t, ω)T ´
dB = 0
and by the Itˆo isometry,
0 =
¯¯¯¯¯
¯¯¯¯¯
Z T
0
³
f (t, ω)T −f1 (t, ω)T ´
dB
¯¯¯¯¯
¯¯¯¯¯
L2(Ω)
= ||f −f 1||L2(Ω×[0,T ];Rn)
which proves uniqueness. This proves the theorem.
With the above major result, here is another interesting representation theorem.
Recall that if you have an Ht adapted function, f and f ∈L2 (Ω× [0, T]) , then
R t
0 f T dB is a martingale. This was proved in Theorem 34.12 for the case of one
dimensional Brownian motion but it will end up being true for the general case
also. The next theorem is sort of a converse. It starts with an Ht martingale and
represents it as an Itˆo integral. In this theorem, Ht continues to be the ﬁltration
determined by n dimensional Brownian motion.
Theorem 35.19 Let Mt be an Ht martingale and suppose Mt ∈L2 (Ω) for all
t ≥0. Then there exists a unique stochastic process, g (s, ω) such that g is Ht
adapted and in L2 (Ω× [0, t]) for each t > 0, and for all t ≥0,
Mt = E (M0) +
Z t
0
gT dB
Proof: First suppose f is an adapted function of the sort that g is. Then the
following claim is the ﬁrst step in the proof.
Claim: Let t1 < t2. Then
E
µZ t2
t1
f T dB|Ht1
¶
= 0
Proof of claim: First consider the claim in the case that f is an adapted step
function of the form
f (t) =
n−1
X
i=0
aiX[ti,ti+1) (t)
Then
Z t2
t1
f T dB (ω) =
n−1
X
i=0
aT
i (ω)
¡
Bti+1 (ω) −Bti (ω)
¢
.

35.3.
SOME REPRESENTATION THEOREMS
959
Now letting A ∈Ht1
Z
A
E
µZ t2
t1
f T dB|Ht1
¶
dP
≡
Z
A
Z t2
t1
f T dBdP =
Z
A
n−1
X
i=0
aT
i (ω)
¡
Bti+1 (ω) −Bti (ω)
¢
dP
=
n−1
X
i=0
Z
Ω
XA (ω) aT
i (ω)
¡
Bti+1 (ω) −Bti (ω)
¢
dP
=
n−1
X
i=0
Z
Ω
XA (ω) aT
i (ω) dP
Z
Ω
¡
Bti+1 (ω) −Bti (ω)
¢
dP = 0.
Since A is arbitrary, E
³R t2
t1 f T dB|Ht1
´
= 0. This proves the claim in the case that
f is an adapted step function. The general case follows from this in the usual way.
If f is not a step function, there is a sequence of adapted step functions, {fk} such
that
Z t2
t1
f T
k dB →
Z t2
t1
f T dB
in L2 (Ω, P) and ||fk −f||L2(Ω×[t1,t2];Rn) →0. Then using the Itˆo isometry,
Z
Ω
µ
E
µZ t2
t1
f T
k dB|Ht1
¶
−E
µZ t2
t1
f T dB|Ht1
¶¶2
dP
=
Z
Ω
E
µZ t2
t1
f T
k dB −
Z t2
t1
f TdB|Ht1
¶2
dP
=
Z
Ω
µZ t2
t1
f T
k dB −
Z t2
t1
f TdB
¶2
dP =
Z
Ω
µZ t2
t1
¡
f T
k −f T¢
dB
¶2
dP
=
||fk −f||L2(Ω×[t1,t2];Rn) →0
Thus the desired conclusion holds in the general case as well.
Now to prove the theorem, it follows from Theorem 35.18 and the assumption
that Mt is a martingale that for t > 0 there exists f t ∈L2 (Ω× [0, T] ; Rn) such that
Mt
=
E (Mt) +
Z t
0
f t (s, ·)T dB
=
E (M0) +
Z t
0
f t (s, ·)T dB.
Now let t1 < t2. Then since Mt is a martingale,
Mt1 = E (Mt2|Ht1) = E
µ
E (M0) +
Z t2
0
f t2 (s, ·)T dB|Ht1
¶

960
STOCHASTIC PROCESSES
= E (M0) + E
µZ t1
0
f t2 (s, ·)T dB+
Z t2
t1
f t2 (s, ·)T dB|Ht1
¶
=
E (M0) + E
µZ t1
0
f t2 (s, ·)T dB|Ht1
¶
=
E (M0) +
Z t1
0
f t2 (s, ·)T dB
because
R t1
0 f t2 (s, ·)T dB is Ht1 measurable. Thus
Mt1 = E (M0) +
Z t1
0
f t2 (s, ·)T dB = E (M0) +
Z t1
0
f t1 (s, ·)T dB
and so
0 =
Z t1
0
f t1 (s, ·)T dB−
Z t1
0
f t2 (s, ·)T dB
and so by the Itˆo isometry,
¯¯¯¯f t1 −f t2¯¯¯¯
L2(Ω×[0,t1];Rn) = 0.
Letting N ∈N, it follows that
Mt = E (M0) +
Z t
0
f N (s, ·)T dB
for all t ≤N. Let g = f N for t ∈[0, N] . Then asside from a set of measure zero,
this is well deﬁned and for all t ≥0
Mt = E (M0) +
Z t
0
g (s, ·)T dB
This proves the theorem.
Surely this is an incredible theorem. Note it implies all the martingales which
are in L2 for each t must be continuous a.e. Also, any such martingale satisﬁes
M0 = E (M0) . Isn’t that amazing?
35.4
Stochastic Diﬀerential Equations
35.4.1
Gronwall’s Inequality
The fundamental tool in estimating diﬀerential equations is Gronwall’s inequality.
It is a very elementary result but of enormous signiﬁcance. I will ﬁrst give a proof
of this important theorem. Also, I will write X (t) rather than Xt.

35.4.
STOCHASTIC DIFFERENTIAL EQUATIONS
961
Lemma 35.20 Let k ≥0 and suppose u (t) is a Lebesgue measurable function in
L1 ([0, T]) which satisﬁes
u (t) ≤u0 +
Z t
0
ku (s) ds.
Then
u (t) ≤u0ekt.
Proof: Let
f (t) = u0ekt −
µ
u0 +
Z t
0
ku (s) ds
¶
.
Then f (0) = 0 and
f ′ (t)
=
ku0ekt −ku (t)
≥
ku0ekt −k
µ
u0 +
Z t
0
ku (s) ds
¶
=
kf (t)
and so f ′ (t) −kf (t) ≥0 and so
d
dt
¡
e−ktf (t)
¢
≥0
which implies f (t) ≥0. Hence
u (t) ≤u0 +
Z t
0
ku (s) ds ≤u0ekt.
This proves Gronwall’s inequality.
35.4.2
Review Of Itˆo Integrals And A Filtration
Next recall the deﬁnition of the Itˆo integral. The context is that Ht is a ﬁltration,
Bt is a martingale for Ht, and if s > t, Bs −Bt is independent of Ht.
Deﬁnition 35.21 Suppose f is Ht adapted and B × F measurable such that for
ω /∈E a set of measure zero,
Z T
S
f (t, ω)2 dt < ∞.
Then there exists a sequence of adapted bounded step functions, {φn} satisfying
Z T
S
(f (t, ω) −φn (t, ω))2 dt ≤2−n

962
STOCHASTIC PROCESSES
for ω /∈E, a set of measure zero. Then for t ∈[S, T] , the Itˆo integral is deﬁned by
Z t
S
fdB (ω) = lim
n→∞
Z t
S
φndB (ω) .
Furthermore, for these ω, t →
R t
S fdB (ω) is continuous because by Theorem 34.5
the convergence of
R t
S φndB (ω) is uniform on [0, T].
In what follows Bt will be m dimensional Brownian motion and the ﬁltration
will be denoted by Ht where Ht is the completion of the smallest σ algebra which
contains
(Bt0, · · ·, Btk)−1 (U)
whenever 0 ≤t0 < · · · < tk ≤t and U is a Borel set. Also, Z, a measurable Rn
valued function will be independent of Ht for all t > 0. Then HZ
t will denote the
completion of the smallest σ algebra which contains
¡
Z, Bt0, · · ·, Btk
¢−1 (U)
whenever 0 ≤t0 < · · · < tk ≤t and U is a Borel set. Then the following lemma is
what is needed to consider certain Itˆo integrals.
Lemma 35.22 Bt is an HZ
t martingale and if s > t, the increments Bs −Bt are
independent of HZ
t .
Proof: Let A, Uk, V for k = 0, · · ·, p be open sets and let s > t and
D =
¡
Z, Bt0, · · ·, Btp
¢−1 (A × U0 × · · · × Up) , E = (Bs −Bt)−1 (V ) .
I need to verify that P (D ∩E) = P (D) P (E) .
D ∩E = Z−1 (A) ∩∩p
i=0B−1
ti (Ui) ∩E
From independence of Z to Ht for all t > 0, and independence of the increments,
Bs −Bt to Ht,
P (D ∩E)
=
P
¡
Z−1 (A)
¢
P
¡
∩p
i=0B−1
ti (Ui) ∩E
¢
=
P
¡
Z−1 (A)
¢
P
¡
∩p
i=0B−1
ti (Ui)
¢
P (E)
=
P
¡
Z−1 (A) ∩∩p
i=0B−1
ti (Ui)
¢
P (E)
=
P (D) P (E) .
It follows that for all D an inverse image of an open set and E of the above form
where V is open, P (D ∩E) = P (D) P (E). It follows easily this holds for all D
and E inverse images of Borel sets. If D ∈Ht and E = (Bs −Bt)−1 (V ) then there
exists D1 an inverse image of a Borel set such that D1 ⊇D and P (D1 \ D) = 0 so
P (D ∩E)
=
P (D1 ∩E)
=
P (D1) P (E) = P (D) P (E) .

35.4.
STOCHASTIC DIFFERENTIAL EQUATIONS
963
This veriﬁes the independence.
Now let A ∈HZ
t . Then from the above independence result,
Z
A
E
¡
Bs −Bt|HZ
t
¢
dP
=
Z
A
Bs −BtdP
=
Z
A
dP
Z
Ω
Bs −BtdP = 0
and so
E
¡
Bs|HZ
t
¢
=
E
¡
Bs −Bt + Bt|HZ
t
¢
=
0 + E
¡
Bt|HZ
t
¢
= Bt.
This proves the lemma.
35.4.3
A Function Space
Lemma 35.23 Let C
¡
[0, T] ; L2 (Ω)p¢
denote the space of continuous functions
with values in L2 (Ω)p and for each λ ≥0, denote for X ∈C
¡
[0, T] ; L2 (Ω)p¢
||X||λ ≡max
n
e−λt ||X (t)||L2(Ω)p : t ∈[0, T]
o
Then all these norms are equivalent and
¡
C
¡
[0, T] ; L2 (Ω)p¢
, ||·||λ
¢
is a Banach
space. Suppose also that Gt is a ﬁltration and that X (t) is Gt measurable. Then by
changing X (t) There exists a B × F measurable function, Y such that for each
t, Y (t) is Gt measurable and for all t not in a Borel measurable set of mea-
sure zero, X (t) = Y (t) in L2 (Ω)p .Furthermore, if VG denotes those functions
in C
¡
[0, T] ; L2 (Ω)p¢
which are Gt adapted, then VG is a closed subspace of
C
¡
[0, T] ; L2 (Ω)p¢
.
Proof: The assertion about the norms and the Banach space are all obvious.
The main message is about the measurability assertions. Let P ≡{t0, · · ·, tn} be
a partition of [0, T] of the usual sort where 0 = t0 < t1 < · · · < tn = T. Then for
X ∈C
¡
[0, T] ; L2 (Ω)p¢
and Gt adapted, consider
XP (t) ≡
n
X
k=1
X (tk−1) X[tk−1,tk) (t) .
By the assumption of continuity of X, it follows ||X −XP ||λ →0 as ||P|| →0
where ||P|| is the norm of the partition given by max {|ti+1 −ti|} . Picking λ = 0
for convenience, it follows there exists a sequence of partitions, {Pn} such that
||X −XPn||0 < 2−n. Therefore, for each t ∈[0, T] , XPn (t) (ω) →X (t) (ω) a.e. ω.
It follows X (t) is Gt measurable.

964
STOCHASTIC PROCESSES
Now each XPn is B × F measurable because it is a ﬁnite sum of such functions.
It follows {XPn} is a Cauchy sequence in L2 ([0, T] × Ω)p and so there exists Y
which is B × F measurable and XPn converges to Y in L2 ([0, T] × Ω)p . Now
t →
Z
Ω
|XPn −Y|2 dP
is measurable and so taking the limit as n →∞, it follows
t →
Z
Ω
|X −Y|2 dP
is also measurable. Also
Z T
0
Z
Ω
|X −Y|2 dPdt
≤
2
ÃZ T
0
Z
Ω
|X −XPn|2 dPdt +
Z T
0
Z
Ω
|XPn −Y|2 dPdt
!
and both these integrals converge to 0 as n →∞. Therefore, there is a Borel set of
measure zero, N ⊆[0, T] such that for t /∈N,
Z
Ω
|X (t) −Y (t)|2 dP = 0
and it follows that for such t,
X (t) = Y (t) in L2 (Ω)p .
For t in the exceptional set, modify Y (t) by setting it equal to 0. Then Y is Gt
adapted.
It only remains to consider the last claim about VG. Suppose {Xn}∞
n=1 ⊆VG and
||Xn −Y||λ →0. I need to verify Y is Gt adapted. However, taking a subsequence,
still called n and letting λ = 0 for convenience, it can be assumed
||Xn −Y||0 < 2−n
and so it follows for each t ∈[0, T] , Xn (t) (ω) →Y (t) (ω) a.e. ω. It follows since
(Ω, Gt, P) is complete, Y (t) is Gt measurable for each t. This proves the lemma.
35.4.4
An Extension Of The Itˆo Integral
Now I will give a deﬁnition of the Itˆo integral on VG.
It is assumed here that
Gt is a ﬁltration with the property that m dimensional Brownian motion, Bt is a
martingale for it and if s > t, Bs −Bt is independent of Gt so it makes sense to
speak of an Itˆo integral,
R t
0 XT dB given X is Gt adapted, B × F measurable and in
L2 ([0, T] × Ω)m. Here is the deﬁnition.

35.4.
STOCHASTIC DIFFERENTIAL EQUATIONS
965
Deﬁnition 35.24 Let X ∈VG. Then
Z t
0
XT dB ≡
Z t
0
YT dB in L2 (Ω)p
where Y is a Gt adapted function which is B × F measurable and Y (t) = X (t) in
L2 (Ω)p for a.e. t ∈[0, T].
Lemma 35.25 The above deﬁnition is well deﬁned.
Proof: Suppose both Y and Y1 work as described in the deﬁnition. Then
||Y −Y1||L2([0,T ]×Ω)p = 0
and so by the Itˆo isometry,
¯¯¯¯
¯¯¯¯
Z t
0
¡
YT −YT
1
¢
dB
¯¯¯¯
¯¯¯¯
L2(Ω)p = 0
which shows
R t
0 YT dB =
R t
0 YT
1 dB in L2 (Ω)p. This proves the lemma.
For x ∈Rp, b (t, x) ∈Rm and σ (t, x) will be an p × m matrix. It is assumed
that for given x, y ∈Rp the following measurability and Lipschitz conditions hold.
t →b (t, x) , t →σ (t, x) are Lebesgue measurable,
(35.39)
|b (t, x) −b (t, y)| + |σ (t, x) −σ (t, y)| ≤K |x −y| ,
(35.40)
|b (t, x)| + |σ (t, x)| ≤C (1 + |x|) .
(35.41)
In the above, it suﬃces to have the components of b and σ measurable. Also,the
norm refers to any convenient norm. This does not matter because all the norms
on a ﬁnite dimensional vector space are equivalent.
Deﬁnition 35.26 Let Gt be a ﬁltration for which Bt is a martingale and such that
for s > t, Bs −Bt is independent of Gt. For X product measurable in B × F and
Gt adapted deﬁne
µZ t
0
σ (s, X) dB
¶
k
≡
Z t
0
(σ (s, X))k dB
where (σ (s, X))k refers to the kth row of the matrix, σ.
35.4.5
A Vector Valued Deterministic Integral
Lemma 35.27 Let X ∈C
¡
[0, T] ; L2 (Ω)p¢
and let b be given as above. Then
t →
Z
Ω
b (t, X (t)) dP

966
STOCHASTIC PROCESSES
is Lebesgue measurable. It is also possible to deﬁne an integral, having values in
L2 (Ω)p according to the following formula in which [a, b] ⊆[0, T].
ÃZ b
a
b (t, X (t)) dt, h
!
L2(Ω)p
≡
Z b
a
(b (t, X (t)) , h)L2(Ω)p dt
The integral deﬁned in this way satisﬁes all the usual algebraic properties for inte-
grals and
t →
Z t
a
b (s, X (s)) ds
is continuous as a function with values in L2 (Ω)p. Also if X is Gt adapted for Gt a
ﬁltration, then
Z b
a
b (s, X (s)) ds
is Gb measurable.
Proof: Let XPn (t) be the sequence of step functions converging to X (t) which
is described in Lemma 35.23. Then on [tj, tj+1),
Z
Ω
b (t, XPn (t)) dP =
Z
Ω
b (t, X (tj)) dP
where X (tj) ∈L2 (Ω)p . It follows X (tj) is the pointwise limit of simple functions
of the form Pm
k=1 ckXEk (ω) which also converge to X (tj) in L2 (Ω)p. Thus for
t ∈[tj, tj+1),
Z
Ω
b
Ã
t,
m
X
k=1
ckXEk (ω)
!
dP =
m
X
k=1
Z
Ek
b (t, ck) dP,
a measurable function of t. Now let {Sn} be a sequence of these simple functions
converging to X (tj) in L2 (Ω)p. Then
¯¯¯¯
Z
Ω
b (t, X (tj)) dP −
Z
Ω
b (t, Sn) dP
¯¯¯¯
≤
Z
Ω
K |Sn −X (tj)| dP
≤
K ||Sn −X (tj)||L2(Ω)p
and so
R
Ωb (t, X (tj)) dP is a pointwise limit of Lebesgue measurable functions on
[tj, tj+1). It follows
R
Ωb (t, XPn (t)) dP is Lebesgue measurable. Using a similar
argument to what was just done, this converges to
R
Ωb (t, X (t)) dP, and so this
last integral is also Lebesgue measurable in t. By a repeat of the above arguments
or by simple specializing to b having real values, it follows
t →
Z
Ω
|b (t, X (t))| dP

35.4.
STOCHASTIC DIFFERENTIAL EQUATIONS
967
is Lebesgue measurable. Also, using the properties of b and Holder’s inequality, if
Xn →X in C
¡
[0, T] ; L2 (Ω)p¢
,
¯¯¯¯
Z
Ω
|b (t, X (t))|2 dt −
Z
Ω
|b (t, Xn (t))|2 dt
¯¯¯¯ ≤C ||X (t) −Xn (t)||2
L2(Ω)p .
Therefore, exploiting the same sorts of arguments involving ﬁrst approximating by
step functions and then by simple functions, it follows t →
R
Ω|b (t, X (t))|2 dt is
Lebesgue measurable.
Next consider the deﬁnition of the integral. From the ﬁrst part,
t →(b (t, X (t)) , h)L2(Ω)p
is Lebesgue measurable and also
¯¯¯¯¯
Z b
a
(b (t, X (t)) , h)L2(Ω)p dt
¯¯¯¯¯ ≤
Z b
a
||b (t, X (t))||2
L2(Ω)p dt ||h||L2(Ω)p .
Letting Λ (h) ≡
R b
a (b (t, X (t)) , h)L2(Ω)p dt, it follows Λ is a continuous linear func-
tional on L2 (Ω)p and so by the Riesz representation theorem, there exists a unique
element of L2 (Ω)p denoted by
Z b
a
b (t, X (t)) dt
such that
ÃZ b
a
b (t, X (t)) dt, h
!
L2(Ω)p
=
Z b
a
(b (t, X (t)) , h)L2(Ω)p dt.
This completes the deﬁnition of the integral.
It is obvious the integral satisﬁes all the usual algebraic properties. Consider
the claim about continuity. Let s < t. Then
¯¯¯¯¯
µZ s
a
b (r, X (r)) dr −
Z t
a
b (r, X (r)) dr, h
¶
L2(Ω)p
¯¯¯¯¯
≤
¯¯¯¯¯
µZ t
s
b (r, X (r)) , h
¶
L2(Ω)p
¯¯¯¯¯ ≤
Z t
s
¯¯¯(b (r, X (r)) , h)L2(Ω)p
¯¯¯ dr
≤C
Z t
s
||b (r, X (r))||L2(Ω)p dr ||h||L2(Ω)p
≤C′ (t −s)1/2 ||h||L2(Ω)p .
It follows
¯¯¯¯
¯¯¯¯
Z s
a
b (r, X (r)) dr −
Z t
a
b (r, X (r)) dr
¯¯¯¯
¯¯¯¯
L2(Ω)p ≤C′ |t −s|1/2 .

968
STOCHASTIC PROCESSES
The last assertion follows from approximating by step functions as in Lemma
35.23, noting the step functions are Gb measurable and then passing to a limit to
obtain the desired conclusion. This proves the lemma.
35.4.6
The Existence And Uniqueness Theorem
In the next lemma, the two integrals are as deﬁned above.
Lemma 35.28 Let b and σ satisfy 35.39 - 35.41. Let Z be a random vector which
is either independent of Ht for all t > 0 or else is measurable with respect to Ht for
all t and suppose
Z
Ω
|Z|2 dP < ∞
Let Gt = HZ
t in the ﬁrst case and let Gt = Ht in the second. Then there exists a
unique solution, X ∈VG to the integral equation,
X (t) = Z +
Z t
0
b (s, X (s)) ds +
Z t
0
σ (s, X (s)) dB.
Proof: For X ∈VG, supplied with the norm ||·||λ described above, let
ΦX (t) ≡Z +
Z t
0
b (s, X (s)) ds +
Z t
0
σ (s, X (s)) dB
It follows from Corollary 31.43 on Page 890 and Lemmas 34.8 on Page 925 and
Lemma 35.27 that ΦX is Gt adapted and B × F measurable. The deterministic
integral is a continuous function of t with values in L2 (Ω)p by Lemma 35.27. The
same is true of the Itˆo integral. To see this, let Y be adapted and product measur-
able and equal to X for a.e. t. Then by the Itˆo isometry and the above deﬁnition
of this integral of functions in VG,
¯¯¯¯
¯¯¯¯
Z t
0
σ (r, X (r)) dB−
Z s
0
σ (r, X (r)) dB
¯¯¯¯
¯¯¯¯
2
L2(Ω)p
=
¯¯¯¯
¯¯¯¯
Z t
0
σ (r, Y (r)) dB−
Z s
0
σ (r, Y (r)) dB
¯¯¯¯
¯¯¯¯
2
L2(Ω)p
=
¯¯¯¯
¯¯¯¯
Z t
s
σ (r, Y (r)) dB
¯¯¯¯
¯¯¯¯
2
L2(Ω)p =
Z t
s
Z
Ω
|σ (r, Y (r))|2 dPdr
≤
2C
Z t
s
Z
Ω
³
1 + |Y (r)|2´
dPdr = 2C
Z t
s
Z
Ω
³
1 + |X (r)|2´
dPdr
which converges to 0 as s →t. Thus Φ : VG →VG.
In fact, if λ is large enough, Φ is a contraction mapping. I will show this next.
Let X, Y ∈VG and let X1, Y1 be corresponding measurable representatives as

35.4.
STOCHASTIC DIFFERENTIAL EQUATIONS
969
above. By the Itˆo isometry,
¯¯¯¯
¯¯¯¯e−λt
µZ t
0
σ (s, X (s)) dB−
Z t
0
σ (s, Y (s)) dB
¶¯¯¯¯
¯¯¯¯
2
L2(Ω)p
≤
e−λt
Z t
0
Z
Ω
|σ (s, X1 (s)) −σ (s, Y1 (s))|2 dPds
≤
Ke−λt
Z t
0
Z
Ω
|X1 (s) −Y1 (s)|2 dPds
=
Ke−λt
Z t
0
eλs
µ
e−λs
Z
Ω
|X (s) −Y (s)|2 dP
¶
ds
≤
K
Z t
0
eλ(s−t)ds ||X −Y||λ ≤K 1
λ ||X −Y||λ .
Thus if λ is large enough, this term is a contraction. Similar but easier reasoning
applies to the deterministic integral in the deﬁnition of Φ. Therefore, by the usual
contraction mapping theorem, Φ has a unique ﬁxed point in VG. This proves the
lemma.
Theorem 35.29 Let b and σ satisfy 35.39 - 35.41.
Let Z be a random vector
which is either independent of Ht for all t > 0 or else is measurable with respect to
Ht for all t and suppose
Z
Ω
|Z|2 dP < ∞
Let Gt = HZ
t in the ﬁrst case and let Gt = Ht in the second. Then there exists a
B × F measurable function, Y ∈L2 ([0, T] × Ω)p and a set of measure zero, N such
that for ω /∈N,
Y (t) (ω) = Z +
Z t
0
b (s, Y (s) (ω)) ds +
Z t
0
σ (s, Y (s)) dB (ω)
for all t ∈[0, T].
Proof: Let X be the solution of Lemma 35.28. Thus
X (t) = Z +
Z t
0
b (s, X (s)) ds +
Z t
0
σ (s, X (s)) dB.
Now let eY be B × F measurable, adapted, in L2 ([0, T] × Ω)p , and eY (t) = X (t)
a.e. t. Letting h ∈L2 (Ω)p , the deﬁnition of the ﬁrst integral in the above implies
¯¯¯¯¯
µZ t
0
b (s, X (s)) ds −
Z t
0
b
³
s, eY (s) (·)
´
ds, h
¶
L2(Ω)p
¯¯¯¯¯

970
STOCHASTIC PROCESSES
≤
Z t
0
³
b (s, X (s)) −b
³
s, eY (s)
´
, h
´
L2(Ω)p ds
≤
K
Z t
0
¯¯¯
¯¯¯X (s) −eY (s)
¯¯¯
¯¯¯
L2(Ω)p ds ||h||L2(Ω)p = 0
and so
Z t
0
b (s, X (s)) ds =
Z t
0
b
³
s, eY (s)
´
ds in L2 (Ω)p .
It follows that in L2 (Ω)p ,
X (t) = Z +
Z t
0
b
³
s, eY (s)
´
ds +
Z t
0
σ
³
s, eY (s)
´
dB
(35.42)
where now the ﬁrst integral on the right is the usual thing given by
Z t
0
b
³
s, eY (s)
´
ds (ω) =
Z t
0
b
³
s, eY (s) (ω)
´
ds
Also, for a.e. ω, t →eY (t) (ω) is a function in L2 (0, T) and from the theory of
the Itˆo integral,
R t
0 σ
³
s, eY (s)
´
dB is a continuous function of t for ω not in a set of
measure zero. Therefore, for ω oﬀa set of measure zero, the right side of 35.42 is
continuous in t. It also delivers an adapted product measurable function, Y. Thus
for a.e. ω, Y (t) (ω) is a continuous function of t and
Y (t) = Z +
Z t
0
b
³
s, eY (s)
´
ds +
Z t
0
σ
³
s, eY (s)
´
dB
and so Y (t) = X (t) in L2 (Ω)p for all t. Now this also shows Y (t) = eY (t) for a.e.
t. Hence by the Itˆo isometry, the right side of the above is unchanged in L2 (Ω)p if eY
is replaced by Y. By the argument just given, the resulting right side is continuous
in t for a.e. ω and so there exists a set of measure zero such that for ω not in this
set,
Y (t) (ω) = Z +
Z t
0
b (s, Y (s) (ω)) ds +
Z t
0
σ (s, Y (s)) dB (ω)
and both sides are continuous functions of t. This proves the theorem.
Note there were two cases given for the initial condition in the above theorem.
The second is not very interesting. If Z is H0 measurable, then since B0 = x, a
constant, it follows H0 = {∅, Ω} so Z is a constant. However, if Z is a constant,
then it satisﬁes the ﬁrst condition.
Not surprisingly, the solution to the above theorem is unique. This is stated as
the following corollary which is the main result.
Corollary 35.30 Let b and σ satisfy 35.39 - 35.41. Let Z be a random vector
which is independent of Ht for all t > 0 and suppose
Z
Ω
|Z|2 dP < ∞

35.4.
STOCHASTIC DIFFERENTIAL EQUATIONS
971
Then there exists a unique HZ
t adapted solution, X ∈L2 ([0, T] × Ω)n to the integral
equation,
X (t) = Z +
Z t
0
b (s, X (s)) ds +
Z t
0
σ (s, X (s)) dB a.e. ω
(35.43)
in the sense that if eX is another solution, then there exists a set of measure zero,
N such that for ω /∈N, eX (t) = X (t) for all t ∈[0, T].
Proof: The existence part of this proof is already done. Let N denote the union
of the exceptional sets corresponding to X and eX . Then from 35.43 and the various
assumptions on b and σ,it follows that for ω /∈N,
¯¯¯X (t) −eX (t)
¯¯¯
2
≤
2K2T
Z t
0
¯¯¯X (s) −eX (s)
¯¯¯
2
ds
+2
¯¯¯¯
Z t
0
³
σ (s, X (s)) −σ
³
s, eX (s)
´´
dB
¯¯¯¯
2
.
Then by the Itˆo isometry, this implies
¯¯¯
¯¯¯X (t) −eX (t)
¯¯¯
¯¯¯
2
L2(Ω)n
≤
2K2T
Z t
0
¯¯¯
¯¯¯X (s) −eX (s)
¯¯¯
¯¯¯
2
L2(Ω)n ds
+2
Z t
0
¯¯¯
¯¯¯σ (s, X (s)) −σ
³
s, eX (s)
´¯¯¯
¯¯¯
2
ds
≤
CT
Z t
0
¯¯¯
¯¯¯X (s) −eX (s)
¯¯¯
¯¯¯
2
L2(Ω)n ds
(35.44)
and by assumption both X and eX are in L2 ([0, T] × Ω)n so t →
¯¯¯
¯¯¯X (t) −eX (t)
¯¯¯
¯¯¯
2
L2(Ω)n
is in L1 ([0, T]). By Gronwall’s inequality, eX (t) = X (t) in L2 (Ω)n for all t. It fol-
lows there exists a set of measure zero, N1 such that for ω /∈N1,
Z T
0
¯¯¯ eX (t) −X (t)
¯¯¯
2
dt = 0
But for ω /∈N, the functions, eX and X are continuous and so if ω /∈N1 ∪N, eX (t) =
X (t) for all t. This proves the corollary.
Note that if diﬀerent initial conditions had been given, say Z and Z1, the above
argument for uniqueness also gives a continuous dependence result with no eﬀort.
In fact, 35.44 then would take the form
¯¯¯
¯¯¯X (t) −eX (t)
¯¯¯
¯¯¯
2
L2(Ω)n ≤3 ||Z −Z1||2
L2(Ω)n + CT
Z t
0
¯¯¯
¯¯¯X (s) −eX (s)
¯¯¯
¯¯¯
2
L2(Ω)n ds

972
STOCHASTIC PROCESSES
and Gronwall’s inequality would then imply
¯¯¯
¯¯¯X (t) −eX (t)
¯¯¯
¯¯¯
2
L2(Ω)n ≤C ||Z −Z1||2
L2(Ω)n
for some constant, C.
The equivalent form of the above integral equation,
X (t) = Z +
Z t
0
b (s, X (s)) ds +
Z t
0
σ (s, X (s)) dB
is
dX = b (t, X) dt + σ (t, X (t)) dB, X (0) = Z.
35.4.7
Some Simple Examples
Here are some examples of simple stochastic diﬀerential equations which are solved
using the Itˆo formula.
Example 35.31 In this example, m = n = 1 and B is one dimensional Brownian
motion. The diﬀerential equation is
dX = h (t) XdB, X (0) = 1
Obviously, one would want to do something like dX
X = h (t) dB. However, you
have to follow the rules. Let g (x) = ln (x) and Y = g (X) . Then by the Itˆo formula,
dY
=
1
X dX + 1
2
µ −1
X2
¶
dX2
=
1
X h (t) XdB −1
2
1
X2 h (t)2 X2dB2
=
h (t) dB −1
2h (t)2 dt
and also Y (0) = 0. Therefore, Y (t) = ln (X (t)) =
R t
0 h (s) dB −1
2
R t
0 h (t)2 dt and
so
X (t) = exp
µZ t
0
h (s) dB −1
2
Z t
0
h (s)2 ds
¶
Note the extra term, −1
2
R t
0 h (s)2 ds.
Example 35.32 Let m = n = 1.
dX = f (t) Xdt + h (t) XdB, X (0) = 1.

35.4.
STOCHASTIC DIFFERENTIAL EQUATIONS
973
In this case it is a lot like the above example but it has an extra f (t) Xdt. This
suggests something useful might be obtained by letting Y = ln (X) as was done
earlier. Thus
dY
=
1
X (Xf (t) dt + h (t) XdB) + 1
2
µ −1
X2
¶
(f (t) dt + h (t) XdB)2
=
1
X (Xf (t) dt + h (t) XdB) + 1
2
µ −1
X2
¶
h (t)2 X2dB2
=
1
X
µ
Xf (t) dt −1
2Xh (t)2 dt + h (t) XdB
¶
=
µ
f (t) −1
2h (t)2
¶
dt + h (t) dB
and so ln (X) =
R t
0
³
f (s) −1
2h (s)2´
ds +
R t
0 h (s) dB and so
X (t) = exp
µZ t
0
µ
f (s) −1
2h (s)2
¶
ds +
Z t
0
h (s) dB
¶
The next example is a model for stock prices. Learn this model and get rich.
Example 35.33 For P (t) the price of stock,
dP = µPdt + σPdB
In this model, µ is called the drift and σ is called the volatility.
It is just a special case of the above model in which f (t) = µ and h (t) = σ.
Then from the above,
P (t) = exp
µ
tµ −1
2tσ2 + σBt
¶
Example 35.34 This example is called the Brownian bridge.
dX = −X
1 −t + dB, X (0) = 0.
This is also a special case in which f (t) = 1/ (t −1) and h (t) = 1. Thus the
solution is
X (t)
=
exp
µZ t
0
µ
1
t −1 −1
2
¶
ds + Bt
¶
=
exp
µ1
2
Z t
0
µt −3
t −1
¶
ds + Bt
¶
=
exp
µ1
2t
µt −3
t −1
¶
+ Bt
¶
Before doing another example I will give a simple lemma on integration by parts.
In this lemma B will denote m dimensional Brownian motion.

974
STOCHASTIC PROCESSES
Lemma 35.35 Let (t, ω) →g (t, ω) be an Gt adapted measurable function such that
P
µZ t
0
|g (s, ω)|2 ds < ∞
¶
= 1
where Bt is a martingale with respect to the ﬁltration Gt and the increments, Bs−Bt
for s > t are independent of Gt so that the Itˆo integral,
R t
0 gT dB is deﬁned. Suppose
also that t →g (t, ω) is C1 and B0 = 0. Then
Z t
0
gT (s, ω) dB = gT (t, ω) Bt (ω) −
Z t
0
∂gT
∂t (s, ω) B (s) ds a.e.
Proof: Let gn (t) ≡Pn−1
k=0 g (tk) X[tk,tk+1) (t) where tk = k (t/n) . Then by the
deﬁnition of the Itˆo integral,
Z t
0
gT dB
=
lim
n→∞
Z t
0
gT
n dB = lim
n→∞
n−1
X
k=0
g (tk)T ¡
Btk+1 −Btk
¢
=
lim
n→∞
Ã n
X
k=1
g (tk−1)T Btk −
n−1
X
k=0
g (tk)T Btk
!
=
lim
n→∞
"³
g (tn−1)T Bt
´
−
n−1
X
k=1
³
g (tk)T −g (tk−1)T ´
Btk
#
=
g (t, ω) Bt (ω) −
Z t
0
∂gT
∂t (s, ω) B (s, ω) ds a.e. ω.
Example 35.36 Linear systems of equations. Here B is m dimensional Brownian
motion. The equation of interest is
dX = (AX + h (t)) dt + KdB, X (0) = X0
where X0 is a random vector in Rm which is independent of Ht for all t ≥0 and
A, K are constant m × m matrices. Then I will show
X (t) = eAt
µ
X0 +
Z t
0
¡
e−Ash (s) + e−AsAKB (s)
¢
ds + e−AtKB (t)
¶
Let Y (t) = e−AtX (t) . Then from the above,
dY
=
−Ae−AtX + e−AtIdX+1
2e−AtdXT 0dX
=
−Ae−AtX + e−AtI ((AX + h (t)) dt + KdB)
=
e−Ath (t) dt + e−AtKdB.
Hence using integration by parts,
e−AtX (t) −X0
=
Z t
0
e−Ash (s) ds +
Z t
0
e−AsKdB
=
Z t
0
e−Ash (s) ds + e−AtKB (t) + A
Z t
0
e−AsKB (s) ds

35.5.
A DIFFERENT PROOF OF EXISTENCE AND UNIQUENESS
975
and so
X (t)
=
eAt
µ
X0 +
Z t
0
e−Ash (s) ds + e−AtKB (t) + A
Z t
0
e−AsKB (s) ds
¶
=
eAt
µ
X0 +
Z t
0
¡
e−Ash (s) + e−AsAKB (s)
¢
ds + e−AtKB (t)
¶
.(35.45)
In this formula e−As is the matrix, M (t) which solves M ′ = AM, M (0) = I.
Note that formally diﬀerentiating the above equation gives
X′
=
AeAt
µ
X0 +
Z t
0
¡
e−Ash (s) + e−AsAKB (s)
¢
ds + e−AtKB (t)
¶
+eAt
µ¡
e−Ath (t) + e−AtAKB (t)
¢
−Ae−AtKB (t) + e−AtK dB
dt
¶
and so
X′
=
AX + h (t) + AKB (t) −AKB (t) + K dB
dt
=
AX + h (t) + K dB
dt .
Of course this is total nonsense because B is known to not be diﬀerentiable. How-
ever, multiplying by dt gives
dX = (AX + h (t)) dt + KdB
and the formula 35.45 shows X (0) = X0. This was the original diﬀerential equation.
Note that it was not necessary to assume very much about X0 to write 35.45.
35.5
A Diﬀerent Proof Of Existence And Unique-
ness
The proof given here is much longer and uses Picard Iteration directly. However, it
requires much less background material so the over all presentation is shorter.
35.5.1
Gronwall’s Inequality
The fundamental tool in estimating diﬀerential equations is Gronwall’s inequality.
It is a very elementary result but of enormous signiﬁcance. I will ﬁrst give a proof
of this important theorem. Also, I will write X (t) rather than Xt.
Lemma 35.37 Let k ≥0 and suppose u (t) is a Lebesgue measurable function in
L1 ([0, T]) which satisﬁes
u (t) ≤u0 +
Z t
0
ku (s) ds.

976
STOCHASTIC PROCESSES
Then
u (t) ≤u0ekt.
Proof: Let
f (t) = u0ekt −
µ
u0 +
Z t
0
ku (s) ds
¶
.
Then f (0) = 0 and
f ′ (t)
=
ku0ekt −ku (t)
≥
ku0ekt −k
µ
u0 +
Z t
0
ku (s) ds
¶
=
kf (t)
and so f ′ (t) −kf (t) ≥0 and so
d
dt
¡
e−ktf (t)
¢
≥0
which implies f (t) ≥0. Hence
u (t) ≤u0 +
Z t
0
ku (s) ds ≤u0ekt.
This proves Gronwall’s inequality.
35.5.2
Review Of Itˆo Integrals
Next recall the deﬁnition of the Itˆo integral. The context is that Ht is a ﬁltration,
Bt is a martingale for Ht, and if s > t, Bs −Bt is independent of Ht.
Deﬁnition 35.38 Suppose f is Ht adapted and B × F measurable such that for
ω /∈E a set of measure zero,
Z T
S
f (t, ω)2 dt < ∞.
Then there exists a sequence of adapted bounded step functions, {φn} satisfying
Z T
S
(f (t, ω) −φn (t, ω))2 dt ≤2−n
for ω /∈E, a set of measure zero. Then for t ∈[S, T] , the Itˆo integral is deﬁned by
Z t
S
fdB (ω) = lim
n→∞
Z t
S
φndB (ω) .
Furthermore, for these ω, t →
R t
S fdB (ω) is continuous because by Theorem 34.5
the convergence of
R t
S φndB (ω) is uniform on [0, T].

35.5.
A DIFFERENT PROOF OF EXISTENCE AND UNIQUENESS
977
In what follows Bt will be m dimensional Brownian motion and the ﬁltration
will be denoted by Ht where Ht is the completion of the smallest σ algebra which
contains
(Bt0, · · ·, Btk)−1 (U)
whenever 0 ≤t0 < · · · < tk ≤t and U is a Borel set. Also, Z, a measurable Rn
valued function will be independent of Ht for all t > 0. Then HZ
t will denote the
completion of the smallest σ algebra which contains
¡
Z, Bt0, · · ·, Btk
¢−1 (U)
whenever 0 ≤t0 < · · · < tk ≤t and U is a Borel set. Then the following lemma is
what is needed to consider certain Itˆo integrals.
Lemma 35.39 Bt is an HZ
t martingale and if s > t, the increments Bs −Bt are
independent of HZ
t .
Proof: Let A, Uk, V for k = 0, · · ·, p be open sets and let s > t and
D =
¡
Z, Bt0, · · ·, Btp
¢−1 (A × U0 × · · · × Up) , E = (Bs −Bt)−1 (V ) .
I need to verify that P (D ∩E) = P (D) P (E) .
D ∩E = Z−1 (A) ∩∩p
i=0B−1
ti (Ui) ∩E
From independence of Z to Ht for all t > 0, and independence of the increments,
Bs −Bt to Ht,
P (D ∩E)
=
P
¡
Z−1 (A)
¢
P
¡
∩p
i=0B−1
ti (Ui) ∩E
¢
=
P
¡
Z−1 (A)
¢
P
¡
∩p
i=0B−1
ti (Ui)
¢
P (E)
=
P
¡
Z−1 (A) ∩∩p
i=0B−1
ti (Ui)
¢
P (E)
=
P (D) P (E) .
It follows that for all D an inverse image of an open set and E of the above form
where V is open, P (D ∩E) = P (D) P (E). It follows easily this holds for all D
and E inverse images of Borel sets. If D ∈Ht and E = (Bs −Bt)−1 (V ) then there
exists D1 an inverse image of a Borel set such that D1 ⊇D and P (D1 \ D) = 0 so
P (D ∩E)
=
P (D1 ∩E)
=
P (D1) P (E) = P (D) P (E) .
This veriﬁes the independence.
Now let A ∈HZ
t . Then from the above independence result,
Z
A
E
¡
Bs −Bt|HZ
t
¢
dP
=
Z
A
Bs −BtdP
=
Z
A
dP
Z
Ω
Bs −BtdP = 0

978
STOCHASTIC PROCESSES
and so
E
¡
Bs|HZ
t
¢
=
E
¡
Bs −Bt + Bt|HZ
t
¢
=
0 + E
¡
Bt|HZ
t
¢
= Bt.
This proves the lemma.
For x ∈Rn, b (t, x) ∈Rm and σ (t, x) will be an n × m matrix. It is assumed
that for given x, y ∈Rn the following measurability and Lipschitz conditions hold.
t →b (t, x) , t →σ (t, x) are Lebesgue measurable,
(35.46)
|b (t, x) −b (t, y)| + |σ (t, x) −σ (t, y)| ≤K |x −y| ,
(35.47)
|b (t, x)| + |σ (t, x)| ≤C (1 + |x|) .
(35.48)
In the above, it suﬃces to have the components of b and σ measurable. Also,the
norm refers to any convenient norm. This does not matter because all the norms
on a ﬁnite dimensional vector space are equivalent.
Deﬁnition 35.40 Let Gt be a ﬁltration for which Bt is a martingale and such that
for s > t, Bs −Bt is independent of Gt. For X product measurable in B × F and
Gt adapted deﬁne
µZ t
0
σ (s, X) dB
¶
k
≡
Z t
0
(σ (s, X))k dB
where (σ (s, X))k denotes the kth row of the matrix, σ.
35.5.3
The Existence And Uniqueness Theorem
Theorem 35.41 Let b and σ satisfy 35.46 - 35.48.
Let Z be a random vector
which is either independent of Ht for all t > 0 or else is measurable with respect to
Ht for all t and suppose
Z
Ω
|Z|2 dP < ∞
Let Gt = HZ
t in the ﬁrst case and let Gt = Ht in the second. Then there exists a
solution, X to the integral equation,
X (t) = Z +
Z t
0
b (s, X (s)) ds +
Z t
0
σ (s, X (s)) dB a.e. ω
This solution satisﬁes X ∈L2 ([0, T] × Ω)n.
Proof: Let iterates be deﬁned as follows.
X1 (t) ≡Z +
Z t
0
b (s, Z) ds +
Z t
0
σ (s, Z) dB

35.5.
A DIFFERENT PROOF OF EXISTENCE AND UNIQUENESS
979
The Itˆo integral on the right is well deﬁned for all ω not in some set of measure
zero because Z is Gt adapted. Now also X1 is Gt adapted because both integrals in
the above yield Gt adapted functions of t by Theorem 34.8 on Page 925 and the Itˆo
integral yields B × F measurable function by Corollary 31.43 on Page 890 and the
convention mentioned after this corollary. Then
X2 (t) ≡Z +
Z t
0
b
¡
s, X1 (s)
¢
ds +
Z t
0
σ
¡
s, X1 (s)
¢
dB.
Continue this way. Each iteration involves a set of measure zero. Take the union of
all these sets, N. Then for ω /∈N
Xk+1 (t) ≡Z +
Z t
0
b
¡
s, Xk (s)
¢
ds +
Z t
0
σ
¡
s, Xk (s)
¢
dB
(35.49)
and each Xk is Gt adapted and B × F measurable. Now
Z
Ω
¯¯Xk+1 (t) −Xk (t)
¯¯2 dP
≤
TK
Z
Ω
Z t
0
¯¯Xk (s) −Xk−1 (s)
¯¯2 ds
+
Z
Ω
¯¯¯¯
Z t
0
σ
¡
s, Xk (s)
¢
−σ
¡
s, Xk−1 (s)
¢
dB
¯¯¯¯
2
dP.
Using the Itˆo isometry,
≤
TK
Z t
0
Z
Ω
¯¯Xk (s) −Xk−1 (s)
¯¯2 dPds
+
Z
Ω
Z t
0
¯¯σ
¡
s, Xk (s)
¢
−σ
¡
s, Xk−1 (s)
¢¯¯2 dsdP
≤
TK
Z t
0
Z
Ω
¯¯Xk (s) −Xk−1 (s)
¯¯2 dPds
+K
Z t
0
Z
Ω
¯¯Xk (s) −Xk−1 (s)
¯¯2 dPds
≤
CT
Z t
0
Z
Ω
¯¯Xk (s) −Xk−1 (s)
¯¯2 dPds
where CT is a constant depending on T and K. Then iterating this inequality yields
Z
Ω
¯¯Xk+1 (t) −Xk (t)
¯¯2 dP
≤
Ck
T
Z t
0
Z t1
0
· · ·
Z tk−1
0
Z
Ω
¯¯X1 (tk) −Z
¯¯2 dPdtk · · · dt1.

980
STOCHASTIC PROCESSES
Now
Z
Ω
¯¯X1 (tk) −Z
¯¯2 dP
≤
CT
ÃZ T
0
Z
Ω
³
1 + |Z|2´
dPdt
!
≡CZ < ∞.
Then it follows
µZ
Ω
¯¯Xk+1 (t) −Xk (t)
¯¯2 dP
¶1/2
≤
µ
Ck
T CZ
Z t
0
Z t1
0
· · ·
Z tk−1
0
dtk · · · dt1
¶1/2
≤
µ
Ck
T CZ
tk
k!
¶1/2
≤
µ
Ck
T CZ
T k
k!
¶1/2
.
Since P∞
k=0
³
Ck
T CZ T k
k!
´1/2
< ∞, it follows
©
Xkª
converges in C
¡
[0, T] ; L2 (Ω)n¢
to a function, f
X. It follows
©
Xkª
is also Cauchy in L2 ([0, T] × Ω)n . Therefore,
there exists X, B × F measurable and in L2 ([0, T] × Ω) such that upon taking
a suitable subsequence still denoted by k,
©
Xkª
converges to X pointwise and in
L2 ([0, T] × Ω)n. The function, t →
R
Ω
¯¯¯X −Xk¯¯¯
2
dP is Lebesgue measurable and
t →
R
Ω
¯¯¯X−eX
¯¯¯
2
dP is the limit so it is also Lebesgue measurable. Also,
Z T
0
Z
Ω
¯¯¯X−eX
¯¯¯
2
dPdt ≤2
ÃZ T
0
Z
Ω
¯¯¯X −Xk¯¯¯
2
dPdt +
Z T
0
Z
Ω
¯¯¯Xk−eX
¯¯¯
2
dPdt
!
and both of these integrals converge to 0 as k →∞, the ﬁrst because of convergence
in L2 ([0, T] × Ω)n and the second because of the uniform convergence of Xk to eX.
Therefore, X (t) = eX (t) in L2 (Ω)n for a.e. t. Changing X (t) on this exceptional
set by setting it equal to 0, it follows X is product measurable and adapted because
it either is identically 0 on a set of measure zero or X (t) = eX (t) and it is clear eX
is adapted.
Now recall 35.49. Consider the Itˆo integral. By the Itˆo isometry and the Lips-
chitz property of σ,
nR t
0 σ
¡
s, Xk (s)
¢
dB
o
converges to
R t
0 σ (s, X (s)) dB in L2 (Ω)n
for each t. Using the Lipschitz property of b, and passing to the limit in 35.49 the
following equation must hold in L2 (Ω)n.
eX (t) ≡Z +
Z t
0
b (s, X (s)) ds +
Z t
0
σ (s, X (s)) dB
(35.50)
For a.e. ω, the right side of the above is a continuous function of t. This is true of
the Itˆo integral and it also follows for the deterministic integral because of the ob-
servation that for a.e. ω, s →X (s) (ω) is in L2 (0, T) . For ω not in this exceptional
set of measure zero, deﬁne
Y (t) (ω) ≡Z +
Z t
0
b (s, X (s) (ω)) ds +
Z t
0
σ (s, X (s)) dB (ω)
(35.51)

35.5.
A DIFFERENT PROOF OF EXISTENCE AND UNIQUENESS
981
Thus Y (t) is adapted by Theorem 34.8 on Page 925 and Y is product measurable.
Also it follows from 35.50 that Y (t) = eX (t) in L2 (Ω)n and X (t) = eX (t) for a.e. t
so Y (t) = X (t) a.e. t. It follows that
Y (t) ≡Z +
Z t
0
b (s, Y (s)) ds +
Z t
0
σ (s, Y (s)) dB
(35.52)
holds in L2 (Ω)n for each t and so equality is also true in L2 ([0, T] × Ω)n . As before,
the right side is a continuous function of t for ω oﬀa set of measure zero. Oﬀa set
of measure zero, t →Y (t) (ω) is also continuous. This follows from the deﬁnition
of Y (t) in 35.51. Since both sides are product measurable, there exists a set of
measure zero, N such that for ω /∈N,
Z T
0
¯¯¯¯Y (t) −
µ
Z +
Z t
0
b (s, Y (s)) ds +
Z t
0
σ (s, Y (s)) dB
¶¯¯¯¯
2
dt = 0
and the integrand is a continuous function. Therefore, 35.52 holds a.e. and both
sides are continuous for ω not in a suitable set of measure zero. This proves the
theorem.
Note there were two cases given for the initial condition in the above theorem.
The second is not very interesting. If Z is H0 measurable, then since B0 = x, a
constant, it follows H0 = {∅, Ω} so Z is a constant. However, if Z is a constant,
then it satisﬁes the ﬁrst condition.
Not surprisingly, the solution to the above theorem is unique. This is stated as
the following corollary which is the main result.
Corollary 35.42 Let b and σ satisfy 35.46 - 35.48. Let Z be a random vector
which is independent of Ht for all t > 0 and suppose
Z
Ω
|Z|2 dP < ∞
Then there exists a unique HZ
t adapted solution, X ∈L2 ([0, T] × Ω)n to the integral
equation,
X (t) = Z +
Z t
0
b (s, X (s)) ds +
Z t
0
σ (s, X (s)) dB a.e. ω
(35.53)
in the sense that if eX is another solution, then there exists a set of measure zero,
N such that for ω /∈N, eX (t) = X (t) for all t ∈[0, T].
Proof: The existence part of this proof is already done. Let N denote the union
of the exceptional sets corresponding to X and eX . Then from 35.53 and the various
assumptions on b and σ,it follows that for ω /∈N,
¯¯¯X (t) −eX (t)
¯¯¯
2
≤
2K2T
Z t
0
¯¯¯X (s) −eX (s)
¯¯¯
2
ds
+2
¯¯¯¯
Z t
0
³
σ (s, X (s)) −σ
³
s, eX (s)
´´
dB
¯¯¯¯
2
.

982
STOCHASTIC PROCESSES
Then by the Itˆo isometry, this implies
¯¯¯
¯¯¯X (t) −eX (t)
¯¯¯
¯¯¯
2
L2(Ω)n
≤
2K2T
Z t
0
¯¯¯
¯¯¯X (s) −eX (s)
¯¯¯
¯¯¯
2
L2(Ω)n ds
+2
Z t
0
¯¯¯
¯¯¯σ (s, X (s)) −σ
³
s, eX (s)
´¯¯¯
¯¯¯
2
ds
≤
CT
Z t
0
¯¯¯
¯¯¯X (s) −eX (s)
¯¯¯
¯¯¯
2
L2(Ω)n ds
(35.54)
and by assumption both X and eX are in L2 ([0, T] × Ω)n so t →
¯¯¯
¯¯¯X (t) −eX (t)
¯¯¯
¯¯¯
2
L2(Ω)n
is in L1 ([0, T]). By Gronwall’s inequality, eX (t) = X (t) in L2 (Ω)n for all t. It fol-
lows there exists a set of measure zero, N1 such that for ω /∈N1,
Z T
0
¯¯¯ eX (t) −X (t)
¯¯¯
2
dt = 0
But for ω /∈N, the functions, eX and X are continuous and so if ω /∈N1 ∪N, eX (t) =
X (t) for all t. This proves the corollary.
Note that if diﬀerent initial conditions had been given, say Z and Z1, the above
argument for uniqueness also gives a continuous dependence result with no eﬀort.
In fact, 35.54 then would take the form
¯¯¯
¯¯¯X (t) −eX (t)
¯¯¯
¯¯¯
2
L2(Ω)n ≤3 ||Z −Z1||2
L2(Ω)n + CT
Z t
0
¯¯¯
¯¯¯X (s) −eX (s)
¯¯¯
¯¯¯
2
L2(Ω)n ds
and Gronwall’s inequality would then imply
¯¯¯
¯¯¯X (t) −eX (t)
¯¯¯
¯¯¯
2
L2(Ω)n ≤C ||Z −Z1||2
L2(Ω)n
for some constant, C.
The equivalent form of the above integral equation,
X (t) = Z +
Z t
0
b (s, X (s)) ds +
Z t
0
σ (s, X (s)) dB
is
dX = b (t, X) dt + σ (t, X (t)) dB, X (0) = Z.
35.5.4
Some Simple Examples
Here are some examples of simple stochastic diﬀerential equations which are solved
using the Itˆo formula.

35.5.
A DIFFERENT PROOF OF EXISTENCE AND UNIQUENESS
983
Example 35.43 In this example, m = n = 1 and B is one dimensional Brownian
motion. The diﬀerential equation is
dX = h (t) XdB, X (0) = 1
Obviously, one would want to do something like dX
X = h (t) dB. However, you
have to follow the rules. Let g (x) = ln (x) and Y = g (X) . Then by the Itˆo formula,
dY
=
1
X dX + 1
2
µ −1
X2
¶
dX2
=
1
X h (t) XdB −1
2
1
X2 h (t)2 X2dB2
=
h (t) dB −1
2h (t)2 dt
and also Y (0) = 0. Therefore, Y (t) = ln (X (t)) =
R t
0 h (s) dB −1
2
R t
0 h (t)2 dt and
so
X (t) = exp
µZ t
0
h (s) dB −1
2
Z t
0
h (s)2 ds
¶
Note the extra term, −1
2
R t
0 h (s)2 ds.
Example 35.44 Let m = n = 1.
dX = f (t) Xdt + h (t) XdB, X (0) = 1.
In this case it is a lot like the above example but it has an extra f (t) Xdt. This
suggests something useful might be obtained by letting Y = ln (X) as was done
earlier. Thus
dY
=
1
X (Xf (t) dt + h (t) XdB) + 1
2
µ −1
X2
¶
(f (t) dt + h (t) XdB)2
=
1
X (Xf (t) dt + h (t) XdB) + 1
2
µ −1
X2
¶
h (t)2 X2dB2
=
1
X
µ
Xf (t) dt −1
2Xh (t)2 dt + h (t) XdB
¶
=
µ
f (t) −1
2h (t)2
¶
dt + h (t) dB
and so ln (X) =
R t
0
³
f (s) −1
2h (s)2´
ds +
R t
0 h (s) dB and so
X (t) = exp
µZ t
0
µ
f (s) −1
2h (s)2
¶
ds +
Z t
0
h (s) dB
¶
The next example is a model for stock prices. Learn this model and get rich.

984
STOCHASTIC PROCESSES
Example 35.45 For P (t) the price of stock,
dP = µPdt + σPdB
In this model, µ is called the drift and σ is called the volatility.
It is just a special case of the above model in which f (t) = µ and h (t) = σ.
Then from the above,
P (t) = exp
µ
tµ −1
2tσ2 + σBt
¶
Example 35.46 This example is called the Brownian bridge.
dX = −X
1 −t + dB, X (0) = 0.
This is also a special case in which f (t) = 1/ (t −1) and h (t) = 1. Thus the
solution is
X (t)
=
exp
µZ t
0
µ
1
t −1 −1
2
¶
ds + Bt
¶
=
exp
µ1
2
Z t
0
µt −3
t −1
¶
ds + Bt
¶
=
exp
µ1
2t
µt −3
t −1
¶
+ Bt
¶
Before doing another example I will give a simple lemma on integration by parts.
In this lemma B will denote m dimensional Brownian motion.
Lemma 35.47 Let (t, ω) →g (t, ω) be an Gt adapted measurable function such that
P
µZ t
0
|g (s, ω)|2 ds < ∞
¶
= 1
where Bt is a martingale with respect to the ﬁltration Gt and the increments, Bs−Bt
for s > t are independent of Gt so that the Itˆo integral,
R t
0 gT dB is deﬁned. Suppose
also that t →g (t, ω) is C1 and B0 = 0. Then
Z t
0
gT (s, ω) dB = gT (t, ω) Bt (ω) −
Z t
0
∂gT
∂t (s, ω) B (s) ds a.e.

35.5.
A DIFFERENT PROOF OF EXISTENCE AND UNIQUENESS
985
Proof: Let gn (t) ≡Pn−1
k=0 g (tk) X[tk,tk+1) (t) where tk = k (t/n) . Then by the
deﬁnition of the Itˆo integral,
Z t
0
gT dB
=
lim
n→∞
Z t
0
gT
n dB = lim
n→∞
n−1
X
k=0
g (tk)T ¡
Btk+1 −Btk
¢
=
lim
n→∞
Ã n
X
k=1
g (tk−1)T Btk −
n−1
X
k=0
g (tk)T Btk
!
=
lim
n→∞
"³
g (tn−1)T Bt
´
−
n−1
X
k=1
³
g (tk)T −g (tk−1)T ´
Btk
#
=
g (t, ω) Bt (ω) −
Z t
0
∂gT
∂t (s, ω) B (s, ω) ds a.e. ω.
Example 35.48 Linear systems of equations. Here B is m dimensional Brownian
motion. The equation of interest is
dX = (AX + h (t)) dt + KdB, X (0) = X0
where X0 is a random vector in Rm which is independent of Ht for all t ≥0 and
A, K are constant m × m matrices. Then I will show
X (t) = eAt
µ
X0 +
Z t
0
¡
e−Ash (s) + e−AsAKB (s)
¢
ds + e−AtKB (t)
¶
Let Y (t) = e−AtX (t) . Then from the above,
dY
=
−Ae−AtX + e−AtIdX+1
2e−AtdXT 0dX
=
−Ae−AtX + e−AtI ((AX + h (t)) dt + KdB)
=
e−Ath (t) dt + e−AtKdB.
Hence using integration by parts,
e−AtX (t) −X0
=
Z t
0
e−Ash (s) ds +
Z t
0
e−AsKdB
=
Z t
0
e−Ash (s) ds + e−AtKB (t) + A
Z t
0
e−AsKB (s) ds
and so
X (t)
=
eAt
µ
X0 +
Z t
0
e−Ash (s) ds + e−AtKB (t) + A
Z t
0
e−AsKB (s) ds
¶
=
eAt
µ
X0 +
Z t
0
¡
e−Ash (s) + e−AsAKB (s)
¢
ds + e−AtKB (t)
¶
.(35.55)

986
STOCHASTIC PROCESSES
In this formula e−As is the matrix, M (t) which solves M ′ = AM, M (0) = I.
Note that formally diﬀerentiating the above equation gives
X′
=
AeAt
µ
X0 +
Z t
0
¡
e−Ash (s) + e−AsAKB (s)
¢
ds + e−AtKB (t)
¶
+eAt
µ¡
e−Ath (t) + e−AtAKB (t)
¢
−Ae−AtKB (t) + e−AtK dB
dt
¶
and so
X′
=
AX + h (t) + AKB (t) −AKB (t) + K dB
dt
=
AX + h (t) + K dB
dt .
Of course this is total nonsense because B is known to not be diﬀerentiable. How-
ever, multiplying by dt gives
dX = (AX + h (t)) dt + KdB
and the formula 35.55 shows X (0) = X0. This was the original diﬀerential equation.
Note that it was not necessary to assume very much about X0 to write 35.55.

Probability In Inﬁnite
Dimensions
I am following the book by Da Prato and Zabczyk for much of this material. [15].
36.1
Expected Value Covariance And Correlation
Let (Ω, F, P) be a probability space. First recall the notion of expected value for a
scalar valued random variable, X denoted by
E (X) ≡
Z
Ω
X (ω) dP =
Z
R
xdλX
where λX is a Radon measure which satisﬁes
λX (G) ≡P (X (ω) ∈G) .
To speak of the expected value, it is necessary that X ∈L1 (Ω; R) . Now the variance
is deﬁned as
E
³
(X −E (X))2´
≡
Z
Ω
(X (ω) −E (X))2 dP
and it is necessary that X ∈L2 (Ω; R) .
What about random vectors where X has values in Rp? In this case, the expected
value would be a vector in Rp given by
E (X) ≡
Z
Ω
X (ω) dP
and the thing which takes the place of the variance is the covariance. This is a
linear transformation mapping Rp to Rp just as the variance could be considered a
linear transformation mapping R to R. The covariance is deﬁned as
E
¡
(X−E (X)) (X−E (X))∗¢
987

988
PROBABILITY IN INFINITE DIMENSIONS
Written in terms of the tensor product, this is
E ((X−E (X)) ⊗(X−E (X))) .
Recall the way this works.
u ⊗v (w) ≡(w, v) u.
If there are two random vectors, X and Y, X having values in Rp and Y having
values in Rq, the correlation is the linear transformation deﬁned by
E ((X−E (X)) ⊗(Y−E (Y)))
or in terms of matrices,
E
¡
(X−E (X)) (Y−E (Y))∗¢
This all makes sense provided X and Y are in L2 (Ω; Rr) where r = p or q because
you can simply integrate the entries of the matrix which results when you write
(X−E (X)) (Y−E (Y))∗.
What does it all mean in the case where X ∈L2 (Ω; H) and Y ∈L2 (Ω; G) for
H, G separable Hilbert spaces? In this case there is no “matrix”. This involves the
notion of a Hilbert Schmidt operator.
Deﬁnition 36.1 Let H and G be two separable Hilbert spaces and let T map H to
G be continuous and linear. Then T is called a Hilbert Schmidt operator if there
exists some orthonormal basis for H, {ej} such that
X
j
||Tej||2 < ∞.
The collection of all such linear maps will be denoted by L2 (H, G) .
For convenience I have restated Theorem 14.40 on Page 14.40 here.
Theorem 36.2 L2 (H, G) ⊆L (H, G) and L2 (H, G) is a separable Hilbert space
with norm given by
||T||L2 ≡
ÃX
k
||Tek||2
!1/2
where {ek} is some orthonormal basis for H. Also
||T|| ≤||T||L2 .
(36.1)
All Hilbert Schmidt opearators are compact. Also if X ∈H and Y ∈G, then
Y ⊗X ∈L2 (H, G) ,
and
||Y ⊗X||L2 = ||X||H ||Y ||G .
(36.2)

36.1.
EXPECTED VALUE COVARIANCE AND CORRELATION
989
Now if X ∈L1 (Ω, H) ,
E (X) ≡
Z
Ω
XdP.
There is no problem here. Next, consider the correlation.
Theorem 36.3 Suppose X ∈L2 (Ω; H) and Y ∈L2 (Ω; G) where H and G are
separable Hilbert spaces. Then (Y −E (Y )) ⊗(X −E (X)) ∈L1 (Ω; L2 (H, G)) and
the correlation is deﬁned by
cor (Y, X)
≡
E ((Y −E (Y )) ⊗(X −E (X)))
∈
L2 (H, G)
while the covariance is deﬁned by
cov (X, X)
≡
E ((X −E (X)) ⊗(X −E (X)))
∈
L2 (H, H) .
Proof: It suﬃces to verify the claim about cor (Y, X). First consider the issue
of measurability. I need to verify that ω →(Y (ω) −E (Y )) ⊗(X (ω) −E (X)) is
measurable. Since L2 (H, G) is a separable Hilbert space, it suﬃces to use the Pettis
theorem and verify
ω →((Y (ω) −E (Y )) ⊗(X (ω) −E (X)) , A)L2
is measurable for every A ∈L2 (H, G). Therefore, letting {ek} be an orthonormal
basis in H ,
((Y (ω) −E (Y )) ⊗(X (ω) −E (X)) , A)L2
≡
X
k
((Y (ω) −E (Y )) ⊗(X (ω) −E (X)) (ek) , A (ek))
=
X
k
(ek, X (ω) −E (X)) ((Y (ω) −E (Y )) , A (ek)) .
Each term in this sum is measurable and so this shows measurability.
Finally, from Theorem 14.40,
Z
Ω
||(Y (ω) −E (Y )) ⊗(X (ω) −E (X))||L2 dP
≤
Z
Ω
||Y (ω) −E (Y )|| ||X (ω) −E (X)|| dP
≤
||X −E (X)||L2(Ω;H) ||Y −E (Y )||L2(Ω;G) .
This proves the theorem.

990
PROBABILITY IN INFINITE DIMENSIONS
36.2
Independence
Recall that for X a random variable, σ (X) is the smallest σ algebra containing all
the sets of the form X−1 (F) where F is Borel. Since such sets, X−1 (F) for F Borel
form a σ algebra it follows σ (X) =
©
X−1 (F) : F is Borel
ª
.
Deﬁnition 36.4 Let (Ω, F, P) be a probability space. A ﬁnite set of random vec-
tors, {Xk}n
k=1 is independent if whenever Fk ∈σ (Xk) ,
P (∩n
k=1Fk) =
n
Y
k=1
P (Fk) .
More generally, if {Fj}j∈J are σ algebras, they are said to be independent if when-
ever I ⊆J is a ﬁnite set of indices and Ai ∈Fi,
P (∩i∈IAi) =
Y
i∈I
P (Ai) .
Recall the following lemma.
Lemma 36.5 If {Xk}r
k=1 are independent and if gk is a Borel measurable function,
then {gk (Xk)}n
k=1 is also independent. Furthermore, if the random variables have
values in R and they are all bounded, then
E
Ã r
Y
i=1
Xi
!
=
r
Y
i=1
E (Xi) .
Proof: First consider the claim about {gk (Xk)}r
k=1. Letting O be an open set
in R,
(gk ◦Xk)−1 (O) = X−1
k
¡
g−1
k
(O)
¢
= X−1
k
(Borel set) ∈σ (Xk) .
It follows (gk ◦Xk)−1 (E) is in σ (Xk) whenever E is Borel. Thus σ (gk ◦Xk) ⊆
σ (Xk) and this proves the ﬁrst part of the lemma.
Now let
©
si
n
ª∞
n=1 be a bounded sequence of simple functions measurable in σ (Xi)
which converges to Xi uniformly. (Since Xi is bounded, such a sequence exists by
breaking Xi into positive and negative parts and using Theorem 8.27 on Page 190.)
Say
si
n (ω) =
mn
X
k=1
cn,i
k XEn,i
k
(ω)
where the Ek are disjoint elements of σ (Xi) and some might be empty. This is for
convenience in keeping the same index on the top of the sum. Then since all the
random variables are bounded, there is no problem about existence of any of the

36.2.
INDEPENDENCE
991
above. Then from the assumption that the Xi are independent,
E
Ã r
Y
i=1
Xi
!
=
Z
Ω
r
Y
i=1
Xi (ω) dP = lim
n→∞
Z
Ω
r
Y
i=1
si
n (ω) dP
=
lim
n→∞
Z
Ω
r
Y
i=1
mn
X
k=1
cn,i
k XEn,i
k
(ω) dP
=
lim
n→∞
Z
Ω
X
k1,k2,···,kr
cn,1
k1 cn,2
k2 · · · cn,r
kr XEn,1
k1 XEn,2
k2 · · · XEn,r
kr dP
=
lim
n→∞
X
k1,k2,···,kr
Z
Ω
cn,1
k1 cn,2
k2 · · · cn,r
kr XEn,1
k1 XEn,2
k2 · · · XEn,r
kr dP
=
lim
n→∞
X
k1,k2,···,kr
cn,1
k1 cn,2
k2 · · · cn,r
kr
r
Y
i=1
P
³
En,i
ki
´
=
lim
n→∞
r
Y
i=1
Z
Ω
si
n (ω) dP =
r
Y
i=1
E (Xi) .
This proves the lemma.
Next consider the case where you have an independent set of σ algebras. First
here are some preliminary results.
Deﬁnition 36.6 Let Ωbe a set and let K be a collection of subsets of Ω. Then K
is called a π system if ∅∈K and whenever A, B ∈K, it follows A ∩B ∈K.
Obviously an example of a π system is the set of measurable rectangles. Note
how simple this deﬁnition is. It does not involve an algebra. Now recall the funda-
mental lemma on π systems, Lemma 9.72 on Page 257.
The following lemma is helpful when you try to verify such a set of σ algebras is
independent. It says you only need to check things on π systems contained in the
σ algebras.
Lemma 36.7 Suppose {Fi}i∈I is a set of σ algebras contained in F where F
is
a σ algebra of sets of Ω. Suppose that Ki ⊆Fi is a π system and Fi = σ (Ki).
Suppose also that whenever J is a ﬁnite subset of I and Aj ∈Kj for j ∈J, it
follows
P (∩j∈JAj) =
Y
j∈J
P (Aj) .
Then {Fi}i∈I is independent.
Proof: I need to verify that for all n ∈N, if {j1, j2, · · ·, jn} ⊆I and Ajk ⊆Fjk,
then
P (∩n
k=1Ajk) =
n
Y
k=1
P (Ajk) .

992
PROBABILITY IN INFINITE DIMENSIONS
Pick
¡
Aj1 · ··, Ajn−1
¢
∈Kj1 × · · ·, Kjn−1 and let
G(Aj1···,Ajn−1) ≡
(
Ajn ∈Fjn : P (∩n
k=1Ajk) =
n
Y
k=1
P (Ajk)
)
Then by hypothesis, Kjn ⊆G(Aj1···,Ajn−1). If Ajn ∈G(Aj1···,Ajn−1),
n−1
Y
k=1
P (Ajk)
=
P
¡
∩n−1
k=1Ajk
¢
=
P
¡¡
∩n−1
k=1Ajk ∩AC
jn
¢
∪
¡
∩n−1
k=1Ajk ∩Ajn
¢¢
=
P
¡
∩n−1
k=1Ajk ∩AC
jn
¢
+ P
¡
∩n−1
k=1Ajk ∩Ajn
¢
=
P
¡
∩n−1
k=1Ajk ∩AC
jn
¢
+
n
Y
k=1
P (Ajk)
and so
P
¡
∩n−1
k=1Ajk ∩AC
jn
¢
=
n−1
Y
k=1
P (Ajk) (1 −P (Ajn))
=
n−1
Y
k=1
P (Ajk) P
¡
AC
jn
¢
showing if Ajn ∈G(Aj1···,Ajn−1), then so is AC
jn. It is clear that G(Aj1···,Ajn−1) is
closed with respect to disjoint unions also. Therefore, by Lemma 9.72 G(Aj1···,Ajn−1) =
Fjn.
Next ﬁx Ajn ∈Fjn and
¡
Aj1 · ··, Ajn−2
¢
∈Kj1 × · · ·, Kjn−2. Let
G(Aj1···,Ajn−2) ≡
(
Ajn−1 ∈Fjn−1 : P (∩n
k=1Ajk) =
n
Y
k=1
P (Ajk)
)
It was just shown G(Aj1···,Ajn−2) ⊇Kjn−1. Also by similar reasoning to the above, it
follows G(Aj1···,Ajn−2) satisﬁes the conditions needed to apply Lemma 9.72 on Page
257 and so whenever Ajn, Ajn−1 are in Fjn and Fjn−1 respectively and
¡
Aj1 · ··, Ajn−2
¢
∈Kj1 × · · ·, Kjn−2,
it follows P (∩n
k=1Ajk) = Qn
k=1 P (Ajk) . Continue this way to obtain the desired
result. This proves the lemma.
What is a useful π system for B (E) where E is a Banach space?
Recall the fundamental lemma used to prove the Pettis theorem. It was proved
on Page 579 but here I want to show that in addition, the set D′ can be taken as a
subset of a given dense subspace, M of E′. Thus I will present next a generalization
of that important lemma. You might consider whether the following lemma can be
generalized even more.

36.2.
INDEPENDENCE
993
Lemma 36.8 If E is a separable Banach space with B′ the closed unit ball in E′,
and if M is a dense subspace of E′, then there exists a sequence {fn}∞
n=1 ≡D′ ⊆
B′ ∩M with the property that for every x ∈E,
||x|| = sup
f∈D′ |f (x)|
The set, D′ also has the property that if f ∈D′ then −f ∈D′.
Proof: Let {an} ≡D be a dense subset of E. Deﬁne a subset of Cn, Cn by
{(f (a1) , · · ·, f (an)) : f ∈B′ ∩M}
Then Cn is a bounded subset of Cn and so it is separable. Note each f delivers a
point in Cn. Now let {f n
k }∞
k=1 ⊆B′ ∩M be such that the points
{(f n
k (a1) , · · ·, f n
k (an))}∞
k=1
are dense in Cn. Then D′ ≡∪∞
n=1 {f n
k }∞
k=1 .
It remains to verify D′ works. Pick x ∈E. I need to show there exists f n
k such
that ||x|| < |f n
k (x)| + ε. By a standard exercise in the Hahn Banach theorem, there
exists f ∈B′ such that f (x) = ||x|| . Next choose an ∈D such that ||x −an||E <
ε/4. Since M is dense, there exists g ∈M ∩B′ such that |g (an) −f (an)| < ε/4.
Finally, there exists f n
k ∈D′ such that |f n
k (an) −g (an)| < ε/4. Then
|||x|| −|f n
k (x)||
=
||f (x)| −|f n
k (x)||
≤
||f (x)| −|f (an)|| + ||f (an)| −|g (an)||
+ ||g (an)| −|f n
k (an)|| + ||f n
k (an)| −|f n
k (x)||
<
ε
4 + ε
4 + ε
4 + ε
4 = ε.
It follows ||x|| < |f n
k (x)| + ε and this proves the lemma because for every f ∈D′
you can simply include −f.
Lemma 36.9 Let E be a separable real Banach space. Sets of the form
{x ∈E : x∗
i (x) ≤αi, i = 1, 2, · · ·, m}
where x∗
i ∈M, a dense subspace of E′ and αi ∈[−∞, ∞) are a π system, and
denoting this π system by K, it follows σ (K) = B (E).
Proof: The sets described are obviously a π system.
I want to show σ (K)
contains the closed balls because then σ (K) contains the open balls and hence the
open sets and the result will follow. Let D′ ⊆B′ ∩M be described in Lemma 36.8.

994
PROBABILITY IN INFINITE DIMENSIONS
Then
{x ∈E : ||x −a|| ≤r}
=
(
x ∈E : sup
f∈D′ |f (x −a)| ≤r
)
=
(
x ∈E : sup
f∈D′ |f (x) −f (a)| ≤r
)
=
∩f∈D′ {x ∈E : f (a) −r ≤f (x) ≤f (a) + r}
=
∩f∈D′ {x ∈E : f (x) ≤f (a) + r and (−f) (x) ≤r −f (a)}
which equals a countable intersection of sets of the given π system.
Therefore,
every closed ball is contained in σ (K). It follows easily that every open ball is also
contained in σ (K) because
B (a, r) = ∪∞
n=1B
µ
a, r −1
n
¶
.
Since the Banach space is separable, it is completely separable and so every open
set is the countable union of balls.
This shows the open sets are in σ (K) and
so σ (K) ⊇B (E) . However, all the sets in the π system are closed hence Borel
because they are inverse images of closed sets. Therefore, σ (K) ⊆B (E) and so
σ (K) = B (E). This proves the lemma.
Next suppose you have some random variables having values in a separable
Banach space, E, {Xi}i∈I . How can you tell if they are independent? To show they
are independent, you need to verify that
P
¡
∩n
k=1X−1
ik (Fik)
¢
=
n
Y
k=1
P
¡
X−1
ik (Fik)
¢
whenever the Fik are Borel sets in E. It is desirable to ﬁnd a way to do this easily.
Lemma 36.10 Let K be a π system of sets of E, a separable real Banach space
and let (Ω, F, P) be a probability space and X : Ω→E be a random variable. Then
X−1 (σ (K)) = σ
¡
X−1 (K)
¢
Proof: First note that X−1 (σ (K)) is a σ algebra which contains X−1 (K) and
so it contains σ
¡
X−1 (K)
¢
. Now let
G ≡
©
A ∈σ (K) : X−1 (A) ∈σ
¡
X−1 (K)
¢ª
Then G ⊇K. If A ∈G, then
X−1 (A) ∈σ
¡
X−1 (K)
¢

36.2.
INDEPENDENCE
995
and so
X−1 (A)C = X−1 ¡
AC¢
∈σ
¡
X−1 (K)
¢
because σ
¡
X−1 (K)
¢
is a σ algebra. Hence AC ∈G. Finally suppose {Ai} is a
sequence of disjoint sets of G. Then
X−1 (∪∞
i=1Ai) = ∪∞
i=1X−1 (Ai) ∈σ
¡
X−1 (K)
¢
again because σ
¡
X−1 (K)
¢
is a σ algebra. It follows from Lemma 9.72 on Page 257
that G ⊇σ (K) and this shows that whenever A ∈σ (K) , X−1 (A) ∈σ
¡
X−1 (K)
¢
.
Thus X−1 (σ (K)) ⊆σ
¡
X−1 (K)
¢
and this proves the lemma.
With this lemma, here is the desired result about independent random variables.
Essentially, you can reduce to the case of random vectors having values in Rn.
Theorem 36.11 The random variables, {Xi}i∈I are independent if whenever
{i1, · · ·, in} ⊆I,
mi1, · · ·, min are positive integers, and gmi1 , · · ·, gmin are respectively in (M)mi1 , · ·
·, (M)mn for M a dense subspace of E′,
n
gmij ◦Xij
on
j=1 are independent random
vectors having values in Rmi1 , · · ·, Rmin respectively.
Proof: Let K denote sets of the form
{x ∈E : x∗
i (x) ≤αi, i = 1, 2, · · ·m}
as described in Lemma 36.9. Then as proved in this lemma, σ (K) = B (E). Then
the random vectors are independent if whenever
{i1, · · ·, in} ⊆I
and Ai1, · · ·, Ain sets of σ (Xi1) , · · ·, σ (Xin) respectively,
P
¡
∩n
j=1Aij
¢
=
n
Y
j=1
P
¡
Aij
¢
.
By Lemma 9.72 on Page 257 if Kij is a π system contained in σ
¡
Xij
¢
such that
σ
¡
Kij
¢
= σ
¡
Xij
¢
, then it suﬃces to check only the case where the Aij is in Kij.
So what will serve for such a collection of π systems? Let
Kij ≡X−1
ij (K) ≡
n
X−1
ij (A) : A ∈K
o
.
This is clearly a π system contained in σ
¡
Xij
¢
and by Lemma 36.10
σ
¡
Kij
¢
= σ
³
X−1
ij (K)
´
= X−1
ij (σ (K)) ≡σ
¡
Xij
¢
.

996
PROBABILITY IN INFINITE DIMENSIONS
Thus it suﬃces to show that whenever Bi1, · · ·, Bin are sets of K,
P
³
∩n
j=1X−1
ij
¡
Bij
¢´
=
n
Y
j=1
P
³
X−1
ij
¡
Bij
¢´
Let Bij =
n
x ∈E : gmij (x) ∈Aij
o
where Aij = Qmj
j=1(−∞, αi] and gmj ∈M mj.
It follows
X−1
ij
¡
Bij
¢
=
³
gmij ◦Xij
´−1 ¡
Aij
¢
.
Then by the assumption the random vectors gmij ◦Xij are independent,
P
³
∩n
j=1X−1
ij
¡
Bij
¢´
=
P
µ
∩n
j=1
³
gmij ◦Xij
´−1 ¡
Aij
¢¶
=
n
Y
j=1
P
µ³
gmij ◦Xij
´−1 ¡
Aij
¢¶
=
n
Y
j=1
P
³
X−1
ij
¡
Bij
¢´
and this proves the theorem.
Procedure 36.12 Suppose you have random vectors, {Xi}i∈I having values in a
real separable Banach space, E. Then they are independent if the Rk valued random
vectors, {g◦Xi}i∈I,g∈M k are independent for M a dense subspace of E′. You check
whether these are independent to determine whether {Xi}i∈I are independent.
The above assertion also goes the other way as you may want to show.
So how can you determine whether random vectors having values in Rn are
independent? Recall an earlier proposition which relates independence of random
vectors with characteristic functions. It is proved starting on Page 865.
Proposition 36.13 Let {Xk}n
k=1be random vectors such that Xk has values in
Rpk. Then the random vectors are independent if and only if
E
¡
eiP ¢
=
n
Y
j=1
E
¡
eitj·Xj¢
where P ≡Pn
j=1 tj · Xj for tj ∈Rpj.
36.3
Conditional Expectation
Let (Ω, F, P) be a probability space and let X ∈L1 (Ω; R). Also let G ⊆F where
G is also a σ algebra. Then the usual conditional expectation is deﬁned by
Z
A
XdP =
Z
A
E (X|G) dP

36.3.
CONDITIONAL EXPECTATION
997
where E (X|G) is G measurable and A ∈G is arbitrary. Recall this is an application
of the Radon Nikodym theorem. Also recall E (X|G) is unique up to a set of measure
zero.
I want to do something like this here. Denote by L1 (Ω; E, G) those functions in
L1 (Ω; E) which are measurable with respect to G.
Theorem 36.14 Let E be a separable Banach space and let X ∈L1 (Ω; E, F) where
X is measurable with respect to F. Then there exists a unique Z ∈L1 (Ω; E, G) such
that for all A ∈G,
Z
A
XdP =
Z
A
ZdP
Denoting this Z as E (X|G) , it follows
||E (X|G)|| ≤E (||X|| |G) .
Proof: First consider uniqueness. Suppose Z′ is another in L1 (Ω; E, G) which
works. Then let A ≡{ω : ||Z (ω) −Z′ (ω)|| > δ} where δ > 0. Now let D = {ak}
be a countable dense subset of E and consider the balls B
¡
ak, 1
4 ||ak||
¢
≡Bk for
which ||ak|| > δ. Since each of these balls has radius larger than δ/4 and the {ak}
are dense, it follows the union of these balls includes {x ∈E : ||x|| > δ}.
Now let
Ak
≡
{ω : ||Z (ω) −Z′ (ω)|| > δ}
∩
½
ω : ||Z (ω) −Z′ (ω) −ak|| < 1
2 ||ak||
¾
.
If P (A) > 0, then for some k, P (Ak) > 0 because the balls Bk cover the set
{x : ||x|| > δ} . Then
1
2 ||ak|| P (Ak)
≥
Z
Ak
||Z′ −Z + ak|| dP
≥
¯¯¯¯
¯¯¯¯
Z
Ak
(Z′ −Z + ak) dP
¯¯¯¯
¯¯¯¯
=
¯¯¯¯
¯¯¯¯
Z
Ak
akdP
¯¯¯¯
¯¯¯¯ = ||ak|| P (Ak)
which is a contradiction. Hence P (A) = 0 after all. It follows Z′ = Z a.e. because
δ > 0 is arbitrary. This establishes the uniqueness part of the theorem.
Next I will show Z exists. To do this recall Theorem 21.19 on Page 588 which
is stated below for convenience.
Theorem 36.15 An E valued function, X, is Bochner integrable if and only if X
is strongly measurable and
Z
Ω
||X (ω)|| dP < ∞.
(36.3)

998
PROBABILITY IN INFINITE DIMENSIONS
In this case there exists a sequence of simple functions {Xn} satisfying
Z
Ω
||Xn (ω) −Xm (ω)|| dP →0 as m, n →∞.
(36.4)
Xn (ω) converging pointwise to X (ω),
||Xn (ω)|| ≤2 ||X (ω)||
(36.5)
and
lim
n→∞
Z
Ω
||X (ω) −Xn (ω)|| dP = 0.
(36.6)
Now let {Xn} be the simple functions just deﬁned and let
Xn (ω) =
m
X
k=1
xkXFk (ω)
where Fk ∈F, the Fk being disjoint. Then deﬁne
Zn ≡
m
X
k=1
xkE (XFk|G) .
Thus, if A ∈G,
Z
A
ZndP
=
m
X
k=1
xk
Z
A
E (XFk|G) dP
=
m
X
k=1
xk
Z
A
XFkdP
=
m
X
k=1
xkP (Fk) =
Z
A
XndP
(36.7)
Then since E (XFk|G) ≥0,
E (||Zn||)
≤
m
X
k=1
||xk||
Z
E (XFk|G) dP
=
m
X
k=1
||xk||
Z
XFkdP = E (||Xn||) .
Similarly,
E (||Zn −Zm||) ≤E (||Xn −Xm||)
and this last term converges to 0 as n, m →∞by the properties of the Xn. There-
fore, {Zn} is a Cauchy sequence in L1 (Ω; E; G) . It follows it converges to Z in

36.3.
CONDITIONAL EXPECTATION
999
L1 (Ω; E, G) . Then letting A ∈G, and using 36.7,
Z
A
ZdP
=
Z
XAZdP
=
lim
n→∞
Z
XAZndP
=
lim
n→∞
Z
A
ZndP
=
lim
n→∞
Z
A
XndP
=
Z
A
XdP.
It remains to verify ||E (X|G)|| ≤E (||X|| |G) . This follows similar to the above.
Letting Zn and Z have the same meaning as above and A ∈G,
E (XA ||Zn||)
=
Z
A
¯¯¯¯¯
¯¯¯¯¯
m
X
k=1
xkE (XFk|G)
¯¯¯¯¯
¯¯¯¯¯ dP
≤
m
X
k=1
||xk||
Z
A
E (XFk|G) dP
=
m
X
k=1
||xk||
Z
A
XFkdP
=
Z
A
m
X
k=1
||xk|| XFkdP
=
E (XA ||Xn||) .
Therefore,
Z
A
||Z|| dP
=
Z
XA ||Z|| dP
=
lim
n→∞
Z
XA ||Zn|| dP
≤
lim
n→∞E (XA ||Xn||)
=
Z
A
||X|| dP
Thus for all A ∈G,
Z
A
||E (X|G)|| dP ≤
Z
A
||X|| dP =
Z
A
E (||X|| |G) dP
which shows
||E (X|G)|| ≤E (||X|| |G)

1000
PROBABILITY IN INFINITE DIMENSIONS
as claimed. This proves the theorem.
In the case where E is reﬂexive, one could also use Corollary 21.48 on Page 617
to get the above result. You would deﬁne a vector measure on G,
ν (F) ≡
Z
F
XdP
and then you would use the fact that reﬂexive separable Banach spaces have the
Radon Nikodym property to obtain Z ∈L1 (Ω; E, G) such that
ν (F) =
Z
F
XdP =
Z
F
ZdP.
The function, Z whose existence and uniqueness is guaranteed by Theorem 36.15
is called E (X|G).
36.4
Probability Measures And Tightness
Here and in what remains, B (E) will denote the Borel sets of E where E is a topo-
logical space, usually at least a Banach space. Because of the fact that probability
measures are ﬁnite, you can use a simpler deﬁnition of what it means for a measure
to be regular. Recall that there were two ingredients, inner regularity which said
that the measure of a set is the supremum of the measures of compact subsets and
outer regularity which says that the measure of a set is the inﬁmum of the measures
of the open sets which contain the given set. Here the deﬁnition will be similar
but instead of using compact sets, closed sets are substituted. Thus the following
deﬁnition is a little diﬀerent than the earlier one. I will show, however, that in many
interesting cases, this deﬁnition of regularity is actually the same as the earlier one.
Deﬁnition 36.16 A measure, µ deﬁned on B (E) will be called inner regular if for
all F ∈B (E) ,
µ (F) = sup {µ (K) : K ⊆F and K is closed}
A measure, µ deﬁned on B (E) will be called outer regular if for all F ∈B (E) ,
µ (F) = inf {µ (V ) : V ⊇F and V is open}
When a measure is both inner and outer regular, it is called regular.
For probability measures, regularity tends to come free.
Lemma 36.17 Let µ be a ﬁnite measure deﬁned on B (E) where E is a metric
space. Then µ is regular.
Proof: First note every open set is the countable union of closed sets and every
closed set is the countable intersection of open sets. Here is why. Let V be an open
set and let
Kk ≡
©
x ∈V : dist
¡
x, V C¢
≥1/k
ª
.

36.4.
PROBABILITY MEASURES AND TIGHTNESS
1001
Then clearly the union of the Kk equals V. Next, for K closed let
Vk ≡{x ∈E : dist (x, K) < 1/k} .
Clearly the intersection of the Vk equals K. Therefore, letting V denote an open set
and K a closed set,
µ (V )
=
sup {µ (K) : K ⊆V and K is closed}
µ (K)
=
inf {µ (V ) : V ⊇K and V is open} .
Also since V is open and K is closed,
µ (V )
=
inf {µ (U) : U ⊇V and V is open}
µ (K)
=
sup {µ (L) : L ⊆K and L is closed}
In words, µ is regular on open and closed sets. Let
F ≡{F ∈B (E) such that µ is regular on F} .
Then F contains the open sets. I want to show F is a σ algebra and then it will
follow F = B (E).
First I will show F is closed with respect to complements. Let F ∈F. Then
since µ is ﬁnite and F is inner regular, there exists K ⊆F such that µ (F \ K) < ε.
But KC \ F C = F \ K and so µ
¡
KC \ F C¢
< ε showning that F C is outer regular.
I have just approximated the measure of F C with the measure of KC, an open set
containing F C. A similar argument works to show F C is inner regular. You start
with V ⊇F such that µ (V \ F) < ε, note F C \ V C = V \ F, and then conclude
µ
¡
F C \ V C¢
< ε, thus approximating F C with the closed subset, V C.
Next I will show F is closed with respect to taking countable unions. Let {Fk}
be a sequence of sets in F. Then µ is inner regular on each of these so there exist
{Kk} such that Kk ⊆Fk and µ (Fk \ Kk) < ε/2k+1. First choose m large enough
that
µ ((∪∞
k=1Fk) \ (∪m
k=1Fk)) < ε
2.
Then
µ ((∪m
k=1Fk) \ (∪m
k=1Kk)) ≤
m
X
k=1
ε
2k+1 < ε
2
and so
µ ((∪∞
k=1Fk) \ (∪m
k=1Kk))
≤
µ ((∪∞
k=1Fk) \ (∪m
k=1Fk))
+µ ((∪m
k=1Fk) \ (∪m
k=1Kk))
<
ε
2 + ε
2 = ε

1002
PROBABILITY IN INFINITE DIMENSIONS
showing µ is inner regular on ∪∞
k=1Fk. Since µ is outer regular on Fk, there exists
Vk such that µ (Vk \ Fk) < ε/2k. Then
µ ((∪∞
k=1Vk) \ (∪∞
k=1Fk))
≤
∞
X
k=1
µ (Vk \ Fk)
<
∞
X
k=1
ε
2k = ε
and this shows µ is outer regular on ∪∞
k=1Fk and this proves the lemma.
Lemma 36.18 Let µ be a ﬁnite measure on B (E) , the Borel sets of E, a separable
complete metric space. Then if C is a closed set,
µ (C) = sup {µ (K) : K ⊆C and K is compact.}
Proof: Let {ak} be a countable dense subset of C. Thus ∪∞
k=1B
¡
ak, 1
n
¢
⊇C.
Therefore, there exists mn such that
µ
Ã
C \ ∪mn
k=1B
µ
ak, 1
n
¶!
≡µ (C \ Cn) < ε
2n .
Now let K = C ∩(∩∞
n=1Cn) . Then K is a subset of Cn for each n and so for each
ε > 0 there exists an ε net for K since Cn has a 1/n net, namely a1, · · ·, amn. Since
K is closed, it is complete and so it is also compact. Now
µ (C \ K) = µ (∪∞
n=1 (C \ Cn)) <
∞
X
n=1
ε
2n = ε.
Thus µ (C) can be approximated by µ (K) for K a compact subset of C. This proves
the lemma.
This shows that for a ﬁnite measure on the Borel sets of a separable metric
space, the above deﬁnition of regular coincides with the earlier one.
Now here is a deﬁnition of what it means for a set of measures to be tight.
Deﬁnition 36.19 Let Λ be a set of probability measures deﬁned on the Borel sets
of a topological space. Then Λ is “tight” if for all ε > 0 there exists a compact set,
Kε such that
µ ([x /∈Kε]) < ε
for all µ ∈Λ.
Lemma 36.18 implies a single probability measure on the Borel sets of a separable
metric space is tight. The proof of that lemma generalizes slightly to give a simple
criterion for a set of measures to be tight.

36.4.
PROBABILITY MEASURES AND TIGHTNESS
1003
Lemma 36.20 Let E be a separable complete metric space and let Λ be a set of
Borel probability measures. Then Λ is tight if and only if for every ε > 0 and r > 0
there exists a ﬁnite collection of balls, {B (ai, r)}m
i=1 such that
µ
³
∪m
i=1B (ai, r)
´
> 1 −ε
for every µ ∈Λ.
Proof: If Λ is tight, then there exists a compact set, Kε such that
µ (Kε) > 1 −ε
for all µ ∈Λ. Then consider the open cover, {B (x, r) : x ∈Kε} . Finitely many of
these cover Kε and this yields the above condition.
Now suppose the above condition and let
Cn ≡∪mn
i=1B (an
i , 1/n)
satisfy µ (Cn) > 1 −ε/2n for all µ ∈Λ. Then let Kε ≡∩∞
n=1Cn. Then as in Lemma
36.18 µ (Kε) > 1 −ε for all µ ∈Λ.
Prokhorov’s theorem is an important result which also involves tightness. In
order to give a proof of this important theorem, it is necessary to consider some
simple results from topology which are interesting for their own sake.
Theorem 36.21 Let H be a compact metric space. Then there exists a compact
subset of [0, 1] , K and a continuous function, θ which maps K onto H.
Proof: Without loss of generality, it can be assumed H is an inﬁnite set since
otherwise the conclusion is trivial. You could pick ﬁnitely many points of [0, 1] for
K.
Since H is compact, it is totally bounded. Therefore, there exists a 1 net for
H {hi}m1
i=1 . Letting H1
i ≡B (hi, 1), it follows H1
i is also a compact metric space
and so there exists a 1/2 net for each H1
i ,
©
hi
j
ªmi
j=1 . Then taking the intersection
of B
¡
hi
j, 1
2
¢
with H1
i to obtain sets denoted by H2
j and continuing this way, one
can obtain compact subsets of H,
©
Hi
k
ª
which satisﬁes: each Hi
j is contained in
some Hi−1
k
, each Hi
j is compact with diameter less than i−1, each Hi
j is the union
of sets of the form Hi+1
k
which are contained in it. Denoting by
©
Hi
j
ªmi
j=1 those
sets corresponding to a superscript of i, it can also be assumed mi < mi+1. If
this is not so, simply add in another point to the i−1 net. Now let
©
Ii
j
ªmi
j=1 be
disjoint closed intervals in [0, 1] each of length no longer than 2−mi which have the
property that Ii
j
is contained in Ii−1
k
for some k. Letting Ki ≡∪mi
j=1Ii
j, it follows
Ki is a sequence of nested compact sets. Let K = ∩∞
i=1Ki. Then each x ∈K is
the intersection of a unique sequence of these closed intervals,
©
Ik
jk
ª∞
k=1. Deﬁne
θx ≡∩∞
k=1Hk
jk. Since the diameters of the Hi
j converge to 0 as i →∞, this function
is well deﬁned. It is continuous because if xn →x, then ultimately xn and x are

1004
PROBABILITY IN INFINITE DIMENSIONS
both in Ik
jk, the kth closed interval in the sequence whose intersection is x. Hence,
d (θxn, θx) ≤diameter(Hk
jk) ≤1/k. To see the map is onto, let h ∈H.
Then
from the construction, there exists a sequence
©
Hk
jk
ª∞
k=1 of the above sets whose
intersection equals h. Then θ
¡
∩∞
i=1Ik
jk
¢
= h. This proves the theorem.
Note θ is maybe not one to one.
As an important corollary, it follows that the continuous functions deﬁned on
any compact metric space is separable.
Corollary 36.22 Let H be a compact metric space and let C (H) denote the con-
tinuous functions deﬁned on H with the usual norm,
||f||∞≡max {|f (x)| : x ∈H}
Then C (H) is separable.
Proof: The proof is by contradiction. Suppose C (H) is not separable. Let
Hk denote a maximal collection of functions of C (H) with the property that if
f, g ∈Hk, then ||f −g||∞≥1/k. The existence of such a maximal collection of
functions is a consequence of a simple use of the Hausdorﬀmaximallity theorem.
Then ∪∞
k=1Hk is dense. Therefore, it cannot be countable by the assumption that
C (H) is not separable. It follows that for some k, Hk is uncountable. Now by
Theorem 36.21 there exists a continuous function, θ deﬁned on a compact subset,
K of [0, 1] which maps K onto H. Now consider the functions deﬁned on K
Gk ≡{f ◦θ : f ∈Hk} .
Then Gk is an uncountable set of continuous functions deﬁned on K with the prop-
erty that the distance between any two of them is at least as large as 1/k. This
contradicts separability of C (K) which follows from the Weierstrass approximation
theorem in which the separable countable set of functions is the restrictions of poly-
nomials that involve only rational coeﬃcients. This proves the corollary. Now here
is Prokhorov’s theorem.
Theorem 36.23 Let Λ = {µn}∞
n=1 be a sequence of probability measures deﬁned
on B (E) where E is a separable Banach space. If Λ is tight then there exists a
probability measure, λ and a subsequence of {µn}∞
n=1 , still denoted by {µn}∞
n=1
such that whenever φ is a continuous bounded complex valued function deﬁned on
E,
lim
n→∞
Z
φdµn =
Z
φdλ.
Proof: By tightness, there exists an increasing sequence of compact sets, {Kn}
such that
µ (Kn) > 1 −1
n
for all µ ∈Λ. Now letting µ ∈Λ and φ ∈C (Kn) such that ||φ||∞≤1, it follows
¯¯¯¯
Z
Kn
φdµ
¯¯¯¯ ≤µ (Kn) ≤1

36.4.
PROBABILITY MEASURES AND TIGHTNESS
1005
and so the restrictions of the measures of Λ to Kn are contained in the unit ball of
C (Kn)′ . Recall from the Riesz representation theorem, the dual space of C (Kn)
is a space of complex Borel measures. Theorem 13.37 on Page 356 implies the unit
ball of C (Kn)′ is weak ∗sequentially compact. This follows from the observation
that C (Kn) is separable which is proved in Corollary 36.22 and leads to the fact
that the unit ball in C (Kn)′ is actually metrizable by Theorem 13.37 on Page 356.
Therefore, there exists a subsequence of Λ, {µ1k} such that their restrictions to K1
converge weak ∗to a measure, λ1 ∈C (K1)′. That is, for every φ ∈C (K1) ,
lim
k→∞
Z
K1
φdµ1k =
Z
K1
φdλ1
By the same reasoning, there exists a further subsequence {µ2k} such that the
restrictions of these measures to K2 converge weak ∗to a measure λ2 ∈C (K2)′
etc. Continuing this way,
µ11, µ12, µ13, · · · →Weak ∗in C (K1)′
µ21, µ22, µ23, · · · →Weak ∗in C (K2)′
µ31, µ32, µ33, · · · →Weak ∗in C (K3)′
...
Here the jth sequence is a subsequence of the (j −1)th. Let λn denote the measure
in C (Kn)′ to which the sequence {µnk}∞
k=1 converges weak∗. Let {µn} ≡{µnn} ,
the diagonal sequence. Thus this sequence is ultimately a subsequence of every one
of the above sequences and so µn converges weak∗in C (Km)′ to λm for each m.
Claim: For p > n, the restriction of λp to the Borel sets of Kn equals λn.
Proof of claim: Let H be a compact subset of Kn. Then there are sets, Vl open
in Kn which are decreasing and whose intersection equals H. This follows because
this is a metric space. Then let H ≺φl ≺Vl. It follows
λn (Vl)
≥
Z
Kn
φldλn = lim
k→∞
Z
Kn
φldµk
=
lim
k→∞
Z
Kp
φldµk =
Z
Kp
φldλp ≥λp (H) .
Now considering the ends of this inequality, let l →∞and pass to the limit to
conclude
λn (H) ≥λp (H) .
Similarly,
λn (H)
≤
Z
Kn
φldλn = lim
k→∞
Z
Kn
φldµk
=
lim
k→∞
Z
Kp
φldµk =
Z
Kp
φldλp ≤λp (Vl) .

1006
PROBABILITY IN INFINITE DIMENSIONS
Then passing to the limit as l →∞, it follows
λn (H) ≤λp (H) .
Thus the restriction of λp, λp|Kn to the compact sets of Kn equals λn. Then by
inner regularity it follows the two measures, λp|Kn, and λn are equal on all Borel
sets of Kn. Recall that for ﬁnite measures on separable metric spaces, regularity is
obtained for free.
It is fairly routine to exploit regularity of the measures to verify that λm (F) ≥
0 for all F a Borel subset of Km. (Whenever φ ≥0,
R
Km φdλm ≥0 because
R
Km φdµk ≥0. Now you can approximate XF with a suitable nonnegative φ using
regularity of the measure.) Also, letting φ ≡1,
1 ≥λm (Km) ≥1 −1
m.
(36.8)
Deﬁne for F a Borel set,
λ (F) ≡lim
n→∞λn (F ∩Kn) .
The limit exists because the sequence on the right is increasing due to the above
observation that λn = λm on the Borel subsets of Km whenever n > m. Thus for
n > m
λn (F ∩Kn) ≥λn (F ∩Km) = λm (F ∩Km) .
Now let {Fk} be a sequence of disjoint Borel sets. Then
λ (∪∞
k=1Fk)
≡
lim
n→∞λn (∪∞
k=1Fk ∩Kn) = lim
n→∞λn (∪∞
k=1 (Fk ∩Kn))
=
lim
n→∞
∞
X
k=1
λn (Fk ∩Kn) =
∞
X
k=1
λ (Fk)
the last equation holding by the monotone convergence theorem.
It remains to verify
lim
k→∞
Z
φdµk =
Z
φdλ
for every φ bounded and continuous. This is where tightness is used again. Suppose
||φ||∞< M. Then as noted above,
λn (Kn) = λ (Kn)
because for p > n, λp (Kn) = λn (Kn) and so letting p →∞, the above is obtained.
Also, from 36.8,
λ
¡
KC
n
¢
=
lim
p→∞λp
¡
KC
n ∩Kp
¢
≤
lim sup
p→∞(λp (Kp) −λp (Kn))
≤
lim sup
p→∞(λp (Kp) −λn (Kn))
≤
lim sup
p→∞
µ
1 −
µ
1 −1
n
¶¶
= 1
n

36.5.
A MAJOR EXISTENCE AND CONVERGENCE THEOREM
1007
Consequently,
¯¯¯¯
Z
φdµk −
Z
φdλ
¯¯¯¯ ≤
¯¯¯¯¯
Z
KC
n
φdµk +
Z
Kn
φdµk −
ÃZ
Kn
φdλ +
Z
KC
n
φdλ
!¯¯¯¯¯
≤
¯¯¯¯
Z
Kn
φdµk −
Z
Kn
φdλn
¯¯¯¯ +
¯¯¯¯¯
Z
KC
n
φdµk −
Z
KC
n
φdλ
¯¯¯¯¯
≤
¯¯¯¯
Z
Kn
φdµk −
Z
Kn
φdλn
¯¯¯¯ +
¯¯¯¯¯
Z
KC
n
φdµk
¯¯¯¯¯ +
¯¯¯¯¯
Z
KC
n
φdλ
¯¯¯¯¯
≤
¯¯¯¯
Z
Kn
φdµk −
Z
Kn
φdλn
¯¯¯¯ + M
n + M
n
First let n be so large that 2M/n < ε/2 and then pick k large enough that the
above expression is less than ε. This proves the theorem.
Deﬁnition 36.24 Let E be a Banach space and let µ and the sequence of probability
measures, {µn} deﬁned on B (E) satisfy
lim
n→∞
Z
φdµn =
Z
φdµ.
for every φ a bounded continuous function. Then µn is said to converge weakly to
µ.
36.5
A Major Existence And Convergence Theo-
rem
Here is an interesting lemma about weak convergence.
Lemma 36.25 Let µn converge weakly to µ and let U be an open set with µ (∂U) =
0. Then
lim
n→∞µn (U) = µ (U) .
Proof: Let {ψk} be a sequence of bounded continuous functions which decrease
to XU. Also let {φk} be a sequence of bounded continuous functions which increase
to XU. For example, you could let
ψk (x)
≡
(1 −k dist (x, U))+ ,
φk (x)
≡
1 −
¡
1 −k dist
¡
x, U C¢¢+ .
Let ε > 0 be given. Then since µ (∂U) = 0, the dominated convergence theorem
implies there exists ψ = ψk and φ = φk such that
ε >
Z
ψdµ −
Z
φdµ

1008
PROBABILITY IN INFINITE DIMENSIONS
Next use the weak convergence to pick N large enough that if n ≥N,
Z
ψdµn ≤
Z
ψdµ + ε,
Z
φdµn ≥
Z
φdµ −ε.
Therefore, for n this large,
µ (U) , µn (U) ∈
·Z
φdµ −ε,
Z
ψdµ + ε
¸
and so
|µ (U) −µn (U)| < 3ε.
since ε is arbitrary, this proves the lemma.
Deﬁnition 36.26 Let (Ω, F, P) be a probability space and let X : Ω→E be a
random variable where here E is some topological space. Then one can deﬁne a
probability measure, λX on B (E) as follows:
λX (F) ≡P ([X ∈F])
More generally, if µ is a probability measure on B (E) , and X is a random variable
deﬁned on a probability space, L (X) = µ means
µ (F) ≡P ([X ∈F]) .
The following amazing theorem is due to Skorokhod. It starts with a measure,
µ on B (E) and produces a random variable, X for which L (X) = µ. It also has
something to say about the convergence of a sequence of such random variables.
Theorem 36.27 Let E be a separable Banach space and let {µn} be a sequence
of Borel probability measures deﬁned on B (E) such that µn converges weakly to µ
another probability measure on B (E). Then there exist random variables, Xn, X
deﬁned on the probability space, ([0, 1), B ([0, 1)) , m) where m is one dimensional
Lebesgue measure such that
L (X) = µ, L (Xn) = µn,
(36.9)
each random variable, X, Xn is continuous oﬀa set of measure zero, and
Xn (ω) →X (ω) m a.e.
Proof: Let {ak} be a countable dense subset of E.
Construction of sets in E
First I will describe a construction. Letting C ∈B (E) and r > 0,
Cr
1
≡
C ∩B (a1, r) , Cr
2 ≡B (a2, r) ∩C \ Cr
1, · · ·,
Cr
n
≡
B (an, r) ∩C \
¡
∪n−1
k=1Cr
k
¢
.

36.5.
A MAJOR EXISTENCE AND CONVERGENCE THEOREM
1009
Thus the sets, Cr
k for k = 1, 2, · · · are disjoint Borel sets whose union is all of C.
Now let C = E, the whole Banach space. Also let {rk} be a decreasing sequence of
positive numbers which converges to 0. Let
Ak ≡Er1
k , k = 1, 2, · · ·
Thus {Ak} is a sequence of Borel sets, Ak ⊆B (ak, r1) , and the union of the Ak
equals E.
For (i1, · · ·, im) ∈Nm, suppose Ai1,···,im has been deﬁned.
Then for
k ∈N,
Ai1,···,imk ≡(Ai1,···,im)rm+1
k
Thus Ai1,···,imk ⊆B (ak, rm+1), is a Borel set, and
∪∞
k=1 Ai1,···,imk = Ai1,···,im.
(36.10)
Also note that Ai1,···,im could be empty. This is because Ai1,···,imk ⊆B (ak, rm+1)
but Ai1,···,im ⊆B (aim, rm) which might have empty intersection with B (ak, rm+1) .
However, applying 36.10 repeatedly,
E = ∪i1 · · · ∪imAi1,···,im
and also, the construction shows the Borel sets, Ai1,···,im are disjoint.
Construction of intervals depending on the measure
Next I will construct intervals, Iν
i1,···,in in [0, 1) corresponding to these Ai1,···,in.
In what follows, ν = µn or µ. These intervals will depend on the measure chosen
as indicated in the notation.
Iν
1 ≡[0, ν (A1)), · · ·, Iν
j ≡
"j−1
X
k=1
ν (Ak) ,
j
X
k=1
ν (Ak)
!
for j = 1, 2, · · ·. Note these are disjoint intervals whose union is [0, 1). Also note
m
¡
Iν
j
¢
= ν (Aj) .
The endpoints of these intervals as well as their lengths depend on the measures of
the sets Ak. Now supposing Iν
i1,···,im = [α, β) where β −α = ν (Ai1···,im) , deﬁne
Iν
i1···,im,j ≡
"
α +
j−1
X
k=1
ν (Ai1···,im,k) , α +
j
X
k=1
ν (Ai1···,im,k)
!
Thus m
¡
Iν
i1···,im,j
¢
= ν (Ai1···,im,j) and
ν (Ai1···,im) =
∞
X
k=1
ν (Ai1···,im,k) =
∞
X
k=1
m
¡
Iν
i1···,im,k
¢
= β −α,
the intervals, Iν
i1···,im,j being disjoint and
Iν
i1···,im = ∪∞
j=1Iν
i1···,im,j.

1010
PROBABILITY IN INFINITE DIMENSIONS
Choosing the sequence {rk} in an auspicious manner
There are at most countably many positive numbers, r such that for ν = µn
or µ, ν (∂B (ai, r)) > 0. This is because ν is a ﬁnite measure. Taking the count-
able union of these countable sets, there are only countably many r such that
ν (∂B (ai, r)) > 0 for some ai. Let the sequence avoid all these bad values of r.
Thus for
F ≡∪∞
m=1 ∪∞
k=1 ∂B (ak, rm)
and ν = µ or µn, ν (F) = 0.
Claim 1: ∂Ai1,···,ik ⊆F.
Proof of claim: Suppose C is a Borel set for which ∂C ⊆F. I need to show
∂Cri
k
∈F. First consider k = 1. Then Cri
1
≡B (a1, ri) ∩C. If x ∈∂Cri
1 , then
B (x, δ) contains points of B (a1, ri) ∩C and points of B (a1, ri)C ∪CC for every
δ > 0. First suppose x ∈B (a1, ri) . Then a small enough neighborhood of x has no
points of B (a1, ri)C and so every B (x, δ) has points of C and points of CC so that
x ∈∂C ⊆F by assumption. If x ∈∂Cri
1 , then it can’t happen that ||x −a1|| > ri
because then there would be a neighborhood of x having no points of Cri
1 . The
only other case to consider is that ||x −ai|| = ri but this says x ∈F. Now assume
∂Cri
j ⊆F for j ≤k −1 and consider ∂Cri
k .
Cri
k
≡
B (ak, ri) ∩C \ ∪k−1
j=1Cri
j
=
B (ak, ri) ∩C ∩
³
∩k−1
j=1
¡
Cri
j
¢C´
(36.11)
Consider x ∈∂Cri
k . If x ∈int (B (ak, ri) ∩C) (int ≡interior) then a small enough
ball about x contains no points of (B (ak, ri) ∩C)C and so every ball about x must
contain points of
³
∩k−1
j=1
¡
Cri
j
¢C´C
= ∪k−1
j=1Cri
j
Since there are only ﬁnitely many sets in the union, there exists s ≤k −1 such that
every ball about x contains points of Cri
s but from 36.11, every ball about x contains
points of (Cri
s )C which implies x ∈∂Cri
s ⊆F by induction. It is not possible that
||x −ak|| > ri and yet have x in ∂Cri
k . This follows from the description in 36.11.
If ||x −ak|| = ri then by deﬁnition, x ∈F. The only other case to consider is
that x /∈int (B (ak, ri) ∩C) but x ∈B (ak, ri). From 36.11, every ball about x
contains points of C. However, since x ∈B (ak, ri) , a small enough ball is contained
in B (ak, ri) . Therefore, every ball about x must also contain points of CC since
otherwise, x ∈int (B (ak, ri) ∩C) . Thus x ∈∂C ⊆F by assumption. Now apply
what was just shown to the case where C = E, the whole space.
In this case,
∂E ⊆F because ∂E = ∅. Then keep applying what was just shown to the Ai1,···,in.
This proves the claim.
From the claim, ν (int (Ai1,···,in)) = ν (Ai1,···,in) whenever ν = µ or µn.
Some functions on [0, 1)

36.5.
A MAJOR EXISTENCE AND CONVERGENCE THEOREM
1011
By the axiom of choice, there exists xi1,···,im ∈int (Ai1,···,im) whenever int (Ai1,···,im) ̸=
∅. For ν = µn or µ, deﬁne the following functions. For ω ∈Iν
i1,···,im
Zν
m (ω) ≡xi1,···,im.
This deﬁnes the functions, Zµn
m and Zµ
m. Note these functions have the same values
but on slightly diﬀerent intervals. Here is an important claim.
Claim 2: For a.e. ω ∈[0, 1), limn→∞Zµn
m (ω) = Zµ
m (ω) .
Proof of the claim: This follows from the weak convergence of µn to µ and
Lemma 36.25. This lemma implies µn (int (Ai1,···,im)) →µ (int (Ai1,···,im)) . Thus
by the construction described above, µn (Ai1,···,im) →µ (Ai1,···,im) because of claim
1 and the construction of F in which it is always a set of measure zero. It follows
that if ω ∈int
¡
Iµ
i1,···,im
¢
, then for all n large enough, ω ∈int
¡
Iµn
i1,···,im
¢
and so
Zµn
m (ω) = Zµ
m (ω) . Note this convergence is very far from being uniform.
Claim 3: For ν = µn or µ, {Zν
m}∞
m=1 is uniformly Cauchy independent of n.
Proof of the claim: For ω ∈Iν
i1,···,im, then by the construction, ω ∈Iν
i1,···,im,im+1···,in
for some im+1 · ··, in. Therefore, Zν
m (ω) and Zν
n (ω) are both contained in Ai1,···,im
which is contained in B (aim, rm) . Since ω ∈[0, 1) was arbitrary, and rm →0, it
follows these functions are uniformly Cauchy as claimed.
Let Xν (ω) = limm→∞Zν
m (ω). Since each Zν
m is continuous oﬀa set of measure
zero, it follows from the uniform convergence that Xν is also continuous oﬀa set of
measure zero.
Claim 4: For a.e. ω,
lim
n→∞Xµn (ω) = Xµ (ω) .
Proof of the claim: From Claim 3 and letting ε > 0 be given, there exists m
large enough that for all n,
||Zµn
m −Xµn||∞< ε/3, ||Zµ
m −Xµ||∞< ε/3.
Now pick ω ∈[0, 1) such that ω is not equal to any of the end points of any of the
intervals,
©
Iν
i1,···,im
ª
, a set of measure zero. Then by Claim 2, there exists N such
that if n ≥N, then
¯¯¯¯Zµn
m (ω) −Zµ
m (ω)
¯¯¯¯
E < ε/3. Therefore, for such n and this ω,
||Xµn (ω) −Xµ (ω)||E
≤
||Xµn (ω) −Zµn
m (ω)||E + ||Zµn
m (ω) −Zµ
m (ω)||E
+ ||Zµ
m (ω) −Xµ (ω)||
<
ε/3 + ε/3 + ε/3 = ε.
This proves the claim.
Showing L (Xν) = ν.
This has mostly proved the theorem except for the claim that L (Xν) = ν for
ν = µn and µ. To do this, I will ﬁrst show m
³
(Xν)−1 (∂Ai1,···,im)
´
= 0. By the

1012
PROBABILITY IN INFINITE DIMENSIONS
construction, ν (∂Ai1,···,im) = 0. Let ε > 0 be given and let δ > 0 be small enough
that
Hδ ≡{x ∈E : dist (x, ∂Ai1,···,im) ≤δ}
is a set of measure less than ε/2.
Denote by Gk the sets of the form Ai1,···,ik
where (i1, · · ·, ik) ∈Nk. Recall also that corresponding to Ai1,···,ik is an interval,
Iν
i1,···,ik having length equal to ν (Ai1,···,ik) . Denote by Bk those sets of Gk which
have nonempty intersection with Hδ and let the corresponding intervals be denoted
by Iν
k. If ω /∈∪Iν
k, then from the construction, Zν
p (ω) is at a distance of at least
δ from ∂Ai1,···,im for all p ≥k and so, passing to the limit as p →∞, it follows
Xν (ω) /∈∂Ai1,···,im. Therefore,
(Xν)−1 (∂Ai1,···,im) ⊆∪Iν
k
Recall that Ai1,···,ik ⊆B (aik, rk) and the rk →0. Therefore, if k is large enough,
ν (∪Bk) < ε
because ∪Bk approximates Hδ closely (In fact, ∩∞
k=1 (∪Bk) = Hδ.). Therefore,
m
³
(Xν)−1 (∂Ai1,···,im)
´
≤
m (∪Iν
k)
=
X
Iν
i1,···,ik ∈Iν
k
m
¡
Iν
i1,···,ik
¢
=
X
Ai1,···,ik ∈Bk
ν (Ai1,···,ik)
=
ν (∪Bk) < ε.
Since ε > 0 is arbitrary, this shows m
³
(Xν)−1 (∂Ai1,···,im)
´
= 0.
If ω ∈Iν
i1,···,im, then from the construction, Zν
p (ω) ∈int (Ai1,···,im) for all p ≥k.
Therefore, taking a limit, as p →∞,
Xν (ω) ∈int (Ai1,···,im) ∪∂Ai1,···,im
and so
Iν
i1,···,im ⊆(Xν)−1 (int (Ai1,···,im) ∪∂Ai1,···,im)
but also, if Xν (ω) ∈int (Ai1,···,im) , then Zν
p (ω) ∈int (Ai1,···,im) for all p large
enough and so
(Xν)−1 (int (Ai1,···,im))
⊆
Iν
i1,···,im
⊆
(Xν)−1 (int (Ai1,···,im) ∪∂Ai1,···,im)

36.5.
A MAJOR EXISTENCE AND CONVERGENCE THEOREM
1013
Therefore,
m
³
(Xν)−1 (int (Ai1,···,im))
´
≤
m
¡
Iν
i1,···,im
¢
≤
m
³
(Xν)−1 (int (Ai1,···,im))
´
+ m
³
(Xν)−1 (∂Ai1,···,im)
´
=
m
³
(Xν)−1 (int (Ai1,···,im))
´
which shows
m
³
(Xν)−1 (int (Ai1,···,im))
´
= m
¡
Iν
i1,···,im
¢
= ν (Ai1,···,im) .
(36.12)
Also
m
³
(Xν)−1 (int (Ai1,···,im))
´
≤
m
³
(Xν)−1 (Ai1,···,im)
´
≤
m
³
(Xν)−1 (int (Ai1,···,im) ∪∂Ai1,···,im)
´
=
m
³
(Xν)−1 (int (Ai1,···,im))
´
Hence from 36.12,
ν (Ai1,···,im) = m
³
(Xν)−1 (int (Ai1,···,im))
´
= m
³
(Xν)−1 (Ai1,···,im)
´
(36.13)
Now let U be an open set in E. Then letting
Hk =
©
x ∈U : dist
¡
x, U C¢
≥rk
ª
it follows
∪kHk = U.
Next consider the sets of Gk which have nonempty intersection with Hk, Hk. Then
Hk is covered by Hk and every set of Hk is contained in U, the sets of Hk also being
disjoint. Then from 36.13,
m
³
(Xν)−1 (∪Hk)
´
=
X
A∈Hk
m
³
(Xν)−1 (A)
´
=
X
A∈Hk
ν (A) = ν (∪Hk) .
Therefore, letting k →∞and passing to the limit in the above,
m
³
(Xν)−1 (U)
´
= ν (U) .
Since this holds for every open set, it is routine to verify using regularity that it
holds for every Borel set and so L (Xν) = ν as claimed. This proves the theorem.

1014
PROBABILITY IN INFINITE DIMENSIONS
36.6
Characteristic Functions
Recall the characteristic function for a random variable having values in Rn. I will
give a review of this to begin with. Then the concept will be generalized to random
variables (vectors) which have values in a real separable Banach space.
Deﬁnition 36.28 Let X be a random variable. The characteristic function is
φX (t) ≡E
¡
eit·X¢
≡
Z
Ω
eit·X(ω)dP =
Z
Rp eit·xdλX
the last equation holding by Lemma 31.4 on Page 858.
Recall the following fundamental lemma and deﬁnition, Lemma 19.12 on Page
522.
Deﬁnition 36.29 For T ∈G∗, deﬁne FT, F −1T ∈G∗by
FT (φ) ≡T (Fφ) , F −1T (φ) ≡T
¡
F −1φ
¢
Lemma 36.30 F and F −1 are both one to one, onto, and are inverses of each
other.
The main result on characteristic functions is the following is in Theorem 31.10
on Page 860 which is stated here for convenience.
Theorem 36.31 Let X and Y be random vectors with values in Rp and suppose
E
¡
eit·X¢
= E
¡
eit·Y¢
for all t ∈Rp. Then λX = λY.
I want to do something similar for random variables which have values in a
separable real Banach space, E instead of Rp.
Corollary 36.32 Let K be a π system of subsets of Ωand suppose two probability
measures, µ and ν deﬁned on σ (K) are equal on K. Then µ = ν.
Proof: This follows from the Lemma 9.72 on Page 257. Let
G ≡{E ∈σ (K) : µ (E) = ν (E)}
Then K ⊆G, since µ and ν are both probability measures, it follows that if E ∈G,
then so is EC. Since these are measures, if {Ai} is a sequence of disjoint sets from
G then
µ (∪∞
i=1Ai) =
X
i
µ (Ai) =
X
i
ν (Ai) = ν (∪∞
i=1A)
and so from Lemma 9.72, G = σ (K) . This proves the corollary.
Next recall the following fundamental lemma used to prove Pettis’ theorem. It
is proved on Page 579 but is stated here for convenience.

36.6.
CHARACTERISTIC FUNCTIONS
1015
Lemma 36.33 If E is a separable Banach space with B′ the closed unit ball in E′,
then there exists a sequence {fn}∞
n=1 ≡D′ ⊆B′ with the property that for every
x ∈E,
||x|| = sup
f∈D′ |f (x)|
Deﬁnition 36.34 Let E be a separable real Banach space. A cylindrical set is one
which is of the form
{x ∈E : x∗
i (x) ∈Γi, i = 1, 2, · · ·, m}
where here x∗
i ∈E′ and Γi is a Borel set in R.
It is obvious that ∅is a cylindrical set and that the intersection of two cylindrical
sets is another cylindrical set. Thus the cylindrical sets form a π system. What is
the smallest σ algebra containing the cylindrical sets? Letting {fn}∞
n=1 = D′ be the
sequence of Lemma 36.33 it follows that
{x ∈E : ||x −a|| ≤δ}
=
(
x ∈E : sup
f∈D′ |f (x −a)| ≤δ
)
=
(
x ∈E : sup
f∈D′ |f (x) −f (a)| ≤δ
)
=
∩∞
n=1
n
x ∈E : fn (x) ∈B (fn (a) , δ)
o
which yields a countable intersection of cylindrical sets. It follows the smallest σ
algebra containing the cylindrical sets contains the closed balls and hence the open
balls and consequently the open sets and so it contains the Borel sets. However,
each cylindrical set is a Borel set and so in fact this σ algebra equals B (E).
From Corollary 36.32 it follows that two probability measures which are equal
on the cylindrical sets are equal on the Borel sets, B (E).
Deﬁnition 36.35 Let µ be a probability measure on a real separable Banach space,
E. Then for x∗∈E′,
φµ (x∗) ≡
Z
E
eix∗(x)dµ (x) .
φµ is called the characteristic function for the measure µ.
Note this is a little diﬀerent than earlier when the symbol φX (t) was used and
X was a random variable. Here the focus is more on the measure than a random
variable, X such that L (X) = µ but it does not matter much because of Skorokhod’s
theorem presented above. The fundamental result is the following theorem.

1016
PROBABILITY IN INFINITE DIMENSIONS
Theorem 36.36 Let µ and ν be two probability measures on B (E) where E is a
separable real Banach space. Suppose
φµ (x∗) = φν (x∗)
for all x∗∈E′. Then µ = ν.
Proof: Let x∗
1, · · ·, x∗
n be in E′ and deﬁne for A a Borel set of Rn,
eµ (A)
≡
µ ({x ∈E : (x∗
1 (x) , · · ·, x∗
n (x)) ∈A}) ,
eν (A)
≡
ν ({x ∈E : (x∗
1 (x) , · · ·, x∗
n (x)) ∈A}) .
(36.14)
Note these sets in the parentheses are cylindrical sets. Letting λ ∈Rn, consider in
the deﬁnition of the characteristic function, λ1x∗
1 + · · · + λnx∗
n ∈E′. Thus
Z
E
ei(λ1x∗
1(x)+···+λnx∗
n(x))dµ =
Z
E
ei(λ1x∗
1(x)+···+λnx∗
n(x))dν
Now if F is a Borel measurable subset of Rn,
Z
Rn XF (y) deµ (y) = eµ (F)
≡
µ ({x ∈E : (x∗
1 (x) , · · ·, x∗
n (x)) ∈F})
=
Z
E
XF (x∗
1 (x) , · · ·, x∗
n (x)) dµ
and using the usual approximations involving simple functions, it follows that for
any f bounded and Borel measurable,
Z
Rn f (y) deµ (y) =
Z
E
f ((x∗
1 (x) , · · ·, x∗
n (x))) dµ (x) .
Similarly,
Z
Rn f (y) deν (y) =
Z
E
f ((x∗
1 (x) , · · ·, x∗
n (x))) dν (x) ,
Therefore,
Z
Rn eiλ·ydeµ (y)
=
Z
E
ei(λ1x∗
1(x)+···+λnx∗
n(x))dµ
=
Z
E
ei(λ1x∗
1(x)+···+λnx∗
n(x))dν
=
Z
Rn eiλ·ydeν (y)
which shows from Theorem 36.31 that eν = eµ on the Borel sets of Rn. However,
from the deﬁnition of these measures in 36.14 this says nothing more than µ = ν

36.6.
CHARACTERISTIC FUNCTIONS
1017
on any cylindrical set. Hence by Corollary 36.32 this shows µ = ν on B (E) . This
proves the theorem.
Finally, I will consider the relation between the characteristic function and in-
dependence of random variables. Recall an earlier proposition which relates inde-
pendence of random vectors with characteristic functions. It is proved starting on
Page 865 in the case of two random variables and concludes with the observation
that the general case is entirely similar but more tedious to write down.
Proposition 36.37 Let {Xk}n
k=1be random vectors such that Xk has values in
Rpk. Then the random vectors are independent if and only if
E
¡
eiP ¢
=
n
Y
j=1
E
¡
eitj·Xj¢
where P ≡Pn
j=1 tj · Xj for tj ∈Rpj.
It turns out there is a generalization of the above proposition to the case where
the random variables have values in a real separable Banach space. Before proving
this recall an earlier theorem which had to do with reducing to the case where the
random variables had values in Rn. It is restated here for convenience.
Theorem 36.38 The random variables, {Xi}i∈I are independent if whenever
{i1, · · ·, in} ⊆I,
mi1, ···, min are positive integers, and gmi1 , ···, gmin are in (E′)mi1 , ···, (E′)mn re-
spectively,
n
gmij ◦Xij
on
j=1 are independent random vectors having values in Rmi1 , ··
·, Rmin respectively.
Now here is the theorem about independence and the characteristic functions.
Theorem 36.39 Let {Xk}n
k=1be random variables having values in E, a real sep-
arable Banach space. Then the random variables are independent if and only if
E
¡
eiP ¢
=
n
Y
j=1
E
³
eit∗
j (Xj)´
where P ≡Pn
j=1 t∗
j (Xj) for t∗
j ∈E′.
Proof: If the random variables are independent, then so are the random vari-
ables, t∗
j (Xj) and so the equation follows.
The interesting case is when the equation holds. Can you draw the conclusion
the random variables are independent? By Theorem 36.38, it suﬃces to show the
random variables {gmk ◦Xk}n
k=1 are independent. This happens if whenever tmk ∈
Rmk and
P =
n
X
k=1
tmk · (gmk ◦Xk) ,

1018
PROBABILITY IN INFINITE DIMENSIONS
it follows
E
¡
eiP ¢
=
n
Y
j=1
E
³
eitmk ·(gmk ◦Xk)´
.
(36.15)
Now consider one of these terms in the exponent on the right.
tmk · (gmk ◦Xk) (ω)
=
mk
X
j=1
tjx∗
j (Xk (ω))
=
y∗
k (Xk (ω))
where y∗≡Pmk
j=1 tjx∗
j. Therefore, 36.15 reduces to
E
³
ei Pn
k=1 y∗
k(Xk)´
=
n
Y
k=1
E
³
eiy∗
k(Xk)´
which is assumed to hold. Therefore, the random variables are independent. This
proves the theorem.
There is an obvious corollary which is useful.
Corollary 36.40 Let {Xk}n
k=1be random variables having values in E, a real sep-
arable Banach space. Then the random variables are independent if and only if
E
¡
eiP ¢
=
n
Y
j=1
E
³
eit∗
j (Xj)´
where P ≡Pn
j=1 t∗
j (Xj) for t∗
j ∈M where M is a dense subset of E′.
Proof: The easy direction follows from Theorem 36.39. Suppose then the above
equation holds for all t∗
j ∈M. Then let t∗
j ∈E′ and let
©
t∗
nj
ª
be a sequence in M
such that
lim
n→∞t∗
nj = t∗
j in E′
Then deﬁne
P ≡
n
X
j=1
t∗
jXj, Pn ≡
n
X
j=1
t∗
njXj.
It follows
E
¡
eiP ¢
=
lim
n→∞E
¡
eiPn¢
=
lim
n→∞
n
Y
j=1
E
³
eit∗
nj(Xj)´
=
n
Y
j=1
E
³
eit∗
j (Xj)´
and this proves the corollary.

36.7.
CONVOLUTION
1019
36.7
Convolution
Lemma 36.18 on Page 1002 makes possible a deﬁnition of convolution of two prob-
ability measures deﬁned on B (E) where E is a separable Banach space as well as
some other interesting theorems which held earlier in the context of locally compact
spaces. I will ﬁrst show a little theorem about density of continuous functions in
Lp (E) and then deﬁne the convolution of two ﬁnite measures. First here is a simple
technical lemma.
Lemma 36.41 Suppose K is a compact subset of U an open set in E a metric
space. Then there exists δ > 0 such that
dist (x, K) + dist
¡
x, U C¢
≥δ for all x ∈E.
Proof: For each x ∈K, there exists a ball, B (x, δx) such that B (x, 3δx) ⊆U.
Finitely many of these balls cover K because K is compact, say {B (xi, δxi)}m
i=1.
Let
0 < δ < min (δxi : i = 1, 2, · · ·, m) .
Now pick any x ∈K. Then x ∈B (xi, δxi) for some xi and so B (x, δ) ⊆B (xi, 2δxi) ⊆
U. Therefore, for any x ∈K, dist
¡
x, U C¢
≥δ. If x ∈B (xi, 2δxi) for some xi, it
follows dist
¡
x, U C¢
≥δ because then B (x, δ) ⊆B (xi, 3δxi) ⊆U. If x /∈B (xi, 2δxi)
for any of the xi, then x /∈B (y, δ) for any y ∈K because all these sets are contained
in some B (xi, 2δxi) . Consequently dist (x, K) ≥δ. This proves the lemma.
From this lemma, there is an easy corollary.
Corollary 36.42 Suppose K is a compact subset of U, an open set in E a metric
space. Then there exists a uniformly continuous function f deﬁned on all of E,
having values in [0, 1] such that f (x) = 0 if x /∈U and f (x) = 1 if x ∈K.
Proof: Consider
f (x) ≡
dist
¡
x, U C¢
dist (x, U C) + dist (x, K).
Then some algebra yields
|f (x) −f (x′)| ≤
1
δ
¡¯¯dist
¡
x, U C¢
−dist
¡
x′, U C¢¯¯ + |dist (x, K) −dist (x′, K)|
¢
where δ is the constant of Lemma 36.41. Now it is a general fact that
|dist (x, S) −dist (x′, S)| ≤d (x, x′) .
Therefore,
|f (x) −f (x′)| ≤2
δ d (x, x′)
and this proves the corollary.

1020
PROBABILITY IN INFINITE DIMENSIONS
Now suppose µ is a ﬁnite measure deﬁned on the Borel sets of a separable Banach
space, E. It was shown above that µ is inner and outer regular. Lemma 36.18 on
Page 1002 shows that µ is inner regular in the usual sense with respect to compact
sets. This makes possible the following theorem.
Theorem 36.43 Let µ be a ﬁnite measure on B (E) where E is a separable Banach
space and let f ∈Lp (E; µ) . Then for any ε > 0, there exists a uniformly continuous,
bounded g deﬁned on E such that
||f −g||Lp(E) < ε.
Proof: As usual in such situations, it suﬃces to consider only f ≥0. Then
by Theorem 8.27 on Page 190 and an application of the monotone convergence
theorem, there exists a simple measurable function,
s (x) ≡
m
X
k=1
ckXAk (x)
such that ||f −s||Lp(E) < ε/2. Now by regularity of µ there exist compact sets,
Kk and open sets, Vk such that 2 Pm
k=1 |ck| µ (Vk \ K)1/p < ε/2 and by Corollary
36.42 there exist uniformly continuous functions gk having values in [0, 1] such that
gk = 1 on Kk and 0 on V C
k . Then consider
g (x) =
m
X
k=1
ckgk (x) .
This function is bounded and uniformly continuous. Furthermore,
||s −g||Lp(E)
≤
ÃZ
E
¯¯¯¯¯
m
X
k=1
ckXAk (x) −
m
X
k=1
ckgk (x)
¯¯¯¯¯
p
dµ
!1/p
≤
ÃZ
E
Ã m
X
k=1
|ck| |XAk (x) −gk (x)|
!p!1/p
≤
m
X
k=1
|ck|
µZ
E
|XAk (x) −gk (x)|p dµ
¶1/p
≤
m
X
k=1
|ck|
ÃZ
Vk\Kk
2pdµ
!1/p
=
2
m
X
k=1
|ck| µ (Vk \ K)1/p < ε/2.
Therefore,
||f −g||Lp ≤||f −s||Lp + ||s −g||Lp < ε/2 + ε/2.
This proves the theorem.

36.7.
CONVOLUTION
1021
Lemma 36.44 Let A ∈B (E) where µ is a ﬁnite measure on B (E) for E a sepa-
rable Banach space. Also let xi ∈E for i = 1, 2, · · ·, m. Then for x ∈Em,
x →µ
Ã
A +
m
X
i=1
xi
!
, x →µ
Ã
A −
m
X
i=1
xi
!
are Borel measurable functions. Furthermore, the above functions are
B (E) × · · · × B (E)
measurable where the above denotes the product measurable sets as described in
Theorem 9.75 on Page 260.
Proof: First consider the case where A = U, an open set. Let
y ∈
(
x ∈Em : µ
Ã
U +
m
X
i=1
xi
!
> α
)
(36.16)
Then from Lemma 36.18 on Page 1002 there exists a compact set, K ⊆U +Pm
i=1 yi
such that µ (K) > α. Then if y′ is close enough to y, it follows K ⊆U + Pm
i=1 y′
i
also. Therefore, for all y′ close enough to y,
µ
Ã
U +
m
X
i=1
y′
i
!
≥µ (K) > α.
In other words the set described in 36.16 is an open set and so y →µ (U + Pm
i=1 yi)
is Borel measurable whenever U is an open set in E.
Deﬁne a π system, K to consist of all open sets in E. Then deﬁne G as
(
A ∈σ (K) = B (E) : y →µ
Ã
A +
m
X
i=1
yi
!
is Borel measurable
)
I just showed G ⊇K. Now suppose A ∈G. Then
µ
Ã
AC +
m
X
i=1
yi
!
= µ (E) −µ
Ã
A +
m
X
i=1
yi
!
and so AC ∈G whenever A ∈G. Next suppose {Ai} is a sequence of disjoint sets
of G. Then
µ

(∪∞
i=1Ai) +
m
X
j=1
yj


=
µ

∪∞
i=1

Ai +
m
X
j=1
yj




=
∞
X
i=1
µ

Ai +
m
X
j=1
yj



1022
PROBABILITY IN INFINITE DIMENSIONS
and so ∪∞
i=1Ai ∈G because it is the sum of Borel measurable functions. By the
lemma on π systems, Lemma 9.72 on Page 257, it follows G = σ (K) = B (E) .
Similarly, x →µ
³
A −Pm
j=1 xj
´
is also Borel measurable whenever A ∈B (E).
Finally note that
B (E) × · · · × B (E)
contains the open sets of Em because the separability of E implies the existence of
a countable basis for the topology of Em consisting of sets of the form
m
Y
i=1
Ui
where the Ui come from a countable basis for E. Since every open set is the countable
union of sets like the above, each being a measurable box, the open sets are contained
in
B (E) × · · · × B (E)
which implies B (Em) ⊆B (E) × · · · × B (E) also. This proves the lemma.
With this lemma, it is possible to deﬁne the convolution of two ﬁnite measures.
Deﬁnition 36.45 Let µ and ν be two ﬁnite measures on B (E) , for E a separable
Banach space. Then deﬁne a new measure, µ ∗ν on B (E) as follows
µ ∗ν (A) ≡
Z
E
ν (A −x) dµ (x) .
This is well deﬁned because of Lemma 36.44 which says that x →ν (A −x) is Borel
measurable.
Here is an interesting theorem about convolutions. However, ﬁrst here is a little
lemma. The following picture is descriptive of the set described in the following
lemma.
A
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
E
E
SA
Lemma 36.46 For A a Borel set in E, a separable Banach space, deﬁne
SA ≡{(x, y) ∈E × E : x + y ∈A}
Then SA ∈B (E) × B (E) , the σ algebra of product measurable sets, the smallest σ
algebra which contains all the sets of the form A × B where A and B are Borel.

36.7.
CONVOLUTION
1023
Proof: Let K denote the open sets in E. Then K is a π system. Let
G ≡{A ∈σ (K) = B (E) : SA ∈B (E) × B (E)} .
Then K ⊆G because if U ∈K then SU is an open set in E × E and all open sets
are in B (E) × B (E) because a countable basis for the topology of E × E are sets
of the form B × C where B and C come from a countable basis for E. Therefore,
K ⊆G. Now let A ∈G. For (x, y) ∈E × E, either x + y ∈A or x + y /∈A. Hence
E × E = SA ∪SAC which shows that if A ∈G then so is AC. Finally if {Ai} is a
sequence of disjoint sets of G
S∪∞
i=1Ai = ∪∞
i=1SAi
and this shows that G is also closed with respect to countable unions of disjoint
sets. Therefore, by the lemma on π systems, Lemma 9.72 on Page 257 it follows
G = σ (K) = B (E) . This proves the lemma.
Theorem 36.47 Let µ, ν, and λ be ﬁnite measures on B (E) for E a separable
Banach space. Then
µ ∗ν = ν ∗µ
(36.17)
(µ ∗ν) ∗λ = µ ∗(ν ∗λ)
(36.18)
If µ is the distribution for an E valued random variable, X and if ν is the distribution
for an E valued random variable, Y, and X and Y are independent, then µ ∗ν is
the distribution for the random variable, X + Y .
Proof: First consider 36.17. Letting A ∈B (E) , the following computation
holds from Fubini’s theorem and Lemma 36.46
µ ∗ν (A)
≡
Z
E
ν (A −x) dµ (x) =
Z
E
Z
E
XSA (x, y) dν (y) dµ (x)
=
Z
E
Z
E
XSA (x, y) dµ (x) dν (y) = ν ∗µ (A) .
Next consider 36.18. Using 36.17 whenever convenient,
(µ ∗ν) ∗λ (A)
≡
Z
E
(µ ∗ν) (A −x) dλ (x)
=
Z
E
Z
E
ν (A −x −y) dµ (y) dλ (x)
while
µ ∗(ν ∗λ) (A)
≡
Z
E
(ν ∗λ) (A −y) dµ (y)
=
Z
E
Z
E
ν (A −y −x) dλ (x) dµ (y)
=
Z
E
Z
E
ν (A −y −x) dµ (y) dλ (x) .

1024
PROBABILITY IN INFINITE DIMENSIONS
The necessary product measurability comes from Lemma 36.44.
Recall
(µ ∗ν) (A) ≡
Z
E
ν (A −x) dµ (x) .
Therefore, if s is a simple function, s (x) = Pn
k=1 ckXAk (x) ,
Z
E
sd (µ ∗ν)
=
n
X
k=1
ck
Z
E
ν (Ak −x) dµ (x)
=
Z
E
n
X
k=1
ckν (Ak −x) dµ (x)
=
Z
E
Z
E
s (x + y) dν (x) dµ (y)
Approximating with simple functions it follows that whenever f is bounded and
measurable or nonnegative and measurable,
Z
E
fd (µ ∗ν) =
Z
E
Z
E
f (x + y) dν (y) dµ (x)
(36.19)
Therefore, letting Z = X + Y, and λ the distribution of Z, it follows from indepen-
dence of X and Y that for t∗∈E′,
φλ (t∗) ≡E
³
eit∗(Z)´
= E
³
eit∗(X+Y )´
= E
³
eit∗(X)´
E
³
eit∗(Y )´
But also, it follows from 36.19
φ(µ∗ν) (t∗)
=
Z
E
eit∗(z)d (µ ∗ν) (z)
=
Z
E
Z
E
eit∗(x+y)dν (y) dµ (x)
=
Z
E
Z
E
eit∗(x)eit∗(y)dν (y) dµ (x)
=
µZ
E
eit∗(y)dν (y)
¶ µZ
E
eit∗(x)dµ (x)
¶
=
E
³
eit∗(X)´
E
³
eit∗(Y )´
Since φλ (t∗) = φ(µ∗ν) (t∗) , it follows λ = µ ∗ν. This proves the theorem.
Note the last part of this argument shows the characteristic function of a con-
volution equals the product of the characteristic functions.
36.8
The Multivariate Normal Distribution
Here I give a review of the main theorems and deﬁnitions about multivariate normal
random variables. Recall that for a random vector (variable), X having values in

36.8.
THE MULTIVARIATE NORMAL DISTRIBUTION
1025
Rp, λX is the law of X deﬁned by
P ([X ∈E]) = λX (E)
for all E a Borel set in Rp. In diﬀerent notaion, L (X) = λX. Then the following
deﬁnitions and theorems are proved and presented starting on Page 867
Deﬁnition 36.48 A random vector, X, with values in Rp has a multivariate nor-
mal distribution written as X ∼Np (m, Σ) if for all Borel E ⊆Rp,
λX (E) =
Z
Rp XE (x)
1
(2π)p/2 det (Σ)1/2 e
−1
2 (x−m)∗Σ−1(x−m)dx
for µ a given vector and Σ a given positive deﬁnite symmetric matrix.
Theorem 36.49 For X ∼Np (m, Σ) , m = E (X) and
Σ = E
¡
(X −m) (X −m)∗¢
.
Theorem 36.50 Suppose X1 ∼Np (m1, Σ1) , X2 ∼Np (m2, Σ2) and the two ran-
dom vectors are independent. Then
X1 + X2 ∼Np (m1 + m2, Σ1 + Σ2).
(36.20)
Also, if X ∼Np (m, Σ) then −X ∼Np (−m, Σ) . Furthermore, if X ∼Np (m, Σ)
then
E
¡
eit·X¢
= eit·me−1
2 t∗Σt
(36.21)
Also if a is a constant and X ∼Np (m, Σ) then aX ∼Np
¡
am, a2Σ
¢
.
Following [42] a random vector has a generalized normal distribution if its char-
acteristic function is given as
eit·me−1
2 t∗Σt
(36.22)
where Σ is symmetric and has nonnegative eigenvalues. For a random real valued
variable, m is scalar and so is Σ so the characteristic function of such a generalized
normally distributed random variable is
eitme−1
2 t2σ2
(36.23)
These generalized normal distributions do not require Σ to be invertible, only that
the eigenvalues by nonnegative. In one dimension this would correspond the charac-
teristic function of a dirac measure having point mass 1 at m. In higher dimensions,
it could be a mixture of such things with more familiar things. I will often not
bother to distinguish between generalized normal and normal distributions.
Here are some other interesting results about normal distributions found in [42].
The next theorem has to do with the question whether a random vector is normally
distributed in the above generalized sense. It is proved on Page 870.

1026
PROBABILITY IN INFINITE DIMENSIONS
Theorem 36.51 Let X = (X1, · · ·, Xp) where each Xi is a real valued random
variable. Then X is normally distributed in the above generalized sense if and only
if every linear combination, Pp
j=1 aiXi is normally distributed. In this case the
mean of X is
m = (E (X1) , · · ·, E (Xp))
and the covariance matrix for X is
Σjk = E ((Xj −mj) (Xk −mk))
where mj = E (Xj).
Also proved there is the interesting corollary listed next.
Corollary 36.52 Let X = (X1, · · ·, Xp) , Y = (Y1, · · ·, Yp) where each Xi, Yi is a
real valued random variable. Suppose also that for every a ∈Rp, a · X and a · Y
are both normally distributed with the same mean and variance. Then X and Y are
both multivariate normal random vectors with the same mean and variance.
Theorem 36.53 Suppose X = (X1, · · ·, Xp) is normally distributed with mean m
and covariance Σ. Then if X1 is uncorrelated with any of the Xi,
E ((X1 −m1) (Xj −mj)) = 0 for j > 1
then X1 and (X2, · · ·, Xp) are both normally distributed and the two random vectors
are independent. Here mj ≡E (Xj) .
Next I will consider the question of existence of independent random variables
having a given law.
Lemma 36.54 Let µ be a probability measure on B (E) , the Borel subsets of a
separable real Banach space. Then there exists a probability space (Ω, F, P) and two
independent random variables, X, Y mapping Ωto E such that L (X) = L (Y ) = µ.
Proof: First note that if A, B are Borel sets of E then A × B is a Borel set in
E × E where the norm on E × E is given by
||(x, y)|| ≡max (||x|| , ||y||) .
This can be proved by letting A be open and considering
G ≡{B ∈B (E) : A × B ∈B (A × B)} .
Show G is a σ algebra and it contains the open sets. Therefore, this will show A×B
is in B (A × B) whenever A is open and B is Borel. Next repeat a similar argument
to show that this is true whenever either set is Borel. Since E is separable, it is
completely separable and so is E × E. Thus every open set in E × E is the union

36.8.
THE MULTIVARIATE NORMAL DISTRIBUTION
1027
of balls from a countable set. However, these balls are of the form B1 × B2 where
Bi is a ball in E. Now let
K ≡{A × B : A, B are Borel}
Then K ⊆B (E × E) as was just shown and also every open set from E × E is in
σ (K). It follows σ (K) equals the σ algebra of product measurable sets, B (E)×B (E)
and you can consider the product measure, µ×µ. By Skorokhod’s theorem, Theorem
36.27, there exists (X, Y ) a random variable with values in E ×E and a probability
space, (Ω, F, P) such that L ((X, Y )) = µ × µ. Then for A, B Borel sets in E
P (X ∈A, Y ∈B) = (µ × µ) (A × B) = µ (A) µ (B) .
Also, P (X ∈A) = P (X ∈A, Y ∈E) = µ (A) and similarly, P (Y ∈B) = µ (B)
showing L (X) = L (Y ) = µ and X, Y are independent.
Now here is an interesting theorem in [15].
Theorem 36.55 Suppose ν is a probability measure on the Borel sets of R and
suppose that ξ and ζ are independent random variables such that L (ξ) = L (ζ) = ν
and whenever α2 + β2 = 1 it follows L (αξ + βζ) = ν. Then
L (ξ) = N
¡
0, σ2¢
for some σ ≥0. Also if L (ξ) = L (ζ) = N
¡
0, σ2¢
where ξ, ζ are independent, then
if α2 + β2 = 1, it follows L (αξ + βζ) = N
¡
0, σ2¢
.
Proof: Let ξ, ζ be independent random variables with L (ξ) = L (ζ) = ν and
whenever α2 + β2 = 1 it follows L (αξ + βζ) = ν.
By independence of ξ and ζ,
φν (t)
≡
φαξ+αζ (t)
=
E
³
eit(αξ+βζ)´
=
E
¡
eitαξ¢
E
¡
eitβζ¢
=
φξ (αt) φζ (βt)
≡
φν (αt) φν (βt)
In simpler terms and suppressing the subscript,
φ (t) = φ (cos (θ) t) φ (sin (θ) t) .
(36.24)
Since ν is a probability measure, φ (0) = 1. Also, letting θ = π/4, this yields
φ (t) = φ
Ã√
2
2 t
!2
(36.25)
and so if φ has real values, then φ (t) ≥0.

1028
PROBABILITY IN INFINITE DIMENSIONS
Next I will show φ is real. To do this, it follows from the deﬁnition of φν,
φν (−t) ≡
Z
R
e−itxdν =
Z
R
eitxdν = φν (t).
Then letting θ = π,
φ (t) = φ (−t) · φ (0) = φ (−t) = φ (t)
showing φ has real values.
It is positive near 0 because φ (0) = 1 and φ is a
continuous function of t thanks to the dominated convergence theorem. However,
this and 36.25 implies it is positive everywhere. Here is why. If not, let tm be the
smallest positive value of t where φ (t) = 0. Then tm > 0 by continuity. Now from
36.25, an immediate contradiction results. Therefore, φ (t) > 0 for all t > 0. Similar
reasoning yields the same conclusion for t < 0.
Next note that φ (t) = φ (−t) also implies φ depends only on |t| because it takes
the same value for t as for −t. More simply, φ depends only on t2. Thus one can
deﬁne a new function of the form φ (t) = f
¡
t2¢
and 36.24 implies the following for
α ∈[0, 1] .
f
¡
t2¢
= f
¡
α2t2¢
f
¡¡
1 −α2¢
t2¢
.
Taking ln of both sides, one obtains the following for g
¡
t2¢
≡ln f
¡
t2¢
.
ln f
¡
t2¢
= ln f
¡
α2t2¢
+ ln f
¡¡
1 −α2¢
t2¢
.
Now letting x = α2t2 and y =
¡
1 −α2¢
t2, it follows that for all x ≥0
ln f (x + y) = ln f (x) + ln f (y) .
Hence ln f (x) = kx and so ln f
¡
t2¢
= kt2 and so φ (t) = f
¡
t2¢
= ekt2for all t.
The constant, k must be nonpositive because φ (t) is bounded due to its deﬁnition.
Therefore, the characteristic function of ν is
φν (t) = e−1
2 t2σ2
for some σ ≥0. That is, ν is the law of a generalized normal random variable.
Note the other direction of the implication is obvious. If ξ, ζ ∼N (0, σ) and
they are independent, then if α2 + β2 = 1, it follows
αξ + βζ ∼N
¡
0, σ2¢
because
E
³
eit(αξ+βζ)´
=
E
¡
eitαξ¢
E
¡
eitβζ¢
=
e−1
2 (αt)2σ2e−1
2 (βt)2σ2
=
e−1
2 t2σ2,
the characteristic function for a random variable which is N (0, σ). This proves the
theorem.
The next theorem is a useful gimick for showing certain random variables are
independent in the context of normal distributions.

36.8.
THE MULTIVARIATE NORMAL DISTRIBUTION
1029
Theorem 36.56 Let X and Y be random vectors having values in Rp and Rq
respectively. Suppose also that (X, Y) is multivariate normally distributed and
E
¡
(X−E (X)) (Y−E (Y))∗¢
= 0.
Then X and Y are independent random vectors.
Proof:
Let Z = (X, Y) , m = p + q. Then by hypothesis, the characteristic
function of Z is of the form
E
¡
eit·Z¢
= eit·me−1
2 it∗Σt
where m = (mX, mY) = E (Z) = E (X, Y) and
Σ
=
µ E
¡
(X−E (X)) (X−E (X))∗¢
0
0
E
¡
(Y −E (Y)) (Y −E (Y))∗¢
¶
≡
µ
ΣX
0
0
ΣY
¶
.
Therefore, letting t = (u, v) where u ∈Rp and v ∈Rq
E
¡
eit·Z¢
=
E
³
ei(u,v)·(X,Y)´
= E
³
ei(u·X+v·Y)´
=
eiu·mXe−1
2 u∗ΣXueiv·mYe−1
2 v∗ΣYv
=
E
¡
eiu·X¢
E
¡
eiv·Y¢
.
(36.26)
Where the last equality needs to be justiﬁed. When this is done it will follow from
Proposition 36.37 on Page 1017 which is proved on Page 996 that X and Y are
independent. Thus all that remains is to verify
E
¡
eiu·X¢
= eiu·mXe−1
2 u∗ΣXu, E
¡
eiv·Y¢
= eiv·mYe−1
2 v∗ΣYv.
However, this follows from 36.26. To get the ﬁrst formula, let v = 0. To get the
second, let u = 0. This proves the Theorem.
Note that to verify the conclusion of this theorem, it suﬃces to show
E (Xi −E (Xi) (Yj −E (Yj))) = 0.
Next are some technical lemmas. The ﬁrst is like an earlier result but will require
more work because it will not be assumed a certain function is bounded.
Lemma 36.57 Let (Ω, F, P) be a probability space and let X : Ω→E be a random
variable, where E is a real separable Banach space. Also let L (X) = µ, a probability
measure deﬁned on B (E) , the Borel sets of E. Suppose h : E →R is continuous
and also suppose h ◦X is in L1 (Ω) . Then
Z
Ω
(h ◦X) dP =
Z
E
h (x) dµ.

1030
PROBABILITY IN INFINITE DIMENSIONS
Proof: Let {ai}∞
i=1 be a countable dense subset of R. Let Bn
i ≡B
¡
ai, 1
n
¢
⊆R
and deﬁne Borel sets, An
i ⊆E as follows:
An
1 = h−1 (Bn
1 ) , An
k+1 ≡h−1 ¡
Bn
k+1
¢
\
¡
∪k
i=1An
i
¢
.
Thus {An
i }∞
i=1 are disjoint Borel sets, with h (An
i ) ⊆Bn
i . Also let bn
i denote the
endpoint of B
¡
ai, 1
n
¢
which is closer to 0.
hn
i ≡
½ bn
i if h−1 (Bn
i ) ̸= ∅
0 if h−1 (Bn
i ) = ∅
Then deﬁne
hn (x) ≡
∞
X
i=1
hn
i XAn
i (x)
Thus |hn (x)| ≤|h (x)| for all x ∈E and |hn (x) −h (x)| ≤1/n for all x ∈E. Then
hn ◦X is in L1 (Ω) and for all n,
|hn ◦X (ω)| ≤|h ◦X (ω)| .
Let
hn
k (x) ≡
k
X
i=1
hn
i XAn
i (x) .
Then from the construction in which the {An
i }∞
i=1 are disjoint,
|hn
k (X (ω))| ≤|h (X (ω))| , |hn
k (x)| ≤|h (x)|
and |hn
k (x)| is increasing in k.
Z
Ω
|hn
k (X (ω))| dP
=
Z
Ω
k
X
i=1
|hn
i | XAn
i (X (ω)) dP
=
Z
Ω
k
X
i=1
|hn
i | XX−1(An
i ) (ω) dP
=
k
X
i=1
|hn
i | P
¡
X−1 (An
i )
¢
=
k
X
i=1
|hn
i | µ (An
i )
=
Z
E
|hn
k (x)| dµ.
By the monotone convergence theorem, and letting k →∞,
Z
Ω
|hn (X (ω))| dP =
Z
E
|hn (x)| dµ.

36.9.
GAUSSIAN MEASURES
1031
Now by the uniform convergence in the construction, you can let n →∞and obtain
Z
Ω
|h (X (ω))| dP =
Z
E
|h (x)| dµ.
Thus h ∈L1 (E, µ). It is obviously Borel measurable, being the limit of a sequence
of Borel measurable functions. Now similar reasoning to the above and using the
dominated convergence theorem when necessary yields
Z
Ω
hn (X (ω)) dP =
Z
E
hn (x) dµ
Now another application of the dominated convergence theorem yields
Z
Ω
h (X (ω)) dP =
Z
E
h (x) dµ.
This proves the lemma.
36.9
Gaussian Measures
36.9.1
Deﬁnitions And Basic Properties
First suppose X is a random vector having values in Rn and its distribution function
is N (m,Σ) where m is the mean and Σ is the covariance. Then the characteristic
function of X or equivalently, the characteristic function of its distribution is
eit·me−1
2 t∗Σt
What is the distribution of a · X where a ∈Rn? In other words, if you take a
linear functional and do it to X to get a scalar valued random variable, what is the
distribution of this scalar valued random variable? Let Y = a · X. Then
E
¡
eitY ¢
= E
¡
eita·X¢
which from the above formula is
eia·mte−1
2 a∗Σat2
which is the characteristic function of a random variable whose distribution is
N (a · m, a∗Σa) . In other words, it is normally distributed having mean equal to
a · m and variance equal to a∗Σa. Obviously such a concept generalizes to a Banach
space in place of Rn and this motivates the following deﬁnition.
Deﬁnition 36.58 Let E be a real separable Banach space. A probability measure,
µ deﬁned on B (E) is called a Gaussian measure if for every h ∈E′, the law of h
considered as a random variable deﬁned on the probability space, (E, B (E) , µ) is
normal. That is, for A ⊆R a Borel set,
λh (A) ≡µ
¡
h−1 (A)
¢

1032
PROBABILITY IN INFINITE DIMENSIONS
is given by
Z
A
1
√
2πσ e−
1
2σ2 (x−m)2dx
for some σ and m. A Gaussian measure is called symmetric if m is always equal
to 0.
Lemma 36.59 Let µ = L (X) where X is a random variable deﬁned on a proba-
bility space, (Ω, F, P) which has values in E, a Banach space. Suppose also that
for all φ ∈E′, φ ◦X is normally distributed. Then µ is a Gaussian measure. Con-
versely, suppose µ is a Gaussian measure on B (E) and X is a random variable
having values in E such that L (X) = µ. Then for every h ∈E′, h ◦X is normally
distributed.
Proof: First suppose µ is a Gaussian measure and X is a random variable such
that L (X) = µ. Then if F is a Borel set in R, and h ∈E′
P
³
(h ◦X)−1 (F)
´
=
P
¡
X−1 ¡
h−1 (F)
¢¢
=
µ
¡
h−1 (F)
¢
=
1
√
2πσ
Z
F
e−|x−m|2
2σ2
dx
for some m and σ2 showing that h ◦X is normally distributed.
Next suppose h ◦X is normally distributed whenever h ∈E′ and L (X) = µ.
Then letting F be a Borel set in R, I need to verify
µ
¡
h−1 (F)
¢
=
1
√
2πσ
Z
F
e−|x−m|2
2σ2
dx.
However, this is easy because
µ
¡
h−1 (F)
¢
=
P
¡
X−1 ¡
h−1 (F)
¢¢
=
P
³
(h ◦X)−1 (F)
´
which is given to equal
1
√
2πσ
Z
F
e−|x−m|2
2σ2
dx
for some m and σ2. This proves the lemma.
Here is another important observation. Suppose X is as just described, a random
variable having values in E such that L (X) = µ and suppose h1, · · ·, hn are each in
E′. Then for scalars, t1, · · ·, tn,
t1h1 ◦X + · · · + tnhn ◦X
=
(t1h1 + · · · + tnhn) ◦X

36.10.
GAUSSIAN MEASURES FOR A SEPARABLE HILBERT SPACE
1033
and this last is assumed to be normally distributed because (t1h1 + · · · + tnhn) ∈
E′. Therefore, by Theorem 36.51
(h1 ◦X, · · ·, hn ◦X)
is distributed as a multivariate normal.
Obviously there exist examples of Gaussian measures deﬁned on E, a Banach
space. Here is why. Let ξ be a random variable deﬁned on a probability space,
(Ω, F, P) which is normally distributed with mean 0 and variance σ2. Then let
X (ω) ≡ξ (ω) e where e ∈E. Then let µ ≡L (X) . For A a Borel set of R and
h ∈E′,
µ ([h (x) ∈A])
≡
P ([X (ω) ∈[x : h (x) ∈A]])
=
P ([h ◦X ∈A]) = P ([ξ (ω) h (e) ∈A])
=
1
|h (e)| σ
√
2π
Z
A
e
−
1
2|h(e)|2σ2 x2
dx
because h (e) ξ is a random variable which has variance |h (e)|2 σ2 and mean 0. Thus
µ is indeed a Gaussian measure. Similarly, one can consider ﬁnite sums of the form
n
X
i=1
ξi (ω) ei
where the ξi are independent normal random variables having mean 0 for conve-
nience. However, this is a rather trivial case. It is much more interesting to consider
the case of inﬁnite sums of random variables.
36.10
Gaussian Measures For A Separable Hilbert
Space
First recall the Kolmogorov extension theorem, Theorem 11.11 on Page 310 which
is stated here for convenience. In this theorem, I is an ordered index set, possibly
inﬁnite, even uncountable.
Theorem 36.60 (Kolmogorov extension theorem) For each ﬁnite set
J = (t1, · · ·, tn) ⊆I,
suppose there exists a Borel probability measure, νJ = νt1···tn deﬁned on the Borel
sets of Q
t∈J Mt where Mt is a locally compact metric space such that if
(t1, · · ·, tn) ⊆(s1, · · ·, sp) ,
then
νt1···tn (Ft1 × · · · × Ftn) = νs1···sp
¡
Gs1 × · · · × Gsp
¢
(36.27)

1034
PROBABILITY IN INFINITE DIMENSIONS
where if si = tj, then Gsi = Ftj and if si is not equal to any of the indices, tk,
then Gsi = Msi. Then there exists a probability space, (Ω, P, F) and measurable
functions, Xt : Ω→Mt for each t ∈I such that for each (t1 · · · tn) ⊆I,
νt1···tn (Ft1 × · · · × Ftn) = P ([Xt1 ∈Ft1] ∩· · · ∩[Xtn ∈Ftn]) .
(36.28)
Lemma 36.61 There exists a sequence, {ξk}∞
k=1 of random variables such that
L (ξk) = N (0, 1)
and {ξk}∞
k=1 is independent.
Proof: Let i1 < i2 · ·· < in be positive integers and deﬁne
µi1···in (F1 × · · · × Fn) ≡
1
¡√
2π
¢n
Z
F1×···×Fn
e−|x|2/2dx.
Then for the index set equal to N the measures satisfy the necessary consistency
condition for the Kolmogorov theorem above. Therefore, there exists a probability
space, (Ω, P, F) and measurable functions, ξk : Ω→R such that
P
¡£
ξi1 ∈Fi1
¤
∩
£
ξi2 ∈Fi2
¤
· · · ∩
£
ξin ∈Fin
¤¢
=
µi1···in (F1 × · · · × Fn)
=
P
¡£
ξi1 ∈Fi1
¤¢
· · · P
¡£
ξin ∈Fin
¤¢
which shows the random variables are independent as well as normal with mean 0
and variance 1. This proves the Lemma.
Now let H be a separable Hilbert space. Consider
∞
X
k=1
λkek ⊗ek
where {ek} is a complete orthonormal set of vectors and
∞
X
k=1
λk < ∞, λk ≥0.
Thus if A = P∞
k=1 λkek ⊗ek, it follows A is a nuclear operator and Aek = λkek.
Now deﬁne for a ∈H,
X (ω) ≡a +
∞
X
k=1
p
λkξk (ω) ek
(36.29)
Claim: The series converges a.e. and in L2 (Ω) .
Proof of claim: Let Xn (ω) ≡a + Pn
k=1
√λkξk (ω) ek. Then
Xn (ω) = a +
n
X
k=1
p
λkξk (ω) ek

36.10.
GAUSSIAN MEASURES FOR A SEPARABLE HILBERT SPACE
1035
≡a + Yn (ω) .
(36.30)
For n > m,
|Yn (ω) −Ym (ω)|2
H =
n
X
k=m
λkξk (ω)2
(36.31)
and
Z
Ω
∞
X
k=1
λkξk (ω)2 dP =
∞
X
k=1
λk < ∞
and so for a.e. ω, 36.31 shows {Yn (ω)} is a Cauchy sequence in H and therefore,
converges.
The series also converges in L2 (Ω; H) because
Z
Ω


n
X
k=m
p
λkξk (ω) ek,
n
X
j=m
p
λjξj (ω) ej

dP
=
Z
Ω
n
X
k=m
λk |ξk (ω)|2 dP =
n
X
k=m
λk ≤
∞
X
k=m
λk
which by assumption converges to 0 as m →∞. Thus the partial sums form a
Cauchy sequence in L2 (Ω; H) . This proves the claim.
Letting
(h, X (ω))n ≡(h, a) +
n
X
k=1
p
λkξk (ω) (h, ek)
it follows
(h, X (ω))n →(h, X (ω)) a.e.
and an application of the dominated convergence theorem, shows that since the ξk
are normal and independent, it follows from Theorem 36.50 and the description of
the characteristic function of a normally distributed random variable,
E
³
eit(h,X)´
=
lim
n→∞E
³
eit(h,X)n
´
=
lim
n→∞eit(h,a)e−t2 Pn
k=1 λk(h,ek)2
=
eit(h,a)e−t2 P∞
k=1 λk(h,ek)2
and this is the characteristic function for a random variable with mean (h, a) and
variance P∞
k=1 λk (h, ek)2 , this last series converging because
M
X
k=1
λk (h, ek)2 ≤C
∞
X
k=1
(h, ek)2 = C |h|2 .
Thus for every h ∈H′, h ◦X is normally distributed. Therefore, Lemma 36.59
implies the following theorem.
Theorem 36.62 Let X (ω) be given by 36.29 as described above.
Then letting
µ ≡L (X) , it follows µ is a Gaussian measure on the separable Hilbert space, H.

1036
PROBABILITY IN INFINITE DIMENSIONS
36.11
Abstract Wiener Spaces
This material follows [11], [30] and [25]. More can be found on this subject in these
references. Here H will be a separable Hilbert space.
Deﬁnition 36.63 Cylinder sets in H are of the form
{x ∈H : ((x, e1) , · · ·, (x, en)) ∈F}
where F ∈B (Rn) , the Borel sets of Rn and {ek} are orthonormal. Denote this
collection of cylinder sets as C.
Lemma 36.64 σ (C) , the smallest σ algebra containing C, contains the Borel sets
of H, B (H).
Proof: It follows from the deﬁnition of these cylinder sets that if fi (x) ≡(x, ei) ,
so that fi ∈H′, then with respect to σ (C) , each fi is measurable. It follows that
every linear combination of the fi is also measurable with respect to σ (C). However,
this set of linear combinations is dense in H′ and so the conclusion of the lemma
follows from Lemma 36.9 on Page 993. This proves the lemma.
Deﬁnition 36.65 Deﬁne ν on the cylinder sets, C by the following rule. For {ek}
a complete orthonormal set in H,
ν ({x ∈H : ((x, e1) , · · ·, (x, en)) ∈F})
≡
1
(2π)n/2
Z
F
e−|x|2/2dx.
Lemma 36.66 The above deﬁnition is well deﬁned.
Proof: Let {fk} be another orthonormal set such that
{x ∈H : ((x, e1) , · · ·, (x, en)) ∈F}
=
{x ∈H : ((x, f1) , · · ·, (x, fn)) ∈G}
Then it needs to be the case that ν gives the same result for the two equal cylinder
sets. Let
L =
X
i
ei ⊗fi.
Thus Lfi = ei and L maps H one to one and onto and preserves norms and
L∗=
X
i
fi ⊗ei
and maps ei to fi and has the same properties of being one to one and onto H and
preserving norms.
Let
x ∈{x ∈H : ((x, e1) , · · ·, (x, en)) ∈F} ≡A.

36.11.
ABSTRACT WIENER SPACES
1037
Then by deﬁnition,
((x, e1) , · · ·, (x, en)) ∈F
and so
((x, Lf1) , · · ·, (x, Lfn)) ∈F
which implies
((L∗x, f1) , · · ·, (L∗x, fn)) ∈F
Thus, since L, L∗are one to one and onto,
A
=
{x ∈H : ((x, e1) , · · ·, (x, en)) ∈F}
=
{x ∈H : ((L∗x, f1) , · · ·, (L∗x, fn)) ∈F}
=
{x ∈LH : ((L∗x, f1) , · · ·, (L∗x, fn)) ∈F}
=
{L∗x ∈H : ((L∗x, f1) , · · ·, (L∗x, fn)) ∈F}
=
{y ∈H : ((y, f1) , · · ·, (y, fn)) ∈F}
=
{x ∈H : ((x, f1) , · · ·, (x, fn)) ∈G}
If α ∈F, then there exists y ∈H such that
((y, f1) , · · ·, (y, fn)) ∈F
and this y must be in the set,
{x ∈H : ((x, f1) , · · ·, (x, fn)) ∈G}
which shows
((y, f1) , · · ·, (y, fn)) ∈G.
Hence F ⊆G. Similarly, G ⊆F and ν is well deﬁned. This proves the lemma.
It would be natural to try to extend ν to the σ algebra determined by C and
obtain a measure deﬁned on this σ algebra. However, this is always impossible if
the Hilbert space, H is inﬁnite dimensional.
Proposition 36.67 ν cannot be extended to a measure deﬁned on σ (C) whenever
H is inﬁnite dimensional.
Proof: Let {en} be a complete orthonormal set of vectors in H. Then ﬁrst note
that H is a cylinder set.
H = {x ∈H : (x, e1) ∈R}
and so
ν (H) =
1
√
2π
Z
R
e−x2/2dx = 1.
However, H is also equal to the countable union of the sets,
An ≡{x ∈H : ((x, e1)H , · · ·, (x, ean)H) ∈B (0, n)}

1038
PROBABILITY IN INFINITE DIMENSIONS
where an →∞.
ν (An)
≡
1
¡√
2π
¢an
Z
B(0,n)
e−|x|2/2dx
≤
1
¡√
2π
¢an
Z n
−n
· · ·
Z n
−n
e−|x|2/2dx1 · · · dxan
=
ÃR n
−n e−x2/2dx
√
2π
!an
Now pick an so large that the above is smaller than 1/2n+1. This can be done
because for no matter what choice of n,
R n
−n e−x2/2dx
√
2π
< 1.
Then
∞
X
n=1
ν (An) ≤
∞
X
n=1
1
2n+1 = 1
2.
This proves the proposition and shows something else must be done to get a measure
from ν.
Deﬁnition 36.68 Let H be a separable Hilbert space and let ||·|| be a norm deﬁned
on H which has the following property. Whenever {en} is an orthonormal sequence
of vectors in H and F ({en}) consists of the set of all orthogonal projections onto
the span of ﬁnitely many of the ek the following condition holds. For every ε > 0
there exists Pε ∈F ({en}) such that if P ∈F ({en}) and PPε = 0, then
ν ({x ∈H : ||Px|| > ε}) < ε.
Then ||·|| is called Gross measurable.
The following lemma is a fundamental result about Gross measurable norms.
It is about the continuity of ||·|| . It is obvious that with respect to the topology
determined by ||·|| that x →||x|| is continuous. However, it would be interesting if
this were the case with respect to the topology determined by the norm on H, |·| .
This lemma shows this is the case and so the funny condition above implies x →||x||
is a continuous, hence Borel measurable function.
Lemma 36.69 Let ||·|| be Gross measurable. Then there exists c > 0 such that
||x|| ≤c |x|
for all x ∈H. Furthermore, the above deﬁnition is well deﬁned.

36.11.
ABSTRACT WIENER SPACES
1039
Proof: First it is important to consider the question whether the above deﬁ-
nition is well deﬁned. To do this note that on PH, the two norms are equivalent
because PH is a ﬁnite dimensional space. Let G = {y ∈PH : ||y|| > ε} so G is an
open set in PH. Then
{x ∈H : ||Px|| > ε}
equals
{x ∈H : Px ∈G}
which equals a set of the form
{x ∈H : ((x, ei1)H , · · ·, (x, eim)H) ∈G′}
for G′ an open set in Rm and so everything makes sense in the above deﬁnition.
Now it is necessary to verify ||·|| ≤c |·|. If it is not so, there exists e1 such that
||e1|| ≥1, |e1| = 1.
Suppose {ek}n
k=1 have been chosen such that each is a unit vector in H and ||ek|| ≥k.
Then considering span (e1, · · ·, en)⊥if for every x ∈span (e1, · · ·, en)⊥, ||x|| ≤c |x| ,
then if z ∈H is arbitrary, z = x+y where y ∈span (e1, · · ·, en) and so since the two
norms are equivalent on a ﬁnite dimensional subspace, there exists c′ corresponding
to span (e1, · · ·, en) such that
||z||2
≤
(||x|| + ||y||)2 ≤2 ||x||2 + 2 ||y||2
≤
2c2 |x|2 + 2c′ |y|2
≤
¡
2c2 + 2c′2¢ ³
|x|2 + |y|2´
=
¡
2c2 + 2c′2¢
|z|2
and the lemma is proved. Therefore it can be assumed, there exists
en+1 ∈span (e1, · · ·, en)⊥
such that |en+1| = 1 and ||en+1|| ≥n + 1.
This constructs an orthonormal set of vectors, {ek} . Letting 0 < ε <
1
2, it
follows since ||·|| is measurable, there exists Pε ∈F ({en}) such that if PPε = 0
where P ∈F ({en}) , then
ν ({x ∈H : ||Px|| > ε}) < ε.
Say Pε is the projection onto the span of ﬁnitely many of the ek, the last one being
eN. Then for n > N and Pn the projection onto en, it follows PεPn = 0 and from
the deﬁnition of ν,
ε
>
ν ({x ∈H : ||Pnx|| > ε})
=
ν ({x ∈H : |(x, en)| ||en+1|| > ε})
=
ν ({x ∈H : |(x, en)| > ε/ ||en+1||})
≥
ν ({x ∈H : |(x, en)| > ε/ (n + 1)})
>
1
√
2π
Z ∞
ε/(n+1)
e−x2/2dx

1040
PROBABILITY IN INFINITE DIMENSIONS
which yields a contradiction for all n large enough. This proves the lemma.
What are examples of Gross measurable norms deﬁned on a separable Hilbert
space, H? The following lemma gives an important example.
Lemma 36.70 Let H be a separable Hilbert space and let A ∈L2 (H, H) , a Hilbert
Schmidt operator. Thus A is a continuous linear operator with the property that for
any orthonormal set, {ek} ,
∞
X
k=1
|Aek|2 < ∞.
Then deﬁne ||·|| by
||x|| ≡|Ax|H .
Then if ||·|| is a norm, it is measurable1.
Proof: Let {ek} be an orthonormal sequence. Let Pn denote the orthogonal
projection onto span (e1, · · ·, en) . Let ε > 0 be given. Since A is a Hilbert Schmidt
operator, there exists N such that
∞
X
k=N
|Aek|2 < α
where α is chosen very small. In fact, α is chosen such that α < ε2/r2 where r is
suﬃciently large that
2
√
2π
Z ∞
r
e−t2/2dt < ε.
(36.32)
Let P denote an orthogonal projection in F ({ek}) such that PPN = 0. Thus P is
the projection on to span (ei1, · · ·, eim) where each ik > N. Then
ν ({x ∈H : ||Px|| > ε})
=
ν ({x ∈H : |APx| > ε})
Now Px = Pm
j=1
¡
x, eij
¢
eij and the above reduces to
ν




x ∈H :
¯¯¯¯¯¯
m
X
j=1
¡
x, eij
¢
Aeij
¯¯¯¯¯¯
> ε




≤
1If it is only a seminorm, it satisﬁes the same conditions.

36.11.
ABSTRACT WIENER SPACES
1041
ν








x ∈H :


m
X
j=1
¯¯¡
x, eij
¢¯¯2


1/2 

m
X
j=1
¯¯Aeij
¯¯2


1/2
> ε








≤
ν








x ∈H :


m
X
j=1
¯¯¡
x, eij
¢¯¯2


1/2
α1/2 > ε








=
ν








x ∈H :


m
X
j=1
¯¯¡
x, eij
¢¯¯2


1/2
>
ε
α1/2








=
ν
µ½
x ∈H : ((x, ei1) , · · ·, (x, eim)) ∈B
³
0,
ε
α1/2
´C¾¶
≤
ν
µ½
x ∈H : max
©¯¯¡
x, eij
¢¯¯ª
>
ε
√mα1/2
¾¶
This is no larger than
1
¡√
2π
¢m
Z
|t1|>
ε
√m√α
Z
|t2|>
ε
√m√α
· · ·
Z
|tm|>
ε
√m√α
e−|t|2/2dtm · · · dt1
=


2
R ∞
ε/(
√mα1/2) e−t2/2dt
√
2π


m
which by Jensen’s inequality is no larger than
2
R ∞
ε/(
√mα1/2) e−mt2/2dt
√
2π
=
2
1
√m
R ∞
ε/(α1/2) e−t2/2dt
√
2π
≤
2
R ∞
ε/(ε/r) e−t2/2dt
√
2π
=
2
R ∞
r
e−t2/2dt
√
2π
< ε
By 36.32. This proves the lemma.
Deﬁnition 36.71 A triple, (i, H, B) is called an abstract Wiener space if B is a
separable Banach space and H is a separable Hilbert space such that H is dense and
continuously embedded in B and the norm ||·|| on B is Gross measurable.
Next consider a weaker norm for H which comes from the inner product
(x, y)E ≡
∞
X
k=1
1
k2 (x, ek)H (y, ek)H .

1042
PROBABILITY IN INFINITE DIMENSIONS
Then let E be the completion of H with respect to this new norm. Thus {kek}
is a complete orthonormal basis for E. This follows from the density of H in E
along with the obvious observation that in the above inner product, {kek} is an
orthonormal set of vectors.
Lemma 36.72 There exists a countably additive Gaussian measure, λ deﬁned on
B (E). This measure is the law of the random variable,
X (ω) ≡
∞
X
k=1
ξk (ω) ek,
where {ξk} denotes a sequence of independent normally distributed random variables
having mean 0 and variance 1, the series converging pointwise a.e. in E. Also
k2 (X (ω) , ek)E = ξk (ω) a.e.
Proof: Observe that P∞
k=1
1
k2 (kek)⊗(kek) is a nuclear operator on the Hilbert
space, E. Letting {ξk} be a sequence of independent random variables each normally
distributed with mean 0 and variance 1, it follows as in Theorem 36.62 that
X (ω) ≡
∞
X
k=1
1
k ξk (ω) kek =
∞
X
k=1
ξk (ω) ek
(36.33)
is a random variable with values in E and L (X) is a Gaussian measure on B (E) ,
the series converging pointwise a.e.
in E.
Let λ be the name of this Gaussian
measure and denote the probability space on which the ξk are deﬁned as (Ω, F, P).
Thus for F ∈B (E) ,
λ (F) ≡P ({ω ∈Ω: X (ω) ∈F})
Finally, denoting by XN, the partial sum,
XN (ω) ≡
N
X
k=1
ξk (ω) ek,
the deﬁnition of (·, ·)E on H and a simple computation yields
ξk (ω)
=
lim
N→∞k2 (XN (ω) , ek)E
=
k2 (X (ω) , ek)E .
(36.34)
One can pass to the limit because XN (ω) converges to X (ω) in E. This proves the
lemma.
Theorem 36.73 Let (i, H, B) be an abstract Wiener space. Then there exists a
Gaussian measure on the Borel sets of B.

36.11.
ABSTRACT WIENER SPACES
1043
Proof: Let E be deﬁned above as the completion of H with respect to that
weaker norm. Then from Lemma 36.72 and X (ω) given above in 36.33,
k2 (X (ω) , ek)E = ξk (ω) a.e. ω.
Let {en} be a complete orthonormal set for H.
There exists an increasing
sequence of projections, {Qn} ⊆F ({en}) such that Qnx →x in H for each x ∈
H. Say Qn is the orthogonal projection onto span (e1, · · ·, epn) . Then since ||·|| is
measurable, these can be chosen such that if Q is the orthogonal projection onto
span (e1, · · ·, ek) for some k > pn then
ν
¡©
x : ||Qx −Qnx|| > 2−nª¢
< 2−n.
In particular,
ν
¡©
x : ||Qnx −Qmx|| > 2−mª¢
< 2−m
whenever n ≥m.
I would like to consider the inﬁnite series,
S (ω) ≡
∞
X
k=1
k2 (X (ω) , ek)E ek ∈B.
converging in B but of course this might make no sense because the series might
not converge. It was shown above that the series converges in E but it has not been
shown to converge in B.
Suppose the series did converge a.e. Then let f ∈B′ and consider the random
variable f ◦S which maps Ωto R. I would like to verify this is normally distributed.
First note that the following ﬁnite sum is weakly measurable and separably valued
so it is strongly measurable with values in B.
Spn (ω) ≡
pn
X
k=1
k2 (X (ω) , ek)E ek,
Since f ∈B′ which is a subset of H′ due to the assumption that H is dense in B,
there exists a unique v ∈H such that f (x) = (x, v) for all x ∈H. Then from the
above sum,
f (Spn (ω)) = (Spn (ω) , v) =
pn
X
k=1
k2 (X (ω) , ek)E (ek, v)
which by Lemma 36.72 equals
pn
X
k=1
(ek, v)H ξk (ω)
a ﬁnite linear combination of the independent N (0, 1) random variables, ξk (ω) .
Then it follows
ω →f (Spn (ω))

1044
PROBABILITY IN INFINITE DIMENSIONS
is also normally distributed and has mean 0 and variance equal to
pn
X
k=1
(ek, v)2
H .
Then it seems reasonable to suppose
E
¡
eitf◦S¢
=
lim
n→∞E
¡
eitf◦Spn¢
=
lim
n→∞e−t2 Ppn
k=1(ek,v)2
H
=
e−t2 P∞
k=1(ek,v)2
H
=
e−t2|v|2
H
(36.35)
the characteristic function of a random variable which is N
³
0, |v|2
H
´
. Thus at least
formally, this would imply for all f ∈B′, f ◦S is normally distributed and so if
µ = L (S) , then by Lemma 36.59 it follows µ is a Gaussian measure.
What is missing to make the above a proof? First of all, there is the issue of the
sum. Next there is the problem of passing to the limit in the little argument above
in which the characteristic function is used.
First consider the the sum. Note that QnX (ω) ∈H. Then for any n > pm,
P
¡©
ω ∈Ω: ||Sn (ω) −Spm (ω)|| > 2−mª¢
=
P




ω ∈Ω:
¯¯¯¯¯¯
¯¯¯¯¯¯
n
X
k=pm+1
k2 (X (ω) , ek)E ek
¯¯¯¯¯¯
¯¯¯¯¯¯
> 2−m





=
P




ω ∈Ω:
¯¯¯¯¯¯
¯¯¯¯¯¯
n
X
k=pm+1
ξk (ω) ek
¯¯¯¯¯¯
¯¯¯¯¯¯
> 2−m





(36.36)
Let Q be the orthogonal projection onto span (e1, · · ·, en) . Deﬁne
F ≡
©
x ∈(Q −Qm) H : ||x|| > 2−mª
Then continuing the chain of equalities ending with 36.36,
= P




ω ∈Ω:
n
X
k=pm+1
ξk (ω) ek ∈F





=
P
¡©
ω ∈Ω:
¡
ξn (ω) , · · ·, ξpm+1 (ω)
¢
∈F ′ª¢
=
ν
¡©
x ∈H :
¡
(x, en)H , · · ·, (x, epm+1)H
¢
∈F ′ª¢
=
ν ({x ∈H : Q (x) −Qm (x) ∈F})
=
ν
¡©
x ∈H : ||Q (x) −Qm (x)|| > 2−mª¢
< 2−m.

36.11.
ABSTRACT WIENER SPACES
1045
This has shown that
P
¡©
ω ∈Ω: ||Sn (ω) −Spm (ω)|| > 2−mª¢
< 2−m
(36.37)
for all n > pm. In particular, the above is true if n = pn for n > m.
If {Spn (ω)} fails to converge, then ω must be contained in the set,
A ≡∩∞
m=1 ∪∞
n=m
©
ω ∈Ω: ||Spn (ω) −Spm (ω)|| > 2−mª
(36.38)
because if ω is in the complement of this set,
∪∞
m=1 ∩∞
n=m
©
ω ∈Ω: ||Spn (ω) −Spm (ω)|| ≤2−mª
,
it follows {Spn (ω)}∞
n=1 is a Cauchy sequence and so it must converge. However, the
set in 36.38 is a set of measure 0 because of 36.37 and the observation that for all
m,
P (A)
≤
∞
X
n=m
P
¡©
ω ∈Ω: ||Spn (ω) −Spm (ω)|| > 2−mª¢
≤
∞
X
n=m
1
2m
Thus the subsequence {Spn} of the sequence of partial sums of the above series
does converge pointwise in B and so the dominated convergence theorem also veriﬁes
that the computations involving the characteristic function in 36.35 are correct.
The random variable obtained as the limit of the partial sums, {Spn (ω)} de-
scribed above is strongly measurable because each Spn (ω) is strongly measurable
due to each of these being weakly measurable and separably valued.
Thus the
measure given as the law of S deﬁned as
S (ω) ≡lim
n→∞Spn (ω)
is deﬁned on the Borel sets of B.This proves the theorem.
Also, there is an important observation from the proof which I will state as the
following corollary.
Corollary 36.74 Let (i, H, B) be an abstract Wiener space. Then there exists a
Gaussian measure on the Borel sets of B.
This Gaussian measure equals L (S)
where S (ω) is the a.e. limit of a subsequence of the sequence of partial sums,
Spn (ω) ≡
pn
X
k=1
ξk (ω) ek
for {ξk} a sequence of independent random variables which are normal with mean
0 and variance 1 which are deﬁned on a probability space, (Ω, F, P). Furthermore,
for any k > pn,
P
¡©
ω ∈Ω: ||Sk (ω) −Spn (ω)|| > 2−nª¢
< 2−n.

1046
PROBABILITY IN INFINITE DIMENSIONS
36.12
White Noise
In an abstract Wiener space as discussed above there is a Gaussian measure, µ
deﬁned on the Borel sets of B. This measure is the law of a random variable having
values in B which is the limit of a subsequence of a sequence of partial sums. I will
show here that the sequence of partial sums also converges pointwise a.e.
First is a simple deﬁnition and lemma about random variables whose distribution
is symmetric.
Deﬁnition 36.75 Let X be a random variable deﬁned on a probability space, (Ω, F, P)
having values in a Banach space, E. Then it has a symmetric distribution if when-
ever A is a Borel set,
P ([X ∈A]) = P ([X ∈−A])
In terms of the distribution,
λX = λ−X.
It is good to observe that if X, Y are independent random variables deﬁned on a
probability space, (Ω, F, P) such that each has symmetric distribution, then X +Y
also has symmetric distribution. Here is why. Let A be a Borel set in E. Then by
Theorem 36.47 on Page 1023,
λX+Y (A)
=
Z
E
λX (A −z) dλY (z)
=
Z
E
λ−X (A −z) dλ−Y (z)
=
λ−(X+Y ) (A)
By induction, it follows that if you have n independent random variables each having
symmetric distribution, then their sum has symmetric distribution.
Here is a simple lemma about random variables having symmetric distributions.
It will depend on Lemma 36.57 on Page 1029.
Lemma 36.76 Let X ≡(X1, · · ·, Xn) and Y be random variables deﬁned on a
probability space, (Ω, F, P) such that Xi, i = 1, 2, ···, n and Y have values in E a sep-
arable Banach space. Thus X has values in En. Suppose also that {X1, · · ·, Xn, Y }
are independent and that Y has symmetric distribution.
Then if A ∈B (En) , it
follows
P
Ã
[X ∈A] ∩
"¯¯¯¯¯
¯¯¯¯¯
n
X
i=1
Xi + Y
¯¯¯¯¯
¯¯¯¯¯ < r
#!
=
P
Ã
[X ∈A] ∩
"¯¯¯¯¯
¯¯¯¯¯
n
X
i=1
Xi −Y
¯¯¯¯¯
¯¯¯¯¯ < r
#!
You can also change the inequalities in the obvious way, < to ≤, > to ≥.

36.12.
WHITE NOISE
1047
Proof: Denote by λX and λY the distribution measures for X and Y respec-
tively. Since the random variables are independent, the distribution for the random
variable, (X, Y ) mapping into En+1 is λX×λY where this denotes product measure.
Since the Banach space is separable, the Borel sets are contained in the product
measurable sets. Then by symmetry of the distribution of Y
P
Ã
[X ∈A] ∩
"¯¯¯¯¯
¯¯¯¯¯
n
X
i=1
Xi + Y
¯¯¯¯¯
¯¯¯¯¯ < r
#!
=
Z
En×E
XA (x) XB(0,r)
Ã n
X
i=1
xi + y
!
d (λX × λY ) (x,y)
=
Z
E
Z
En XA (x) XB(0,r)
Ã n
X
i=1
xi + y
!
dλXdλY
=
Z
E
Z
En XA (x) XB(0,r)
Ã n
X
i=1
xi + y
!
dλXdλ−Y
=
Z
En×E
XA (x) XB(0,r)
Ã n
X
i=1
xi + y
!
d (λX × λ−Y ) (x,y)
=
P
Ã
[X ∈A] ∩
"¯¯¯¯¯
¯¯¯¯¯
n
X
i=1
Xi + (−Y )
¯¯¯¯¯
¯¯¯¯¯ < r
#!
This proves the lemma. Other cases are similar.
Now here is a really interesting lemma.
Lemma 36.77 Let E be a real separable Banach space. Assume ξ1, · · ·, ξN are
independent random variables having values in E, a separable Banach space which
have symmetric distributions. Also let Sk = Pk
i=1 ξi. Then for any r > 0,
P
µ·
sup
k≤N
||Sk|| > r
¸¶
≤2P ([||SN|| > r]) .
Proof: First of all,
P
µ·
sup
k≤N
||Sk|| > r
¸¶
=
P
µ·
sup
k≤N
||Sk|| > r and ||SN|| > r
¸¶
+P
µ·
sup
k≤N−1
||Sk|| > r and ||SN|| ≤r
¸¶
≤
P ([||SN|| > r]) + P
µ·
sup
k≤N−1
||Sk|| > r and ||SN|| ≤r
¸¶
.
(36.39)
I need to estimate the second of these terms. Let
A1 ≡[||S1|| > r] , · · ·, Ak ≡[||Sk|| > r, ||Sj|| ≤r for j < k] .

1048
PROBABILITY IN INFINITE DIMENSIONS
Thus Ak consists of those ω where ||Sk (ω)|| > r for the ﬁrst time at k. Thus
·
sup
k≤N−1
||Sk|| > r and ||SN|| ≤r
¸
= ∪N−1
j=1 Aj ∩[||SN|| ≤r]
and the sets in the above union are disjoint. Consider Aj ∩[||SN|| ≤r] . For ω in
this set,
||Sj (ω)|| > r, ||Si (ω)|| ≤r if i < j.
Since ||SN (ω)|| ≤r in this set, it follows
¯¯¯¯¯¯
¯¯¯¯¯¯
Sj (ω) +
N
X
i=j+1
ξi (ω)
¯¯¯¯¯¯
¯¯¯¯¯¯
≤r
and so from the symmetry of the distributions and Lemma 36.76 the following
computation is valid.
P (Aj ∩[||SN|| ≤r])
(36.40)
= P

∩j−1
i=1 [||Si|| ≤r] ∩[||Sj|| > r] ∩


¯¯¯¯¯¯
¯¯¯¯¯¯
Sj +
N
X
i=j+1
ξi
¯¯¯¯¯¯
¯¯¯¯¯¯
≤r




(36.41)
Now ∩j−1
i=1 [||Si|| ≤r] ∩[||Sj|| > r] is of the form
£¡
ξ1, · · ·, ξj
¢
∈A
¤
for some Borel set, A. Then letting Y = PN
i=j+1 ξi in Lemma 36.76 and Xi = ξi,
36.41 equals
P

∩j−1
i=1 [||Si|| ≤r] ∩[||Sj|| > r] ∩


¯¯¯¯¯¯
¯¯¯¯¯¯
Sj −
N
X
i=j+1
ξi
¯¯¯¯¯¯
¯¯¯¯¯¯
≤r




=
P
³
∩j−1
i=1 [||Si|| ≤r] ∩[||Sj|| > r] ∩[||Sj −(SN −Sj)|| ≤r]
´
=
P
³
∩j−1
i=1 [||Si|| ≤r] ∩[||Sj|| > r] ∩[||2Sj −SN|| ≤r]
´
Now since ||Sj (ω)|| > r,
[||2Sj −SN|| ≤r]
⊆
[2 ||Sj|| −||SN|| ≤r]
⊆
[2r −||SN|| < r]
=
[||SN|| > r]
and so, referring to 36.40, this has shown
P (Aj ∩[||SN|| ≤r])

36.12.
WHITE NOISE
1049
=
P
³
∩j−1
i=1 [||Si|| ≤r] ∩[||Sj|| > r] ∩[||2Sj (ω) −SN (ω)|| ≤r]
´
≤
P
³
∩j−1
i=1 [||Si|| ≤r] ∩[||Sj|| > r] ∩[||SN (ω)|| > r]
´
=
P (Aj ∩[||SN (ω)|| > r]) .
It follows that
P
µ·
sup
k≤N−1
||Sk|| > r and ||SN|| ≤r
¸¶
=
N−1
X
i=1
P (Aj ∩[||SN|| ≤r])
≤
N−1
X
i=1
P (Aj ∩[||SN|| > r])
≤
P ([||SN|| > r])
and using 36.39, this proves the lemma.
This interesting lemma will now be used to prove the following which concludes
a sequence of partial sums converges given a subsequence of the sequence of partial
sums converges.
Lemma 36.78 Let {ζk} be a sequence of random variables having values in a
separable real Banach space, E whose distributions are symmetric. Letting Sk ≡
Pk
i=1 ζi, suppose {Snk} converges a.e. Also suppose that for every m > nk,
P
¡£
||Sm −Snk||E > 2−k¤¢
< 2−k.
(36.42)
Then in fact,
Sk (ω) →S (ω) a.e.ω
(36.43)
Proof: Let nk ≤l ≤m. Then by Lemma 36.77
P
µ·
sup
nk<l≤m
||Sl −Snk|| > 2−k
¸¶
≤2P
¡£
||Sm −Snk|| > 2−k¤¢
In using this lemma, you could renumber the ζi so that the sum
l
X
j=nk+1
ζj
corresponds to
l−nk
X
j=1
ξj
where ξj = ζj+nk. Then using 36.42,
P
µ·
sup
nk<l≤m
||Sl −Snk|| > 2−k
¸¶
≤2P
¡£
||Sm −Snk|| > 2−k¤¢
< 2−(k−1)

1050
PROBABILITY IN INFINITE DIMENSIONS
If Sl (ω) fails to converge then ω must be in inﬁnitely many of the sets,
·
sup
nk<l
||Sl −Snk|| > 2−k
¸
each of which has measure no more than 2−(k−1).
Thus ω must be in a set of
measure zero. This proves the lemma.
Now with this preparation, here is the theorem about white noise.
Theorem 36.79 Let (i, H, B) be an abstract Wiener space. Then there exists a
Gaussian measure on the Borel sets of B.
This Gaussian measure equals L (S)
where S (ω) is the a.e. limit of the sequence of partial sums,
Sn (ω) ≡
n
X
k=1
ξk (ω) ek
for {ξk} a sequence of independent random variables which are normal with mean
0 and variance 1 which are deﬁned on a probability space, (Ω, F, P) and {ek} is a
complete orthonormal sequence in H.
Proof: By Corollary 36.74 there is a subsequence, {Spn} of these partial sums
which converge pointwise a.e. to S (ω). However, this corollary also states that
P
¡©
ω ∈Ω: ||Sk (ω) −Spn (ω)|| > 2−nª¢
< 2−n
whenever k > pn and so by Lemma 36.78 the original sequence of partial sums
also converges a.e. The reason this lemma applies is that ξk (ω) ek has symmetric
distribution. This proves the corollary.
36.13
Existence Of Abstract Wiener Spaces
It turns out that if E is a separable Banach space, then it is the top third of an
abstract Wiener space. This is what will be shown in this section. Therefore, it
follows from the above that there exists a Gaussian measure on E which is the law
of an a.e. convergent series as discussed above. First here is a little lemma which
is interesting for its own sake.
Lemma 36.80 Let E be a separable Banach space. Then there exists an increasing
sequence of subspaces, {Fn} such that dim (Fn+1) −dim (Fn) ≤1 and equals 1 for
all n if the dimension of E is inﬁnite. Also ∪∞
n=1Fn is dense in E.
Proof: Since E is separable, so is ∂B (0, 1) , the boundary of the unit ball. Let
{wk}∞
k=1 be a countable dense subset of ∂B (0, 1).
Let z1 = w1. Let F1 = Fz1. Suppose Fn has been obtained and equals span (z1, · · ·, zn)
where {z1, · · ·, zn} is independent, ||zk|| = 1, and if n ̸= m,
||zm −zn|| ≥1
2.

36.13.
EXISTENCE OF ABSTRACT WIENER SPACES
1051
Claim:
Fn is closed. Let
yk ≡
n
X
j=1
ck
j zj
(36.44)
be such that yk →y. I need to verify y ∈Fn. Let ck =
¡
ck
1, · · ·, ck
n
¢
. Suppose ﬁrst
{ck} is unbounded in Fn. Then taking a subsequence, still denoted by ck, it can be
assumed |ck| →∞. Therefore,
0 = lim
k→∞
yk
|ck| = lim
k→∞
n
X
j=1
ck
j
|ck|zj.
(36.45)
Then taking another subsequence it can also be assumed that
ck
|ck| →c, |c| = 1.
but then 36.45 implies
0 =
n
X
j=1
cjzj
and this is a contradiction since the zj are independent.
Thus it must be the case that {ck} is bounded in Fn. But now, taking a suitable
subsequence such that ck →c, it follows from 36.44 that
y ≡
n
X
j=1
cjzj
so y ∈Fn. This shows Fn is closed and this proves the claim.
If Fn contains {wk} , let Fm = Fn for all m > n. Otherwise, pick w ∈{wk} to
be the point of {wk} having the smallest subscript which is not contained in Fn.
Then w is at a positive distance, λ from Fn because Fn is closed. Therefore, there
exists y ∈Fn such that λ ≤||y −w|| ≤2λ. Let zn+1 =
w−y
||w−y||. It follows
w = ||w −y|| zn+1 + y ∈span (z1, · · ·, zn+1) ≡Fn+1
Then if m < n + 1,
||zn+1 −zm||
=
¯¯¯¯
¯¯¯¯
w −y
||w −y|| −zm
¯¯¯¯
¯¯¯¯
=
¯¯¯¯
¯¯¯¯
w −y
||w −y|| −||w −y|| zm
||w −y||
¯¯¯¯
¯¯¯¯
≥
1
2λ ||w −y −||w −y|| zm||
≥
λ
2λ = 1
2.

1052
PROBABILITY IN INFINITE DIMENSIONS
This has shown the existence of an increasing sequence of subspaces, {Fn} as de-
scribed above. It remains to show the union of these subspaces is dense. First note
that the union of these subspaces must contain the {wk} because if wm is miss-
ing, then it would contradict the construction at the mth step. That one should
have been chosen. However, {wk} is dense in ∂B (0, 1). If x ∈E and x ̸= 0, then
x
||x|| ∈∂B (0, 1) then there exists
wm ∈{wk} ⊆∪∞
n=1Fn
such that
¯¯¯
¯¯¯wm −
x
||x||
¯¯¯
¯¯¯ <
ε
||x||. But then
||||x|| wm −x|| < ε
and so ||x|| wm is a point of ∪∞
n=1Fn which is within ε of x. This proves ∪∞
n=1Fn is
dense as desired. This proves the lemma.
Lemma 36.81 Let E be a separable Banach space. Then there exists a sequence
{en} of points of E such that whenever |β| ≤1 for β ∈Fn,
n
X
k=1
βkek ∈B (0, 1)
the unit ball in E.
Proof: By Lemma 36.80, let {z1, · · ·, zn} be a basis for Fn where ∪∞
n=1Fn is
dense in E. Then let α1 be such that e1 ≡α1z1 ∈B (0, 1) . Thus |β1e1| ∈B (0, 1)
whenever |β1| ≤1. Suppose αi has been chosen for i = 1, 2, · · ·, n such that for all
β ∈Dn ≡{α ∈Fn : |α| ≤1} , it follows
n
X
k=1
βkαkzk ∈B (0, 1) .
Then
Cn ≡
( n
X
k=1
βkαkzk : β ∈Dn
)
is a compact subset of B (0, 1) and so it is at a positive distance from the complement
of B (0, 1) , δ. Now let 0 < αn+1 < δ/ ||zn+1|| . Then for β ∈Dn+1,
n
X
k=1
βkαkzk ∈Cn
and so
¯¯¯¯¯
¯¯¯¯¯
n+1
X
k=1
βkαkzk −
n
X
k=1
βkαkzk
¯¯¯¯¯
¯¯¯¯¯
=
¯¯¯¯βn+1αn+1zn+1
¯¯¯¯
<
||αn+1zn+1|| < δ

36.13.
EXISTENCE OF ABSTRACT WIENER SPACES
1053
which shows
n+1
X
k=1
βkαkzk ∈B (0, 1) .
This proves the lemma. Let ek ≡αkzk.
Now the main result is the following. It says that any separable Banach space
is the upper third of some abstract Wiener space.
Theorem 36.82 Let E be a real separable Banach space with norm ||·||. Then there
exists a separable Hilbert space, H such that H is dense in E and the inclusion map
is continuous. Furthermore, if ν is the Gaussian measure deﬁned earlier on the
cylinder sets of H, ||·|| is Gross measurable.
Proof: Let {ek} be the points of E described in Lemma 36.81. Then let H0
denote the subspace of all ﬁnite linear combinations of the {ek}. It follows H0 is
dense in E. Next decree that {ek} is an orthonormal basis for H0. Thus for
n
X
k=1
ckek,
n
X
j=1
djek ∈H0,


n
X
k=1
ckek,
n
X
j=1
djej


H0
≡
n
X
k=1
ckdk
this being well deﬁned because the {ek} are linearly independent. Let the norm on
H0 be denoted by |·|H0. Let H1 be the completion of H0 with respect to this norm.
I want to show that |·|H0 is stronger than ||·||. Suppose then that
¯¯¯¯¯
n
X
k=1
βkek
¯¯¯¯¯
H0
≤1.
It follows then from the deﬁnition of |·|H0 that
¯¯¯¯¯
n
X
k=1
βkek
¯¯¯¯¯
2
H0
=
n
X
k=1
β2
k ≤1
and so from the construction of the ek, it follows that
¯¯¯¯¯
¯¯¯¯¯
n
X
k=1
βkek
¯¯¯¯¯
¯¯¯¯¯ < 1
Stated more simply, this has just shown that if h ∈H0 then since
¯¯h/ |h|H0
¯¯
H0 ≤1,
it follows that
||h|| / |h|H0 < 1

1054
PROBABILITY IN INFINITE DIMENSIONS
and so
||h|| < |h|H0 .
It follows that the completion of H0 must lie in E because this shows that every
Cauchy sequence in H0 is a Cauchy sequence in E. Thus H1 embedds continuously
into E and is dense in E. Denote its norm by |·|H1.
Now consider the Hilbert Schmidt operator,
A =
∞
X
k=1
λkek ⊗ek
where each λk > 0 and P
k λ2
k < ∞. This operator is clearly one to one. Let
H ≡AH1.
and for x ∈H, deﬁne
|x|H ≡
¯¯A−1x
¯¯
H1 .
Since each ek is in H it follows that H is dense in E. Note also that H ⊆H1 because
A maps H1 to H1.
Ax ≡
∞
X
k=1
λk (x, ek) ek
and the series converges in H1 because
∞
X
k=1
λk |(x, ek)| ≤
Ã ∞
X
k=1
λ2
k
!1/2 Ã ∞
X
k=1
|(x, ek)|2
!1/2
< ∞.
Also H is a Hilbert space with inner product given by
(x, y)H ≡
¡
A−1x, A−1y
¢
H1 .
H is complete because if {xn} is a Cauchy sequence in H, this is the same as
©
A−1xn
ª
being a Cauchy sequence in H1 which implies A−1xn →y for some
y ∈H1. Then it follows xn = A
¡
A−1xn
¢
→Ay in H.
For x ∈H ⊆H1,
||x|| ≤|x|H1 =
¯¯AA−1x
¯¯
H1 ≤||A||
¯¯A−1x
¯¯
H1 ≡||A|| |x|H
and so the embedding of H into E is continuous. Why is ||·|| a measurable norm
on H? Note ﬁrst that for x ∈H ⊆H1,
|Ax|H ≡
¯¯A−1Ax
¯¯
H1 = |x|H1 ≥||x||E .
(36.46)
Therefore, if it can be shown A is a Hilbert Schmidt operator on H, the desired
measurability will follow from Lemma 36.70 on Page 1040.
Claim:
A is a Hilbert Schmidt operator on H.

36.14.
FERNIQUE’S THEOREM
1055
Proof of the claim: From the deﬁnition of the inner product in H, it follows
an orthonormal basis for H is {λkek} . This is because
(λkek, λjej)H ≡
¡
λkA−1ek, λjA−1ej
¢
H1 = (ek, ej)H1 = δjk.
To show that A is Hilbert Schmidt, it suﬃces to show that
X
k
|A (λkek)|2
H < ∞
because this is the deﬁnition of an operator being Hilbert Schmidt. However, the
above equals
X
k
¯¯A−1A (λkek)
¯¯2
H1 =
X
k
λ2
k < ∞.
This proves the claim.
Now consider 36.46. By Lemma 36.70, it follows the norm ||x||′ ≡|Ax|H is Gross
measurable on H. Therefore, ||·||E is also Gross measurable because it is smaller.
This proves the theorem.
Using Theorem 36.73 and Theorem 36.82 this proves the following important
corollary.
Corollary 36.83 Let E be any real separable Banach space and let {ξk} be any
sequence of independent random variables such that L (ξk) = N (0, 1). Then there
exists a sequence, {ek} ⊆E such that
X (ω) ≡
∞
X
k=1
ξk (ω) ek
converges a.e. and its law is a Gaussian measure deﬁned on B (E).
36.14
Fernique’s Theorem
The following is an interesting lemma.
Lemma 36.84 Suppose µ is a symmetric Gaussian measure on the real separable
Banach space, E. Then there exists a probability space, (Ω, F, P) and independent
random variables, X and Y mapping Ωto E such that L (X) = L (Y ) = µ. Also,
the two random variables,
1
√
2 (X −Y ) ,
1
√
2 (X + Y )
are independent and
L
µ 1
√
2 (X −Y )
¶
= L
µ 1
√
2 (X + Y )
¶
= µ.

1056
PROBABILITY IN INFINITE DIMENSIONS
Proof: Letting X′ ≡
1
√
2 (X + Y ) and Y ′ ≡
1
√
2 (X −Y ) , it follows from Theo-
rem 36.38 on Page 1017, that X′ and Y ′ are independent if whenever h1, ···, hm ∈E′
and g1, · · ·, gk ∈E′, the two random vectors,
(h1 ◦X′, · · ·, hm ◦X′) and (g1 ◦Y ′, · · ·, gk ◦Y ′)
are linearly independent. Now consider linear combinations
m
X
j=1
tjhj ◦X′ +
k
X
i=1
sigi ◦Y ′.
This equals
1
√
2
m
X
j=1
tjhj (X) + 1
√
2
m
X
j=1
tjhj (Y )
+ 1
√
2
k
X
i=1
sigi (X) −1
√
2
k
X
i=1
sigi (Y )
=
1
√
2


m
X
j=1
tjhj +
k
X
i=1
sigi

(X)
+ 1
√
2


m
X
j=1
tjhj −
k
X
i=1
sigi

(Y )
and this is the sum of two independent normally distributed random variables so it
is also normally distributed. Therefore, by Theorem 36.51
(h1 ◦X′, · · ·, hm ◦X′, g1 ◦Y ′, · · ·, gk ◦Y ′)
is a random variable with multivariate normal distribution and by Theorem 36.56
the two random vectors
(h1 ◦X′, · · ·, hm ◦X′) and (g1 ◦Y ′, · · ·, gk ◦Y ′)
are linearly independent if
E ((hi ◦X′) (gj ◦Y ′)) = 0
for all i, j. This is what I will show next.
E ((hi ◦X′) (gj ◦Y ′))
=
1
4E ((hi (X) + hi (Y )) (gj (X) −gj (Y )))
=
1
4E (hi (X) gj (X)) −1
4E (hi (X) gj (Y ))
+1
4E (hi (Y ) gj (X)) −1
4E (hi (Y ) gj (Y ))
(36.47)

36.14.
FERNIQUE’S THEOREM
1057
Now from the above observation after the deﬁnition of Gaussian measure hi (X) gj (X)
and hi (Y ) gj (Y ) are both in L1 because each term in each product is normally dis-
tributed. Therefore, by Lemma 36.57,
E (hi (X) gj (X))
=
Z
Ω
hi (Y ) gj (Y ) dP
=
Z
E
hi (y) gj (y) dµ
=
Z
Ω
hi (X) gj (X) dP
=
E (hi (Y ) gj (Y ))
and so 36.47 reduces to
1
4 (E (hi (Y ) gj (X) −hi (X) gj (Y ))) = 0
because hi (X) and gj (Y ) are independent due to the assumption that X and Y
are independent. Thus
E (hi (X) gj (Y )) = E (hi (X)) E (gj (Y )) = 0
due to the assumption that µ is symmetric which implies the mean of these ran-
dom variables equals 0. The other term works out similarly. This has proved the
independence of the random variables, X′ and Y ′.
Next consider the claim they have the same law and it equals µ. To do this, I
will use Theorem 36.36 on Page 1016. Thus I need to show
E
³
eih(X′)´
= E
³
eih(Y ′)´
= E
³
eih(X)´
(36.48)
for all h ∈E′. Pick such an h. Then h ◦X is normally distributed and has mean 0.
Therefore, for some σ,
E
¡
eith◦X¢
= e−1
2 t2σ2.
Now since X and Y are independent,
E
³
eith◦X′´
=
E
µ
e
ith
³
1
√
2
´
(X+Y )
¶
=
E
µ
e
ith
³
1
√
2
´
X
¶
E
µ
e
ith
³
1
√
2
´
Y
¶
the product of two characteristic functions of two random variables,
1
√
2X and
1
√
2Y.
The variance of these two random variables which are normally distributed with
zero mean is 1
2σ2 and so
E
³
eith◦X′´
= e−1
2( 1
2 σ2)e−1
2( 1
2 σ2) = e−1
2 σ2 = E
¡
eith◦X¢
.

1058
PROBABILITY IN INFINITE DIMENSIONS
Similar reasoning shows E
³
eith◦Y ′´
= E
¡
eith◦Y ¢
= E
¡
eith◦X¢
. Letting t = 1, this
yields 36.48. This proves the lemma.
With this preparation, here is an incredible theorem due to Fernique.
Theorem 36.85 Let µ be a symmetric Gaussian measure on B (E) where E is a
real separable Banach space. Then for λ suﬃciently small and positive,
Z
R
eλ||x||2dµ < ∞.
More speciﬁcally, if λ and r are chosen such that
ln

µ ([x : ||x|| > r])
µ
³
B (0, r)
´

+ 25λr2 < −1,
then
Z
R
eλ||x||2dµ ≤exp
¡
λr2¢
+
e2
e2 −1.
Proof: Let X, Y be independent random variables having values in E such that
L (X) = L (Y ) = µ. Then by Lemma 36.84
1
√
2 (X −Y ) , 1
√
2 (X + Y )
are also independent and have the same law. Now let 0 ≤s ≤t and use indepen-
dence of the above random variables along with the fact they have the same law as
X and Y to obtain
P (||X|| ≤s, ||Y || > t) = P (||X|| ≤s) P (||Y || > t)
=
P
µ¯¯¯¯
¯¯¯¯
1
√
2 (X −Y )
¯¯¯¯
¯¯¯¯ ≤s
¶
P
µ¯¯¯¯
¯¯¯¯
1
√
2 (X + Y )
¯¯¯¯
¯¯¯¯ > t
¶
=
P
µ¯¯¯¯
¯¯¯¯
1
√
2 (X −Y )
¯¯¯¯
¯¯¯¯ ≤s,
¯¯¯¯
¯¯¯¯
1
√
2 (X + Y )
¯¯¯¯
¯¯¯¯ > t
¶
≤
P
µ 1
√
2 |||X|| −||Y ||| ≤s,
1
√
2 (||X|| + ||Y ||) > t
¶
.
Now consider the following picture in which the region, R represents the points,
(||X|| , ||Y ||) such that
1
√
2 |||X|| −||Y ||| ≤s and
1
√
2 (||X|| + ||Y ||) > t.

36.14.
FERNIQUE’S THEOREM
1059
¡
¡
¡
¡
¡
¡
¡
¡
¡
¡
r
r (?, t−s
√
2 )
( t−s
√
2 , ?)-
R
Therefore, continuing with the chain of inequalities above,
P (||X|| ≤s) P (||Y || > t)
≤
P
µ
||X|| > t −s
√
2 , ||Y || > t −s
√
2
¶
=
P
µ
||X|| > t −s
√
2
¶2
.
Since X, Y have the same law, this can be written as
P (||X|| > t) ≤
P
³
||X|| > t−s
√
2
´2
P (||X|| ≤s)
.
Now deﬁne a sequence as follows. t0 ≡r > 0 and tn+1 ≡r +
√
2tn. Also, in the
above inequality, let s ≡r and then it follows
P (||X|| > tn+1)
≤
P
³
||X|| > tn+1−r
√
2
´2
P (||X|| ≤r)
=
P (||X|| > tn)2
P (||X|| ≤r) .
Let
αn (r) ≡P (||X|| > tn)
P (||X|| ≤r) .
Then it follows
αn+1 (r) ≤αn (r)2 , α0 (r) = P (||X|| > r)
P (||X|| ≤r).
Consequently, αn (r) ≤α0 (r)2n
and also
P (||X|| > tn)
=
αn (r) P (||X|| ≤r)
≤
P (||X|| ≤r) α0 (r)2n
=
P (||X|| ≤r) eln(α0(r))2n.
(36.49)

1060
PROBABILITY IN INFINITE DIMENSIONS
Now using the distribution function technique and letting λ > 0,
Z
E
eλ||x||2dµ
=
Z ∞
0
µ
³h
eλ||x||2 > t
i´
dt
=
1 +
Z ∞
1
µ
³h
eλ||x||2 > t
i´
dt
=
1 +
Z ∞
1
P
³h
eλ||X||2 > t
i´
dt.
(36.50)
From 36.49,
P
³h
exp
³
λ ||X||2´
> exp
¡
λt2
n
¢i´
≤P ([||X|| ≤r]) eln(α0(r))2n.
Now split the above improper integral into intervals,
¡
exp
¡
λt2
n
¢
, exp
¡
λt2
n+1
¢¢
for
n = 0, 1, · · · and note that P
³h
eλ||X||2 > t
i´
is decreasing in t. Then from 36.50,
Z
E
eλ||x||2dµ ≤exp
¡
λr2¢
+
∞
X
n=0
Z exp(λt2
n+1)
exp(λt2
n)
P
³h
eλ||X||2 > t
i´
dt
≤
exp
¡
λr2¢
+
∞
X
n=0
P
³h
eλ||X||2 > exp
¡
λt2
n
¢i´ ¡
exp
¡
λt2
n+1
¢
−exp
¡
λt2
n
¢¢
≤
exp
¡
λr2¢
+
∞
X
n=0
P ([||X|| ≤r]) eln(α0(r))2n exp
¡
λt2
n+1
¢
≤
exp
¡
λr2¢
+
∞
X
n=0
eln(α0(r))2n exp
¡
λt2
n+1
¢
.
It remains to estimate tn+1. From the description of the tn,
tn =
Ã n
X
k=0
³√
2
´k
!
r = r
¡√
2
¢n+1 −1
√
2 −1
≤
√
2
√
2 −1r
³√
2
´n
and so
tn+1 ≤5r
³√
2
´n
Therefore,
Z
E
eλ||x||2dµ ≤exp
¡
λr2¢
+
∞
X
n=0
eln(α0(r))2n+λ25r22n.
Now ﬁrst pick r large enough that ln (α0 (r)) < −2 and then let λ be small enough
that 25λr2 < 1 or some such scheme and you obtain ln (α0 (r))+λ25r2 < −1. Then

36.15.
REPRODUCING KERNELS
1061
for this choice of r and λ, or for any other choice which makes ln (α0 (r)) + λ25r2 <
−1,
Z
E
eλ||x||2dµ
≤
exp
¡
λr2¢
+
∞
X
n=0
e−2n
≤
exp
¡
λr2¢
+
∞
X
n=0
e−2n
=
exp
¡
λr2¢
+
e2
e2 −1.
This proves the theorem.
Note this theorem implies all moments exist for Gaussian measures.
36.15
Reproducing Kernels
Suppose µ is a symmetric Gaussian measure on a real separable Banach space, E.
Recall this means that for φ ∈E′, L (φ) = N
¡
0, σ2¢
for some σ2. So what is σ2 in
terms of φ? By deﬁnition
σ2 = E
¡
φ2¢
=
Z
E
φ (x)2 dµ
(36.51)
and so φ ∈L2 (E) . Thus you can consider E′ ⊆L2 (E) . Let E′ denote the closure
of E′ in L2 (E). Then E′ is a Hilbert space with inner product given by
(φ, ψ) ≡
Z
E
φ (x) ψ (x) dµ.
For φ ∈L2 (E) , denote by R−1φ the element of E given by the Bochner integral,
R−1φ ≡
Z
E
xφ (x) dµ.
(36.52)
It is necessary to verify this integral makes sense. By Fernique’s theorem, Theorem
36.85,
Z
E
||x||2 dµ ≤C
Z
E
eλ||x||2dµ < ∞
and so by the Cauchy Schwarz inequality,
Z
E
||xφ (x)|| dµ ≤
µZ
E
||x||2 dµ
¶1/2 µZ
E
|φ (x)|2 dµ
¶1/2
< ∞.
Also in 36.52 the integrand is weakly measurable and is separably valued so the
Bochner integral makes sense as claimed and the integrand is in L1 (E; E).

1062
PROBABILITY IN INFINITE DIMENSIONS
The map, R−1 is clearly linear and it is also one to one on E′ because if R−1φ =
0, then there exists a sequence {φn} ⊆E′ converging to φ in L2 (E) . Therefore,
0 = φn
µZ
E
xφ (x) dµ
¶
=
Z
E
φn (x) φ (x) dµ →
Z
E
φ (x)2 dµ
and so φ (x) = 0 a.e. x.
Now deﬁne
H ≡
©
R−1φ : φ ∈E′ª
and let an inner product be given by
¡
R−1φ, R−1ψ
¢
H ≡
Z
E
φ (x) ψ (x) dµ.
Since R−1 is one to one, the inner product is well deﬁned and the map, R−1 : E′ →
H is one to one, onto, and preserves norms. Therefore, H is also a Hilbert space.
Now before making the next observation, note that by Fernique’s theorem, The-
orem 36.85, there exists λ > 0 such that
Z
E
||x||2 dµ = 1
λ
Z
E
λ ||x||2 dµ ≤1
λ
Z
E
eλ||x||2dµ ≡Cµ < ∞.
This implies H embedds continuously into E because
¯¯¯¯R−1φ
¯¯¯¯
E
=
¯¯¯¯
¯¯¯¯
Z
E
xφ (x) dµ
¯¯¯¯
¯¯¯¯
E
≤
Z
E
||x||E |φ (x)| dµ
≤
µZ
E
||x||2 dµ
¶1/2 µZ
E
φ (x)2 dµ
¶1/2
=
Cµ
µZ
E
φ (x)2 dµ
¶1/2
≡Cµ
¯¯¯¯R−1φ
¯¯¯¯
H
Now it follows from all this that H is a Hilbert space which embedds continuously
into E and for φ ∈E′,
||i∗φ||H′
≡
sup
|h|H≤1,h∈H
φ (h)
=
sup
|R−1ψ|H≤1,ψ∈E′ φ
¡
R−1 (ψ)
¢
=
sup
|R−1ψ|H≤1,ψ∈E′ φ
µZ
E
xψ (x) dµ
¶
=
sup
||ψ||L2(E)≤1,ψ∈E′
Z
E
φ (x) ψ (x) dµ
=
||φ||L2(E) = σ.
by 36.51.

36.15.
REPRODUCING KERNELS
1063
Finally, I claim that H must be dense in E. To see this, suppose it is not the
case. Then by a standard use of the Hahn Banch theorem, there would exist φ ∈E′
such that φ (H) = 0 but φ ̸= 0. But then
0 = φ
¡
R−1φ
¢
≡φ
µZ
E
xφ (x) dµ
¶
=
Z
E
φ (x)2 dµ
which is a contradiction. In fact, this shows even more than H is dense in E. It
also shows that R−1 (E) ≡H0 ⊆H is dense in E.
Deﬁnition 36.86 Let µ be a symmetric Gaussian measure on a real separable Ba-
nach space, E. Then a Hilbert space, H is said to be a reproducing kernel space for
µ if H ⊆E with the inclusion map continuous, and for every φ ∈E′,
L (φ) = N (0, |φ|H)
where
||i∗φ||H′ ≡
sup
||h||H≤1,h∈H
φ (h) = ||φ||L2(E)
Implicit in this deﬁnition are the inclusions,
H ⊆E, E′ ⊆H′ ⊆L2 (E, µ)
where i is the inclusion map of H into E.
Now I need a technical lemma before proving the next theorem.
Lemma 36.87 Suppose A is a reﬂexive Banach space and A ⊆B with the inclusion
map, i continuous. Also suppose M is a subset of B′ which separates the points of
A. Then i∗M is dense in A′.
Proof: Suppose that i∗M is not dense in A′. Then there exists a∗∈A′\
¡
i∗M
¢
.
It follows from a standard construction using the Hahn Banach theorem there exists
a∗∗∈A′′ such that a∗∗(a∗) ̸= 0 but a∗∗(i∗b∗) = 0 for all b∗∈M. Since A is
reﬂexive, there exists a ̸= 0 such that a ∈A and Ja = a∗∗where J is the James
map from A to A∗∗given by Ja (a∗) ≡a∗(a) . Then for all b∗∈M,
0 = a∗∗(i∗b∗) = Ja (i∗b∗) = i∗b∗(a) ≡b∗(a) .
Since M separates the points, this implies that a = 0 contrary to a ̸= 0. This proves
the lemma.
The above discussion proves the existence part of the following theorem.
Theorem 36.88 If µ is a symmetric Gaussian measure on E, a real separable
Banach space, then there exists a unique reproducing kernel space, H satisfying the
above properties of Deﬁnition 36.86. Also it must be the case that H is dense in E
and that the inverse Riesz map, R−1 from H′ to H is given by
R−1φ ≡
Z
E
xφ (x) dµ

1064
PROBABILITY IN INFINITE DIMENSIONS
Proof: For φ ∈L2 (E, µ) deﬁne
S−1φ ≡
Z
E
xφ (x) dµ.
The integrand is weakly measurable and separably valued and Fernique’s theorem
implies
Z
E
||x||E |φ (x)| dµ ≤
µZ
E
||x||2 dµ
¶1/2 µZ
E
|φ (x)|2 dµ
¶1/2
< ∞
so S−1 is deﬁned on all of L2 (E, µ).
S−1 (E′) is dense in E because if not, there would exist φ ∈E′ such that φ ̸= 0
but φ
¡
S−1 (E′)
¢
= 0 but then
0 = φ
¡
S−1 (φ)
¢
= φ
µZ
E
xφ (x) dµ
¶
=
Z
E
φ (x)2 dµ,
a contradiction to φ ̸= 0.
Now suppose H1 and H are two reproducing kernel spaces for µ.
Let φ ∈
H′
1 ⊆L2 (E, µ). Since the norm on H′ equals the L2 (E) norm, it follows that for
φ ∈E′, ψ ∈H′ and R the Riesz map from H to H′,
φ
¡
R−1 (ψ)
¢
=
R
¡
R−1 (φ)
¢ ¡
R−1ψ
¢
=
¡
R−1φ, R−1ψ
¢
H = (φ, ψ)H′
=
Z
E
φ (x) ψ (x) dµ = φ
¡
S−1 (ψ)
¢
.
Therefore, R−1 = S−1 on H′. A similar conclusion holds for H1.
By Lemma 36.87, E′ must be dense in H′
1 and also dense in H′. Thus S−1 (E′)
is dense in both H and H1. Letting φ ∈H′
1 there exists {φn} a sequence in E′
which converges to φ in H′
1. Which implies φn →φ in L2 (E, µ) because the norms
are the same. But then φn is also a Cauchy sequence in H′ which shows φ ∈H′.
Thus H′
1 ⊆H′ and similarly, H′ ⊆H′
1. It follows H = S−1 (H′) = S−1 (H′
1) = H1.
This proves the theorem.
Deﬁnition 36.89 For µ a symmetric Gaussian measure on E a real separable Ba-
nach space, denote by Hµ the reproducing kernel Hilbert space described in Deﬁnition
36.86.
Here is an interesting formula. Letting E be a real separable Banach space and
µ a symmetric Gaussian measure on B (E) , with Hµ the reproducing kernel space,
consider h, g ∈Hµ. Then letting φh, φg ∈H′
µ such that R−1φh = h and R−1φg = g,
(h, g)Hµ ≡
Z
E
φh (x) φg (x) dµ.
(36.53)

36.15.
REPRODUCING KERNELS
1065
Also, for x ∈H,
(h, x)Hµ =
¡
R−1φh, x
¢
Hµ ≡φh (x) ,
a similar formula holding for g in place of h. Now using this in 36.53 yields the
following interesting formula.
(h, g)Hµ ≡
Z
E
(h, x)Hµ (g, x)Hµ dµ.
Next consider the question of how to identify reproducing kernels and how to
tell whether a given probability measure is a Gaussian measure.
Before the next theorem is proved, recall the following two theorems proved on
Pages 1029 and 1027 respectively.
Theorem 36.90 Let X and Y be random vectors having values in Rp and Rq
respectively. Suppose also that (X, Y) is normally distributed and
E
¡
(X −E (X)) (Y −E (Y))∗¢
= 0.
Then X and Y are independent random vectors.
Theorem 36.91 Suppose ν is a probability measure on the Borel sets of R and
suppose that ξ and ζ are independent random variables such that L (ξ) = L (ζ) = ν
and whenever α2 + β2 = 1 it follows L (αξ + βζ) = ν. Then
L (ξ) = N
¡
0, σ2¢
for some σ ≥0. Also if L (ξ) = L (ζ) = N
¡
0, σ2¢
where ξ, ζ are independent, then
if α2 + β2 = 1, it follows L (αξ + βζ) = N
¡
0, σ2¢
.
Also recall the following theorem and corollary proved on Page 870.
Theorem 36.92 Let X = (X1, · · ·, Xp) where each Xi is a real valued random
variable. Then X is normally distributed in the above generalized sense if and only
if every linear combination, Pp
j=1 aiXi is normally distributed. In this case the
mean of X is
m = (E (X1) , · · ·, E (Xp))
and the covariance matrix for X is
Σjk = E ((Xj −mj) (Xk −mk))
where mj = E (Xj).
Corollary 36.93 Let X = (X1, · · ·, Xp) , Y = (Y1, · · ·, Yp) where each Xi, Yi is a
real valued random variable. Suppose also that for every a ∈Rp, a · X and a · Y
are both normally distributed with the same mean and variance. Then X and Y are
both multivariate normal random vectors with the same mean and covariance.

1066
PROBABILITY IN INFINITE DIMENSIONS
Lemma 36.94 Let M ⊆E′, where E is a real separable Banach space, be such that
σ (M) = B (E) . Also suppose X, Y are two E valued random variables such that for
all n ∈N, and ⃗φ ∈M n, L
³
⃗φ ◦X
´
= L
³
⃗φ ◦Y
´
. That is, for all F ∈B (Rn) ,
P
³h
⃗φ ◦X ∈F
i´
= P
³h
⃗φ ◦Y ∈F
i´
Then L (X) = L (Y ).
Proof: Deﬁne F as the π system which consists of cylindrical sets of the form
(
x ∈E : ⃗φ (x) ∈
m
Y
i=1
Gi, Gi ∈B (R)
)
where ⃗φ ∈M mfor some m ∈N. Thus σ (F) = σ (M) = B (E) and F is clearly a π
system.
Now deﬁne
G ≡{F ∈σ (F) = B (E) : P ([X ∈F]) = P ([Y ∈F])} .
First suppose F ∈F. Then
F = ⃗φ
−1
Ã m
Y
i=1
Gi
!
where each Gi is in B (R). Thus
P ([X ∈F])
=
P
Ã"
X ∈⃗φ
−1
Ã m
Y
i=1
Gi
!#!
=
P
Ã"
⃗φ (X) ∈
Ã m
Y
i=1
Gi
!#!
=
P
Ã"
⃗φ (Y ) ∈
Ã m
Y
i=1
Gi
!#!
=
P ([Y ∈F])
and so F ⊆G. If A ∈G then
P
¡£
X ∈AC¤¢
=
1 −P ([X ∈A])
=
1 −P ([Y ∈A]) = P
¡£
Y ∈AC¤¢
and so G is closed under complements. Next, if {Ai} is a sequence of disjoint sets

36.15.
REPRODUCING KERNELS
1067
of G,
P ([X ∈∪∞
i=1Ai])
=
P (∪∞
i=1 [X ∈Ai])
=
∞
X
i=1
P ([X ∈Ai])
=
∞
X
i=1
P ([Y ∈Ai])
=
P ([Y ∈∪∞
i=1Ai]) .
It follows from the lemma about π systems, Lemma 9.72 on Page 257 that G = σ (F) =
B (E) and this says L (X) = L (Y ). This proves the lemma.
So when do the conditions of this lemma hold? It seems a fairly strong assump-
tion to have L
³
⃗φ ◦X
´
= L
³
⃗φ ◦Y
´
for all ⃗φ ∈M n for any n ∈N. In the next
corollary, this condition will hold. This corollary says that if σ (M) = B (E) , then
in verifying a probability measure is Gaussian, you only need to consider φ ∈M
rather than all φ ∈E′.
Corollary 36.95 Suppose E is a real separable Banach space and µ is a probability
measure on B (E) . Suppose M is a subspace of E′ with the property that σ (M)2=
B (E) such that each φ ∈M considered as a random variable on the probability
space, (E, B (E) , µ) is normally distributed with mean 0 and variance ||φ||2
L2(E) .
Then µ is a symmetric Gaussian measure.
Proof: Let X, Y be independent random variables having values in E such
that L (X) = L (Y ) = µ.
As indicated earlier, such a thing exists.
You apply
Skorokhod’s theorem to the product measure µ × µ to ﬁnd (X, Y ) having values in
E × E such that L ((X, Y )) = µ × µ.
I want to show that for all φ ∈E′, L (φ) = N
¡
0, σ2¢
for some σ. I know this is
true for φ ∈M. Therefore, by Theorem 36.91, if φ ∈M and α2 + β2 = 1, then
L (φ (αX + βY )) = L (φ (X)) ,
and both random variables are normally distributed with 0 mean. Now take ⃗φ ∈M n
and consider a·⃗φ which is also in M because M is a subspace. Then from the above,
L
³
a · ⃗φ (αX + βY )
´
= L
³
a ·
³
α⃗φ (X) + β⃗φ (Y )
´´
= L
³
a · ⃗φ (X)
´
.
and the random variables, a · ⃗φ (X) and a ·
³
α⃗φ (X) + β⃗φ (Y )
´
are both normally
distributed with 0 mean and have the same distribution. Then by Corollary 36.93
L
³
⃗φ (X)
´
=
L
³
α⃗φ (X) + β⃗φ (Y )
´
=
L
³
⃗φ (αX + βY )
´
2Recall this means the smallest σ algebra such that each function in M is measurable.

1068
PROBABILITY IN INFINITE DIMENSIONS
and both are equal to a multvariate normal distribution. Now applying Lemma
36.94, it follows
L (X) = L (αX + βY ) = µ
(36.54)
whenever α2 + β2 = 1.
I want to verify L (φ) = N
³
0, ||φ||2
L2(E)
´
for all φ ∈E′. I have just shown that
whenever X, Y are independent with L (X) = L (Y ) = µ, then if α2 + β2 = 1, it
follows 36.54 holds. Now take an arbitrary φ ∈E′. It follows
L (φ (X)) = L (φ (αX + βY )) = L (αφ (X) + βφ (Y ))
(36.55)
whenever X, Y are independent having L (X) = L (Y ) = µ and α2 + β2 = 1. This
is a good time to state Theorem 36.91 again. Here it is:
Theorem 36.96 Suppose ν is a probability measure on the Borel sets of R and
suppose that ξ and ζ are independent random variables such that L (ξ) = L (ζ) = ν
and whenever α2 + β2 = 1 it follows L (αξ + βζ) = ν. Then
L (ξ) = N
¡
0, σ2¢
for some σ ≥0. Also if L (ξ) = L (ζ) = N
¡
0, σ2¢
where ξ, ζ are independent, then
if α2 + β2 = 1, it follows L (αξ + βζ) = N
¡
0, σ2¢
.
Fixing φ ∈E′, deﬁne ν (F) ≡µ ([φ (X) ∈F]) = µ ([φ (Y ) ∈F]) so ν is a proba-
bility measure on the Borel sets of R and L (φ ◦X) = L (φ ◦X) = ν. Furthermore,
from 36.55 ν = L (αφ (X) + βφ (Y )) whenever α2 + β2 = 1 and φ ◦X and φ ◦Y are
independent. Therefore by Theorem 36.91 L (φ ◦X) = N
¡
0, σ2¢
. In other words,
letting (Ω, F, P) be the probability space on which X is deﬁned,
Z
E
eitφ(x)dµ =
Z
Ω
eitφ(X(ω))dP = e−1
2 σ2t2
which shows L (φ) = N
¡
0, σ2¢
because the characteristic function of the random
variable, φ equals the characteristic function of one which has law equal to N
¡
0, σ2¢
.
This proves the corollary.
In the above corollary, you could say µ was Gaussian by verifying it worked as
it should with regard to φ ∈M where M was a suitable subset of E′. In this next
theorem, this result will be combined with one which also gives a way to identify
the reproducing kernel space.
Theorem 36.97 Suppose E is a real separable Banach space and µ is a probability
measure on B (E) . Suppose M is a subspace of E′ with the property that σ (M) =
B (E) such that each φ ∈M considered as a random variable on the probability space,
(E, B (E) , µ) is normally distributed with mean 0 and variance ||φ||2
L2(E) . Then µ
is a symmetric Gaussian measure. Next also assume M separates the points of E
and that H is a Hilbert space continuously embedded in E with the property that for
every φ ∈M,
||i∗φ||H′ = ||φ||L2(E) .

36.15.
REPRODUCING KERNELS
1069
Then it follows
||i∗φ||H′ = ||φ||L2(E)
for all φ ∈E′ and H is the reproducing kernel space for µ.
Proof: By Corollary 36.95 it follows µ is a Gaussian measure. It remains to
verify the assertion that H is the reproducing kernel space. To do this I will ﬁrst
show M = E′ where the closure is taken in L2 (E; µ) . If this is not so, then there
exists φ ∈E′ \ M. Then there exists φ0 ∈M such that φ −φ0 ̸= 0 is orthogonal
to M, the orthogonality being in L2 (E). Furthermore, there exists a sequence,
{φ0n} ⊆M such that φ0n →φ0 in L2 (E).
From the ﬁrst part, whenever ψ ∈E′, L (ψ) = N
³
0, ||φ||2
L2(E)
´
.(This is what
it means for µ to be Gaussian.) Let {ψ1, · · ·, ψm} ⊆M. Then an arbitrary linear
combination of these ψj and φ −φ0n is another function in E′ and so its law is
normal with zero mean. It follows from Theorem 36.92 that
(φ −φ0n, ψ1, · · ·, ψm)
(36.56)
is a multivariate normal random vector having values in Rm+1. Now the random
vector,
(φ −φ0, ψ1, · · ·, ψm)
(36.57)
is the limit in L2 (E) as n →∞of the random vectors in 36.56 and so the means
and covariances of the vectors in 36.56 converge. Thus the vector in 36.57 is also a
multivariate normal random vector. By Theorem 36.90 it follows the two random
vectors, φ −φ0 and (ψ1, · · ·, ψm) are independent. Now it is easy to see that
σ (M) = ∪F ⊆M,F ﬁniteσ (F) .
Therefore, σ (φ −φ0) and σ (M) = B (E) are independent. This implies φ−φ0 = 0.
Here is why. Since φ−φ0 is the limit in L2 (E) of continuous functions, and since µ
is regular by Lemma 36.17 on Page 1000 it can be assumed by changing φ −φ0 on
a set of measure zero that φ −φ0 is Borel measurable. Now here is an interesting
lemma.
Lemma 36.98 Suppose G and F are two σ algebras on a probability space, (Ω, S, P)
and suppose they are independent and that G ⊆F. Then if A ∈G it follows either
P (A) = 0 or P (A) = 1.
Proof of the lemma: Let A ∈G. Then
Z
Ω
XA (ω) dP
=
Z
Ω
XA (ω)2 dP
=
µZ
Ω
XAdP
¶ µZ
Ω
XAdP
¶
and so P (A) = P (A)2 . This proves the lemma.

1070
PROBABILITY IN INFINITE DIMENSIONS
Now continuing with the proof of Theorem 36.97, σ (φ −φ0) ⊆B (E) and the
two are independent so every set in σ (φ −φ0) has measure either 0 or 1. Thus
µ ([|φ −φ0| > α])
always equals either 0 or 1.
However, t →µ
³h
|φ −φ0|2 > t
i´
is a decreasing
function and so if t is large enough this function equals 0 since otherwise it always
equals 1 and
Z ∞
0
µ
³h
|φ −φ0|2 > t
i´
dt = ∞
contrary to φ −φ0 being in L2. Therefore, there exists M such that
µ ([x ∈E : |φ (x) −φ0 (x)| ≤M]) = 1
This is impossible if the distribution of φ −φ0 is normal having positive variance
which is the case if φ −φ0 ̸= 0 in L2 (E). Therefore, φ = φ0 which shows that
M = E′ in L2 (E) as claimed.
With this, it is time to show ||i∗φ||H′ = ||φ||L2(E) whenever φ ∈E′ given this
holds for φ ∈M. It is here that the assumption that M separates the points of E
is used for the ﬁrst time. Thus, assume
||i∗φ||H′ = ||φ||L2(E)
(36.58)
for all φ ∈M.
Let f ∈E′. Then i∗f ∈H′. By Lemma 36.87 there exists a
sequence, {φn} ⊆M such that i∗φn →i∗f in H′. Hence by 36.58 it is also the case
that φn →f in L2 (E). Let φ, ψ ∈M. Then by 36.58 it is routine to verify
(i∗φ, i∗ψ)H′ =
Z
E
φ (x) ψ (x) dµ.
Also recall that by Fernique’s theorem and f ∈E′
Z
E
||x|| |f (x)| dµ ≤||f||
Z
E
||x||2 dµ < ∞
Therefore, letting φ ∈M,
φ
µZ
E
xf (x) dµ
¶
=
Z
E
φ (x) f (x) dµ
=
lim
n→∞
Z
φ (x) φn (x) dµ
=
lim
n→∞(i∗φ, i∗φn)H′ = (i∗φ, i∗f)H′
=
φ
¡
R−1 (i∗f)
¢
where R−1 is the inverse of the Riesz map, R from H to H′ which is deﬁned by
Rx (y) = (x, y)H .

36.16.
REPRODUCING KERNELS AND WHITE NOISE
1071
Now here is where M separates the points is used. The above equation shows
since φ is arbitrary that
Z
E
xf (x) dµ = R−1 (i∗f)
for any f ∈E′. This also shows that for all f, g ∈E′
(i∗f, i∗g)H′ =
Z
E
f (x) g (x) dµ
because
(i∗f, i∗g)H′
=
¡
R−1 (i∗f) , R−1 (i∗g)
¢
H
=
i∗f
¡
R−1 (i∗g)
¢
= f
µZ
E
xg (x) dµ
¶
=
Z
E
f (x) g (x) dµ.
Therefore, letting f ∈E′, and noting that by Lemma 36.87 i∗E′ is dense in H′
||i∗f||H′
≡
sup
||h||H≤1
f (h) =
sup
||ψ||H′≤1
f
¡
R−1ψ
¢
=
sup
||i∗ψ||H′≤1,ψ∈E′ f
¡
R−1i∗ψ
¢
=
sup
||ψ||L2(E)≤1,ψ∈E′
Z
E
f (x) ψ (x) dµ = ||f||L2(E)
and this proves the theorem. Since H has the properties of the reproducing kernel
space, it equals Hµ.
36.16
Reproducing Kernels And White Noise
Consider the case where E is a real separable Banach space and µ is a symmetric
Gaussian measure on the Borel sets of E. Then as discussed in Theorem 36.88 there
exists a unique reproducing kernel space, Hµ such that Hµ is a dense subset of
E, E′ is a dense subset of H′
µ, and the norm on H′
µ is the same as the norm in
L2 (E, µ) , Hµ being a closed subspace of L2 (E, µ). Thus
Hµ ⊆E, E′ ⊆H′
µ ⊆L2 (E, µ) .
Also recall H0
µ ≡R−1 (E′) where R is the Riesz map from Hµ to H′
µ satisfying
Rx (y) ≡(x, y)Hµ .
Then the theorem about white noise to be proved here is the following.

1072
PROBABILITY IN INFINITE DIMENSIONS
Theorem 36.99 Let E be a real separable Banach space and let µ be a Gaussian
measure deﬁned on the Borel sets of E and let Hµ be the reproducing kernel space for
E. Suppose also that there exists an orthonormal complete basis for Hµ, {en} ⊆H0
µ
such that for φn ∈E′ deﬁned by en = R−1φn, span ({φn}) is also dense in E′. Then
if
©
ξj
ª
is a sequence of independent random variables having mean 0 and variance
1, which are deﬁned on a probability space, (Ω, F, P) it follows
X (ω) ≡
∞
X
i=1
ξi (ω) ei
(36.59)
converges in E a.e. and L (X) = µ.
Proof: Let φi = R (ei) where R is the Riesz map from Hµ to H′
µ. Then it
follows φi is normally distributed with mean 0 and variance σ2. What is σ2? By
deﬁnition, and the properties of the reproducing kernel space,
σ2
=
Z
E
φ2
i (x) dµ ≡(φi, φi)H′µ
=
¡
R−1φi, R−1φi
¢
Hµ = (ei, ei)Hµ = 1.
I claim that it is also the case that {φi} are independent. First note that if αi ∈R,
then Pp
i=1 αiφni ∈E′ and so is also normally distributed. Hence by Theorem 31.23
on Page 870,
³
φn1, · · ·, φnp
´
is multivariate normal. Now
E
³
φnjφnk
´
≡
Z
E
φnj (x) φnk (x) dµ
=
³
φnj, φnk
´
H′µ
=
¡
enj, enk
¢
Hµ = δjk
and so the covariance matrix is a diagonal. It follows from Theorem 31.25 on Page
872 that
n
φnj
op
j=1 is independent. This establishes the claim and shows that a
special case of the theorem involves the consideration of
∞
X
k=1
φk (x) ek.
(36.60)
Here the probability space is E and the measure is µ. Now this special case is easier
to work with and the plan is to consider this special case ﬁrst, showing that the
above sum in 36.60 converges to x for a.e. x ∈E and then extending to the general
case. The advantage of considering this special case ﬁrst is that you have a candidate
for the function to which the series converges which has known distribution.
Let S (x) ≡x and let SN (x) ≡PN
n=1 φn (x) en. First of all, observe that
(E, B (E) , µ) is a probability space and S maps E to E and L (S) = µ.
Thus
S has known distribution and it is reasonable to try and get SN (x) to converge to
S (x).

36.16.
REPRODUCING KERNELS AND WHITE NOISE
1073
Let
L (SN) ≡µN, L (S −SN) ≡µ⊥
N.
First note that SN and SM −SN for M > N are independent random variables by
the ﬁrst part of this argument. Letting φ ∈span ({φn})
φ
Ã N
X
k=1
φn (x) en
!
=
N
X
k=1
φn (x) φ (en)
and this series converges for each x ∈E as N →∞because φk (en) = (ek, en)Hµ =
δkn which implies that if n is suﬃciently large φ (en) = 0 so the above sequence of
partial sums is eventually constant.
Therefore, letting φ ∈span ({φn}) ,
E (exp (iφ (S −SN))) E (exp (iφ (SN)))
=
lim
M→∞E (exp (iφ (SM −SN))) E (exp (iφ (SN)))
=
lim
M→∞E (exp (iφ (SM −SN)) exp (iφ (SN)))
=
E (exp (iφ (S −SN)) exp (iφ (SN)))
Now span ({φn}) is dense in E′ by assumption and so it follows from Corollary 36.40
on Page 1018 that S −SN and SN are independent random variables.
It follows from Theorem 36.47 on Page 1023 that
µ = µN ∗µ⊥
N
(36.61)
because S = SN + (S −SN) and the two random variables, SN and S −SN were
just shown to be independent.
Next I will show the measures
©
µ⊥
N
ª
are tight. This will set things up for an
application of Prokhorov’s theorem. Let ε > 0 be given. Since µ is a ﬁnite measure
and E is separable, it follows from Lemmas 36.17 and 36.18 there exists a compact
set, K ⊆E such that
µ (K) ≥1 −ε.
By 36.61,
1 −ε ≤µ (K) =
Z
E
µ⊥
N (K −x) dµN (x)
and so there exists xN ∈E such that µ⊥
N (K −xN) ≥1−ε. However, each φk has a
symmetric distribution since they are each normally distributed with mean 0. Also,
S has a symmetric distribution and so it follows so does S −SN. Thus
µ⊥
N (−K + xN) = µ⊥
N (K −xN) ≥1 −ε.
Now note
(−K + xN) ∩(K −xN) ⊆K −K
2

1074
PROBABILITY IN INFINITE DIMENSIONS
because if x ∈(−K + xN) ∩(K −xN) , then x = −k1 + xN = k2 −xN and so
2x = k2 −k1 ∈K −K.
Therefore,
µ⊥
N
µK −K
2
¶
≥µ⊥
N ((−K + xN) ∩(K −xN)) ≥1 −2ε.
This follows easily because
µ⊥
N
³
(−K + xN)C ∪(K −xN)C´
≤
µ⊥
N
³
(−K + xN)C´
+ µ⊥
N
³
(K −xN)C´
≤2ε.
Now note that K−K
2
is a compact set because if f : E×E →E is given by f (x, y) =
x−y
2
then f is continuous and so it maps the compact subset of E × E, K × K to
the compact set K−K
2
. Since this set is not dependent on N this shows
©
µ⊥
N
ª
is
tight.
By Prokhorov’s theorem, Theorem 36.23 on Page 1004 every subsequence of
©
µ⊥
N
ª
has a subsequence which converges weakly. I will show they all converge
weakly to the measure δ0 deﬁned by δ0 (F) = 1 if 0 ∈F and δ0 (F) = 0 if 0 /∈
F. From this it will follow that µ⊥
N must converge weakly to δ0. When this is
established, it will lead to the desired conclusion.
Let φ ∈span ({φn}) and let
©
µ⊥
k
ª
denote a weakly convergent subsequence of
©
µ⊥
N
ª
. Say this converges weakly to ν. Then recall that since φ ∈span ({φn}) ,
lim
k→∞φ (S (x) −Sk (x)) = 0
and so letting Y : E →E be given by Y (x) ≡0,
1
=
E (exp (iφ (Y ))) = lim
k→∞E (exp (iφ (S −Sk)))
≡
lim
k→∞
Z
E
exp (iφ (x)) dµ⊥
k (x) =
Z
E
exp (iφ (x)) dν.
By density of span ({φn}) in E′, it follows that
1 = E (exp (iφ (Y ))) =
Z
E
exp (iφ (x)) dν
for all φ ∈E′. If λ = L (Y ) , then for all φ ∈E′,
Z
E
exp (iφ (x)) dλ = E (exp (iφ (Y ))) =
Z
E
exp (iφ (x)) dν
By Theorem 36.36 it follows λ = ν and so ν = L (Y ) where Y (x) ≡0. As discussed
above, this has shown that
©
µ⊥
N
ª
converges weakly to ν where ν = L (Y ). Also,

36.16.
REPRODUCING KERNELS AND WHITE NOISE
1075
ν = δ0 because by Theorem 36.36 the two measures, ν and δ0, have the same
characteristic functions.
Now consider B (0, ε)C ⊆E. δ0
³
∂
³
B (0, ε)C´´
= 0 and so it follows by Lemma
36.25 on Page 1007 that
lim
N→∞µ⊥
N
³
B (0, ε)C´
= δ0
³
B (0, ε)C´
= 0.
Therefore,
0
=
lim
N→∞µ⊥
N
³
B (0, ε)C´
=
lim
N→∞µ
³h
S −SN ∈B (0, ε)Ci´
=
lim
N→∞µ ([||S −SN||E ≥ε]) .
Which shows SN converges in probability to S. In particular, there exists a subse-
quence nk such that for all m > nk,
µ
¡£
||S −Snk|| > 2−k¤¢
< 2−k
µ
¡£
||Sm −Snk|| > 2−k¤¢
< 2−k
(36.62)
Then {Snk} converges pointwise a.e. to S. Now it follows from Lemma 36.78 on
Page 1049 it follows that since the distributions of the φk are symmetric that {Sn}
converges pointwise a.e. to S. Letting φ ∈E′,
φ (Sn (x)) =
n
X
k=1
φk (x) φ (ek)
which is a normally distributed random variable having mean 0 and variance Pn
k=1 φ (ek)2 .
Therefore,
E (exp (itφ (Sn))) = e−1
2 t2 Pn
k=1 φ(ek)2
and so, passing to the limit, yields
E (exp (itφ (S))) = e−1
2 t2 P∞
k=1 φ(ek)2
the series in the last term converging because it equals
∞
X
k=1
¡
R−1φ, ek
¢2 =
¯¯R−1φ
¯¯2
Hµ = |φ|2
H′µ = ||φ||2
L2(E,µ) .
Thus φ (S) is normally distributed with mean 0 and variance ||φ||2
L2(E).
Hence
L (S) = µ because if ν = L (S) , the above has just shown, for ψ ∈E′,
φν (ψ) = e−1
2 ||ψ||2
L2(E)

1076
PROBABILITY IN INFINITE DIMENSIONS
while
φµ (ψ) ≡
Z
E
eiψ(x)dµ = e−1
2 ||ψ||2
L2(E)
due to the observation that since µ is Gaussian, each ψ ∈E′ is normal with mean 0
and variance equal to ||ψ||2
L2(E). Since the two measures have the same characteristic
functions, they are equal by Theorem 36.36.
It only remains to consider the general case described in 36.59. Consider the
sum,
Xn (ω) ≡
n
X
i=1
ξi (ω) ei.
Letting νnm = L (Xn −Xm) for m < n, I would like to show that νnm = L (Sn −Sm)
deﬁned above in terms of the sums involving the φk. The reason for this is that if
these are the same, then
µ
¡£
||Sm −Snk|| > 2−k¤¢
= P
¡
||Xm −Xnk|| > 2−k¢
< 2−k
(36.63)
and the pointwise a.e. convergence of {Xn} will follow as above using Lemma 36.78
on Page 1049 and then the same characteristic function argument will show X (ω)
deﬁned in 36.59 has L (X) = µ. But the ξi are given to be independent and normally
distributed with mean 0 and variance 1 so
E (exp (iφ (Xn −Xm))) = e−1
2
Pn
k=m+1 φ(ek)2
which is the same as the result of
E (exp (iφ (Sn −Sm)))
and this implies the desired result. Thus 36.63 implies {Xnk}∞
k=1 converges point-
wise a.e. and then Lemma 36.78 on Page 1049 applies again to conclude {Xn}
converges pointwise a.e. That L (X) = µ follows as before from a characteristic
function argument. This proves the theorem.

Part V
Sobolev Spaces
1077


Weak Derivatives
37.1
Weak ∗Convergence
A very important sort of convergence in applications of functional analysis is the
concept of weak or weak ∗convergence. It is important because it allows you to
assert the existence of a convergent subsequence of a given bounded sequence. The
only problem is the convergence is very weak so it does not tell you as much as
you would like. Nevertheless, it is a very useful concept. The big theorems in the
subject are the Eberlein Smulian theorem and the Banach Alaoglu theorem about
the weak or weak ∗compactness of the closed unit balls in either a Banach space
or its dual space. These theorems are proved in Yosida [52]. Here I will present a
special case which turns out to be by far the most important in applications and it
is not hard to get from the Riesz representation theorem for Lp. First I deﬁne weak
and weak ∗convergence.
Deﬁnition 37.1 Let X′ be the dual of a Banach space X and let {x∗
n} be a sequence
of elements of X′. Then x∗
n converges weak ∗to x∗if and only if for all x ∈X,
lim
n→∞x∗
n (x) = x∗(x) .
A sequence in X, {xn} converges weakly to x ∈X if and only if for all x∗∈X′
lim
n→∞x∗(xn) = x∗(x) .
The main result is contained in the following lemma.
Lemma 37.2 Let X′ be the dual of a Banach space, X and suppose X is separa-
ble. Then if {x∗
n} is a bounded sequence in X′, there exists a weak ∗convergent
subsequence.
Proof: Let D be a dense countable set in X. Then the sequence, {x∗
n (x)} is
bounded for all x and in particular for all x ∈D. Use the Cantor diagonal process to
obtain a subsequence, still denoted by n such that x∗
n (d) converges for each d ∈D.
1079

1080
WEAK DERIVATIVES
Now let x ∈X be completely arbitrary. In fact {x∗
n (x)} is a Cauchy sequence. Let
ε > 0 be given and pick d ∈D such that for all n
|x∗
n (x) −x∗
n (d)| < ε
3.
This is possible because D is dense. By the ﬁrst part of the proof, there exists Nε
such that for all m, n > Nε,
|x∗
n (d) −x∗
m (d)| < ε
3.
Then for such m, n,
|x∗
n (x) −x∗
m (x)|
≤
|x∗
n (x) −x∗
n (d)| + |x∗
n (d) −x∗
m (d)|
+ |x∗
m (d) −x∗
m (x)|
<
ε
3 + ε
3 + ε
3 = ε.
Since ε is arbitrary, this shows {x∗
n (x)} is a Cauchy sequence for all x ∈X.
Now deﬁne f (x) ≡limn→∞x∗
n (x). Since each x∗
n is linear, it follows f is also
linear. In addition to this,
|f (x)| = lim
n→∞|x∗
n (x)| ≤K ||x||
where K is some constant which is larger than all the norms of the x∗
n. Such a
constant exists because the sequence, {x∗
n} was bounded. This proves the lemma.
The lemma implies the following important theorem.
Theorem 37.3 Let Ωbe a measurable subset of Rn and let {fk} be a bounded
sequence in Lp (Ω) where 1 < p ≤∞.
Then there exists a weak ∗convergent
subsequence.
Proof: Since Lp′ (Ω) is separable, this follows from the Riesz representation
theorem.
Note that from the Riesz representation theorem, it follows that if p < ∞, then
the sequence converges weakly.
37.2
Test Functions And Weak Derivatives
In elementary courses in mathematics, functions are often thought of as things
which have a formula associated with them and it is the formula which receives
the most attention. For example, in beginning calculus courses the derivative of a
function is deﬁned as the limit of a diﬀerence quotient. You start with one function
which tends to be identiﬁed with a formula and, by taking a limit, you get another
formula for the derivative. A jump in abstraction occurs as soon as you encounter
the derivative of a function of n variables where the derivative is deﬁned as a certain
linear transformation which is determined not by a formula but by what it does to
vectors. When this is understood, it reduces to the usual idea in one dimension. The

37.2.
TEST FUNCTIONS AND WEAK DERIVATIVES
1081
idea of weak partial derivatives goes further in the direction of deﬁning something
in terms of what it does rather than by a formula, and extra generality is obtained
when it is used.
In particular, it is possible to diﬀerentiate almost anything if
the notion of what is meant by the derivative is suﬃciently weak. This has the
advantage of allowing the consideration of the weak partial derivative of a function
without having to agonize over the important question of existence but it has the
disadvantage of not being able to say much about the derivative. Nevertheless, it
is the idea of weak partial derivatives which makes it possible to use functional
analytic techniques in the study of partial diﬀerential equations and it is shown in
this chapter that the concept of weak derivative is useful for unifying the discussion
of some very important theorems. Certain things which shold be true are.
Let Ω⊆Rn. A distribution on Ωis deﬁned to be a linear functional on C∞
c (Ω),
called the space of test functions. The space of all such linear functionals will be
denoted by D∗(Ω). Actually, more is sometimes done here. One imposes a topology
on C∞
c (Ω) making it into a topological vector space, and when this has been done,
D′ (Ω) is deﬁned as the dual space of this topological vector space. To see this,
consult the book by Yosida [52] or the book by Rudin [46].
Example:
The space L1
loc (Ω) may be considered as a subset of D∗(Ω) as
follows.
f (φ) ≡
Z
Ω
f (x) φ (x) dx
for all φ ∈C∞
c (Ω).
Recall that f ∈L1
loc (Ω) if fXK ∈L1 (Ω) whenever K is
compact.
Example: δx ∈D∗(Ω) where δx (φ) ≡φ (x).
It will be observed from the above two examples and a little thought that D∗(Ω)
is truly enormous. The derivative of a distribution will be deﬁned in such a way that
it agrees with the usual notion of a derivative on those distributions which are also
continuously diﬀerentiable functions. With this in mind, let f be the restriction to
Ωof a smooth function deﬁned on Rn. Then Dxif makes sense and for φ ∈C∞
c (Ω)
Dxif (φ) ≡
Z
Ω
Dxif (x) φ (x) dx = −
Z
Ω
fDxiφdx = −f (Dxiφ).
This motivates the following deﬁnition.
Deﬁnition 37.4 For T ∈D∗(Ω)
DxiT (φ) ≡−T (Dxiφ).
Of course one can continue taking derivatives indeﬁnitely. Thus,
DxixjT ≡Dxi
¡
DxjT
¢
and it is clear that all mixed partial derivatives are equal because this holds for
the functions in C∞
c (Ω).
In this weak sense, the derivative of almost anything
exists, even functions that may be discontinuous everywhere. However the notion
of “derivative” is very weak, hence the name, “weak derivatives”.

1082
WEAK DERIVATIVES
Example: Let Ω= R and let
H (x) ≡
½
1 if x ≥0,
0 if x < 0.
Then
DH (φ) = −
Z
H (x) φ′ (x) dx = φ (0) = δ0(φ).
Note that in this example, DH is not a function.
What happens when Df is a function?
Theorem 37.5 Let Ω= (a, b) and suppose that f and Df are both in L1 (a, b).
Then f is equal to a continuous function a.e., still denoted by f and
f (x) = f (a) +
Z x
a
Df (t) dt.
In proving Theorem 37.5 the following lemma is useful.
Lemma 37.6 Let T ∈D∗(a, b) and suppose DT = 0. Then there exists a constant
C such that
T (φ) =
Z b
a
Cφdx.
Proof: T (Dφ) = 0 for all φ ∈C∞
c (a, b) from the deﬁnition of DT = 0. Let
φ0 ∈C∞
c (a, b) ,
Z b
a
φ0 (x) dx = 1,
and let
ψφ (x) =
Z x
a
[φ (t) −
ÃZ b
a
φ (y) dy
!
φ0 (t)]dt
for φ ∈C∞
c (a, b). Thus ψφ ∈C∞
c (a, b) and
Dψφ = φ −
ÃZ b
a
φ (y) dy
!
φ0.
Therefore,
φ = Dψφ +
ÃZ b
a
φ (y) dy
!
φ0
and so
T (φ) = T(Dψφ) +
ÃZ b
a
φ (y) dy
!
T(φ0) =
Z b
a
T (φ0) φ (y) dy.
Let C = Tφ0. This proves the lemma.

37.2.
TEST FUNCTIONS AND WEAK DERIVATIVES
1083
Proof of Theorem 37.5 Since f and Df are both in L1 (a, b),
Df (φ) −
Z b
a
Df (x) φ (x) dx = 0.
Consider
f (·) −
Z (·)
a
Df (t) dt
and let φ ∈C∞
c (a, b).
D
Ã
f (·) −
Z (·)
a
Df (t) dt
!
(φ)
≡−
Z b
a
f (x) φ′ (x) dx +
Z b
a
µZ x
a
Df (t) dt
¶
φ′ (x) dx
=
Df (φ) +
Z b
a
Z b
t
Df (t) φ′ (x) dxdt
=
Df (φ) −
Z b
a
Df (t) φ (t) dt = 0.
By Lemma 37.6, there exists a constant, C, such that
Ã
f (·) −
Z (·)
a
Df (t) dt
!
(φ) =
Z b
a
Cφ (x) dx
for all φ ∈C∞
c (a, b). Thus
Z b
a
{
µ
f (x) −
Z x
a
Df (t) dt
¶
−C}φ (x) dx = 0
for all φ ∈C∞
c (a, b). It follows from Lemma 37.9 in the next section that
f (x) −
Z x
a
Df (t) dt −C = 0 a.e. x.
Thus let f (a) = C and write
f (x) = f (a) +
Z x
a
Df (t) dt.
This proves Theorem 37.5.
Theorem 37.5 says that
f (x) = f (a) +
Z x
a
Df (t) dt

1084
WEAK DERIVATIVES
whenever it makes sense to write
R x
a Df (t) dt, if Df is interpreted as a weak deriva-
tive. Somehow, this is the way it ought to be. It follows from the fundamental
theorem of calculus that f ′ (x) exists for a.e. x where the derivative is taken in the
sense of a limit of diﬀerence quotients and f ′ (x) = Df (x). This raises an inter-
esting question. Suppose f is continuous on [a, b] and f ′ (x) exists in the classical
sense for a.e. x. Does it follow that
f (x) = f (a) +
Z x
a
f ′ (t) dt?
The answer is no. To see an example, consider Problem 4 on Page 445 which gives
an example of a function which is continuous on [0, 1], has a zero derivative for
a.e. x but climbs from 0 to 1 on [0, 1]. Thus this function is not recovered from
integrating its classical derivative.
In summary, if the notion of weak derivative is used, one can at least give
meaning to the derivative of almost anything, the mixed partial derivatives are
always equal, and, in one dimension, one can recover the function from integrating
its derivative. None of these claims are true for the classical derivative. Thus weak
derivatives are convenient and rule out pathologies.
37.3
Weak Derivatives In Lp
loc
Deﬁnition 37.7 Let U be an open set in Rn.f ∈Lp
loc (U) if fXK ∈Lp whenever
K is a compact subset of U.
Deﬁnition 37.8 For α = (k1, · · ·, kn) where the ki are nonnegative integers, deﬁne
|α| ≡
n
X
i=1
|kxi|, Dαf (x) ≡
∂|α|f (x)
∂xk1
1 ∂xk2
2 · · · ∂xkn
n
.
Also deﬁne φk to be a molliﬁer if spt (φk) ⊆B
¡
0, 1
k
¢
, φk ≥0,
R
φkdx = 1, and
φk ∈C∞
c
¡
B
¡
0, 1
k
¢¢
. In the case a Greek letter like δ or ε is used as a subscript,
it will mean spt (φδ) ⊆B (0, δ) , φδ ≥0,
R
φδdx = 1, and φδ ∈C∞
c (B (0, δ)) . You
can always get a molliﬁer by letting φ ≥0, φ ∈C∞
c (B (0, 1)) ,
R
φdx = 1,and then
deﬁning φk (x) ≡knφ (kx) or in the case of a Greek subscript, φδ (x) =
1
δn φ
¡ x
δ
¢
.
Consider the case where u and Dαu for |α| = 1 are each in Lp
loc (Rn). The next
lemma is the one alluded to in the proof of Theorem 37.5.
Lemma 37.9 Suppose f ∈L1
loc (U) and suppose
Z
fφdx = 0
for all φ ∈C∞
c (U). Then f (x) = 0 a.e.
x.

37.3.
WEAK DERIVATIVES IN LP
LOC
1085
Proof: Without loss of generality f is real valued. Let
E ≡{x : f (x) > ε}
and let
Em ≡E ∩B(0, m).
Is m (Em) = 0? If not, there exists an open set, V , and a compact set K satisfying
K ⊆Em ⊆V ⊆B (0, m) , m (V \ K) < 4−1m (Em) ,
Z
V \K
|f| dx < ε4−1m (Em) .
Let H and W be open sets satisfying
K ⊆H ⊆H ⊆W ⊆W ⊆V
and let
H ≺g ≺W
where the symbol, ≺, in the above implies spt (g) ⊆W, g has all values in [0, 1] ,
and g (x) = 1 on H. Then let φδ be a molliﬁer and let h ≡g∗φδ for δ small enough
that
K ≺h ≺V.
Thus
0
=
Z
fhdx =
Z
K
fdx +
Z
V \K
fhdx
≥
εm (K) −ε4−1m (Em)
≥
ε
¡
m (Em) −4−1m (Em)
¢
−ε4−1m (Em)
≥
2−1εm(Em).
Therefore, m (Em) = 0, a contradiction. Thus
m (E) ≤
∞
X
m=1
m (Em) = 0
and so, since ε > 0 is arbitrary,
m ({x : f (x) > 0}) = 0.
Similarly m ({x : f (x) < 0}) = 0. This proves the lemma.
This lemma allows the following deﬁnition.
Deﬁnition 37.10 Let U be an open subset of Rn and let u ∈L1
loc (U) . Then Dαu ∈
L1
loc (U) if there exists a function g ∈L1
loc (U), necessarily unique by Lemma 37.9,
such that for all φ ∈C∞
c (U),
Z
U
gφdx = Dαu (φ) ≡
Z
U
(−1)|α| u (Dαφ) dx.
Then Dαu is deﬁned to equal g when this occurs.

1086
WEAK DERIVATIVES
Lemma 37.11 Let u ∈L1
loc (Rn) and suppose u,i ∈L1
loc (Rn), where the subscript
on the u following the comma denotes the ith weak partial derivative. Then if φε is
a molliﬁer and uε ≡u ∗φε, it follows uε,i ≡u,i ∗φε.
Proof: If ψ ∈C∞
c (Rn), then
Z
u (x −y) ψ,i (x) dx
=
Z
u (z) ψ,i (z + y) dz
=
−
Z
u,i (z) ψ (z + y) dz
=
−
Z
u,i (x −y) ψ (x) dx.
Therefore,
uε,i (ψ)
=
−
Z
uεψ,i = −
Z Z
u (x −y) φε (y) ψ,i (x) d ydx
=
−
Z Z
u (x −y) ψ,i (x) φε (y) dxdy
=
Z Z
u,i (x −y) ψ (x) φε (y) dxdy
=
Z
u,i ∗φε (x) ψ (x) dx.
The technical questions about product measurability in the use of Fubini’s theorem
may be resolved by picking a Borel measurable representative for u. This proves
the lemma.
What about the product rule? Does it have some form in the context of weak
derivatives?
Lemma 37.12 Let U be an open set, ψ ∈C∞(U) and suppose u, u,i ∈Lp
loc (U).
Then (uψ),i and uψ are in Lp
loc (U) and
(uψ),i = u,iψ + uψ,i.
Proof: Let φ ∈C∞
c (U) then
(uψ),i (φ)
≡
−
Z
U
uψφ,idx
=
−
Z
U
u[(ψφ),i −φψ,i]dx
=
Z
U
¡
u,iψφ + uψ,iφ
¢
dx
=
Z
U
¡
u,iψ + uψ,i
¢
φdx
This proves the lemma.

37.4.
MORREY’S INEQUALITY
1087
Recall the notation for the gradient of a function.
∇u (x) ≡(u,1 (x) · · · u,n (x))T
thus
Du (x) v =∇u (x) · v.
37.4
Morrey’s Inequality
The following inequality will be called Morrey’s inequality. It relates an expression
which is given pointwise to an integral of the pth power of the derivative.
Lemma 37.13 Let u ∈C1 (Rn) and p > n.
Then there exists a constant, C,
depending only on n such that for any x, y ∈Rn,
|u (x) −u (y)|
≤C
ÃZ
B(x,2|x−y|)
|∇u (z) |pdz
!1/p ³
| x −y|(1−n/p)´
.
(37.1)
Proof:
In the argument C will be a generic constant which depends on n.
Consider the following picture.
x
U
r W
r
V
y
This is a picture of two balls of radius r in Rn, U and V having centers at x and
y respectively, which intersect in the set, W. The center of U is on the boundary
of V and the center of V is on the boundary of U as shown in the picture. There
exists a constant, C, independent of r depending only on n such that
m (W)
m (U) = m (W)
m (V ) = C.
You could compute this constant if you desired but it is not important here.
Deﬁne the average of a function over a set, E ⊆Rn as follows.
Z
−
E
fdx ≡
1
m (E)
Z
E
fdx.

1088
WEAK DERIVATIVES
Then
|u (x) −u (y)|
=
Z
−
W
|u (x) −u (y)| dz
≤
Z
−
W
|u (x) −u (z)| dz +
Z
−
W
|u (z) −u (y)| dz
=
C
m (U)
·Z
W
|u (x) −u (z)| dz +
Z
W
|u (z) −u (y)| dz
¸
≤
C
·Z
−
U
|u (x) −u (z)| dz +
Z
−
V
|u (y) −u (z)| dz
¸
Now consider these two terms. Using spherical coordinates and letting U0 denote
the ball of the same radius as U but with center at 0,
Z
−
U
|u (x) −u (z)| dz
=
1
m (U0)
Z
U0
|u (x) −u (z + x)| dz
=
1
m (U0)
Z r
0
ρn−1
Z
Sn−1 |u (x) −u (ρw + x)| dσ (w) dρ
≤
1
m (U0)
Z r
0
ρn−1
Z
Sn−1
Z ρ
0
|∇u (x + tw) · w| dtdσdρ
≤
1
m (U0)
Z r
0
ρn−1
Z
Sn−1
Z ρ
0
|∇u (x + tw)| dtdσdρ
≤
C 1
r
Z r
0
Z
Sn−1
Z r
0
|∇u (x + tw)| dtdσdρ
=
C 1
r
Z r
0
Z
Sn−1
Z r
0
|∇u (x + tw)|
tn−1
tn−1dtdσdρ
=
C
Z
Sn−1
Z r
0
|∇u (x + tw)|
tn−1
tn−1dtdσ
=
C
Z
U0
|∇u (x + z)|
|z|n−1
dz
≤
C
µZ
U0
|∇u (x + z)|p dz
¶1/p µZ
U
|z|p′−np′¶1/p′
=
C
µZ
U
|∇u (z)|p dz
¶1/p µZ
Sn−1
Z r
0
ρp′−np′ρn−1dρdσ
¶(p−1)/p
=
C
µZ
U
|∇u (z)|p dz
¶1/p ÃZ
Sn−1
Z r
0
1
ρ
n−1
p−1 dρdσ
!(p−1)/p

37.4.
MORREY’S INEQUALITY
1089
=
C
µ p −1
p −n
¶(p−1)/p µZ
U
|∇u (z)|p dz
¶1/p
r1−n
p
=
C
µ p −1
p −n
¶(p−1)/p µZ
U
|∇u (z)|p dz
¶1/p
|x −y|1−n
p
Similarly,
Z
−
V
|u (y) −u (z)| dz ≤C
µ p −1
p −n
¶(p−1)/p µZ
V
|∇u (z)|p dz
¶1/p
|x −y|1−n
p
Therefore,
|u (x) −u (y)| ≤C
µ p −1
p −n
¶(p−1)/p ÃZ
B(x,2|x−y|)
|∇u (z)|p dz
!1/p
|x −y|1−n
p
because B (x, 2 |x −y|) ⊇V ∪U. This proves the lemma.
The following corollary is also interesting
Corollary 37.14 Suppose u ∈C1 (Rn) . Then
|u (y) −u (x) −∇u (x) · (y −x)|
≤C
Ã
1
m (B (x, 2 |x −y|))
Z
B(x,2|x−y|)
|∇u (z) −∇u (x) |pdz
!1/p
| x −y|. (37.2)
Proof: This follows easily from letting g (y) ≡u (y) −u (x) −∇u (x) · (y −x) .
Then g ∈C1 (Rn), g (x) = 0, and ∇g (z) = ∇u (z) −∇u (x) . From Lemma 37.13,
|u (y) −u (x) −∇u (x) · (y −x)|
=
|g (y)| = |g (y) −g (x)|
≤
C
ÃZ
B(x,2|x−y|)
|∇u (z) −∇u (x) |pdz
!1/p
|x −y|1−n
p
=
C
Ã
1
m (B (x, 2 |x −y|))
Z
B(x,2|x−y|)
|∇u (z) −∇u (x) |pdz
!1/p
| x −y|.
This proves the corollary.
It may be interesting at this point to recall the deﬁnition of diﬀerentiability
on Page 115. If you knew the above inequality held for ∇u having components in
L1
loc (Rn) , then at Lebesgue points of ∇u, the above would imply Du (x) exists.
This is exactly the approach taken below.

1090
WEAK DERIVATIVES
37.5
Rademacher’s Theorem
The inequality of Corollary 37.14 can be extended to the case where u and u,i are
in Lp
loc (Rn) for p > n. This leads to an elegant proof of the diﬀerentiability a.e. of
a Lipschitz continuous function as well as a more general theorem.
Theorem 37.15 Suppose u and all its weak partial derivatives, u,i are in Lp
loc (Rn).
Then there exists a set of measure zero, E such that if x, y /∈E then inequalities
37.2 and 37.1 are both valid. Furthermore, u equals a continuous function a.e.
Proof: Let u ∈Lp
loc (Rn) and ψk ∈C∞
c (Rn) , ψk ≥0, and ψk (z) = 1 for all
z ∈B (0, k). Then it is routine to verify that
uψk, (uψk),i ∈Lp(Rn).
Here is why:
(uψk),i (φ)
≡
−
Z
Rn uψkφ,idx
=
−
Z
Rn uψkφ,idx −
Z
Rn uψk,iφdx +
Z
Rn uψk,iφdx
=
−
Z
Rn u (ψkφ),i dx +
Z
Rn uψk,iφdx
=
Z
Rn
¡
u,iψk + uψk,i
¢
φdx
which shows
(uψk),i = u,iψk + uψk,i
as expected.
Let φε be a molliﬁer and consider
(uψk)ε ≡uψk ∗φε.
By Lemma 37.11 on Page 1086,
(uψk)ε,i = (uψk),i ∗φε.
Therefore
(uψk)ε,i →(uψk),i in Lp (Rn)
(37.3)
and
(uψk)ε →uψk in Lp (Rn)
(37.4)
as ε →0. By 37.4, there exists a subsequence ε →0 such that for |z| < k and for
each i = 1, 2, · · ·, n
(uψk)ε,i (z) →(uψk),i (z) = u,i (z) a.e.

37.5.
RADEMACHER’S THEOREM
1091
(uψk)ε (z) →uψk (z) = u (z) a.e.
(37.5)
Denoting the exceptional set by Ek, let
x, y /∈∪∞
k=1Ek ≡E
and let k be so large that
B (0,k) ⊇B (x,2|x −y|).
Then by 37.1 and for x, y /∈E,
|(uψk)ε (x) −(uψk)ε (y)|
≤C
ÃZ
B(x,2|y−x|)
|∇(uψk)ε|pdz
!1/p
|x −y|(1−n/p)
where C depends only on n. Similarly, by 37.2,
|(uψk)ε (x) −(uψk)ε (y) −∇(uψk)ε (x) · (y −x)| ≤
C
Ã
1
m (B (x, 2 |x −y|))
Z
B(x,2|x−y|)
|∇(uψk)ε (z) −∇(uψk)ε (x) |pdz
!1/p
| x −y|.
Now by 37.5 and 37.3 passing to the limit as ε →0 yields
|u (x) −u (y)| ≤C
ÃZ
B(x,2|y−x|)
|∇u|pdz
!1/p
|x −y|(1−n/p)
(37.6)
and
|u (y) −u (x) −∇u (x) · (y −x)|
≤C
Ã
1
m (B (x, 2 |x −y|))
Z
B(x,2|x−y|)
|∇u (z) −∇u (x) |pdz
!1/p
| x −y|. (37.7)
Redeﬁning u on the set of mesure zero, E yields 37.6 for all x, y. This proves the
theorem.
Corollary 37.16 Let u, u,i ∈Lp
loc (Rn) for i = 1, · · ·, n and p > n.
Then the
representative of u described in Theorem 37.15 is diﬀerentiable a.e.
Proof: From Theorem 37.15
|u (y) −u (x) −∇u (x) · (y −x)|
≤C
Ã
1
m (B (x, 2 |x −y|))
Z
B(x,2|x−y|)
|∇u (z) −∇u (x) |pdz
!1/p
| x −y|. (37.8)

1092
WEAK DERIVATIVES
and at every Lebesgue point, x of ∇u
lim
y→x
Ã
1
m (B (x, 2 |x −y|))
Z
B(x,2|x−y|)
|∇u (z) −∇u (x) |pdz
!1/p
= 0
and so at each of these points,
lim
y→x
|u (y) −u (x) −∇u (x) · (y −x)|
|x −y|
= 0
which says that u is diﬀerentiable at x and Du (x) (v) = ∇u (x)·(v) . See Page 115.
This proves the corollary.
Deﬁnition 37.17 Now suppose u is Lipschitz on Rn,
|u (x) −u (y)| ≤K |x −y|
for some constant K. Deﬁne Lip (u) as the smallest value of K that works in this
inequality.
The following corollary is known as Rademacher’s theorem. It states that every
Lipschitz function is diﬀerentiable a.e.
Corollary 37.18 If u is Lipschitz continuous then u is diﬀerentiable a.e.
and
||u,i||∞≤Lip (u).
Proof: This is done by showing that Lipschitz continuous functions have weak
derivatives in L∞(Rn) and then using the previous results. Let
Dh
eiu (x) ≡h−1 [u (x + hei) −u (x)].
Then Dh
eiu is bounded in L∞(Rn) and
||Dh
eiu||∞≤Lip (u).
It follows that Dh
eiu is contained in a ball in L∞(Rn), the dual space of L1 (Rn).
By Theorem 37.3 on Page 1080, there is a subsequence h →0 such that
Dh
eiu ⇀w, ||w||∞≤Lip (u)
where the convergence takes place in the weak ∗topology of L∞(Rn). Let φ ∈
C∞
c (Rn). Then
Z
wφdx = lim
h→0
Z
Dh
eiuφdx
= lim
h→0
Z
u (x) (φ (x −hei) −φ (x))
h
dx
= −
Z
u (x) φ,i (x) dx.
Thus w = u,i and u,i ∈L∞(Rn) for each i. Hence u, u,i ∈Lp
loc (Rn) for all p > n
and so u is diﬀerentiable a.e. by Corollary 37.16. This proves the corollary.

37.6.
CHANGE OF VARIABLES FORMULA LIPSCHITZ MAPS
1093
37.6
Change Of Variables Formula Lipschitz Maps
With Rademacher’s theorem, one can give a general change of variables formula
involving Lipschitz maps.
Deﬁnition 37.19 Let E be a Lebesgue measurable set.x ∈E is a point of density
if
lim
r→0
m(E ∩B(x, r))
m(B(x, r))
= 1.
You see that if x were an interior point of E, then this limit will equal 1.
However, it is sometimes the case that the limit equals 1 even when x is not an
interior point. In fact, these points of density make sense even for sets that have
empty interior.
Lemma 37.20 Let E be a Lebesgue measurable set.
Then there exists a set of
measure zero, N, such that if x ∈E \ N, then x is a point of density of E.
Proof: Consider the function, f (x) = XE (x).
This function is in L1
loc (Rn).
Let N C denote the Lebesgue points of f. Then for x ∈E \ N,
1
=
XE (x) = lim
r→0
1
mn (B (x, r))
Z
B(x,r)
XE (y) dmn
=
lim
r→0
mn (B (x, r) ∩E)
mn (B (x, r))
.
In this section, Ωwill be a Lebesgue measurable set in Rn and h : Ω→Rn will
be Lipschitz. Recall the following deﬁnition and theorems. See Page 10.17 for the
proofs and more discussion.
Deﬁnition 37.21 Let F
be a collection of balls that cover a set, E, which have
the property that if x ∈E and ε > 0, then there exists B ∈F, diameter of B < ε
and x ∈B. Such a collection covers E in the sense of Vitali.
Theorem 37.22 Let E ⊆Rn and suppose mn(E) < ∞where mn is the outer
measure determined by mn, n dimensional Lebesgue measure, and let F, be a col-
lection of closed balls of bounded radii such that F covers E in the sense of Vitali.
Then there exists a countable collection of disjoint balls from F, {Bj}∞
j=1, such that
mn(E \ ∪∞
j=1Bj) = 0.
Now this theorem implies a simple lemma which is what will be used.
Lemma 37.23 Let V be an open set in Rr, mr (V ) < ∞.
Then there exists a
sequence of disjoint open balls {Bi} having radii less than δ and a set of measure
0, T, such that
V = (∪∞
i=1Bi) ∪T.

1094
WEAK DERIVATIVES
As in the proof of the change of variables theorem given earlier, the ﬁrst step
is to show that h maps Lebesgue measurable sets to Lebesgue measurable sets. In
showing this the key result is the next lemma which states that h maps sets of
measure zero to sets of measure zero.
Lemma 37.24 If mn (T) = 0 then mn (h (T)) = 0.
Proof: Let V be an open set containing T whose measure is less than ε. Now
using the Vitali covering theorem, there exists a sequence of disjoint balls {Bi},
Bi = B (xi, ri) which are contained in V such that the sequence of enlarged balls,
n
bBi
o
, having the same center but 5 times the radius, covers T. Then
mn (h (T)) ≤mn
³
h
³
∪∞
i=1 bBi
´´
≤
∞
X
i=1
mn
³
h
³
bBi
´´
≤
∞
X
i=1
α (n) (Lip (h))n 5nrn
i = 5n (Lip (h))n
∞
X
i=1
mn (Bi)
≤
(Lip (h))n 5nmn (V ) ≤ε (Lip (h))n 5n.
Since ε is arbitrary, this proves the lemma.
With the conclusion of this lemma, the next lemma is fairly easy to obtain.
Lemma 37.25 If A is Lebesgue measurable, then h (A) is mn measurable. Fur-
thermore,
mn (h (A)) ≤(Lip (h))n mn (A).
(37.9)
Proof: Let Ak = A ∩B (0, k) , k ∈N. Let V ⊇Ak and let mn (V ) < ∞. By
Lemma 37.23, there is a sequence of disjoint balls {Bi} and a set of measure 0, T,
such that
V = ∪∞
i=1Bi ∪T, Bi = B(xi, ri).
By Lemma 37.24,
mn (h (Ak)) ≤mn (h (V ))
≤mn (h (∪∞
i=1Bi)) + mn (h (T)) = mn (h (∪∞
i=1Bi))
≤
∞
X
i=1
mn (h (Bi)) ≤
∞
X
i=1
mn (B (h (xi) , Lip (h) ri))
≤
∞
X
i=1
α (n) (Lip (h) ri)n = Lip (h)n
∞
X
i=1
mn (Bi) = Lip (h)n mn (V ).
Therefore,
mn (h (Ak)) ≤Lip (h)n mn (V ).

37.6.
CHANGE OF VARIABLES FORMULA LIPSCHITZ MAPS
1095
Since V is an arbitrary open set containing Ak, it follows from regularity of Lebesgue
measure that
mn (h (Ak)) ≤Lip (h)n mn (Ak).
(37.10)
Now let k →∞to obtain 37.9. This proves the formula. It remains to show h (A)
is measurable.
By inner regularity of Lebesgue measure, there exists a set, F, which is the
countable union of compact sets and a set T with mn (T) = 0 such that
F ∪T = Ak.
Then h (F) ⊆h (Ak) ⊆h (F) ∪h (T). By continuity of h, h (F) is a countable
union of compact sets and so it is Borel. By 37.10 with T in place of Ak,
mn (h (T)) = 0
and so h (T) is mn measurable. Therefore, h (Ak) is mn measurable because mn
is a complete measure and this exhibits h (Ak) between two mn measurable sets
whose diﬀerence has measure 0. Now
h (A) = ∪∞
k=1h (Ak)
so h (A) is also mn measurable and this proves the lemma.
The following lemma, depending on the Brouwer ﬁxed point theorem and found
in Rudin [45], will be important for the following arguments. A slightly more precise
version was presented earlier on Page 462 but this version given below will suﬃce
in this context. The idea is that if a continuous function mapping a ball in Rk to
Rk doesn’t move any point very much, then the image of the ball must contain a
slightly smaller ball.
Lemma 37.26 Let B = B (0, r), a ball in Rk and let F : B →Rk be continuous
and suppose for some ε < 1,
|F (v) −v| < εr
for all v ∈B. Then
F
¡
B
¢
⊇B (0, r (1 −ε)).
Proof: Suppose a ∈B (0, r (1 −ε)) \ F
¡
B
¢
and let
G (v) ≡r (a −F (v))
|a −F (v)| .

1096
WEAK DERIVATIVES
Then by the Brouwer ﬁxed point theorem, G (v) = v for some v ∈B. Using the
formula for G, it follows |v| = r. Taking the inner product with v,
(G (v) , v)
=
|v|2 = r2 =
r
|a −F (v)| (a −F (v) , v)
=
r
|a −F (v)| (a −v + v −F (v) , v)
=
r
|a −F (v)| [(a −v, v) + (v −F (v) , v)]
=
r
|a −F (v)|
h
(a, v) −|v|2 + (v −F (v) , v)
i
≤
r
|a −F (v)|
£
r2 (1 −ε) −r2+r2ε
¤
= 0,
a contradiction. Therefore, B (0, r (1 −ε)) \ F
¡
B
¢
= ∅and this proves the lemma.
Now let Ωbe a Lebesgue measurable set and suppose h : Rn →Rn is Lipschitz
continuous and one to one on Ω. Let
N ≡{x ∈Ω: Dh (x) does not exist}
(37.11)
S ≡
n
x ∈Ω\ N : Dh (x)−1 does not exist
o
(37.12)
Lemma 37.27 Let x ∈Ω\ (S ∪N). Then if ε ∈(0, 1) the following hold for all r
small enough.
mn
³
h
³
B (x,r)
´´
≥mn (Dh (x) B (0, r (1 −ε))),
(37.13)
h (B (x, r)) ⊆h (x) + Dh (x) B (0, r (1 + ε)),
(37.14)
mn
³
h
³
B (x,r)
´´
≤mn (Dh (x) B (0, r (1 + ε)))
(37.15)
If x ∈Ω\ (S ∪N) is also a point of density of Ω, then
lim
r→0
mn (h (B (x, r) ∩Ω))
mn (h (B (x, r)))
= 1.
(37.16)
If x ∈Ω\ N, then
|det Dh (x)| = lim
r→0
mn (h (B (x, r)))
mn (B (x,r))
a.e.
(37.17)
Proof: Since Dh (x)−1 exists,
h (x + v)
=
h (x) + Dh (x) v+o (|v|)
(37.18)
=
h (x) + Dh (x)



v+
=o(|v|)
z
}|
{
Dh (x)−1 o (|v|)




(37.19)

37.6.
CHANGE OF VARIABLES FORMULA LIPSCHITZ MAPS
1097
Consequently, when r is small enough, 37.14 holds. Therefore, 37.15 holds. From
37.19, and the assumption that Dh (x)−1 exists,
Dh (x)−1 h (x + v) −Dh (x)−1 h (x) −v =o(|v|).
(37.20)
Letting
F (v) = Dh (x)−1 h (x + v) −Dh (x)−1 h (x),
apply Lemma 37.26 in 37.20 to conclude that for r small enough, whenever |v| < r,
Dh (x)−1 h (x + v) −Dh (x)−1 h (x) ⊇B (0, (1 −ε) r).
Therefore,
h
³
B (x,r)
´
⊇h (x) + Dh (x) B (0, (1 −ε) r)
which implies
mn
³
h
³
B (x,r)
´´
≥mn (Dh (x) B (0, r (1 −ε)))
which shows 37.13.
Now suppose that x is a point of density of Ωas well as being a point where
Dh (x)−1 and Dh (x) exist. Then whenever r is small enough,
1 −ε < mn (h (B (x, r) ∩Ω))
mn (h (B (x, r)))
≤1
and so
1 −ε
<
mn
¡
h
¡
B (x, r) ∩ΩC¢¢
mn (h (B (x, r)))
+ mn (h (B (x, r) ∩Ω))
mn (h (B (x, r)))
≤
mn
¡
h
¡
B (x, r) ∩ΩC¢¢
mn (h (B (x, r)))
+ 1.
which implies
mn (B (x,r) \ Ω) < εα (n) rn.
(37.21)
Then for such r,
1 ≥mn (h (B (x, r) ∩Ω))
mn (h (B (x, r)))
≥mn (h (B (x, r))) −mn (h (B (x,r) \ Ω))
mn (h (B (x, r)))
.
From Lemma 37.25, 37.21, and 37.13, this is no larger than
1 −
Lip (h)n εα (n) rn
mn (Dh (x) B (0, r (1 −ε))).

1098
WEAK DERIVATIVES
By the theorem on the change of variables for a linear map, this expression equals
1 −
Lip (h)n εα (n) rn
|det (Dh (x))| rnα (n) (1 −ε)n ≡1 −g (ε)
where limε→0g (ε) = 0. Then for all r small enough,
1 ≥mn (h (B (x, r) ∩Ω))
mn (h (B (x, r)))
≥1 −g (ε)
which shows 37.16 since ε is arbitrary. It remains to verify 37.17.
In case x ∈S, for small |v| ,
h (x + v) = h (x) + Dh (x) v+o (|v|)
where |o (|v|)| < ε |v| . Therefore, for small enough r,
h (B (x, r)) −h (x) ⊆K + B (0, rε)
where K is a compact subset of an n−1 dimensional subspace contained in Dh (x) (Rn)
which has diameter no more than 2 ||Dh (x)|| r. By Lemma 10.33 on Page 285,
mn (h (B (x, r)))
=
mn (h (B (x, r)) −h (x))
≤
2nεr (2 ||Dh (x)|| r + rε)n−1
and so, in this case, letting r be small enough,
mn (h (B (x, r)))
mn (B (x,r))
≤2nεr (2 ||Dh (x)|| r + rε)n−1
α (n) rn
≤Cε.
Since ε is arbitrary, the limit as r →0 of this quotient equals 0.
If x /∈S, use 37.13 - 37.15 along with the change of variables formula for linear
maps. This proves the Lemma.
Since h is one to one, there exists a measure, µ, deﬁned by
µ (E) ≡mn (h (E))
on the Lebesgue measurable subsets of Ω. By Lemma 37.25 µ ≪mn and so by the
Radon Nikodym theorem, there exists a nonnegative function, J (x) in L1
loc (Rn)
such that whenever E is Lebesgue measurable,
µ (E) = mn (h (E ∩Ω)) =
Z
E∩Ω
J (x) dmn.
(37.22)
Extend J to equal zero oﬀΩ.
Lemma 37.28 The function, J (x) equals |det Dh (x)| a.e.

37.6.
CHANGE OF VARIABLES FORMULA LIPSCHITZ MAPS
1099
Proof: Deﬁne
Q ≡{x ∈Ω: x is not a point of density of Ω} ∪N∪
{x ∈Ω: x is not a Lebesgue point of J}.
Then Q is a set of measure zero and if x /∈Q, then by 37.17, and 37.16,
|det Dh (x)|
=
lim
r→0
mn (h (B (x, r)))
mn (B (x, r))
=
lim
r→0
mn (h (B (x, r)))
mn (h (B (x, r) ∩Ω))
mn (h (B (x, r) ∩Ω))
mn (B (x, r))
=
lim
r→0
1
mn (B (x, r))
Z
B(x,r)∩Ω
J (y) dmn
=
lim
r→0
1
mn (B (x, r))
Z
B(x,r)
J (y) dmn = J (x) .
the last equality because J was extended to be zero oﬀΩ. This proves the lemma.
Here is the change of variables formula for Lipschitz mappings. It is a special
case of the area formula.
Theorem 37.29 Let Ωbe a Lebesgue measurable set, let f ≥0 be Lebesgue mea-
surable. Then for h a Lipschitz mapping deﬁned on Rn which is one to one on
Ω,
Z
h(Ω)
f (y) dmn =
Z
Ω
f (h (x)) |det Dh (x)| dmn.
(37.23)
Proof: Let F be a Borel set. It follows that h−1 (F) is a Lebesgue measurable
set. Therefore, by 37.22,
mn
¡
h
¡
h−1 (F) ∩Ω
¢¢
(37.24)
=
Z
h(Ω)
XF (y) dmn =
Z
Ω
Xh−1(F ) (x) J (x) dmn
=
Z
Ω
XF (h (x)) J (x) dmn.
What if F is only Lebesgue measurable? Note there are no measurability problems
with the above expression because x →XF (h (x)) is Borel measurable due to the
assumption that h is continuous while J is given to be Lebesgue measurable. How-
ever, if F is Lebesgue measurable, not necessarily Borel measurable, then it is no
longer clear that x →XF (h (x)) is measurable. In fact this is not always even true.
However, x →XF (h (x)) J (x) is measurable and 37.24 holds.
Let F be Lebesgue measurable. Then by inner regularity, F = H ∪N where N
has measure zero, H is the countable union of compact sets so it is a Borel set, and

1100
WEAK DERIVATIVES
H ∩N = ∅. Therefore, letting N ′ denote a Borel set of measure zero which contains
N,
b (x) ≡XH (h (x)) J (x) ≤XF (h (x)) J (x)
=
XH (h (x)) J (x) + XN (h (x)) J (x)
≤
XH (h (x)) J (x) + XN′ (h (x)) J (x) ≡u (x)
Now since N ′ is Borel,
Z
Ω
(u (x) −b (x)) dmn =
Z
Ω
XN ′ (h (x)) J (x) dmn
= mn
¡
h
¡
h−1 (N ′) ∩Ω
¢¢
= mn (N ′ ∩h (Ω)) = 0
and this shows XH (h (x)) J (x) = XF (h (x)) J (x) except on a set of measure zero.
By completeness of Lebesgue measure, it follows x →XF (h (x)) J (x) is Lebesgue
measurable and also since h maps sets of measure zero to sets of measure zero,
Z
Ω
XF (h (x)) J (x) dmn
=
Z
Ω
XH (h (x)) J (x) dmn
=
Z
h(Ω)
XH (y) dmn
=
Z
h(Ω)
XF (y) dmn.
It follows that if s is any nonnegative Lebesgue measurable simple function,
Z
Ω
s (h (x)) J (x) dmn =
Z
h(Ω)
s (y) dmn
(37.25)
and now, if f ≥0 is Lebesgue measurable, let sk be an increasing sequence of
Lebesgue measurable simple functions converging pointwise to f. Then since 37.25
holds for sk, the monotone convergence theorem applies and yields 37.23.
This
proves the theorem.
It turns out that a Lipschitz function deﬁned on some subset of Rn always has a
Lipschitz extension to all of Rn. The next theorem gives a proof of this. For more
on this sort of theorem see Federer [22]. He gives a better but harder theorem than
what follows.
Theorem 37.30 If h : Ω→Rm is Lipschitz, then there exists h : Rn →Rm which
extends h and is also Lipschitz.
Proof: It suﬃces to assume m = 1 because if this is shown, it may be applied
to the components of h to get the desired result. Suppose
|h (x) −h (y)| ≤K |x −y|.
(37.26)

37.6.
CHANGE OF VARIABLES FORMULA LIPSCHITZ MAPS
1101
Deﬁne
h (x) ≡inf{h (w) + K |x −w| : w ∈Ω}.
(37.27)
If x ∈Ω, then for all w ∈Ω,
h (w) + K |x −w| ≥h (x)
by 37.26. This shows h (x) ≤h (x). But also you could take w = x in 37.27 which
yields h (x) ≤h (x). Therefore h (x) = h (x) if x ∈Ω.
Now suppose x, y ∈Rn and consider
¯¯h (x) −h (y)
¯¯. Without loss of gener-
ality assume h (x) ≥h (y) . (If not, repeat the following argument with x and y
interchanged.) Pick w ∈Ωsuch that
h (w) + K |y −w| −ε < h (y).
Then
¯¯h (x) −h (y)
¯¯ = h (x) −h (y) ≤h (w) + K |x −w| −
[h (w) + K |y −w| −ε] ≤K |x −y| + ε.
Since ε is arbitrary,
¯¯h (x) −h (y)
¯¯ ≤K |x −y|
and this proves the theorem.
This yields a simple corollary to Theorem 37.29.
Corollary 37.31 Let h : Ω→Rn be Lipschitz continuous and one to one where Ω
is a Lebesgue measurable set. Then if f ≥0 is Lebesgue measurable,
Z
h(Ω)
f (y) dmn =
Z
Ω
f (h (x))
¯¯det Dh (x)
¯¯ dmn.
(37.28)
where h denotes a Lipschitz extension of h.

1102
WEAK DERIVATIVES

The Area And Coarea
Formulas
38.1
The Area Formula Again
Recall the area formula presented earlier. For convenience, here it is.
Theorem 38.1 Let g : h (A) →[0, ∞] be Hn measurable where h is a continuous
function and A is a Lebesgue measurable set which satisﬁes 17.8 - 17.10. That is,
U is an open set in Rn on which h is deﬁned and A ⊆U is a Lebesgue measurable
set, m ≥n, and
h : U →Rm is continuous,
(38.1)
Dh (x) exists for all x ∈A,
(38.2)
Also assume that for every x ∈A, there exists rx and Lx such that for all y, z ∈
B (x, rx) ,
|h (z) −h (y)| ≤Lx |x −y|
(38.3)
Then
x →(g ◦h) (x) J (x)
is Lebesgue measurable and
Z
h(A)
g (y) dHn =
Z
A
g (h (x)) J (x) dm
where J (x) = det (U (x)) = det
¡
Dh (x)∗Dh (x)
¢1/2.
Obviously, one can obtain improved versions of this important theorem by using
Rademacher’s theorem and condition 38.3. As mentioned earlier, a function which
satisﬁes 38.3 is called locally Lipschitz at x. Here is a simple lemma which is in the
spirit of similar lemmas presented in the chapter on Hausdorﬀmeasures.
Lemma 38.2 Let U be an open set in Rn and let h : U →Rm where m ≥n.
Let A ⊆U and let h be locally Lipschitz at every point of A. Then if N ⊆A has
Lebesgue measure zero, it follows that Hn (h (N)) = 0.
1103

1104
THE AREA AND COAREA FORMULAS
Proof: Let Nk be deﬁned as
Nk ≡{x ∈N : for some Rx > 0, |h (z) −h (y)| ≤k |z −y| for all y, z ∈B (x,Rx)}
Thus Nk ↑N. Let ε > 0 be given and let U ⊇Vk ⊇N be open and mn (Vk) <
ε
5nkn .
Now ﬁx δ > 0. For x ∈Nk let B (x, 5rx) ⊆Vk such that rx < min
¡ δ
5k, Rx
¢
. By
the Vitali covering theorem, there exists a disjoint sequence of these balls, {Bi}∞
i=1
such that
n
c
Bi
o∞
i=1 , the corresponding sequence of balls having the same centers
but ﬁve times the radius covers Nk. Then diam
³
c
Bi
´
< 2δ/k. Hence
n
h
³
c
Bi
´o∞
i=1
covers h (Nk) and diam
³
h
³
c
Bi
´´
< 2δ. It follows
Hn
2δ (h (Nk))
≤
∞
X
i=1
α (n) r
³
h
³
c
Bi
´´n
≤
∞
X
i=1
α (n) kn5nr (Bi)n
=
5nkn
∞
X
i=1
mn (Bi) ≤5nknmn (Vk) < ε
Since δ was arbitrary, this shows Hn (h (Nk)) ≤ε. Since k was arbitrary, this
shows Hn (h (N)) = limk→∞Hn (h (Nk)) ≤ε. Since ε is arbitrary, this shows
Hn (h (N)) = 0. This proves the lemma.
Now with this lemma, here is one of many possible generalizations of the area
formula.
Theorem 38.3 Let U be an open set in Rn and h : U →Rm. Let h be locally
Lipschitz and one to one on A, a Lebesgue measurable subset of U and let g :
h (A) →R be a nonnegative Hn measurable function. Then
x →(g ◦h) (x) J (x)
is Lebesgue measurable and
Z
h(A)
g (y) dHn =
Z
A
g (h (x)) J (x) dmn
where J (x) = det (U (x)) = det
¡
Dh (x)∗Dh (x)
¢1/2.
Proof:
For x ∈A, there exists a ball, Bx on which h is Lipschitz.
By
Rademacher’s theorem, h is diﬀerentiable a.e. on Bx. There is a countable cover
of A consisting of such balls on which h is Lipschitz. Therefore, h is diﬀerentiable
on A0 ⊆A where mn (A \ A0) = 0. Then by the earlier area formula,
Z
h(A0)
g (y) dHn =
Z
A0
g (h (x)) J (x) dmn

38.1.
THE AREA FORMULA AGAIN
1105
By Lemma 38.2
Z
h(A)
g (y) dHn
=
Z
h(A0)
g (y) dHn
=
Z
A0
g (h (x)) J (x) dmn =
Z
A
g (h (x)) J (x) dmn
This proves the theorem.
Note how a special case of this occurs when h is one to one and C1. Of course
this yields the earlier change of variables formula as a still more special case.
In addition to this, recall the divergence theorem, Theorem 17.50 on Page 492.
This theorem was stated for bounded open sets which have a Lipschitz boundary.
This deﬁnition of Lipschitz boundary involved an assumption that certain Lips-
chitz mappings had a derivative a.e. Rademacher’s theorem makes this assumption
redundant. Therefore, the statement of Theorem 17.50 remains valid with the fol-
lowing deﬁnition of a Lipschitz boundary.
Deﬁnition 38.4 A bounded open set, U ⊆Rn is said to have a Lipschitz boundary
and to lie on one side of its boundary if the following conditions hold. There exist
open boxes, Q1, · · ·, QN ,
Qi =
n
Y
j=1
¡
ai
j, bi
j
¢
such that ∂U ≡U \ U is contained in their union. Also, for each Qi, there exists k
and a Lipschitz function, gi such that U ∩Qi is of the form


x : (x1, · · ·, xk−1, xk+1, · · ·, xn) ∈
k−1
Y
j=1
¡
ai
j, bi
j
¢
×
n
Y
j=k+1
¡
ai
j, bi
j
¢
and ai
k < xk < gi (x1, · · ·, xk−1, xk+1, · · ·, xn)



(38.4)
or else of the form


x : (x1, · · ·, xk−1, xk+1, · · ·, xn) ∈
k−1
Y
j=1
¡
ai
j, bi
j
¢
×
n
Y
j=k+1
¡
ai
j, bi
j
¢
and gi (x1, · · ·, xk−1, xk+1, · · ·, xn) < xk < bi
j


.
(38.5)
Also, there exists an open set, Q0 such that Q0 ⊆Q0 ⊆U and U ⊆Q0∪Q1∪···∪QN.

1106
THE AREA AND COAREA FORMULAS
38.2
Mappings That Are Not One To One
Next I will consider the case where h is not necessarily one to one.
Recall the
major theorem presented earlier on which the proof of the area formula depended,
Theorem 17.25 on Page 466. Here it is.
Theorem 38.5 Let h : U →Rm where U is an open set in Rn for n ≤m and
suppose h is locally Lipschitz at every point of a Lebesgue measurable subset, A of
U. Also suppose that for every x ∈A, Dh (x) exists. Then for x ∈A,
J (x) = lim
r→0
Hn (h (B (x, r)))
mn (B (x,r))
,
(38.6)
where J (x) ≡det (U (x)) = det
¡
Dh (x)∗Dh (x)
¢1/2.
The next lemma is a version of Sard’s lemma.
Lemma 38.6 Let h : U →Rm where U is an open set in Rn for n ≤m and
suppose h is locally Lipschitz at every point of a Lebesgue measurable subset, A of
U. Let
N ≡{x ∈A : Dh (x) does not exist}
(38.7)
and let
S ≡{x ∈A0 ≡A \ N : J (x) = 0}
(38.8)
Then Hn (h (S ∪N)) = 0.
Proof: By Rademacher’s theorem, N has measure 0. Therefore, Hn (h (N)) = 0
by Lemma 38.2.
It remains to show Hn (h (S)) = 0. Let Sk = B (0, k)∩S for k a positive integer
large enough that Sk ̸= ∅. By Theorem 17.25 on Page 466 stated above, if x ∈Sk,
there exists rx such that 5rx < min (Rx, 1) and if r ≤5rx,
Hn (h (B (x, r)))
mn (B (x,r))
<
ε
5nkn , B (x, r) ⊆B (0,k) ∩U
(38.9)
Then by the Vitali covering theorem, there exists a sequence of disjoint balls of this
sort, {Bi}∞
i=1 such that the balls having 5 times the radius but the same center,
n
c
Bi
o∞
i=1 cover Sk. Then
n
h
³
c
Bi
´o∞
i=1 covers h (Sk) . Then from 38.9
Hn (h (Sk))
≤
∞
X
i=1
Hn ³
h
³
c
Bi
´´
≤
∞
X
i=1
5nHn (h (Bi))
≤
∞
X
i=1
5n
ε
5nkn mn (Bi) ≤ε
kn mn (B (0, k)) = εα (n)
Since ε > 0 is arbitrary, it follows Hn (h (Sk)) = 0 and now letting k →0, it follows
Hn (h (S)) = 0. This proves the lemma.
The following very technical lemma provides the necessary theory to generalize
to functions which are not one to one.

38.2.
MAPPINGS THAT ARE NOT ONE TO ONE
1107
Lemma 38.7 Let h : U →Rm where U is an open set in Rn for n ≤m and
suppose h is locally Lipschitz at every point of a Lebesgue measurable subset, A of
U. Let
N ≡{x ∈A : Dh (x) does not exist}
and let
S ≡{x ∈A0 ≡A \ N : J (x) = 0}
Let B = A \ (S ∪N) . Then there exist measurable disjoint sets, {Ei}∞
i=1 such that
A = ∪∞
i=1Ei and h is one to one on Ei. Furthermore, h−1 is Lipschitz on h (Ei) .
Proof:
Let C be a dense countable subset of B and let F be a countable
dense subset of the invertible elements of L (Rn, Rn). For i a positive integer and
T ∈F, c ∈C
E (c, T, i) ≡
½
b ∈B
µ
c, 1
i
¶
∩B : (a) , (b) both hold
¾
where (a) , (b) are given by
2
3 |Tv| ≤|U (b) v| for all v
(a)
|h (a) −h (b) −Dh (b) (a −b)| ≤1
2 |T (a −b)| .
(b)
for all a ∈B
¡
b, 2
i
¢
.
a
2
i
6
1
i ¡
¡
ª
b r
c
r
First I will show these sets, E (c, T, i) cover B and that they are measurable
sets. To begin with consider the measurability question. Inequality (a) is the same
as saying
2
3 |Tv| ≤|Dh (b) v| for all v
which is the same as saying
2
3 |v| ≤
¯¯Dh (b) T −1v
¯¯ for all v.

1108
THE AREA AND COAREA FORMULAS
Let {vi} denote a dense countable subset of Rn. Letting
Si ≡
½
b : 2
3 |vi| ≤
¯¯Dh (b) T −1vi
¯¯
¾
it follows easily that Si is measurable because the component functions of the matrix
of Dh (b) are limits of diﬀerence quotients of continuous functions so they are Borel
measurable. (Note that if B were Borel, then Si would also be Borel.) Now by
continuity,
∪∞
i=1Si =
½
b : 2
3 |v| ≤
¯¯Dh (b) T −1v
¯¯ for all v
¾
and so this set is measurable also. Inequality (b) also determines a measurable set
by similar reasoning. It is the same as saying that for all |v| < 2/i,
|h (b + v) −h (b) −Dh (b) (v)| ≤1
2 |T (v)|
Use {vi} a countable dense subset of B (0,2/i) in a similar fashion to (a) .
Next I need to show these sets cover B. Let x ∈B. Then pick ci ∈B
¡
x, 1
i
¢
and
Ti ∈B
¡
U (x) , 1
i
¢
. I need to show that x ∈E (ci, Ti, i) for i large enough. For i
large enough,
¯¯¯
¯¯¯TiU (x)−1¯¯¯
¯¯¯ < 3
2. Therefore, for such i
¯¯¯TiU (x)−1 (v)
¯¯¯ < 3
2 |v|
for all v and so
|Tiw| < 3
2 |U (x) w|
for all w. Next consider (b). An equivalent norm is v →|U (x) v| and so, for i large
enough,
|h (a) −h (x) −Dh (x) (a −x)| ≤1
8 |U (x) (a −x)|
(38.10)
whenever |a −x| < 2/i. Now also, for i large enough,
¯¯¯¯U (x) T −1
i
¯¯¯¯ < 4 and so for
all w,
¯¯U (x) T −1
i
w
¯¯ < 4 |w|
which implies
|U (x) v| < 4 |Tiv| .
Applying this in 38.10 yields
|h (a) −h (x) −Dh (x) (a −x)| ≤1
2 |Ti (a −x)|
with implies x ∈E (ci, Ti, i) .

38.2.
MAPPINGS THAT ARE NOT ONE TO ONE
1109
Next I need to show h is one to one on E (c, T, i) . Suppose b1, b2 ∈E (c, T, i) .
From (b) and (a) ,
|T (b2 −b1)|
≤
3
2 |U (b1) (b2 −b1)| = 3
2 |Dh (b1) (b2−b1)|
≤
3
2
1
2 |T (b2 −b1)|
which is a contradiction unless b2 = b1.
There are clearly countably many E (c, T, i) . Denote them as {Fi}∞
i=1 . Then let
E1 = F1 and if E1, · · ·, Em have been chosen, let
Em+1 = Fm+1 \ ∪m
i=1Ei.
Thus the Ei are disjoint measurable sets whose union is B and h is one to one on
each Ei.
Now consider one of the Ei. This is a subset of some E (c, T, i) . Let a, b ∈Ei.
Then using (a) and (b) ,
|T (a −b)|
≤
3
2 |U (b) (a −b)|
=
3
2 |Dh (b) (a −b)|
≤
3
2 |h (a) −h (b)| + 3
4 |T (a −b)| .
Hence
1
4 |T (a −b)| ≤3
2 |h (a) −h (b)|
Since v →|Tv| is an equivalent norm, there exists some r > 0 such that |Tv| ≥r |v|
for all v. Therefore,
|a −b| ≤6
r |h (a) −h (b)| .
In other words,
¯¯h−1 (h (a)) −h−1 (h (b))
¯¯ = |a −b| ≤6
r |h (a) −h (b)| .
which completes the proof.
With these lemmas, here is the main theorem which is a generalization of The-
orem 38.3. First remember that from Lemma 17.18 on Page 462 a locally Lipschitz
function maps Lebesgue measurable sets to Hausdorﬀmeasurable sets.
Theorem 38.8 Let U be an open set in Rn and h : U →Rm. Let h be locally
Lipschitz on A, a Lebesgue measurable subset of U and let g : h (A) →R be a
nonnegative Hn measurable function. Also let
# (y) ≡Number of elements of h−1 (y)

1110
THE AREA AND COAREA FORMULAS
Then # is Hn measurable,
x →(g ◦h) (x) J (x)
is Lebesgue measurable, and
Z
h(A)
# (y) g (y) dHn =
Z
A
g (h (x)) J (x) dmn
where J (x) = det (U (x)) = det
¡
Dh (x)∗Dh (x)
¢1/2.
Proof: Let B = A \ (S ∪N) where S is the set of points where J (x) = 0 and
N is the set of points, x of A where Dh (x) does not exist. Also from Lemma 38.7
there exists {Ei}∞
i=1, a sequence of disjoint measurable sets whose union equals B
such that h is one to one on each Ei. Then from Theorem 38.3
Z
A
g (h (x)) J (x) dmn
=
Z
B
g (h (x)) J (x) dmn =
∞
X
i=1
Z
Ei
g (h (x)) J (x) dmn
=
∞
X
i=1
Z
h(Ei)
g (y) dHn =
Z
h(B)
Ã ∞
X
i=1
Xh(Ei) (y)
!
g (y) dHn.
(38.11)
Now # (y) =
¡P∞
i=1 Xh(Ei) (y)
¢
on h (B) and # diﬀers from this Hn measurable
function only on h (S ∪N) , which by Lemma 38.6 is a set of Hn measure zero.
Therefore, # is Hn measurable and the last term of 38.11 equals
Z
h(A)
Ã ∞
X
i=1
Xh(Ei) (y)
!
g (y) dHn =
Z
h(A)
# (y) g (y) dHn.
This proves the theorem.
38.3
The Coarea Formula
The coarea formula involves a function, h which maps a subset of Rn to Rm where
m ≤n instead of m ≥n as in the area formula. The symbol, Lip (h) will denote
the Lipschitz constant for h.
It is possible to obtain the coarea formula as a computation involving the area
formula and some simple linear algebra and this is the approach taken here. To
begin with, here is the necessary linear algebra.
Theorem 38.9 Let A be an m×n matrix and let B be an n×m matrix for m ≤n.
Then
pBA (t) = tn−mpAB (t) ,
so the eigenvalues of BA and AB are the same including multiplicities except that
BA has n −m extra zero eigenvalues.

38.3.
THE COAREA FORMULA
1111
Proof: Use block multiplication to write
µ
AB
0
B
0
¶ µ
I
A
0
I
¶
=
µ
AB
ABA
B
BA
¶
µ
I
A
0
I
¶ µ
0
0
B
BA
¶
=
µ
AB
ABA
B
BA
¶
.
Therefore,
µ
I
A
0
I
¶−1 µ
AB
0
B
0
¶ µ
I
A
0
I
¶
=
µ
0
0
B
BA
¶
It follows that
µ
0
0
B
BA
¶
and
µ
AB
0
B
0
¶
have the same characteristic polyno-
mials because the two matrices are simlar. Thus
det
µ
tI −AB
0
−B
tI
¶
= det
µ
tI
0
−B
tI −BA
¶
and so noting that BA is an n × n matrix and AB is an m × m matrix,
tm det (tI −BA) = tn det (tI −AB)
and so det (tI −BA) = pBA (t) = tn−m det (tI −AB) = tn−mpAB (t) . This proves
the theorem.
The following corollary is what will be used to prove the coarea formula.
Corollary 38.10 Let A be an m × n matrix. Then
det (I + AA∗) = det (I + A∗A) .
Proof: Assume m ≤n. From Theorem 38.9 AA∗and A∗A have the eigenval-
ues, λ1, · · .λm, necessarily nonnegative, with the same multiplicities and some zero
eigenvalues which have diﬀering multiplicities. The eigenvalues, λ1, · · .λm are the
zeros of pAA∗(t) . Thus there is an orthogonal transformation, P such that
A∗A = P










λ1
...
0
λm
0
0
...
0










P ∗.
Therefore,
I + A∗A = P










λ1 + 1
...
0
λm + 1
1
0
...
1










P ∗

1112
THE AREA AND COAREA FORMULAS
and so
det (I + A∗A) = det



λ1 + 1
0
...
0
λm + 1


= det (I + AA∗) .
This proves the corollary.
The other main ingredient is the following version of the chain rule.
Theorem 38.11 Let h and g be locally Lipschitz mappings from Rn to Rn with
h (g (x)) = x on A, a Lebesgue measurable set. Then for a.e. x ∈A, Dg (h (x)),
Dh (x), and D (h ◦g) (x) all exist and
I = D (g ◦h) (x) = Dg (h (x)) Dh (x).
The proof of this theorem is based on the following lemma.
Lemma 38.12 If h : Rn →Rn is locally Lipschitz, then if h (x) = 0 for all x ∈
A, then det (Dh (x)) = 0 a.e.
Proof: By the case of the Area formula which involves mappings which are not
one to one, 0 =
R
{0} # (y) dy =
R
A |det (Dh (x))| dx and so det (Dh (x)) = 0 a.e.
Proof of the theorem: On A, g (h (x)) −x = 0 and so by the lemma, there
exists a set of measure zero, N1 such that if x /∈N1, D (g ◦h) (x) −I = 0. Let M
be the set of measure zero of points in h (Rn) where g fails to be diﬀerentiable and
let N2 ≡g (M) ∩A, also a set of measure zero because locally Lipschitz maps take
sets of measure zero to sets of measure zero. Finally let N3 be the set of points
where h fails to be diﬀerentiable. Then if x /∈N1 ∪N2 ∪N3, the chain rule implies
I = D (g ◦h) (x) = Dg (h (x)) Dh (x). This proves the theorem.
Lemma 38.13 Let h : Rp →Rm be Lipschitz continuous and δ > 0.
Then if
A ⊆Rp is either open or compact,
y →Hs
δ
¡
A ∩h−1 (y)
¢
is Borel measurable.
Proof: Suppose ﬁrst that A is compact and suppose for δ > 0,
Hs
δ
¡
A ∩h−1 (y)
¢
< t
Then there exist sets Si, satisfying
diam (Si) < δ, A ∩h−1 (y) ⊆∪∞
i=1Si,
and
∞
X
i=1
α (s) (r (Si))s < t.

38.3.
THE COAREA FORMULA
1113
I claim these sets can be taken to be open sets. Choose λ > 1 but close enough to
1 that
∞
X
i=1
α (s) (λr (Si))s < t
Replace Si with Si + B (0, ηi) where ηi is small enough that
diam (Si) + 2ηi < λ diam (Si) .
Then
diam (Si + B (0, ηi)) ≤λ diam (Si)
and so r (Si + B (0, ηi)) ≤λr (Si) . Thus
∞
X
i=1
α (s) r (Si + B (0, ηi))s < t.
Hence you could replace Si with Si + B (0, ηi) and so one can assume the sets Si
are open.
Claim: If z is close enough to y, then A ∩h−1 (z) ⊆∪∞
i=1Si.
Proof: If not, then there exists a sequence {zk} such that
zk →y,
and
xk ∈(A ∩h−1 (zk)) \ ∪∞
i=1Si.
By compactness of A, there exists a subsequence still denoted by k such that
zk →y, xk →x ∈A \ ∪∞
i=1Si.
Hence
h (x) = lim
k→∞h (xk) = lim
k→∞zk = y.
But x /∈∪∞
i=1Si contrary to the assumption that A ∩h−1 (y) ⊆∪∞
i=1Si.
It follows from this claim that whenever z is close enough to y,
Hs
δ
¡
A ∩h−1 (z)
¢
< t.
This shows
©
z ∈Rp : Hs
δ
¡
A ∩h−1 (z)
¢
< t
ª
is an open set and so y →Hs
δ
¡
A ∩h−1 (y)
¢
is Borel measurable whenever A is
compact. Now let V be an open set and let
Ak ↑V, Ak compact.
Then
Hs
δ
¡
V ∩h−1 (y)
¢
= lim
k→∞Hs
δ
¡
Ak ∩h−1 (y)
¢
so y →Hs
δ
¡
V ∩h−1 (y)
¢
is Borel measurable for all V open. This proves the lemma.

1114
THE AREA AND COAREA FORMULAS
Lemma 38.14 Let h : Rp →Rm be Lipschitz continuous. Suppose A is either open
or compact in Rp. Then y →Hs ¡
A ∩h−1 (y)
¢
is also Borel measurable and
Z
Rm Hs ¡
A ∩h−1 (y)
¢
dy ≤2m (Lip (h))m α (s) α (m)
α (s + m) Hs+m (A)
In particular, if s = n −m and p = n
Z
Rm Hn−m ¡
A ∩h−1 (y)
¢
dy ≤2m (Lip (h))m α (n −m) α (m)
α (n)
mn (A)
Proof: From Lemma 38.13 y →Hs
δ
¡
A ∩h−1 (y)
¢
is Borel measurable for each
δ > 0. Without loss of generality, Hs+m (A) < ∞. Now let Bi be closed sets with
diam (Bi) < δ, A ⊆∪∞
i=1Bi, and
Hs+m
δ
(A) + ε >
∞
X
i=1
α (s + m) r (Bi)s+m .
Note each Bi is compact so y →Hs
δ
¡
Bi ∩h−1 (y)
¢
is Borel measurable. Thus
Z
Rm Hs
δ
¡
A ∩h−1 (y)
¢
dy
≤
Z
Rm
X
i
Hs
δ
¡
Bi ∩h−1 (y)
¢
dy
=
X
i
Z
Rm Hs
δ
¡
Bi ∩h−1 (y)
¢
dy
≤
X
i
Z
h(Bi)
Hs
δ (Bi) dy
=
X
i
mm (h (Bi)) Hs
δ (Bi)
≤
X
i
(Lip (h))m 2mα (m) r (Bi)m α (s) r (Bi)s
=
(Lip (h))m α (m) α (s)
α (m + s) 2m X
i
α (s + m) r (Bi)m+s
≤
(Lip (h))m α (m) α (s)
α (m + s) 2mHs+m (A)
Taking a limit as δ →0 this proves the lemma.
Next I will show that whenever A is Lebesgue measurable,
y →Hn−m ¡
A ∩h−1 (y)
¢
is mm measurable and the above estimate holds.

38.3.
THE COAREA FORMULA
1115
Lemma 38.15 Let A be a Lebesgue measurable subset of Rn and let h : Rn →Rm
be Lipschitz. Then
y →Hn−m ¡
A ∩h−1 (y)
¢
is Lebesgue measurable. Furthermore, for all A Lebesgue measurable,
Z
Rm Hn−m ¡
A ∩h−1 (y)
¢
dy ≤2m (Lip (h))m α (n −m) α (m)
α (n)
mn (A)
Proof: Let A be a bounded Lebesgue measurable set in Rn. Then by inner and
outer regularity of Lebesgue measure there exists an increasing sequence of compact
sets, {Kk} contained in A and a decreasing sequence of open sets, {Vk} containing
A such that mn (Vk \ Kk) < 2−k. Thus mn (V1) ≤mn (A) + 1. By Lemma 38.14
Z
Rm Hn−m
δ
¡
V1 ∩h−1 (y)
¢
dy < 2m (Lip (h))m α (n −m) α (m)
α (n)
(mn (A) + 1) .
Then
Hn−m
δ
¡
Kk ∩h−1 (y)
¢
≤Hn−m
δ
¡
A ∩h−1 (y)
¢
≤Hn−m
δ
¡
Vk ∩h−1 (y)
¢
(38.12)
By Lemma 38.14
=
Z
Rm
¡
Hn−m
δ
¡
Vk ∩h−1 (y)
¢
−Hn−m
δ
¡
Kk ∩h−1 (y)
¢¢
dy
=
Z
Rm Hn−m
δ
¡
(Vk −Kk) ∩h−1 (y)
¢
dy
≤
2m (Lip (h))m α (n −m) α (m)
α (n)
mn (Vk \ Kk)
<
2m (Lip (h))m α (n −m) α (m)
α (n)
2−k
Let the Borel measurable functions, g and f be deﬁned by
g (y) ≡lim
k→∞Hn−m
δ
¡
Vk ∩h−1 (y)
¢
, f (y) ≡lim
k→∞Hn−m
δ
¡
Kk ∩h−1 (y)
¢
It follows from the dominated convergence theorem and 38.12 that
f (y) ≤Hn−m
δ
¡
A ∩h−1 (y)
¢
≤g (y)
and
Z
Rm (g (y) −f (y)) dy = 0.
By completness of mm, this establishes y →Hn−m
δ
¡
A ∩h−1 (y)
¢
is Lebesgue mea-
surable. Then by Lemma 38.14 again,
Z
Rm Hn−m
δ
¡
A ∩h−1 (y)
¢
dy ≤2m (Lip (h))m α (n −m) α (m)
α (n)
mn (A) .

1116
THE AREA AND COAREA FORMULAS
Letting δ →0 and using the monotone convergence theorem yields the desired
inequality for Hn−m ¡
A ∩h−1 (y)
¢
.
The case where A is not bounded can be handled by considering Ar = A∩B (0, r)
and letting r →∞. This proves the lemma.
By fussing with the isodiametric inequality one can remove the factor of 2m in
the above inequalities obtaining much more attractive formulas. This is done in
[20]. See also [36] which follows [20] and [22]. This last reference probably has the
most complete treatment of these topics.
With these lemmas, it is now possible to give a proof of the coarea formula.
Deﬁne Λ (n, m) as all possible ordered lists of m numbers taken from {1, 2, · · ·, n} .
Lemma 38.16 Let A be a measurable set in Rn and let h : Rn →Rm be a Lipschitz
map where m ≤n which is diﬀerentiable at every point of A and for which
Jh (x) ≡det
¡
Dh (x) Dh (x)∗¢1/2 ̸= 0.
Then the following formula holds along with all measurability assertions needed for
it to make sense.
Z
Rm Hn−m ¡
A ∩h−1 (y)
¢
dy =
Z
A
Jh (x) dx
(38.13)
Proof: For x ∈Rn, and i ∈Λ (n, m), with i = (i1, · · ·, im), deﬁne xi ≡(xi1,
· · ·, xim), and πix ≡xi. Also for i ∈Λ (n, m), let ic ∈Λ (n, n −m) consist of
the remaining indices taken in order.
For h : Rn →Rm where m ≤n, deﬁne
Jh (x) ≡det
¡
Dh (x) Dh (x)∗¢1/2. For each i ∈Λ (n, m), deﬁne
hi (x) ≡
µ
h (x)
xic
¶
.
By Lemma 38.7, there exist disjoint measurable sets
©
F i
j
ª∞
j=1 such that hi is one
to one on F i
j,
¡
hi¢−1 is Lipschitz on hi ¡
F i
j
¢
, and
∪∞
j=1F i
j =
©
x ∈A : det
¡
Dhi (x)
¢
̸= 0
ª
.
For x ∈A, det (Dxih (x)) ̸= 0 for some i ∈Λ (n, m).
But det (Dxih (x)) =
det
¡
Dhi (x)
¢
and so x ∈F i
j for some i and j. Hence
∪i,jF i
j = A.
Now let
©
Ei
j
ª
be measurable sets such that Ei
j ⊆F i
k for some k, the sets are
disjoint, and their union coincides with ∪i,jF i
j. Then
Z
A
Jh (x) dx =
X
i ∈Λ(n,m)
∞
X
j=1
Z
Ei
j∩A
det
¡
Dh (x) Dh (x)∗¢1/2 dx.
(38.14)

38.3.
THE COAREA FORMULA
1117
Let g : Rn →Rn be a Lipschitz extension of
¡
hi¢−1 so g ◦hi (x) = x for all x ∈
Ei
j. First, using Theorem 38.11, and the fact that Lipschitz mappings take sets of
measure zero to sets of measure zero, replace Ei
j with a measurable set, eEi
j ⊆Ei
j
such that Ei
j \ eEi
j has measure zero and
Dhi (g (y)) Dg (y) = I
on hi ³
eEi
j
´
. Changing the variables using the area formula, the expression in 38.14
equals
Z
A
Jh (x) dx =
X
i ∈Λ(n,m)
∞
X
j=1
Z
hi( e
Ei
j∩A)
det
¡
Dh (g (y)) Dh (g (y))∗¢1/2 ¯¯det Dhi (g (y))
¯¯−1 dy.
(38.15)
Note the integrands are all Borel measurable functions because they are continu-
ous functions of the entries of matrices which entries come from taking limits of
diﬀerence quotients of continuous functions. Thus,
Z
e
Ei
j∩A
det
¡
Dh (x) Dh (x)∗¢1/2 dx =
Z
Rn Xhi( e
Ei
j∩A) (y) det
¡
Dh (g (y)) Dh (g (y))∗¢1/2 ¯¯det Dhi (g (y))
¯¯−1 dy
=
Z
Rm
Z
πic(h−1(y1)∩e
Ei
j∩A)
det
¡
Dh (g (y)) Dh (g (y))∗¢1/2 |det Dhxi (g (y))|−1 dy2dy1
(38.16)
where y1 = h (x) and y2 = xic. Thus
y2 = πicg (y) = πicg
¡
hi (x)
¢
= xic.
(38.17)
Now consider the inner integral in 38.16 in which y1 is ﬁxed. The integrand
equals
det
·¡
Dxih (g (y))
Dxich (g (y))
¢ µ
Dxih (g (y))∗
Dxic h (g (y))∗
¶¸1/2
|det Dhxi (g (y))|−1 .
(38.18)
I want to massage the above expression slightly.
Since y1 is ﬁxed, and y1 =
h (πig (y) , πicg (y)) = h (g (y)), it follows from 38.17 that
0
=
Dxih (g (y)) Dy2πig (y) + Dxic h (g (y)) Dy2πicg (y)
=
Dxih (g (y)) Dy2πig (y) + Dxic h (g (y)).

1118
THE AREA AND COAREA FORMULAS
Letting A ≡Dxih (g (y)) and B ≡Dy2πig (y) and using the above formula, 38.18
is of the form
det
·¡
A
−AB
¢ µ
A∗
−B∗A∗
¶¸1/2
|det A|−1
=
det [A∗A + ABB∗A∗]1/2 |det A|−1
=
det [A∗(I + BB∗) A]1/2 |det A|−1
=
det (I + BB∗)1/2,
which, by Corollary 38.10, equals det (I + B∗B)1/2. (Note the size of the identity
changes in these two expressions, the ﬁrst being an m × m matrix and the second
being a n −m × n −m matrix.)
By 38.17 πicg (y) = y2 and so,
det (I + B∗B)1/2 = det
·¡
B∗
I
¢ µ
B
I
¶¸1/2
= det
·¡ Dy2πig (y)∗
Dy2πicg (y)∗¢ µ
Dy2πig (y)
Dy2πicg (y)
¶¸1/2
= det
¡
Dy2g (y)∗Dy2g (y)
¢1/2.
Therefore, 38.16 reduces to
Z
e
Ei
j∩A
det
¡
Dh (x) Dh (x)∗¢1/2 dx =
Z
Rm
Z
πic(h−1(y1)∩e
Ei
j∩A)
det
¡
Dy2g (y)∗Dy2g (y)
¢1/2 dy2dy1.
(38.19)
By the area formula applied to the inside integral, this integral equals
Hn−m ³
h−1 (y1) ∩eEi
j ∩A
´
and so
Z
e
Ei
j∩A
det
¡
Dh (x) Dh (x)∗¢1/2 dx
=
Z
Rm Hn−m ³
h−1 (y1) ∩eEi
j ∩A
´
dy1.
Using Lemma 38.15, along with the inner regularity of Lebesgue measure, eEi
j
can be replaced with Ei
j. Therefore, summing the terms over all i and j,
Z
A
det
¡
Dh (x) Dh (x)∗¢1/2 dx =
Z
Rm Hn−m ¡
h−1 (y) ∩A
¢
dy.
This proves the lemma.
Now the following is the Coarea formula.

38.3.
THE COAREA FORMULA
1119
Corollary 38.17 Let A be a measurable set in Rn and let h : Rn →Rm be a
Lipschitz map where m ≤n. Then the following formula holds along with all mea-
surability assertions needed for it to make sense.
Z
Rm Hn−m ¡
A ∩h−1 (y)
¢
dy =
Z
A
Jh (x) dx
(38.20)
where Jh (x) ≡det
¡
Dh (x) Dh (x)∗¢1/2 .
Proof: By Lemma 38.15 again, this formula is true for all measurable A ⊆
Rn \ S. It remains to verify the formula for all measurable sets, A, whether or not
they intersect S.
Consider the case where
A ⊆S ≡{x : J (Dh (x)) = 0}.
Let A be compact so that by Lemma 38.14, y →Hn−m ¡
A ∩h−1 (y)
¢
is Borel. For
ε > 0, deﬁne k, p : Rn × Rm →Rm by
k (x, y) ≡h (x) + εy, p (x, y) ≡y.
Then
Dk (x, y) = (Dh (x) , εI) = (UR, εI)
where the dependence of U and R on x has been suppressed. Thus
Jk2 = det (UR, εI)
µ
R∗U
εI
¶
= det
¡
U 2 + ε2I
¢
= det
¡
Q∗DQQ∗DQ + ε2I
¢
= det
¡
D2 + ε2I
¢
=
m
Y
i=1
¡
λ2
i + ε2¢
∈[ε2m, C2ε2]
(38.21)
since one of the λi equals 0. All the eigenvalues must be bounded independent of
x, since ||Dh (x)|| is bounded independent of x due to the assumption that h is
Lipschitz. Since Jk ̸= 0, the ﬁrst part of the argument implies
εCmn+m
³
A × B (0,1)
´
≥
Z
A×B(0,1)
|Jk| dmn+m
=
Z
Rm Hn ³
k−1 (y) ∩A × B (0,1)
´
dy
Which by Lemma 38.14,
≥Cnm
Z
Rm
Z
Rm Hn−m ³
k−1 (y) ∩p−1 (w) ∩A × B (0,1)
´
dwdy
(38.22)
where Cnm =
α(n)
α(n−m)α(m).

1120
THE AREA AND COAREA FORMULAS
Claim:
Hn−m ³
k−1 (y) ∩p−1 (w) ∩A × B (0,1)
´
≥XB(0,1) (w) Hn−m ¡
h−1 (y −εw) ∩A
¢
.
Proof of the claim: If w /∈B (0,1), there is nothing to prove so assume w ∈
B (0,1). For such w,
(x, w1) ∈k−1 (y) ∩p−1 (w) ∩A × B (0,1)
if and only if h (x) + εw1 = y, w1 = w, and x ∈A, if and only if
(x, w1) ∈h−1 (y −εw) ∩A × {w}.
Therefore for w ∈B (0,1),
Hn−m ³
k−1 (y) ∩p−1 (w) ∩A × B (0,1)
´
≥Hn−m ¡
h−1 (y −εw) ∩A × {w}
¢
= Hn−m ¡
h−1 (y −εw) ∩A
¢
.
(Actually equality holds in the claim.) From the claim, 38.22 is at least as large as
Cnm
Z
Rm
Z
B(0,1)
Hn−m ¡
h−1 (y −εw) ∩A
¢
dwdy
(38.23)
= Cnm
Z
B(0,1)
Z
Rm Hn−m ¡
h−1 (y −εw) ∩A
¢
dydw
=
α (n)
α (n −m)
Z
Rm Hn−m ¡
h−1 (y) ∩A
¢
dy.
(38.24)
The use of Fubini’s theorem is justiﬁed because the integrand is Borel measurable.
Now by 38.24, it follows since ε > 0 is arbitrary,
Z
Rm Hn−m ¡
A ∩h−1 (y)
¢
dy = 0 =
Z
A
Jh (x) dx.
Since this holds for arbitrary compact sets in S, it follows from Lemma 38.15 and
inner regularity of Lebesgue measure that the equation holds for all measurable
subsets of S. This completes the proof of the coarea formula.There is a simple
corollary to this theorem in the case of locally Lipschitz maps.
Corollary 38.18 Let h : Rn →Rm where m ≤n and h is locally Lipschitz. Then
the Coarea formula, 38.13, holds for h.
Proof: The assumption that h is locally Lipschitz implies that for each r > 0 it
follows h is Lipschitz on B (0, r) . To see this, cover the compact set, B (0, r) with
ﬁnitely many balls on which h is Lipschitz.

38.4.
A NONLINEAR FUBINI’S THEOREM
1121
Let A ⊆B (0,r) and let hr be Lipschitz with
h (x) = hr (x)
for x ∈B (0,r + 1) . Then
Z
A
J (Dh (x)) dx =
Z
A
J(Dhr (x))dx =
Z
Rm Hn−m ¡
A ∩h−1
r
(y)
¢
dy
=
Z
hr(A)
Hn−m ¡
A ∩h−1
r
(y)
¢
dy =
Z
h(A)
Hn−m ¡
A ∩h−1 (y)
¢
dy
=
Z
Rm Hn−m ¡
A ∩h−1 (y)
¢
dy
Now for arbitrary measurable A the above shows for k = 1, 2, · · ·
Z
A∩B(0,k)
J (Dh (x)) dx =
Z
Rm Hn−m ¡
A ∩B (0,k) ∩h−1 (y)
¢
dy.
Use the monotone convergence theorem to obtain 38.13.
From the deﬁnition of Hausdorﬀmeasure it follows H0 (E) equals the number
of elements in E. Thus, if n = m, the Coarea formula implies
Z
A
J (Dh (x)) dx =
Z
h(A)
H0 ¡
A ∩h−1 (y)
¢
dy =
Z
h(A)
# (y) dy
This gives a version of Sard’s theorem by letting S = A.
38.4
A Nonlinear Fubini’s Theorem
Coarea formula holds for h : Rn →Rm, n ≥m
if whenever A is a Lebesgue
measurable subset of Rn,the following formula is valid.
Z
Rm Hn−m ¡
A ∩h−1 (y)
¢
dy =
Z
A
Jh (x) dx
(38.25)
Note this is the same as
Z
A
J(Dh (x))dx =
Z
h(A)
Hn−m ¡
A ∩h−1 (y)
¢
dy
because if y /∈h (A) , then h−1 (y) = ∅. Now let
s (x) =
p
X
i=1
ciXEi (x)

1122
THE AREA AND COAREA FORMULAS
where Ei is measurable and ci ≥0. Then
Z
Rn s (x) J ((Dh (x))) dx
=
p
X
i=1
ci
Z
Ei
J (Dh (x)) dx
=
p
X
i=1
ci
Z
h(Ei)
Hn−m ¡
Ei ∩h−1(y)
¢
dy
=
Z
h(Rn)
p
X
i=1
ciHn−m ¡
Ei ∩h−1(y)
¢
dy
=
Z
h(Rn)
"Z
h−1(y)
s dHn−m
#
dy
=
Z
h(Rn)
"Z
h−1(y)
s dHn−m
#
dy.
(38.26)
Theorem 38.19 Let g ≥0 be Lebesgue measurable and let
h : Rn →Rm, n ≥m
satisfy the Coarea formula. For example, it could be locally Lipschitz. Then
Z
Rn g (x) J ((Dh (x))) dx =
Z
h(Rn)
"Z
h−1(y)
g dHn−m
#
dy.
Proof: Let si ↑g where si is a simple function satisfying 38.26. Then let i →∞
and use the monotone convergence theorem to replace si with g. This proves the
change of variables formula.
Note that this formula is a nonlinear version of Fubini’s theorem. The “n −
m dimensional surface”, h−1 (y), plays the role of Rn−m and Hn−m is like n −
m dimensional Lebesgue measure. The term, J ((Dh (x))), corrects for the error
occurring because of the lack of ﬂatness of h−1 (y).

Integration On Manifolds
You can do integration on various manifolds by using the Hausdorﬀmeasure of an
appropriate dimension. However, it is possible to discuss this through the use of
the Riesz representation theorem and some of the machinery for accomplishing this
is interesting for its own sake so I will present this alternate point of view.
39.1
Partitions Of Unity
This material has already been mostly discussed starting on Page 481. However,
that was a long time ago and it seems like it might be good to go over it again and
so, for the sake of convenience, here it is again.
Deﬁnition 39.1 Let C be a set whose elements are subsets of Rn.1 Then C is said
to be locally ﬁnite if for every x ∈Rn, there exists an open set, Ux containing x
such that Ux has nonempty intersection with only ﬁnitely many sets of C.
Lemma 39.2 Let C be a set whose elements are open subsets of Rn and suppose
∪C ⊇H, a closed set. Then there exists a countable list of open sets, {Ui}∞
i=1 such
that each Ui is bounded, each Ui is a subset of some set of C, and ∪∞
i=1Ui ⊇H.
Proof: Let Wk ≡B (0, k) , W0 = W−1 = ∅. For each x ∈H ∩Wk there exists
an open set, Ux such that Ux is a subset of some set of C and Ux ⊆Wk+1 \ Wk−1.
Then since H ∩Wk is compact, there exist ﬁnitely many of these sets,
©
U k
i
ªm(k)
i=1
whose union contains H ∩Wk. If H ∩Wk = ∅, let m (k) = 0 and there are no such
sets obtained.The desired countable list of open sets is ∪∞
k=1
©
U k
i
ªm(k)
i=1 . Each open
set in this list is bounded. Furthermore, if x ∈Rn, then x ∈Wk where k is the
ﬁrst positive integer with x ∈Wk. Then Wk \Wk−1 is an open set containing x and
this open set can have nonempty intersection only with with a set of
©
U k
i
ªm(k)
i=1 ∪
©
U k−1
i
ªm(k−1)
i=1
, a ﬁnite list of sets. Therefore, ∪∞
k=1
©
U k
i
ªm(k)
i=1
is locally ﬁnite.
The set, {Ui}∞
i=1 is said to be a locally ﬁnite cover of H. The following lemma
gives some important reasons why a locally ﬁnite list of sets is so signiﬁcant. First
1The deﬁnition applies with no change to a general topological space in place of Rn.
1123

1124
INTEGRATION ON MANIFOLDS
of all consider the rational numbers, {ri}∞
i=1 each rational number is a closed set.
Q = {ri}∞
i=1 = ∪∞
i=1{ri} ̸= ∪∞
i=1 {ri} = R
The set of rational numbers is deﬁnitely not locally ﬁnite.
Lemma 39.3 Let C be locally ﬁnite. Then
∪C = ∪
©
H : H ∈C
ª
.
Next suppose the elements of C are open sets and that for each U ∈C, there exists a
diﬀerentiable function, ψU having spt (ψU) ⊆U. Then you can deﬁne the following
ﬁnite sum for each x ∈Rn
f (x) ≡
X
{ψU (x) : x ∈U ∈C} .
Furthermore, f is also a diﬀerentiable function2 and
Df (x) =
X
{DψU (x) : x ∈U ∈C} .
Proof: Let p be a limit point of ∪C and let W be an open set which intersects
only ﬁnitely many sets of C. Then p must be a limit point of one of these sets. It
follows p ∈∪
©
H : H ∈C
ª
and so ∪C ⊆∪
©
H : H ∈C
ª
. The inclusion in the other
direction is obvious.
Now consider the second assertion. Letting x ∈Rn, there exists an open set, W
intersecting only ﬁnitely many open sets of C, U1, U2, · · ·, Um. Then for all y ∈W,
f (y) =
m
X
i=1
ψUi (y)
and so the desired result is obvious. It merely says that a ﬁnite sum of diﬀerentiable
functions is diﬀerentiable. Recall the following deﬁnition.
Deﬁnition 39.4 Let K be a closed subset of an open set, U. K ≺f ≺U if f is
continuous, has values in [0, 1] , equals 1 on K, and has compact support contained
in U.
Lemma 39.5 Let U be a bounded open set and let K be a closed subset of U. Then
there exist an open set, W, such that W ⊆W ⊆U and a function, f ∈C∞
c (U)
such that K ≺f ≺U.
Proof: The set, K is compact so is at a positive distance from U C. Let
W ≡
©
x : dist (x, K) < 3−1 dist
¡
K, U C¢ª
.
2If each ψU were only continuous, one could conclude f is continuous. Here the main interest
is diﬀerentiable.

39.1.
PARTITIONS OF UNITY
1125
Also let
W1 ≡
©
x : dist (x, K) < 2−1 dist
¡
K, U C¢ª
Then it is clear
K ⊆W ⊆W ⊆W1 ⊆W1 ⊆U
Now consider the function,
h (x) ≡
dist
¡
x, W C
1
¢
dist
¡
x, W C
1
¢
+ dist
¡
x, W
¢
Since W is compact it is at a positive distance from W C
1 and so h is a well deﬁned
continuous function which has compact support contained in W 1, equals 1 on W,
and has values in [0, 1] . Now let φk be a molliﬁer. Letting
k−1 < min
¡
dist
¡
K, W C¢
, 2−1 dist
¡
W 1, U C¢¢
,
it follows that for such k,the function, h ∗φk ∈C∞
c (U) , has values in [0, 1] , and
equals 1 on K. Let f = h ∗φk.
The above lemma is used repeatedly in the following.
Lemma 39.6 Let K be a closed set and let {Vi}∞
i=1 be a locally ﬁnite list of bounded
open sets whose union contains K. Then there exist functions, ψi ∈C∞
c (Vi) such
that for all x ∈K,
1 =
∞
X
i=1
ψi (x)
and the function f (x) given by
f (x) =
∞
X
i=1
ψi (x)
is in C∞(Rn) .
Proof: Let K1 = K \ ∪∞
i=2Vi. Thus K1 is compact because K1 ⊆V1. Let
K1 ⊆W1 ⊆W 1 ⊆V1
Thus W1, V2, ···, Vn covers K and W 1 ⊆V1. Suppose W1, ···, Wr have been deﬁned
such that Wi ⊆Vi for each i, and W1, · · ·, Wr, Vr+1, · · ·, Vn covers K. Then let
Kr+1 ≡K \ (
¡
∪∞
i=r+2Vi
¢
∪
¡
∪r
j=1Wj
¢
).
It follows Kr+1 is compact because Kr+1 ⊆Vr+1. Let Wr+1 satisfy
Kr+1 ⊆Wr+1 ⊆W r+1 ⊆Vr+1
Continuing this way deﬁnes a sequence of open sets, {Wi}∞
i=1 with the property
Wi ⊆Vi, K ⊆∪∞
i=1Wi.

1126
INTEGRATION ON MANIFOLDS
Note {Wi}∞
i=1 is locally ﬁnite because the original list, {Vi}∞
i=1 was locally ﬁnite.
Now let Ui be open sets which satisfy
W i ⊆Ui ⊆U i ⊆Vi.
Similarly, {Ui}∞
i=1 is locally ﬁnite.
Wi
Ui
Vi
Since the set, {Wi}∞
i=1 is locally ﬁnite, it follows ∪∞
i=1Wi = ∪∞
i=1Wi and so it
is possible to deﬁne φi and γ, inﬁnitely diﬀerentiable functions having compact
support such that
U i ≺φi ≺Vi, ∪∞
i=1W i ≺γ ≺∪∞
i=1Ui.
Now deﬁne
ψi(x) =
½ γ(x)φi(x)/ P∞
j=1 φj(x) if P∞
j=1 φj(x) ̸= 0,
0 if P∞
j=1 φj(x) = 0.
If x is such that P∞
j=1 φj(x) = 0, then x /∈∪∞
i=1Ui because φi equals one on Ui.
Consequently γ (y) = 0 for all y near x thanks to the fact that ∪∞
i=1Ui is closed
and so ψi(y) = 0 for all y near x. Hence ψi is inﬁnitely diﬀerentiable at such x. If
P∞
j=1 φj(x) ̸= 0, this situation persists near x because each φj is continuous and so
ψi is inﬁnitely diﬀerentiable at such points also thanks to Lemma 39.3. Therefore
ψi is inﬁnitely diﬀerentiable. If x ∈K, then γ (x) = 1 and so P∞
j=1 ψj(x) = 1.
Clearly 0 ≤ψi (x) ≤1 and spt(ψj) ⊆Vj. This proves the theorem.
The method of proof of this lemma easily implies the following useful corollary.
Corollary 39.7 If H is a compact subset of Vi for some Vi there exists a partition
of unity such that ψi (x) = 1 for all x ∈H in addition to the conclusion of Lemma
39.6.
Proof: Keep Vi the same but replace Vj with f
Vj ≡Vj \ H. Now in the proof
above, applied to this modiﬁed collection of open sets, if j ̸= i, φj (x) = 0 whenever
x ∈H. Therefore, ψi (x) = 1 on H.
Theorem 39.8 Let H be any closed set and let C be any open cover of H. Then
there exist functions {ψi}∞
i=1 such that spt (ψi) is contained in some set of C and ψi
is inﬁnitely diﬀerentiable having values in [0, 1] such that on H, P∞
i=1 ψi (x) = 1.
Furthermore, the function, f (x) ≡P∞
i=1 ψi (x) is inﬁnitely diﬀerentiable on Rn.
Also, spt (ψi) ⊆Ui where Ui is a bounded open set with the property that {Ui}∞
i=1
is locally ﬁnite and each Ui is contained in some set of C.

39.2.
INTEGRATION ON MANIFOLDS
1127
Proof: By Lemma 39.2 there exists an open cover of H composed of bounded
open sets, Ui such that each Ui is a subset of some set of C and the collection,
{Ui}∞
i=1 is locally ﬁnite.
Then the result follows from Lemma 39.6 and Lemma
39.3.
Corollary 39.9 Let H be any closed set and let {Vi}m
i=1 be a ﬁnite open cover of
H. Then there exist functions {φi}m
i=1 such that spt (φi) ⊆Vi and φi is inﬁnitely
diﬀerentiable having values in [0, 1] such that on H, Pm
i=1 φi (x) = 1.
Proof: By Theorem 39.8 there exists a set of functions, {ψi}∞
i=1 having the
properties listed in this theorem relative to the open covering, {Vi}m
i=1 . Let φ1 (x)
equal the sum of all ψj (x) such that spt
¡
ψj
¢
⊆V1. Next let φ2 (x) equal the sum
of all ψj (x) which have not already been included and for which spt
¡
ψj
¢
⊆V2.
Continue in this manner. Since the open sets, {Ui}∞
i=1 mentioned in Theorem 39.8
are locally ﬁnite, it follows from Lemma 39.3 that each φi is inﬁnitely diﬀerentiable
having support in Vi. This proves the corollary.
39.2
Integration On Manifolds
Manifolds are things which locally appear to be Rn for some n. The extent to
which they have such a local appearance varies according to various analytical
characteristics which the manifold possesses.
Deﬁnition 39.10 Let U ⊆Rn be an open set and let h : U →Rm. Then for
r ∈[0, 1), h ∈Ck,r (U) for k a nonnegative integer means that Dαh exists for all
|α| ≤k and each Dαh is Holder continuous with exponent r. That is
|Dαh (x) −Dαh (y)| ≤K |x −y|r .
Also h ∈Ck,r ¡
U
¢
if it is the restriction of a function of Ck,r (Rn) to U.
Deﬁnition 39.11 Let Γ be a closed subset of Rp where p ≥n. Suppose Γ = ∪∞
i=1Γi
where Γi = Γ∩Wi for Wi a bounded open set. Suppose also {Wi}∞
i=1 is locally ﬁnite.
This means every bounded open set intersects only ﬁnitely many. Also suppose there
are open bounded sets, Ui having Lipschitz boundaries and functions hi : Ui →Γi
which are one to one, onto, and in Cm,1 (Ui) . Suppose also there exist functions,
gi : Wi →Ui such that gi is Cm,1 (Wi) , and gi ◦hi = id on Ui while hi ◦gi = id on
Γi. The collection of sets, Γj and mappings, gj,
©¡
Γj, gj
¢ª
is called an atlas and
an individual entry in the atlas is called a chart. Thus
¡
Γj, gj
¢
is a chart. Then Γ
as just described is called a Cm,1 manifold. The number, m is just a nonnegative
integer. When m = 0 this would be called a Lipschitz manifold, the least smooth of
the manifolds discussed here.
For example, take p = n + 1 and let
hi (u) = (u1, · · ·, ui, φi (u) , ui+1, · · ·, un)T

1128
INTEGRATION ON MANIFOLDS
for u = (u1, · · ·, ui, ui+1, · · ·, un)T ∈Ui for φi ∈Cm,1 (Ui) and gi : Ui × R →Ui
given by
gi (u1, · · ·, ui, y, ui+1, · · ·, un) ≡u
for i = 1, 2, · · ·, p. Then for u ∈Ui, the deﬁnition gives
gi ◦hi (u) = gi (u1, · · ·, ui, φi (u) , ui+1, · · ·, un) = u
and for Γi ≡hi (Ui) and (u1, · · ·, ui, φi (u) , ui+1, · · ·, un)T ∈Γi,
hi ◦gi (u1, · · ·, ui, φi (u) , ui+1, · · ·, un)
=
hi (u) = (u1, · · ·, ui, φi (u) , ui+1, · · ·, un)T .
This example can be used to describe the boundary of a bounded open set and since
φi ∈Cm,1 (Ui) , such an open set is said to have a Cm,1 boundary. Note also that
in this example, Ui could be taken to be Rn or if Ui is given, both hi and and gi
can be taken as restrictions of functions deﬁned on all of Rn and Rp respectively.
The symbol, I will refer to an increasing list of n indices taken from {1, · · ·, p} .
Denote by Λ (p, n) the set of all such increasing lists of n indices.
Let
Ji (u) ≡


X
I∈Λ(p,n)
Ã
∂
¡
xi1 · · · xin¢
∂(u1 · · · un)
!2

1/2
where here the sum is taken over all possible increasing lists of n indices, I, from
{1, · · ·, p} and x = hiu. Thus there are
¡p
n
¢
terms in the sum. In this formula,
∂(xi1···xin)
∂(u1···un)
is deﬁned to be the determinant of the following matrix.




∂xi1
∂u1
· · ·
∂xi1
∂un
...
...
∂xin
∂u1
· · ·
∂xin
∂un



.
Note that if p = n there is only one term in the sum, the absolute value of the
determinant of Dx (u). Deﬁne a positive linear functional, Λ on Cc (Γ) as follows:
First let {ψi} be a C∞partition of unity subordinate to the open sets, {Wi} . Thus
ψi ∈C∞
c (Wi) and P
i ψi (x) = 1 for all x ∈Γ. Then
Λf ≡
∞
X
i=1
Z
giΓi
fψi (hi (u)) Ji (u) du.
(39.1)
Is this well deﬁned?
Lemma 39.12 The functional deﬁned in 39.1 does not depend on the choice of
atlas or the partition of unity.

39.2.
INTEGRATION ON MANIFOLDS
1129
Proof: In 39.1, let {ψi} be a C∞partition of unity which is associated with
the atlas (Γi, gi) and let {ηi} be a C∞partition of unity associated in the same
manner with the atlas (Γ′
i, g′
i). In the following argument, the local ﬁniteness of
the Γi implies that all sums are ﬁnite. Using the change of variables formula with
u =
¡
gi ◦h′
j
¢
v
∞
X
i=1
Z
giΓi
ψif (hi (u)) Ji (u) du =
(39.2)
∞
X
i=1
∞
X
j=1
Z
giΓi
ηjψif (hi (u)) Ji (u) du =
∞
X
i=1
∞
X
j=1
Z
g′
j(Γi∩Γ′
j)
·
ηj
¡
h′
j (v)
¢
ψi
¡
h′
j (v)
¢
f
¡
h′
j (v)
¢
Ji (u)
¯¯¯¯¯
∂
¡
u1 · · · un¢
∂(v1 · · · vn)
¯¯¯¯¯ dv
=
∞
X
i=1
∞
X
j=1
Z
g′
j(Γi∩Γ′
j)
ηj
¡
h′
j (v)
¢
ψi
¡
h′
j (v)
¢
f
¡
h′
j (v)
¢
Jj (v) dv.
(39.3)
Thus
the deﬁnition of Λf using (Γi, gi) ≡
∞
X
i=1
Z
giΓi
ψif (hi (u)) Ji (u) du =
∞
X
i=1
∞
X
j=1
Z
g′
j(Γi∩Γ′
j)
ηj
¡
h′
j (v)
¢
ψi
¡
h′
j (v)
¢
f
¡
h′
j (v)
¢
Jj (v) dv
=
∞
X
j=1
Z
g′
j(Γ′
j)
ηj
¡
h′
j (v)
¢
f
¡
h′
j (v)
¢
Jj (v) dv
the deﬁnition of Λf using (Vi, g′
i) .
This proves the lemma.
This lemma and the Riesz representation theorem for positive linear functionals
implies the part of the following theorem which says the functional is well deﬁned.
Theorem 39.13 Let Γ be a Cm,1 manifold.
Then there exists a unique Radon
measure, µ, deﬁned on Γ such that whenever f is a continuous function having
compact support which is deﬁned on Γ and (Γi, gi) denotes an atlas and {ψi} a
partition of unity subordinate to this atlas,
Λf =
Z
Γ
fdµ =
∞
X
i=1
Z
giΓi
ψif (hi (u)) Ji (u) du.
(39.4)
Also, a subset, A, of Γ is µ measurable if and only if for all r, gr (Γr ∩A) is νr
measurable where νr is the measure deﬁned by
νr (gr (Γr ∩A)) ≡
Z
gr(Γr∩A)
Jr (u) du

1130
INTEGRATION ON MANIFOLDS
Proof: To begin, here is a claim.
Claim : A set, S ⊆Γi, has µ measure zero if and only if giS has measure zero
in giΓi with respect to the measure, νi.
Proof of the claim: Let ε > 0 be given. By outer regularity, there exists a
set, V ⊆Γi, open3 in Γ such that µ (V ) < ε and S ⊆V ⊆Γi. Then giV is open in
Rn and contains giS. Letting h ≺giV and h1 (x) ≡h (gi (x)) for x ∈Γi it follows
h1 ≺V . By Corollary 39.7 on Page 1126 there exists a partition of unity such that
spt (h1) ⊆{x ∈Rp : ψi (x) = 1}. Thus ψjh1 (hj (u)) = 0 unless j = i when this
reduces to h1 (hi (u)). It follows
ε
≥
µ (V ) ≥
Z
V
h1dµ =
Z
Γ
h1dµ
=
∞
X
j=1
Z
gjΓj
ψjh1 (hj (u)) Jj (u) du
=
Z
giΓi
h1 (hi (u)) Ji (u) du =
Z
giΓi
h (u) Ji (u) du
=
Z
giV
h (u) Ji (u) du
Now this holds for all h ≺giV and so
Z
giV
Ji (u) du ≤ε.
Since ε is arbitrary, this shows giV has measure no more than ε with respect to the
measure, νi. Since ε is arbitrary, giS has measure zero.
Consider the converse. Suppose giS has νi measure zero. Then there exists an
open set, O ⊆giΓi such that O ⊇giS and
Z
O
Ji (u) du < ε.
Thus hi (O) is open in Γ and contains S. Let h ≺hi (O) be such that
Z
Γ
hdµ + ε > µ (hi (O)) ≥µ (S)
(39.5)
As in the ﬁrst part, Corollary 39.7 on Page 1126 implies there exists a partition of
unity such that h (x) = 0 oﬀthe set,
{x ∈Rp : ψi (x) = 1}
3This means V is the intersection of an open set with Γ. Equivalently, it means that V is an
open set in the traditional way regarding Γ as a metric space with the metric it inherits from Rm.

39.2.
INTEGRATION ON MANIFOLDS
1131
and so as in this part of the argument,
Z
Γ
hdµ
≡
∞
X
j=1
Z
gjUj
ψjh (hj (u)) Jj (u) du
=
Z
giΓi
h (hi (u)) Ji (u) du
=
Z
O∩giΓi
h (hi (u)) Ji (u) du
≤
Z
O
Ji (u) du < ε
(39.6)
and so from 39.5 and 39.6 µ (S) ≤2ε. Since ε is arbitrary, this proves the claim.
For the last part of the theorem, it suﬃces to let A ⊆Γr because otherwise, the
above argument would apply to A ∩Γr. Thus let A ⊆Γr be µ measurable. By
the regularity of the measure, there exists an Fσ set, F and a Gδ set, G such that
Γr ⊇G ⊇A ⊇F and µ (G \ F) = 0.(Recall a Gδ set is a countable intersection
of open sets and an Fσ set is a countable union of closed sets.) Then since Γr is
compact, it follows each of the closed sets whose union equals F is a compact set.
Thus if F = ∪∞
k=1Fk, gr (Fk) is also a compact set and so gr (F) = ∪∞
k=1gr (Fk) is
a Borel set. Similarly, gr (G) is also a Borel set. Now by the claim,
Z
gr(G\F )
Jr (u) du = 0.
Since gr is one to one,
grG \ grF = gr (G \ F)
and so
gr (F) ⊆gr (A) ⊆gr (G)
where gr (G)\gr (F) has measure zero. By completeness of the measure, νr, gr (A)
is measurable. It follows that if A ⊆Γ is µ measurable, then gr (Γr ∩A) is νr
measurable for all r. The converse is entirely similar. This proves the theorem.
Corollary 39.14 Let f ∈L1 (Γ; µ) and suppose f (x) = 0 for all x /∈Γr where
(Γr, gr) is a chart. Then
Z
Γ
fdµ =
Z
Γr
fdµ =
Z
grΓr
f (hr (u)) Jr (u) du.
(39.7)
Furthermore, if {(Γi, gi)} is an atlas and {ψi} is a partition of unity as described
earlier, then for any f ∈L1 (Γ, µ),
Z
Γ
fdµ =
∞
X
r=1
Z
grΓr
ψrf (hr (u)) Jr (u) du.
(39.8)

1132
INTEGRATION ON MANIFOLDS
Proof: Let f ∈L1 (Γ, µ) with f = 0 oﬀΓr. Without loss of generality assume
f ≥0 because if the formulas can be established for this case, the same formulas are
obtained for an arbitrary complex valued function by splitting it up into positive
and negative parts of the real and imaginary parts in the usual way.
Also, let
K ⊆Γr a compact set. Since µ is a Radon measure there exists a sequence of
continuous functions, {fk} , fk ∈Cc (Γr), which converges to f in L1 (Γ, µ) and for
µ a.e. x. Take the partition of unity, {ψi} to be such that
K ⊆{x : ψr (x) = 1} .
Therefore, the sequence {fk (hr (·))} is a Cauchy sequence in the sense that
lim
k,l→∞
Z
gr(K)
|fk (hr (u)) −fl (hr (u))| Jr (u) du = 0
It follows there exists g such that
Z
gr(K)
|fk (hr (u)) −g (u)| Jr (u) du →0,
and
g ∈L1 (grK; νr) .
By the pointwise convergence and the claim used in the proof of Theorem 39.13,
g (u) = f (hr (u))
for µ a.e. hr (u) ∈K. Therefore,
Z
K
fdµ
=
lim
k→∞
Z
K
fkdµ = lim
k→∞
Z
gr(K)
fk (hr (u)) Jr (u) du
=
Z
gr(K)
g (u) Jr (u) du =
Z
gr(K)
f (hr (u)) Jr (u) du.
(39.9)
Now let · · ·Kj ⊆Kj+1 · ·· and ∪∞
j=1Kj = Γr where Kj is compact for all j. Replace
K in 39.9 with Kj and take a limit as j →∞.
By the monotone convergence
theorem,
Z
Γr
fdµ =
Z
gr(Γr)
f (hr (u)) Jr (u) du.
This establishes 39.7.
To establish 39.8, let f ∈L1 (Γ, µ) and let {(Γi, gi)} be an atlas and {ψi} be a
partition of unity. Then fψi ∈L1 (Γ, µ) and is zero oﬀΓi. Therefore, from what
was just shown,
Z
Γ
fdµ
=
∞
X
i=1
Z
Γi
fψidµ
=
∞
X
r=1
Z
gr(Γr)
ψrf (hr (u)) Jr (u) du

39.3.
COMPARISON WITH HN
1133
39.3
Comparison With Hn
The above gives a measure on a manifold, Γ. I will now show that the measure
obtained is nothing more than Hn, the n dimensional Hausdorﬀmeasure. Recall
Λ (p, n) was the set of all increasing lists of n indices taken from {1, 2, · · ·, p}
Recall
Ji (u) ≡


X
I∈Λ(p,n)
Ã
∂
¡
xi1 · · · xin¢
∂(u1 · · · un)
!2

1/2
where here the sum is taken over all possible increasing lists of n indices, I, from
{1, · · ·, p} and x = hiu and the functional was given as
Λf ≡
∞
X
i=1
Z
giΓi
fψi (hi (u)) Ji (u) du
(39.10)
where the {ψi}∞
i=1 was a partition of unity subordinate to the open sets, {Wi}∞
i=1
as described above. I will show
Ji (u) = det
¡
Dh (u)∗Dh (u)
¢1/2
and then use the area formula. The key result is really a special case of the Binet
Cauchy theorem and this special case is presented in the next lemma.
Lemma 39.15 Let A = (aij) be a real p×n matrix in which p ≥n. For I ∈Λ (p, n)
denote by AI the n × n matrix obtained by deleting from A all rows except for those
corresponding to an element of I. Then
X
I∈Λ(p,n)
det (AI)2 = det (A∗A)
Proof: For (j1, · · ·, jn) ∈Λ (p, n) , deﬁne θ (jk) ≡k. Then let for {k1, · · ·, kn} =
{j1, · · ·, jn} deﬁne
sgn (k1, · · ·, kn) ≡sgn (θ (k1) , · · ·, θ (kn)) .
Then from the deﬁnition of the determinant and matrix multiplication,
det (A∗A)
=
X
i1,···,in
sgn (i1, · · ·, in)
p
X
k1=1
ak1i1ak11
p
X
k2=1
ak2i2ak22
· · ·
p
X
kn=1
akninaknn
=
X
J∈Λ(p,n)
X
{k1,···,kn}=J
X
i1,···,in
sgn (i1, · · ·, in) ak1i1ak11ak2i2ak22 · · · akninaknn

1134
INTEGRATION ON MANIFOLDS
=
X
J∈Λ(p,n)
X
{k1,···,kn}=J
X
i1,···,in
sgn (i1, · · ·, in) ak1i1ak2i2 · · · aknin · ak11ak22 · · · aknn
=
X
J∈Λ(p,n)
X
{k1,···,kn}=J
sgn (k1, · · ·, kn) det (AJ) ak11ak22 · · · aknn
=
X
J∈Λ(p,n)
det (AJ) det (AJ)
and this proves the lemma.
It follows from this lemma that
Ji (u) = det
¡
Dh (u)∗Dh (u)
¢1/2 .
From 39.10 and the area formula, the functional equals
Λf
≡
∞
X
i=1
Z
giΓi
fψi (hi (u)) Ji (u) du
=
∞
X
i=1
Z
Γi
fψi (y) dHn =
Z
Γ
f (y) dHn.
Now Hn is a Borel measure deﬁned on Γ which is ﬁnite on all compact subsets of Γ.
This ﬁniteness follows from the above formula. If K is a compact subset of Γ, then
there exists an open set, W whose closure is compact and a continuous function
with compact support, f such that K ≺f ≺W. Then Hn (K) ≤
R
Γ f (y) dHn < ∞
because of the above formula.
Lemma 39.16 µ = Hn on every µ measurable set.
Proof: The Riesz representation theorem shows that
Z
Γ
fdµ =
Z
Γ
fdHn
for every continuous function having compact support. Therefore, since every open
set is the countable union of compact sets, it follows µ = Hn on all open sets. Since
compact sets can be obtained as the countable intersection of open sets, these two
measures are also equal on all compact sets. It follows they are also equal on all
countable unions of compact sets. Suppose now that E is a µ measurable set of ﬁnite
measure. Then there exist sets, F, G such that G is the countable intersection of
open sets each of which has ﬁnite measure and F is the countable union of compact
sets such that µ (G \ F) = 0 and F ⊆E ⊆G. Thus Hn (G \ F) = 0,
Hn (G) = µ (G) = µ (F) = Hn (F)
By completeness of Hn it follows E is Hn measurable and Hn (E) = µ (E) . If
E is not of ﬁnite measure, consider Er ≡E ∩B (0, r) . This is contained in the
compact set Γ ∩B (0, r) and so µ (Er) if ﬁnite. Thus from what was just shown,
Hn (Er) = µ (Er) and so, taking r →∞Hn (E) = µ (E) .
This shows you can simply use Hn for the measure on Γ.

Basic Theory Of Sobolev
Spaces
Deﬁnition 40.1 Let U be an open set of Rn. Deﬁne Xm,p (U) as the set of all
functions in Lp (U) whose weak partial derivatives up to order m are also in Lp (U)
where 1 ≤p. The norm1 in this space is given by
||u||m,p ≡


Z
U
X
|α|≤m
|Dαu|p dx


1/p
.
where α = (α1, · · ·, αn) ∈Nn and |α| ≡P αi. Here D0u ≡u. C∞¡
U
¢
is deﬁned
to be the set of functions which are restrictions to U of a function in C∞
c (Rn).
Thus C∞¡
U
¢
⊆W m,p (U) . The Sobolev space, W m,p (U) is deﬁned to be the clo-
sure of C∞¡
U
¢
in Xm,p (U) with respect to the above norm. Denote this norm by
||u||W m,p(U), ||u||Xm,p(U) , or ||u||m,p,U when it is important to identify the open set,
U.
Also the following notation will be used pretty consistently.
Deﬁnition 40.2 Let u be a function deﬁned on U. Deﬁne
eu (x) ≡
½
u (x) if x ∈U
0 if x /∈U
.
Theorem 40.3 Both Xm,p (U) and W m,p (U) are separable reﬂexive Banach spaces
provided p > 1.
Proof: Deﬁne Λ : Xm,p (U) →Lp (U)w where w equals the number of multi
indices, α, such that |α| ≤m as follows. Letting {αi}w
i=1 be the set of all multi
indices with α1 = 0,
Λ (u) ≡(Dα1u, Dα2u, · · ·, Dαwu) = (u, Dα2u, · · ·, Dαwu) .
1You could also let the norm be given by ||u||m,p
≡
P
|α|≤m ||Dαu||p or ||u||m,p
≡
max
n
||Dαu||p : |α| ≤m
o
because all norms are equivalent on Rp where p is the number of multi
indices no larger than m. This is used whenever convenient.
1135

1136
BASIC THEORY OF SOBOLEV SPACES
Then Λ is one to one because one of the multi indices is 0. Also Λ (Xm,p (U))
is a closed subspace of Lp (U)w . To see this, suppose (uk, Dα2uk, · · ·, Dαwuk) →
(f1, f2, · · ·, fw) in Lp (U)w . Then uk →f1 in Lp (U) and Dαjuk →fj in Lp (U) .
Therefore, letting φ ∈C∞
c (U) and letting k →∞,
R
U (Dαjuk) φdx
= (−1)|α| R
U ukDαjφdx
→(−1)|α| R
U f1Dαjφdx
≡Dαj (f1) (φ)
↓
R
U fjφdx
It follows Dαj (f1) = fj and so Λ (Xm,p (U)) is closed as claimed. This is clearly
also a subspace of Lp (U)w and so it follows that Λ (Xm,p (U)) is a reﬂexive Banach
space. This is because Lp (U)w, being the product of reﬂexive Banach spaces, is
reﬂexive and any closed subspace of a reﬂexive Banach space is reﬂexive.
Now
Λ is an isometry of Xm,p (U) and Λ (Xm,p (U)) which shows that Xm,p (U) is a
reﬂexive Banach space.
Finally, W m,p (U) is a closed subspace of the reﬂexive
Banach space, Xm,p (U) and so it is also reﬂexive. To see Xm,p (U) is separable,
note that Lp (U)w is separable because it is the ﬁnite product of the separable hence
completely separable metric space, Lp (U) and Λ (Xm,p (U)) is a subset of Lp (U)w .
Therefore, Λ (Xm,p (U)) is separable and since Λ is an isometry, it follows Xm,p (U)
is separable also. Now W m,p (U) must also be separable because it is a subset of
Xm,p (U) .
The following theorem is obvious but is worth noting because it says that if a
function has a weak derivative in Lp (U) on a large open set, U then the restriction
of this weak derivative is also the weak derivative for any smaller open set.
Theorem 40.4 Suppose U is an open set and U0 ⊆U is another open set. Suppose
also Dαu ∈Lp (U) . Then for all ψ ∈C∞
c (U0) ,
Z
U0
(Dαu) ψdx = (−1)|α|
Z
U0
u (Dαψ) .
The following theorem is a fundamental approximation result for functions in
Xm,p (U) .
Theorem 40.5 Let U be an open set and let U0 be an open subset of U with the
property that dist
¡
U0, U C¢
> 0. Then if u ∈Xm,p (U) and eu denotes the zero
extention of u oﬀU,
lim
l→∞||eu ∗φl −u||Xm,p(U0) = 0.
Proof: Always assume l is large enough that 1/l < dist
¡
U0, U C¢
. Thus for
x ∈U0,
eu ∗φl (x) =
Z
B(0, 1
l )
u (x −y) φl (y) dy.
(40.1)

1137
The theorem is proved if it can be shown that Dα (eu ∗φl) →Dαu in Lp (U0) . Let
ψ ∈C∞
c (U0)
Dα (eu ∗φl) (ψ)
≡
(−1)|α|
Z
U0
(eu ∗φl) (Dαψ) dx
=
(−1)|α|
Z
U0
Z
eu (y) φl (x −y) (Dαψ) (x) dydx
=
(−1)|α|
Z
U
u (y)
Z
U0
φl (x −y) (Dαψ) (x) dxdy.
Also,
³
g
Dαu ∗φl
´
(ψ)
≡
Z
U0
µZ
g
Dαu (y) φl (x −y) dy
¶
ψ (x) dx
=
Z
U0
µZ
U
Dαu (y) φl (x −y) dy
¶
ψ (x) dx
=
Z
U0
µZ
U
u (y) (Dαφl) (x −y) dy
¶
ψ (x) dx
=
Z
U
u (y)
Z
U0
(Dαφl) (x −y) ψ (x) dxdy
=
(−1)|α|
Z
U
u (y)
Z
U0
φl (x −y) (Dαψ) (x) dxdy.
It follows that Dα (eu ∗φl) =
³
g
Dαu ∗φl
´
as weak derivatives deﬁned on C∞
c (U0) .
Therefore,
||Dα (eu ∗φl) −Dαu||Lp(U0)
=
¯¯¯
¯¯¯ g
Dαu ∗φl −Dαu
¯¯¯
¯¯¯
Lp(U0)
≤
¯¯¯
¯¯¯ g
Dαu ∗φl −g
Dαu
¯¯¯
¯¯¯
Lp(Rn) →0.
This proves the theorem.
As part of the proof of the theorem, the following corollary was established.
Corollary 40.6 Let U0 and U be as in the above theorem. Then for all l large
enough and φl a molliﬁer,
Dα (eu ∗φl) =
³
g
Dαu ∗φl
´
(40.2)
as distributions on C∞
c (U0) .
Deﬁnition 40.7 Let U be an open set. C∞(U) denotes the set of functions which
are deﬁned and inﬁnitely diﬀerentiable on U.

1138
BASIC THEORY OF SOBOLEV SPACES
Note that f (x) =
1
x is a function in C∞(0, 1) . However, it is not equal to
the restriction to (0, 1) of some function which is in C∞
c (R) . This illustrates the
distinction between C∞(U) and C∞¡
U
¢
. The set, C∞¡
U
¢
is a subset of C∞(U) .
The following theorem is known as the Meyer Serrin theorem.
Theorem 40.8 (Meyer Serrin) Let U be an open subset of Rn. Then if δ > 0 and
u ∈Xm,p (U) , there exists J ∈C∞(U) such that ||J −u||m,p,U < δ.
Proof: Let ···Uk ⊆Uk ⊆Uk+1··· be a sequence of open subsets of U whose union
equals U such that Uk is compact for all k. Also let U−3 = U−2 = U−1 = U0 = ∅.
Now deﬁne Vk ≡Uk+1 \ Uk−1. Thus {Vk}∞
k=1 is an open cover of U. Note the open
cover is locally ﬁnite and therefore, there exists a partition of unity subordinate to
this open cover, {ηk}∞
k=1 such that each spt (ηk) ∈Cc (Vk) . Let ψm denote the sum
of all the ηk which are non zero at some point of Vm. Thus
spt (ψm) ⊆Um+2 \ Um−2, ψm ∈C∞
c (U) ,
∞
X
m=1
ψm (x) = 1
(40.3)
for all x ∈U, and ψmu ∈W m,p (Um+2) .
Now let φl be a molliﬁer and consider
J ≡
∞
X
m=0
uψm ∗φlm
(40.4)
where lm is chosen large enough that the following two conditions hold:
spt
¡
uψm ∗φlm
¢
⊆Um+3 \ Um−3,
(40.5)
¯¯¯¯(uψm) ∗φlm −uψm
¯¯¯¯
m,p,Um+3 =
¯¯¯¯(uψm) ∗φlm −uψm
¯¯¯¯
m,p,U <
δ
2m+5 ,
(40.6)
where 40.6 is obtained from Theorem 40.5. Because of 40.3 only ﬁnitely many terms
of the series in 40.4 are nonzero and therefore, J ∈C∞(U) . Now let N > 10, some
large value.
||J −u||m,p,UN−3
=
¯¯¯¯¯
¯¯¯¯¯
N
X
k=0
¡
uψk ∗φlk −uψk
¢
¯¯¯¯¯
¯¯¯¯¯
m,p,UN−3
≤
N
X
k=0
¯¯¯¯uψk ∗φlk −uψk
¯¯¯¯
m,p,UN−3
≤
N
X
k=0
δ
2m+5 < δ.
Now apply the monotone convergence theorem to conclude that ||J −u||m,p,U ≤δ.
This proves the theorem.

1139
Note that J = 0 on ∂U. Later on, you will see that this is pathological.
In the study of partial diﬀerential equations it is the space W m,p (U) which is
of the most use, not the space Xm,p (U) . This is because of the density of C∞¡
U
¢
.
Nevertheless, for reasonable open sets, U, the two spaces coincide.
Deﬁnition 40.9 An open set, U ⊆Rn is said to satisfy the segment condition if
for all z ∈U, there exists an open set Uz containing z and a vector a such that
U ∩U z + ta ⊆U
for all t ∈(0, 1) .
u
z
U z
U
U z
T U + ta
You can imagine open sets which do not satisfy the segment condition.
For
example, a pair of circles which are tangent at their boundaries. The condition in
the above deﬁnition breaks down at their point of tangency.
Here is a simple lemma which will be used in the proof of the following theorem.
Lemma 40.10 If u ∈W m,p (U) and ψ ∈C∞
c (Rn) , then uψ ∈W m,p (U) .
Proof: Let |α| ≤m and let φ ∈C∞
c (U) . Then
(Dxi (uψ)) (φ)
≡
−
Z
U
uψφ,xidx
=
−
Z
U
u
³
(ψφ),xi −φψ,xi
´
dx
=
(Dxiu) (ψφ) +
Z
U
uψ,xiφdx
=
Z
U
¡
ψDxiu + uψ,xi
¢
φdx
Therefore, Dxi (uψ) = ψDxiu + uψ,xi ∈Lp (U) . In other words, the product rule
holds.
Now considering the terms in the last expression, you can do the same
argument with each of these as long as they all have derivatives in Lp (U) . Therefore,
continuing this process the lemma is proved.

1140
BASIC THEORY OF SOBOLEV SPACES
Theorem 40.11 Let U be an open set and suppose there exists a locally ﬁnite
covering2 of U which is of the form {Ui}∞
i=1 such that each Ui is a bounded open set
which satisﬁes the conditions of Deﬁnition 40.9. Thus there exist vectors, ai such
that for all t ∈(0, 1) ,
Ui ∩U + tai ⊆U.
Then C∞¡
U
¢
is dense in Xm,p (U) and so W m,p (U) = Xm,p (U) .
Proof: Let {ψi}∞
i=1 be a partition of unity subordinate to the given open cover
with ψi ∈C∞
c (Ui) and let u ∈Xm,p (U) . Thus
u =
∞
X
k=1
ψku.
Consider Uk for some k. Let ak be the special vector associated with Uk such that
tak + U ∩Uk ⊆U
(40.7)
for all t ∈(0, 1) and consider only t small enough that
spt (ψk) −tak ⊆Uk
(40.8)
Pick l (t) > 1/t which is also large enough that
tak + U ∩Uk + B
µ
0,
1
l (t)
¶
⊆U, spt (ψk) + B
µ
0,
1
l (tk)
¶
−tak ⊆Uk.
(40.9)
This can be done because tak +U ∩Uk is a compact subset of U and so has positive
distance to U C and spt (ψk)−tak is a compact subset of Uk having positive distance
to U C
k . Let tk be such a value for t and for φl a molliﬁer, deﬁne
vtk (x) ≡
Z
Rn eu (x + tkak −y) ψk (x + tkak −y) φl(tk) (y) dy
(40.10)
where as usual, eu is the zero extention of u oﬀU. For vtk (x) ̸= 0, it is necessary
that x + tkak −y ∈spt (ψk) for some y ∈B
³
0,
1
l(tk)
´
. Therefore, using 40.9, for
vtk (x) ̸= 0, it is necessary that
x ∈y −tkak + U ∩spt (ψk) ⊆B
µ
0,
1
l (tk)
¶
+ spt (ψk) −tkak
⊆B
µ
0,
1
l (tk)
¶
+ spt (ψk) −tkak ⊆Uk
2This is never a problem in Rn. In fact, every open covering has a locally ﬁnite subcovering in
Rn or more generally in any metric space due to Stone’s theorem. These are issues best left to
you in case you are interested. I am usually interested in bounded sets, U, and for these, there is
a ﬁnite covering.

1141
showing that vtk has compact support in Uk. Now change variables in 40.10 to
obtain
vtk (x) ≡
Z
Rn eu (y) ψk (y) φl(tk) (x + tkak −y) dy.
(40.11)
For x ∈U ∩Uk, the above equals zero unless
y −tkak −x ∈B
µ
0,
1
l (tk)
¶
which implies by 40.9 that
y ∈tkak + U ∩Uk + B
µ
0,
1
l (tk)
¶
⊆U
Therefore, for such x ∈U ∩Uk,40.11 reduces to
vtk (x)
=
Z
Rn u (y) ψk (y) φl(tk) (x + tkak −y) dy
=
Z
U
u (y) ψk (y) φl(tk) (x + tkak −y) dy.
It follows that for |α| ≤m, and x ∈U ∩Uk
Dαvtk (x)
=
Z
U
u (y) ψk (y) Dαφl(tk) (x + tkak −y) dy
=
Z
U
Dα (uψk) (y) φl(tk) (x + tkak −y) dy
=
Z
Rn
^
Dα (uψk) (y) φl(tk) (x + tkak −y) dy
=
Z
Rn
^
Dα (uψk) (x + tkak −y) φl(tk) (y) dy.
(40.12)
Actually, this formula holds for all x ∈U. If x ∈U but x /∈Uk, then the left
side of the above formula equals zero because, as noted above, spt (vtk) ⊆Uk. The
integrand of the right side equals zero unless
x ∈B
µ
0,
1
l (tk)
¶
+ spt (ψk) −tkak ⊆Uk
by 40.9 and here x /∈Uk.
Next an estimate is obtained for ||Dαvtk −Dα (uψk)||Lp(U) . By 40.12,
||Dαvtk −Dα (uψk)||Lp(U)
≤
µZ
U
µZ
Rn
¯¯¯
^
Dα (uψk) (x + tkak −y) −
^
Dα (uψk) (x)
¯¯¯ φl(tk) (y) dy
¶p
dx
¶1/p
≤
Z
Rn φl(tk) (y)
µZ
U
¯¯¯
^
Dα (uψk) (x + tkak −y) −
^
Dα (uψk) (x)
¯¯¯
p
dx
¶1/p
dy
≤
ε
2k

1142
BASIC THEORY OF SOBOLEV SPACES
whenever tk is taken small enough. Pick tk this small and let wk ≡vtk. Thus
||Dαwk −Dα (uψk)||Lp(U) ≤ε
2k
and wk ∈C∞
c (Rn) . Now let
J (x) ≡
∞
X
k=1
wk.
Since the Uk are locally ﬁnite and spt (wk) ⊆Uk for each k, it follows DαJ =
P∞
k=0 Dαwk and the sum is always ﬁnite. Similarly,
Dα
∞
X
k=1
(ψku) =
∞
X
k=1
Dα (ψku)
and the sum is always ﬁnite. Therefore,
||DαJ −Dαu||Lp(U)
=
¯¯¯¯¯
¯¯¯¯¯
∞
X
k=1
Dαwk −Dα (ψku)
¯¯¯¯¯
¯¯¯¯¯
Lp(U)
≤
∞
X
k=1
||Dαwk −Dα (ψku)||Lp(U) ≤
∞
X
k=1
ε
2k = ε.
By choosing tk small enough, such an inequality can be obtained for
¯¯¯¯DβJ −Dβu
¯¯¯¯
Lp(U)
for each multi index, β such that |β| ≤m. Therefore, there exists J ∈C∞
c (Rn)
such that
||J −u||W m,p(U) ≤εK
where K equals the number of multi indices no larger than m. Since ε is arbitrary,
this proves the theorem.
Corollary 40.12 Let U be an open set which has the segment property.
Then
W m,p (U) = Xm,p (U) .
Proof: Start with an open covering of U whose sets satisfy the segment condition
and obtain a locally ﬁnite reﬁnement consisting of bounded sets which are of the
sort in the above theorem.
Now consider a situation where h : U →V where U and V are two open sets
in Rn and Dαh exists and is continuous and bounded if |α| < m −1 and Dαh is
Lipschitz if |α| = m −1.
Deﬁnition 40.13 Whenever h : U →V, deﬁne h∗mapping the functions which
are deﬁned on V to the functions which are deﬁned on U as follows.
h∗f (x) ≡f (h (x)) .
h : U →V is bilipschitz if h is one to one, onto and Lipschitz and h−1 is also one
to one, onto and Lipschitz.

1143
Theorem 40.14 Let h : U →V be one to one and onto where U and V are two
open sets. Also suppose that Dαh and Dα ¡
h−1¢
exist and are Lipschitz continuous
if |α| ≤m −1 for m a positive integer. Then
h∗: W m,p (V ) →W m,p (U)
is continuous, linear, one to one, and has an inverse with the same properties, the
inverse being
¡
h−1¢∗.
Proof: It is clear that h∗is linear. It is required to show it is one to one and
continuous. First suppose h∗f = 0. Then
0 =
Z
V
|f (h (x))|p dx
and so f (h (x)) = 0 for a.e. x ∈U. Since h is Lipschitz, it takes sets of measure
zero to sets of measure zero. Therefore, f (y) = 0 a.e. This shows h∗is one to one.
By the Meyer Serrin theorem, Theorem 40.8, it suﬃces to verify that h∗is
continuous on functions in C∞(V ) . Let f be such a function. Then using the chain
rule and product rule, (h∗f),i (x) = f,k (h (x)) hk,i (x) ,
(h∗f),ij (x)
=
(f,k (h (x)) hk,i (x)),j
=
f,kl (h (x)) hl,j (x) hk,i (x) + f,k (h (x)) hk,ij (x)
etc. In general, for |α| ≤m −1, succsessive applications of the product rule and
chain rule yield that Dα (h∗f) (x) has the form
Dα (h∗f) (x) =
X
|β|≤|α|
h∗¡
Dβf
¢
(x) gβ (x)
where gβ is a bounded Lipschitz function with Lipschitz constant dependent on h
and its derivatives. It only remains to take one more derivative of the functions,
Dαf for |α| = m −1.
This can be done again but this time you have to use
Rademacher’s theorem which assures you that the derivative of a Lipschitz function
exists a.e. in order to take the partial derivative of the gβ (x) . When this is done,
the above formula remains valid for all |α| ≤m. Therefore, using the change of
variables formula for multiple integrals, Corollary 37.31 on Page 1101,
Z
U
|Dα (h∗f) (x)|p dx
≤
Cm,p,h
X
|β|≤m
Z
U
¯¯h∗¡
Dβf
¢
(x)
¯¯p dx
=
Cm,p,h
X
|β|≤m
Z
U
¯¯¡
Dβf
¢
(h (x))
¯¯p dx
=
Cm,p,h
X
|β|≤m
Z
V
¯¯¡
Dβf
¢
(y)
¯¯p ¯¯det Dh−1 (y)
¯¯ dy
≤
Cm,p,h,h−1 ||f||m,p,V
This shows h∗is continuous on C∞(V ) ∩W m,p (U) and since this set is dense,
this proves h∗is continuous. The same argument applies to
¡
h−1¢∗and now the
deﬁnitions of h∗and
¡
h−1¢∗show these are inverses.

1144
BASIC THEORY OF SOBOLEV SPACES
40.1
Embedding Theorems For W m,p (Rn)
Recall Theorem 37.15 which is listed here for convenience.
Theorem 40.15 Suppose u, u,i ∈Lp
loc (Rn) for i = 1, · · ·, n and p > n. Then u has
a representative, still denoted by u, such that for all x, y ∈Rn,
|u (x) −u (y)| ≤C
ÃZ
B(x,2|y−x|)
|∇u|pdz
!1/p
|x −y|(1−n/p).
(40.13)
This amazing result shows that every u ∈W m,p (Rn) has a representative which
is continuous provided p > n.
Using the above inequality, one can give an important embedding theorem.
Deﬁnition 40.16 Let X, Y be two Banach spaces and let f : X →Y be a function.
Then f is a compact map if whenever S is a bounded set in X, it follows that f (S)
is precompact in Y .
Theorem 40.17 Let U be a bounded open set and for u a function deﬁned on Rn,
let rUu (x) ≡u (x) for x ∈U. Then if p > n, rU : W 1,p (Rn) →C
¡
U
¢
is continuous
and compact.
Proof: First suppose uk →0 in W 1,p (Rn) . Then if rUuk does not converge
to 0, it follows there exists a sequence, still denoted by k and ε > 0 such that
uk →0 in W 1,p (Rn) but ||rUuk||∞≥ε. Selecting a further subsequence which is
still denoted by k, you can also assume uk (x) →0 a.e. Pick such an x0 ∈U where
this convergence takes place. Then from 40.13, for all x ∈U,
|uk (x)| ≤|uk (x0)| + C ||uk||1,p,Rn diam (U)
showing that uk converges uniformly to 0 on U contrary to ||rUuk||∞≥ε. Therefore,
rU is continuous as claimed.
Next let S be a bounded subset of W 1,p (Rn) with ||u||1,p < M for all u ∈S.
Then for u ∈S
rpmn ([|u| > r] ∩U) ≤
Z
[|u|>r]∩U
|u|p dmn ≤M p
and so
mn ([|u| > r] ∩U) ≤M p
rp .
Now choosing r large enough, M p/rp < mn (U) and so, for such r, there exists
xu ∈U such that |u (xu)| ≤r. Therefore from 40.13, whenever x ∈U,
|u (x)|
≤
|u (xu)| + CM diam (U)1−n/p
≤
r + CM diam (U)1−n/p

40.1.
EMBEDDING THEOREMS FOR W M,P ¡
RN¢
1145
showing that {rUu : u ∈S} is uniformly bounded.
But also, for x, y ∈U,40.13
implies
|u (x) −u (y)| ≤CM |x −y|1−n
p
showing that {rUu : u ∈S} is equicontinuous. By the Ascoli Arzela theorem, it
follows rU (S) is precompact and so rU is compact.
Deﬁnition 40.18 Let α ∈(0, 1] and K a compact subset of Rn
Cα (K) ≡{f ∈C (K) : ρα (f) + ||f|| ≡||f||α < ∞}
where
||f|| ≡||f||∞≡sup{|f (x)| : x ∈K}
and
ρα (f) ≡sup
½|f (x) −f (y)|
|x −y|α
: x, y ∈K, x ̸= y
¾
.
Then (Cα (K) , ||·||α) is a complete normed linear space called a Holder space.
The veriﬁcation that this is a complete normed linear space is routine and is left
for you. More generally, one considers the following class of Holder spaces.
Deﬁnition 40.19 Let K be a compact subset of Rn and let λ ∈(0, 1]. Cm,λ (K)
denotes the set of functions, u which are restrictions of functions deﬁned on Rn to
Ksuch that for |α| ≤m,
Dαu ∈C (K)
and if |α| = m,
Dαu ∈Cλ (K) .
Thus C0,λ (K) = Cλ (K) . The norm of a function in Cm,λ (K) is given by
||u||m,λ ≡sup
|α|=m
ρλ (Dαu) +
X
|α|≤m
||Dαu||∞.
Lemma 40.20 Let m be a positive integer, K a compact subset of Rn, and let
0 < β < λ ≤1. Then the identity map from Cm,λ (K) into Cm,β (K) is compact.
Proof: First note that the containment is obvious because for any function, f,
if
ρλ (f) ≡sup
(
|f (x) −f (y)|
|x −y|λ
: x, y ∈K, x ̸= y
)
< ∞,
Then
ρβ (f)
≡
sup
(
|f (x) −f (y)|
|x −y|β
: x, y ∈K, x ̸= y
)
=
sup
(
|f (x) −f (y)|
|x −y|λ
|x −y|λ−β : x, y ∈K, x ̸= y
)
≤
sup
(
|f (x) −f (y)|
|x −y|λ
diam (K)λ−β : x, y ∈K, x ̸= y
)
< ∞.

1146
BASIC THEORY OF SOBOLEV SPACES
Suppose the identity map, id, is not compact. Then there exists ε > 0 and a
sequence, {fk}∞
k=1 ⊆Cm,λ (K) such that ||fk||m,λ < M for all k but ||fk −fl||β ≥ε
whenever k ̸= l. By the Ascoli Arzela theorem, there exists a subsequence of this,
still denoted by fk such that P
|α|≤m ||Dα (fl −fk)||∞< δ where δ satisﬁes
0 < δ < min
µε
2,
³ε
8
´ ³ ε
8M
´β/(λ−β)¶
.
(40.14)
Therefore, sup|α|=m ρβ (Dα (fk −fl)) ≥ε−δ for all k ̸= l. It follows that there exist
pairs of points and a multi index, α with |α| = m, {xkl, ykl, α} such that
ε −δ
2
< |(Dαfk −Dαfl) (xkl) −((Dαfk −Dαfl) (ykl))|
|xkl −ykl|β
≤2M |xkl −ykl|λ−β
(40.15)
and so considering the ends of the above inequality,
µε −δ
4M
¶1/(λ−β)
< |xkl −ykl| .
Now also, since P
|α|≤m ||Dα (fl −fk)||∞< δ, it follows from the ﬁrst inequality in
40.15 that
ε −δ
2
<
2δ
¡ ε−δ
4M
¢β/(λ−β) .
Since δ < ε/2, this implies
ε
4 <
2δ
¡ ε
8M
¢β/(λ−β)
and so
³ε
8
´ ³ ε
8M
´β/(λ−β)
< δ
contrary to 40.14. This proves the lemma.
Corollary 40.21 Let p > n, U and rU be as in Theorem 40.17 and let m be a
nonnegative integer. Then rU : W m+1,p (Rn) →Cm,λ ¡
U
¢
is continuous as a map
into Cm,λ ¡
U
¢
for all λ ∈[0, 1 −n
p ] and rU is compact if λ < 1 −n
p .
Proof: Suppose uk →0 in W m+1,p (Rn) . Then from 40.13, if λ ≤1 −n
p and
|α| = m
ρλ (Dαuk) ≤C ||Dαuk||1,p diam (U)1−n
p −λ .
Therefore, ρλ (Dαuk) →0. From Theorem 40.17 it follows that for |α| ≤m,
||Dαuk||∞→0
and so ||uk||m,λ →0. This proves the claim about continuity. The claim about
compactness for λ < 1 −n
p follows from Lemma 40.20 and this.
(Bounded in W m,p (Rn)
rU
→Bounded in Cm,1−n
p ¡
U
¢ id
→Compact in Cm,λ ¡
U
¢
.)
It is just as important to consider the case where p < n. To do this case the
following lemma due to Gagliardo [23] will be of interest. See also [1].

40.1.
EMBEDDING THEOREMS FOR W M,P ¡
RN¢
1147
Lemma 40.22 Suppose n ≥2 and wj does not depend on the jth component of x,
xj. Then
Z
Rn
n
Y
j=1
|wj (x)| dmn ≤
n
Y
i=1
µZ
Rn−1 |wj (x)|n−1 dmn−1
¶1/(n−1)
.
In this inequality, assume all the functions are continuous so there can be no mea-
surability questions.
Proof: First note that for n = 2 the inequality reduces to the statement
Z Z
|w1 (x2)| |w2 (x1)| dx1dx2 ≤
Z
|w1 (x2)| dx2
Z
|w2 (x1)| dx1
which is obviously true. Suppose then that the inequality is valid for some n. Using
Fubini’s theorem, Holder’s inequality, and the induction hypothesis,
Z
Rn+1
n+1
Y
j=1
|wj (x)| dmn+1
=
Z
R
Z
Rn |wn+1 (x)|
n
Y
j=1
|wj (x)| dmndxn+1
=
Z
Rn |wn+1 (x)|
Z
R
n
Y
j=1
|wj (x)| dxn+1dmn
=
Z
Rn |wn+1 (x)|


n
Y
j=1
Z
R
|wj (x)|n dxn+1


1/n
dmn
=
Z
Rn |wn+1 (x)|
n
Y
j=1
µZ
R
|wj (x)|n dxn+1
¶1/n
dmn
≤
µZ
Rn |wn+1 (x)|n dmn
¶1/n
·



Z
Rn


n
Y
j=1
µZ
R
|wj (x)|n dxn+1
¶1/n


n/(n−1)
dmn



(n−1)/n
=
µZ
Rn |wn+1 (x)|n dmn
¶1/n
·


Z
Rn
n
Y
j=1
µZ
R
|wj (x)|n dxn+1
¶1/(n−1)
dmn


(n−1)/n

1148
BASIC THEORY OF SOBOLEV SPACES
≤
µZ
Rn |wn+1 (x)|n dmn
¶1/n
·


n
Y
j=1
µZ
Rn−1
µZ
R
|wj (x)|n dxn+1
¶
dmn−1
¶1/(n−1)


(n−1)/n
=
µZ
Rn |wn+1 (x)|n dmn
¶1/n
n
Y
j=1
µZ
Rn |wj (x)|n dmn
¶1/n
=
n+1
Y
j=1
µZ
Rn |wj (x)|n dmn
¶1/n
This proves the lemma.
Lemma 40.23 If φ ∈C∞
c (Rn) and n ≥1, then
||φ||n/(n−1) ≤
1
n√n
n
X
j=1
¯¯¯¯
¯¯¯¯
∂φ
∂xj
¯¯¯¯
¯¯¯¯
1
.
Proof:
The case where n = 1 is obvious if n/ (n −1) is interpreted as ∞.
Assume then that n > 1 and note that for ai ≥0,
n
n
Y
i=1
ai ≤


n
X
j=1
ai


n
In fact, the term on the left is one of many terms of the expression on the right.
Therefore, taking nth roots
n
Y
i=1
a1/n
i
≤
1
n√n
n
X
j=1
ai.
Then observe that for each j = 1, 2, · · ·, n,
|φ (x)| ≤
Z ∞
−∞
¯¯φ,j (x)
¯¯ dxj
so
||φ||n/(n−1)
n/(n−1) ≡
Z
Rn |φ (x)|n/(n−1) dmn
≤
Z
Rn
n
Y
j=1
µZ ∞
−∞
¯¯φ,j (x)
¯¯ dxj
¶1/(n−1)
dmn
and from Lemma 40.22 this is dominated by
≤
n
Y
j=1
µZ
Rn
¯¯φ,j (x)
¯¯ dmn
¶1/(n−1)
.

40.1.
EMBEDDING THEOREMS FOR W M,P ¡
RN¢
1149
Hence Qn
i=1 a1/n
i
≤
1
n√n
Pn
j=1 ai
||φ||n/(n−1)
≤
n
Y
j=1
µZ
Rn
¯¯φ,j (x)
¯¯ dmn
¶1/n
≤
1
n√n
n
X
j=1
Z
Rn
¯¯φ,j (x)
¯¯ dmn
=
1
n√n
n
X
j=1
¯¯¯¯φ,i
¯¯¯¯
1
and this proves the lemma.
The above lemma is due to Gagliardo and Nirenberg.
With this lemma, it is possible to prove a major embedding theorem which
follows.
Theorem 40.24 Let 1 ≤p < n and 1
q = 1
p −1
n. Then if f ∈W 1,p (Rn) ,
||f||q ≤
1
n√n
(n −1) p
n −p
||f||1,p,Rn .
Proof:
From the deﬁnition of W 1,p (Rn) , C1
c (Rn) is dense in W 1,p.
Here
C1
c (Rn) is the space of continuous functions having continuous derivatives which
have compact support. The desired inequality will be established for such φ and
then the density of this set in W 1,p (Rn) will be exploited to obtain the inequality
for all f ∈W 1,p (Rn). First note that the case where p = 1 follows immediately
from the above lemma and so it is only necessary to consider the case where p > 1.
Let φ ∈C1
c (Rn) and consider |φ|r where r > 1. Then a short computation shows
|φ|r ∈C1
c (Rn) and
¯¯¯|φ|r
,i
¯¯¯ = r |φ|r−1 ¯¯φ,i
¯¯ .
Therefore, from Lemma 40.23,
µZ
|φ|
rn
n−1 dmn
¶(n−1)/n
≤
r
n√n
n
X
i=1
Z
|φ|r−1 ¯¯φ,i
¯¯ dmn
≤
r
n√n
n
X
i=1
µZ ¯¯φ,i
¯¯p
¶1/p µZ ³
|φ|r−1´p/(p−1)
dmn
¶(p−1)/p
.
Now choose r such that
(r −1) p
p −1
=
rn
n −1.

1150
BASIC THEORY OF SOBOLEV SPACES
That is, let r = p(n−1)
n−p
> 1 and so
rn
n−1 =
np
n−p. Then this reduces to
µZ
|φ|
np
n−p dmn
¶(n−1)/n
≤
r
n√n
n
X
i=1
µZ ¯¯φ,i
¯¯p
¶1/p µZ
|φ|
np
n−p dmn
¶(p−1)/p
.
Also, n−1
n
−p−1
p
= n−p
np and so, dividing both sides by the last term yields
µZ
|φ|
np
n−p dmn
¶ n−p
np
≤
r
n√n
n
X
i=1
µZ ¯¯φ,i
¯¯p
¶1/p
≤
r
n√n ||φ||1,p,Rn .
Letting q =
np
n−p, it follows 1
q = n−p
np = 1
p −1
n and
||φ||q ≤
r
n√n ||φ||1,p,Rn .
Now let f ∈W m,p (Rn) and let ||φk −f||1,p,Rn →0 as k →∞. Taking another
subsequence, if necessary, you can also assume φk (x) →f (x) a.e. Therefore, by
Fatou’s lemma,
||f||q
≤
lim inf
k→∞
µZ
Rn |φk (x)|q dmn
¶1/q
≤
lim inf
k→∞
r
n√n ||φk||1,p,Rn = ||f||1,p,Rn .
This proves the theorem.
Corollary 40.25 Suppose mp < n. Then W m,p (Rn) ⊆Lq (Rn) where q =
np
n−mp
and the identity map, id : W m,p (Rn) →Lq (Rn) is continuous.
Proof: This is true if m = 1 according to Theorem 40.24. Suppose it is true for
m −1 where m > 1. If u ∈W m,p (Rn) and |α| ≤1, then Dαu ∈W m−1,p (Rn) so by
induction, for all such α,
Dαu ∈L
np
n−(m−1)p (Rn) .
Thus u ∈W 1,q1 (Rn) where
q1 =
np
n −(m −1) p
By Theorem 40.24, it follows that u ∈Lq (Rn) where
1
q = n −(m −1) p
np
−1
n = n −mp
np
.
This proves the corollary.
There is another similar corollary of the same sort which is interesting and useful.

40.1.
EMBEDDING THEOREMS FOR W M,P ¡
RN¢
1151
Corollary 40.26 Suppose m ≥1 and j is a nonnegative integer satisfying jp < n.
Then
W m+j,p (Rn) ⊆W m,q (Rn)
for
q ≡
np
n −jp
(40.16)
and the identity map is continuous.
Proof: If |α| ≤m, then Dαu ∈W j,p (Rn) and so by Corollary 40.25, Dαu ∈
Lq (Rn) where q is given above. This means u ∈W m,q (Rn).
The above corollaries imply yet another interesting corollary which involves em-
beddings in the Holder spaces.
Corollary 40.27 Suppose jp < n < (j + 1) p and let m be a positive integer. Let
U be any bounded open set in Rn. Then letting rU denote the restriction to U,
rU : W m+j,p (Rn) →Cm−1,λ ¡
U
¢
is continuous for every λ ≤λ0 ≡(j + 1) −n
p and
if λ < (j + 1) −n
p , then rU is compact.
Proof: From Corollary 40.26 W m+j,p (Rn) ⊆W m,q (Rn) where q is given by
40.16. Therefore,
np
n −jp > n
and so by Corollary 40.21, W m,q (Rn) ⊆Cm−1,λ ¡
U
¢
for all λ satisfying
0 < λ < 1 −(n −jp) n
np
= p (j + 1) −n
p
= (j + 1) −n
p .
The assertion about compactness follows from the compactness of the embedding
of Cm−1,λ0 ¡
U
¢
into Cm−1,λ ¡
U
¢
for λ < λ0. See Lemma 40.20.
There are other embeddings of this sort available. You should see Adams [1] for a
more complete listing of these. Next are some theorems about compact embeddings.
This requires some consideration of which subsets of Lp (U) are compact. The main
theorem is the following. See [1].
Theorem 40.28 Let K be a bounded subset of Lp (U) and suppose that for all
ε > 0, there exist a δ > 0 such that if |h| < δ, then
Z
Rn |eu (x + h) −eu (x)|p dx < εp
(40.17)
Suppose also that for each ε > 0 there exists an open set, G ⊆U such that G is
compact and for all u ∈K,
Z
U\G
|u (x)|p dx < εp
(40.18)
Then K is precompact in Lp (Rn).

1152
BASIC THEORY OF SOBOLEV SPACES
Proof: To save fussing ﬁrst consider the case where U = Rn so that eu = u.
Suppose the two conditions hold and let φk be a molliﬁer of the form φk (x) =
knφ (kx) where spt (φ) ⊆B (0, 1) . Consider
Kk ≡{u ∗φk : u ∈K} .
and verify the conditions for the Ascoli Arzela theorem for these functions deﬁned
on G. Say ||u||p ≤M for all u ∈K.
First of all, for u ∈K and x ∈Rn,
|u ∗φk (x)|p
≤
µZ
|u (x −y) φk (y)| dy
¶p
=
µZ
|u (y) φk (x −y)| dy
¶p
≤
Z
|u (y)|p φk (x −y) dy
≤
µ
sup
z∈Rn φk (z)
¶ Z
|u (y)| dy ≤M
µ
sup
z∈Rn φk (z)
¶
showing the functions in Kk are uniformly bounded.
Next suppose x, x1 ∈Kk and consider
|u ∗φk (x) −u ∗φk (x1)|
≤
Z
|u (x −y) −u (x1−y)| φk (y) dy
≤
µZ
|u (x −y) −u (x1−y)|p dy
¶1/p µZ
φk (y)q dy
¶q
which by assumption 40.17 is small independent of the choice of u whenever |x −x1|
is small enough.
Note that k is ﬁxed in the above.
Therefore, the set, Kk is
precompact in C
¡
G
¢
thanks to the Ascoli Arzela theorem. Next consider how well
u ∈K is approximated by u ∗φk in Lp (Rn) . By Minkowski’s inequality,
µZ
|u (x) −u ∗φk (x)|p dx
¶1/p
≤
µZ µZ
|u (x) −u (x −y)| φk (y) dy
¶p
dx
¶1/p
≤
Z
B(0, 1
k)
φk (y)
µZ
|u (x) −u (x −y)|p dx
¶1/p
dy.
Now let η > 0 be given. From 40.17 there exists k large enough that for all u ∈K,
Z
B(0, 1
k)
φk (y)
µZ
|u (x) −u (x −y)|p dx
¶1/p
dy ≤
Z
B(0, 1
k)
φk (y) η dy = η.

40.1.
EMBEDDING THEOREMS FOR W M,P ¡
RN¢
1153
Now let ε > 0 be given and let δ and G correspond to ε as given in the hypotheses
and let 1/k < δ and also k is large enough that for all u ∈K,
||u −u ∗φk||p < ε
as in the above inequality. By the Ascoli Arzela theorem there exists an
Ã
ε
m
¡
G + B (0, 1)
¢
!1/p
net for Kk in C
¡
G
¢
. That is, there exist {ui}m
i=1 ⊆K such that for any u ∈K,
||u ∗φk −uj ∗φk||∞<
Ã
ε
m
¡
G + B (0, 1)
¢
!1/p
for some j. Letting u ∈K be given, let uj ∈{ui}m
i=1 ⊆K be such that the above
inequality holds. Then
||u −uj||p
≤
||u −u ∗φk||p + ||u ∗φk −uj ∗φk||p + ||uj ∗φk −uj||p
<
2ε + ||u ∗φk −uj ∗φk||p
≤
2ε +
ÃZ
G+B(0,1)
|u ∗φk −uj ∗φk|p dx
!1/p
+
ÃZ
Rn\(G+B(0,1))
|u ∗φk −uj ∗φk|p dx
!1/p
≤
2ε + ε1/p
+
ÃZ
Rn\(G+B(0,1))
µZ
|u (x −y) −uj (x −y)| φk (y) dy
¶p
dx
!1/p
≤
2ε + ε1/p
+
Z
φk (y)
ÃZ
Rn\(G+B(0,1))
(|u (x −y)| + |uj (x −y)|)p dx
!1/p
dy
≤
2ε + ε1/p +
Z
φk (y)
ÃZ
Rn\G
(|u (x)| + |uj (x)|)p dx
!1/p
dy
≤
2ε + ε1/p + 2p−1
Z
φk (y)
ÃZ
Rn\G
(|u (x)|p + |uj (x)|p) dx
!1/p
dy
≤
2ε + ε1/p + 2p−121/pε

1154
BASIC THEORY OF SOBOLEV SPACES
and since ε > 0 is arbitrary, this shows that K is totally bounded and is therefore
precompact.
Now for an arbitrary open set, U and K given in the hypotheses of the theorem,
let eK ≡{eu : u ∈K} and observe that eK is precompact in Lp (Rn) . But this is the
same as saying that K is precompact in Lp (U) . This proves the theorem.
Actually the converse of the above theorem is also true [1] but this will not be
needed so I have left it as an exercise for anyone interested.
Lemma 40.29 Let u ∈W 1,1 (U) for U an open set and let φ ∈C∞
c (U) . Then
there exists a constant,
C
³
φ, ||u||1,1,U
´
,
depending only on the indicated quantities such that whenever v ∈Rn with |v| <
dist
¡
spt (φ) , U C¢
, it follows that
Z
Rn
¯¯¯f
φu (x + v) −f
φu (x)
¯¯¯ dx ≤C
³
φ, ||u||1,1,U
´
|v| .
Proof: First suppose u ∈C∞¡
U
¢
. Then for any x ∈spt (φ) ∪(spt (φ) −v) ≡
Gv, the chain rule implies
|φu (x + v) −φu (x)|
≤
Z 1
0
n
X
i=1
¯¯¯(φu),i (x + tv) vi
¯¯¯ dt
≤
Z 1
0
n
X
i=1
¯¯¡
φ,iu + u,iφ
¢
(x + tv)
¯¯ dt |v| .
Therefore, for such u,
Z
Rn
¯¯¯f
φu (x + v) −f
φu (x)
¯¯¯ dx
=
Z
Gv
|φu (x + v) −φu (x)| dx
≤
Z
Gv
Z 1
0
n
X
i=1
¯¯¡
φ,iu + u,iφ
¢
(x + tv)
¯¯ dtdx |v|
≤
Z 1
0
Z
Gv
n
X
i=1
¯¯¡
φ,iu + u,iφ
¢
(x + tv)
¯¯ dxdt |v|
≤
C
³
φ, ||u||1,1,U
´
|v|

40.1.
EMBEDDING THEOREMS FOR W M,P ¡
RN¢
1155
where C is a continuous function of ||u||1,1,U. Now for general u ∈W 1,1 (U) , let
uk →u in W 1,1 (U) where uk ∈C∞¡
U
¢
. Then for |v| < dist
¡
spt (φ) , U C¢
,
Z
Rn
¯¯¯f
φu (x + v) −f
φu (x)
¯¯¯ dx
=
Z
Gv
|φu (x + v) −φu (x)| dx
=
lim
k→∞
Z
Gv
|φuk (x + v) −φuk (x)| dx
≤
lim
k→∞C
³
φ, ||uk||1,1,U
´
|v|
=
C
³
φ, ||u||1,1,U
´
|v| .
This proves the lemma.
Lemma 40.30 Let U be a bounded open set and deﬁne for p > 1
S ≡
n
u ∈W 1,1 (U) ∩Lp (U) : ||u||1,1,U + ||u||Lp(U) ≤M
o
(40.19)
and let φ ∈C∞
c (U) and
S1 ≡{uφ : u ∈S} .
(40.20)
Then S1 is precompact in Lq (U) where 1 ≤q < p.
Proof: This depends on Theorem 40.28. The second condition is satisﬁed by
taking G ≡spt (φ). Thus, for w ∈S1,
Z
U\G
|w (x)|q dx = 0 < εp.
It remains to satisfy the ﬁrst condition. It is necessary to verify there exists δ > 0
such that if |v| < δ, then
Z
Rn
¯¯¯f
φu (x + v) −f
φu (x)
¯¯¯
q
dx < εp.
(40.21)
Let spt (φ) ∪(spt (φ) −v) ≡Gv. Now if h is any measurable function, and if
θ ∈(0, 1) is chosen small enough that θq < 1,
Z
Gv
|h|q dx
=
Z
Gv
|h|θq |h|(1−θ)q dx
≤
µZ
Gv
|h| dx
¶θq µZ
Gv
³
|h|(1−θ)q´
1
1−θq ¶1−θq
=
µZ
Gv
|h| dx
¶θq µZ
Gv
|h|
(1−θ)q
1−θq
¶1−θq
.
(40.22)

1156
BASIC THEORY OF SOBOLEV SPACES
Now let θ also be small enough that there exists r > 1 such that
r(1 −θ) q
1 −θq
= p
and use Holder’s inequality in the last factor of the right side of 40.22. Then 40.22
is dominated by
µZ
Gv
|h| dx
¶θq µZ
Gv
|h|p
¶ 1−θq
r
µZ
Gv
1dx
¶1/r′
=
C
³
||h||Lp(Gv) , mn (Gv)
´ µZ
Gv
|h| dx
¶θq
.
Therefore, for u ∈S,
Z
Rn
¯¯¯f
φu (x + v) −f
φu (x)
¯¯¯
q
dx =
Z
Gv
|φu (x + v) −φu (x)|q dx
≤C
³
||φu (·+v) −φu (·)||Lp(Gv) , mn (Gv)
´ µZ
Gv
|φu (x + v) −φu (x)| dx
¶θq
≤C
³
2 ||φu (·)||Lp(U) , mn (U)
´ µZ
Gv
|φu (x + v) −φu (x)| dx
¶θq
≤
C (φ, M, mn (U))
µZ
Gv
|φu (x + v) −φu (x)| dx
¶θq
=
C (φ, M, mn (U))
µZ
Rn
¯¯¯f
φu (x + v) −f
φu (x)
¯¯¯ dx
¶θq
.
(40.23)
Now by Lemma 40.29,
Z
Rn
¯¯¯f
φu (x + v) −f
φu (x)
¯¯¯ dx ≤C
³
φ, ||u||1,1,U
´
|v|
(40.24)
and so from 40.23 and 40.24, and adjusting the constants
Z
Rn
¯¯¯f
φu (x + v) −f
φu (x)
¯¯¯
q
dx
≤
C (φ, M, mn (U))
³
C
³
φ, ||u||1,1,U
´
|v|
´θq
=
C (φ, M, mn (U)) |v|θq
which veriﬁes 40.21 whenever |v| is suﬃciently small. This proves the lemma be-
cause the conditions of Theorem 40.28 are satisﬁed.
Theorem 40.31 Let U be a bounded open set and deﬁne for p > 1
S ≡
n
u ∈W 1,1 (U) ∩Lp (U) : ||u||1,1,U + ||u||Lp(U) ≤M
o
(40.25)
Then S is precompact in Lq (U) where 1 ≤q < p.

40.2.
AN EXTENSION THEOREM
1157
Proof: If suﬃces to show that every sequence, {uk}∞
k=1 ⊆S has a subsequence
which converges in Lq (U) . Let {Km}∞
m=1 denote a sequence of compact subsets
of U with the property that Km ⊆Km+1 for all m and ∪∞
m=1Km = U. Now let
φm ∈C∞
c (U) such that φm (x) ∈[0, 1] and φm (x) = 1 for all x ∈Km. Let
Sm ≡{φmu : u ∈S}.
By Lemma 40.30 there exists a subsequence of {uk}∞
k=1 ,
denoted here by {u1,k}∞
k=1 such that {φ1u1,k}∞
k=1 converges in Lq (U) . Now S2 is
also precompact in Lq (U) and so there exists a subsequence of {u1,k}∞
k=1 , denoted
by {u2,k}∞
k=1 such that {φ2u2,k}∞
k=1 converges in L2 (U) . Thus it is also the case that
{φ1u2,k}∞
k=1 converges in Lq (U) . Continue taking subsequences in this manner such
that for all l ≤m, {φlum,k}∞
k=1 converges in Lq (U). Let {wm}∞
m=1 = {um,m}∞
m=1 so
that {wk}∞
k=m is a subsequence of {um,k}∞
k=1 . Then it follows for all k, {φkwm}∞
m=1
must converge in Lq (U) . For u ∈S,
||u −φku||q
Lq(U)
=
Z
U
|u|q (1 −φk)q dx
≤
µZ
U
|u|p dx
¶q/p µZ
U
(1 −φk)qr dx
¶1/r
≤
M
µZ
U
(1 −φk)qr dx
¶1/r
where q/p + 1/r = 1. Now φl (x) →XU (x) and so the integrand in the last integral
converges to 0 by the dominated convergence theorem. Therefore, k may be chosen
large enough that for all u ∈S,
||u −φku||q
Lq(U) ≤
³ε
3
´q
.
Fix such a value of k. Then
||wq −wp||Lq(U) ≤
||wq −φkwq||Lq(U) + ||φkwq −φkwp||Lq(U) + ||wp −φkwp||Lq(U)
≤2ε
3 + ||φkwq −φkwp||Lq(U) .
But {φkwm}∞
m=1 converges in Lq (U) and so the last term in the above is less than
ε/3 whenever p, q are large enough. Thus {wm}∞
m=1 is a Cauchy sequence and must
therefore converge in Lq (U). This proves the theorem.
40.2
An Extension Theorem
Deﬁnition 40.32 An open subset, U, of Rn has a Lipschitz boundary if it satisﬁes
the following conditions.
For each p ∈∂U ≡U \ U, there exists an open set,
Q, containing p, an open interval (a, b), a bounded open box B ⊆Rn−1, and an
orthogonal transformation R such that
RQ = B × (a, b),
(40.26)

1158
BASIC THEORY OF SOBOLEV SPACES
R (Q ∩U) = {y ∈Rn : by ∈B, a < yn < g (by)}
(40.27)
where g is Lipschitz continuous on B, a < min
©
g (x) : x ∈B
ª
, and
by ≡(y1, · · ·, yn−1).
Letting W = Q ∩U the following picture describes the situation.




ZZZZZ
ZZZZZ




x
W
Q
-
R
R(W)
a
b
R(Q)
y
The following lemma is important.
Lemma 40.33 If U is an open subset of Rn which has a Lipschitz boundary, then
it satisﬁes the segment condition and so Xm,p (U) = W m,p (U) .
Proof: For x ∈∂U, simply look at a single open set, Qx described in the above
which contains x. Then consider an open set whose intersection with U is of the
form RT ({y :by ∈B, g (by) −ε < yn < g (by)}) and a vector of the form εRT (−en)
where ε is chosen smaller than min
©
g (x) : x ∈B
ª
−a. There is nothing to prove
for points of U.
One way to extend many of the above theorems to more general open sets than
Rn is through the use of an appropriate extension theorem. In this section, a fairly
general one will be presented.
Lemma 40.34 Let B × (a, b) be as described in Deﬁnition 40.32 and let
V −≡{(by, yn) : yn < g (by)} , V + ≡{(by, yn) : yn > g (by)},
for g a Lipschitz function of the sort described in this deﬁnition. Suppose u+ and
u−are Lipschitz functions deﬁned on V + and V −respectively and suppose that
u+ (by, g (by)) = u−(by, g (by)) for all by ∈B. Let
u (by, yn) ≡
½
u+ (by, yn) if (by, yn) ∈V +
u−(by, yn) if (by, yn) ∈V −
and suppose spt (u) ⊆B × (a, b). Then extending u to be 0 oﬀof B × (a, b), u is
continuous and the weak partial derivatives, u,i, are all in L∞(Rn) ∩Lp (Rn) for
all p > 1 and u,i = (u+),i on V + and u,i = (u−),i on V −.

40.2.
AN EXTENSION THEOREM
1159
Proof: Consider the following picture which is descriptive of the situation.
a
b
¡
¡
¡¡ spt(u)
B
Note ﬁrst that u is Lipschitz continuous. To see this, consider |u (y1) −u (y2)|
where
¡byi, yi
n
¢
= yi. There are various cases to consider depending on whether
yi
n is above g (byi) . Suppose y1
n < g (by1) and y2
n > g (by2) . Then letting K ≥
max (Lip (u+) , Lip (u−)) ,
¯¯u
¡by1, y1
n
¢
−u
¡by2, y2
n
¢¯¯
≤
¯¯u
¡by1, y1
n
¢
−u
¡by2, y1
n
¢¯¯ +
¯¯u
¡by2, y1
n
¢
−u (by2, g (by2))
¯¯
+
¯¯u (by2, g (by2)) −u
¡by2, y2
n
¢¯¯
≤
K |by1 −by2| + K
£
g (by2) −y1
n + y2
n −g (by2)
¤
=
K
¡
|by1 −by2| +
¯¯y1
n −y2
n
¯¯¢
≤K√n |y1 −y2|
The other cases are similar. Thus u is a Lipschitz continuous function which has
compact support. By Corollary 37.18 on Page 1092 it follows that u,i ∈L∞(Rn) ∩
Lp (Rn) for all p > 1. It remains to verify u,i = (u+),i on V + and u,i = (u−),i on
V −. The last claim is obvious from the deﬁnition of weak derivatives.
Lemma 40.35 In the situation of Lemma 40.34 let u ∈C1 ³
V −
´
∩C1
c (B × (a, b))3
and deﬁne
w (by, yn) ≡



u (by, yn) if by ∈B and yn ≤g (by) ,
u (by, 2g (by) −yn) , if by ∈B and yn > g (by)
0 if by /∈B.
Then w ∈W 1,p (Rn) and there exists a constant, C depending only on Lip (g) and
dimension such that
||w||W 1,p(Rn) ≤C ||u||W 1,p(V −) .
Denote w by E0u. Thus E0 (u) (y) = u (y) for all y ∈V −but E0u = w is deﬁned
on all of Rn. Also, E0 is a linear mapping.
Proof: As in the previous lemma, w is Lipschitz continuous and has compact
support so it is clear w ∈W 1,p (Rn) . The main task is to ﬁne w,i for by ∈B and
3This means that spt (u) ⊆B × (a, b) and u ∈C1 ³
V −
´
.

1160
BASIC THEORY OF SOBOLEV SPACES
yn > g (by) and then to extract an estimate of the right sort. Denote by U the set
of points of Rn with the property that (by, yn) ∈U if and only if by /∈B or by ∈B
and yn > g (by) . Then letting φ ∈C∞
c (U) , suppose ﬁrst that i < n. Then
Z
U
w (by, yn) φ,i (y) dy
≡lim
h→0
Z
U
φ (y) u
¡by −hen−1
i
, 2g
¡by −hen−1
i
¢
−yn
¢
−u (by, 2g (by) −yn)
h
dy
(40.28)
=
lim
h→0
½−1
h
Z
U
φ (y)
£
D1u (by, 2g (by) −yn)
¡
hen−1
i
¢
+2D2u (by, 2g (by) −yn)
¡
g
¡by −hen−1
i
¢
−g (by)
¢¤
dy
+ −1
h
Z
U
φ (y)
£
o
¡
g
¡by −hen−1
i
¢
−g (by)
¢
+ o (h)
¤
dy
¾
where en−1
i
is the unit vector in Rn−1 having all zeros except for a 1 in the ith
position. Now by Rademacher’s theorem, Dg (by) exists for a.e. by and so except for
a set of measure zero, the expression, g
¡by −hen−1
i
¢
−g (by) is o (h) and also for by
not in the exceptional set,
g
¡by −hen−1
i
¢
−g (by) = −hDg (by) en−1
i
+ o (h) .
Therefore, since the integrand in 40.28 has compact support and because of the
Lipschitz continuity of all the functions, the dominated convergence theorem may
be applied to obtain
Z
U
w (by, yn) φ,i (y) dy =
Z
U
φ (y)
£
−D1u (by, 2g (by) −yn)
¡
en−1
i
¢
+ 2D2u (by, 2g (by) −yn)
¡
Dg (by) en−1
i
¢¤
dy
=
Z
U
φ (y)
·
−∂u
∂yi
(by, 2g (by) −yn) + 2 ∂u
∂yn
(by, 2g (by) −yn) ∂g (by)
∂yi
¸
dy
and so
w,i (y) = ∂u
∂yi
(by, 2g (by) −yn) −2 ∂u
∂yn
(by, 2g (by) −yn) ∂g (by)
∂yi
(40.29)

40.2.
AN EXTENSION THEOREM
1161
whenever i < n which is what you would expect from a formal application of the
chain rule. Next suppose i = n.
Z
U
w (by, yn) φ,n (y) dy
=
lim
h→0
Z
U
u (by, 2g (by) −(yn −h)) −u (by, 2g (by) −yn)
h
φ (y) dy
=
lim
h→0
Z
U
D2u (by, 2g (by) −yn) h + o (h)
h
φ (y) dy
=
Z
U
∂u
∂yn
(by, 2g (by) −yn) φ (y) dy
showing that
w,n (y) = −∂u
∂yn
(by, 2g (by) −yn)
(40.30)
which is also expected.
From the deﬁnnition, for y ∈Rn \ U ≡{(by, yn) : yn ≤g (by)} it follows w,i = u,i
and on U, w,i is given by 40.29 and 40.30. Consider ||w,i||p
Lp(U) for i < n. From
40.29
||w,i||p
Lp(U) =
Z
U
¯¯¯¯
∂u
∂yi
(by, 2g (by) −yn) −2 ∂u
∂yn
(by, 2g (by) −yn) ∂g (by)
∂yi
¯¯¯¯
p
dy

1162
BASIC THEORY OF SOBOLEV SPACES
≤
2p−1
Z
U
¯¯¯¯
∂u
∂yi
(by, 2g (by) −yn)
¯¯¯¯
p
+2p
¯¯¯¯
∂u
∂yn
(by, 2g (by) −yn)
¯¯¯¯
p
Lip (g)p dy
≤
4p (1 + Lip (g)p)
Z
U
¯¯¯¯
∂u
∂yi
(by, 2g (by) −yn)
¯¯¯¯
p
+
¯¯¯¯
∂u
∂yn
(by, 2g (by) −yn)
¯¯¯¯
p
dy
=
4p (1 + Lip (g)p)
Z
B
Z ∞
g(by)
¯¯¯¯
∂u
∂yi
(by, 2g (by) −yn)
¯¯¯¯
p
+
¯¯¯¯
∂u
∂yn
(by, 2g (by) −yn)
¯¯¯¯
p
dyndby
=
4p (1 + Lip (g)p)
Z
B
Z g(by)
−∞
¯¯¯¯
∂u
∂yi
(by, zn)
¯¯¯¯
p
+
¯¯¯¯
∂u
∂yn
(by, zn)
¯¯¯¯
p
dzndby
=
4p (1 + Lip (g)p)
Z
B
Z g(by)
a
¯¯¯¯
∂u
∂yi
(by, zn)
¯¯¯¯
p
+
¯¯¯¯
∂u
∂yn
(by, zn)
¯¯¯¯
p
dzndby
≤
4p (1 + Lip (g)p) ||u||p
1,p,V −
Now by similar reasoning,
||w,n||p
Lp(U)
=
Z
U
¯¯¯¯
−∂u
∂yn
(by, 2g (by) −yn)
¯¯¯¯
p
dy
=
Z
B
Z ∞
g(by)
¯¯¯¯
−∂u
∂yn
(by, 2g (by) −yn)
¯¯¯¯
p
dyndby
=
Z
B
Z g(by)
a
¯¯¯¯
−∂u
∂yn
(by, zn)
¯¯¯¯
p
dzndby = ||u,n||p
1,p,V −.
It follows
||w||p
1,p,Rn
=
||w||p
1,p,U + ||u||p
1,p,V −
≤
4pn (1 + Lip (g)p) ||u||p
1,p,V −+ ||u||p
1,p,V −
and so
||w||p
1,p,Rn ≤4pn (2 + Lip (g)p) ||u||p
1,p,V −
which implies
||w||1,p,Rn ≤4n1/p (2 + Lip (g)p)1/p ||u||1,p,V −

40.2.
AN EXTENSION THEOREM
1163
It is obvious that E0 is a linear mapping. This proves the theorem.
Now recall Deﬁnition 40.32, listed here for convenience.
Deﬁnition 40.36 An open subset, U, of Rn has a Lipschitz boundary if it satisﬁes
the following conditions.
For each p ∈∂U ≡U \ U, there exists an open set,
Q, containing p, an open interval (a, b), a bounded open box B ⊆Rn−1, and an
orthogonal transformation R such that
RQ = B × (a, b),
(40.31)
R (Q ∩U) = {y ∈Rn : by ∈B, a < yn < g (by)}
(40.32)
where g is Lipschitz continuous on B, a < min
©
g (x) : x ∈B
ª
, and
by ≡(y1, · · ·, yn−1).
Letting W = Q ∩U the following picture describes the situation.




ZZZZZ
ZZZZZ




x
W
Q
-
R
R(W)
a
b
R(Q)
y
Lemma 40.37 In the situation of Deﬁnition 40.32 let u ∈C1 ¡
U
¢
∩C1
c (Q) and
deﬁne
Eu ≡R∗E0
¡
RT ¢∗u.
where
¡
RT ¢∗maps W 1,p (U ∩Q) to W 1,p (R (W)) . Then E is linear and satisﬁes
||Eu||W 1,p(Rn) ≤C ||u||W 1,p(Q∩U) , Eu (x) = u (x) for x ∈Q ∩U.
where C depends only on the dimension and Lip (g) .
Proof: This follows from Theorem 40.14 and Lemma 40.35.
The following theorem is a general extension theorem for Sobolev spaces.
Theorem 40.38 Let U be a bounded open set which has Lipschitz boundary. Then
for each p ≥1, there exists E ∈L
¡
W 1,p (U) , W 1,p (Rn)
¢
such that Eu (x) = u (x)
a.e. x ∈U.
Proof: Let ∂U ⊆∪p
i=1Qi Where the Qi are as described in Deﬁnition 40.36.
Also let Ri be the orthogonal trasformation and gi the Lipschitz functions associated
with Qi as in this deﬁnition. Now let Q0 ⊆Q0 ⊆U be such that U ⊆∪p
i=0Qi, and

1164
BASIC THEORY OF SOBOLEV SPACES
let ψi ∈C∞
c (Qi) with ψi (x) ∈[0, 1] and Pp
i=0 ψi (x) = 1 on U. For u ∈C∞¡
U
¢
,
let E0 (ψ0u) ≡ψ0u on Q0 and 0 oﬀQ0. Thus
¯¯¯¯E0 (ψ0u)
¯¯¯¯
1,p,Rn = ||ψ0u||1,p,U .
For i ≥1, let
Ei (ψiu) ≡R∗
i E0
¡
RT ¢∗(ψiu) .
Thus, by Lemma 40.37
¯¯¯¯E1 (ψiu)
¯¯¯¯
1,p,Rn ≤C ||ψiu||1,p,Qi∩U
where the constant depends on Lip (gi) but is independent of u ∈C∞¡
U
¢
. Now
deﬁne E as follows.
Eu ≡
p
X
i=0
Ei (ψiu) .
Thus for u ∈C∞¡
U
¢
, it follows Eu (x) = u (x) for all x ∈U. Also,
||Eu||1,p,Rn
≤
p
X
i=0
¯¯¯¯Ei (ψiu)
¯¯¯¯ ≤
p
X
i=0
Ci ||ψiu||1,p,Qi∩U
=
p
X
i=0
Ci ||ψiu||1,p,U ≤
p
X
i=0
Ci ||u||1,p,U
≤
(p + 1)
p
X
i=0
Ci ||u||1,p,U ≡C ||u||1,p,U .
(40.33)
where C depends on the ψi and the gi but is independent of u ∈C∞¡
U
¢
. Therefore,
by density of C∞¡
U
¢
in W 1,p (U) , E has a unique continuous extension to W 1,p (U)
still denoted by E satisfying the inequality determined by the ends of 40.33. It
remains to verify that Eu (x) = u (x) a.e. for x ∈U.
Let uk →u in W 1,p (U) where uk ∈C∞¡
U
¢
. Therefore, by 40.33, Euk →Eu
in W 1,p (Rn) . Since Euk (x) = uk (x) for each k,
||u −Eu||Lp(U)
=
lim
k→∞||uk −Euk||Lp(U)
=
lim
k→∞||Euk −Euk||Lp(U) = 0
which shows u (x) = Eu (x) for a.e. x ∈U as claimed. This proves the theorem.
Deﬁnition 40.39 Let U be an open set. Then W m,p
0
(U) is the closure of the set,
C∞
c (U) in W m,p (U) .
Corollary 40.40 Let U be a bounded open set which has Lipschitz boundary and
let W be an open set containing U.
Then for each p ≥1, there exists EW ∈
L
³
W 1,p (U) , W 1,p
0
(W)
´
such that EW u (x) = u (x) a.e. x ∈U.

40.3.
GENERAL EMBEDDING THEOREMS
1165
Proof: Let ψ ∈C∞
c (W) and ψ = 1 on U. Then let EW u ≡ψEu where E is
the extension operator of Theorem 40.38.
Extension operators of the above sort exist for many open sets, U, not just for
bounded ones. In particular, the above discussion would apply to an open set, U,
not necessarily bounded, if you relax the condition that the Qi must be bounded
but require the existence of a ﬁnite partition of unity {ψi}p
i=1 having the property
that ψi and ψi,j are uniformly bounded for all i, j. The proof would be identical
to the above. My main interest is in bounded open sets so the above theorem will
suﬃce. Such an extension operator will be referred to as a (1, p) extension operator.
40.3
General Embedding Theorems
With the extension theorem it is possible to give a useful theory of embeddings.
Theorem 40.41 Let 1 ≤p < n and
1
q =
1
p −1
n and let U be any open set for
which there exists a (1, p) extension operator. Then if u ∈W 1,p (U) , there exists a
constant independent of u such that
||u||Lq(U) ≤C ||u||1,p,U .
If U is bounded and r < q, then id : W 1,p (U) →Lr (U) is also compact.
Proof: Let E be the (1, p) extension operator. Then by Theorem 40.24 on Page
1149
||u||Lq(U)
≤
||Eu||Lq(Rn) ≤
1
n√n
(n −1) p
(n −p) ||Eu||1,p,Rn
≤
C ||u||1,p,U .
It remains to prove the assertion about compactness. If S ⊆W 1,p (U) is bounded
then
sup
u∈S
n
||u||1,1,U + ||u||Lq(U)
o
< ∞
and so by Theorem 40.31 on Page 1156, it follows S is precompact in Lr (U) .This
proves the theorem.
Corollary 40.42 Suppose mp < n and U is an open set satisfying the segment con-
dition which has a (1, p) extension operator for all p. Then id ∈L (W m,p (U) , Lq (U))
where q =
np
n−mp.
Proof: This is true if m = 1 according to Theorem 40.41. Suppose it is true for
m −1 where m > 1. If u ∈W m,p (U) and |α| ≤1, then Dαu ∈W m−1,p (U) so by
induction, for all such α,
Dαu ∈L
np
n−(m−1)p (U) .

1166
BASIC THEORY OF SOBOLEV SPACES
Thus, since U has the segment condition, u ∈W 1,q1 (U) where
q1 =
np
n −(m −1) p
By Theorem 40.41, it follows u ∈Lq (Rn) where
1
q = n −(m −1) p
np
−1
n = n −mp
np
.
This proves the corollary.
There is another similar corollary of the same sort which is interesting and useful.
Corollary 40.43 Suppose m ≥1 and j is a nonnegative integer satisfying jp < n.
Also suppose U has a (1, p) extension operator for all p ≥1 and satisﬁes the segment
condition. Then
id ∈L
¡
W m+j,p (U) , W m,q (U)
¢
where
q ≡
np
n −jp.
(40.34)
If, in addition to the above, U is bounded and 1 ≤r < q, then
id ∈L
¡
W m+j,p (U) , W m,r (U)
¢
and is compact.
Proof: If |α| ≤m, then Dαu ∈W j,p (U) and so by Corollary 40.42, Dαu ∈
Lq (U) where q is given above.
Since U has the segment property, this means
u ∈W m,q (U). It remains to verify the assertion about compactness of id.
Let S be bounded in W m+j,p (U) . Then S is bounded in W m,q (U) by the
ﬁrst part. Now let {uk}∞
k=1 be any sequence in S. The corollary will be proved
if it is shown that any such sequence has a convergent subsequence in W m,r (U).
Let {α1, α2, · · ·, αh} denote the indices satisfying |α| ≤m. Then for each of these
indices, α,
sup
u∈S
n
||Dαu||1,1,U + ||Dαu||Lq(U)
o
< ∞
and so for each such α, satisfying |α| ≤m, it follows from Lemma 40.30 on Page 1155
that {Dαu : u ∈S} is precompact in Lr (U) . Therefore, there exists a subsequence,
still denoted by uk such that Dα1uk converges in Lr (U) . Applying the same lemma,
there exists a subsequence of this subsequence such that both Dα1uk and Dα2uk
converge in Lr (U) . Continue taking subsequences until you obtain a subsequence,
{uk}∞
k=1 for which {Dαuk}∞
k=1 converges in Lr (U) for all |α| ≤m. But this must
be a convergent subsequence in W m,r (U) and this proves the corollary.
Theorem 40.44 Let U be a bounded open set having a (1, p) extension operator
and let p > n. Then id : W 1,p (U) →C
¡
U
¢
is continuous and compact.

40.3.
GENERAL EMBEDDING THEOREMS
1167
Proof: Theorem 40.17 on Page 40.17 implies rU : W 1,p (Rn) →C
¡
U
¢
is con-
tinuous and compact. Thus
||u||∞,U = ||Eu||∞,U ≤C ||Eu||1,p,Rn ≤C ||u||1,p,U .
This proves continuity.
If S is a bounded set in W 1,p (U) , then deﬁne S1 ≡
{Eu : u ∈S} . Then S1 is a bounded set in W 1,p (Rn) and so by Theorem 40.17
the set of restrictions to U, is precompact. However, the restrictions to U are just
the functions of S. Therefore, id is compact as well as continuous.
Corollary 40.45 Let p > n, let U be a bounded open set having a (1, p) extension
operator which also satisﬁes the segment condition, and let m be a nonnegative
integer. Then id : W m+1,p (U) →Cm,λ ¡
U
¢
is continuous for all λ ∈[0, 1 −n
p ] and
id is compact if λ < 1 −n
p .
Proof: Let uk →0 in W m+1,p (U) . Then it follows that for each |α| ≤m,
Dαuk →0 in W 1,p (U) . Therefore,
E (Dαuk) →0 in W 1,p (Rn) .
Then from Morrey’s inequality, 40.13 on Page 1144, if λ ≤1 −n
p and |α| = m
ρλ (E (Dαuk)) ≤C ||E (Dαuk)||1,p,Rn diam (U)1−n
p −λ .
Therefore, ρλ (E (Dαuk)) = ρλ (Dαuk) →0. From Theorem 40.44 it follows that
for |α| ≤m, ||Dαuk||∞→0 and so ||uk||m,λ →0. This proves the claim about
continuity. The claim about compactness for λ < 1 −n
p follows from Lemma 40.20
on Page 1145 and this.
(Bounded in W m,p (U)
id
→Bounded in Cm,1−n
p ¡
U
¢
id
→
Compact in Cm,λ ¡
U
¢
.)
Theorem 40.46 Suppose jp < n < (j + 1) p and let m be a positive integer. Let
U be any bounded open set in Rn which has a (1, p) extension operator for each
p ≥1 and the segment property. Then id ∈L
¡
W m+j,p (U) , Cm−1,λ ¡
U
¢¢
for every
λ ≤λ0 ≡(j + 1) −n
p and if λ < (j + 1) −n
p , id is compact.
Proof: From Corollary 40.43 W m+j,p (U) ⊆W m,q (U) where q is given by 40.34.
Therefore,
np
n −jp > n
and so by Corollary 40.45, W m,q (U) ⊆Cm−1,λ ¡
U
¢
for all λ satisfying
0 < λ < 1 −(n −jp) n
np
= p (j + 1) −n
p
= (j + 1) −n
p .
The assertion about compactness follows from the compactness of the embedding
of Cm−1,λ0 ¡
U
¢
into Cm−1,λ ¡
U
¢
for λ < λ0, Lemma 40.20 on Page 1145.

1168
BASIC THEORY OF SOBOLEV SPACES
40.4
More Extension Theorems
The theorem about the existence of a (1, p) extension is all that is needed to obtain
general embedding theorems for Sobolev spaces. However, a more general theory
is needed in order to tie the theory of Sobolev spaces presented thus far to a very
appealing description using Fourier transforms.
First the problem of extending
W k,p (H) to W k,p (Rn) is considered for H−a half space
H−≡{y ∈Rn : yn < 0} .
(40.35)
I am following Adams [1].
Lemma 40.47 Let H−be a half space as in 40.35. Let H+ be the half space in
which yn < 0 is replaced with yn > 0. Also let (y′, yn) = y
u (y′, yn) ≡
½
u+ (y′, yn) if y ∈H+
u−(y′, yn) if y ∈H−
,
suppose u+ ∈C∞³
H+
´
and u−∈C∞³
H−
´
, and that for l ≤k −1,
Dlenu+ (y′, 0) = Dlenu−(y′, 0) .
Then u ∈W k,p (Rn). Furthermore,
Dαu (y′, yn) ≡
½
Dαu+ (y′, yn) if y ∈H+
Dαu−(y′, yn) if y ∈H−
Proof: Consider the following for φ ∈C∞
c (Rn) and |α| ≤k.
(−1)|α|
µZ
Rn−1
Z ∞
0
u+Dαφdyndy′ +
Z
Rn−1
Z 0
−∞
u−Dαφdyndy′
¶
.
Integrating by parts, this yields
(−1)|α| (−1)|β|
µZ
Rn−1
Z ∞
0
Dβu+Dαnenφdyndy′
+
Z
Rn−1
Z 0
−∞
Dβu−Dαnenφdyndy′
¶
where β ≡(α1, α2, · · ·αn−1, 0) . Do integration by parts on the inside integral and
by assumption, the boundary terms will cancel and the whole thing reduces to
(−1)|α| (−1)|β| (−1)αn
µZ
Rn−1
Z ∞
0
Dαu+φdyndy′
+
Z
Rn−1
Z 0
−∞
Dαu−φdyndy′
¶
=
µZ
Rn−1
Z ∞
0
Dαu+φdyndy′ +
Z
Rn−1
Z 0
−∞
Dαu−φdyndy′
¶
which proves the lemma.

40.4.
MORE EXTENSION THEOREMS
1169
Lemma 40.48 Let H−be the half space in 40.35 and let u ∈C∞³
H−
´
. Then
there exists a mapping,
E : C∞³
H−
´
→W k,p (Rn)
and a constant, C which is independent of u ∈C∞³
H−
´
such that E is linear and
for all l ≤k,
||Eu||l,p,Rn ≤C ||u||l,p,H−.
(40.36)
Proof: Deﬁne
Eu (x′, xn) ≡
½ u (x′, xn) if xn < 0
Pk
j=1 λju (x′, −jxn) if xn ≥0
where the λj are chosen in such a way that for l ≤k −1,
Dlenu (x′, 0) −Dlen


k
X
j=1
λju

(x′, 0) = 0
so that Lemma 40.47 may be applied. Do there exist such λj? It is necessary to
have the following hold for each r = 0, 1, · · ·, k −1.
k
X
j=1
(−j)r λjDrenu (x′, 0) = Drenu (x′, 0) .
This is satisﬁed if
k
X
j=1
(−j)r λj = 1
for r = 0, 1, · · ·, k −1. This is a system of k equations for the k variables, the λj.
The matrix of coeﬃcients is of the form







1
1
1
· · ·
1
−1
−2
−3
· · ·
−k
1
4
9
· · ·
k2
...
...
...
...
(−1)k
(−2)k
(−3)k
· · ·
(−k)k







This matrix has an inverse because its determinant is nonzero.
Now from Lemma 40.47, it follows from the above description of E that for
|α| ≤k,
Dα (Eu) (x′, xn) ≡
½ Dαu (x′, xn) if xn < 0
Pk
j=1 λj (−j)αn (Dαu) (x′, −jxn) if xn ≥0
It follows that E is linear and there exists a constant, C independent of u such that
40.36 holds. This proves the lemma.

1170
BASIC THEORY OF SOBOLEV SPACES
Corollary 40.49 Let H−be the half space of 40.35. There exists E with the prop-
erty that E : W l,p (H−) →W l,p (Rn) and is linear and continuous for each l ≤k.
Proof: This immediate from the density of C∞
c
³
H−
´
in W k,p ³
H−
´
and
Lemma 40.48.
There is nothing sacred about a half space or this particular half space. It is
clear that everything works as well for a half space of the form
H−
k ≡{x : xk < 0} .
Thus the half space featured in the above discussion is H−
n .
Corollary 40.50 Let {k1, · · ·, kr} ⊆{1, · · ·, n} where the ki are distinct and let
H−
k1···kr ≡H−
k1 ∩H−
k2 ∩· · · ∩H−
kr.
(40.37)
Then there exists E : W k,p ¡
H−
k1···kr
¢
→W k,p (Rn) such that E is linear and con-
tinuous.
Proof: Follow the above argument with minor modiﬁcations to ﬁrst extend
from H−
k1···kr to H−
k1···kr−1 and then from from H−
k1···kr−1 to H−
k1···kr−2 etc.
This easily implies the ability to extend oﬀbounded open sets which near their
boundaries look locally like an intersection of half spaces.
Theorem 40.51 Let U be a bounded open set and suppose U0, U1, ···, Um are open
sets with the property that U ⊆∪m
k=0Uk, U0 ⊆U, and ∂U ⊆∪m
k=1Uk. Suppose also
there exist one to one and onto functions, hk : Rn →Rn, hk (Uk ∩U) = Wk where
Wk equals the intersection of a bounded open set with a ﬁnite intersection of half
spaces, H−
k1···kr, as in 40.37 such that hk (∂U ∩Uk) ⊆∂H−
k1···kr. Suppose also that
for all |α| ≤k −1,
Dαhk and Dαh−1
k
exist and are Lipschitz continuous. Then there letting W be an open set which con-
tains U, there exists E : W k,p (U) →W k,p (W) such that E is a linear continuous
map from W l,p (U) to W l,p (W) for each l ≤k.
Proof: Let ψj ∈C∞
c (Uj), ψj (x) ∈[0, 1] for all x ∈Rn, and Pm
j=0 ψj (x) = 1
on U. This is a C∞partition of unity on U. By Theorem 40.14
¡
h−1
j
¢∗uψj ∈
W k,p (Wj) . By the assumption that hj (∂U ∩Uj) ⊆∂H−
k1···kr, the zero extension of
¡
h−1
j
¢∗uψj to the rest of H−
k1···kr results in an element of W k,p ¡
H−
k1···kr
¢
. Apply
Corollary 40.50 to conclude there exists Ej : W k,p ¡
H−
k1···kr
¢
→W k,p (Rn) which is
continuous and linear. Abusing notation slightly, by using
¡
h−1
j
¢∗uψj as the above
zero extension, it follows Ej
³¡
h−1
j
¢∗uψj
´
∈W k,p (Rn) . Now let η be a function in
C∞
c (h (W)) such that η (y) = 1 on h
¡
U
¢
. Then Deﬁne
Eu ≡
m
X
j=0
h∗
jηEj
³¡
h−1
j
¢∗¡
uψj
¢´
.

40.4.
MORE EXTENSION THEOREMS
1171
Clearly Eu (x) = u (x) if x ∈U. It is also clear that E is linear. It only remains
to verify E is continuous.
In what follows, Cj will denote a constant which is
independent of u which may change from line to line. By Theorem 40.14,
||Eu||k,p,W
≤
m
X
j=0
¯¯¯
¯¯¯h∗
jηEj
³¡
h−1
j
¢∗¡
uψj
¢´¯¯¯
¯¯¯
k,p,W
≤
m
X
j=0
Cj
¯¯¯
¯¯¯ηEj
³¡
h−1
j
¢∗¡
uψj
¢´¯¯¯
¯¯¯
k,p,h(W )
=
m
X
j=0
Cj
¯¯¯
¯¯¯ηEj
³¡
h−1
j
¢∗¡
uψj
¢´¯¯¯
¯¯¯
k,p,Rn
≤
m
X
j=0
Cj
¯¯¯
¯¯¯Ej
³¡
h−1
j
¢∗¡
uψj
¢´¯¯¯
¯¯¯
k,p,Rn
≤
m
X
j=0
Cj
¯¯¯
¯¯¯
¡
h−1
j
¢∗¡
uψj
¢¯¯¯
¯¯¯
k,p,hj(U∩Uj)
≤
m
X
j=0
Cj
¯¯¯¯uψj
¯¯¯¯
k,p,U∩Uk
≤
m
X
j=0
Cj ||u||k,p,U∩Uk ≤


m
X
j=0
Cj

||u||k,p,U .
Similarly E : W l,p (U) →W l,p (U) for l ≤k. This proves the theorem.
Deﬁnition 40.52 When E is a linear continuous map from W l,p (U) to W l,p (Rn)
for each l ≤k. it is called a strong (k, p) extension map.
There is also a very easy sort of extension theorem for the space, W m,p
0
(U) which
does not require any assumptions on the boundary of U other than mn (∂U) = 0.
First here is the deﬁnition of W m,p
0
(U) .
Deﬁnition 40.53 Denote by W m,p
0
(U) the closure of C∞
c (U) in W m,p (U) .
Theorem 40.54 For u ∈W m,p
0
(U) , deﬁne
Eu (x) ≡
½ u (x) if x ∈U
0 if x /∈U
Then E is a strong (k, p) extension map.
Proof: Letting l ≤m, it is clear that for |α| ≤l,
DαEu =
½
Dαu for x ∈U
0 for x /∈U
.

1172
BASIC THEORY OF SOBOLEV SPACES
This follows because, since mn (∂U) = 0 it suﬃces to consider φ ∈C∞
c (U) and
φ ∈C∞
c
³
U
C´
. Therefore, ||Eu||l,p,Rn = ||u||l,p,U.
There are many other extension theorems and if you are interested in pursuing
this further, consult Adams [1]. One of the most famous which is discussed in this
reference is due to Calderon and depends on the theory of singular integrals.

Sobolev Spaces Based On L2
41.1
Fourier Transform Techniques
Much insight can be obtained easily through the use of Fourier transform methods.
This technique will be developed in this chapter. When this is done, it is necessary
to use Sobolev spaces of the form W k,2 (U) , those Sobolev spaces which are based
on L2 (U) . It is true there are generalizations which use Fourier transform methods
in the context of Lp but the spaces so considered are called Bessel potential spaces.
They are not really Sobolev spaces.
Furthermore, it is Mihlin’s theorem rather
than the Plancherel theorem which is the main tool of the analysis. This is a hard
theorem.
It is convenient to consider the Schwartz class of functions,S. These are func-
tions which have inﬁnitely many derivatives and vanish quickly together with their
derivatives as |x| →∞. In particular, C∞
c (Rn) is contained in S which is not true of
the functions, G used earlier in deﬁning the Fourier transforms which are a suspace
of S. Recall the following deﬁnition.
Deﬁnition 41.1 f ∈S, the Schwartz class, if f ∈C∞(Rn) and for all positive
integers N,
ρN(f) < ∞
where
ρN(f) = sup{(1 + |x|2)N|Dαf(x)| : x ∈Rn , |α| ≤N}.
Thus f ∈S if and only if f ∈C∞(Rn) and
sup{|xβDαf(x)| : x ∈Rn} < ∞
(41.1)
for all multi indices α and β.
Thus all partial derivatives of a function in S are in Lp (Rn) for all p ≥1.
Therefore, for f ∈S, the Fourier and inverse Fourier transforms are given in the
usual way,
Ff (t) =
µ 1
2π
¶n/2 Z
Rn f (x) e−it·xdx, F −1f (t) =
µ 1
2π
¶n/2 Z
Rn f (x) eit·xdx.
1173

1174
SOBOLEV SPACES BASED ON L2
Also recall that the Fourier transform and its inverse are one to one and onto maps
from S to S.
To tie the Fourier transform technique in with what has been done so far, it is
necessary to make the following assumption on the set, U. This assumption is made
so that it is possible to consider elements of W k,2 (U) as restrictions of elements of
W k,2 (Rn) .
Assumption 41.2 Assume U satisﬁes the segment condition and that for any m of
interest, there exists E ∈L (W m,p (U) , W m,p (Rn)) such that for each k ≤m, E ∈
L
¡
W k,p (U) , W k,p (Rn)
¢
. That is, there exists a stong (m, p) extension operator.
Lemma 41.3
The Schwartz class, S, is dense in W m,p (Rn) .
Proof: The set, Rn satisﬁes the segment condition and so C∞
c (Rn) is dense in
W m,p (Rn) . However, C∞
c (Rn) ⊆S. This proves the lemma.
Recall now Plancherel’s theorem which states that ||f||0,2,Rn = ||Ff||0,2,Rn when-
ever f ∈L2 (Rn) . Also it is routine to verify from the deﬁnition of the Fourier
transform that for u ∈S,
F∂ku = ixkFu.
From this it follows that
||Dαu||0,2,Rn = ||xαFu||0,2,Rn .
Here xα denotes the function x →xα. Therefore,
||u||m,2,Rn =


Z
Rn
X
|α|≤m
x2α1
1
· · · x2αn
n
|Fu (x)|2 dx


1/2
.
Also, it is not hard to verify that
X
|α|≤m
x2α1
1
· · · x2αn
n
≤

1 +
n
X
j=1
x2
j


m
≤C (n, m)
X
|α|≤m
x2α1
1
· · · x2αn
n
where C (n, m) is the largest of the multinomial coeﬃcients obtained in the expan-
sion,

1 +
n
X
j=1
x2
j


m
.
Therefore, for all u ∈S,
||u||m,2,Rn ≤
µZ
Rn
³
1 + |x|2´m
|Fu (x)|2 dx
¶1/2
≤C (n, m) ||u||m,2,Rn .
(41.2)
This motivates the following deﬁnition.

41.1.
FOURIER TRANSFORM TECHNIQUES
1175
Deﬁnition 41.4 Let Hm (Rn) ≡
(
u ∈L2 (Rn) : ||u||Hm(Rn) ≡
µZ
Rn
³
1 + |x|2´m
|Fu (x)|2 dx
¶1/2
< ∞
)
.
(41.3)
Lemma 41.5 S is dense in Hm (Rn) and Hm (Rn) = W 2,m (Rn). Furthermore,
the norms are equivalent.
Proof: First it is shown that S is dense in Hm (Rn) . Let u ∈Hm (Rn) . Let
µ (E) ≡
R
E
³
1 + |x|2´m
dx. Thus µ is a regular measure and u ∈Hm (Rn) just
means that Fu ∈L2 (µ) , the space of functions which are in L2 (Rn) with respect
to this measure, µ. Therefore, from the regularity of the measure, µ, there exists
uk ∈Cc (Rn) such that
||uk −Fu||L2(µ) →0.
Now let ψε be a molliﬁer and pick εk small enough that
¯¯¯¯uk ∗ψεk −uk
¯¯¯¯
L2(µ) < 1
2k .
Then uk ∗ψεk ∈C∞
c (Rn) ⊆S. Therefore, there exists wk ∈G such that Fwk =
uk ∗ψεk. It follows
||Fwk −Fu||L2(µ) ≤||Fwk −uk||L2(µ) + ||uk −Fu||L2(µ)
and these last two terms converge to 0 as k →∞. Therefore, wk →u in Hm (Rn)
and this proves the ﬁrst part of this lemma.
Now let u ∈Hm (Rn) . By what was just shown, there exists a sequence, uk →u
in Hm (Rn) where uk ∈S. It follows from 41.2 that
||uk −ul||Hm ≥||uk −ul||m,2,Rn
and so {uk} is a Cauchy sequence in W m,2 (Rn) . Therefore, there exists w ∈
W m,2 (Rn) such that
||uk −w||m,2,Rn →0.
But this implies
0 = lim
k→∞||uk −w||0,2,Rn = lim
k→∞||uk −u||0,2,Rn
showing u = w which veriﬁes Hm (Rn) ⊆W 2,m (Rn) . The opposite inclusion is
proved the same way, using density of S and the fact that the norms in both spaces
are larger than the norms in L2 (Rn). The equivalence of the norms follows from
the density of S and the equivalence of the norms on S. This proves the lemma.
The conclusion of this lemma with the density of S and 41.2 implies you can
use either norm, ||u||Hm(Rn) or ||u||m,2,Rn when working with these Sobolev spaces.
What of open sets satisfying Assumption 41.2? How does W m,2 (U) relate to
the Fourier transform?

1176
SOBOLEV SPACES BASED ON L2
Deﬁnition 41.6 Let U be an open set in Rn. Then
Hm (U) ≡{u : u = v|U for some v ∈Hm (Rn)}
(41.4)
Here the notation, v|U means v restricted to U. Deﬁne the norm in this space by
||u||Hm(U) ≡inf
n
||v||Hm(Rn) : v|U = u
o
.
(41.5)
Lemma 41.7 Hm (U) is a Banach space.
Proof: First it is necessary to verify that the given norm really is a norm.
Suppose then that u = 0. Is ||u||Hm(U) = 0? Of course it is. Just take v ≡0.
Then v|U = u and ||v||Hm = 0. Next suppose ||u||Hm(U) = 0. Does it follow that
u = 0? Letting ε > 0 be given, there exists v ∈Hm (Rn) such that v|U = u and
||v||Hm(Rn) < ε. Therefore,
||u||0,U ≤||v||0,Rn ≤||v||Hm(U) < ε.
Since ε > 0 is arbitrary, it follows u = 0 a.e. Next suppose ui ∈Hm (U) for i = 1, 2.
There exists vi ∈Hm (Rn) such that
||vi||Hm(Rn) < ||ui||Hm(U) + ε.
Therefore,
||u1 + u2||Hm(U)
≤
||v1 + v2||Hm(Rn) ≤||v1||Hm(Rn) + ||v2||Hm(Rn)
≤
||u1||Hm(U) + ||u2||Hm(U) + 2ε
and since ε > 0 is arbitrary, this shows the triangle inequality.
The interesting question is the one about completeness. Suppose then {uk} is
a Cauchy sequence in Hm (U) . There exists Nk such that if k, l ≥Nk, it follows
||uk −ul||Hm(U) <
1
2k and the numbers, Nk can be taken to be strictly increasing in
k. Thus for l ≥Nk, ||ul −uNk||Hm(U) < 1/2l. Therefore, there exists wl ∈Hm (Rn)
such that
wl|U = ul −uNk, ||wl||Hm(Rn) < 1
2l .
Also let vNk|U = uNk with vNk ∈Hm (Rn) and
||vNk||Hm(Rn) < ||uNk||Hm(U) + 1
2k .
Now for l > Nk, deﬁne vl by vl −vNk = wNk so that ||vl −vNk||Hm(Rn) < 1/2k. In
particular,
¯¯¯¯vNk+1 −vNk
¯¯¯¯
Hm(Rn) < 1/2k
which shows that {vNk}∞
k=1 is a Cauchy sequence. Consequently it must converge
to v ∈Hm (Rn) . Let u = v|U. Then
||u −uNk||Hm(U) ≤||v −vNk||Hm(Rn)

41.1.
FOURIER TRANSFORM TECHNIQUES
1177
which shows the subsequence, {uNk}k converges to u. Since {uk} is a Cauchy se-
quence, it follows it too must converge to u. This proves the lemma.
The main result is next.
Theorem 41.8 Suppose U satisﬁes Assumption 41.2. Then for m a nonnegative
integer, Hm (U) = W m,2 (U) and the two norms are equivalent.
Proof: Let u ∈Hm (U) . Then there exists v ∈Hm (Rn) such that v|U = u.
Hence v ∈W k,2 (Rn) and so all its weak derivatives up to order m are in L2 (Rn) .
Therefore, the restrictions of these weak derivitves are in L2 (U) . Since U satisﬁes
the segment condition, it follows u ∈W m,2 (U) which shows Hm (U) ⊆W m,2 (U) .
Next take u ∈W m,2 (U) . Then Eu ∈W m,2 (Rn) = Hm (Rn) and this shows
u ∈Hm (U) . This has shown the two spaces are the same. It remains to verify their
norms are equivalent. Let u ∈Hm (U) and let v|U = u where v ∈Hm (Rn) and
||u||Hm(U) + ε > ||v||Hm(Rn) .
Then recalling that ||·||Hm(Rn) and ||·||m,2,Rn are equivalent norms for Hm (Rn) ,
there exists a constant, C such that
||u||Hm(U) + ε > ||v||Hm(Rn) ≥C ||v||m,2,Rn ≥C ||u||m,2,U
Now consider the two Banach spaces,
³
Hm (U) , ||·||Hm(U)
´
,
³
W m,2 (U) , ||·||m,2,U
´
.
The above inequality shows since ε > 0 is arbitrary that id :
³
Hm (U) , ||·||Hm(U)
´
→
³
W m,2 (U) , ||·||m,2,U
´
is continuous. By the open mapping theorem, it follows id
is continuous in the other direction. Thus there exists a constant, K such that
||u||Hm(U) ≤K ||u||k,2,U . Hence the two norms are equivalent as claimed.
Specializing Corollary 40.43 and Theorem 40.46 starting on Page 1166 to the case
of p = 2 while also assuming more on U yields the following embedding theorems.
Theorem 41.9 Suppose m ≥0 and j is a nonnegative integer satisfying 2j <
n.
Also suppose U is an open set which satisﬁes Assumption 41.2.
Then id ∈
L
¡
Hm+j (U) , W m,q (U)
¢
where
q ≡
2n
n −2j .
(41.6)
If, in addition to the above, U is bounded and 1 ≤r < q, then
id ∈L
¡
Hm+j (U) , W m,r (U)
¢
and is compact.
Theorem 41.10 Suppose for j a nonnegative integer, 2j < n < 2 (j + 1) and let m
be a positive integer. Let U be any bounded open set in Rn which satisﬁes Assump-
tion 41.2. Then id ∈L
¡
Hm+j (U) , Cm−1,λ ¡
U
¢¢
for every λ ≤λ0 ≡(j + 1) −n
2
and if λ < (j + 1) −n
2 , id is compact.

1178
SOBOLEV SPACES BASED ON L2
41.2
Fractional Order Spaces
What has been gained by all this? The main thing is that Hm+s (U) makes sense
for any s ∈(0, 1) and m an integer. You simply replace m with m + s in the above
for s ∈(0, 1). This gives what is meant by Hm+s (Rn)
Deﬁnition 41.11 For m an integer and s ∈(0, 1) , let Hm+s (Rn) ≡
(
u ∈L2 (Rn) : ||u||Hm+s(Rn) ≡
µZ
Rn
³
1 + |x|2´m+s
|Fu (x)|2 dx
¶1/2
< ∞
)
.
(41.7)
You could also simply refer to Ht (Rn) where t is a real number replacing the m + s
in the above formula with t but I want to emphasize the notion that t = m+s where
m is a nonnegative integer. Therefore, I will often write m + s. Let U be an open
set in Rn. Then
Hm+s (U) ≡
©
u : u = v|U for some v ∈Hm+s (Rn)
ª
.
(41.8)
Deﬁne the norm in this space by
||u||Hm+s(U) ≡inf
n
||v||Hm+s(Rn) : v|U = u
o
.
(41.9)
Lemma 41.12 Hm+s (U) is a Banach space.
Proof: Just repeat the proof of Lemma 41.7.
The theorem about density of S also remains true in Hm+s (Rn) . Just repeat
the proof of that part of Lemma 41.5 replacing the integer, m, with the symbol,
m + s.
Lemma 41.13 S is dense in Hm+s (Rn).
In fact, more can be said.
Corollary 41.14 Let U be an open set and let S|U denote the restrictions of func-
tions of S to U. Then S|U is dense in Ht (U) .
Proof: Let u ∈Ht (U) and let v ∈Ht (Rn) such that v|U = u a.e. Then since
S is dense in Ht (Rn) , there exists w ∈S such that
||w −v||Ht(Rn) < ε.
It follows that
||u −w||Ht(U)
≤
||u −v||Ht(U) + ||v −w||Ht(U)
≤
0 + ||v −w||Ht(Rn) < ε.
These fractional order spaces are important when trying to understand the trace
on the boundary.
The Fourier transform description also makes it very easy to
establish interesting inequalities such as interpolation inequalities.

41.2.
FRACTIONAL ORDER SPACES
1179
Lemma 41.15 Let 0 ≤r < s < t. Then if u ∈Ht (Rn) ,
||u||Hs(Rn) ≤||u||θ
Hr(Rn) ||u||1−θ
Ht(Rn)
where θ is a positve number such that θr + (1 −θ) t = s.
Proof: This follows from Holder’s inequality applied to the measure µ given by
µ (E) =
Z
E
|Fu|2 dx
Thus
Z ³
1 + |x|2´s
|Fu|2 dx
=
Z ³
1 + |x|2´rθ ³
1 + |x|2´(1−θ)t
|Fu|2 dx
≤
µZ ³
1 + |x|2´r
|Fu|2 dx
¶θ µZ ³
1 + |x|2´(1−θ)t
|Fu|2 dx
¶1−θ
=
||u||2θ
Hr(Rn) ||u||2(1−θ)
Ht(Rn) .
Taking square roots yields the desired inequality.
Corollary 41.16 Let U be an open set satisfying Assumption 41.2 and let p < q
where p, q are two nonnegative integers. Also let t ∈(p, q) . Then exists a constant,
C independent of u ∈Hq (U) such that for all u ∈Hq (U) ,
||u||Ht(U) ≤C ||u||θ
Hp(U) ||u||1−θ
Hq(U)
where θ is such that t = θp + (1 −θ) q.
Proof: Let E ∈L (Hq (U) , Hq (Rn)) such that for all positive integers, l less
than or equal to q, E ∈L
¡
Hl (U) , Hl (Rn)
¢
. Then Eu|U = u and Eu ∈Ht (Rn) .
Therefore, by Lemma 41.15,
||u||Ht(U)
≤
||Eu||Ht(Rn) ≤||Eu||θ
Hp(Rn) ||Eu||1−θ
Hq(Rn)
≤
C ||u||θ
Hp(U) ||u||1−θ
Hq(U) .
Now recall the very important Theorem 40.14 on Page 1143 which is listed here
for convenience.
Theorem 41.17 Let h : U →V be one to one and onto where U and V are two
open sets. Also suppose that Dαh and Dα ¡
h−1¢
exist and are Lipschitz continuous
if |α| ≤m −1 for m a positive integer. Then
h∗: W m,p (V ) →W m,p (U)
is continuous, linear, one to one, and has an inverse with the same properties, the
inverse being
¡
h−1¢∗.

1180
SOBOLEV SPACES BASED ON L2
Is there something like this for the fractional order spaces? Yes there is. How-
ever, in order to prove it, it is convenient to use an equivalent norm for Hm+s (Rn)
which does not depend explicitly on the Fourier transform. The following theorem
is similar to one in [28]. It describes the norm in Hm+s (Rn) in terms which are
free of the Fourier transform. This is also called an intrinsic norm [1].
Theorem 41.18 Let s ∈(0, 1) and let m be a nonnegative integer. Then an equiv-
alent norm for Hm+s (Rn) is
|||u|||2
m+s ≡||u||2
m,2,Rn +
X
|α|=m
Z Z
|Dαu (x) −Dαu (y)|2 |x −y|−n−2s dxdy.
Also if |β| ≤m, there are constants, m (s) and M (s) such that
m (s)
Z
|Fu (z)|2 ¯¯zβ¯¯2 |z|2s dz ≤
Z Z ¯¯Dβu (x) −Dβu (y)
¯¯2 |x −y|−n−2s dxdy
≤M (s)
Z
|Fu (z)|2 ¯¯zβ¯¯2 |z|2s dz
(41.10)
Proof: Let u ∈S which is dense in Hm+s (Rn). The Fourier transform of the
function, y →Dαu (x + y) −Dαu (y) equals
¡
eix·z −1
¢
FDαu (z) .
Now by Fubini’s theorem and Plancherel’s theorem along with the above, taking
|α| = m,
Z Z
|Dαu (x) −Dαu (y)|2 |x −y|−n−2s dxdy
=
Z Z
|Dαu (y + t) −Dαu (y)|2 |t|−n−2s dtdy
=
Z
|t|−n−2s
Z
|Dαu (y + t) −Dαu (y)|2 dydt
=
Z
|t|−n−2s
Z ¯¯¡
eit·z −1
¢
FDαu (z)
¯¯2 dzdt
=
Z
|FDαu (z)|2
µZ
|t|−n−2s ¯¯¡
eit·z −1
¢¯¯2 dt
¶
dz.
(41.11)
Consider the inside integral, the one taken with respect to t.
G (z) ≡
µZ
|t|−n−2s ¯¯¡
eit·z −1
¢¯¯2 dt
¶
.
The essential thing to notice about this function of z is that it is a positive real
number whenever z ̸= 0. This is because for small |t| , the integrand is dominated
by C |t|−n+2(1−s) . Changing to polar coordinates, you see that
Z
[|t|≤1]
|t|−n−2s ¯¯¡
eit·z −1
¢¯¯2 dt < ∞

41.2.
FRACTIONAL ORDER SPACES
1181
Next, for |t| > 1, the integrand is bounded by 4 |t|−n−2s , and changing to polar
coordinates shows
Z
[|t|>1]
|t|−n−2s ¯¯¡
eit·z −1
¢¯¯2 dt ≤4
Z
[|t|>1]
|t|−n−2s dt < ∞.
Now for α > 0,
G (αz)
=
Z
|t|−n−2s ¯¯¡
eit·αz −1
¢¯¯2 dt
=
Z
|t|−n−2s ¯¯¡
eiαt·z −1
¢¯¯2 dt
=
Z ¯¯¯ r
α
¯¯¯
−n−2s ¯¯¡
eir·z −1
¢¯¯2 1
αn dr
=
α2s
Z
|r|−n−2s ¯¯¡
eir·z −1
¢¯¯2 dr = α2sG (z) .
Also G is continuous and strictly positive. Letting
0 < m (s) = min {G (w) : |w| = 1}
and
M (s) = max {G (w) : |w| = 1} ,
it follows from this, and letting α = |z| , w ≡z/ |z| , that
G (z) ∈
³
m (s) |z|2s , M (s) |z|2s´
.
More can be said but this will suﬃce. Also observe that for s ∈(0, 1) and b > 0,
(1 + b)s ≤1 + bs, 21−s (1 + b)s ≥1 + bs.
In what follows, C (s) will denote a constant which depends on the indicated quan-
tities which may be diﬀerent on diﬀerent lines of the argument. Then from 41.11,
Z Z
|Dαu (x) −Dαu (y)|2 |x −y|−n−2s dxdy
≤
M (s)
Z
|FDαu (z)|2 |z|2s dz
=
M (s)
Z
|Fu (z)|2 |zα|2 |z|2s dz.
No referrence was made to |α| = m and so this establishes the top half of 41.10.
Therefore,
|||u|||2
m+s
≡
||u||2
m,2,Rn +
X
|α|=m
Z Z
|Dαu (x) −Dαu (y)|2 |x −y|−n−2s dxdy
≤
C
Z ³
1 + |z|2´m
|Fu (z)|2 dz + M (s)
Z
|Fu (z)|2 X
|α|=m
|zα|2 |z|2s dz

1182
SOBOLEV SPACES BASED ON L2
Recall that
X
|α|≤m
z2α1
1
· · · z2αn
n
≤

1 +
n
X
j=1
z2
j


m
≤C (n, m)
X
|α|≤m
z2α1
1
· · · z2αn
n
.
(41.12)
Therefore, where C (n, m) is the largest of the multinomial coeﬃcients obtained in
the expansion,

1 +
n
X
j=1
z2
j


m
.
Therefore,
|||u|||2
m+s
≤
C
Z ³
1 + |z|2´m
|Fu (z)|2 dz + M (s)
Z
|Fu (z)|2 X
|α|=m
|zα|2 |z|2s dz
≤
C
Z ³
1 + |z|2´m+s
|Fu (z)|2 dz + M (s)
Z
|Fu (z)|2 ³
1 + |z|2´m
|z|2s dz
≤
C
Z ³
1 + |z|2´m+s
|Fu (z)|2 dz = C ||u||Hm+s(Rn) .
It remains to show the other inequality. From 41.11,
Z Z
|Dαu (x) −Dαu (y)|2 |x −y|−n−2s dxdy
≥
m (s)
Z
|FDαu (z)|2 |z|2s dz
=
m (s)
Z
|Fu (z)|2 |zα|2 |z|2s dz.
No reference was made to |α| = m and so this establishes the bottom half of 41.10.
Therefore, from 41.12,
|||u|||2
m+s
≥
C
Z ³
1 + |z|2´m
|Fu (z)|2 dz + m (s)
Z
|Fu (z)|2 X
|α|=m
|zα|2 |z|2s dz
≥
C
Z ³
1 + |z|2´m
|Fu (z)|2 dz + C
Z
|Fu (z)|2 ³
1 + |z|2´m
|z|2s dz
=
C
Z ³
1 + |z|2´m ³
1 + |z|2s´
|Fu (z)|2 dz
≥
C
Z ³
1 + |z|2´m ³
1 + |z|2´s
|Fu (z)|2 dz
=
C
Z ³
1 + |z|2´m+s
|Fu (z)|2 dz = ||u||Hm+s(Rn) .

41.2.
FRACTIONAL ORDER SPACES
1183
This proves the theorem.
With the above intrinsic norm, it becomes possible to prove the following version
of Theorem 41.17.
Lemma 41.19 Let h : Rn →Rn be one to one and onto. Also suppose that Dαh
and Dα ¡
h−1¢
exist and are Lipschitz continuous if |α| ≤m for m a positive integer.
Then
h∗: Hm+s (Rn) →Hm+s (Rn)
is continuous, linear, one to one, and has an inverse with the same properties, the
inverse being
¡
h−1¢∗.
Proof: Let u ∈S. From Theorem 41.17 and the equivalence of the norms in
W m,2 (Rn) and Hm (Rn) ,
||h∗u||2
Hm(Rn) +
R R P
|α|=m |Dαh∗u (x) −Dαh∗u (y)|2 |x −y|−n−2s dxdy
≤C ||u||2
Hm(Rn) +
R R P
|α|=m |Dαh∗u (x) −Dαh∗u (y)|2 |x −y|−n−2s dxdy
= C ||u||2
Hm(Rn) +
R R P
|α|=m
¯¯¯
P
|β(α)|≤m h∗¡
Dβ(α)u
¢
gβ(α) (x)
−h∗¡
Dβ(α)u
¢
gβ(α) (y)
¯¯2 |x −y|−n−2s dxdy
≤C ||u||2
Hm(Rn) + C
R R P
|α|=m
P
|β(α)|≤m
¯¯h∗¡
Dβ(α)u
¢
gβ(α) (x)
−h∗¡
Dβ(α)u
¢
gβ(α) (y)
¯¯2 |x −y|−n−2s dxdy
(41.13)
A single term in the last sum corresponding to a given α is then of the form,
Z Z ¯¯h∗¡
Dβu
¢
gβ (x) −h∗¡
Dβu
¢
gβ (y)
¯¯2 |x −y|−n−2s dxdy
(41.14)
≤
·Z Z ¯¯h∗¡
Dβu
¢
(x) gβ (x) −h∗¡
Dβu
¢
(y) gβ (x)
¯¯2 |x −y|−n−2s dxdy +
Z Z ¯¯h∗¡
Dβu
¢
(y) gβ (x) −h∗¡
Dβu
¢
(y) gβ (y)
¯¯2 |x −y|−n−2s dxdy
¸
≤
·
C (h)
Z Z ¯¯h∗¡
Dβu
¢
(x) −h∗¡
Dβu
¢
(y)
¯¯2 |x −y|−n−2s dxdy +
Z Z ¯¯h∗¡
Dβu
¢
(y)
¯¯2 |gβ (x) −gβ (y)|2 |x −y|−n−2s dxdy
¸
.
Changing variables, and then using the names of the old variables to simplify the
notation,
≤
·
C
¡
h, h−1¢ Z Z ¯¯¡
Dβu
¢
(x) −
¡
Dβu
¢
(y)
¯¯2 |x −y|−n−2s dxdy +

1184
SOBOLEV SPACES BASED ON L2
Z Z ¯¯h∗¡
Dβu
¢
(y)
¯¯2 |gβ (x) −gβ (y)|2 |x −y|−n−2s dxdy
¸
.
By 41.10,
≤
C (h)
Z
|F (u) (z)|2 ¯¯zβ¯¯2 |z|2s dz
+
Z Z ¯¯h∗¡
Dβu
¢
(y)
¯¯2 |gβ (x) −gβ (y)|2 |x −y|−n−2s dxdy.
In the second term, let t = x −y. Then this term is of the form
Z ¯¯h∗¡
Dβu
¢
(y)
¯¯2 Z
|gβ (y + t) −gβ (y)|2 |t|−n−2s dtdy
(41.15)
≤
C
Z ¯¯h∗¡
Dβu
¢
(y)
¯¯2 dy ≤C ||u||2
Hm(Rn) .
(41.16)
because the inside integral equals a constant which depends on the Lipschitz con-
stants and bounds of the function, gβ and these things depend only on h. The
reason this integral is ﬁnite is that for |t| ≤1,
|gβ (y + t) −gβ (y)|2 |t|−n−2s ≤K |t|2 |t|−n−2s
and using polar coordinates, you see
Z
[|t|≤1]
|gβ (y + t) −gβ (y)|2 |t|−n−2s dt < ∞.
Now for |t| > 1, the integrand in 41.15 is dominated by 4 |t|−n−2s and using polar
coordinates, this yields
Z
[|t|>1]
|gβ (y + t) −gβ (y)|2 |t|−n−2s dt ≤4
Z
[|t|>1]
|t|−n−2s dt < ∞.
It follows 41.14 is dominated by an expression of the form
C (h)
Z
|F (u) (z)|2 ¯¯zβ¯¯2 |z|2s dz + C ||u||2
Hm(Rn)
and so the sum in 41.13 is dominated by
C (m, h)
Z
|F (u) (z)|2 |z|2s X
|β|≤m
¯¯zβ¯¯2 dz + C ||u||2
Hm(Rn)
≤
C (m, h)
Z
|F (u) (z)|2 ³
1 + |z|2´s ³
1 + |z|2´m
dz + C ||u||2
Hm(Rn)
≤
C ||u||2
Hm+s(Rn) .
This proves the theorem because the assertion about h−1 is obvious. Just replace
h with h−1 in the above argument.
Next consider the case where U is an open set.

41.2.
FRACTIONAL ORDER SPACES
1185
Lemma 41.20 Let h (U) ⊆V where U and V are open subsets of Rn and sup-
pose that h, h−1 : Rn →Rn are both functions in Cm,1 (Rn) . Recall this means
Dαh and Dαh−1 exist and are Lipschitz continuous for all |α| ≤m. Then h∗∈
L (Hm+s (V ) , Hm+s (U)).
Proof: Let u ∈Hm+s (V ) and let v ∈Hm+s (Rn) such that v|V = u. Then
from the above, h∗v ∈Hm+s (Rn) and so h∗u ∈Hm+s (U) because h∗u = h∗v|U.
Then by Lemma 41.19,
||h∗u||Hm+s(U) ≤||h∗v||Hm+s(Rn) ≤C ||v||Hm+s(Rn)
Since this is true for all v ∈Hm+s (Rn) , it follows that
||h∗u||Hm+s(U) ≤C ||u||Hm+s(V ) .
With harder work, you don’t need to have h, h−1 deﬁned on all of Rn but I
don’t feel like including the details so this lemma will suﬃce.
Another interesting application of the intrinsic norm is the following.
Lemma 41.21 Let φ ∈Cm,1 (Rn) and suppose spt (φ) is compact.
Then there
exists a constant, Cφ such that whenever u ∈Hm+s (Rn) ,
||φu||Hm+s(Rn) ≤Cφ ||u||Hm+s(Rn) .
Proof: It is a routine exercise in the product rule to verify that ||φu||Hm(Rn) ≤
Cφ ||u||Hm(Rn) . It only remains to consider the term involving the integral. A typical
term is
Z Z
|Dαφu (x) −Dαφu (y)|2 |x −y|−n−2s dxdy.
This is a ﬁnite sum of terms of the form
Z Z ¯¯Dγφ (x) Dβu (x) −Dγφ (y) Dβu (y)
¯¯2 |x −y|−n−2s dxdy
where |γ| and |β| ≤m.
≤
2
Z Z
|Dγφ (x)|2 ¯¯Dβu (x) −Dβu (y)
¯¯2 |x −y|−n−2s dxdy
+2
Z Z ¯¯Dβu (y)
¯¯2 |Dγφ (x) −Dγφ (y)|2 |x −y|−n−2s dxdy

1186
SOBOLEV SPACES BASED ON L2
By 41.10 and the Lipschitz continuity of all the derivatives of φ, this is dominated
by
CM (s)
Z
|Fu (z)|2 ¯¯zβ¯¯2 |z|2s dz
+K
Z Z ¯¯Dβu (y)
¯¯2 |x −y|2 |x −y|−n−2s dxdy
=
CM (s)
Z
|Fu (z)|2 ¯¯zβ¯¯2 |z|2s dz
+K
Z ¯¯Dβu (y)
¯¯2 Z
|t|−n+2(1−s) dtdy
≤
C (s)
µZ
|Fu (z)|2 ¯¯zβ¯¯2 |z|2s dz + K
Z ¯¯Dβu (y)
¯¯2 dy
¶
≤
C (s)
Z ³
1 + |y|2´m+s
|Fu (y)|2 dy.
Since there are only ﬁnitely many such terms, this proves the lemma.
Corollary 41.22 Let t = m + s for s ∈[0, 1) and let U, V be open sets.
Let
φ ∈Cm,1
c
(V ). This means spt (φ) ⊆V and φ ∈Cm,1 (Rn) . Then if u ∈Ht (U) it
follows that uφ ∈Ht (U ∩V ) and ||uφ||Ht(U∩V ) ≤Cφ ||u||Ht(U) .
Proof: Let v|U = u a.e. where v ∈Ht (Rn) . Then by Lemma 41.21, φv ∈
Ht (Rn) and φv|U∩V = φu a.e. Therefore, φu ∈Ht (U ∩V ) and
||φu||Ht(U∩V ) ≤||φv||Ht(Rn) ≤Cφ ||v||Ht(Rn) .
Taking the inﬁmum for all such v whose restrictions equal u, this yields
||φu||Ht(U∩V ) ≤Cφ ||u||Ht(U) .
This proves the corollary.
41.3
Embedding Theorems
The Fourier transform description of Sobolev spaces makes possible fairly easy
proofs of various embedding theorems.
Deﬁnition 41.23 Let Cm
b (Rn) denote the functions which are m times continu-
ously diﬀerentiable and for which
sup
|α|≤m
sup
x∈Rn |Dαu (x)| ≡||u||Cm
b (Rn) < ∞.
For U an open set, Cm ¡
U
¢
denotes the functions which are restrictions of Cm
b (Rn)
to U.

41.3.
EMBEDDING THEOREMS
1187
It is clear this is a Banach space, the proof being a simple exercise in the use
of the fundamental theorem of calculus along with standard results about uniform
convergence.
Lemma 41.24 Let u ∈S and let n
2 + m < t. Then there exists C independent of
u such that
||u||Cm
b (Rn) ≤C ||u||Ht(Rn) .
Proof: Using the fact that the Fourier transform maps S to S and the deﬁnition
of the Fourier transform,
|Dαu (x)|
≤
C ||FDαu||L1(Rn)
=
C
Z
|xα| |Fu (x)| dx
≤
C
Z ³
1 + |x|2´|α|/2
|Fu (x)| dx
≤
C
Z ³
1 + |x|2´m/2 ³
1 + |x|2´−t/2 ³
1 + |x|2´t/2
|Fu (x)| dx
≤
C
µZ ³
1 + |x|2´m−t
dx
¶1/2 µZ ³
1 + |x|2´t
|Fu (x)|t
¶1/2
≤
C ||u||Ht(Rn)
because for the given values of t and m the ﬁrst integral is ﬁnite. This follows from
a use of polar coordinates. Taking sup over all x ∈Rn and |α| ≤m, this proves the
lemma.
Corollary 41.25 Let u ∈Ht (Rn) where t > m + n
2 . Then u is a.e. equal to a
function of Cm
b (Rn) still denoted by u. Furthermore, there exists a constant, C
independent of u such that
||u||Cm
b (Rn) ≤C ||u||Ht(Rn) .
Proof: This follows from the above lemma. Let {uk} be a sequence of functions
of S which converges to u in Ht and a.e. Then by the inequality of the above
lemma, this sequence is also Cauchy in Cm
b (Rn) and taking the limit,
||u||Cm
b (Rn) = lim
k→∞||uk||Cm
b (Rn) ≤C lim
k→∞||uk||Ht(Rn) = C ||u||Ht(Rn) .
What about open sets, U?
Corollary 41.26 Let t > m + n
2 and let U be an open set with u ∈Ht (U) . Then
u is a.e. equal to a function of Cm ¡
U
¢
still denoted by u. Furthermore, there exists
a constant, C independent of u such that
||u||Cm(U) ≤C ||u||Ht(U) .

1188
SOBOLEV SPACES BASED ON L2
Proof: Let u ∈Ht (U) and let v ∈Ht (Rn) such that v|U = u. Then
||u||Cm(U) ≤||v||Cm
b (Rn) ≤C ||v||Ht(Rn) .
Now taking the inf for all such v yields
||u||Cm(U) ≤C ||u||Ht(U) .
41.4
The Trace On The Boundary Of A Half Space
It is important to consider the restriction of functions in a Sobolev space onto a
smaller dimensional set such as the boundary of an open set.
Deﬁnition 41.27 For u ∈S, deﬁne γu a function deﬁned on Rn−1 by γu (x′) ≡
u (x′, 0) where x′ ∈Rn−1 is deﬁned by x = (x′, xn).
The following elementary lemma featuring trig. substitutions is the basis for the
proof of some of the arguments which follow.
Lemma 41.28 Consider the integral,
Z
R
¡
a2 + x2¢−t dx.
for a > 0 and t > 1/2. Then this integral is of the form Cta−2t+1 where Ct is some
constant which depends on t.
Proof: Letting x = a tan θ,
Z
R
¡
a2 + x2¢−t dx = a−2t+1
Z π/2
−π/2
cos2t−2 (θ) dθ
and since t > 1/2 the last integral is ﬁnite. This yields the desired conclusion and
proves the lemma.
Lemma 41.29 Let u ∈S. Then there exists a constant, Cn, depending on n but
independent of u ∈S such that
Fγu (x′) = Cn
Z
R
Fu (x′, xn) dxn.
Proof: Using the dominated convergence theorem,
Z
R
Fu (x′, xn) dxn ≡lim
ε→0
Z
R
e−(εxn)2Fu (x′, xn) dxn

41.4.
THE TRACE ON THE BOUNDARY OF A HALF SPACE
1189
≡
lim
ε→0
Z
R
e−(εxn)2 µ 1
2π
¶n/2 Z
Rn e−i(x′·y′+xnyn)u (y′, yn) dy′dyndxn
=
lim
ε→0
µ 1
2π
¶n/2 Z
Rn u (y′, yn) e−ix′·y′ Z
R
e−(εxn)2e−ixnyndxndy′dyn.
Now −(εxn)2 −ixnyn = −ε2 ¡
xn + iyn
2
¢2 −ε2 y2
n
4 and so the above reduces to an
expression of the form
lim
ε→0 Kn
Z
R
1
εe−ε2 y2
n
4
Z
Rn−1 u (y′, yn) e−ix′·y′dy′dyn
=
Kn
Z
Rn u (y′, 0) e−ix′·y′dy′
=
KnFγu (x′)
and this proves the lemma with Cn ≡K−1
n .
Earlier Ht (Rn) was deﬁned and then for U an open subset of Rn, Ht (U) was
deﬁned to be the space of restrictions of functions of Ht (Rn) to U and a norm
was given which made Ht (U) into a Banach space. The next task is to consider
Rn−1×{0} , a smaller dimensional subspace of Rn and examine the functions deﬁned
on this set, denoted by Rn−1 for short which are restrictions of functions in Ht (Rn) .
You note this is somewhat diﬀerent because heuristically, the dimension of the
domain of the function is changing. An open set in Rn is considered an n dimensional
thing but Rn−1 is only n−1 dimensional. I realize this is vague because the standard
deﬁnition of dimension requires a vector space and an open set is not a vector space.
However, think in terms of fatness. An open set is fat in n directions whereas Rn−1
is only fat in n −1 directions. Therefore, something interesting is likely to happen.
Let S denote the Schwartz class of functions on Rn and S′ the Schwartz class of
functions on Rn−1. Also, y′ ∈Rn−1 while y ∈Rn. Let u ∈S. Then from Lemma
41.29 and s > 0,
Z
Rn−1
³
1 + |y′|2´s
|Fγu (y′)|2 dy′
=
Cn
Z
Rn−1
³
1 + |y′|2´s ¯¯¯¯
Z
R
Fu (y′, yn) dyn
¯¯¯¯
2
dy′
= Cn
Z
Rn−1
³
1 + |y′|2´s ¯¯¯¯
Z
R
Fu (y′, yn)
³
1 + |y|2´t/2 ³
1 + |y|2´−t/2
dyn
¯¯¯¯
2
dy′
Then by the Cauchy Schwarz inequality,
≤Cn
Z
Rn−1
³
1 + |y′|2´s Z
R
|Fu (y′, yn)|2 ³
1 + |y|2´t
dyn
Z
R
³
1 + |y|2´−t
dyndy′.
(41.17)
Consider
Z
R
³
1 + |y|2´−t
dyn =
Z
R
³
1 + |y′|2 + y2
n
´−t
dyn

1190
SOBOLEV SPACES BASED ON L2
by Lemma 41.28 and taking a =
³
1 + |y′|2´1/2
, this equals
Ct
µ³
1 + |y′|2´1/2¶−2t+1
= Ct
³
1 + |y′|2´(−2t+1)/2
.
Now using this in 41.17,
Z
Rn−1
³
1 + |y′|2´s
|Fγu (y′)|2 dy′
≤
Cn,t
Z
Rn−1
³
1 + |y′|2´s Z
R
|Fu (y′, yn)|2 ³
1 + |y|2´t
dyn ·
³
1 + |y′|2´(−2t+1)/2
dy′
=
Cn,t
Z
Rn−1
³
1 + |y′|2´s+(−2t+1)/2 Z
R
|Fu (y′, yn)|2 ³
1 + |y|2´t
dyndy′.
What is the correct choice of t so that the above reduces to ||u||2
Ht(Rn)? It is clearly
the one for which
s + (−2t + 1) /2 = 0
which occurs when t = s + 1
2. Then for this choice of t, the following inequality is
obtained for any u ∈S.
||γu||Ht−1/2(Rn−1) ≤Cn,t ||u||Ht(Rn) .
(41.18)
This has proved part of the following theorem.
Theorem 41.30 For each t > 1/2 there exists a unique mapping
γ ∈L
³
Ht (Rn) , Ht−1/2 ¡
Rn−1¢´
which has the property that for u ∈S, γu (x′) = u (x′, 0) . In addition to this, γ is
onto. In fact, there exists a continuous map, ζ ∈L
¡
Ht−1/2 ¡
Rn−1¢
, Ht (Rn)
¢
such
that γ ◦ζ = id.
Proof: It only remains to verify that γ is onto and that the continuous map, ζ
exists. Now deﬁne
φ (y) ≡φ (y′, yn) ≡
³
1 + |y′|2´t−1/2
³
1 + |y|2´t
.
Then for u ∈S′, let
ζu (x) ≡CF −1 (φFu) (x) =
C
Z
Rn eiy·x
³
1 + |y′|2´t−1/2
³
1 + |y|2´t
Fu (y′) dy
(41.19)

41.4.
THE TRACE ON THE BOUNDARY OF A HALF SPACE
1191
Here the inside Fourier transform is taken with respect to Rn−1 because u is only
deﬁned on Rn−1 and C will be chosen in such a way that γ ◦ζ = id. First the
existence of C such that γ ◦ζ = id will be shown. Since u ∈S′ it follows
y →
³
1 + |y′|2´t−1/2
³
1 + |y|2´t
Fu (y′)
is in S. Hence the inverse Fourier transform of this function is also in S and so
for u ∈S′, it follows ζu ∈S. Therefore, to check γ ◦ζ = id it suﬃces to plug in
xn = 0. From Lemma 41.28 this yields
γ (ζu) (x′, 0)
=
C
Z
Rn eiy′·x′
³
1 + |y′|2´t−1/2
³
1 + |y|2´t
Fu (y′) dy
=
C
Z
Rn−1
³
1 + |y′|2´t−1/2
eiy′·x′Fu (y′)
Z
R
1
³
1 + |y|2´t dyndy′
=
CCt
Z
Rn−1
³
1 + |y′|2´t−1/2
eiy′·x′Fu (y′)
³
1 + |y′|2´ −2t+1
2
dy′
=
CCt
Z
Rn−1 eiy′·x′Fu (y′) dy′ = CCt (2π)n/2 F −1 (Fu) (x′)
and so the correct value of C is
³
Ct (2π)n/2´−1
to obtain γ ◦ζ = id. It only remains
to verify that ζ is continuous. From 41.19, and Lemma 41.28,
||ζu||2
Ht(Rn)
=
Z
Rn
³
1 + |x|2´t
|Fζu (x)|2 dx
=
C2
Z
Rn
³
1 + |x|2´t ¯¯F
¡
F −1 (φFu) (x)
¢¯¯2 dx
=
C2
Z
Rn
³
1 + |x|2´t
|φ (x) Fu (x′)|2 dx
=
C2
Z
Rn
³
1 + |x|2´t
¯¯¯¯¯¯¯
³
1 + |x′|2´t−1/2
³
1 + |x|2´t
Fu (x′)
¯¯¯¯¯¯¯
2
dx
=
C2
Z
Rn
³
1 + |x|2´−t ¯¯¯¯
³
1 + |x′|2´t−1/2
Fu (x′)
¯¯¯¯
2
dx
=
C2
Z
Rn−1
³
1 + |x′|2´2t−1
|Fu (x′)|2
Z
R
³
1 + |x|2´−t
dxndx′

1192
SOBOLEV SPACES BASED ON L2
=
C2Ct
Z
Rn−1
³
1 + |x′|2´2t−1
|Fu (x′)|2 ³
1 + |y′|2´ −2t+1
2
dx′
=
C2Ct
Z
Rn−1
³
1 + |x′|2´t−1/2
|Fu (x′)|2 dx′ = C2Ct ||u||2
Ht−1/2(Rn−1) .
This proves the theorem because S is dense in Rn.
Actually, the assertion that γu (x′) = u (x′, 0) holds for more functions, u than
just u ∈S. I will make no eﬀort to obtain the most general description of such
functions but the following is a useful lemma which will be needed when the trace
on the boundary of an open set is considered.
Lemma 41.31 Suppose u is continuous and u ∈H1 (Rn) . Then there exists a set
of m1 measure zero, N such that if xn /∈N, then for every φ ∈L2 ¡
Rn−1¢
(γu, φ)H +
Z xn
0
(u,n (·, t) , φ)H dt = (u (·, xn) , φ)H
where here
(f, g)H ≡
Z
Rn−1 fgdx′,
just the inner product in L2 ¡
Rn−1¢
. Furthermore,
u (·, 0) = γu a.e. x′.
Proof: Let {uk} be a sequence of functions from S which converges to u in
H1 (Rn) and let {φk} denote a countable dense subset of L2 ¡
Rn−1¢
. Then
¡
γuk, φj
¢
H +
Z xn
0
¡
uk,n (·, t) , φj
¢
H dt =
¡
uk (·, xn) , φj
¢
H .
(41.20)
Now
µZ ∞
0
¯¯¯
¡
uk (·, xn) , φj
¢
H −
¡
u (·, xn) , φj
¢
H
¯¯¯
2
dxn
¶1/2
=
µZ ∞
0
¯¯¯
¡
uk (·, xn) −u (·, xn) , φj
¢
H
¯¯¯
2
dxn
¶1/2
≤
µZ ∞
0
|uk (·, xn) −u (·, xn)|2
H
¯¯φj
¯¯2
H dxn
¶1/2
=
¯¯φj
¯¯2
H
µZ ∞
0
|uk (·, xn) −u (·, xn)|2
H dxn
¶1/2
=
¯¯φj
¯¯2
H
µZ ∞
0
Z
Rn−1 |uk (x′, xn) −u (x′, xn)|2 dx′dxn
¶1/2
which converges to zero. Therefore, there exists a set of measure zero, Nj and a
subsequence, still denoted by k such that if xn /∈Nj, then
¡
uk (·, xn) , φj
¢
H →
¡
u (·, xn) , φj
¢
H .

41.4.
THE TRACE ON THE BOUNDARY OF A HALF SPACE
1193
Now by Theorem 41.30, γuk →γu in H = L2 ¡
Rn−1¢
. It only remains to consider
the term of 41.20 which involves an integral.
¯¯¯¯
Z xn
0
¡
uk,n (·, t) , φj
¢
H dt −
Z xn
0
¡
u,n (·, t) , φj
¢
H dt
¯¯¯¯
≤
Z xn
0
¯¯¯
¡
uk,n (·, t) −u,n (·, t) , φj
¢
H
¯¯¯ dt
≤
Z xn
0
|uk,n (·, t) −u,n (·, t)|H
¯¯φj
¯¯
H dt
≤
µZ xn
0
|uk,n (·, t) −u,n (·, t)|2
H dt
¶1/2 µZ xn
0
¯¯φj
¯¯2
H dt
¶1/2
=
x1/2
n
¯¯φj
¯¯
H
µZ xn
0
Z
Rn−1 |uk,n (x′, t) −u,n (x′, t)|2 dx′
¶1/2
dt
and this converges to zero as k →∞. Therefore, using a diagonal sequence ar-
gument, there exists a subsequence, still denoted by k and a set of measure zero,
N ≡∪∞
j=1Nj such that for x′ /∈N, you can pass to the limit in 41.20 and obtain
that for all φj,
¡
γu, φj
¢
H +
Z xn
0
¡
u,n (·, t) , φj
¢
H dt =
¡
u (·, xn) , φj
¢
H .
By density of
©
φj
ª
, this equality holds for all φ ∈L2 ¡
Rn−1¢
. In particular, the
equality holds for every φ ∈Cc
¡
Rn−1¢
. Since u is uniformly continuous on the
compact set, spt (φ)×[0, 1] , there exists a sequence, (xn)k →0 such that the above
equality holds for xn replaced with (xn)k and φ in place of φj. Now taking k →∞,
this uniform continuity implies
(γu, φ)H = (u (·, 0) , φ)H
This implies since Cc
¡
Rn−1¢
is dense in L2 ¡
Rn−1¢
that γu = u (·, 0) a.e. and this
proves the lemma.
Lemma 41.32 Suppose U is an open subset of Rnof the form
U ≡{u ∈Rn : u′ ∈U ′ and 0 < un < φ (u′)}
where U ′ is an open subset of Rn−1 and
φ (u′) is a positive function such that
φ (u′) ≤∞and
inf {φ (u′) : u′ ∈U ′} = δ > 0
Suppose v ∈Ht (Rn) such that v = 0 a.e. on U. Then γv = 0 mn−1 a.e. point of
U ′. Also, if v ∈Ht (Rn) and φ ∈C∞
c (Rn) , then γvγφ = γ (φv) .
Proof: First consider the second claim. Let v ∈Ht (Rn) and let vk →v in
Ht (Rn) where vk ∈S. Then from Lemma 41.21 and Theorem 41.30
||γ (φv) −γφγv||Ht−1/2(Rn−1) = lim
k→∞||γ (φvk) −γφγvk||Ht−1/2(Rn−1) = 0

1194
SOBOLEV SPACES BASED ON L2
because each term in the sequence equals zero due to the observation that for vk ∈S
and φ ∈C∞
c (U) , γ (φvk) = γvkγφ.
Now suppose v = 0 a.e. on U. Deﬁne for 0 < r < δ, vr (x) ≡v (x′, xn + r) .
Claim: If u ∈Ht (Rn) , then
lim
r→0 ||vr −v||Ht(Rn) = 0.
Proof of claim: First of all, let v ∈S. Then v ∈Hm (Rn) for all m and so by
Lemma 41.15,
||vr −v||Ht(Rn) ≤||vr −v||θ
Hm(Rn) ||vr −v||1−θ
Hm+1(Rn)
where t ∈[m, m + 1] . It follows from continuity of translation in Lp (Rn) that
lim
r→0 ||vr −v||θ
Hm(Rn) ||vr −v||1−θ
Hm+1(Rn) = 0
and so the claim is proved if v ∈S. Now suppose u ∈Ht (Rn) is arbitrary. By
density of S in Ht (Rn) , there exists v ∈S such that
||u −v||Ht(Rn) < ε/3.
Therefore,
||ur −u||Ht(Rn)
≤
||ur −vr||Ht(Rn) + ||vr −v||Ht(Rn) + ||v −u||Ht(Rn)
=
2ε/3 + ||vr −v||Ht(Rn) .
Now using what was just shown, it follows that for r small enough, ||ur −u||Ht(Rn) <
ε and this proves the claim.
Now suppose v ∈Ht (Rn) . By the claim,
||vr −v||Ht(Rn) →0
and so by continuity of γ,
γvr →γv in Ht−1/2 ¡
Rn−1¢
.
(41.21)
Note vr = 0 a.e. on
Ur ≡{u ∈Rn : u′ ∈U ′ and −r < un < φ (u′) −r}
Let φ ∈C∞
c (Ur) and consider φvr. Then it follows φvr = 0 a.e. on Rn. Let
w ≡0. Then w ∈S and so γw = 0 = γ (φvr) = γφγvr in Ht−1/2 ¡
Rn−1¢
. It
follows that for mn−1 a.e. x′ ∈[φ ̸= 0] ∩Rn−1, γvr (x′) = 0. Now let U ′ = ∪∞
k=1Kk
where the Kk are compact sets such that Kk ⊆Kk+1 and let φk ∈C∞
c (U) such
that φk has values in [0, 1] and φk (x′) = 1 if x′ ∈Kk. Then from what was just
shown, γvr = 0 for a.e. point of Kk. Therefore, γvr = 0 for mn−1 a.e. point in U ′.
Therefore, since each γvr = 0, it follows from 41.21 that γv = 0 also. This proves
the lemma.

41.5.
SOBOLEV SPACES ON MANIFOLDS
1195
Theorem 41.33 Let t > 1/2 and let U be of the form
{u ∈Rn : u′ ∈U ′ and 0 < un < φ (u′)}
where U ′ is an open subset of Rn−1 and
φ (u′) is a positive function such that
φ (u′) ≤∞and
inf {φ (u′) : u′ ∈U ′} = δ > 0.
Then there exists a unique
γ ∈L
³
Ht (U) , Ht−1/2 (U ′)
´
which has the property that if u = v|U where v is continuous and also a function of
H1 (Rn) , then γu (x′) = u (x′, 0) for a.e. x′ ∈U ′.
Proof:
Let u ∈Ht (U) . Then u = v|U for some v ∈Ht (Rn) . Deﬁne
γu ≡γv|U ′
Is this well deﬁned? The answer is yes because if vi|U = u a.e., then γ (v1 −v2) = 0
a.e. on U ′ which implies γv1 = γv2 a.e. and so the two diﬀerent versions of γu
diﬀer only on a set of measure zero.
If u = v|U where v is continuous and also a function of H1 (Rn) , then for a.e.
x′ ∈Rn−1, it follows from Lemma 41.31 on Page 1192 that γv (x′) = v (x′, 0) .
Hence, it follows that for a.e. x′ ∈U ′, γu (x′) ≡u (x′, 0).
In particular, γ is determined by γu (x′) = u (x′, 0) on S|U and the density of
S|U and continuity of γ shows γ is unique.
It only remains to show γ is continuous. Let u ∈Ht (U) . Thus there exists
v ∈Ht (Rn) such that u = v|U. Then
||γu||Ht−1/2(U ′) ≤||γv||Ht−1/2(Rn−1) ≤C ||v||Ht(Rn)
for C independent of v. Then taking the inf for all such v ∈Ht (Rn) which are
equal to u a.e. on U, it follows
||γu||Ht−1/2(U ′) ≤C ||v||Ht(Rn)
and this proves γ is continuous.
41.5
Sobolev Spaces On Manifolds
41.5.1
General Theory
The type of manifold, Γ for which Sobolev spaces will be deﬁned on is:
Deﬁnition 41.34
1. Γ is a closed subset of Rp where p ≥n.
2. Γ = ∪∞
i=1Γi where Γi = Γ ∩Wi for Wi a bounded open set.

1196
SOBOLEV SPACES BASED ON L2
3. {Wi}∞
i=1 is locally ﬁnite.
4. There are open bounded sets, Ui and functions hi : Ui →Γi which are one to
one, onto, and in Cm,1 (Ui) . There exists a constant, C, such that C ≥Lip hr
for all r.
5. There exist functions, gi : Wi →Ui such that gi is Cm,1 (Wi) , and gi◦hi = id
on Ui while hi ◦gi = id on Γi.
This will be referred to as a Cm,1 manifold.
Lemma 41.35 Let gi, hi, Ui, Wi, and Γi be as deﬁned above. Then
gi ◦hk : Uk ∩h−1
k
(Γi) →Ui ∩h−1
i
(Γk)
is Cm,1. Furthermore, the inverse of this map is gk ◦hi.
Proof: First it is well to show it does indeed map the given open sets. Let
x ∈Uk∩h−1
k
(Γi) . Then hk (x) ∈Γk∩Γi and so gi (hk (x)) ∈Ui because hk (x) ∈Γi.
Now since hk (x) ∈Γk, gi (hk (x)) ∈h−1
i
(Γk) also and this proves the mappings do
what they should in terms of mapping the two open sets. That gi◦hk is Cm,1 follows
immediately from the chain rule and the assumptions that the functions gi and hk
are Cm,1. The claim about the inverse follows immediately from the deﬁnitions of
the functions.
Let {ψi}∞
i=1 be a partition of unity subordinate to the open cover {Wi} satisfying
ψi ∈C∞
c (Wi) . Then the following deﬁnition provides a norm for Hm+s (Γ) .
Deﬁnition 41.36 Let s ∈(0, 1) and m is a nonnegative integer. Also let µ denote
the surface measure for Γ deﬁned in the last section. A µ measurable function, u
is in Hm+s (Γ) if whenever {Wi, ψi, Γi, Ui, hi, gi}∞
i=1 is described above, h∗
i (uψi) ∈
Hm+s (Ui) and
||u||Hm+s(Γ) ≡
Ã ∞
X
i=1
||h∗
i (uψi)||2
Hm+s(Ui)
!1/2
< ∞.
Are there functions which are in Hm+s (Γ)? The answer is yes. Just take the
restriction to Γ of any function, u ∈C∞
c (Rm) . Then each h∗
i (uψi) ∈Hm+s (Ui)
and the sum is ﬁnite because spt u has nonempty intersection with only ﬁnitely
many Wi.
It is not at all obvious this norm is well deﬁned. What if
©
W ′
i, ψ′
i, Γ′
i, Ui, h′
i, g′
i
ª∞
i=1
is as described above? Would the two norms be equivalent? If they aren’t, then
this is not a good way to deﬁne Hm+s (Γ) because it would depend on the choice of
partition of unity and functions, hi and choice of the open sets, Ui. To begin with
pick a particular choice for {Wi, ψi, Γi, Ui, hi, gi}∞
i=1 .
Lemma 41.37 Hm+s (Γ) as just described, is a Banach space.

41.5.
SOBOLEV SPACES ON MANIFOLDS
1197
Proof: Let {uj}∞
j=1 be a Cauchy sequence in Hm+s (Γ) . Then {h∗
i (ujψi)}∞
j=1
is a Cauchy sequence in Hm+s (Ui) for each i. Therefore, for each i, there exists
wi ∈Hm+s (Ui) such that
lim
j→∞h∗
i (ujψi) = wi in Hm+s (Ui) .
(41.22)
It is required to show there exists u ∈Hm+s (Γ) such that wi = h∗
i (uψi) for each i.
Now from Corollary 39.14 it follows easily by approximating with simple func-
tions that for ever nonnegative µ measurable function, f,
Z
Γ
fdµ =
∞
X
r=1
Z
grΓr
ψrf (hr (u)) Jr (u) du.
Therefore,
Z
Γ
|uj −uk|2 dµ
=
∞
X
r=1
Z
grΓr
ψr |uj −uk|2 (hr (u)) Jr (u) du
≤
C
∞
X
r=1
Z
grΓr
ψr |uj −uk|2 (hr (u)) du
=
C
∞
X
r=1
||h∗
r (ψr |uj −uk|)||2
0,2,Ur
≤
C ||uj −uk||Hm+s(Γ)
and it follows there exists u ∈L2 (Γ) such that
||uj −u||0,2,Γ →0.
and a subsequence, still denoted by uj such that uj (x) →u (x) for µ a.e. x ∈Γ. It
is required to show that u ∈Hm+s (Γ) such that wi = h∗
i (uψi) for each i. First of
all, u is measurable because it is the limit of measurable functions. The pointwise
convergence just established and the fact that sets of measure zero on Γi correspond
to sets of measure zero on Ui which was discussed in the claim found in the proof
of Theorem 39.13 on Page 1129 shows that
h∗
i (ujψi) (x) →h∗
i (uψi) (x)
a.e. x. Therefore,
h∗
i (uψi) = wi
and this shows that h∗
i (uψi) ∈Hm+s (Ui) . It remains to verify that u ∈Hm+s (Γ) .
This follows from Fatou’s lemma. From 41.22,
||h∗
i (ujψi)||2
Hm+s(Ui) →||h∗
i (uψi)||2
Hm+s(Ui)

1198
SOBOLEV SPACES BASED ON L2
and so
∞
X
i=1
||h∗
i (uψi)||2
Hm+s(Ui)
≤
lim inf
j→∞
∞
X
i=1
||h∗
i (ujψi)||2
Hm+s(Ui)
=
lim inf
j→∞||uj||2
Hm+s(Γ) < ∞.
This proves the lemma.
In fact any two such norms are equivalent. This follows from the open map-
ping theorem. Suppose ||·||1 and ||·||2 are two such norms and consider the norm
||·||3 ≡max (||·||1 , ||·||2) . Then (Hm+s (Γ) , ||·||3) is also a Banach space and the
identity map from this Banach space to (Hm+s (Γ) , ||·||i) for i = 1, 2 is continuous.
Therefore, by the open mapping theorem, there exist constants, C, C′ such that for
all u ∈Hm+s (Γ) ,
||u||1 ≤||u||3 ≤C ||u||2 ≤C ||u||3 ≤CC′ ||u||1
Therefore,
||u||1 ≤C ||u||2 , ||u||2 ≤C′ ||u||1 .
This proves the following theorem.
Theorem 41.38 Let Γ be described above. Deﬁning Ht (Γ) as in Deﬁnition 41.36,
any two norms like those given in this deﬁnition are equivalent.
Suppose (Γ, Wi, Ui, Γi, hi, gi) are as deﬁned above where hi, gi are Cm,1 func-
tions. Take W, an open set in Rp and deﬁne Γ′ ≡W ∩Γ. Then letting
W ′
i ≡W ∩Wi, Γ′
i ≡W ′
i ∩Γ,
and
U ′
i ≡gi (Γ′
i) = h−1
i
(W ′
i ∩Γ) ,
it follows that U ′
i is an open set because hi is continuous and (Γ′, W ′
i, U ′
i, Γ′
i, h′
i, g′
i)
is also a Cm,1 manifold if you deﬁne h′
i to be the restriction of hi to U ′
i and g′
i to
be the restriction of gi to W ′
i.
As a case of this, consider a Cm,1 manifold, Γ where (Γ, Wi, Ui, Γi, hi, gi) are as
described in Deﬁnition 41.34 and the submanifold consisting of Γi. The next lemma
shows there is a simple way to deﬁne a norm on Ht (Γi) which does not depend on
dragging in a partition of unity.
Lemma 41.39 Suppose Γ is a Cm,1 manifold and (Γ, Wi, Ui, Γi, hi, gi) are as de-
scribed in Deﬁnition 41.34. Then for t ∈[m, m + s), it follows that if u ∈Ht (Γ) ,
then u ∈Ht (Γk) and the restriction map is continuous. Also an equivalent norm
for Ht (Γk) is given by
|||u|||t ≡||h∗
ku||Ht(Uk) .

41.5.
SOBOLEV SPACES ON MANIFOLDS
1199
Proof: Let u ∈Ht (Γ) and let (Γk, W ′
i, U ′
i, Γ′
i, h′
i, g′
i) be the sets and functions
which deﬁne what is meant by Γk being a Cm,1 manifold as described in Deﬁnition
41.34. Also let (Γ, Wi, Ui, Γi, hi, gi) be pertain to Γ in the same way and let
©
φj
ª
be a C∞partition of unity for the {Wj}. Since the {W ′
i} are locally ﬁnite, only
ﬁnitely many can intersect Γk, say {W ′
1, · · ·, W ′
s} . Also only ﬁnitely many of the Wi
can intersect Γk, say {W1, · · ·, Wq} . Then letting
©
ψ′
i
ª
be a C∞partition of unity
subordinate to the {W ′
i} .
∞
X
i=1
¯¯¯¯h′∗
i
¡
uψ′
i
¢¯¯¯¯
Ht(U ′
i)
=
s
X
i=1
¯¯¯¯¯¯
¯¯¯¯¯¯
h′∗
i


q
X
j=1
φjuψ′
i


¯¯¯¯¯¯
¯¯¯¯¯¯
Ht(U ′
i)
≤
s
X
i=1
q
X
j=1
¯¯¯¯h′∗
i φjuψ′
i
¯¯¯¯
Ht(U ′
i)
=
q
X
j=1
s
X
i=1
¯¯¯¯h′∗
i φjuψ′
i
¯¯¯¯
Ht(U ′
i)
=
q
X
j=1
s
X
i=1
¯¯¯¯(gj ◦h′
i)∗h∗
jφjuψ′
i
¯¯¯¯
Ht(U ′
i) .
By Lemma 41.20 on page 1185, there exists a single constant, C such that the above
is dominated by
C
q
X
j=1
s
X
i=1
¯¯¯¯h∗
jφjuψ′
i
¯¯¯¯
Ht(Uj) .
Now by Corollary 41.22 on Page 1186, this is no larger than
C
q
X
j=1
s
X
i=1
Cψ′
i
¯¯¯¯h∗
jφju
¯¯¯¯
Ht(Uj)
≤
C
q
X
j=1
s
X
i=1
¯¯¯¯h∗
jφju
¯¯¯¯
Ht(Uj)
≤
C
q
X
j=1
¯¯¯¯h∗
jφju
¯¯¯¯
Ht(Uj) < ∞.
This shows that u restricted to Γk is in Ht (Γk). It also shows that the restriction
map of Ht (Γ) to Ht (Γk) is continuous.
Now consider the norm |||·|||t . For u ∈Ht (Γk) , let (Γk, W ′
i, U ′
i, Γ′
i, h′
i, g′
i) be
sets and functions which deﬁne an atlas for Γk. Since the {W ′
i} are locally ﬁnite,
only ﬁnitely many can have nonempty intersection with Γk, say {W1, · · ·, Ws} . Thus
i ≤s for some ﬁnite s. The problem is to compare |||·|||t with ||·||Ht(Γk) . As above,

1200
SOBOLEV SPACES BASED ON L2
let
©
ψ′
i
ª
denote a C∞partition of unity subordinate to the
©
W ′
j
ª
. Then
|||u|||t
≡
||h∗
ku||Ht(Uk) =
¯¯¯¯¯¯
¯¯¯¯¯¯
h∗
k
s
X
j=1
ψ′
ju
¯¯¯¯¯¯
¯¯¯¯¯¯
Ht(Uk)
≤
s
X
j=1
¯¯¯¯h∗
k
¡
ψ′
ju
¢¯¯¯¯
Ht(Uk)
=
s
X
j=1
¯¯¯
¯¯¯
¡
g′
j ◦hk
¢∗h′∗
j
¡
ψ′
ju
¢¯¯¯
¯¯¯
Ht(Uk)
≤
C
s
X
j=1
¯¯¯¯h′∗
j
¡
ψ′
ju
¢¯¯¯¯
Ht(U ′
j) .
≤
C


s
X
j=1
¯¯¯¯h′∗
j
¡
ψ′
ju
¢¯¯¯¯2
Ht(U ′
j)


1/2
= ||u||Ht(Γk) .
where Lemma 41.20 on page 1185 was used in the last step. Now also, from Lemma
41.20 on page 1185
||u||Ht(Γk)
=


s
X
j=1
¯¯¯¯h′∗
j
¡
ψ′
ju
¢¯¯¯¯2
Ht(U ′
j)


1/2
=


s
X
j=1
¯¯¯
¯¯¯
¡
gk ◦h′
j
¢∗h∗
k
¡
ψ′
ju
¢¯¯¯
¯¯¯
2
Ht(U ′
j)


1/2
≤
C


s
X
j=1
¯¯¯¯h∗
k
¡
ψ′
ju
¢¯¯¯¯2
Ht(Uk)


1/2
≤
C


s
X
j=1
||h∗
ku||2
Ht(Uk)


1/2
= Cs ||h∗
ku||Ht(Uk) = |||u|||t .
This proves the lemma.
41.5.2
The Trace On The Boundary
Deﬁnition 41.40 A bounded open subset, Ω, of Rn has a Cm,1boundary if it sat-
isﬁes the following conditions. For each p ∈Γ ≡Ω\Ω, there exists an open set, W,
containing p, an open interval (0, b), a bounded open box U ′ ⊆Rn−1, and an aﬃne
orthogonal transformation, RW consisting of a distance preserving linear transfor-
mation followed by a translation such that
RW W = U ′ × (0, b),
(41.23)

41.5.
SOBOLEV SPACES ON MANIFOLDS
1201
RW (W ∩Ω) = {u ∈Rn : u′ ∈U ′, 0 < un < φW (u′)} ≡UW
(41.24)
where φW ∈Cm,1 ¡
U ′¢
meaning φW is the restriction to U ′ of a function, still
denoted by φW which is in Cm,1 ¡
Rn−1¢
and
inf {φW (u′) : u′ ∈U ′} > 0
The following picture depicts the situation.




ZZZZZ
ZZZZZ




-
R
W
ΩT W
RW (ΩT W)
0
b
u′ ∈U ′
For the situation described in the above deﬁnition, let hW : U ′ →Γ ∩W be
deﬁned by
hW (u′) ≡R−1
W (u′, φW (u′)) , gW (x) ≡(RW x)′ , HW (u) ≡R−1
W (u′, φW (u′) −un) .
where x′ ≡(x1, · · ·, xn−1) for x = (x1, · · ·, xn). Thus gW ◦hW = id on U ′ and
hW ◦gW = id on Γ∩W. Also note that HW is deﬁned on all of Rn is Cm,1, and has
an inverse with the same properties. To see this, let GW (u) = (u′, φW (u′) −un) .
Then HW = R−1
W ◦GW and G−1
W = (u′, φW (u′) −un) and so H−1
W = G−1
W ◦RW .
Note also that as indicated in the picture,
RW (W ∩Ω) = {u ∈Rn : u′ ∈U ′ and 0 < un < φW (u′)} .
Since Γ = ∂Ωis compact, there exist ﬁnitely many of these open sets, W, denoted
by {Wi}q
i=1 such that Γ ⊆∪q
i=1Wi. Let the corresponding sets, U ′ be denoted by U ′
i
and let the functions, φ be denoted by φi. Also let hi = hWi etc. Now let {ψi}q
i=1
be a C∞partition of unity subordinate to the {Wi}q
i=1. If u ∈Ht (Ω) , then by
Corollary 41.22 on Page 1186 it follows that uψi ∈Ht (Wi ∩Ω) . Now
Hi : Ui ≡{u ∈Rn : u′ ∈U ′
i, 0 < un < φi (u′)} →Wi ∩Ω
and Hi and its inverse are deﬁned on Rn and are in Cm,1 (Rn) . Therefore, by
Lemma 41.20 on Page 1185,
H∗
i ∈L
¡
Ht (Wi ∩Ω) , Ht (Ui)
¢
.
Now it is possible to deﬁne the trace on Γ ≡∂Ω. For u ∈Ht (Ω) ,
γu ≡
q
X
i=1
g∗
i (γH∗
i (uψi)) .
(41.25)
I must show it satisﬁes what it should. Recall the deﬁnition of what it means for a
function to be in Ht−1/2 (Γ) where t = m + s.

1202
SOBOLEV SPACES BASED ON L2
Deﬁnition 41.41 Let s ∈(0, 1) and m is a nonnegative integer. Also let µ denote
the surface measure for Γ. A µ measurable function, u is in Hm+s (Γ) if whenever
{Wi, ψi, Γi, Ui, hi, gi}∞
i=1 is described above, h∗
i (uψi) ∈Hm+s (Ui) and
||u||Hm+s(Γ) ≡
Ã ∞
X
i=1
||h∗
i (uψi)||2
Hm+s(Ui)
!1/2
< ∞.
Recall that all these norms which are obtained from various partitions of unity
and functions, hi and gi are equivalent. Here there are only ﬁnitely many Wi so
the sum is a ﬁnite sum. The theorem is the following.
Theorem 41.42 Let Ωbe a bounded open set having Cm,1 boundary as discussed
above in Deﬁnition 41.40. Then for t ≤m + 1, there exists a unique
γ ∈L
³
Ht (Ω) , Ht−1/2 (Γ)
´
which has the property that for µ the measure on the boundary,
γu (x) = u (x) for µ a.e. x ∈Γwhenever u ∈S|Ω.
(41.26)
Proof: First consider the claim that γ ∈L
¡
Ht (Ω) , Ht−1/2 (Γ)
¢
. This involves
ﬁrst showing that for u ∈Ht (Ω) , γu ∈Ht−1/2 (Γ) . To do this, use the above
deﬁnition.
h∗
j
¡
ψj (γu)
¢
=
q
X
i=1
h∗
j
¡
ψjg∗
i (γH∗
i (uψi))
¢
=
q
X
i=1
¡
h∗
jψj
¢ ¡
h∗
j (g∗
i (γH∗
i (uψi)))
¢
=
q
X
i=1
¡
h∗
jψj
¢
(gi ◦hj)∗(γH∗
i (uψi))
(41.27)
First note that
γH∗
i (uψi) ∈Ht−1/2 (U ′
i)
Now gi ◦hj and its inverse, gj ◦hi are both functions in Cm,1 ¡
Rn−1¢
and
gi ◦hj : U ′
j →U ′
i.
Therefore, by Lemma 41.20 on Page 1185,
(gi ◦hj)∗(γH∗
i (uψi)) ∈Ht−1/2 ¡
U ′
j
¢
and
¯¯¯¯(gi ◦hj)∗(γH∗
i (uψi))
¯¯¯¯
Ht−1/2(U ′
j) ≤Cij ||γH∗
i (uψi)||Ht−1/2(U ′
i) .

41.5.
SOBOLEV SPACES ON MANIFOLDS
1203
Also h∗
jψj ∈Cm,1 ¡
U ′
j
¢
and has compact support in U ′
j and so by Corollary 41.22
on Page 1186
¡
h∗
jψj
¢
(gi ◦hj)∗(γH∗
i (uψi)) ∈Ht−1/2 ¡
U ′
j
¢
and
¯¯¯¯¡
h∗
jψj
¢
(gi ◦hj)∗(γH∗
i (uψi))
¯¯¯¯
Ht−1/2(U ′
j)
≤
Cij
¯¯¯¯(gi ◦hj)∗(γH∗
i (uψi))
¯¯¯¯
Ht−1/2(U ′
j)
(41.28)
≤
Cij ||γH∗
i (uψi)||Ht−1/2(U ′
i) .
(41.29)
This shows γu ∈Ht−1/2 (Γ) because each h∗
j
¡
ψj (γu)
¢
∈Ht−1/2 ¡
U ′
j
¢
. Also
from 41.29 and 41.27
||γu||2
Ht−1/2(Γ) ≤
q
X
j=1
¯¯¯¯h∗
j
¡
ψj (γu)
¢¯¯¯¯2
Ht−1/2(U ′
j)
=
q
X
j=1
¯¯¯¯h∗
j
¡
ψj (γu)
¢¯¯¯¯2
Ht−1/2(U ′
j)
=
q
X
j=1
¯¯¯¯¯
¯¯¯¯¯
q
X
i=1
¡
h∗
jψj
¢
(gi ◦hj)∗(γH∗
i (uψi))
¯¯¯¯¯
¯¯¯¯¯
2
Ht−1/2(U ′
j)
≤
Cq
q
X
j=1
q
X
i=1
¯¯¯¯¡
h∗
jψj
¢
(gi ◦hj)∗(γH∗
i (uψi))
¯¯¯¯2
Ht−1/2(U ′
j)
≤
Cq
q
X
j=1
q
X
i=1
Cij ||(γH∗
i (uψi))||2
Ht−1/2(U ′
i)
≤
Cq
q
X
i=1
||(γH∗
i (uψi))||2
Ht−1/2(U ′
i)
≤
Cq
q
X
i=1
||H∗
i (uψi)||2
Ht(Ri(Wi∩Ω))
≤
Cq
q
X
i=1
||uψi||2
Ht(Wi∩Ω) ≤Cq ||u||2
Ht(Ω) .
Does γ satisfy 41.26? Let x ∈Γ and u ∈S|Ω. Let
Ix ≡{i ∈{1, 2, · · ·, q} : x = hi (u′
i) for some u′
i ∈U ′
i} .

1204
SOBOLEV SPACES BASED ON L2
Then
γu (x)
=
X
i∈Ix
(γH∗
i (uψi)) (gi (x))
=
X
i∈Ix
(γH∗
i (uψi)) (gi (hi (u′
i)))
=
X
i∈Ix
(γH∗
i (uψi)) (u′
i) .
Now because Hi is Lipschitz continuous and uψ ∈S, it follows that H∗
i (uψi) ∈
H1 (Rn) and is continuous and so by Theorem 41.33 on Page 1195 for a.e. u′
i,
=
X
i∈Ix
H∗
i (uψi) (u′
i, 0)
=
X
i∈Ix
h∗
i (uψi) (u′
i)
=
X
i∈Ix
(uψi) (hi (u′
i)) = u (x) for µ a.e.x.
(41.30)
This veriﬁes 41.26 and completes the proof of the theorem.

Weak Solutions
42.1
The Lax Milgram Theorem
The Lax Milgram theorem is a fundamental result which is useful for obtaining
weak solutions to many types of partial diﬀerential equations. It is really a general
theorem in functional analysis.
Deﬁnition 42.1 Let A ∈L (V, V ′) where V is a Hilbert space. Then A is said to
be coercive if
A (v) (v) ≥δ ||v||2
for some δ > 0.
Theorem 42.2 (Lax Milgram) Let A ∈L (V, V ′) be coercive. Then A maps one to
one and onto.
Proof: The proof that A is onto involves showing A (V ) is both dense and
closed.
Consider ﬁrst the claim that A (V ) is closed. Let Axn →y∗∈V ′. Then
δ ||xn −xm||2
V ≤||Axn −Axm||V ′ ||xn −xm||V .
Therefore, {xn} is a Cauchy sequence in V. It follows xn →x ∈V and since A is
continuous, Axn →Ax. This shows A (V ) is closed.
Now let R : V →V ′ denote the Riesz map deﬁned by Rx (y) = (y, x) . Recall
that the Riesz map is one to one, onto, and preserves norms. Therefore, R−1 (A (V ))
is a closed subspace of V. If there R−1 (A (V )) ̸= V, then
¡
R−1 (A (V ))
¢⊥̸= {0} .
Let x ∈
¡
R−1 (A (V ))
¢⊥and x ̸= 0. Then in particular,
0 =
¡
x, R−1Ax
¢
= R
¡
R−1 (A (x))
¢
(x) = A (x) (x) ≥δ ||x||2
V ,
a contradiction to x ̸= 0. Therefore, R−1 (A (V )) = V and so A (V ) = R (V ) = V ′.
Since A (V ) is both closed and dense, A (V ) = V ′. This shows A is onto.
If Ax = Ay, then 0 = A (x −y) (x −y) ≥δ ||x −y||2
V , and this shows A is one
to one. This proves the theorem.
1205

1206
WEAK SOLUTIONS
Here is a simple example which illustrates the use of the above theorem. In the
example the repeated index summation convention is being used. That is, you sum
over the repeated indices.
Example 42.3 Let U be an open subset of Rn and let V be a closed subspace of
H1 (U) . Let αij ∈L∞(U) for i, j = 1, 2, · · ·, n. Now deﬁne A : V →V ′ by
A (u) (v) ≡
Z
U
¡
αij (x) u,i (x) v,j (x) + u (x) v (x)
¢
dx.
Suppose also that
αijvivj ≥δ |v|2
whenever v ∈Rn. Then A maps V to V ′ one to one and onto.
Here is why. It is obvious that A is in L (V, V ′) . It only remains to verify that
it is coercive.
A (u) (u)
≡
Z
U
¡
αij (x) u,i (x) u,j (x) + u (x) u (x)
¢
dx
≥
Z
U
δ |∇u (x)|2 + |u (x)|2 dx
≥
δ ||u||2
H1(U)
This proves coercivity and veriﬁes the claim.
What has been obtained in the above example?
This depends on how you
choose V. In Example 42.3 suppose U is a bounded open set with C0,1 boundary
and V = H1
0 (U) where
H1
0 (U) ≡
©
u ∈H1 (U) : γu = 0
ª
.
Also suppose f ∈L2 (U) . Then you can consider F ∈V ′ by deﬁning
F (v) ≡
Z
U
f (x) v (x) dx.
According to the Lax Milgram theorem and the veriﬁcation of its conditions in
Example 42.3, there exists a unique solution to the problem of ﬁnding u ∈H1
0 (U)
such that for all v ∈H1
0 (U) ,
Z
U
¡
αij (x) u,i (x) v,j (x) + u (x) v (x)
¢
dx =
Z
U
f (x) v (x) dx
(42.1)
In particular, this holds for all v ∈C∞
c (U) . Thus for all such v,
Z
U
³
−
¡
αij (x) u,i (x)
¢
,j + u (x) −f (x)
´
v (x) dx = 0.
Therefore, in terms of weak derivatives,
−
¡
αiju,i
¢
,j + u = f

42.1.
THE LAX MILGRAM THEOREM
1207
and since u ∈H1
0 (U) , it must be the case that γu = 0 on ∂U. This is why the
solution to 42.1 is referred to as a weak solution to the boundary value problem
−
¡
αij (x) u,i (x)
¢
,j + u (x) = f (x) , u = 0 on ∂U.
Of course you then begin to ask the important question whether u really has two
derivatives.
It is not immediately clear that just because −
¡
αij (x) u,i (x)
¢
,j ∈
L2 (U) it follows that the second derivatives of u exist. Actually this will often be
true and is discussed somewhat in the next section.
Next suppose you choose V = H1 (U) and let g ∈H1/2 (∂U). Deﬁne F ∈V ′ by
F (v) ≡
Z
U
f (x) v (x) dx +
Z
∂U
g (x) γv (x) dµ.
Everything works the same way and you get the existence of a unique u ∈H1 (U)
such that for all v ∈H1 (U) ,
Z
U
¡
αij (x) u,i (x) v,j (x) + u (x) v (x)
¢
dx =
Z
U
f (x) v (x) dx +
Z
∂U
g (x) γv (x) dµ
(42.2)
is satisﬁed. It you pretend u has all second order derivatives in L2 (U) and apply
the divergence theorem, you ﬁnd that you have obtained a weak solution to
−
¡
αiju,i
¢
,j + u = f, αiju,inj = g on ∂U
where nj is the jth component of n, the unit outer normal. Therefore, u is a weak
solution to the above boundary value problem.
The conclusion is that the Lax Milgram theorem gives a way to obtain existence
and uniqueness of weak solutions to various boundary value problems. The following
theorem is often very useful in establishing coercivity. To prove this theorem, here
is a deﬁnition.
Deﬁnition 42.4 Let U be an open set and δ > 0. Then
Uδ ≡
©
x ∈U : dist
¡
x,U C¢
> δ
ª
.
Theorem 42.5 Let U be a connected bounded open set having C0,1 boundary such
that for some sequence, ηk ↓0,
U = ∪∞
k=1Uηk
(42.3)
and Uηk is a connected open set. Suppose Γ ⊆∂U has positive surface measure and
that
V ≡
©
u ∈H1 (U) : γu = 0 a.e. on Γ
ª
.
Then the norm |||·||| given by
|||u||| ≡
µZ
U
|∇u|2 dx
¶1/2
is equivalent to the usual norm on V.

1208
WEAK SOLUTIONS
Proof: First it is necessary to verify this is actually a norm. It clearly satisﬁes
all the usual axioms of a norm except for the condition that |||u||| = 0 if and only
if u = 0. Suppose then that |||u||| = 0. Let δ0 = ηk for one of those ηk mentioned
above and deﬁne
uδ (x) ≡
Z
B(0,δ)
u (x −y) φδ (y) dy
where φδ is a molliﬁer having support in B (0, δ) . Then changing the variables, it
follows that for x ∈Uδ0
uδ (x) =
Z
B(x,δ)
u (t) φδ (x −t) dt =
Z
U
u (t) φδ (x −t) dt
and so uδ ∈C∞(Uδ0) and
∇uδ (x) =
Z
U
u (t) ∇φδ (x −t) dt =
Z
B(0,δ)
∇u (x −y) φδ (y) dy = 0.
Therefore, uδ equals a constant on Uδ0 because Uδ0 is a connected open set and
uδ is a smooth function deﬁned on this set which has its gradient equal to 0. By
Minkowski’s inequality,
ÃZ
Uδ0
|u (x) −uδ (x)|2 dx
!1/2
≤
Z
B(0,δ)
φδ (y)
ÃZ
Uδ0
|u (x) −u (x −y)|2 dx
!1/2
dy
and this converges to 0 as δ →0 by continuity of translation in L2. It follows
there exists a sequence of constants, cδ ≡uδ (x) such that {cδ} converges to u in
L2 (Uδ0) . Consequently, a subsequence, still denoted by uδ, converges to u a.e. By
Eggoroﬀ’s theorem there exists a set, Nk having measure no more than 3−kmn (Uδ0)
such that uδ converges to u uniformly on N C
k . Thus u is constant on N C
k . Now
P
k mn (Nk) ≤
1
2mn (Uδ0) and so there exists x0 ∈Uδ0 \ ∪∞
k=1Nk. Therefore, if
x /∈Nk it follows u (x) = u (x0) and so, if u (x) ̸= u (x0) it must be the case that
x ∈∩∞
k=1Nk, a set of measure zero. This shows that u equals a constant a.e. on
Uδ0 = Uηk. Since k is arbitrary, 42.3 shows u is a.e. equal to a constant on U.
Therefore, u equals the restriction of a function of S to U and so γu equals this
constant in L2 (∂Ω) . Since the surface measure of Γ is positive, the constant must
equal zero. Therefore, |||·||| is a norm.
It remains to verify that it is equivalent to the usual norm.
It is clear that
|||u||| ≤||u||1,2 . What about the other direction? Suppose it is not true that for
some constant, K, ||u||1,2 ≤K |||u||| . Then for every k ∈N, there exists uk ∈V
such that
||uk||1,2 > k |||uk||| .
Replacing uk with uk/ ||uk||1,2 , it can be assumed that ||uk||1,2 = 1 for all k.
Therefore, using the compactness of the embedding of H1 (U) into L2 (U) , there

42.1.
THE LAX MILGRAM THEOREM
1209
exists a subsequence, still denoted by uk such that
uk
→
u weakly in V,
(42.4)
uk
→
u strongly in L2 (U) ,
(42.5)
|||uk|||
→
0,
(42.6)
uk
→
u weakly in (V, |||·|||) .
(42.7)
From 42.6 and 42.7, it follows u = 0. Therefore, |uk|L2(U) →0. This with 42.6
contradicts the fact that ||uk||1,2 = 1 and this proves the equivalence of the two
norms.
The proof of the above theorem yields the following interesting corollary.
Corollary 42.6 Let U be a connected open set with the property that for some
sequence, ηk ↓0,
U = ∪∞
k=1Uηk
for Uηk a connected open set and suppose u ∈W 1,p (U) and ∇u = 0 a.e. Then u
equals a constant a.e.
Example 42.7 Let U be a bounded open connected subset of Rn and let V be a
closed subspace of H1 (U) deﬁned by
V ≡
©
u ∈H1 (U) : γu = 0 on Γ
ª
where the surface measure of Γ is positive.
Let αij ∈L∞(U) for i, j = 1, 2, · · ·, n and deﬁne A : V →V ′ by
A (u) (v) ≡
Z
U
αij (x) u,i (x) v,j (x) dx.
for
αijvivj ≥δ |v|2
whenever v ∈Rn. Then A maps V to V ′ one to one and onto.
This follows from Theorem 42.5 using the equivalent norm deﬁned there. Deﬁne
F ∈V ′ by
Z
U
f (x) v (x) dx +
Z
∂U\Γ
g (x) γv (x) dx
for f ∈L2 (U) and g ∈H1/2 (∂U) . Then the equation,
Au = F in V ′
which is equivalent to u ∈V and for all v ∈V,
Z
U
αij (x) u,i (x) v,j (x) dx =
Z
U
f (x) v (x) dx +
Z
∂U\Γ
g (x) γv (x) dµ
is a weak solution for the boundary value problem,
−
¡
αiju,i
¢
,j = f in U, αiju,inj = g on ∂U \ Γ, u = 0 on Γ
as you can verify by using the divergence theorem formally.

1210
WEAK SOLUTIONS

Korn’s Inequality
A fundamental inequality used in elasticity to obtain coercivity and then apply the
Lax Milgram theorem or some other theorem is Korn’s inequality. The proof given
here of this fundamental result follows [41] and [19].
43.1
A Fundamental Inequality
The proof of Korn’s inequality depends on a fundamental inequality involving neg-
ative Sobolev space norms. The theorem to be proved is the following.
Theorem 43.1 Let f ∈L2 (Ω) where Ωis a bounded Lipschitz domain. Then there
exist constants, C1 and C2 such that
C1 ||f||0,2,Ω≤
Ã
||f||−1,2,Ω+
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Ω
!
≤C2 ||f||0,2,Ω,
where here ||·||0,2,Ωrepresents the L2 norm and ||·||−1,2,Ωrepresents the norm in
the dual space of H1
0 (Ω) , denoted by H−1 (Ω) .
Similar conventions will apply for any domain in place of Ω. The proof of this
theorem will proceed through the use of several lemmas.
Lemma 43.2 Let U −denote the set,
{(x,xn) ∈Rn : xn < g (x)}
where g : Rn−1 →R is Lipschitz and denote by U + the set
{(x,xn) ∈Rn : xn > g (x)} .
Let f ∈L2 (U −) and extend f to all of Rn in the following way.
f (x,xn) ≡−3f (x,2g (x) −xn) + 4f (x, 3g (x) −2xn) .
1211

1212
KORN’S INEQUALITY
Then there is a constant, Cg, depending on g such that
||f||−1,2,Rn +
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Rn
≤Cg
Ã
||f||−1,2,U −+
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,U−
!
.
Proof: Let φ ∈C∞
c (Rn) . Then,
Z
Rn f ∂φ
∂xn
dx =
Z
U +
∂φ
∂xn
[−3f (x,2g (x) −xn) + 4f (x, 3g (x) −2xn)] dx
+
Z
U −f ∂φ
∂xn
dx.
(43.1)
Consider the ﬁrst integral on the right in 43.1.
Changing the variables, letting
yn = 2g (x) −xn in the ﬁrst term of the integrand and 3g (x) −2xn in the next, it
equals
−3
Z
U −
∂φ
∂xn
(x,2g (x) −yn) f (x,yn) dyndx
+2
Z
U −
∂φ
∂xn
µ
x,3
2g (x) −yn
2
¶
f (x,yn) dyndx.
For (x,yn) ∈U −, and deﬁning
ψ (x,yn) ≡φ (x,yn) + 3φ (x,2g (x) −yn) −4φ
µ
x,3
2g (x) −yn
2
¶
,
it follows ψ = 0 when yn = g (x) and so
Z
Rn f ∂φ
∂xn
dx =
Z
U −
∂ψ
∂yn
f (x,yn) dxdyn.
Now from the deﬁnition of ψ given above,
||ψ||1,2,U −≤Cg ||φ||1,2,U −≤Cg ||φ||1,2,Rn
and so
¯¯¯¯
¯¯¯¯
∂f
∂xn
¯¯¯¯
¯¯¯¯
−1,2,Rn ≡
sup
½Z
Rn f ∂φ
∂xn
dx : φ ∈C∞
c (Rn) , ||φ||1,2,Rn ≤1
¾
≤
sup
½¯¯¯¯
Z
U −f ∂ψ
∂xn
dxdyn
¯¯¯¯ : ψ ∈H1
0
¡
U −¢
, ||ψ||1,2,U −≤Cg
¾
= Cg
¯¯¯¯
¯¯¯¯
∂f
∂xn
¯¯¯¯
¯¯¯¯
−1,2,U −
(43.2)

43.1.
A FUNDAMENTAL INEQUALITY
1213
It remains to establish a similar inequality for the case where the derivatives are
taken with respect to xi for i < n. Let φ ∈C∞
c (Rn) . Then
Z
Rn f ∂φ
∂xi
dx =
Z
U −f ∂φ
∂xi
dx
Z
U +
∂φ
∂xi
[−3f (x,g (x) −xn) + 4f (x, 3g (x) −2xn)] dx.
Changing the variables as before, this last integral equals
−3
Z
U −Diφ (x,2g (x) −yn) f (x,yn) dyndx
+ 2
Z
U −Diφ
µ
x,3
2g (x) −yn
2
¶
f (x,yn) dyndx.
(43.3)
Now let
ψ1 (x,yn) ≡φ (x,2g (x) −yn) , ψ2 (x,yn) ≡φ
µ
x,3
2g (x) −yn
2
¶
.
Then
∂ψ1
∂xi
= Diφ (x,2g (x) −yn) + Dnφ (x,2g (x) −yn) 2Dig (x) ,
∂ψ2
∂xi
= Diφ
µ
x,3
2g (x) −yn
2
¶
+ Dnφ
µ
x,3
2g (x) −yn
2
¶ 3
2Dig (x) .
Also
∂ψ1
∂yn
(x,yn) = −Dnφ (x,2g (x) −yn) ,
∂ψ2
∂yn
(x,yn) =
µ−1
2
¶
Dnφ
µ
x,3
2g (x) −yn
2
¶
.
Therefore,
∂ψ1
∂xi
(x,yn) = Diφ (x,2g (x) −yn) −2∂ψ1
∂yn
(x,yn) Dig (x) ,
∂ψ2
∂xi
(x,yn) = Diφ
µ
x,3
2g (x) −yn
2
¶
−3∂ψ2
∂yn
(x,yn) Dig (x) .
Using this in 43.3, the integrals in this expression equal
−3
Z
U −
·∂ψ1
∂xi
(x,yn) + 2∂ψ1
∂yn
(x,yn) Dig (x)
¸
f (x,yn) dyndx+
2
Z
U −
·∂ψ2
∂xi
(x,yn) + 3∂ψ2
∂yn
(x,yn) Dig (x)
¸
f (x,yn) dyndx

1214
KORN’S INEQUALITY
=
Z
U −
·
−3∂ψ1 (x,y)
∂xi
+ 2∂ψ2 (x,yn)
∂xi
¸
f (x,yn) dyndx.
Therefore,
Z
Rn
∂φ
∂xi
fdx =
Z
U −
· ∂φ
∂xi
−3∂ψ1
∂xi
+ 2∂ψ2
∂xi
¸
fdxdyn
and also
φ (x,g (x)) −3ψ1 (x,g (x)) + 2ψ2 (x,g (x)) =
φ (x,g (x)) −3φ (x,g (x)) + 2φ (x,g (x)) = 0
and so φ−3ψ1 +2ψ2 ∈H1
0 (U −) . It also follows from the deﬁnition of the functions,
ψi and the assumption that g is Lipschitz, that
||ψi||1,2,U −≤Cg ||φ||1,2,U −≤Cg ||φ||1,2,Rn .
(43.4)
Therefore,
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Rn
≡sup
½¯¯¯¯
Z
Rn f ∂φ
∂xi
dx
¯¯¯¯ : ||φ||1,2,Rn ≤1
¾
= sup
½¯¯¯¯
Z
U −f
· ∂φ
∂xi
−3∂ψ1
∂xi
+ 2∂ψ2
∂xi
¸
dx
¯¯¯¯ : ||φ||1,2,Rn ≤1
¾
≤Cg
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,U −
where Cg is a constant which depends on g. This inequality along with 43.2 yields
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Rn
≤Cg
Ã
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,U −
!
.
The inequality,
||f||−1,2,Rn ≤Cg ||f||−1,2,U −
follows from 43.4 and the equation,
Z
Rn fφdx =
Z
U −fφdx −3
Z
U −f (x,yn) ψ1 (x,yn) dxdyn
+2
Z
U −f (x,yn) ψ2 (x,yn) dxdyn
which results in the same way as before by changing variables using the deﬁnition
of f oﬀU −. This proves the lemma.
The next lemma is a simple application of Fourier transforms.
Lemma 43.3 If f ∈L2 (Rn) , then the following formula holds.
Cn ||f||0,2,Rn =
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Rn
+ ||f||−1,2,Rn

43.1.
A FUNDAMENTAL INEQUALITY
1215
Proof: For φ ∈C∞
c (Rn)
||φ||1,2,Rn ≡
µZ
Rn
³
1 + |t|2´
|Fφ|2 dt
¶1/2
is an equivalent norm to the usual Sobolev space norm for H1
0 (Rn) and is used in
the following argument which depends on Plancherel’s theorem and the fact that
F
³
∂φ
∂xi
´
= tiF (φ) .
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Rn
≡sup
½¯¯¯¯
Z
Rn
∂φ
∂xi
fdx
¯¯¯¯ : ||φ||1,2 ≤1
¾
= Cn sup
½¯¯¯¯
Z
Rn ti (Fφ) (Ff)dt
¯¯¯¯ : ||φ||1,2 ≤1
¾
= Cn sup





¯¯¯¯¯¯¯
Z
Rn
ti (Fφ)
³
1 + |t|2´1/2
³
1 + |t|2´1/2
(Ff)dt
¯¯¯¯¯¯¯
: ||φ||1,2 ≤1





= Cn


Z
|Ff|2 t2
i
³
1 + |t|2´dt


1/2
(43.5)
Also,
||f||−1,2 ≡sup
½¯¯¯¯
Z
Rn φfdx
¯¯¯¯ : ||φ||1,2 ≤1
¾
= Cn sup
½¯¯¯¯
Z
Rn (Fφ)
¡
Ff
¢
dx
¯¯¯¯ : ||φ||1,2 ≤1
¾
= Cn sup





¯¯¯¯¯¯¯
Z
Rn
Fφ
³
1 + |t|2´1/2
³
1 + |t|2´1/2
(Ff)dt
¯¯¯¯¯¯¯
: ||φ||1,2 ≤1





= Cn


Z
Rn
|Ff|2
³
1 + |t|2´dt


1/2
This along with 43.5 yields the conclusion of the lemma because
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
2
−1,2
+ ||f||2
−1,2 = Cn
Z
Rn |Ff|2 dx = Cn ||f||2
0,2 .
Now consider Theorem 43.1. First note that by Lemma 43.2 and U −deﬁned
there, Lemma 43.3 implies that for f extended as in Lemma 43.2,
||f||0,2,U −≤||f||0,2,Rn = Cn
Ã
||f||−1,2,Rn +
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Rn
!

1216
KORN’S INEQUALITY
≤Cgn
Ã
||f||−1,2,U −+
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,U −
!
.
(43.6)
Let Ωbe a bounded open set having Lipschitz boundary which lies locally on
one side of
its boundary. Let {Qi}p
i=0 be cubes of the sort used in the proof of
the divergence theorem such that Q0 ⊆Ωand the other cubes cover the boundary
of Ω. Let {ψi} be a C∞partition of unity with spt (ψi) ⊆Qi and let f ∈L2 (Ω) .
Then for φ ∈C∞
c (Ω) and ψ one of these functions in the partition of unity,
¯¯¯¯
¯¯¯¯
∂(fψ)
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Ω
≤
sup
||φ||1,2≤1
¯¯¯¯
Z
Ω
f ∂
∂xi
(ψφ) dx
¯¯¯¯ +
sup
||φ||1,2≤1
¯¯¯¯
Z
Ω
fφ ∂ψ
∂xi
dx
¯¯¯¯
Now if ||φ||1,2 ≤1, then for a suitable constant, Cψ,
||ψφ||1,2 ≤Cψ ||φ||1,2 ≤Cψ,
¯¯¯¯
¯¯¯¯φ ∂ψ
∂xi
¯¯¯¯
¯¯¯¯
1,2
≤Cψ.
Therefore,
¯¯¯¯
¯¯¯¯
∂(fψ)
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Ω
≤
sup
||η||1,2≤Cψ
¯¯¯¯
Z
Ω
f ∂η
∂xi
dx
¯¯¯¯ +
sup
||η||1,2≤Cψ
¯¯¯¯
Z
Ω
fηdx
¯¯¯¯
≤Cψ
Ã¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Ω
+ ||f||−1,2,Ω
!
.
(43.7)
Now using 43.7 and 43.6
¯¯¯¯fψj
¯¯¯¯
0,2,Ω≤Cg

¯¯¯¯fψj
¯¯¯¯
−1,2,Ω+
n
X
i=1
¯¯¯¯¯
¯¯¯¯¯
∂
¡
fψj
¢
∂xi
¯¯¯¯¯
¯¯¯¯¯
−1,2,Ω


≤CψjCg
Ã
||f||−1,2,Ω+
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Ω
!
.
Therefore, letting C = Pp
j=1 CψjCg,
||f||0,2,Ω≤
p
X
j=1
¯¯¯¯fψj
¯¯¯¯
0,2,Ω≤C
Ã
||f||−1,2,Ω+
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Ω
!
.
(43.8)
This proves the hard half of the inequality of Theorem 43.1.
To complete the proof, let f denote the zero extension of f oﬀΩ. Then
||f||−1,2,Ω+
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Ω
≤
¯¯¯¯f
¯¯¯¯
−1,2,Rn +
n
X
i=1
¯¯¯¯
¯¯¯¯
∂f
∂xi
¯¯¯¯
¯¯¯¯
−1,2,Rn
≤Cn
¯¯¯¯f
¯¯¯¯
0,2,Rn = Cn ||f||0,2,Ω.
This along with 43.8 proves Theorem 43.1.

43.2.
KORN’S INEQUALITY
1217
43.2
Korn’s Inequality
The inequality in this section is known as Korn’s second inequality. It is also known
as coercivity of strains. For u a vector valued function in Rn, deﬁne
εij (u) ≡1
2 (ui,j + uj,i)
This is known as the strain or small strain. Korn’s inequality says that the norm
given by,
|||u||| ≡


n
X
i=1
||ui||2
0,2,Ω+
n
X
i=1
n
X
j=1
||εij (u)||2
0,2,Ω


1/2
(43.9)
is equivalent to the norm,
||u|| ≡


n
X
i=1
||ui||2
0,2,Ω+
n
X
i=1
n
X
j=1
¯¯¯¯
¯¯¯¯
∂ui
∂xj
¯¯¯¯
¯¯¯¯
2
0,2,Ω


1/2
(43.10)
It is very signiﬁcant because it is the strain as just deﬁned which occurs in many of
the physical models proposed in continuum mechanics. The inequality is far from
obvious because the strains only involve certain combinations of partial derivatives.
Theorem 43.4 (Korn’s second inequality) Let Ωbe any domain for which the con-
clusion of Theorem 43.1 holds. Then the two norms in 43.9 and 43.10 are equivalent.
Proof: Let u be such that ui ∈H1 (Ω) for each i = 1, · · ·, n. Note that
∂2ui
∂xj, ∂xk
=
∂
∂xj
(εik (u)) +
∂
∂xk
(εij (u)) −∂
∂xi
(εjk (u)) .
Therefore, by Theorem 43.1,
¯¯¯¯
¯¯¯¯
∂ui
∂xj
¯¯¯¯
¯¯¯¯
0,2,Ω
≤C
"¯¯¯¯
¯¯¯¯
∂ui
∂xj
¯¯¯¯
¯¯¯¯
−1,2,Ω
+
n
X
k=1
¯¯¯¯
¯¯¯¯
∂2ui
∂xj, ∂xk
¯¯¯¯
¯¯¯¯
−1,2,Ω
#
≤C
"¯¯¯¯
¯¯¯¯
∂ui
∂xj
¯¯¯¯
¯¯¯¯
−1,2,Ω
+
X
r,s,p
¯¯¯¯
¯¯¯¯
∂εrs (u)
∂xp
¯¯¯¯
¯¯¯¯
−1,2,Ω
#
≤C
"¯¯¯¯
¯¯¯¯
∂ui
∂xj
¯¯¯¯
¯¯¯¯
−1,2,Ω
+
X
r,s
||εrs (u)||0,2,Ω
#
.
But also by this theorem,
||ui||−1,2,Ω+
X
p
¯¯¯¯
¯¯¯¯
∂ui
∂xp
¯¯¯¯
¯¯¯¯
−1,2,Ω
≤C ||ui||0,2,Ω

1218
KORN’S INEQUALITY
and so
¯¯¯¯
¯¯¯¯
∂ui
∂xj
¯¯¯¯
¯¯¯¯
0,2,Ω
≤C
"
||ui||0,2,Ω+
X
r,s
||εrs (u)||0,2,Ω
#
This proves the theorem.
Note that Ωdid not need to be bounded. It suﬃces to be able to conclude
the result of Theorem 43.1 which would hold whenever the boundary of Ωcan be
covered with ﬁnitely many boxes of the sort to which Lemma 43.2 can be applied.

Elliptic Regularity And
Nirenberg Diﬀerences
44.1
The Case Of A Half Space
Regularity theorems are concerned with obtaining more regularity given a weak
solution. This extra regularity is essential in order to obtain error estimates for
various problems. In this section a regularity is given for weak solutions to various
elliptic boundary value problems. To save on notation, I will use the repeated index
summation convention. Thus you sum over repeated indices. Consider the following
picture.
R
Rn−1
U
V
¡
¡
¡
¡
ª
Γ
U1
Here V is an open set,
U ≡{y ∈V : yn < 0} , Γ ≡{y ∈V : yn = 0}
and U1 is an open set as shown for which U1 ⊆V ∩U. Assume also that V is
bounded. Suppose
f ∈L2 (U) ,
αrs ∈C0,1 ¡
U
¢
,
(44.1)
1219

1220
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES
αrs (y) vrvs ≥δ |v|2 , δ > 0.
(44.2)
The following technical lemma gives the essential ideas.
Lemma 44.1 Suppose
w
∈
H1 (U) ,
(44.3)
αrs
∈
C0,1 ¡
U
¢
,
(44.4)
hs
∈
H1 (U) ,
(44.5)
f
∈
L2 (U) .
(44.6)
and
Z
U
αrs (y) ∂w
∂yr
∂z
∂ys dy +
Z
U
hs (y) ∂z
∂ys dy =
Z
U
fzdy
(44.7)
for all z ∈H1 (U) having the property that spt (z) ⊆V. Then w ∈H2 (U1) and for
some constant C, independent of f, w, and g, the following estimate holds.
||w||2
H2(U1) ≤C
Ã
||w||2
H1(U) + ||f||2
L2(U) +
X
s
||hs||2
H1(U)
!
.
(44.8)
Proof: Deﬁne for small real h,
Dh
kl (y) ≡1
h (l (y + hek) −l (y)) .
Let U1 ⊆U1 ⊆W ⊆W ⊆V and let η ∈C∞
c (W) with η (y) ∈[0, 1] , and η = 1 on
U1 as shown in the following picture.
R
Rn−1
U
V
¡
¡
¡
¡
ª
Γ
U1
W
For h small (3h < dist
¡
W, V C¢
), let
z (y) ≡1
h
½
η2 (y−hek)
·w (y) −w (y −hek)
h
¸

44.1.
THE CASE OF A HALF SPACE
1221
−η2 (y)
·w (y + hek) −w (y)
h
¸¾
(44.9)
≡
−D−h
k
¡
η2Dh
kw
¢
,
(44.10)
where here k < n. Thus z can be used in equation 44.7. Begin by estimating the
left side of 44.7.
Z
U
αrs (y) ∂w
∂yr
∂z
∂ys dy
=
1
h
Z
U
αrs (y + hek) ∂w
∂yr (y + hek) ∂
¡
η2Dh
kw
¢
∂ys
dy
−1
h
Z
U
αrs (y) ∂w
∂yr
∂
¡
η2Dh
kw
¢
∂ys
dy
=
Z
U
αrs (y + hek) ∂
¡
Dh
kw
¢
∂yr
∂
¡
η2Dh
kw
¢
∂ys
dy+
1
h
Z
U
(αrs (y + hek) −αrs (y)) ∂w
∂yr
∂
¡
η2Dh
kw
¢
∂ys
dy
(44.11)
Now
∂
¡
η2Dh
kw
¢
∂ys
= 2η ∂η
∂ys Dh
kw + η2 ∂
¡
Dh
kw
¢
∂ys
.
(44.12)
therefore,
=
Z
U
η2αrs (y + hek) ∂
¡
Dh
kw
¢
∂yr
∂
¡
Dh
kw
¢
∂ys
dy
+
(Z
W ∩U
αrs (y + hek) ∂
¡
Dh
kw
¢
∂yr
2η ∂η
∂ys Dh
kwdy
+ 1
h
Z
W ∩U
(αrs (y + hek) −αrs (y)) ∂w
∂yr
∂
¡
η2Dh
kw
¢
∂ys
dy
)
≡A. + {B.} .
(44.13)
Now consider these two terms. From 44.2,
A. ≥δ
Z
U
η2 ¯¯∇Dh
kw
¯¯2 dy.
(44.14)
Using the Lipschitz continuity of αrs and 44.12,
B. ≤C (η, Lip (α) , α)
n¯¯¯¯Dh
kw
¯¯¯¯
L2(W ∩U)
¯¯¯¯η∇Dh
kw
¯¯¯¯
L2(W ∩U;Rn) +
||η∇w||L2(W ∩U;Rn)
¯¯¯¯η∇Dh
kw
¯¯¯¯
L2(W ∩U;Rn)
+ ||η∇w||L2(W ∩U;Rn)
¯¯¯¯Dh
kw
¯¯¯¯
L2(W ∩U)
o
.
(44.15)

1222
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES
≤C (η, Lip (α) , α) Cε
³¯¯¯¯Dh
kw
¯¯¯¯2
L2(W ∩U) + ||η∇w||2
L2(W ∩U;Rn)
´
+
εC (η, Lip (α) , α)
³¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(W ∩U;Rn) +
¯¯¯¯Dh
kw
¯¯¯¯2
L2(W ∩U)
´
.
(44.16)
Now
¯¯¯¯Dh
kw
¯¯¯¯
L2(W ) ≤||∇w||2
L2(U;Rn) .
(44.17)
To see this, observe that if w is smooth, then
ÃZ
W
¯¯¯¯
w (y + hek) −w (y)
h
¯¯¯¯
2
dy
!1/2
≤


Z
W
¯¯¯¯¯
1
h
Z h
0
∇w (y + tek) · ekdt
¯¯¯¯¯
2
dy


1/2
≤
ÃZ h
0
µZ
W
|∇w (y + tek) · ek|2 dy
¶1/2 dt
h
!
≤||∇w||L2(U;Rn)
so by density of such functions in H1 (U) , 44.17 holds. Therefore, changing ε, yields
B. ≤Cε (η, Lip (α) , α) ||∇w||2
L2(U;Rn) + ε
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(W ∩U;Rn) .
(44.18)
With 44.14 and 44.18 established, consider the other terms of 44.7.
¯¯¯¯
Z
U
fzdy
¯¯¯¯
≤
¯¯¯¯
Z
U
f
¡
−D−h
k η2Dh
kw
¢
dy
¯¯¯¯
≤
µZ
U
|f|2 dy
¶1/2 µZ
U
¯¯D−h
k
¡
η2Dh
kw
¢¯¯2 dy
¶1/2
≤
||f||L2(U)
¯¯¯¯∇
¡
η2Dh
kw
¢¯¯¯¯
L2(U;Rn)
≤
||f||L2(U)
³¯¯¯¯2η∇ηDh
kw
¯¯¯¯
L2(U;Rn) +
¯¯¯¯η2∇Dh
kw
¯¯¯¯
L2(U;Rn)
´
≤
C ||f||L2(U) ||∇w||L2(U;Rn) + ||f||L2(U)
¯¯¯¯η∇Dh
kw
¯¯¯¯
L2(U;Rn)
≤
Cε
³
||f||2
L2(U) + ||∇w||2
L2(U;Rn)
´
+ ε
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(U;Rn)(44.19)

44.1.
THE CASE OF A HALF SPACE
1223
¯¯¯¯
Z
U
hs (y) ∂z
∂ys dy
¯¯¯¯
≤
¯¯¯¯¯
Z
U
hs (y) ∂
¡
−D−h
k
¡
η2Dh
kw
¢¢
∂ys
dy
¯¯¯¯¯
≤
¯¯¯¯¯
Z
U
Dh
khs (y) ∂
¡¡
η2Dh
kw
¢¢
∂ys
¯¯¯¯¯
≤
Z
U
¯¯¯¯Dh
khs2η ∂η
∂ys Dh
kw
¯¯¯¯ dy +
Z
U
¯¯¯¯¯
¡
ηDh
khs
¢
Ã
η ∂
¡
Dh
kw
¢
∂ys
!¯¯¯¯¯ dy
≤
C
X
s
||hs||H1(U)
³
||w||H1(U) +
¯¯¯¯η∇Dh
kw
¯¯¯¯
L2(U;Rn)
´
≤
Cε
X
s
||hs||2
H1(U) + ||w||2
H1(U) + ε
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(U;Rn) .
(44.20)
The following inequalities in 44.14,44.18, 44.19and 44.20 are summarized here.
A. ≥δ
Z
U
η2 ¯¯∇Dh
kw
¯¯2 dy,
B. ≤Cε (η, Lip (α) , α) ||∇w||2
L2(U;Rn) + ε
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(W ∩U;Rn) ,
¯¯¯¯
Z
U
fzdy
¯¯¯¯ ≤Cε
³
||f||2
L2(U) + ||∇w||2
L2(U;Rn)
´
+ ε
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(U;Rn)
¯¯¯¯
Z
U
hs (y) ∂z
∂ys dy
¯¯¯¯
≤
Cε
X
s
||hs||2
H1(U)
+ ||w||2
H1(U) + ε
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(U;Rn) .
Therefore,
δ
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(U;Rn)
≤
Cε (η, Lip (α) , α) ||∇w||2
L2(U;Rn) + ε
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(U;Rn)
+Cε
X
s
||hs||2
H1(U) + ||w||2
H1(U) + ε
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(U;Rn)
+Cε
³
||f||2
L2(U) + ||∇w||2
L2(U;Rn)
´
+ ε
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(U;Rn) .
Letting ε be small enough and adjusting constants yields
¯¯¯¯∇Dh
kw
¯¯¯¯2
L2(U1;Rn) ≤
¯¯¯¯η∇Dh
kw
¯¯¯¯2
L2(U;Rn) ≤

1224
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES
C
Ã
||w||2
H1(U) + ||f||2
L2(U) + Cε
X
s
||hs||2
H1(U)
!
where the constant, C, depends on η, Lip (α) , α, δ. Since this holds for all h small
enough, it follows
∂w
∂yk ∈H1 (U1) and
¯¯¯¯
¯¯¯¯∇∂w
∂yk
¯¯¯¯
¯¯¯¯
2
L2(U1;Rn)
≤
C
Ã
||w||2
H1(U) + ||f||2
L2(U) + Cε
X
s
||hs||2
H1(U)
!
(44.21)
for each k < n. It remains to estimate
¯¯¯
¯¯¯ ∂2w
∂y2n
¯¯¯
¯¯¯
2
L2(U1) . To do this return to 44.7
which must hold for all z ∈C∞
c (U1) . Therefore, using 44.7 it follows that for all
z ∈C∞
c (U1) ,
Z
U
αrs (y) ∂w
∂yr
∂z
∂ys dy = −
Z
U
∂hs
∂ys zdy +
Z
U
fzdy.
Now from the Lipschitz assumption on αrs, it follows
F
≡
X
r,s≤n−1
∂
∂ys
µ
αrs ∂w
∂yr
¶
+
X
s≤n−1
∂
∂ys
µ
αns ∂w
∂yn
¶
−
X
s
∂hs
∂ys + f
∈
L2 (U1)
and
||F||L2(U1) ≤C
Ã
||w||2
H1(U) + ||f||2
L2(U) + Cε
X
s
||hs||2
H1(U)
!
.
(44.22)
Therefore, from density of C∞
c (U1) in L2 (U1) ,
−∂
∂yn
µ
αnn (y) ∂w
∂yn
¶
= F, no sum on n
and so
−∂αnn
∂yn
∂w
∂yn −αnn
∂2w
∂(yn)2 = F
By 44.2 αnn (y) ≥δ and so it follows from 44.22 that there exists a constant,C
depending on δ such that
¯¯¯¯¯
∂2w
∂(yn)2
¯¯¯¯¯
L2(U1)
≤C
³
|F|L2(U1) + ||w||H1(U)
´

44.1.
THE CASE OF A HALF SPACE
1225
which with 44.21 and 44.22 implies the existence of a constant, C depending on δ
such that
||w||2
H2(U1) ≤C
Ã
||w||2
H1(U) + ||f||2
L2(U) + Cε
X
s
||hs||2
H1(U)
!
,
proving the lemma.
What if more regularity is known for f , hs, αrs and w? Could more be said
about the regularity of the solution? The answer is yes and is the content of the
next corollary.
First here is some notation.
For α a multi-index with |α| = k −1, α =
(α1, · · ·, αn) deﬁne
Dh
αl (y) ≡
n
Y
k=1
¡
Dh
k
¢αk l (y) .
Also, for α and τ multi indices, τ < α means τ i < αi for each i.
Corollary 44.2 Suppose in the context of Lemma 44.1 the following for k ≥1.
w
∈
Hk (U) ,
αrs
∈
Ck−1,1 ¡
U
¢
,
hs
∈
Hk (U) ,
f
∈
Hk−1 (U) ,
and
Z
U
αrs (y) ∂w
∂yr
∂z
∂ys dy +
Z
U
hs (y) ∂z
∂ys dy =
Z
U
fzdy
(44.23)
for all z ∈H1 (U) or H1
0 (U) such that spt (z) ⊆V. Then there exists C independent
of w such that
||w||Hk+1(U1) ≤C
Ã
||f||Hk−1(U) +
X
s
||hs||Hk(U) + ||w||Hk(U)
!
.
(44.24)
Proof: The proof involves the following claim which is proved using the conclu-
sion of Lemma 44.1 on Page 1220.
Claim : If α = (α′, 0) where |α′| ≤k −1, then there exists a constant indepen-
dent of w such that
||Dαw||H2(U1) ≤C
Ã
||f||Hk−1(U) +
X
s
||hs||Hk(U) + ||w||Hk(U)
!
.
(44.25)
Proof of claim: First note that if |α| = 0, then 44.25 follows from Lemma 44.1
on Page 1220. Now suppose the conclusion of the claim holds for all |α| ≤j −1
where j < k.
Let |α| = j and α = (α′, 0) . Then for z ∈H1 (U) having compact
support in V, it follows that for h small enough,
D−h
α z ∈H1 (U) , spt
¡
Dh
αz
¢
⊆V.

1226
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES
Therefore, you can replace z in 44.23 with D−h
α z. Now note that you can apply the
following manipulation.
Z
U
p (y) D−h
α z (y) dy =
Z
U
Dh
αp (y) z (y) dy
and obtain
Z
U
µ
Dh
α
µ
αrs ∂w
∂yr
¶ ∂z
∂ys + Dh
α (hs) ∂z
∂ys
¶
dy =
Z
U
¡¡
Dh
αf
¢
z
¢
dy.
(44.26)
Letting h →0, this gives
Z
U
µ
Dα
µ
αrs ∂w
∂yr
¶ ∂z
∂ys + Dα (hs) ∂z
∂ys
¶
dy =
Z
U
((Dαf) z) dy.
Now
Dα
µ
αrs ∂w
∂yr
¶
= αrs ∂(Dαw)
∂yr
+
X
τ<α
C (τ) Dα−τ (αrs) ∂(Dτw)
∂yr
where C (τ) is some coeﬃcient. Therefore, from 44.26,
Z
U
αrs ∂(Dαw)
∂yr
∂z
∂ys dy +
Z
U
ÃX
τ<α
C (τ) Dα−τ (αrs) ∂(Dτw)
∂yr
+ Dα (hs)
!
∂z
∂ys dy
=
Z
U
(Dαf) zdy.
(44.27)
Let bU1 be as indicated in the following picture
R
Rn−1
U
V
U1
bU1
Now apply the induction hypothesis to bU1 in order to write
¯¯¯¯
¯¯¯¯
∂(Dτw)
∂yr
¯¯¯¯
¯¯¯¯
H1( bU1)
≤||Dτw||H2( bU1)

44.1.
THE CASE OF A HALF SPACE
1227
≤C
Ã
||f||Hk−1(U) +
X
s
||hs||Hk(U) + ||w||Hk(U)
!
.
Since αrs ∈Ck−1,1 ¡
U
¢
, it follows that each term from the sum in 44.27 satisﬁes
an inequality of the form
¯¯¯¯
¯¯¯¯C (τ) Dα−τ (αrs) ∂(Dτw)
∂yr
¯¯¯¯
¯¯¯¯
H1( bU1)
≤
C
Ã
||f||Hk−1(U) +
X
s
||hs||Hk(U) + ||w||Hk(U)
!
and consequently,
¯¯¯¯¯
¯¯¯¯¯
X
τ<α
C (τ) Dα−τ (αrs) ∂(Dτw)
∂yr
+ Dα (hs)
¯¯¯¯¯
¯¯¯¯¯
H1( bU1)
≤
C
Ã
||f||Hk−1(U) +
X
s
||hs||Hk(U) + ||w||Hk(U)
!
.
(44.28)
Now consider 44.27. The equation remains true if you replace U with bU1 and require
that spt (z) ⊆bU1. Therefore, by Lemma 44.1 on Page 1220 there exists a constant,
C independent of w such that
||Dαw||H2(U1) ≤C
³
||Dαf||L2( bU1) + ||Dαw||H1( bU1) +
+
X
s
¯¯¯¯¯
¯¯¯¯¯
X
τ<α
C (τ) Dα−τ (αrs) ∂(Dτw)
∂yr
+ Dα (hs)
¯¯¯¯¯
¯¯¯¯¯
H1( bU1)


and by 44.28, this implies
||Dαw||H2(U1) ≤C
Ã
||f||Hk−1(U) + ||w||Hk(U) +
X
s
||hs||Hk(U)
!
which proves the Claim.
To establish 44.24 it only remains to verify that if |α| ≤k + 1, then
||Dαw||L2(U1) ≤C
Ã
||f||Hk−1(U) + ||w||Hk(U) +
X
s
||hs||Hk(U)
!
.
(44.29)
If |α| < k + 1, there is nothing to show because it is given that w ∈Hk (U) .
Therefore, assume |α| = k + 1. If αn equals 0 the conclusion follows from the claim

1228
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES
because in this case, you can subtract 1 from a pair of positive αi and obtain a new
multi index, β such that |β| = k −1 and βn = 0 and then from the claim,
||Dαw||L2(U1) ≤
¯¯¯¯Dβw
¯¯¯¯
H2(U1) ≤C
Ã
||f||Hk−1(U) + ||w||Hk(U) +
X
s
||hs||Hk(U)
!
.
If αn = 1, then subtract 1 from some positive αi and consider
β = (α1, · · ·, αi −1, αi+1, · · ·, αn−1, 0)
Then from the claim,
||Dαw||L2(U1) ≤
¯¯¯¯Dβw
¯¯¯¯
H2(U1) ≤C
Ã
||f||Hk−1(U) + ||w||Hk(U) +
X
s
||hs||Hk(U)
!
.
Suppose 44.29 holds for αn ≤j −1 where j −1 ≥1 and consider α for which
|α| = k + 1 and αn = j. Let
β ≡(α1, · · ·, αn−1, αn −2) .
Thus Dα = DβD2
n. Restricting 44.23 to z ∈C∞
c (U1) and using the density of this
set of functions in L2 (U1) , it follows that
−∂
∂ys
µ
αrs (y) ∂w
∂yr
¶
−∂hs
∂ys = f.
Therefore, from the product rule,
∂αrs
∂ys
∂w
∂yr + αrs
∂2w
∂ys∂yr + ∂hs
∂ys = −f
and so
αnnD2
nw
=
−

∂αrs
∂ys
∂w
∂yr +
X
r≤n−1
X
s≤n−1
αrs
∂2w
∂ys∂yr +
X
s
αns
∂2w
∂ys∂yn +
X
r
αrn
∂2w
∂yn∂yr + ∂hs
∂ys + f
!
.
As noted earlier, the condition, 44.2 implies αnn (y) ≥δ > 0 and so
D2
nw
=
−1
αnn

∂αrs
∂ys
∂w
∂yr +
X
r≤n−1
X
s≤n−1
αrs
∂2w
∂ys∂yr +
X
s
αns
∂2w
∂ys∂yn +
X
r
αrn
∂2w
∂yn∂yr + ∂hs
∂ys + f
!
.

44.2.
THE CASE OF BOUNDED OPEN SETS
1229
It follows from Dα = DβD2
n that
Dαw
=
Dβ

−1
αnn

∂αrs
∂ys
∂w
∂yr +
X
r≤n−1
X
s≤n−1
αrs
∂2w
∂ys∂yr +
X
s
αns
∂2w
∂ys∂yn +
X
r
αrn
∂2w
∂yn∂yr + ∂hs
∂ys + f
!#
.
Now you note that terms like Dβ ³
∂2w
∂ys∂yn
´
have αn = j −1 and so, from the
induction hypothesis along with the assumptions on the given functions,
||Dαw||L2(U1) ≤C
Ã
||f||Hk−1(U) + ||w||Hk(U) +
X
s
||hs||Hk(U)
!
.
This proves the corollary.
44.2
The Case Of Bounded Open Sets
The main interest in all this is in the application to bounded open sets. Recall the
following deﬁnition.
Deﬁnition 44.3 A bounded open subset, Ω, of Rn has a Cm,1boundary if it satis-
ﬁes the following conditions. For each p ∈Γ ≡Ω\ Ω, there exists an open set, W,
containing p, an open interval (0, b), a bounded open box U ′ ⊆Rn−1, and an aﬃne
orthogonal transformation, RW consisting of a distance preserving linear transfor-
mation followed by a translation such that
RW W = U ′ × (0, b),
(44.30)
RW (W ∩Ω) = {u ∈Rn : u′ ∈U ′, 0 < un < φW (u′)}
(44.31)
where φW ∈Cm,1 ¡
U ′¢
meaning φW is the restriction to U ′ of a function, still
denoted by φW which is in Cm,1 ¡
Rn−1¢
and
inf {φW (u′) : u′ ∈U ′} > 0
The following picture depicts the situation.




ZZZZZ
ZZZZZ




-
RW
W
ΩT W
RW (ΩT W)
0
b
u′ ∈U ′

1230
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES
For the situation described in the above deﬁnition, let hW : U ′ →Γ ∩W be
deﬁned by
hW (u′) ≡R−1
W (u′, φW (u′)) , gW (x) ≡(RW x)′ , HW (u) ≡R−1
W (u′, φW (u′) −un) .
where x′ ≡(x1, · · ·, xn−1) for x = (x1, · · ·, xn). Thus gW ◦hW = id on U ′ and
hW ◦gW = id on Γ∩W. Also note that HW is deﬁned on all of Rn is Cm,1, and has
an inverse with the same properties. To see this, let GW (u) = (u′, φW (u′) −un) .
Then HW = R−1
W ◦GW and G−1
W = (u′, φW (u′) −un) and so H−1
W = G−1
W ◦RW .
Note also that as indicated in the picture,
RW (W ∩Ω) = {u ∈Rn : u′ ∈U ′ and 0 < un < φW (u′)} .
Since Γ = ∂Ωis compact, there exist ﬁnitely many of these open sets, W, denoted
by {Wi}q
i=1 such that Γ ⊆∪q
i=1Wi. Let the corresponding sets, U ′ be denoted by U ′
i
and let the functions, φ be denoted by φi. Also let hi = hWi, GWi = Gi etc. Now
let
Φi : GiRi (Ω∩W) ≡Vi →Ω∩Wi
be deﬁned by
Φi (y) ≡R−1
i
◦G−1
i
(y) .
Thus Φi, Φ−1
i
∈Cm,1 (Rn). The following picture might be helpful.




ZZZZZ
ZZZZZ




@
@
@
@
@
R
Ri
Wi
ΩT Wi
spt(ψi)




Ri(ΩT Wi)
¡
¡
ª
0
b
u′ ∈U ′
¢
¢
¢
¢
¢
¢
¢
Gi
0
Rn−1
y
Φ−1
i (spt(ψi))




+
Vi
Φ−1
i (ΩT Wi)
@
@
@
R
Ui

44.2.
THE CASE OF BOUNDED OPEN SETS
1231
Therefore, by Lemma 41.20 on Page 1185, it follows that for t ∈[m, m + 1),
Φ∗
i ∈L
¡
Ht (Wi ∩Ω) , Ht (Vi)
¢
.
Assume
aij (x) vivj ≥δ |v|2 .
(44.32)
Lemma 44.4 Let W be one of the sets described in the above deﬁnition and let
m ≥1. Let W1 ⊆W1 ⊆W where W1 is an open set. Suppose also that
u
∈
H1 (Ω) ,
αrs
∈
C0,1 ¡
Ω
¢
,
f
∈
L2 (Ω) ,
hk
∈
H1 (Ω) ,
and that for all v ∈H1 (Ω∩W) such that spt (v) ⊆Ω∩W,
Z
Ω
aij (x) u,i (x) v,j (x) dx +
Z
Ω
hk (x) v,k (x) dx =
Z
Ω
f (x) v (x) dx.
(44.33)
Then there exists a constant, C, independent of f, u, and g such that
||u||2
H2(Ω∩W1) ≤C
Ã
||f||2
L2(Ω) + ||u||2
H1(Ω) +
X
k
||hk||2
H1(Ω)
!
.
(44.34)
Proof: Let
E ≡
©
v ∈H1 (Ω∩W) : spt (v) ⊆W
ª
u restricted to W ∩Ωis in H1 (Ω∩W) and
Z
Ω∩W
aij (x) u,iv,jdx +
Z
Ω
hk (x) v,k (x) dx =
Z
Ω
f (x) v (x) dx for all v ∈E.
(44.35)
Now let Φi (y) = x. For this particular W, denote Φi more simply by Φ, Ui ≡
Φi (Ω∩Wi) by U, and Vi by V. Denoting the coordinates of V by y, and letting
u (x) ≡w (y) and v (x) ≡z (y) , it follows that in terms of the new coordinates,
44.35 takes the form
Z
U
aij (Φ (y)) ∂w
∂yr
∂yr
∂xi
∂z
∂ys
∂ys
∂xj |det DΦ (y)| dy
+
Z
U
hk (Φ (y)) ∂z
∂yl
∂yl
∂xk |det DΦ (y)| dx
=
Z
U
f (Φ (y)) z (y) |det DΦ (y)| dy
Let
αrs (y) ≡aij (Φ (y)) ∂yr
∂xi
∂ys
∂xj |det DΦ (y)| ,
(44.36)

1232
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES
ehl (y) ≡hk (Φ (y)) ∂yl
∂xk |det DΦ (y)| ,
(44.37)
and
ef (y) ≡Φ∗f |det DΦ| (y) ≡f (Φ (y)) |det DΦ (y)| .
(44.38)
Now the function on the right in 44.36 is in C0,1 ¡
U
¢
. This is because of the
assumption that m ≥1 in the statement of the lemma. This function is therefore a
ﬁnite product of bounded functions in C0,1 ¡
U
¢
.
The function ehl deﬁned in 44.37 is in H1 (U) and
¯¯¯
¯¯¯ ehl
¯¯¯
¯¯¯
H1(U) ≤C
X
k
||hk||H1(Ω∩W )
again because m ≥1.
Finally, the right side of 44.38 is a function in L2 (U) by Lemma 41.20 on Page
1185 and the observation that |det DΦ (·)| ∈C0,1 ¡
U
¢
which follows from the as-
sumption of the lemma that m ≥1 so Φ ∈C1,1 (Rn). Also
¯¯¯
¯¯¯ ef
¯¯¯
¯¯¯
L2(U) ≤C ||f||L2(Ω∩W ) .
Therefore, 44.35 is of the form
Z
U
αrs (y) w,rz,sdy +
Z
U
ehlz,ldy =
Z
U
efzdy,
(44.39)
for all z in H1 (U) having support in V.
Claim: There exists r > 0 independent of y ∈U such that for all y ∈U,
αrs (y) vrvs ≥r |v|2 .
Proof of the claim: If this is not so, there exist vectors, vn, |vn| = 1, and
yn ∈U such that αrs (yn) vn
r vn
s ≤1
n. Taking a subsequence, there exists y ∈U and
|v| = 1 such that αrs (y) vrvs = 0 contradicting 44.32.
Therefore, by Lemma 44.1, there exists a constant, C, independent of f, g, and
w such that
||w||2
H2(Φ−1(W1∩Ω)) ≤C
Ã¯¯¯
¯¯¯ ef
¯¯¯
¯¯¯
2
L2(U) + ||w||2
H1(U) +
X
l
¯¯¯
¯¯¯ ehl
¯¯¯
¯¯¯
2
H1(U)
!
.
Therefore,
||u||2
H2(W1∩Ω)
≤
C
Ã
||f||2
L2(W ∩Ω) + ||w||2
H1(W ∩Ω) +
X
k
||hk||2
H1(W ∩Ω)
!
≤
C
Ã
||f||2
L2(Ω) + ||w||2
H1(Ω) +
X
k
||hk||2
H1(Ω)
!
.
which proves the lemma.
With this lemma here is the main result.

44.2.
THE CASE OF BOUNDED OPEN SETS
1233
Theorem 44.5 Let Ωbe a bounded open set with C1,1 boundary as in Deﬁnition
44.3, let f ∈L2 (Ω) , hk ∈H1 (Ω), and suppose that for all x ∈Ω,
aij (x) vivj ≥δ |v|2 .
Suppose also that u ∈H1 (Ω) and
Z
Ω
aij (x) u,i (x) v,j (x) dx +
Z
Ω
hk (x) v,k (x) dx =
Z
Ω
f (x) v (x) dx
for all v ∈H1 (Ω) . Then u ∈H2 (Ω) and for some C independent of f, g, and u,
||u||2
H2(Ω) ≤C
Ã
||f||2
L2(Ω) + ||u||2
H1(Ω) +
X
k
||hk||2
H1(Ω)
!
.
Proof: Let the Wi for i = 1, · · ·, l be as described in Deﬁnition 44.3. Thus
∂Ω⊆∪l
j=1Wj. Then let C1 ≡∂Ω\ ∪l
i=2Wi, a closed subset of W1. Let D1 be an
open set satisfying
C1 ⊆D1 ⊆D1 ⊆W1.
Then D1, W2, ···, Wl cover ∂Ω. Let C2 = ∂Ω\
¡
D1 ∪
¡
∪l
i=3Wi
¢¢
. Then C2 is a closed
subset of W2. Choose an open set, D2 such that
C2 ⊆D2 ⊆D2 ⊆W2.
Thus D1, D2, W3 · ··, Wl covers ∂Ω. Continue in this way to get Di ⊆Wi, and
∂Ω⊆∪l
i=1Di, and Di is an open set. Now let
D0 ≡Ω\ ∪l
i=1Di.
Also, let Di ⊆Vi ⊆Vi ⊆Wi. Therefore, D0, V1, · · ·, Vl covers Ω. Then the same
estimation process used above yields
||u||H2(D0) ≤C
Ã
||f||2
L2(Ω) + ||u||2
H1(Ω) +
X
k
||hk||2
H1(Ω)
!
.
From Lemma 44.4
||u||H2(Vi∩Ω) ≤C
Ã
||f||2
L2(Ω) + ||u||2
H1(Ω) +
X
k
||hk||2
H1(Ω)
!
also. This proves the theorem since
||u||H2(Ω) ≤
l
X
i=1
||u||H2(Vi∩Ω) + ||u||H2(D0) .
What about the Dirichlet problem? The same diﬀerencing procedure as above
yields the following.

1234
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES
Theorem 44.6 Let Ωbe a bounded open set with C1,1 boundary as in Deﬁnition
44.3, let f ∈L2 (Ω) , hk ∈H1 (Ω), and suppose that for all x ∈Ω,
aij (x) vivj ≥δ |v|2 .
Suppose also that u ∈H1
0 (Ω) and
Z
Ω
aij (x) u,i (x) v,j (x) dx +
Z
Ω
hk (x) v,k (x) dx =
Z
Ω
f (x) v (x) dx
for all v ∈H1
0 (Ω) . Then u ∈H2 (Ω) and for some C independent of f, g, and u,
||u||2
H2(Ω) ≤C
Ã
||f||2
L2(Ω) + ||u||2
H1(Ω) +
X
k
||hk||2
H1(Ω)
!
.
What about higher regularity?
Lemma 44.7 Let W be one of the sets described in Deﬁnition 44.3 and let m ≥k.
Let W1 ⊆W1 ⊆W where W1 is an open set. Suppose also that
u
∈
Hk (Ω) ,
αrs
∈
Ck−1,1 ¡
Ω
¢
,
f
∈
Hk−1 (Ω) ,
hs
∈
Hk (Ω) ,
and that for all v ∈H1 (Ω∩W) such that spt (v) ⊆Ω∩W,
Z
Ω
aij (x) u,i (x) v,j (x) dx +
Z
Ω
hs (x) v,s (x) dx =
Z
Ω
f (x) v (x) dx.
(44.40)
Then there exists a constant, C, independent of f, u, and g such that
||u||2
Hk+1(Ω∩W1) ≤C
Ã
||f||2
Hk−1(Ω) + ||u||2
Hk(Ω) +
X
s
||hs||2
Hk(Ω)
!
.
(44.41)
Proof: Let
E ≡
©
v ∈Hk (Ω∩W) : spt (v) ⊆W
ª
u restricted to W ∩Ωis in Hk (Ω∩W) and
Z
Ω∩W
aij (x) u,iv,jdx +
Z
Ω
hs (x) v,s (x) dx
=
Z
Ω
f (x) v (x) dx for all v ∈E.
(44.42)
Now let Φi (y) = x. For this particular W, denote Φi more simply by Φ, Ui ≡
Φi (Ω∩Wi) by U, and Vi by V. Denoting the coordinates of V by y, and letting

44.2.
THE CASE OF BOUNDED OPEN SETS
1235
u (x) ≡w (y) and v (x) ≡z (y) , it follows that in terms of the new coordinates,
44.35 takes the form
Z
U
aij (Φ (y)) ∂w
∂yr
∂yr
∂xi
∂z
∂ys
∂ys
∂xj |det DΦ (y)| dy
+
Z
U
hk (Φ (y)) ∂z
∂yl
∂yl
∂xk |det DΦ (y)| dx
=
Z
U
f (Φ (y)) z (y) |det DΦ (y)| dy
Let
αrs (y) ≡aij (Φ (y)) ∂yr
∂xi
∂ys
∂xj |det DΦ (y)| ,
(44.43)
ehl (y) ≡hk (Φ (y)) ∂yl
∂xk |det DΦ (y)| ,
(44.44)
and
ef (y) ≡Φ∗f |det DΦ| (y) ≡f (Φ (y)) |det DΦ (y)| .
(44.45)
Now the function on the right in 44.43 is in Ck,1 ¡
U
¢
. This is because of the
assumption that m ≥k in the statement of the lemma. This function is therefore a
ﬁnite product of bounded functions in Ck,1 ¡
U
¢
.
The function ehl deﬁned in 44.44 is in Hk (U) and
¯¯¯
¯¯¯ ehl
¯¯¯
¯¯¯
Hk(U) ≤C
X
s
||hs||Hk(Ω∩W )
again because m ≥k.
Finally, the right side of 44.45 is a function in Hk−1 (U) by Lemma 41.20 on
Page 1185 and the observation that |det DΦ (·)| ∈Ck−1,1 ¡
U
¢
which follows from
the assumption of the lemma that m ≥k so Φ ∈Ck−1,1 (Rn). Also
¯¯¯
¯¯¯ ef
¯¯¯
¯¯¯
Hk−1(U) ≤C ||f||Hk−1(Ω∩W ) .
Therefore, 44.42 is of the form
Z
U
αrs (y) w,rz,sdy +
Z
U
ehlz,ldy =
Z
U
efzdy,
(44.46)
for all z in H1 (U) having support in V.
Claim: There exists r > 0 independent of y ∈U such that for all y ∈U,
αrs (y) vrvs ≥r |v|2 .
Proof of the claim: If this is not so, there exist vectors, vn, |vn| = 1, and
yn ∈U such that αrs (yn) vn
r vn
s ≤1
n. Taking a subsequence, there exists y ∈U and
|v| = 1 such that αrs (y) vrvs = 0 contradicting 44.32.

1236
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES
Therefore, by Corollary 44.2, there exists a constant, C, independent of f, g, and
w such that
||w||2
Hk+1(Φ−1(W1∩Ω)) ≤C
Ã¯¯¯
¯¯¯ ef
¯¯¯
¯¯¯
2
Hk−1(U) + ||w||2
Hk(U) +
X
l
¯¯¯
¯¯¯ ehl
¯¯¯
¯¯¯
2
Hk(U)
!
.
Therefore,
||u||2
Hk+1(W1∩Ω)
≤
C
Ã
||f||2
Hk−1(W ∩Ω) + ||w||2
Hk(W ∩Ω) +
X
s
||hs||2
Hk(W ∩Ω)
!
≤
C
Ã
||f||2
Hk−1(Ω) + ||w||2
Hk(Ω) +
X
s
||hs||2
Hk(Ω)
!
.
which proves the lemma.
Now here is a theorem which generalizes the one above in the case where more
regularity is known.
Theorem 44.8 Let Ωbe a bounded open set with Ck,1 boundary as in Deﬁnition
44.3, let f ∈Hk−1 (Ω) , hs ∈Hk (Ω), and suppose that for all x ∈Ω,
aij (x) vivj ≥δ |v|2 .
Suppose also that u ∈Hk (Ω) and
Z
Ω
aij (x) u,i (x) v,j (x) dx +
Z
Ω
hk (x) v,k (x) dx =
Z
Ω
f (x) v (x) dx
for all v ∈Hk (Ω) . Then u ∈Hk+1 (Ω) and for some C independent of f, g, and u,
||u||2
Hk+1(Ω) ≤C
Ã
||f||2
Hk−1(Ω) + ||u||2
Hk(Ω) +
X
s
||hs||2
Hk(Ω)
!
.
Proof: Let the Wi for i = 1, · · ·, l be as described in Deﬁnition 44.3. Thus
∂Ω⊆∪l
j=1Wj. Then let C1 ≡∂Ω\ ∪l
i=2Wi, a closed subset of W1. Let D1 be an
open set satisfying
C1 ⊆D1 ⊆D1 ⊆W1.
Then D1, W2, ···, Wl cover ∂Ω. Let C2 = ∂Ω\
¡
D1 ∪
¡
∪l
i=3Wi
¢¢
. Then C2 is a closed
subset of W2. Choose an open set, D2 such that
C2 ⊆D2 ⊆D2 ⊆W2.
Thus D1, D2, W3 · ··, Wl covers ∂Ω. Continue in this way to get Di ⊆Wi, and
∂Ω⊆∪l
i=1Di, and Di is an open set. Now let
D0 ≡Ω\ ∪l
i=1Di.

44.2.
THE CASE OF BOUNDED OPEN SETS
1237
Also, let Di ⊆Vi ⊆Vi ⊆Wi. Therefore, D0, V1, · · ·, Vl covers Ω. Then the same
estimation process used above yields
||u||Hk+1(D0) ≤C
Ã
||f||2
Hk−1(Ω) + ||u||2
Hk(Ω) +
X
k
||hk||2
Hk(Ω)
!
.
From Lemma 44.7
||u||Hk+1(Vi∩Ω) ≤C
Ã
||f||2
Hk−1(Ω) + ||u||2
Hk(Ω) +
X
k
||hk||2
Hk(Ω)
!
also. This proves the theorem since
||u||Hk+1(Ω) ≤
l
X
i=1
||u||Hk+1(Vi∩Ω) + ||u||Hk+1(D0) .

1238
ELLIPTIC REGULARITY AND NIRENBERG DIFFERENCES

Interpolation In Banach
Space
45.1
An Assortment Of Important Theorems
45.1.1
Weak Vector Valued Derivatives
In this section, several signiﬁcant theorems are presented. Unless indicated other-
wise, the measure will be Lebesgue measure. First here is a lemma.
Lemma 45.1 Suppose g ∈L1 ([a, b] ; X) where X is a Banach space.
Then if
R b
a g (t) φ (t) dt = 0 for all φ ∈C∞
c (a, b) , then g (t) = 0 a.e.
Proof: Let E be a measurable subset of (a, b) and let K ⊆E ⊆V ⊆(a, b)
where K is compact, V is open and m (V \ K) < ε. Let K ≺h ≺V as in the proof
of the Riesz representation theorem for positive linear functionals. Enlarging K
slightly and convolving with a molliﬁer, it can be assumed h ∈C∞
c (a, b) . Then
¯¯¯¯¯
Z b
a
XE (t) g (t) dt
¯¯¯¯¯
=
¯¯¯¯¯
Z b
a
(XE (t) −h (t)) g (t) dt
¯¯¯¯¯
≤
Z b
a
|XE (t) −h (t)| ||g (t)|| dt
≤
Z
V \K
||g (t)|| dt.
Now let Kn ⊆E ⊆Vn with m (Vn \ Kn) < 2−n. Then from the above,
¯¯¯¯¯
Z b
a
XE (t) g (t) dt
¯¯¯¯¯ ≤
Z b
a
XVn\Kn (t) ||g (t)|| dt
and the integrand of the last integral converges to 0 a.e.
as n →∞because
P
n m (Vn \ Kn) < ∞. By the dominated convergence theorem, this last integral
1239

1240
INTERPOLATION IN BANACH SPACE
converges to 0. Therefore, whenever E ⊆(a, b) ,
Z b
a
XE (t) g (t) dt = 0.
Since the endpoints have measure zero, it also follows that for any measurable E,
the above equation holds.
Now g ∈L1 ([a, b] ; X) and so it is measurable. Therefore, g ([a, b]) is separable.
Let D be a countable dense subset and let E denote the set of linear combinations of
the form P
i aidi where ai is a rational point of F and di ∈D. Thus E is countable.
Denote by Y the closure of E in X. Thus Y
is a separable closed subspace of X
which contains all the values of g.
Now let Sn ≡g−1 (B (yn, ||yn|| /2)) where E = {yn}∞
n=1 . Therefore, ∪nSn =
g−1 (X \ {0}) . This follows because if x ∈Y and x ̸= 0, then in B
³
x, ||x||
4
´
there
is a point of E, yn. Therefore, ||yn|| > 3
4 ||x|| and so ||yn||
2
> 3||x||
8
> ||x||
4
so x ∈
B (yn, ||yn|| /2) . It follows that if each Sn has measure zero, then g (t) = 0 for a.e.
t. Suppose then that for some n, the set, Sn has positive mesure. Then from what
was shown above,
||yn||
=
¯¯¯¯
¯¯¯¯
1
m (Sn)
Z
Sn
g (t) dt −yn
¯¯¯¯
¯¯¯¯ =
¯¯¯¯
¯¯¯¯
1
m (Sn)
Z
Sn
g (t) −yndt
¯¯¯¯
¯¯¯¯
≤
1
m (Sn)
Z
Sn
||g (t) −yn|| dt ≤
1
m (Sn)
Z
Sn
||yn|| /2dt = ||yn|| /2
and so yn = 0 which implies Sn = ∅, a contradiction to m (Sn) > 0. This contradic-
tion shows each Sn has measure zero and so as just explained, g (t) = 0 a.e.
Deﬁnition 45.2 For f ∈L1 (a, b; X) , deﬁne an extension, f deﬁned on
[2a −b, 2b −a] = [a −(b −a) , b + (b −a)]
as follows.
f (t) ≡



f (t) if t ∈[a, b]
f (2a −t) if t ∈[2a −b, a]
f (2b −t) if t ∈[b, 2b −a]
Deﬁnition 45.3 Also if f ∈Lp (a, b; X) and h > 0, deﬁne for t ∈[a, b] , fh (t) ≡
f (t −h) for all h < b −a. Thus the map f →fh is continuous and linear on
Lp (a, b; X) . It is continuous because
Z b
a
||fh (t)||p dt
=
Z a+h
a
||f (2a −t + h)||p dt +
Z b−h
a
||f (t)||p dt
=
Z a+h
a
||f (t)||p dt +
Z b−h
a
||f (t)||p dt ≤2 ||f||p
p .
The following lemma is on continuity of translation in Lp (a, b; X) .

45.1.
AN ASSORTMENT OF IMPORTANT THEOREMS
1241
Lemma 45.4 Let f be as deﬁned in Deﬁnition 45.2. Then for f ∈Lp (a, b; X) for
p ∈[1, ∞),
lim
δ→0
Z b
a
¯¯¯¯f (t −δ) −f (t)
¯¯¯¯p
X dt = 0.
Proof:
Regarding the measure space as (a, b) with Lebesgue measure, by
Lemma 21.42 there exists g ∈Cc (a, b; X) such that ||f −g||p < ε. Here the norm
is the norm in Lp (a, b; X) . Therefore,
||fh −f||p
≤
||fh −gh||p + ||gh −g||p + ||g −f||p
≤
³
21/p + 1
´
||f −g||p + ||gh −g||p
<
³
21/p + 1
´
ε + ε
whenever h is suﬃciently small. This is because of the uniform continuity of g.
Therefore, since ε > 0 is arbitrary, this proves the lemma.
Deﬁnition 45.5 Let f ∈L1 (a, b; X) . Then the distributional derivative in the
sense of X valued distributions is given by
f ′ (φ) ≡−
Z b
a
f (t) φ′ (t) dt
Then f ′ ∈L1 (a, b; X) if there exists h ∈L1 (a, b; X) such that for all φ ∈C∞
c (a, b) ,
f ′ (φ) =
Z b
a
h (t) φ (t) dt.
Then f ′ is deﬁned to equal h. Here f and f ′ are considered as vector valued distri-
butions in the same way as was done for scalar valued functions.
Lemma 45.6 The above deﬁnition is well deﬁned.
Proof: Suppose both h and g work in the deﬁnition. Then for all φ ∈C∞
c (a, b) ,
Z b
a
(h (t) −g (t)) φ (t) dt = 0.
Therefore, by Lemma 45.1, h (t) −g (t) = 0 a.e.
The other thing to notice about this is the following lemma. It follows immedi-
ately from the deﬁnition.
Lemma 45.7 Suppose f, f ′ ∈L1 (a, b; X) . Then if [c, d] ⊆[a, b], it follows that
¡
f|[c,d]
¢′ = f ′|[c,d]. This notation means the restriction to [c, d] .

1242
INTERPOLATION IN BANACH SPACE
Recall that in the case of scalar valued functions, if you had both f and its
weak derivative, f ′ in L1 (a, b) , then you were able to conclude that f is almost
everywhere equal to a continuous function, still denoted by f and
f (t) = f (a) +
Z t
a
f ′ (s) ds.
In particular, you can deﬁne f (a) to be the initial value of this continuous function.
It turns out that an identical theorem holds in this case.
To begin with here
is the same sort of lemma which was used earlier for the case of scalar valued
functions. It says that if f ′ = 0 where the derivative is taken in the sense of X
valued distributions, then f equals a constant.
Lemma 45.8 Suppose f ∈L1 (a, b; X) and for all φ ∈C∞
c (a, b) ,
Z b
a
f (t) φ′ (t) dt = 0.
Then there exists a constant, a ∈X such that f (t) = a a.e.
Proof: Let φ0 ∈C∞
c (a, b) ,
R b
a φ0 (x) dx = 1 and deﬁne for φ ∈C∞
c (a, b)
ψφ (x) ≡
Z x
a
[φ (t) −
ÃZ b
a
φ (y) dy
!
φ0 (t)]dt
Then ψφ ∈C∞
c (a, b) and ψ′
φ = φ −
³R b
a φ (y) dy
´
φ0. Then
Z b
a
f (t) (φ (t)) dt
=
Z b
a
f (t)
Ã
ψ′
φ (t) +
ÃZ b
a
φ (y) dy
!
φ0 (t)
!
dt
=
Z b
a
f (t) ψ′
φ (t) dt +
ÃZ b
a
φ (y) dy
! Z b
a
f (t) φ0 (t) dt
=
ÃZ b
a
ÃZ b
a
f (t) φ0 (t) dt
!
φ (y) dy
!
.
It follows that for all φ ∈C∞
c (a, b) ,
Z b
a
Ã
f (t) −
ÃZ b
a
f (t) φ0 (t) dt
!!
φ (t) dt
and so by Lemma 45.1,
f (t) −
ÃZ b
a
f (t) φ0 (t) dt
!
= 0 a.e.
This proves the lemma.

45.1.
AN ASSORTMENT OF IMPORTANT THEOREMS
1243
Theorem 45.9 Suppose f, f ′ both are in L1 (a, b; X) where the derivative is taken
in the sense of X valued distributions.
Then there exists a unique point of X,
denoted by f (a) such that the following formula holds a.e. t.
f (t) = f (a) +
Z t
a
f ′ (s) ds
Proof:
Z b
a
µ
f (t) −
Z t
a
f ′ (s) ds
¶
φ′ (t) dt =
Z b
a
f (t) φ′ (t) dt −
Z b
a
Z t
a
f ′ (s) φ′ (t) dsdt.
Now consider
R b
a
R t
a f ′ (s) φ′ (t) dsdt. Let Λ ∈X′. Then it is routine from approxi-
mating f ′ with simple functions to verify
Λ
ÃZ b
a
Z t
a
f ′ (s) φ′ (t) dsdt
!
=
Z b
a
Z t
a
Λ (f ′ (s)) φ′ (t) dsdt.
Now the ordinary Fubini theorem can be applied to obtain
=
Z b
a
Z b
s
Λ (f ′ (s)) φ′ (t) dtds
=
Λ
ÃZ b
a
Z b
s
f ′ (s) φ′ (t) dtds
!
.
Since X′ separates the points of X, it follows
Z b
a
Z t
a
f ′ (s) φ′ (t) dsdt =
Z b
a
Z b
s
f ′ (s) φ′ (t) dtds.
Therefore,
Z b
a
µ
f (t) −
Z t
a
f ′ (s) ds
¶
φ′ (t) dt
=
Z b
a
f (t) φ′ (t) dt −
Z b
a
Z b
s
f ′ (s) φ′ (t) dtds
=
Z b
a
f (t) φ′ (t) dt −
Z b
a
f ′ (s)
Z b
s
φ′ (t) dtds
=
Z b
a
f (t) φ′ (t) dt +
Z b
a
f ′ (s) φ (s) ds = 0.
Therefore, by Lemma 45.8, there exists a constant, denoted as f (a) such that
f (t) −
Z t
a
f ′ (s) ds = f (a)
and this proves the theorem.
The integration by parts formula is also important.

1244
INTERPOLATION IN BANACH SPACE
Corollary 45.10 Suppose f, f ′ ∈L1 (a, b; X) and suppose φ ∈C1 ([a, b]) . Then
the following integration by parts formula holds.
Z b
a
f (t) φ′ (t) dt = f (b) φ (b) −f (a) φ (a) −
Z b
a
f ′ (t) φ (t) dt.
Proof: From Theorem 45.9
Z b
a
f (t) φ′ (t) dt
=
Z b
a
µ
f (a) +
Z t
a
f ′ (s) ds
¶
φ′ (t) dt
=
f (a) (φ (b) −φ (a)) +
Z b
a
Z t
a
f ′ (s) dsφ′ (t) dt
=
f (a) (φ (b) −φ (a)) +
Z b
a
f ′ (s)
Z b
s
φ′ (t) dtds
=
f (a) (φ (b) −φ (a)) +
Z b
a
f ′ (s) (φ (b) −φ (s)) ds
=
f (a) (φ (b) −φ (a)) −
Z b
a
f ′ (s) φ (s) ds + (f (b) −f (a)) φ (b)
=
f (b) φ (b) −f (a) φ (a) −
Z b
a
f ′ (s) φ (s) ds.
The interchange in order of integration is justiﬁed as in the proof of Theorem 45.9.
With this integration by parts formula, the following interesting lemma is ob-
tained. This lemma shows why it was appropriate to deﬁne f as in Deﬁnition 45.2.
Lemma 45.11 Let f be given in Deﬁnition 45.2 and suppose f, f ′ ∈L1 (a, b; X) .
Then f, f
′ ∈L1 (2a −b, 2b −a; X) also and
f
′ (t) ≡



f ′ (t) if t ∈[a, b]
−f (2a −t) if t ∈[2a −b, a]
−f (2b −t) if t ∈[b, 2b −a]
(45.1)
Proof: It is clear from the deﬁnition of f that f ∈L1 (2a −b, 2b −a; X) and
that in fact
¯¯¯¯f
¯¯¯¯
L1(2a−b,2b−a;X) ≤3 ||f||L1(a,b;X) .
(45.2)

45.1.
AN ASSORTMENT OF IMPORTANT THEOREMS
1245
Let φ ∈C∞
c (2a −b, 2b −a) . Then from the integration by parts formula,
Z 2b−a
2a−b
f (t) φ′ (t) dt
=
Z b
a
f (t) φ′ (t) dt +
Z 2b−a
b
f (2b −t) φ′ (t) dt +
Z a
2a−b
f (2a −t) φ′ (t) dt
=
Z b
a
f (t) φ′ (t) dt +
Z b
a
f (u) φ′ (2b −u) du +
Z b
a
f (u) φ′ (2a −u) du
=
f (b) φ (b) −f (a) φ (a) −
Z b
a
f ′ (t) φ (t) dt −f (b) φ (b) + f (a) φ (2b −a)
+
Z b
a
f ′ (u) φ (2b −u) du −f (b) φ (2a −b)
+f (a) φ (a) +
Z b
a
f ′ (u) φ (2a −u) du
=
−
Z b
a
f ′ (t) φ (t) dt +
Z b
a
f ′ (u) φ (2b −u) du +
Z b
a
f ′ (u) φ (2a −u) du
=
−
Z b
a
f ′ (t) φ (t) dt −
Z 2b−a
b
−f ′ (2b −t) φ (t) dt −
Z a
2a−b
−f ′ (2a −t) φ (t) dt
=
−
Z 2b−a
2a−b
f
′ (t) φ (t) dt
where f
′ (t) is given in 45.1. This proves the lemma.
Deﬁnition 45.12 Let V be a Banach space and let H be a Hilbert space. (Typically
H = L2 (Ω)) Suppose V ⊆H is dense in H meaning that the closure in H of V
gives H. Then it is often the case that H is identiﬁed with its dual space, and then
because of the density of V in H, it is possible to write
V ⊆H = H′ ⊆V ′
When this is done, H is called a pivot space. Another notation which is often used
is ⟨f, g⟩to denote f (g) for f ∈V ′ and g ∈V. This may also be written as ⟨f, g⟩V ′,V
The next theorem is an example of a trace theorem.
In this theorem, f ∈
Lp (0, T; V ) while f ′ ∈Lp (0, T; V ′) . It makes no sense to consider the initial values
of f in V because it is not even continuous with values in V . However, because of
the derivative of f it will turn out that f is continuous with values in a larger space
and so it makes sense to consider initial values of f in this other space. This other
space is called a trace space.
Theorem 45.13 Let V and H be a Banach space and Hilbert space as described
in Deﬁnition 45.12. Suppose f ∈Lp (0, T; V ) and f ′ ∈Lp′ (0, T; V ′) . Then f is

1246
INTERPOLATION IN BANACH SPACE
a.e. equal to a continuous function mapping [0, T] to H. Furthermore, there exists
f (0) ∈H such that
1
2 |f (t)|2
H −1
2 |f (0)|2
H =
Z t
0
⟨f ′ (s) , f (s)⟩ds,
(45.3)
and for all t ∈[0, T] ,
Z t
0
f ′ (s) ds ∈H,
(45.4)
and for a.e. t ∈[0, T] ,
f (t) = f (0) +
Z t
0
f ′ (s) ds in H,
(45.5)
Here f ′ is being taken in the sense of V ′ valued distributions and 1
p + 1
p′ = 1 and
p ≥2.
Proof: Let Ψ ∈C∞
c (−T, 2T) satisfy Ψ (t) = 1 if t ∈[−T/2, 3T/2] and Ψ (t) ≥0.
For t ∈R, deﬁne
bf (t) ≡
½
f (t) Ψ (t) if t ∈[−T, 2T]
0 if t /∈[−T, 2T]
and
fn (t) ≡
Z 1/n
−1/n
bf (t −s) φn (s) ds
(45.6)
where φn is a molliﬁer having support in (−1/n, 1/n) . Then by Minkowski’s in-
equality
¯¯¯
¯¯¯fn −bf
¯¯¯
¯¯¯
Lp(R;V ) =
ÃZ
R
¯¯¯¯¯
¯¯¯¯¯
bf (t) −
Z 1/n
−1/n
bf (t −s) φn (s) ds
¯¯¯¯¯
¯¯¯¯¯
p
V
dt
!1/p
=
ÃZ
R
¯¯¯¯¯
¯¯¯¯¯
Z 1/n
−1/n
³
bf (t) −bf (t −s)
´
φn (s) ds
¯¯¯¯¯
¯¯¯¯¯
p
V
dt
!1/p
≤
ÃZ
R
ÃZ 1/n
−1/n
¯¯¯
¯¯¯ bf (t) −bf (t −s)
¯¯¯
¯¯¯
V φn (s) ds
!p
dt
!1/p
≤
Z 1/n
−1/n
φn (s)
µZ
R
¯¯¯
¯¯¯ bf (t) −bf (t −s)
¯¯¯
¯¯¯
p
V dt
¶1/p
ds
≤
Z 1/n
−1/n
φn (s) εds = ε
provided n is large enough.
This follows from Lemma 45.4 about continuity of
translation. Since ε > 0 is arbitrary, it follows fn →bf in Lp (R; V ) . Similarly,

45.1.
AN ASSORTMENT OF IMPORTANT THEOREMS
1247
fn →f in L2 (R; H). This follows because p ≥2 and the norm in V and norm in
H are related by |x|H ≤C ||x||V for some constant, C. Now
bf (t) =







Ψ (t) f (t) if t ∈[0, T] ,
Ψ (t) f (2T −t) if t ∈[T, 2T] ,
Ψ (t) f (−t) if t ∈[0, T] ,
0 if t /∈[−T, 2T] .
An easy modiﬁcation of the argument of Lemma 45.11 yields
bf ′ (t) =







Ψ′ (t) f (t) + Ψ (y) f ′ (t) if t ∈[0, T] ,
Ψ′ (t) f (2T −t) −Ψ (t) f ′ (2T −t) if t ∈[T, 2T] ,
Ψ′ (t) f (−t) −Ψ (t) f ′ (−t) if t ∈[−T, 0] ,
0 if t /∈[−T, 2T] .
.
Recall
fn (t)
=
Z 1/n
−1/n
bf (t −s) φn (s) ds =
Z
R
bf (t −s) φn (s) ds
=
Z
R
bf (s) φn (t −s) ds.
Therefore,
f ′
n (t)
=
Z
R
bf (s) φ′
n (t −s) ds =
Z 2T + 1
n
−T −1
n
bf (s) φ′
n (t −s) ds
=
Z 2T + 1
n
−T −1
n
bf ′ (s) φn (t −s) ds =
Z
R
bf ′ (s) φn (t −s) ds
=
Z
R
bf ′ (t −s) φn (s) ds =
Z 1/n
−1/n
bf ′ (t −s) φn (s) ds
and it follows from the ﬁrst line above that f ′
n is continuous with values in V for all
t ∈R. Also note that both f ′
n and fn equal zero if t /∈[−T, 2T] whenever n is large
enough. Exactly similar reasoning to the above shows that f ′
n →bf ′ in Lp′ (R; V ′) .
Now let φ ∈C∞
c (0, T) .
Z
R
|fn (t)|2
H φ′ (t) dt
=
Z
R
(fn (t) , fn (t))H φ′ (t) dt
(45.7)
= −
Z
R
2 (f ′
n (t) , fn (t)) φ (t) dt
=
−
Z
R
2 ⟨f ′
n (t) , fn (t)⟩φ (t) dt
Now
¯¯¯¯
Z
R
⟨f ′
n (t) , fn (t)⟩φ (t) dt −
Z
R
⟨f ′ (t) , f (t)⟩φ (t) dt
¯¯¯¯
≤
Z
R
(|⟨f ′
n (t) −f ′ (t) , fn (t)⟩| + |⟨f ′ (t) , fn (t) −f (t)⟩|) φ (t) dt.

1248
INTERPOLATION IN BANACH SPACE
From the ﬁrst part of this proof which showed that fn →bf in Lp (R; V ) and f ′
n →bf ′
in Lp′ (R; V ′) , an application of Holder’s inequality shows the above converges to 0
as n →∞. Therefore, passing to the limit as n →∞in the 45.8,
Z
R
¯¯¯ bf (t)
¯¯¯
2
H φ′ (t) dt = −
Z
R
2
D
bf ′ (t) , bf (t)
E
φ (t) dt
which shows t →
¯¯¯ bf (t)
¯¯¯
2
H equals a continuous function a.e. and it also has a weak
derivative equal to 2
D
bf ′, bf
E
.
It remains to verify that bf is continuous on [0, T] . Of course bf = f on this
interval. Let N be large enough that fn (−T) = 0 for all n > N. Then for m, n > N
and t ∈[−T, 2T]
|fn (t) −fm (t)|2
H
=
2
Z t
−T
(f ′
n (s) −f ′
m (s) , fn (s) −fm (s)) ds
=
2
Z t
−T
⟨f ′
n (s) −f ′
m (s) , fn (s) −fm (s)⟩V ′,V ds
≤
2
Z
R
||f ′
n (s) −f ′
m (s)||V ′ ||fn (s) −fm (s)||V ds
≤
2 ||fn −fm||Lp′(R;V ′) ||fn −fm||Lp(R;V )
which shows from the above that {fn} is uniformly Cauchy on [−T, 2T] with values
in H. Therefore, there exists g a continuous function deﬁned on [−T, 2T] having
values in H such that
lim
n→∞max {|fn (t) −g (t)|H ; t ∈[−T, 2T]} = 0.
However, g = bf a.e. because fn converges to f in Lp (0, T; V ) . Therefore, taking a
subsequence, the convergence is a.e. It follows from the fact that V ⊆H = H′ ⊆V ′
and Theorem 45.9 there exists f (0) ∈V ′ such that for a.e. t,
f (t) = f (0) +
Z t
0
f ′ (s) ds in V ′
Now g = f a.e. and g is continuous with values in H hence continuous with values
in V ′and so
g (t) = f (0) +
Z t
0
f ′ (s) ds in V ′
for all t. Since g is continuous with values in H it is continuous with values in V ′.
Taking the limit as t ↓0 in the above, g (a) = limt→0+ g (t) = f (0) , showing that
f (0) ∈H. Therefore, for a.e. t,
f (t) = f (0) +
Z t
0
f ′ (s) ds in H,
Z t
0
f ′ (s) ds ∈H.

45.1.
AN ASSORTMENT OF IMPORTANT THEOREMS
1249
This proves the theorem.
Note that if f ∈Lp (0, T; V ) and f ′ ∈Lp′ (0, T; V ′) , then you can consider the
initial value of f and it will be in H. What if you start with something in H? Is
it an initial condition for a function f ∈Lp (0, T; V ) such that f ′ ∈Lp′ (0, T; V ′)?
This is worth thinking about. If it is not so, what is the space of initial values?
How can you give this space a norm? What are its properties? It turns out that if
V is a closed subspace of the Sobolev space, W 1,p (Ω) which contains W 1,p
0
(Ω) for
p ≥2 and H = L2 (Ω) the answer to the above question is yes. Not surprisingly,
there are many generalizations of the above ideas.
45.1.2
Some Imbedding Theorems
The next theorem is very useful in getting estimates in partial diﬀerential equations.
It is called Erling’s lemma.
Deﬁnition 45.14 Let E, W be Banach spaces such that E ⊆Wand the injection
map from E into W is continuous. The injection map is said to be compact if every
bounded set in E has compact closure in W. In other words, if a sequence is bounded
in E it has a convergent subsequence converging in W. This is also referred to by
saying that bounded sets in E are precompact in W.
Theorem 45.15 Let E ⊆W ⊆X where the injection map is continuous from W
to X and compact from E to W. Then for every ε > 0 there exists a constant, Cε
such that for all u ∈E,
||u||W ≤ε ||u||E + Cε ||u||X
Proof: Suppose not. Then there exists ε > 0 and for each n ∈N, un such that
||un||W > ε ||un||E + n ||un||X
Now let vn = un/ ||un||E . Therefore, ||vn||E = 1 and
||vn||W > ε + n ||vn||X
It follows there exists a subsequence, still denoted by vn such that vn converges to
v in W. However, the above inequality shows that ||vn||X →0. Therefore, v = 0.
But then the above inequality would imply that ||vn|| > ε and passing to the limit
yields 0 > ε, a contradiction.
Deﬁnition 45.16 Deﬁne C ([a, b] ; X) the space of functions continuous at every
point of [a, b] having values in X.
You should verify that this is a Banach space with norm
||u||∞,X = max
©
||unk (t) −u (t)||X : t ∈[a, b]
ª
.
The following theorem is an inﬁnite dimensional version of the Ascoli Arzela
theorem.

1250
INTERPOLATION IN BANACH SPACE
Theorem 45.17 Let q > 1 and let E ⊆W ⊆X where the injection map is con-
tinuous from W to X and compact from E to W. Let S be deﬁned by
n
u such that ||u (t)||E + ||u′||Lq([a,b];X) ≤R for all t ∈[a, b]
o
.
Then S ⊆C ([a, b] ; W) and if {un} ⊆S, there exists a subsequence, {unk} which
converges to a function u ∈C ([a, b] ; W) in the following way.
lim
k→∞||unk −u||∞,W = 0.
Proof: First consider the issue of S being a subset of C ([a, b] ; W) . By Theorem
45.9 on Page 1243 the following holds in X for u ∈S.
u (t) −u (s) =
Z t
s
u′ (r) dr.
Thus S ⊆C ([a, b] ; X) . Let ε > 0 be given. Then by Theorem 45.15 there exists a
constant, Cε such that for all u ∈W
||u||W ≤ε
4R ||u||E + Cε ||u||X .
Therefore, for all u ∈S,
||u (t) −u (s)||W
≤
ε
6R ||u (t) −u (s)||E + Cε ||u (t) −u (s)||X
≤
ε
3 + Cε
¯¯¯¯
¯¯¯¯
Z t
s
u′ (r) dr
¯¯¯¯
¯¯¯¯
X
≤
ε
3 + Cε
Z t
s
||u′ (r)||X dr ≤ε
3 + CεR |t −s|1/q . (45.8)
Since ε is arbitrary, it follows u ∈C ([a, b] ; W).
Let D = Q ∩[a, b] so D is a countable dense subset of [a, b]. Let D = {tn}∞
n=1.
By compactness of the embedding of E into W, there exists a subsequence u(n,1)
such that as n →∞, u(n,1) (t1) converges to a point in W. Now take a subsequence
of this, called (n, 2) such that as n →∞, u(n,2) (t2) converges to a point in W.
It follows that u(n,2) (t1) also converges to a point of W. Continue this way. Now
consider the diagonal sequence, uk ≡u(k,k) This sequence is a subsequence of u(n,l)
whenever k > l. Therefore, uk (tj) converges for all tj ∈D.
Claim: Let {uk} be as just deﬁned, converging at every point of [a, b] . Then
{uk} converges at every point of [a, b].
Proof of claim: Let ε > 0 be given. Let t ∈[a, b] . Pick tm ∈D ∩[a, b] such
that in 45.8 CεR |t −tm| < ε/3. Then there exists N such that if l, n > N, then
||ul (tm) −un (tm)||X < ε/3. It follows that for l, n > N,
||ul (t) −un (t)||X
≤
||ul (t) −ul (tm)|| + ||ul (tm) −un (tm)||
+ ||un (tm) −un (t)||
≤
2ε
3 + ε
3 + 2ε
3 < 2ε

45.1.
AN ASSORTMENT OF IMPORTANT THEOREMS
1251
Since ε was arbitrary, this shows {uk (t)}∞
k=1 is a Cauchy sequence. Since W is
complete, this shows this sequence converges.
Now for t ∈[a, b] , it was just shown that if ε > 0 there exists Nt such that if
n, m > Nt, then
||un (t) −um (t)|| < ε
3.
Now let s ̸= t. Then
||un (s) −um (s)|| ≤||un (s) −un (t)|| + ||un (t) −um (t)|| + ||um (t) −um (s)||
From 45.8
||un (s) −um (s)|| ≤2
³ε
3 + CεR |t −s|1/q´
+ ||un (t) −um (t)||
and so it follows that if δ is suﬃciently small and s ∈B (t, δ) , then when n, m > Nt
||un (s) −um (s)|| < ε.
Since [a, b] is compact, there are ﬁnitely many of these balls, {B (ti, δ)}p
i=1 , such
that for s ∈B (ti, δ) and n, m > Nti, the above inequality holds.
Let N >
max
©
Nt1, · · ·, Ntp
ª
. Then if m, n > N and s ∈[a, b] is arbitrary, it follows the
above inequality must hold. Therefore, this has shown the following claim.
Claim: Let ε > 0 be given. Then there exists N such that if m, n > N, then
||un −um||∞,W < ε.
Now let u (t) = limk→∞uk (t) .
||u (t) −u (s)||W ≤||u (t) −un (t)||W + ||un (t) −un (s)||W + ||un (s) −u (s)||W
(45.9)
Let N be in the above claim and ﬁx n > N. Then
||u (t) −un (t)||W = lim
m→∞||um (t) −un (t)||W ≤ε
and similarly, ||un (s) −u (s)||W ≤ε. Then if |t −s| is small enough, 45.8 shows the
middle term in 45.9 is also smaller than ε. Therefore, if |t −s| is small enough,
||u (t) −u (s)||W < 3ε.
Thus u is continuous. Finally, let N be as in the above claim. Then letting m, n >
N, it follows that for all t ∈[a, b] ,
||um (t) −un (t)|| < ε.
Therefore, letting m →∞, it follows that for all t ∈[a, b] ,
||u (t) −un (t)|| ≤ε.
and so ||u −un||∞,W ≤ε. Since ε is arbitrary, this proves the theorem.
The next theorem is another such imbedding theorem. It is often used in partial
diﬀerential equations.

1252
INTERPOLATION IN BANACH SPACE
Theorem 45.18 Let E ⊆W ⊆X where the injection map is continuous from W
to X and compact from E to W. Let p ≥1, let q > 1, and deﬁne
S ≡{u ∈Lp ([a, b] ; E) : u′ ∈Lq ([a, b] ; X)
and ||u||Lp([a,b];E) + ||u′||Lq([a,b];X) ≤R}.
Then S is precompact in Lp ([a, b] ; W). This means that if {un}∞
n=1 ⊆S, it has a
subsequence {unk} which converges in Lp ([a, b] ; W) .
Proof: By Proposition 6.12 on Page 136 it suﬃces to show S has an η net in
Lp ([a, b] ; W) for each η > 0.
If not, there exists η > 0 and a sequence {un} ⊆S, such that
||un −um|| ≥η
(45.10)
for all n ̸= m and the norm refers to Lp ([a, b] ; W). Let
a = t0 < t1 < · · · < tn = b, tk −tk−1 = T/k.
Now deﬁne
un (t) ≡
k
X
i=1
uniX[ti−1,ti) (t) , uni ≡
1
ti −ti−1
Z ti
ti−1
un (s) ds.
The idea is to show that un approximates un well and then to argue that a subse-
quence of the {un} is a Cauchy sequence yielding a contradiction to 45.10.
Therefore,
un (t) −un (t) =
k
X
i=1
1
ti −ti−1
Z ti
ti−1
(un (t) −un (s)) dsX[ti−1,ti) (t) .
It follows from Jensen’s inequality that
||un (t) −un (t)||p
W
=
k
X
i=1
¯¯¯¯¯
¯¯¯¯¯
1
ti −ti−1
Z ti
ti−1
(un (t) −un (s)) ds
¯¯¯¯¯
¯¯¯¯¯
p
W
X[ti−1,ti) (t)
≤
k
X
i=1
1
ti −ti−1
Z ti
ti−1
||un (t) −un (s)||p
W dsX[ti−1,ti) (t)
and so
Z b
a
||(un (t) −un (s))||p
W ds
≤
Z b
a
k
X
i=1
1
ti −ti−1
Z ti
ti−1
||un (t) −un (s)||p
W dsX[ti−1,ti) (t) dt
=
k
X
i=1
1
ti −ti−1
Z ti
ti−1
Z ti
ti−1
||un (t) −un (s)||p
W dsdt.
(45.11)

45.1.
AN ASSORTMENT OF IMPORTANT THEOREMS
1253
From Theorems 45.15 and 45.9, if ε > 0, there exists Cε such that
||un (t) −un (s)||p
W ≤ε ||un (t) −un (s)||p
E + Cε ||un (t) −un (s)||p
X
≤
2p−1ε (||un (t)||p + ||un (s)||p) + Cε
¯¯¯¯
¯¯¯¯
Z t
s
u′
n (r) dr
¯¯¯¯
¯¯¯¯
p
X
≤
2p−1ε (||un (t)||p + ||un (s)||p) + Cε
µZ t
s
||u′
n (r)||X dr
¶p
≤
2p−1ε (||un (t)||p + ||un (s)||p)
+Cε
ÃµZ t
s
||u′
n (r)||q
X dr
¶1/q
|t −s|1/q′
!p
=
2p−1ε (||un (t)||p + ||un (s)||p) + CεRp/q |t −s|p/q′
.
This is substituted in to 45.11 to obtain
Z b
a
||(un (t) −un (s))||p
W ds ≤
k
X
i=1
1
ti −ti−1
Z ti
ti−1
Z ti
ti−1
¡
2p−1ε (||un (t)||p + ||un (s)||p)
+CεRp/q |t −s|p/q′´
dsdt
=
k
X
i=1
2pε
Z ti
ti−1
||un (t)||p
W + CεRp/q
1
ti −ti−1
Z ti
ti−1
Z ti
ti−1
|t −s|p/q′
dsdt
=
2pε
Z b
a
||un (t)||p dt + CεRp/q
k
X
i=1
1
(ti −ti−1) (ti −ti−1)p/q′ Z ti
ti−1
Z ti
ti−1
dsdt
=
2pε
Z b
a
||un (t)||p dt + CεRp/q
k
X
i=1
1
(ti −ti−1) (ti −ti−1)p/q′
(ti −ti−1)2
≤
2pεRp + CεRp/q
k
X
i=1
(ti −ti−1)1+p/q′
= 2pεRp + CεRp/qk
µT
k
¶1+p/q′
.
Taking ε so small that 2pεRp < ηp/8p and then choosing k suﬃciently large, it
follows
||un −un||Lp([a,b];W ) < η
4.
Now use compactness of the embedding of E into W to obtain a subsequence
such that {un} is Cauchy in Lp (a, b; W) and use this to contradict 45.10. Suppose
un (t) = Pk
i=1 un
i X[ti−1,ti) (t) . Thus
||un (t)||E =
k
X
i=1
||un
i ||E X[ti−1,ti) (t)

1254
INTERPOLATION IN BANACH SPACE
and so
R ≥
Z b
a
||un (t)||p
E dt = T
k
k
X
i=1
||un
i ||p
E
Therefore, the {un
i } are all bounded.
It follows that after taking subsequences
k times there exists a subsequence {unk} such that unk is a Cauchy sequence in
Lp (a, b; W) . You simply get a subsequence such that unk
i
is a Cauchy sequence in
W for each i. Then denoting this subsequence by n,
||un −um||Lp(a,b;W )
≤
||un −un||Lp(a,b;W )
+ ||un −um||Lp(a,b;W ) + ||um −um||Lp(a,b;W )
≤
η
4 + ||un −um||Lp(a,b;W ) + η
4 < η
provided m, n are large enough, contradicting 45.10. This proves the theorem.
45.2
The K Method
This considers the problem of interpolating Banach spaces. The idea is to build
a Banach space between two others in a systematic way, thus constructing a new
Banach space from old ones. The ﬁrst method of deﬁning intermediate Banach
spaces is called the K method. For more on this topic as well as the other topics on
interpolation see [8] which is what I am following. See also [50]. There is far more
on these subjects in these books than what I am presenting here! My goal is to
present only enough to give an introduction to the topic and to use it in presenting
more theory of Sobolev spaces.
In what follows a topological vector space is a vector space in which vector
addition and scalar multiplication are continuous.
That is · : F × X →X is
continuous and + : X × X →X is also continuous.
A common example of a topological vector space is the dual space, X′ of a
Banach space, X with the weak ∗topology. For S ⊆X a ﬁnite set, deﬁne
BS (x∗, r) ≡{y∗∈X′ : |y∗(x) −x∗(x)| < r for all x ∈S}
Then the BS (x∗, r) for S a ﬁnite subset of X and r > 0 form a basis for the topology
on X′ called the weak ∗topology. You can check that the vector space operations
are continuous.
Deﬁnition 45.19 Let A0 and A1 be two Banach spaces with norms ||·||0 and ||·||1
respectively, also written as ||·||A0 and ||·||A1 and let X be a topological vector space
such that Ai ⊆X for i = 1, 2, and the identity map from Ai to X is continuous.
For each t > 0, deﬁne a norm on A0 + A1 by
K (t, a) ≡||a||t ≡inf {||a0||0 + t ||a1||1 : a0 + a1 = a}.
This is short for K (t, a, A0, A1) . Thus K (t, a, A1, A0) will mean
K (t, a, A1, A0) ≡inf
©
||a1||A1 + t ||a0||A0 : a0 + a1 = a
ª

45.2.
THE K METHOD
1255
but the default is K (t, a, A0, A1) if K (t, a) is written.
The following lemma is an interesting exercise.
Lemma 45.20 (A0 + A1, K (t, ·)) is a Banach space and all the norms, K (t, ·) are
equivalent.
Proof: First, why is K (t, ·) a norm? It is clear that K (t, a) ≥0 and that if
a = 0 then K (t, a) = 0. Is this the only way this can happen? Suppose K (t, a) = 0.
Then there exist a0n ∈A0 and a1n ∈A1 such that ||a0n||0 →0, ||a1n||1 →0, and
a = a0n + a1n. Since the embedding of Ai into X is continuous and since X is a
topological vector space1, it follows
a = a0n + a1n →0
and so a = 0.
Let α be a nonzero scalar. Then
K (t, αa)
=
inf {||a0||0 + t ||a1||1 : a0 + a1 = αa}
=
inf
n
|α|
¯¯¯
¯¯¯a0
α
¯¯¯
¯¯¯
0 + t |α|
¯¯¯
¯¯¯a1
α
¯¯¯
¯¯¯
1 : a0
α + a1
α = a
o
=
|α| inf
n¯¯¯
¯¯¯a0
α
¯¯¯
¯¯¯
0 + t
¯¯¯
¯¯¯a1
α
¯¯¯
¯¯¯
1 : a0
α + a1
α = a
o
=
|α| inf {||a0||0 + t ||a1||1 : a0 + a1 = a} = |α| K (t, a) .
It remains to verify the triangle inequality. Let ε > 0 be given. Then there exist
a0, a1, b0, and b1 in A0, A1, A0, and A1 respectively such that a0+a1 = a, b0+b1 = b
and
ε + K (t, a) + K (t, b)
>
||a0||0 + t ||a1||1 + ||b0||0 + t ||b1||1
≥
||a0 + b0||0 + t ||b1 + a1||1 ≥K (t, a + b) .
This has shown that K (t, ·) is at least a norm. Are all these norms equivalent?
If 0 < s < t then it is clear that K (t, a) ≥K (s, a) . To show there exists a constant,
C such that CK (s, a) ≥K (t, a) for all a,
t
sK (s, a)
≡
t
s inf {||a0||0 + s ||a1||1 : a0 + a1 = a}
=
inf
½ t
s ||a0||0 + s t
s ||a1||1 : a0 + a1 = a
¾
=
inf
½ t
s ||a0||0 + t ||a1||1 : a0 + a1 = a
¾
≥
inf {||a0||0 + t ||a1||1 : a0 + a1 = a} = K (t, a) .
Therefore, the two norms are equivalent as hoped.
1Vector addition is continuous is the property which is used here.

1256
INTERPOLATION IN BANACH SPACE
Finally, it is required to verify that (A0 + A1, K (t, ·)) is a Banach space. Since
all these norms are equivalent, it suﬃces to only consider the norm, K (1, ·). Let
{a0n + a1n}∞
n=1 be a Cauchy sequence in A0 + A1. Then for m, n large enough,
K (1, a0n + a1n −(a0m + a1m)) < ε.
It follows there exist xn ∈A0 and yn ∈A1 such that xn + yn = 0 for every n and
whenever m, n are large enough,
||a0n + xn −(a0m + xm)||0 + ||a1n + yn −(a1m + ym)||1 < ε
Hence {a1n + yn} is a Cauchy sequence in A1 and {a0n + xn} is a Cauchy sequence
in A0. Let
a0n + xn
→
a0 ∈A0
a1n + yn
→
a1 ∈A1.
Then
K (1, a0n + a1n −(a0 + a1))
=
K (1, a0n + xn + a1n + yn −(a0 + a1))
≤
||a0n + xn −a0||0 + ||a1n + yn −a1||1
which converges to 0. Thus A0 + A1 is a Banach space as claimed.
With this, there exists a method for constructing a Banach space which lies
between A0 ∩A1 and A0 + A1.
Deﬁnition 45.21 Let 1 ≤q < ∞, 0 < θ < 1.
Deﬁne (A0, A1)θ,q to be those
elements of A0 + A1, a, such that
||a||θ,q ≡
·Z ∞
0
¡
t−θK (t, a, A0, A1)
¢q dt
t
¸1/q
< ∞.
Theorem 45.22 (A0, A1)θ,q is a normed linear space satisfying
A0 ∩A1 ⊆(A0, A1)θ,q ⊆A0 + A1,
(45.12)
with the inclusion maps continuous, and
³
(A0, A1)θ,q , ||·||θ,q
´
is a Banach space.
(45.13)
If a ∈A0 ∩A1, then
||a||θ,q ≤
µ
1
qθ (1 −θ)
¶1/q
||a||θ
1 ||a||1−θ
0
.
(45.14)
If A0 ⊆A1 with ||·||0 ≥||·||1, then
A0 ∩A1 = A0 ⊆(A0, A1)θ,q ⊆A1 = A0 + A1.

45.2.
THE K METHOD
1257
Also, if bounded sets in A0 have compact closures in A1 then the same is true if A1
is replaced with (A0, A1)θ,q. Finally, if
T ∈L (A0, B0) , T ∈L (A1, B1),
(45.15)
and T is a linear map from A0 + A1 to B0 + B1 where the Ai and Bi are Banach
spaces with the properties described above, then it follows
T ∈L
³
(A0, A1)θ,q , (B0, B1)θ,q
´
(45.16)
and if M is its norm, and M0 and M1 are the norms of T as a map in L (A0, B0)
and L (A1, B1) respectively, then
M ≤M 1−θ
0
M θ
1 .
(45.17)
Proof: Suppose ﬁrst a ∈A0 ∩A1. Then
||a||q
θ,q
≡
Z r
0
¡
t−θK (t, a)
¢q dt
t +
Z ∞
r
¡
t−θK (t, a)
¢q dt
t
(45.18)
≤
Z r
0
¡
t−θ ||a||1 t
¢q dt
t +
Z ∞
r
¡
t−θ ||a||0
¢q dt
t
=
||a||q
1
Z r
0
tq(1−θ)−1dt + ||a||q
0
Z ∞
r
t−1−θqdt
=
||a||q
1
rq−qθ
q −qθ + ||a||q
0
r−θq
θq
< ∞
(45.19)
Which shows the ﬁrst inclusion of 45.12. The above holds for all r > 0 and in
particular for the value of r which minimizes the expression on the right in 45.19,
r = ||a||0 / ||a||1. Therefore, doing some calculus,
||a||q
θ,q ≤
1
θq (1 + θ) ||a||q(1−θ)
0
||a||qθ
1
which shows 45.14. This also veriﬁes that the inclusion map is continuous in 45.12.
Now consider the second inclusion in 45.12. The inclusion is obvious because
(A0, A1)θ,q is given to be a subset of A0+A1. It remains to verify the inclusion map is
continuous. Therefore, suppose an →0 in (A0, A1)θ,q. Since an →0 in (A0, A1)θ,q ,
it follows the function, t →t−θK (t, an) converges to zero in Lq (0, ∞) with respect
to the measure, dt/t. Therefore, taking another subsequence, still denoted as an, you
can assume this function converges to 0 a.e. Pick such a t where this convergence
takes place. Then K (t, an) →0 as n →∞and so an →0 in A0 + A1. this shows
that if an →0 in (A0, A1)θ,q , then there exists a subsequence {ank} such that
ank →0 in A0 + A1. It follows that if an →0 in (A0, A1)θ,q , then an →0 in
A0 + A1. This proves the continuity of the embedding.
What about 45.13? Suppose {an} is a Cauchy sequence in (A0, A1)θ,q. Then
there exists a ∈A0 + A1 such that an →a in A0 + A1 because A0 + A1 is a Banach

1258
INTERPOLATION IN BANACH SPACE
space. Thus, K (t, an) →K (t, a) for all t > 0. Therefore, by Fatou’s lemma,
µZ ∞
0
¡
t−θK (t, a)
¢q dt
t
¶1/q
≤
lim inf
n→∞
µZ ∞
0
¡
t−θK (t, an)
¢q dt
t
¶1/q
≤
max
n
||an||θ,q : n ∈N
o
< ∞
and so a ∈(A0, A1)θ,q. Now
||a −an||θ,q ≤lim inf
m→∞
µZ ∞
0
¡
t−θK (t, an −am)
¢q dt
t
¶1/q
< ε
whenever n is large enough. Thus (A0, A1)θ,q is complete as claimed.
Next suppose A0 ⊆A1 and the inclusion map is compact. In this case, A0∩A1 =
A0 and so it has been shown above that A0 ⊆(A0, A1)θ,q. It remains to show that
every bounded subset, S, contained in A0 has an η net in (A0, A1)θ,q. Recall the
inequality, 45.14
||a||θ,q
≤
µ
1
qθ (1 −θ)
¶1/q
||a||θ
1 ||a||1−θ
0
=
C
ε ||a||θ
1 ε ||a||1−θ
0
.
Now this implies
||a||θ,q ≤
µC
ε
¶1/θ
θ ||a||1 + ε1/(1−θ) (1 −θ) ||a||0
By compactness of the embedding of A0 into A1, it follows there exists an ε(1+θ)/θ
net for S in A1, {a1, · · ·, ap} . Then for a ∈S, there exists k such that ||a −ak||1 <
ε(1+θ)/θ. It follows
||a −ak||θ,q
≤
µC
ε
¶1/θ
θ ||a −ak||1 + ε1/(1−θ) (1 −θ) ||a −ak||0
≤
µC
ε
¶1/θ
θε(1+θ)/θ + ε1/(1−θ) (1 −θ) 2M
=
C1/θθε + ε1/(1−θ) (1 −θ) 2M
where M is large enough that ||a||0 ≤M for all a ∈S. Since ε is arbitrary, this
shows the existence of a η net and proves the compactness of the embedding into
(A0, A1)θ,q .
It remains to verify the assertions 45.15-45.17. Let T ∈L (A0, B0) , T ∈L (A1, B1)
with T a linear map from A0 + A1 to B0 + B1. Let a ∈(A0, A1)θ,q ⊆A0 + A1 and
consider Ta ∈B0 + B1.
Denote by K (t, ·) the norm described above for both
A0 + A1 and B0 + B1 since this will cause no confusion. Then
||Ta||θ,q ≡
µZ ∞
0
¡
t−θK (t, Ta)
¢q dt
t
¶1/q
.
(45.20)

45.3.
THE J METHOD
1259
Now let a0 + a1 = a and so Ta0 + Ta1 = Ta
K (t, Ta)
≤
||Ta0||0 + t ||Ta1||1 ≤M0 ||a0||0 + M1t ||a1||1
≤
M0
µ
||a0||0 + t
µM1
M0
¶
||a1||1
¶
and so, taking inf for all a0 + a1 = a, yields
K (t, Ta) ≤M0K
µ
t
µM1
M0
¶
, a
¶
It follows from 45.20 that
||Ta||θ,q
≡
µZ ∞
0
¡
t−θK (t, Ta)
¢q dt
t
¶1/q
≤
µZ ∞
0
µ
t−θM0K
µ
t
µM1
M0
¶
, a
¶¶q dt
t
¶1/q
=
M0
µZ ∞
0
µ
t−θK
µ
t
µM1
M0
¶
, a
¶¶q dt
t
¶1/q
=
M0
ÃZ ∞
0
ÃµM0
M1
s
¶−θ
K (s, a)
!q
ds
s
!1/q
=
M θ
1 M (1−θ)
0
µZ ∞
0
¡
s−θK (s, a)
¢q ds
s
¶1/q
= M θ
1 M (1−θ)
0
||a||θ,q .
This shows T ∈L
³
(A0, A1)θ,q , (B0, B1)θ,q
´
and if M is the norm of T, M ≤
M 1−θ
0
M θ
1 as claimed. This proves the theorem.
45.3
The J Method
There is another method known as the J method.
Deﬁnition 45.23 For A0 and A1 Banach spaces as described above, and a ∈A0 ∩
A1,
J (t, a) ≡max
¡
||a||A0 , t ||a||A1
¢
.
(45.21)
this is short for J (t, a, A0, A1). Thus
J (t, a, A1, A0) ≡max
¡
||a||A1 , t ||a||A0
¢
but unless indicated otherwise, A0 will come ﬁrst. Now for θ ∈(0, 1) and q ≥1,
deﬁne a space, (A0, A1)θ,q,J as follows. The space, (A0, A1)θ,q,J will consist of those
elements, a, of A0 + A1 which can be written in the form
a =
Z ∞
0
u (t) dt
t ≡lim
ε→0+
Z 1
ε
u (t) dt
t + lim
r→∞
Z r
1
u (t) dt
t
(45.22)

1260
INTERPOLATION IN BANACH SPACE
the limits taking place in A0 + A1 with the norm
K (1, a) ≡
inf
a=a0+a1
¡
||a0||A0 + ||a1||A1
¢
,
where u (t) is strongly measurable with values in A0 ∩A1 and bounded on every
compact subset of (0, ∞) such that
µZ ∞
0
¡
t−θJ (t, u (t) , A0, A1)
¢q dt
t
¶1/q
< ∞.
(45.23)
For such a ∈A0 + A1, deﬁne
||a||θ,q,J ≡inf
u
(µZ ∞
0
¡
t−θJ (t, u (t) , A0, A1)
¢q dt
t
¶1/q)
(45.24)
where the inﬁmum is taken over all u satisfying 45.22 and 45.23.
Note that a norm on A0 × A1 would be
||(a0, a1)|| ≡max
¡
||a0||A0 , t ||a1||A1
¢
and so J (t, ·) is the restriction of this norm to the subspace of A0 × A1 deﬁned
by {(a, a) : a ∈A0 ∩A1}. Also for each t > 0 J (t, ·) is a norm on A0 ∩A1 and
furthermore, any two of these norms are equivalent. In fact, it is easy to see that
for 0 < t < s, t
sJ (s, a) ≤J (t, a) ≤J (s, a) .
The following lemma is signiﬁcant and follows immediately from the above def-
inition.
Lemma 45.24 Suppose a ∈(A0, A1)θ,q,J and a =
R ∞
0
u (t) dt
t where u is described
above. Then letting r > 1,
ur (t) ≡
½
u (t) if t ∈
¡ 1
r, r
¢
0 otherwise
.
it follows that
Z ∞
0
ur (t) dt
t ∈A0 ∩A1.
Proof: The integral equals
R r
1/r u (t) dt
t .
R r
1/r
1
t dt = 2 ln r < ∞. Now ur is mea-
surable in A0 ∩A1 and bounded. Therefore, there exists a sequence of measurable
simple functions, {sn} having values in A0 ∩A1 which converges pointwise and uni-
formly to ur. It can also be assumed J (r, sn (t)) ≤J (r, ur (t)) for all t ∈[1/r, r].
Therefore,
lim
n,m→∞
Z r
1/r
J (r, sm −sn) dt
t = 0.
It follows from the deﬁnition of the Bochner integral that
lim
n→∞
Z r
1/r
sn
dt
t =
Z r
1/r
ur
dt
t ∈A0 ∩A1.

45.3.
THE J METHOD
1261
This proves the lemma.
The remarkable thing is that the two spaces, (A0, A1)θ,q and (A0, A1)θ,q,J co-
incide and have equivalent norms. The following important lemma, called the fun-
damental lemma of interpolation theory in [8] is used to prove this. This lemma is
really incredible.
Lemma 45.25 Suppose for a ∈A0+A1, limt→0+ K (t, a) = 0 and limt→∞
K(t,a)
t
=
0. Then for any ε > 0, there is a representation,
a =
∞
X
i=−∞
ui =
lim
n,m→∞
n
X
i=−m
ui, ui ∈A0 ∩A1,
(45.25)
the convergences taking place in A0 + A1, such that
J
¡
2i, ui
¢
≤3 (1 + ε) K
¡
2i, a
¢
.
(45.26)
Proof: For each i, there exist a0,i ∈A0 and a1,i ∈A1 such that
a = a0,i + a1,i,
and
(1 + ε) K
¡
2i, a
¢
≥||a0,i||A0 + 2i ||a1,i||A1 .
(45.27)
This follows directly from the deﬁnition of K (t, a) . From the assumed limit condi-
tions on K (t, a) ,
lim
i→∞||a1,i||A1 = 0,
lim
i→−∞||a0,i||A0 = 0.
(45.28)
Then let ui ≡a0,i −a0,i−1 = a1,i−1 −a1,i. The reason these are equal is a =
a0,i + a1,i = a0,i−1 + a1,i−1. Then
n
X
i=−m
ui = a0,n −a0,−(m+1) = a1,−(m+1) −a1,n.
It follows a −Pn
i=−m ui = a −
¡
a0,n −a0,−(m+1)
¢
= a0,−(m+1) + a1,n, and both
terms converge to zero as m and n converge to ∞by 45.28. Therefore,
K
Ã
1, a −
n
X
i=−m
ui
!
≤
¯¯¯¯a0,−(m+1)
¯¯¯¯ + ||a1,n||
and so this shows a = P∞
i=−∞ui which is one of the claims of the lemma. Also
J
¡
2i, ui
¢
≡max
¡
||ui||A0 , 2i ||ui||A1
¢
≤||ui||A0 + 2i ||ui||A1
≤||a0,i||A0 + 2i ||a1,i||A1 +
≤2
³
||a0,i−1||A0+2i−1||a1,i−1||A1
´
z
}|
{
||a0,i−1||A0 + 2i ||a1,i−1||A1
≤(1 + ε) K
¡
2i, a
¢
+ 2 (1 + ε) K
¡
2i−1, a
¢
≤3 (1 + ε) K
¡
2i, a
¢
because t →K (t, a) is nondecreasing. This proves the lemma.

1262
INTERPOLATION IN BANACH SPACE
Lemma 45.26 If a ∈A0 ∩A1, then K (t, a) ≤min
¡
1, t
s
¢
J (s, a) .
Proof: If s ≥t, then min
¡
1, t
s
¢
= t
s and so
min
µ
1, t
s
¶
J (s, a)
=
t
s max
¡
||a||A0 , s ||a||A1
¢
≥
µ t
s
¶
s ||a||A1
=
t ||a||A1 ≥K (t, a) .
Now in case s < t, then min
¡
1, t
s
¢
= 1 and so
min
µ
1, t
s
¶
J (s, a)
=
max
¡
||a||A0 , s ||a||A1
¢
≥||a||A0
≥
K (t, a) .
This proves the lemma.
Theorem 45.27 Let A0, A1, K and J be as described above. Then for all q ≥1
and θ ∈(0, 1) ,
(A0, A1)θ,q = (A0, A1)θ,q,J
and furthermore, the norms are equivalent.
Proof: Begin with a ∈(A0, A1)θ,q . Thus
||a||q
θ,q =
Z ∞
0
¡
t−θK (t, a)
¢q dt
t < ∞
(45.29)
and it is necessary to produce u (t) as described above,
a =
Z ∞
0
u (t) dt
t where
Z ∞
0
¡
t−θJ (t, u (t))
¢q dt
t < ∞.
From 45.29, limt→0+ K (t, a) = 0 since t →K (t, a) is nondecreasing and so if its
limit is positive, the integrand would have a non integrable singularity like t−θq−1.
Next consider what happens to K(t,a)
t
as t →∞.
Claim: t →K(t,a)
t
is decreasing.
Proof of the claim: Choose a0 ∈A0 and a1 ∈A1 such that a0 + a1 = a and
K (t, a) + εt > ||a0||A0 + t ||a1||A1
let s > t. Then
K (t, a) + tε
t
≥||a0||A0 + t ||a1||A1
t
≥||a0||A0 + s ||a1||A1
s
≥K (s, a)
s
.
Since ε is arbitrary, this proves the claim.

45.3.
THE J METHOD
1263
Let r ≡limt→∞
K(t,a)
t
. Is r = 0? Suppose to the contrary that r > 0. Then the
integrand of 45.29, is at least as large as
t−θqK (t, a)q−1 K (t, a)
t
≥t−θqK (t, a)q−1 r
≥t−θq (tr)q−1 r ≥rqtq(1−θ)−1
whose integral is inﬁnite. Therefore, r = 0.
Lemma 45.25, implies there exist ui ∈A0 ∩A1 such that a = P∞
i=−∞ui, the
convergence taking place in A0 + A1with the inequality of that Lemma holding,
J
¡
2i, ui
¢
≤3 (1 + ε) K
¡
2i, a
¢
.
For i an integer and t ∈[2i−1, 2i), let
u (t) ≡ui/ ln 2.
Then
a =
∞
X
i=−∞
ui =
Z ∞
0
u (t) dt
t .
(45.30)
Now
||a||q
θ,q,J
≤
Z ∞
0
¡
t−θJ (t, u (t))
¢q dt
t
=
∞
X
i=−∞
Z 2i
2i−1
³
t−θJ
³
t, ui
ln 2
´´q dt
t
≤
µ 1
ln 2
¶q
∞
X
i=−∞
Z 2i
2i−1
¡
t−θJ
¡
2i, ui
¢¢q dt
t
≤
µ 1
ln 2
¶q
∞
X
i=−∞
Z 2i
2i−1
¡
t−θ3 (1 + ε) K
¡
2i, a
¢¢q dt
t
Using the above claim,
K(2i,a)
2i
≤
K(2i−1,a)
2i−1
and so K
¡
2i, a
¢
≤2K
¡
2i−1, a
¢
. There-
fore, the above is no larger than
≤
2
µ 1
ln 2
¶q
∞
X
i=−∞
Z 2i
2i−1
¡
t−θ3 (1 + ε) K
¡
2i−1, a
¢¢q dt
t
≤
2
µ 1
ln 2
¶q
∞
X
i=−∞
Z 2i
2i−1
¡
t−θ3 (1 + ε) K (t, a)
¢q dt
t
=
2
µ3 (1 + ε)
ln 2
¶q Z ∞
0
¡
t−θK (t, a)
¢q dt
t ≡2
µ3 (1 + ε)
ln 2
¶q
||a||q
θ,q .(45.31)

1264
INTERPOLATION IN BANACH SPACE
This has shown that if a ∈(A0, A1)θ,q , then by 45.30 and 45.31, a ∈(A0, A1)θ,q,J
and
||a||q
θ,q,J ≤2
µ3 (1 + ε)
ln 2
¶q
||a||q
θ,q .
(45.32)
It remains to prove the other inclusion and norm inequality, both of which are
much easier to obtain. Thus, let a ∈(A0, A1)θ,q,J with
a =
Z ∞
0
u (t) dt
t
(45.33)
where u is a strongly measurable function having values in A0 ∩A1 and for which
Z ∞
0
¡
t−θJ (t, u (t))
¢q dt < ∞.
(45.34)
K (t, a) = K
µ
t,
Z ∞
0
u (s) ds
s
¶
≤
Z ∞
0
K (t, u (s)) ds
s .
Now by 45.26, this is dominated by an expression of the form
≤
Z ∞
0
min
µ
1, t
s
¶
J (s, u (s)) ds
s =
Z ∞
0
min
µ
1, 1
s
¶
J (ts, u (ts)) ds
s
where the equation follows from a change of variable. From Minkowski’s inequality,
||a||θ,q
≡
µZ ∞
0
¡
t−θK (t, a)
¢q dt
t
¶1/q
≤
µZ ∞
0
µ
t−θ
Z ∞
0
min
µ
1, 1
s
¶
J (ts, u (ts)) ds
s
¶q dt
t
¶1/q
≤
Z ∞
0
µZ ∞
0
µ
t−θ min
µ
1, 1
s
¶
J (ts, u (ts))
¶q dt
t
¶1/q ds
s .
Now change the variable in the inside integral to obtain, letting t = τs,
≤
Z ∞
0
min
µ
1, 1
s
¶ µZ ∞
0
¡
t−θJ (ts, u (ts))
¢q dt
t
¶1/q ds
s
=
Z ∞
0
min
µ
1, 1
s
¶
sθ ds
s
µZ ∞
0
¡
τ −θJ (τ, u (τ))
¢q dτ
τ
¶1/q
=
µ
1
(1 −θ) θ
¶ µZ ∞
0
¡
τ −θJ (τ, u (τ))
¢q dτ
τ
¶1/q
.
This has shown that
||a||θ,q ≤
µ
1
(1 −θ) θ
¶ µZ ∞
0
¡
τ −θJ (τ, u (τ))
¢q dτ
τ
¶1/q
< ∞

45.4.
DUALITY AND INTERPOLATION
1265
for all u satisfying 45.33 and 45.34. Therefore, taking the inﬁmum it follows a ∈
(A0, A1)θ,q and
||a||θ,q ≤
µ
1
(1 −θ) θ
¶
||a||θ,q,J .
This proves the theorem.
45.4
Duality And Interpolation
In this section it will be assumed that A0 ∩A1 is dense in Ai for i = 0, 1. This is
done so that A′
i ⊆(A0 ∩A1)′ and the inclusion map is continuous. Thus it makes
sense to add something in A′
0 to something in A′
1.
What is the dual space of (A0, A1)θ,q? The answer is based on the following
lemma, [8]. Remember that
J (t, a) = max
¡
||a||A0 , t ||a||A1
¢
and this is a norm on A0 ∩A1 and
K (t, a) = inf
©
||a0||A0 + t ||a1||A1 : a = a0 + a1
ª
.
As mentioned above, A′
0 + A′
1 ⊆(A0 ∩A1)′. In fact these two are equal. This is
the ﬁrst part of the following lemma.
Lemma 45.28 Suppose A0 ∩A1 is dense in Ai, i = 0, 1. Then
A′
0 + A′
1 = (A0 ∩A1)′ ,
(45.35)
and for a′ ∈A′
0 + A′
1 = (A0 ∩A1)′ ,
K (t, a′) =
sup
a∈A0∩A1
|a′ (a)|
J (t−1, a).
(45.36)
Thus K (t, ·) is an equivalent norm to the usual operator norm on (A0 ∩A1)′ taken
with respect to J
¡
t−1, ·
¢
. If, in addition to this, Ai is reﬂexive, then for a′ ∈A′
0∩A′
1,
and a ∈A0 ∩A1,
J (t, a′) K
¡
t−1, a
¢
≥|a′ (a)| .
(45.37)
Proof: First consider the claim that A′
0 + A′
1 = (A0 ∩A1)′. As noted above, ⊆
is clear. Deﬁne a norm on A0 × A1 as follows.
||(a0, a1)||A0×A1 ≡max
¡
||a0||A0 , t−1 ||a1||A1
¢
.
(45.38)
Let a′ ∈(A0 ∩A1)′. Let
E ≡{(a, a) : a ∈A0 ∩A1}

1266
INTERPOLATION IN BANACH SPACE
with the norm J
¡
t−1, a
¢
≡max
¡
||a||A0 , t−1 ||a||A1
¢
. Now deﬁne λ on E, the sub-
space of A0 × A1 by
λ ((a, a)) ≡a′ (a) .
Thus λ is a continuous linear map on E and in fact,
|λ ((a, a))| = |a′ (a)| ≤||a′|| J
¡
t−1, a
¢
.
By the Hahn Banach theorem there exists an extension of λ to all of A0 × A1. This
extension is of the form (a′
0, a′
1) ∈A′
0 × A′
1. Thus
(a′
0, a′
1) ((a, a)) = a′
0 (a) + a′
1 (a) = a′ (a)
and therefore, a′
0 + a′
1 = a′ provided a′
0 + a′
1 is continuous. But
|(a′
0 + a′
1) (a)|
=
|a′
0 (a) + a′
1 (a)| ≤|a′
0 (a)| + |a′
1 (a)|
≤
||a′
0|| ||a||A0 + ||a′
1|| ||a||A1
≤
||a′
0|| ||a||A0 + t ||a′
1|| t−1 ||a||A1
≤
(||a′
0|| + t ||a′
1||) J
¡
t−1, a
¢
which shows that a′
0 + a′
1 is continuous and in fact
||a′
0 + a′
1||(A0∩A1)′ ≤(||a′
0|| + t ||a′
1||) .
This proves the ﬁrst part of the lemma.
Claim: With this deﬁnition of the norm in 45.38, the operator norm of (a′
0, a′
1) ∈
(A0 × A1)′ = A′
0 × A′
1 is
||(a′
0, a′
1)||(A0×A1)′ = ||a′
0||A′
0 + t ||a′
1||A′
1 .
(45.39)
Proof of the claim: |(a′
0, a′
1) (a0, a1)| ≤||a′
0|| ||a0|| + ||a′
1|| ||a1|| . Now suppose
that ||a0|| = max
¡
||a0|| , t−1 ||a1||
¢
. Then this is no larger than
(||a′
0|| + t ||a′
1||) ||a0|| = (||a′
0|| + t ||a′
1||) max
¡
||a0|| , t−1 ||a1||
¢
.
The other case is that t−1 ||a1|| = max
¡
||a0|| , t−1 ||a1||
¢
. In this case,
|(a′
0, a′
1) (a0, a1)|
≤
||a′
0|| ||a0|| + ||a′
1|| ||a1||
≤
||a′
0|| t−1 ||a1|| + ||a′
1|| ||a1||
=
(||a′
0|| + t ||a′
1||) t−1 ||a1||
=
(||a′
0|| + t ||a′
1||) max
¡
||a0|| , t−1 ||a1||
¢
.
This shows ||(a′
0, a′
1)||(A0×A1)′ ≤(||a′
0|| + t ||a′
1||) . Is equality achieved?
Let a0n
and a1n be points of A0 and A1 respectively such that ||a0n|| , ||a1n|| ≤1 and
limn→∞a′
i (ain) = ||a′
i|| . Then
(a′
0, a′
1) (a0n, ta1n) →||a′
0|| + t ||a′
1||

45.4.
DUALITY AND INTERPOLATION
1267
and also, ||(a0n, ta1n)||A0×A1 = max
¡
||a0n|| , t−1t ||a1n||A1
¢
≤1. Therefore, equality
is indeed achieved and this proves the claim.
Consider 45.36. Take a′ ∈A′
0 + A′
1 = (A0 ∩A1)′ and let
E ≡{(a, a) ∈A0 × A1 : a ∈A0 ∩A1} .
Now deﬁne a linear map, λ on E as before.
λ ((a, a)) ≡a′ (a) .
If a′ = ea′
0 + ea′
1,
|λ ((a, a))|
≤
||ea′
0||A′
0 ||a||A0 + ||ea′
1||A′
1 ||a||A1
=
||ea′
0||A′
0 ||a||A0 + t ||ea′
1||A′
1 t−1 ||a||A1
≤
(||ea′
0|| + t ||ea′
1||) ||(a, a)||A0×A1
so λ is continuous on the subspace, E of A0 × A1 and
||λ||E′ ≤||ea′
0|| + t ||ea′
1|| .
(45.40)
By the Hahn Banach theorem, there exists an extension of λ deﬁned on all of A0×A1
with the same norm. Thus, from 45.39, there exists (a′
0, a′
1) ∈(A0 × A1)′ which is
an extension of λ such that
||(a′
0, a′
1)||(A0×A1)′ = ||a′
0||A′
0 + t ||a′
1||A′
1 = ||λ||E′
and for all a ∈A0 ∩A1,
a′
0 (a) + a′
1 (a) = λ ((a, a)) = a′ (a) .
It follows that a′
0 + a′
1 = a′ in (A0 ∩A1)′. Therefore, from 45.40,
||λ||E′
≤
inf
©
||ea′
0||A0 + t ||ea′
1||A1 : a′ = ea′
0 + ea′
1
ª
≡K (t, a′)
(45.41)
≤
||a′
0||A′
0 + t ||a′
1||A′
1 = ||λ||E′ ≡
sup
a∈A0∩A1
|a′ (a)|
J (t−1, a)
(45.42)
because on E, J
¡
t−1, a
¢
= ||(a, a)||A0×A1 which proves 45.36.
To obtain 45.37 in the case that Ai is reﬂexive, apply 45.36 to the case where
A′′
i plays the role of Ai in 45.36. Thus, for a′′ ∈A′′
0 + A′′
1,
K (t, a′′) =
sup
a′∈A′
0∩A′
1
|a′′ (a′)|
J (t−1, a′).
Now a′′ = a′′
1 + a′′
0 = η1a1 + η0a0 where ηi is the map from Ai to A′′
i which is onto
and preserves norms, given by ηa (a′) ≡a′ (a) . Therefore, letting a1 + a0 = a
K (t, a)
=
K (t, a′′) =
sup
a′∈A′
0∩A′
1
|a′′ (a′)|
J (t−1, a′)
=
sup
a′∈A′
0∩A′
1
|(η1a1 + η0a0) (a′)|
J (t−1, a′)
=
sup
a′∈A′
0∩A′
1
|(a′ (a1 + a0))|
J (t−1, a′)

1268
INTERPOLATION IN BANACH SPACE
and so
K (t, a) =
sup
a′∈A′
0∩A′
1
|a′ (a)|
J (t−1, a′)
Changing t →t−1,
K
¡
t−1, a
¢
J (t, a′) ≥|a′ (a)| .
which proves the lemma.
Consider (A0, A1)′
θ,q .
Deﬁnition 45.29 Let q ≥1. Then λθ,q will denote the sequences, {αi}∞
i=−∞such
that
∞
X
i=−∞
¡
|αi| 2−iθ¢q < ∞.
For α ∈λθ,q,
||α||λθ,q ≡
Ã
∞
X
i=−∞
¡
|αi| 2−iθ¢q
!1/q
.
Thus α ∈λθ,q means
©
αi2−iθª
∈lq.
Lemma 45.30 Let f (t) ≥0, and let f (t) = αi for t ∈[2i, 2i+1) where α ∈λθ,q.
Then there exists a constant, C, such that
¯¯¯¯t−θf
¯¯¯¯
Lq(0,∞; dt
t ) ≤C ||α||λθ,q .
(45.43)
Also, if whenever α ∈λθ,q, and αi ≥0 for all i,
X
i
f
¡
2i¢
2−iαi ≤C ||α||λθ,q ,
(45.44)
then
¯¯¯
¯¯¯
©
f
¡
2i¢ª∞
i=−∞
¯¯¯
¯¯¯
λ1−θ,q′ ≤C.
(45.45)
Proof: Consider 45.43.
Z ∞
0
¡
t−θf (t)
¢q dt
t =
X
i
Z 2i+1
2i
t−θqαq
i
dt
t
≤
X
i
Z 2i+1
2i
¡
2−iθαi
¢q dt
t = ln 2
X
i
¡
2−iθαi
¢q = ln 2 ||α||q
λθ,q .
45.45 is next. By 45.44, whenever α ∈λθ,q,
¯¯¯¯¯
X
i
³
f
¡
2i¢
2−(1−θ)i´
2−θiαi
¯¯¯¯¯ ≤C
¯¯¯¯©
2−θi |αi|
ª¯¯¯¯
lq .

45.4.
DUALITY AND INTERPOLATION
1269
It follows from the Riesz representation theorem that
©
f
¡
2i¢
2−(1−θ)iª
is in lq′ and
¯¯¯
¯¯¯
n
f
¡
2i¢
2−(1−θ)io¯¯¯
¯¯¯
lq′ =
¯¯¯¯©
f
¡
2i¢ª¯¯¯¯
λ1−θ,q′ ≤C.
This proves the lemma.
The dual space of (A0, A1)θ,q,J is discussed next.
Lemma 45.31 Let θ ∈(0, 1) and let q ≥1. Then,
(A0, A1)′
θ,q,J ⊆(A′
1, A′
0)1−θ,q′
and the inclusion map is continuous.
Proof: Let a′ ∈(A0, A1)′
θ,q,J . Now
A0 ∩A1 ⊆(A0, A1)θ,q,J
and if
a ∈(A0, A1)θ,q,J ,
then a has a representation of the form
a =
Z ∞
0
u (t) dt
t
where
Z ∞
0
¡
t−θJ (t, u (t))
¢q dt
t < ∞
where
J (t, u (t)) = max
¡
||u (t)||A0 , t ||u (t)||A1
¢
for u (t) ∈A0 ∩A1. Now let
ur (t) ≡
½
u (t) if t ∈
¡ 1
r, r
¢
0 otherwise
.
Then
R ∞
0
¡
t−θJ (t, ur (t))
¢q dt
t < ∞and
ar ≡
Z ∞
0
ur (t) dt
t ∈A0 ∩A1
by Lemma 45.24. Also
||a −ar||q
θ,q,J ≤
Z
1
r
0
¡
t−θJ (t, u (t))
¢q dt
t +
Z ∞
r
¡
t−θJ (t, u (t))
¢q dt
t

1270
INTERPOLATION IN BANACH SPACE
which is small whenever r is large enough thanks to the dominated convergence
theorem. Therefore, A0 ∩A1 is dense in (A0, A1)θ,q,J and so
(A0, A1)′
θ,q,J ⊆(A0 ∩A1)′ = A′
0 + A′
1,
the equality following from Lemma 45.28.
It follows a′ ∈A′
0 + A′
1 and so, by Lemma 45.28, there exists bi ∈A0 ∩A1 such
that
K
¡
2−i, a′, A′
0, A′
1
¢
−ε min
¡
1, 2−i¢
≤
a′ (bi)
J (2i, bi, A0, A1).
Now let α ∈λθ,q with αi ≥0 for all i and let
a∞≡
X
i
J
¡
2i, bi, A0, A1
¢−1 biαi.
(45.46)
Consider ﬁrst whether a∞makes sense before proceeding further.
a∞≡
X
i
bi2iθ
max
¡
||bi||A0 , 2i ||bi||A1
¢2−iθαi.
Now
¯¯¯¯¯
¯¯¯¯¯
bi2iθ
max
¡
||bi||A0 , 2i ||bi||A1
¢
¯¯¯¯¯
¯¯¯¯¯
A0+A1
≤
½ 2iθ if i < 0
2−i(1−θ) if i ≥0 .
(45.47)
This is fairly routine to verify. Consider the case where i ≥0. Then
¯¯¯¯¯
¯¯¯¯¯
bi2iθ
max
¡
||bi||A0 , 2i ||bi||A1
¢
¯¯¯¯¯
¯¯¯¯¯
A0+A1
≤
¯¯¯¯¯
¯¯¯¯¯
bi2iθ
2i ||bi||A1
¯¯¯¯¯
¯¯¯¯¯
A0+A1
≤2−i(1−θ)
because ||bi||A1 ≥||bi||A0+A1. Therefore,
M
X
i=0
¯¯¯¯¯
¯¯¯¯¯
bi2iθ
max
¡
||bi||A0 , 2i ||bi||A1
¢2−iθαi
¯¯¯¯¯
¯¯¯¯¯
A0+A1
≤
M
X
i=0
2−i(1−θ)2−iθαi ≤
Ã ∞
X
i=0
2−i(1−θ)q′
!1/q′ Ã ∞
X
i=0
2−iqθαq
i
!1/q
< ∞
and similarly,
0
X
i=−∞
¯¯¯¯¯
¯¯¯¯¯
bi2iθ
max
¡
||bi||A0 , 2i ||bi||A1
¢2−iθαi
¯¯¯¯¯
¯¯¯¯¯
A0+A1
converges. Therefore, a∞makes sense in A0 + A1 and also from 45.47, we see that
(
||bi||A0+A1 2iθ
J (2i, bi)
)
∈λ(1−θ)q′

45.4.
DUALITY AND INTERPOLATION
1271
Now let
u (t) ≡
αibi
J (2i, bi) ln 2 on [2i−1, 2i).
Then
Z ∞
0
u (t) dt
t
=
X
i
Z 2i
2i−1
αibi
J (2i, bi) ln 2
dt
t
=
X
i
αibi
J (2i, bi) = a∞.
Also
Z ∞
0
¡
t−θJ (t, u (t))
¢q dt
t ≤
X
i
Z 2i
2i−1
³
2(1−i)θJ
¡
2i, u
¡
2i−1¢¢´ dt
t
≤
X
i
h
2−(i−1)θJ
¡
2i, u
¡
2i−1¢¢iq
ln 2
=
X
i
"
2−(i−1)θ J
¡
2i, bi
¢
αi
J (2i, bi) ln 2
#q
ln 2
= C
X
i
¡
2−iθ |αi|
¢q < ∞
(45.48)
and so ||a∞||θ,q,J < ∞. Now for a′ as above, a′ ∈(A0, A1)′
θ,q,J ⊆(A0 + A1)′ , and
so since the sum for a∞converges in A0 + A1, we have
a′ (a∞) =
X
i
J
¡
2i, bi
¢−1 αia′ (bi) .
Therefore,
a′ (a∞)
≥
X
i
£
K
¡
2−i, a′¢
−ε min
¡
1, 2−i¢¤
αi
=
X
i
K
¡
2−i, a′¢
αi −
X
i
ε min
¡
1, 2−i¢
αi
=
X
i
K
¡
2−i, a′¢
αi −O (ε)
(45.49)

1272
INTERPOLATION IN BANACH SPACE
The reason for this is that α ∈λθ,q so
©
αi2−iθª
∈lq. Therefore,
X
i
ε min
¡
1, 2−i¢
αi
=
ε
( ∞
X
i=0
2−iαi +
−1
X
i=−∞
αi
)
=
ε
( ∞
X
i=0
2−iθ2(θ−1)iαi +
−1
X
i=−∞
αi2−iθ2iθ
)
≤
ε



ÃX
i
¯¯αi2−iθ¯¯q
!1/q Ã ∞
X
i=0
³
2(θ−1)i´q′!1/q′
+
ÃX
i
¯¯αi2−iθ¯¯q
!1/q Ã ∞
X
i=0
¡
2θi¢q′!1/q′


<
Cε.
Also
|a′ (a∞)| ≤||a′||(A0,A1)′
θ,q,J ||a∞||(A0,A1)θ,q,J .
Now from the deﬁnition of K,
K
¡
2−i, a′, A′
0, A′
1
¢
= 2−iK
¡
2i, a′, A′
1, A′
0
¢
and so from 45.49
X
i
2−iK
¡
2i, a′, A′
1, A′
0
¢
αi −O (ε)
≤
a′ (a∞)
≤
||a′||(A0,A1)′
θ,q,J Cθ ||α||λθ,q .
Since ε is arbitrary, it follows that whenever, α ∈λθ,q, αi ≥0,
X
i
2−iK
¡
2i, a′, A′
1, A′
0
¢
αi ≤||a′||(A0,A1)′
θ,q,J Cθ ||α||λθ,q .
By Lemma 45.30,
©
K
¡
2i, a′, A′
1, A′
0
¢ª
∈λ1−θ,q′ and
¯¯¯¯©
K
¡
2i, a′, A′
1, A′
0
¢ª¯¯¯¯
λ1−θ,q′ ≤||a′||(A0,A1)′
θ,q,J Cθ.

45.4.
DUALITY AND INTERPOLATION
1273
Therefore,
µ 1
ln 2
Z ∞
0
³
K (t, a′, A′
1, A′
0) t−(1−θ)´q′ dt
t
¶1/q′
=
ÃX
i
1
ln 2
Z 2i+1
2i
³
K (t, a′, A′
1, A′
0) t−(1−θ)´q′ dt
t
!1/q′
≤
ÃX
i
³
2−i(1−θ)K
¡
2i, a′, A′
1, A′
0
¢´q′!1/q′
≤
||a′||(A0,A1)′
θ,q,J Cθ.
Thus
||a′||(A′
1,A′
0)1−θ,q′
≡
¯¯¯
¯¯¯t−(1−θ)K (t, a′, A′
1, A′
0)
¯¯¯
¯¯¯
Lq′(0,∞, dt
t )
≤
C ||a′||(A0,A1)′
θ,q,J
which shows that (A0, A1)′
θ,q,J ⊆(A′
1, A′
0)1−θ,q′ with the inclusion map continuous.
This proves the lemma.
Lemma 45.32 If Ai is reﬂexive for i = 0, 1 and if A0 ∩A1 is dense in Ai, then
(A′
1, A′
0)1−θ,q′,J ⊆(A0, A1)′
θ,q
and the inclusion map is continuous.
Proof: Let a′ ∈(A′
1, A′
0)1−θ,q′,J . Thus, there exists u∗bounded on compact
subsets of (0, ∞) and measurable with values in A0 ∩A1 and
a′ =
Z ∞
0
u∗(t) dt
t ,
(45.50)
Z ∞
0
³
t−(1−θ)J (t, u∗(t))
´q′ dt
t < ∞.
Then
a′ =
∞
X
i=−∞
Z 2i+1
2i
u∗(t) dt
t ≡
∞
X
i=−∞
a′
i
where a′
i ∈A′
1 ∩A′
0, the convergence taking place in A′
1 + A′
0. Now let a ∈A0 ∩A1.

1274
INTERPOLATION IN BANACH SPACE
From Lemma 45.28
|a′ (a)|
≤
∞
X
i=−∞
|a′
i (a)|
≤
∞
X
i=−∞
J
¡
2−i, a′
i, A′
0, A′
1
¢
K
¡
2i, a, A0, A1
¢
=
∞
X
i=−∞
2−iJ
¡
2i, a′
i, A′
1, A′
0
¢
K
¡
2i, a, A0, A1
¢
≤
ÃX
i
³
2−(1−θ)iJ
¡
2i, a′
i, A′
1, A′
0
¢´q′!1/q′
·
ÃX
i
¡
2−θiK
¡
2i, a, A0, A1
¢¢q
!1/q
≤
C
·Z ∞
0
³
t−(1−θ)J (t, u∗(t) , A′
1, A′
0)
´q′ dt
t
¸1/q′
·
·Z ∞
0
¡
t−θK (t, a, A0, A1)
¢q dt
t
¸1/q
.
In going from the sums to the integrals, express the ﬁrst sum as a sum of integrals
on [2i, 2i+1) and the second sum as a sum of integrals on (2i−1, 2i].
Taking the inﬁmum over all u∗representing a′,
|a′ (a)| ≤C ||a′||(A′
1,A′
0)1−θ,q′,J ||a||θ,q .
It follows a′ ∈(A0, A1)′
θ,q and ||a′||(A0,A1)′
θ,q ≤C ||a′||(A′
1,A′
0)1−θ,q′,J which proves
the lemma.
With these two lemmas the main result follows.
Theorem 45.33 Suppose A0 ∩A1 is dense in Ai and Ai is reﬂexive. Then
(A′
1, A′
0)1−θ,q′ = (A0, A1)′
θ,q
and the norms are equivalent.
Proof: By Theorem 45.27, and the last two lemmas,
(A0, A1)′
θ,q
=
(A0, A1)′
θ,q,J ⊆(A′
1, A′
0)1−θ,q′
=
(A′
1, A′
0)1−θ,q′,J ⊆(A0, A1)′
θ,q .
This proves the theorem.

Trace Spaces
46.1
Deﬁnition And Basic Theory Of Trace Spaces
As in the case of interpolation spaces, suppose A0 and A1 are two Banach spaces
which are continuously embedded in some topological vector space, X.
Deﬁnition 46.1 Deﬁne a norm on A0 + A1 as follows.
||a||A0+A1 ≡inf
©
||a0||A0 + ||a1||A1 : a0 + a1 = a
ª
(46.1)
Lemma 46.2 A0 + A1 with the norm just described is a Banach space.
Proof: This was already explained in the treatment of the K method of inter-
polation. It is just K (1, a) .
Deﬁnition 46.3 Take f ′ in the sense of distributions for any
f ∈L1
loc (0, ∞; A0 + A1)
as follows.
f ′ (φ) ≡
Z ∞
0
−f (t) φ′ (t) dt
whenever φ ∈C∞
c (0, ∞) . Deﬁne a Banach space, W (A0, A1, p, θ) = W where
p ≥1, θ ∈(0, 1). Let
||f||W ≡max
³¯¯¯¯tθf
¯¯¯¯
Lp(0,∞, dt
t ;A0) ,
¯¯¯¯tθf ′¯¯¯¯
Lp(0,∞, dt
t ;A1)
´
(46.2)
and let W consist of f ∈L1
loc (0, ∞; A0 + A1) such that ||f||W < ∞.
Note that to be in W, f (t) ∈A0 and f ′ (t) ∈A1.
Lemma 46.4 If f ∈W, then
Trace (f) ≡f (0) ≡lim
t→0 f (t)
exists in A0 + A1. Also Z ≡{f ∈W : f (0) = 0} is a closed subspace of W.
1275

1276
TRACE SPACES
Proof: Let 0 < s < t. Let ν + 1
p = θ. Then
Z ∞
0
||τ νg (τ)||p dτ =
Z ∞
0
¯¯¯¯τ θg (τ)
¯¯¯¯p dτ
τ
so that tνf ′ ∈Lp (0, ∞; A1) , the measure in this case being usual Lebesgue measure.
Then
f (t) −f (s) =
Z t
s
f ′ (τ) dτ =
Z t
s
τ νf ′ (τ) τ −νdτ.
For 1
p + 1
p′ = 1, νp′ =
³
θ −1
p
´
p′ < 1 because θ < 1 = 1
p′ + 1
p. Therefore,
||f (t) −f (s)||A0+A1
≤
Z t
s
||f ′ (τ)||A0+A1 dτ
(46.3)
≤
Z t
s
||f ′ (τ)||A1 dτ =
Z t
s
||τ νf ′ (τ)||A1 τ −νdτ
≤
µZ t
s
||τ νf ′ (τ)||p
A1 dτ
¶1/p µZ t
s
τ −νp′dτ
¶1/p′
≤
||f||W
Ã
t1−νp′
1 −νp′ −s1−νp′
1 −νp′
!
(46.4)
≤
||f||W
t1−νp′
1 −νp′ .
which converges to 0 as t →0. This shows that limt→0+ f (t) exists in A0 + A1.
Clearly Z is a subspace. Let fn →f in W and suppose fn ∈Z. Then since
f ∈W, 46.4 implies f is continuous. Using 46.4 and replacing f with fn −fm and
then taking a limit as s →0,
||fn (t) −fm (t)||A0+A1 ≤||fn −fm||W Cνt1−νp′
Taking a subsequence, it can be assumed fn (t) converges to f (t) a.e.
But the
above inequality shows that fn (t) is a Cauchy sequence in C ([0, β] ; A0 + A1) for
all β < ∞. Therefore, fn (t) →f (t) for all t. Also,
||fn (t)||A0+A1 ≤Cν ||fn||W t1−νp′ ≤Kt1−νp′
for some K depending on max {||fn|| : n ≥1} and so
||f (t)||A0+A1 ≤Kt1−νp′
which implies f (0) = 0. Thus Z is closed.
Deﬁnition 46.5 Let W be a Banach space and let Z be a closed subspace. Then
the quotient space, denoted by W/Z consists of the set of equivalence classes [x]

46.1.
DEFINITION AND BASIC THEORY OF TRACE SPACES
1277
where the equivalence relation is deﬁned by x ∽y means x −y ∈Z. Then W/Z is
a vector space if the operations are deﬁned by α [x] ≡[αx] and [x] + [y] ≡[x + y]
and these vector space operations are well deﬁned. The norm on the quotient space
is deﬁned as ||[x]|| ≡inf {||x + z|| : z ∈Z} .
The veriﬁcation of the algebraic claims made in the above deﬁnition is left to
the reader. It is routine. What is not as routine is the following lemma. However,
it is similar to some topics in the presentation of the K method of interpolation.
Lemma 46.6 Let W be a Banach space and let Z be a closed subspace of W. Then
W/Z with the norm described above is a Banach space.
Proof: That W/Z is a vector space is left to the reader. Why is ||·|| a norm?
Suppose α ̸= 0. Then
||α [x]||
=
||[αx]|| ≡inf {||αx + z|| : z ∈Z}
=
inf {||αx + αz|| : z ∈Z}
=
|α| inf {||x + z|| : z ∈Z} = |α| ||[x]|| .
Now let ||[x]|| ≥||x + z1|| −ε and let ||[y]|| ≥||y + z2|| −ε where zi ∈Z. Then
||[x] + [y]||
≡
||[x + y]|| ≤||x + y + z1 + z2||
≤
||x + z1|| + ||y + z2|| ≤||[x]|| + ||[y]|| + 2ε.
Since ε is arbitrary, this shows the triangle inequality. Clearly, ||[x]|| ≥0. It remains
to show that the only way ||[x]|| = 0 is for x ∈Z. Suppose then that ||[x]|| = 0.
This means there exist zn ∈Z such that ||x + zn|| →0. Therefore, −x is a limit of
a sequence of points of Z and since Z is closed, this requires −x ∈Z. Hence x ∈Z
also because Z is a subspace. This shows ||·|| is a norm on W/Z. It remains to
verify that W/Z is a Banach space.
Suppose {[xn]} is a Cauchy sequence in W/Z and suppose ||[xn] −[xn+1]|| <
1
2n+1 . Let x′
1 = x1. If x′
n has been chosen let x′
n+1 = xn+1 + zn+1 where zn+1 ∈Z
be such that
¯¯¯¯x′
n+1 −x′
n
¯¯¯¯
≤
||[xn+1 −xn]|| +
1
2(n+1)
=
||[xn+1] −[xn]|| +
1
2(n+1) < 1
2n .
It follows {x′
n} is a Cauchy sequence in W and so it must converge to some x ∈W.
Now
||[x] −[xn]|| = ||[x −xn]|| = ||[x −x′
n]|| ≤||x −x′
n||
which converges to 0.
Now if {[xn]} is just a Cauchy sequence, there exists a
subsequence satisfying
¯¯¯¯[xnk] −
£
xnk+1
¤¯¯¯¯ <
1
2k+1 and so from the ﬁrst part, the
subsequence converges to some [x] ∈W/Z and so the original Cauchy sequence also
converges. therefore, W/Z is a Banach space as claimed.

1278
TRACE SPACES
Deﬁnition 46.7 Deﬁne T (A0, A1, p, θ) = T, to consist of
½
a ∈A0 + A1 : a = lim
t→0+ f (t) for some f ∈W (A0, A1, p, θ)
¾
,
the limit taking place in A0+A1. Let γf be deﬁned for f ∈W by γf ≡limt→0+ f (t) .
Thus T = γ (W) . As above Z ≡{f ∈W : γf = 0} = ker (γ) .
Lemma 46.8 T is a Banach space with norm given by
||a||T ≡inf {||f||W : f (0) = a} .
(46.5)
Proof: Deﬁne a mapping, ψ : W/Z →T by
ψ ([f]) ≡γf.
Then ψ is one to one and onto. Also
||[f]|| ≡inf {||f + g|| : g ∈Z} = inf {||h||W : γh = γf} = ||γ (f)||T .
Therefore, the Banach space, W/Z and T are isometric and so T must be a Banach
space since W/Z is.
The following is an important interpolation inequality.
Theorem 46.9 If a ∈T, then
||a||T = inf
n¯¯¯¯tθf
¯¯¯¯1−θ
Lp(0,∞, dt
t ;A0)
¯¯¯¯tθf ′¯¯¯¯θ
Lp(0,∞, dt
t ;A1)
o
(46.6)
where the inﬁmum is taken over all f ∈W such that a = f (0) . Also, if a ∈A0∩A1,
then a ∈T and
||a||T ≤K ||a||1−θ
A1 ||a||θ
A0
(46.7)
for some constant K. Also
A0 ∩A1 ⊆T (A0, A1, p, θ) ⊆A0 + A1
(46.8)
and the inclusion maps are continuous.
Proof: First suppose f (0) = a where f ∈W. Then letting fλ (t) ≡f (λt) , it
follows that fλ (0) = a also and so
||a||T
≤
max
³¯¯¯¯tθfλ
¯¯¯¯
Lp(0,∞, dt
t ;A0) ,
¯¯¯¯tθ (fλ)′¯¯¯¯
Lp(0,∞, dt
t ;A1)
´
=
max
³
λ−θ ¯¯¯¯tθf
¯¯¯¯
Lp(0,∞, dt
t ;A0) , λ1−θ ¯¯¯¯tθf ′¯¯¯¯
Lp(0,∞, dt
t ;A1)
´
≡
max
³
λ−θR, λ1−θS
´
.
Now choose λ = R/S to obtain
||a||T ≤R1−θSθ =
¯¯¯¯tθf
¯¯¯¯1−θ
Lp(0,∞, dt
t ;A0)
¯¯¯¯tθf ′¯¯¯¯θ
Lp(0,∞, dt
t ;A1) .

46.1.
DEFINITION AND BASIC THEORY OF TRACE SPACES
1279
Thus
||a||T ≤inf
n¯¯¯¯tθf
¯¯¯¯1−θ
Lp(0,∞, dt
t ;A0)
¯¯¯¯tθf ′¯¯¯¯θ
Lp(0,∞, dt
t ;A1)
o
.
Next choose f ∈W such that f (0) = a and ||f||W ≈||a||T . More precisely, pick
f ∈W such that f (0) = a and ||a||T > −ε + ||f||W . Also let
R ≡
¯¯¯¯tθf
¯¯¯¯
Lp(0,∞, dt
t ;A0) , S ≡
¯¯¯¯tθf ′¯¯¯¯
Lp(0,∞, dt
t ;A1) .
Then as before,
¯¯¯¯tθfλ
¯¯¯¯
Lp(0,∞, dt
t ;A0) = λ−θR,
¯¯¯¯tθ (fλ)′¯¯¯¯
Lp(0,∞, dt
t ;A1) = λ1−θS.
(46.9)
so that ||f||W = max (R, S) . Then, changing the variables, letting λ = R/S,
¯¯¯¯tθfλ
¯¯¯¯
Lp(0,∞, dt
t ;A0) =
¯¯¯¯tθ (fλ)′¯¯¯¯
Lp(0,∞, dt
t ;A1) = R1−θSθ
(46.10)
Since fλ (0) = a, fλ ∈W, and it is always the case that for positive R, S, R1−θSθ ≤
max (R, S) , this shows that
||a||T
≤
max
³¯¯¯¯tθfλ
¯¯¯¯
Lp(0,∞, dt
t ;A0) ,
¯¯¯¯tθ (fλ)′¯¯¯¯
Lp(0,∞, dt
t ;A1)
´
=
R1−θSθ ≤max (R, S) = ||f||W < ||a||T + ε,
the ﬁrst inequality holding because ||a||T is the inﬁmum of such things on the right.
This shows 46.6.
It remains to verify 46.7.
To do this, let ψ ∈C∞([0, ∞)) , with ψ (0) = 1
and ψ (t) = 0 for all t > 1. Then consider the special f ∈W which is given by
f (t) ≡aψ (t) where a ∈A0 ∩A1. Thus f ∈W and f (0) = a so a ∈T (A0, A1, p, θ) .
From the ﬁrst part, there exists a constant, K such that
||a||T
≤
¯¯¯¯tθf
¯¯¯¯1−θ
Lp(0,∞, dt
t ;A0)
¯¯¯¯tθf ′¯¯¯¯θ
Lp(0,∞, dt
t ;A1)
≤
K ||a||1−θ
A0 ||a||θ
A1
This shows 46.7 and the ﬁrst inclusion in 46.8. From the inequality just obtained,
||a||T
≤
K
¡
(1 −θ) ||a||A0 + θ ||a||A1
¢
≤
K ||a||A0∩A1 .
This shows the ﬁrst inclusion map of 46.8 is continuous.
Now take a ∈T. Let f ∈W
be such that a = f (0) and
||a||T + ε > ||f||W ≥||a||T .
By 46.4,
||a −f (t)||A0+A1 ≤Cνt1−νp′ ||f||W

1280
TRACE SPACES
where 1
p + ν = θ, and so
||a||A0+A1 ≤||f (t)||A0+A1 + Cνt1−νp′ ||f||W .
Now ||f (t)||A0+A1 ≤||f (t)||A0 .
||a||A0+A1
≤
tν ||f (t)||A0+A1 t−ν + Cνt1−νp′ ||f||W
≤
tν ||f (t)||A0 t−ν + Cνt1−νp′ ||f||W
Therefore, recalling that νp′ < 1, and integrating both sides from 0 to 1,
||a||A0+A1 ≤Cν ||f||W ≤Cν (||a||T + ε) .
To see this,
Z 1
0
tν ||f (t)||A0 t−νdt
≤
µZ 1
0
¡
tν ||f (t)||A0
¢p dt
¶1/p µZ 1
0
t−νp′dt
¶1/p′
≤
C ||f||W .
Since ε > 0 is arbitrary, this veriﬁes the second inclusion and continuity of the
inclusion map completing the proof of the theorem.
The interpolation inequality, 46.7 is very signiﬁcant. The next result concerns
bounded linear transformations.
Theorem 46.10 Now suppose A0, A1 and B0, B1 are pairs of Banach spaces such
that Ai embeds continuously into a topological vector space, X and Bi embeds con-
tinuously into a topological vector space, Y. Suppose also that L ∈L (A0, B0) and
L ∈L (A1, B1) where the operator norm of L in these spaces is Ki, i = 0, 1. Then
L ∈L (A0 + A1, B0 + B1)
(46.11)
with
||La||B0+B1 ≤max (K0, K1) ||a||A0+A1
(46.12)
and
L ∈L (T (A0, A1, p, θ) , T (B0, B1, p, θ))
(46.13)
and for K the operator norm,
K ≤K1−θ
0
Kθ
1.
(46.14)
Proof: To verify 46.11, let a ∈A0 +A1 and pick a0 ∈A0 and a1 ∈A1 such that
||a||A0+A1 + ε > ||a0||A0 + ||a1||A1 .
Then
||L (a)||B0+B1 = ||La0 + La1||B0+B1 ≤||La0||B0 + ||La1||B1

46.2.
EQUIVALENCE OF TRACE AND INTERPOLATION SPACES
1281
≤K0 ||a0||A0 + K1 ||a1||A1 ≤max (K0, K1)
¡
||a||A0+A1 + ε
¢
.
This establishes 46.12. Now consider the other assertions.
Let a ∈T (A0, A1, p, θ) and pick f ∈W (A0, A1, p, θ) such that γf = a and
||a||T (A0,A1,p,θ) + ε >
¯¯¯¯tθf
¯¯¯¯1−θ
Lp(0,∞, dt
t ,A0)
¯¯¯¯tθf ′¯¯¯¯θ
Lp(0,∞, dt
t ,A1) .
Then consider Lf. Since L is continuous on A0 + A1,
Lf (0) = La
and Lf ∈W (B0, B1, p, θ) . Therefore, by Theorem 46.9,
||La||T (B0,B1,p,θ)
≤
¯¯¯¯tθLf
¯¯¯¯1−θ
Lp(0,∞, dt
t ,A0)
¯¯¯¯tθLf ′¯¯¯¯θ
Lp(0,∞, dt
t ,A1)
≤
K1−θ
0
Kθ
1
¯¯¯¯tθf
¯¯¯¯1−θ
Lp(0,∞, dt
t ,A0)
¯¯¯¯tθf ′¯¯¯¯θ
Lp(0,∞, dt
t ,A1)
≤
K1−θ
0
Kθ
1
³
||a||T (A0,A1,p,θ) + ε
´
.
and since ε > 0 is arbitrary, this proves the theorem.
46.2
Equivalence Of Trace And Interpolation Spaces
Trace spaces are equivalent to interpolation spaces. In showing this, a more general
sort of trace space than that presented earlier will be used.
Deﬁnition 46.11 Deﬁne for m a positive integer, V m = V m (A0, A1, p, θ) to be
the set of functions, u such that
t →tθu (t) ∈Lp
µ
0, ∞, dt
t ; A0
¶
(46.15)
and
t →tθ+m−1u(m) (t) ∈Lp
µ
0, ∞, dt
t ; A1
¶
.
(46.16)
V m is a Banach space with the norm
||u||V m ≡max
µ¯¯¯¯tθu (t)
¯¯¯¯
Lp(0,∞, dt
t ;A0) ,
¯¯¯
¯¯¯tθ+m−1u(m) (t)
¯¯¯
¯¯¯
Lp(0,∞, dt
t ;A1)
¶
.
Thus V m equals W in the case when m = 1. More generally, as in [8] diﬀerent
exponents are used for the two Lp spaces, p0 in place of p for the space corresponding
to A0 and p1 in place of p for the space corresponding to A1.
Deﬁnition 46.12 Denote by T m (A0, A1, p, θ) the set of all a ∈A0 + A1 such that
for some u ∈V m,
a = lim
t→0+ u (t) ≡trace (u) ,
(46.17)
the limit holding in A0 + A1. For the norm
||a||T m ≡inf {||u||V m : trace (u) = a} .
(46.18)

1282
TRACE SPACES
The case when m = 1 was discussed in Section 46.1. Note it is not known at
this point whether limt→0+ u (t) even exists for every u ∈V m. Of course, if m = 1
this was shown earlier but it has not been shown for m > 1. The following theorem
is absolutely amazing. Note the lack of dependence on m of the right side!
Theorem 46.13 The following hold.
T m (A0, A1, p, θ) = (A0, A1)θ,p,J = (A0, A1)θ,p .
(46.19)
Proof: It is enough to show the ﬁrst equality because of Theorem 45.27 which
identiﬁes (A0, A1)θ,p,J and (A0, A1)θ,p. Let a ∈T m. Then there exists u ∈V m such
that
a = lim
t→0+ u (t) in A0 + A1.
The ﬁrst task is to modify this u (t) to get a better one which is more usable in
order to show a ∈(A0, A1)θ,p,J. Remember, it is required to ﬁnd w (t) ∈A0 ∩A1
for all t ∈(0, ∞) and a =
R ∞
0
w (t) dt
t , a representation which is not known at this
time. To get such a thing, let
φ ∈C∞
c (0, ∞) , spt (φ) ⊆[α, β]
(46.20)
with φ ≥0 and
Z ∞
0
φ (t) dt
t = 1.
(46.21)
Then deﬁne
eu (t) ≡
Z ∞
0
φ
µ t
τ
¶
u (τ) dτ
τ =
Z ∞
0
φ (s) u
µ t
s
¶ ds
s .
(46.22)
Claim: limt→0+ eu (t) = a and limt→∞eu(k) (t) = 0 in A0 + A1 for all k ≤m.
Proof of the claim: From 46.22 and 46.21 it follows that for ||·|| referring to
||·||A0+A1 ,
||eu (t) −a||
≤
Z ∞
0
¯¯¯¯
¯¯¯¯u
µ t
s
¶
−a
¯¯¯¯
¯¯¯¯ φ (s) ds
s
=
Z ∞
0
||u (τ) −a|| φ
µ t
τ
¶ dτ
τ
=
Z t/α
t/β
||u (τ) −a|| φ
µ t
τ
¶ dτ
τ
≤
Z t/α
t/β
εφ
µ t
τ
¶ dτ
τ = ε
Z β
α
φ (s) ds
s = ε
whenever t is small enough due to the convergence of u (t) to a in A0 + A1.
Now consider what occurs when t →∞. For ||·|| referring to the norm in A0,
eu(k) (t) =
Z ∞
0
φ(k)
µ t
τ
¶ 1
τ k u (τ) dτ
τ

46.2.
EQUIVALENCE OF TRACE AND INTERPOLATION SPACES
1283
and so
¯¯¯
¯¯¯eu(k) (t)
¯¯¯
¯¯¯
A0
≤Ck
Z t/α
t/β
||u (τ)||A0
dτ
τ
≤C
ÃZ t/α
t/β
dτ
τ
!1/p′ ÃZ t/α
t/β
||u (τ)||p
A0
dτ
τ
!1/p
.
Now
³
β
t
´θ
τ θ ≥1 for τ ≥t/β and so the above expression
≤C
µ
ln β
α
¶1/p′ µβ
t
¶θ ÃZ ∞
t/β
¡
τ θ ||u (τ)||A0
¢p dτ
τ
!1/p
and so limt→∞
¯¯¯¯eu(k) (t)
¯¯¯¯
A0 = 0 and therefore, this also holds in A0 + A1. This
proves the claim.
Thus eu has the same properties as u in terms of having a as its trace. eu is used
to build the desired w, representing a as an integral. Deﬁne
v (t) ≡(−1)m tm
(m −1)! eu(m) (t) =
(−1)m
(m −1)!
Z ∞
0
tm
τ m φ(m)
µ t
τ
¶
u (τ) dτ
τ
=
(−1)m
(m −1)!
Z ∞
0
smφ(m) (s) u
µ t
s
¶ ds
s .
(46.23)
Then from the claim, and integration by parts in the last step,
Z ∞
0
v
µ1
t
¶ dt
t =
Z ∞
0
v (t) dt
t =
(−1)m
(m −1)!
Z ∞
0
tm−1eu(m) (t) dt = a.
(46.24)
Thus v
¡ 1
t
¢
represents a in the way desired for (A0, A1)θ,p,J if it is also true that
v
¡ 1
t
¢
∈A0 ∩A1 and t →t−θv
¡ 1
t
¢
is in Lp ¡
0, ∞, dt
t ; A0
¢
and t →t1−θv
¡ 1
t
¢
is in
Lp ¡
0, ∞, dt
t ; A1
¢
. First consider whether v (t) ∈A0 ∩A1. v (t) ∈A0 for each t from
46.23 and the assumption that u ∈Lp ¡
0, ∞, dt
t ; A0
¢
. To verify v (t) ∈A1, integrate
by parts in 46.23 to obtain
v (t) =
(−1)m
(m −1)!
Z ∞
0
φ(m) (s)
µ
sm−1u
µ t
s
¶¶
ds
(46.25)
=
1
(m −1)!
Z ∞
0
φ (s) dm
dsm
µ
sm−1u
µ t
s
¶¶
ds
=
(−1)m
(m −1)!
Z ∞
0
φ (s)
tm
sm+1 u(m)
µ t
s
¶
ds ∈A1

1284
TRACE SPACES
The last step may look very mysterious. If so, consider the case where m = 2.
φ (s)
µ
su
µ t
s
¶¶′′
=
φ (s)
µ
−t
su′
µ t
s
¶
+ u
µ t
s
¶¶′
=
φ (s)
µµ
−t
s
¶
u′′
µ t
s
¶ µ
−t
s2
¶
+ t
s2 u′
µ t
s
¶
−t
s2 u′
µ t
s
¶¶
=
φ (s) t2
s3 u′′
µ t
s
¶
.
You can see the same pattern will take place for other values of m.
Now
||a||θ,p,J ≤
µZ ∞
0
µ
t−θJ
µ
t, v
µ1
t
¶¶¶p dt
t
¶1/p
≤Cp
(Z ∞
0
"Ã
t−θ
¯¯¯¯
¯¯¯¯v
µ1
t
¶¯¯¯¯
¯¯¯¯
A0
!
+
Ã
t1−θ
¯¯¯¯
¯¯¯¯v
µ1
t
¶¯¯¯¯
¯¯¯¯
A1
!#p
dt
t
)1/p
≤Cp



ÃZ ∞
0
Ã
t−θ
¯¯¯¯
¯¯¯¯v
µ1
t
¶¯¯¯¯
¯¯¯¯
A0
!p
dt
t
!1/p
+
ÃZ ∞
0
Ã
t1−θ
¯¯¯¯
¯¯¯¯v
µ1
t
¶¯¯¯¯
¯¯¯¯
A1
!p
dt
t
!1/p

.
(46.26)
The ﬁrst term equals
ÃZ ∞
0
Ã
t−θ
¯¯¯¯
¯¯¯¯v
µ1
t
¶¯¯¯¯
¯¯¯¯
A0
!p
dt
t
!1/p
=
µZ ∞
0
¡
tθ ||v (t)||A0
¢p dt
t
¶1/p
=
ÃZ ∞
0
Ã
tθ
¯¯¯¯
¯¯¯¯
Z ∞
0
smφ(m) (s) u
µ t
s
¶ ds
s
¯¯¯¯
¯¯¯¯
A0
!p
dt
t
!1/p
≤
Z ∞
0
ÃZ ∞
0
Ã
tθsm ¯¯¯φ(m) (s)
¯¯¯
¯¯¯¯
¯¯¯¯u
µ t
s
¶¯¯¯¯
¯¯¯¯
A0
!p
dt
t
!1/p
ds
s
≤
Z ∞
0
sm ¯¯¯φ(m) (s)
¯¯¯
ÃZ ∞
0
Ã
tθ
¯¯¯¯
¯¯¯¯u
µ t
s
¶¯¯¯¯
¯¯¯¯
A0
!p
dt
t
!1/p
ds
s

46.2.
EQUIVALENCE OF TRACE AND INTERPOLATION SPACES
1285
=
Z ∞
0
sθ+m ¯¯¯φ(m) (s)
¯¯¯ ds
s
µZ ∞
0
¡
τ θ ||u (τ)||A0
¢p dτ
τ
¶1/p
= C
µZ ∞
0
¡
τ θ ||u (τ)||A0
¢p dτ
τ
¶1/p
.
(46.27)
The second term equals
ÃZ ∞
0
Ã
t1−θ
¯¯¯¯
¯¯¯¯v
µ1
t
¶¯¯¯¯
¯¯¯¯
A1
!p
dt
t
!1/p
=
µZ ∞
0
¡
tθ−1 ||v (t)||A1
¢p dt
t
¶1/p
=
ÃZ ∞
0
Ã
tθ−1
¯¯¯¯
¯¯¯¯
1
(m −1)!
Z ∞
0
φ (s) tm
sm u(m)
µ t
s
¶ ds
s
¯¯¯¯
¯¯¯¯
A1
!p
dt
t
!1/p
≤
Z ∞
0
ÃZ ∞
0
Ãµtθ+m−1
sm
¶
|φ (s)|
¯¯¯¯
¯¯¯¯u(m)
µ t
s
¶¯¯¯¯
¯¯¯¯
A1
!p
dt
t
!1/p
ds
s
≤
Z ∞
0
|φ (s)|
sm
ÃZ ∞
0
Ã
tθ+m−1
¯¯¯¯
¯¯¯¯u(m)
µ t
s
¶¯¯¯¯
¯¯¯¯
A1
!p
dt
t
!1/p
ds
s
=
Z ∞
0
|φ (s)|
sm
sθ+m−1
µZ ∞
0
µ
τ θ+m−1 ¯¯¯
¯¯¯u(m) (τ)
¯¯¯
¯¯¯
A1
¶p dτ
τ
¶1/p ds
s
= C
µZ ∞
0
µ
τ θ+m−1 ¯¯¯
¯¯¯u(m) (τ)
¯¯¯
¯¯¯
A1
¶p dτ
τ
¶1/p
.
(46.28)
Now from the estimates on the two terms in 46.26 found in 46.27 and 46.28, and
the simple estimate,
2 max (α, β) ≥α + β,
it follows
||a||θ,p,J
(46.29)
≤
C max
ÃµZ ∞
0
¡
τ θ ||u (τ)||A0
¢p dτ
τ
¶1/p
(46.30)
,
µZ ∞
0
µ
τ θ+m−1 ¯¯¯
¯¯¯u(m) (τ)
¯¯¯
¯¯¯
A1
¶p dτ
τ
¶1/p!
(46.31)
which shows that after taking the inﬁmum over all u whose trace is a, it follows
a ∈(A0, A1)θ,p,J .
||a||θ,p,J ≤C ||a||T m
(46.32)
Thus T m (A0, A1, θ, p) ⊆(A0, A1)θ,p,J .

1286
TRACE SPACES
Is (A0, A1)θ,p,J ⊆T m (A0, A1, θ, p)? Let a ∈(A0, A1)θ,p,J . There exists u having
values in A0 ∩A1 and such that
a =
Z ∞
0
u (t) dt
t =
Z ∞
0
u
µ1
t
¶ dt
t ,
in A0 + A1 such that
Z ∞
0
¡
t−θJ (t, u (t))
¢p dt < ∞, where J (t, a) = max
¡
||a||A0 , t ||a||A1
¢
.
Then let
w (t) ≡
Z ∞
t
µ
1 −t
τ
¶m−1
u
µ1
τ
¶ dτ
τ =
(46.33)
Z 1/t
0
(1 −st)m−1 u (s) ds
s =
Z 1
0
(1 −τ)m−1 u
³τ
t
´ dτ
τ .
(46.34)
It is routine to verify from 46.33 that
w(m) (t) = (m −1)! (−1)m u
¡ 1
t
¢
tm .
(46.35)
For example, consider the case where m = 2.
µZ ∞
t
µ
1 −t
τ
¶
u
µ1
τ
¶ dτ
τ
¶′′
=
µ
0 +
Z ∞
t
µ
−1
τ
¶
u
µ1
τ
¶ dτ
τ
¶′
=
1
t2 u
µ1
t
¶
.
Also from 46.33, it follows that trace (w) = a. It remains to verify w ∈V m.
From 46.35,
µZ ∞
0
µ
tθ+m−1 ¯¯¯
¯¯¯w(m) (t)
¯¯¯
¯¯¯
A1
¶p dt
t
¶1/p
=
Cm
ÃZ ∞
0
Ã
tθ−1
¯¯¯¯
¯¯¯¯u
µ1
t
¶¯¯¯¯
¯¯¯¯
A1
!p
dt
t
!1/p
= Cm
µZ ∞
0
¡
t1−θ ||u (t)||A1
¢p dt
t
¶1/p
≤Cm
µZ ∞
0
¡
t−θJ (t, u (t))
¢p dt
t
¶1/p
< ∞.
(46.36)
It remains to consider
¡R ∞
0
¡
tθ ||w (t)||A0
¢p dt
t
¢1/p . From 46.34,
µZ ∞
0
¡
tθ ||w (t)||A0
¢p dt
t
¶1/p
=
ÃZ ∞
0
Ã
tθ
¯¯¯¯
¯¯¯¯
Z 1
0
(1 −τ)m−1 u
³τ
t
´ dτ
τ
¯¯¯¯
¯¯¯¯
A0
!p
dt
t
!1/p

46.2.
EQUIVALENCE OF TRACE AND INTERPOLATION SPACES
1287
=
ÃZ ∞
0
Ã
t−θ
¯¯¯¯
¯¯¯¯
Z 1
0
(1 −τ)m−1 u (τt) dτ
τ
¯¯¯¯
¯¯¯¯
A0
!p
dt
t
!1/p
≤
Z 1
0
µZ ∞
0
³
t−θ (1 −τ)m−1 ||u (τt)||A0
´p dt
t
¶1/p dτ
τ
=
Z 1
0
τ θ (1 −τ)m−1
µZ ∞
0
¡
s−θ ||u (s)||A0
¢p ds
s
¶1/p dτ
τ
=
µZ 1
0
τ θ−1 (1 −τ)m−1 dτ
¶ µZ ∞
0
¡
s−θ ||u (s)||A0
¢p ds
s
¶1/p
≤C
µZ ∞
0
¡
s−θ ||u (s)||A0
¢p ds
s
¶1/p
≤C
µZ ∞
0
¡
t−θJ (t, u (t))
¢p dt
¶1/p
< ∞.
(46.37)
It follows that
||w||V m ≡
max
ÃµZ ∞
0
¡
tθ ||w (t)||A0
¢p dt
t
¶1/p
,
µZ ∞
0
µ
tθ+m−1 ¯¯¯
¯¯¯w(m) (t)
¯¯¯
¯¯¯
A1
¶p dt
t
¶1/p!
≤C
µZ ∞
0
¡
t−θJ (t, u (t))
¢p dt
¶1/p
< ∞
which shows that a ∈T m (A0, A1, θ, p) . Taking the inﬁmum,
||a||T m ≤C ||a||θ,p,J .
This together with 46.32 proves the theorem.
By Theorem 46.13 and Theorem 45.33, we obtain the following important corol-
lary describing the dual space of a trace space.
Corollary 46.14 Let A0 ∩A1 be dense in Ai for i = 0, 1 and suppose that Ai is
reﬂexive for i = 0, 1. Then for ∞> p ≥1,
T m (A0, A1, θ, p)′ = T m (A′
1, A′
0, 1 −θ, p′)

1288
TRACE SPACES

Traces Of Sobolev Spaces
And Fractional Order Spaces
47.1
Traces Of Sobolev Spaces On The Boundary
Of A Half Space
In this section we consider the trace of W m,p ¡
Rn
+
¢
onto a Sobolev space of functions
deﬁned on Rn−1. This latter Sobolev space will be deﬁned in terms of the following
theory in such a way that the trace map is continuous. We already know the trace
map is continuous as a map from W m,p ¡
Rn
+
¢
to W m−1,p ¡
Rn−1¢
but we can do
much better than this using the above theory.
Deﬁnition 47.1 Let θ ∈(0, 1) and let Ωbe an open subset of Rm. We deﬁne
W θ,p (Ω) ≡T
¡
W 1,p (Ω) , Lp (Ω) , p, 1 −θ
¢
.
Thus, from the above general theory, W 1,p (Ω) ,→W θ,p (Ω) ,→Lp (Ω) = Lp (Ω)+
W 1,p (Ω) . Now we consider the trace map for Sobolev space.
Lemma 47.2 Let φ ∈C∞¡
Rn
+
¢
. Then γφ (x′) ≡φ (x′, 0) . Then γ : C∞¡
Rn
+
¢
→
Lp ¡
Rn−1¢
is continuous as a map from W 1,p ¡
Rn
+
¢
to Lp ¡
Rn−1¢
.
Proof: We know
φ (x′, xn) = γφ (x′) +
Z xn
0
∂φ (x′, t)
∂t
dt
1289

1290
TRACES OF SOBOLEV SPACES AND FRACTIONAL ORDER SPACES
Then by Jensen’s inequality,
Z
Rn−1 |γφ (x′)|p dx′
=
Z 1
0
Z
Rn−1 |γφ (x′)|p dx′dxn
≤
C
Z 1
0
Z
Rn−1 |φ (x′, xn)|p dx′dxn
+C
Z 1
0
Z
Rn−1
¯¯¯¯
Z xn
0
∂φ (x′, t)
∂t
dt
¯¯¯¯
p
dx′dxn
≤
C ||φ||p
0,p,Rn−1 + C
Z 1
0
xp−1
n
Z
Rn−1
Z xn
0
¯¯¯¯
∂φ (x′, t)
∂t
¯¯¯¯
p
dtdx′dxn
≤
C ||φ||p
0,p,Rn−1 + C
Z 1
0
xp−1
n
Z
Rn−1
Z ∞
0
¯¯¯¯
∂φ (x′, t)
∂t
¯¯¯¯
p
dtdx′dxn
≤
C ||φ||p
0,p,Rn−1 + C
p
Z
Rn−1
Z ∞
0
¯¯¯¯
∂φ (x′, t)
∂t
¯¯¯¯
p
dtdx′
≤
C ||φ||p
1,p,Rn
+
This proves the lemma.
Deﬁnition 47.3 We deﬁne the trace, γ : W 1,p ¡
Rn
+
¢
→Lp ¡
Rn−1¢
as follows.
γφ (x′) ≡φ (x′, 0) whenever φ ∈C∞¡
Rn
+
¢
. For u ∈W 1,p ¡
Rn
+
¢
, we deﬁne γu ≡
limk→∞γφk in Lp ¡
Rn−1¢
where φk →u in W 1,p ¡
Rn
+
¢
. Then the above lemma
shows this is well deﬁned.
Also from this lemma we obtain a constant, C such that
||φ||0,p,Rn−1 ≤C ||φ||1,p,Rn
+
and we see the same constant holds for all u ∈W 1,p ¡
Rn
+
¢
. Now we will assert more
than this. From the deﬁnition of the norm in the trace space, if f ∈C∞¡
Rn
+
¢
, and
we let θ = 1 −1
p, then
||γf||1−1
p ,p,Rn−1
≤
max
ÃµZ ∞
0
³
t1/p ||f (t)||1,p,Rn−1
´p dt
t
¶1/p
,
µZ ∞
0
³
t1/p ||f ′ (t)||0,p,Rn−1
´p dt
t
¶1/p!
≤
C ||f||1,p,Rn
+ .
Thus, if f ∈W 1,p ¡
Rn
+
¢
, we may deﬁne γf ∈W 1−1
p ,p ¡
Rn−1¢
according to the rule,
γf = lim
k→∞γφk,

47.1. TRACES OF SOBOLEV SPACES ON THE BOUNDARY OF A HALF SPACE1291
where φk →f in W 1,p ¡
Rn
+
¢
and φk ∈C∞¡
Rn
+
¢
. This shows the continuity part of
the following lemma.
Lemma 47.4 The trace map, γ, is a continuous map from W 1,p ¡
Rn
+
¢
onto
W 1−1
p ,p ¡
Rn−1¢
.
Furthermore, for f ∈W 1,p ¡
Rn
+
¢
,
γf = f (0) = lim
t→0+ f (t)
the limit taking place in Lp ¡
Rn−1¢
.
Proof: It remains to verify γ is onto along with the displayed equation. But
by deﬁnition, things in W 1−1
p ,p ¡
Rn−1¢
are of the form limt→0+ f (t) where f ∈
Lp ¡
0, ∞; W 1,p ¡
Rn−1¢¢
, and f ′ ∈Lp ¡
0, ∞; Lp ¡
Rn−1¢¢
, the limit taking place in
W 1,p ¡
Rn−1¢
+ Lp ¡
Rn−1¢
= Lp ¡
Rn−1¢
,
and
µZ ∞
0
||f (t)||p
1,p,Rn−1 dt
¶1/p
+
µZ ∞
0
||f ′ (t)||p
0,p dt
¶1/p
< ∞.
Then taking a measurable representative, we see f ∈W 1,p ¡
Rn
+
¢
and f,xn = f ′.
Also, as an equation in Lp ¡
Rn−1¢
, the following holds for all t > 0.
f (·, t) = f (0) +
Z t
0
f,xn (·, s) ds
But we also have that for a.e. x′,the following equation holds for a.e. t > 0.
f (x′, t) = γf (x′) +
Z t
0
f,xn (x′, s) ds,
(47.1)
showing that
γf = f (0) ∈W 1−1
p ,p ¡
Rn−1¢
≡T
µ
W 1,p (Ω) , Lp (Ω) , p, 1
p
¶
.
To see that 47.1 holds, we approximate f with a sequence from C∞¡
Rn
+
¢
and
ﬁnally obtain an equation of the form
Z
Rn−1
Z ∞
0
·
f (x′, t) −γf (x′) −
Z t
0
f,xn (x′, s) ds
¸
ψ (x′, t) dtdx′ = 0,
which holds for all ψ ∈C∞
c
¡
Rn
+
¢
. This proves the lemma.
Thus we lose 1
p derivatives when we take the trace of a function in W 1,p ¡
Rn
+
¢
.

1292
TRACES OF SOBOLEV SPACES AND FRACTIONAL ORDER SPACES
47.2
A Right Inverse For The Trace For A Half
Space
It is also important to show there is a continuous linear function,
R : W 1−1
p ,p ¡
Rn−1¢
→W 1,p ¡
Rn
+
¢
which has the property that γ (Rg) = g. We will deﬁne this function as follows.
Rg (x′, xn) ≡
Z
Rn−1 g (y′) φ
µx′ −y′
xn
¶
1
xn−1
n
dy′
(47.2)
where φ is a molliﬁer having support in B (0, 1) . Then we have the following lemma.
Lemma 47.5 Let R be deﬁned in 47.2. Then Rg ∈W 1,p ¡
Rn
+
¢
and is a continuous
linear map from W 1−1
p ,p ¡
Rn−1¢
to W 1,p ¡
Rn
+
¢
with the property that γRg = g.
Proof: Let f ∈W 1,p ¡
Rn
+
¢
be such that γf = g. Let ψ (xn) ≡(1 −xn)+ and
assume f is Borel measurable by taking a Borel measurable representative. Then
for a.e. x′ we have the following formula holding for a.e. xn.
Rg (x′, xn)
=
Z
Rn−1
"
ψ (xn) f (y′, ψ (xn)) −
Z ψ(xn)
0
(ψf),n (y′, t) dt
#
φ
µx′ −y′
xn
¶
x1−n
n
dy′.
Using the repeated index summation convention to save space, we obtain that in
terms of weak derivatives,
Rg,n (x′, xn)
=
Z
Rn−1
"
ψ (xn) f (y′, ψ (xn)) −
Z ψ(xn)
0
(ψf),n (y′, t) dt
#
·
·
φ,k
µx′ −y′
xn
¶ µyk −xk
xnn
¶
+ φ
µx′ −y′
xn
¶ (1 −n)
xnn
¸
dy′
=
Z
Rn−1
"
ψ (xn) f (x′ −xnz′, ψ (xn)) −
Z ψ(xn)
0
(ψf),n (x′ −xnz′, t) dt
#
·
·
φ,k (z′)
µyk −xk
xnn
¶
zk + φ (z′) (1 −n)
xnn
¸
xn
ndz′
and so
|Rg,n (x′, xn)|
≤
C (φ)
¯¯¯¯¯
Z
B(0,1)
[ψ (xn) f (x′ −xnz′, ψ (xn))
−
Z ψ(xn)
0
(ψf),n (x′ −xnz′, t) dt
#¯¯¯¯¯

47.2.
A RIGHT INVERSE FOR THE TRACE FOR A HALF SPACE
1293
≤
C (φ)
xn−1
n
(Z
B(0,xn)
|ψ (xn) f (x′ + y′, ψ (xn))| dy′
+
Z
B(0,xn)
Z ψ(xn)
0
¯¯¯(ψf),n (x′ + y′, t)
¯¯¯ dtdy′
)
Therefore,
µZ ∞
0
Z
Rn−1 |Rg,n (x′, xn)|p dx′dxn
¶1/p
≤
C (φ)
ÃZ ∞
0
Z
Rn−1
Ã
1
xn−1
n
Z
B(0,xn)
|ψ (xn) f (x′ + y′, ψ (xn))| dy′
!p
dx′dxn
!1/p
+C (φ)
ÃZ ∞
0
Z
Rn−1
Ã
1
xn−1
n
Z
B(0,xn)
Z ψ(xn)
0
¯¯¯(ψf),n (x′ + y′, t)
¯¯¯ dtdy′
!p
dx′dxn
!1/p
(47.3)
Consider the ﬁrst term on the right. We change variables, letting y′ = z′xn. Then
this term becomes
C (φ)
ÃZ 1
0
Z
Rn−1
ÃZ
B(0,1)
|ψ (xn) f (x′ + xnz′, ψ (xn))| dz′
!p
dx′dxn
!1/p
≤C (φ)
Z
B(0,1)
µZ 1
0
Z
Rn−1 |ψ (xn) f (x′ + xnz′, ψ (xn))|p dx′dxn
¶1/p
dz′
Now we change variables, letting t = ψ (xn) . This yields
= C (φ)
Z
B(0,1)
µZ 1
0
Z
Rn−1 |tf (x′ + xnz′, t)|p dx′dt
¶1/p
dz′ ≤C (φ) ||f||0,p,Rn
+ .
(47.4)
Now we consider the second term on the right in 47.3. Using the same arguments
which were used on the ﬁrst term involving Minkowski’s inequality and changing
the variables, we obtain the second term
≤
C (φ)
Z
B(0,1)
Z 1
0
µZ 1
0
Z
Rn−1
¯¯¯(ψf),n (x′ + xnz′, t)
¯¯¯
p
dx′dxn
¶1/p
dtdy′
≤
C (φ) ||f||1,p,Rn
+ .
(47.5)
It is somewhat easier to verify that
||Rg,j||0,p,Rn
+ ≤C (φ) ||f||1,p,Rn
+ .
Therefore, we have shown that whenever γf = f (0) = g,
||Rg||1,p,Rn
+ ≤C (φ) ||f||1,p,Rn
+ .

1294
TRACES OF SOBOLEV SPACES AND FRACTIONAL ORDER SPACES
Taking the inﬁmum over all such f and using the deﬁnition of the norm in
W 1−1
p ,p ¡
Rn−1¢
,
it follows
||Rg||1,p,Rn
+ ≤C (φ) ||g||1−1
p ,p,Rn−1,
showing that this map, R, is continuous as claimed. It is obvious that
lim
xn→0 Rg (xn) = g,
the convergence taking place in Lp ¡
Rn−1¢
because of general results about convo-
lution with molliﬁers. This proves the lemma.
47.3
Fractional Order Sobolev Spaces
Deﬁnition 47.6 Let m be a nonnegative integer and let s = m+σ where σ ∈(0, 1) .
Then W s,p (Ω) will consist of those elements of W m,p (Ω) for which Dαu ∈W σ,p (Ω)
for all |α| = m. The norm is given by the following.
||u||s,p,Ω≡

||u||p
m,p,Ω+
X
|α|=m
||Dαu||p
σ,p,Ω


1/p
.
Corollary 47.7 The space, W s,p (Ω) is a reﬂexive Banach space whenever p > 1.
Proof: We know from the theory of interpolation spaces that W σ,p (Ω) is reﬂex-
ive. This is because it is an iterpolation space for the two reﬂexive spaces, Lp (Ω)
and W 1,p (Ω) . Now the formula for the norm of an element in W s,p (Ω) shows this
space is isometric to a closed subspace of W m,p (Ω) × W σ,p (Ω)k for suitable k.
Therefore, W s,p (Ω) is also reﬂexive.
Theorem 47.8 The trace map, γ : W m,p ¡
Rn
+
¢
→W m−1
p ,p ¡
Rn−1¢
is continuous.
Proof: Let f ∈S. We let σ = 1 −1
p so that m −
³
1
p
´
= m −1 + σ. Then from
the deﬁnition,
||γf||m−1
p ,p,Rn−1 =

||γf||p
m−1,p,Rn−1 +
X
|α|=m−1
||Dαγf||p
1−1
p ,p,Rn−1


1/p
and from Lemma 47.4, and the fact that the trace is continuous as a map from
W m,p ¡
Rn
+
¢
to W m−1,p ¡
Rn−1¢
,
||γf||m−1
p ,p,Rn−1 ≤
³
C1 ||f||p
m,p,Rn
+ + C2 ||f||m,p,Rn+
´1/p
≤C ||f||m,p,Rn+ .
This proves the theorem.
With the deﬁnition of W s,p (Ω) for s not an integer, we can generalize an earlier
theorem.

47.3.
FRACTIONAL ORDER SOBOLEV SPACES
1295
Theorem 47.9 Let h : U →V where U and V are two open sets and suppose h is
bilipschitz and that Dαh and Dαh−1 exist and are Lipschitz continuous if |α| ≤m
where m = 0, 1, · · ·.and s = m + σ where σ ∈(0, 1) . Then
h∗: W s,p (V ) →W s,p (U)
is continuous, linear, one to one, and has an inverse with the same properties, the
inverse being
¡
h−1¢∗.
Proof: In case m = 0, the conclusion of the theorem is immediate from the
general theory of trace spaces. Therefore, we can assume m ≥1. We know from the
deﬁnition that
||h∗u||m+σ,p,U ≡

||h∗u||p
m,p,U +
X
|α|=m
||Dα (h∗u)||p
σ,p,U


1/p
Now consider the case when m = 1. Then it is routine to verify that
Djh∗u (x) = u,k (h (x)) hk,j (x) .
Let Lk : W 1,p (V ) →W 1,p (U) be deﬁned by
Lkv = h∗(v) hk,j.
Then Lk is continuous as a map from W 1,p (V ) to W 1,p (U) and as a map from
Lp (V ) to Lp (U) and therefore, it follows that Lk is continuous as a map from
W σ,p (V ) to W σ,p (U) . Therefore,
||Lk (v)||σ,p,U ≤Ck ||v||σ,p,U
and so
||Dj (h∗u)||σ,p,U
≤
X
k
||Lk (u,k)||σ,p,U
≤
X
k
Ck ||Dku||σ,p,V
≤
C
ÃX
k
||Dku||p
σ,p,V
!1/p
.
Therefore, it follows that
||h∗u||1+σ,p,U
≤

||h∗u||p
1,p,U +
X
j
Cp X
k
||Dku||p
σ,p,V


1/p
≤
C
"
||u||p
1,p,V +
X
k
||Dku||p
σ,p,V
#1/p
= C ||u||1+σ,p,V .

1296
TRACES OF SOBOLEV SPACES AND FRACTIONAL ORDER SPACES
The general case is similar. We simply have a more complicated continuous linear
operator in place of Lk.
Now we prove an important interpolation inequality for Sobolev spaces.
Theorem 47.10 Let Ωbe an open set in Rn and let f ∈W m+1,p (Ω) and σ ∈
(0, 1) . Then for some constant, C, independent of f,
||f||m+σ,p,Ω≤C ||f||1−σ
m+1,p,Ω||f||σ
m,p,Ω.
Also, if L ∈L (W m,p (Ω) , W m,p (Ω)) for all m = 0, 1, · · ·, and L ◦Dα = Dα ◦L on
C∞¡
Ω
¢
, then L ∈L (W m+σ,p (Ω) , W m+σ,p (Ω)) for any m = 0, 1, · · ·.
Proof: Recall from above, W 1−θ,p (Ω) ≡T
¡
W 1,p (Ω) , Lp (Ω) , p, θ
¢
. Therefore,
from Theorem 46.9, if f ∈W 1,p (Ω) ,
||f||1−θ,p,Ω≤K ||f||θ
1,p,Ω||f||1−θ
0,p,Ω
Therefore,
||f||m+σ,p,Ω
≤

||f||p
m,p,Ω+
X
|α|=m
K
³
||Dαf||1−σ
1,p,Ω||Dαf||σ
0,p,Ω
´p


1/p
≤
C
h
||f||p
m,p,Ω+
³
||f||1−σ
m+1,p,Ω||f||σ
m,p,Ω
´pi1/p
≤
C
h³
||f||1−σ
m+1,p,Ω||f||σ
m,p,Ω
´p
+
³
||f||1−σ
m+1,p,Ω||f||σ
m,p,Ω
´pi1/p
≤
C ||f||1−σ
m+1,p,Ω||f||σ
m,p,Ω.
This proves the ﬁrst part. Now we consider the second. Let φ ∈C∞¡
Ω
¢
||Lφ||m+σ,p,Ω=

||Lφ||p
m,p,Ω+
X
|α|=m
||DαLφ||p
σ,p,Ω


1/p
=

||Lφ||p
m,p,Ω+
X
|α|=m
||LDαφ||p
T (W 1,p,Lp,p,1−σ)


1/p
=

||Lφ||p
m,p,Ω+
X
|α|=m
h
inf
³¯¯¯¯t1−σLfα
¯¯¯¯σ
1
¯¯¯¯t1−σLf ′
α
¯¯¯¯1−σ
2
´ip


1/p
(47.6)
where
inf
³¯¯¯¯t1−σLfα
¯¯¯¯σ
1
¯¯¯¯t1−σLf ′
α
¯¯¯¯1−σ
2
´
=
inf
³¯¯¯¯t1−σLfα
¯¯¯¯σ
Lp(0,∞; dt
t ;W 1,p(Ω))
¯¯¯¯t1−σLf ′
α
¯¯¯¯1−σ
Lp(0,∞; dt
t ;Lp(Ω))
´
,

47.3.
FRACTIONAL ORDER SOBOLEV SPACES
1297
fα (0) ≡limt→0 fα (t) = Dαφ in W 1,p (Ω) + Lp (Ω) , and the inﬁmum is taken over
all such functions. Therefore, from 47.6, and letting ||L||1 denote the operator norm
of L in W 1,p (Ω) and ||L||2 denote the operator norm of L in Lp (Ω) ,
||Lφ||m+σ,p,Ω
≤

||Lφ||p
m,p,Ω+
X
|α|=m
h
inf
³
||L||σ
1 ||L||1−σ
2
¯¯¯¯t1−σfα
¯¯¯¯σ
1
¯¯¯¯t1−σf ′
α
¯¯¯¯1−σ
2
´ip


1/p
≤

||Lφ||p
m,p,Ω+
³
||L||σ
1 ||L||1−σ
2
´p X
|α|=m
h
inf
³¯¯¯¯t1−σfα
¯¯¯¯σ
1
¯¯¯¯t1−σf ′
α
¯¯¯¯1−σ
2
´ip


1/p
≤
C

||φ||p
m,p,Ω+
X
|α|=m
h
||Dαφ||σ,p,Ω
ip


1/p
= C ||φ||m+σ,p,Ω.
Since C∞¡
Ω
¢
is dense in all the Sobolev spaces, this inequality establishes the
desired result.
Deﬁnition 47.11 We deﬁne for s ≥0, W −s,p′ (Rn) to be the dual space of
W s,p (Rn) .
Here 1
p + 1
p′ = 1.
Note that in the case of m = 0 this is consistent with the Riesz representation
theorem for the Lp spaces.

1298
TRACES OF SOBOLEV SPACES AND FRACTIONAL ORDER SPACES

Sobolev Spaces On Manifolds
48.1
Basic Deﬁnitions
We will be considering the following situation. We have a set, Γ ⊆Rm where m > n,
mappings, hi : Ui →Γi = Γ ∩Wi for Wi an open set in Rmwith Γ ⊆∪l
i=1Wi and
Ui is an open subset of Rn. We assume hi is of the form
hi (x) = Hi (x, 0)
(48.1)
where for some open set, Oi, Hi : Ui × Oi →Wi is bilipschitz having bilipschitz
inverse such that for G = Hi or H−1
i , DαG is Lipschitz for |α| ≤k.
For example, we could let m = n + 1 and let
Hi (x,y) =
µ
x
φ (x) + y
¶
where φ is a Lipschitz function having Dαφ Lipschitz for all |α| ≤k. This is an
example of the sort of thing just described, letting x ∈Ui ⊆Rn and Oi = R,
becuase it is obvious the inverse of Hi is given by
H−1
i
(x, y) =
µ
x
y −φ (x)
¶
.
We will also let {ψi}l
i=1 be a partition of unity subordinate to the open cover {Wi}
satisfying ψi ∈C∞
c (Wi) . Then we give the following deﬁnition.
Deﬁnition 48.1 We say u ∈W s,p (Γ) if whenever {Wi, ψi, Γi, Ui, hi, Hi}l
i=1 is
described above, h∗
i (uψi) ∈W s,p (Ui) . We deﬁne the norm as
||u||s,p,Γ ≡
l
X
i=1
||h∗
i (uψi)||s,p,Ui
It is not at all obvious this norm is well deﬁned. What if
{W ′
i, φi, Γi, Vi, gi, Gi}r
i=1
is as described above. Would the two norms be equivalent? To begin with we show
the following lemma which involves a particular choice for {Wi, ψi, Γi, Ui, hi, Hi}l
i=1 .
1299

1300
SOBOLEV SPACES ON MANIFOLDS
Lemma 48.2 W s,p (Γ) as just described, is a reﬂexive Banach space.
Proof: Let L : W s,p (Γ) →Ql
i=1 W s,p (Ui) be deﬁned by (Lu)i ≡h∗
i (uψi) .
Let {uj}∞
j=1 be a Cauchy sequence in W s,p (Γ) . Then {h∗
i (ujψi)}∞
j=1 is a Cauchy
sequence in W s,p (Ui) for each i. Therefore, for each i, there exists wi ∈W s,p (Ui)
such that
lim
j→∞h∗
i (ujψi) = wi in W s,p (Ui) .
But also, we may take a subsequence such that
(
l
X
i=1
h∗
i (ujψi) (x)
)∞
j=1
= {uj (h (x))}∞
j=1
converges for a.e. x. Since h maps sets of measure zero to sets of n dimensional
Hausdorﬀmeasure zero, it follows that for a.e. y ∈Γ,
uj (y) →u (y) a.e.
Therefore, wi (x) = h∗
i (uψi) (x) a.e. and this shows h∗
i (uψi) ∈W s,p (Ui) . Thus
u ∈W s,p (Γ) and this shows completness. It is clear ||·||s,p,Γ is a norm. Thus L is
an isometry of W s,p (Γ) and a closed subspace of Ql
i=1 W s,p (Ui) so this proves the
lemma since by Corollary 47.7, W s,p (Ui) is reﬂexive.
We now show that any two such norms are equivalent.
Suppose
©
W ′
j, φj, Γj, Vj, gj, Gj
ªr
j=1and {Wi, ψi, Γi, Ui, hi, Hi}l
i=1 both satisfy
the conditions described above. Let ||·||1
s,p,Γ denote the norm deﬁned by
||u||1
s,p,Γ ≡
r
X
j=1
¯¯¯¯g∗
j
¡
uφj
¢¯¯¯¯
s,p,Vj
≤
r
X
j=1
¯¯¯¯¯
¯¯¯¯¯g∗
j
Ã
l
X
i=1
uφjψi
!¯¯¯¯¯
¯¯¯¯¯
s,p,Vj
≤
X
j,i
¯¯¯¯g∗
j
¡
uφjψi
¢¯¯¯¯
s,p,Vj
=
X
j,i
¯¯¯¯g∗
j
¡
uφjψi
¢¯¯¯¯
s,p,g−1
j (Wi∩W ′
j)
(48.2)
Now we may deﬁne a new norm ||u||1,g
s,p,Γ by the formula 48.2. This norm is deter-
mined by
©
W ′
j ∩Wi, ψiφj, Γj ∩Γi, Vj, gi,j, Gi,j
ª
where gi,j = gj. Thus the identity map is continuous from
³
W s,p (Γ) , ||·||1,g
s,p,Γ
´
to
³
W s,p (Γ) , ||·||1
s,p,Γ
´
. It follows the two norms, ||·||1,g
s,p,Γ and ||·||1
s,p,Γ , are equivalent
by the open mapping theorem. In a similar way, the norms, ||·||2,h
s,p,Γ and ||·||2
s,p,Γ
are equivalent where
||u||2
s,p,Γ ≡
l
X
j=1
||h∗
i (uψi)||s,p,Ui

48.2.
THE TRACE ON THE BOUNDARY OF AN OPEN SET
1301
and
||u||2,h
s,p,Γ ≡
X
j,i
¯¯¯¯h∗
i
¡
uφjψi
¢¯¯¯¯
s,p,Ui . =
X
j,i
¯¯¯¯h∗
i
¡
uφjψi
¢¯¯¯¯
s,p,h−1
i (Wi∩W ′
j)
But from the assumptions on h and g, in particular the assumption that these
are restrictions of functions which are deﬁned on open subsets of Rm which have
Lipschitz derivatives up to order k along with their inverses, we know from Theorem
47.9, there exist constants Ci, independent of u such that
¯¯¯¯h∗
i
¡
uφjψi
¢¯¯¯¯
s,p,h−1
i (Wi∩W ′
j) ≤C1
¯¯¯¯g∗
j
¡
uφjψi
¢¯¯¯¯
s,p,g−1
j (Wi∩W ′
j)
and
¯¯¯¯g∗
j
¡
uφjψi
¢¯¯¯¯
s,p,g−1
j (Wi∩W ′
j) ≤C2
¯¯¯¯h∗
i
¡
uφjψi
¢¯¯¯¯
s,p,h−1
i (Wi∩W ′
j) .
Therefore, the two norms, ||·||1,g
s,p,Γ and ||·||2,h
s,p,Γ are equivalent. It follows that the
norms, ||·||2
s,p,Γ and ||·||1
s,p,Γ are equivalent. This proves the following theorem.
Theorem 48.3 Let Γ be described above.
Then we may deﬁne W s,p (Γ) as in
Deﬁnition 41.36 and any two norms like those given in this deﬁnition are equivalent.
48.2
The Trace On The Boundary Of An Open Set
Next we generalize earlier theorems about the loss of 1
p derivatives on the boundary.
Deﬁnition 48.4 We deﬁne
Rn−1
k
≡{x ∈Rn : xk = 0} , bxk ≡(x1, · · ·, xk−1, 0, xk+1, · · ·, xn) .
We will say an open set, Ωis Cm,1 if there exist open sets, Wi, i = 0, 1, · · ·, l such
that
Ω= ∪l
i=0Wi
with W0 ⊆Ω, open sets Ui ⊆Rn−1
k
for some k, and open intervals, (ai, bi) containing
0 such that for i ≥1,
∂Ω∩Wi = {bxk + φi (bxk) ek : bxk ∈Ui} ,
Ω∩Wi = {bxk + (φi (bxk) + xk) ek : (bxk, xk) ∈Ui × (0, bi)} ,
where φi is Lipschitz with partial derivatives up to order m also Lipschitz. Note
that it makes no diﬀerence whether we use (0, bi) or (ai, 0) in the last part of this
deﬁnition since we can go from one to the other by a simple change if the φi.
Assume Ω∈Cm−1,1. Then, if we deﬁne
hi (bxk) = bxk + φi (bxk) ek, Hi (x) ≡bxk + (φi (bxk) + xk) ek,

1302
SOBOLEV SPACES ON MANIFOLDS
and let ψi ∈C∞
c (Wi) with Pl
i=0 ψi (x) = 1 on Ω, we see that
{Wi, ψi, ∂Ω∩Wi, Ui, hi, Hi}l
i=1
satisﬁes all the conditions for deﬁning W s,p (∂Ω) for s ≤m. Let u ∈C∞¡
Ω
¢
and
let hi be as just described. Using Theorem 47.8, and Theorem 40.14,
||γu||m−1
p ,p,∂Ω=
l
X
i=1
||h∗
i (ψiγu)||m−1
p ,p,Ui
=
l
X
i=1
||h∗
i (ψiγu)||m−1
p ,p,Rn−1
k
≤C
l
X
i=1
||H∗
i (ψiu)||m,p,Rn
+
≤C
l
X
i=1
||H∗
i (ψiu)||m,p,Ui×(0,bi) ≤C
l
X
i=1
||(ψiu)||m,p,Wi∩Ω
≤C
l
X
i=1
||(ψiu)||m,p,Ω≤C
l
X
i=1
||u||m,p,Ω≤Cl ||u||m,p,Ω.
Now we use the density of C∞¡
Ω
¢
in W m,p (Ω) to see that γ extends to a continuous
linear map deﬁned on W m,p (Ω) still called γ such that for all u ∈W m,p (Ω) ,
||γu||m−1
p ,p,∂Ω≤Cl ||u||m,p,Ω.
(48.3)
In addition to this, in the case where m = 1, we may use Lemma 47.5 to obtain a
continuous linear map, R, from W 1−1
p ,p (∂Ω) to W 1,p (Ω) which has the property
that γRg = g for every g ∈W 1−1
p ,p (∂Ω) . Letting g ∈W 1−1
p ,p (∂Ω) ,
g =
l
X
i=1
ψig.
Then also,
h∗
i (ψig) ∈W 1−1
p ,p ¡
Rn−1¢
and so from Lemma 47.5, we can extend this to W 1,p ¡
Rn
+
¢
, Rh∗
i (ψig) . We may also
assume that Rh∗
i (ψig) ∈W 1,p (Ui × (0, bi)) . We can accomplish this by multiplying
by a suitable cut oﬀfunction in the deﬁnition of R or else adjusting the function, ψ
occuring in the proof of this lemma so that it vanishes oﬀ(0, bi) . Then our extension
is
Rg =
l
X
i=1
¡
H−1
i
¢∗Rh∗
i (ψig) .

48.2.
THE TRACE ON THE BOUNDARY OF AN OPEN SET
1303
This works because
γRg
≡
l
X
i=1
γ
¡
H−1
i
¢∗Rh∗
i (ψig)
=
l
X
i=1
¡
H−1
i
¢∗γRh∗
i (ψig)
=
l
X
i=1
¡
H−1
i
¢∗h∗
i (ψig) = g.
This proves the following theorem about the trace.
Theorem 48.5 Let Ω∈Cm,1. Then there exists a constant, C independent of
u ∈W m,p (Ω) and a continuous linear map, γ : W m,p (Ω) →W m−1
p ,p (∂Ω) such that
48.3 holds. This map satisﬁes γu (x) = u (x) for all u ∈C∞¡
Ω
¢
. In the case where
m = 1, we obtain also the existence of a continuous linear map, R : W 1−1
p ,p (∂Ω) →
W 1,p (Ω) which has the property that γRg = g for all g ∈W 1−1
p ,p (∂Ω).

1304
SOBOLEV SPACES ON MANIFOLDS

The HausdorﬀMaximal
Theorem
The purpose of this appendix is to prove the equivalence between the axiom of
choice, the Hausdorﬀmaximal theorem, and the well-ordering principle. The Haus-
dorﬀmaximal theorem and the well-ordering principle are very useful but a little
hard to believe; so, it may be surprising that they are equivalent to the axiom of
choice. First it is shown that the axiom of choice implies the Hausdorﬀmaximal
theorem, a remarkable theorem about partially ordered sets.
A nonempty set is partially ordered if there exists a partial order, ≺, satisfying
x ≺x
and
if x ≺y and y ≺z then x ≺z.
An example of a partially ordered set is the set of all subsets of a given set and
≺≡⊆. Note that two elements in a partially ordered sets may not be related. In
other words, just because x, y are in the partially ordered set, it does not follow
that either x ≺y or y ≺x. A subset of a partially ordered set, C, is called a chain
if x, y ∈C implies that either x ≺y or y ≺x. If either x ≺y or y ≺x then x and
y are described as being comparable. A chain is also called a totally ordered set. C
is a maximal chain if whenever eC is a chain containing C, it follows the two chains
are equal. In other words C is a maximal chain if there is no strictly larger chain.
Lemma A.1 Let F be a nonempty partially ordered set with partial order ≺. Then
assuming the axiom of choice, there exists a maximal chain in F.
Proof: Let X be the set of all chains from F. For C ∈X, let
SC = {x ∈F such that C∪{x} is a chain strictly larger than C}.
If SC = ∅for any C, then C is maximal. Thus, assume SC ̸= ∅for all C ∈X. Let
f(C) ∈SC. (This is where the axiom of choice is being used.) Let
g(C) = C ∪{f(C)}.
1305

1306
THE HAUSDORFF MAXIMAL THEOREM
Thus g(C) ⊋C and g(C) \ C ={f(C)} = {a single element of F}. A subset T of X
is called a tower if
∅∈T ,
C ∈T implies g(C) ∈T ,
and if S ⊆T is totally ordered with respect to set inclusion, then
∪S ∈T .
Here S is a chain with respect to set inclusion whose elements are chains.
Note that X is a tower. Let T0 be the intersection of all towers. Thus, T0 is a
tower, the smallest tower. Are any two sets in T0 comparable in the sense of set
inclusion so that T0 is actually a chain? Let C0 be a set of T0 which is comparable
to every set of T0. Such sets exist, ∅being an example. Let
B ≡{D ∈T0 : D ⊋C0 and f (C0) /∈D} .
The picture represents sets of B. As illustrated in the picture, D is a set of B when
D is larger than C0 but fails to be comparable to g (C0). Thus there would be more
than one chain ascending from C0 if B ̸= ∅, rather like a tree growing upward in
more than one direction from a fork in the trunk. It will be shown this can’t take
place for any such C0 by showing B = ∅.
C0
D
f(C0)
·
This will be accomplished by showing eT0 ≡T0 \ B is a tower. Since T0 is the
smallest tower, this will require that eT0 = T0 and so B = ∅.
Claim: eT0 is a tower and so B = ∅.
Proof of the claim: It is clear that ∅∈eT0 because for ∅to be contained in B
it would be required to properly contain C0 which is not possible. Suppose D ∈eT0.
The plan is to verify g (D) ∈eT0.
Case 1: f (D) ∈C0. If D ⊆C0, then since both D and {f (D)} are contained in
C0, it follows g (D) ⊆C0 and so g (D) /∈B. On the other hand, if D ⊋C0, then since
D ∈eT0, f (C0) ∈D and so g (D) also contains f (C0) implying g (D) /∈B. These are
the only two cases to consider because C0 is comparable to every set of T0.
Case 2: f (D) /∈C0. If D ⊊C0 it can’t be the case that f (D) /∈C0 because if
this were so, g (D ) would not compare to C0.
D
C0
f(C0)
·
f(D)
·
Hence if f (D) /∈C0, then D ⊇C0. If D = C0, then f (D) = f (C0) ∈g (D) so

1307
g (D) /∈B. Therefore, assume D ⊋C0. Then, since D is in eT0, f (C0) ∈D and so
f (C0) ∈g (D). Therefore, g (D) ∈eT0.
Now suppose S is a totally ordered subset of eT0 with respect to set inclusion.
Then if every element of S is contained in C0, so is ∪S and so ∪S ∈eT0. If, on
the other hand, some chain from S, C, contains C0 properly, then since C /∈B,
f (C0) ∈C ⊆∪S showing that ∪S /∈B also. This has proved eT0 is a tower and
since T0 is the smallest tower, it follows eT0 = T0. This has shown roughly that no
splitting into more than one ascending chain can occur at any C0 which is comparable
to every set of T0. Next it is shown that every element of T0 has the property that
it is comparable to all other elements of T0. This is done by showing that these
elements which possess this property form a tower.
Deﬁne T1 to be the set of all elements of T0 which are comparable to every
element of T0. (Recall the elements of T0 are chains from the original partial order.)
Claim: T1 is a tower.
Proof of the claim: It is clear that ∅∈T1 because ∅is a subset of every set.
Suppose C0 ∈T1. It is necessary to verify that g (C0) ∈T1. Let D ∈T0 (Thus D ⊆C0
or else D ⊋C0.)and consider g (C0) ≡C0 ∪{f (C0)}. If D ⊆C0, then D ⊆g (C0)
so g (C0) is comparable to D. If D ⊋C0, then D ⊇g (C0) by what was just shown
(B = ∅). Hence g (C0) is comparable to D. Since D was arbitrary, it follows g (C0)
is comparable to every set of T0. Now suppose S is a chain of elements of T1 and
let D be an element of T0. If every element in the chain, S is contained in D, then
∪S is also contained in D. On the other hand, if some set, C, from S contains D
properly, then ∪S also contains D. Thus ∪S ∈T 1 since it is comparable to every
D ∈T0.
This shows T1 is a tower and proves therefore, that T0 = T1. Thus every set of
T0 compares with every other set of T0 showing T0 is a chain in addition to being a
tower.
Now ∪T0, g (∪T0) ∈T0. Hence, because g (∪T0) is an element of T0, and T0 is a
chain of these, it follows g (∪T0) ⊆∪T0. Thus
∪T0 ⊇g (∪T0) ⊋∪T0,
a contradiction. Hence there must exist a maximal chain after all. This proves the
lemma.
If X is a nonempty set,≤is an order on X if
x ≤x,
and if x, y ∈X, then
either x ≤y or y ≤x
and
if x ≤y and y ≤z then x ≤z.
≤is a well order and say that (X, ≤) is a well-ordered set if every nonempty subset
of X has a smallest element. More precisely, if S ̸= ∅and S ⊆X then there exists
an x ∈S such that x ≤y for all y ∈S. A familiar example of a well-ordered set is
the natural numbers.

1308
THE HAUSDORFF MAXIMAL THEOREM
Lemma A.2 The Hausdorﬀmaximal principle implies every nonempty set can be
well-ordered.
Proof: Let X be a nonempty set and let a ∈X. Then {a} is a well-ordered
subset of X. Let
F = {S ⊆X : there exists a well order for S}.
Thus F ̸= ∅. For S1, S2 ∈F, deﬁne S1 ≺S2 if S1 ⊆S2 and there exists a well
order for S2, ≤2 such that
(S2, ≤2) is well-ordered
and if
y ∈S2 \ S1 then x ≤2 y for all x ∈S1,
and if ≤1is the well order of S1 then the two orders are consistent on S1. Then
observe that ≺is a partial order on F. By the Hausdorﬀmaximal principle, let C
be a maximal chain in F and let
X∞≡∪C.
Deﬁne an order, ≤, on X∞as follows. If x, y are elements of X∞, pick S ∈C such
that x, y are both in S. Then if ≤S is the order on S, let x ≤y if and only if x ≤S y.
This deﬁnition is well deﬁned because of the deﬁnition of the order, ≺. Now let U
be any nonempty subset of X∞. Then S ∩U ̸= ∅for some S ∈C. Because of the
deﬁnition of ≤, if y ∈S2 \S1, Si ∈C, then x ≤y for all x ∈S1. Thus, if y ∈X∞\S
then x ≤y for all x ∈S and so the smallest element of S ∩U exists and is the
smallest element in U. Therefore X∞is well-ordered. Now suppose there exists
z ∈X \ X∞. Deﬁne the following order, ≤1, on X∞∪{z}.
x ≤1 y if and only if x ≤y whenever x, y ∈X∞
x ≤1 z whenever x ∈X∞.
Then let
eC = {S ∈C or X∞∪{z}}.
Then eC is a strictly larger chain than C contradicting maximality of C. Thus X \
X∞= ∅and this shows X is well-ordered by ≤. This proves the lemma.
With these two lemmas the main result follows.
Theorem A.3 The following are equivalent.
The axiom of choice
The Hausdorﬀmaximal principle
The well-ordering principle.

A.1.
EXERCISES
1309
Proof: It only remains to prove that the well-ordering principle implies the
axiom of choice. Let I be a nonempty set and let Xi be a nonempty set for each
i ∈I. Let X = ∪{Xi : i ∈I} and well order X. Let f (i) be the smallest element
of Xi. Then
f ∈
Y
i∈I
Xi.
A.1
Exercises
1. Zorn’s lemma states that in a nonempty partially ordered set, if every chain
has an upper bound, there exists a maximal element, x in the partially ordered
set. x is maximal, means that if x ≺y, it follows y = x. Show Zorn’s lemma
is equivalent to the Hausdorﬀmaximal theorem.
2. Let X be a vector space. Y ⊆X is a Hamel basis if every element of X can be
written in a unique way as a ﬁnite linear combination of elements in Y . Show
that every vector space has a Hamel basis and that if Y, Y1 are two Hamel
bases of X, then there exists a one to one and onto map from Y to Y1.
3. ↑Using the Baire category theorem of the chapter on Banach spaces show
that any Hamel basis of a Banach space is either ﬁnite or uncountable.
4. ↑Consider the vector space of all polynomials deﬁned on [0, 1]. Does there
exist a norm, ||·|| deﬁned on these polynomials such that with this norm, the
vector space of polynomials becomes a Banach space (complete normed vector
space)?

1310
THE HAUSDORFF MAXIMAL THEOREM

Bibliography
[1] Adams R. Sobolev Spaces, Academic Press, New York, San Francisco, London,
1975.
[2] Alfors, Lars Complex Analysis, McGraw Hill 1966.
[3] Apostol, T. M., Mathematical Analysis,
Addison Wesley Publishing Co.,
1969.
[4] Apostol, T. M., Calculus second edition, Wiley, 1967.
[5] Apostol, T. M., Mathematical Analysis,
Addison Wesley Publishing Co.,
1974.
[6] Ash, Robert, Complex Variables, Academic Press, 1971.
[7] Baker, Roger, Linear Algebra, Rinton Press 2001.
[8] Bergh J. and L¨ofstr¨om J. Interpolation Spaces, Springer Verlag 1976.
[9] Billingsley P., Probability and Measure, Wiley, 1995.
[10] Bledsoe W.W., Am. Math. Monthly vol. 77, PP. 180-182 1970.
[11] Bogachev Vladimir I. Gaussian Measures American Mathematical Society
Mathematical Surveys and Monographs, volume 62 1998.
[12] Bruckner A. , Bruckner J., and Thomson B., Real Analysis
Prentice
Hall 1997.
[13] Conway J. B. Functions of one Complex variable Second edition, Springer
Verlag 1978.
[14] Cheney, E. W., Introduction To Approximation Theory, McGraw Hill 1966.
[15] Da Prato, G. and Zabczyk J., Stochastic Equations in Inﬁnite Dimensions,
Cambridge 1992.
[16] Diestal J. and Uhl J.,
Vector Measures, American Math. Society, Provi-
dence, R.I., 1977.
1311

1312
BIBLIOGRAPHY
[17] Dontchev A.L. The Graves theorem Revisited, Journal of Convex Analysis,
Vol. 3, 1996, No.1, 45-53.
[18] Dunford N. and Schwartz J.T. Linear Operators, Interscience Publishers,
a division of John Wiley and Sons, New York, part 1 1958, part 2 1963, part 3
1971.
[19]
Duvaut, G. and Lions, J. L.,
Inequalities in Mechanics and Physics,
Springer-Verlag, Berlin, 1976.
[20] Evans L.C. and Gariepy, Measure Theory and Fine Properties of Functions,
CRC Press, 1992.
[21] Evans L.C. Partial Diﬀerential Equations, Berkeley Mathematics Lecture
Notes. 1993.
[22] Federer H., Geometric Measure Theory, Springer-Verlag, New York, 1969.
[23] Gagliardo, E., Properieta di alcune classi di funzioni in piu variabili, Ricerche
Mat. 7 (1958), 102-137.
[24] Grisvard, P. Elliptic problems in nonsmooth domains, Pittman 1985.
[25] Gross L. Abstract Wiener Spaces, Proc. ﬁfth Berkeley Sym. Math. Stat. Prob.
1965.
[26] Hewitt E. and Stromberg K. Real and Abstract Analysis, Springer-Verlag,
New York, 1965.
[27] Hille Einar, Analytic Function Theory, Ginn and Company 1962.
[28] H¨ormander, Lars Linear Partial Diﬀerrential Operators, Springer Verlag,
1976.
[29] H¨ormander L. Estimates for translation invariant operators in Lp spaces,
Acta Math. 104 1960, 93-139.
[30] Hui-Hsiung Kuo Gaussian Measures in Banach Spaces Lecture notes in
Mathematics Springer number 463 1975.
[31] John, Fritz, Partial Diﬀerential Equations, Fourth edition, Springer Verlag,
1982.
[32] Jones F., Lebesgue Integration on Euclidean Space, Jones and Bartlett 1993.
[33] Karatzas and Shreve, Brownian Motion and Stochastic Calculus, Springer
Verlag, 1991.
[34] Kuratowski K. and Ryll-Nardzewski C. A general theorem on selectors,
Bull. Acad. Pol. Sc., 13, 397-403.
[35] Kuttler K.L. Basic Analysis. Rinton Press. November 2001.

BIBLIOGRAPHY
1313
[36] Kuttler K.L., Modern Analysis CRC Press 1998.
[37] Levinson, N. and Redheﬀer, R. Complex Variables, Holden Day, Inc. 1970
[38] Liptser, R.S. Nd Shiryaev, A. N. Statistics of Random Processes. Vol I
General theory. Springer Verlag, New York 1977.
[39] Markushevich, A.I., Theory of Functions of a Complex Variable, Prentice
Hall, 1965.
[40] McShane E. J. Integration, Princeton University Press, Princeton, N.J. 1944.
[41] Neˇcas J. and Hlav´aˇcek, Mathematical Theory of Elasic and Elasto-Plastic
Bodies: An introduction, Elsevier, 1981.
[42] Øksendal Bernt Stochastic Diﬀerential Equations, Springer 2003.
[43] Ray W.O. Real Analysis, Prentice-Hall, 1988.
[44] Rudin, W., Principles of mathematical analysis, McGraw Hill third edition
1976
[45] Rudin W. Real and Complex Analysis, third edition, McGraw-Hill, 1987.
[46] Rudin W. Functional Analysis, second edition, McGraw-Hill, 1991.
[47] Saks and Zygmund, Analytic functions, 1952. (This book is available on the
web. http://www.geocities.com/alex stef/mylist.html#FuncAn)
[48] Smart D.R. Fixed point theorems Cambridge University Press, 1974.
[49] Stein E. Singular Integrals and Diﬀerentiability Properties of Functions.
Princeton University Press, Princeton, N. J., 1970.
[50] Triebel H. Interpolation Theory, Function Spaces and Diﬀerential Operators,
North Holland, Amsterdam, 1978.
[51] Varga R. S. Functional Analysis and Approximation Theory in Numerical
Analysis, SIAM 1984.
[52] Yosida K. Functional Analysis, Springer-Verlag, New York, 1978.

Index
C1 functions, 118
C∞
c , 328
Cm
c , 328
Fσ sets, 172
Gδ, 339
Gδ sets, 172
L1
loc, 429
Lp
compactness, 333
Lp multipliers, 546
Lp (Ω; X), 603
L∞, 335
Lp
loc, 1084
π systems, 257
σ algebra, 171
(1,p) extension operator, 1165
Abel’s formula, 80
Abel’s theorem, 654
absolutely continuous, 434
adapted, 903
adapted step function, 903
adjugate, 71
Alexander subbasis theorem, 306
algebra, 161
algebra of sets, 245
analytic continuation, 748, 850
Analytic functions, 641
approximate identity, 329
area formula, 470, 480, 1104
at most countable, 22
atlas, 1127
automorphic function, 836
axiom of choice, 17, 21
axiom of extension, 17
axiom of speciﬁcation, 17
axiom of unions, 17
Banach Alaoglu theorem, 355
Banach space, 319
Banach Steinhaus theorem, 341
basis of module of periods, 824
Besicovitch covering theorem, 495, 510
Bessel’s inequality, 380
Big Picard theorem, 763
Binet Cauchy theorem, 1133
Blaschke products, 805
Bloch’s lemma, 751
block matrix, 77
Bochner integrable, 586
Borel Cantelli lemma, 183
Borel measure, 215
Borel regular, 453
Borel regularity, 451
Borel sets, 171
bounded continuous linear functions,
339
bounded variation, 629
box topology, 307
branch of the logarithm, 684
Brouwer ﬁxed point theorem, 294, 369
Brownian motion, 890
Calderon Zygmund decomposition, 545
Cantor diagonalization procedure, 144
Cantor function, 446
Cantor set, 445
Caratheodory, 209
Caratheodory extension theorem, 303
Caratheodory’s criterion, 450
Caratheodory’s procedure, 210
Cartesian coordinates, 53
1314

INDEX
1315
Casorati Weierstrass theorem, 664
Cauchy
general Cauchy integral formula,
670
integral formula for disk, 649
Cauchy Riemann equations, 643
Cauchy Schwarz inequality, 92, 365
Cauchy sequence, 112
Cauchy sequence, 104
Cayley Hamilton theorem, 75
central limit theorem, 879
chain rule, 116
change of variables, 1122
change of variables general case, 290
characteristic function, 180, 1015
characteristic polynomial, 74
chart, 1127
closed graph theorem, 345
closed set, 94, 148
closure of a set, 149
Coarea formula, 1118
coarea formula, 1116
cofactor, 68
compact, 135
compact injection map, 1249
compact set, 150
complement, 94
complete measure space, 210
completion of measure space, 253
conditional expectation, 893
conformal maps, 647, 736
connected, 152
connected components, 153
continuity set, 877
continuous function, 93, 149
convergence in measure, 183
convex
set, 366
convex
functions, 333
convolution, 329, 535
convolution of measures, 1022
Coordinates, 51
correlation, 988
countable, 22
counting zeros, 694
covariance, 987
Cramer’s rule, 71
cycle, 670
cylinder sets, 1036
cylindrical set, 1015
Darboux, 48
Darboux integral, 48
derivatives, 115
determinant, 63
product, 67
transpose, 65
diﬀerentiation
Radon measures, 512
dilations, 736
Dini derivates, 447
distribution, 858, 1081
distribution function, 232, 446, 542
distributional derivative, 1241
divergence theorem, 492
dominated convergence theorem, 202,
606
Doob Dynkin lemma, 866
Doob estimate, 900
Doob’s martingale estimate, 915
doubly periodic, 822
dual space, 350
duality maps, 363
Eberlein Smulian theorem, 359
Egoroﬀtheorem, 180
eigenvalues, 74, 699, 702
elementary factors, 789
elementary set, 313
elementary sets, 248
elliptic, 822
entire, 659
epsilon net, 136, 141
equality of mixed partial derivatives,
125
equivalence class, 24
equivalence relation, 23
Erling’s lemma, 1249
essential singularity, 665

1316
INDEX
Euler’s theorem, 817
exchange theorem, 56
exponential growth, 537
extended complex plane, 627
extension theorem, 1163
Fatou’s lemma, 196
ﬁltration, 903
ﬁnite intersection property, 140, 151
ﬁnite measure space, 172
Fourier series
uniform convergence, 362
Fourier transform L1, 525
fractional linear transformations, 736,
741
mapping three points, 738
Frechet derivative, 115
Fredholm alternative, 397
Fresnel integrals, 727
Fubini’s theorem, 243, 252, 261
Bochner integrable functions, 601
function, 20
uniformly continuous, 25
function element, 748, 850
functional equations, 840
fundamental theorem of algebra, 660
fundamental theorem of calculus, 47,
431, 433
general Radon measures, 503
Gamma function, 334, 457
gamma function, 811
gauge function, 347
Gauss’s formula, 812
Gaussian measure, 1031
Gerschgorin’s theorem, 698
Gram determinant, 373
Gram matrix, 373
Gramm Schmidt process, 82
great Picard theorem, 762
Hadamard three circles theorem, 689
Hahn Banach theorem, 348
Hardy Littlewood maximal function,
429
Hardy’s inequality, 334
harmonic functions, 646
Haursdorﬀmeasures, 449
Hausdorﬀand Lebesgue measure, 456,
458
Hausdorﬀdimension, 456
Hausdorﬀmaximal principle, 24, 271,
306, 347
Hausdorﬀmaximal theorem, 1305
Hausdorﬀmeasure
translation invariant, 453
Hausdorﬀmeasure and nonlinear maps,
466, 476
Hausdorﬀmeasures, 449
Hausdorﬀmetric, 167
Hausdorﬀspace, 148
Heine Borel, 25
Heine Borel theorem, 138
Hermitian, 85
Hilbert Schmidt operator, 988
Hilbert Schmidt operators, 390, 988
Hilbert Schmidt theorem, 382, 597
Hilbert space, 365
Holder’s inequality, 315
homotopic to a point, 781
Hormander condition, 546
implicit function theorem, 125, 128,
129
independent random vectors, 859, 990
indicator function, 180
inﬁnite products, 785
inner product space, 365
inner regular, 1000
inner regular measure, 215
interior point, 94
inverse function theorem, 129, 130
inverses and determinants, 70
inversions, 736
isogonal, 646, 735
isolated singularity, 664
isometric, 617
Ito isometry, 926
Ito representation theorem, 956
James map, 352

INDEX
1317
Jensen’s formula, 802
Jensens inequality, 333, 896
Kolmogorov extension theorem, 310
Lagrange multipliers, 130, 132
Laplace expansion, 68
Laplace transform, 538
Laurent series, 716
law, 1025
Lebesgue
set, 433
Lebesgue decomposition, 399
Lebesgue measure, 267
Lebesgue point, 431
limit of a function, 98
limit point, 148
limit points, 98
linear combination, 55, 66
linearly dependent, 55
linearly independent, 55
Liouville theorem, 659
Lipschitz, 26, 97, 107
Lipschitz boundary, 485, 1105
Lipschitz manifold, 1127
Lipschitz maps
extension, 1100
little Picard theorem, 852
locally compact , 150
locally ﬁnite, 481, 1123
locally Lipschitz, 461
Lusin’s theorem, 333
manifold, 1127
manifolds
radon measure, 1129
surface measure, 1129
Marcinkiewicz interpolation, 543
martingale, 896, 910
matrix
left inverse, 71
lower triangular, 71
non defective, 85
normal, 85
right inverse, 71
upper triangular, 71
maximal function
general Radon measures, 501
maximum modulus theorem, 685
mean value theorem
for integrals, 49
measurable, 209
Borel, 174
measurable function, 174
pointwise limits, 174
measurable functions
Borel, 182
combinations, 180
measurable rectangle, 248, 313
measurable representative, 612
measurable sets, 172, 210
measure space, 172
Mellin transformations, 724
meromorphic, 666
Merten’s theorem, 769
Meyer Serrin theorem, 1138
Mihlin’s theorem, 558
Minkowski functional, 362
Minkowski’s inequality, 321
minor, 68
Mittag Leﬄer, 728, 796
mixed partial derivatives, 123
modular function, 834, 836
modular group, 765, 824
module of periods, 820
molliﬁer, 329
monotone class, 247
monotone convergence theorem, 192
Montel’s theorem, 739, 761
Morrey’s inequality, 1087
multi-index, 97, 123, 157, 517
multipliers, 546
Muntz’s ﬁrst theorem, 377
Muntz’s second theorem, 378
Neumann series, 729
nonlinear Fubini’s theorem, 1122
normal, 867, 1025
normal family of functions, 741
normal topological space, 149
nowhere diﬀerentiable functions, 360

1318
INDEX
nuclear operator, 387
one point compactiﬁcation, 150, 218
open cover, 150
open mapping theorem, 342, 681
open set, 94
open sets, 147
operator norm, 112, 339
order, 811
order of a pole, 665
order of a zero, 657
order of an elliptic function, 822
orthonormal set, 378
outer measure, 183, 209
outer regular, 1000
outer regular measure, 215
partial derivative, 118
partial order, 24, 346
partially ordered set, 1305
partition, 33
partition of unity, 220, 482, 1125
period parallelogram, 822
Pettis theorem, 580
Phragmen Lindelof theorem, 687
pi systems, 257
pivot space, 1245
Plancherel theorem, 529
point of density, 464, 474, 1093
pointwise limits of measurable func-
tions, 581
polar decomposition, 411
pole, 665
polynomial, 157, 517
positive and negative parts of a mea-
sure, 441
positive linear functional, 221
power series
analytic functions, 653
power set, 17
precompact, 150, 167, 1249
primitive, 637
principal branch of logarithm, 685
principal ideal, 800
probability space, 857
product measure, 251
product rule, 1086
product topology, 150
projection in Hilbert space, 368
Prokhorov’s theorem, 1004
properties of integral
properties, 45
quotient space, 1276
Rademacher’s theorem, 1090, 1092
Radon Nikodym derivative, 402
Radon Nikodym property, 614
Radon Nikodym Theorem
σ ﬁnite measures, 402
ﬁnite measures, 399
Radon Nikodym theorem
Radon Measures, 515
random variable, 446, 857
random vector, 857
independent, 862
rank of a matrix, 72
real Schur form, 83
reﬂexive Banach Space, 353
reﬂexive Banach space, 419
region, 657
regular measure, 215
regular topological space, 148
removable singularity, 664
reproducing kernel space, 1063
residue, 705
resolvent set, 729
Riemann criterion, 37
Riemann integrable, 36
Riemann integral, 36
Riemann sphere, 627
Riemann Stieltjes integral, 36
Riesz map, 371
Riesz representation theorem, 619
C0 (X), 423
Hilbert space, 370
locally compact Hausdorﬀspace,
221
Riesz Representation theorem
C (X), 422

INDEX
1319
Riesz representation theorem Lp
ﬁnite measures, 412
Riesz representation theorem Lp
σ ﬁnite case, 418
Riesz representation theorem for L1
ﬁnite measures, 416
right polar decomposition, 87
Rouche’s theorem, 711
Runge’s theorem, 774
Sard’s lemma, 287
scalars, 53, 93
Schottky’s theorem, 759
Schroder Bernstein theorem, 21
Schwartz class, 1173
Schwarz formula, 655
Schwarz reﬂection principle, 679
Schwarz’s lemma, 742
self adjoint, 85
separability of C(H), 1004
separated, 152
separation theorem, 363
sequential compactness, 25
sequential weak* compactness, 357
sequentially compact set, 110
sets, 17
Shannon sampling theorem, 540
simple function, 187, 577
simple functions, 175
Skorokhod’s theorem, 1008
Sobolev Space
embedding theorem, 539
equivalent norms, 538
Sobolev space, 1135
Sobolev spaces, 539
span, 55, 66
spectral radius, 730
stereographic projection, 628, 760
Stirling’s formula, 813
stochastic process, 881
strict convexity, 363
strongly measurable, 577
subbasis, 306
submartingale, 896
submartingale convergence theorem, 900
subspace, 55
supermartingale, 896
support of a function, 219
Tietze extension theorem, 146
tight, 875, 1002
topological space, 147
total variation, 405, 435
totally bounded set, 136
totally ordered set, 1305
trace, 389
translation invariant, 269
translations, 736
trivial, 55
Tychonoﬀtheorem, 307
uniform boundedness theorem, 341
uniform convergence, 626
uniform convexity, 363
uniformly bounded, 141, 761
uniformly continuous, 25
uniformly equicontinuous, 141, 761
uniformly integrable, 203, 335
unimodular transformations, 824
upcrossing, 896
upper and lower sums, 34
Urysohn’s lemma, 216
variational inequality, 368
vector measures, 405, 612
Vector valued distributions, 1241
version, 890
Vitali convergence theorem, 204, 334
Vitali cover, 510
Vitali covering theorem, 272, 275, 276,
278, 1093
Vitali coverings, 276, 278, 1093
Vitali theorem, 765
volume of unit ball, 457
weak * convergence, 1079
weak convergence, 364
weak convergence of measures, 1007
weak derivative, 1081
weak topology, 354
weak∗measurable, 584

1320
INDEX
weak* topology, 354
weakly measurable, 577
Weierstrass
Stone Weierstrass theorem, 162
Weierstrass M test, 626
Weierstrass P function, 829
well ordered sets, 1307
winding number, 667
Wronskian, 80
Young’s inequality, 315, 427
zeta function, 813

