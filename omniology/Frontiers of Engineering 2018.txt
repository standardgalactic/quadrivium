
F R O N T I E R S  O F
ENGINEERING

THE NATIONAL ACADEMIES PRESS • 500 Fifth Street, NW • Washington, DC 20001
NOTICE: Publication of signed work signifies that it is judged a competent and use-
ful contribution worthy of public consideration, but it does not imply endorsement of 
conclusions or recommendations by the National Academy of Engineering (NAE). The 
interpretations and conclusions in such publications are those of the authors and do not 
purport to represent the views of the council, officers, or staff of the NAE.
Funding for the activity that led to this publication was provided by The Grainger 
Foundation, United Technologies Corporation, National Science Foundation, Defense 
Advanced Research Projects Agency, Department of Defense ASD(R&E) Research 
­Directorate—Laboratories Office, Air Force Office of Scientific Research, Microsoft 
Research, ­Cummins Inc., and individual donors. This material is based upon work 
­supported by the Air Force Office of Scientific Research under award number FA9550-
17-1-0406. Any opinions, findings, and conclusions or recommendations expressed in this 
material are those of the author(s) and do not necessarily reflect the views of the United 
States Air Force. This material is based upon work supported by the National Science 
Foundation under Grant No. 1724425. Any opinions, findings, and conclusions or recom-
mendations expressed in this material are those of the author(s) and do not necessarily 
reflect the views of the National Science Foundation.
International Standard Book Number-13:  978-0-309-46601-1
International Standard Book Number-10:  0-309-46601-6
Digital Object Identifier:  https://doi.org/10.17226/24906
Additional copies of this publication are available from the National Academies Press, 
500 Fifth Street, NW, Keck 360, Washington, DC 20001; (800) 624-6242 or (202) 334-3313; 
http://www.nap.edu.
Copyright 2018 by the National Academy of Sciences. All rights reserved.
Printed in the United States of America 
Suggestion citation: National Academy of Engineering. 2018. Frontiers of Engineering: 
Reports on Leading-Edge Engineering from the 2017 Symposium. Washington, DC: The 
National Academies Press. doi: https://doi.org/10.17226/24906.

The National Academy of Sciences was established in 1863 by an Act of ­Congress, 
signed by President Lincoln, as a private, nongovernmental institution to advise 
the nation on issues related to science and technology. Members are elected 
by their peers for outstanding contributions to research. Dr. Marcia McNutt is 
president.
The National Academy of Engineering was established in 1964 under the char-
ter of the National Academy of Sciences to bring the practices of engineering to 
advis­ing the nation. Members are elected by their peers for extraordinary contri-
butions to engineering. Dr. C. D. Mote, Jr., is president.
The National Academy of Medicine (formerly the Institute of Medicine) was 
established in 1970 under the charter of the National Academy of Sciences to 
advise the nation on medical and health issues. Members are elected by their 
peers for distinguished contributions to medicine and health. Dr. Victor J. Dzau 
is president.
The three Academies work together as the National Academies of Sciences, Engi­
neering, and Medicine to provide independent, objective analysis and ­advice to 
the nation and conduct other activities to solve complex problems and inform 
public policy decisions. The National Academies also encourage educa­tion and 
research, recognize outstanding contributions to knowledge, and ­increase public 
understanding in matters of science, engineering, and medicine. 
Learn more about the National Academies of Sciences, Engineering, and Medi-
cine at www.nationalacademies.org. 

iv
ORGANIZING COMMITTEE
ROBERT D. BRAUN (Chair), Dean of Engineering and Applied Science, 
University of Colorado Boulder
RAJAN BHATTACHARYYA, Senior Research Engineer, Information and 
Systems Sciences Laboratory, HRL Laboratories
KATHERINE DYKES, Senior Engineer, National Wind Technology Center, 
National Renewable Energy Laboratory
MARIA-PAZ GUTIERREZ, Associate Professor, Department of Architecture, 
University of California, Berkeley
XUE HAN, Assistant Professor, Department of Biomedical Engineering, Boston 
University
JEREMY MUNDAY, Associate Professor, Department of Electrical and 
Computer Engineering, University of Maryland
MARYAM SHANECHI, Assistant Professor and Viterbi Early Career Chair, 
Department of Electrical Engineering, University of Southern California
MARIJA TRCKA, Technology Sourcing Specialist, Innovation Business 
Development, United Technologies
Staff
JANET HUNZIKER, Senior Program Officer
SHERRI HUNTER, Program Coordinator

v
This volume presents papers on the topics covered at the National Academy 
of Engineering’s 2017 US Frontiers of Engineering Symposium. Every year the 
symposium brings together 100 outstanding young leaders in engineering to 
share their cutting-edge research and innovations in selected areas. The 2017 
symposium was hosted by United Technologies Research Center (UTRC) in East 
Hartford, Connecticut, September 25–27. The intent of this book is to convey the 
excitement of this unique meeting and to highlight innovative developments in 
engineering research and technical work. 
GOALS OF THE FRONTIERS OF ENGINEERING PROGRAM
The practice of engineering is continually changing. Engineers must be able 
not only to thrive in an environment of rapid technological change and globaliza-
tion but also to work on interdisciplinary teams. Today’s research is being done 
at the intersections of engineering disciplines, and successful researchers and 
practitioners must be aware of developments and challenges in areas that may 
not be familiar to them. 
At the annual 2½-day US Frontiers of Engineering Symposium, 100 of this 
country’s best and brightest engineers—ages 30 to 45, from academia, industry, 
and government and a variety of engineering disciplines—learn from their peers 
about pioneering work in different areas of engineering. The number of partici-
pants is limited to 100 to maximize opportunities for interactions and exchanges 
among the attendees, who are chosen through a competitive nomination and selec-
tion process. The symposium is designed to foster contacts and learning among 
promising individuals who would not meet in the usual round of professional 
Preface

vi	
PREFACE
meetings. This networking may lead to collaborative work, facilitate the transfer 
of new techniques and approaches, and produce insights and applications that 
bolster US innovative capacity. 
The four topics and the speakers for each year’s meeting are selected by an 
organizing committee of engineers in the same 30- to 45-year-old cohort as the 
participants. Speakers describe the challenges they face and communicate the 
excitement of their work to a technically sophisticated but nonspecialist audi-
ence. They provide a brief overview of their field of inquiry; define the frontiers 
of that field; describe experiments, prototypes, and design studies (completed or 
in progress) as well as new tools and methods, limitations and controversies; and 
assess the long-term significance of their work. 
THE 2017 SYMPOSIUM
The topics covered at the 2017 symposium were (1) machines that teach 
themselves, (2) energy strategies to power our future, (3) unraveling the com-
plexity of the brain, and (4) megatall buildings and other future places of work. 
The first session described machines that process information into useful 
output by learning their own models. The first speaker discussed the application 
of interactive machine learning to self-optimizing tutoring systems in classrooms, 
work that advances reinforcement learning—an important foundation for building 
machines that teach themselves. The next speaker focused on machine systems 
that utilize highly heterogeneous data (e.g., sensor streams, genomic data, text) to 
make inferences that improve health care through predictive models and individu-
alized treatment. The session concluded with a talk on machine learning qualities 
such as question-answering AI that are necessary for a future where machines 
interact naturally with humans. 
The next session addressed the question, “How will we power our future?” 
The answer will be multifaceted and involve power generation and storage, new 
grid technologies, and transportation electrification. The first speaker set the stage 
by discussing “deep decarbonization” and what it will take to move from a carbon-
based energy system to one based on renewable energy. Because this will require 
substantial changes to how electric power systems are planned and operated, the 
talk described emerging technologies that will improve real-time grid state aware-
ness, achieve more robust control over power flows, and enable comprehensive 
approaches to power system optimization. This was followed by a presentation 
on the merger of advanced physical models for wind energy with big data and 
analytics to enable a reduction in the cost of energy supplied by the next genera-
tion of wind plants. The third presenter talked about how imaging and machine 
learning will help design tomorrow’s energy conversion devices. The final speaker 
described the state of the art for stationary and dynamic wireless charging of 
electric vehicles and the challenges in performance, cost, and safety that need to 
be overcome for wide-scale adoption of wireless power transfer systems.

PREFACE	
vii
Because the brain is a complex system consisting of microscopic and macro-
scopic networks, understanding it requires simultaneous measurements at multiple 
spatiotemporal scales. In the session Unraveling the Complexity of the Brain, 
speakers outlined the advances that engineers have made in the quest to understand 
the brain, treat its disorders, and enhance its functions. The presentations described 
technologies to interface with the brain for recording and modulation, the neural 
basis of skill learning using brain-machine interfaces, new models for neuroscience, 
and efficient feature extraction and classification methods in neural interfaces. 
This decade launched the rise of a new breed of skyscrapers, megatall build-
ings, defined as being more than 600 meters tall. The session began with an 
overview of fundamental design transformations in the construction of megatall 
buildings and how their distinctive spatial characteristics influence the quality of 
life inside and outside the building. The next speaker addressed the role of digital 
interaction, physical-human interface, and intuitive behavior in the transformation 
of vertical transportation. This was followed by a talk on the functional natural 
materials such as bamboo that challenge the status quo of structural systems in 
high-rise buildings. The final speaker described the applications of insights from 
biology and mathematics to the design of material structures in the form of adap-
tive building skins, material assemblies, and architectural interventions. 
In addition to the plenary sessions, the attendees had many opportunities 
for informal interaction. On the first afternoon, they gathered in small groups for 
“Meet and Connect” sessions during which they presented short descriptions of 
their work and answered questions from their colleagues. This helped them get 
to know more about each other relatively early in the program. On the second 
afternoon, UTRC arranged tours of its state-of-the-art “innovation hub” that 
highlighted several research areas: digital service for Otis Elevator, measurement 
sciences and microscopy, human-machine interaction, machine learning, and 
additive and advanced manufacturing.
Every year a distinguished engineer addresses the participants at dinner on the 
first evening of the symposium. The 2017 speaker, Dr. David E. Parekh, corporate 
vice president and director of UTRC, gave the dinner speech titled, “Navigating 
Innovation’s Uncertain Course.” He compared the ability to know where innova-
tion is heading to an autocross competition—one does not know the race course, it 
is constantly changing, and others are in fast pursuit. He noted that the transitions 
from film to digital imaging and from taxis to shared transportation exemplify the 
challenges of managing disruptive technological change. Dr. Parekh closed his 
presentation by observing that innovation is best served when it is developed by 
people with different perspectives.
The NAE is deeply grateful to the following for their support of the 2017 US 
Frontiers of Engineering symposium:
•	
United Technologies Corporation
•	
The Grainger Foundation

viii	
PREFACE
•	
Defense Advanced Research Projects Agency
•	
Air Force Office of Scientific Research (This material is based upon work 
supported by the Air Force Office of Scientific Research under award 
number FA9550-17-1-0406. Any opinions, findings, and conclusions or 
recommendations expressed in this material are those of the author(s) 
and do not necessarily reflect the views of the United States Air Force.)
•	
Department of Defense ASD(R&E) Research Directorate–Laboratories 
Office
•	
National Science Foundation (This material is based on work supported 
by the NSF under grant EFMA-1724425. Any opinions, findings, and 
conclusions or recommendations expressed in this material are those 
of the author(s) and do not necessarily reflect the views of the National 
Science Foundation.)
•	
Microsoft Research
•	
Cummins Inc.
•	
Individual contributors
We also thank the members of the Symposium Organizing Committee (p. iv), 
chaired by Dr. Robert Braun, for planning and organizing the event.

ix
Contents
MACHINES THAT TEACH THEMSELVES
Introduction	
3
	
Rajan Bhattacharyya
Humans and Computers Working Together to Measure Machine 	
 
Learning Interpretability	
5
	
Jordan Boyd-Graber
ENERGY STRATEGIES TO POWER OUR FUTURE
Introduction	
15
	
Katherine Dykes and Jeremy Munday
Agile Fractal Systems: Reenvisioning Power System Architecture	
17
	
Timothy D. Heidel and Craig Miller
Big Data and Analytics for Wind Energy Operations and Maintenance: 	
 
Opportunities, Trends, and Challenges in the Industrial Internet	
25
	
Bouchra Bouqata
Across Dimensions and Scales: How Imaging and Machine Learning 	
 
Will Help Design Tomorrow’s Energy Conversion Devices	
29
	
Mariana Bertoni

x	
CONTENTS
Wireless Charging of Electric Vehicles	
37
	
Khurram Afridi
UNRAVELING THE COMPLEXITY OF THE BRAIN
Introduction	
49
	
Xue Han and Maryam M. Shanechi
Technologies to Interface with the Brain for Recording and Modulation	
51
	
Ellis Meng
Brain-Machine Interface Paradigms for Neuroscience and Clinical 	
 
Translation	
57
	
Samantha R. Santacruz, Vivek R. Athalye, Ryan M. Neely, and  
Jose M. Carmena
The Roles of Machine Learning in Biomedical Science	
61
	
Konrad Paul Kording, Ari S. Benjamin, Roozbeh Farhoodi, and  
Joshua I. Glaser
Efficient Feature Extraction and Classification Methods in Neural 	
 
Interfaces	
73
	
Mahsa Shoaran, Benyamin A. Haghi, Masoud Farivar, and  
Azita Emami
MEGATALL BUILDINGS AND OTHER FUTURE PLACES OF WORK
Introduction	
83
	
Maria Paz Gutierrez and Marija Trcka
The Evolution of Elevators: Physical-Human Interface, Digital Interaction, 	
 
and Megatall Buildings	
85
	
Stephen R. Nichols
Supertall Timber: Functional Natural Materials for High-Rise Structures	
99
	
Michael H. Ramage
Applications of Insights from Biology and Mathematics to the Design 	
 
of Material Structures	
105
	
Jenny E. Sabin

CONTENTS	
xi
APPENDIXES
Contributors	
113
Participants	
117
Program	
125

Machines That Teach Themselves


3
The human race has been using tools for more than 2.5 million years, and 
building machines for just more than 2,000 years. Over the past 200 years, humans 
developed machines to do physical work during the Industrial Age, and in the past 
50 years innovations in technology areas such as electronics and computer science 
spawned the Digital Age. 
Until now, machines were designed by hand to perform specialized functions 
in a highly efficient way using engineering principles. In the Information Age, 
data volume is increasing by 40 percent annually and streaming at faster rates 
each year. Moreover, this exponential growth is dominated by an acceleration in 
unstructured data due to the variety of sources, which include documents, video, 
audio, and embedded sensors. Finally, high dimensionality and uncertainty in 
data require new computational methods to extract latent patterns and semantics. 
Taken together, these challenges necessitate a new way to build machines to make 
Information Age data useful. 
In this session the speakers explored machines that process information into 
useful output in a variety of applications but that are optimized in a very differ-
ent way: by learning their own models. Emma Brunskill (Stanford University) 
opened the session with a presentation on how interactive machine learning can be 
applied to self-optimizing tutoring systems in classrooms.1 Her work advances the 
paradigm of reinforcement learning, an important pillar in building machines that 
teach themselves. Suchi Saria (Johns Hopkins University) focused on machine 
systems that utilize highly heterogeneous data, ranging from sensor streams 
and genomic data to unstructured data, such as text, to perform inference.1 She 
1  Paper not included in this volume.
Machines That Teach Themselves
Rajan Bhattacharyya
HRL Laboratories

4	
FRONTIERS OF ENGINEERING
explained how she applies a variety of machine learning methods and computa-
tional statistics to improve health care through predictive models and individual-
ized treatment. Jordan Boyd-Graber (University of Maryland) discussed qualities 
that ubiquitous machine learning should have to allow for a future filled with 
“natural” interactions with humans. He explained the use of question-answering 
artificial intelligence (AI) as a way of evaluating how well AI systems can com-
municate what they are “thinking” to humans.

Machine learning is ubiquitous: it is involved in detecting spam emails, 
flagging fraudulent purchases, and providing the next movie in a Netflix binge. 
But few users at the mercy of machine learning outputs know what is happening 
behind the curtain. My research goal is to demystify the black box for nonexperts 
by creat­ing algorithms that can inform, collaborate, and compete in real-world 
settings.
This is at odds with mainstream machine learning. Topic models, for exam-
ple, are sold as a tool for understanding large data collections: lawyers scouring 
Enron emails for a smoking gun, journalists making sense of Wikileaks, or human-
ists characterizing the oeuvre of Lope de Vega. But topic models’ proponents 
never asked what those lawyers, journalists, or humanists needed. Instead, they 
optimized held-out likelihood.
THE NEED FOR IMPROVED INTERPRETABILITY
When my colleagues and I developed an interpretability measure to assess 
whether topic model users understood the models’ outputs, we found that inter-
pretability and held-out likelihood were negatively correlated (Chang et al. 2009)! 
The machine learning community (including me) had fetishized complexity at the 
expense of usability.
Understanding what users want and need offers technical improvements to 
machine learning methods, and it improves the social process of machine learn-
ing adoption. A program manager who used topic models to characterize National 
Institutes of Health (NIH) research investments uncovered interesting synergies 
and trends, but the results were unpresentable because of a fatal flaw: one of the 
Humans and Computers Working 
Together to Measure Machine 
Learning Interpretability
Jordan Boyd-Graber
University of Maryland
5

6	
FRONTIERS OF ENGINEERING
700 clusters lumped urology together with the nervous system, ­anathema to NIH 
insiders (Talley et al. 2011). Algorithms that prevent nonexperts from fixing such 
obvious problems (obvious to a human, that is) will never overcome the social 
barriers that often hamper adoption.
These problems are also evident in supervised machine learning. Ribeiro 
and colleagues (2016) cite an example of a classifier to distinguish wolves from 
dogs that detects only whether the background is snow. More specifically for 
deep learning, Karpathy and colleagues (2015) look at the computational units 
responsible for detecting the end of phrases in natural language or computer code.
These first steps at interpretability fall short because they ignore utility. At 
the risk of caricature, engineers can optimize only what they can measure. How 
can ­researchers actually measure what machine learning algorithms are supposed 
to be doing?
QUESTION ANSWERING
A brief detour through question answering (QA) can shed light on the answer 
to that question. QA is difficult because it has all the nuance and ambiguity associ-
ated with natural language processing (NLP) tasks and it requires deep, expert-
level world knowledge.
Completely open-domain QA is considered AI-complete (Yampolskiy 2013). 
Short-answer QA can be made more interactive and more discriminative by giv-
ing up the assumptions of batch QA to allow questions to be interrupted so that 
answers provided earlier reward deeper knowledge. 
Quiz Bowl
Fortunately, there is a ready-made source of questions written with these 
properties from a competition known as Quiz Bowl. Thousands of questions 
are written every year for competitions that engage participants from middle 
schoolers to grizzled veterans on the “open circuit.” These questions represent 
decades of iterative refinement of how to best discriminate which humans are most 
knowledgeable (in contrast, Jeopardy’s format has not changed since its debut 
half a century ago; its television-oriented format is thus not considered as “pure” 
a competition among trivia enthusiasts).
Interpretability cannot be divorced from the task a machine learning algo-
rithm is attempting to solve. Here, the existence of Quiz Bowl as a popular 
recreational activity is again a benefit: thousands of trivia enthusiasts form teams 
to compete in Quiz Bowl tournaments. Thus far, our algorithm has played only 
by itself. Can it be a good team player? And can it learn from its teammates? 
The answers to these questions can also reveal how useful it is at conveying 
its intentions.

HUMANS AND COMPUTERS WORKING TOGETHER	
7
BOX 1   
Sample Quiz Bowl Question
The question begins with obscure information and incorporates more 
well-known clues as it progresses. In our exhibition match, Ken Jennings 
answered (*) this question before the computer could (**), showing he 
had deeper knowledge on this topic.
Q: This man ordered Thomas Larkin to buy him 70 square miles 
of land, leading him to acquire his Mariposa gold mine. He married 
­Jessie, the daughter of Thomas Hart Benton, and, during the Civil War, 
he controversially confiscated (*) slave-holder property while acting as 
the leader of Missouri. Kit Carson served as the guide for the first two of 
his expeditions to survey the American West. For 10 points, name this 
explorer known as “the Pathfinder” (**) who was also the first presidential 
candidate of the Republican Party.
A: John C. Fremont
Box 1 shows an example of a question written to reward deeper knowledge 
and the places in the text where our system (**) and Ken Jennings1 (*) answered 
the question.
A moderator reads the question word by word and the first player who knows 
the answer uses a signaling device to “buzz in.” If the player has the correct answer, 
he earns points; if not, the moderator reads the rest of the question to the opponent. 
Because the question begins with obscure clues and moves to more well-known 
information, the player who can buzz first presumably has more knowledge.
We have good evidence that Quiz Bowl serves as a good setting for conveying 
how computers think. Our trivia-playing robot (Boyd-Graber et al. 2012; Iyyer 
et al. 2014, 2015) faced off against four former Jeopardy champions in front of 
600 high school students.2 The computer claimed an early lead, but we foolishly 
projected the computer’s thought process for all to see (Figure 1). The humans 
learned to read the algorithm’s ranked dot products and schemed to answer just 
before the computer. In five years of teaching machine learning, I have never had 
students catch on so quickly to how linear classifiers work. The probing ques-
tions from high school students in the audience showed that they caught on too. 
1   Ken Jennings holds the record for longest winning streak—74 consecutive games in 2004—on 
the quiz show Jeopardy.
2   See https://www.youtube.com/watch?v=LqsUaprYMOw.

8	
FRONTIERS OF ENGINEERING
FIGURE 1  When opponents can see what a computer is thinking in a trivia game, they 
can more easily defeat it.
(Later, when we played against Ken Jennings,3 he was not able to see the system’s 
thought process and our system did much better.)
“Centaur Chess”
A growing trend in competitive chess is “centaur chess” (Thompson 2013). 
The best chess players are neither a human nor a computer but a computer and a 
human playing together. The language of chess is relatively simple; given a single 
board configuration, only a handful of moves are worthwhile. Unlike chess, Quiz 
Bowl is grounded in language, which makes the task of explaining hypotheses, 
features, and probabilities more complicated.
I propose a “Centaur Quiz Bowl” as a method of evaluating the interpret-
ability of predictions from a machine learning system. The system could be part 
of a team with humans if it could communicate its hypotheses to its teammates.
3   See https://www.youtube.com/watch?v=kTXJCEvCDYk.

HUMANS AND COMPUTERS WORKING TOGETHER	
9
EFFORTS TO EXPLAIN MACHINE LEARNING ANSWERS
At our exhibitions, we have shown ordered lists of predictions while the sys-
tem is considering answers. This is effective for communicating what the system is 
“thinking,” but not why it provides an answer. Thus, a prerequisite for ­cooperative 
QA is the creation of interpretable explanations for the answers that machine learn-
ing systems provide.
Linear Approximations
Deep learning algorithms have earned a reputation for being ­uninterpretable 
and susceptible to tampering to produce the wrong answer (Szegedy et al. 
2013). But, instead of making predictions based on explicit features, one of their 
strengths is that they embed features in a continuous space. These representa-
tions are central to deep learning, but how they translate into final results is often 
­difficult—if not impossible—to determine. Ribeiro and colleagues (2016) propose 
local interpretable model-agnostic explanations (LIME): linear approximations of 
a complicated deep learning model around an example.
LIME can, for example, create a story of why a particular word caused an 
algorithm to provide a specific answer to a question. A logistic regression (a linear 
approximation of a more complicated predictor) can explain that seeing the words 
“poet” and “Leander” in a question would be a good explanation of why “John 
Keats” would be a reasonable answer. But individual words are often poor clues 
for why the algorithm suggests a particular answer. It would be even better to 
highlight the phrase “this poet of ‘On a Picture of Leander’” as its explanation.
Human-Computer Teamwork
I propose to extend LIME’s formula to capture a larger set of features as pos-
sible explanations for a model’s predictions. For example, “And no birds sing” is 
a well-known line from Keats’ poem “La Belle Dame sans Merci,” but explaining 
the prediction by providing a high weight for just the word “sing” would be a poor 
predictor. The algorithm should make itself clear by explaining that the whole 
phrase “no birds sing” is why it cites “La Belle Dame sans Merci” as the answer. 
While recurrent neural networks can discover these multiword patterns, they lack 
a clear mechanism to communicate this clue to a user.
Fortunately, Quiz Bowl provides the framework needed to measure the col-
laboration between computers and humans. The goal of a Quiz Bowl team is to 
take a combination of players and produce a consensus answer. It is thus the ideal 
proxy for seeing how well computers can help humans answer questions—if it is 
possible to separately assess how well the computer aids its “teammates.”

10	
FRONTIERS OF ENGINEERING
Statistical Analyses and Visualizations
Just as baseball computes a “runs created” statistic (James 1985) for players 
to gauge how much they contribute to a team, Quiz Bowlers create statistical 
analyses to determine how effective a player is.4 A simple version of this analysis 
is a regression that predicts the number of points a team will win by (a negative 
number if it is a loss) with a given set of players.
There are two independent variables we want to understand: the effect of the 
algorithm and the effect of visualizations. We analyze the effect of a QA system 
and a visualization as two distinct “team members.” The better a visualization is 
doing, the better its individual statistics will be. This allows us to measure the 
contribution of a visualization to overall team performance and thus optimize 
how well a visualization is communicating what a machine learning algorithm 
is thinking.
CONCLUSION
Combined with the renaissance of reinforcement learning (Thrun and ­Littman 
2000) in machine learning, having a clear metric based on interpretability allows 
algorithms to adapt their presentations to best aid human collaboration. In other 
words, the rise of machine learning in everyday life becomes a virtuous cycle: 
with a clear objective that captures human interpretability, machine learning algo-
rithms become less opaque and more understandable every time they are used.
Despite the hyperbole about an impending robot apocalypse associated with 
artificial intelligence killing all humans, I think a bigger threat is automation dis-
rupting human livelihood. In juxtaposition to the robot apocalypse is a utopia of 
human-computer cooperation, where machines and people work together using 
their complementary skills to be better than either could be on their own. This is 
the future that I would like to live in, and if we are to get there as engineers we 
need to be able to measure our progress toward that goal.
REFERENCES
Boyd-Graber J, Satinoff B, He H, Daumé H III. 2012. Besting the quiz master: Crowdsourcing incre-
mental classification games. Proceedings of the 2012 Joint Conference on Empirical Methods 
in Natural Language Processing and Computational Natural Language Learning, July 12–14, 
Jeju Island, Korea. 
Chang J, Boyd-Graber J, Wang C, Gerrish S, Blei DM. 2009. Reading tea leaves: How humans 
interpret topic models. Proceedings of Advances in Neural Information Processing Systems, 
December 7–10, Vancouver. 
Iyyer M, Boyd-Graber J, Claudino L, Socher R, Daumé H III. 2014. A neural network for factoid 
question answering over paragraphs. Proceedings of Empirical Methods in Natural Language 
Processing, October 25–29, Doha.
4   The Quiz Bowl Statistics Program (SQBS), http://ai.stanford.edu/~csewell/sqbs/.

HUMANS AND COMPUTERS WORKING TOGETHER	
11
Iyyer M, Manjunatha V, Boyd-Graber J, Daumé H III. 2015. Deep unordered composition rivals 
syntactic methods for text classification. In: Association for Computational Linguistics, August 
15–20, Beijing. 
James B. 1985. The Bill James Historical Baseball Abstract. New York: Villard. 
Karpathy A, Johnson J, Li F-F. 2015. Visualizing and understanding recurrent networks. arXiv, 
abs/1506.02078. http://arxiv.org/abs/1506.02078.
Ribeiro MT, Singh S, Guestrin C. 2016. “Why should I trust you?”: Explaining the predictions of 
any classifier. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge 
Discovery and Data Mining, August 13–17, San Francisco.
Szegedy C, Zaremba W, Sutskever I, Bruna J, Erhan D, Goodfellow IJ, Fergus R. 2013. Intriguing 
properties of neural networks. arXiv, abs/1312.6199. http://arxiv.org/abs/1312.6199.
Talley EM, Newman D, Mimno D, Herr BW II, Wallach HM, Burns GAPC, Leenders AGM, 
­McCallum A. 2011. Database of NIH grants using machine-learned categories and graphical 
clustering. Nature Methods 8(6):443–444.
Thompson C. 2013. Smarter Than You Think: How Technology Is Changing Our Minds for the ­Better. 
London: Penguin Group. 
Thrun S, Littman ML. 2000. EW of reinforcement learning. AI Magazine 21(1):103–105.
Yampolskiy RV. 2013. Turing test as a defining feature of AI-completeness. In: Artificial Intelligence, 
Evolutionary Computing and Metaheuristics: In the Footsteps of Alan Turing, ed. Yan X-S. 
Berlin: Springer-Verlag. pp. 3–17.


Energy Strategies to Power Our Future


15
Energy Strategies to Power Our Future
Katherine Dykes
National Renewable Energy Laboratory
Jeremy Munday
University of Maryland
Power consumption is a good proxy for quality of life, and societies around 
the world currently consume about 18 terawatts (TW) globally. Greater than 60 
percent of that power is derived from fossil fuels. In many countries, there has 
been increasing use of renewable energy, due to both declining costs of renewable 
energy and national policies that seek to increase energy security and decrease 
the environmental footprint of the energy sector. This session aimed to address 
the question, “how will we power our future?” Answers were multifaceted and 
involved not only power generation and storage but also new grid technologies 
and transportation electrification.
Over the next few decades, new power generation technologies will be 
deployed at a large scale to match power demand with the lowest cost and envi-
ronmental impact. As a resource, solar power is abundant (>105 TW at Earth’s 
surface), although it makes up only about 1 percent of US electricity generation. 
Challenges to widespread adoption include the need for reduced cost, improved 
efficiency, and storage solutions over a range of time scales (hourly to seasonal). 
For wind energy, a substantial US market has developed and wind now supplies 
nearly 6 percent of US electricity demand. However, the complexity of mesoscale 
flow as it makes its way down and through the plant, transforming into electricity 
as it goes, involves many open research challenges. 
Both solar and wind energy promise to become prominent sources of elec-
tricity generation. But their variable nature means that the current grid system 
needs to be flexible in order to adapt as solar and wind energy are added. Such 
adaptability necessitates substantial technology innovation to transform the grid 
to support high levels of variable generation. 

16	
FRONTIERS OF ENGINEERING
Furthermore, the grid of the future is likely to support a significant amount of 
electric transportation on the distribution side. The transportation sector consumes 
nearly 30 percent of US energy production, with 90 percent from fossil fuels. 
While electrification could significantly reduce petroleum use, it affects the grid 
in terms of power generation and distribution. Concurrently, new opportunities are 
emerging in storage and new grid technologies, with high renewable penetration 
and dynamic distribution systems.
The first speaker, Tim Heidel (National Rural Electric Cooperative Associa-
tion), set the stage by discussing “deep decarbonization” and what it will take to 
move from a carbon-rich energy system to one dominated by renewable energy, 
a transition that will require substantial changes to how electric power systems 
are planned and operated. He described technologies emerging from the research 
community that promise to improve real-time grid state awareness, achieve more 
robust control over power flows, and enable comprehensive approaches to power 
system optimization. Next, Bouchra Bouqata (GE Global Research Center) 
discussed how the merger of advanced physical models for wind energy with 
big data and analytics will enable a new generation of wind plants with substan-
tially reduced energy costs, increasing the competitiveness of wind with fossil 
fuels even at very low cost levels. Mariana Bertoni (Arizona State University) 
explained how imaging and machine learning will help design tomorrow’s energy 
conversion devices. Khurram Afridi (University of Colorado Boulder) discussed 
wireless power transfer that allows self-driving vehicles to be fully autonomous. 
He described the state of the art for stationary and dynamic wireless power transfer 
for electric vehicles, and identified performance, cost, and safety challenges that 
need to be overcome for wireless power transfer systems to be widely adopted.

The methods used to plan and operate the grid since the dawn of electrifica-
tion have worked well. Indeed, the US grid has set the absolute standard for scale 
and performance of engineered systems for more than a century, but new tech-
nologies, economics, social attitudes, and environmental sensibilities are calling 
this model into question.
Rapidly falling costs of distributed electricity generation methods such as 
solar photovoltaics and storage technologies coupled with the growing emphasis 
on improving electric power system resiliency have motivated the investigation 
of alternative architectures for planning and operating electric power systems.
In addition, recent advances in power electronics, computation, and com-
munication technologies could provide the opportunity to optimize and control 
grid operations closer to the locations where power is consumed (Kassakian et 
al. 2011), offering significant efficiency, cost, reliability, and emissions benefits.
But the methods that have historically been relied on for designing and 
operating power systems will prevent the full realization of the potential benefits 
associated with the newer technologies. Power system design and control ­methods 
that are both agile and fractal are needed to fully realize the benefits offered by 
distributed generation and storage technologies.
BACKGROUND
In a 2014 speech, then US Secretary of Energy Ernest Moniz defined the 
electrical grid of North America as “a continent-spanning machine of immense 
complexity that is at its best when it is invisible” (Moniz 2014). There has prob-
Agile Fractal Systems:  
Reenvisioning Power System Architecture
Timothy D. Heidel and Craig Miller
National Rural Electric Cooperative Association
17

18	
FRONTIERS OF ENGINEERING
ably never been a more succinct and accurate definition of the grid that has grown 
from the first central power plant opened in 1882 in Manhattan.
For more than a century the electric power delivery system has evolved 
continuously as generations of engineers have identified improvements enabling 
greater reliability, resilience, and lower cost. Over time, every component and 
procedure has been refined and polished. Today, the grid operates with impressive 
reliability, often making it invisible.
The grid’s generally routine reliability is largely a consequence of the sys-
tem’s scale, literally its angular momentum. Titanic power flows from the Hoover 
Dam and its kin, an immense fleet of large-scale central power generation stations 
throughout the country. Small generators and loads are effortlessly swept into 
synchronicity by the current flowing from these huge turbines. This has proven to 
be a very good way to design a system, especially given the economies of scale 
and increased efficiency of most electricity generation technologies.
RECENT CHANGES MOTIVATING NEW ADAPTATION
The recent rapid growth of distributed energy resources located at the far, thin 
edge of the grid is calling the existing model into question. As these resources 
continue to proliferate, individual homes, businesses, and factories will begin to 
have a far larger influence on the operation of the grid both locally and throughout 
the system (Kristov 2015).
Distributed and, particularly, customer-owned generation, thermal and elec-
trical storage, and load control technology such as communicating thermostats 
and building management systems all raise the question of what constitutes a 
grid. Is the grid the continent-spanning totality, or is it one utility, one feeder, one 
portion of a feeder, or one building? The answer is, increasingly, all of these. A 
useful working definition of a grid is a collection of electrical assets (generation, 
load, storage, transport) that can be controlled by a single entity. By this defini-
tion, grids range from individual buildings to regional transmission organizations 
(RTOs) spanning multiple states.
A building energy management system may control rooftop photovoltaic or 
gas-powered combined heat and power technologies, loads, energy storage, and 
purchases from or sales to the grid. It is an electrical grid in every sense except 
scale and presents many of the same problems in optimal control. It must also act 
in harmony with all the other actors in the grid. This will become increasingly 
critical as the electric power system as a whole evolves to rely ever more heavily 
on distributed energy resources.
This is a unique time of challenges to adapt the grid for new and chang-
ing needs. The challenges present an opportunity to think beyond incremental 
improvement to a fundamental reimagining and reinvention, building on emergent 
technology in distributed generation and sensor technology and advances in com-
munications and industrial controls.

AGILE FRACTAL SYSTEMS	
19
AGILE AND FRACTAL GRIDS
The hierarchical model of the grid challenges the old simplifying dichotomy 
in which generation and transmission companies thought of the distribution system 
as an exogenous, slowly varying, uncontrollable load, and distribution companies 
treated the transmission systems as an infinite bus. With many systems and actors 
involved, the fundamental problem in operations moves from pure control to 
harmonization.
A conglomeration of today’s distinct and incompatible methods of operating 
buildings, campuses, feeders, distribution systems, generation and transmission 
systems, RTOs, and independent system operators (ISOs) will not enable high 
potential agility. Furthermore, it will create a morass of interoperability standards 
and local, ad hoc, idiosyncratic methods of coordination.
Efforts to establish commonality in the problems of grid operations across 
many scales can move the system closer to a grid that continuously adapts, col-
laborates, and harmonizes to achieve greater reliability, resiliency, and efficiency. 
We believe that such a grid must be agile and fractal.
What Is an Agile Grid?
To be agile in this context, a grid must be capable of dynamically reconfigur-
ing and optimizing based on rapidly changing local conditions.
Even under ideal conditions the grid is constantly changing—components 
are installed and retired every day, and load varies with weather, season, and 
the vagaries of human activity. Beyond these (literally) “blue sky” variations, 
storms, natural disasters, equipment failures, and other factors disrupt normal 
grid operations.
Variations have always been present, but they are poised to have more sig-
nificant impacts as new weather-dependent generation sources (such as solar and 
wind) and new electricity uses (such as electric vehicles) become ubiquitous. 
Efforts to design and build the grid of the future must therefore be based not on a 
static approach but on a design process that is constantly evolving and that allows 
the routine and continuous adaptation of operations to account for changing condi-
tions and circumstances.
As new technologies enable a more efficient grid, the fiction of a static grid—
designed to a fixed point and then simply operated as designed—will be further 
undermined. A campus or individual building in an office park may sometimes 
operate autonomously, sometimes focus on local coordination, sometimes operate 
as part of a much larger whole. The future grid must be envisioned as a grid of 
grids of grids, dynamically adapting when challenged.

20	
FRONTIERS OF ENGINEERING
What Is a Fractal Grid?
Fractal design is an essential element to achieve desired grid agility. ­Taking 
inspiration from fractal geometric figures, fractal grids will exhibit the same con-
trol and operational characteristics at every scale.
In a fractal grid, any part of the overall power system will be capable of 
performing all of the functions of the full grid today. With fractal design, parts 
of the grid can safely isolate from the rest of the power system if and when it is 
optimal to do so (e.g., in response to local weather conditions, changes in fuel 
costs) but return to the broader system when conditions change. Decisions on how 
and when to segment parts of the system will be based on economic, engineering, 
and business considerations.
Figure 1 illustrates the concept of an agile, fractal grid. Figure 1a illustrates 
the current operation of a distribution grid. Energy flows to customers from two 
substations and the system operates with a tree structure. A normally open switch 
isolates the green and blue portions of the distribution system. Individual cus­
tomers with generation or storage can use power generated locally and may in 
some circumstances be able to feed that power back to the local grid.
Figure 1b illustrates how the grid might be reconfigured after an equipment 
or line failure. In this scenario, energy is still fed from two substations, but cer-
tain customers are now receiving power from Substation B instead of Substation 
A. This scenario is becoming increasingly common as utilities install automated 
switching technologies in distribution systems.
Finally, Figure 1c illustrates the potential for a portion of the grid, correspond-
ing to a small group of customers, to further isolate from the rest of the system for 
business or economic reasons. That portion of the system would consume power, 
in this specific scenario, purely based on locally available generation resources. 
Eventually, one would generally expect the operation of the system to return to 
that shown in Figure 1a.
TECHNICAL CHALLENGES
Rearchitecting the control of electric power systems will not be achieved 
quickly or simply. Indeed, the study of grid architecture is emerging as an 
important new research domain (e.g., Taft and Becker-Dippmann 2015). But the 
technology needed is there or nearly there.
Achieving the transition to an agile and fractal future grid will rely primarily 
on three classes of innovation:
(1)	 precise state awareness,
(2)	 precise controls, and
(3)	 advanced analytics (including forecasting and optimization technologies).

AGILE FRACTAL SYSTEMS	
21
FIGURE 1  Agile, fractal grid scenarios. (a) Normal distribution system operations with 
power fed from two substations. The green and blue portions of the feeders are electrically 
isolated by a normally open switch. (b) Distribution system reconfiguration, widely used 
today, transfers some customers to a new substation feed in the case of an outage in a por-
tion of the network to minimize the scale and duration of the outage. (c) Agile, fractal grid 
design enables portions of the system (shown in red) to operate independently in order to 
satisfy objectives for reliability and economics. Decisions on when and how to segment 
networks can be made centrally or in a distributed fashion.

22	
FRONTIERS OF ENGINEERING
Precise State Awareness
Successful grid operations in an agile, fractal environment will require pre-
cise knowledge of the state of the grid at all times and locations. Grid operators 
need to understand the operating state and the real-time capability of loads, gen-
erators, and storage devices. Ensuring the safety of utility personnel and customers 
will also require a precise understanding, at all times, of what parts of the system 
are connected to each other (and what reconfiguration options are permitted).
Fortunately, recent years have seen dramatic advances in sensor technologies 
that can contribute to state awareness, such as communicating digital consump-
tion meters and distribution system phasor measurement units (von Meier et al. 
2017). The rapidly falling costs of communication technologies also enable grid 
operators at all levels to communicate state-related information more often and 
on a more granular basis.
Precise Controls
Many companies are developing advanced switching and power electron-
ics technologies that can enable more rapid and precise control (Bhattacharya 
2017). More advanced protection system devices, reactive power controllers, 
networked switches, and disconnect-capable meters can enable more agile volt/
voltage-ampere reactive (VAR) control throughout the system and a wider range 
of feasible system reconfiguration options.
Many of these technologies are already being adopted in the utility community 
to reduce system losses, enhance efficiency through conservation voltage reduc-
tion, or improve resiliency during and after storms. The power ­electronics–based 
inverters that interface with distributed energy resources such as photo­voltaics or 
storage devices will play an increasingly important role in enabling more precise 
control of the system.
ADVANCED ANALYTICS
A new generation of electricity system data analytics is needed (National 
Academies 2016), with more precise and accurate algorithms for forecasting 
the evolution of customer needs and generation resource capabilities. Scalable 
algorithms will also need to be developed to optimize large, diverse fleets of 
controllable resources (Panciatici et al. 2014). These algorithms will help translate 
improved state awareness into decisions on how best to deploy distributed energy 
resources and other controllable devices.
Effectively and securely managing the transport, storage, and analysis of data 
among a large number of diverse stakeholders will be a key architectural design 
challenge. Advances in the analysis of corrupted or incomplete data will also be 
critically important. Many of these advances will rely on techniques for making 
decisions in the face of significant uncertainty.

AGILE FRACTAL SYSTEMS	
23
CONCLUSION
Analytically driven and agile control of the grid is being made technologi-
cally possible by declining costs of renewable and distributed generation tech-
nologies, higher-performance computing, and high-bandwidth communications, 
coupled with advances in power electronics and related control technologies. 
Indeed, many of the individual components required to realize agile, fractal grid 
operations are either already available or in advanced development.
But significant research and development are still needed to determine how 
to optimally integrate all the required component technologies. A particular chal-
lenge will be harmonization of this vision for future grid operation with the reality 
of continuous incremental change, which is necessary to the engineering of all 
critical infrastructure technologies. Control systems that are consistent with agile, 
fractal operation will have to coexist for some time with the control approaches 
that are used widely today.
As this new architecture for the control of electricity delivery infrastructure 
becomes widely used, we expect it will be possible to achieve greater reliability, 
resiliency, and efficiency while also easing the challenge of adapting to future 
changes. Finally, we believe insights gained throughout this transformation could 
have important implications for the design of other highly distributed engineered 
systems.
REFERENCES
Bhattacharya S. 2017. Smart transformers will make the grid cleaner and more flexible. IEEE 
­Spectrum, June. http://spectrum.ieee.org/energy/renewables/smart-transformers-will-make-the-
grid-cleaner-and-more-flexible.
Kassakian JG, Schmalensee R, Desgroseilliers G, Heidel TD, Afridi K, Farid AM, Grochow JM, 
Hogan WW, Jacoby HD, Kirtley JL, and 5 others. 2011. The Future of the Electric Grid: An 
Inter­disciplinary MIT Study. Massachusetts Institute of Technology Energy Initiative, December. 
http://mit.edu/mitei/research/studies/the-electric-grid-2011.shtml.
Kristov L. 2015. The future history of tomorrow’s energy network. Fortnightly Magazine, May.
Moniz E. 2014. Keynote Address, IEEE Innovative Smart Grid Technologies Conference, Febru-
ary 19, Washington, DC.
National Academies of Sciences, Engineering, and Medicine. 2016. Analytic Research Foundations 
for the Next-Generation Electric Grid. Washington: National Academies Press. 
Panciatici P, Campi MC, Garatti S, Low SH, Molzahn DK, Sun AX, Wehenkel L. 2014. Advanced 
optimization methods for power systems. Proceedings of the 18th Power System Computation 
Conference, August 18–22, Wroclaw. 
Taft JD, Becker-Dippmann A. 2015. Grid Architecture. Richland WA: Pacific Northwest ­National 
Laboratory. http://gridarchitecture.pnnl.gov/media/white-papers/Grid%20Architecture%20%20
-%20DOE%20QER.pdf. 
von Meier A, Stewart E, McEachern A, Andersen M, Mehrmanesh L. 2017. Precision micro­
synchrophasors for distribution systems: A summary of applications. IEEE Transactions on 
Smart Grid, June.


Big Data and Analytics for Wind Energy 
Operations and Maintenance:  
Opportunities, Trends, and Challenges 
in the Industrial Internet
Bouchra Bouqata
GE Renewable Energy
Clean renewable energy from sources such as the wind has been moving to 
the forefront of social awareness and public policy. And major tech corporations 
such as Google and Apple are increasing their investments to achieve 100 percent 
power for their data centers from renewable energy (Etherington 2016; Moodie 
2016; Saintvilus  2016).
As wind energy becomes more economically competitive, wind farm opera-
tors must understand and manage the performance analysis of their farms in order 
to achieve desired production and revenue goals. But farm operators face a deluge 
of data from multiple sensors connected to wind turbines’ complex systems. 
Big data and analytics are resulting in disruptive innovation across many 
industry sectors. Given the uncertainty and complexity associated with wind 
energy systems, there is huge potential for these techniques to significantly 
improve the performance and reduce the costs of wind energy systems. 
There is also a paradigm shift with the Internet of Things (IoT)—­connecting 
machines to machines through networks, data, and analytics—as an important 
technology to deal with challenges of big data analytics for wind energy opera-
tions and maintenance (O&M). Through emerging technologies in the IoT’s 
advanced analytics capabilities, it is possible to reduce operating expenses 
and move away from traditional reactive O&M to sophisticated predictive and 
­proactive O&M solutions. 
This paper provides an overview of big data analytics trends, challenges, and 
enabling technologies both generally and as they relate to wind energy O&M. 
Next, it describes the IoT as a technological tool for dealing with the challenges 
of big data analytics for wind energy O&M. It then reviews opportunities and 
25

26	
FRONTIERS OF ENGINEERING
challenges of this new paradigm to address wind energy O&M expenses and move 
from reactive to proactive O&M. 
INTRODUCTION
As wind energy grows in market share, the more it needs to increase its output 
(performance) and reduce its cost (maintenance). 
Wind energy systems stand out from other complex technical systems because 
of the combination of large levels of wind uncertainty and high levels of interac-
tion of wind farm physics. Big data analytics techniques can significantly improve 
wind farm performance and reduce costs.
Data are estimated to be created at 2.5 quintillion bytes/day from sensors, 
social media, images, and myriad other sources. The growing use of big data 
in wind power operations and maintenance generates an estimated 25 trillion 
bytes/day. The ubiquitous availability of data has created a paradigm shift from 
information-poor to information-rich management and impacts virtually every 
area of modern life.
TRENDS IN BIG DATA ADVANCED ANALYTICS
The use of big data advanced analytics for knowledge discovery, especially 
machine learning (ML), has emerged as a means to enable smart decisions. It has 
been successfully used to address problems in many industrial domains, resulting 
in disruptive innovation that can be leveraged to solve challenges such as those 
in performance and maintenance costs of wind energy. 
The design and development of high-quality large-scale analytics are com-
plex, involving big, “noisy,” structured and/or unstructured datasets as well as a 
large pool of diverse models. Evaluating just a single model involves a search 
across all combinations of structures and parameter values, and finding the right 
scalable ML approach can require many attempts. 
The availability of new infrastructures at scale, such as cloud platforms, 
has provided a new direction for efforts to solve these challenges. The emerg-
ing paradigm needs to involve automation of a significant portion of the current 
manual process involved in problem formulation (to select the appropriate ML 
algorithms) as well as data preparation, model selection, model tuning, and so 
forth. In addition, it is important to leverage parallel computing environments—
through cloud computing (such as Hadoop), high-performance computing, and 
large-scale optimizations—to create, maintain, and deploy large-scale machine 
learning on big data.
Good-quality data are essential to the development of an effective predictive 
model. There are two main challenges when dealing with data quality: (1) The 
data are unlabeled even when there is a large pool, and (2) the features do not 
have predictive power. 

BIG DATA AND ANALYTICS FOR WIND ENERGY OPERATIONS AND MAINTENANCE	
27
In the first scenario, the data could be annotated by subject matter experts. 
Since their time is very expensive, the challenge is to determine what data points 
are the most informative to focus their time and effort. ML techniques, such as 
active learning (Settles 2010), can interactively query the expert to obtain the 
desired outputs at new data points and solve an optimization problem in order to get 
the highest performance from the predictive model with the smallest training set. 
The second scenario is common when the predictive problem is very compli-
cated and predictive features are missing. In this case, feature engineering (Heaton 
2016) can be used for the design of the best (or at least a better) representation of 
the sample data to yield the necessary information for the predictive algorithm.
BIG DATA ANALYTICS AND THE IOT
The IoT, connecting machines both to machines and to people through 
networks, data, and analytics, is an important technology for dealing with chal-
lenges of big data analytics. As it shapes modern businesses from manufacturing 
to marketing, the IoT promises to remake global industry, boost productivity, and 
launch a new age of prosperity and growth. 
Machines and other objects have long been used to issue early warnings, but 
in an inconsistent and unactionable way. The advent of networked machines with 
embedded sensors and advanced analytics tools has changed that reality. Most 
machines now either have or are in the process of getting multiple sensors and 
being connected. The sensors constitute a plethora of data sources that are often 
neither connected nor integrated, yielding a deluge of data from wind turbines. 
To harness the power of data integration and systems-level analytics and opti-
mization in applications such as wind energy O&M, it is critical to ensure inter­
operability among data sources. But concerns about privacy and cybersecurity are 
raised by both industry and government. The risk of connecting unsecure devices 
to the Internet should be properly mitigated through a combination of cyber- and 
physical security solutions. To accelerate secure data-driven innovation and dis-
covery, new technologies, infrastructure (for networking, storage architecture, 
cloud computing), new platforms, and cybersecurity technologies are needed to 
enable industry to effectively tackle the flow of data from machines and objects.
CHALLENGES AND OPPORTUNITIES
The Industrial Internet—the combination of big data analytics with the ­IoT—
is producing huge opportunities for companies in all industries, and renewable 
energy is no exception. But as one analysis put it, “Not all Big Data is created 
equal” (Kelly and Floyer 2013). According to the authors, “data created by indus-
trial equipment such as wind turbines, jet engines and MRI machines . . . holds 
more potential business value on a size-adjusted basis than other types of Big Data 
associated with the social Web, consumer Internet and other sources.” 

28	
FRONTIERS OF ENGINEERING
To support and accelerate data-driven innovation and discovery, new tech-
nologies and infrastructure are needed to empower industry. To that end, GE has 
invested significantly in a new Industrial Internet platform, Predix Asset Perfor-
mance Management (Evans and Annunziata 2012; Floyer 2013),1 to enable big 
data analytics to address complex systems such as wind farm O&M. Through 
the diagnostic and prognostic capabilities of GE’s new platform, it is possible 
to reduce operating expenses and move away from traditional reactive O&M to 
sophisticated predictive and proactive O&M solutions. 
For wind energy O&M, this approach extensively leverages physics-based 
modeling of the system and fuses it with data-driven models and statistical and 
ML techniques to increase performance and reduce maintenance costs in wind 
energy O&M. It does so by
•	
continuously collecting data from assets combined with other operational 
data to monitor, analyze, and improve performance and maintenance;
•	
delivering insights from asset-specific advanced analytics models; and 
•	
providing the asset issues to enable smart decisions and the best course 
of action.
Wind farm operators can thus better understand what is happening in the 
field, plan ahead, and properly predict extended operating life, resulting in reduced 
maintenance costs and improved performance.
REFERENCES
Etherington D. 2016. Google says it will hit 100% renewable energy by 2017. ­TechCrunch, ­December 6. 
https://techcrunch.com/2016/12/06/google-says-it-will-hit-100-­renewable-energy-by-2017/.
Evans PC, Annunziata M. 2012. General Electric: Industrial Internet, pushing the boundaries of minds and 
machines, November 26. https://www.ge.com/docs/chapters/Industrial_Internet.pdf.
Floyer D. 2013. Defining and sizing the Industrial Internet. Wikibon, June 27. 
Heaton J. 2016. An empirical analysis of feature engineering for predictive modeling. Paper presented 
at IEEE SoutheastCon, March 30–April 3, Norfolk VA.
Kelly J, Floyer D. 2013. The Industrial Internet and big data analytics: Opportunities and challenges. 
Wikibon, September 16. http://wikibon.org/wiki/v/The_Industrial_Internet_and_Big_Data_
Analytics:_Opportunities_and_Challenges.
Moodie A. 2016. Google, Apple, Facebook race towards 100% renewable energy target. The 
­Guardian, December 6. https://www.theguardian.com/sustainable-business/2016/dec/06/­google-
renewable-energy-target-solar-wind-power.
Saintvilus R. 2016. Microsoft makes largest wind energy investment. Investopedia, November 15. https://
www.investopedia.com/news/­microsoft-makes-largest-wind-energy-investment-msft/?lgl=rira-
baseline-vertical.
Settles B. 2010. Active learning literature survey. Computer Science Technical Report 1648, Univer-
sity of Wisconsin–Madison. http://burrsettles.com/pub/settles.activelearning.pdf.
1  See https://www.ge.com/digital/products/asset-performance-management-for-power.

Energy is the single most important factor that impacts the prosperity of any 
society, underpinning advances on which all depend. To supply the more than 
7 billion people on this planet at the level of energy that the developed world 
is accustomed to, 60 terawatts would need to be generated—the equivalent of 
900 million barrels of oil per day. Where could this astonishing amount of energy 
come from? The term “terawatt challenge” refers to the endeavor to produce 
energy at the level needed in an economically, socially, and technologically sus-
tainable way. 
When one searches for potential sources of energy at the terawatt (TW) scale 
it is striking to find that the biggest resources and most technically exploitable 
options are those that barely make up 10 percent of the energy mix today—solar, 
wind, and geothermal. If the TW challenge is solved, though, the world energy 
breakdown will look quite different by 2050. 
It is not unreasonable to think that renewables can handle heavy loads. Reports 
have proposed that 100 percent of the world’s energy needs by 2030 (11.5 TW) 
can be fully achieved with an energy mix of roughly 50 percent wind, 40 percent 
solar (concentrated solar power and photovoltaic [PV]), 4 percent hydroelectric, 
4 percent geothermal, and 1 percent tidal turbines (Jacobson et al. 2015).
No renewable energy source is as abundant as the Sun, and in recent years 
its potential has been capitalized to the point that solar has moved from a niche 
source toward a mainstream electricity generation source with grid parity. With 
15 gigawatts (GWDC) installed, solar was the number one source of new US 
­capacity in 2016—an unprecedented 39 percent. That momentum carried into 
2017, as solar accounted for 30 percent of all new electric capacity installed in 
Across Dimensions and Scales:  
How Imaging and Machine Learning 
Will Help Design Tomorrow’s 
Energy Conversion Devices
Mariana I. Bertoni
Arizona State University
29

30	
FRONTIERS OF ENGINEERING
the first quarter. Global PV shipments reached an astonishing 75 GW in 2016, 
arguably making the solar industry the largest optoelectronic sector in the world, 
worth $110 billion/year (Perea 2017).
The aspirational goal set by the US Department of Energy Sunshot initiative 
to meet $1/watt by 2020 initially seemed unrealistic and even comical to many 
in the industry (US DOE 2010). But 6 years later and 3 years ahead of schedule, 
module prices have dropped to $0.99/watt for fixed-tilt utility-size installations 
(Perea 2017).
For 18 states the levelized cost of solar energy is below gross electricity bill 
savings in the first year of a solar PV system’s life. This means grid parity under 
business-as-usual conditions is a reality, and 32 more states are expected to ­follow 
suit by 2020 (Munsell 2016). If PV reaches grid parity it will be an important 
milestone, but it is just the beginning. High market penetration will require that 
PV system costs drop to offset the additional costs of storage and transmission 
so that solar generation can be distributed to meet electricity demand both cost 
effectively and more broadly in time and space (Kurtz et al. 2016).
The rapid pace of change brings its own challenges and opportunities. For 
example, there are concerns about the maximum penetration possible with PV 
power because of its impact on utility demand, lowering its value as PV penetra-
tion increases and requiring further cost reductions. In addition, the important 
metrics of photovoltaics for sustainable energy are expanding to include factors 
previously not analyzed, such as the impact of capital expenditures on realizing 
sustained high growth rates (Haegel et al. 2017; Powell et al. 2015).
Technological barriers to PV have in some ways increased. Cost reductions 
from economies of scale are plateauing, the cost of photovoltaics is a moving 
target, and efficiency from single-junction technologies is approaching its tech-
nological limits, hampering the ability to use efficiency boosts as the lever to 
overcome previous barriers. 
In this context, like Moore’s Law, an underlying law based on fundamental 
physics can help make a specific, quantitative prediction about innovation as a 
function of time. For semiconductors, the technical parameter has been transis-
tor density; for photovoltaics the analogue is energy produced per unit volume. 
Figure 1 puts a lot of this discussion in perspective. It shows that computing 
and photovoltaics have seen significant and steady cost reductions during the past 
20 years by “packing more in a smaller volume,” while oil and natural gas have 
remained relatively constant despite shorter-term price fluctuations. It also depicts 
how competitive today’s solar energy prices are (light blue inset data in $/kWh) 
compared to other electricity sources, that unlike solar benefit from federal and 
state subsidies. The achievement of silicon module prices below $1/W—and pro-
jections of $0.50/W—has fundamentally changed solar R&D. 
Slim margins have pushed some companies into bankruptcy and challenged 
the annual profitability of others. Cost, intermittency, and dispatchability have 
been major challenges in the pursuit of utility-scale solar energy generation. More 

ACROSS DIMENSIONS AND SCALES	
31
FIGURE 1  Photovoltaic (PV) module, natural gas, and oil price trends (blue, left axis) 
compared to computing cost trend (green, right axis), 1997–2016. Data taken from annual 
reports of the US Energy Information Administration (www.eia.gov). Light blue inset: 
*Solar levelized cost of electricity (LCOE) estimated for 0.72 $/W PV Module peak 
nominal, 100 MWDC fixed-tilt system installation with 0.5%/yr. and financial parameters 
from Jones-Albertus et al. (2016).
recently, materials’ degradation studies and long-term system performance R&D 
have become crucial for the bankability of projects. However, the standard busi-
ness model of the solar industry, with each company eager to outcompete the next 
in price, has made the industry very risk averse when it comes to implementation 
of innovation.
What are the next steps? Movement toward an “electric-powered world” 
and increased demands for clean and efficient electricity (e.g., electric vehicles, 
portable electronics, rural electrification) raises new challenges. 
The first of these challenges concerns portability: the availability of light-
weight and flexible modules necessary for implementation in everyday life. 
Additional challenges involve the achievement of high power in small areas and 
the use of sustainable materials for device manufacturing. 
As with other consumer applications, solar margins will improve and engi-
neering hurdles associated with aesthetics, customization, and functionality will 
become standard R&D considerations. An analogy is the introduction of Ford’s 
Model T car: photovoltaics has demonstrated its affordability, impact, and poten-
tial, and now a whole new technology is taking off. 
The path for improved PV is to make cells thinner and more efficient. The 
industry is maturing, costs are becoming dominated by those of materials, and 

32	
FRONTIERS OF ENGINEERING
expensive process changes are yielding very small incremental benefits. Fun-
damental scientific breakthroughs are necessary to propel this energy source to 
next-generation levels. 
Higher-power cells can be achieved by stacking cells with different band-
gaps to efficiently capture a wider portion of the solar spectrum. The efficiency 
limits rise from 33 percent for a single-junction cell to 43 percent for two junc-
tions under no concentration, 49 percent for three junctions, and 66 percent for 
all greater numbers of junctions. This approach is not novel; multijunction cells 
are well known in space applications, where very high quality single crystals 
are epitaxially grown and cells are engineered to withstand radiation and high 
levels of illumination (Takamoto et al. 2005). The automotive analogy would be 
a limited-edition Ferrari. 
Although these modules are very expensive, epitaxial liftoff techniques 
enabling substrate reuse have demonstrated a path to lower costs. The future of 
solar lies in merging the ubiquitousness of the Model T solar cells with the per-
formance of the limited-edition Ferrari cells.
The first thing to realize is the necessity of relying on the mass-production 
low-cost manufacturing lines of the Model T cells, which most likely means a 
silicon cell will be the bottom cell and high-quality single-crystal films will not 
be available for the multilayer stack. Instead faster deposition methods, like 
evaporation or sputtering, and defect-engineered top films will have to be used 
to achieve the desired electrical and optical properties (Bobela et al. 2016). This 
is crucial to the success of next-generation solar absorbers; engineered defect–­
tolerant ­materials are the best way to enable ultra-low-cost manufacturing technol-
ogy for high-efficiency devices. A top-cell bandgap of 1.7 electron volt (eV) and 
an efficiency comparable to standard silicon cells today (20 percent) can enable 
32 percent efficient tandems (Yu et al. 2016). 
The task seems daunting, especially when one considers that the performance 
of a full device is usually governed by the concentration and distribution of 
nanoscale inhomogeneities and defects throughout the solar cell. 
How can discovery and defect engineering be accelerated to facilitate a 
high-power, portable, and economic solar industry? The paradigms for materials 
discovery have to be redefined, especially for systems with complex functional-
ities, to move beyond serendipitous discoveries, Edisonian approaches, and the 
classical synthesis-characterization-theory methods. The answer lies in highly 
correlative imaging methods under operating conditions combined with big data 
analytics.
Understanding the fundamental relationships between composition and struc-
ture properties on a nanopixel basis, under real operating conditions and in situ 
(with both controlled and ambient temperature) is necessary to unravel the causes 
and effects of certain defects, including their impact on performance. 
Current imaging techniques do not merely provide a picture of the system 
under study, they actually contain compositional, structural, and functional infor-

ACROSS DIMENSIONS AND SCALES	
33
mation. The correlation of multiple 2D or 3D mapping modalities on a pixel-to-
pixel basis and the multiple dimensions of these maps, based on time, temperature, 
and ambient conditions, creates a big data challenge.
In situ and operando measurement techniques combined with nanoscale 
resolution have proven invaluable in multiple fields of study. I argue that cor-
relative hard X-ray microscopy (HXM) with <100 nm resolution can radically 
change the approach for optimizing solar absorbers, interfaces, and full devices 
in solar cell research. 
Unlike other fields of microscopy, HXM has excellent penetration through 
layers and entire devices, yielding 3D imaging of buried structures. It can easily 
penetrate gases and fluids, enabling studies at pressure and under process condi-
tions. It also enables quantitative studies of sample composition with trace ele-
ment sensitivity in structured materials and devices. Chemical state information of 
individual atomic species can be obtained using X-ray spectroscopic techniques. 
X-rays do not interact with external fields and are therefore useful for studies in 
electric or magnetic fields (Stuckelberger et al. 2017). 
As acquisition speeds and resolution increase, providing more density of 
data points, and the functionality of measurements adds more dimensions to be 
analyzed, the handling, management, and analysis of datasets become more and 
more complicated. Operando measurements as well as in situ studies pose a new 
challenge: Finding correlations in the 3D+ datasets that result from many of these 
measurements is not straightforward, and the possibility of missing connections, 
relationships, and trends is cause for concern.
Machine learning techniques, including principal component and cluster 
analyses, have been widely used in fields plagued with tremendous amounts of 
data (Hastie et al. 2013). A key benefit of these approaches is the ability to identify 
trends in highly dimensional data, a task that is otherwise difficult and sometimes 
even impossible.
The first step toward full information recovery from high-resolution multi-
functional imaging data is the adoption of big data analytics (Kalinin et al. 2015; 
Rajan 2012, 2015; Runkler 2016). This requires implementation of dimensionality 
reduction, clustering techniques, and statistical unsupervised learning (Hastie et 
al. 2013). Unsupervised image analysis tools targeted to high-performance com-
puting platforms can analyze high-resolution scanning and electron microscopy 
data in 2D in real time (Belianinov et al. 2015). Advances in high-resolution 
experimental imaging and high-performance computing (Dongarra et al. 2011) 
will undoubtedly propel materials discovery and ultimately “materials by design.”
However, just because a statistical correlation is observed does not imply 
an accurate understanding of the underlying physics in the multimodal imaging. 
Transitioning from big data to “deep data” is the next step. All the structure-prop-
erty relationships at the nanoscale retrieved from big data can be examined with 
real physical models, allowing for verification and improvements in predictive 
modeling (Kalinin et al. 2015). This step makes it possible to close the loop and 

34	
FRONTIERS OF ENGINEERING
propose design guidelines to develop or process a material with desired properties 
and functionalities.
Materials informatics is ready to lay the foundation for a new paradigm in 
materials discovery, especially for complex functional systems like solar cells. It 
could very well end up being data that ultimately push the cost of solar power to 
the levels of subsidized fossil fuel. 
REFERENCES
Belianinov A, Vasudevan R, Strelcov E, Steed C, Yang SM, Tselev A, Jesse S, Biegalski M, Shipman 
G, Symons C, and 3 others. 2015. Big data and deep data in scanning and electron microscopies: 
Deriving functionality from multidimensional data sets. Advanced Structural and Chemical 
Imaging 1:6.
Bobela DC, Gedvilas L, Woodhouse M, Horowitz KAW, Basore PA. 2016. Economic competitiveness 
of III-V on silicon tandem one-sun photovoltaic solar modules in favorable future scenarios. 
Progress in Photovoltaics: Research and Applications 25(1):41–48. 
Dongarra J, Beckman P, Moore T, Aerts P, Aloisio G, André J-C, Barkai D, Berthou J-Y, Boku T, 
Braunschweig B, and 55 others. 2011. The International Exascale Software Project roadmap. 
International Journal of High Performance Computing Applications 25:3–60. 
Haegel NM, Margolis R, Buonassisi T, Feldman D, Froitzheim A, Garabedian R, Green M, Glunz 
S, Henning HM, Holder B, and 11 others. 2017. Terawatt-scale photovoltaics: Trajectories and 
challenges. Science 356:141–143.
Hastie T, Tibshirani R, Friedman J. 2013. The Elements of Statistical Learning. Berlin: Springer 
Science & Business Media.
Jacobson MZ, Delucchi MA, Bazouin G, Bauer ZAF, Heavey CC, Fisher E, Morris SB, Piekutowski 
DJY, Vencilla TA, Yeskoo TW. 2015. 100% clean and renewable wind, water, and sunlight 
(WWS) all-sector energy roadmaps for the 50 United States. Energy and Environmental Sci-
ence 8:2093–2117.
Jones-Albertus R, Feldman D, Fu R, Horowitz K, Woodhouse M. 2016. Technology advances needed 
for photovoltaics to achieve widespread grid price parity. Progress in Photovoltaics: Research 
and Applications 24:1272–1283.
Kalinin SV, Sumpter BG, Archibald RK. 2015. Big-deep-smart data in imaging for guiding materials 
design. Nature Materials 14:973–980.
Kurtz S, Atwater H, Rockett A, Buonassisi T, Honsberg C, Benner J. 2016. Solar research not finished. 
Nature Photonics 10(3):141–142.
Munsell M. 2016. GTM Research: 20 US states at grid parity for residential solar. Greentech Media, 
February 10. https://www.greentechmedia.com/articles/read/gtm-research-20-us-states-at-grid-
parity-for-residential-solar. 
Perea A. 2017. US Solar Market Insight 2017 Q2. Washington: Solar Energy Industries Association.
Powell DM, Fu R, Horowitz K, Basore PA, Woodhouse M, Buonassisi T. 2015. The capital intensity 
of photovoltaics manufacturing: Barrier to scale and opportunity for innovation. Energy and 
Environmental Science 8(12):3395–3408.
Rajan K. 2012. Materials informatics. Materials Today 15:470.
Rajan K. 2015. Materials informatics: The materials ‘gene’ and big data. Annual Review of Materials 
Research 45:153–169.
Runkler TA. 2016. Data Analytics. Wiesbaden: Springer Fachmedien Wiesbaden. 
Stuckelberger M, West B, Nietzold T, Lai B, Maser JM, Rose V, and Bertoni MI. 2017. Engineering 
solar cells based on correlative x-ray microscopy. Journal of Materials Research 32(10):1825–
1854.

ACROSS DIMENSIONS AND SCALES	
35
Takamoto T, Kaneiwa M, Imaizumi M, Yamaguchi M. 2005. InGaP/GaAs-based multijunction solar 
cells. Progress in Photovoltaics: Research and Applications 13:495–511.
US DOE. 2010. $1/W Photovoltaic Systems: White Paper to Explore a Grand Challenge for Electricity 
from Solar. https://www1.eere.energy.gov/solar/sunshot/pdfs/dpw_white_paper.pdf.
Yu ZJ, Leilaeioun M, Holman Z. 2016. Selecting tandem partners for silicon solar cells. Nature 
Energy 1:16137–16134.


Road transportation, which accounts for 23 percent of US total energy con-
sumption, 59 percent of petroleum consumption, and 22 percent of greenhouse 
gas emissions (Davis et al. 2016), is undergoing a major transformation with the 
advent of ridesharing, autonomous driving, and vehicle electrification. Collec-
tively these technologies, in conjunction with renewable sources of electricity, 
have the potential to dramatically reduce the negative impact of road transporta-
tion on the health of the planet.
The successful convergence of these technologies will require electric vehi-
cles (EVs) that are low cost and fully autonomous. These attributes can be realized 
through wireless charging.
INTRODUCTION
Consider a future in which a driverless ridesharing EV pulls over as you exit 
a building, takes you to your destination, and proceeds to drive passenger after 
passenger without ever needing to stop to recharge its battery. Instead, power 
generated by nearby wind and solar resources is delivered wirelessly from the 
roadway to the vehicle while it is in motion.
Not having to stop for recharging will make EVs truly autonomous, and, 
because the vehicles can thus remain in service for more hours, fewer vehicles 
will be needed to meet passenger demand. Furthermore, EVs with in-motion 
(dynamic) wireless charging can have much smaller batteries, an option that can 
reduce their cost and accelerate adoption.
While the concept of medium-range wireless power transfer (WPT), achieved 
using near-field (nonradiative) electromagnetic coupling, has existed since the 
Wireless Charging of Electric Vehicles
Khurram Afridi
University of Colorado Boulder
37

38	
FRONTIERS OF ENGINEERING
pioneering work of Nikola Tesla (1891) more than a century ago, the technology 
to enable effective dynamic WPT for EVs is still in its nascent stage. Numerous 
challenges related to performance, cost, and safety need to be overcome before 
the vision of wirelessly powered EVs can be realized.
NEAR-FIELD WIRELESS POWER TRANSFER
Near-field WPT systems are of two types: inductive, which use magnetic 
field coupling between conducting coils, and capacitive, which use electric 
field ­coupling between conducting plates to transfer energy (see Figure 1). For 
medium-range applications (in which the distance between the transmitter and the 
receiver couplers is comparable to the size of the couplers, as in EV charging), 
inductive WPT systems have traditionally been preferred. 
Inductive WPT Systems
Building on work done for material handling applications during the 1990s 
(Green and Boys 1994), the past decade has seen tremendous progress in induc-
tive WPT technology for stationary charging of EVs (Bosshard and Kolar 2016). 
Aftermarket stationary chargers are already available, and some EV manu­
facturers have announced plans to introduce built-in stationary inductive WPT 
systems as early as 2018.
However, for magnetic flux guidance and shielding, inductive WPT systems 
require ferrite cores, making them expensive and bulky. Also, to limit losses in 
the ferrites, the operating frequencies of these systems are kept under 100 kHz, 
resulting in large coils and low power transfer densities. The high cost and low 
power transfer density are particularly problematic for dynamic WPT, as these 
systems need to have very high power capability to deliver sufficient energy to 
the vehicle during its very brief time passing over a charging coil. 
For these reasons dynamic inductive WPT is yet to become commercially 
viable, although a few experimental systems have been demonstrated (Choi et al. 
2015; Onar et al. 2013).
Capacitive WPT Systems
Capacitive WPT systems have potential advantages over the inductive sys-
tems because of the relatively directed nature of electric fields, which reduces the 
need for electromagnetic field shielding. Also, because capacitive WPT systems 
do not use ferrites, they can be operated at higher frequencies, allowing them to 
be smaller and less expensive. Capacitive WPT could thus make dynamic EV 
charging a reality.
But because of the very small capacitance between the road and vehicle 
plates, effective power transfer can occur only at very high frequencies, making 

	
39
FIGURE 1  Physical implementation (left) and block diagram representation (right) of two approaches to deliver energy wirelessly to electric 
vehicles from an electrified roadway: (a) inductive wireless power transfer (WPT) using coils (embedded in the roadway and in the vehicle) 
that are coupled through magnetic fields, and (b) capacitive WPT using plates coupled through electric fields. In both cases, power electronics 
(comprising a high-frequency inverter and rectifier with semiconductor devices, and gain and compensation networks with inductors, capaci-
tors, and/or transformers) is the enabling technology. 
Receiver 
power electronics 
Transmitting coil 
Transmitter power 
electronics 
Receiving coil 
Power line 
VIN 
Road 
Vehicle 
Current gain 
and 
compensation 
network 
Voltage gain 
and 
compensation 
network 
High 
frequency 
rectifier 
High 
frequency 
inverter 
VOUT 
(a)
VIN 
Road 
Vehicle 
Voltage gain 
and 
compensation 
network 
Current gain 
and 
compensation 
network 
High 
frequency 
rectifier 
High 
frequency 
inverter 
VOUT 
(b)
Transmitting plate 
Receiving plate 
Transmitter power 
electronics 
Power line 
Receiver 
power electronics 
Transmitter 
power electronics 
Receiver 
power electronics 
Transmitter 
power electronics 
Receiver 
power electronics 

40	
FRONTIERS OF ENGINEERING
the design of these systems extremely challenging. With the recent availability 
of wide-bandgap (gallium nitride [GaN] and silicon carbide [SiC]) power semi­
conductor devices that enable higher-frequency operation, high-power medium-
range capacitive WPT systems are becoming viable (Regensburger et al. 2017; 
Zhang et al. 2016).
Two major challenges associated with capacitive WPT for EV charging are 
(1) achieving high-power transfer density at high efficiencies while meeting 
electromagnetic safety requirements, and (2) maintaining effective power trans-
fer even as the couplers’ relative position changes. These challenges have been a 
focus of my group’s recent efforts.
ACHIEVING SAFE AND EFFICIENT HIGH-POWER TRANSFER
The size of the couplers in WPT systems can be reduced and the power trans-
fer density increased by designing the systems to operate at higher frequencies. 
In inductive systems the increase in induced voltage with higher frequency com-
pensates for the reduced mutual inductance of the smaller coils, and in capacitive 
systems the increase in displacement current with higher frequency compensates 
for the smaller plates’ lower capacitance. Higher operating frequencies also enable 
smaller power electronics associated with WPT systems (see Figure 1) thanks to 
a decrease in energy storage requirements.
But achieving high efficiencies at high switching frequencies is very chal-
lenging. And the fringing fields of WPT systems must be within safe levels (as 
defined by the International Commission on Non-Ionizing Radiation Protection; 
ICNIRP 1998) in areas occupied by people and animals (e.g., the vehicle cabin 
and outside the perimeter of the chassis). These requirements for capacitive WPT 
systems can be met through circuit stages that provide appropriate voltage and 
current gain (to reduce displacement currents) as well as reactive compensation 
(Figure 1). An active area of research is the design of these circuit stages (Lu et 
al. 2015; Theodoridis 2012).
Multistage Matching Networks
Our work in this area has explored approaches utilizing multistage matching 
networks that can simultaneously provide gain and compensation (Sinha et al. 
2016). We have discovered that, depending on the ratio of the system input and 
output voltages, there is an optimal number of stages that maximizes efficiency, 
and we have identified the optimal distribution of gain and compensation among 
these stages.
To further reduce fringing fields in capacitive WPT systems, various coupler 
design approaches have been considered. Those that use dielectric materials for 
field guidance introduce additional losses and have limited success in medium-
range applications.

WIRELESS CHARGING OF ELECTRIC VEHICLES	
41
Phased-Array Field Focusing
We have been exploring techniques traditionally used for beamforming in 
radars and other far-field applications (Hansen 2009). We have developed a near-
field phased-array field-focusing approach that uses multiple phase-shifted capaci-
tive WPT modules to achieve dramatic reductions in fringing fields (Figure 2). We 
have shown that a 180°-outphased configuration yields a progressive reduction in 
fringing electric fields as the number of modules increases (Kumar et al. 2015).
Phased-array field focusing provides opportunities for innovation, for exam-
ple in the exploration of methods that incorporate parasitic interactions between 
multiple coupling plates in the design of the matching networks. Such phased-
array approaches could also be adapted for inductive WPT to help eliminate 
­ferrites (Waters et al. 2015).
ACHIEVING VARIABLE COMPENSATION
To achieve effective power transfer, WPT systems need to operate close to 
the resonant frequency of the resonant tank formed by the reactances (capacitive 
and inductive) of the coupler and compensating network. However, the coupler 
reactance depends on the vehicle’s road clearance, and varies as the vehicle moves 
across the charger (Figure 3). The drift between resonant and operating frequency 
causes a reduction in power transfer and WPT system efficiency.
In WPT systems that operate at frequencies below 100 kHz, where band-
widths are not restrictive, the traditional way to deal with variations in coupling 
is to change the operating frequency to track the resonant frequency (Covic and 
Boys 2013; Shekhar et al. 2013). But in high-frequency WPT systems the operat-
ing frequency must stay within one of the designated, very restrictive industrial, 
scientific, and medical (ISM) bands (e.g., 6.78 MHz, 13.56 MHz, and 27.12 MHz; 
FCC 2014).
One solution, employed in low-power inductive WPT systems, is to use a 
bank of capacitors that can be switched in and out of the compensating network, 
to keep the resonant frequency roughly unchanged as the transmitter and receiver 
move relative to each other (Lim et al. 2014). But this is not an effective approach 
for higher-power WPT systems as the switches have to be much bigger and more 
expensive to keep the system efficient. This approach is also less suited to capaci-
tive WPT because it requires multiple switchable compensating inductors, which 
are bigger than capacitors.
Other adaptive impedance matching techniques include the use of saturable 
and variable inductors (James et al. 2005), but these techniques reduce system 
efficiency and do not scale well with power.
We have developed new high-frequency rectifier and inverter architectures 
that compensate for coupling variations while operating at fixed frequency and 
maintaining high efficiency. An example is the active variable reactance (AVR) 

42
FIGURE 2  Multimodular near-field phased-array capacitive wireless power transfer (WPT) system: (a) block diagram representation, (b) 
simulated performance showing fringing field reduction with progressive increase in the number of modules, and (c) photograph of a prototype 
system. E = electric field strength; V/m = volt per meter. 
…
…
…
Vehicle battery
…
Rectiﬁer and 
matching 
network
Rectiﬁer and 
matching 
network
Rectiﬁer and 
matching 
network
Grid
~
…
…
Inverter and 
matching 
network
…
ac-dc
converter
~
Inverter and 
matching 
network
Inverter and 
matching 
network
E (V/m)
20
300
0
10
30
(b)
)c(
)a(

	
43
FIGURE 3  Coupling variations and an approach to compensate for these variations: (a) variation in coupling due to different vehicle road 
clearances, (b) variation in coupling due to change in vehicle position as it drives over the charger, and (c) a capacitive wireless power transfer 
(WPT) system with an active variable reactance (AVR) rectifier that can provide continuously variable compensation by controlling the volt-
ages V1 and V2. jX = tank reactance; Zr = rectifier input impedance.
(c)
(a)
(b)
Road 
Vehicle 
Road 
Vehicle 
Road 
Vehicle 
Road 
Vehicle 
VOUT 
+jX 
-jX 
dc-dc 
dc-dc 
V1 
V2 
Zr 
AVR 
rectifier 
VIN 
Road 
Vehicle 
Voltage gain 
and 
compensation 
network 
Current gain 
and 
compensation 
network 
High 
frequency 
inverter 

44	
FRONTIERS OF ENGINEERING
rectifier shown in Figure 3 (Sinha et al. 2017). By appropriately controlling the 
output voltages of its two coupled rectifiers, the AVR can provide continuously 
variable compensation while maintaining optimum soft switching to ensure high 
efficiency. This compensation architecture ensures that the output power of the 
WPT system is maintained at a fixed level across wide variations in coupling and 
is applicable to both capacitive and inductive WPT systems.
CONCLUSIONS AND FUTURE DIRECTIONS
High-performance, safe, and cost-effective dynamic electric vehicle charg-
ing has the potential to revolutionize road transportation. What combination of 
capacitive and inductive WPT will enable this revolution is an open question. Both 
systems offer tremendous opportunities for research, especially in high-frequency 
power electronics and near-field coupler design. Research is also needed on
•	
health effects of long-term exposure to weak electric and magnetic fields,
•	
mechanisms to detect living and foreign objects in the proximity of WPT 
systems,
•	
methods to determine optimal charger power levels and spacing for cost 
effectiveness,
•	
techniques to embed WPT technology in roadways, and
•	
approaches to analyze impacts of large-scale WPT system deployment 
on the electric grid.
The technologies developed for dynamic EV charging are foundational—they 
can also enable wirelessly powered biomedical implants, humanoid robots, and 
supersonic hyperloop transport. The technological challenges are exciting and the 
possibilities endless.
REFERENCES
Bosshard R, Kolar JW. 2016. All-SiC 9.5 kW/dm3 on-board power electronics for 50 kW/85 kHz 
automotive IPT system. IEEE Journal of Emerging and Selected Topics in Power Electronics 
5(1):419–431.
Choi SY, Gu BW, Jeong SY, Rim CT. 2015. Advances in wireless power transfer systems for roadway-
powered electric vehicles. IEEE Journal of Emerging and Selected Topics in Power Electronics 
3(1):18–36.
Covic GA, Boys JT. 2013. Inductive power transfer. Proceedings of the IEEE 101(6):1276–1289.
Davis SC, Williams SE, Boundy RG. 2016. Transportation Energy Data Book, edition 35. Oak Ridge 
National Laboratory (ORNL).
FCC [Federal Communications Commission]. 2014. Part 15: Radio frequency devices. Electronic 
Code of Federal Regulations, Title 47: Telecommunications (47CFR15). https://www.fcc.gov/
general/rules-regulations-title-47.

WIRELESS CHARGING OF ELECTRIC VEHICLES	
45
Green AW, Boys JT. 1994. 10 kHz inductively coupled power transfer: Concept and control. Pro-
ceedings of the IEE International Conference on Power Electronics and Variable-Speed Drives, 
October 26–28, London. 
Hansen RC. 2009. Phased Array Antennas, 2nd ed. Hoboken NJ: John Wiley & Sons.
ICNIRP [International Commission on Non-Ionizing Radiation Protection]. 1998. Guidelines for 
limiting exposure to time-varying electric, magnetic, and electromagnetic fields (up to 300 GHz). 
Health Physics 74(4):494–592.
James J, Boys J, Covic G. 2005. A variable inductor-based tuning method for ICPT pickups. Proceed-
ings of the International Power Engineering Conference (IPEC), November 29–December 2, 
Singapore.
Kumar A, Pervaiz S, Chang CK, Korhummel S, Popovic Z, Afridi KK. 2015. Investigation of power 
transfer density enhancement in large air-gap capacitive wireless power transfer systems. Pro-
ceedings of the IEEE Wireless Power Transfer Conference (WPTC), May 13–15, Boulder.
Lim Y, Tang H, Lim S, Park J. 2014. An adaptive impedance-matching network based on a 
­novel capacitor matrix for wireless power transfer. IEEE Transactions on Power Electronics 
29(8):4403–4413.
Lu F, Zhang H, Hofmann H, Mi C. 2015. A double-sided LCLC-compensated capacitive power transfer 
system for electric vehicle charging. IEEE Transactions on Power Electronics 30(11):6011–6014.
Onar OC, Miller JM, Campbell SL, Coomer C, White CP, Seiber LE. 2013. A novel wireless power 
transfer system for in-motion EV/PHEV charging. Proceedings of the IEEE Applied Power 
Electronics Conference and Exposition (APEC), March 17–21, Long Beach, CA.
Regensburger B, Kumar A, Sinha S, Doubleday K, Pervaiz S, Popovic Z, Afridi KK. 2017. High-
performance large air-gap capacitive wireless power transfer system for electric vehicle charg-
ing. Proceedings of the IEEE Transportation Electrification Conference & Exposition (ITEC), 
June 13–15, Chicago.
Shekhar S, Mishra S, Joshi A. 2013. A utility interfaced half-bridge based capacitively coupled power 
transfer circuit with automatic frequency control. Proceedings of the IEEE Energy Conversion 
Congress and Exposition (ECCE), September 15–19, Denver.
Sinha S, Kumar A, Pervaiz S, Regensburger B, Afridi KK. 2016. Design of efficient matching networks 
for capacitive wireless power transfer systems. Proceedings of the IEEE Workshop on Control 
and Modeling for Power Electronics (COMPEL), June 27–30, Trondheim, Norway.
Sinha S, Kumar A, Afridi KK. 2017. Active variable reactance rectifier: A new approach to com-
pensating for coupling variations in wireless power transfer systems. Proceedings of the IEEE 
Workshop on Control and Modeling for Power Electronics (COMPEL), July 9–12, Stanford, CA.
Tesla N. 1891. Experiments with alternating currents of very high frequency and their application to 
methods of artificial illumination. Evening session at Columbia College, June 20, New York.
Theodoridis MP. 2012. Effective capacitive power transfer. IEEE Transactions on Power Electronics 
27(12):4906–4913.
Waters BH, Mahoney BJ, Ranganathan V, Smith JR. 2015. Power delivery and leakage field control 
using an adaptive phased-array wireless power system. IEEE Transactions on Power Electronics 
30(11):6298–6309.
Zhang H, Lu F, Hofmann H, Liu W, Mi C. 2016. A four-plate compact capacitive coupler design and 
LCL-compensated topology for capacitive power transfer in electric vehicle charging applica-
tion. IEEE Transactions on Power Electronics 31(12):8541–8551.


Unraveling the Complexity of the Brain


Unraveling the Complexity of the Brain
Xue Han
Boston University
Maryam M. Shanechi
University of Southern California
The brain is a complex system consisting of microscopic and macroscopic 
networks that give rise to its function. Efforts to understand the brain require 
simultaneous measurements at multiple spatiotemporal scales. Over the years, 
technology has been established to record high-dimensional electrical activity 
from a network of brain cells at small (single neurons) and large (local field poten-
tials and electrocorticography [ECoG]) scales. Recent advances in ­optogenetic 
techniques have further enabled the possibility of imaging and controlling a large 
number of neurons. 
The ability to collect high-dimensional neural activity introduces the great 
challenge of analyzing and modeling this activity to understand the brain’s 
function and dysfunction, to devise novel treatments for various neurological 
­disorders, and to enhance brain function. Advanced mathematical techniques 
are being developed spanning the fields of machine learning, signal process-
ing, control, and information theory. Novel photonic and genetic techniques are 
being explored for increasingly precise optogenetic imaging and control. Finally, 
development of the next generation of neurotechnologies requires the design of 
low-power biocompatible electronic implants that can simultaneously record and 
stimulate the brain, and wirelessly transmit the recorded data to the outside world. 
This session explored these challenges and the advances that engineers 
have made to tackle them. It began with a talk by Ellis Meng (University of 
Southern California) on technologies to interface with the brain for recording 
and modulation. She was followed by Jose Carmena (University of California, 
Berkeley), who discussed efforts to understand the neural basis of skill learning 
using brain-machine interfaces. The third speaker, Konrad Kording (University 
of ­Pennsylvania), described new models for neuroscience. The session concluded 
49

50	
FRONTIERS OF ENGINEERING
with a talk by Azita Emami (California Institute of Technology) on efficient fea-
ture extraction and classification methods in neural interfaces. 
Together these efforts will help pave the way to understand the brain, treat 
its disorders, and enhance its functions.

Technologies to Interface with the 
Brain for Recording and Modulation
Ellis Meng
University of Southern California
“The history of electrophysiology has been decided by the history of 
electrical recording instruments.”
Edgar Douglas Adrian (1932)
The desire to decipher targeted neural activities in the mammalian nervous 
system has inspired the development of many innovative technologies that incor-
porate a variety of signaling modalities (electrical, chemical, and mechanical). 
While decades of neural engineering have been dedicated to electronic interfaces 
with neural tissue, more recent advances acknowledge the multiple modalities of 
neural activity and make use of other interface methods. Scaling of such technolo-
gies to acquire data from large numbers of neurons remains a challenge, as is the 
long-term stability of the recording interface, which is susceptible to foreign body 
response. The goal of advancing interface technologies is both to better understand 
proper functioning of the brain and to address a variety of neurological, neuro­
degenerative, psychiatric, and neuromuscular conditions and deficits.
BRAIN COMPOSITION AND ANATOMY
The anatomical and functional complexity of the brain poses a great chal-
lenge for engineering the interfaces needed to record and modulate its activity 
with precision and over short and long time scales. The human brain (~1.3 cm3) 
has 100 billion (1011) electrically active neurons (cell body ~20 mm diameter) that 
are interconnected to one another via chemically active synapses (20–40 nm wide 
gaps). Each neuron possesses about 103 synapses and therefore 100 trillion (1014) 
such connections exist in the brain. Furthermore, chemical synapses communicate 
51

52	
FRONTIERS OF ENGINEERING
via 102 different neurotransmitters, with events occurring at a rate of 0.1–200 Hz 
(“firing” rate). For comparison, the number of estimated stars in the observable 
universe is on the order of 1022–1024.
Electrically active neurons account for only 50 percent of the cells in the 
brain. The other 50 percent are electrically inactive support cells (e.g., oligo-
dendrocytes, astrocytes, and microglia; Chen et al. 2017). To support all the cell 
types, the organ is bathed in and cushioned by cerebrospinal fluid and nourished 
via blood vessels.
Neurons are anatomically organized into different regions, each with spe-
cific functions. Interfaces to neurons target specific brain regions associated with 
functions of interest. While it is possible to engineer devices that are smaller and 
computationally faster than neurons, it is not possible to fully recreate functional 
neural tissues. Hence, the ability to reliably interface with different brain regions 
is of immense scientific and clinical interest.
THE NATURE OF BRAIN ACTIVITY
Brain activity can be recorded from single neurons (single unit spikes or 
action potentials, APs) or from groups of neurons (multiunit recordings or local 
field potentials, LFPs) in a particular region. An inactive neuron has a resting 
potential of −70 mV (cell membrane voltage). An active neuron exhibits an AP 
of 80–100 mV, lasting a few milliseconds, that propagates down a neuron. This 
measurable electrochemical gradient results from the cell’s selective permeability 
to specific ionic species mediated by voltage-sensitive ion channels in the mem-
brane and produces a measurable electrochemical gradient. 
At the synapse, the AP induces the release of neurotransmitters, which cross 
the gap and bind to receptors on the cell membrane of the recipient neuron, trigger-
ing the opening of its ion channels. Signal transmission between two neurons con-
nected by such a chemical synapse goes from electrical to chemical to electrical, 
where electrical signaling involves the movement of ions and not electrons. It is 
possible to modulate this natural activity using artificial stimuli such as electrical 
current or chemical agents.
The AP or “spike” from a single neuron (single unit) represents communica-
tive activity and is measurable using invasive electrodes placed in (intracellular) 
or next to (extracellular) neurons. The “recording” electrode can be used in 
conjunction with a distant reference electrode to enable measurement of current 
or potential difference. Given the difficulty of targeting the interior of a single 
neuron, the destructive nature of such an interface, and the limited information it 
provides, the focus here is on extracellular interfaces.
Extracellular interfaces can also be used to record the LFP, the collective 
activity of a nearby group of neurons. Less invasive FPs can be recorded on 
the surface of the brain or through the protective dura membrane covering via 
electro­corticogram (ECoG) or exterior to the skull via electroencephalogram 

TECHNOLOGIES TO INTERFACE WITH THE BRAIN	
53
(EEG). The less invasive the interface, the lower the resolution and the higher 
the tissue volume from which recordings are obtained (e.g., ~0.1 mm for an 
invasive penetrating electrode, compared to 2 mm for ECoG and 10 mm for EEG; 
Borton et al. 2013). With advances in recording interfaces, multiple penetrating 
electrodes can be placed to obtain recordings from multiple single units, thus 
achieving both high resolution and access to information from different regions 
of the brain. 
It should be noted that while most synaptic transmission is chemical in 
nature (involving neurotransmitters), there are also electrical synapses that form 
a mechanical and electrically conductive link via a structure known as a gap 
junction (~3–4 nm). And some neurons possess specialized ion channels that 
respond to physical stimuli such as pH, temperature, pressure, and tension (Chen 
et al. 2017).
HISTORY OF ELECTRICAL STIMULATION AND RECORDING
Early Explorations and Applications
Electrical interfaces that interact with the nervous system have been used 
since ancient times, when Egyptians and Romans used electric shocks delivered 
by electric eels to treat pain. The foundations of bioelectricity and electrophysiol-
ogy were laid much later in experiments conducted by Luigi Galvani in the 1780s, 
in which dead frog’s leg muscles moved in response to current applied to nerves 
via metal wires, a phenomenon dubbed “animal electricity.” 
With the discovery of the effects of electricity on the human body (often 
the investigator’s own body), “medical electricity” research commenced shortly 
thereafter (Bresadola 1998). Giovanni Aldini, nephew of Luigi Galvani, dis-
covered that electrical stimulation of the cerebral cortex could elicit physical 
responses (facial grimaces on decapitated prisoners; Aldini 1804). This discovery 
inspired work on brain stimulation both to understand function and as a means 
of therapy. In 1938, Ugo Cerletti applied electric current to the skull to induce 
“therapeutic” epileptic seizures to treat severe psychosis (Cerletti 1940). 
Another paradigm shift occurred in 1947 when electrodes were used for 
intraoperative electrical stimulation to determine the location of lesioned targets 
with the assistance of stereotactic techniques; until that point, electrodes were 
used clinically to lesion the brain in neurosurgery (Spiegel et al. 1947). Brain 
stimulation was also investigated for pain control in the 1950s. 
Together these efforts provided the foundation for new clinical therapies 
such as transcranial magnetic stimulation, cortical brain stimulation, and deep 
brain stimulation (DBS). DBS has borrowed heavily from cardiac pacemaker and 
defibrillator electrode concepts that were developed earlier.

54	
FRONTIERS OF ENGINEERING
Evolution of Technologies
Recordings of animal electricity were first reported by Leopoldo Nobili 
in 1828 using an electromagnetic galvanometer, but the first true recordings of 
the resting and action potentials were made in 1868 by Julius Bernstein using 
a differential rheotome that allowed measurement of fast electrical processes 
(­Verkhratsky et al. 2006). The detection of currents from the brain was achieved 
using an early form of EEG by Richard Caton in 1875 (Grimnes 2014). Wire 
electrodes were used to record from behaving animals in the 1950s. 
Advances in microelectronics led to the development of miniaturized multi­
electrode arrays on planar surfaces in the 1970s. They interfaced with cell and 
tissue cultures and demonstrated that electrodes could be made at the scale of a 
single neuron. At about the same time, microelectrodes on penetrating probes were 
introduced. The technology was independently developed by multiple groups, 
leading to commercially available products for research in animals and investi-
gational studies in humans, including use in clinical trials in 2004 (Chen et al. 
2017). But while silicon microelectrode arrays have been developed over several 
decades, the inability to achieve reliable and stable long-term device-tissue inter-
faces has spurred interest in the development of more compliant polymer probes.
Electrodes used for stimulation and recording have opposing requirements, 
which prevent their simultaneous use. Smaller recording electrodes are preferred 
to isolate activity from single cells, whereas stimulation electrodes should have 
larger surface area to increase the charge injection capacity available to excite 
neurons. Because electrical stimulation indiscriminately activates nearby neurons 
and produces a large artifact that interferes with recording, its use in understanding 
brain activity and therapy is limited; but lowering the electrode area to minimize 
activation proportionately increases the input charge densities and the risk of tis-
sue damage. Electrical stimulation is unable to inhibit activity. These drawbacks 
of electrical interfaces have given rise to alternative interface modalities.
NONELECTRICAL INTERFACES
Advances in genetic engineering of cells have opened new avenues to inter-
face with neurons. In optogenetics, a neural population is genetically manipulated 
so that it can be selectively perturbed optically and probed electrically at the same 
time. This is accomplished by injecting a cell with light-sensitive microbial ion 
channels (opsins), which can change their conformation in response to light and 
affect ion transport. Unlike electrical stimulation, optogenetic approaches can 
both excite and inhibit neural activity.
Chemical stimulation, whether excitatory or inhibitory, can be achieved 
by infusing (through conventional cannulae or microfluidics) chemical agents 
or biological (genetic) agents to modulate activity. Electrochemical sensors 
provide a means of detecting neurotransmitters and can be specific to particular 

TECHNOLOGIES TO INTERFACE WITH THE BRAIN	
55
electro­active neurotransmitters. They may be located nearby conventional micro­
electrodes, even on the same supporting substrate, and provide information about 
the concentration of molecules.
Nanoscale transducers introduced into brain tissue can modulate brain activity 
through the conversion of optical, acoustic, and magnetic stimulation into voltage 
or electric fields. These nanotransducers include quantum dots, gold nanoparticles, 
up-conversion nanoparticles, and magnetic nanoparticles. The latter can activate 
mechanosensitive ion channels by producing the required piconewton-level forces 
in the presence of a magnetic field gradient. The delivery of these nanomaterials 
and control of their targeting remain a challenge. 
Interfaces need not be invasive. Acoustic waves and magnetic fields can be 
harnessed to modulate activity in the brain. Whereas electromagnetic waves in the 
visible and infrared spectrum have limited penetration depth (1 mm), transcranial 
focused ultrasound can access deeper regions (>50 mm), although at inferior spa-
tial resolution (1 mm3). Transcranial magnetic stimulation can access the upper 
10 mm but with reduced spatial resolution (Chen et al. 2017).
Although electrical and nonelectrical interfaces are discussed separately here, 
several have been combined to leverage the advantages of the particular technique 
for research purposes.
CHALLENGES AND OPPORTUNITIES
The availability of appropriate interface technologies for the brain strongly 
affects the ability of researchers and clinicians to understand it and develop new 
therapies. Yet even the limited and imperfect information currently available 
has resulted in clinically implemented technologies with only a few stimulating 
electrodes that have dramatically improved lives. DBS, for example, has been 
approved by the US Food and Drug Administration for the treatment of tremor 
(1997), Parkinson’s disease (2002), dystonia (2003), and obsessive compulsive 
disorder (OCD; 2009) (Sironi 2011). 
Future advances seek to seamlessly integrate neural interfaces with the brain 
to enable both long-term recording and modulation of neurons with a higher num-
ber of input and output channels (Wellman et al. 2017). To achieve this, the health 
of the tissue-device interface needs to be improved by addressing tissue damage 
related to surgical delivery, the biological immune response, and the ­stability 
of the materials used in the construction of the interfaces. More information is 
needed about the effects of the complex interplay between material selection, 
device design, and fabrication methodology on the long-term performance and 
function of the device in the body. These advances are critical to obtain chronically 
stable high-density and large-scale recordings. 
In addition, modulation technologies need improvements in reliability and 
precision. When used together, recording and modulation can achieve exciting 
new concepts in closed-loop therapeutic systems of the future. With rigorous 

56	
FRONTIERS OF ENGINEERING
engineering focused on reliability, the next generation of life-changing medical 
technology breakthroughs can be realized.
REFERENCES
Adrian E. 1932. The Mechanism of Nervous Action: Electrical Studies of the Neurone. Philadelphia: 
University of Pennsylvania Press.
Aldini G. 1804. Essai théorique et expérimental sur le galvanisme, avec une série d’expériences 
faites en présence des commissaires de l’Institut National de France, et en divers amphithéâtres 
anatomiques de Londres par Jean Aldini. Paris: De l’imprimerie de Fournier fils.
Borton D, Micera S, Millan J del R, Courtine G. 2013. Personalized neuroprosthetics. Science Trans-
lational Medicine 5(210):210rv2.
Bresadola M. 1998. Medicine and science in the life of Luigi Galvani (1737–1798). Brain Research 
Bulletin 46(5):367–380.
Cerletti U. 1940. L’elettroshock. Reggio-Emilia: Istituo psichiatrico di s. Lazzaro.
Chen R, Canales A, Anikeeva P. 2017. Neural recording and modulation technologies. Nature Reviews 
Materials 2:16093.
Grimnes S. 2014. Bioimpedance and Bioelectricity Basics. Boston: Elsevier.
Sironi VA. 2011. Origin and evolution of deep brain stimulation. Frontiers in Integrative Neuro­
science 5:42.
Spiegel EA, Wycis HT, Marks M, Lee AJ. 1947. Stereotaxic apparatus for operations on the human 
brain. Science 106(2754):349–350.
Verkhratsky A, Krishtal OA, Petersen OH. 2006. From Galvani to patch clamp: The development of 
electrophysiology. Pflügers Archiv 453(3):233–247.
Wellman SM, Eles JR, Ludwig KA, Seymour JP, Michelson NJ, McFadden WE, Vazquez AL, Kozai 
TDY. 2017. A materials roadmap to functional neural interface design. Advanced Functional 
Materials 1701269.

Brain-Machine Interface Paradigms for 
Neuroscience and Clinical Translation
Samantha R. Santacruz, Vivek R. Athalye, Ryan M. Neely, and 
Jose M. Carmena
University of California, Berkeley 
The brain-machine interface (BMI) is a novel technology that holds great 
potential to aid large numbers of people with sensory, motor, and cognitive dis-
abilities. The goal of cortically controlled BMIs is to reliably, accurately, and 
robustly convey enough motor control intent from the central nervous system 
(CNS) to drive multi-degree-of-freedom (DOF) prosthetic devices by patients 
with amputated, paralyzed, or otherwise immobilized limbs for long periods of 
time (decades). Two main challenges need to be addressed in order to achieve this 
goal: (1) how to make viable neural interfaces that last a lifetime, and (2) how to 
enable skillful control and dexterity of a multi-DOF prosthetic device comparable 
to natural movements. 
In a BMI system, neural signals recorded from the brain are fed into a 
machine that transforms them into a motor plan. This is the subject’s “intention 
of movement,” which is then streamed to the prosthetic device. A closed control 
loop is established by providing the subject with visual and sensory feedback of 
the prosthetic device. 
BMIs also provide a framework for examining basic neuroscience questions, 
especially those related to the understanding of how neural plasticity relates to the 
acquisition and consolidation of skills.
We postulate that achieving skillful, natural control of a multi-DOF BMI will 
entail synergizing two types of adaptation processes—natural (brain ­plasticity) 
and artificial (decoder adaptation)—as well as providing realistic sensory feedback 
from the prosthetic device. Recent work shows that (1) neuroplasticity facilitates 
consolidation of neuroprosthetic motor skill in a way that resembles that of natural 
motor learning, (2) corticostriatal plasticity is necessary for neuroprosthetic skill 
learning, and (3) closed-loop decoder adaptation (CLDA) techniques can expedite 
57

58	
FRONTIERS OF ENGINEERING
the learning process by adapting the decoder parameters during closed-loop BMI 
operation (i.e., while the subject is using the BMI). 
The design process of a CLDA algorithm requires important decisions not 
only about which parameters of the decoder should be adapted and how, but also 
when (i.e., how often), as the rate at which the decoder changes can influence per-
formance. We believe that BMI systems capable of exploiting both neuroplasticity 
and CLDA will be able to boost learning, generalize well to novel movements and 
environments, and ultimately achieve a level of control and dexterity comparable 
to that of natural arm movement.
Next we discuss how to use BMIs to study skill learning and consolidation. 
In addition to holding great therapeutic potential as assistive and rehabilitation 
technology, BMIs provide a powerful framework for examining basic neuro-
science questions, especially those related to the neural correlates of learning 
behavior, as it offers researchers the unique opportunity to directly control the 
causal relationship between neuronal activity and behavioral output. In particu-
lar, we focus on the question of how neuroplasticity relates to the acquisition 
and consolidation of skills. This question is paramount as it affects both brain 
function and dysfunction. 
We examine the question of how a task-relevant neural population explores 
and consolidates spatiotemporal patterns supporting neuroprosthetic skill learn-
ing. In the early stages of motor skill learning, movements are variable from 
attempt to attempt. This variability can be beneficial to learning, permitting the 
motor system to explore actions and their consequences. Gradually movement 
variability decreases as the motor system consolidates the movements that lead 
to success. 
Neurophysiological motor learning studies have found that neural activity 
in various species and brain areas follows a similar trend, exhibiting high vari-
ability in early training and reducing variability as particular activity patterns 
are consolidated in late training. These studies have focused on overall changes 
in neural variability. Given the large dimensionality of possible activity patterns 
available to a neural population, and the possibilities for interaction among cells, 
it is critical to understand how different sources of neural variability contribute 
to motor learning. If the variability in a neural population is driven mostly by 
private independent inputs, then each neuron produces independent activity and 
the population fully explores high dimensional activity space. If, on the other 
hand, cells receive coordinating inputs (input activity that drives multiple cells 
simultaneously), then activity becomes constrained to a coactivation manifold.
Because the motor system is a distributed and redundant dynamical system, 
with parallel degenerate pathways and many more neurons than muscles, a 
fundamental challenge of neuroscience has been to ascertain the causal relation-
ship between observed neural activity patterns and motor output. This apparent 
complexity and degeneracy makes the question of how neural plasticity changes 
movement production difficult to answer. 

BRAIN-MACHINE INTERFACE PARADIGMS FOR NEUROSCIENCE	
59
We took advantage of a paradigm in which we could identify the output 
neurons that control behavior and identify the explicit transformation between 
output neuron activity and behavior. We used an operant learning BMI paradigm 
in which stable recordings from ensembles of primary motor cortex neurons in 
macaque monkeys are fed through a constant mathematical transform, referred 
to as a decoder, to transform neural activity into prosthetic movements. The BMI 
provided a closed-loop feedback system operating within the natural motor sys-
tem, called the neuroprosthetic circuit. 
Under the condition of a fixed decoder and fixed neural population over train-
ing, subjects acquire proficient neuroprosthetic control that is stable and ­readily 
recalled over days. This neuroprosthetic skill learning paradigm is uniquely 
advantageous to investigate how task-relevant neural populations explore and 
consolidate activity patterns that support skill learning. 
By selecting the stable cells whose activity is fed through the decoder 
(known as direct cells), we define the direct cells as task relevant. By designing 
the decoder and task goals, we define the neural activity space that is relevant for 
behavioral output as well as the possible activity patterns that can lead to success. 
By holding the neuroprosthetic circuit fixed, we can investigate how variability 
from different sources in a task-relevant neural population evolves with training, 
contributes to the consolidated activity and neuroprosthetic patterns, and ulti-
mately drives neuroprosthetic learning.
We used factor analysis to model independent and coordinated sources of 
variability in a neuroprosthetic skill learning task, and revealed that population 
dynamics became more coordinated and low dimensional with training. We 
­leveraged the decoder structure to interpret the observed changes in dynamics and 
found that task-relevant coordinating input signals were consolidated. 
Previous studies have shown that motor learning is accompanied by a 
decrease in total trial-to-trial neural variability. We found that private and shared 
sources of variability evolve differently over training. While private variability is 
important early in training and then decreases, shared variability slowly consoli-
dates to produce faster and straighter movements. Hence, our findings describe 
neuroprosthetic skill learning as a process of spatiotemporal neural pattern con-
solidation, whereby the strengthening of task-relevant input signals coordinates 
initially variable, high-dimensional activity. 
A greater understanding of the neural substrates of neuroprosthetic skill learn-
ing can provide insight into the mechanisms of natural sensorimotor learning as 
well as help guide the design and development of neurobiologically informed 
neuroprosthetic systems to aid people with devastating neurological conditions.
Finally, in the last part of the talk I discuss the emerging field of mind pros-
thetics, which has applications to mental health. The current paradigm for the 
treatment of neuropsychiatric disorders, such as addiction and depression, relies 
heavily on pharmacological and behavioral therapies. This paradigm is inherently 
limited by its palliative rather than curative approach. Prospective corrective ther-

60	
FRONTIERS OF ENGINEERING
apies must target the etiology of neuropsychiatric disorders, and this approach can 
be realized using neurotechnologies that are capable of leveraging neurofeedback 
to construct targeted mechanisms that ameliorate pathological activity. 
BMI technologies are ideal for neuropsychiatric treatment therapeutics. In 
combination with new physiological biomarkers and animal models, future BMI 
neurotherapeutic devices will have the potential to cure people suffering from 
psychiatric and mood disorders. Toward this goal, we have developed a novel 
animal model for assaying correlates of acute anxiety and closed-loop strategies 
for mood modulation with strong anxiolytic effects.

While the direct goal of biological modeling is to describe data, it ultimately 
aims to find ways of fixing systems and enhancing understanding of system objec-
tives, algorithms, and mechanisms. Thanks to engineering applications, machine 
learning is making it possible to model data extremely well, without using strong 
assumptions about the modeled system. Machine learning can usually better 
describe data than biomedical models and thus provides both engineering solu-
tions and an essential benchmark. It can also be a tool to advance understanding.
Using examples from neuroscience, we highlight the contributions, both real-
ized and potential, of machine learning, which is becoming easy to use and should 
be adopted as a critical tool across the full spectrum of biomedical questions.
INTRODUCTION
The goal of nearly all of computational biology is to numerically describe a 
system, which is often quantified as the explained variance. In some cases, only 
the explained variance is of interest—for example, to make predictions. But in 
most cases, just describing the data successfully is not sufficient. There has been 
much discussion of objectives in the neuroscience community (e.g., Dayan and 
Abbott 2001; Marr 1982).
Uses of Models
The typical model is designed not only to numerically describe data but also 
to meet other objectives of the researcher. In some cases it is used to inform how 
to fix things—to predict what would happen based on certain interventions. In 
The Roles of Machine Learning 
in Biomedical Science
Konrad Paul Kording, Ari S. Benjamin, Roozbeh Farhoodi
University of Pennsylvania
Joshua I. Glaser
Northwestern University
61

62	
FRONTIERS OF ENGINEERING
others, the goal is to determine whether the system optimizes some objective; for 
example, whether the intricate folds of the brain minimize wiring length (Van 
Essen 1997). Or the aim may be to understand the system as an algorithm—for 
example, which algorithms the brain uses to learn (Marblestone et al. 2016). Prob-
ably most commonly, a model is used to understand underlying mechanisms—for 
example, how action potentials are enabled by interactions between voltage-
dependent ion channels (Hodgkin and Huxley 1952).
So far, progress in the modeling field comes mostly from human insights into 
systems. People think about the involved components, conceptualize the system’s 
behavior, and then build a model based on their intuitive insights. This has been 
done for neurons (Dayan and Abbott 2001), molecules (Leszczynski 1999), and 
the immune system (Petrovsky and Brusic 2002).
Biomedical researchers are starting to use computational models both to 
describe data and to specify the underlying principles. However, understanding 
such complex systems is extremely difficult, and human intuition is bound to 
be incomplete in systems with many nonlinearly interacting pieces (Jonas and 
Kording 2017).
What Is Machine Learning?
The vast field of machine learning is a radically different way of approach-
ing modeling that relies on minimal human insight (Bishop 2006). We focus here 
on the most popular subdiscipline, supervised learning, which assumes that the 
relationship between the measured variables and those to be predicted is in some 
sense simple (Wolpert 2012), with characteristics such as smoothness, sparseness, 
or invariance.
Supervised algorithms receive vectors of features as inputs and produce 
predictions as outputs. Machine learning techniques mostly differ by the nature 
of the function they use for predicting (Schölkopf and Smola 2002). Rather than 
assuming an explicit model about the relationship of variables, ML techniques 
assume a generic notion of simplicity.
The field of machine learning is undergoing a revolution. It has moved 
from a niche discipline to a major driver of economic activity over the past 
couple of decades as progress revolutionizes web searching, speech to text, 
and countless other areas of economic importance. The influx of talent into 
this field has led to massive improvements in algorithm performance, allow-
ing computers to out­perform humans at tasks such as image recognition (He et 
al. 2015) and playing Go (Silver et al. 2016). These developments in machine 
learning promise to make it an important tool in biomedical research. Indeed, 
the number of ML-related papers and patents in biomedical research has grown 
exponentially (Figure 1).

THE ROLES OF MACHINE LEARNING IN BIOMEDICAL SCIENCE	
63
FIGURE 1  Trends in use of machine learning (ML) for biomedical sciences, 1992–2016. 
Publication data (blue) were collected from the Semantic Scholar website using the key-
words “biomedical” and “machine learning.” Patent data (red) were collected from Google 
Patents using the same keywords.
0
1992
2000
2008
2016
Publications
Patents
10
100
1000
Year
Number of occurrences
USES OF MACHINE LEARNING FOR BIOMEDICAL RESEARCH
Many kinds of questions can be answered using machine learning techniques. 
In some cases they are useful for predictions, such as whether a drug will cure 
a particular cancer. In others they set a benchmark—for example, what are the 
shortcomings of the human-thought-out model relative to what may be possible? 
In yet other cases machine learning may enhance understanding of a system by 
revealing which variables are shared between components of a system. 
Description and Prediction
The standard use for machine learning is to make a prediction based on some-
thing that can be measured. For example, in psychiatric medicine, studies have used 
smartphone recordings of everyday behaviors (e.g., when patients wake up or how 
much they exercise) to predict mood using machine learning (Wang et al. 2014).
A typical problem in neuroscience is the decoding of neural activity (Velliste 
et al. 2008) to infer intentions from brain measurements. This application is useful 
for developing interactive prosthetic devices, in which one uses measurements 
from the brain of a paralyzed subject to enable a robot to execute the movement. 
Many algorithms have been developed to solve such problems (Corbett et al. 
2012; Yu et al. 2007); for this application, general purpose machine learning tends 
to do extremely well (Glaser et al. 2017).
Computationally similar problems exist throughout biomedical research, 
in areas such as cancer (Kourou et al. 2015), preventive medicine (Albert et al. 

64	
FRONTIERS OF ENGINEERING
2012), and medical diagnostics (Foster et al. 2014). In these areas only the quality 
of the predictions is of interest. Similarly, many engineering problems are mainly 
concerned with the error size of predictions. When the main goal is to obtain 
accurate predictions, it is best to first try machine learning methods.
Benchmarking
Often the goal is not only to describe and predict data but also to produce 
models that can be readily understood and taught. Machine learning can be 
extremely useful by providing a benchmark.
One problem when evaluating a model is that it is hard to know how much 
its errors are due to noise versus the insufficiency of the model. Because machine 
learning is a useful tool for making predictions, it may provide close to an upper 
bound for human-produced models. If a human-generated model produces results 
that are very different from the ML benchmark, it may be because important prin-
ciples are missing or because the modeling is misguided. If, on the other hand, 
a model based on human intuition is very close to the ML benchmark, it is more 
likely that the posited concepts are, indeed, meaningful. 
But how is it possible to know whether a model is missing important aspects? 
We argue that ML benchmarking can help answer those questions (Benjamin et 
al. 2017).
Understanding
Machine learning can also directly help understanding. One important ques-
tion is whether a system carries information about some variables (for example, 
whether neural activity contains information about an external stimulus), but it 
may not be clear whether the relation between the variables is linear or nonlinear. 
With machine learning it is possible to determine whether information is contained 
in a signal without having to specify the exact nature of the relationship.
Another important question concerns the information shared between two 
parts of a system. For example, which aspects of the world (high dimensional) are 
shared with which aspects of the brain (also high dimensional)? Machine learn-
ing makes it possible to ask such questions in a well-defined way (Andrew et al. 
2013; Hardoon et al. 2004).
For many questions in biology, machine learning promises to enable new 
approaches to enhance understanding.
MACHINE LEARNING:  
A NECESSITY FOR EVER-GROWING DATASETS
Datasets are rapidly growing and becoming more and more complex as they 
become multimodal and multifaceted (Glaser and Kording 2016). In neuro­science, 

THE ROLES OF MACHINE LEARNING IN BIOMEDICAL SCIENCE	
65
the number of simultaneously recorded neurons is increasing exponentially 
(Stevenson and Kording 2011), as is the amount of electronic health record data 
(Shortliffe 1998).
Challenges in Modeling for Complex Datasets
There are several ways in which these changes in datasets will create new 
problems for modeling. First, we humans are not very good at thinking about 
complex datasets. We can only consider a small hypothesis space. But in biology, 
as opposed to physics, there are good reasons to assume that truly meaningful 
models must be fairly complex (O’Leary et al. 2015). While humans will cor-
rectly see some structure in the data, they will miss much of the actual structure. 
It could be argued that it is nearly impossible for humans to intuit models of 
complex biological systems.
Second, nonlinearity and recurrence make it much more difficult to model 
complex systems (O’Leary et al. 2015), which require complex models. It can 
be hard to falsify models that are very expressive or have many free parameters. 
One needs to both explain complexity and ensure that the model will fail if the 
causal structure is dissimilar to the model. For full-cell interactions or full-brain 
modeling, the design of models that strike this delicate balance seems implausible.
Finally, in the case of the large complex systems that are characteristic of 
biology, a major problem is the lack of understanding of how many different 
models could in principle describe the data. Models can explain some portion 
of the variance, but not necessarily the mechanism (Lazebnik 2002). Comparing 
models is pointless if they are not good at describing the relevant mechanisms.
Given all these arguments, it may be that physics-based non-ML-based 
approaches can only partially succeed. Any reasonably small number of principles 
can describe only part of the overall variance (and potentially a relatively small 
part). It is unclear how far the typical approach in biomedical research, drawing 
on concepts of necessity and sufficiency, can help to enhance understanding of the 
bulk of activity in complex interacting systems (Gomez-Marin 2017). Machine 
learning has the potential to describe a very large part of the variance.
A Note about Model Simplicity and Complexity
Machine learning also changes the objectives of data collection. In tradi-
tional approaches, measuring many variables is unattractive as, through multiple 
comparison testing corrections, it is not possible to say much about each of them. 
But with machine learning, using many variables improves predictions—even if 
it is not clear which variables contribute—making it attractive to record many 
variables.
This is not just a vacuous statement about information processing. It reflects 
the fact that the brain and other biological systems are not simple, with few 

66	
FRONTIERS OF ENGINEERING
interactions, but highly recurrent and nonlinear. The assumption of simplicity in 
biology is largely a fanciful, if highly convenient, illusion. And if the systems 
subject to machine learning are not simple, then biases toward simple models 
will not do much good.
Based on their intuitions, researchers are starting to fit rather complex models 
to biological data, and those models usually fit the data better than simpler models. 
However, a complex model based on a wrong idea may fit the data extremely well 
and thus negate the advantage of an interpretable model.
A good fit does not mean that the model is right. For example, Lamarckian 
evolution explains a lot of data about species, but it was based on a fundamentally 
misleading concept of causal transmission of traits. The problem of apparent fit 
affects human intuition–based models, but not ML models, which, by design, do 
not produce a meaningful causal interpretation.
SPECIALIST KNOWLEDGE NOT NECESSARY 
FOR MACHINE LEARNING
There are countless approaches in machine learning, certainly more than 
most biomedical researchers have time to learn. Kernel-based systems such as 
support vector machines are built on the idea of regulating model complexity 
(Schölkopf and Smola 2002). Neural networks are built on the idea of hierarchical 
representations (Goodfellow et al. 2016). Random forests are built on the idea of 
having many weak learners (Breiman 2001). One could easily fill books with all 
the knowledge about machine learning techniques.
Yet the use of ML techniques has actually become very simple. At application 
time, one requires a matrix of training features and a vector of the known labels. 
And given the availability of the right software packages (Pedregosa et al. 2011), 
generally only a few lines of code are needed to train any ML system.
Moreover, ensemble methods obviate the need to choose a single machine 
learning technique (Dietterich 2000). The idea is that a system can run all tech-
niques and then combine their predictions using yet another ML technique. Such 
approaches often win ML competitions (e.g., kaggle.com).
Furthermore, a new trend has developed rapidly in the past few years: auto-
matic machine learning (Guyon et al. 2015). The idea is that most ML experts 
do similar things: they choose one of a number of methods (or all of them if they 
use ensembling) and then optimize the hyperparameters of those techniques. They 
may also optimize the feature representation. Although this can take a significant 
amount of time via trial and error, the process is relatively standard and several 
new packages allow automation of some or all of it.1
1   Examples of these packages are available at https://github.com/automl/auto-sklearn, www.cs.ubc.
ca/labs/beta/Projects/autoweka/, https://github.com/KordingLab/spykesML, and https://github.com/
KordingLab/Neural_Decoding.

THE ROLES OF MACHINE LEARNING IN BIOMEDICAL SCIENCE	
67
These developments are likely to pick up speed in the next year or two, mak-
ing it less necessary for biomedical scientists to know the details of the individual 
methods and freeing them to focus on the scientific questions that machine learn-
ing can answer.
EXAMPLES OF STATE-OF-THE-ART MACHINE 
LEARNING IN NEUROSCIENCE
With examples from neuroscience we illustrate two uses of ML approaches, 
predictions and benchmarking.
Neural Decoding
In neural decoding the aim is to estimate subjects’ intentions based on brain 
activity—for example, to predict intended movements so that they can move an 
exoskeleton with their thoughts. A standard approach in the field is still the use 
of simple linear techniques such as those used in the Wiener filter, in which all 
previous signals during a given time period are linearly combined to predict the 
output.
There has recently been a lot of interest in improving this and similar 
approaches using modern machine learning. For many applications the goal is 
simply good performance. To analyze the advantages of using standard machine 
learning, we implemented many approaches: the linear Wiener filter, the non-
linear extension called the Wiener cascade, the Kalman filter, nonlinear support 
vector machines, extreme gradient–boosted trees, and various neural networks 
(Figure 2).
The modern neural network–based techniques did very well (Glaser et 
al. 2017), and a combination of all the techniques, using ensemble methods, 
performed even better. The same phenomenon was seen when decoding from 
different brain regions. Thus we conclude that, to solve biomedical engineering 
problems, use of standard machine learning should be the starting point.
In this sense, machine learning also sets a benchmark for other decoding 
approaches. When neuroscientists write decoding algorithms they are often based 
on their insights into the way the brain works (Corbett et al. 2012). However, 
without a comparison to modern machine learning, it is not possible to know 
whether or to what extent these insights are appropriate.
As machine learning becomes automatic and easy to use, we argue that it 
should always be used as a benchmark for engineering applications.
Neural Encoding
Neural encoding, or tuning curve analysis, involves the study of signals from 
a neuron or a brain region to understand how they relate to external variables. 

68	
FRONTIERS OF ENGINEERING
FIGURE 2  State-of-the-art machine learning decoding (left) and encoding (right). Left: 
Predicting state based on signals from three brain areas using various machine learning 
techniques and then ensemble analysis. Right: Predicting spikes using signals from three 
brain areas. Motor cortex data are from a study of macaques; somatosensory cortex and 
hippocampus data are those of humans. Data replotted with permission from Glaser et 
al. (2017), Benjamin et al. (2017). Casc. = cascade; GLM = generalized linear model; 
GRU = gated recurrent unit; LSTM = long short-term memory; NN = neural network; 
RNN = recurrent neural network; SVR = support vector; XG = extreme gradient.
 
R2
1.0
0.6
R2
1.0
0.6
R2
0.75
0.25
Motor Cortex
Somatosensory Cortex
Hippocampus
SVR
Kalman Filt.
XGBoost
Feedfrwrd NN
Simple RNN
GRU
LSTM
Ensemble
Wiener Casc.
Wiener Filter
WF
WC
KF
SVR XGB FNN RNN GRU LSTM Ens
WF
WC
KF
SVR XGB FNN RNN GRU LSTM Ens
WF
WC
KF
SVR XGB FNN RNN GRU LSTM Ens
pseudo R2
0.2
0
GLM
XGB
FNN
Ens
0.1
pseudo R2
0.2
0
GLM
XGB
FNN
Ens
0.1
pseudo R2
0.2
0
GLM
XGB
FNN
Ens
0.1
GLM
Motor Cortex
Somatosensory Cortex
Hippocampus

THE ROLES OF MACHINE LEARNING IN BIOMEDICAL SCIENCE	
69
Such a characterization can yield insights into the role of a neuron in computation 
(Jonas and Kording 2017).
Typically, the neuroscientist chooses a model (often implicitly) and the aver-
age signal is plotted as a function of external variables such as visual stimuli or 
movements. This approach generally assumes a simple model. Would machine 
learning give better results?
For such applications it is impossible to know whether poor model perfor-
mance is due to external variables unrelated to neural activity or to the choice of 
model form. In principle, input variables may affect the neuron’s activity in highly 
nonlinear ways. This hypothesis can be tested with machine learning.
When we compared the generalized linear model (GLM; Pillow et al. 2008), it 
performed considerably worse than neural networks or extreme gradient–boosted 
trees (Figure 2). And again, the combination of all the methods using ensemble 
techniques yielded the best results. It can be difficult to guess features that relate 
to neural activity in exactly the form specified by the GLM.
Interestingly, despite the fact that the space was rather low dimensional, 
GLMs performed poorly relative to modern machine learning. This may suggest 
that the tuning curves measured by neuroscientists are rather poor at describing 
neurons in real-world settings.
In this context, machine learning can conceptually contribute in the follow-
ing ways:
1.	 It can detect that a variable is represented, even if there is no linear 
correlation.
2.	 It can set a benchmark that humans can strive for.
3.	 It offers a possibility of replacing the common cartoon model of neural 
computation with a complex (although admittedly hard to interpret) 
alternative.
CONCLUSION
The incorporation of machine learning has profound implications for neuro-
science and biomedical science.
For biomedical modeling, traditional modeling and machine learning cover 
opposite corners. Traditional modeling leads to models that can be compactly 
communicated and taught, while explaining only a limited amount of variance. 
Machine learning modeling explains a lot of variance, but is difficult to commu-
nicate. The two types of modeling can inform one another, and both should be 
used to their maximal possibility.

70	
FRONTIERS OF ENGINEERING
REFERENCES
Albert MV, Kording K, Herrmann M, Jayaraman A. 2012. Fall classification by machine learning 
using mobile phones. PLoS One 7:e36556.
Andrew G, Arora R, Bilmes J, Livescu K. 2013. Deep canonical correlation analysis. Proceedings of 
Machine Learning Research 28(3):1247–1255.
Benjamin AS, Fernandes HL, Tomlinson T, Ramkumar P, VerSteeg C, Miller L, Kording KP. 2017. 
Modern machine learning far outperforms GLMS at predicting spikes. bioRxiv 111450.
Bishop C. 2006. Pattern Recognition and Machine Learning. New York: Springer.
Breiman L. 2001. Random forests. Machine Learning 45:5–32.
Corbett EA, Perreault EJ, Kording KP. 2012. Decoding with limited neural data: A mixture of time-
warped trajectory models for directional reaches. Journal of Neural Engineering 9:036002.
Dayan P, Abbott LF. 2001. Theoretical Neuroscience: Computational and Mathematical Modeling of 
Neural Systems. Cambridge: MIT Press.
Dietterich TG. 2000. Ensemble methods in machine learning. Proceedings of the First International 
Workshop on Multiple Classifier Systems, June 21–23, Cagliari, Italy. Berlin: Springer-Verlag.
Foster KR, Koprowski R, Skufca JD. 2014. Machine learning, medical diagnosis, and biomedical 
engineering research: Commentary. BioMedical Engineering OnLine 13:94.
Glaser JI, Kording KP. 2016. The development and analysis of integrated neuroscience data. Frontiers 
in Computational Neuroscience 10:11.
Glaser JI, Chowdhury RH, Perich MG, Miller LE, Kording KP. 2017. Machine learning for neural 
decoding. arXiv preprint 1708.00909.
Gomez-Marin A. 2017. Causal circuit explanations of behavior: Are necessity and sufficiency neces-
sary and sufficient? In: Decoding Neural Circuit Structure and Function, eds. Çelik A, Wernet 
MF. Cham: Springer.
Goodfellow I, Bengio Y, Courville A. 2016. Deep Learning. Cambridge: MIT Press.
Guyon I, Bennett K, Cawley G, Escalante HJ, Escalera S, Ho TK, Macià N, Ray B, Saeed M, Statnikov 
A, Viegas E. 2015. Design of the 2015 ChaLearn autoML challenge. 2015 International Joint 
Conference on Neural Networks (IJCNN), July 12–17, Killarney. 
Hardoon DR, Szedmak S, Shawe-Taylor J. 2004. Canonical correlation analysis: An overview with 
application to learning methods. Neural Computation 16:2639–2664.
He K, Zhang X, Ren S, Sun J. 2015. Delving deep into rectifiers: Surpassing human-level performance 
on imagenet classification. Proceedings of the IEEE International Conference on Computer 
­Vision, December 7–13, Santiago.
Hodgkin AL, Huxley AF. 1952. A quantitative description of membrane current and its application to 
conduction and excitation in nerve. Journal of Physiology 117:500–544.
Jonas E, Kording KP. 2017. Could a neuroscientist understand a microprocessor? PLoS Computational 
Biology 13:e1005268.
Kourou K, Exarchos TP, Exarchos KP, Karamouzis MV, Fotiadis DI. 2015. Machine learning appli­
cations in cancer prognosis and prediction. Computational and Structural Biotechnology Journal 
13:8–17.
Lazebnik Y. 2002. Can a biologist fix a radio?—Or, what I learned while studying apoptosis. Cancer 
Cell 2(3):179–182.
Leszczynski JE. 1999. Computational Molecular Biology, vol 8. Amsterdam: Elsevier.
Marblestone AH, Wayne G, Kording KP. 2016. Toward an integration of deep learning and neuro­
science. Frontiers in Computational Neuroscience 10:94.
Marr D. 1982. Vision: A Computational Approach. San Francisco: Freeman & Co.
O’Leary T, Sutton AC, Marder E. 2015. Computational models in the age of large datasets. Current 
Opinion in Neurobiology 32:87–94.

THE ROLES OF MACHINE LEARNING IN BIOMEDICAL SCIENCE	
71
Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, Blondel M, Prettenhofer P, 
Weiss R, Dubourg V, and 6 others. 2011. Scikit-learn: Machine learning in python. Journal of 
Machine Learning Research 12:2825–2830.
Petrovsky N, Brusic V. 2002. Computational immunology: The coming of age. Immunology and Cell 
Biology 80(3):248–254.
Pillow JW, Shlens J, Paninski L, Sher A, Litke AM, Chichilnisky EJ, Simoncelli EP. 2008. Spatiotem-
poral correlations and visual signalling in a complete neuronal population. Nature 454:995–999.
Schölkopf B, Smola AJ. 2002. Learning with Kernels. Cambridge: MIT Press.
Shortliffe EH. 1998. The evolution of health-care records in the era of the Internet. Medinfo 98:8–14.
Silver D, Huang A, Maddison CJ, Guez A, Sifre L, Van Den Driessche G, Schrittwieser J, Antonoglou 
I, Panneershelvam V, Lanctot M, and 10 others. 2016. Mastering the game of go with deep neural 
networks and tree search. Nature 529:484–489.
Stevenson IH, Kording KP. 2011. How advances in neural recording affect data analysis. Nature 
Neuroscience 14:139–142.
Van Essen DC. 1997. A tension-based theory of morphogenesis and compact wiring in the central 
nervous system. Nature 385(6614):313–318.
Velliste M, Perel S, Spalding MC, Whitford AS, Schwartz AB. 2008. Cortical control of a prosthetic 
arm for self-feeding. Nature 453:1098–1101.
Wang R, Chen F, Chen Z, Li T, Harari G, Tignor S, Zhou X, Ben-Zeev D, Campbell AT. 2014. 
StudentLife: Assessing mental health, academic performance and behavioral trends of college 
students using smartphones. Proceedings of the 2014 ACM International Joint Conference on 
Pervasive and Ubiquitous Computing, September 13–17, Seattle.
Wolpert DH. 2012. What the no free lunch theorems really mean: How to improve search algorithms. 
SFI Working Paper 2012-10-017. Santa Fe Institute.
Yu BM, Kemere C, Santhanam G, Afshar A, Ryu SI, Meng TH, Sahani M, Shenoy KV. 2007. Mixture 
of trajectory models for neural decoding of goal-directed movements. Journal of Neuro­physiology 
97:3763–3780.


Efficient Feature Extraction and 
Classification Methods in Neural Interfaces
Mahsa Shoaran
Cornell University
Benyamin A. Haghi
California Institute of Technology
Masoud Farivar
Google 
Azita Emami
California Institute of Technology
Brain disorders such as dementia, epilepsy, migraine, and autism remain 
largely undertreated, but neural devices are increasingly being used for their treat-
ment. Such devices are designed to interface with the brain, monitor and detect 
neurological abnormalities, and trigger an appropriate type of therapy such as 
neuromodulation to restore normal function.
A key challenge to these new treatments is to integrate state-of-the-art signal 
acquisition techniques, as well as efficient biomarker extraction and classifica-
tion methods to accurately identify symptoms, using low-cost, highly integrated, 
wireless, and miniaturized devices.
THERAPEUTIC NEURAL DEVICES 
A general block diagram of a closed-loop neural interface system is shown in 
Figure 1. The neural signals recorded by an array of electrodes (intracranial, scalp, 
or other types) are initially amplified, filtered, and digitized. A feature extraction 
processor is then activated to extract the disease-associated biomarkers. Upon 
abnormality detection, a programmable neural stimulator is triggered to suppress 
the symptoms of disease (e.g., a seizure, migraine attack, Parkinson’s tremor, 
memory dysfunction) through periodic charge delivery to the tissue.
73

74	
FRONTIERS OF ENGINEERING
FIGURE 1  General block diagram of a closed-loop therapeutic system for detection and 
suppression of disabling neurological symptoms.
Biomarker (feature) 
extraction 
Implantable therapeutic device
Neural input
Neurological disorder 
detection
Neurostimulation
Signal conditioning, 
digitization
The abnormality detector device must demonstrate high sensitivity (true posi-
tive rate), sufficient specificity (true negative rate), and low latency. It also has to 
satisfy the safety, portability, and biocompatibility requirements of the human body.
AN EXAMPLE OF NEUROENGINEERING TREATMENT: EPILEPSY
The emerging field of neuroengineering uses engineering technologies to 
investigate and treat neurological diseases. Epilepsy has been one of the primary 
targets, along with movement disorders, stroke, chronic pain, affective disorders, 
and paralysis (Stacey and Litt 2008).
Approximately one-third of epileptic patients exhibit seizures that are not 
controlled by medications. Neuromodulation offers a new avenue of treatment 
for intractable epilepsy. 
Over decades, research on epilepsy has led to fundamental understandings 
of brain function, with strong implications for other neurological disorders. In 
addition, because of the severity of refractory epilepsy and the need for surgery, 
human tissue and epileptic EEG datasets are largely available. Most therapeutic 
neural interfaces reported in the literature have therefore focused on extracting 
epileptic biomarkers for automated seizure detection (Shoaran et al. 2015; Shoeb 
et al. 2004; Verma et al. 2010).
The spectral energy of neural channels in multiple frequency bands as well as 
various time and frequency domain features have been used as potential seizure 
biomarkers. To improve the power and area efficiency in multichannel systems, 
a ­spatial filtering technique was proposed to precede the seizure detection unit 
­(Shoaran et al. 2016b). But in most devices the classification of neural features 
is performed either remotely or by means of moderately accurate thresholding 
techniques.

EFFICIENT FEATURE EXTRACTION AND CLASSIFICATION METHODS	
75
FIGURE 2  Schematic of common learning models as potential candidates for hardware 
implementation.
For one patient-specific support vector machine (SVM) classifier (imple-
mented by Yoo et al. 2013), the classification processor contributes to a significant 
portion of chip area and power. To improve the accuracy of detection, resource-
efficient on-chip learning is becoming an essential element of next-generation 
implantable and wearable diagnostic devices.
MACHINE LEARNING IN NEURAL DEVICES: 
SCALABILITY CHALLENGES
Conventional classification techniques such as SVMs, k-nearest neighbors 
(KNNs), and neural networks (illustrated in Figure 2) are hardware intensive 
and require high processing power and large memory units to perform complex 
computations on chip.
Numerous studies show that a large number of acquisition channels are 
required to obtain an accurate representation of brain activity, and that the thera-
peutic potential of neural devices is limited at low spatiotemporal resolution. It is 
expected that future interfaces will integrate thousands of channels at relatively 
high sampling rates, making it crucial to operate at extremely low power. The 
device must also be very small to minimize implantation challenges.
Despite a substantial literature on machine learning, hardware-friendly 
implementation of such techniques is not sufficiently addressed. Indeed, even the 

76	
FRONTIERS OF ENGINEERING
simple arithmetic operations performed in conventional classification methods 
can become very costly with an increasing number of channels.
Finally, filter banks and, in general, feature extraction units can be hardware 
intensive, particularly at higher frequencies associated with intracranial EEG. 
Extensive system-level design improvement is needed to meet the requirements 
of an implantable device while preserving high-resolution recording capability.
DECISION TREE–BASED CLASSIFIERS
We present and evaluate a seizure detection algorithm using an ensemble of 
decision tree (DT) classifiers. The general schematic of a single decision tree is 
shown in Figure 2.
With only simple comparators as their core building blocks, DT classifiers 
are a preferable solution to reduce hardware design complexity. Using a gradient-
boosted ensemble of decision trees, we achieve a reasonable tradeoff between 
detection accuracy and implementation cost.
Gradient boosting (Friedman 2001), one of the most successful machine 
learning techniques, adaptively combines many simple models to get an improved 
predictive performance. Binary split decision trees are commonly used as the 
“weak” learners. Boosted trees are at the core of state-of-the-art solutions in a 
variety of learning domains because of their accuracy and fast computation and 
operation.
Combined with an efficient feature extraction model, we show that, with 
only a small number of low-depth “shallow” trees, the boosted classifiers quickly 
become competitive with more complex learning models (Shoaran et al. 2016a). 
These ensembles of axis-parallel DT classifiers are excellent candidates for on-
chip integration, eliminating the multiplication operation and offering significant 
reductions in power and chip area.
Performance Evaluation and Hardware Design
As a benchmark, we compare a boosted ensemble of 8 trees with a depth of 3 
to linear SVM, cubic SVM, and KNN-3 models proposed for on-chip classifica-
tion, using the following features: line length, time-domain variance, and multiple 
band powers. The proposed approach is tested on a large dataset of more than 140 
days of intracranial EEG data from 23 epileptic patients.
Figure 3 (left) shows the average F1 measure of classifiers. This benchmark 
is already competitive with its peers and can outperform using larger ensemble 
sizes. It achieves an average seizure detection sensitivity of 98.3 percent.
Decision trees are very efficient, but also susceptible to overfitting in prob-
lems with high feature space dimensionality. To address this, we limit the number 
of nodes in each tree—that is, we design shallow trees with a small number of 
features. These shorter trees are also more efficient in hardware and, equally 

	
77
FIGURE 3  Comparison of predictive ability of different classification methods with an ensemble of 8 decision trees (DT) of depth 3 (left), 
and the classification performance of the asynchronous hardware model compared to a conventional (conv.) DT (right). KNN = K-nearest 
neighbor; LIN = linear; PLY3 = polynomial kernel of order 3; SVM = support vector machine.
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
Patient number
Sensitivity and specificity
DT (Conv.) Spec.
DT (Hardware) Spec.
DT (Conv.) Sens.
DT (Hardware) Sens.
DT
SVM-LIN
SVM-PLY3
KNN3
0.7
0.74
0.78
0.82
0.86
0.9
Average F1 score
Classifier

78	
FRONTIERS OF ENGINEERING
important, incur less detection delay. In our simulations, the detection accuracy 
is not significantly improved (<0.5 percent) with DT depth values of 4 or more.
Proposed Decision Tree Architecture
We propose the architecture shown in Figure 4 (top) to implement ensembles 
of decision trees. At each comparison step, only the features appearing in the 
active nodes of trees are needed; the rest of the recording array can be switched 
off to save power.
Because the final decision is made upon completing decisions at prior levels, 
a single feature extraction unit can be sequentially used per tree. This results in a 
significant hardware saving, in contrast to SVM, which requires all features from 
the entire array.
For example, the memory required to classify 32-channel neural data with 
8 trees (a maximum depth of 3 and threshold resolution of 8 bits) is as low as 
100 bytes, while SVM and KNN-based arrays would need more than 500 kB of 
­memory. Depending on the specific patient and the difficulty of the detection 
task, additional “supportive” trees can be used to further boost the classification 
accuracy.
The proposed architecture faces a practical challenge of designing deci-
sion trees under application-specific delay constraints. Given any DT ensemble 
τ = {τ1,…,τk} obtained from our original method, we need to ensure that each 
tree τi satisfies the delay constraint: ∑i∈π(h)di ≤ ΔT, where di is the time required 
to compute feature fi, ΔT is the maximum tolerable detection delay, and π(h) is 
the set of all predecessors of node h. We propose a “greedy” algorithm to solve 
this practical constraint by building trees that satisfy the delay requirement, as 
illustrated in Figure 4 (bottom).
However, this algorithm may result in a suboptimal solution. We therefore 
investigate a novel asynchronous model to learn from neural data streams, the 
results of which are shown in Figure 3 (right). In this model, the trees are built with 
features that maximize accuracy regardless of their computational delay. Based 
on averaged results of completed trees and previous results of incomplete trees, 
decisions are frequently updated (over 0.5-sec intervals) to avoid long latencies 
and maximize sensitivity. Once completed, longer trees contribute to decisions 
at future time steps.
CONCLUSIONS
Based on a simple yet sufficiently accurate (98.3 percent) decision tree model, 
we introduce efficient hardware architectures and related training algorithms to 
predict the abnormal neurological states in various disorders, such as epilepsy, 
Parkinson’s disease, and migraine. Such classifiers may allow the full integra-

EFFICIENT FEATURE EXTRACTION AND CLASSIFICATION METHODS	
79
FIGURE 4  Hardware-level architecture for an ensemble of decision tree classifier with 
primary and supportive trees (top) and a greedy training algorithm to meet the delay con-
straints (bottom). A = amplifier; A/D = analog to digital converter; CH = channel; Comp. = 
comparator; k, N = number of features and channels; MUX = multiplexer; R = result.
Feature2
Feature k
X1<T1
X2<T2
X3<T3
X4<T4
X5<T5
X6<T6
X7<T7
Feature bank
Address decoder
Y
N
X1<T1
X2<T2
X3<T3
X4<T4
X5<T5
X6<T6
X7<T7
CH1
CHN
Feature1
Extra trees
Feature and 
threshold select
Channel select
A/D
X1<T1
X2<T2
X3<T3
X4<T4
X5<T5
X6<T6
X7<T7
+
R1
R5
T1
T5
Decision
Comp.
Training
A
A
MUX
Serial control input

80	
FRONTIERS OF ENGINEERING
tion of processing circuitry with the sensor array in various resource-constrained 
biomedical applications.
REFERENCES
Friedman JH. 2001. Greedy function approximation: A gradient boosting machine. Annals of Statistics 
29(5):1189–1232.
Shoaran M, Pollo C, Schindler K, Schmid A. 2015. A fully-integrated IC with 0.85µW/channel con-
sumption for epileptic iEEG detection. IEEE Transactions on Circuits and Systems II: Express 
Briefs (TCAS-II) 62(2):114–118.
Shoaran M, Farivar M, Emami A. 2016a. Hardware-friendly seizure detection with a boosted ensemble 
of shallow decision trees. International Conference of the IEEE Engineering in Medicine and 
Biology Society (EMBC), August 16–20, Orlando.
Shoaran M, Shahshahani M, Farivar M, Almajano J, Shahshahani A, Schmid A, Bragin A, Leblebici 
Y, Emami A. 2016b. A 16-channel 1.1mm2 implantable seizure control SoC with sub-µW/
channel consumption and closed-loop stimulation in 0.18µm CMOS. Proceedings of the IEEE 
Symposium on VLSI Circuits (VLSIC), June 13–17, Honolulu.
Shoeb A, Edwards H, Connolly J, Bourgeois B, Treves ST, Guttag J. 2004. Patient-specific seizure 
onset detection. Epilepsy and Behavior 5(4):483–498.
Stacey WC, Litt B. 2008. Technology insight: Neuroengineering and epilepsy—Designing devices 
for seizure control. Nature Clinical Practice Neurology 4(4):190–201.
Verma N, Shoeb A, Bohorquez J, Dawson J, Guttag J, Chandrakasan AP. 2010. A micropower EEG 
acquisition SoC with integrated feature extraction processor for a chronic seizure detection 
system. IEEE Journal of Solid-State Circuits 45:804–816.
Yoo J, Yan L, El-Damak D, Altaf MAB, Shoeb A, Chandrakasan AP. 2013. An 8-channel scalable 
EEG acquisition SoC with patient-specific seizure classification and recording processor. IEEE 
Journal of Solid-State Circuits 48:214–228.

Megatall Buildings and  
Other Future Places of Work


Megatall Buildings and  
Other Future Places of Work
Maria Paz Gutierrez
University of California, Berkeley
Marija Trcka
United Technologies Research Center
In 2015 a record-breaking 106 skyscrapers above 200 meters high emerged 
across the globe; the Council on Tall Buildings and Urban Habitat (CTBUH) 
reported that 62 skyscrapers were built in China alone. The growth is ­exponential 
in both number and height—CTBUH forecast an increase from 18 percent to 
27 percent in supertall buildings from 2015 to 2016. 
Of the 100 tallest buildings in the world, all are at least supertall, rising more 
than 300 meters. This decade launched a new breed of skyscraper, the megatall 
building, which rises 600 meters or more; in 2016, 6 megatall buildings were 
either fully completed or under way. This scale challenges conceptions and 
notions of livability at great heights. The new record for a megatall building will 
be set by the kilometer-high Jeddah Tower, by Adrian Smith and Gordon Gill 
Architecture, in Saudi Arabia; it is scheduled for completion in 2020. 
Megatall buildings elicit mixed reactions. They are seen as towering master­
pieces that serve as icons and symbols of power—or destroyers of urban ­quality 
of life. They are praised as efficient green construction models for vertical 
­densification—and denounced as consumers of resources that cannot possibly 
be sustainable. 
The mega-high structures are more than aesthetic and structural advances 
that establish urban and corporate statements. Their scale challenges fundamental 
inhabitation models and affects multiple spheres of urban life and society, from 
geography and zoning regulations to economics and cultural beliefs. It is there-
fore essential to understand the role of science, technology, and development in 
addressing the complex environmental and sociocultural challenges inherent to 
megatall constructions. 
83

84	
FRONTIERS OF ENGINEERING
How does scientific research enable and influence the design of megatall 
buildings? What are the scientific and technological innovations that will best 
support environmental sensibility and quality of life? What key driving factors 
will shape how engineers, architects, and scientists pursue new models that can 
be truly sustainable? 
Megatall constructions will influence potential paradigm shifts in intelligent 
buildings and transportation systems, materials, structures, and the very future 
of the workplace. This session aimed to prompt discussion of the critical role of 
advances in sustainability and energy, intelligent transportation, functional natural 
materials for structural innovation, and spatial quality of the future of work in 
megatall buildings. 
The session began with a review of fundamental design transformations in the 
making of megatall buildings and the impact of their distinctive spatial character-
istics on daily life. Stephen Nichols (Otis) surveyed the role of digital interaction, 
physical-human interface, and intuitive behavior, spanning the disciplines of 
computer science and electrical, mechanical, and systems engineering as vertical 
transportation continues to evolve in taller buildings. The next presenter, Michael 
Ramage (University of Cambridge), looked at functional natural materials for 
structural systems in high-rise buildings. He is a research leader in such materials, 
in particular engineered timber and bamboo for high-rise structures. The session 
concluded with a talk by Jenny Sabin (Cornell University) on the applications of 
insights from biology and mathematics to the design of environmentally adaptable 
material structures.
As population concentration in urban settings continues to grow, so will verti-
cal densification at unforeseen scales. It is essential to prepare for this outcome 
through fundamental research and development in potentially transformative 
models, in order to design and construct megatall buildings that exist in synergy 
with nature while promoting health and overall urban quality of life. 

For more than 160 years advances in vertical transportation and elevator tech-
nology have been key enablers of the increasingly high-rise buildings that define 
cities around the world. Improvements in elevator safety, robustness, quality, space 
efficiency, and performance have allowed buildings and cities to grow megatall.1 
The design and construction of such buildings and their vertical transportation 
systems need to be balanced with improvements that reduce passengers’ anxiety 
while increasing convenience and efficiency.
This article reviews the history of elevators and their technologies. It then 
examines specific considerations for megatall buildings, such as building traffic, 
lobbies and layout, and evacuation. The discussion considers the incorporation 
of new technologies and user-centered design to improve passenger experience.
BRIEF HISTORY OF ELEVATORS
The functional “job to be done” (Christensen 2011) of an elevator is simple: 
transport passengers and cargo safely and quickly from one altitude to another.
Early Methods
Elevators have been part of human history as far back as the pyramids of 
ancient Egypt (Gavois 1983), when the construction of large structures required 
1   Megatall buildings are 600 meters or more. For reference, the original 110-floor World Trade 
Towers in New York were just over 540 meters. The world’s tallest building, Burj Khalifa in Dubai, 
is 828 meters.
The Evolution of Elevators:  
Physical-Human Interface,  
Digital Interaction, and Megatall Buildings
Stephen R. Nichols
Otis Elevator Company
85

86	
FRONTIERS OF ENGINEERING
the capacity to raise materials to greater heights than humans could lift without 
mechanical advantage. The Egyptians, Romans, Babylonians, and others devised 
increasingly sophisticated rope and pulley systems, capstans, and other hoists 
for construction purposes—and there is evidence of an elevator hoistway in the 
Roman Colosseum completed in the year 80.
The first counterweight, used to balance and counteract the effects of gravity, 
did not appear before 1670, and hoists were not widely applied to industry until 
1830 (Goodwin 2001). Elevators were generally not successful because of their 
unreliability and lack of safety. Fraying rope and other mechanical failures due 
to wear and excessive weight were common causes of dangerous accidents that 
made factory owners reluctant to use elevators for cargo. Passenger use was all 
but unthinkable.
Invention of the Elevator Safety Brake
The use of levers, ropes and pulleys, and other lifting means persisted without 
many significant improvements until the invention in 1852 of the elevator safety 
brake by Elisha G. Otis (1811–61). He demonstrated it at the New York World’s 
Fair (Figure 12) in 1854 (Goodwin 2001), and it was patented in 1861.
Otis’s invention took a simple flat-leaf spring from a cart and applied it to 
the roof of an elevated hoist such that, in the event of the hoist rope’s failure, the 
tension in the spring would cause shoes on either end of the spring to engage with 
notches in the guide rails at either side of the hoist. As dramatically demonstrated 
at the World’s Fair, when the rope was cut, the safety brake activated and brought 
the hoist to an abrupt halt with no harm to the cargo or passengers.
The safety brake quickly transformed an unreliable, little-used industrial tool 
into a viable means of transporting not only cargo but also people. The first-ever 
safe commercial passenger elevator was installed in 1857 in a Manhattan depart-
ment store owned by E.V. Haughwout and Co.
With the commercial success of safe passenger elevators, architects and 
builders started constructing taller buildings. Prime real estate in buildings and 
cities quickly moved from the first few floors that were conveniently close to the 
building entry to the top floors and penthouses away from the dust and clamor 
of the city street.
The breakthrough in elevator safety prompted the evolution toward taller and 
taller cities and, eventually, today’s megatall buildings.
2   All figures and images are provided from the Otis Historical Archive: Historical Photographs, 
Illustrations and Ads; Digital Image Collection.

THE EVOLUTION OF ELEVATORS	
87
FIGURE 1  Elisha Graves Otis performs his safety elevator demonstration in the dome of 
the Crystal Palace at the World’s Fair in New York City (May 1854). Hired by showman 
PT Barnum to perform the feat, Otis rode up on the platform, had the rope cut, and, when 
the car did not fall in front of the stunned crowd, proclaimed: “All safe, ladies and gentle-
men! All safe!” Courtesy Otis Elevator Company.
ELEVATOR TECHNOLOGY DRIVERS
The competing benefits and disadvantages of gravity and friction, coupled 
with continuous improvements in power management, building materials, and 
other factors, transformed elevators from purely functional devices to a central 
component of urban buildings and city life.

88	
FRONTIERS OF ENGINEERING
Harnessing Gravity
The art of elevatoring—moving people vertically through buildings—is 
fundamentally about controlling gravity, which is both the elevator’s enemy and 
friend. It must be overcome to move people safely and smoothly, and harnessed 
(through counterweights and other means) for control and energy savings.
Early advances focused on propulsion technology. Steam engines in the 
1850s and 1860s, hydraulic systems in the 1870s, and electric motors in the 1890s 
(installed at either the top of the elevator hoistway or the bottom of the elevator 
pit) powered elevators through a variety of arrangements and layouts to enable 
higher rises, different building configurations, and efficient vertical motion. Rotat-
ing machinery and ropes, hydraulic pistons, or the combination thereof created 
the upward force to pull or push the passenger and cargo compartment up and to 
stop it safely, smoothly, and accurately at a desired destination.
Improvements in propulsion technology enabled the control of gravity, fos-
tered public confidence in elevators, and led to widespread success. Advertise-
ments initially showed the elevator’s industrial roots with a focus on machinery 
(Figure 2), but soon luxurious elevator interiors shifted the focus to passengers 
and elevators became part of the architectural intention of a building.
Controlling Friction
The safe, controlled, smooth deceleration and stopping of an elevator are of 
paramount importance.
Traction elevators balance friction and the interface between the rope (or belt) 
and the drive sheave, whether the “rope” is a hemp rope, steel cable, polyurethane-
coated steel belt, or carbon-fiber suspension member. Innovations in roping (with 
one-to-one and two-to-one roping, under- and overslung, and roped hydraulic 
arrangements) and other technological advances yielded a series of inventions 
from the latter half of the 19th century into the 20th (see Figures 3, 4). These 
improvements in elevator machinery and propulsion benefited both passengers 
and architects as elevators became faster and larger.
Systems in which propulsion did not rely on frictional interfaces were 
introduced in the 1990s: the first linear motor elevator system was commercially 
offered by Otis in Japan (Janovský 1999). This system, with the motor mounted 
on the counterweight, reduces the complexities of controlling friction for propul-
sion while retaining the counterweight for the advantages of working with gravity. 
Advances in linear motors will eventually make it possible for multiple elevator 
cars to travel simultaneously in individual hoistways.

THE EVOLUTION OF ELEVATORS	
89
FIGURE 2  This 1869 Otis Brothers ad illustrates advances in steam engines and belt-
driven hoist machinery for early elevator propulsion. Hydraulic piston-powered elevators 
were adopted in the 1870s and electric elevator motors in 1889. Courtesy Otis Elevator 
Company.

90	
FRONTIERS OF ENGINEERING
FIGURE 3  Elevator innovations in the mid-20th century looked beyond propulsion and 
hoisting technology. In the 1920s signal control and push buttons start to pave the way for 
automated control that, with the introduction of automatic doors, is realized in the 1950s 
(car operating panel shown to the left of the doors). In the 1970s the first integrated circuit, 
electronic, controlled elevator is introduced by Otis as the technology continues to shrink. 
Courtesy Otis Elevator Company.

THE EVOLUTION OF ELEVATORS	
91
FIGURE 4  Elevator innovations in the late 20th century. Looking beyond the eleva-
tor shaft, remote service was introduced in the 1980s. In the 1990s space-saving linear 
magnetic motors (shown to the right along the counterweight rail) remove the need for 
an elevator machine room. The turn of the century ushers in machine-roomless (MRL) 
elevators with flat coated steel belts and other more sustainable technologies. Courtesy 
Otis Elevator Company.
Managing Power
Rotating machinery, whether powered by steam or electricity, and linear 
motors all require power. Careful management of that power is required for both 
the elevator system and the building system as a whole.
Innovations like the counterweight and two-to-one roping are advantageous 
because they require lower power. Reduced power consumption allows propulsion 
components to be smaller and more efficient, benefiting both the building owner 
and the architect in the long-term operational cost of the elevator and the build-
ing’s overall energy footprint. Linear motors may offer some benefits, but they 
require significantly higher amounts of power than traditional means (Janovský 
1999).
An elevator system’s power use, environmental impact, and sustainability 
must be considered in the context of the building system and the city itself. Recent 

92	
FRONTIERS OF ENGINEERING
innovations in battery-, solar-, and even hydrogen-powered elevators (Auditeau 
2007) are intended to help elevator systems coexist in the environment where 
they operate.3
Building Construction, Materials, and Use of Core Space
An elevator system must adapt to a building’s construction methods and 
materials (e.g., concrete, steel, timber). Steel construction in North America may 
yield different optimal configurations than concrete or prefabricated buildings in 
Asia. Advances in timber construction for sustainability or seismic advantage will 
require elevators to innovate along with the building material.
In addition, architects must consider a building’s core space (allocated to 
elevators, machine and utility rooms, ventilation shafts, and the like) and the 
percentage of rentable space consumed by an elevator system. Developments 
such as the ability to use multiple cars in a hoistway can optimize both core space 
use and traffic flow through a building, as explained below in the discussion of 
double-deck elevators.
THE PASSENGER EXPERIENCE AND HUMAN BEHAVIOR
Passenger experience is the art and science of matching the elevator expe-
rience to the expectations of the people riding the elevator. It is a true human-
machine interface that requires enhanced technology, an understanding of human 
behavior, and the smooth interaction between the two. A user-centered design 
approach helps to adapt beyond the functional “job to be done” in order to meet 
new social and emotional requirements.
Personal Expectations
One important dimension of this experience is ride quality. The quality of an 
elevator ride—the noise and vibration experienced by passengers—is another area 
where technology has progressed steadily to provide smoother and quieter rides.
Social, circumstantial, and ethnographic differences, however, are associated 
with different expectations of what constitutes a “good ride.” Residential passen-
gers may think of the elevator as an extension of their living space. Hospitality 
passengers may want their visit to be better than their home. Commercial pas-
sengers may simply expect an efficient and secure journey that does not impinge 
on their valuable time. Passengers in New York City may want to feel the rush of 
moving quickly up the building. Passengers in Tokyo may look for the experience 
3   Also see “GeN2 Switch” brochure and information from the Otis Elevator Company (www.otis.
com/site/lb/Pages/Gen2-Switch.aspx).

THE EVOLUTION OF ELEVATORS	
93
of leaving one space, entering the elevator, and a moment later having the doors 
open in an entirely new space with little physical feeling of movement.
Technological Enhancements
For much of the early history of elevators, the experience was simple and 
very personal. Passengers would communicate directly with elevator operators 
who guided traffic, opened and closed doors, and directed the movement of the 
elevator car.
Elevator buttons were introduced in 1892, electronic signal control in 1924, 
automatic doors in 1948, and in 1950 the first operatorless elevator was installed 
at the Atlantic Refining Building in Dallas. Full automatic control and autotronic 
supervision and operation followed in 1962, and elevator efficiency has steadily 
increased in other ways.
Yet questions associated with personal interaction remain. Where is the 
passenger in relation to the elevator? Is the passenger ready to ride or leave the 
elevator? Is the passenger allowed to go to his desired destination? How does 
the machine interact with the passenger to communicate valuable information? 
Integration of the Two
Many of the challenges in modern passenger experience involve providing 
intuitive interactions and behavior solutions, and these can largely be achieved 
through new technologies and the application of connected and Internet of Things 
(IoT) technologies from other industries (Gulan et al. 2016). Digital interaction 
technology such as smartphones, wearables, video analytics, and other sensors, 
as well as advances in physical-human interfaces (e.g., touchscreens instead of 
buttons), will greatly improve intuitive behavior.
Technologies can be combined and introduced to lower anxiety and increase 
convenience and efficiency. Ensuring that passengers feel safe, trust equipment 
reliability, reduce or eliminate their wait time, get to their destination faster, and 
travel in a secure, comfortable, personalized space is of paramount importance to 
elevator technology well beyond the early physics-based problems.
CHALLENGES OF MEGATALL BUILDINGS
The growing height of buildings and the desire for people to live and work 
at higher altitudes amplify all the challenges discussed.
•	
Propulsion systems must be devised to carry increasing duty loads of 
­passengers and cargos, yet fairly quickly in high-rise buildings the com-
bined weight of the ropes and suspension components outweighs the 
desired movable mass. 

94	
FRONTIERS OF ENGINEERING
•	
Safety and braking technology that works well at low speeds must com-
bat increasingly high forces, thermal loads, and more demanding friction 
environments. 
•	
Physically moving larger and larger elevator machinery to the top of the 
building during construction and providing power to those machines 
throughout the life of the building are monumental challenges for both 
the elevator and the building itself. 
All the challenges in elevator design, from ride quality to seismic concerns, 
must be considered and optimized, in addition to new, unique challenges such as 
building sway due to wind. Challenges to the passenger experience (e.g., com-
fort, convenience, dispatching, traffic flow) also increase dramatically with taller 
buildings.
Automated Destination Dispatching
Tall buildings and their operators must accommodate the need to efficiently 
move large numbers of people. With megatall buildings, passengers’ experience 
must be considered from the moment they enter the building, traverse the lobby, 
and approach the elevator system.
The potentially competing experiences of seamless elevator use and robust 
security must be balanced via access control. Effective integration of these aspects 
is demonstrated at 7 World Trade Center, where the presentation of credentials at 
lobby turnstiles automatically calls the elevator within milliseconds as passengers 
walk the 45 meters to board the elevator.
Elevator travel in very tall buildings can be enhanced by faster, smoother 
rides, but the demands on the propulsion system require that the journey be broken 
into two or more partial trips. Thus a passenger wishing to go to the 100th floor 
might board an elevator in the lobby, exit into a “sky lobby” at the 50th floor, and 
board a different elevator to complete the trip to the 100th floor. One or more of 
these momentary pauses can delay arrival at the destination floor and increase 
confusion for the passenger.
Destination dispatching systems were introduced at the turn of the 21st cen-
tury largely to increase building efficiency and improve traffic flow. They have 
mathematical advantages over traditional up/down dispatching in taller buildings. 
Because the passenger enters the final destination (“floor 72”) on the building 
landing, rather than entering first an “up” call and then “floor 72” in the elevator 
cab, the dispatching algorithms can intelligently group passengers, route them to 
the appropriate car, and improve the building’s dispatching efficiency.
In addition, the elevator of the not-too-distant future will be able to automati-
cally recognize individuals, call the elevator, and adapt to where they are going 
in the building from day to day and hour by hour. 

THE EVOLUTION OF ELEVATORS	
95
Double-Deck and Multiple Elevators
Megatall building lobbies and their layout must accommodate both the 
natural flow of people and the desired outcomes of the architects and elevator 
designers. Double-deck elevators4 appeared in 1931, enabling the transport of 
significantly more people in a single elevator shaft (Figure 5). Double-deck and 
super-double-deck elevators (where two cars travel together but can move up to 
2 meters independently to accommodate floor height differences) may be used to 
move larger populations throughout buildings, but they can also be used to seg-
ment populations and ferry people to different locations in the building. 
The introduction of multiple cars in elevator hoistways provides a dramatic 
change to the experience of riding an elevator, mandating changes to how eleva-
tors communicate with individuals who become more like the passengers of 
vertical trains.
Evacuation 
Evacuation and egress of megatall buildings is of special concern. Historical 
practice for evacuating any building mandates the use of stairwells for safe evacu-
ation. With increasingly tall buildings and the need to move larger numbers of 
people, the use of elevators for evacuation is preferable to stairs or refuge spaces. 
Newer versions of the International Building Code (IBC) provide incentives for 
using elevators in an occupant evacuation operation for any building over 420 feet 
tall (128 meters or roughly 38 floors; NEII 2016).
CONCLUSION
The Internet of Things, advances in connectivity, ubiquitous smartphones, 
and other new digital technologies offer enormous opportunities for interpersonal 
communication and improvements in myriad dimensions of urban life, including 
people’s vertical movement in increasingly towering structures for living and 
working.
Megatall buildings amplify the challenges in all aspects of elevator design 
for both technology and passenger experience. The goal of vertical transportation 
systems in megatall buildings should be to provide a natural interaction with the 
building ecosystem for a safe, efficient, convenient, and personalized passenger 
experience, balancing advances in elevator and building performance to provide 
a delightful ride every time.
4   Two elevator cars attached to the same frame move together, the bottom car serving odd-numbered 
floors and the upper car even-numbered floors.

96	
FRONTIERS OF ENGINEERING
FIGURE 5  (Left) Most elevators are a single-deck configuration: one car serves all the 
floors for a given hoistway. (Center) High-rise buildings that require efficient flow of large 
numbers of people may use a double-deck car: two linked elevator cars move together, 
the top one stopping at the even-numbered floors and the lower one at the odd-numbered 
floors. (Right) Super-double-deck cars accommodate buildings with different floor heights 
(e.g., an entrance lobby with a higher ceiling) and heavy passenger traffic: the two cars 
travel together but can move up to 2 meters independently via a pantograph scissor-like 
device between them. Courtesy Otis Elevator Company.

THE EVOLUTION OF ELEVATORS	
97
REFERENCES
Auditeau P. 2007. The hydrogen elevator, a world first by Otis in Gien. Synoptos news brief, July 5. 
http://newsbrief.synoptos.com/fileuploads/L’ascenseur_%C3%A0_hydrog%C3%A8ne_EN.pdf.
Christensen CM. 2011. The Innovator’s Dilemma: The Revolutionary Book That Will Change the 
Way You Do Business. New York: Harper Business.
Gavois J. 1983. Going Up: An Informal History of the Elevator from the Pyramids to the Present, 1st 
ed. Farmington CT: Otis Elevator Company.
Goodwin J. 2001. Otis: Giving Rise to the Modern City, 1st ed. Chicago: Ivan R. Dee.
Gulan B, Peterson E, Costabile R, Tang J. 2016. “Informative Design” – Personalized Elevators in 
the Information Age. Proceedings of the Council of Tall Buildings and Urban Habitat (CT-
BUH) Conference on Cities to Megacities: Shaping Dense Vertical Urbanism, October 16–21, 
Hong Kong. http://global.ctbuh.org/resources/papers/download/2991-informative-design-
personalized-elevators-in-the-information-age.pdf.
Janovský L. 1999. Elevator Mechanical Design, 3rd ed. Mobile AL: Elevator World.
NEII [National Elevator Industry, Inc.]. 2016. Occupant Evacuation Operation. The Insider, May 18. 
http://www.neii.org/insider/editions/20160518.pdf.


Supertall Timber:  
Functional Natural Materials 
for High-Rise Structures
Michael H. Ramage
University of Cambridge
Wood and wood products have been used as building materials since before 
recorded history, but the full potential of timber and other plants as building 
materials has not yet been realized. 
Engineered timber materials, among them cross-laminated timber (CLT) and 
laminated veneer lumber (LVL), have enabled architects and engineers to design 
and build larger and larger timber buildings. The tallest is Brock ­Commons, a 
55-meter, 18-story student dormitory completed in 2016 at the University of ­British 
Columbia. Before that, the tallest was Treet (“tree” in Norwegian), a 53-meter, 
14-story condominium completed in 2015 in Bergen, Norway (Figure 1). Brock 
Commons has two concrete cores, while Treet is a fully timber structure, so each 
may be the tallest of its type (Foster et al. 2016). 
The scale of these contemporary buildings is significant, as the first metal-
framed skyscraper, William Le Baron Jenney’s Home Insurance Building in 
­Chicago, was 55 meters tall when completed in 1891, and 1931 saw the comple-
tion of the Empire State Building in New York City, at 381 meters. 
Innovation in natural materials, design, and construction may allow a simi-
lar increase in the height of timber skyscrapers. And the use of natural materials 
instead of steel and concrete in taller and larger buildings can reduce carbon 
emissions. Furthermore, CLT construction requires only about 30 m3 for an apart-
ment for two people. Using wood from only 30 percent of Europe’s managed 
forests with current practices, the entire population of Europe could be housed in 
perpetuity, even assuming the entire housing stock was renewed every 50 years 
(Ramage et al. 2017a).
99

100	
FRONTIERS OF ENGINEERING
FIGURE 1  Treet, a 14-story apartment building in Bergen, Norway, rises 52.8 meters and 
is made of cross-laminated and glued laminated timber. 

SUPERTALL TIMBER	
101
BACKGROUND
Timber has exceptional properties for building, many of which have been 
overlooked in the construction of ever-taller buildings in the past century. 
Advances in biological knowledge, engineering of plant-based materials, and 
interest in renewable construction are converging to create new possibilities for 
materials and allow for larger, taller, and more natural engineered wood buildings 
(Green 2012; Ramage et al. 2017a).1 
There is also competition in the building industry to construct the tallest 
timber tower. Height increases are currently incremental, but through a combina-
tion of theoretical design and physical testing, the viability of timber buildings 
can be demonstrated at much greater heights than previously possible (Ramage 
et al. 2017b). 
By pushing the limits of theoretical designs into the realm of the supertall2—
and sometimes beyond that which is feasible using current materials and construc-
tion technologies—our research sets out the requirements for the next generation 
of engineered plant-based materials. Research and the design and construction of 
contemporary large-scale timber buildings together further the architectural and 
structural engineering knowledge necessary to make tall timber buildings a reality. 
Materials science has advanced the industrial production of steel and ­reinforced 
concrete since the mid-19th century. The materials science of natural materials is 
less well understood, but the use of biofuels has helped drive fundamental research 
on the makeup of plant cells and their constituent parts. 
Improved information about how to break down plants into useful com-
ponents can also enhance understanding of their underlying properties. As an 
example, the model plant Arabidopsis thaliana, whose genome is well defined 
and editable, is essentially the mouse of plant science. Through biochemistry, it 
can be grown with lignin-depleted cells for studies of the role of lignin in giving 
plant cells their characteristic properties. In Arabidopsis, lignin appears to help 
control the way cells move past each other as they are pulled apart in tensile tests. 
With better knowledge of how the elements of cell walls contribute to the 
properties of plants and forest products, it may be possible to breed or geneti-
cally engineer plants with specific functional properties that are more favorable 
to construction.
CURRENT DEVELOPMENTS AND APPLICATIONS
Novel properties in trees may give rise to a new class of natural materials, but 
engineered timber products on the market are already giving designers around the 
1  Also see the 2013 technical report of the SOM Timber Tower Research Project, available at http://
www.som.com/ideas/research/timber_tower_research_project.
2  Supertall buildings are 300–600 meters. For reference, the original 110-floor World Trade Towers 
in New York were just over 540 meters, and the Sears Tower in Chicago is 442 meters.

102	
FRONTIERS OF ENGINEERING
world opportunities to innovate with large-scale construction. CLT can be used 
much like slabs of concrete in walls and floors, and glue-laminated timber and 
LVL can substitute for steel or concrete columns and beams. All can be used with 
existing modes of construction. 
But there are limitations. For example, platform construction with CLT is 
limited by the perpendicular-to-grain crushing of panels at floor junctions, a 
phenomenon that is difficult to overcome above 10 stories or so. And although 
the axial strength of some hardwood LVL in compression and tension is suf-
ficient to engineer very large buildings, the ability to transfer tensile loads that 
can be carried by the full section from one element of timber to another remains 
to be determined. 
Our supertall timber project, in which we have designed wooden skyscrapers 
(Figure 2), shows the viability of commercial and residential buildings at a new 
scale in timber, using components and materials that are commercially available 
FIGURE 2  Maquette of River Beech Tower proposed for Chicago. The 80-story residential 
skyscraper is a design collaboration of Perkins+Will, Thornton Thomasetti, and Cambridge 
University Centre for Natural Material Innovation. 

SUPERTALL TIMBER	
103
today. Our design and research demonstrate the architectural, engineering, and eco-
nomic possibilities that stem from thinking about traditional materials in new ways.
OTHER PLANTS
A variety of plants may add to the materials available. Bamboo has excellent 
properties in tension and compression, and is among the world’s fastest growing 
plants—it can be harvested every few years. In addition, a number of processing 
methods exist to turn the raw product into an engineered material (Sharma et al. 
2015), and more are being developed. Engineered bamboo looks like wood and 
is crafted with woodworking equipment. It behaves differently as a structural 
­material (Reynolds et al. 2016), so new engineering codes are necessary. 
Other crops, such as flax and hemp, are being used to make structural com-
posites for automotive and industrial design and at the same time engineered to 
deliver improved properties. All of these crops are available at a scale necessary 
for construction. 
ADVANTAGES
Construction with timber has many advantages, not least for the environment. 
•	
Timber is the only major building material that can be grown, and the sus-
tainable harvest of lumber is vast—crop-planted forests around the world 
are expanding. 
•	
Timber is five times lighter than concrete, so to construct an equivalent 
volume of building, only one timber truckload is needed, as compared 
to five concrete mixers. 
•	
No formwork needs to be brought to site (and removed) and no reinforc-
ing steel is necessary. The steel in timber connections is negligible. We 
roughly redesigned the Treet building in reinforced concrete for com-
parison and discovered that it would have five times as much steel in it 
as the timber building. 
•	
The savings multiplier on construction truck traffic can be as high as 
eight.3 These savings have implications for today’s crowded metropo-
lises: smaller foundations, or indeed no new ones, as the existing foun-
dation for a demolished 10-story concrete building can hold a timber 
building three to four times as tall, with quieter construction and smaller 
cranes. 
•	
Contemporary timber buildings are largely prefabricated for component 
assembly, meaning they are quick to erect accurately on site and tend 
3  Personal communication February 2, 2017, with Ralph Austin of Seagate Structures, which has 
built a number of large-scale timber buildings in Vancouver.

104	
FRONTIERS OF ENGINEERING
to be naturally draft-proof and efficient, saving time and energy and 
improving overall quality. 
CONCLUSION
As manufacturers, architects, engineers, and contractors learn to expand 
what they can do with large-scale engineered timber, a new architecture of 21st 
century timber will arise, drawing on a rich tradition of centuries of wooden 
construction while reaching higher to embrace the full potential of innovation 
and construction with natural materials.
ACKNOWLEDGMENT
This research is supported by EPSRC Grant EP/M01679X/1 and by a 
­Leverhulme Trust Programme Grant.
REFERENCES
Foster RM, Reynolds TPS, Ramage MH. 2016. Proposal for defining a tall timber building. Journal 
of Structural Engineering 142(12):1943–1954.
Green M. 2012. The Case for Tall Wood Buildings. http://cwc.ca/wp-content/uploads/publications-
Tall-Wood.pdf.
Ramage MH, Burridge H, Busse-Wicher M, Fereday G, Reynolds T, Shah DU, Wu G, Yu L, Fleming 
RP, Densley-Tingley D, and 4 others. 2017a. The wood from the trees: The use of timber in 
construction. Renewable and Sustainable Energy Reviews 68(1):333–359.
Ramage MH, Foster RM, Smith S, Flanagan K, Bakker R. 2017b. Super tall timber: Design research 
for the next generation of natural structure. Journal of Architecture 22(1):104–122. 
Reynolds T, Sharma B, Harries K, Ramage M. 2016. Dowelled structural connections in laminated 
bamboo and timber. Composites Part B: Engineering 90:232–240. 
Sharma B, Gatóo A, Bock M, Ramage MH. 2015. Engineered bamboo for structural applications. 
Journal of Construction and Building Materials 81:66–73.

For the past 12 years, Jenny Sabin Studio and the Sabin Lab (based at ­Cornell 
University’s College of Architecture, Art, and Planning) have engaged in work at 
the forefront of a new direction for 21st century architectural research practice—
one that investigates the intersections of architecture and science, and applies 
insights and theories from biology and computation to the design of material 
structures that are adaptive, interactive, and resilient.1
This paper describes multidirectional and multidisciplinary investigations 
shaping the future trajectories of these material innovations and technologies for 
architecture. The work aims to advance materials research and digital fabrication 
across disciplines to effect pragmatic change in the economical, ecological, and 
cultural production of contemporary architecture.
BACKGROUND
Buildings account for nearly 40 percent of CO2 emissions in the United 
States, with the remainder primarily from the industrial and transportation sec-
tors.2 Most contemporary sustainable approaches to reduce these emissions offer 
technological solutions through sanctioned rating systems such as LEED, a rating 
system launched by the US Green Building Council for both new construction 
and renovations of existing buildings. While these measures adequately address 
1 Portions of this paper have been adapted from Sabin (2015).
 1 See Sabin and Jones (2017), a book on design research across disciplines through the lens of 
LabStudio, cofounded by Sabin, an architectural designer, and Jones, a molecular and cell biologist.
2   See “Benefits of Green Building,” https://www.usgbc.org/articles/green-building-facts.
Applications of Insights from 
Biology and Mathematics to the 
Design of Material Structures 
Jenny E. Sabin
Cornell University
105

106	
FRONTIERS OF ENGINEERING
resource consumption in buildings, they do not address the systemic ecology of 
the built environment over the long term.
What are ways to rethink conceptual approaches to sustainability in architec-
ture? What design research models are available to address these questions and 
thus shape future innovations and applications in architecture?
RECENT PIONEERING RESEARCH
Forward-thinking research in building materials includes that of Matthias 
Kohler’s group at ETH Zürich.3 In the group’s work with industrial robots Kohler 
coined the term digital materiality, which enables real-time feedback with mate-
rial constraints through robotic digital fabrication processes. His more recently 
coined term, computational contextualism, refers to how sensors operate to inte-
grate environmental feedback in a robust design process for the built environment.
Ronald Rael and Virginia San Fratello of Emerging Objects (www.emergin-
gobjects.com) claim that all materials start as powder or end in dust. Their 
3D-printed work integrates bits of data and particles of light to transform this dust 
into nonstandard objects and products for future building blocks, challenging the 
status quo of rapid prototyping by designing the material itself.
Researchers such as Rob Shepherd and Maria Paz Gutierrez explore archi-
tecture applications in programmable matter and materials science. Shepherd’s 
work on actuators, sensors, displays, and additive manufacturing protocols for 
soft wearable robots underscores the importance of iterative complex feedback 
between material and mechanical design in the development of these techniques 
and wearables.
In parallel, the work of the BIOMS group (Bio Input onto Material Systems), 
directed by Gutierrez at the University of California, Berkeley, takes direct inspi-
ration from skins found in nature. Repurposing the textile as an important archi-
tectural element, the BIOMS multifunctional membrane features an integrative 
sensor and actuator system that not only is designed to answer to many functions 
through what Gutierrez calls the “synergistic optimization of heat, light, and 
humidity transfer” but also is a closed loop system.4 It therefore does not require 
energy input through mechanical actuators, sensors, and a mainframe.
And through select research projects at the Institute for Computational Design 
and Construction at the University of Stuttgart, Achim Menges argues that tech-
nological innovation across multiple disciplines suggests that design computation 
is no longer limited to the binary world of the digital, but is now interfacing with 
3   As discussed at the Matter Design Computation Symposium: The Art of Building from Nano to 
Macro, Cornell AAP Preston Thomas Memorial Lecture Series, March 10–11, 2017.
4   As stated in an unpublished text, “Multifunctional Building Membrane: Self-Active Cells, Not 
Blocks,” M.P. Gutierrez (BIOMS director/lead) with L.P. Lee (BioPoets director), the UC Berkeley 
BIOMS team (C. Irby, K. Sobolski, P. Hernandez, D. Campbell, P. Suen), and B. Kim (BioPoets team).

APPLICATIONS OF INSIGHTS TO THE DESIGN OF MATERIAL STRUCTURES	
107
the complex realm of the physical. How is this innovative and forward-thinking 
work leveraged and funded?
FEDERAL SUPPORT FOR INNOVATION
In 2010 the National Science Foundation (NSF), under the Emerging ­Frontiers 
for Research Innovation (EFRI) Science in Energy and Environmental Design 
(SEED) umbrella, solicited proposals for transdisciplinary research teams to 
engage the problem of sustainability in terms of building energy use and its impacts 
on the built environment.
In an unprecedented occurrence, applicant teams were to include architects 
and, importantly, AIA licensure was not required. This opened up opportunities 
for both licensed architects and architectural designers engaged in practice and 
core academic design research to apply with collaborative teams across academia, 
practice, and industry. Successful project proposals required a radical departure 
from traditional research and design models in architecture and science, with a 
move toward hybrid, transdisciplinary concepts and new models for collaboration.
DRAWING ON NATURE TO INFORM ARCHITECTURE
In the Sabin Lab we ask: How might architecture address issues of ecology 
and sustainability so that buildings behave more like organisms in their built 
environments? We are interested in studying the human body for design models 
that give rise to new ways of thinking about adaptation, change, and performance 
in architecture.
Our expertise and interests focus on the study of natural and artificial ecology 
and design, especially in the realm of nonlinear biological systems and program-
mable materials that use minimum energy with maximum effect. Seminal points 
of reference for the work include matrix biology, materials science, bioengineer-
ing, and mathematics through the filter of crafts-based media such as textiles and 
ceramics, with advanced digital fabrication protocols including robotic fabrication 
and 3D printing.
Our collaborative work looks to nature, specifically cellular biology, for an 
analogous deep organicity of interrelated parts, material components, and building 
ecology. Generative design techniques emerge with direct references to natural 
systems such as cellular networking behavior and models of structural color found 
in the wings of the blue Morpho butterfly or the feathers of hummingbirds. We 
do not simply mimic these exquisite systems and structures, but instead focus 
on modeling and simulating behavior and processes through custom tools and 
methods that translate flexibility, adaptation, growth, and complexity into applied 
architectural prototypes and adaptive materials systems. Our work offers novel 
possibilities for redefining architecture in terms of ecological design and digital 
fabrication.

108	
FRONTIERS OF ENGINEERING
RESEARCH TO CREATE ADAPTIVE BUILDING SKINS
Since the start in fall 2010 of our NSF SEED project, Energy Minimization 
via Multi-Scalar Architectures: From Cell Contractility to Sensing Materials to 
Adaptive Building Skins, my colleague Andrew Lucia and I (as co-PI) have led 
a team of architects, graduate architecture students, and researchers in the inves-
tigation of biologically informed design. We use the visualization of complex 
datasets, digital fabrication, and the production of experimental material systems 
for prototype speculations of adaptive building skins, designated eSkin, at the 
macrobuilding scale (Figure 1). The full team, led by principal investigator Shu 
Yang, is engaged in rigorous scientific research at the core of ecological building 
materials and design.
The work described here is a subset of ongoing transdisciplinary research 
spanning cell biology, materials science, electrical and systems engineering, and 
architecture. The eSkin project applies these disciplines to the design and engi-
neering of responsive materials and sensors (Sabin et al. 2014), operating on a 
multiyear research plan in three phases:
FIGURE 1  eSkin interactive prototype. Indium tin oxide (ITO)–treated glass cells with 
voltage-controlled nanoparticle solution, housed on a custom-built PCB substrate and 
controlled locally via ambient sensing nodes. © Sabin Design Lab, Cornell University; 
Shu Yang Group, University of Pennsylvania; Jan Van der Spiegel and Nader Engheta, 
University of Pennsylvania.

APPLICATIONS OF INSIGHTS TO THE DESIGN OF MATERIAL STRUCTURES	
109
1.	 production of catalogues of visualization and simulation tools to discover 
new behaviors in geometry and matter;
2.	 exploration of the material and ecological potentials of these tools using 
experimental structures and material systems created through digital 
fabrication; and
3.	 generation of scientifically based, design-oriented applications in con-
temporary architecture practice for adaptive building skins and material 
assemblies.
The goal of the eSkin project is to explore materiality from nano to macro 
scales based on an understanding of nonlinear, dynamic human cell behaviors 
on geometrically defined substrates. To achieve this, human smooth muscle cells 
are plated on polymer substrates at a micro scale. Sensors and imagers are being 
designed and engineered to capture material and environmental changes based on 
manipulations by the cells, such as changes in color, transparency, polarity, and 
pattern (Lee et al. 2014; Li et al. 2012).
In recent eSkin prototypes, the team is exploring dynamic switching between 
opaque, transparent, and highly colorful components assembled in a single full-
scale prototypical building façade unit (Figure 1). Specifically, the team is work-
ing with structural color, where physical structures in the form of particles interact 
with light to produce a particular color.
Silica colloidal nanoparticles dispersed in an organic medium (solvent) are 
sandwiched between two transparent conductively treated indium tin oxide (ITO) 
pieces of glass, housed in an assembly of three laser-cut plexiglass frames. The 
light reflected from the ordered structure (depending on the particle size, distance, 
and reflective index contrast between the silica nanoparticles and the organic 
medium) is of a specific wavelength.
When a voltage is applied to the particulate solution, the surface charge of 
the particles is altered, changing both the distance between the particles and the 
color. At each intersection between the color cells, a sensor based on shifts in light 
intensity levels actuates voltage change between the adjacent color cells. Thus 
when a finger, hand, or figure passes by a sensor, a detected shift in light intensity 
triggers a small voltage shift across the ITO component, reorganizing the distribu-
tion of particles in the solution, ultimately affecting the reflected appearance of 
color from the nanoparticle solution (Sabin et al. 2014; Sabin and Jones 2017).
The relevance of this particular prototype and the eSkin project to megatall 
buildings is primarily in building façade design. For example, in many glass-clad 
megatall buildings, a glazing treatment known as ceramic frit patterning is used 
to minimize solar heat gain and energy loss without obstructing the occupants’ 
view. These treatments are effective but permanently static.
We envision and have demonstrated a strategy for dynamic and adaptive 
building skin treatments that behave similarly to a standard frit pattern, but change 
throughout the day and night and in response to extreme shifts in climate and local 

110	
FRONTIERS OF ENGINEERING
environment. We propose to integrate eSkin in either existing building façade 
construction to enhance energy saving or in new megatall building façade design.
CONCLUSION
Through the eSkin project, insights into how cells can modify their immedi-
ate extracellular microenvironment are investigated and applied to the design and 
engineering of highly aesthetic passive materials, sensors, and imagers that will be 
integrated in responsive building skins. Such skins will enable buildings to adapt 
to external changes in temperature and internal solar heat gains to better regulate 
energy consumption and loss.
Our project addresses energy minimization at multiple scales of architecture 
by working toward challenging goals such as those put forward by the US DOE.5 
We hope that our interdisciplinary work will not only redefine research and design 
through collaboration but also address social, environmental, and technological 
dimensions that ultimately enhance building design and the built environment.
REFERENCES
Lee E, Zhang M, Cho Y, Cui Y, Van der Spiegel J, Engheta N, Yang S. 2014. Tilted pillars on wrinkled 
elastomers as a reversibly tunable optical window. Advanced Materials 26(24):4127–4133. 
Li J, Shim J, Overvelde JTB, Deng J, Zhu X, Bertoldi K, Yang S. 2012. Switching reflective color to 
transparency in photonic membranes via pattern transformation and shape memory effect. Soft 
Matter 8(40):10322–10328.
Sabin J. 2015. Transformative research practice: Architectural affordances and crisis. Journal of 
Architectural Education 69(1):63–71.
Sabin J, Jones PL. 2017. LabStudio: Design Research Between Architecture and Biology. London & 
New York: Routledge Taylor and Francis.
Sabin JE, Lucia A, Ott G, Wang S. 2014. Prototyping interactive nonlinear nano-to-micro-scaled 
material properties and effects at the human scale. Proceedings of the Symposium on Simulation 
for Architecture and Urban Design (SimAUD), April 13–16, Tampa.
5   See https://www.energy.gov/eere/buildings/commercial-buildings-integration-0. 

Appendixes


Contributors
Khurram Afridi is an assistant professor of electrical, computer, and energy 
engineering and the Goh Faculty Fellow at the University of Colorado Boulder. 
His research focuses on power electronics and energy systems that incorporate 
power electronic controls. His work includes ultra-high-efficiency compact 
grid-interfaced power converters, long-life high-energy-density electrolytic-free 
energy buffers, radio frequency power electronics for ultra-high power density 
energy conversion, and wireless power transfer.
Mariana Bertoni is an assistant professor of electrical, computer, and energy engi-
neering at Arizona State University. Her research focuses on defect engineering of 
materials for energy conversion and the underlying physical mechanisms that ­govern 
degradation, charge transport, and collection. She specializes in advanced correla-
tive characterization using X-ray probes and multidimensional image analysis.
Rajan Bhattacharyya is a senior research engineer at HRL Laboratories, where 
his work focuses on how humans process information and interact with the envi-
ronment with the goal of developing smarter autonomous systems, enhancing 
human performance, and creating novel processing systems. His research involves 
the development of large-scale, neuro-biologically and behaviorally validated 
neural and cognitive models, experimental work measuring neural activity (EEG, 
fMRI), and neuro-inspired algorithms for resilient autonomous systems, dexterous 
robots, and threat warning applications.
Bouchra Bouqata is a senior analytics product manager and senior scientist at GE 
Renewable Energy and GE Global Research. She leads programs in large-scale, 
113

114	
FRONTIERS OF ENGINEERING
automated-intelligent Big Data advanced analytics; the industrial Internet; prog-
nostics and health management; remote and online monitoring; and diagnostics.
Jordan Boyd-Graber is an associate professor of computer science at the Univer-
sity of Maryland, where he studies human-in-the-loop machine learning applied 
to natural language. His research focuses on making machine learning more use-
ful, more interpretable, and able to learn and interact from humans. Applications 
include having machines that can sift through decades of documents; discover 
when individuals lie, reframe, or change the topic in a conversation; and compete 
against humans in games that are based in natural language. 
Robert Braun is dean of engineering and applied science at the University of 
Colorado Boulder. His research focuses on planetary entry systems, hypersonics, 
landing systems design, and multidisciplinary optimization.
Emma Brunskill is an assistant professor of computer science at Carnegie ­Mellon 
University. Her work focuses on reinforcement learning, machine learning, 
sequential decisionmaking, and human-in-the-loop systems to create automated 
artificial intelligence agents that help people reach their goals.
Jose Carmena is a professor of electrical engineering and computer sciences at 
the University of California, Berkeley. His research program in neural engineer-
ing and systems neuroscience aims to understand the neural basis of sensorimotor 
learning and control and to build the science and engineering base that will allow 
the creation of reliable neuroprosthetic systems for the severely disabled.
Katherine Dykes is a senior engineer at the National Renewable Energy Labora-
tory, where she leads a group that seeks to integrate wind turbine, plant engineering, 
and cost models to enable full-system analysis and to apply a variety of advanced 
analysis methods to the study of wind plant system performance and cost.
Azita Emami is the Andrew and Peggy Cherng Professor of Electrical Engi-
neering and Medical Engineering at the California Institute of Technology. Her 
research is in integrated circuits and systems, high-speed communication systems, 
silicon photonics, and wearable and implantable devices for neural recording, 
stimulation, sensing, and drug delivery.
Maria-Paz Gutierrez is an associate professor of architecture at the University of 
California, Berkeley, where she focuses on exploring the biophysical and cultural 
implications of functional natural materials and agricultural waste through multi-
scale additive manufacturing. She founded BIOMS, an interdisciplinary research 
initiative that brings together architecture and science to integrate principles of 
design and biophysics from the nanoscale to the building scale.

CONTRIBUTORS	
115
Xue Han is an assistant professor of biomedical engineering at Boston University, 
where she leads a neuroengineering lab that focuses on developing radical new 
genetic, molecular, and optical neurotechnologies and application protocols for 
understanding disease mechanisms with the goal of designing next-generation 
neurotechnologies to treat neurological and psychiatric disorders. 
Tim Heidel is the deputy chief scientist at the National Rural Electric Coopera-
tive Association. His research focus is on the analysis, control, and optimization 
of electric power systems, especially in the context of high penetrations of dis-
tributed energy resources and renewable generation. He is also involved in grid 
cybersecurity.
Konrad Kording is a Penn Integrates Knowledge Professor of Bioengineering at 
the University of Pennsylvania. His group uses data science to understand brain 
function, improve personalized medicine, collaborate with clinicians to diagnose 
diseases based on mobile phone data, and understand the careers of professors 
through the analysis of large datasets to test new models and better understand 
complex problems in bioengineering, neuroscience, and beyond.
Ellis Meng is a professor and department chair of biomedical engineering at the 
University of Southern California. Her research interests include microelectro-
mechanical systems (MEMS), microsensors and actuators, micromachining and 
microfabrication, microfluidics, polymer MEMS, flexible devices, implantable 
devices, medical MEMS, wireless power and data telemetry for implants, and 
neural engineering. 
Jeremy Munday is an associate professor of electrical and computer engineering 
at the University of Maryland, where his focus is on demonstrating new technolo-
gies based on novel physics and engineering. His research interests range from 
solar energy, optics, and plasmonics to quantum electrodynamic phenomena (such 
as the Casimir effect), solar sails, and novel energy conversion processes.
Stephen Nichols is associate director of the passenger experience segment at 
the Otis Elevator Company. His team works at the intersection of human experi-
ence and people-centered-design with vertical transportation technology and the 
building ecosystem. Products and concepts focus on digital interaction, human 
interface, and intuitive behavior with work spanning the disciplines of engineer-
ing, marketing, and information technology. 
David Parekh is the corporate vice president of research and the director of 
the United Technologies Research Center (UTRC), providing global leadership 
for United Technologies Corporation’s (UTC) central research organization. In 
this role, he develops technology strategies in anticipation of future trends and 

116	
FRONTIERS OF ENGINEERING
aligns the Research Center’s breakthrough innovations for transition to UTC’s 
business units to enable their growth. He also leads UTC’s Innovation Business 
Development group whose mission is to monetize UTC technology and intellec-
tual ­property in non-core markets and to develop business innovations for core 
markets.
Michael Ramage is an architectural engineer and senior lecturer of architecture 
at the University of Cambridge. His research focuses on developing low-energy 
structural materials and systems in masonry, better housing in the developing 
world, and large-scale, high-rise buildings in engineered timber and bamboo 
through natural material innovation. 
Jenny Sabin is the Arthur L. and Isabel B. Wiesenberger Associate ­Professor of 
Architecture at Cornell University, where she investigates the inter­sections of archi-
tecture and science and applies insights and theories from biology, emerging 
technologies, and mathematics to the design of material structures for application 
at the building scale. She is principal of Jenny Sabin Studio, an experimental 
architectural design studio based in Ithaca and director of the Sabin Lab at Cornell 
AAP (­Architecture, Art, and Planning), a trans-disciplinary design research lab with 
specialization in computational design, data visualization, and digital fabrication.
Suchi Saria is an assistant professor of computer science at Johns Hopkins 
University. Her research spans machine learning, computational statistics, and 
their applications to domains where one has to draw inferences from observing 
a complex, real-world system evolve over time. Her focus is on Bayesian and 
probabilistic graphical modeling approaches to address challenges associated with 
modeling and prediction in real-world temporal systems. 
Maryam Shanechi is an assistant professor and the Viterbi Early Career Chair 
of Electrical Engineering at the University of Southern California. She works at 
the interface of control, machine-learning, and neuroscience to develop neuro-
technologies that improve the quality of care for millions of patients, including 
the development of brain-machine interfaces to restore movement in paralyzed 
patients, to automatically control unconsciousness under anesthesia, and to treat 
neuropsychiatric disorders through brain stimulation.
Marija Trcka is a technology sourcing specialist at United Technologies, where 
she disseminates cutting-edge research into industrial practice that facilitates fast 
and impactful energy retrofits in existing buildings, making a significant impact 
on worldwide carbon emissions. Her software tool seamlessly analyzes advanced 
building technologies and provides building managers with decision support met-
rics based on complex techno-economic analysis.

Participants
Sarah Absher
Front End Innovation Process 
Development Leader
Skin and Personal Care, Research & 
Development
Procter & Gamble
Khurram Afridi**
Assistant Professor
Department of Electrical, Computer, 
and Energy Engineering
University of Colorado Boulder
James (Brad) Aimone
Principal Member of Technical Staff
Data-Driven and Neural Computing
Sandia National Laboratories
Adolph (Miller) Allen
Director, Distinguished Member of 
Technical Staff
Transistor and Interconnect Group/ 
Metal Deposition Products
Applied Materials
Elma Avdic
Director
EBU On-Highway Product Engineering
Cummins Inc.
Gregg Beckham
Group Leader
National Bioenergy Center
National Renewable Energy Laboratory
Julie Bert
Area Manager
Electronics, Materials, and Devices 
Lab
PARC, A Xerox Company
*Organizing Committee
**Speaker
117

118	
FRONTIERS OF ENGINEERING
Mariana Bertoni**
Assistant Professor
School of Electrical, Computer, and 
Energy Engineering
Arizona State University
Rajan Bhattacharyya*
Senior Research Engineer
Information and Systems Sciences 
Laboratory
HRL Laboratories
Griselda Bonilla
Senior Technical Staff Member and 
Senior Manager
Semiconductor Technology Research
IBM T.J. Watson Research Center
Bouchra Bouqata**
Senior Analytics Product Manager 
and Senior Scientist 
GE Renewable Energy
GE Global Research
Jordan Boyd-Graber**
Associate Professor
Department of Computer Science
University of Maryland
Danielle Braje
Assistant Group Leader
Quantum Information and Integrated 
Nanosystems Group
MIT Lincoln Laboratory
Robert Braun*
Dean
College of Engineering and Applied 
Science
University of Colorado Boulder
Kristen Brosnan
Technical Operations Leader
Metals Discipline
GE Global Research
Emma Brunskill**
Assistant Professor
Department of Computer Science
Carnegie Mellon University
Otger Campas
Assistant Professor and Mellichamp 
Chair in Systems Biology
Department of Mechanical Engineering
University of California, Santa Barbara
Liling Cao
Vice President
Forensics and Advanced Analytics
Thornton Tomasetti
John Gunnar Carlsson
Associate Professor
Department of Industrial and Systems 
Engineering
University of Southern California
Jose Carmena**
Professor
Department of Electrical Engineering 
and Computer Sciences
University of California, Berkeley
Nurcin Celik
Associate Professor
Department of Industrial Engineering
University of Miami
Vikas Chandra
Senior Principal Research Engineer
ARM

PARTICIPANTS	
119
Junho Cho
Member of Technical Staff
Optical Transmission Subsystems 
Department
Nokia Bell Labs
Jerry Chow
Manager, Experimental Quantum 
Computing
Research
IBM
Louis Christen
Director, Advanced Communications 
and Electronics
Applied Research and Technology 
Development
Northrop Grumman
Francesca D’Arcangelo
Technical Staff
Homeland Protection Systems
MIT Lincoln Laboratory
Katherine Davis
Assistant Professor
Department of Electrical and 
Computer Engineering
Texas A&M University
Ying Diao
Assistant Professor and Dow 
Chemical Faculty Scholar
Department of Chemical and 
Biomolecular Engineering
University of Illinois at 
Urbana-Champaign
Jonathan Dyer
Chief Engineer
Terra Bella (Skybox Imaging)
Google
Katherine Dykes*
Senior Engineer
National Wind Technology Center
National Renewable Energy Laboratory
Azita Emami**
Andrew and Peggy Cherng Professor
Departments of Electrical Engineering 
and Medical Engineering
California Institute of Technology
Randy Ewoldt
Associate Professor
Department of Mechanical Science 
and Engineering
University of Illinois at 
Urbana-Champaign
Matthew Facchine
Advanced Systems Architect
Advanced Concepts and Technology
Northrop Grumman
Anne Fischer
Program Manager
Defense Sciences Office
DARPA
Gregory Fritz
Principal Member of the Technical 
Staff
Materials Science and Engineering
Draper Laboratory
Cynthia Ginestra
Research Engineer
Long Range Research
Shell
Sidhant Gupta
Researcher
Microsoft Research NExT

120	
FRONTIERS OF ENGINEERING
Maria-Paz Gutierrez*
Associate Professor
Department of Architecture
University of California, Berkeley
Xue Han*
Assistant Professor
Department of Biomedical Engineering
Boston University
Tim Heidel**
Deputy Chief Scientist
National Rural Electric Cooperative 
Association
Florian Herrault
Senior Research Staff Engineer
Microelectronics Laboratory
HRL Laboratories
Laura Hiatt
Research Scientist
Information Technology Division
Naval Research Laboratory
David Hoelzle
Assistant Professor
Department of Mechanical and 
Aerospace Engineering
Ohio State University
Marcus Holzinger
Assistant Professor
Department of Aerospace Engineering
Georgia Institute of Technology
Kun Hu
Research Manager
Accelerated Discovery Lab
IBM
Anya Jones
Associate Professor
Department of Aerospace Engineering
University of Maryland
Amit Kanvinde
Professor and Chair
Department of Civil and 
Environmental Engineering
University of California, Davis
Sinan Keten
Associate Professor
Departments of Mechanical 
Engineering and Civil and 
Environmental Engineering
Northwestern University
Oleg Komogortsev
Associate Professor
Department of Computer Science and 
Engineering
Michigan State University
Konrad Kording**
Penn Integrates Knowledge Professor
Department of Bioengineering
University of Pennsylvania
Venkatesh Krishnan
Director, Product Management
Technology Licensing
Qualcomm
Ana Maria Kupresanin
Applied Statistics Group Leader
Engineering
Lawrence Livermore National 
Laboratory

PARTICIPANTS	
121
Duygu Kuzum
Assistant Professor
Department of Electrical and 
Computer Engineering
University of California, San Diego
Gabe Kwong
Assistant Professor
Wallace H. Coulter Department of 
Biomedical Engineering
Georgia Institute of Technology
Markita Landry
Assistant Professor
Department of Chemical and 
Biological Engineering
University of California, Berkeley
Alvin Lin
Master Engineer
Wireless Connectivity Combo
Broadcom
Erin MacDonald
Assistant Professor
Department of Mechanical Engineering
Stanford University
Jonathan Malen
Associate Professor
Department of Mechanical Engineering
Carnegie Mellon University
Schuyler Marsh
Chemical Engineering Consultant
Engineering Research and Technology
DuPont
Claude Matalanis
Principal Research Engineer
Thermal and Fluid Sciences
United Technologies Research Center
Ellis Meng**
Professor and Chair
Department of Biomedical Engineering
University of Southern California
Grace Metcalfe
Physicist
Sensors and Electron Devices 
Directorate
US Army Research Laboratory
Jeremy Munday*
Associate Professor
Department of Electrical and 
Computer Engineering
University of Maryland
Viswanath Nagarajan
Assistant Professor
Department of Industrial and 
Operations Engineering
University of Michigan
Abhijit Namjoshi
Application Development and 
Technical Services Leader
Polyurethanes
Dow Chemical Company
Osama Nayfeh
Engineer
Space and Naval Warfare Systems 
Center, Pacific
Caleb Nelson
Research Specialist
Corporate Research Laboratory
3M

122	
FRONTIERS OF ENGINEERING
Stephen Nichols**
Associate Director, Passenger 
Experience Segment
Global Engineering
Otis Elevator Company
Mira Olson
Associate Professor
Department of Civil, Architectural, 
and Environmental Engineering
Drexel University
William Osborn
Materials Research Engineer
Material Measurement Laboratory
National Institute of Standards and 
Technology
Carla Pereira
Senior Researcher
R&D - Process Technology
ExxonMobil Research and Engineering
Dimitrios Peroulis
Professor
Department of Electrical and 
Computer Engineering
Purdue University
Julie Pietrzak
Civil Engineer
Buildings and Facilities Division
STV
Michael Ramage**
Architectural Engineer and Senior 
Lecturer
Department of Architecture
University of Cambridge
Karthik Raman
Research Scientist
Google
Amanda Randles
Assistant Professor
Department of Biomedical Engineering
Duke University
Sujith Ravi
Staff Research Scientist, Technical 
Lead Manager, and Head of 
Graph Machine Learning Group
Google
Debora Rodrigues
Associate Professor
Department of Civil and 
Environmental Engineering
University of Houston
Tim Rupert
Associate Professor
Department of Mechanical and 
Aerospace Engineering
University of California, Irvine
Jenny Sabin**
Arthur L. and Isabel B. Wiesenberger 
Associate Professor
Department of Architecture
Cornell University
Dareen Salama
Director of Technical Services
Lehrer LLC
James Salvador
Staff Researcher, Energy Storage 
Materials
Chemical and Materials Systems Lab
GM Global Research and 
Development

PARTICIPANTS	
123
Kelly Sanders
Assistant Professor
Sonny Astani Department of Civil and 
Environmental Engineering
University of Southern California
Suchi Saria**
Assistant Professor
Department of Computer Science
Johns Hopkins University
Will Scott
Software Architect
Accessibility Technology and 
Innovation
IBM Research
Onome Scott-Emuakpor
Aerospace Engineer
Aerospace Systems Directorate
Air Force Research Laboratory
Maryam Shanechi*
Assistant Professor and Viterbi Early 
Career Chair
Department of Electrical Engineering
University of Southern California
Mikhail Shapiro
Assistant Professor
Department of Chemical Engineering
California Institute of Technology
Hadley Sikes
Associate Professor
Department of Chemical Engineering
Massachusetts Institute of Technology
Min-Sun Son
Manager
Biomedical Engineering
Exponent, Inc.
Wil Srubar
Assistant Professor
Department of Civil, Environmental, 
and Architectural Engineering
University of Colorado Boulder
Cui Tao
Associate Professor
School of Biomedical Informatics
University of Texas at Houston
Iris Tien
Assistant Professor
Department of Civil and 
Environmental Engineering
Georgia Institute of Technology
Marija Trcka*
Technology Sourcing Specialist
Innovation Business Development
United Technologies Corp.
Sara Tucker
LiDAR Staff Consultant
Systems Engineering
Ball Aerospace
Robert Visco
Lead Machinery Engineer
Operational Excellence Technical Team
Air Products and Chemicals
Helen Wang
Scientist
Altuglas
Arkema Inc.
Nora Wang
Engineer
Building Energy Systems – Energy 
and Environment Directorate
Pacific Northwest National Laboratory

124	
FRONTIERS OF ENGINEERING
Renee Wegrzyn
Program Manager
Biological Technologies Office
DARPA
Jennifer Wortman Vaughan
Senior Researcher
Microsoft
Xiaobo Yin
Assistant Professor
Department of Mechanical Engineering
University of Colorado Boulder
Yan Zhao
Principal Research Engineer
Energy Process Industry R&D
Air Products and Chemicals
Joshua Zide
Associate Professor
Department of Materials Science and 
Engineering
University of Delaware
Dinner Speaker
David Parekh
Corporate Vice President, Research 
and Director
United Technologies Research Center
United Technologies
Gregory J. Hayes
Chairman and Chief Executive Officer
United Technologies Corporation
J. Michael McQuade
Senior Vice President, Science and 
Technology 
United Technologies Corporation
Guests
William (Bill) Hayden
Vice President
The Grainger Foundation
Sohi Rastegar
Senior Advisor
Emerging Frontiers and 
Multidisciplinary Activities
Directorate for Engineering
National Science Foundation
William Regli
Special Assistant to the Director
Defense Advanced Research Projects 
Agency (DARPA)
National Academy of Engineering
C. D. Mote, Jr.
President
Alton D. Romig, Jr.
Executive Officer
Janet Hunziker
Senior Program Officer
Sherri Hunter
Program Coordinator

Program
NATIONAL ACADEMY OF ENGINEERING
2017 US Frontiers of Engineering
September 25-27, 2017
Chair:  Robert Braun, University of Colorado Boulder
MACHINES THAT TEACH THEMSELVES
Organizer: 
Rajan Bhattacharyya, HRL Laboratories
Reinforcement Learning and Learning to Promote Learning
Emma Brunskill, Stanford University
 
Can Machines Spot Diseases Faster Than Expert Humans?
Suchi Saria, Johns Hopkins University
Humans and Computers Working Together to  
Measure Machine Learning Interpretability
Jordan Boyd-Graber, University of Maryland
***
125

126	
FRONTIERS OF ENGINEERING
ENERGY STRATEGIES TO POWER OUR FUTURE
Organizers: 
Katherine Dykes, National Renewable Energy Laboratory, and  
Jeremy Munday, University of Maryland
Agile Fractal Systems: Re-Envisioning Power System Architecture
Tim Heidel, National Rural Electric Cooperative Association
Big Data and Analytics for Wind Energy Operations and Maintenance:  
Opportunities, Trends, and Challenges in the Industrial Internet
Bouchra Bouqata, GE Global Research Center
Across Dimensions and Scales:  
How Imaging and Machine Learning  
Will Help Design Tomorrow’s Energy Conversion Devices
Mariana Bertoni, Arizona State University
Wireless Charging of Electric Vehicles
Khurram Afridi, University of Colorado Boulder
***
UNRAVELING THE COMPLEXITY OF THE BRAIN
Organizers: 
Xue Han, Boston University, and  
Maryam Shanechi, University of Southern California
Technologies to Interface with the Brain for Recording and Modulation
Ellis Meng, University of Southern California
Brain-Machine Interface Paradigms for Neuroscience and Clinical Translation
Jose Carmena, University of California, Berkeley
The Roles of Machine Learning in Biomedical Science
Konrad Kording, University of Pennsylvania
Efficient Feature Extraction and Classification Methods in Neural Interfaces
Azita Emami, California Institute of Technology
***

PROGRAM	
127
MEGATALL BUILDINGS AND OTHER FUTURE PLACES OF WORK
Organizers: 
Maria Paz Gutierrez, University of California, Berkeley, and  
Marija Trcka, United Technologies Corp.
The Evolution of Elevators:  
Physical Human Interface, Digital Interaction, and Megatall Buildings
Stephen Nichols, Otis
Supertall Timber: Functional Natural Materials for High-Rise Structures
Michael Ramage, University of Cambridge
Applications of Insights from Biology and Mathematics to the  
Design of Material Structures
Jenny Sabin, Cornell University


