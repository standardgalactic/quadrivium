


































































































Figure 3.11
Example of closed and not closed sets in Mormann’s
 closure structures based on Mormann 1993, figure 7.
  

may be grouped" as Stalnaker (1981, 347) would like to see. The theory of conceptual spaces can be seen
as an extension of what Stalnaker (1981) calls logical space. The main difference between his notion and
mine is that he does not consider the role of the geometrical structure of the quality dimensions, and thus
he can not talk about "convexity" and similar notions.
The following quotation from Stalnaker 1981, 348-349, presents his solution to the problem of expressing
the antiessentialistic doctrine. By "location function" he means a function that maps the individuals
(object) into a logical space. 87
It should be clear that every property (every region of logical space) determines a propositional function in the
following way: given any property, the value of the corresponding propositional function, relative to a given
possible world, will be the class of individuals that have the property in that possible worldâthe individuals that are
located in that region of logical space by the location function that represents the possible world. Thus every
property determines a unique propositional function and the correspondence is one-one: distinct properties never
determine the same propositional function. But it is not the case that every propositional function corresponds to
an intrinsic property, for the classes of individuals selected by a propositional function in the different possible
worlds need not all come from the same region of logical space. Among the propositional functions, or properties
in the broad sense, that do not correspond to regions of logical space are, of course, just those that the
anti-essentialist wants to distinguish from full-fledged intrinsic properties. For example, referential properties such
as being the same weight as Babe Ruth will clearly not correspond to regions of logical space.
Thus the possible worlds semantics generated from conceptual space semantics is rich enough to represent
the distinctions needed to make sense of the appropriate kind of antiessentialism.
Fourth and finally, the problems that Putnam’s theorem attests for the traditional definition of "property"
dissolve into thin air under the new criterion. "Cat" presumably denotes a region of a conceptual space
(relating to the class of possible animals, be they determined in terms of shape, biological functions, or
whatever). This region would, at least partly, be determined by the perceptual features of cats (compare,
for example, Marr and Nishihara’s 1978 shape representations that will be presented in section 3.10). We
cannot create a new natural property "cat*" by relating it to what facts are true in various possible worlds.
The denotation of "cat*" as introduced by Putnam is indeed a
  

propositional function since it is defined as a function from possible worlds to objects, but it is not a
natural property in the sense of this book since it cannot be described as anything like a region of a
conceptual space (compare the above quotation from Stalnaker). In my opinion this distinction accords
well with a common-sense notion of a natural property. The role of "cat*" in various truth-functional
constructions is totally irrelevant for whether it is a natural property or not.
3.7 The Relativism of Conceptual Spaces
Natural properties have here been defined in relation to a given conceptual space. But is not the choice of
a conceptual space arbitrary? Since a conceptual space may seem like a Kuhnian paradigm, aren’t we
thereby stuck with an unavoidable relativism? After all, anyone can pick her own conceptual space and in
this way make her favorite properties come out natural in that space. 88 More generally, for a domain of
objects, there are several geometric structures that will generate different classes of natural properties.
Which structure is the right one?
Mormann (1993, 1994) calls this the problem of "structural conventionalism." He compares it to
geometrical conventionalism, which is "the thesis that the metrical structure of physical space is a matter
of convention, that is physical space is metrically amorphous and may be metrically structured in many
different ways, and all these metrical structures are on the same par." (1994, 248). Analogously, structural
conventionalism claims that conceptual spaces are structurally amorphous.
Putnam (1975, 164-165) has criticized geometrical conventionalism as follows: "The conventionalist fails
precisely because of an insight of Quine’s. That is the insight that meaning, in the sense of reference, is a
function of theory, and that the enterprise of trying to list the statements containing a term which are true
by virtue of its meaning, let alone to give a list of statements which exhausts its meaning, is a futile one."
Mormann (1993, 236-237) generalizes this argument to structural conventionalism. He discusses a
conceptual space Co  with different closure structures $ and $’ (see section 3.5):
Thus in the case of conceptual spaces the meaning of terms like "naturalness" of predicates, defined on Co  by the
structures $ (or $’), is not exhausted by a short list of axioms . . . of a closure structure, rather it is a function of an
extended net of empirical knowledge: that is, we do not fix the reference of the term natural predicate of Co ’ by
convention but by coherence.
  

The fixation of projectibility by coherence means that the task of determining which of the subsets of Co
represent natural predicates is not achieved by defining simple structures like closure or topological structures on 
Co, rather it involves large parts of scientific (and cultural) background knowledge.
As an example of the background knowledge that may be involved, Mormann considers the color domain.
The underlying neurological theory says that there are three types of color sensitive cells in the human eye
that are adapted to blue, green, and orange, respectively (see figure 1.7). Furthermore, according to the
theory, there is a systematic mapping among the relations between stimulations of the different kinds of
retinal cells and the color perceptions of an individual. On the basis of such a mapping Mormann (1993,
237) argues as follows:
Since according to the neurological theory of colour vision there are no Goodmanian cells (preferably stimulated
by bleen or grue, respectively), the predicates "bleen" and "grue" are certainly more complicated, and are to be
considered as contrived. In this way the symmetry between the traditional and Goodmanian predicates is broken.
Hence, if we rely on a coherentist approach for fixing the meaning of "natural" this counts as strong evidence
against the Goodmanian predicatesâthe traditional ones are far better entrenched in the global system of our
conceptual framework.
As a result, the freedom in choosing a conceptual space is rather limited and thus the relativism inherent in
this choice is not as problematic as it may first appear. 89
As was noted in section 1.9, some quality dimensions are innate. This is the main reason why human
beings, to a remarkable extent, agree on which properties are projectible, in particular if the properties are
closely connected to what is provided by our senses. These are the properties that are named in language
(compare Quine 1969, 123). For instance, different cultures show high agreement in identifying species of
animals and plants, at least what concerns basic categories in the sense of prototype theory. It appears
reasonable to assume that the psychological conceptual spaces of humans are, at least in their fundamental
dimensions, close to identical. Mormann concludes (1993, 238-239):
Even if we cannot exhaust the meaning of "natural" by imposing an all-embracing final structure on the conceptual
space in question, we can approximate it step by step, thereby eliminating
  

more and more Goodmanian predicates of various degrees of sophistication.
This structural approach leads to a kind of "mathematical epistemology" based not on the unspecific and general
framework of set theory but on specific frameworks of appropriate mathematical theories, e.g., topological and
geometrical ones.
But even if such an agreement on the structure of a conceptual space exists, we must answer the question
of why our way of identifying natural properties accords so well with the external world as to make our
generalizations come out right. Peirce notes that "it can no longer be denied that the human intellect is
peculiarly adapted to the comprehension of the laws and facts of nature" (1932, 474). Quine (1969, 126)
formulates the problem in the following way: "[W]hy does our innate subjective spacing of qualities
accord so well with the functionally relevant groupings in nature as to make our inductions tend to come
out right? Why should our subjective spacing of qualities have a special purchase on nature and a lien on
the future?"
The answer for me comes from evolutionary theory. Natural selection has made us all develop a
conceptual space that results in inductions that are valid most of the time and thus promote survival. 90
Our quality dimensions are what they are because they have been selected to fit the surrounding world. In
Peirce’s words: "[T]here is a special adaptation of the mind to the universe, so that we are more apt to
make true theories than we otherwise should be" (1932, 472). And Quine (1969, 126) says ironically:
"Creatures inveterately wrong in their inductions have a pathetic but praise-worthy tendency to die before
reproducing their kind."
Now, as indicated in section 1.9, not all of our quality dimensions have a genetic origin, but the agreement
among the conceptual spaces of different individuals of our species is still high enough to produce very
similar conceptions of, at least, the perceptual categories of the world.91 As mentioned in section 1.9,
another reason for this has been given by Freyd (1983), who argues that conceptual spaces may evolve as
a representational form just because people have to share knowledge. The upshot is that rather limited
freedom exists for humans in choosing a conceptual space for the most ecologically basic properties. The
relativism that will occur only applies to the more advanced learned and culturally dependent quality 
dimensions.
A far-reaching consequence of this evolutionary account of conceptual spaces, however, is that what we
count as natural properties will depend on the ecological circumstances under which the spaces have 
evolved. The psychological spaces of humans are attuned to the environment of
  

thousands of years of hunting and gathering. Consequently, we cannot expect our intuitions about which
properties are projectible to be successful in environments that wildly diverge from those present during
our evolutionary history. The conclusion to be drawn is that we should only trust our capacities for
inductive reasoning in situations that are "ecologically valid," to borrow a notion from Gibson (1979). 92
What should we do about the increasing proportion of artificial objects and situations that surround us?
This is where science enters on the scene. By introducing theoretically precise, nonpsychological quality
dimensions, a scientific theory may help us find new properties that would not be possible to discover on
the basis of our subjective conceptual spaces alone. A scientific breakthrough is often made when a new
quality dimension or domain is introduced to a theory. Take, for example, the distinction between
temperature and heat, which is central for thermodynamics, but which has no correspondence in human 
perception.93 Equally important is Newton’s distinction between weight and mass. This is the very first
definition introduced in the Principiaâwithout it his celestial mechanics would not have been possible.
The quality dimensions of scientific theories and their associated measurement procedures help us create
new useful properties in environments that are completely different from those of our evolutionary cradle.
Furthermore, the precise metrics of the scientific quality dimensions make it possible to formulate 
functional laws that in turn enable us to compute more sophisticated predictions (Galileo’s laws of free fall
have set the standard). Once a scientific conceptual space has been established, the formulation of such
laws is a kind of inductive inference.94 Clearly, such laws supersede generalizations of the form "all Fs
are Gs." Such generalizations are the only possible inductive inferences on quality dimensions that just
have a crude or rudimentary metric or merely classify objects. As Quine (1969) notes, it is a sign of
mature science that notions of similarity become less and less important, being replaced by theoretically
more sophisticated concepts (compare section 6.4). The development is away from "the immediate, the
subjective, animal sense of similarity to the remoter sense of similarity determined by scientific
hypotheses and posits and constructs" (1969, 134).
In this way science builds upon our more or less evolutionarily determined conceptual spaces, but in its
most mature form becomes independent of them. Peirce (1932, 477) notes that this is a general trend of
human thinking: "Side by side, then, with the well established proposition that all knowledge is based on
experience, and that science is only advanced by the experimental verifications of theories, we have to
place this other equally important truth, that all human knowledge,
  

up to the highest flights of science, is but the development of our inborn animal instincts.’’
3.8 Connections to Prototype Theory
As we have seen, the delimitation of natural properties in terms of convex regions, that is criterion P,
provides intuitively plausible solutions to the problems caused by the account within intensional
semantics. Apart from this, the criterion derives independent support from the prototype theory of
categorization developed by Rosch and her collaborators (see, for example, Rosch 1975, 1978, Mervis and
Rosch 1981, Lakoff 1987).
The main idea of prototype theory is that within a category of objects, like those instantiating a property or
a concept, certain members are judged to be more representative of the category than others. For example
robins are judged to be more representative of the category "bird" than are ravens, penguins, and emus;
while desk chairs are more typical instances of the category chair than rocking chairs, deck chairs, and
beanbag chairs. The most representative members of a category are called prototypical members.
In the classical Aristotelian theory of concepts (Smith and Medin 1981), a concept is defined via a set of
necessary and sufficient properties. Consequently, all instances of a classical concept thus have equal
status. Another part of prototype theory, however, says that concepts show graded membership,
determined by how representative the members are. It is well-known that some properties, like "red" and
"bald," have no sharp boundaries and for these it is perhaps not surprising that one finds prototypicality
effects. These effects have been found, however, for most concepts, including those with comparatively
clear boundaries like bird and chair. Concept theories other than the prototype theory can also represent
graded membership. Some such theories like "nearest neighbor" and "average distance" (Reed 1972,
Nosofsky 1988b) are presented in section 4.9.
An intriguing illustration of how the prototypical structures determine categorizations is the phonetic
identification of vowels in various languages. According to phonetic theory, what determines a vowel are
the relations between the basic frequency of the sound and its formants (higher frequencies that are present
at the same time). In general, the first two formants F1 and F2 are sufficient to identify a vowel. This
means that the co-ordinates of two-dimensional space spanned by F1 and F2 (in relation to a fixed basic
pitch F0) can be used as a fairly accurate representation of a vowel. Fairbanks and Grubb (1961)
investigated how people produce and recognize vowels in
  

Figure 3.12
Frequency areas of different vowels in the two-
dimensional space generated by the first
 two formants. Values in Hz. 
(From Fairbanks and Grubb 1961).
"general American" speech. Figure 3.12 summarizes some of their findings.
The scale of the abscissa and the ordinate is the logarithm of the frequencies of F1 and F2, respectively
(the basic frequency of the vowels was 130Hz). As can be seen from the diagram, the "preferred,"
"identified," and "self-approved’’ examples of different vowels form convex subregions (with focal
regions) of the space determined by F1 and F2 with the given scales. 95 As in the case of color terms,
different languages carve up the phonetic space in different ways (the number of vowels identified in
different languages varies considerably), but I conjecture that each vowel in a language will correspond to
a convex region of the formant space. This is another example of an empirical prediction generated from
criterion P.
Prototype theory can also be used to provide a reasonable explication of the notion of similarity that is
tightly connected to the notion of a property. Quine (1969, 119-120) argues that "natural kind"
(corresponding to "natural property") is definable in terms of "similarity" and he proposes a precursor to
the psychological prototype theory:
One may be tempted to picture a kind, suitable to a comparative similarity relation, as any set which is
’qualitatively spherical’ in this sense: it takes in exactly the things that differ less than so-

  

and-so much from some central norm. If without serious loss of accuracy we can assume that there are one or more
actual things (paradigm cases) that nicely exemplify the desired norm, and one or more actual things (foils) that
deviate just barely too much to be counted into the desired kind at all, then our definition is easy: the kind with
paradigm a and foil b is the set of all things to which a is more similar than a is to b.
Quine notes that, as it stands, this definition of a kind is not satisfactory:
Thus take red. Let us grant that a central shade of red can be picked as norm. The trouble is that the paradigm
cases, objects in just that shade of red, can come in all sorts of shapes, weights, sizes, and smells. Mere degree of
overall similarity to any such paradigm case will afford little evidence of degree of redness, since it will depend
also on shape, weight, and the rest. If our assumed relation of comparative similarity were just comparative
chromatic similarity, then our paradigm-and-foil definition of kind would indeed accommodate redkind. What the
definition will not do is distill purely chromatic kinds from mixed similarity. (Quine, 1969, 120)
What causes the problem for Quine is that he does not assume anything like the notion of domains in
conceptual spaces to help structuring the relations of similarity. If such a structure is given, however, we
need not rely on actual objects as paradigm cases but can use focal points on a particular quality
dimension, like the hue dimension, as a basis for comparing chromatic similarity. In a series of
experiments, Rosch (1975, 1978) and others have been able to demonstrate the psychological reality of
such focal colors. The shape, weight, and the rest of the qualities of objects will simply not be relevant for
such comparisons.
Now, if the traditional extensional or intensional definition of a property is adopted, it is very difficult to
explain the degrees of representativeness that prototype theory predicts. Either an object is a member of
the class assigned to a property or it is not. Furthermore, all members of the class have equal status as
category members. Rosch and her colleagues’ research has been aimed at showing asymmetries among
category members and asymmetric structures within categories. Since the traditional definition of a
property does not predict such asymmetries, something else must be going on.
In contrast, when natural properties are defined as convex regions of a conceptual space, prototype effects
are indeed to be expected. In a
  

convex region one can describe positions as being more or less central. In particular, if the space has a
metric, one can calculate the center of gravity of a region. For dense spaces, it can be shown that the
center of gravity of a convex region always belongs to the region. This is not true in general for connected
or star-shaped regions. For example, if color properties are identified with convex subsets of the color
space, the central points of these regions would be the most prototypical examples of the color. 96 These
would correspond to the focal colors identified by Rosch. This assumption is also supported empirically
by the typicality patterns generated by Sivik and Taft (1994).
Even if different members of a category are judged to be more or less prototypical, it does not follow that
some of the existing members must represent "the prototype" (see Lakoff 1987, chapter 2). If a category is
viewed as a convex region of a conceptual space this is easily explained, since a central point of the region
represents a possible object with the features that are most typical for the category, but such an object need
not be among the existing members of the category.
3.9 Voronoi Tessellations of a Space
It is possible to argue conversely and show that if prototype theory is adopted, then the representation of
properties as convex regions is to be expected, at least in metric spaces. Assume that some quality
dimensions of a conceptual space S are given, for example the dimensions of color space, and that we
want to partition it into a number of categories, for example color categories. If we start from a set of
prototypes p1, . . . , pn  of the categories, for example the focal colors, then these should be the central
points in the categories they represent. If we assume that S is a metric space, the information about
prototypes can be used to generate a categorization. To see this, assume that S is equipped with the
Euclidean metric so that for every point p in the space one can measure the distance dE (p, pi ) from p to
each of the pi’s (dE  is the Euclidean metric defined in section 1.6.3). If we now stipulate that p belongs to
the same category as the closest prototype pi, it can be shown that this rule will generate a partitioning of
the spaceâthe so called Voronoi tessellation (see Okabe, Boots, and Sugihara 1992 for an extensive
treatment of such tessellations and their variants). An illustration of the Voronoi tessellation is given in
figure 3.13.
The line between pi  and pj  is called the bisector of the two points and it is defined as the set of points x
such that dE (x, pi ) = dE (x, pj ). Each bisector divides the plane into two halves. The following lemma
(see Okabe, Boots, and Sugihara 1992) brings out a crucial property of the Voronoi partitioning of a
conceptual space, where the cell around a particular
  

Figure 3.13
Voronoi tessellation of the plane into convex sets.
point pi  is generated by the intersection of all the bisector half-planes containing pi :
LEMMA 3.1 The Voronoi tessellation based on an Euclidean metric always results in a partitioning of the
space into convex regions.
Thus, assuming that a Euclidean metric is defined on the subspace that is subject to categorization, a set of
prototypes will by this method generate a unique partitioning of the subspace into convex regions. The
upshot is that there is an intimate link between prototype theory and criterion P. Furthermore, the metric is
an obvious candidate for a measure of similarity between different objects according to equation (1.7) or
(1.8). In this way, the Voronoi tessellation provides a constructive answer to how a similarity measure
together with a set of prototypes determine a set of natural properties. In a more "dynamic" vocabulary,
the prototypes can be seen as attractors and the Voronoi region associated with the prototype as its basin
of attraction (see also section 7.2.1 below). Fenstad (1998, 16) gives the following example:
[C]olor prototypes can be interpreted as a fixed set of patterns to be stored by a suitable attractor neural
network. . . . In this case the prototypes are the attractors of the system and the concept of color corresponds to a
domain of attraction in the energy surface of the system. This would give a reasonable dynamics for color
perception. The correspondence between convex geometry and the dynamics of attractors is quite close; granted
sufficiently regularity assumptions the claim is that the two accounts tell basically the same story. In this way we
see a connection between grammar and mindâthe link being geometry.
  

A Voronoi tessellation based on a set of prototypes is a simple way of classifying a continuous space of
stimuli. The partitioning results in a discretization of the space. The prime cognitive effect is that the
discretization speeds up learning. The reason for this is that remembering the finite prototypes, which is
sufficient to compute the tessellation once the metric is given, puts considerably less burden on memory
than remembering the categorization of each single point in the space. In other words, a Voronoi
tessellation is a cognitively economical way of representing information about concepts. Furthermore,
having a space partitioned into a finite number of classes means that it is possible to give names to the
classes. As argued in chapter 4, however, psychological metrics are imprecise and often context
dependent. As a consequence, the borderlines will not be exactly determined. 97
For some category systems, the effects of a categorization are amplified by the perceptual systems so that
distances within a category are perceived as being smaller and distances between categories are perceived
as larger than they "really" are. This phenomenon is called categorical perception (see Harnad 1987 and
the other articles in the same volume).98
The mechanism of categorical perception has been found in many kinds of categorization but has been
studied in particular for phonetic systems (see, for example, Petitot 1989). Even though a set of sounds
may be produced by an articulatory parameter that varies continuously (output variable), the auditory
system perceives this variable in a categorical way so that when the articulatory parameter is varied along
its scale, the perceived sound (input variable) appears to remain constant for a large interval and then
suddenly jumps to a new sound that is relatively stable too. Figure 3.14 illustrates the functional relation
between an articulatory parameter and the perceived sound.
Petitot (1989) applies Voronoi categorizations to explain some aspects related to the categorical
perception of phonemes. In particular, he analyses the relations among the so called stop consonants /b/,
/d/, /g/, /p/, /t/ and /k/. The relations among these consonants are expressed with the aid of two dimensions;
one is the voiced-unvoiced dimension, the other is the labial-dental-velar dimension that relates to the
place of articulation of the consonant. Both these dimensions can be treated as continuous. Figure 3.15
shows how Petitot represents the boundaries between the six consonants.
As an example of the information contained in this model, he points out (Petitot 1989, 68): "The geometry
of the system of boundaries can provide precious information about the hierarchical relations that stop
consonants maintain with each other. The fact that . . . the domains of /p/ and /d/ are adjacent, whereas
those of /b/ and /t/ are separated,
  

Figure 3.14
The relation between an articulatory parameter and
 the corresponding sound perception (from Petitot 1989, 49).
Figure 3.15
A Voronoi model of the boundaries of stop consonants (from Petitot 1989, 69).
indicates that the contrast between /b/ and /t/ is much greater than that between /p/ and /d/."
Lemma 3.1 provides a connection between prototypes and convex regions. The lemma heavily depends,
however, on the assumption that the appropriate metric for the space S is the Euclidean metric. As we
have seen in section 1.7, the city-block metric is sometimes more suitable, in particular if the dimensions
of the space are not integral.
  

Figure 3.16
Voronoi tessellation based on the city-block metric
(based on Okabe, Boots and Sugihara 1992, 187).
For the city-block metric dc , the bisector defined as the set of points x such that dc (x, pi ) = dc (x, pj ) is
not always a straight line as in the Euclidean case. The Voronoi partitioning of the space generated by
these bisectors will therefore be of a more complicated nature than the Euclidean metric. Figure 3.16 gives
an illustration.
As can be seen from the figure, not all areas are convex if between-ness is defined as illustrated in figure
1.12. It is possible, however, to prove the following property with respect to the points pi  that generate
the Voronoi tessellation (Okabe, Boots and Sugihara 1992, p. 187):
LEMMA 3.2 The Voronoi tessellation based on the city-block metric always results in a partitioning of the
space into star-shaped regions with respect to the points pi .
Thus we see that a set of prototypes within a given conceptual space will result in different partitionings of
the space, depending on which metric is chosen. Yet another example of a Voronoi tessellation, based on a
different kind of metric, is discussed in section 4.7.
This section has presented a number of criteria for natural properties. So, which of them is the "right"
criterion? Partly, this appears to be an empirical question; for different quality dimensions, different
assumptions concerning metrics and other geometrical properties are justified. For conceptual spaces that
contain integral dimensions, the Euclidean metric is often warranted. If we make the additional
assumption that, for each property, one can identify a prototype, lemma 3.1 shows that then the (strong) 
convexity assumption of criterion P is applicable. If the conceptual space consists of separable dimensions,
the city-block metric appears to be empirically more motivated (see section 1.8). Again, if prototypes exist
for the different properties, then
  

a criterion of natural properties based on star-shaped regions follows from lemma 3.2. Finally, for
domains where there is no natural metric and no prototype structure, a criterion of natural properties based
on connected regions is perhaps the strongest that will be justified.
3.10 Higher Level Properties and Relations
3.10.1 Relations and Properties
The notion of a property has been analyzed as regions of a conceptual space. But apart from the direct
methods of specifying regions of a space that have been used here, there are more sophisticated
possibilities. The dimensions of a space can often be used to create new "higher order" dimensions. Let me
illustrate the general idea by first showing how the idea of regions can be extended to binary relations.
A comparative relation like "longer than" is determined from the lengths of two objects. The length
dimension can be represented by R+, that is the positive half of the line of real numbers. Let l(x) denote
the length of an object x. We can then consider the space of all pairs of length values <l(x), l(y)>, that is, 
(R+)2. In this space the relation "y is longer than x" can be identified with the region of all pairs such that 
l(y) > l(x). This region turns out to be a convex subset of (R+)2 (see figure 3.17). 99 It is easy to see that
this kind of analysis applies to all comparative relations where the generating dimension is isomorphic to 
R or R+.
To give a less elementary example, consider "y is a (direct) heir of x." The relevant underlying conceptual
space is the genealogical tree of social relations that is generated among the members of a society by
Figure 3.17
A geometric representation of "longer than."
  

combining links of the types "x is a child of y," "x is a parent to y," "x is married to y," "x is a sister or
brother to y.’’ If we fix a particular y we can look at the set H(x) of all y which are (legal) heirs of x.
This set may vary a lot in different societies depending on various cultural factors. Even the structure of
the genealogical tree may vary. For example, there are many cultures where no distinction is made
between "mother" and "(maternal) aunt." Nevertheless, my conjecture is that H(x) will be a convex set in
most cultures in the sense that an individual z will not be counted as a heir of x unless all individuals y that
are between z and x (in terms of the genealogical tree) are also considered to be heirs. For example, a
grandparent will not be a heir unless the parents are also heirs or a niece unless the brother or sister is a 
heir.
As an alternative representation of kin relations, Joost Zwarts (personal communication) has proposed a
two-dimensional scheme; one dimension is the number of steps "backward" in the genealogy, represented
as the horizontal dimension in figure 3.18; the other is the number of steps "forward," represented as the
vertical dimension.
Note that this representation makes "cousin" correspond to a convex region, unlike what would happen if
we represent the concept in the genealogical tree. It would be interesting to investigate how this
two-dimensional mapping treats kinship terms in other cultures.
A relation between two objects can be seen as a simple case of a pattern of the location of the objects
along a particular quality dimension. There are also properties that can be seen as more general patterns
that arise from relations among points located in a conceptual space. On the Cartesian space R2 with the
standard Euclidean metric, we can of course define regions as subsets of the space. But we can also
introduce a new space of "shapes" that are patterns of points in the space. For example, let us consider the
set of "rectangles." This set can be defined using the set of all quadruples <a, b, c, d> of points in R2 that
satisfy the condition that the lines ab, bc, cd, and ad form a convex
Figure 3.18
Zwarts’s two-dimensional representation of kinship (the figure only covers one gender).
  

Figure 3.19
The mapping <a, b, c, d> Â® (|ab|, |ac|).
polygon such that ax  - bx  =cx  - dx  and ay  - cy  = by  - dy  (sides are pair-wise equally long) and |ad| = 
|bc|, where |ad| denotes the length of the line between a and d (diagonals are equally long). Let us partition
this set of quadruples into equivalence classes by saying that two rectangles <a, b, c, d> and <e, f, g, h>
are identical if |ab| = |ef| and |ac| = |eg|. In this way we identify a rectangle by the size of its sides,
independently of its position in R2. Now let E be the set of all such equivalence classes. On E we can now
define a distance function d as follows:
As a matter of fact, this measure corresponds to identifying a rectangle <a, b, c, d> with the point (|ab|, 
|ac|) in R2 as shown in figure 3.19. The space E of rectangles is therefore isomorphic to (R+)2 with the
width and the length of the rectangle as the generating dimensions.
On E, we can now identify some regions that correspond to properties. For example, a square is a point 
<|ab|,|cd|> in E such that |ab| = |ac|. It is easy to show that this region is a convex subset of E (since this set
will correspond to the line x = y in E and a line is a convex set). On the right side of this line, that is, when 
x > y, one finds the set of all rectangles that are wider than they are high, which is also a convex set.
3.10.2 Shapes
So far, the examples of higher level properties and relations have been based on low-level perceptual or
social domains. For more complex concepts like "bird" or "cat," it is more difficult to describe the
underlying conceptual space (see section 4.2). If something like Marr and Nishihara’s (1978) analysis of 
shapes is adopted, however, we can begin

  

to see how such a space would appear. 100 As an example of a more advanced domain, here is a brief
outline of their model.
Marr and Nishihara’s scheme for describing biological forms uses cylinder-like modeling primitives as
illustrated in figure 3.20. Each cylinder can be described by two coordinates (length and width). If we
want, we can add dimensions describing the spatial orientation of the cylinder, for example, to describe
whether it is horizontal or vertical.
Cylinders are combined by determining the angle between the dominating cylinder and the added one, as
well as the position of the added cylinder in relation to the dominating one. Figure 3.20 provides an
illustration of the cylinder-based representations. The details of the representation are not important in the
present context, but it is worth noting that an object can be described by a comparatively small number of
coordinates based on lengths and angles. Thus, the object can be represented as a vector in a
high-dimensional space where most dimensions are constituted of spatial dimensions with a Euclidean
metric while some dimensions represent the angles between cylinders (in polar coordinates). In this sense,
the shape space is supervenient on the spatial and angular dimensions (just like the rectangles above are
supervenient on the length dimension). The physical location of an object, say an animal, is, of course,
described with the aid of the ordinary spatial dimensions.
The coordinates for the cylinders and their connecting points will generate a multidimensional space of
shapes. Each particular cylinder shape will then correspond to a point in this space. It is easy to define an
elementary betweenness relation for this space by comparing the values of each dimension separately (so
that <b1, . . ., bn > is between <a1, . . ., an > and <c1, . . ., cn >, if and only if bi  is between ai  and ci,
for all i). In this way one can, for example, create shapes between the "human" and the "ape" shape. It is
possible to introduce a nontrivial metric on the shape space. For example, we can take the city-block
metric over all the dimensions (possibly with different weights for the dimensions as in equation (1.5) or
(1.6)). Intuitively, the "ape’’ shape is much more similar to the "human" than to the "horse" shape, which
can be confirmed by this kind of metric (see also Aisbett and Gibbon’s 1994 article discussed below).
In the multidimensional shape space one can then look at various regions, perhaps generated from
prototypical animal shapes, and investigate their properties. Since Marr and Nishihara’s simple cylinder
figures already make it possible for us to identify a large class of animal shapes, it appears plausible that a
lot of the contents of our concepts for animals comes from their shapes. Landau, Smith, and Jones (1998,
21) emphasize the role of shapes in early concept learning: "Our
  

Figure 3.20
Representation of animal shapes using cylinders as modeling primitives
(from Marr and Nishihara 1978).

  

view holds that, however the meanings underlying object names are ultimately characterized, shape
similarity constitutes a critical bootstrapping mechanism operating to initiate learning of object names in
young children by allowing them to identify category members in the absence of dense knowledge about
the category."
For adults there are, of course, other dimensions involved in the animal concepts. (Some further aspects of
this are developed in chapter 4). In natural language, however, nouns are often used on the basis of similar
shapes. Naming at the basic level often ignores fundamental differences in other domains, while
respecting shape similarities; we gladly say "teddy bear," "porcelain cat" and "plastic duck" about objects
that have very little in common with the real animals except for their shape. In particular this ’’shape bias"
applies when new words are learned (Jones and Smith 1993, 122-128).
The main factor preventing a more detailed analysis of shape space is the lack of knowledge about the
relevant quality dimensions. The models developed by Marr and Nishihara (1978), Tversky and
Hemenway (1984), Pentland (1986), Biederman (1987), Chella, Frixione, and Gaglio (1997) among
others, are interesting attempts to solve the problem of how shapes are best represented. 101 Nevertheless,
a lot remains to be learned about the geometrical structure of shape space and about the structure of the
regions corresponding to the properties that we identify in this space.102 The next chapter presents an
experimental investigation of an idealized space of shell shapes, based on a three-dimensional conceptual 
space.
Aisbett and Gibbon (1994) develop a mathematical measure of the similarity of objects, where the
judgments are supposed to be based on the shapes and colors of the objects. Their shape representations
are much more sophisticated than Marr and Nishihara’s (1978) cylinder models. Furthermore, the
similarity measure they assume is context sensitive. Their model is "inspired by an attempt to treat
physical and colour discontinuities as a human observer treats them . . ." (1994, 150). They make the
following conjectures about how humans match objects:
Firstly, humans seek to identify parts of one object as uniquely corresponding to parts of the other. Secondly, they
will ignore parts of objects rather than force a fit between dissimilar objects. . . . Thirdly, . . . we believe humans
are happy to match smooth regions onto piecewise smooth regions, but not vice-versa: it is not natural to "smooth
out" creased areas to match them to smooth areas. Fourthly, humans are happy to collapse smooth regions onto
parts of their boundaries, . . . (1994, 150-151)
  

On the basis of these assumptions, they define a distance function that is based on visual discontinuities
(in shape as well as in color). This function combines visually prominent features of objects with a
measure of geometrical distortions in their edges and surfaces.
3.10.3 Actions and Functions
This chapter’s examples have all been of a static nature where the properties modeled do not depend on
the time dimension. It is obvious, however, that a considerable part of our cognitive representations
concern dynamic properties (see, for example, van Gelder 1995, Port and van Gelder 1995). If we, for the
moment, consider what is represented in natural languages, verbs normally express dynamic properties of
objects. Such dynamic properties can also be judged about similarities in a distinctive way: "walking" is
more similar to "running" than to "throwing." 103
An important question is how the meaning of such verbs can be expressed with the aid of conceptual
spaces. One idea comes from Marr and Vaina (1982), who extend Marr and Nishihara’s (1978) cylinder
models to an analysis of actions. In Marr and Vaina’s model, an action is described via differential
equations for movements of the body parts of, say, a walking human (see figure 3.21).104
It is clear that these equations can be derived from the forces that are applied to the legs, arms, and other
moving parts of the body. And as Talmy (1988) has convincingly demonstrated, a great deal of our
understanding of verbs depends on the forces that are involved in the actions expressed by the verbs
(compare section 5.5).
The upshot is that by adding force dimensions to a conceptual space, we may obtain the basic tools for
analyzing dynamic properties. Scott Kelso’s (1995) book presents a number of examples of self-organized
patterns that emerge in dynamic systems. The forces involved need not only be physical forces, but can,
by metaphorical extension, also be social forces.105 Very little research has been directed toward this
topic, however, so the details of the analysis will have to be left for the future.
Another large class of properties are the functional properties that are often used for characterizing
artifacts. For example, Vaina (1983) notes that when deciding whether an object is a "chair," the
perceptual dimensions of the object, like those of shape, color, and weight, are largely irrelevant or at least
extremely variable. Since I have focused on such dimensions in my description of conceptual spaces, the
analysis of functional properties is an enigma for my theory.
One possibility for analyzing these properties is to reduce them to the actions the objects "afford."106 To
continue with the example, a chair is prototypically an object that affords back-supported sitting for one
  

Figure 3.21
A representation of "walking"
 (from Marr and Vaina 1982, 509).
person, that is, an object that contains a flat surface at a reasonable height from the ground and another flat
surface that supports the back. The actions involved in the affordance may then, in turn, be reduced to
force dynamic patterns as was explained above. At this stage, however, the proposed strategy is little more
than a programmatic statement. Hence, even if this path of analysis is long and to a large extent
unexplored, functional properties can, in principle, be explained in the more basic properties that formed
the starting point of this chapter. 107
3.11 Conclusion
I have presented here a theory of properties that is based on conceptual spaces. In brief, a property is
identified with a "well-behaved" region of a domain (consisting of integral dimensions). I have proposed
three increasingly restrictive meanings of "well-behaved": connected, star-shaped, and convex. It is not
possible to reduce this theory to any of the traditional philosophical theories since it heavily depends on
the geometrical structures of the underlying domains. Several aspects of
  

the prototype theory of concepts, however, can be explained with the aid of the theory of properties
presented here.
As has been argued in section 3.3, traditional philosophical theories of properties do not give us the
answers we intuitively expect. In addition to the criteria discussed earlier in the chapter, we can also return
to Armstrong’s desiderata presented in section 1.2. It can now be seen that the proposed theory of
properties explains the phenomena that he brings out concerning the class of shapes and the class of 
colors:
a. What colors have in common is that they are all represented as regions of the color domain and what
shapes have in common is that they all correspond to regions of the (higher level) shape domain.
b. While colors (shapes) have the color (shape) domain in common, they differ by being represented as 
distinct regions of the domain.
c. Since the regions differ in how closely they are located (in terms of a distance function), shapes and
colors "exhibit a resemblance order based upon their intrinsic nature" (Armstrong, 1978, 116).
d. Colors and shapes form "a set of incompatibles" in the sense that the regions of a domain corresponding
to different properties like "triangular" and "circular" or "red" and ’’blue" do not overlap (at least on the
"basic level" of categorization).
  

Chapter 4â
Concepts
4.1 Concepts versus Properties
Properties, which were the focus of chapter 3, form a special case of concepts. There, I defined this
distinction by saying that a property is based on one domain (a subspace of integral dimensions), while a
concept may be based on several domains (consisting of separable domains).
The distinction between properties and concepts has been obliterated in the symbolic as well as
connectionist representations that have dominated the discussion in the cognitive sciences. In particular,
this applies to representations in logic: both properties and concepts are represented by predicates in
first-order languages. The predicates of a first-order language, however, correspond to several different
grammatical categories in a natural language, most importantly those of adjectives, nouns, and verbs. The
main semantic difference between adjectives and nouns is that adjectives like "red," "tall," and "round’’
usually, refer to a single domain and thus represent properties, while nouns like "dog," "apple" and "city"
normally contain information about several domains and thus represent concepts. 108 Verbs are
characterized by their temporal structure, which means that they essentially involve a time dimension.
Even though it is difficult to formulate a generally valid rule, most "basic" verbs represent dynamic
properties of domains.109
Using the notion of domains in conceptual spaces, one can in this way express the fundamental semantic
differences between the most important grammatical categories. First-order languages do not appear to be
sufficiently rich to make these distinctions in a systematic manner. The differences among the semantic
representations of the major word categories are further developed in the cognitive semantics of section 
5.5.
I provide an analysis here of concepts based on several domains. Even though the domains are assumed to
be separable, the values of their dimensions may be correlated. Such correlations are also included in the
concept representations. A significant feature of the chosen
  

representation is that the salience given to various aspects of a concept may vary depending on the
context. Thus the meaning of a concept is not static, but changes with the context in which it is used.
Some further dynamic aspects of concepts show up when concepts are combined. The process of concept
combination are analyzed in section 4.4.
We are not born with a fixed set of properties and concepts that we use to come to grips with the
surrounding world. On the contrary, we constantly learn new concepts and adjust old ones in the light of
new experiences. Section 4.5 outlines how the theory of conceptual spaces can explain some features of
concept learning. This is also illustrated later in connection with the experiments on categorizations of
shell shapes.
Since our applications of properties and concepts depend on context and earlier learning, it turns out that
concepts exhibit a number of non-monotonic features. Unlike the case in classical reasoning, new
information may lead to the withdrawal of earlier conclusions or expectations even though the new
information is consistent with the previous state of belief. Section 4.6 presents the different types of
nonmonotonicity of concepts. The theory of concepts developed here will be used to explain these
nonmonotonic effects.
In conclusion, the chapter presents a series of experiments on concept formation (presented in greater
detail in GÃ¤rdenfors and Holmquist 1994). These experiments compared four different categorization
rules. The rules presume that the stimuli to be classified can be modeled psychologically as points in a
conceptual space. Two of the rules are based on the assumption that there are prototypical representatives
of a concept, a third rule is a "nearest neighbor" model, and the fourth is based on "average distances"
(Reed 1972), where distances are measured in the underlying conceptual space.
4.2 Modeling Concepts
4.2.1 Concepts with Features in Several Domains
The focus now is on the differences between single-domain properties and multi-domain concepts. As a
paradigm example of a concept that is represented in several domains, consider "apple" (compare Smith et
al. 1988). The first problem when representing a concept is to decide which are the relevant domains.
When we encounter apples as children, the first domains that we learn about are presumably color, shape,
texture, and taste. Later, we learn about apples as (biological) fruits, their nutritional value, and possibly
some other dimensions. I do not require that a concept be associated with a closed set of domains. 110 On
the contrary, this set may be expanded as one learns about further
  

aspects of a concept. The addition of new domains is often connected with new forms of actions that
require attention to previously unnoticed aspects of concepts. 111
The next problem is to determine the geometrical structure of the domains. The color domain can be
represented by hue, chromaticness, and brightness and taste space presumably by the four dimensions
sweet, sour, salty, and bitter, as seen in section 1.5. Other domains are trickier; it is difficult to be precise
about the topological structure of "fruit space." Pomologyâthe biological categorization of applesâprovides
some notions, for example, the seed shapes and characters of the apple’s flesh and peel. Some ideas about
how "shape space" should be modeled were discussed in section 3.10 (following Marr and Nishihara 1978
and others). Textures could possibly be modeled using fractal theory (see, for example, Pentland 1986). It
would be very cumbersome to give psychological support for a detailed presentation of the geometrical
structures of the different domains. Instead, let me represent the "apple’’ regions associated with each of
these domains by verbal means as shown in table 4.1.
When several domains are involved in a representation, some principle for how the different domains are
to be weighed together must be assumed (compare equations (1.5) and (1.6)). To model this, I assume that
the concept representation also contains information about the salience of the different domains.112 One
reason for this assumption is that the relative weight of the domains depends on the context in which the
concept is used, as will be argued in the following section. If you are eating an apple, for example, its taste
is more salient than if you are using it as a ball when playing with an infant, which would make the shape
domain particularly prominent.
In section 1.6.5, the following equation was used to define a Euclidean distance measure, where the
dimensions are weighted:
Table 4.1
Domains and regions in the representation of "apple"
Domain
Region
Color
Red-yellow-green
Shape
Roundish (cycloid)
Texture
Smooth
Taste
Regions of the sweet and sour dimensions
Fruit
Specification of seed structure, flesh and peel type, etc. according to principles of pomology
Nutrition
Values of sugar content, vitamins, fibers, etc.
  

The weights wi  can be seen as context-dependent variables that represent the relative degree of salience
assigned to different dimensions. In this model the distance between two objects x and y, and
consequently their degree of similarity, is not constant but depends on changes in salience of the
dimensions of the objects: similarity varies both with the magnitude of the difference between stimuli on
the dimensions and with the dimension weights. 113
The knowledge and interests of the user will also influence the salience weights. For example (following
Bartsch 1996, 426), one can talk about taking different perspectives when using a concept. Taking a
particular perspective means giving some domain particular attention. The salience of different domains
determines which associations can be made and, to some extent, which inferences can be triggered by a
particular use of a concept, as will be shown in section 4.7. In a context of moving furniture, for example,
the weight dimension becomes highly prominent. Hence, the concept piano may lead to an association of 
heavy. In contrast, in a context of musical instruments, the weight dimension is much less important and
an application of the concept piano will probably not become associated with heavy (Barclay et al. 1974).
In addition to salience effects, which means putting extra weight on an entire dimension, Goldstone
(1994a) presents some empirical results that show subjects can be trained to become sensitized to certain 
areas of a dimension so that the perceived length of the area is increased in categorization tasks. The
effect means that the metric of the dimension is changed locally, for example by "stretching" distances in a
certain region. To borrow an example from Goldstone, suppose that objects are categorized by their
length, and objects that are 1 or 2 cm belong to one category, while objects that are 3 or 4 cm belong to
another. By attending to the gap between 2 and 3cm, subjects will selectively highlight this difference so
that, as a consequence, the perceived distance between 2 and 3 cm objects will become larger than the
perceived distance between 1 and 2 cm (or between 3 and 4 cm). This selective attention will effect the
similarity judgments of the subjects. Goldstone (1994a) also found "competition" for sensitization
between dimensions so that dimension x is more sensitized when categorization depends only on
dimension x than when it depends on both dimensions x and y. This kind of competition was stronger for
separable than for integral dimensions.
Concepts are not just bundles of properties. The proposed representation of a concept also includes an
account of the correlations between the regions from different domains that are associated with the 
concept.
  

In the "apple" example, there is a very strong (positive) correlation between the sweetness in the taste
domain and the sugar content in the nutrition domain and a weaker correlation between the color red and a
sweet taste. As shown in sections 4.7 and 6.6, there are several ways of modeling such connections in
technical representations of concepts.
Condensing the previous considerations of salience and correlations results in the following general
definition of concept representation:
CRITERION C A natural concept is represented as a set of regions in a number of domains together with an
assignment of salience weights to the domains and information about how the regions in different domains
are correlated.
To give a more precise model of a particular concept, however, several aspects of criterion C must be
specified in more detail. For example, the notion of a "region" can be made more exact by using one of the
definitions from section 3.5, leading to more special kinds of concepts based on connected, star-shaped, or
convex regions. Even though criterion C makes concepts partly context-dependent, it is rich in empirical
predictions, as will be seen later in the chapter.
In this analysis of concepts, I have tried to bring in elements from other theories in psychology and
linguistics. The kind of representation proposed in criterion C is on the surface similar to frames with slots
for different features that have been very popular within the cognitive science as well as linguistics and
computer science (from Minsky 1975 and on). My definition is richer since a representation based on
conceptual spaces will allow me to talk about concepts being close to each other and about objects being
more or less central representatives of a concept. My model combines frames with prototype theory,
although the geometry of the domains will make possible predictions that cannot be made in either frame
theory or prototype theory. Other related ideas about concept representation can be found in, among
others, Langacker (1987, 154-166), Smith et al. (1988), Barsalou (1992), Holmqvist (1993), and Hampton
(1993, 1998).
The main difference among these theories and the one presented here is that I put greater emphasis on the
geometrical structure of the concept representations. For example, features in frames are often represented
in a symbolic form. As will be seen in the following sections, the geometrical structures are cardinal in the
analysis of combinations of concepts, learning, and the nonmonotonic aspects of concepts.
4.2.2 Essential Properties and the Theory-Theory of Concepts
Some models of concepts, presume a distinction between essential and incidental properties. This idea
goes back to Aristotle’s theory of
  

essences. In modern psychological theories (see for example Osherson and Smith 1981, Rips 1995), "core"
properties are supposed to determine the meaning of concepts, while other "peripheral" properties
(KÃ¶vescezs 1993) only have diagnostic value. The core is considered to be those properties that are
essential to the concepts, while the peripheral properties do not determine whether something belongs to
the concept or not, even though peripheral properties may be helpful in "identification procedures"
(Osherson and Smith 1981). To repeat a classical example, "rational" and "animal’’ are essential
properties of "human," while "featherless" and "bipedal" are peripheral. Sometimes the position is
formulated as perception versus conception: perception delivers the peripheral properties, which may
serve as cues for conception where the essential properties are represented.
This kind of psychological essentialism does not fit well with the instrumentalist cognitive epistemology
of this book. A way out of the potential conflict is provided in the following quotation from Medin (1989,
1477), where he gives the following explanation of why people have a tendency to behave as if
psychological essentialism is valid: 114
If psychological essentialism is bad metaphysics, why should people act as if things had essences? The reason is
that it may prove to be good epistemology. One could say that people adopt an essentialist heuristic, namely, the
hypothesis that things that look alike tend to share deeper properties (similarities). Our perceptual and conceptual
systems appear to have evolved such that the essentialist heuristic is very often correct. . . .
In criterion C, the distinction between essential and core properties is not assumed. I believe that a theory
of concepts can do without it. First of all, the present theory is conceptualistic. Human categorizations are
based on how we represent things mentally, not on what ultimate physical properties they have. Hence,
even if there were "real" essences in the world, they could not be allowed in theory. Locke formulated the
idea elegantly in his Essay:
Nor indeed can we rank and sort things, and consequently (which is the end of sorting) denominate them, by their
essences; because we know them not. Our faculties carry us no further towards the knowledge and distinction of
substances, than a collection of those sensible ideas which toe observe in them. . . . When we come to examine the
stones we tread on, or the iron we daily handle, we presently find we know not their make; and can give no reason
of the different qualities we find in them. . . .  A blind man may as soon sort things by their colours, and he that has
lost his smell as
  

well distinguish a lily and a rose by their odours, as by those internal constitutions which he knows not.
(1690/1959, book III, chapter VI, 9)
Second, the role core properties play in essentialist theories of concepts can be taken over by the notion of
salience. 115 A "core" (essential) property of a concept is a property that belongs to a domain with a high
degree of salience, while a "peripheral" property is associated with a domain with lower salience. Radical
essentialism then corresponds to assigning extreme salience to some "essential" domains when
determining the content of a concept. I see no need, however, to introduce any definite distinction between
what counts as sufficiently high or low degree of salience. Furthermore, the salience weights of different
domains vary depending on the context. Hence, what appears to be a core property in one context may
seem peripheral in another. The problems philosophers and psychologists have had in identifying the
essential properties of various concepts is a symptom of the fact that there is no sharp border between core
and peripheral properties. For example, Smith and Heise (1992, 244) describe how categorization
judgments depend on the task given to the subject:
[A] demonstration that children perceive a bat and crow to be similar in a classification task and a crow and
flamingo to be similar in the category induction task need not mean that children shifted from perceptual similarity
to conceptual similarity when asked to make inductions. They may only have shifted the perceptual feature
weights. Perceptual similarity may have played the key role in both judgments.
Some psychologist have criticized the prototype theory and other similarity-based theories of concept
formation and proposed a so-called "theory-theory" of concepts (for example, Nelson 1974, Keil 1979,
Murphy and Medin 1985, Rips 1989, Medin and Ortony 1989, Gopnik and Meltzoff 1997). The basic idea
is that concepts should be thought of as embedded in knowledge that contains theories of the world
(Murphy and Medin 1985). These theories are supposed to contain information on the origins and causes
of category membershipâthe "core" of the concepts. For this reason, the theory-theory is closely related to
theories of psychological essentialism: the theories are about the essences of the concepts.
It would take too long to go into the details of the theory-theory or of the battle with similarity-based
theories of concepts. One weakness of theory-theories, however, is that they hardly give any account of 
how the assumed theories are represented in cognitive systems. And,
  

assuming that they are expressed symbolically, this would amount to putting the cart before the horse
(compare the criticism of the symbolic approach in section 2.2.2). Furthermore, it is not clear what can
count as a theory: if everything can, then the theory-theory is empty. 116 For one attempt to specify what a
theory is in this context, see Gopnik and Meltzoff (1997, 32-41). I believe, however, that most of the
features they claim are characteristic of theories could be accounted for on the basis of similarity as well,
in particular, if dynamic conceptual spaces are considered.
Smith and Samuelson (1997, 165) summarize the criticism against the theory-theory as follows:
First, there is no consensus as to what naive theories are, how they are mentally represented, or what kinds of
knowledge are included. . . . Secondly, there is no well-formulated account of any natural category within this
framework. Thus, once again, there is no demonstration that this kind of theory can actually do the job of
explaining human category judgements. Thirdly, even amidst the vagueness of these accounts, naive theories
clearly do not explain all the data. For example, they offer no account of why robins are psychologically better
birds than blue jays.
Much of the criticism from theory-theorists against similarity-based accounts of concept formation has
been based on the assumption that similarity is too general and that no constraints have been provided on
what counts as a feature in analyses of similarity (Murphy and Medin 1985, 292). If similarity is
connected to distances in conceptual spaces, as it is in this book, the criticism loses much of its force.
Other accounts have presumed that similarity is purely perceptual (compare, for example, Rips 1989).
Once some domains other than the basic perceptual dimensions are given higher salience weights,
however, then there can be no simple perceptual account of similarity. For example, folk botany may
classify plants according to the color or shape of the flowers and leaves, but after Linnaeus the number of
pistils and stamens became the most important dimensions for botanical categorizations. And these
dimensions are perceptually much less salient than the color or shape domains. Shifts of attention to other
domains thus also involve a shift in overall similarity judgments. The general trend in the development of
the categorizations of a domain is toward less dependence on perceptual similarity.117
For more advanced concepts, the perceptually grounded similarity can be transfered to abstract domains
by metaphoric mappings. Such mappings will be studied in section 5.6.
  

Furthermore, I believe that most of the role that the theories are supposed to play in representations of
concepts can be taken over by the dimensions or domains that are considered to have the highest salience.
In many cases these domains may not be perceptual, but indeed correspond to what is conceived of as 
theoretical entities in science (discussed in section 6.4). 118 From this perspective, there may be no
fundamental conflict between a similarity-based theory of the kind developed in this book and a
theory-theory. In theories there is also similarity behind the scenes. Hahn and Chater (1997, 50) conclude:
"Thus theory-based views demand a better account of similarity, rather than no account of similarity in
explaining concepts."
4.3 The Role of Similarity in Concept Formation
4.3.1 Similarity as a Theoretical Construct
One of the most fundamental notions in the study of concept formation is that of similarity: concepts
group together things that are similar. The notion of similarity, however, is also central to many other
aspects of cognition like learning, memory, and perceptual organization. For example, Shepard and
Chipman (1970) and Edelman (1996) go so far as to claim that representation is representation of 
similarities. By this they mean that representations need not be similar to the objects they represent. What
is important is that the representations preserve the similarity relations between the objects they represent
(compare section 1.5).
I focus here on the question of what role similarity plays in concept formation and categorization. The
ultimate goal is to show how a theory of similarity can be used to explain why people and animals form
the kind of concepts that they do.
Goodman (1972, 437) challenges the very meaningfulness of the notion of similarity. He says, "Similarity,
I submit, is insidious. . . . Similarity, ever ready to solve philosophical problems and overcome obstacles,
is a pretender, an impostor, a quack." He also states, "First, we must recognize that similarity is relative
and variable, as undependable as indispensable. Clear enough when closely confined by context and
circumstances in ordinary discourse, it is hopelessly ambiguous when torn loose" (1972, 444).
Goodman argues that there is nothing like overall similarity that can be universally measured, but we
always have to say in what respects two things are similar. Similarity judgments will thus crucially depend
on the context in which they occur. My interpretation of this point is that the degree of similarity between
two things must always be determined relative to a particular domain (or dimension) as defined in
  

section 1.8. Things are similar in color or size, or in any other domain, but they are not similar tout court. 
119 The domain that is considered when a similarity judgment is made is often determined by the context
of the judgment (Medin, Goldstone, and Gentner 1993).
A fundamental question about similarity that is often neglected is: what kind of quantity is similarity?
Among the few who address the question, one can distinguish three major positions:
1. Realism: Similarity is something that exists objectively in the world, independent of any perceptual or
other cognitive processes.
2. Conceptualism, empirical entity: Similarity is a cognitive magnitude that can be measured directly in
subjects. This can be done, for example, by asking them "to rate the similarity or dissimilarity of stimuli
on some scale or to judge which set of alternatives is most similar to some standard stimulus" (Medin,
Goldstone, and Gentner 1993, 255).
3. Conceptualism, theoretical entity: Similarity is a cognitive magnitude that is used as a theoretical entity
in models of categorization, concept formation, and so forth. If we follow Sneed’s (1971) analysis of
theoretical entities, similarity cannot be measured directly, but only determined by applying a theoretical 
model.120
In this book, I focus on cognitive phenomena. The question of whether things are inherently similar
independent of any cognizing subject will, in general, be irrelevant to my concerns. Realism is thus put
within brackets. The position adopted here is that similarity is best understood as a theoretical entity used
in cognitive models. According to position 3, any measurement of similarity, direct or indirect, will be
based on some assumptions concerning the properties of a similarity relation. Such assumptions come
from a more or less explicit theoretical model.
What is, then, an appropriate theoretical model? Similarity data from direct or indirect measurements are
usually interpreted as proximity data, giving information about the distance between objects in a
conceptual space (Hahn and Chater 1997, 54). Multidimensional scaling is a typical technique for
reconstructing spaces from similarity data (see section 1.7). The cognitive models that are studied here are
based on conceptual spaces. Consequently, it will be assumed that similarity can be modeled by using the 
distance measures in the conceptual spaces. I will assume that similarity is a function of distance (and
possibly some other factors) in a conceptual space. As described in section 1.6.5 (equations (1.7) and
(1.8)), a common assumption in the psychological literature (Shepard 1987, Nosofsky 1988b, 1992, Hahn
and Chater 1997) is that similarity is an exponentially decaying function of distance.
  




































figure 4.11c below. Our graphics program always used a circle as the aperture of the shell.
Figure 4.11 shows some examples of shapes that are produced by different combinations of values for the
coordinates. All shell pictures here and in the following are generated by our program. The only input to
the program are the three coordinates.
The three dimensions V, E, and R, span a space of possible shell shapes that is suitable for testing the four
models of categorization described above. The conceptual space is defined, however, with the aid of three
mathematical dimensions. As a preliminary step, it is
Figure 4.11
Some examples of shell shapes drawn by the graphics program
 together with their generating coordinates rate of whorl
 expansion, vertical growth, growth of radius of aperture.

  

necessary to test the psychological validity of the hypothesis that our perceptions of shells also form a
three-dimensional space. But even if the phenomenal shell space is three-dimensional, it does not follow
that the metric of the space is the same as the mathematical coordinates used by the graphics program. 151
Before we can apply the four categorization models, it is necessary to establish the relevant psychological
metric, the so-called scaling solution, of the shell space.
This methodology is supported by Shepard’s (1987, 1318) recommendations for how psychological laws
should be obtained:
Analogously in psychology, a law that is invariant across perceptual dimensions, modalities, individuals, and
species may be attained only by formulating the law with respect to the appropriate abstract psychological space.
The previously troublesome variations in the gradient of generalisation might then be attributable to variations in
the psycho-physical function that, for each individual, maps physical parameter space (the space whose
coordinates include the physical intensity, frequency, and orientation of each stimulus) into that individual’s
psychological space. If so, a purely psychological function relating generalisations to distance in such a
psychological space might attain invariance.
The three dimensions given by Raup’s (1966) model are not the most natural ones from a perceptual point
of view. We found that when estimating the vertical and horizontal growth rates of shells, subjects do not
look at the center of the generating circle. Instead, they focus on its extreme points in the vertical and
horizontal direction, loosely speaking the height and width of the shell. The vertical and horizontal
expansion rates should instead be described by the following values:
Using the space generated by the dimensions V’, E’, and R, we wanted to check whether further
transformations of the dimensions were necessary to obtain a satisfactory description of subjects’
perceptions of shell forms. The transformations we tested for each of the dimensions were instances of
Stevens’ power law d’(x) = w Â· (d(x))b, where w is the weight of the dimension.152 Since there were
three dimensions (V’, E’, and R), we estimated the values of six parameters wV’, wE’, wR  and bV’, bE’, 
bR. The optimal vector according to our analysis was (1, 1.55, 1, 1.72, 1, 0.99) which gave a correlation
with subjects’ average answers as high as 0.92.
  

These results strongly confirm our hypothesis that it is possible to identify an underlying perceptual space
of shell shapes with sufficient accuracy. Since small changes of the optimal vector resulted in clearly
smaller correlation coefficients, we decided to use the calibrated shell space that was generated by this
vector in the main experiments.
There are several reasons why shell shapes constitute a useful domain for empirical investigations:
1. It is possible to generate a great number of fairly realistic shell shapes in a conceptual space that is built
up from three dimensions.
2. The shells can easily be drawn by a graphic computer program where the only inputs are three
coordinates in the shell space.
3. The pictures generated by our program are identified by the subjects as pictures of realistic 3-D shells.
They are thus much more natural than most of the stimuli used in classification tasks in current cognitive
psychology, for example, the dot-patterns (Posner and Keele 1968, Shin and Nosofsky 1992) or the
semicircles with an additional radius (Nosofsky 1986, Ashby and Lee 1991). Not even the schematic faces
used by Reed (1972) have a very high degree of "ecological validity" (Gibson 1979).
4. Even though test subjects recognize the object on the pictures as shells, they usually have no
"prejudices" about how shells are actually categorized in biology in the sense that they have not already
partitioned the shell space into categories. Consequently, in an experimental set-up, one can "create" new
concepts for the subjects by showing appropriate shells, that is, more or less prototypical examples, in a
desired region of the shell space. These newly learned concepts will then not be disturbed by prior
categorizations of the space.
In the categorizations of the shells in our experiments, we assumed that only the shape domain is relevant.
This is a simplifying assumption, since there may, of course, be other domains that influence the behavior
of the subjects. The strong correlation between the values of the predictive model and the subjects’
average answers, however, attest that other domains only have a marginal influence.
4.11 Experiments
The goal of the two main experiments was to evaluate the four categorization rules that were presented in
section 4.9, that is, nearest neighbor categorization (NN), generalized Voronoi categorization (GV),
prototype Voronoi categorization (PV), and average distance
  

categorization (AD). The preliminary results from the pilot studies indicate that the best predictors are NN
and GV.
The two main categorization experiments were based on different setups. In the first experiment, all the
exemplars used to induce a category for a subject were visible on sheets of paper during the classifications
of new test shells so that exemplars and test shells could be directly compared. We later assumed that such
a setup would favor the NN model, which functions by comparing test shells to the exemplars. In contrast,
the second experiment required subjects to learn the category from the exemplars presented on a computer
screen. These exemplars were not shown when the new shells to be classified were presented.
4.11.1 Experiment 1
We expected that the closer a shell lies to a border between two categories in the psychological space, the
more diversity we will find in the classification answers from the subjects. To model this intuition, we
defined, for each of the four categorization models, a predicted response frequency for a given category x.
Each of the four models provides a distance measure that determines the distance from the stimulus shell x
to any category n. For PV, dPV (x, n) is the distance between x and the prototype for category n. For GV, 
dGV (x, n) is the distance between x and the prototypical circle for category n. 153 For NN, dNN (x, n) is
the distance between x and the nearest shell in category n. For AD, dAD (x, n) is the average distance
between x and the instances of category n.
If dM (x, n) is the distance function for one of the four models, we then define the predicted response
frequency pM (x, n), the predicted number of times subjects will answer that the shell represented by x will
belong to category n, by the following equation:
The main method of evaluating the predictive power of any of the four models is to compute the
correlation between the predicted response frequency and the actual frequency.
The experimental data were classification judgments from the subjects. They first saw two (or sometimes
three) groups of pictures of shells (three or four shells in each group). They were then shown a picture of a
new shell and asked to classify this shell into one of the two (three) groups. In the trials where only two
groups were involved, one sheet of paper with four exemplars of one group of shells, the "A-shells," was
put on one side of a central sheet, and one sheet with four pictures of another group, the "B-shells," was
put on the other side (the three sheets are presented simultaneously in figure 4.12). For each of the ten
trials, between four and five pictures of test shells to be classified were then presented in a random order
to the subjects.
  

Figure 4.12
Example of classification of shells. Subjects were asked to check one of the squares.
In three of the ten trials, there were examples of three groups, "A-shells," "B-shells," and "C-shells.’’ The
purpose of these trials was to study the effects of adding a new category to a classification trial. For each
test shell in all of the trials, the subjects were required to make a two-alternative (or three-alternative)
forced choice decision, indicating whether the shell on the middle sheet was an A-shell or a B-shell (or a 
C-shell).
For each test shell x, let f(x, A) be the actual frequency of subjects that classified x as an A-shell. For each
model M among the four we studied, this number was compared to the predicted answer frequency pM (x, 
A). For each model, we computed the average squared sum of errors 
 ,
where n is the number of test shells involved. The smaller the SSE-value is for a model, the better is its
predictive capacity.

  

The results suggest that NN has the best predictive power, while GV has the worst; however, the
differences were not significant at the 5 percent level (t-test). 154 It should be remembered that we
selected test shells that were close to the border lines between the categories that were generated by the
four different models. One hypothesis that we formed at this stage concerned the case when the
classification is a border-line case, in the sense that the test shell is perceived to be as similar to the
A-shells as to the B-shells. In this case we predicted that subjects tend to focus on the A- or B-shells that
are most similar to the test shell, which means that they employ the NN model so that the other models
would not be applicable.
On the trials having variants with three categories, the results strongly support that the relations between
the A- and B-category remained stable after the addition of the C-shells.
In experiment 1, the subjects could see the different examples of A-and B-shells during all trials. This is
an advantage for the NN model since it benefits from visible examples. An easily accessible strategy
(which may be unconsciously used by the subjects) is that to classify a test shell as an A- or a B-shell, a
subject identifies the example among the displayed A- and B-shells that is most similar to the test shell
and then classifies the test shell according to this example.
4.11.2 Experiment 2
In the second experiment, the shells were presented on a computer screen and not on paper sheets. The
experiment was run in two phases. First, examples of A- and B-shells (and sometimes C-shells) were
presented to the subjects and they were trained to remember the exemplars so that they could be correctly
classified. The purpose of this identification learning was to induce the subjects to create some form of
internal representation of the two (or three) categories.155 Hence, the similarity judgments necessary for
the NN model could not be based on direct visual information.
Only after this phase was completed could the subject see and classify new test shells in the same way as
in experiment 1, but now the test shells were presented alone on the computer screen without the presence
of the exemplars from the learning phase. Our hypothesis was that since this experimental setup blocked
the visual availability of the different examples, we would obtain a better evaluation of the predictive
power of the four categorization models, in particular the results of GV and NN.
In the learning phase, the subjects were instructed to determine what kind of shell was shown (without
seeing the original pictures). The response time of the subject was measured by the program. The sub-
  

ject was informed by the program whether or not the response was correct. The identification learning
procedure continued until the subject showed an error rate of less than 10 percent.
In the test phase, the subjects were presented with a series of test shells that were always different from the
example shells. The subjects were asked to classify the test shell as one of the two (or three) categories
that had been studied in the learning phase. Again, the response time was measured.
We hypothesized that the "naturalness" of a class of examples would be reflected in the difficulty of
learning to correctly classify these examples in the first phase of a trial. To operationalize this we
measured several variables, including learning rounds, which were defined as the number of presentations
of the example shells that had to be made before a subject passed the 90 percent correctness level, 
learning time, which is the time a subject spent studying the screen with the two or three classes of
examples before pressing the "ready" button, and learning errors, which were defined as the total number
of classification errors during the learning phase. Apart from these three learning variables, we also
measured classification time, which is the time it took for a subject to classify a test shell as an A- or
B-shell (or C-shell) after it was presented on the screen.
First of all, when evaluating the results, the predictive accuracy of the models should be compared. This
was done by calculating the average squared sum of errors (SSE) values for each trial.
The predictive power of the models was quite good. Out of the 34 test examples, PV made the same
classification prediction as the majority of the subjects in 25 cases, GV in 26 cases, NN in 30 and AD in
22 cases. These figures should be seen as high since we have deliberately chosen test examples that are
"difficult" in that they represent border cases for the categorization rules.
Our general hypothesis was that NN performed better than GV when the categorizations were "unnatural,"
that is, when the examples of a category were spread out over a large area of the shell space (like the
B-shells in figure 4.10). Thus, the results of the models should be compared to the performance measures
that were introduced above. The correlations among the three learning variables above were very high.
Each of these will thus function as a reliable indicator of the difficulty for the subjects in forming the
categorizations from the learning examples presented to them.
A central result of our investigation is the correlations between the SSE of GV and NN, which can be seen
as measures of the predictive powers of the two models, and the performance values. The results suggest
that there is a general negative correlation between how
  

"natural" the concepts to be learned in the classifications trials are and the degree of misfit of PV, NN, and
AD. Thus, these models have a smaller misfit when the trials are unnatural. The converse is true of GV
which handles the "natural" concepts better, although the correlations are not quite as strong in this 
direction.
The general conclusion to be drawn from the two experiments is that none of the four models is superior
overall to the others in explaining the subjects’ classifications in all situations. In the process of testing the
models, however, we have discovered that the difficulty in forming new categories and remembering them
can vary enormously. We have used a number of performance measures (learning rounds, learning time,
learning errors, and classification time) that serve as good indicators of the difficulty of forming a
category from some exemplars. The strong correlations between these measures support their validity.
If the "naturalness" of a categorization trial is taken into account, a clearer pattern in the performance of
the four models can be seen. If the exemplars used to generate a category form a "natural kind" so that
categorization is "easy," then the GV model is the best predictor of the test results. On the other hand, if
categorization is "unnatural,’’ as measured by the indicators used above, then the NN model appears to
perform best.
Summing up, the experiments have shown that the shell space is an example of a conceptual space that
can become a rich source for investigations of human concept formation. The stimuli that are generated by
the graphics program have a high degree of "ecological validity" (in the sense of Gibson 1979) compared
to other kinds of stimuli that have been used in categorization experiments. Perhaps the most important
finding of our experiments is that the level of "naturalness" of categorization, as measured by the
indicators we have identified, has been shown to play an important role in the performance of the models.
  

Chapter 5â
Semantics
5.1 What Is a Semantics?
5.1.1 Questions for a Semantic Theory
Everybody agrees that semantics concerns the relation between the words or expressions of a language
and their meanings. But when it comes to explicating this relation, opinons soon diverge. As a
consequence, there is a long-standing philosophical dispute concerning the meaning of "meaning." The
semantic relation can, however, be studied from several perspectives. The aim here is not to settle the
debate, but to structure it around four basic questions that a theory of semantics should be able to answer:
1. What are meanings? (the ontological question)
2. What is the relation between linguistic expressions and their meanings? (the semantic question)
3. How can the coupling between linguistic expressions and their meanings be learned? (the learnability 
question)
4. How do we communicate meanings? (the communicative question)
On the ontological question, a first division concerns whether semantics is referential or notâwhether there
are some kinds of objects that are the meanings of linguistic expressions. Within modern philosophy of
language, one can find two fundamentally different referential answers to the ontological question, one 
realist and one cognitive (or conceptualist). 156 In the realist approach to semantics, the meaning of a
word or expression is something out there in the world. According to the cognitivist answer, meanings are 
mental entitiesâthings in the head. This chapter outlines how the theory of conceptual spaces can be used
as a basis for a cognitive semantics.
Within the philosophy of language there is also a functionalist tradition of meaning that is nonreferential.
An excellent survey of this tradition is given by Harder (1996, chapter 4). Perhaps the most well-known
proponent of this view is the later Wittgenstein, who in
  

Philosophical Investigations (1953) defended a view that is often summarized by the slogan "meaning is
use." Harder (1996, 101) provides this more precise account of the functionalist notion of meaning: "The
(linguistic) meaning of a linguistic expression is its (canonical, proper) communicative function, i.e. its
potential contribution to the communicative function of utterances of which it forms part."
He relates this definition to the position of the later Wittgenstein:
The definition that equates the meaning of a word with its function (rather than with the representational content
itself) updates Wittgenstein’s famous dictum about meaning as use in two ways. First, it explicitly filters off
accidental aspects of the use of an expression; secondly, it avoids the antimentalistic stance: the mental element is
necessary, but does not in itself constitute meaningâmeaning needs to be understood as communicative potential
for the speaker. (Harder 1996, 105)
By explicitly defining meaning as communication, however, the functionalist tradition makes meaning a
part of pragmatics rather than part of a narrower semantic theory. There is no immediate conflict between
a functionalist position and the cognitivist theory that will be focused on here. Even though I agree with
the functionalists that part of the meaning of some expressions is only determined in the context of its use,
I want to argue that for many kinds of expressions a semantic meaning can be modeled independently of
its communicative use. 157
Why is the ontological status of meanings so important? Apart from its long-standing philosophical
bearings, a different kind of motivation comes from the constructive aims of cognitive science. When
building robots that are capable of linguistic communication, the constructor must decide at an early stage
how the robot grasps the meaning of words. A fundamental methodological decision is whether the
meanings are determined by the state of the world or whether they are based on the robot’s internal model
of the world. I view only the latter option as a viable alternative.158
5.1.2 A Classification of Semantic Theories
For the referential types of semantics one needs to account for how linguistic expressions are related to
their meanings. Realist semantics comes in two flavors: extensional and intensional. These positions have
been presented in section 3.2 in connection with the analysis of properties. In the extensional type of
semantics, the constituents of the language become mapped onto a "world." Names are mapped onto
objects, predicates are mapped onto sets of objects or relations between
  

objects, and so forth. By compositions of these mappings, sentences are mapped onto truth values.
The main objective of this kind of semantics is to formulate truth conditions for the sentences in the
language. Such conditions are supposed to determine the meaning of the expressions in that they specify
the way the world should be constituted if the sentences of the language are to be true. By specifying truth
conditions, one intends to describe the semantic knowledge of competent speakers. A consequence of this
approach is that the meaning of an expression is independent of how individual users understand it. The
first developed theory of this type is Frege’s semantics, but it acquires a more precise form in Tarski’s
theory of truth. Schematically, the semantic mapping can be illustrated as in figure 5.1.
The extensional theory of reference implicit in this kind of semantics was soon found to be wanting as an
account of several phenomena in natural languages. To handle some of these problems, so-called 
intensional semantics was developed by logicians and linguists. In this brand of semantics, the set of
linguistic expressions is mapped onto a set of possible worlds instead of only a single world (compare
section 3.2). The goal of intensional semantics is still to provide truth conditions for the sentences. The
meaning of a sentence is taken to be a proposition that is identified with a set of possible worlds: the set of
worlds where the sentence is true. The setting can be illustrated as in figure 5.2.
Figure 5.1
The ontology of extensional semantics.
Figure 5.2
The ontology of intensional semantics.
  

As an alternative to possible worlds semantics, situation semantics was developed during the 1980s (see,
for example, Barwise and Perry 1983). Instead of mapping the linguistic expressions onto a set of possible
worlds, they were connected to "situations." Situations consist of a number of "facts" that are built up from
relations among individuals. Instead of a truth value, a fact contains a ’’polarity value" that expresses
whether the fact holds in the situation or not. Situations are partial descriptions of the world (Barwise
1981). Consequently, situation semantics is also a branch of realist semantics. The general structure is
illustrated in figure 5.3.
We next turn to the conceptualist (alias cognitive) approach to the semantic question which will be the
focus of this chapter. The core idea is that meanings of linguistic expressions are mental entitiesâmeanings
are elements of the cognitive structure in the heads of the language users. 159 Language itself is seen as
part of the cognitive structure and not an entity with independent standing. The framework of cognitive
semantics can be illustrated as in figure 5.4.
A semantics is described as a mapping from the expressions to a conceptual structure. This mapping can
be seen as a set of associations between words and meaningsâassociations that have been established
when the individual learned the language. According to this view, language represents a conceptual
structure, but it does not directly represent the world (see below).
Figure 5.3
The ontology of situation semantics.
Figure 5.4
The components of cognitive semantics.
  

A special case of such a mapping is Jackendoff’s "conceptual semantics" where the mapping between the
linguistic expressions and the conceptual structure is seen as a cognitive version of the model-theoretic
semantics developed by Tarski or Kripke (see Jackendoff 1990, 12-13). For Jackendoff, the meaning
relation is described by traditional truth conditions, with the exception that the referents of the linguistic
expressions are mental representations instead of entities in an external world. In principle, this does not
put his position in conflict with the one proposed here. As argued in section 5.5, however, it is difficult to
combine truth conditions with the idea that the semantic mapping consists of associations between words
and meanings. Furthermore, Jackendoff does not exploit any geometrical structure of the mental 
representation.
Since both linguistic expressions and their meanings are in the head of an individual, a semantics for a
language is primarily connected to a single speaker (or listener). Prima facie, this appears to be an enigma
for the cognitive approach to semantics: meanings are things that are common to the language users. A
possible solution to this problem, which is essentially the communicative problem, is outlined in sections
5.9 and 5.10. The idea is that the conceptual structures of different individuals will become attuned to each
other, otherwise linguistic communication will break down. Thus, for practical purposes, cognitive
linguists often write as if every (adult) speaker of a language is endowed with the same conceptual 
structure.
Interestingly enough, something very much like a conceptualist theory of semantics is found in Aristotle’s 
De Interpretatione. The following is an excerpt from the first paragraph of E. M. Edghill’s translation:
"Spoken words are the symbols of mental experience and written words are the symbols of spoken words.
Just as all men have not the same writing, so all men have not the same speech sounds, but the mental
experiences, which these directly symbolize, are the same for all, as also are those things of which our
experiences are the images."
Aristotle makes a distinction between "mental experiences" and the "things" of which the experiences are
’’images." Furthermore, spoken or written words refer to the mental experiences and not to any external
reality. He assumes, however, that the mental experience of all speakers is the same. This is not obvious
for a cognitive theory of semantics since individual conceptual structures, and thereby meanings, may be
very different prima facie.
De Saussure (1966) also proposes a conceptualist analysis of the signification relation. The following
excerpt from the first paragraph of his first chapter illustrates this:
  

[F]or some people a language, reduced to its essentials, is a nomenclature: a list of terms corresponding to a list of
things. . . . This conception is open to a number of objections. It assumes that ideas already exist independently of
words. . . . It does not clarify whether the name is a vocal or psychological entity. . . . Furthermore, it leads one to
assume that the link between a name and a thing is something quite unproblematic, which is far from being the
case. None the less, this naive view contains one element of truth, which is that linguistic units are dual in nature,
comprising two elements. . . .
[T]he two elements involved in the linguistic sign are both psychological and are connected in the brain by an
associative link. This is a point of major importance.
A linguistic sign is not a link between a thing and a name, but between a concept and a sound pattern.
Like Aristotle, de Saussure appears to assume that the linguistic signâthe link between a concept and a
sound patternâis the same for all users of a language.
5.1.3 The Relation between the Conceptual Structure and the World
In figure 5.4 the nature of the relation between the conceptual structure and the world is left unspecified.
We have a strong sense that some of our utterances have a fit to reality. The question then is what is the
relation between the conceptual structure and reality according to cognitive semantic theories? There is no
unique answer to this question, but here I adopt a pragmatic account. 160 The appropriate question on the
relation between the conceptual structure and the world is whether a conceptual structure is viable or not.
Having a viable conceptual structure means that one is able to solve the essential problems when acting in
the world.
Via successful and less successful interactions with the world, the conceptual structure of an individual
will adapt to the structure of reality. It must be emphasized, however, that this does not entail that the
conceptual structure represents the world.161 Take color vision, for example, where Thompson (1995, 29)
defends a pragmatic view of conceptual structures:
[T]he biological function of colour vision is not to detect surface reflectance, but rather to generate a set of colour
categories that have significance for the perceptual guidance of activity. In my view, the categories that give
structure to colour perception are indeed modes of presentation in visual perception, but they are not modes of 
representation, at least not in the typical computational-
  

ist [realist] sense, because colour perception does not represent something that is already present in the world apart
from perceivers; rather, it presents the world in a manner that satisfies the perceiver’s adaptive ecological 
needs. . . .
The epistemological question of the relation between the conceptual structure and the world must be kept
separated from the semantic question of the relation between linguistic expressions and the conceptual
structure. Grasping the meanings of linguistic expressions is a combination of having the right
associations from the words to a conceptual structure and having a viable conceptual structure. A person
who has severe misunderstandings of the meanings of the words of a language will, by the failures of his
plans or his attempts to communicate, be forced to revise either his semantic mapping or his conceptual 
structure.
In particular, our conceptual representation of space must be well attuned both to our perceptions of space
and the way we express spatial structures in language. As Bryant (1997, 240) points out this is important ".
. . because of the need to coordinate action in space on the basis of perceptual and linguistic information.
In other words, one must move given what one has seen, but also given what one has been told. Effective
coordination of action depends on having a representational format that can incorporate both kinds of
information and extract the abstract, amodal structure of the environment."
This chapter attempts to show how the conceptual structure required for a cognitive semantics can be
modeled with the aid of conceptual spaces. To start, I discuss whether words or sentences form the
building blocks of a semantics. Then, in section 5.2, I outline some of the main tenets of cognitive
semantics as it has developed during the last years. This position will be contrasted with the extensional
and intensional semantics, but my goal is not primarily to criticize these kinds of semantics. 162 In the
following sections, the semantic model is then applied to some problems in lexical semantics, including a
theory of metaphors. The last part of the chapter treats the communicative question, arguing that semantics
cannot be seen as purely intramental (and individual), but that a certain social component, in the form of a
linguistic power structure, is also required.
5.1.4 Lexical Meaning versus Truth Conditions
Even though cognitive linguists often deny that there is a sharp distinction between lexicon and syntax, the
emphasis of the studies within cognitive semantics has been on lexical meaning rather than on the
meaning of sentences. Hence most of the analyses concern relations
  

between words and representations of concepts, for example, the "image schemas" developed by
Langacker (1987), Lakoff (1987), and Talmy (1988). Such schemas are abstract pictures constructed from
elementary topological and geometrical structures like "container," ’’link," and "source-path-goal." A
common assumption is that such schemas constitute the representational form that is common to
perception, memory, and semantic meaning. In contrast, traditional semantic theories within philosophy
have focused on logical operatorsâfor example, quantifiersâand sentences have been the main units of
analysis. Consequently, these two semantic traditions often talk past each other.
Within philosophical logic, the focus has been on sentences. In section 3.3, I presented Putnam’s theorem
that can be taken to show that the traditional truth-functional accounts of meaning do not work. It appears
that the point of Putnam’s theorem was anticipated, in an informal way, by Quine. 163 Assuming a
traditional truth-functional account of semantics, Quine writes (1979, 165):
What were observational were not terms but observation sentences. Sentences, in their truth or falsity, are what run
deep; ontology is by the way.
The point gains in vividness when we reflect on the multiplicity of possible interpretations of any consistent
formal system. For consider again our standard regimented notation, with a lexicon of interpreted predicates and
some fixed range of values for the variables of quantification. The sentences of this language that are true remain
true under countless reinterpretations of the predicates and revisions of the range of values of the variables.
The moral that Quine draws from this, however, is not that there is something wrong with
truth-conditional semantics (as I suggest). He prefers to retain the truth conditions and acknowledges that
reference is indeterministic:
Perhaps our primary concern belongs with the truth of sentences and with their truth conditions, rather than with
the reference of terms. If we adopt this attitude, questions of reference and ontology become incidental.
Ontological stipulations can play a role in the truth conditions of theoretical sentences, but a role that could be
played as well by any number of alternative ontological stipulations. The indecisiveness of ordinary language
toward questions of reference is the more readily excused. (1979, 165)
I do not agree. I maintain that a cognitive approach to semantics requires that meaning be separated from
truth conditions. The meaning
  

of an expression is a conceptual structure (with its own ontology) that must be determined before the
correspondence with the world, that is, truth conditions, can be discussed. In the analytic philosophy of
language emanating from Frege, it has been taken for granted that sentences are the principal carriers of
meaning, as witnessed in the quotation from Quine above. 164 Within model theory itself, however, this
has not been the case, since the "interpretations" of a formal language have been built up from
assignments of meanings to names and predicates. In addition to rejecting truth-functional semantics, I
believe that the semantics of words in general should be given primacy to a semantics of sentences. A
completely atomistic approach to meanings, however, cannot be upheld: the meaning of many verbs, for
instance, is inseparable from the syntactic context in which they appear.165
The root of the problem is that within analytic philosophy, language has been seen as an abstract system,
preferably formal and rule-based, that exists independently of its users and of other cognitive 
functions.166 In contrast, a cognitive approach to semantics puts language in the heads of the users and
connects it to perception, memory, action, and mental representation in general. It is, indeed, we that give
meaning to language.
5.2 Six Tenets of Cognitive Semantics
According to the cognitive view, semantics is a relation between linguistic expressions and a cognitive
structure. The main proposal here is that the appropriate framework for the cognitive structure is a
conceptual space. Some general aspects of using conceptual spaces as a foundation for a cognitive
semantics are discussed here. In particular, I want to show that conceptual spaces provide an appropriate 
ontology for such a semantics.
A programmatic presentation of cognitive semantics in the form of six tenets is presented here, together
with some comments (see also GÃ¤rdenfors 1996c). The approach of a cognitively oriented semantics
will be contrasted with the more traditional realist cum symbolic view. Prime examples of works in the
cognitive tradition are Lakoff’s (1987) and Langacker’s (1987, 1991a, 1991b). Related versions of
cognitive semantics can be found in the writings of Johnson-Laird (1983), Fauconnier (1985), Talmy
(1988), Rudzka-Ostyn (1988), Sweetser (1990), Holmqvist (1993), Allwood and GÃ¤rdenfors (1999), and
many others. There is also a French semiotic tradition, exemplified by DesclÃ©s (1985) and Petitot (1985,
1992, 1995), that shares many features with the American group. Jackendoff’s (1983, 1987a, 1990, 1997)
"conceptual semantics" shows some similarities, but he tries to marry it to a
  

Chomskian style of syntax. In the following sections, I give some examples of how the cognitive approach
to semantics can be merged with the theory of conceptual spaces.
I Meaning is a conceptual structure in a cognitive system (not truth conditions in possible worlds).
The prime slogan for cognitive semantics is meanings are in the head. More precisely, a semantics for a
language is seen as a mapping from the expressions of the language to some cognitive entities. Harnad
(1987, 550) says that ". . . the meanings of elementary symbols must be grounded in perceptual categories.
That is, symbols, which are manipulated only on the basis of their form (i.e., syntactically) rather than
their ’meaning,’ must be reducible to nonsymbolic, shape-preserving representations."
This thesis puts cognitive semantics in contact with psychological notions and makes it possible to talk
about a speaker "grasping" a meaning (compare Jackendoff 1983). As noted in the previous section, a
consequence of the cognitivist position that puts it in conflict with many other semantic theories is that no
reference to reality is necessary to determine the meaning of a linguistic expression. Jackendoff (1987a,
123) says, "The buck stops here: expressions at the level of conceptual structure simply are the meanings
of utterances." A related point is that the truth of expressions is considered to be secondary since truth
concerns the relation between a cognitive structure and the world. To put it tersely; meaning comes before 
truth.
Sometimes Fodor’s (1975) "language of thought" hypothesis is grouped with cognitive semantics, but the
two should be kept strictly separated. There are some superficial similarities, though: Fodor also uses
mental entities to represent linguistic information. This is his "language of thought" which is sometimes
also called ’’Mentalese." According to Fodor, this is what speakers use when they compute inferences
(according to some internal set of rules) and when they formulate verbal responses (translated back from
Mentalese to some appropriate natural language). The mental entities constituting Mentalese, however,
form a symbolic language with syntactic structures governed by some recursive set of rules. And when it
comes to the semantics of Mentalese, Fodor still is a realist and relies on references in the external world
as well as truth conditions (see Fodor 1975, 79-84).
II Conceptual structures are embodied (meaning is not independent of perception or of bodily experience).
Since the cognitive structures in our heads are connected to our perceptual mechanisms, directly or
indirectly, it follows that meanings are,
  

at least partly, perceptually grounded. 167 Jackendoff (1983, 16-18) formulates this as "the cognitive 
constraint":
There must be levels of mental representation at which information conveyed by language is compatible with
information from other peripheral systems such as vision, nonverbal audition, smell, kinesthesia, and so forth. If
there were no such levels, it would be impossible to use language to report sensory input. We couldn’t talk about
what we see and hear. Likewise, there must be a level at which linguistic information is compatible with
information eventually conveyed to the motor system, in order to account for our ability to carry out orders and 
instructions.
Following Johnson (1987) (and also Lakoff 1987, Clark 1997, Zlatev 1997, Bailey et al. 1998) it is
appropriate to go even further and say that meanings are embodied, that is, the conceptual structures are
tied to bodily experiences and to emotions. Conceptual spaces are well suited for modeling the perceptual
and embodied aspects of semantics since many basic dimensions have a grounding in perception or 
kinaesthetics.
The second tenet is also in conflict with traditional realist versions of semantics which claim that since
meaning is a mapping between the linguistic expressions and the external world (or several worlds),
meaning has nothing to do with perception. The relation between language and perception will be
discussed further in section 5.5 in connection with the learnability question.
III Semantic elements are constructed from geometrical or topological structures (not symbols that can be
composed according to some system of rules).
Instead of being a symbolic system, with syntactic structure like Mentalese, the conceptual schemes that
are used to represent meanings are often based on spatial or force dynamic constructions. As will be seen
in the following sections, conceptual spaces function very well as a framework for representing such
semantic elements.
In particular, there is a strong similarity between the domains of a conceptual space as defined in section
1.8 and the domains as used in Langacker’s (1987) semantic theory. The following quotation concerning
his notion strongly supports this thesis:
What occupies the lowest level in conceptual hierarchies? I am neutral in regard to the possible existence of
conceptual primitives. It is however necessary to posit a number of "basic domains," that is, cognitively irreducible
representational spaces
  

or fields of conceptual potential. Among these basic domains are the experience of time and our capacity for
dealing with two- and three-dimensional spatial configurations. There are basic domains associated with various
senses: color space (an array of possible color sensations), coordinated with the extension of the visual field; the
pitch scale; a range of possible temperature sensations (coordinated with positions on the body); and so on.
Emotive domains must also be assumed. It is possible that certain linguistic predications are characterized solely in
relation to one or more basic domains, for example time for (BEFORE), color space for (RED), or time and the
pitch scale for (BEEP). However, most expressions pertain to higher levels of conceptual organization and
presuppose nonbasic domains for their semantic characterization. (Langacker 1987, 5)
IV Cognitive models are primarily image-schematic (not propositional). Image-schemas are transformed by 
metaphoric and metonymic operations (which are treated as exceptional features on the traditional view).
The main metonymic operations are pars pro toto, where a part represents a whole as in "there are twenty
heads in the class room," and toto pro pars, where a whole represents a part as in "Paris announces shorter 
skirts."
The most important semantic structure in cognitive semantics is that of an image schema. A common
assumption is that such schemas constitute the form of representation common to perception, memory, and
semantic meaning (compare tenet II). Image schemas have an inherent spatial structure. Lakoff (1987) and
Johnson (1987) argue that schemas such as "container," "source-path-goal," and "link" are among the most
fundamental carriers of meaning. They also claim that most image schemas are closely connected to 
kinaesthetic experiences.
As an example of an image schema, consider Langacker’s (1991b, 22) depiction of "across" in figure 5.5.
According to Langacker, the meaning of "across" is a "complex atemporal relation" where one object, the 
trajector (the small circle in figure 5.5) is located in different relations to another elongated object, the 
landmark (the thick rectangle in figure 5.5). First, the trajector is outside the landmark, then it is inside,
and finally it is on the other side. The image schema contains two domains: a time dimension, marked by
the horizontal arrow at the bottom of figure 5.5, and two spatial dimensions, indicated by the thin
rectangle that is repeated five times in different stages of the crossing. Note that the geometrical notions
presumed in this schema are "elongated,’’ "outside," "inside," and "the other side," which are quite weak
in the sense that they do not presume that the space has a metric.
  

Figure 5.5
An image schema for "across" (from Langacker 1991b, 22)
Neither Lakoff nor Langacker, who use the notion extensively, give a very precise description of what
constitutes an image schema. Zlatev (1997, 40-44) argues that the notion is used in different ways by
different cognitive semanticists. The most condensed account I have found comes from Gibbs and Colston
(1995, 349), who define image schemas as "dynamic analog representations of spatial relations and
movements in space." Unlike Lakoff and Langacker, who focus on the spatial structure of image schemas,
this definition puts the dynamics of the representations in focus.
My proposal is that a more precise account of what constitutes an image schema can be given with the aid
of the theory of conceptual spaces. The image schemas are often just topological structures. A "container",
for example, is a closed border that separates space into "inside" and "outside." An object such as a cup
may count as a container even though is it not physically closed. Cognitively, the rim surface of the cup
functions as part of the border (see Herskovits 1986 for a discussion of how the border is determined). In
the following section, I give some examples of how the topological and geometrical structures of
conceptual spaces are helpful in modeling lexical meanings.
The writers within cognitive linguistics present lists of image schemas but never any analysis of which
schemas are possible and which are not. A developed theory of images schemas should present a
principled account of what constitutes a schema. A fascinating proposal in this direction is that of Thom
(1970, 232) who claims that any basic phrase expressing an interactive process can be described as one out
of sixteen fundamental types. Among these types one finds "begin," "unite," "capture," and "cut.’’ The
sixteen types are derived from some deep mathematical results on "morphologies" within
  

catastrophe theory. Even if there are excellent mathematical reasons why there are exactly sixteen types of
interaction, it is not obvious that they correspond neatly to cognitive representations, although such a
correspondence would be very gratifying.
An image schema is a conceptual structure that belongs to a particular individual. When the authors within
cognitive linguistics write about them, however, they are often presented as structures that are common to
all speakers of a language. In most situations this is a reasonable assumption for several reasons. One is
that since basic image schemas are supposed to represent perceptual and other bodily experiences, the very
fact that humans have similar constitutions make it likely that our representations are very similar.
Furthermore, if the image schema corresponding to a particular expression is markedly different for two
individuals, it is likely that this will lead to problems of communication. A desire for successful
communication will therefore lead to a gradual alignment among the members of a linguistic community
of the image schemas as well as their underlying conceptual spaces. This process will be further discussed
in sections 5.6 and 5.7.
Metaphors and metonymies have been notoriously difficult to handle within realist semantic theories. In
these theories such linguistic figures have been treated as deviant phenomena that have been ignored or
incorporated via special stylistic rules. In contrast, they are given key positions within cognitive
semantics. Not only poetic metaphors but also everyday "dead" metaphors are seen as central semantic
features and are given systematic analyses. One of the first works in this area was Lakoff and Johnson
(1980). Analyses of different kinds of metaphorical expressions have since then become one of the
trademarks of cognitive semantics (see, for example, Brugman 1981, Tourangeau and Sternberg 1982,
Indurkhya 1986, Lakoff 1987, 1994, Sweetser 1990, BrostrÃ¶m 1994, and GÃ¤rdenfors 1996b, 1996c).
Metaphors will be analyzed with the aid of conceptual spaces in section 5.4.
Metaphors and metonymies are primarily seen as cognitive operations, and their linguistic expression is
only a secondary phenomenon. They are analyzed as transformations of image schemas. Such
transformations involve operations on spatial structures. In line with this, Lakoff (1987, 283) puts forward
what he calls the "spatialization of form hypothesis" which says that the meanings of linguistic
expressions should be analyzed as spatial image schemas plus metaphorical mappings. For example, many
uses of prepositions, which primarily have a spatial meaning, are seen as metaphorical when applied to
other domains (see, for example, Brugman 1981 and Herskovits 1986).
  

V Semantics is primary to syntax and partly determines it (syntax cannot be described independently of 
semantics).
This thesis is anathema to the Chomskian tradition within linguistics. Within Chomsky’s school, grammar
is a formal calculus, which can be described via a system of rules, where the rules are formulated
independently of the meaning of the linguistic expressionsÂ· Semantics is something that is added, as a
secondary independent feature, to the grammatical rule system. Similar claims are made for pragmatic
aspects of language.
Within cognitive linguistics, semantics is the primary component (which, in the form of conceptual
representations, exists before, both phylogenetically and ontogenetically, syntax is fully developed). 168
The structure of the semantic schemas puts constraints on the possible grammars that can be used to
represent those schemas. Petitot (1995, 232), who is building on a proposal from Thom, formulates the
idea very clearly (see also Dixon 1982, 8):
One of our main theses is that syntactic structures linking participant roles in verbal actions are organized by
universals and invariants of a topological, geometric, and morphological nature. This thesis is deeply akin to the
work . . . concerning the central cognitive role of spatial and temporal Gestalten or image schemas. Actually, we
will show how constituent structures can be retrieved from the morphologial analysis of perceptual scenes.
Later on, he puts the position in stark contrast to the Chomskian symbolic theory:
The formal universals, which are not characterizable within the theory of formal grammars, need not necessarily
be conceived of as innate. They can be explained by cognitive universal structures. . . . Insofar as these structures
are not symbolic but of a topological and dynamical nature, there exists in syntax a deep iconicy. At this level,
semantics and syntax are inseparable: syntax is no longer an independent and autonomous linguistic dimensionÂ·
(Petitot 1995, 256)
Since the cognitive analysis focuses more on speech acts rather than on free-floating sentences, the
meaning of the modals is partly determined by a pragmatic analysis, and thus it does not provide just a
semantics in the sense of philosophical logic. Traditionally, semantics concerns the meaning of
expressions, while pragmatics concerns their use (but compare section 5.4.3 below). But if the meanings
of certain expressions, like the modal verbs studied in Talmy (1988) and Winter and GÃ¤rdenfors (1995),
cannot be determined without recourse to their
  

use, the traditional distinction between semantics and pragmatics may not be sustainable.
There is also a sense in which semantics to some extent not only determines syntax but also the logic of
the language. If the meanings of the predicates are determined by a mapping into regions of a conceptual
space S, it follows from the geometrical structure of different domains that certain statements will become 
analytically true in the sense that they are independent of empirical considerations. For example the fact
that comparative relations like "earlier than" are transitive follows from the linear structure of the time
dimension and is thus an analytic feature of this relation (analytic-in-S, that is). 169 Similarly, it is analytic
that everything that is green is colored, since "green" refers to a region of the color domain, and that
nothing is both red and green (all over), since these words refer to disjoint regions of the color domain.
Analytic-in-S can thus be defined on the basis of the topological and geometrical structure of the
conceptual space S together with the partitioning into regions for concepts.170 Since different conceptual
spaces, however, do not have the same underlying geometrical or topological structure, they will yield
different notions of analyticity.171
The Chomskian tradition within linguistics has been dominated by syntactic studies. Since grammars are
represented by formal rules, they are suitable for computer implementations. This kind of work has, to be
sure, been the main focus of computational linguistics.
Within cognitive semantics, computer friendly representations are much rarer. Implementing the
diagrammatic representations of Langacker’s and Lakoff’s image schemas are tough challenges for a
programmer. One notable exception is Holmqvist (1993, 1994, 1999), who develops implementable
representations of image schemas and other concepts from the cognitive linguists. To some extent, he is
inspired by Langacker’s compositional image schemas and Lang’s spatial models (see Lang, Carstensen,
and Simmons 1991), but he extends their formalisms to much richer computational structures in particular 
super-impositions of image schemas.172 In his (1994) he also utilizes an old idea of Behaghel to generate
grammatical structure from the valence expectations of different lexical items. The result is something that
looks like a rule-governed syntax, albeit there is no single explicit syntactic rule in the system. Also
Regier’s (1996) and Zlatev’s (1997) implementations of spatial expressions take some steps in this
direction. The upshot is that much of syntax is semantically motivated.173
VI Concepts show prototype effects (instead of following the Aristotelian paradigm based on necessary and
sufficient conditions).
  

The prototype theory of concepts was presented in section 3.8. Within cognitive semantics, one attempts
to account for prototype effects of concepts (Lakoff 1987). A concept is often represented in the form of
an image schema and such schemas can show variations just like birds and chairs. As we have seen,
prototype effects are difficult to model using traditional symbolic structures: the predicates that are used in
most formal representations are supposed to have a precise denotation and graded membership must be
represented in an ad hoc fashion.
5.3 Analyses of Some Aspects of Lexical Semantics
Here and in the following sections, I turn to lexical aspects of natural languages. I have no ambition of
providing a comprehensive analysis of the semantics of the lexical items of a language, but I will focus on
some areas where the theory of conceptual spaces has immediate applications. I intend to show that
geometry and topology are useful tools when analyzing meanings. The basis for the lexical analyses is the
following fundamental semantic thesis (L for "lexical"):
L: Basic lexical expressions in a language are represented semantically as natural concepts.
Here, "basic" should be taken in the sense of prototype theory (as discussed in sections 3.8) and "natural
concept" in the sense of section 4.2âbeing represented by a convex region of a conceptual space (or, as a
weaker claim, as connected or star-shaped regions). It is still rather unclear how far the applicability of
this thesis ranges. It can be given further content by being specified to the following grammatical 
categories:
LA: Basic adjectives are represented semantically as natural properties.
Recall that a property is a concept only represented in one domain (see section 3.1). 174
LV: Basic verbs are represented semantically as dynamic natural concepts.
By a dynamic concept, I mean a concept that involves the time domain (see section 3.9).
LN: Basic nouns are represented semantically as multidomain, nondynamic natural concepts (see section 
4.2).
Apart from these word classes, prepositions have been studied extensively within cognitive semantics (for
example, Herskovits 1986, Lakoff
  

1987, Bowermann 1991, Landau and Jackendoff 1993, Zwarts 1995, Regier 1996, Zlatev 1997, Zwarts
and Winter 1998, Helmantel 1998). The basic semantic function of prepositions is to express spatial 
relations, but they also have obtained a number of metaphorical and metonymic extensions. 175 A
neurolinguistic connection is brought forward by Landau and Jackendoff (1993), who propose that there
are two distinct cognitive systems for objects the "what" system, and for places the "where" system. These
systems are connected to two different pathways of the visual cortex. The separation of the systems result
in a separation between a nominal and a prepositional system in language.176
The criteria LA, LV, and LN should be seen as programmatic theses, and they will presumably have
numerous counterexamples. Nevertheless, they contain the embryo for a semantic foundation for word 
classes based on conceptual spaces.177
On thesis LA, it was argued in section 3.5 that most properties expressed by simple words in natural
languages correspond to connected (or star-shaped or convex) regions. I predict that there is no language,
for example, that has a single color word for the hues denoted by "green" and "orange" in English (and
which denotes no other colors), since such a word would represent two disjoint areas in the color space.
Theoretically, the analysis presented in chapter 3 thus directly provides a cognitive semantics for all words
that express (basic) properties. An impediment is that for many words in natural languages that denote
properties, we have only vague ideas, if any at all, about what are the underlying conceptual dimensions
and their geometrical structure.
As an example of thesis LV, consider an image schema representing the verb "leave." In the theory of
image schemas, developed by Lakoff (1987) and Langacker (1987) among others, "leave" would be
analyzed as a dynamic process where the thing departing, the trajector, follows a path from the inside to
the outside of the neighborhood of the presumed point of departure, the landmark. This process is depicted
in figure 5.6. Several verbs like ’’sit" and "support" do not not express any movement, but they can
nevertheless be described as dynamic since they involve forces (acting and counteracting) in a nontrivial 
way.
The horizontal dimension is the time dimension and the vertical is a spatial dimension representing 
distance from the landmark rather than any particular spatial direction. The core of the meaning of "leave"
is a change in the spatial relation of the trajector to the landmark, going from closeness to being distant.
Thus the scheme is basically topological, representing a change in the spatial relation of the trajector to the
  

Figure 5.6
An image-schematic representation of "leave"
 from Langacker (1988, 96). The object departing 
is the trajector tr which is leaving the landmark lm.
landmark and going from inclusion (or closeness) to separateness (and being distant). 178
Technically, the meaning of "leave" can be represented as the set of all paths of a trajector that fulfil this
general condition. Even though I have no precise definition of betweenness for paths, it appears
reasonable to claim that this set is convex, in the sense that for any two paths p and q representing a
departure from a point x, any path in between p and q will also represent a departure from x. It is thus a
(dynamic) natural concept in conformity with LV.
For an example involving another domain, consider "shout." Shouting is represented as a dynamic process
involving primarily a path within the loudness dimension. Again, I would predict that the set of all such
paths representing shouting is a convex set. In this case where the paths run along the time dimension
(they are bijective functions), it is easy to define betweenness: path p is between paths q and r, if and only
if q(t) Å p(t) Å r(t), for all points of time t (or r(t) Å p(t) Å q(t)).
A more action oriented cognitive model of verb meanings has been proposed by Bailey et al. (1998). The
key notion is that of an executing schema (which replaces image schemas). These schemas represent
actions that are executed and they contain information about the movements and postures of different
body parts as well as information about the object that is interacted with (if any). Bailey et al. (1998)
describe a simulated agent based on executing schemas that can learn to label actions (hand motions) and
to carry out similar actions.
As a paradigmatic example of LN one can take the analysis of "apple" from section 4.2. Nouns do not
merely denote physical objects that are located within a limited spatial regionâconsider, for example,
"thunder," "family," and "language," let alone more abstract nouns.
  


Rather, a noun typically denotes a phenomenon that shows a number of correlations in a number of
domains. Thus, nouns are represented by clusters in the conceptual space (see also section 5.8.2). Not all
clusters of correlations that exist, however, will be named by nouns in a languageâan important factor is
whether the correlations have a (potential) pragmatic significance, that is, whether they are helpful in
choosing the right actions.
So far, I have given only a few examples of how the theses LA, LV, and LN can be applied (for the
distinction between LV and LN, see also Thom 1970, 244). A gargantuan amount of lexical work remains
to substantiate these theses.
The thesis L can also be applied to other word classes. An elegant geometrical semantics for locative 
prepositions has been developed by Zwarts (1995). 179 Even though he does not refer to conceptual
spaces explicitly, it is obvious that his analysis can be directly rephrased within the theory of the present 
book.
The locative prepositions discussed by Zwarts are the following:
in front of
in back of/behind
above
below
over
under
next to/beside
between
inside
outside
in/on/at
near
A locative preposition, for example, "in front of," combines with a noun phrase, for example, "the castle,"
that refers to a spatially located object. The basic idea is that the preposition maps the reference object to a 
region that is related to the object (this criterion is also put forward by Jackendoff 1983, and by Landau
and Jackendoff 1993, 223). Zwarts proposes to analyze this region as a set of vectors emanating from the
reference object.180 The interpretation of "Oscar is in front of the castle" can be illustrated as in figure 5.7,
where the marked area represents the region in front of the castle and v is one of the vectors starting from
the castle and ending at o which is Oscar’s position.181
Zwarts studies closure and continuity properties of the vector regions representing prepositions. He studies 
closure under vector addition, for example, which is defined by the condition that if v and w are both
vectors in the region representing a preposition, then v + w also belongs to the region. Among the locative
prepositions listed above, this property is satisfied by "in front of," "behind," "over," "under," "above,’’
and "below," but not by the remaining prepositions.
Another closure property operation is closure under shortening, which means that if v is a vector in the
region representing a preposition, then

  

Figure 5.7
The set of vectors denoting
"in front of" in relation to the castle.
Figure 5.8
Two senses of "between" for vectors.
kÂ·v is also in the region, for any k such that 0 < k < 1. It turns out that all the prepositions in the list above
satisfy this condition. He calls these simple prepositions, in contrast to modified prepositions like "far
behind," "just behind," and "three meters behind." So Zwarts proposes the following universal about the
semantics of the class of locative preposition he is considering:
UNIVERSAL 1 All simple locative prepositions are closed under shortening.
Another universal about locative prepositions can be identified using the notion of "betweenness" for
vectors. There are two basic definitions of this relation for vectors. One is that a vector v is linearly
between u and w; the other is that v is radially between u and w (compare section 3.5). The two senses of
"between" are illustrated in figure 5.8. In both cases it is assumed that all three vectors have the same
starting point.
We can then say that a set R of vectors is linearly (radially) convex, if and only if for all u and w in R
holds that if v is linearly (radially) between u and w, then v also belongs to R. 182 Using these concepts,

  

Zwarts can now formulate the following two universals that exploit these geometrical notions:
UNIVERSAL 2 All simple locative propositions are linearly and radially convex.
UNIVERSAL 3 All locative prepositions (including the modified ones) are linearly or radially convex.
Recall criterion P in chapter 3 which said that a natural property is a convex region of a conceptual space.
Convexity is defined with the aid of "between" but, as shown in section 3.5, there may be several notions
of betweenness for a set of points that belong to a conceptual space. Universal 2 can be rephrased as
saying that, independently of whether we define convexity as linear or radial betweenness, all simple
locative prepositions will be natural properties according to criterion P. Correspondingly, universal 3 says
that any locative preposition, simple or modified, will be a natural property in at least one of the two types
of betweenness. Zwarts (personal communication) also notes that all the regions associated with locative
prepositions are symmetric along at least one axis.
Elegant as it appears, Herskovits (personal communication) has pointed out some problems for Zwarts’
analysis (see also Zlatev 1997). She writes:
supporters of the region view generally assume, without checking or justifying it, that the meaning of a
prepositional phrase is fully "reducible" to a region; that is, this region depends strictly on the preposition, the
landmark, and sometimes an observer; and a uniform relation of inclusion relates the target to this region. In other
words the spatial expression is true iff the object is in such a region.
She then gives the following arguments against this position:
1. Many spatial prepositions such as "on," "against," "upon," and "on top of’’ require contiguity between objects.
This notion is not reducible to a region.
2. The region is context-dependent. This context-dependence also involves environmental characteristics beyond a
frame of reference (see Herskovits 1986).
3. Such a region can be defined; inclusion in it is necessary but
not sufficient. Examples:
â¢ "On": requires support also.
â¢ "Throughout," "about," "over" (covering): besides being included in the region, the target must be distributed
over or extended all over it.
  

â¢ "Alongside": a flower bed alongside the fence must have its length parallel to the fence.
â¢ The static senses of the motion prepositions all present problems; a cable over the yard must extend beyond the
yard’s edges; a path along the ocean must be approximately parallel to it; and so forth.
â¢ "Among": the target must be commensurable with the objects in the landmark.
4. Such a region is definable, but applicability is not uniform within itâthere is context-dependence involving more
than a frame of reference here, too.
Herskovits’ arguments show that the semantics of prepositions is not a simple matter. While I cannot go
into a detailed discussion of the issue here, the example of "on" shows that just a spatial region is not
sufficient to determine the meaning of the preposition. The region that is "on" a table (or a box) in its
normal position is not the same as the region when the table (or the box) is turned upside down. To
analyze this phenomenon, something like Talmy’s (1988) force dynamics is required, taking the
gravitational direction into account. The object that is "on" must be supported from below. Thus the force
dimension is also required for modeling the meaning of "on.’’
For linguistic concepts on a more abstract level, it appears that some kind of spatial contiguity constraints
can be identified. Bickerton (1990, 44-46) gives the example of words that are used to express the abstract
concepts of "existence," "location," "possession," and "ownership." The main difference between the
semantics of "possession" and "ownership" is that the former but not the latter involves spatial contiguity.
Different languages use different verbs to express these concepts. In English "be" is used for existence,
location, and ownership, while "have" is used for possession. Bickerton suggests that the contiguity
relations of the four abstract notions can be represented as shown in figure 5.9.
He claims (1996, 45) that "no language has turned up that uses the same verb for ’location’ and
’possession’ but a different verb (or verbs)
Figure 5.9
Spatial relations between
some abstract lexemes.
  

for ’existence’ and ’ownership,’ or that has the same verb for ’existence’ and ’ownership’ but a different
verb (or verbs) for ’location’ and ’possession.’"
Even though the geometrical structure of the space for these abstract notions may not be very elaborate,
Bickerton’s argument holds that the meaning of the verbs correspond at least to connected regions of the 
space.
A more advanced example of a spatial structure in a grammatical category has been proposed by Broschart
(1996). He presents a geometrical model of case relations that is suggested to work across languages. One
dimension of the model (the horizontal axis in figure 5.10) is the "closeness to the frame of comparison."
This measure of closeness should be seen as the relation between an "observer" (who functions as a
landmark) and an object (the trajector) within a "perceptual field" where the "perceptions" may only be
imagined. This cognitive closeness varies from (1) identity, followed by (2) concomitance, which implies
some form of contact, followed by (3) possession, which requires control but not contact, (4) separation of
the objects, and then finally (5) localization in relation to some (not necessarily spatial) frame of
comparison. The other dimension (the vertical axis in figure 5.10) is "transfer’’ which goes from the agent
of a situation, who is the source (normally in control of the transfer), via a neutral (noncontrol) state to the 
patient, who is the goal. Broschart shows how the cases of different languages can be mapped onto the
conceptual space spanned by these two dimensions. 183
In languages like English and German, cases are often expressed by prepositions. Simplifying Broschart’s
model slightly, the meanings of a large class of prepositions can be mapped onto the two-dimensional
space as shown in figure 5.10.
Since there are only a few distinctions along the two axes, the geometrical structure of the space is rather
meagre. Nevertheless, the areas representing the prepositions appear to conform to Criterion P, forming
roughly convex regions.
Another example involving prepositions is provided by Bowermann and Pedersen (1992) (see also
Bowermann and Choi, to appear). In a cross-linguistic study involving thirty-eight languages, they
investigated how native speakers described situations of containment, support, attachment, adhesion,
hanging, and so forth. In particular, they studied the following six spatial situations: (1) support from
below (for example, cup on table), (2) clingy attachment (band-aid on leg), (3) hanging over/against
(picture on wall), (4) fixed attachment (handle on door), (5) point-to-point attachment (apple on twig), and
(6) full inclusion (apple in bowl) (compare figure 2 in Bowermann and Choi, to appear).
  









































































































































































Shepard, R. N. 1962b. "The analysis of proximities: multidimensional scaling with an unknown
distance function. II." Psychometrika 27: 219-246.
Shepard, R. N. 1964. "Attention and the metric structure of the stimulus space." Journal of
Mathematical Psychology 1: 54-87.
Shepard, R. N. 1982. "Geometrical approximations to the structure of musical pitch." Psychological
Review 89: 305-333.
Shepard, R. N 1984. "Ecological constraints on internal representation: resonant kinematics of
perceiving, imagining, thinking, and dreaming." Psychological Review 91: 417-447.
Shepard, R. N. 1987. "Toward a universal law of generalization for psychological science." Science 
237: 1317-1323.
Shepard, R. N., and Chipman, S. 1970. "Second-order isomorphism of internal representations:
shapes of states." Cognitive Psychology 1: 1-17.
Shepp, B. E. 1983. "The analyzability of multidimensional objects: some constraints on perceived
structure, the development of perceived structure, and attention." In Thighe, T. J., and Shepp, B. E.,
eds. Perception, Cognition, and Development, 39-75. Hillsdale, NJ: Lawrence Erlbaum.
Shin, H. J., and Nosofsky, R. M. 1992. "Similarity-scaling studies of dot-pattern classification and
recognition." Journal of Experimental Psychology: General 121: 278-304.
Sivik, L., and Taft, C. 1994. "Color naming: a mapping in the NCS of common color terms." 
Scandinavian Journal of Psychology 35: 144-164.
Sloman, A. 1971. "Interactions between philosophy and AIâthe role of intuition and nonlogical
reasoning in intelligence." Proceedings 2nd IJCAI. London.
Sloman, S. A. 1993. "Feature-based induction." Cognitive Psychology 25: 231-280.
Sloman, S. A., Love, B. C., and Ahn, W.-K. 1998. "Feature centrality and conceptual coherence." 
Cognitive Science 22: 189-228.
Smith, E. E., and Medin, D L. 1981. Categories and Concepts. Cambridge, MA: Harvard University 
Press.
Smith, E. E., Osherson, D. N., Rips, L. J., and Keane, M. 1988. "Combining prototypes: a selective
modification model." Cognitive Science 12: 485-527.
Smith, E. E., and Sloman, S. A. 1994. "Similarity- versus rule-based categorization." Memory and
Cognition 22: 377-386.
Smith, L B. 1989. "From global similarities to kinds of similaritiesâthe construction of dimensions in
development." In Vosniadou, S., and Ortony, A., eds. Similarity and Analogical Reasoning.
Cambridge: Cambridge University Press.
Smith, L. B., Gasser, M., and Sandhofer, C. 1997. "Learning to talk about the properties of objects: a
network model of the development of dimensions." In Goldstone, R. L., Schyns, P. G., and Medin,
D. L., eds. Psychology of Learning and Motivation, vol. 36, 219-256. San Diego, CA: Academic 
Press.
Smith, L. B., and Heise, D. 1992. "Perceptual similarity and conceptual structure." In Burns, B., ed. 
Percepts, Concepts, and Categories. Amsterdam: Elsevier.
Smith, L. B., and Samuelson, L. K. 1997. "Perceiving and remembering: category stability,
variability and development." In Lambert, K., and Shanks, D., eds. Knowledge, Concepts, and 
Categories, 161-195. East Sussex: Psychology Press.
Smith, L. B., and Sera, M. D. 1992. "A developmental analysis of the polar structure of dimensions." 
Cognitive Psychology 24: 99-142.
Smolensky, P. 1986. "Information processing in dynamical systems: foundations of harmony
theory." In Rumelhart, D. E., and McClelland, J. L. 1986. Parallel Distributed Processing, vol. 1,
194-281. Cambridge, MA: MIT Press.
Smolensky, P. 1988. "On the proper treatment of connectionism." Behavioral and Brain Sciences 11: 
1-23.

  

Smolensky, P. 1990. "Tensor product variable binding and the representation of symbolic structures
in connectionist systems." Artificial Intelligence 46: 159-216.
Smolensky, P. 1991. "Connectionism, constituency and the language of thought." In Loewer, B., and
Rey, G., eds. Meaning in Mind: Fodor and His Critics, 210-227. Oxford: Blackwell.
Sneed, J. 1971. The Logical Structure of Mathematical Physics. Dordrecht: Reidel.
Stalnaker, R. 1981. "Antiessentialism." Midwest Studies of Philosophy 4: 343-355.
Steels, L. 1996. "Perceptually grounded meaning creation." Artificial Intelligence Laboratory.
Brussels: Vrije Universiteit Brussel.
Stegmuller, W. 1973. Personelle und Statistische Wahrscheinlichkeit, Erster Halbband: Personelle
Wahrscheinlichkeit und Rationale Entscheidung. Berlin Springer-Verlag.
Stegmuller, W. 1976. The Structure and Dynamics of Theories. Berlin: Springer-Verlag.
Stein, B. A., and Meredith, M. A. 1993. The Merging of the Senses. Cambridge, MA: MIT Press.
Stewart, J. 1996. "Cognition = life: implications for higher-level cognition." Behavioural Processes 
35: 311-326.
Suppes, P., Krantz, D. M., Luce, R. D., and Tversky, A. 1989. Foundations of Measurement, volume
II: Geometrical, Threshold, and Probabilistic Representations. San Diego, CA: Academic Press.
Sweetser, E. 1990. From Etymology to Pragmatics. Cambridge: Cambridge University Press.
Taft, C. 1997. Generality Aspects of Color Naming and Color Meaning. Gothenburg University,
Gothenburg: Department of Psychology.
Taft, C., and Sivik, L. 1997. "Salient color terms in four languages." Scandinavian Journal of
Psychology 38: 26-31.
Talmy, L. 1988. "Force dynamics in language and cognition." Cognitive Science 12: 49-100.
Tarr, M. J., and Pinker, S. 1989. "Mental rotation and orientation-dependence in shape recognition." 
Cognitive Psychology 21: 233-282.
Thom, R. 1970. "Topologie et linguistique." In Essays on Topology, 226-248. Berlin: 
Springer-Verlag.
Thom, R. 1972. StabilitÃ© Structurelle et MorphogenÃ¨se. New York, NY: Benjamin.
Thompson, E. 1995. "Color vision, evolution, and perceptual content." Synthese 104: 1-32.
Tirri, H. 1991. "Implementing expert system rule conditions by neural networks." New Generation
Computing 10: 55-71.
Tolman, E. C. 1948. "Cognitive maps in rats and men." Psychological Review 55: 189-208.
Toulmin, S., and Good field, J. 1965. The Discovery of Time. Harmondsworth: Penguin.
Tourangeau, R., and Sternberg, R. J. 1982. "Understanding and appreciating metaphors." Cognition 
11: 203-244.
Touretsky, D. S. 1986. The Mathematics of Inheritance Systems. Los Altos, CA: Morgan Kaufmann.
Tversky, A. 1977. "Features of similarity." Psychological Review 84: 327-352.
Tversky, A., and Gati, I. 1982. "Similarity, separability, and the triangle inequality." Psychological
Review 89: 123-154.
Tversky, A., and Hutchinson, J. W. 1986. "Nearest neighbor analysis of psychological spaces." 
Psychological Review 93: 3-22.
Tversky, B., and Hemenway, K. 1984. "Objects, parts, and categories." Journal of Experimental
Psychology: General 113: 169-191.
UexkÃ¼ll, J. von 1985. "Environment and inner world of animals." In Burghardt, G. M., ed. 
Foundations of Comparative Ethology. New York, NY: Van Nostrand Reinhold Company.
Ullman, S. 1995. "The visual analysis of shape anf form." In Gazzaniga, M. S., ed. The Cognitive 
Neurosciences, 339-350. Cambridge, MA: MIT Press.

  

Ullman, S., and Basri, R. 1991. ’’Recognition by linear combination of models." IEEE Transactions
PAMI 13: 992-1006.
Vaina, L. 1983. "From shapes and movements to objects and actions." Synthese 54: 3-36.
Vandeloise, C. 1991. Spatial Prepositions: A Case Study from French. Chicago, IL: University, of
Chicago Press.
Van Fraassen, B. 1969. "Presuppositions, supervaluations and free logic." In Lambert, K., ed. The
Logical Way of Doing Things. New Haven, CT: Yale University Press.
Van Gelder, T. 1995. "What might cognition be, if not computation?" Journal of Philosophy 92: 
345-381.
Van Gelder, T. 1998. "The dynamical hypothesis in cognitive science." Behavioral and Brain
Sciences 21: 615-628.
Verbrugge, R. R. 1980. "Transformations in knowing: a realist view of metaphor." In Honeck, R. P.,
and Hoffman, R. R., eds. Cognition and Figurative Language, 87-125. Hillsdale, NJ: Lawrence
Erlbaum Associates.
Von Glasersfeld, E. 1995. Radical Constructivism. London: The Falmer Press
Waddington, C. H. 1957. The Strategy of the Genes: A Discussion of Some Aspects of Theoretical 
Biology. London: Allen.
Wallin, A. 1997. "Is there a way for constructivism to distinguish what we experience from what we
represent?" In Riegler, A., and Peschl, M., eds. New Trends in Cognitive Scienceâ97 "Does
Representation Need Reality? "13-18. Vienna: Austrian Society of Cognitive Science Technical
Report 97-01.
Whiten, A., and Byrne, R. W. 1988. "Tactical deception in primates." Behavioral and Brain Sciences 
11: 233-273.
Wiener, N. 1961. Cybernetics. Cambridge, MA: MIT Press.
Wilkins, W. K., and Wakefield, J. 1995. "Brain evolution and neurolinguistic preconditions." 
Behavioral and Brain Sciences 18: 161-182.
Winter, S. 1998. Expectations and Linguistic Meaning. Lund: Lund University Cognitive Studies 71.
Winter, S, and GÃ¤rdenfors, P. 1995. "Linguistic modality as expressions of social power." Nordic
Journal of Linguistics 18: 137-166.
Winter, S., and GÃ¤rdenfors, P. 1998. "Evolving social constraints on individual conceptual
representations." Lund: Lund University Cognitive Studies 69.
Wisniewski, E. J. 1996. "Construal and similarity in conceptual combination." Journal of Memory
and Language 35: 434-453.
Wittgenstein, L. 1953. Philosophical Investigations. New York, NY: Macmillan.
Woozley 1967. "Universals." Encyclopedia of Philosophy, vol. 8, 194-206. New York: Macmillan
and The Free Press.
Zeeman, C. 1977. Catastrophe Theory: Selected Papers 1972-1977. Redwood City, CA: 
Addison-Wesley.
Zlatev, J. 1997. Situated Embodiment: Studies in the Emergence of Spatial Meaning. Stockholm: 
Gotab.
Zornetzer, S. E., Davis, J L., and Lau, C. 1990. An Introduction to Neural and Electronic Networks.
San Diego, CA: Academic Press.
Zwarts, J. 1995. "The semantics of relative position." Manuscript, OTS: Utrecht University.
Zwarts, J., and Winter, Y. 1998. "The formal semantics of locative prepositions." Manuscript.
Utrecht: Utrecht Institute of Linguistics.

  


Illustration Credits
Figure 1.5  Reprinted by permission of Cambridge University Press and the authors.
Figure 1.6  Reprinted by permission of Cambridge University Press and the authors.
Figure 1.7  Reprinted by permission of the author.
Figure 1.13 Reprinted by permission of Psychometrika and the author.
Figure 2.2  Reprinted by permission of MIT Press and the author.
Figure 3.7  Reprinted by permission of Cambridge University Press and the authors.
Figure 3.8  Reprinted by permission of Cambridge University Press and the authors
Figure 3.9  Reprinted by permission of Cambridge University Press and the authors
Figure 3.10 Reprinted by permission of Cambridge University Press and the authors.
Figure 3.12 Reprinted by permission of American Speech-Language-Hearing Association.
Figure 3.14 Reprinted by permission of the author.
Figure 3.15 Reprinted by permission of the author.
Figure 3.20 Reprinted by permission of the Royal Society of London and the authors.
Figure 3.21 Reprinted by permission of the Royal Society of London and the authors.
Figure 4.5  Reprinted by permission of Georgetown University Press
Figure 4.6  Reprinted by permission of Georgetown University Press.
Figure 4.7  Reprinted by permission of Elsevier Science Publishers.
Figure 5.5  Reprinted by permission of Mouton de Gruyter and the author
Figure 5.6  Reprinted by permission of John Benjamins Publishers and the author
Figure 6.2  Reprinted by permission of Springer Verlag and the author
Figure 6.3  Reprinted by permission of Springer Verlag and the author.
Figure 6.4  Reprinted by permission of Springer Verlag and the author.

  

Index
A
Action, 98-99, 103, 261
AD. See Average distance
Adjective, 60, 101, 115, 167, 194-195
Ahn, W.-K., 60
AI. See Artificial intelligence
Aisbett, J., 44, 95, 97
Allwood, J., 159
Amit, D. A., 244
Analytically true, 166, 214-215
Anderson, J. R., 233
Anderson, R. C., 120
Animal
concept, 8, 81, 125, 132, 218
shape, 95-97 (see also Shape space)
ANN. See Artificial neuron network
Antiessentialism. See Essentialism
Aristotle, 155, 156, 204
Armstrong, D. M., 4, 5, 100
Artificial agent, 1, 9, 33, 56, 152, 189, 253, 256
Artificial intelligence, 35-37, 43, 126, 209-211, 230, 236, 261
Artificial neuron network, 34, 38, 42-43, 46-47, 56-58, 88, 126, 204, 221-224, 233, 237-247, 
259-261
energy function of, 34
resonant, 246
Ashby, E G., 137, 145
Association, 1-2, 33, 40-41, 154, 187-189; 238, 245, 249-250, 252, 257
Associationism. See Association
Attention-weight, 20. See also Salience
Attneave, F., 25
Attractor, 88, 244-246, 252, 260
Average distance, 84, 102, 141, 145-146, 149-150
B
Bailey, D., 161, 169
Balkenius, C., 47, 228, 246-247
Barclay, J. R, 104
Barsalou, L W., 28, 45-47, 105, 128
Bartsch, R., 104
Barwise, J., 154
Beale, R., 41-42
Bealer, G., 62
Behaghel, O., 166
Belief revision, 131. See also Concept, revision of
Berlin, B., 73, 183
Betweenness, 15-19, 68-73, 95, 169, 171-172
axioms, 15-17
Bickerton, D., 173-174
Biederman, I., 97
Billman, D. O., 225, 226
Boots, B., 87, 91
Borsuk, K., 15-17
Bowermann, M., 168, 174, 176
Boyle, R., 215
Brachman, R. J., 252
Braitenberg, V, 237
Brightness, 10, 26, 28, 103
Broschart, J., 174-175
Brostrom, S, 164, 182-183, 185-186
Brugman, C., 164
Bryant, D. J., 157
Burge, T., 190, 197, 201
Buss, A. H., 13
C
Carey, S, 28, 196
Carnap, R., 206, 208, 212-214
Carstensen, K.-U., 166
Categorical
inductive inference, 226-228
perception, 89-90, 194
representation, 54
Categorization, 20, 24, 60, 77, 84, 89, 102, 106, 109, 124-126, 134, 136, 138,

  

Categorization (cont.)
140-141, 145, 218
models, 136-141
unnatural, 149-150
Chater, N., 20, 46, 109-110, 112, 236
Chella, A., 97, 229, 242, 251-253, 257-258, 261
Chipman, S., 12, 109
Choi, S., 174
Chromaticness, 10, 26, 71, 73, 103
Church, A., 234, 250
Churchland, P. M., 236, 240, 244
Churchland, P. S., 37, 51, 241
City-block metric, 18-20 See also Distance, city-block
Clark, Andy, 41-42, 161, 216
Clark, Austen, 5, 11, 22-23, 260
Clark, H. H., 184
Closure structure, 76-78, 80-81, 212
Cluster, 113, 126, 170, 193-194, 218, 233, 235, 258
of properties, 225-226
Cognitive development See Development of cognition
Cognitive economics. See Economy of cognition
Cognitive linguistics, 2-3, 76, 155, 157, 163-166, 258. See also Semantics, cognitive
Cohn, A. G., 67-68
Color, 9-13, 87, 100, 103, 108, 121, 132, 219
circle, 9-10, 22-23, 72-73
perception, 8-13, 52, 81, 88, 98, 156
predicate (see Color, term)
spindle, 10-11, 72, 121-122, 184
term, 12, 71-77, 85, 120-122, 168, 183-184, 186
Colston, H. L., 163
Combination of concepts. See Concept combination
Common knowledge. See Sharing of knowledge
Communication, 30, 151-152, 155, 164, 187, 189-195, 202, 226. See also Sharing of knowledge
Computationalism, 35, 156, 247
Concept, 60, 101-150
combination, 102, 105, 114-122, 131
dynamic, 101, 124, 131-132
formation, 1-4, 20, 30, 42, 44, 54-55, 57, 102, 109, 116, 209-211, 235, 238, 256, 261
functional, 98-99, 118, 261
learning, 102, 122-126, 146, 213
modality-free, 46-47
natural, 105, 167
revision of, 116, 131
subordinate, 128, 131
Conceptualism, 39, 60, 106, 110, 255
Connected region, 59, 67-69, 76-77, 87, 99, 105, 167-168, 174, 182, 213
Connectionism, 1-3, 30, 35, 40-47, 53, 58, 123, 227, 235, 238-239, 243-250, 256, 259, 262
Context dependency, 97, 103-105, 107, 109, 113, 118-119, 128-130, 152, 172-173
Continuity, 17, 89, 135, 170
Contrast class, 119-122, 130, 182-184
Conventionalism, 80
Convexity, 59, 69-74, 77, 79, 86-88, 90-93, 99, 105, 131, 138-139, 167-169, 171-174, 176, 182, 
212-214
linear, 171-172
radial, 72, 171-172
Coordinate transformation, 236, 240, 253
Correlation between domains, 104-105, 116, 132, 170, 193, 218, 225-230
D
Davis, J. L., 41-42
Deacon, T. W., 47, 196
Default inferences, 118, 126-127, 140 See also Nonmontonicity
Dellarosa, D., 41, 246
Dennett, D., 37, 249
De Saussure, F., 155-156, 187-188
Descartes, R., 48
DesclÃ©s, J.-P., 159
Development of cognition, 38, 181-182, 191, 219, 234
Dimension, 2, 6-15, 30, 67, 76, 79, 81
discrete, 7-8, 17
identification of, 21-24
integral, 24-26, 60, 77, 90-91, 99, 101, 136
origins of, 26-30, 82, 196
phenomenal, 5, 8-15, 21-22, 117, 144
reduction of, 221, 240-242, 257
scientific, 5, 8-9
separable, 24-26, 28, 60, 77, 91, 101, 136
spatial, 6, 34
weight of (see Salience)
Distal representation, 52, 236, 251, 258
Distance, 5, 17-21, 31, 71, 98, 110-112, 123, 141, 146, 222, 235, 240, 248, 260

  

city-block, 18-20, 25, 90-91, 134
Euclidean, 18-20, 25, 72, 87-88, 90-91, 93, 95, 133, 138-139
Dixon, R M. W., 165, 258
Domain, 5, 26, 28-30, 37, 43, 46-48, 50, 60, 71, 100-110, 115-122, 132-133, 161-162, 167, 176-182, 
185-187, 195-196, 205, 211, 213-217, 219, 228-229, 238, 240-241
Dynamic
representation, 31, 57, 88, 98-99, 163, 165, 169, 260 (see also Force dynamics; Concept, dynamic)
system, 238, 244-246, 256
E
Ecological validity, 145, 150
Economy of cognition, 29, 70, 89, 194, 218, 221-222, 243
Edelman, S., 109, 240
Embodied cognition, 160-161, 257
Engberg Pedersen, E., 185-186
Energy function. See Harmony function
Equidistance, 15, 17-19, 73
Essentialism, 64, 77, 79, 105-107, 200-201
conceptualistic, 201
psychological, 106
Evolutionary argument, 47-48, 70, 82-83, 203, 261
Expectation, 102, 118, 126, 138, 194, 230, 246, 253
F
Fairbanks, G., 84-85, 260
Fauconnier, G., 159
Feature, 12, 45, 47, 54, 56, 79, 102, 105, 108, 112-113, 126, 195, 218, 226-228, 238, 246, 258
map, 222, 258
Fenstad, J. E., 88, 189
Fischer Nilsson, J., 76
Fodor, J. A., 35-36, 39-40, 43, 160, 234, 246-247, 249
Force dynamics, 56, 98, 173
Foss, J, 240
Frame, 105, 118, 120
problem, 37, 46
Frege, G., 153, 159
Freyd, J., 29-30, 82, 190-191, 195-196, 237
Fried, L. S., 138
Frixione, M., 97, 229, 242, 251-253, 257-258, 261
Functionalism, 36, 258
semantic, 151-152, 184
Fuzzy set, 115. See also Property, fuzzy
Gaglio, S., 97, 229, 242, 251-253, 257-258, 261
Galileo, G., 218, 237
Gallistel, C. R., 8-9, 27, 52-53, 236-237
GÃ¤rdenfors, P., 104, 131, 136, 159, 164-165, 184, 190, 197, 231, 226, 228, 246-247
Garner, W. R., 24-25
Gati, I., 112-113
Generalization, 20, 122-123, 125, 204-207, 213, 222, 230, 240
Genesereth, M., 209-211
Gentner, D., 21, 31, 110, 113
Geometrical structure, 2, 6, 8-9, 12-15, 30, 34, 52, 56-57, 59, 67, 70, 79-82, 88, 97, 99, 105, 113, 
118-119, 124, 126, 132, 136, 155, 158, 161, 163, 166, 174, 176-181, 183, 186-187, 196, 215-216, 
235, 252-253, 255, 259-260
Gibbon, G, 44, 95, 97
Gibbs, R. W, 163
Gibson, J. J., 83, 145, 150
GivÃ³n, T., 195
Goldberg, A. E., 40
Goldstone, R I., 21, 28, 31, 42, 45-46, 104, 110, 113, 134, 240-242
Goodfield, J, 29
Goodman, N., 39, 63, 74, 77, 81, 109, 111, 204-208, 210-212
Gopnik, A., 107-108, 217
Gott, R. E., 137
Graph, 8, 18, 26, 260
Grenholm, P., 126, 236
Grubb, P., 84-85, 260
Grue, 63, 81, 206-208, 211-213
GV. See Voronoi tessellation, generalized
H
Hahn, U, 20, 46, 109-110, 112, 236
Halff, H. M., 120
Hampton, J A., 105, 115-117, 217-218
Hanson, N. R., 219
HÃ¥rd, A., 9
Harder, P., 151-152, 184
Hardin, C. L., 9, 10
Harmony function, 245
Harnad, S., 38, 53-54, 89, 160, 250
Hayes, P., 37
Hebb’s rule, 126, 252
Heise, D., 107, 113, 132-133, 137, 193
Heit, E, 225-226
Hemenway, K, 97, 261
Hempel, C. G., 39, 205-206, 210, 212

  

Henning, H., 14
Herskovits, A., 163-164, 167, 172, 178
Hintikka, J., 61
Hinton, G. E., 57
Hintzman, D. L., 123
Holland, J. H., 118, 126, 138, 226, 228
Holmqvist, K., 104-105, 119, 136, 159, 166, 202
Holyoak, K. J., 138
Hopfield, J. J., 252
Hue, 9, 12, 22-24, 26, 71-73, 86, 103, 212
Hulth, N., 126, 236
Hume, D., 40
Hutchinson, J. W., 113-114, 141
I
Identification learning, 148-149
Image schema, 55-56, 158, 162-164, 168-169, 176, 186, 199
Induction, 3, 30, 39, 63, 67, 77, 82-83, 132, 203-231, 238, 255, 261
riddle of, 39, 63, 206-208
Indurkhya, B., 164, 180
Inner product, 46
Instrumentalism, 31, 106
J
Jackendoff, R., 4, 8, 155, 159-161, 168, 170, 184, 188
Jackson, T., 41-42
James, W., 27, 40
Janlert, L -E, 37
Johannesson, M., 136
Johnson, M. G., 161-162, 164, 176-178, 180
Johnson-Laird, P. N., 159
Jones, L. E., 242
Jones, S. S., 95, 97, 132, 137, 188
Jordan, M. J., 46
K
Kamp, H., 115, 118-119
Kanger, S., 61
Katz, J. J., 40
Kay, P., 73, 183
Keele, S. W., 145
Keil, E, 107
Kirsch, D., 59
Knutson, J., 225
Koehly, L. M., 242
Kohonen, T., 42, 217, 221-225, 229-230, 235, 240, 242-243, 258, 260
Kornblith, H., 225
KÃ¶vesces, Z., 106
Kripke, S., 61, 155
Krumhansl, C. L., 114
Kruskal, J. B., 22
Kuhl, P. K., 260
Kuhn, T., 201, 219
L
Labov, W., 112, 128-130, 133, 137
Lakoff, G., 2, 84, 87, 158-159, 161-164, 166-168, 176-178, 180, 186
Land, E., 13
Landau, B., 95, 168, 170
Landmark, 162, 168-169, 172-174, 191
Lang, E., 166
Langacker, R. W., 2, 105, 158-159, 161-163, 166, 168-169, 185-186, 202
Langley, P., 123-126, 210, 235-236
Language of thought, 35, 43, 160
Lau, C., 41-42
Learning, 42, 52, 89, 105, 235, 243, 256, 260-261. See also Identification learning; Machine learning
of concept (see Concept, learning)
error, 149-150
of language, 55, 151, 154, 187-189
rule, 41, 222, 229, 239
supervised, 125, 240
time, 149-150
unsupervised, 125-126
Lee, W. W., 145
Leibniz’ law, 135
Lewis, D. K., 61, 66-67, 187, 208
Lexical semantics. See Semantics, lexical
Linguistic power structure, 157, 197-202, 255
Linneaus, C. von, 219
Llinas, R., 52, 244
Locke, J., 40, 106, 259
Logical inference, 36-37, 246. See also Nonmonotonicity
Logical positivism, 39, 204-208, 210-211, 230, 261
Love, B. C., 60
M
McCarthy, J., 37
McClelland, J. L., 34, 41-42, 57, 126, 245
Machine learning, 30, 126, 209-210, 236, 259
Maddox, W. T., 24
Makinson, D., 127, 131
Malgady, R. G., 176
Mandler, J., 55
Marr, D., 29, 79, 94-99, 103, 236, 252
MDS. See Multidimensional scaling

  

Meaning postulate, 135
Medin D. L., 21, 31, 84, 106-108, 110-113, 116, 138
Melara, R. D., 24, 25
Meltzoff, A. N., 107-108, 217
Memory, 3, 50, 70, 89, 158-159, 162
Mendel, G., 216
Mentalese. See Language of thought
Mervis, C., 84
Metaphor, 98, 108, 130-131, 162, 164, 168, 176-187, 202, 259
Metonymy, 117, 130, 162, 164, 168
Metric, 17-20, 22, 26, 48, 71, 73, 80, 83, 87, 89, 139, 214. See also Distance, Euclidean; Distance, 
city-block
Minkowski, 20, 26
Michalski, R. S., 126, 210, 236
Minsky, M., 105
Montague, R., 61, 115
Morasso, P., 238
MorÃ©n, J., 47
Mormann, T., 76-78, 80-81, 212
Multidimensional scaling, 21-25, 43, 110, 112-113, 182, 217, 221, 240-242, 248, 260
Murphy, G. L., 107-108, 116
Murtagh, F. D., 126, 236
N
Natural color system, 9-11
Natural kind, 39, 70, 85-86, 200-201, 208. See also Property, natural; Concept, natural
NCS. See Natural color system
Nearest neighbor, 84, 102, 114, 141, 145-150
Nelson, K., 107
Neural network. See Artificial neuron network
Newell, A., 35, 233, 247
Newton, I, 30, 215-217, 219
Nilsson, N. J., 209-211
Nisbett, R. E., 138, 225
Nishihara, H. K., 79, 94-95, 97-99, 103
NN. See Nearest neighbor
Nolan, R., 213
Nonmonotonicity, 58, 102, 105, 116, 126-133, 228, 246-247, 255
Nosofsky, R. M., 20-21, 84, 110, 113, 123, 137, 141, 145, 243
Noun, 60, 101, 115-117, 167, 169-170
O
Object
centered representation (see Distal representation)
permanence, 135
recognition, 57, 240, 251-253
representation, 134-136, 190-196, 235
Observation, 39, 46, 138, 158, 203-206, 209-211, 219-220, 240
Okabe, A., 87, 91
Ontology. See Semantics, ontology of
Ortony, A., 107, 120
Osherson, D. N., 106, 115, 118, 226-228
P
Palmer, S. E., 44
Paradox of confirmation, 39, 206, 212-213
Parallel distributed systems, 41. See also Connectionism
Partee, B., 115, 118-119
Pattern recognition, 239, 253
Pearl, J., 210
Pedersen, E., 174, 176
Peirce, C. S., 82-83, 203
Pellionisz, A., 52, 244
Pentland, A. P., 97, 103, 252
Perry, J., 154
Petitot, J., 2, 52, 58, 89-90, 159, 165, 194, 240, 244-245, 257-260
Pitch, 6, 13-14, 24, 26, 50, 84, 162
Pittenger, J. B, 137
Polar coordinate, 9, 72-74
Popper, K. R., 217
Port, R. F., 31, 98, 244
Positivism. See Logical positivism
Posner, M. I., 145
Possible world, 3, 59-66, 79-80, 120, 136, 153-154, 160, 189, 234, 255
Power. See Linguistic power structure
Pragmatics, 152, 156, 165-166, 170, 182, 184-185
Predicate, 38-40, 61, 64-65, 70, 80-82, 101, 127, 136, 152, 158, 166-167. See also Property
Predicted response, 146-147
Preposition, 167-168, 170-176, 178
Principal component, 241-242
Projectible, 63, 77, 81, 83, 203-204, 208-209, 213
Property, 3, 6, 26, 59-101, 111-112, 168
abundant, 66-67
core, 106-107, 217
definition of, 60
essential, 64, 217
extensional, 61, 64, 86
fuzzy, 71, 118

  

Property (cont.)
higher level, 92-95, 179
intensional, 60-64, 86
natural, 39, 67, 70-86, 88, 91-92, 137, 182, 211-214, 255
perceptually grounded, 77
relation between, 45
shared, 111-112
sparse, 66
Proposition, 36, 61-62, 66, 79, 126-127, 153, 214
Prototype, 87-92, 95, 102, 123-125, 129, 131-134, 137-141, 145, 194, 213, 258
area, 139-141
effect, 60, 166
theory, 60, 77, 81, 84-92, 100, 105, 107, 118, 167, 226
Proximal representation, 52, 236, 251
Putnam, H., 64-65, 77, 79-80, 158, 190, 196-202
PV. See Voronoi tessellation
Pylyshyn, Z., 35-37, 247, 249
Q
Quality dimension See Dimension
Quine, W. V. O., 27, 81-83, 85-86, 158-159, 203, 208
Quinlan, P., 42
R
Radermacher, F. J, 56
Raup, D. M., 142, 144
Realism, 67, 110, 151, 187, 200, 234
Reed, S. K., 84, 104, 123, 137, 141
Referent, 189-196
Regier, T., 166, 168
Region, 67, 74, 80, 100, 115-119, 132, 138, 170-172. See also Convexity; Star-shaped region
connection calculus, 67-68
natural, 66, 76, 105, 214
Reichenbach, H., 115
Reiter, R., 127
Relation, 92-93, 118
Relativism, 80-81, 215
Representation. See also Categorical, representation; Distal representation; Object, representation;
Proximal representation; Subconceptual representation; Symbolic representation
extrinsic, 44-45
intrinsic, 44-45
Resonant systems. See Artificial neuron network, resonant
Rips, L J., 106-108, 140
Robot. See Artificial agent
Rosch, E., 84, 86-87, 138, 194, 226
Ross, L., 225
Roth, E M, 128
Rott, H., 10
Rudzka-Ostyn, B., 159
Rumelhart, D. E., 34, 41-42, 57, 126, 245
Rutherford, E., 216
S
Salience, 20, 102-109, 113, 117-118, 129, 132-134, 217-219
Samuelson, L. K., 108
Sanguineti, V., 238
Saturation. See Chromaticness
Schiffman, H. R., 6
Schlechta, K, 127
Schmoltze, J. C., 252
Schyns, E G., 42, 123, 240-242, 258
Scott Kelso, J. A., 31, 98, 244
Sejnowski, T. J., 241
Self-organizing maps, 42, 57, 217, 221-225, 229-230
Semantics
cognitive, 3, 60, 101, 151, 154-168, 184, 187-190, 196-197, 200-202, 255, 259
extensional, 59, 61-62, 114, 152-153, 157, 201
intensional, 59-64, 67, 115, 136, 152-153, 157, 189, 202
lexical, 157, 163, 176, 201
ontology of, 151-154, 231
situation, 154
social, 199-202
theory of, 151-156
Sensitization, 104, 134
Shapere, D., 220
Shape space, 93-98, 103, 108, 132, 178-179, 219, 239, 261
Sharing of knowledge, 29, 35, 82, 190, 237
Shaw, R. E., 137
Shell space, 21, 97, 136, 142-150
Shepard, R. N., 12, 20, 22-23, 25, 70, 109-110, 137, 144, 221, 248
Shepp, B. E., 28
Shin, H. J., 145
Shoben, E. J, 116, 128
Similarity, 1-2, 5-6, 20-22, 31, 46, 61, 66, 83, 85-86, 104, 107-114, 132-133, 193, 208, 228, 235, 
243, 248, 260
judgment of, 22-25, 44, 110, 112-114, 132, 140, 148, 217-219

  

measure of, 20-21, 41-42, 88, 97, 126
of perceptions, 4, 28, 45, 108
relation, 6, 123, 214, 222-223
Simmons, G., 166
Simon H., 35, 247
Situation semantics. See Semantics, situation
Sivik, L., 9, 11, 73-76, 87
Sloman, A., 250
Sloman, S. A., 60, 140, 227-228
Smith, E. E., 84, 102, 105-106, 112, 115-116, 118, 140
Smith, L. B., 27, 95, 97, 107-108, 113, 132-133, 137, 188, 193, 195
Smolensky, P., 57, 238, 243-250
Sneed, J., 21, 31, 110, 217
Stalnaker, R., 64, 77, 79-80, 135-136
Star-shaped region, 68-69, 87, 91-92, 99, 105, 167-168, 182, 213
StegmÃ¼ller, W., 31, 208
Stepp, R. E., 126, 210, 236
Sternberg, R. J., 164, 180-181
Stevens’ power law, 144
Stewart, J., 38, 234
Structural conventionalism. See Conventionalism
Subconceptual representation, 33-35, 40-43, 204-205, 219-221, 225, 230-231, 236, 240, 246-255, 
258, 261
Subordinate concept. See Concept, subordinate
Subsymbolic representation. See Subconceptual representation
Sugihara, K., 87, 91
Suppes, P., 2, 21, 259
Sweetser, E., 159, 164
Symbol
grounding, 38, 43
manipulation, 35-36, 250
Symbolic representation, 1-3, 30, 33-47, 53-54, 58, 108, 123, 126-127, 161, 204-205, 209-211, 
215-216, 221, 228-231, 233-239, 242, 247-259, 261
Syntax, 36, 157, 160, 165-166, 185
Szmielew, W., 15-17
T
Taft, C., 11, 73-76, 87
Talmy, L., 2, 98, 158-159, 165, 173
Tarski, A., 153, 155
Taste, 14-15, 103, 105
Theoretical entity, 31, 48, 83, 109, 215-219
Theory-theory of concepts, 105-109
Thibaut, J.-P., 42, 240-242
Thom, R., 2, 57, 163, 165, 170, 244
Thompson, E., 13, 156
Thorndike, E. L., 40
Time, 6, 28-29, 162, 166-169, 177-178, 212, 217
Tirri, H., 37
Topographic map, 27, 49-50, 57, 236, 241
Topological structure, 6, 43, 56-59, 67, 76, 81-82, 103, 161, 163, 166, 168, 176, 180, 186-187, 
221-225, 235, 237-238, 242, 244-245, 255-256, 259-260
Toulmin, S., 29
Tourangeau, R., 164, 180-181
Touretsky, D. S., 127
Trajector, 162, 168-169, 174
Truth condition, 65, 153-160
Turing machine, 36, 232-233, 239, 249-250
Tversky, A., 112-114, 141
Tversky, B., 97, 261
V
Vaina, L., 29, 98
Van Fraassen, B., 118
Van Gelder, T., 31, 42, 98, 238-239, 243-245
Vector
averaging, 241
completion, 230, 246
space, 52-53, 57, 235-238, 248
Verb, 98, 101, 167-169, 173-174
Verbrugge, R. R., 181
Viewer centered representation. See Proximal representation
Vision, 42, 47, 251-252, 257
Voronoi tessellation, 87-91, 124-125, 134, 136-139, 145-146, 149-150, 213, 223, 235, 260
generalized, 114, 129, 139-141, 145-150
Vowel space, 14, 84-85, 260
W
Wiener, N., 198
Winter, S., 165, 184, 190, 226
Winter, Y., 168
Wisniewski, E. J., 116-117
Wittgenstein, L., 151-152
Z
Zeeman, C., 50
Zlatev, J., 161, 163, 166, 168, 172
Zornetzer, S F., 41-42
Zwarts, J., 93, 168, 170-172

  

