An Introduction to
Statistical Computing

WILEY SERIES IN COMPUTATIONAL STATISTICS
Consulting Editors:
Paolo Giudici
University of Pavia, Italy
Geof H. Givens
Colorado State University, USA
Bani K. Mallick
Texas A & M University, USA
Wiley Series in Computational Statistics is comprised of practical guides and cutting
edge research books on new developments in computational statistics. It features
quality authors with a strong applications focus. The texts in the series provide
detailed coverage of statistical concepts, methods and case studies in areas at the
interface of statistics, computing, and numerics.
With sound motivation and a wealth of practical examples, the books show in
concrete terms how to select and to use appropriate ranges of statistical comput-
ing techniques in particular Ô¨Åelds of study. Readers are assumed to have a basic
understanding of introductory terminology.
The series concentrates on applications of computational methods in statistics to
Ô¨Åelds of bioinformatics, genomics, epidemiology, business, engineering, Ô¨Ånance and
applied statistics.
Titles in the Series
Biegler, Biros, Ghattas, Heinkenschloss, Keyes, Mallick, Marzouk, Tenorio,
Waanders, Willcox ‚Äì Large-Scale Inverse Problems and QuantiÔ¨Åcation of Uncertainty
Billard and Diday ‚Äì Symbolic Data Analysis: Conceptual Statistics and Data Mining
Bolstad ‚Äì Understanding Computational Bayesian Statistics
Borgelt, Steinbrecher and Kruse ‚Äì Graphical Models, 2e
Dunne ‚Äì A Statistical Approach to Neutral Networks for Pattern Recognition
Liang, Liu and Carroll ‚Äì Advanced Markov Chain Monte Carlo Methods
Ntzoufras ‚Äì Bayesian Modeling Using WinBUGS
Tuff¬¥ery ‚Äì Data Mining and Statistics for Decision Making

An Introduction to
Statistical Computing
A Simulation-based Approach
Jochen Voss
School of Mathematics, University of Leeds, UK

This edition Ô¨Årst published 2014
C‚Éù2014 John Wiley & Sons, Ltd
Registered ofÔ¨Åce
John Wiley & Sons, Ltd, The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ,
United Kingdom
For details of our global editorial ofÔ¨Åces, for customer services and for information about how to apply
for permission to reuse the copyright material in this book please see our website at www.wiley.com.
The right of the author to be identiÔ¨Åed as the author of this work has been asserted in accordance with the
Copyright, Designs and Patents Act 1988.
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or
transmitted, in any form or by any means, electronic, mechanical, photocopying, recording or otherwise,
except as permitted by the UK Copyright, Designs and Patents Act 1988, without the prior permission of
the publisher.
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print may
not be available in electronic books.
Designations used by companies to distinguish their products are often claimed as trademarks. All brand
names and product names used in this book are trade names, service marks, trademarks or registered
trademarks of their respective owners. The publisher is not associated with any product or vendor
mentioned in this book.
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in
preparing this book, they make no representations or warranties with respect to the accuracy or
completeness of the contents of this book and speciÔ¨Åcally disclaim any implied warranties of
merchantability or Ô¨Åtness for a particular purpose. It is sold on the understanding that the publisher is not
engaged in rendering professional services and neither the publisher nor the author shall be liable for
damages arising herefrom. If professional advice or other expert assistance is required, the services of a
competent professional should be sought.
Library of Congress Cataloging-in-Publication Data
Voss, Jochen.
An introduction to statistical computing : a simulation-based approach / Jochen Voss. ‚Äì First edition.
pages cm. ‚Äì (Wiley series in computational statistics)
Includes bibliographical references and index.
ISBN 978-1-118-35772-9 (hardback)
1. Mathematical statistics‚ÄìData processing.
I. Title.
QA276.4.V66 2013
519.501‚Ä≤13‚Äìdc23
2013019321
A catalogue record for this book is available from the British Library.
ISBN: 978-1-118-35772-9
Typeset in 10/12pt Times by Aptara Inc., New Delhi, India
1
2014

Contents
List of algorithms
ix
Preface
xi
Nomenclature
xiii
1
Random number generation
1
1.1
Pseudo random number generators
2
1.1.1
The linear congruential generator
2
1.1.2
Quality of pseudo random number generators
4
1.1.3
Pseudo random number generators in practice
8
1.2
Discrete distributions
8
1.3
The inverse transform method
11
1.4
Rejection sampling
15
1.4.1
Basic rejection sampling
15
1.4.2
Envelope rejection sampling
18
1.4.3
Conditional distributions
22
1.4.4
Geometric interpretation
26
1.5
Transformation of random variables
30
1.6
Special-purpose methods
36
1.7
Summary and further reading
36
Exercises
37
2
Simulating statistical models
41
2.1
Multivariate normal distributions
41
2.2
Hierarchical models
45
2.3
Markov chains
50
2.3.1
Discrete state space
51
2.3.2
Continuous state space
56
2.4
Poisson processes
58
2.5
Summary and further reading
67
Exercises
67

vi
CONTENTS
3
Monte Carlo methods
69
3.1
Studying models via simulation
69
3.2
Monte Carlo estimates
74
3.2.1
Computing Monte Carlo estimates
75
3.2.2
Monte Carlo error
76
3.2.3
Choice of sample size
80
3.2.4
ReÔ¨Åned error bounds
82
3.3
Variance reduction methods
84
3.3.1
Importance sampling
84
3.3.2
Antithetic variables
88
3.3.3
Control variates
93
3.4
Applications to statistical inference
96
3.4.1
Point estimators
97
3.4.2
ConÔ¨Ådence intervals
100
3.4.3
Hypothesis tests
103
3.5
Summary and further reading
106
Exercises
106
4
Markov Chain Monte Carlo methods
109
4.1
The Metropolis‚ÄìHastings method
110
4.1.1
Continuous state space
110
4.1.2
Discrete state space
113
4.1.3
Random walk Metropolis sampling
116
4.1.4
The independence sampler
119
4.1.5
Metropolis‚ÄìHastings with different move types
120
4.2
Convergence of Markov Chain Monte Carlo methods
125
4.2.1
Theoretical results
125
4.2.2
Practical considerations
129
4.3
Applications to Bayesian inference
137
4.4
The Gibbs sampler
141
4.4.1
Description of the method
141
4.4.2
Application to parameter estimation
146
4.4.3
Applications to image processing
151
4.5
Reversible Jump Markov Chain Monte Carlo
158
4.5.1
Description of the method
160
4.5.2
Bayesian inference for mixture distributions
171
4.6
Summary and further reading
178
4.6
Exercises
178
5
Beyond Monte Carlo
181
5.1
Approximate Bayesian Computation
181
5.1.1
Basic Approximate Bayesian Computation
182
5.1.2
Approximate Bayesian Computation with regression
188
5.2
Resampling methods
192

CONTENTS
vii
5.2.1
Bootstrap estimates
192
5.2.2
Applications to statistical inference
197
5.3
Summary and further reading
209
Exercises
209
6
Continuous-time models
213
6.1
Time discretisation
213
6.2
Brownian motion
214
6.2.1
Properties
216
6.2.2
Direct simulation
217
6.2.3
Interpolation and Brownian bridges
218
6.3
Geometric Brownian motion
221
6.4
Stochastic differential equations
224
6.4.1
Introduction
224
6.4.2
Stochastic analysis
226
6.4.3
Discretisation schemes
231
6.4.4
Discretisation error
236
6.5
Monte Carlo estimates
243
6.5.1
Basic Monte Carlo
243
6.5.2
Variance reduction methods
247
6.5.3
Multilevel Monte Carlo estimates
250
6.6
Application to option pricing
255
6.7
Summary and further reading
259
Exercises
260
Appendix A
Probability reminders
263
A.1 Events and probability
263
A.2 Conditional probability
266
A.3 Expectation
268
A.4 Limit theorems
269
A.5 Further reading
270
Appendix B
Programming in R
271
B.1
General advice
271
B.2
R as a Calculator
272
B.2.1
Mathematical operations
273
B.2.2
Variables
273
B.2.3
Data types
275
B.3
Programming principles
282
B.3.1
Don‚Äôt repeat yourself!
283
B.3.2
Divide and conquer!
286
B.3.3
Test your code!
290
B.4
Random number generation
292
B.5
Summary and further reading
294
Exercises
294

viii
CONTENTS
Appendix C
Answers to the exercises
299
C.1
Answers for Chapter 1
299
C.2
Answers for Chapter 2
315
C.3
Answers for Chapter 3
319
C.4
Answers for Chapter 4
328
C.5
Answers for Chapter 5
342
C.6
Answers for Chapter 6
350
C.7
Answers for Appendix B
366
References
375
Index
379

List of algorithms
Random number generation
alg. 1.2
linear congruential generator
2
alg. 1.13
inverse transform method
12
alg. 1.19
basic rejection sampling
15
alg. 1.22
envelope rejection sampling
19
alg. 1.25
rejection sampling for conditional distributions
22
Simulating statistical models
alg. 2.9
mixture distributions
47
alg. 2.11
componentwise simulation
49
alg. 2.22
Markov chains with discrete state space
53
alg. 2.31
Markov chains with continuous state space
58
alg. 2.36
Poisson process
61
alg. 2.41
thinning method for Poisson processes
65
Monte Carlo methods
alg. 3.8
Monte Carlo estimate
75
alg. 3.22
importance sampling
85
alg. 3.26
antithetic variables
89
alg. 3.31
control variates
93
Markov Chain Monte Carlo methods
alg. 4.2
Metropolis‚ÄìHastings method for continuous state space
110
alg. 4.4
Metropolis‚ÄìHastings method for discrete state space
113
alg. 4.9
random walk Metropolis
117
alg. 4.11
independence sampler
119
alg. 4.12
Metropolis‚ÄìHastings method with different move types
121
alg. 4.27
Gibbs sampler
142
alg. 4.31
Gibbs sampler for the Ising model
155
alg. 4.32
Gibbs sampler in image processing
158
alg. 4.36
reversible jump Markov Chain Monte Carlo
165

x
LIST OF ALGORITHMS
Beyond Monte Carlo
alg. 5.1
basic Approximate Bayesian Computation
182
alg. 5.6
Approximate Bayesian Computation with regression
191
alg. 5.11
general bootstrap estimate
196
alg. 5.15
bootstrap estimate of the bias
200
alg. 5.18
bootstrap estimate of the standard error
202
alg. 5.20
simple bootstrap conÔ¨Ådence interval
205
alg. 5.21
BCa bootstrap conÔ¨Ådence interval
207
Continuous-time models
alg. 6.6
Brownian motion
217
alg. 6.12
Euler‚ÄìMaruyama scheme
232
alg. 6.15
Milstein scheme
235
alg. 6.26
multilevel Monte Carlo estimates
251
alg. 6.29
Euler‚ÄìMaruyama scheme for the Heston model
256

Preface
This is a book about exploring random systems using computer simulation and thus,
this book combines two different topic areas which have always fascinated me:
the mathematical theory of probability and the art of programming computers. The
method of using computer simulations to study a system is very different from the
more traditional, purely mathematical approach. On the one hand, computer exper-
iments normally can only provide approximate answers to quantitative questions,
but on the other hand, results can be obtained for a much wider class of systems,
including large and complex systems where a purely theoretical approach becomes
difÔ¨Åcult.
In this text we will focus on three different types of questions. The Ô¨Årst, easiest
question is about the normal behaviour of the system: what is a typical state of the sys-
tem? Such questions can be easily answered using computer experiments: simulating
a few random samples of the system gives examples of typical behaviour. The second
kind of question is about variability: how large are the random Ô¨Çuctuations? This
type of question can be answered statistically by analysing large samples, generated
using repeated computer simulations. A Ô¨Ånal, more complicated class of questions is
about exceptional behaviour: how small is the probability of the system behaving in
a speciÔ¨Åed untypical way? Often, advanced methods are required to answer this third
type of question. The purpose of this book is to explain how such questions can be
answered. My hope is that, after reading this book, the reader will not only be able
to conÔ¨Ådently use methods from statistical computing for answering such questions,
but also to adjust existing methods to the requirements of a given problem and, for
use in more complex situations, to develop new specialised variants of the existing
methods.
This text originated as a set of handwritten notes which I used for teaching
the ‚ÄòStatistical Computing‚Äô module at the University of Leeds, but now is greatly
extended by the addition of many examples and more advanced topics. The material
we managed to cover in the ‚ÄòStatistical Computing‚Äô course during one semester is less
than half of what is now the contents of the book! This book is aimed at postgraduate
students and their lecturers; it can be used both for self-study and as the basis of
taught courses. With the inclusion of many examples and exercises, the text should
also be accessible to interested undergraduate students and to mathematically inclined
researchers from areas outside mathematics.

xii
PREFACE
Only very few prerequisites are required for this book. On the mathematical side,
the text assumes that the reader is familiar with basic probability, up to and including
the law of large numbers; Appendix A summarises the required results. As a con-
sequence of the decision to require so little mathematical background, some of the
Ô¨Åner mathematical subtleties are not discussed in this book. Results are presented in a
way which makes them easily accessible to readers with limited mathematical back-
ground, but the statements are given in a form which allows the mathematically more
knowledgeable reader to easily add the required detail on his/her own. (For example,
I often use phrases such as ‚Äòevery set A ‚äÜRd‚Äô where full mathematical rigour would
require us to write ‚Äòevery measurable set A ‚äÜRd‚Äô.) On the computational side, basic
programming skills are required to make use of the numerical methods introduced
in this book. While the text is written independent of any speciÔ¨Åc programming
language, the reader will need to choose a language when implementing methods
from this book on a computer. Possible choices of programming language include
Python, Matlab and C/C++. For my own implementations, provided as part of the
solutions to the exercises in Appendix C, I used the R programming language; a short
introduction to programming with R is provided in Appendix B.
Writing this book has been a big adventure for me. When I started this project,
more than a year ago, my aim was to cover enough material so that I could discuss
the topics of multilevel Monte Carlo and reversible jump Markov Chain Monte Carlo
methods. I estimated that 350 pages would be enough to cover this material but it
quickly transpired that I had been much too optimistic: my estimates for the Ô¨Ånal
page count kept rising and even after several rounds of throwing out side-topics and
generally tightening the text, the book is still stretching this limit! Nevertheless, the
text now covers most of the originally planned topics, including multilevel Monte
Carlo methods near the very end of the book. Due to my travel during the last year,
parts of this book have been written on a laptop in exciting places. For example, the
initial draft of section 1.5 was written on a coach travelling through the beautiful
island of Kyushu, halfway around the world from where I live! All in all, I greatly
enjoyed writing this book and I hope that the result is useful to the reader.
This book contains an accompanying website. Please visit www.wiley.com/
go/statistical_computing
Jochen Voss
Leeds, March 2013

Nomenclature
For reference, the following list summarises some of the notation used throughout
this book.
√∏
the empty set
N
the natural numbers: N = {1, 2, 3, . . .}
N0
the non-negative integers: N = {0, 1, 2, . . .}
Z
the integers: Z = {. . . , ‚àí2, ‚àí1, 0, 1, 2, . . .}
n mod m
the remainder of the division of n by m, in the range 0, 1, . . . , m ‚àí1
Œ¥kl
the Kronecker delta: Œ¥kl = 1 if k = l and Œ¥kl = 0 otherwise
R
the real numbers
‚åàx‚åâ
the number x ‚ààR ‚Äòrounded up‚Äô, that is the smallest integer greater than
or equal to x
(an)n‚ààN
a sequence of (possibly random) numbers: (an)n‚ààN = (a1, a2, . . .)
O(¬∑)
the big O notation, introduced in deÔ¨Ånition 3.16
[a, b]
an interval of real numbers: [a, b] =

x ‚ààR
 a ‚â§x ‚â§b

{a, b}
the set containing a and b
A‚àÅ
the complement of a set: A‚àÅ=

x
 x /‚ààA

.
A √ó B
the Cartesian product of the sets A and B:
A √ó B =

(a, b)
 a ‚ààA, b ‚ààB

1A(x)
the indicator function of the set A: 1A(x) = 1 if x ‚ààA and 0 otherwise
(see section A.3)
U[0, 1]
the uniform distribution on the interval [0, 1]
U{‚àí1, 1}
the uniform distribution on the two-element set {‚àí1, 1}
Pois(Œª)
the Poisson distribution with parameter Œª
X ‚àºŒº
indicates that a random variable X is distributed according to a probability
distribution Œº
|S|
the number of elements in a Ô¨Ånite set S; in section 1.4 also the volume of
a subsets S ‚äÜRd
RS
space of vectors where the components are indexed by elements of S (see
section 2.3.2)
RS√óS
space of matrices where rows and columns are indexed by elements of S
(see section 2.3.2)

1
Random number generation
The topic of this book is the study of statistical models using computer simulations.
Here we use the term ‚Äòstatistical models‚Äô to mean any mathematical models which
include a random component. Our interest in this chapter and the next is in simu-
lation of the random component of these models. The basic building block of such
simulations is the ability to generate random numbers on a computer, and this is the
topic of the present chapter. Later, in Chapter 2, we will see how the methods from
Chapter 1 can be combined to simulate more complicated models.
Generation of random numbers, or more general random objects, on a computer
is complicated by the fact that computer programs are inherently deterministic: while
the output of computer program may look random, it is obtained by executing the
steps of some algorithm and thus is totally predictable. For example the output of a
program computing the decimal digits of the number
œÄ = 3.14159265358979323846264338327950288419716939937510 ¬∑ ¬∑ ¬∑
(the ratio between the perimeter and diameter of a circle) looks random at Ô¨Årst sight,
but of course œÄ is not random at all! The output can only start with the string of digits
given above and running the program twice will give the same output twice.
We will split the problem of generating random numbers into two distinct sub-
problems: Ô¨Årst we will study the problem of generating any randomness at all, con-
centrating on the simple case of generating independent random numbers, uniformly
distributed on the interval [0, 1]. This problem and related concerns will be discussed
in Section 1.1. In the following sections, starting with Section 1.2, we will study the
generation of random numbers from different distributions, using the independent,
uniformly distributed random numbers obtained in the previous step as a basis.
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

2
AN INTRODUCTION TO STATISTICAL COMPUTING
1.1
Pseudo random number generators
There are two fundamentally different classes of methods to generate random
numbers:
(a) True random numbers are generated using some physical phenomenon which
is random. Generating such numbers requires specialised hardware and can
be expensive and slow. Classical examples of this include tossing a coin or
throwing dice. Modern methods utilise quantum effects, thermal noise in
electric circuits, the timing of radioactive decay, etc.
(b) Pseudo random numbers are generated by computer programs. While these
methods are normally fast and resource effective, a challenge with this
approach is that computer programs are inherently deterministic and therefore
cannot produce ‚Äòtruly random‚Äô output.
In this text we will only consider pseudo random number generators.
DeÔ¨Ånition 1.1
A pseudo random number generator (PRNG) is an algorithm which
outputs a sequence of numbers that can be used as a replacement for an independent
and identically distributed (i.i.d.) sequence of ‚Äòtrue random numbers‚Äô.
1.1.1
The linear congruential generator
This section introduces the linear congruential generator (LCG), a simple example of
a PRNG. While this random number generator is no longer of practical importance,
it shares important characteristics with the more complicated generators used in
practice today and we study it here as an accessible example. The LCG is given by
the following algorithm.
Algorithm 1.2
(linear congruential generator)
input:
m > 1 (the modulus)
a ‚àà{1, 2, . . . , m ‚àí1} (the multiplier)
c ‚àà{0, 1, . . . , m ‚àí1} (the increment)
X0 ‚àà{0, 1, . . . , m ‚àí1} (the seed)
output:
a sequence X1, X2, X3, . . . of pseud random numbers
1: for n = 1, 2, 3, . . . do
2:
Xn ‚Üê(aXn‚àí1 + c) mod m
3:
output Xn
4: end for

RANDOM NUMBER GENERATION
3
In the algorithm, ‚Äòmod‚Äô denotes the modulus for integer division, that is the value
n mod m is the remainder of the division of n by m, in the range 0, 1, . . . , m ‚àí
1. Thus the sequence generated by algorithm 1.2 consists of integers Xn from the
range {0, 1, 2, . . . , m ‚àí1}. The output depends on the parameters m, a, c and on the
seed X0. We will see that, if m, a and c are carefully chosen, the resulting sequence
behaves ‚Äòsimilar‚Äô to a sequence of independent, uniformly distributed random vari-
ables. By choosing different values for the seed X0, different sequences of pseudo
random numbers can be obtained.
Example 1.3
For parameters m = 8, a = 5, c = 1 and seed X0 = 0, algorithm 1.2
gives the following output:
n
5Xn‚àí1 + 1
Xn
1
1
1
2
6
6
3
31
7
4
36
4
5
21
5
6
26
2
7
11
3
8
16
0
9
1
1
10
6
6
The output 1, 6, 7, 4, 5, 2, 3, 0, 1, 6, . . . shows no obvious pattern and could be con-
sidered to be a sample of a random sequence.
While the output of the LCG looks random, from the way it is generated it is
clear that the output has several properties which make it different from truly random
sequences. For example, since each new value of Xn is computed from Xn‚àí1, once the
generated series reaches a value Xn which has been generated before, the output starts
to repeat. In example 1.3 this happens for X8 = X0 and we get X9 = X1, X10 = X2
and so on. Since Xn can take only m different values, the output of a LCG starts
repeating itself after at most m steps; the generated sequence is eventually periodic.
Sometimes the periodicity of a sequence of pseudo random numbers can cause
problems, but on the other hand, if the period length is longer than the amount of
random numbers we use, periodicity cannot affect our result. For this reason, one
needs to carefully choose the parameters m, a and c in order to achieve a long enough
period. In particular m, since it is an upper bound for the period length, needs to be
chosen large. In practice, typical values of m are on the order of m = 232 ‚âà4 ¬∑ 109
and a and c are then chosen such that the generator actually achieves the maximally
possible period length of m. A criterion for the choice of m, a and c is given in the
following theorem (Knuth, 1981, Section 3.2.1.2).

4
AN INTRODUCTION TO STATISTICAL COMPUTING
Theorem 1.4
The LCG has period m if and only if the following three conditions
are satisÔ¨Åed:
(a) m and c are relatively prime;
(b) a ‚àí1 is divisible by every prime factor of m;
(c) if m is a multiple of 4, then a ‚àí1 is a multiple of 4.
In the situation of the theorem, the period length does not depend on the seed X0
and usually this parameter is left to be chosen by the user of the PRNG.
Example 1.5
Let m = 232, a = 1 103 515 245 and c = 12 345. Since the only
prime factor of m is 2 and c is odd, the values m and c are relatively prime and condition
(a) of the theorem is satisÔ¨Åed. Similarly, condition (b) is satisÔ¨Åed, since a ‚àí1 is
even and thus divisible by 2. Finally, since m is a multiple of 4, we have to check
condition (c) but, since a ‚àí1 = 1 103 515 244 = 275 878 811 ¬∑ 4, this condition also
holds. Therefore the LCG with these parameters m, a and c has period 232 for every
seed X0.
1.1.2
Quality of pseudo random number generators
PRNGs used in modern software packages such as R or Matlab are more sophisticated
(and more complicated) than the LCG presented in Section 1.1.1, but they still share
many characteristics of the LCG. We will see that no PRNG can produce a perfect
result, but the random number generators used in practice, for example the Mersenne
Twister algorithm (Matsumoto and Nishimura, 1998), are good enough for most
purposes. In this section we will discuss criteria for the quality of the output of
general PRNGs, and will illustrate these criteria using the LCG as an example.
1.1.2.1
Period length of the output
We have seen that the output of the LCG is eventually periodic, with a period length
of at most m. This property that the output is eventually periodic is shared by all
PRNGs implemented in software. Most PRNGs used in practice have a period length
which is much larger than the amount of random numbers a computer program could
ever use in a reasonable time. For this reason, periodicity of the output is not a big
problem in practical applications of PRNGs. The period length is a measure for the
quality of a PRNG.
1.1.2.2
Distribution of samples
The output of almost all PRNGs is constructed so that it can be used as a replacement
for an i.i.d. sample of uniformly distributed random numbers. Since the output takes

RANDOM NUMBER GENERATION
5
values in a Ô¨Ånite set S = {0, 1, . . . , m ‚àí1}, in the long run, for every set A ‚äÜS we
should have
#

i
 1 ‚â§i ‚â§N, Xi ‚ààA

N
‚âà#A
#S ,
(1.1)
where #A stands for the number of elements in a Ô¨Ånite set A.
Uniformity of the output can be tested using statistical tests like the chi-
squared test or the Kolmogorov‚ÄìSmirnov test (see e.g. Lehmann and Romano, 2005,
Chapter 14).
One peculiarity when applying statistical tests for the distribution of samples to the
output of a PRNG is that the test may fail in two different ways: The output could either
have the wrong distribution (i.e. not every value appears with the same probability),
or the output could be too regular. For example, the sequence Xn = n mod m hits
every value equally often in the long run, but it shows none of the Ô¨Çuctuations which
are typical for a sequence of real random numbers. For this reason, statistical tests
should be performed as two-sided tests when the distribution of the output of a PRNG
is being tested.
Example 1.6
Assume that we have a PRNG with m = 1024 possible output values
and that we perform a chi-squared test for the hypothesis
P (Xi ‚àà{64 j, 64 j + 1, . . . , 64 j + 63}) = 1/16
for j = 0, 1, . . . , 15.
If we consider a sample X1, X2, . . . , X N, the test statistic of the chi-squared test
is computed from the observed numbers of samples in each block, given by
O j = #

i
 64 j ‚â§Xi < 64( j + 1)

.
The expected count for block j, assuming that (1.1) holds, is
E j = N ¬∑ 64/1024 = N/16
for j = 0, 1, . . . , 15 and the test statistic of the corresponding chi-squared test is
Q =
15

j=0
(O j ‚àíE j)2
E j
.

6
AN INTRODUCTION TO STATISTICAL COMPUTING
For large sample size N, and under the hypothesis (1.1), the value Q follows a
œá2-distribution with 15 degrees of freedom. Some quantiles of this distribution are:
q
6.262
7.261
¬∑ ¬∑ ¬∑
24.996
27.488
P(Q ‚â§q)
0.025
0.05
¬∑ ¬∑ ¬∑
0.95
0.975
Thus, for a one-sided test with signiÔ¨Åcance level 1 ‚àíŒ± = 95% we would reject the
hypothesis if Q > 24.996. In contrast, for a two-sided test with signiÔ¨Åcance level
1 ‚àíŒ± = 95%, we would reject the hypothesis if either Q < 6.262 or Q > 27.488.
We consider two different test cases: Ô¨Årst, if Xn = n mod 1024 for n =
1, 2, . . . , N = 106, we Ô¨Ånd Q = 0.244368. Since the series is very regular, the value
of Q is very low. The one-sided test would accept this sequence as being uniformly
distributed, whereas the two-sided test would reject the sequence.
Secondly, we consider Xn = n mod 1020 for n = 1, 2, . . . , N = 106. Since this
series never takes the values 1021 to 1023, the distribution is wrong and we expect a
large value of Q. Indeed, for this case we get Q = 232.5864 and thus both versions
of the test reject this sequence.
Random number generators used in practice, and even the LCG for large enough
values of m, pass statistical tests for the distribution of the output samples without
problems.
1.1.2.3
Independence of samples
Another aspect of the quality of PRNGs is the possibility of statistical dependence
between consecutive samples. For example, in the LCG each output sample is a
deterministic function of the previous sample and thus consecutive samples are clearly
dependent. To some extent this problem is shared by all PRNGs.
An easy way to visualise the dependence between pairs of consecutive samples
is a scatter plot of the points (Xi, Xi+1) for i = 1, 2, . . . , N ‚àí1. A selection of such
plots is shown in Figure 1.1. Figure 1.1(a) illustrates what kind of plot one would
expect if Xi ‚àºU[0, 1] was a true i.i.d. sequence. The remaining panels correspond
to different variants of the LCG. Figure 1.1(b) (using m = 81) clearly illustrates that
each Xi can only be followed by exactly one value Xi+1. While the same is true for
Figure 1.1(c) and (d) (using m = 1024 and m = 232, respectively), the dependence
is much convoluted there and in particular the structure of Figure 1.1(d) is visually
indistinguishable from the structure of Figure 1.1(a).
One method for constructing PRNGs where Xi+1 is not a function of Xi is to
use a function f (Xi) of the state, instead of the state Xi itself, as the output of
the PRNG. Here, f : {0, 1, . . . , m ‚àí1} ‚Üí{0, 1, . . . , Àúm ‚àí1} is a map where Àúm < m
and where the same number of pre-images is mapped to each output value. Then a
uniform distribution of Xi will be mapped to a uniform distribution for f (Xi) but
the output f (Xi+1) is not a function of the previous output f (Xi). This allows to
construct random number generators with some degree of independence between
consecutive values.

RANDOM NUMBER GENERATION
7
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Xi
Xi+1
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Xi
Xi+1
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Xi
Xi+1
Xi+1
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Xi
(a)
(b)
(c)
(d)
Figure 1.1
Scatter plots to illustrate the correlation between consecutive outputs
Xi and Xi+1 of different pseudo random number generators. The random number
generators used are the runif function in R (a), the LCG with m = 81, a = 1 and
c = 8 (b), the LCG with m = 1024, a = 401, c = 101 (c) and Ô¨Ånally the LCG with
parameters m = 232, a = 1 664 525, c = 1 013 904 223 (d). Clearly the output in the
second and third example does not behave like a sequence of independent random
variables.
One way to quantify the independence of the output samples of a PRNG is the
following criterion.
DeÔ¨Ånition 1.7
A periodic sequence (Xn)n‚ààN with values in a Ô¨Ånite set S and
period length P is k-dimensionally equidistributed, if every possible subsequence
x = (x1, . . . , xk) ‚ààSk of length k occurs equally often in the sequence X, that is if
Nx = #

i
 0 ‚â§i < P, Xi+1 = xi, . . . , Xi+k = xk

does not depend on x.
A random number generator is good, if the output is k-dimensionally equidis-
tributed for large values of k.

8
AN INTRODUCTION TO STATISTICAL COMPUTING
1.1.3
Pseudo random number generators in practice
This section contains advice on using PRNGs in practice.
First, it is normally a bad idea to implement your own PRNG: Ô¨Ånding a good
algorithm for pseudo random number generation is a difÔ¨Åcult problem, and even
when an algorithm is available, given the nature of the generated output, it can be
a challenge to spot and remove all mistakes in the implementation. Therefore, it is
advisable to use a well-established method for random number generation, typically
the random number generator built into a well-known software package or provided
by a well-established library.
A second consideration concerns the rÀÜole of the seed. While different PRNGs
differ greatly in implementation details, they all use a seed (like the value X0 in
algorithm 1.2) to initialise the state of the random number generator. Often, when
non-predictability is required, it is useful to set the seed to some volatile quantity
(like the current time) to get a different sequence of random numbers for different
runs of the program. At other times it can be more useful to get reproducible results,
for example to aid debugging or to ensure repeatability of published results. In these
cases, the seed should be set to a known, Ô¨Åxed value.
Finally, PRNGs like the LCG described above often generate a sequence which
behaves like a sequence of independent random numbers, uniformly distributed on a
Ô¨Ånite set {0, 1, . . . , m ‚àí1} for a big value of m. In contrast, most applications require
a sequence of independent, U[0, 1]-distributed random variables, that is a sequence
of i.i.d. values which are uniformly distributed on the real interval [0, 1]. We can
obtain a sequence (Un)n‚ààN of pseudo random numbers to replace an i.i.d. sequence
of U[0, 1] random variables by setting
Un = Xn + 1
m + 1 ,
where (Xn)n‚ààN is the output of the PRNG. The output Un can only take the m different
values
1
m + 1,
2
m + 1, . . . ,
m
m + 1
and thus Un is not exactly uniformly distributed on the continuous interval [0, 1].
But, since the possible values are evenly spaced inside the interval [0, 1] and since
each of these values has the same probability, the distribution of Un is a reasonable
approximation to a uniform distribution on [0, 1]. This is particularly true since
computers can only represent Ô¨Ånitely many real numbers exactly.
This concludes our discussion of how a replacement for an i.i.d. sequence of
U[0, 1]-distributed random numbers can be generated on a computer.
1.2
Discrete distributions
Building on the methods from Section 1.1, in this and the following sections we will
study methods to transform an i.i.d. sequence of U[0, 1]-distributed random variables

RANDOM NUMBER GENERATION
9
into an i.i.d. sequence from a prescribed target distribution. The methods from the
previous section were inexact, since the output of a PRNG is not ‚Äòtruly random‚Äô.
In contrast, the transformations described in this and the following sections can be
carried out with complete mathematical rigour. We will discuss different methods for
generating samples from a given distribution, applicable to different classes of target
distributions. In this section we concentrate on the simplest case where the target
distribution only takes Ô¨Ånitely or countably inÔ¨Ånitely many values.
As a Ô¨Årst example, we consider the uniform distribution on the set A =
{0, 1, . . . , n ‚àí1}, denoted by U{0, 1, . . . , n ‚àí1}. Since the set A has n elements,
a random variable X with X ‚àºU{0, 1, . . . , n ‚àí1} satisÔ¨Åes
P(X = k) = 1
n
for all k ‚ààA. To generate samples from such a random variable X, at Ô¨Årst it may
seem like a good idea to just use a PRNG with state space A, for example the LCG
with modulus m = n. But considering the fact that the maximal period length of a
PRNG is restricted to the size of the state space, it becomes clear that this is not a
good idea. Instead we will follow the approach to Ô¨Årst generate a continuous sample
U ‚àºU[0, 1] and then to transform this sample into the required discrete uniform
distribution. A method to implement this idea is described in the following lemma.
Lemma 1.8
Let U ‚àºU[0, 1] and n ‚ààN. DeÔ¨Åne a random variable X by X = ‚åänU‚åã,
where ‚åä¬∑‚åãdenotes rounding down. Then X ‚àºU{0, 1, . . . , n ‚àí1}.
Proof
By the deÔ¨Ånition of X we have
P (X = k) = P (‚åänU‚åã= k) = P (nU ‚àà[k, k + 1)) = P

U ‚àà
k
n , k + 1
n

for all k = 0, 1, . . . , n ‚àí1.
The uniform distribution U[0, 1] is characterised by the fact that U ‚àºU[0, 1]
satisÔ¨Åes
P (U ‚àà[a, b]) = b ‚àía
for all 0 ‚â§a ‚â§b ‚â§1. Also, since U is a continuous distribution, we have P(U =
x) = 0 for all x ‚àà[0, 1] and thus the boundary points of the interval [a, b] can be
included or excluded without changing the probability. Using these results, we Ô¨Ånd
P (X = k) = P

U ‚àà
k
n , k + 1
n

= k + 1
n
‚àík
n = 1
n
for all k = 0, 1, . . . , n ‚àí1. This completes the proof.
Another common problem related to discrete distributions is the problem of
constructing random events which occur with a given probability p. Such events will,

10
AN INTRODUCTION TO STATISTICAL COMPUTING
for example, be needed in the rejection algorithms considered in Section 1.4. There
are many fascinating aspects to this problem, but here we will restrict ourselves to the
simplest case where the probability p is known explicitly and where we have access to
U[0, 1]-distributed random variables. This case is considered in the following lemma.
Lemma 1.9
Let p ‚àà[0, 1] andU ‚àºU[0, 1] and deÔ¨Åne the event E as E = {U ‚â§p}.
Then P(E) = p.
Proof
We have
P(E) = P(U ‚â§p) = P (U ‚àà[0, p]) = p ‚àí0 = p.
This completes the proof.
The idea underlying lemmas 1.8 and 1.9 can be generalised to sample from
arbitrary distributions on a Ô¨Ånite set A. Let A = {a1, . . . , an} where ai Ã∏= a j for
i Ã∏= j and let p1, . . . , pn ‚â•0 be given with 	n
i=1 pi = 1. Assume that we want to
generate random values X ‚ààA with P(X = ai) = pi for i = 1, 2, . . . , n. Since the
pi sum up to 1, we can split the unit interval [0, 1] into disjoint sub-intervals lengths
p1, . . . , pn.
0
p1
p2
p3
¬∑ ¬∑ ¬∑
pn
1
U
With this arrangement, if we choose U ‚àà[0, 1] uniformly, the value of U lies in the
ith subinterval with probability pi. Thus, we can choose X to be the ai corresponding
to the subinterval which contains U. This idea is formalised in the following lemma.
Lemma 1.10
Assume A = {ai | i ‚ààI} where either I = {1, 2, . . . , n} for some
n ‚ààN or I = N, and where ai Ã∏= a j whenever i Ã∏= j. Let pi ‚â•0 be given for i ‚ààI
with 	
i‚ààI pi = 1. Finally let U ‚àºU[0, 1] and deÔ¨Åne
K = min

k ‚ààI

k

i=1
pi ‚â•U

.
(1.2)
Then X = aK ‚ààA satisÔ¨Åes P(X = ak) = pk for all k ‚ààI.
Proof
We have
P(X = ak) = P(K = k) = P
k‚àí1

i=1
pi < U,
k

i=1
pi ‚â•U

= P

U ‚àà
k‚àí1

i=1
pi,
k

i=1
pi

=
k

i=1
pi ‚àí
k‚àí1

i=1
pi = pk

RANDOM NUMBER GENERATION
11
for all k ‚ààI, where we interpret the sum 	0
i=1 pi for k = 1 as 0. This completes the
proof.
The numerical method described by lemma 1.10 requires that we Ô¨Ånd the index K
of the subinterval which contains U. The most efÔ¨Åcient way to do this is to Ô¨Ånd a
function œï which maps the boundaries of the subintervals to consecutive integers and
then to consider the rounded value ‚åäœï(I)‚åã. This approach is taken in lemma 1.8 and
also in the following example.
Example 1.11
The geometric distribution, describing the number X of individual
trials with probability p until the Ô¨Årst success, has probability weights P(X = i) =
pi‚àí1(1 ‚àíp) = pi for i ‚ààN. We can use lemma 1.10 with ai = i for all i ‚ààN to
generate samples from this distribution.
For the weights pi, the value sum in equation (1.2) can be determined explicitly:
using the formula for geometric sums we Ô¨Ånd
k

i=1
pi = (1 ‚àíp)
k

i=1
pi‚àí1 = (1 ‚àíp)1 ‚àípk
1 ‚àíp = 1 ‚àípk.
Thus, we can rewrite the event 	k
i=1 pi ‚â•U as follows:

U ‚â§
k

i=1
pi

=

U ‚â§1 ‚àípk
=

pk ‚â§1 ‚àíU

= {k log(p) ‚â§log(1 ‚àíU)}
=

k ‚â•log(1 ‚àíU)
log(p)

.
In the last expression, we had to change the ‚â§sign into a ‚â•sign, since we divided by
the negative number log(p). By deÔ¨Ånition, the K from equation (1.2) is the smallest
integer such that 	k
i=1 pi ‚â•U is satisÔ¨Åed and thus the smallest integer greater than
or equal to log(1 ‚àíU)/ log(p). Thus, the value
X = aK = K =
log(1 ‚àíU)
log(p)

,
where ‚åà¬∑‚åâdenotes the operation of rounding up a number to the nearest integer, is
geometrically distributed with parameter p.
1.3
The inverse transform method
The inverse transform method is a method which can be applied when the target
distribution is one-dimensional, that is to generate samples from a prescribed target

12
AN INTRODUCTION TO STATISTICAL COMPUTING
x
F(x)
u
F ‚àí1(u)
v
F ‚àí1(v)
w
F ‚àí1(w)
a
Figure 1.2
Illustration of the inverse F‚àí1 of a CDF F. At level u the function F
is continuous and injective; here F‚àí1 coincides with the usual inverse of a function.
The value v falls in the middle of a jump of F and thus has no preimage; F‚àí1(v) is
the preimage of the right-hand limit of F and F(F‚àí1(v)) Ã∏= v. At level w the function
F is not injective, several points map to w; the preimage F‚àí1(w) is the left-most of
these points and we have, for example, F‚àí1(F(a)) Ã∏= a.
distribution on the real numbers R. The method uses the cumulative distribution
function (CDF) (see Section A.1) to specify the target distribution and can be applied
for distributions which have no density.
DeÔ¨Ånition 1.12
Let F be a distribution function. Then the inverse of F is
deÔ¨Åned by
F‚àí1(u) = inf

x ‚ààR
 F(x) ‚â•u

for all u ‚àà(0, 1).
The deÔ¨Ånition of the inverse of a distribution function is illustrated in Figure 1.2.
In the case where F is bijective, that is when F is strictly monotonically increasing
and has no jumps, F‚àí1 is just the usual inverse of a function. In this case we can
Ô¨Ånd F‚àí1(u) by solving the equation F(x) = u for x. The following algorithm can be
used to generate samples from a given distribution, whenever the inverse F‚àí1 of the
distribution function can be determined.
Algorithm 1.13
(inverse transform method)
input:
the inverse F‚àí1 of a CDF F
randomness used:
U ‚àºU[0, 1]

RANDOM NUMBER GENERATION
13
output:
X ‚àºF
1: generate U ‚àºU[0, 1]
2: return X = F‚àí1(U)
This algorithm is very simple and it directly transforms U[0, 1]-distributed sam-
ples into samples with distribution function F. The following proposition shows that
the samples X generated by algorithm 1.13 have the correct distribution.
Proposition 1.14
Let F: R ‚Üí[0, 1] be a distribution function and U ‚àºU[0, 1].
DeÔ¨Åne X = F‚àí1(U). Then X has distribution function F.
Proof
Using the deÔ¨Ånitions of X and F‚àí1 we Ô¨Ånd
P(X ‚â§a) = P

F‚àí1(U) ‚â§a

= P (inf{ x | F(x) ‚â•U } ‚â§a) .
Since inf{ x | F(x) ‚â•U } ‚â§a holds if and only if F(a) ‚â•U, we can conclude
P(X ‚â§a) = P (F(a) ‚â•U) = F(a)
where the Ô¨Ånal equality comes from the deÔ¨Ånition of the uniform distribution on the
interval [0, 1].
Example 1.15
The exponential distribution Exp(Œª) has density
f (x) =
Œªe‚àíŒªx
if x ‚â•0 and
0
otherwise.
Using integration, we Ô¨Ånd the corresponding CDF as
F(a) =
 a
‚àí‚àû
f (x) dx =
 a
0
Œªe‚àíŒªx dx = ‚àíe‚àíŒªxa
x=0 = 1 ‚àíe‚àíŒªa
for all a ‚â•0. Since this function is strictly monotonically increasing and continuous,
F‚àí1 is the usual inverse of F. We have
1 ‚àíe‚àíŒªx = u
‚áê‚áí
‚àíŒªx = log(1 ‚àíu)
‚áê‚áí
x = ‚àílog(1 ‚àíu)
Œª
and thus F‚àí1(u) = ‚àílog(1 ‚àíu)/Œª for all u ‚àà(0, 1). Now assume U ‚àºU[0, 1]. Then
proposition 1.14 gives that X = ‚àílog(1 ‚àíU)/Œª is Exp(Œª)-distributed. Thus we have
found a method to transform U[0, 1] random variables into Exp(Œª)-distributed random
variables. The method can be further simpliÔ¨Åed by using the observation that U and
1 ‚àíU have the same distribution: if U ‚àºU[0, 1], then ‚àílog(U)/Œª ‚àºExp(Œª).

14
AN INTRODUCTION TO STATISTICAL COMPUTING
Example 1.16
The Rayleigh distribution with parameter œÉ > 0 has density
f (x) =
‚éß
‚é®
‚é©
x
œÉ 2 e‚àíx2/2œÉ 2
if x ‚â•0 and
0
otherwise.
For this distribution we Ô¨Ånd
F(a) =
 a
0
x
œÉ 2 e‚àíx2/2œÉ 2 dx = ‚àíe‚àíx2/2œÉ 2
a
x=0 = 1 ‚àíe‚àía2/2œÉ 2
for all a ‚â•0. Solving the equation u = F(x) = 1 ‚àíe‚àía2/2œÉ 2 for x we Ô¨Ånd the
inverse F‚àí1(u) = x =

‚àí2œÉ 2 log(1 ‚àíu). By proposition 1.14 we know that X =

‚àí2œÉ 2 log(1 ‚àíU) has density f if we choose U ‚àºU[0, 1]. As in the previous
example, we can also write U instead of 1 ‚àíU.
Example 1.17
Let X have density
f (x) =
3x2
for x ‚àà[0, 1] and
0
otherwise.
Then
F(a) =
 a
‚àí‚àû
f (x) dx =
‚éß
‚é®
‚é©
0
if a < 0
a3
if 0 ‚â§a < 1 and
1
for 1 ‚â§a.
Since F maps (0, 1) into (0, 1) bijectively, F‚àí1 is given by the usual inverse function
and consequently F‚àí1(u) = u1/3 for all u ‚àà(0, 1). Thus, by proposition 1.14, if
U ‚àºU[0, 1], the cubic root U 1/3 has the same distribution as X.
Example 1.18
Let X be discrete with P(X = 0) = 0.6 and P(X = 1) = 0.4. Then
F(a) =
‚éß
‚é®
‚é©
0
if a < 0
0.6
if 0 ‚â§a < 1 and
1
if 1 ‚â§a.
Using the deÔ¨Ånition of F‚àí1 we Ô¨Ånd
F‚àí1(u) =
0
if 0 < u ‚â§0.6 and
1
if 0.6 < u < 1.

RANDOM NUMBER GENERATION
15
By proposition 1.14 we can construct a random variable X with the correct distribution
from U ‚àºU[0, 1], by setting
X =
0
if U ‚â§0.6 and
1
if U > 0.6.
The inverse transform method can always be applied when the inverse F‚àí1 is
easy to evaluate. For some distributions like the normal distribution this is not the
case, and the inverse transform method cannot be applied directly. The method can be
applied (but may not be very useful) for discrete distributions such as in example 1.18.
The main restriction of the inverse transform method is that distribution functions
only exist in the one-dimensional case. For distributions on Rd where d > 1, more
sophisticated methods are required.
1.4
Rejection sampling
The rejection sampling method is a more advanced, and very popular, method for
random number generation. Several aspects make this method different from basic
methods such as inverse transform method discussed in the previous section. First,
rejection sampling is not restricted to U[0, 1]-distributed input samples. The method
is often used in multi-stage approaches where different methods are used to generate
samples of approximately the correct distribution and then rejection sampling is used
to convert these samples to follow the target distribution exactly. Secondly, while we
state the method here only for distributions on the Euclidean space Rd, the rejection
sampling method can be generalised to work on very general spaces. Finally, a
random and potentially large number of input samples is required to generate one
output sample in the rejection method. As a consequence, the efÔ¨Åciency of the method
becomes a concern.
1.4.1
Basic rejection sampling
In this section we introduce the fundamental idea that all rejection algorithms are
based on. We start by presenting the basic algorithm which forms the prototype of
the methods presented later.
Algorithm 1.19
(basic rejection sampling)
input:
a probability density g (the proposal density),
a function p with values in [0,1] (the acceptance probability)
randomness used:
Xn i.i.d. with density g (the proposals),
Un ‚àºU[0, 1] i.i.d.

16
AN INTRODUCTION TO STATISTICAL COMPUTING
output:
a sequence of i.i.d. random variables with density
f (x) = 1
Z p(x)g(x)
where
Z =

p(x)g(x) dx.
(1.3)
1: for n = 1, 2, 3, . . . do
2:
generate Xn with density g
3:
generate Un ‚àºU[0, 1]
4:
if Un ‚â§p(Xn) then
5:
output Xn
6:
end if
7: end for
The effect of the random variables Un in the algorithm is to randomly decide
whether to output or to ignore the value Xn: the value Xn is output with probability
p(Xn), and using the trick from lemma 1.9 we use the event {U ‚â§p(Xn)} to decide
whether or not to output the value. In the context of rejection sampling, the random
variables Xn are called proposals. If the proposal Xn is chosen for output, that is if
Un ‚â§p(Xn), we say that Xn is accepted, otherwise we say that Xn is rejected.
Proposition 1.20
For k ‚ààN, let X Nk denote the kth output of algorithm 1.19. Then
the following statements hold:
(a) The elements of the sequence (X Nk)k‚ààN are i.i.d. with density f given by
(1.3).
(b) Each proposal is accepted with probability Z; the number of proposals
required to generate each X Nk is geometrically distributed with mean 1/Z.
Proof
For Ô¨Åxed n, the probability of accepting Xn is
P (Un ‚â§p(Xn)) =

p(x)g(x) dx = Z,
(1.4)
where Z is the constant deÔ¨Åned in equation (1.3). Since the decisions whether to accept
Xn for different n are independent, the time until the Ô¨Årst success is geometrically
distributed with mean 1/Z as required. This completes the proof of the second
statement.
For the proof of the Ô¨Årst statement, Ô¨Årst note that the indices N1, N2, N3, . . . of
the accepted Xn are random. If we let N0 = 0, we can write
Nk = min

n ‚ààN
 n > Nk-1,Un ‚â§p(Xn)


RANDOM NUMBER GENERATION
17
for all k ‚ààN. If we consider the distribution of X Nk conditional on the value of Nk‚àí1,
we Ô¨Ånd
P

X Nk ‚ààA
 Nk‚àí1 = n

=
‚àû

m=1
P

Nk = n + m, Xn+m ‚ààA
 Nk‚àí1 = n

=
‚àû

m=1
P (Un+1 > p(Xn+1), . . . ,Un+m‚àí1 > p(Xn+m‚àí1),
Un+m ‚â§p(Xn+m), Xn+m ‚ààA
 Nk‚àí1 = n

=
‚àû

m=1
P (Un+1 > p(Xn+1)) ¬∑ ¬∑ ¬∑ P (Un+m-1 > p(Xn+m-1)) ¬∑
P (Un+m ‚â§p(Xn+m), Xn+m ‚ààA) .
Here we used the fact that all the probabilities considered in the last expression are
independent of the value of Nk‚àí1. Similar to (1.4) we Ô¨Ånd
P (Un ‚â§p(Xn), Xn ‚ààA) =

A
p(x)g(x) dx
and consequently we have
P

X Nk ‚ààA
 Nk‚àí1 = n

=
‚àû

m=1
(1 ‚àíZ)m‚àí1

A
p(x)g(x) dx
= 1
Z

A
p(x)g(x) dx
by the geometric series formula. Since the right-hand side does not depend on n, we
can conclude
P

X Nk ‚ààA

= 1
Z

A
p(x)g(x) dx
and thus we Ô¨Ånd that X Nk has density pg/Z.
To see that the X Nk are independent we need to show that
P

X N1 ‚ààA1, . . . , X Nk ‚ààAk

=
k
i=1
P

X Ni ‚ààAi


18
AN INTRODUCTION TO STATISTICAL COMPUTING
for all sets A1, . . . , Ak and for all k ‚ààN. This can be done by summing up the
probabilities for the cases N1 = n1, . . . , Nk = nk, similar to the Ô¨Årst part of the
proof, but we omit this tedious calculation here.
Example 1.21
Let X ‚àºU[‚àí1, +1] and accept X with probability
p(X) =

1 ‚àíX2.
Then, by proposition 1.20, the accepted samples have density
f (x) = 1
Z p(x)g(x) = 1
Z ¬∑

1 ‚àíx2 ¬∑ 1
21[‚àí1,+1](x),
where we use the indicator function notation from equation (A.7) to get the
abbreviation
1[‚àí1,+1](x) =
1
if x ‚àà[‚àí1, +1] and
0
otherwise
and
Z =

R

1 ‚àíx2 ¬∑ 1
21[‚àí1,+1](x) dx = 1
2
 1
‚àí1

1 ‚àíx2 dx = 1
2 ¬∑ œÄ
2 = œÄ
4 .
Combining these results, we Ô¨Ånd that the density f of accepted samples is given by
f (x) = 2
œÄ

1 ‚àíx2 1[‚àí1,+1](x).
The graph of the density f forms a semicircle and the resulting distribution is known
as Wigner‚Äôs semicircle distribution.
One important property of the rejection algorithm 1.19 is that none of the steps in
the algorithm makes any reference to the normalisation constant Z. Thus, we do not
need to compute the value of Z in order to apply this algorithm. We will see that this
fact, while looking like a small detail at Ô¨Årst glance, is extremely useful in practical
applications.
1.4.2
Envelope rejection sampling
The basic rejection sampling algorithm 1.19 from the previous section is usually
applied by choosing the acceptance probabilities p so that the density f of the
output values, given by (1.3), coincides with a given target distribution. The resulting
algorithm can be written as in the following.

RANDOM NUMBER GENERATION
19
Algorithm 1.22
(envelope rejection sampling)
input:
a function f with values in [0, ‚àû) (the non-normalised target density),
a probability density g (the proposal density),
a constant c > 0 such that f (x) ‚â§c g(x) for all x
randomness used:
Xn i.i.d. with density g (the proposals),
Un ‚àºU[0, 1] i.i.d.
output:
a sequence of i.i.d. random variables with density
Àúf (x) = 1
Z f
f (x)
where
Z f =

f (x) dx
1: for n = 1, 2, 3, . . . do
2:
generate Xn with density g
3:
generate Un ‚àºU[0, 1]
4:
if cg(Xn)Un ‚â§f (Xn) then
5:
output Xn
6:
end if
7: end for
The assumption in the algorithm is that we can already sample from the distri-
bution with probability density g, but we would like to generate samples from the
distribution with density Àúf instead. Normally, f will be chosen to be a probability
density and in this case we have Àúf = f , but in some situations the normalising con-
stant Z f is difÔ¨Åcult to obtain and due to the distinction between f and Àúf , in these
situations the algorithm can still be applied. The rejection mechanism employed in
algorithm 1.22 is illustrated in Figure 1.3. The function cg is sometimes called an
‚Äòenvelope‚Äô for f .
Proposition 1.23
Let X Nk for k ‚ààN denote the kth output value of algorithm 1.22
with (non-normalised) target density f . Then the following statements hold:
(a) The elements of the sequence (X Nk)k‚ààN are i.i.d. with density Àúf .
(b) Each proposal is accepted with probability Z f /c; the number Mk = Nk ‚àí
Nk‚àí1 of proposals required to generate each X Nk is geometrically distributed
with mean E(Mk) = c/Z f .
Proof
Algorithm 1.22 coincides with algorithm 1.19 where the acceptance proba-
bility p is chosen as
p(x) =
 f (x)
cg(x)
if g(x) > 0 and
1
otherwise.

20
AN INTRODUCTION TO STATISTICAL COMPUTING
x
Xk
c ¬∑ g(Xk)
cg(Xk)Uk
f
cg
Figure 1.3
Illustration of the envelope rejection sampling method from algorithm
1.22. The proposal (Xk, cg(Xk) Uk) is accepted, if it falls into the area underneath the
graph of f . In Section 1.4.4 we will see that the proposal is distributed uniformly on
the area under the graph of cg.
In this situation, the normalisation constant Z from (1.3) is given by:
Z =

p(x)g(x) dx =

f (x)
cg(x) g(x) dx = 1
c

f (x) dx = Z f /c.
From proposition 1.20 we then know that the output of algorithm 1.19 is an i.i.d.
sequence with density
1
Z pg = c
Z f
f
cg g = 1
Z f
f
and that the required number of proposals to generate one output sample is geomet-
rically distributed with mean 1/Z = c/Z f .
Example 1.24
We can use rejection sampling to generate samples from the half-
normal distribution with density
f (x) =

2
‚àö
2œÄ exp

‚àíx2
2

if x ‚â•0 and
0
otherwise.
(1.5)

RANDOM NUMBER GENERATION
21
If we assume that the proposals are Exp(Œª)-distributed, then the density of the pro-
posals is
g(x) =
Œª exp(‚àíŒªx)
if x ‚â•0 and
0
otherwise.
In order to apply algorithm 1.22 we need to determine a constant c > 0 such
that f (x) ‚â§cg(x) for all x ‚ààR. For x < 0 we have f (x) = g(x) = 0. For x ‚â•0 we
have
f (x)
g(x) =
2
‚àö
2œÄŒª
exp

‚àíx2
2 + Œªx

.
It is easy to check that the quadratic function ‚àíx2/2 + Œªx attains its maximum at
x = Œª. Thus we have
f (x)
g(x) ‚â§c‚àó
for all x ‚â•0, where
c‚àó=
2
‚àö
2œÄŒª
exp

‚àíŒª2
2 + Œª ¬∑ Œª

=

2
œÄŒª2 exp

Œª2/2

.
Consequently, any c ‚â•c‚àósatisÔ¨Åes the condition f ‚â§cg. From proposition 1.23 we
know that the average number of proposals required for generating one sample, and
thus the computational cost, is proportional to c. Thus we should choose c as small
as possible and c = c‚àóis the optimal choice.
Given our choice of g and c, the acceptance criterion from algorithm 1.22 can be
simpliÔ¨Åed as follows:
cg(x) U ‚â§f (x)
‚áê‚áí

2
œÄŒª2 exp
Œª2
2

Œª exp(‚àíŒªx) U ‚â§
2
‚àö
2œÄ
exp

‚àíx2
2

‚áê‚áí
U ‚â§exp

‚àíx2
2 + Œªx ‚àíŒª2
2

‚áê‚áí
U ‚â§exp

‚àí1
2(x ‚àíŒª)2

.
This leads to the following algorithm for generating samples from the half-normal
distribution:
1: for n = 1, 2, 3, . . . do
2:
generate Xn ‚àºExp(Œª)
3:
generate Un ‚àºU[0, 1]

22
AN INTRODUCTION TO STATISTICAL COMPUTING
4:
if Un ‚â§exp(‚àí1
2(Xn ‚àíŒª)2) then
5:
output Xn
6:
end if
7: end for
Finally, since the density f is the density of a standard-normal distribution con-
ditioned on being positive, and since the normal distribution is symmetric, we can
generate standard normal distributed values by randomly choosing Xn or ‚àíXn, both
with probability 1/2, for each accepted sample.
In algorithm 1.22, we can choose the density g of the proposal distribution in
order to maximise efÔ¨Åciency of the method. The only constraint is that we need to
be able to Ô¨Ånd the constant c. This condition implies, for example, that the support
of g cannot be smaller than the support of f , that is we need g(x) > 0 whenever
f (x) > 0. The average cost of generating one sample is given by the average number
of proposals required times the cost for generating each proposal. Therefore the
algorithm is efÔ¨Åcient, if the following two conditions are satisÔ¨Åed:
(a) There is an efÔ¨Åcient method to generate the proposals Xi. This affects the
choice of the proposal density g.
(b) The average number c/Z f of proposals required to generate one sample is
small. This number is inÔ¨Çuenced by the value of c and, since the possible
choices of c depend on g, also by the proposal density g.
1.4.3
Conditional distributions
The conditional distribution PX|X‚ààA corresponds to the remaining randomness in X
when we already know that X ‚ààA occurred (see equation (A.4) for details). Sampling
from a conditional distribution can be easily done by rejection sampling. The basic
result is the following.
Algorithm 1.25
(rejection sampling for conditional distributions)
input:
a set A with P(X ‚ààA) > 0
randomness used:
a sequence Xn of i.i.d. copies of X (the proposals)
output:
a sequence of i.i.d. random variables with distribution PX|X‚ààA
1: for n = 1, 2, 3, . . . do
2:
generate Xn
3:
if Xn ‚ààA then
4:
output Xn
5:
end if
6: end for

RANDOM NUMBER GENERATION
23
Proposition 1.26
Let X be a random variable and let A be a set. Furthermore, let
X Nk for k ‚ààN denote the kth output value of algorithm 1.25. Then the following
statements hold:
(a) The elements of the sequence (X Nk)k‚ààN are i.i.d. and satisfy
P(X Nk ‚ààB) = P(X ‚ààB|X ‚ààA)
for all k ‚ààN and all sets B.
(b) The number Mk = Nk ‚àíNk‚àí1 of proposals required to generate each X Nk is
geometrically distributed with mean E(Mk) = 1/P(X ‚ààA).
Proof
Algorithm 1.25 is a special case of algorithm 1.19 where the acceptance
probability is chosen as p(x) = 1A(x). For this choice of p, the decision whether or
not to accept the proposal given the value of Xn is deterministic and thus we can omit
generation of the auxiliary random variables Un in the algorithm.
Now assume that the distribution of X has a density g. Using equation (1.3) we
then Ô¨Ånd
Z =

1A(x)g(x) dx = P(X ‚ààA)
and by proposition 1.20 we have
P(X Nk ‚ààB) =

B 1A(x)g(x) dx
Z
= P(X ‚ààB ‚à©A)
P(X ‚ààA)
= P(X ‚ààB|X ‚ààA).
A similar proof gives the result in the case where X does not have a density. This
completes the proof of the Ô¨Årst statement of the proposition. The second statement is
a direct consequence of proposition 1.20.
The method presented in algorithm 1.25 works well if p = P(X ‚ààA) is not too
small; the time required for producing a single output sample is proportional to 1/p.
Example 1.27
We can use algorithm 1.25 to generate samples X ‚àºN(0, 1), con-
ditioned on X ‚â•a. We simply have to repeat the following two steps until enough
samples are output:
(a) generate X ‚àºN(0, 1);
(b) if X ‚â•a, output X.
The efÔ¨Åciency of this method depends on the value of a. The following table
shows the average number E(Na) of samples required to generate one output sample
for different values of a, rounded to the nearest integer:

24
AN INTRODUCTION TO STATISTICAL COMPUTING
a
1
2
3
4
5
6
E(Na)
6
44
741
31 574
3 488 556
1 013 594 692
The table shows that the method will be slow even for moderate values of a. For
a ‚â•5 the required number of samples is so large that the method will likely be no
longer practical.
For conditions with very small probabilities, rejection sampling can still be used
to generate samples from the conditional distribution, but we have to use the full
rejection sampling algorithm 1.22 instead of the simpliÔ¨Åed version from algorithm
1.25. This is illustrated in the following example.
Example 1.28
We can use algorithm 1.22 to generate samples from the condi-
tional distribution of X ‚àºN(0, 1), conditioned on X ‚â•a > 0. The density of the
conditional distribution is
Àúf (x) = 1
Z exp(‚àíx2/2)1[a,‚àû](x) = 1
Z f (x),
where Z is the normalising constant (we have included the pre-factor 1/
‚àö
2œÄ into Z
to simplify notation).
We can sample from this distribution using proposals of the form X = ÀúX + a
where ÀúX ‚àºExp(Œª). This proposal distribution has density
g(x) = Œª exp (‚àíŒª(x ‚àía)) 1[a,‚àû](x)
and we need to Ô¨Ånd a constant c > 0 such that f (x) ‚â§cg(x) for all x ‚â•a. Also, we
can still choose the parameter Œª and, in order to maximise efÔ¨Åciency of the method,
we should choose a value of Œª such that the shape of g is as similar to the shape of f
as possible. In order to achieve this, we choose c and Œª so that at x = a both the values
and the derivatives of f and cg coincide (see Figure 1.4 for illustration). This leads to
the conditions e‚àía2/2 = f (a) = cg(a) = cŒª and ‚àíae‚àía2/2 = f ‚Ä≤(a) = cg‚Ä≤(a) = ‚àícŒª2
and solving these two equations for the two unknowns c and Œª gives Œª = a and
c = e‚àía2/2/a.
Figure 1.4 indicates that for this choice of Œª and c, condition f ‚â§cg will be
satisÔ¨Åed. Indeed we Ô¨Ånd
f (x)
cg(x) =
exp(‚àíx2/2)
1/a exp(‚àía2/2) ¬∑ a exp (‚àía(x ‚àía))
= exp

‚àíx2/2 + ax ‚àía2/2

= exp

‚àí(x ‚àía)2
2

‚â§1

RANDOM NUMBER GENERATION
25
x
a
f(a) = cg(a), f (a) = cg (a)
f(x)
cg(x)
Figure 1.4
Illustration of the rejection mechanism from example 1.28. The graph
shows the (scaled) proposal density cg, enveloping the (non-normalised) target den-
sity f .
and thus f (x) ‚â§cg(x) for all x ‚â•a. Thus, we can apply algorithm 1.22 with proposal
density g to generate samples from the distribution with density Àúf . The resulting
method consists of the following steps:
(a) generate ÀúX ‚àºExp(a) and U ‚àºU[0, 1];
(b) let X = ÀúX + a;
(c) if U ‚â§exp(‚àí(X ‚àía)2/2), output X.
From proposition 1.23 we know that the average number Ma of proposals required
to generate one sample is
E(Ma) =
c

R f (x) dx =
exp(‚àía2/2)/a
 ‚àû
a exp(‚àíx2/2) dx =
exp(‚àía2/2)
a
‚àö
2œÄ (1 ‚àí(a))
,
where
(a) =
1
‚àö
2œÄ
 a
‚àí‚àû
exp(‚àíx2/2) dx
is the CDF of the standard normal distribution. The following table lists the value of
E(Ma), rounded to three signiÔ¨Åcant digits, for different values of a:
a
1
2
3
4
5
6
E(Ma)
1.53
1.19
1.09
1.06
1.04
1.03
The table clearly shows that the resulting algorithm works well for large values of a:
the steps required to generate one proposal are more complicated than for the method
from example 1.27, but signiÔ¨Åcantly fewer proposals are required.

26
AN INTRODUCTION TO STATISTICAL COMPUTING
1.4.4
Geometric interpretation
The rejection sampling method can be applied not only to the generation of random
numbers, but also to the generation of random objects in arbitrary spaces. To illustrate
this, in this section we consider the problem of sampling from the uniform distribution
on subsets of the Euclidean space Rd. We then use the resulting techniques to give
an alternative proof of proposition 1.23, based on geometric arguments.
We write |A| for the d-dimensional volume of a set A ‚äÜRd. Then the cube Q =
[a, b]3 ‚äÜR3 has volume |Q| = (b ‚àía)3, the unit circle C = {x ‚ààR2  x2
1 + x2
2 ‚â§1}
has two-dimensional ‚Äòvolume‚Äô œÄ (area) and the line segment [a, b] ‚äÜR has one-
dimensional ‚Äòvolume‚Äô b ‚àía (length). For more general sets A, the volume can be
found by integration: we have
|A| =

Rd 1A(x) dx =

¬∑ ¬∑ ¬∑

1A(x1, . . . , xd) dxd ¬∑ ¬∑ ¬∑ dx1.
DeÔ¨Ånition 1.29
A random variable X with values in Rd is uniformly distributed on
a set A ‚äÜRd with 0 < |A| < ‚àû, if
P(X ‚ààB) = |A ‚à©B|
|A|
for all B ‚äÜRd. As for real intervals, we use the notation X ‚àºU(A) to indicate that
X is uniformly distributed on A.
The intuitive meaning of X being uniformly distributed on a set A is that X is
a random element of A, and that all regions of A are hit by X equally likely. The
probability of X falling into a subset of A only depends on the volume of this subset,
but not on the location inside A.
Let X ‚àºU(A). From the deÔ¨Ånition we can derive simple properties of the uniform
distribution: Ô¨Årst we have
P(X ‚ààA) = |A ‚à©A|
|A|
= 1
and if A and B are disjoint we Ô¨Ånd
P(X ‚ààB) = |A ‚à©B|
|A|
= |‚àÖ|
|A| = 0.
For general B ‚äÜRd we get
P(X /‚ààB) = P(X ‚ààRd \ B)
= |A ‚à©(Rd \ B)|
|A|
= |A \ B|
|A|
= |A| ‚àí|A ‚à©B|
|A|
= 1 ‚àí|A ‚à©B|
|A|
.

RANDOM NUMBER GENERATION
27
Lemma 1.30
Let A ‚äÜRd be a set with volume 0 < |A| < ‚àû. Then the uniform
distribution U(A) has probability density f = 1A/|A| on Rd.
Proof
Let X ‚àºU(A). For B ‚äÜRd we have
P(X ‚ààB) = |A ‚à©B|
|A|
= 1
|A|

Rd 1A‚à©B(x) dx =

Rd 1B(x)1A(X)
|A|
dx
and thus X has the given density f .
Lemma 1.31
Let X be uniformly distributed on a set A, and let B be a set with
|A ‚à©B| > 0. Then the conditional distribution PX|X‚ààB of X conditioned on the event
X ‚ààB coincides with the uniform distribution on A ‚à©B.
Proof
From the deÔ¨Ånition of the uniform distribution we get
P(X ‚ààC|X ‚ààB) = P(X ‚ààB ‚à©C)
P(X ‚ààB)
= |A ‚à©B ‚à©C|/|A|
|A ‚à©B|/|A|
= |(A ‚à©B) ‚à©C|
|A ‚à©B|
.
Since this is the probability of a U(A ‚à©B)-distributed random variable to hit the
set C, the statement is proved.
By combining the result of lemma 1.31 with the method given in algorithm 1.25,
we can sample from the uniform distribution of every set which can be covered by a
(union of) rectangles. This is illustrated in the following example.
Example 1.32
(uniform distribution on the circle) Let Xn, Yn ‚àºU[‚àí1, +1] be i.i.d.
By exercise E1.10 the pairs (Xn, Yn) are then uniformly distributed on the square
A = [0, 1] √ó [0, 1]. Now let (Zk)k‚ààN be the subsequence of all pairs (Xnk, Ynk) which
satisfy the condition
X2
n + Y 2
n ‚â§1.
Then (Zk)k‚ààN is an i.i.d. sequence, uniformly distributed on the unit circle
B =

x ‚ààR2  |x| ‚â§1

. The probability p to accept each sample is given by
p = P((Xn, Vn) ‚ààB) = |B|
|A| = œÄ12
22 = œÄ
4 ‚âà78.5%
and the number of proposals required to generate one sample is, on average,
1/p ‚âà1.27.

28
AN INTRODUCTION TO STATISTICAL COMPUTING
To conclude this section, we give an alternative proof of proposition 1.23. This
proof is based on the geometric approach taken in this section and uses a connection
between distributions with general densities on Rd and uniform distributions on Rd+1,
given in the following result.
Lemma 1.33
Let f : Rd ‚Üí[0, ‚àû) be a probability density and let
A =

(x, y) ‚ààRd √ó [0, ‚àû)
 0 ‚â§y < f (x)

‚äÜRd+1.
Then |A| = 1 and the following two statements are equivalent:
(a) (X, Y) is uniformly distributed on A.
(b) X is distributed with density f on Rd and Y = f (X)U where U ‚àºU[0, 1],
independently of X.
Proof
The volume of the set A can be found by integrating the ‚Äòheight‚Äô f (x) over
all of Rd. Since f is a probability density, we get
|A| =

Rd f (x) dx = 1.
Assume Ô¨Årst that (X, Y) is uniformly distributed on A and deÔ¨Åne U = Y/f (X).
Since (X, Y) ‚ààA, we have f (X) > 0 with probability 1 and thus there is no problem
in dividing by f (X). Given sets C ‚äÜRd and D ‚äÜR we Ô¨Ånd
P (X ‚ààC,U ‚ààD) = P

(X, Y) ‚àà

(x, y)
 x ‚ààC, y/f (x) ‚ààD

=
A ‚à©

(x, y)
 x ‚ààC, y/f (x) ‚ààD

=

Rd

f (x)
0
1C(x)1D (y/f (x)) dy dx.
Using the substitution u = y/f (x) in the inner integral we get
P (X ‚ààC,U ‚ààD) =

Rd
 1
0
1C(x)1D(u) f (x) du dx
=

C
f (x) dx ¬∑

D
1[0,1](u) du.
Therefore X and U are independent with densities f and 1[0,1], respectively.

RANDOM NUMBER GENERATION
29
For the converse statement assume now that the random variables X with density
f and U ‚àºU[0, 1] are independent, and let Y = f (X)U. Furthermore let C ‚äÜRd,
D ‚äÜ[0, ‚àû) and B = C √ó D. Then we get
P ((X, Y) ‚ààB) = P (X ‚ààC, Y ‚ààD)
=

C
P(Y ‚ààD|X = x) f (x) dx
=

C
P ( f (x)U ‚ààD) f (x) dx
=

C
|D ‚à©[0, f (x)]|
f (x)
f (x) dx
=

C
|D ‚à©[0, f (x)]| dx.
On the other hand we have
|A ‚à©B| =

Rd

f (x)
0
1B(x, y) dy dx
=

Rd 1C(x)

f (x)
0
1D(y) dy dx
=

C
|D ‚à©[0, f (x)]| dx
and thus P((X, Y) ‚ààB) = |A ‚à©B|. This shows that (X, Y) is uniformly distributed
on A.
An easy application of lemma 1.33 is to convert a uniform distribution of a subset
of R2 to a distribution on R with a given density f : [a, b] ‚ÜíR. For simplicity, we
assume Ô¨Årst that f lives on a bounded interval [a, b] and satisÔ¨Åes f (x) ‚â§M for all
x ‚àà[a, b]. We can generate samples from the distribution with density f as follows:
(a) Let (Xk, Yk) are be i.i.d., uniformly distributed on the rectangle R = [a, b] √ó
[0, M].
(b) Consider the set A = {(x, y) ‚ààR
 y ‚â§f (x)} and let N = min{ k ‚ààN |
Xk ‚ààB }. By lemma 1.31, (X N, YN) is uniformly distributed on A.
(c) By lemma 1.33, the value X N is distributed with density f .
This procedure is illustrated in Figure 1.5.
In the situation of algorithm 1.22, that is when f is deÔ¨Åned on an unbounded
set, we cannot use proposals which are uniformly distributed on a rectangle any-
more. A solution to this problem is to use lemma 1.33 a second time to obtain a
suitable proposal distribution. This approach provides an alternative way of under-
standing algorithm 1.22: in the situation of algorithm 1.22, Xk has density g and
Uk is uniformly distributed on [0, 1]. Then we know from lemma 1.33 that the

30
AN INTRODUCTION TO STATISTICAL COMPUTING
a
b
0
M
R
f
A
f
Yk
Xk
Figure 1.5
Illustration of the rejection sampling method where the graph of the target
density is contained in a rectangle R = [a, b] √ó [0, M]. In this case the proposals
are uniformly distributed on the rectangle R and a proposal is accepted if it falls into
the shaded region.
pair (Xk, g(Xk)Uk) is uniformly distributed on the set {(x, v)
 0 ‚â§v < g(x)}. Con-
sequently, Zk = (Xk, cg(Xk)Uk) is uniformly distributed on A = {(x, y)
 0 ‚â§y <
cg(x)}. By lemma 1.31 and proposition 1.26, the accepted values are uniformly
distributed on the set B = {(x, y)
 0 ‚â§y < f (x)} ‚äÜA and, applying lemma 1.33
again, we Ô¨Ånd that the Xk, conditional on being accepted, have density f . This
argument can be made into an alternative proof of proposition 1.23.
1.5
Transformation of random variables
Samples from a wide variety of distributions can be generated by considering
deterministic transformations of random variables. The inverse transform method,
introduced in Section 1.3, is a special case of this technique where we transform a
uniformly distributed random variable using the inverse of a CDF. In this section, we
consider more general transformations.
The fundamental question we have to answer in order to generate samples by
transforming a random variable is the following: if X is a random variable with
values in Rd and a given distribution, and if œï : Rd ‚ÜíRd is a function, what is the
distribution of œï(X)? This question is answered in the following theorem.
Theorem 1.34
(transformation of random variables) Let A, B ‚äÜRd be open sets,
œï : A ‚ÜíB be bijective and differentiable with continuous partial derivatives, and

RANDOM NUMBER GENERATION
31
let X be a random variable with values in A. Furthermore let g : B ‚Üí[0, ‚àû) be a
probability density and deÔ¨Åne f : Rd ‚ÜíR by
f (x) =
g(œï(x)) ¬∑ |det Dœï(x)|
if x ‚ààA and
0
otherwise.
(1.6)
Then f is a probability density and the random variable X has density f if and only
if œï(X) has density g.
The matrix Dœï used in the theorem is the Jacobian of œï, as given in the following
deÔ¨Ånition.
DeÔ¨Ånition 1.35
Let œï : Rd ‚ÜíRd be differentiable. Then the Jacobian matrix Dœï
is the d √ó d matrix consisting of the partial derivatives of œï: for i, j = 1, 2, . . . , d
we have Dœï(x)i j = ‚àÇœïi
‚àÇx j (x).
Theorem 1.34 is a consequence of the substitution rule for integrals. Before we
give the proof of theorem 1.34, we Ô¨Årst state the substitution rule in the required form.
Lemma 1.36
(substitution rule for integrals) Let A, B ‚äÜRd be open sets, f : B ‚Üí
R integrable, and œï: A ‚ÜíB be bijective and differentiable with continuous partial
derivatives. Then

B
f (y) dy =

A
f (œï(x)) |det Dœï(x)| dx
where Dœï denotes the Jacobian matrix of œï.
A proof of lemma 1.36 can, for example, be found in the book by Rudin (1987,
theorem 7.26). Using lemma 1.36 we can now give the proof of the transformation
rule for random variables.
Proof
(of theorem 1.34). By deÔ¨Ånition, the function f is positive and using lemma
1.36, we get

Rd f (x) dx =

A
g (œï(x)) ¬∑ |det Dœï(x)| dx =

B
g(y) dy = 1.
Thus f is a probability density.
Now assume that X is distributed with density f and let C ‚äÜB. Then, by equation
(A.8):
P (œï(X) ‚ààC) =

A
1C (œï(x)) f (x) dx
=

A
1C (œï(x)) g (œï(x)) ¬∑ |det Dœï(x)| dx.

32
AN INTRODUCTION TO STATISTICAL COMPUTING
Now we can apply lemma 1.36, again, to transform the integral over A into an integral
over the set B: we Ô¨Ånd
P (œï(X) ‚ààC) =

B
1C(y)g(y) dy.
Since this equality holds for all sets C, the random variable œï(X) has density g. The
converse statement follows by reversing the steps in this argument.
While theorem 1.34 is most powerful in the multidimensional case, it can be
applied in the one-dimensional case, too. In this case the Jacobian matrix is a 1 √ó 1
matrix, that is a number, and we have |det Dœï(x)| = |œï‚Ä≤(x)|.
Example 1.37
(two-dimensional normal distribution) Assume that we want to
sample from the two-dimensional standard normal distribution, that is from the
distribution with density
g(x, y) = 1
2œÄ exp

‚àíx2 + y2
2

.
Since g depends on (x, y) only via the squared length x2 + y2 of this vector, we
try to simplify g using polar coordinates. The corresponding transformation œï is
given by
œï(r, Œ∏) = (r cos(Œ∏),r sin(Œ∏))
for all r > 0, œï ‚àà(0, 2œÄ). Note that we deÔ¨Åne œï only on the open set A = (0, ‚àû) √ó
(0, 2œÄ) in order to satisfy the requirement from theorem 1.34 that œï must be bijective.
The resulting image set is B = œï(A) = R2 \ {(x, y)
 x ‚â•0, y = 0}, that is B is
strictly smaller than R2 since it does not include the positive x-axis. This is not a
problem, since the two-dimensional standard normal distribution hits the positive
x-axis only with probability 0 and thus takes values in the set B with probability 1.
The Jacobian matrix of œï is given by
Dœï(r, Œ∏) =
 ‚àÇ
‚àÇr œï1
‚àÇ
‚àÇŒ∏ œï1
‚àÇ
‚àÇr œï2
‚àÇ
‚àÇŒ∏ œï2

=
 cos(Œ∏) ‚àír sin(Œ∏)
sin(Œ∏)
r cos(Œ∏)

and thus we get |det Dœï(r, Œ∏)| =
r cos(Œ∏)2 + r sin(Œ∏)2 = r. Using theorem 1.34 we
have reduced the problem of sampling from a two-dimensional normal distribution
to the problem of sampling from the density
f (r, Œ∏) = g (œï(r, Œ∏)) ¬∑ |det Dœï(r, Œ∏)| = 1
2œÄ exp(‚àír2/2) ¬∑ r
on (0, ‚àû) √ó (0, 2œÄ).

RANDOM NUMBER GENERATION
33
The density f (r, Œ∏) does not depend on Œ∏ and we can rewrite it as the product
f (r, Œ∏) = f1(Œ∏) f2(r) where f1(Œ∏) = 1/2œÄ is the density of U[0, 2œÄ] and f2(r) =
r exp(‚àír2/2). From example 1.16 we know how to sample from the density f2: if
U ‚àºU[0, 1], then R = ‚àö‚àí2 log(U) has density f2. Consequently, we can use the
following steps to sample from the density g:
(a) Generate  ‚àºU[0, 2œÄ] and U ‚àºU[0, 1] independently.
(b) Let R = ‚àö‚àí2 log(U).
(c) Let (X, Y) = œï(R, ) = (R cos(), R sin()).
Then (R, ) has density f and, by theorem 1.34, the vector (X, Y) is standard
normally distributed in R2. This method for converting pairs of uniformly distributed
samples into pairs of normally distributed samples is called the Box‚ÄìMuller transform
(Box and Muller, 1958).
When the lemma is used to Ô¨Ånd sampling methods, usually g will be the given
density of the distribution we want to sample from. Our task is then to Ô¨Ånd a trans-
formation œï so that the density f described by (1.6) corresponds to a distribution we
can already sample from. In this situation, œï should be chosen so that it ‚ÄòsimpliÔ¨Åes‚Äô
the given density g. In practice, Ô¨Ånding a useful transformation œï often needs some
experimentation.
Example 1.38
Assume we want to sample from the distribution with density
g(y) = 3
2
‚àöy ¬∑ 1[0,1](y). We can cancel the square root from the deÔ¨Ånition of g by
choosing œï(x) = x2. Then we can apply theorem 1.34 with A = B = [0, 1] and,
since |det Dœï(x)| =
œï‚Ä≤(x)
 = 2x, we get
f (x) = g (œï(x)) ¬∑ |det Dœï(x)| = 3
2x ¬∑ 2x = 3x2
for all x ‚àà[0, 1]. From example 1.17 we already know how to generate samples from
this density: If U ‚àºU[0, 1], then X = U 1/3 has density f and, by theorem 1.34,
Y = œï(X) = X2 = U 2/3 has density g.
An important application of the transformation rule from theorem 1.34 is the case
where X and œï(X) are both uniformly distributed. From the relation (1.6) we see that
if X is uniformly distributed and if |det Dœï| is constant, then œï(X) is also uniformly
distributed. For example, using this idea we can sometimes transform the problem of
sampling from the uniform distribution on an unbounded set to the easier problem
of sampling from the uniform distribution on a bounded set. This idea is illustrated
in Figure 1.6. Combining this approach with lemma 1.33 results in the following
general sampling method.

34
AN INTRODUCTION TO STATISTICAL COMPUTING
y0
y1
B
œï
x0
x1
A
(a)
(b)
Figure 1.6
Illustration of the transformation used in the ratio-of-uniforms method.
The map œï from equation (1.7) maps the bounded set shown in (b) into the unbounded
set in (a). The areas shown in grey in (b) map into the tails in (a) (not displayed).
Since œï preserves area (up to a constant), the uniform distribution on the set in (b) is
mapped into the uniform distribution on the set in (a).
Theorem 1.39
(ratio-of-uniforms method) Let f : Rd ‚ÜíR+ be such that Z =

Rd f (x) dx < ‚àûand let X be uniformly distributed on the set
A =

(x0, x1, . . . , xd)
 x0 > 0, xd+1
0
d + 1 < f
x1
x0
, . . . , xd
x0

‚äÜR+ √ó Rd.
Then the vector
Y =
 X1
X0
, . . . , Xd
X0

has density 1
Z f on Rd.
Proof
The proof is an application of the transformation rule for random variables.
To see this, consider the set
B =

(y0, y1, . . . , yd)
 0 < y0 < f (y1, . . . , yd) /Z

‚äÜR+ √ó Rd

RANDOM NUMBER GENERATION
35
and deÔ¨Åne a transformation œï : R+ √ó Rd ‚ÜíR+ √ó Rd by
œï(x0, x1, . . . , xd) =

Zxd+1
0
d + 1 , x1
x0
, . . . , xd
x0

.
(1.7)
We have x ‚ààA if and only if œï(x) ‚ààB and thus œï maps A onto B bijectively. Since
the determinant of a triagonal matrix is the product of the diagonal elements, the
Jacobian determinant of œï is given by
det Dœï(x) = det
‚éõ
‚éú‚éú‚éú‚éú‚éù
Zxd
0
‚àíx1
x2
0
1
x0
...
...
‚àíxd
x2
0
1
x0
‚éû
‚éü‚éü‚éü‚éü‚é†
= Zxd
0
1
x0
¬∑ ¬∑ ¬∑ 1
x0
= Z
for all x ‚ààA.
Since X is uniformly distributed on A, the density h of X satisÔ¨Åes
h(x) = 1
|A|1A(x) =
1
Z|A|1B (œï(x)) ¬∑ |det Dœï(x)|
and by theorem 1.34 the random variable œï(X) then has density
g(y) =
1
Z|A|1B(y)
for all y ‚ààR+ √ó Rd. This density is constant on B and thus the random variable
œï(X) is uniformly distributed on B.
To complete the proof we note that the vector Y given in the statement of the
theorem consists of the last d components of œï(X). Using this observation, the claim
now follows from lemma 1.33.
Example 1.40
The Cauchy distribution has density
f (x) =
1
œÄ(1 + x2).
For this case, the set A from theorem 1.39 is
A =
‚éß
‚é®
‚é©(x0, x1)
 x0 > 0, x2
0
2 ‚â§
1
œÄ

1 + ( x1
x0 )2

‚é´
‚é¨
‚é≠
=

(x0, x1)
 x0 > 0, œÄ
2 x2
0 ‚â§
x2
0
x2
0 + x2
1

=

(x0, x1)
 x0 > 0, x2
0 + x2
1 ‚â§2
œÄ

,

36
AN INTRODUCTION TO STATISTICAL COMPUTING
that is A is a semicircle in the x0/x1-plane. Since we can sample from the uniform
distribution on the semicircle (see exercises E1.13 and E1.14), we can use the ratio-
of-uniforms method from theorem 1.39 to sample from the Cauchy distribution. The
following steps are required:
(a) Generate (X0, X1) uniformly on the semicircle A.
(b) Return Y = X1/X0.
Note that, since only the ratio between X1 and X0 is returned, A can be replaced by
a semicircle with arbitrary radius instead of the radius ‚àö2/œÄ found above.
1.6
Special-purpose methods
There are many specialised methods to generate samples from speciÔ¨Åc distributions.
These are often faster than the generic methods described in the previous sections,
but can typically only be used for a single distribution. These specialised methods
(optimised for speed and often quite complex) form the basis of the random number
generators built into software packages. In contrast, the methods discussed in the
previous sections are general purpose methods which can be used for a wide range
of distributions when no pre-existing method is available.
1.7
Summary and further reading
In this chapter we have learned about various aspects of random number generation
on a computer. The chapter started by considering the differences between ‚Äòpseudo
random number generators‚Äô (the ones considered in this book) and ‚Äòreal random
number generators‚Äô (which we will not consider further). Using the LCG as an
example, we have learned about properties of pseudo number generators. In particular
we considered the rÀÜole of the ‚Äòseed‚Äô to control reproducability of the generated
numbers. Going beyond the scope of this book, a lot of information about LCGs
and about testing of random number generators can be found in Knuth (1981).
The Mersenne Twister, a popular modern PRNG, is described in Matsumoto and
Nishimura (1998).
Building on the output of pseudo number generators, the following sections
considered various general purpose methods for generating samples from different
distributions. The methods we discussed here are the inverse transform method,
the rejection sampling method, and the ratio-of-uniforms method (a special case
of the transformation method). More information about rejection sampling and its
extensions can be found in Robert and Casella (2004, Section 2.3). A specialised
method for generating normally distributed random variables can, for example, be
found in Marsaglia and Tsang (2000). Specialised methods for generating random
numbers from various distributions are, for example, covered in Dagpunar (2007,
Chapter 4) and Kennedy and Gentle (1980, Section 6.5).
An expository presentation of random number generation and many more refer-
ences can be found in Gentle et al. (2004, Chapter II.2).

RANDOM NUMBER GENERATION
37
Exercises
E1.1
Write a function to implement the LCG. The function should take a length n,
the parameters m, a and c as well as the seed X0 as input and should return
a vector X = (X1, X2, . . . , Xn). Test your function by calling it with the
parameters m = 8, a = 5 and c = 1 and by comparing the output with the
result from example 1.3.
E1.2
Given a sequence X1, X2, . . . of U[0, 1]-distributed pseudo random
numbers, we can use a scatter plot of (Xi, Xi+1) for i = 1, . . . , n ‚àí1 in
order to try to assess whether the Xi are independent.
(a)
Create such a plot using the built-in random number generator of R:
X <- runif(1000)
plot(X[1:999], X[2:1000], asp=1)
Can you explain the resulting plot?
(b)
Create a similar plot, using your function LCG from exercise E1.1:
m <- 81
a <- 1
c <- 8
seed <- 0
X <- LCG(1000, m, a, c, seed)/m
plot(X[1:999], X[2:1000], asp=1)
Discuss the resulting plot.
(c)
Repeat the experiment from (b) using the parameters m = 1024, a =
401, c = 101 and m = 232, a = 1 664 525, c = 1 013 904 223. Discuss
the results.
E1.3
One (very early) method for pseudo random number generation is von Neu-
mann‚Äôs middle square method (von Neumann, 1951). The method works as
follows: starting with X0 ‚àà{0, 1, . . . , 99}, deÔ¨Åne Xn for n ‚ààN to be the
middle two digits of the four-digit number X2
n‚àí1. If X2
n‚àí1 does not have four
digits, it is padded with leading zeros. For example, if X0 = 64, we have
X2
0 = 4096 and thus X1 = 09 = 9. In the next step, we Ô¨Ånd X2
1 = 81 = 0081
and thus X2 = 08 = 8.
(a)
Write a function which computes Xn from Xn‚àí1.
(b)
The output of the middle square method has loops. For example, once
we have X N = 0, we will have Xn = 0 for all n ‚â•N. Write a program
to Ô¨Ånd all cycles of the middle square method.
(c)
Comment
on
the
quality
of
the
middle
square
method
as
a PRNG.

38
AN INTRODUCTION TO STATISTICAL COMPUTING
E1.4
Write a program which uses the inverse transform method to generate random
numbers with the following density:
f (x) =
1/x2
if x ‚â•1 and
0
otherwise.
To test your program, plot a histogram of 10 000 random numbers together
with the density f .
E1.5
For n ‚ààN, let Kn denote the (random) number of accepted proposals
among the Ô¨Årst n generated proposals in algorithm 1.19. Show that, with
probability 1, we have
lim
n‚Üí‚àû
1
n Kn = Z.
E1.6
Implement the rejection method from example 1.24 to generate samples
from a half-normal distribution from Exp(1)-distributed proposals. Test your
program by generating a histogram of the output and by comparing the
histogram with the theoretical density of the half-normal distribution.
E1.7
In example 1.24 we have learned how rejection sampling can be used to con-
vert Exp(Œª)-distributed proposals into standard normally distributed samples.
(a)
Extend the method to convert Exp(Œª)-distributed proposals into
N(0, œÉ 2)-distributed samples.
(b)
For given œÉ 2, determine the optimal value of the parameter Œª.
E1.8
Consider algorithm 1.22 where the target distribution has density f/Z f with
f (x) =
1
‚àöx exp

‚àíy2/2x ‚àíx

and Z f =
 ‚àû
0
f (Àúx) d Àúx, and where the proposals are Exp(1)-distributed. Find
the optimal value for the constant c from algorithm 1.22 for this example.
E1.9
Let f and g be two probability densities and c ‚ààR with f (x) ‚â§cg(x) for
all x. Show that c ‚â•1 and that c = 1 is only possible for f = g (except
possibly on sets with volume 0).
E1.10
Let X ‚àºU[a, b] and Y ‚àºU[c, d] be independent. Using the deÔ¨Ånition of
the uniform distribution on a set, show that (X, Y) is uniformly distributed
on the rectangle R = [a, b] √ó [c, d].
E1.11
Without using rejection sampling, propose a method to sample from the
uniform distribution on the set
A = ([0, 1] √ó [0, 1]) ‚à™([2, 4] √ó [0, 1]) .
Write a program implementing your method.

RANDOM NUMBER GENERATION
39
E1.12
Without using rejection sampling, propose a method to sample from the
uniform distribution on the set
B = ([0, 2] √ó [0, 2]) ‚à™([1, 3] √ó [1, 3]) .
Write a program implementing your method.
E1.13
Consider the uniform distribution on a semicircle.
(a)
Explain how rejection sampling can be used to convert i.i.d. proposals
Un ‚àºU([‚àí1, 1] √ó [0, 1]) into an i.i.d. sequence (Vk)k‚ààN which is uni-
formly distributed on the semicircle {(x, y) ‚ààR2  x2 + y2 ‚â§1, y ‚â•
0}. Compute the acceptance probability of the method.
(b)
Write a computer program which generates 1000 samples from the
uniform distribution on the semicircle, using the method from (a).
Create a scatter plot showing the random points. How many proposals
were needed to generate 1000 samples?
E1.14
Propose a rejection method to sample from the uniform distribution on the
semicircle

(x, y) ‚ààR2  x2 + y2 ‚â§1, y ‚â•0

which has an acceptance probability of greater than 80%. Implement your
method.
E1.15
Let (X, Y) be uniformly distributed on the semicircle

(x, y) ‚ààR2  x2 + y2 ‚â§1, y ‚â•0

.
Find the densities of X and Y, respectively.
E1.16
Let X be a random variable on Rd with density f : Rd ‚Üí[0, ‚àû) and let
c Ã∏= 0 be a constant. Determine the density of cX.
E1.17
Let X ‚àºN(0, 1). Determine the density of Y = (X2 ‚àí1)/2.
E1.18
Write a program to implement the ratio-of-uniforms method to sample from
the Cauchy distribution with density
f (x) =
1
œÄ(1 + x2).

2
Simulating statistical models
The output of the methods for random number generation considered in Chapter 1
is a series of independent random samples from a given distribution. In contrast,
most real-world statistical models of interest will involve random samples with a
non-trivial dependence structure and often samples will consist not just of a sequence
of numbers, but will feature a more complicated structure. In this chapter, we will
discuss some examples to show how the methods from Chapter 1 can be used as a
building block to generate samples from more complex statistical models.
2.1
Multivariate normal distributions
One of the most important multivariate distributions is the multivariate normal distri-
bution. In this section, we will derive the basic properties of the multivariate normal
distribution and will discuss how to generate samples from this distribution.
DeÔ¨Ånition 2.1
Let Œº ‚ààRd be a vector and  ‚ààRd√ód be a symmetric, positive
deÔ¨Ånite matrix. Then a random vector X ‚ààRd is normally distributed with mean Œº
and covariance matrix , if the distribution of X has density f : Rd ‚ÜíR given by
f (x) =
1
(2œÄ)d/2 |det |1/2 exp

‚àí1
2(x ‚àíŒº)‚ä§‚àí1(x ‚àíŒº)

(2.1)
for all x ‚ààRd.
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

42
AN INTRODUCTION TO STATISTICAL COMPUTING
In this deÔ¨Ånition we consider the vector x ‚àíŒº ‚ààRd to be a d √ó 1 matrix, and
the expression (x ‚àíŒº)‚ä§denotes the transpose of this vector, that is the vector x ‚àíŒº
interpreted as an 1 √ó d matrix. Using this interpretation we have
(x ‚àíŒº)‚ä§‚àí1(x ‚àíŒº) =
d

i, j=1
(xi ‚àíŒºi)(‚àí1)ij(x j ‚àíŒº j).
The multivariate normal distribution from deÔ¨Ånition 2.1 is a generalisation of the
one-dimensional normal distribution: If  is a diagonal matrix, say
 =
‚éõ
‚éú‚éú‚éú‚éù
œÉ 2
1
0
. . .
0
0
œÉ 2
2
. . .
0
...
...
...
...
0
0
. . .
œÉ 2
d
‚éû
‚éü‚éü‚éü‚é†,
then | det | = d
i=1 œÉ 2
i and
‚àí1 =
‚éõ
‚éú‚éú‚éú‚éù
1/œÉ 2
1
0
. . .
0
0
1/œÉ 2
2
. . .
0
...
...
...
...
0
0
. . .
1/œÉ 2
d
‚éû
‚éü‚éü‚éü‚é†
and thus the density f from (2.1) can be written as
f (x) =
1
(2œÄ)d/2

d
i=1 œÉ 2
i

1/2 exp

‚àí1
2
d

i=1
(xi ‚àíŒºi) 1
œÉ 2
i
(xi ‚àíŒºi)

=
d
i=1
1

2œÄœÉ 2
i
1/2 exp

‚àí(xi ‚àíŒºi)2
2œÉ 2
i

=
d
i=1
fi (xi) ,
where the function fi, given by
fi(x) =
1

2œÄœÉ 2
i
1/2 exp

‚àí(x ‚àíŒºi)2
2œÉ 2
i

for all x ‚ààR, is the density of the one-dimensional normal distribution with mean
Œºi and variance œÉ 2
i . This shows that X is normally distributed on Rd with diag-
onal covariance matrix, if and only if the components Xi for i = 1, 2, . . . , d are
independent and normally distributed on R.

SIMULATING STATISTICAL MODELS
43
A sample X from a d-dimensional normal distribution with diagonal covariance
matrix can be generated by generating the individual components Xi ‚àºN(Œºi, œÉ 2
i )
independently. The following lemma gives a method to transform such samples into
samples from arbitrary d-dimensional normal distributions.
Lemma 2.2
Let Œº ‚ààRd and A ‚ààRd√ód be invertible. DeÔ¨Åne  = AA‚ä§‚àà
Rd. Furthermore, let X = (X1, X2, . . . , Xd) ‚ààRd be a random vector such that
X1, X2, . . . , Xd ‚àºN(0, 1) are independent. Then
AX + Œº ‚àºN(Œº, )
on Rd.
Proof
The result is a direct consequence of theorem 1.34: let f be the density of X
and g be the density of N(Œº, ), that is
f (x) =
1
(2œÄ)d/2 exp

‚àí1
2x‚ä§x

and
g(x) =
1
(2œÄ)d/2 |det |1/2 exp

‚àí1
2(x ‚àíŒº)‚ä§‚àí1(x ‚àíŒº)

for all x ‚ààRd. Consider the transformation œï(x) = Ax + Œº. Then
g (œï(x)) =
1
(2œÄ)d/2 det(AA‚ä§)
1/2 exp

‚àí1
2(Ax)‚ä§(AA‚ä§)‚àí1(Ax)

=
1
(2œÄ)d/2 det A det A‚ä§1/2 exp

‚àí1
2x‚ä§A‚ä§(A‚ä§)‚àí1A‚àí1Ax

=
1
(2œÄ)d/2 |det A| exp

‚àí1
2x‚ä§x

for all x ‚ààRd, since det A = det A‚ä§. Assume A = (aij)i, j=1,...,d. Then the Jacobian
Dœï(x) has components
(Dœï(x))ij =
‚àÇ
‚àÇx j
 d

k=1
aikxk

= aij
and thus Dœï(x) = A and | det Dœï(x)| = | det A| for all x ‚ààRd. Consequently,
f (x) = g(œï(x))| det Dœï(x)| and, by theorem 1.34, the distribution of œï(X)
has density g.

44
AN INTRODUCTION TO STATISTICAL COMPUTING
Lemma 2.2 can be used to generate samples from a multivariate normal distribu-
tion N(Œº, ). This can be done by performing the following steps:
(a) Find a matrix A such that  = AAT , for example using the Cholesky decom-
position of A.
(b) Generate independent random values X1, X2, . . . , Xd ‚àºN(0, 1).
(c) Return AX + Œº.
In cases where many N(Œº, œÉ)-distributed random values need to be generated for the
same covariance matrix , the algorithm can be sped up by computing the matrix A
only once and then storing it for later use.
For completeness, we now verify that the distribution N(Œº, ) given by
deÔ¨Ånition 2.1 indeed has mean Œº and covariance matrix .
Lemma 2.3
Let X ‚àºN(Œº, ) where Œº ‚ààRd and  = (œÉij)i, j=1,...,n ‚ààRd√ód. Then
E(Xi) = Œºi
and
Cov(Xi, X j) = œÉij
for all i, j = 1, 2, . . . , d.
Proof
By lemma 2.2 we can write X as X = AZ + Œº where A = (aij)i, j=1,...,d
is a matrix such that AA‚ä§=  and Z1, Z2, . . . , Zd are independent and standard-
normally distributed. For the components of X we Ô¨Ånd
Xi =
d

j=1
aijZ j + Œºi
and thus
E(Xi) =
d

j=1
aijE(Z j) + Œºi = Œºi
and
Cov(Xi, X j) = Cov
 d

k=1
aikZk,
d

l=1
ajlZl

=
d

k,l=1
aikajlCov (Zk, Zl)
=
d

k=1
aikajk = (AA‚ä§)ij = œÉij.
This completes the proof.

SIMULATING STATISTICAL MODELS
45
Example 2.4
Let Œµi ‚àºN(0, œÉ 2) be i.i.d. and deÔ¨Åne
Xi =
i
k=1
Œµk
for all i ‚ààN. Then E(Xi) = 0 and
Cov(Xi, X j) = Cov

i
k=1
Œµk,
j

l=1
Œµl

=
i
k=1
j

l=1
Cov (Œµk, Œµl) .
Since Cov(Œµk, Œµl) = œÉ 2 if k = l and Cov(Œµk, Œµl) = 0 otherwise, we Ô¨Ånd
Cov(Xi, X j) = min(i, j) œÉ 2
for all i, j ‚ààN. Consequently, for d ‚ààN, we can use lemma 2.3 to conclude that the
vector X = (X1, X2, . . . , Xd) satisÔ¨Åes X ‚àºN(0, ) where
 = œÉ 2
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
1
1
1
. . .
1
1
2
2
. . .
2
1
2
3
. . .
3
...
...
...
...
...
1
2
3
. . .
d
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
.
2.2
Hierarchical models
Many important statistical models have a hierarchical structure: not all random vari-
ables in the model are deÔ¨Åned simultaneously, but instead there are several ‚Äòlevels‚Äô of
randomness and the distribution of the random variables in the later levels depends
on the values of random variables in earlier levels. This structure is, for example,
present in the following situations.
r In Bayesian models (discussed in Section 4.3) the distribution of the data
depends on the value of one or more random parameters.
r In mixture models the distribution of samples depends on the random choice
of mixture component.
r In Markov chains (discussed in Section 2.3) the distribution of the value at
time t depends on the value of the Markov chain at time t ‚àí1.
Simulating hierarchical models is often easy: the simulation procedure will be per-
formed in steps, closely following the structure of the model. We illustrate this
approach here using examples.

46
AN INTRODUCTION TO STATISTICAL COMPUTING
Example 2.5
Consider the Bayesian model where the data are described as i.i.d.
samples X1, . . . , Xn ‚àºN(Œº, œÉ 2), and where the mean Œº and the variance œÉ 2
are themselves assumed to be random with distributions œÉ 2 ‚àºExp(Œª) and Œº ‚àº
N(Œº0, Œ±œÉ 2). Since the variance œÉ 2 occurs in the distribution of Œº, the model has
the following dependence structure:
œÉ 2
‚àí‚Üí
Œº
‚àí‚Üí
X1, . . . , Xn.
To generate samples from this model, we use steps corresponding to the levels in the
model:
1: generate œÉ 2 ‚àºExp(Œª)
2: generate Œº ‚àºN(Œº0, Œ±œÉ 2)
3: for i = 1, . . . , n do
4:
generate Xi ‚àºN(Œº, œÉ 2)
5: end for
Sometimes, the hierarchical structure of a model is not immediately clear. This
is for example the case for mixture distributions as given in the following deÔ¨Ånition,
but we will see that for generating samples from a mixture distribution it is beneÔ¨Åcial
to introduce a hierarchical structure.
DeÔ¨Ånition 2.6
Let P1, . . . , Pk be probability distributions on Rd and let Œ∏1, . . . , Œ∏k >
0 such that k
a=1 Œ∏a = 1. Then the mixture PŒ∏ of the distributions P1, . . . , Pk with
weights Œ∏1, . . . , Œ∏k is given by
PŒ∏(A) =
k

a=1
Œ∏a Pa(A)
for all A ‚äÜRd.
It is important to note that a mixture is a weighted sum of distributions, not the
distribution of a weighted sum of random variables. The difference is illustrated in
the following example.
Example 2.7
Consider the three normal distributions P1 = N(1, 0.012), P2 =
N(2, 0.52) and P3 = N(5, 0.022), together with the weights Œ∏1 = 0.1, Œ∏2 = 0.7
and Œ∏3 = 0.02. If Xi ‚àºPi for i = 1, 2, 3 are independent, then X = 3
i=1 Œ∏i Xi
is normally distributed. In contrast, the mixture distribution PŒ∏ = 3
i=1 Œ∏i Pi has
the density shown in Figure 2.1. The Ô¨Ågure shows clearly that PŒ∏ is not a nor-
mal distribution. The density shown in Figure 2.1 was determined using the
following lemma.

SIMULATING STATISTICAL MODELS
47
X
Density
‚àí1
0
1
2
3
4
5
0.0
0.1
0.2
0.3
0.4
0.5
Figure 2.1
A histogram generated from 10 000 samples of the mixture model from
example 2.7.
Lemma 2.8
Assume that P1, . . . , Pk have densities f1, . . . , fk. Then the mixture
distribution PŒ∏ also has a density which is given by
fŒ∏ =
k

a=1
Œ∏a fa.
Proof
Let A ‚äÜRd. Then
PŒ∏(A) =
k

a=1
Œ∏a Pa(A) =
k

a=1
Œ∏a

A
fa(x) dx =

A
k

a=1
Œ∏a fa(x) dx =

A
fŒ∏(x) dx.
Thus, fŒ∏ is the density of PŒ∏.
At Ô¨Årst glance, the problem of generating samples from a mixture distribution is
straightforward: since we know the distribution, we could just use the methods from
Chapter 1 to generate such samples. But, as Figure 2.1 shows, mixture distributions
can have a complicated density and it transpires that often the easiest way to generate
samples from a mixture distribution is to artiÔ¨Åcially introduce a hierarchical struc-
ture, used only for the generation of samples. This method is used in the following
algorithm.
Algorithm 2.9
(mixture distributions)
input:
probability distributions P1, . . . , Pk
weights Œ∏1, . . . , Œ∏k > 0 with k
a=1 Œ∏a = 1

48
AN INTRODUCTION TO STATISTICAL COMPUTING
randomness used:
Y ‚àà{1, 2, . . . , k} with P(Y = a) = Œ∏a for all a
samples X ‚àºPa for different a ‚àà{1, . . . , k}
output:
X ‚àºPŒ∏
1: generate Y ‚àà{1, 2, . . . , k} with P(Y = a) = Œ∏a for all a
2: generate X ‚àºPY
3: return X
Lemma 2.10
The sample X constructed by algorithm 2.9 is distributed according
to the mixture distribution from deÔ¨Ånition 2.6, that is X ‚àºPŒ∏.
Proof
Let A ‚äÜRd. By splitting the event {X ‚ààA} according to the possible values
of Y and using Bayes‚Äô rule (see Section A.2), we Ô¨Ånd
P(X ‚ààA) =
k

a=1
P(X ‚ààA, Y = a) =
k

a=1
P(Y = a)P(X ‚ààA|Y = a).
From step 1 of algorithm 2.9 we know P(Y = a) = Œ∏a and from step 2 we see that,
conditional on Y = a, we have X ‚àºPa. Thus we get
P(X ‚ààA) =
k

a=1
Œ∏a Pa(A) = PŒ∏(A).
Thus, X ‚àºPŒ∏ as required.
Algorithm 2.9 showed the idea of artiÔ¨Åcially introducing a hierarchical structure
to simplify sampling. We will reuse the idea, again in the context of mixture dis-
tributions, in Section 4.4.2. To conclude the present section, we will rephrase this
idea in a more general (and more abstract) form: one method for generating sam-
ples from a multivariate distribution P is to simulate the components one by one.
Instead of directly generating a sample X = (X1, X2, . . . , Xn) ‚ààRn we can Ô¨Årst sam-
ple X1 from the corresponding marginal distribution and then, for i = 2, 3, . . . , n,
sampling Xi from the conditional distribution given the (already sampled) values
X1, . . . , Xi‚àí1.
In the following algorithm we assume (for simplicity) that the distribution P has
a density p: Rd ‚Üí[0, ‚àû) and we use the marginal density pX1 of X1, given by
pX1(x1) =

R
¬∑ ¬∑ ¬∑

R
p(x1, x2, . . . , xn) dxn ¬∑ ¬∑ ¬∑ dx2,
as well as the conditional densities pXi|X1,...,Xi‚àí1 as deÔ¨Åned in Section A.2.

SIMULATING STATISTICAL MODELS
49
Algorithm 2.11
(componentwise simulation)
input:
marginal density pX1
conditional densities pXi|X1,...,Xi‚àí1 for i = 2, 3, . . . , n
randomness used:
samples from pX1 and pXi|X1,...,Xi‚àí1
output:
a sample (X1, . . . , Xn) ‚àºp
1: generate X1 ‚àºpX1
2: for i = 2, 3, . . . , n do
3:
generate Xi ‚àºpXi|X1,...,Xi‚àí1( ¬∑ |X1, . . . , Xi‚àí1)
4: end for
5: return (X1, . . . , Xn)
Lemma 2.12
The random vector (X1, . . . , Xn) constructed by algorithm 2.11 has
density p.
Proof
For i = 1, 2, . . . , n, denote the marginal density of P for the Ô¨Årst i coordi-
nates by pX1,...,Xi, that is let
pX1,...,Xi(x1, . . . , xi) =

R
¬∑ ¬∑ ¬∑

R
p(x1, . . . , xi, xi+1, . . . , xn) dxn ¬∑ ¬∑ ¬∑ dxi+1
for all x1, . . . , xi ‚ààR. We will use induction to prove that (X1, . . . , Xi), as constructed
by the Ô¨Årst i iterations of the loop in algorithm 2.11, has density pX1,...,Xi for all
i = 1, 2, . . . , n.
For i = 1 we have P(X1 ‚ààA1) = pX1(A1) by construction of X1 in line 1 of the
algorithm. Thus the statement holds for i = 1. Let i > 1 and assume we have already
shown that (X1, . . . , Xi‚àí1) has density pX1,...,Xi‚àí1. The construction of Xi in line 3 of
the algorithm depends on the values of X1, . . . , Xi‚àí1 constructed in previous steps
of the algorithm. We can integrate over all possible values of X1, . . . , Xi‚àí1 to Ô¨Ånd
P(X1 ‚ààA1, . . . , Xi ‚ààAi)
=
 
1A1√ó¬∑¬∑¬∑√óAi(x1, . . . , xi)
¬∑ pXi|X1,...,Xi‚àí1( ¬∑ |x1, . . . , xi‚àí1) dxi
¬∑ pX1,...,Xi‚àí1(x1, . . . , xi‚àí1) dxi‚àí1 ¬∑ ¬∑ ¬∑ dx1
=
 
1A1√ó¬∑¬∑¬∑√óAi(x1, . . . , xi) pX1,...,Xi(x1, . . . , xi) dxi ¬∑ ¬∑ ¬∑ dx1.
This shows that (X1, . . . , Xi) has density pX1,...,Xi. Using induction, we get this
statement for all i = 1, . . . , n. Since pX1,...,Xn = p, this completes the proof.

50
AN INTRODUCTION TO STATISTICAL COMPUTING
2.3
Markov chains
Markov chains are stochastic processes, which play an important rÀÜole in many areas
of probability, both as objects of independent mathematical interest and as a tool
in other areas of mathematics. In this section we will give a very brief introduction
to Markov chains, concentrating on basic properties of Markov chains and how to
simulate Markov chains on a computer. Later in this book, in Chapter 4, we will see
how Markov chains can be used as a tool in random number generation.
Throughout this section, we restrict ourselves to the case of discrete-time Markov
chains and we omit some of the technical details.
DeÔ¨Ånition 2.13
A stochastic process X = (X j) j‚ààN0 with values in a set S is a
Markov chain, if
P

X j ‚ààA j
 X j‚àí1 ‚ààA j‚àí1, X j‚àí2 ‚ààA j‚àí2, . . . , X0 ‚ààA0

= P

X j ‚ààA j
 X j‚àí1 ‚ààA j‚àí1

(2.2)
for all A0, A1, . . . , A j ‚äÜS and all j ‚ààN, that is if the distribution of X j depends
on X0, . . . , X j‚àí2 only through X j‚àí1. The set S is called the state space of X. The
distribution of X0 is called the initial distribution of X.
Often X0 is deterministic, that is P(X0 = x) = 1 for some x ‚ààS; in this case x
is called the initial value or starting point of X. The index j is typically interpreted
as time.
Example 2.14
Let (Œµ j) j‚ààN be an i.i.d. sequence of random variables. The process
X given by X0 = 0 and X j = X j‚àí1 + Œµ j for all j ‚ààN is a Markov chain. We can
write X j as
X j =
j

i=1
Œµi.
A Markov chain of this type is called a random walk. Important special cases are
Œµ j ‚àºU({‚àí1, 1}) (the symmetric, simple random walk on Z) and Œµ j ‚àºN(0, 1).
Example 2.15
Let (Œµ j) j‚ààN be an i.i.d. sequence of random variables with variance
Var(Œµ j) = 1. Then the process X given by X0 = X1 = 0 and
X j = X j‚àí1 + X j‚àí2
2
+ Œµ j
for all j = 2, 3, . . . is not a Markov chain.

SIMULATING STATISTICAL MODELS
51
DeÔ¨Ånition 2.16
If the transition probabilities given by the right-hand side of (2.2)
do not depend on the time j, the Markov chain X is called time-homogeneous.
For the rest of this chapter (and nearly all of the book) we restrict ourselves to
the case of time-homogeneous Markov chains.
2.3.1
Discrete state space
If the state space S is Ô¨Ånite, for example S = {1, 2, . . . , N}, then the transition
probabilities P(Xn ‚ààAn
 Xn‚àí1 ‚ààAn‚àí1) in (2.2) can be described by giving the
probabilities
pxy = P

X j = y
 X j‚àí1 = x

of the transitions between all pairs of elements x, y ‚ààS. The resulting matrix P =
(pxy)x,y‚ààS is called the transition matrix of the Markov chain X.
When considering transition matrices, it is often convenient to label the rows
and columns of the matrix P using elements of S instead of using the usual indices
{1, 2, . . . , n}. Thus, if S is the alphabet S = {A, B, . . . , Z} we write pAZ instead of
p1,26 to denote the probability of transitions from A to Z. We write RS√óS for the set
of all matrices where the columns and rows are indexed by elements of S. Similarly,
for vectors consisting of probability weights for the elements of S, for example the
initial distribution of a Markov chain, it is convenient to label the components of the
vector by elements of S. We write RS for the set of all such vectors.
At this stage, collecting the transition probabilities into a matrix could be seen
to be only a method for bookkeeping, but in the rest of this section we will see the
surprising fact that the connection between Markov chains and matrices is much
deeper. Many of the concepts from linear algebra, including matrix multiplica-
tion and eigenvectors, have a probabilistic interpretation in the context of transition
matrices!
So far we have considered Markov chains with Ô¨Ånite state space S, but we can also
consider transition matrices for Markov chains with countably inÔ¨Ånite state space. In
these cases, the transition matrix P is an ‚ÄòinÔ¨Ånite matrix‚Äô
P =
‚éõ
‚éú‚éù
p11
p12
p13
¬∑ ¬∑ ¬∑
p21
p22
p23
¬∑ ¬∑ ¬∑
...
...
...
...
‚éû
‚éü‚é†.
Markov chains with Ô¨Ånite or countably inÔ¨Ånite state space are called Markov chains
with discrete state space.
Example 2.17
Consider the state space S = {1, 2, 3} and let X be the Markov chain
with X0 = 1 where transitions between states have the probabilities:

52
AN INTRODUCTION TO STATISTICAL COMPUTING
1
2
3
1/2
1/2
1/2
1/2
1
This Markov chain has transition matrix
P =
‚éõ
‚éú‚éú‚éù
1
2
1
2
0
0
1
2
1
2
1
0
0
‚éû
‚éü‚éü‚é†.
Row x of this matrix, for x = 1, 2, 3, consists of the probabilities px,1, px,2, px,3 for
going from state x to states 1, 2 and 3, respectively.
Example 2.18
The symmetric simple random walk X, given by
X j =
j

i=1
Œµi
for all j ‚ààN0 with Œµi ‚àºU{‚àí1, +1} i.i.d., is a Markov chain with state space S = Z.
Lemma 2.19
Let P S√óS be the transition matrix of a Markov chain with state space S.
Then P = (pxy)x,y‚ààS has the following properties:
(a) pxy ‚â•0 for all x, y ‚ààS.
(b) 
y‚ààS pxy = 1 for all x ‚ààS.
Proof
The claim follows directly from the deÔ¨Ånition of P.
DeÔ¨Ånition 2.20
A vector œÄ ‚ààRS is called a probability vector, if œÄx ‚â•0 for all
x ‚ààS and 
x‚ààS œÄx = 1.
DeÔ¨Ånition 2.21
A matrix which satisÔ¨Åes the two conditions from lemma 2.19 is
called a stochastic matrix.
In order to simulate paths of a Markov chain with discrete state space on a
computer, we have to provide a probability vector œÄ to specify the initial distribution
and a transition matrix P to specify the transition probabilities. As in Section 2.2, the
simulation of the random variables X j is done one at a time, starting with X0.

SIMULATING STATISTICAL MODELS
53
Algorithm 2.22
(Markov chains with discrete state space)
input:
a Ô¨Ånite or countable state space S
a probability vector œÄ ‚ààRS
a stochastic matrix P = (pxy)x,y‚ààS ‚ààRS√óS
randomness used:
samples from discrete distributions on S
output:
a path of a Markov chain with initial distribution œÄ and transition matrix P
1: generate X0 ‚ààS with P(X0 = x) = œÄx for all x ‚ààS
2: output X0
3: for j = 1, 2, 3, . . . do
4:
generate X j ‚ààS with P(X j = x) = pX j‚àí1,x for all x ‚ààS
5:
output X j
6: end for
Lemma 2.23
Let X be a time-homogeneous Markov chain with Ô¨Ånite state space
and transition matrix P. Then
P

X j+k = y
 X j = x

= (Pk)xy
for all j, k ‚ààN0 and x, y ‚ààS, where Pk = P ¬∑ P ¬∑ ¬∑ ¬∑ P is the kth power of the
transition matrix P.
Proof
For k = 0, the matrix P0 is by deÔ¨Ånition the identity matrix and the statement
holds. Also, for k = 1 we have
P

X j+1 = y
 X j = x

= pxy = (P1)xy
by the deÔ¨Ånition of the transition matrix.
Now let k > 1 and assume that the statement holds for k ‚àí1. Then we have
P

X j+k = y
 X j = x

= P

X j+k = y, X j = x

P

X j = x

=
1
P

X j = x


z‚ààS
P

X j+k = y, X j+k‚àí1 = z, X j = x

=
1
P

X j = x


z‚ààS
P

X j+k‚àí1 = z, X j = x

¬∑P

X j+k = y
 X j+k‚àí1 = z, X j = x

.

54
AN INTRODUCTION TO STATISTICAL COMPUTING
Using the Markov property (2.2) we get
P

X j+k = y
 X j = x

=

z‚ààS
P

X j+k‚àí1 = z, X j = x

P

X j = x

P

X j+k = y
 X j+k‚àí1 = z

=

z‚ààS
P

X j+k‚àí1 = z
 X j = x

pzy
=

z‚ààS
(Pk‚àí1)xz pzy.
The last expression can be read as a matrix-matrix multiplication of Pk‚àí1 with P and
thus we get
P

X j+k = y
 X j = x

= (Pk‚àí1 ¬∑ P)xy = (Pk)xy
as required.
Lemma 2.24
Let X be a time-homogeneous Markov chain with Ô¨Ånite state space
and transition matrix P and initial distribution œÄ. Then we have
P(X j = y) = (œÄ‚ä§P j)y
(2.3)
for all y ‚ààS.
Proof
At time 0 we have
P(X0 = x) = œÄx
for all x ‚ààS. For time k > 0 we can use Bayes‚Äô formula to Ô¨Ånd
P(X j = y) =

x‚ààS
P

X j = y, X0 = x

=

x‚ààS
P (X0 = x) P

X j = y
 X0 = x

=

x‚ààS
œÄx(P j)xy
for all y ‚ààS. If we consider the transposed vector œÄ‚ä§as a matrix with one row and
|S| columns, we can write the last expression as a matrix-matrix multiplication. This
gives the required expression (2.3).

SIMULATING STATISTICAL MODELS
55
DeÔ¨Ånition 2.25
Let X be a time-homogeneous Markov chain with transition
matrix P. A probability vector œÄ is called a stationary distribution of X, if
œÄ‚ä§P = œÄ‚ä§, that is if

x‚ààS
œÄx pxy = œÄy
(2.4)
for all y ‚ààS.
To understand the signiÔ¨Åcance of this deÔ¨Ånition, we have to recall relation (2.3):
we know that
P(X j = y) = (œÄ‚ä§P j)y
for all y ‚ààS. If œÄ is a stationary distribution, we have œÄ‚ä§P = œÄ‚ä§and then
œÄ‚ä§P j = œÄ‚ä§for all j ‚ààN. Consequently, if we start the Markov chain with initial
distribution œÄ, the distribution of X j does not change in time: we have X j ‚àºœÄ for all
j ‚ààN.
In general, a Markov chain may have more than one stationary distribution, but
for the cases which will be of interest in this chapter, there will only be one stationary
distribution.
Example 2.26
On the state space S = {1, 2, 3}, consider the Markov chain with
transition matrix
P =
‚éõ
‚éù
1/2
1/2
0
0
1/2
1/2
1/5
0
4/5
‚éû
‚é†
and initial distribution Œ± = (1, 0, 0).
We can use equation (2.3) to get the distribution after one step: P(X1 = x) =
(Œ±‚ä§P)x where
Œ±‚ä§P =
1
0
0 
¬∑
‚éõ
‚éù
1/2
1/2
0
0
1/2
1/2
1/5
0
4/5
‚éû
‚é†=
1/2
1/2
0 
.
Similarly, for X2 we Ô¨Ånd P(X2 = x) = (Œ±‚ä§P2)x where
Œ±‚ä§P2 =
1/2
1/2
0
¬∑
‚éõ
‚éù
1/2
1/2
0
0
1/2
1/2
1/5
0
4/5
‚éû
‚é†=
1/4
1/2
1/4 
.

56
AN INTRODUCTION TO STATISTICAL COMPUTING
Continuing to X2, X3, . . . we get
Œ±‚ä§P3 = (0.175
0.375
0.450)
Œ±‚ä§P4 = (0.178
0.275
0.548)
...
Œ±‚ä§P10 = (0.223
0.222
0.555).
Experimenting shows that the value of Œ±‚ä§P j does not change signiÔ¨Åcantly when
j is increased further, so we can guess that this value is close to the stationary
distribution of the Markov chain. Indeed, we can use equation (2.4) to verify that
œÄ = (2/9, 2/9, 5/9) is a stationary distribution of X:
œÄ‚ä§P =
2/9
2/9
5/9 
¬∑
‚éõ
‚éù
1/2
1/2
0
0
1/2
1/2
1/5
0
4/5
‚éû
‚é†=
2/9
2/9
5/9 
= œÄ‚ä§.
Thus, we have seen that for the Markov chain considered in this example, as n ‚Üí‚àû,
the probabilities P(X j = x) converge to the stationary probabilities œÄx. Convergence
results like this often, but not always, hold.
The condition for œÄ being a stationary distribution can be rewritten by taking
the transpose of the equation œÄ‚ä§P = œÄ‚ä§: a probability vector œÄ is a stationary
distribution for P if and only if
P‚ä§œÄ = œÄ,
that is if œÄ is an eigenvector of P‚ä§with eigenvalue 1. Since computing eigenvectors
is a well-studied problem, and many software packages provide built-in functions for
this purpose, this property can be used to Ô¨Ånd a stationary distribution œÄ for a given
transition matrix P.
2.3.2
Continuous state space
In this section we will brieÔ¨Çy discuss Markov chains with continuous state space.
Markov chains can be considered on very general state spaces, but here we restrict
ourselves to the case S = Rd. Most of the results from the previous section formally
carry over to the case of continuous state space, with only changes in notation.
The concept of transition matrices in the case of continuous state space is replaced
by transition kernels, as given in the following deÔ¨Ånition.
DeÔ¨Ånition 2.27
A transition kernel is a map P(¬∑, ¬∑) such that:
(a) P(x, A) ‚â•0 for all x ‚ààRd and all A ‚äÜRd; and
(b) P(x, ¬∑) is a probability distribution on Rd for all x ‚ààRd.

SIMULATING STATISTICAL MODELS
57
This deÔ¨Ånition hides some of the technical complications associated with the
study of Markov chains on a continuous state space. If full mathematical rigour is
required, an additional condition, relating to ‚Äòmeasurability‚Äô, must be included.
The idea in this deÔ¨Ånition is that x takes the rÀÜole of the current state of the Markov
chain and, for given x, the map A 	‚ÜíP(x, A) is the distribution of the next value of
the Markov chain. Thus, the transition kernel of a time-homogeneous Markov chain
is deÔ¨Åned by
P(x, A) = P(X j ‚ààA|X j‚àí1 = x).
Often, the conditional distribution of X j, given X j‚àí1 = x, has a density. In this
case, instead of giving a transition kernel, we can describe the transitions of a Markov
chain by giving a transition density. In analogy to lemma 2.19, a transition density is
deÔ¨Åned in the following.
DeÔ¨Ånition 2.28
A transition density is a map p: Rd √ó Rd ‚ÜíR such that:
(a) p(x, y) ‚â•0 for all x, y ‚ààRd; and
(b)

Rd p(x, y) dy = 1 for all x ‚ààRd.
If the Markov chain X can be described by a transition density, then we have
P(X j ‚ààA|X j‚àí1 = x) =

A
p(x, y) dy
for all x ‚ààRd.
Example 2.29
On S = R, let X0 = 0 and
X j = 1
2 X j‚àí1 + Œµ j
for all j ‚ààN, where Œµ j ‚àºN(0, 1) i.i.d. is a Markov chain with state space S = R.
Given X j‚àí1 = x, we have X j = 1
2x + Œµ j ‚àºN(x/2, 1). Thus, the transition kernel
for this Markov chain satisÔ¨Åes P(x, ¬∑) = N(x/2, 1) for all x ‚ààRd. Since the normal
distribution has a density, the Markov chain X has a transition density p, given by
p(x, y) =
1
‚àö
2œÄ
exp

‚àí1
2(y ‚àíx/2)2

for all x, y ‚ààR.
As already remarked, most of the results from the previous section carry over with
only changes in notation required, but the resulting notation is often cumbersome.
Here we restrict ourselves to state the deÔ¨Ånition of a stationary density in analogy to
deÔ¨Ånition 2.25 we have the following deÔ¨Ånition.

58
AN INTRODUCTION TO STATISTICAL COMPUTING
DeÔ¨Ånition 2.30
A probability density œÄ: Rd ‚Üí[0, ‚àû) is a stationary density for a
Markov chain on the state space Rd with transition density p, if it satisÔ¨Åes

S
œÄ(x)p(x, y) dx = œÄ(y)
for all y ‚ààRd.
To conclude this section, we state the algorithm for generating paths from a
time-homogeneous Markov chain with a transition density on Rd.
Algorithm 2.31
(Markov chains with continuous state space)
input:
a probability density œÄ: Rd ‚Üí[0, ‚àû)
a transition density p: Rd √ó Rd ‚Üí[0, ‚àû)
randomness used:
one sample X0 ‚àºœÄ
samples from the densities p(x, ¬∑) for x ‚ààRd
output:
a path of a Markov chain with initial distribution œÄ and transition matrix P
1: generate X0 ‚àºœÄ
2: output X0
3: for j = 1, 2, 3, . . . do
4:
generate X j ‚àºp(X j‚àí1, ¬∑)
5:
output X j
6: end for
2.4
Poisson processes
A sample of a Poisson process consists not of a single number, but of a random number
of random points in a given set. Poisson processes are used to model the occurrence of
events in space and/or time, when the individual events are random and independent
of each other. For example, a Poisson process on a time interval [t1, t2] could be used
to model the times where individual telephone calls arrive at a call centre.
The deÔ¨Ånition of the Poisson process builds on the Poisson distribution, as given
in the following deÔ¨Ånition.
DeÔ¨Ånition 2.32
A random variable X follows a Poisson distribution with para-
meter Œª, if X ‚ààN0 and
P(X = k) = e‚àíŒª Œªk
k!
for all k ‚ààN0. The Poisson distribution with parameter Œª is denoted by Pois(Œª).

SIMULATING STATISTICAL MODELS
59
For reference, we state the following basic results about Poisson distributions.
Lemma 2.33
Let X ‚àºPois(Œª). Then the following statements hold:
(a) E(X) = Œª.
(b) Var(X) = Œª.
(c) If Y ‚àºPois(Œº), independent of X, then X + Y ‚àºPois(Œª + Œº).
In the mathematical formalism, the points of a Poisson process are usually col-
lected into a set, so that a sample of a Poisson process can be seen as a random set.
This idea leads to the following deÔ¨Ånition of a Poisson process.
DeÔ¨Ånition 2.34
A Poisson process on a set D ‚äÜRd with intensity function Œª: Rd ‚Üí
[0, ‚àû) is a random set  ‚äÜD such that the following two conditions hold:
(a) If A ‚äÜD, then | ‚à©A| ‚àºPois((A)) where | ‚à©A| is the number of points
of  in A and
(A) =

A
Œª(x) dx.
(2.5)
(b) If A, B ‚äÜD are disjoint, then | ‚à©A| and | ‚à©B| are independent.
The intensity function Œª in the deÔ¨Ånition speciÔ¨Åes how many points of the Poisson
process, on average, are located in a given region. The process will have many points
where Œª is large and will have only few points where Œª is small. This is illustrated in
Figure 2.2. More speciÔ¨Åcally, Since the expectation of the Pois(Œª)-distribution equals
Œª, the expected number of points in a set A is
E (| ‚à©A|) = (A).
A consequence of the independence statement in deÔ¨Ånition 2.34 is the following
lemma, which allows to build up a Poisson process from smaller building blocks.
Lemma 2.35
(a) Let  be a Poisson process on D with intensity Œª and let A ‚äÜD. Then the
restriction  ‚à©A of the process  to the set A is a Poisson process on A with
intensity Œª.
(b) Let 1 and 2 be independent Poisson processes on D1 and D2, respectively,
and let D1 ‚à©D2 = ‚àÖ. Assume that both processes have the same intensity
Œª: Rd ‚Üí[0, ‚àû). Then  = 1 ‚à™2 is a Poisson process on D = D1 ‚à™D2
with intensity Œª.

60
AN INTRODUCTION TO STATISTICAL COMPUTING
‚àí6
‚àí4
‚àí2
0
2
4
6
‚àí4
‚àí2
0
2
4
X1
X2
Figure 2.2
One sample of a two-dimensional Poisson process with a non-
homogeneous intensity. The intensity Œª is high at the location of the two visi-
ble clusters and low elsewhere. The exact setup for this Ô¨Ågure is described in
example 2.40.
Proof
The Ô¨Årst statement is a direct consequence of deÔ¨Ånition 2.34. For the second
statement, let A ‚äÜD and deÔ¨Åne Ai = A ‚à©Di for i = 1, 2. Since A1 and A2 are
disjoint, the random variables | ‚à©A1| ‚àºPois((A1)) and | ‚à©A2| ‚àºPois((A2))
are independent. Thus, by lemma 2.33:
| ‚à©A| = | ‚à©A1| + | ‚à©A2| ‚àºPois ((A1) + (A2)) = Pois ((A)) .
This shows that  satisÔ¨Åes the Ô¨Årst condition from deÔ¨Ånition 2.34. For the second
condition, let A and B be disjoint. Then, the four sets Ai = A ‚à©Di and Bi = B ‚à©
Di for i = 1, 2 are disjoint. Since 1 and 2 are Poisson processes, |1 ‚à©A1| is
independent of |1 ‚à©B1| and |2 ‚à©A2| is independent of |2 ‚à©B2|. By assumption,
|1 ‚à©A1| is independent of |2 ‚à©B2| and |2 ‚à©A2| is independent of |1 ‚à©B1|.
Thus, the two values
| ‚à©A| = |1 ‚à©A1| + |2 ‚à©A2|
and
| ‚à©B| = |1 ‚à©B1| + |2 ‚à©B2|
are independent as required.

SIMULATING STATISTICAL MODELS
61
Since the deÔ¨Ånition of a Poisson process only speciÔ¨Åes the behaviour of the
number of points in a given set, but does not mention the points of  individually,
the deÔ¨Ånition cannot be directly used to simulate samples from a Poisson process.
Instead, most methods for simulating a Poisson process are based on the construction
described in the following algorithm and in proposition 2.37.
Algorithm 2.36
(Poisson process)
input:
an intensity function Œª: Rd ‚ÜíR
a set D ‚äÜRd with (D) < ‚àûwhere  is given by (2.5)
randomness used:
N ‚àºPois((D))
i.i.d. samples Xi ‚àº1DŒª(¬∑)/(D) for i = 1, 2, . . . , N
output:
a sample from the Poisson process on D with intensity Œª
1: generate N ‚àºPois((D))
2:  ‚Üê‚àÖ
3: for i = 1, 2, . . . , N do
4:
generate Xi ‚àº
1
(D)1DŒª(¬∑)
5:
 ‚Üê ‚à™{Xi}
6: end for
7: return 
The function 1DŒª/(D) in the algorithm, is given by
1DŒª(x)
(D) =
‚éß
‚é®
‚é©
Œª(x)
(D)
if x ‚ààD and
0
otherwise.
This function is a probability density whenever (D) > 0. For (D) = 0 this
expression is undeÔ¨Åned but, since in this case we always have N = 0, we will
never need to generate any Xi when the density is not deÔ¨Åned, so there is no
problem.
Proposition 2.37
Let D ‚äÜRd be a set and Œª: Rd ‚Üí[0, ‚àû) a function such that 
deÔ¨Åned by (2.5) satisÔ¨Åes (D) < ‚àû. Then the following statements hold:
(a) The output  of algorithm 2.36 is a sample of a Poisson process on D with
intensity Œª.
(b) The number of iterations of the loop in algorithm 2.36 is random with expec-
tation (D).

62
AN INTRODUCTION TO STATISTICAL COMPUTING
Proof
To show that the output  is a Poisson process, we have to verify that 
satisÔ¨Åes the two conditions from deÔ¨Ånition 2.34: let A ‚äÜD and k ‚ààN. Then
P(| ‚à©A| = k) = P
 ‚àû

n=k
{| ‚à©A| = k, N = n}

=
‚àû

n=k
P(N = n)P(| ‚à©A| = k|N = n).
By construction of , each of the Xi independently takes a value in A with probability
p = P(Xi ‚ààA) =
1
(D)

A
Œª(x) dx = (A)
(D).
Consequently, the probability that k out of the n values Xi are in A is given by the
binomial distribution B(n, p) and we Ô¨Ånd
P (| ‚à©A| = k)
=
‚àû

n=k
e‚àí(D) (D)n
n!
¬∑
n!
k!(n ‚àík)!
 (A)
(D)
k (D) ‚àí(A)
(D)
n‚àík
= e‚àí(D) (A)k
k!
‚àû

n=k
((D) ‚àí(A))n‚àík
(n ‚àík)!
= e‚àí(D) (A)k
k!
e(D)‚àí(A)
= e‚àí(A) (A)k
k!
.
Thus, | ‚à©A| is Poisson-distributed with parameter (A) as required.
For the second part of the deÔ¨Ånition, let A, B ‚äÜD be disjoint. Similar to the
previous calculation, we Ô¨Ånd
P (| ‚à©A| = k, | ‚à©B| = l)
=
‚àû

n=k+l
P(N = n)P

| ‚à©A| = k, | ‚à©B| = l
 N = n

.
Since A and B are disjoint, each of the Xi is either in A or in B or in D \ (A ‚à™B).
Consequently, | ‚à©A| = k and | ‚à©B| = l follow a multinomial distribution:
P (| ‚à©A| = k, | ‚à©B| = l)
=
‚àû

n=k+l
e‚àí(D) (D)n
n!
n!
k!l! (n ‚àík ‚àíl)!

SIMULATING STATISTICAL MODELS
63
¬∑
 (A)
(D)
k  (B)
(D)
l (D) ‚àí(A) ‚àí(B)
(D)
n‚àík‚àíl
= e‚àí(D) (A)k
k!
(B)l
l!
‚àû

n=k+l
((D) ‚àí(A) ‚àí(B))n‚àík‚àíl
(n ‚àík ‚àíl)!
= e‚àí(D) (A)k
k!
(B)l
l!
e(D)‚àí(A)‚àí(B)
= e‚àí(A) (A)k
k!
¬∑ e‚àí(B) (B)l
l!
= P (| ‚à©A| = k) ¬∑ P (| ‚à©B| = l) ,
for all k,l ‚ààN0. Thus, the two random variables | ‚à©A| = k and | ‚à©B| = l are
independent. This completes the proof of the Ô¨Årst statement.
The second statement, about computational cost, is clear from the Ô¨Årst property
in lemma 2.33.
Example 2.38
Assume that we want to sample from a Poisson process with constant
intensity Œª ‚ààR on an interval D = [a, b] ‚äÜR. Then we have (D) =
 b
a Œª dx =
Œª(b ‚àía) and thus Œª/(D) = 1/(b ‚àía) is the density of the uniform distribution on
[a, b]. Consequently, by proposition 2.37, we can generate a sample of a Poisson
process on [a, b] by the following procedure:
(a) Generate N ‚àºPois(Œª(b ‚àía)).
(b) Generate X1, X2, . . . , X N ‚àºU[a, b] i.i.d.
(c) Let  = {X1, X2, . . . , X N}.
Example 2.39
We can use lemma 2.35 to simulate a Poisson process with a
piecewise constant intensity function Œª as shown, for example, in Figure 2.3. Let
a = t0 < t1 < ¬∑ ¬∑ ¬∑ < tn = b be given and assume that Œª satisÔ¨Åes
Œª(t) =
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©
Œª1
if t ‚àà[t0, t1]
Œª2
if t ‚àà[t1, t2]
...
Œªn
if t ‚àà[tn‚àí1, tn].
We can use algorithm 2.36 to generate a sample of a Poisson process on each of
the intervals [ti‚àí1, ti). Since Œª is constant on these intervals, we can just generate
Ni ‚àºPois(Œªi) and then let i = {X(i)
1 , . . . , X(i)
Ni } where X(i)
1 , . . . , X(i)
Ni ‚àºU[ti‚àí1, ti)
are i.i.d. Finally, by lemma 2.35 the set  = 1 ‚à™2 ‚à™¬∑ ¬∑ ¬∑ ‚à™n is a sample of a
Poisson process on [a, b] with intensity Œª.

64
AN INTRODUCTION TO STATISTICAL COMPUTING
t
Œª(t)
Œª1
Œª2
Œª3
. . .
Œªn
a = t0
t1
t2
t3
tn‚àí1
tn = b
Figure 2.3
A Poisson process on an interval [a, b] ‚äÜR with piecewise constant
intensity function Œª. The function Œª satisÔ¨Åes Œª(t) = Œªi whenever t ‚àà[ti‚àí1, ti). The
marked points on the t-axis form one sample of the corresponding Poisson process.
Example 2.40
Assume that we want to sample a Poisson process on the domain
D = [‚àí6, 6] √ó [‚àí4, 4] ‚äÜR2 with intensity function
Œª(x) = 100 exp

‚àíx2
1 + x2
2
2

+ 100 exp

‚àí(x1 ‚àí4)2 ‚àí(x2 ‚àí2)2
for all x ‚ààR2. In this case, (D) is difÔ¨Åcult to determine and we cannot directly
apply algorithm 2.36. Instead, we can get samples from this Poisson process by Ô¨Årst
simulating the Poisson process on R2 with intensity Œª, and the use lemma 2.35 to
restrict the resulting process to the given domain D.
By rewriting the intensity-function Œª as
Œª(x) = 200œÄ 1
2œÄ exp

‚àíx2
1 + x2
2
2

+ 100œÄ
1
2œÄ 1
2
exp

‚àí(x1 ‚àí4)2 + (x2 ‚àí2)2
2 ¬∑ 1
2

,
we see that Œª is 300œÄ times the density of the mixture distribution
2
3 N(0, I2) + 1
3 N(Œº, I2/2)
where Œº = (4, 2) and I2 is the identity matrix in R2. Consequently, we have
(R2) =

R2 Œª(x) dx = 200 œÄ + 100 œÄ = 300 œÄ.
Thus, if we set N ‚àºPois(300 œÄ) and deÔ¨Åne Àú = {X1, . . . , X N} where the Xi are
independent samples from the mixture distribution with density Œª/300œÄ, then Àú is

SIMULATING STATISTICAL MODELS
65
a Poisson process on R2 with intensity Œª. Finally we deÔ¨Åne  = Àú ‚à©D. Then, by
lemma 2.35,  is a Poisson process on D with intensity Œª. The result of a simulation
using the method described in this example is shown in Figure 2.2.
To conclude this section, we describe a rejection algorithm for converting a
Poisson process with intensity Œª into a Poisson process with intensity ÀúŒª ‚â§Œª by
randomly omitting some of the points.
Algorithm 2.41
(thinning method for Poisson processes)
input:
intensity functions Œª, ÀúŒª: Rd ‚ÜíR with ÀúŒª < Œª
a set D ‚äÜRd with (D) < ‚àûwhere  is given by (2.5)
randomness used:
N ‚àºPois((D))
i.i.d. samples Xi ‚àº1DŒª(¬∑)/(D) for i = 1, 2, . . . , N
Ui ‚àºU[0, 1] i.i.d.
output:
a sample from the Poisson process on D with intensity ÀúŒª
1: generate N ‚àºPois((D))
2: Àú ‚Üê‚àÖ
3: for i = 1, 2, . . . , N do
4:
generate Xi ‚àº
1
(D)1DŒª(¬∑)
5:
generate Ui ‚àºU[0, 1]
6:
if Ui ‚â§ÀúŒª(Xi)/Œª(Xi) then
7:
Àú ‚ÜêÀú ‚à™{Xi}
8:
end if
9: end for
10: return Àú
Proposition 2.42 shows that this algorithm returns a sample from a Poisson
process with intensity ÀúŒª. While the result does not depend on the choice of the
auxiliary density Œª, the choice of Œª affects efÔ¨Åciency. Under the constraint Œª ‚â•ÀúŒª, the
intensity Œª should be chosen such that the samples Xi in step 4 of the algorithm can
be generated efÔ¨Åciently and that (D) is as small as possible.
Proposition 2.42
Let  be a Poisson process on D ‚äÜRd with intensity Œª: Rd ‚Üí
[0, ‚àû). Let ÀúŒª : Rd ‚Üí[0, ‚àû) such that ÀúŒª(x) ‚â§Œª(x) for all x ‚ààD and deÔ¨Åne a random
subset Àú ‚äÜ by randomly including each point x ‚àà into Àú with probability
ÀúŒª(x)/Œª(x), independently of each other and of . Then Àú is a Poisson process with
intensity function ÀúŒª.
Proof
We prove the statement of the proposition by verifying that Àú satisÔ¨Åes
deÔ¨Ånition 2.34: let A ‚äÜRd. Then, to check the Ô¨Årst statement from deÔ¨Ånition 2.34,
we have to show that |A ‚à©| is Poisson-distributed with the correct expectation.

66
AN INTRODUCTION TO STATISTICAL COMPUTING
We start the proof by Ô¨Årst considering the conditional distribution of , condi-
tioned on |A ‚à©| = n ‚ààN0. Using the construction of  given in algorithm 2.36 and
proposition 2.37 we see that, under this condition, the set A ‚à© consists of n random
points X1, . . . , Xn ‚ààA, independently distributed with density Œª/(A). Depending
on its location in A, each point Xi is included in Àú with probability ÀúŒª(Xi)/Œª(Xi)
and averaging over the possible locations for Xi, we Ô¨Ånd the probability of Xi being
included in Àú as
p =

A
ÀúŒª(x)
Œª(x) ¬∑ Œª(x)
(A) dx =
1
(A)

A
ÀúŒª(x) dx =
Àú(A)
(A),
where we used the abbreviation
Àú(A) =

A
ÀúŒª(x) dx.
Since this probability does not depend on i, the total number of points in | Àú ‚à©A|,
conditioned on |A ‚à©| = n, is B(n, p)-distributed. Thus we have
P
 Àú ‚à©A
 = k
 |A ‚à©| = n

=
n
k
  Àú(A)
(A)
k 
1 ‚àí
Àú(A)
(A)
n‚àík
(2.6)
=
n
k
 Àú(A)k 
(A) ‚àíÀú(A)
n‚àík
(A)n
.
To Ô¨Ånd the distribution of | Àú ‚à©A|, we have to average the result from equation
(2.6) over the possible values of | ‚à©A|. Since |A ‚à©| ‚àºPois((A)), we get
P
 Àú ‚à©A
 = k

=
‚àû

n=k
P
 Àú ‚à©A
 = k
 |A ‚à©| = n

P (|A ‚à©| = n)
=
‚àû

n=k
n!
k!(n ‚àík)!
Àú(A)k 
(A) ‚àíÀú(A)
n‚àík
(A)n
e‚àí(A) (A)n
n!
=
Àú(A)k
k!
‚àû

n=k

(A) ‚àíÀú(A)
n‚àík
(n ‚àík)!
e‚àí(A)
=
Àú(A)k
k!
‚àû

l=0

(A) ‚àíÀú(A)
l
l!
e‚àí(A)
=
Àú(A)k
k!
e(A)‚àíÀú(A)e‚àí(A)
= e‚àíÀú(A) Àú(A)k
k!
for all k ‚ààN0. Thus | Àú ‚à©A| ‚àºPois( Àú(A)) as required.

SIMULATING STATISTICAL MODELS
67
For the second condition from deÔ¨Ånition 2.34, let A, B ‚äÜD be disjoint. Then,
since  is a Poisson process, the numbers | ‚à©A| and | ‚à©B| are independent. Also,
given , the choices whether to include any of the x ‚àà into the subset Àú ‚äÜ
are independent, and thus | Àú ‚à©A| and | Àú ‚à©B| are independent. This completes
the proof.
2.5
Summary and further reading
In this chapter we illustrated with the help of examples, how sequences of independent
random numbers can be used as building blocks to simulate more complex statistical
models. The key aspect of such simulations is that the random components of statis-
tical models are often no longer independent but can feature a complex dependence
structure.
Among the models discussed here were Markov chains (Section 2.3) and Poisson
processes (Section 2.4). For both classes of processes, we restricted discussion of the-
oretical aspects to a minimum. More detail can be found in the literature, for example
in the books by Norris (1997) for Markov chains and Kingman (1993) for Poisson
processes. Space restrictions force us to leave out many popular classes of models,
for example we did not discuss the autoregressive and moving average models for
time series (see e.g. ChatÔ¨Åeld, 2004), but often simulation of such processes is either
straightforward or can be performed building on the ideas illustrated in this chapter.
This concludes our study of methods for simulating statistical models. In the
following chapters we will learn how the samples by such simulations can be used
to study the underlying models. We will return to the question of how to simulate
statistical models in a slightly different context in Chapter 6, where we will consider
stochastic processes in continuous time.
Exercises
E2.1
Write a program which generates samples from the mixture of P1 =
N(1, 0.012), P2 = N(2, 0.52) and P3 = N(5, 0.022) with weights Œ∏1 = 0.1,
Œ∏2 = 0.7 and Œ∏3 = 0.2. Generate a plot showing a histogram of 10 000 samples
of this distribution, together with the density of the mixture distribution.
E2.2
Let Œµ j ‚àºN(0, 1) i.i.d. for j ‚ààN and let X = (X j) j‚ààN be deÔ¨Åned by
X0 = 0, X1 = Œµ1 and X j = X j‚àí1 + X j‚àí2 + Œµ j for all j ‚â•2. Show that the
process X is not a Markov chain.
E2.3
Let X be the Markov chain with transition matrix
P =
‚éõ
‚éú‚éú‚éù
2/3
1/3
0
0
1/10
9/10
0
0
1/10
0
9/10
0
1/10
0
0
9/10
‚éû
‚éü‚éü‚é†
and initial distribution Œº = (1/4, 1/4, 1/4, 1/4).

68
AN INTRODUCTION TO STATISTICAL COMPUTING
(a)
Write a program which generates a random path X0, X1, X2, . . . , X N
from this Markov chain.
(b)
Use the program from (a) and Monte Carlo integration to numerically
determine the distribution of X10 (i.e. you have to estimate the proba-
bilities P(X10 = x) for x = 1, 2, 3, 4).
(c)
Analytically compute the distribution of X10. You may use a computer
to obtain your answer.
E2.4
(a)
Let P be a stochastic matrix. Show that the vector v = (1, 1, . . . , 1) is
an eigenvector of P and determine the corresponding eigenvalue.
(b)
Let v be an eigenvector of a matrix A with eigenvalue Œª. Show that for
Œ± Ã∏= 0 the vector Œ±v is also an eigenvector of A.
(c)
Find a stationary distribution for the stochastic matrix P from exercise
E2.3 by computing the eigenvectors of P‚ä§. You can use the R functions
t and eigen for this exercise. Some care is needed because the entries
of the computed eigenvector may not be positive and may not sum up
to 1 (see (b) for an explanation). How can we solve this problem?
E2.5
Write a program which simulates a Poisson process with constant intensity
Œª > 0 on an interval [a, b] ‚äÜR.
E2.6
Write a program which simulates a Poisson process with piecewise con-
stant intensity function Œª. The program should take t0 < t1 < ¬∑ ¬∑ ¬∑ < tn and
Œª1, . . . , Œªn ‚â•0 as inputs (see Figure 2.3 and example 2.39) and should return
one sample of the Poisson process.

3
Monte Carlo methods
So far, in the Ô¨Årst two chapters of this book, we have learned how to simulate statistical
models on a computer. In this and the following two chapters we will discuss how such
simulations can be used to study properties of the underlying statistical model. In this
chapter we will concentrate on the approach to directly generate a large number of
samples from the given model. The idea is then that the samples reÔ¨Çect the statistical
behaviour of the model; questions about the model can then be answered by studying
statistical properties of the samples. The resulting methods are called Monte Carlo
methods.
3.1
Studying models via simulation
When studying statistical models, analytical calculations often are only possible
under assumptions such as independence of samples, normality of samples or large
sample size. For this reason, many problems occurring in ‚Äòreal life‚Äô situations are
only approximately covered by the available analytical results. This chapter presents
an alternative approach to such problems, based on estimates derived from computer
simulations instead of analytical calculations.
The fundamental observation underlying the methods discussed in this and the
following chapters is the following: if we can simulate a statistical model on a
computer, then we can generate a large set of samples from the model and then we
can learn about the behaviour of the model by studying the computer-generated set
of samples instead of the model itself. We give three examples for this approach:
r As a consequence of the law of large numbers (see theorem A.8), the expected
value of a random variable can be approximated by generating a large number
of samples of the random variable and then considering the average value.
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

70
AN INTRODUCTION TO STATISTICAL COMPUTING
r The probability of an event can be approximated by generating a large number
of samples and then considering the proportion of samples where the event
occurs.
r The quality of a method for statistical inference can be assessed by repeatedly
generating synthetic data with a known distribution and then analysing how
well the inference method recovers the (known) properties of the underlying
distribution from the synthetic data sets.
Since many interesting questions can be reduced to computing the expectation
of some random variable, we will mostly restrict our attention to the problem of
computing expectations of the form E( f (X)) where X is a random sample from
the system under consideration and f is a real-valued function, determining some
quantity of interest in the system. There are several different methods to compute
such an expectation:
(a) Sometimes we can Ô¨Ånd the answer analytically. For example, if the distribu-
tion of X has a density œï, we can use the relation
E( f (X)) =

f (x) œï(x) dx
(3.1)
to obtain the value of the expectation (see Section A.3). This method only
works if we can solve the resulting integral.
(b) If the integral in (3.1) cannot be solved analytically, we can try to use numer-
ical integration to get an approximation to the value of the integral. When
X takes values in a low-dimensional space, this method often works well,
but for higher dimensional spaces numerical approximation can become very
expensive and the resulting method may no longer be efÔ¨Åcient. Since numeri-
cal integration is outside the topic of statistical computing, we will not follow
this approach here.
(c) The approach we will study in this chapter is called Monte Carlo estimation
or Monte Carlo integration. This technique is based on the strong law of large
numbers: if (X j) j‚ààN is a sequence of i.i.d. random variables with the same
distribution as X, then
E( f (X)) = lim
N‚Üí‚àû
1
N
N

j=1
f (X j)
(3.2)
with probability 1.
Our aim for this chapter is to study approximations for E( f (X)) based on Equation
(3.2). While the exact equality in (3.2) holds only in the limit N ‚Üí‚àû, we can use
the approximation with Ô¨Åxed, large N to get the following approximation method.

MONTE CARLO METHODS
71
DeÔ¨Ånition 3.1
A Monte Carlo method for estimating the expectation E( f (X)) is a
numerical method based on the approximation
E( f (X)) ‚âà1
N
N

j=1
f (X j),
(3.3)
where (X j) j‚ààN are i.i.d. with the same distribution as X.
In order to compute a numerical value for this approximation we will need to
generate a large number of samples X j from the model. This can be done using the
techniques from Chapters 1 and 2. In the present chapter we will assume that we have
solved the problem of generating these samples and we will concentrate on the esti-
mate (3.3) itself: we will consider how the error in the approximation (3.3) depends
on the computational cost and we will derive improved variants of the basic approxi-
mation (3.3).
Example 3.2
For f (x) = x, the Monte Carlo estimate (3.3) reduces to
E(X) ‚âà1
N
N

j=1
X j = ¬ØX.
This is just the usual estimator for the mean.
Example 3.3
Assume that we want to compute the expectation E(sin(X)2) where
X ‚àºN(Œº, œÉ 2). Obtaining the exact value analytically will be difÔ¨Åcult, but we can
easily get an approximation using Monte Carlo estimation: if we choose the number
of samples N large and generate independent, N(Œº, œÉ)-distributed random variables
X1, X2, . . . , X N, then, by the strong law of large numbers, we have
E (sin(X)) ‚âà1
N
N

j=1
sin(X j)2.
The right-hand side of this approximation can be easily evaluated numerically, giving
an estimate for the required expectation.
While the approximation (3.3) is only stated for the problem of estimating an
expectation, the same technique applies to a wider class of problems. To illustrate
this, we consider two different problems, which can be reduced to the problem of
computing an expectation.
As a Ô¨Årst application of Monte Carlo estimates we consider here the problem of
estimating probabilities. While computing expectations and computing probabilities
at Ô¨Årst look like different problems, the latter can be reduced to the former: if X

72
AN INTRODUCTION TO STATISTICAL COMPUTING
is a random variable, we have P(X ‚ààA) = E(1A(X)); this relation is, for example,
explained in Section A.3. Using this equality, we can estimate P(X ‚ààA) by
P(X ‚ààA) = E (1A(X)) ‚âà1
N
N

j=1
1A(X j)
(3.4)
for sufÔ¨Åciently large N.
Example 3.4
Let X ‚àºN(0, 1) and a ‚ààR. Then the probability p = P(X ‚â§a)
cannot be computed analytically in an explicit form, but
pN = 1
N
N

j=1
1(‚àí‚àû,a](X j)
can be used as an approximation for p.
As a second application of Monte Carlo estimation we consider the problem of
approximating the value of integrals such as
 b
a f (x) dx. Again, this problem at Ô¨Årst
looks like it is distinct from the problem of computing expectations, but it transpires
that the two problems are closely related. To see this, we utilise the relation (3.1)
from the beginning of this chapter as follows: let X, X j ‚àºU[a, b] be i.i.d. Then the
density of X j is œï(x) =
1
b‚àía 1[a,b]. We get
 b
a
f (x) dx = (b ‚àía)
 b
a
f (x)œï(x) dx
= (b ‚àía)E( f (X))
(3.5)
‚âàb ‚àía
N
N

j=1
f (X j)
for sufÔ¨Åciently large N.
Example 3.5
To estimate the integral
 2œÄ
0
eŒ∫ cos(x) dx we can generate X j ‚àºU[0, 2œÄ]
and then use the approximation
 2œÄ
0
eŒ∫ cos(x) dx ‚âà2œÄ
N
N

j=1
eŒ∫ cos(X j).
To conclude this section, we give a longer example showing how the methods
from Chapter 1 can be used in Monte Carlo estimates.
Example 3.6
Consider a simple Bayesian inference problem, where we want to
make inference about X ‚àºExp(1) using a single observation of Y ‚àºN(0, X). To

MONTE CARLO METHODS
73
solve this problem, we have to Ô¨Ånd the posterior distribution, that is the conditional
distribution of X given the observation Y = y.
We can Ô¨Ånd the density of the conditional distribution of X using Bayes‚Äô rule
pX|Y(x|y) = pY|X(y|x)pX(x)
pY(y)
as found, for example, using equation (A.5). The value X ‚àºExp(1) has density
pX(x) = exp(‚àíx) and, given X = x, the conditional density of Y ‚àºN(0, X) is
pY|X(y|x) =
1
‚àö
2œÄx
exp

‚àíy2/2x

.
By averaging over the possible values of X we Ô¨Ånd the unconditional density of Y as
pY(y) =
 ‚àû
0
pY|X(y|Àúx) pX(Àúx) d Àúx =
 ‚àû
0
1
‚àö
2œÄ Àúx
exp

‚àíy2/2Àúx ‚àíÀúx

d Àúx.
Thus, the conditional density of X given Y = y is
pX|Y(x|y) = pY|X(y|x)pX(x)
pY(y)
=
1
‚àö
2œÄx exp

‚àíy2/2x ‚àíx

 ‚àû
0
1
‚àö
2œÄ Àúx exp

‚àíy2/2Àúx ‚àíÀúx

d Àúx
(3.6)
= 1
Z f
f (x)
for all x ‚â•0, where
f (x) =
1
‚àöx exp

‚àíy2/2x ‚àíx

and Z f =
 ‚àû
0
f (Àúx) d Àúx. This is the required density of the conditional distribution of
X given Y.
To derive estimates about X using Monte Carlo estimation, we need to be able
to generate samples from the posterior distribution of X, that is we need to be able
to generate samples from the distribution with the density pX|Y given in equation
(3.6). Generating samples from this distribution is complicated by the fact that we
do not know the value of the integral Z f . But, since the rejection sampling algorithm
from Section 1.4 can still be applied when the normalising constant Z f is unknown,
we can use algorithm 1.22 for this purpose. Since f is bounded near 0 and since

74
AN INTRODUCTION TO STATISTICAL COMPUTING
f (x) ‚âàexp(‚àíx) when x is large, we try to use an Exp(1)-distribution for the propos-
als; the corresponding density is
g(x) = exp(‚àíx)
for all x ‚â•0. For this to work, we need to Ô¨Ånd a constant c > 0 with f (x) ‚â§cg(x)
for all x ‚â•0. A straightforward calculation (see exercise E1.8) shows that this bound
is satisÔ¨Åed for the value
c = 1
|y| exp(‚àí1/2)
and thus the rejection sampling algorithm 1.22 can be applied to generate the required
samples.
Using samples generated by the rejection algorithm, we can now answer questions
about the posterior distribution. If we generate samples X1, X2, . . . , X N for large N,
for example for N = 10 000, we can use estimates such as
E(X|Y = y) ‚âà1
N
N

j=1
X j = ¬ØX
and
Var(X|Y = y) ‚âà
1
N ‚àí1
N

j=1

X j ‚àí¬ØX
2 .
Without the use of Monte Carlo estimation, the posterior mean E(X|Y = y) and the
posterior variance Var(X|Y = y) would be difÔ¨Åcult to determine.
3.2
Monte Carlo estimates
In this section we study the basic properties of Monte Carlo estimates as introduced
in the previous section.
DeÔ¨Ånition 3.7
Let X be a random variable and f be a function such that f (X) ‚ààR.
Then the Monte Carlo estimate for E( f (X)) is given by
ZMC
N
= 1
N
N

j=1
f (X j),
(3.7)
where X1, . . . , X N are i.i.d. with the same distribution as X.

MONTE CARLO METHODS
75
Since the estimate ZMC
N
is constructed from random samples X j, it is a random
quantity itself. The random variables X j in (3.7) are sometimes called i.i.d. copies
of X.
3.2.1
Computing Monte Carlo estimates
We can rewrite equation (3.7) as the following very simple algorithm.
Algorithm 3.8
(Monte Carlo estimate)
input:
a function f with values in R
N ‚ààN
randomness used:
i.i.d. copies (X j) j‚ààN of X
output:
an estimate ZMC
N
for E( f (X))
1: s ‚Üê0
2: for j = 1, 2, . . . , N do
3:
generate X j, with the same distribution as X has
4:
s ‚Üês + f (X j)
5: end for
6: return s/N
Ignoring the negligible computational cost for the initial assignment of the vari-
able s and of the Ô¨Ånal division by N, the execution time of algorithm 3.8 is proportional
to N. On the other hand, by the law of large numbers, we know that the estimate
ZMC
N
converges to the correct value E( f (X)) only as N increases, and thus the error
decreases as N increases. For this reason, choosing the sample size N in algorithm
3.8 involves a trade-off between computational cost and accuracy of the result. We
will discuss this trade-off in more detail in the following section.
An alternative to algorithm 3.8 would be to Ô¨Årst generate all samples f (X1),
f (X2), . . . , f (Xn) and then, in a second step, to compute and return the average of
the samples. The advantage of using the temporary variable s in algorithm 3.8 to
accumulate the results instead is, that the samples f (X j) do not need to be stored
in the computer‚Äôs memory, thus greatly reducing the memory requirements of the
algorithm: the memory required to execute algorithm 3.8 is independent of N.
DeÔ¨Ånition 3.7 and algorithm 3.8 do not explicitly state the space the random
variables X and X j take their values in. The reason for this omission is that algorithm
3.8 poses no restrictions on the random variable X except for the requirement that
the expectation E( f (X)) must exist. In simple cases, the random variable X could
take values in R or in Rd, but many practical applications require the values of X to
have a more complicated structure. As an example, in Section 6.5 we will consider
the case where X is a random function. In contrast, we will assume throughout this
text that f (X) ‚ààR so that there are no complications to deÔ¨Åne the sum in equation
(3.7) or to deÔ¨Åne the expectation E( f (X)).

76
AN INTRODUCTION TO STATISTICAL COMPUTING
3.2.2
Monte Carlo error
Since the estimate ZMC
N
from deÔ¨Ånition 3.7 and algorithm 3.8 is random, the Monte
Carlo error ZMC
N
‚àíE( f (X)) is also random. To quantify the magnitude of this random
error, we use the concepts of bias and mean squared error from statistics.
DeÔ¨Ånition 3.9
The bias of an estimator ÀÜŒ∏ = ÀÜŒ∏(X) for a parameter Œ∏ is given by
bias( ÀÜŒ∏) = EŒ∏
 ÀÜŒ∏(X) ‚àíŒ∏

= EŒ∏
 ÀÜŒ∏(X)

‚àíŒ∏,
where the subscript Œ∏ in the expectations on the right-hand side indicates that the
sample X in the expectation comes from the distribution with true parameter Œ∏.
Since the bias as given in deÔ¨Ånition 3.9 depends on the value of Œ∏, sometimes the
notation biasŒ∏( ÀÜŒ∏) is used to indicate the dependence on Œ∏. While the bias measures
how far off the estimate is on average, a small value of the bias does not necessarily
indicate a useful estimator: even when the estimator is correct on average, the actual
values of the estimator may Ô¨Çuctuate so wildly around Œ∏ that they are not useful in
practice. For this reason, the size of Ô¨Çuctuations of an estimator is considered.
DeÔ¨Ånition 3.10
The standard error of an estimator ÀÜŒ∏ = ÀÜŒ∏(X) is given by
se( ÀÜŒ∏) = stdevŒ∏
 ÀÜŒ∏(X)

,
where the subscript Œ∏ on the standard deviation indicates that the sample X comes
from the distribution with true parameter Œ∏.
Finally, the mean squared error, introduced in the following deÔ¨Ånition, combines
both kinds of error: it measures the Ô¨Çuctuations of the estimator around the true value
of the parameter.
DeÔ¨Ånition 3.11
The mean squared error (MSE) of an estimator ÀÜŒ∏ = ÀÜŒ∏(X) for a
parameter Œ∏ is given by
MSE( ÀÜŒ∏) = EŒ∏
 ÀÜŒ∏(X) ‚àíŒ∏
2
.
As for the bias, the expressions for the standard error and for the mean squared
error depend on the value of Œ∏ and sometimes the notations seŒ∏( ÀÜŒ∏) and MSEŒ∏( ÀÜŒ∏) are
used to indicate this dependence. The following lemma shows that the mean squared
error can be computed from the bias and the standard error.
Lemma 3.12
Let ÀÜŒ∏ = ÀÜŒ∏(X1, . . . , Xn) be an estimator for a parameter Œ∏ ‚ààR. Then
the mean squared error of ÀÜŒ∏ satisÔ¨Åes
MSE( ÀÜŒ∏) = Var( ÀÜŒ∏) + bias( ÀÜŒ∏)2 = se( ÀÜŒ∏)2 + bias( ÀÜŒ∏)2.

MONTE CARLO METHODS
77
Proof
We have
MSE( ÀÜŒ∏) = EŒ∏

( ÀÜŒ∏ ‚àíŒ∏)2
= EŒ∏( ÀÜŒ∏2) ‚àí2Œ∏EŒ∏( ÀÜŒ∏) + Œ∏2
= EŒ∏( ÀÜŒ∏2) ‚àíEŒ∏( ÀÜŒ∏)2 + EŒ∏( ÀÜŒ∏)2 ‚àí2Œ∏EŒ∏( ÀÜŒ∏) + Œ∏2
= EŒ∏( ÀÜŒ∏2) ‚àíEŒ∏( ÀÜŒ∏)2 +

EŒ∏( ÀÜŒ∏) ‚àíŒ∏
2
= Var( ÀÜŒ∏) + bias( ÀÜŒ∏)2.
This completes the proof.
Example 3.13
Let X1, . . . , X N ‚àºN(Œº, œÉ 2) be i.i.d. with a known variance œÉ 2 and
unknown mean Œº ‚ààR. Then
ÀÜŒº(X) = 1
n
n

i=1
Xi
is an estimator for Œº with
bias( ÀÜŒº) = EŒº
	
1
n
n

i=1
Xi

‚àíŒº = 1
n
n

i=1
EŒº(Xi) ‚àíŒº = 1
n
n

i=1
Œº ‚àíŒº = 0
and, using the independence of the Xi,
se( ÀÜŒº) =



VarŒº
	
1
n
n

i=1
Xi

=



 1
n2
n

i=1
VarŒº(Xi) =

nœÉ 2
n2 = œÉ
‚àön
for all Œº ‚ààR. Finally, using lemma 3.12, we Ô¨Ånd MSE( ÀÜŒ∏) = (œÉ/‚àön)2 + 02 = œÉ 2/n.
Proposition 3.14
The Monte Carlo estimate ZMC
N
for E( f (X)), as computed in
algorithm 3.8, has
bias

ZMC
N

= 0
and
MSE

ZMC
N

= Var

ZMC
N

= 1
N Var( f (X)).
(3.8)

78
AN INTRODUCTION TO STATISTICAL COMPUTING
Proof
The expectation of ZMC
N
is given by
E

ZMC
N

= E
‚éõ
‚éù1
N
N

j=1
f (X j)
‚éû
‚é†= 1
N
N

j=1
E

f (X j)

= E( f (X))
and thus we have
bias

ZMC
N

= E

ZMC
N

‚àíE( f (X)) = 0.
Since the X j are independent, the variance of the Monte Carlo estimate can be
found as
Var

ZMC
N

= Var
‚éõ
‚éù1
N
N

j=1
f (X j)
‚éû
‚é†= 1
N 2
N

j=1
Var

f (X j)

= 1
N Var( f (X)).
Finally, using lemma 3.12, we get
MSE

ZMC
N

= Var

ZMC
N

+ bias

ZMC
N
2 = 1
N Var( f (X)) + 0.
This completes the proof.
Example 3.15
Let X ‚àºN(0, 1) and assume that we want to estimate the expectation
E(sin(X)2). The Monte Carlo estimate for this expectation is given by
ZMC
N
=
N

j=1
sin(X j)2,
where X1, . . . , X N ‚àºN(0, 1) are independent. From proposition 3.14 we know that
ZMC
N
is random and that, for every value of N, we have E(ZMC
N ) = E(sin(X)2).
But due to random Ô¨Çuctuations, individual Monte Carlo estimates ZMC
N
will not
be equal to this value, but instead will Ô¨Çuctuate around this value with variance
proportional to 1/N. This is illustrated in Figure 3.1 which shows the spread of the
distribution of ZMC
N
for two different values of N. The Ô¨Ågure shows histograms of
a large number of Monte Carlo estimates with sample size N = 1000 (a) and N =
10 000 (b). As expected from proposition 3.14, the distribution of the estimates with
N = 10 000 has noticeably smaller variance than the distribution of the estimates with
N = 1000.

MONTE CARLO METHODS
79
Z1000
Frequency
0.40
0.42
0.44
0.46
0
500
1000
2000
Z10 000
Frequency
0.40
0.42
0.44
0.46
0
500
1000
2000
(a)
(b)
Figure 3.1
Histograms of Monte Carlo estimates for the expectation E(sin(X)2)
where X ‚àºN(0, 1). The plots clearly show that the estimates with (a) N = 1000
and (b) N = 10 000 are clustered around the same mean. (b) shows that the estimates
using N = 10 000 samples have much smaller variance, and thus smaller error, than
the estimates for N = 1000. This conÔ¨Årms the result of proposition 3.14.
Since the mean squared error as considered in proposition 3.14 is a squared
quantity, its magnitude is not directly comparable with the magnitude of the estimate
ZMC
N
itself. For this reason, we occasionally consider the root-mean-square error,
given by
RMSE

ZMC
N

=

MSE

ZMC
N

= stdev( f (X))
‚àö
N
.
From this we see that the error of a Monte Carlo estimate decays proportionally to
1/
‚àö
N. As a consequence of this result, in practice huge numbers of samples can
be required to achieve a reasonable level of error. For example, to increase accuracy
by a factor of 10, that is to get one more signiÔ¨Åcant digit of the result, one needs to
increase the number of samples, and thus the computational cost of the method, by a
factor of 100.
An alternative way to write the results from this section is using the so-called ‚Äòbig
O notation‚Äô, as described in the following deÔ¨Ånition.
DeÔ¨Ånition 3.16
Given two function f : N ‚ÜíR and g: N ‚ÜíR we say that f is
of order O(g), written symbolically as f (N) = O(g(N)), as N ‚Üí‚àûif there are
constants N0 ‚ààN and c > 0 such that
| f (N)| ‚â§c |g(N)|
for all N ‚â•N0.

80
AN INTRODUCTION TO STATISTICAL COMPUTING
Similar deÔ¨Ånitions exist for other limits, for example for f (Œ¥) = O(g(Œ¥)) as Œ¥ ‚Üì0.
Using this notation we can summarise the result of proposition 3.14 as
MSE

ZMC
N

= O
 1
N

and for the root-mean-square error we get
RMSE

ZMC
N

= O
 1
‚àö
N

.
3.2.3
Choice of sample size
The error bound from proposition 3.14 can be used to guide the choice of sample size
N in the Monte Carlo method from algorithm 3.8. The most direct way to use the
proposition in this context is to use equation (3.8) to determine the error of the result
after a run of algorithm 3.8 has completed. If the error is too large, another run with
a larger value of N can be started, until the required precision is reached. The bound
of equation (3.8) can only be applied directly, if the sample variance Var( f (X)) is
known. If the sample variance is unknown, it can be estimated together during the
computation of the Monte Carlo estimate: The estimate ZMC
N
has mean squared error
MSE

ZMC
N

= Var( f (X))
N
‚âàÀÜœÉ 2
N ,
where
ÀÜœÉ 2 =
1
N ‚àí1
N

j=1

f (X j) ‚àíZMC
N
2
(3.9)
is the sample variance of the generated values f (X1), . . . , f (X N).
An alternative way to use proposition 3.14 is to determine the required sample
size N for a run of algorithm 3.8 in advance: by solving equation (3.8) for N we see
that, in order to achieve error MSE(ZMC
N ) ‚â§Œµ2, the sample size N must satisfy
N ‚â•Var( f (X))
Œµ2
.
(3.10)
If the value of Var( f (X)) is known, equation (3.10) can be directly used to Ô¨Ånd an
appropriate sample size N for algorithm 3.8. Normally, the variance Var( f (X)) in
a Monte Carlo estimate is not explicitly known, but there are various ways to work
around this problem. For example, if an upper bound for Var( f (X)) is known, this
bound can be used in place of the true variance.

MONTE CARLO METHODS
81
Example 3.17
Assume Var( f (X)) = 1. In order to estimate E( f (X)) so that the
error satisÔ¨Åes MSE(ZMC
N ) = Œµ2 for Œµ = 0.01, we can use a Monte Carlo estimate with
N ‚â•Var( f (X))
Œµ2
=
1
(0.01)2 = 10 000
samples.
Example 3.18
Let X be a real-valued random variable and A ‚äÜR. As we have
seen in equation (3.4), we can estimate p = P(X ‚ààA) by
ZMC
N
= 1
N
N

j=1
1A(X j),
where the X j are i.i.d. copies of X. The variance of the Monte Carlo samples is
Var (1A(X)) = E

1A(X)2
‚àíE (1A(X))2 = p ‚àíp2 = p(1 ‚àíp).
Thus, from equation (3.10) we know that we can achieve MSE(ZMC
N ) ‚â§Œµ2 by choos-
ing
N ‚â•p(1 ‚àíp)
Œµ2
.
(3.11)
This bound depends on the unknown probability p but, since p(1 ‚àíp) ‚â§1/4 for all
p ‚àà[0, 1], choosing
N ‚â•
1
4Œµ2
is always sufÔ¨Åcient to reduce the mean squared error to Œµ2.
Another approach to using the bound (3.10) in cases where the variance of
the Monte Carlo samples is not known is the following: one can try a two-step
procedure where Ô¨Årst Monte Carlo integration with a Ô¨Åxed number N0 of samples
(say N0 = 10 000) is used to estimate Var( f (X)). Then, in a second step, one can use
estimates as above to determine the required value of N to achieve a mean squared
error of less than Œµ2. In this approach, new samples X1, . . . , X N should be generated
for the Ô¨Ånal estimate instead of reusing the initial N0 samples.
Finally, sequential methods can be used to control the error of a Monte Carlo
estimate. In these methods, one generates samples X j one-by-one and estimates
the standard deviation of the generated f (X j) from time to time. The procedure is
continued until the estimated standard deviation falls below a prescribed limit. This
approach should be used with care, since a bias can be introduced by the fact that N
now depends on the samples used in the estimate.

82
AN INTRODUCTION TO STATISTICAL COMPUTING
So far we have seen how the description of the mean squared error from proposi-
tion 3.14 can be used to determine the error of a given Monte Carlo method. Another
application of the mean squared error is to compare different Monte Carlo estimates
for the same quantity. The smaller the variance Var( f (X)) of the samples is, the better
is the resulting Monte Carlo method. We will discuss this idea in detail in Section 3.3.
3.2.4
ReÔ¨Åned error bounds
We will conclude this section by showing how the central limit theorem can be used
to obtain reÔ¨Åned bounds for the Monte Carlo error.
Lemma 3.19
Let Œ± ‚àà(0, 1) and qŒ± = 
‚àí1(1 ‚àíŒ±/2) where 
 is the CDF of the
standard normal distribution N(0, 1). Furthermore let œÉ 2 = Var( f (X)) and
N ‚â•q2
Œ±œÉ 2
Œµ2 .
Then, approximately for large N, the Monte Carlo estimate ZMC
N
for E( f (X)), given
by equation (3.7), satisÔ¨Åes
P
ZMC
N
‚àíE( f (X))
 ‚â§Œµ

‚â•1 ‚àíŒ±.
Proof
As an abbreviation, write
eMC
N
= ZMC
N
‚àíE( f (X)) = 1
N
N

j=1
f (X j) ‚àíE( f (X)).
Using this notation, the results of proposition 3.14 state that E(eMC
N ) = 0 and
Var(eMC
N ) = œÉ 2/N. By the central limit theorem (see theorem A.9), for large val-
ues of N we Ô¨Ånd, approximately,
‚àö
N
œÉ eMC
N
‚àºN(0, 1)
and consequently
P

|eMC
N | ‚â§Œµ

= P
	
|eMC|
œÉ/
‚àö
N
‚â§Œµ
‚àö
N
œÉ

‚âà
	
Œµ
‚àö
N
œÉ

‚àí
	
‚àíŒµ
‚àö
N
œÉ

= 2
	
Œµ
‚àö
N
œÉ

‚àí1.
Thus we have
P

|eMC
N | ‚â§Œµ

‚â•1 ‚àíŒ±

MONTE CARLO METHODS
83
if and only if
2
	
Œµ
‚àö
N
œÉ

‚àí1 ‚â•1 ‚àíŒ±.
The latter inequality is equivalent to
Œµ
‚àö
N
œÉ
‚â•
‚àí1 
1 ‚àíŒ±
2

= qŒ±
and solving this inequality for N gives the required lower bound on N.
As a special case of lemma 3.19, for Œ± = 5% we have q0.05 = 
‚àí1(0.975) ‚âà1.96
and thus we need
N ‚â•1.962œÉ 2
Œµ2
samples in order to have an absolute error of at most Œµ with 95% probability. Compar-
ing this inequality with (3.10), we see that approximately 4 times as many samples
are required as for the condition MSE(ZMC
N ) ‚â§Œµ2.
Example 3.20
Assume Var( f (X)) = 1. In order to estimate E( f (X)) so that the
error |ZMC
N
‚àíE( f (X))| is at most Œµ = 0.01 with probability at least 1 ‚àíŒ± = 95%,
we can use a Monte Carlo estimate with
N ‚â•1.962Var( f (X))
Œµ2
= 1.962
(0.01)2 = 38 416
samples.
An alternative way to express the result of lemma 3.19 is to replace the point esti-
mator ZMC
N
by a conÔ¨Ådence interval for E( f (X)): we Ô¨Ånd that ZMC
N
(approximately)
satisÔ¨Åes
P

E

f (X)

‚àà

ZMC
N
‚àíœÉqŒ±
‚àö
N
, ZMC
N
+ œÉqŒ±
‚àö
N

‚â•1 ‚àíŒ±
(3.12)
for sufÔ¨Åciently large N, where qŒ± and œÉ 2 are as in lemma 3.19.
If the standard deviation œÉ in (3.12) is unknown, it can be replaced by the estimate
ÀÜœÉ from equation (3.9). A standard result from statistics shows that in this case the
value qŒ± should be replaced by the corresponding quantile of Student‚Äôs t-distribution
with N ‚àí1 degrees of freedom. These quantiles converge to qŒ± as N ‚Üí‚àûand for
the values of N used in a Monte Carlo estimate, qŒ± can be used without problems.

84
AN INTRODUCTION TO STATISTICAL COMPUTING
In all the error estimates of this section, we used the fact that f (X) has Ô¨Ånite
variance. As Var( f (X)) gets bigger, convergence to the correct result gets slower
and slower, and the required number of samples to obtain a given error increases to
inÔ¨Ånity. Since the strong law of large numbers does not require the random variables
to have Ô¨Ånite variance, equation (3.2) still holds for Var( f (X)) = ‚àû, but in this case
the convergence in (3.2) will be extremely slow and the resulting method will not be
useful in practice.
3.3
Variance reduction methods
As we have seen, the efÔ¨Åciency of Monte Carlo estimation is determined by the
variance of the estimate: the higher the variance, the more samples required to obtain
a given accuracy. This chapter describes methods to improve efÔ¨Åciency by considering
modiÔ¨Åed Monte Carlo methods. Compared with the basic Monte Carlo method from
Section 3.2, the improved methods considered here produce estimates with a lower
variance and thus with smaller error.
3.3.1
Importance sampling
The importance sampling method is based on the following argument. Assume that
X is a random variable with density œï, that f is a real-valued function and that œà is
another probability density with œà(x) > 0 whenever f (x)œï(x) > 0. Then we have
E( f (X)) =

f (x) œï(x) dx =

f (x) œï(x)
œà(x) œà(x) dx,
where we deÔ¨Åne the fraction to be 0 whenever the denominator (and thus the numer-
ator) equals 0. Since œà is a probability density, the integral on the right can be written
as an expectation again: if Y has density œà, we have
E( f (X)) = E

f (Y) œï(Y)
œà(Y)

.
(3.13)
Now we can use a basic Monte Carlo estimate for the expectation on the right-hand
side to get the following estimate.
DeÔ¨Ånition 3.21
Let X be a random variable with density œï and let f be a function
such that f (X) ‚ààR. Furthermore, let œà be another probability density, on the same
space as œï. Then the importance sampling estimate for E( f (X)) is given by
ZIS
N = 1
N
N

j=1
f (Y j) œï(Y j)
œà(Y j)
(3.14)
where the Y j are i.i.d. with density œà.

MONTE CARLO METHODS
85
The estimator ZIS
N can be used as an alternative to the basic Monte Carlo estimator
ZMC
N
from (3.7). Instead of the arithmetic average used in the basic Monte Carlo
method, the importance sampling method uses a weighted average where each sample
Y j is assigned the weight œï(Y j)/œà(Y j). We can write the resulting estimation method
as the following algorithm.
Algorithm 3.22
(importance sampling)
input:
a function f
the density œï of X
an auxiliary density œà
N ‚ààN
randomness used:
an i.i.d. sequence (Y j) j‚ààN with density œà
output:
an estimate ZIS
N for E( f (X))
1: s ‚Üê0
2: for j = 1, 2, . . . , N do
3:
generate Y j ‚àºœà
4:
s ‚Üês + f (Y j)œï(Y j)/œà(Y j)
5: end for
6: return s/N
This method is a generalisation of the basic Monte Carlo method: if we choose
œà = œï, the two densities in (3.14) cancel and the Y j are i.i.d. copies of X; for this
case, the method is identical to basic Monte Carlo estimation. The usefulness of
importance sampling lies in the fact that we can choose the density œà (and thus the
distribution of the Y j) in order to maximise efÔ¨Åciency.
As for the basic Monte Carlo method, the sample size N can be used to control
the balance between error and computational cost. As N increases, the computational
cost increases but the error of the method decreases.
Proposition 3.23
The importance sampling estimate ZIS
N from (3.14), as computed
by algorithm 3.22, has
bias

ZIS
N

= 0
and
MSE

ZIS
N

= 1
N Var

f (Y) œï(Y)
œà(Y)

= 1
N

Var( f (X)) ‚àíE

f (X)2

1 ‚àíœï(X)
œà(X)

.
(3.15)

86
AN INTRODUCTION TO STATISTICAL COMPUTING
Proof
Using the deÔ¨Ånition of ZIS
N and equation (3.13) we Ô¨Ånd
E

ZIS
N

= E
‚éõ
‚éù1
N
N

j=1
f (Y j) œï(Y j)
œà(Y j)
‚éû
‚é†= E

f (Y) œï(Y)
œà(Y)

= E( f (X))
and thus
bias

ZMC
N

= E

ZIS
N

‚àíE( f (X)) = 0.
For the variance we have
Var

ZIS
N

= Var
‚éõ
‚éù1
N
N

j=1
f (Y j) œï(Y j)
œà(Y j)
‚éû
‚é†= 1
N Var

f (Y) œï(Y)
œà(Y)

.
(3.16)
Rewriting the right-hand side of this equation, we get
Var
 f (Y)œï(Y)
œà(Y)

= E
 f (Y)2œï(Y)2
œà(Y)2

‚àíE
 f (Y)œï(Y)
œà(Y)
2
=

f (y)2œï(y)2
œà(y)2
œà(y) dy ‚àíE( f (X))2
=

f (x)2œï(x)
œà(x)
œï(x) dx ‚àíE( f (X))2,
where the integration variable is changed from y to x in the last line. Transforming
the integral back to an expectation, we get
Var
 f (Y)œï(Y)
œà(Y)

= E

f 2(X) œï(X)
œà(X)

‚àíE( f (X))2
= E

f (X)2
‚àíE( f (X))2 ‚àíE

f (X)2
+ E

f 2(X) œï(X)
œà(X)

= Var( f (X)) ‚àíE

f (X)2

1 ‚àíœï(X)
œà(X)

,
and thus, substituting this expression into (3.16), we get
MSE

ZIS
N

= Var

ZIS
N

+ bias

ZIS
N
2
= 1
N Var

f (Y) œï(Y)
œà(Y)

+ 02
= 1
N

Var( f (X)) ‚àíE

f (X)2

1 ‚àíœï(X)
œà(X)

.
This completes the proof.

MONTE CARLO METHODS
87
By comparing the mean squared error (3.15) for the importance sampling estimate
to the mean squared error (3.8) of the basic Monte Carlo estimate, we see that the
importance sampling method has smaller error than the basic Monte Carlo method
whenever the density œà satisÔ¨Åes the condition
cœà = E

f (X)2

1 ‚àíœï(X)
œà(X)

> 0.
The importance sampling method is efÔ¨Åcient, if both of the following criteria are
satisÔ¨Åed:
(a) The samples Y j can be generated efÔ¨Åciently.
(b) Var( f (Y)œï(Y)/œà(Y)) is small or, equivalently, the constant cœà is large.
To understand how œà and thus the distribution of Y can be chosen to minimise
the variance in the second criterion, we Ô¨Årst consider the extreme case where f œï/œà
is constant: for this choice of œà, the variance of the Monte Carlo estimate is 0 and
therefore there is no error at all! In this case we have
œà(x) = 1
a f (x)œï(x)
(3.17)
for all x where a is the constant value of f œï/œà. We can Ô¨Ånd the value of a by using
the fact that œà is a probability density:
a = a

œà(x) dx =

f (x) œï(x) dx = E( f (X)).
Therefore, in order to choose œà as in (3.17) we have to already have solved the
problem of computing the expectation E( f (X)) and thus we do not get a useful
method for this case. Still, this boundary case offers some guidance: since we get
optimal efÔ¨Åciency if œà is chosen proportional to f œï, we can expect, at least for f ‚â•0,
that we will get good efÔ¨Åciency if we choose œà to be approximately proportional to
the function f œï or even if we choose a distribution such that œà is big wherever | f |
is big.
Example 3.24
Let X be a real-valued random variable and A ‚äÜR. Then the
importance sampling estimate for the probability P(X ‚ààA) = E(1A(X)) is given by
ZIS
N = 1
N
N

j=1
1A(Y j)œï(Y j)
œà(Y j)
where œà is a probability density, satisfying œà(x) > 0 for all points x ‚ààA with
œï(x) > 0, and (Y j) j‚ààN is a sequence of i.i.d. random variables with density œà. Then,

88
AN INTRODUCTION TO STATISTICAL COMPUTING
by proposition 3.23, the mean squared error of the importance sampling estimate for
P(X ‚ààA) is given by
MSE

ZIS
N

= 1
N Var (1A(X)) ‚àí1
N E

1A(X)

1 ‚àíœï(X)
œà(X)

= MSE

ZMC
N

‚àí1
N E

1A(X)

1 ‚àíœï(X)
œà(X)

.
We see that the importance sampling method will have a smaller mean squared error
than basic Monte Carlo estimation, if we can choose the density œà such that œà > œï
on the set A.
For the choice of the sample size N in algorithm 3.22, the same considerations
apply as for basic Monte Carlo estimation: an estimate for the mean squared error
MSE

ZIS
N

can be computed together with ZIS
N itself, by using the following relation
from proposition 3.23. The estimate ZIS
N has mean squared error
MSE

ZIS
N

= 1
N Var
 f (Y)œï(Y)
œà(Y)

‚âàÀÜœÉ 2
N ,
(3.18)
where
ÀÜœÉ 2 =
1
N ‚àí1
N

j=1
 f (Y j)œï(Y j)
œà(Y j)
‚àíZIS
N
2
(3.19)
is the sample variance of the weighted samples generated to compute ZIS
N . As for the
basic Monte Carlo method, the relation (3.18) can also be solved for N to determine
the value of N required to achieve a given level of error.
3.3.2
Antithetic variables
The antithetic variables method (also called antithetic variates method) reduces the
variance and thus the error of Monte Carlo estimates by using pairwise dependent
samples X j instead of the independent samples used in basic Monte Carlo estimation.
For illustration, we Ô¨Årst consider the case N = 2: assume that X and X‚Ä≤ are identi-
cally distributed random variables, which are not independent. As for the independent
case we have
E
 f (X) + f (X‚Ä≤)
2

= E( f (X)) + E

f (X‚Ä≤)

2
= E( f (X)),
but for the variance we get
Var
 f (X) + f (X‚Ä≤)
2

= Var( f (X)) + 2 Cov

f (X), f (X‚Ä≤)

+ Var

f (X‚Ä≤)

4
= 1
2Var( f (X)) + 1
2Cov

f (X), f (X‚Ä≤)

.

MONTE CARLO METHODS
89
Compared with the expression for the variance in the independent case, an additional
covariance term 1
2Cov( f (X), f (X‚Ä≤)) is present. The idea of the antithetic variables
method is to construct X and X‚Ä≤ such that Cov( f (X), f (X‚Ä≤)) is negative, thereby
reducing the total variance.
There are many methods available to construct pairs of samples X, X‚Ä≤ which
have the required properties for use in the antithetic variables method (one possible
construction is given below). Once we have found a way to construct such pairs of a
given distribution, we can use the following approximation.
DeÔ¨Ånition 3.25
Let X be a random variable and let f be a function such that
f (X) ‚ààR. Furthermore, let X‚Ä≤ be another random variable, with the same distribution
as X. Then the antithetic variables estimate for E( f (X)) with sample size N ‚àà2N
is given by
ZAV
N = 1
N
N/2

k=1

f (Xk) + f (X‚Ä≤
k)

(3.20)
where (Xk, X‚Ä≤
k) are i.i.d. copies of (X, X‚Ä≤).
In the deÔ¨Ånition, 2N denotes the set of even integers. Since each term in the sum
contributes two terms, f (Xk) and f (X‚Ä≤
k), to the estimate ZAV
N , the sum in (3.20) ranges
only from 1 to N/2. When applying the algorithm, X and X‚Ä≤ will be dependent. For
Ô¨Åxed k, the pair (Xk, X‚Ä≤
k) has the same dependence structure as (X, X‚Ä≤), but Xk and
X‚Ä≤
k are independent of X j and X‚Ä≤
j when j Ã∏= k. The pairs (X, X‚Ä≤) and (Xk, X‚Ä≤
k) are
called antithetic pairs. We can write the resulting method as the following algorithm.
Algorithm 3.26
(antithetic variables)
input:
a function f
N ‚ààN even
randomness used:
i.i.d. copies (Xk, X‚Ä≤
k) of (X, X‚Ä≤)
output:
the estimate ZAV
N for E( f (X))
1: s ‚Üê0
2: for k = 1, 2, . . . , N/2 do
3:
generate (Xk, X‚Ä≤
k)
4:
s ‚Üês + f (Xk) + f (X‚Ä≤
k)
5: end for
6: return s/N
As for the Monte Carlo methods discussed so far, the running time of algorithm
3.26 is proportional to N. The loop in line 2 of the algorithm has only N/2 iterations,
compared with N iterations for the basic Monte Carlo method, but in each iteration
two terms are added to the cumulative sum s and thus the Ô¨Ånal result is still the sum

90
AN INTRODUCTION TO STATISTICAL COMPUTING
of N terms. For this reason, the computational cost of the antithetic variables method
is usually very similar to the computational cost of the corresponding basic Monte
Carlo algorithm.
Proposition 3.27
Let X and X‚Ä≤ be two random variables with the same distribu-
tion and let œÅ = Corr( f (X), f (X‚Ä≤)). Then the antithetic variables estimate ZAV
N for
E( f (X)) satisÔ¨Åes
bias

ZAV
N

= 0
and
MSE(ZAV
N ) = 1
N Var( f (X))(1 + œÅ).
(3.21)
Proof
The expectation of ZAV
N is given by
E

ZAV
N

= 1
N
N/2

k=1
E

f (Xk) + f (X‚Ä≤
k)

= 1
N ¬∑ N
2 ¬∑ 2E( f (X)) = E( f (X)).
Thus the estimate ZAV
N is unbiased and the mean squared error of ZAV
N coincides with
the variance.
For the variance we can use the fact that the pairs (X j, X‚Ä≤
j) and (Xk, X‚Ä≤
k) are
independent for j Ã∏= k. This gives
Var

ZAV
N

= 1
N 2
N/2

j,k=1
Cov

f (X j) + f (X‚Ä≤
j)

,

f (Xk) + f (X‚Ä≤
k)

= 1
N 2
N/2

k=1

Var ( f (Xk)) + Var

f (X‚Ä≤
k)

+ 2 Cov

f (Xk), f (X‚Ä≤
k)

= 1
N 2 ¬∑ N
2 ¬∑

Var( f (X)) + Var

f (X‚Ä≤)

+ 2 Cov

f (X), f (X‚Ä≤)

= 1
N

Var( f (X)) + Cov

f (X), f (X‚Ä≤)

.
Finally, since
œÅ = Corr

f (X), f (X‚Ä≤)

=
Cov

f (X), f (X‚Ä≤)

‚àöVar( f (X))Var ( f (X‚Ä≤)) = Cov

f (X), f (X‚Ä≤)

Var( f (X))
,
we Ô¨Ånd
MSE

eAV
N

= Var

eAV
N

= 1
N (Var( f (X)) + Var( f (X))œÅ) .

MONTE CARLO METHODS
91
This completes the proof.
Comparing equation (3.8) and equation (3.21) for the mean squared error of the
basic Monte Carlo estimate and of the antithetic variables estimate, respectively, we
see that the antithetic variables method has smaller mean squared error than the basic
Monte Carlo method if and only if œÅ < 0.
In order to apply the antithetic variables method, we need to construct the pairs
(X, X‚Ä≤) of samples such that both values have the correct distribution but, at the
same time, f (X) and f (X‚Ä≤) are negatively correlated. There is no generic method to
construct such antithetic pairs; here will restrict ourselves to discussing ideas which
can help to construct antithetic pairs in speciÔ¨Åc cases.
A Ô¨Årst idea for constructing antithetic pairs, if the distribution of X is symmetric,
is to use X‚Ä≤ = ‚àíX. The correlation Corr( f (X), f (X‚Ä≤)) depends on the function f ,
but in many cases we have Corr( f (X), f (‚àíX)) < 0. This idea is illustrated in the
following example and, in a much more complex situation, in Section 6.5.2.
Example 3.28
Let X ‚àºN(0, 1) and consider the problem of estimating the prob-
ability p = P(X ‚àà[1, 3]) = E(1[1,3](X)). Since the distribution of X is symmetric,
we can try to use (X, X‚Ä≤) with X‚Ä≤ = ‚àíX as an antithetic pair. For this choice we Ô¨Ånd
Cov

1[1,3](X), 1[1,3](‚àíX)

= E

1[1,3](X)1[1,3](‚àíX)

‚àíE

1[1,3](X)

¬∑ E

1[1,3](‚àíX)

= 0 ‚àíp ¬∑ p
= ‚àíp2,
since the two values 1[1,3](X) and 1[1,3](‚àíX) cannot be non-zero simultaneously. As
in example 3.18 we Ô¨Ånd
Var

1[1,3](X)

= Var

1[1,3](‚àíX)

= p(1 ‚àíp)
and thus
œÅ = Corr

1[1,3](X), 1[1,3](X‚Ä≤)

=
Cov

1[1,3](X), 1[1,3](X‚Ä≤)


Var

1[1,3](X)

Var

1[1,3](X‚Ä≤)

= ‚àí
p
1 ‚àíp .

92
AN INTRODUCTION TO STATISTICAL COMPUTING
Thus, by the result of proposition 3.27, the mean squared error of the antithetic
variables estimate ZAV
N for this example, compared with the error for the basic Monte
Carlo method, is
MSE

ZAV
N

= (1 + œÅ)MSE

ZMC
N

=

1 ‚àí
p
1 ‚àíp

MSE

ZMC
N

.
By computing an estimate for p we Ô¨Ånd p ‚âà0.16 and œÅ = ‚àíp/(1 ‚àíp) ‚âà‚àí0.19.
Thus, in this example the mean squared error of ZAV
N is only about 81% of the error
for ZMC
N .
Another method for generating antithetic pairs can be applied if X is one-
dimensional and if we can generate samples of X using the inverse transform method
from Section 1.3: let F be the distribution function of X and let U ‚àºU[0, 1]. Then
1 ‚àíU ‚àºU[0, 1] and we can use X = F‚àí1(U) and X‚Ä≤ = F‚àí1(1 ‚àíU) to generate an
antithetic pair. Since the inverse F‚àí1 of the distribution function is monotonically
increasing, X increases as U increases while X‚Ä≤ decreases as U increases. For this
reason we expect X and X‚Ä≤ to be negatively correlated.
Lemma 3.29
Let g: R ‚ÜíR be monotonically increasing and U ‚àºU[0, 1]. Then
Cov (g(U), g(1 ‚àíU)) ‚â§0.
Proof
The proof uses a trick, which is based on the idea of introducing a new
random variable V ‚àºU[0, 1], independent of U. We distinguish two cases: if U ‚â§V
we have g(U) ‚â§g(V ) and g(1 ‚àíU) ‚â•g(1 ‚àíV ). Otherwise, if U > V , we have
g(U) ‚â•g(V ) and g(1 ‚àíU) ‚â§g(1 ‚àíV ). Thus, in both cases we have
(g(U) ‚àíg(V )) (g(1 ‚àíU) ‚àíg(1 ‚àíV )) ‚â§0
and consequently
Cov (g(U), g(1 ‚àíU))
= E (g(U)g(1 ‚àíU)) ‚àíE (g(U)) E (g(1 ‚àíU))
= 1
2E (g(U)g(1 ‚àíU) + g(V )g(1 ‚àíV ) ‚àíg(U)g(1 ‚àíV ) ‚àíg(V )g(1 ‚àíU))
= 1
2E ((g(U) ‚àíg(V )) (g(1 ‚àíU) ‚àíg(1 ‚àíV ))) ‚â§0.
This completes the proof.
If the function f is monotonically increasing, we can apply the lemma to g(u) =
f (F‚àí1(u)). In this case we have
f (X) = f (F‚àí1(U)) = g(U)

MONTE CARLO METHODS
93
and
f (X‚Ä≤) = f

F‚àí1(1 ‚àíU)

= g(1 ‚àíU).
The lemma allows then to conclude Cov( f (X1), f (X2)) ‚â§0. While lemma 3.29 only
guarantees that the variance for the antithetic variables method is smaller or equal
to the variance of standard Monte Carlo estimation, in practice often a signiÔ¨Åcant
reduction of variance is observed.
3.3.3
Control variates
The control variates method is another method to reduce the variance of Monte Carlo
estimates for expectations of the form E( f (X)). The method is based on the following
idea: if we can Ô¨Ånd a ‚Äòsimpler‚Äô function g ‚âàf such that E(g(X)) can be computed
analytically, then we can use our knowledge of E(g(X)) to assist with the estimation
of E( f (X)). In the control variates methods, this is done by rewriting the expectation
of interest as
E( f (X)) = E ( f (X) ‚àíg(X)) + E(g(X)).
Since we know E(g(X)), the Monte Carlo estimation can now be restricted to the
term E( f (X) ‚àíg(X)) and since f (X) ‚âàg(X), the random quantity f (X) ‚àíg(X)
has smaller variance and thus smaller Monte Carlo error than f (X) has on its own.
In this context, the random variable g(X) is called a control variate for f (X).
DeÔ¨Ånition 3.30
Let g be a function such that E(g(X)) is known. Then the control
variates estimate for E( f (X)) is given by
ZCV
N
= 1
N
N

j=1

f (X j) ‚àíg(X j)

+ E(g(X))
where the X j are i.i.d. copies of X.
The algorithm for computing the estimate ZCV
N
is a trivial modiÔ¨Åcation of the
basic Monte Carlo algorithm.
Algorithm 3.31
(control variates)
input:
a function f
a function g ‚âàf such that E(g(X)) is known
N ‚ààN
randomness used:
a sequence (X j) j‚ààN of i.i.d. copies of X

94
AN INTRODUCTION TO STATISTICAL COMPUTING
output:
the estimate ZCV
N for E( f (X))
1: s ‚Üê0
2: for j = 1, 2, . . . , N do
3:
generate X j with the same distribution as X has
4:
s ‚Üês + f (X j) ‚àíg(X j)
5: end for
6: return s/N + E(g(X))
As for the other Monte Carlo algorithms, the sample size N controls the trade-
off between error and computational cost. The computational cost of this algorithm
increases with N, but at the same time the error decreases when N gets larger.
Proposition 3.32
The control variates estimate ZCV
N for E( f (X)) satisÔ¨Åes
bias

ZCV
N

= 0
and
MSE

ZCV
N

= 1
N Var ( f (X) ‚àíg(X)) .
Proof
This result is a direct consequence of proposition 3.14. We have
E

ZCV
N

= E
‚éõ
‚éù1
N
N

j=1

f (X j) ‚àíg(X j)

+ E(g(X))
‚éû
‚é†
= E ( f (X) ‚àíg(X)) + E(g(X))
= E( f (X))
and thus
bias

ZCV
N

= E

ZCV
N

‚àíE( f (X)) = 0.
Using proposition 3.14 again, we Ô¨Ånd the mean squared error as
MSE

ZCV
N

= Var
‚éõ
‚éù1
N
N

j=1

f (X j) ‚àíg(X j)

+ E(g(X))
‚éû
‚é†
= Var
‚éõ
‚éù1
N
N

j=1

f (X j) ‚àíg(X j)

‚éû
‚é†
= 1
N Var ( f (X) ‚àíg(X)) .
This completes the proof.

MONTE CARLO METHODS
95
The control variates method described above is a special case of a more general
method. Using a correlated control variate Y, every random variable Z can be trans-
formed into a new random variable ÀúZ with the same mean but smaller variance. This
technique is described in the following lemma.
Lemma 3.33
Let Z be a random variable with E(Z) = Œº and Var(Z) = œÉ 2. Fur-
thermore, let Y be a random variable with Corr(Y, Z) = œÅ and deÔ¨Åne
ÀúZ = Z ‚àíCov(Y, Z)
Var(Y)
(Y ‚àíE(Y)) .
Then the random variable ÀúZ satisÔ¨Åes E( ÀúZ) = Œº and
Var( ÀúZ) =

1 ‚àíœÅ2
œÉ 2 ‚â§œÉ 2.
Proof
For c ‚ààR deÔ¨Åne
Zc = Z ‚àíc (Y ‚àíE(Y)) .
Then the random variable Zc has expectation
E(Zc) = E(Z) ‚àíc (E(Y) ‚àíE(Y)) = E(Z)
and the variance of Zc is given by
Var(Zc) = Var(Z) ‚àí2cCov(Y, Z) + c2Var(Y).
(3.22)
The value ÀúZ in the statement satisÔ¨Åes ÀúZ = Zc for c = Cov(Y, Z)/Var(Y) and thus
we get
Var( ÀúZ) = Var(Z) ‚àí2Cov(Y, Z)
Var(Y)
Cov(Y, Z) + Cov(Y, Z)2
Var(Y)2
Var(Y)
= Var(Z) ‚àíCov(Y, Z)2
Var(Y)
=

1 ‚àíCorr(Y, Z)2
Var(Z).
This completes the proof.
Lemma 3.33 can, for example, be used to construct improved versions of an
unbiased estimator: if Z is an unbiased estimator for a parameter Œ∏, then
bias( ÀúZ) = E( ÀúZ) ‚àíŒ∏ = E(Z) ‚àíŒ∏ = 0

96
AN INTRODUCTION TO STATISTICAL COMPUTING
and
MSE( ÀúZ) = Var( ÀúZ) < Var(Z) = MSE(Z),
that is ÀúZ is then also an unbiased estimator for Œ∏, but has smaller mean squared error
than Z.
It is easy to check that the value of c used in (3.22) is optimal: the c which
minimises the variance satisÔ¨Åes the condition
0 = d
dcVar(Zc) = ‚àí2 Cov(Y, Z) + 2cVar(Y)
and thus the optimal value of c is given by
c‚àó= Cov(Y, Z)
Var(Y)
.
In practice, the exact covariance between Z and Y is often unknown. From
equation (3.22) we know that it sufÔ¨Åces to have
2c Cov(Y, Z) > c2 Var(Y)
for variance reduction to occur. It is easy to check that this condition is satisÔ¨Åed for
all values of c between 0 and 2 Cov(Z, Y)/Var(Y). Therefore we can replace the
estimator ÀúZ from lemma 3.33 by
Zc = Z ‚àíc (Y ‚àíE(Y))
where c is only an approximation to Cov(Y, Z)/Var(Y), and still expect the estimator
Zc to have smaller variance than Z.
3.4
Applications to statistical inference
In this section we will use a series of examples to illustrate how Monte Carlo methods
can be used to study methods from statistical inference. We will consider point
estimates in Section 3.4.1, conÔ¨Ådence intervals in Section 3.4.2 and hypothesis tests
in Section 3.4.3.
In statistical inference problems, we have observed data x = (x1, . . . , xn) and
our aim is to decide which statistical model, typically chosen from a family of
models under consideration, the observed data could have been generated by. More
speciÔ¨Åcally, we consider a family (PŒ∏)Œ∏‚àà of probability distributions, where Œ∏ is the
parameter vector of the models and  is the set of all possible parameter values, and we
assume that the observed data are a sample of a random variable X = (X1, . . . , Xn) ‚àº
PŒ∏, for an unknown parameter value Œ∏ ‚àà. In this context, the random variable X is
called the random sample.

MONTE CARLO METHODS
97
3.4.1
Point estimators
A point estimator (or an estimator in short) for the parameter Œ∏ is any function of the
random sample X with values in . Typically, we write ÀÜŒ∏ = ÀÜŒ∏(X) = ÀÜŒ∏(X1, . . . , Xn)
to denote an estimator for a parameter Œ∏. The value of the estimator for the observed
data x, that is ÀÜŒ∏(x) is called a point estimate (or an estimate) for Œ∏.
While the deÔ¨Ånition of an estimator does not refer to the ‚Äòtrue‚Äô value Œ∏, useful
estimators will have the property that ÀÜŒ∏ is close to Œ∏. How close the estimate is to
the exact value determines the quality of an estimator. This is measured by quantities
like the bias and the standard error. In simple cases, for example when the data
consist of independent, normally distributed values or in the limit n ‚Üí‚àû, it is
possible to determine the bias and standard error of estimators analytically. In more
complicated cases, exact expressions for the bias and the standard error are no longer
available. Here we will illustrate how Monte Carlo estimation can be used in these
cases, to obtain numerical approximations for the bias and the standard error of an
estimator.
3.4.1.1
Monte Carlo estimates of the bias
From deÔ¨Ånition 3.9 we know that the bias of an estimator ÀÜŒ∏ = ÀÜŒ∏(X) for a parameter Œ∏
is given by
biasŒ∏( ÀÜŒ∏) = E
 ÀÜŒ∏(X)

‚àíŒ∏
for all Œ∏ ‚àà. For given values of Œ∏, we can use basic Monte Carlo estimation to
approximate the expection E( ÀÜŒ∏(X)). The resulting Monte Carlo estimate for the bias
is given by

biasŒ∏( ÀÜŒ∏) = 1
N
N

j=1
ÀÜŒ∏(X( j)) ‚àíŒ∏,
where the samples X( j) = (X( j)
1 , . . . , X( j)
n ) are i.i.d. copies of X, using the given
parameter value Œ∏.
While this procedure is a simple application of Monte Carlo estimation as
described in proposition 3.14, some care is needed to not confuse the two conceptual
levels characterised by the size n of samples, and the number N of samples used
in the Monte Carlo estimate: while ÀÜŒ∏ can be computed from a sample of size n, we
need to generate N samples, that is n ¬∑ N random values, to compute the estimate ÀÜŒº.
Similarly, while ÀÜŒ∏ is an estimator for Œ∏, the value 
biasŒ∏( ÀÜŒ∏) is an estimate for the bias
of an estimator.
Of course, the true value of the parameter Œ∏ is normally not known, but we can
systematically compute 
bias(Œ∏) for a range of different Œ∏ to get, for example, an
approximate upper bound for the bias of an estimator. This approach is illustrated in
the following example.

98
AN INTRODUCTION TO STATISTICAL COMPUTING
Example 3.34
Let œÅ ‚àà[‚àí1, 1] and X, Œ∑ ‚àºN(0, 1) and deÔ¨Åne
Y = œÅX +

1 ‚àíœÅ2 Œ∑.
Then
Cov(X, Y) = Cov(X, œÅX +

1 ‚àíœÅ2 Œ∑)
= œÅCov(X, X) +

1 ‚àíœÅ2Cov(X, Œ∑)
= œÅVar(X)
= œÅ,
since X and Œ∑ are independent. Using independence again, we Ô¨Ånd
Var(Y) = Var

œÅX +

1 ‚àíœÅ2 Œ∑

= œÅ2Var(X) + (1 ‚àíœÅ2)Var(Œ∑)
= œÅ2 + 1 ‚àíœÅ2
= 1.
Consequently,
Corr(X, Y) =
Cov(X, Y)
‚àöVar(X)Var(Y) =
œÅ
‚àö
1 ¬∑ 1
= œÅ.
The correlation between any two random variables X and Y can be estimated by the
sample correlation
ÀÜœÅ(X, Y) =
n
i=1(Xi ‚àí¬ØX)(Yi ‚àí¬ØY)
n
i=1(Xi ‚àí¬ØX)2 n
i=1(Yi ‚àí¬ØY)2
(3.23)
where ¬ØX = 1
n
n
i=1 Xi, ¬ØY = 1
n
n
i=1 Yi and (Xi, Yi), i = 1, 2, . . . , n is a sequence of
i.i.d. copies of (X, Y). Thus, we can use ÀÜœÅ(X, Y) as an estimator for œÅ. Our aim in
this example is to determine the bias of this estimator.
For given œÅ, the estimator 
biasœÅ( ÀÜœÅ) for the bias of the estimator ÀÜœÅ from equation
(3.23) can be computed using the following steps:
1: s ‚Üê0
2: for j = 1, 2, . . . , N do
3:
generate X( j)
1 , . . . , X( j)
n
‚àºN(0, 1)
4:
generate Œ∑( j)
1 , . . . , Œ∑( j)
n
‚àºN(0, 1)
5:
let Y ( j)
i
= œÅX( j)
i
+

1 ‚àíœÅ2 Œ∑( j)
i
for i = 1, 2, . . . , n
6:
compute ÀÜœÅ( j) = ÀÜœÅ(X( j), Y ( j)) using (3.23)

MONTE CARLO METHODS
99
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè‚óè
‚óè
‚óè
‚óè‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè‚óè
‚óè
‚óè
‚óè‚óè
‚óè‚óè
‚óè
‚óè
‚óè
‚óè
‚àí1.0
‚àí0.5
0.0
0.5
1.0
‚àí0.02
0.00
0.01
0.02
œÅ
Estimated bias
Figure 3.2
The estimated bias of the sample correlation (3.23) when estimating the
correlation œÅ. The circles denote Monte Carlo estimates for the bias, for different
values of œÅ, obtained using the method described in example 3.34. The solid line is
obtained by Ô¨Åtting a smooth curve to the Monte Carlo estimates.
7:
s ‚Üês + ÀÜœÅ( j)
8: end for
9: return s/N ‚àíœÅ
Finally, this code can be run repeatedly for different values of œÅ ‚àà[‚àí1, +1] to get
the dependence of the bias on the parameter œÅ. The result of one run of this procedure
is shown in Figure 3.2.
3.4.1.2
Monte Carlo estimates of the standard error
From deÔ¨Ånition 3.10 we know that the standard error of an estimator ÀÜŒ∏ = ÀÜŒ∏(X) is
given by
seŒ∏( ÀÜŒ∏) = stdevŒ∏
 ÀÜŒ∏(X)

=

VarŒ∏
 ÀÜŒ∏(X)

for all Œ∏ ‚àà. While this expression does not exactly have the form E( f (x)) consid-
ered for Monte Carlo estimates in this chapter, we can still us a Monte Carlo approach
to estimating the standard error: for given Œ∏, we can estimate seŒ∏( ÀÜŒ∏) as
seŒ∏( ÀÜŒ∏) =




1
N ‚àí1
N

j=1

ÀÜŒ∏(X( j)) ‚àíÀÜŒ∏(¬∑)
2
,

100
AN INTRODUCTION TO STATISTICAL COMPUTING
where
ÀÜŒ∏(¬∑) = 1
N
N

j=1
ÀÜŒ∏(X( j))
and X( j) for j = 1, 2, . . . , N are i.i.d. copies of X and in the formula for seŒ∏( ÀÜŒ∏) we
use the standard estimate for the variance.
3.4.2
ConÔ¨Ådence intervals
If the set  of all possible parameter values is one-dimensional, that is if  ‚äÜR,
we can draw inference about the unknown parameter Œ∏ using conÔ¨Ådence intervals.
ConÔ¨Ådence intervals serve a similar purpose as point estimators but, instead of return-
ing just one ‚Äòplausible‚Äô value of the parameter, they determine a range of possible
parameter values, chosen large enough so that the true parameter value lies inside the
range with high probability.
DeÔ¨Ånition 3.35
A conÔ¨Ådence interval with conÔ¨Ådence coefÔ¨Åcient 1 ‚àíŒ± for a
parameter Œ∏ is a random interval [U, V ] ‚äÇR where U = U(X) and V = V (X) are
functions of the random sample X = (X1, . . . , Xn), such that
PŒ∏ (Œ∏ ‚àà[U(X), V (X)]) ‚â•1 ‚àíŒ±
(3.24)
for all Œ∏ ‚àà. The subscript Œ∏ on the probability P indicates that the random sam-
ple X = (X1, . . . , Xn), for the purpose of computing the probability in (3.24), is
distributed according to the distribution with parameter Œ∏.
It is important to note that in equation (3.24) the interval [U, V ] is random,
since it depends on the random sample X, but the value Œ∏ is not. The usefulness of
conÔ¨Ådence intervals lies in the fact that equation (3.24) holds for all possible values
of Œ∏ simultaneously. Thus, even without knowing the true value of Œ∏, we can be
certain that the relation (3.24) holds and for given data x we can use [U(x), V (x)] as
an interval estimate for Œ∏.
In many cases, a conÔ¨Ådence interval for a parameter Œ∏ can be constructed by
considering a point estimator ÀÜŒ∏(X) for Œ∏ and then choosing the boundaries of the
conÔ¨Ådence interval as U(X) = ÀÜŒ∏(X) ‚àíŒµ and V (X) = ÀÜŒ∏(X) + Œµ for an appropriate
value Œµ > 0. In this case, the condition (3.24) can be written as
PŒ∏
 ÀÜŒ∏ ‚àíŒ∏ ‚àà[‚àíŒµ, Œµ]

‚â•1 ‚àíŒ±
(3.25)
and, if the distribution of ÀÜŒ∏ ‚àíŒ∏ is known, this relation can be used to choose the
value Œµ. This approach is illustrated in the following example.

MONTE CARLO METHODS
101
Example 3.36
Let X1, . . . , X N ‚àºN(Œº, œÉ 2) be i.i.d. with a known variance œÉ 2 and
assume that we want to construct the conÔ¨Ådence interval for the unknown mean Œº.
As the centre of the conÔ¨Ådence interval we choose the estimator
ÀÜŒº = ÀÜŒº(X) =
n

i=1
Xi/n
from example 3.13. As a sum of independent, normally distributed random variables,
ÀÜŒº is itself normally distributed, and computing the mean and variance as in exam-
ple 3.13, we Ô¨Ånd ÀÜŒº ‚àíŒº ‚àºN(0, œÉ 2/n). Denoting the CDF of the standard normal
distribution by 
, we get
PŒº
 ÀÜŒ∏ ‚àíŒ∏ ‚àà[‚àíŒµ, Œµ]

= PŒº
	 ÀÜŒ∏ ‚àíŒ∏
œÉ/‚àön ‚àà

‚àí
Œµ
œÉ/‚àön ,
Œµ
œÉ/‚àön

= 
Œµ‚àön
œÉ

‚àí

‚àíŒµ‚àön
œÉ

= 2
Œµ‚àön
œÉ

‚àí1.
In order for the condition (3.25) to be satisÔ¨Åed, we need to choose Œµ such that
2
Œµ‚àön
œÉ

‚àí1 ‚â•1 ‚àíŒ±
or, equivalently,
Œµ ‚â•œÉ
‚àön ¬∑ 
‚àí1 
1 ‚àíŒ±
2

= œÉqŒ±
‚àön
holds, where we use qŒ± = 
‚àí1(1 ‚àíŒ±/2). Using the smallest valid choice of Œµ, we
Ô¨Ånd
I(X) =

ÀÜŒº(X) ‚àíqŒ±œÉ
‚àön , ÀÜŒº(X) + qŒ±œÉ
‚àön

as a conÔ¨Ådence interval for Œº. Commonly used values for qŒ± are q0.1 ‚âà1.64, q0.05 ‚âà
1.96 and q0.01 ‚âà2.58, corresponding to conÔ¨Ådence coefÔ¨Åcients of 90%, 95% and
99%, respectively.
Example 3.37
If, in the situation of example 3.36, the variance œÉ is not known, the
interval
I(X) =

ÀÜŒº(X) ‚àípn,Œ± ÀÜœÉ
‚àön , ÀÜŒº(X) + pn,Œ± ÀÜœÉ
‚àön

,
(3.26)

102
AN INTRODUCTION TO STATISTICAL COMPUTING
where ÀÜœÉ is given by
ÀÜœÉ 2 =
1
n ‚àí1
n

i=1
(Xi ‚àíÀÜŒº(X))2 ,
can be used as a conÔ¨Ådence interval for the mean. A standard result from statistics
shows that pn,Œ± can be chosen as the (1 ‚àíŒ±/2)-quantile of Student‚Äôs t-distribution
with n ‚àí1 degrees of freedom, in order for this conÔ¨Ådence interval to be exact.
If the Xi are not normally distributed, theoretical analysis becomes difÔ¨Åcult and,
in particular for small n, often only approximate conÔ¨Ådence intervals can be derived.
Monte Carlo estimates can be used, both to assist with the construction of conÔ¨Ådence
intervals and to assess the conÔ¨Ådence coefÔ¨Åcient of a given conÔ¨Ådence interval.
The underlying idea for both of these approaches is, following equation (3.4), to
approximate the expectation in (3.24) as
PŒ∏ (Œ∏ ‚àà[U, V ]) ‚âà1
N
N

j=1
1[U ( j),V ( j)](Œ∏),
(3.27)
where U ( j) = U(X( j)), V ( j) = V (X( j)), and the vectors X( j) = (X( j)
1 , . . . , X( j)
n ) for
j = 1, 2, . . . , N are i.i.d. copies of X = (X1, . . . , Xn). Since equation (3.24) is
required to hold for all Œ∏ ‚àà, we have to compute the value of the approxima-
tion (3.27) for a representative sample of parameter values Œ∏.
Example 3.38
If the data X do not consist of independent, normally distributed
samples, the conÔ¨Ådence interval for the mean given by (3.26) in example 3.37 is no
longer exact. In such a situation, we can use Monte Carlo estimation to estimate the
resulting conÔ¨Ådence coefÔ¨Åcient.
Here, we consider the case where X1, . . . , Xn are independent and Poisson-
distributed with parameter Œª. Since the mean of the Pois(Œª) distribution is Œª, we need
to estimate the probability PŒª(U ‚â§Œª ‚â§V ), where U and V are the boundaries of the
conÔ¨Ådence interval (3.26). A Monte Carlo estimate for this probability, for given Œª,
can be obtained by the following algorithm.
1: k ‚Üê0
2: for j = 1, 2, . . . , N do
3:
generate X1, . . . , Xn ‚àºPois(Œª)
4:
ÀÜŒº ‚ÜêN
i=1 Xi/n
5:
ÀÜœÉ ‚Üê
n
i=1(Xi ‚àíÀÜŒº)2/(n ‚àí1)
6:
U ‚ÜêÀÜŒº ‚àípn,Œ± ÀÜœÉ/‚àön
7:
V ‚ÜêÀÜŒº + pn,Œ± ÀÜœÉ/‚àön
8:
if U ‚â§Œª ‚â§V then
9:
k ‚Üêk + 1

MONTE CARLO METHODS
103
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè‚óè‚óè‚óè‚óè‚óè‚óè
‚óè‚óè‚óè‚óè‚óè‚óè‚óè
‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
Œª
Confidence coefficient
Figure 3.3
Estimated conÔ¨Ådence coefÔ¨Åcients for the conÔ¨Ådence interval (3.26) with
Œ± = 5%, when the data are Pois(Œª) distributed, for different values of Œª. The con-
Ô¨Ådence coefÔ¨Åcients are estimated using Monte Carlo estimates, as described in
example 3.38. The plot shows that for Poisson-distributed data, in particular when Œª
is small, the conÔ¨Ådence coefÔ¨Åcient is much smaller than 95%. This indicates that the
conÔ¨Ådence interval (3.26), designed for normally distributed data, is too small for
data following a Poisson distribution.
10:
end if
11: end for
12: return k/N
The above algorithm determines the probability that the conÔ¨Ådence interval covers
the mean for Ô¨Åxed Œª. Running this algorithm repeatedly, we can systematically
estimate PŒª(U ‚â§Œª ‚â§V ) for a range of Œª. The result of such an estimation, for
Œ± = 5%, is shown in Figure 3.3. The Ô¨Ågure clearly shows that the interval given in
(3.26) is not a 95% conÔ¨Ådence interval for Poisson-distributed values. In particular, for
small parameter values, the probability of the interval covering the actual parameter
value is very small. Thus, to derive an acceptable conÔ¨Ådence interval for the parameter
of a Poisson distribution, the interval (3.26) needs to be enlarged. A more detailed
Monte Carlo analysis could be used to derive approximate bounds for such improved
conÔ¨Ådence intervals.
3.4.3
Hypothesis tests
In hypothesis testing, inference about an unknown parameter is restricted to the
question of whether or not the parameter satisÔ¨Åes a given ‚Äòhypothesis‚Äô H0. Such a
hypothesis about the parameter Œ∏ could, for example, be a statement like ‚ÄòŒ∏ = 0‚Äô or
‚ÄòŒ∏ > 0‚Äô. The alternative hypothesis, that is the hypothesis that Œ∏ does not satisfy H0,
is denoted by H1.

104
AN INTRODUCTION TO STATISTICAL COMPUTING
While the dichotomy between H0 and H1 is symmetric, it transpires that in most
situations any given statistical test can only determine for one of the hypotheses
whether it is likely to be true, whereas the other hypothesis can only be shown to be
likely to be wrong. Traditionally the names are chosen such that H0 is the hypothesis
which can only be disproved (called the null hypothesis) and H1 is the hypothesis
which can be proved. The two possible outcomes of a statistical test are then ‚ÄòH0 has
been rejected‚Äô and ‚ÄòH0 has not been rejected‚Äô.
Example 3.39
Assume that X1, . . . , Xn ‚àºN(Œº, œÉ 2) are i.i.d. with unknown
mean Œº. Furthermore assume that, given one instance x1, . . . , xn ‚ààR of the ran-
dom sample X1, . . . , Xn, we want to test the hypothesis that Œº = 0. In this case, for
example if all the xi are concentrated far away from 0, it is possible to conclude
that the observations xi are not compatible with the hypothesis Œº = 0. In contrast,
even if the observations are clustered around 0, we will never be able to exclude the
possibility that Œº has a value which is only very close to but not identical with 0.
Thus, for this example, we should choose H0 to be the hypothesis Œº = 0 and we
should choose H1 to be the alternative hypothesis Œº Ã∏= 0.
Since the null-hypothesis H0 is a statement about the parameter Œ∏, we can describe
the hypothesis H0 by a subset 0 of the set  of all possible parameter values where
H0 holds.
DeÔ¨Ånition 3.40
A statistical hypothesis test (or statistical test) of size Œ± ‚àà(0, 1)
for the hypothesis H0 = {Œ∏ ‚àà0} for 0 ‚äÜ is given by a function T = T (X) of
the random sample X = (X1, . . . , Xn) together with a set C, such that
PŒ∏

T (X) ‚ààC

‚â§Œ±
(3.28)
for all Œ∏ ‚àà0. The test rejects the hypothesis H0 if and only if T (X) ‚ààC. The
function T is called the test statistic and the set C is called the critical region of
the test.
A statistical test can fail in two different ways: if Œ∏ ‚àà0, the random sample X
could take a value such that T (X) ‚ààC. In this case, the hypothesis H0 is wrongly
rejected despite being true. This is called a type I error. From equation (3.28) we
know PŒ∏(T (X) ‚ààC) ‚â§Œ± for all Œ∏ ‚àà0 and thus the probability of type I errors is
bounded from above by the size Œ± of the test. Conversely, if Œ∏ /‚àà0, it can happen
that T (X) /‚ààC. In this case, the test fails to reject the hypothesis H0, despite it being
wrong. The probability of the corresponding type II error is given by PŒ∏(T (X) /‚ààC)
for all Œ∏ ‚àà \ 0. This probability depends on Œ∏ and can only be expected to be
small if the parameter value Œ∏ is ‚ÄòsufÔ¨Åciently far away‚Äô from 0.
The rÀÜole of the parameter Œ± is to allow for rare, untypical behaviour of the random
sample X. If H0 holds and X shows typical behaviour, the null hypothesis H0 will
not be wrongly rejected. But in rare cases, with probability less than Œ±, the random
behaviour of X will be such that H0 is wrongly rejected, that is such that a type I error

MONTE CARLO METHODS
105
occurs. By choosing the value of Œ±, a trade-off between accuracy and sensitivity can
be made: smaller values of Œ± lead to reduced probability of type I errors, but at the
same time the test will become less and less likely to reject H0 and the probability of
type II errors increases.
In many cases the relation (3.28) can only be proven (or only holds) for large
values of n while for small values of n the real signiÔ¨Åcance level of the test will not
be known exactly.
Example 3.41
The skewness
Œ≥ = E
	 X ‚àíŒº
œÉ
3
= E

(X ‚àíŒº)3
œÉ 3
of a random variable with mean Œº and standard deviation œÉ can be estimated by
ÀÜŒ≥n =
1
n
n
i=1(Xi ‚àí¬ØX)3
 1
n
n
i=1(Xi ‚àí¬ØX)23/2 ,
where X1, X2, . . . , Xn are i.i.d. copies of X and ¬ØX is the average of the Xi. If
X ‚àºN(Œº, œÉ 2), then Œ≥ = 0 and one can show that
 n
œÉ ÀÜŒ≥n ‚àí‚ÜíN(0, 1)
(3.29)
as n ‚Üí‚àû.
Assume that we want to construct a test for the null hypothesis H0 that X is
normally distributed with variance œÉ 2. As a consequence of (3.29), for large n, we
can use the test statistic T = ‚àön/œÉ | ÀÜŒ≥n| and the critical region
C = (1.96, ‚àû) ‚äÜR
to construct a test of size Œ± = 5%: We reject H0 if T ‚ààC, that is if | ÀÜŒ≥n| ‚â•1.96‚àöœÉ/n.
One problem with the test constructed in the preceding example is, that the
convergence of the distribution of ‚àön/œÉ ÀÜŒ≥n to N(0, 1) is very slow. For small or
moderate n the probability of wrongly rejecting H0 (type I error) may be bigger
than Œ±.
We can use Monte Carlo estimation to estimate the probability of type I errors of
statistical tests. For simple hypotheses (i.e. if H0 speciÔ¨Åes the distribution of the test
statistic completely), this can be done as follows:
(a) For j = 1, 2, . . . , N, generate samples (X( j)
1 , . . . , X( j)
n ) according to the dis-
tribution given by the null hypothesis.
(b) Compute T ( j) = T (X( j)
1 , . . . , X( j)
n ) for j = 1, 2, . . . , N.

106
AN INTRODUCTION TO STATISTICAL COMPUTING
(c) Check for which percentage of samples H0 is (wrongly) rejected:
P (T ‚ààC) ‚âà1
N
N

j=1
1C(T ( j)).
3.5
Summary and further reading
In this chapter we have learned how Monte Carlo methods can be used to study
statistical models via simulation. We have given special consideration to the relation
between computational cost and accuracy of the results: the error of Monte Carlo
estimates decays proportional to 1/
‚àö
N where N is the number of samples used. We
have also studied several ‚Äòvariance reduction methods‚Äô which allow to reduce the
constant of proportionality in this relation, thus allowing for more efÔ¨Åcient estimates.
Some information about Monte Carlo methods and variance reduction can be found
in Ripley (1987). A more extensive discussion of Monte Carlo methods and variance
reduction is contained in Chapters 3‚Äì5 of Robert and Casella (2004). The historical
origins of the Monte Carlo method are described in Metropolis (1987).
Finally, we illustrated the methods introduced in this chapter by studying problems
in statistical inference using Monte Carlo estimates. While we only touched the basics
of statistical inference, there are many textbooks about statistics available, ranging
from application oriented texts to more theoretical treatments. Details about statistical
inference can, for example, be found in the books Garthwaite et al. (2002) and Casella
and Berger (2001).
Exercises
E3.1
Assume X ‚àºExp(1) and Y ‚àºN(0, X), that is Y is normally distributed with
a random variance. Use Monte Carlo estimation to estimate E(X|Y = 4) and
Var(X|Y = 4).
E3.2
Write a program which, for given N, computes the Monte Carlo estimate from
algorithm 3.8 for the expectation z = E(sin(X)2). For N = 1000, use this
program to repeatedly generate estimates for z and then use these estimates
to assess the accuracy of the Monte Carlo method for the given problem.
Repeat this experiment for N = 10 000 and use the results to illustrate that
the resulting estimates for z are more accurate than the estimates obtained for
N = 1000.
E3.3
Let X ‚àºN(0, 1). Use Monte Carlo estimation to obtain an estimate for
E(cos(X)) to three digits of accuracy.
E3.4
Let X ‚àºN(0, 1) and a ‚â•0. Consider the estimates
pN = 1
N
N

j=1
1(‚àí‚àû,a](X j)

MONTE CARLO METHODS
107
and
ÀúpN = 1
2 +
a
‚àö
2œÄ N
N

j=1
e‚àía2U 2
j /2
for p = P(X ‚â§a), where X j ‚àºN(0, 1) and U j ‚àºU[0, 1] for j ‚ààN are
i.i.d.
(a)
Using equation (3.5) or otherwise, show that ÀúpN ‚Üíp as N ‚Üí‚àû.
(b)
For a = 1, perform a numerical experiment to determine which of the
two estimates has smaller mean squared error.
E3.5
The na¬®ƒ±ve approach to compute the Monte Carlo sample variance ÀÜœÉ 2 from
equation (3.9) is to store all generated samples f (X j) in memory and to
compute the sample variance (3.9) only after all samples are generated. A
disadvantage of this approach is that this requires an amount of memory
which is proportional to N. Describe a way to compute ÀÜœÉ 2 which requires
only a constant (i.e. independent of N) amount of memory.
E3.6
Let X ‚àºN(0, 1) and A = [3, 4] and consider importance sampling estimates
for the probability P(X ‚ààA), using samples Y j from the following sample
distributions:
r Y j ‚àºN(1, 1);
r Y j ‚àºN(2, 1);
r Y j ‚àºN(3.5, 1);
r Y j ‚àºExp(1) + 3.
Each of these four distributions gives rise to a different importance sampling
method. Our aim is to compare the resulting estimates.
(a)
For each of the four methods, determine the sample variance ÀÜœÉ 2 for the
weighted samples, as given in (3.19). Which of these four methods gives
the best results?
(b)
Determine a good estimate for P(X ‚ààA) and discuss the accuracy of
your estimate.
(c)
For each of the four methods, approximately how many samples Y j are
required to reduce the error of the estimate of P(X ‚ààA) to 1%?
E3.7
In this question we study the Monte Carlo estimate 
biasœÅ( ÀÜœÅ) for the bias of
the estimator ÀÜœÅ from (3.23) for the correlation œÅ = Corr(X, Y).
(a)
Implement a function which computes, for given n ‚ààN and œÅ ‚àà[‚àí1, 1],
the estimate 
biasœÅ( ÀÜœÅ) as in example 3.34. Comment on your choice of
the sample size N for the Monte Carlo estimate.

108
AN INTRODUCTION TO STATISTICAL COMPUTING
(b)
For n = 10, create a plot which shows the bias of r(X, Y) as a function
of œÅ.
(c)
Use your results to give an (approximately) unbiased estimate of the
correlation for the following data.
i
1
2
3
4
5
. . .
Xi
0.218
0.0826
0.091
0.095
‚àí0.826
. . .
Yi
0.369
0.715
‚àí1.027
‚àí1.499
1.291
. . .
i
. . .
6
7
8
9
10
Xi
. . .
0.208
0.600
‚àí0.058
0.602
0.620
Yi
. . .
‚àí0.213
‚àí2.400
1.064
‚àí0.367
‚àí1.490
E3.8
Write a program to compute the Monte Carlo estimate (3.27) for the conÔ¨Å-
dence coefÔ¨Åcient of the conÔ¨Ådence interval (3.26). For n = 10 and Œ± = 5%,
using the value p10,0.05 = 2.262157, estimate the conÔ¨Ådence coefÔ¨Åcient when
X1, . . . , X10 ‚àºPois(Œª) for a range of Œª and create a plot of the results. Is
(3.26) a useful conÔ¨Ådence interval for Poisson-distributed data?

4
Markov Chain Monte
Carlo methods
Monte Carlo methods, as discussed in Chapter 3, use a sequence (X j) j‚ààN of i.i.d.
samples as a tool to explore the behaviour of a statistical model. Large numbers
of samples are required and thus these methods depend on our ability to generate
the samples from a given distribution efÔ¨Åciently. Sometimes, when generating these
samples is difÔ¨Åcult, it can be easier to replace the i.i.d. sequence (X j) j‚ààN by a Markov
chain instead. The resulting methods are called Markov Chain Monte Carlo methods.
DeÔ¨Ånition 4.1
A Markov Chain Monte Carlo (MCMC) method for estimating the
expectation E ( f (X)) is a numerical method based on the approximation
E ( f (X)) ‚âà1
N
N

j=1
f (X j),
(4.1)
where (X j) j‚ààN is a Markov chain with the distribution of X as its stationary distri-
bution.
MCMC methods form a generalisation of the Monte Carlo methods discussed in
the previous chapter. Where Monte Carlo methods use independent samples, MCMC
methods use samples which can have direct dependence on the immediately preceding
value. Since the dependence structure of samples is restricted in this way, the samples
in MCMC methods are in some sense still ‚Äòclose to being independent‚Äô.
Compared with the situation of Monte Carlo methods, the theory behind MCMC
methods is more challenging but, at the same time, the resulting methods are often
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

110
AN INTRODUCTION TO STATISTICAL COMPUTING
easier to apply since no extra knowledge about random number generation is required
for MCMC methods.
4.1
The Metropolis‚ÄìHastings method
In order to apply MCMC methods as in deÔ¨Ånition 4.1, we need to be able to construct
Markov chains with a prescribed stationary distribution. The Metropolis‚ÄìHastings
method, presented in this section, is a popular method to solve this problem. The
resulting algorithm is similar to the rejection sampling algorithm: starting from a
nearly arbitrary Markov chain, the Metropolis‚ÄìHastings algorithm generates a new
Markov chain with the required stationary distribution by ‚Äòrejecting‚Äô some of the state
transitions of the original Markov chain.
Here we concentrate solely on the problem of constructing a Markov chain with
a given stationary distribution. Use of the resulting Markov chain in Monte Carlo
estimates will be discussed in Section 4.2. The discussion in this and the following
sections requires basic knowledge about Markov chains; we refer to Section 2.3 for
a short introduction.
4.1.1
Continuous state space
In its general form, the Metropolis‚ÄìHastings method can be used on nearly arbitrary
state spaces. In order to avoid technical complications, we do not give the general
form of the algorithm here but, instead, consider the most important special cases
separately. In this section, we will discuss the case where the state space is S = Rd.
The following section considers the case of Ô¨Ånite or countable state space.
Algorithm 4.2
(Metropolis‚ÄìHastings method for continuous state space)
input:
a probability density œÄ (the target density)
a transition density p: S √ó S ‚Üí[0, ‚àû)
X0 ‚àà

x ‚ààS
 œÄ(x) > 0

randomness used:
independent samples Y j from the transition density p (the proposals)
U j ‚àºU[0, 1] i.i.d.
output:
a sample of a Markov chain X with stationary density œÄ.
As an abbreviation we deÔ¨Åne a function Œ±: S √ó S ‚Üí[0, 1] by
Œ±(x, y) = min
œÄ(y)p(y, x)
œÄ(x)p(x, y), 1

for all x, y ‚ààS with œÄ(x)p(x, y) > 0.
1: for j = 1, 2, 3, . . . do
2:
generate Y j with density p(X j‚àí1, ¬∑)
3:
generate U j ‚àºU[0, 1]

MARKOV CHAIN MONTE CARLO METHODS
111
4:
if U j ‚â§Œ±(X j‚àí1, Y j) then
5:
X j ‚ÜêY j
6:
else
7:
X j ‚ÜêX j‚àí1
8:
end if
9:
output X j
10: end for
The acceptance probability Œ±(x, y) is only deÔ¨Åned for elements x, y ‚ààS which
satisfy œÄ(x)p(x, y) > 0. At a Ô¨Årst glance it seems that the algorithm could fail by
hitting a proposal Y j such that Œ±(X j‚àí1, Y j) is undeÔ¨Åned, but it transpires that this
cannot happen: Assume that we have already found X0, X1, . . . , X j‚àí1. Then we have
œÄ(X j‚àí1) > 0 (it would not have been accepted otherwise in a previous step) and,
given X j‚àí1, the proposal Y j satisÔ¨Åes p(X j‚àí1, Y j) > 0 with probability 1 (it would
not have been proposed otherwise). Consequently, Œ±(X j‚àí1, Y j) is deÔ¨Åned and we can
compute the next value X j.
The purpose of algorithm 4.2 is to generate a Markov chain with stationary
density œÄ, that is ideally we want to achieve X j ‚àºœÄ for all j ‚ààN. The following
results shows that, assuming we have X0 ‚àºœÄ, the algorithm achieves this aim. In
practice, if we could generate samples with density œÄ, we would be able to use basic
Monte Carlo estimation and there would be no need to employ MCMC methods.
Thus, realistically we will not exactly have X0 ‚àºœÄ but the results of Section 4.2
will show that, under mild additional assumptions, the Markov chains generated by
algorithm 4.2 can be used as the basis for MCMC methods, even if the algorithm is
not started with X0 ‚àºœÄ.
Proposition 4.3
The process (X j) j‚ààN constructed in the Metropolis‚ÄìHastings algo-
rithm 4.2 is a Markov chain with stationary density œÄ.
Proof
Assume that X j‚àí1 has density œÄ. Then we have
P(X j ‚ààA) = E

1A(X j)
	
=

S
œÄ(x)

S
p(x, y) (Œ±(x, y)1A(y) + (1 ‚àíŒ±(x, y)) 1A(x)) dy dx
=

S
œÄ(x)

S
p(x, y) Œ±(x, y)1A(y) dy dx
+

S
œÄ(x)

S
p(x, y) (1 ‚àíŒ±(x, y)) 1A(x) dy dx.
From the deÔ¨Ånition of the acceptance probability Œ± we know
œÄ(x)p(x, y)Œ±(x, y) = min (œÄ(x)p(x, y), œÄ(y)p(y, x)) = œÄ(y)p(y, x)Œ±(y, x)

112
AN INTRODUCTION TO STATISTICAL COMPUTING
and thus
P(X j ‚ààA) =

S

S
œÄ(y)p(y, x)Œ±(y, x) 1A(y) dy dx
+

S
œÄ(x)

S
p(x, y) (1 ‚àíŒ±(x, y)) 1A(x) dy dx.
Finally, interchanging the variables x and y in the Ô¨Årst double integral, we get
P(X j ‚ààA) =

S

S
œÄ(x)p(x, y)Œ±(x, y)1A(x) dx dy
+

S
œÄ(x)

S
p(x, y) (1 ‚àíŒ±(x, y)) 1A(x) dy dx
=

S
œÄ(x)

S
p(x, y) (Œ±(x, y)1A(x) + (1 ‚àíŒ±(x, y)) 1A(x)) dy dx
=

S
œÄ(x)

S
p(x, y)1A(x) dy dx
=

S
œÄ(x)1A(x) dx
= P(X j‚àí1 ‚ààA)
for all sets A. This shows that the distributions of X j‚àí1 and X j are the same and thus
that œÄ is a stationary density of the Markov chain.
The result of proposition 4.3 can be slightly improved: it transpires that the
Markov chain constructed by algorithm 4.2, when started with initial distribution œÄ,
is balanced in the sense that
P(X j ‚ààA, X j‚àí1 ‚ààB) = P(X j ‚ààB, X j‚àí1 ‚ààA)
(4.2)
for all sets A, B ‚äÜRd. The condition (4.2), for B = Rd, implies
P(X j ‚ààA) = P(X j ‚ààA, X j‚àí1 ‚ààRd)
= P(X j ‚ààRd, X j‚àí1 ‚ààA)
= P(X j‚àí1 ‚ààA)
for all j ‚ààN and by induction we Ô¨Ånd P(X j ‚ààA) = P(X0 ‚ààA) = œÄ(A). Thus,
condition (4.2) for X0 ‚àºœÄ implies the statement of proposition 4.3. A process which
satisÔ¨Åes condition (4.2) for X j ‚àºœÄ is called œÄ-reversible. Since we do not require
reversibility in the following, we restrict proofs of reversibility to the simpler, discrete
case and only prove stationarity as in proposition 4.3 for the continuous case.

MARKOV CHAIN MONTE CARLO METHODS
113
One big advantage of the Metropolis‚ÄìHastings algorithm is that, as for the rejec-
tion sampling algorithm, the target density œÄ only needs to be known up to a constant:
the only place where œÄ occurs in the algorithm is in the acceptance probability Œ±;
if we only know the product c ¬∑ œÄ but not the value of the constant c, we can still
evaluate the function Œ±, since
Œ±(x, y) = min
œÄ(y)p(y, x)
œÄ(x)p(x, y), 1

= min
c œÄ(y)p(y, x)
c œÄ(x)p(x, y), 1

.
This property of the Metropolis‚ÄìHastings algorithm can, for example, be used in
situations such as the one from Section 4.3 where we need to sample from the density
p(Œ∏ | x) =
p(x | Œ∏)p(Œ∏)

p

x
 ÀúŒ∏
	
p( ÀúŒ∏) d ÀúŒ∏
with an unknown normalisation constant

p

x
 ÀúŒ∏
	
p( ÀúŒ∏) d ÀúŒ∏.
4.1.2
Discrete state space
In this section, we state the Metropolis‚ÄìHastings algorithm for discrete state spaces.
The algorithm for this case is obtained from algorithm 4.2 by replacing densities
with probability weights. Since the situation of discrete state is less technically
challenging, here we prove a slightly better result than we did for the continuous case
in proposition 4.3.
Algorithm 4.4
(Metropolis‚ÄìHastings method for discrete state space)
input:
a probability vector œÄ ‚ààRS (the target distribution)
a transition matrix P = (pxy)x,y‚ààS
X0 ‚ààS with œÄX0 > 0
randomness used:
independent samples Y j from the transition matrix P (the proposals)
U j ‚àºU[0, 1] i.i.d.
output:
a sample of a Markov chain X with stationary distribution œÄ.
As an abbreviation we deÔ¨Åne a function Œ±: S √ó S ‚Üí[0, 1] by
Œ±(x, y) = min
œÄy pyx
œÄx pxy
, 1

(4.3)
for all x, y ‚ààS with œÄx pxy > 0.
1: for j = 1, 2, 3, . . . do
2:
generate Y j with P(Y j = y) = pX j‚àí1,y for all y ‚ààS
3:
generate U j ‚àºU[0, 1]
4:
if U j ‚â§Œ±(X j‚àí1, Y j) then

114
AN INTRODUCTION TO STATISTICAL COMPUTING
5:
X j ‚ÜêY j
6:
else
7:
X j ‚ÜêX j‚àí1
8:
end if
9:
output X j
10: end for
While we could follow the structure of Section 4.1.1 and prove a result in analogy
to proposition 4.3, we will prove a slightly better result in this section, by showing
that the Markov chain constructed by algorithm 4.4 is reversible in the sense of the
following deÔ¨Ånition.
DeÔ¨Ånition 4.5
A time-homogeneous Markov chain X with state space S and
transition matrix P = (pxy)x,y‚ààS satisÔ¨Åes the detailed balance condition, if there is a
probability vector œÄ ‚ààRS with
œÄx pxy = œÄy pyx
for all x, y ‚ààS. In this case we say that the Markov chain X is œÄ-reversible.
The following lemma shows that being œÄ-reversible is indeed a stronger condition
for a Markov chain than having stationary distribution œÄ.
Lemma 4.6
Let X be a œÄ-reversible Markov chain. Then œÄ is a stationary distribu-
tion of X.
Proof
If X satisÔ¨Åes the detailed balance condition for a probability vector œÄ, we
have

x‚ààS
œÄx pxy =

x‚ààS
œÄy pyx = œÄy

x‚ààS
pyx = œÄy
for all y ‚ààS. Thus, œÄ satisÔ¨Åes the condition from equation (2.4) and consequently is
a stationary distribution.
Proposition 4.7
The process (X j) j‚ààN constructed in the Metropolis‚ÄìHastings algo-
rithm 4.4 is a œÄ-reversible Markov chain. In particular, X has stationary distribution œÄ.
Proof
Since X j in the algorithm depends only on X j‚àí1 and on the additional,
independent randomness from Y j and U j, the process (X j) j‚ààN is a Markov chain.
Let Q = (qxy)x,y‚ààS be the transition matrix of this Markov chain, that is
qxy = P(X j = y | X j‚àí1 = x)

MARKOV CHAIN MONTE CARLO METHODS
115
for all x, y ‚ààS. Then we have to show that Q satisÔ¨Åes the detailed balance condition
œÄxqxy = œÄyqyx
(4.4)
for all x, y ‚ààS.
In the case x = y, the relation (4.4) is trivially true; thus we can assume x Ã∏= y.
For the process X to jump from x to y, the proposal Yn must equal y and then the
proposal must be accepted. Since these two events are independent, we Ô¨Ånd
qxy = pxy ¬∑ Œ±(x, y)
and thus
œÄxqxy = œÄx pxy min
œÄy pyx
œÄx pxy
, 1

= min

œÄy pyx, œÄx pxy
	
= œÄy pyx min

1, œÄx pxy
œÄy pyx

= œÄyqyx
for all x, y ‚ààS with œÄx pxy > 0 and œÄy pyx > 0. There are various cases with œÄx pxy =
0 or œÄy pyx = 0; using the that fact the pxy = 0 implies qxy = 0 (since transitions
from x to y are never proposed) it is easy to check that in all of these cases œÄxqxy =
0 = œÄyqyx holds. Thus, equation (4.4) is satisÔ¨Åed for all x, y ‚ààS, the process X is
œÄ-reversible and, by lemma 4.6, œÄ is a stationary distribution of X.
Example 4.8
Let œÄx = 2‚àí|x|/3 for all x ‚ààZ. Then

x‚ààZ
œÄx = 1
3

¬∑ ¬∑ ¬∑ + 1
4 + 1
2 + 1 + 1
2 + 1
4 + ¬∑ ¬∑ ¬∑

= 1
3

1 + 2
‚àû

x=1
2‚àíx

= 1,
that is the inÔ¨Ånite vector œÄ is a probability vector on S = Z. Using algorithm 4.4,
we can easily Ô¨Ånd a Markov chain which has œÄ as a stationary distribution: for the
algorithm, we can choose the transition matrix P for the proposals. For this example
we consider
P(Y j = x + 1 | X j‚àí1 = x) = P(Y j = x ‚àí1 | X j‚àí1 = x) = 1
2

116
AN INTRODUCTION TO STATISTICAL COMPUTING
for all x ‚ààS and all n ‚ààN. This corresponds to pxy = 1/2 if y = x + 1 or y =
x ‚àí1 and pxy = 0 otherwise. From this we can compute the acceptance probabilities
Œ±(x, y):
Œ±(x, y) = min
œÄy pyx
œÄx pxy
, 1

= min
 2‚àí|y|
3
pyx
2‚àí|x|
3
pxy
, 1

= min

2|x|‚àí|y| pyx
pxy
, 1

.
In the Metropolis‚ÄìHastings algorithm, the function Œ±(x, y) is only evaluated for
x = y + 1 and x = y ‚àí1. In either of these cases we have pxy = 1/2 and thus
Œ±(x, y) =

2|x|‚àí|y|
if |y| > |x| and
1
otherwise.
Finally, substituting this transition matrix P and the corresponding function Œ± into
algorithm 4.4 we get the following:
1: for j = 1, 2, 3, . . . do
2:
Let Y j ‚ÜêX j‚àí1 + Œµ j where Œµ j ‚àºU{‚àí1, 1}.
3:
generate U j ‚àºU[0, 1]
4:
if U j ‚â§2|X j‚àí1|‚àí|Y j| then
5:
X j ‚ÜêY j
6:
else
7:
X j ‚ÜêX j‚àí1
8:
end if
9: end for
By proposition 4.7, the resulting process X is a Markov chain with stationary
distribution œÄ.
4.1.3
Random walk Metropolis sampling
The random walk Metropolis algorithm discussed in this section is an important
special case of the Metropolis‚ÄìHastings algorithm. It can be considered both for the
continuous and for the discrete case; here we restrict ourselves to the continuous case
and refer to example 4.8 for an illustration of the corresponding discrete case.
The Metropolis‚ÄìHastings method for the case p(x, y) = p(y, x) is called the
Metropolis method. In this case, the expression for the acceptance probability Œ±
simpliÔ¨Åes to
Œ±(x, y) = min
œÄ(y)p(y, x)
œÄ(x)p(x, y), 1

= min
œÄ(y)
œÄ(x), 1


MARKOV CHAIN MONTE CARLO METHODS
117
for all x, y ‚ààS with œÄ(x) > 0 (or œÄy/œÄx for discrete state space). The condition
p(x, y) = p(y, x) is, for example, satisÔ¨Åed when the proposals Y j are constructed as
Y j = X j‚àí1 + Œµ j
where the Œµ j are i.i.d. with a symmetric distribution (i.e. Œµ j has the same distribution
as ‚àíŒµ j). We only state the version of the resulting algorithm for continuous state
space S, the discrete version is found by using a probability vector instead of a
density for the target distribution.
Algorithm 4.9
(random walk Metropolis)
input:
a probability density œÄ: S ‚Üí[0, ‚àû) (the target density)
X0 ‚ààS with œÄ(X0) > 0
randomness used:
an i.i.d. sequence (Œµ j) j‚ààN with a symmetric distribution (the increments)
U j ‚àºU[0, 1] i.i.d.
output:
a sample of a Markov chain X with stationary density œÄ.
As an abbreviation we deÔ¨Åne a function Œ±: S √ó S ‚Üí[0, 1] by
Œ±(x, y) = min
œÄ(y)
œÄ(x), 1

(4.5)
for all x, y ‚ààS with œÄ(x) > 0.
1: for j = 1, 2, 3, . . . do
2:
generate Œµ j
3:
let Y j ‚ÜêX j‚àí1 + Œµ j
4:
generate U j ‚àºU[0, 1]
5:
if U j ‚â§Œ±(X j‚àí1, Y j) then
6:
X j ‚ÜêY j
7:
else
8:
X j ‚ÜêX j‚àí1
9:
end if
10: end for
Since algorithm 4.9 is a special case of the general Metropolis‚ÄìHastings algo-
rithm 4.2, we can use proposition 4.3 to see that the output of algorithm 4.9 is a
Markov chain with stationary distribution œÄ, independently of the choice of incre-
ments Œµ j. The results of Section 4.2 can be used to prove convergence of MCMC
methods based on algorithm 4.9. For state space S = Rd, the most common choice
of increments is Œµ j ‚àºN(0, œÉ 2); convergence of the MCMC methods resulting from
this choice of increments is proved in example 4.24.
The proposal variance œÉ 2 can be chosen to maximise efÔ¨Åciency of the method:
if œÉ 2 is small, we have Y j ‚âàX j‚àí1, that is œÄ(Y j) ‚âàœÄ(X j‚àí1) and consequently

118
AN INTRODUCTION TO STATISTICAL COMPUTING
Œ±(X j‚àí1, Y j) ‚âà1. In this case, almost all proposals are accepted, but the algorithm
moves slowly since the increments in each step are small. On the other hand, if œÉ 2
is large, the proposals Y j are widely dispersed and often œÄ(Y j) will be small. In this
case, many proposals are rejected; the process X does not move very often but when
it does, the increment is typically large. The optimal choice of œÉ 2 will be between
these two extremes. This is illustrated in Figure 4.1.
‚àí10
‚àí5
0
5
10
Xj
Xj
Xj
‚àí10
‚àí5
0
5
10
0
1000
2000
3000
4000
5000
‚àí10
‚àí5
0
5
10
j
(a)
(b)
(c)
Figure 4.1
Paths of the random walk Metropolis process from example 4.10, with
N(0, œÉ 2)-distributed increments, for different values of the proposal variance œÉ: (a)
œÉ = 1; (b) œÉ = 6; (c) œÉ = 36.

MARKOV CHAIN MONTE CARLO METHODS
119
Example 4.10
We can use the random walk Metropolis algorithm to generate
samples from the density
œÄ(x) = 1
Z ¬∑
 sin(x)2
x2
if x ‚àà[‚àí3œÄ, 3œÄ] and
0
otherwise,
(4.6)
where Z is the normalisation constant which makes œÄ a probability density. For this
target distribution, the acceptance probabilities Œ±(x, y) from equation (4.5) are found
as
Œ±(x, y) = min
œÄ(y)
œÄ(x), 1

= min
‚éõ
‚éù
1
Z ¬∑ sin(y)2
y2
1[‚àí3œÄ,3œÄ](y)
1
Z ¬∑ sin(x)2
x2
1[‚àí3œÄ,3œÄ](x)
, 1
‚éû
‚é†
= min
x sin(y)
y sin(x)
2
1[‚àí3œÄ,3œÄ](y), 1

for all x, y ‚ààR with œÄ(x) > 0.
In this section we have only argued that the given target density œÄ is a stationary
density for the Markov chain generated by the random walk Metropolis algorithm.
This result is a consequence of proposition 4.3 and does not make any assumptions
on œÄ or on the increments Œµ j. Later, when using the generated Markov chain as
part of a Monte Carlo method in Section 4.2, we will require additional assumptions
to guarantee that the average in the estimate (4.1) converges to the correct value,
even if the Markov chain is not started in stationarity. This will require that the
increments Œµ j are large enough for the process to move freely within the region of
value typically taken by the target distribution. For this reason, the random walk
Metropolis‚ÄìHastings method will often be inefÔ¨Åcient if œÄ has several isolated max-
ima, and the method works best if the target density has just one connected region of
high probability.
4.1.4
The independence sampler
Another special case of the Metropolis‚ÄìHastings algorithm is obtained by choosing
the proposals Y j independently of X j‚àí1, that is by using a transition density of the
form p(x, y) = p(y).
Algorithm 4.11
(independence sampler)
input:
a probability density œÄ ‚ààRS (the target density)
X0 ‚ààS

120
AN INTRODUCTION TO STATISTICAL COMPUTING
randomness used:
an i.i.d. sequence (Y j) j‚ààN with density p (the proposals)
U j ‚àºU[0, 1] i.i.d.
output:
a sample of a Markov chain X with stationary density œÄ.
As an abbreviation we deÔ¨Åne a function Œ±: S √ó S ‚Üí[0, 1] by
Œ±(x, y) = min
œÄ(y)p(x)
œÄ(x)p(y), 1

for all x, y ‚ààS with œÄ(x) > 0.
1: for j = 1, 2, 3, . . . do
2:
generate Y j ‚àºp
3:
generate U j ‚àºU[0, 1]
4:
if U j ‚â§Œ±(X j‚àí1, Y j) then
5:
X j ‚ÜêY j
6:
else
7:
X j ‚ÜêX j‚àí1
8:
end if
9: end for
While the proposals Y j in this algorithm are independent, the X j are still depen-
dent, since the acceptance probability Œ±(X j‚àí1, Y j) for X j depends on the value of
X j‚àí1. The algorithm is a special case of the general Metropolis‚ÄìHastings method
from algorithm 4.2 and by proposition 4.3 the generated Markov chain has stationary
density œÄ.
The resulting method resembles the rejection sampling method from algorithm
1.22. When we use rejection sampling to generate (independent) samples with
density œÄ from proposals with density p, we have the condition œÄ(x)/p(x) ‚â§c
for all x and we accept proposals, if the condition
cp(Y j)U j ‚â§œÄ(Y j)
is satisÔ¨Åed. In contrast, the independence sampler generates dependent samples, but
does not require boundedness of œÄ(x)/p(x). For the independence sampler, proposals
are accepted whenever
œÄ(X j)
p(X j) p(Y j)U j ‚â§œÄ(Y j)
holds.
4.1.5
Metropolis‚ÄìHastings with different move types
As a simple generalisation of the Metropolis‚ÄìHastings algorithm, we can split the
transition mechanism into different move types. This generalisation allows more
Ô¨Çexibility in the design of MCMC algorithms. There are two different situations

MARKOV CHAIN MONTE CARLO METHODS
121
where this approach can be employed. First, sometimes an existing MCMC method
can be improved by adding additional move types which allow the algorithm to
explore the state space faster. An example of this approach can be found in example
4.14. Secondly, some MCMC methods are constructed from the ground up as a
combination of different move types, each of which serves a different purpose. We
will see examples of this approach in Sections 4.4 and 4.5.
A Ô¨Ånite or countable set M is used to denote the possible types of move. Instead of
directly generating a proposal Y j with density p(X j‚àí1, ¬∑) as in the basic Metropolis‚Äì
Hastings algorithm, we Ô¨Årst randomly choose a move type m ‚ààM and then generate
Y j with a move-dependent density pm(X j‚àí1, ¬∑). Let Œ≥m(x) denote the probability of
choosing move m when the current state is X j‚àí1 = x. Then, given the value of X j‚àí1,
the distribution of the proposal Y j is given by
P(Y j ‚ààA | X j‚àí1) =

m‚ààM
Œ≥m(X j‚àí1)

A
pm(X j‚àí1, y) dy.
The resulting algorithm follows.
Algorithm 4.12
(Metropolis‚ÄìHastings method with different move types)
input:
a probability density œÄ (the target density)
(Œ≥m(x))m‚ààM,x‚ààS with 
m‚ààM Œ≥m(x) = 1 for all x ‚ààS
transition densities pm: S √ó S ‚Üí[0, ‚àû) for m ‚ààM
X0 ‚àà

x ‚ààS
 œÄ(x) > 0

randomness used:
independent m j ‚ààM with P(m j = m) = Œ≥m(x) for all m ‚ààM
independent Y j from the transition densities pm (the proposals)
U j ‚àºU[0, 1] i.i.d.
output:
a sample of a Markov chain X with stationary density œÄ.
As an abbreviation we deÔ¨Åne Œ±m: S √ó S ‚Üí[0, 1] by
Œ±m(x, y) = min
œÄ(y)Œ≥m(y)pm(y, x)
œÄ(x)Œ≥m(x)pm(x, y), 1

(4.7)
for all x, y ‚ààS and all m ‚ààM.
1: for j = 1, 2, 3, . . . do
2:
generate m j ‚ààM with P(m j = m) = Œ≥m(X j‚àí1) for all m ‚ààM.
3:
generate Y j with density pm j(X j‚àí1, ¬∑)
4:
generate U j ‚àºU[0, 1]
5:
if U j ‚â§Œ±m j(X j‚àí1, Y j) then
6:
X j ‚ÜêY j
7:
else
8:
X j ‚ÜêX j‚àí1
9:
end if
10: end for

122
AN INTRODUCTION TO STATISTICAL COMPUTING
Proposition 4.13
The process (X j) j‚ààN constructed by algorithm 4.12 is a Markov
chain with stationary density œÄ.
Proof
Assume that X j‚àí1 has density œÄ. Then we have
P(X j ‚ààA) =

S
œÄ(x)

m‚ààM
Œ≥m(x)

S
pm(x, y)
(Œ±m(x, y)1A(y) + (1 ‚àíŒ±m(x, y)) 1A(x)) dy dx
=

m‚ààM

S

S
œÄ(x)Œ≥m(x)pm(x, y)
(Œ±m(x, y)1A(y) + (1 ‚àíŒ±m(x, y)) 1A(x)) dy dx.
From the deÔ¨Ånition of the acceptance probabilities Œ±m we get
œÄ(x)Œ≥m(x)pm(x, y)Œ±m(x, y)
= min (œÄ(x)Œ≥m(x)pm(x, y), œÄ(y)Œ≥m(y)pm(y, x))
= œÄ(y)Œ≥m(y)pm(y, x)Œ±m(y, x)
for all x, y ‚ààS and all m ‚ààM. Thus, following the same steps as in the proof of
proposition 4.3, we get
P(X j ‚ààA) =

m‚ààM

S
œÄ(x)Œ≥m(x)

S
pm(x, y)
(Œ±m(x, y)1A(x) + (1 ‚àíŒ±m(x, y)) 1A(x)) dy dx
=

S
œÄ(x)

m‚ààM
Œ≥m(x)

S
pm(x, y) 1A(x) dy dx
=

S
œÄ(x) 1A(x) dx
= P(X j‚àí1 ‚ààA)
for all sets A. This shows that the distributions of X j‚àí1 and X j are the same and thus
œÄ is a stationary density of the Markov chain.
Since the proof of proposition 4.13 considers each transition X j‚àí1 ‚ÜíX j sepa-
rately, the statement stays true if the probabilities Œ≥m(x) for choosing move m depend
on the time j as well as on the location x. In particular, it is possible to choose the
moves solely based on time, for example by applying a pair of moves alternatingly
or, more generally, by having move types M = {0, 1, . . . , k ‚àí1} and then always
choosing move type ( j mod k) at time j. Since proposition 4.13 still applies, œÄ is still
a stationary density even if the move probabilities are time dependent. It transpires

MARKOV CHAIN MONTE CARLO METHODS
123
that, even if every move type on its own would result in a reversible Markov chain,
the combined Markov chain is no longer necessarily reversible.
Example 4.14
Assume that the target distribution œÄ is known to have several
disjoint regions A1, . . . , An of high probability and that œÄ is very small outside these
regions. Such a situation could, for example, occur when œÄ is a mixture distribution
(see deÔ¨Ånition 2.6). In this situation we can augment a random walk Metropolis
algorithm tuned for moving inside these regions by adding a separate move type
for moving between different regions. A very simple example of this approach is as
follows: let M = {1, 2}. For moves of type m = 1 construct proposals as
Y j = X j‚àí1 + Œµ j,
where Œµ j ‚àºN(0, œÉ 2
1 ) and œÉ1 is comparable with the diameter of the regions Ai. For
moves of type m = 2 construct proposals as
Y j = X j‚àí1 + Œ∑ j,
where Œ∑ j ‚àºN(0, œÉ 2
2 ) and œÉ2 is comparable with the distances between the regions
Ai.
Some subtleties occur in the context of the Metropolis‚ÄìHastings method with
different move types: a common choice for move types is to construct moves which
only change a single coordinate of the state X j‚àí1 ‚ààRd. In such cases, the values
Y j are concentrated on a lower dimensional subset of Rd and the distribution of
Y j cannot be described by a density on Rd. Thus, the densities pm(x, ¬∑) from the
deÔ¨Ånition of Œ±m do not exist in this situation. Nevertheless, inspection of the proof of
proposition 4.13 reveals that a slight generalisation of algorithm 4.12 still works in
this case. The resulting generalisation is described in the following lemma.
Lemma 4.15
Assume that for each move m ‚ààM in algorithm 4.12 there is a set
Cm ‚äÜRd √ó Rd such that
(x, y) ‚ààCm
‚áê‚áí
(y, x) ‚ààCm
(4.8)
for all x, y ‚ààRd and a density œïm: Cm ‚Üí[0, ‚àû) such that, if a proposal Y j is
constructed from a previous state X j‚àí1 ‚àºœÄ, we have
P(Y j ‚ààB, X j‚àí1 ‚ààA) =

Cm
1A(x)1B(y) œïm(x, y) dy dx
(4.9)
for all A, B ‚äÜRd. Consider algorithm 4.12, but using acceptance probabilities
Œ±m(x, y) = min
Œ≥m(y)œïm(y, x)
Œ≥m(x)œïm(x, y), 1

(4.10)

124
AN INTRODUCTION TO STATISTICAL COMPUTING
instead of the expression from (4.7). The process generated by this algorithm is a
Markov chain with stationary density œÄ.
While the pair (x, y) in (4.9) lies in the 2d-dimensional space Rd √ó Rd, the
integral in (4.9) is an integral over the subset Cm only and in many applications we
have dim(Cm) < 2d. For example, if Cm is (d + 1)-dimensional, the integral will only
be a (d + 1)-dimensional integral, even if the state space S of the Markov chain Xn
has dimension d > 1 and thus 2d > d + 1. Similarly, if Cm contains isolated points,
the integral is interpreted as a sum over these points.
Proof
(of lemma 4.15, outline only). We Ô¨Årst observe that (4.10) can be obtained
from (4.7) by replacing œÄ(y)pm(y, x)/œÄ(x)pm(x, y) with œïm(y, x)/œïm(x, y). Assume
that X j‚àí1 ‚àºœÄ. If the conditional distribution of Y j given X j = x for move type
m has a density pm(x, ¬∑) then, by (4.9), we have œïm(x, y) = œÄ(x)pm(x, y) and
we are in the situation of algorithm 4.12. In this case we get X j ‚àºœÄ from proposi-
tion 4.13.
If the conditional distribution of Y j has no density, as discussed above, a more
advanced concept of integration is required to make sense of the integrals in (4.9)
and we omit the required technical details. Once the meaning of the integrals with
density œïm(x, y) has been clariÔ¨Åed, a proof can be constructed by following the lines
of the proof of proposition 4.13 while replacing occurrences of œÄ(x)pm(x, y) with
œïm(x, y) and using the modiÔ¨Åed deÔ¨Ånition of Œ±(x, y).
Example 4.16
If the move m ‚ààM maps the current state X j‚àí1 ‚ààRd to the proposal
Y j ‚ààRd, constructed such that the component Y j,1 is random with density q: R ‚Üí
[0, ‚àû) and (Y j,2, . . . , Y j,n) = (X j‚àí1,2, . . . , X j‚àí1,n), then we can apply lemma 4.15
with
C =

(x, y) ‚ààRd √ó Rd  x2 = y2, . . . , xd = yd
 ‚àº= Rd √ó R.
Since we have
P(Y j ‚ààB, X j‚àí1 ‚ààA) =

Rd œÄ(x) 1A(x)

R
q(y1) 1B(y1, x2, . . . , xd) dy1 dx,
the pair (X j‚àí1, Y j) has density œï(x, y) = œÄ(x)q(y1) on the (d + 1)-dimensional set
C and the required acceptance probability for move m is
Œ±m(x, y) = min
Œ≥m(y)œï(y, x)
Œ≥m(x)œï(x, y), 1

= min
Œ≥m(y)œÄ(y)q(x1)
Œ≥m(x)œÄ(x)q(y1), 1

.
The resulting moves only change the Ô¨Årst component of the state vector, but similar
moves can be introduced to change any of the remaining components.

MARKOV CHAIN MONTE CARLO METHODS
125
Example 4.17
If the move m ‚ààM maps the current state X ‚ààRd to the proposal
Y = X + Œµ, where the distribution of Œµ ‚ààRd is symmetric, that is where P(Œµ ‚ààA) =
P(‚àíŒµ ‚ààA), then lemma 4.15 can be applied with
C =

(x, y) ‚ààRd √ó Rd  x ‚àíy ‚ààsupp(Œµ j)
 ‚àº= Rd √ó supp(Œµ).
Here supp(Œµ) is the support of the distribution of Œµ and, since Œµ is symmetric, the
support of Œµ satisÔ¨Åes z ‚ààsupp(Œµ) if and only if ‚àíz ‚ààsupp(Œµ). Thus condition (4.8) is
satisÔ¨Åed. Also, the probabilities for going from x to y = x + Œµ and for going from y
to x = y + (‚àíŒµ) are the same and thus, for this example, we have œï(y, x)/œï(x, y) =
œÄ(y)/œÄ(x). Consequently, the acceptance probability for this move type is
Œ±m(x, y) = min
Œ≥m(y)œï(y, x)
Œ≥m(x)œï(x, y), 1

= min
Œ≥m(y)œÄ(y)
Œ≥m(x)œÄ(x), 1

.
In the case dim (supp(Œµ)) < d, this result is a generalisation of the random walk
Metropolis sampling method from Section 4.1.3.
4.2
Convergence of Markov Chain Monte
Carlo methods
MCMC methods are based on the following deÔ¨Ånition.
DeÔ¨Ånition 4.18
Let X be a random variable and f be a function such that f (X) ‚ààR.
Then the MCMC estimate for E ( f (X)) is given by
ZMCMC
N
= 1
N
N

j=1
f (X j)
(4.11)
where (X j) j‚ààN is a Markov chain with the distribution of X as a stationary distribution.
We have discussed methods for constructing such Markov chains in Section 4.1.
In this section we will discuss conditions for the estimate ZMCMC
N
to converge to
the expectation E ( f (X)) and we will also discuss factors affecting the error of this
estimate.
4.2.1
Theoretical results
Whether or not the MCMC estimate ZMCMC
N
from (4.11) converges to the exact value
E ( f (X)) as N ‚Üí‚àû, depends on the Markov chain X: if the Markov chain does not
reach all parts of the state space, or if it moves too slowly, the estimator ZMCMC
N
will
only correspond to an average of f over the visited part of the state space instead

126
AN INTRODUCTION TO STATISTICAL COMPUTING
of to the full expectation E ( f (X)). Thus, for the approximation (4.1) to work, the
Markov chain (X j) j‚ààN must move through the state space quickly enough. In this
section we will discuss criteria for the Markov chain to explore the state space fast
enough.
DeÔ¨Ånition 4.19 and deÔ¨Ånition 4.20, as well as the result from theorem 4.21, use
the concept of ‚ÄòœÉ-Ô¨Ånite measures‚Äô from mathematical analysis. A measure Œº on S
assigns a ‚Äòsize‚Äô Œº(A) to subsets A ‚äÜS. In order to avoid technical complications, we
do not give the formal deÔ¨Ånition of a ‚ÄòœÉ-Ô¨Ånite measure‚Äô here but instead give a few
examples:
r If S = Rd, then the d-dimensional volume, that is Œº(A) = |A| for all A ‚äÜS,
is a œÉ-Ô¨Ånite measure on S.
r If S is Ô¨Ånite or countable, the number of elements in a subset, that is Œº(A) = #A
for all A ‚äÜS, is a œÉ-Ô¨Ånite measure on S.
r Every probability measure is a œÉ-Ô¨Ånite measure on S, that is if X is a random
variable we can use Œº(A) = P(X ‚ààA). In particular, the stationary distribution
œÄ of a Markov chain X is a œÉ-Ô¨Ånite measure.
DeÔ¨Ånition 4.19
Let (X j) j‚ààN be a Markov chain with state space S and let Œº be
a œÉ-Ô¨Ånite measure on S with Œº(S) > 0. Then the Markov chain (X j) j‚ààN is called
Œº-irreducible, if for every A ‚äÜS with Œº(A) > 0 and for every x ‚ààS there is a j ‚ààN
such that
P(X j ‚ààA | X0 = x) > 0.
This deÔ¨Ånition formalises the idea that there are regions A in the state space
which can always be reached by the process, independently of where it is started,
thus preventing situations where the state space consists of different parts between
which no transitions are possible. The following extension of the concept of Œº-
irreducibility makes sure that the times between returns to A are small enough so that
inÔ¨Ånitely many visits to A happen for every individual sample path of the Markov
chain.
DeÔ¨Ånition 4.20
Let (X j) j‚ààN be a Markov chain with state space S. The Markov
chain (X j) j‚ààN is called Harris recurrent, if there exists a œÉ-Ô¨Ånite measure Œº on S
with Œº(S) > 0 such that the following conditions hold:
(a) (X j) j‚ààN is Œº-irreducible.
(b) For every A ‚äÜS with Œº(A) > 0 and for every x ‚ààA we have
P
‚éõ
‚éù
‚àû

j=1
1A(X j) = ‚àû

X0 = x
‚éû
‚é†> 0.

MARKOV CHAIN MONTE CARLO METHODS
127
Using the concept of Harris recurrence we can state the main result of this
section, guaranteeing convergence of the estimate ZMCMC
N
from (4.11) to the required
limit.
Theorem 4.21
(law of large numbers for Markov chains) Let (X j) j‚ààN be a time
homogeneous, Harris recurrent Markov chain on a state space S with stationary
distribution œÄ and let X ‚àºœÄ. Let f : S ‚ÜíR be a function such that the expectation
E ( f (X)) exists. Then, for every initial distribution, we have
lim
N‚Üí‚àû
1
N
N

j=1
f (X j) = E ( f (X))
with probability 1.
Proofs of this result can, for example, be found in the books by Robert and Casella
(2004, theorem 6.63) and Meyn and Tweedie (2009, theorem 17.0.1).
In order to apply theorem 4.21 to the Markov chains generated by the
Metropolis‚ÄìHastings algorithms 4.2 and 4.4, we need to Ô¨Ånd conditions for the
resulting Markov chains to be Harris recurrent. While irreducibility as described
in deÔ¨Ånition 4.19 is often relatively easy to check, the second condition in the
deÔ¨Ånition 4.20 of Harris recurrence is less obvious. In many cases, verifying the
conditions of theorem 4.21 for Markov chains generated by the Metropolis‚ÄìHastings
algorithm is greatly simpliÔ¨Åed by the following result (Robert and Casella, 2004,
lemma 7.3).
Lemma 4.22
Let (X j) j‚ààN be the Markov chain generated by the Metropolis‚Äì
Hastings algorithms 4.2 or 4.4, with stationary distribution œÄ. Assume that (X j) j‚ààN
is œÄ-irreducible. Then (X j) j‚ààN is Harris recurrent.
This lemma, together with theorem 4.21 allows the convergence of the
Metropolis‚ÄìHastings method to be proved in many situations. For reference, we
state the combined result as a corollary.
Corollary 4.23
Let (X j) j‚ààN be the Markov chain generated by the Metropolis‚Äì
Hastings algorithms 4.2 or 4.4, with state space S, initial value X0 ‚ààS (either random
or deterministic) and stationary distribution œÄ. Assume that (X j) j‚ààN is œÄ-irreducible.
Let X ‚àºœÄ, let f : S ‚ÜíR be a function such that the expectation E ( f (X)) exists
and let ZMCMC
N
be deÔ¨Åned by (4.11). Then we have
lim
N‚Üí‚àûZMCMC
N
= E ( f (X))
with probability 1.

128
AN INTRODUCTION TO STATISTICAL COMPUTING
Proof
The statement is a direct consequence of lemma 4.22 and theorem 4.21.
The usefulness of corollary 4.23 is illustrated by the following example.
Example 4.24
Assume that the target distribution is given by a density œÄ on S = Rd.
Let (X j) j‚ààN be generated by the random walk Metropolis method from algorithm
4.9 with increments Œµ j ‚àºN(0, œÉ 2). Assume that A ‚äÜRd with
œÄ(A) =

A
œÄ(x) dx > 0
and x ‚ààRd. The proposal Y1 satisÔ¨Åes
P(Y1 ‚ààA | X0 = x) =

A
œà0,œÉ 2(y ‚àíx) dy,
where œà0,œÉ 2 is the density of the N(0, œÉ 2)-distribution. Similarly, the probability p
of the proposal Y1 falling in the set A and being accepted, conditional on X0 = x, is
given by
p =

A
Œ±(x, y) œà0,œÉ 2(y ‚àíx) dy =

A
min
œÄ(y)
œÄ(x), 1

œà0,œÉ 2(y ‚àíx) dy.
(4.12)
Our aim is to show p > 0, thus proving œÄ-irreducibility of the generated Markov
chain in one time step.
Assume Ô¨Årst that œÄ(x) > 0. To show that p > 0 in this case, we will use
the fact that for every function h ‚â•0 we have

A h(x) dx > 0 if and only if

y ‚ààA
 h(y) > 0
 > 0 where | ¬∑ | denotes the d-dimensional volume. Thus, since

A œÄ(y) dy > 0, we have

y ‚ààA
 œÄ(y) > 0
 > 0.
Since œÄ(x) > 0 and since the density œà0,œÉ 2 is strictly positive, we Ô¨Ånd


y ‚ààA
 min
œÄ(y)
œÄ(x), 1

œà0,œÉ 2(y ‚àíx) > 0
 > 0
and thus, using (4.12), we get p > 0. For the case œÄ(x) = 0, the value Œ±(x, y) and
thus the next step in algorithm 4.9 is not deÔ¨Åned. There are two ways to deal with
this case. Either we can restrict the state space S to only include points x ‚ààRd
with œÄ(x) > 0. In this case, corollary 4.23 guarantees convergence of the random
walk Metropolis algorithm for all initial points X0 with œÄ(X0) > 0. Alternatively,
we can modify the algorithm to always accept the proposal whenever œÄ(x) = 0

MARKOV CHAIN MONTE CARLO METHODS
129
causes Œ±(x, y) to be undeÔ¨Åned. For the modiÔ¨Åed algorithm we get p > 0 for all
initial values x ‚ààRd. In this case, corollary 4.23 gives convergence of ZMCMC
N
for
all X0 ‚ààRd.
The result from theorem 4.21 only states convergence of the averages ZMCMC
N
to
the limit E ( f (X)), but does not give convergence of the distributions of the X j to the
distribution of X. In fact, it transpires that for convergence of the distributions to hold,
the additional assumption of ‚Äòaperiodicity‚Äô of (X j) j‚ààN is required. In practice, the
Markov chains generated by the Metropolis‚ÄìHastings method are normally aperiodic
and thus, in situations where theorem 4.21 applies we normally also have convergence
of the distribution of X j to œÄ as j ‚Üí‚àû. For discussion of this topic we refer again
to the books by Robert and Casella (2004, theorem 6.63) and Meyn and Tweedie
(2009, theorem 17.0.1).
When applying the results from this section, it is important to keep in mind that
theorem 4.21 and corollary 4.23 only make statements about the behaviour of the
estimator ZMCMC
N
in the limit as N ‚Üí‚àû. The results do not quantify the speed
of convergence and convergence can sometimes be extremely slow (we will see an
example of this at the end of Section 4.4.2).
4.2.2
Practical considerations
In the previous section we have seen that the Markov chain constructed for an MCMC
method must be irreducible in order for the MCMC estimate to converge to the correct
value E ( f (X)). In this section we will discuss different aspects of the speed of this
convergence. As before, we consider the mean squared error
MSE(ZMCMC
N
) = Var(ZMCMC
N
) + bias(ZMCMC
N
)2,
(4.13)
where the estimator ZMCMC
N
is given by equation (4.11) and we use lemma 3.12 to
get the representation (4.13) for the mean squared error.
4.2.2.1
Convergence to stationarity
Since œÄ is a stationary density of the Markov chain X, if we start the Markov chain
with X0 ‚àºœÄ, we have X j ‚àºœÄ for every j ‚ààN. While this is true in theory, in
practice we usually cannot easily generate samples from the density œÄ (otherwise we
would be using Monte Carlo estimation instead of MCMC) and thus we need to start
the Markov chain with a different distribution or with a Ô¨Åxed value. Consequently,
for Ô¨Ånite j, the distribution of X j will not have density œÄ and normally we will have
E

f (X j)
	
Ã∏= E ( f (X)). Thus, the argument from proposition 3.14 will no longer
apply and we will have bias(ZMCMC
N
) Ã∏= 0.
On the other hand, assuming aperiodicity of X, the distribution of X j will
converge to the correct distribution as j ‚Üí‚àûand thus we can normally expect

130
AN INTRODUCTION TO STATISTICAL COMPUTING
bias(ZMCMC
N
) ‚Üí0 as N ‚Üí‚àû. A typical approach to reduce the effect of bias is to
omit the Ô¨Årst samples from the Monte Carlo estimate in order to give the Markov
chain time to get close to stationarity. In practice one often uses
E ( f (X)) ‚âà
1
N ‚àíM
N

j=M+1
f (X j)
(4.14)
instead of the estimate ZMCMC
N
from (4.11). The value M is chosen large enough
that the process can be assumed close to stationarity, but small enough that enough
samples remain for the estimate. Even if the samples X1, X2, . . . , X M are not directly
used in the estimate (4.14), the corresponding values still need to be computed in
order to get the following values X M+1, X M+2, . . . In the context of the estimate
(4.14), the time interval 1, 2, . . . , M is called the burn-in period.
A very simple illustration of the effect of a burn-in period can be found in
Figure 4.2. In the situation depicted there, the Ô¨Årst values of the process do not
resemble typical samples from the target distribution. The samples become useful
only after the region of high probability is reached. The same kind of behaviour,
a directional motion towards a region of high probability followed by Ô¨Çuctuations
inside this region, can sometimes be observed in more realistic applications of MCMC
and can the guide the choice of burn-in period.
From the results in Section 4.2.1 we know that a burn-in period is not required
for convergence of the method. The main effect of a burn-in period is to remove
0
200
400
600
800
1000
0
20
40
60
80
100
j
X j
Figure 4.2
Path of a Metropolis‚ÄìHastings Markov chain, started far away from
equilibrium: the displayed path corresponds to a random walk Metropolis method
with target distribution N(100, 1), started at X0 = 0. The Ô¨Årst values of X j, until the
vertical line, do not behave like a sample from the target distribution. A good choice
of the burn-in period for this Markov chain would be the time interval before the
vertical line.

MARKOV CHAIN MONTE CARLO METHODS
131
samples which would be extremely unlikely under the target distribution from the
computation, thus reducing the sample size N required to get good estimates. An
alternative approach to the use of a burn-in phase is to start the Markov chain with a
‚Äòtypical value‚Äô for the target distribution, for example at the maximum of the target
density œÄ.
4.2.2.2
Effective sample size
The mean squared error given in equation (4.13) is determined by the bias (considered
above) as well as the variance of the estimator. Since X forms a Markov chain, the
samples X j are not independent, and we have
Var

ZMCMC
N
	
= Var
‚éõ
‚éù1
N
N

j=1
f (X j)
‚éû
‚é†
= Cov
‚éõ
‚éù1
N
N

j=1
f (X j), 1
N
N

l=1
f (Xl)
‚éû
‚é†
= 1
N 2
N

j,l=1
Cov

f (X j), f (Xl)
	
.
(4.15)
If we assume that the Markov chain is close to stationarity, then we have
Var(X j) ‚âàVar(X), that is the variance of X j is approximately constant in time.
Similarly, the joint distribution of X j and Xl (approximately) only depends on the
lag k = l ‚àíj but not on the individual values of j and l. Thus, the covariance between
f (X j) and f (Xl) only (approximately) depends on l ‚àíj and we get
Cov

f (X j), f (Xl)
	
‚âàCov

f (X0), f (Xl‚àíj)
	
.
Similarly, if the Markov chain is close to stationarity, the correlation between f (X j)
and f (Xl) satisÔ¨Åes
Corr

f (X j), f (Xl)
	
=
Cov

f (X j), f (Xl)
	

Var

f (X j)
	
Var ( f (Xl))
‚âàCov

f (X j), f (Xl)
	
Var ( f (X))
(4.16)
and (approximately) only depends on l ‚àíj. This correlation is called the lag-(l ‚àíj)
autocorrelation of the Markov chain X.

132
AN INTRODUCTION TO STATISTICAL COMPUTING
Combining equation (4.15) and equation (4.16) and using the symmetry of the
covariance we Ô¨Ånd
Var

ZMCMC
N
	
= 1
N 2
N

j,l=1
Cov

f (X j), f (Xl)
	
‚âà1
N Var ( f (X)) + 2 1
N 2
N

j=1
N

l= j+1
Cov

f (X j), f (Xl)
	
‚âà1
N Var ( f (X))
‚éõ
‚éù1 + 2 1
N
N

j=1
N

l= j+1
Corr

f (X0), f (Xl‚àíj)
	
‚éû
‚é†
‚âà1
N Var ( f (X))
‚éõ
‚éù1 + 2 1
N
N

j=1
N‚àíj

k=1
Corr ( f (X0), f (Xk))
‚éû
‚é†.
Markov chains used in MCMC methods (under the assumption of aperiodicity)
have the property that the distribution of a Markov chain is guaranteed to converge
to the same distribution œÄ for every initial distribution. Thus, the Markov chain
‚Äòforgets‚Äô the initial distribution over time and we expect the lag-k autocorrelations
œÅk = Corr ( f (X0), f (Xk)) to converge to 0 as k ‚Üí‚àû(see Figure 4.3 for illustration).
For sufÔ¨Åciently large N we have
N‚àíj

k=1
Corr ( f (X0), f (Xk)) ‚âà
‚àû

k=1
Corr ( f (X0), f (Xk))
and, since the right-hand side no longer depends on j we Ô¨Ånd
Var

ZMCMC
N
	
‚âà1
N Var ( f (X))
‚éõ
‚éù1 + 2 1
N
N

j=1
‚àû

k=1
Corr ( f (X0), f (Xk))
‚éû
‚é†
= 1
N Var ( f (X))

1 + 2
‚àû

k=1
Corr ( f (X0), f (Xk))

.
(4.17)
Comparing Var

ZMCMC
N
	
from equation (4.17) to the corresponding variance
Var(eMC) from (3.8) for the basic Monte Carlo estimate we see that the variance,
and thus the error, of the MCMC estimate differs by the presence of the additional
correlation term on the right-hand side of (4.17). Typically this term is positive and
thus MCMC methods are less efÔ¨Åcient than a basic Monte Carlo method would be.
While the above derivation is heuristic, an exact result such as (4.17) can be
derived under conditions very similar to the conditions required for theorem 4.21.

MARKOV CHAIN MONTE CARLO METHODS
133
0.0 0.2 0.4 0.6 0.8 1.0
œÅk
œÅk
œÅk
0.0 0.2 0.4 0.6 0.8 1.0
0
50
100
150
200
0.0 0.2 0.4 0.6 0.8 1.0
Lag
(a)
(b)
(c)
Figure 4.3
The autocorrelation functions for the Markov chain from example 4.10
and example 4.25 for different values of œÉ: (a) œÉ = 1; (b) œÉ = 6; (c) œÉ = 36. The
corresponding estimation problem is to Ô¨Ånd E(X2). The values of œÉ considered here
are the same as for the paths shown in Figure 4.1. The autocorrelation function in (b)
decays fastest, indicating that this is the most efÔ¨Åcient of the three MCMC methods
considered here.
Such a result can, for example, be found as part of theorem 17.0.1 in the book by
Meyn and Tweedie (2009).
In analogy to equation (3.8) we write
Var

ZMCMC
N
	
‚âà
1
Neff
Var ( f (X))
where
Neff =
N
1 + 2 ‚àû
k=1 Corr ( f (X0), f (Xk))

134
AN INTRODUCTION TO STATISTICAL COMPUTING
is called the effective sample size. The effective sample size does not only depend
on N and on the Markov chain X, but it also depends on the function f used
in the estimation problem. The value Neff can be used to quantify the increase in
computational cost caused by the dependence of samples in an MCMC method.
Compared with a Monte Carlo method for the same problem, the number of samples
generated needs to be increased by a factor N/Neff to achieve a comparable level of
error. The empirical sample size can be used to compare the efÔ¨Åciency of different
MCMC methods: the larger Neff/N is, the more efÔ¨Åcient the resulting method.
Example 4.25
In example 4.10 and the corresponding Figure 4.1 we considered
a family of random walk Metropolis methods for the target distribution œÄ given by
equation (4.6). In the methods considered there, we can choose the variance œÉ of
the increments of the random walk. To compare the efÔ¨Åciency of the random walk
Metropolis algorithm for different values of œÉ, we can consider the effective sample
sizes Neff.
The autocorrelations and thus the effective sample size depend on the speciÔ¨Åc
estimation problem, that is on the choice of the function f in (4.1). Here we consider
the problem of estimating the variance of X. Since œÄ is symmetric, we have E(X) = 0
and thus Var(X) = E(X2). Thus, we consider f (x) = x2.
The autocorrelations Corr

f (X j), f (X j+k)
	
for this choice of f are shown in
Figure 4.3. Using these autocorrelations, we Ô¨Ånd the following effective samples
sizes.
œÉ = 1
œÉ = 6
œÉ = 36
Neff
0.0119 ¬∑ N
0.1317 ¬∑ N
0.0337 ¬∑ N
N/Neff
84.0
7.6
29.7
Thus, even ignoring the additional error introduced by bias, the MCMC method
from example 4.10 needs for œÉ = 1 approximately 84 times more samples than a
basic Monte Carlo method with the same error would need. The efÔ¨Åciency can be
greatly improved by tuning the parameter œÉ, for example for œÉ = 6 the MCMC
method only needs approximately 7.6 times more samples than a basic Monte Carlo
method. Thus we see that œÉ = 6 is a much better choice for the given problem than
either œÉ = 1 or œÉ = 36.
4.2.2.3
Acceptance rates
By comparing Figure 4.1 and Figure 4.3 we see that the effective sample size in
example 4.25 is inÔ¨Çuenced by two different effects. In Figure 4.1(a) and Figure 4.3(a),
where the variance œÉ 2 of the increments is smallest, the effective sample size is large
because the small increments allow the process only slow movement through the state
space; reaching different regions of state space takes a long time and thus samples
close in time have a tendency to also be close in space. In contrast, the constant

MARKOV CHAIN MONTE CARLO METHODS
135
1e‚àí04
1e‚àí01
1e+02
1e+05
0.0
0.2
0.4
0.6
0.8
1.0
œÉ2
Average acceptance probability
Figure 4.4
The average acceptance probability E(Œ±(X j‚àí1, Y j)) of the random walk
Metropolis sampler from example 4.10 and example 4.25, as a function of œÉ 2. The
three vertical lines (from left to right) correspond to the values œÉ 2 = 12, œÉ 2 = 62,
and œÉ 2 = 362 from Figure 4.3.
stretches of the path in Figure 4.1(c) indicate that the large œÉ 2 considered there leads
to very low acceptance rates and this, in turn causes the small effective sample size
for large values of œÉ.
The observation that the acceptance rate affects the efÔ¨Åciency of MCMC methods
can be used as a simple, heuristic tuning criterion: in a random walk Metropolis
method, we expect the average acceptance rate to decrease as the variance œÉ 2 of the
increments increases. (This decrease is not necessarily monotonically, though.) The
variance œÉ 2 should be chosen as large as possible under the constraint that the average
acceptance probability should not be too small. To illustrate this, Figure 4.4 shows
the average acceptance rate for the random walk Metropolis methods considered in
example 4.10 and example 4.25, as a function of œÉ 2.
4.2.2.4
Convergence diagnostics
Even in cases where convergence of an MCMC method is formally proved conver-
gence to equilibrium can be extremely slow, resulting in inaccurate and misleading
estimates. Situations where this problem occurs include:
r In multimodal distributions the Markov chain can get ‚Äòstuck‚Äô in a mode for a
very long time. This will be the case if transitions between modes require
a very unlikely sequence of steps, for example if the states between the
modes are very unlikely and if direct transitions between the modes are never
proposed.
If the positions of modes of the target distribution are not known in advance,
this problem can be very difÔ¨Åcult to detect since, before the Ô¨Årst transition

136
AN INTRODUCTION TO STATISTICAL COMPUTING
between modes happens, the path of the Markov chain ‚Äòlooks stationary‚Äô. If
the problem is not detected, the resulting estimate ZMCMC
N
will estimate the
conditional expectation E

f (X)
 X ‚ààA
	
where A is the mode in question,
instead of the full expectation E ( f (X)).
One way to resolve this issue is to use an MCMC method with different
move types (see Section 4.1.5) and to introduce special move types which
perform transitions between modes.
r In high-dimensional situations it takes a long time for a Markov chain to explore
all of the space. In cases where most of the mass of the target distribution is
concentrated in a small region of the state space, the Markov chain may take
an extremely long time to Ô¨Ånd this region or even may never reach the relevant
region of space at all.
This kind of problem can be recognised by the fact that the Markov chain
moves through space ‚Äòaimlessly‚Äô, possibly behaving like a random walk, or
diverging to inÔ¨Ånity. If enough information about the target distribution is
available, this problem can be resolved by starting the Markov chain in the
region of space where the target distribution is concentrated.
To recognise problems caused by slow convergence, so called convergence diag-
nostics can be used. Here we restrict ourselves to a few very simple cases. First,
it is always a good idea to plot some one-dimensional functions of the state of the
Markov chain over time. If the Markov chain is one-dimensional, this could be the
state X j itself. In the case of multidimensional Markov chains this could be, for
example, the coordinate with the highest variance. The resulting plots (see for exam-
ple Figure 4.1 and Figure 4.2) allow to visually assess whether the process is close to
stationarity.
To detect the presence of different modes, one can run several copies of the
Markov chain, using different starting values. The idea here is then to assess whether
all of these Markov chains move into the same mode of the distribution, or whether
they end up in different modes. This question can either be answered visually by using
plots as above, or by analytical methods, for example based on the idea of comparing
the sample variance of the samples from each instance of the Markov chain to the
sample variance of all generated samples combined. A commonly used convergence
diagnostic based on this idea is introduced in Gelman and Rubin (1992).
Convergence diagnostics can be used both to determine a good burn-in period
and to determine whether a given value of N is large enough to give useful estimates.
4.2.2.5
Numerical errors
A Ô¨Ånal consideration when using MCMC methods in practice is the effect of rounding
error caused by the number representation in the computer. While stochastic methods
are often quite robust in this regard, the effect of rounding errors often causes problems
when evaluating the acceptance probability Œ±(X j‚àí1, Y j) in the Metropolis‚ÄìHastings
algorithm.

MARKOV CHAIN MONTE CARLO METHODS
137
As an example we consider here the case of algorithm 4.2, where the acceptance
probability has the form
Œ±(x, y) = min
œÄ(y)p(y, x)
œÄ(x)p(x, y), 1

.
(4.18)
Due to the restrictions of number representation in the computer, the numerical values
for probabilities œÄ(x) and p(x, y) in the program will not exactly coincide with the
exact values and problems can occur in cases where œÄ gets very small. To avoid the
resulting problems, equation (4.18) can be rewritten as
Œ±(x, y) = min

exp

log œÄ(y)p(y, x)
œÄ(x)p(x, y)

, 1

= min (exp (log œÄ(y) + log p(y, x) ‚àílog œÄ(x) ‚àílog p(x, y)) , 1) .
(4.19)
This representation avoids numerical problems by performing all arithmetic on the
logarithmic terms, which are of much smaller magnitude, and only exponentiating
the result after all possible cancellations have taken place.
4.3
Applications to Bayesian inference
In a Bayesian model, one assumes that the parameter Œ∏ of a statistical model is itself
random. We consider the following setting:
r Data x = (x1, . . . , xn) is given, where x forms a sample of i.i.d. random vari-
ables X1, . . . , Xn ‚ààRd. Here we assume that the distribution of the Xi has a
density œïX|Œ∏(x | Œ∏), so that the distribution of X = (X1, . . . , Xn) is given by
pX|Œ∏(x | Œ∏) =
n
i=1
œïX|Œ∏(xi | Œ∏)
(4.20)
for all x = (x1, . . . , xn) ‚àà(Rd)n and all Œ∏ ‚ààRp.
r The distribution of the data depends on an unknown parameter Œ∏ ‚ààRp where Œ∏
is assumed to be random with density pŒ∏(Œ∏). The distribution pŒ∏ of Œ∏ is called
the prior distribution.
Thus, the data are assumed to be generated by a two-step procedure where Ô¨Årst Œ∏
is chosen randomly and then, given the value of Œ∏, samples X1, . . . , Xn ‚àºœïX|Œ∏(¬∑ | Œ∏)
are generated to obtain the observations x1, . . . , xn.
Here, symbols such as pX|Œ∏ denote densities and the subscript indicates that this
is the conditional density of X, given the value of Œ∏. The variables used as arguments
of these densities are mostly denoted by the corresponding lower case letters, that is
pX(x) is the density of X at the point x ‚àà(Rd)n. By a slight abuse of notation, we
use lower case Œ∏ both for the random variable and for the corresponding values.

138
AN INTRODUCTION TO STATISTICAL COMPUTING
Our aim is to gather as much information as possible about the unknown para-
meter Œ∏ from given data x. Typically, the data x do not completely determine the
value of Œ∏. Instead, since Œ∏ is assumed to be random, the solution of this parameter
estimation problem will be given by the conditional distribution of Œ∏, given the
observation X = x. This distribution is called the posterior distribution; it depends
both on the data x and on the prior distribution for Œ∏. By Bayes‚Äô rule (see Section
A.2), we Ô¨Ånd the density of the posterior distribution as
pŒ∏|X(Œ∏ | x) =
pX|Œ∏(x | Œ∏)pŒ∏(Œ∏)

pX|Œ∏(x | t)pŒ∏(t) dt = 1
Z pX|Œ∏(x | Œ∏)pŒ∏(Œ∏)
(4.21)
for all Œ∏ ‚ààRp, where Z =

pX|Œ∏(x | t)pŒ∏(t) dt is the normalisation constant. The
value x in equation (4.21) is the given data and thus a constant and we will consider
the given expression as a function of Œ∏.
Denote the true value of Œ∏ which was used to generate the observations x by Œ∏‚àó.
If sufÔ¨Åcient data are given and if the dependence of the distribution of the Xi on the
parameter Œ∏ is sensitive enough, the posterior distribution pŒ∏|X will be concentrated
around the true value Œ∏‚àóand the more data are given the more concentrated the
posterior will be. Given the posterior distribution from equation (4.21), we can obtain
results such as:
r An estimates for the unknown parameter value can be found by either taking
the conditional expectation E(Œ∏ | X = x) or by considering the mode or median
of the posterior distribution.
r The uncertainty remaining in the estimate can be quantiÔ¨Åed by considering the
conditional variance Var(Œ∏ | X = x) or the corresponding standard deviation.
r More speciÔ¨Åc questions about the possible behaviour of the parameter, given the
available observations, can be obtained by studying the posterior distribution.
For example the probability that the parameter is inside a region A ‚äÜRp can
be found as P(Œ∏ ‚ààA | X = x).
While the posterior distribution is known ‚Äòexplicitly‚Äô from equation (4.21), eval-
uating expectations or probabilities with respect to the posterior distribution can be
challenging in practice. Reasons for this include the fact that often the value of the
normalisation constant Z in (4.21) cannot be found, and also the general problems
involved in evaluating expectations for distributions with complicated densities.
Following the approach described in Section 3.1, a widely used strategy is to
employ Monte Carlo and MCMC methods to evaluate expectations with respect
to the posterior distribution. This allows us to evaluate expectations of the form
E( f (Œ∏) | X = x), if we are able to generate samples from the distribution with density
œÄ(Œ∏) = pŒ∏|X(Œ∏ | x) = 1
Z pX|Œ∏(x | Œ∏)pŒ∏(Œ∏)
(4.22)
for all Œ∏ ‚ààRp, where x is the given data. In some simple situations, for example in
example 3.6, it is possible to generate the required samples using rejection sampling,

MARKOV CHAIN MONTE CARLO METHODS
139
but often it is cumbersome to Ô¨Ånd a feasible proposal distribution and thus samples
from the density (4.22) are more commonly generated using MCMC methods. This
is the approach we will consider here.
Since the posterior distribution is typically concentrated around the true parameter
value Œ∏‚àó, we do not expect any problems arising from multimodality and we can use
the random walk Metropolis algorithm described in Section 4.1.3. For this algorithm,
the probability of accepting a proposal ÀúŒ∏ if the previous state was Œ∏ is given by
Œ±(Œ∏, ÀúŒ∏) = min
œÄ( ÀúŒ∏)
œÄ(Œ∏), 1

= min
 pX|Œ∏(x | ÀúŒ∏)pŒ∏( ÀúŒ∏)
pX|Œ∏(x | Œ∏)pŒ∏(Œ∏), 1

(4.23)
where x is the given observations and where we use the fact that the normalisation
constant Z from (4.22) in the numerator and denominator cancels. The right-hand
side in (4.23) can be further expanded using the deÔ¨Ånition of pX|Œ∏ from equation
(4.20). Since, for large n, the product in (4.20) can be very small, we also use the
trick from equation (4.19) to avoid potential problems caused by rounding errors.
The resulting expression is
pX|Œ∏(x | ÀúŒ∏)pŒ∏( ÀúŒ∏)
pX|Œ∏(x | Œ∏)pŒ∏(Œ∏) =
n
i=1 œïX|Œ∏(xi | ÀúŒ∏)pŒ∏( ÀúŒ∏)
n
i=1 œïX|Œ∏(xi | Œ∏)pŒ∏(Œ∏)
= exp
 n

i=1
log œïX|Œ∏(xi | ÀúŒ∏) + log pŒ∏( ÀúŒ∏)
‚àí
n

i=1
log œïX|Œ∏(xi | Œ∏) ‚àílog pŒ∏(Œ∏)

.
(4.24)
Substituting this expression into (4.23) gives the form in which Œ±(Œ∏, ÀúŒ∏) should be
used in an implementation of algorithm 4.9.
Example 4.26
For the prior let Œº ‚àºU[‚àí10, 10] and œÉ ‚àºExp(1), independently,
and set Œ∏ = (Œº, œÉ) ‚ààR2. Assume that the data consist of i.i.d. values X1, . . . , Xn ‚àº
N(Œº, œÉ 2) and that we have observed values x = (x1, . . . , xn) for the data. In this
case, the prior density is
pŒº,œÉ(Œº, œÉ) = 1
201[‚àí10,10](Œº) ¬∑ exp(‚àíœÉ)1[0,‚àû)(œÉ)
and the conditional density of the observations given the parameters is
pX|Œº,œÉ(x | Œº, œÉ) =
n
i=1
1
‚àö
2œÄœÉ 2 exp

‚àí(xi ‚àíŒº)2
2œÉ 2

=
1
(2œÄ)n/2 ¬∑ 1
œÉ n exp

‚àí1
2œÉ 2
n

i=1
(xi ‚àíŒº)2

.

140
AN INTRODUCTION TO STATISTICAL COMPUTING
The constants 1/20 and 1/(2œÄ)n/2 cancel in the numerator and denominator of (4.23)
and using (4.24) we Ô¨Ånd
pX|Œº,œÉ(x | ÀúŒº, ÀúœÉ)pŒº,œÉ( ÀúŒº, ÀúœÉ)
pX|Œº,œÉ(x | Œº, œÉ)pŒº,œÉ(Œº, œÉ)
= 1[‚àí10,10]( ÀúŒº) ¬∑ 1[0,‚àû)(ÀúœÉ) ¬∑ œÉ n
ÀúœÉ n
¬∑ exp

‚àí1
2ÀúœÉ 2
n

i=1
(xi ‚àíÀúŒº)2 ‚àíÀúœÉ +
1
2œÉ 2
n

i=1
(xi ‚àíŒº)2 + œÉ

for all ÀúŒº, ÀúœÉ ‚ààR and all Œº ‚àà[‚àí10, 10] and œÉ ‚â•0. Here we can assume that Œº and œÉ
are inside the valid parameter range (and thus can omit the corresponding indicator
functions in the denominator), because Œ±(Œº, œÉ, ÀúŒº, ÀúœÉ) only needs to be deÔ¨Åned for
(Œº, œÉ) with œÄ(Œº, œÉ) > 0. Finally, substituting these expressions into equation (4.23)
we get the acceptance probability for the random walk Metropolis algorithm for this
example:
Œ±(Œº, œÉ, ÀúŒº, ÀúœÉ)
= min

1[‚àí10,10]( ÀúŒº) ¬∑ 1[0,‚àû)(ÀúœÉ) ¬∑ œÉ n
ÀúœÉ n
¬∑ exp

‚àí1
2ÀúœÉ 2
n

i=1
(xi ‚àíÀúŒº)2 ‚àíÀúœÉ +
1
2œÉ 2
n

i=1
(xi ‚àíŒº)2 + œÉ

, 1

In order to apply the random walk Metropolis algorithm as given in algorithm
4.9, we have to choose a distribution for the increments Œµ j. This choice affects
the efÔ¨Åciency of the resulting MCMC method. For simplicity we choose here Œµ j ‚àº
N(0, œÉ 2Ip) where Ip is the p-dimensional identity matrix. The parameter œÉ 2 can be
used to tune the method for efÔ¨Åciency as described in Section 4.2.2. This leads to the
following algorithm:
1: choose a Œ∏0 with œÄ(Œ∏0) > 0
2: for j = 1, 2, 3, . . . do
3:
generate Œµ j ‚àºN(0, œÉ 2Ip)
4:
ÀúŒ∏ j ‚ÜêŒ∏ j‚àí1 + Œµ j
5:
compute a = Œ±(Œ∏ j‚àí1, ÀúŒ∏ j) using (4.23) and (4.24)
6:
generate U j ‚àºU[0, 1]
7:
if U j ‚â§a then
8:
Œ∏ j ‚ÜêÀúŒ∏ j
9:
else
10:
Œ∏ j ‚ÜêŒ∏ j‚àí1
11:
end if
12: end for

MARKOV CHAIN MONTE CARLO METHODS
141
From proposition 4.3 we know that the output of this algorithm is a Markov chain
with stationary distribution œÄ = pŒ∏|X(¬∑ | x), that is that it generates samples from the
posterior distribution in our Bayesian parameter estimation problem. Using corollary
4.23 and example 4.24 we the Ô¨Ånd that
E

f (Œ∏)
 X = x
	
= lim
N‚Üí‚àû
1
N
N

j=1
f

Œ∏ j
	
.
This convergence holds for every initial value Œ∏0 with œÄ(Œ∏0) > 0. Thus we have solved
the given estimation problem.
While the MCMC method works for every initial value Œ∏0, we have seen in
Section 4.2.2 that convergence of the results can be improved if Œ∏0 is chosen inside
a region where the target distribution œÄ is large. If a classical point estimate ÀÜŒ∏n =
ÀÜŒ∏n(x1, . . . , xn) for Œ∏ is available, Œ∏0 = ÀÜŒ∏n will often be a good choice.
Many generalisations of the methodology presented in this section are possible:
if some of the parameters or the observations are discrete instead of continuous,
very similar methods can be derived by replacing the corresponding densities with
probability weights. Also, MCMC methods can be used for Bayesian inference where
the models have a more complex structure than in the situation of the present section.
Examples of such situations can be found in Sections 4.4.2 (mixture model with
known number of components) and 4.5.2 (mixture model with unknown number of
components).
4.4
The Gibbs sampler
The Gibbs sampler is an MCMC method which can be used if the state space has a
product structure. It is based on the idea of updating the different components of the
state one at a time, thus potentially reducing a high-dimensional sampling problem
to a sequence of more manageable, low-dimensional sampling problems.
4.4.1
Description of the method
The Gibbs sampler is applicable in situations where the state space S can be written
as a Ô¨Ånite product of spaces, that is where we have
S = S1 √ó S2 √ó ¬∑ ¬∑ ¬∑ √ó Sn.
Elements of this space are vectors x = (xi)i=1,2,...,n where xi ‚ààSi for every i. Situa-
tions where the Gibbs sampler can be applied include:
r In Bayesian parameter estimation problems, n is typically small, say 2 or 3,
and often the spaces Si have different dimensions. We will study examples of
this type in Section 4.4.2.

142
AN INTRODUCTION TO STATISTICAL COMPUTING
r In applications from statistical mechanics or image processing, n is typically
large but all spaces Si are the same. In this case we write
S = C I
where I = {1, 2, . . . , n} and C is the state space for the individual components.
We will see examples of such situations in Section 4.4.3.
As with other MCMC methods, our aim is to construct a Markov chain
with a given distribution œÄ on S as its stationary distribution. In algorithm 4.27
we use the conditional distribution of a single component Xi of X ‚ààS, condi-
tioned on the values of all other components and we denote this distribution by
œÄXi|X¬¨i(¬∑ | x1, . . . , xi‚àí1, xi+1, . . . , xn). Here, X¬¨i stands for X with the component Xi
left out. In the case of discrete state space Si, the conditional distribution of Xi is given
by probability weights œÄXi|X¬¨i whereas, if Si is continuous, œÄXi|X¬¨i is normally given
as a probability density. To simplify notation, in this section we write the time of the
Markov chain as an upper index, so that X( j)
i
corresponds to the value of component
i ‚ààI of the Markov chain X at time j ‚ààN0. Using this notation, the general Gibbs
sampler algorithm takes the following form.
Algorithm 4.27
(Gibbs sampler)
input:
a distribution œÄ = œÄX1,...,Xn
initial state X0 ‚ààS = S1 √ó S2 √ó ¬∑ ¬∑ ¬∑ √ó Sn
randomness used:
samples from the distributions œÄXi|X¬¨i(¬∑ | x1, . . . , xi‚àí1, xi+1, . . . , xn)
output:
a sample of a Markov chain (X( j)) j‚ààN with stationary distribution œÄ
1: for j = 1, 2, 3, . . . do
2:
let m ‚Üê( j ‚àí1 mod n) + 1
3:
generate
Œæ ( j) ‚àºœÄXm|X¬¨m(¬∑ | X( j‚àí1)
1
, . . . , X( j‚àí1)
m‚àí1 , X( j‚àí1)
m+1 , . . . , X( j‚àí1)
n
)
4:
deÔ¨Åne X( j) ‚ààS by
X( j)
i
=

X( j‚àí1)
i
if i Ã∏= m and
Œæ ( j)
otherwise
for all i = 1, 2, . . . , n.
5: end for

MARKOV CHAIN MONTE CARLO METHODS
143
The index m = ( j ‚àí1 mod n) + 1 constructed in step 2 of algorithm 4.27
periodically cycles through the components 1, 2, . . . , n as j increases. Alternative
versions of the Gibbs sampler algorithm can be constructed where the index m ‚àà
{1, . . . , n} is chosen randomly in each iteration of the loop in algorithm 4.27
instead.
Proposition 4.28
The process (X( j)) j‚ààN constructed by algorithm 4.27 is a Markov
chain with stationary density œÄ.
Proof
Since in each step of the algorithm X( j) is constructed from X( j‚àí1) and
additional randomness, the process X = (X( j)) j‚ààN is a Markov chain starting in X0.
Assume X j‚àí1 ‚àºœÄ. Then
X( j‚àí1)
¬¨m
= (X( j‚àí1)
1
, . . . , X( j‚àí1)
m‚àí1 , X( j‚àí1)
m+1 , . . . , X( j‚àí1)
n
) ‚àºœÄ¬¨m.
The construction of X( j)
m = Œæ ( j) in line 3 of the algorithm depends on the values of
the components of X( j‚àí1)
¬¨m
. Assuming the distribution of the components X( j)
i
has a
density, we can integrate over all possible values of X( j‚àí1)
¬¨m
to Ô¨Ånd
P(X( j)
1
‚ààA1, . . . , X( j)
n
‚ààAn)
=

 
1A1√ó¬∑¬∑¬∑√óAn(x1, . . . , xn)
¬∑ œÄXm|X¬¨m(xm | x¬¨m) dxm
¬∑ œÄX¬¨m(x¬¨m) dx1 ¬∑ ¬∑ ¬∑ dxm‚àí1 dxm+1 ¬∑ ¬∑ ¬∑ dxn
=

 
1A1√ó¬∑¬∑¬∑√óAn(x1, . . . , xn) ¬∑ œÄX1,...,Xm(x1, . . . , xm) dx1 ¬∑ ¬∑ ¬∑ dxn.
This shows that (X( j)
1 , . . . , X( j)
n ) has density œÄ = œÄX1,...,Xm as required. If the distri-
bution of the X( j)
i
is given by probability weights instead of densities, the same result
can be obtained by replacing the integrals over densities with sums over probability
weights.
Example 4.29
Let A ‚äÜR2 be a set with area |A| < ‚àûand let X be uniformly
distributed on A, that is X ‚àºœÄ where the density œÄ is given by
œÄ(x) = 1
|A|1A(x)

144
AN INTRODUCTION TO STATISTICAL COMPUTING
for all x ‚ààR2. Writing the state space R2 as R √ó R, we can apply the Gibbs sampler
from algorithm 4.27 to generate samples from the distribution of X. Using equation
(A.5), we can Ô¨Ånd the conditional density of X1 given X2 = x2 ‚ààR as
œÄX1|¬¨X1(x1 | x2) = œÄX1|X2(x1 | x2)
=
œÄ(x1, x2)

R œÄ(Àúx1, x2) d Àúx1
=
1
|A|1A(x1, x2)

R
1
|A|1A(Àúx1, x2) d Àúx1
=
1
Àúx1
 (Àúx1, x2) ‚ààA
1{Àúx1|(Àúx1,x2)‚ààA}(x1)
for all x1 ‚ààR. Thus, œÄX1|¬¨X1 is the density of the uniform distribution on the set
Àúx1
 (Àúx1, x2) ‚ààA

, that is on the ‚Äòslice‚Äô of A where the second coordinate is Ô¨Åxed to
x2. Similarly, the density œÄX2|¬¨X2 = œÄX2|X1 transpires to be the density of the uniform
distribution on the ‚Äòslice‚Äô
Àúx2
 (x1, Àúx2) ‚ààA

, where the Ô¨Årst coordinate is Ô¨Åxed to
the value x1. Thus, the Gibbs sampler for œÄ takes the following form:
1: for j = 1, 2, 3, . . . do
2:
if j is odd then
3:
generate Œæ ( j) ‚àºU

x1
 (x1, X( j‚àí1)
2
) ‚ààA

4:
X( j) ‚Üê

Œæ ( j), X( j‚àí1)
2

5:
else
6:
generate Œæ ( j) ‚àºU

x2
 (X( j‚àí1)
1
, x2) ‚ààA

7:
X( j) ‚Üê

X( j‚àí1)
1
, Œæ ( j)
8:
end if
9: end for
From Lemma 1.33 we know that we can generate samples X with density f by
sampling (X, Y) from the uniform distribution on the set
A =

(x, y) ‚ààR √ó [0, ‚àû)
 0 ‚â§y < f (x)

‚äÜR2.
Such samples can be obtained using the Gibbs sampler as explained in the Ô¨Årst part
of this example. The resulting method and its higher dimensional variants are known
as the slice sampler.
Despite the fact that the Gibbs sampler from algorithm 4.27 does not contain
a rejection mechanism, the algorithm is a special case of the Metropolis‚ÄìHastings
algorithm with different move types as introduced in Section 4.1.5. To see this,
consider the Metropolis‚ÄìHastings algorithm with move types M = {0, 1, . . . , n ‚àí1}.

MARKOV CHAIN MONTE CARLO METHODS
145
Assume that the algorithm, at time j, always performs a move of type m = j mod n
by constructing the proposal Y from the current state X as
Yi =

Xi
for i Ã∏= m and
Œæ
for i = m
for i = 1, 2, . . . , n, where
Œæ ‚àºœÄXm|X¬¨m(¬∑ | X1, . . . , Xm‚àí1, Xm+1, . . . , Xn).
The random variable Y, given X, is concentrated on the subspace {X1} √ó ¬∑ ¬∑ ¬∑ √ó
{Xm‚àí1} √ó Sm √ó {Xm+1} √ó ¬∑ ¬∑ ¬∑ √ó {Xn}. Thus, Y has no density but instead we are in
the situation of lemma 4.15. If we let
Cm =

(x, y) ‚ààS √ó S
 xi = yi for all i Ã∏= m
 ‚àº= S √ó Sm,
we have (X, Y) ‚ààCm with probability 1 and, assuming X ‚àºœÄ,
P(Y ‚ààB, X ‚ààA)
=

S
œÄ(x)1A(x)

Sm
œÄXm|X¬¨m(ym | x¬¨m)
¬∑ 1B (x1, . . . , xm‚àí1, ym, xm+1, . . . , xn) dym dx1 ¬∑ ¬∑ ¬∑ dxn.
Thus, the pair (X, Y) has density œï(x, ym) = œÄ(x) œÄXm|X¬¨m(ym | x¬¨m) on Cm. From
lemma 4.15 we know now that we should choose the acceptance probability Œ±m(x, y)
for this move type as
Œ±m(x, y) = min
Œ≥m(y) œï(y, x)
Œ≥m(x) œï(x, y), 1

= min
Œ≥m(y) œÄ(y) œÄXm|X¬¨m(xm | y¬¨m)
Œ≥m(x) œÄ(x) œÄXm|X¬¨m(ym | x¬¨m), 1

Since all possible transitions from x to y satisfy x¬¨m = y¬¨m, the acceptance proba-
bilities can be rewritten as
Œ±m(x, y) = min
Œ≥m(y) œÄ(y) œÄXm|X¬¨m(xm | x¬¨m)
Œ≥m(x) œÄ(x) œÄXm|X¬¨m(ym | y¬¨m), 1

= min
œÄ(y) œÄXm|X¬¨m(xm | x¬¨m) œÄX¬¨m(x¬¨m)
œÄ(x) œÄXm|X¬¨m(ym | y¬¨m) œÄX¬¨m(y¬¨m), 1

= min
œÄ(y) œÄXm,X¬¨m(xm, x¬¨m)
œÄ(x) œÄXm,X¬¨m(ym, y¬¨m), 1

= min
œÄ(y) œÄ(x)
œÄ(x) œÄ(y), 1

= 1.

146
AN INTRODUCTION TO STATISTICAL COMPUTING
Thus, moves of type m will always be accepted and no rejection step is necessary.
The resulting algorithm is identical with the Gibbs sampler from algorithm 4.27.
4.4.2
Application to parameter estimation
In this section we illustrate the use of the Gibbs sampler in Bayesian inference, by
considering the problem of sampling from the posterior distribution of the parameters
in a mixture distribution, given a random sample from the mixture. The difference
compared with the more generic Bayesian parameter estimation problems considered
in Section 4.3 is that here we can make use of the hierarchical structure of the
mixture distribution to derive a specialised MCMC algorithm for the problem under
consideration.
Let k ‚ààN and œÉ > 0 be Ô¨Åxed and let Œº1, . . . , Œºk ‚àºœïŒº be independent random
vectors in Rd, where we assume the distribution œïŒº to have a density. Given Œº =
(Œº1, . . . , Œºk), let X1, . . . , Xn be an i.i.d. sample from the mixture distribution
œïX|Œº = 1
k
k

a=1
N(Œºa, œÉ Id),
where the mixture components are normal distribution with mean Œºa and covariance
matrix œÉ Id and where Id denotes the d-dimensional identity matrix. In the later parts
of this example we will restrict ourselves to the case d = 2 and we will assume that,
under the prior distribution, Œº1, . . . , Œºk ‚àºU ([‚àí10, +10] √ó [‚àí10, +10]) i.i.d., that
is we will assume that the prior density for the cluster means Œºa is given by
œïŒº(Œºa) =
1
202 1[‚àí10,10]√ó[‚àí10,10](Œºa).
(4.25)
for all Œºa ‚ààR2.
Our aim is to generate samples from the posterior distribution of the Œºa, that is
from the conditional distribution of Œº1, . . . , Œºk given observations Xi = xi ‚ààRd for
i = 1, 2, . . . , n. This target distribution has density
pŒº|X(Œº | x) = pX|Œº(x | Œº) pŒº(Œº)
pX(x)
.
(4.26)
In this section we will explain how the Gibbs sampling algorithm 4.27 can be used
to generate samples from this density.
We can extend the state space of the model by introducing new variables Yi ‚àà
{1, 2, . . . , k} to indicate which component the values Xi belongs to: for this we
generate Xi in a two-step procedure by Ô¨Årst generating Yi ‚àºU{1, 2, . . . , k} and

MARKOV CHAIN MONTE CARLO METHODS
147
then generating Xi ‚àºN(ŒºYi, œÉ Id). Using this approach, the joint distribution of the
vectors Œº = (Œº1, . . . , Œºk), Y = (Y1, . . . , Yn) and X = (X1, . . . , Xn) is given by
pŒº,Y,X(Œº, y, x) =
k
a=1
œïŒº(Œºa) ¬∑
n
i=1
1
k œà(xi; Œºyi, œÉ Id)
for all Œº ‚àà(Rd)k, y ‚àà{1, . . . , k}n and x ‚àà(Rd)n, where the term 1/k gives the
probability P(Yi = yi) and œà(¬∑; Œºyi, œÉ Id), given by
œà(Œæ; Œº, œÉ Id) =
1
(2œÄœÉ 2)d/2 exp

‚àí|Œæ ‚àíŒº|2
2œÉ 2

(4.27)
for all Œæ ‚ààRd, is the density of the normal distribution N(Œº, œÉ Id) and | ¬∑ | denotes
the Euclidean norm in Rd. In this extended model, both Œº and Y are unknown and
we want to sample from the conditional distribution of (Œº, Y) ‚àà(Rd)k √ó {1, . . . , k}n,
given a sample x ‚àà(Rd)n of X.
To solve this extended sampling problem we can use the Gibbs sampler with state
space S = S1 √ó S2 where S1 = (Rd)k and S2 = {1, . . . , k}n. The resulting version of
algorithm 4.27 requires us to alternatingly generate samples
Œº( j) ‚àºpŒº|Y,X

¬∑
Y ( j‚àí1), x
	
and
Y ( j) ‚àºpY|Œº,X

¬∑
Œº( j‚àí1), x
	
.
The densities pŒº|Y,X and pY|Œº,X can be found using Bayes‚Äô rule: for pŒº|Y,X we have
pŒº|Y,X(Œº | y, x) = pŒº,Y,X(Œº, y, x)
pY,X(y, x)
=
k
a=1 œïŒº(Œºa) ¬∑ n
i=1
1
k œà(xi; Œºyi , œÉ Id)
pY,X(y, x)
=
1
Z y,x
k
a=1
‚éõ
‚éú‚éùœïŒº(Œºa) ¬∑
n
i=1
yi =a
œà(xi; Œºa, œÉ Id)
‚éû
‚éü‚é†
(4.28)
for all Œº ‚àà(Rd)k, where we grouped the factors œà(xi; Œºyi , œÉ Id) according to the
values of yi and Z y,x is the normalisation constant which makes the function
pŒº|Y,X(¬∑ | y, x) a probability density. Since the right-hand side of (4.28) is the product
of individual functions of Œºa for a = 1, 2, . . . , k, under the conditional distribution

148
AN INTRODUCTION TO STATISTICAL COMPUTING
pŒº|Y,X the components Œº1, . . . , Œºk are independent with densities given by the cor-
responding factors in the product. Using a similar calculation, we Ô¨Ånd the density
pY|Œº,X as
pY|Œº,X(y | Œº, x) = pŒº,Y,X(Œº, y, x)
pŒº,X(Œº, x)
=
k
a=1 œïŒº(Œºa) ¬∑ n
i=1
1
k œà(xi; Œºyi, œÉ Id)
pŒº,X(Œº, x)
=
1
ZŒº,x
n
i=1
œà(xi; Œºyi, œÉ Id)
for all y ‚àà{1, 2, . . . , k}n, where ZŒº,k is the normalisation constant. Since the right-
hand side is a product where each factor only depends on one of the components yi,
under the conditional distribution pY|Œº,X the components Y1, . . . , Yn are independent
with weights
P(Yi = a | Œº, X) =
œà(Xi; Œºa, œÉ Id)
k
Àúa=1 œà(Xi; ŒºÀúa, œÉ Id)
(4.29)
for a = 1, 2, . . . , k and for all i = 1, 2, . . . , n, where the density œà is given by (4.27).
To be more speciÔ¨Åc, we now restrict ourselves to the case d = 2 and we consider
the prior density œïŒº given by (4.25). Then, using equation (4.28) and the deÔ¨Ånition
of œà from (4.27), we Ô¨Ånd the conditional density of Œºa given Y and X as
pŒºa|Y,X(Œºa | y, x) = 1
Z1
œïŒº(Œºa)
n
i=1
yi =a
œà(xi; Œºa, œÉ I2)
= 1
Z1
œïŒº(Œºa)
n
i=1
yi =a
1
2œÄœÉ 2 exp

‚àí|xi ‚àíŒºa|2
2œÉ 2

= 1
Z2
œïŒº(Œºa) exp
‚éõ
‚éú‚éù‚àí
n

i=1
yi =a
|xi ‚àíŒºa|2
2œÉ 2
‚éû
‚éü‚é†
= 1
Z3
œïŒº(Œºa) exp
‚éõ
‚éú‚éù‚àína
2œÉ 2 ¬∑ |Œºa|2 + na
2œÉ 2 ¬∑ 2‚ü®Œºa, 1
na
n

i=1
yi =a
xi‚ü©
‚éû
‚éü‚é†,
where Z1, Z2 and Z3 are normalisation constants, na = n
i=1 1{a}(yi), and | ¬∑ | and
‚ü®¬∑, ¬∑‚ü©denote the Euclidean norm and inner product on R2, respectively. Completing

MARKOV CHAIN MONTE CARLO METHODS
149
the square in the exponent and substituting the deÔ¨Ånition of œïŒº from Equation (4.25)
we Ô¨Ånd
pŒºa|Y,X(Œºa | y, x)
= 1
Z4
1[‚àí10,+10]√ó[‚àí10,+10](Œºa) exp
‚éõ
‚éú‚éù‚àí
1
2œÉ 2/na

Œºa ‚àí1
na
n

i=1
yi =a
xi

2‚éû
‚éü‚é†,
(4.30)
where Z4 is the resulting normalisation constant. Thus, pŒºa|Y,X is the density of the
two-dimensional normal distribution N

1
na
n
i=1 1{a}(yi)xi, œÉ 2
na I2

, conditioned on
the value lying in the square [‚àí10, +10] √ó [‚àí10, +10]. Samples from this condi-
tional distribution can be easily generated using the rejection sampling algorithm
1.25 for conditional distributions, that is by repeatedly sampling from the uncondi-
tioned normal distribution and rejecting all values which fall outside the square. The
representation from (4.30) for pŒºa|Y,X is only deÔ¨Åned for na > 0. In the case na = 0
we have no observations corresponding to the mean Œºa and consequently for this
case pŒºa|Y,X coincides with the prior distribution œïŒº.
As we have already seen, the components of the vector Y under the distribution
pY|Œº,X are independent. Their distribution is found by substituting (4.27) for d = 2
into equation (4.29).
Now that we have identiÔ¨Åed the conditional distributions pŒº|Y,X and pY|Œº,X, we
can implement the Gibbs sampler from algorithm 4.27 to sample from the posterior
distribution of Œº and Y as follows:
1: for a = 1, 2, . . . , k do
2:
generate Œº(0)
a ‚àºU ([‚àí10, 10] √ó [‚àí10, 10])
3: end for
4: for i = 1, 2, . . . , n do
5:
generate Y (0)
i
‚àºU{1, 2, . . . , k}
6: end for
7: for j = 1, 2, 3, . . . do
8:
if j is odd then
9:
for a = 1, 2, . . . , k do
10:
na ‚Üên
i=1 1{a}(Y ( j‚àí1)
i
)
11:
repeatedly generate Œæ ( j) ‚àºN

1
na
n
i=1 1{a}(yi)xi, œÉ 2
na I2

,
until Œæ ( j) ‚àà[‚àí10, +10] √ó [‚àí10, +10]
12:
Œº( j)
a
‚ÜêŒæ ( j)
13:
end for
14:
Y ( j) ‚ÜêY ( j‚àí1)
15:
else
16:
Œº( j) ‚ÜêŒº( j‚àí1)
17:
for i = 1, 2, . . . , n do
18:
for a = 1, 2, . . . , k do

150
AN INTRODUCTION TO STATISTICAL COMPUTING
19:
qa ‚Üê
1
2œÄœÉ 2 exp

‚àí|Œæi‚àíŒº( j‚àí1)
a
|2
2œÉ 2

20:
end for
21:
generate Y ( j)
i
‚àà{1, 2, . . . , k} with P(Y ( j)
i
= a) = qa/ k
b=1 qb
22:
end for
23:
end if
24: end for
The implementation of the Gibbs sampler presented here is based on the following
considerations:
r We need to decide how to generate the initial values for Œº(0) and Y (0). In the
implementation given above we generate Œº(0) from the prior distribution. Since
there is no prior distribution for the auxiliary variables Y (0), we use the uniform
distribution on the set {1, 2, . . . , k} of allowed values instead.
r We need to alternatingly update Œº and Y. In the implementation above we
update Œº when j is odd and we update Y when j is even.
r In step 11 of the algorithm some care is needed when na = 0, that is when
there are no observations corresponding to cluster a. In this case the normal
distribution must be replaced by the prior distribution œïŒº.
r Since the distribution of Œº( j) only converges to the posterior distribution pŒº|X
from (4.26) as j ‚Üí‚àû, a burn-in period should be implemented by discarding
the Ô¨Årst samples.
The result of a run of the Gibbs sampler presented above is shown in Figure 4.5.
In proposition 4.28 we have seen that the target distribution œÄ = pŒº|X from
equation (4.26) is indeed a stationary distribution of the Markov chain constructed
by the algorithm described in this section, and often the distribution of the resulting
Markov chain converges to a plausible posterior sample quickly. This is illustrated
in Figure 4.5 where after only 100 steps of burn-in period the samples for the Ô¨Åve
cluster means Œºa are all centred well inside the Ô¨Åve clusters. Nevertheless, it takes an
extremely long time for the Markov chain to explore the complete state space. This
can be seen by the fact that the posterior distribution is invariant under relabelling
the cluster means and thus, in stationarity, each of the Ô¨Åve cluster means should be
found in any of the Ô¨Åve clusters with equal probability. In the simulation depicted in
Figure 4.5, no transition of cluster means between clusters is observed and indeed
such transitions will not be observed in any runs of realistically achievable length.
The Markov chain generated by the algorithm converges to its stationary distri-
bution very slowly. As a consequence, it is possible for the algorithm to get ‚Äòstuck‚Äô
in states which have low probability but where all ‚Äòclose by‚Äô states have even lower
probability. Such states are called metastable states and, while the algorithm will
eventually escape from such states, this can take an extremely long time and thus
may not happen in practice. Such a problem is illustrated by Figure 4.6, where during
the burn-in period two components of Œº moved into the same cluster, leaving a third
component to ‚Äòcover‚Äô two clusters. For typical samples from the posterior distribution

MARKOV CHAIN MONTE CARLO METHODS
151
‚àí10
‚àí5
0
5
10
‚àí10
‚àí5
0
5
10
Xi, 2
Xi, 1
Figure 4.5
A typical sample of size 100 from the posterior distribution (4.26) of
the cluster means for the parameter estimation problem described in Section 4.4.2.
The grey circles give the positions of the observations X1, . . . , X100, the Ô¨Åve different
kinds of smaller, black symbols give the positions of Œº( j)
a
for j = 1, 2, . . . , 100 and
a = 1, . . . , 5. A burn-in period of length 1000 has been used for this Ô¨Ågure.
we would expect the components of Œº to be distributed such that each cluster contains
exactly one of them, but numerical experiments show that the Markov chain needs
an extremely (and unachievably) long time to reach states resembling this situation.
Thus, as for any MCMC method, the output of the Gibbs sampler needs to be carefully
checked to verify that the distribution of the output is sufÔ¨Åciently close to stationarity.
4.4.3
Applications to image processing
In this section we illustrate the Gibbs sampler using an application to a simple image
processing problem. Here we will represent images as a square grid of ‚Äòpixels‚Äô (short
for ‚Äòpicture elements‚Äô), each of which takes values in the two-element set {‚àí1, +1}
where ‚àí1 stands for a white pixel and the value +1 stands for a black pixel. Thus,
images in this setup are considered to be elements of the product space
S = {‚àí1, +1}I,
(4.31)

152
AN INTRODUCTION TO STATISTICAL COMPUTING
‚àí10
‚àí5
0
5
10
‚àí10
‚àí5
0
5
10
Xi, 2
Xi, 1
Figure 4.6
A sample of size 100, similar to Figure 4.5 but using a different seed
of the random number generator. Different from Figure 4.5, the Markov chain here
has not yet converged to the stationary distribution, despite the presence of a burn-in
period of length 10 000: two components of Œº, represented by the symbols √ó and ‚ãÑ,
are concentrated in one cluster while the component + is situated in the gap between
two clusters. This Ô¨Ågure was created by selecting one of a large number of runs of
the algorithm.
where I is the lattice
I = {1, 2, . . . , L} √ó {1, 2, . . . , L}.
The elements of S are vectors of the form x = (xi)i‚ààI. States x ‚ààS can be visualised
as square grids of small black and white dots, where the colour at location i ‚ààI in
the grid encodes the possible values ‚àí1 and +1 for xi.
DeÔ¨Ånition 4.30
A probability measure on S where the weights are written in the
form
œÄ(x) = 1
Z exp (‚àíH(x))
(4.32)

MARKOV CHAIN MONTE CARLO METHODS
153
for all x ‚ààS is called a Gibbs measure. The function H: S ‚ÜíR is called the energy
and the normalisation constant
Z =

x‚ààS
exp (‚àíH(x))
is called the partition function.
4.4.3.1
The Ising model
The Ising model is a model from statistical mechanics which describes the distribution
of random elements X ‚ààS where the state space S is of the form given by (4.31).
Motivated by the situation of image processing, we restrict ourselves to the two-
dimensional case I ‚äÜZ2, but we note that everything in this section can be easily
generalised to the case I ‚äÜZd for d ‚ààN. For the Ising model, the distribution of X
is assumed to be a Gibbs measure, as described in equation (4.32), where the energy
H is given by
H(x) = ‚àíŒ≤

i, j‚ààI
i‚àºj
xix j
(4.33)
for all x ‚ààS. Here we write i ‚àºj to indicate that i, j ‚ààI are nearest neighbours
and the sum in the deÔ¨Ånition of H is taken over all pairs of nearest neighbours
in the grid. The constant Œ≤ > 0 is called the inverse temperature. The model can
be considered for different deÔ¨Ånitions of ‚Äòneighbouring‚Äô pixels. Here we consider
only nearest neighbours, that is we consider a pixel i = (i1, i2) in the interior of the
grid to have neighbours (i1 + 1, i2), (i1, i2 + 1), (i1 ‚àí1, i2) and (i1, i2 ‚àí1). Pixels
on the edges of the grid are considered to have only three neighbours and the four
corner pixels have only two neighbours. An alternative approach, often chosen to
avoid complications in theoretical analysis, would be to extend the grid periodically
or, equivalently, to consider the left-most column to be adjacent to the right-most
column and the top-most row to be adjacent to the bottom-most row.
Samples X from the Ising model for different values of Œ≤ are depicted in Figure
4.7. The Ô¨Ågure clearly shows that with increasing Œ≤ the tendency of neighbouring
pixels to have the same colour increases.
To apply the Gibbs sampler from algorithm 4.27 in this situation, we need to Ô¨Ånd
the conditional distributions œÄXm|X¬¨m, that is we need to Ô¨Ånd the distribution of the
state Xm of one pixel, given the state X¬¨m of all the other pixels. Using Bayes‚Äô rule
we get
œÄXm|X¬¨m(xm | x¬¨m) = œÄXm,X¬¨m(xm, x¬¨m)
œÄX¬¨m(x¬¨m)
=
œÄXm,X¬¨m(xm, x¬¨m)
œÄXm,X¬¨m(‚àí1, x¬¨m) + œÄXm,X¬¨m(+1, x¬¨m).
(4.34)

154
AN INTRODUCTION TO STATISTICAL COMPUTING
Œ≤ = 0.3
Œ≤ = 0.34
Œ≤ = 0.38
Œ≤ = 0.42
Œ≤ = 0.46
Œ≤ = 0.5
(a)
(b)
(c)
(d)
(e)
(f)
Figure 4.7
Samples from the Ising model given by equation (4.32) and equation
(4.33), on the grid I = {1, 2, . . . , 150}2, for different values of Œ≤. The panels show
the Ô¨Ånal state X(N) of the Gibbs sampling algorithm 4.31, for N = 10 000 √ó 1502.

MARKOV CHAIN MONTE CARLO METHODS
155
Here, œÄXm,X¬¨m(xm, x¬¨m) = œÄX(x) is the probability of the state x. Using equation
(4.32) and equation (4.33) we can write this probability as
œÄ(x) = 1
Z exp
‚éõ
‚éú‚éùŒ≤

i, j‚ààI
i‚àºj
xix j
‚éû
‚éü‚é†
= 1
Z exp
‚éõ
‚éùŒ≤ xm

i‚ààI
i‚àºm
xi
‚éû
‚é†exp
‚éõ
‚éú‚éùŒ≤

i, j‚ààI
i‚àºj,iÃ∏=m, jÃ∏=m
xix j
‚éû
‚éü‚é†.
Since both Z and the Ô¨Ånal factor do not depend on the value of xm, the corresponding
terms in the numerator and denominator of equation (4.34) cancel and we get
œÄXm|X¬¨m(xm | x¬¨m) =
exp

xm Œ≤ 
i‚àºm xi
	
exp

Œ≤ 
i‚àºm xi
	
+ exp

‚àíŒ≤ 
i‚àºm xi
	.
(4.35)
These are the required conditional probabilities to generate the new value Œæ j for
location j ‚ààI in step 3 of the Gibbs sampler algorithm 4.27. The probabilities can
be computed using only the values of the image at the (up to) four neighbours of j.
Thus, the update step in the Gibbs algorithm for the Ising model can be performed
very efÔ¨Åciently.
Algorithm 4.31
(Gibbs sampler for the Ising model)
input:
Œ≤ ‚â•0 (the inverse temperature)
X0 ‚àà{‚àí1, +1}I (the initial state)
output:
a path of a Markov chain with the Gibbs measure from (4.32) and (4.33) as its
stationary distribution
randomness used:
independent samples Œæ ( j) ‚àà{‚àí1, +1} for j ‚ààN
1: for j = 1, 2, 3, . . . do
2:
m1 ‚Üê(( j ‚àí1) mod L) + 1
3:
m2 ‚Üê(‚åä( j ‚àí1)/L‚åãmod L) + 1
4:
d ‚ÜêX( j‚àí1)
m1‚àí1,m2 + X( j‚àí1)
m1+1,m2 + X( j‚àí1)
m1,m2‚àí1 + X( j‚àí1)
m1,m2+1
5:
p ‚Üê
1
1+exp(‚àí2Œ≤d)
6:
Generate Œæ ( j) ‚àà{‚àí1, +1} such that P

Œæ ( j) = +1
	
= p.
7:
DeÔ¨Åne X( j) ‚ààS by
X( j)
i
=

X( j‚àí1)
i
if i Ã∏= (m1, m2) and
Œæ ( j)
otherwise
for all i ‚ààI.
8: end for

156
AN INTRODUCTION TO STATISTICAL COMPUTING
In steps 2 and 3 of the algorithm, a pixel position m = (m1, m2) is constructed
such that m cycles through all possible pixel positions cyclically. When implementing
step 4 of the algorithm, some care is needed when m is on the edge of the grid I:
we set Xi = 0 for all i /‚ààI. The result of different simulations using this algorithm
is shown in Figure 4.7.
As a direct consequence of proposition 4.28, the distribution of the Ising model,
given by equation (4.32) and equation (4.33) is a stationary distribution of the Markov
chain X constructed by algorithm 4.31. Using the results from Section 4.2.1, it is
easy to check that the Markov chain constructed in algorithm 4.31 is irreducible and
aperiodic and thus the distribution of X( j) converges to the exact distribution of the
Ising model for every initial condition X(0).
The Ising model is well-studied in statistical mechanics and nearly everything
about the behaviour of the model is known. For example, a well-known result is that
for large grid sizes the behaviour of the system changes when the inverse temperature
crosses the critical value
Œ≤‚àó= log(1 +
‚àö
2)
2
‚âà0.44
(see e.g. Pathria, 1996, Section 12.3). For Œ≤ < Œ≤‚àótypical states consist of a‚Äòpatchwork
pattern‚Äô of mostly white and mostly black regions. This pattern is visible in Figure
4.7(a‚Äìd). For Œ≤ > Œ≤‚àótypical states are dominated by one colour, showing only
isolated ‚Äòspecks‚Äô of the opposite colour. This pattern is shown by Figure 4.7(e)
and (f). By symmetry, the Markov chain will be in predominantly white states and
predominantly black states for approximately equal amounts of time. Transitions
between these two patterns take an extremely long time and will not be observed in
practice but, for Ô¨Ånite grid size, it is easy to show that the Markov chain is irreducible
and thus, by the results from Section 4.2.1, transitions will happen on long time-scales.
In contrast, for the extension of the Ising model to an inÔ¨Ånite grid such transitions no
longer happen. This change of behaviour of the system when Œ≤ crosses the critical
point Œ≤‚àóis an example of a phase transition and is of great interest in statistical
physics. In particular, many interesting and difÔ¨Åcult results concern the behaviour of
the system at the critical point Œ≤ = Œ≤‚àó.
4.4.3.2
Bayesian image analysis
We will now consider an application of Bayesian inference to the denoising of images.
For this setup we assume that the original image X is described by a probability
distribution on the space of all possible images, and that we have observed a noisy
version Y of this image. Our aim is to reconstruct the original image X from the
observation Y.
For simplicity we assume that we are in the situation of the preceding section, that
is that the original image is square and consists only of black and white pixels. Thus
we have X ‚ààS where S is the state space given in Equation (4.31) at the beginning of
this section. We also assume that the prior distribution of the original image X is given

MARKOV CHAIN MONTE CARLO METHODS
157
by the Ising model from equation (4.32) and equation (4.33). Finally, for the noisy
observation Y of the image X we assume that independent, N(0, œÉ 2)-distributed
random variables are added to every pixel of X, that is we have Y ‚ààRI and the
conditional distribution of Yi given the value of X is
Yi ‚àºN(Xi, œÉ 2)
for all i ‚ààI, independently.
Using this model, the posterior distribution of X given the observations Y is found
using Bayes‚Äô rule as
pX|Y(x | y) = pY|X(y | x) pX(x)
pY(y)
=
1
pY(y)

i‚ààI
1
‚àö
2œÄœÉ 2 ¬∑ exp

‚àí(yi ‚àíxi)2
2œÉ 2

¬∑ 1
Z exp (‚àíH(x)) ,
(4.36)
where the energy function H is given in equation (4.33). Since xi ‚àà{‚àí1, +1} for all
i ‚ààI, we have (yi ‚àíxi)2 = ‚àí2yi xi + (y2
i + 1) and thus we can write the posterior
distribution as the Gibbs measure
pX|Y(x | y) = 1
Z y
exp

‚àíHy(x)
	
,
with energy Hy given by
Hy(x) = ‚àí1
œÉ 2

i‚ààI
yixi + H(x) = ‚àí1
œÉ 2

i‚ààI
yi xi + Œ≤

i, j‚ààI
i‚àºj
xix j
for all x ‚ààI, where Œ≤ is the inverse temperature from the Ising model.
To generate samples from the posterior distribution, we can employ the Gibbs
sampler from algorithm 4.27 with target distribution œÄ = pX|Y. As in equation (4.34)
we have
œÄXm|X¬¨m(xm | x¬¨m) =
œÄXm,X¬¨m(xm, x¬¨m)
œÄXm,X¬¨m(‚àí1, x¬¨m) + œÄXm,X¬¨m(+1, x¬¨m)
and introducing the additional term 
i‚ààI yixi/œÉ 2 into the derivation of equation
(4.35) gives
œÄXm|X¬¨m(xm | x¬¨m)
=
exp

xm

Œ≤ 
i‚àºm xi ‚àíym
œÉ 2
		
exp

Œ≤ 
i‚àºm xi ‚àíym
œÉ 2
	
+ exp

‚àí

Œ≤ 
i‚àºm xi ‚àíym
œÉ 2
		

158
AN INTRODUCTION TO STATISTICAL COMPUTING
and thus
œÄXm|X¬¨m(+1 | x¬¨m) =
1
1 + exp

‚àí2

Œ≤(
i‚àºm xi) ‚àíym/œÉ 2		.
Substituting these conditional probabilities into the general Gibbs sampler algorithm
4.27 leads to the following variant of algorithm 4.31.
Algorithm 4.32
(Gibbs sampler in image processing)
input:
Œ≤ ‚â•0 (the inverse temperature)
y ‚ààRI (the observed, noisy image)
X0 ‚àà{‚àí1, +1}I (the initial state)
output:
a path of a Markov chain with the Gibbs measure from (4.32) and (4.33) as its
stationary distribution
randomness used:
independent samples Œæ ( j) ‚àà{‚àí1, +1} for j ‚ààN
1: for j = 1, 2, 3, . . . do
2:
m1 ‚Üê(( j ‚àí1) mod L) + 1
3:
m2 ‚Üê(‚åä( j ‚àí1)/L‚åãmod L) + 1
4:
d ‚ÜêX( j‚àí1)
m1‚àí1,m2 + X( j‚àí1)
m1+1,m2 + X( j‚àí1)
m1,m2‚àí1 + X( j‚àí1)
m1,m2+1
5:
p ‚Üê
1
1+exp(‚àí2(Œ≤d+ym/œÉ 2))
6:
Generate Œæ ( j) ‚àà{‚àí1, +1} such that P

Œæ ( j) = +1
	
= p.
7:
DeÔ¨Åne X( j) ‚ààS by
X( j)
i
=

X( j‚àí1)
i
if i Ã∏= (m1, m2) and
Œæ ( j)
otherwise,
for all i ‚ààI.
8: end for
In steps 2 and 3 of the algorithm, a pixel position m = (m1, m2) is constructed
such that m cycles through all possible pixel positions cyclically. When implementing
step 4 of the algorithm, we set Xi = 0 for all i /‚ààI. The result of three simulations
using this algorithm, for different values of œÉ, is shown in Figure 4.8.
4.5
Reversible Jump Markov Chain Monte Carlo
While MCMC methods like the Metropolis‚ÄìHastings method can be used in arbitrary
spaces, so far we only have considered the case of generating samples in the Euclidean
space Rd. The Reversible Jump Markov Chain Monte Carlo (RJMCMC) method,
described in this section, is concerned with a more general case, where the target

MARKOV CHAIN MONTE CARLO METHODS
159
œÉ = 0.5
Y
P(X = 1|Y)
œÉ = 1
œÉ = 2
Figure 4.8
Pairs of noisy images Y together with reconstructions generated using
algorithm 4.32 with inverse temperature Œ≤ = 0.5. The grey values in the reconstructed
images give the posterior probability that the corresponding pixel in the original
image was black, ranging from black for probability 1 to white for probability 0.
distribution lives on the disjoint union of several spaces Rdk. This setup, while
seeming artiÔ¨Åcial at Ô¨Årst glance, is useful in various classes of practical applications:
r Bayesian inference can be used to make simultaneous inference about the
choice of model as well as the model parameters, by assigning prior proba-
bilities to different models. If the models under consideration have different

160
AN INTRODUCTION TO STATISTICAL COMPUTING
numbers of parameters, the basic MCMC approach becomes difÔ¨Åcult, but
RJMCMC can still be used. This approach is illustrated in Section 4.5.2.
r Many types of random geometric objects have a variable number of parameters.
These include, for example random trees and random graphs. The RJMCMC
meethod can be used to generate samples from the distribution of such random
geometrical objects.
r Intensity functions, describing the rate of random events in time, can be mod-
elled as piecewise constant functions, parameterised by change point positions
and function values between the change points. The number of parameters in
such a model depends on the number of change points. In a Bayesian setting,
such an intensity function will have a random number of change points and
thus the model will have a random number of parameters. Application of the
RJMCMC method in this context is, for example, discussed in the article by
Green (1995).
4.5.1
Description of the method
Due to the complex structure of the state space used in RJMCMC methods, more
mathematical formalism is required to state the RJMCMC algorithm than was neces-
sary in the previous sections. This section introduces the required notation and states
the general RJMCMC algorithm.
We start the exposition by giving a mathematical description of the state space:
Let I be a Ô¨Ånite or countable set and let dk ‚ààN0 for all k ‚ààI be given. DeÔ¨Åne
Sk = {k} √ó Rdk
for all k ‚ààI and
S =

k‚ààI
Sk.
Then the elements z of the space S have the form z = (k, x), where x ‚ààRdk and
k ‚ààI. Since the index k is included as the Ô¨Årst component of all elements in Sk, the
spaces Sk are disjoint and each z ‚ààS is contained in exactly one of the subspaces
Sk. For a value (k, x) ‚ààS, the Ô¨Årst component, k, indicates which of the spaces Rdk
a point is in while the second component, x, gives the position in this space. The
space S is the state space our target distribution will live on and the Markov chain
constructed by the RJMCMC algorithm will move in.
Next, we specify the target distribution œÄ on the space S. If Z ‚àºœÄ, then Z can
be written as Z = (K, X) and we need to specify the joint distribution of K ‚ààI and
X ‚ààRdK . To describe such a distribution we can use a density œÄ which is split between

MARKOV CHAIN MONTE CARLO METHODS
161
the different subspaces Sk, that is a function œÄ(¬∑, ¬∑) such that œÄ(k, ¬∑) : Rdk ‚Üí[0, ‚àû)
for every k ‚ààI and

k‚ààI

Rdk
œÄ(k, x) dx = 1.
(4.37)
Then we have
P(K = k) =

Rdk
œÄ(k, x) dx
and
P(K = k, X ‚ààA) =

A
œÄ(k, x) dx
for all A ‚äÜRdk and all k ‚ààI.
Example 4.33
We can use the above formalism to construct a simple model for the
number and diameter of craters on a given area of moon surface. Assume that the
number K of craters is Poisson-distributed with parameter Œª, and that each crater,
independently, has a random diameter X given by a Pareto distribution with density
f (x) =

Œ±
xŒ±+1
if x ‚â•1 and
0
otherwise.
(We ignore craters with size less than 1 for this example.) Then, using the notation
introduced above, we have
I = N0
the possible numbers of craters,
dk = k
one parameter per crater (the diameter),
P(K = k) = e‚àíŒª Œªk
k!
the probability of having exactly k craters,
œÄ(k, x) = e‚àíŒª Œªk
k!
k
i=1 f (xi)
the joint density of k diameters X1, . . . , Xk
for all x ‚ààRdk and all k ‚ààI.
Our aim is to construct a Markov chain with stationary distribution œÄ, using
the Metropolis‚ÄìHastings algorithm on the state space S. Since this Markov chain
moves in S, the state at time j is described by a pair (K j, X j). To describe the
transition probabilities of such a Markov chain, for each (k, x) ‚ààS we need to
specify the distribution of (K j, X j) when (K j‚àí1, X j‚àí1) = (k, x). It transpires that in
the RJMCMC algorithm it is advantageous to Ô¨Årst determine the value of K j and only
then, in a second step, to determine the value of X j from the conditional distribution,

162
AN INTRODUCTION TO STATISTICAL COMPUTING
conditioned on the value of K j. Thus, the transitions of the Markov chain from
(k, x) ‚ààS to (l, y) ‚ààS will be described by probability weights b(k, x;l) with

l‚ààI
b(k, x;l) = 1
and probability densities p(k, x;l, ¬∑) on Rdl for all (k, x) ‚ààS. If (K j, X j) j‚ààN is
described by b and p, then
P

K j = l, X j ‚ààA
 K j‚àí1 = k, X j‚àí1 = x
	
= b(k, x;l)

A
p(k, x;l, y) dy
for all k,l ‚ààI, x ‚ààRdk and A ‚äÜRdl.
The next ingredient used in the RJMCMC algorithm is the idea of splitting the
transition mechanism into different move types, as described in Section 4.1.5. We
denote the set of all possible move types by M and, for a given state (k, x) ‚ààSk, the
probability of choosing move m ‚ààM will be denoted by Œ≥m(k, x). The probabilities
Œ≥m(k, x) satisfy

m‚ààM
Œ≥m(k, x) = 1
for all (k, x) ‚ààS. In the presence of different move types, the transition probabilities
given by b and p depend on the move type m, that is instead of b and p we consider
probability weights bm and probability densities pm for all m ‚ààM.
When computing the corresponding acceptance probabilities for the Metropolis‚Äì
Hastings algorithm, there are two different cases to consider: the simpler of the two
cases is the case when the proposal (l, y) lies in the same space as the previous
state (k, x) does, that is when we have l = k. In this case, occurring with with
probability bm(k, x; k), the distribution of the new location X j is given by a density
pm(k, x; ¬∑) : Rdk ‚Üí[0, ‚àû). We will see in proposition 4.37, that the corresponding
acceptance probabilities for this case can be chosen as
Œ±m(k, x; y) = min
œÄ(k, y)Œ≥m(k, y)bm(k, y; k)pm(k, y; x)
œÄ(k, x)Œ≥m(k, x)bm(k, x; k)pm(k, x; y), 1

(4.38)
for all x, y ‚ààRdk and all k ‚ààI. This expression is very similar to the form of the
acceptance probability we found for algorithm 4.12; only the probabilities bm(k, ¬∑; k)
for staying in the space k ‚ààI need to be included. Many variations of this type
of move are possible: for example, if the proposal can take only a discrete set of
values, we can replace the densities pm(k, x; ¬∑) by probability weights. Alternatively,
in case the distribution of proposals is continuous but restricted to a lower dimensional
subset of Rdk, we can replace œÄ(k, x)pm(k, x; y) by a density œïm(k, x; y) on a lower
dimensional subspace as described in lemma 4.15.

MARKOV CHAIN MONTE CARLO METHODS
163
The case where the proposal (l, y) falls into a space Sl Ã∏= Sk is more complicated:
with probability bm(k, x;l) a proposal in the space Sl = {l} √ó Rdl needs to be con-
structed. In the RJMCMC algorithm, instead of directly specifying the density of the
proposal on the space Rdl, the following mechanism is used. For a transition from Sk
to Sl, both Rdk and Rdl are temporarily extended to spaces of matching dimension,
that is instead of Rdk and Rdl we consider Rdk √ó Rnk and Rdl √ó Rnl, where
dk + nk = dl + nl.
(4.39)
To construct the proposal Y, we proceed as follows:
(a) Use a probability density œàm(k, x, ¬∑;l) : Rnk ‚Üí[0, ‚àû) to generate an auxil-
iary random variable U ‚ààRnk.
(b) Use a map œïk‚Üíl
m
: Rdk √ó Rnk ‚ÜíRdl √ó Rnl to obtain
(Y, V ) = œïk‚Üíl
m
(x,U).
While the value V ‚ààRnl is not part of the proposal itself, we will see in equation
(4.40), that the value V is required to compute the acceptance probability for this
transition. The densities œàm and the maps œïk‚Üíl
m
can be chosen as part of designing
the algorithm, subject to the following conditions.
Assumption 4.34
The maps œïk‚Üíl
m
: Rdk √ó Rnk ‚ÜíRdl √ó Rnl are bijective with
continuous partial derivatives. If the move type m allows transitions from Sk to Sl, it
also allows the reverse transition and the corresponding transition maps satisfy the
condition
œïl‚Üík
m
= (œïk‚Üíl
m
)‚àí1.
We will see in proposition 4.37, that we can choose the acceptance probabilities
for transitions from Sk to Sl as
Œ±m(k, x, u;l, y, v)
= min
 œÄ(l, y)Œ≥m(l, y)bm(l, y; k)œàm(l, y, v; k)
œÄ(k, x)Œ≥m(k, x)bm(k, x;l)œàm(k, x, u;l)
det Dœïk‚Üíl
m
(x, u)
 , 1

,
(4.40)
where Dœïk‚Üíl
m
(x, u) is the Jacobian matrix of œïk‚Üíl
m
as given in deÔ¨Ånition 1.35.
Example 4.35
Consider the case d1 = 1 and d2 = 2. To construct a move between
the corresponding spaces Rd1 and Rd2, we need to Ô¨Årst extend the dimensions of
theses spaces to make them equal. For simplicity we can choose n1 = 1 and n2 = 0,

164
AN INTRODUCTION TO STATISTICAL COMPUTING
so that d1 + n1 = 1 + 1 = 2 + 0 = d2 + n2. The corresponding transitions are then
described by a bijective, differentiable map œï1‚Üí2
m
: R √ó R ‚ÜíR2. If we choose
œï1‚Üí2
m
(x, u) =

x + u
x ‚àíu

(4.41)
for all (x, u) ‚ààR √ó R we Ô¨Ånd
det Dœï1‚Üí2
m
(x, u) = det
 ‚àÇ
‚àÇx œï1‚Üí2
m,1 (x, u)
‚àÇ
‚àÇu œï1‚Üí2
m,1 (x, u)
‚àÇ
‚àÇx œï1‚Üí2
m,2 (x, u)
‚àÇ
‚àÇx œï1‚Üí2
m,2 (x, u)

= det

1
1
1
‚àí1

= 1 ¬∑ (‚àí1) ‚àí1 ¬∑ 1
= ‚àí2.
Thus, for a move starting from (1, x) ‚ààS1 into S2, the proposal is constructed by Ô¨Årst
generating U ‚ààR with density œàm(1, x, ¬∑; 2) and then letting Y = (x + U, x ‚àíU).
The move is accepted with probability Œ±m(1, x,U; 2, Y), where
Œ±m(1, x, u; 2, y) = min

œÄ(2, y)Œ≥m(2, y)bm(2, y; 1)
œÄ(1, x)Œ≥m(1, x)bm(1, x; 2)œàm(1, x, u; 2) ¬∑ 2, 1

.
The argument v and the term œàm(2, y, v; 1) are omitted since n2 = 0.
Assumption 4.34 requires us to also include a corresponding transition from Rd2
and Rd1 into the same move type. This transition is described by a function œï2‚Üí1
m
:
R2 ‚ÜíR1 √ó R1 and, following assumption 4.34, œï2‚Üí1
m
has to satisfy the condition
œï2‚Üí1
m
= (œï1‚Üí2
m
)‚àí1. Solving the equations y1 = x + u and y2 = x ‚àíu for x and u we
Ô¨Ånd
œï2‚Üí1
m
(y) =
 y1+y2
2
y1‚àíy2
2

for all y ‚ààR2. The Jacobian determinant for this function can either be found directly,
or by using the rules for the derivative of inverse functions:
det Dœï2‚Üí1
m
(y) = det

Dœï1‚Üí2
m
(x, u)
	‚àí1
=
1
det Dœï1‚Üí2
m
(x, u) = ‚àí1
2.
To describe the resulting reverse moves from S2 to S1 we switch notation by swapping
x, u with y, v: let (2, x) ‚ààS2 be the current state and assume that a move to S1

MARKOV CHAIN MONTE CARLO METHODS
165
Table 4.1
An overview of the notation used in the RJMCMC algorithm.
I
index set for the state spaces (Ô¨Ånite or countable)
Sk
state space with index k ‚ààI: Sk = {k} √ó Rdk
S
state space of the Markov chain: S = 
k‚ààI Sk
œÄ(¬∑, ¬∑)
split density of the stationary distribution, satisfying (4.37)
M
index set for the moves (Ô¨Ånite or countable)
Œ≥m(k, x)
probability of choosing move m ‚ààM while in state (k, x) ‚ààSk
bm(k, x;l)
probability for move m to move into space l ‚ààI when the
current state is (k, x) ‚ààSk
pm(k, x; ¬∑)
density of the proposal when moving inside space k ‚ààI with
move m
œàm(k, x, ¬∑;l)
density of the auxiliary random variable U ‚ààRnk, when
moving from space k into space l using move m
œïk‚Üíl
m
map describing moves from Rdk √ó Rnk to Rdl √ó Rnl: the
proposal y ‚ààRdl is given by (y, v) = œïk‚Üíl
m
(x, u)
was selected. Then, using œï2‚Üí1, the proposal (1, Y) ‚ààS1 is constructed as Y =
(x1 + x2)/2 and the move is accepted with probability Œ±m(2, x; 1, Y, V ) where V =
(x1 ‚àíx2)/2 and
Œ±m(2, x; 1, y, v) = min
œÄ(1, y)Œ≥m(1, y)bm(1, y; 2)œàm(1, y, v; 2)
œÄ(2, x)Œ≥m(2, x)bm(2, x; 1)
¬∑ 1
2, 1

.
For this direction of move, the auxiliary value U and and the corresponding density
œàm(2, x, u; 1) are omitted since n2 = 0. To conclude this example we note that the
only choices made in this example were to use two as the dimension of the extended
spaces and the choice of the map œï1‚Üí2 in equation (4.41). All remaining expressions
arise as a consequence of equation (4.40) and assumption 4.34.
Table 4.1 summarises the notation introduced for the RJMCMC method. Normally
the state space S, together with the stationary distribution described by œÄ, will be
given as part of the problem whereas the set M of moves and all quantities depending
on the move (indicated by a subscript m in Table 4.1) need to be chosen as part of
designing the method. The resulting Metropolis‚ÄìHastings algorithm has the following
form.
Algorithm 4.36
(reversible jump Markov Chain Monte Carlo)
input:
target distribution œÄ
parameters Œ≥m, bm, pm œàm and œïk‚Üíl
m
as in Table 4.1
initial values (K0, X0) ‚àà

(k, x) ‚ààS
 œÄ(k, x) > 0


166
AN INTRODUCTION TO STATISTICAL COMPUTING
randomness used:
continuous samples with densities pm and œàm
discrete samples with weights Œ≥m and bm
W j ‚àºU[0, 1] i.i.d.
output:
a sample of a Markov chain (K j, X j) j‚ààN on S with stationary distribution
given by œÄ
1: for j = 1, 2, 3, . . . do
2:
generate m j ‚ààM with P(m j = m) = Œ≥m(K j‚àí1, X j‚àí1) for all m ‚ààM
3:
generate L j ‚ààI with P(L j = l) = bm j(K j‚àí1, X j‚àí1;l) for all l ‚ààI
4:
if L j = K j‚àí1 then
5:
generate Y j with density pm j(K j‚àí1, X j‚àí1; ¬∑)
6:
let Œ±( j) ‚ÜêŒ±m j(K j‚àí1, X j‚àí1; Y j), using Œ±m from (4.38)
7:
else
8:
generate U j‚àí1 with density œàm j(K j‚àí1, X j‚àí1, ¬∑; L j)
9:
let (Y j, Vj) ‚Üêœï
K j‚àí1‚ÜíL j
m j
(X j‚àí1,U j‚àí1)
10:
let Œ±( j) ‚ÜêŒ±m j(K j‚àí1, X j‚àí1,U j‚àí1; L j, Y j, Vj), using Œ±m from (4.40)
11:
end if
12:
generate W j ‚àºU[0, 1]
13:
if W j ‚â§Œ±( j) then
14:
K j ‚ÜêL j
15:
X j ‚ÜêY j
16:
else
17:
K j ‚ÜêK j‚àí1
18:
X j ‚ÜêX j‚àí1
19:
end if
20: end for
This algorithm can be used to generate samples from the target distribution œÄ for
use in a MCMC method, as described in Section 4.2. As for the basic Metropolis‚Äì
Hastings method from Section 4.1.1, the resulting Markov chain is œÄ-reversible but, to
avoid technical complications, we restrict ourselves to showing that œÄ is a stationary
distribution of the process X. This is the result of the following proposition.
Proposition 4.37
Let œÄ, Œ≥m, bm, pm œàm and œïk‚Üíl
m
be as described in Table 4.1 and
let assumption 4.34 be satisÔ¨Åed. Then the Markov chain (K j, X j) j‚ààN generated by
algorithm 4.36 has a stationary distribution with
P(K j = k, X j ‚ààA) =

A
œÄ(k, x) dx
for all j ‚ààN, A ‚äÜRdk and k ‚ààI.
Proof
Let j ‚ààN and assume that
P(K j‚àí1 = k, X j‚àí1 ‚ààA) =

A
œÄ(k, x) dx

MARKOV CHAIN MONTE CARLO METHODS
167
for all A ‚äÜRdk and all k ‚ààI. To prove the proposition, we have to show that the
probability P(K j = k, X j ‚ààA) equals this expression.
To determine the distribution of (K j, X j), we have to consider all possible values
(k, x) of (K j‚àí1, X j‚àí1), all possible move types m ‚ààM and then the possible target
spaces i ‚ààI for the proposed move. Systematically listing all combinations, we Ô¨Ånd
P

K j = l, X j ‚ààB
	
=

k‚ààI

Rdk
œÄ(k, x)

m‚ààM
Œ≥m(k, x)

i‚ààI
bm(k, x; i) Qm,i(k, x;l, B) dx
(4.42)
for all l ‚ààI and B ‚äÜRdl, where Qm,i(k, x;l, B) is the probability of the event
X j ‚ààB ‚äÜRdl, conditioned on the proposal moving from space Sk into space Si
using move type m. Most terms in the Ô¨Ånal sum will be zero, nonzero contributions
occur only for i = l if the proposal is accepted and for l = k if the proposal is rejected.
We discuss the two resulting cases separately.
For the Ô¨Årst case, if i = k, we always stay in space Sk and the process can only
reach B ‚äÜRdl if l = k. In this case we have
Qm,k(k, x;l, B)
= Œ¥kl

Rdk
pm(k, x; y) (Œ±m(k, x; y)1B(y) + (1 ‚àíŒ±m(k, x; y)) 1B(x)) dy
where Œ¥kl denotes the Kronecker delta. For this case, the acceptance probability Œ±m
is given by (4.38) and using the deÔ¨Ånition of Œ±m we Ô¨Ånd
œÄ(k, x)Œ≥m(k, x)bm(k, x; k)pm(k, x; y) Œ±m(k, x; y)
= œÄ(k, y)Œ≥m(k, y)bm(k, y; k)pm(k, y; x) Œ±m(k, y; x).
As in the proof of proposition 4.13, we can use this symmetry to deduce

Rdk
œÄ(k, x)Œ≥m(k, x) bm(k, x; k) Qm,k(k, x;l, B) dx
= Œ¥kl

B
œÄ(k, x)Œ≥m(k, x)bm(k, x; k) dx
and thus, by summing both sides over k,

k‚ààI

Rdk
œÄ(k, x)Œ≥m(k, x) bm(k, x; k) Qm,k(k, x;l, B) dx
=

B
œÄ(l, x)Œ≥m(l, x) bm(l, x;l) dx.
(4.43)
For the second case, if i Ã∏= k in (4.42), there are two possible ways to achieve
X j ‚ààB: for l = i the process can reach the space Sl by accepting the proposal,

168
AN INTRODUCTION TO STATISTICAL COMPUTING
whereas for l = k the process can stay in the space Sl by rejecting the proposal. For
all other cases, the probability Qm,i(k, x;l, B) in (4.42) equals 0. Thus we have
Qm,i(k, x;l, B) = Q(1)
m,i(k, x;l, B) + Q(2)
m,i(k, x;l, B)
where, deÔ¨Åning y and v by (y, v) = œïk‚Üíi
m
(x, u) again,
Q(1)
m,i(k, x;l, B) = Œ¥li

Rnk
œàm(k, x, u; i)Œ±m(k, x, u; i, y, v)1B(y) du
is the probability of reaching B with an accepted jump from Sk to Sl and
Q(2)
m,i(k, x;l, B) = Œ¥kl

Rnk
œàm(k, x, u; i) (1 ‚àíŒ±m(k, x, u; i, y, v)) du ¬∑ 1B(x)
is the probability of staying in space l = k by rejecting a move, both conditional on
the proposal using move type m and it being in space Si.
Since œïi‚Üík
m
= (œïk‚Üíi
m
)‚àí1 by assumption 4.34, the Jacobian of œïi‚Üík
m
satisÔ¨Åes
Dœïi‚Üík
m
(y, v) =

Dœïk‚Üíi
m
(x, u)
	‚àí1 and using the rule for the determinant of the inverse
of a matrix, we have
det Dœïi‚Üík
m
(y, v)
 = 1/
det Dœïk‚Üíi
m
(x, u)
. From this relation
and the deÔ¨Ånition (4.40) of Œ±m we Ô¨Ånd
œÄ(k, x)Œ≥m(k, x)bm(k, x; i)œàm(k, x, u; i) Œ±m(k, x, u; i, y, v)
= œÄ(i, y)Œ≥m(i, y)bm(i, y; k)œàm(i, y, v; k) Œ±m(i, y, v; k, x, u)
¬∑
det Dœïk‚Üíi
m
(x, u)
 .
Thus, we have

Rdk
œÄ(k, x) Œ≥m(k, x)bm(k, x; i)Q(1)
m,i(k, x;l, B) dx
= Œ¥li

Rdk

Rnk
œÄ(k, x)Œ≥m(k, x)bm(k, x; i)œàm(k, x, u; i)
¬∑ Œ±m(k, x, u; i, y, v) 1B(y) du dx
= Œ¥li

Rdk

Rnk
œÄ(i, y)Œ≥m(i, y)bm(i, y; k)œàm(i, y, v; k)
¬∑ Œ±m(i, y, v; k, x, u) 1B(y)
det Dœïk‚Üíi
m
(x, u)
 du dx
= Œ¥li

Rdl

Rnl
œÄ(i, y)Œ≥m(i, y)bm(i, y; k)œàm(i, y, v; k)
¬∑ Œ±m(i, y, v; k, x, u) 1B(y) dv dy
= Œ¥li

B
œÄ(i, y) Œ≥m(i, y)bm(i, y; k)
¬∑

Rnl
œàm(i, y, v; k)Œ±m(i, y, v; k, x, u) dv dy,

MARKOV CHAIN MONTE CARLO METHODS
169
where the last equality uses the substitution rule for integrals (see lemma 1.36) and
on the last line of the equation x and u are deÔ¨Åned by (x, u) = œïi‚Üík
m
(y, v). Summing
this expression over k ‚ààI and i Ã∏= k we Ô¨Ånd

k‚ààI

Rdk
œÄ(k, x) Œ≥m(k, x)

iÃ∏=k
bm(k, x; i)Q(1)
m,i(k, x;l, B) dx
=

B
œÄ(l, y) Œ≥m(l, y)

kÃ∏=l
bm(l, y; k)
¬∑

Rnl
œàm(l, y, v; k)Œ±m(l, y, v; k, x, u) dv dy.
(4.44)
For the terms involving Q(2)
m,i we Ô¨Ånd

Rdk
œÄ(k, x) Œ≥m(k, x)bm(k, x; i)Q(2)
m,i(k, x;l, B) dx
= Œ¥kl

B
œÄ(k, x) Œ≥m(k, x)bm(k, x; i)

Rnk
œàm(k, x, u; i)
¬∑ (1 ‚àíŒ±m(k, x, u; i, y, v)) du dx
= Œ¥kl

B
œÄ(k, x) Œ≥m(k, x)bm(k, x; i) dx
‚àíŒ¥kl

B
œÄ(k, x) Œ≥m(k, x)bm(k, x; i)
¬∑

Rnk
œàm(k, x, u; i)Œ±m(k, x, u; i, y, v) du dx
and summing this expression over k ‚ààI and i Ã∏= k we get

k‚ààI

Rdk
œÄ(k, x) Œ≥m(k, x)

iÃ∏=k
bm(k, x; i)Q(2)
m,i(k, x;l, B) dx
=

B
œÄ(l, x) Œ≥m(l, x)

iÃ∏=l
bm(l, x; i) dx
‚àí

B
œÄ(l, x) Œ≥m(l, x)

iÃ∏=l
bm(l, x; i)
¬∑

Rnl
œàm(l, x, u; i)Œ±m(l, x, u; i, y, v) du dx.
(4.45)

170
AN INTRODUCTION TO STATISTICAL COMPUTING
So far we have considered the terms involving Q(1)
m,i and Q(2)
m,i separately. From these
results we can get the corresponding expressions for Qm,i. Combining equation (4.44)
and equation (4.45) we Ô¨Ånd

k‚ààI

Rdk
œÄ(k, x) Œ≥m(k, x)

iÃ∏=k
bm(k, x; i)Qm,i(k, x;l, B) dx
=

B
œÄ(l, x) Œ≥m(l, x)

iÃ∏=l
bm(l, x; i) dx.
(4.46)
This is the result for the second case.
Finally, we can add the result from equation (4.43) and equation (4.46) to get

k‚ààI

Rdk
œÄ(k, x) Œ≥m(k, x)

i‚ààI
bm(k, x; i)Qm,i(k, x;l, B) dx
=

B
œÄ(l, x) Œ≥m(l, x)

i‚ààI
bm(l, x; i) dx
=

B
œÄ(l, x) Œ≥m(l, x) dx
and summing this formula over m ‚ààM gives the right-hand side in (4.42). Thus we
Ô¨Ånd
P

K j = l, X j ‚ààB
	
=

B
œÄ(l, x)

m‚ààM
Œ≥m(l, x) dx
=

B
œÄ(l, x) dx.
This shows that K j and X j have the correct distribution and that thus œÄ is a stationary
density of (K j, X j) j‚ààN.
As for the original Metropolis‚ÄìHastings algorithm, the target density œÄ enters
the RJMCMC algorithm only via the acceptance probabilities given by equation
(4.38) and equation (4.40). Since both forms of the acceptance probabilities contain
only the ratio of the two values of œÄ, for the proposal and the current state, the
algorithm can still be applied when œÄ is only known up to a multiplicative constant.
This is particularly useful for applications in Bayesian inference, where the constant
probability of the observations, for example the constant Z in equation (4.21), can
be omitted from the deÔ¨Ånition of œÄ. Since the ratio of œÄ(l, y)/œÄ(k, x) in equation
(4.40) contains values of œÄ corresponding to different subspaces Sl Ã∏= Sk, the above
argument only applies to global constants: if the subdensities œÄ(k, ¬∑) contain unknown

MARKOV CHAIN MONTE CARLO METHODS
171
multiplicative constants which depend on the space k and where the ratio of these
constants between different spaces is not known, the RJMCMC algorithm cannot be
applied directly.
4.5.2
Bayesian inference for mixture distributions
In this section we illustrate the RJMCMC algorithm 4.36 with the help of an example:
we consider a Bayesian inference problem for mixture distributions. For the example,
we assume the following model: observations Y1, . . . , Yn are given from a two-
dimensional mixture distribution
Œº = 1
k
k

a=1
N

Œºa,r2
a I2
	
,
(4.47)
where I2 is the two-dimensional identity matrix. We assume that the number k of
modes, the means Œºa and the standard deviations ra are all random, with distributions
given by
k ‚àºPois(3) + 1
(4.48)
as well as
Œºa ‚àºU ([‚àí10, +10] √ó [‚àí10, +10])
(4.49)
and
ra ‚àºU
1
2, 5
2
 
(4.50)
for all a ‚àà{1, . . . , k}. Our aim is to generate samples from the posterior distribution
of k, Œºa and ra, given the data Y1, . . . , Yn.
In this section we will use the RJMCMC algorithm to generate the required
samples. In order to do so we Ô¨Årst have to determine the state space S and the target
distribution on this state space, and then we have to choose a set of moves which
allows the algorithm to efÔ¨Åciently explore all of the state space.
4.5.2.1
State space
Since we are interested in the posterior distribution of the parameters, the state space
consists of all possible parameter values. The parameters for each component of the
mixture are Œºa ‚ààR2 and ra ‚ààR and thus we can choose I = N and
Sk =

R2	k √ó Rk ‚àº= R3k

172
AN INTRODUCTION TO STATISTICAL COMPUTING
for all k ‚ààI. Here, the parameter vector (Œº,r) = (Œº1, . . . , Œºk,r1, . . . ,rk) plays the
role of the state vector x in the general description of the method in Section 4.5.1 and
we have dk = 3k for all k ‚ààI.
4.5.2.2
Target distribution
The target distribution is the posterior distribution of the parameters k, Œº =
(Œº1, . . . , Œºk) and r = (r1, . . . ,rk), given observations y = (y1, . . . , yn) for Y =
(Y1, . . . , Yn). Using Bayes‚Äô rule and the prior distributions of k, Œºa and ra given
by equation (4.48), equation (4.49) and equation (4.50), we Ô¨Ånd the target distribu-
tion to be
œÄ(k, Œº,r)
= pk,Œº,r|Y(k, Œº,r | y)
= pY|k,Œº,r(y | k, Œº,r) pk,Œº,r(k, Œº,r)
pY(y)
= 1
Z pY|k,Œº,r(y | k, Œº,r) pŒº|k(Œº | k) pr|k(r | k) pk(k)
(4.51)
for all (Œº,r) ‚ààSk and all k ‚ààI, where Z = pY(y) is constant, the observations have
density
pY|k,Œº,r(y | k, Œº,r) =
n
i=1
1
k
k

a=1
1
2œÄr2a
exp

‚àí(yi,1 ‚àíŒºa,1)2 + (yi,2 ‚àíŒºa,2)2
2r2a

for all y ‚àà(R2)n and the prior distribution is given by the densities
pŒº|k(Œº | k) =
k
a=1
1
202 1[‚àí10,10]√ó[‚àí10,10](Œºa)
pr|k(r | k) =
k
a=1
1
21[1/2,5/2](ra)
pk(k) = e‚àí3
3k‚àí1
(k ‚àí1)!
for all Œº ‚àà(R2)k, r ‚ààRk and k ‚ààN.
4.5.2.3
Move types
In order to allow the process to explore all of the state space, we need moves to
change the means Œºa and variances ra of the mixture components, and to change the
number k of components. Here we use a four-element set M = {mŒº, mr, m¬±, m‚Üî} to
enumerate the move types, where mŒº denotes a move which changes the means, mr
denotes a move which changes the variances and m¬± denotes a move which increases

MARKOV CHAIN MONTE CARLO METHODS
173
or decreases the number of mixture components by one. For simplicity we assume
that m¬± only removes or adds a component at the end of the list of components. To
compensate for this and to allow for arbitrary mixture components to be removed,
we introduce an additional move type m‚Üî, which only changes the numbering of the
mixture components, and otherwise leaves the state unchanged. We will now consider
these four move types in detail.
We need to specify the move type probabilities Œ≥m(k, Œº,r) for all move types
m ‚ààM, such that

m‚ààM
Œ≥m(k, Œº,r) = 1.
Since k is a discrete variable, fewer moves may be necessary to explore the possible
values for k than for the variables Œº and r. To reÔ¨Çect this we choose the move
probabilities as
Œ≥mŒº = Œ≥mŒº(k, Œº,r) = 4/10,
Œ≥mœÉ = Œ≥mœÉ (k, Œº,r) = 4/10,
Œ≥m¬± = Œ≥m¬±(k, Œº,r) = 1/10,
Œ≥m‚Üî= Œ≥m¬±(k, Œº,r) = 1/10
for all Œº ‚ààR2k, r ‚ààRk and k ‚ààN.
4.5.2.4
Move details
Moves of type mŒº only change the mixture component means Œº and thus always
propose values which stay inside the current subspace: we have bmŒº(k, y; k) = 1 and
bmŒº(k, y;l) = 0 for all l Ã∏= k. To perform a move of type mŒº, we Ô¨Årst randomly
choose an index
a ‚àºU{1, 2, . . . , k}
and then replace Œºa by
ÀúŒºa ‚àºŒºa + N(0, œÉ 2
ŒºI2);
all other components of Œº stay unchanged. Since the increments ÀúŒº ‚àíŒº are symmetric,
we can use use equation (4.38) together with example 4.17 to determine the acceptance
probability for this move type: we get
Œ±mŒº(k, Œº,r; ÀúŒº,r) = min

œÄ(k, ÀúŒº,r) ¬∑ 4
10 ¬∑ 1
œÄ(k, Œº,r) ¬∑ 4
10 ¬∑ 1, 1

= min
œÄ(k, ÀúŒº,r)
œÄ(k, Œº,r), 1

,
(4.52)

174
AN INTRODUCTION TO STATISTICAL COMPUTING
where œÄ is the posterior density given in equation (4.51). Since the unknown con-
stant Z in (4.51) appears both in the numerator and denominator of (4.52), both
occurrences of Z cancel and the value of Z is not required to evaluate the acceptance
probability Œ±mŒº. Similar considerations apply to the acceptance probabilities for the
remaining move types.
Moves of type mr change the mixture component variances r2
a. This move type
leaves the subspaces invariant and thus we have bmr (k, y; k) = 1 and bmr (k, y;l) = 0
for all l Ã∏= k. To perform a move of type mr, we Ô¨Årst randomly choose an index
a ‚àºU{1, 2, . . . , k}
and then replace ra by
Àúra ‚àºra + N(0, œÉ 2
r );
all other components of r stay unchanged. Again, we can use use example 4.17 to
determine the acceptance probability for this move type: we get
Œ±mr (k, Œº,r; Œº, Àúr) = min

œÄ(k, Œº, Àúr) ¬∑ 4
10 ¬∑ 1
œÄ(k, Œº,r) ¬∑ 4
10 ¬∑ 1, 1

= min
œÄ(k, Œº, Àúr)
œÄ(k, Œº,r), 1

.
(4.53)
Moves of types m¬± change the number k of mixture components by exactly one.
Thus, this move type always changes subspaces and we set
bm¬±(k, Œº,r; k + 1) = bm¬±(k, Œº,r; k ‚àí1) = 1/2
for all k > 1. For the case k = 1 we cannot decrease the number of mixture compo-
nents any further and so we set
bm¬±(1, Œº,r; 2) = 1.
Finally, for all other combinations of k,l ‚ààI we set bm¬±(k, Œº,r;l) = 0.
Since dk = 3k and dk+1 = 3k + 3, we can satisfy the dimension matching crite-
rion (4.39) for moves from k to l = k + 1 by choosing nk = 3 and nk+1 = 0. The
transition maps œïk‚Üík+1
m¬±
and œïk+1‚Üík
m¬±
must satisfy assumption 4.34, so we need to
specify only one of the two maps and the second map is then found as the inverse of
the Ô¨Årst one. For simplicity, we choose
œïk‚Üík+1
m¬±
(Œº,r, u) = (Œº1, . . . , Œºk, (u1, u2),r1, . . . ,rk, u3) ,
that is we just construct a new mean and and new standard deviation from the
auxiliary sample u ‚ààRnk as Œºk+1 = (u1, u2) and rk+1 = u3, and leave the remaining

MARKOV CHAIN MONTE CARLO METHODS
175
mixture components unchanged. To get an appropriate distribution for the newly
added mixture component, we use the prior distribution to construct the density œàm¬±
of the auxiliary sample U j: we set
œàm¬±(u) = pŒº|k

(u1, u2)
1
	
pr|k(u3 | 1)
=
1
202 1[‚àí10,10](u1)1[‚àí10,10](u2) 1
21[1/2,5/2](u3)
(4.54)
for all u ‚ààRnk. This density does not depend on k and x, and thus we write œàm¬±(u)
instead of œàm¬±(k, x, u; k + 1). Since œïk‚Üík+1
m¬±
just returns a permutation of its argu-
ments, we have
det Dœïk‚Üík+1
m¬±
 = 1. Putting everything together, we can now get the
corresponding acceptance probabilities from (4.40): for k ‚â•2 we Ô¨Ånd
Œ±m¬±(k, Œº,r, u; k + 1, ÀúŒº, Àúr)
= min

œÄ(k + 1, ÀúŒº, Àúr) ¬∑ 1
10 ¬∑ 1
2 ¬∑ 1
œÄ(k, Œº,r) ¬∑ 1
10 ¬∑ 1
2 ¬∑ œàm¬±(u), 1

= min

œÄ(k + 1, ÀúŒº, Àúr)
œÄ(k, Œº,r) œàm¬±(u), 1

(4.55)
and for k = 1 we have
Œ±m¬±(1, Œº,r, u; 2, ÀúŒº, Àúr)
= min

œÄ(2, ÀúŒº, Àúr) ¬∑ 1
10 ¬∑ 1
2 ¬∑ 1
œÄ(1, Œº,r) ¬∑ 1
10 ¬∑ 1 ¬∑ œàm¬±(u), 1

= min

œÄ(2, ÀúŒº, Àúr)
2 ¬∑ œÄ(1, Œº,r) œàm¬±(u), 1

,
(4.56)
where œÄ is again given by (4.51) and œàm¬± is deÔ¨Åned in equation (4.54). Since
the auxiliary sample Vj is in Rnk+1 with nk+1 = 0, we can omit v and its density
œàm¬±(k + 1, Œº,r, ¬∑; k) from the formula.
The reverse transition, from k to k ‚àí1 mixture components, is now completely
speciÔ¨Åed by assumption 4.34: we Ô¨Ånd
œïk‚Üík‚àí1
m¬±
(Œº1, . . . , Œºk,r1, . . . ,rk)
=

(Œº1, . . . , Œºk‚àí1,r1, . . . ,rk‚àí1), (Œºk,1, Œºk,2,rk)
	
for all (Œº, œÉ) ‚ààR2k √ó Rk, that is œïk‚Üík‚àí1
m¬±
performs a permutation and again we
have
det Dœïk‚Üík‚àí1
m¬±
 = 1. This time we can omit the argument u ‚ààR0 and the

176
AN INTRODUCTION TO STATISTICAL COMPUTING
corresponding density œàm¬±(k, Œº,r, ¬∑; k ‚àí1). The resulting form of the acceptance
probability for k ‚â•3 is
Œ±m¬±(k, Œº,r; k ‚àí1, ÀúŒº, Àúr, v)
= min

œÄ(k ‚àí1, ÀúŒº, Àúr) ¬∑ 1
10 ¬∑ 1
2 ¬∑ œàm¬±(v)
œÄ(k, Œº,r) ¬∑ 1
10 ¬∑ 1
2 ¬∑ 1
, 1

= min
œÄ(k ‚àí1, ÀúŒº, Àúr) œàm¬±(v)
œÄ(k, Œº,r)
, 1

(4.57)
and for k = 2 we get
Œ±m¬±(2, Œº,r; 1, ÀúŒº, Àúr, v)
= min

œÄ(1, ÀúŒº, Àúr) ¬∑ 1
10 ¬∑ 1 ¬∑ œàm¬±(v)
œÄ(2, Œº,r) ¬∑ 1
10 ¬∑ 1
2 ¬∑ 1
, 1

= min
2 ¬∑ œÄ(1, ÀúŒº, Àúr) œàm¬±(v)
œÄ(2, Œº,r)
, 1

.
(4.58)
Finally, moves of type m‚Üîchange the numbering of the components only. If
k = 1, this move type does nothing: the proposal equals the current state, and the
corresponding acceptance probability is 1. For k > 1, we randomly choose an index
a ‚àºU{1, 2, . . . , k ‚àí1}
and the construct the proposal as
ÀúŒº = (Œºk‚àía+1, . . . , Œºk, Œº1, . . . , Œºk‚àía) ,
Àúr = (rk‚àía+1, . . . ,rk,r1, . . . ,rk‚àía) .
Using equation (4.38) and the fact that the target distribution œÄ does not change when
the mixture components are interchanged, we Ô¨Ånd the corresponding acceptance
probability as
Œ±m‚Üî(k, Œº,r; ÀúŒº, Àúr) = min

œÄ(k, ÀúŒº, Àúr) ¬∑ 1
10 ¬∑ 1 ¬∑
1
k‚àí1
œÄ(k, Œº,r) ¬∑ 1
10 ¬∑ 1 ¬∑
1
k‚àí1
, 1

= 1.
This completes the description of the different move types.
4.5.2.5
Implementation
Using the state space, moves and acceptance probabilities described above, we can
now implement the RJMCMC algorithm 4.36 for the Bayesian parameter estimation
problem described in this section. Once the algorithm is implemented we still need

MARKOV CHAIN MONTE CARLO METHODS
177
to choose the standard deviations œÉŒº and œÉr used in the moves of type mŒº and mr,
respectively. The parameters œÉŒº and œÉr control the size of the increments in the corre-
sponding moves and as in Section 4.1.3 we expect the acceptance rates to decrease as
œÉŒº and œÉr are increased. The methods from Section 4.2.2 can be used to guide tuning
of these parameters. For example, the values could be chosen so that the acceptance
rates are not too close to either 0 or 1. In our experiments it was also required to
write the acceptance probabilities in the numerically more robust form (4.19).
Figure 4.9 shows the Ô¨Ånal state of one run of the RJMCMC algorithm for the
setup considered in this section. As an example of the kind of questions which can
‚àí10
‚àí5
0
5
10
‚àí10
‚àí5
0
5
10
K
Probability
0
2
4
6
8
0.0
0.2
0.4
(a)
(b)
Figure 4.9
(a) The Ô¨Ånal state of a run of the RJMCMC algorithm described in Section
4.5.2. The small circles give the locations of n = 80 observations from the mixture
distribution (4.47). The Ô¨Åve sets of concentric circles give the locations and standard
deviations of the Ô¨Åve mixture components present in a sample from the posterior
distribution (the radii are ra, 1.5ra and 2ra), obtained by running N = 50 000 steps
of the RJMCMC algorithm. (b) A histogram of the values (K100 j) j=1,...,N/100 observed
during the run.

178
AN INTRODUCTION TO STATISTICAL COMPUTING
be answered using the RJMCMC algorithm, Figure 4.9(b) gives a histogram of the
distribution of the number k of mixture components observed during the run. For the
given set of observations, showing signiÔ¨Åcant overlap between mixture components,
all values k ‚àà{4, 5, 6, 7} can be observed with non-negligible probability.
4.6
Summary and further reading
In this chapter we have learned how Markov chains can be used as the basis of
Monte Carlo methods. The foundation of all such methods is the Metropolis‚ÄìHastings
algorithm which we have discussed in several variants. An overview over the area of
MCMC methods and more pointers to the literature can be found in Gentle et al. (2004,
Chapter II.3). Markov chains and the Metropolis‚ÄìHastings method are discussed in
Chapter 7 of Robert and Casella (2004). Applications and extensions to the methods
can also be found in Gilks et al. (1996) and Kroese et al. (2011). We have also covered
the Gibbs sampler and the RJMCMC method; both of these methods technically still
fall under the umbrella of the Metropolis‚ÄìHastings framework, but these methods are
so specialised that they are often treated as separate approaches. More information
about the Gibbs sampler can be found in Chapters 8‚Äì10 of Robert and Casella (2004)
and the RJMCMC method, introduced in Green (1995), is for example discussed in
Waagepetersen and Sorensen (2001) and Chapter 11 of Robert and Casella (2004).
In Section 4.2 we have discussed both theoretical and practical aspects related to
the convergence of MCMC methods: Section 4.2.1 summarises some of the theoret-
ical results which underpin the mathematical analysis of the resulting methods and
Section 4.2.2 discusses aspects relevant to using MCMC methods in practice. Further
discussion of convergence of MCMC methods can be found in Chapter 6 of Robert
and Casella (2004), a survey is given in Roberts and Rosenthal (2004) and many of
the technical details can be found in the monograph by Meyn and Tweedie (2009).
To illustrate the different methods introduced in this chapter we have considered
a variety of Bayesian inference problems, ranging from simple Bayesian models
(Section 4.3) over parameter estimation for mixture distributions (Sections 4.4.2 and
4.5.2) to applications in image processing (Section 4.4.3). More details about the use
of Monte Carlo methods in Bayesian statistics can be found in Gentle et al. (2004,
Chapter III.11) and Bayesian image analysis is, for example, discussed in Winkler
(1995). In passing we also discussed the Ising model from statistical mechanics;
this model is treated in many advanced texts, for example in Plischke and Bergersen
(2006) and Privman (1990).
Exercises
E4.1
Implement the random walk Metropolis algorithm with target density œÄ given
by equation (4.6). Plot paths of the generated Markov chains for different
values of œÉ.

MARKOV CHAIN MONTE CARLO METHODS
179
E4.2
Implement the random walk Metropolis sampler for sampling from the target
distribution N(100, 1) on R, using proposals Y j = X j‚àí1 + Œµ j where Œµ j ‚àº
N(0, 1). Experiment with different starting values X0 ‚ààR and create a plot
of a path X0, X1, . . . , X N which illustrates the need for a burn-in period.
E4.3
Implement the Metropolis‚ÄìHastings algorithm with target density given
by equation (4.6) and proposals Y j ‚àºN(X j, œÉ 2). For œÉ = 1, 6, 36, use
the output of the algorithm to estimate the lag k autocorrelations œÅk =
Corr(X j, X j+k) for k = 1, 2, . . . , 100. Create plots of the autocorrelations
œÅk as a function of k.
E4.4
For the situation of example 4.25, write a program which estimates, for a given
value of œÉ, the average acceptance probability in the Metropolis‚ÄìHastings
algorithm. Create a plot of this acceptance probability as a function of œÉ.
E4.5
Implement the random walk Metropolis method with N(0, Œ∑2)-distributed
increments for the posterior distribution from example 4.26. The input of your
program should be the variance Œ∑2 and a list x = (x1, . . . , xn) of observations.
The output of your program should be a path (Œº j, œÉ j) of a Markov chain
which has pŒº,œÉ(¬∑ | X = x) as its stationary distribution. Test your program
using randomly generated data.
E4.6
Implement the Gibbs sampler for sampling from the posterior distribution
(4.26), using the method described in Section 4.4.2.
E4.7
Write a program to implement the Gibbs sampler for the Ising model from
algorithm 4.31. Test your program by generating samples from the Ising
model for Œ≤ = 0.30, Œ≤ = 0.34, Œ≤ = 0.38, Œ≤ = 0.42, Œ≤ = 0.46 and Œ≤ = 0.50.
E4.8
Write a program to generate samples from the posterior distribution pX|Y
in the Bayesian image denoising problem from equation (4.36), given a
noisy input image y ‚ààRI. The program should follow the steps described in
algorithm 4.32.
E4.9
Write a program to implement the RJMCMC method described in Section
4.5.2.

5
Beyond Monte Carlo
In this chapter we present two methods which can be used instead of Monte Carlo
methods if either no statistical model is available or if the available models are too
complicated to easily apply Monte Carlo methods. The Ô¨Årst of these two methods,
called Approximate Bayesian Computation (ABC), is tailored towards the case where
a computer model of the studied system is available, which can be used instead of a
mathematical model. The second method, Bootstrap sampling, is used in cases where
only a set of observations but no model at all is available.
5.1
Approximate Bayesian Computation
ABC is a computational technique to obtain approximate parameter estimates in a
Bayesian setting. The ABC approach, described in this section, is less efÔ¨Åcient than
MCMC methods are, but ABC is easier to implement than MCMC and the method
requires very little theoretical knowledge about the underlying model.
Our aim in this section is to generate samples from the posterior distribution of
the parameter Œ∏ in a Bayesian model, given observations X = x. From Section 4.3
we know that the posterior density of Œ∏ is given by
pŒ∏|X(Œ∏ |x) = 1
Z pX|Œ∏

x
Œ∏

pŒ∏(Œ∏),
(5.1)
where Z is a normalising constant. The problem that ABC is aiming to solve is that
in many situations the density pX|Œ∏(¬∑|Œ∏) can be difÔ¨Åcult to obtain in closed form. The
ABC method can be applied in situations where generating samples from this density
is easier than working with the density itself. Since the resulting method avoids use
of any explicit form of this density, ABC is called a likelihood free method.
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

182
AN INTRODUCTION TO STATISTICAL COMPUTING
The ABC method is based on the basic rejection sampling algorithm 1.19: if
proposals are generated with density g and if each proposal X is accepted with prob-
ability p(X), then the accepted proposals are distributed with density proportional to
p ¬∑ g. In the context of Bayesian parameter estimation, we can apply this algorithm
as follows:
(a) Generate samples Œ∏ j ‚àºpŒ∏ for j = 1, 2, 3, . . . .
(b) Accept each sample Œ∏ j with probability proportional to pX|Œ∏(x|Œ∏ j), where x
is the observed data.
By Proposition 1.20, the accepted samples are distributed with density p(Œ∏ |x)
given by (5.1). Methods based on this idea are called ABC methods. Since we assume
that we do not have access to an explicit formula for p(x|Œ∏), our aim is to Ô¨Ånd a
method implementing the rejection procedure described above, using only samples
from the density p(x|Œ∏) but not the density itself.
5.1.1
Basic Approximate Bayesian Computation
In this section we describe a basic version of the ABC method. We start the presenta-
tion by describing the method as an algorithm, and then give the required explanations
to understand why this algorithm gives the desired result.
Algorithm 5.1
(basic Approximate Bayesian Computation)
input:
data x‚àó‚ààRn
the prior density œÄ for the unknown parameter Œ∏ ‚ààRp
a summary statistic S: Rn ‚ÜíRq
an approximation parameter Œ¥ > 0
randomness used:
samples Œ∏ j ‚àºpŒ∏ and X j ‚àºpX|Œ∏(¬∑|Œ∏ j) for j ‚ààN
output:
Œ∏ j1, Œ∏ j2, . . . approximately distributed with density pŒ∏|X(Œ∏ |x‚àó)
1: s‚àó‚ÜêS(x‚àó)
2: for j = 1, 2, 3, . . . do
3:
sample Œ∏ j ‚àºpŒ∏(¬∑)
4:
sample X j ‚àºpX|Œ∏(¬∑|Œ∏ j)
5:
Sj ‚ÜêS(X j)
6:
if |Sj ‚àís‚àó| ‚â§Œ¥ then
7:
output Œ∏ j
8: end if
9: end for

BEYOND MONTE CARLO
183
In the algorithm, the summary statistic S is assumed to take values in Rq. The
dimension q is typically much smaller than the dimension n of the data, and often q
equals the number p of parameters. The distance |Sj ‚àís‚àó| in line 6 of the algorithm
is the Euclidean norm in Rq. Since the algorithm considers the summary statistic
s‚àó= S(x‚àó) instead of the full data, the method can only be expected to work if S(Œ∏)
contains ‚Äòenough‚Äô information about Œ∏. The optimal case for this is if S is a sufÔ¨Åcient
statistic, as described in the following deÔ¨Ånition.
DeÔ¨Ånition 5.2
A statistic S = S(X) is a sufÔ¨Åcient statistic for Œ∏, if the conditional
distribution of X given the value S does not depend on the parameter Œ∏.
If S is a sufÔ¨Åcient statistic, then the value S(X) contains all information from X
about Œ∏: once the value S(X) is known, the sample does not contain any additional
information about Œ∏. More information about sufÔ¨Åcient statistics can be found in the
literature, for example in Section 6.2 of the book by Casella and Berger (2001). If
no summary statistic is available, the algorithm can be applied with a nonsufÔ¨Åcient
statistic S, but this will introduce an additional error. To minimise this error, S should
be chosen so that it contains as much information about Œ∏ as possible.
Algorithm 5.1 involves a trade-off between speed and accuracy: if the approxi-
mation parameter Œ¥ > 0 is chosen small, the distribution of the generated samples is
closer to the exact posterior. On the other hand, if Œ¥ is chosen larger, generation of
the samples is faster. This is described in the following proposition.
Proposition 5.3
Let (Œ∏ jk)k‚ààN be the accepted output samples of Algorithm 5.1 for
given data x‚àó‚ààRn and s‚àó= S(x‚àó). Then the following statements hold.
(a) Let pS|Œ∏ be the density of S(X) where X ‚àºpX|Œ∏. Assume that for every Œ∏ the
function s ‚ÜípS|Œ∏(s|Œ∏) is continuous in a neighbourhood of s‚àóand that pS|Œ∏
is uniformly bounded in a neighbourhood of s‚àó, that is
sup
s‚ààRq
|s‚àís‚àó|<Œµ
sup
Œ∏‚ààRp pS|Œ∏(s|Œ∏) < ‚àû
for all sufÔ¨Åciently small Œµ > 0. Then we have
lim
Œ¥‚Üì0 P

Œ∏ jk ‚ààA

=

Rp 1A(Œ∏) pABC
Œ∏|S (Œ∏ |s‚àó) dŒ∏
(5.2)
where pABC
Œ∏|S
is the probability density given by
pABC
Œ∏|S (Œ∏ |s) ‚àùpS|Œ∏(s|Œ∏) pŒ∏(Œ∏)
(5.3)
for all Œ∏ ‚ààRp. Thus, in the limit Œ¥ ‚Üì0, the samples Œ∏ jk have density pABC
Œ∏|S .

184
AN INTRODUCTION TO STATISTICAL COMPUTING
(b) If S is a sufÔ¨Åcient statistic, the limiting density pABC
Œ∏|S
from (5.3) satisÔ¨Åes
pABC
Œ∏|S (Œ∏ |s‚àó) = pŒ∏|X(Œ∏ |x‚àó),
that is in the limit Œ¥ ‚Üì0 the distribution of the output samples coincides with
the posterior distribution (5.1).
(c) The average number of proposals required to generate each output sample is
of order O(Œ¥‚àíq).
Proof
The proposal Œ∏ j in the algorithm has density pŒ∏. The probability of accepting
the proposal Œ∏ j is given by
P

|s j ‚àís‚àó| ‚â§Œ¥
Œ∏ j

= P

|S(X j) ‚àís‚àó| ‚â§Œ¥
Œ∏ j

=

BŒ¥(s‚àó)
pS|Œ∏(s j |Œ∏ j) ds j,
where BŒ¥(s‚àó) is the ball around s‚àówith radius Œ¥ in Rq. Thus, by proposition 1.20, the
accepted proposals Œ∏ jk have density
pŒ¥(Œ∏) ‚àù

BŒ¥(s‚àó)
pS|Œ∏(s j |Œ∏) ds j ¬∑ pŒ∏(Œ∏).
As an abbreviation, we write
rŒ¥(Œ∏) =
1
BŒ¥(s‚àó)


BŒ¥(s‚àó)
pS|Œ∏(s j |Œ∏) ds j ¬∑ pŒ∏(Œ∏)
(5.4)
where
BŒ¥(s‚àó)
 denotes the q-dimensional volume of the ball BŒ¥(s‚àó). Using this
notation we have pŒ¥(Œ∏) = rŒ¥(Œ∏)/ZŒ¥. Similarly, we write
r(Œ∏) = pS|Œ∏(s‚àó|Œ∏) pŒ∏(Œ∏)
to get
pABC
Œ∏|S (Œ∏ |s‚àó) = r(Œ∏)/Z
where Z
is the normalisation constant. Since
s ‚ÜípS|Œ∏(s|Œ∏) is continuous, we have
1
BŒ¥(s‚àó)


BŒ¥(s‚àó)
pS|Œ∏(s j |Œ∏ j) ds j ‚àí‚ÜípS|Œ∏(s‚àó|Œ∏ j)
and thus rŒ¥(Œ∏) ‚Üír(Œ∏) as Œ¥ ‚Üì0 for all Œ∏. By the dominated convergence theorem
from analysis (see e.g. Rudin, 1987, theorem 1.34) we then have
lim
Œ¥‚Üì0 ZŒ¥ = lim
Œ¥‚Üì0

Rp rŒ¥(Œ∏) dŒ∏ =

Rp r(Œ∏) dŒ∏ = Z
and thus
pŒ¥(Œ∏) = 1
ZŒ¥
rŒ¥(Œ∏) ‚àí‚Üí1
Z r(Œ∏) = pABC
Œ∏|S (Œ∏ |s‚àó).

BEYOND MONTE CARLO
185
Consequently, the density of the accepted samples Œ∏ jk converges to pABC
Œ∏|S (Œ∏ |s‚àó) as
Œ¥ ‚Üì0 for every Œ∏ ‚ààRp. By Scheff¬¥e‚Äôs lemma (Scheff¬¥e, 1947), this implies the con-
vergence of probabilities in (5.2) and thus the Ô¨Årst statement of the proposition is
proved.
For the second part of the proposition, we assume that S is a sufÔ¨Åcient statistic.
By deÔ¨Ånition 5.2 of sufÔ¨Åciency we have pX|S,Œ∏(x|s, Œ∏) = pX|S(x|s). Using this fact,
and the fact that S(X) is a deterministic function of X, we get
pX|Œ∏(x|Œ∏) = pX,S|Œ∏

x, S(x)
Œ∏

= pX|S,Œ∏

x
 S(x), Œ∏

¬∑ pS|Œ∏

S(x)
Œ∏

= pX|S

x
 S(x)

¬∑ pS|Œ∏

S(x)
Œ∏

.
Similarly, we Ô¨Ånd
pX(x) = pX,S

x, S(x)

= pX|S

x
 S(x)

¬∑ pS

S(x)

.
Using these two relations, we get
pŒ∏|X(Œ∏ |x) = pX|Œ∏(x|Œ∏) ¬∑ pŒ∏(Œ∏)
pX(x)
= pX|S

x
 S(x)

pS|Œ∏

S(x)
Œ∏

¬∑ pŒ∏(Œ∏)
pX|S

x
 S(x)

pS

S(x)

= pS|Œ∏

S(x)
Œ∏

pŒ∏(Œ∏)
pS

S(x)

= pABC
Œ∏|S

Œ∏
 S(x)

.
This completes the proof of the second statement.
Finally, using equation (5.4) and the deÔ¨Ånition of ZŒ¥ from the Ô¨Årst part of the
proof, we have
P

|Sj ‚àís‚àó| ‚â§Œ¥

=

Rp

BŒ¥(s‚àó)
pS|Œ∏(s j |Œ∏) ds j pŒ∏(Œ∏) dŒ∏
=
BŒ¥(s‚àó)


Rp rŒ¥(Œ∏) dŒ∏
=
BŒ¥(s‚àó)
ZŒ¥.
Thus, the number NŒ¥ of proposals required to generate one sample is geometrically
distributed with mean
E(NŒ¥) =
1
P

|Sj ‚àís‚àó| ‚â§Œ¥
 =
1
BŒ¥(s‚àó)
ZŒ¥
=
1
Œ¥qB1(s‚àó)
ZŒ¥
.

186
AN INTRODUCTION TO STATISTICAL COMPUTING
Since ZŒ¥ ‚ÜíZ as Œ¥ ‚Üì0, we Ô¨Ånd
lim
Œ¥‚Üì0
E(NŒ¥)
Œ¥‚àíq
=
1
B1(s‚àó)
Z
and consequently E(NŒ¥) = O(Œ¥‚àíq). This completes the proof.
To illustrate use of the ABC method, we consider a very simple example. In the
example, use of ABC is not really necessary, but the simplicity of the situation helps
to illustrate the method.
Example 5.4
For the prior let Œº ‚àºU[‚àí10, 10] and œÉ ‚àºExp(1), independently,
and set Œ∏ = (Œº, œÉ) ‚ààR2. Assume that the data consist of i.i.d. values X1, . . . , Xn ‚àº
N(Œº, œÉ 2) and that we have observed values x = (x1, . . . , xn) for the data. Our aim
is to generate samples from the posterior distribution of Œ∏ for given observations x.
To apply the ABC method, we Ô¨Årst have to choose a summary statistic S. From
the second statement of proposition 5.3 we know that it is best to choose a sufÔ¨Åcient
statistic. In the simple case considered here, the statistic
S(x) =

1
n
n

i=1
xi, 1
n
n

i=1
x2
i

.
is known to be sufÔ¨Åcient for Œ∏ = (Œº, œÉ) (see, e.g. Casella and Berger, 2001, example
6.2.9). Denote the components of S(x) where x is the observed data by s‚àó
1 and s‚àó
2.
Then we can use ABC with this summary statistic, to generate posterior samples as
follows:
(a) Sample Œº j ‚àºU[‚àí10, 10] and œÉ j ‚àºExp(1) independently.
(b) Sample X j,1, . . . , X j,n ‚àºN(Œº j, œÉ 2
j ) i.i.d.
(c) Let s j,1 = 1
n
	n
i=1 X j,i and s j,2 = 1
n
	n
i=1 X2
j,i.
(d) Accept Œ∏ j = (Œº j, œÉ 2
j ) if (si,1 ‚àís‚àó
1)2 + (s j,2 ‚àís‚àó
2)2 ‚â§Œ¥2.
In this example, the posterior density can easily be computed explicitly, and thus
methods like MCMC could be applied in this situation. But even here, implementation
of ABC is easier than implementation of MCMC, since we do not need to perform
the calculation to obtain the formula for the posterior density. The power of ABC
lies in the fact that we can use the method without evaluating the posterior density
(except possibly to verify the assumptions of proposition 5.3) and thus ABC can be
applied in more general situations than MCMC.
The results of a simulation with n = 20 and s‚àó= (6.989, 52.247) are shown in
Figure 5.1. Figure 5.1(a) corresponds to Œ¥ = 0.05 (generating one sample on average
took 60 549 proposals), Figure 5.1(b) corresponds to Œ¥ = 0.15 (6022 proposals per
sample) and Figure 5.1(c) corresponds to Œ¥ = 0.25 (1059 proposals per sample).

BEYOND MONTE CARLO
187
From algorithm 5.1 is is clear that in the limit Œ¥ ‚Üí‚àûthe distribution of the
output converges to the prior distribution: in the algorithm, the proposals Œ∏ j are
generated from the prior density pŒ∏ and if Œ¥ is large most or even all of the generated
samples are output without any change. This effect is clearly visible in the right-hand
column of Figure 5.1: as Œ¥ increases, the histograms get closer and closer to the
Exp(1)-distribution used as the prior for œÉ.
5
6
7
8
9
0.0
0.5
1.0
1.5
0
1
2
3
4
0.0
0.5
1.0
1.5
5
6
7
8
9
0.0
0.5
1.0
1.5
0
1
2
3
4
0.0
0.5
1.0
1.5
Œº
5
6
7
8
9
0.0
0.5
1.0
1.5
œÉ
0
1
2
3
4
0.0
0.5
1.0
1.5
(a)
(b)
(c)
Figure 5.1
The effect of the approximation parameter Œ¥ in the ABC method from
example 5.4. The histograms show the distribution of the ABC samples, the solid
lines give the exact posterior density of Œº and œÉ. The rows correspond to different
values of Œ¥: (a) Œ¥ = 0.05; (b) Œ¥ = 0.15; Œ¥ = 0.25; The Ô¨Ågure clearly shows that the
distribution of the ABC samples gets more accurate as Œ¥ decreases (from bottom to
top). On the other hand, computational cost increases with accuracy.

188
AN INTRODUCTION TO STATISTICAL COMPUTING
In practical applications it is important to scale the components of the summary
statistic S so that they are all approximately of the same order of magnitude. For the
generated proposals, the range of values observed for each of the components of S
must have width bigger than Œ¥, otherwise a situation can arise where for a given Œ¥
only the largest component of the summary statistic has an appreciable effect on the
decision whether to accept a sample and the other components of S are effectively
ignored. The required scaling causes no problems, since a rescaled version (and
indeed any bijective image) of a sufÔ¨Åcient statistic is again sufÔ¨Åcient.
5.1.2
Approximate Bayesian Computation with regression
The basic ABC method as described in the previous section can be computationally
very expensive. Many variants of ABC, aiming to reduce the computational cost, are
used in application areas. In this section we describe one approach to constructing such
improved variants of ABC. This approach is based on the idea of accepting a larger
proportion of the samples and then to numerically compensate for the systematic
error introduced by the discrepancy between the sampled values s j = S(X j) and the
observed value s‚àó= S(x‚àó).
The method discussed here is based on the assumption that the samples Œ∏ j can be
written as
Œ∏ j ‚âàf (Sj) + Œµ j
for all accepted j, where f (s) = E(Œ∏ |S = s) and the Œµ j are independent of each other
and of the Sj. If this relation holds at least approximately, we can use the modiÔ¨Åed
samples
ÀúŒ∏ j = f (s‚àó) + Œµ j
= f (Sj) + Œµ j + f (s‚àó) ‚àíf (Sj)
(5.5)
= Œ∏ j + f (s‚àó) ‚àíf (Sj)
instead of Œ∏ j in order to transform samples corresponding to S = Sj into samples
corresponding to the required value S = s‚àó. This idea is made more rigorous by the
following result.
Lemma 5.5
Let Œµ ‚ààRp and X ‚ààRn be independent random variables. Furthermore,
let S: Rn ‚ÜíRq and f : Rq ‚ÜíRp be functions and deÔ¨Åne Œ∏ ‚ààRp by
Œ∏ = f

S(X)

+ Œµ.
(5.6)
Then the following statements hold:
(a) S is a sufÔ¨Åcient statistic for Œ∏.
(b) Let s‚àó‚ààRq. Then the conditional distribution of Œ∏, given S(X) = s‚àó, coin-
cides with the distribution of ÀúŒ∏ = Œ∏ + f (s‚àó) ‚àíf (S(X)).

BEYOND MONTE CARLO
189
Proof
For the proof we restrict ourselves to the case where the distributions of X
and Œµ have densities. In this case, since Œ∏ can be written in the form (5.6), the pair
(X, Œ∏) has joint density
pX,Œ∏(x, Œ∏) = pX(x) ¬∑ pŒµ

Œ∏ ‚àíf

S(x)

.
Consequently, the conditional density of X given Œ∏ is
pX|Œ∏(x|Œ∏) = pX,Œ∏(x, Œ∏)
pŒ∏(Œ∏)
= pX(x) ¬∑
pŒµ

Œ∏ ‚àíf

S(x)

pŒ∏(Œ∏)
.
Thus, since the Ô¨Årst term is independent of Œ∏ and the second term depends on x only
via S(x), we can use the factorisation theorem for sufÔ¨Åcient statistics (see e.g. Casella
and Berger, 2001, theorem 6.2.6) to conclude that S is sufÔ¨Åcient for Œ∏. This proves
the Ô¨Årst statement of the lemma.
The second statement is a consequence of the independence between X and Œµ: the
expression f (S(X)), conditioned on S(X) = s‚àóis the constant value f (s‚àó) and, since
Œµ is independent of X, conditioning on S(X) does not change the distribution of Œµ.
Thus, the conditional distribution of Œ∏ = f (S(X)) + Œµ coincides with the distribution
of ÀúŒ∏ = f (s‚àó) + Œµ. Substituting Œµ = Œ∏ ‚àíf (S(X)) into this expression completes the
proof.
Since we apply the correction only to samples which are accepted in the basic
ABC algorithm, that is where s j is close to s‚àó, we only need to consider f in a
neighbourhood of s. If f is smooth and Œ¥ is chosen small enough, then f will be
approximately afÔ¨Åne. For this reason, the usual approach to modelling f is to assume
that near s‚àóthe function f is an afÔ¨Åne function of the form
f (s) = Œ± + s‚ä§Œ≤
for all s ‚ààRq, where Œ± ‚ààRp and Œ≤ ‚ààRq√óp. In this case, estimates ÀÜŒ± and ÀÜŒ≤ for the
parameters Œ± and Œ≤ can be computed from the values (s j, Œ∏ j), using the least squares
method, that is by Ô¨Ånding ÀÜŒ± and ÀÜŒ≤ which minimise the residual sum of squares
r(Œ±, Œ≤) =
N

j=1
Œ∏ j ‚àíf (s j)
2 =
N

j=1
Œ∏ j ‚àíŒ± ‚àís‚ä§
j Œ≤
2.
To compute the solution of the multidimensional least-squares problem, we
rewritetheproblem inmatrixnotation. Usingthevectors s j ‚ààRq for j = 1, 2, . . . , N,
we deÔ¨Åne a matrix S ‚ààRN√ó(q+1) by
Sji =
(s j)i
if i ‚àà{1, 2, . . . , q} and
1
if i = q + 1
(5.7)

190
AN INTRODUCTION TO STATISTICAL COMPUTING
for all j ‚àà{1, 2, . . . , N} and i ‚àà{1, 2, . . . , q + 1}. Using the coefÔ¨Åcients Œ± ‚ààRp
and Œ≤ ‚ààRq√óp, we deÔ¨Åne a matrix B ‚ààR(q+1)√óp by
Bik =
Œ≤ik
if i ‚àà{1, 2, . . . , q} and
Œ±k
if i = q + 1
(5.8)
for all i ‚àà{1, 2, . . . , q + 1} and k ‚àà{1, 2, . . . , p}. Finally, we collect the vectors Œ∏ j
for j = 1, 2, . . . , N in a matrix 	 ‚ààRN√óp, given by
	 jk = (Œ∏ j)k
(5.9)
for all j ‚àà{1, 2, . . . , N} and k ‚àà{1, 2, . . . , p}. Using this notation, we have f (s j)k =
(SB) jk where SB is the matrix product of S and B (Figure 5.2), and the residual sum
of squares can be rewritten as
r(Œ±, Œ≤) =
n

j=1
p

k=1
(	 ‚àíSB)2
jk.
The matrices 	 and S only depend on the given data while the matrix B collects the
entries of the unknowns Œ± and Œ≤ as described in (5.8). Using the standard theory for
multidimensional least squares, the least squares estimate for B can be found as
ÀÜB = (S‚ä§S)‚àí1S‚ä§	,
Œ∏1
Œ∏2
...
Œ∏N
Œò
=
s1
1
s2
1
...
...
sN
1
S
¬∑
Œ±
Œ≤
B
+
Œµ1
Œµ2
...
ŒµN
Œµ
Figure 5.2
Illustration of the matrices 	, S and B introduced in Section 5.1.2. The
matrices 	 and S are given, and the aim is to estimate B (and thus Œ± and Œ≤) using
the least squares method.

BEYOND MONTE CARLO
191
where S‚ä§is the transposed matrix and (S‚ä§S)‚àí1 is the inverse of S‚ä§S. Finally, the
estimates for Œ± and Œ≤ can be extracted from ÀÜB using (5.8), that is by deÔ¨Åning
ÀÜŒ±k = ÀÜBq+1,k and
ÀÜŒ≤ik = ÀÜBik
(5.10)
for all j ‚àà{1, 2, . . . , N} and k ‚àà{1, 2, . . . , p}. Substituting the result of the least
squares estimation into (5.5), the modiÔ¨Åed samples are then
ÀúŒ∏ j = Œ∏ j + (s‚àó‚àís j)‚ä§ÀÜŒ≤.
Since f (s) ‚âàÀÜŒ± + s‚ä§ÀÜŒ≤, we can use lemma 5.5 to conclude that the distribution of the
resulting samples ÀúŒ∏ j approximately coincides with the conditional distribution of Œ∏
given S = s‚àó. The resulting algorithm follows.
Algorithm 5.6
(Approximate Bayesian Computation with regression)
input:
data x ‚ààRn
the prior density œÄ for the unknown parameter Œ∏ ‚ààRp
a summary statistic S: Rn ‚ÜíRq
an approximation parameter Œ¥ > 0
the output sample size N
randomness used:
samples Œ∏ j ‚àºpŒ∏ and X j ‚àºpX|Œ∏(¬∑|Œ∏ j) for j ‚ààN
output:
ÀúŒ∏1, . . . , ÀúŒ∏N, approximately distributed with density pŒ∏|X(Œ∏ |x)
1: s‚àó‚ÜêS(x‚àó)
2: Use basic ABC to get samples Œ∏1, . . . , Œ∏N and s1, . . . , sN.
3: Compute the matrix S ‚ààRN√ó(q+1) given by (5.7).
4: Compute C = S‚ä§	 ‚ààR(q+1)√óp, where 	 is given by (5.9).
5: Compute the matrix S‚ä§S ‚ààR(q+1)√ó(q+1).
6: Solve the system of linear equations (S‚ä§S) ÀÜB = C, to Ô¨Ånd the matrix
ÀÜB ‚ààR(q+1)√óp.
7: Construct ÀÜŒ≤ from B, using (5.10).
8: for j = 1, 2, . . . , N do
9:
ÀúŒ∏ j ‚ÜêŒ∏ j + (s‚àó‚àís j)‚ä§ÀÜŒ≤
10: end for
The correction of samples implemented by this algorithm allows to use larger
values of Œ¥, resulting in a more efÔ¨Åcient method, while still getting reason-
ably accurately distributed samples. This is illustrated by the difference between
Figure 5.1 (for basic ABC) and Figure 5.3 (for ABC with regression): while the
distribution of samples generated by basic ABC for Œ¥ = 0.25 in Figure 5.1(c) is very
different from the exact distribution (shown as solid lines), the distribution of samples

192
AN INTRODUCTION TO STATISTICAL COMPUTING
Œº
5
6
7
8
9
0.0
0.5
1.0
1.5
œÉ
0
1
2
3
4
0.0
0.5
1.0
1.5
Figure 5.3
The improvements in the distribution of ABC samples which can be
achieved by using algorithm 5.6 instead of algorithm 5.1 in the situation of example
5.4. The value of Œ¥ = 0.25 used for this Ô¨Ågure is the same as for Figure 5.1(c).
Comparing this Ô¨Ågure with Figure 5.1(c) shows that ABC with regression gives
samples with a much improved distribution.
obtained from ABC with regression for Œ¥ = 0.25 in Figure 5.3 is reasonably close to
the exact distribution.
5.2
Resampling methods
Resampling methods are applied in situations where a sample of data is available for a
stochastic system, but where no adequate model is available to describe the data. This
can be the case, for example when the data are obtained by physical measurements
of the state of a complex system. In such situations, Monte Carlo methods cannot be
applied directly, because generation of samples requires a statistical model.
The methods described in this section are based on the idea of replacing the sam-
ples in Monte Carlo methods with values picked at random from the available sample
of data. This procedure of reusing the data for sampling is called resampling and the
resulting methods are called resampling methods. While such methods will typically
be less accurate than Monte Carlo methods, their advantages are the simplicity of the
resulting algorithms and the wide applicability of these methods.
5.2.1
Bootstrap estimates
The basis of all resampling methods is to replace the distribution given by a model
with the ‚Äòempirical distribution‚Äô of the given data, as described in the following
deÔ¨Ånition.
DeÔ¨Ånition 5.7
Given a sequence x = (x1, x2, . . . , xM), the distribution of X‚àó= xK,
where the index K is random and uniformly distributed on the set {1, 2, . . . , M}, is
called the empirical distribution of the xi. In this chapter we denote the empirical
distribution of x by P‚àó
x .

BEYOND MONTE CARLO
193
In the deÔ¨Ånition, the vector x is assumed to be Ô¨Åxed. The randomness in X‚àóstems
from the choice of a random element, with index K ‚àºU{1, , 2, . . . , M}, of this Ô¨Åxed
sequence. Computational methods which are based on the idea of approximating an
unknown ‚Äòtrue‚Äô distribution by an empirical distribution are called bootstrap methods.
Assume that X‚àóis distributed according to the empirical distribution P‚àó
x . Then
we have
P(X‚àó= a) = 1
M
M

i=1
1{a}(xi),
that is under the empirical distribution, the probability that X‚àóequals a is given by
the relative frequency of occurrences of a in the given data. Similarly, we have the
relations
P

X‚àó‚ààA

= 1
M
M

i=1
1A(xi)
and
E

f (X‚àó)

=

a‚àà{x1,...,xM}
f (a)P

X‚àó= a

=

a‚àà{x1,...,xM}
f (a) 1
M
M

i=1
1{a}(xi) = 1
M
M

i=1
f (xi).
(5.11)
Some care is needed when verifying this relation: the sums where the index a runs
over the set {x1, . . . , xM} have only one term for each element of the set, even if the
corresponding value occurs repeatedly in the given data.
Example 5.8
Let the data x = (1, 2, 1, 4) be given and let X‚àóbe distributed accord-
ing to the empirical distribution of x. Then we have the probabilities P(X‚àó= 1) =
2/4 = 1/2 and P(X‚àó= 2) = P(X‚àó= 4) = 1/4. The expectation of X‚àóis
E(X‚àó) = 1 ¬∑ 2
4 + 2 ¬∑ 1
4 + 4 ¬∑ 1
4 = 2 + 2 + 4
4
= 2.
In the context of resampling methods, the data X = (X1, X2, . . . , X M) is assumed
to be an i.i.d. sample from some distribution P unknown to us. When considering
X‚àó‚àºP‚àó
X in this situation, there are two different levels of randomness involved:
Ô¨Årst, the data X and thus the empirical distribution P‚àó
X is random. And secondly,
for every instance of the data X, the sample X‚àócontains the additional randomness
from the random choice of the index K in deÔ¨Ånition 5.7. In this section we write
P‚àó
X(¬∑) and E‚àó
X(¬∑) for probabilities and expectations which take X as being Ô¨Åxed and
which only consider the randomness from generating X‚àó‚àºP‚àó
X. Technically, P‚àó
X is

194
AN INTRODUCTION TO STATISTICAL COMPUTING
the conditional probability and E‚àó
X is the conditional expectation, both conditioned
on the value of X. The following lemma shows how these two different levels of
randomness combine to create the total variance.
Lemma 5.9
Let X = (X1, . . . , X M) where the Xi ‚àºP are i.i.d. Furthermore, let
X‚àó
1, . . . , X‚àó
n ‚àºP‚àó
X be i.i.d. and Y ‚àó= f (X‚àó
1, . . . , X‚àó
n) for some function f . Then
E(Y ‚àó) = E

E‚àó
X(Y ‚àó)

(5.12)
and
Var(Y ‚àó) = E

Var‚àó
X(Y ‚àó)

+ Var

E‚àó
X(Y ‚àó)

.
(5.13)
Proof
Since we have E‚àó
X(Y ‚àó) = E(Y ‚àó|X), we can use the tower property
E(E(Y |X)) = E(Y) of the conditional expectation to get (5.12). For the variance
(5.13) we Ô¨Ånd
Var(Y ‚àó) = E

(Y ‚àó)2
‚àíE(Y ‚àó)2
= E

E((Y ‚àó)2|X)

‚àíE

E(Y ‚àó|X)
2
= E

E((Y ‚àó)2|X) ‚àíE(Y ‚àó|X)2
+ E

E(Y ‚àó|X)2
‚àíE

E(Y ‚àó|X)
2
= E

Var(Y ‚àó|X)

+ Var

E(Y ‚àó|X)

= E

Var‚àó
X(Y ‚àó)

+ Var

E‚àó
X(Y ‚àó)

.
This completes the proof.
If we consider the data x = (x1, . . . , xM) to be an instance of an i.i.d. sample
from the distribution P, and if we let X‚àó‚àºP‚àó
x as well as X ‚àºP, then the law of
large numbers (theorem A.8) guarantees
P‚àó
x (X‚àó‚ààA) = 1
M
M

i=1
1A(xi) ‚âàP(X ‚ààA)
(5.14)
for every set A and sufÔ¨Åciently large M. Similarly, we Ô¨Ånd
E‚àó
x

f (X‚àó)

= 1
M
M

i=1
f (Xi) ‚âàE

f (X)

for all functions f . These two equations show that the distribution of the random
variable X‚àó(i.e. the empirical distribution P‚àó
x ) can be used as an approximation to
the distribution of X (i.e. the unknown distribution P).

BEYOND MONTE CARLO
195
In typical applications of the bootstrap method, the function f depends on
n independent values, that is we want to compute an expectation of the form
E( f (X1, . . . , Xn)) where X1, . . . , Xn are i.i.d., distributed with an unknown dis-
tribution P. In these cases, we can use the approximation
E‚àó
x

f (X‚àó
1, . . . , X‚àó
n)

‚âàE

f (X1, . . . , Xn)

,
(5.15)
where X‚àó
1, . . . , X‚àó
n are independent samples from the empirical distribution P‚àó
x .
Finally, if we are interested in any property Œ∏ = Œ∏(P) of the unknown distribution
P we can approximate the result by considering the same property of the empirical
distribution P‚àó
x :
Œ∏(P) ‚âàŒ∏(P‚àó
x ).
(5.16)
For example, if œÉ 2(P) is the variance of the distribution P (or equivalently, of X ‚àºP),
then we can use the approximation
œÉ 2(P) ‚âàœÉ 2(P‚àó
x ) = Var‚àó
x(X‚àó)
where X‚àó‚àºP‚àó
x . Since the distribution P‚àó
x of X‚àóis known, the value Var‚àó
x(X‚àó) can
be computed from the given data x.
Equation (5.14), equation (5.15) and equation (5.16) illustrate a general method
for constructing estimators from given data x. The method is based on two different
(but related) substitutions:
(a) Every direct occurrence of the unknown distribution P is replaced with the
empirical distribution P‚àó
x .
(b) All instances of random variables X ‚àºP are replaced with bootstrap samples
X‚àó‚àºP‚àó
x .
The examples above shows only one of the two substitutions at a time, but
in the next section we will see an application where both substitutions occur
simultaneously. Estimates based on this methodology are called bootstrap esti-
mates and samples (X‚àó
1, . . . , X‚àó
n) from the empirical distribution are called bootstrap
samples.
Example 5.10
Let X1, X2, . . . , Xn be i.i.d. with P(Xi = 1) = p and P(Xi = 0) =
1 ‚àíp. Assume that the value of p is unknown to us, but that we have a sample x =
(x1, x2, . . . , xn) from the distribution of the Xi. Since we do not know the value of p,
we do not know the distribution P of the random variables Xi. As we have seen above,
the empirical distribution P‚àó
x can be used to approximate the unknown distribution P:
let X‚àó‚àºP‚àó
x and k = 	n
i=1 xi. Since X‚àóis chosen uniformly from the entries of x, we
have P(X‚àó= 1) = k/n and P(X‚àó= 0) = 1 ‚àík/n. A bootstrap sample X‚àó
1, . . . , X‚àó
n
can be constructed by generating n i.i.d. samples from the distribution P‚àó
x . Expressions

196
AN INTRODUCTION TO STATISTICAL COMPUTING
involving Xi can be approximated using the corresponding expression for X‚àó
i . For
example, using (5.14), we Ô¨Ånd the bootstrap estimate for P(	n
i=1 Xi ‚â§a) as
P
 n

i=1
Xi ‚â§a

‚âàP‚àó
x
 n

i=1
X‚àó
i ‚â§a

=
a

j=1
P‚àó
x
 n

i=1
X‚àó
i = j

=
a

j=1
n
j
 k
n
 j 
1 ‚àík
n
n‚àíj
for all a ‚ààN. This result is not surprising: the bootstrap estimate equals the exact
probability where p is replaced by the estimate k/n.
The difÔ¨Åculty in bootstrap methods lies in evaluating the expressions involving
the empirical distribution P‚àó
x in (5.14), (5.15) and (5.16). In simple cases, such as in
example 5.10, this can be done analytically but in most situations an analytical solution
will not be available. Since generating samples from the empirical distribution is easy,
Monte Carlo methods can be used instead. For example, in the case of approximation
(5.15) we can generate independent samples X‚àó( j)
i
‚àºP‚àó
x for i = 1, 2, . . . , n and j =
1, 2, . . . , N, and then compute the approximation
E‚àó
x

f (X‚àó
1, . . . , X‚àó
n)

‚âà1
N
N

j=1
f

X‚àó( j)
1
, . . . , X‚àó( j)
n

.
(5.17)
This method leads to the following algorithm.
Algorithm 5.11
(general bootstrap estimate)
input:
data x1, x2, . . . , xM ‚ààA with values in some set A
f : An ‚ÜíR
N ‚ààN
randomness used:
a sequence (K ( j)
i ) j‚ààN, i=1,...,n with K ( j)
i
‚àºU{1, 2, . . . , M} i.i.d.
output:
an estimate for E( f (X1, . . . , Xn)) where X1, . . . , Xn are i.i.d. from the
distribution of the data xi
distribution of the data xi
1: s ‚Üê0
2: for j = 1, 2, . . . , N do
3:
generate K ( j)
1 , . . . , K ( j)
n
‚àºU{1, 2, . . . , M} i.i.d.

BEYOND MONTE CARLO
197
4:
let X‚àó( j)
i
‚ÜêxK ( j)
i
for i = 1, 2, . . . , n
5:
s ‚Üês + f (X‚àó( j)
1
, . . . , X‚àó( j)
n
)
6: end for
7: return s/N
As explained above, this algorithm is based on the following sequence of approx-
imations:
1
N
N

j=1
f

X‚àó( j)
1
, . . . , X‚àó( j)
n

‚âàE‚àó
x

f (X‚àó
1, . . . , X‚àó
n)

‚âàE

f (X1, . . . , Xn)

.
The error in the Ô¨Årst of these two approximations goes to 0 as N increases. Since we
control generation of the samples X‚àó( j), we can make this error arbitrarily small at
the expense of additional computation time. The error in the second approximation
decreases as M ‚Üí‚àû. Normally, the given data set x1, x2, . . . , xM is Ô¨Åxed and cannot
be easily extended; in these cases there is no way to reduce the error in the second
approximation.
Proving the convergence
E‚àó
x

f (X‚àó
1, . . . , X‚àó
n)

‚ÜíE

f (X1, . . . , Xn)

for M ‚Üí‚àûis challenging in the general setting and results depend on regularity
properties of the function f . The ususal approach is to prove convergence only for the
speciÔ¨Åc forms of f arising in applications, instead of relying on general theorems.
In most applications, the number M of available samples equals the number n
of arguments of the function f , that is enough data are given to compute one value
f (X1, . . . , Xn). The bootstrap estimate computed by algorithm 5.11 allows to reuse
the available information to also get an estimate for the expectation of this value.
Some care is needed when using bootstrap estimates in practice: while
the arguments X‚àó
1, . . . , X‚àó
n of f in Equation (5.15) have (approximately) the correct
distribution, with large probability the bootstrap sample contains duplicate values and
thus the arguments are not independent. On the other hand, the arguments X1, . . . , Xn
on the right-hand side of (5.15) are independent. For this reason, the bootstrap esti-
mate (5.17) is usually biased (this is in contrast to the Monte Carlo estimate, which
by proposition 3.14 is always unbiased) and sometimes it is not even clear that the
total error decreases to 0 as the value of n increases.
5.2.2
Applications to statistical inference
The main application of the bootstrap method in statistical inference is to quantify
the accuracy of parameter estimates.

198
AN INTRODUCTION TO STATISTICAL COMPUTING
In this section, we will consider parameters as a function of the corresponding
distribution: if Œ∏ is a parameter, for example the mean or the variance, then we
write Œ∏(P) for the corresponding parameter. In statistics, there are many ways of
constructing estimators for a parameter Œ∏. One general method for constructing
parameter estimators, the plug-in principle, is given in the following deÔ¨Ånition.
DeÔ¨Ånition 5.12
Consider an estimator ÀÜŒ∏n = ÀÜŒ∏n(X1, . . . , Xn) for a parameter Œ∏(P).
The estimator ÀÜŒ∏n satisÔ¨Åes the plug-in principle, if it satisÔ¨Åes the relation
ÀÜŒ∏n(x1, . . . , xn) = Œ∏(P‚àó
x ),
(5.18)
for all x = (x1, . . . , xn), where P‚àó
x is the empirical distribution of x. In this case, ÀÜŒ∏n
is called the plug-in estimator for Œ∏.
Since the idea of bootstrap methods is to approximate the distribution P by the
empirical distribution P‚àó
x , plug-in estimators are particularly useful in conjunction
with bootstrap methods.
Example 5.13
The plug-in estimator for the mean Œº is found by taking the mean
of the empirical distribution. Taking X‚àó‚àºP‚àó
x we get
ÀÜŒº(x1, . . . , xn) = Œº

P‚àó
x

= E

X‚àó
and using equation (5.11), with M = n and f (x) = x, we Ô¨Ånd
ÀÜŒº(x1, . . . , xn) = 1
n
n

i=1
xi.
Thus, the plug-in estimator for the mean is just the sample average.
Example 5.14
The plug-in estimator for the variance œÉ 2 is the variance of the
empirical distribution. Taking X‚àó‚àºP‚àó
x again, we get
ÀÜœÉ 2(x1, . . . , xn) = œÉ 2
P‚àó
x

= Var

X‚àó
= E

(X‚àó)2
‚àí

E(X‚àó)
2.
From equation (5.11) we Ô¨Ånd
ÀÜœÉ 2(x1, . . . , xn) = 1
n
n

i=1
x2
i ‚àí

1
n
n

i=1
xi
2
,

BEYOND MONTE CARLO
199
and using the abbreviation ¬Øx = 1
n
	n
i=1 xi we can rewrite this as
ÀÜœÉ 2(x1, . . . , xn) = 1
n
n

i=1
x2
i ‚àí¬Øx2
= 1
n
 n

i=1
x2
i ‚àí2
n

i=1
xi ¬Øx +
n

i=1
¬Øx2

= 1
n
n

i=1
(xi ‚àí¬Øx)2.
This is the plug-in estimator for the variance.
5.2.2.1
Bootstrap estimates of the bias
The bias, as given in deÔ¨Ånition 3.9, is a measure for the systematic error of an
estimator. In the notation of this section, the bias of an estimator ÀÜŒ∏n for a parameter Œ∏
is given by
bias( ÀÜŒ∏n) = EP( ÀÜŒ∏n) ‚àíŒ∏(P),
where EP(¬∑) denotes the expectation with respect to the distribution P. If the distri-
bution P is not known, we cannot compute the bias analytically but for a given i.i.d.
sample X = (X1, . . . , Xn) from the distribution P we can Ô¨Ånd the bootstrap estimate
for the bias by applying the bootstrap principle. This results in the estimator

bias
‚àó( ÀÜŒ∏n) = E‚àó
X( ÀÜŒ∏‚àó
n ) ‚àíŒ∏(P‚àó
X)
(5.19)
for the bias, where
ÀÜŒ∏‚àó
n = ÀÜŒ∏n

X‚àó
1, . . . , X‚àó
n

(5.20)
and X‚àó
1, . . . , X‚àó
n ‚àºP‚àó
X are i.i.d. As before, we write E‚àó
X(¬∑) to indicate that the expec-
tation takes X1, . . . , Xn as Ô¨Åxed and only considers the additional randomness in
X‚àó
1, . . . , X‚àó
n.
Since, for given X1, . . . , Xn, the distribution P‚àó
X is known, we can evaluate
the right-hand side of (5.19): If we assume that ÀÜŒ∏n satisÔ¨Åes the plug-in principle,
then, by equation (5.18), we have Œ∏(P‚àó
X) = ÀÜŒ∏n(X1, . . . , Xn). For the evaluation of
E‚àó( ÀÜŒ∏‚àó
n ) we can use a Monte Carlo estimate: we generate samples X‚àó( j)
i
‚àºP‚àó
x i.i.d.
for i = 1, . . . , n and j = 1, 2, . . . , N and let
ÀÜŒ∏‚àó( j)
n
= ÀÜŒ∏n

X‚àó( j)
1
, . . . , X‚àó( j)
n

(5.21)

200
AN INTRODUCTION TO STATISTICAL COMPUTING
as well as
ÀÜŒ∏‚àón = 1
N
N

j=1
ÀÜŒ∏‚àó( j)
n
.
(5.22)
Finally, for sufÔ¨Åciently large N, we can use the approximation ÀÜŒ∏‚àón ‚âàE‚àó( ÀÜŒ∏‚àó
n ). Substi-
tuting these expressions into equation (5.19), we get

bias
‚àó( ÀÜŒ∏n) ‚âàÀÜŒ∏‚àón ‚àíÀÜŒ∏n(X1, . . . , Xn).
This is the usual form for the bootstrap estimate of the bias of the estimator ÀÜŒ∏n.
Some care is needed here, since there are two different levels of estimation
involved: ÀÜŒ∏n is an estimator for Œ∏(P) while 
bias
‚àóis an estimate for the bias of the
estimate ÀÜŒ∏n.
Algorithm 5.15
(bootstrap estimate of the bias)
input:
data x1, x2, . . . , xn
the plug-in estimator ÀÜŒ∏n for a parameter Œ∏
N ‚ààN
randomness used:
K ( j)
i
‚àºU{1, 2, . . . , n} i.i.d. for i = 1, . . . , n and j = 1, . . . , N
output:
an estimate for the bias of ÀÜŒ∏n
1: for j=1, 2, . . . , N do
2:
generate K ( j)
1 , . . . , K ( j)
n
‚àºU{1, 2, . . . , n} i.i.d.
3:
let X‚àó( j)
i
‚ÜêxK ( j)
i
for i = 1, 2, . . . , n
4:
let ÀÜŒ∏‚àó( j)
n
‚ÜêÀÜŒ∏n(X‚àó( j)
1
, . . . , X‚àó( j)
n
)
5: end for
6: let ÀÜŒ∏‚àón = 1
N
N

j=1
ÀÜŒ∏‚àó( j)
n
7: return ÀÜŒ∏‚àón ‚àíÀÜŒ∏n(X1, . . . , Xn)
Both, the accuracy and the computational cost of this estimate increase when the
size n of the given data set and the Monte Carlo sample size N increase.
If ÀÜŒ∏n satisÔ¨Åes the plug-in principle, an elegant alternative formula for 
bias‚àócan
be derived. From (5.18) we know
ÀÜŒ∏n

X‚àó
1, . . . , X‚àó
n

= Œ∏

P‚àó
X‚àó


BEYOND MONTE CARLO
201
and substituting this relation into Equation (5.19) we get

bias
‚àó( ÀÜŒ∏n) = E‚àó
X

Œ∏

P‚àó
X‚àó

‚àíŒ∏

P‚àó
X

.
(5.23)
On the other hand, substituting the deÔ¨Ånition (5.18) of a plug-in estimate into the
deÔ¨Ånition of the bias gives
bias( ÀÜŒ∏n) = EP

Œ∏(P‚àó
X)) ‚àíŒ∏(P).
(5.24)
Comparing the expressions in (5.23) and (5.24) we Ô¨Ånd that the bootstrap estimate of
the bias makes use of the fact that, in some sense, P‚àó
X‚àórelates to P‚àó
X, as P‚àó
X does to P.
5.2.2.2
Bootstrap estimates of the standard error
The standard error of an estimator ÀÜŒ∏n for a parameter Œ∏(P), introduced in deÔ¨Å-
nition 3.10, is the standard deviation of ÀÜŒ∏n(X1, . . . , Xn) when the random sample
X1, . . . , Xn is distributed according to the distribution P:
se( ÀÜŒ∏n) = stdev
 ÀÜŒ∏n(X1, . . . , Xn)

.
(5.25)
Together with the bias, the standard error is a measure for the accuracy of an estimator.
In this section we will see how the bootstrap method can be used to obtain an estimate
of the standard error of a given estimator.
Example 5.16
Consider the estimator ÀÜŒº(x) = 1
n
	n
i=1 xi for the mean Œº of a
distribution. The standard error of this estimator is given by
se( ÀÜŒºn) =



Var

1
n
n

i=1
Xi

= œÉ(P)
‚àön ,
where X1, . . . , Xn ‚àºP are i.i.d. and œÉ(P) denotes the standard deviation of the
distribution P.
The value se( ÀÜŒ∏n) does not directly depend on P, but only on the values Xi.
Consequently, for Ô¨Ånding the bootstrap estimate of the standard error, it is sufÔ¨Å-
cient to replace the random variables X1, . . . , Xn ‚àºP in (5.25) with i.i.d. samples
X‚àó
1, . . . , X‚àó
n ‚àºP‚àó
X from the empirical distribution. The resulting estimate is
se‚àó( ÀÜŒ∏n) = stdev‚àó ÀÜŒ∏‚àó
n

,
(5.26)
where
ÀÜŒ∏‚àó
n = ÀÜŒ∏n

X‚àó
1, . . . , X‚àó
n


202
AN INTRODUCTION TO STATISTICAL COMPUTING
and the symbol stdev‚àó(¬∑) indicates the standard deviation for Ô¨Åxed values of
X1, . . . , Xn, taking only the randomness in the X‚àó
i into account. In contrast to the
bootstrap estimate of the bias from the previous section, for the bootstrap estimate of
the standard error we do not need to assume that the estimator ÀÜŒ∏n satisÔ¨Åes the plug-in
principle.
Example 5.17
Consider the estimate ÀÜŒºn(x) = 	n
i=1 xi/n for the mean. From
example 5.16 we know that the standard error of the mean is se( ÀÜŒºn) = œÉ(P)/‚àön.
Instead of using the general formula (5.26), we can apply the bootstrap principle to
se( ÀÜŒºn) and Ô¨Ånd the bootstrap estimate for the standard error of ÀÜŒºn as
se‚àó( ÀÜŒºn) = œÉ(P‚àó
X)
‚àön .
Using the result from example 5.14 we get
se‚àó( ÀÜŒºn) =

1
n
	n
i=1

Xi ‚àí¬ØX
2
‚àön
=



 1
n2
n

i=1

Xi ‚àí¬ØX
2.
This is the bootstrap estimate for the standard error of the mean.
Only in simple situations such as the one in example 5.17 is it possible to
compute the bootstrap estimate of the standard error analytically. Typically, the
standard deviation on the right-hand side of equation (5.26) cannot be evaluated
exactly and is approximated using a Monte Carlo estimate instead. This leads to the
following expression for the bootstrap estimate of the standard error:
se‚àó( ÀÜŒ∏n) ‚âà




1
N ‚àí1
N

j=1

ÀÜŒ∏‚àó( j)
n
‚àíÀÜŒ∏‚àón
2
where ÀÜŒ∏‚àón and the ÀÜŒ∏‚àó( j)
n
are given by equation (5.21) and equation (5.22), respectively.
This leads to the following algorithm.
Algorithm 5.18
(bootstrap estimate of the standard error)
input:
data x1, x2, . . . , xn
an estimator ÀÜŒ∏n for a parameter Œ∏
N ‚ààN
randomness used:
K ( j)
i
‚àºU{1, 2, . . . , n} i.i.d. for i = 1, . . . , n and j = 1, . . . , N
output:
an estimate for the standard error of ÀÜŒ∏n

BEYOND MONTE CARLO
203
1: for j=1, 2, . . . , N do
2:
generate K ( j)
1 , . . . , K ( j)
n
‚àºU{1, 2, . . . , n} i.i.d.
3:
let X‚àó( j)
i
‚ÜêxK ( j)
i
for i = 1, 2, . . . , n
4:
let ÀÜŒ∏‚àó( j)
n
‚ÜêÀÜŒ∏n(X‚àó( j)
1
, . . . , X‚àó( j)
n
)
5: end for
6: let ÀÜŒ∏‚àón = 1
N
N

j=1
ÀÜŒ∏‚àó( j)
n
7: return




1
N ‚àí1
N

j=1

ÀÜŒ∏‚àó( j)
n
‚àíÀÜŒ∏‚àón
2
Both the accuracy and the computational cost of this estimate increase when the
size n of the given data set and the Monte Carlo sample size N increase.
5.2.2.3
Bootstrap conÔ¨Ådence intervals
ConÔ¨Ådence intervals, as introduced in Section 3.4.2, are often difÔ¨Åcult to construct
exactly. There are many different approaches to construct bootstrap approximations
for conÔ¨Ådence intervals. Here we restrict ourselves to Ô¨Årst derive one simple bootstrap
conÔ¨Ådence interval and to then give a very short description of a more complicated
bootstrap conÔ¨Ådence interval.
A conÔ¨Ådence interval is an interval [U, V ], computed from the given data
(X1, . . . , Xn) ‚àºPŒ∏, such that
PŒ∏

Œ∏ ‚àà[U, V ]

‚â•1 ‚àíŒ±.
(5.27)
While we only require this relation to hold for the true value of Œ∏, this value is not
known and thus U = U(X1, . . . , Xn) and V = V (X1, . . . , Xn) are constructed such
that the relation (5.27) holds for all possible values of Œ∏ simultaneously. To construct
exact conÔ¨Ådence intervals, detailed knowledge of the family of distributions PŒ∏ is
required. In contrast, the bootstrap methods presented in this section allow to construct
approximate conÔ¨Ådence intervals, based on just the given data X1, . . . , Xn. These
methods use exactly the same information as is required for computing the point
estimate ÀÜŒ∏n. Thus, using bootstrap conÔ¨Ådence intervals allows information about
accuracy to be attached to any parameter estimate.
Let ÀÜŒ∏n be the plug-in estimate for the parameter Œ∏ = Œ∏(PŒ∏). To construct a conÔ¨Å-
dence interval, we can try to Ô¨Ånd values a and b such that
PŒ∏

ÀÜŒ∏n ‚àía ‚â§Œ∏ ‚â§ÀÜŒ∏n + b

= 1 ‚àíŒ±.
(5.28)

204
AN INTRODUCTION TO STATISTICAL COMPUTING
Direct application of the bootstrap principle, that is replacing PŒ∏ with P‚àó
X and
X1, . . . , Xn ‚àºPŒ∏ with X‚àó
1, . . . , X‚àó
n ‚àºP‚àó
X, yields the condition
P‚àó
X

ÀÜŒ∏‚àó
n ‚àía ‚â§Œ∏(P‚àó
X) ‚â§ÀÜŒ∏‚àó
n + b

= 1 ‚àíŒ±,
(5.29)
where ÀÜŒ∏‚àó
n is deÔ¨Åned in equation (5.20) and we write P‚àó
X to indicate that, when
computing the probability, the data X1, . . . , Xn are assumed to be Ô¨Åxed. We use the
relation (5.29) to construct values a and b for an approximate conÔ¨Ådence interval
for Œ∏.
Lemma 5.19
Let ÀÜŒ∏n be the plug-in estimator for Œ∏. Let Œ∏‚àó
Œ±/2 and Œ∏‚àó
1‚àíŒ±/2 be the Œ±/2
and 1 ‚àíŒ±/2 quantiles of the distribution of ÀÜŒ∏‚àó
n given by (5.20). DeÔ¨Åne
a = Œ∏‚àó
1‚àíŒ±/2 ‚àíÀÜŒ∏n

X1, . . . , Xn

and
b = ÀÜŒ∏n

X1, . . . , Xn

‚àíŒ∏‚àó
Œ±/2.
Then (5.29) is satisÔ¨Åed.
Proof
Since ÀÜŒ∏n is the plug-in estimator for Œ∏, we have ÀÜŒ∏n(X1, . . . , Xn) = Œ∏(P‚àó
X).
Substituting this relation into the deÔ¨Ånitions of a and b, we get
P‚àó
ÀÜŒ∏‚àó
n ‚àía ‚â§Œ∏(P‚àó
X) ‚â§ÀÜŒ∏‚àó
n + b

= P‚àó
‚àíŒ∏‚àó
1‚àíŒ±/2 + Œ∏(P‚àó
X) ‚â§Œ∏(P‚àó
X) ‚àíÀÜŒ∏‚àó
n ‚â§Œ∏(P‚àó
X) ‚àíŒ∏‚àó
Œ±/2

= P‚àó
Œ∏‚àó
1‚àíŒ±/2 ‚â•ÀÜŒ∏‚àó
n ‚â•Œ∏‚àó
Œ±/2

= 1 ‚àíŒ±.
This completes the proof.
An approximate conÔ¨Ådence interval [U ‚àó, V ‚àó] can now be found by substituting
the values a and b from the lemma into (5.28). The resulting boundaries are
U ‚àó= ÀÜŒ∏n

X1, . . . , Xn

‚àía = 2 ÀÜŒ∏n

X1, . . . , Xn

‚àíŒ∏‚àó
1‚àíŒ±/2
and
V ‚àó= ÀÜŒ∏n

X1, . . . , Xn

+ b = 2 ÀÜŒ∏n

X1, . . . , Xn

‚àíŒ∏‚àó
Œ±/2.
Normally, the quantiles Œ∏‚àó
Œ±/2 and Œ∏‚àó
1‚àíŒ±/2 cannot be computed analytically and are
estimated using Monte Carlo instead. In order to obtain such estimates, we generate

BEYOND MONTE CARLO
205
N samples, sort them in increasing order, and then pick out the entries with indices
NŒ±/2 and N(1 ‚àíŒ±/2), with appropriate rounding, from the sorted list. This technique
is used in the following algorithm.
Algorithm 5.20
(simple bootstrap conÔ¨Ådence interval)
input:
data x1, x2, . . . , xn
the plug-in estimator ÀÜŒ∏n for a one-dimensional parameter Œ∏
N ‚ààN
Œ± ‚àà(0, 1)
randomness used:
K ( j)
i
‚àºU{1, 2, . . . , n} i.i.d. for i = 1, . . . , n and j = 1, . . . , N
output:
an approximate conÔ¨Ådence interval [U ‚àó, V ‚àó] for Œ∏
1: for j=1, 2, . . . , N do
2:
generate K ( j)
1 , . . . , K ( j)
n
‚àºU{1, 2, . . . , n} i.i.d.
3:
let X‚àó( j)
i
‚ÜêxK ( j)
i
for i = 1, 2, . . . , n
4:
let ÀÜŒ∏‚àó( j)
n
‚ÜêÀÜŒ∏n(X‚àó( j)
1
, . . . , X‚àó( j)
n
)
5: end for
6: let t ‚ÜêÀÜŒ∏n

X1, . . . , Xn)
7: let l ‚Üê
 Œ±
2 N

8: let u ‚Üê

(1 ‚àíŒ±
2 )N

9: let Œ∏‚àó
(1), . . . , Œ∏‚àó
(N) be Œ∏‚àó
1 , . . . , Œ∏‚àó
N, sorted in increasing order
10: return (2t ‚àíŒ∏‚àó
(u), 2t ‚àíŒ∏‚àó
(l))
In the algorithm, the symbol ‚åà¬∑‚åâdenotes the operation of rounding up a number,
that is for x ‚ààR the value ‚åàx‚åâis the smallest integer greater than or equal to x.
The parameter N in algorithm 5.20 controls the accuracy of the bootstrap esti-
mate for the quantiles of the distribution of ÀÜŒ∏‚àó
n . For bigger values of N the result
gets more accurate but, at the same time, the computation gets slower. The situation
is slightly different from the case of Monte Carlo estimates. For the bootstrap esti-
mates considered here, the total error does not converge to 0 even as N increases
to inÔ¨Ånity, since an additional error is introduced by the Ô¨Ånite size n of the given
data set.
One easy method of Ô¨Ånding good values for N is to repeatedly compute a con-
Ô¨Ådence interval for the same data set and to consider the standard deviation of
the bounds between runs of the algorithm. This standard deviation is a measure
for the error contributed by the Ô¨Åniteness of N. The value of N should be chosen
large enough that this standard deviation is small, compared with the size of the
conÔ¨Ådence interval. Numerical experiments indicate the N should be chosen to be
relatively large, for example in the situation of exercise E5.6 with N = 4000 the sam-
pling error is still a noticeable percentage of the width of the estimated conÔ¨Ådence
interval.

206
AN INTRODUCTION TO STATISTICAL COMPUTING
Many variants of and improvements to the simple bootstrap conÔ¨Ådence interval
from algorithm 5.20 are possible. Here we restrict ourselves to describing one of the
many variants, known as the BCa method (BCa stands for ‚Äòbias corrected and acceler-
ated‚Äô), but without giving any derivation. Using a bootstrap sample ÀÜŒ∏‚àó(1)
n
, . . . , ÀÜŒ∏‚àó(N)
n
,
constructed as in (5.21), the BCa conÔ¨Ådence interval is deÔ¨Åned using the following
steps.
First, let 
: R ‚Üí(0, 1) be the distribution function of the standard normal distri-
bution and deÔ¨Åne a value ÀÜz by
ÀÜz = 
‚àí1

#

j
 ÀÜŒ∏‚àó( j)
n
‚â§ÀÜŒ∏n

N

.
Next, let x(i) = (x1, . . . , xi‚àí1, xi+1, . . . , xn), that is the data x with xi left out, and
deÔ¨Åne Œ∏(i) = ÀÜŒ∏n‚àí1(x(i)) for i = 1, 2, . . . , n, as well as
Œ∏(¬∑) = 1
n
n

i=1
Œ∏(i).
From this, a value ÀÜa is computed as
ÀÜa = 1
6 ¬∑
	n
i=1

Œ∏(¬∑) ‚àíÀÜŒ∏(i)
3

	n
i=1

Œ∏(¬∑) ‚àíÀÜŒ∏(i)
23/2 .
Finally, using ÀÜz and ÀÜa, we deÔ¨Åne a map q: (0, 1) ‚Üí(0, 1) by
q(Œ±) = 

ÀÜz +
ÀÜz + 
‚àí1(Œ±)
1 ‚àíÀÜa
ÀÜz + 
‚àí1(Œ±)


for all Œ± ‚àà(0, 1). Then the BCa bootstrap conÔ¨Ådence interval [U ‚àó, V ‚àó] is given by
the boundaries
U ‚àó= Œ∏‚àó
q(Œ±/2)
and
V ‚àó= Œ∏‚àó
q(1‚àíŒ±/2),
where Œ∏‚àó
Œ± denotes the Œ±-quantile of the distribution of the ÀÜŒ∏‚àó
n . As before, these quantiles
can be approximated by the corresponding quantiles of the empirical distribution of
ÀÜŒ∏‚àó(1)
n
, . . . , ÀÜŒ∏‚àó(N)
n
. This leads to the following algorithm.

BEYOND MONTE CARLO
207
Algorithm 5.21
(BCa bootstrap conÔ¨Ådence interval)
input:
data x1, x2, . . . , xn
an estimator ÀÜŒ∏n for a one-dimensional parameter Œ∏
N ‚ààN
Œ± ‚àà(0, 1)
randomness used:
K ( j)
i
‚àºU{1, 2, . . . , n} i.i.d. for i = 1, . . . , n and j = 1, . . . , N
output:
an approximate conÔ¨Ådence interval [U ‚àó, V ‚àó] for Œ∏
1: for j=1, 2, . . . , N do
2:
generate K ( j)
1 , . . . , K ( j)
n
‚àºU{1, 2, . . . , n} i.i.d.
3:
let X‚àó( j)
i
‚ÜêxK ( j)
i
for i = 1, 2, . . . , n
4:
let ÀÜŒ∏‚àó( j)
n
‚ÜêÀÜŒ∏n(X‚àó( j)
1
, . . . , X‚àó( j)
n
)
5: end for
6: let ÀÜz = 
‚àí1

#

j
 ÀÜŒ∏‚àó( j) ‚â§ÀÜŒ∏n

N

7: for i=1, 2, . . . , n do
8:
let Œ∏(i) ‚ÜêÀÜŒ∏n‚àí1(x1, . . . , xi‚àí1, xi+1, . . . , xn)
9: end for
10: let Œ∏(¬∑) ‚Üê1
n
	n
i=1 Œ∏(i)
11: let ÀÜa ‚Üê1
6 ¬∑
	n
i=1( Œ∏(¬∑) ‚àíÀÜŒ∏(i))3
	n
i=1( Œ∏(¬∑) ‚àíÀÜŒ∏(i))23/2
12: let ql ‚Üê

ÀÜz +
ÀÜz + 
‚àí1(Œ±/2)
1 ‚àíÀÜa(ÀÜz + 
‚àí1(Œ±/2))

13: let qu ‚Üê

ÀÜz +
ÀÜz + 
‚àí1(1 ‚àíŒ±/2)
1 ‚àíÀÜa(ÀÜz + 
‚àí1(1 ‚àíŒ±/2))

14: let l ‚Üê‚åàql N‚åâ
15: let u ‚Üê‚åàqu N‚åâ
16: let Œ∏‚àó
(1), . . . , Œ∏‚àó
(N) be Œ∏‚àó
1 , . . . , Œ∏‚àó
N, sorted in increasing order
17: return (Œ∏‚àó
(l), Œ∏‚àó
(u))
The derivation of the speciÔ¨Åc form of bounds in the BCa method is beyond the
scope of this text; the reader is referred to Efron and Tibshirani (1993, Chapter 22)
and DiCiccio and Efron (1996) for discussion of the details. Instead, we study the
quality of the conÔ¨Ådence intervals from algorithm 5.20 and algorithm 5.21 with the
help of a numerical experiment.
By deÔ¨Ånition, a conÔ¨Ådence interval [U, V ] with conÔ¨Ådence coefÔ¨Åcient 1 ‚àíŒ± for
a parameter Œ∏ satisÔ¨Åes
P

U(X1, . . . , Xn) ‚â§Œ∏ ‚â§V (X1, . . . , Xn)

‚â•1 ‚àíŒ±.

208
AN INTRODUCTION TO STATISTICAL COMPUTING
Typically, the interval is constructed symmetrically in the sense that it satisÔ¨Åes P(Œ∏ <
U) = Œ±/2 and P(Œ∏ > V ) = Œ±/2. The remaining probability 1 ‚àíŒ±/2 ‚àíŒ±/2 = 1 ‚àíŒ±
corresponds to the case U ‚â§Œ∏ ‚â§V . For a Ô¨Åxed distribution P with known parameter
Œ∏ = Œ∏(P), and for a given conÔ¨Ådence interval, we can estimate the probabilities
P(Œ∏ < U), P(U ‚â§Œ∏ ‚â§V ) and P(Œ∏ < U) using the following Monte Carlo approach:
(a) Generate X( j)
1 , . . . , X( j)
n
‚àºP, i.i.d., for j = 1, 2, . . . , N.
(b) Compute U ( j) = U ( j)(X( j)
1 , . . . , X( j)
n ) and V ( j) = V ( j)(X( j)
1 , . . . , X( j)
n ) for
j = 1, 2, . . . , N.
(c) Let
pinside = #

j
 U ( j) ‚â§Œ∏(P) ‚â§V ( j)
N
as well as
pleft = #

j
 Œ∏(P) < U ( j)
N
and
pright = #

j
 Œ∏(P) > V ( j)
N
.
This allows to quantify how well the conÔ¨Ådence intervals perform for different
models.
Example 5.22
We apply the above procedure to three different families of models:
r the mean Œº of standard normally distributed values;
r the mean Œº of Exp(1)-distributed values; and
r the variance œÉ 2 of standard normally distributed values.
Each of these three families is considered for three different sample sizes (n =
10, 50, 100), resulting in nine different models being considered in total. Approximate
conÔ¨Ådence intervals were computed using both algorithm 5.20 and algorithm 5.21.
The resulting Monte Carlo estimates for the probabilities pleft, pinside and pright, using
Œ± = 0.05, are shown in Table 5.1.
The results show, as expected, that the conÔ¨Ådence intervals improve as the sample
size increases. Both methods perform better for the symmetric problem of estimating
the mean of a normal distribution than they do for the more skewed cases of the last
two problems. For the last two problems, both methods result in conÔ¨Ådence intervals
which extend too far to the left and not far enough to the right, resulting in very small
probabilities for the event Œ∏ < U and too large probabilities for the event Œ∏ > V . For
the three test problems considered here, there is no clear difference in quality of the
conÔ¨Ådence intervals constructed by the two methods.

BEYOND MONTE CARLO
209
Table 5.1
The results of a numerical experiment to measure the empirical coverage
of the simple and BCa bootstrap conÔ¨Ådence intervals, for three different test
problems and different sample sizes n. The exact setup is described in example 5.22.
The experimentally determined coverage is shown in the last six columns of this
table. The theoretical values are 0.025 (left), 0.95 (inside) and 0.025 (right); results
close to the theoretical values are displayed in bold face.
Simple
BCa
P
Œ∏
n
Left
Inside
Right
Left
Inside
Right
10
0.042
0.91
0.049
0.062
0.89
0.048
N(0, 1)
Œº
50
0.032
0.94
0.031
0.029
0.94
0.035
100
0.027
0.95
0.022
0.024
0.95
0.027
10
0.011
0.85
0.14
0.021
0.86
0.12
Exp(1)
Œº
50
0.008
0.92
0.072
0.015
0.93
0.055
100
0.014
0.94
0.048
0.022
0.94
0.038
10
0.021
0.86
0.12
0.006
0.77
0.23
N(0, 1)
œÉ 2
50
0.014
0.92
0.063
0.007
0.91
0.083
100
0.018
0.94
0.038
0.011
0.92
0.069
5.3
Summary and further reading
In this chapter we have studied two different methods which can be applied when
not enough mathematical structure is available to employ Monte Carlo methods. The
Ô¨Årst part of this chapter introduced the ABC method which can be used in Bayesian
problems when the posterior density is not explicitly known (or is too complicated),
but when a method for generating samples is still available. The second part of
this chapter introduced bootstrap methods, which can be used when even generating
samples is problematic.
One of the earliest papers about the ABC method, covering applications in pop-
ulation genetics, was by Tavar¬¥e et al. (1997). Newer developments and extensions of
the method can be found, for example in Beaumont et al. (2002), Blum and Franc¬∏ois
(2010) and Fearnhead and Prangle (2012).
The bootstrap method is described in various textbooks, for example in Efron and
Tibshirani (1993). A wealth of practical information about bootstrap methods can be
found in the monograph by Davison and Hinkley (1997).
Exercises
E5.1
Implement the ABC method described in example 5.4. Test your implemen-
tation by generating samples for n = 20 and s‚àó= (6.989, 52.247).

210
AN INTRODUCTION TO STATISTICAL COMPUTING
E5.2
Implement ABC with regression from algorithm 5.6 for the problem described
in example 5.4. Test your implementation by generating samples for n = 20
and s‚àó= (6.989, 52.247).
E5.3
Consider the estimator
ÀÜœÉ 2(x1, . . . , xn) = 1
n
n

i=1

xi ‚àí¬Øx
2
for the variance, where ¬Øx is the average of the xi. Write a program that
computes, for given data x = (x1, . . . , xn), the bootstrap estimate of the bias
as given in algorithm 5.15. Test your program on a data set consisting of 100
standard normally distributed values. Justify your choice of the Monte Carlo
sample size N.
E5.4
Assume that we observe 2500 tosses of a biased coin and that we get the
following sequence of heads and tails:
H H T H H H H T H T T T H T T H T H T T T H H H H T T H T . . . T H T H,
containing 1600 heads and 900 tails in total. From these observations, we
estimate the probability p of head as ÀÜp = 1600/2500 = 16/25. Compute the
bootstrap estimate of the standard error of ÀÜp.
E5.5
Implement algorithm 5.20 for computing bootstrap conÔ¨Ådence intervals. Test
your program by computing bootstrap conÔ¨Ådence intervals for the mean of
a normal distribution and by comparing the output of your program with the
theoretically exact conÔ¨Ådence interval for this case.
E5.6
(a)
For n = 25, create a sample of n independent standard normally dis-
tributed random variables X1, . . . , Xn.
(b)
For Ô¨Åxed N, repeatedly apply algorithm 5.20 to this data set to get dif-
ferent estimates for a conÔ¨Ådence interval for the variance. Numerically
determine the standard deviation of both bounds as well as the average
width of the interval.
(c)
Repeat the previous step for N = 1000, N = 2000 and N = 4000 and
comment on your results.
E5.7
Implement the BCa method from algorithm 5.21.
E5.8
Write a program which numerically determines the coverage probabilities
for the simple bootstrap conÔ¨Ådence interval (algorithm 5.20) and for the BCa
bootstrap conÔ¨Ådence interval (algorithm 5.21), as described in example 5.22.
Use this program to estimate the probability P(Œ∏ ‚àà[U, V ]) for the following
three problems:
(a)
Estimating conÔ¨Ådence intervals for the mean Œº of standard normally
distributed values.
(b)
Estimating conÔ¨Ådence intervals for the mean Œº of Exp(1)-distributed
values.

BEYOND MONTE CARLO
211
(c)
Estimating conÔ¨Ådence intervals for the variance œÉ 2 of standard normally
distributed values.
Compare the quality of the two different kinds of conÔ¨Ådence intervals.
Determine how the quality of the conÔ¨Ådence intervals depends on the sample
size n.

6
Continuous-time models
In this chapter we will pick up the thread we left in Chapter 2 and will return to the topic
of simulating statistical models. The models we are interested in here are described by
continuous-time processes, that is by stochastic processes where time is represented
by a bounded or unbounded interval of real numbers. There are two main motivations
for using continuous-time processes. First, physical time is continuous: physical quan-
tities like the temperature at a point or the location of a particle in space are in principle
deÔ¨Åned for all times. Thus, continuous-time models are appropriate for describing
physical processes. Secondly, in mathematical models continuous-time processes can
arise as the limit of discrete-time processes when the distance between the time steps
converges to zero. In such cases, analysis of the limiting continuous-time process is
typically much easier than analysis of the underlying discrete-time process.
In this chapter we will introduce the most important classes of continuous-time
stochastic processes and we will study how these processes can be simulated on a
computer. In the second part of this chapter we will revisit the Monte Carlo techniques
introduced in Chapter 3 and we will study how statistical continuous-time models
can be studied by simulation.
6.1
Time discretisation
Compared with the situation of discrete-time processes, for example the Markov
chains considered in Section 2.3, simulation in continuous-time introduces new chal-
lenges. Consider a stochastic process (Xt)t‚ààI where I ‚äÜR is a time interval, for
example I = [0, ‚àû) or I = [0, T ] for some time horizon T > 0. Even if the time
interval I is bounded, the trajectory (Xt)t‚ààI consists of uncountably many values.
Since computers only have Ô¨Ånite storage capacity, it is impossible to store the whole
trajectory of a continuous-time process on a computer. Even computing values for
all Xt would take an inÔ¨Ånite amount of time. For these reasons, we restrict ourselves
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

214
AN INTRODUCTION TO STATISTICAL COMPUTING
to simulate X only for times t ‚ààIn where In = {t1, t2, . . . , tn} ‚äÇI is Ô¨Ånite. This
procedure is called time discretisation.
In many cases we can simulate the process X by iterating through the times
t1, t2, . . . , tn ‚ààIn: we Ô¨Årst simulate Xt1, next we use the value of Xt1 to simulate
Xt2, then we use the values Xt1 and Xt2 to simulate Xt3 and so on. The Ô¨Ånal step in
this procedure is to use the values Xt1, . . . , Xtn‚àí1 to simulate Xtn. One problem with
this approach is that often the distribution of Xtk does not only depend on Xti for
i = 1, 2, . . . , k ‚àí1, but also on (unknown to us) values Xt where t /‚ààIn. For this
reason, most continuous-time processes cannot be simulated exactly on a computer
and we have to resort to approximate solutions instead. The error introduced by these
approximations is called discretisation error.
6.2
Brownian motion
Brownian motion forms a basic building block for many kinds of continuous-time
stochastic processes.
DeÔ¨Ånition 6.1
An Rd-valued stochastic process (Bt)t‚â•0 is a Brownian motion (also
called a Wiener process), if it satisÔ¨Åes the following three conditions:
(a) B0 = 0;
(b) for every t ‚â•0 and h > 0, the increment Bt+h ‚àíBt is N(0, hId)-distributed
and independent of (Bs)0‚â§s‚â§t; and
(c) the map t ‚ÜíBt is continuous.
In the deÔ¨Ånition, N(0, hId) denotes the d-dimensional normal distribution with
covariance matrix hId (see Section 2.1) and Id is the d-dimensional identity matrix.
For a one-dimensional Brownian motion, the distribution of the increments of B
simpliÔ¨Åes to Bt+h ‚àíBt ‚àºN(0, h).
In this book we denote Brownian motion by B. Some authors prefer the name
‚ÄòWiener process‚Äô over ‚ÄòBrownian motion‚Äô, and then use W to denote this process.
Both conventions are widely used in the literature.
From the deÔ¨Ånition of a Brownian motion B we see that t ‚ÜíBt is a random
continuous function of time with values in Rd. One path of a one-dimensional
Brownian motion is shown in Figure 6.1.
In many cases, models based on Brownian motion are a good Ô¨Åt for processes
which are, on a microscopic scale, driven by small, random, independent, additive
contributions. For such models, there are two possible categories:
r If the variance of the individual contributions is small (compared with the
inverse of their number), then the macroscopic behaviour of the system will be
deterministic.
r If the variance of the individual contributions is larger (comparable with the
inverse of the number of contributions), the resulting system will show random

CONTINUOUS-TIME MODELS
215
0
20
40
60
80
100
‚àí4
‚àí2
0
2
4
6
t
Bt
Figure 6.1
One instance of a one-dimensional Brownian motion, simulated until
time T = 100.
behaviour on a macroscopic scale. In these cases often the central limit theorem
(theorem A.9) applies and macroscopic increments are approximately normally
distributed.
Models based on Brownian motion are used for situations falling into the second
category.
Example 6.2
A tiny particle, like a grain of dust, suspended in a liquid is sub-
ject to ‚Äòimpulses‚Äô by the individual water molecules hitting the particle. These
impacts happen with very high frequency and due to the complicated dynamics
of the water molecules can be considered to be random. This effect causes a visible
motion of the suspended particle which can be described by a three-dimensional
Brownian motion.
Example 6.3
The price of a share of stock of a company is determined by individual
trades of this stock. For stocks with a high enough volume of trading, the stock price
can be described as a (transformed) Brownian motion.
For both of these examples it is important to keep in mind that models based on
Brownian motion only form approximations. Use of these approximations is justiÔ¨Åed
by the fact that the resulting models describe the systems well on a wide range of
timescales. Nevertheless, since normally distributed increments are only observed
when sufÔ¨Åciently many of the microscopic contributions are combined, the models
will break down on very short timescales. Similarly, on very long timescales new
effects can occur; for example the physical particle considered in example 6.2 will
eventually hit the boundary of the enclosing container, whereas the Brownian motion
used as a model here does not include information about the container boundaries.

216
AN INTRODUCTION TO STATISTICAL COMPUTING
6.2.1
Properties
In this section we brieÔ¨Çy state some of the most important properties of Brownian
motion. Using deÔ¨Ånition 6.1, we can immediately derive the following results:
r We have Bt = Bt ‚àíB0 ‚àºN(0, t Id) and in particular the expectation of Bt is
E

Bt

= 0.
r For the one-dimensional case we Ô¨Ånd Bt ‚àºN(0, t) and thus the standard
deviation of Bt is ‚àöt.
r Similarly, for any dimension, we Ô¨Ånd that Bt has the same distribution as ‚àöt B1.
Thus, the magnitude of |Bt| only grows like ‚àöt as t increases.
Another basic result, relating the one-dimensional case to the d-dimensional case,
is given in the following lemma.
Lemma 6.4
The d-dimensional process B = (B(1)
t , . . . , B(d)
t )t‚â•0 is a Brownian
motion if and only if the components B(i) for i = 1, 2, . . . , d are independent, one-
dimensional Brownian motions.
Proof
This follows directly from the deÔ¨Ånition of a Brownian motion. We check
the three conditions from deÔ¨Ånition 6.1 one by one. First, the vector B0 is zero if
and only if all d of its components are zero. Secondly, Bt+h ‚àíBt ‚àºN(0, hId) if and
only if B(i)
t+h ‚àíB(i)
t
‚àºN(0, h) for all i = 1, 2, . . . , d. And, Ô¨Ånally, the map t ‚ÜíBt
is continuous if and only if all of its components are continuous.
To conclude this section, in the following lemma we collect three invariance
properties of Brownian motion.
Lemma 6.5
Let B be a Brownian motion. Then the following statements hold.
(a) The process (‚àíBt)t‚â•0 is a Brownian motion.
(b) For every s ‚â•0, the process (Bs+t ‚àíBs)t‚â•0 is a Brownian motion, indepen-
dent of (Br)0‚â§r‚â§s. (This is called the Markov property of Brownian motion.)
(c) For every c > 0, the process (‚àöcBt/c)t‚â•0 is a Brownian motion. (This is called
the scaling property of Brownian motion.)
Proof
All three statements follow directly from the deÔ¨Ånition of a Brownian motion.
For the Ô¨Årst statement, let Xt = ‚àíBt for all t ‚â•0. Then we have X0 = ‚àíB0 =
‚àí0 = 0, the increments Xt+h ‚àíXt = ‚àí(Bt+h ‚àíBt) are N(0, hId) distributed since
Bt+h ‚àíBt ‚àºN(0, hId), and t ‚ÜíXt = ‚àíBt is continuous since t ‚ÜíBt is contin-
uous. Thus X = ‚àíB satisÔ¨Åes the conditions of deÔ¨Ånition 6.1 and consequently is a
Brownian motion.

CONTINUOUS-TIME MODELS
217
For the second statement, let s ‚â•0 and deÔ¨Åne Yt = Bs+t ‚àíBs for all t ‚â•0. Then
Y0 = Bs+0 ‚àíBs = 0 and
Yt+h ‚àíYt = (Bs+t+h ‚àíBs) ‚àí(Bs+t ‚àíBs)
= Bs+t+h ‚àíBs+t
‚àºN(0, hId),
since B is a Brownian motion. Furthermore, t ‚ÜíYt = Bs+t ‚àíBs is continuous and
thus Y is a Brownian motion. Again, since B is a Brownian motion, the random
variables Yt = Bs+t ‚àíBs are independent of (Br)0‚â§r‚â§s.
Finally, for the third statement, let Zt = ‚àöcBt/c for all t ‚â•0. Clearly Z0 =
‚àöcB0/c = 0. For the increments we have
Zt+h ‚àíZt = ‚àöcB(t+h)/c ‚àí‚àöcBt/c = ‚àöc

Bt/c+h/c ‚àíBt/c

and, since Bt/c+h/c ‚àíBt/c ‚àºN(0, h/cId), we Ô¨Ånd Zt+h ‚àíZt ‚àºN(0, hId). Again,
the continuity of B implies continuity of Z and thus the process Z is a Brownian
motion. This completes the proof of the lemma.
6.2.2
Direct simulation
As we have seen at the start of this chapter, we cannot hope to simulate all of the
inÔ¨Ånitely many values (Bt)t‚â•0 on a computer simultaneously. Instead, we restrict our-
selves to simulating the values of B for times 0 = t0 < t1 < ¬∑ ¬∑ ¬∑ < tn. For a Brownian
motion, this can be easily done by using the Ô¨Årst two conditions from deÔ¨Ånition 6.1:
we have B0 = 0 and Bti can be computed from Bti‚àí1 by adding an N(0, ti ‚àíti‚àí1)-
distributed random value, independent of all values computed so far. This method is
described in the following algorithm.
Algorithm 6.6
(Brownian motion)
input:
sample times 0 = t0 < t1 < ¬∑ ¬∑ ¬∑ < tn
randomness used:
an i.i.d. sequence (Œµi)i=1,2,...,n with distribution N(0, 1)
output:
a sample of Bt0, . . . , Btn, that is a discretised path of a Brownian motion
1: B0 ‚Üê0
2: for i = 1, 2, . . . , n do
3:
generate Œµi ‚àºN(0, 1)
4:
Bi ‚Üê‚àöti ‚àíti‚àí1 Œµi
5:
Bti ‚ÜêBti‚àí1 + Bi
6: end for
7: return (Bti)i=0,1,...,n

218
AN INTRODUCTION TO STATISTICAL COMPUTING
‚àí1
0
1
2
3
4
5
‚àí3
‚àí2
‚àí1
0
1
2
3
Bt
(2)
Bt
(1)
Figure 6.2
Path of a two-dimensional Brownian motion, simulated until time T =
10. The shades indicate time, ranging from t = 0 (light grey) to t = T (black).
While algorithm 6.6 only covers the one-dimensional case, it can also be used
to simulate a d-dimensional Brownian motion B = (B(1), . . . , B(d)) for d > 1: by
lemma 6.4 it sufÔ¨Åces to simulate the individual components B(i) for i = 1, 2, . . . , d,
independently.
Since the paths of B are continuous, for large n we can assume that the values
of B in between grid points are close to the values at the neighbouring grid points.
By using small grid spacing and connecting the values Bti using straight lines, we
can obtain a good approximation to a path of a Brownian motion. Results of such
simulations are shown in Figure 6.1 and Figure 6.2.
6.2.3
Interpolation and Brownian bridges
If we have already simulated values of a Brownian motion B for a set of times,
it is possible to reÔ¨Åne the simulated path afterwards by simulating values of B for
additional times. This method is called interpolation of the Brownian path. Since
these additional simulations need to be compatible with the already sampled values,
some care is needed when implementing this method.
Assume that we know the values of B at times 0 = t0 < t1 < ¬∑ ¬∑ ¬∑ < tn and that
we want to simulate an additional value for B at time s with ti‚àí1 < s < ti for
some i ‚àà{2, 3, . . . , n}. As an abbreviation we write r = ti‚àí1 and t = ti. By the

CONTINUOUS-TIME MODELS
219
Markov property of Brownian motion (lemma 6.5, part (b)), the increment Bs ‚àíBr
is independent of (Bu)0‚â§u‚â§r. Similarly, (Bu ‚àíBt)u‚â•t is independent of (Bu)0‚â§u‚â§t and
thus of Bs ‚àíBr. Consequently, we only need to take the value Bt = Bti into account
when sampling the increment Bs ‚àíBr; by independence the remaining Bt j with j Ã∏= i
do not affect the distribution of Bs ‚àíBr.
Assume that B is one-dimensional with Br = a. Since (Bu+r ‚àíBr)u‚â•0 is a
Brownian motion independent of Br, we have Bs ‚àºN(a, s ‚àír) and Bt ‚àíBs ‚àº
N(0, t ‚àís), independently of each other. Thus, the joint density of (Bs, Bt) is
fBs,Bt(x, y) =
1
‚àö2œÄ(s ‚àír) exp

‚àí(x ‚àía)2
2(s ‚àír)

1
‚àö2œÄ(t ‚àís) exp

‚àí(y ‚àíx)2
2(t ‚àís)

for all x, y ‚ààR. We need to condition this distribution on the, already sampled, value
of Bt. By deÔ¨Ånition of the conditional density fBs|Bt from (A.5) we have
fBs|Bt(x|b) = c1 fBs,Bt(x, b)
= c1
1
‚àö2œÄ(s ‚àír) exp

‚àí(x ‚àía)2
2(s ‚àír)

1
‚àö2œÄ(t ‚àís) exp

‚àí(b ‚àíx)2
2(t ‚àís)

= c2 exp

‚àí(x ‚àía)2
2(s ‚àír) ‚àí(b ‚àíx)2
2(t ‚àís)

,
where c1 and c2 are constants. By expanding the expressions inside the exponential
and then completing the square we Ô¨Ånd
fBs|Bt(x|b) = c3 exp

‚àí(x ‚àíŒº)2
2œÉ 2

,
where c3 is a constant,
Œº = t ‚àís
t ‚àír a + s ‚àír
t ‚àír b
and
œÉ 2 = (t ‚àís)(s ‚àír)
t ‚àír
.
Since fBs|Bt is a probability density, we know c3 = 1/
‚àö
2œÄœÉ 2 and thus fBs|Bt is the
density of a N(Œº, œÉ 2)-distribution.
The argument presented above shows that, given Br = a and Bt = b, the value
Bs for r < s < t satisÔ¨Åes
Bs ‚àºN
t ‚àís
t ‚àír a + s ‚àír
t ‚àír b, (t ‚àís)(s ‚àír)
t ‚àír

.
(6.1)
The expectation of Bs for r < s < t is found by linear interpolation between Br and
Bt (corresponding to the dashed line in Figure 6.3). The variance of Bs is biggest at

220
AN INTRODUCTION TO STATISTICAL COMPUTING
s
Bs
r
t
a
b
Figure 6.3
Path of a Brownian bridge (Bs)s‚àà[r,t], interpolated between the points
(r, a) and (t, b). The dashed line gives the mean of the Brownian bridge, the shaded
region has a width of one standard deviation around the mean.
the centre of the interval [r, t] and converges to 0 when s approaches either of the
boundary points; the corresponding standard deviation is represented by the shaded
region in Figure 6.3.
Using equation (6.1), the procedure for interpolating a Brownian path is as fol-
lows: let 0 = t0 < t1 < ¬∑ ¬∑ ¬∑ < tn be the times where the values Bti are already known
and let t > 0.
(a) If t = ti for an index i ‚àà{0, 1, . . . , n}, we return the already sampled value
Bt = Bti.
(b) If t > tn, return Bt ‚àºN(Btn, t ‚àítn).
(c) If ti‚àí1 < t < ti, return
Bt ‚àºN
 ti ‚àít
ti ‚àíti‚àí1
Bti‚àí1 + t ‚àíti‚àí1
ti ‚àíti‚àí1
Bti, (ti ‚àít)(t ‚àíti‚àí1)
ti ‚àíti‚àí1

.
For the last two cases, if the procedure is repeated, we need to add the newly sampled
value to the list of already known values for B. The result of a simulation using this
method is shown in Figure 6.4.
The method we used to interpolate a Brownian path between already sampled
points describes a continuous-time stochastic process on the time interval [r, t].
DeÔ¨Ånition 6.7
A Brownian bridge between (r, a) and (t, b), where r < t are times
and a, b ‚ààRd, is the continuous-time stochastic process on the time interval [r, t],
obtained by conditioning a Brownian motion B on the events Br = a and Bt = b.

CONTINUOUS-TIME MODELS
221
0
5
10
15
20
‚àí2
‚àí1
0
1
2
3
t
Bt
Figure 6.4
One instance of a one-dimensional Brownian motion, simulated using
the interpolation method described in Section 6.2.3. The grey ‚Äòskeleton‚Äô of the path is
simulated Ô¨Årst. The reÔ¨Åned path, shown in black, is sampled later using interpolation.
A Brownian bridge can be simulated by interpolating a Brownian path between
Br = a and Bt = b, as described above. The distribution of a Brownian bridge at a
Ô¨Åxed time s ‚àà[r, t] is described by equation (6.1).
A second method for sampling a path of a Brownian bridge is given by the
following procedure: we can Ô¨Årst sample a path B of an ordinary Brownian motion,
and then deÔ¨Åne a process X by
Xs = Bs‚àír + a ‚àís ‚àír
t ‚àír (Bt‚àír ‚àíb + a).
(6.2)
One can prove that the resulting process (Xs)s‚àà[r,t] is again a Brownian bridge. This
method is often more efÔ¨Åcient than the interpolation method, when many samples
from the path of a Brownian bridge are required.
6.3
Geometric Brownian motion
Geometric Brownian motion is a continuous-time stochastic process which is derived
from Brownian motion and can, for example, be used as a simple model for stock
prices.
DeÔ¨Ånition 6.8
A continuous-time stochastic process X = (Xt)t‚â•0 is a geometric
Brownian motion, if
Xt = X0 exp

Œ±Bt + Œ≤t

(6.3)
for all t ‚â•0, where Œ± > 0 and Œ≤ ‚ààR are constants and B is a one-dimensional
Brownian motion, independent of X0.

222
AN INTRODUCTION TO STATISTICAL COMPUTING
0
2
4
6
8
10
0 2 4 6 8 10
t
Xt
Figure 6.5
One path of a geometrical Brownian motion with X0 = 1, Œ± = 1 and
Œ≤ = ‚àí0.1, simulated until time T = 10.
Since we know how to generate samples of a Brownian motion from section 6.2.2,
generating samples of a geometric Brownian motion is easy: we can simply simulate
Bt, for example using algorithm 6.6, and then separately compute X0 exp(Œ±Bt + Œ≤t)
for every t-value used in the simulation (the result of one such simulation is shown
in Figure 6.5). Nevertheless, we will see below that some care is needed when using
the simulated values for Monte Carlo estimates.
Lemma 6.9
Let X be a geometric Brownian motion with parameters Œ± and Œ≤. Then
E(Xt) = E(X0) exp

(Œ±2/2 + Œ≤)t

for all t ‚â•0.
Proof
Since we know Bt ‚àºN(0, t), we can compute the expectation of Xt using
integration:
E(Xt) = E(X0) E

exp

Œ±Bt + Œ≤t

= E(X0)

R
exp

Œ±y + Œ≤t

1
‚àö
2œÄt
exp

‚àíy2
2t

dy
= E(X0) eŒ≤t
‚àö
2œÄt

R
exp

‚àíy2
2t + Œ±y

dy.
By completing the square we Ô¨Ånd
E(Xt) = E(X0)exp

(Œ±2/2 + Œ≤)t

‚àö
2œÄt

R
exp

‚àí1
2t

y2 ‚àí2yŒ±t + Œ±2t2
dy
= E(X0) exp

(Œ±2/2 + Œ≤)t

1
‚àö
2œÄt

R
exp

‚àí(y ‚àíŒ±t)2
2t

dy
= E(X0) exp

(Œ±2/2 + Œ≤)t

.
(6.4)
This completes the proof.
As a consequence of lemma 6.9 we see that the conditions for Xt to have constant
expectation on the one hand and for the exponent Œ±Bt + Œ≤t in (6.3) to have constant

CONTINUOUS-TIME MODELS
223
expectation on the other hand are different. For Œ≤ = ‚àíŒ±2/2 we Ô¨Ånd that the process
Xt satisÔ¨Åes
E(Xt) = E(X0) exp
Œ±2
2 ‚àíŒ±2
2

t

= E(X0),
that is for Œ≤ = ‚àíŒ±2/2 the geometric Brownian motion has constant expectation. On
the other hand, the exponent Œ±Bt + Œ≤t satisÔ¨Åes for this case
E(Œ±Bt + Œ≤t) = E

Œ±Bt ‚àíŒ±2
2 t

= ‚àíŒ±2
2 t
and thus E(Œ±Bt + Œ≤t) is not constant but converges to ‚àí‚àûas t ‚Üí‚àû.
The difference in behaviour of E(Xt) and E(Œ±Bt + Œ≤t) is caused by the fact
that positive Ô¨Çuctuations of Œ±Bt + Œ≤t are greatly ampliÔ¨Åed by the exponential in the
deÔ¨Ånition (6.3) whereas negative Ô¨Çuctuations are damped down. A more quantitative
result can be obtained by studying the integral in equation (6.4): the integration
variable y runs over all possible values of Bt and the integrand exp

‚àí(y ‚àíŒ±t)2/2t

in the last integral combined the map which transforms B into X with the density
for Bt. It is easy to check that the main contribution of this integral comes from
the region y ‚âàŒ±t ¬± ‚àöt. Thus, the main contribution to E(Xt) comes from values
of Bt ‚âàŒ±t ¬± ‚àöt. This corresponds to very unlikely events which, when they occur,
make huge a contribution to the expectation: The probability of Bt ‚âàŒ±t ¬± ‚àöt can
be estimated as
P

Œ±t ‚àí‚àöt ‚â§Bt ‚â§Œ±t + ‚àöt

= P

Œ±‚àöt ‚àí1 ‚â§Bt
‚àöt ‚â§Œ±
‚àö
t + 1

=
1
‚àö
2œÄ
 1
‚àí1
exp

‚àí1
2(x + Œ±
‚àö
t)2

dx
‚âà
2
‚àö
2œÄ
exp

‚àíŒ±2t
2

.
(6.5)
As a consequence, Monte Carlo methods cannot be used to estimate E(Xt) for large
values of t. In order to get a reasonable estimate for E(Xt), at least a few Monte
Carlo samples need to fall into the region Bt ‚âàŒ±t ¬± ‚àöt. From equation (6.5) we
see that this requires sample size N ‚â´exp(Œ±2t/2) and for large values of Œ±2t such
sample sizes will no longer be practical. This effect is illustrated in Figure 6.6. A
solution to this problem would be to use importance sampling and to replace the i.i.d.
copies Bt ‚àºN(0, t) used in the basic Monte Carlo method with N(Œ±t, t)-distributed
proposals.

224
AN INTRODUCTION TO STATISTICAL COMPUTING
‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
‚óè
‚óè
‚óè‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè
‚óè‚óè‚óè‚óè
‚óè‚óè
‚óè‚óè
‚óè
‚óè
‚óè
‚óè‚óè‚óè‚óè
‚óè
‚óè‚óè‚óè
‚óè
‚óè‚óè‚óè‚óè‚óè
‚óè
‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
0
20
40
60
80
100
0.0
0.5
1.0
1.5
2.0
2.5
3.0
t
E(X t)
Figure 6.6
Monte Carlo estimates for the expectation of the geometric Brownian
motion Xt = exp(Bt ‚àít/2), where B is a Brownian motion, using N = 106 Monte
Carlo samples for each value of t. The estimates for different t are displayed as
circles whereas the exact value of the expectation, E(Xt) = 1 by lemma 6.9, is given
by the horizontal line. The Ô¨Ågure shows that good estimates are only obtained for
t < 15.
6.4
Stochastic differential equations
A wide class of continuous-time stochastic processes X = (Xt)t‚â•0 can be described
as solutions to stochastic differential equations (SDEs) of the form
dXt = Œº(t, Xt) dt + œÉ(t, Xt) dBt
for all t > 0,
X0 = x0,
(6.6)
where B = (Bt)t‚â•0 is a Brownian motion with values in Rm and Œº: [0, ‚àû) √ó Rd ‚Üí
Rd as well as œÉ: [0, ‚àû) √ó Rd ‚ÜíRd√óm are functions, and the initial condition x0 ‚àà
Rd can be random or deterministic.
6.4.1
Introduction
In this section we will give a very short introduction to SDEs, mainly by giving an
intuitive idea about the properties of processes described by equations such as (6.6).
We start by giving an informal explanation of different aspects of equation (6.6).
r The stochastic process X = (Xt)t‚â•0 is the ‚Äòunknown‚Äô in equation (6.6). Solving
the SDE means to Ô¨Ånd a stochastic process X such that (6.6) is satisÔ¨Åed. (We
will discuss below what this means.) Since the Brownian motion B on the
right-hand side of (6.6) is random, the solution X is random, too.
r x0 ‚ààRd is called the initial value of the SDE.

CONTINUOUS-TIME MODELS
225
‚àí1.5
‚àí1.0
‚àí0.5
0.0
0.5
1.0
1.5
‚àí1.0
0.0
0.5
‚àí0.5
1.0
Xt
(2)
Xt
(1)
‚óèx0
Figure 6.7
One path of a two-dimensional SDE. The drift Œº is indicated by the grey
arrows; the diffusion coefÔ¨Åcient is large inside the grey rectangle and small outside
it.
r The function Œº: [0, ‚àû) √ó Rd ‚ÜíRd is called the drift of the SDE. Given the
current time t and the current value Xt, it determines the direction of mean
change of the process just after time t:
E

Xt+h
 Xt

‚âàXt + Œº(t, Xt)h
as h ‚Üì0. The effect of the drift is illustrated in Figure 6.7.
r The matrix-valued function œÉ: [0, ‚àû) √ó Rd ‚ÜíRd√óm is called the diffusion
coefÔ¨Åcient of the SDE. It determines the amount of random Ô¨Çuctuations X is
subject to at any given time and place. Conditioned on the value of Xt, the
covariance matrix of Xt+h satisÔ¨Åes
Cov

Xt+h
 Xt

‚âàœÉ(t, Xt)œÉ(t, Xt)‚ä§h
as h ‚Üì0.
r The stochastic differentials dXt, dt and dBt describe the increments of the
processes X, t and B. Formally, we have dXt = Xt ‚àíX0, dt = t ‚àí0 = t and
dBt = Bt ‚àíB0 = Bt.
r The ‚Äòproducts‚Äô Œº(t, Xt) dt and œÉ(t, Xt) dBt are shorthand notations for inte-
grals. The Ô¨Årst of these terms, Œº(t, Xt) dt, stands for the vector with compo-
nents

Œº(t, Xt) dt)i =
 t
0
Œºi(s, Xs) ds

226
AN INTRODUCTION TO STATISTICAL COMPUTING
for i = 1, 2, . . . , d where Œºi is the ith component of the vector Œº. Similarly,
œÉ(t, Xt) dBt stands for the random vector where the components are given by
the sum of the stochastic integrals

œÉ(t, Xt) dBt

i =
m

j=1
 t
0
œÉi j(s, Xs) dB( j)
s
(6.7)
for i = 1, 2, . . . , d. Here, œÉi j stands for the element in row i, column j of
the matrix œÉ, the values B(1), . . . , B(m) are the components of the Brownian
motion B, and the sum over j is part of a matrix-vector product between
the matrix-valued function œÉ and the vector-valued process B. We will defer
explanation of the stochastic integrals in (6.7) until Section 6.4.2.
Using the notation introduced, a continuous-time stochastic process X is deÔ¨Åned to
be a solution of the SDE (6.6), if X = (X(1), . . . , X(d)) satisÔ¨Åes
X(i)
t
= x(i)
0 +
 t
0
Œºi(s, Xs) ds +
m

j=1
 t
0
œÉi j(s, Xs) dB( j)
s
(6.8)
for all t ‚â•0 and all i = 1, 2, . . . , d.
In order for the SDE (6.6) to have a solution, that is for a process X which satisÔ¨Åes
(6.8) to exist, assumptions on the drift Œº and the diffusion coefÔ¨Åcient œÉ are required.
We will not consider these conditions here and instead refer to the literature given
at the end of this chapter, for example the books by Mao (2007, Section 5.2) and
Kloeden and Platen (1999, Section 4.5).
6.4.2
Stochastic analysis
Some technical detail is required to give a mathematically rigorous deÔ¨Ånition of the
stochastic integrals in equation (6.7). We omit the rigorous deÔ¨Ånition here and refer to
the references given at the end of this chapter for details. Instead, we restrict ourselves
to heuristic explanations of the most important aspects.
6.4.2.1
Ito integrals
The stochastic integral, also called the Ito integral, of the integrand Y with a integrator
X is given by the limit
 T
0
Yt dXt = lim
n‚Üí‚àû
n‚àí1

i=0
Yt(n)
i

Xt(n)
i+1 ‚àíXt(n)
i

(6.9)
where t(n)
i
= iT/n for i = 0, 1, . . . , n. Here, X and Y are stochastic processes. In
(6.7) this relation is used with the integrand œÉi j(s, Xs) instead of Y and with the
integrator B instead of X. Since X and Y are random, the value of the stochastic

CONTINUOUS-TIME MODELS
227
integral (6.9) is a random variable. Equation (6.9) is in analogy to the approximation
of the ordinary Riemann integral by Riemann sums:
 T
0
f (t) dt = lim
n‚Üí‚àû
n‚àí1

i=0
f (ti)

ti+1 ‚àíti

.
(6.10)
While the characterisation of a stochastic integral given in Equation (6.9) is not
enough to be able to give mathematically rigorous proofs of statements involving
stochastic integrals, it sufÔ¨Åces to motivate the numerical methods introduced in this
chapter. Also, equation (6.9) can be used as the basis of numerical methods to compute
stochastic integrals.
An important special case of equation (6.9) is when Y is constant, that is Yt = c
for all t ‚àà[0, T ]. In this case, we have
 T
0
c dXt = c lim
n‚Üí‚àû
n‚àí1

i=0

Xt(n)
i+1 ‚àíXt(n)
i

= c

Xtn ‚àíXt0

= c

XT ‚àíX0

.
6.4.2.2
Ito‚Äôs formula
An important tool from stochastic analysis is Ito‚Äôs formula: This formula allows
to evaluate the stochastic differentials of functions of a stochastic process. If X is
a stochastic process with values in Rd and f : [0, ‚àû) √ó Rd ‚ÜíR is differentiable
with respect to the Ô¨Årst argument and differentiable twice with respect to the second
argument, then the stochastic differentials of the process f (t, Xt) satisfy
d

f (t, Xt)

= ‚àÇ
‚àÇt f (t, Xt) dt +
d

i=1
‚àÇ
‚àÇxi
f (t, Xt) dX(i)
t
+1
2
d

i, j=1
‚àÇ2
‚àÇxi‚àÇx j
f (t, Xt) dX(i)
t dX( j)
t ,
(6.11)
where the product dX(i)
t dX( j)
t
is determined by the rules
dB(i)
t dB( j)
t
=
	dt
if i = j and
0
otherwise,
dB(i)
t dt = 0.
In particular, if X solves the SDE (6.6), we have
dX(i)
t
= Œºi(t, Xt) dt +
d

k=1
œÉik(t, Xt) dB(k)
t

228
AN INTRODUCTION TO STATISTICAL COMPUTING
and thus
dX(i)
t dX( j)
t
= Œºi(t, Xt)Œº j(t, Xt) dt dt + Œºi(t, Xt)
d

l=1
œÉ jl(t, Xt) dB(l)
t dt
+
d

k=1
œÉik(t, Xt)Œº j(t, Xt) dB(k)
t
dt
+
d

k,l=1
œÉik(t, Xt)œÉ jl(t, Xt) dB(k)
t
dB(l)
t
=
d

k=1
œÉik(t, Xt)œÉ jk(t, Xt) dt
= (œÉœÉ ‚ä§)i j(t, Xt) dt.
These expressions can be substituted into (6.11).
One important special case is the case of a one-dimensional stochastic process X.
In this case, equation (6.11) simpliÔ¨Åes to
d

f (t, Xt)

= ‚àÇ
‚àÇt f (t, Xt) dt + ‚àÇ
‚àÇx f (t, Xt) dXt
+ 1
2
‚àÇ2
‚àÇx2 f (t, Xt) dXt dXt.
(6.12)
Furthermore, if f does not depend on t, we get
d

f (Xt)

= f ‚Ä≤(Xt) dXt + 1
2 f ‚Ä≤‚Ä≤(Xt) dXt dXt.
(6.13)
Finally, if X solves a one-dimensional SDE of the form (6.6), the product dXt dXt
can be written as
dXt dXt = œÉ(t, Xt)2 dt
and we get
d

f (Xt)

= f ‚Ä≤(Xt) dXt + 1
2 f ‚Ä≤‚Ä≤(Xt)œÉ(t, Xt)2 dt
= f ‚Ä≤(Xt) (Œº(t, Xt) dt + œÉ(t, Xt) dBt) + 1
2 f ‚Ä≤‚Ä≤(Xt)œÉ(t, Xt)2 dt
=

f ‚Ä≤(Xt)Œº(t, Xt) + 1
2 f ‚Ä≤‚Ä≤(Xt)œÉ(t, Xt)2

dt + f ‚Ä≤(Xt)œÉ(t, Xt) dBt.
(6.14)

CONTINUOUS-TIME MODELS
229
Example 6.10
Let X = B be a one-dimensional Brownian motion and f (x) = x2.
In this case, since f ‚Ä≤(x) = 2x and f ‚Ä≤‚Ä≤(x) = 2, we can use Ito‚Äôs formula in the form
of equation (6.13) to Ô¨Ånd
d

B2
t

= 2Bt dBt + 1
22 dB dB = 2Bt dBt + dt.
This equation can be written in integral notation as
B2
t ‚àíB2
0 = 2
 t
0
Bs dBs + (t ‚àí0)
and, since B0 = 0, we can rewrite this as
 t
0
Bs dBs = 1
2

B2
t ‚àít

.
Thus, with the help of Ito‚Äôs formula we have found the exact value of the stochastic
integral

 t
0 Bs dBs.
Example 6.11
Let Xt = x0 exp

Œ±Bt + Œ≤t

be a geometric Brownian motion with
x0 ‚ààR. Then we can write Xt = f (t, Bt) for all t ‚â•0, where
f (t, x) = x0 exp

Œ±x + Œ≤t

.
In order to Ô¨Ånd the stochastic differential dX, we need to compute the derivatives of
f : we get
‚àÇ
‚àÇt f (t, x) = x0Œ≤ exp

Œ±x + Œ≤t

= Œ≤ f (t, x),
‚àÇ
‚àÇx f (t, x) = x0Œ± exp

Œ±x + Œ≤t

= Œ±f (t, x),
‚àÇ2
‚àÇx2 f (t, x) = x0Œ±2 exp

Œ±x + Œ≤t

= Œ±2 f (t, x).
Now we can apply Ito‚Äôs formula in the form of equation (6.12) to get
dXt = d

f (t, Bt)

= ‚àÇ
‚àÇt f (t, Bt) dt + ‚àÇ
‚àÇx f (t, Bt) dBt + 1
2
‚àÇ2
‚àÇx2 f (t, Bt) dBt dBt
= Œ≤ f (t, Bt) dt + Œ±f (t, Bt) dBt + 1
2Œ±2 f (t, Bt) dt

230
AN INTRODUCTION TO STATISTICAL COMPUTING
=

Œ≤ + Œ±2
2

f (t, Bt) dt + Œ±f (t, Bt) dBt
=

Œ≤ + Œ±2
2

Xt dt + Œ±Xt dBt.
Thus, we have found that the geometric Brownian motion X is a solution of the SDE
dXt =
Œ±2
2 + Œ≤

Xt dt + Œ±Xt dBt
X0 = x0.
6.4.2.3
Stratonovich integrals
Looking back at the deÔ¨Ånition of the Ito integral in equation (6.9) we can see that
we had a choice when we chose the analogy to the Riemann integral from equation
(6.10): The approximation in (6.10) still works if f (ti) is replaced with f (ti+1), or
with any f (Àúti) where Àúti ‚àà[ti, ti+1]. It transpires that the stochastic integral in (6.9) is
much less robust: the integrand Y must be evaluated at the left-most point ti of each
discretisation interval [ti, ti+1]. If Yti in (6.9) is, for example, replaced with Yti+1, one
can show that for many integrators X the approximation converges to a different limit
as n ‚Üí‚àû. This is caused by the irregular paths featured by typical integrators, for
example, for X = B as before.
By choosing different times to evaluate the integrand of a stochastic integral,
different kinds of stochastic integrals can be obtained. The most common choice,
after the Ito integral, is called the Stratonovich integral. This integral is obtained by
evaluating the integrand at the centre of each discretisation interval, and it is denoted
by an additional ‚ó¶in front of the integrand dX:
 T
0
f (t) ‚ó¶dXt = lim
n‚Üí‚àû
n‚àí1

i=0
f

t(n)
i
+ t(n)
i+1
2


Xt(n)
i+1 ‚àíXt(n)
i

.
(6.15)
Correspondingly, by replacing the Ito integral in (6.8) with a Stratonovich integral,
Stratonovich SDEs of the form
dXt = Œº(t, Xt) dt + œÉ(t, Xt) ‚ó¶dBt
X0 = x0
(6.16)
can be deÔ¨Åned.
Studying the difference between the Ito integral (6.9) and the Stratonovich inte-
gral (6.15) more closely, one can show that a process X solves the Stratonovich

CONTINUOUS-TIME MODELS
231
SDE (6.16) with differentiable diffusion coefÔ¨Åcient œÉ, if and only if it solves the
Ito SDE
dXt = ÀúŒº(t, Xt) dt + œÉ(t, Xt) dBt
X0 = x0,
where the drift vector ÀúŒº: [0, ‚àû) √ó Rd ‚ÜíRd has components
ÀúŒºi(t, x) = Œºi(t, x) + 1
2
m

j=1
d

k=1
œÉkj(t, x) ‚àÇ
‚àÇxk
œÉi j(t, x)
for all t ‚â•0 and x ‚ààRd and for all i = 1, 2, . . . , d. This allows to convert any
Stratonovich SDE into an Ito SDE with the same solutions. For this reason, in the
rest of this chapter we will only discuss Ito SDEs.
6.4.3
Discretisation schemes
In this section we will discuss methods to simulate solutions of an SDE using a
computer. We consider the SDE
dXt = Œº(t, Xt) dt + œÉ(t, Xt) dBt
X0 = x0
(6.17)
where B = (Bt)t‚â•0 is an m-dimensional Brownian motion, Œº: [0, ‚àû) √ó Rd ‚ÜíRd is
the drift, and the diffusion coefÔ¨Åcient is given by œÉ: [0, ‚àû) √ó Rd ‚ÜíRd√óm. Our aim
is to simulate values of X at times 0 = t0 < t1 < ¬∑ ¬∑ ¬∑ < tn. We will proceed, starting
with X0 = x0, by successively computing Xt1, Xt2, . . . until time tn is reached.
The amount of change of X over the time interval [ti, ti+1] can be found from the
deÔ¨Ånition (6.8) of a solution: subtracting the expressions for Xti from the expression
for Xti+1, we Ô¨Ånd
X( j)
ti+1 ‚àíX( j)
ti
=
 ti+1
ti
Œº j(t, Xt) dt +
m

k=1
 ti+1
ti
œÉ jk(t, Xt) dB(k)
t
(6.18)
for j = 1, 2, . . . , d. Assume that we have already computed X0, Xt1, . . . , Xti and we
want to compute Xti+1. Then we have to solve the following two problems:
r The integrals on the right-hand side of (6.18) depend on the values Xt for
t ‚àà[ti, ti+1]. This is a problem, since we only know the (approximate) value
of Xti and the values of Xt for t > ti are unknown.
r Even if X was known, it is still not clear how the integrals can be solved for
nontrivial functions Œº and œÉ.

232
AN INTRODUCTION TO STATISTICAL COMPUTING
There are different approaches to solving these problems, leading to different
numerical schemes.
6.4.3.1
The Euler‚ÄìMaruyama scheme
The idea behind the Euler‚ÄìMaruyama scheme (sometimes called the stochastic Euler
scheme or just the Euler scheme) is to evaluate the drift and diffusion coefÔ¨Åcient in
(6.18) at time ti instead of time t for all t ‚àà[ti, ti+1]. Then the integrals can be
approximated by
 ti+1
ti
Œº j(t, Xt) dt ‚âà
 ti+1
ti
Œº j(ti, Xti ) dt = Œº j(ti, Xti ) (ti+1 ‚àíti)
and
m

k=1
 ti+1
ti
œÉ jk(t, Xt) dB(k)
t
‚âà
m

k=1
 ti+1
ti
œÉ jk(ti, Xti ) dB(k)
t
=
m

k=1
œÉ jk(ti, Xti )

B(k)
ti+1 ‚àíB(k)
ti

=

œÉ(ti, Xti )

Bti+1 ‚àíBti

j .
where the last expression uses matrix-vector multiplication to simplify notation. Sub-
stituting these approximations into equation (6.18) allows us to compute approximate
values
Xti+1 ‚àíXti ‚âàŒº j(ti, Xti ) (ti+1 ‚àíti) + œÉ(ti, Xti )

Bti+1 ‚àíBti

(6.19)
for i = 0, 1, . . . , n ‚àí1. This leads to the following algorithm for computing approx-
imate solutions to SDEs.
Algorithm 6.12
(Euler‚ÄìMaruyama scheme)
input:
the drift Œº: [0, ‚àû) √ó Rd ‚ÜíRd
the diffusion coefÔ¨Åcient œÉ: [0, ‚àû) √ó Rd ‚ÜíRm√ód
the initial value x0 ‚ààRd
the time horizon T ‚â•0
the discretisation parameter n ‚ààN
randomness used:
samples B0, Bh, B2h, . . . , Bnh from a d-dimensional Brownian motion,
where h = T/n
output:
an approximation (XEM
ih )i=0,...,n to a solution of (6.17)
1: h ‚ÜêT/n
2: XEM
0
‚Üêx0

CONTINUOUS-TIME MODELS
233
3: for i = 0, 1, . . . , n ‚àí1 do
4:
Bi ‚ÜêB(i+1)h ‚àíBih
5:
XEM
(i+1)h ‚ÜêXEM
ih + Œº(ih, XEM
ih ) h + œÉ(ih, XEM
ih ) Bi
6: end for
7: return (XEM
ih )i=0,1,...,n
The algorithm can either use a given path of a Brownian motion, or alternatively
the increments Bi can be directly sampled in the algorithm by generating Bi ‚àº
N(0, hId) independently in each iteration of the loop.
Lemma 6.13
The computational cost for computing a path using the Euler‚Äì
Maruyama scheme from algorithm 6.12 is of order C(n) = O(n).
Proof
Each of the iterations of the loop has the same cost, so the total cost is
C(n) = a + bn, where a is the cost of the assignments at the start of the algorithm
and b is the cost per iteration of the loop.
Since the approximations underlying the Euler method get more accurate when
the size of the time step decreases, we expect the ‚Äòerror‚Äô of the Euler‚ÄìMaruyama
approximation to go to 0 as the discretisation parameter n increases. This convergence
is discussed in Section 6.4.4.
Example 6.14
For Œ±, Œ≤ ‚ààR, consider the one-dimensional SDE
dXt =
Œ±2
2 + Œ≤

Xt dt + Œ±Xt dBt.
(6.20)
The Euler‚ÄìMaruyama scheme for this SDE is
XEM
(i+1)h = XEM
ih +
Œ±2
2 + Œ≤

XEM
ih h + Œ± XEM
ih Bi
for i = 0, 1, . . . , n ‚àí1, where XEM
0
= x0 and Bi = B(i+1)h ‚àíBih. We can obtain
numerical solutions of SDE (6.20) by iteratively computing XEM
ih
for i =
0, 1, . . . , n ‚àí1.
When applying algorithm 6.12, there is a trade-off between speed and accuracy to
be made: larger values of the discretisation parameter n lead to more accurate results,
smaller values of n lead to faster execution.
6.4.3.2
The Milstein scheme
The Milstein scheme is an improved version of the Euler‚ÄìMaruyama scheme. It
uses a slightly more complicated discretisation mechanism to achieve more accurate

234
AN INTRODUCTION TO STATISTICAL COMPUTING
results. In this section we only discuss the one-dimensional case. More speciÔ¨Åcally,
we consider
dXt = Œº(Xt) dt + œÉ(Xt) dBt
for all t >0,
X0 = x0,
(6.21)
where B = (Bt)t‚â•0 is a one-dimensional Brownian motion, Œº: R ‚ÜíR is the drift
and œÉ: R ‚ÜíR is the diffusion coefÔ¨Åcient.
Like the Euler‚ÄìMaruyama scheme, the Milstein scheme is based on equation
(6.18), but instead of the approximation œÉ(Xt) ‚âàœÉ(Xti) for all t ‚àà[ti, ti+1], the
Milstein scheme uses an improved approximation: since the paths of the Brownian
motion B are very rough, for t ‚âàti the Brownian increment |Bt ‚àíBti| is much bigger
than |t ‚àíti|. Consequently, the second term in the approximation (6.19) dominates
and we have
Xt ‚àíXti ‚âàœÉ(Xti) ¬∑

Bt ‚àíBti

.
Using this approximation, together with Ô¨Årst-order Taylor approximation for œÉ, we
Ô¨Ånd
œÉ(Xt) = œÉ(Xti + Xt ‚àíXti)
‚âàœÉ(Xti) + œÉ ‚Ä≤(Xti)(Xt ‚àíXti)
‚âàœÉ(Xti) + œÉ ‚Ä≤(Xti)œÉ(Xti) ¬∑

Bt ‚àíBti

.
Using this expression, the second integral in (6.18) can be approximated as
 ti+1
ti
œÉ(Xt) dBt ‚âà
 ti+1
ti
œÉ(Xti ) + œÉ ‚Ä≤(Xti)œÉ(Xti ) ¬∑

Bt ‚àíBti

dBt
= œÉ(Xti )

Bti+1 ‚àíBti

+ œÉ ‚Ä≤(Xti )œÉ(Xti )
 ti+1
ti

Bt ‚àíBti

dBt
= œÉ(Xti )

Bti+1 ‚àíBti

+ œÉ ‚Ä≤(Xti )œÉ(Xti )1
2

Bti+1 ‚àíBti
2 ‚àí(ti+1 ‚àíti)

,
where the value of the last stochastic integral is found similar to the one in example
6.10. Based on this argument, the Milstein scheme replaces (6.19) by
Xti+1 ‚àíXti ‚âàŒº j(Xti) hi + œÉ(Xti ) Bi
+1
2œÉ(Xih)œÉ ‚Ä≤(Xih)

B2
i ‚àíhi

,
(6.22)
where œÉ ‚Ä≤ is the derivative of œÉ, Bi = Bti+1 ‚àíBti , and hi = ti+1 ‚àíti for i =
0, 1, . . . , n ‚àí1. Comparing this expression with equation (6.19) shows that the only

CONTINUOUS-TIME MODELS
235
difference between the Euler‚ÄìMaruyama and Milstein methods is the term in the sec-
ond line of equation (6.22). In the special case where œÉ is constant, we have œÉ ‚Ä≤ = 0
and both methods coincide.
Algorithm 6.15
(Milstein scheme)
input:
the drift Œº: R ‚ÜíR
the diffusion coefÔ¨Åcient œÉ: R ‚ÜíR and its derivative œÉ ‚Ä≤
the initial value X0 ‚ààR
the time horizon T ‚â•0
the discretisation parameter n ‚ààN
randomness used:
samples B0, Bh, B2h, . . . , Bnh from a one-dimensional Brownian motion,
where h = T/n
output:
an approximation (XMIL
ih )i=0,...,n to a solution of (6.21)
1: h ‚ÜêT/n
2: for i = 0, 1, . . . , n ‚àí1 do
3:
generate Bi = B(i+1)h ‚àíBih
4:
XMIL
(i+1)h = XMIL
ih
+ Œº(XMIL
ih ) h + œÉ(XMIL
ih ) Bi
+ 1
2œÉ(XMIL
ih )œÉ ‚Ä≤(XMIL
ih )

B2
i ‚àíh

5: end for
6: return (XMIL
ih )i=0,1,...,n
As before, there is a trade-off between speed of the algorithm and accuracy of the
obtained approximation: larger values of the discretisation parameter n lead to more
accurate results, smaller values of n lead to faster execution.
Lemma 6.16
The computational cost for computing a path from the Milstein
scheme in algorithm 6.1 is of order C(n) = O(n).
Proof
Each of the iterations of the loop has the same cost, so the total cost is
C(n) = a + bn where a is the cost of the assignments at the start of the algorithm
and b is the cost per iteration of the loop.
We defer discussion of the error of the Milstein method until Section 6.4.4.
Example 6.17
Continuing from example 6.14, we consider again the SDE
dXt =
Œ±2
2 + Œ≤

Xt dt + Œ±Xt dBt.

236
AN INTRODUCTION TO STATISTICAL COMPUTING
Since the diffusion coefÔ¨Åcient is œÉ(x) = Œ±x, we have œÉ ‚Ä≤(x) = Œ± and œÉ(x)œÉ ‚Ä≤(x) =
Œ±2x. Thus the Milstein scheme for this SDE is
XMIL
(i+1)h = XMIL
ih
+
Œ±2
2 + Œ≤

XMIL
ih
h + Œ± XMIL
ih
Bi
+ Œ±2
2 XMIL
ih

B2
i ‚àíh

for i = 0, 1, . . . , n ‚àí1, where XMIL
0
= x0 and Bi = B(i+1)h ‚àíBih.
6.4.4
Discretisation error
Since numerical methods for SDEs replace the increments from equation (6.18) by
approximations, a numerically obtained solution will not exactly coincide with the
exact solution. In this section we will discuss the resulting discretisation error.
Since both the exact solution and the numerical approximation are random, dif-
ferent ways of quantifying the error can be considered.
6.4.4.1
Strong error
Let X be the exact solution of the SDE (6.17) and let ÀÜX be a numerical approximation
to X, using the same Brownian motion as X does. Then the strong error of the
approximation ÀÜX at time T is given by
estrong = E
 ÀÜXT ‚àíXT

(6.23)
for all sufÔ¨Åciently large n. The quantity estrong measures the average distance between
the exact and the approximate solution. The strong error is small, if the values of the
numerical solution are close to the values of the exact solution, that is if the paths of
the SDE are approximated well.
Different numerical methods can be compared by studying how the strong error
decreases when the discretisation parameter increases. This needs to be balanced to
the corresponding increase in computational cost.
Let XEM be the Euler‚ÄìMaruyama approximation computed by algorithm 6.12
with discretisation parameter n. Then, under appropriate assumptions on the drift Œº
and the diffusion coefÔ¨Åcient œÉ, there is a constant c > 0 such that
eEM
strong = E
XEM
T
‚àíXT
 ‚â§
c
‚àön .
Let XMIL be the Milstein approximation, computed by algorithm 6.15 with dis-
cretisation parameter n. Then, under appropriate assumptions on the drift Œº and the

CONTINUOUS-TIME MODELS
237
diffusion coefÔ¨Åcient œÉ, there is a constant c > 0 such that the strong error of the
Milstein scheme satisÔ¨Åes
eMIL
strong = E
XMIL
T
‚àíXT
 ‚â§c
n
for all sufÔ¨Åciently large n. As n gets large, this bound decays faster than the bound
c/‚àön for the Euler‚ÄìMaruyama method. Thus, for large n, the Milstein scheme has a
signiÔ¨Åcantly smaller strong error than the Euler‚ÄìMaruyama scheme.
Example 6.18
SDE (6.20) from example 6.14 is simple enough that it can be
solved explicitly: from example 6.11 we know that the exact solution of (6.20) is the
geometric Brownian motion
Xt = X0 exp (Œ±Bt + Œ≤t) .
This knowledge of the exact solution allows us to ‚Äòmeasure‚Äô the error of different
discretisation schemes: comparing a numerical solution ÀÜXT to the exact value XT
allows to determine | ÀÜXT ‚àíXT |. By repeating this experiment for different paths of
the Brownian motion B and taking averages, we can obtain a Monte Carlo estimate
for the error estrong = E
 ÀÜXT ‚àíXT
. Repeating this estimation procedure for different
values of n allows then to determine the dependence of eEM
strong on the discretisation
parameter n.
Figure 6.8 shows the result of such simulations, for ÀÜX = XEM and ÀÜX = XMIL,
respectively. The Ô¨Ågure conÔ¨Årms that we have indeed eEM
strong ‚âàc/‚àön and eMIL
strong ‚âà
c/n.
6.4.4.2
Weak error
In cases where we solve the SDE for use in a Monte Carlo estimate, it is only important
that the distribution of XEM
T
is accurate, whereas it is less important that the values
of XEM
T
(as a function of B) are accurate. For this reason, a second error criterion is
considered in this section.
As before, let X be the exact solution of an SDE and let ÀÜX be a numerical
approximation to X. Furthermore, let A be a class of functions from Rd to R (e.g.
all bounded, twice differentiable functions). Then the error in the distribution of ÀÜXT
can be quantiÔ¨Åed by considering
eweak( f ) =
E

f ( ÀÜXT )

‚àíE ( f (XT ))

(6.24)
for all f ‚ààA and all sufÔ¨Åciently large n. The quantity
eweak = sup
f ‚ààA
eweak( f )

238
AN INTRODUCTION TO STATISTICAL COMPUTING
x
x
x
x
x
x
x
x
x
0.005
0.010
0.020
0.050
1
2
5
10
20
h
Strong error
o
o
o
o
o
o
o
o
o
x
o
Euler‚àíMaruyama
Milstein
Figure 6.8
Strong error of the Euler‚ÄìMaruyama and Milstein schemes, for the SDE
(6.20) with Œ± = 1, Œ≤ = 0.4 and T = 5. The plot shows the estimated strong error for
both methods as a function of the step size h = T/n, for different values of n. The points
marked with ‚Äòx‚Äô are Monte Carlo estimates for eEM
strong, the points marked with ‚Äòo‚Äô are
Monte Carlo estimates for eMIL
strong, and the bars give 95% conÔ¨Ådence intervals for the
Monte Carlo estimates. Finally, the solid lines are Ô¨Åtted curves of the forms c/‚àön
(for the Euler‚ÄìMaruyama method) and c/n (for the Milstein method), respectively.
is called the weak error of ÀÜX at time T . In this context, the functions f ‚ààA are called
test functions. The weak error is small, if the distribution of the numerical solution is
close to the distribution of the exact solution.
Let XEM be the Euler‚ÄìMaruyama approximation with discretisation parameter n.
Then, under appropriate assumptions on the drift Œº, the diffusion coefÔ¨Åcient œÉ and
the class A, there is a constant c > 0 such that
eEM
weak = sup
f ‚ààA
E

f (XEM
T )

‚àíE ( f (XT ))
 ‚â§c
n
(6.25)
for all f ‚ààA and all sufÔ¨Åciently large n. Similarly, let XMIL be the Milstein approx-
imation to X. Then, under appropriate assumptions on the drift Œº, the diffusion
coefÔ¨Åcient œÉ and the class A, there is a constant c > 0 such that
eMIL
weak( f ) = sup
f ‚ààA
E

f (XMIL
T
)

‚àíE ( f (XT ))
 ‚â§c
n
(6.26)
for all f ‚ààA and all sufÔ¨Åciently large n. This is the same rate of convergence as
for the Euler‚ÄìMaruyama scheme. Thus we would expect the weak errors for the two
schemes to stay comparable as n increases.

CONTINUOUS-TIME MODELS
239
Example 6.19
Continuing from example 6.18, it is possible to numerically estimate
eEM
weak( f ) for solutions of (6.20). The exact expectation is given by
E ( f (XT )) = E ( f (X0 exp(Œ±BT + Œ≤T ))) .
Since BT ‚àºN(0, T ), for simple functions f and deterministic X0 this expectation
can be calculated analytically. On the other hand, the expectation E

f (XEM
T )

can
be estimated using Monte Carlo integration.
For this example we consider the case of X0 = 1 and f (x) = 1(‚àí‚àû,a](x) for some
constant a. Then we have
E ( f (XT )) = P (exp (Œ±BT + Œ≤t) ‚â§a) = P

BT ‚â§log(a) ‚àíŒ≤t
Œ±

.
(6.27)
Figure 6.9 shows a simulation where a is chosen such that the expectation in (6.27)
equals 0.6.
Some care is needed when performing numerical experiments of this kind: since
eweak( f ) is typically much smaller than either of the values E

f ( ÀÜXT )

and E ( f (XT )),
the Monte Carlo estimates for the expectation need to be performed with high accuracy
and thus require huge sample sizes. In addition, for unbounded test functions f , the
x
x
x
x
x
x
x
x
x
0.005
0.010
0.020
0.050
5e‚àí04
2e‚àí03 5e‚àí03
2e‚àí02
h
Weak error
o
o
o
o
o
o
o
o
o
x
o
Euler‚àíMaruyama
Milstein
Figure 6.9
Weak error for the Euler‚ÄìMaruyama and Milstein schemes, for the SDE
(6.20) with Œ± = 1, Œ≤ = 0.4 and T = 5. The plot shows the estimated weak error for
both methods as a function of the step size h = T/n, for different values of n. The
points marked ‚Äòx‚Äô are Monte Carlo estimates for eEM
weak( f ), the points marked ‚Äòo‚Äô
are Monte Carlo estimates for eMIL
weak( f ), and the bars give 95% conÔ¨Ådence intervals
for the Monte Carlo estimates. The test function used is f (x) = 1(‚àí‚àû,a](x) for some
constant a. The solid lines correspond to 0.6275/n (for the Euler‚ÄìMaruyama method)
and 1.584/n (for the Milstein method), respectively.

240
AN INTRODUCTION TO STATISTICAL COMPUTING
SDE (6.20) is susceptible to problems such as the one illustrated in Figure 6.6,
potentially making Monte Carlo estimation very difÔ¨Åcult.
6.4.4.3
Qualitative behaviour of solutions
The strong and weak errors discussed so far describe convergence of numerical
approximations to the exact solutions as the discretisation parameter increases. In
this section we will discuss two effects which, for Ô¨Åxed discretisation parameter, can
affect the qualitative behaviour of numerical solutions.
One case where numerical solutions can be qualitatively different from the
exact solution is when the exact solution is known to be positive whereas the
numerical solution may become negative. This problem could, for example, occur
when the SDE in question models a stock price or an interest rate. We illustrate
this problem here for the case of the one-dimensional Euler‚ÄìMaruyama scheme:
assume that the current value of the simulation is XEM
ih = x. Then the next value is
given by
XEM
(i+1)h = x + Œº(x) h + œÉ(x) Bi
‚àºN

x + Œº(x)h, œÉ(x)2h

.
Since XEM
(i+1)h is normally distributed, it takes negative values with positive probability.
Usually, the probability of this happening is negligible, but in cases where the current
state x is close to 0 or when Œº or œÉ is large, the problem can appear with high enough
probability to be seen in practice. This effect is illustrated in Figure 6.10.
t
(i ‚àí1)h
ih
(i + 1)h
ÀÜX(i‚àí1)h
ÀÜXih
ÀÜX(i+1)h
Figure 6.10
Illustration of a case where the numerical solution of an SDE becomes
negative while the exact solution stays positive. The dashed line shows the solution of
the equation with the noise term removed, starting at (ih, ÀÜXih). A method such as the
Euler‚ÄìMaruyama scheme will choose the next approximation point ((i + 1)h, ÀÜX(i+1)h)
by following the tangent of this line and then adding the random term coming from
the Brownian increment. If h is large enough, this can lead to ÀÜX(i+1)h < 0. The thin,
rough line gives a path of the exact SDE, starting (ih, ÀÜXih), for comparison.

CONTINUOUS-TIME MODELS
241
If this effect causes problems, for example in cases when Œº or œÉ are only deÔ¨Åned
for x > 0, there are several ad hoc ways to force the numerical solution to be positive:
r One can replace negative values of ÀÜXih with | ÀÜXih| throughout the algorithm.
For example, for the Euler method, one could replace the update step by
ÀÜX(i+1)h =
 ÀÜXih + Œº(ih, ÀÜXih) h + œÉ(ih, ÀÜXih) Bi
,
with the modulus added to keep the solution positive. This method may intro-
duce a bias, because solutions are only ever modiÔ¨Åed to take larger values.
r One can consider Yt = log(Xt) instead of X. Since the function f (x) = log(x)
has derivatives f ‚Ä≤(x) = 1/x and f ‚Ä≤‚Ä≤(x) = ‚àí1/x2, Ito‚Äôs formula in the form of
equation (6.14) can be used to derive and SDE for Y:
dYt = d (log(Xt))
=
Œº(t, Xt)
Xt
‚àíœÉ(t, Xt)2
2X2
t

dt + œÉ(t, Xt)
Xt
dBt
=
Œº(t, eYt)
eYt
‚àíœÉ(t, eYt)2
2e2Yt

dt + œÉ(t, eYt)
eYt
dBt
= ÀúŒº(t, Yt) dt + ÀúœÉ(t, Yt) dBt,
where
ÀúŒº(t, y) = Œº(t, ey)
ey
‚àíœÉ(t, ey)2
2e2y
and
ÀúœÉ(t, y) = œÉ(t, ey)
ey
.
Another class of problems of numerical solutions of SDEs comes from the lack
of stability of some numerical methods: it can happen that the numerical solution
‚Äòexplodes‚Äô, while the exact solution of the SDE stays bounded. This effect is illustrated
in Figure 6.11.
We illustrate the problem of numerical instability here with the help of an example.
Consider the one-dimensional SDE
dXt = ‚àíX3 dt + dBt.
The Euler‚ÄìMaruyama scheme with step size h > 0 for this SDE is given by
ÀÜX(i+1)h = ÀÜXih ‚àíÀÜX3
ih h + Bi = ÀÜXih

1 ‚àíÀÜX2
ih h

+ Bi.
Assume now that the discretised solution reaches by chance a state ÀÜXih = x with
|x| ‚â•

2 + Œµ
h

242
AN INTRODUCTION TO STATISTICAL COMPUTING
0
200
400
600
800
1000
‚àí4 ‚àí2
0
2
4
Xt
950
960
970
980
990
1000
‚àí20 ‚àí10
0
10
20
t
Xt
(a)
(b)
Figure 6.11
Numerical solution of an SDE where the Euler scheme is unstable. (a)
A simulation of the SDE until the method becomes unstable. (b) A ‚Äòzoomed in‚Äô view
of the last few steps before the numerical solution explodes.
for some Œµ > 0. Then we have ÀÜX2
ihh ‚â•2 + Œµ. If h is small, for this x the drift ‚àíx3
will be much bigger than the diffusion term Bi and thus we Ô¨Ånd
 ÀÜX(i+1)h
 ‚âà
 ÀÜXih
1 ‚àíÀÜX2
ihh
 ‚â•(1 + Œµ)
 ÀÜXih
,
where ÀÜX(i+1)h and ÀÜXih have opposite signs. Since this implies ÀÜX(i+1)h > ÀÜXih, the
same argument applies again for the next step of the discretisation, and we Ô¨Ånd
 ÀÜX(i+k)h
 ‚™Ü(1 + Œµ)k ÀÜXih

and consequently ÀÜX(i+k)h diverges exponentially fast. While in theory the values
ÀÜX(i+k)h stay Ô¨Ånite (but very big) numbers, in a numerical simulation the resulting
numbers will quickly leave the range of values which can be represented on a com-
puter.
In cases where numerical instability is a problem, the best solution is often
to decrease the step size h of the discretisation scheme. With decreasing h, the
probability that the approximation hits an unstable state decays normally very quickly,
so that the instability, even when present theoretically, is not seen in practice for small
enough h.

CONTINUOUS-TIME MODELS
243
6.5
Monte Carlo estimates
One situation where numerical solutions of SDEs are employed is the computation
of Monte Carlo estimates.
6.5.1
Basic Monte Carlo
Assume that X = (Xt)t‚àà[0,T ] is given as the solution of an SDE and that we want to
compute E ( f (X)). In order to estimate this quantity using Monte Carlo integration,
we generate independent samples X(n,1), X(n,2), . . . , X(n,N), using numerical approx-
imations to X, obtained by repeatedly solving a discretised SDE with discretisation
parameter n. Then we can use the approximation
E ( f (X)) ‚âà1
N
N

j=1
f (X(n, j)) = Zn,N.
(6.28)
Here we allow for the function f to depend on the whole path of X until time T . We
can choose, for example,
f (X) = sup
t‚àà[0,T ]
Xt
to get the maximum of a one-dimensional path, or f (X) = |XT |2 to get the second
moment of the Ô¨Ånal point of the path.
As for all Monte Carlo methods, there is a trade-off between accuracy of the result
and computational cost. One notable feature of Monte Carlo estimation for SDEs is
that the result is not only affected by the Monte Carlo error, but also by discretisation
error.
Lemma 6.20
The computational cost of computing the Monte Carlo estimate Zn,N
from (6.28) is of order C = O(nN). The mean squared error of the estimate is
MSE(Zn,N) = œÉ 2
N + eweak( f )2,
where œÉ 2 = Var

f (X(n)
T )

is the sample variance corresponding to the endpoint of
the numerical solution of the SDE with discretisation parameter n and eweak( f ) is the
weak error of the approximation scheme used.
Proof
The cost of computing a single solution X(n, j) with discretisation parameter
n is of order O(n). For Zn,N we have to compute N such solutions and add them up,
leading to a total cost of order O(nN).

244
AN INTRODUCTION TO STATISTICAL COMPUTING
By lemma 3.12, the mean squared error of the estimator Zn,N is
MSE(Zn,N) = E

Zn,N ‚àíE ( f (XT ))
2
= Var(Zn,N) + bias(Zn,N)2.
The variance of Zn,N is given by
Var(Zn,N) =
Var

f (X(n,1)
T
)

N
= œÉ 2
N .
The bias of Zn,N can be found as
bias(Zn,N)
 =
E(Zn,N) ‚àíE ( f (XT ))

=
E

f (X(n,1)
T
)

‚àíE ( f (XT ))

= eweak( f ).
Substituting these two expressions into the formula for the mean squared error com-
pletes the proof.
The variance of Zn,N, given by the term œÉ 2/N, corresponds to Monte Carlo error.
It decreases to 0 as the Monte Carlo sample size N increases. The bias of Zn,N,
corresponding to eweak( f )2 in the lemma, decreases to 0 as the grid parameter n
increases.
Example 6.21
Consider the process
dXt = ‚àíXt dt + dBt
X0 = 0.
(6.29)
Assume that we want to estimate the probability that the process X exceeds the level
c > 0 before time T , that is we want to estimate
p = P

sup
t‚àà[0,T ]
Xt > c

.
A basic Monte Carlo estimate for this probability is obtained as follows:
(a) Choose a discretisation parameter n and let h = T/n.
(b) Simulate solutions (X( j)
ih )i=0,1,...,n of (6.29) for j = 1, 2, . . . , N. The Euler‚Äì
Maruyama scheme (algorithm 6.12) can be used for this purpose.

CONTINUOUS-TIME MODELS
245
(c) For each path X( j), determine
1(c,‚àû)

sup
i
X( j)
ih

=
	
1
ifX( j)
ih > c for at least one i ‚àà{0, 1, 2, . . . , n}
0
otherwise.
(d) Compute the estimate pMC for p as
pMC = 1
N
N

j=1
1(c,‚àû)(sup
i
X( j)
ih ).
A numerical experiment, using 200000 simulated paths of SDE (6.29), results in
the estimate
P

sup
t‚àà[0,5]
Xt > 3.2

‚âà1.45 ¬∑ 10‚àí4.
An estimated conÔ¨Ådence interval for this probability, obtained ignoring the bias
and only considering the standard deviation of the Monte Carlo samples, is [0.92 ¬∑
10‚àí4, 1.98 ¬∑ 10‚àí4].
We can optimise the parameters N and n to minimise the computational cost
required to achieve a given error. For the Euler‚ÄìMaruyama scheme and the Milstein
scheme the rate of decay of the weak error is given in equation (6.25) and equation
(6.26), respectively. The weak error typically decays as a/n for some constant a > 0.
Thus, the mean squared error of the estimator Zn,N satisÔ¨Åes
MSE(Zn,N) ‚âàœÉ 2
N + a2
n2
(6.30)
where n is the grid parameter used for discretising the SDE and N is the sample size
for the Monte Carlo estimate. This error needs to be balanced against the cost of
computing the estimate Zn,N, given by
C(n, N) = bnN
(6.31)
for some constant b > 0.
Our aim is now to tune the parameters N and n to minimise the computational
cost while, at the same time, keeping the mean squared error below a speciÔ¨Åed level.
For this, we will use the following general result.
Theorem 6.22
(optimisation under constraints). Let f, g1, . . . , gn: Rd ‚ÜíR be
continuously differentiable functions. DeÔ¨Åne C ‚äÜRd by
C =

x ‚ààRd  g1(x) = g2(x) = ¬∑ ¬∑ ¬∑ = gn(x) = 0


246
AN INTRODUCTION TO STATISTICAL COMPUTING
and let x‚àó‚ààC be a global maximum or minimum of the restriction of f to the set C,
that is f (x‚àó) ‚â•f (x) for all x ‚ààC. Then x‚àósatisÔ¨Åes
‚àáf (x‚àó) = Œª1‚àág1(x‚àó) + Œª2‚àág2(x‚àó) + ¬∑ ¬∑ ¬∑ + Œªn‚àágn(x‚àó)
(6.32)
for some Œª1, . . . , Œªn ‚ààR. The numbers Œªi are called Lagrange multipliers.
While the criterion given in theorem 6.22 is only necessary but not sufÔ¨Åcient, it can
be used to identify candidates for maxima or minima. The relation (6.32) is a system
of d equations and the constraints gi(x‚àó) = 0 provide another n equations, giving
d + n equations in total. On the other hand, the unknown vector x‚àóhas d components
and we also have to identify the Lagrange multipliers Œª1, . . . , Œªn. Thus the total
number of unknowns, d + n, matches the number of equations. As a consequence,
in many cases the resulting set of equations has only Ô¨Ånitely many solutions and by
a systematic search we can determine which of these solutions corresponds to the
maximum or minimum of f .
Taking n and N to be continuous variables for simplicity, we can apply the-
orem 6.22 to Ô¨Ånd the minimum of the cost function (6.31) under the constraint
MSE(Zn,N) = Œµ2, where the mean squared error is given by equation (6.30). For the
partial derivatives, comprising the gradients in (6.32) we Ô¨Ånd
‚àÇ
‚àÇn MSE(Zn,N) = ‚àí2a2
n3 ,
‚àÇ
‚àÇn C(n, N) = bN
and
‚àÇ
‚àÇN MSE(Zn,N) = ‚àíœÉ 2
N 2 ,
‚àÇ
‚àÇN C(n, N) = bn.
Thus, the minimum of C under the constraint MSE(Zn,N) = Œµ2 satisÔ¨Åes the equations
‚àí2a2
(n‚àó)3 = Œª ¬∑ bN ‚àó,
‚àíœÉ 2
(N ‚àó)2 = Œª ¬∑ bn‚àó,
where Œª is the Lagrange multiplier, as well as the constraint
œÉ 2
N ‚àó+
a2
(n‚àó)2 = Œµ2.
The unique solution of this system of equations is given by
n‚àó=
‚àö
3 a ¬∑ 1
Œµ ,
N ‚àó= 3 œÉ 2
2
¬∑ 1
Œµ2 ,
(6.33)

CONTINUOUS-TIME MODELS
247
where Œª = ‚àí4 Œµ5/
‚àö
243 abœÉ 2, and substituting these values into (6.31) gives
C(n‚àó, N ‚àó) =
‚àö
27 abœÉ 2
Œµ3
= O

1/Œµ3
.
(6.34)
This is the optimal cost for Monte Carlo estimates of E ( f (XT )) with mean squared
error Œµ2, where XT is the end-point of the solution of an SDE.
From equation (6.33), assuming that œÉ 2 and a are both of order 1, we Ô¨Ånd that
the optimal way to balance the parameters N and n is to choose n approximately
equal to
‚àö
N. While the variance, controlled by N, is easy to determine numerically,
the bias, controlled by n, is difÔ¨Åcult to measure. For this reason, in practice it might
make sense to choose n bigger than
‚àö
N in order to avoid the risk of an unnoticed
bias affecting the Monte Carlo estimates for SDEs.
6.5.2
Variance reduction methods
The error in Monte Carlo estimates such as (6.28) can be signiÔ¨Åcantly reduced by
employing the variance reduction techniques from Section 3.3.
6.5.2.1
Antithetic paths
Pairs of antithetic paths can be easily generated for SDEs by using the fact that, if B
is a Brownian motion, ‚àíB is also a Brownian motion (see lemma 6.5): thus, solving
the SDE using the Brownian motions B and B‚Ä≤ = ‚àíB gives rise to two paths X and
X‚Ä≤ of the SDE. Since Bt and B‚Ä≤
t are negatively correlated, typically Xt and X‚Ä≤
t will
also be negatively correlated for all t ‚àà[0, T ].
Example 6.23
For illustration, Figure 6.12 (a) shows two paths of the SDE
dXt = (0.8 ‚àíXt) dt + Xt(1 ‚àíXt) dBt
X0 = 0,
(6.35)
(a)
(b)
0
1
2
3
4
5
0.0
0.4
0.8
t
Xt
0.3
0.5
0.7
0.9
0.3
0.5
0.7
0.9
XT
XT
'
Figure 6.12
Illustration of the antithetic variables method for SDEs. (a) Two paths
X and X‚Ä≤ of SDE (6.35), computed using Brownian paths B and ‚àíB. (b) A scatter
plot of 1000 pairs (XT , X‚Ä≤
T ), illustrating that the values are negatively correlated.

248
AN INTRODUCTION TO STATISTICAL COMPUTING
one path X computed from a Brownian path B and one path X‚Ä≤ computed from ‚àíB.
One can clearly see that often, if one path moves up, the other path moves down.
Figure 6.12(b) shows a scatter plot of 1000 pairs (XT , X‚Ä≤
T ), clearly illustrating that
the values are negatively correlated. In this example, the numerical value for the
correlation coefÔ¨Åcient is ‚àí0.787. From proposition 3.14 and proposition 3.27 we see
that for Ô¨Åxed sample size N, the root-mean squared error of this antithetic variables
method satisÔ¨Åes
RMSEAV =
‚àö
1 ‚àí0.787 RMSEMC = 0.461 RMSEMC.
Thus, for the same number of SDEs solved, the antithetic variables method in this
example has less than half the error than the corresponding basic Monte Carlo
estimate.
6.5.2.2
Importance sampling
In this section we will study how to apply the importance sampling method from
Section 3.3.1 to Monte Carlo estimates for SDEs. At Ô¨Årst this seems an impossible
task, since the solution of an SDE is a random function and not just a random number,
but it transpires that the method still works in many cases.
Consider solutions to the two SDEs
dXt = Œº(t, Xt) dt + œÉ(t, Xt) dBt
(6.36)
and
dYt = ÀúŒº(t, Yt) dt + œÉ(t, Yt) dBt,
(6.37)
on the time interval t ‚àà[0, T ], where B = (Bt)t‚â•0 is a d-dimensional Brownian
motion, Œº, ÀúŒº: [0, ‚àû) √ó Rd ‚ÜíRd are different drift functions and the common diffu-
sion coefÔ¨Åcient œÉ: [0, ‚àû) √ó Rd ‚ÜíRd√ód is invertible. We assume that both processes
start at the same initial value X0 = Y0.
Importance sampling for SDEs is based on the following consequence of Gir-
sanov‚Äôs theorem (see e.g. Mao, 2007, theorem 2.2). Here we state the result without
proof.
Theorem 6.24
Assume that the SDEs (6.36) and (6.37) have solutions X and Y,
respectively, up to time T > 0. Let f be a function which maps paths X: [0, T ] ‚ÜíRd
to real numbers. Then, under additional technical assumptions, we have
E ( f (X)) = E

f (Y) œï(Y)
œà(Y)

,
(6.38)

CONTINUOUS-TIME MODELS
249
where
œï(Y) = exp
 T
0
a(t, Yt)‚àí1Œº(t, Yt) dYt ‚àí1
2
 T
0
Œº(t, Yt)‚ä§a(t, Yt)‚àí1Œº(t, Yt) dt

and
œà(Y) = exp
 T
0
a(t, Yt)‚àí1 ÀúŒº(t, Yt) dYt ‚àí1
2
 T
0
ÀúŒº(t, Yt)‚ä§a(t, Yt)‚àí1 ÀúŒº(t, Yt) dt

with
a(t, x) = œÉ(t, x)œÉ(t, x)‚ä§‚ààRd√ód.
The relation (6.38) from the theorem replaces (3.13) in the basic importance
sampling method. When the theorem is used for importance sampling, the paths
Y will be generated using an approximation scheme for the SDE (6.37), and the
integrals in the expressions for œï and œà are evaluated using the approximations (6.9)
and (6.10).
An important special case is the situation where the SDEs for X and Y are one-
dimensional, Œº and ÀúŒº do not depend on time, and œÉ is constant. In this case, the
expression for œï simpliÔ¨Åes to
œï(Y) = exp
 1
œÉ 2
 T
0
Œº(Yt) dYt ‚àí
1
2œÉ 2
 T
0
Œº(Yt)2 dt

and œà is the corresponding expression obtained by replacing Œº with ÀúŒº. Thus, the
factor œï(Y)/œà(Y) from (6.38) can be found as
œï(Y)
œà(Y) = exp
 1
œÉ 2
 T
0
(Œº(Yt) ‚àíÀúŒº(Yt)) dYt ‚àí
1
2œÉ 2
 T
0

Œº(Yt)2 ‚àíÀúŒº(Yt)2
dt

.
(6.39)
Example 6.25
In example 6.21, we considered the probability that the solution of
the SDE (6.29) exceeds level c before time T . Since the drift Œº(x) = ‚àíx of this SDE
drives the process towards 0, large values of Xt are very unlikely. Thus, when c is
big, a large number of Monte Carlo samples is required to see a sufÔ¨Åcient number of
cases where 1(c,‚àû)(supi X( j)
ih ) = 1.
To reduce the required number of samples, we can use importance sampling with
samples from a modiÔ¨Åed process Y. The process Y should be chosen so that Y is
‚Äòsimilar‚Äô to X but that the event supt‚àà[0,1] Yt > c happens with probability higher than
p. For this example we will use solutions of the SDE
dYt = ‚àíqYt dt + dBt
Y0
= 0
(6.40)

250
AN INTRODUCTION TO STATISTICAL COMPUTING
with constant q ‚àà[0, 1). Since the drift is weaker, this process will stay less close
to 0 and thus is more likely to exceed level c. The drift of Y is ÀúŒº(x) = ‚àíqx and
consequently we Ô¨Ånd Œº(x) ‚àíÀúŒº(x) = ‚àíx ‚àí(‚àíqx) = ‚àí(1 ‚àíq)x as well as Œº(x)2 ‚àí
ÀúŒº(x)2 = x2 ‚àíq2x2 = (1 ‚àíq2)x2. Substituting these expressions into (6.39), we Ô¨Ånd
œï(Y)
œà(Y) = exp

‚àí(1 ‚àíq)
 T
0
Yt dYt ‚àí1 ‚àíq2
2
 T
0
Y 2
t dt

.
A numerical experiment, using 200000 simulated paths of SDE (6.40), results in
the estimate
P

sup
t‚àà[0,5]
Xt > 3.2

‚âà1.55 ¬∑ 10‚àí4.
An estimated conÔ¨Ådence interval, obtained by considering the standard deviation of
the Monte Carlo samples, for this probability is [1.41 ¬∑ 10‚àí4, 1.70 ¬∑ 10‚àí4]. Comparing
these estimates with the corresponding results from example 6.21 shows that the
importance sampling estimate, for the same number of samples, has signiÔ¨Åcantly
smaller error.
Another important variance reduction technique for Monte Carlo estimates for
solutions of SDEs is described in the next section.
6.5.3
Multilevel Monte Carlo estimates
The variance reduction methods we have discussed so far are applications of the
general methods from Section 3.3 to the problem of estimating expectations for paths
of SDEs. In contrast, the multilevel Monte Carlo approach, discussed in the rest of
this section, is speciÔ¨Åc to situations where discretisation error is involved.
Multilevel Monte Carlo methods, by cleverly balancing the effects of discretisa-
tion error and Monte Carlo error, allow us to reduce the computational cost required
to compute an estimate with a given level of error. Let X be the solution of an SDE
and let Œµ > 0. In equation (6.34) we have seen that the basic Monte Carlo estimate
for E ( f (XT )) requires computational cost of order O(1/Œµ3) in order to bring the
root-mean squared error down to Œµ > 0. We will see that multilevel Monte Carlo
methods can reduce this cost to nearly O(1/Œµ2).
Let
Yi = f

X(ni)
T

where X(ni)
T
is the approximation for XT with discretisation parameter ni. We
assume that n1 < n2 < . . . < nk so that the approximations Yi get more accurate
as i increases. Also, except for the smallest values of i we expect Yi ‚âàYi‚àí1, when
computed from the same path of the underlying Brownian motion. Thus the two

CONTINUOUS-TIME MODELS
251
values will be strongly correlated. We will exploit this correlation by using a variant
of the control variates method (see Section 3.3.3): we can expand Yk in a telescopic
sum as
Yk =
k

i=1
(Yi ‚àíYi‚àí1)
where Y0 = 0. For large enough k we have
E ( f (XT )) ‚âàE (Yk) =
k

i=1
E (Yi ‚àíYi‚àí1) .
Since we can obtain values of a Brownian path on the coarse and on the Ô¨Åne grid
simultaneously, each of the terms on the right-hand side can be estimated using Monte
Carlo integration: we get
E (Yi ‚àíYi‚àí1) ‚âà1
Ni
Ni

j=1

Y (i, j)
i
‚àíY (i, j)
i‚àí1

.
The resulting multilevel Monte Carlo estimate for E ( f (XT )) is then
Z N1,...,Nk =
k

i=1
1
Ni
Ni

j=1

Y (i, j)
i
‚àíY (i, j)
i‚àí1

.
(6.41)
Here, Y (i, j)
i
= f

X(ni,i, j)
T

and Y (i, j)
i‚àí1 = f

X(ni‚àí1,i, j)
T

where X(ni,i, j) and X(ni‚àí1,i, j)
are numerical solutions of the SDE with discretisation parameters ni and ni‚àí1,
respectively. The two solutions X(ni,i, j) and X(ni‚àí1,i, j) are both computed using the
same Brownian motion B(i, j). The Brownian motions B(i, j) for different (i, j) are
independent.
Algorithm 6.26
(multilevel Monte Carlo estimate)
input:
a function f
an SDE on the time interval t ‚àà[0, T ]
k ‚ààN, n1 < ¬∑ ¬∑ ¬∑ < nk and N1, . . . , Nk ‚ààN
randomness used:
independent Brownian paths B(i, j) for i = 1, . . . , k, j = 1, . . . , Ni
output:
an estimate for E ( f (XT )) where X solves the given SDE
1: s ‚Üê0
2: for i = 1, 2, . . . , k do
3:
si ‚Üê0

252
AN INTRODUCTION TO STATISTICAL COMPUTING
4:
for j = 1, 2, . . . , Ni do
5:
Generate a Brownian path B(i, j).
6:
Compute a solution (X(ni,i, j)
t
)t‚àà[0,T ] of the SDE, using discretisation
parameter ni and the Brownian path B(i, j).
7:
Y (i, j)
i
‚Üêf

X(ni,i, j)
T

8:
if i > 1 then
9:
Compute a solution (X(ni‚àí1,i, j)
t
)t‚àà[0,T ] of the SDE, using discretisation
parameter ni‚àí1 and the Brownian path B(i, j).
10:
Y (i, j)
i‚àí1 ‚Üêf

X(ni‚àí1,i, j)
T

11:
else
12:
Y (i, j)
i‚àí1 ‚Üê0
13:
end if
14:
si ‚Üêsi + Y (i, j)
i
‚àíY (i, j)
i‚àí1
15: end for
16: s ‚Üês + si/Ni
17: end for
18: return s
A convenient choice for the discretisation parameters ni in the algorithm is
ni = mi. Then X(ni,i, j) and X(ni‚àí1,i, j) can be simulated jointly, where X(ni,i, j) uses
time steps of length T/ni and m of these time steps together form one time step for
the simulation of X(ni‚àí1,i, j).
Lemma 6.27
The computational cost for obtaining the multilevel Monte Carlo
estimate Z N1,...,Nk from (6.41) is
C(N1, . . . , Nk) ‚àù
k

i=1
ni Ni.
The mean squared error of the estimate satisÔ¨Åes
MSE(Z N1,...,Nk) =
k

i=1
œÉ 2
i
Ni
+

e(nk)
weak( f )
2
,
where œÉ 2
i = Var(Yi ‚àíYi‚àí1) and e(nk)
weak( f ) is the weak error from (6.24) for discretisa-
tion parameter nk.
Proof
The statement about the computational cost follows from the fact that
the cost of simulating one path at level i is proportional to the discretisation
parameter ni.

CONTINUOUS-TIME MODELS
253
For the statement about the mean squared error we Ô¨Årst note that, by lemma 3.12,
the mean squared error of the estimate is
MSE(Z N1,...,Nk) = Var(Z N1,...,Nk) + bias(Z N1,...,Nk)2.
For the variance we Ô¨Ånd
Var(Z N1,...,Nk) =
k

i=1
1
N 2
i
Ni

j=1
Var

Y (i, j)
i
‚àíY (i, j)
i‚àí1

=
k

i=1
œÉ 2
i
Ni
and the bias is given by
bias(Z N1,...,Nk) = E

Z N1,...,Nk

‚àíE ( f (XT ))
=
k

i=1
1
Ni
Ni

j=1

E

Y (i, j)
i

‚àíE

Y (i, j)
i‚àí1

‚àíE ( f (XT ))
=
k

i=1
(E (Yi) ‚àíE (Yi‚àí1)) ‚àíE ( f (XT ))
= E

f (X(nk)
T
)

‚àíE ( f (XT )) .
Substituting the deÔ¨Ånition of e(nk)
weak( f ) completes the proof.
The parameters k ‚ààN and N1, . . . , Nk can be chosen to minimise the numerical
error for a given computational cost C. Since the weak error e(ni)
weak( f ) is independent
of the values N1, . . . , Nk, it sufÔ¨Åces to minimise
V (N1, . . . , Nk) =
k

i=1
œÉ 2
i
Ni
under the constraint of Ô¨Åxed cost C(N1, . . . , Nk) = C. For simplicity, we take
N1, . . . , Nk to be continuous variables. Then, using minimisation under constraints
(theorem 6.22), we Ô¨Ånd that the minimum satisÔ¨Åes the equations
0 = ‚àÇV
‚àÇNi
(N1, . . . , Nk) ‚àíŒª ‚àÇC
‚àÇNi
(N1, . . . , Nk) = ‚àíœÉ 2
i
N 2
i
‚àíŒªcni
fori = 1, 2, . . . , k, where Œª is the Lagrange multiplier. The solution of these equations
is
Ni ‚àº

œÉ 2
i /ni
(6.42)

254
AN INTRODUCTION TO STATISTICAL COMPUTING
for all i = 1, 2, . . . , k, where the common constant is chosen so that the condition
C(N1, . . . , Nk) = C is satisÔ¨Åed.
Since
Yi ‚àíYi‚àí1 =

f (X(ni)
T ) ‚àíf (XT )

‚àí

f (X(ni‚àí1)
T
) ‚àíf (XT )

,
the variances œÉ 2
i depend on the path-wise accuracy of the approximations X(ni)
T
and
X(ni‚àí1)
T
for XT (i.e. on the strong error of the numerical scheme for solving the SDE),
as well as on the regularity of the function f . For the Euler‚ÄìMaruyama scheme and
Lipschitz continuous f , one can show œÉ 2
i = O(1/ni).
Example 6.28
Let ni = mi for some m ‚ààN and assume œÉ 2
i ‚àº1/ni as well as
e(n)
weak ‚àº1/n. The condition on the weak error is, for example, satisÔ¨Åed for the Euler‚Äì
Maruyama scheme and the Milstein scheme. In this case, the optimality condition
(6.42) turns into Ni ‚àº1/ni.
For Œµ > 0, set
k ‚âàlog(Œµ‚àí1)
log(m)
and
Ni ‚àº
k
niŒµ2 .
Here, k is chosen in order to get a bias of order O(Œµ2) and the form of the sample
sizes Ni is dictated by (6.42). Then we have
k

i=1
œÉ 2
i
Ni
‚àº
k

i=1
1
ni
¬∑ niŒµ2
k
= Œµ2
and

e(nk)
weak( f )
2
‚àº1
n2
k
= m‚àí2k ‚âàexp

‚àí2log(Œµ‚àí1)
log(m) log(m)

= Œµ2
and thus, by lemma 6.27, the mean squared error satisÔ¨Åes
MSE(Z N1,...,Nk) ‚àºŒµ2,
On the other hand, the computational cost of the resulting estimate is
C(N1, . . . , Nk) ‚àº
k

i=1
ni Ni ‚àº
k

i=1
ni
k
niŒµ2 = k2
Œµ2 ‚àºlog(Œµ)2
Œµ2
.
Since log(Œµ)2 grows only very slowly as Œµ ‚Üì0, the cost of the method is nearly
O(1/Œµ2). For small values of Œµ, this computational cost will be much lower than the
cost O(1/Œµ3), from (6.34), for the basic Monte Carlo estimate with the same error.

CONTINUOUS-TIME MODELS
255
The results from this section suggest the following procedure for choosing the
parameters of a multilevel Monte Carlo method: Ô¨Årst, choose nk large enough that the
weak error of solutions with discretisation parameter nk is expected to be smaller than
the level of error we are willing to tolerate. Next, choose discretisation parameters
n1 < n2 < ¬∑ ¬∑ ¬∑ < nk for the intermediate levels. Normally, these value are chosen
so that ni ‚âàmni‚àí1 for all i and some constant m. Experiments (e.g. example 6.30)
indicate that it is best not to use too many intermediate levels. Finally, let Ni ‚âàL/ni
where the constant L ‚â•nk is chosen large enough to keep the Monte Carlo variance
of the samples small. The execution time of the program will be proportional to L,
the Monte Carlo variance will decay as 1/L.
6.6
Application to option pricing
In this section we illustrate the techniques from Chapter 6 with the help of an example
from Ô¨Ånancial mathematics. In the Heston model (Heston, 1993), the joint evolution
of a stock price St and of the corresponding volatility ‚àöVt at time t is described by a
system of two stochastic differential equations:
dSt = r St dt + St
‚àöVt dB(1)
t ,
dVt = Œª(œÉ 2 ‚àíVt) dt + Œæ‚àöVt

œÅ dB(1)
t
+

1 ‚àíœÅ2 dB(2)
t

.
(6.43)
Here, r ‚â•1 (the interest rate), Œª > 0, œÉ 2 > 0, Œæ > 0 and the correlation œÅ ‚àà(‚àí1, 1)
are Ô¨Åxed parameters and B(1) and B(2) are two independent Brownian motions. The
SDEs start at time t = 0 (assumed to be the current time) with given values S0 and
V0. Our aim is to numerically estimate the price of a call option with expiry time
T > 0 and strike price K > 0. This price is given by the expectation
C = E

e‚àírT max(ST ‚àíK, 0)

,
(6.44)
where ST is the solution of (6.43) at time T .
We start our analysis by rewriting (6.43) as a two-dimensional SDE. By
lemma 6.4, the process Bt = (B(1)
t , B(2)
t ) is a two-dimensional Brownian motion.
DeÔ¨Åning Xt = (St, Vt), we have
dX = Œº(Xt) dt + œÉ(Xt) dBt
with
Œº(x) =

rx1
Œª(œÉ 2 ‚àíx2)

and
œÉ(x) =
 x1
‚àöx2
0
œÅŒæ‚àöx2
(1 ‚àíœÅ2)Œæ‚àöx2


256
AN INTRODUCTION TO STATISTICAL COMPUTING
for all x ‚ààR2
+. Thus, the system (6.43) of SDEs Ô¨Åts into the framework discussed in
this chapter. To simulate solutions of this SDE numerically, we can use the Euler‚Äì
Maruyama scheme described in algorithm 6.12. Specialised to (6.43), the algorithm
has the following form.
Algorithm 6.29
(Euler‚ÄìMaruyama scheme for the Heston model)
input:
interest rate r ‚â•1
parameters Œª > 0, œÉ 2 > 0, Œæ > 0 and œÅ ‚àà(‚àí1, 1)
initial values S0, V0 > 0
time horizon T ‚â•0
discretisation parameter n ‚ààN
randomness used:
B( j)
i
‚àºN(0, h) i.i.d. for i = 0, . . . , n ‚àí1 and j ‚àà{1, 2}, where
h = T/n
output:
approximate solutions (S(n)
ih )i=0,...,n and (V (n)
ih )i=0,...,n to (6.43)
1: h ‚ÜêT/n
2: S(n)
0
‚ÜêS0
3: V (n)
0
‚ÜêV0
4: for i = 0, 1, . . . , n ‚àí1 do
5:
S(n)
(i+1)h ‚ÜêS(n)
ih + r S(n)
ih h + S(n)
ih

V (n)
ih B(1)
i
6:
V (n)
(i+1)h ‚ÜêV (n)
ih + Œª

œÉ 2 ‚àíV (n)
ih

h + Œæ

V (n)
ih

œÅB(1)
i
+

1 ‚àíœÅ2B(2)
i

6: end for
7: return (S(n)
ih )i=0,1,...,n and (V (n)
ih )i=0,1,...,n
This algorithm can easily be implemented on a computer. One problem with this
approach is that there is the possibility that the numerical approximations for S and
V may take negative values. Details of this problem are discussed near the end of
Section 6.4.4. Once negative values occur for Vt, the algorithm cannot continue since
the next iteration will involve computing the value ‚àöVt, which is not deÔ¨Åned for
Vt < 0. One solution to this problem is to replace

V (n)
ih with

|V (n)
ih | throughout the
algorithm. Then the solution for V can still take negative values, but the algorithm can
continue and due to the drift term the process V will return to positive values soon.
A pair (S, V ) of paths of a simulation using this algorithm is shown in Figure 6.13.
Now that we are able to simulate paths from the Heston model, our next aim
is to use these paths to estimate the expectation C from (6.44). For this task, we
employ Monte Carlo estimation as described in Section 6.5. Given a discretisation
parameter n and a Monte Carlo sample size N, the basic Monte Carlo estimate can
be computed as follows:
(a) Simulate solutions (S( j)
ih )i=0,1,...,n to (6.43) for j = 1, 2, . . . , N, indepen-
dently, using algorithm 6.29 with step size h = T/n.

CONTINUOUS-TIME MODELS
257
1 2 3 4 5 6 7
St
Vt
0
1
2
3
4
5
0
1
2
3
t
(a)
(b)
Figure 6.13
A pair (St, Vt) of paths from the Heston model (6.43). The evolution
of (a) the stock price St and (b) the instantaneous variance Vt is given by the
SDEs (6.43). The solutions were simulated using the Euler‚ÄìMaruyama scheme from
algorithm 6.29.
(b) Compute the estimate CMC for C as
CMC = 1
N
N

j=1
f

S( j)
T

,
where f (s) = e‚àírT max(s ‚àíK, 0) for all s ‚ààR.
As an example, the histogram in Figure 6.14 shows the distribution of 10000 samples
of S( j)
T . A Monte Carlo estimate for C can be obtained by applying f to each of these
samples and then averaging the results.
From Section 6.5.1 we know that the computational cost of computing CMC is
proportional to nN and the mean squared error satisÔ¨Åes
MSE(CMC) ‚âàœÉ 2
N 2 +

e(n)
weak( f )
2
,
(6.45)
where œÉ 2 = Var

f (S(n)
T )

and e(n)
weak( f ) is the weak error for the Euler‚ÄìMaruyama
discretisation with discretisation parameter n. From (6.33) we know that the optimal
balance of N and n is approximately to choose N ‚âàn2. While the weak error is
difÔ¨Åcult to determine, the mean squared Monte Carlo error œÉ 2/N 2 can be easily
estimated together with C, by taking the sample variance of the Monte Carlo sample.

258
AN INTRODUCTION TO STATISTICAL COMPUTING
ST
Density
0
2
4
6
8
10
12
0.0
0.1
0.2
0.3
0.4
Figure 6.14
A histogram showing the distribution of the stock price ST at time
T = 1, obtained by generating 10 000 samples with initial values S0 = 1, V0 = 0.16
and parameters r = 1.02, Œª = 1, œÉ = 0.5, Œæ = 1 and œÅ = ‚àí0.5.
In order to compute estimates faster or more accurately, we can use the variance
reduction methods from Section 6.5.2. As an example, here we consider the multi-
level Monte Carlo method (see Section 6.5.3). From lemma 6.27 we know that the
computational cost of this method is proportional to k
i=1 ni Ni and the mean squared
error of this method satisÔ¨Åes
MSE(ZMLMC) =
k

i=1
œÉ 2
i
Ni
+

e(nk)
weak( f )
2
,
(6.46)
where ni is the discretisation parameter on level i, Ni is the number of Monte Carlo
samples on level i and œÉ 2
i is the variance of these samples. From example 6.28 we
know that for the Euler method the optimal balance between Ni and ni is to choose
Ni proportional to 1/ni.
As for the mean squared error of the basic Monte Carlo estimate, the bias,
controlled by the weak error e(nk)
weak( f ), is difÔ¨Åcult to estimate while the Monte Carlo
variance k
i=1 œÉ 2
i /Ni can be estimated together with C at nearly no extra cost.
If the discretisation parameter n for the Monte Carlo estimate is the same as the
discretisation parameter nk for the Ô¨Ånest grid in the multilevel estimate, the two bias
terms in (6.45) and (6.46) are identical. Thus, for n = nk the difference in mean
squared error can easily be estimated numerically.
Example 6.30
We compare the Monte Carlo estimate with n = 256 and N = 2562
to different multilevel Monte Carlo estimates, with ni = mi. The multilevel estimates
we consider correspond to m = 2, m = 4 and m = 16. The corresponding numbers
of levels are chosen so that nk = n, that is we consider k = 8, k = 4 and k = 2.

CONTINUOUS-TIME MODELS
259
The Monte Carlo sample sizes Ni are taken to be Ni = L/ni, where L is chosen so
that the computation time for the corresponding multilevel estimate is close to the
computation time for the basic Monte Carlo estimate. The results are summarised as:
Method
m
Estimate
Error
Time
MC
‚Äî
0.1138
0.7965 ¬∑ 10‚àí6
1.000
MLMC
2
0.1137
1.1570 ¬∑ 10‚àí6
1.011
MLMC
4
0.1145
0.5315 ¬∑ 10‚àí6
1.004
MLMC
16
0.1133
0.4532 ¬∑ 10‚àí6
1.013
The column ‚ÄòTime‚Äô gives the computation time (measured CPU time), relative to
the time for the Monte Carlo estimate and ‚ÄòError‚Äô lists the Monte Carlo variance of
the estimate.
The table clearly shows that, in this example, the mean squared error for m = 4
and m = 16 is smaller than the mean squared error for the basic Monte Carlo estimate,
indicating that the estimate from these two methods will be more accurate than the
basic Monte Carlo estimate, while taking the same amount of time to compute. The
theory in Section 6.5.2 shows that the advantage of multilevel methods will become
more pronounced as n increases; for larger n, the multilevel method with m = 2 will
also become more accurate than the corresponding Monte Carlo method.
6.7
Summary and further reading
In this chapter we have discussed continuous-time stochastic processes, including
Brownian motion and the solutions of SDEs. Following the topics of interest for this
book, we have focused on computational aspects, leaving out most of the underlying
theory. Many texts about continuous-time stochastic processes are available to provide
more theoretical detail. Brownian motion is, for example, covered in Rogers and
Williams (2000), Karatzas and Shreve (1991) and, in great detail, in M¬®orters and
Peres (2010) and Borodin and Salminen (1996). SDEs are covered in textbooks
such as Mao (2007), Karatzas and Shreve (1991) and √òksendal (2003), numerical
methods are discussed in Kloeden and Platen (1999) and in the very accessible review
by Higham (2001).
In the second part of the chapter, simulation of continuous-time processes gave
the opportunity to review the Monte Carlo methods from Chapter 3 in a different
context: we considered both basic Monte Carlo estimates and the variance reduction
techiques from Section 3.3 for continuous-time models. Finally, we have studied the
multilevel Monte Carlo method which is well-adapted to the problem of computing
Monte Carlo estimates in the presence of discretisation errors. More details about
multilevel Monte Carlo estimates can be found in the publications by Giles (2008a,b).

260
AN INTRODUCTION TO STATISTICAL COMPUTING
Exercises
E6.1
Write a program to simulate the values of a one-dimensional Brownian
motion at times t1 < t2 < . . . < tn. Test your program by plotting the graph
of one path of a Brownian motion.
E6.2
Write a program to simulate a path of a two-dimensional Brownian motion.
Test your program by generating a plot of one such path, similar to the one
in Figure 6.2.
E6.3
Write a function which takes time t as an argument and computes the value
Bt of a Brownian path. Repeated calls to the function should return samples
for the same Brownian path.
E6.4
Write a program to sample paths of a one-dimensional Brownian bridge
between (r, a) and (t, b), where r < t are times and a, b ‚ààR.
E6.5
Write a program to simulate paths of a geometric Brownian motion X until a
time T > 0, for given parameters Œ±, Œ≤, initial value X0, and time horizon T .
Test your program by generating plots of X for different values of Œ± and Œ≤.
E6.6
Use Monte Carlo integration with a sample size of N = 106 to estimate the
expectation of Xt = exp(Bt ‚àít/2) for t ‚â•0. By experiment, determine the
range of t-values where this method results in reasonable estimates.
E6.7
Implement the Euler‚ÄìMaruyama scheme for computing an approximate solu-
tion of the SDE (6.17). Test your program by generating plots of solutions X
with drift
Œº(t, x1, x2) =

x2
x1(1 ‚àíx2
1)

and diffusion coefÔ¨Åcient
œÉ(t, x1, x2) = s(x1, x2)
1
0
0
1

where
s(x1, x2) =
	0.2
if x1, x2 > 0 and
0.03
otherwise.
E6.8
Implement the Milstein scheme for computing approximate solutions to
SDEs of the form (6.21). Test your program by simulating solutions of
dXt = 0.1 dt + Xt dB
with initial condition X0 = 1.

CONTINUOUS-TIME MODELS
261
E6.9
Implement a Monte Carlo method to estimate the strong error for the
Euler‚ÄìMaruyama and Milstein schemes, when simulating paths of a geo-
metric Brownian motion. Use the resulting program to recreate the plot in
Figure 6.8.
E6.10
Implement a program to use Monte Carlo estimation to estimate the
weak error of the Euler‚ÄìMaruyama and Milstein methods, as described in
example 6.19. Use your program to recreate the plot in Figure 6.9. Note, the
resulting program will probably take a long time to run!
E6.11
Use Monte Carlo estimation to estimate the probability that the solution X
of the SDE (6.29) exceeds the level c = 2.5 before time T = 5. Determine
the approximate root-mean squared error of your estimate.
E6.12
Use importance sampling to estimate the probability that the solution X of
the SDE (6.29) exceeds the level c = 2.5 before time T = 5. Determine an
approximate conÔ¨Ådence interval for the probability in question.
E6.13
Write a program to simulate paths (St)t‚àà[0,T ] and (Vt)t‚àà[0,T ] from the Heston
model (6.43).
E6.14
Write a program to compute Monte Carlo estimates for the price C
of a call option with expiry time T > 0 and strike price K > 0, where
the underlying stock is described by the Heston model (6.43).
Test your program by determining an estimate for C for the case where
S0 = 1 and V0 = 0.16, and where the parameters in the Heston model are
r = 1.02, Œª = 1, œÉ = 0.5, Œæ = 1 and œÅ = ‚àí0.5. Ignoring the bias, estimate
the mean squared Monte Carlo error of your estimate.
E6.15
Write a program to compute multilevel Monte Carlo estimates for the price C
of a call option with expiry time T > 0 and strike price K > 0, where the
underlying stock is described by the Heston model (6.43). Test your program
by comparing the result with the result from exercise E6.14.

Appendix A
Probability reminders
In this text we assume that the reader is familiar with the basic results of probability.
For reference, and to Ô¨Åx notation, this chapter summarises some important concepts
and results.
A.1
Events and probability
The basic objects in probability theory are events and random variables. Typically
events are denoted by capital letters such as A, B and C and we write P(A) for the
probability that an event A occurs. Random variables are typically denoted by upper
case letters such as X, Y, Z and they can take values either in the real numbers R, in
the Euclidean space Rd or even in more general spaces. Random variables are often
used to construct events; for example {X < 3} denotes the event that X takes a value
which is smaller than 3 and we write P(X < 3) for the probability of this event. If X
is a random variable taking values in some set, and if f is a function on this set, then
f (X) is again a random variable.
Each random variable has a distribution or probability distribution, which com-
pletely describes its probabilistic behaviour. Special probability distributions are
often designated by calligraphic upper case letters, sometimes with parameters given
in brackets, for example N(Œº, œÉ 2) for the normal distribution with mean Œº and
variance œÉ 2 or U[a, b] for the uniform distribution on the interval [a, b]. General
distributions are often designated by P or Œº. We write
X ‚àºP
to state that a random variable X has distribution P. For real-valued random variables,
the distribution can always be completely described by a distribution function.
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

264
APPENDIX A: PROBABILITY REMINDERS
DeÔ¨Ånition A.1
The cumulative distribution function (CDF) of a random variable
X on R is given by
F(a) = P(X ‚â§a)
for all a ‚ààR.
Often the CDF of a random variable is simply referred to as the ‚Äòdistribution func-
tion‚Äô, omitting the term ‚Äòcumulative‚Äô for brevity. Distribution functions are normally
denoted by capital letters such as F or FX (where the subscript denotes which ran-
dom variable this is the CDF of), occasionally Greek letters such as  are used. We
sometimes write X ‚àºF (slightly abusing notation) to indicate that the distribution
of X has distribution function F.
DeÔ¨Ånition A.2
A random variable X has probability density f , if
P

X ‚ààA

=

A
f (x) dx
(A.1)
for every set A.
Often the probability density of a random variable X is referred to just as the
density of X. While every random variable on R has a distribution function F, a
density f may or may not exist. If f exists, then it can be found as the derivative
of the CDF, that is f = F‚Ä≤. Probability densities are typically denoted by Roman or
Greek letters such as f, g, p, œï and œà.
One important property of probability densities is that they are not uniquely
deÔ¨Åned. If the density œï is only changed on sets which are small enough to not affect
the value of the integral in (A.1), for example in a Ô¨Ånite number of points, the changed
density will still describe the same distribution.
Example A.3
The uniform distribution U[0, 1] on the interval [0, 1] has density
f (x) =
1
if x ‚àà[0, 1] and
0
otherwise.
Since we can change f at individual points without changing the distribution, we can
equivalently use densities such as
Àúf (x) =
1
if x ‚àà(0, 1) and
0
otherwise
to describe the distribution U[0, 1]. The corresponding distribution function is
F(a) =
 a
‚àí‚àû
f (x) dx =
‚éß
‚é®
‚é©
0
if a < 0
a
if 0 ‚â§a < 1 and
1
otherwise.

APPENDIX A: PROBABILITY REMINDERS
265
Note that the CDF F is uniquely determined; we get the same result if we compute
F using the alternative density Àúf .
Example A.4
The standard normal distribution N(0, 1) has density
f (x) =
1
‚àö
2œÄ
e‚àíx2/2
and distribution function
F(x) =
1
‚àö
2œÄ
 x
‚àí‚àû
e‚àíy2/2 dy.
The integral in the CDF cannot be evaluated explicitly, but many programming
languages provide functions to evaluate F numerically.
Example A.5
The exponential distribution Exp(Œª) has density
f (x) =
Œªe‚àíŒªx
if x ‚â•0 and
0
if x < 0.
The distribution function is
F(x) =
1 ‚àíe‚àíŒªx
if x ‚â•0 and
0
if x < 0.
Example A.6
The value X ‚àà{1, 2, 3, 4, 5, 6} of a single dice throw has no density.
Its distribution function is
F(x) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
0
for x < 1
1/6
for 1 ‚â§x < 2
2/6
for 2 ‚â§x < 3
3/6
for 3 ‚â§x < 4
4/6
for 4 ‚â§x < 5
5/6
for 5 ‚â§x < 6 and
1
for 6 ‚â§x.
The most important properties of densities are given by the following charac-
terisation: a function f is a probability density if and only if it satisÔ¨Åes the two
properties:
(a) f ‚â•0; and
(b) f is integrable with

f (x) dx = 1.

266
APPENDIX A: PROBABILITY REMINDERS
Sometimes a density f is only known up to a constant Z, that is we know the function
g(x) = Z f (x) for all x, but we do not know f and the value of Z. In these cases, the
second property listed can be used to Ô¨Ånd Z: if we let
Z = Z

f (x) dx =

Z f (x) dx =

g(x) dx,
then
f (x) = 1
Z g(x)
is a probability density. In this context, Z is called the normalisation constant for the
unnormalized density g.
DeÔ¨Ånition A.7
Two random variables X and Y are independent of each other if
P(X ‚ààA, Y ‚ààB) = P(X ‚ààA)P(Y ‚ààB)
for all sets A and B. More generally, random variables X1, . . . , Xn are independent
if
P

Xi ‚ààAi for i = 1, . . . , n

=
n
i=1
P(Xi ‚ààAi)
for all sets A1, . . . , An.
If the random variable Xi has density fi for i = 1, 2, . . . , n, then we can charac-
terise independence of the Xi via their densities: X1, . . . , Xn are independent if and
only if the joint density f of X1, . . . , Xn is of the form
f (x1, . . . , xn) =
n
i=1
f (xi).
A.2
Conditional probability
The conditional probability of an event A, given another event B with P(B) > 0, is
deÔ¨Åned as
P(A|B) = P

A ‚à©B

P(B)
,
(A.2)

APPENDIX A: PROBABILITY REMINDERS
267
where P

A ‚à©B

is the probability that both A and B occur simultaneously. The
same relation multiplied by P(B) is known as Bayes‚Äô rule:
P

A ‚à©B

= P(A|B)P(B).
(A.3)
Often, the event and condition in a conditional probability concern the distribution
of a random variable X: if P(X ‚ààB) > 0 we can consider P(X ‚ààA|X ‚ààB). For
Ô¨Åxed B, the conditional distribution PX|X‚ààB of X given X ‚ààB, deÔ¨Åned by
PX|X‚ààB(A) = P(X ‚ààA|X ‚ààB),
(A.4)
is itself a probability distribution.
The random variable X here can take values on an arbitrary space. By taking X to
be a vector, X = (X1, X2) ‚ààR2 say, and by choosing A = A1 √ó R and B = R √ó B2,
we get
P(X ‚ààA|X ‚ààB) = P(X1 ‚ààA1|X2 ‚ààB2).
Using this idea, results such as proposition 1.26 can also be applied to the distribution
of a random variable X, conditioned on the values of a different random variable Y.
If the pair (X, Y) ‚ààRm √ó Rn has a joint density f (x, y), it is also possible to
consider X conditioned on the event Y = y. Since the event Y = y has probability 0,
deÔ¨Ånition (A.2) can no longer be used; instead, one deÔ¨Ånes the conditional density
of X given Y = y as
fX|Y(x|y) =
 f (x,y)
fY (y)
if fY(y) > 0 and
œÄ(x)
otherwise,
(A.5)
where
fY(y) =

f (Àúx, y) d Àúx
is the density of Y and œÄ is an arbitrary probability density. The choice of œÄ in the
deÔ¨Ånition does not matter, since it is used only for the case fY(y) = 0, that is when
conditioning on cases which never occur. The function fX|Y(x|y) deÔ¨Åned in this way
satisÔ¨Åes

fX|Y(x|y) dx = 1
for all y and

A

B
fX|Y(x|y) fY(y) dy dx =

A

B
f (x, y) dy dx = P(X ‚ààA, Y ‚ààB).

268
APPENDIX A: PROBABILITY REMINDERS
The latter relation is the analogue of Bayes‚Äô rule (A.3) for conditional densities.
A.3
Expectation
Real-valued random variables X often (but not always) have an expectation, which
we denote by E(X). If X only takes Ô¨Ånitely many values, say x1, . . . , xn, then the
expectation of X is given by
E(X) =
n

i=1
xi P(X = xi).
If the distribution of X has a density f , the expectation of X can be computed as
E(X) =

x f (x) dx.
Similarly, if œï is a function, the expectation of the random variable œï(X) can be
computed as
E

œï(X)

=

œï(x) f (x) dx.
(A.6)
In cases where the integral on the right-hand side can be solved explicitly, this formula
allows expectations to be computed analytically.
Probabilities of events involving X can be rewritten as expectations using the
indicator function of the event: the indicator function of the event {X ‚ààA} is the
random variable 1A(X) given by
1A(x) =
1
if x ‚ààA and
0
otherwise.
(A.7)
Using the deÔ¨Ånition of the expectation, we Ô¨Ånd
E(1A(X)) = 1 ¬∑ P(X ‚ààA) + 0 ¬∑ P(X /‚ààA) = P(X ‚ààA)
and from (A.6) we get
P(X ‚ààA) = E

1A(X)

=

1A(x) f (x) dx,
where f is the density of X. Similarly, if œï(X) is a function of X, we have
P

œï(X) ‚ààA

= E

1A

œï(X)

=

1A

œï(x)

f (x) dx.
(A.8)

APPENDIX A: PROBABILITY REMINDERS
269
A.4
Limit theorems
In this section we cite, for reference, two well-known limit theorems which all Monte
Carlo methods rely on heavily: the law of large numbers and the central limit theorem.
The strong law of large numbers allows to approximate an expectation by the
average of a large i.i.d. sample. This approximation forms the basis of the Monte
Carlo methods discussed in Chapter 3.
Theorem A.8
(strong law of large numbers). Let (Xn)n‚ààN be a sequence of i.i.d.
random variables with expectation Œº. Then
lim
n‚Üí‚àû
1
n
n

i=1
Xi = Œº
with probability 1.
This theorem is due to Kolmogorov and it can be found in most textbooks about
probability, for example as theorem 20.2 in Jacod and Protter (2000) or as 4.3S in
Williams (2001).
From the law of large numbers we know that
1
n
n

i=1

Xi ‚àíŒº

‚àí‚Üí0
as n ‚Üí‚àû. The central limit theorem, given below, is a reÔ¨Ånement of this result: it
describes the Ô¨Çuctuations around this limit. The central limit theorem can for example
be used to analyse the error of numerical methods based on the law of large numbers.
Theorem A.9
(central limit theorem). Let (Xn)n‚ààN be a sequence of independent
random variables with expectation Œº and Ô¨Ånite variance œÉ 2 > 0. Then we have
1
‚àön
n

i=1

Xi ‚àíŒº

d
‚àí‚àí‚ÜíN(0, œÉ 2),
(A.9)
where
d
‚àí‚àí‚Üídenotes convergence in law.
In the central limit theorem, the ‚Äòconvergence in law‚Äô in equation (A.9) is equiv-
alent to the statement
P
 1
‚àön
n

i=1

Xi ‚àíŒº

‚àà[a, b]

‚àí‚Üí
1
‚àö
2œÄœÉ 2
 b
a
exp

‚àíx2
2œÉ 2

dx

270
APPENDIX A: PROBABILITY REMINDERS
as n ‚Üí‚àûfor all a, b ‚ààR with a ‚â§b. Again, this result can be found in most
textbooks about probability, for example as theorem 21.1 in Jacod and Protter (2000)
or in Section 5.4 of Williams (2001).
A.5
Further reading
A concise and rigorous exposition of basic probability is given in Jacod and Protter
(2000). A longer introduction, with a view towards applications in statistics, can be
found in Williams (2001) and a classical text is the book by Feller (1968).

Appendix B
Programming in R
This appendix contains a short introduction to programming with the R program-
ming language (R Development Core Team, 2011). R can be downloaded from the
R homepage at http://www.r-project.org/ and there are many online tutorials
available which describe how to install and use the R system. Therefore, we assume
that the reader has access to a working R installation and already knows how start the
program and how to use the built-in help system. The presentation here will focus on
aspects of the language which are relevant for statistical computing.
B.1
General advice
One of the most important points to understand when learning to program is the
distinction between learning to program and learning a programming language.
Learning to program involves understanding how to approach and structure a problem
in order to turn it into an algorithm which a computer can execute. This process often
requires that the problem is rephrased or broken down into smaller subproblems.
Becoming a proÔ¨Åcient programmer is a slow process which requires a lot of practice
and which can take a long time. In contrast, once you already know how to program,
learning a new programming language is relatively easy. Typically this just requires
learning a small number (normally much less than 100) of commands and rules.
This appendix gives an introduction to both, the basics of programming and of the
programming language R.
While it may be possible to learn the mathematical contents of this book just by
reading and understanding the text, programming can only be learned by practising
a lot (just like learning to juggle or learning to play a musical instrument). One of
the main reasons for this is that attention to detail is crucially important in computer
programming. While a typo in a mathematical argument will normally just make the
argument a bit more difÔ¨Åcult to follow, a single typo in a computer program will
typically cause the program to abort with an error or to return nonsensical results.
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

272
APPENDIX B: PROGRAMMING IN R
The text includes numerous exercises which allow you to practise your program-
ming skills. Another way to train your programming skills is to read and understand
other people‚Äôs programs; but only after you have written the corresponding program
yourself! For this purpose, the text includes answers for all of the exercises. But,
again, it is not possible to learn to program by just reading programs (just as it is
impossible to become a good violinist only by watching other people play the violin),
so it is important that you try the exercises yourself before looking at the answers.
Finally, and as already remarked, learning to program takes a long time, so make sure
that you commit enough time to learning and practising.
B.2
R as a Calculator
In this section we discuss basic use of R and introduce some fundamental concepts.
Many of the topics discussed here will be covered in more detail in the following
sections.
You interact with the R system by entering textual commands, and the system
then reacts on these commands. A simple example of a command is
3 + 4
This command asks R to add the numbers 3 and 4, the result 7 is printed to the screen.
After you try the above command in R, you should see the following two lines:
> 3 + 4
[1] 7
Your command is preceded by > and the result is preceded by [1]. We use this
distinction throughout the appendix: listings starting with the character > show both
your commands and the resulting output. Listings not starting with the character >
only show the commands without giving the output. You can (and should!) always
run the commands yourself to see the result.
An example of a more complicated command is
plot(c(1,2,3,4), c(5,2,1,6), xlab="x", ylab="y", type="o")
(B.1)
Try this example yourself! If everything worked, a graph such as the one in Figure B.1
will appear on the screen.
R processes commands one at a time. Commands can be split over more than one
line, for example a plot command could look as follows:
plot(c(1,2,3,4), c(5,2,1,6), type="o",
xlab="really long label for the x-axis", ylab="y")
When you enter this command into R, nothing will happen when you enter the Ô¨Årst
line (since R notices that the Ô¨Årst bracket is not yet closed, so the command cannot be

APPENDIX B: PROGRAMMING IN R
273
‚óè
‚óè
‚óè
‚óè
1.0
1.5
2.0
2.5
3.0
3.5
4.0
1
2
3
4
5
6
x
y
Figure B.1
The graph generated by the command in listing (B.1). The circles cor-
respond to the x and y coordinates provided in the command, the axis labels are as
speciÔ¨Åed.
complete). Only after the command is completed by the second line, the plot appears.
For programming, we need to split the solution to a problem into steps which are
small enough that each step can be performed in a single command.
B.2.1
Mathematical operations
Some of the simplest commands available are the ones which correspond directly
to mathematical operations. In the Ô¨Årst example of this section, we could just type
3 + 4 to compute the corresponding sum. Table B.1 lists the R equivalent of the most
important mathematical operations.
B.2.2
Variables
In R you can use variables to store intermediate results of computations. The following
transscript illustrates the use of variables:
> a <- 1
> b <- 7
> c <- 2
> root1 <- (-b + sqrt(b^2 - 4*a*c)) / (2*a)
> root2 <- (-b - sqrt(b^2 - 4*a*c)) / (2*a)
> root1
[1] -0.2984379
> root2
[1] -6.701562
> root1*root2
[1] 2

274
APPENDIX B: PROGRAMMING IN R
Table B.1
List of some commonly used mathematical operations in R.
Operation
Example
R code
Addition
8 + 3
8 + 3
Subtraction
8 ‚àí3
8 - 3
Multiplication
8 ¬∑ 3
8 * 3
Division
8/3
8 / 3
Power
83
8 ^ 3
Modulus
8 mod 3
8 %% 3
Absolute value
|x|
abs(x)
Square root
‚àöx
sqrt(x)
Exponential
ex
exp(x)
Natural logarithm
log(x)
log(x)
Sine
sin(2œÄx)
sin(2 * pi * x)
Cosine
cos(2œÄx)
cos(2 * pi * x)
You can freely choose names for your variables, consisting of letters, digits and the
dot character (but starting with a letter), and you can assign values to variables using
the assignment operator <-. After a value is assigned to a variable, the name of the
variable can be used as a shorthand for the assigned value.
Since variable names in R cannot contain accented or greek characters, some
creativity is required when translating a mathematical formula into R code: instead
of Xk we could, for example, write Xk and instead of ÀúŒ± we could, for example, write
alpha.tilde.
There is a subtle difference between the use of variables in mathematics and in
programming. While in mathematics expressions like x = x + 1 are not very useful,
the corresponding expression x <- x+1 in R has a useful meaning:
> x <- 6
> x <- x + 1
> x
[1] 7
What happens here is that in the assignment x <- x+1, the right-hand side x + 1
is evaluated Ô¨Årst: by the rules for the use of variables, x is replaced by its value 6,
and then 6 + 1 is evaluated to 7. Once the value to be assigned is determined, this
value (the 7) is assigned to x. Consequently, the effect of the command x <- x+1 is
to increase the value stored in the variable x by 1.
An alternative notation for assigning a value to a variable in R is using the operator
=. The R statements x <- 1 and x = 1 are equivalent. To avoid confusion with the
equality sign from mathematics, we use the <- operator to assign values to variables
throughout. One consequence of the fact that <- indicates an assignment, that is some

APPENDIX B: PROGRAMMING IN R
275
action the computer will perform, is that the order of commands can matter when
assignments are involved:
x <- 3
y <- x + 1
sets x to 3 and y to 4, whereas
y <- x + 1
x <- 3
also sets x to 3 but sets y to whatever value x previously had, plus 1. If the value of
x has not been previously set, an error message to this effect will be shown when the
line y <- x + 1 is executed.
The main use of variables is to store data and results of computations for later
reference. This has several advantages: Ô¨Årst, once a value is stored, the variable name
can be used to refer to this value, potentially saving much typing and making the
program shorter. If a descriptive name is chosen for the variable, this can also make
the intention of a command much clearer to human readers. Secondly, if the result of
a time-consuming computation is stored in a variable, the result from the variable can
be reused without performing the computation again. Thus, sometimes the speed of
a program can be greatly improved by storing results in variables instead of redoing
the same computation over and over again.
B.2.3
Data types
Every object in R represents one of a handful of possible ‚Äòdata types‚Äô. In the examples
above we have already seen numbers and strings (short for ‚Äòcharacter strings‚Äô).
B.2.3.1
Numbers
The basic data type in R are numbers. Most of the time, numbers in R programs are
written in the same way as that used in mathematics, but there are a few aspects to
be aware of. These mostly relate to very small or very large numbers.
A special notation is used in R (and in many other programming languages) to
denote multiplication with a power of 10: the R code xey, where x and y are ordinary
numbers, stands for x ¬∑ 10y. Thus, 1e6 is a shorthand notation for one million and
1.3e-5 stands for 0.000013. The number before the symbol e is allowed to be a
decimal fraction, but the number after the e must be an integer. This notation is
widely used and R uses it, for example, when it needs to print very large or very
small numbers. For example the output of the following command tells us that e100
is approximately equal to 2.69 ¬∑ 1043:
> exp(100)
[1] 2.688117e+43

276
APPENDIX B: PROGRAMMING IN R
An important issue to keep in mind is the fact that R, like any programming
language, has only limited precision when storing numbers: the internal representation
of a number may be affected by truncation error, slightly changing the value of the
number stored. As a result, very small positive numbers are rounded to 0 in the
internal representation, and very large values are represented as ‚àû:
> exp(-10000)
[1] 0
> exp(10000)
[1] Inf
The number system in R can explicitly represent the numbers +‚àûand ‚àí‚àû. The
corresponding symbols in R are Inf and -Inf.
Truncation error in particular causes problems in situations where two large but
nearly equal values are subtracted and nearly cancel. For example, if we subtract 1015
from 1015 + 0.2 in R, we do not get the expected result 0.2, but 0.25 instead.
> (1e15 + 0.2) - 1e15
[1] 0.25
Similar problems can occur when very small, but approximately equal, positive
numbers are divided. This type of cancellation can, for example, be encountered when
evaluating the acceptance probability (4.3) of a Metropolis-Hastings algorithm. The
best solution to problems caused by such cancellations is to rewrite the underlying
mathematical expressions so that the cancellations in the program no longer occur. For
the problem of evaluating the acceptance probability (4.3), this approach is illustrated
in equation (4.19).
Finally, the special value NaN, short for ‚Äònot a number‚Äô, is used to represent the
outcome of calculation where the result is not mathematically deÔ¨Åned.
> 0 / 0
[1] NaN
> log(-1)
[1] NaN
B.2.3.2
Vectors
Vector objects in R are useful to represent mathematical vectors in a program; they can
also be used as a way to store data for later processing. An easy way to create vector
objects is the function c (short for ‚Äòconcatenate‚Äô) which collects all its arguments into
a vector. The vector
x =
‚éõ
‚éù
1
2
3
‚éû
‚é†

APPENDIX B: PROGRAMMING IN R
277
can be represented in R as follows:
> c(1, 2, 3)
[1] 1 2 3
The elements of a vector can be accessed by using square brackets: if x is a vector,
x[1] is the Ô¨Årst element, x[2] the second element and so on:
> x <- c(7, 6, 5, 4)
> x[1]
[1] 7
> x[1] + x[2]
[1] 13
> x[1] <- 99
> x
[1] 99
6
5
4
The function c can also be used to append elements to the end of an existing vector,
thus increasing its length:
> x <- c(1, 2, 3)
> x <- c(x, 4)
> x
[1] 1 2 3 4
In addition to the function c, there are several ways of constructing vectors: one
can start with an empty vector and add elements one-by-one:
> x <- c()
> x[1] <- 1
> x[2] <- 1
> x[3] <- x[2] + x[1]
> x[4] <- x[3] + x[2]
> x
[1] 1 1 2 3
Vectors consisting of consecutive, increasing numbers can be created using the colon
operator:
> 1:15
[1]
1
2
3
4
5
6
7
8
9 10 11 12 13 14 15
> 10:20
[1] 10 11 12 13 14 15 16 17 18 19 20

278
APPENDIX B: PROGRAMMING IN R
More complicated vectors can be generated using the function seq:
> seq(from=1, to=15, by=2)
[1]
1
3
5
7
9 11 13 15
> seq(from=15, to=1, by=-2)
[1] 15 13 11
9
7
5
3
1
Vectors in R programs are mostly used to store data sets, but they can also be used
to store the components of mathematical vectors, that is of elements of the space Rd.
Mathematical operations on vectors work as expected:
> c(1, 2, 3) * 2
[1] 2 4 6
> c(1, 2, 3) + c(3, 2, 1)
[1] 4 4 4
Other useful functions on vectors include sum (to compute the sum of the vector
elements), mean (the average), var (the sample variance), sd (the sample standard
deviation), and length (the length of the vector):
> x <- c(1, 2, 3)
> (x[1] + x[2] + x[3]) / 3
[1] 2
> sum(x) / length(x)
[1] 2
> mean(x)
[1] 2
The operators and functions from Table B.1, when applied to a vector, operate on
the individual elements:
> x <- c(-1, 0, 1, 2, 3)
> abs(x)
[1] 1 0 1 2 3
> x^2
[1] 1 0 1 4 9
This allows to efÔ¨Åciently operate on a whole data set with a single instruction.
B.2.3.3
Matrices
Matrices can be constructed in R using the function matrix. To represent the matrix
A =
 1
2
3
4
5
6


APPENDIX B: PROGRAMMING IN R
279
in R, the following command can be used:
> A <- matrix(c(1, 2, 3,
+
4, 5, 6),
+
nrow=2, ncol=3, byrow=TRUE)
> A
[,1] [,2] [,3]
[1,]
1
2
3
[2,]
4
5
6
The Ô¨Årst argument to matrix is a vector giving the numbers to be stored in the matrix.
The following two arguments set the number of rows/columns of the matrix, and the
last argument states that we gave the entries row-by-row. The whole command can be
given on one line, the line breaks are only inserted to increase readability. The n √ó n
identity matrix can be generated by diag(n) and an m √ó n zero matrix by matrix(0,
nrow=m, ncol=n).
Individual elements of a matrix can be accessed using square brackets, just as
for vectors: if A is a matrix, A[1,1] denotes the top-left element of the matrix, A[1,]
denotes the Ô¨Årst row of the matrix (as a vector), and A[,1] denotes the Ô¨Årst column
of A:
> A <- matrix(c(1,2,3,4), nrow=2, ncol=2, byrow=TRUE)
> A[1,1] <- 9
> A
[,1] [,2]
[1,]
9
2
[2,]
3
4
> A[1,]
[1]
9 2
> A[,1]
[1]
9 3
For complicated matrices it is sometimes useful to Ô¨Årst create an empty matrix,
and then use a short program to Ô¨Åll in the values. This can be achieved by using
a command such as matrix(nrow=m, ncol=n), without specifying values for the
matrix elements:
> A <- matrix(nrow=2, ncol=10)
> A
[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
[2,]
NA
NA
NA
NA
NA
NA
NA
NA
NA
NA
> A[1,] <- 1
> A[2,] <- 1:10
> A

280
APPENDIX B: PROGRAMMING IN R
[,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]
1
1
1
1
1
1
1
1
1
1
[2,]
1
2
3
4
5
6
7
8
9
10
The entries of the empty matrix are originally displayed as NA (for ‚Äònot available‚Äô),
and we have to assign values to the elements of A before the matrix can be used.
The sum of matrices and the product of a matrix with a number can be computed
using + and *, the matrix-matrix and matrix-vector products from linear algebra are
given by %*%. (Note, A * A is not the matrix product, but the element-wise product!)
> A <- matrix(c(1, 2,
+
2, 3),
+
nrow=2, ncol=2, byrow=TRUE)
> A
[,1] [,2]
[1,]
1
2
[2,]
2
3
> A %*% A
[,1] [,2]
[1,]
5
8
[2,]
8
13
> x <- c(0, 1)
> A %*% x
[,1]
[1,]
2
[2,]
3
> x %*% A %*% x
[,1]
[1,]
3
The last command shows that vectors are automatically interpreted as row vectors
or column vectors as needed: in R it is not required to transpose the vector x when
evaluating expressions such as x‚ä§Ax.
Many matrix operations are available, for example the transpose of a matrix A can
be computed using t(A), the inverse by solve(A), the functions rowSums and colSums
return the row and column sums as vectors, and rowMeans and colMeans return the
row and column averages, respectively. The solution x to a system Ax = b of linear
equations can be computed using the command solve(A, b).
B.2.3.4
Strings
Strings are used in R to represent short texts, represented as a sequence of characters.
Strings are used, for example, to specify the text used for the axis labels in a plot.
Strings in R are enclosed in quotation marks.

APPENDIX B: PROGRAMMING IN R
281
Sometimes a bit of care is needed when using strings: the string "12" represents
the text consisting of the digits one and two; this is different from the number 12:
> 12 + 1
[1] 13
> "12" + "1"
Error in "12" + "1" : non-numeric argument to binary operator
R complains that it cannot add "12" and "1", because these values are not numbers.
Strings can be stored in variables just as for numbers and the function paste can
be used to concatenate strings:
> s <- paste("this", "is", "a", "test")
> paste(s, ": ", "a", "bra", "ca", "da", "bra", sep="")
[1] "this is a test: abracadabra"
> paste("x=", 12, sep="")
[1] "x=12"
The argument sep for the function paste speciÔ¨Åes a ‚Äòseparator‚Äô which is put between
the individual strings. The default value is a single space character. If the arguments
of paste are not strings, they are converted to a string before the concatenation:
> paste("x=", 12, sep="")
[1] "x=12"
B.2.3.5
Truth values
To represent truth values (also known as boolean values), R uses the special values
TRUE and FALSE. The shorthand versions T for TRUE and F for FALSE can also be used.
Truth values are most commonly encountered as the results of comparisons, using
the operators from Table B.2:
> 1 < 2
[1] TRUE
> 3 < 2
[1] FALSE
Truth values can be stored in variables:
> result <- 1 < 2
> result
[1] TRUE
When used in a context where a numeric value is expected, truth values are
automatically converted to numbers: TRUE is interpreted as 1 and FALSE is interpreted
as 0. This behaviour is, for example, useful to count how many elements of a list

282
APPENDIX B: PROGRAMMING IN R
Table B.2
List of comparison operators in R. The values
textttx and y can be replaced by arbitrary numeric expressions,
the result of the comparison is either TRUE or FALSE.
Comparison
Example
R code
Strictly smaller
x < y
x < y
Smaller or equal
x ‚â§y
x <= y
Strictly bigger
x > y
x > y
Bigger or equal
x ‚â•y
x >= y
Equal
x = y
x == y
Not equal
x Ã∏= y
x != y
satisfy a given condition; adding the truth values using sum gives the number of TRUE
entries in a vector of booleans:
> x <- rnorm(10)
> x
[1] -1.1497316
0.9251614 0.2357447 0.7422293
1.8712479
[6] -0.7683445 -0.4054793 0.9313800 1.1917342 -0.7275102
> x > 0
[1] FALSE TRUE TRUE TRUE TRUE FALSE FALSE TRUE TRUE FALSE
> sum(x > 0)
[1] 6
B.3
Programming principles
In the previous section we have seen many examples of R commands. An R program
is a sequence of commands, designed to solve a speciÔ¨Åc problem when executed
in order. As an example, consider the Fibonacci sequence deÔ¨Åned by x1 = x2 = 1
and xk = xk‚àí1 + xk‚àí2 for all n > 2. The following commands form an R program to
compute x6:
x <- c()
x[1] <- 1
x[2] <- 1
x[3] <- x[2] + x[1]
x[4] <- x[3] + x[2]
x[5] <- x[4] + x[3]
x[6] <- x[5] + x[4]
cat("the 6th Fibonacci number is", x[6], "\n")
(B.2)

APPENDIX B: PROGRAMMING IN R
283
When these commands are executed in R, one after another, the last command prints
‚Äòthe 6th Fibonacci number is 8‚Äô to the screen (the \n starts a new line in the
output). While this program works, it still has a number of shortcomings which we
will address in the following sections.
B.3.1
Don‚Äôt repeat yourself!
A fundamental principle in programming is to avoid duplication wherever possible.
This principle applies on many different levels and in many different situations. It is
sometimes called the don‚Äôt repeat yourself (DRY) principle. In this section we will
discuss some aspects of the DRY principle, using the program (B.2) as an example.
B.3.1.1
Loops
The way we compute x[6] in the program (B.2) involves a lot of repetition: to
represent the equation xn = xn‚àí1 + xn‚àí2, we used four different lines in our program!
Because of this, it will be impractical to use a similar program to compute x[100]. A
second problem is that it can be difÔ¨Åcult to spot mistakes caused by this repetition.
Another complication appears if we want to modify the program to use the
equation xn = xn‚àí1 ‚àíxn‚àí2 instead: a single change to the mathematical formula
requires multiple changes to our program.
The problem of this speciÔ¨Åc repetition can be solved using a ‚Äòloop‚Äô in the R
program. Such a loop instructs R to execute a command repeatedly. We can use such
a loop to write the command for the relation xk = xk‚àí1 + xk‚àí2 only once, and then
let R repeat this command as needed:
n <- 10
x <- c()
x[1] <- 1
x[2] <- 1
for (k in 3:n) {
x[k] <- x[k-1] + x[k-2]
}
cat("the ", n, "th Fibonacci number is ", x[n], "\n", sep="")
(B.3)
The loop is implemented by the for statement: for is followed by a group of one or
more commands, enclosed in curly brackets { and }, which are executed repeatedly.
The number of repetitions is determined by the vector 3:n, the commands are executed
once for each element of this vector, that is n ‚àí2 times in total. The variable k is set
to the corresponding element of the vector before each iteration starts: the Ô¨Årst time
the loop is executed, k is set to 3. The executed statement is then x[3] <- x[3-1] +
x[3-2]. Before the next iteration, k is set to 4 and, after substituting k, the executed
statement is x[4] <- x[4-1] + x[4-2]. This is repeated until, in the last iteration of
the loop, k is set to the value of n. Once the loop is completed, the program continues
with the Ô¨Årst instruction after the loop and the program outputs ‚Äòthe 10th Fibonacci
number is 55‚Äô.

284
APPENDIX B: PROGRAMMING IN R
The choice of the name k for the loop variable in the example above was arbitrary
(it was chosen to match the index in the mathematical formula), any other variable
name could have been used instead. Similarly, the vector 3:n can be replaced by any
other vector, the elements are not required to be adjacent or increasing.
A further improvement of this program, compared with the Ô¨Årst version, is the
introduction of the variable n: with the new program, we can compute a different
Fibonacci number by changing only a single line. Similarly, if we want to implement
a different recursion relation, we can just replace the command x[k] <- x[k-1] +
x[k-2] with a different one. By avoiding repetition in the program text, mistakes
such as the one in exercise EB.5 where the required change to the output string was
forgotten, are no longer possible.
There is a second kind of loop available, the while loop, which can be used when
the required number of iterations is not known in advance. For example, the following
program determines the Ô¨Årst Fibonacci number which is bigger than or equal to 1000:
x <- c()
x[1] <- 1
x[2] <- 1
n <- 2
while (x[n] < 1000) {
n <- n + 1
x[n] <- x[n-1] + x[n-2]
}
cat("the ", n, "th Fibonacci number is ", x[n], "\n", sep="")
The while loop repeats its commands while the condition in the round brackets is
satisÔ¨Åed. In the condition, all the usual comparison operators can be used (Table B.2).
For this type of loop, no automatic assignment to a loop variable takes place, so we
have to increment n ourselves using the command n <- n + 1. As soon as the
condition is false, the loop ends and the program continues with the Ô¨Årst command
after the loop.
B.3.1.2
Conditional statements
Inside loops it is often useful to be able to execute different commands in different
iterations of the loop. For example, to print all numbers n = 1, 2, . . . , 100 satisfying
sin(n) > 1
2 to the screen, we can use the following program:
for (n in 1:100) {
if (sin(n) > 0.5) {
cat(n, "\n")
}
}
The if statement is followed by a block of one or more commands, enclosed in curly
brackets { and }. These commands are only executed if the condition given inside

APPENDIX B: PROGRAMMING IN R
285
the round brackets is true, otherwise the whole if block has no effect. As with the
while statement, all the usual comparison operators (Table B.2) can be used in the
condition. There is a second form of the if statement:
for (n in 1:10) {
if (n %% 2 == 1) {
cat(n, "is odd\n")
} else {
cat(n, "is even\n")
}
}
(B.4)
Here, the commands in the Ô¨Årst block of curly brackets are executed if the condi-
tion is true, and otherwise the commands in the second block are executed. Since
n mod 2 equals 0 for even numbers and 1 for odd numbers, this program gives the
correct output.
Finally, for cases where a result is computed using one of two alternative formulas,
the ifelse statement can be used. Using ifelse, the loop from listing (B.4) can be
rewritten as follows:
for (n in 1:10) {
cat(n, ifelse(n %% 2 == 1, "is odd", "is even"), "\n")
}
The Ô¨Årst argument of ifelse must be a truth value which determines which of the
following two values should be used: if the Ô¨Årst argument is true, the result is taken
from the second argument, otherwise it is taken from the third argument. While the
ifelse function can always be replaced by an if statement, use of ifelse sometimes
allows to simplify programs.
B.3.1.3
Command scripts
The DRY principle applies also to repetition between different programs: if you have
solved a problem once, it is better to reuse the old program, instead of writing a new
one. Reuse of old programs does not only avoid unnecessary work, it also reduces
the risk of mistakes being introduced in the code and allows to improve the program
over time. To facilitate this, the following guidelines are useful:
r Save all your R programs in Ô¨Åles (Ô¨Åle names for such Ô¨Åles typically end in .R),
store these Ô¨Åles somewhere safe, and keep the programs organised in a way
which allows you to Ô¨Ånd them again when needed at a later time.
r When writing programs, take care to write them in a way which makes the
code reusable. As we have seen, the DRY principle can help with this. Also, it
is useful to write the program as clearly as possible, to use descriptive names

286
APPENDIX B: PROGRAMMING IN R
for your variables, and to use indentation to make the structure of loops and if
statements easy to follow.
r If the program uses any nonobvious constructions or clever tricks, it is often
helpful to add comments with explanations to the program. Such comments
can be very helpful when trying to reuse programs written more than a few
weeks ago. Since R ignores every line of input which starts with the character
#, such comments can be stored directly in the program. For example, when
reading the (slightly cryptic) program
# compute Fibonacci numbers x[n]
# y = (x[n], x[n-1])
y <- c(1,1)
for (n in 3:17) {
y <- c(sum(y), y[1])
}
print(y[1])
the comments make it a lot easier to Ô¨Ågure out what the program does.
B.3.2
Divide and conquer!
In this section we will discuss a second fundamental programming principle, some-
times called the ‚Äòdivide and conquer paradigm‚Äô. This principle is to break down a
problem into smaller subproblems which can be solved individually. After solving the
individual subproblems, the individual solutions can be combined to obtain a solution
to the full problem. As for the DRY principle discussed above, the divide and conquer
principle applies on many different levels and in many different situations. In this
text we will focus on the most basic aspects of this principle.
The basic tool for isolating individual building blocks of a program is a ‚Äòfunction‚Äô
which allows to use a simple name as an abbreviation for a list of commands. We
will illustrate the concept of functions in R with the help of examples.
Example B.1
The program from listing (B.3) can be turned into an R function as
follows:
fibonacci <- function(n) {
x <- c()
x[1] <- 1
x[2] <- 1
for (k in 3:n) {
x[k] <- x[k-1] + x[k-2]
}
return(x[n])
}
(B.5)

APPENDIX B: PROGRAMMING IN R
287
When we execute the above lines in R, nothing seems to happen. The commands only
deÔ¨Åne the name fibonacci as an abbreviation for the commands on the following
lines, the commands are not yet executed. This step of assigning a name to the
function is referred to as ‚ÄòdeÔ¨Åning the function‚Äô.
After the function is deÔ¨Åned, we can execute the commands in the function by
using the assigned name fibonacci:
> fibonacci(5)
[1] 5
> res <- fibonacci(10)
> res
[1] 55
(B.6)
This step is referred to as ‚Äòcalling the function‚Äô. The second call to fibonacci shows
that we can assign the result of a function call to a variable and thus store it for
later use.
The Ô¨Årst line of listing (B.5) not only gives the name of the function but also,
in the brackets after the keyword function, it indicates that the function has exactly
one argument, called n. Every time the function is called, we have to specify a value
for this argument n, for the Ô¨Årst call of fibonacci in (B.6) we write fibonacci(5)
to indicate that the value 5 should be used for n, for the second call n equals 10.
The next six lines in listing (B.5), copied from listing (B.3), then compute the Ô¨Årst n
elements of the Fibonacci sequence, and the return statement indicates the result of
the computation and ends the function.
Example B.2
The R equivalent of a mathematical function is often straightforward
to implement. For example, to deÔ¨Åne an R function for computing the value of
f (x) = e‚àíx2,
for a given x, we can use the following R code:
f <- function(x) {
return(exp(-x^2))
}
The idea of a function like fibonacci in listing (B.5) is that, following the DRY
principle, we write the function only once; from then on we can use the function
by calling it without having to think about the details of how Fibonacci numbers
are computed. The function can be used as one of the building blocks for a bigger
program, alongside the built-in R functions such as sqrt and plot.
To allow for easy reuse of existing functions, some of the effect of commands
inside the function is hidden from the caller: while the variables n and x are used and

288
APPENDIX B: PROGRAMMING IN R
modiÔ¨Åed inside the function, R takes care not to disturb any variables which may be
used by the caller:
> n <- 3
> fibonacci(10)
[1] 55
> n
[1] 3
> x
Error: object ‚Äôx‚Äô not found
As we can see, the assignment n=10 used inside fibonacci does not affect the
value 3 we stored in n before the call and, similarly, the variable x used inside
the function is not visible to the caller. This isolation of the variables inside the
function is the reason that we need to use return to pass the result of a function to
the caller.
Sometimes, it is required to pass several argument values into a function. For
example, the built-in function rnorm to generate normally distributed random vari-
ables could be deÔ¨Åned as follows:
rnorm <- function(n, mean, sd) {
# code for generating random numbers
...
}
This declares three arguments: n speciÔ¨Åes how many random numbers should be
generated, mean speciÔ¨Åes the mean, and sd speciÔ¨Åes the standard deviation. We can
use the command rnorm(10, 0, 1) to get 10 standard normally distributed random
variables. Since the special case of mean 0 and standard deviation 1 is very common,
these value are used as ‚Äòdefault values‚Äô. The true declaration of rnorm is
rnorm <- function(n, mean=0, sd=1) {
...
}
The mean=0 tells R to use 0 for the mean, if no other value is given, and similarly for
the standard deviation. Thus, rnorm(10, 5) generates 10 random values with mean 5
(since we speciÔ¨Åed the mean in the second argument), and standard deviation 1 (the
default value is used because we did not give a third argument).
When calling a function which uses default values for some or all of its arguments,
and if we want to specify only some of the arguments, we can give values for individual
function arguments as in the following example:
X <- rnorm(10, sd=3)

APPENDIX B: PROGRAMMING IN R
289
This will generate 10 values from a normal distribution with mean 0 (the default
value is used because we did not specify this argument) and standard deviation 3 (as
speciÔ¨Åed by sd=3).
Example B.3
Consider the following function:
test <- function(a=1, b=2, c=3, d=4) {
cat("a=", a, ", b=", b, ", c=", c, ", d=", d, "\n", sep="")
}
When experimenting with this function, we get the following output:
> test()
a=1, b=2, c=3, d=4
> test(5, 6)
a=5, b=6, c=3, d=4
> test(a=5, d=6)
a=5, b=2, c=3, d=6
> n <- 3
> test(a=n, b=n+1, c=n+2, d=n+3)
a=3, b=4, c=5, d=6
As we have seen, functions can be used to encapsulate parts of your program as a
single unit. Functions help to follow both the ‚Äòdivide and conquer‚Äô principle (because
they allow to easily break down a program into smaller building blocks) and the
DRY principle (because they are easily reused). We conclude this section with some
general guidelines for writing functions:
r Sometimes there is a choice about which parts of a program could be split into
functions. A good idea in such situations is to aim for functions whose purpose
is easily explained: ‚Äòcompute the nth Fibonacci number‚Äô is a task which will
make a good function. In contrast, it seems less clear whether implementing a
formula such as:
xn =
xn‚àí1/2
if xn‚àí1 is even and
3xn‚àí1 + 1
if xn‚àí1 is odd
(B.7)
in a function is a good idea: the description of this function will likely be as
long as the function itself, and reuse of the resulting function seems not very
likely.
r Using descriptive names for functions is a good idea. Examples of well-chosen
function names include mean, sin and plot; in all three cases it is easy to guess
from the name what the function will do.

290
APPENDIX B: PROGRAMMING IN R
r The ‚Äòdivide and conquer‚Äô principle becomes most powerful when functions
make use of previously deÔ¨Åned functions which implement more fundamental
building blocks. The extreme case of this is when the deÔ¨Ånition of a function
includes calls to itself (for example when sorting of a list of length n is
reduced to the problem of sorting lists of length n ‚àí1); this technique is called
‚Äòrecursion‚Äô.
B.3.3
Test your code!
The Ô¨Ånal programming principle we will discuss in this text is the importance of
testing programs: even for experienced programmers, it is almost impossible to get a
non-trivial program right at the Ô¨Årst attempt. Thus, the usual procedure is to complete
a program bit by bit (following the approach in the previous section), and every time
a part of the program is completed to systematically test for the presence of errors.
There are different kinds of errors which can occur in computer programs:
(a) ‚ÄòSyntax errors‚Äô are errors caused by not following the restrictions and require-
ments of the programming language. In this case, R does not understand the
program at all and complains immediately with an error message. Examples
include excess commas and brackets:
> mean(c(1,2,,3))
Error in c(1, 2, , 3) : argument 3 is empty
> mean(c(1,2,3)))
Error: unexpected ‚Äô)‚Äô in "mean(c(1,2,3)))"
Normally, the cause of these errors can be spotted immediately, and the
problem is usually easy to resolve by following the hints given in the error
message.
(b) ‚ÄòRun-time errors‚Äô occur when the program is syntactically correct, but when
R encounters an operation which cannot be performed during the execution
of the program. Examples include programs which try to compute the sample
variance of an empty data set. In this case, the program is stopped immediately
and an error message is printed:
> print.var <- function(x) {
+
cat("the variance is", var(x), "\n")
+ }
> print.var(c(1,2,3))
the variance is 1
> print.var(c())
Error in var(x) : ‚Äôx‚Äô is NULL
This kind of error is often more difÔ¨Åcult to detect and Ô¨Åx, because the error
may not occur in every run of the program and because it may be difÔ¨Åcult to
Ô¨Ånd the exact location of the error in the program.

APPENDIX B: PROGRAMMING IN R
291
‚ÄòArithmetic errors‚Äô are special cases of run-time errors, where the pro-
gram tries to evaluate expressions like 0/0 or to compute the square root
of a negative number. In these cases, R just sets the result to NaN (short
for ‚Äònot a number‚Äô) and sometimes (but not always) produces a warning
message:
> 0/0
[1] NaN
> 2/2 + 1/1 + 0/0
[1] NaN
> sqrt(-1)
[1] NaN
Warning message:
In sqrt(-1) : NaNs produced
(c) ‚ÄòSemantic errors‚Äô are the errors caused by a program being a valid program,
but one which does not implement the intended algorithm. These errors
are cases where the program does what you told it to do instead of what
you meant it to do. Such errors can be very difÔ¨Åcult to spot and Ô¨Åx. As a
simple example, consider the following function for computing the mean of
a vector:
# something is wrong here!
average <- function(x) {
n <- length(x)
s <- sum(x)
return(x/n)
}
(B.8)
This function does not work as intended (since the return statement erro-
neously uses x instead of s), but there is no error message. The best way to
Ô¨Ånd this mistake is to test the function by trying to call it.
Errors in programs are sometimes called ‚Äòbugs‚Äô, and the process of locating
and Ô¨Åxing errors in a program is called ‚Äòdebugging‚Äô. There are various aspects to
debugging:
r A good start is to try the code in question for a few cases where the correct
result is known. Make sure to try some boundary cases (such as very short data
sets) as well as some typical cases. Test each function of a program separately,
starting with the most fundamental ones.
r Carefully look out for any error messages or warnings. These messages often
contain useful hints about what went wrong.
r To locate the position of an error, it is often helpful to temporarily insert a
print or cat statement into a program to check whether the program actually

292
APPENDIX B: PROGRAMMING IN R
executes certain lines of code and to see whether variables at these locations
still have the expected values.
r The functions debug and undebug can be used to watch the execution of a func-
tionstepbystep.SeetheRhelptextfor debug [obtainedbytyping help(debug)]
for usage instructions.
Example B.4
Assume we want to debug the function average given in listing (B.8).
The Ô¨Årst step is to try a few values:
> average(c(1, 2, 3))
[1] 0.3333333 0.6666667 1.0000000
Since the mean of (1, 2, 3) is 2, we see immediately that something is wrong. Assum-
ing that we do not spot the typo yet, we can try to modify the function by inserting a
cat statement as follows:
average <- function(x) {
n <- length(x)
s <- sum(x)
cat("n =", n, " s =", s, "\n")
return(x/n)
}
If we rerun the function, we now get the following output:
> average(c(1, 2, 3))
n = 3
s = 6
[1] 0.3333333 0.6666667 1.0000000
Since the printed values are what we expect (the list has length n = 3, and the sum of
the elements should be s = 1 + 2 + 3 = 6), we know that the mistake must be after
the cat statement. Thus, we have narrowed down the location of the problem to a
single line (the return statement), and looking at this line it is now easy to spot that
x should be replaced with s.
B.4
Random number generation
R contains an extensive set of built-in functions for generating (pseudo-)random
numbers of many of the standard probability distributions. There are also functions
available to compute densities, CDFs and quantiles of these distributions. Since these
functions will be used extensively for the exercises in the main text, we give a short
introduction here.

APPENDIX B: PROGRAMMING IN R
293
Table B.3
Some probability distributions supported by R.
Distribution
Name in R
Binomial distribution
binom
œá2 distribution
chisq
Exponential distribution
exp
Gamma distribution
gamma
Normal distribution
norm
Poisson distribution
pois
Uniform distribution
unif
The names of all these functions are constructed using the following scheme: the
Ô¨Årst letter is
r
for random number generators,
d
for densities (weights for the discrete case),
p
for the CDFs and
q
for quantiles.
The rest of the name determines the distribution; some possible distributions are
given in Table B.3.
Example B.5
The function to generate normal distributed random numbers is rnorm
and the density of the exponential distribution is dexp.
The functions starting with r, examples include runif and rnorm, can be used
to generate random numbers. The Ô¨Årst argument for each of these functions is the
number n of random values required; the output is a vector of length n. The following
arguments give parameters of the underlying distribution; often these arguments have
the most commonly used parameter values as their default values. Details about how
to use these functions and how to set the distribution parameters can be found in the R
online help. Finally, the function set.seed is available to set the seed of the random
number generator (see the discussion in section 1.1.3).
Example B.6
A vector of 10 independent, standard normally distributed random
numbers can be obtained using the command rnorm(10). A single sample from a
N(2, 9) distribution can be obtained using rnorm(1, 2, 3), where the last argument
gives the standard deviation (not the variance) of the distribution.
An exception to the naming scheme for random number generators is the discrete
uniform distribution: a sample X1, . . . , Xn ‚àºU{1, 2, . . . , a} can be generated with
the R command sample.int(a, n, replace=TRUE).

294
APPENDIX B: PROGRAMMING IN R
B.5
Summary and further reading
The best way to learn programming is to gain a lot of practice. For this reason, I
recommend trying to solve as many of the exercises provided in this text as possi-
ble. Other interesting sources of programming challenges can be found online, for
example on the web page of Project Euler.1
An extensive introduction to all aspects of R can be found online in Venables et al.
(2011). A more in-depth description can be found in Venables and Ripley (2000).
R source code for many of the methods discussed here can be found in Rizzo (2008).
Information about speciÔ¨Åc R functions can be found using the built-in help system
(accessed using the function help).
Exercises
EB.1
Use R to compute the following values:
(a)
1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10
(b)
216
(c)
2100
(d)
2
1 +
‚àö
5
EB.2
What are the values of x and y after the following commands are executed
in R?
x <- 1
y <- 2
x <- x + y
y <- x + y
EB.3
Use R to compute the value of 1 + 2 + ¬∑ ¬∑ ¬∑ + 100.
EB.4
Write an R function to compute the sample excess kurtosis
g2 =
1
n
	n
i=1(xi ‚àí¬Øx)4

 1
n
	n
i=1(xi ‚àí¬Øx)22 ‚àí3,
for a given vector x = (x1, . . . , xn), where ¬Øx is the average of the elements
of x.
1 Available from http://projecteuler.net/.

APPENDIX B: PROGRAMMING IN R
295
EB.5
The following code is an extension of the program from listing (B.2),
changed to compute the Fibbonacci numbers until x[8] (instead of x[6]).
x <- c()
x[1] <- 1
x[2] <- 1
x[3] <- x[2] + x[1]
x[4] <- x[3] + x[2]
x[6] <- x[5] + x[4]
x[7] <- x[6] + x[5]
x[8] <- x[7] + x[6]
cat("the 6th Fibonacci number is", x[8], "\n")
Can you spot the mistake?
EB.6
Let x0 = 0 and xn = cos(xn‚àí1) for all n ‚ààN. Use R to compute the value of
x20.
EB.7
Write an R program which uses a for loop to print the elements of the
decreasing sequence 100, 99, . . . , 0 to the screen, one per line.
EB.8
Write an R program which uses a while loop to determine the smallest
square number bigger than 5000.
EB.9
Write an R program which uses a while loop to determine the biggest square
number smaller than 5000.
EB.10
Given x0 ‚ààN, a sequence (xn)n‚ààN of integers can be deÔ¨Åned by equation
(B.7). Once this sequence reaches 1, it starts to cycle through the values
3 ¬∑ 1 + 1 = 4, 4/2 = 2, and 2/2 = 1, but it is unknown whether this cycle
is reached from every starting point x0. Write an R program which prints
the values of xn, starting with x0 = 27. The program should stop when the
value 1 is reached for the Ô¨Årst time.
EB.11
What does the following function compute?
f <- function(x) {
n <- length(x)
m <- mean(x)
s <- 0
for (i in 1:n) {
s <- s + (x[i] - m)^2
}
return(s/(n-1))
}
EB.12
Continuing example B.3, feed the following commands into R:
test <- function(a=1, b=2, c=3, d=4) {
cat("a=", a, ", b=", b, ", c=", c, ", d=", d, "\n", sep="")
}

296
APPENDIX B: PROGRAMMING IN R
b <- "a"
test(c=b)
Explain the result R prints to the screen.
EB.13
Section B.3.3 introduces three categories of programming errors. Which
categories do the two (!) errors from exercise EB.5 fall into?
EB.14
When trying to solve exercise E3.7, one could try to implement the function
ÀÜœÅ(X, Y) from equation (3.23) as follows:
# something is wrong here!
rxy <- function(X,Y) {
mX <- mean(X)
mY <- mean(Y)
numerator <- sum((X - mX) * (Y - mY))
denominator <- sqrt(sum(X-mX)^2 * sum(Y-mY)^2)
return(numerator / denominator)
}
When testing this function, we quickly discover that something must be
wrong:
> X <- c(1.6, -1.1, -1.2)
> Y <- c(0.1, 0.2, 0.1)
> rxy(X, Y)
[1] -Inf
One can check that ‚àí1 ‚â§ÀÜœÅ(X, Y) ‚â§1, so the value ‚àí‚àûclearly cannot be
the correct result! Use the techniques explained in section B.3.3 to Ô¨Ånd the
mistake.
EB.15
The following function is a (failed) attempt to compute
n‚àí1

i=1
(xi+1 ‚àíxi)2,
that is the sum of squared increments, in R:
SomethingWrong <- function(x) {
n <- length(x)
sum <- 0
for (i in 1:n-1) {
sum <- sum + (x[i+1] - x[i])^2
}
return(sum)
}

APPENDIX B: PROGRAMMING IN R
297
When we apply this function to the vector (1, 2, 3), we do not get the correct
answer 2, but numeric(0) instead.
> SomethingWrong(c(1,2,3))
numeric(0)
What is the mistake in the function SomethingWrong?
EB.16
Use R to create plots of the densities and CDFs of the following distributions:
(a)
N(0, 1) ‚Äî the standard normal distribution;
(b)
N(3, 4) ‚Äî the normal distribution with mean Œº = 3 and variance
œÉ 2 = 4;
(c)
Exp(1) ‚Äî the exponential distribution with rate 1;
(d)
(9, 0.5) ‚Äî the gamma distribution with shape parameter k = 9 and
scale parameter Œ∏ = 0.5.

Appendix C
Answers to the exercises
This appendix contains solutions to the exercises found throughout the book. Most
of the answers require use of a computer. Any programs used in the solutions here
are written using the R programming language (R Development Core Team, 2011);
of course, similar solutions can be written in different programming languages. For
reference, a short introduction to programming in R can be found in Appendix B.
All R programs used for this book, both to generate the Ô¨Ågures and for the
answers of the exercises, can be downloaded from the accompanying web page at
www.wiley.com/go/statistical computing
C.1
Answers for Chapter 1
Solution E1.1
To implement the LCG in R, we can execute the commands from
algorithm 1.2 in a loop.
LCG <- function(n, m, a, c, X0) {
X <- numeric(length=n)
Xn <- X0
for (i in 1:n) {
Xn <- (a*Xn + c) %% m
X[i] <- Xn
}
return(X)
}
The resulting function LCG can be called as follows:
> LCG(10, 8, 5, 1, 0)
[1] 1 6 7 4 5 2 3 0 1 6
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

300
APPENDIX C: ANSWERS TO THE EXERCISES
The output matches the manually computed result from Example 1.3, so we can
assume that the program is correct.
Solution E1.2
Using the function LCG from exercise E1.1, we can generate the
graphs as follows:
par(mfrow=c(2,2))
X <- runif(1000)
plot(X[1:999], X[2:1000], asp=1, cex=.5,
xlab=expression(X[i]), ylab=expression(X[i+1]))
m <- 81
a <- 1
c <- 8
seed <- 0
X <- LCG(1000, m, a, c, seed)/m
plot(X[1:999], X[2:1000], asp=1, cex=.5,
xlab=expression(X[i]), ylab=expression(X[i+1]))
m <- 1024
a <- 401
c <- 101
seed <- 0
X <- LCG(1000, m, a, c, seed)/m
plot(X[1:999], X[2:1000], asp=1, cex=.5,
xlab=expression(X[i]), ylab=expression(X[i+1]))
m <- 2^32
a <- 1664525
c <- 1013904223
seed <- 0
X <- LCG(1000, m, a, c, seed)/m
plot(X[1:999], X[2:1000], asp=1, cex=.5,
xlab=expression(X[i]), ylab=expression(X[i+1]))
The output is shown in Figure 1.1.
Solution E1.3
(a) There are different approaches to picking out the middle two digits of a
number. One method is to use algebraic operations:
middle.square <- function (x) {
square <- x^2
middle <- floor(square / 10) %% 100
return(middle);
}

APPENDIX C: ANSWERS TO THE EXERCISES
301
Another method is to convert between numbers and strings:
middle.square2 <- function(x) {
square <- x^2
padded <- formatC(square, width=4, flag="0")
middle <- substring(padded, 2, 3)
return(as.numeric(middle))
}
(b) The easiest method to Ô¨Ånd a loop is to generate elements of the sequence Xn,
until a previously seen element is reached:
find.loop <- function (start) {
seen <- c()
# follow the sequence until it runs back into itself
x <- start
while (! is.element(x, seen)) {
seen <- c(seen, x)
x <- middle.square(x)
}
# get the complete loop
loop <- c(x)
y <- middle.square(x)
while (y != x) {
loop <- c(loop, y)
y <- middle.square(y)
}
return(loop)
}
Using this function, we can systematically look for loops:
all.loops <- c()
for (x in 0:99) {
loop <- find.loop(x)
# To see whether we‚Äôve found this loop already,
# we keep track of the smallest element in each loop.
smallest <- min(loop)
if (! is.element(smallest, all.loops)) {
cat("found a loop: ", loop, "\n");
all.loops <- c(all.loops, smallest)
}
}

302
APPENDIX C: ANSWERS TO THE EXERCISES
This program generates the following output:
found a loop:
0
found a loop:
10
found a loop:
60
found a loop:
24 57
found a loop:
50
The function middle.square is illustrated in Figure C.1.
(c) Figure C.1 shows that the output starts repeating itself after at most 15 steps
and that all loops are very short (length 1 or 2). Therefore, the method forms
a rather poor PRNG.
42
69
34
66
76
15
35
65
85
26
86
94
79
50
24
83
88
74
47
99
53
49
80
97
40
98
51
60
20
57
39
23
59
67
22
89
77
92
48
48
46
31
63
30
70
90
96
11
87
81
56
12
21
38
10
44
54
91
71
93
58
37
19
41
16
25
68
75
36
27
61
82
64
28
33
78
9
72
43
29
62
7
71
84
18
73
8
6
95
55
45
32
5
4
1
2
3
0
14
13
Figure C.1
The transition graph of the middle square method for two-digit numbers.

APPENDIX C: ANSWERS TO THE EXERCISES
303
Solution E1.4
The Ô¨Årst step in solving this question is to Ô¨Ånd the CDF of the given
distribution. For x < 1 we have f (x) = 0 and thus F(x) = 0. For x ‚â•1 we have
f (x) = 1/x2 and thus
F(a) =
 a
1
1
x2 dx =

‚àí1
x

a
x=1 = 1
1 ‚àí1
a = 1 ‚àí1
a .
Next, we have to Ô¨Ånd the inverse of F. Since F is continuous, we can just compute
the ordinary inverse:
u = F(x) = 1 ‚àí1
x
‚áê‚áí
1
x = 1 ‚àíu
‚áê‚áí
x =
1
1 ‚àíu .
By proposition 1.14, if U ‚àºU[0, 1], then X = 1/(1 ‚àíU) has density f . The result-
ing method can be implemented in R as follows:
GenerateSample <- function(n) {
U <- runif(n)
return(1/(1-U))
}
To generate a histogram of 10 000 values, we can then use the following
commands:
X <- GenerateSample(10000)
hist(X, freq=FALSE, breaks=seq(0, max(X)+1, 0.1),
xlim=c(0,10), ylim=c(0,1),
main=NULL, col="gray80", border="gray20")
Some care is needed, because X occasionally takes very big values:
> summary(X)
Min.
1st Qu.
Median
Mean
3rd Qu.
Max.
1.000
1.336
1.971
8.073
3.899 2746.000
To make the histogram useful we have to choose sufÔ¨Åciently narrow bars (using the
breaks argument) and to restrict the displayed horizontal coordinate range (using
the xlim argument). Also, since we want to compare the output with the density,
we have to switch to a density plot instead of a frequency plot (using the argument
freq=FALSE). The density can be added to the plot using the lines command:
x <- seq(0, 10, 0.01)
f <- ifelse(x <= 1, 0, 1/x^2)
lines(x, f, lw=1)
The resulting plot is shown in Figure C.2. The plot shows a good match between the
density function and the histogram.

304
APPENDIX C: ANSWERS TO THE EXERCISES
X
Density
0
2
4
6
8
10
0.0
0.2
0.4
0.6
0.8
1.0
Figure C.2
A histogram of 10 000 samples from the distribution given in exer-
cise E1.4, together with the corresponding density function (solid line).
Solution E1.5
Let Yn = 1, if the proposal Xn is accepted and Yn = 0 otherwise.
Then we can write Kn = n
i=1 Yi. From equation (1.4) in the proof of proposition
1.20 we know that each of the proposals is accepted with probability Z and thus we
have
E(Yn) = 1 ¬∑ P(Yn = 1) + 0 ¬∑ P(Yn = 0) = Z
for all n ‚ààN. Finally, by the strong law of large numbers (theorem A.8), we Ô¨Ånd
lim
n‚Üí‚àû
1
n Kn = lim
n‚Üí‚àû
1
n
n

i=1
Yi = E(Y1) = Z.
This completes the proof.
Solution E1.6
We can implement the rejection algorithm as follows:
f <- function(x) {
return((x> 0) * 2 * dnorm(x,0,1))
}
g <- function(x) { return(dexp(x,1)) }
c <- sqrt(2 * exp(1) / pi)
rhalfnormal <- function(n) {
res <- numeric(length=n)
i <- 0

APPENDIX C: ANSWERS TO THE EXERCISES
305
X
Density
0
1
2
3
0.0
0.2
0.4
0.6
0.8
1.0
Figure C.3
A histogram of the output of the algorithm from exercise E1.6. The
histogram is generated from 10 000 samples from the half-normal distribution. For
comparison, the solid line gives the exact density from equation (1.5).
while (i<n) {
U <- runif(1, 0, 1)
X <- rexp(1, 1)
if (c * g(X) * U <= f(X)) {
i <- i+1
res[i] <- X;
}
}
return(res)
}
To test the function rhalfnormal, we generate a histogram as follows:
X <- rhalfnormal(10000)
hist(X, breaks=50, prob=TRUE, ylim=c(0,1),
main=NULL, col="gray80", border="gray20")
curve(f, min(X), max(X), n=500,
ylim=c(0,1), ylab="f", add=TRUE)
The output of this program is shown in Figure C.3.
Solution E1.7
In this question we are asked to construct a rejection algorithm to
convert the Exp(Œª)-distributed proposal into N(0, 1)-distributed samples. We con-
struct the algorithm in two steps: Ô¨Årst we generate half-normal distributed samples
with density
f (x) =
2
‚àö
2œÄœÉ 2 exp

‚àíx2
2œÉ 2


306
APPENDIX C: ANSWERS TO THE EXERCISES
for all x ‚â•0. Since the corresponding samples are positive, we can use the density
of the Exp(Œª)-distribution, that is
g(x) = Œª exp (‚àíŒªx)
for all x ‚â•0 as the proposal density. In a second step, we then attach a random sign
to get the full normal distribution.
For the rejection sampling algorithm, we need to Ô¨Ånd a constant c with
f (x)
‚â§
c ¬∑ g(x)
‚áê‚áí
2
‚àö
2œÄœÉ 2 exp

‚àíx2
2œÉ 2

‚â§c ¬∑ Œª exp (‚àíŒªx)
‚áê‚áí
2
Œª
‚àö
2œÄœÉ 2 exp

‚àíx2
2œÉ 2 + Œªx

‚â§c
‚áê‚áí
2
Œª
‚àö
2œÄœÉ 2 exp

‚àí1
2œÉ 2 (x ‚àíŒªœÉ 2)2

exp

Œª2œÉ 2/2
	
‚â§c
for all x ‚ààR. Since (x ‚àíŒªœÉ 2)2 ‚â•0, this condition is satisÔ¨Åed for all values of c with
c ‚â•
2
Œª
‚àö
2œÄœÉ 2 exp

Œª2œÉ 2/2
	
.
Since the method is most efÔ¨Åcient for small values of c, the best choice is to choose
c equal to this bound. The resulting acceptance condition is
c ¬∑ g (X)U ‚â§f (X)
‚áê‚áí
2
Œª
‚àö
2œÄœÉ 2 exp

Œª2œÉ 4	
Œª exp (‚àíŒªx) U ‚â§
2
‚àö
2œÄœÉ 2 exp

‚àíx2
2œÉ 2

‚áê‚áí
U ‚â§exp

‚àí1
2œÉ 2 (x ‚àíŒªœÉ 2)2

.
This leads to the following algorithm:
(a) Generate X ‚àºExp(Œª).
(b) Generate U ‚àºU[0, 1].
(c) Accept X if U ‚â§exp

‚àí(X ‚àíŒªœÉ 2)2/2œÉ 2	
, otherwise reject X.
(d) For accepted samples, return ‚àíX or X randomly, each with probability 1/2.
We can optimise the method by choosing the value of Œª which minimises
c(Œª) = 2 exp

Œª2œÉ 2/2
	
Œª
‚àö
2œÄœÉ 2
.

APPENDIX C: ANSWERS TO THE EXERCISES
307
Setting the derivative of c(Œª) equal to zero, we Ô¨Ånd the following necessary condition
for an extremum:
0 = c‚Ä≤(Œª)
=
2
‚àö
2œÄœÉ 2 ¬∑ ŒªœÉ 2 exp

Œª2œÉ 2/2
	
¬∑ Œª ‚àí1 ¬∑ exp

Œª2œÉ 2/2
	
Œª2
=

Œª2œÉ 2 ‚àí1
	 2 exp

‚àíŒª2œÉ 4	
Œª2‚àö
2œÄœÉ 2
.
This condition is only satisÔ¨Åed for Œª = Œª‚àó= 1/œÉ and, since c(Œª) converges to ‚àûfor
Œª ‚Üì0 and Œª ‚Üí‚àû, the value Œª‚àóis a minimum of c(Œª). Thus, the optimal value of Œª
is Œª‚àóand the corresponding, optimal value of c is
c(Œª‚àó) = œÉ 2 exp(1/2)
‚àö
2œÄœÉ 2
=

2e
œÄ ‚âà1.315.
This shows that, when the algorithm is optimally tuned, we need on average 1.315
proposals to generate one output sample.
Solution E1.8
Since the proposals are Exp(1)-distributed, the proposal density is
given by
g(x) = exp(‚àíx)
and we need to Ô¨Ånd a constant c > 0 with f (x) ‚â§cg(x) for all x ‚â•0. We have
f (x)
‚â§
c ¬∑ g(x)
‚áê‚áí
1
‚àöx exp

‚àíy2/2x ‚àíx
	
‚â§c exp(‚àíx)
‚áê‚áí
1
‚àöx exp

‚àíy2/2x
	
‚â§c,
for all x ‚â•0 and thus we need to Ô¨Ånd the maximum of the left-hand side of this
equation. Setting the derivative equal to zero, gives the condition
0 =
 1
‚àöx exp

‚àíy2/2x
	‚Ä≤
=
y2
2x2 exp(‚àíy2/2x)‚àöx ‚àí
1
2‚àöx exp(‚àíy2/2x)
x
=
 y2
x ‚àí1
 exp(‚àíy2/2x)
2x3/2
,

308
APPENDIX C: ANSWERS TO THE EXERCISES
which is satisÔ¨Åed for x = y2; it is easy to check that this value corresponds to a
maximum. Thus, the optimal choice for c is
c =
1

y2 exp

‚àíy2/2y2	
= 1
|y| exp(‚àí1/2).
This is the required result.
Solution E1.9
The inequality c ‚â•1 follows from
1 =

f (x) dx ‚â§

cg(x) dx = c

g(x) dx = c.
Now assume c = 1. Then we have f ‚â§g. For Œµ > 0 let AŒµ =

x
 f (x) ‚â§g(x) ‚àíŒµ

.
Then we have
1 =

f (x) dx =

AŒµ
f (x) dx +

A‚àÅŒµ
f (x) dx
‚â§

AŒµ
(g(x) ‚àíŒµ) dx +

A‚àÅŒµ
g(x) dx =

g(x) dx ‚àíŒµ|AŒµ| = 1 ‚àíŒµ|AŒµ|
and thus Œµ|AŒµ| ‚â§0. Since Œµ > 0, this is only possible if |AŒµ| = 0. Therefore we Ô¨Ånd

x
 f (x) < g(x)
 =


Œµ>0
AŒµ
 = lim
Œµ‚Üì0 |AŒµ| = 0.
This completes the proof.
Solution E1.10
Since we have X ‚àºU[a, b] and Y ‚àºU[c, d], the density of X is
given by 1[a,b](x)/(b ‚àía) and the density of Y is 1[c,d](y)/(d ‚àíc), where
1[a,b](x) =
1
if x ‚àà[a, b] and
0
otherwise.
Since X and Y are independent, the joint density of (X, Y) is
f (x, y) = 1[a,b](x)
b ‚àía
¬∑ 1[c,d](y)
d ‚àíc
= 1[a,b](x)1[c,d](y)
(b ‚àía)(d ‚àíc) .
Consequently,
P

(X, Y) ‚ààA
	
=
 
1A(x, y) f (x, y) dy dx
=
 
1A(x, y)1[a,b](x)1[c,d](y)
(b ‚àía)(d ‚àíc) dy dx
=
1
(b ‚àía)(d ‚àíc)
 b
a
 d
c
1A(x, y) dy dx

APPENDIX C: ANSWERS TO THE EXERCISES
309
where
1A(x, y) =
1
if (x, y) ‚ààA and
0
otherwise.
Since the rectangle R = [a, b] √ó [c, d] satisÔ¨Åes |R| = (b ‚àía)(d ‚àíc) and any set A
satisÔ¨Åes
A ‚à©R
 =
 b
a
 d
c
1A(x, y) dy dx
we Ô¨Ånd
P

(X, Y) ‚ààA
	
=
A ‚à©R

|R|
.
This is the probability from the deÔ¨Ånition of the uniform distribution on R and
therefore the proof is complete.
Solution E1.11
The set A consists of two disjoint components. The probability for
a sample to be in the left component is 1/3 and the probability of being in the right
component is 2/3. Using lemma 1.31 we know that, conditioned on being in one
of the components, the sample should be distributed uniformly on this component.
Consequently we can generate samples Xi ‚àºU(A) as follows:
(a) Let I ‚àà{1, 2} with P(I = 1) = 1/3 and P(I = 2) = 2/3.
(b) If
I = 1
generate
X ‚àºU

[0, 1] √ó [0, 1]
	
.
Otherwise
generate
X ‚àº
U

[2, 4] √ó [0, 1]
	
.
The method can be implemented in R as follows:
r.two.squares <- function(n) {
U <- runif(n)
X <- ifelse(U < 1/3, runif(n), runif(n, 2, 4))
Y <- runif(n)
return(cbind(X, Y))
}
Z <- r.two.squares(1000)
plot(Z[,1], Z[,2], xlab="X", ylab="Y", cex=.5, asp=1)
The resulting plot is shown in Figure C.4.
Solution E1.12
We can proceed as in exercise E1.11, but some care is needed
since the two squares composing the set B overlap. To avoid this problem,
we write B = B1 ‚à™B2 ‚à™B3 where B1 = [0, 2] √ó [0, 1], B2 = [0, 3] √ó [1, 2] and

310
APPENDIX C: ANSWERS TO THE EXERCISES
0
1
2
3
4
0.0
0.5
1.0
X
Y
Figure C.4
A sample of 1000 points from the uniform distribution on set A from
exercise E1.11.
B3 = [1, 3] √ó [2, 3]. The corresponding probabilities are P(X ‚ààB1) = |B1|/|B| =
2/7, P(X ‚ààB2) = |B2|/|B| = 3/7 and P(X ‚ààB3) = |B3|/|B| = 2/7.
The method can be implemented in R as follows:
r.three.rectangles <- function(n) {
U <- runif(n)
X <- ifelse(U < 2/7, runif(n, 0, 2),
ifelse(U < 5/7, runif(n, 0, 3), runif(n, 1, 3)))
Y <- ifelse(U < 2/7, runif(n, 0, 1),
ifelse(U < 5/7, runif(n, 1, 2), runif(n, 2, 3)))
return(cbind(X, Y))
}
A plot of a sample generated by this function is shown in Figure C.5.
Solution E1.13
(a) We can use the following procedure: let Xn ‚àºU[‚àí1, 1] and Yn ‚àº
U[0, 1] be independent. Accept Un = (Xn, Yn) if X2
n + Y 2
n ‚â§1. Then the
accepted points are uniformly distributed on the semicircle. The acceptance
probability is
P

(Xn, Yn) accepted
	
= P

(Xn, Yn) in semicircle
	
=
semicircle

rectangle
 = œÄ/2
2
= œÄ
4 ‚âà0.7854.

APPENDIX C: ANSWERS TO THE EXERCISES
311
‚àí1
0
1
2
3
4
0.0
0.5
1.0
1.5
2.0
2.5
3.0
X
Y
Figure C.5
A sample of 1000 points from the uniform distribution on set B from
exercise E1.12.
(b) Since we do not know in advance how many proposals are required to generate
a given number of samples, we use a while loop in our program:
rsemicircle <- function(n) {
res = c()
k <- 0
while (length(res) < 2*n) {
k <- k + 1
X <- runif(1, -1, 1)
Y <- runif(1, 0, 1)
if (X^2 + Y^2 < 1) {
res <- rbind(res, c(X, Y))
}
}
cat(k, "proposals ->", n, "samples\n")
return(res)
}
Z <- rsemicircle(1000)
plot(Z[,1], Z[,2], xlab="X", ylab="Y", cex=.5, asp=1)
The resulting plot is shown in Figure C.6.
Solution E1.14
To obtain a rejection method with acceptance probability of at
least 80% we need to Ô¨Ånd a region for the proposals which contains the semicircle,
but which has an area of at most œÄ/(2 ¬∑ 0.8). Here we use the area depicted in
Figure C.7.

312
APPENDIX C: ANSWERS TO THE EXERCISES
‚àí1.0
‚àí0.5
0.0
0.5
1.0
0.0
0.2
0.4
0.6
0.8
1.0
X
Y
Figure C.6
A sample of 1000 points from the uniform distribution on the semicircle
(see exercise E1.13). A total of 1274 proposals was used in the rejection algorithm
to generate the 1000 samples.
The proposal region A has area |A| = 2 ‚àí2 ¬∑ 1/42 = 30/16 (6/16 for the upper
region and 24/16 for the lower region) and thus the acceptance probability is œÄ/2
|A| ‚âà
0.8378. We can sample from the uniform distribution on A as in exercise E1.12:
proposal <- function() {
U <- runif(1)
X <- ifelse(U < 6/30, runif(1, -0.75, 0.75), runif(1, -1, 1))
Y <- ifelse(U < 6/30, runif(1, 0.75, 1), runif(1, 0, 0.75))
return(c(X,Y))
}
0.75
0.75
0.75
‚àí0.75
Figure C.7
Proposal region for the rejection sampling algorithm proposed in the
solution to exercise E1.14.

APPENDIX C: ANSWERS TO THE EXERCISES
313
Using rejection sampling to obtain the uniform distribution on the semicircle is
now straightforward:
rsemicircle <- function(n) {
res = c()
k <- 0
while (length(res) < 2*n) {
k <- k + 1
Z <- proposal()
if (sum(Z^2) < 1) {
res <- rbind(res, Z)
}
}
return(res)
}
Solution E1.15
To Ô¨Ånd the density of X we can use lemma 1.33: since X is
distributed uniformly on the area between the x-axis and the graph of the function
‚àö
1 ‚àíx2, the vector (X, 2
œÄ Y) is uniformly distributed on
A =

(x, y) ‚ààR2  0 ‚â§y < f (x)

where
f (x) =
 2
œÄ
‚àö
1 ‚àíx2
if x ‚àà[‚àí1, 1] and
0
otherwise.
Since f ‚â•0 and

f (x) dx = 2
œÄ ¬∑ œÄ
2 = 1, the function f is a probability density, and
by lemma 1.33, the random variable X has density f .
To Ô¨Ånd the density of Y we use a direct calculation:
P

Y ‚ààA
	
=
 1
0 1A(y)‚ü®width of semicircle at level y‚ü©dy
‚ü®area of semicircle‚ü©
=
 1
0
1A(y)2

1 ‚àíy2
œÄ/2
dy
=

R
1A(y) g(y) dy
where
g(y) = 4
œÄ

1 ‚àíy2 1[0,1](y).
Thus, Y is distributed with density g.

314
APPENDIX C: ANSWERS TO THE EXERCISES
Solution E1.16
Denote the density of cX by g and deÔ¨Åne œï(x) = cx for all x ‚ààRd.
By theorem 1.34, if X has density
f (x) = g

œï(x)
	
¬∑
det Dœï(x)
,
then œï(X) has density g. Since œï(x)i = cxi for all i = 1, 2, . . . , d, we Ô¨Ånd
det Dœï(x) = det
‚éõ
‚éú‚éú‚éú‚éù
c
0
¬∑ ¬∑ ¬∑
0
0
c
¬∑ ¬∑ ¬∑
0
...
...
...
...
0
0
¬∑ ¬∑ ¬∑
c
‚éû
‚éü‚éü‚éü‚é†= cd
and thus f (x) = g(cx)|cd| for all x ‚ààRd. We can use the substitution y = cx to
solve this equation for g, the result is
g(y) =
1
|cd| f (y/c).
This is the required density of cX.
Solution E1.17
We have Y = œï(X) with œï(x) = (x2 ‚àí1)/2 for all x ‚ààR. We
would like to apply theorem 1.34 but, since œï is not bijective, the theorem does not
apply directly. To work around this problem we Ô¨Årst consider the random variable
Z = |X|. Since X2 = Z2, Y can also be written as Y = œï(Z) where œï: [0, ‚àû) ‚ÜíR
is bijective. We have
P(Z ‚ààA) = P(X ‚ààA) + P(‚àíX ‚ààA) =
2
‚àö
2œÄ

A
exp(‚àíx2/2) dx
for all A ‚äÜ[0, ‚àû) and thus Z has density
f (z) =

2
‚àö
2œÄ exp(‚àíz2/2)
if z ‚â•0 and
0
otherwise.
Now we can apply theorem 1.34 by considering œï to be a map from A = (0, ‚àû) to
B = (‚àí1/2, ‚àû). Denoting the density of Y by g we get
2
‚àö
2œÄ
exp(‚àíz2/2) = g

œï(z)
	œï‚Ä≤(z)
 = g

œï(z)
	
z
for all z > 0. Choosing z = œï‚àí1(y) = ‚àö2y + 1 we get
2
‚àö
2œÄ
exp(‚àíy ‚àí1/2) = g(y)

2y + 1

APPENDIX C: ANSWERS TO THE EXERCISES
315
and thus
g(y) =

exp(‚àíy‚àí1/2)
‚àöœÄ(y+1/2)
if y ‚â•‚àí1/2 and
0
otherwise.
This is the required density of Y.
Solution E1.18
Following the steps presented in example 1.40, we can use the
following R program:
rcauchy.ratio <- function(n) {
X0 <- c()
X1 <- c()
while (length(X0) < 2*n) {
x <- runif(1, 0, 1)
y <- runif(1, -1, 1)
if (x^2 + y^2 < 1) {
X0 <- c(X0, x)
X1 <- c(X1, y)
}
}
return(X1 / X0)
}
C.2
Answers for Chapter 2
Solution E2.1
Following algorithm 2.9 we can sample from the mixture distribution
as follows:
mu <- c(1, 2, 5)
sigma <- sqrt(c(0.01, 0.5, 0.02))
theta <- c(0.1, 0.7, 0.2)
Y <- sample(3, 10000, replace=TRUE, prob=theta)
X <- rnorm(10000, mu[Y], sigma[Y])
The required histogram can be plotted using the hist command.
hist(X, breaks=50, prob=TRUE,
main=NULL, col="gray80", border="gray20")
Finally, from lemma 2.8 we know that the density of the mixture distribution is
the mixture of the component densities. Using the function rnorm for the components,
we can overlay the mixture density over the plot as follows:

316
APPENDIX C: ANSWERS TO THE EXERCISES
curve(theta[1] * dnorm(x, mu[1], sigma[1])
+ theta[2] * dnorm(x, mu[2], sigma[2])
+ theta[3] * dnorm(x, mu[3], sigma[3]),
min(X), max(X), n=1000, add=TRUE)
The resulting plot is shown in Figure 2.1.
Solution E2.2
To show that X is not a Markov chain, we need to Ô¨Ånd a case where
the Markov chain condition (2.2) is violated. Example: if X j‚àí1 = a and X j‚àí2 = b
then X j ‚àºN(a + b, 1). Thus, for small Œµ > 0,
P

X j ‚àà[‚àí3, 3]
 X j‚àí1 ‚àà[‚àíŒµ, +Œµ], X j‚àí2 ‚àà[10 ‚àíŒµ, 10 + Œµ]

‚âà0
but
P

X j ‚àà[‚àí3, 3]
 X j‚àí1 ‚àà[‚àíŒµ, +Œµ], X j‚àí2 ‚àà[‚àíŒµ, +Œµ]

‚âà1.
If X was a Markov chain, the two probabilities would be equal, but here they are not.
Thus, X is not a Markov chain.
Solution E2.3
(a) To sample paths from the Markov chain we can use a program
such as:
MC <- function(N, initial, P) {
Xj <- sample(length(initial), 1, prob=initial)
res <- c(Xj)
for (j in 1:N) {
p <- P[Xj,]
Xj <- sample(length(p), 1, prob=p)
res <- c(res, Xj)
}
return(res)
}
# transition matrix
P <- matrix(c(2/3, 1/3, 0, 0,
.1, .9, 0, 0,
.1, 0, .9, 0,
.1, 0, 0, .9),
nrow = 4, ncol = 4, byrow=TRUE)

APPENDIX C: ANSWERS TO THE EXERCISES
317
# initial distribution
mu <- c(.25, .25, .25, .25)
MC(10, mu, P)
(b) To numerically estimate the distribution of X10 we can use a histogram:
data <- c()
for (k in 1:10000) {
X <- MC(10, mu, P)
data <- c(data, X[11])
}
hist(data, breaks=seq(0.5,4.5), probability=TRUE,
main=NULL, col="gray80", border="gray20")
The histogram allows us to Ô¨Ånd estimated probabilities for the different states of the
Markov chain: from the plot (not shown here) we read off the values P(X10 = 1) ‚âà
0.22, P(X10 = 2) ‚âà0.6, P(X10 = 3) ‚âà0.09, and P(X10 = 4) ‚âà0.09.
(c) We have to compute Œº‚ä§P10:
> mu %*% P %*% P %*% P %*% P %*% P %*% P %*% P %*% P %*% P %*% P
[,1]
[,2]
[,3]
[,4]
[1,] 0.2308349 0.5948259 0.08716961 0.08716961
The result coincides well with the values we read off the histogram.
Solution E2.4
(a) This follows directly from the properties of a stochastic matrix:
(Pv)y =

x‚ààS
pxyvy =

x‚ààS
pxy1 = 1 = 1 ¬∑ vy
for all y ‚ààS. Thus, v is an eigenvector with eigenvalue 1.
(b) Assume Av = Œªv. Then A(Œ±v) = Œ±Av = Œ±(Œªv) = Œª(Œ±v).
(c) We Ô¨Ånd the eigenvalues of P as follows:
> E <- eigen(t(P))
$values
[1] 1.0000000 0.9000000 0.9000000 0.5666667
$vectors
[,1]
[,2]
[,3]
[,4]
[1,] -0.2873479 -3.925231e-17 -3.925231e-17 -0.7071068
[2,] -0.9578263 -7.071068e-01 -7.071068e-01
0.7071068
[3,]
0.0000000
7.071068e-01
0.000000e+00
0.0000000
[4,]
0.0000000
0.000000e+00
7.071068e-01
0.0000000

318
APPENDIX C: ANSWERS TO THE EXERCISES
Looking at the Ô¨Årst column of this matrix (corresponding to the eigenvalue
1.0000000), we see that
v = (‚àí0.2873479, ‚àí0.9578263, 0.0000000, 0.0000000)
is the (only) eigenvector of P‚ä§with eigenvalue 1. Thus, by normalising this vector
to be a probability vector, we Ô¨Ånd the stationary distribution of P:
> v <- E$vectors[,1]
> v / sum(v)
[1] 0.2307692 0.7692308 0.0000000 0.0000000
Solution E2.5
To simulate a Poisson process with constant intensity, we can
directly follow the steps described in example 2.38. In R, we can use the following
function:
PoissonProcessConst <- function(a, b, lambda) {
N <- rpois(1, lambda * (b-a))
X <- runif(N, a, b)
return(X)
}
If we want the function to return the points in increasing order, we could replace the
return statement by return(sort(X)).
Solution E2.6
To implement the required function in R, we can directly follow the
steps described in example 2.39:
PoissonProcessStep <- function(t, lambda) {
stopifnot(length(t) == length(lambda)+1)
X <- c()
for (i in 1:length(lambda)) {
N <- rpois(1, lambda * (t[i+1]-t[i]))
X <- c(X, runif(N, t[i], t[i+1]))
}
return(X)
}
The function can be used as follows:
t <- c(1.4, 3,
4, 6,
6.2, 7.9,
8,
9.5)
lambda <- c(1, 4.5, 2, 1.4,
0,
1.1, 0.8)
X <- PoissonProcessStep(t, lambda)
The output of a call such as this has been used to determine the position of the marked
points in Figure 2.3.

APPENDIX C: ANSWERS TO THE EXERCISES
319
C.3
Answers for Chapter 3
Solution E3.1
We can use the rejection algorithm suggested in example 3.6,
that is we apply the rejection sampling algorithm 1.22 with target density f (x) =
exp(‚àíy2/2x ‚àíx)/‚àöx, proposal density g(x) = exp(‚àíx) and c = exp(‚àí1/2)/|y|.
The condition cg(X)U ‚â§f (X) from the algorithm takes the following form:
cg (X)U ‚â§f (X)
‚áê‚áí
1
|y| exp(‚àí1/2) exp(‚àíx)U ‚â§
1
‚àöx exp

‚àíy2/2x ‚àíx
	
‚áê‚áí
U ‚â§
|y|
‚àöx exp

‚àíy2/2x + 1/2
	
.
This gives the following algorithm for generating samples from the conditional
distribution of X given Y = y:
(a) Generate X ‚àºExp(1).
(b) Generate U ‚àºU[0, 1].
(c) Accept X if U ‚â§|y|
‚àöx exp

‚àíy2/2x + 1/2
	
.
We can implement this rejection algorithm in R as follows:
GeneratePosteriorSamples <- function(n, y) {
res <- c()
while (length(res) < n) {
X <- rexp(1)
U <- runif(1)
if (U <= abs(y) * exp(-y^2/(2*X) + 0.5) / sqrt(X)) {
res <- c(res, X)
}
}
return(res)
};
Finally, Monte Carlo estimation can be used to get approximations for the mean
E(X |Y = 4) and the variance Var(X |Y = 4):
> X <- GeneratePosteriorSamples(10000, 4)
> mean(X)
[1] 3.329493
> var(X)
[1] 1.934953
This shows that the posterior expectation is approximately 3.33 and the posterior
variance is approximately 1.93.

320
APPENDIX C: ANSWERS TO THE EXERCISES
Solution E3.2
To compute a single Monte Carlo estimate for E

sin(X)2	
we can
use the following function:
GetMCEstimate <- function(N) {
X <- rnorm(N)
return(mean(sin(X)^2))
}
This function takes N as its only parameter and computes one instance of the Monte
Carlo estimate ZMC
N . An estimate for E(sin(X)2) can be obtained with the following
command:
> GetMCEstimate(1000000)
[1] 0.4318852
We want to compare the variances of the Monte Carlo estimates for N = 1000 and
N = 10 000. To do so, we Ô¨Årst generate estimates repeatedly and then plot a histogram
of the resulting values:
estimates <- replicate(10000, GetMCEstimate(1000))
range <- c(min(estimates), max(estimates))
hist(estimates, breaks=seq(range[1], range[2], length.out=50),
xlab=expression(Z[1000]), xlim=range, ylim=c(0,2100),
main=NULL, col="gray80", border="gray20")
By taking a huge value of N we can generate a single estimate which is close to
the true value of the expectation. This value can be marked in the histogram using
the following commands:
good.estimate <- GetMCEstimate(1000000)
abline(v=good.estimate)
The resulting plot is shown in Figure 3.1(a). The Ô¨Ågure shows that the exact value for
the expectation is approximately 0.43, the estimates for N = 1000 range from about
0.40 to about 0.46. The width of this range is more than 10% of the exact value and
thus a single estimate for N = 1000 would not be a very accurate approximation for
the mean.
Finally, for the second part of the question, we repeat the experiment with Monte
Carlo sample size N = 10 000:
estimates2 <- replicate(10000, GetMCEstimate(10000))
hist(estimates2, breaks=seq(range[1], range[2], length.out=50),
xlab=expression(Z[10000]), xlim=range, ylim=c(0,2100),
main=NULL, col="gray80", border="gray20")
abline(v=good.estimate)

APPENDIX C: ANSWERS TO THE EXERCISES
321
The new histogram is shown in Figure 3.1(b). As expected from proposition 3.14,
the variance of the samples in the second histogram is signiÔ¨Åcantly lower than in the
Ô¨Årst histogram.
Solution E3.3
The Monte Carlo estimate for E

cos(X)
	
is given by
ZMC
N
= 1
N
N

j=1
cos(X j),
where X1, . . . , X N ‚àºN(0, 1) are i.i.d. The difÔ¨Åculty lies in the choice of N.
The question asks us to obtain and estimate with ‚Äòthree digits of accuracy‚Äô. This
statement is open to interpretation and to answer the question, we need to choose
which interpretation of ‚Äòthree digits of accuracy‚Äô we choose. Here we interpret ‚Äòthree
digits of accuracy‚Äô to mean MSE(ZMC
N ) ‚â§0.0012. (The square on the right-hand side
is needed, since the mean squared error is a squared quantity.) Since
Var

cos(X)
	
= E

cos(X)2	
‚àíE

cos(X)
	2 ‚â§1 ‚àí0 = 1,
we can use the estimate
MSE

ZMC
N
	
‚â§Var (cos(X))
N
‚â§1
N .
Using this estimate we see that N = 106 is enough to achieve MSE(ZMC
N ) ‚â§10‚àí6 =
0.0012. A computer experiment can be used to get a numerical value for the expec-
tation:
> N <- 1e6
> X <- rnorm(N)
> mean(cos(X))
[1] 0.6064109
Thus, our estimate is E(cos(X)) ‚âà0.606.
Solution E3.4
From equation (3.5) we get
P(X ‚â§a) =
 a
‚àí‚àû
1
‚àö
2œÄ
e‚àíx2/2 dx
= 1
2 +
1
‚àö
2œÄ
 a
0
e‚àíx2/2 dx
= 1
2 +
a
‚àö
2œÄ
E

e‚àía2U 2/2	

322
APPENDIX C: ANSWERS TO THE EXERCISES
where U ‚àºU[0, 1]. Since the estimate ÀúpN is obtained by replacing the expectation
on the right-hand side with the corresponding Monte Carlo estimate, we know what
ÀúpN ‚Üíp as N ‚Üí‚àûand that ÀúpN is unbiased.
Since both estimates are unbiased, we have
MSE(pN) = Var(pN) = 1
N Var

1[a,‚àû)(X)
	
and
MSE( ÀúpN) = Var( ÀúpN) = Var
1
2 +
a
‚àö
2œÄ N
N

j=1
e‚àía2U 2/2
= 1
N ¬∑ a2
2œÄ Var

e‚àía2U 2/2	
.
To estimate the MSE of the estimator pN we can use the following R
commands:
> a <- 1
> X <- rnorm(1000000)
> var(X >= a)
[1] 0.1332084
Thus, we have MSE(pN) ‚âà0.1332/N. For the estimator ÀúpN we get:
> U <- runif(1000000)
> var(exp(-a^2*U^2/2)) * a^2 / (2*pi)
[1] 0.002345373
that is we have MSE( ÀúpN) ‚âà0.0023/N. Thus the estimator ÀúpN has much smaller
error than the estimator pN does.
Solution E3.5
The key observation which allows to compute ÀÜœÉ 2 using only a
constant amount of memory is that ÀÜœÉ 2 can be written as
ÀÜœÉ 2 =
1
N ‚àí1
N

j=1

f (X j)2 ‚àí2 f (X j)ZMC
N
+

ZMC
N
	2
=
1
N ‚àí1
N

j=1
f (X j)2 ‚àí2 ZMC
N
N ‚àí1
N

j=1
f (X j) +
N
N ‚àí1

ZMC
N
	2
=
1
N ‚àí1
N

j=1
f (X j)2 ‚àí
N
N ‚àí1(ZMC
N )2
=
1
N ‚àí1
N

j=1
f (X j)2 ‚àí
1
N(N ‚àí1)
 N

j=1
f (X j)
2
.

APPENDIX C: ANSWERS TO THE EXERCISES
323
Using this formula, we can compute ZMC
N
and ÀÜœÉ 2 simultaneously, using the following
steps:
1: s ‚Üê0
2: t ‚Üê0
3: for j = 1, 2, . . . , N do
4:
generate X j
5:
s ‚Üês + f (X j)
6:
t ‚Üêt + f (X j)2
7: end for
8: return ZMC
N
= s/N and ÀÜœÉ 2 = (t ‚àís2/N)/(N ‚àí1).
This algorithm requires a constant amount of memory, since only the variables s and
t need to be stored between iterations of the loop.
Solution E3.6
We consider importance sampling estimates of the probability
p = P(X ‚ààA), where X ‚àºN(0, 1) and A = [3, 4]. If samples Y j ‚àºœà are used, the
corresponding importance sampling estimate for p is given by
ÀÜp = 1
N
N

j=1
1A(Y j) œï(Y j)
œà(Y j),
where
œï(x) =
1
‚àö
2œÄ
exp

‚àíx2
2

is the density of X.
(a) An importance sampling estimate ÀÜp, together with the sample variance ÀÜœÉ 2 can
be computed using the following R code
GetISEstimate <- function(N, gen.Y, psi) {
Y <- gen.Y(N)
phi <- function(x) dnorm(x, 0, 1);
weighted.samples <- (Y >= 3 & Y <= 4) * phi(Y) / psi(Y)
return(list(p=mean(weighted.samples),
var=var(weighted.samples)))
}
The R function GetISEstimate takes three arguments: N is the sample size, gen.Y is
an R function to generate the samples Y1, . . . , YN and psi is an R function to compute
the density œà. The function GetISEstimate can be called as follows:
> gen.Y1 <- function(N) { rnorm(N, 1, 1) }
> psi1 <- function(x) { dnorm(x, 1, 1) }
> GetISEstimate(10000, gen.Y1, psi1)
$p
[1]
0.001243597

324
APPENDIX C: ANSWERS TO THE EXERCISES
The output of GetISEstimate is a list which contains the estimate for p in the Ô¨Åeld
$p and the estimated variance of the weighted samples in $var.
To get a list of estimated variances for all four methods, we have to call GetISEs-
timate repeatedly. One way of doing so is to deÔ¨Åne the following helper functions:
PrintISVariance <- function(name, gen.Y, psi) {
est <- GetISEstimate(10000, gen.Y, psi)
cat(name, "
-->
Var = ", est$var, "\n", sep="")
return(est$var)
}
gen.Y2 <- function(N) { rnorm(N, 2, 1) }
psi2 <- function(x) { dnorm(x, 2, 1) }
gen.Y3 <- function(N) { rnorm(N, 3.5, 1) }
psi3 <- function(x) { dnorm(x, 3.5, 1) }
gen.Y4 <- function(N) { rexp(N) + 3 }
psi4 <- function(x) { dexp(x-3) }
PrintAllVariances <- function() {
v1 <- PrintISVariance("N(1,1)
", gen.Y1, psi1)
v2 <- PrintISVariance("N(2,1)
", gen.Y2, psi2)
v3 <- PrintISVariance("N(3.5,1)", gen.Y3, psi3)
v4 <- PrintISVariance("Exp(1)+3", gen.Y4, psi4)
return(c(v1, v2, v3, v4))
}
These functions determine the variances for all four estimators. The result is as
follows:
> res <- PrintAllVariances()
N(1,1)
-->
Var = 7.882264e-05
N(2,1)
-->
Var = 1.400159e-05
N(3.5,1)
-->
Var = 6.666196e-06
EXP(1)+3
-->
Var = 1.897206e-06
The results show that the method which uses Y j ‚àºExp(1) + 3 has the smallest
variance and thus gives the most accurate results for given sample size N. We store
the list of variances in the variable res for use in (c).
(b) We use the most efÔ¨Åcient method, identiÔ¨Åed in the previous part of the question,
to obtain a good estimate for p:
> N <- 10000
> est <- GetISEstimate(N, gen.Y4, psi4)
> est$p
[1] 0.001329137
> 1.96 * sqrt(est$var) / sqrt(N)
[1] 2.70939e-05

APPENDIX C: ANSWERS TO THE EXERCISES
325
The output shows that the computed value for the estimate is ÀÜp = 0.001329137
and that a 95% conÔ¨Ådence interval for p around ÀÜp has a width of approximately
2 ¬∑ 2.7 ¬∑ 10‚àí5 = 0.000054. Since the width of the conÔ¨Ådence interval is much smaller
than the value itself, we expect ÀÜp to be an accurate estimate.
(c) To get an estimate with an error of 1% we choose N such that MSE( ÀÜp) = Œµ2,
where Œµ = 0.01 ÀÜp. Solving (3.18) for N we Ô¨Ånd that the required condition for N is
given by
N ‚â•ÀÜœÉ 2
Œµ2 =
ÀÜœÉ 2
(0.01 ÀÜp)2 .
Using the variances from (a) we get the following results:
> eps <- 0.01 * est$p
> ceiling(res / eps^2)
[1]
446182
79257
37735
10740
For comparison we note that from equation (3.11) we know that the corresponding
lower bound for a basic Monte Carlo estimate is N ‚â•p(1 ‚àíp)/Œµ2:
> est$p * (1 - est$p) / eps^2
[1]
7513676
We see that computation of the basic Monte Carlo estimate will take approximately
7513676/10740 ‚âà700 times as long as computing the best of the importance sam-
pling estimates considered here.
Solution E3.7
We study how Monte Carlo estimation can be used to estimate the
bias of the estimator ÀÜœÅ(X, Y) from equation (3.23).
(a) The estimator ÀÜœÅ(X, Y) can be implemented as an R function as follows:
rxy <- function(x, y) {
x.bar <- mean(x)
y.bar <- mean(y)
numerator <- mean((x-x.bar)*(y-y.bar))
denominator <- sqrt(mean((x-x.bar)^2)*mean((y-y.bar)^2))
return(numerator/denominator)
}
Using this function, the bias of ÀÜœÅ(X, Y) can be estimated by the following
program: we generate random pairs (X, Y) with given length n and given
correlation œÅ as in the previous question. The following function generates
samples ÀÜœÅ(X j, Y j) for j = 1, 2, . . . , N:
rhohat.sample <- function(N, n, rho) {
res <- c()

326
APPENDIX C: ANSWERS TO THE EXERCISES
for (j in 1:N) {
X <- rnorm(n)
eta <- rnorm(n)
Y <- rho*X + sqrt(1-rho^2)*eta
res[j] <- rxy(X, Y)
}
return(res)
}
Using the output of this function, a Monte Carlo estimate for the bias can be
computed as follows:
EstimateBias <- function(N, n, rho) {
return(mean(rhohat.sample(N, n, rho)) - rho)
}
Since ÀÜœÅ(X, Y) ‚àà[‚àí1, 1], we have the upper bound Var

ÀÜœÅ(X, Y)
	
‚â§1 and
thus the variance of the estimate for the bias is smaller than 1/N. Conse-
quently, for N = 10 000, the standard deviation of the estimate is guaranteed
to be smaller than 0.01 (and in reality will be much smaller than this). Since
correlations lie in the range [‚àí1, +1], bringing the error below 0.01 seems
sufÔ¨Åcient; thus we will use N = 10 000 in (b) and (c).
(b) We can call the function EstimateBias in a loop in order to plot the estimated
bias as a function of œÅ. Assuming n = 10, we can use the following program:
n <- 10
N <- 10000
rho.values <- seq(-1, +1, by=0.05)
bias.values <- c()
for (rho in rho.values) {
cat("rho =", rho, "\n")
bias.values <- c(bias.values, EstimateBias(N, n, rho))
}
plot(rho.values, bias.values,
xlab=expression(rho), ylab="estimated bias")
The resulting data points in the plot are still affected by random noise, caused
by the Monte Carlo error for Ô¨Ånite N. To make the picture clearer, we can
add a smoothed curve through the estimated values:
s <- smooth.spline(rho.values, bias.values, spar=0.6)
lines(s)
The resulting plot is shown in Figure 3.2.
(c) We can compute ÀÜœÅ(X, Y) for the given data as follows:
X <- c(0.218, 0.0826, 0.091, 0.095, -0.826,
0.208, 0.600, -0.058, 0.602, 0.620)

APPENDIX C: ANSWERS TO THE EXERCISES
327
Y <- c(0.369, 0.715, -1.027, -1.499, 1.291,
-0.213, -2.400, 1.064, -0.367, -1.490)
print(rxy(X,Y))
The result is -0.6917216. From Figure 3.2 we know that the bias for œÅ-values
of this magnitude is about 0.02, that is on average ÀÜœÅ(X, Y) will over-estimate
œÅ by about 0.02. Consequently, ‚àí0.69 ‚àí0.02 is an approximately unbiased
estimate for œÅ.
Solution E3.8
We can use the following R code to get the Monte Carlo estimate
of the conÔ¨Ådence coefÔ¨Åcients:
EstimateConfidenceCoefficient <- function(n, lambda, N=100000){
p.alpha <- qt(0.975, df=n-1)
k <- 0
for (j in 1:N) {
X <- rpois(n, lambda)
m <- mean(X)
sigma.hat <- sd(X)
d <- p.alpha * sigma.hat / sqrt(n)
if (m - d <= lambda && lambda <= m + d) {
k <- k + 1
}
}
return(k / N)
}
To call this function for a range of different Œª, we can use a loop such as the
following:
lambda.list <- c()
prob.list <- c()
width.list <- c()
for (lambda in seq(0.025, 1, length.out=40)) {
prob <- EstimateConfidenceCoefficient(10, lambda)
print(c(lambda, prob))
lambda.list <- c(lambda.list, lambda)
prob.list <- c(prob.list, prob)
}
The results of the estimation are stored in the vector prob.list, the corresponding
values of Œª are stored in lambda.list. Finally, we create a plot of the results:
plot(lambda.list, prob.list, ylim=c(0,1),
xlab=expression(lambda), ylab="confidence coefficient")

328
APPENDIX C: ANSWERS TO THE EXERCISES
The plot, shown in Figure 3.3, clearly shows that for Poisson-distributed data the
interval (3.26), at least when Œª is allowed to be arbitrarily small, has an extremely
low conÔ¨Ådence coefÔ¨Åcient and thus is not a useful conÔ¨Ådence interval.
C.4
Answers for Chapter 4
Solution E4.1
To implement the random walk Metropolis method described in
example 4.10, we can use the following R function:
GenerateMCMCSample <- function(N, sigma) {
X <- numeric(length=N)
Xj <- runif(1, -1, 1)
for (j in 1:N) {
Yj <- rnorm(1, Xj, sigma)
if (abs(Yj) <= 3 * pi) {
alpha <- (Xj * sin(Yj) / (Yj * sin(Xj))) ^ 2
} else {
alpha <- 0
}
U <- runif(1)
if (U < alpha) {
Xj <- Yj
}
X[j] <- Xj
}
return(X)
}
Some care is needed with the choice of the initial value X0: since, at least in our
implementation, Œ±(x, y) is undeÔ¨Åned for x = 0, we cannot start the process with
X0 = 0. Instead we start with a random initial point X0 ‚àºU[‚àí1, 1]. This choice
avoids the problem at 0 and, at the same time, guarantees that X0 falls into a region
where œÄ is large. Figure 4.1 shows paths resulting from three runs of the algorithm,
for different values of œÉ.
Solution E4.2
To implement the random walk Metropolis method in R we can use
the following functions:
pi <- function(x, log=FALSE) {
dnorm(x, 100, 1, log=log)
}
p <- function(x, y, log=FALSE) {
dnorm(y, x, log=log)
}

APPENDIX C: ANSWERS TO THE EXERCISES
329
alpha <- function(x, y) {
return(exp(pi(y, log=TRUE) + p(y, x, log=TRUE)
- pi(x, log=TRUE) - p(x, y, log=TRUE)))
}
MCMC <- function(X0, N) {
X <- numeric(length=N)
Xj <- X0
for (j in 1:N) {
Yj <- rnorm(1, Xj)
U <- runif(1)
if (U < alpha(Xj, Yj)) {
Xj <- Yj
}
X[j] <- Xj
}
return(c(X0, X))
}
These functions can be used as follows:
N <- 1000
j <- 0:N
X <- MCMC(0, N)
plot(j, X, type="l", ylab=expression(X[j]))
The resulting plot is shown in Figure 4.2. Experiments show that the process always
moves towards the value 100 with approximately constant speed. Once the process
is close to 100, it starts Ô¨Çuctuating around this value. A good choice for the burn-in
period is, for example the time until the process reaches the interval [99, 101]. In
this simple example it would be even better to always start with X0 = 100 instead of
using a burn-in period.
Solution E4.3
In exercise E4.1 we have already written an R-function to generate
paths from the random walk Metropolis algorithm with target density œÄ. Using
this function, named GenerateMCMCSample we can generate plots of the estimated
autocorrelations as follows:
PlotAutocorrelation <- function(N, sigma, ...) {
X <- GenerateMCMCSample(N, sigma)
a <- acf(X^2, lag.max=200, ci=0, ylab=expression(rho[k]), ...)
text(195, 0.92, bquote(sigma==.(sigma)))
# a$acf stores the autocorrelation coefficients,
# a$acf[1] = rho_0 = 1, a$acf[2] = rho_1, ...

330
APPENDIX C: ANSWERS TO THE EXERCISES
eff <- 1/(1 + 2 * sum(a$acf[-1]))
print(c(eff, 1/eff))
}
Here we use the built-in R function acf to estimate the autocorrelation of the samples.
The function PlotAutocorrelation can be used as follows:
> PlotAutocorrelation(1000000, 6)
[1] 0.1520343
Solution E4.4
There are two different ways we can estimate the required acceptance
probability. We can either use the ratio of accepted samples to proposed samples in
the algorithm, or we can take the average of the acceptance probabilities Œ±(X j‚àí1, Y j)
for j = 1, 2, . . . , N. Here we use the second of these methods:
AverageAcceptanceRate <- function(N, sigma) {
asum <- 0;
Xj <- runif(1, -1, 1)
for (j in 1:N) {
Yj <- rnorm(1, Xj, sigma)
if (abs(Yj) <= 3 * pi) {
alpha <- min((Xj * sin(Yj) / (Yj * sin(Xj))) ^ 2, 1)
} else {
alpha <- 0
}
U <- runif(1)
if (U < alpha) {
Xj <- Yj
}
asum <- asum + alpha
}
return(asum / N)
}
xx <- c()
yy <- c()
for (p in seq(-2, 3, 0.2)) {
sigma <- 10^p
cat("sigma = ", sigma, "\n", sep="")
xx <- c(xx, sigma^2)
yy <- c(yy, AverageAcceptanceRate(100000, sigma))
}
plot(xx, yy, type="l", log="x",
xlab=expression(sigma^2), ylab="average acceptance probability")

APPENDIX C: ANSWERS TO THE EXERCISES
331
abline(v=1, lty=3)
abline(v=6^2, lty=3)
abline(v=36^2, lty=3)
The output of this program is shown in Figure 4.4.
Solution E4.5
The random walk Metropolis algorithm for the posterior distribution
can be implemented as follows:
GeneratePosteriorSample <- function(N, x, eta) {
n <- length(x)
mu <- mean(x)
sigma <- sd(x)
theta <- matrix(nrow=N, ncol=2)
for (j in 1:N) {
eps <- rnorm(2, 0, eta)
mu.tilde <- mu + eps[1]
sigma.tilde <- sigma + eps[2]
if (-10 <= mu.tilde && mu.tilde <= 10 && sigma.tilde > 0) {
a <- n * (log(sigma) - log(sigma.tilde))
b <- sum((x - mu.tilde)^2) / (2 * sigma.tilde) + sigma.tilde
c <- sum((x - mu)^2) / (2 * sigma) + sigma
alpha <- min(exp(a - b + c), 1)
} else {
alpha <- 0
}
U <- runif(1)
if (U < alpha) {
mu <- mu.tilde
sigma <- sigma.tilde
}
theta[j,1] <- mu
theta[j,2] <- sigma
}
return(theta)
}
The function can be used as follows:
n <- 100
x <- rnorm(n, 5, 2)
N <- 10000
theta <- GeneratePosteriorSample(N, x, 0.1)

332
APPENDIX C: ANSWERS TO THE EXERCISES
5.0
5.4
5.8
Œºj
0
2000
4000
6000
8000
1.4 1.8 2.2 2.6
j
œÉj
Figure C.8
Output of the program from exercise E4.5.
The path of the Markov chain is now stored in theta. The value theta[j,1] corre-
sponds to Œº j and the entry theta[j,1] stores œÉ j. These data can now be used for
Monte Carlo estimates. Here we restrict ourselves to plotting the data:
j = 1:N
plot(j, theta[j,1], type="l", ylab=expression(mu[j]))
plot(j, theta[j,2], type="l", ylab=expression(sigma[j]))
The resulting plot is shown in Figure C.8.
Solution E4.6
The Gibbs sampler described in section 4.4.2 can be implemented
in R as follows:
GeneratePosteriorSample <- function(N, burn.in=1000) {
muj <- matrix(runif(2*k, -10, 10), nrow=k, ncol=2)
Yj <- sample(1:k, n, replace=TRUE)
for (j in 1:(burn.in + N)) {
if (j %% 2 == 1) {
for (a in 1:k) {
ind <- Yj == a
na <- sum(ind)
if (na > 0) {
m <- c(mean(x[ind,1]), mean(x[ind,2]))
s <- sigma / sqrt(na)
xi <- c(999, 999)
# this is re-set in the loop below
while (xi[1] < -10 || xi[1] > 10
|| xi[2] < -10 || xi[2] > 10) {

APPENDIX C: ANSWERS TO THE EXERCISES
333
xi = rnorm(2, m, s)
}
if (j > burn.in) {
points(xi[1], xi[2], pch=a+1, cex=0.6)
}
} else {
xi <- runif(2, -10, 10)
}
muj[a,] <- xi
}
} else {
for (i in 1:n) {
q <- numeric(length=k)
for (a in 1:k) {
q[a] <- (dnorm(x[i,1], muj[a,1], sigma)
* dnorm(x[i,2], muj[a,2], sigma))
}
Yj[i] <- sample(1:k, 1, prob=q)
}
}
}
}
The function assumes that the number of modes is stored in the global variable k,
the number of observations is stored in n and the observations are stored in an n √ó 2
matrix x. For simplicity we plot the generated samples inside this function (using the
points command) instead of returning the values.
To test the function we generate a synthetic data set from the model:
k <- 5
n <- 100
sigma <- 1
true.mu <- matrix(runif(2*k, -10, 10), nrow=k, ncol=2)
true.y <- sample(1:k, n, replace=TRUE)
x <- matrix(nrow=n, ncol=2)
x[,1] <- rnorm(n, true.mu[true.y, 1], sigma)
x[,2] <- rnorm(n, true.mu[true.y, 2], sigma)
A sample from the posterior distribution of the cluster means Œº1, . . . , Œºn given
the observations stored in x can now be obtained by calling the function Gener-
atePosteriorSample as follows:
plot(x[,1], x[,2], xlim=c(-10,10), ylim=c(-10,10),
xlab=expression(X[list(i,1)]), ylab=expression(X[list(i,2)]),

334
APPENDIX C: ANSWERS TO THE EXERCISES
col="gray60", asp=1)
GeneratePosteriorSample(100)
The results of two different runs of this program are shown in Figure 4.5 (a typical
output) and Figure 4.6 (an exceptional output, where the Markov chain has not yet
converged).
Solution E4.7
Since the Gibbs sampler for the Ising model, as given by algorithm
4.31, can require a large number of iterations to reach equilibrium, we take some care
to provide an efÔ¨Åcient implementation:
r To avoid special-casing the pixels on the boundaries of the grid in step 4, we
add extra rows/columns of zeros around the image, resulting in an extended
grid size of (L + 2) √ó (L + 2).
r Since the variable d computed in step 4 can only take the Ô¨Åve possible values
‚àí4, ‚àí2, 0, 2, and 4, we can pre-compute the resulting probability weights
œÄXm|X¬¨m(+1|x¬¨m) =
exp(+Œ≤d)
exp(+Œ≤d) + exp(‚àíŒ≤d) =
1
1 + exp(‚àí2Œ≤d),
to avoid evaluating the exponential function inside the main loop of the algo-
rithm.
The resulting method can be implemented in R as follows:
RunGibbs <- function(M, beta, L) {
X <- matrix(0, nrow=L+2, ncol=L+2)
pixels <- sample(c(-1,+1), size=L*L, replace=TRUE)
X[2:(L+1),2:(L+1)] <- matrix(pixels, nrow=L, ncol=L)
p.table <- numeric(length=5)
for (d in seq(-4, 4, by=2)) {
p.table[(d+6)/2] <- 1 / (1 + exp(-2 * beta * d))
}
for (sweep in 1:M) {
n <- matrix(0, nrow=L, ncol=L)
for(ix in 2:(L+1)) {
for (iy in 2:(L+1)) {
d <- X[iy-1, ix] + X[iy+1, ix] + X[iy, ix-1] + X[iy, ix+1]
p <- p.table[(d+6)/2]
X[iy, ix] <- sample(c(-1, +1), size=1, prob=c(1-p, p))
}
}
}
return(X[2:(L+1),2:(L+1)])
}

APPENDIX C: ANSWERS TO THE EXERCISES
335
For given inverse temperature Œ≤ and given M, the program performs N = M ¬∑ L2
steps of algorithm 4.31, that is it performs M ‚Äòsweeps‚Äò over the complete picture,
and returns the Ô¨Ånal state X(N) ‚ààS. This state can then be plotted using R commands
such as image(1:L, 1:L, X). The results of different runs of this function are shown
in Figure 4.7.
It is tempting to attempt to implement a much faster version of the program
which would update all pixels in parallel. Unfortunately step 4 of algorithm 4.31
references pixels which have only been updated during the current ‚Äòsweep‚Äô over the
image (X( j‚àí1)
m1‚àí1,m2 and X( j‚àí1)
m1,m2‚àí1), making parallel updates difÔ¨Åcult.
Solution E4.8
For implementing algorithm 4.32 in R, we follow the steps described
in the solution to exercise E4.7, and only modify the expression for sampling from
the posterior distribution pXm|X¬¨m to include the given observation Y of the original
image:
RunGibbs <- function(M, beta, Y, sigma, burn.in=100) {
L <- ncol(Y)
count <- matrix(0, nrow=L, ncol=L)
X <- matrix(0, nrow=L+2, ncol=L+2)
pixels <- sample(c(-1,+1), size=L*L, replace=TRUE)
X[2:(L+1),2:(L+1)] <- matrix(pixels, nrow=L, ncol=L)
for (sweep in 1:(burn.in + M)) {
for (ix in 2:(L+1)) {
for (iy in 2:(L+1)) {
d <- X[iy-1, ix] + X[iy+1, ix] + X[iy, ix-1] + X[iy, ix+1]
p <- 1 / (1 + exp(-2 * (beta * d + Y[iy-1, ix-1] / sigma^2)))
X[iy, ix] <- sample(c(-1, +1), size=1, prob=c(1-p, p))
}
}
if (sweep > burn.in) {
count <- count + (X[2:(L+1),2:(L+1)] == 1)
}
}
return(count / M)
}
The return value of this function is a matrix of the same size as Y, giving the posterior
probability that the corresponding pixel in the original image was black. The output
of this function can be plotted using commands such as the following.
prob <- RunGibbs(N, beta, Y, sigma)
image(1:L, 1:L, prob)
The result of three different runs of this function is shown in Figure 4.8.

336
APPENDIX C: ANSWERS TO THE EXERCISES
Solution E4.9
We start by implementing the mixture model from equation (4.47)
in R. Samples from the mixture distribution can be generated using the following
function:
model.clusters.mean <- 4
# the average number of clusters
model.r.min <- 0.5
# smallest possible stddev for a cluster
model.r.max <- 2.5
# largest possible stddev for a cluster
GenerateMixtureSample <- function(n) {
# Sample the parameters:
k <- rpois(1, lambda=model.clusters.mean-1) + 1
mu <- matrix(nrow=2, ncol=k)
mu[1,] <- runif(k, -10, 10)
mu[2,] <- runif(k, -10, 10)
sigma <- runif(k, model.r.min, model.r.max)
# Generate a sample of size n from the mixture distribution:
a <- sample.int(k, n, replace=TRUE)
x_1 <- rnorm(n, mu[1,a], sigma[a])
x_2 <- rnorm(n, mu[2,a], sigma[a])
return(rbind(x_1, x_2))
}
We will need a function to evaluate the posterior distribution as given in equation
(4.51). This is implemented in the function GetLogPosterior:
GetLogPrior <- function(mu, r) {
# Since both, x and y coordinates of the mean have the same
# distribution, we can merge them into one list:
log.p.mu <- sum(dunif(as.vector(mu), -10, 10, log=TRUE))
log.p.r <- sum(dunif(r, model.r.min, model.r.max, log=TRUE))
k <- length(r)
log.p.k <- dpois(k-1, lambda=model.clusters.mean-
1, log=TRUE)
return(log.p.mu + log.p.r + log.p.k)
}
GetLogMixDens <- function(mu, r, x) {
mix.dens <- mean(dnorm(mu[1,], x[1], r) * dnorm(mu[2,], x[2], r))
return(log(mix.dens))
}
GetLogPosterior <- function(mu, r, obs) {

APPENDIX C: ANSWERS TO THE EXERCISES
337
log.prior <- GetLogPrior(mu, r)
# Avoid calling GetLogMixDens for negative variances:
if (log.prior == -Inf) return(-Inf)
log.p.obs <- 0
for (i in 1:ncol(obs)) {
tmp <- GetLogMixDens(mu, r, obs[,i])
log.p.obs <- log.p.obs + tmp
}
return(log.p.obs + log.prior)
}
To avoid problems caused by rounding errors, this function computes log œÄ(k, x)
instead of œÄ(k, x). Some care is needed, since the function GetLogPosterior may be
called with ‚Äòimpossible‚Äô parameter values, for example some components of r may
be negative; in these cases, log 0 = ‚àí‚àûmust be returned.
Using the function GetLogPosterior to deÔ¨Åne the target density and using
the different move types described in section 4.5.2, we can now implement
algorithm 4.36.
The RJMCMC method can be implemented by the following R code. We start by
introducing names for the different move probabilities:
MCMC.prob.mu.move <- 4 / 10
MCMC.prob.r.move <- 4 / 10
MCMC.prob.k.move <- 1 / 10
MCMC.prob.rot.move <- 1 / 10
MCMC.move.names = c("mu", "r", "k", "rot")
MCMC.move.probabilities <- c(MCMC.prob.mu.move,
MCMC.prob.r.move,
MCMC.prob.k.move,
MCMC.prob.rot.move)
names(MCMC.move.probabilities) <- MCMC.move.names
Moves of types mŒº and mr depend on the parameters œÉŒº and œÉr, respectively.
Experimentation shows that the following values lead to reasonable acceptance rates:
MCMC.sigma.mu <- 0.28
MCMC.sigma.r <- 0.22
Next we deÔ¨Åne functions to compute the acceptance probabilities given in equa-
tion (4.52), equation (4.53), equation (4.55), equation (4.56), equation (4.57) and
equation (4.58).
GetMuMoveAlpha <- function(GetLogPi, mu1, mu2, r) {

338
APPENDIX C: ANSWERS TO THE EXERCISES
return(exp(GetLogPi(mu2, r) - GetLogPi(mu1, r)))
}
GetRadiusMoveAlpha <- function(GetLogPi, mu, r1, r2) {
return(exp(GetLogPi(mu, r2) - GetLogPi(mu, r1)))
}
GetLogPsi <- function(mu, r) {
log.p.mu <- sum(dunif(mu, -10, 10, log=TRUE))
log.p.r <- dunif(r, model.r.min, model.r.max, log=TRUE)
return(log.p.mu + log.p.r)
}
GetAddMoveAlpha <- function(GetLogPi, mu1, mu2, r1, r2) {
k.new <- length(r2)
a <- exp(GetLogPi(mu2, r2)
- GetLogPi(mu1, r1)
- GetLogPsi(mu2[,k.new], r2[k.new]))
return(ifelse(k.new == 2, a / 2, a))
}
GetRemoveMoveAlpha <- function(GetLogPi, mu1, mu2, r1, r2) {
k.old <- length(r1)
a <- exp(GetLogPi(mu2, r2)
+ GetLogPsi(mu1[,k.old], r1[k.old])
- GetLogPi(mu1, r1))
return(ifelse(k.old == 2, 2 * a, a))
}
With all these preparations in place, we can now implement algorithm 4.36:
RunRJMCMC <- function(GetLogPi, N, count.every=1) {
types <- length(MCMC.move.probabilities)
count.proposals <- rep(0, types)
names(count.proposals) <- MCMC.move.names
count.accepts <- rep(0, types)
names(count.accepts) <- MCMC.move.names
path.k <<- c()
for (j in 1:N) {
move.type = sample.int(types, 1,
prob=MCMC.move.probabilities)
count.proposals[move.type] <- count.proposals[move.type] + 1
k2 <- k

APPENDIX C: ANSWERS TO THE EXERCISES
339
Mu2 <- Mu
R2 <- R
if (move.type == 1) {
# try a mean move
a <- sample.int(k, 1)
Mu2[,a] <- rnorm(2, Mu[,a], MCMC.sigma.mu)
alpha <- GetMuMoveAlpha(GetLogPi, Mu, Mu2, R)
} else if (move.type == 2) {
# try a radius move
a <- sample.int(length(R), 1)
R2[a] <- rnorm(1, R[a], MCMC.sigma.r)
alpha <- GetRadiusMoveAlpha(GetLogPi, Mu, R, R2)
} else if (move.type == 3) {
if (k == 1 || runif(1) < 0.5) { # try to add a component
k2 <- k + 1
Mu2 <- cbind(Mu, runif(2, -10, 10))
R2 <- c(R, runif(1, model.r.min, model.r.max))
alpha <- GetAddMoveAlpha(GetLogPi, Mu, Mu2, R, R2)
} else {
# try to remove a component
k2 <- k - 1
# prevent R from converting Mu2 to a vector if k2==1:
Mu2 <- as.matrix(Mu[,-k], nrow=k2, ncol=2)
R2 <- R[-k]
alpha <- GetRemoveMoveAlpha(GetLogPi, Mu, Mu2, R, R2)
}
} else {
# cyclic right shift of components by a:
if (k > 1) {
a <- sample.int(length(R)-1, 1)
Mu2[,1:a] <- Mu[,(k-a+1):k]
Mu2[,(a+1):k] <- Mu[,1:(k-a)]
R2[1:a] <- R[(k-a+1):k]
R2[(a+1):k] <- R[1:(k-a)]
alpha <- 1
}
}
if (runif(1) < alpha) {
# accept the move
count.accepts[move.type] <- count.accepts[move.type] + 1
# store the updated values in the global namespace
k <<- k2
Mu <<- Mu2
R <<- R2
}
if (j %% count.every == 0) {
path.k <<- c(path.k, k)

340
APPENDIX C: ANSWERS TO THE EXERCISES
}
}
cat("acceptance rates for each move type:\n")
print(count.accepts / count.proposals, digits=3)
cat("\n")
}
The argument GetLogPi to the function RunRJMCMC must be a function which returns
the logarithm log œÄ(k, Œº,r). Since k can be found by inspecting Œº, the function
GetLogPi just takes Mu and R as arguments. The function uses the global variables k,
Mu and R to store the current state of the Markov chain. These variables need to be
set before RunRJMCMC is called, and they contain the Ô¨Ånal state of the Markov chain
on return from this function.
To test the function RunRJMCMC, we Ô¨Årst run the RJMCMC algorithm without any
observations, that is in the case where œÄ is the prior distribution:
k <- rpois(1, lambda=model.clusters.mean-1) + 1
Mu <- matrix(runif(2*k, -10, 10), nrow=2, ncol=k)
R <- runif(k, model.r.min, model.r.max)
RunRJMCMC(GetLogPrior, 10000)
# burn-in
RunRJMCMC(GetLogPrior, 1000000, count.every=100)
h <- hist(path.k, breaks=seq(-0.5, max(path.k) + 1, by=1),
prob=TRUE, xlab="k", ylab="probability",
main=NULL, col="gray80", border="gray20")
p <- c(0, dpois(0:9, lambda=model.clusters.mean-1))
points(0:10, p)
The resulting histogram is shown in Figure C.9.
Finally, we can run the function RunRJMCMC on data generated from the model:
k <- rpois(1, lambda=model.clusters.mean-1) + 1
Mu <- matrix(runif(2*k, -10, 10), nrow=2, ncol=k)
R <- runif(k, model.r.min, model.r.max)
obs <- GenerateMixtureSample(80)
GetLogPi <- function(mu, r) {
return(GetLogPosterior(mu, r, obs))
}
RunRJMCMC(GetLogPi, 5000)
# burn-in
RunRJMCMC(GetLogPi, 50000, count.every=100)
To visualise the results of the run, we deÔ¨Åne two auxiliary functions for plotting:
PlotObservations <- function(obs) {
plot(obs[1,], obs[2,], xlim=c(-13,13), ylim=c(-11,11),

APPENDIX C: ANSWERS TO THE EXERCISES
341
k
Probability
0
2
4
6
8
10
12
14
0.00
0.10
0.20
Figure C.9
A histogram showing the distribution of k in the RJMCMC algorithm
from exercise E4.9, in the case where there are no observations and the target
distribution coincides with the prior distribution œÄ. The bars in the histogram give the
frequencies observed in one run of the algorithm, the circles denote exact probabilities
expected for the stationary distribution. Both sets of values coincide well, giving
conÔ¨Ådence that the implementation of the algorithm works correctly.
asp=1, cex=0.5, xlab="", ylab="")
rect(-10, -10, 10, 10)
}
PlotState <- function(mu, r) {
symbols(mu[1,], mu[2,], circles=r,
inches=FALSE, add=TRUE)
symbols(mu[1,], mu[2,], circles=1.5*r,
inches=FALSE, add=TRUE)
symbols(mu[1,], mu[2,], circles=2*r,
inches=FALSE, add=TRUE)
}
Using these functions, we can plot the Ô¨Ånal state of the RJMCMC Markov chain,
together with a histogram of K j.
par(mai=c(0.35, 0.35, 0.05, 0.05))
PlotObservations(obs)
PlotState(Mu, R)
par(mai=c(0.65, 0.75, 0.15, 0.05))
hist(path.k, breaks=seq(-0.5, max(path.k) + 0.5, by=1), prob=TRUE,
xlab="K", ylab="probability",
main=NULL, col="gray80", border="gray20")
The resulting plot is shown in Figure 4.9.

342
APPENDIX C: ANSWERS TO THE EXERCISES
C.5
Answers for Chapter 5
Solution E5.1
The function to generate the ABC samples is modelled directly
after the steps described in example 5.4. These steps are executed in a loop until N
samples are accumulated.
S <- function(x) {
return(c(sum(x), sum(x^2)) / n)
}
ABC.basic <- function(N, n, s, delta) {
res.theta <- matrix(nrow=N, ncol=2) # col. 1: mu, col. 2: sigma
res.s <- matrix(nrow=N, ncol=2) # row j = s_j
j <- 1
k <- 1
while (k <= N) {
mu <- runif(1, -10, 10)
sigma <- rexp(1)
X <- rnorm(n, mu, sigma)
sj <- S(X)
if (sum((sj-s)^2) <= delta^2) {
res.theta[k,] <- c(mu, sigma)
res.s[k,] <- sj
k <- k + 1
}
j <- j + 1
}
cat("delta=", delta, ": ", j/N, " proposals/sample\n",
sep="")
return(list(theta=res.theta, s=res.s))
}
The newly deÔ¨Åned function ABC.basic does not only return the samples Œ∏ jk, but also
the values s jk. The values s j are sometimes useful, for example in methods which
weight the samples according to the discrepancy s j ‚àís‚àó. The function ABC.basic
can be used as follows:
n <- 20
s.obs <- c(6.989, 52.247)
X <- ABC.basic(100, n, s.obs, 0.1)
Figure 5.1 shows histograms of the output values X$theta[,1] (corresponding to Œº)
and X$theta[,2] (corresponding to œÉ) for different values of Œ¥.

APPENDIX C: ANSWERS TO THE EXERCISES
343
Solution E5.2
Using the function ABC.basic from exercise E5.1, we can implement
algorithm 5.6 as follows:
ABC.regression <- function(N, n, s, delta) {
samples <- ABC.basic(N, n, s, delta)
S <- cbind(samples$s, 1)
C <- t(S) %*% samples$theta
B.hat <- solve(t(S) %*% S, C)
beta.hat <- B.hat[1:2, 1:2]
correction <- t((s - t(samples$s))) %*% beta.hat
theta.tilde <- samples$theta + correction
return(list(theta=theta.tilde))
}
Here, we return a list with just one element theta so that ABC.regression can be used
as a drop-in replacement for ABC.basic. Different from the function in exercise E5.1,
we do not return the s j, since the correction makes these values largely meaningless
for the returned values. The function ABC.regression can be called as follows:
n <- 20
s.obs <- c(6.989, 52.247)
samples <- ABC.basic(100, n, s.obs, 0.1)
Solution E5.3
Algorithm 5.15 can be implemented in R as follows:
bias.boot <- function(theta.hat, x, N=10000) {
n <- length(x)
theta.star <- c()
for (j in 1:N) {
X.star <- sample(x, n, replace=TRUE)
theta.star[j] <- theta.hat(X.star)
}
cat("RMSE* = ", sd(theta.star)/sqrt(N), "\n", sep="")
return(mean(theta.star) - theta.hat(x))
}
The Ô¨Årst argument of this function must be an implementation of the estimator in
question. For the estimator ÀÜœÉ 2 from the question we can use the following function.
sigma.squared <- function(x) {
x.bar <- mean(x)
return(mean((x - x.bar)^2))
}

344
APPENDIX C: ANSWERS TO THE EXERCISES
The bootstrap estimate for the bias can then be computed with calls such as:
bias.boot(sigma.squared, x)
To test the function, we use a generated data set x:
x <- rnorm(100)
The resulting estimate of the bias is then
> bias.boot(sigma.squared, x)
RMSE* = 0.001194376
[1] -0.009388906
Since this result is close to the theoretical value ‚àíVar(X)/‚àön = ‚àí0.1 for the bias,
we can assume that our implementation works correctly.
The Monte Carlo sample size N affects the size of error in the approximation
(5.22). To justify our choice of N we Ô¨Årst note that, by proposition 3.14, the magnitude
of this error is given by the root-mean-square error
RMSE = stdev‚àó
f (X‚àó)
	
‚àö
N
.
The function bias.boot prints an estimate for the RMSE; for the example the value
is approximately 0.0012. With 95% probability the magnitude of the Monte Carlo
error is less than 1.96 ¬∑ RMSE ‚âà0.0023. Thus, we expect the error introduced by the
Monte Carlo integration to be approximately 25%. Since this ratio is still quite large,
we increase the value of N from 10 000 to 100 000 by specifying the optional, third
argument to bias.boot:
> bias.boot(sigma.squared, x, 100000)
RMSE* = 0.0003801055
[1] -0.0107199
This brings the Monte Carlo error down to about 7% which seems acceptable, since
the result is only approximate even in the absence of Monte Carlo error.
Solution E5.4
If we interpret each head as X = 1 and each tail as X = 0, then
the probability p of heads can be written as p = E(X), that is p is the mean of the
distribution of X, and our estimate is ÀÜp = n
i=1 Xi/n = ¬ØX. The bootstrap estimate
of the standard error of the mean is
se‚àó( ÀÜp) =



 1
n2
n

i=1

Xi ‚àí¬ØX
	2.

APPENDIX C: ANSWERS TO THE EXERCISES
345
Each of the 1600 terms in the sum where Xi = 1 contributes (1 ‚àí16/25)2 = 92/252.
Each of the 900 terms in the sum where Xi = 0 contributes (0 ‚àí16/25)2 = 162/252.
Thus we get
se‚àó( ÀÜp) =

1
n2

1600 ¬∑ 92
252 + 900 ¬∑ 162
252

=

1
n2
100 ¬∑ 16 ¬∑ 9 ¬∑ (9 + 16)
(16 + 9)2
= 10 ¬∑ 4 ¬∑ 3
n ¬∑ 5
=
24
2500.
This is the bootstrap estimate of the standard error of ÀÜp.
Solution E5.5
We can implement algorithm 5.20 in R as follows:
GetSimpleBootstrapCI <- function(x, theta.hat, N, alpha=0.05) {
# generate the bootstrap samples
n <- length(x)
theta.star <- c()
for (j in 1:N) {
X.star <- sample(x, n, replace=TRUE)
theta.star[j] <- theta.hat(X.star)
}
# construct the confidence interval
t <- theta.hat(x)
l <- ceiling(0.5 * alpha * N)
u <- ceiling((1 - 0.5 * alpha) * N)
theta.star <- sort(theta.star)
return(c(2 * t - theta.star[u], 2 * t - theta.star[l]))
}
In order to test GetSimpleBootstrapCI, we consider conÔ¨Ådence intervals for the
mean. Algorithm 5.20 requires the plug-in estimator for the parameter in question;
from example 5.13 we know that the plug-in estimator for the mean is the average
¬Øx of the sample x. This estimator, in form of the built-in R function mean, can be
used as the parameter theta.hat of GetSimpleBootstrapCI. To check our function,
we compare the output to the exact conÔ¨Ådence interval. Assuming the variance is not

346
APPENDIX C: ANSWERS TO THE EXERCISES
known, the exact conÔ¨Ådence interval is given by
[U, V ] =

¬Øx ‚àít1‚àíŒ±/2,n‚àí1 ÀÜœÉ
‚àön
, ¬Øx + t1‚àíŒ±/2,n‚àí1 ÀÜœÉ
‚àön
 
,
where ÀÜœÉ 2 = n
i=1(xi ‚àí¬Øx)2/(n ‚àí1) and t1‚àíŒ±/2,n‚àí1 denotes the 1 ‚àíŒ±/2 quantile of
the t-distribution with n ‚àí1 degrees of freedom. We can compute the exact conÔ¨Å-
dence interval using the following R code.
GetExactCI <- function(x, alpha=0.05) {
n <- length(x)
m <- mean(x)
s <- sd(x)
c <- qt(1 - 0.5*alpha, n-1)
return(c(m - c * s / sqrt(n), m + c * s / sqrt(n)))
}
Finally, in order to easily perform repeated comparisons, we write a function
which, for a given sample size, prints the output of both GetSimpleBootstrapCI and
GetExactCI to the screen.
Test <- function(n, alpha=0.05) {
X <- rnorm(n)
ci.bootstrap <- GetSimpleBootstrapCI(X, mean, 1000)
cat("bootstrap CI: [", ci.bootstrap[1], ", ",
ci.bootstrap[2], "]\n", sep="")
ci.exact <- GetExactCI(X)
cat("exact CI:
[", ci.exact[1], ", ",
ci.exact[2], "]\n", sep="")
}
Using this function, we can perform tests as follows:
> Test(10)
bootstrap CI: [-0.5593357, 0.206685]
exact CI:
[-0.6447165, 0.3395043]
> Test(50)
bootstrap CI: [-0.08583986, 0.448177]
exact CI:
[-0.1023353, 0.4421098]
> Test(100)
bootstrap CI: [-0.1195222, 0.2811508]
exact CI:
[-0.1205862, 0.2828386]
The output shows that there is reasonably good agreement between the bootstrap
conÔ¨Ådence intervals and the theoretically exact conÔ¨Ådence intervals. Thus, we can
assume that our implementation of algorithm 5.20 works correctly.

APPENDIX C: ANSWERS TO THE EXERCISES
347
Solution E5.6
First we generate the test data set:
X <- rnorm(25)
From example 5.14 we know that the plug-in estimate for the variance is given
by ÀÜœÉn(x) = n
i=1(xi ‚àí¬Øx)2/n. Since the built-in R function var uses n ‚àí1 instead of
n, we replace var by our own version:
PlugInVar <- function(x) {
return(mean((x - mean(x))^2))
}
Next, we write a function to estimate the standard deviation of the boundary
points and the average width of the conÔ¨Ådence interval for the variance, always using
the data set X we created above:
PrintStdDevAndMean <- function(N) {
lower <- c()
upper <- c()
width <- c()
for (i in 1:1000) {
ci <- GetSimpleBootstrapCI(X, PlugInVar, N);
lower[i] <- ci[1]
upper[i] <- ci[2]
width[i] <- ci[2] - ci[1]
}
cat("lower bound stddev: ", sd(lower), "\n", sep="")
cat("upper bound stddev: ", sd(upper), "\n", sep="")
cat("average width: ", mean(width), "\n", sep="")
}
Finally, we call this function for different values of N:
> PrintStdDevAndMean(1000)
lower bound stddev: 0.01664069
upper bound stddev: 0.0102032
average width: 0.6364756
> PrintStdDevAndMean(2000)
lower bound stddev: 0.01174421
upper bound stddev: 0.007007113
average width: 0.6358301
> PrintStdDevAndMean(4000)
lower bound stddev: 0.008348285
upper bound stddev: 0.005002864
average width: 0.6371888

348
APPENDIX C: ANSWERS TO THE EXERCISES
As expected, the standard deviation of and thus the error in the boundaries decreases.
But even for N = 4000 the standard deviation of either boundary is still approximately
1% of the width of the interval, so the error is still signiÔ¨Åcant.
Solution E5.7
The BCa algorithm 5.21 can be implemented in R as follows:
GetBCaBootstrapCI <- function(x, theta.hat, N, alpha=0.05) {
# generate the bootstrap samples
n <- length(x)
theta.star <- c()
for (j in 1:N) {
X.star <- sample(x, n, replace=TRUE)
theta.star[j] <- theta.hat(X.star)
}
# compute z.hat and a.hat
z.hat <- qnorm(sum(theta.star < theta.hat(x)) / N)
theta.jack <- c()
for (i in 1:n) {
theta.jack[i] <- theta.hat(x[-i])
}
y <- theta.jack - mean(theta.jack)
a.hat <- (sum(y^3) / (6 * sum(y^2)^1.5))
# pick out the BCa quantiles
p <- c(0.5 * alpha, 1 - 0.5 * alpha)
w <- z.hat + qnorm(p)
q <- pnorm(z.hat + w / (1 - a.hat * w))
idx <- ceiling(q * N)
theta.star <- sort(theta.star)
return(theta.star[idx])
}
Solution E5.8
The Monte Carlo estimate for the coverage probabilities can be
implemented in R as follows:
TestConfInt <- function(get.ci, gen.sample, n, theta, theta.hat) {
res <- c(0, 0, 0)
names(res) <- c("left", "inside", "right")
for (i in 1:1000) {
x <- gen.sample(n, theta)
ci <- get.ci(x, theta.hat, 5000)
if (theta < ci[1]) {
res[1] <- res[1] + 1

APPENDIX C: ANSWERS TO THE EXERCISES
349
} else if (theta > ci[2]) {
res[3] <- res[3] + 1
} else {
res[2] <- res[2] + 1
}
}
return(res / sum(res))
}
Using this function, we can now compare the two different methods for estimating
conÔ¨Ådence intervals.
CompareConfInts <- function(gen.sample, n, theta, theta.hat) {
res.simple <- TestConfInt(GetSimpleBootstrapCI, gen.sample,
n, theta, theta.hat)
res.BCa <- TestConfInt(GetBCaBootstrapCI, gen.sample,
n, theta, theta.hat)
res <- rbind(res.simple, res.BCa)
rownames(res) <- c("simple", "BCa")
return(res)
}
# test 1: mean of standard normal random variables
print(CompareConfInts(rnorm, 10, 0, mean))
print(CompareConfInts(rnorm, 50, 0, mean))
print(CompareConfInts(rnorm, 100, 0, mean))
# test 2: mean of exponentially distributed random variables
gen2 <- function(n, mu) {
return(rexp(n, 1/mu))
}
print(CompareConfInts(gen2, 10, 1, mean))
print(CompareConfInts(gen2, 50, 1, mean))
print(CompareConfInts(gen2, 100, 1, mean))
# test 3: standard deviation of normal random variables
gen3 <- function(n, sigma) {
return(rnorm(n, 0, sigma))
}
theta.hat3 <- function(x) {
x.bar <- mean(x)
return(sqrt(sum((x - x.bar)^2)/length(x)))
}
print(CompareConfInts(gen3, 10, 1, theta.hat3))
print(CompareConfInts(gen3, 50, 1, theta.hat3))
print(CompareConfInts(gen3, 100, 1, theta.hat3))

350
APPENDIX C: ANSWERS TO THE EXERCISES
The resulting output of one run of this program is summarised in Table 5.1. The
results shown in the table indicate that for the test problems considered here, the
performance of both methods is comparable. The data also show that the quality of
the conÔ¨Ådence intervals improves as the sample size n increases.
C.6
Answers for Chapter 6
Solution E6.1
We construct the solution iteratively, starting at time t = 0 and
then computing Bih from B(i‚àí1)h for i = 1, 2, . . . , n by adding N(0, h)-distributed
random increments as described in algorithm 6.6. In R, this can be implemented as
follows:
BrownianMotion1d <- function(t) {
s.prev <- 0
# initial time
B <- 0
# initial value
res <- c()
for (s in t) {
h <- s - s.prev
dB <- rnorm(1, 0, sqrt(h))
B <- B + dB
res <- c(res, B)
s.prev <- s
}
return(res)
}
Since R has a built-in function cumsum for computing cumulative sums, we can use this
function to write a shorter and more efÔ¨Åcient implementation of the same algorithm:
BrownianMotion1d <- function(t) {
n <- length(t)
h <- t - c(0, t[-n])
dB <- rnorm(n, 0, sqrt(h))
B <- cumsum(dB)
return(B)
}
(C.1)
We test the new function BrownianMotion1d by creating a plot of one path of a
Brownian motion until time T = 10:
t <- seq(0, 100, by=0.01)
B <- BrownianMotion1d(t)
plot(t, B, type="l", xlab="t", ylab=expression(B[t]))
The resulting plot is shown in Figure 6.1.

APPENDIX C: ANSWERS TO THE EXERCISES
351
Solution E6.2
We construct the solution iteratively, starting at time t = 0 and
then computing Bih from B(i‚àí1)h for i = 1, 2, . . . , n by adding N(0, h)-distributed
random increments as described in algorithm 6.6. In R, this can be implemented as
follows:
BrownianMotion <- function(t, d=1) {
n <- length(t)
sqrt.h <- sqrt(t - c(0, t[-n]))
B <- c()
for (i in 1:d) {
dB <- rnorm(n, 0, sqrt.h)
B <- cbind(B,cumsum(dB))
}
return(B)
}
We test the new function BM by creating a plot of one path of a two-dimensional
Brownian motion until time T = 10:
n <- 32000
t <- seq(0, 10, length.out=n+1)
B <- BrownianMotion(t, d=2)
plot(B[,1], B[,2], asp=1, type="l", lwd=0.1,
xlab=expression(B[t]^(1)), ylab=expression(B[t]^(2)))
col <- gray(n:0/n*0.8)
segments(B[1:(n-1),1], B[1:(n-1),2], B[2:n,1], B[2:n,2],
asp=1, col=col)
The resulting plot is shown in Figure 6.2.
Solution E6.3
A function B to return samples from a single Brownian path can be
implemented in R as follows:
t.known <- 0;
# times sampled so far
B.known <- 0;
# values of B corresponding to the times
in t.known
B <- function(times) {
res <- c()
for (s in times) {
i <- max(c(which(t.known < s), 1))
r <- t.known[i]
if (s == r) {
Bs <- B.known[i]
} else {

352
APPENDIX C: ANSWERS TO THE EXERCISES
if (i < length(t.known)) {
t <- t.known[i+1]
mu <- B.known[i]*(t-s)/(t-r)+B.known[i+1]*(s-r)/(t-r)
sigma <- sqrt((t-s)*(s-r)/(t-r))
} else {
mu <- B.known[i]
sigma <- sqrt(s-r)
}
Bs <- rnorm(1, mu, sigma)
t.known <<- append(t.known, s, after=i)
B.known <<- append(B.known, Bs, after=i)
}
res <- c(res, Bs)
}
return(res)
}
The function works by storing all values simulated so far in the global variable
B.known and the corresponding times in the global variable t.known.
The function B can be used like an ordinary function, the argument can be
either a single time or a vector of times. The following commands illustrate how
to use B:
t <- seq(0, 20, by=2)
plot(t, B(t), type="l", ylim=c(min(B(t))-0.5, max(B(t))+0.5),
ylab=expression(B[t]), col="gray", lwd=1.4)
t <- seq(0, 20, by=0.02)
lines(t, B(t))
The plot created by these commands is shown in Figure 6.4.
Solution E6.4
To generate a Brownian bridge, we Ô¨Årst generate a Brownian
motion and then use equation (6.2) to convert this into a Brownian bridge. Using the
function BrownianMotion1d from listing (C.1), we can implement this method in R as
follows:
BrownianBridge <- function(s, r=0, a=0, t=1, b=0) {
s.shifted <- c(s-r, t-r)
# make sure we sample B_{t-r}
B <- BrownianMotion1d(s.shifted)
Bt <- B[length(B)]
X <- B + a - s.shifted / (t - r) * (Bt - b + a)
return(X[-length(X)])
}

APPENDIX C: ANSWERS TO THE EXERCISES
353
Solution E6.5
We can use the following function to simulate a path of a geometric
Brownian motion, based on the function BrownianMotion1d from listing (C.1):
GeometricBM <- function(t, x0, alpha, beta, B) {
if (missing(B)) {
B <- BrownianMotion1d(t)
}
X <- x0 * exp(alpha * B + beta * t)
return(X)
}
As in the solution to exercise E6.1, we use the cumsum function to efÔ¨Åciently simulate
the Brownian motion B. We can plot paths of the simulated geometric Brownian
motion with commands such as:
t <- seq(0, 10, by=0.01)
X <- GeometricBM(t, x0=1, alpha=1, beta=-0.1)
plot(t, X, type="l", xlab="t", ylab=expression(X[t]))
The plot resulting from one run of this program is shown in Figure 6.5.
Solution E6.6
From lemma 6.9 we know that Xt = exp(Bt ‚àít/2) has expectation
E(Xt) = 1 ¬∑ exp

(1/2 ‚àí1/2)t
	
= exp(0) = 1.
We can use the following R code to generate Monte Carlo estimates for this value
with t = 0, 1, 2, . . . , 100 and to generate a plot of the resulting estimates:
N <- 1e6
tt <- seq(0, 100, by=1)
xx <- c()
for (t in tt) {
Bt <- rnorm(N, 0, sqrt(t))
Xt <- exp(Bt - 0.5*t)
xx <- c(xx, mean(Xt))
}
plot(tt, xx, ylim=c(0,3), xlab="t", ylab=expression(E(X[t])))
abline(h=1)
The plot resulting from one run of this program is shown in Figure 6.6. The Ô¨Ågure
shows that for t ‚â§15 the Monte Carlo estimates are accurate and for 15 < t ‚â§40
the estimates have high variance but may be still acceptable. For t > 40 most of the
estimates are close to 0 instead of being close to the exact value 1, and thus for this
range of times t the sample size N = 106 is much too small.

354
APPENDIX C: ANSWERS TO THE EXERCISES
Solution E6.7
To solve SDE (6.17) with the given drift and diffusion coefÔ¨Åcient,
we implement the Euler-Maruyama method from algorithm 6.12. This can be done
by using an R function such as:
EulerMaruyama1d <- function(t, x0, mu, sigma, B) {
n <- length(t)
h <- t - c(0, t[-n])
if (missing(B)) {
dB <- rnorm(n, 0, sqrt(h))
} else {
if (length(B) != n) {
stop("lengths of t and B don‚Äôt match (",
n, " vs. ", length(B), ")")
}
dB <- B - c(0, B[-n])
}
path <- c()
s = 0
X = x0
for (i in 1:n) {
X <- X + mu(s, X) * h[i] + sigma(s, X) * dB[i]
s <- t[i]
path[i] <- X
}
return(path)
}
A function which works for d > 1 or m > 1 can be implemented as follows:
EulerMaruyama <- function(t, x0, mu, sigma, B) {
n <- length(t)
## dimension of the solution (from the initial condition)
d <- length(x0)
## dimension of the noise (from the columns of sigma)
m <- ncol(sigma(0, x0))
if (! is.numeric(m)) m <- 1;
h <- t - c(0, t[-n])
if (missing(B)) {
dB <- matrix(rnorm(n*m, 0, sqrt(h)), nrow=n, ncol=m)
} else {
B <- as.matrix(B)

APPENDIX C: ANSWERS TO THE EXERCISES
355
if (nrow(B) != n) {
stop("lengths of t and B don‚Äôt match (",
n, " vs. ", nrow(B), ")")
}
if (ncol(B) != m) {
stop("dimensions of sigma and B don‚Äôt match (",
m, " vs. ", ncol(B), ")")
}
dB = B - rbind(rep(0, d), as.matrix(B[-n,]))
}
path <- matrix(nrow=n, ncol=d)
s = 0
X = x0
for (i in 1:n) {
X <- X + mu(s, X) * h[i] + sigma(s, X) %*% dB[i,]
s <- t[i]
path[i,] <- X
}
return(path)
}
For one-dimensional SDEs, EulerMaruyama1d takes about half the time that
EulerMaruyama does to solve the same SDE.
In order to use the function EulerMaruyama, we have to provide implementations
of the drift Œº and of the diffusion coefÔ¨Åcient œÉ as R functions. For the given functions,
this can be done as follows:
mu <- function(t, x) { c(x[2], x[1]*(1-x[1]^2)) }
sigma <- function(t, x) {
ifelse(x[1]> 0 && x[2]> 0, 0.2, 0.03) * diag(2)
}
x0 <- c(-0.03, -0.49)
t <- seq(0, 15, by=0.001)
X <- EulerMaruyama(t, x0, mu, sigma)
Then the path of X in R2 can be plotted as follows:
plot(X[,1], X[,2], type="l")
The output, together with arrows visualising the drift Œº, is shown in Figure 6.7.
Solution E6.8
The Milstein scheme from algorithm 6.15 can be implemented in
R as shown in the following. Here we allow the functions mu and sigma to depend on

356
APPENDIX C: ANSWERS TO THE EXERCISES
the time t, in order to make the function more compatible with the EulerMaruyama1d
function from exercise E6.7.
Milstein1d <- function(t, x0, mu, sigma, sigma.prime, B) {
n <- length(t)
h <- t - c(0, t[-n])
if (missing(B)) {
dB <- rnorm(n, 0, sqrt(h))
} else {
if (length(B) != n) {
stop("lengths of t and B don‚Äôt match (",
n, " vs. ", length(B), ")")
}
dB <- B - c(0, B[-n])
}
path <- c()
s = 0
X = x0
for (i in 1:n) {
sig <- sigma(t, X)
X <- (X
+ mu(s, X) * h[i]
+ sigma(s, X) * dB[i]
+ 0.5 * sig * sigma.prime(s, X) * (dB[i]^2 - h[i]))
s <- t[i]
path[i] <- X
}
return(path)
}
The function can be used as follows:
mu <- function(t, x) { 0.1 }
sigma <- function(t, x) { x }
sigma.prime <- function(t, x) { 1 }
t <- seq(0, 20, length.out=10001)
X <- Milstein1d(t, 1, mu, sigma, sigma.prime)
plot(t, X, type="l")
Solution E6.9
In order to determine the strong error using Monte Carlo integration,
we will need to solve SDE (6.20) many times, the and efÔ¨Åciency of the method
becomes important. Since the strong error in (6.23) only depends on the Ô¨Ånal point XT

APPENDIX C: ANSWERS TO THE EXERCISES
357
of the path, we introduce a specialised, faster version of the function EulerMaruyama1d
(see Exercise 6.7), which returns only the endpoint instead of the whole path.
EulerMaruyama1dEndpoint <- function(t, x0, mu, sigma, B) {
n <- length(t)
h <- t - c(0, t[-n])
if (missing(B)) {
dB <- rnorm(n, 0, sqrt(h))
} else {
if (length(B) != n) {
stop("lengths of t and B don‚Äôt match (",
n, " vs. ", length(B), ")")
}
dB <- B - c(0, B[-n])
}
s = 0
X = x0
for (i in 1:n) {
X <- X + mu(s, X) * h[i] + sigma(s, X) * dB[i]
s <- t[i]
}
return(X)
}
As a result of the simpliÔ¨Åed code, a call to EulerMaruyama1dEndpoint takes only
approximately 30% of the time EulerMaruyama1d does. A similar simpliÔ¨Åcation can
be applied to Milstein1d from exercise E6.8:
Milstein1dEndpoint <- function(t, x0, mu, sigma, sigma.prime, B) {
n <- length(t)
h <- t - c(0, t[-n])
if (missing(B)) {
dB <- rnorm(n, 0, sqrt(h))
} else {
if (length(B) != n) {
stop("lengths of t and B don‚Äôt match (",
n, " vs. ", length(B), ")")
}
dB <- B - c(0, B[-n])
}
s = 0
X = x0
for (i in 1:n) {

358
APPENDIX C: ANSWERS TO THE EXERCISES
sig <- sigma(t, X)
X <- (X
+ mu(s, X) * h[i]
+ sigma(s, X) * dB[i]
+ 0.5 * sig * sigma.prime(s, X) * (dB[i]^2 - h[i]))
s <- t[i]
}
return(X)
}
Next, we deÔ¨Åne the drift and diffusion coefÔ¨Åcient.
alpha <- 1
beta <- 0.4
mu <- function(t,x) { (0.5*alpha^2 + beta) * x }
sigma <- function(t,x) { alpha * x }
sigma.prime <- function(t,x) { alpha }
x0 <- 1
# initial value
T <- 5
# time horizon
Now we have to simulate solutions of the SDE repeatedly, for different grid sizes,
and to compute the strong error from the results. This can be done as follows:
n.max <- 1024
# largest discretisation parameter to try
n.min <- 64
# smallest discretisation parameter to try
K <- 9
# number of resolution steps
n <- round(exp(seq(log(n.min), log(n.max), length.out=K)))
N <- 20000
# number of runs to average over
samples.euler <- matrix(nrow=N, ncol=K)
samples.milstein <- matrix(nrow=N, ncol=K)
progress <- txtProgressBar(min=0, max=N, style=3)
t <- seq(0, T, length.out=n.max+1)
for (j in 1:N) {
B <- c(0, cumsum(rnorm(n.max, 0, sqrt(t[2:(n.max+1)]-
t[1:n.max]))))
X.exact <- x0 * exp(alpha*B + beta*t)
Xt.exact <- X.exact[n.max+1]
for (k in 1:K) {
I <- round(seq(1, n.max+1, length.out=n[k]+1))
Xt.euler <- EulerMaruyama1dEndpoint(t[I], x0, mu, sigma, B[I])
samples.euler[j,k] <- abs(Xt.euler - Xt.exact)

APPENDIX C: ANSWERS TO THE EXERCISES
359
Xt.milstein <- Milstein1dEndpoint(t[I], x0, mu, sigma,
sigma.prime, B[I])
samples.milstein[j,k] <- abs(Xt.milstein - Xt.exact)
}
setTxtProgressBar(progress, j)
}
close(progress)
error.euler <- colMeans(samples.euler)
error.milstein <- colMeans(samples.milstein)
Finally, we use the resulting data to create a plot:
h <- T / n
plot(h, error.euler, pch="x",
xlab="h", ylab="strong error",
ylim=range(c(error.euler, error.milstein)),
log="xy")
points(h, error.milstein, pch="o")
The resulting plot, together with conÔ¨Ådence intervals for each measurement, is
shown in Figure 6.8.
Solution E6.10
First, we have to implement the Euler-Maruyama scheme and
the Milstein scheme for SDE (6.20). To speed up the computation, we perform N
simulations at the same time, thus reducing the required number of loops in the R
program:
alpha <- 1
beta <- 0.4
x0 <- 1
# initial value
T <- 5
# time horizon
EulerMaruyama <- function(n, N) {
h <- T / n
X <- rep(x0, times=N)
for (i in 1:n) {
dB <- rnorm(N, 0, sqrt(h))
X <- (X
+ (0.5 * alpha^2 + beta) * X * h
+ alpha * X * dB)
}
return(X)

360
APPENDIX C: ANSWERS TO THE EXERCISES
}
Milstein <- function(n, N) {
h <- T / n
X <- rep(x0, times=N)
for (i in 1:n) {
dB <- rnorm(N, 0, sqrt(h))
X <- (X
+ (0.5 * alpha^2 + beta) * X * h
+ alpha * X * dB
+ 0.5 * alpha^2 * X * (dB^2 - h))
}
return(X)
}
Next, we implement the test function f :
prob <- 0.6
threshold <- x0 * exp(alpha*qnorm(prob, 0, sqrt(T)) + beta*T)
f <- function(x) {
as.numeric(x <= threshold)
}
Now we have to solve the SDE repeatedly for different grid sizes and to compute the
weak error. This can be done as follows:
n.max <- 1024
# largest discretisation parameter to try
n.min <- 64
# smallest discretisation parameter to try
K <- 9
# number of resolution steps
n <- round(exp(seq(log(n.min), log(n.max), length.out=K)))
N <- 10000000
# number of runs to average over
mean.euler <- c()
mean.milstein <- c()
sd.euler <- c()
sd.milstein <- c()
progress <- txtProgressBar(min=0, max=2*K, style=3)
for (k in 1:K) {
Xt.euler <- f(Euler--Maruyama(n[k], N))
mean.euler[k] <- mean(Xt.euler)
sd.euler[k] <- sd(Xt.euler)
setTxtProgressBar(progress, 2*k-1)
Xt.milstein <- f(Milstein(n[k], N))
mean.milstein[k] <- mean(Xt.milstein)
sd.milstein[k] <- sd(Xt.milstein)

APPENDIX C: ANSWERS TO THE EXERCISES
361
setTxtProgressBar(progress, 2*k)
}
close(progress)
exact <- prob
error.euler <- abs(mean.euler - exact)
error.milstein <- abs(mean.milstein - exact)
Finally, we use the resulting data to create a plot:
h <- T / n
plot(h, error.euler, pch="x",
xlab="h", ylab="weak error",
ylim=range(c(error.euler, error.milstein)),
log="xy")
points(h, error.milstein, pch="o")
This completes the answers.
Solution E6.11
A basic Monte Carlo estimate for the probability that X exceeds a
given level c can be based on the following R code.
f <- function(X, c) {
return(as.numeric(max(X) > c))
}
x0 <- 0
T <- 5
t <- seq(0, T, by=0.01)
mu <- function(t, x) { -x }
sigma <- function(t, x) { 1.0 }
MC.sample <- function(N, c) {
res <- c()
for (i in 1:N) {
X <- EulerMaruyama1d(t, x0, mu, sigma)
res[i] <- f(X, c)
}
return(res)
}
For c = 2.5, we can use the function MC.sample as follows:
N <- 10000

362
APPENDIX C: ANSWERS TO THE EXERCISES
Z <- MC.sample(N, 2.5)
m <- mean(Z)
s <- sd(Z)/sqrt(N)
cat("estimate for p: ", m, "\n", sep="")
cat("estimate for RMSE: ", sd(Z)/sqrt(N), "\n", sep="")
cat("estimate for CI: [", m - 1.96*s, ", ", m + 1.96*s, "]\n",
sep="")
In the estimation of the root-mean squared error we neglected the discretisation error
of the Euler-Maruyama method and only use the Monte Carlo error. The true error
will be slightly bigger than the obtained estimate, due to the bias introduced by the
discretisation error. The output of one run of the program is as follows:
estimate for p: 0.007
estimate for RMSE: 0.0008337683
CI = [0.005365814, 0.008634186]
This completes our solution of exercise E6.11.
Solution E6.12
An importance sampling estimate for the probability that X exceeds
a given level c can be based on the following R code.
q <- 0.5
mu.tilde <- function(t, x) { -q*x }
phi.over.psi <- function(t, Y) {
n <- length(t)
h <- t[-1] - t[-n]
dY <- Y[-1] - Y[-n]
stoch.int <- sum(Y[-n] * dY)
int <- sum(Y[-n]^2 * h)
return(exp(-(1-q)*stoch.int - .5*(1-q*q)*int))
}
IS.sample <- function(N, c) {
res <- c()
for (i in 1:N) {
Y <- EulerMaruyama1d(t, x0, mu.tilde, sigma)
res[i] <- f(Y, c) * phi.over.psi(t, Y)
}
return(res)
}
For c = 3.4 and N = 200 000, we can use the function IS.sample as follows:
N <- 200000

APPENDIX C: ANSWERS TO THE EXERCISES
363
Z <- IS.sample(N, 3.2)
m <- mean(Z)
s <- sd(Z)/sqrt(N)
cat("estimate for p: ", m, "\n", sep="")
cat("estimate for RMSE: ", sd(Z)/sqrt(N), "\n", sep="")
cat("estimate for CI: [", m - 1.96*s, ", ", m + 1.96*s, "]\n",
sep="")
The output of one run of the program is as follows:
estimate for p: 4.241444e-05
estimate for RMSE: 3.296227e-06
estimate for CI: [3.595384e-05, 4.887505e-05]
Solution E6.13
Algorithm 6.29 can be implemented as shown in the following. In
the program we use the absolute value inside the square roots ‚àö|Vt| in order to avoid
problems when Vt temporarily takes negative values caused by discretisation error.
Heston <- function(t, S0, V0, r, lambda, sigma, xi, rho) {
n <- length(t)
h <- t - c(0, t[-n])
dB <- matrix(rnorm(2*n, 0, sqrt(h)), nrow=n, ncol=2)
sigma.square <- sigma^2
rho.prime <- sqrt(1 - rho^2)
path <- matrix(nrow=n, ncol=2)
S <- S0
V <- V0
for (i in 1:n) {
sqrt.V = sqrt(abs(V))
S <- S + r * S * h[i] + S * sqrt.V * dB[i,1]
V <- (V + lambda * (sigma.square - V) * h[i]
+ xi * sqrt.V * (rho * dB[i,1] + rho.prime * dB[i,2]))
path[i,1] <- S
path[i,2] <- V
}
return(path)
}
We pre-compute sigma^2 and sqrt(1 - rho^2) outside the loop in order to avoid
unnecessary, repeated evaluations of the squares and the square root. The function
can be used as follows:
t <- seq(0, 5, by=0.001)

364
APPENDIX C: ANSWERS TO THE EXERCISES
X <- Heston(t, S0=1, V0=0.16, r=1.02,
lambda=1, sigma=1, xi=1, rho=-0.5)
plot(t, X[,1], type="l")
plot(t, X[,2], type="l")
The resulting plot is shown in Figure 6.13.
Solution E6.14
The Monte Carlo estimate requires us to solve SDE (6.43) many
times in a row. To reduce the time required for computing these estimates, we slightly
modify the code from exercise E6.13 to make it faster: since we are only interested
in the Ô¨Ånal value ST , there is no need to store the whole paths of S and V , and we can
also assume a Ô¨Åxed step size h = T/n for the Euler scheme. The resulting, simpliÔ¨Åed
function is as follows:
HestonEndpointS <- function(n) {
h <- T/n
dB <- matrix(rnorm(2*n, 0, sqrt(h)), nrow=n, ncol=2)
sigma.square <- sigma^2
rho.prime <- sqrt(1 - rho^2)
S <- S0
V <- V0
for (i in 1:n) {
sqrt.V = sqrt(abs(V))
S <- S + r * S * h + S * sqrt.V * dB[i,1]
V <- (V + lambda * (sigma.square - V) * h
+ xi * sqrt.V * (rho * dB[i,1] + rho.prime * dB[i,2]))
}
return(S)
}
To compute the Monte Carlo estimate, we have to call this function repeatedly, with
the given parameters, and we have to apply f to the results.
r <- 1.02
lambda <- 1
sigma <- 0.5
xi <- 1
rho <- -0.5
S0 <- 1
V0 <- 0.16
T <- 1
K <- 3

APPENDIX C: ANSWERS TO THE EXERCISES
365
f <- function(s) {
exp(-r*T) * max(s - K, 0)
}
MC.estimate <- function(n, N) {
C <- replicate(N, f(HestonEndpointS(n)))
est <- mean(C)
mse <- var(C) / N
return(list(est=est, mse=mse))
}
Estimates can now be obtained using calls such as:
> MC.estimate(100, 10000)
C=0.1147109, MSE=5.295385e-06
For the speciÔ¨Åed parameters, our estimate for the option price is C = 0.1139534,
with an estimated mean squared error of 5.3 ¬∑ 10‚àí6.
Solution E6.15
To implement the multilevel algorithm 6.26, we modify the func-
tion HestonEndpointS from exercise E6.14 to compute the solution of the SDE for
discretisation parameters n and n/m simultaneously.
MLMCSample <- function(n, m) {
if (n == m) return(f(HestonEndpointS(n)))
if (n %% m != 0 || n <= m) stop("invalid grid size")
h <- T/n
dB <- matrix(rnorm(2*n, 0, sqrt(h)), nrow=n, ncol=2)
sigma.square <- sigma^2
rho.prime <- sqrt(1 - rho^2)
S <- S0
V <- V0
Sm <- S0
Vm <- V0
dBm <- c(0, 0)
for (i in 1:n) {
sqrt.V = sqrt(abs(V))
S <- S + r * S * h + S * sqrt.V * dB[i,1]
V <- (V + lambda * (sigma.square - V) * h
+ xi * sqrt.V * (rho * dB[i,1] + rho.prime * dB[i,2]))
dBm <- dBm + dB[i,]
if (i %% m == 0) {
sqrt.Vm = sqrt(abs(Vm))
Sm <- Sm + r * Sm * m * h + Sm * sqrt.Vm * dBm[1]

366
APPENDIX C: ANSWERS TO THE EXERCISES
Vm <- (Vm + lambda * (sigma.square - Vm) * m * h
+ xi * sqrt.Vm * (rho * dBm[1] + rho.prime * dBm[2]))
dBm <- c(0, 0)
}
}
return(f(S)-f(Sm))
}
This function gives us the difference Y (i, j)
i
‚àíY (i, j)
i‚àí1 in the multilevel Monte Carlo
estimate (6.41). The full estimate can be computed by combining the individual steps
as follows:
MLMC.estimate <- function(n, m, L) {
k = round(log(n) / log(m))
if (n != m^k) stop("n=", n, " is not a power of k=", k)
est <- 0
mse <- 0
n <- 1
N <- L * m^k
for (i in 1:k) {
n <- n * m
N <- N / m
Ci <- replicate(N, MLMCSample(n, m))
est <- est + mean(Ci)
mse <- mse + var(Ci) / N
}
return(list(est=est, mse=mse))
}
C.7
Answers for Appendix B
Solution EB.1
As the following transcript of an R session shows, the Ô¨Årst three
expressions are straightforward:
> 1+2+3+4+5+6+7+8+9+10
[1] 55
> 2^16
[1] 65536
> 2^100
[1] 1.267651e+30
The sum of the Ô¨Årst 10 natural numbers is 55 and 216 = 65536. The Ô¨Ånal answer
1.267651e+30 uses a shorthand notation: the returned result stands for 1.267651 ¬∑ 1030

APPENDIX C: ANSWERS TO THE EXERCISES
367
(e is short for ‚Äòexponent‚Äô). R chooses this representation because the result is very
big and would be difÔ¨Åcult to read when written in standard notation.
For the Ô¨Ånal part of the exercise, computing 2/(1 +
‚àö
5), we can use the fact that
brackets in R can be used exactly as they are used in mathematical expressions: using
the function sqrt (see Table B.1), we can write
> 2/(1+sqrt(5))
[1] 0.618034
to get the correct (up to six decimal digits) result 0.618034.
Solution EB.2
The value of x is 3, the value of y is 5.
Solution EB.3
The sum can be computed by Ô¨Årst constructing a vector of the
numbers 1, 2, . . . , 100, and then using the R function sum to add all elements of the
vector:
> x <- 1:100
> x
[1]
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
[16]
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
[31]
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
[46]
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
[61]
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
[76]
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
[91]
91
92
93
94
95
96
97
98
99 100
> sum(x)
[1] 5050
Thus, the required sum is 5050. A shorter solution is to merge the two steps into one
command by just typing sum(1:100). This results in the same answer.
Solution EB.4
There are various ways to implement expressions such as the one
for g2 in R. To get a readable and short solution, it is important to make good use
of the built-in R functions such as sum and mean. To compute g2, we can use the
following R code:
excessKurtosis <- function(x) {
x.bar <- mean(x)
numerator <- mean((x - x.bar)^4)
denominator <- mean((x - x.bar)^2)^2
return(numerator / denominator - 3)
}
This function computes the value g2 for any sample x.

368
APPENDIX C: ANSWERS TO THE EXERCISES
To test the function, we try large samples of distributions with a known kurtosis.
First, the theoretical excess kurtosis of normal distributed values is 0. If we use the
estimator g2 for large samples, we should get results close to 0:
> excessKurtosis(rnorm(1000000))
[1] -0.00452515
> excessKurtosis(rnorm(1000000))
[1] 0.0002580271
> excessKurtosis(rnorm(1000000))
[1] -7.535562e-05
As a second test, we estimate the kurtosis of an exponential distribution; in this case,
the theoretical excess kurtosis equals 6:
> excessKurtosis(rexp(1000000))
[1] 5.945269
> excessKurtosis(rexp(1000000))
[1] 5.991549
> excessKurtosis(rexp(1000000))
[1] 6.09649
Both sets of tests give the results close to the theoretical values, so we have reason to
assume that the function excessKurtosis works.
Solution EB.5
The program contains at least two (!) mistakes: the line to assign
a value to x[5] is missing, and the output claims wrongly that x[8] is the sixth (not
eighth) Fibonacci number.
Solution EB.6
Since we need to repeat the operation of computing the cosine 20
times, we use a for loop in R:
X <- 0
for (i in 1:20) X <- cos(X)
print(X)
The output of these commands, and thus the value of x20, is 0.7389378.
Solution EB.7
We Ô¨Årst use seq to construct a vector which contains the numbers
from 100 to 0, and then use this vector to control the for loop:
for (i in seq(from=100, to=0, by=-1)) {
cat(i, "\n")
}

APPENDIX C: ANSWERS TO THE EXERCISES
369
The command print(i) can be used instead of cat(i, "\n"), but the output is not
quite as tidy (try this yourself!).
Solution EB.8
We can use the following program:
n <- 1
while (n^2 <= 5000) {
n <- n + 1
}
print(n)
The result is n = 71.
Solution EB.9
One solution is the following program:
n <- 1
while ((n+1)^2 < 5000) {
n <- n + 1
}
print(n)
Alternatively we can use the program from EB.8, and print n-1 instead of n [we also
need to check that (n-1)^2 is not exactly equal to 5000; otherwise we would have to
use n-2 instead]. Using either method, the result is 70.
Solution EB.10
One solution is given in the following program.
x <- 27
n <- 0
while (x != 1) {
cat("x[", n, "] = ", x, "\n", sep="")
n = n + 1
if (x %% 2 == 0) {
x = x / 2
} else {
x = 3*x + 1
}
}
cat("x[", n, "] = ", x, "\n", sep="")
This program violates the DRY principle: the cat command is duplicated to output
the Ô¨Ånal value. One way to Ô¨Åx this problem is to stop the loop one iteration later,

370
APPENDIX C: ANSWERS TO THE EXERCISES
that is when the previous value equals one. This idea is implemented in the following
version of the program:
n <- 0
x <- 27
old <- 0
while (old != 1) {
old <- x
cat("x[", n, "] = ", x, "\n", sep="")
n = n + 1
if (x %% 2 == 0) {
x = x / 2
} else {
x = 3*x + 1
}
}
Solution EB.11
The function computes the sample variance of the elements of x.
Solution EB.12
We set the variable b to the string "a". Since variables inside the
function are independent of the names used by the caller, the function call test(c=b)
is equivalent to test(c="a"), that is inside the function the value of the variable c
is the string "a". Finally, the function cat does not include the enclosing quotation
marks into the output when processing strings and thus the output is ‚Äòa=1, b=2,
c=a, d=4‚Äô.
Solution EB.13
The missing line, where x[5] should have been set, causes a run-
time error: the command x[6] <- x[5] + x[4] tries to read the uninitialised value
x[5] and consequently x[6] and all the following values are set to NA. The mistake
in the message printed via cat is a semantic error.
Solution EB.15
To Ô¨Ånd the mistake in the given R function, we Ô¨Årst add a series
of print commands to the function, to see at which step the function deviates from
our expectations:
SomethingWrong <- function(x) {
n <- length(x)
cat("x =", x, ", n =", n, "\n")
sum <- 0
for (i in 1:n-1) {
cat("i =", i, ", sum =", sum, "\n")
sum <- sum + (x[i+1] - x[i])^2

APPENDIX C: ANSWERS TO THE EXERCISES
371
}
return(sum)
}
This results in the following output:
> SomethingWrong(c(1,2,3))
x = 1 2 3 ,n = 3
i = 0 , sum = 0
i = 1 , sum =
i = 2 , sum =
numeric(0)
The Ô¨Årst line of the output is what we expect: the input data are 1 2 3 and the length
of the input data are 3. The second line already shows a problem: we asked R to use
the values 1, . . . , n ‚àí1 for i, but the Ô¨Årst iteration of the loop has i = 0. This is
the cause of the problem, since the loop evaluates x[0] which is not the value we
intended to use.
To Ô¨Ånd out why i took the value 0, we inspect the loop statement: we have i in
1:n-1 and we know that at this point n equals 3. Thus the range of i is 1:3-1:
> 1:3-1
[1] 0 1 2
> 1:2
[1] 1 2
> 1:(3-1)
[1] 1 2
The experiments shown above clearly point out the problem: R interprets 1:n-1 as
(1, 2, . . . , n) ‚àí1, that is the computer subtracts 1 from every value in the sequence
1:n. This is not what we intended, and we can Ô¨Åx this by introducing brackets around
n-1. The following version of the function Ô¨Åxes the error:
SomethingWrong <- function(x) {
n <- length(x)
sum <- 0
for (i in 1:(n-1)) {
sum <- sum + (x[i+1] - x[i])^2
}
return(sum)
}
Finally, we test the new version of the function:
> SomethingWrong(c(1,2,3))
[1] 2

372
APPENDIX C: ANSWERS TO THE EXERCISES
‚àí2
0
2
4
6
8
0.0
0.1
0.2
0.3
0.4
dnorm(x, 0, 1)
‚àí2
0
2
4
6
8
0.0
0.4
0.8
pnorm(x, 0, 1)
‚àí2
0
2
4
6
8
0.00
0.10
0.20
dnorm(x, 3, sqrt(4))
‚àí2
0
2
4
6
8
0.0
0.4
0.8
pnorm(x, 3, sqrt(4))
‚àí2
0
2
4
6
8
0.0
0.4
0.8
dexp(x, 1)
‚àí2
0
2
4
6
8
0.0
0.4
0.8
pexp(x, 1)
‚àí2
0
2
4
6
8
0.00
0.10
0.20
x
dgamma(x, 9, scale = 0.5)
‚àí2
0
2
4
6
8
0.0
0.4
0.8
x
pgamma(x, 9, scale = 0.5)
Figure C.10
Output of the R script from exercise EB.16. The graphs show the
densities (left column) and distribution functions (right column) of the distributions
N(0, 1), N(3, 4), Exp(1) and (9, 0.5) (top to bottom).

APPENDIX C: ANSWERS TO THE EXERCISES
373
Since this is the expected result, we can assume that we have correctly identiÔ¨Åed and
Ô¨Åxed the problem.
Solution EB.16
The function dnorm gives the density and pnorm gives the CDF
of the normal distribution. Similarly, we can use the functions dexp and pexp for the
exponential distribution and dgamma and pgamma for the gamma distribution. Thus,
we can plot the required graphs as follows:
par(mfrow=c(4,2))
curve(dnorm(x,0,1), -3, 9)
curve(pnorm(x,0,1), -3, 9, ylim=c(0,1))
curve(dnorm(x,3,sqrt(4)), -3, 9)
curve(pnorm(x,3,sqrt(4)), -3, 9, ylim=c(0,1))
curve(dexp(x,1), -3, 9)
curve(pexp(x,1), -3, 9, ylim=c(0,1))
curve(dgamma(x,9,scale=.5), -3, 9)
curve(pgamma(x,9,scale=.5), -3, 9, ylim=c(0,1))
The resulting plot is shown in Figure C.10.

References
M. A. Beaumont, W. Zhang, and D. J. Balding. Approximate Bayesian Computation in popu-
lation genetics. Genetics, 162(4):2025‚Äì2035, 2002.
M. Blum and O. Franc¬∏ois. Non-linear regression models for Approximate Bayesian Compu-
tation. Statistics and Computing, 20:63‚Äì73, 2010.
A. N. Borodin and P. Salminen. Handbook of Brownian Motion ‚Äî Facts and Formulae.
Probability and its Applications. Birkh¬®auser, 1996.
G. E. P. Box and M. E. Muller. A note on the generation of random normal deviates. Annals of
Mathematical Statistics, 29(2):610‚Äì611, 1958.
G. Casella and R. L. Berger. Statistical Inference. Duxbury Press, second edition, 2001.
C. ChatÔ¨Åeld. The Analysis of Time Series. Chapman & Hall/CRC Texts in Statistical Science
Series. Chapman & Hall/CRC, sixth edition, 2004.
J. S. Dagpunar. Simulation and Monte Carlo, with Applications in Finance and MCMC. John
Wiley & Sons, Ltd, 2007.
A. C. Davison and D. V. Hinkley. Bootstrap Methods and their Application. Cambridge
University Press, 1997.
T. J. DiCiccio and B. Efron. Bootstrap conÔ¨Ådence intervals. Statistical Science, 11(3):189‚Äì212,
1996.
B. Efron and R. J. Tibshirani. An Introduction to the Bootstrap. Chapman & Hall, 1993.
P. Fearnhead and D. Prangle. Constructing summary statistics for approximate Bayesian com-
putation: semi-automatic approximate Bayesian computation. Journal of the Royal Statisti-
cal Society: Series B, 74(3):419‚Äì474, 2012.
W. Feller. An Introduction to Probability Theory and Its Applications, volume I. John Wiley
& Sons, Ltd, third edition, 1968.
P. H. Garthwaite, I. T. Jolliffe, and B. Jones. Statistical Inference. Oxford University Press,
2002.
A. Gelman and D. B. Rubin. Inference from iterative simulation using multiple sequences.
Statistical Science, 7(4):457‚Äì472, 1992.
J. E. Gentle, W. H¬®ardle, and Y. Mori, editors. Handbook of Computational Statistics. Springer,
2004.
M. B. Giles. Multilevel Monte Carlo path simulation. Operations Research, 56(3):607‚Äì617,
2008a.
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

376
REFERENCES
M. B. Giles. Improved multilevel Monte Carlo convergence using the Milstein scheme. In
A. Keller, S. Heinrich, and H. Niederreiter, editors, Monte Carlo and Quasi-Monte Carlo
Methods 2006, pages 343‚Äì358. Springer, 2008b.
W. R. Gilks, S. Richardson, and D. J. Spiegelhalter, editors. Markov Chain Monte Carlo in
Practice. Chapman & Hall/CRC, 1996.
P. J. Green. Reversible jump Markov Chain Monte Carlo computation and Bayesian model
determination. Biometrika, 82(4):711‚Äì732, 1995.
S. L. Heston. A closed-form solution for options with stochastic volatility with applications to
bond and currency options. The Review of Financial Studies, 6(2):327‚Äì343, 1993.
D. J. Higham. An algorithmic introduction to numerical simulation of stochastic differential
equations. SIAM Review, 43(3):525‚Äì546, 2001.
J. Jacod and P. Protter. Probability Essentials. Springer, 2000.
I. Karatzas and S. E. Shreve. Brownian Motion and Stochastic Calculus, volume 113 of
Graduate Texts in Mathematics. Springer, second edition, 1991.
W. J. Kennedy Jr and J. E. Gentle. Statistical Computing. Marcel Dekker, Inc., 1980.
J. F. C. Kingman. Poisson Processes, volume 3 of Oxford Studies in Probability. Clarendon
Press, 1993.
P. E. Kloeden and E. Platen. Numerical Solution of Stochastic Differential Equations. Number
23 in Applications of Mathematics. Springer, 1999. Corrected Third Printing.
D. E. Knuth. Seminumerical Algorithms, volume 2 of The Art of Computer Programming.
Addison-Wesley, second edition, 1981.
D. P. Kroese, T. Taimre, and Z. I. Botev. Handbook of Monte Carlo Methods. John Wiley &
Sons, Ltd, 2011.
E. L. Lehmann and J. P. Romano. Testing Statistical Hypotheses. Springer, third edition, 2005.
X. Mao. Stochastic Differential Equations and Applications. Woodhead Publishing, second
edition, 2007.
G. Marsaglia and W. W. Tsang. The ziggurat method for generating random variables. Journal
of Statistical Software, 5(8):1‚Äì7, 2000.
M. Matsumoto and T. Nishimura. Mersenne twister: a 623-dimensionally equidistributed uni-
form pseudo-random number generator. ACM Transactions on Modeling and Computer
Simulation, 8(1):3‚Äì30, 1998.
N. Metropolis. The beginning of the Monte Carlo method. Los Alamos Science, 125‚Äì130,
1987.
S. P. Meyn and R. L. Tweedie. Markov Chains and Stochastic Stability. Cambridge University
Press, second edition, 2009.
P. M¬®orters and Y. Peres. Brownian Motion. Cambridge University Press, 2010.
J. R. Norris. Markov Chains. Cambridge University Press, 1997.
B. K. √òksendal. Stochastic Differential Equations. Springer, sixth edition, 2003.
R. K. Pathria. Statistical Mechanics. Elsevier, second edition, 1996.
M. Plischke and B. Bergersen. Equilibrium Statistical Physics. World ScientiÔ¨Åc, third edition,
2006.
V. Privman, editor. Finite Size Scaling and Numerical Simulation of Statistical Systems. World
ScientiÔ¨Åc, 1990.
R Development Core Team. R: A Language and Environment for Statistical Computing. 2011.

REFERENCES
377
B. D. Ripley. Stochastic Simulation. John Wiley & Sons, Ltd, 1987.
M. L. Rizzo. Statistical Computing with R. Chapman & Hall/CRC, 2008.
C. P. Robert and G. Casella. Monte Carlo Statistical Methods. Springer Texts in Statistics.
Springer, second edition, 2004.
G. O. Roberts and J. S. Rosenthal. General state space Markov chains and MCMC algorithms.
Probability Surveys, 1:20‚Äì71, 2004.
L. C. G. Rogers and D. Williams. Diffusions, Markov Processes, and Martingales, volume 2 of
Cambridge Mathematical Library. Cambridge University Press, 2000. Ito calculus, Reprint
of the second (1994) edition.
W. Rudin. Real and Complex Analysis. McGraw-Hill, third edition, 1987.
H. Scheff¬¥e. A useful convergence theorem for probability distributions. Annals of Mathematical
Statistics, 18(3):434‚Äì438, 1947.
S. Tavar¬¥e, D. J. Balding, R. C. GrifÔ¨Åths, and P. Donnelly. Inferring coalescence times from
DNA sequence data. Genetics, 145(2):505‚Äì518, 1997.
W. N. Venables and B. D. Ripley. S Programming. Springer, 2000.
W. N. Venables, D. M. Smith, and the R Development Core Team. An introduction to R.
Available from http://cran.r-project.org/doc/manuals/R-intro.html, 2011 (accessed
14 May 2013).
J. von Neumann. Various techniques used in connection with random digits. In A. S. House-
holder, G. E. Forsythe and H. H. Germond, editors, Monte Carlo Method, volume 12 of
National Bureau of Standards Applied Mathematics Series, pages 36‚Äì38. US Government
Printing OfÔ¨Åce, 1951.
R. Waagepetersen and D. Sorensen. A tutorial on reversible jump MCMC with a view toward
applications in QTL-mapping. International Statistical Review, 69:49‚Äì61, 2001.
D. Williams. Weighing the Odds: A Course in Probability and Statistics. Cambridge University
Press, 2001.
G. Winkler. Image Analysis, Random Fields and Dynamic Monte Carlo Methods. Springer,
1995.

Index
ABC, see Approximate Bayesian
Computation
acceptance probability
independence sampler, 120
Metropolis‚ÄìHastings method, 110,
113
random walk Metropolis, 117
rejection sampling, 15
RJMCMC, 163, 164
thinning method, 65
antithetic paths, 247‚Äì248
antithetic variables, 88‚Äì93
for SDEs, 247‚Äì248
Approximate Bayesian Computation,
182‚Äì188
with regression, 188‚Äì192
autocorrelation, 132‚Äì135
Bayes‚Äô rule, 139, 267
Bayesian inference, 72, 138‚Äì142,
147‚Äì152, 172‚Äì179
bias, 76
bootstrap estimates, 199‚Äì201
Monte Carlo estimation, 97‚Äì99
of discretised SDEs, 243‚Äì244
binomial distribution, 293
boolean values, 281
bootstrap conÔ¨Ådence intervals, 203‚Äì208
BCa, 207
simple, 205
bootstrap estimates, 192‚Äì208
general, 196
of conÔ¨Ådence intervals, 203‚Äì208
of the bias, 199‚Äì201
of the standard error, 201‚Äì203
Box‚ÄìMuller transform, 34
Brownian bridge, 220
Brownian motion, 214‚Äì221
geometric, 221‚Äì223
interpolation, 218‚Äì221
Markov property, 216
scaling property, 216
simulation, 217‚Äì218
burn-in period, 130‚Äì132, 137, 151
Cauchy distribution, 37
CDF, see cumulative distribution
function
change of variables, 33
œá2-distribution, 6, 293
componentwise simulation, 48‚Äì50, 142
computational cost
ABC, 184
MCMC, 135
Monte Carlo estimation, 75
rejection sampling, 20, 22
SDEs, 233, 235, 247
conditional density, 267
conditional distribution, 23‚Äì27, 183
conditional expectation, 194
An Introduction to Statistical Computing: A Simulation-based Approach, First Edition. Jochen Voss.
¬© 2014 John Wiley & Sons, Ltd. Published 2014 by John Wiley & Sons, Ltd.

380
INDEX
conÔ¨Ådence intervals, 83, 100‚Äì103, 245
bootstrap, 203‚Äì208
continuous-time processes, 213‚Äì261
control variates, 93‚Äì96, 251
convergence diagnostics, 136‚Äì137
correlation, 90, 91‚Äì93, 95, 132
auto-, 132‚Äì135
of a sample, 97‚Äì99
critical region, 104
cumulative distribution function, 12,
264
detailed balance condition, 114
diffusion coefÔ¨Åcient, 225
discretisation error, 214
for SDEs, 236‚Äì242
don‚Äôt repeat yourself
drift, 225
DRY, see don‚Äôt repeat yourself
effective sample size, 134
empirical distribution, 192
energy, 154
Euler‚ÄìMaruyama scheme, 232‚Äì233
for the Heston model, 256
events, 263
exponential distribution, 13, 265, 293
gamma distribution, 293
geometric Brownian motion, 221‚Äì223
geometric distribution, 11, 17, 20, 185
Gibbs measure, 154
Gibbs sampler, 142‚Äì159
image processing, 157‚Äì159
Ising model, 154‚Äì157
parameter estimation, 147‚Äì152
half-normal distribution, 21
Harris recurrence, 127
Heston model, 255‚Äì259
hierarchical models, 45‚Äì50, 52, 147
hypothesis tests, 5, 103‚Äì106
i.i.d., 2
i.i.d. copies, 75
importance sampling, 84‚Äì88, 223
for SDEs, 248‚Äì250
independence, 109, 266
independence sampler, 120‚Äì121
indicator function, 268
initial distribution
for Markov chains, 50, 128
for SDEs, 224
intensity function, 59, 161
inverse temperature, 154
inverse transform method, 12‚Äì15, 92
irreducible Markov chain, 127
Ising model, 154
Ito integral, 226‚Äì227
Ito‚Äôs formula, 227‚Äì230
Jacobian matrix, 33, 34, 37, 164, 165
Kronecker delta, 168
kurtosis, 294
Lagrange multipliers, 246
law of large numbers, 269
for Markov chains, 128‚Äì130
LCG, see linear congruential generator
Linear Congruential Generator, 2‚Äì4
marginal distribution, 48‚Äì50
Markov chain, 50‚Äì58, 109, 126‚Äì130
continuous state space, 56‚Äì58
discrete state space, 51‚Äì56
Harris recurrent, 127
initial distribution, 50, 128
irreducible, 127
law of large numbers, 128‚Äì130
reversible, 112, 114
time-homogeneous, 51
Markov Chain Monte Carlo, 109‚Äì180
convergence, 126‚Äì138
reversible jump, 159‚Äì179
Markov property
of Brownian motion, 216
MCMC, see Markov Chain Monte
Carlo

INDEX
381
mean squared error, 76
for antithetic variables, 90
for control variates, 94
for importance sampling, 85
for MCMC, 130
for Monte Carlo estimates, 77
for SDEs, 243, 245‚Äì247
Metropolis‚ÄìHastings method, 110‚Äì126
continuous state space, 110‚Äì113
discrete state space, 113‚Äì116
independence sampler, 120‚Äì121
move types, 121‚Äì126, 163, 173‚Äì177
random walk Metropolis, 116‚Äì119,
129, 140‚Äì142
Milstein scheme, 234, 233‚Äì236
mixture distributions, 46‚Äì48, 147, 172
models
continuous-time, 213‚Äì261
hierarchical, 45‚Äì50, 52, 147
statistical, 1, 41‚Äì68
Monte Carlo estimates, 69‚Äì108
choice of sample size, 80‚Äì82
error, 76‚Äì80, 82‚Äì84
for integrals, 72
for probabilities, 71, 81, 87, 91, 102,
105, 244, 249
for SDEs, 243‚Äì255
multi-level, 250‚Äì255
variance reduction, 84‚Äì96, 247‚Äì255
MSE, see mean squared error
multi-level Monte Carlo estimates,
250‚Äì255
normal distribution, 265, 293
generation, 23, 34
half, 21
multivariate, 41‚Äì45, 214
normalisation constant, 266
optimisation under constraints, 245
option pricing, 255‚Äì259
Pareto distribution, 162
partition function, 154
pixels, 153
plug-in estimator, 198
plug-in principle, 198
point estimators, 83, 97‚Äì100, 197‚Äì203
Poisson distribution, 58, 102, 162, 293
Poisson process, 58‚Äì67
intensity function, 59
thinning method, 65
posterior distribution, 73, 138‚Äì141,
147, 158, 181
prior distribution, 138
PRNG, see pseudo random number
generator
probability, 263‚Äì270
probability density, 264
probability distribution, 263
probability vector, 52
pseudo random number generator, 2
R programming, 271‚Äì297
random number generators, 2‚Äì8
random variables, 263, 292
transformation of, 32‚Äì38
random walk, 50
random walk Metropolis, 116‚Äì119
ratio-of-uniforms method, 35‚Äì38
Rayleigh distribution, 14
rejection sampling, 15‚Äì32, 73, 120
basic, 15‚Äì19, 182
envelope, 19‚Äì23
for conditional distributions, 23‚Äì27,
150
resampling methods, 192‚Äì208
reversible jump Markov Chain Monte
Carlo, 159‚Äì179
dimension matching, 163‚Äì166, 175
state space, 161, 172
target distribution, 161, 173
transitions, 162, 173
reversible Markov chain, 112, 114
RJMCMC, see reversible jump Markov
Chain Monte Carlo
RMSE, see root-mean-square error
root-mean-square error, 79, 344

382
INDEX
sample correlation, 97‚Äì99
scaling property
of Brownian motion, 216
SDE, see stochastic differential
equations
seed, 2, 8, 153, 293
semicircle distribution, 18
skewness, 105
slice sampler, 145
stability of discretisation schemes,
241
standard error, 76, 201
bootstrap estimates, 201‚Äì203
standard normal distribution, see
normal distribution
state space
Gibbs sampler, 142
Markov chain, 50, 51, 56
RJMCMC, 161
stationary density, 58
stationary distribution, 55
statistical computing, 1‚Äì262
statistical hypothesis tests, 5, 103‚Äì106
statistical inference, 96‚Äì106
Bayesian, 138‚Äì142, 147‚Äì152,
172‚Äì179
bootstrap methods, 197‚Äì208
statistical models, 1, 41‚Äì68
stochastic analysis, 226‚Äì231
stochastic differential equations,
224‚Äì242
Euler‚ÄìMaruyama scheme, 232‚Äì233
initial distribution, 224
Milstein scheme, 233‚Äì236
Monte Carlo estimates, 243‚Äì255
strong error, 236‚Äì237
weak error, 237‚Äì240
stochastic integrals, 226‚Äì231
time discretisation, 226
stochastic matrix, 52
Stratonovich integral, 230, 230‚Äì231
strong error, 236, 236‚Äì237
substitution rule, 33, 170
sufÔ¨Åcient statistic, 183
test functions, 238
tests
statistical, 5, 103‚Äì106
time discretisation, 214
Brownian motion, 217
for SDEs, 231‚Äì242
stochastic integrals, 226
transformation
of random variables, 32‚Äì38, 43
of U[0, 1], 13
transition density, 57
transition kernel, 56
transition matrix, 51
truncation error, 276
uniform distribution, 4, 8, 27, 293
discrete, 9, 293
ratio-of-uniforms, 35
variance reduction methods, 84‚Äì96,
247‚Äì255
weak error, 237‚Äì240
Wiener process, see Brownian motion
Wigner‚Äôs semicircle distribution, 18

