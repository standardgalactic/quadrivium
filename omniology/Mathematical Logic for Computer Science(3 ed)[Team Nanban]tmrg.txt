

Mathematical Logic for Computer Science


Mordechai Ben-Ari
Mathematical
Logic for
Computer Science
Third Edition

Prof. Mordechai (Moti) Ben-Ari
Department of Science Teaching
Weizmann Institute of Science
Rehovot, Israel
ISBN 978-1-4471-4128-0
ISBN 978-1-4471-4129-7 (eBook)
DOI 10.1007/978-1-4471-4129-7
Springer London Heidelberg New York Dordrecht
Library of Congress Control Number: 2012941863
1st edition: © Prentice Hall International Ltd. 1993
© Springer-Verlag London 2009, 2012
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of
the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations, recitation,
broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information
storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology
now known or hereafter developed. Exempted from this legal reservation are brief excerpts in connection
with reviews or scholarly analysis or material supplied speciﬁcally for the purpose of being entered
and executed on a computer system, for exclusive use by the purchaser of the work. Duplication of
this publication or parts thereof is permitted only under the provisions of the Copyright Law of the
Publisher’s location, in its current version, and permission for use must always be obtained from Springer.
Permissions for use may be obtained through RightsLink at the Copyright Clearance Center. Violations
are liable to prosecution under the respective Copyright Law.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
While the advice and information in this book are believed to be true and accurate at the date of pub-
lication, neither the authors nor the editors nor the publisher can accept any legal responsibility for any
errors or omissions that may be made. The publisher makes no warranty, express or implied, with respect
to the material contained herein.
Printed on acid-free paper
Springer is part of Springer Science+Business Media (www.springer.com)

For Anita


Preface
Students of science and engineering are required to study mathematics during their
ﬁrst years at a university. Traditionally, they concentrate on calculus, linear algebra
and differential equations, but in computer science and engineering, logic, combi-
natorics and discrete mathematics are more appropriate. Logic is particularly im-
portant because it is the mathematical basis of software: it is used to formalize the
semantics of programming languages and the speciﬁcation of programs, and to ver-
ify the correctness of programs.
Mathematical Logic for Computer Science is a mathematics textbook, just as a
ﬁrst-year calculus text is a mathematics textbook. A scientist or engineer needs more
than just a facility for manipulating formulas and a ﬁrm foundation in mathematics
is an excellent defense against technological obsolescence. Tempering this require-
ment for mathematical competence is the realization that applications use only a
fraction of the theoretical results. Just as the theory of calculus can be taught to
students of engineering without the full generality of measure theory, students of
computer science need not be taught the full generality of uncountable structures.
Fortunately (as shown by Raymond M. Smullyan), tableaux provide an elegant way
to teach mathematical logic that is both theoretically sound and yet sufﬁciently ele-
mentary for the undergraduate.
Audience
The book is intended for undergraduate computer science students. No speciﬁc
mathematical knowledge is assumed aside from informal set theory which is sum-
marized in an appendix, but elementary knowledge of concepts from computer sci-
ence (graphs, languages, programs) is used.
vii

viii
Preface
Organization
The book can be divided into four parts. Within each part the chapters should be
read sequentially; the prerequisites between the parts are described here.
Propositional Logic:
Chapter 2 is on the syntax and semantics of propositional
logic. It introduces the method of semantic tableaux as a decision procedure for
the logic. This chapter is an essential prerequisite for reading the rest of the book.
Chapter 3 introduces deductive systems (axiomatic proof systems). The next three
chapters present techniques that are used in practice for tasks such as automatic
theorem proving and program veriﬁcation: Chap. 4 on resolution, Chap. 5 on binary
decision diagrams and Chap. 6 on SAT solvers.
First-Order Logic:
The same progression is followed for ﬁrst-order logic. There
are two chapters on the basic theory of the logic: Chap. 7 on syntax, semantics and
semantic tableaux, followed by Chap. 8 on deductive systems. Important applica-
tion of ﬁrst-order logic are automatic theorem proving using resolution (Chap. 10)
and logic programming (Chap. 11). These are preceded by Chap. 9 which intro-
duces an essential extension of the logic to terms and functions. Chapter 12 surveys
fundamental theoretical results in ﬁrst-order logic. The chapters on ﬁrst-order logic
assume as prerequisites the corresponding chapters on propositional logic; for ex-
ample, you should read Chap. 4 on resolution in the propositional logic before the
corresponding Chap. 10 in ﬁrst-order logic.
Temporal Logic:
Again, the same progression is followed: Chap. 13 on syntax,
semantics and semantic tableaux, followed by Chap. 14 on deductive systems. The
prerequisites are the corresponding chapters on propositional logic since ﬁrst-order
temporal logic is not discussed.
Program Veriﬁcation:
One of the most important applications of mathematical
logic in computer science is in the ﬁeld of program veriﬁcation. Chapter 15 presents
a deductive system for the veriﬁcation of sequential programs; the reader should
have mastered Chap. 3 on deductive systems in propositional logic before reading
this chapter. Chapter 16 is highly dependent on earlier chapters: it includes deduc-
tive proofs, the use of temporal logic, and implementations using binary decision
diagrams and satisﬁability solvers.
Supplementary Materials
Slides of the diagrams and tables in the book (in both PDF and LATEX) can be down-
loaded from http://www.springer.com/978-1-4471-4128-0, which also contains in-
structions for obtaining the answers to the exercises (qualiﬁed instructors only). The
source code and documentation of Prolog programs for most of the algorithms in the
book can be downloaded from http://code.google.com/p/mlcs/.

Preface
ix
Third Edition
The third edition has been totally rewritten for clarity and accuracy. In addition, the
following major changes have been made to the content:
• The discussion of logic programming has been shortened somewhat and the Pro-
log programs and their documentation have been removed to a freely available
archive.
• The chapter on the Z notation has been removed because it was difﬁcult to do
justice to this important topic in a single chapter.
• The discussion of model checking in Chap. 16 has been signiﬁcantly expanded
since model checking has become a widely used technique for program veriﬁca-
tion.
• Chapter 6 has been added to reﬂect the growing importance of SAT solvers in all
areas of computer science.
Notation
If and only if is abbreviated iff. Deﬁnitions by convention use iff to emphasize that
the deﬁnition is restrictive. For example: A natural number is even iff it can be
expressed as 2k for some natural number k. In the deﬁnition, iff means that numbers
expressed as 2k are even and these are the only even numbers.
Deﬁnitions, theorems and examples are consecutively numbered within each
chapter to make them easy to locate. The end of a deﬁnition, example or proof
is denoted by
.
Advanced topics and exercises, as well as topics outside the mainstream of the
book, are marked with an asterisk.
Acknowledgments
I am indebted to Jørgen Villadsen for his extensive comments on the second edition
which materially improved the text. I would like to thank Joost-Pieter Katoen and
Doron Peled for reviewing parts of the manuscript. I would also like to thank Helen
Desmond, Ben Bishop and Beverley Ford of Springer for facilitating the publication
of the book.
Mordechai (Moti) Ben-Ari
Rehovot, Israel


Contents
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
The Origins of Mathematical Logic . . . . . . . . . . . . . . . .
1
1.2
Propositional Logic
. . . . . . . . . . . . . . . . . . . . . . . .
2
1.3
First-Order Logic
. . . . . . . . . . . . . . . . . . . . . . . . .
3
1.4
Modal and Temporal Logics . . . . . . . . . . . . . . . . . . . .
4
1.5
Program Veriﬁcation . . . . . . . . . . . . . . . . . . . . . . . .
5
1.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.7
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.8
Exercise
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
2
Propositional Logic: Formulas, Models, Tableaux . . . . . . . . . . .
7
2.1
Propositional Formulas
. . . . . . . . . . . . . . . . . . . . . .
7
2.2
Interpretations . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
2.3
Logical Equivalence . . . . . . . . . . . . . . . . . . . . . . . .
21
2.4
Sets of Boolean Operators * . . . . . . . . . . . . . . . . . . . .
26
2.5
Satisﬁability, Validity and Consequence . . . . . . . . . . . . . .
29
2.6
Semantic Tableaux . . . . . . . . . . . . . . . . . . . . . . . . .
33
2.7
Soundness and Completeness . . . . . . . . . . . . . . . . . . .
39
2.8
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
2.9
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . .
45
2.10
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
3
Propositional Logic: Deductive Systems
. . . . . . . . . . . . . . . .
49
3.1
Why Deductive Proofs? . . . . . . . . . . . . . . . . . . . . . .
49
3.2
Gentzen System G . . . . . . . . . . . . . . . . . . . . . . . . .
51
3.3
Hilbert System H . . . . . . . . . . . . . . . . . . . . . . . . .
55
3.4
Derived Rules in H . . . . . . . . . . . . . . . . . . . . . . . .
58
3.5
Theorems for Other Operators . . . . . . . . . . . . . . . . . . .
62
3.6
Soundness and Completeness of H . . . . . . . . . . . . . . . .
64
xi

xii
Contents
3.7
Consistency
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
3.8
Strong Completeness and Compactness * . . . . . . . . . . . . .
67
3.9
Variant Forms of the Deductive Systems *
. . . . . . . . . . . .
68
3.10
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
3.11
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . .
71
3.12
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
4
Propositional Logic: Resolution . . . . . . . . . . . . . . . . . . . . .
75
4.1
Conjunctive Normal Form . . . . . . . . . . . . . . . . . . . . .
75
4.2
Clausal Form . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
4.3
Resolution Rule . . . . . . . . . . . . . . . . . . . . . . . . . .
80
4.4
Soundness and Completeness of Resolution *
. . . . . . . . . .
82
4.5
Hard Examples for Resolution * . . . . . . . . . . . . . . . . . .
88
4.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
4.7
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . .
92
4.8
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
93
5
Propositional Logic: Binary Decision Diagrams . . . . . . . . . . . .
95
5.1
Motivation Through Truth Tables . . . . . . . . . . . . . . . . .
95
5.2
Deﬁnition of Binary Decision Diagrams
. . . . . . . . . . . . .
97
5.3
Reduced Binary Decision Diagrams . . . . . . . . . . . . . . . .
98
5.4
Ordered Binary Decision Diagrams . . . . . . . . . . . . . . . . 102
5.5
Applying Operators to BDDs . . . . . . . . . . . . . . . . . . . 104
5.6
Restriction and Quantiﬁcation * . . . . . . . . . . . . . . . . . . 107
5.7
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
5.8
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 110
5.9
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
6
Propositional Logic: SAT Solvers . . . . . . . . . . . . . . . . . . . . 111
6.1
Properties of Clausal Form
. . . . . . . . . . . . . . . . . . . . 111
6.2
Davis-Putnam Algorithm
. . . . . . . . . . . . . . . . . . . . . 115
6.3
DPLL Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . 116
6.4
An Extended Example of the DPLL Algorithm . . . . . . . . . . 117
6.5
Improving the DPLL Algorithm . . . . . . . . . . . . . . . . . . 122
6.6
Stochastic Algorithms . . . . . . . . . . . . . . . . . . . . . . . 125
6.7
Complexity of SAT *
. . . . . . . . . . . . . . . . . . . . . . . 126
6.8
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
6.9
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 128
6.10
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
7
First-Order Logic: Formulas, Models, Tableaux . . . . . . . . . . . . 131
7.1
Relations and Predicates . . . . . . . . . . . . . . . . . . . . . . 131
7.2
Formulas in First-Order Logic . . . . . . . . . . . . . . . . . . . 133

Contents
xiii
7.3
Interpretations . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
7.4
Logical Equivalence . . . . . . . . . . . . . . . . . . . . . . . . 140
7.5
Semantic Tableaux . . . . . . . . . . . . . . . . . . . . . . . . . 143
7.6
Soundness and Completion of Semantic Tableaux
. . . . . . . . 150
7.7
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
7.8
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 153
7.9
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154
8
First-Order Logic: Deductive Systems . . . . . . . . . . . . . . . . . 155
8.1
Gentzen System G . . . . . . . . . . . . . . . . . . . . . . . . . 155
8.2
Hilbert System H . . . . . . . . . . . . . . . . . . . . . . . . . 158
8.3
Equivalence of H and G
. . . . . . . . . . . . . . . . . . . . . 160
8.4
Proofs of Theorems in H . . . . . . . . . . . . . . . . . . . . . 161
8.5
The C-Rule * . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163
8.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
8.7
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 165
8.8
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
9
First-Order Logic: Terms and Normal Forms . . . . . . . . . . . . . 167
9.1
First-Order Logic with Functions . . . . . . . . . . . . . . . . . 167
9.2
PCNF and Clausal Form . . . . . . . . . . . . . . . . . . . . . . 172
9.3
Herbrand Models
. . . . . . . . . . . . . . . . . . . . . . . . . 177
9.4
Herbrand’s Theorem * . . . . . . . . . . . . . . . . . . . . . . . 180
9.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
9.6
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 182
9.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
10
First-Order Logic: Resolution . . . . . . . . . . . . . . . . . . . . . . 185
10.1
Ground Resolution . . . . . . . . . . . . . . . . . . . . . . . . . 185
10.2
Substitution
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
10.3
Uniﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
10.4
General Resolution . . . . . . . . . . . . . . . . . . . . . . . . . 195
10.5
Soundness and Completeness of General Resolution * . . . . . . 198
10.6
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
10.7
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 202
10.8
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
11
First-Order Logic: Logic Programming
. . . . . . . . . . . . . . . . 205
11.1
From Formulas in Logic to Logic Programming
. . . . . . . . . 205
11.2
Horn Clauses and SLD-Resolution
. . . . . . . . . . . . . . . . 209
11.3
Search Rules in SLD-Resolution
. . . . . . . . . . . . . . . . . 213
11.4
Prolog
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216
11.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220

xiv
Contents
11.6
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 221
11.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
12
First-Order Logic: Undecidability and Model Theory *
. . . . . . . 223
12.1
Undecidability of First-Order Logic . . . . . . . . . . . . . . . . 223
12.2
Decidable Cases of First-Order Logic . . . . . . . . . . . . . . . 226
12.3
Finite and Inﬁnite Models . . . . . . . . . . . . . . . . . . . . . 227
12.4
Complete and Incomplete Theories . . . . . . . . . . . . . . . . 228
12.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
12.6
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 229
12.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
13
Temporal Logic: Formulas, Models, Tableaux . . . . . . . . . . . . . 231
13.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
13.2
Syntax and Semantics . . . . . . . . . . . . . . . . . . . . . . . 233
13.3
Models of Time
. . . . . . . . . . . . . . . . . . . . . . . . . . 237
13.4
Linear Temporal Logic
. . . . . . . . . . . . . . . . . . . . . . 240
13.5
Semantic Tableaux . . . . . . . . . . . . . . . . . . . . . . . . . 244
13.6
Binary Temporal Operators * . . . . . . . . . . . . . . . . . . . 258
13.7
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
13.8
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 261
13.9
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
14
Temporal Logic: A Deductive System . . . . . . . . . . . . . . . . . . 263
14.1
Deductive System L
. . . . . . . . . . . . . . . . . . . . . . . 263
14.2
Theorems of L
. . . . . . . . . . . . . . . . . . . . . . . . . . 264
14.3
Soundness and Completeness of L * . . . . . . . . . . . . . . . 269
14.4
Axioms for the Binary Temporal Operators * . . . . . . . . . . . 271
14.5
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
14.6
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 272
14.7
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
15
Veriﬁcation of Sequential Programs . . . . . . . . . . . . . . . . . . . 273
15.1
Correctness Formulas . . . . . . . . . . . . . . . . . . . . . . . 274
15.2
Deductive System H L . . . . . . . . . . . . . . . . . . . . . . 275
15.3
Program Veriﬁcation . . . . . . . . . . . . . . . . . . . . . . . . 277
15.4
Program Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . 279
15.5
Formal Semantics of Programs *
. . . . . . . . . . . . . . . . . 283
15.6
Soundness and Completeness of H L * . . . . . . . . . . . . . 289
15.7
Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
15.8
Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 293
15.9
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295

Contents
xv
16
Veriﬁcation of Concurrent Programs . . . . . . . . . . . . . . . . . . 297
16.1
Deﬁnition of Concurrent Programs . . . . . . . . . . . . . . . . 298
16.2
Formalization of Correctness
. . . . . . . . . . . . . . . . . . . 300
16.3
Deductive Veriﬁcation of Concurrent Programs . . . . . . . . . . 303
16.4
Programs as Automata . . . . . . . . . . . . . . . . . . . . . . . 307
16.5
Model Checking of Invariance Properties . . . . . . . . . . . . . 311
16.6
Model Checking of Liveness Properties . . . . . . . . . . . . . . 314
16.7
Expressing an LTL Formula as an Automaton
. . . . . . . . . . 315
16.8
Model Checking Using the Synchronous Automaton . . . . . . . 317
16.9
Branching-Time Temporal Logic * . . . . . . . . . . . . . . . . 319
16.10 Symbolic Model Checking *
. . . . . . . . . . . . . . . . . . . 322
16.11 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
16.12 Further Reading . . . . . . . . . . . . . . . . . . . . . . . . . . 324
16.13 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
Appendix
Set Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327
A.1
Finite and Inﬁnite Sets . . . . . . . . . . . . . . . . . . . . . . . 327
A.2
Set Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . 328
A.3
Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330
A.4
Relations and Functions . . . . . . . . . . . . . . . . . . . . . . 331
A.5
Cardinality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333
A.6
Proving Properties of Sets . . . . . . . . . . . . . . . . . . . . . 335
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336
Index of Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
Name Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
Subject Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341


Chapter 1
Introduction
1.1 The Origins of Mathematical Logic
Logic formalizes valid methods of reasoning. The study of logic was begun by the
ancient Greeks whose educational system stressed competence in reasoning and in
the use of language. Along with rhetoric and grammar, logic formed part of the
trivium, the ﬁrst subjects taught to young people. Rules of logic were classiﬁed and
named. The most widely known set of rules are the syllogisms; here is an example
of one form of syllogism:
Premise All rabbits have fur.
Premise Some pets are rabbits.
Conclusion Some pets have fur.
If both premises are true, the rules ensure that the conclusion is true.
Logic must be formalized because reasoning expressed in informal natural lan-
guage can be ﬂawed. A clever example is the following ‘syllogism’ given by
Smullyan (1978, p. 183):
Premise Some cars rattle.
Premise My car is some car.
Conclusion My car rattles.
The formalization of logic began in the nineteenth century as mathematicians at-
tempted to clarify the foundations of mathematics. One trigger was the discovery
of non-Euclidean geometries: replacing Euclid’s parallel axiom with another ax-
iom resulted in a different theory of geometry that was just as consistent as that of
Euclid. Logical systems—axioms and rules of inference—were developed with the
understanding that different sets of axioms would lead to different theorems. The
questions investigated included:
Consistency A logical system is consistent if it is impossible to prove both a for-
mula and its negation.
Independence The axioms of a logical system are independent if no axiom can be
proved from the others.
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_1, © Springer-Verlag London 2012
1

2
1
Introduction
Soundness All theorems that can be proved in the logical system are true.
Completeness All true statements can be proved in the logical system.
Clearly, these questions will only make sense once we have formally deﬁned the
central concepts of truth and proof.
During the ﬁrst half of the twentieth century, logic became a full-ﬂedged topic
of modern mathematics. The framework for research into the foundations of math-
ematics was called Hilbert’s program, (named after the great mathematician David
Hilbert). His central goal was to prove that mathematics, starting with arithmetic,
could be axiomatized in a system that was both consistent and complete. In 1931,
Kurt Gödel showed that this goal cannot be achieved: any consistent axiomatic sys-
tem for arithmetic is incomplete since it contains true statements that cannot be
proved within the system.
In the second half of the twentieth century, mathematical logic was applied in
computer science and has become one of its most important theoretical foundations.
Problems in computer science have led to the development of many new systems
of logic that did not exist before or that existed only at the margins of the classical
systems. In the remainder of this chapter, we will give an overview of systems of
logic relevant to computer science and sketch their applications.
1.2 Propositional Logic
Our ﬁrst task is to formalize the concept of the truth of a statement. Every statement
is assigned one of two values, conventionally called true and false or T and F .
These should be considered as arbitrary symbols that could easily be replaced by
any other pair of symbols like 1 and 0 or even ♣and ♠.
Our study of logic commences with the study of propositional logic (also called
the propositional calculus). The formulas of the logic are built from atomic propo-
sitions, which are statements that have no internal structure. Formulas can be com-
bined using Boolean operators. These operators have conventional names derived
from natural language (and, or, implies), but they are given a formal meaning in the
logic. For example, the Boolean operator and is deﬁned as the operator that gives
the value true if and only if applied to two formulas whose values are true.
Example 1.1 The statements ‘one plus one equals two’ and ‘Earth is farther from the
sun than Venus’ are both true statements; therefore, by deﬁnition, so is the following
statement:
‘one plus one equals two’ and ‘Earth is farther from the sun than Venus’.
Since ‘Earth is farther from the sun than Mars’ is a false statement, so is:
‘one plus one equals two’ and ‘Earth is farther from the sun than Mars’.
Rules of syntax deﬁne the legal structure of formulas in propositional logic. The
semantics—the meaning of formulas—is deﬁned by interpretations, which assign

1.3
First-Order Logic
3
one of the (truth) values T or F to every atomic proposition. For every legal way
that a formula can be constructed, a semantical rule speciﬁes the truth value of the
formula based upon the values of its constituents.
Proof is another syntactical concept. A proof is a deduction of a formula from a
set of formulas called axioms using rules of inference. The central theoretical result
that we prove is the soundness and completeness of the axiom system: the set of
provable formulas is the same as the set of formulas which are always true.
Propositional logic is central to the design of computer hardware because hard-
ware is usually designed with components having two voltage levels that are arbi-
trarily assigned the symbols 0 and 1. Circuits are described by idealized elements
called logic gates; for example, an and-gate produces the voltage level associated
with 1 if and only if both its input terminals are held at this same voltage level.
Example 1.2 Here is a half-adder constructed from and, or- and not-gates.
The half-adder adds two one-bit binary numbers and by joining several half-adders
we can add binary numbers composed of many bits.
Propositional logic is widely used in software, too. The reason is that any pro-
gram is a ﬁnite entity. Mathematicians may consider the natural numbers to be in-
ﬁnite (0,1,2,...), but a word of a computer’s memory can only store numbers in
a ﬁnite range. By using an atomic proposition for each bit of a program’s state, the
meaning of a computation can be expressed as a (very large) formula. Algorithms
have been developed to study properties of computations by evaluating properties
of formulas in propositional logic.
1.3 First-Order Logic
Propositional logic is not sufﬁciently expressive for formalizing mathematical the-
ories such as arithmetic. An arithmetic expression such as x + 2 > y −1 is neither
true nor false: (a) its truth depends on the values of the variables x and y; (b) we
need to formalize the meaning of the operators + and −as functions that map a pair
of numbers to a number; (c) relational operators like > must be formalized as map-
ping pairs of numbers into truth values. The system of logic that can be interpreted
by values, functions and relations is called ﬁrst-order logic (also called predicate
logic or the predicate calculus).

4
1
Introduction
The study of the foundations of mathematics emphasized ﬁrst-order logic, but
it has also found applications in computer science, in particular, in the ﬁelds of
automated theorem proving and logic programming. Can a computer carry out the
work of a mathematician? That is, given a set of axioms for, say, number theory, can
we write software that will ﬁnd proofs of known theorems, as well as statements
and proofs of new ones? With luck, the computer might even discover a proof of
Goldbach’s Conjecture, which states that every even number greater than two is the
sum of two prime numbers:
4 = 2 + 2,
6 = 3 + 3,
...,
100 = 3 + 97,
102 = 5 + 97,
104 = 3 + 101,
....
Goldbach’s Conjecture has not been proved, though no counterexample has been
found even with an extensive computerized search.
Research into automated theorem proving led to a new and efﬁcient method of
proving formulas in ﬁrst-order logic called resolution. Certain restrictions of resolu-
tion have proved to be so efﬁcient they are the basis of a new type of programming
language. Suppose that a theorem prover is capable of proving the following for-
mula:
Let A be an array of integers. Then there exists an array A′ such that the elements of A′ are
a permutation of those of A, and such that A′ is ordered: A′(i) ≤A′(j) for i < j.
Suppose, further, that given any speciﬁc array A, the theorem prover constructs the
array A′ which the required properties. Then the formula is a program for sorting,
and the proof of the formula generates the result. The use of theorem provers for
computation is called logic programming. Logic programming is attractive because
it is declarative—you just write what you want from the computation—as opposed
to classical programming languages, where you have to specify in detail how the
computation is to be carried out.
1.4 Modal and Temporal Logics
A statement need not be absolutely true or false. The statement ‘it is raining’ is
sometimes true and sometimes false. Modal logics are used to formalize statements
where ﬁner distinctions need to be made than just ‘true’ or ‘false’. Classically, modal
logic distinguished between statements that are necessarily true and those that are
possibly true. For example, 1 + 1 = 2, as a statement about the natural numbers,
is necessarily true because of the way the concepts are deﬁned. But any historical
statement like ‘Napoleon lost the battle of Waterloo’ is only possibly true; if cir-
cumstances had been different, the outcome of Waterloo might have been different.
Modal logics have turned out to be extremely useful in computer science. We will
study a form of modal logic called temporal logic, where ‘necessarily’ is interpreted
as always and ‘possibly’ is interpreted as eventually. Temporal logic has turned
out to be the preferred logic for program veriﬁcation as described in the following
section.

1.5
Program Veriﬁcation
5
1.5 Program Veriﬁcation
One of the major applications of logic to computer science is in program veriﬁca-
tion. Software now controls our most critical systems in transportation, medicine,
communications and ﬁnance, so that it is hard to think of an area in which we are not
dependent on the correct functioning of a computerized system. Testing a program
can be an ineffective method of verifying the correctness of a program because we
test the scenarios that we think will happen and not those that arise unexpectedly.
Since a computer program is simply a formal description of a calculation, it can be
veriﬁed in the same way that a mathematical theorem can be veriﬁed using logic.
First, we need to express a correctness speciﬁcation as a formal statement in
logic. Temporal logic is widely used for this purpose because it can express the dy-
namic behavior of program, especially of reactive programs like operating systems
and real-time systems, which do not compute an result but instead are intended to
run indeﬁnitely.
Example 1.3 The property ‘always not deadlocked’ is an important correctness
speciﬁcation for operating systems, as is ‘if you request to print a document, even-
tually the document will be printed’.
Next, we need to formalize the semantics (the meaning) of a program, and, ﬁ-
nally, we need a formal system for deducing that the program fulﬁlls a correctness
speciﬁcation. An axiomatic system for temporal logic can be used to prove concur-
rent programs correct.
For sequential programs, veriﬁcation is performed using an axiomatic system
called Hoare logic after its inventor C.A.R. Hoare. Hoare logic assumes that we
know the truth of statements of the program’s domain like arithmetic; for example,
−(1 −x) = (x −1) is considered to be an axiom of the logic. There are axioms and
rules of inference that concern the structure of the program: assignment statements,
loops, and so on. These are used to create a proof that a program fulﬁlls a correctness
speciﬁcation.
Rather than deductively prove the correctness of a program relative to a spec-
iﬁcation, a model checker veriﬁes the truth of a correctness speciﬁcation in every
possible state that can appear during the computation of a program. On a physical
computer, there are only a ﬁnite number of different states, so this is always possible.
The challenge is to make model checking feasible by developing methods and algo-
rithms to deal with the very large number of possible states. Ingenious algorithms
and data structures, together with the increasing CPU power and memory of modern
computers, have made model checkers into viable tools for program veriﬁcation.
1.6 Summary
Mathematical logic formalizes reasoning. There are many different systems of logic:
propositional logic, ﬁrst-order logic and modal logic are really families of logic with

6
1
Introduction
many variants. Although systems of logic are very different, we approach each logic
in a similar manner: We start with their syntax (what constitutes a formula in the
logic) and their semantics (how truth values are attributed to a formula). Then we
describe the method of semantic tableaux for deciding the validity of a formula.
This is followed by the description of an axiomatic system for the logic. Along the
way, we will look at the applications of the various logics in computer science with
emphasis on theorem proving and program veriﬁcation.
1.7 Further Reading
This book was originally inspired by Raymond M. Smullyan’s presentation of logic
using semantic tableaux. It is still worthwhile studying Smullyan (1968). A more
advanced logic textbook for computer science students is Nerode and Shore (1997);
its approach to propositional and ﬁrst-order logic is similar to ours but it includes
chapters on modal and intuitionistic logics and on set theory. It has a useful ap-
pendix that provides an overview of the history of logic as well as a comprehensive
bibliography. Mendelson (2009) is a classic textbook that is more mathematical in
its approach.
Smullyan’s books such as Smullyan (1978) will exercise your abilities to think
logically! The ﬁnal section of that book contains an informal presentation of Gödel’s
incompleteness theorem.
1.8 Exercise
1.1 What is wrong with Smullyan’s ‘syllogism’?
References
E. Mendelson. Introduction to Mathematical Logic (Fifth Edition). Chapman & Hall/CRC, 2009.
A. Nerode and R.A. Shore. Logic for Applications (Second Edition). Springer, 1997.
R.M. Smullyan. First-Order Logic. Springer-Verlag, 1968. Reprinted by Dover, 1995.
R.M. Smullyan. What Is the Name of This Book?—The Riddle of Dracula and Other Logical
Puzzles. Prentice-Hall, 1978.

Chapter 2
Propositional Logic: Formulas, Models,
Tableaux
Propositional logic is a simple logical system that is the basis for all others. Propo-
sitions are claims like ‘one plus one equals two’ and ‘one plus two equals two’ that
cannot be further decomposed and that can be assigned a truth value of true or false.
From these atomic propositions, we will build complex formulas using Boolean op-
erators:
‘one plus one equals two’ and ‘Earth is farther from the sun than Venus’.
Logical systems formalize reasoning and are similar to programming languages
that formalize computations. In both cases, we need to deﬁne the syntax and the se-
mantics. The syntax deﬁnes what strings of symbols constitute legal formulas (legal
programs, in the case of languages), while the semantics deﬁnes what legal formu-
las mean (what legal programs compute). Once the syntax and semantics of propo-
sitional logic have been deﬁned, we will show how to construct semantic tableaux,
which provide an efﬁcient decision procedure for checking when a formula is true.
2.1 Propositional Formulas
In computer science, an expression denoted the computation of a value from other
values; for example, 2 ∗9 + 5. In propositional logic, the term formula is used in-
stead. The formal deﬁnition will be in terms of trees, because our the main proof
technique called structural induction is easy to understand when applied to trees.
Optional subsections will expand on different approaches to syntax.
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_2, © Springer-Verlag London 2012
7

8
2
Propositional Logic: Formulas, Models, Tableaux
2.1.1 Formulas as Trees
Deﬁnition 2.1 The symbols used to construct formulas in propositional logic are:
• An unbounded set of symbols P called atomic propositions (often shortened
to atoms). Atoms will be denoted by lower case letters in the set {p,q,r,...},
possibly with subscripts.
• Boolean operators. Their names and the symbols used to denote them are:
negation
¬
disjunction
∨
conjunction
∧
implication
→
equivalence
↔
exclusive or
⊕
nor
↓
nand
↑
The negation operator is a unary operator that takes one operand, while the
other operators are binary operators taking two operands.
Deﬁnition 2.2 A formula in propositional logic is a tree deﬁned recursively:
• A formula is a leaf labeled by an atomic proposition.
• A formula is a node labeled by ¬ with a single child that is a formula.
• A formula is a node labeled by one of the binary operators with two children both
of which are formulas.
Example 2.3 Figure 2.1 shows two formulas.
2.1.2 Formulas as Strings
Just as we write expressions as strings (linear sequences of symbols), we can write
formulas as strings. The string associated with a formula is obtained by an inorder
traversal of the tree:
Algorithm 2.4 (Represent a formula by a string)
Input: A formula A of propositional logic.
Output: A string representation of A.

2.1
Propositional Formulas
9
Fig. 2.1 Two formulas
Call the recursive procedure Inorder(A):
Inorder(F)
if F is a leaf
write its label
return
let F1 and F2 be the left and right subtrees of F
Inorder(F1)
write the label of the root of F
Inorder(F2)
If the root of F is labeled by negation, the left subtree is considered to be empty and
the step Inorder(F1) is skipped.
Deﬁnition 2.5 The term formula will also be used for the string with the under-
standing that it refers to the underlying tree.
Example 2.6 Consider the left formula in Fig. 2.1. The inorder traversal gives: write
the leftmost leaf labeled p, followed by its root labeled →, followed by the right
leaf of the implication labeled q, followed by the root of the tree labeled ↔, and so
on. The result is the string:
p →q ↔¬p →¬q.
Consider now the right formula in Fig. 2.1. Performing the traversal results in the
string:
p →q ↔¬p →¬q,
which is precisely the same as that associated with the left formula.

10
2
Propositional Logic: Formulas, Models, Tableaux
Although the formulas are not ambiguous—the trees have entirely different
structures—their representations as strings are ambiguous. Since we prefer to deal
with strings, we need some way to resolve such ambiguities. There are three ways
of doing this.
2.1.3 Resolving Ambiguity in the String Representation
Parentheses
The simplest way to avoid ambiguity is to use parentheses to maintain the structure
of the tree when the string is constructed.
Algorithm 2.7 (Represent a formula by a string with parentheses)
Input: A formula A of propositional logic.
Output: A string representation of A.
Call the recursive procedure Inorder(A):
Inorder(F)
if F is a leaf
write its label
return
let F1 and F2 be the left and right subtrees of F
write a left parenthesis ’(’
Inorder(F1)
write the label of the root of F
Inorder(F2)
write a right parenthesis ’)’
If the root of F is labeled by negation, the left subtree is considered to be empty and
the step Inorder(F1) is skipped.
The two formulas in Fig. 2.1 are now associated with two different strings and
there is no ambiguity:
((p →q) ↔((¬q) →(¬p))),
(p →(q ↔(¬(p →(¬q))))).
The problem with parentheses is that they make formulas verbose and hard to read
and write.
Precedence
The second way of resolving ambiguous formulas is to deﬁne precedence and as-
sociativity conventions among the operators as is done in arithmetic, so that we

2.1
Propositional Formulas
11
immediately recognize a ∗b ∗c + d ∗e as (((a ∗b) ∗c) + (d ∗e)). For formulas the
order of precedence from high to low is as follows:
¬
∧,↑
∨,↓
→
↔,⊕
Operators are assumed to associate to the right, that is, a ∨b∨c means (a ∨(b∨c)).
Parentheses are used only if needed to indicate an order different from that im-
posed by the rules for precedence and associativity, as in arithmetic where a∗(b+c)
needs parentheses to denote that the addition is done before the multiplication. With
minimal use of parentheses, the formulas above can be written:
p →q ↔¬q →¬p,
p →(q ↔¬(p →¬q)).
Additional parentheses may always be used to clarify a formula: (p ∨q) ∧(q ∨r).
The Boolean operators ∧, ∨, ↔, ⊕are associative so we will often omit paren-
theses in formulas that have repeated occurrences of these operators: p ∨q ∨r ∨s.
Note that →, ↓, ↑are not associative, so parentheses must be used to avoid confu-
sion. Although the implication operator is assumed to be right associative, so that
p →q →r unambiguously means p →(q →r), we will write the formula with
parentheses to avoid confusion with (p →q) →r.
Polish Notation *
There will be no ambiguity if the string representing a formula is created by a pre-
order traversal of the tree:
Algorithm 2.8 (Represent a formula by a string in Polish notation)
Input: A formula A of propositional logic.
Output: A string representation of A.
Call the recursive procedure Preorder(A):
Preorder(F)
write the label of the root of F
if F is a leaf
return
let F1 and F2 be the left and right subtrees of F
Preorder(F1)
Preorder(F2)
If the root of F is labeled by negation, the left subtree is considered to be empty and
the step Preorder(F1) is skipped.

12
2
Propositional Logic: Formulas, Models, Tableaux
Example 2.9 The strings associated with the two formulas in Fig. 2.1 are:
↔→p q →¬p¬q,
→p ↔q¬ →p¬q
and there is no longer any ambiguity.
The formulas are said to be in Polish notation, named after a group of Polish
logicians led by Jan Łukasiewicz.
We ﬁnd inﬁx notation easier to read because it is familiar from arithmetic, so
Polish notation is normally used only in the internal representation of arithmetic
and logical expressions in a computer. The advantage of Polish notation is that the
expression can be evaluated in the linear order that the symbols appear using a stack.
If we rewrite the ﬁrst formula backwards (reverse Polish notation):
q¬p¬ →qp →↔,
it can be directly compiled to the following sequence of instructions of an assembly
language:
Push q
Negate
Push p
Negate
Imply
Push q
Push p
Imply
Equiv
The operators are applied to the top operands on the stack which are then popped
and the result pushed.
2.1.4 Structural Induction
Given an arithmetic expression like a ∗b + b ∗c, it is immediately clear that the
expression is composed of two terms that are added together. In turn, each term is
composed of two factors that are multiplied together. In the same way, any proposi-
tional formula can be classiﬁed by its top-level operator.
Deﬁnition 2.10 Let A ∈F. If A is not an atom, the operator labeling the root of
the formula A is the principal operator of the A.
Example 2.11 The principal operator of the left formula in Fig. 2.1 is ↔, while the
principal operator of the right formulas is →.

2.1
Propositional Formulas
13
Structural induction is used to prove that a property holds for all formulas. This
form of induction is similar to the familiar numerical induction that is used to prove
that a property holds for all natural numbers (Appendix A.6). In numerical induc-
tion, the base case is to prove the property for 0 and then to prove the inductive step:
assume that the property holds for arbitrary n and then show that it holds for n + 1.
By Deﬁnition 2.10, a formula is either a leaf labeled by an atom or it is a tree with a
principal operator and one or two subtrees. The base case of structural induction is
to prove the property for a leaf and the inductive step is to prove the property for the
formula obtained by applying the principal operator to the subtrees, assuming that
the property holds for the subtrees.
Theorem 2.12 (Structural induction) To show that a property holds for all formulas
A ∈F:
1. Prove that the property holds all atoms p.
2. Assume that the property holds for a formula A and prove that the property holds
for ¬A.
3. Assume that the property holds for formulas A1 and A2 and prove that the prop-
erty holds for A1 op A2, for each of the binary operators.
Proof Let A be an arbitrary formula and suppose that (1), (2), (3) have been shown
for some property. We show that the property holds for A by numerical induction
on n, the height of the tree for A. For n = 0, the tree is a leaf and A is an atom p,
so the property holds by (1). Let n > 0. The subtrees A are of height n −1, so by
numerical induction, the property holds for these formulas. The principal operator
of A is either negation or one of the binary operators, so by (2) or (3), the property
holds for A.
We will later show that all the binary operators can be deﬁned in terms negation
and either disjunction or conjunction, so a proof that a property holds for all formu-
las can be done using structural induction with the base case and only two inductive
steps.
2.1.5 Notation
Unfortunately, books on mathematical logic use widely varying notation for the
Boolean operators; furthermore, the operators appear in programming languages
with a different notation from that used in mathematics textbooks. The following
table shows some of these alternate notations.

14
2
Propositional Logic: Formulas, Models, Tableaux
Operator
Alternates
Java language
¬
∼
!
∧
&
&, &&
∨
|, ||
→
⊃, ⇒
↔
≡, ⇔
⊕
̸≡
^
↑
|
2.1.6 A Formal Grammar for Formulas *
This subsection assumes familiarity with formal grammars.
Instead of deﬁning formulas as trees, they can be deﬁned as strings generated by
a context-free formal grammar.
Deﬁnition 2.13 Formula in propositional logic are derived from the context-free
grammar whose terminals are:
• An unbounded set of symbols P called atomic propositions.
• The Boolean operators given in Deﬁnition 2.1.
The productions of the grammar are:
fml ::= p
for any p ∈P
fml ::= ¬fml
fml ::= fml op fml
op
::= ∨| ∧| →| ↔| ⊕| ↑| ↓
A formula is a word that can be derived from the nonterminal fml. The set of all
formulas that can be derived from the grammar is denoted F.
Derivations of strings (words) in a formal grammar can be represented as trees
(Hopcroft et al., 2006, Sect. 4.3). The word generated by a derivation can be read
off the leaves from left to right.
Example 2.14 Here is a derivation of the formula p →q ↔¬p →¬q in proposi-
tional logic; the tree representing its derivation is shown in Fig. 2.2.

2.1
Propositional Formulas
15
Fig. 2.2 Derivation tree for p →q ↔¬p →¬q
1.
fml
2.
fml op fml
3.
fml ↔fml
4.
fml op fml ↔fml
5.
fml →fml ↔fml
6.
p →fml ↔fml
7.
p →q ↔fml
8.
p →q ↔fml op fml
9.
p →q ↔fml →fml
10.
p →q ↔¬fml →fml
11.
p →q ↔¬p →fml
12.
p →q ↔¬p →¬fml
13.
p →q ↔¬p →¬q
The methods discussed in Sect. 2.1.2 can be used to resolve ambiguity. We can
change the grammar to introduce parentheses:
fml ::= (¬fml)
fml ::= (fml op fml)
and then use precedence to reduce their number.

16
2
Propositional Logic: Formulas, Models, Tableaux
vI (A) = IA(A)
if A is an atom
vI (¬A) = T
if vI (A) = F
vI (¬A) = F
if vI (A) = T
vI (A1 ∨A2) = F
if vI (A1) = F and vI (A2) = F
vI (A1 ∨A2) = T
otherwise
vI (A1 ∧A2) = T
if vI (A1) = T and vI (A2) = T
vI (A1 ∧A2) = F
otherwise
vI (A1 →A2) = F
if vI (A1) = T and vI (A2) = F
vI (A1 →A2) = T
otherwise
vI (A1 ↑A2) = F
if vI (A1) = T and vI (A2) = T
vI (A1 ↑A2) = T
otherwise
vI (A1 ↓A2) = T
if vI (A1) = F and vI (A2) = F
vI (A1 ↓A2) = F
otherwise
vI (A1 ↔A2) = T
if vI (A1) = vI (A2)
vI (A1 ↔A2) = F
if vI (A1) ̸= vI (A2)
vI (A1 ⊕A2) = T
if vI (A1) ̸= vI (A2)
vI (A1 ⊕A2) = F
if vI (A1) = vI (A2)
Fig. 2.3 Truth values of formulas
2.2 Interpretations
We now deﬁne the semantics—the meaning—of formulas. Consider again arith-
metic expressions. Given an expression E such as a ∗b + 2, we can assign values
to a and b and then evaluate the expression. For example, if a = 2 and b = 3 then
E evaluates to 8. In propositional logic, truth values are assigned to the atoms of a
formula in order to evaluate the truth value of the formula.
2.2.1 The Deﬁnition of an Interpretation
Deﬁnition 2.15 Let A ∈F be a formula and let PA be the set of atoms appearing
in A. An interpretation for A is a total function IA : PA →{T,F} that assigns one
of the truth values T or F to every atom in PA.
Deﬁnition 2.16 Let IA be an interpretation for A ∈F. vIA(A), the truth value of
A under IA is deﬁned inductively on the structure of A as shown in Fig. 2.3.
In Fig. 2.3, we have abbreviated vIA(A) by vI (A). The abbreviation I for IA
will be used whenever the formula is clear from the context.
Example 2.17 Let A = (p →q) ↔(¬q →¬p) and let IA be the interpretation:
IA(p) = F,
IA(q) = T.

2.2
Interpretations
17
The truth value of A can be evaluated inductively using Fig. 2.3:
vI (p)
= IA(p) = F
vI (q)
= IA(q) = T
vI (p →q)
= T
vI (¬q)
= F
vI (¬p)
= T
vI (¬q →¬p)
= T
vI ((p →q) ↔(¬q →¬p)) = T.
Partial Interpretations *
We will later need the following deﬁnition, but you can skip it for now:
Deﬁnition 2.18 Let A ∈F. A partial interpretation for A is a partial function
IA : PA →{T,F} that assigns one of the truth values T or F to some of the atoms
in PA.
It is possible that the truth value of a formula can be determined in a partial
interpretation.
Example 2.19 Consider the formula A = p ∧q and the partial interpretation that as-
signs F to p. Clearly, the truth value of A is F . If the partial interpretation assigned
T to p, we cannot compute the truth value of A.
2.2.2 Truth Tables
A truth table is a convenient format for displaying the semantics of a formula by
showing its truth value for every possible interpretation of the formula.
Deﬁnition 2.20 Let A ∈F and supposed that there are n atoms in PA. A truth
table is a table with n + 1 columns and 2n rows. There is a column for each atom in
PA, plus a column for the formula A. The ﬁrst n columns specify the interpretation
I that maps atoms in PA to {T,F}. The last column shows vI (A), the truth value
of A for the interpretation I .
Since each of the n atoms can be assigned T or F independently, there are 2n
interpretations and thus 2n rows in a truth table.

18
2
Propositional Logic: Formulas, Models, Tableaux
Example 2.21 Here is the truth table for the formula p →q:
p
q
p →q
T
T
T
T
F
F
F
T
T
F
F
T
When the formula A is complex, it is easier to build a truth table by adding
columns that show the truth value for subformulas of A.
Example 2.22 Here is a truth table for the formula (p →q) ↔(¬q →¬p) from
Example 2.17:
p
q
p →q
¬p
¬q
¬q →¬p
(p →q) ↔(¬q →¬p)
T
T
T
F
F
T
T
T
F
F
F
T
F
T
F
T
T
T
F
T
T
F
F
T
T
T
T
T
A convenient way of computing the truth value of a formula for a speciﬁc inter-
pretation I is to write the value T or F of I (pi) under each atom pi and then
to write down the truth values incrementally under each operator as you perform
the computation. Each step of the computation consists of choosing an innermost
subformula and evaluating it.
Example 2.23 The computation of the truth value of (p →q) ↔(¬q →¬p) for
the interpretation I (p) = T and I (q) = F is:
(p
→
q)
↔
(¬
q
→
¬
p)
T
F
F
T
T
F
T
F
T
T
F
T
F
F
T
T
F
T
F
F
F
T
T
F
F
T
F
F
F
T
T
F
F
T
T
F
F
F
T

2.2
Interpretations
19
If the computations for all subformulas are written on the same line, the truth
table from Example 2.22 can be written as follows:
p
q
(p
→
q)
↔
(¬
q
→
¬
p)
T
T
T
T
T
T
F
T
T
F
T
T
F
T
F
F
T
T
F
F
F
T
F
T
F
T
T
T
F
T
T
T
F
F
F
F
T
F
T
T
F
T
T
F
2.2.3 Understanding the Boolean Operators
The natural reading of the Boolean operators ¬ and ∧correspond with their formal
semantics as deﬁned in Fig. 2.3. The operators ↑and ↓are simply negations of ∧
and ∨. Here we comment on the operators ∨, ⊕and →, whose formal semantics
can be the source of confusion.
Inclusive or vs. Exclusive or
Disjunction ∨is inclusive or and is a distinct operator from ⊕which is exclusive
or. Consider the compound statement:
At eight o’clock ‘I will go to the movies’ or ‘I will go to the theater’.
The intended meaning is ‘movies’ ⊕‘theater’, because I can’t be in both places at
the same time. This contrasts with the disjunctive operator ∨which evaluates to true
when either or both of the statements are true:
Do you want ‘popcorn’ or ‘candy’?
This can be denoted by ‘popcorn’ ∨‘candy’, because it is possible to want both of
them at the same time.
For ∨, it is sufﬁcient for one statement to be true for the compound statement to
be true. Thus, the following strange statement is true because the truth of the ﬁrst
statement by itself is sufﬁcient to ensure the truth of the compound statement:
‘Earth is farther from the sun than Venus’ ∨‘1 + 1 = 3’.
The difference between ∨and ⊕is seen when both subformulas are true:
‘Earth is farther from the sun than Venus’ ∨‘1 + 1 = 2’.
‘Earth is farther from the sun than Venus’ ⊕‘1 + 1 = 2’.
The ﬁrst statement is true but the second is false.

20
2
Propositional Logic: Formulas, Models, Tableaux
Inclusive or vs. Exclusive or in Programming Languages
When or is used in the context of programming languages, the intention is usually
inclusive or:
if (index < min || index > max) /* There is an error */
The truth of one of the two subexpressions causes the following statements to be
executed. The operator || is not really a Boolean operator because it uses short-
circuit evaluation: if the ﬁrst subexpression is true, the second subexpression is
not evaluated, because its truth value cannot change the decision to execute the
following statements. There is an operator | that performs true Boolean evaluation;
it is usually used when the operands are bit vectors:
mask1 = 0xA0;
mask2 = 0x0A;
mask
= mask1 | mask2;
Exclusive or ^ is used to implement encoding and decoding in error-correction
and cryptography. The reason is that when used twice, the original value can be
recovered. Suppose that we encode bit of data with a secret key:
codedMessage = data ^ key;
The recipient of the message can decode it by computing:
clearMessage = codedMessage ^ key;
as shown by the following computation:
clearMessage == codedMessage ^ key
== (data ^ key) ^ key
== data ^ (key ^ key)
== data ^ false
== data
Implication
The operator of p→q is called material implication; p is the antecedent and q is the
consequent. Material implication does not claim causation; that is, it does not assert
there the antecedent causes the consequent (or is even related to the consequent
in any way). A material implication merely states that if the antecedent is true the
consequent must be true (see Fig. 2.3), so it can be falsiﬁed only if the antecedent is
true and the consequent is false. Consider the following two compound statements:
‘Earth is farther from the sun than Venus’ →‘1 + 1 = 3’.
is false since the antecedent is true and the consequent is false, but:

2.3
Logical Equivalence
21
‘Earth is farther from the sun than Mars’ →‘1 + 1 = 3’.
is true! The falsity of the antecedent by itself is sufﬁcient to ensure the truth of the
implication.
2.2.4 An Interpretation for a Set of Formulas
Deﬁnition 2.24 Let S = {A1,...} be a set of formulas and let PS = 
i PAi, that
is, PS is the set of all the atoms that appear in the formulas of S. An interpretation
for S is a function IS : PS →{T,F}. For any Ai ∈S, vIS(Ai), the truth value of
Ai under IS, is deﬁned as in Deﬁnition 2.16.
The deﬁnition of PS as the union of the sets of atoms in the formulas of S
ensures that each atom is assigned exactly one truth value.
Example 2.25 Let S = {p →q, p, q ∧r, p ∨s ↔s ∧q} and let IS be the inter-
pretation:
IS(p) = T,
IS(q) = F,
IS(r) = T,
IS(s) = T.
The truth values of the elements of S can be evaluated as:
vI (p →q)
= F
vI (p)
= IS(p) = T
vI (q ∧r)
= F
vI (p ∨s)
= T
vI (s ∧q)
= F
vI (p ∨s ↔s ∧q) = F.
2.3 Logical Equivalence
Deﬁnition 2.26 Let A1, A2 ∈F. If vI (A1) = vI (A2) for all interpretations I ,
then A1 is logically equivalent to A2, denoted A1 ≡A2.
Example 2.27 Is the formula p ∨q logically equivalent to q ∨p? There are four
distinct interpretations that assign to the atoms p and q:
I (p)
I (q)
vI (p ∨q)
vI (q ∨p)
T
T
T
T
T
F
T
T
F
T
T
T
F
F
F
F

22
2
Propositional Logic: Formulas, Models, Tableaux
Since p ∨q and q ∨p agree on all the interpretations, p ∨q ≡q ∨p.
This example can be generalized to arbitrary formulas:
Theorem 2.28 Let A1, A2 ∈F. Then A1 ∨A2 ≡A2 ∨A1.
Proof Let I be an arbitrary interpretation for A1 ∨A2. Obviously, I is also an
interpretation for A2 ∨A1 since PA1 ∪PA2 = PA2 ∪PA1.
Since PA1 ⊆PA1 ∪PA2, I assigns truth values to all atoms in A1 and can be
considered to be an interpretation for A1. Similarly, I can be considered to be an
interpretation for A2.
Now vI (A1 ∨A2) = T if and only if either vI (A1) = T or vI (A2) = T , and
vI (A2 ∨A1) = T if and only if either vI (A2) = T or vI (A1) = T . If vI (A1) =
T , then:
vI (A1 ∨A2) = T = vI (A2 ∨A1),
and similarly if vI (A2) = T . Since I was arbitrary, A1 ∨A2 ≡A2 ∨A1.
This type of argument will be used frequently. In order to prove that something
is true of all interpretations, we let I be an arbitrary interpretation and then write a
proof without using any property that distinguishes one interpretation from another.
2.3.1 The Relationship Between ↔and ≡
Equivalence, ↔, is a Boolean operator in propositional logic and can appear in
formulas of the logic. Logical equivalence, ≡, is not a Boolean operator; instead,
is a notation for a property of pairs of formulas in propositional logic. There is
potential for confusion because we are using a similar vocabulary both for the object
language, in this case the language of propositional logic, and for the metalanguage
that we use reason about the object language.
Equivalence and logical equivalence are, nevertheless, closely related as shown
by the following theorem:
Theorem 2.29 A1 ≡A2 if and only if A1 ↔A2 is true in every interpretation.
Proof Suppose that A1 ≡A2 and let I be an arbitrary interpretation; then
vI (A1) = vI (A2) by deﬁnition of logical equivalence. From Fig. 2.3, vI (A1 ↔
A2) = T . Since I was arbitrary, vI (A1 ↔A2) = T in all interpretations. The proof
of the converse is similar.

2.3
Logical Equivalence
23
Fig. 2.4 Subformulas
2.3.2 Substitution
Logical equivalence justiﬁes substitution of one formula for another.
Deﬁnition 2.30 A is a subformula of B if A is a subtree of B. If A is not the same
as B, it is a proper subformula of B.
Example 2.31 Figure 2.4 shows a formula (the left formula from Fig. 2.1) and its
proper subformulas. Represented as strings, (p →q) ↔(¬p →¬q) contains the
proper subformulas: p →q, ¬p →¬q, ¬p, ¬q, p, q.
Deﬁnition 2.32 Let A be a subformula of B and let A′ be any formula. B{A ←A′},
the substitution of A′ for A in B, is the formula obtained by replacing all occurrences
of the subtree for A in B by A′.
Example 2.33 Let B = (p →q) ↔(¬p →¬q), A = p →q and A′ = ¬p ∨q.
B{A ←A′} = (¬p ∨q) ↔(¬q →¬p).
Given a formula A, substitution of a logically equivalent formula for a subfor-
mula of A does not change its truth value under any interpretation.
Theorem 2.34 Let A be a subformula of B and let A′ be a formula such that A ≡
A′. Then B ≡B{A ←A′}.

24
2
Propositional Logic: Formulas, Models, Tableaux
Proof Let I be an arbitrary interpretation. Then vI (A) = vI (A′) and we must
show that vI (B) = vI (B′). The proof is by induction on the depth d of the highest
occurrence of the subtree A in B.
If d = 0, there is only one occurrence of A, namely B itself. Obviously, vI (B) =
vI (A) = vI (A′) = vI (B′).
If d ̸= 0, then B is ¬B1 or B1 opB2 for some formulas B1, B2 and operator op. In
B1, the depth of A is less than d. By the inductive hypothesis, vI (B1) = vI (B′
1) =
vI (B1{A ←A′}), and similarly vI (B2) = vI (B′
2) = vI (B2{A ←A′}). By the
deﬁnition of v on the Boolean operators, vI (B) = vI (B′).
2.3.3 Logically Equivalent Formulas
Substitution of logically equivalence formulas is frequently done, for example, to
simplify a formula, and it is essential to become familiar with the common equiva-
lences that are listed in this subsection. Their proofs are elementary from the deﬁni-
tions and are left as exercises.
Absorption of Constants
Let us extend the syntax of Boolean formulas to include the two constant atomic
propositions true and false. (Another notation is ⊤for true and ⊥for false.) Their
semantics are deﬁned by I (true) = T and I (false) = F for any interpretation.
Do not confuse these symbols in the object language of propositional logic with
the truth values T and F used to deﬁne interpretations. Alternatively, it is possible
to regard true and false as abbreviations for the formulas p ∨¬p and p ∧¬p,
respectively.
The appearance of a constant in a formula can collapse the formula so that the
binary operator is no longer needed; it can even make a formula become a constant
whose truth value no longer depends on the non-constant subformula.
A ∨true
≡true
A ∧true
≡A
A ∨false
≡A
A ∧false
≡false
A →true
≡true
true →A
≡A
A →false ≡¬A
false →A ≡true
A ↔true
≡A
A ⊕true
≡¬A
A ↔false
≡¬A
A ⊕false
≡A

2.3
Logical Equivalence
25
Identical Operands
Collapsing can also occur when both operands of an operator are the same or one is
the negation of another.
A
≡¬¬A
A
≡A ∧A
A
≡
A ∨A
A ∨¬A ≡true
A ∧¬A
≡
false
A →A
≡true
A ↔A
≡true
A ⊕A
≡
false
¬A
≡A ↑A¬A
≡
A ↓A
Commutativity, Associativity and Distributivity
The binary Boolean operators are commutative, except for implication.
A ∨B
≡B ∨A
A ∧B
≡B ∧A
A ↔B
≡B ↔A
A ⊕B
≡B ⊕A
A ↑B
≡B ↑A
A ↓B
≡B ↓A
If negations are added, the direction of an implication can be reversed:
A →B ≡¬B →¬A
The formula ¬B →¬A is the contrapositive of A →B.
Disjunction, conjunction, equivalence and non-equivalence are associative.
A ∨(B ∨C)
≡(A ∨B) ∨C
A ∧(B ∧C)
≡(A ∧B) ∧C
A ↔(B ↔C) ≡(A ↔B) ↔C
A ⊕(B ⊕C) ≡(A ⊕B) ⊕C
Implication, nor and nand are not associative.
Disjunction and conjunction distribute over each other.
A ∨(B ∧C) ≡(A ∨B) ∧(A ∨C)
A ∧(B ∨C) ≡(A ∧B) ∨(A ∧C)
Deﬁning One Operator in Terms of Another
When proving theorems about propositional logic using structural induction, we
have to prove the inductive step for each of the binary operators. It will simplify
proofs if we can eliminate some of the operators by replacing subformulas with
formulas that use another operator. For example, equivalence can be eliminated be-

26
2
Propositional Logic: Formulas, Models, Tableaux
cause it can be deﬁned in terms of conjunction and implication. Another reason for
eliminating operators is that many algorithms on propositional formulas require that
the formulas be in a normal form, using a speciﬁed subset of the Boolean operators.
Here is a list of logical equivalences that can be used to eliminate operators.
A ↔B
≡(A →B) ∧(B →A)
A ⊕B
≡¬(A →B) ∨¬(B →A)
A →B
≡¬A ∨B
A →B
≡¬(A ∧¬B)
A ∨B
≡¬(¬A ∧¬B)
A ∧B
≡¬(¬A ∨¬B)
A ∨B
≡¬A →B
A ∧B
≡¬(A →¬B)
The deﬁnition of conjunction in terms of disjunction and negation, and the deﬁnition
of disjunction in terms of conjunction and negation are called De Morgan’s laws.
2.4 Sets of Boolean Operators *
From our earliest days in school, we are taught that there are four basic operators
in arithmetic: addition, subtraction, multiplication and division. Later on, we learn
about additional operators like modulo and absolute value. On the other hand, mul-
tiplication and division are theoretically redundant because they can be deﬁned in
terms of addition and subtraction.
In this section, we will look at two issues: What Boolean operators are there?
What sets of operators are adequate, meaning that all other operators can be deﬁned
using just the operators in the set?
2.4.1 Unary and Binary Boolean Operators
Since there are only two Boolean values T and F , the number of possible n-place
operators is 22n, because for each of the n arguments we can choose either of the
two values T and F and for each of these 2n n-tuples of arguments we can choose
the value of the operator to be either T or F . We will restrict ourselves to one- and
two-place operators.
The following table shows the 221 = 4 possible one-place operators, where the
ﬁrst column gives the value of the operand x and the other columns give the value
of the nth operator ◦n(x):
x
◦1
◦2
◦3
◦4
T
T
T
F
F
F
T
F
T
F

2.4
Sets of Boolean Operators *
27
x1
x2
◦1
◦2
◦3
◦4
◦5
◦6
◦7
◦8
T
T
T
T
T
T
T
T
T
T
T
F
T
T
T
T
F
F
F
F
F
T
T
T
F
F
T
T
F
F
F
F
T
F
T
F
T
F
T
F
x1
x2
◦9
◦10
◦11
◦12
◦13
◦14
◦15
◦16
T
T
F
F
F
F
F
F
F
F
T
F
T
T
T
T
F
F
F
F
F
T
T
T
F
F
T
T
F
F
F
F
T
F
T
F
T
F
T
F
Fig. 2.5 Two-place Boolean operators
Of the four one-place operators, three are trivial: ◦1 and ◦4 are the constant oper-
ators, and ◦2 is the identity operator which simply maps the operand to itself. The
only non-trivial one-place operator is ◦3 which is negation.
There are 222 = 16 two-place operators (Fig. 2.5). Several of the operators are
trivial: ◦1 and ◦16 are constant; ◦4 and ◦6 are projection operators, that is, their value
is determined by the value of only one of operands; ◦11 and ◦13 are the negations of
the projection operators.
The correspondence between the operators in the table and those we deﬁned in
Deﬁnition 2.1 are shown in the following table, where the operators in the right-hand
column are the negations of those in the left-hand column.
op
name
symbol
op
name
symbol
◦2
disjunction
∨
◦15
nor
↓
◦8
conjunction
∧
◦9
nand
↑
◦5
implication
→
◦7
equivalence
↔
◦10
exclusive or
⊕
The operator ◦12 is the negation of implication and is not used. Reverse implication,
◦3, is used in logic programming (Chap. 11); its negation, ◦14, is not used.
2.4.2 Adequate Sets of Operators
Deﬁnition 2.35 A binary operator ◦is deﬁned from a set of operators {◦1,...,◦n}
iff there is a logical equivalence A1◦A2 ≡A, where A is a formula constructed from
occurrences of A1 and A2 using the operators {◦1,...,◦n}. The unary operator ¬

28
2
Propositional Logic: Formulas, Models, Tableaux
is deﬁned by a formula ¬A1 ≡A, where A is constructed from occurrences of A1
and the operators in the set.
Theorem 2.36 The Boolean operators ∨,∧,→,↔,⊕,↑,↓can be deﬁned from
negation and one of ∨,∧,→.
Proof The theorem follows by using the logical equivalences in Sect. 2.3.3. The
nand and nor operators are the negations of conjunction and disjunction, respec-
tively. Equivalence can be deﬁned from implication and conjunction and non-
equivalence can be deﬁned using these operators and negation. Therefore, we need
only →,∨,∧, but each of these operators can be deﬁned by one of the others and
negation as shown by the equivalences on page 26.
It may come as a surprise that it is possible to deﬁne all Boolean operators from
either nand or nor alone. The equivalence ¬A ≡A ↑A is used to deﬁne negation
from nand and the following sequence of equivalences shows how conjunction can
be deﬁned:
(A ↑B) ↑(A ↑B)
≡by the deﬁnition of ↑
¬((A ↑B) ∧(A ↑B)) ≡by idempotence
¬(A ↑B)
≡by the deﬁnition of ↑
¬¬(A ∧B)
≡by double negation
A ∧B.
From the formulas for negation and conjunction, all other operators can be deﬁned.
Similarly deﬁnitions are possible using nor.
In fact it can be proved that only nand and nor have this property.
Theorem 2.37 Let ◦be a binary operator that can deﬁne negation and all other
binary operators by itself. Then ◦is either nand or nor.
Proof We give an outline of the proof and leave the details as an exercise.
Suppose that ◦is an operator that can deﬁne all the other operators. Negation
must be deﬁned by an equivalence of the form:
¬A ≡A ◦··· ◦A.
Any binary operator op must be deﬁned by an equivalence:
A1 op A2 ≡B1 ◦··· ◦Bn,
where each Bi is either A1 or A2. (If ◦is not associative, add parentheses as neces-
sary.) We will show that these requirements impose restrictions on ◦so that it must
be nand or nor.
Let I be any interpretation such that vI (A) = T ; then
F = vI (¬A) = vI (A ◦··· ◦A).

2.5
Satisﬁability, Validity and Consequence
29
Prove by induction on the number of occurrences of ◦that vI (A1 ◦A2) = F
when vI (A1) = T and vI (A2) = T . Similarly, if I is an interpretation such that
vI (A) = F , prove that vI (A1 ◦A2) = T .
Thus the only freedom we have in deﬁning ◦is in the case where the two
operands are assigned different truth values:
A1
A2
A1 ◦A2
T
T
F
T
F
T or F
F
T
T or F
F
F
T
If ◦is deﬁned to give the same truth value T for these two lines then ◦is nand, and
if ◦is deﬁned to give the same truth value F then ◦is nor.
The remaining possibility is that ◦is deﬁned to give different truth values for
these two lines. Prove by induction that only projection and negated projection are
deﬁnable in the sense that:
B1 ◦··· ◦Bn ≡¬ ···¬Bi
for some i and zero or more negations.
2.5 Satisﬁability, Validity and Consequence
We now deﬁne the fundamental concepts of the semantics of formulas:
Deﬁnition 2.38 Let A ∈F.
• A is satisﬁable iff vI (A) = T for some interpretation I .
A satisfying interpretation is a model for A.
• A is valid, denoted |= A, iff vI (A) = T for all interpretations I .
A valid propositional formula is also called a tautology.
• A is unsatisﬁable iff it is not satisﬁable, that is, if vI (A) = F for all interpreta-
tions I .
• A is falsiﬁable, denoted ̸|= A, iff it is not valid, that is, if vI (A) = F for some
interpretation v.
These concepts are illustrated in Fig. 2.6.
The four semantical concepts are closely related.
Theorem 2.39 Let A ∈F. A is valid if and only if ¬A is unsatisﬁable. A is satis-
ﬁable if and only if ¬A is falsiﬁable.

30
2
Propositional Logic: Formulas, Models, Tableaux
Fig. 2.6 Satisﬁability and validity of formulas
Proof Let I be an arbitrary interpretation. vI (A) = T if and only if vI (¬A) = F
by the deﬁnition of the truth value of a negation. Since I was arbitrary, A is true in
all interpretations if and only if ¬A is false in all interpretations, that is, iff ¬A is
unsatisﬁable.
If A is satisﬁable then for some interpretation I , vI (A) = T . By deﬁnition of
the truth value of a negation, vI (¬A) = F so that ¬A is falsiﬁable. Conversely, if
vI (¬A) = F then vI (A) = T .
2.5.1 Decision Procedures in Propositional Logic
Deﬁnition 2.40 Let U ⊆F be a set of formulas. An algorithm is a decision pro-
cedure for U if given an arbitrary formula A ∈F, it terminates and returns the
answer yes if A ∈U and the answer no if A ̸∈U .
If U is the set of satisﬁable formulas, a decision procedure for U is called a
decision procedure for satisﬁability, and similarly for validity.
By Theorem 2.39, a decision procedure for satisﬁability can be used as a decision
procedure for validity. To decide if A is valid, apply the decision procedure for
satisﬁability to ¬A. If it reports that ¬A is satisﬁable, then A is not valid; if it
reports that ¬A is not satisﬁable, then A is valid. Such an decision procedure is
called a refutation procedure, because we prove the validity of a formula by refuting
its negation. Refutation procedures can be efﬁcient algorithms for deciding validity,
because instead of checking that the formula is always true, we need only search for
a falsifying counterexample.
The existence of a decision procedure for satisﬁability in propositional logic is
trivial, because we can build a truth table for any formula. The truth table in Ex-
ample 2.21 shows that p →q is satisﬁable, but not valid; Example 2.22 shows that
(p →q) ↔(¬q →¬p) is valid. The following example shows an unsatisﬁable
formula.

2.5
Satisﬁability, Validity and Consequence
31
Example 2.41 The formula (p ∨q) ∧¬p ∧¬q is unsatisﬁable because all lines of
its truth table evaluate to F .
p
q
p ∨q
¬p
¬q
(p ∨q) ∧¬p ∧¬q
T
T
T
F
F
F
T
F
T
F
T
F
F
T
T
T
F
F
F
F
F
T
T
F
The method of truth tables is a very inefﬁcient decision procedure because we
need to evaluate a formula for each of 2n possible interpretations, where n is the
number of distinct atoms in the formula. In later chapters we will discuss more
efﬁcient decision procedures for satisﬁability, though it is extremely unlikely that
there is a decision procedure that is efﬁcient for all formulas (see Sect. 6.7).
2.5.2 Satisﬁability of a Set of Formulas
The concept of satisﬁability can be extended to a set of formulas.
Deﬁnition 2.42 A set of formulas U = {A1,...} is (simultaneously) satisﬁable iff
there exists an interpretation I such that vI (Ai) = T for all i. The satisfying in-
terpretation is a model of U. U is unsatisﬁable iff for every interpretation I , there
exists an i such that vI (Ai) = F .
Example 2.43 The set U1 = {p, ¬p ∨q, q ∧r} is simultaneously satisﬁable by the
interpretation which assigns T to each atom, while the set U2 = {p, ¬p ∨q, ¬p}
is unsatisﬁable. Each formula in U2 is satisﬁable by itself, but the set is not simulta-
neously satisﬁable.
The proofs of the following elementary theorems are left as exercises.
Theorem 2.44 If U is satisﬁable, then so is U −{Ai} for all i.
Theorem 2.45 If U is satisﬁable and B is valid, then U ∪{B} is satisﬁable.
Theorem 2.46 If U is unsatisﬁable, then for any formula B, U ∪{B} is unsatisﬁ-
able.
Theorem 2.47 If U is unsatisﬁable and for some i, Ai is valid, then U −{Ai} is
unsatisﬁable.

32
2
Propositional Logic: Formulas, Models, Tableaux
2.5.3 Logical Consequence
Deﬁnition 2.48 Let U be a set of formulas and A a formula. A is a logical conse-
quence of U, denoted U |= A, iff every model of U is a model of A.
The formula A need not be true in every possible interpretation, only in those
interpretations which satisfy U, that is, those interpretations which satisfy every
formula in U. If U is empty, logical consequence is the same as validity.
Example 2.49 Let A = (p ∨r) ∧(¬q ∨¬r). Then A is a logical consequence
of {p,¬q}, denoted {p,¬q} |= A, since A is true in all interpretations I such
that I (p) = T and I (q) = F . However, A is not valid, since it is not true in the
interpretation I ′ where I ′(p) = F , I ′(q) = T , I ′(r) = T .
The caveat concerning ↔and ≡also applies to →and |=. Implication, →,
is an operator in the object language, while |= is a symbol for a concept in the
metalanguage. However, as with equivalence, the two concepts are related:
Theorem 2.50 U |= A if and only if |= 
i Ai →A.
Deﬁnition 2.51 i=n
i=1 Ai is an abbreviation for A1 ∧··· ∧An. The notation 
i is
used if the bounds are obvious from the context or if the set of formulas is inﬁnite.
A similar notation  is used for disjunction.
Example 2.52 From Example 2.49, {p,¬q} |= (p ∨r) ∧(¬q ∨¬r), so by Theo-
rem 2.50, |= (p ∧¬q) →(p ∨r) ∧(¬q ∨¬r).
The proof of Theorem 2.50, as well as the proofs of the following two theorems
are left as exercises.
Theorem 2.53 If U |= A then U ∪{B} |= A for any formula B.
Theorem 2.54 If U |= A and B is valid then U −{B} |= A.
2.5.4 Theories *
Logical consequence is the central concept in the foundations of mathematics. Valid
logical formulas such as p ∨q ↔q ∨p are of little mathematical interest. It is much
more interesting to assume that a set of formulas is true and then to investigate
the consequences of these assumptions. For example, Euclid assumed ﬁve formulas
about geometry and deduced an extensive set of logical consequences. The formal
deﬁnition of a mathematical theory is as follows.
Deﬁnition 2.55 Let T be a set of formulas. T is closed under logical consequence
iff for all formulas A, if T |= A then A ∈T . A set of formulas that is closed under
logical consequence is a theory. The elements of T are theorems.

2.6
Semantic Tableaux
33
Theories are constructed by selecting a set of formulas called axioms and deduc-
ing their logical consequences.
Deﬁnition 2.56 Let T be a theory. T is said to be axiomatizable iff there exists a
set of formulas U such that T = {A | U |= A}. The set of formulas U are the axioms
of T . If U is ﬁnite, T is said to be ﬁnitely axiomatizable.
Arithmetic is axiomatizable: There is a set of axioms developed by Peano whose
logical consequences are theorems of arithmetic. Arithmetic is not ﬁnitely axioma-
tizable, because the induction axiom is not by a single axiom but an axiom scheme
with an instance for each property in arithmetic.
2.6 Semantic Tableaux
The method of semantic tableaux is an efﬁcient decision procedure for satisﬁability
(and by duality validity) in propositional logic. We will use semantic tableaux ex-
tensively in the next chapter to prove important theorems about deductive systems.
The principle behind semantic tableaux is very simple: search for a model (satisfy-
ing interpretation) by decomposing the formula into sets of atoms and negations of
atoms. It is easy to check if there is an interpretation for each set: a set of atoms
and negations of atoms is satisﬁable iff the set does not contain an atom p and its
negation ¬p. The formula is satisﬁable iff one of these sets is satisﬁable.
We begin with some deﬁnitions and then analyze the satisﬁability of two formu-
las to motivate the construction of semantic tableaux.
2.6.1 Decomposing Formulas into Sets of Literals
Deﬁnition 2.57 A literal is an atom or the negation of an atom. An atom is a positive
literal and the negation of an atom is a negative literal. For any atom p, {p,¬p} is
a complementary pair of literals.
For any formula A, {A,¬A} is a complementary pair of formulas. A is the com-
plement of ¬A and ¬A is the complement of A.
Example 2.58 In the set of literals {¬p,q,r,¬r}, q and r are positive literals, while
¬p and ¬r are negative literals. The set contains the complementary pair of literals
{r,¬r}.
Example 2.59 Let us analyze the satisﬁability of the formula:
A = p ∧(¬q ∨¬p)
in an arbitrary interpretation I , using the inductive rules for the evaluation of the
truth value of a formula.

34
2
Propositional Logic: Formulas, Models, Tableaux
• The principal operator of A is conjunction, so vI (A) = T if and only if both
vI (p) = T and vI (¬q ∨¬p) = T .
• The principal operator of ¬q ∨¬p is disjunction, so vI (¬q ∨¬p) = T if and
only if either vI (¬q) = T or vI (¬p) = T .
• Integrating the information we have obtained from this analysis, we conclude that
vI (A) = T if and only if either:
1. vI (p) = T and vI (¬q) = T , or
2. vI (p) = T and vI (¬p) = T .
A is satisﬁable if and only if there is an interpretation such that (1) holds or an
interpretation such that (2) holds.
We have reduced the question of the satisﬁability of A to a question about the
satisﬁability of sets of literals.
Theorem 2.60 A set of literals is satisﬁable if and only if it does not contain a
complementary pair of literals.
Proof Let L be a set of literals that does not contain a complementary pair. Deﬁne
the interpretation I by:
I (p) = T
if p ∈L,
I (p) = F
if ¬p ∈L.
The interpretation is well-deﬁned—there is only one value assigned to each atom in
L—since there is no complementary pair of literals in L. Each literal in L evaluates
to T so L is satisﬁable.
Conversely, if {p,¬p} ⊆L, then for any interpretation I for the atoms in L,
either vI (p) = F or vI (¬p) = F , so L is not satisﬁable.
Example 2.61 Continuing the analysis of the formula A = p∧(¬q ∨¬p) from Ex-
ample 2.59, A is satisﬁable if and only at least one of the sets {p,¬p} and {p,¬q}
does not contain a complementary pair of literals. Clearly, only the second set does
not contain a complementary pair of literals. Using the method described in Theo-
rem 2.60, we obtain the interpretation:
I (p) = T,
I (q) = F.
We leave it to the reader to check that for this interpretation, vI (A) = T .
The following example shows what happens if a formula is unsatisﬁable.
Example 2.62 Consider the formula:
B = (p ∨q) ∧(¬p ∧¬q).

2.6
Semantic Tableaux
35
Fig. 2.7 Semantic tableaux
The analysis of the formula proceeds as follows:
• vI (B) = T if and only if vI (p ∨q) = T and vI (¬p ∧¬q) = T .
• Decomposing the conjunction, vI (B)=T if and only if vI (p ∨q) = T and
vI (¬p) = vI (¬q) = T .
• Decomposing the disjunction, vI (B) = T if and only if either:
1. vI (p) = vI (¬p) = vI (¬q) = T , or
2. vI (q) = vI (¬p) = vI (¬q) = T .
Both sets of literals {p,¬p,¬q} and {q,¬p,¬q} contain complementary pairs,
so by Theorem 2.60, both set of literals are unsatisﬁable. We conclude that it is
impossible to ﬁnd a model for B; in other words, B is unsatisﬁable.
2.6.2 Construction of Semantic Tableaux
The decomposition of a formula into sets of literals is rather difﬁcult to follow when
expressed textually, as we did in Examples 2.59 and 2.62. In the method of semantic
tableaux, sets of formulas label nodes of a tree, where each path in the tree represents
the formulas that must be satisﬁed in one possible interpretation.
The initial formula labels the root of the tree; each node has one or two child
nodes depending on how a formula labeling the node is decomposed. The leaves are
labeled by the sets of literals. A leaf labeled by a set of literals containing a comple-
mentary pair of literals is marked ×, while a leaf labeled by a set not containing a
complementary pair is marked ⊙.
Figure 2.7 shows semantic tableaux for the formulas from the examples.
The tableau construction is not unique; here is another tableau for B:
(p ∨q) ∧(¬p ∧¬q)
↓
p ∨q,¬p ∧¬q
↙
↘
p,¬p ∧¬q
q,¬p ∧¬q
↓
↓
p,¬p,¬q
q,¬p,¬q
×
×

36
2
Propositional Logic: Formulas, Models, Tableaux
α
α1
α2
¬¬A1
A1
A1 ∧A2
A1
A2
¬(A1 ∨A2)
¬A1
¬A2
¬(A1 →A2)
A1
¬A2
¬(A1 ↑A2)
A1
A2
A1 ↓A2
¬A1
¬A2
A1 ↔A2
A1→A2
A2→A1
¬(A1 ⊕A2)
A1→A2
A2→A1
β
β1
β2
¬(B1 ∧B2)
¬B1
¬B2
B1 ∨B2
B1
B2
B1 →B2
¬B1
B2
B1 ↑B2
¬B1
¬B2
¬(B1 ↓B2)
B1
B2
¬(B1 ↔B2)
¬(B1→B2)
¬(B2→B1)
B1 ⊕B2
¬(B1→B2)
¬(B2→B1)
Fig. 2.8 Classiﬁcation of α- and β-formulas
It is constructed by branching to search for a satisfying interpretation for p ∨q be-
fore searching for one for ¬p∧¬q. The ﬁrst tableau contains fewer nodes, showing
that it is preferable to decompose conjunctions before disjunctions.
A concise presentation of the rules for creating a semantic tableau can be given if
formulas are classiﬁed according to their principal operator (Fig. 2.8). If the formula
is a negation, the classiﬁcation takes into account both the negation and the principal
operator. α-formulas are conjunctive and are satisﬁable only if both subformulas α1
and α2 are satisﬁed, while β-formulas are disjunctive and are satisﬁed even if only
one of the subformulas β1 or β2 is satisﬁable.
Example 2.63 The formula p ∧q is classiﬁed as an α-formula because it is true if
and only if both p and q are true. The formula ¬(p ∧q) is classiﬁed as a β-formula.
It is logically equivalent to ¬p ∨¬q and is true if and only if either ¬p is true or
¬q is true.
We now give the algorithm for the construction of a semantic tableau for a for-
mula in propositional logic.
Algorithm 2.64 (Construction of a semantic tableau)
Input: A formula φ of propositional logic.
Output: A semantic tableau T for φ all of whose leaves are marked.
Initially, T is a tree consisting of a single root node labeled with the singleton
set {φ}. This node is not marked.
Repeat the following step as long as possible: Choose an unmarked leaf l labeled
with a set of formulas U(l) and apply one of the following rules.
• U(l) is a set of literals. Mark the leaf closed × if it contains a complementary
pair of literals. If not, mark the leaf open ⊙.
• U(l) is not a set of literals. Choose a formula in U(l) which is not a literal.
Classify the formula as an α-formula A or as a β-formula B and perform one of
the following steps according to the classiﬁcation:

2.6
Semantic Tableaux
37
– A is an α-formula. Create a new node l′ as a child of l and label l′ with:
U(l′) = (U(l) −{A}) ∪{A1,A2}.
(In the case that A is ¬¬A1, there is no A2.)
– B is a β-formula. Create two new nodes l′ and l′′ as children of l. Label l′ with:
U(l′) = (U(l) −{B}) ∪{B1},
and label l′′ with:
U(l′′) = (U(l) −{B}) ∪{B2}.
Deﬁnition 2.65 A tableau whose construction has terminated is a completed tab-
leau. A completed tableau is closed if all its leaves are marked closed. Otherwise (if
some leaf is marked open), it is open.
2.6.3 Termination of the Tableau Construction
Since each step of the algorithm decomposes one formula into one or two simpler
formulas, it is clear that the construction of the tableau for any formula terminates,
but it is worth proving this claim.
Theorem 2.66 The construction of a tableau for any formula φ terminates. When
the construction terminates, all the leaves are marked × or ⊙.
Proof Let us assume that ↔and ⊕do not occur in the formula φ; the extension of
the proof for these cases is left as an exercise.
Consider an unmarked leaf l that is chosen to be expanded during the construc-
tion of the tableau. Let b(l) be the total number of binary operators in all formulas
in U(l) and let n(l) be the total number of negations in U(l). Deﬁne:
W(l) = 3 · b(l) + n(l).
For example, if U(l) = {p ∨q,¬p ∧¬q}, then W(l) = 3 · 2 + 2 = 8.
Each step of the algorithm adds either a new node l′ or a pair of new nodes
l′,l′′ as children of l. We claim that W(l′) < W(l) and, if there is a second node,
W(l′′) < W(l).
Suppose that A = ¬(A1 ∨A2) and that the rule for this α-formula is applied at l
to obtain a new leaf l′ labeled:
U(l′) = (U(l) −{¬(A1 ∨A2)}) ∪{¬A1,¬A2}.
Then:
W(l′) = W(l) −(3 · 1 + 1) + 2 = W(l) −2 < W(l),

38
2
Propositional Logic: Formulas, Models, Tableaux
because one binary operator and one negation are removed, while two negations are
added.
Suppose now that B = B1 ∨B2 and that the rule for this β-formula is applied at
l to obtain two new leaves l′,l′′ labeled:
U(l′) = (U(l) −{B1 ∨B2}) ∪{B1},
U(l′′) = (U(l) −{B1 ∨B2}) ∪{B2}.
Then:
W(l′) ≤W(l) −(3 · 1) < W(l),
W(l′′) ≤W(l) −(3 · 1) < W(l).
We leave it to the reader to prove that W(l) decreases for the other α- and β-
formulas.
The value of W(l) decreases as each branch in the tableau is extended. Since,
obviously, W(l) ≥0, no branch can be extended indeﬁnitely and the construction of
the tableau must eventually terminate.
A branch can always be extended if its leaf is labeled with a set of formulas that
is not a set of literals. Therefore, when the construction of the tableau terminates,
all leaves are labeled with sets of literals and each is marked open or closed by the
ﬁrst rule of the algorithm.
2.6.4 Improving the Efﬁciency of the Algorithm *
The algorithm for constructing a tableau is not deterministic: at most steps, there
is a choice of which leaf to extend and if the leaf contains more than one formula
which is not a literal, there is a choice of which formula to decompose. This opens
the possibility of applying heuristics in order to cause the tableau to be completed
quickly. We saw in Sect. 2.6.2 that it is better to decompose α-formulas before β-
formulas to avoid duplication.
Tableaux can be shortened by closing a branch if it contains a formula and its
negation and not just a pair of complementary literals. Clearly, there is no reason to
continue expanding a node containing:
(p ∧(q ∨r)),
¬(p ∧(q ∨r)).
We leave it as an exercise to prove that this modiﬁcation preserves the correctness
of the algorithm.
There is a lot of redundancy in copying formulas from one node to another:
U(l′) = (U(l) −{A}) ∪{A1,A2}.
In a variant of semantic tableaux called analytic tableaux (Smullyan, 1968), when a
new node is created, it is labeled only with the new formulas:

2.7
Soundness and Completeness
39
U(l′) = {A1,A2}.
The algorithm is changed so that the formula to be decomposed is selected from the
set of formulas labeling the nodes on the branch from the root to a leaf (provided,
of course, that the formula has not already been selected). A leaf is marked closed
if two complementary literals (or formulas) appear in the labels of one or two nodes
on a branch, and a leaf is marked open if is not closed but there are no more formulas
to decompose.
Here is an analytic tableau for the formula B from Example 2.62, where the
formula p ∨q is not copied from the second node to the third when p ∧q is decom-
posed:
(p ∨q) ∧(¬p ∧¬q)
↓
p ∨q,¬p ∧¬q
↓
¬p,¬q
↙
↘
p
q
×
×
We prefer to use semantic tableaux because it is easy to see which formulas are
candidates for decomposition and how to mark leaves.
2.7 Soundness and Completeness
The construction of a semantic tableau is a purely formal. The decomposition of a
formula depends solely on its syntactical properties: its principal operator and—if it
is a negation—the principal operator of the formula that is negated. We gave several
examples to motivate semantic tableau, but we have not yet proven that the algorithm
is correct. We have not connected the syntactical outcome of the algorithm (Is the
tableau closed or not?) with the semantical concept of truth value. In this section,
we prove that the algorithm is correct in the sense that it reports that a formula is
satisﬁable or unsatisﬁable if and only if there exists or does not exist a model for the
formula.
The proof techniques of this section should be studied carefully because they will
be used again and again in other logical systems.
Theorem 2.67 Soundness and completeness Let T be a completed tableau for a
formula A. A is unsatisﬁable if and only if T is closed.
Here are some corollaries that follow from the theorem.
Corollary 2.68 A is satisﬁable if and only if T is open.
Proof A is satisﬁable iff (by deﬁnition) A is not unsatisﬁable iff (by Theorem 2.67)
T is not closed iff (by deﬁnition) T is open.

40
2
Propositional Logic: Formulas, Models, Tableaux
Corollary 2.69 A is valid if and only if the tableau for ¬A closes.
Proof A is valid iff ¬A is unsatisﬁable iff the tableau for ¬A closes.
Corollary 2.70 The method of semantic tableaux is a decision procedure for valid-
ity in propositional logic.
Proof Let A be a formula of propositional logic. By Theorem 2.66, the construction
of the semantic tableau for ¬A terminates in a completed tableau. By the previous
corollary, A is valid if and only if the completed tableau is closed.
The forward direction of Corollary 2.69 is called completeness: if A is valid,
we can discover this fact by constructing a tableau for ¬A and the tableau will
close. The converse direction is called soundness: any formula A that the tableau
construction claims valid (because the tableau for ¬A closes) actually is valid. In-
variably in logic, soundness is easier to show than completeness. The reason is that
while we only include in a formal system rules that are obviously sound, it is hard
to be sure that we haven’t forgotten some rule that may be needed for completeness.
At the extreme, the following vacuous algorithm is sound but far from complete!
Algorithm 2.71 (Incomplete decision procedure for validity)
Input: A formula A of propositional logic.
Output: A is not valid.
Example 2.72 If the rule for ¬(A1 ∨A2) is omitted, the construction of the tab-
leau is still sound, but it is not complete, because it is impossible to construct a
closed tableau for the obviously valid formula A = ¬p ∨p. Label the root of the
tableau with the negation ¬A = ¬(¬p ∨p); there is now no rule that can be used
to decompose the formula.
2.7.1 Proof of Soundness
The theorem to be proved is: if the tableau T for a formula A closes, then A is un-
satisﬁable. We will prove a more general theorem: if Tn, the subtree rooted at node
n of T , closes then the set of formulas U(n) labeling n is unsatisﬁable. Soundness
is the special case for the root.
To make the proof easier to follow, we will use A1 ∧A2 and B1 ∨B2 as repre-
sentatives of the classes of α- and β-formulas, respectively.
Proof of Soundness The proof is by induction on the height hn of the node n in Tn.
Clearly, a closed leaf is labeled by an unsatisﬁable set of formulas. Recall (Deﬁni-
tion 2.42) that a set of formulas is unsatisﬁable iff for any interpretation the truth
value of at least one formula is false. In the inductive step, if the children of a node n

2.7
Soundness and Completeness
41
are labeled by an unsatisﬁable set of formulas, then: (a) either the unsatisﬁable for-
mula also appears in the label of n, or (b) the unsatisﬁable formulas in the labels of
the children were used to construct an unsatisﬁable formula in the label of n. Let us
write out the formal proof.
For the base case, hn = 0, assume that Tn closes. Since hn = 0 means that n is a
leaf, U(n) must contain a complementary set of literals so it is unsatisﬁable.
For the inductive step, let n be a node such that hn > 0 in Tn. We need to show
that Tn is closed implies that U(n) is unsatisﬁable. By the inductive hypothesis,
we can assume that for any node m of height hm < hn, if Tm closes, then U(m) is
unsatisﬁable.
Since hn > 0, the rule for some α- or β-formula was used to create the children
of n:
n′ : {A1,A2} ∪U0
n : {A1 ∧A2} ∪U0
n′ : {B1} ∪U0
n′′ : {B2} ∪U0
n : {B1 ∨B2} ∪U0





@
@
@
@
@
Case 1: U(n) = {A1 ∧A2} ∪U0 and U(n′) = {A1,A2} ∪U0 for some (possibly
empty) set of formulas U0.
Clearly, Tn′ is also a closed tableau and since hn′ = hn −1, by the inductive
hypothesis U(n′) is unsatisﬁable. Let I be an arbitrary interpretation. There
are two possibilities:
• vI (A0) = F for some formula A0 ∈U0. But U0 ⊂U(n) so U(n) is also
unsatisﬁable.
• Otherwise, vI (A0) = T for all A0 ∈U0, so vI (A1) = F or vI (A2) = F .
Suppose that vI (A1) = F . By the deﬁnition of the semantics of ∧, this im-
plies that vI (A1 ∧A2) = F . Since A1 ∧A2 ∈U(n), U(n) is unsatisﬁable. A
similar argument holds if vI (A2) = F .
Case 2: U(n) = {B1 ∨B2} ∪U0, U(n′) = {B1} ∪U0, and U(n′′) = {B2} ∪U0 for
some (possibly empty) set of formulas U0.
Clearly, Tn′ and Tn′′ are also closed tableaux and since hn′ ≤hn −1 and hn′′ ≤
hn −1, by the inductive hypothesis U(n′) and U(n′′) are both unsatisﬁable. Let
I be an arbitrary interpretation. There are two possibilities:
• vI (B0) = F for some formula B0 ∈U0. But U0 ⊂U(n) so U(n) is also
unsatisﬁable.
• Otherwise, vI (B0) = T for all B0 ∈U0, so vI (B1) = F (since U(n′) is
unsatisﬁable) and vI (B2) = F (since U(n′′) is unsatisﬁable). By the def-
inition of the semantics of ∨, this implies that vI (B1 ∨B2) = F . Since
B1 ∨B2 ∈U(n), U(n) is unsatisﬁable.

42
2
Propositional Logic: Formulas, Models, Tableaux
2.7.2 Proof of Completeness
The theorem to be proved is: if A is unsatisﬁable then every tableau for A closes.
Completeness is much more difﬁcult to prove than soundness. For soundness, we
had a single (though arbitrary) closed tableau for a formula A and we proved that
A is unsatisﬁable by induction on the structure of a tableau. Here we need to prove
that no matter how the tableau for A is constructed, it must close.
Rather than prove that every tableau must close, we prove the contrapositive
(Corollary 2.68): if some tableau for A is open (has an open branch), then A is
satisﬁable. Clearly, there is a model for the set of literals labeling the leaf of an open
branch. We extend this to an interpretation for A and then prove by induction on the
length of the branch that the interpretation is a model of the sets of formulas labeling
the nodes on the branch, including the singleton set {A} that labels the root.
Let us look at some examples.
Example 2.73 Let A = p ∧(¬q ∨¬p). We have already constructed the tableau
for A which is reproduced here:
p ∧(¬q ∨¬p)
↓
p, ¬q ∨¬p
↙
↘
p,¬q
p,¬p
⊙
×
The interpretation I (p) = T , I (q) = F deﬁned by assigning T to the literals
labeling the leaf of the open branch is clearly a model for A.
Example 2.74 Now let A = p ∨(q ∧¬q); here is a tableau for A:
p ∨(q ∧¬q)
↙
↘
p
q ∧¬q
⊙
↓
q,¬q
×
The open branch of the tableau terminates in a leaf labeled with the singleton set of
literals {p}. We can conclude that any model for A must deﬁne I (p) = T . However,
an interpretation for A must also deﬁne an assignment to q and the leaf gives us no
guidance as to which value to choose for I (q). But it is obvious that it doesn’t
matter what value is assigned to q; in either case, the interpretation will be a model
of A.
To prove completeness we need to show that the assignment of T to the liter-
als labeling the leaf of an open branch can be extended to a model of the formula
labeling the root. There are four steps in the proof:

2.7
Soundness and Completeness
43
1. Deﬁne a property of sets of formulas;
2. Show that the union of the formulas labeling nodes in an open branch has this
property;
3. Prove that any set having this property is satisﬁable;
4. Note that the formula labeling the root is in the set.
Deﬁnition 2.75 Let U be a set of formulas. U is a Hintikka set iff:
1. For all atoms p appearing in a formula of U, either p ̸∈U or ¬p ̸∈U.
2. If A ∈U is an α-formula, then A1 ∈U and A2 ∈U.
3. If B ∈U is a β-formula, then B1 ∈U or B2 ∈U.
Example 2.76 U, the union of the set of formulas labeling the nodes in the open
branch of Example 2.74, is {p, p ∨(q ∧¬q)}. We claim that U is a Hintikka set.
Condition (1) obviously holds since there is only one literal p in U and ¬p ̸∈U.
Condition (2) is vacuous. For Condition (3), B = p ∨(q ∧¬q) ∈U is a β-formula
and B1 = p ∈U.
Condition (1) requires that a Hintikka set not contain a complementary pair of
literals, which to be expected on an open branch of a tableau. Conditions (2) and (3)
ensure that U is downward saturated, that is, U contains sufﬁcient subformulas so
that the decomposition of the formula to be satisﬁed will not take us out of U. In
turn, this ensures that an interpretation deﬁned by the set of literals in U will make
all formulas in U true.
The second step of the proof of completeness is to show that the set of formulas
labeling the nodes in an open branch is a Hintikka set.
Theorem 2.77 Let l be an open leaf in a completed tableau T . Let U = 
i U(i),
where i runs over the set of nodes on the branch from the root to l. Then U is a
Hintikka set.
Proof In the construction of the semantic tableau, there are no rules for decompos-
ing a literal p or ¬p. Thus if a literal p or ¬p appears for the ﬁrst time in U(n) for
some n, the literal will be copied into U(k) for all nodes k on the branch from n to
l, in particular, p ∈U(l) or ¬p ∈U(l). This means that all literals in U appear in
U(l). Since the branch is open, no complementary pair of literals appears in U(l),
so Condition (1) holds for U.
Suppose that A ∈U is an α-formula. Since the tableau is completed, A was the
formula selected for decomposing at some node n in the branch from the root to l.
Then {A1,A2} ⊆U(n′) ⊆U, so Condition (2) holds.
Suppose that B ∈U is an β-formula. Since the tableau is completed, B was the
formula selected for decomposing at some node n in the branch from the root to l.
Then either B1 ∈U(n′) ⊆U or B2 ∈U(n′) ⊆U, so Condition (3) holds.

44
2
Propositional Logic: Formulas, Models, Tableaux
The third step of the proof is to show that a Hintikka set is satisﬁable.
Theorem 2.78 (Hintikka’s Lemma) Let U be a Hintikka set. Then U is satisﬁable.
Proof We deﬁne an interpretation and then show that the interpretation is a model
of U. Let PU be set of all atoms appearing in all formulas of U. Deﬁne an inter-
pretation I : PU →{T,F} as follows:
I (p) = T
if p ∈U,
I (p) = F
if ¬p ∈U,
I (p) = T
if p ̸∈U and ¬p ̸∈U.
Since U is a Hintikka set, by Condition (1) I is well-deﬁned, that is, every
atom in PU is given exactly one value. Example 2.74 demonstrates the third case:
the atom q appears in a formula of U so q ∈PU, but neither the literal q nor its
complement ¬q appear in U. The atom is arbitrarily mapped to the truth value T .
We show by structural induction that for any A ∈U,vI (A) = T .
• If A is an atom p, then vI (A) = vI (p) = I (p) = T since p ∈U.
• If A is a negated atom ¬p, then since ¬p ∈U, I (p) = F , so vI (A) =
vI (¬p) = T .
• If A is an α-formula, by Condition (2) A1 ∈U and A2 ∈U. By the inductive hy-
pothesis, vI (A1) = vI (A2) = T , so vI (A) = T by deﬁnition of the conjunctive
operators.
• If A is β-formula B, by Condition (3) B1 ∈U or B2 ∈U. By the inductive hy-
pothesis, either vI (B1) = T or vI (B2) = T , so vI (A) = vI (B) = T by deﬁ-
nition of the disjunctive operators.
Proof of Completeness Let T be a completed open tableau for A. Then U, the
union of the labels of the nodes on an open branch, is a Hintikka set by Theo-
rem 2.77. Theorem 2.78 shows an interpretation I can be found such that U is
simultaneously satisﬁable in I . A, the formula labeling the root, is an element of
U so I is a model of A.
2.8 Summary
The presentation of propositional logic was carried out in a manner that we will
use for all systems of logic. First, the syntax of formulas is given. The formulas are
deﬁned as trees, which avoids ambiguity and simpliﬁes the description of structural
induction.
The second step is to deﬁne the semantics of formulas. An interpretation is a
mapping of atomic propositions to the values {T,F}. An interpretation is used to
give a truth value to any formula by induction on the structure of the formula, start-
ing from atoms and proceeding to more complex formulas using the deﬁnitions of
the Boolean operators.

2.9
Further Reading
45
A formula is satisﬁable iff it is true in some interpretation and it is valid iff is true
in all interpretations. Two formulas whose values are the same in all interpretations
are logically equivalent and can be substituted for each other. This can be used to
show that for any formula, there exists a logically equivalent formula that uses only
negation and either conjunction or disjunction.
While truth tables can be used as a decision procedure for the satisﬁability or
validity of formulas of propositional logic, semantic tableaux are usually much more
efﬁcient. In a semantic tableau, a tree is constructed during a search for a model of
a formula; the construction is based upon the structure of the formula. A semantic
tableau is closed if the formula is unsatisﬁable and open if it is satisﬁable.
We proved that the algorithm for semantic tableaux is sound and complete as a
decision procedure for satisﬁability. This theorem connects the syntactical aspect of
a formula that guides the construction of the tableau with its meaning. The central
concept in the proof is that of a Hintikka set, which gives conditions that ensure that
a model can be found for a set of formulas.
2.9 Further Reading
The presentation of semantic tableaux follows that of Smullyan (1968) although he
uses analytic tableaux. Advanced textbooks that also use tableaux are Nerode and
Shore (1997) and Fitting (1996).
2.10 Exercises
2.1 Draw formation trees and construct truth tables for
(p →(q →r)) →((p →q) →(p →r)),
(p →q) →p,
((p →q) →p) →p.
2.2 Prove that there is a unique formation tree for every derivation tree.
2.3 Prove the following logical equivalences:
A ∧(B ∨C) ≡(A ∧B) ∨(A ∧C),
A ∨B ≡¬(¬A ∧¬B),
A ∧B ≡¬(¬A ∨¬B),
A →B ≡¬A ∨B,
A →B ≡¬(A ∧¬B).
2.4 Prove ((A ⊕B) ⊕B) ≡A and ((A ↔B) ↔B) ≡A.

46
2
Propositional Logic: Formulas, Models, Tableaux
2.5 Simplify A ∧(A ∨B) and A ∨(A ∧B).
2.6 Prove the following logical equivalences using truth tables, semantic tableaux
or Venn diagrams:
A →B
≡A ↔(A ∧B),
A →B
≡B ↔(A ∨B),
A ∧B
≡(A ↔B) ↔(A ∨B),
A ↔B
≡(A ∨B) →(A ∧B).
2.7 Prove |= (A →B) ∨(B →C).
2.8 Prove or disprove:
|= ((A →B) →B) →B,
|= (A ↔B) ↔(A ↔(B ↔A)).
2.9 Prove:
|= ((A ∧B) →C) →((A →C) ∨(B →C)).
This formula may seem strange since it could be misinterpreted as saying that if C
follows from A ∧B, then it follows from one or the other of A or B. To clarify this,
show that:
{A ∧B →C} |= (A →C) ∨(B →C),
but:
{A ∧B →C} ̸|= A →C,
{A ∧B →C} ̸|= B →C.
2.10 Complete the proof that ↑and ↓can each deﬁne all unary and binary Boolean
operators (Theorem 2.37).
2.11 Prove that ∧and ∨cannot deﬁne all Boolean operators.
2.12 Prove that {¬,↔} cannot deﬁne all Boolean operators.
2.13 Prove that ↑and ↓are not associative.
2.14 Prove that if U is satisﬁable then U ∪{B} is not necessarily satisﬁable.
2.15 Prove Theorems 2.44–2.47 on the satisﬁability of sets of formulas.
2.16 Prove Theorems 2.50–2.54 on logical consequence.

References
47
2.17 Prove that for a set of axioms U, T (U) is closed under logical consequence
(see Deﬁnition 2.55).
2.18 Complete the proof that the construction of a semantic tableau terminates
(Theorem 2.66).
2.19 Prove that the method of semantic tableaux remains sound and complete if a
tableau can be closed non-atomically.
2.20 Manna (1974) Let ifte be a tertiary (3-place) operator deﬁned by:
A
B
C
ifte(A,B,C)
T
T
T
T
T
T
F
T
T
F
T
F
T
F
F
F
F
T
T
T
F
T
F
F
F
F
T
T
F
F
F
F
The operator can be deﬁned using inﬁx notation as:
if A then B else C.
1. Prove that if then else by itself forms an adequate sets of operators if the use of
the constant formulas true and false is allowed.
2. Prove: |= if A then B else C ≡(A →B) ∧(¬A →C).
3. Add a rule for the operator if then else to the algorithm for semantic tableaux.
References
M. Fitting. First-Order Logic and Automated Theorem Proving (Second Edition). Springer, 1996.
J.E. Hopcroft, R. Motwani, and J.D. Ullman. Introduction to Automata Theory, Languages and
Computation (Third Edition). Addison-Wesley, 2006.
Z. Manna. Mathematical Theory of Computation. McGraw-Hill, New York, NY, 1974. Reprinted
by Dover, 2003.
A. Nerode and R.A. Shore. Logic for Applications (Second Edition). Springer, 1997.
R.M. Smullyan. First-Order Logic. Springer-Verlag, 1968. Reprinted by Dover, 1995.


Chapter 3
Propositional Logic: Deductive Systems
The concept of deducing theorems from a set of axioms and rules of inference is very
old and is familiar to every high-school student who has studied Euclidean geome-
try. Modern mathematics is expressed in a style of reasoning that is not far removed
from the reasoning used by Greek mathematicians. This style can be characterized
as ‘formalized informal reasoning’, meaning that while the proofs are expressed in
natural language rather than in a formal system, there are conventions among math-
ematicians as to the forms of reasoning that are allowed. The deductive systems
studied in this chapter were developed in an attempt to formalize mathematical rea-
soning.
We present two deductive systems for propositional logic. The second one H
will be familiar because it is a formalization of step-by-step proofs in mathematics:
It contains a set of three axioms and one rule of inference; proofs are constructed
as a sequence of formulas, each of which is either an axiom (or a formula that has
been previously proved) or a derivation of a formula from previous formulas in the
sequence using the rule of inference. The system G will be less familiar because
it has one axiom and many rules of inference, but we present it ﬁrst because it is
almost trivial to prove the soundness and completeness of G from its relationship
with semantic tableaux. The proof of the soundness and completeness of H is then
relatively easy to show by using G . The chapter concludes with three short sections:
the deﬁnition of an important property called consistency, a generalization to inﬁnite
sets of formulas, and a survey of other deductive systems for propositional logic.
3.1 Why Deductive Proofs?
Let U = {A1,...,An}. Theorem 2.50 showed that U |= A if and only if |= A1 ∧
··· ∧An →A. Therefore, if U is a set of axioms, we can use the completeness of
the method of semantic tableaux to determine if A follows from U (see Sect. 2.5.4
for precise deﬁnitions). Why would we want to go through the trouble of searching
for a mathematical proof when we can easily compute if a formula is valid?
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_3, © Springer-Verlag London 2012
49

50
3
Propositional Logic: Deductive Systems
There are several problems with a purely semantical approach:
• The set of axioms may be inﬁnite. For example, the axiom of induction in arith-
metic is really an inﬁnite set of axioms, one for each property to be proved. For
semantic tableaux in propositional logic, the only formulas that appear in the tab-
leaux are subformulas of the formula being checked or their negations, and there
are only a ﬁnite number of such formulas.
• Very few logics have decision procedures like propositional logic.
• A decision procedure may not give insight into the relationship between the ax-
ioms and the theorem. For example, in proofs of theorems about prime num-
bers, we would want to know exactly where primality is used (Velleman, 2006,
Sect. 3.7). This understanding can also help us propose other formulas that might
be theorems.
• A decision procedure produces a ‘yes/no’ answer, so it is difﬁcult to recognize
intermediate results (lemmas). Clearly, the millions of mathematical theorems in
existence could not have been inferred directly from axioms.
Deﬁnition 3.1 A deductive system is a set of formulas called axioms and a set of
rules of inference. A proof in a deductive system is a sequence of formulas S =
{A1,...,An} such that each formula Ai is either an axiom or it can be inferred from
previous formulas of the sequence Aj1,...,Ajk, where j1 < ··· < jk < i, using a
rule of inference. For An, the last formula in the sequence, we say that An is a
theorem, the sequence S is a proof of An, and An is provable, denoted ⊢An. If
⊢A, then A may be used like an axiom in a subsequent proof.
The deductive approach can overcome the problems described above:
• There may be an inﬁnite number of axioms, but only a ﬁnite number will appear
in any proof.
• Although a proof is not a decision procedure, it can be mechanically checked;
that is, given a sequence of formulas, an syntax-based algorithm can easily check
whether the sequence is a proof as deﬁned above.
• The proof of a formula clearly shows which axioms, theorems and rules are used
and for what purposes.
• Once a theorem has been proved, it can be used in proofs like an axiom.
Deductive proofs are not generated by decision procedures because the formulas
that appear in a proof are not limited to subformulas of the theorem and because
there is no algorithm telling us how to generate the next formula in the sequence
forming a proof. Nevertheless, algorithms and heuristics can be used to build soft-
ware systems called automatic theorem provers which search for proofs. In Chap. 4,
we will study a deductive system that has been successfully used in automatic theo-
rem provers. Another promising approach is to use a proof assistant which performs
administrative tasks such as proof checking, bookkeeping and cataloging previously
proved theorems, but a person guides the search by suggesting lemmas that are likely
to lead to a proof.

3.2
Gentzen System G
51
α
α1
α2
β
β1
β2
¬¬A
A
¬(A1 ∧A2)
¬A1
¬A2
B1 ∧B2
B1
B2
A1 ∨A2
A1
A2
¬(B1 ∨B2)
¬B1
¬B2
A1 →A2
¬A1
A2
¬(B1 →B2)
B1
¬B2
A1 ↑A2
¬A1
¬A2
¬(B1 ↑B2)
B1
B2
¬(A1 ↓A2)
A1
A2
B1 ↓B2
¬B1
¬B2
¬(A1 ↔A2)
¬(A1 →A2)
¬(A2 →A1)
B1 ↔B2
B1 →B2
B2 →B1
A1 ⊕A2
¬(A1 →A2)
¬(A2 →A1)
¬(B1 ⊕B2)
B1 →B2
B2 →B1
Fig. 3.1 Classiﬁcation of α- and β-formulas
3.2 Gentzen System G
The ﬁrst deductive system that we study is based on a system proposed by Gerhard
Gentzen in the 1930s. The system itself will seem unfamiliar because it has one type
of axiom and many rules of inference, unlike familiar mathematical theories which
have multiple axioms and only a few rules of inference. Furthermore, deductions in
the system can be naturally represented as trees rather in the linear format character-
istic of mathematical proofs. However, it is this property that makes it easy to relate
Gentzen systems to semantic tableaux.
Deﬁnition 3.2 (Gentzen system G ) An axiom of G is a set of literals U containing
a complementary pair. Rule of inference are used to infer a set of formulas U from
one or two other sets of formulas U1 and U2; there are two types of rules, deﬁned
with reference to Fig. 3.1:
• Let {α1,α2} ⊆U1 and let U′
1 = U1 −{α1,α2}. Then U = U′
1 ∪{α} can be inferred.
• Let {β1} ⊆U1, {β2} ⊆U2 and let U′
1 = U1 −{β1}, U′
2 = U2 −{β2}. Then U =
U′
1 ∪U′
2 ∪{β} can be inferred.
The set or sets of formulas U1,U2 are the premises and set of formulas U that is
inferred is the conclusion. A set of formulas U that is an axiom or a conclusion is
said to be proved, denoted ⊢U. The following notation is used for rules of inference:
⊢U′
1 ∪{α1,α2}
⊢U′
1 ∪{α}
⊢U′
1 ∪{β1}
⊢U′
2 ∪{β2}
⊢U′
1 ∪U′
2 ∪{β}
.
Braces can be omitted with the understanding that a sequence of formulas is to be
interpreted as a set (with no duplicates).
Example 3.3 The following set of formulas is an axiom because it contains the
complementary pair {r, ¬r}:
⊢p ∧q,q,r,¬r,q ∨¬r.

52
3
Propositional Logic: Deductive Systems
The disjunction rule for A1 = q,A2 = ¬r can be used to deduce:
⊢p ∧q,q,r,¬r,q ∨¬r
⊢p ∧q,r,q ∨¬r,q ∨¬r .
Removing the duplicate formula q ∨¬r gives:
⊢p ∧q,q,r,¬r,q ∨¬r
⊢p ∧q,r,q ∨¬r
.
Note that the premises {q,¬r} are no longer elements of the conclusion.
A proof can be written as a sequence of sets of formulas, which are numbered
for convenient reference. On the right of each line is its justiﬁcation: either the set
of formulas is an axiom, or it is the conclusion of a rule of inference applied to a set
or sets of formulas earlier in the sequence. A rule of inference is identiﬁed by the
rule used for the α- or β-formula on the principal operator of the conclusion and by
the number or numbers of the lines containing the premises.
Example 3.4 Prove ⊢(p ∨q) →(q ∨p) in G .
Proof
1.
⊢¬p,q,p
Axiom
2.
⊢¬q,q,p
Axiom
3.
⊢¬(p ∨q),q,p
β ∨, 1, 2
4.
⊢¬(p ∨q),(q ∨p)
α ∨, 3
5.
⊢(p ∨q) →(q ∨p)
α →, 4
Example 3.5 Prove ⊢p ∨(q ∧r) →(p ∨q) ∧(p ∨r) in G .
Proof
1.
⊢¬p,p,q
Axiom
2.
⊢¬p,(p ∨q)
α ∨, 1
3.
⊢¬p,p,r
Axiom
4.
⊢¬p,(p ∨r)
α ∨, 3
5.
⊢¬p,(p ∨q) ∧(p ∨r)
β ∧, 2, 4
6.
⊢¬q,¬r,p,q
Axiom
7.
⊢¬q,¬r,(p ∨q)
α ∨, 6
8.
⊢¬q,¬r,p,r
Axiom
9.
⊢¬q,¬r,(p ∨r)
α ∨, 8
10.
⊢¬q,¬r,(p ∨q) ∧(p ∨r)
β ∧, 7, 9
11.
⊢¬(q ∧r),(p ∨q) ∧(p ∨r)
α ∧, 10
12.
⊢¬(p ∨(q ∧r)),(p ∨q) ∧(p ∨r)
β ∨, 5, 11
13.
⊢p ∨(q ∧r) →(p ∨q) ∧(p ∨r)
α →, 12

3.2
Gentzen System G
53
3.2.1 The Relationship Between G and Semantic Tableaux
It might seem that we have been rather clever to arrange all the inferences in these
proofs so that everything comes out exactly right in the end. In fact, no cleverness
was required. Let us rearrange the Gentzen proof into a tree format rather than a
linear sequence of sets of formulas. Let the axioms be the leaves of the tree, and let
the inference rules deﬁne the interior nodes. The root at the bottom will be labeled
with the formula that is proved.
The proof from Example 3.4 is displayed in tree form on the left below:
¬p,q,p
¬q,q,p
↘
↙
¬(p ∨q),q,p
↓
¬(p ∨q),(q ∨p)
↓
(p ∨q) →(q ∨p)
¬[(p ∨q) →(q ∨p)]
↓
p ∨q,¬(q ∨p)
↓
p ∨q,¬q,¬p
↙
↘
p,¬q,¬p
q,¬q,¬p
×
×
If this looks familiar, it should. The semantic tableau on the right results from
turning the derivation in G upside down and replacing each formula in the labels on
the nodes by its complement (Deﬁnition 2.57).
A set of formulas labeling a node in a semantic tableau is an implicit conjunction,
that is, all the formulas in the set must evaluate to true for the set to be true. By taking
complements, a set of formulas labeling a node in a derivation in G is an implicit
disjunction.
An axiom in G is valid: Since it contains a complementary pair of literals, as a
disjunction it is:
··· ∨p ∨··· ∨¬p ∨··· ,
which is valid.
Consider a rule applied to obtain an α-formula, for example, A1 ∨A2; when the
rule is written using disjunctions it becomes:
⊢U′
1 ∨A1 ∨A2
⊢U′
1 ∨(A1 ∨A2),
and this is a valid inference in propositional logic that follows immediately from
associativity.
Similarly, when a rule is applied to obtain a β-formula, we have:
⊢U′
1 ∨B1
U′
2 ∨B2
⊢U′
1 ∨U′
2 ∨(B1 ∧B2)
,
which follows by the distribution of disjunction over conjunction. This inference
simply says that if we can prove both B1 and B2 then we can prove B1 ∧B2.

54
3
Propositional Logic: Deductive Systems
The relationship between semantic tableaux and Gentzen systems is formalized
in the following theorem.
Theorem 3.6 Let A be a formula in propositional logic. Then ⊢A in G if and only
if there is a closed semantic tableau for ¬A.
This follows immediately from a more general theorem on sets of formulas.
Theorem 3.7 Let U be a set of formulas and let ¯U be the set of complements of
formulas in U. Then ⊢U in G if and only if there is a closed semantic tableau
for ¯U.
Proof Let T be a closed semantic tableau for ¯U. We prove ⊢U by induction on h,
the height of T . The other direction is left as an exercise.
If h = 0, then T consists of a single node labeled by ¯U. By assumption, T is
closed, so it contains a complementary pair of literals {p,¬p}, that is, ¯U = ¯U′ ∪
{p,¬p}. Obviously, U = U′ ∪{¬p,p} is an axiom in G , hence ⊢U.
If h > 0, then some tableau rule was used on an α- or β-formula at the root of
T on a formula ¯φ ∈¯U, that is, ¯U = ¯U′ ∪{ ¯φ}. The proof proceeds by cases, where
you must be careful to distinguish between applications of the tableau rules and
applications of the Gentzen rules of the same name.
Case 1: ¯φ is an α-formula (such as) ¬(A1 ∨A2). The tableau rule created a child
node labeled by the set of formulas ¯U′ ∪{¬A1,¬A2}. By assumption, the
subtree rooted at this node is a closed tableau, so by the inductive hypothe-
sis, ⊢U′ ∪{A1,A2}. Using the appropriate rule of inference from G , we obtain
⊢U′ ∪{A1 ∨A2}, that is, ⊢U′ ∪{φ}, which is ⊢U.
Case 2: ¯φ is a β-formula (such as) ¬(B1 ∧B2). The tableau rule created two child
nodes labeled by the sets of formulas ¯U′ ∪{¬B1} and ¯U′ ∪{¬B2}. By assump-
tion, the subtrees rooted at this node are closed, so by the inductive hypothesis
⊢U′ ∪{B1} and ⊢U′ ∪{B2}. Using the appropriate rule of inference from G ,
we obtain ⊢U′ ∪{B1 ∧B2}, that is, ⊢U′ ∪{φ}, which is ⊢U.
Theorem 3.8 (Soundness and completeness of G )
|= A if and only if ⊢A in G .
Proof A is valid iff ¬A is unsatisﬁable iff there is a closed semantic tableau for
¬A iff there is a proof of A in G .
The proof is very simple because we did all the hard work in the proof of the
soundness and completeness of tableaux.
The Gentzen system G described in this section is not very useful; other versions
(surveyed in Sect. 3.9) are more convenient for proving theorems and are closer to
Gentzen’s original formulation. We introduced G as a theoretical stepping stone to
Hilbert systems which we now describe.

3.3
Hilbert System H
55
3.3 Hilbert System H
In Gentzen systems there is one axiom and many rules of inference, while in a
Hilbert system there are several axioms but only one rule of inference. In this sec-
tion, we deﬁne the deductive system H and use it to prove many theorems. Actu-
ally, only one theorem (Theorem 3.10) will be proved directly from the axioms and
the rule of inference; practical use of the system depends on the use of derived rules,
especially the deduction rule.
Notation:
Capital letters A,B,C,... represent arbitrary formulas in proposi-
tional logic. For example, the notation ⊢A→A means: for any formula A of propo-
sitional logic, the formula A →A can be proved.
Deﬁnition 3.9 (Deductive system H ) The axioms of H are:
Axiom 1
⊢(A →(B →A)),
Axiom 2
⊢(A →(B →C)) →((A →B) →(A →C)),
Axiom 3
⊢(¬B →¬A) →(A →B).
The rule of inference is modus ponens (MP for short):
⊢A
⊢A →B
⊢B
.
In words: the formula B can be inferred from A and A →B.
The terminology used for G —premises, conclusion, theorem, proved— carries
over to H , as does the symbol ⊢meaning that a formula is proved.
Theorem 3.10 ⊢A →A.
Proof
1.
⊢(A →((A →A) →A)) →((A →(A →A)) →(A →A))
Axiom 2
2.
⊢A →((A →A) →A)
Axiom 1
3.
⊢(A →(A →A)) →(A →A)
MP 1, 2
4.
⊢A →(A →A)
Axiom 1
5.
⊢A →A
MP 3, 4
When an axiom is given as the justiﬁcation, identify which formulas are substi-
tuted for the formulas A,B,C in the deﬁnition of the axioms above.
3.3.1 Axiom Schemes and Theorem Schemes *
As we noted above, a capital letter can be replaced by any formula of propositional
logic, so, strictly speaking, ⊢A→(B →A) is not an axiom, and similarly, ⊢A→A

56
3
Propositional Logic: Deductive Systems
is not a theorem. A more precise terminology would be to say that ⊢A →(B →A)
is an axiom scheme that is a shorthand for an inﬁnite number of axioms obtained by
replacing the ‘variables’ A and B with actual formulas, for example:
A



((p ∨¬q) ↔r) →(
B



¬(q ∧¬r) →
A



((p ∨¬q) ↔r) ).
Similarly, ⊢A →A is a theorem scheme that is a shorthand for an inﬁnite number
of theorems that can be proved in H , including, for example:
⊢((p ∨¬q) ↔r) →((p ∨¬q) ↔r).
We will not retain this precision in our presentation because it will always clear
if a given formula is an instance of a particular axiom scheme or theorem scheme.
For example, a formula φ is an instance of Axiom 1 if it is of the form:
A
B
A



JJJ
→




JJJ
→
where there are subtrees for the formulas represented by A and B. There is a simple
and efﬁcient algorithm that checks if φ is of this form and if the two subtrees A are
identical.
3.3.2 The Deduction Rule
The proof of Theorem 3.10 is rather complicated for such a trivial formula. In order
to formalize the powerful methods of inference used in mathematics, we introduce
new rules of inference called derived rules. The most important derived rule is the
deduction rule. Suppose that you want to prove A →B. Assume that A has already
been proved and use it in the proof of B. This is not a proof of B unless A is an axiom
or theorem that has been previously proved, in which case it can be used directly in
the proof. However, we claim that the proof can be mechanically transformed into a
proof of A →B.
Example 3.11 The deduction rule is used frequently in mathematics. Suppose that
you want to prove that the sum of any two odd integer numbers is even, expressed
formally as:
odd(x) ∧odd(y) →even(x + y),
for every x and y. To prove this formula, let us assume the formula odd(x)∧odd(y)
as if it were an additional axiom. We have available all the theorems we have already

3.3
Hilbert System H
57
deduced about odd numbers, in particular, the theorem that any odd number can be
expressed as 2k + 1. Computing:
x + y = 2k1 + 1 + 2k2 + 1 = 2(k1 + k2 + 1),
we obtain that x +y is a multiple of 2, that is, even(x +y). The theorem now follows
from the deduction rule which discharges the assumption.
To express the deduction rule, we extend the deﬁnition of proof.
Deﬁnition 3.12 Let U be a set of formulas and A a formula. The notation U ⊢
A means that the formulas in U are assumptions in the proof of A. A proof is a
sequence of lines Ui ⊢φi, such that for each i, Ui ⊆U, and φi is an axiom, a
previously proved theorem, a member of Ui or can be derived by MP from previous
lines Ui′ ⊢φi′,Ui′′ ⊢φi′′, where i′,i′′ < i.
Rule 3.13 (Deduction rule)
U ∪{A} ⊢B
U ⊢A →B .
We must show that this derived rule is sound, that is, that the use of the derived
rule does not increase the set of provable theorems in H . This is done by showing
how to transform any proof using the rule into one that does not use the rule. There-
fore, in principle, any proof that uses the derived rule could be transformed to one
that uses only the three axioms and MP.
Theorem 3.14 (Deduction theorem) The deduction rule is a sound derived rule.
Proof We show by induction on the length n of the proof of U ∪{A} ⊢B how to
obtain a proof of U ⊢A →B that does not use the deduction rule.
For n = 1, B is proved in one step, so B must be either an element of U ∪{A} or
an axiom of H or a previously proved theorem:
• If B is A, then ⊢A →A by Theorem 3.10, so certainly U ⊢A →A.
• Otherwise (B is an axiom or a previously proved theorem), here is a proof of
U ⊢A →B that does not use the deduction rule or the assumption A:
1.
U ⊢B
Axiom or theorem
2.
U ⊢B →(A →B)
Axiom 1
3.
U ⊢A →B
MP 1, 2
If n > 1, the last step in the proof of U ∪{A} ⊢B is either a one-step inference
of B or an inference of B using MP. In the ﬁrst case, the result holds by the proof
for n = 1. Otherwise, MP was used, so there is a formula C and lines i,j < n in the
proof such that line i in the proof is U ∪{A} ⊢C and line j is U ∪{A} ⊢C →B.
By the inductive hypothesis, U ⊢A →C and U ⊢A →(C →B). A proof of U ⊢
A →B is given by:

58
3
Propositional Logic: Deductive Systems
1.
U ⊢A →C
Inductive hypothesis
2.
U ⊢A →(C →B)
Inductive hypothesis
3.
U ⊢(A →(C →B)) →((A →C) →(A →B))
Axiom 2
4.
U ⊢(A →C) →(A →B)
MP 2,3
5.
U ⊢A →B
MP 1,4
3.4 Derived Rules in H
The general form of a derived rule will be one of:
U ⊢φ1
U ⊢φ ,
U ⊢φ1
U ⊢φ2
U ⊢φ
.
The ﬁrst form is justiﬁed by proving the formula U ⊢φ1 →φ and the second by
U ⊢φ1 →(φ2 →φ); the formula U ⊢φ that is the conclusion of the rule follows
immediately by one or two applications of MP. For example, from Axiom 3 we
immediately have the following rule:
Rule 3.15 (Contrapositive rule)
U ⊢¬B →¬A
U ⊢A →B
.
The contrapositive is used extensively in mathematics. We showed the complete-
ness of the method of semantic tableaux by proving: If a tableau is open, the formula
is satisﬁable, which is the contrapositive of the theorem that we wanted to prove: If
a formula is unsatisﬁable (not satisﬁable), the tableau is closed (not open).
Theorem 3.16 ⊢(A →B) →[(B →C) →(A →C)].
Proof
1.
{A →B,B →C,A} ⊢A
Assumption
2.
{A →B,B →C,A} ⊢A →B
Assumption
3.
{A →B,B →C,A} ⊢B
MP 1, 2
4.
{A →B,B →C,A} ⊢B →C
Assumption
5.
{A →B,B →C,A} ⊢C
MP 3, 4
6.
{A →B,B →C} ⊢A →C
Deduction 5
7.
{A →B} ⊢[(B →C) →(A →C)]
Deduction 6
8.
⊢(A →B) →[(B →C) →(A →C)]
Deduction 7

3.4
Derived Rules in H
59
Rule 3.17 (Transitivity rule)
U ⊢A →B
U ⊢B →C
U ⊢A →C
.
The transitivity rule justiﬁes the step-by-step development of a mathematical the-
orem ⊢A→C through a series of lemmas. The antecedent A of the theorem is used
to prove a lemma ⊢A →B1 whose consequent is used to prove the next lemma
⊢B1 →B2 and so on until the consequent of the theorem appears as ⊢Bn →C.
Repeated use of the transitivity rule enables us to deduce ⊢A →C.
Theorem 3.18 ⊢[A →(B →C)] →[B →(A →C)].
Proof
1.
{A →(B →C),B,A} ⊢A
Assumption
2.
{A →(B →C),B,A} ⊢A →(B →C)
Assumption
3.
{A →(B →C),B,A} ⊢B →C
MP 1, 2
4.
{A →(B →C),B,A} ⊢B
Assumption
5.
{A →(B →C),B,A} ⊢C
MP 3, 4
6.
{A →(B →C),B} ⊢A →C
Deduction 5
7.
{A →(B →C)} ⊢B →(A →C)
Deduction 6
8.
⊢[A →(B →C)] →[B →(A →C)]
Deduction 7
Rule 3.19 (Exchange of antecedent rule)
U ⊢A →(B →C)
U ⊢B →(A →C).
Exchanging the antecedent simply means that it doesn’t matter in which order
we use the lemmas necessary in a proof.
Theorem 3.20 ⊢¬A →(A →B).
Proof
1.
{¬A} ⊢¬A →(¬B →¬A)
Axiom 1
2.
{¬A} ⊢¬A
Assumption
3.
{¬A} ⊢¬B →¬A
MP 1, 2
4.
{¬A} ⊢(¬B →¬A) →(A →B)
Axiom 3
5.
{¬A} ⊢A →B
MP 3, 4
6.
⊢¬A →(A →B)
Deduction 5
Theorem 3.21 ⊢A →(¬A →B).
Proof
1.
⊢¬A →(A →B)
Theorem 3.20
2.
⊢A →(¬A →B)
Exchange 1

60
3
Propositional Logic: Deductive Systems
These two theorems are of major theoretical importance. They say that if you can
prove some formula A and its negation ¬A, then you can prove any formula B! If
you can prove any formula then there are no unprovable formulas so the concept of
proof becomes meaningless.
Theorem 3.22 ⊢¬¬A →A.
Proof
1.
{¬¬A} ⊢¬¬A →(¬¬¬¬A →¬¬A)
Axiom 1
2.
{¬¬A} ⊢¬¬A
Assumption
3.
{¬¬A} ⊢¬¬¬¬A →¬¬A
MP 1, 2
4.
{¬¬A} ⊢¬A →¬¬¬A
Contrapositive 3
5.
{¬¬A} ⊢¬¬A →A
Contrapositive 4
6.
{¬¬A} ⊢A
MP 2, 5
7.
⊢¬¬A →A
Deduction 6
Theorem 3.23 ⊢A →¬¬A.
Proof
1.
⊢¬¬¬A →¬A
Theorem 3.22
2.
⊢A →¬¬A
Contrapositive 1
Rule 3.24 (Double negation rule)
U ⊢¬¬A
U ⊢A
,
U ⊢A
U ⊢¬¬A.
Double negation is a very intuitive rule. We expect that ‘it is raining’ and ‘it is
not true that it is not raining’ will have the same truth value, and that the second
formula can be simpliﬁed to the ﬁrst. Nevertheless, some logicians reject the rule
because it is not constructive. Suppose that we can prove for some number n, ‘it is
not true that n is prime’ which is the same as ‘it is not true that n is not composite’.
This double negation could be reduced by the rule to ‘n is composite’, but we have
not actually demonstrated any factors of n.
Theorem 3.25 ⊢(A →B) →(¬B →¬A).
Proof
1.
{A →B} ⊢A →B
Assumption
2.
{A →B} ⊢¬¬A →A
Theorem 3.22
3.
{A →B} ⊢¬¬A →B
Transitivity 2, 1
4.
{A →B} ⊢B →¬¬B
Theorem 3.23
5.
{A →B} ⊢¬¬A →¬¬B
Transitivity 3, 4
6.
{A →B} ⊢¬B →¬A
Contrapositive 5
7.
⊢(A →B) →(¬B →¬A)
Deduction 6

3.4
Derived Rules in H
61
Rule 3.26 (Contrapositive rule)
U ⊢A →B
U ⊢¬B →¬A.
This is the other direction of the contrapositive rule shown earlier.
Recall from Sect. 2.3.3 the deﬁnition of the logical constants true as an abbrevi-
ation for p ∨¬p and false as an abbreviation for p ∧¬p. These can be expressed
using implication and negation alone as p →p and ¬(p →p).
Theorem 3.27
⊢true,
⊢¬false.
Proof ⊢true is an instance of Theorem 3.10. ⊢¬false, which is ⊢¬¬(p →p),
follows by double negation.
Theorem 3.28 ⊢(¬A →false) →A.
Proof
1.
{¬A →false} ⊢¬A →false
Assumption
2.
{¬A →false} ⊢¬false →¬¬A
Contrapositive
3.
{¬A →false} ⊢¬false
Theorem 3.27
4.
{¬A →false} ⊢¬¬A
MP 2, 3
5.
{¬A →false} ⊢A
Double negation 4
6.
⊢(¬A →false) →A
Deduction 5
Rule 3.29 (Reductio ad absurdum)
U ⊢¬A →false
U ⊢A
.
Reductio ad absurdum is a very useful rule in mathematics: Assume the negation
of what you wish to prove and show that it leads to a contradiction. This rule is also
controversial because proving that ¬A leads to a contradiction provides no reason
that directly justiﬁes A.

62
3
Propositional Logic: Deductive Systems
Here is an example of the use of this rule:
Theorem 3.30 ⊢(A →¬A) →¬A.
Proof
1.
{A →¬A,¬¬A} ⊢¬¬A
Assumption
2.
{A →¬A,¬¬A} ⊢A
Double negation 1
3.
{A →¬A,¬¬A} ⊢A →¬A
Assumption
4.
{A →¬A,¬¬A} ⊢¬A
MP 2, 3
5.
{A →¬A,¬¬A} ⊢A →(¬A →false)
Theorem 3.21
6.
{A →¬A,¬¬A} ⊢¬A →false
MP 2, 5
7.
{A →¬A,¬¬A} ⊢false
MP 4, 6
8.
{A →¬A} ⊢¬¬A →false
Deduction 7
9.
{A →¬A} ⊢¬A
Reductio ad absurdum 8
10.
⊢(A →¬A) →¬A
Deduction 9
We leave the proof of the following theorem as an exercise.
Theorem 3.31 ⊢(¬A →A) →A.
These two theorems may seem strange, but they can be understood on the se-
mantic level. For the implication of Theorem 3.31 to be false, the antecedent
¬A →A must be true and the consequent A false. But if A is false, then so is
¬A →A ≡A ∨A, so the formula is true.
3.5 Theorems for Other Operators
So far we have worked with only negation and implication as operators. These two
operators are adequate for deﬁning all others (Sect. 2.4), so we can use these def-
initions to prove theorems using other operators. Recall that A ∧B is deﬁned as
¬(A →¬B), and A ∨B is deﬁned as ¬A →B.

3.5
Theorems for Other Operators
63
Theorem 3.32 ⊢A →(B →(A ∧B)).
Proof
1.
{A,B} ⊢(A →¬B) →(A →¬B)
Theorem 3.10
2.
{A,B} ⊢A →((A →¬B) →¬B)
Exchange 1
3.
{A,B} ⊢A
Assumption
4.
{A,B} ⊢(A →¬B) →¬B
MP 2, 3
5.
{A,B} ⊢¬¬B →¬(A →¬B)
Contrapositive 4
6.
{A,B} ⊢B
Assumption
7.
{A,B} ⊢¬¬B
Double negation 6
8.
{A,B} ⊢¬(A →¬B)
MP 5, 7
9.
{A} ⊢B →¬(A →¬B)
Deduction 8
10.
⊢A →(B →¬(A →¬B))
Deduction 9
11.
⊢A →(B →(A ∧B))
Deﬁnition of ∧
Theorem 3.33 (Commutativity) ⊢A ∨B ↔B ∨A.
Proof
1.
{¬A →B,¬B} ⊢¬A →B
Assumption
2.
{¬A →B,¬B} ⊢¬B →¬¬A
Contrapositive 1
3.
{¬A →B,¬B} ⊢¬B
Assumption
4.
{¬A →B,¬B} ⊢¬¬A
MP 2, 3
5.
{¬A →B,¬B} ⊢A
Double negation 4
6.
{¬A →B} ⊢¬B →A
Deduction 5
7.
⊢(¬A →B) →(¬B →A)
Deduction 6
8.
⊢A ∨B →B ∨A
Def. of ∨
The other direction is similar.
The proofs of the following theorems are left as exercises.
Theorem 3.34 (Weakening)
⊢A →A ∨B,
⊢B →A ∨B,
⊢(A →B) →((C ∨A) →(C ∨B)).
Theorem 3.35 (Associativity)
⊢A ∨(B ∨C) ↔(A ∨B) ∨C.
Theorem 3.36 (Distributivity)
⊢A ∨(B ∧C) ↔(A ∨B) ∧(A ∨C),
⊢A ∧(B ∨C) ↔(A ∧B) ∨(A ∧C).

64
3
Propositional Logic: Deductive Systems
3.6 Soundness and Completeness of H
We now prove the soundness and completeness of the Hilbert system H . As usual,
soundness is easy to prove. Proving completeness will not be too difﬁcult because
we already know that the Gentzen system G is complete so it is sufﬁcient to show
how to transform any proof in G into a proof in H .
Theorem 3.37 The Hilbert system H is sound: If ⊢A then |= A.
Proof The proof is by structural induction. First we show that the axioms are valid,
and then we show that MP preserves validity. Here are closed semantic tableaux for
the negations of Axioms 1 and 3:
¬[A →(B →A)]
↓
A,¬(B →A)
↓
A,B,¬A
×
¬[(¬B →¬A) →(A →B)]
↓
¬B →¬A,¬(A →B)
↓
¬B →¬A,A,¬B
↙
↘
¬¬B,A,¬B
¬A,A,¬B
↓
×
B,A,¬B
×
The construction of a tableau for the negation of Axiom 2 is left as an exercise.
Suppose that MP were not sound. There would be a set of formulas {A,A →
B,B} such that A and A →B are valid, but B is not valid. Since B is not valid,
there is an interpretation I such that vI (B) = F . Since A and A →B are valid,
for any interpretation, in particular for I , vI (A) = vI (A→B) = T . By deﬁnition
of vI for implication, vI (B) = T , contradicting vI (B) = F .
There is no circularity in the ﬁnal sentence of the proof: We are not using the
syntactical proof rule MP, but, rather, the semantic deﬁnition of truth value in the
presence of the implication operator.
Theorem 3.38 The Hilbert system H is complete: If |= A then ⊢A.
By the completeness of the Gentzen system G (Theorem 3.8), if |= A, then ⊢A
in G . The proof of the theorem showed how to construct the proof of A by ﬁrst
constructing a semantic tableau for ¬A; the tableau is guaranteed to close since A
is valid. The completeness of H is proved by showing how to transform a proof in
G into a proof in H . Note that all three steps can be carried out algorithmically:
Given an arbitrary valid formula in propositional logic, a computer can generate its
proof.

3.6
Soundness and Completeness of H
65
We need a more general result because a proof in G is a sequence of sets of
formulas, while a proof in H is a sequence of formulas.
Theorem 3.39 If ⊢U in G , then ⊢U in H .
The difﬁculty arises from the clash of the data structures used: U is a set while
U is a single formula. To see why this is a problem, consider the base case of the
induction. The set {¬p,p} is an axiom in G and we immediately have ⊢¬p ∨p in
H since this is simply ⊢p →p. But if the axiom in G is {q,¬p,r,p,s}, we can’t
immediately conclude that ⊢q ∨¬p ∨r ∨p ∨s in H .
Lemma 3.40 If U′ ⊆U and ⊢U′ in H then ⊢U in H .
Proof The proof is by induction using weakening, commutativity and associativity
of disjunction (Theorems 3.34–3.35). We give the outline here and leave it as an
exercise to ﬁll in the details.
Suppose we have a proof of U′. By repeated application of Theorem 3.34, we
can transform this into a proof of U′′, where U′′ is a permutation of the elements
of U. By repeated applications of commutativity and associativity, we can move the
elements of U′′ to their proper places.
Example 3.41 Let U′ = {A,C} ⊂{A,B,C} = U and suppose we have a proof of
⊢U′ = A ∨C. This can be transformed into a proof of ⊢U = A ∨(B ∨C) as
follows, where Theorems 3.34–3.35 are used as derived rules:
1.
⊢A ∨C
Assumption
2.
⊢(A ∨C) ∨B
Weakening, 1
3.
⊢A ∨(C ∨B)
Associativity, 2
4.
⊢(C ∨B) →(B ∨C)
Commutativity
5.
⊢A ∨(C ∨B) →A ∨(B ∨C)
Weakening, 4
6.
⊢A ∨(B ∨C)
MP 3, 5
Proof of Theorem 3.39 The proof is by induction on the structure of the proof in G .
If U is an axiom, it contains a pair of complementary literals and ⊢¬p ∨p can be
proved in H . By Lemma 3.40, this can be transformed into a proof of U.
Otherwise, the last step in the proof of U in G is the application of a rule to an α-
or β-formula. As usual, we will use disjunction and conjunction as representatives
of α- and β-formulas.
Case 1: A rule in G was applied to obtain an α-formula ⊢U1 ∪{A1 ∨A2} from
⊢U1 ∪{A1,A2}. By the inductive hypothesis, ⊢((U1)∨A1)∨A2 in H from
which we infer ⊢U1 ∨(A1 ∨A2) by associativity.
Case 2: A rule in G was applied to obtain a β-formula ⊢U1 ∪U2 ∪{A1 ∧A2}
from ⊢U1 ∪{A1} and ⊢U2 ∪{A2}. By the inductive hypothesis, ⊢(U1)∨A1
and ⊢(U2) ∨A2 in H . We leave it to the reader to justify each step of the
following deduction of ⊢U1 ∨U2 ∨(A1 ∧A2):

66
3
Propositional Logic: Deductive Systems
1.
⊢U1 ∨A1
2.
⊢¬ U1 →A1
3.
⊢A1 →(A2 →(A1 ∧A2))
4.
⊢¬ U1 →(A2 →(A1 ∧A2))
5.
⊢A2 →(¬ U1 →(A1 ∧A2))
6.
⊢U2 ∨A2
7.
⊢¬ U2 →A2
8.
⊢¬ U2 →(¬ U1 →(A1 ∧A2))
9.
⊢U1 ∨U2 ∨(A1 ∧A2)
Proof of Theorem 3.38 If |= A then ⊢A in G by Theorem 3.8. By the remark at the
end of Deﬁnition 3.2, ⊢A is an abbreviation for ⊢{A}. By Theorem 3.39, ⊢{A}
in H . Since A is a single formula, ⊢A in H .
3.7 Consistency
What would mathematics be like if both 1 + 1 = 2 and ¬(1 + 1 = 2) ≡1 + 1 ̸= 2
could be proven? An inconsistent deductive system is useless, because all formulas
are provable and the concept of proof becomes meaningless.
Deﬁnition 3.42 A set of formulas U is inconsistent iff for some formula A, both
U ⊢A and U ⊢¬A. U is consistent iff it is not inconsistent. A deductive system is
inconsistent iff it contains an inconsistent set of formulas.
Theorem 3.43 U is inconsistent iff for all A, U ⊢A.
Proof Let A be an arbitrary formula. If U is inconsistent, for some formula B,
U ⊢B and U ⊢¬B. By Theorem 3.21, ⊢B →(¬B →A). Using MP twice, U ⊢A.
The converse is trivial.
Corollary 3.44 U is consistent if and only if for some A, U ̸⊢A.
If a deductive system is sound, then ⊢A implies |= A, and, conversely, ̸|= A
implies ̸⊢A. Therefore, if there is even a single falsiﬁable formula A in a sound
system, the system must be consistent! Since ̸|= false (where false is an abbrevi-
ation for ¬(p →p)), by the soundness of H , ̸⊢false. By Corollary 3.44, H is
consistent.

3.8
Strong Completeness and Compactness *
67
The following theorem is another way of characterizing inconsistency.
Theorem 3.45 U ⊢A if and only if U ∪{¬A} is inconsistent.
Proof If U ⊢A, obviously U ∪{¬A} ⊢A, since the extra assumption will not
be used in the proof. U ∪{¬A} ⊢¬A because ¬A is an assumption. By Deﬁ-
nition 3.42, U ∪{¬A} is inconsistent.
Conversely, if U ∪{¬A} is inconsistent, then U ∪{¬A} ⊢A by Theorem 3.43.
By the deduction theorem, U ⊢¬A→A, and U ⊢A follows by MP from ⊢(¬A→
A) →A (Theorem 3.31).
3.8 Strong Completeness and Compactness *
The construction of a semantic tableau can be generalized to an inﬁnite set of for-
mulas S = {A1,A2,...}. The label of the root is {A1}. Whenever a rule is applied to
a leaf of depth n, An+1 will be added to the label(s) of its child(ren) in addition to
the αi or βi.
Theorem 3.46 A set of formulas S = {A1,A2,...} is unsatisﬁable if and only if a
semantic tableau for S closes.
Proof Here is an outline of the proof that is given in detail in Smullyan (1968,
Chap. III).
If the tableau closes, there is only a ﬁnite subset S0 ⊂S of formulas on each
closed branch, and S0 is unsatisﬁable. By a generalization of Theorem 2.46 to an
inﬁnite set of formulas, it follows that S = S0 ∪(S −S0) is unsatisﬁable.
Conversely, if the tableau is open, it can be shown that there must be an inﬁnite
branch containing all formulas in S, and the union of formulas in the labels of nodes
on the branch forms a Hintikka set, from which a satisfying interpretation can be
found.
The completeness of propositional logic now generalizes to:
Theorem 3.47 (Strong completeness) Let U be a ﬁnite or countably inﬁnite set of
formulas and let A be a formula. If U |= A then U ⊢A.
The same construction proves the following important theorem.
Theorem 3.48 (Compactness) Let S be a countably inﬁnite set of formulas, and
suppose that every ﬁnite subset of S is satisﬁable. Then S is satisﬁable.
Proof Suppose that S were unsatisﬁable. Then a semantic tableau for S must close.
There are only a ﬁnite number of formulas labeling nodes on each closed branch.
Each such set of formulas is a ﬁnite unsatisﬁable subset of S, contracting the as-
sumption that all ﬁnite subsets are satisﬁable.

68
3
Propositional Logic: Deductive Systems
3.9 Variant Forms of the Deductive Systems *
G and H , the deductive systems that we presented in detail, are two of many pos-
sible deductive systems for propositional logic. Different systems are obtained by
changing the operators, the axioms or the representations of proofs. In propositional
logic, all these systems are equivalent in the sense that they are sound and complete.
In this section, we survey some of these variants.
3.9.1 Hilbert Systems
Hilbert systems almost invariably have MP as the only rule. They differ in the choice
of primitive operators and axioms. For example, H ′ is an Hilbert system where
Axiom 3 is replaced by:
Axiom 3′
⊢(¬B →¬A) →((¬B →A) →B).
Theorem 3.49 H and H ′ are equivalent in the sense that a proof in one system
can be transformed into a proof in the other.
Proof We prove Axiom 3′ in H . It follows that any proof in H ′ can be transformed
into a proof in H , by starting with this proof of the new axiom and using it as a
previously proved theorem.
1.
{¬B →¬A,¬B →A,¬B} ⊢¬B
Assumption
2.
{¬B →¬A,¬B →A,¬B} ⊢¬B →A
Assumption
3.
{¬B →¬A,¬B →A,¬B} ⊢A
MP 1, 2
4.
{¬B →¬A,¬B →A,¬B} ⊢¬B →¬A
Assumption
5.
{¬B →¬A,¬B →A,¬B} ⊢A →B
Contrapositive 4
6.
{¬B →¬A,¬B →A,¬B} ⊢B
MP 3, 5
7.
{¬B →¬A,¬B →A} ⊢¬B →B
Deduction 7
8.
{¬B →¬A,¬B →A} ⊢(¬B →B) →B
Theorem 3.31
9.
{¬B →¬A,¬B →A} ⊢B
MP 8, 9
10.
{¬B →¬A} ⊢(¬B →A) →B
Deduction 9
11.
⊢(¬B →¬A) →((¬B →A) →B)
Deduction 10
The use of the deduction theorem is legal because its proof in H does not use
Axiom 3, so the identical proof can be done in H ′.
We leave it as an exercise to prove Axiom 3 in H ′.
Either conjunction or disjunction may replace implication as the binary oper-
ator in the formulation of a Hilbert system. Implication can then be deﬁned by
¬(A ∧¬B) or ¬A ∨B, respectively, and MP is still the only inference rule. For
disjunction, a set of axioms is:

3.9
Variant Forms of the Deductive Systems *
69
Axiom 1
⊢A ∨A →A,
Axiom 2
⊢A →A ∨B,
Axiom 3
⊢A ∨B →B ∨A,
Axiom 4
⊢(B →C) →(A ∨B →A ∨C).
The steps needed to show the equivalence of this system with H are given in
Mendelson (2009, Exercise 1.54).
Finally, Meredith’s axiom:
⊢({[(A →B) →(¬C →¬D)] →C} →E) →[(E →A) →(D →A)],
together with MP as the rule of inference is a complete deductive system for proposi-
tional logic. Adventurous readers are invited to prove the axioms of H from Mered-
ith’s axiom following the 37-step plan given in Monk (1976, Exercise 8.50).
3.9.2 Gentzen Systems
G was constructed in order to simplify the theoretical treatment by using a nota-
tion that is identical to that of semantic tableaux. We now present a deductive sys-
tem similar to the one that Gentzen originally proposed; this system is taken from
Smullyan (1968, Chap. XI).
Deﬁnition 3.50 If U and V are (possibly empty) sets of formulas, then U ⇒V is
a sequent.
Intuitively, a sequent represents ‘provable from’ in the sense that the formulas in
U are assumptions for the set of formulas V that are to be proved. The symbol ⇒is
similar to the symbol ⊢in Hilbert systems, except that ⇒is part of the object lan-
guage of the deductive system being formalized, while ⊢is a metalanguage notation
used to reason about deductive systems.
Deﬁnition 3.51 Axioms in the Gentzen sequent system S
are sequents of the
form:
U ∪{A} ⇒V ∪{A}.
The rules of inference are shown in Fig. 3.2.
The semantics of the sequent system S are deﬁned as follows:
Deﬁnition 3.52 Let S = U ⇒V be a sequent where U = {U1,...,Un} and V =
{V1,...,Vm}, and let I be an interpretation for U ∪V . Then vI (S) = T if and
only if vI (U1) = ··· = vI (Un) = T implies that for some i, vI (Vi) = T .
This deﬁnition relates sequents to formulas: Given an interpretation I for U ∪V ,
vI (U ⇒V ) = T if and only if vI (U →V ) = T .

70
3
Propositional Logic: Deductive Systems
op
Introduction into consequent
Introduction into antecedent
∧
U ⇒V ∪{A}
U ⇒V ∪{B}
U ⇒V ∪{A ∧B}
U ∪{A,B} ⇒V
U ∪{A ∧B} ⇒V
∨
U ⇒V ∪{A,B}
U ⇒V ∪{A ∨B}
U ∪{A} ⇒V
U ∪{B} ⇒V
U ∪{A ∨B} ⇒V
→
U ∪{A} ⇒V ∪{B}
U ⇒V ∪{A →B}
U ⇒V ∪{A}
U ∪{B} ⇒V
U ∪{A →B} ⇒V
¬
U ∪{A} ⇒V
U ⇒V ∪{¬A}
U ⇒V ∪{A}
U ∪{¬A} ⇒V
Fig. 3.2 Rules of inference for sequents
3.9.3 Natural Deduction
The advantage of working with sequents is that the deduction theorem is a rule
of inference: introduction into the consequent of →. The convenience of Gentzen
systems is apparent when proofs are presented in a format called natural deduction
that emphasizes the role of assumptions.
Look at the proof of Theorem 3.30, for example. The assumptions are dragged
along throughout the entire deduction, even though each is used only twice, once as
an assumption and once in the deduction rule. The way we reason in mathematics
is to set out the assumptions once when they are ﬁrst needed and then to discharge
them by using the deduction rule. A natural deduction proof of Theorem 3.30 is
shown in Fig. 3.3.
The boxes indicate the scope of assumptions. Just as in programming where local
variables in procedures can only be used within the procedure and disappear when
the procedure is left, an assumption can only be used within the scope of its box,
and once it is discharged by using it in a deduction, it is no longer available.
3.9.4 Subformula Property
Deﬁnition 3.53 A deductive system has the subformula property iff any formula
appearing in a proof of A is either a subformula of A or the negation of a subformula
of A.
The systems G and S have the subformula property while H does not. For
example, in the proof of the theorem of double negation ⊢¬¬A →A, the formula
⊢¬¬¬¬A →¬¬A appeared even though it is obviously not a subformula of the
theorem.
Gentzen proposed his deductive system in order to obtain a system with the sub-
formula property. Then he deﬁned the system S ′ by adding an additional rule of
inference, the cut rule:
U,A ⇒V
U ⇒V,A
U ⇒V

3.10
Summary
71
1.
A →¬A
Assumption
2.
¬¬A
Assumption
3.
A
Double negation 2
4.
¬A
MP 1, 3
5.
A →(¬A →false)
Theorem 3.21
6.
¬A →false
MP 3, 5
7.
false
MP 4, 6
8.
¬¬A →false
Deduction 2, 7
9.
¬A
Reductio ad absurdum 8
10.
(A →¬A) →¬A
Deduction 1, 9
Fig. 3.3 A natural deduction proof
to the system S and showed that proofs in S ′ can be mechanically transformed into
proofs in S . See Smullyan (1968, Chap. XII) for a proof of the following theorem.
Theorem 3.54 (Gentzen’s Hauptsatz) Any proof in S ′ can be transformed into a
proof in S not using the cut rule.
3.10 Summary
Deductive systems were developed to formalize mathematical reasoning. The struc-
ture of Hilbert systems such as H imitates the style of mathematical theories: a
small number of axioms, modus ponens as the sole rule of inference and proofs as
linear sequences of formulas. The problem with Hilbert systems is that they offer
no guidance on how to ﬁnd a proof of a formula. Gentzen systems such as G (and
variants that use sequents or natural deduction) facilitate ﬁnding proofs because all
formulas that appear are subformulas of the formula to be proved or their negations.
Both the deductive systems G and H are sound and complete. Completeness
of G follows directly from the completeness of the method of semantic tableaux as
a decision procedure for satisﬁability and validity in propositional logic. However,
the method of semantic tableaux is not very efﬁcient. Our task in the next chapters
is to study more efﬁcient algorithms for satisﬁability and validity.
3.11 Further Reading
Our presentation is based upon Smullyan (1968) who showed how Gentzen systems
are closely related to tableaux. The deductive system H is from Mendelson (2009);
he develops the theory of H (and later its generalization to ﬁrst-order logic) with-
out recourse to tableaux. Huth and Ryan (2004) base their presentation of logic on
natural deduction. Velleman (2006) will help you learn how to prove theorems in
mathematics.

72
3
Propositional Logic: Deductive Systems
3.12 Exercises
3.1 Prove in G :
⊢(A →B) →(¬B →¬A),
⊢(A →B) →((¬A →B) →B),
⊢((A →B) →A) →A.
3.2 Prove that if ⊢U in G then there is a closed semantic tableau for ¯U (the forward
direction of Theorem 3.7).
3.3 Prove the derived rule modus tollens:
⊢¬B
⊢A →B
⊢¬A
.
3.4 Give proofs in G for each of the three axioms of H .
3.5 Prove ⊢(¬A →A) →A (Theorem 3.31) in H .
3.6 Prove ⊢(A →B) ∨(B →C) in H .
3.7 Prove ⊢((A →B) →A) →A in H .
3.8 Prove {¬A} ⊢(¬B →A) →B in H .
3.9 Prove Theorem 3.34 in H :
⊢A →A ∨B,
⊢B →A ∨B,
⊢(A →B) →((C ∨A) →(C ∨B)).
3.10 Prove Theorem 3.35 in H :
⊢A ∨(B ∨C) ↔(A ∨B) ∨C.
3.11 Prove Theorem 3.36 in H :
⊢A ∨(B ∧C) ↔(A ∨B) ∧(A ∨C),
⊢A ∧(B ∨C) ↔(A ∧B) ∨(A ∧C).
3.12 Prove that Axiom 2 of H is valid by constructing a semantic tableau for its
negation.
3.13 Complete the proof that if U′ ⊆U and ⊢U′ then ⊢U (Lemma 3.40).
3.14 Prove the last two formulas of Exercise 3.1 in H .

References
73
3.15 * Prove Axiom 3 of H in H ′.
3.16 * Prove that the Gentzen sequent system S is sound and complete.
3.17 * Prove that a set of formulas U is inconsistent if and only if there is a ﬁnite
set of formulas {A1,...,An} ⊆U such that ⊢¬A1 ∨··· ∨¬An.
3.18 A set of formulas U is maximally consistent iff every proper superset of U is
not consistent. Let S be a countable, consistent set of formulas. Prove:
1. Every ﬁnite subset of S is satisﬁable.
2. For every formula A, at least one of S ∪{A}, S ∪{¬A} is consistent.
3. S can be extended to a maximally consistent set.
References
M. Huth and M.D. Ryan. Logic in Computer Science: Modelling and Reasoning about Systems
(Second Edition). Cambridge University Press, 2004.
E. Mendelson. Introduction to Mathematical Logic (Fifth Edition). Chapman & Hall/CRC, 2009.
J.D. Monk. Mathematical Logic. Springer, 1976.
R.M. Smullyan. First-Order Logic. Springer-Verlag, 1968. Reprinted by Dover, 1995.
D.J. Velleman. How to Prove It: A Structured Approach (Second Edition). Cambridge University
Press, 2006.


Chapter 4
Propositional Logic: Resolution
The method of resolution, invented by J.A. Robinson in 1965, is an efﬁcient method
for searching for a proof. In this section, we introduce resolution for the proposi-
tional logic, though its advantages will not become apparent until it is extended to
ﬁrst-order logic. It is important to become familiar with resolution, because it is
widely used in automatic theorem provers and it is also the basis of logic program-
ming (Chap. 11).
4.1 Conjunctive Normal Form
Deﬁnition 4.1 A formula is in conjunctive normal form (CNF) iff it is a conjunction
of disjunctions of literals.
Example 4.2 The formula:
(¬p ∨q ∨r) ∧(¬q ∨r) ∧(¬r)
is in CNF while the formula:
(¬p ∨q ∨r) ∧((p ∧¬q) ∨r) ∧(¬r)
is not in CNF, because (p ∧¬q) ∨r is not a disjunction.
The formula:
(¬p ∨q ∨r) ∧¬ (¬q ∨r) ∧(¬r)
is not in CNF because the second disjunction is negated.
Theorem 4.3 Every formula in propositional logic can be transformed into an
equivalent formula in CNF.
Proof To convert an arbitrary formula to a formula in CNF perform the following
steps, each of which preserves logical equivalence:
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_4, © Springer-Verlag London 2012
75

76
4
Propositional Logic: Resolution
1. Eliminate all operators except for negation, conjunction and disjunction by sub-
stituting logically equivalent formulas:
A ↔B
≡(A →B) ∧(B →A),
A ⊕B
≡¬ (A →B) ∨¬ (B →A),
A →B
≡¬A ∨B,
A ↑B
≡¬(A ∧B),
A ↓B
≡¬(A ∨B).
2. Push negations inward using De Morgan’s laws:
¬ (A ∧B) ≡(¬A ∨¬B),
¬ (A ∨B) ≡(¬A ∧¬B),
until they appear only before atomic propositions or atomic propositions pre-
ceded by negations.
3. Eliminate sequences of negations by deleting double negation operators:
¬¬A ≡A.
4. The formula now consists of disjunctions and conjunctions of literals. Use the
distributive laws:
A ∨(B ∧C) ≡(A ∨B) ∧(A ∨C),
(A ∧B) ∨C
≡(A ∨C) ∧(B ∨C)
to eliminate conjunctions within disjunctions.
Example 4.4 The following sequence of formulas shows the four steps applied to
the formula (¬p →¬q) →(p →q):
(¬p →¬q) →(p →q) ≡¬ (¬¬p ∨¬q) ∨(¬p ∨q)
≡(¬¬¬p ∧¬¬q) ∨(¬p ∨q)
≡(¬p ∧q) ∨(¬p ∨q)
≡(¬p ∨¬p ∨q) ∧(q ∨¬p ∨q).

4.2
Clausal Form
77
4.2 Clausal Form
The clausal form of formula is a notational variant of CNF. Recall (Deﬁnition 2.57)
that a literal is an atom or the negation of an atom.
Deﬁnition 4.5
• A clause is a set of literals.
• A clause is considered to be an implicit disjunction of its literals.
• A unit clause is a clause consisting of exactly one literal.
• The empty set of literals is the empty clause, denoted by 2.
• A formula in clausal form is a set of clauses.
• A formula is considered to be an implicit conjunction of its clauses.
• The formula that is the empty set of clauses is denoted by ∅.
The only signiﬁcant difference between clausal form and the standard syntax is
that clausal form is deﬁned in terms of sets, while our standard syntax was deﬁned
in terms of trees. A node in a tree may have multiple children that are identical
subtrees, but a set has only one occurrence of each of its elements. However, this
difference is of no logical signiﬁcance.
Corollary 4.6 Every formula φ in propositional logic can be transformed into an
logically equivalent formula in clausal form.
Proof By Theorem 4.3, φ can be transformed into a logically equivalent formula φ′
in CNF. Transform each disjunction in φ′ into a clause (a set of literals) and φ′ itself
into the set of these clauses. Clearly, the transformation into sets will cause multi-
ple occurrences of literals and clauses to collapse into single occurrences. Logical
equivalence is preserved by idempotence: A ∧A ≡A and A ∨A ≡A.
Example 4.7 The CNF formula:
(p ∨r) ∧(¬q ∨¬p ∨q) ∧(p ∨¬p ∨q ∨p ∨¬p) ∧(r ∨p)
is logically equivalent to its clausal form:
{{p,r}, {¬q,¬p,q}, {p,¬p,q}}.
The clauses corresponding to the ﬁrst and last disjunctions collapse into a single set,
while in the third disjunction multiple occurrences of p and ¬p have been collapsed
to obtain the third clause.
Trivial Clauses
A formula in clausal form can be simpliﬁed by removing trivial clauses.
Deﬁnition 4.8 A clause if trivial if it contains a pair of clashing literals.

78
4
Propositional Logic: Resolution
Since a trivial clause is valid (p ∨¬p ≡true), it can be removed from a set of
clauses without changing the truth value of the formula.
Lemma 4.9 Let S be a set of clauses and let C ∈S be a trivial clause. Then S −{C}
is logically equivalent to S.
Proof Since a clause is an implicit disjunction, C is logically equivalent to a for-
mula obtained by weakening, commutativity and associativity of a valid disjunction
p ∨¬p (Theorems 3.34–3.35). Let I be any interpretation for S −{C}. Since
S −{C} is an implicit conjunction, the value vI (S −{C}) is not changed by adding
the clause C, since vI (C) = T and A ∧T ≡A. Therefore, vI (S −{C}) = vI (S).
Since I was arbitrary, it follows that S −{C} ≡S.
Henceforth, we will assume that all trivial clauses have been deleted from for-
mulas in clausal form.
The Empty Clause and the Empty Set of Clauses
The following results may be a bit hard to understand at ﬁrst, but they are very
important. The proof uses reasoning about vacuous sets.
Lemma 4.10
2,the empty clause, is unsatisﬁable.
∅,the empty set of clauses, is valid.
Proof A clause is satisﬁable iff there is some interpretation under which at least
one literal in the clause is true. Let I be an arbitrary interpretation. Since there are
no literals in 2, there are no literals whose value is true under I . But I was an
arbitrary interpretation, so 2 is unsatisﬁable.
A set of clauses is valid iff every clause in the set is true in every interpretation.
But there are no clauses in ∅that need be true, so ∅is valid.
Notation
When working with clausal form, the following additional notational conventions
will be used:
• An abbreviated notation will be used for a formula in clausal form. The set de-
limiters { and } are removed from each clause and a negated literal is denoted by
a bar over the atomic proposition. In this notation, the formula in Example 4.7
becomes:
{pr, ¯q ¯pq, p ¯pq}.
• S is a formula in clausal form, C is a clause and l is a literal. The symbols will be
subscripted and primed as necessary.
• If l is a literal lc is its complement: if l = p then lc = ¯p and if l = ¯p then lc = p.

4.2
Clausal Form
79
• The concept of an interpretation is generalized to literals. Let l be a literal deﬁned
on the atomic proposition p, that is, l is p or l is ¯p. Then an interpretation I for
a set of atomic propositions including p is extended to l as follows:
– I (l) = T , if l = p and I (p) = T ,
– I (l) = F , if l = p and I (p) = F ,
– I (l) = T , if l = ¯p and I (p) = F ,
– I (l) = F , if l = ¯p and I (p) = T .
The Restriction of CNF to 3CNF *
Deﬁnition 4.11 A formula is in 3CNF iff it is in CNF and each disjunction has
exactly three literals.
The problem of ﬁnding a model for a formula in CNF belongs to an important
class of problems called N P-complete problems (Sect. 6.7). This important the-
oretical result holds even if the formulas are restricted to 3CNF. To prove this, an
efﬁcient algorithm is needed to transform a CNF formula into one in 3CNF.
Algorithm 4.12 (CNF to 3CNF)
Input: A formula in CNF.
Output: A formula in 3CNF.
For each disjunction Ci = l1
i ∨l2
i ∨··· ∨lni
i , perform the appropriate transforma-
tion depending of the value of ni:
• If ni = 1, create two new atoms p1
i ,p2
i and replace Ci by:
(l1
i ∨p1
i ∨p2
i ) ∧(l1
i ∨¬p1
i ∨p2
i ) ∧(l1
i ∨p1
i ∨¬p2
i ) ∧(l1
i ∨¬p1
i ∨¬p2
i ).
• If ni = 2, create one new atom p1
i and replace Ci by:
(l1
i ∨l2
i ∨p1
i ) ∧(l1
i ∨l2
i ∨¬p1
i ).
• If ni = 3, do nothing.
• If ni > 3, create n −3 new atoms p1
i ,p2
i ,...,pn−3
i
and replace Ci by:
(l1
i ∨l2
i ∨p1
i ) ∧(¬p1
i ∨l3
i ∨p2
i ) ∧··· ∧(¬pn−3
i
∨ln−1
i
∨ln
i ).
We leave the proof of the following theorem as an exercise.
Theorem 4.13 Let A be a formula in CNF and let A′ be the formula in 3CNF
constructed from A by Algorithm 4.12. Then A is satisﬁable if and only if A′ is
satisﬁable. The length of A′ (the number of symbols in A′) is a polynomial in the
length of A.

80
4
Propositional Logic: Resolution
4.3 Resolution Rule
Resolution is a refutation procedure used to check if a formula in clausal form is
unsatisﬁable. The resolution procedure consists of a sequence of applications of
the resolution rule to a set of clauses. The rule maintains satisﬁability: if a set of
clauses is satisﬁable, so is the set of clauses produced by an application of the rule.
Therefore, if the (unsatisﬁable) empty clause is ever obtained, the original set of
clauses must have been unsatisﬁable.
Rule 4.14 (Resolution rule) Let C1, C2 be clauses such that l ∈C1, lc ∈C2. The
clauses C1, C2 are said to be clashing clauses and to clash on the complementary
pair of literals l, lc. C, the resolvent of C1 and C2, is the clause:
Res(C1,C2) = (C1 −{l}) ∪(C2 −{lc}).
C1 and C2 are the parent clauses of C.
Example 4.15 The pair of clauses C1 = ab¯c and C2 = bc¯e clash on the pair of
complementary literals c, ¯c. The resolvent is:
C = (ab¯c −{¯c}) ∪(bc¯e −{c}) = ab ∪b¯e = ab¯e.
Recall that a clause is a set so duplicate literals are removed when taking the union:
{a,b} ∪{b, ¯e} = {a,b, ¯e}.
Resolution is only performed if the pair of clauses clash on exactly one pair of
complementary literals.
Lemma 4.16 If two clauses clash on more than one literal, their resolvent is a
trivial clause (Deﬁnition 4.8).
Proof Consider a pair of clauses:
{l1, l2} ∪C1,
{lc
1, lc
2} ∪C2,
and suppose that we perform the resolution rule because the clauses clash on the
pair of literals {l1,lc
1}. The resolvent is the trivial clause:
{l2, lc
2} ∪C1 ∪C2.
It is not strictly incorrect to perform resolution on such clauses, but since trivial
clauses contribute nothing to the satisﬁability or unsatisﬁability of a set of clauses
(Theorem 4.9), we agree to delete them from any set of clauses and not to perform
resolution on clauses with two clashing pairs of literals.

4.3
Resolution Rule
81
Theorem 4.17 The resolvent C is satisﬁable if and only if the parent clauses C1
and C2 are both satisﬁable.
Proof Let C1 and C2 be satisﬁable under an interpretation I . Since l,lc are
complementary, either I (l) = T or I (lc) = T . Suppose that I (l) = T ; then
I (lc) = F and C2, the clause containing lc, can be satisﬁed only if I (l′) = T
for some other literal l′ ∈C2,l′ ̸= lc. By construction in the resolution rule, l′ ∈C,
so I is also a model for C. A symmetric argument holds if I (lc) = T .
Conversely, let I be an interpretation which satisﬁes C; then I (l′) = T for at
least one literal l′ ∈C. By the resolution rule, l′ ∈C1 or l′ ∈C2 (or both). If l′ ∈C1,
then vI (C1) = T . Since neither l ∈C nor lc ∈C, I is not deﬁned on either l or lc,
and we can extend I to an interpretation I ′ by deﬁning I (lc) = T . Since lc ∈C2,
vI ′(C2) = T and vI ′(C1) = vI (C1) = T (because I is an extension of v) so I ′
is a model for both C1 and C2. A symmetric argument holds if l′ ∈C2.
Algorithm 4.18 (Resolution procedure)
Input: A set of clauses S.
Output: S is satisﬁable or unsatisﬁable.
Let S be a set of clauses and deﬁne S0 = S.
Repeat the following steps to obtain Si+1 from Si until the procedure terminates
as deﬁned below:
• Choose a pair of clashing clauses {C1,C2} ⊆Si that has not been chosen before.
• Compute C = Res(C1,C2) according to the resolution rule.
• If C is not a trivial clause, let Si+1 = Si ∪{C}; otherwise, Si+1 = Si.
Terminate the procedure if:
• C = 2.
• All pairs of clashing clauses have be resolved.
Example 4.19 Consider the set of clauses:
S = {(1)p, (2) ¯pq, (3) ¯r, (4) ¯p ¯qr},
where the clauses have been numbered. Here is a resolution derivation of 2 from S,
where the justiﬁcation for each line is the pair of the numbers of the parent clauses
that have been resolved to give the resolvent clause:
5.
¯p ¯q
3,4
6.
¯p
5,2
7.
2
6,1
It is easier to read a resolution derivation if it is presented as a tree. Figure 4.1
shows the tree that represents the derivation of Example 4.19. The clauses of S label
leaves, and the resolvents label interior nodes whose children are the parent clauses
used in the resolution.

82
4
Propositional Logic: Resolution
Fig. 4.1 A resolution
refutation represented
as a tree
Deﬁnition 4.20 A derivation of 2 from a set of clauses S is a refutation by resolu-
tion of S or a resolution refutation of S.
Since 2 is unsatisﬁable, by Theorem 4.17 if there exists a refutation of S by
resolution then S is unsatisﬁable.
In Example 4.19, we derived the unsatisﬁable clause 2, so we conclude that the
set of clauses S is unsatisﬁable. We leave it to the reader to check that S is the
clausal form of ¬A where A is an instance of Axiom 2 of H (p →(q →r)) →
((p →q) →(p →r)). Since ¬A is unsatisﬁable, A is valid.
4.4 Soundness and Completeness of Resolution *
The soundness of resolution follows easily from Theorem 4.17, but completeness
is rather difﬁcult to prove, so you may want to skip the this section on your ﬁrst
reading.
Theorem 4.21 If the set of clauses labeling the leaves of a resolution tree is satisﬁ-
able then the clause at the root is satisﬁable.
The proof is by induction using Theorem 4.17 and is left as an exercise.
The converse to Theorem 4.21 is not true because we have no way of ensuring
that the extensions made to I on all branches are consistent. In the tree in Fig. 4.2,
the set of clauses on the leaves S = {r,pq ¯r, ¯r,p ¯qr} is not satisﬁable even though
the clause p at the root is satisﬁable. Since S is unsatisﬁable, it has a refutation:
whenever the pair of clashing clauses r and ¯r is chosen, the resolvent will be 2.
Resolution is a refutation procedure, so soundness and completeness are better
expressed in terms of unsatisﬁability, rather than validity.

4.4
Soundness and Completeness of Resolution *
83
Fig. 4.2 Incomplete
resolution tree
Corollary 4.22 (Soundness) Let S be a set of clauses. If there is a refutation by
resolution for S then S is unsatisﬁable.
Proof Immediate from Theorem 4.21 and Lemma 4.10.
Theorem 4.23 (Completeness) If a set of clauses is unsatisﬁable then the empty
clause 2 will be derived by the resolution procedure.
We have to prove that given an unsatisﬁable set of clauses, the resolution proce-
dure will eventually terminate producing 2, rather than continuing indeﬁnitely or
terminating but failing to produce 2. The resolution procedure was deﬁned so that
the same pair of clauses is never chosen more than once. Since there are only a ﬁnite
number of distinct clauses on the ﬁnite set of atomic propositions appearing in a set
of clauses, the procedure terminates. We need only prove that when the procedure
terminates, the empty clause is produced.
Semantic Trees
The proof will use semantic trees (which must not be confused with semantic tab-
leaux). A semantic tree is a data structure for recording assignments of T and F to
the atomic propositions of a formula in the process of searching for a model (satis-
fying interpretation). If the formula is unsatisﬁable, the search for a model must end
in failure. Clauses that are created during a resolution refutation will be associated
with nodes of the tree called failure nodes; these nodes represent assignments that
falsify the associated clauses. Eventually, the root node (associated with the empty
clause 2) will be shown to be a failure node.
Deﬁnition 4.24 (Semantic tree) Let S be a set of clauses and let PS = {p1,...,pn}
be the set of atomic propositions appearing in S. T , the semantic tree for S, is a
complete binary tree of depth n such that for 1 ≤i ≤n, every left-branching edge
from a node at depth i −1 is labeled pi and every right-branching edge is labeled
by ¯pi.

84
4
Propositional Logic: Resolution
Fig. 4.3 Semantic tree
Every branch b from the root to a leaf in T is labeled by a sequence of literals
{l1,...,ln}, where li = pi or li = ¯pi. b deﬁnes an interpretation by:
Ib(pi) = T
if li = pi,
Ib(pi) = F
if li = ¯pi.
A branch b is closed if vb(S) = F , otherwise b is open. T is closed if all branches
are closed, otherwise T is open.
Example 4.25 The semantic tree for S = {p, ¯pq, ¯r, ¯p ¯qr} is shown in Fig. 4.3 where
the numbers on the nodes will be explained later. The branch b ending in the leaf
labeled 4 deﬁnes the interpretation:
Ib(p) = T,
Ib(q) = T,
Ib(r) = F.
Since vIb( ¯p ¯qr) = F , vIb(S) = F (a set of clauses is the conjunction of its mem-
bers) and the branch b is closed. We leave it to the reader to check that every branch
in this tree is closed.
Lemma 4.26 Let S be a set of clauses and let T a semantic tree for S. Every
interpretation I for S corresponds to Ib for some branch b in T , and conversely,
every Ib is an interpretation for S.
Proof By construction.
Theorem 4.27 The semantic tree T for a set of clauses S is closed if and only if
the set S is unsatisﬁable.
Proof Suppose that T is closed and let I be an arbitrary interpretation for S. By
Lemma 4.26, I is Ib for some branch in T . Since T is closed, vb(S) = F . But
I = Ib was arbitrary so S is unsatisﬁable.
Conversely, let S be an unsatisﬁable set of clauses, T the semantic tree for S and
b an arbitrary branch in T . Then vb is an interpretation for S by Lemma 4.26, and
vb(S) = F since S is unsatisﬁable. Since b was arbitrary, T is closed.

4.4
Soundness and Completeness of Resolution *
85
Failure Nodes
When traversing a branch of the semantic tree top-down, a (partial) branch from
the root to a node represents a partial interpretation (Deﬁnition 2.18) deﬁned by the
labels of the edges that were traversed. It is possible that this partial interpretation is
sufﬁciently deﬁned to evaluate the truth value of some clauses; in particular, some
clause might evaluate to F . Since a set of clauses is an implicit conjunction, if even
one clause evaluates to F , the partial interpretation is sufﬁcient to conclude that the
entire set of clauses is false. In a closed semantic tree, there must be such a node on
every branch. However, if a clause contains the literal labeling the edge to a leaf, a
(full) interpretation may be necessary to falsify the clause.
Example 4.28 In the semantic tree for S = {p, ¯pq, ¯r, ¯p ¯qr} (Fig. 4.3), the partial
branch bp ¯q from the root to the node numbered 2 deﬁnes a partial interpretation
Ibp ¯q(p) = T , Ibp ¯q(q) = F , which falsiﬁes the clause ¯pq and thus the entire set of
clauses S.
Consider now the partial branches bp and bpq and the full branch bpqr that are
obtained by always taking the child labeled by a positive literal. The partial in-
terpretation Ibp(p) = T does not falsify any of the clauses, nor does the partial
interpretation Ibpq(p) = T , I bpq(q) = T . Only the full interpretation Ibpqr that
assigns T to r falsiﬁes one of the clauses (¯r).
Deﬁnition 4.29 Let T be a closed semantic tree for a set of clauses S and let b be
a branch in T . The node in b closest to the root which falsiﬁes S is a failure node.
Example 4.30 Referring again to Fig. 4.3, the node numbered 2 is a failure node
since neither its parent node (which deﬁnes the partial interpretation Ibp) nor the
root itself falsiﬁes any of the clauses in the set. We leave it to the read to check that
all the numbered nodes are failure nodes.
Since a failure node falsiﬁes S (an implicit conjunction of clauses), it must falsify
at least once clause in S.
Deﬁnition 4.31 A clause falsiﬁed by a failure node is a clause associated with the
node.
Example 4.32 The failure nodes in Fig. 4.3 are labeled with the number of a clause
associated with it; the numbers were given in Examples 4.19.
It is possible that more than one clause is associated with a failure node; for
example, if q is added to the set of clauses, then q is another clause associated with
failure node numbered 2.
We can characterize the clauses associated with failure nodes. For C to be fal-
siﬁed at a failure node n, all the literals in C must be assigned F in the partial
interpretation.

86
4
Propositional Logic: Resolution
Fig. 4.4 Inference and
failure nodes
Example 4.33 In Fig. 4.3, ¯r is a clause associated with the failure node numbered 3.
{¯r} is a proper subset of { ¯p, ¯q, ¯r}, the set of complements of the literals assigned to
on the branch.
Lemma 4.34 A clause C associated with a failure node n is a subset of the com-
plements of the literals appearing on the partial branch b from the root to n.
Proof Let C = l1 ···lk and let E = {e1,...,em} be the set of literals labeling edges
in the branch. Since C is the clause associated with the failure node n, vb(C) = F for
the interpretation Ib deﬁned by Ib(ej) = T for all ej ∈E. C is a disjunction so for
each li ∈C, Ib(li) must be assigned F . Since Ib only assigns to the literals in E,
it follows that li = ec
j for some ej ∈E. Therefore, C = l1 ···lk ⊆{ec
1,...,ec
m}.
Inference Nodes
Deﬁnition 4.35 n is an inference node iff its children are failure nodes.
Example 4.36 In Fig. 4.3, the parent of nodes 3 and 4 is an inference node.
Lemma 4.37 Let T be a closed semantic tree for a set of clauses S. If there are at
least two failure nodes in T , then there is at least one inference node.
Proof Suppose that n1 is a failure node and that its sibling n2 is not (Fig. 4.4). Then
no ancestor of n2 can be a failure node, because its ancestors are also ancestors of
n1, which is, by assumption, a failure node and thus the node closest to the root on
its branch which falsiﬁes S.
T is closed so every branch in T is closed, in particular, any branch b that
includes n2 is closed. By deﬁnition of a closed branch, Ib, the full interpretation
associated with the leaf of b, must falsify S. Since neither n2 nor any ancestor of
n2 is a failure node, some node below n2 on b (perhaps the leaf itself) must be the
highest node which falsiﬁes a clause in S.
We have shown that given an arbitrary failure node n1, either its sibling n2 is a
failure node (and hence their parent is an inference node), or there is a failure node
at a greater depth than n1 and n2. Therefore, if there is no inference node, there must
be an inﬁnite sequence of failure nodes. But this is impossible, since a semantic tree
is ﬁnite (its depth is the number of different atomic propositions in S).

4.4
Soundness and Completeness of Resolution *
87
Lemma 4.38 Let T be closed semantic tree and let n be an inference node whose
children n1 and n2 of n are (by deﬁnition) failure nodes with clauses C1 and C2
associated with them, respectively. Then C1, C2 clash and the partial interpretation
deﬁned by the branch from the root to n falsiﬁes their resolvent.
Proof of the Notation follows Fig. 4.4. Let b1 and b2 be the partial branches from
the root to the nodes n1 and n2, respectively. Since n1 and n2 are failure nodes and
since C1 and C2 are clauses associated with the nodes, they are not falsiﬁed by any
node higher up in the tree. By Lemma 4.34, the clauses C1 and C2 are subsets of the
complements of the literals labeling the nodes of b1 and b2, respectively. Since b1
and b2 are identical except for the edges from n to n1 and n2, we must have ¯l ∈C1
and ¯lc ∈C2 so that the clauses are falsiﬁed by the assignments to the literals.
Since the nodes n1 and n2 are failure nodes, vIb1(C1) = vIb2(C2) = F . But
clauses are disjunctions so vIb1(C1 −{¯l}) = vIb2(C2 −{ ¯lc}) = F and this also
holds for the interpretation Ib. Therefore, their resolvent is also falsiﬁed:
vIb( (C1 −{¯l}) ∪(C2 −{ ¯lc}) ) = F.
Example 4.39 In Fig. 4.3, ¯r and ¯p ¯qr are clauses associated with failure nodes 3
and 4, respectively. The resolvent ¯p ¯q is falsiﬁed by Ipq(p) = T,Ipq(q) = T , the
partial interpretation associated with the parent node of 3 and 4. The parent node is
now a failure node for the set of clauses S ∪{ ¯p ¯q}.
There is a technicality that must be dealt with before we can prove completeness.
A semantic tree is deﬁned by choosing an ordering for the set of atoms that appear
in all the clauses in a set; therefore, an inference node may not be a failure node.
Example 4.40 The semantic tree in Fig. 4.3 is also a semantic tree for the set of
clauses {p, ¯pq, ¯r, ¯pr}. Node 3 is a failure node associated with ¯r and 4 is a failure
node associated with ¯pr, but their parent is not a failure node for their resolvent ¯p,
since it is already falsiﬁed by a node higher up in the tree. (Recall that a failure node
was deﬁned to be the node closest to the root which falsiﬁes the set of clauses.)
Lemma 4.41 Let n be an inference node, C1,C2 ∈S clauses associated with the
failure nodes that are the children of n, and C their resolvent. Then S ∪{C} has a
failure node that is either n or an ancestor of n and C is a clause associated with
the failure node.
Proof By Lemma 4.38, vIb(C) = F , where Ib is the partial interpretation associ-
ated with the partial branch b from the root to the inference node. By Lemma 4.34,
C ⊆{lc
1,...,lc
n}, the set of complements of the literals labeling b. Let j be the
smallest index such C ∩{lc
j+1,...,lc
n} = ∅. Then C ⊆{lc
1,...,lc
j} ⊆{lc
1,...,lc
n} so
vI j
b (C) = vIb(C) = F where I j
b is the partial interpretation deﬁned by the partial
branch from the root to node j. It follows that j is a failure node and C is a clause
associated with it.

88
4
Propositional Logic: Resolution
Example 4.42 Returning to the set of clauses {p, ¯pq, ¯r, ¯pr} in Example 4.40, the
resolvent at the inference node is C = { ¯p}. Now C = { ¯p} ⊆{ ¯p, ¯q}, the complements
of the literals on the partial branch from the root to the inference node. Let j = 1.
Then { ¯p} ∩{¯q} = ∅, { ¯p} ⊆{ ¯p} and C = { ¯p} is falsiﬁed by the partial interpretation
Ibp(p) = T .
We now have all the machinery needed to proof completeness.
Proof of Completeness of resolution If S is an unsatisﬁable set of clauses, there is a
closed semantic tree T for S. If S is unsatisﬁable and does not already contain 2,
there must be at least two failure nodes in T (exercise), so by Lemma 4.37, there is
at least one inference node in T .
An application of the resolution rule at the inference node adds the resolvent
to the set, creating a failure node by Lemma 4.41 and deleting two failure nodes,
thus decreasing the number of failure nodes. When the number of failure nodes has
decreased to one, it must be the root which is associated with the derivation of the
empty clause by the resolution rule.
4.5 Hard Examples for Resolution *
If you try the resolution procedure on formulas in clausal form, you will ﬁnd that is
usually quite efﬁcient. However, there are families of formulas on which any resolu-
tion refutation is necessarily inefﬁcient. We show how an unsatisﬁable set of clauses
can be associated with an arbitrarily large graph such that a resolution refutation of
a set of clauses from this family produces an exponential number of new clauses.
Let G be an undirected graph. Label the nodes with 0 or 1 and the edges with
distinct atoms. The following graph will be used as an example throughout this sec-
tion.
Deﬁnition 4.43
• The parity of a natural number i is 0 if i is even and 1 if i is odd.
• Let C be a clause. Π(C), the parity of C, is the parity of the number of comple-
mented literals in C.
• Let I be an interpretation for a set of atomic propositions P. Π(I ), the parity
of I , is the parity of the number of atoms in P assigned T in I .

4.5
Hard Examples for Resolution *
89
Example 4.44 Π(p¯r ¯s) = 2 and Π( ¯p¯r ¯s) = 3. For the interpretation I deﬁned by
I (p) = T , I (q) = T , I (r) = F , the parity Π(I ) is 2.
With each graph we associate a set of clauses.
Deﬁnition 4.45 Let G be an undirected, connected graph, whose nodes are labeled
with 0 or 1 and whose edges are labeled with distinct atomic propositions. Let n
be a node of G labeled an (0 or 1) and let Pn = {p1,...,pk} be the set of atoms
labeling edges incident with n.
C(n), the set of clauses associated with n, is the set of all clauses C that can
be formed as follows: the literals of C are all the atoms in Pn, some of which are
negated so that Π(C) ̸= an.
C(G), the set of clauses associated with G, is 
n∈G C(n).
Let I be an interpretation on all the atomic propositions 
n Pn in G. In is the
restriction of I to node n which assigns truth values only to the literals in C(n).
Example 4.46 The sets of clauses associated with the four nodes of the graph are
(clockwise from the upper-left corner):
{ ¯pq, p ¯q },
{prs, ¯p¯rs, ¯pr ¯s, p¯r ¯s },
{¯st, s¯t },
{¯qrt, q ¯rt, qr ¯t, ¯q ¯r ¯t }.
By deﬁnition, the parity of each clause associated with a node n must be opposite
the parity of n. For example:
Π( ¯p¯rs) = 0 ̸= 1,
Π(¯qrt) = 1 ̸= 0.
Lemma 4.47 In is a model for C(n) if and only if Π(In) = an.
Proof Suppose that Π(In) ̸= an and consider the clause C ∈C(n) deﬁned by:
li = pi
if In(pi) = F,
li = ¯pi
if In(pi) = T.
Then:
Π(C) = parity of negated atoms of C
(by deﬁnition)
= parity of literals assigned T
(by construction)
= Π(In)
(by deﬁnition)
̸= an
(by assumption).
But In(C) = F since In assigns F to each literal li ∈C (T to negated literals and
F to atoms). Therefore, In does not satisfy all clauses in C(n).
We leave the proof of the converse as an exercise.

90
4
Propositional Logic: Resolution
Example 4.48 Consider an interpretation I such that In is:
In(p) = In(r) = In(s) = T
for n the upper right node in the graph. For such interpretations, Π(In) = 1 = an,
and it is easy to see that vn(prs) = vn( ¯p¯rs) = vn( ¯pq¯s) = vn(p¯r ¯s) = T so I is a
model for C(n).
Consider an interpretation I such that In is:
In(p) = In(r) = In(s) = F.
Π(In) = 0 ̸= an and vn(prs) = F so I is not a model for C(n).
C(G) is the set of clauses obtained by taking the union of the clauses associ-
ated with all the nodes in the graph. Compute the sum modulo 2 (denoted  in
the following lemma) of the labels of the nodes and the sum of the parities of the
restrictions of an interpretation to each node. Since each atom appears twice, the
sum of the parities of the restricted interpretations must be 0. By Lemma 4.47, for
the clauses to be satisﬁable, the sum of the node labels must be the same as the sum
of the parities of the interpretations, namely zero.
Lemma 4.49 If 
n∈G an = 1 then C(G) is unsatisﬁable.
Proof Suppose that there exists a model I for C(G) = 
n∈G C(n). By Lemma 4.47,
for all n, Π(In) = an, so:

n∈G
Π(In) =

n∈G
an = 1.
Let pe be the atom labeling an arbitrary edge e in G; it is incident with (exactly)
two nodes, n1 and n2. The sum of the parities of the restricted interpretations can be
written:

n∈G
Π(In) = Π(In1) + Π(In2) +

n∈(G−{n1,n2})
Π(In).
Whatever the value of the assignment of I to pe, it appears once in the ﬁrst term,
once in the second term and not at all in the third term above. By modulo 2 arith-
metic, the total contribution of the assignment to pe to 
n∈G Π(In) is 0. Since e
was arbitrary, this is true for all atoms, so:

n∈G
Π(In) = 0,
contradicting 
n∈G Π(In) = 1 obtained above. Therefore, I cannot be a model
for C(G), so C(G) must be unsatisﬁable.

4.5
Hard Examples for Resolution *
91
Tseitin (1968) deﬁned a family Gn of graphs of arbitrary size n and showed
that for a restricted form of resolution the number of distinct clauses that appear
a resolution refutation of C(Gn) is exponential in n. About twenty years later, the
restriction was removed by Urquhart (1987).
4.5.1 Tseitin Encoding
The standard procedure for transforming a formula into CNF (Sect. 4.1) can lead
to formulas that are signiﬁcantly larger than the original formula. In practice, an
alternate transformation by Tseitin (1968) yields a more compact set of clauses at
the expense of adding new atoms.
Algorithm 4.50 (Tseitin encoding) Let A be a formula in propositional logic. De-
ﬁne a sequence of formulas A = A0,A1,A2,... by repeatedly performing the trans-
formation:
• Let B′
i ◦B′′
i be a subformula of Ai, where B′
i, B′′
i are literals.
• Let pi be a new atom that does not appear in Ai. Construct Ai+1 by replacing the
subformula B′
i ◦B′′
i by pi and adding the CNF of:
pi ↔B′
i ◦B′′
i .
• Terminate the transformation when An is in CNF.
Theorem 4.51 Let A be a formula in propositional logic and apply Algorithm 4.50
to obtain the CNF formula An. Then A is satisﬁable if and only if An is satisﬁable.
Example 4.52 Let n be a node labeled 1 with ﬁve incident edges labeled by the
atoms p, q, r, s, t. C(n) consists of all clauses of even parity deﬁned on these
atoms:
pqrst,
¯p ¯qrst, ¯pq ¯rst, ..., pq ¯rs¯t, pqr ¯s¯t
p ¯q ¯r ¯s¯t, ¯pq ¯r ¯s¯t, ¯p ¯qr ¯s¯t, ¯p ¯q ¯rs¯t, ¯p ¯q ¯r ¯st.
There are 16 clauses in C(n) since there 25 = 32 clauses on ﬁve atoms and half of
them have even parity: one clause with parity 0,
5!
2!·(5−2)! = 10 clauses with parity
2 and ﬁve clauses with parity 4. We leave it to the reader to show that this set of
clauses is logically equivalent to the formula:
(p ↔(q ↔(r ↔(s ↔t)))),
where we have used parentheses to bring out the structure of subformulas. Applying
the Tseitin encoding, we choose four new atoms a,b,c,d and obtain the set of
formulas:
{a ↔(s ↔t), b ↔(r ↔a), c ↔(q ↔b), d ↔(s ↔c)}.

92
4
Propositional Logic: Resolution
Each of the new formulas is logically equivalent to one in CNF that contains four
disjunctions of three literals each; for example:
a ↔(s ↔t) ≡{a ∨s ∨t, ¯a ∨¯s ∨t, ¯a ∨s ∨¯t, a ∨¯s ∨¯t}.
Sixteen clauses of ﬁve literals have been replaced by the same number of clauses
but each clause has only three literals.
4.6 Summary
Resolution is a highly efﬁcient refutation procedure that is a decision procedure for
unsatisﬁability in propositional logic. It works on formulas in clausal form, which
is a set representation of conjunctive normal form (a conjunction of disjunctions
of literals). Each resolution step takes two clauses that clash on a pair of comple-
mentary literals and produces a new clause called the resolvent. If the formula is
unsatisﬁable, the empty clause will eventually be produced.
4.7 Further Reading
Resolution for propositional logic is presented in the advanced textbooks by Nerode
and Shore (1997) and Fitting (1996).
4.8 Exercises
4.1 A formula is in disjunctive normal form (DNF) iff it is a disjunction of conjunc-
tions of literals. Show that every formula is equivalent to one in DNF.
4.2 A formula A is in complete DNF iff it is in DNF and each propositional letter
in A appears in a literal in each conjunction. For example, (p ∧q) ∨( ¯p ∧q) is in
complete DNF. Show that every formula is equivalent to one in complete DNF.
4.3 Simplify the following sets of literals, that is, for each set S ﬁnd a simpler set
S′, such that S′ is satisﬁable if and only if S is satisﬁable.
{p ¯q, q ¯r, rs, p¯s},
{pqr, ¯q, p¯rs, qs, p¯s},
{pqrs, ¯qrs, ¯prs, qs, ¯ps},
{ ¯pq, qrs, ¯p ¯qrs, ¯r, q}.
4.4 Given the set of clauses { ¯p ¯qr, pr, qr, ¯r} construct two refutations: one by
resolving the literals in the order {p,q,r} and the other in the order {r,q,p}.

References
93
4.5 Transform the set of formulas
{p, p →((q ∨r)∧¬ (q ∧r)), p →((s ∨t)∧¬ (s ∧t)), s →q, ¬r →t, t →s }
into clausal form and refute using resolution.
4.6 * The half-adder of Example 1.2 implements the pair of formulas:
s ↔¬ (b1 ∧b2) ∧(b1 ∨b2),
c ↔b1 ∧b2.
Transform the formulas to a set of clauses. Show that the addition of the unit clauses
{b1, b2, ¯s, ¯c} gives an unsatisﬁable set while the addition of {b1, b2, ¯s, c} gives a
satisﬁable set. Explain what this means in terms of the behavior of the circuit.
4.7 Prove that if the set of clauses labeling the leaves of a resolution tree is satisﬁ-
able then the clause at the root is satisﬁable (Theorem 4.21).
4.8 Construct a resolution refutation for the set of Tseitin clauses given in Exam-
ple 4.46.
4.9 * Construct the set of Tseitin clauses corresponding to a labeled complete graph
on ﬁve vertices and give a resolution refutation of the set.
4.10 * Construct the set of Tseitin clauses corresponding to a labeled complete
bipartite graph on three vertices on each side and give a resolution refutation of the
set.
4.11 * Show that if Π(vn) = bn, then vn satisﬁes all clauses in C(n) (the converse
direction of Lemma 4.47).
4.12 * Let {q1,...,qn} be literals on distinct atoms. Show that q1 ↔··· ↔qn is
satisﬁable iff {p ↔q1,...,p ↔qn} is satisﬁable, where p is a new atom. Construct
an efﬁcient decision procedure for formulas whose only operators are ¬, ↔and ⊕.
4.13 Prove Theorem 4.13 on the correctness of the CNF-to-3CNF algorithm.
4.14 Carry out the Tseitin encoding on the formula (a →(c ∧d)) ∨(b →(c ∧e)).
References
M. Fitting. First-Order Logic and Automated Theorem Proving (Second Edition). Springer, 1996.
A. Nerode and R.A. Shore. Logic for Applications (Second Edition). Springer, 1997.
G.S. Tseitin. On the complexity of derivation in propositional calculus. In A.O. Slisenko, edi-
tor, Structures in Constructive Mathematics and Mathematical Logic, Part II, pages 115–125.
Steklov Mathematical Institute, 1968.
A. Urquhart. Hard examples for resolution. Journal of the ACM, 34:209–219, 1987.


Chapter 5
Propositional Logic: Binary Decision Diagrams
The problem of deciding the satisﬁability of a formula in propositional logic has
turned out to have many important applications in computer science. This chapter
and the next one present two widely used approaches for computing with formulas
in propositional logic.
A binary decision diagram (BDD) is a data structure for representing the seman-
tics of a formula in propositional logic. A formula is represented by a directed graph
and an algorithm is used to reduce the graph. Reduced graphs have the property that
the graphs for logically equivalent formulas are identical. Clearly, this gives a deci-
sion procedure for logical equivalence: transform A1 and A2 into BDDs and check
that they are identical. A formula is valid iff its BDD is identical to the trivial BDD
for true and a formula is satisﬁable iff its BDD is not identical to the trivial BDD
for false.
Before deﬁning BDDs formally, the next section motivates the concept by reduc-
ing truth tables for formulas.
5.1 Motivation Through Truth Tables
Suppose that we want to decide if two formulas A1 and A2 in propositional logic
are logically equivalent. Let us construct systematic truth tables, where systematic
means that the assignments to the atomic propositions are arranged in some consis-
tent order, for example, in lexicographic order by placing T before F and varying
the values assigned to the atoms from the right to the left. Now, all we have to do
is to check if the truth tables for A1 and A2 are identical. Of course, this is very
inefﬁcient, because 2n rows are needed for each formula with n variables. Can we
do better?
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_5, © Springer-Verlag London 2012
95

96
5
Propositional Logic: Binary Decision Diagrams
Consider the following truth table for p ∨(q ∧r), where we have numbered the
rows for convenience in referring to them:
p
q
r
p ∨(q ∧r)
1
T
T
T
T
2
T
T
F
T
3
T
F
T
T
4
T
F
F
T
5
F
T
T
T
6
F
T
F
F
7
F
F
T
F
8
F
F
F
F
From rows 1 and 2, we see that when p and q are assigned T , the formula evaluates
to T regardless of the value of r, and similarly for rows 3 and 4. The ﬁrst four rows
can therefore be condensed into two rows:
p
q
r
p ∨(q ∧r)
1
T
T
∗
T
2
T
F
∗
T
where ∗indicates that the value assigned to r is immaterial. We now see that the
value assigned to q is immaterial, so these two rows collapse into one:
p
q
r
p ∨(q ∧r)
1
T
∗
∗
T
After similarly collapsing rows 7 and 8, the truth table has four rows:
p
q
r
p ∨(q ∧r)
1
T
∗
∗
T
2
F
T
T
T
3
F
T
F
F
4
F
F
∗
F

5.2
Deﬁnition of Binary Decision Diagrams
97
Let us try another example, this time for the formula p ⊕q ⊕r. It is easy to
compute the truth table for a formula whose only operator is ⊕, since a row evaluates
to T if and only if an odd number of atoms are assigned T :
p
q
r
p ⊕q ⊕r
1
T
T
T
T
2
T
T
F
F
3
T
F
T
F
4
T
F
F
T
5
F
T
T
F
6
F
T
F
T
7
F
F
T
T
8
F
F
F
F
Here, adjacent rows cannot be collapsed, but careful examination reveals that rows
5 and 6 show the same dependence on r as do rows 3 and 4. Rows 7 and 8 are
similarly related to rows 1 and 2. Instead of explicitly writing the truth table entries
for these rows, we can simply refer to the previous entries:
p
q
r
p ⊕q ⊕r
1
T
T
T
T
2
T
T
F
F
3
T
F
T
F
4
T
F
F
T
5, 6
F
T
∗
(See rows 3 and 4.)
7, 8
F
F
∗
(See rows 1 and 2.)
The size of the table has been reduced by removing repetitions of computations of
truth values.
5.2 Deﬁnition of Binary Decision Diagrams
A binary decision diagram, like a truth table, is a representation of the value of a
formula under all possible interpretations. Each node of the tree is labeled with an
atom, and solid and dotted edges leaving the node represent the assignment of T
and F , respectively, to this atom. Along each branch, there is an edge for every
atom in the formula, so there is a one-to-one correspondence between branches and
interpretations. The leaf of a branch is labeled with the value of the formula under
its interpretation.

98
5
Propositional Logic: Binary Decision Diagrams
Fig. 5.1 A binary decision diagram for p ∨(q ∧r)
Deﬁnition 5.1 A binary decision diagram (BDD) for a formula A in propositional
logic is a directed acyclic graph. Each leaf is labeled with a truth value T or F .
Each interior node is labeled with an atom and has two outgoing edges: one, the
false edge, is denoted by a dotted line, while the other, the true edge, is denoted by
a solid line. No atom appears more than once in a branch from the root to an edge.
A full or partial interpretation Ib for A is associated with each branch b from
the root to a leaf. Ib(p) = T if the true edge was taken at the node labeled p and
Ib(p) = F if the false edge was taken at the node labeled p.
Given a branch b and its associated interpretation Ib, the leaf is labeled with
vIb(A), the truth value of the formula under Ib. If the interpretation is partial, it
must assign to enough atoms so that the truth value is deﬁned.
Example 5.2 Figure 5.1 is a BDD for A = p ∨(q ∧r). The interpretation associated
with the branch that goes left, right, left is
I (p) = F,
I (q) = T,
I (r) = F.
The leaf is labeled F so we can conclude that for this interpretation, vI (A) = F .
Check that the value of the formula for the interpretation associated with each
branch is the same as that given in the ﬁrst truth table on page 96.
The BDD in the ﬁgure is a special case, where the directed acyclic graph is a tree
and a full interpretation is associated with each branch.
5.3 Reduced Binary Decision Diagrams
We can modify the structure of a tree such as the one in Fig. 5.1 to obtain a more
concise representation without losing the ability to evaluate the formula under all
interpretations. The modiﬁcations are called reductions and they transform the tree
into a directed acyclic graph, where the direction of an edge is implicitly from a
node to its child. When no more reductions can be done, the BDD is reduced.

5.3
Reduced Binary Decision Diagrams
99
Algorithm 5.3 (Reduce)
Input: A binary decision diagram bdd.
Output: A reduced binary decision diagram bdd ′.
• If bdd has more than two distinct leaves (one labeled T and one labeled F ),
remove duplicate leaves. Direct all edges that pointed to leaves to the remaining
two leaves.
• Perform the following steps as long as possible:
1. If both outgoing edges of a node labeled pi point to the same node labeled pj,
delete this node for pi and direct pi’s incoming edges to pj.
2. If two nodes labeled pi are the roots of identical sub-BDDs, delete one sub-
BDD and direct its incoming edges to the other node.
Deﬁnition 5.4 A BDD that results from applying the algorithm Reduce is a reduced
binary decision diagram.
See Bryant (1986) or Baier and Katoen (2008, Sect. 6.7.3) for a proof of the
following theorem:
Theorem 5.5 The reduced BDD bdd ′ returned by the algorithm Reduce is logically
equivalent to the input BDD bdd.
Let us apply the algorithm Reduce to the two formulas used as motivating ex-
amples in Sect. 5.1.
Example 5.6 Figure 5.1 shows a non-reduced BDD for A = p ∨(q ∧r).
First, merge all leaves into just two, one for T and one for F :
Now we apply Step (1) of the algorithm repeatedly in order to remove nodes that
are not needed to evaluate the formula. Once on the left-hand side of the diagram
and twice on the right-hand side, the node for r has both outgoing edges leading
to the same node. This means that the partial assignment to p and q is sufﬁcient to
determine the value of the formula. The three nodes labeled r and their outgoing
edges can be deleted and the incoming edges to the r nodes are directed to the joint
target nodes:

100
5
Propositional Logic: Binary Decision Diagrams
Step (1) can now be applied again to delete the right-hand node for q:
Since neither Step (1) nor Step (2) can be applied, the BDD is reduced.
There are four branches in the reduced BDD for p ∨(q ∧r). The interpretations
associated with the branches are (from left to right):
Ib1(p) = F,
Ib1(q) = F,
Ib2(p) = F,
Ib2(q) = T,
Ib2(r) = F,
Ib3(p) = F,
Ib3(q) = T,
Ib3(r) = T,
Ib4(p) = T.
The interpretations Ib1 and Ib4 are partial interpretations, but they assign truth
values to enough atoms for the truth values of the formula to be computed.

5.3
Reduced Binary Decision Diagrams
101
Example 5.7 Consider now the formula A′ = p ⊕q ⊕r. We start with a tree that
deﬁnes full interpretations for the formula and delete duplicate leaves. Here is the
BDD that results:
The reduction of Step (1) is not applicable, but examination of the BDD reveals
that the subgraphs rooted at the left and right outermost nodes for r have the same
structure: their F and T edges point to the same subgraphs, in this case the leaves
F and T , respectively. Applying Step (2), the T edge from the rightmost node
for q can be directed to the leftmost node for r:
Similarly, the two innermost nodes for r are the roots of identical subgraphs and
the F from the rightmost node for q can be directed to the second r node from the
left:

102
5
Propositional Logic: Binary Decision Diagrams
Neither Step (1) nor Step (2) can be applied so the BDD is reduced. By rearrang-
ing the nodes, the following symmetric representation of the BDD is obtained:
Check that the truth values of A′ under the interpretations associated with each
branch correspond to those in the reduced truth table on page 97.
5.4 Ordered Binary Decision Diagrams
The deﬁnition of BDDs did not place any requirements on the order in which atoms
appear on a branch from the root to the leaves. Since branches can represent partial
interpretations, the set of atoms appearing on one branch can be different from the
set on another branch. Algorithms on BDDs require that the different orderings do
not contradict each other.
Deﬁnition 5.8 Let O = {O1
A,...,On
A}, where for each i, Oi
A is a sequence of the
elements of PA (the set of atoms in A) deﬁned by <i
PA, a total relation that orders
PA. O is a compatible set of orderings for PA iff for all i ̸= j, there are no atoms
p,p′ such that p <i
PA p′ in Oi
A while p′ <j
PA p in Oj
A.
Example 5.9 Here is a BDD that is the same as the one in Fig. 5.1, except that the
orderings are not compatible because q appears before r on the left branches, while
r appears before q on the right branches:

5.4
Ordered Binary Decision Diagrams
103
Example 5.10 Consider again the reduced BDD for p ∨(q ∧r):
The four branches deﬁne three distinct orderings of the atoms:
{(p,q), (p,q,r), (p)},
but the orderings are compatible.
Deﬁnition 5.11 An ordered binary decision diagram (OBDD) is a BDD such that
the set of orderings of atoms deﬁned by the branches is compatible.
The proofs of the following theorems can be found in Bryant (1986).
Theorem 5.12 The algorithm Reduce constructs an OBDD if the original BDD is
ordered. For a given ordering of atoms, the reduced OBDDs for logically equivalent
formulas are structurally identical.
The theorem means that a reduced, ordered BDD is a canonical representation
of a formula. It immediately provides a set of algorithms for deciding properties of
formulas. Let A and B be formulas in propositional logic; construct reduced OBDDs
for both formulas using a compatible ordering of {PA,PB}. Then:
• A is satisﬁable iff T appears in its reduced OBDD.
• A is falsiﬁable iff F appears in its reduced OBDD.
• A is valid iff its reduced OBDD is the single node T .
• A is unsatisﬁable iff its reduced OBDD is the single node F .
• If the reduced OBDDs for A and B are identical, then A ≡B.
The usefulness of OBDDs depends of course on the efﬁciency of the algorithm
Reduce (and others that we will describe), which in turn depends on the size of
reduced OBDDs. In many cases the size is quite small, but, unfortunately, the size
of the reduced OBDD for a formula depends on the ordering and the difference in
sizes among different orderings can be substantial.

104
5
Propositional Logic: Binary Decision Diagrams
Theorem 5.13 The OBDD for the formula:
(p1 ∧p2) ∨··· ∨(p2n−1 ∧p2n)
has 2n + 2 nodes under the ordering p1,...,p2n, and 2n+1 nodes under the order-
ing p1,pn+1,p2,pn+2,...,pn,p2n.
Fortunately, you can generally use heuristics to choose an efﬁcient ordering, but
there are formulas that have large reduced OBDDs under any ordering.
Theorem 5.14 There is a formula A with n atoms such that the reduced OBDD for
any ordering of the atoms has at least 2cn nodes for some c > 0.
5.5 Applying Operators to BDDs
It hardly seems worthwhile to create a BDD if we start from the full binary tree
whose size is about the same as the size of the truth table. The power of BDDs
comes from the ability to perform operations directly on two reduced BDDs. The
algorithm Apply recursively constructs the BDD for A1 opA2 from the reduced
BDDs for A1 and A2. It can also be used to construct an initial BDD for an arbitrary
formula by building it up from the BDDs for atoms.
The algorithm Apply works only on ordered BDDs.
Algorithm 5.15 (Apply)
Input: OBDDs bdd1 for formula A1 and bdd2 for formula A2, using a compatible
ordering of {PA1,PA2}; an operator op.
Output: An OBDD for the formula A1 op A2.
• If bdd1 and bdd2 are both leaves labeled w1 and w2, respectively, return the leaf
labeled by w1 op w2.
• If the roots of bdd1 and bdd2 are labeled by the same atom p, return the following
BDD: (a) the root is labeled by p; (b) the left sub-BDD is obtained by recursively
performing this algorithm on the left sub-BDDs of bdd1 and bdd2; (c) the right
sub-BDD is obtained by recursively performing this algorithm on the right sub-
BDDs of bdd1 and bdd2.
• If the root of bdd1 is labeled p1 and the root of bdd2 is labeled p2 such that
p1 < p2 in the ordering, return the following BDD: (a) the root is labeled by p1;
(b) the left sub-BDD is obtained by recursively performing this algorithm on the
left sub-BDD of bdd1 and on (the entire BDD) bdd2; (c) the right sub-BDD is
obtained by recursively performing this algorithm on the right sub-BDD of bdd1
and on (the entire BDD) bdd2.
This construction is also performed if bdd2 is a leaf, but bdd1 is not.
• Otherwise, we have a symmetrical case to the previous one. The BDD returned
has its root labeled by p2 and its left (respectively, right) sub-BDD obtained by
recursively performing this algorithm on bdd1 and on the left (respectively, right)
sub-BDD of bdd2.

5.5
Applying Operators to BDDs
105
We now work out a complete example of the application of the Apply algorithm.
It is quite lengthy, but each step in the recursive algorithm should not be difﬁcult to
follow.
Example 5.16 We construct the BDD for the formula (p ⊕q) ⊕(p ⊕r) from the
BDDs for p ⊕q and p ⊕r. In the following diagram, we have drawn the two BDDs
with the operator ⊕between them:
The sub-BDDs will be BDDs for the four subformulas obtained by substituting T
and F for p. Notations such as F ⊕r will be used to denote the formula obtained
by partially evaluating a formula, in this case, partially evaluating p ⊕r under an
interpretation such that I (p) = F .
Since there is only one atom in each sub-BDD, we know what the labels of their
roots are:
Let us now take the right-hand branch in both BDDs that represent assigning
T to p. Evaluating the partial assignment gives T ⊕q ≡¬q and T ⊕r ≡¬r. To
obtain the right-hand sub-BDD of the result, we have to compute ¬q ⊕¬r:

106
5
Propositional Logic: Binary Decision Diagrams
The recursion can be continued by taking the right-hand branch of the BDD for
¬q and assigning F to q. Since the BDD for ¬r does not depend on the assignment
to q, it does not split into two recursive subcases. Instead, the algorithm must be ap-
plied for each sub-BDD of ¬q together with the entire BDD for ¬r. The following
diagram shows the computation that is done when the right-hand branch of the BDD
for ¬q is taken:
Recursing now on the BDD for ¬r also gives base cases, one for the left-hand (true)
branch:
and one for the right-hand (false) branch:
When returning from the recursion, these two results are combined:
Similarly, taking the left-hand branch of the BDD for ¬q gives:

5.6
Restriction and Quantiﬁcation *
107
Fig. 5.2 BDD after the Apply and Reduce algorithms terminate
Returning from the recursion to the BDD for ¬q gives:
The BDD obtained upon termination of the algorithm is shown in Fig. 5.2 and
to its right is the BDD that results from reducing the BDD. Check that this is the
reduced BDD for q ⊕r:
(p ⊕q) ⊕(p ⊕r) ≡(p ⊕p) ⊕(q ⊕r) ≡false ⊕(q ⊕r) ≡q ⊕r.
5.6 Restriction and Quantiﬁcation *
This section presents additional important algorithms on BDDs.
5.6.1 Restriction
Deﬁnition 5.17 The restriction operation takes a formula A, an atom p and a truth
value w = T or w = F . It returns the formula obtained by substituting w for p and
partially evaluating A. Notation: A|p=w.

108
5
Propositional Logic: Binary Decision Diagrams
Example 5.18 Let A = p ∨(q ∧r); its restrictions are:
A|r=T ≡p ∨(q ∧T ) ≡p ∨q,
A|r=F ≡p ∨(q ∧F) ≡p ∨F ≡p.
The correctness of the algorithm Reduce is based upon the following theorem
which expresses the application of an operator in terms of its application to restric-
tions. We leave its proof as an exercise.
Theorem 5.19 (Shannon expansion)
A1 op A2 ≡(p ∧(A1|p=T op A2|p=T )) ∨(¬p ∧(A1|p=F op A2|p=F )).
Restriction is very easy to implement on OBDDs.
Algorithm 5.20 (Restrict)
Input: An OBDD bdd for a formula A; a truth value w.
Output: An OBDD for A|p=w.
Perform a recursive traversal of the OBDD:
• If the root of bdd is a leaf, return the leaf.
• If the root of bdd is labeled p, return the sub-BDD reached by its true edge if
w = T and the sub-BDD reached by its false edge if w = F .
• Otherwise (the root is labeled p′ for some atom which is not p), apply the algo-
rithm to the left and right sub-BDDs, and return the BDD whose root is p′ and
whose left and right sub-BDDs are those returned by the recursive calls.
The BDD that results from Restrict may not be reduced, so the Reduce algo-
rithm is normally applied immediately afterwards.
Example 5.21 The OBDD of A = p ∨(q ∧r) is shown in (a) below. (b) is A|r=T ,
(c) is A|r=F and (d) is (c) after reduction.
Compare the OBDDs in (b) and (d) with the formulas in Example 5.18.

5.7
Summary
109
5.6.2 Quantiﬁcation
Deﬁnition 5.22 Let A be a formula and p an atom. The existential quantiﬁcation of
A is the formula denoted ∃pA and the universal quantiﬁcation of A is the formula
denoted ∀pA. ∃pA is true iff A is true for some assignment to p, while ∀pA is true
iff for all assignments to p, A is true.
These formulas are in an extension of propositional logic called quantiﬁed propo-
sitional logic. The proof of the following theorem is left as an exercise.
Theorem 5.23
∃pA ≡A|p=F ∨A|p=T ,
∀pA ≡A|p=F ∧A|p=T .
Quantiﬁcation is easily computed using OBDDs:
∃pA
is
Apply(Restrict(A,p,F),or,Restrict(A,p,T )),
∀pA
is
Apply(Restrict(A,p,F),and,Restrict(A,p,T )).
Example 5.24 For the formulas A = p ∨(q ∧r), we can use A|r=F ≡p and
A|r=T ≡p ∨q from Example 5.18 to compute its quantiﬁcations on r:
∃r (p ∨(q ∧r)) ≡p ∨(p ∨q) ≡p ∨q,
∀r (p ∨(q ∧r)) ≡p ∧(p ∨q) ≡p.
We leave it as an exercise to perform these computations using OBDDs.
5.7 Summary
Binary decision diagrams are a data structure for representing formulas in propo-
sitional logic. A BDD is a directed graph that reduces redundancy when compared
with a truth table or a semantic tree. Normally, one ensures that all branches of a
BDD use compatible orderings of the atomic propositions. An OBDD can be re-
duced and reduced OBDDs of two formulas are structurally identical if and only
if the formulas are logically equivalent. A recursive algorithm can be used to efﬁ-
ciently compute A op B given the OBDDs for A and B. BDDs have been widely
used in model checkers for the veriﬁcation of computer hardware.

110
5
Propositional Logic: Binary Decision Diagrams
5.8 Further Reading
Bryant’s original papers on BDDs (Bryant, 1986, 1992) are relatively easy to read.
There is an extensive presentation of BDDs in Baier and Katoen (2008, Sect. 6.7).
5.9 Exercises
5.1 Construct reduced OBDDs for p ↑(q ↑r) and (p ↑q) ↑r. What does this
show?
5.2 Construct reduced OBDDs for the formula (p1 ∧p2) ∨(p3 ∧p4) using two
orderings of the variables: p1, p2, p3, p4 and p1, p3, p2, p4.
5.3 How can OBDDs be used to check if A |= B?
5.4 Compute the Shannon expansion of (p →(q →r)) →((p →q) →(p →r))
with respect to each one of its atomic propositions. Why do you know the answer
even before you start the computation?
5.5 Prove the Shannon expansion (Theorem 5.19) and the formula for propositional
quantiﬁcation (Theorem 5.23).
5.6 Prove that ∃r (p ∨(q ∧r)) = p ∨q and ∀r (p ∨(q ∧r)) = p using BDDs
(Example 5.24).
References
C. Baier and J.-P. Katoen. Principles of Model Checking. MIT Press, 2008.
R.E. Bryant. Graph-based algorithms for Boolean function manipulation. IEEE Transactions on
Computers, C-35:677–691, 1986.
R.E. Bryant. Symbolic Boolean manipulation with ordered binary-decision diagrams. ACM Com-
puting Surveys, 24:293–318, 1992.

Chapter 6
Propositional Logic: SAT Solvers
Although it is believed that there is no efﬁcient algorithm for the decidability of
satisﬁability in propositional logic, many algorithms are efﬁcient in practice. This is
particularly true when a formula is satisﬁable; for example, when you build a truth
table for an unsatisﬁable formula of size n you will have to generate all 2n rows, but
if the formula is satisﬁable you might get lucky and ﬁnd a model after generating
only a few rows. Even an incomplete algorithm—one that can ﬁnd a model if one
exists but may not be able to detect if a formula is unsatisﬁable—can be useful in
practice.
A computer program that searches for a model for a propositional formula is
called a SAT Solver. This is a highly developed area of research in computer science
because many problems in computer science can be encoded in propositional logic
so that a model for a formula is a solution to the problem.
We begin the chapter by proving properties of formulas in clausal form. These
properties are the basis of classical algorithms for satisﬁability by Davis and Putnam
(DP), and Davis, Logemann and Loveland (DLL), which we present next. The joint
contribution of these two papers is usually recognized by the use of the acronym
DPLL. Then we give an overview of two of the main approaches used in modern
SAT solvers that are based upon modiﬁcations of the DPLL algorithm. In one ap-
proach, algorithms and heuristics are used to guide the search for a model; the other
approach uses random search.
6.1 Properties of Clausal Form
This section collects several theorems that describe transformations on sets of
clauses that do not affect its satisﬁability. These theorems are important because
they justify the algorithms presented in the next section.
Deﬁnition 6.1 Let S, S′ be sets of clauses. S ≈S′ denotes that S is satisﬁable if and
only if S′ is satisﬁable.
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_6, © Springer-Verlag London 2012
111

112
6
Propositional Logic: SAT Solvers
It is important to understand that S ≈S′ (S is satisﬁable if and only if S′ is
satisﬁable) does not imply that S ≡S′ (S is logically equivalent to S′).
Example 6.2 Consider the two sets of clauses:
S = {pq ¯r,p ¯q, ¯pq},
S′ = {p ¯q, ¯pq}.
S is satisﬁed by the interpretation:
I (p) = F,
I (q) = F,
I (r) = F,
while S′ is satisﬁed by the interpretation:
I ′(p) = F,
I ′(q) = F.
Therefore, S ≈S′. However, under the interpretation:
I ′′(p) = F,
I ′′(q) = F,
I ′′(r) = T,
vI ′′(S) = F (since vI ′′(pq ¯r) = F ) but vI ′′(S′) = T , so S ̸≡S′.
Pure Literals
Deﬁnition 6.3 Let S be a set of clauses. A pure literal in S is a literal l that appears
in at least one clause of S, but its complement lc does not appear in any clause of
S.
Theorem 6.4 Let S be a set of clauses and let l be a pure literal in S. Let S′ be
obtained from S by deleting every clause containing l. Then S ≈S′.
Proof If S′ is satisﬁable, there is a model I ′ for S′ such that vI ′(C′) = T for
every C′ ∈S′. Extend I ′ to a new interpretation I by deﬁning I (l) = T and
I (p) = I ′(p) for all other atoms.
Let us show that I is a model for S by showing that vI (C) = T for every
C ∈S. If C ∈S′, vI (C) = vI ′(C) since I (p) = I ′(p) for all atoms p in C. If
C ∈S −S′, vI (C) = T since l ∈C and I (l) = T .
Conversely, if S is satisﬁable, S′ is obviously satisﬁable since S′ ⊂S.
Example 6.5 For the sets of clauses in Example 6.2, S′ was obtained from S by
deleting the clause pq ¯r containing ¯r since ¯rc = r does not appear in S. The inter-
pretation I was obtained by extending the interpretation I ′ by I (¯r) = T so that
vI (pq ¯r) = T .

6.1
Properties of Clausal Form
113
Unit Clauses
Theorem 6.6 Let {l} ∈S be a unit clause and let S′ be obtained from S by deleting
every clause containing l and by deleting lc from every (remaining) clause. Then
S ≈S′.
Proof Let I be a model for S and let I ′ be the interpretation deﬁned by I ′(p) =
I (p) for all atoms p ∈PS′. I ′ is the same as I except no assignment is made
to the atom for l which does not occur in S′. Since {l} is a unit clause, for I be a
model for S it must be true that I (l) = T and therefore I (lc) = F .
Let C′ be an arbitrary clause in S′. We must show that vI ′(C) = T . There are
two cases:
• C′ is also a member of S. C is not the unit clause {l} (which was deleted); there-
fore, I and I ′ coincide on the literals of C′, so vI ′(C′) = vI (C) = T .
• C′ = C −{lc} for some C ∈S. By the ﬁrst paragraph of the proof, I (lc) = F ,
so vI (C) = T holds only if I (l′′) = T for some other literal l′′ ∈C. But l′′ ∈C′
which implies vI ′(C′) = vI (C) = T .
The proof of the converse is similar to the proof of Theorem 6.4.
Example 6.7 Let:
S = {r,pq ¯r,p ¯q, ¯qp},
S′ = {pq,p ¯q, ¯qp}.
S′ was obtained by deleting the unit clause {r} from S and the literal ¯r from the
second clause of S. Since I (r) = T in any model I for S, vI (pq ¯r) = T can hold
only if either I (p) = T or I (q) = T from which we have vI ′(pq) = T .
Here is a proof of the unsatisﬁability of the empty clause 2 that does not use
reasoning about vacuous sets.
Corollary 6.8 2 is unsatisﬁable.
Proof {{p},{ ¯p}} is the clausal form of the unsatisﬁable formula p ∧¬p. Delete
the ﬁrst clause {p} from the formula and the literal ¯p from the second clause;
the result is {{}} = {2}. By Theorem 6.6, {2} ≈{{p},{ ¯p}} and therefore 2 is
unsatisﬁable.
Subsumption
Deﬁnition 6.9 Let C1 ⊆C2 be two clauses. The clause C1 subsumes the clause C2
and C2 is subsumed by C1.

114
6
Propositional Logic: SAT Solvers
Theorem 6.10 Let C1,C2 ∈S be clauses such that C1 subsumes C2, and let S′ =
S −{C2}. Then S ≈S′.
Proof Trivially, if S is satisﬁable, so is S′ since it is a subset of S.
Conversely, let I ′ be an interpretation for S′. If C2 contains atoms not in
S′, we might have to extend I ′ to an interpretation I of S, but C1 ⊆C2, so
vI ′(C1) = vI (C1) = T implies vI (C2) = T since a clause is an implicit disjunc-
tion. Therefore, I is a model for S.
The concept of subsumption is somewhat confusing because the smaller clause
subsumes (is stronger than) the larger clause. From the proof of the theorem, how-
ever, it is easy to see that if C1 subsumes C2 then C1 →C2.
Example 6.11 Let:
S = {pr, ¯pq ¯r,q ¯r},
S′ = {pr,q ¯r},
where {q ¯r}, the third clause of S, subsumes { ¯pq ¯r}, the second clause of S. Any
interpretation which satisﬁes {q ¯r} can be extended to an interpretation that satisﬁes
{ ¯pq ¯r} because it doesn’t matter what is assigned to p.
Renaming
Deﬁnition 6.12 Let S be a set of clauses and U a set of atomic propositions. RU(S),
the renaming of S by U, is obtained from S by replacing each literal l on an atomic
proposition in U by lc.
Theorem 6.13 S ≈RU(S).
Proof Let I be a model for S. Deﬁne an interpretation I ′ for RU(S) by:
I ′(p) = I ( ¯p),
if p ∈U,
I ′(p) = I (p),
if p ̸∈U.
Let C ∈S and C′ = RU({C}). Since I is a model for S, vI (C) = T and I (l) = T
for some l ∈C. If the atom p of l is not in U then l ∈C′ so I ′(l) = I (l) = T and
vI ′(C′) = T . If p ∈U then lc ∈C′ so I ′(lc) = I (l) = T and vI ′(C′) = T .
The converse is similar.
Example 6.14 The set of clauses:
S = {pqr, ¯pq, ¯q ¯r,r}
is satisﬁed by the interpretation:
vI (p) = F,
vI (q) = F,
vI (r) = T.

6.2
Davis-Putnam Algorithm
115
The renaming:
R{p,q}(S) = { ¯p ¯qr,p ¯q,q ¯r,r}
is satisﬁed by:
vI ′(p) = T,
vI ′(q) = T,
vI ′(r) = T.
6.2 Davis-Putnam Algorithm
The Davis-Putnam (DP) algorithm was one of the ﬁrst algorithms proposed for de-
ciding satisﬁability. It uses two rules based upon the concepts introduced in the
previous section, as well as the resolution rule (Chap. 4).
Algorithm 6.15 (Davis-Putnam algorithm)
Input: A formula A in clausal form.
Output: Report that A is satisﬁable or unsatisﬁable.
Perform the following rules repeatedly, but the third rule is used only if the ﬁrst
two do not apply:
• Unit-literal rule: If there is a unit clause {l}, delete all clauses containing l and
delete all occurrences of lc from all other clauses.
• Pure-literal rule: If there is a pure literal l, delete all clauses containing l.
• Eliminate a variable by resolution: Choose an atom p and perform all possible
resolutions on clauses that clash on p and ¯p. Add these resolvents to the set of
clauses and then delete all clauses containing p or ¯p.
Terminate the algorithm under the following conditions:
• If empty clause 2 is produced, report that the formula is unsatisﬁable.
• If no more rules are applicable, report that the formula is satisﬁable.
Clearly, the algorithm terminates because the number of atoms in a formula is
ﬁnite, as is the number of possible clauses that can be produced by resolution. The
soundness of the three rules is justiﬁed by Theorem 6.6, Theorem 6.4 and Theo-
rem 4.17, respectively.
Example 6.16 Consider the set of clauses:
{p, ¯pq, ¯qr, ¯rst}.
Performing the unit-literal rule on p leads to the creation of a new unit clause q
upon which the rule can be applied again. This leads to a new unit clause r and
applying the rule results in the singleton set of clauses {st}. Since no more rules are
applicable, the set of clauses is satisﬁable.
Deﬁnition 6.17 Repeatedly applying the unit-literal rule until it is no longer appli-
cable is called unit propagation or Boolean constraint propagation.

116
6
Propositional Logic: SAT Solvers
6.3 DPLL Algorithm
Creating all possible resolvents on an atom is very inefﬁcient. The DPLL algorithm
improves on the DP algorithm by replacing the variable elimination step with a
search for a model of the formula.
Deﬁnition 6.18 Let A be a set of clauses and let I be a partial interpretation (Deﬁ-
nition 2.18) for A. For C ∈A, if vI (C) = T , the interpretation I satisﬁes C, while
if vI (C) = F , then C is a conﬂict clause for I .
Example 6.19 Let A = {pqr, ¯pq, ¯q ¯r,r} and let I¯qr be the partial interpretation
deﬁned by:
I¯qr(q) = F,
I¯qr(r) = T.
I¯qr satisﬁes all the clauses except for ¯pq, which cannot be satisﬁed or falsiﬁed
without also assigning a truth value to p.
The fourth clause r is a conﬂict clause for the partial interpretation Ir deﬁned
by Ir(r) = F . Clearly, no interpretation that is an extension of this partial interpre-
tation can satisfy A.
The DPLL algorithm recursively extends a partial interpretation by adding an
assignment to some atom that has not yet been assigned a truth value. The current
set of clauses is evaluated using the new partial interpretation and simpliﬁed by
unit propagation. If the set of clauses contains a conﬂict clause, there is no need to
continue extending this partial interpretation and the search backtracks to try another
one.
Algorithm 6.20 (DPLL algorithm)
Input: A formula A in clausal form.
Output: Report that A is unsatisﬁable or report that A is satisﬁable and return a
partial interpretation that satisﬁes A.
The algorithm is expressed as the recursive function DPLL(B,I ) which takes
two parameters: a formula B in clausal form and a partial interpretation I . It is
initially called with the formula A and the empty partial interpretation.
DPLL(B,I )
• Construct the set of clauses B′ by performing unit propagation on B. Construct
I ′ by adding to I all the assignments made during propagation.
• Evaluate B′ under the partial interpretation I ′:
– If B′ contains a conﬂict clause return ‘unsatisﬁable’;
– If B′ is satisﬁed return I ′;
– (otherwise, continue).
• Choose an atom p in B′; choose a truth value val as T or F; I1 is the interpreta-
tion I ′ together with the assignment of val to p.

6.4
An Extended Example of the DPLL Algorithm
117
• result ←DPLL(B′,I1).
– If result is not ‘unsatisﬁable’ return result;
– (otherwise, continue).
• I2 is the interpretation I ′ together with the assignment of the complement of
val to p.
• result ←DPLL(B′,I2).
– Return result.
The DPLL algorithm is highly nondeterministic: it must choose an unassigned
atom and then choose which truth value will be assigned to it ﬁrst.
6.4 An Extended Example of the DPLL Algorithm
We now give an extended example of the DPLL algorithm by solving the 4-queens
problem, a smaller instance of the 8-queens problem. Given a 4 × 4 chess board,
place four queens so that no one can capture any of the others. Here is a solution:
6.4.1 Encoding the Problem in Propositional Logic
First, we have to encode this problem as a formula in propositional logic. It should
not be too surprising that any ﬁnite computational problem can be encoded by binary
numbers, which in turn can be represented by truth values. Here we take a more
direct approach to the encoding. Suppose that we want to encode the fact that a
variable can take one of the values 1, 2, 3. Let us use three atoms p1, p2, p3; the
intended meaning is that pi is true if the variable has the value i. The formula:
p1 ∨p2 ∨p3,
states that the variable must have at least one of these values, while the following
formula in CNF states that the variable can have at most one of the values:
(p1 ∨p2) ∧(p1 ∨p3) ∧(p2 ∨p3).

118
6
Propositional Logic: SAT Solvers
For example, if p1 is assigned T , then p1 is false, so both p2 and p3 must be true,
that is, p2 and p3 must be false for the formula to encode that the variable has the
value 1. The conjunction of p1 ∨p2 ∨p3 with this formula states that the variable
must have exactly one of the values.
In the 4-queens problem, we need 16 atoms: pij, 1 ≤i ≤4, 1 ≤i ≤4, where pij
is true iff a queen is placed on the square at row i and column j. To simplify notation,
instead of p11,p12,...,p43,p44, we will use the subscripts 11,12,...,43,44 alone
to denote each atom.
The clauses that claim that there is at least one queen in each row are:
11 ∨12 ∨13 ∨14,
21 ∨22 ∨23 ∨24,
31 ∨32 ∨33 ∨34,
41 ∨42 ∨43 ∨44.
But no more than one queen may be placed in each row:
11 ∨12, 11 ∨13, 11 ∨14, 12 ∨13, 12 ∨14, 13 ∨14,
21 ∨22, 21 ∨23, 21 ∨24, 22 ∨23, 22 ∨24, 23 ∨24,
31 ∨32, 31 ∨33, 31 ∨34, 32 ∨33, 32 ∨34, 33 ∨34,
41 ∨42, 41 ∨43, 41 ∨44, 42 ∨43, 42 ∨44, 43 ∨44,
and no more than one queen in each column:
11 ∨21, 11 ∨31, 11 ∨41, 21 ∨31, 21 ∨41, 31 ∨41,
12 ∨22, 12 ∨32, 12 ∨42, 22 ∨32, 22 ∨42, 32 ∨42,
13 ∨23, 13 ∨33, 13 ∨43, 23 ∨33, 23 ∨43, 33 ∨43,
14 ∨24, 14 ∨34, 14 ∨44, 24 ∨34, 24 ∨44, 34 ∨44.
We also have to ensure that no more than one queen is placed in each diagonal. To do
this systematically, we check each square (i,j), starting at the top left and enumerate
the squares that are diagonally below it, which are (i −1,j + 1), (i + 1,j + 1),
(i −2,j + 2), (i + 2,j + 2), as long as both numbers are within the range from
1 to 4. By commutativity, 12 ∨21 ≡21 ∨12, we do not have to check the squares
above. Here are the clauses:
11 ∨22, 11 ∨33, 11 ∨44,
12 ∨21, 12 ∨23, 12 ∨34,
13 ∨22, 13 ∨31, 13 ∨24,
14 ∨23, 14 ∨32, 14 ∨41,
21 ∨32, 21 ∨43,
22 ∨31, 22 ∨33, 22 ∨44,
23 ∨32, 23 ∨41, 23 ∨34,
24 ∨33, 24 ∨42,
31 ∨42,
32 ∨41, 32 ∨43,
33 ∨42, 33 ∨44,
34 ∨43.

6.4
An Extended Example of the DPLL Algorithm
119
Check this by drawing a 4 × 4 chess board on a piece of paper and tracing each of
the diagonals.
The total number of clauses is:
4
+
(4 × 6)
+
(4 × 6)
+
(3 + 3 + 3 + 3 + 2 + 3 + 3 + 2 + 1 + 2 + 2 + 1) =
4 + 24 + 24 + 28
= 80.
The 4-queens problem has a solution if and only if this 80-clause formula is
satisﬁable. If an algorithm not only decides that the formula is satisﬁable, but also
returns a model, the atoms assigned T in the model will tell us where to place the
queens.
6.4.2 Solving the Problem with the DP Algorithm?
Let us try to use the DP algorithm to solve the 4-queens problem. There are no
unit clauses, so we much choose an atom to eliminate. In the absence of any other
information, let us start with the ﬁrst atom 11. The atom appears as a positive literal
only in the ﬁrst clause 11 ∨12 ∨13 ∨14, so that clause must participate in the
resolution rule. Negative literals appear in all three sets that exclude two queens in
a row, column or diagonal. However, the row exclusion clauses 11 ∨12, 11 ∨13,
11 ∨14, cannot be resolved with 11 ∨12 ∨13 ∨14 because they clash on more
than one literal, so resolving them would result in trivial clauses (Lemma 4.16).
This leaves six clashing clauses—three for column exclusion and three for diagonal
exclusion—and the resolvents are:
21 ∨12 ∨13 ∨14, 31 ∨12 ∨13 ∨14, 41 ∨12 ∨13 ∨14,
22 ∨12 ∨13 ∨14, 33 ∨12 ∨13 ∨14, 44 ∨12 ∨13 ∨14,
The ten original clauses with 11 or 11 are now removed from the set. We don’t seem
to be making much progress, so let us turn to the DPLL algorithm.
6.4.3 Solving the Problem with the DPLL Algorithm
In this section we will carry out the DPLL algorithm in a purely formal manner as
a computer would. We suggest, however, that you ‘cheat’ by referring to the 4 × 4
chessboard, which will clarify what happens at each step.

120
6
Propositional Logic: SAT Solvers
We start by assigning T to 11 (and F to 11). The clause 11 ∨12 ∨13 ∨14
becomes true and can be deleted, while 11 can be deleted from all other clauses.
This results in nine new (unit) clauses:
12, 13, 14, 21, 31, 41, 22, 33, 44.
The next step is to carry out unit propagation for each of these literals. Negated
atoms like 12 are assigned T so they are erased from clauses with positive literals
and all clauses contain the negated atoms are deleted:
≥one / row
23 ∨24, 32 ∨34, 42 ∨43,
≤one / row
23 ∨24, 32 ∨34, 42 ∨43,
≤one / column
32 ∨42, 23 ∨43, 24 ∨34,
≤one / diagonal
24 ∨42, 23 ∨32, 23 ∨34, 32 ∨43, 34 ∨43.
By choosing the value of only one literal and propagating units, 80 clauses have
been reduced to only 14 clauses!
Let us now assign T to 23 (and F to 23); this creates four new unit clauses:
24, 43, 32, 34
and the other clauses are:
32 ∨34, 42 ∨43,
32 ∨34, 42 ∨43,
32 ∨42, 24 ∨34,
24 ∨42, 32 ∨43, 34 ∨43.
Propagating the unit 24 gives:
32 ∨34, 42 ∨43,
32 ∨34, 42 ∨43,
32 ∨42,
32 ∨43, 34 ∨43
and then propagating the unit 43 gives:
32 ∨34, 42,
32 ∨34,
32 ∨42.

6.4
An Extended Example of the DPLL Algorithm
121
The next unit to propagate is 32; the result is the pair of clauses 34, 42, which we
can written more formally as {{34},{42}}. The remaining unit to propagate is l = 34,
but erasing the literal lc = 34 from the clause {34} produces the empty clause 2,
which is unsatisﬁable. Just by choosing values for the two literals 11 and 23, unit
propagation has caused the entire set of 80 clauses to collapse into the empty clause.
We have ruled out 214 of the 216 possible interpretations, because any interpretation
which assigns T to 11 and 23 cannot satisfy the set of clauses.
We should now backtrack and assign F to 23. But wait, let us ‘cheat’ and notice
that there are no solutions with a queen placed on the top left square. Instead, we
backtrack to the very start of the algorithm and assign T to 12. The ﬁrst clause is
deleted and unit propagation produces new unit clauses:
11, 13, 14, 22, 32, 42, 21, 23, 34.
Clearly, propagating the unit clauses: 11, 13, 14, 21, 22, 23 removes all clauses
with literals from the ﬁrst two rows except those with 24 or 24:
≥one / row
24, 31 ∨32 ∨33 ∨34, 41 ∨42 ∨43 ∨44,
≤one / row
31 ∨32, 31 ∨33, 31 ∨34, 32 ∨33, 32 ∨34, 33 ∨34,
41 ∨42, 41 ∨43, 41 ∨44, 42 ∨43, 42 ∨44, 43 ∨44,
≤one / column
24 ∨34, 24 ∨44, 31 ∨41, 32 ∨42, 33 ∨43, 34 ∨44,
≤one / diagonal
24 ∨33, 24 ∨42, 31 ∨42, 32 ∨41, 32 ∨43, 33 ∨42,
33 ∨44, 34 ∨43.
We can now propagate 32, 34, 42 to obtain:
24, 31 ∨33, 41 ∨43 ∨44,
31 ∨33, 41 ∨43, 41 ∨44, 43 ∨44,
24 ∨44, 31 ∨41, 33 ∨43,
24 ∨33, 33 ∨44.
There is now a new unit clause 24 which can be propagated:
31 ∨33, 41 ∨43 ∨44,
31 ∨33, 41 ∨43, 41 ∨44, 43 ∨44,
44, 31 ∨41, 33 ∨43,
33, 33 ∨44.

122
6
Propositional Logic: SAT Solvers
Propagating 33 gives:
31, 41 ∨43 ∨44,
41 ∨43, 41 ∨44, 43 ∨44,
44, 31 ∨41
and then propagating 44 gives:
31, 41 ∨43,
41 ∨43, 31 ∨41.
The new unit clause is 31 can be propagated:
41 ∨43, 41 ∨43, 41.
Finally, propagating 41 leaves one last clause 43. We conclude that the set of clauses
is satisﬁable. If you check which atomic propositions are assigned T , you will ﬁnd
that they are 12, 24, 31, 43, which is precisely the placement of queens shown in the
diagram at the beginning of this section!
6.5 Improving the DPLL Algorithm
An efﬁcient implementation of the DPLL algorithm must use data structures de-
signed so that operations like unit propagation are efﬁcient. Furthermore, an itera-
tive algorithm must replace the recursive one. Beyond such issues of implementa-
tion, the DPLL algorithm has become a practical approach for SAT solving because
of optimizations to the algorithm itself. We will survey several of these: heuristics
to resolve the nondeterministic choice of which assignments to make, learning from
conﬂicts and non-chronological backtracking.
6.5.1 Branching Heuristics
The DPLL algorithm is nondeterministic since when branching occurs we have to
choose an atom and an assignment of a truth value. As we saw in the formula for the
4-queens problem, choosing 12 as the ﬁrst literal to branch on was more efﬁcient
than choosing 11.
Various heuristics have been developed for choosing literals to branch on. The
choice of a literal is based upon some measurable characteristic of the formula,
such as the size of the clauses and number of the literals in a clause. The 4-queens
problem is symmetric so measure-based heuristics are unlikely to help. Consider,
instead, the following set of clauses:

6.5
Improving the DPLL Algorithm
123
¯pqs, p ¯qs, pq¯s,
¯p ¯q¯s,
¯ptv, p¯tv, pt ¯v,
¯p¯t ¯v,
t ¯u, ¯tu, u¯v, ¯uv,
q ¯r, ¯qr, r ¯s, ¯rs.
These are the Tseitin clauses (Sect. 4.5) associated with two triangles qrs and tuv
connected by an edge labeled p. However, the parity on each node is zero so that
clauses are satisﬁable.
Let us try the heuristic: branch on the literal that occurs most often in the set of
clauses. This is p (or ¯p) which occur four times. Deleting all clauses with p and all
occurrences of ¯p gives:
qs, ¯q¯s, tv, ¯t ¯v
t ¯u, ¯tu, u¯v, ¯uv,
q ¯r, ¯qr, r ¯s, ¯rs.
We haven’t progressed very far.
Let us try, instead, the heuristic: branch on a literal whose atom occurs most often
in a clause of shortest length. The intuition behind this heuristic is that assigning to
literals in short clauses will bring us rapidly to a unit clause that can be propagated or
even to an unsatisﬁable clause. In this set of clauses, we can choose r or u; suppose
that we choose r and assign T to r. Immediately, we obtain two unit clauses q and s.
Propagating these units leads to another unit ¯p and propagating that unit results in:
t ¯v, ¯tv, t ¯u, ¯tu, u¯v, ¯uv.
This heuristic leads to fewer clauses than the previous one.
6.5.2 Non-chronological Backtracking
Consider now the set of clauses:
pq, qr,
¯p¯st,
¯psu,
¯p¯tu,
¯ps ¯u,
¯p¯s ¯u.
Let us set the atom p to T . The ﬁrst clause is deleted and ¯p is deleted from the other
clauses, resulting in:
qr, ¯st, su, ¯tu, s ¯u, ¯s ¯u.

124
6
Propositional Logic: SAT Solvers
Obviously, it is possible to assign values to q and r to satisfy the clause qr without in
any way affecting the satisﬁability of the rest of the formula, but the DPLL algorithm
doesn’t know that. It might just choose to branch on the these atoms, ﬁrst assigning
T to q:
¯st, su, ¯tu, s ¯u, ¯s ¯u.
The algorithms next choice might be to assign T to s, resulting in:
t, ¯tu, ¯u.
Unit propagation immediately produces the empty clause showing that this set of
assignments does not satisfy the formula. Backtracking and assigning F to s leads
to:
u, ¯tu, ¯u
and then to the empty clause.
The algorithm returns from the recursion and tries the assignment F to q even
though that assignment will also lead to an unsatisﬁable clause. The DPLL algo-
rithm can be modiﬁed to analyze the sequence of assignments and to discover that
the assignments of T to p and T or F to s are sufﬁcient by themselves to show that
the formula is unsatisﬁable. Therefore, once the two calls on s have returned, the
algorithm can directly return all the way up to try the assignment of F to p without
checking the other assignment to q.
An algorithm which returns up the tree of assignments to an ancestor that is not
its parent is said to engage in non-chronological backtracking. These algorithms are
signiﬁcantly more efﬁcient than the DPLL algorithm that performs chronological
backtracking.
6.5.3 Learning Conﬂict Clauses
We showed that the assignment of T to both p and s necessarily falsiﬁes the for-
mula in the previous section. Unfortunately, backtracking causes this information
to be lost. In a large set of clauses, the algorithm might again try a sequence of
assignments that includes assignments known lead to interpretations that falsify the
formula. The DPLL algorithm can be modiﬁed to prevent this by adding clauses to
the formula, such as ¯p¯s in this case; these clauses will immediately force the set to
be unsatisﬁable on an interpretation that contains the known assignments.
A clause like ¯p¯s is called a conﬂict clause, because it is obtained from an anal-
ysis of the assignments that led to the detection of a conﬂict—a partial assignment
that falsiﬁes the formula. An algorithm that performs conﬂict analysis learns (adds)
conﬂict clauses in the hope of improving performance. Since memory is limited, an
algorithm must also include a policy for deleting clauses that have been learned.

6.6
Stochastic Algorithms
125
6.6 Stochastic Algorithms
On the surface, nothing appears to be less random than algorithms because they
formally specify the steps taken to solve a problem. It may come as a surprise that
algorithms that use randomness can be very effective. A random algorithm will not
be complete—it may not return an answer—but many random algorithms can be
shown to return the correct answer with high probability. In practice, an efﬁcient
incomplete algorithm can be more useful than an inefﬁcient complete algorithm.
Many SAT solvers employ stochastic algorithms that use randomness. Of course,
they can only be used when we are looking for a model, because an incomplete
algorithm can never declare that a formula is unsatisﬁable.
The basic form of a stochastic algorithm for SAT is very simple:
Algorithm 6.21 (Stochastic algorithm for SAT)
Input: A formula A in clausal form.
Output: A model for A (or failure to return any answer).
• Choose a random interpretation I for A.
• Repeat indeﬁnitely:
– If vI (A) = T return I ;
– Otherwise:
· Choose an atom p in A;
· Modify I by ﬂipping p (changing its assignment to the complementary as-
signment).
In practice, Algorithm 6.21 is modiﬁed to limit the number of attempts to ﬂip an
atom in the interpretation; when the limit is reached, the loop restarts after choosing
a new random interpretation. Of course, you might want to limit the number of
restarts so that the algorithm does not run indeﬁnitely.
Stochastic algorithms for SAT differ in the strategy used to choose an atom to ﬂip.
A simple strategy is to choose to ﬂip the atom that will cause the largest number of
currently unsatisﬁed clauses to become satisﬁed. An algorithm can add randomness
to avoid getting stuck in a local minimum: a partial interpretation where no ﬂip of
an atom can improve the chance of obtaining a model.
6.6.1 Solving the 4-Queens Problem with a Stochastic Algorithm
The n-queens problem is quite unsuited for stochastic algorithms, because the num-
ber of models (solutions) is very small compared to the number of interpretations so
a random algorithm has a low probability of ﬁnding one. For the 4-queens problem,
there are only two solutions, but there are 216 = 65536 interpretations! Nevertheless,
we will use this problem to an example of how the algorithm works.

126
6
Propositional Logic: SAT Solvers
Consider the random assignment associated with the conﬁguration:
The atoms 11, 12, 24, 31, 43 are assigned T and the rest are assigned F . There are
two unsatisﬁed clauses:
11 ∨12, 11 ∨31,
corresponding to having two queens in the ﬁrst row and two in the ﬁrst column.
Obviously, we want to ﬂip the assignment to 11 from T to F because that reduces
the number of unsatisﬁed clauses from two to zero, but let us see what other choices
give.
Flipping 12 will satisfy 11 ∨12 but leave 11 ∨31 unsatisﬁed, reducing the num-
ber of unsatisﬁed clauses from two to one. Flipping 31 will also satisfy one of the
unsatisﬁed clauses, but it will make the previously satisﬁed clause 31∨32∨33∨34
(at least one queen in a row) unsatisﬁed; therefore, the number of unsatisﬁed clauses
in unchanged. Flipping 24 or 43 will satisfy no unsatisﬁed clause and make the cor-
responding row clause unsatisﬁed, increasing the number of unsatisﬁed clauses.
Flipping any of the atoms that have been assigned F is even worse, because sev-
eral clauses will become unsatisﬁed. For example, ﬂipping 22 will falsify 22 ∨24,
12 ∨22, 11 ∨22 and 22 ∨31.
For this example, the heuristic of ﬂipping the atom that causes the largest reduc-
tion in the number of unsatisﬁed clauses works very well and it leads immediately
to a solution.
6.7 Complexity of SAT *
The problems of deciding satisﬁability and validity in propositional logic are central
to complexity theory. In this section we survey some of the basic results. It assumes
that you are familiar with fundamental concepts of computational complexity: de-
terministic and nondeterministic algorithms, polynomial and exponential time and
space, the complexity classes P, N P, co-N P.
The method of truth tables is a deterministic algorithm for deciding both satisﬁ-
ability and validity in propositional logic. The algorithm is exponential, because the
size of a formula is polynomial in n, the number of variables, while the truth table
has 2n rows.

6.7
Complexity of SAT *
127
The method of semantic tableaux is a nondeterministic algorithm for both sat-
isﬁability and validity, because at any stage of the construction, we can choose a
leaf to expand and choose a formula in the label of the leaf to which a rule will be
applied. Nevertheless, it can be shown that there are families of formulas for which
the method of semantic tableaux is exponential, as are the David-Putnam procedure
and resolution (Sect. 4.5).
There is a very simple nondeterministic algorithm for deciding the satisﬁability
of a formula A in propositional logic:
Choose an interpretation I for A.
Compute the truth value vI (A).
If vI (A) = T then A is satisﬁable.
If A is satisﬁable, for some computation (choice of I ), the algorithm returns with
the answer that A is satisﬁable. Of course, other choices may not give the correct
answer, but that does not affect the correctness of the nondeterministic algorithm.
Furthermore, the algorithm is very efﬁcient, since choosing an interpretation and
computing the truth value of a formula are linear in the size of the formula. This
shows that the problem of satisﬁability in propositional logic is in the class N P of
problems solvable by a Nondeterministic algorithm in Polynomial time.
In the context of deciding satisﬁability, the difference between a deterministic
and a nondeterministic algorithm seems to be that guessing and checking is efﬁcient
whereas searching is inefﬁcient. One can conjecture that satisﬁability is not in the
class P of problems solvable in Polynomial time by a deterministic algorithm.
A famous theorem by Cook and Levin from 1971 showed that if satisﬁability is in
P, then for every problem in N P, there is a deterministic polynomial algorithm!
A problem with this property is called an N P-complete problem. The theorem on
N P-completeness is proved by showing how to transform an arbitrary nondeter-
ministic Turing machine into a formula in propositional logic such that the Turing
machine produces an answer if and only if the corresponding formula is satisﬁable.
(It must also be shown that the size of the formula is a polynomial of the size of the
Turing machine.) Satisﬁability was the ﬁrst problem shown to be N P-complete,
although since then thousands of problems have been proven to be in this class.
A major open theoretical question in computer science is called P = N P?:
Are the two classes the same or are nondeterministic algorithms more efﬁcient? The
problem can be settled by demonstrating a polynomial algorithm for one of these
problems like satisﬁability or by proving that no such algorithm exists.
Unsatisﬁability (validity) in propositional logic is in the class co-N P of prob-
lems whose complement (here, satisﬁability) is in N P. It can be shown that co-
N P = N P if and only if unsatisﬁability is in N P, but it is not known if there
is a nondeterministic polynomial decision procedure for unsatisﬁability.

128
6
Propositional Logic: SAT Solvers
6.8 Summary
The problems of deciding satisﬁability and validity in propositional logic are almost
certainly intractable: the former is in N P and the latter in co-N P. However,
algorithms and data structures like the ones described in this chapter have proved
themselves to be highly efﬁcient in many practical applications. The DPLL algo-
rithm uses elementary properties of clauses to search for a model. SAT solvers based
upon the DPLL algorithm employ heuristics and randomness to make the search for
a model more efﬁcient.
6.9 Further Reading
The original papers on the DP and DLL algorithms are: Davis and Putnam (1960)
and Davis et al. (1962). Malik and Zhang (2009) and Zhang (2003) contain good
introductions to SAT solvers. For the state of the art on SAT algorithms, see the
handbook by Biere et al. (2009). The presentation in Sect. 6.5.2 was adapted from
Sect. 3.6.4.1 of this book.
See http://www.satlive.org/ for links to software for SAT solvers.
The encoding of the 8-queens problem is taken from Biere et al. (2009,
Sect. 2.3.1), which is based on Nadel (1990).
There are many textbooks on computational models: Gopalakrishnan (2006),
Sipser (2005), Hopcroft et al. (2006).
6.10 Exercises
6.1 Are there other solutions to the 4-queens problem? If so, compute these solu-
tions using the DPLL algorithm and an appropriate choice of assignments.
6.2 A variant of the n-queens problem is the n-rooks problem. A rook can only
capture horizontally and vertically, not diagonally. Solve the 4-rooks problem using
DPLL.
6.3 The pigeon-hole problem is to place n + 1 pigeons into n holes such that each
hole contains at most one pigeon. There is no solution, of course!
1. Encode the pigeon-hole problem for 3 holes and 4 pigeons as a formula in clausal
form.
2. Use the DPLL algorithm to show that the formula is unsatisﬁable for one assign-
ment.
3. Develop an expression for the number of clauses in the formula for the pigeon-
hole problem with n holes.

References
129
6.4 Let G be a connected undirected graph. The graph coloring problem is to decide
if one of k colors {c1,...,ck} can be assigned to each vertex color(vi) = cj such
that color(vi1) ̸= color(vi2) if (vi1,vi1) is an edge in E. Show how to translate the
graph coloring problem for any G into SAT. Use the DPLL algorithm to show that
K2,2 is 2-colorable and that the triangle is 3-colorable.
6.5 What is the relation between the DP algorithm and resolution?
6.6 * Let 3SAT be the problem of deciding satisﬁability of formulas in CNF such
that there are three literals in each clause. The proof that SAT is N P-complete
actually shows that 3SAT is N P-complete. Let 2SAT be the problem of deciding
satisﬁability of formulas in CNF such that there are two literals in each clause. Show
that there is an efﬁcient algorithm for 2SAT.
6.7 * Show that there is an efﬁcient algorithm for Horn-SAT, deciding if a set of
Horn clauses is satisﬁable.
References
A. Biere, M. Heule, H. Van Maaren, and T. Walsh, editors. Handbook of Satisﬁability, volume 185
of Frontiers in Artiﬁcial Intelligence and Applications. IOS Press, 2009.
M. Davis and H. Putnam. A computing procedure for quantiﬁcation theory. Journal of the ACM,
7:201–215, 1960.
M. Davis, G. Logemann, and D. Loveland. A machine program for theorem-proving. Communica-
tions of the ACM, 5:394–397, 1962.
G. Gopalakrishnan. Computational Engineering: Applied Automata Theory and Logic. Springer,
2006.
J.E. Hopcroft, R. Motwani, and J.D. Ullman. Introduction to Automata Theory, Languages and
Computation (Third Edition). Addison-Wesley, 2006.
S. Malik and L. Zhang. Boolean satisﬁability: From theoretical hardness to practical success. Com-
munications of the ACM, 52(8):76–82, 2009.
B.A. Nadel. Representation selection for constraint satisfaction: A case study using n-queens. IEEE
Expert: Intelligent Systems and Their Applications, 5:16–23, June 1990.
M. Sipser. Introduction to the Theory of Computation (Second Edition). Course Technology, 2005.
L. Zhang. Searching for truth: Techniques for satisﬁability of Boolean formulas. PhD thesis,
Princeton University, 2003. http://research.microsoft.com/en-us/people/
lintaoz/thesis_lintao_zhang.pdf.


Chapter 7
First-Order Logic: Formulas, Models, Tableaux
7.1 Relations and Predicates
The axioms and theorems of mathematics are deﬁned on sets such as the set of in-
tegers Z . We need to be able to write and manipulate logical formulas that contain
relations on values from arbitrary sets. First-order logic is an extension of proposi-
tional logic that includes predicates interpreted as relations on a domain.
Before continuing, you may wish to review Appendix on set theory.
Example 7.1 P(x) ⊂N is the unary relation that is the subset of natural numbers
that are prime: {2,3,5,7,11,...}.
Example 7.2 S (x,y) ⊂N 2 is the binary relation that is the subset of pairs (x,y)
of natural numbers such that y = x2: {(0,0),(1,1),(2,4),(3,9),...}.
It would be more usual in mathematics to deﬁne a unary function f (x) = x2 which maps
a natural number x into its square. As shown in the example, functions are special cases
of relations. For simplicity, we limit ourselves to relations in this chapter and the next; the
extension of ﬁrst-order logic to include functions is introduced in Sect. 9.1.
Deﬁnition 7.3 Let R be an n-ary relation on a domain D, that is, R is a subset of
Dn. The relation R can be represented by the Boolean-valued function PR : Dn →
{T,F} that maps an n-tuple to T if and only if the n-tuple is an element of the
relation:
PR(d1,...,dn) = T iff (d1,...,dn) ∈R,
PR(d1,...,dn) = F iff (d1,...,dn) ̸∈R.
Example 7.4 The set of primes P is represented by the function PP:
PP(0) = F, PP(1) = F, PP(2) = T,
PP(3) = T, PP(4) = F, PP(5) = T,
PP(6) = F, PP(7) = T, PP(8) = F, ...
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_7, © Springer-Verlag London 2012
131

132
7
First-Order Logic: Formulas, Models, Tableaux
Example 7.5 The set of squares S is represented by the function PS :
PS (0,0) = PS (1,1) = PS (2,4) = PS (3,9) = ··· = T,
PS (0,1) = PS (1,0) = PS (0,2) = PS (2,0) =
PS (1,2) = PS (2,1) = PS (0,3) = PS (2,2) = ··· = F.
This correspondence provides the link necessary for a logical formalization of
mathematics. All the logical machinery—formulas, interpretations, proofs—that we
developed for propositional logic can be applied to predicates. The presence of a do-
main upon which predicates are interpreted considerably complicates the technical
details but not the basic concepts.
Here is an overview of our development of ﬁrst-order logic:
• Syntax (Sect. 7.2): Predicates are used to represent functions from a domain to
truth values. Quantiﬁers allow a purely syntactical expression of the statement
that the relation represented by a predicate is true for some or all elements of the
domain.
• Semantics (Sect. 7.3): An interpretation consists of a domain and an assignment
of relations to the predicates. The semantics of the Boolean operators remains
unchanged, but the evaluation of the truth value of the formula must take the
quantiﬁers into account.
• Semantic tableaux (Sect. 7.5): The construction of a tableau is potentially inﬁnite
because a formula can be interpreted in an inﬁnite domain. It follows that the
method of semantic tableaux is not decision procedure for satisﬁability in ﬁrst-
order logic. However, if the construction of a tableau for a formula A terminates
in a closed tableau, then A is unsatisﬁable (soundness); conversely, a systematic
tableau for an unsatisﬁable formula will close (completeness).
• Deduction (Sects. 8.1, 8.2): There are Gentzen and Hilbert deductive systems
which are sound and complete. A valid formula is provable and we can construct
a proof of the formula using tableaux, but given an arbitrary formula we cannot
decide if it is valid and hence provable.
• Functions (Sect. 9.1): The syntax of ﬁrst-order logic can be extended with func-
tion symbols that are interpreted as functions on the domain. With functions we
can reason about mathematical operations, for example:
((x > 0 ∧y > 0) ∨(x < 0 ∧y < 0)) →(x · y > 0).
• Herbrand interpretations (Sect. 9.3): There are canonical interpretations called
Herbrand interpretations. If a formula in clausal form has a model, it has a model
which is an Herbrand interpretation, so to check satisﬁability, it is sufﬁcient to
check if there is an Herbrand model for a formula.
• Resolution (Chap. 10): Resolution can be generalized to ﬁrst-order logic with
functions.

7.2
Formulas in First-Order Logic
133
7.2 Formulas in First-Order Logic
7.2.1 Syntax
Deﬁnition 7.6 Let P, A and V be countable sets of predicate symbols, constant
symbols and variables. Each predicate symbol pn ∈P is associated with an arity,
the number n ≥1 of arguments that it takes. pn is called an n-ary predicate. For
n = 1,2, the terms unary and binary, respectively, are also used.
Notation
• We will drop the word ‘symbol’ and use the words ‘predicate’ and ‘constant’ by
themselves for the syntactical symbols.
• By convention, the following lower-case letters, possibly with subscripts, will
denote these sets: P = {p,q,r}, A = {a,b,c}, V = {x,y,z}.
• The superscript denoting the arity of the predicate will not be written since the
arity can be inferred from the number of arguments.
Deﬁnition 7.7
∀is the universal quantiﬁer and is read for all.
∃is the existential quantiﬁer and is read there exists.
Deﬁnition 7.8 An atomic formula is an n-ary predicate followed by a list of n ar-
guments in parentheses: p(t1,t2,...,tn), where each argument ti is either a variable
or a constant. A formula in ﬁrst-order logic is a tree deﬁned recursively as follows:
• A formula is a leaf labeled by an atomic formula.
• A formula is a node labeled by ¬ with a single child that is a formula.
• A formula is a node labeled by ∀x or ∃x (for some variable x) with a single child
that is a formula.
• A formula is a node labeled by a binary Boolean operator with two children both
of which are formulas.
A formula of the form ∀xA is a universally quantiﬁed formula or, simply, a universal
formula. Similarly, a formula of the form ∃xA is an existentially quantiﬁed formula
or an existential formula.
The deﬁnition of derivation and formation trees, and the concept of induction
on the structure of a formula are taken over unchanged from propositional logic.
When writing a formula as a string, the quantiﬁers are considered to have the same
precedence as negation and a higher precedence than the binary operators.
Example 7.9 Figure 7.1 shows the tree representation of the formula:
∀x(¬∃yp(x,y) ∨¬∃yp(y,x)).
The parentheses in p(x,y) are part of the syntax of the atomic formula.

134
7
First-Order Logic: Formulas, Models, Tableaux
Fig. 7.1 Tree for
∀x(¬∃yp(x,y)∨¬∃yp(y,x))
Example 7.10 Here are some examples of formulas in ﬁrst-order logic:
∀x∀y(p(x,y) →p(y,x)),
∀x∃yp(x,y),
∃x∃y(p(x) ∧¬p(y)),
∀xp(a,x),
∀x(p(x) ∧q(x)) ↔(∀xp(x) ∧∀xq(x)),
∃x(p(x) ∨q(x)) ↔(∃xp(x) ∨∃xq(x)),
∀x(p(x) →q(x)) →(∀xp(x) →∀xq(x)),
(∀xp(x) →∀xq(x)) →∀x(p(x) →q(x)).
For now, they are just given as examples of the syntax of formulas in ﬁrst-order
logic; their meaning will be discussed in Sect. 7.3.2.
7.2.2 The Scope of Variables
Deﬁnition 7.11 A universal or existential formula ∀xA or ∃xA is a quantiﬁed for-
mula. x is the quantiﬁed variable and its scope is the formula A. It is not required
that x actually appear in the scope of its quantiﬁcation.
The concept of the scope of variables in formulas of ﬁrst-order logic is similar to
the concept of the scope of variables in block-structured programming languages.
Consider the program in Fig. 7.2. The variable x is declared twice, once globally
and once locally in method p. The scope of the global declaration includes p, but
the local declaration hides the global one. Within p, the value printed will be 1, the

7.2
Formulas in First-Order Logic
135
Fig. 7.2 Global and local
variables
class MyClass {
int x;
void p() {
int x;
x = 1;
// Print the value of x
}
void q() {
// Print the value of x
}
... void main(...) {
x = 5;
p;
q;
}
value of the local variable. Within the method q, the global variable x is in scope but
not hidden and the value 5 will be printed. As in programming, hiding a quantiﬁed
variable within its scope is confusing and should be avoided by giving different
names to each quantiﬁed variable.
Deﬁnition 7.12 Let A be a formula. An occurrence of a variable x in A is a free
variable of A iff x is not within the scope of a quantiﬁed variable x. A variable
which is not free is bound.
If a formula has no free variables, it is closed. If {x1,...,xn} are all the free
variables of A, the universal closure of A is ∀x1 ···∀xnA and the existential closure
is ∃x1 ···∃xnA.
A(x1,...,xn) indicates that the set of free variables of the formula A is a subset
of {x1,...,xn}.
Example 7.13 p(x,y) has two free variables x and y, ∃yp(x,y) has one free vari-
able x and ∀x∃yp(x,y) is closed. The universal closure of p(x,y) is ∀x∀yp(x,y)
and its existential closure is ∃x∃yp(x,y).
Example 7.14 In ∀xp(x) ∧q(x), the occurrence of x in p(x) is bound and the
occurrence in q(x) is free. The universal closure is ∀x(∀xp(x) ∧q(x)). Obviously,
it would have been better to write the formula as ∀xp(x) ∧q(y) with y as the free
variable; its universal closure is ∀y(∀xp(x) ∧q(y)).

136
7
First-Order Logic: Formulas, Models, Tableaux
7.2.3 A Formal Grammar for Formulas *
As with propositional logic (Sect. 2.1.6), formulas in ﬁrst-order logic can be deﬁned
as the strings generated by a context-free grammar.
Deﬁnition 7.15 The following grammar deﬁnes atomic formulas and formulas in
ﬁrst-order logic:
argument
::= x
for any x ∈V
argument
::= a
for any a ∈A
argument_list
::= argument
argument_list
::= argument,argument_list
atomic_formula ::= p (argument_list)
for any n-ary p ∈P,n ≥1
formula
::= atomic_formula
formula
::= ¬formula
formula
::= formula ∨formula
similarly for ∧,···
formula
::= ∀x formula
for any x ∈V
formula
::= ∃x formula
for any x ∈V
An n-ary predicate p must have an argument list of length n.
7.3 Interpretations
In propositional logic, an interpretation is a mapping from atomic propositions to
truth values. In ﬁrst-order logic, the analogous concept is a mapping from atomic
formulas to truth values. However, atomic formulas contain variables and constants
that must be assigned elements of some domain; once that is done, the predicates
are interpreted as relations over the domain.
Deﬁnition 7.16 Let A be a formula where {p1,...,pm} are all the predicates ap-
pearing in A and {a1,...,ak} are all the constants appearing in A. An interpretation
IA for A is a triple:
(D, {R1,...,Rm}, {d1,...,dk}),
where D is a non-empty set called the domain, Ri is an ni-ary relation on D that is
assigned to the ni-ary predicate pi and di ∈D is assigned to the constant ai.
Example 7.17 Here are three interpretations for the formula ∀xp(a,x):
I1 = (N ,{≤},{0}),
I2 = (N ,{≤},{1}),
I3 = (Z ,{≤},{0}).

7.3
Interpretations
137
The domain is either the N , the set of natural numbers, or Z , the set of integers.
The binary relation ≤(less-than) is assigned to the binary predicate p and either 0
or 1 is assigned to the constant a.
The formula can also be interpreted over strings:
I4 = (S ,{substr},{""}).
The domain S is a set of strings, substr is the binary relation such that (s1,s2) ∈
substr iff s1 is a substring of s2, and "" is the null string.
A formula might have free variables and its truth value depends on the assign-
ment of domain elements to the variables. For example, it doesn’t make sense to ask
if the formula p(x,a) is true in the interpretation (N ,{>},{10}). If x is assigned
15 the truth value of the formula is T , while if x is assigned 6 the truth value of the
formula is F .
Deﬁnition 7.18 Let IA be an interpretation for a formula A. An assignment σIA :
V →D is a function which maps every free variable v ∈V to an element d ∈D,
the domain of IA.
σIA[xi ←di] is an assignment that is the same as σIA except that xi is mapped
to di.
We can now deﬁne the truth value of a formula of ﬁrst-order logic.
Deﬁnition 7.19 Let A be a formula, IA an interpretation and σIA an assignment.
vσIA(A), the truth value of A under IA and σIA, is deﬁned by induction on the
structure of A (where we have simpliﬁed the notation by writing vσ for vσIA ):
• Let A = pk(c1,...,cn) be an atomic formula where each ci is either a variable
xi or a constant ai. vσ(A) = T iff (d1,...,dn) ∈Rk where Rk is the relation
assigned by IA to pk, and di is the domain element assigned to ci, either by IA
if ci is a constant or by σIA if ci is a variable.
• vσ(¬A1) = T iff vσ(A1) = F .
• vσ(A1 ∨A2) = T iff vσ(A1) = T or vσ(A2) = T ,
and similarly for the other Boolean operators.
• vσ(∀xA1) = T iff vσ[x←d](A1) = T for all d ∈D.
• vσ(∃xA1) = T iff vσ[x←d](A1) = T for some d ∈D.
7.3.1 Closed Formulas
We deﬁne satisﬁability and validity only on closed formulas. The reason is both
convenience (not having to deal with assignments in addition to interpretations) and
simplicity (because we can use the closures of formulas).

138
7
First-Order Logic: Formulas, Models, Tableaux
Theorem 7.20 Let A be a closed formula and let IA be an interpretation for A.
Then vσIA(A) does not depend on σIA.
Proof Call a formula independent of σIA if its value does not depend on σIA. Let
A′ = ∀xA1(x) be a (not necessarily proper) subformula of A, where A′ is not con-
tained in the scope of any other quantiﬁer. Then vσIA(A′) = T iff vσIA[x←d](A1)
for all d ∈D. But x is the only free variable in A1, so A1 is independent of σIA
since what is assigned to x is replaced by the assignment [x ←d]. A similar results
holds for an existential formula ∃xA1(x).
The theorem can now be proved by induction on the depth of the quantiﬁers
and by structural induction, using the fact that a formula constructed using Boolean
operators on independent formulas is also independent.
By the theorem, if A is a closed formula we can use the notation vI (A) without
mentioning an assignment.
Example 7.21 Let us check the truth values of the formula A = ∀xp(a,x) under the
interpretations given in Example 7.17:
• vI1(A) = T : For all n ∈N , 0 ≤n.
• vI2(A) = F : It is not true that for all n ∈N , 1 ≤n. If n = 0 then 1 ̸≤0.
• vI3(A) = F : There is no smallest integer.
• vI4(A) = T : By deﬁnition, the null string is a substring of every string.
The proof of the following theorem is left as an exercise.
Theorem 7.22 Let A′ = A(x1,...,xn) be a (non-closed) formula with free vari-
ables x1,...,xn, and let I be an interpretation. Then:
• vσIA(A′) = T for some assignment σIA iff vI (∃x1 ···∃xnA′) = T .
• vσIA(A′) = T for all assignments σIA iff vI (∀x1 ···∀xnA′) = T .
7.3.2 Validity and Satisﬁability
Deﬁnition 7.23 Let A be a closed formula of ﬁrst-order logic.
• A is true in I or I is a model for A iff vI (A) = T . Notation: I |= A.
• A is valid if for all interpretations I , I |= A. Notation: |= A.
• A is satisﬁable if for some interpretation I , I |= A.
• A is unsatisﬁable if it is not satisﬁable.
• A is falsiﬁable if it is not valid.
Example 7.24 The closed formula ∀xp(x) →p(a) is valid. If it were not, there
would be an interpretation I = (D,{R},{d}) such that vI (∀xp(x)) = T and
vI (p(a)) = F . By Theorem 7.22, vσI (p(x)) = T for all assignments σI , in
particular for the assignment σ ′
I that assigns d to x. But p(a) is closed, so
vσ ′
I (p(a)) = vI (p(a)) = F , a contradiction.

7.3
Interpretations
139
Let us now analyze the semantics of the formulas in Example 7.10.
Example 7.25
• ∀x∀y(p(x,y) →p(y,x))
The formula is satisﬁable in an interpretation where p is assigned a symmetric
relation like =. It is not valid because the formula is falsiﬁed in an interpretation
that assigns to p a non-symmetric relation like <.
• ∀x∃yp(x,y)
The formula is satisﬁable in an interpretation where p is assigned a relation that is
a total function, for example, (x,y) ∈R iff y = x + 1 for x,y ∈Z . The formula
is falsiﬁed if the domain is changed to the negative numbers because there is no
negative number y such that y = −1 + 1.
• ∃x∃y(p(x) ∧¬p(y))
This formula is satisﬁable only in a domain with at least two elements.
• ∀xp(a,x)
This expresses the existence of an element with special properties. For example,
if p is interpreted by the relation ≤on the domain N , then the formula is true for
a = 0. If we change the domain to Z the formula is false for the same assignment
of ≤to p.
• ∀x(p(x) ∧q(x)) ↔(∀xp(x) ∧∀xq(x))
The formula is valid. We prove the forward direction and leave the converse as
an exercise. Let I = (D,{R1,R2},{}) be an arbitrary interpretation. By Theo-
rem 7.22, vσI (p(x) ∧q(x)) = T for all assignments σI , and by the inductive
deﬁnition of an interpretation, vσI (p(x)) = T and vσI (q(x)) = T for all assign-
ments σI . Again by Theorem 7.22, vI (∀xp(x)) = T and vI (∀xq(x)) = T , and
by the deﬁnition of an interpretation vI (∀xp(x) ∧∀xq(x)) = T .
Show that ∀does not distribute over disjunction by constructing a falsifying in-
terpretation for ∀x(p(x) ∨q(x)) ↔(∀xp(x) ∨∀xq(x)).
• ∀x(p(x) →q(x)) →(∀xp(x) →∀xq(x))
We leave it as an exercise to show that this is a valid formula, but its converse
(∀xp(x) →∀xq(x)) →∀x(p(x) →q(x)) is not.
7.3.3 An Interpretation for a Set of Formulas
In propositional logic, the concept of interpretation and the deﬁnition of properties
such as satisﬁability can be extended to sets of formulas (Sect. 2.2.4). The same
holds for ﬁrst-order logic.
Deﬁnition 7.26 Let U = {A1,...} be a set of formulas where {p1,...,pm} are all
the predicates appearing in all Ai ∈S and {a1,...,ak} are all the constants appear-
ing in all Ai ∈S. An interpretation IU for S is a triple:
(D, {R1,...,Rm}, {d1,...,dk}),

140
7
First-Order Logic: Formulas, Models, Tableaux
where D is a non-empty set called the domain, Ri is an ni-ary relation on D that is
assigned to the ni-ary predicate pi and di ∈D is an element of D that is assigned
to the constant ai.
Similarly, an assignment needs to assign elements of the domain to the free vari-
ables (if any) in all formulas in U. For simplicity, the following deﬁnition is given
only for closed formulas.
Deﬁnition 7.27 A set of closed formulas U = {A1,...} is (simultaneously) satis-
ﬁable iff there exists an interpretation IU such that vIU (Ai) = T for all i. The
satisfying interpretation is a model of U. U is valid iff for every interpretation IU,
vIU (Ai) = T for all i.
The deﬁnitions of unsatisﬁable and falsiﬁable are similar.
7.4 Logical Equivalence
Deﬁnition 7.28
• Let U = {A1,A2} be a pair of closed formulas. A1 is logically equivalent to A2
iff vIU (A1) = vIU (A2) for all interpretations IU. Notation: A1 ≡A2.
• Let A be a closed formula and U a set of closed formulas. A is a logical conse-
quence of U iff for all interpretations IU∪{A}, vIU∪{A}(Ai) = T for all Ai ∈U
implies vIU∪{A}(A) = T . Notation: U |= A.
As in propositional logic, the metamathematical concept A ≡B is not the same
as the formula A ↔B in the logic, and similarly for logical consequence and impli-
cation. The relations between the concepts is given by the following theorem whose
proof is similar to the proofs of Theorems 2.29, 2.50.
Theorem 7.29 Let A, B be closed formulas and U = {A1,...,An} be a set of
closed formulas. Then:
A ≡B
iff
|= A ↔B,
U |= A
iff
|= (A1 ∧··· ∧An) →A.

7.4
Logical Equivalence
141
7.4.1 Logical Equivalences in First-Order Logic
Duality
The two quantiﬁers are duals:
|= ∀xA(x) ↔¬∃x¬A(x),
|= ∃xA(x) ↔¬∀x¬A(x).
In many presentations of ﬁrst-order logic, ∀is deﬁned in the logic and ∃is consid-
ered to be an abbreviation of ¬∀¬.
Commutativity and Distributivity
Quantiﬁers of the same type commute:
|= ∀x∀yA(x,y) ↔∀y∀xA(x,y),
|= ∃x∃yA(x,y) ↔∃y∃xA(x,y),
but ∀and ∃commute only in one direction:
|= ∃x∀yA(x,y) →∀y∃xA(x,y).
Universal quantiﬁers distribute over conjunction, and existential quantiﬁers dis-
tribute over disjunction:
|= ∃x(A(x) ∨B(x)) ↔∃xA(x) ∨∃xB(x),
|= ∀x(A(x) ∧B(x)) ↔∀xA(x) ∧∀xB(x),
but only one direction holds when distributing universal quantiﬁers over disjunction
and existential quantiﬁers over conjunction:
|= ∀xA(x) ∨∀xB(x) →∀x(A(x) ∨B(x)),
|= ∃x(A(x) ∧B(x)) →∃xA(x) ∧∃xB(x).
To see that the converse direction of the second formula is falsiﬁable, let D =
{d1,d2} be a domain with two elements and consider an interpretation such that:
v(A(d1)) = T,
v(A(d2)) = F,
v(B(d1)) = F,
v(B(d2)) = T.
Then v(∃xA(x) ∧∃xB(x)) = T but v(∃x(A(x) ∧B(x))) = F . A similar counterex-
ample can be found for the ﬁrst formula with the universal quantiﬁers and disjunc-
tion.
In the formulas with more than one quantiﬁer, the scope rules ensure that each quantiﬁed
variable is distinct. You may wish to write the formulas in the equivalent form with distinct
variables names:
|= ∀x(A(x) ∧B(x)) ↔∀yA(y) ∧∀zB(z).

142
7
First-Order Logic: Formulas, Models, Tableaux
Quantiﬁcation Without the Free Variable in Its Scope
When quantifying over a disjunction or conjunction, if one subformula does not
contain the quantiﬁed variable as a free variable, then distribution may be freely
performed. If x is not free in B then:
|= ∃xA(x) ∨B ↔∃x(A(x) ∨B),
|= ∀xA(x) ∨B ↔∀x(A(x) ∨B),
|= B ∨∃xA(x) ↔∃x(B ∨A(x)),
|= B ∨∀xA(x) ↔∀x(B ∨A(x)),
|= ∃xA(x) ∧B ↔∃x(A(x) ∧B),
|= ∀xA(x) ∧B ↔∀x(A(x) ∧B),
|= B ∧∃xA(x) ↔∃x(B ∧A(x)),
|= B ∧∀xA(x) ↔∀x(B ∧A(x)).
Quantiﬁcation over Implication and Equivalence
Distributing a quantiﬁer over an equivalence or an implication is not trivial.
As with the other operators, if the quantiﬁed variable does not appear in one of
the subformulas there is no problem:
|= ∀x(A →B(x)) ↔(A →∀xB(x)),
|= ∀x(A(x) →B) ↔(∃xA(x) →B).
Distribution of universal quantiﬁcation over equivalence works in one direction:
|= ∀x(A(x) ↔B(x)) →(∀xA(x) ↔∀xB(x)),
while for existential quantiﬁcation, we have the formula:
|= ∀x(A(x) ↔B(x)) →(∃xA(x) ↔∃xB(x)).
For distribution over an implication, the following formulas hold:
|= ∃x(A(x) →B(x)) ↔(∀xA(x) →∃xB(x)),
|= (∃xA(x) →∀xB(x)) →∀x(A(x) →B(x)),
|= ∀x(A(x) →B(x)) →(∃xA(x) →∃xB(x)),
|= ∀x(A(x) →B(x)) →(∀xA(x) →∃xB(x)).
To derive these formulas, replace the implication or equivalence by the equivalent
disjunction and conjunction and use the previous equivalences.
Example 7.30
∃x(A(x) →B(x)) ≡∃x(¬A(x) ∨B(x))
≡∃x¬A(x) ∨∃xB(x)
≡¬∃x¬A(x) →∃xB(x)
≡∀xA(x) →∃xB(x).

7.5
Semantic Tableaux
143
The formulas for conjunction and disjunction can be proved directly using the
semantic deﬁnitions.
Example 7.31 Prove: |= ∀x(A(x) ∨B(x)) →∀xA(x) ∨∃xB(x).
Use logical equivalences of propositional logic (considering each atomic formula
as an atomic proposition) to transform the formula:
∀x(A(x) ∨B(x)) →(∀xA(x) ∨∃xB(x))
≡
∀x(A(x) ∨B(x)) →(¬∀xA(x) →∃xB(x))
≡
¬∀xA(x) →(∀x(A(x) ∨B(x)) →∃xB(x)).
By duality of the quantiﬁers, we have:
∃x¬A(x) →(∀x(A(x) ∨B(x)) →∃xB(x))).
For the formula to be valid, it must be true under all interpretations. Clearly, if
vI (∃x¬A(x)) = F or vI (∀x(A(x) ∨B(x))) = F , the formula is true, so we need
only show vI (∃xB(x)) = T for interpretations vI under which these subformulas
are true. By Theorem 7.22, for some assignment σ ′
I , vσ ′
I (¬A(x)) = T and thus
vσ ′
I (A(x)) = F . Using Theorem 7.22 again, vσI (A(x) ∨B(x)) = T under all as-
signments, in particular under σ ′
I . By deﬁnition of an interpretation for disjunction,
vσ ′
I (B(x)) = T , and using Theorem 7.22 yet again, vI (∃xB(x)) = T .
7.5 Semantic Tableaux
Before presenting the formal construction of semantic tableaux for ﬁrst-order logic,
we informally construct several tableaux in order to demonstrate the difﬁculties that
must be dealt with and to motivate their solutions.
First, we need to clarify the concept of constant symbols. Recall from Deﬁni-
tion 7.6 that formulas of ﬁrst-order are constructed from countable sets of predicate,
variable and constant symbols, although a particular formula such as ∃xp(a,x) will
only use a ﬁnite subset of these symbols. To build semantic tableaux in ﬁrst-order
logic, we will need to use the entire set of constant symbols A = {a0,a1,...}. If a
formula like ∃xp(a,x) contains a constant symbol, we assume that it is one of the
ai.
Deﬁnition 7.32 Let A be a quantiﬁed formula ∀xA1(x) or ∃xA1(x) and let a be
a constant symbol. An instantiation of A by a is the formula A1(a), where all free
occurrences of x are replaced by the constant a.

144
7
First-Order Logic: Formulas, Models, Tableaux
7.5.1 Examples for Semantic Tableaux
Instantiate Universal Formulas with all Constants
Example 7.33 Consider the valid formula:
A = ∀x(p(x) →q(x)) →(∀xp(x) →∀xq(x)),
and let us build a semantic tableau for its negation. Applying the rule for the α-
formula ¬(A1 →A2) twice, we get:
¬(∀x(p(x) →q(x)) →(∀xp(x) →∀xq(x)))
↓
∀x(p(x) →q(x)), ¬(∀xp(x) →∀xq(x))
↓
∀x(p(x) →q(x)), ∀xp(x), ¬∀xq(x)
↓
∀x(p(x) →q(x)), ∀xp(x), ∃¬xq(x)
where the last node is obtained by the duality of ∀and ∃.
The third formula will be true in an interpretation only if there exists a domain
element c such that c ∈Rq, where Rq is the relation assigned to the predicate q. Let
us use the ﬁrst constant a1 to represent this element and instantiate the formula with
it:
∀x(p(x) →q(x)), ∀xp(x), ∃¬xq(x)
↓
∀x(p(x) →q(x)), ∀xp(x), ¬q(a1).
The ﬁrst two formulas are universally quantiﬁed, so they can be true only if they
hold for every element of the domain of an interpretation. Since any interpretation
must include the domain element that is assigned to the constant a1, we instantiate
the universally quantiﬁed formulas with this constant:
∀x(p(x) →q(x)), ∀xp(x), ¬q(a1)
↓
∀x(p(x) →q(x)), p(a1), ¬q(a1)
↓
p(a1) →q(a1), p(a1), ¬q(a1).
Applying the rule to the β-formula p(a1) →q(a1) immediately gives a closed tab-
leau, which to be expected for the negation of the valid formula A.
From this example we learn that existentially quantiﬁed formulas must be in-
stantiated with a constant the represents the domain element that must exist. Once a
constant is introduced, instantiations of all universally quantiﬁed formulas must be
done for that constant.

7.5
Semantic Tableaux
145
¬ (∀x(p(x) ∨q(x)) →(∀xp(x) ∨∀xq(x)))
↓
∀x(p(x) ∨q(x)), ¬ (∀xp(x) ∨∀xq(x))
↓
∀x(p(x) ∨q(x)), ¬∀xp(x), ¬∀xq(x)
↓
∀x(p(x) ∨q(x)), ∃¬xp(x), ∃¬xq(x)
↓
∀x(p(x) ∨q(x)), ∃¬xp(x), ¬q(a1)
↓
∀x(p(x) ∨q(x)), ¬p(a1), ¬q(a1)
↓
p(a1) ∨q(a1), ¬p(a1), ¬q(a1)
↙
↘
p(a1), ¬p(a1), ¬q(a1)
q(a1), ¬p(a1), ¬q(a1)
×
×
Fig. 7.3 Semantic tableau for the negation of a satisﬁable, but not valid, formula
Don’t Use the Same Constant Twice to Instantiate Existential Formulas
Example 7.34 Figure 7.3 shows an attempt to construct a tableau for the negation
of the formula:
A = ∀x(p(x) ∨q(x)) →(∀xp(x) ∨∀xq(x)),
which is satisﬁable but not valid. As a falsiﬁable formula, its negation ¬A is satis-
ﬁable, but the tableau in the ﬁgure is closed. What went wrong?
The answer is that instantiation of ∃x¬p(x)) should not have used the constant
a1 once it had already been chosen for the instantiation of ∃¬xq(x). Choosing the
same constant means that the interpretation will assign the same domain element
to both occurrences of the constant. In fact, the formula A true (and ¬A is false)
in all interpretations over domains of a single element, but the formula might be
satisﬁable in interpretations with larger domains.
To avoid unnecessary constraints on the domain of a possible interpretation, a
new constant must be chosen for every instantiation of an existentially quantiﬁed
formula:
∀x(p(x) ∨q(x)), ∃¬xp(x), ∃¬xq(x)
↓
∀x(p(x) ∨q(x)), ∃¬xp(x), ¬q(a1)
↓
∀x(p(x) ∨q(x)), ¬p(a2), ¬q(a1).
Instantiating the universally quantiﬁed formula with a1 gives:
p(a1) ∨q(a1), ¬p(a2), ¬q(a1).

146
7
First-Order Logic: Formulas, Models, Tableaux
Don’t Use Up Universal Formulas
Example 7.35 Continuing the tableau from the previous example:
∀x(p(x) ∨q(x)), ¬p(a2), ¬q(a1)
↓
p(a1) ∨q(a1), ¬p(a2), ¬q(a1)
we should now instantiate the universal formula ∀x(p(x) ∨q(x)) again with a2,
since it must be true for all domain elements, but, unfortunately, the formula has
been used up by the tableau construction. To prevent this, universal formulas will
never be deleted from the label of a node. They remain in the labels of all descendant
nodes so as to constrain the possible interpretations of every new constant that is
introduced:
∀x(p(x) ∨q(x)), ¬p(a2), ¬q(a1)
↓
∀x(p(x) ∨q(x)), p(a1) ∨q(a1), ¬p(a2), ¬q(a1)
↓
∀x(p(x) ∨q(x)), p(a2) ∨q(a2), p(a1) ∨q(a1), ¬p(a2), ¬q(a1).
We leave it to the reader to continue the construction the tableau using the rule
for β-formulas. Exactly one branch of the tableau will be open. A model can be
deﬁned by specifying a domain with two elements, say, 1 and 2. These elements
are assigned to the constants a1 and a2, respectively, and the relations Rp and Rq
assigned to p and q, respectively, hold for exactly one of the domain elements:
I = ({1,2},{Rp = {1}, Rq = {2}},{a1 = 1,a2 = 2}).
As expected, this model satisﬁes ¬A, so A is falsiﬁable.
A Branch May not Terminate
Example 7.36 Let us construct a semantic tableau to see if the formula A =
∀x∃yp(x,y) is satisﬁable. Apparently, no rules apply since the formula is univer-
sally quantiﬁed and we only required that they had to be instantiated for constants al-
ready appearing in the formulas labeling a node. The constants are those that appear
in the original formula and those that were introduced by instantiating existentially
quantiﬁed formulas.
However, recall from Deﬁnition 7.16 that an interpretation is required to have a
non-empty domain; therefore, we can arbitrarily choose the constant a1 to represent
that element. The tableau construction begins by instantiating A and then instanti-
ating the existential formula with a new constant:

7.5
Semantic Tableaux
147
∀x∃yp(x,y)
↓
∀x∃yp(x,y), ∃yp(a1,y)
↓
∀x∃yp(x,y), p(a1,a2).
Since A = ∀x∃yp(x,y) is universally quantiﬁed, it is not used up.
The new constant a2 is used to instantiate the universal formula A again; this
results in an existential formula which must be instantiated with a new constant a3:
∀x∃yp(x,y), p(a1,a2)
↓
∀x∃yp(x,y), ∃yp(a2,y), p(a1,a2)
↓
∀x∃yp(x,y), p(a2,a3), p(a1,a2).
The construction of this semantic tableau will not terminate and an inﬁnite branch
results. It is easy to see that there are models for A with inﬁnite domains, for exam-
ple, (N ,{<},{}).
The method of semantic tableaux is not a decision procedure for satisﬁability
in ﬁrst-order logic, because we can never know if a branch that does not close de-
ﬁnes an inﬁnite model or if it will eventually close, say, after one million further
applications of the tableau rules.
Example 7.36 is not very satisfactory because the formula ∀x∃yp(x,y) is sat-
isﬁable in a ﬁnite model, in fact, even in a model whose domain contains a single
element. We were being on the safe side in always choosing new constants to in-
stantiate existentially quantiﬁed formulas. Nevertheless, it is easy to ﬁnd formulas
that have no ﬁnite models, for example:
∀x∃yp(x,y) ∧∀x¬p(x,x) ∧∀x∀y∀z(p(x,y) ∧p(y,z) →p(x,z)).
Check that (N ,{<},{}) is an inﬁnite model for this formula; we leave it as an
exercise to show that the formula has no ﬁnite models.
An Open Branch with Universal Formulas May Terminate
Example 7.37 The ﬁrst two steps of the tableau for {∀xp(a,x)} are:
{∀xp(a,x)}
↓
{p(a,a),∀xp(a,x)}
↓
{p(a,a),∀xp(a,x)}.
There is no point in creating the same node again and again, so we specify that
this branch is ﬁnite and open. Clearly, ({a},{P = (a,a)},{a}) is a model for the
formula.

148
7
First-Order Logic: Formulas, Models, Tableaux
∀x∃yp(x,y) ∧∀x(q(x) ∧¬q(x))
↓
∀x∃yp(x,y), ∀x(q(x) ∧¬q(x))
↓
∀x∃yp(x,y), ∃yp(a1,y), ∀x(q(x) ∧¬q(x))
↓
∀x∃yp(x,y), p(a1,a2), ∀x(q(x) ∧¬q(x))
↓
∀x∃yp(x,y), ∃yp(a2,y), p(a1,a2), ∀x(q(x) ∧¬q(x))
↓
∀x∃yp(x,y), p(a2,a3), p(a1,a2), ∀x(q(x) ∧¬q(x))
Fig. 7.4 A tableau that should close, but doesn’t
The Tableau Construction Must Be Systematic
Example 7.38 The tableau in Fig. 7.4 is for the formula which is the conjunction
of ∀x∃yp(x,y), which we already know to be satisﬁable, together with the for-
mula ∀x(q(x) ∧¬q(x)), which is clearly unsatisﬁable. However, the branch can
be continued indeﬁnitely, because we are, in effect, choosing to apply rules only
to subformulas of ∀x∃yp(x,y), as we did in Example 7.36. This branch will never
close although the formula is unsatisﬁable. A systematic construction is needed to
make sure that rules are eventually applied to all the formulas labeling a node.
7.5.2 The Algorithm for Semantic Tableaux
The following deﬁnition extends a familiar concept from propositional logic:
Deﬁnition 7.39 A literal is a closed atomic formula p(a1,...,ak), an atomic for-
mula all of whose arguments are constants, or the negation of a closed atomic for-
mula ¬p(a1,...,ak). If A is p(a1,...,ak) then Ac = ¬p(a1,...,ak), while if A
is ¬p(a1,...,ak) then Ac = p(a1,...,ak).
The classiﬁcation of formulas in propositional logic as α and β formulas
(Sect. 2.6.2) is retained and we extend the classiﬁcation to formulas with quan-
tiﬁers. γ -formulas are universally quantiﬁed formulas ∀xA(x) and the negations
of existentially quantiﬁed formulas ¬∃xA(x), while δ-formulas are existentially
quantiﬁed formulas ∃xA(x) and the negations of universally quantiﬁed formulas
¬∀xA(x). The rules for these formulas are simply instantiation with a constant:
γ
γ (a)
∀xA(x)
A(a)
¬∃xA(x)
¬A(a)
δ
δ(a)
∃xA(x)
A(a)
¬∀xA(x)
¬A(a)

7.5
Semantic Tableaux
149
The algorithm for the construction of a semantic tableau in ﬁrst-order logic is
similar to that for propositional logic with the addition of rules for quantiﬁed for-
mulas, together with various constraints designed to avoid the problems were saw
in the examples.
Algorithm 7.40 (Construction of a semantic tableau)
Input: A formula φ of ﬁrst-order logic.
Output: A semantic tableau T for φ: each branch may be inﬁnite, ﬁnite and marked
open, or ﬁnite and marked closed.
A semantic tableau is a tree T where each node is labeled by a pair W(n) =
(U(n),C(n)), where:
U(n) = {An1,...,Ank}
is a set of formulas and:
C(n) = {cn1,...,cnm}
is a set of constants. C(n) contains the list of constants that appear in the formulas
in U(n). Of course, the sets C(n) could be created on-the-ﬂy from U(n), but the
algorithm in easier to understand if they explicitly label the nodes.
Initially, T consists of a single node n0, the root, labeled with
({φ},{a01,...,a0k}),
where {a01,...,a0k} is the set of constants that appear in φ. If φ has no constants,
take the ﬁrst constant a0 in the set A and label the node with ({φ},{a0}).
The tableau is built inductively by repeatedly choosing an unmarked leaf l la-
beled with W(l) = (U(l),C(l)), and applying the ﬁrst applicable rule in the follow-
ing list:
• If U(l) contains a complementary pair of literals, mark the leaf closed ×.
• If U(l) is not a set of literals, choose a formula A in U(l) that is an α-, β- or
δ-formula.
– If A is an α-formula, create a new node l′ as a child of l. Label l′ with:
W(l′) = ((U(l) −{A}) ∪{α1,α2}, C(l)).
(In the case that A is ¬¬A1, there is no α2.)
– If A is a β-formula, create two new nodes l′ and l′′ as children of l. Label l′
and l′′ with:
W(l′)
= ((U(l) −{A}) ∪{β1}, C(l)),
W(l′′) = ((U(l) −{A}) ∪{β2}, C(l)).
– If A is a δ-formula, create a new node l′ as a child of l and label l′ with:
W(l′) = ((U(l) −{A}) ∪{δ(a′)}, C(l) ∪{a′}),
where a′ is some constant that does not appear in U(l).

150
7
First-Order Logic: Formulas, Models, Tableaux
• Let {γl1,...,γlm} ⊆U(l) be all the γ -formulas in U(l) and let C(l) = {cl1,...,clk}.
Create a new node l′ as a child of l and label l′ with
W(l′) =

U(l) ∪
 m

i=1
k
j=1
γli(clj )

, C(l)

.
However, if U(l) consists only of literals and γ -formulas and if U(l′) as con-
structed would be the same as U(l), do not create node l′; instead, mark the leaf
l as open ⊙.
Compare the algorithm with the examples in Sect. 7.5.1. The phrase ﬁrst appli-
cable rule ensures that the construction is systematic. For δ-formulas, we added the
condition that a new constant be used in the instantiation. For γ -formulas, the for-
mula to which the rule is applied is not removed from the set U(l) when W(l′) is
created. The sentence beginning however in the rule for γ -formulas is intended to
take care of the case where no new formulas are produced by the application of the
rule.
Deﬁnition 7.41 A branch in a tableau is closed iff it terminates in a leaf marked
closed; otherwise (it is inﬁnite or it terminates in a leaf marked open), the branch is
open.
A tableau is closed if all of its branches are closed; otherwise (it has a ﬁnite or
inﬁnite open branch), the tableau is open.
Algorithm 7.40 is not a search procedure for a satisfying interpretation, because
it may choose to inﬁnitely expand one branch. Semantic tableaux in ﬁrst-order logic
can only be used to prove the validity of a formula by showing that a tableau for its
negation closes. Since all branches close in a closed tableau, the nondeterminism in
the application of the rules (choosing a leaf and choosing an α-, β- or γ -formula)
doesn’t matter.
7.6 Soundness and Completion of Semantic Tableaux
7.6.1 Soundness
The proof of the soundness of the algorithm for constructing semantic tableaux in
ﬁrst-order logic is a straightforward generalization of the one for propositional logic
(Sect. 2.7.2).
Theorem 7.42 (Soundness) Let φ be a formula in ﬁrst-order logic and let T be a
tableau for φ. If T closes, then φ is unsatisﬁable.
Proof The theorem is a special case of the following statement: if a subtree rooted
at a node n of T closes, the set of formulas U(n) is unsatisﬁable.

7.6
Soundness and Completion of Semantic Tableaux
151
The proof is by induction on the height h of n. The proofs of the base case
for h = 0 and the inductive cases 1 and 2 for α- and β-rules are the same as in
propositional logic (Sect. 2.6).
Case 3: The γ -rule was used. Then:
U(n) = U0 ∪{∀xA(x)}
and
U(n′) = U0 ∪{∀xA(x), A(a)},
for some set of formulas U0, where we have simpliﬁed the notation and explic-
itly considered only one formula.
The inductive hypothesis is that U(n′) is unsatisﬁable and we want to prove
that U(n) is also unsatisﬁable. Assume to the contrary that U(n) is satisﬁ-
able and let I be a model for U(n). Then vI (Ai) = T for all Ai ∈U0 and
also vI (∀xA(x)) = T . But U(n′) = U(n) ∪{A(a)}, so if we can show that
vI (A(a)) = T , this will contradict the inductive hypothesis that U(n′) is unsat-
isﬁable.
Now vI (∀xA(x)) = T iff vσI (A(x)) = T for all assignments σI , in particular
for any assignment that assigns the same domain element to x that I does to a,
so vI (A(a)) = T . By the tableau construction, a ∈C(n) and it appears in some
formula of U(n); therefore, I , a model of U(n), does, in fact, assign a domain
element to a.
Case 4: The δ-rule was used. Then:
U(n) = U0 ∪{∃xA(x)}
and
U(n′) = U0 ∪{A(a)},
for some set of formulas U0 and for some constant a that does not occur in any
formula of U(n).
The inductive hypothesis is that U(n′) is unsatisﬁable and we want to prove that
U(n) is also unsatisﬁable. Assume to the contrary that U(n) is satisﬁable and
let:
I = (D,{R1,...,Rn},{d1,...,dk})
be a model for U(n).
Now vI (∃xA(x)) = T iff vσI (A(x)) = T for some assignment σI , that is,
σI (x) = d for some d ∈D. Extend I to the interpretation:
I ′ = (D,{R1,...,Rn},{d1,...,dk,d})
by assigning d to the constant a. I ′ is well-deﬁned: since a does not occur in
U(n), it is not among the constants {a1,...,ak} already assigned {d1,...,dk}
in I . Since vI ′(U0) = vI (U0) = T , vI ′(A(a)) = T contradicts the inductive
hypothesis that U(n′) is unsatisﬁable.
7.6.2 Completeness
To prove the completeness of the algorithm for semantic tableaux we deﬁne a Hin-
tikka set, show that a (possibly inﬁnite) branch in a tableau is a Hintikka set and

152
7
First-Order Logic: Formulas, Models, Tableaux
then prove Hintikka’s Lemma that a Hintikka set can be extended to a model. We
begin with a technical lemma whose proof is left as an exercise.
Lemma 7.43 Let b be an open branch of a semantic tableau, n a node on b, and
A a formula in U(n). Then some rule is applied to A at node n or at a node m that
is a descendant of n on b. Furthermore, if A is a γ -formula and a ∈C(n), then
γ (a) ∈U(m′), where m′ is the child node created from m by applying a rule.
Deﬁnition 7.44 Let U be a set of closed formulas in ﬁrst-order logic. U is a Hin-
tikka set iff the following conditions hold for all formulas A ∈U:
1. If A is a literal, then either A ̸∈U or Ac ̸∈U.
2. If A is an α-formula, then α1 ∈U and α2 ∈U.
3. If A is a β-formula, then β1 ∈U or β2 ∈U.
4. If A is a γ -formula, then γ (c) ∈U for all constants c in formulas in U.
5. If A is a δ-formula, then δ(c) ∈U for some constant c.
Theorem 7.45 Let b be a (ﬁnite or inﬁnite) open branch of a semantic tableau and
let U = 
n∈b U(n). Then U is a Hintikka set.
Proof Let A ∈U. We show that the conditions for a Hintikka set hold.
Suppose that A is a literal. By the construction of the tableau, once a literal
appears in a branch, it is never deleted. Therefore, if A appears in a node n and Ac
appears in a node m which is a descendant of n, then A must also appear in m. By
assumption, b is open, so either A ̸∈U or Ac ̸∈U and condition 1 holds.
If A is not atomic and not a γ -formula, by Lemma 7.43 eventually a rule is
applied to A, and conditions 2, 3 and 5 hold.
Let A be a γ -formula that ﬁrst appears in U(n), let c be a constant that ﬁrst
appears in C(m) and let k = max(n,m). By the construction of the tableau, the
set of γ -formulas and the set of constants are non-decreasing along a branch, so
A ∈U(k) and c ∈C(k). By Lemma 7.43, γ (c) ∈U(k′) ⊆U, for some k′ > k.
Theorem 7.46 (Hintikka’s Lemma) Let U be a Hintikka set. Then there is a (ﬁnite
or inﬁnite) model for U.
Proof Let C = {c1,c2,...} be the set of constants in formulas of U. Deﬁne an inter-
pretation I as follows. The domain is the same set of symbols {c1,c2,...}. Assign
to each constant ci in U the symbol ci in the domain. For each n-ary predicate pi in
U, deﬁne an n-ary relation Ri by:
(ai1,...,ain) ∈Ri
if
p(ai1,...,ain) ∈U,
(ai1,...,ain) ̸∈Ri
if
¬p(ai1,...,ain) ∈U,
(ai1,...,ain) ∈Ri
otherwise.
The relations are well-deﬁned by condition 1 in the deﬁnition of Hintikka sets. We
leave as an exercise to show that I |= A for all A ∈U by induction on the structure
of A using the conditions deﬁning a Hintikka set.

7.7
Summary
153
Theorem 7.47 (Completeness) Let A be a valid formula. Then the semantic tableau
for ¬A closes.
Proof Let A be a valid formula and suppose that the semantic tableau for ¬A does
not close. By Deﬁnition 7.41, the tableau must contain a (ﬁnite or inﬁnite) open
branch b. By Theorem 7.45, U = 
n∈b U(n) is a Hintikka set and by Theorem 7.46,
there is a model I for U. But ¬A ∈U so I |= ¬A contradicting the assumption
that A is valid.
7.7 Summary
First-order logic adds variables and constants to propositional logic, together with
the quantiﬁers ∀(for all) and ∃(there exists). An interpretation includes a domain;
the predicates are interpreted as relations over elements of the domain, while con-
stants are interpreted as domain elements and variables in non-closed formulas are
assigned domain elements.
The method of semantic tableaux is sound and complete for showing that a
formula is unsatisﬁable, but it is not a decision procedure for satisﬁability, since
branches of a tableau may be inﬁnite. When a tableau is constructed, a universal
quantiﬁer followed by an existential quantiﬁer can result in an inﬁnite branch: the
existential formula is instantiated with a new constant and then the instantiation of
the universal formula results in a new occurrence of the existentially quantiﬁed for-
mula, and so on indeﬁnitely. There are formulas that are satisﬁable only in an inﬁnite
domain.
7.8 Further Reading
The presentation of semantic tableaux follows that of Smullyan (1968) although he
uses analytic tableaux. Advanced textbooks that also use tableaux are Nerode and
Shore (1997) and Fitting (1996).
7.9 Exercises
7.1 Find an interpretation which falsiﬁes ∃xp(x) →p(a).
7.2 Prove the statements left as exercises in Example 7.25:
• ∀xp(x) ∧∀xq(x) →∀x(p(x) ∧q(x)) is valid.
• ∀x(p(x) →q(x)) →(∀xp(x) →∀xq(x)) is a valid formula, but its converse
(∀xp(x) →∀xq(x)) →∀x(p(x) →q(x)) is not.

154
7
First-Order Logic: Formulas, Models, Tableaux
7.3 Prove that the following formulas are valid:
∃x(A(x) →B(x)) ↔(∀xA(x) →∃xB(x)),
(∃xA(x) →∀xB(x)) →∀x(A(x) →B(x)),
∀x(A(x) ∨B(x)) →(∀xA(x) ∨∃xB(x)),
∀x(A(x) →B(x)) →(∃xA(x) →∃xB(x)).
7.4 For each formula in the previous exercise that is an implication, prove that the
converse is not valid by giving a falsifying interpretation.
7.5 For each of the following formulas, either prove that it is valid or give a falsify-
ing interpretation.
∃x∀y((p(x,y) ∧¬p(y,x)) →(p(x,x) ↔p(y,y))),
∀x∀y∀z(p(x,x) ∧(p(x,z) →(p(x,y) ∨p(y,z)))) →∃y∀zp(y,z).
7.6 Suppose that we allowed the domain of an interpretation to be empty. What
would this mean for the equivalence:
∀yp(y,y) ∨∃xq(x,x) ≡∃x(∀yp(y,y) ∨q(x,x)).
7.7 Prove Theorem 7.22 on the relationship between a non-closed formula and its
closure.
7.8 Complete the semantic tableau construction for the negation of
∀x(p(x) ∨q(x)) →(∀xp(x) ∨∀xq(x)).
7.9 Prove that the formula (∀xp(x) →∀xq(x)) →∀x(p(x) →q(x)) is not valid by
constructing a semantic tableau for its negation.
7.10 Prove that the following formula has no ﬁnite models:
∀x∃yp(x,y) ∧∀x¬p(x,x) ∧∀x∀y∀z(p(x,y) ∧p(y,z) →p(x,z)).
7.11 Prove Lemma 7.43, the technical lemma used in the proof of the completeness
of the method of semantic tableaux.
7.12 Complete the proof of Lemma 7.46 that every Hintikka set has a model.
References
M. Fitting. First-Order Logic and Automated Theorem Proving (Second Edition). Springer, 1996.
A. Nerode and R.A. Shore. Logic for Applications (Second Edition). Springer, 1997.
R.M. Smullyan. First-Order Logic. Springer-Verlag, 1968. Reprinted by Dover, 1995.

Chapter 8
First-Order Logic: Deductive Systems
We extend the deductive systems G and H from propositional logic to ﬁrst-order
logic by adding axioms and rules of inference for the universal quantiﬁer. (The exis-
tential quantiﬁer is deﬁned as the dual of the universal quantiﬁer.) The construction
of semantic tableaux for ﬁrst-order logic included restrictions on the use of constants
and similar restrictions will be needed here.
8.1 Gentzen System G
Figure 8.1 is a closed semantic tableau for the negation of the valid formula
∀xp(x) ∨∀xq(x) →∀x(p(x) ∨q(x)).
The formulas to which rules are applied are underlined, while the sets of constants
C(n) in the labels of each node are implicit.
Let us turn the tree upside down and in every node n replace U(n), the set of
formulas labeling the node n, by ¯U(n), the set of complements of the formulas in
U(n). The result (Fig. 8.2) is a Gentzen proof for the formula.
Here is the classiﬁcation of quantiﬁed formulas into γ - and δ-formulas:
γ
γ (a)
∃xA(x)
A(a)
¬∀xA(x)
¬A(a)
δ
δ(a)
∀xA(x)
A(a)
¬∃xA(x)
¬A(a)
Deﬁnition 8.1 The Gentzen system G is a deductive system. Its axioms are sets of
formulas U containing a complementary pair of literals. The rules of inference are
the rules given for α- and β-formulas in Sect. 3.2, together with the following rules
for γ - and δ-formulas:
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_8, © Springer-Verlag London 2012
155

156
8
First-Order Logic: Deductive Systems
¬ (∀xp(x) ∨∀xq(x) →∀x(p(x) ∨q(x)))
↓
∀xp(x) ∨∀xq(x), ¬∀x(p(x) ∨q(x))
↙
↘
∀xp(x), ¬∀x(p(x) ∨q(x))
∀xq(x), ¬∀x(p(x) ∨q(x))
↓
↓
∀xp(x), ¬ (p(a) ∨q(a))
∀xq(x), ¬ (p(a) ∨q(a))
↓
↓
∀xp(x), ¬p(a), ¬q(a)
∀xq(x), ¬p(a), ¬q(a)
↓
↓
∀xp(x), p(a), ¬p(a), ¬q(a)
∀xq(x), q(a), ¬p(a), ¬q(a)
×
×
Fig. 8.1 Semantic tableau in ﬁrst-order logic
U ∪{γ,γ (a)}
U ∪{γ }
,
U ∪{δ(a)}
U ∪{δ} .
The rule for δ-formulas can be applied only if the constant a does not occur in any
formula of U.
The γ -rule can be read: if an existential formula and some instantiation of it are
true, then the instantiation is redundant.
The δ-rules formalizes the following frequently used method of mathematical
reasoning: Let a be an arbitrary constant. Suppose that A(a) can be proved. Since
a was arbitrary, the proof holds for ∀xA(x). In order to generalize from a speciﬁc
constant to for all, it is essential that a be an arbitrary constant and not one of the
constants that is constrained by another subformula.
¬∀xp(x), ¬p(a), p(a), q(a)
¬∀xq(x), ¬q(a), p(a), q(a)
↓
↓
¬∀xp(x), p(a), q(a)
¬∀xq(x), p(a), q(a)
↓
↓
¬∀xp(x), p(a) ∨q(a)
¬∀xq(x), p(a) ∨q(a)
↓
↓
¬∀xp(x), ∀x(p(x) ∨q(x))
¬∀xq(x), ∀x(p(x) ∨q(x))
↘
↙
¬ (∀xp(x) ∨∀xq(x)), ∀x(p(x) ∨q(x))
↓
∀xp(x) ∨∀xq(x) →∀x(p(x) ∨q(x))
Fig. 8.2 Gentzen proof tree in ﬁrst-order logic

8.1
Gentzen System G
157
¬∀yp(a,y), ¬p(a,b), ∃xp(x,b), p(a,b)
↓
¬∀yp(a,y), ∃xp(x,b), p(a,b)
↓
¬∀yp(a,y), ∃xp(x,b)
↓
¬∀yp(a,y), ∀y∃xp(x,y)
↓
¬∃x∀yp(x,y), ∀y∃xp(x,y)
↓
∃x∀yp(x,y) →∀y∃xp(x,y)
Fig. 8.3 Gentzen proof: use rules for γ -formulas followed by rules for δ-formulas
Example 8.2 The proof of ∃x∀yp(x,y) →∀y∃xp(x,y) in Fig. 8.3 begins with the
axiom obtained from the complementary literals ¬p(a,b) and p(a,b). Then the
rule for the γ -formulas is used twice:
U,¬∀yp(a,y),¬p(a,b)
U,¬∀yp(a,y)
,
U,∃xp(x,b),p(a,b)
U,∃xp(x,b)
.
Once this is done, it is easy to apply rules for the δ-formulas because the constants
a and b appear only once so that the condition in the rule is satisﬁed:
U,∃xp(x,b)
U,∀y∃xp(x,y),
U,¬∀yp(a,y)
U,¬∃x∀y∃xp(x,y).
A ﬁnal application of the rule for the α-formula completes the proof.
We leave the proof of the soundness and completeness of G as an exercise.
Theorem 8.3 (Soundness and completeness) Let U be a set of formulas in ﬁrst-
order logic. There is a Gentzen proof for U if and only if there is a closed semantic
tableau for ¯U.

158
8
First-Order Logic: Deductive Systems
8.2 Hilbert System H
The Hilbert system H for propositional logic is extended to ﬁrst-order logic by
adding two axioms and a rule of inference.
Deﬁnition 8.4 The axioms of the Hilbert system H for ﬁrst-order logic are:
Axiom 1
⊢(A →(B →A)),
Axiom 2
⊢(A →(B →C)) →((A →B) →(A →C)),
Axiom 3
⊢(¬B →¬A) →(A →B),
Axiom 4
⊢∀xA(x) →A(a),
Axiom 5
⊢∀x(A →B(x)) →(A →∀xB(x)).
• In Axioms 1, 2 and 3, A, B and C are any formulas of ﬁrst-order logic.
• In Axiom 4, A(x) is a formula with a free variable x.
• In Axiom 5, B(x) is a formula with a free variable x, while x is not a free variable
of the formula A.
The rules of inference are modus ponens and generalization:
⊢A →B
⊢A
⊢B
,
⊢A(a)
⊢∀xA(x).
Propositional Reasoning in First-Order Logic
Axioms 1, 2, 3 and the rule of inference MP are generalized to any formulas in ﬁrst-
order logic so all of the theorems and derived rules of inference that we proved in
Chap. 3 can be used in ﬁrst-order logic.
Example 8.5
⊢∀xp(x) →(∃y∀xq(x,y) →∀xp(x))
is an instance of Axiom 1 in ﬁrst-order logic and:
⊢∀xp(x) →(∃y∀xq(x,y) →∀xp(x))
⊢∀xp(x)
⊢∃y∀xq(x,y) →∀xp(x)
uses the rule of inference modus ponens.
In the proofs in this chapter, we will not bother to give the details of deductions
that use propositional reasoning because these are easy to understand. The notation
PC will be used for propositional deductions.

8.2
Hilbert System H
159
Specialization and Generalization
Axiom 4 can also be used as a rule of inference:
Rule 8.6 (Axiom 4)
U ⊢∀xA(x)
U ⊢A(a) .
Any occurrence of ∀xA(x) can be replaced by A(a) for any a. If A(x) is true
whatever the assignment of a domain element of an interpretation I to x, then
A(a) is true for the domain element that I assigns to a.
The generalization rule of inference states that if a occurs in a formula, we may
bind all occurrences of a with the quantiﬁer. Since a is arbitrary, that is the same as
saying that A(x) is true for all assignments to x.
There is a reason that the generalization rule was given only for formulas that
can be proved without a set of assumptions U:
⊢A(a)
⊢∀xA(x).
Example 8.7 Suppose that we were allowed to apply generalization to A(a) ⊢A(a)
to obtain A(a) ⊢∀xA(x) and consider the interpretation:
(Z ,{even(x)},{2}).
The assumption A(a) is true but ∀xA(x) is not, which means that generalization is
not sound as it transforms A(a) |= A(a) into A(a) ̸|= ∀xA(x).
Since proofs invariably have assumptions, a constraint must be placed on the
generalization rule to make it useful:
Rule 8.8 (Generalization)
U ⊢A(a)
U ⊢∀xA(x),
provided that a does not appear in U.
The Deduction Rule
The Deduction rule is essential for proving theorems from assumptions.
Rule 8.9 (Deduction rule)
U ∪{A} ⊢B
U ⊢A →B .

160
8
First-Order Logic: Deductive Systems
Theorem 8.10 (Deduction Theorem) The deduction rule is sound.
Proof The proof is by induction on the length of the proof of U ∪{A} ⊢B. We must
show how to obtain a proof of U ⊢A →B that does not use the deduction rule. The
proof for propositional logic (Theorem 3.14) is modiﬁed to take into account the
new axioms and generalization.
The modiﬁcation for the additional axioms is trivial.
Consider now an application of the generalization rule, where, without loss of
generality, we assume that the generalization rule is applied to the immediately pre-
ceding formula in the proof:
i
U ∪{A} ⊢B(a)
i + 1
U ∪{A} ⊢∀xB(x)
Generalization
By the condition on the generalization rule in the presence of assumptions, a does
not appear in either U or A.
The proof that the deduction rule is sound is as follows:
i
U ∪{A} ⊢B(a)
i′
U ⊢A →B(a)
Inductive hypothesis, i
i′ + 1
U ⊢∀x(A →B)
Generalization, i′
i′ + 2
U ⊢∀x(A →B) →(A →∀xB)
Axiom 5
i′ + 3
U ⊢A →∀xB
MP, i′ + 1, i′ + 2
The fact that a does not appear in U is used in line i′ + 1 and the fact that a does
not appear in A is used in line i′ + 2.
8.3 Equivalence of H and G
We prove that any theorem that can be proved in G can also be proved in H .
We already know how to transform propositional proofs in G to proofs in H ; what
remains is to show that any application of the γ - and δ-rules in G can be transformed
into a proof in H .
Theorem 8.11 The rule for a γ -formula can be simulated in H .
Proof Suppose that the rule:
U ∨¬∀xA(x) ∨¬A(a)
U ∨¬∀xA(x)
was used. This can be simulated in H as follows:
1.
⊢∀xA(x) →A(a)
Axiom 4
2.
⊢¬∀xA(x) ∨A(a)
PC 1
3.
⊢U ∨¬∀xA(x) ∨A(a)
PC 2
4.
⊢U ∨¬∀xA(x) ∨¬A(a)
Assumption
5.
⊢U ∨¬∀xA(x)
PC 3, 4

8.4
Proofs of Theorems in H
161
Theorem 8.12 The rule for a δ-formula can be simulated in H .
Proof Suppose that the rule:
U ∨A(a)
U ∨∀xA(x)
was used. This can be simulated in H as follows:
1.
⊢U ∨A(a)
Assumption
2.
⊢¬U →A(a)
PC 1
3.
⊢∀x(¬U →A(x))
Gen. 2
4.
⊢∀x(¬U →A(x)) →(¬U →∀xA(x))
Axiom 5
5.
⊢¬U →∀xA(x)
MP 3, 4
6.
⊢U ∨∀xA(x)
PC 5
The use of Axiom 5 requires that a not occur in U, but we know that this holds by
the corresponding condition on the rule for the δ-formula.
Simulations in G of proofs in H are left as an exercise. From this follows:
Theorem 8.13 (Soundness and completeness) The Hilbert system H is sound and
complete.
8.4 Proofs of Theorems in H
We now give a series of theorems and proofs in H .
The ﬁrst two are elementary theorems using existential quantiﬁers.
Theorem 8.14 ⊢A(a) →∃xA(x).
Proof
1.
⊢∀x¬A(x) →¬A(a)
Axiom 4
2.
⊢A(a) →¬∀x¬A(x)
PC 1
3.
⊢A(a) →∃xA(x)
Deﬁnition ∃
Theorem 8.15 ⊢∀xA(x) →∃xA(x).
Proof
1.
∀xA(x) ⊢∀xA(x)
Assumption
2.
∀xA(x) ⊢A(a)
Axiom 4
3.
∀xA(x) ⊢A(a) →∃xA(x)
Theorem 8.14
4.
∀xA(x) ⊢∃xA(x)
MP 2, 3
5.
⊢∀xA(x) →∃xA(x)
Deduction

162
8
First-Order Logic: Deductive Systems
Theorem 8.16 ⊢∀x(A(x) →B(x)) →(∀xA(x) →∀xB(x)).
Proof
1.
∀x(A(x) →B(x)), ∀xA(x) ⊢∀xA(x)
Assumption
2.
∀x(A(x) →B(x)), ∀xA(x) ⊢A(a)
Axiom 4
3.
∀x(A(x) →B(x)), ∀xA(x) ⊢∀x(A(x) →B(x))
Assumption
4.
∀x(A(x) →B(x)), ∀xA(x) ⊢A(a) →B(a)
Axiom 4
5.
∀x(A(x) →B(x)), ∀xA(x) ⊢B(a)
PC 2, 4
6.
∀x(A(x) →B(x)), ∀xA(x) ⊢∀xB(x)
Gen. 5
7.
∀x(A(x) →B(x)) ⊢∀xA(x) →∀xB(x)
Deduction
8.
⊢∀x(A(x) →B(x)) →(∀xA(x) →∀xB(x))
Deduction
Rule 8.17 (Generalization)
⊢A(a) →B(a)
⊢∀xA(x) →∀xB(x).
The next theorem was previously proved in the Gentzen system. Make sure that
you understand why Axiom 5 can be used.
Theorem 8.18 ⊢∃x∀yA(x,y) →∀y∃xA(x,y).
Proof
1.
⊢A(a,b) →∃xA(x,b)
Theorem 8.14
2.
⊢∀yA(a,y) →∀y∃xA(x,y)
Gen 1
3.
⊢¬∀y∃xA(x,y) →¬∀yA(a,y)
PC 2
4.
⊢∀x(¬∀y∃xA(x,y) →¬∀yA(x,y))
Gen. 3
5.
⊢(∀x(¬∀y∃xA(x,y) →¬∀yA(x,y)))→
(¬∀y∃xA(x,y) →∀x¬∀yA(x,y))
Axiom 5
6.
⊢¬∀y∃xA(x,y) →∀x¬∀yA(x,y)
MP 4, 5
7.
⊢¬∀x¬∀yA(x,y) →∀y∃xA(x,y)
PC 6
8.
⊢∃x∀yA(x,y) →∀y∃xA(x,y)
Deﬁnition of ∃
The proof of the following theorem is left as an exercise:
Theorem 8.19 Let A be a formula that does not have x as a free variable.
⊢∀x(A →B(x)) ↔(A →∀xB(x)),
⊢∃x(A →B(x)) ↔(A →∃xB(x)).

8.5
The C-Rule *
163
The name of a bound variable can be changed if necessary:
Theorem 8.20 ⊢∀xA(x) ↔∀yA(y).
Proof
1.
⊢∀xA(x) →A(a)
Axiom 4
2.
⊢∀y(∀xA(x) →A(y))
Gen. 1
3.
⊢∀xA(x) →∀yA(y)
Axiom 5
4.
⊢∀yA(y) →∀xA(x)
Similarly
5.
⊢∀xA(x) ↔∀yA(y)
PC 3, 4
The next theorem shows a non-obvious relation between the quantiﬁers.
Theorem 8.21 Let B be a formula that does not have x as a free variable.
⊢∀x(A(x) →B) ↔(∃xA(x) →B).
Proof
1.
∀x(A(x) →B) ⊢∀x(A(x) →B)
Assumption
2.
∀x(A(x) →B) ⊢∀x(¬B →¬A(x))
Exercise
3.
∀x(A(x) →B) ⊢¬B →∀x¬A(x)
Axiom 5
4.
∀x(A(x) →B) ⊢¬∀x¬A(x) →B
PC 3
5.
∀x(A(x) →B) ⊢∃xA(x) →B
Deﬁnition of ∃
6.
⊢∀x(A(x) →B) →(∃xA(x) →B)
Deduction
7.
∃xA(x) →B ⊢∃xA(x) →B
Assumption
8.
∃xA(x) →B ⊢¬∀x¬A(x) →B
Deﬁnition of ∃
9.
∃xA(x) →B ⊢¬B →∀x¬A(x)
PC 8
10.
∃xA(x) →B ⊢∀x(¬B →¬A(x))
Theorem 8.19
11.
∃xA(x) →B ⊢∀x(A(x) →B)
Exercise
12.
⊢∀x(A(x) →B) ↔(∃xA(x) →B)
PC 6, 11
8.5 The C-Rule *
The C-rule is a rule of inference that is useful in proofs of existentially quantiﬁed
formulas. The rule is the formalization of the argument: if there exists an object
satisfying a certain property, let a be that object.

164
8
First-Order Logic: Deductive Systems
Deﬁnition 8.22 (C-Rule) The following rule may be used in a proof:
i
U ⊢∃xA(x)
(an existentially quantiﬁed formula)
i + 1
U ⊢A(a)
C-rule
provided that
• The constant a is new and does not appear in steps 1,...,i of the proof.
• Generalization is never applied to a free variable or constant in the formula to
which the C-rule is applied:
i
U ⊢∃xA(x,y)
(an existentially quantiﬁed formula)
i + 1
U ⊢A(a,y)
C-rule
···
j
U ⊢∀yA(a,y)
Illegal!
For a proof that the rule is sound, see Mendelson (2009, Proposition 2.10).
We use the C-Rule to give a more intuitive proof of Theorem 8.18.
Theorem 8.23 ⊢∃x∀yA(x,y) →∀y∃xA(x,y)
Proof
1.
∃x∀yA(x,y) ⊢∃x∀yA(x,y)
Assumption
2.
∃x∀yA(x,y) ⊢∀yA(a,y)
C-Rule
3.
∃x∀yA(x,y) ⊢A(a,b)
Axiom 4
4.
∃x∀yA(x,y) ⊢∃xA(x,b)
Theorem 8.14
5.
∃x∀yA(x,y) ⊢∀y∃xA(x,y)
Gen. 4
6.
⊢∃x∀yA(x,y) →∀y∃xA(x,y)
Deduction
The conditions in the C-rule are necessary. The ﬁrst condition is similar to the
condition on the deduction rule. The second condition is needed so that a formula
that is true for one speciﬁc constant is not generalized for all values of a variable.
Without the condition, we could prove the converse of Theorem 8.18, which is not
a valid formula:
1.
∀x∃yA(x,y) ⊢∀x∃yA(x,y)
Assumption
2.
∀x∃yA(x,y) ⊢∃yA(a,y)
Axiom 4
3.
∀x∃yA(x,y) ⊢A(a,b)
C-rule
4.
∀x∃yA(x,y) ⊢∀xA(x,b)
Generalization (illegal!)
5.
∀x∃yA(x,y) ⊢∃y∀xA(x,y)
Theorem 8.14
6.
⊢∀x∃yA(x,y) →∃y∀xA(x,y)
Deduction

8.6
Summary
165
8.6 Summary
Gentzen and Hilbert deductive systems were deﬁned for ﬁrst-order logic. They are
sound and complete. Be careful to distinguish between completeness and decid-
ability. Completeness means that every valid formula has a proof. We can discover
the proof by constructing a semantic tableau for its negation. However, we cannot
decide if an arbitrary formula is valid and provable.
8.7 Further Reading
Our presentation is adapted from Smullyan (1968) and Mendelson (2009). Chap-
ter X of (Smullyan, 1968) compares various proofs of completeness.
8.8 Exercises
8.1 Prove in G :
⊢∀x(p(x) →q(x)) →(∃xp(x) →∃xq(x)),
⊢∃x(p(x) →q(x)) ↔(∀xp(x) →∃xq(x)).
8.2 Prove the soundness and completeness of G (Theorem 8.3).
8.3 Prove that Axioms 4 and 5 are valid.
8.4 Show that a proof in H can be simulated in G .
8.5 Prove in H : ⊢∀x(p(x) →q) ↔∀x(¬q →¬p(x)).
8.6 Prove in H : ⊢∀x(p(x) ↔q(x)) →(∀xp(x) ↔∀xq(x)).
8.7 Prove the theorems of Exercise 8.1 in H .
8.8 Prove Theorem 8.19 in H . Let A be a formula that does not have x as a free
variable.
⊢∀x(A →B(x)) ↔(A →∀xB(x)),
⊢∃x(A →B(x)) ↔(A →∃xB(x)).
8.9 Let A be a formula built from the quantiﬁers and the Boolean operators ¬, ∨, ∧
only. A′, the dual of A is obtained by exchanging ∀and ∃and exchanging ∨and ∧.
Prove that ⊢A iff ⊢¬A′.

166
8
First-Order Logic: Deductive Systems
References
E. Mendelson. Introduction to Mathematical Logic (Fifth Edition). Chapman & Hall/CRC, 2009.
R.M. Smullyan. First-Order Logic. Springer-Verlag, 1968. Reprinted by Dover, 1995.

Chapter 9
First-Order Logic: Terms and Normal Forms
The formulas in ﬁrst-order logic that we have deﬁned are sufﬁcient to express many
interesting properties. Consider, for example, the formula:
∀x∀y∀z(p (x,y) ∧p (y,z) →p (x,z)).
Under the interpretation:
{Z ,{<},{}},
it expresses the true statement that the relation less-than is transitive in the domain
of the integers. Suppose, now, that we want to express the following statement which
is also true in the domain of integers:
for all x,y,z : (x < y) →(x + z < y + z).
The difference between this statement and the previous one is that it uses the func-
tion +.
Section 9.1 presents the extension of ﬁrst-order logic to include functions. In
Sect. 9.2, we describe a canonical form of formulas called prenex conjunctive nor-
mal form, which extends CNF to ﬁrst-order logic. It enables us to deﬁne formulas as
sets of clauses and to perform resolution on the clauses. In Sects. 9.3, 9.4, we show
that canonical interpretations can be deﬁned from syntactical objects like predicate
and function letters.
9.1 First-Order Logic with Functions
9.1.1 Functions and Terms
Recall (Deﬁnition 7.8) that atomic formulas consist of an n-ary predicate followed
by a list of n arguments that are variables and constants. We now generalize the
arguments to include terms built from functions.
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_9, © Springer-Verlag London 2012
167

168
9
First-Order Logic: Terms and Normal Forms
Deﬁnition 9.1 Let F be a countable set of function symbols, where each symbol
has an arity denoted by a superscript. Terms are deﬁned recursively as follows:
• A variable, constant or 0-ary function symbol is a term.
• If f n is an n-ary function symbol (n > 0) and {t1,t2,...,tn} are terms, then
f n(t1,t2,...,tn) is a term.
An atomic formula is an n-ary predicate followed by a list of n arguments where
each argument ti is a term: p(t1,t2,...,tn).
Notation
• We drop the word ‘symbol’ and use the word ‘function’ alone with the under-
standing that these are syntactical symbols only.
• By convention, functions are denoted by {f,g,h} possibly with subscripts.
• The superscript denoting the arity of the function will not be written since the
arity can be inferred from the number of arguments.
• Constant symbols are no longer needed since they are the same as 0-ary functions;
nevertheless, we retain them since it is more natural to write p(a,b) than to write
p(f1,f2).
Example 9.2 Examples of terms are
a,
x,
f (a,x),
f (g(x),y),
g(f (a,g(b))),
and examples of atomic formulas are
p(a,b),
p(x,f (a,x)),
q(f (a,a),f (g(x),g(x))).
9.1.2 Formal Grammar *
The following grammar deﬁnes terms and a new rule for atomic formulas:
term
::= x
for any x ∈V
term
::= a
for any a ∈A
term
::= f 0
for any f 0 ∈F
term
::= f n(term_list)
for anyf n ∈F
term_list
::= term
term_list
::= term,term_list
atomic_formula ::= p (term_list)
for any p ∈P.
It is required that the number of elements in a term_list be equal to the arity of the
function or predicate symbol that is applied to the list.

9.1
First-Order Logic with Functions
169
9.1.3 Interpretations
The deﬁnition of interpretation in ﬁrst-order logic is extended so that function sym-
bols are interpreted by functions over the domain.
Deﬁnition 9.3 Let U be a set of formulas such that {p1,...,pk} are all the predicate
symbols, {f n1
1 ,...,f nl
l } are all the function symbols and {a1,...,am} are all the
constant symbols appearing in U. An interpretation I is a 4-tuple:
I = (D, {R1,...,Rk}, {F n1
1 ,...,F nl
l }, {d1,...,dm}),
consisting of a non-empty domain D, an assignment of an ni-ary relation Ri on
D to the ni-ary predicate symbols pi for 1 ≤i ≤k, an assignment of an nj-ary
function F
nj
j
on D to the function symbol f
nj
j
for 1 ≤j ≤l, and an assignment of
an element dn ∈D to the constant symbol an for 1 ≤n ≤m.
The rest of the semantical deﬁnitions in Sect. 7.3 go through unchanged, except
for the meaning of an atomic formula. We give an outline and we leave the details as
an exercise. In an interpretation I , let DI be a map from terms to domain elements
that satisﬁes:
DI (fi(t1,...,tn)) = Fi(DI (t1),...,DI (tn)).
Given an atomic formula A = pk(t1,...,tn), vσI (A) = T iff
(DI (t1),...,DI (dn)) ∈Rk.
Example 9.4 Consider the formula:
A = ∀x∀y(p(x,y) →p(f (x,a),f (y,a))).
We claim that the formula is true in the interpretation:
(Z , {≤}, {+}, {1}).
For arbitrary m,n ∈Z assigned to x,y:
DI (f (x,a)) = +(DI (x),DI (a)) = +(m,1) = m + 1,
DI (f (y,a)) = +(DI (y),DI (a)) = +(n,1) = n + 1,
where we have changed to inﬁx notation. p is assigned to the relation ≤by I and
m ≤n implies m + 1 ≤n + 1 in Z , so the formula is true for this assignment. Since
m and n were arbitrary, the quantiﬁed formula A is true in this interpretation.
Here is another interpretation for the same formula A:
({S ∗}, {sufﬁx}, {·}, {tuv}),

170
9
First-Order Logic: Terms and Normal Forms
where S ∗is the set of strings over some alphabet S , sufﬁx is the relation such
that (s1,s2) ∈sufﬁx iff s1 is a sufﬁx of s2, · is the function that concatenates its
arguments, and tuv is a string. The formula A is true for arbitrary s1 and s2 assigned
to x and y. For example, if x is assigned def and y is assigned abcdef, then
deftuv is a sufﬁx of abcdeftuv.
A is not valid since it is falsiﬁed by the interpretation:
(Z ,{>},{·},{−1}).
Obviously, 5 > 4 does not imply 5 · (−1) > 4 · (−1).
9.1.4 Semantic Tableaux
The algorithm for building semantic tableaux for formulas of ﬁrst-order logic with
function symbols is almost the same as Algorithm 7.40 for ﬁrst-order logic with
constant symbols only. The difference is that any term, not just a constant, can be
substituted for a variable. Deﬁnition 7.39 of a literal also needs to be generalized.
Deﬁnition 9.5
• A ground term is a term which does not contain any variables.
• A ground atomic formula is an atomic formula, all of whose terms are ground.
• A ground literal is a ground atomic formula or the negation of one.
• A ground formula is a quantiﬁer-free formula, all of whose atomic formula are
ground.
• A is a ground instance of a quantiﬁer-free formula A′ iff it can be obtained from
A′ by substituting ground terms for the (free) variables in A′.
Example 9.6 The terms a, f (a,b), g(b,f (a,b)) are ground. p(f (a,b),a) is a
ground atomic formula and ¬p(f (a,b),a) is a ground literal. p(f (x,y),a) is not
a ground atomic formula because of the variables x,y.
The construction of the semantic tableaux can be modiﬁed for formulas with
functions. The rule for δ-formulas, which required that a set of formulas be instanti-
ated with a new constant, must be replaced with a requirement that the instantiation
be done with a new ground term. Therefore, we need to ensure that there exists
an enumeration of ground terms. By deﬁnition, the sets of constant symbols and
function symbols were assumed to be countable, but we must show that the set of
ground terms constructed from them are also countable. The proof will be familiar
to readers who have seen a proof that the set of rational is countable.
Theorem 9.7 The set of ground terms is countable.
Proof To simplify the notation, identify the constant symbols with the 0-ary func-
tion symbols. By deﬁnition, the set of function symbols is countable:

9.1
First-Order Logic with Functions
171
{f0, f1, f2, f3, ...}.
Clearly, for every n, there is a ﬁnite number kn of ground terms of height at most n
that can be constructed from the ﬁrst n function symbols {f0,...,fn}, where by the
height of a formula we mean the height of its tree representation. For each n, place
these terms in a sequence T n = (tn
1 ,tn
2 ,...,tn
kn). The countable enumeration of all
ground terms is obtained by concatenating these sequences:
t0
1,...,t0
k0,
t1
1,...,t1
k1,
t2
1,...,t2
k2,
....
Example 9.8 Let the ﬁrst four function symbols be {a,b,f,g,...}, where f is unary
and g is binary. Figure 9.1 shows the ﬁrst four sequences of ground terms (without
duplicates). The point is not that one would actually carry out this construction; we
only need the theoretical result that such an enumeration is possible.
n = 1
a
n = 2
b
n = 3
f (a), f (b), f (f (a)), f (f (b))
n = 4
f (f (f (a))), f (f (f (b))),
g(a,a), g(a,b), g(a,f (a)), g(a,f (b)), g(a,f (f (a))), g(a,f (f (b))),
six similar terms with b as the ﬁrst argument of g,
g(f (a),a), g(f (a),b), g(f (a),f (a)), g(f (a),f (b)),
g(f (a),f (f (a))), g(f (a),f (f (b))),
six similar terms with f (b) as the ﬁrst argument of g,
g(f (f (a)),a), g(f (f (a)),b), g(f (f (a)),f (a)), g(f (f (a)),f (b)),
g(f (f (a)),f (f (a))), g(f (f (a)),f (f (b))),
six similar terms with f (f (b)) as the ﬁrst argument of g,
f (g(a,a)), f (g(a,b)), f (g(a,f (a)), f (g(a,f (b)),
twelve similar terms with b,f (a),f (b) as the ﬁrst argument of g,
f (f (g(a,a))), f (f (g(a,b))), f (f (g(b,a))), f (f (g(b,b))).
Fig. 9.1 Finite sequences of terms

172
9
First-Order Logic: Terms and Normal Forms
9.2 PCNF and Clausal Form
Recall that a formula of propositional logic is in conjunctive normal form (CNF) iff
it is a conjunction of disjunctions of literals. A notational variant of CNF is clausal
form: the formula is represented as a set of clauses, where each clause is a set of
literals. We now proceed to generalize CNF to ﬁrst-order logic by deﬁning a normal
form that takes the quantiﬁers into account.
Deﬁnition 9.9 A formula is in prenex conjunctive normal form (PCNF) iff it is of
the form:
Q1x1 ···QnxnM
where the Qi are quantiﬁers and M is a quantiﬁer-free formula in CNF. The se-
quence Q1x1 ···Qnxn is the preﬁx and M is the matrix.
Example 9.10 The following formula is in PCNF:
∀y∀z([p(f (y)) ∨¬p(g(z)) ∨q(z)] ∧[¬q(z) ∨¬p(g(z)) ∨q(y)]).
Deﬁnition 9.11 Let A be a closed formula in PCNF whose preﬁx consists only of
universal quantiﬁers. The clausal form of A consists of the matrix of A written as a
set of clauses.
Example 9.12 The formula in Example 9.10 is closed and has only universal quan-
tiﬁers, so it can be written in clausal form as:
{{p(f (y)), ¬p(g(z)), q(z)}, {¬q(z), ¬p(g(z)), q(y)}}.
9.2.1 Skolem’s Theorem
In propositional logic, every formula is equivalent to one in CNF, but this is not true
in ﬁrst-order logic. However, a formula in ﬁrst-order logic can be transformed into
one in clausal form without modifying its satisﬁability.
Theorem 9.13 (Skolem) Let A be a closed formula. Then there exists a formula A′
in clausal form such that A ≈A′.
Recall that A ≈A′ means that A is satisﬁable if and only if A′ is satisﬁable; that
is, there exists a model for A if and only if there exists a model for A′. This is not
the same as logically equivalence A ≡A′, which means that for all models I , I
is a model for A if and only if it is a model for A′.
It is straightforward to transform A into a logically equivalent formula in PCNF.
It is the removal of the existential quantiﬁers that causes the new formula not to be
equivalent to the old one. The removal is accomplished by deﬁning new function

9.2
PCNF and Clausal Form
173
symbols. In A = ∀x∃yp(x,y), the quantiﬁers can be read: for all x, produce a value
y associated with that x such that the predicate p is true. But our intuitive concept
of a function is the same: y = f (x) means that given x, f produces a value y asso-
ciated with x. The existential quantiﬁer can be removed giving A′ = ∀xp(x,f (x)).
Example 9.14 Consider the interpretation:
I = (Z ,{>},{})
for the PCNF formula A = ∀x∃yp(x,y). Obviously, I |= A.
The formula A′ = ∀xp(x,f (x)) is obtained from A by removing the existential
quantiﬁer and replacing it with a function. Consider the following interpretation:
I ′ = (Z ,{>},{F(x) = x + 1}).
Clearly, I ′ |= A (just ignore the function), but I ′ ̸|= A′ since it is not true that
n > n + 1 for all integers (in fact, for any integer). Therefore, A′ ̸≡A.
However, there is a model for A′, for example:
I ′′ = (Z ,{>},{F(x) = x −1}).
The introduction of function symbols narrows the choice of models. The relations
that interpret predicate symbols are many-many, that is, each x may be related to
several y, while functions are many-one, that is, each x is related (mapped) to a
single y, although different x’s may be mapped into a single y. For example, if:
R = {(1,1),(1,2),(1,3),(2,1),(2,2),(2,3)},
then when trying to satisfy A, the whole relation R can be used, but for the clausal
form A′, only a functional subset of R such as {(1,2),(2,3)} or {(1,2),(2,2)} can
be used to satisfy A′.
9.2.2 Skolem’s Algorithm
We now give an algorithm to transform a formula A into a formula A′ in clausal
form and then prove that A ≈A′. The description of the transformation will be
accompanied by a running example using the formula:
∀x(p(x) →q(x)) →(∀xp(x) →∀xq(x)).
Algorithm 9.15
Input: A closed formula A of ﬁrst-order logic.
Output: A formula A′ in clausal form such that A ≈A′.

174
9
First-Order Logic: Terms and Normal Forms
• Rename bound variables so that no variable appears in two quantiﬁers.
∀x(p(x) →q(x)) →(∀yp(y) →∀zq(z)).
• Eliminate all binary Boolean operators other than ∨and ∧.
¬∀x(¬p(x) ∨q(x)) ∨¬∀yp(y) ∨∀zq(z).
• Push negation operators inward, collapsing double negation, until they apply to
atomic formulas only. Use the equivalences:
¬∀xA(x) ≡∃x¬A(x),
¬∃xA(x) ≡∀x¬A(x).
The example formula is transformed to:
∃x(p(x) ∧¬q(x)) ∨∃y¬p(y) ∨∀zq(z).
• Extract quantiﬁers from the matrix. Choose an outermost quantiﬁer, that is, a
quantiﬁer in the matrix that is not within the scope of another quantiﬁer still in
the matrix. Extract the quantiﬁer using the following equivalences, where Q is a
quantiﬁer and op is either ∨or ∧:
A op QxB(x) ≡Qx(A op B(x)),
QxA(x) op B ≡Qx(A(x) op B).
Repeat until all quantiﬁers appear in the preﬁx and the matrix is quantiﬁer-free.
The equivalences are applicable because since no variable appears in two quanti-
ﬁers. In the example, no quantiﬁer appears within the scope of another, so we can
extract them in any order, for example, x,y,z:
∃x∃y∀z((p(x) ∧¬q(x)) ∨¬p(y) ∨q(z)).
• Use the distributive laws to transform the matrix into CNF. The formula is now
in PCNF.
∃x∃y∀z((p(x) ∨¬p(y) ∨q(z)) ∧(¬q(x) ∨¬p(y) ∨q(z))).
• For every existential quantiﬁer ∃x in A, let y1,...,yn be the universally quan-
tiﬁed variables preceding ∃x and let f be a new n-ary function symbol. Delete
∃x and replace every occurrence of x by f (y1,...,yn). If there are no univer-
sal quantiﬁers preceding ∃x, replace x by a new constant (0-ary function). These
new function symbols are Skolem functions and the process of replacing existen-
tial quantiﬁers by functions is Skolemization. For the example formula we have:
∀z((p(a) ∨¬p(b) ∨q(z)) ∧(¬q(a) ∨¬p(b) ∨q(z))),
where a and b are the Skolem functions (constants) corresponding to the existen-
tially quantiﬁed variables x and y, respectively.

9.2
PCNF and Clausal Form
175
• The formula can be written in clausal form by dropping the (universal) quantiﬁers
and writing the matrix as sets of clauses:
{{p(a), ¬p(b), q(z)}, {¬q(a), ¬p(b), q(z)}}.
Example 9.16 If we extract the quantiﬁers in the order z, x, y, the equivalent PCNF
formula is:
∀z∃x∃y((p(x) ∨¬p(y) ∨q(z)) ∧(¬q(x) ∨¬p(y) ∨q(z))).
Since the existential quantiﬁers are preceded by a (single) universal quantiﬁer, the
Skolem functions are (unary) functions, not constants:
∀z((p(f (z)) ∨¬p(g(z)) ∨q(z)) ∧(¬q(f (z)) ∨¬p(g(z)) ∨q(z))),
which is:
{{p(f (z)), ¬p(g(z)), q(z)}, {¬q(f (z)), ¬p(g(z)), q(z)}}
in clausal form.
Example 9.17 Let us follow the entire transformation on another formula.
Original formula
∃x∀yp(x,y) →∀y∃xp(x,y)
Rename bound variables
∃x∀yp(x,y) →∀w∃zp(z,w)
Eliminate Boolean operators
¬∃x∀yp(x,y) ∨∀w∃zp(z,w)
Push negation inwards
∀x∃y¬p(x,y) ∨∀w∃zp(z,w)
Extract quantiﬁers
∀x∃y∀w∃z(¬p(x,y) ∨p(z,w))
Distribute matrix
(no change)
Replace existential quantiﬁers
∀x∀w(¬p(x,f (x)) ∨p(g(x,w),w))
Write in clausal form
{{¬p(x,f (x)), p(g(x,w),w)}}.
f is unary because ∃y is preceded by one universal quantiﬁer ∀x, while g is binary
because ∃z is preceded by two universal quantiﬁers ∀x and ∀w.
9.2.3 Proof of Skolem’s Theorem
Proof of Skolem’s Theorem The ﬁrst ﬁve transformations of the algorithm can easily
be shown to preserve equivalence. Consider now the replacement of an existential
quantiﬁer by a Skolem function. Suppose that:
I |= ∀y1 ···∀yn∃xp(y1,...,yn,x).

176
9
First-Order Logic: Terms and Normal Forms
We need to show that there exists an interpretation I ′ such that:
I ′ |= ∀y1 ···∀ynp(y1,...,yn,f (y1,...,yn)).
I ′ is constructed by extending I . Add a n-ary function F deﬁned by: For all:
{c1,...,cn} ⊆D,
let F(c1,...,cn) = cn+1 for some cn+1 ∈D such that:
(c1,...,cn,cn+1) ∈Rp,
where Rp is assigned to p in I . Since I |= A, there must be at least one element
d of the domain such that (c1,...,cn,d) ∈Rp. We simply choose one of them
arbitrarily and assign it to be the value of F(c1,...,cn). The Skolem function f
was chosen to be a new function symbol not in A so the deﬁnition of F does not
clash with any existing function in I .
To show that:
I ′ |= ∀y1 ···∀ynp(y1,...,yn,f (y1,...,yn)),
let {c1,...,cn} be arbitrary domain elements. By construction, F(c1,...,cn) =
cn+1 for some cn+1 ∈D and vI ′(p(c1,...,cn,cn+1)) = T . Since c1,...,cn were
arbitrary:
vI ′(∀y1 ···∀ynp(y1,...,yn,f (y1,...,yn))) = T.
This completes one direction of the proof of Skolem’s Theorem. The proof of the
converse (A is satisﬁable if A′ is satisﬁable) is left as an exercise.
In practice, it is better to use a different transformation of a formula to clausal
form. First, push all quantiﬁers inward, then replace existential quantiﬁers by
Skolem functions and ﬁnally extract the remaining (universal) quantiﬁers. This en-
sures that the number of universal quantiﬁers preceding an existential quantiﬁer is
minimal and thus the arity of the Skolem functions is minimal.
Example 9.18 Consider again the formula of Example 9.17:
Original formula
∃x∀yp(x,y) →∀y∃xp(x,y)
Rename bound variables
∃x∀yp(x,y) →∀w∃zp(z,w)
Eliminate Boolean operators
¬∃x∀yp(x,y) ∨∀w∃zp(z,w)
Push negation inwards
∀x∃y¬p(x,y) ∨∀w∃zp(z,w)
Replace existential quantiﬁers
∀x¬p(x,f (x)) ∨∀wp(g(w),w)
Extract universal quantiﬁers
∀x∀w(¬p(x,f (x)) ∨p(g(w),w))
Write in clausal form
{{¬p(x,f (x)), p(g(w),w)}}.

9.3
Herbrand Models
177
9.3 Herbrand Models
When function symbols are used to form terms, there is no easy way to describe
the set of possible interpretations. The domain could be a numerical domain or a
domain of data structures or almost anything else. The deﬁnition of even one func-
tion can choose to assign an arbitrary element of the domain to an arbitrary subset
of arguments. In this section, we show that for sets of clauses there are canonical
interpretations called Herbrand models, which are a relatively limited set of inter-
pretations that have the following property: If a set of clauses has a model then it
has an Herbrand model. Herbrand models will be central to the theoretical develop-
ment of resolution in ﬁrst-order logic (Sects. 10.1, 11.2); they also have interesting
theoretical properties of their own (Sect. 9.4).
Herbrand Universes
The ﬁrst thing that an interpretation needs is a domain. For this we use the set of
syntactical terms that can be built from the symbols in the formula.
Deﬁnition 9.19 Let S be a set of clauses, A the set of constant symbols in S, and
F the set of function symbols in S. HS, the Herbrand universe of S, is deﬁned
inductively:
ai ∈HS
for ai ∈A ,
f 0
i ∈HS
for f 0
i ∈F,
f n
i (t1,...,tn) ∈HS
for n > 1,f n
i ∈F,tj ∈HS.
If there are no constant symbols or 0-ary function symbols in S, initialize the in-
ductive deﬁnition of HS with an arbitrary constant symbol a.
The Herbrand universe is just the set of ground terms that can be formed from
symbols in S. Obviously, if S contains a function symbol, the Herbrand universe is
inﬁnite since f (f (...(a)...)) ∈HS.
Example 9.20 Here are some examples of Herbrand universes:
S1
= {{p(a), ¬p(b), q(z)}, {¬p(b), ¬q(z)}}
HS1
= {a, b}
S2
= {{¬p(x,f (y))}, {p(w,g(w))}}
HS2
= {a, f (a), g(a), f (f (a)), g(f (a)), f (g(a)), g(g(a)), ...}
S3
= {{¬p(a,f (x,y))}, {p(b,f (x,y))}}
HS3
= {a, b, f (a,a), f (a,b), f (b,a), f (b,b), f (a,f (a,a)), ...}.

178
9
First-Order Logic: Terms and Normal Forms
Herbrand Interpretations
Now that we have a domain, an interpretation needs to specify assignments for the
predicate, function and constant symbols. Clearly, we can let function and constant
symbols be themselves: When interpreting p(x,f (a)), we interpret the term a by
the domain element a and the term f (a) by the domain element f (a). Of course,
this is somewhat confusing because we are using the same symbols for two pur-
poses! Herbrand interpretations have complete ﬂexibility in how they assign rela-
tions over the Herbrand universe to predicate symbols.
Deﬁnition 9.21 Let S be a formula in clausal where PS = {p1,...,pk} are the
predicate symbols, FS = {f1,...,fl} the function symbols and AS = {a1,...,am}
the constant symbols appearing in S.
An Herbrand interpretation for S is:
I = {HS,{R1,...,Rk},{f1,...,fl},AS},
where {R1,...,Rk} are arbitrary relations of the appropriate arities over the domain
HS.
If fi is a function symbol of arity ji, then the function fi is deﬁned as follows:
Let {t1,...,tji} ∈HS; then fi(t1,...,tji) = fi(t1,...,tji).
An assignment in I is deﬁned by:
vI (a) = a,
vI (f (t1,...,tn)) = f (vI (t1),...,vI (tn)).
If I |= S, then I is an Herbrand model for S.
Herbrand Bases
An alternate way of deﬁning Herbrand models uses the following deﬁnition:
Deﬁnition 9.22 Let HS be the Herbrand universe for S. BS, the Herbrand base for
S, is the set of ground atomic formulas that can be formed from predicate symbols
in S and terms in HS.
A relation over the Herbrand universe is simply a subset of the Herbrand base.
Example 9.23 The Herbrand base for S3 from Example 9.20 is:
BS3
= {p(a,f (a,a)), p(a,f (a,b)), p(a,f (b,a)), p(a,f (b,b)), ...,
p(a,f (a,f (a,a))), ...,
p(b,f (a,a)), p(b,f (a,b)), p(b,f (b,a)), p(b,f (b,b)), ...,
p(b,f (a,f (a,a))), ...}.

9.3
Herbrand Models
179
An Herbrand interpretation for S3 can be deﬁned by giving the subset of the Her-
brand base where the relation Rp holds, for example:
{p(b,f (a,a)), p(b,f (a,b)), p(b,f (b,a)), p(b,f (b,b))}.
Herbrand Models Are Canonical
Theorem 9.24 A set of clauses S has a model iff it has an Herbrand model.
Proof Let:
I = (D, {R1,...,Rl}, {F1,...,Fm}, {d1,...,dn})
be an arbitrary model for S. Deﬁne the Herbrand interpretation HI by the follow-
ing subset of the Herbrand base:
{pi(t1,...,tn) | (vI (t1),...,vI (tn)) ∈Ri},
where Ri is the relation assigned to pi in I . That is, a ground atom is in the subset
of the Herbrand base if its value vI (pi(t1,...,tn)) is true when interpreted in the
model I .
We need to show that HI |= S.
A set of clauses is a closed formula that is a conjunction of disjunctions of literals,
so it sufﬁces to show that one literal of each disjunction is in the subset, for each
assignment of elements of the Herbrand universe to the variables.
Since I |= S, vI (S) = T so for all assignments by I to the variables and for all
clauses Ci ∈S, vI (Ci) = T . Thus for all clauses Ci ∈S, there is some literal Dij
in the clause such that vI (Dij) = T . But, by deﬁnition of the HI , vHI (Dij) = T
iff vI(Dij) = T , from which follows vHI (Ci) = T for all clauses Ci ∈S, and
vHI (S) = T . Thus HI is an Herbrand model for S.
The converse is trivial.
Theorem 9.24 is not true if S is an arbitrary formula.
Example 9.25 Let S = p(a) ∧∃x¬p(x). Then
({0,1}, {{0}}, {}, {0})
is a model for S since v(p(0)) = T , v(p(1)) = F .
S has no Herbrand models since there are only two Herbrand interpretations and
neither is a model:
({a}, {{a}}, {}, {a}),
({a}, {{}}, {}, {a}).

180
9
First-Order Logic: Terms and Normal Forms
9.4 Herbrand’s Theorem *
Herbrand’s Theorem shows that questions of validity and provability in ﬁrst-order
logic can be reduced to questions about ﬁnite sets of ground atomic formulas. Al-
though these results can now be obtained directly from the theory of semantic tab-
leaux and Gentzen systems, we bring these results here (without proof) for their
historical interest.
Consider a semantic tableau for an unsatisﬁable formula in clausal form. The
formula is implicitly a universally quantiﬁed formula:
A = ∀x1 ···∀xnA′(x1,...,xn)
whose matrix is a conjunction of disjunctions of literals. The only rules that can be
used are the propositional rules for α- and β-formulas and the rule for γ -formulas
with universal quantiﬁers. Since the closed tableau is ﬁnite, there will be a ﬁnite
number of applications of the rule for γ -formulas.
Suppose that we construct the tableau by initially applying the rule for γ -
formulas repeatedly for some sequence of ground terms, and only then apply the
rule for α-formulas repeatedly in order to ‘break up’ each instantiation of the matrix
A′ into separate clauses. We obtain a node n labeled with a ﬁnite set of clauses.
Repeated use of the rule for β-formulas on each clause (disjunction) will cause the
tableau to eventually close because each leaf contains clashing literals. This sketch
motivates the following theorem.
Theorem 9.26 (Herbrand’s Theorem, semantic form 1) A set of clauses S is unsat-
isﬁable if and only if a ﬁnite set of ground instances of clauses of S is unsatisﬁable.
Example 9.27 The clausal form of the formula:
¬[∀x(p(x) →q(x)) →(∀xp(x) →∀xq(x))]
(which is the negation of a valid formula) is:
S = {{¬p(x), q(x)}, {p(y)}, {¬q(z)}}.
The set of ground instances obtained by substituting a for each variable is:
S′ = {{¬p(a), q(a)}, {p(a)}, {¬q(a)}}.
Clearly, S′ is unsatisﬁable because an application of the rule for the β-formula
gives two nodes containing pairs of clashing literals: {¬p(a), p(a), ¬q(a)} and
{q(a), p(a), ¬q(a)}. Theorem 9.26 states that the unsatisﬁability of S′ implies that
S is unsatisﬁable.
Since a formula is satisﬁable if and only if its clausal form is satisﬁable, the
theorem can also be expressed as follows.

9.4
Herbrand’s Theorem *
181
Theorem 9.28 (Herbrand’s Theorem, semantic form 2) A formula A is unsatisﬁable
if and only if a formula built from a ﬁnite set of ground instances of subformulas of
A is unsatisﬁable.
Herbrand’s Theorem transforms the problem of satisﬁability within ﬁrst-order
logic into a problem of ﬁnding an appropriate set of ground terms and then checking
satisﬁability within propositional logic.
A syntactic form of Herbrand’s theorem easily follows from the fact that a tableau
can be turned upside-down to obtain a Gentzen proof of the formula.
Theorem 9.29 (Herbrand’s Theorem, syntactic form) A formula A of ﬁrst-order
logic is provable if and only if a formula built from a ﬁnite set of ground instances
of subformulas of A is provable using only the axioms and inference rules of propo-
sitional logic.
From Herbrand’s theorem we obtain a relatively efﬁcient semi-decision proce-
dure for validity of formulas in ﬁrst-order logic:
1. Negate the formula;
2. Transform into clausal form;
3. Generate a ﬁnite set of ground clauses;
4. Check if the set of ground clauses is unsatisﬁable.
The ﬁrst two steps are trivial and the last is not difﬁcult because any convenient
decision procedure for the propositional logic can be used by treating each distinct
ground atomic formula as a distinct propositional letter. Unfortunately, we have no
efﬁcient way of generating a set of ground clauses that is likely to be unsatisﬁable.
Example 9.30 Consider the formula ∃x∀yp(x,y) →∀y∃xp(x,y).
Step 1: Negate it:
¬(∃x∀yp(x,y) →∀y∃xp(x,y)).
Step 2: Transform into clausal form:
¬(∃x∀yp(x,y) →∀w∃zp(z,w)))
∃x∀yp(x,y) ∧¬∀w∃zp(z,w)
∃x∀yp(x,y) ∧∃w∀z¬p(z,w)
∀yp(a,y) ∧∀z¬p(z,b)
∀y∀z(p(a,y) ∧¬p(z,b))
{{p(a,y)}, {¬p(z,b)}}.
Step 3: Generate a ﬁnite set of ground clauses. In fact, there are only eight different
ground clauses, so let us generate the entire set:
{ {p(a,a)}, {¬p(a,b)},
{p(a,b)}, {¬p(b,b)},
{p(a,b)}, {¬p(a,b)},
{p(a,a)}, {¬p(b,b)} }.

182
9
First-Order Logic: Terms and Normal Forms
Step 4: Check if the set is unsatisﬁable. Clearly, a set of clauses containing the
clashing unit clauses {¬p(a,b)} and {p(a,b)} is unsatisﬁable.
The general resolution procedure described in the next chapter is a better ap-
proach because it does not need to generate a large number of ground clauses before
checking for unsatisﬁability. Instead, it generates clashing non-ground clauses and
resolves them.
9.5 Summary
First-order logic with functions and terms is used to formalize mathematics. The
theory of this logic (semantic tableaux, deductive systems, completeness, undecid-
ability) is very similar to that of ﬁrst-order logic without functions.
The clausal form of a formula in ﬁrst-order logic is obtained by transforming the
formula into an equivalent formula in prenex conjunctive normal form (PCNF) and
then replacing existential quantiﬁers by Skolem functions. A formula in clausal form
is satisﬁable iff it has an Herbrand model, which is a model whose domain is the
set of ground terms built from the function and constant symbols that appear in the
formula. Herbrand’s theorem states that questions of unsatisﬁability and provability
can be expressed in propositional logic applied to ﬁnite sets of ground formulas.
9.6 Further Reading
Functions and terms are used in all standard treatments of ﬁrst-order logic such as
Mendelson (2009) and Monk (1976). Herbrand models are discussed in texts on
theorem-proving ((Fitting, 1996), (Lloyd, 1987)).
9.7 Exercises
9.1 Transform each of the following formulas to clausal form:
∀x(p(x) →∃yq(y)),
∀x∀y(∃zp(z) ∧∃u(q(x,u) →∃vq(y,v))),
∃x(¬∃yp(y) →∃z(q(z) →r(x))).
9.2 For the formulas of the previous exercise, describe the Herbrand universe and
the Herbrand base.
9.3 Prove the converse direction of Skolem’s Theorem (Theorem 9.13).
9.4 Prove:
|= ∀xA(x,f (x)) →∀x∃yA(x,y),
̸|= ∀x∃yA(x,y) →∀xA(x,f (x)).

References
183
9.5 Let A(x1,...,xn) be a formula with no quantiﬁers and no function symbols.
Prove that ∀x1 ···∀xnA(x1,...,xn) is satisﬁable if and only if it is satisﬁable in an
interpretation whose domain has only one element.
References
M. Fitting. First-Order Logic and Automated Theorem Proving (Second Edition). Springer, 1996.
J.W. Lloyd. Foundations of Logic Programming (Second Edition). Springer, Berlin, 1987.
E. Mendelson. Introduction to Mathematical Logic (Fifth Edition). Chapman & Hall/CRC, 2009.
J.D. Monk. Mathematical Logic. Springer, 1976.


Chapter 10
First-Order Logic: Resolution
Resolution is a sound and complete algorithm for propositional logic: a formula in
clausal form is unsatisﬁable if and only if the algorithm reports that it is unsatisﬁ-
able. For propositional logic, the algorithm is also a decision procedure for unsatis-
ﬁability because it is guaranteed to terminate. When generalized to ﬁrst-order logic,
resolution is still sound and complete, but it is not a decision procedure because the
algorithm may not terminate.
The generalization of resolution to ﬁrst-order logic will be done in two stages.
First, we present ground resolution which works on ground literals as if they were
propositional literals; then we present the general resolution procedure, which uses
a highly efﬁcient matching algorithm called uniﬁcation to enable resolution on non-
ground literals.
10.1 Ground Resolution
Rule 10.1 (Ground resolution rule) Let C1, C2 be ground clauses such that l ∈C1
and lc ∈C2. C1, C2 are said to be clashing clauses and to clash on the complemen-
tary literals l, lc. C, the resolvent of C1 and C2, is the clause:
Res(C1,C2) = (C1 −{l}) ∪(C2 −{lc}).
C1 and C2 are the parent clauses of C.
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_10, © Springer-Verlag London 2012
185

186
10
First-Order Logic: Resolution
Example 10.2 Here is a tree representation of the ground resolution of two clauses.
They clash on the literal q(f (b)):
Theorem 10.3 The resolvent C is satisﬁable if and only if the parent clauses C1
and C2 are both satisﬁable.
Proof Let C1 and C2 be satisﬁable clauses which clash on the literals l, lc. By
Theorem 9.24, they are satisﬁable in an Herbrand interpretation H . Let B be the
subset of the Herbrand base that deﬁnes H , that is,
B = {p(c1,...,ck) | vH(p(c1,...,ck)) = T }
for ground terms ci. Obviously, two complementary ground literals cannot both be
elements of B. Suppose that l ∈B. For C2 to be satisﬁed in H there must be some
other literal l′ ∈C2 such that l′ ∈B. By construction of the resolvent C using the
resolution rule, l′ ∈C, so vH (C) = T , that is, H is a model for C. A symmetric
argument holds if lc ∈B.
Conversely, if C is satisﬁable, it is satisﬁable in an Herbrand interpretation H
deﬁned by a subset B of the Herbrand base. For some literal l′ ∈C, l′ ∈B. By the
construction of the resolvent clause in the rule, l′ ∈C1 or l′ ∈C2 (or both). Suppose
that l′ ∈C1. We can extend the H to H ′ by deﬁning B′ = B ∪{lc}. Again, by
construction, l ̸∈C and lc ̸∈C, so l ̸∈B and lc ̸∈B and therefore B′ is well deﬁned.
We need to show that C1 and C2 are both satisﬁed by H ′ deﬁned by the Herbrand
base B′. Clearly, since l′ ∈C, l′ ∈B ⊆B′, so C1 is satisﬁed in H ′. By deﬁnition,
lc ∈B′, so C2 is satisﬁed in H ′.
A symmetric argument holds if l′ ∈C2.
The ground resolution procedure is deﬁned like the resolution procedure for
propositional logic. Given a set of ground clauses, the resolution step is performed
repeatedly. The set of ground clauses is unsatisﬁable iff some sequence of resolu-
tion steps produces the empty clause. We leave it as an exercise to show that ground
resolution is a sound and complete refutation procedure for ﬁrst-order logic.
Ground resolution is not a useful refutation procedure for ﬁrst-order logic be-
cause the set of ground terms is inﬁnite (assuming that there is even one function
symbols). Robinson (1965) showed that how to perform resolution on clauses that
are not ground by looking for substitutions that create clashing clauses. The deﬁni-
tions and algorithms are rather technical and are described in detail in the next two
sections.

10.2
Substitution
187
10.2 Substitution
We have been somewhat informal about the concept of substituting a term for a
variable. In this section, the concept is formally deﬁned.
Deﬁnition 10.4 A substitution of terms for variables is a set:
{x1 ←t1, ..., xn ←tn},
where each xi is a distinct variable and each ti is a term which is not identical to the
corresponding variable xi. The empty substitution is the empty set.
Lower-case Greek letters {λ,μ,σ,θ} will be used to denote substitutions. The
empty substitution is denoted ε.
Deﬁnition 10.5 An expression is a term, a literal, a clause or a set of clauses. Let E
be an expression and let θ = {x1 ←t1, ..., xn ←tn} be a substitution. An instance
Eθ of E is obtained by simultaneously replacing each occurrence of xi in E by ti.
Example 10.6 Here is an expression (clause) E = {p(x), q(f (y))} and a substitu-
tion θ = {x ←y, y ←f (a)}, the instance obtained by performing the substitution
is:
Eθ = {p(y), q(f (f (a)))}.
The word simultaneously in Deﬁnition 10.5 means that one does not substitute y for
x in E to obtain:
{p(y), q(f (y))},
and then substitute f (a) for y to obtain:
{p(f (a)), q(f (f (a)))}.
The result of a substitution need not be a ground expression; at the extreme, a
substitution can simply rename variables: {x ←y, z ←w}. Therefore, it makes
sense to apply a substitution to an instance, because the instance may still have
variables. The following deﬁnition shows how substitutions can be composed.
Deﬁnition 10.7 Let:
θ = {x1 ←t1, ..., xn ←tn},
σ = {y1 ←s1, ..., yk ←sk}
be two substitutions and let X = {x1, ..., xn} and Y = {y1, ..., yk} be the sets of
variables substituted for in θ and σ, respectively. θσ, the composition of θ and σ, is
the substitution:
θσ = {xi ←tiσ | xi ∈X, xi ̸= tiσ} ∪{yj ←sj | yj ∈Y, yj ̸∈X}.

188
10
First-Order Logic: Resolution
In words: apply the substitution σ to the terms ti of θ (provided that the resulting
substitutions do not collapse to xi ←xi) and then append the substitutions from σ
whose variables do not already appear in θ.
Example 10.8 Let:
E
=
p(u,v,x,y,z),
θ
=
{x ←f (y), y ←f (a), z ←u},
σ
=
{y ←g(a), u ←z, v ←f (f (a))}.
Then:
θσ = {x ←f (g(a)), y ←f (a), u ←z, v ←f (f (a))}.
The vacuous substitution z ←z = (z ←u)σ has been deleted. The substitution y ←
g(a) ∈σ has also been deleted since y already appears in θ. Once the substitution
y ←f (a) is performed, no occurrences of y remain in the expression. The instance
obtained from the composition is:
E(θσ) = p(z,f (f (a)),f (g(a)),f (a),z).
Alternatively, we could have performed the substitution in two stages:
Eθ
=
p(u,v,f (y),f (a),u),
(Eθ)σ
=
p(z,f (f (a)),f (g(a)),f (a),z).
We see that E(θσ) = (Eθ)σ.
The result of performing two substitutions one after the other is the same as the
result of computing the composition followed by a single substitution.
Lemma 10.9 For any expression E and substitutions θ, σ, E(θσ) = (Eθ)σ.
Proof Let E be a variable z. If z is not substituted for in θ or σ, the result is trivial.
If z = xi for some {xi ←ti} in θ, then (zθ)σ = tiσ = z(θσ) by the deﬁnition of
composition. If z = yj for some {yj ←sj} in σ and z ̸= xi for all i, then (zθ)σ =
zσ = sj = z(θσ).
The result follows by induction on the structure of E.
We leave it as an exercise to show that composition is associative.
Lemma 10.10 For any substitutions θ, σ, λ, θ(σλ) = (θσ)λ.

10.3
Uniﬁcation
189
10.3 Uniﬁcation
The two literals p(f (x), g(y)) and ¬p(f (f (a)), g(z)) do not clash. However,
under the substitution:
θ1 = {x ←f (a), y ←f (g(a)), z ←f (g(a))},
they become clashing (ground) literals:
p(f (f (a)), g(f (g(a)))),
¬p(f (f (a)), g(f (g(a)))).
The following simpler substitution:
θ2 = {x ←f (a), y ←a, z ←a}
also makes these literals clash:
p(f (f (a)), g(a)),
¬p(f (f (a)), g(a)).
Consider now the substitution:
μ = {x ←f (a), z ←y}.
The literals that result are:
p(f (f (a)), g(y)),
¬p(f (f (a)), g(y)).
Any further substitution of a ground term for y will produce clashing ground literals.
The general resolution algorithm allows resolution on clashing literals that con-
tain variables. By ﬁnding the simplest substitution that makes two literals clash, the
resolvent is the most general result of a resolution step and is more likely to clash
with another clause after a suitable substitution.
Deﬁnition 10.11 Let U = {A1,...,An} be a set of atoms. A uniﬁer θ is a substitu-
tion such that:
A1θ = ··· = Anθ.
A most general uniﬁer (mgu) for U is a uniﬁer μ such that any uniﬁer θ of U can
be expressed as:
θ = μλ
for some substitution λ.
Example 10.12 The substitutions θ1, θ2, μ, above, are uniﬁers of the set of two
atoms {p(f (x),g(y)), p(f (f (a)),g(z))}. The substitution μ is an mgu. The ﬁrst
two substitutions can be expressed as:
θ1 = μ{y ←f (g(a))},
θ2 = μ{y ←a}.

190
10
First-Order Logic: Resolution
Not all atoms are uniﬁable. It is clearly impossible to unify atoms whose pred-
icate symbols are different such as p(x) and q(x), as well as atoms with terms
whose outer function symbols are different such as p(f (x)) and p(g(y)). A more
tricky case is shown by the atoms p(x) and p(f (x)). Since x occurs within the
larger term f (x), any substitution—which must substitute simultaneously in both
atoms—cannot unify them. It turns out that as long as these conditions do not hold
the atoms will be uniﬁable.
We now describe and prove the correctness of an algorithm for uniﬁcation by
Martelli and Montanari (1982). Robinson’s original algorithm is presented brieﬂy
in Sect. 10.3.4.
10.3.1 The Uniﬁcation Algorithm
Trivially, two atoms are uniﬁable only if they have the same predicate letter of the
same arity. Thus the uniﬁability of atoms is more conveniently described in terms
of the uniﬁability of the arguments, that is, the uniﬁability of a set of terms. The set
of terms to be uniﬁed will be written as a set of term equations.
Example 10.13 The uniﬁability of {p(f (x),g(y)), p(f (f (a)),g(z))} is expressed
by the set of term equations:
f (x) = f (f (a)),
g(y) = g(z).
Deﬁnition 10.14 A set of term equations is in solved form iff:
• All equations are of the form xi = ti where xi is a variable.
• Each variable xi that appears on the left-hand side of an equation does not appear
elsewhere in the set.
A set of equations in solved form deﬁnes a substitution:
{x1 ←t1, ..., xn ←tn}.
The following algorithm transforms a set of term equations into a set of equations
in solved form, or reports if it is impossible to do so. In Sect. 10.3.3, we show that
the substitution deﬁned by the set in solved form is a most general uniﬁer of the
original set of term equations, and hence of the set of atoms from which the terms
were taken.
Algorithm 10.15 (Uniﬁcation algorithm)
Input: A set of term equations.
Output: A set of term equations in solved form or report not uniﬁable.

10.3
Uniﬁcation
191
Perform the following transformations on the set of equations as long as any one
of them is applicable:
1. Transform t = x, where t is not a variable, to x = t.
2. Erase the equation x = x.
3. Let t′ = t′′ be an equation where t′, t′′ are not variables.
• If the outermost function symbols of t′ and t′′ are not identical, terminate the
algorithm and report not uniﬁable.
• Otherwise, replace the equation f (t′
1,...,t′
k) = f (t′′
1 ,...,t′′
k ) by the k equa-
tions t′
1 = t′′
1 ,...,t′
k = t′′
k .
4. Let x = t be an equation such that x has another occurrence in the set.
• If x occurs in t and x differs from t, terminate the algorithm and report not
uniﬁable.
• Otherwise, transform the set by replacing all occurrences of x in other equa-
tions by t.
Example 10.16 Consider the following set of two equations:
g(y) = x,
f (x,h(x),y) = f (g(z),w,z).
Apply rule 1 to the ﬁrst equation and rule 3 to the second equation:
x
= g(y),
x
= g(z),
h(x) = w,
y
= z.
Apply rule 4 to the second equation by replacing occurrences of x in other equations
by g(z):
g(z) = g(y),
x
= g(z),
h(g(z)) = w,
y
= z.
Apply rule 3 to the ﬁrst equation:
z = y,
x
= g(z),
h(g(z)) = w,
y
= z.

192
10
First-Order Logic: Resolution
Apply rule 4 to the last equation by replacing y by z in the ﬁrst equation; next, erase
the result z = z using rule 2:
x
= g(z),
h(g(z)) = w,
y
= z.
Finally, transform the second equation by rule 1:
x
= g(z),
w = h(g(z)),
y
= z.
This successfully terminates the algorithm. We claim that:
μ = {x ←g(z), w ←h(g(z)), y ←z}
is a most general uniﬁer of the original set of equations. We leave it to the reader to
check that the substitution does in fact unify the original set of term equations and
further to check that the uniﬁer:
θ = {x ←g(f (a)), w ←h(g(f (a))), y ←f (a), z ←f (a)}
can be expressed as θ = μ{z ←f (a)}.
10.3.2 The Occurs-Check
Algorithms for uniﬁcation can be extremely inefﬁcient because of the need to check
the condition in rule 4, called the occurs-check.
Example 10.17 To unify the set of equations:
x1
=
f (x0,x0),
x2
=
f (x1,x1),
x3
=
f (x2,x2),
···
we successively create the equations:
x2
=
f (f (x0,x0),f (x0,x0)),
x3
=
f (f (f (x0,x0),f (x0,x0)),f (f (x0,x0),f (x0,x0))),
···
The equation for xi contains 2i variables.

10.3
Uniﬁcation
193
In the application of uniﬁcation to logic programming (Chap. 11), the occurs-
check is simply ignored and the risk of an illegal substitution is taken.
10.3.3 The Correctness of the Uniﬁcation Algorithm *
Theorem 10.18
• Algorithm 10.15 terminates with the set of equations in solved form or it reports
not uniﬁable.
• If the algorithm reports not uniﬁable, there is no uniﬁer for the set of term equa-
tions.
• If the algorithm terminates successfully, the resulting set of equations is in solved
form and deﬁnes the mgu:
μ = {x1 ←t1, ..., xn ←tn}.
Proof Obviously, rules 1–3 can be used only ﬁnitely many times without using
rule 4. Let m be the number of distinct variables in the set of equations. Rule 4 can
be used at most m times since it removes all occurrences, except one, of a variable
and can never be used twice on the same variable. Thus the algorithm terminates.
The algorithm terminates with failure in rule 3 if the function symbols are dis-
tinct, and in rule 4 if a variable occurs within a term in the same equation. In both
cases there can be no uniﬁer.
It is easy to see that if it terminates successfully, the set of equations is in solved
form. It remains to show that μ is a most general uniﬁer.
Deﬁne a transformation as an equivalence transformation if it preserves sets of
uniﬁers of the equations. Obviously, rules 1 and 2 are equivalence transformations.
Consider now an application of rule 3 for t′ = f (t′
1,...,t′
k) and t′′ = f (t′′
1 ,...,t′′
k ).
If t′σ = t′′σ, by the inductive deﬁnition of a term this can only be true if t′
iσ = t′′
i σ
for all i. Conversely, if some uniﬁer σ makes t′
i = t′′
i for all i, then σ is a uniﬁer for
t′ = t′′. Thus rule 3 is an equivalence transformation.
Suppose now that t1 = t2 was transformed into u1 = u2 by rule 4 on x = t. After
applying the rule, x = t remains in the set. So any uniﬁer σ for the set must make
xσ = tσ. Then, for i = 1,2:
uiσ = (ti{x ←t})σ = ti({x ←t}σ) = tiσ
by the associativity of substitution and by the deﬁnition of composition of substitu-
tion using the fact that xσ = tσ. So if σ is a uniﬁer of t1 = t2, then u1σ = t1σ =
t2σ = u2σ and σ is a uniﬁer of u1 = u2; it follows that rule 4 is an equivalence
transformation.
Finally, the substitution deﬁned by the set is an mgu. We have just proved that the
original set of equations and the solved set of equations have the same set of uniﬁers.
But the solved set itself deﬁnes a substitution (replacements of terms for variables)

194
10
First-Order Logic: Resolution
which is a uniﬁer. Since the transformations were equivalence transformations, no
equation can be removed from the set without destroying the property that it is a
uniﬁer. Thus any uniﬁer for the set can only substitute more complicated terms for
the same variables or substitute for other variables. That is, if μ is:
μ = {x1 ←t1, ..., xn ←tn},
any other uniﬁer σ can be written:
σ = {x1 ←t′
1, ..., xn ←t′
n} ∪{y1 ←s1, ..., ym ←sm},
which is σ = μλ for some substitution λ by deﬁnition of composition. Therefore, μ
is an mgu.
The algorithm is nondeterministic because we may choose to apply a rule to any
equation to which it is applicable. A deterministic algorithm can be obtained by
specifying the order in which to apply the rules. One such deterministic algorithm
is obtained by considering the set of equations as a queue. A rule is applied to the
ﬁrst element of the queue and then that equation goes to the end of the queue. If new
equations are created by rule 3, they are added to the beginning of the queue.
Example 10.19 Here is Example 10.16 expressed as a queue of equations:
⟨g(y) = x,
f (x,h(x),y) = f (g(z),w,z)
⟩
⟨f (g(y),h(g(y)),y) = f (g(z),w,z), x = g(y)
⟩
⟨g(y) = g(z), h(g(y)) = w,
y = z,
x = g(y)
⟩
⟨y = z,
h(g(y)) = w,
y = z,
x = g(y)
⟩
⟨h(g(z)) = w, z = z,
x = g(z),
y = z
⟩
⟨z = z,
x = g(z),
y = z,
w = h(g(z)) ⟩
⟨x = g(z),
y = z,
w = h(g(z))
⟩
10.3.4 Robinson’s Uniﬁcation Algorithm *
Robinson’s algorithm appears in most other works on resolution so we present it
here without proof (see Lloyd (1987, Sect. 1.4) for a proof).
Deﬁnition 10.20 Let A and A′ be two atoms with the same predicate symbols.
Considering them as sequences of symbols, let k be the leftmost position at which
the sequences are different. The pair of terms {t,t′} beginning at position k in A and
A′ is the disagreement set of the two atoms.
Algorithm 10.21 (Robinson’s uniﬁcation algorithm)
Input: Two atoms A and A′ with the same predicate symbol.
Output: A most general uniﬁer for A and A′ or report not uniﬁable.

10.4
General Resolution
195
Initialize the algorithm by letting A0 = A and A′
0 = A′. Perform the following
step repeatedly:
• Let {t,t′} be the disagreement set of Ai, A′
i. If one term is a variable xi+1 and the
other is a term ti+1 such that xi+1 does not occur in ti+1, let σi+1 = {xi+1 ←ti+1}
and Ai+1 = Aiσi+1, A′
i+1 = A′
iσi+1.
If it is impossible to perform the step (because both elements of the disagree-
ment set are compound terms or because the occurs-check fails), the atoms are
not uniﬁable. If after some step An = A′
n, then A, A′ are uniﬁable and the mgu
is μ = σi ···σn.
Example 10.22 Consider the pair of atoms:
A = p(g(y), f (x,h(x),y)),
A′ = p(x, f (g(z),w,z)).
The initial disagreement set is {x, g(y)}. One term is a variable which does not
occur in the other so σ1 = {x ←g(y)}, and:
Aσ1 = p(g(y), f (g(y),h(g(y)),y)),
A′σ1 = p(g(y), f (g(z),w,z)).
The next disagreement set is {y, z} so σ2 = {y ←z}, and:
Aσ1σ2 = p(g(z), f (g(z),h(g(z)),z)),
A′σ1σ2 = p(g(z), f (g(z),w,z)).
The third disagreement set is {w, h(g(z))} so σ3 = {w ←h(g(z))}, and:
Aσ1σ2σ3 = p(g(z), f (g(z),h(g(z)),z)),
A′σ1σ2σ3 = p(g(z), f (g(z),h(g(z)),z)).
Since Aσ1σ2σ3 = A′σ1σ2σ3, the atoms are uniﬁable and the mgu is:
μ = σ1σ2σ3 = {x ←g(z), y ←z, w ←h(g(z))}.
10.4 General Resolution
The resolution rule can be applied directly to non-ground clauses by performing
uniﬁcation as an integral part of the rule.
Deﬁnition 10.23 Let L = {l1,...,ln} be a set of literals. Then Lc = {lc
1,...,lc
n}.

196
10
First-Order Logic: Resolution
Rule 10.24 (General resolution rule) Let C1,C2 be clauses with no variables in
common. Let L1 = {l1
1,...,l1
n1} ⊆C1 and L2 = {l2
1,...,l2
n2} ⊆C2 be subsets of
literals such that L1 and Lc
2 can be uniﬁed by an mgu σ. C1 and C2 are said to be
clashing clauses and to clash on the sets of literals L1 and L2. C, the resolvent of
C1 and C2, is the clause:
Res(C1,C2) = (C1σ −L1σ) ∪(C2σ −L2σ).
Example 10.25 Given the two clauses:
{p(f (x),g(y)), q(x,y)},
{¬p(f (f (a)),g(z)), q(f (a),z)},
an mgu for L1 = {p(f (x),g(y))} and Lc
2 = {p(f (f (a)),g(z))} is:
{x ←f (a),y ←z}.
The clauses resolve to give:
{q(f (a),z), q(f (a),z)}
=
{q(f (a),z)}.
Clauses are sets of literals, so when taking the union of the clauses in the resolu-
tion rule, identical literals will be collapsed; this is called factoring.
The general resolution rule requires that the clauses have no variables in com-
mon. This is done by standardizing apart: renaming all the variables in one of the
clauses before it is used in the resolution rule. All variables in a clause are implicitly
universally quantiﬁed so renaming does not change satisﬁability.
Example 10.26 To resolve the two clauses p(f (x)) and ¬p(x), ﬁrst rename the
variable x of the second clause to x′: ¬p(x′). An mgu is {x′ ←f (x)}, and p(f (x))
and ¬p(f (x)) resolve to 2.
The clauses represent the formulas ∀xp(f (x)) and ∀x¬p(x), and it is obvious
that their conjunction ∀xp(f (x)) ∧∀x¬p(x) is unsatisﬁable.
Example 10.27 Let C1 = {p(x),p(y)} and C2 = {¬p(x),¬p(y)}. Standard-
ize apart so that C′
2 = {¬p(x′),¬p(y′)}. Let L1 = {p(x),p(y)} and let Lc
2 =
{p(x′),p(y′)}; these sets have an mgu:
σ = {y ←x,x′ ←x,y′ ←x}.
The resolution rule gives:
Res(C1,C2) = (C1σ −L1σ) ∪(C′
2σ −L2σ)
= ({p(x)} −{p(x)}) ∪({¬p(x)} −{¬p(x)})
= 2.

10.4
General Resolution
197
In this example, the empty clause cannot be obtained without factoring, but we
will talk about clashing literals rather than clashing sets of literals when no confu-
sion will result.
Algorithm 10.28 (General Resolution Procedure)
Input: A set of clauses S.
Output: If the algorithm terminates, report that the set of clauses is satisﬁable or
unsatisﬁable.
Let S0 = S. Assume that Si has been constructed. Choose clashing clauses
C1,C2 ∈Si and let C = Res(C1,C2). If C = 2, terminate and report that S is un-
satisﬁable. Otherwise, construct Si+1 = Si ∪{C}. If Si+1 = Si for all possible pairs
of clashing clauses, terminate and report S is satisﬁable.
While an unsatisﬁable set of clauses will eventually produce 2 under a suitable
systematic execution of the procedure, the existence of inﬁnite models means that
the resolution procedure on a satisﬁable set of clauses may never terminate, so gen-
eral resolution is not a decision procedure.
Example 10.29 Lines 1–7 contain a set of clauses. The resolution refutation in lines
8–15 shows that the set of clauses is unsatisﬁable. Each line contains the resolvent,
the mgu and the numbers of the parent clauses.
1.
{¬p(x), q(x), r(x,f (x))}
2.
{¬p(x), q(x), r′(f (x))}
3.
{p′(a)}
4.
{p(a)}
5.
{¬r(a,y), p′(y)}
6.
{¬p′(x), ¬q(x)}
7.
{¬p′(x), ¬r′(x)}
8.
{¬q(a)}
x ←a
3,6
9.
{q(a), r′(f (a))}
x ←a
2,4
10.
{r′(f (a))}
8,9
11.
{q(a), r(a,f (a))}
x ←a
1,4
12.
{r(a,f (a))}
8,11
13.
{p′(f (a))}
y ←f (a)
5,12
14.
{¬r′(f (a))}
x ←f (a)
7,13
15.
{2}
10,14
Example 10.30 Here is another example of a resolution refutation showing variable
renaming and mgu’s which do not produce ground clauses. The ﬁrst four clauses
form the set of clauses to be refuted.

198
10
First-Order Logic: Resolution
1.
{¬p(x,y), p(y,x)}
2.
{¬p(x,y), ¬p(y,z), p(x,z)}
3.
{p(x,f (x))}
4.
{¬p(x,x)}
3′.
{p(x′,f (x′))}
Rename 3
5.
{p(f (x),x)}
σ1 = {y ←f (x),x′ ←x}
1,3′
3′′.
{p(x′′,f (x′′))}
Rename 3
6.
{¬p(f (x),z), p(x,z)}
σ2 = {y ←f (x),x′′ ←x}
2,3′′
5′′′.
{p(f (x′′′),x′′′)}
Rename 5
7.
{p(x,x)}
σ3 = {z ←x,x′′′ ←x}
6,5′′′
4′′′′.
{¬p(x′′′′,x′′′′)}
Rename 4
8.
{2}
σ4 = {x′′′′ ←x}
7,4′′′′
If we concatenate the substitutions, we get:
σ = σ1σ2σ3σ4 = {y ←f (x),z ←x,x′ ←x,x′′ ←x,x′′′ ←x,x′′′′ ←x}.
Restricted to the variables of the original clauses, σ = {y ←f (x),z ←x}.
10.5 Soundness and Completeness of General Resolution *
10.5.1 Proof of Soundness
We now show the soundness and completeness of resolution. The reader should
review the proofs in Sect. 4.4 for propositional logic as we will just give the modi-
ﬁcations that must be made to those proofs.
Theorem 10.31 (Soundness of resolution) Let S be a set of clauses. If the empty
clause 2 is derived when the resolution procedure is applied to S, then S is unsat-
isﬁable.
Proof We need to show that if the parent clauses are (simultaneously) satisﬁable,
so is the resolvent; since 2 is unsatisﬁable, this implies that S must also be unsatis-
ﬁable. If parent clauses are satisﬁable, there is an Herbrand interpretation H such
that vH (Ci) = T for i = 1,2. The elements of the Herbrand base that satisfy C1
and C2 have the same form as ground atoms, so there must be a substitutions λi
such that C′
i = Ciλi are ground clauses and vH (C′
i) = T .
Let C be the resolvent of C1 and C2. Then there is an mgu μ for C1 and C2 that
was used to resolve the clauses. By deﬁnition of an mgu, there must substitutions θi
such that λi = σθi. Then C′
i = Ciλi = Ci(σθi) = (Ciσ)θi, which shows that Ciσ is
satisﬁable in the same interpretation.

10.5
Soundness and Completeness of General Resolution *
199
Let l1 ∈C1 and lc
2 ∈C2 be the clashing literals used to derive C. Exactly one
of l1σ,lc
2σ is satisﬁable in H . Without loss of generality, suppose that vH (l1σ) =
T . Since C2σ is satisﬁable, there must be a literal l′ ∈C2 such that l′ ̸= lc
2 and
vH (l′σ) = T . But by the construction of the resolvent, l′ ∈C so vH (C) = T .
10.5.2 Proof of Completeness
Using Herbrand’s theorem and semantic trees, we can prove that there is a ground
resolution refutation of an unsatisﬁable set of clauses. However, this does not gen-
eralize into a proof for general resolution because the concept of semantic trees
does not generalize since the variables give rise to a potentially inﬁnite number of
elements of the Herbrand base. The difﬁculty is overcome by taking a ground reso-
lution refutation and lifting it into a more abstract general refutation.
The problem is that several literals in C1 or C2 might collapse into one literal
under the substitutions that produce the ground instances C′
1 and C′
2 to be resolved.
Example 10.32 Consider the clauses:
C1 = {p(x), p(f (y)), p(f (z)), q(x)},
C2 = {¬p(f (u)), ¬p(w), r(u)}
and the substitution:
{x ←f (a), y ←a, z ←a, u ←a, w ←f (a)}.
The substitution results in the ground clauses:
C′
1 = {p(f (a)), q(f (a))},
C′
2 = {¬p(f (a)), r(a)},
which resolve to: C′ = {q(f (a)), r(a)}. The lifting lemma claims that there is a
clause C = {q(f (u)), r(u)} which is the resolvent of C1 and C2, such that C′ is a
ground instance of C. This can be seen by using the uniﬁcation algorithm to obtain
an mgu:
{x ←f (u), y ←u, z ←u, w ←f (u)}
of C1 and C2, which then resolve giving C.
Theorem 10.33 (Lifting Lemma) Let C′
1, C′
2 be ground instances of C1, C2, re-
spectively. Let C′ be a ground resolvent of C′
1 and C′
2. Then there is a resolvent C
of C1 and C2 such that C′ is a ground instance of C.

200
10
First-Order Logic: Resolution
The relationships among the clauses are displayed in the following diagram.
Proof The steps of the proof for Example 10.32 are shown in Fig. 10.1.
First, standardize apart so that the names of the variables in C1 are different from
those in C2.
Let l ∈C′
1, lc ∈C′
2 be the clashing literals in the ground resolution. Since C′
1 is
an instance of C1 and l ∈C′
1, there must be a set of literals L1 ⊆C1 such that l is an
instance of each literal in L1. Similarly, there must a set L2 ⊆C2 such that lc is an
instance of each literal in L2. Let λ1 and λ2 mgu’s for L1 and L2, respectively, and
let λ = λ1 ∪λ2. λ is a well-formed substitution since L1 and L2 have no variables
in common.
By construction, L1λ and L2λ are sets which contain a single literal each. These
literals have clashing ground instances, so they have a mgu σ. Since Li ⊆Ci, we
have Liλ ⊆Ciλ. Therefore, C1λ and C2λ are clauses that can be made to clash
under the mgu σ. It follows that they can be resolved to obtain clause C:
C = ((C1λ)σ −(L1λ)σ) ∪((C2λ)σ −(L2λ)σ).
By the associativity of substitution (Theorem 10.10):
C = (C1(λσ) −L1(λσ)) ∪(C2(λσ) −(L2(λσ)).
C is a resolvent of C1 and C2 provided that λσ is an mgu of L1 and Lc
2. But λ
is already reduced to equations of the form x ←t for distinct variables x and σ
is constructed to be an mgu, so λσ is a reduced set of equations, all of which are
necessary to unify L1 and Lc
2. Hence λσ is an mgu.
Since C′
1 and C′
2 are ground instances of C1 and C2:
C′
1 = C1θ1 = C1λσθ′
1
C′
2 = C2θ2 = C2λσθ′
2
for some substitutions θ1,θ2,θ′
1,θ′
2. Let θ′ = θ′
1 ∪θ′
2. Then C′ = Cθ′ and C′ is a
ground instance of C.
Theorem 10.34 (Completeness of resolution) If a set of clauses is unsatisﬁable, the
empty clause 2 can be derived by the resolution procedure.
Proof The proof is by induction on the semantic tree for the set of clauses S. The
deﬁnition of semantic tree is modiﬁed as follows:

10.5
Soundness and Completeness of General Resolution *
201
C1
=
{p(x), p(f (y)), p(f (z)), q(x)}
C2
=
{¬p(f (u)), ¬p(w), r(u)}
θ1
=
{x ←f (a), y ←a, z ←a}
θ2
=
{u ←a, w ←f (a)}
C′
1
=
C1θ1 = {p(f (a)), q(f (a))}
C′
2
=
C2θ2 = {¬p(f (a)), r(a)}
C′
=
Res(C1,C2) = {q(f (a)), r(a)}
L1
=
{p(x), p(f (y)), p(f (z))}
λ1
=
{x ←f (y), z ←y}
L1λ1
=
{p(f (y))}
L2
=
{¬p(f (u)), ¬p(w)}
λ2
=
{w ←f (u)}
L2λ2
=
{¬p(f (u))}
λ
=
λ1 ∪λ2 = {x ←f (y),z ←y,w ←f (u)}
L1λ
=
{p(f (y))}
C1λ
=
{p(f (y)), q(f (y))}
L2λ
=
{¬p(f (u))}
C2λ
=
{¬p(f (u)), r(u)}
σ
=
{u ←y}
C
=
Res(C1λ,C2λ) = {q(f (y)), r(y)}, using σ
λσ
=
{x ←f (y), z ←y, w ←f (y), u ←y}
C1λσ
=
{p(f (y)), q(f (y))}
C2λσ
=
{¬p(f (y)), r(y)}
C
=
Res(C1,C2) = {q(f (y)), r(y)}, using λσ
θ′
1
=
{y ←a}
C′
1
=
C1θ1 = {p(f (a)), q(f (a))} = C1λσθ1
θ′
2
=
{y ←a}
C′
2
=
C2θ2 = {¬p(f (a)), r(a)} = C2λσθ2
θ′
=
{y ←a}
C′
=
Res(C′
1,C′
2) = {q(f (a)), r(a)}
Fig. 10.1 Example for the lifting lemma
A node is a failure node if the (partial) interpretation deﬁned by a branch falsiﬁes some
ground instance of a clause in S.
The critical step in the proof is showing that an inference node n can be associated
with the resolvent of the clauses on the two failure nodes n1, n2 below it. Suppose
that C1, C2 are associated with the failure nodes. Then there must be ground in-

202
10
First-Order Logic: Resolution
stances C′
1, C′
2 which are falsiﬁed at the nodes. By construction of the semantic
tree, C′
1 and C′
2 are clashing clauses. Hence they can be resolved to give a clause C′
which is falsiﬁed by the interpretation at n. By the Lifting Lemma, there is a clause
C such that C is the resolvent of C′
1 and C′
2, and C′ is a ground instance of C.
Hence C is falsiﬁed at n and n (or an ancestor of n) is a failure node.
10.6 Summary
General resolution has proved to be a successful method for automated theorem
proving in ﬁrst-order logic. The key to its success is the uniﬁcation algorithm. There
is a large literature on strategies for choosing which clauses to resolve, but that is
beyond the scope of this book. In Chap. 11 we present logic programming, in which
programs are written as formulas in a restricted clausal form. In logic programming,
uniﬁcation is used to compose and decompose data structures, and computation is
carried out by an appropriately restricted form of resolution that is very efﬁcient.
10.7 Further Reading
Loveland (1978) is a classic book on resolution; a more modern one is Fitting
(1996). Our presentation of the uniﬁcation algorithm is taken from Martelli and
Montanari (1982). Lloyd (1987) presents resolution in the context of logic program-
ming that is the subject of the next chapter.
10.8 Exercises
10.1 Prove that ground resolution is sound and complete.
10.2 Let:
θ
= {x ←f (g(y)), y ←u, z ←f (y)},
σ
= {u ←y, y ←f (a), x ←g(u)},
E
= p(x,f (y),g(u),z).
Show that E(θσ) = (Eθ)σ.
10.3 Prove that the composition of substitutions is associative (Lemma 10.10).
10.4 Unify the following pairs of atomic formulas, if possible.
p(a,x,f (g(y))),
p(y,f (z),f (z)),
p(x,g(f (a)),f (x)),
p(f (a),y,y),
p(x,g(f (a)),f (x)),
p(f (y),z,y),
p(a,x,f (g(y))),
p(z,h(z,u),f (u)).

References
203
10.5 A substitution θ = {x1 ←t1, ..., xn ←tn} is idempotent iff θ = θθ. Let V be
the set of variables occurring in the terms {t1,...,tn}. Prove that θ is idempotent iff
V ∩{x1,...,xn} = ∅. Show that the mgu’s produced by the uniﬁcation algorithm is
idempotent.
10.6 Try to unify the set of term equations:
x = f (y),
y = g(x).
What happens?
10.7 Show that the composition of substitutions is not commutative: θ1θ2 ̸= θ2θ2
for some θ1, θ2.
10.8 Unify the atoms in Example 10.13 using both term equations and Robinson’s
algorithm.
10.9 Let S be a ﬁnite set of expressions and θ a uniﬁer of S. Prove that θ is an
idempotent mgu iff for every uniﬁer σ of S, σ = θσ.
10.10 Prove the validity of (some of) the equivalences in by resolution refutation of
their negations.
References
M. Fitting. First-Order Logic and Automated Theorem Proving (Second Edition). Springer, 1996.
J.W. Lloyd. Foundations of Logic Programming (Second Edition). Springer, Berlin, 1987.
D.W. Loveland. Automated Theorem Proving: A Logical Basis. North-Holland, Amsterdam, 1978.
A. Martelli and U. Montanari. An efﬁcient uniﬁcation algorithm. ACM Transactions on Program-
ming Languages and Systems, 4:258–282, 1982.
J.A. Robinson. A machine-oriented logic based on the resolution principle. Journal of the ACM,
12:23–41, 1965.


Chapter 11
First-Order Logic: Logic Programming
Resolution was originally developed as a method for automatic theorem proving.
Later, it was discovered that a restricted form of resolution can be used for pro-
gramming a computation. This approach is called logic programming. A program is
expressed as a set of clauses and a query is expressed as an additional clause that
can clash with one or more of the program clauses. The query is assumed to be the
negation of result of the program. If a refutation succeeds, the query is not a logical
consequence of the program, so its negation must be a logical consequence. Uniﬁ-
cations done during the refutation provide answers to the query in addition to the
simple fact that the negation of the query is true.
In this chapter we give an overview of logic programming. First, we work through
an example for motivation. In the following section, we deﬁne SLD-resolution,
which is the formal system most often used in logical programming. Section 11.4
is an introduction to Prolog, a widely used language for logic programming. The
supplementary materials that can be downloaded contain Prolog implementations
of most of the algorithms in this book.
11.1 From Formulas in Logic to Logic Programming
Consider a deductive system with axioms of two forms. One form is a universally-
closed predicate:
∀x(x + 0 = x).
The other form is a universally-closed implication where the premise is a conjunc-
tion:
∀x∀y∀z(x ≤y ∧y ≤z →x ≤z).
In clausal form, the ﬁrst form is a single positive literal:
x + 0 = x,
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_11, © Springer-Verlag London 2012
205

206
11
First-Order Logic: Logic Programming
whereas the second form is a clause all of whose literals are negative except for the
last one which is positive:
¬(x ≤y) ∨¬(y ≤z) ∨(x ≤z).
These types of clauses are called program clauses.
Suppose now that we have a set of program clauses and we want to prove that
some formula:
G1 ∧··· ∧Gn
is a logical consequence of the set. This can be done by taking the negation of the
formula:
¬(G1 ∧··· ∧Gn) ≡¬G1 ∨··· ∨¬Gn
and refuting it by resolution with the program clauses.
The formula ¬G1 ∨···∨¬Gn, called a goal clause, consists entirely of negative
literals, so it can only clash on the single positive literal of a program clause. Let:
B1 ∨¬B2 ∨··· ∨¬Bm
be a program clause such that G1 and B1 can be uniﬁed by mgu σ. The resolvent is:
(¬G2 ∨··· ∨¬Gn ∨¬B2 ∨··· ∨¬Bm)σ,
which is again a goal clause with no positive literals. We can continue resolving
goal clauses with the program clauses until a unit (negative) goal clause remains
that clashes with a unit (positive) program clause, resulting in the empty clause and
terminating the refutation.
The sequence of resolution steps will generate a sequence of substitutions used
to unify the literals and these substitutions become the answer to the query. Let us
see how this is done in an example.
Refuting a Goal Clause
Consider a fragment of the theory of strings with a single binary function symbol
for concatenation denoted by the inﬁx operator · and three predicates:
• substr(x,y)—x is a substring of y,
• preﬁx(x,y)—x is a preﬁx of y,
• sufﬁx(x,y)—x is a sufﬁx of y.

11.1
From Formulas in Logic to Logic Programming
207
The axioms of the theory are:
1.
∀x substr(x,x),
2.
∀x∀y sufﬁx(x,y · x),
3.
∀x∀y preﬁx(x,x · y),
4.
∀x∀y∀z(substr(x,y) ∧sufﬁx(y,z) →substr(x,z)),
5.
∀x∀y∀z(substr(x,y) ∧preﬁx(y,z) →substr(x,z)).
They can be written in clausal form as:
1.
substr(x,x),
2.
sufﬁx(x,y · x),
3.
preﬁx(x,x · y),
4.
¬substr(x,y) ∨¬sufﬁx(y,z) ∨substr(x,z),
5.
¬substr(x,y) ∨¬preﬁx(y,z) ∨substr(x,z).
We can prove the formula:
substr(a · b · c, a · a · b · c · c)
by refuting its negation:
¬substr(a · b · c, a · a · b · c · c).
Here is a refutation, where the parent clauses of each resolvent are given in the right-
hand column, together with the substitutions needed to unify the clashing clauses:
6.
¬substr(a · b · c, a · a · b · c · c)
7.
¬substr(a · b · c, y1) ∨¬sufﬁx(y1, a · a · b · c · c)
6,4,{x ←a · b · c, y ←y1, z ←a · a · b · c · c}
8.
¬substr(a · b · c, a · b · c · c)
7,2,{x ←a · b · c · c, y ←a, y1 ←a · b · c · c}
9.
¬substr(a · b · c, y2) ∨¬preﬁx(y2, a · b · c · c)
8, 5, {x ←a · b · c, y ←y2, z ←a · b · c · c}
10.
¬substr(a · b · c, a · b · c)
9,3,{x ←a · b · c, y ←c, y2 ←a · b · c}
11.
2
10,1,{x ←a · b · c}
Answer Substitutions
This refutation is not very exciting; all it does is check if substr(a ·b·c, a ·a ·b·c·c)
is true or not. Suppose, however, that instead of determining whether a ground goal
clause is a logical consequence of the axioms, we try to determine if the existentially
quantiﬁed formula ∃w substr(w, a · a · b · c · c) is a logical consequence of the
axioms. In terms of resolution we try to refute the negation of the formula:
¬(∃w substr(w, a · a · b · c · c)) ≡∀w¬ substr(w, a · a · b · c · c).

208
11
First-Order Logic: Logic Programming
A universally quantiﬁed literal is a clause so a resolution refutation of this clause
together with the clauses from the axioms can be attempted:
6.
¬substr(w, a · a · b · c · c)
7.
¬substr(w, y1) ∨¬sufﬁx(y1, a · a · b · c · c)
6,4,{x ←w, y ←y1, z ←a · a · b · c · c}
8.
¬substr(w, a · b · c · c)
7,2,{x ←a · b · c · c, y ←a, y1 ←a · b · c · c}
9.
¬substr(w, y2) ∨¬preﬁx(y2, a · b · c · c)
8,5,{x ←w, y ←y2, z ←a · b · c · c}
10.
¬substr(w, a · b · c)
9,3,{x ←a · b · c, y ←c, y2 ←a · b · c}
11.
2
10,1,{x ←w, w ←a · b · c}
The uniﬁcation in the ﬁnal step of the resolution causes w to receive the substi-
tution {w ←a · b · c}. Not only have we proved that ∃w substr(w, a · a · b · c · c) is
a logical consequence of the axioms, but we have also computed a value a · b · c for
w such that substr(w, a · a · b · c · c) is true.
Refutations as Computations
Given a set of program clauses and a query expressed as a goal clause with no
positive literals, the result of a successful refutation is an answer obtained from the
substitutions carried out during uniﬁcations. In ordinary programming languages,
control of the computation is explicitly constructed by the programmer as part of
the program. This can be instantly recognized by the central place occupied by the
control structures:
if ( ... ) { ... } else { ... }
while ( ... ) { ... }
for ( ... ) { ... }
In logic programming, the programmer writes declarative formulas (program and
goal clauses) that describe the relationship between the input and output. The reso-
lution inference engine supplies a uniform implicit control structure, thus relieving
the programmer of the task of explicitly specifying it. Logic programming abstracts
away from the control structure in the same way that a programming language ab-
stracts away from the explicit memory and register allocation that must be done
when writing assembler.

11.2
Horn Clauses and SLD-Resolution
209
The computation of a logic program is highly nondeterministic:
• Given a goal clause:
¬ substr(w, y1) ∨¬ sufﬁx(y1, a · a · b · c · c),
it is possible that several literals clash with a positive literal of a program clause.
The computation rule of a logic programming language must specify how a literal
in the goal clause is chosen.
• Once a literal has been chosen, it is possible that (after uniﬁcation) it clashes with
the positive literal of several program clauses. The literal ¬ substr(w, y1) in the
goal clause above can be made to clash with both clauses 4 and 5 after uniﬁcation.
The search rule of a logic programming language must specify how a program
clause is chosen.
11.2 Horn Clauses and SLD-Resolution
In this section we present the theoretical basis of logic programming. We start by
deﬁning Horn clauses, the restricted form of clauses used in logic programming.
Refutations of Horn clauses are done by a restriction of the resolution procedure
called SLD-resolution, which is sound and complete for Horn clauses.
11.2.1 Horn Clauses
Deﬁnition 11.1 A Horn clause is a clause of the form:
A ←B1, ..., Bn ≡A ∨¬B1, ..., ¬Bn
with at most one positive literal. The positive literal A is the head and the negative
literals Bi are the body. The following terminology is used with Horn clauses:
• A fact is a positive unit Horn clause A←.
• A goal clause is a Horn clause with no positive literals ←B1, ..., Bn.
• A program clause is a Horn clause with one positive literal and one or more
negative literals.
Logic programming prefers the use of ←, the reverse implication operator, to the
familiar forward implication operator →. The reverse operator in A ←B1, ..., Bn
has the natural reading:
To prove A, prove B1,...,Bn.
We can interpret this computationally as a procedure executing a sequence of state-
ments or calling other procedures: To compute A, compute B1,...,Bn.

210
11
First-Order Logic: Logic Programming
Deﬁnition 11.2
• A set of non-goal Horn clauses whose heads have the same predicate letter is a
procedure.
• A set of procedures is a (logic) program.
• A procedure composed of ground facts only is a database.
Example 11.3 The following program has two procedures p and q; p is also a
database.
1.
q(x,y) ←p(x,y)
2.
q(x,y) ←p(x,z), q(z,y)
3.
p(b,a)
7.
p(f,b)
4.
p(c,a)
8.
p(h,g)
5.
p(d,b)
9.
p(i,h)
6.
p(e,b)
10.
p(j,h)
11.2.2 Correct Answer Substitutions for Horn Clauses
Deﬁnition 11.4 Let P be a program and G a goal clause. A substitution θ for the
variables in G is a correct answer substitution if P |= ∀(¬Gθ), where the universal
quantiﬁcation is taken over all the free variables in ¬Gθ.
Example 11.5 Let P be a set of axioms for arithmetic.
• Let G be the goal clause ¬ (6 + y = 13) and θ the substitution {y ←7}:
∀(¬Gθ) ≡∀(¬¬ (6 + y = 13){y ←7})
≡∀(6 + 7 = 13)
≡(6 + 7 = 13).
Since P |= (6 + 7 = 13), θ is a correct answer substitution for G.
• Let G be the goal clause ¬ (x = y + 13) and θ = {y ←x −13}:
∀(¬Gθ) ≡∀(¬¬ (x = y + 13){y ←x −13})
≡∀x(x = x −13 + 13).
Since P |= ∀x(x = x −13 + 13), θ is a correct answer substitution for G.
• Let G be the goal clause ¬ (x = y + 13) and θ = ε, the empty substitution:
∀(¬Gθ) ≡∀(¬¬ (x = y + 13)ε)
≡∀x∀y(x = y + 13).
Since P ̸|= ∀x∀y(x = y + 13), θ is not a correct answer substitution.

11.2
Horn Clauses and SLD-Resolution
211
Given a program P , goal clause G = ¬G1 ∨··· ∨¬Gn, and a correct answer
substitution θ, by deﬁnition P |= ∀(¬G)θ, so:
P |= ∀(G1 ∧··· ∧Gn)θ.
Therefore, for any substitution σ that makes the conjunction into a ground formula,
(G1 ∧···∧Gn)θσ is true in any model of P . This explains the terminology because
the substitution θσ gives an answer to the query expressed in the goal clause.
11.2.3 SLD-Resolution
Before deﬁning the resolution procedure for logic programs, let use work through
an example.
Example 11.6 Let ←q(y,b), q(b,z) be a goal clause for the program in Exam-
ple 11.3. At each step we must choose a literal within the clause and a clause whose
head clashes with the literal. (For simplicity, the only substitutions shown are those
to the original variables of the goal clause.)
1. Choose q(y,b) and resolve with clause 1 giving ←p(y,b), q(b,z).
2. Choose p(y,b) and resolve with clause 5 giving ←q(b,z).
This requires the substitution {y ←d}.
3. There is only one literal and we resolve it with clause 1 giving ←p(b,z).
4. There is only one literal and we resolve it with clause 3 giving 2.
This requires the substitution {z ←a}.
Therefore, we have a refutation of ←q(y,b), q(b,z) under the substitution θ =
{y ←d,z ←a}. By the soundness of resolution:
P |= ∀¬( ¬q(y,b) ∨¬q(b,z) )θ ),
so that θ is a correct answer substitution and q(d,b) ∧q(b,a) is true in any model
of P .
Deﬁnition 11.7 (SLD-resolution) Let P be a set of program clauses, R a compu-
tation rule and G a goal clause. A derivation by SLD-resolution is a sequence of
resolution steps between goal clauses and the program clauses. The ﬁrst goal clause
G0 is G. Gi+1 is derived from Gi selecting a literal Aj
i ∈Gi, choosing a clause
Ci ∈P such that the head of Ci uniﬁes with Aj
i by mgu θi and resolving:
Gi
= ←A1
i ,...,Aj−1
i
, Aj
i , Aj+1
i
,...,Ani
i
Ci
= B0
i ←B1
i ,...,Bki
i
Aj
i θi
= B0
i θi
Gi+1 = ←(A1
i ,...,Aj−1
i
,B1
i ,...,Bki
i ,Aj+1
i
,...,Ani
i )θi.

212
11
First-Order Logic: Logic Programming
An SLD-refutation is an SLD-derivation of 2.
The rule for selecting a literal Aj
i from a goal clause Gi is the computation rule.
The rule for choosing a clause Ci ∈P is the search rule.
Soundness of SLD-Resolution
Theorem 11.8 (Soundness of SLD-resolution) Let P be a set of program clauses,
R a computation rule and G a goal clause. Suppose that there is an SLD-refutation
of G. Let θ = θ1 ···θn be the sequence of uniﬁers used in the refutation and let σ
be the restriction of θ to the variables of G. Then σ is a correct answer substitution
for G.
Proof By deﬁnition of σ, Gθ = Gσ, so P ∪{Gσ} = P ∪{Gθ} which is unsatisﬁable
by the soundness of resolution. But P ∪{Gσ} is unsatisﬁable implies that P |=
¬Gσ. Since this is true for any substitution into the free variables of Gσ, P |=
∀(¬Gσ).
Completeness of SLD-Resolution
SLD-refutation is complete for sets of Horn clauses but not in general.
Example 11.9 Consider the unsatisﬁable set of clauses S:
1.
p ∨q
2.
¬p ∨q
3.
p ∨¬q
4.
¬p ∨¬q
S is not a set of Horn clauses since p ∨q has two positive literals. S has an un-
restricted resolution refutation, of course, since it is unsatisﬁable and resolution is
complete:
4.
q
1,2
5.
¬q
3,4
6.
2
4,5
However, this is not an SLD-refutation because the ﬁnal step resolves two goal
clauses, not a goal clause with one of the program clauses in S.
Theorem 11.10 (Completeness of SLD-resolution) Let P be a set of program
clauses, R a computation rule, G a goal clause, and σ be a correct answer sub-
stitution. There is an SLD-refutation of G from P such that σ is the restriction of
the sequence of uniﬁers θ = θ1 ···θn to the variables in G.
Proof We will give an outline of the proof which can be found in Lloyd (1987,
Sect. 2.8).

11.3
Search Rules in SLD-Resolution
213
The proof is by induction on the depth of the terms in the goal clause. Consider
the program P :
p(a)
p(f (x))
←
p(x).
Obviously there is a one-step refutation of the goal clause ←p(a) and just as obvi-
ously p(a) is a logical consequence of P .
Given a goal clause Gi = ←p(f (f (···(a)···))), we can resolve it with the
second program clause to obtain Gi−1 = ←p(f (···(a)···)), reducing the depth of
the term. By induction, Gi−1 can be refuted and p(f (···(a)···)) is a logical conse-
quence of P . From Gi−1 and the second clause, it follows that p(f (f (···(a)···)))
is a logical consequence of P .
This bottom-up inductive construction—starting from facts in the program
and resolving with program clauses—deﬁnes an Herbrand interpretation. Given a
ground goal clause whose atoms are in the Herbrand base of the interpretation, it
can be proved by induction that it has a refutation and that its negation is a logical
consequence of P . To prove that a non-ground clause has a refutation, technical
lemmas are needed which keep track of the uniﬁers. The ﬁnal step is a proof that
there exists a refutation regardless of the choice of computation rule.
11.3 Search Rules in SLD-Resolution
Theorem 11.10 states that some SLD-refutation of a program exists regardless of the
computation rule that is used. The same is not true of the choice of the search rule.
In this section we explore the effect that the search rule can have on a refutation.
11.3.1 Possible Outcomes when Attempting a Refutation
The discussion will be based upon the program in Example 11.3, repeated here for
convenience:
1.
q(x,y) ←p(x,y)
2.
q(x,y) ←p(x,z), q(z,y)
3.
p(b,a)
7.
p(f,b)
4.
p(c,a)
8.
p(h,g)
5.
p(d,b)
9.
p(i,h)
6.
p(e,b)
10.
p(j,h)
In Example 11.6, we showed that there is a refutation for the goal ←q(y,b), q(b,z)
with correct answer substitution θ = {y ←d,z ←a}. Consider now the following

214
11
First-Order Logic: Logic Programming
refutation, where we have omitted the steps of standardizing apart the variables of
the program clauses and the substitutions to these new variables:
11.
←q(y,b), q(b,z)
12.
←p(y,b), q(b,z)
1,11
13.
←q(b,z)
6,12,{y ←e}
14.
←p(b,z)
1,13
15.
2
3,14,{z ←a}
The goal clause has been refuted with the substitution {y ←e,z ←a}, showing that
there may be more than one correct answer substitution for a given goal clause and
the answer obtained depends on the search rule.
Suppose now that the computation rule is to always choose the last literal in a
goal clause, in this case q(b,z), and suppose that the search rule always chooses to
resolve literals with the predicate symbol q ﬁrst with clause 2 and only then with
clause 1. The SLD-derivation becomes:
11.
←q(y,b),q(b,z)
12.
←q(y,b),p(b,z′),q(z′,z)
2,11
13.
←q(y,b),p(b,z′),p(z′,z′′),q(z′′,z)
2,12
14.
←q(y,b),p(b,z′),p(z′,z′′),p(z′′,z′′′),q(z′′′,z)
2,13
···
Even though a correct answer substitution exists for the goal clause, this speciﬁc
attempt at constructing a refutation does not terminate.
Returning to the computation rule that always chooses the ﬁrst literal in the goal
clause, we have the following attempt at a refutation:
11.
←q(y,b), q(b,z)
12.
←p(y,z′),q(z′,b),q(b,z)
2,11
13.
←q(b,b),q(b,z)
6,12,{y ←e, z′ ←b}
14.
←p(b,b),q(b,z)
1,13
15.
???
Even though a correct answer substitution exists, the refutation has failed, because
no program clause uniﬁes with p(b,b).
SLD-resolution is very sensitive to the computation and search rules that are
used. Even if there are one or more correct answer substitutions, the resolution pro-
cedure may fail to terminate or terminate without ﬁnding an answer.
11.3.2 SLD-Trees
The set of SLD-derivations for a logic program can be displayed as a tree.
Deﬁnition 11.11 Let P be a set of program clauses, R a computation rule and G a
goal clause. An SLD-tree is generated as follows: The root is labeled with the goal

11.3
Search Rules in SLD-Resolution
215
Fig. 11.1 SLD-tree for selection of leftmost literal
clause G. Given a node n labeled with a goal clause Gn, create a child ni for each
new goal clause Gni that can be obtained by resolving the literal chosen by R with
the head of a clause in P .
Example 11.12 An SLD-tree for the program clauses in Example 11.3 and the goal
clause ←q(y,b) is shown in Fig. 11.1. The computation rule is always to choose
the leftmost literal of the goal clause. This is indicated by underlining the chosen
literal. The number on an edge refers to the number of the program clause resolved
with the goal clause.
Deﬁnition 11.13 In an SLD-tree, a branch leading to a refutation is a success
branch. A branch leading to a goal clause whose selected literal does not unify
with any clause in the program is a failure branch. A branch corresponding to a
non-terminating derivation is an inﬁnite branch.
There are many different SLD-trees, one for each computation rule; nevertheless,
we have the following theorem which shows that all trees are similar. The proof can
be found in Lloyd (1987, Sect. 2.10).
Theorem 11.14 Let P be a program and G be a goal clause. Then every SLD-tree
for P and G has inﬁnitely many success branches or they all have the same ﬁnite
number of success branches.
Deﬁnition 11.15 A search rule is a procedure for searching an SLD-tree for a refu-
tation. An SLD-refutation procedure is the SLD-resolution algorithm together with
the speciﬁcation of a computation rule and a search rule.
Theorem 11.10 states that SLD-resolution is complete regardless of the choice
of the computation rule, but it only says that some refutation exists. The search rule

216
11
First-Order Logic: Logic Programming
will determine if the refutation is found or not and how efﬁcient the search will be.
A breadth-ﬁrst search of an SLD-tree, where the nodes at each depth are checked
before searching deeper in the tree, is guaranteed to ﬁnd a success branch if one
exists, while a depth-ﬁrst search can choose to head down a non-terminating branch
if one exists. In practice, depth-ﬁrst search is preferred because it needs much less
memory: a stack of the path being searched, where each element in the stack records
which the branch taken at each node and the substitutions done at that node. In a
breadth-ﬁrst search, this information must be stored for all the leaves of the search.
11.4 Prolog
Prolog was the ﬁrst logic programming language. There are high-quality implemen-
tations that make Prolog a practical tool for software development.
The computation rule in Prolog is to choose the leftmost literal in the goal clause.
The search rule is to choose clauses from top to bottom in the list of the clauses
of a procedure. The notation of Prolog is different from the mathematical notation
that we have been using: (a) variables begin with upper-case letters, (b) predicates
begin with lower-case letters (as do functions and constants), and (c) the symbol :-
is used for ←.
Let us rewrite program of Example 11.3 using the notation of Prolog. We have
also replaced the arbitrary symbols by symbols that indicate the intended meaning
of the program:
ancestor(X,Y) :- parent(X,Y).
ancestor(X,Y) :- parent(X,Z), ancestor(Z,Y).
parent(bob,allen).
parent(fred,dave).
parent(catherine,allen).
parent(harry,george).
parent(dave,bob).
parent(ida,george).
parent(ellen,bob).
parent(joe,harry).
The database contains facts that we are assuming to be true, such as catherine is a
parent of allen. The procedure for ancestor gives a declarative meaning to this
concept in terms of the parent relation:
• X is an ancestor of Y if X is a parent of Y.
• X is an ancestor of Y if there are Z’s such that X is a parent of Z and Z is
an ancestor of Y.
Using the Prolog computation and search rules, the goal clause:
:- ancestor(Y,bob), ancestor(bob,Z).
will succeed and return the correct answer substitution Y=dave, Z=allen, mean-
ing that dave is an ancestor of bob who in turn is an ancestor of allen.
Here is the refutation:

11.4
Prolog
217
:- ancestor(Y,bob), ancestor(bob,Z).
:- parent(Y, bob), ancestor(bob, Z). { Y <- dave }
:- ancestor(bob, Z).
:- parent(bob, Z).
{ Z <-allen }
:-
11.4.1 Depth-First Search
The search in the proof tree is depth-ﬁrst, which can lead to non-termination of the
computation even if a terminating computation exists. A Prolog programmer must
carefully order clauses within a procedure and literals within clauses to avoid non-
termination.
Since failure may occur at any step, the Prolog implementation must store a list of
backtrack points. These backtrack points represent previous nodes in the SLD-tree
where additional branches exist.
Example 11.16 Consider the program consisting of four facts:
p(a).
p(b).
p(c).
q(c).
and the goal clause:
:- p(X), q(X).
Here is the SLD-tree for this program:
:- p(X), q(X).
↙
↓
↘
:- q(a)
:- q(b)
:- q(c)
×
×
↓
2
The depth-ﬁrst search attempts to resolve the ﬁrst literal p(X) from the goal clause
with p(a). While this succeeds, the goal clause q(a) which results cannot be
resolved. The search must backtrack and try the next clause in the procedure for p,
namely, p(b). Here too, the computation fails and must backtrack again to ﬁnd a
successful refutation.
An important concept in Prolog programming is forcing failure. This is imple-
mented by the predicate fail for which no program clauses are deﬁned. Consider
the goal clause:
:- ancestor(Y,bob), ancestor(bob,Z), fail.

218
11
First-Order Logic: Logic Programming
Once the answer Y=dave, Z=allen is obtained, backtracking will force the refu-
tation to continue and produce a second answer Y=ellen, Z=allen. Prolog lacks
iterative structures such as for- and while-loops, so recursion and forced failure
are fundamental programming techniques in the language.
11.4.2 Prolog and the Theory of Logic Programming
The designers of Prolog added a number of constructs to the language to enable
it become a practical programming language, even though these constructs are not
consistent with the theory of logic programming that we presented in the previous
sections.
Non-logical Predicates
Non-logical predicates are predicates whose main or only purpose is the side-effects
they generate. Obvious examples are the I/O predicates read and write that have
no declarative meaning as logical formulas. As literals in a goal clause, they always
succeed (except that read may fail at end of ﬁle), but they have side-effects causing
data to be read into a variable or displayed on a screen.
Arithmetic
Prolog departs from theoretical logic programming in its treatment of numeric data
types. As we show in Sect. 12.4, it is possible to formalize arithmetic in ﬁrst-order
logic, but there are two problems with the formalism. The ﬁrst is that it would be
unfamiliar, to say the least, to execute a query on the number of employees in a
department and to receive as an answer the term f (f (f (f (f (a))))) instead of 5.
The second problem is the inefﬁciency of resolution as a method for numeric com-
putation.
Prolog supports standard arithmetic computation. The syntax is that of a predi-
cate with an inﬁx operator Result is Expression. The following clause re-
trieves the list price and the discount from a database and computes the value of
Price after applying the discount:
selling_price(Item, Price) :-
list_price(Item, List),
discount_percent(Item, Discount),
Price is List - List * Discount / 100.
Arithmetic predicates differ from ordinary predicates, because they are one-way,
unlike uniﬁcation. If 10 is X+Y were a logical predicate, X and Y could be uniﬁed
with say, 0 and 10, and upon backtracking with 1 and 9, and so on. However, this is

11.4
Prolog
219
illegal. In Result is Expression, Expression must evaluate to a numeric
value, which is then uniﬁed with Result (usually an uninstantiated variable).
Arithmetic predicates are not assignment statements. The following program is
not correct:
selling_price(Item,Price) :-
list_price(Item,List),
discount_percent(Item,Discount),
Price is List - List * Discount / 100,
tax_percent(Item,Tax),
Price is Price * (1 + Tax / 100).
Once Price has been uniﬁed with the result of the computation List - List *
Discount / 100, any attempt to unify again will fail, just as a variable x in a
logical formula cannot be modiﬁed once a ground substitution such as {x ←a} has
been applied. An additional variable must be used to hold the intermediate value:
selling_price(Item,Price) :-
list_price(Item,List),
discount_percent(Item,Discount),
Price1 is List - List * Discount / 100,
tax_percent(Item,Tax),
Price is Price1 * (1 + Tax / 100).
Cuts
The most controversial modiﬁcation of logic programming introduced into Prolog is
the cut. Consider the following program for computing the factorial of a number N:
factorial(0, 1).
factorial(N, F) :-
N1 is N - 1,
factorial(N1, F1),
F is N * F1.
This is a translation into Prolog of the recursive formula:
f (0) = 1,
f (n) = n · f (n −1).
Now assume that factorial is called in another procedure, perhaps for checking
a property of numbers that are factorials:
check(N) :- factorial(N, F), property(F).
If check is called with N=0, it will call factorial(0, F) which will compute
F=1 and call property(1). Suppose that this call fails. Then the SLD-resolution
procedure will backtrack, undo the substitution F=1, and try the second clause in
the procedure for factorial. The recursive call factorial(-1,F1) will initiate a
non-terminating computation. A call to factorial with the argument 0 has only
one possible answer; if we backtrack through it, the goal clause should fail.

220
11
First-Order Logic: Logic Programming
This can be avoided by introducing a cut, denoted by an exclamation point, into
the ﬁrst clause:
factorial(0, 1) :- !.
The cut prevents backtracking in this procedure. Once a cut is executed it cuts away
a portion of the SLD-tree and prevents unwanted backtracking. In the following
diagram, the rightmost branch is cut away, so that if property(1) fails, there is
no longer a backtrack point in its parent node:
:- check(0).
↓
:- factorial(0, F), property(F).
↙
↘
:- property(1)
:- factorial(-1, F1),
property(F1).
×
···
In the case of the factorial procedure there is a better solution, namely, adding a
predicate to the body of the procedure that explicitly prevents the unwanted behav-
ior:
factorial(0, 1).
factorial(N, F) :-
N > 0,
N1 is N - 1,
factorial(N1, F1),
F is N * F1.
11.5 Summary
A Horn clause is a clause that has at most one positive literal. A fact is a unit Horn
clause with one positive literal; a program clause is a Horn clause with one positive
literal and one or more negative literals; a goal clause is a Horn clause with no pos-
itive literals. A logic program consists of a set of program clauses and facts. Given
a logic program and a goal clause, SLD-resolution (which is sound and complete)
can be used to search for a refutation. If a refutation exists, then the negation of
the goal clause is a logical consequence of the program clauses and facts, and the
substitutions made during the refutation form the answer of the program.
Prolog is a logic programming language written as Horn clauses. Computation in
Prolog is by SLD-resolution with a speciﬁc computation rule—choose the leftmost
literal of a goal—and a speciﬁc search rule—choose the program clauses in textual
order.

11.6
Further Reading
221
11.6 Further Reading
Lloyd (1987) presents the theory of SLD resolution in full detail. For more on Pro-
log programming, see textbooks Sterling and Shapiro (1994), Bratko (2011) and
Clocksin and Mellish (2003).
11.7 Exercises
11.1 Let P be the program p(a) ←and G be the goal clause ←p(x). Is the empty
substitution a correct answer substitution? Explain.
11.2 Draw an SLD-tree similar to that of Fig. 11.1 except that the computation rule
is to select the rightmost literal in a clause.
11.3 Given the logic program
p(a,b)
p(c,b)
p(x,y) ←p(x,y),p(y,z)
p(x,y) ←p(y,x),
and the goal clause ←p(a,c), show that if any clause is omitted from the program
then there is no refutation. From this prove that if a depth-ﬁrst search rule is used
with any ﬁxed order of the clauses, there is no refutation no matter what computation
rule is used.
11.4 Given the logic program
p ←q(x,x)
q(x,f (x)),
and the goal clause ←p, prove that there is a refutation if and only if the occurs-
check is omitted. Show that omitting the occurs-check invalidates the soundness of
SLD-resolution.
11.5 Given the logic program
p
←q(x,x)
q(x,f (x)) ←q(x,x),
and the goal clause ←p, what happens if a refutation is attempted without using the
occurs-check?
11.6 Write a logic program for the Slowsort algorithm by directly implementing the
following speciﬁcation of sorting: sort(L1,L2) is true if L2 is a permutation of L1
and L2 is ordered.

222
11
First-Order Logic: Logic Programming
11.7 (Assumes a knowledge of lists.) In Prolog, [] denotes the empty list and
[Head | Tail] denotes the list whose head is Head and whose tail is Tail.
Consider the Prolog program for appending one list to another:
append([], List, List).
append ([Head | Tail], List, [Head | NewTail]) :-
append (Tail, List, NewTail).
It is common to add a cut to the ﬁrst clause of the program:
append([], List, List) :- !.
Compare the execution of the programs with and without the cut for the goal
clauses:
:- append([a,b,c], [d,e,f], List).
:- append([a,b,c], List1, List2).
:- append(List1, List2, [a,b,c]).
11.8 A set of clauses S is renamable-Horn iff there is a set of propositional letters U
such that RU(S) is a set of Horn clauses. (Recall Deﬁnition 6.12 and Lemma 6.13).
Prove the following theorem:
Theorem 11.9 (Lewis) Let S = {C1,...,Cm} be a set of clauses where Ci = li
1 ∨
··· ∨li
ni, and let
S∗=
m

i=1

1≤j<k≤ni
(li
j ∨li
k).
Then S is renamable-Horn if and only if S∗is satisﬁable.
References
I. Bratko. Prolog Programming for Artiﬁcial Intelligence (Fourth Edition). Addison-Wesley,
Boston, 2011.
W.F. Clocksin and C.S. Mellish. Programming in Prolog: Using the ISO Standard. Springer, Berlin,
2003.
J.W. Lloyd. Foundations of Logic Programming (Second Edition). Springer, Berlin, 1987.
L. Sterling and E. Shapiro. The Art of Prolog: Advanced Programming Techniques (Second Edi-
tion). MIT Press, Cambridge, MA, 1994.

Chapter 12
First-Order Logic: Undecidability and Model
Theory *
The chapter surveys several important theoretical results in ﬁrst-order logic. In
Sect. 12.1 we prove that validity in ﬁrst-order logic is undecidable, a result ﬁrst
proved by Alonzo Church. Validity is decidable for several classes of formulas de-
ﬁned by syntactic restrictions on their form (Sect. 12.2). Next, we introduce model
theory (Sect. 12.3): the fact that a semantic tableau has a countable number of nodes
leads to some interesting results. Finally, Sect. 12.4 contains an overview of Gödel’s
surprising incompleteness result.
12.1 Undecidability of First-Order Logic
We show the undecidability of validity in ﬁrst-order logic by reduction from a prob-
lem whose undecidability is already known, the halting problem: to decide whether
a Turing machine will halt if started on a blank tape (Minsky (1967, Sect. 8.3.3),
Manna (1974, Sect. 1-5.2)). The proof that there is no decision procedure for valid-
ity describes an algorithm that takes an arbitrary Turing machine T and generates
a formula ST in ﬁrst-order logic, such that ST is valid if and only if T halts on an
blank tape. If there were a decision procedure for validity, this construction would
give us an decision procedure for the halting problem.
12.1.1 Two-Register Machines
Instead of working directly with Turing machines, we work with a simpler form
of automata: two-register machines. The halting problem for two-register machines
is undecidable because there is a reduction from Turing machines to two-register
machines.
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_12, © Springer-Verlag London 2012
223

224
12
First-Order Logic: Undecidability and Model Theory *
Deﬁnition 12.1 A two-register machine M consists of two registers x and y which
can store natural numbers, and a program P = {L0,...,Ln}, where Ln is the in-
struction halt and for 0 ≤i < n, Li is one of the instructions:
• x = x + 1;
• y = y + 1;
• if (x == 0) goto Lj; else x = x - 1;
• if (y == 0) goto Lj; else y = y - 1;
An execution sequence of M is a sequence of states sk = (Li,x,y), where Li is the
current instruction and x,y are the contents of the registers x and y. sk+1 is obtained
from sk by executing Li. The initial state is s0 = (L0,m,0) for some m. If for some
k, sk = (Ln,x,y), the computation of M halts and M has computed y = f (m).
Theorem 12.2 Let T be a Turing machine that computes a function f . Then there
is a two-register machine MT that computes the function f .
Proof Minsky (1967, Sect. 14.1), Hopcroft et al. (2006, Sect. 7.8).
The proof shows how the contents of the tape of a Turing machine can be encoded
in an (extremely large) natural number and how the modiﬁcations to the tape can be
carried out when copying the contents of one register into another. Clearly, two-
register machines are even more impractical than Turing machines, but it is the
theoretical result that is important.
12.1.2 Church’s Theorem
Theorem 12.3 (Church) Validity in ﬁrst-order logic is undecidable.
Proof Let M be an arbitrary two-register machine. We will construct a formula
SM such that SM is valid iff M terminates when started in the state (L0,0,0). The
formula is:
SM =

p0(a,a) ∧
n−1

i=0
Si

→∃z1∃z2pn(z1,z2),
where Si is deﬁned by cases of the instruction Li:
Li
Si
x = x + 1;
∀x∀y(pi(x,y) →pi+1(s(x),y))
y = y + 1;
∀x∀y(pi(x,y) →pi+1(x,s(y)))
if (x == 0) goto Lj;
else x = x - 1;
∀x(pi(a,x) →pj(a,x)) ∧
∀x∀y(pi(s(x),y) →pi+1(x,y))
if (y == 0) then goto Lj;
else y = y - 1;
∀x(pi(x,a) →pj(x,a)) ∧
∀x∀y(pi(x,s(y)) →pi+1(x,y))

12.1
Undecidability of First-Order Logic
225
The predicates are p0,...,pn, one for each statement in M. The intended meaning
of pi(x,y) is that the computation of M is at the label Li and the values x,y are in
the two registers. The constant a is intended to mean 0 and the function s is intended
to mean the successor function s(m) = m + 1.
s is used both for the function symbol in the formula SM and for states in the
execution of M. The meaning will be clear from the context.
We have to prove that M halts if and only if SM is valid.
If M Halts then SM Is Valid
Let s0,...,sm be a computation of M that halts after m steps; we need to show that
SM is valid, that is, that it is true under any interpretation for the formula. However,
we need not consider every possible interpretation. If I is an interpretation for SM
such that vI (Si) = F for some 0 ≤i ≤n −1 or such that vI (p0(a,a)) = F , then
trivially vI (SM) = T since the antecedent of SM is false. Therefore, we need only
consider interpretations that satisfy the antecedent of SM. For such interpretations,
we need to show that vI (∃z1∃z2pn(z1,z2)) = T . By induction on k, we show that
vI (∃z1∃z2pk(z1,z2)) = T .
If k = 0, the result is trivial since p0(a,a) →∃z1∃z2p0(z1,z2) is valid.
Let us assume the inductive hypothesis for k −1 (provided that k > 0) and prove
vI (∃z1∃z2pk(z1,z2)) = T . We will work through the details when Lk is x=x+1
and leave the other cases to the reader.
By assumption the antecedent is true, in particular, its subformula Sk−1:
vI (∀x∀y(pk−1(x,y) →pk(s(x),y))) = T,
and by the inductive hypothesis:
vI (∃z1∃z2pk−1(z1,z2)) = T,
from which:
vI (∃z1∃z2pk(s(z1),z2)) = T
follows by reasoning in ﬁrst-order logic.
Let c1 and c2 be the domain elements assigned to z1 and z2, respectively, such
that (succ(c1),c2) ∈Pk, where Pk is the interpretation of pk and succ is the inter-
pretation of s. Since c3 = succ(c1) for some domain element c3, the existentially
quantiﬁed formula in the consequent is true:
vI (∃z1∃z2pk(z1,z2)) = T.

226
12
First-Order Logic: Undecidability and Model Theory *
If SM Is Valid then M Halts
Suppose that SM is valid and consider the interpretation:
I = (N ,{P0,...,Pn},{succ},{0}),
where succ is the successor function on N , and (x,y) ∈Pi iff (Li,x,y) is reached
by the register machine when started in (L0,0,0).
We show by induction on the length of the computation that the antecedent of
SM is true in I . The initial state is (L0,0,0), so (a,a) ∈P0 and vI (p0(a,a)) =
T . The inductive hypothesis is that in state sk−1 = (Li,xi,yi), (xi,yi) ∈Pi. The
inductive step is again by cases on the type of the instruction Li. For x=x+1, sk =
(Li+1,succ(xi),yi) and (succ(xi),yi) ∈Pi+1 by the deﬁnition of Pi+1.
Since SM is valid, vI (∃z1∃z2pn(z1,z2)) = T and vI (pn(m1,m2)) = T for
some m1,m2 ∈N . By deﬁnition, (m1,m2) ∈Pn means that M halts and computes
m2 = f (0).
Church’s Theorem holds even if the structure of the formulas is restricted:
• The formulas contain only binary predicate symbols, one constant and one unary
function symbol. This follows from the structure of SM in the proof.
• The formulas are logic programs: a set of program clauses, a set of facts and a
goal clause (Chap. 11). This follows immediately since SM is of this form.
• The formulas are pure (Mendelson, 2009, 3.6).
Deﬁnition 12.4 A formula of ﬁrst-order logic is pure if it contains no function
symbols (including constants which are 0-ary function symbols).
12.2 Decidable Cases of First-Order Logic
Theorem 12.5 There are decision procedures for the validity of pure PCNF formu-
las whose preﬁxes are of one of the forms (where m,n ≥0):
∀x1 ···∀xn ∃y1 ···∃ym,
∀x1 ···∀xn ∃y ∀z1 ···∀zm,
∀x1 ···∀xn ∃y1∃y2 ∀z1 ···∀zm.
These classes are conveniently abbreviated ∀∗∃∗, ∀∗∃∀∗, ∀∗∃∃∀∗.
The decision procedures can be found in Dreben and Goldfarb (1979). This is the
best that can be done because the addition of existential quantiﬁers makes validity
undecidable. See Lewis (1979) for proofs of the following result.

12.3
Finite and Inﬁnite Models
227
Theorem 12.6 There are no decision procedures for the validity of pure PCNF
formulas whose preﬁxes are of one of the forms:
∃z ∀x1 ···∀xn ∃y1 ···∃ym,
∀x1 ···∀xn ∃y1∃y2∃y3 ∀z1 ···∀zm.
For the ﬁrst preﬁx, the result holds even if n = m = 1:
∃z ∀x1 ∃y1,
and for the second preﬁx, the result holds even if n = 0,m = 1:
∃y1∃y2∃y3 ∀z1.
Even if the matrix is restricted to contain only binary predicate symbols, there is
still no decision procedure.
There are other restrictions besides those on the preﬁx that enable decision pro-
cedures to be given (see Dreben and Goldfarb (1979)):
Theorem 12.7 There is a decision procedure for PCNF formulas whose matrix is
of one of the forms:
1. All conjunctions are single literals.
2. All conjunctions are either single atomic formulas or consists entirely of negative
literals.
3. All atomic formulas are monadic, that is, all predicate letters are unary.
12.3 Finite and Inﬁnite Models
Deﬁnition 12.8 A set of formulas U has the ﬁnite model property iff: U is satisﬁ-
able iff it is satisﬁable in an interpretation whose domain is a ﬁnite set.
Theorem 12.9 Let U be a set of pure formulas of the form:
∃x1 ···∃xk∀y1 ···∀ylA(x1,...,xk,y1,...,yl),
where A is quantiﬁer-free. Then U has the ﬁnite model property.
Proof In a tableau for U, once the δ-rules have been applied to the existential quan-
tiﬁers, no more existential quantiﬁers remain. Thus the set of constants will be ﬁnite
and the tableau will terminate once all substitutions using these constants have been
made for the universal quantiﬁers.
Theorem 12.10 (Löwenheim) If a formula is satisﬁable then it is satisﬁable in a
countable domain.
Proof The domain D deﬁned in the proof of completeness is countable.

228
12
First-Order Logic: Undecidability and Model Theory *
Löwenheim’s Theorem can be generalized to countable sets of formulas U =
{A0,A1,A2,...}. Start the tableaux with formula A0 at the root. Whenever con-
structing a node at depth d, add the formula Ad into its label in addition to whatever
formulas are speciﬁed by the tableau rule. If the tableau does not close, eventually,
every Ai will appear on the branch, and the labels will form a Hintikka set. Hin-
tikka’s Lemma and completeness can be proved as before.
Theorem 12.11 (Löwenheim–Skolem) If a countable set of formulas is satisﬁable
then it is satisﬁable in a countable domain.
Uncountable sets such as the real numbers can be described by countably many
axioms (formulas). Thus formulas that describe real numbers also have a countable
model in addition to the standard uncountable model! Such models are called non-
standard models.
As in propositional logic (Theorem 3.48), compactness holds.
Theorem 12.12 (Compactness) Let U be a countable set of formulas. If all ﬁnite
subsets of U are satisﬁable then so is U.
12.4 Complete and Incomplete Theories
Deﬁnition 12.13 Let T (U) be a theory. T (U) is complete if and only if for every
closed formula A, U ⊢A or U ⊢¬A. T (U) is incomplete iff it is not complete,
that is, iff for some closed formula A, U ̸⊢A and U ̸⊢¬A.
It is important not to confuse a complete theory with the completeness of a deduc-
tive system. The latter relates the syntactic concept of proof to the semantic concept
of validity: a closed formula can be proved if and only if it is valid. Completeness
of a theory looks at what formulas are logical consequences of a set of formulas.
In one of the most surprising results of mathematical logic, Kurt Gödel proved
that number theory is incomplete. Number theory, ﬁrst developed by Guiseppe
Peano, is a ﬁrst-order logic with one constant symbol 0, one binary predicate sym-
bol =, one unary function symbol s representing the successor function and two
binary function symbols +, ∗. A set of axioms for number theory N T consists of
eight axioms and one axiom scheme for induction (Mendelson, 2009, 3.1).
Theorem 12.14 (Gödel’s Incompleteness Theorem) If T (N T ) is consistent then
T (N T ) is incomplete.
If T (N T ) were inconsistent, that is, if a theorem and its negation were both
provable, then by Theorem 3.43, every formula would be a theorem so the theory
would have be of no interest whatsoever.
The detailed proof of Gödel’s theorem is tedious but not too difﬁcult. An informal
justiﬁcation can be found in Smullyan (1978). Here we give a sketch of the formal

12.5
Summary
229
proof (Mendelson, 2009, 3.4–3.5). The idea is to deﬁne a mapping, called a Gödel
numbering, from logical objects such as formulas and proofs to natural numbers,
and then to prove the following theorem.
Theorem 12.15 There exists a formula A(x,y) in N T with the following prop-
erty: For any numbers i, j, A(i,j) is true if and only if i is the Gödel number
associated with some formula B(x) with one free variable x, and j is the Gödel
number associated with the proof of B(i). Furthermore, if A(i,j) is true then a
proof can be constructed for these speciﬁc integers ⊢A(i,j).
Consider now the formula C(x) = ∀y¬A(x,y) which has one free variable x,
and let m be the Gödel number of this formula C(x). Then C(m) = ∀y¬A(m,y)
means that for no y is y the Gödel number of a proof of C(m)!
Theorem 12.16 (Gödel) If N T is consistent then ̸⊢C(m) and ̸⊢¬C(m).
Proof We show that assuming either ⊢C(m) or ⊢¬C(m) contradicts the consis-
tency of N T .
• Suppose that ⊢C(m) = ∀y¬A(m,y) and compute n, the Gödel number of this
proof. Then A(m,n) is true and by Theorem 12.15, ⊢A(m,n). Now apply Ax-
iom 4 of ﬁrst-order logic to C(m) to obtain ⊢¬A(m,n). But ⊢A(m,n) and
⊢¬A(m,n) contradict the consistency of N T .
• Suppose that ⊢¬C(m) = ¬∀y¬A(m,y) = ∃yA(m,y). Then for some n,
A(m,n) is true, where n is the Gödel number of a proof of C(m), that is, ⊢C(m).
But we assumed ⊢¬C(m) so N T is inconsistent.
12.5 Summary
The decidability of validity for ﬁrst-order logic has been investigated in detail and it
is possible to precisely demarcate restricted classes of formulas which are decidable
from less restricted classes that are not decidable. The Löwenheim-Skolem Theo-
rem is surprising since it means that it is impossible to characterize uncountable
structures in ﬁrst-order logic. Even more surprising is Gödel’s incompleteness re-
sult, since it demonstrates that there are true formulas of mathematical theories that
cannot be proved in the theories themselves.
12.6 Further Reading
The two sides of the decidability question are comprehensively presented by Dreben
and Goldfarb (1979) and Lewis (1979). The details of Gödel numbering can be
found in (Mendelson, 2009, Chap. 3) and (Monk, 1976, Chap. 3). For an introduc-
tion to model theory see (Monk, 1976, Part 4).

230
12
First-Order Logic: Undecidability and Model Theory *
12.7 Exercises
12.1 Prove that a formula is satisﬁable iff it is satisﬁable in an inﬁnite model.
12.2 Prove the Löwenheim-Skolem Theorem (12.11) using the construction of se-
mantic tableaux for inﬁnite sets of formulas.
12.3 A closed pure formula A is n-condensable iff every unsatisﬁable conjunction
of instances of the matrix of A contains an unsatisﬁable subconjunction made up of
n or fewer instances.
• Let A be a PCNF formula whose matrix is a conjunction of literals. Prove that A
is 2-condensable.
• Let A be a PCNF formula whose matrix is a conjunction of positive literals and
disjunctions of negative literals. Prove that A is n + 1-condensable, where n is
the maximum number of literals in a disjunction.
12.4 * Prove Church’s Theorem by reducing Post’s Correspondence Problem to
validity in ﬁrst-order logic.
References
B. Dreben and W.D. Goldfarb. The Decision Problem: Solvable Classes of Quantiﬁcational For-
mulas. Addison-Wesley, Reading, MA, 1979.
J.E. Hopcroft, R. Motwani, and J.D. Ullman. Introduction to Automata Theory, Languages and
Computation (Third Edition). Addison-Wesley, 2006.
H.R. Lewis. Unsolvable Classes of Quantiﬁcational Formulas. Addison-Wesley, Reading, MA,
1979.
Z. Manna. Mathematical Theory of Computation. McGraw-Hill, New York, NY, 1974. Reprinted
by Dover, 2003.
E. Mendelson. Introduction to Mathematical Logic (Fifth Edition). Chapman & Hall/CRC, 2009.
M.L. Minsky. Computation: Finite and Inﬁnite Machines. Prentice-Hall, Englewood Cliffs, NJ,
1967.
J.D. Monk. Mathematical Logic. Springer, 1976.
R.M. Smullyan. What Is the Name of This Book?—The Riddle of Dracula and Other Logical
Puzzles. Prentice-Hall, 1978.

Chapter 13
Temporal Logic: Formulas, Models, Tableaux
Temporal logic is a formal system for reasoning about time. Temporal logic has
found extensive application in computer science, because the behavior of both hard-
ware and software is a function of time. This section will follow the same approach
that we used for other logics: we deﬁne the syntax of formulas and their interpreta-
tions and then describe the construction of semantic tableaux for deciding satisﬁa-
bility.
Unlike propositional and ﬁrst-order logics whose variants have little theoretical
or practical signiﬁcance, there are many temporal logics that are quite different from
each other. A survey of this ﬂexibility is presented in Sect. 13.3, but you can skim
it and go directly to Sect. 13.4 that presents the logic we focus on: linear temporal
logic.
13.1 Introduction
Example 13.1 Here are some examples of speciﬁcations that use temporal concepts
(italicized):
• After the reset-line of a ﬂip-ﬂop is asserted, the zero-line is asserted. The output
lines maintain their values until the set-line is asserted; then they are comple-
mented.
• If a request is made to print a ﬁle, eventually the ﬁle will be printed.
• The operating system will never deadlock.
The temporal aspects of these speciﬁcation can be expressed in ﬁrst-order logic
using quantiﬁed variables for points in time:
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_13, © Springer-Verlag London 2012
231

232
13
Temporal Logic: Formulas, Models, Tableaux
∀t1(reset(t1) →∃t2(t2 ≥t1 ∧zero(t2))),
∀t1∃n(output(t1) = n∧
∃t2(t2 ≥t1 ∧set(t2) ∧output(t2 + 1) = 1 −n∧
∀t3(t1 ≤t3 < t2 →output(t3) = n))),
∀t1(RequestPrint(t1) →∃t2(t2 ≥t1 ∧PrintedAt(t2))),
∀t¬deadlocked(t).
The use of explicit variables for points of time is awkward, especially since the
speciﬁcations do not actually refer to concrete values of time. ‘Eventually’ simply
means at any later time; the speciﬁcation does not require that the ﬁle be printed
within one minute or ten minutes. Temporal logic introduces new operators that
enable abstract temporal relations like ‘eventually’ to be expressed directly within
the logic.
Temporal logics are related to formal systems called modal logics. Modal logics
express the distinction between what is necessarily true and what is possibly true.
For example, the statement ‘7 is a prime number’ is necessarily true because—
given the deﬁnitions of the concepts in the statement—the statement is true always
and everywhere. In contrast, the statement the head of state of this country is a
king is possibly true, because its truth changes from place to place and from time
to time. Temporal logic and modal logic are related because ‘always’ is similar to
‘necessarily’ and ‘eventually’ to ‘possibly’.
Although temporal and modal logics ﬁrst appeared in Greek philosophy, their
vague concepts proved difﬁcult to formalize and an acceptable formal semantics for
modal logic was ﬁrst given by Saul Kripke in 1959. In 1977, Amir Pnueli showed
that temporal logic can specify properties of concurrent programs and that Kripke’s
semantics could be adapted to develop a formal theory of the temporal logic of pro-
grams. In this chapter and the next one we present the theory of linear temporal
logic. Chapter 16 shows how the logic can be used for the speciﬁcation of correct-
ness properties of concurrent programs and for the veriﬁcation of these properties.
In that chapter, we will describe another temporal logic called computational tree
logic that is also widely used in computer science.

13.2
Syntax and Semantics
233
13.2 Syntax and Semantics
13.2.1 Syntax
The initial presentation of the syntax and semantics of temporal logic will follow
that used for general modal logics. We do this so that the presentation will be useful
for readers who have a broader interest in modal logic and so that temporal logic can
be seen within this wider context. Later, we specialize the presentation to a speciﬁc
temporal logic that is used for the speciﬁcation and veriﬁcation of programs.
Deﬁnition 13.2 The syntax of propositional temporal logic (PTL) is deﬁned like
the syntax of propositional logic (Deﬁnition 2.1), except for the addition of two
additional unary operators:
• 2, read always,
• 3, read eventually.
The discussion of syntax in Sect. 2.1 is extended appropriately: formulas of PTL
are trees so they are unambiguous and various conventions are used to write the
formulas as linear text. In particular, the two unary temporal logic operators have
the same precedence as negation.
Example 13.3 The following are syntactically correct formulas in PTL:
p∧q,
2p,
3(p∧q)→3p,
22p↔2p,
32p↔23p,
¬3p∧2¬q.
The formula ¬3p ∧2¬q is not ambiguous because the temporal operators and
negation have higher precedence than the conjunction operator. The formula can be
written (¬3p) ∧(2¬q) to distinguish it from ¬(3p ∧2¬q).
13.2.2 Semantics
Informally, 2 is a universal operator meaning ‘for any time t in the future’, while
3 is an existential operator meaning ‘for some time t in the future’. Two of the
formulas from Example 13.1 can be written as follows in PTL:
2(reset →3zero),
2¬deadlocked.
Interpretations of PTL formulas are based upon state transition diagrams. The
intuitive meaning is that each state represents a world and a formula can have dif-
ferent truth values in different worlds. The transitions represent changes from one
world to another.

234
13
Temporal Logic: Formulas, Models, Tableaux
Fig. 13.1 State transition
diagram
Deﬁnition 13.4 A state transition diagram is a directed graph. The nodes are states
and the edges are transitions. Each state is labeled with a set of propositional literals
such that clashing literals do not appear in any state.
Example 13.5 Figure 13.1 shows a state transition diagram where states are circles
labeled with literals and transitions are arrows.
In modal logic, necessarily means in all (reachable) worlds, whereas possibly
means in some (reachable) world. If a formula is possibly true, it can be true in
some worlds and false in another.
Example 13.6 Consider the formula A = the head of state of this country is a king.
The formula is possibly true but not necessarily true. If the possible worlds are the
different countries, then at the present time A is true in Spain, false in Denmark
(because the head of state is a queen) and false in France (which does not have a
royal house). Even in a single country, the truth of A can change over time if a king
is succeeded by a queen or if a monarchy becomes a republic.
Temporal logic is similar to modal logic except that the states are considered
to specify what is true at a particular point of time and the transitions deﬁne the
passage of time.
Example 13.7 Consider the formula A = it is raining in London today. On the day
that this is being written, A is false. Let us consider each day as a state and the
transitions to be the passage of time from one day to the next. Even in London 2A
(meaning every day, it rains in London) is not true, but 3A (meaning eventually,
London will have a rainy day) is certainly true.
We are now ready to deﬁne the semantics of PTL. An interpretation is a state tran-
sition diagram and the truth value of a formula is computed using the assignments to
atomic propositions in each state and their usual meaning of the propositional oper-
ators. A formula that contains a temporal operator is interpreted using the transitions
between the states.

13.2
Syntax and Semantics
235
Fig. 13.2 Alternate
representation of the state
transition diagram in
Fig. 13.1
Deﬁnition 13.8 An interpretation I for a formula A in PTL is a pair (S ,ρ), where
S = {s1,...,sn} is a set of states each of which is an assignment of truth values to
the atomic propositions in A, si : P →{T,F}, and ρ is a binary relation on the
states, ρ ⊆S × S.
When displaying an interpretation graphically, the states are usually labeled only
with the atomic propositions that are assigned T (Fig. 13.2). If an atom is not shown
in the label of a state, it is assumed to be assigned F . Since it is clear how to trans-
form one representation to the other, we will use whichever one is convenient.
A binary relation can be considered to be a mapping from a state to a set of
states ρ : S →2S, so the relational notation (s1,s2) ∈ρ will usually be written
functionally as s2 ∈ρ(s1).
Example 13.9 In Fig. 13.2:
s0(p) = T,
s0(q) = F,
s1(p) = T,
s1(q) = T,
s2(p) = F,
s2(q) = T,
s3(p) = F,
s3(q) = F.
ρ(s0) = {s1,s2},
ρ(s1) = {s1,s2,s3},
ρ(s2) = {s1},
ρ(s3) = {s2,s3}.

236
13
Temporal Logic: Formulas, Models, Tableaux
Deﬁnition 13.10 Let A be a formula in PTL. vI ,s(A), the truth value of A in s, is
deﬁned by structural induction as follows:
• If A is p ∈P, then vI ,s(A) = s(p).
• If A is ¬A′ then vI ,s(A) = T iff vI ,s(A′) = F .
• If A is A′ ∨A′′ then vI ,s(A) = T iff vI ,s(A′) = T or vI ,s(A′′) = T ,
and similarly for the other Boolean operators.
• If A is 2A′ then vI ,s(A) = T iff vI ,s′(A′) = T for all states s′ ∈ρ(s).
• If A is 3A′ then vI ,s(A) = T iff vI ,s′(A′) = T for some state s′ ∈ρ(s).
The notation s |=I A is used for vI ,s(A) = T . When I is clear from the context,
it can be omitted s |= A iff vs(A) = T .
Example 13.11 Let us compute the truth value of the formula 2p ∨2q for each
state s in Fig. 13.2.
• ρ(s0) = {s1,s2}. Since s1 |= q and s2 |= q, it follows that s0 |= 2q. By the seman-
tics of ∨, s0 |= 2p ∨2q.
• s3 ∈ρ(s1), but s3 ̸|= p and s3 ̸|= q, so s1 ̸|= 2p and s1 ̸|= 2q. Therefore, s1 ̸|=
2p ∨2q.
• ρ(s2) = {s1}. Since s1 |= p, we have s2 |= 2p and s2 |= 2p ∨2q.
• s3 ∈ρ(s3). s3 ̸|= 2p ∨2q by the same argument used for s1.
13.2.3 Satisﬁability and Validity
The deﬁnition of semantic properties in PTL is more complex than it is in proposi-
tional or ﬁrst-order logic, because an interpretation consists of both states and truth
values.
Deﬁnition 13.12 Let A be a formula in PTL.
• A is satisﬁable iff there is an interpretation I = (S ,ρ) for A and a state s ∈S
such that s |=I A.
• A is valid iff for all interpretations I = (S ,ρ) for A and for all states s ∈S ,
s |=I A. Notation: |= A.
Example 13.13 The analysis we did for the formula A = 2p∨2q in Example 13.11
shows that A is satisﬁable because s0 |=I A or because s2 |=I A. The formulas A
is not valid because s1 ̸|=I A or because s3 ̸|=I A.
We leave it as an exercise to show that any valid formula of propositional logic
is a valid formula of PTL, as is any substitution instance of a valid propositional
formula obtained by substituting PTL formulas uniformly for propositional letters.
For example, 2p →(2q →2p) is valid since it is a substitution instance of the
valid propositional formula A →(B →A).

13.3
Models of Time
237
There are other formulas of PTL that are valid because of properties of temporal
logic and not as instances of propositional validities. We will prove the validity of
two formulas directly from the semantic deﬁnition. The ﬁrst establishes a duality
between 2 and 3, and the second is the distribution of 2 over →, similar to the
distribution of ∀over →.
Theorem 13.14 (Duality) |= 2p ↔¬3¬p.
Proof Let I = (S ,ρ) be an arbitrary interpretation for the formula and let s be an
arbitrary state in S . Assume that s |= 2p, and suppose that s |= 3¬p. Then there
exists a state s′ ∈ρ(s) such that s′ |= ¬p. Since s |= 2p, for all states t ∈ρ(s), t |=
p, in particular, s′ |= p, contradicting s′ |= ¬p. Therefore, s |= ¬3¬p. Since I
and s were arbitrary we have proved that |= 2p →¬3¬p. We leave the converse
as an exercise.
Theorem 13.15 |= 2(p →q) →(2p →2q).
Proof Suppose, to the contrary, that there is an interpretation I = (S,ρ) and a state
s ∈S, such that s |= 2(p →q) and s |= 2p, but s |= ¬2q. By Theorem 13.14,
s |= ¬2q is equivalent to s |= 3¬q, so there exists a state s′ ∈ρ(s) such that
s′ |= ¬q. By the ﬁrst two assumptions, s′ |= p →q and s′ |= p, which imply s′ |= q,
a contradiction.
13.3 Models of Time
In modal and temporal logics, different logics can be obtained by placing restrictions
on the transition relation. In this section, we discuss the various restrictions, leading
up to the ones that are appropriate for the temporal logics used in computer science.
For each restriction on the transition relation, we give a formula that characterizes
interpretations with that restriction. Proofs of the characterizations are given in a
separate subsection.
Reﬂexivity
Deﬁnition 13.16 An interpretation I = (S ,ρ) is reﬂexive iff ρ is a reﬂexive rela-
tion: for all s ∈S , (s,s) ∈ρ, or s ∈ρ(s) in functional notation.
Consider the formula 3running, whose intuitive meaning is eventually the pro-
gram is in the state ‘running’. Obviously, if a program is running now, then there is
an reachable state (namely, now) in which the program is running. Thus it is reason-
able to require that interpretations for properties of programs be reﬂexive.
Theorem 13.17 An interpretation with a reﬂexive relation is characterized by the
formula 2A →A (or, by duality, by the formula A →3A).

238
13
Temporal Logic: Formulas, Models, Tableaux
Transitivity
Deﬁnition 13.18 An interpretation I = (S ,ρ) is transitive iff ρ is a transitive
relation: for all s1,s2,s3 ∈S , s2 ∈ρ(s1) ∧s3 ∈ρ(s2) →s3 ∈ρ(s1).
It is natural to require that interpretations be transitive. Consider a situation where
we have proved that s1 |= 3running because s2 |= running for s2 ∈ρ(s1), and, fur-
thermore, we have proved s2 |= 3running because s3 |= running for s3 ∈ρ(s2). It
would be very strange if s3 ̸∈ρ(s1) and could not be used to prove s1 |= 3running.
Theorem 13.19 An interpretation with a transitive relation is characterized by the
formula 2A →22A (or by the formula 33A →3A).
Example 13.20 In Fig. 13.2, ρ is not transitive since s1 ∈ρ(s2) and s3 ∈ρ(s1) but
s3 ̸∈ρ(s2). This leads to the anomalous situation where s2 |= 2p but s2 ̸|= 22p.
Corollary 13.21 In an interpretation that both is reﬂexive and transitive, |= 2A ↔
22A and |= 3A ↔33A.
Linearity
Deﬁnition 13.22 An interpretation I = (S ,ρ) is linear if ρ is a function, that is,
for all s ∈S , there is at most one s′ ∈S such that s′ ∈ρ(s).
It might appear that a linear temporal logic would be limited to expressing proper-
ties of sequential programs and could not express properties of concurrent programs,
where each state can have several possible successors depending on the interleaving
of the statements of the processes. However, linear temporal logic is successful pre-
cisely in the context of concurrent programs because there is an implicit universal
quantiﬁcation in the deﬁnitions.
Suppose we want to prove that a program satisﬁes a correctness property ex-
pressed as a temporal logic formula like A = 23running: in any state, the execu-
tion will eventually reach a state in which the computation is running. The program
will be correct if this formula is true in every possible execution of the program
obtained by interleaving the instructions of its processes. Each interleaving can be
considered as a single linear interpretation, so if we prove |=I A for an arbitrary
linear interpretation I , then the correctness property holds for the program.
Discreteness
Although the passage of time is often considered to be continuous and expressible by
real numbers, the execution of a program is considered to be a sequence of discrete
steps, where each step consists of the execution of a single instruction of the CPU.
Thus it makes sense to express the concept of the next instant in time. To express
discrete steps in temporal logic, an additional operator is added.

13.3
Models of Time
239
Deﬁnition 13.23 The unary operator # is called next.
The deﬁnition of the truth value of a formula is extended as expected:
Deﬁnition 13.24 If A is #A′ then vI ,s(A) = T iff vI ,s′(A′) = T for some s′ ∈
ρ(s).
The next operator is self-dual in a linear interpretation.
Theorem 13.25 A linear interpretation whose relation ρ is a function is character-
ized by the formula #A ↔¬#¬A.
The operator # plays a crucial role in the theory of temporal logic and in al-
gorithms for deciding properties like satisﬁability, but it is rarely used to express
properties of programs. In a concurrent program, not much can be said about what
happens next since we don’t know which operation will be executed in the next
step. Furthermore, we want a correctness statement to hold regardless of how the
interleaving selects a next operation. Therefore, properties are almost invariably ex-
pressed in terms of always and eventually, not in terms of next.
13.3.1 Proofs of the Correspondences *
The following deﬁnition enables us to talk about the structure (the states and tran-
sitions) of an entire class of interpretations while abstracting away from the assign-
ment to atomic propositions in each state. A frame is obtained from an interpretation
by ignoring the assignments in the states; conversely, a interpretation is obtained
from a frame by associating an assignment with each state.
Deﬁnition 13.26 A frame F is a pair (W ,ρ), where W is a set of states and ρ
is a binary relation on states. An interpretation I = (S ,ρ) is based on a frame
F = (W ,ρ) iff there is a one-to-one mapping from S onto W .
A PTL formula A characterizes a class of frames iff for every Fi in the class,
the set of interpretations I based on Fi is the same as the set of interpretations in
which A is true.
Theorems 13.17, 13.19 and 13.25 are more precisely stated as follows: the for-
mulas 2A →A, 2A →22A and #A ↔¬#¬A characterize the sets of reﬂexive,
transitive, and linear frames, respectively.
Proof of Theorem 13.17 Let Fi be a reﬂexive frame, let I be an arbitrary inter-
pretation based on Fi, and suppose that ̸|=I 2A →A. Then there is a state s ∈S
such that s |=I 2A and s ̸|=I A. By the deﬁnition of 2, for any state s′ ∈ρ(s),
s′ |=I A. By reﬂexivity, s ∈ρ(s), so s |=I A, a contradiction.
Conversely, suppose that Fi is not reﬂexive, and let s ∈S be a state such that
s ̸∈ρ(s). If ρ(s) is empty, 2p is vacuously true in s; by assigning F to vs(p),
s ̸|=I 2p →p. If ρ(s) is non-empty, let I be an interpretation based on Fi such

240
13
Temporal Logic: Formulas, Models, Tableaux
that vs(p) = F and vs′(p) = T for all s′ ∈ρ(s). These assignments are well-deﬁned
since s ̸∈ρ(s). Then s ̸|=I 2p →p.
Proof of Theorem 13.19 Let Fi be a transitive frame, let I be an arbitrary interpre-
tation based on Fi, and suppose that ̸|=I 2A→22A. Then there is an s ∈S such
that s |=I 2A and s ̸|=I 22A. From the latter formula, there must be an s′ ∈ρ(s)
such that s′ ̸|=I 2A, and, then, there must be an s′′ ∈ρ(s′) be such that s′′ ̸|=I A.
But s |=I 2A, and by transitivity, s′′ ∈ρ(s), so s′′ |=I A, a contradiction.
Conversely, suppose that Fi is not transitive, and let s,s′,s′′ ∈S be states such
that s′ ∈ρ(s), s′′ ∈ρ(s′), but s′′ ̸∈ρ(s). Let I be an interpretation based on Fi
which assigns T to p in all states in ρ(s) and F to p in s′′, which is well-deﬁned
since s′′ ̸∈ρ(s). Then s |=I 2p, but s ̸|=I 22p. If there are only two states, s′
need not be distinct from s. A one state frame is necessarily transitive, possibly
vacuously if the relation is empty.
We leave the proof of Theorem 13.25 as an exercise.
13.4 Linear Temporal Logic
In the context of programs, the natural interpretations of temporal logic formulas
are discrete, reﬂexive, transitive and linear. There is another restriction that sim-
pliﬁes the presentation: the transition function must be total so that each state has
exactly one next state. An interpretation for a computation that terminates in state s
is assumed to have a transition from s to s.
Deﬁnition 13.27 Linear temporal logic (LTL) is propositional temporal logic
whose interpretations are limited to transitions which are discrete, reﬂexive, tran-
sitive, linear and total.
These interpretations can be represented as inﬁnite paths:
Since there is only one transition out of each state, it need not be explicitly repre-
sented, so interpretations in LTL are deﬁned to be paths of states:
Deﬁnition 13.28 An interpretation for an LTL formula A is a path of states:
σ = s0,s1,s2,...,
where each si is an assignment of truth values to the atomic propositions in A,
si : P →{T,F}. Given σ, σi is the path that is the ith sufﬁx of σ:
σi = si,si+1,si+2,....
vσ(A), the truth value of A in σ, is deﬁned by structural induction:

13.4
Linear Temporal Logic
241
• If A is p ∈P, then vσ(A) = s0(p).
• If A is ¬A′ then vσ(A) = T iff vσ(A′) = F .
• If A is A′ ∨A′′ then vσ(A) = T iff vσ(A′) = T or vσ(A′′) = T , and similarly for
the other Boolean operators.
• If A is #A′ then vσ(A) = T iff vσ1(A′) = T .
• If A is 2A′ then vσ(A) = T iff vσi(A′) = T for all i ≥0.
• If A is 3A′ then vσ(A) = T iff vσi(A′) = T for some i ≥0.
If vσ(A) = T , we write σ |= A.
Deﬁnition 13.29 Let A be a formula in LTL. A is satisﬁable iff there is an interpre-
tation σ for A such that σ |= A. A is valid iff for all interpretations σ for A, σ |= A.
Notation: |= A.
Deﬁnition 13.30 A formula of the form #A or ¬#A is a next formula. A formula
of the form 3A or ¬2A is a future formula.
13.4.1 Equivalent Formulas in LTL
This section presents LTL formulas that are equivalent because of their temporal
properties. Since any substitution instance of a formula in propositional logic is also
an LTL formula, the equivalences in Sect. 2.3.3 also hold.
The equivalences are expressed in terms of an atom p but the intention is that
they hold for arbitrary LTL formulas A.
The following formulas are direct consequences of our restriction of interpreta-
tions in LTL. The ﬁrst three hold because interpretations are total, while the fourth
holds because of linearity.
Theorem 13.31
|= 2p →#p,
|= #p →3p,
|= 2p →3p,
|= #p ↔¬#¬p.
Inductive
The following theorem is extremely important because it provides an method for
proving properties of LTL formulas inductively.
Theorem 13.32
|= 2p ↔p ∧#2p,
|= 3p ↔p ∨#3p.
These formulas can be easily understood by reading them in words: For a formula
to be always true, p must be true today and, in addition, p must be always true
tomorrow. For a formula to be true eventually, either p is true today or it must be
true in some future of tomorrow.
We prove the ﬁrst formula; the second follows by duality.

242
13
Temporal Logic: Formulas, Models, Tableaux
Proof Let σ be an arbitrary interpretation and assume that σ |= 2p. By deﬁnition,
σi |= p for all i ≥0; in particular, σ0 |= p. But σ0 is the same as σ, so σ |= p. If
σ ̸|= #2p, then σ1 ̸|= 2p, so for some i ≥1, σi ̸|= p, contradicting σ |= 2p.
Conversely, assume that σ |= p ∧#2p. We prove by induction that σi |= p ∧
#2p for all i ≥0. Since |= A ∧B →A is a valid formula of propositional logic,
we can conclude that σi |= p for all i ≥0, that is, σ |= 2p.
The base case is immediate from the assumption since σ0 = σ. Assume the
inductive hypothesis that σi |= p ∧#2p. By deﬁnition of the semantics of #,
σi+1 |= 2p, that is, for all j ≥i + 1, σj |= p, in particular σi+1 |= p. Furthermore,
for j ≥i + 2, σj |= p, so σi+2 |= 2p and σi+1 |= #2p.
Induction in LTL is based upon the following valid formula:
|= 2(p →#p) →(p →2p).
The base case is to show that p holds in a state. The inductive assumption is p
and the inductive step is to show that p →#p. When these two steps have been
performed, we can conclude that 2p.
Instead of proving the following equivalences semantically as in Theorem 13.32,
we will prove them deductively in Chap. 14. By the soundness of the deductive
system, they are valid.
Distributivity
The operators 2 and # distribute over conjunction:
|= 2(p ∧q) ↔(2p ∧2q),
|= #(p ∧q) ↔(#p ∧#q).
The next operator also distributes over disjunction because it is self-dual, but 2 only
distributes over disjunction in one direction:
|= (2p ∨2q) →2(p ∨q),
|= #(p ∨q) ↔(#p ∨#q).
By duality, there are similar formulas for 3:
|= 3(p ∨q) ↔(3p ∨3q),
|= 3(p ∧q) →(3p ∧3q).
Similarly, 2 and # distribute over implication in one direction, while # distributes
in both directions:
|= 2(p →q) →(2p →2q),
|= (3p →3q) →3(p →q),
|= #(p →q) ↔(#p →#q).

13.4
Linear Temporal Logic
243
Example 13.33 Here is a counterexample to |= (3p ∧3q) →3(p ∧q):
The atomic proposition p is true in even-numbered states, while q is true in odd-
numbered states, but there is no state in which both are true.
Commutativity
The operator # commutes with 2 and 3, but 2 and 3 commute only in one direc-
tion:
|= 2#p ↔#2p,
|= 3#p ↔#3p,
|= 32p →23p.
Be careful to distinguish between 23p and 32p. The formula 23p means in-
ﬁnitely often: p is not required to hold continuously, but at any state it will hold at
some future state.
The formula 32p means for all but a ﬁnite number of states: in a path σ =
s0,s1,s2,... , there is a natural number n such that p is true in all states in
σn = sn,sn+1,sn+2,... .
Theorem 13.34 |= (32p ∧23q) →23(p ∧q).
Once p becomes always true, it will be true in the (inﬁnite number of) states
where q is true. We leave the proof as an exercise.
The diagram in Example 13.33 is also a counterexample to the formula: |=
(23p ∧23q) →23(p ∧q).
Collapsing
In a formula without the # operator, no more than two temporal operators need
appear in a sequence. A sequence of identical operators 2 or 3 is equivalent to a
single occurrence and a sequence of three non-identical operators collapses to a pair
of operators:

244
13
Temporal Logic: Formulas, Models, Tableaux
|= 22p ↔2p,
|= 33p ↔3p,
|= 232p ↔32p,
|= 323p ↔23p.
13.5 Semantic Tableaux
The method of semantic tableaux is a decision procedure for satisﬁability in LTL.
The construction of a semantic tableau for a formula of LTL is more complex than
that it is for a formula of propositional logic for two reasons:
First, to show that a formula in propositional logic is satisﬁable, one need only
ﬁnd a single assignment to the atomic propositions that makes the formula evaluate
to true. In LTL, however, there are many different assignments, one for each state.
Therefore, we need to distinguish between ordinary nodes in the tableau used to
decompose formulas such as p ∧q and p ∨q from nodes that represent different
states. For example, if #p is to be true in state s, then p must be assigned T in the
state s′ that follows s, but p could be assigned either T or F in s itself.
The second complication comes from future formulas like 3p. For future for-
mulas, it is not sufﬁcient that they are consistent with the other subformulas; 3p
requires that there actually exist a subsequent state where p is assigned T . This is
similar to the case of ∃xp(x) in ﬁrst-order logic: we must demonstrate that a value
a exists such that p(a) is true. In ﬁrst-order logic, this was simple, because we just
chose new constant symbols from a countable set. In LTL, to establish the existence
or non-existence of a state that fulﬁlls a future formula requires an analysis of the
graph of states constructed when the tableau is built.
13.5.1 The Tableau Rules for LTL
The tableau rules for LTL consist of the rules for propositional logic shown in
Fig. 2.8, together with the following new rules, where next formulas are called X-
formulas:
α
α1
α2
2A
A
#2A
¬3A
¬A
¬#3A
β
β1
β2
3A
A
#3A
¬2A
¬A
¬#2A
X
X1
#A
A
¬#A
¬A

13.5
Semantic Tableaux
245
The Rules for α- and β-Formulas
The rules for the α- and β-formulas are based on Theorem 13.32:
• If 2A is true in a state s, then A is true in s and A must continue to be true in all
subsequent states starting at the next state s′.
• If 3A is true in a state s, then either A is true in s or A will eventually become
true in some subsequent state starting at the next state s′.
The Rule for X-Formulas
Consider now the tableau obtained for the formula A = (p ∨q) ∧#(¬p ∧¬q)
after applying the rules for α- and β-formulas:
(p ∨q) ∧#(¬p ∧¬q)
↓
p ∨q, #(¬p ∧¬q)
↙
↘
p, #(¬p ∧¬q)
q, #(¬p ∧¬q)
In a model σ for A, either vσ(p) = s0(p) = T or vσ(q) = s0(q) = T , and this is
expressed by the two leaf nodes that contain the atomic propositions. Since no more
rules for α- and β-formulas are applicable, we have complete information on the
assignment to atomic propositions in the initial state s0. These nodes, therefore,
deﬁne states, indicated by the frame around the node.
These nodes contain additional information: in order to satisfy the formula A, the
formula #(¬p ∧¬q) must evaluate to T in σ0. Therefore, the formula ¬p ∧¬q
must evaluate to T in σ1. The application of the rule for X-formulas begins the
construction of the new state s1:
(p ∨q) ∧#(¬p ∧¬q)
↓
p ∨q, #(¬p ∧¬q)
↙
↘
p, #(¬p ∧¬q)
q, #(¬p ∧¬q)
↓
↓
¬p ∧¬q
¬p ∧¬q
↓
↓
¬p, ¬q
¬p, ¬q
The literals in s0 are not copied to the labels of the nodes created by the application
of the rule for the X-formula because whatever requirements exist on the assignment
in s0 are not relevant to what happens in s1.
On both branches, the new node is labeled by the formula ¬p ∧¬q and an
application of the rule for the propositional α-formula gives {¬p,¬q} as the label

246
13
Temporal Logic: Formulas, Models, Tableaux
of the next node. Since this node no longer contains α- or β-formulas, it deﬁnes a
new state s1.
The construction of the tableau is now complete and we have two open branches.
Therefore, we can conclude that any model for A must be consistent with one of the
following graphs:
This structure is not an interpretation. First, it is not total since there is no transition
from s1, but this is easily ﬁxed by adding a self-loop to the ﬁnal state:
More importantly, we have not speciﬁed the value of the second literal in either of
the possible states s0. However, the structures are Hintikka structures, which can be
extended to interpretations by specifying the values of all atoms in each state.
Future Formulas
Consider the formula A = ¬(2(p ∧q) →2p) which is the negation of a valid
formula. Here is a semantic tableau, where (by duality) we have implicitly changed
¬2 to 3¬ for clarity:
¬(2(p ∧q) →2p)
↓
2(p ∧q), 3¬p
↓
p ∧q, #2(p ∧q), 3¬p
↓
p, q, #2(p ∧q), 3¬p
↙
↘
p, q, #2(p ∧q), ¬p
p, q, #2(p ∧q), #3¬p
×
The left-hand branch closes, while the right-hand leaf deﬁnes a state s0 in which p
and q must be true. When rule for the X-formula is applied to this node, a new node
is created that is labeled by {2(p ∧q), 3¬p}. But this is the same set of formulas
that labels the second node in the tableau. It is clear that the continuation of the
construction will create an inﬁnite structure:

13.5
Semantic Tableaux
247
Something is wrong since A is unsatisﬁable and its tableau should close!
This structure is a Hintikka structure (no node contains clashing literals and for
every α-, β- and X-formula, the Hintikka conditions hold). However, the structure
cannot be extended to model for A, since the future subformula 3¬p is not fulﬁlled;
that is, the structure promises to eventually produce a state in which ¬p is true but
defers forever the creation of such a state.
Finite Presentation of an Interpretation
There are only a ﬁnite number of distinct states in an interpretation for an LTL
formula A since every state is labeled with a subset of the atomic propositions ap-
pearing in A and there are a ﬁnite number of such subsets. Therefore, although an
interpretation is an inﬁnite path, it can be ﬁnitely presented by reusing existing states
instead of creating new ones. The inﬁnite structure above can be ﬁnitely presented
as follows:
13.5.2 Construction of Semantic Tableaux
The construction of semantic tableaux for LTL formulas and the proof of an algo-
rithm for the decidability of satisﬁability is contained in the following four sub-
sections. First, we describe the construction of the tableau; then, we show how a
Hintikka structure is deﬁned by an open tableau; third, we extract a linear structure
which can be extended to an interpretation; and ﬁnally, we show how to decide if
future formulas are fulﬁlled.
The meaning of the following deﬁnition will become clear in the following sub-
section, but it is given here so that we can use it in the algorithm for constructing a
tableau.
Deﬁnition 13.35 A state node in a tableau is a node l such that its label U(l) con-
tains only literals and next formulas, and there are no complementary pairs of literals
in U(l).
Algorithm 13.36 (Construction of a semantic tableau)
Input: An LTL formula A.
Output: A semantic tableau T for A.

248
13
Temporal Logic: Formulas, Models, Tableaux
Each node of T is labeled with a set of formulas. Initially, T consists of a single
node, the root, labeled with the singleton set {A}. The tableau is built inductively as
follows. Choose an unmarked leaf l labeled with a set of formulas U(l) and perform
one of the following steps:
• If there is a complementary pair of literals {p,¬p} ⊆U(l), mark the leaf closed
×. If U(l) is a set of literals but no pair is complementary, mark the leaf open ⊙.
• If U(l) is not a set of literals, choose A ∈U(l) which is an α-formula. Create a
new node l′ as a child of l and label l′ with:
U(l′) = (U(l) −{A}) ∪{α1,α2}.
(In the case that A is ¬¬A1, there is no α2.)
• If U(l) is not a set of literals, choose A ∈U(l) which a β-formula. Create two
new nodes l′ and l′′ as children of l. Label l′ with:
U(l′) = (U(l) −{A}) ∪{β1},
and label l′′ with:
U(l′′) = (U(l) −{A}) ∪{β2}.
• If l is a state node (Deﬁnition 13.35) with at least one next formula, let:
{#A1,...,#Am,¬#Am+1,...,¬#An}
be the set of next formulas in U(l). Create a new node l′ as a child of l and label
l′ with:
U(l′) = {A1,...,Am,¬Am+1,...,¬An}.
If U(l′) = U(l′′) for a state node l′′ that already exists in the tableau, do not create
l′; instead connect l to l′′.
The construction terminates when every leaf is marked × or ⊙.
We leave it as an exercise to show that the construction always terminates.
Deﬁnition 13.37 A tableau whose construction has terminated is a completed tab-
leau. A completed tableau is closed if all leaves are marked closed and there are no
cycles. Otherwise, it is open.

13.5
Semantic Tableaux
249
Example 13.38 Here is a completed open semantic tableau with no leaves:
l0 : 23p
↓
l1 : 3p, #23p
↙
↘
l2 : p, #23p
l3 : #3p, #23p
↓
↓
l4 : 23p
l5 : 3p, 23p
↓
↓
l6 : 3p, #23p
l7 : 3p, #23p
↙
↘
↙
↘
To l2
To l3
To l2
To l3
13.5.3 From a Semantic Tableau to a Hintikka Structure
The next step is to construct a structure from an open tableau, to deﬁne the condi-
tions for a structure to be a Hintikka structure and to prove that the structure resulting
from the tableau satisﬁes those conditions. The deﬁnition of a structure is similar to
the deﬁnition of an interpretation for PTL formulas (Deﬁnition 13.8); the difference
is that the labels of a state are sets of formulas, not just sets of atomic propositions
that are assigned true. To help understand the construction, you might want to re-
fresh your memory by re-reading Sect. 2.7.2 on the deﬁnition and use of Hintikka
structures in propositional logic.
Deﬁnition 13.39 A structure H for a formula A in LTL is a pair (S ,ρ), where
S = {s1,...,sn} is a set of states each of which is labeled by a subset of formulas
built from the atomic propositions in A and ρ is a binary relation on states, ρ ⊆
S × S.
As before, functional notation may be used s2 ∈ρ(s1).
The states of the structure will be the state nodes of the tableau. However, the
labels of the states must include more than the literals that label the nodes in the
tableau. To obtain a Hintikka structure, the state in the structure must also include
the formulas whose decomposition eventually led to each literal.
Example 13.40 In Example 13.38, state node l2 will deﬁne a state in the structure
that is labeled with p, since p must be assigned true in any interpretation contain-
ing that state. In addition, the state in the structure must also include 3p from l1
(because p in l2 resulted from the decomposition of 3p), as well as 23p from l0
(because 3p in l1 resulted from the decomposition of 23p).

250
13
Temporal Logic: Formulas, Models, Tableaux
The transitions in the structure are deﬁned by paths between state nodes.
Deﬁnition 13.41 A state path is a path (l0,l1,...,lk−1,lk) through connected
nodes in the tableau, such that l0 is a state node or the root of the tableau, lk is
a state node, and none of {l1,...,lk−1} are state nodes. It is possible that l0 = lk so
that the set {l1,...,lk−1} is empty.
Given a tableau, a structure can be deﬁned by taking the state nodes as the states
and deﬁning the transitions by the state paths. The label of a state is the union of
all formulas that appear on incoming state paths (not including the ﬁrst state of the
path unless it is the root). The formal deﬁnition is:
Deﬁnition 13.42 Let T be an open tableau for an LTL formula A. The structure
H constructed from T is:
• S is the set of state nodes.
• Let s ∈S . Then s = l for some node l in the tableau. Let πi = (li
0,li
1,...,li
ki = l)
be a state path terminating in the node l and let:
Ui = U(li
1) ∪··· ∪U(li
ki)
or
Ui = U(li
0) ∪··· ∪U(li
ki)
if li
0 is the root. Label s by the set of formulas:
Ui = ∪iUi,
where the union is taken over all i such that πi is a state path terminating in l = s.
• s′ ∈ρ(s) iff there is a state path from s to s′.
It is possible to obtain several disconnected structures from the tableau for a
formula such as 3p ∨3q, but this is no problem as the formula can be satisﬁable
if and only if at least one of the structures leads to a model.
Now that we know how the structure is constructed from the tableau, it is possible
to optimize Algorithm 13.36. Change:
For a state node l′, if U(l′) = U(l′′) for a state node l′′ that already exists in the tableau, do
not create l′; instead connect l to l′′.
so that it applies to any node l′ in the tableau, not just to state nodes, provided that
this doesn’t create a cycle not containing a state node.

13.5
Semantic Tableaux
251
Fig. 13.3 Structure for
2(3(p ∧q) ∧3(¬p ∧q) ∧
3(p ∧¬q))
Example 13.43 Here is an optimized tableau corresponding to the one in Exam-
ple 13.38:
l0 : 23p
↓
l1 : 3p, #23p
↙
↘
l2 : p, #23p
l3 : #3p, #23p
↓
↓
To l0
To l1
and here is the structure constructed from this semantic tableau:
where s0 = l2 and s1 = l3. To save space, each state si is labeled only with the
positive literals in Ui.
Example 13.44 Let:
A = 2(3(p ∧q) ∧3(¬p ∧q) ∧3(p ∧¬q)).
The construction of the tableau for A is left as an exercise. The structure obtained
from the tableau is shown in Fig. 13.3.
Deﬁnition 13.45 Let H = (S ,ρ) be a structure for an LTL formula A. H is a
Hintikka structure for A iff A ∈s0 and for all states si the following conditions hold
for Ui, the set of formulas labeling si:

252
13
Temporal Logic: Formulas, Models, Tableaux
1. For all atomic propositions p in A, either p ̸∈Ui or ¬p ̸∈Ui.
2. If α ∈Ui, then α1 ∈Ui and α2 ∈Ui.
3. If β ∈Ui, then β1 ∈Ui or β2 ∈Ui.
4. If X ∈Ui, then for all sj ∈ρ(si), X1 ∈Uj.
Theorem 13.46 Let A be an LTL formula and suppose that the tableau T for A is
open. Then the structure H created as described in Deﬁnition 13.42 is a Hintikka
structure for A.
Proof The structure H is created from an open tableau, so condition (1) holds.
Rules for α- and β-formulas are applied before rules for next formulas, so the union
of the formulas on every incoming state path to a state node contains all the formulas
required by conditions (2) and (3). When the rule for a next formula #A is applied,
A will appear in the label of the next node (and similarly for ¬#A), and hence in
every state at the end of a state path that includes this node.
13.5.4 Linear Fulﬁlling Hintikka Structures
The construction of the tableau and the Hintikka structure is quite straightforward
given the decomposition of formulas with temporal operators. Now we turn to the
more difﬁcult problem of deciding if an interpretation for an LTL formula can be
extracted from a Hintikka structure. First, we need to extract a linear structure and
show that it is also a Hintikka structure.
Deﬁnition 13.47 Let H be a Hintikka structure for an LTL formula A. H is a
linear Hintikka structure iff ρ is a total function, that is, if for each si there is exactly
one sj ∈ρ(si).
Lemma 13.48 Let H be a Hintikka structure for an LTL formula A and let H ′ be
an inﬁnite path through H . Then H ′ is a linear Hintikka structure.
Proof Clearly, H ′ is a linear structure. Conditions (1–3) of Deﬁnition 13.45 hold
because they already held in H . Let s be an arbitrary state and let U be the label of
s. If a next formula #A′ occurs in U, then by condition (4) of Deﬁnition 13.45, A′
occurs in all states of ρ(s), in particular, for the one chosen in the construction of
H ′.
Next, we need to check if the linear structure fulﬁlls all the future formulas. We
deﬁne the concept of fulﬁlling and then show that a fulﬁlling Hintikka structure
can be used to deﬁne a model. The algorithm for deciding if a Hintikka structure
is fulﬁlling is somewhat complex and is left to the next subsection. To simplify the
presentation, future formulas will be limited to those of the form 3A. By duality,
the same presentation is applicable to future formulas of the form ¬2A.
Recall that ρ∗is the transitive, reﬂexive closure of ρ (Deﬁnition A.21).

13.5
Semantic Tableaux
253
Deﬁnition 13.49 Let H = (S ,ρ) be a Hintikka structure. H is a fulﬁlling iff the
following condition holds for all future formulas 3A:
For all s ∈S , if 3A ∈Us, then for some s′ ∈ρ∗(s), A ∈Us′.
The state s′ is said to fulﬁll 3A.
Theorem 13.50 (Hintikka’s Lemma for LTL) Let H = (S ,ρ) be a linear fulﬁlling
Hintikka structure for an LTL formula A. Then A is satisﬁable.
Proof An LTL interpretation is a path consisting of states labeled with atomic
propositions (see Deﬁnition 13.28). The path is deﬁned simply by taking the lin-
ear Hintikka structure and restricting the labels to atomic propositions. There is thus
a natural mapping between states of the interpretation and states of the Hintikka
structure, so for the propositional operators and next formulas, we can use the con-
ditions on the structure to prove that A is satisﬁable using structural induction.
For future formulas, the satisﬁability follows from the assumption that the Hin-
tikka structure is fulﬁlling.
Consider now a formula of the form 2A ∈Usi. We must show that vσj (A) = T
for all j ≥i. We generalize this for the inductive proof and show that vσj (A) = T
and vσj (#2A) = T for all j ≥i.
The base case is j = i. But 2A ∈Usi, so by Hintikka condition (2) A ∈Usi and
#2A ∈Usi.
Let k ≥i and assume the inductive hypothesis that vσk(A) = T and #2A ∈
Usk. By Hintikka condition (4), 2A ∈Usk+1, so using Hintikka condition (2) again,
vσk+1(A) = T and #2A ∈Usk+1.
Here is a ﬁnite presentation of a linear fulﬁlling Hintikka structure constructed
from the structure in Fig. 13.3:
13.5.5 Deciding Fulﬁllment of Future Formulas *
The last link needed to obtain a decision procedure for satisﬁability in LTL is an
algorithm that takes an arbitrary Hintikka structure, and decides if it contains a path
that is a linear fulﬁlling Hintikka structure. We begin with some deﬁnitions from
graph theory. The concepts should be familiar, though it is worthwhile giving formal
deﬁnitions.
Deﬁnition 13.51 A graph G = (V,E) consists of a set of vertices V = {v1,...,vn}
and a set of edges E = {e1,...,em}, which are pairs of vertices ek = {vi,vj} ⊆V .

254
13
Temporal Logic: Formulas, Models, Tableaux
Fig. 13.4 Strongly
connected components
In a directed graph, each edge is an ordered pair, ek = (vi,vj). A path from v to v′,
denoted v ; v′, is a sequence of edges such that the second component of one edge
is the ﬁrst component of the next:
e1 =
(v = vi1,vi2),
e2 =
(vi2,vi3),
...
el−1 =
(vil−2,vil−1),
el
=
(vil−1,vil = v′).
A subgraph G′ = (V ′,E′) of a directed graph G = (V,E) is a graph such that
V ′ ⊆V and E′ ⊆E, provided that e = (vi,vj) ∈E′ implies {vi,vj} ⊆V ′.
Deﬁnition 13.52 A strongly connected component (SCC) G′ = (V ′,E′) in a di-
rected graph G is a subgraph such that vi ; vj for all {vi,vj} ⊆V ′. A maximal
strongly connected component (MSCC) is an SCC not properly contained in an-
other. A transient SCC is an MSCC consisting of a single vertex. A terminal SCC is
an MSCC with no outgoing edges.
Example 13.53 The directed graph in Fig. 13.4 contains three strongly connected
components: G0 = {s0},G1 = {s1,s2,s3},G2 = {s4,s5,s6,s7}. G0 is transient and
G1 is terminal.
Deﬁnition 13.54 A directed graph G can be represented as a component graph,
which is a directed graph whose vertices are the MSCCs of G and whose edges are
edges of G pointing from a vertex of one MSCC to a vertex of another MSCC.
See Even, Sect. 3.4 for an algorithm that constructs the component graph of a
directed graph and a proof of the following theorem.
Theorem 13.55 The component graph is acyclic.

13.5
Semantic Tableaux
255
Fig. 13.5 Component graph
Example 13.56 Figure 13.5 shows the graph of Fig. 13.4 with its component graph
indicated by ovals and thick arrows.
Suppose that we have a Hintikka structure and a future formula in a terminal
MSCC, such as G1 in Fig. 13.5. Then if the formula is going to be fulﬁlled at all,
it will be fulﬁlled within the terminal MSCC because there are no other reachable
nodes to which the fulﬁllment can be deferred. If a future formula is in a non-
terminal MSCC such as G2, it can either be fulﬁlled within its own MSCC, or the
fulﬁllment can be deferred to an reachable MSCC, in this case G1. This suggests an
algorithm for checking fulﬁllment: start at terminal MSCCs and work backwards.
Let H = (S ,ρ) be a Hintikka structure. H can be considered a graph G =
(V,E), where V is S and (si,sj) ∈E iff sj ∈ρ(si). We simplify the notation and
write A ∈v for A ∈Ui when v = si.
Deﬁnition 13.57 Let G = (V,E) be a SCC of H . G is self-fulﬁlling iff for all
v ∈V and for all future formulas 3A ∈v, A ∈v′ for some v′ ∈V .
Lemma 13.58 Let G = (V,E) ⊆G′ = (V ′,E′) be SCCs of a Hintikka structure. If
G is self-fulﬁlling, then so is G′.
Fig. 13.6 An SCC is contained in an MSCC

256
13
Temporal Logic: Formulas, Models, Tableaux
Example 13.59 Let 3A be an arbitrary future formula that has to be fulﬁlled in G′
in Fig. 13.6. If 3A ∈si for si ∈G, then by the assumption that G is self-fulﬁlling,
A ∈sj for some sj ∈G ⊂G′ and G′ is also self-fulﬁlling.
Suppose now that 3A ∈s7, where s7 ∈V ′ −V . If A ∈s7, then s7 itself fulﬁlls
3A. Otherwise, by Hintikka condition (3), #3A ∈s7, so 3A ∈s6 by Hintikka con-
dition (4). Continuing, A ∈s6 or #3A ∈s6; A ∈s4 or #3A ∈s4; A ∈s5 or #3A ∈
s5. If A ∈sj for one of these vertices in V ′ −V , we have the G′ is self-fulﬁlling.
If not, then by Hintikka condition (4), #3A ∈s4 implies that 3A ∈s1, be-
cause condition (4) is a requirement on all immediate successors of a node. By
assumption, G is self-fulﬁlling, so A ∈sj for some sj ∈G ⊂G′ and G′ is also
self-fulﬁlling.
Proof of Lemma 13.58 Let 3A be an arbitrary future formula in v′ ∈V ′ −V . By
deﬁnition of a Hintikka structure, either A ∈v′ or #3A ∈v′. If A ∈v′, then A
is fulﬁlled in G′; otherwise, 3A ∈v′′ for every v′′ ∈ρ(v′). By induction on the
number of vertices in V ′ −V , either A is fulﬁlled in V ′ −V or 3A ∈v for some v
in V . But G is self-fulﬁlling, so 3A is fulﬁlled in some state vA ∈V ⊆V ′. Since
G′ is an SCC, v′ ; vA and A is fulﬁlled in G′.
Corollary 13.60 Let G be a self-fulﬁlling SCC of a Hintikka structure. Then G can
be extended to a self-fulﬁlling MSCC.
Proof If G itself is not an MSCC, create a new graph G′ by adding a vertex v′ ∈
V ′ −V and all edges (v′,v) and (v,v′), where v ∈V , provided that G′ is an SCC.
Continue this procedure until no new SCCs can be created. By Lemma 13.58, the
SCC is self-fulﬁlling and by construction it is maximal.
Lemma 13.61 Let G = (V,E) be an MSCC of H and let 3A ∈v ∈V be a future
formula. If G is not self-fulﬁlling, 3A can only be fulﬁlled by some v′ in an MSCC
G′, such that G ; G′ in the component graph.
Proof Since G is not self-fulﬁlling, 3A must be fulﬁlled by some v′ ̸∈V such that
v ; v′. But v′ ̸; v, otherwise v′ could be added to the vertices of G creating a
larger SCC, contradicting the assumption that G is maximal. Therefore, v′ ∈G′ for
a component G′ ̸= G.
This lemma directly gives the following corollary.
Corollary 13.62 If G is a terminal MSCC and 3A ∈v for v ∈V , then if 3A cannot
be fulﬁlled in G, it cannot be fulﬁlled at all.
Algorithm 13.63 (Construction of a linear fulﬁlling structure)
Input: A Hintikka structure H .
Output: A linear fulﬁlling Hintikka structure that is a path in H , or a report that
no such structure exists.
Construct the component graph H of H . Since H is acyclic (Theorem 13.55),
there must be a terminal MSCC G. If G is not self-fulﬁlling, delete G and all its

13.5
Semantic Tableaux
257
incoming edges from H. Repeat until every terminal MSCC is self-fulﬁlling or until
the component graph is empty. If every terminal MSCC is self-fulﬁlling, the proof
of the following theorem shows how a linear fulﬁlling Hintikka structure can be
constructed. Otherwise, if the graph is empty, the algorithm reports that no linear
fulﬁlling Hintikka structure exists.
Theorem 13.64 Algorithm 13.63 terminates with a non-empty graph iff a linear
fulﬁlling Hintikka structure can be constructed.
Proof Suppose that the algorithm terminates with an non-empty component graph
G and let G1 ; ··· ; Gn be a maximal path in G. We now deﬁne a path in H
based upon this path in the component graph.
There must be vertices {v1,...,vn} in H , such that vi ∈Gi,vi+1 ∈Gi+1 and
vi ; vi+1. Furthermore, each component Gi is an SCC, so for each i there is a path
vi
1 ; ··· ; vi
ki in H containing all the vertices in Gi.
Construct a path in H by replacing every component by a partial path and con-
necting them by the edges vi ; vi+1:
• Replace a transient component by the single vertex vi
1.
• Replace a terminal component by the closure
vi ; ··· ; (vi
1 ; ··· ; vi
ki)∗.
• Replace a non-transient, non-terminal component by
vi ; ··· ; vi
1 ; ···vi
ki ; vi
1 ; ···vi
ki ; ··· ; vi+1.
We leave it as an exercise to prove that this path is a fulﬁlling linear Hintikka struc-
ture.
Conversely, let H ′ = (s1,...,...) be a fulﬁlling linear Hintikka structure in H .
Since H is ﬁnite, some sufﬁx of H ′ must be composed of states which repeat
inﬁnitely often. These states must be contained within a self-fulﬁlling SCC G. By
Corollary 13.60, G is contained in a self-fulﬁlling MSCC.
Example 13.65 There are two maximal paths in the component graph in Fig. 13.5:
G0 ; G1 and G0 ; G2 ; G1. The paths constructed in the underlying graphs are:
s0 ; (s3 ; s2 ; s1)∗
and
s0 ; s4 ; s5 ; s7 ; s6 ; s4 ; s5 ; s7 ; s6 ; s4 ; (s1 ; s2 ; s3)∗,
respectively.
Theorem 13.66 There is a decision procedure for satisﬁability in LTL.
Proof Let A be a formula in LTL. Construct a semantic tableau for A. If it closes,
A is unsatisﬁable. If there is an open branch, A is satisﬁable. Otherwise, construct
the structure from the tableau as described in Deﬁnition 13.42. By Theorem 13.46,

258
13
Temporal Logic: Formulas, Models, Tableaux
this is a Hintikka structure. Apply Algorithm 13.63 to construct a fulﬁlling Hintikka
structure. If the resulting graph is empty, A is unsatisﬁable. Otherwise, apply the
construction in Theorem 13.64 to construct a linear fulﬁlling Hintikka structure. By
Theorem 13.50, a model can be constructed from the structure.
The following corollary is obvious since the number of possible states in a struc-
ture constructed for a particular formula is ﬁnite:
Corollary 13.67 (Finite model property) A formula in LTL is satisﬁable iff it is
satisﬁable in a ﬁnitely-presented model.
13.6 Binary Temporal Operators *
Consider the following correctness speciﬁcation from the introduction:
The output lines maintain their values until the set-line is asserted.
We cannot express this in LTL as deﬁned above because we have no binary temporal
operators that can connect two propositions: unchanged-output and set-asserted. To
express such properties, a binary operator U (read until) can be added to LTL. Inﬁx
notation is used:
unchanged-output U
set-asserted.
The semantics of the operator is deﬁned by adding the following item to Deﬁni-
tion 13.28:
• If A is A1U A2 then vσ(A) = T iff vσi(A2) = T for some i ≥0 and for all
0 ≤k < i, vσk(A1) = T .
Example 13.68 The formula p U q is true in the interpretation represented by the
following path:
q is true at s2 and for all previous states {s0,s1}, p is true.
p U q is not true in the following interpretation assuming that state s2 is repeated
indeﬁnitely:
The reason is that q never becomes true.

13.6
Binary Temporal Operators *
259
p U q is also not true in the following interpretation:
because p becomes false before q becomes true.
Deﬁning the Existing Operators in Terms of U
It is easy to see that:
3A ≡true U A.
The deﬁnition of the semantics of U requires that A become true eventually just
as in the semantics of 3A. The additional requirement is that true evaluate to T in
every previous state, but that clearly holds in every interpretation.
Since binary operators are essential for expressing correctness properties, ad-
vanced presentations of LTL take # and U as the primitive operators of LTL and
deﬁne 3 as an abbreviation for the above formula, and then 2 as an abbreviation
for ¬3¬.
Semantic Tableaux with U
Constructing a semantic tableau for a formula that uses the U operator does not
require any new concepts. The operator can be decomposed as follows:
A1U A2 ≡A2 ∨(A1 ∧#(A1U A2)).
For A1U A2 to be true, either A2 is true today, or we put off to tomorrow the require-
ment to satisfy A1U A2, while requiring that A1 be true today. The decomposition
shows that a U -formula is a β-formula very similar to 3A. The similarity goes
deeper, because A1U A2 is a future formula and must be fulﬁlled by having A2
appear in a state eventually.
The construction of semantic tableau is more efﬁcient if operators have duals.
The dual of U is the operator R (read release), deﬁned as:
A1RA2 ≡¬(¬A1U ¬A2).
We leave it as an exercise to write the deﬁnition of the semantics of R.

260
13
Temporal Logic: Formulas, Models, Tableaux
The Weak Until Operator
Sometimes it is convenient to express precedence properties without actually requir-
ing that something eventually occur. W (read weak until) is the same as the operator
U except that it is not required that the second formula ever become true:
• If A is A1W A2 then vσ(A) = T iff: if vσi(A2) = T for some i ≥0, then for all
0 ≤k < i, vσk(A1) = T .
Clearly, the following equivalence holds:
A1W A2 ≡(A1U A2) ∨2A1.
We leave it as an exercise to show:
2A ≡AW false,
¬(A1W A2) ≡(A1 ∧¬A2)U (¬A1 ∧¬A2),
¬(A1U A2) ≡(A1 ∧¬A2)W (¬A1 ∧¬A2),
¬(A1U A2) ≡(¬A2)W (¬A1 ∧¬A2).
13.7 Summary
Since the state of a computation changes over time, temporal logic is an appropriate
formalism for expressing correctness properties of programs. The syntax of linear
temporal logic (LTL) is that of propositional logic together with the unary temporal
operators 2, 3, #. Interpretations are inﬁnite sequences of states, where each state
assigns truth values to atomic propositions. The meaning of the temporal operators
is that some property must hold in 2 all subsequent states, in 3 some subsequent
state or in the # next state.
Satisﬁability and validity of formulas in LTL are decidable. The tableau construc-
tion for propositional logic is extended so that next formulas (of the form #A) cause
new states to be generated. A open tableau deﬁnes a Hintikka structure which can
be extended to a satisfying interpretation, provided that all future formulas (of the
form 3A or ¬2A) are fulﬁlled. By constructing the component graph of strongly
connected components, the fulﬁllment of the future formulas can be decided.
Many important correctness properties use the binary operators U and W , which
require that one formula hold until a second one becomes true.

13.8
Further Reading
261
13.8 Further Reading
Temporal logic (also called tense logic) has a long history, but it was ﬁrst applied to
program veriﬁcation by Pnueli (1977). The deﬁnitive reference for the speciﬁcation
and veriﬁcation of concurrent programs using temporal logic is Manna and Pnueli
(1992, 1995). The third volume was never completed, but a partial draft is available
(Manna and Pnueli, 1996). Modern treatments of LTL can be found in Kröger and
Merz (2008, Chap. 2), and Baier and Katoen (2008, Chap. 5). The tableau method
for a different version of temporal logic ﬁrst appeared in Ben-Ari et al. (1983); for
a modern treatment see Kröger and Merz (2008, Chap. 2).
13.9 Exercises
13.1 Prove that in LTL every substitution instance of a valid propositional formula
is valid.
13.2 Prove |= ¬3¬p →2p (the converse direction of Theorem 13.14).
13.3 Prove that a linear interpretation is characterized by #A ↔¬#¬A (Theo-
rem 13.25).
13.4 * Identify the property of a reﬂexive relation characterized by A →23A.
Identify the property of a reﬂexive relation characterized by 3A →23A.
13.5 Show that in an interpretation with a reﬂexive transitive relation, any formula
(without #) is equivalent to one whose only temporal operators are 2, 3, 32, 23,
323 and 232. If the relation is also characterized by the formula 3A →23A,
any formula is equivalent to one with a single temporal operator.
13.6 Prove Theorem 13.34: |= (32p ∧23q) →23(p ∧q).
13.7 Construct a tableau and ﬁnd a model for the negation of 23p →32p.
13.8 Prove that the construction of a semantic tableau terminates.
13.9 Prove that the construction of the path in the proof of Theorem 13.64 gives a
linear fulﬁlling Hintikka structure.
13.10 Write the deﬁnition of the semantics of the operator R.
13.11 Prove the equivalences on W at the end of Sect. 13.6.

262
13
Temporal Logic: Formulas, Models, Tableaux
References
C. Baier and J.-P. Katoen. Principles of Model Checking. MIT Press, 2008.
M. Ben-Ari, Z. Manna, and A. Pnueli. The temporal logic of branching time. Acta Informatica,
20:207–226, 1983.
S. Even. Graph Algorithms. Computer Science Press, Potomac, MD, 1979.
F. Kröger and S. Merz. Temporal Logic and State Systems. Springer, 2008.
Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems. Vol. I: Speciﬁ-
cation. Springer, New York, NY, 1992.
Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems. Vol. II: Safety.
Springer, New York, NY, 1995.
Z. Manna and A. Pnueli. Temporal veriﬁcation of reactive systems: Progress. Draft available at
http://www.cs.stanford.edu/~zm/tvors3.html, 1996.
A. Pnueli. The temporal logic of programs. In 18th IEEE Annual Symposium on Foundations of
Computer Science, pages 46–57, 1977.

Chapter 14
Temporal Logic: A Deductive System
This chapter deﬁnes the deductive system L for linear temporal logic. We will
prove many of the formulas presented in the previous chapter, as well as the sound-
ness and completeness of L .
14.1 Deductive System L
The operators of L are the Boolean operators of propositional logic together with
the temporal operators 2 and #. The operator 3 is deﬁned as an abbreviation for
¬2¬.
Deﬁnition 14.1 The axioms of L are:
Axiom 0
Prop
Any substitution instance of
a valid propositional formula.
Axiom 1
Distribution of 2
⊢2(A →B) →(2A →2B).
Axiom 2
Distribution of #
⊢#(A →B) →(#A →#B).
Axiom 3
Expansion of 2
⊢2A →(A ∧#A ∧#2A).
Axiom 4
Induction
⊢2(A →#A) →(A →2A).
Axiom 5
Linearity
⊢#A ↔¬#¬A.
The rules of inference are modus ponens and generalization: ⊢A
⊢2A.
In order to simplify proofs of formulas in LTL, the deductive system L takes all
substitution instances of valid formulas of propositional logic as axioms. Validity in
propositional logic is decidable and by the completeness of H we can produce a
proof of any valid formula if asked to do so. In fact, we will omit justiﬁcations of
deductions in propositional logic and just write Prop if a step in a proof is justiﬁed
by propositional reasoning.
The distributive axioms are valid in virtually all modal and temporal logics (The-
orem 13.15). The expansion axiom expresses the basic properties of 2 that were
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_14, © Springer-Verlag London 2012
263

264
14
Temporal Logic: A Deductive System
used to construct semantic tableaux, as well as ⊢2A →#A (Theorem 13.25),
which holds because all interpretations are inﬁnite paths. The linearity axiom for
# (Theorem 13.25) captures the restriction of LTL to linear interpretations.
The induction axiom is fundamental in L : since interpretations in LTL are in-
ﬁnite paths, proofs of non-trivial formulas usually require induction. In a proof by
induction, the inductive step is A →#A, that is, we assume that A is true today and
prove that A is true tomorrow. If this inductive step is always true, 2(A →#A),
then A →2A by the induction axiom. Finally, if A is true today (the base case),
then A is always true 2A.
The rules of inference are the familiar modus ponens and generalization using 2,
which is similar to generalization using ∀in ﬁrst-order logic.
Derived Rules
Here are some useful derived rules:
⊢A →B
⊢2A →2B ,
⊢A →B
⊢#A →#B ,
⊢A →#A
⊢A →2A.
The ﬁrst is obtained by applying generalization and then the distribution axiom; the
second is similar except that the expansion axiom is used between the generalization
and the distribution. When using these rules, we write the justiﬁcation as generaliza-
tion. The third rule will be called induction because it is a shortcut for generalization
followed by the induction axiom.
14.2 Theorems of L
The theorems and their proofs will be stated and proved for atomic propositions p
and q although the intention is that they hold for arbitrary LTL formulas.
Distributivity
This subsection explores in more detail the distributivity of the temporal operators
over proposition operators. The results will not be surprising, because 2 and 3 be-
have similarly to ∀and ∃in ﬁrst-order logic. # is a special case because of linearity.

14.2
Theorems of L
265
Theorem 14.2 ⊢#(p ∧q) ↔(#p ∧#q).
Proof
1.
⊢(p ∧q) →p
Prop
2.
⊢#(p ∧q) →#p
Generalization
3.
⊢(p ∧q) →q
Prop
4.
⊢#(p ∧q) →#q
Generalization
5.
⊢#(p ∧q) →(#p ∧#q)
2, 4, Prop
6.
⊢#(p →¬q) →(#p →#¬q)
Distribution
7.
⊢¬ (#p →#¬q) →¬#(p →¬q)
6, Prop
8.
⊢¬#p ∨#¬q ∨¬#(p →¬q)
7, Prop
9.
⊢¬#p ∨¬#q ∨#¬ (p →¬q)
8, Linearity
10.
⊢(#p ∧#q) →#(p ∧q)
9, Prop
11.
⊢#(p ∧q) ↔(#p ∧#q)
5, 10, Prop
By linearity, # is self-dual, while ∨is the dual of ∧, so we immediately have
⊢#(p ∨q) ↔(#p ∨#q).
Theorem 14.3 (Distribution) ⊢2(p ∧q) ↔(2p ∧2q).
The proof of the forward implication ⊢2(p ∧q) →(2p ∧2q) is similar to that
of Theorem 14.2 and is left as an exercise. Before proving the converse, we need to
prove the converse of the expansion axiom; the proof uses the forward implication
of Theorem 14.3, which we assume that you have already proved.
Theorem 14.4 (Contraction) ⊢p ∧#2p →2p.
Proof
1.
⊢2p →p ∧#2p
Expansion
2.
⊢#2p →#(p ∧#2p)
1, Generalization
3.
⊢p ∧#2p →#(p ∧#2p)
2, Prop
4.
⊢p ∧#2p →2(p ∧#2p)
3, Induction
5.
⊢p ∧#2p →(2p ∧2#2p)
4, Distribution
6.
⊢p ∧#2p →2p
5, Prop
For symmetry with the expansion axiom, #p could have been included in the
premise of this theorem, but it is not needed.
Now we can prove the converse of Theorem 14.3. The structure of the proof is
typical of inductive proofs in L . An explanation of some of the more difﬁcult steps
of the formal proof is given at its end.

266
14
Temporal Logic: A Deductive System
Proof Let r = 2p ∧2q ∧¬2(p ∧q).
1.
⊢r →(p ∧#2p) ∧(q ∧#2q) ∧
Expansion
¬ ((p ∧q) ∧#2(p ∧q))
Contraction
2.
⊢r →(p ∧#2p) ∧(q ∧#2q) ∧
1, Prop
(¬ (p ∧q) ∨¬#2(p ∧q))
3.
⊢r →(p ∧#2p) ∧(q ∧#2q) ∧¬#2(p ∧q)
2, Prop
4.
⊢r →#2p ∧#2q ∧¬#2(p ∧q)
3, Prop
5.
⊢r →#2p ∧#2q ∧#¬2(p ∧q)
4, Linearity
6.
⊢r →#r
5, Distribution
7.
⊢r →2r
6, Induction
8.
⊢r →2p ∧2q
Def. of r, Prop
9.
⊢r →p ∧q
8, Expansion
10.
⊢2r →2(p ∧q)
9, Generalization
11.
⊢r →2(p ∧q)
7, 10, Prop
12.
⊢r →¬2(p ∧q)
Def. of r, Prop
13.
⊢r →false
11, 12, Prop
14.
⊢2p ∧2q ∧¬2(p ∧q) →false
13, Def. of r
15.
⊢2p ∧2q →2(p ∧q)
14, Prop
Steps 1–7 prove that r is invariant, meaning that r is true initially and remains
true in any interpretation. The second line of Step 1 is justiﬁed by the contrapositive
of contraction ¬2(p ∧q) →¬((p ∧q) ∧#2(p ∧q)). Step 3 follows from Step 2
because ¬(p ∧q) is inconsistent with p and q that must be true by the expansion
of 2p and 2q.
The operator 2 distributes over disjunction only in one direction. We leave the
proof as an exercise, together with the task of showing that the converse is not valid.
Theorem 14.5 (Distribution) ⊢(2p ∨2q) →2(p ∨q).
Transitivity of 2
Induction is used to prove that 2 is transitive.
Theorem 14.6 (Transitivity) ⊢22p ↔2p
Proof
1.
⊢22p →2p
Expansion
2.
⊢2p →#2p
Expansion
3.
⊢2p →22p
2, Induction
4.
⊢22p ↔2p
1, 3, Prop

14.2
Theorems of L
267
Commutativity
Another expected result is that 2 and # commute:
Theorem 14.7 (Commutativity) ⊢2#p ↔#2p.
Proof
1.
⊢2p →#p
Expansion
2.
⊢22p →2#p
1, Generalization
3.
⊢2p →2#p
2, Transitivity
4.
⊢2p →p
Expansion
5.
⊢2p →p ∧2#p
3, 4, Prop
6.
⊢#2p →#(p ∧2#p)
5, Generalization
7.
⊢#2p →#p ∧#2#p
6, Distribution
8.
⊢#2p →2#p
7, Contraction
9.
⊢2#p →#p ∧#2#p
Expansion
10.
⊢p ∧2#p →#p ∧#2#p
9, Prop
11.
⊢p ∧2#p →#(p ∧2#p)
10, Distribution
12.
⊢p ∧2#p →2(p ∧2#p)
11, Induction
13.
⊢p ∧2#p →2p
12, Distribution, Prop
14.
⊢#(p ∧2#p) →#2p
13, Generalization
15.
⊢#p ∧#2#p →#2p
14, Distribution
16.
⊢2#p →#2p
9, 15, Prop
17.
⊢2#p ↔#2p
8, 16, Prop
2 and 3 commute in only one direction.
Theorem 14.8 ⊢32p →23p.
We leave the proof as an exercise.
Example 14.9 Consider the interpretation where si(p) = T for even i and si(p) =
F for odd i:
The formula 23p is true, since for any i, σ2i |= p. Obviously, 32p is false in all
states of the diagram, because for any i, σi |= ¬p if i is odd and σi+1 |= ¬p if i is
even.

268
14
Temporal Logic: A Deductive System
Dual Theorems for 3
We leave it as an exercise to prove the following theorems using the duality of 2
and 3 and the linearity of #.
Theorem 14.10
(a)
⊢p →3p
(b)
⊢#p →3p
(c)
⊢2p →3p
(d)
⊢2(p →q) →(3p →3q)
(e)
⊢3(p ∨q) ↔(3p ∨3q)
(f)
⊢3(p ∧q) →(3p ∧3q)
(g)
⊢3p ↔p ∨#3p
(h)
⊢3#p ↔#3p
(i)
⊢33p ↔3p
From Theorem 14.10(d), we obtain a generalization rule for 3:
⊢A →B
⊢3A →3B .
Collapsing Sequences of Operators
The transitivity of 2 (Theorem 14.6) and its dual for 3 (Theorem 14.10(i)) show
that any string of 2’s or 3’s can be collapsed. No expressive power is gained by
using more than two operators in sequence, as shown by the following theorem.
Theorem 14.11
(a)
⊢232p ↔32p
(b)
⊢323p ↔23p.
We prove (a) and then (b) follows by duality.
Proof
1.
⊢232p →32p
Expansion
2.
⊢2p →#2p
Expansion
3.
⊢32p →3#2p
2, Generalization
4.
⊢32p →#32p
3, Commutativity
5.
⊢32p →232p
4, Induction
6.
⊢232p ↔32p
1, 5, Prop

14.3
Soundness and Completeness of L *
269
14.3 Soundness and Completeness of L *
Soundness
Theorem 14.12 (Soundness of L ) Let A be a formula of LTL. If ⊢L A then |= A.
Proof We need to show that each axiom is a valid LTL formula and that the two rules
of inference preserve validity. By deﬁnition, valid formulas of propositional logic
are valid, and the soundness of MP was shown in Theorem 3.37. The soundness of
Axioms 1 and 5 was shown in Theorems 13.15 and 13.25, respectively. We leave
the soundness of Axioms 2 and 3 as an exercise and show the soundness of the
induction axiom and the generalization rule.
Axiom 4: ⊢2(A →#A) →(A →2A).
If the formula is not valid, there exists an interpretation σ such that:
σ |= 2(A →#A) ∧A ∧¬2A.
Since σ |= A and σ |= ¬2A there exists a smallest value i > 0 such that σi |= ¬A
and σj |= A for 0 ≤j < i. In particular, σi−1 |= A. But we also have that σ |=
2(A →#A), so by deﬁnition of the 2 operator, σi−1 |= A →#A. By MP we have
σi−1 |= #A and thus σi |= A, contradicting σi |= ¬A.
Generalization: If |= A, then |= 2A.
We need to show that for all interpretations σ, σ |= 2A. This means that for all
i ≥0, it is true that σi |= A. But |= A implies that for all interpretation σ ′, σ ′ |= A,
in particular, this must hold for σ ′ = σi.
Completeness
Theorem 14.13 (Completeness of L ) Let A be a formula of LTL. If |= A then
⊢L A.
Proof If A is valid, the construction of a semantic tableau for ¬A will fail, either
because it closes or because all the MSCCs are non-fulﬁlling and were deleted. We
show by induction that for every node in the tableau, the disjunction of the negations
of the formulas labeling the node is provable in L . Since the formula labeling the
root is ¬A, it follows that ⊢¬¬A, from which ⊢A follows by propositional logic.
The base case of the leaves and the inductive steps for the rules for α- and β-
formulas follow by propositional reasoning together with the expansion axiom.
Suppose that the rule for an X-formula is used:
#A1,...,#An, B1,...,Bk
↓
A1,...,An

270
14
Temporal Logic: A Deductive System
where we assume that negations are pushed inwards as justiﬁed by the linearity
axiom. By the inductive hypothesis, ⊢¬A1 ∨··· ∨¬An. The following deduction
proves the formula associated with the parent node:
1.
⊢¬A1 ∨··· ∨¬An
Inductive hypothesis
2.
⊢2(¬A1 ∨··· ∨¬An)
1, Generalization
3.
⊢#(¬A1 ∨··· ∨¬An)
2, Expansion
4.
⊢#¬A1 ∨··· ∨#¬An
3, Distribution
5.
⊢¬#A1 ∨··· ∨¬#An
4, Linearity
6.
⊢¬#A1 ∨··· ∨¬#An ∨¬B1 ∨··· ∨¬Bk
5, Prop
There remains the case of a node that is part of a non-fulﬁlling MSCC. We
demonstrate the technique on a speciﬁc example, proving ⊢2p →#2p by con-
structing a semantic tableau for the negation of the formula.
¬ (2p →#2p)
↓
2p, #3¬p
↓
ls
p, #2p, #3¬p
↓
2p, 3¬p
↓
lβ
p, #2p, 3¬p
↙
↘
p, #2p, ¬p
(To node ls)
×
The crucial part of the proof is to deﬁne the invariant of the loop, that is, a formula
A such that ⊢A →#A. The invariant will be the conjunction of the formulas Ai,
where #Ai are the next formulas in the states of the SCC, as these represent what
must be true from one state to the next. In the example, for invariant is 2p ∧3¬p.
We proceed to prove that this formula is inductive.
1.
⊢(2p ∧3¬p) →(p ∧#2p) ∧(¬p ∨#3¬p)
Expansion
2.
⊢(2p ∧3¬p) →(p ∧#2p ∧#3¬p)
1, Prop
3.
⊢(2p ∧3¬p) →(#2p ∧#3¬p)
2, Prop
4.
⊢(2p ∧3¬p) →#(2p ∧3¬p)
3, Distribution
5.
⊢(2p ∧3¬p) →2(2p ∧3¬p)
4, Induction
The leaf on the left of the tableau has a complementary pair of literals, so ⊢
¬p ∨¬#2p ∨¬¬p is an axiom. We use this formula together with formula (5)
to prove the formula associated with lβ.

14.4
Axioms for the Binary Temporal Operators *
271
6.
⊢¬p ∨¬#2p ∨¬¬p
Axiom 0
7.
⊢(p ∧#2p) →¬¬p
6, Prop
8.
⊢2p →¬¬p
7, Contraction
9.
⊢(2p ∧3¬p) →¬¬p
8, Prop
10.
⊢2(2p ∧3¬p) →2¬¬p
9, Generalization
11.
⊢(2p ∧3¬p) →2¬¬p
5, 10, Prop
12.
⊢(p ∧#2p ∧3¬p) →2¬¬p
11, Expansion
13.
⊢(p ∧#2p ∧3¬p) →¬3¬p
12, Duality
14.
⊢¬p ∨¬#2p ∨¬3¬p
13, Prop
Line 14 is the disjunction of the complements of the formulas at node lβ.
The method used in the proof will almost certainly not yield the shortest possible
proof of a formula, but it is an algorithmic procedure for discovering a proof of a
valid LTL formula.
14.4 Axioms for the Binary Temporal Operators *
Section 13.6 presented several binary temporal operators, any one of which can be
chosen as a basic operator and the others deﬁned from it. If we choose U as the
basic operator, a complete axiom system is obtained by adding the following two
axioms to the axioms of Deﬁnition 14.1:
Axiom 6
Expansion of U
⊢AU B ↔(B ∨(A ∧#(AU B))).
Axiom 7
Eventuality
⊢AU B →3B.
U is similar to 3: Axiom 6 requires that either B is true today or A is true today
and AU B will be true tomorrow. Axiom 7 requires that B eventually be true.
14.5 Summary
The deductive system L assumes that propositional reasoning can be informally
applied. There are ﬁve axioms: the distributive and expansion axioms are straight-
forward, while the duality axiom for # is essential to capture the linearity of in-
terpretations of LTL. The central axiom of L is the induction axiom: since inter-
pretations in LTL are inﬁnite paths, proofs of non-trivial formulas usually require
induction. The rules of inference are the familiar modus ponens and generalization
using 2. As usual, the proof of soundness is straightforward. Proving completeness
is based on the existence of a non-fulﬁlling MSCC in a tableau. The formulas label-
ing the nodes of the MSCC can be used to construct a formula that can be proved
by induction.

272
14
Temporal Logic: A Deductive System
14.6 Further Reading
The deductive system L and the proof of its soundness and completeness is based
on Ben-Ari et al. (1983), although that paper used a different system of temporal
logic. The deﬁnitive reference for the speciﬁcation and veriﬁcation of concurrent
programs using temporal logic is Manna and Pnueli (1992, 1995). The third volume
was never completed, but a partial draft is available (Manna and Pnueli, 1996). Ax-
ioms for the various binary temporal operators are given in Kröger and Merz (2008,
Chap. 3).
14.7 Exercises
14.1 Prove ⊢2(p ∧q) →(2p ∧2q) (Theorem 14.3).
14.2 Prove ⊢(2p ∨2q) →2(p ∨q) (Theorem 14.5) and show that the converse
is not valid.
14.3 Prove the future formulas in Theorem 14.10.
14.4 Prove that Axioms 2 and 3 are valid.
14.5 Prove ⊢323p ↔23p (Theorem 14.11) and ⊢32p →23p (Theo-
rem 14.8).
14.6 Prove ⊢2(23p →3q) ↔(23q ∨32¬p).
14.7 Fill in the details of the proof of ⊢2((p ∨2q) ∧(2p ∨q)) ↔(2p ∨2q).
References
M. Ben-Ari, Z. Manna, and A. Pnueli. The temporal logic of branching time. Acta Informatica,
20:207–226, 1983.
F. Kröger and S. Merz. Temporal Logic and State Systems. Springer, 2008.
Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems. Vol. I: Speciﬁ-
cation. Springer, New York, NY, 1992.
Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems. Vol. II: Safety.
Springer, New York, NY, 1995.
Z. Manna and A. Pnueli. Temporal veriﬁcation of reactive systems: Progress. Draft available at
http://www.cs.stanford.edu/~zm/tvors3.html, 1996.

Chapter 15
Veriﬁcation of Sequential Programs
A computer program is not very different from a logical formula. It consists of a
sequence of symbols constructed according to formal syntactical rules and it has
a meaning which is assigned by an interpretation of the elements of the language.
In programming, the symbols are called statements or commands and the intended
interpretation is the execution of the program on a computer. The syntax of program-
ming languages is speciﬁed using formal systems such as BNF, but the semantics is
usually informally speciﬁed.
In this chapter, we describe a formal semantics for a simple programming lan-
guage, as well as a deductive system for proving that a program is correct. Unlike
our usual approach, we ﬁrst deﬁne the deductive system and only later deﬁne the
formal semantics. The reason is that the deductive system is useful for proving pro-
grams, but the formal semantics is primarily intended for proving the soundness and
completeness of the deductive system.
The chapter is concerned with sequential programs. A different, more complex,
logical formalism is needed to verify concurrent programs and this is discussed
separately in Chap. 16.
Our programs will be expressed using a fragment of the syntax of popular lan-
guages like Java and C. A program is a statement S, where statements are deﬁned
recursively using the concepts of variables and expressions:
Assignment statement
variable = expression ;
Compound statement
{ statement1 statement2 ...}
Alternative statement
if (expression) statement1 else statement2
Loop statement
while (expression) statement
We assume that the informal semantics of programs written in this syntax is familiar.
In particular, the concept of the location counter (sometimes called the instruction
pointer) is fundamental: During the execution of a program, the location counter
stores the address of the next instruction to be executed by the processor.
In our examples the values of the variables will be integers.
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_15, © Springer-Verlag London 2012
273

274
15
Veriﬁcation of Sequential Programs
15.1 Correctness Formulas
A statement in a programming language can be considered to be a function that
transforms the state of a computation. If the variables (x,y) have the values (8,7)
in a state, then the result of executing the statement x = 2*y+1 is the state in
which (x,y) = (15,7) and the location counter is incremented.
Deﬁnition 15.1 Let S be a program with n variables (x1,...,xn). A state s of S
consists of an n + 1-tuple of values (lc,x1,...,xn), where lc is the value of the
location counter and xi is the value of the variable xi.
The variables of a program will be written in typewriter font x, while the corre-
sponding value of the variable will be written in italic font x. Since a state is always
associated with a speciﬁc location, the location counter will be implicit and the state
will be an n-tuple of the values of the variables.
In order to reason about programs within ﬁrst-order logic, predicates are used to
specify sets of states.
Deﬁnition 15.2 Let U be the set of all n-tuples of values over some domain(s),
and let U′ ⊆U be a relation over U. The n-ary predicate PU′ is the characteristic
predicate of U′ if it is interpreted over the domain U by the relation U′. That is,
v(PU′(x1,...,xn)) = T iff (x1,...,xn) ∈U′.
We can write {(x1,...,xn) | (x1,...,xn) ∈U′} as {(x1,...,xn) | PU′}.
Example 15.3 Let U be the set of 2-tuples over Z and let U′ ⊆U be the 2-tuples
described in the following table:
···
···
(−2,−3)
(−2,−2)
(−2,−1)
(−2,0)
(−2,1)
(−2,2)
(−2,3)
···
(−1,−3)
(−1,−2)
(−1,−1)
(−1,0)
(−1,1)
(−1,2)
(−1,3)
···
(0,−3)
(0,−2)
(0,−1)
(0,0)
(0,1)
(0,2)
(0,3)
···
(1,−3)
(1,−2)
(1,−1)
(1,0)
(1,1)
(1,2)
(1,3)
···
(2,−3)
(2,−2)
(2,−1)
(2,0)
(2,1)
(2,2)
(2,3)
···
Two characteristic predicates of U′ are (x1 = x1)∧(x2 ≤3) and x2 ≤3. The set can
be written as {(x1,x2) | x2 ≤3}.
The semantics of a programming language is given by specifying how each state-
ment in the language transforms one state into another.
Example 15.4 Let S be the statement x = 2*y+1. If started in an arbitrary state
(x,y), the statement terminates in the state (x′,y′) where x′ = 2y′ +1. Another way
of expressing this is to say that S transforms the set of states {(x,y) | true} into the
set {(x,y) | x = 2y + 1}.
The statement S also transforms the set of states {(x,y) | y ≤3} into the set
{(x,y) | (x ≤7) ∧(y ≤3)}, because if y ≤3 then 2y + 1 ≤7.

15.2
Deductive System H L
275
The concept of transforming a set of states can be extended from an assignment
statement to the statement representing the entire program. This is then used to
deﬁne correctness.
Deﬁnition 15.5 A correctness formula is a triple {p} S {q}, where S is a program,
and p and q are formulas called the precondition and postcondition, respectively. S
is partially correct with respect to p and q, |= {p} S {q}, iff:
If S is started in a state where p is true and if the computation of S terminates,
then it terminates in a state where q is true.
Correctness formulas were ﬁrst deﬁned in Hoare (1969). The term is taken from
Apt et al. (2009); the formulas are also called inductive expressions, inductive as-
sertions and Hoare triples.
Example 15.6 |= {y ≤3} x = 2*y+1 {(x ≤7) ∧(y ≤3)}.
Example 15.7 For any S, p and q:
|= {false} S {q},
|= {p} S {true},
since false is not true in any state and true is true in all states.
15.2 Deductive System H L
The deductive system H L (Hoare Logic) is sound and relatively complete for
proving partial correctness. By relatively complete, we mean that the formulas ex-
pressing properties of the domain will not be formally proven. Instead, we will sim-
ply take all true formulas in the domain as axioms. For example, (x ≥y)→(x +1 ≥
y + 1) is true in arithmetic and will be used as an axiom. This is reasonable since
we wish to concentrate on the veriﬁcation that a program S is correct without the
complication of verifying arithmetic formulas that are well known.
Deﬁnition 15.8 (Deductive system H L )
Domain axioms
Every true formula over the domain(s) of the program variables.
Assignment axiom
⊢{p(x){x ←t}} x = t {p(x)}.
Composition rule
⊢{p} S1 {q}
⊢{q} S2 {r}
⊢{p} S1 S2 {r}
.

276
15
Veriﬁcation of Sequential Programs
Alternative rule
⊢{p ∧B} S1 {q}
⊢{p ∧¬B} S2 {q}
⊢{p} if (B) S1 else S2 {q}
.
Loop rule
⊢{p ∧B} S {p}
⊢{p} while (B) S {p ∧¬B}.
Consequence rule
⊢p1 →p
⊢{p} S {q}
⊢q →q1
⊢{p1} S {q1}
.
The consequence rule says that we can always strengthen the precondition or
weaken the postcondition.
Example 15.9 From Example 15.6, we know that:
|= {y ≤3} x = 2*y+1 {(x ≤7) ∧(y ≤3)}.
Clearly:
|= {y ≤1} x = 2*y+1 {(x ≤10) ∧(y ≤3)}.
The states satisfying y ≤1 are a subset of those satisfying y ≤3, so a computation
started in a state where, say, y = 0 ≤1 satisﬁes y ≤3. Similarly, the states satisfying
x ≤10 are a superset of those satisfying x ≤7; we know that the computation results
in a value of x such that x ≤7 and that value is also less than or equal to 10.
Since ⊢p →p and ⊢q →q, we can strengthen the precondition without weak-
ening the postcondition or conversely.
The assignment axiom may seem strange at ﬁrst, but it can be understood by
reasoning from the conclusion to the premise. Consider:
⊢{?} x = t {p(x)}.
After executing the assignment statement, we want p(x) to be true when the value
assigned to x is the value of the expression t. If the formula that results from per-
forming the substitution p(x){x ←t} is true, then when x is actually assigned the
value of t, p(x) will be true.
The composition rule and the alternative rule are straightforward.
The formula p in the loop rule is called an invariant: it describes the behavior of
a single execution of the statement S in the body of the while-statement. To prove:
⊢{p0} while (B) S {q0},
we ﬁnd a formula p and prove that it is an invariant: ⊢{p ∧B} S {p}.

15.3
Program Veriﬁcation
277
By the loop rule:
⊢{p} while (B) S {p ∧¬B}.
If we can prove p0 →p and (p ∧¬B)→q0, then the consequence rule can be used
to deduce the correctness formula. We do not know how many times the while-
loop will be executed, but we know that p ∧¬B holds when it does terminate.
To prove the correctness of a program, one has to ﬁnd appropriate invariants. The
weakest possible formula true is an invariant of any loop since ⊢{true ∧B} S {true}
holds for any B and S. Of course, this formula is too weak, because it is unlikely
that we will be able to prove (true ∧¬B) →q0. On the other hand, if the formula
is too strong, it will not be an invariant.
Example 15.10 x = 5 is too strong to be an invariant of the while-statement:
while (x > 0) x = x - 1;
because x = 5 ∧x > 0 clearly does not imply that x = 5 after executing the state-
ment x = x - 1. The weaker formula x ≥0 is also an invariant: x ≥0 ∧x > 0
implies x ≥0 after executing the loop body. By the loop rule, if the loop terminates
then x ≥0 ∧¬(x > 0). This can be simpliﬁed to x = 0 by reasoning within the
domain and using the consequence rule.
15.3 Program Veriﬁcation
Let us use H L to proving the partial correctness of the following program P:
{true}
x = 0;
{x = 0}
y = b;
{x = 0 ∧y = b}
while (y != 0)
{x = (b −y) · a}
{
x = x + a;
y = y - 1;
}
{x = a · b}
Be careful to distinguish between braces {} used in the syntax of the program from
those used in the correctness formulas.
We have annotated P with formulas between the statements. Given:
{p1}S1{p2}S2···{pn}Sn{pn+1},
if we can prove {pi} Si {pi+1} for all i, then we can conclude:

278
15
Veriﬁcation of Sequential Programs
{p1} S1 ··· Sn {pn+1}
by repeated application of the composition rule. See Apt et al. (2009, Sect. 3.4) for
a proof that H L with annotations is equivalent to H L without them.
Theorem 15.11 ⊢{true} P {x = a · b}.
Proof From the assignment axiom we have {0 = 0} x=0 {x = 0}, and from the con-
sequence rule with premise true →(0 = 0), we have {true} x=0 {x = 0}. The proof
of {x = 0} y=b {(x = 0) ∧(y = b)} is similar.
Let us now show that x = (b −y) · a is an invariant of the loop. Executing the
loop body will substitute x + a for x and y −1 for y. Since the assignments have
no variable in common, we can do them simultaneously. Therefore:
(x = (b −y) · a){x ←x + a,y ←y −1} ≡x + a = (b −(y −1)) · a
≡x = (b −y + 1) · a −a
≡x = (b −y) · a + a −a
≡x = (b −y) · a.
By the consequence rule, we can strengthen the precondition:
{(x = (b −y) · a) ∧y ̸= 0} x=x+a; y=y-1; {x = (b −y) · a},
and then use the Loop Rule to deduce:
{x = (b −y) · a}
while (y != 0)
{
x=x+a;
y=y-1;
}
{(x = (b −y) · a) ∧¬(y ̸= 0)}
Since ¬(y ̸= 0) ≡(y = 0), we obtain the required postcondition:
(x = (b −y) · a) ∧(y = 0) ≡(x = b · a) ≡(x = a · b).
15.3.1 Total Correctness *
Deﬁnition 15.12 A program S is totally correct with respect to p and q iff:
If S is started in a state where p is true, then the computation of S terminates
and it terminates in a state where q is true.

15.4
Program Synthesis
279
The program in Sect. 15.3 is partial correct but not totally correct: if the initial
value of b is negative, the program will not terminate. The precondition needs to be
strengthened to b ≥0 for the program to be totally correct.
Clearly, the only construct in a program that can lead to non-termination is a
loop statement, because the number of iterations of a while-statement need not be
bounded. Total correctness is proved by showing that the body of the loop always
decreases some value and that that value is bounded from below. In the above pro-
gram, the value of the variable y decreases by one during each execution of the loop
body. Furthermore, it is easy to see that y ≥0 can be added to the invariant of the
loop and that y is bounded from below by 0. Therefore, if the precondition is b ≥0,
then b ≥0 →y ≥0 and the program terminates when y = 0.
H L can be extended to a deductive system for total correctness; see Apt et al.
(2009, Sect. 3.3).
15.4 Program Synthesis
Correctness formulas may also be used in the synthesis of programs: the construc-
tion of a program directly from a formal speciﬁcation. The emphasis is on ﬁnding
invariants of loops, because the other aspects of proving a program (aside from
deductions within the domain) are purely mechanical. Invariants are hypothesized
as modiﬁcations of the postcondition and the program is constructed to maintain
the truth of the invariant. We demonstrate the method by developing two different
programs for ﬁnding the integer square root of a non-negative integer x = ⌊√a⌋;
expressed as a correctness formula using integers, this is:
{0 ≤a} S {0 ≤x2 ≤a < (x + 1)2}.
15.4.1 Solution 1
A loop is used to calculate values of the variable x until the postcondition holds.
Suppose we let the ﬁrst part of the postcondition be the invariant and try to establish
the second part upon termination of the loop. This gives the following program
outline, where E1(x,a), E2(x,a) and B(x,a) represent expressions that must
be determined:
{0 ≤a}
x = E1(x,a);
while (B(x,a))
{0 ≤x2 ≤a}
x = E2(x,a);
{0 ≤x2 ≤a < (x + 1)2}.

280
15
Veriﬁcation of Sequential Programs
Let p denote the formula 0 ≤x2 ≤a that is the ﬁrst subformula of the postcon-
dition and then see what expressions will make p an invariant:
• The precondition is 0 ≤a, so p will be true at the beginning of the loop if the ﬁrst
statement is x=0.
• By the loop rule, when the while-statement terminates, the formula p ∧
¬B(x,a) is true. If this formula implies the postcondition:
(0 ≤x2 ≤a) ∧¬B(x,a) →0 ≤x2 ≤a < (x + 1)2,
the postcondition follows by the consequence rule. Clearly, ¬B(x,a) should be
a < (x + 1)2, so we choose B(x,a) to be (x+1)*(x+1)<=a.
• Given this Boolean expression, if the loop body always increases the value of x,
then the loop will terminate. The simplest way to do this is x=x+1.
Here is the resulting program:
{0 ≤a}
x = 0;
while ((x+1)*(x+1) <= a)
{0 ≤x2 ≤a}
x = x + 1;
{0 ≤x2 ≤a < (x + 1)2}.
What remains to do is to check that p is, in fact, an invariant of the loop: {p ∧
B} S {p}. Written out in full, this is:
{0 ≤x2 ≤a ∧(x + 1)2 ≤a} x=x+1 {0 ≤x2 ≤a}.
The assignment axiom for x=x+1 is:
{0 ≤(x + 1)2 ≤a} x=x+1 {0 ≤x2 ≤a}.
The invariant follows from the consequence rule if the formula:
(0 ≤x2 ≤a ∧(x + 1)2 ≤a) →(0 ≤(x + 1)2 ≤a)
is provable. But this is a true formula of arithmetic so it is a domain axiom.
15.4.2 Solution 2
Incrementing the variable x is not a very efﬁcient way of computing the integer
square root. With some more work, we can ﬁnd a better solution. Let us introduce
a new variable y to bound x from above; if we maintain x < y while increasing the
value of x or decreasing the value of y, we should be able to close in on a value that
makes the postcondition true. Our invariant will contain the formula:

15.4
Program Synthesis
281
0 ≤x2 ≤a < y2.
Looking at the postcondition, we see that y is overestimated by a +1, so a candidate
for the invariant p is:
(0 ≤x2 ≤a < y2) ∧(x < y ≤a + 1).
Before trying to establish p as an invariant, let us check that we can ﬁnd an
initialization statement and a Boolean expression that will make p true initially and
the postcondition true when the loop terminates.
• The statement y=a+1 makes p true at the beginning of the loop.
• If the loop terminates when ¬B is y = x + 1, then:
p ∧¬B →0 ≤x2 ≤a < (x + 1)2.
The outline of the program is:
{0 ≤a}
x = 0;
y = a+1;
while (y != x+1)
{(0 ≤x2 ≤a < y2) ∧(x < y ≤a + 1)}
E(x,y,a);
{0 ≤x2 ≤a < (x + 1)2}.
Before continuing with the synthesis, let us try an example.
Example 15.13 Suppose that a = 14. Initially, x = 0 and y = 15. The loop should
terminate when x = 3 and y = x + 1 = 4 so that 0 ≤9 ≤14 < 16. We need to
increase x or decrease y while maintaining the invariant 0 ≤x2 ≤a < y2. Let us
take the midpoint ⌊(x + y)/2⌋= ⌊(0 + 15)/2⌋= 7 and assign it to either x or y, as
appropriate, to narrow the range. In this case, a = 14 < 49 = 7·7, so assigning 7 to y
will maintain the invariant. On the next iteration, ⌊(x +y)/2⌋= ⌊(0+7)/2⌋= 3 and
3 · 3 = 9 < 14 = a, so assigning 3 to x will maintain the invariant. After two more
iterations during which y receives the values 5 and then 4, the loop terminates.
Here is an outline for the annotated loop body; the annotations are derived from
the invariant {p ∧B} S1 {p} that must be proved and as well as from additional
formulas that follow from the assignment axiom.

282
15
Veriﬁcation of Sequential Programs
{p ∧(y ̸= x + 1)}
z = (x+y) / 2;
{p ∧(y ̸= x + 1) ∧(⌊z = (x + y)/2⌋)}
if (Cond(x,y,z))
{p{x ←z}}
x = z;
else
{p{y ←z}}
y = z;
{p}
z is a new variable and Cond(x,y,z) is a Boolean expression chosen so that:
(p ∧(y ̸= x + 1) ∧(z = ⌊(x + y)/2⌋) ∧Cond(x,y,z))
→p{x ←z},
(p ∧(y ̸= x + 1) ∧(z = ⌊(x + y)/2⌋) ∧¬Cond(x,y,z)) →p{y ←z}.
Let us write out the ﬁrst subformula of p on both sides of the equations:
(0 ≤x2 ≤a < y2) ∧Cond(x,y,z)
→(0 ≤z2 ≤a < y2),
(0 ≤x2 ≤a < y2) ∧¬Cond(x,y,z) →(0 ≤x2 ≤a < z2).
These formulas will be true if Cond(x,y,z) is chosen to be z*z <= a.
We have to establish the second subformulas of p{x ←z} and p{y ←z}, which
are z < y ≤a + 1 and x < z ≤a + 1. Using the second subformulas of p, they
follow from arithmetical reasoning:
(x < y ≤a + 1)∧
z = ⌊(x + y)/2⌋→(z < y ≤a + 1),
(x < y ≤a + 1)∧(y ̸= x + 1) ∧z = ⌊(x + y)/2⌋→(x < z ≤a + 1).
Here is the ﬁnal program:
{0 ≤a}
x = 0;
y = a+1;
while (y != x+1)
{0 ≤x2 ≤a < y2 ∧x < y ≤a + 1}
{
z = (x+y) / 2;
if (z*z <= a)
x = z;
else
y = z;
}
{0 ≤x2 ≤a < (x + 1)2}.

15.5
Formal Semantics of Programs *
283
15.5 Formal Semantics of Programs *
A statement transforms a set of initial states where the precondition holds into a
set of ﬁnal states where the postcondition holds. In this section, the semantics of a
program is deﬁned in terms the weakest precondition that causes the postcondition
to hold when a statement terminates. In the next section, we show how the formal
semantics can be used to prove the soundness and relative completeness of the de-
ductive system H L .
15.5.1 Weakest Preconditions
Let us start with an example.
Example 15.14 Consider the assignment statement x=2*y+1. A correctness for-
mula for this statement is:
{y ≤3} x=2*y+1 {(x ≤7) ∧(y ≤3)},
but y ≤3 is not the only precondition that will make the postcondition true. Another
one is y = 1 ∨y = 3:
{y = 1 ∨y = 3} x = 2*y+1 {(x ≤7) ∧(y ≤3)}.
The precondition y = 1 ∨y = 3 is ‘less interesting’ than y ≤3 because it does not
characterize all the states from which the computation can reach a state satisfying
the postcondition.
We wish to choose the least restrictive precondition so that as many states as
possible can be initial states in the computation.
Deﬁnition 15.15 A formula A is weaker than formula B if B →A. Given a set of
formulas {A1,A2,...}, Ai is the weakest formula in the set if Aj →Ai for all j.
Example 15.16 y ≤3 is weaker than y = 1∨y = 3 because (y = 1∨y = 3)→(y ≤
3). Similarly, y = 1 ∨y = 3 is weaker than y = 1, and (by transitivity) y ≤3 is also
weaker than y = 1. This is demonstrated by the following diagram:
which shows that the weaker the formula, the most states it characterizes.

284
15
Veriﬁcation of Sequential Programs
The consequence rule is based upon the principle that you can always strengthen
an antecedent and weaken a consequent; for example, if p→q, then (p∧r)→q and
p →(q ∨r). The terminology is somewhat difﬁcult to get used to because we are
used to thinking about states rather than predicates. Just remember that the weaker
the predicate, the more states satisfy it.
Deﬁnition 15.17 Given a program S and a formula q, wp(S, q), the weakest pre-
condition of S and q, is the weakest formula p such that |= {p} S {q}.
E.W. Dijkstra called this the weakest liberal precondition wlp, and reserved wp
for preconditions that ensure total correctness. Since we only discuss partial correct-
ness, we omit the distinction for conciseness.
Lemma 15.18 |= {p} S {q} if and only if |= p →wp(S, q).
Proof Immediate from the deﬁnition of weakest.
Example 15.19 wp(x=2*y+1, x ≤7 ∧y ≤3) = y ≤3. Check that y ≤3 re-
ally is the weakest precondition by showing that for any weaker formula p′,
̸|= {p′} x=2*y+1 {x ≤7 ∧y ≤3}.
The weakest precondition p depends upon both the program and the postcondi-
tion. If the postcondition in the example is changed to x ≤9 the weakest precondi-
tion becomes y ≤4. Similarly, if S is changed to x = y+6 without changing the
postcondition, the weakest precondition becomes y ≤1.
wp is a called a predicate transformer because it deﬁnes a transformation of a
postcondition predicate into a precondition predicate.
15.5.2 Semantics of a Fragment of a Programming Language
The following deﬁnitions formalize the semantics of the fragment of the program-
ming language used in this chapter.
Deﬁnition 15.20 wp(x=t, p(x)) = p(x){x ←t}.
Example 15.21 wp(y=y-1, y ≥0) = (y −1 ≥0) ≡y ≥1.
For a compound statement, the weakest precondition obtained from the second
statement and postcondition of the compound statement deﬁnes the postcondition
for the ﬁrst statement.
Deﬁnition 15.22 wp(S1 S2, q) = wp(S1, wp(S2, q)).

15.5
Formal Semantics of Programs *
285
The following diagram illustrates the deﬁnition:
The precondition wp(S2, q) characterizes the largest set of states such that execut-
ing S2 leads to a state in which q is true. If executing S1 leads to one of these states,
then S1 S2 will lead to a state whose postcondition is q.
Example 15.23
wp(x=x+1; y=y+2, x < y) = wp(x=x+1, wp(y=y+2, x < y))
≡wp(x=x+1, x < y + 2)
≡x + 1 < y + 2
≡x < y + 1.
Example 15.24
wp(x=x+a; y=y-1, x
= (b −y) · a)
= wp(x=x+a, wp(y=y-1, x = (b −y) · a))
≡wp(x=x+a, x = (b −y + 1) · a)
≡x + a = (b −y + 1) · a
≡x = (b −y) · a.
Given the precondition x = (b −y) · a, the statement x=x+a; y=y-1, considered
as a predicate transformer, does nothing! This is not really surprising because the
formula is an invariant. Of course, the statement does transform the state of the
computation by changing the values of the variables, but it does so in such a way
that the formula remains true.
Deﬁnition 15.25 A predicate I is an invariant of S iff wp(S, I) = I.
Deﬁnition 15.26
wp(if (B) S1 else S2, q) = (B ∧wp(S1, q)) ∨(¬B ∧wp(S2, q)).
The deﬁnition is straightforward because the predicate B partitions the set of
states into two disjoint subsets, and the preconditions are then determined by the
actions of each Si on its subset.

286
15
Veriﬁcation of Sequential Programs
From the propositional equivalence:
(p →q) ∧(¬p →r) ≡(p ∧q) ∨(¬p ∧r),
it can be seen that an alternate deﬁnition is:
wp(if (B) S1 else S2, q) = (B →wp(S1, q)) ∧(¬B →wp(S2, q)).
Example 15.27
wp(if (y=0) x=0; else x=y+1, x = y)
=
(y = 0 →wp(x=0, x = y)) ∧(y ̸= 0 →wp(x=y+1, x = y))
≡
((y = 0) →(0 = y)) ∧((y ̸= 0) →(y + 1 = y))
≡
true ∧((y ̸= 0) →false)
≡
¬(y ̸= 0)
≡
y = 0.
Deﬁnition 15.28
wp(while (B) S, q) = (¬B ∧q) ∨(B ∧wp(S; while (B) S, q)).
The execution of a while-statement can proceed in one of two ways.
• The statement can terminate immediately because the Boolean expression eval-
uates to false, in which case the state does not change so the precondition is the
same as the postcondition.
• The expression can evaluate to true and cause S, the body of the loop, to be
executed. Upon termination of the body, the while-statement again attempts to
establish the postcondition.
Because of the recursion in the deﬁnition of the weakest precondition for a
while-statement, we cannot constructively compute it; nevertheless, an attempt
to do so is informative.
Example 15.29 Let W be an abbreviation for while (x>0) x=x-1.
wp(W, x = 0)
=
[¬(x > 0) ∧(x = 0)] ∨[(x > 0) ∧wp(x=x-1; W, x = 0)]
≡
(x = 0) ∨[(x > 0) ∧wp(x=x-1, wp(W, x = 0))]
≡
(x = 0) ∨[(x > 0) ∧wp(W, x = 0){x ←x −1}].
We have to perform the substitution {x ←x −1} on wp(W, x = 0). But we have just
computed a value for wp(W, x = 0). Performing the substitution and simplifying
gives:

15.5
Formal Semantics of Programs *
287
wp(W, x = 0)
≡
(x = 0) ∨[(x > 0) ∧
wp(W, x = 0){x ←x −1}]
≡
(x = 0) ∨[(x > 0) ∧
((x = 0) ∨[(x > 0) ∧wp(W, x = 0){x ←x −1}]){x ←x −1}]
≡
(x = 0) ∨[(x −1 > 0) ∧
((x −1 = 0) ∨[(x −1 > 0) ∧wp(W, x = 0){x ←x −1}{x ←x −1}])]
≡
(x = 0) ∨[(x > 1) ∧
((x = 1) ∨[(x > 1) ∧wp(W, x = 0){x ←x −1}{x ←x −1}])]
≡
(x = 0) ∨(x = 1) ∨[(x > 1) ∧
wp(W, x = 0){x ←x −1}{x ←x −1}].
Continuing the computation, we arrive at the following formula:
wp(W, x = 0) ≡(x = 0) ∨(x = 1) ∨(x = 2) ∨···
≡x ≥0.
The theory of ﬁxpoints can be used to formally justify the inﬁnite substitution
but that is beyond the scope of this book.
15.5.3 Theorems on Weakest Preconditions
Weakest preconditions distribute over conjunction.
Theorem 15.30 (Distributivity) |= wp(S, p) ∧wp(S, q) ↔wp(S, p ∧q).
Proof Let s be an arbitrary state in which wp(S, p) ∧wp(S, q) is true. Then both
wp(S, p) and wp(S, q) are true in s. Executing S starting in state s leads to a state
s′ such that p and q are both true in s′. By propositional logic, p ∧q is true in s′.
Since s was arbitrary, we have proved that:
{s ||= wp(S, p) ∧wp(S, q)} ⊆{s ||= wp(S, p ∧q)},
which is the same as:
|= wp(S, p) ∧wp(S, q) →wp(S, p ∧q).
The converse is left as an exercise.

288
15
Veriﬁcation of Sequential Programs
Corollary 15.31 (Excluded miracle) |= wp(S, p) ∧wp(S, ¬p) ↔wp(S, false).
According to the deﬁnition of partial correctness, any postcondition (including
false) is vacuously true if the program does not terminate. It follows that the weakest
precondition must include all states for which the program does not terminate. The
following diagram shows how wp(S, false) is the intersection (conjunction) of the
weakest preconditions wp(S, p) and wp(S, ¬p):
The diagram also furnishes an informal proof of the following theorem.
Theorem 15.32 (Duality) |= ¬wp(S, ¬p) →wp(S, p).
Theorem 15.33 (Monotonicity) If |= p →q then |= wp(S, p) →wp(S, q).
Proof
1.
|= wp(S, p) ∧wp(S, ¬q) →wp(S, p ∧¬q)
Theorem 15.30
2.
|= p →q
Assumption
3.
|= ¬(p ∧¬q)
2, PC
4.
|= wp(S, p) ∧wp(S, ¬q) →wp(S, false)
1,3
5.
|= wp(S, false) →wp(S, q) ∧wp(S, ¬q)
Corollary 15.31
6.
|= wp(S, false) →wp(S, q)
5, PC
7.
|= wp(S, p) ∧wp(S, ¬q) →wp(S, q)
4, 6, PC
8.
|= wp(S, p) →¬wp(S, ¬q) ∨wp(S, q)
7, PC
9.
|= wp(S, p) →wp(S, q)
8, Theorem 15.32, PC
The theorem shows that a weaker formula satisﬁes more states:

15.6
Soundness and Completeness of H L *
289
Example 15.34 Let us demonstrate the theorem where p is x < y −2 and q is x < y
so that |= p →q. We leave it to the reader to calculate:
wp(x=x+1; y=y+2;, x < y −2) = x < y −1
wp(x=x+1; y=y+2;, x < y)
= x < y + 1.
Clearly |= x < y −1 →x < y + 1.
15.6 Soundness and Completeness of H L *
We start with deﬁnitions and lemmas which will be used in the proofs.
The programming language is extended with two statements skip and abort
whose semantics are deﬁned as follows.
Deﬁnition 15.35 wp(skip, p) = p and wp(abort, p) = false.
In other words, skip does nothing and abort doesn’t terminate.
Deﬁnition 15.36 Let W be an abbreviation for while (B) S.
W0
= if (B) abort; else skip
Wk+1
= if (B) S;Wk else skip
The inductive deﬁnition will be used to prove that an execution of W is equivalent
to Wk for some k.
Lemma 15.37 wp(W0, p) ≡¬B ∧(¬B →p).
Proof
wp(W0, p)
≡
wp(if (B) abort; else skip, p)
≡
(B →wp(abort, p)) ∧(¬B →wp(skip, p)) ≡
(B →false) ∧(¬B →p)
≡
(¬B ∨false) ∧(¬B →p)
≡
¬B ∧(¬B →p).

290
15
Veriﬁcation of Sequential Programs
Lemma 15.38 ∞
k=0 wp(Wk, p) →wp(W, p).
Proof We show by induction that for each k, wp(Wk, p) →wp(W, p).
For k = 0:
1.
wp(W0, p) →¬B ∧(¬B →p)
Lemma 15.37
2.
wp(W0, p) →¬B ∧p
1, PC
3.
wp(W0, p) →(¬B ∧p) ∨(B ∧wp(S;W, p))
2, PC
4.
wp(W0, p) →wp(W, p)
3, Def. 15.28
For k > 0:
1.
wp(Wk+1, p) = wp(if (B) S;Wk else skip, p)
Def. 15.36
2.
wp(Wk+1, p) ≡(B →wp(S;Wk, p))∧
Def. 15.26
(¬B →wp(skip, p))
3.
wp(Wk+1, p) ≡(B →wp(S, wp(Wk, p)))∧
Def. 15.22
(¬B →wp(skip, p))
4.
wp(Wk+1, p) ≡(B →wp(S, wp(Wk, p))) ∧(¬B →p)
Def. 15.35
5.
wp(Wk+1, p) →(B →wp(S, wp(W, p))) ∧(¬B →p)
Ind. hyp.
6.
wp(Wk+1, p) →(B →wp(S;W, p)) ∧(¬B →p)
Def. 15.22
7.
wp(Wk+1, p) →wp(W, p)
Def. 15.28
As k increases, more and more states are included in k
i=0 wp(Wi, p):
Theorem 15.39 (Soundness of H L ) If ⊢HL {p} S {q} then |= {p} S {q}.
Proof The proof is by induction on the length of the H L proof. By assumption,
the domain axioms are true, and the use of the consequence rule can be justiﬁed by
the soundness of MP in ﬁrst-order logic.
By Lemma 15.18, |= {p} S {q} iff |= p →wp(S, q), so it is sufﬁcient to prove
|= p →wp(S, q). The soundness of the assignment axioms is immediate by Deﬁni-
tion 15.20.
Suppose that the composition rule is used. By the inductive hypothesis, we can
assume that |= p →wp(S1, q) and |= q →wp(S2, r). From the second assumption
and monotonicity (Theorem 15.33),

15.6
Soundness and Completeness of H L *
291
|= wp(S1, q) →wp(S1, wp(S2, r)).
By the consequence rule and the ﬁrst assumption, |= p →wp(S1, wp(S2, r)),
which is |= p →wp(S1;S2, r) by the deﬁnition of wp for a compound statement.
We leave the proof of the soundness of the alternative rule as an exercise.
For the loop rule, by structural induction we assume that:
|= (p ∧B) →wp(S, p)
and show:
|= p →wp(W, p ∧¬B).
We will prove by numerical induction that for all k:
|= p →wp(Wk, p ∧¬B).
For k = 0, the proof of
|= wp(W0, p ∧¬B) = wp(W, p ∧¬B)
is the same as the proof of the base case in Lemma 15.38. The inductive step is
proved as follows:
1.
|= p →(¬B →(p ∧¬B))
PC
2.
|= p →(¬B →wp(skip, p ∧¬B))
Def. 15.35
3.
|= (p ∧B) →wp(S, p)
Structural ind. hyp.
4.
|= p →wp(Wk, p ∧¬B)
Numerical ind. hyp.
5.
|= (p ∧B) →wp(S, wp(Wk, p ∧¬B))
3, 4, Monotonicity
6.
|= (p ∧B) →wp(S;Wk, p ∧¬B)
5, Composition
7.
|= p →(B →wp(S;Wk, p ∧¬B))
6, PC
8.
|= p →wp(if (B) S;Wk else skip, p ∧¬B)
2, 7, Def. 15.26
9.
|= p →wp(Wk+1, p ∧¬B)
Def. 15.36
By inﬁnite disjunction:
|= p →
∞

k=0
wp(Wk, p ∧¬B),
and:
|= p →wp(W, p ∧¬B)
follows by Lemma 15.38.

292
15
Veriﬁcation of Sequential Programs
Theorem 15.40 (Completeness of H L ) If |= {p} S {q}, then ⊢HL {p} S {q}.
Proof We have to show that if |= p →wp(S, q), then ⊢HL {p}S{q}. The proof is by
structural induction on S. Note that p →wp(S, q) is just a formula of the domain,
so ⊢p →wp(S, q) follows by the domain axioms.
Case 1: Assignment statement x=t.
⊢{q{x ←t}} x=t {q}
is an axiom, so:
⊢{wp(x=t, q)} x=t {q}
by Deﬁnition 15.20. By assumption, ⊢p →wp(x=t, q), so by the consequence
rule ⊢{p} x=t {q}.
Case 2: Composition S1 S2.
By assumption:
|= p →wp(S1 S2, q)
which is equivalent to:
|= p →wp(S1, wp(S2, q))
by Deﬁnition 15.22, so by the inductive hypothesis:
⊢{p} S1 {wp(S2, q)}.
Obviously:
|= wp(S2, q) →wp(S2, q),
so again by the inductive hypothesis (with wp(S2, q) as p):
⊢{wp(S2, q)} S2 {q}.
An application of the composition rule gives ⊢{p} S1 S2 {q}.
Case 3: if-statement. Exercise.
Case 4: while-statement, W = while (B) S.
1.
|= wp(W, q) ∧B →wp(S;W, q)
Def. 15.28
2.
|= wp(W, q) ∧B →wp(S, wp(W, q))
Def. 15.22
3.
⊢{wp(W, q) ∧B} S {wp(W, q)}
Inductive hypothesis
4.
⊢{wp(W, q)} W {wp(W, q) ∧¬B}
Loop rule
5.
⊢(wp(W, q) ∧¬B) →q
Def. 15.28, Domain axiom
6.
⊢{wp(W, q)} W {q}
4, 5, Consequence rule
7.
⊢p →wp(W, q)
Assumption, domain axiom
8.
⊢{p} W {q}
Consequence rule

15.7
Summary
293
15.7 Summary
Computer programs are similar to logical formulas in that they are formally deﬁned
by syntax and semantics. Given a program and two correctness formulas—the pre-
condition and the postcondition—we aim to verify the program by proving: if the
input to the program satisﬁes the precondition, then the output of the program will
satisfy the postcondition. Ideally, we should perform program synthesis: start with
the pre- and postconditions and derive the program from these logical formulas.
The deductive system Hoare Logic H L is sound and relatively complete for
verifying sequential programs in a programming language that contains assignment
statements and the control structures if and while.
15.8 Further Reading
Gries (1981) is the classic textbook on the veriﬁcation of sequential programs; it
emphasizes program synthesis. Manna (1974) includes a chapter on program veri-
ﬁcation, including the veriﬁcation of programs written as ﬂowcharts (the formalism
originally used by Robert W. Floyd). The theory of program veriﬁcation can be
found in Apt et al. (2009), which also treats deductive veriﬁcation of concurrent
programs.
SPARK is a software system that supports the veriﬁcation of programs; an open-
source version can be obtained from http://libre.adacore.com/.
15.9 Exercises
15.1 What is wp(S, true) for any statement S?
15.2 Let S1 be x=x+y and S2 be y=x*y. What is wp(S1 S2, x < y)?
15.3 Prove |= wp(S, p ∧q) →wp(S, p) ∧wp(S, q), (the converse direction of
Theorem 15.30).
15.4 Prove that
wp(if (B) { S1 S3 } else { S2 S3 }, q) =
wp({if (B) S1 else S2} S3, q).
15.5 * Suppose that wp(S, q) is deﬁned as the weakest formula p that ensures
total correctness of S, that is, if S is started in a state in which p is true, then
it will terminate in a state in which q is true. Show that under this deﬁnition |=
¬wp(S, ¬q) ≡wp(S, q) and |= wp(S, p) ∨wp(S, q) ≡wp(S, p ∨q).

294
15
Veriﬁcation of Sequential Programs
15.6 Complete the proofs of the soundness and completeness of H L for the alter-
native rule (Theorems 15.39 and 15.40).
15.7 Prove the partial correctness of the following program.
{a ≥0}
x = 0; y = 1;
while (y <= a)
{
x = x + 1;
y = y + 2*x + 1;
}
{0 ≤x2 ≤a < (x + 1)2}
15.8 Prove the partial correctness of the following program.
{a > 0 ∧b > 0}
x = a; y = b;
while (x != y)
if (x > y)
x = x-y;
else
y = y-x;
{x = gcd(a,b)}
15.9 Prove the partial correctness of the following program.
{a > 0 ∧b > 0}
x = a; y = b;
while (x != y)
{
while (x > y) x = x-y;
while (y > x) y = y-x;
}
{x = gcd(a,b)}
15.10 Prove the partial correctness of the following program.
{a ≥0 ∧b ≥0}
x = a; y = b; z = 1;
while (y != 0)
if (y % 2 == 1) { /* y is odd */
y = y - 1;
z = x*z;
}
else {
x = x*x;
y = y / 2;
}
{z = ab}

References
295
15.11 Prove the partial correctness of the following program.
{a ≥2}
y = 2; x = a; z = true;
while (y < x)
if (x % y == 0)
z = false;
break;
}
else
y = y + 1;
{z ≡(a is prime)}
References
K.R. Apt, F.S. de Boer, and E.-R. Olderog. Veriﬁcation of Sequential and Concurrent Programs
(Third Edition). Springer, London, 2009.
D. Gries. The Science of Programming. Springer, New York, NY, 1981.
C.A.R. Hoare. An axiomatic basis for computer programming. Communications of the ACM,
12(10): 576–580, 583, 1969.
Z. Manna. Mathematical Theory of Computation. McGraw-Hill, New York, NY, 1974. Reprinted
by Dover, 2003.


Chapter 16
Veriﬁcation of Concurrent Programs
Veriﬁcation is routinely used when developing computer hardware and concurrent
programs. A sequential program can always be tested and retested, but the nonde-
terministic nature of hardware and concurrent programs limits the effectiveness of
testing as a method to demonstrate that the system is correct. Slight variations in
timing, perhaps caused by congestion on a network, mean that two executions of
the same program might give different results. Even if a bug is found by testing and
then ﬁxed, we have no way of knowing if the next test runs correctly because we
ﬁxed the bug or because the execution followed a different scenario, one in which
the bug cannot occur.
We start this chapter by showing how temporal logic can be used to verify the
correctness of a concurrent program deductively. Deductive veriﬁcation has proved
to be difﬁcult to apply in practice; in many cases, an alternate approach called model
checking is used. Model checking examines the reachable states in a program look-
ing for a state where the correctness property does not hold. If it searches all reach-
able states without ﬁnding an error, the correctness property holds. While model
checking is easier in practice than deductive veriﬁcation, it is difﬁcult to implement
efﬁciently. We will show how binary decision diagrams (Chap. 5) and SAT solvers
(Chap. 6) can be used to implement model checkers. The chapter concludes with a
short overview of CTL, a branching-time temporal logic that is an alternative to the
linear-time temporal logic that we studied so far. Traditionally, CTL has found wide
application in the veriﬁcation of (synchronous) hardware systems, while LTL was
used for (asynchronous) software systems.
This chapter is a survey only, demonstrating the various concepts and techniques
by examples. For details of the theory and practice of the veriﬁcation of concurrent
programs, see the list of references at the end of the chapter.
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7_16, © Springer-Verlag London 2012
297

298
16
Veriﬁcation of Concurrent Programs
16.1 Deﬁnition of Concurrent Programs
Our concurrent programs will be composed of the same statements used in the se-
quential programs of Chap. 15. A concurrent program is a set of sequential programs
together with a set of global variables.
Deﬁnition 16.1 A concurrent program is a set of processes {p1,p2,...,pn},
where each process is a program as deﬁned in Deﬁnition 15.1. The variables de-
clared in each process are its local variables; a local variable can be read and written
only by the process where it is declared. In addition, there may be global variables
that can be read and written by all of the processes.
Processes are also known as threads; in some contexts, the two terms have dif-
ferent meanings but the difference is not relevant here.
Example 16.2 The following concurrent program consists of two processes p and
q, each of which is a sequential program with two assignment statements (and an
additional label end). There is one global variable n initialized to 0 and no local
variables.
int n = 0
Process p
Process q
1: n = n + 1
1: n = n + 1
2: n = n + 1
2: n = n + 1
end:
end:
The state of a concurrent programs consists of the values of its variables (both
local and global), together with the location counters of its processes.
Deﬁnition 16.3 Let S be a program with processes {p1,p2,...,pn} and let the
statements of process i be labeled by Li = (Li
1,Li
2,...,Li
ki). Let (v1,v2,...,vm)
be the variables of S (both global and local). A state s of a computation of S is an
m + n-tuple:
(v1,v2,...,vm,l1,l2,...,ln),
where vj is the value of the jth variable in the state and li ∈Li is the value in the
location counter of the ith process.
Example 16.4 For the program of Example 16.2, there are 5 × 3 × 3 = 45 different
states, because the variable n can have the values 0, 1, 2, 3, 4 and there are three
labels for each process. These seems like quite a large number of states for such a
simple program, but many of the states (for example, (0,end,end)) will never occur
in any computation.

16.1
Deﬁnition of Concurrent Programs
299
Interleaving
A computation of a concurrent program is obtained by asynchronous interleaving
of atomic instructions.
Deﬁnition 16.5 A computation of a concurrent program S is a sequence of states.
In the initial state s0, vj contains the initial value of the variable vj and li is set to
the initial statement li
1 of the ith process. A transition from state s to state s′ is done
by selecting a process i and executing the statement labeled li. The components of
s′ are the same as those of s except:
• If the statement at li is an assignment statement v=e, then v′, the value of the
variable v in s′, is the value obtained by evaluating the expression e given the
values of the variables in s.
• li′, the value of the ith location counter in s′, is set using the rules for control
structures.
The computation is said to be obtained by interleaving statements from the pro-
cesses of the program.
Example 16.6 Although there are 45 possible states for the program of Exam-
ple 16.2, only a few of them will actually occur in any computation. Here are two
computations, where each triple is (n,lp,lq):
(0,1,1) →(1,2,1) →(2,end,1) →(3,end,2) →(4,end,end),
(0,1,1) →(1,2,1) →(2,2,2) →(3,end,2) →(4,end,end).
In the ﬁrst computation, process p executes its statements to termination and only
then does process q execute its statements. In the second computation, the interleav-
ing is obtained by alternating execution of statements from the two processes. The
result—the ﬁnal value of n—is the same in both cases.
Atomic Operations
In the deﬁnition of a computation, statements are interleaved, that is, each state-
ment is executed to completion before the execution of another statement (from the
same process or another process) is started. We say that the statements are atomic
operations. It is important to deﬁne the atomic operations of a system before you
can reason about it. Consider a system where an assignment statement is not ex-
ecuted atomically; instead, each separate access to memory is an atomic operation
and they can be interleaved. We demonstrate the effect of the speciﬁcation of atomic
operations by comparing the computations of the following two programs.

300
16
Veriﬁcation of Concurrent Programs
In the ﬁrst program, an assignment statement is an atomic operation:
int n = 0
Process p
Process q
1: n = n + 1
1: n = n + 1
end:
end:
In the second program, local variables are used to simulate a computer that eval-
uates expressions in a register; the value of n is loaded into the register and then
stored back into memory when the expression has been evaluated:
int n = 0
Process p
Process q
int temp = 0
int temp = 0
1: temp = n
1: temp = n
2: temp = temp + 1
2: temp = temp + 1
3: n = temp
3: n = temp
end:
end:
Clearly, the ﬁnal value of n in the ﬁrst program will be 2. For the second program,
if all the statements of p are executed before the statements of q, the same result will
be obtained. However, consider the following computation of the second program
obtained by interleaving one statement at a time from each process, where the 5-
tuple is (n,tempp,tempq,lp,lq):
(0,0,0,1,1) →(0,0,0,2,1) →(0,0,0,2,2) →(0,1,0,3,2) →(0,1,1,3,3) →
(1,1,1,end,3) →(1,1,1,end,end).
The result of this computation—n has the value 1—is not the same as the result
of the previous computation. Unlike a sequential program which has only one com-
putation, a concurrent program has many computations and they may have different
results, not all of which may be correct. Consider the correctness property expressed
in LTL as 3(n = 2), eventually the value of the variable n is 2. The formula is true
for some computations but not for all computations, so the correctness property does
not hold for the program.
16.2 Formalization of Correctness
We will use Peterson’s algorithm for solving the critical section problem for two
processes as the running example throughout this chapter.
Deﬁnition 16.7 The critical section problem for two processes is to design an al-
gorithm that for synchronizing two concurrent processes according to the following
speciﬁcation:

16.2
Formalization of Correctness
301
Each process consists of a critical section and a non-critical section. A process may stay
indeﬁnitely in its non-critical section, or—at any time—it may request to enter its critical
section. A process that has entered its critical section will eventually leave it.
The solution must satisfy the following two correctness properties:
• Mutual exclusion: It is forbidden for the two processes to be in their critical
sections simultaneously.
• Liveness: If a process attempts to enter its critical section, it will eventually suc-
ceed.
The problem is difﬁcult to solve. In a classic paper (Dijkstra, 1968), Dijkstra
went through a series of four attempts at solving the problem, each one of which
contained a different type of error, before arriving at a solution called Dekker’s
algorithm (see Ben-Ari (2006)). Here, we choose to work with Peterson’s algorithm,
which is much more concise than Dekker’s.
Peterson’s Algorithm
Here is Peterson’s algorithm (Peterson, 1981):
boolean wantp = false, wantq = false
int turn = 1
Process p
Process q
while (true) {
while (true) {
non-critical-section
non-critical-section
wantp = true
wantq = true
turn = 1
turn = 2
wait until
wait until
(!wantq or turn == 2)
(!wantp or turn == 1)
critical-section
critical-section
wantp = false
wantq = false
}
}
The statement:
wait until (!wantq or turn == 2)
is a more intuitive way of writing:
while (!(!wantq or turn == 2)) /* do nothing */
The intuitive explanation of Peterson’s algorithm is as follows. The variables
wantp and wantq are set to true by the processes to indicate that they are trying to
enter their critical sections and reset to false when they leave their critical sections.
A trying-process waits until the other process is neither trying to enter its critical
section nor is it in its critical section (!wantq or !wantp). Since the algorithm is
symmetric, the variable turn is used to break ties when both processes are trying

302
16
Veriﬁcation of Concurrent Programs
to enter their critical sections. A tie is broken in favor of the ﬁrst process which set
turn. Suppose that process p set turn to 1 and then process q set turn to 2. The
expression turn==2 will be true and allow process p to enter its critical section.
16.2.1 An Abbreviated Algorithm
Before proceeding to specifying and proving the correctness of Peterson’s algo-
rithm, we simplify it to reduce the number of states and transitions:
boolean wantp = false, wantq = false
int turn = 1
Process p
Process q
while (true) {
while (true) {
tryp: wantp = true; turn = 1
tryq: wantq = true; turn = 2
waitp: wait until
waitq: wait until
(!wantq or turn == 2)
(!wantp or turn == 1)
csp: wantp = false
csq: wantq = false
}
}
First, we omit the critical and non-critical section! This may seem strange because
the whole point of the algorithm is the execute a critical section, but we are not at all
interested in the contents of the critical section. It is simply a no-operation that we
are assured must terminate. A process will be considered to be ‘in’ its critical section
when its location counter is at the statement wantp=false or wantq=false. A
process will be considered to be in its non-critical section when its location counter
is at the statement wantp=true or wantq=true.
Second, the two assignments before the wait are written on one line and exe-
cuted as one atomic operation. It follows that we are allowing fewer computations
than in the original algorithm. We leave it as an exercise to show the correctness of
the algorithm without this simpliﬁcation.
Correctness Properties
The following two LTL formulas express the correctness of Peterson’s algorithm for
the critical section problem:
Mutual exclusion:
2¬ (csp ∧csq),
Liveness:
2(tryp →3csp) ∧2(tryq →3csq).
In these formulas, the labels of the statements of the algorithm are used as atomic
propositions meaning that the location counter of the corresponding process is at
that label. For example, in the state:
(true,false,2,csp,tryq),

16.3
Deductive Veriﬁcation of Concurrent Programs
303
wantp is true, wantq is false, the value of the variable turn is 2 and the processes
are at csp and tryq, respectively.
Mutual exclusion forbids (always false) a computation from including a state
where both processes are in their critical section, while liveness requires that (al-
ways) if a computation includes a state where a process is trying to enter its critical
section then (eventually) the computation will include a state where the process is
in its critical section.
16.3 Deductive Veriﬁcation of Concurrent Programs
Invariants
A safety property can be veriﬁed using the induction rule (Sect. 14.2):
⊢A →#A
⊢A →2A.
Assume that A is true in a state and prove that it holds in the next state; if A is also
true in the initial state, then 2A is true. In other words, we have to show that A is
an invariant (cf. Sect. 15.2).
If the formula that is supposed to be an invariant is an implication A →B, the
effort needed to prove the inductive step can often be signiﬁcantly reduced. By the
inductive hypothesis, A →B is assumed to be true and there are only two ways for
a true implication to become false. Either A and B are both true and B ‘suddenly’
becomes false while A remains true, or A and B are both false and A ‘suddenly’
becomes true while B remains false. By ‘suddenly’ we mean that a single transition
changes the truth value of a formula.
Lemma 16.8
(a) ⊢2((turn = 1) ∨(turn = 2)).
(b) ⊢2(wantp ↔(waitp ∨csp)).
(c) ⊢2(wantq ↔(waitq ∨csq)).
Proof The proof of (a) is trivial since turn is initialized to 1 and is only assigned
the values 1 and 2. We prove the forward direction of (b) and leave the other di-
rection of (b) as an exercise. Since the program is symmetric in p and q, the same
proof holds for (c).
The formula wantp →(waitp ∨csp) is true initially since wantp is initialized to
false and an implication is true if its antecedent is true regardless of the truth of its
consequent (although here the initial location counter of process p is set to tryp so
the consequent is also false).
Suppose that the formula is true. It can be falsiﬁed if both the antecedent and
consequent are true and the consequent suddenly becomes false, which can only
occur when the transition csp→tryp is taken. However, the assignment to wantp
at csp falsiﬁes the antecedent, so the formula remains true.

304
16
Veriﬁcation of Concurrent Programs
The formula could also be falsiﬁed if both the antecedent and consequent are
false and the antecedent suddenly becomes true. That can only occur when the tran-
sition tryp→waitp that assigns true to wantp is taken. However, the location
counter is changed so that waitp becomes true, so the consequent waitp ∨csp be-
comes true and the formula remains true.
The proof has been given in great detail, but you will soon learn that invariants
where the value of a variable is coordinated with the value of the location counter are
easily proved. By the properties of material implication, the truth of an invariant is
preserved by any transition such as waitp→csp that cannot make the antecedent
true nor the consequent false. Similarly, no transition of process q can affect the
truth value of the formula.
Mutual Exclusion
To prove that the mutual exclusion property holds for Peterson’s algorithm, we need
to prove that ¬ (csp ∧csq) is an invariant. Unfortunately, we cannot prove that
directly; instead, we show that two other formulas are invariant and then deduce the
mutual exclusion property from them.
Lemma 16.9 The following formulas are invariant in Peterson’s algorithm:
(waitp ∧csq) →(wantq ∧turn = 1),
(csp ∧waitq) →(wantp ∧turn = 2).
Theorem 16.10 In Peterson’s algorithm, ¬ (csp ∧csq) is an invariant.
Proof The formula is true initially.
The deﬁnition of a computation of a concurrent program is by interleaving, where
only one statement from one process is executed at a time. Therefore, either process
q was already in its critical section when process p entered its critical section, or
p was in its critical section when q entered. By the symmetry of the algorithm, it
sufﬁces to consider the ﬁrst possibility.
To falsify the formula ¬ (csp ∧csq), the computation must execute the transition
waitp→csp while waitp ∧csq is true. By Lemma 16.9, this implies that wantq ∧
turn = 1 is true. We have the following chain of logical equivalences:
wantq ∧turn = 1
≡
¬¬(wantq ∧turn = 1)
≡
¬(¬wantq ∨¬(turn = 1)) ≡
¬(¬wantq ∨(turn = 2)).
The last equivalence used the invariant in Lemma 16.8(a).
However, the transition waitp→csp is enabled only if ¬wantq ∨turn = 2 is
true, but we have just shown that it is false. It follows that ¬ (csp ∧csq) can never
become true.

16.3
Deductive Veriﬁcation of Concurrent Programs
305
Proof of Lemma 16.9 By symmetry it sufﬁces to prove the ﬁrst formula.
Clearly, the formula is true initially since the location counters are initialized to
tryp and tryq.
Suppose that the antecedent of (waitp ∧csq) →(wantq ∧turn = 1) becomes
true because the transition tryp→waitp is taken in a state where csq is true. By
Lemma 16.8(c), wantq is true and the transition assigns 1 to turn, so the consequent
remains or becomes true.
Suppose now that the antecedent of (waitp ∧csq) →(wantq ∧turn = 1) be-
comes true because the transition waitq→csq is taken in a state where waitp is
true. By Lemma 16.8(c), wantq is true, so we have to show that turn = 1. But, by
Lemma 16.8(b), waitp implies that wantp is true; therefore, the only way that the
transition waitq→csq could have been taken is if turn = 1, so the consequent
remains or becomes true.
It remains to check the possibility that the consequent becomes false while the
antecedent remains or becomes true. But the only transitions that change the value
of the consequent are tryq→waitq and csq→tryq, both of which falsify csq
in the antecedent.
Progress
The axiom system H L for proving correctness of sequential programs provides
the semantics of the execution of statements in a program (Deﬁnition 15.5). It de-
ﬁnes, for example, the effect of an assignment statement—in the new state, the value
of the assigned variable is the value of the expression—but it does not actually re-
quire that the assignment statement will ever be executed. In order to prove the
liveness of a program like Peterson’s algorithm, we need to add progress axioms for
each type of statement.
In this section, we assume that the interleaving is fair (Deﬁnition 16.20). For a
detailed discussion of this concept see Ben-Ari (2006, Sect. 2.7).
Deﬁnition 16.11 Here are the progress axioms for each statement:
Statement
Progress axioms
li:
v = expression;
⊢li →3li+1
li+1:
li:
if (B)
⊢li →3(lt ∨lf )
lt:
S1;
⊢(li ∧2B) →3lt
else
lf:
S2;
⊢(li ∧2¬B) →3lf
li:
while (B)
⊢li →3(lt ∨lf )
lt:
S1;
⊢(li ∧2B) →3lt
lf:
⊢(li ∧2¬B) →3lf

306
16
Veriﬁcation of Concurrent Programs
An assignment statement will be unconditionally executed eventually. However,
for control statements with alternatives (if- and while-statement), all we can say
for sure is that it will eventually be executed and one of the two alternatives taken
⊢li →3(lt ∨lf ), but without more information we cannot know which branch
will be taken. ⊢(li ∧B) →3lt is not acceptable as an axiom because by the time
that this transition is taken, another process could have modiﬁed a global variable
falsifying B. Only if B is held true or false indeﬁnitely can we prove which branch
will be taken.
For Peterson’s algorithm, we do not assume progress at the statements tryp and
tryq; this models the speciﬁcation that a process need not leave its non-critical
section.
Liveness
We can now prove the liveness of Peterson’s algorithm. By symmetry, it is sufﬁcient
to prove liveness for one process; for process p, the correctness formula is waitp →
3csp. To prove the formula, we assume that it is not true (waitp ∧2¬csp) and
deduce a contradiction.
Lemma 16.12 ⊢waitp ∧2¬csp →23(wantq ∧last ̸= 2).
Proof Recall that the statement at waitp:
waitp: wait until (!wantq or turn == 2)
is an abbreviation for the while-statement:
while (!(!wantq or turn == 2)) /* do nothing */
By the progress axiom:
⊢waitp ∧2¬B →3csp,
where B is the expression in the while-loop. By propositional reasoning and du-
ality, we have:
⊢waitp ∧2¬csp →3B,
which is:
⊢waitp ∧2¬csp →3(wantq ∧turn ̸= 2).
By generalization:
⊢2(waitp ∧2¬csp) →23(wantq ∧turn ̸= 2),
and we leave it as an exercise to show that:
⊢waitp ∧2¬csp →2(waitp ∧2¬csp).

16.4
Programs as Automata
307
Lemma 16.13 ⊢32¬wantq ∨3(turn = 2).
Proof If 3(turn = 2), the formula is true, so we ask what can happen if it is not true.
This is done by cases on the location counter of process q. If the location counter
is at tryq and the computation never leaves there (because it is simulating a non-
critical section), then 2¬wantq (Lemma 16.8(c)). If the computation leaves tryq,
then by the progress axiom, eventually the assignment statement turn=2 must be
executed. If the location counter is at csq, by progress it reaches tryq and we
have just shown what happens in that case. Finally, if the computation is at waitq
and turn = 2 is never true, then turn = 1 is always true (Lemma 16.8(a)) and by the
progress axiom, the computation proceeds to csq and we have already shown what
happens in that case.
Lemma 16.14 ⊢waitp ∧2¬csp ∧3(turn = 2) →32(turn = 2).
Proof The only way that turn = 2 could be falsiﬁed is for process p to execute the
assignment at tryp, assigning 1 to turn, but waitp ∧2¬csp in the antecedent of
the formula implies 2waitp.
Theorem 16.15 ⊢waitp →3csp.
Proof Assume to the contrary that ⊢waitp ∧2¬csp. By Lemmas 16.13 and 16.14,
we conclude that ⊢32¬wantq ∨32(turn = 2). But:
⊢32A ∨32B →32(A ∨B)
is a theorem of LTL, so:
⊢32¬wantq ∨32(turn = 2) →32(¬wantq ∨(turn = 2)).
Therefore, we have:
⊢waitp ∧2¬csp →32(¬wantq ∨(turn = 2)),
which contradicts Lemma 16.12.
16.4 Programs as Automata
There is a different approach to the veriﬁcation of the correctness of a program:
generate all possible computations and check that the correctness property holds for
each of them. Of course, this is possible only if there are a ﬁnite number of states
so that each computation is ﬁnite or ﬁnitely presented. For the program for integer
square root, we could prove its correctness this way for any speciﬁc value of a,
but we could not prove it in general for all values of a. However, many concurrent

308
16
Veriﬁcation of Concurrent Programs
algorithms have a ﬁnite number of states: the synchronization achieved by Peter-
son’s algorithm needs only three variables with two values each and two processes
with three possible values for their location counters. The critical and non-critical
sections might contain sophisticated mathematical computations, but to prove the
correctness of the synchronization we do not need to know these details.
This approach to veriﬁcation is called model checking. A concurrent system is
represented by an abstract ﬁnite model that ignores details of the computation; then,
the correctness of this model is veriﬁed. A second reason for the terminology is tech-
nical: a correctness property is expressed as a formula (usually in temporal logic)
and we wish to show that the program is a model of the formula, that is, an interpre-
tation in which the formula is true.
The remainder of this chapter provides an overview of model checking. We will
continue to use Peterson’s algorithm as the running example.
16.4.1 Modeling Concurrent Programs as Automata
Concurrent programs can be modeled as ﬁnite automata. The abbreviated version of
Peterson’s algorithm (Sect. 16.2.1) can be represented as a pair of ﬁnite automata,
one for each process (Fig. 16.1).
Each value of the location counter is a state of one of the automata, while each
transition is labeled with the Boolean condition that enables it to be taken or with
the assignment statements that change the values of the variables.
Fig. 16.1 Finite automata for Peterson’s algorithm

16.4
Programs as Automata
309
The automata for the individual processes do not deﬁne the entire concurrent
program. We must combine these automata into one automaton. This is done by
constructing an automaton that is the asynchronous product of the automata for each
process. The states are deﬁned as the Cartesian product of the states of the automata
for the individual processes. There is a transition corresponding to each transition of
the individual automata. Because concurrent computation is deﬁned by interleaving
of atomic operations, a transition represents the execution of one atomic operation
by one process.
The following diagram shows the beginning of the construction of the product
automaton for Peterson’s algorithm:
The initial state is one in which both processes are at their try state. From this
initial state, a transition may be taken from either the automaton for process p or
the one for process q; these lead to the states (waitp,tryq) and (tryp,waitq),
respectively.
16.4.2 The State Space
The concept of a state of the computation of a concurrent program was given in
Deﬁnition 16.3. For Peterson’s algorithm, the number of possible states is ﬁnite.
There are two location counters each of which can have one of three values. The two
Boolean variables obviously have two possible values each, while the variable turn
can take only two values by Lemma 16.8(a). Therefore, there are 3×3×2×2×2 =
72 possible states in the algorithm.
Clearly, not all these states will occur in any computation. By Lemma 16.8(b–c),
the values of wantp and wantq are fully determined by the location counters of
the programs. For example, in no state is the location counter of process p at tryp
and the value of wantp true. Therefore, the number of states is at most 3·3·2 = 18,
since only the variable turn can have different values for the same pair of values
of the location counters.
Deﬁnition 16.16 The reachable states of a concurrent program are the states that
can actually occur in a computation. The state space of the program is a directed
graph: each reachable state is a node and there is an edge from state s1 to state
s2 if some transition of the program which is enabled in s1 moves the state of the
computation to s2.

310
16
Veriﬁcation of Concurrent Programs
The state space can be generated algorithmically by traversing the product au-
tomaton. The initial state of the state space is the initial state of the automaton
together with the initial values of the variables. For each node already constructed,
consider each transition of the automaton from this state in turn and create new
nodes in the state space; if the new node already exists, the edge will point to the
existing node.
Be careful to distinguish between the automaton which is the program and the
state space which describes the computation. In practice, the automaton is usually
rather small, but the state space can be extremely large because each variable multi-
plies the number of possible states by the range of its values.
In Peterson’s algorithm, the initial value of turn is 1, so the initial state in the
state space is (tryp,tryq,1). For conciseness, we do not explicitly write the values
of wantp and wantq that can be determined from the location counters. There are
two transitions from this state, so we create two new nodes (waitp,tryq,1) and
(tryp,waitq,2). Continuing this way, we obtain the state space shown in Fig. 16.2.
The left arrow out of each state points to the state obtained by taking a transition
from process p, while the right arrow points to the state obtained by taking a transi-
tion from process q. Note that taking the p transition in state 4 results in a state that
is the same as state 1 so we don’t create a new state; instead, the left edge from 4
points to state 1.
Fig. 16.2 State space for Peterson’s algorithm

16.5
Model Checking of Invariance Properties
311
16.5 Model Checking of Invariance Properties
We now consider the second meaning of the term model: Is the state space a model
of a correctness property? Consider the correctness property for mutual exclusion in
Peterson’s algorithm A = 2¬(csp ∧csq). Since the state space in Fig. 16.2 repre-
sents all the reachable states and all the transitions between them, any interpretation
for A must be an inﬁnite path in this directed graph. A quick inspection of the
graph shows that all of the ten reachable states satisfy the formula ¬(csp ∧csq);
therefore, for any interpretation (that is, for any path constructed from these states),
2¬(csp ∧csq) is true.
We have proved that the mutual exclusion property holds for Peterson’s algorithm
and have done so purely mechanically. Once we have written the program and the
correctness property, there are algorithms to perform the rest of the proof: compile
the program to a set of automata, construct the product automaton, generate the state
space and check the truth of the formula expressing the correctness property at each
state.
In this section we show how to verify invariance properties; Sect. 16.6 describes
the extension of the algorithms to verify liveness properties.
16.5.1 Algorithms for Searching the State Space
Algorithms for searching a directed graph are described in any textbook on data
structures. There are two approaches: breadth-ﬁrst search (BFS), where all the chil-
dren of a node are visited before searching deeper in the graph, and depth-ﬁrst search
(DFS), where as soon as a node is visited, the search continues with its children.
Searching the state space for Peterson’s algorithm (Fig. 16.2) proceeds as fol-
lows, where the numbers in parentheses indicate nodes that have already been vis-
ited, so the search backtracks to try another child or backtracks to a parent when all
children have been searched:
Breadth-ﬁrst: 1, 2, 3, 4, 5, 6, 7, (1), 8, (8), (5), (6), 9, (9), 10, (3), (8), (9), (2),
(2), (3).
Depth-ﬁrst: 1, 2, 4, (1), 8, 3, 6, (6), 9, (9), (2), 7, (9), 10, (2), (3), (8), 5, (5).
Normally, DFS is preferred because the algorithm need only store a stack of the
nodes visited from the root to the current node. In BFS, the algorithm has to store
an indication of which child has been visited for all nodes at the current depth, so
much more memory is required. BFS is preferred if you believe that there is a state
relatively close to the root of the graph that does not satisfy the correctness property.
In that case, DFS is likely to search deep within the graph without ﬁnding such a
state.
The state space generates inﬁnite paths, so they can be ﬁnitely represented only as
directed graphs, not trees. This means that nodes will be revisited and the algorithm
must avoid commencing a new search from these nodes. For example, in the DFS

312
16
Veriﬁcation of Concurrent Programs
of Peterson’s algorithm, node 2 is a child of node 9, but we obviously don’t want
to search again the subgraph rooted at node 2. The node 2 is not on the stack of
the DFS (which is 1, 3, 6, 9), so an additional data structure must be maintained to
store the set of all the nodes that have been visited. When a new node is generated,
it is checked to see if it has been visited before; if so, the search skips the node and
moves on to the next one. The most appropriate data structure is a hash table because
of its efﬁciency. The memory available to store the hash table and the quality of the
hashing function signiﬁcantly affect the practicality of model checking.
16.5.2 On-the-Fly Searching
Here is an attempt to solve the critical section problem:
boolean wantp = false, wantq = false
Process p
Process q
while (true) {
while (true) {
waitp: wait until !wantq
waitq: wait until !wantp
tryp:
wantp = true
tryq:
wantq = true
csp:
wantp = false
csq:
wantq = false
}
}
This is Dijkstra’s Second Attempt; see Ben-Ari (2006, Sect. 3.6).
The state space for this algorithm is shown in Fig. 16.3, where we have explicitly
written the values of the variables wantp and wantq although they can be inferred
from the location counters. Clearly, ¬(csp∧csq) does not hold in state 10 and there
are (many) computations starting in the initial state that include this state. Therefore,
2¬(csp∧csq) does not hold so this algorithm is not a solution to the critical section
problem.
A DFS of the state space would proceed as follows:
1,2,4,(1),7,3,5,(7),8,10.
The search terminates at state 10 because the formula ¬(csp ∧csq) is falsiﬁed.
However, by generating the entire state space, we have wasted time and memory
because the DFS ﬁnds the error without visiting all the states. Here state 6 is not
visited.
This is certainly a trivial example, but in the veriﬁcation of a real program, the
search is likely to ﬁnd an error without visiting millions of states. Of course, if the
program is correct, the search will have to visit all the nodes of the state space, but
(unfortunately) we tend to write many incorrect programs before we write a correct
program. Therefore, it makes sense to optimize the generation of the state space and
the search of the space so that errors can be found more efﬁciently.

16.5
Model Checking of Invariance Properties
313
Fig. 16.3 State space for the Second Attempt
An efﬁcient algorithm for model checking is to generate the state space incre-
mentally and to check the correctness property on-the-ﬂy:
while (true) {
generate a new state;
if (there are no more states) break;
evaluate the correctness property in the new state;
if (the correctness property fails to hold) break;
}
Since each new state is checked immediately after it is generated, the algorithm
terminates as soon as an error is detected. Furthermore, the states on the DFS stack
deﬁne a computation from the initial state that is in error:
1,2,4,7,3,5,8,10.
This example shows that computations found by DFS are very often not the shortest
ones with a given property. Clearly, 1, 2, 5, 7, 10 and 1, 3, 6, 8, 10 are shorter paths to
the error state, and the ﬁrst one will be found by a breadth-ﬁrst search. Nevertheless,
DFS is usually preferred because it needs much less memory.

314
16
Veriﬁcation of Concurrent Programs
16.6 Model Checking of Liveness Properties
Safety properties that are deﬁned by the values of a state are easy to check because
they can be evaluated locally. Given a correctness property like 2¬(csp ∧csq),
the formula ¬(csp ∧csq) can be evaluated in an individual state. Since all the
states generated by a search are by deﬁnition reachable, once a state is found where
¬(csp∧csq) does not hold, it is easy to construct a path that is an interpretation that
falsiﬁes 2¬(csp ∧csq). Liveness properties, however, are more difﬁcult to prove
because no single state can falsify 23csp.
Before showing how to check liveness properties, we need to express the model
checking algorithm in a slightly different form. Recall that a correctness property
like A = 2¬(csp ∧csq) holds iff it is true in all computations. Therefore, the prop-
erty does not hold iff there exists a computation is which A is false. Using negation,
we have: the correctness property does not hold iff there exists a computation is
which ¬A is true, where:
¬A ≡¬2¬(csp ∧csq) ≡3(csp ∧csq).
The model checking algorithm ‘succeeds’ if it ﬁnds a computation where ¬A is
true; it succeeds by ﬁnding a counterexample proving that the program is incorrect.
Model checking can be understood as a ‘bet’ between you and the model checker:
the model checker wins and you lose if it can ﬁnd a model for the negation of the
correctness property.
The liveness property of Peterson’s algorithm is expressed by the correctness
formula 2(waitp →3csp), but let us start with the simpler property A = waitp →
3csp. Its negation is:
¬(waitp →3csp) ≡waitp ∧¬3csp ≡waitp ∧2¬csp.
A computation π = s0,s1,... satisﬁes ¬A if waitp is true in its initial state s0 and
¬csp holds in all states si, i ≥0. Therefore, to show that an interpretation satisﬁes
¬A, the negation of the correctness property, and thus falsiﬁes A, the correctness
property itself, we have to produce an entire computation and not just a state. Based
upon the discussion in Sect. 13.5.5, the computation will be deﬁned by a maximal
strongly connected component (MSCC). For example, if the state space contained a
subgraph of the following form:
then this subgraph would deﬁne a computation that satisﬁes waitp ∧2¬csp and
thus falsiﬁes the liveness property waitp →3csp.

16.7
Expressing an LTL Formula as an Automaton
315
For the full liveness property, the negation is:
¬2(waitp →3csp) ≡3(waitp ∧¬3csp) ≡3(waitp ∧2¬csp).
This would be satisﬁed by a computation deﬁned by the following subgraph:
In the computation π = s0,s1,s2,s3,s2,s3,... , tryp is true in state s0, so π0 ̸|=
waitp ∧2¬csp, but π1 |= waitp ∧2¬csp, so π |= 3(waitp ∧2¬csp).
The states on the stack of a depth ﬁrst search form a path. If the construction ever
tries to generate a state that already exists higher up on the stack, the transition to this
node deﬁnes a ﬁnitely-presented inﬁnite computation like the ones shown above.
What we need is a way of checking if such a path is a model of the negation of the
correctness property. If so, it falsiﬁes the property and the path is a counterexample
to the correctness of the program. Of course, we could generate the entire state
space and then check each distinct path to see if it model, but it is more efﬁcient if
the checking can be done on-the-ﬂy as we did for safety properties. The key is to
transform an LTL formula into an automaton whose computations can be generated
at the same time as those of the program.
16.7 Expressing an LTL Formula as an Automaton
An LTL formula can be algorithmically transformed into an automaton that accepts
an input if and only if the input represents a computation that satisﬁes the LTL
formula. The automaton is a nondeterministic Büchi automaton (NBA), which is the
same as a nondeterministic ﬁnite automaton (NFA) except that it reads an inﬁnite
string as its input and its deﬁnition of acceptance is changed accordingly. An NFA
accepts an input string iff the state reached when the reading of the (ﬁnite) input is
completed is an accepting state. Since the input to an NBA is inﬁnite, the deﬁnition
of acceptance is modiﬁed to:
Deﬁnition 16.17 A nondeterministic Büchi automaton accepts an inﬁnite input
string iff the computation that reads the string is in an accepting state inﬁnitely often.
To demonstrate NBA’s, we construct one NBA corresponding to the LTL for-
mula 2A ≡2(waitp →3csp) that expresses the liveness property of Peterson’s
algorithm, followed by an NBA corresponding to the negation of the formula. The
second NBA will be used in the following section to show that the liveness property
holds.

316
16
Veriﬁcation of Concurrent Programs
Example 16.18 The formula A can be transformed using the inductive decomposi-
tion of 3:
waitp →3csp ≡¬waitp ∨(csp ∨#3csp) ≡(¬waitp ∨csp) ∨#3csp.
2A is true as long as ¬waitp ∨csp holds, but if ¬waitp ∨csp ever becomes false,
then tomorrow 3csp must be true. The NBA constructed from this analysis is:
Since state s0 is an accepting state, if the computation never executes the state-
ment at tryp to get to waitp, the automaton is always in an accepting state and
the formula holds. Otherwise (expressed as true), if the computation chooses to ex-
ecute tryp and gets to waitp, ¬waitp ∨csp becomes false (state s1). The only
way to (re-)enter the accepting state s0 is if eventually the transition to s0 is taken
because csp true, as required by 3csp. If not (expressed as true), the computation
is not accepted since s1 is not an accepting state. The accepting computations of
this NBA are precisely those in which the process decides not to enter its critical
section or those in which every such attempt is eventually followed by a return of
the computation to the accepting state s0.
Example 16.19 Let us now consider the NBA for:
¬2A ≡¬2(waitp →3csp) ≡3(waitp ∧2¬csp),
the negation of the liveness formula. The intuitive meaning of the formula is that the
computation can do anything (expressed as true), but it may nondeterministically
decide to enter a state where waitp is true and csp is and remains false from then on.
Such a computation falsiﬁes the liveness property. The corresponding NBA is:
In state s1, if csp ever becomes true, there is no transition from the state; as with
NFA, an automaton that cannot continue with its computation is considered to have
rejected its input.

16.8
Model Checking Using the Synchronous Automaton
317
16.8 Model Checking Using the Synchronous Automaton
On-the-ﬂy model checking for an invariance property (Sect. 16.5.2) simply evalu-
ates the correctness property as each new state is generated:
while (true) {
generate a new state;
if (there are no more states) break;
evaluate the correctness property in the new state;
if (the correctness property fails to hold) break;
}
When checking a liveness property (or a safety property expressed in LTL as
2A), every step of the program automaton—the asynchronous product automaton
of the processes—is immediately followed by a step of the NBA corresponding to
the LTL formula expressing the negation of the correctness property. The product
of the asynchronous automaton and the NBA is called a synchronous automaton
since the steps of the two automata are synchronized. The model checking algorithm
becomes:
while (true) {
generate a new state of the program automaton;
if (there are no more states) break;
generate a new state of the NBA;
if (the correctness property fails to hold) break;
}
How does the algorithm decide if the correctness property fails to hold? The
intuitive meaning of the NBA for the negation of the correctness property is
that it should never accept an input string. For example, in Peterson’s algorithm,
3(waitp ∧2¬csp) should never hold in any computation. Therefore, if the NBA
corresponding to the formula accepts a computation, the search should terminate
because it deﬁnes a counterexample, a model for the negation of the correctness
property of the program.
Acceptance by the NBA is checked on-the-ﬂy: whenever a future formula is en-
countered in a state, a nested depth-ﬁrst search is initiated. If a state is generated
that already exists on the stack, it is easy to extract an interpretation that falsiﬁes
the formula. For the liveness of Peterson’s algorithm, the correctness property is
2(waitp →3csp) and its negation is 3(waitp ∧2¬csp). In any state where waitp
holds, a nested DFS is commenced and continued as long as ¬csp holds. If the
search reaches a state on the stack, a model for the negation of the correctness prop-
erty has been found and the model checker wins the bet. The details of a nested
DFS are beyond the scope of this book and the reader is referred to Baier and Ka-
toen (2008, Sect. 4.4) and Holzmann (2004, Chap. 8).
Let us trace the model checking algorithm for the liveness of Peterson’s algo-
rithm. The state space is shown again in Fig. 16.4. Starting from the initial state 1,
state 2 is reached and 3(waitp ∧2¬csp) will be true, provided that we can ﬁnd
a reachable MSCC where ¬csp holds in all its states. A nested DFS is initiated.

318
16
Veriﬁcation of Concurrent Programs
Fig. 16.4 Model checking the liveness of Peterson’s algorithm
Clearly, states 4 and 8 cannot be part of the MSCC since ¬csp is false in those
states. However, the computation can continue:
1,2,5,5,5,...,
and the state 5 with its self-loop forms an MSCC such that ¬csp is false in all its
states!
This is strange because it is a counterexample to the liveness of Peterson’s algo-
rithm which we have already proved deductively. The problem is that this computa-
tion is not fair.
Deﬁnition 16.20 A computation is (weakly) fair if a transition that is always en-
abled is eventually executed in the computation.
The statement:
wait until (!wantq or turn == 2)
is always enabled because turn = 2, but it is never taken. Therefore, we reject this
counterexample.
Continuing the DFS, we encounter two more states 6 and 9 where waitp is true.
We leave it as an exercise to show that the nested DFS will ﬁnd computations in
which ¬csp holds in all states, but that these computations are also unfair. There-
fore, the liveness holds for Peterson’s algorithm.

16.9
Branching-Time Temporal Logic *
319
16.9 Branching-Time Temporal Logic *
In linear temporal logic, there is an implicit universal quantiﬁcation over the
computations—the paths in the state space. The formula expressing the liveness
of Peterson’s algorithm 2(waitp →3csp) must be true for all computations. In
branching-time temporal logic, universal and existential quantiﬁers are used as ex-
plicit preﬁxes to the temporal operators. In this section, we give an overview of the
most widely used branching-time logic called Computational Tree Logic (CTL).
16.9.1 The Syntax and Semantics of CTL
The word tree in the name of CTL emphasizes that rather than choosing a single
path as an interpretation (see Deﬁnition 13.28 for LTL), a formula is interpreted as
true or false in a state that is the root of tree of possible computations. Figure 16.5
shows the state space of Peterson’s algorithm unrolled into a tree. Four levels of the
tree are shown with the labels of the states of the lowest level abbreviated to save
space.
Here are the temporal operators in CTL with their intended meaning:
• s |= ∀2A: A is true in all states of all paths rooted at s.
• s |= ∀3A: A is true in some state of all paths rooted at s.
• s |= ∀#A: A is true in all the children of s.
• s |= ∃2A: A is true in all states of some path rooted at s.
• s |= ∃3A: A is true in some state of some path rooted at s.
• s |= ∃#A: A is true in some child of s.
Fig. 16.5 The state space of Peterson’s algorithm as a tree

320
16
Veriﬁcation of Concurrent Programs
We have made two changes to simplify the presentation: As in LTL, the formal
deﬁnition of CTL is based on the binary operator U (Sect. 13.6), but we limit the
discussion to the unary operators. The syntax we use is based on the LTL syntax and
is different from CTL syntax which uses capital letters: AG, AF , AX, EG, EF ,
EX for the operators in the list above and AU, EU for the binary operators.
Example 16.21 Let si be the state labeled by i in Fig. 16.5. It is easy to check that
∃#(turn = 1) is true in s1 and ∀#(turn = 2) is true in s5 just by examining the
next states. The formula ∃2waitp is true is s5 and represents the unfair computation
where process p is never given a chance to execute. Similarly, ∀3(turn = 1) is not
true in s5 by considering its negation and using duality:
¬∀3(turn = 1) ≡∃2¬(turn = 1) ≡∃2(turn = 2).
The unfair computation is a computation whose states all satisfy turn = 2. Finally,
the operator ∀2 can be used to express the correctness properties of Peterson’s al-
gorithm:
∀2¬(csp ∧csq),
∀2(waitp →∀3csp).
16.9.2 Model Checking in CTL
Model checking in CTL is based upon the following decomposition of the temporal
operators:
∀2A ≡A ∧∀#∀2A,
∀3A ≡A ∨∀#∀3A,
∃2A ≡A ∧∃#∃2A,
∃3A ≡A ∨∃#∃3A.
The model checking algorithm is rather different from that of LTL. The truth of
a formula is checked bottom-up from its subformulas.
Example 16.22 We want to show that the formula ∀3csp expressing the liveness
of Peterson’s algorithm is true in the interpretation shown in Fig. 16.5. By its de-
composition A ∨∀#∀3A, it is clearly true in the states s4 and s8 where csp is true
(these states are marked with thick borders in Fig. 16.6). Let S0 = {s4,s8} be the set
of states that we know satisfy ∀3A. By the decomposition, let us create S1 as the
union of S0 and all states for which ∀#∀3A holds, that is, all states from which a
single transition leads to a state in S0. The set of predecessors of s4 is {s2} and the set
of predecessors of s8 is {s4,s5}. So S1 = S0 ∪{s2} ∪{s4,s5} = {s2,s4,s5,s8}, where
the added states are marked with dashed borders. Continuing with the predecessors
of S1, we obtain S2 = {s1,s2,s4,s5,s8,s9,s10} (where the added states are marked

16.9
Branching-Time Temporal Logic *
321
Fig. 16.6 CTL model checking of Peterson’s algorithm
with thin borders). Two more steps of the algorithm will add the remaining states to
S3 and then S4, proving that ∀3csp holds in all states.
Example 16.23 Consider now the formula ∃2waitp. In this case, the algorithm
works top-down by removing states where it does not hold. Initially, S0, the set
of states where the formula is true, is tentatively assumed to be the set of all states.
By the decomposition:
∃2wantp ≡wantp ∧∃#∃2wantp,
wantp must be true in a state for ∃2waitp to be true; therefore, remove from S0
all states where wantp does not hold. The states that remain are S1 = {s2,s5,s6,s9}.
Additionally, ∃#∃2wantp must be true in a state for ∃2waitp to be true. Repeatedly,
remove from the set any state that does not have some successor (∃#) already in the
set. This causes no change to S1.
Check that from all of the states in S1, there exists an inﬁnite path in all of whose
states waitp is true.

322
16
Veriﬁcation of Concurrent Programs
16.10 Symbolic Model Checking *
In symbolic model checking, the states and transitions are not represented explic-
itly; instead, they are encoded as formulas in propositional logic. Model checking
algorithms use efﬁcient representations like BDDs to manipulate these formulas.
A state in the state space of Peterson’s algorithm can be represented as a propo-
sitional formula using ﬁve atomic propositions. There are three locations in each
process, so two bits for each process can represent these values {p0,p1,q0,q1}. Let
us encode the locations as follows:
tryp
p0 ∧p1
tryq
q0 ∧q1
waitp
¬p0 ∧p1
waitq
¬q0 ∧q1
csp
p0 ∧¬p1
csq
q0 ∧¬q1
The variable turn can take two values so one bit is sufﬁcient. The atomic propo-
sition t will encode turn: true for turn = 1 and false for turn = 2. As usual, we
don’t bother to represent the variables wantp and wantq since their values can be
deduced from the location counters.
The initial state of the state space is encoded by the formula:
p0 ∧p1 ∧q0 ∧q1 ∧t,
and, for example, the state s8 = (csp,waitq,2) of Fig. 16.2 is encoded by:
p0 ∧¬p1 ∧¬q0 ∧q1 ∧¬t.
To encode the transitions, we need another set of atomic propositions: the original
set will encode the state before the transition and the new set (denoted by primes)
will encode the state after the transition. The encoding of the transition from s5 =
(waitp,waitq,2) to s8 is given by the formula:
(¬p0 ∧p1 ∧¬q0 ∧q1 ∧¬t) ∧(p′
0 ∧¬p′
1 ∧¬q′
0 ∧q′
1 ∧¬t′).
There are two ways of proceeding from here. One is to encode the formulas us-
ing BDDs. CTL model checking, described in the previous chapter, works on sets
of states. A set of states is represented by the disjunction of the formulas repre-
senting each state. The algorithms on BDDs can be used to compute the formulas
corresponding to new sets of states: union, predecessor, and so on.
The other approach to symbolic model checking is called bounded model check-
ing. Recall that a formula in temporal logic has the ﬁnite model property (Corol-
lary 13.67): if a formula is satisﬁable then it is satisﬁed in a ﬁnitely-presented model.
For an LTL formula, we showed that a model consists of MSCCs that are reachable
from the initial state. In fact, by unwinding the MSCCs, we can always ﬁnd a model
that consists of a single cycle reachable from the initial state (cf. Sect. 16.6):

16.11
Summary
323
In bounded model checking, a maximum size k for the model is guessed. The be-
havior of the program and the negation of a correctness property are expressed as a
propositional formula obtained by encoding each state that can appear at distance i
from the initial state 0 ≤i ≤k. This formula is the input to a SAT solver (Chap. 6);
if a satisfying interpretation is found, then there is a computation that satisﬁes the
negation of the correctness property is true and the program is not correct.
16.11 Summary
The computation of a concurrent program can be deﬁned as the interleaving of the
atomic operations of its processes, where each process is a sequential program.
Since a concurrent program must be correct for every possible computation, it is
not possible to verify or debug programs by testing.
Correctness properties of concurrent programs can be expressed in linear tem-
poral logic. There are two types of properties: safety properties that require that
something bad never happens and liveness properties that require that something
good eventually happen. A safety property is proved by showing inductively that
it is an invariant. Proving a liveness property is more difﬁcult and requires that the
progress of a program be speciﬁed.
Model checking is an alternative to deductive systems for verifying the correct-
ness of concurrent programs. A model checker veriﬁes that a concurrent program
is correct with respect to a correctness formula by searching the entire state space
of the program for a counterexample: a state or path that violates correctness. The
advantage of model checking is that once the program and the correctness prop-
erty have been written, model checking is purely algorithmic and no intervention is
required. Algorithms and data structures have been developed that enable a model
checker to verify very large state spaces.
Model checking with correctness properties speciﬁed in LTL is done by explicitly
generating the state space. If the correctness property is a safety property expressed
as an assertion or an invariant, the correctness can be checked on-the-ﬂy at each
state as it is generated. Liveness properties require the use of nested search when-
ever a state is reached that could be part of a path that is a counterexample. LTL
formulas are translated into Büchi automata so that the path in the computation can
be synchronized with a path speciﬁed by the correctness formula.
Model checking can also be based upon the branching-time logic CTL. Here,
computations are encoded in binary decision diagrams and the algorithms for BDDs
are used to efﬁciently search for counterexamples. SAT solvers have also been used
in model checkers in place of BDDs.

324
16
Veriﬁcation of Concurrent Programs
16.12 Further Reading
For an introduction to concurrent programming, we recommend (of course) Ben-Ari
(2006), which contains deductive proofs of algorithms as well as veriﬁcations using
the SPIN model checker. Magee and Kramer (1999) is an introductory textbook that
takes a different approach using transition systems to model programs.
The deductive veriﬁcation of concurrent programs is the subject of Manna and
Pnueli (1992, 1995): the ﬁrst volume presents LTL and the second volume deﬁnes
rules for verifying safety properties. The third volume on the veriﬁcation of liveness
properties was never completed, but a partial draft is available (Manna and Pnueli,
1996). Deductive veriﬁcation is also the subject of the textbook by Apt et al. (2009).
Textbooks on model checking are Baier and Katoen (2008), and Clarke et al.
(2000).
The SPIN model checker is particular easy to use as described in Ben-Ari (2008).
Holzmann (2004) describes SPIN in detail: both practical aspects of using it and the
important details of how the algorithms are implemented.
Bounded model checking with SAT solvers is presented in Biere et al. (2009,
Chap. 14).
16.13 Exercises
16.1 Show that Peterson’s algorithm remains correct if the assignments in wantp
= true; turn = 1 and in wantq = true; turn = 2 are not executed
as one atomic operation, but rather as two operations. Show that if the order of the
separate assignments is reversed, the algorithm is not correct.
16.2 Complete the proof the invariants of Peterson’s algorithm (Lemma 16.8).
16.3 Complete the proof of Lemma 16.12 by proving:
⊢waitp ∧2¬csp →2(waitp ∧2¬csp).
16.4 Complete the analysis of liveness in Peterson’s algorithm (Sect. 16.8) and
show that computations in which ¬csp holds in all states are unfair.
16.5 Generate the state space for Third Attempt (Ben-Ari, 2006, Sect. 3.7):
boolean wantp = false, wantq = false
Process p
Process q
while (true) {
while (true) {
tryp:
wantp = true
tryq:
wantq = true
waitp: wait until !wantq
waitq: wait until !wantp
csp:
wantp = false
csq:
wantq = false
}
}
Is the algorithm correct?

References
325
16.6 * Show that the CTL operators are not independent:
|= ∃3p ↔¬∀2¬p,
|= ∀3p ↔¬∃2¬p.
16.7 * A CTL formula is said to be equivalent to an LTL formula if the LTL for-
mula is obtained by erasing the quantiﬁers from the CTL formula and the formulas
are true of the same programs. Use the following automaton to show that the CTL
formula ∀3∀2p and the LTL formula 32p are not equivalent.
References
K.R. Apt, F.S. de Boer, and E.-R. Olderog. Veriﬁcation of Sequential and Concurrent Programs
(Third Edition). Springer, London, 2009.
C. Baier and J.-P. Katoen. Principles of Model Checking. MIT Press, 2008.
M. Ben-Ari. Principles of Concurrent and Distributed Programming (Second Edition). Addison-
Wesley, Harlow, UK, 2006.
M. Ben-Ari. Principles of the Spin Model Checker. Springer, London, 2008.
A. Biere, M. Heule, H. Van Maaren, and T. Walsh, editors. Handbook of Satisﬁability, volume 185
of Frontiers in Artiﬁcial Intelligence and Applications. IOS Press, 2009.
E.M. Clarke, O. Grumberg, and D.A. Peled. Model Checking. MIT Press, Cambridge, MA, 2000.
E.W. Dijkstra. Cooperating sequential processes. In F. Genuys, editor, Programming Languages.
Academic Press, New York, NY, 1968.
G.J. Holzmann. The Spin Model Checker: Primer and Reference Manual. Addison-Wesley, Boston,
MA, 2004.
J. Magee and J. Kramer. Concurrency: State Models & Java Programs. John Wiley, Chichester,
1999.
Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems. Vol. I: Speciﬁ-
cation. Springer, New York, NY, 1992.
Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems. Vol. II: Safety.
Springer, New York, NY, 1995.
Z. Manna and A. Pnueli. Temporal veriﬁcation of reactive systems: Progress. Draft available at
http://www.cs.stanford.edu/~zm/tvors3.html, 1996.
G.L. Peterson. Myths about the mutual exclusion problem. Information Processing Letters,
12(3):115–116, 1981.


Appendix
Set Theory
Our presentation of mathematical logic is based upon an informal use of set the-
ory, whose deﬁnitions and theorems are summarized here. For an elementary, but
detailed, development of set theory, see Velleman (2006).
A.1 Finite and Inﬁnite Sets
The concept of an element is undeﬁned, but informally the concept is clear: an ele-
ment is any identiﬁable object like a number, color or node of a graph. Sets are built
from elements.
Deﬁnition A.1 A set is composed of elements. a ∈S denotes that a is an element
of set S and a ̸∈S denotes that a is not an element of S. The set with no elements is
the empty set, denoted ∅. Capital letters like S, T and U are used for sets.
There are two ways to deﬁne a set: (a) We can explicitly write the elements
comprising the set. If a set is large and if it is clearly understood what its elements
are, an ellipsis ‘...’ is used to indicate the elements not explicitly listed. (b) A set
may be deﬁned by set comprehension, where the set is speciﬁed to be composed of
all elements that satisfy a condition. In either case, braces are used to contain the
elements of the set.
Example A.2
• The set of colors of a trafﬁc light is {red,yellow,green}.
• The set of atomic elements is {hydrogen,helium,lithium,...}.
• Z , the set of integers, is {...,−2,−1,0,1,2,...}.
• N , the set of natural numbers, is {0,1,2,...}. N can also be deﬁned by set
comprehension: N = {n | n ∈Z and n ≥0}. Read this as: N is the set of all n
such that n is an integer and n ≥0.
• E , the set of even natural numbers, is {n | n ∈N and n mod 2 = 0}.
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7, © Springer-Verlag London 2012
327

328
Set Theory
• P, the set of prime numbers, is:
{n | n ∈N and n ≥2 and (n mod m = 0 implies m = 1 or m = n)}.
There is no meaning to the order of the elements in a set or to repetition of
elements: {3,2,1,1,2,3} = {1,2,3} = {3,1,2}. A set containing a single element
(a singleton set) and the element itself are not the same: 5 ∈{5}.
A.2 Set Operators
Set Inclusion
Deﬁnition A.3 Let S and T be sets. S is a subset of T , denoted S ⊆T , iff every
element of S is an element of T , that is, x ∈S →x ∈T . S is a proper subset of T ,
denoted S ⊂T , iff S ⊆T and S ̸= T .
Example A.4 N ⊂Z , E ⊂N , {red,green} ⊂{red,yellow,green}.
Theorem A.5 ∅⊆T .
The intuition behind ∅⊆T is as follows. To prove S ⊆T , we have to show that
x ∈S →x ∈T holds for all x ∈S. But there are no elements in ∅, so the statement
is vacuously true.
The relationships among sets can be shown graphically by the use of Venn di-
agrams. These are closed curves drawn in the plane and labeled with the name of
a set. A point is in the set if it is within the interior of the curve. In the following
diagram, since every point within S is within T , S is a subset of T .
Theorem A.6 The subset property is transitive:
If S ⊆T and T ⊆Uthen S ⊆U.
If S ⊂T and T ⊆Uthen S ⊂U.
If S ⊆T and T ⊂Uthen S ⊂U.
If S ⊂T and T ⊂Uthen S ⊂U.
The relationship between equality of sets and set inclusion is given by the fol-
lowing theorem.
Theorem A.7 S = T iff S ⊆T and T ⊆S.

A.2
Set Operators
329
Union, Intersection, Difference
Deﬁnition A.8
• S ∪T , the union of S and T , is the set consisting of those elements which are
elements of either S or T (or both).
• S ∩T , the intersection of S and T , is the set consisting of those elements which
are elements of both S and T . If S ∩T = ∅then S and T are disjoint.
• S −T , the difference of S and T , is the set of elements of S that are not elements
of T .
• Let S be understood as a universal set; then ¯T , the complement of T , is S −T .
The following Venn diagram illustrates these concepts.
Example A.9 Here are some examples of operations on sets:
{red,yellow} ∪{red,green}
= {red,yellow,green},
{red,yellow} ∩{red,green}
= {red},
{red,yellow} −{red,green} = {yellow},
P ∩E
= {2},
P ∩N
= P,
P ∪N
= N .
The operators ∪and ∩are commutative, associative and distributive.
Theorem A.10
S ∪T
= T ∪S,
S ∩T
= T ∩S,
(S ∪T ) ∪U
= S ∪(T ∪U),
(S ∩T ) ∩U
= S ∩(T ∩U),
S ∪(T ∩U) = (S ∪T ) ∩(S ∪U),
S ∩(T ∪U) = (S ∩T ) ∪(S ∩U).

330
Set Theory
The following theorem states some simple properties of the set operators.
Theorem A.11
T = (T −S) ∪(S ∩T ).
If S ⊆T then : S ∩T = S, S ∪T = T, S −T = ∅.
If S and T are disjoint then S −T = S.
S ∪∅= S, S ∩∅= ∅, S −∅= S.
A.3 Sequences
Deﬁnition A.12 Let S be a set.
• A ﬁnite sequence f on S is a function from {0,...,n −1} to S . The length of
the sequence is n.
• An inﬁnite sequence f on S is a mapping from N to S .
Example A.13 Let S be the set of three colors {red,yellow,green}. Suppose that
you see a green light but don’t manage to cross the road before it changes. The
sequence of colors that you will see before you cross the road is the sequence f on
{0,1,2,3} deﬁned by:
f0 = green,
f1 = yellow,
f2 = red,
f3 = green.
The inﬁnite sequence of colors that the light shows (assuming that it is never turned
off or malfunctions) is:
f0 = green,
f1 = yellow,
f2 = red,
...,
where the ellipsis ... indicates that we know how to continue constructing the se-
quence. Alternatively, we could formally deﬁne the sequence as:
fi = green
if i mod 3 = 0,
fi = yellow if i mod 3 = 1,
fi = red
if i mod 3 = 2.
In place of functional notation, one usually lists the elements of a sequence within
parentheses () to differentiate a sequence from a set which is written within braces
{}:
Deﬁnition A.14 Let f be a sequence on S . The sequence is denoted:
(s0,s1,s2,...)
where si = f (i).

A.4
Relations and Functions
331
Deﬁnition A.15 A ﬁnite sequence of length n is an n-tuple. The following terms
are also used: a 2-tuple is a pair, a 3-tuple is a triple and a 4-tuple is a quadruple.
Example A.16 Examples of sequences:
• A 1-tuple: (red).
• A pair: (5,25).
• A triple: (red,yellow,green).
• A different triple: (red,green,yellow).
• A triple with repeated elements: (red,green,green).
• An inﬁnite sequence: (1,2,2,3,3,3,4,4,4,4,...).
Deﬁnition A.17 Let S and T be sets. S × T , their Cartesian product , is the set of
all pairs (s,t) such that s ∈S and t ∈T .
Let S1,...,Sn be sets. S1 × ··· × Sn,, their Cartesian product, is the set of n-
tuples (s1,...,sn), such that si ∈Si. If all the sets Si are the same set S, the notation
Sn is used for S × ··· × S.
Example A.18
• N × N = N 2 is the set of all pairs of natural numbers. This can be used to
represent discrete coordinates in the plane.
• N × {red,yellow,green} is the set of all pairs whose ﬁrst element is a number
and whose second is a color. This could be used to represent the color of a trafﬁc
light at different points of time.
A.4 Relations and Functions
Two central concepts in mathematics are that of relation (3 is less that 5) and func-
tion (the square of 5 is 25). Formally, a relation is a subset of a Cartesian product of
sets and a function is a relation with a special property.
Relations
Deﬁnition A.19 An n-ary relation R is a subset of S1 × ··· × Sn. R is said to be a
relation on S1 × ··· × Sn. A 1-ary (unary) relation is simply a subset.
Example A.20 Here are some relations over N k for various k ≥1:
• The set of prime numbers P is a relation on N 1.
• S Q = {(n1,n2) | n2 = n2
1} is a relation on N 2; it is the set of pairs of numbers
and their squares: (4,16) ∈S , (7,49) ∈S .
• The following relation on N 2:
R = {(n,m) | n mod k = 0 and m mod k = 0 implies k = 1}

332
Set Theory
is the set of relatively prime numbers. Examples are: (4,9) ∈R, (15,28) ∈
R, (7,13) ∈R.
• Pythagorean triples {(x,y,z) | x2 + y2 = z2} are a relation on N 3. They are the
values that can be the lengths of right-angled triangles. Examples are (3,4,5) and
(6,8,10).
• Let F be the set of quadruples {(x,y,z,n) | n > 2 and xn + yn = zn}. Fermat’s
Last Theorem (which was recently proved) states that this relation F on N 4 is
the empty set ∅.
Properties of Relations
Deﬁnition A.21 Let R be a binary relation on S2.
• R is reﬂexive iff R(x,x) for all x ∈S.
• R is symmetric iff R(x1,x2) implies R(x2,x1).
• R is transitive iff R(x1,x2) and R(x2,x3) imply R(x1,x3).
R∗, the reﬂexive transitive closure of R, is deﬁned as follows:
• If R(x1,x2) then R∗(x1,x2).
• R∗(xi,xi) for all xi ∈S.
• R∗(x1,x2) and R∗(x2,x3) imply R∗(x1,x3).
Example A.22 Let C be the relation on the set of ordered pairs of strings (s1,s2)
such that s1 = s2, s1 = c·s2, or s1 = s2 ·c, for some c in the underlying character set.
Then C ∗is the substring relation between strings. Let us check the three properties:
• For each of the three conditions deﬁning C , C (s1,s2) implies that s1 is a substring
of s2.
• C ∗is reﬂexive because every string is a substring of itself.
• ‘Substring of’ is a transitive relation. For example, suppose that the following
relations hold: abc is a substring of xxabcyy and xxabcyy is a substring of
aaxxabcyycc; then the transitive relation also holds: abc is a substring of
aaxxabcyycc.
Functions
Consider the relation S Q = {(n1,n2) | n2 = n2
1} on N 2. It has the special property
that for any n1, there is a most one element n2 such that S (n1,n2). In fact, there is
exactly one such n2 for each n1.
Deﬁnition A.23 Let F be a relation on S1 × ··· × Sn. F is a function iff for every
n−1-tuple (x1,...,xn−1) ∈S1 × ··· × Sn−1, there is at most one xn ∈Sn, such that
F(x1,...,xn). The notation xn = F(x1,...,xn−1) is used.
• The domain of F is the set of all (x1,...,xn−1) ∈S1 × ··· × Sn−1 for which
(exactly one) xn = F(x1,...,xn−1) exists.

A.5
Cardinality
333
• The range of F is the set of all xn ∈Sn such that xn = F(x1,...,xn−1) for at
least one (x1,...,xn−1).
• F is total if the domain of F is (all of) S1 × ··· × Sn−1; otherwise, F is partial.
• F is injective or one-to-one iff (x1,...,xn−1) ̸= (y1,...,yn−1) implies that
F(x1,...,xn−1) ̸= F(y1,...,yn−1).
• F is surjective or onto iff its range is (all of) Sn.
• F is bijective (one-to-one and onto) iff it is injective and surjective.
Example A.24 S Q = {(n1,n2) | n2 = n2
1} is a total function on N 2. Its domain is
all of N , but its range is only the subset of N consisting of all squares. Therefore
S q is not surjective and thus not bijective. The function is injective, because given
an element in its range, there is exactly one square root in N , symbolically, x ̸=
y →x2 ̸= y2, or equivalently, x2 = y2 →x = y. If the domain were taken to be Z ,
the set of integers, the function would no longer be injective, because n ̸= −n but
(n)2 = (−n)2.
A.5 Cardinality
Deﬁnition A.25 The cardinality of a set is the number of elements in the set. The
cardinality of a S is ﬁnite iff there is an integer n such that the number of elements
in S is the same that the number of elements in the set {1,2,...,n}. Otherwise the
cardinality is inﬁnite. An inﬁnite set S is countable if its cardinality is the same as
the cardinality of N . Otherwise the set is uncountable.
To show that the cardinality of a set S is ﬁnite, we can count the elements. For-
mally, we deﬁne a bijective function from the ﬁnite set {1,...,n} to S. To show
that an inﬁnite set is countable, we do exactly the same thing, deﬁning a bijective
function from (all of) N to S. Clearly, we can’t deﬁne the function by listing all of
its elements, but we can give an expression for the function.
Example A.26 E , the set of even natural numbers, is countable. Deﬁne f (i) = 2i
for each i ∈N :
0 →0,
1 →2,
2 →4,
3 →6,
....
We leave it to the reader to show that f is bijective.
We immediately see that non-ﬁnite arithmetic can be quite non-intuitive. The set
of even natural numbers is a proper subset of the set of natural numbers, because, for
example, 3 ∈N but 3 ̸∈E . However, the cardinality of E (the number of elements
in E ) is the same as the cardinality of N (the number of elements in N )! It takes
just a bit of work to show that Z , the set of integers, is countable, as is the set of
rational numbers Q.

334
Set Theory
Georg Cantor ﬁrst proved the following theorem:
Theorem A.27 The set of real numbers R is uncountable.
Proof Suppose to the contrary that there is a bijective function f : N →R, so
that it makes sense to talk about ri, the ith real number. Each real number can be
represented as an inﬁnite decimal number:
ri = d1
i d2
i d3
i d4
i d5
i ··· .
Consider now the real number r deﬁned by:
r = e1e2e3e4e5 ··· ,
where ei = (di
i + 1) mod 10. That is, the ﬁrst digit of r is different from the ﬁrst
digit of r1, the second digit of r is different from the second digit of r2, and so
on. It follows that r ̸= ri for all i ∈N , contradicting the assumption that f was
surjective.
This method of proof, called the diagonalization argument for obvious reasons, is
frequently used in computer science to construct an entity that cannot be a member
of a certain countable set.
Powersets
Deﬁnition A.28 The powerset of a set S, denoted 2S, is the set of all subsets of S.
Example A.29 Here is the powerset of the ﬁnite set S = {red,yellow,green}:
{
{red,yellow,green},
{red,yellow},{red,green},{yellow,green},
{red},{yellow},{green},
∅
}.
The cardinality of S is 3, while the cardinality of the powerset is 8 = 23.
This is true for any ﬁnite set:
Theorem A.30 Let S be a ﬁnite set of cardinality n; then the cardinality of its
powerset is 2n.

A.6
Proving Properties of Sets
335
A.6 Proving Properties of Sets
To show that two sets are equal, use Theorem A.7 and show that each set is a subset
of the other. To show that a set S is a subset of another set T , choose an arbitrary
element x ∈S and show x ∈T . This is also the way to prove a property R(x) of a
set S by showing that S ⊆{x | R(x)}.
Example A.31 Let S be the set of prime numbers greater than 2. We prove that every
element of S is odd. Let n be an arbitrary element of S. If n is greater than 2 and
even, then n = 2k for some k > 1. Therefore, n has two factors other than 1 and
itself, so it cannot be a prime number. Since n was an arbitrary element of S, all
elements of S are odd.
Induction
Let S be an arbitrary set, let s = (s0,s1,s2,...) be a (ﬁnite or inﬁnite) sequence of
elements of S and let R be any unary relation on S, that is, R ⊆S. Suppose that we
want to prove that si ∈R for all i ≥0. The can be done using the rule of induction,
which is a two-step proof method:
• Prove that s0 ∈R; this is the base case.
• Assume si ∈R for an arbitrary element si, and prove si+1 ∈R. This is the induc-
tive step and the assumption is the inductive hypothesis.
The rule of induction enables us to conclude that the set of elements appearing in
the sequence s is a subset of R.
Example A.32 Let s be the sequence of non-zero even numbers in N :
s = (2,4,6,8,...),
and let R be the subset of elements of N that are the sum of two odd numbers, that
is, r ∈R if and only if there exist odd numbers r1 and r2 such that r = r1 + r2. We
wish to prove that s, consider as a set of elements of N , is a subset of R:
{2,4,6,8,...} ⊆R.
Base case: The base case is trivial because 2 = 1 + 1.
Inductive step: Let 2i be the ith non-zero even number. By the inductive hypothe-
sis, 2i is the sum of two odd numbers 2i = (2j + 1) + (2k + 1). Consider now,
2(i + 1), the i + 1st element of S and compute as follows:
2(i + 1) = 2i + 2
= (2j + 1) + (2k + 1) + 2
= (2j + 1) + (2k + 3)
= (2j + 1) + (2(k + 1) + 1).

336
Set Theory
The computation is just arithmetic except for the second line which uses the
inductive hypothesis. We have shown that 2(i +1) is the sum of two odd numbers
2j + 1 and 2(k + 1) + 1. Therefore, by the rule of induction, we can conclude
that {2,4,6,8,...} ⊆R.
The method of proof by induction can be generalized to any mathematical struc-
ture which can be ordered—larger structures constructed out of smaller structures.
The two-step method is the same: Prove the base case for the smallest, indivisible
structures, and then prove the induction step assuming the inductive hypothesis. We
will use induction extensively in the form of structural induction. Since formulas are
built out of subformulas, to prove that a property holds for all formulas, we show
that it holds for the smallest, indivisible atomic formulas and then inductively show
that is holds when more complicated formulas are constructed. Similarly, structural
induction is used to prove properties of trees that are built out of subtrees and even-
tually leaves.
References
D.J. Velleman. How to Prove It: A Structured Approach (Second Edition). Cambridge University
Press, 2006.

Index of Symbols
P (propositional)
8
¬
8
∨
8
∧
8
→
8
↔
8
⊕
8
↓
8
↑
8
::=
14
|
14
F (propositional)
14
PA
16
IA
16
vIA
16
PS
21
≡(propositional)
21
←(substitution)
23
true
24
false
24
T
26
F
26
|= A
29
U |= A (propositional)
32

32

32
×
35
⊙
35
α
36
β
36
φ
36
T
36
⊢
50
G (propositional)
51
¯U
54
H
55
⇒
69
S
69
2 (empty clause)
77
¯p
78
lc
78
Π
89

90
A|p=w
107
∃(propositional)
109
∀(propositional)
109
≈
111
RU(S)
114
PR
131
P (ﬁrst-order)
133
A
133
V
133
∀(ﬁrst-order)
133
∃(ﬁrst-order)
133
A(x1,...,xn)
135
I (ﬁrst-order)
136
σ
137
vσIA
137
I |= A
138
≡(ﬁrst-order)
140
U |= A (ﬁrst-order)
140
γ
148
δ
148
G (ﬁrst-order)
155
H (ﬁrst-order)
158
F (function symbol)
168
I (with functions)
169
HS
177
BS
178
λ
187
μ
187
σ
187
θ
187
ε
187
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7, © Springer-Verlag London 2012
337

338
Index of Symbols
←(reverse implication)
209
:-
216
N T
228
2 (temporal logic)
233
3
233
ρ
235
vI ,s
236
s |=I
236
#
239
F (temporal logic)
239
σ
240
σi
240
vσ
240
σ |= A
241
;
254
L
263
{p} S {q}
275
H L
275
wp(S, q)
284
Wk
289
∀2
319
∀3
319
∀#
319
∃2
319
∃3
319
∃#
319
∈
327
̸∈
327
∅
327
{···}
327
Z
327
N
327
{n | n ∈...}
327
⊆
328
⊂
328
∪
329
∩
329
−
329
¯T
329
×
331
Sn
331
F (function)
332
P(S)
334

Name Index
A
Apt, K., 275, 278, 279, 293, 324
B
Baier, C., 99, 110, 261, 317, 324
Ben-Ari, M., 261, 272, 301, 305, 312, 324
Bratko, I., 221
Bryant, R., 99, 103, 110
C
Cantor, G., 334
Church, A., 223
Clarke, E.M., 324
Clocksin, W.F., 221
D
Davis, M., 128
de Boer, F.S., 275, 278, 279, 293, 324
Dijkstra, E.W., 284, 301
Dreben, B., 226, 227, 229
E
Even, S., 254
F
Fitting, M., 45, 92, 153, 182, 202
Floyd, R.W., 293
G
Gödel, K., 2, 228
Goldfarb, W., 226, 227, 229
Gopalakrishnan, G.L., 128
Gries, D., 293
Grumberg, O., 324
H
Heule, M., 128, 324
Hilbert, D., 2
Hoare, C.A.R., 275
Holzmann, G.J., 317, 324
Hopcroft, J.E., 14, 128, 224
Huth, M., 71
K
Katoen, J.-P., 99, 110, 261, 317, 324
Kramer, J., 324
Kripke, S.A., 232
Kröger, F., 261, 272
L
Lewis, H., 226, 229
Lloyd, J.W., 182, 194, 202, 212, 215, 221
Logemann, G., 128
Loveland, D., 128, 202
Łukasiewicz, J., 12
M
Magee, J., 324
Malik, S., 128
Manna, Z., 47, 223, 261, 272, 293, 324
Martelli, A., 190, 202
Mellish, C.S., 221
Mendelson, E., 6, 69, 71, 164, 165, 182, 226,
228, 229
Merz, S., 261, 272
Minsky, M., 223, 224
Monk, D., 69, 182, 229
Montanari, U., 190, 202
Motwani, R., 128
N
Nadel, B.A., 128
Nerode, A., 6, 45, 92, 153
O
Olderog, E.-R., 275, 278, 279, 293, 324
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7, © Springer-Verlag London 2012
339

340
Name Index
P
Peano, G., 33, 228
Peled, D.A., 324
Peterson, G.L., 301
Pnueli, A., 232, 261, 272, 324
Putnam, H., 128
R
Robinson, J.A., 75, 186
Ryan, M.D., 71
S
Shapiro, E., 221
Shore, R.A., 6, 45, 92, 153
Sipser, M., 128
Smullyan, R.M., 1, 6, 38, 45, 67, 69, 71, 153,
165, 228
Sterling, L., 221
T
Tseitin, G.S., 91
U
Ullman, J.D., 14, 128, 224
Urquhart, A., 91
V
Van Maaren, H., 128, 324
Velleman, D., 50, 71, 372
W
Walsh, T., 128, 324
Z
Zhang, L., 128

Subject Index
A
Argument, 133
Assignment, 137
Atom
ground, 170
Atomic proposition, 8
Automaton
asynchronous, 309
Büchi, 315
synchronous, 317
Axiom, 33, 50
Axiom scheme, 55
Axiomatizable, 33
B
Binary decision diagram, 95–109
algorithm
apply, 104
reduce, 99
restrict, 108
complexity, 104
deﬁnition, 98
ordered, 102–104
quantiﬁcation, 109
reduced, 98–102
restriction, 107–109
Boolean operator, 8
absorption, 24
adequate sets of, 27–29
alternate notations, 13
associativity, 10, 25
collapsing, 24, 25
commutativity, 25
conjunction, 8
deﬁning one operator in terms of another,
25
disjunction, 8
inclusive vs. exclusive, 19
distributivity, 25
equivalence, 8
vs. logical equivalence, 22
implication, 8
material, 20
reverse, 27
vs. logical consequence, 32
nand, 8, 28
negation, 8
nor, 8, 28
number of, 26
precedence, 10
principal operator, 12
Bound variable, see Variable, bound
Breadth-ﬁrst search, 311
C
Cartesian product, 331
Characteristic predicate, 274
Church’s theorem, 224–226
Clausal form, 77, 172
properties of, 111–115
Clause, 77
clashing, 80, 185, 196
conﬂict, 116
empty, 77
and empty set of clauses, 78
empty set of, 77
Horn, 209
fact, 209
goal, 209
program, 209
parent, 80, 185
renaming, 114, 115
subsume, 113
trivial, 77
M. Ben-Ari, Mathematical Logic for Computer Science,
DOI 10.1007/978-1-4471-4129-7, © Springer-Verlag London 2012
341

342
Subject Index
Clause (cont.)
unit, 77, 113
Closure
existential, 135
reﬂexive transitive, 332
universal, 135
Compactness
ﬁrst order logic, 228
propositional logic, 67
Completeness
ﬁrst order logic
Gentzen system, 157
Hilbert system, 161
resolution, 199–202
semantic tableaux, 151–153
SLD-resolution, 212
Hoare logic, 292
propositional logic
Gentzen system, 54
Hilbert system, 64–66
resolution, 83–88
semantic tableaux, 40, 42–44
strong, 67
relative, 275
temporal logic, 269–271
Complexity of algorithms in propositional
logic, 126, 127
Component graph, 254
Computation rule, 212
Conjunctive normal form, 75, 76
3CNF, 79
Consistency, 66, 228
Consistent
maximally, 73
Constant symbol, 133
Contrapositive, 25
Correct answer substitution, 210
Correctness
formula, 275
partial, 275, 277
total, 278
D
Davis-Putnam algorithm, see SAT solver,
Davis-Putnam algorithm
De Morgan’s laws, 26, 76
Decision procedure, 30
ﬁrst order logic
semi-, 181
solvable cases, 226, 227
propositional logic, 30, 40, 93
temporal logic
linear, 257
Deductive system, 50
Depth-ﬁrst search, 311
nested, 317
Derived rule, 56
Disagreement set, 194
Disjunctive normal form, 92
Domain, 136, 140, 152, 169, 275
Duality, 288
E
Expression, 187
F
Factoring, 196
Failure node, 85, 201
Fairness, 318
Falsiﬁable
ﬁrst order logic, 138
propositional logic, 29
Formula
atomic, 168
complementary pair, 33
condensable, 230
ﬁrst order logic, 133, 136
atomic, 133, 136
closed, 135, 138
quantiﬁed, 134
future, 241, 246, 255
ground, 170
monadic, 227
next, 241, 245
propositional logic, 8
pure, 226
Frame, 239
Free variable, see Variable, free
Fulﬁll, 247
Function, 169, 332
bijective, 333
domain, 332
injective, 333
partial, 333
range, 333
surjective, 333
symbol, 168, 169
total, 333
G
Generalization, see Rule of inference,
generalization
Gentzen system
ﬁrst order logic, 155–157
γ and δ formulas, 155
axiom, 155
completeness, 157
rule of inference, 155
soundness, 157

Subject Index
343
Gentzen system (cont.)
Hauptsatz, 71
propositional logic, 51–54
α and β formulas, 51
axiom, 51, 69
completeness, 54
rule of inference, 51, 69
and semantic tableaux, 53
sequent, 69
soundness, 54
Goldbach’s conjecture, 4
Grammar of formulas
ﬁrst order logic, 136
propositional logic, 14
with terms, 168
H
Half-adder, 3, 93
Herbrand
base, 178
interpretation, 178
model, 178
universe, 177
Herbrand’s theorem, 180–182
Hilbert system
ﬁrst order logic, 158–164
axiom, 158
completeness, 161
rule of inference, 158
soundness, 161
propositional logic, 55–67
axiom, 55
completeness, 64–66
with disjunction and conjunction, 62
rule of inference, 55
soundness, 64
variants, 68
Hilbert’s program, 2
Hintikka set, 228
ﬁrst order logic, 152
propositional logic, 43
Hintikka structure
temporal logic, 251
fulﬁlling, 253
linear, 252
Hintikka’s lemma
ﬁrst order logic, 152
propositional logic, 44
temporal logic, 253
Hoare logic, 275–292
Horn clause, 222
I
Idempotent, 203
Incompleteness theorem, 228
Induction, 335
Inference node, 86, 201
Inorder traversal, 8
Instance, 187
ground, 170
Instantiation, 143
Integers, 327
Interpretation
ﬁnitely presented, 247
ﬁrst order logic, 136, 169
partial, 17, 116
propositional logic, 16
for a set of formulas, 21, 139
temporal logic, 235
Invariant, 270, 276, 285, 303
L
Lifting lemma, 199
Linear temporal logic, see Temporal logic,
linear
Literal
complementary pair, 33, 80, 185, 248
ﬁrst order logic, 148
ground, 170
propositional logic, 33, 77
pure, 112
Logic program, 210
database, 210
procedure, 210
Logic programming, 205–220
Logical consequence
closed under, 32
ﬁrst order logic, 140
propositional logic, 32
Logical equivalence
ﬁrst order logic, 140
propositional logic, 21
of formulas, 24–26
Löwenheim’s theorem, 227
Löwenheim–Skolem theorem, 228
M
Matrix, 172
Modal logic, 232
Model
countable, 227
ﬁnite, 227
ﬁnitely presented, 258
ﬁrst order logic, 138, 140
non-standard, 228
propositional logic, 29
of a set of formulas, 31
Model checking, 308

344
Subject Index
Model checking (cont.)
bounded, 322
on-the-ﬂy, 312
searching the state space, 311
symbolic, 322
modus ponens, see Rule of inference, modus
ponens
N
Natural deduction, 70
Natural numbers, 327
P
P=NP?, 127
Peterson’s algorithm, 301, 320, 322
abbreviated, 302
as automata, 308–310
correctness properties, 302
liveness, 306, 314–318
mutual exclusion, 304, 311
Polish notation, 12
Postcondition, 275
Precondition, 275
weakest, 283–289
of statements, 284–287
theorems on, 287–289
Predicate symbol, 133, 169
Predicate transformer, 284
Preﬁx, 172, 226
Prenex conjunctive normal form, 172, 226
Preorder traversal, 11
Program
concurrent, 298
atomic operation, 299
interleaving, 299
state of, 298
semantics, 283–289
speciﬁcation
concurrent, 298–303
synthesis, 279–282
veriﬁcation
concurrent, 303–307
sequential, 277–279
Programming language
Java, 14
operators in, 20
Prolog, 216–220
arithmetic, 218
cut, 219
forcing failure, 217
non-logical predicate, 218
scope of variables, 134
semantics, 284
Progress axiom, 305
Proof, 50
Q
Quantiﬁer
commutativity, 141
distributivity, 141
duality, 141
existential, 133
over equivalence, 142
over implication, 142
universal, 133
without a free variable, 142
R
Reachable state, 309
Refutation procedure, 30
SLD-, 215
Relation, 131, 136, 140, 169, 331
Renamable-Horn, 222
Resolution
ﬁrst order logic, 185–203
general, 195–202
algorithm, 197
completeness, 199–202
soundness, 198
ground, 185, 186
propositional logic, 75–92
completeness, 83–88
complexity, 88–91
procedure, 81
refutation, 82
rule, 80
soundness, 83
SLD-, 211–216
backtrack point, 217
completeness, 212, 213
search rule, 213–215
soundness, 212
tree, 214
Resolvent, 80, 185, 196
Rule of inference, 50
C-Rule, 164
contrapositive, 58, 61
cut, 70
deduction, 57, 159
double negation, 60
exchange of antecedent, 59
generalization, 158, 263
modus ponens, 55, 158, 263
modus tollens, 72
reductio ad absurdum, 61
structural induction, 13

Subject Index
345
Rule of inference (cont.)
temporal logic, 263
transitivity, 59
S
SAT solver, 111–126
David-Putnam algorithm, 115
DPLL algorithm, 116, 117
4-queens problem, 117–122
branching heuristics, 122, 123
learning conﬂict clauses, 124
non-chronological backtracking, 123,
124
stochastic algorithm, 125, 126
4-queens problem, 125
Satisﬁable
ﬁrst order logic, 138
propositional logic, 29, 140
of a set of formulas, 31
temporal logic, 236, 241
Search rule, 212, 215
Semantic tableau
ﬁrst order logic, 143–153
γ and δ formulas, 148
algorithm, 149
closed, 150
completeness, 151–153
open, 150
soundness, 150, 151
propositional logic, 33–44
α and β formulas, 36
closed, 37
completed, 37
completeness, 40, 42–44
open, 37
soundness, 40, 41
termination, 37
temporal logic, 244
α, β and X formulas, 244
algorithm, 247, 248
closed, 248
completed, 248
open, 248
with terms, 170–172
Semantic tree, 83
Sequences, 330
Set, 327
cardinality, 333
complement, 329
countable, 228, 333
difference, 329
disjoint, 329
element, 327
empty, 327
intersection, 329
operator, 328
powerset, 334
proper subset, 328
subset, 328
uncountable, 333
union, 329
Shannon expansion, 108
Skolem function, 174
Skolem’s algorithm, 173
Skolem’s theorem, 172–176
Soundness
ﬁrst order logic
Gentzen system, 157
Hilbert system, 161
resolution, 198
semantic tableaux, 150, 151
SLD-resolution, 212
Hoare logic, 290
propositional logic
Gentzen system, 54
Hilbert system, 64
resolution, 83
semantic tableaux, 40, 41
temporal logic, 269
Standardizing apart, 196
State space, 309
State transition diagram, 234
Strongly connected component, 254
maximal, 254
self-fulﬁlling, 255
terminal, 254
transient, 254
Structural induction, see Rule of inference,
structural induction
Subformula, 23
property, 70
Substitution
composition, 187
ﬁrst order logic, 187, 188
instance, 236, 263
propositional logic, 23
Subsumption, 113, 114
Syllogism, 1
T
Tautology, 29
Temporal logic
computational tree logic, 319
linear, 240–260
axioms, 263
collapsing, 243
commutativity, 267
completeness, 269–271

346
Subject Index
Temporal logic (cont.)
distributivity, 242, 243, 264
duality, 237
equivalent formulas, 241–244
ﬁnite model property, 258
induction, 241
interpretation, 240
soundness, 269
state node, 247, 249
state path, 250
structure, 249
transformed to an automaton, 315
transitivity, 266
models of time, 237–240
discreteness, 238
linearity, 238
reﬂexivity, 237
transitivity, 238
operator, 233
always, 233
binary, 258–260, 271
collapsing, 268
duality, 239, 268
eventually, 233
next, 239
propositional, 233
semantics, 233–236
syntax, 233
Term, 168
equation, 190
ground, 170
Theorem, 32
Theorem scheme, 55
Theory, 32
complete, 228
number, 228
Truth table, 17, 96
Truth value
ﬁrst order logic, 137
propositional logic, 16
temporal logic, 236
linear, 240
Tseitin encoding, 91
Turing machine, 223
Two-register machine, 224
U
Undecidability
ﬁrst order logic, 223–226
of logic programs, 226
of pure formulas, 226
Uniﬁcation, 189–195
algorithm
Martelli & Montanari, 190–194
Robinson, 194, 195
occurs-check, 190, 192
Uniﬁer, 189
most general, 189
Unsatisﬁable
ﬁrst order logic, 138
propositional logic, 29
of a set of formulas, 31
V
Valid
ﬁrst order logic, 138, 140
propositional logic, 29
temporal logic, 236, 241
Variable, 133
bound, 135
change of bound, 163
free, 135
quantiﬁed, 134
scope of, 134
Venn diagram, 328

