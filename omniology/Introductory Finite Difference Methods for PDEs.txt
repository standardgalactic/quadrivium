Professor C. G. Mingham; Professor D. M. Causon
Introductory Finite Difference Methods
for PDEs
Download free books at

2 
Professor D. M. Causon & Professor C. G. Mingham
Introductory Finite Difference 
Methods for PDEs
Download free eBooks at bookboon.com

3 
Introductory Finite Difference Methods for PDEs
© 2010 Professor D. M. Causon, Professor C. G. Mingham & Ventus Publishing ApS
ISBN 978-87-7681-642-1
Download free eBooks at bookboon.com

4 
Contents
Introductory Finite Difference Methods for PDEs
Contents
	
Preface	
9
1. 	
Introduction	
10
1.1 	
Partial Differential Equations	
10
1.2 	
Solution to a Partial Differential Equation	
10
1.3 	
PDE Models	
11
1.4 	
Classification of PDEs	
11
1.5 	
Discrete Notation	
15
1.6 	
Checking Results	
15
1.7 	
Exercise 1	
16
2. 	
Fundamentals	
17
2.1 	
Taylor’s Theorem	
17
2.2 	
Taylor’s Theorem Applied to the Finite Difference Method (FDM)	
17
2.3 	
Simple Finite Difference Approximation to a Derivative	
18
2.4 	
Example: Simple Finite Difference Approximations to a Derivative	
18
2.5 	
Constructing a Finite Difference Toolkit	
20
2.6 	
Simple Example of a Finite Difference Scheme	
24
2.7 	
Pen and Paper Calculation (very important)	
28
2.8	
Exercise 2a	
32
2.9 	
Exercise 2b	
33
Download free eBooks at bookboon.com
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

5 
Contents
Introductory Finite Difference Methods for PDEs
3. 	
Elliptic Equations	
34
3.1 	
Introduction	
34
3.2 	
Finite Difference Method for Laplace’s Equation	
34
3.3 	
Setting up the Equations	
37
3.4 	
Grid Convergence	
38
3.5 	
Direct Solution Method	
38
3.6 	
Exercise 3a	
41
3.7 	
Iterative Solution Methods	
42
3.8 	
Jacobi Iteration	
43
3.9 	
Gauss-Seidel Iteration	
45
3.10	
Exercise 3b	
47
3.11	
Successive Over Relaxation (SoR) Method	
47
3.12 	
Line SoR	
49
3.13 	
Exercise 3c	
51
4. 	
Hyperbolic Equations	
52
4.1 	
Introduction	
52
4.2 	
1D Linear Advection Equation	
53
4.3 	
Results for the Simple Linear Advection Scheme	
55
4.4 	
Scheme Design	
60
4.5 	
Multi-Level Scheme Design	
67
4.6 	
Exercise 4a	
69
4.7 	
Implicit Schemes	
70
4.8 	
Exercise 4b	
76
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
360°
thinking.
© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 


Introductory Finite Difference Methods for PDEs
6 
Contents
5. 	
Parabolic Equations: the Advection-Diffusion Equation	
77
5.1 	
Introduction	
77
5.2 	
Pure Diffusion	
78
5.3 	
Advection-Diffusion Equation	
81
5.4 	
Exercise 5b	
83
6. 	
Extension to Multi-dimensions and Operator Splitting	
84
6.1 	
Introduction	
84
6.2 	
2D Scheme Design (unsplit)	
84
6.3 	
Operator Splitting (Approximate Factorisation)	
92
7. 	
Systems of Equations	
105
7.1 	
Introduction	
105
7.2 	
The Shallow Water Equations	
105
7.3 	
Solving the Shallow Water Equations	
106
7.4 	
Example Scheme to Solve the SWE	
109
7.5 	
Exercise 7	
111
 
Appendix A: Definition and Properties of Order 
112
A.1 	
Definition of O(h)	
112
A.2 	
The Meaning of O(h)	
113
A.3 	
Properties of O(h)	
113
A.4 	
Explanation of the Properties of O(h)	
114
A.5 	
Exercise A	
114
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

 
Introductory Finite Difference Methods for PDEs
7 
Contents
	
Appendix B: Boundary Conditions	
115
B.1 	
Introduction	
115
B.2 	
Boundary Conditions	
116
B.3 	
Specifying Ghost and Boundary Values	
118
B.4 	
Common Boundary Conditions	
120
B.5 	
Exercise B	
121
	
Appendix C: Consistency, Convergence and Stability	
123
C.1 	
Introduction	
123
C.2	
 Convergence	
124
C.3 	
Consistency and Scheme Order	
124
C.4 	
Stability	
126
C.5 	
Exercise C	
133
	
Appendix D: Convergence Analysis for Iterative Methods	
135
D.1 	
Introduction	
135
D.2 	
Jacobi Iteration	
136
D.3 	
Gauss-Seidel Iteration	
137
D.4 	
SoR Iterative Scheme	
139
D.5 	
Theory for Dominant Eigenvalues	
139
D.6 	
Rates of Convergence of Iterative Schemes	
142
D.7 	
Exercise D	
143
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

 
Introductory Finite Difference Methods for PDEs
8 
Professor D.M. Causon and Professor C.G. Mingham
Department of Computing and Mathematics, Manchester Metropolitan University, UK
To our parents and to Mags
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
9 
Preface
Preface
The following chapters contain core material supported by pen and paper exercises together with 
computer-based exercises where appropriate. In addition there are web links to: 

worked solutions,  

computer codes, 

audio-visual presentations,  

case studies, 

further reading. 
Codes are written using Scilab (a Matlab clone, downloadable for free from http://www.scilab.org/) and 
also Matlab.  
The emphasis of this book is on the practical: students are encouraged to experiment with different input 
parameters and investigate outputs in the computer-based exercises. Theory is reduced to a necessary 
minimum and provided in appendices. Web links are found on the following web page:  
http://www2.docm.mmu.ac.uk/STAFF/C.Mingham/ 
This book is intended for final year undergraduates who have knowledge of Calculus and introductory 
level computer programming. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
10 
Introduction
1. Introduction 
This book provides an introduction to the finite difference method (FDM) for solving partial differential 
equations (PDEs). In addition to specific FDM details, general concepts such as stability, boundary 
conditions, verification, validation and grid independence are presented which are important for anyone 
wishing to solve PDEs by using other numerical methods and/or commercial software packages. Material 
is presented in order of increasing complexity and supplementary theory is included in appendices.  
1.1 Partial Differential Equations  
The following equation is an example of a PDE: 
)
y,x
,t(
f
U
)
y,x
,t(c
U
)
y,x
,t(
b
U
)
y,x
,t(
a
yy
x
t



     (1.1) 
where,

t, x, y are the independent variables (often time and space) 

a, b, c and f are known functions of the independent variables,  

U is the dependent variable and is an unknown function of the independent variables. 

partial derivatives are denoted by subscripts: 
2
2
yy
x
t
y
U
U
,
x
U
U
,
t
U
U









 etc. 
The order of a PDE is the order of its highest derivative. A PDE is linear if U and all its partial derivatives 
occur to the first power only and there are no products involving more than one of these terms. (1.1) is 
second order and linear. The dimension of a PDE is the number of independent spatial variables it 
contains. (1.1) is 2D if x and y are spatial variables. 
1.2 Solution to a Partial Differential Equation 
Solving a PDE means finding the unknown function U. An analytical (i.e. exact) solution of a PDE is a 
function that satisfies the PDE and also satisfies any boundary and/or initial conditions given with the PDE 
(more about these later). Most PDEs of interest do not have analytical solutions so a numerical procedure must 
be used to find an approximate solution. The approximation is made at discrete values of the independent 
variables and the approximation scheme is implemented via a computer program. The FDM replaces all partial 
derivatives and other terms in the PDE by approximations. After some manipulation, a finite difference scheme 
(FDS) is created from which the approximate solution is obtained. The FDM depends fundamentally on 
Taylor’s beautiful theorem (circa 1712!) which is stated in the next chapter. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
11 
Introduction
1.3 PDE Models 
PDEs describe many of the fundamental natural laws (e.g. conservation of mass) so describe a wide range 
of physical phenomena. Examples include Laplace’s equation for steady state heat conduction, the 
advection-diffusion equation for pollutant transport, Maxwell’s equations for electromagnetic waves, the 
Navier–Stokes equations for fluid flow and many, many more. The authors’ main interest is in solving 
PDEs for fluid flow problems and details, including pictures and animations, can be found at: 
http://www.docm.mmu.ac.uk/cmmfa/ 
1.4 Classification of PDEs 
Second order linear PDEs can be formally classified into 3 generic types: elliptic, parabolic and 
hyperbolic. The simplest examples are: 
a) Elliptic: e.g.
)
y
,x
(
f
U
U
yy
xx


.
This is Poisson’s equation or Laplace’s equation (when f(x,y) =0) which may be used to model the steady 
state temperature distribution in a plate or incompressible potential flow. Notice there is no time derivative. 
b) Parabolic: e.g. 
xx
t
kU
U 
.
This is the 1D diffusion equation and can be used to model the time-dependent temperature distribution 
along a heated 1D bar. 
c) Hyperbolic: e.g. 
xx
2
tt
U
c
U 
.
This is the wave equation and may be used to model a vibrating guitar string or 1D supersonic flow. 
d)
x
t
cU
U


.
This first order PDE is called the advection equation. Solutions of d) also satisfy c). 
e) 
xx
x
t
kU
cU
U


.
This is the advection-diffusion equation and may be used to model transport of a pollutant in a river. The 
coefficients k, c in the above PDEs quantify material properties that relate to the problem being solved e.g. 
k could be the coefficient of thermal conductivity in the case of a heated bar, or 1D diffusion coefficient in 
the case of pollutant transport; c is a wave speed, usually, in fluid flow, the speed of sound. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
12 
Introduction
1.4.1 Initial and Boundary Conditions 
PDEs require proper initial conditions (ICs) and boundary conditions (BCs) in order to define what is 
known as a well-posed problem. If too many conditions are specified then there will be no solution; if too 
few conditions are specified the solution will not be unique. If the ICs/BCs are specified in the wrong 
place or at the wrong time then the solution will not depend smoothly on the ICs/BCs and small errors in 
the ICs/BCs will bring about large changes in the solution. This is referred to as an ill-posed problem. The 
PDEs encountered in practice are often non-linear and multi-dimensional and cannot be reduced to the 
simple so-called canonical forms of a) - e). However, we need to understand the properties of the solution 
to these simple model PDEs before attempting to solve more complicated PDEs. 
A second order elliptic PDE such as a) requires a boundary condition on U at each point on the boundary. 
Thus, these are called Boundary Value (BV) problems. The BC may be a value of U on the boundary or 
the value of its derivative (see Appendix B). Linear parabolic equations such a b) require ICs at the initial 
start time (usually t=0) and one BC at each end-point of the spatial domain (e.g. at the ends of the heated 
bar). Technically linear hyperbolic equations such as d) require ICs and as many BCs as there are inward-
pointing characteristics (this is an advanced topic which we will not cover) which depend on the sign of 
wave speed c, thus: 
If c>0, we need ICs: U(0,x) = f(x) and BCs: U(t,0) = g(t); 
If c<0, we need ICs: U(0,x) = f(x) but no BCs. 
These are called Initial Boundary Value Problems (IBV) problems. 
1.4.2 Domain of Dependence 
The differences between the types of PDEs can be illustrated by sketching their respective domains of 
dependence. So for example, in the hyperbolic case d), point P (x0, t0) in Figure 1.1 can only be influenced 
by points lying within the region bounded by the two characteristics x+ct = const and x-ct = const and  
t < t0. This region is called the domain of dependence. In turn, point P can influence points at later times 
lying within its zone of influence. In the parabolic case, shown in Figure 1.2 information travels 
downstream (or forward in time) only and so the domain of dependence of point P (x0, t0) in this case is 
the region t < t0 and the zone of influence is all points for which t > t0. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
13 
Introduction
Figure 1.1 Domain of dependence: hyperbolic case. 
Figure 1.2 Domain of dependence: parabolic case. 
x
BC 
P (x0, t0)
Domain of 
dependence
Zone of 
influence
IC
x+ct = const 
t
BC 
x-ct = const 
x
BC
P (x0, t0)
Domain of 
dependence 
Zone of 
influence
IC
t
BC
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
14 
Introduction
In the elliptic case, corresponding to subsonic flow (Figure 1.3), information travels in all directions at 
infinite speed so the solution at point P (x0, t0) influences all points within the domain and vice versa. 
Figure 1.3 Domain of dependence: elliptic case. 
Notice in this case that the whole region bounded by the BCs is both a domain of dependence and zone of 
influence.  
x
BC
P (x0, t0)
Domain of 
dependence 
Zone of 
influence 
BC
y
BC
BC
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

 
Introductory Finite Difference Methods for PDEs
15 
Introduction
The type of PDE fundamentally influences the choice of solution strategy. Time dependent hyperbolic 
problems and parabolic problems illustrated by Figures 1.1 and 1.2 are solved numerically by time-
marching methods which involves, as its name suggests, obtaining the numerical solution at a later time 
from that at an earlier time starting from given ICs.  
Elliptic problems, as illustrated in Figure 1.3 are solved numerically by so-called relaxation methods. 
1.5 Discrete Notation 
We will use upper case U to denote the analytic (exact) solution of the PDE and lower case u to denote the 
numerical (approximate) solution. Subscripts will denote discrete points in space and superscripts discrete 
levels in time. e.g. 
n
j,iu
 denotes the numerical solution at grid point (i, j) in a 2D region at time level n.  
1.6 Checking Results 
Before applying a numerical scheme to real life situations modelled by PDEs there are two important steps 
that should always be undertaken.  
1.6.1 Verification 
The computer program implementing the scheme must be verified. This is a check to see if the program is 
doing what it is supposed to do. Comparing results from pen and paper calculations at a small number of 
points to equivalent computer output is a way to (partially) verify a program. Give or take a small amount 
of rounding error the numbers should be the same. Another way to verify the program is to find an exact 
solution to the PDE for a simpler problem (if one exists) and compare numerical and exact results. 
Complete program verification involves testing that all branches, program elements and statements are 
executed and produce the expected outcomes. For large programs there exist software verification 
programs to facilitate the verification process. For a commercial solver it may not be possible to 
completely verify the program if the source code is unavailable. 
1.6.2 Validation 
Validation is really a check on whether the PDE is a good model for the real problem being studied. 
Validation means comparing numerical results with results from similar physical problems. Physical 
results may come from measurements from real life or from small-scale laboratory experiments. Either 
way, due to measurement errors, scaling problems and the inevitable failure of the PDEs to capture all the 
underlying physics, agreement between numerical and physical results will not be perfect and the user will 
have to decide what is ‘close enough’. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
16 
Introduction
1.7 Exercise 1 
1.  Assuming that t is time and x and y are spatial variables give the dimensions of the PDEs in a) to e) 
of Section 1.4. 
2.  Classify the following PDEs: 
a) 
xx
tt
U
2
U 
,       
 b) 
0
U
U
yy
xx


,    
c) 
0
U
U
xx
t


.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
• STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
• PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
• STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

 
Introductory Finite Difference Methods for PDEs
17 
Fundamentals
2. Fundamentals 
The finite difference method (FDM) works by replacing the region over which the independent variables 
in the PDE are defined by a finite grid (also called a mesh) of points at which the dependent variable is 
approximated. The partial derivatives in the PDE at each grid point are approximated from neighbouring 
values by using Taylor’s theorem. 
2.1 Taylor’s Theorem 
Let U(x) have n continuous derivatives over the interval (a, b). Then for a < xo, xo+h < b, 
)
h
(
O
)!
1
n
(
)
x
(
U
h
...
!2
)
x
(
U
h
)
x
(
U
h
)
x
(
U
)
h
x
(
U
n
o
)
1
n
(
1
n
o
xx
2
o
x
o
o










,     (2.1) 
where,

1
n
1
n
)
1
n
(
2
2
xx
x
dx
U
d
U
,
...
,
dx
U
d
U
,
dx
dU
U





.

)
x
(
U
o
x
 is the derivative of U with respect to x evaluated at x = xo.

O(hn) is an unknown error term defined in Appendix A. 
The usual interpretation of Taylor’s theorem says that if we know the value of U and the values of its 
derivatives at point xo then we can write down the equation (2.1) for its value at the (nearby) point xo+h. 
This expression contains an unknown quantity which is written in as O(h Pn
P) and pronounced ‘order h to the 
n’. If we discard the term O(hPn
P) in (2.1) (i.e. truncate the right hand side of (2.1)) we get an approximation
to U(xo+h). The error in this approximation is O(hPn
P).
2.2 Taylor’s Theorem Applied to the Finite Difference Method (FDM) 
In the FDM we know the U values at the grid points and we want to replace partial derivatives in the PDE 
we are solving by approximations at these grid points. We do this by interpreting (2.1) in another way. In 
the FDM both xo and xo+h are grid points and U(xo) and U(xo+h) are known. This allows us to rearrange 
equation (2.1) to get so-called Finite Difference (FD) approximations to derivatives which have O(hPn
P)
errors. Appendix A explains the meaning of O(hPn
P) notation. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
18 
Fundamentals
2.3 Simple Finite Difference Approximation to a Derivative 
Truncating (2.1) after the first derivative term gives, 
)
h
(
O
)
x
(
U
h
)
x
(
U
)
h
x
(
U
2
o
x
o
o




     (2.2) 
Rearranging (2.2) gives, 
)
3.3.
A
by
(
)
h
(
O
h
)
x
(
U
)
h
x
(
U
h
)
h
(
O
h
)
x
(
U
)
h
x
(
U
)
x
(
U
o
o
2
o
o
o
x








Neglecting the O(h) term gives, 
h
)
x
(
U
)
h
x
(
U
)
x
(
U
o
o
o
x



      (2.3) 
(2.3) is called a first order FD approximation to 
)
x
(
U
o
x
 since the approximation error = O(h) which 
depends on the first power of h. This approximation is called a forward FD approximation since we start 
at xo and step forwards to the point xo+h. h is called the step size (h > 0). 
2.4 Example: Simple Finite Difference Approximations to a Derivative 
This simple example shows that our forward difference approximation works and has the stated order of 
accuracy. We choose a simple function for U. Let U(x) = xP2
P. We will find the first order forward FD 
approximation to 
)
3
(
Ux
 using step size h = 0.1. From (2.3) the general first order forward FD 
approximation formula is, 
h
)
x
(
U
)
h
x
(
U
)
x
(
U
o
o
o
x



     (2.4) 
Substituting for U gives,   
h
x
)
h
x
(
)
x
(
U
2
o
2
o
o
x



Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
19 
Fundamentals
Replacing xo by 3 and h by 0.1 gives, 
1.6
1.0
3
)1.0
3
(
)
3
(
U
2
2
x




The exact answer from basic Calculus is clearly 
6
)
3
(
U x

 so the error in the approximation is  
6.1 – 6 = 0.1. Repeating the problem with h = 0.05 (i.e. half the step size) gives, 
05
.6
05
.0
3
)
05
.0
3
(
)
3
(
U
2
2
x




The error is 6.05 – 6 = 0.05. The approximation formula (2.4) is first order so the errors should be 
proportional to h which is seen to be the case: halving the step size results in a halving of the error. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
20 
Fundamentals
2.5 Constructing a Finite Difference Toolkit 
We now construct common FD approximations to common partial derivatives. For simplicity we suppose 
that U is a function of only two variables, t and x. We will approximate the partial derivatives of U with 
respect to x. As t is held constant U is effectively a function of the single variable x so we can use Taylor’s 
formula (2.1) where the ordinary derivative terms are now partial derivatives and the arguments are (t, x) 
instead of x. Finally we will replace the step size h by x (to indicate a change in x) so that (2.1) becomes, 
)
x
(
O
)
x
,t(
U
)!
1
n
(
x
...
)
x
,t(
U
!2
x
)
x
,t(
U
x
)
x
,t(
U
)
x
x
,t(
U
n
o
)
1
n
(
1
n
o
xx
2
o
x
o
o















(2.5a) 
Truncating (2.5a) to O(x2) gives, 
)
x
(
O
)
x
,t(
U
x
)
x
,t(
U
)
x
x
,t(
U
2
o
x
o
o







     (2.5b) 
Now we derive some FD approximations to partial derivatives. Rearranging (2.5b) gives, 
 
 
 
  
x
)
x
(
O
x
)
x
,t(
U
)
x
x
,t(
U
)
x
,t(
U
2
o
o
o
x








)
x
(
O
x
)
x
,t(
U
)
x
x
,t(
U
)
x
,t(
U
o
o
o
x








     (2.6a)
Equation (2.6a) holds at any point (t, xo). In numerical schemes for solving PDEs we are restricted to a 
grid of discrete x values, x1, x2, … , xN, and discrete t levels 0 = t0, t1, ... . We will assume a constant grid 
spacing, x, in x, so that xi+1 = xi + x. Evaluating Equation (2.6a) for a point, (tn, xi), on the grid gives, 
)
x
(
O
x
)
x
,
t(
U
)
x
,
t(
U
)
x
,
t(
U
i
n
1
i
n
i
n
x






     (2.6b) 
We will use the common subscript/superscript notation, 
)
x
,
t(
U
U
i
n
n
i 
     
(2.6c) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
21 
Fundamentals
so that dropping the O(x) error term, (2.6b) becomes, 
x
U
U
)
x
,
t(
U
n
i
n
1
i
i
n
x




     
(2.6d)
(2.6d) is the first order forward difference approximation to 
)
x
,
t(
U
i
n
x
 that we derived previously in 
approximation (2.4). We now derive another FD approximation to 
)
x
,
t(
U
i
n
x
. Replacing x by –x in 
(2.5b) gives, 
)
x
(
O
)
x
,t(
U
x
)
x
,t(
U
)
x
x
,t(
U
2
o
x
o
o







     (2.7a) 
Evaluating (2.7a) at (tn, xi) and rearranging as previously gives, 
x
U
U
)
x
,
t(
U
n
1
i
n
i
i
n
x



     (2.7b) 
(2.7b) is the first order backward difference approximation to 
)
x
,
t(
U
i
n
x
.
Our first two FD approximations are first order in x but we can increase the order (and so make the 
approximation more accurate) by taking more terms in the Taylor series as follows. Truncating (2.5a) to 
O(x3), then replacing x by -x and subtracting this new expression from (2.5a) and evaluating at (tn, xi)
gives, after some algebra, 
x
2
U
U
)
x
,
t(
U
n
1
i
n
1
i
i
n
x





     
(2.8) 
(2.8) is called the second order central difference FD approximation to 
)
x
,
t(
U
i
n
x
.
We could construct even higher order FD approximations to 
x
U  by taking even more terms in the Taylor 
series but we will stop at second order approximations to first order derivatives. 
Many PDEs of interest contain second order (and higher) partial derivatives so we need to derive 
approximations to them. We will restrict our attention to second order unmixed partial derivatives i.e. 
xx
U
.
Truncating (2.5a) to O(x4) gives, 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
22 
Fundamentals
)
x
(
O
)
x
,t(
U
!3
x
)
x
,t(
U
!2
x
)
x
,t(
U
x
)
x
,t(
U
)
x
x
,t(
U
4
o
xxx
3
o
xx
2
o
x
o
o











     
(2.9a)
Replacing x by -x in (2.9a) gives, 
)
x
(
O
)
x
,t(
U
!3
x
)
x
,t(
U
!2
x
)
x
,t(
U
x
)
x
,t(
U
)
x
x
,t(
U
4
o
xxx
3
o
xx
2
o
x
o
o











     
(2.9b)
Adding (2.9a) and (2.9b) gives, 
)
x
(
O
)
x
,t(
U
x
)
x
,t(
U
2
)
x
x
,t(
U
)
x
x
,t(
U
4
o
xx
2
o
o
o










     (2.10a) 
Evaluating (2.10a) at (tn, xi) and using our discrete notation gives, 
)
x
(
O
)
x
,
t(
U
x
U
2
U
U
4
i
n
xx
2
n
i
n
1
i
n
1
i








     (2.10b) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
“The perfect start 
of a successful, 
international career.”
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

 
Introductory Finite Difference Methods for PDEs
23 
Fundamentals
Rearranging (2.10b) and dropping the O(x2) error term gives, 
2
n
1
i
n
i
n
1
i
i
n
xx
x
U
U
2
U
)
x
,
t(
U






     (2.11) 
(2.11) is the second order symmetric difference FD approximation to 
)
x
,
t(
U
i
n
xx
. These results are put 
into Table 2.1 to form a FD approximation toolkit. FD approximations to partial derivatives with respect 
to t are derived in a similar manner and are included in Table 2.1.  
partial derivative 
finite difference approximation 
type 
order 
x
U
x
U 


x
U
U
n
i
n
1
i



forward 
first in x 
x
U
x
U 


x
U
U
n
1
i
n
i



backward 
first in x 
x
U
x
U 


x
2
U
U
n
1
i
n
1
i




central 
second in x 
xx
2
2
U
x
U 


2
n
1
i
n
i
n
1
i
x
U
U
2
U





symmetric 
second in x 
t
U
t
U 


t
U
U
n
i
1
n
i



forward 
first in t 
t
U
t
U 


t
U
U
1
n
i
n
i



backward 
first in t 
t
U
t
U 


t
2
U
U
1
n
i
1
n
i




central 
second in t  
tt
2
2
U
t
U 


2
1
n
i
n
i
1
n
i
t
U
U
2
U





symmetric 
second in t 
Table 2.1 Finite Difference Toolkit for Partial Derivatives 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
24 
Fundamentals
The above FD toolkit can be used to create a finite difference scheme (FDS) to obtain the approximate solution 
of a large number of PDEs simply by replacing each partial derivative by an appropriate FD approximation.  
2.6 Simple Example of a Finite Difference Scheme 
We construct a simple FDS to find an approximate solution of a simple PDE. This PDE will be studied in 
more detail in Chapter 4. For now it suffices to generate a simple FDS to provide motivation for further 
study. The 1D linear advection equation is,  
Ut + v Ux = 0,     (2.12a) 
where the independent variables are t (time) and x (space). x is restricted to the finite interval [p, q] which 
is called the computational domain. v is a constant and the dependent variable, U = U(t, x). In addition to 
the PDE, we need initial conditions for U. Let the initial conditions be,  
U(0, x) = f(x), 
.q
x
p


     (2.12b) 
i.e. the initial value of U is given for every x value in the computational domain by a known function f(x).  
A solution to (2.12a, 2.12b) is a function U = U(t, x) which satisfies the PDE (2.12a) at all points x in the 
computational domain and all times t and the initial conditions (2.12b). U(t, x), the exact solution of 
(2.12a,b), is defined at an infinite number of values of the independent variables t and x. We will create a 
FDS to approximate U at a finite set of values of the independent variables. The approximate values of U 
on this finite set will be denoted by u. We proceed in stages. 
2.6.1 Step 1: Spatial Discretisation 
The computational domain (Figure 2.1) contains an infinite number of x values so first we must replace 
them by a finite set. This process is called spatial discretisation. 
Figure 2.1: 1D computational domain.
For simplicity the computational domain is replaced by a grid of N equally spaced grid points. Starting with 
the first grid point at x = p and ending with the last grid point at x = q, the constant grid spacing, x, is,  
)1
N
(
)
p
q
(
x




     (2.13a) 
p 
q 
x
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
25 
Fundamentals
The values of x in the discretised computational domain are indexed by subscripts to give, 
x1 = p,x2 = p + x, … , xi = p + (i-1)x, … , xN = p + (N-1)x = q.     (2.13b) 
Since the grid spacing is constant, 
xi+1 = xi + x     (2.13c) 
The discretised computational domain is shown in Figure 2.2: 
Figure 2.2 Discretised computational domain. 
xN=q
* 
* 
*
*
x
p=x1
…
*
x2
x3
xN-1
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
▶▶enroll by September 30th, 2014 and 
▶▶save up to 16% on the tuition!
▶▶pay in 10 installments / 2 years
▶▶Interactive Online education
▶▶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

 
Introductory Finite Difference Methods for PDEs
26 
Fundamentals
Fixing t at t = tn we approximate the spatial partial derivative, 
x
U , in (2.12a) at each point (tn, xi) using 
the forward difference formula from the toolkit in Table 2.1 to give,
x
U
U
)
x
,
t(
U
n
i
n
1
i
i
n
x




     (2.14) 
Replacing 
x
U  in (2.1a) by its approximation (2.14) gives, 
0
x
U
U
v
U
n
i
n
1
i
t





     
(2.15) 
(2.15) is said to be in semi-discrete form since only the spatial derivative has been discretised. 
Note: The grid is also called the mesh and the operation of discretising the computational domain is called 
gridding or meshing.
2.6.2 Step 2: Time Discretisation 
Fixing x at x = xi we approximate the temporal partial derivative, 
t
U , in (2.12a) at each point (tn, xi) using 
the first order forward difference formula from the toolkit in Table 2.1 (where t is the spacing between 
time levels) to give, 
t
U
U
U
n
i
1
n
i
t




     (2.16) 
On substituting (2.16) for Ut, 2.15 becomes, 
0
x
U
U
v
t
U
U
n
i
n
1
i
n
i
1
n
i








     
(2.17a) 
which rearranges to give, 


n
i
n
1
i
n
i
1
n
i
U
U
x
t
v
U
U







     (2.17b) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
27 
Fundamentals
Equation (2.17b) is an example of a FDS to approximate the solution of the PDE (2.12a). (2.17b) is a so-
called time-marching scheme which enables U values at time level n+1 to be approximated from U values 
at the previous time level n. Since all U values are only known exactly at the initial time level (2.17b) is 
rewritten as, 


n
i
n
1
i
n
i
1
n
i
u
u
x
t
v
u
u







     
(2.18) 
where
n
iu  is an approximation to 
).
x
,
t(
U
U
i
n
n
i 
Notes: 
1.
(2.18) holds for each grid point xi, i = 1, 2, … , N. u(tn, xi) is a numerical approximation to  
U(tn, xi), the exact solution of the PDE (2.1a).  
2.
u(0, xi) = U(0, xi) but this will not be true in general for later times. 
3.
u values on the right hand side of (2.18) are all at time tn whereas on the left hand side u values are all 
at the next timed level tn + t = tn+1
4.
(2.18) is an example of a time-marching scheme in that (known) data for each grid point at time tn is 
used to find data at each grid point at the future time tn + t. This is called an iteration of the scheme. 
After an iteration of the scheme all u values at each grid point are known at time tn + t. These new 
values can be used as known data for another iteration of the scheme to give data for each grid point 
at the next time level. This process can be repeated until the required future time is attained. Iterations 
of (2.18) are performed by a computer program. 
5.
The errors in approximating the spatial and temporal derivatives which are used to get (2.18) are 
O(x) and O(t) respectively and so (2.18) is said to be (formally) first order in space (x) and first 
order in time (t). 
6.
The grid spacing, x, was determined by choosing the number of grid points, N. A larger N gives a 
smaller x and a (hopefully) more accurate solution as spatial derivatives are more accurately 
approximated. However as N increases compute time increases so there is a trade off between 
accuracy and speed.  
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
28 
Fundamentals
7.
The time step, t, is for the moment, chosen arbitrarily. However a smaller time step will mean that 
more iterations of (2.18) are needed to reach a stated future time which will obviously increase the 
compute time. In addition, since the result of each iteration is an approximation to the required 
solution, more iterations could cause the build up of more error. We will see later (Chapter 4 and 
Appendix C) that there is often a limit to the maximum size of a time step. 
8.
(2.18) is said to be an explicit method since the value of u at the next time level is given by an explicit 
formula for each grid point. 
9.
Later we will see that (2.18) doesn’t work for v > 0! There is more to FDS than meets the eye!  
2.7 Pen and Paper Calculation (very important) 
In practice numerical schemes are implemented by writing then running a computer program. Before 
doing this it is extremely useful to work through a pen and paper calculation for two reasons:  
1.
To check understanding of the scheme. 
2.
To be able to check results from the computer program against pen and paper results (verification). 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
29 
Fundamentals
Since we are doing a pen and paper calculation we will only use a small number of grid points. In a 
computer implementation of the calculation we would use many more grid points (hundreds, thousands, 
perhaps millions) for accuracy. We now set up a simple problem. 
Let p=0 and q=100, v=0.5 and let the initial conditions be, 








.
elsewhere
,0
,
70
x
20
,
e
)
x
,0
(
U
2
)
45
x
(
01
.0
     
(2.19) 
Note that there is nothing special or realistic about these initial conditions. 
Let the (small) number of grid points be N = 11. Then by (2.13a), 
10
)1
11
(
)
0
100
(
x





.
The subscripts for the grid values go from 1 to 11 and are entered into the first row of Table 2.2. The actual x 
values of the corresponding grid points are 0, 10, 20, 30, … , 90, 100 and are entered into the second row of 
Table 2.2. It remains to choose the time step t. Quite arbitrarily let t = 3. Then (2.18) becomes, 


n
i
n
1
i
n
i
1
n
i
u
u
15
.0
u
u





     (2.20)
(2.20) is a FDS for calculating the solution to our problem at the next time level using data at the current 
time level. We start at time t0=0, i.e. n = 0, hence (2.20) becomes, 


0
i
0
1
i
0
i
1
i
u
u
15
.0
u
u




     (2.21)
Time level zero corresponds to the initial conditions. The initial u values are needed at the computational 
grid points. i.e. we need to know 
0
iu  for i = 1, 2, …, 11. In general 
n
iu is only an approximation to the 
exact solution U(tn, xi) but at time t0=0,
0
iu = U(0, xi).
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
30 
Fundamentals
Using the initial conditions we get, 









.
elsewhere
,0
,
70
x
20
,
e
)
x
,0
(
U
u
2
)
45
x
(
01
.0
i
0
i
i
     (2.22) 
Evaluating (2.22) at a few grid points gives, 
0
)
0,0
(
U
)
x
,0
(
U
u
1
0
1



,
7788
.0
e
)
40
,0
(
U
)
x
,0
(
U
u
2
)
45
40
(
01
.0
5
0
5






, etc. 
These initial values, 
0
iu , are entered into the third row of Table 2.2.  
i 
1 
2 
3 
4 
5  
6 
7 
8 
9 
10 
11 
12 
xi
0 
10 
20 
30 
40 
50 
60 
70 
80 
90 
100 
110 
ui
0
0 
0 
0.0019 
0.1054 
0.7788 
…….  
…….
……. 
0 
0 
0 
0
ui
1 
0 -0.00029 
-0.01363 
 
 
 
 
 
 
 
0 
ui
2 
 
 
 
 
 
 
 
 
 
 
 
Table 2.2 Implementation of Finite difference Scheme (2.20) 
Having set up the initial data we use (2.21) to find ui
1 i.e. the u values at the next time level at each grid 
point. These new values are entered into the fourth row of Table 2.2. The first few values are found from 
the following:  
Putting i = 1 into (2.21) gives: 


0
1
0
2
0
1
1
1
u
u
15
.0
u
u



 = 0 – 0.15 (0 – 0) = 0 
Putting i = 2 into (2.21) gives: 


0
2
0
3
0
2
1
2
u
u
15
.0
u
u



= 0 – 0.15 (0.0019 – 0) = - 0.00029 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
31 
Fundamentals
Putting i = 3 into (2.21) gives: 


0
3
0
4
0
3
1
3
u
u
15
.0
u
u



= 0.0019 – 0.15 (0.1054 - 0.0019) = -0.01363 
etc.  
However there is a problem! We are using forward differences for the spatial derivatives, i.e. to 
approximate the spatial derivative at a grid point we need the function value at the next grid point. This is 
OK for interior grid points but when we come to the last point on the right hand boundary of the 
computational domain (point index i = 11 corresponding to q = 100) we need data at point index i = 12 
which we DO NOT HAVE! In this case we have to invent a fictitious point with an associated function 
value. These points are called ghost points and the function values, ghost values. How we invent ghost 
values is based on the boundary conditions that define the particular problem we are solving. This topic is 
discussed in more detail in Appendix B. In our case we will assume that ghost point is at x12 = 110 and that 
the u value at this point takes the same value as its value at the nearest interior point (i.e. x11) at all times.
i.e. 
,...
2,1,0
n
,
u
u
n
11
n
12


     (2.23) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

 
Introductory Finite Difference Methods for PDEs
32 
Fundamentals
Now we can use our numerical scheme to calculate 
1
11
u
.
Putting i = 11 into (2.21) gives:  


0
11
0
12
0
11
1
11
u
u
15
.0
u
u



 = 0 – 0.15 (0 – 0) = 0
This completes the first iteration of the FDS (2.21) and row 4 of Table 2.2 and we have found the 
approximate solution at each grid point at  
t = t1= t = 3. 
Once all the values of 
1
iu have been calculated the same procedure can be used to find 
2
iu by a second 
iteration: the time indices in equation (2.21) are increased by 1 to give, 


1
i
1
1
i
1
i
2
i
u
u
15
.0
u
u




     (2.24) 
and we repeat the previous process to fill in row 5 of Table 2.2 which is the approximate solution at each 
grid point at t = t2= 2t = 6. 
By successive iteration of (2.20), the solution can be found at each grid point at future time levels. At each 
iteration we use the known data at a particular time level to obtain the unknown data at the next time level. Of 
course this iterative procedure can be automated. A computer program for this scheme is given on the website.  
2.8 Exercise 2a 
1.
U(x) = xP2
P. Find the first order backward difference approximations to 
)
3
(
Ux
 using: a) h = 0.1,  
b) h = 0.05, c) h = 0.025 . 
2.
Repeat Q1a), b), c) using the central FD approximation and show that it is second order accurate. 
3.
Following the text, derive the central FD approximation to a first order spatial derivative. 
4.
Following the text, derive the symmetric FD approximation to a second order spatial derivative. 
5.
Using exactly similar working for the spatial approximations derive all the time derivative 
approximation in Table 2.1. 
6.
Complete Table 2.2 by carrying out pen and paper calculations (tedious but very important for 
checking your numerical algorithm). 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
33 
Fundamentals
2.9 Exercise 2b 
1.
From the website download a computer program to implement (2.20) for the given problem.  
2.
Read each line of the program and make sure you understand it. This program will be used as the 
basis for other programs later on. 
3.
Verify the program by comparison to Table 2.2.  
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Master’s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top master’s programmes
• 33rd place Financial Times worldwide ranking: MSc 
International Business
• 1st place: MSc International Business
• 1st place: MSc Financial Economics
• 2nd place: MSc Management of Learning
• 2nd place: MSc Economics
• 2nd place: MSc Econometrics and Operations Research
• 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier ‘Beste Studies’ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

 
Introductory Finite Difference Methods for PDEs
34 
Elliptic Equations
3. Elliptic Equations 
3.1 Introduction 
Elliptic PDEs form a class of PDEs that may be used to model steady state problems (i.e. the dependent 
variable remains constant over time). Solutions of elliptic PDEs are over closed regions on which boundary 
values are given in some way. These boundary values determine the solution of the PDE in the interior of the 
region. The two most widely used elliptic PDEs are Laplace’s equation and Poisson’s equation.  
In 2D, Laplace’s equation is: 
0
U
U
yy
xx


     (3.1) 
Laplace’s equation may be used to model a wide range of phenomena including steady state groundwater 
flow and temperature distribution over a region. Additionally Laplace’s equation can describe ‘potential 
flow’ which can be used in a simplified description of water flow amongst other things.  
In 2D, Poisson’s equation is: 
)
y
,x
(
f
U
U
yy
xx


.     (3.2) 
Poisson’s equation may also be used to model a wide range of phenomena including gravitational fields, 
stress patterns and simplified viscous flow. 
The above PDEs can only be solved analytically for simple situations so we need to use numerical 
methods to obtain approximate solutions for cases of practical interest. In the following we focus on 
Laplace’s equation since it is simpler than Poisson’s equation and the techniques carry over easily. For 
simplicity the computational domain will be rectangular. 
3.2 Finite Difference Method for Laplace’s Equation 
The computational domain is discretised using constant grid spacings of x and y in the x and y 
directions respectively. Grid points are indexed by (i, j) in the usual way and the approximate value of U 
at grid point (i, j) is denoted by ui,j . Figure 3.1 shows a rectangular grid with M and N grid points in the x 
and y directions respectively. u is known (=U) at the boundary grid points. It is required to find u at the 
interior grid points. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
35 
Elliptic Equations
Figure 3.1: Computational grid showing interior grid points (black) and boundary grid points (white)
Each partial derivative in Equation (3.1) is replaced by a symmetric FD approximation from our tool kit 
(Table 2.1) to give, 
2
j,1
i
j,i
j,1
i
x
u
u
2
u





 + 
0
y
u
u
2
u
2
1
j,i
j,i
1
j,i






     (3.3a) 
Letting b = x/y, (3.3a) can be rewritten to give, 
)
b
1(
2
u
b
u
b
u
u
u
2
1
j,i
2
1
j,i
2
j,1
i
j,1
i
j,i









     (3.3b) 
Equation (3.3b) shows that ui,j depends on its 4 surrounding values. This is called a 5-point stencil. 
Sometimes ‘compass notation’ is used and (3.3b) becomes, 
)
b
1(
2
u
b
u
b
u
u
u
2
S
2
N
2
W
E
o





     (3.3c) 
where o denotes the current grid point and subscripts N, S, E and W denote its north, south, east and west 
neighbours respectively. 
j
y
i
x
2,2  
3,2
4,2
2,3  
3,3
2,1
1,1
1,2
M,N
1,N
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
36 
Elliptic Equations
Notes: 
1.
Using the indexing system in Figure 3.1 the unknown value of u nearest to the bottom left hand 
corner of the computational domain is u2,2 and the unknown value nearest to the top right hand corner 
of the computational domain is uM-1,N-1.
2.
In an MxN grid there will be (M-2)x(N-2) unknown interior values of ui,j which may be a very large 
number. 
3.
Assuming that the boundary values of u are known then (3.3b) gives a system of (M-2)x(N-2) linear 
equations for ui,j in (M-2)x(N-2) unknowns. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
37 
Elliptic Equations
3.3 Setting up the Equations 
There are two basic methods of solving for ui,j. Both methods set up a system of linear equations as 
follows. Letting c = 1/(2(1+b2)),  
d = b2/(2(1+b2)), rearranging Equation (3.3b) gives, 
j,1
i
1
j,i
1
j,i
j,1
i
j,i
u
c
u
d
u
d
u
c
u








     (3.4) 
Evaluating Equation (3.4) at successive grid points starting at 2,2 and sweeping along the rows first gives, 
1
N
,
M
N
,1
M
2
N
,1
M
1
N
,2
M
1
N
,1
M
3,3
4
,2
2
,2
3,1
3,2
2
,
M
3,1
M
1,1
M
2
,2
M
2
,1
M
2
,4
3,3
1,3
2
,2
2
,3
2
,3
3,2
1,2
2
,1
2
,2
u
c
u
d
u
d
u
c
u
u
c
u
d
u
d
u
c
u
u
c
u
d
u
d
u
c
u
u
c
u
d
u
d
u
c
u
u
c
u
d
u
d
u
c
u










































     (3.5) 
The boundary values u1,2, u2,1, uM,2, u1,3, etc. are known. In each equation the known u values are moved to 
the left hand side and the unknown u values moved to the right hand side (and positioned to preserve the 
ordering). For example in the first equation u1,2 and u2,1 are known (being boundary values) so the 
equation becomes, 
2
,3
3,2
2
,2
1,2
2
,1
u
c
u
d
u
u
d
u
c






The result is that Equations (3.5) can be written as a single matrix equation, 
d = A u     (3.6a) 
where,
d is an (M-2)(N-2) by 1 matrix of known constants, 
A is a (M-2)(N-2) by (M-2)(N-2) matrix of known coefficients and  
u is a (M-2)(N-2) by 1 matrix of unknowns and 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
38 
Elliptic Equations
u = (u2,2 u3,2 … u(M-1),2 u2,3 u3,3 … u(M-1),3 ... ... u(M-1),(N-1))T.
The solution to (3.6a) may be written symbolically as, 
u = A-1 d     (3.6b) 
As A may be very large we must study efficient ways of finding u.
3.4 Grid Convergence 
Before looking at solution methods we make the following important point which applies to all grid-based 
numerical schemes. Clearly the accuracy of the numerical results depends on the size of the computational 
grid. Ideally we would like a grid converged solution i.e. a solution that does not change significantly 
when more grid points are used. Grid converged solutions can be studied formally by grid convergence 
indices but for us it is enough to compare numerical solutions with more and more grid points until there 
is no significant difference. A good strategy is to implement a scheme using a small number of grid points 
(for verification of the program) then successively double the number of grid points until numerical results 
don’t change perceptibly. In this way we can be confident that inaccuracies in the numerical solution are 
not caused by the grid. We present other questions about the accuracy of schemes in Appendix C that is 
best read later.  
3.5 Direct Solution Method 
One way to achieve a solution of (3.6a) is by using standard Gaussian elimination. This is a so-called 
direct method. 
Note: 
We state again that in our convention the grid is traversed from left to right starting at the bottom, i.e. we 
start at position (2, 2) go along the whole row, repeat for the next row etc. and eventually end at position 
(M-1, N-1). 
The direct method is illustrated by an example on a small grid (much too small for a real computation but 
useful for verification of a program). Consider the following 5 by 4 grid of u values where  
x = y,
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
39 
Elliptic Equations
Figure 3.2 Boundary (white) and interior (shaded) u values on a 5x4 grid. 
u2,2
u3,2
u4,2
u2,3
u3,3
u4,3
6.1
7.2
8.4
8.9
8.9
8.9
7.7
6.8
8.9
8.7
8.9
9.4
9.8
9.2
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

 
Introductory Finite Difference Methods for PDEs
40 
Elliptic Equations
The u values at the boundary grid points are known, e.g. u1,1 = 6.1. We want to find the unknown values of 
u at the interior grid points, i.e. u2,2, u3,2, u4,2, u2,3, u3,3, u4,3. Since x = y, Equation (3.4) simplifies to, 

4
/
u
u
u
u
u
j,1
i
1
j,i
1
j,i
j,1
i
j,i








     (3.7a) 
In compass notation this is written,  

4
/
u
u
u
u
u
E
N
S
W
o




     (3.7b) 
Starting on the second row, evaluation of (3.7a) at grid point (2, 2) gives, 
u2,2 = (u1,2 + u2,1 + u2,3 + u3,2 )/4 = (7.2 + 6.8 + u2,3 + u3,2 )/4     (3.8a) 
Evaluation of (3.7a) at grid point (3, 2) gives, 
u3,2 = (u2,2 + u3,1 + u3,3 + u4,2 )/4 = (u2,2 + 7.7 + u3,3 + u4,2 )/4     (3.8b) 
Evaluation at grid point (4, 2) gives, 
u4,2 = (u3,2 + u4,1 + u4,3 + u5,2 )/4 = (u3,2 + 8.7 + u4,3 + 9.4 )/4     (3.8c) 
Moving to the next (third) row, evaluation of (3.7a) at grid point (2, 3) gives, 
u2,3 = (u1,3 + u2,2 + u2,4 + u3,3 )/4 = (3.4 + u2,2 + 8.9 + u3,3)/4     (3.8d) 
Evaluation of (3.7a) at grid point (3, 3) gives, 
u3,3 = (u2,3 + u3,2 + u3,4 + u4,3 )/4 = (u2,3 + u3,2 + 8.9 + u4,3)/4     (3.8e) 
Finally evaluation of (3.7a) at grid point (4, 3) gives (fill in this for yourself),     (3.8f) 
These equations can be written out in standard form as 6 simultaneous linear equations in which the order 
of the unknown variables is as above i.e. u2,2, u3,2, u4,2, u2,3, u3,3, u4,3.
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
41 
Elliptic Equations
Rewriting Equation (3.8a) in standard form gives, 
-14/4 = -1 u2,2 + (1/4) u3,2 + 0 u4,2 + (1/4) u2,3 + 0 u3,3 + 0 u4,3 
Rewriting Equation (3.8b) in standard form gives, 
-7.7/4 = (1/4) u2,2 -1 u3,2 + (1/4) u4,2 + 0 u2,3 + (1/4) u3,3 + 0 u4,3
Equations (3.8c-f) are rewritten similarly. The 6 simultaneous linear equations are then written as the 
matrix equation, 





























































3,4
3,3
3,2
2
,4
2
,3
2
,2
u
u
u
u
u
u
0
4
/
1
0
4
/
1
1
4
/
1
0
0
4
/
1
0
4
/
1
1
4
/
7.7
4
/
14







     (3.9) 
which can be solved by standard Gaussian elimination. For large systems this isn’t very efficient so we 
will study efficient iterative methods next. 
3.6 Exercise 3a 
1.
Finish labelling all the grid points in Figure 3.1. 
2.
Check that (3.3a) is correct by referring back to the FD toolkit in Table 2.1. 
3.
Derive (3.3b) from (3.3a). 
4.
Given that x = 4 and y = 2, write down the expression for u3,4 using both subscript and compass 
notation. 
5.
Write down Equation (3.8f) in the space provided in the notes. 
6.
a) Write down Equations (3.8c-f) in the standard way. 
b) Hence complete the matrix equation (3.9). 
7.
Solve (3.9) by Gaussian elimination and check your solution by back substitution. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
42 
Elliptic Equations
3.7 Iterative Solution Methods 
Equation (3.9) can be expressed as, 
A u = b    (3.10)
For practical problems A is likely to be a large matrix which makes the direct solution of (3.10) 
computationally inefficient. More efficient methods use iterative approaches where an initial estimate for 
u is updated to form a better estimate. The process is repeated until the distance between successive 
estimates is less than some pre-defined tolerance (assuming that the iterative process converges to the 
solution). Since the output from each iteration is a vector of u values we define what is meant by distance 
between vectors as follows. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planet’s 
electricity needs. Already today, SKF’s innovative know-
how is crucial to running a large proportion of the 
world’s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

 
Introductory Finite Difference Methods for PDEs
43 
Elliptic Equations
3.7.1 Distance between Vectors 
Let x =(x1, x2, … , xN) and y =(y1, y2, … , yN) be two vectors in RN. The distance between x and y is 
denoted by d(x , y) and defined by, 







|
y
x|
|
y
x
|
max
)
y,x
(
d
i
i
i
     (3.11) 
(this is sometimes called the ‘infinity norm’). 
e.g. x = (1, 3, 5), y = (4, 5, 3),
3
)|
3
5
|
|,
5
3
|
|,
4
1
|
max(
|
y
x|







.
In the following we illustrate three variants of the iterative approach with respect to the test problem of 
Figure 3.2 where x = y. 
When x = y, our 5-point formula is, 

4
/
u
u
u
u
u
j,1
i
1
j,i
1
j,i
j,1
i
j,i








     (3.12)
3.8 Jacobi Iteration 
We introduce the iteration index as a superscript, m, and write (3.12) as the Jacobi formula (also called the 
point-Jacobi formula),  

4
/
u
u
u
u
u
m
j,1
i
m
1
j,i
m
1
j,i
m
j,1
i
1
m
j,i









     (3.13)
(Note that this formula assumes x = y). 
For each interior grid point (i, j), ui,j at the next iteration (m+1) is found from (3.13). Once an iteration has 
been completed for all interior grid points we compute the distance between vectors um+1 and um. If, 
tol
|
u
u|
m
1
m




,     (3.14) 
where tol is a pre-defined tolerance, the iterations terminate and the solution to (3.10) is um+1 otherwise the 
iterations continue. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
44 
Elliptic Equations
To start the iteration (at index 0) values must be given for the unknown interior values of ui,j. These values 
can be set to zero or interpolated from the known boundary values. The following example of Jacobi 
iteration applies to the previous ‘test problem’ with all interior starting values set to zero and a tolerance 
of 0.5 x 10-3.
3.8.1 First Iteration  
Equation (3.13) with m=0 gives, 

4
/
u
u
u
u
u
0
j,1
i
0
1
j,i
0
1
j,i
0
j,1
i
1
j,i








Evaluating at each interior grid point gives, 




500
.3
4
/
0
0
8.6
2.7
4
/
u
u
u
u
u
0
2
,3
0
3,2
0
1,2
0
2
,1
1
2
,2













925
.1
4
/
0
0
7.7
0
4
/
u
u
u
u
u
0
2
,4
0
3,3
0
1,3
0
2
,2
1
2
,3









, similarly 
.
525
.4
u,
225
.2
u
,
325
.4
u
,
525
.4
u
1
3,4
1
3,3
1
3,2
1
2
,4




     (3.15) 
Having completed the first iteration we test for convergence. i.e. we measure how close u0 is to u1.
u0 = (0, 0, 0, 0, 0, 0), u1 = (3.5, 1.925, 4.525, 4.325, 2.225, 4.525), 
therefore, 
This is greater than the specified tolerance of 0.5 x 10-3 so the iteration is repeated to find u2 etc. 
Eventually (we hope!) after p iterations,  
3
1
p
p
10
x
5.0
|
u
u|





and the iterative procedure terminates. The solution is up.
A program to implement Jacobi iteration is available from the website. 

|
0
525
.4||,
0
225
.2||,
0
325
.4||,
0
525
.4
||,
0
925
.1
||,
0
5.3
|
max
|
u
u|
0
1









Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
45 
Elliptic Equations
3.9 Gauss-Seidel Iteration 
This is a potentially more efficient version of Jacobi iteration. We note that in Equation (3.13) some of the 
updated ui.j values are already available for use in the iteration formula. In our way of traversing the grid 
when we reach grid position (i, j) we have already updated ui-1,j and ui,j-1 therefore we can use these values 
in the 5-point formula which becomes, 

4
/
u
u
u
u
u
m
j,1
i
m
1
j,i
1
m
1
j,i
1
m
j,1
i
1
m
j,i











     (3.16) 
(Note that this formula assumes that x = y). 
This is called the Gauss-Seidel formula (also called point-Gauss-Seidel) and the implementation is the 
same as for Jacobi. As an example of Gauss-Seidel iteration we repeat the previous problem using starting 
u values of zero (and where we don’t yet have an updated u value we use its current value). 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
46 
Elliptic Equations
3.9.1 First Iteration  
Equation (3.16) with m=0 gives, 

4
/
u
u
u
u
u
0
j,1
i
0
1
j,i
1
1
j,i
1
j,1
i
1
j,i








Evaluating at each interior grid point gives, 


.4
/
u
u
u
u
u
0
2
,3
0
3,2
1
1,2
1
2
,1
1
2
,2




Note that we don’t have
1
1,2
1
2
,1
u,
u
 yet so we use 
0
1,2
0
2
,1
u,
u
to give,  
                                             




.
500
.3
4
/
0
0
8.6
2.7
4
/
u
u
u
u
0
2
,3
0
3,2
0
1,2
0
2
,1









              

4
/
u
u
u
u
u
0
2
,4
0
3,3
1
1,3
1
2
,2
1
2
,3




Note that we now have 
1
2
,2
u
but not 
,
u1
1,3
so we use 
,
u1
1,3
to give, 
           
 
                        




8.2
4
/
0
0
7.7
5.3
4
/
u
u
u
u
0
2
,4
0
3,3
0
1,3
1
2
,2









                    

4
/
u
u
u
u
u
0
2
,5
0
3,4
1
1,4
1
2
,3
1
2
,4




Note that we now have 
1
2
,3
u
but not 
,
u1
1,4
so we use 
,
u1
1,4
to give, 
                         




225
.5
4
/
4.9
0
7.8
8.2
4
/
u
u
u
u
0
2
,5
0
3,4
0
1,4
1
2
,3









(3.17) 
The remaining values are calculated similarly. 
Notes: 
1.  We are assuming that the iterative procedures converge – this needs further study. 
2.  For simplicity we have taken x = y. It is a simple matter to generalise the iterative formulae for the 
case of different grid spacing in the x and y directions (start from Equation (3.4)). 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
47 
Elliptic Equations
3.  It is quite tricky to write a general program for an M by N mesh. The difficult part is to map the  
(M-2)x(N-2) array of interior grid values to a system of (M-2)(N-2) linear equations in (M-2)(N-2) 
unknowns. 
3.10 Exercise 3b 
1.  Check the direct solution to (3.9) by using Scilab (or Matlab). 
2.  Find 

|
y
x|
 for x=(1,3,5,8,4,-2,4,0,2), y=(2,-4,4,1,4,2,-3,0,2). 
3.  Using pen and paper perform a second iteration for each unknown for the Jacobi test problem 
(equations (3.15)). 
4.  Write a program to implement Jacobi iteration for the test problem above and verify by comparison 
to your pen and paper calculations (and by comparison to the direct solution). Comparison programs 
can be found from the website. 
5a.  Using pen and paper complete the first iteration of the Gauss-Seidel calculations for the test problem. 
5b.  Perform a second iteration. 
6a.  Write a program to implement Gauss-Seidel iteration for the test problem using zero starting values 
and verify by comparison to 5a,b.  
6b.  For a given tolerance compare the number of iterations taken using Gauss-Seidel and Jacobi methods 
for the test problem. 
7.  Write a Jacobi iterative solver for a general rectangular grid and validate it on the test problem  
(a program is available on the website for comparison). 
8.  Repeat Q7. using a Gauss-Seidel iterative solver (a program is available on the website for 
comparison). 
3.11 Successive Over Relaxation (SoR) Method 
The idea behind this method is that in an iterative formula the point value at the new iteration depends on 
the old point value plus some error (residual) at that point.  
i.e. 
 
m
j,i
m
j,i
1
m
j,i
R
u
u



     (3.18) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
48 
Elliptic Equations
m
j,i
R
 is the difference between successive iterates of ui,j and is called the residual. It might be possible to 
speed up the convergence of the iterative scheme by weighting the residual on the right hand side of (3.18) 
appropriately. We write, 
m
j,i
m
j,i
1
m
j,i
R
w
u
u



     (3.19) 
w is called a relaxation parameter. For 0 < w < 1 (3.19) corresponds to under-relaxation and for  
1 < w < 2 (3.19) corresponds to over-relaxation. This idea is applied to improve the point-Gauss-Seidel 
method. The point-Gauss-Seidel iteration formula (for x = y) is,´ 

4
/
u
u
u
u
u
m
j,1
i
m
1
j,i
1
m
1
j,i
1
m
j,1
i
1
m
j,i











     (3.20) 
which can be re-written as, 

4
/
u
u
u
4
u
u
u
u
m
j,1
i
m
1
j,i
m
j,i
1
m
1
j,i
1
m
j,1
i
m
j,i
1
m
j,i













     (3.20a) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
49 
Elliptic Equations
which is the of the same form as (3.18) with, 

4
/
u
u
u
4
u
u
R
m
j,1
i
m
1
j,i
m
j,i
1
m
1
j,i
1
m
j,1
i
m
j,i











     (3.20b) 
Hence we may convert this to, 

4
/
u
u
u
u
w
u
)
w
1(
u
m
j,1
i
m
1
j,i
1
m
1
j,i
1
m
j,1
i
m
j,i
1
m
j,i













     (3.21) 
which is called the (point) SoR method. This method is implemented in the same way as the previous 
iterative methods. If w = 1 (3.21) reduces to the Gauss-Seidel method. The question is what is the best 
choice of w for fastest convergence? This is a difficult question to answer in general and we must use 
numerical experiments to find an approximate best value. For the interested reader some convergence 
analysis for the three iterative methods is given in Appendix D. 
3.12 Line SoR 
As we shall see next, the use of a classical tridiagonal matrix method can greatly improve the efficiency of 
the previous SoR method. This is because we can update the solution along a whole line of grid points at 
once instead of simply point by point, hence the name line SoR. The line of grid points will normally be a 
whole row or column in the grid. We start from the finite difference toolkit approximation to Laplace’s 
equation in compass notation (3.3c) 
)
b
1(
2
)
u
u
(
b
u
u
u
2
1
m
S
m
N
2
1
m
W
m
E
1
m
O








     (3.22) 
where we have introduced the iteration index m and assumed the usual ordering working through the grid 
points left to right and bottom to top. (3.22) is the Gauss-Seidel method (3.16) in compass notation on a 
rectangular mesh with b = x/y. The corresponding point SoR method is, 

)
u
u
(
b
u
u
)
b
1(
2
w
u
)
w
1(
u
1
m
S
m
N
2
1
m
W
m
E
2
m
O
1
m
O










     (3.23) 
which is the compass notation form of (3.21) on a rectangular mesh. We proceed by moving the East and 
West terms onto the left hand side, with the East term written at the m+1 level, i.e. (3.23) becomes, 
O
1
m
W
1
m
E
1
m
O
2
b
wu
wu
u
)
b
1(
2







     (3.24) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
50 
Elliptic Equations
Where 
)
u
u
(
wb
u
)
w
1
)(
b
1(
2
b
1
m
S
m
N
2
m
O
2
O






     (3.25) 
and noting that the data 
1
m
S
u
 on the right hand side is known if we assume a bottom to top ordering for 
the calculation. (3.24) is now in tridiagonal form. The corresponding matrix equations for the unknown 
data u at the interior grid points (i = 2, M-1) in a single row j are: 











































































j,1
M
j,3
j,2
m
j,1
M
1
m
j,3
1
m
j,2
2
2
2
2
b
.
.
.
b
b
u
.
.
.
u
u
)
b
1(
2
w
w
)
b
1(
2
w
0
.
.
.
.
.
.
0
w
)
b
1(
2
w
w
)
b
1(
2
     (3.26)
where we see that a tridiagonal matrix is one in which the entries in the main diagonal and in the diagonals 
above and below it are in general non-zero, with the remaining entries zero. A tridiagonal system like 
(3.26) can be solved very efficiently using the Thomas algorithm (see website) for the m+1 iterated values 
of u along one complete line or row of the mesh at once. This is the line SoR method, or SoR by lines. For 
convenience, the matrix equations (3.26) assume zero end-point boundary values. Dirichlet or von 
Neumann boundary conditions (see Appendix B) involve only marginal changes to the entries in the 
tridiagonal matrix and the right hand side vector b. (3.26) also assumes that the nodes in each row j are 
numbered left to right from i=1 to M where at the end points (i=1 and i=M) boundary conditions are 
applied. Instead of visiting each node in the mesh at each iteration, we solve a complete row at a time by 
solving (3.26), working up the rows bottom to top to complete one iteration cycle. The procedure is 
illustrated in Figure 3.3. The row sweeps are continued until the solution values converge to the required 
accuracy. In order to maintain diagonal dominance of the equations (3.26), and retain computational 
efficiency, we must ensure that w  1+b2 (on a square mesh w 2). 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
51 
Elliptic Equations
Figure 3.3 SoR by Lines 
The faster convergence of line SoR compared to standard (point) SoR is due to the greater influence of the 
boundary values that affect all nodes at each sweep. It can be shown that the optimum value of the 
relaxation parameter w is given by the smaller root of,  
0
16
w
16
w
t
2
2



     (3.27) 
where



)1
N
/(
cos
)1
M
/(
cos
t






 and M and N are the number of grid points in the x and y 
directions respectively. 
3.13 Exercise 3c 
1.
Write a general program to implement SoR and validate it on the test problem. Experiment with 
tolerances and choice of relaxation parameter. 
2.
Repeat Q1 using line SoR.  
y
u=u0=const  
x
u=u0=const
u=u0=const  
m
m+1 
m+1 
m+1 
m+1 
sweep by rows 
bottom to top  
Apply Thomas 
algorithm then 
advance to next 
row up
u=u0=const
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
52 
Hyperbolic Equations
4. Hyperbolic Equations  
4.1 Introduction 
Hyperbolic equations describe many time-dependent (transient) phenomena (e.g. fluid flow) and are 
characterised by a speed of propagation of information (often called ‘wave speed’). Consequently future 
solution values can only be affected by past values in a limited neighbourhood. Hyperbolic equations may 
also admit discontinuities in the solution variables requiring advanced numerical treatment. A proper 
mathematical treatment of hyperbolic equations involves the study of characteristics that is beyond the 
scope of this book. Instead we use experimental results to illustrate key concepts. Attention is focused on 
the 1D linear advection equation that, although not strictly hyperbolic according to the classical definition, 
contains the essential elements of hyperbolic PDEs and, as we will see later, is a component of the shallow 
water equations that are truly hyperbolic. We will look at numerical results from the simple FD scheme in 
Chapter 2 to solve the 1D linear advection equation and this will lead to a series of basic questions about 
numerical schemes in general. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENT…
     RUN FASTER.
          RUN LONGER..
                RUN EASIER…
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

 
Introductory Finite Difference Methods for PDEs
53 
Hyperbolic Equations
4.2 1D Linear Advection Equation 
The linear advection equation (also known as the transport equation) may be used in a model of various 
phenomena like the movement of pollutant in a river or the movement of an air/water interface inside a 
sophisticated numerical method (e.g. Volume of Fluid method). We look at the simplest version of this 
equation. In one spatial dimension the linear advection equation is: 
Ut + v Ux = 0     (4.1a) 
Here the independent variables are t (time) and x (space). The dependent variable U is a function of t  
and x.  
A PDE on its own does not give a complete model of a particular problem. In addition to the PDE, we 
need to give the correct initial and/or boundary conditions for the dependent variable for the particular 
problem. Let the initial condition for U in (4.1a) be,  
U(0, x) = f(x)     (4.1b) 
i.e. the initial value of U is given over the spatial domain by a known function f(x). For the moment we 
will assume that the spatial domain is infinite so that we can ignore any boundary conditions. 
4.2.1 An Interpretation of the Linear Advection Equation 
If we interpret (4.1a, 4.1b) as a (partial) model of the transport of a soluble pollutant by a 1D river then 
U(t, x) is pollutant concentration at time t and position x along the river and v is the (constant) velocity of 
the river. Equation (4.1b) gives the initial pollutant concentration at each point along the river. For a fixed 
value of t the graph of U against x is called the concentration profile. Suitable units measure t in seconds, 
x in metres and U in kg/m. A dimensional analysis of (4.1a) shows that v is measured in m/s which is 
correct for velocity. 
A solution to (4.1a, 4.1b) is a function U = U(t, x) which satisfies (4.1a) and the initial conditions (4.1b) at 
all points (x, t). 
4.2.2 Exact Solution of the Linear Advection Equation 
It can be shown that the exact solution to (4.1a, 4.1b) is, 
U(t, x) = f(x – vt)     (4.1c) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
54 
Hyperbolic Equations
This means that U(t, x) is just the initial concentration profile, f(x), translated vt metres along the x axis. 
For v > 0, the translation is to the right and for v < 0, the translation is to the left. In either case the 
pollution moves downstream at the speed of the river. The following diagrams illustrate this using an 
arbitrary made up initial concentration profile. 
Figure 4.1a Initial concentration profile.  
Figure 4.1b Concentration profile after time t (solid) compared to initial profile (dashed), v > 0. 
Figure 4.1a shows a triangular initial concentration profile along the river. Concentration is only non-zero 
in the interval 2 < x < 4. At time t the concentration profile is the same shape as the initial concentration 
profile but has been translated vt units downstream. Physically equation (4.1a) models pollutant transport 
in the absence of diffusion so the pollutant is just carried along at the speed, v, of the river. This model is 
unrealistic but is useful for learning purposes. It is important to note that the model is NOT a model of the 
flow in the river which flows with constant velocity v (we will look at models of water flow later as they 
are more complicated).  
The linear advection equation is a good PDE to study because it has an exact solution and we can assess 
the performance of FD schemes by comparison to this. 
xx (metres) 
U(0, x) = f(x) 
x
2
x
4
concentration 
U (kg/m) 
x2+vt
xv t
x
2
x
4
x4+vt
concentration 
U (kg/m) 
xx (metres) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
55 
Hyperbolic Equations
4.3 Results for the Simple Linear Advection Scheme 
Graphical output from the simple FD scheme of Chapter 2 is given for a range of parameters. In all cases 
the same initial condition profile given by Equation (2.19) was used and the computational domain,  
[0, 100], was discretised by N = 101 equally spaced points. There is a brief discussion of the output in 
each case which will motivate the analysis later in the chapter. 
4.3.1 Test Case 1  
0
10
20
30
40
50
60
70
80
90
100
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
x
concentration u
comparison of solutions to du/dt + v du/dx = 0, + numerical, o analytical
Figure 4.2a Comparison of numerical (+) and exact solutions (o) to the 1D linear advection equation using 
first order forward differences in both space and time using v = 0.5, t = 0.3, 10 time steps. 
The simulation was run for 0.3x10 = 3 seconds. The initial condition profile has moved about 1.5 metres 
to the right. This is what we would expect since v = 0.5m/s is positive and distance equals speed 
multiplied by time. There is ‘good’ agreement between numerical and exact solutions. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
56 
Hyperbolic Equations
4.3.2 Test Case 2 
0
10
20
30
40
50
60
70
80
90
100
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
x
concentration u
comparison of solutions to du/dt + v du/dx = 0, + numerical, o analytical
Figure 4.2b Comparison of numerical (+) and exact solutions (o) to the 1D linear advection equation using 
first order forward differences in both space and time using v = 0.5, t = 0.3, 25 time steps. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

 
Introductory Finite Difference Methods for PDEs
57 
Hyperbolic Equations
The simulation has been run for 0.3x25 = 7.5 seconds. The numerical concentration peak has moved to the 
right place but is higher than the exact solution. More worryingly there is some noticeable divergence 
from the exact solution in the numerical solution around x = 15 and x = 67. Something is going wrong! 
4.3.3 Test Case 3 
0
10
20
30
40
50
60
70
80
90
100
-20
-15
-10
-5
0
5
10
15
20
x
concentration u
comparison of solutions to du/dt + v du/dx = 0, + numerical, o analytical
Figure 4.2c Comparison of numerical (+) and exact solutions (o) to the 1D linear advection equation using 
first order forward differences in both space and time using v = 0.5, t = 0.3, 44 time steps. 
The simulation has been run for 0.3x45 = 13.5 seconds and numerical results have gone haywire. Note 
that the vertical scale has changed and the numerical results have ‘blown up’. Something is terribly wrong 
with this scheme! 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
58 
Hyperbolic Equations
4.3.4 Test Case 4 
0
10
20
30
40
50
60
70
80
90
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
concentration u
comparison of solutions to du/dt + v du/dx = 0, + numerical, o analytical
Figure 4.2d Comparison of numerical (+) and exact solutions (o) to the 1D linear advection equation using 
first order forward differences in both space and time using v = -0.5, t = 0.3, 44 time steps. 
The simulation has again been run for 13.5 seconds but the sign of the velocity, v, has been changed. As 
expected the concentration profile moves to the left. Results look reasonable this time so there is a lack of 
symmetry with Test Case 3. Obviously the behaviour of the numerical scheme is influenced by the sign  
of v.  
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
59 
Hyperbolic Equations
4.3.5 Test Case 5 
0
10
20
30
40
50
60
70
80
90
100
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
x
concentration u
comparison of solutions to du/dt + v du/dx = 0, + numerical, o analytical
Figure 4.2e Comparison of numerical (+) and exact solutions (o) to the 1D linear advection equation using 
first order forward differences in both space and time using v = -0.5, t = 13.5, 1 time step. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

 
Introductory Finite Difference Methods for PDEs
60 
Hyperbolic Equations
The simulation has again been run for 13.5 seconds with v = -0.5, as before. The time step has been 
increase to 13.5 so that the end result is achieved in a single iteration. As before the concentration profile 
moves to the left. However results look bad and there is evidence that the numerical solution has started to 
‘blow up’! The time step, t, could be too big. 
A number of questions arise naturally from the results of these numerical experiments: 
Q1)  Can we design other FD schemes to get more accurate results? 
Q2)  How do we know the numerical results won’t ‘blow up’ at some future time? 
Q3)  How do we know we have an accurate solution (in the absence of an analytical solution)?  
These questions are addressed by the theory in Appendix C which should be read now. 
4.4 Scheme Design 
We will design FD schemes to solve the 1D linear advection equation (4.1a). First we introduce some 
useful compact notation. 
4.4.1 Operator Notation  
Let, 
tdenote t
,
tt
denote 
2
2
t

,
xy

denote 
x
y
2



 etc. 
Then (4.1a) can be written, 
0
U
v
U
x
t




     (4.2a) 
U
v
U
x
t





     (4.2b) 
By definition, 
)
U
(
U
t
t
tt




     (4.3a) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
61 
Hyperbolic Equations
Using (4.2b), (4.3a) gives, 
       
)
U
v
(
U
x
t
tt





(4.3b) 
)
U
(
v
x
t 



U
v xt



U
v
tx



)
U
(
v
t
x 



)
U
v
(
v
x
x





U
v
xx
2

 
(4.3c) 
Now we can design some FD schemes to solve Equation (4.1a). 
For fixed x, the Taylor expansion of U(t + t, x) to order 3 gives, 
)
t
(
O
U
!2
t
U
t
)
x
,t(
U
)
x
,t
t(
U
3
tt
2
t









     (4.4a) 
which, in operator notation is, 
)
t
(
O
U
!2
t
U
t
)
x
,t(
U
)
x
,t
t(
U
3
tt
2
t











     (4.4b) 
Using (4.2b) and (4.3c) the partial derivatives with respect to t can be replaced by partial derivatives with 
respect to x to give, 
)
t
(
O
U
v
!2
t
U
v
t
)
x
,t(
U
)
x
,t
t(
U
3
xx
2
2
x











     (4.4c) 
Let,    
xx
2
2
x
x
v
2
t
v
t
1
)t
(
L








     (4.5) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
62 
Hyperbolic Equations
Then (4.4c) can be written, 
)
t
(
O
)
x
,t(
U
)t
(
L
)
x
,t
t(
U
3
x






     (4.6) 
)t
(
L x 
is a differential marching operator. To design FD schemes to solve (4.8a) we simply redefine 
)
( t
Lx 
by replacing each continuous partial derivative by a finite difference approximation (denoted by 
x, xx) to give, 
xx
2
2
x
x
v
2
t
v
t
1
)t
(
L








     (4.7) 
)t
(
Lx 
is now a difference marching operator. Different FD approximation choices for x, xx give rise to 
different FD time marching schemes. The general (second order in time) FD time marching scheme for the 
1D linear advection equation (4.8a) can now be written as, 
n
i
x
1
n
i
u
)t
(
L
u



     (4.8a) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360°
thinking.
© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

 
Introductory Finite Difference Methods for PDEs
63 
Hyperbolic Equations
Written out in full this is, 
n
i
xx
2
2
n
i
x
n
i
1
n
i
u
v
2
t
u
v
t
u
u








     (4.8b) 
(As previously defined, 
n
iu is the approximation to the exact solution U(tn, xi) at the ith grid point and the 
nth time step). Some examples of FD schemes are now given. 
4.4.2 Example 1: Forward Time Centred Space (FTCS) Scheme 
From our FD toolkit we choose 
x
2
u
u
u
n
1
i
n
1
i
n
i
x






and 
0
un
i
xx


.
Equation (4.8b) becomes, 


n
1
i
n
1
i
n
i
1
n
i
u
u
x
2
t
v
u
u








     (4.9) 
This is the FTCS scheme and it has the following stencil. 
Figure 4.3 Stencil for the FTCS Scheme 
time level 
n + 1 
n
i-1  
i+1  
t
spatial steps 
i
x
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
64 
Hyperbolic Equations
Notes: 
1) The scheme is first order in time and second order in space (see Appendix C for definition of the order 
of a scheme). 
2) Ghost values are required at both left and right ends of the computational domain (see Appendix B for 
boundary conditions).  
4.4.3 Example 2: First Order Upwind (FOU) Scheme 
From our FD toolkit we choose 
x
u
u
u
n
1
i
n
i
n
i
x




and 
0
un
i
xx


. Equation (4.8b) becomes, 


n
1
i
n
i
n
i
1
n
i
u
u
x
t
v
u
u







     (4.10) 
This is the FOU scheme and it has the following stencil. 
Figure 4.4 Stencil for the FOU Scheme 
Notes: 
1)
The scheme is first order in time and first order in space. 
2)
A ghost value is required at the left end of the computational domain.  
time level 
n + 1 
n
i-1 
t
spatial steps 
i
x
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
65 
Hyperbolic Equations
4.4.4 Example 3: Lax-Wendroff Scheme 
From our FD toolkit choose 
x
2
u
u
u
n
1
i
n
1
i
n
i
x






,
2
n
1
i
n
i
n
1
i
n
i
xx
x
u
u
2
u
u







.
Equation (4.8b) becomes, 




n
1
i
n
i
n
1
i
2
2
2
n
1
i
n
1
i
n
i
1
n
i
u
u
2
u
x
2
t
v
u
u
x
2
t
v
u
u















     (4.11) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

 
Introductory Finite Difference Methods for PDEs
66 
Hyperbolic Equations
This is the Lax-Wendroff scheme and it has the following stencil. 
Figure 4.5 Stencil for the Lax-Wendroff Scheme 
Notes: 
1)
The scheme is second order in time and second order in space. 
2)
Ghost values are required at both left and right ends of the computational domain.  
4.4.5 Example 4: Lax-Friedrichs Scheme 
This is the same as the FTCS scheme except that the first term on the right of (4.9) is replaced by the 
average of its 2 neighbouring values, i.e. 
n
iu  is replaced by 
2
u
u
n
1
i
n
1
i


. As in the FTCS scheme we choose 
x
2
u
u
u
n
1
i
n
1
i
n
i
x






and 
0
un
i
xx


.
Equation (4.8b) becomes, 


n
1
i
n
1
i
n
1
i
n
1
i
1
n
i
u
u
x
2
t
v
2
u
u
u











     (4.12) 
time level 
n + 1 
n
i-1  
i+1  
t
spatial steps 
i
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
67 
Hyperbolic Equations
This is the Lax-Friedrichs scheme and it has the following stencil. 
Figure 4.6 Stencil for the Lax-Friedrichs Scheme 
Notes: 
1)
The scheme is first order in time and first order in space. 
2)
Ghost values are required at both left and right ends of the computational domain.  
3)
Although this scheme appears to be quite similar to the FTCS scheme its performance is very 
different (see Appendix C). 
4.5 Multi-Level Scheme Design 
So far all our schemes have been based on using data at the current time level (n) to advance to the next 
time level (n+1). This approach can be extended to multi-level schemes by performing Taylor 
approximations at t - t and using algebraic manipulation as we shall now see. Replacing t by – t in 
(4.4a) gives, 
)
t
(
O
U
!2
t
U
t
)
x
,t(
U
)
x
,t
t(
U
3
tt
2
t









     (4.13a) 
Subtracting (4.13b) from (4.13a) and gives, 
)
t
(
O
U
t
2
)
x
,t
t(
U
)
x
,t
t(
U
3
t









     (4.13b) 
time level 
n + 1 
n
i-1  
i+1  
t
spatial steps 
i
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
68 
Hyperbolic Equations
In operator notation this is, 
)
t
(
O
U
t
2
)
x
,t
t(
U
)
x
,t
t(
U
3
t










     (4.13c) 
Using (4.2b) this becomes, 
)
t
(
O
U
t
v
2
)
x
,t
t(
U
)
x
,t
t(
U
3
x











     (4.13d) 
Dropping the error term, replacing the differential operator by the difference operator and using the usual 
discrete notation gives the general FD scheme, 
u
t
v
2
u
u
x
1
n
i
1
n
i






     (4.14) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

 
Introductory Finite Difference Methods for PDEs
69 
Hyperbolic Equations
4.5.1 Example 5: Leap-Frog Scheme 
In (4.14) we choose 
x
2
u
u
u
n
1
i
n
1
i
n
i
x






to give, 


n
1
i
n
1
i
1
n
i
1
n
i
u
u
x
t
v
u
u









     (4.15) 
This is the Leap-Frog scheme and it has the following stencil. 
Figure 4.7 Stencil for the Leap-Frog Scheme 
Notes: 
1)
The scheme is second order in time and second order in space. 
2)
Ghost values are required at both left and right ends of the computational domain.  
3)
Initial conditions are required at two time levels!  
4.6 Exercise 4a 
1a.  Download the simple linear advection solver ‘linearadvection’ (from Chapter 2). 
1b.  Run ‘linearadvection’ on Test Cases 1-5 and check that the output agrees with the figures in the notes. 
time level 
n + 1 
n
i-1  
i+1 
t
spatial steps 
i
n-1  
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
70 
Hyperbolic Equations
1c.  Run ‘linearadvection’ with different run times, time steps, spatial steps and values of v (both positive 
and negative). In each case write down in your own words how the numerical scheme behaves in 
comparison to the exact solution. 
1d.  Are there any values of t, x, v, ntimesteps that give good results? 
2a.  Copy ‘linearadvection’ to ‘linearadvectionFOU’. Change the solver in this new file so that it 
implements the FOU scheme. Verify your code by comparison to a pen and paper calculation as per 
Table  
2.2.  Important: the FOU scheme requires a left hand ghost point and hence in the first non-ghost point has 
index 2 and the last non-ghost point has index N+1. 
2b.  Run ‘linearadvectionFOU’ using the parameters from Test Cases  
1-4.  In each case write down in your own words how the numerical scheme behaves with reference to the 
analytical results. 
2c.  Run ‘linearadvectionFOU’ with different run times, time steps, spatial steps and values of v (both 
positive and negative). In each case write down in your own words how the numerical scheme 
behaves with reference to the analytical results. 
2d.  Are there any values of t, x, v, ntimesteps that give good results? 
2e.  Show experimentally that the FOU scheme is first order in space. 
3.  Copy ‘linearadvection’ to ‘linearadvectionLW’. Change the solver in this new file so that it 
implements the Lax-Wendroff scheme and verify the code. Repeat 2b-e for ‘linearadvectionLW’. 
4.  Do all exercises in Appendix C and relate theoretical stability results to your experimentally derived 
results.  
4.7 Implicit Schemes 
The previous schemes are called explicit schemes because data at the next time level is obtained from an 
explicit formula involving data from previous time levels. This leads to a (stability) restriction on the 
maximum allowable time step, t (see Appendix C). Now we come to a different type of scheme – 
implicit, in which data from the next time level occurs on both sides of the difference scheme that 
necessitates solving a system of linear equations. There is no stability restriction on the maximum time 
stepwhich may be much larger than an explicit scheme for the same problem. In implicit schemes the 
time step is chosen on the basis of accuracy considerations. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
71 
Hyperbolic Equations
4.7.1 Example 6: Crank-Nicolson Scheme 
This is an implicit scheme. In previous examples spatial derivatives are approximated at time level n. 
However values change between time level n and time level n+1 so a better approximation to spatial 
derivatives could make use of data at both time levels. Let, 
x
2
u
u
)
1(
x
2
u
u
u
1
n
1
i
1
n
1
i
n
1
i
n
1
i
n
i
x
















 , 
1
0



.      (4.16) 
This is a weighted average of central difference approximations at times levels n and n+1. Choose 
0
un
i
xx


. Then for  = ½ (4.8b) becomes, 




















2
u
u
2
u
u
x
2
t
v
u
u
1
n
1
i
1
n
1
i
n
1
i
n
1
i
n
i
1
n
i
     (4.17) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

 
Introductory Finite Difference Methods for PDEs
72 
Hyperbolic Equations
This is the Crank-Nicolson scheme and it has the following stencil. 
Figure 4.8 Stencil for the Crank-Nicolson Scheme 
Notes: 
1)
The scheme is first order in time and second order in space. 
2)
Ghost values are required at both left and right ends of the computational domain.  
3)
The scheme is implicit so values at time level n+1 are found by solving a system of linear equations.  
4.7.2 Implementation of the Crank-Nicolson Scheme  
Letting 
x
t
v
c



, (4.17) is, 


















2
u
u
2
u
u
2
c
u
u
1
n
1
i
1
n
1
i
n
1
i
n
1
i
n
i
1
n
i
     (4.18) 
Re-writing (4.18) gives, 


1
n
1
i
1
n
1
i
n
1
i
n
1
i
n
i
1
n
i
u
u
u
u
c
u
4
u
4












     (4.19a) 
time level 
n + 1 
n
i-1  
i+1  
t
spatial steps 
i
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
73 
Hyperbolic Equations
Rearranging so that data from the same time level is on the same side gives, 
n
1
i
n
i
n
1
i
1
n
1
i
1
n
i
1
n
1
i
u
c
u
4
u
c
u
c
u
4
u
c













     (4.19b) 
The data at time level n is assumed known so (4.19b) is simplified by replacing the right hand side by
n
id
to give, 
n
i
1
n
1
i
1
n
i
1
n
1
i
d
u
c
u
4
u
c








     (4.19c) 
For each grid point i = 1, 2, … , N, we write out (4.19c) to give, 
n
N
1
n
1
N
1
n
N
1
n
1
N
n
1
N
1
n
N
1
n
1
N
1
n
2
N
n
3
1
n
4
1
n
3
1
n
2
n
2
1
n
3
1
n
2
1
n
1
n
1
1
n
2
1
n
1
1
n
0
d
u
c
u
4
u
c
d
u
c
u
4
u
c
d
u
c
u
4
u
c
d
u
c
u
4
u
c
d
u
c
u
4
u
c










































     (4.19d) 
(4.19d) is a system of N linear equations in what looks like N+2 unknowns! However 
1
n
0
u and 
1
n
1
N
u 
 on 
the left hand side of (4.19d) are ghost values which may be known directly or can be calculated in terms of 
neighbouring values depending on the type of boundary condition given in the problem (see Appendix B). 
In the former case we can move these known values to the right hand side of (4.19d) and, letting 
1
n
1
N
n
N
n
N
1
n
0
n
1
n
1
u
c
d
d
,
u
c
d
d









, (4.19d) becomes, 
n
N
1
n
N
1
n
1
N
n
1
N
1
n
N
1
n
1
N
1
n
2
N
n
3
1
n
4
1
n
3
1
n
2
n
2
1
n
3
1
n
2
1
n
1
n
1
1
n
2
1
n
1
d
u
4
u
c
d
u
c
u
4
u
c
d
u
c
u
4
u
c
d
u
c
u
4
u
c
d
u
c
u
4






































     (4.19e) 
This system is expressed as the matrix equation, 
A un+1= dn     (4.19f) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
74 
Hyperbolic Equations
where,
.
d
d
d
d
d
,
u
u
u
u
u
,
4
c
0
...
0
c
4
c
0
...
0
0
...
0
c
4
c
0
0
0
...
0
c
4
c
0
0
...
0
c
4
c
0
...
0
c
4
A
n
N
n
1
N
n
2
n
1
n
1
n
N
1
n
1
N
1
n
2
1
n
1
1
n
















































































The solution to (4.19f) is obviously, 
un+1= A-1 dn     (4.19g) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
• STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
• PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
• STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

 
Introductory Finite Difference Methods for PDEs
75 
Hyperbolic Equations
Notes: 
1.
(4.19g) is solved at each time step and the solution updated iteratively. 
2.
In practical problems A may be very large (e.g. 1000 x 1000) so an efficient matrix inversion method 
may be needed (see Chapter 3).  
3.
In this example boundary values are known so A is constant and needs only to be inverted once. For 
problems where the left hand side boundary values are calculated in terms of neighbouring values 
(e.g. Derivative boundary conditions, see Appendix B) the first and last rows of A will vary from 
time step to time step. 
4.
In our example A has a special structure – it is tridiagonal. This special structure permits the use of 
the efficient Thomas algorithm for matrix inversion algorithm (see downloadable code for Chapter 3).  
Results for the usual test case are given in Figure 4.9. 
0
10
20
30
40
50
60
70
80
90
100
-0.2
0
0.2
0.4
0.6
0.8
1
distance, x
concentration, u
Comparison of Crank-N numerical (+) and exact solutions to du/dt+vdu/dx=0
Figure 4.9 Comparison of numerical (+) and exact solutions (o) to the 1D linear advection equation using 
the Crank-Nicolson scheme with v = 0.5, C = 2.0, 15 time steps. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
76 
Hyperbolic Equations
4.8 Exercise 4b 
1.
Use von Neumann stability analysis (Appendix C) to show that the Crank-Nicolson scheme is 
unconditionally stable. 
2.
Using the Crank-Nicolson scheme for the 1D linear advection equation with p = 0, q = 100,  
v = 0.5, N = 5, C = 1 and Dirichlet boundary conditions 
n
u
0
u
n
1
N
n
0




, and the usual initial profile. 
Write down the system of linear equations for the first time step of the Crank-Nicolson scheme and 
express them as a matrix equation. Invert the (5x5) matrix (by pen and paper or use a package) and 
hence find the concentration values at each grid point after the first time step. 
3.
Using your calculation from Q2 to verify your program and write a program to implement the Crank-
Nicolson scheme using N = 50 grid points. Experiment with different time steps and compare your 
numerical results to the exact solution. Write a short report detailing the characteristics of the scheme 
(tip: use the code from a previously written scheme as a basis for your new code).  
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
77 
Parabolic Equations: the Advection-Diffusion Equation
5. Parabolic Equations: the Advection-Diffusion 
Equation
5.1 Introduction 
The advection-diffusion equation belongs to the class of parabolic PDEs. In 1 spatial dimension it is, 
xx
x
x
t
U
K
U
v
U


     (5.1) 
Kx is called the diffusion coefficient (in the x direction). If Kx = 0 then (5.1) is the linear advection 
equation which we studied in Chapter 4. Using our previous interpretation of the linear advection equation 
in which U = U(t, x) is river pollutant concentration and v is the speed of the flow, (5.1) is a more realistic 
description of pollutant transport. Not only does the initial pollutant move downstream with velocity v, the 
pollutant also diffuses into the surrounding water at rate Kx (the presence of second order spatial 
derivatives often indicates a diffusive process).  
Figure 5.1 illustrates a pure advective process (K = 0 in (5.1a)) compared to an advection-diffusion 
process (K > 0 in (5.1b)). As we have seen previously for pure advection there is no change in the initial 
concentration profile as it moves downstream at speed v. When diffusion is introduced the initial 
concentration profile moves downstream at speed v but also spreads out (diffuses) and reduces in height 
over time. It is important to realise that Figure 5.1b shows the exact solution – the spreading and reduction 
in height is a consequence of the underlying physical process. Of course we have seen similar behaviour 
with numerical solutions hence we talk of ‘numerical diffusion’ that is a feature of most numerical 
schemes. 
0
10
20
30
40
50
60
70
80
90
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
concentration u
pure advection: initial profile (dotted line) and 2 later solutions
(a) 
0
10
20
30
40
50
60
70
80
90
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
concentration u
advection-diffusion: initial profile (dotted) and solution at later times, 
(b) 
Figure 5.1 Time evolution of solutions for advection (a) and advection-diffusion (b) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
78 
Parabolic Equations: the Advection-Diffusion Equation
5.2 Pure Diffusion 
To keep things simple we will start with the pure diffusion equation, 
xx
x
t
U
K
U 
     (5.2a) 
5.2.1 Analytical Solution of the Pure Diffusion Equation 
Equation (5.2a) has an analytical solution for special conditions that is useful for checking numerical 
schemes. It can be shown that over the x interval [0, 1] with initial condition, U(0, x) = sin(x) and 
boundary conditions, U(t, 0) = U(t, 1) = 0 for all t, the solution of (5.2a) is, 
)
x
sin(
e
)
x,t(
U
t
K
2
x




     (5.2b) 
5.2.2 Finite Difference Scheme for the Pure Diffusion Equation 
We start simply and use our FD toolbox to replace the time derivative by a first order forward difference 
and the spatial derivative by a symmetric difference so that (5.2a) becomes, 
2
n
1
i
n
i
n
1
i
x
n
i
1
n
i
x
u
u
2
u
K
t
u
u









     (5.3a) 
This can be rearranged to give the explicit FD scheme, 


n
1
i
n
i
n
1
i
2
x
n
i
1
n
i
u
u
2
u
x
K
t
u
u









     (5.3b) 
Note that the presence of 
n
1
iu and 
n
1
iu  indicates the need for left and right ghost values. Equation (5.3b) 
is written compactly as, 


n
1
i
n
1
i
n
i
1
n
i
u
r
u
r
u
r
2
1
u







     (5.3c) 
where,
2
x
x
K
t
r



     (5.4) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
79 
Parabolic Equations: the Advection-Diffusion Equation
Since this scheme is explicit the time step, t, will be limited by stability constraints. A von Neumann 
stability analysis (Appendix C) gives, after some manipulation, 
G = (1 – 2 r) + 2 r cos(k x)     (5.5a)
where G is the amplification factor. For stability, 
1
|
G
|
 which gives, 
x
2
K
2
x
t



     (5.5b) 
The problem with the analytical solution (5.2b) was run for 300 time steps with 51 grid points using 
scheme (5.3b) with Kx = 1. The maximum time step given by (5.5b) was multiplied by a safety factor of 
F=0.9. Figure 5.2 shows the results. It can be seen that the initial profile reduces in height but does not 
change its location. This is what we expect from a pure diffusion problem. The numerical and exact 
solutions are close. 
Figure 5.2 Comparison of exact and numerical solutions for a 
special pure diffusion problem. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
concentration u
pure diffusion: initial profile (--) and numerical (+) and exact solutions
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
80 
Parabolic Equations: the Advection-Diffusion Equation
5.2.3 Exercise 5a 
1.  State the units of Kx given standard units for the other variables in (5.1). 
2.  Given the initial concentration in Figure 5.1 draw plausible solutions to (5.1) at two later times on the 
same graph when v = 0. 
3.  Show that (5.2b) satisfies the special initial and boundary conditions. 
4.  Show by partial differentiation that (5.2b) is a solution of (5.2a). 
5.  Obtain (5.3b) from (5.3a). 
6.  Obtain (5.3c) from (5.3b). 
7.  By conducting a von Neumann stability analysis obtain (5.5a) then (5.5b). 
8.  Write a program to solve (5.2a) using the scheme (5.3c). Check your program on the special diffusion 
case and reproduce Figure 5.2. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
“The perfect start 
of a successful, 
international career.”
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

 
Introductory Finite Difference Methods for PDEs
81 
Parabolic Equations: the Advection-Diffusion Equation
5.3 Advection-Diffusion Equation 
We discretise the advection-diffusion equation (5.1) using a first order forward difference for the time 
derivative, a first order backward difference for the first space derivative (assuming v >0) and a (second 
order) symmetric difference for the second space derivative to give, 
2
n
1
i
n
i
n
1
i
x
n
1
i
n
i
n
i
1
n
i
x
u
u
2
u
K
x
u
u
v
t
u
u













     (5.6a) 
which can be rewritten as, 




n
1
i
n
i
n
1
i
2
x
n
1
i
n
i
n
i
1
n
i
u
u
2
u
x
t
K
u
u
x
t
v
u
u














     (5.6b) 
(5.6b) is an explicit FD scheme for solving the advection-diffusion equation. It is first order in time and 
space. As usual we need to find the allowable time step by a stability analysis. For convenience (5.6b) is 
written, 
n
1
i
n
i
n
1
i
1
n
i
u
)
S
R
(
u
)
S
2
R
1(
u
S
u









     (5.6c) 
where,
.
x
t
v
R



     (5.7a) 
.
x
t
K
S
2
x



     (5.7b) 
By von Neumann stability analysis it can be shown that, 
0
S
2
R
1



     (5.8) 
from which it follows that, 
x
2
K
2
x
v
x
t





     (5.9) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
82 
Parabolic Equations: the Advection-Diffusion Equation
Note that when v = 0, (5.9) reduces to the previously calculated stability limit for pure diffusion (5.5b) and 
when Kx = 0 (5.9) gives the well known stability limit for pure advection. Results from scheme (5.6b) are 
given in Figure 5.3 for v = 0.5, Kx = 0.1, N = 101 at time t = 57s where t is its maximum value in (5.9) 
multiplied by a safety factor of 0.9. The simulation required 45 time steps. By inspection the peak of the 
concentration profile has moved about 28m. This correct as v = 0.5 and 0.5 x 57 = 28.5m. The peak value 
of the profile has decreased and its width has increased as would be expected from a diffusive process.  
0
10
20
30
40
50
60
70
80
90
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
concentration u
advection-diffusion: initial profile (dotted) and unsplit numerical solution (+) at later time, 
Figure 5.3 Initial profile and numerical solution (+) to the 1D advection-diffusion equation at t = 57s. 
Important:  
When running a simulation always check your results as much as you can. There are various ways to do 
this: 
Check 1. If there is an exact solution to a special problem run the simulation on it and compare numerical 
and exact results.  
Check 2. Do a pen and paper calculation on a small problem and compare results with your numerical 
output. 
Check 3. Subject your results to a critical scrutiny – are they what you expect to get given the physical 
process you are modelling? 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
83 
Parabolic Equations: the Advection-Diffusion Equation
Of course the whole purpose of a simulation is to model some aspect of reality so the only real check (of 
the model) is to compare it against real data. 
5.4 Exercise 5b 
1.
Derive (5.6a) 
2.
Obtain (5.6b) from (5.6a). 
3.
Obtain (5.6c) from (5.6b). 
4.
Starting with (5.6c) carry out a von Neumann stability analysis on the solution and obtain (5.8) and 
hence (5.9). 
5.
Calculate x and hence t for the simulation whose results are shown in Figure 5.3. 
6.
Draw an approximate sketch of Figure 5.3 if the simulation had been run for 70 seconds. 
7.
For v > 0 show that, a) 






AD
A
0
x
t
t
lim
, b) 
1
t
t
lim
AD
D
0
x





. What do you conclude from this? 
8.
Write a program to implement scheme (5.6b) and reproduce Figure 5.2. (hint: extend code from a 
previous scheme). 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
▶▶enroll by September 30th, 2014 and 
▶▶save up to 16% on the tuition!
▶▶pay in 10 installments / 2 years
▶▶Interactive Online education
▶▶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

 
Introductory Finite Difference Methods for PDEs
84 
Extension to Multi-dimensions and Operator Splitting
6. Extension to Multi-dimensions and Operator 
Splitting
6.1 Introduction 
So far we have looked at PDEs in one (spatial) dimension. The real world is 3D so we must extend schemes to 
multi-dimensions (it should be noted however that there are many useful 1D and 2D models of 3D processes). 
For simplicity and to illustrate key concepts we will consider the 2D linear advection equation, 
0
U
v
U
v
U
y
y
x
x
t



     (6.1a) 
Like the previous 1D linear advection equation this is another so-called ‘model’ equation in that it is a 
simplified version of reality. As for the 1D linear advection equation we can interpret (6.1a) as a (partial) 
model of pollutant transport in a 2D river. U= U(t, x, y) is the pollutant concentration at time t at position 
(x, y) in the river (plan view) and vx and vy are the (constant) components of river velocity in the x and y 
directions respectively. Given initial conditions,  
U(0, x, y) = g(x, y), 
it can be shown that (6.1a) has the exact solution, 
U(t, x, y) = g(x – vx t, y – vy t)     (6.1b) 
i.e. the concentration profile is simply translated (advected) along at the speed of the river without 
changing shape (there is no diffusion term in (6.1a) – it models pure advection). 
6.2 2D Scheme Design (unsplit) 
Our first approach to 2D scheme design is to directly discretise the PDE. These schemes are said to be 
unsplit as opposed to split that we will look at later. We will design FD schemes to solve (6.1a) in an 
exactly similar way to Chapter 4. In operator notation for partial derivatives (6.1a) can be written, 
0
U
v
U
v
U
y
y
x
x
t






     (6.2a) 

U
v
U
v
U
y
y
x
x
t






     (6.2b) 
By definition, 
U)
(
U
t
t
tt




     (6.2c) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
85 
Extension to Multi-dimensions and Operator Splitting
Using (6.2b, 6.2c) gives, 
     
U)
v
U
v
(
U
y
y
x
x
t
tt







     (6.2d) 
U)
(
v
U)
(
v
y
t
y
x
t
x







U)
(
v
U)
(
v
t
y
y
t
x
x







U)
v
U
v
(
v
U)
v
U
v
(
v
y
y
x
x
y
y
y
y
x
x
x
x













U
v
U
v
v
U
v
v
U
v
yy
2
y
xy
x
y
yx
y
x
xx
2
x








U
v
U
v
v
2
U
v
yy
2
y
xy
y
x
xx
2
x






     (6.2e) 
Now we can design some FD schemes to solve the 2D linear advection equation. Holding x and y constant, 
the Taylor series for U(t+t, x, y) expanded about U(t, x, y) to O(t3) is, 
)
t
O(
U
2
t
U
t
y)
x,
U(t,
y)
 x,
t,
+
U(t
3
tt
2
t










     (6.3a) 
Using (6.2b, 6.2e) to replace the time derivatives in (6.3a) and rearranging gives, 
)
t
O(
)U
v
v
2v
(v
2
t
)U
v
(v
t
y)
x,
U(t,
y)
x,
t,
+
U(t
3
yy
2
y
xy
y
x
xx
2
x
2
y
y
x
x
















     (6.3b) 
Let, 
)
v
v
v
2
v
(
2
t
)
v
v
(t
1
)t
(
L
yy
2
y
xy
y
x
xx
2
x
2
y
y
x
x
XY














     (6.4) 
Then (6.3b) can be written, 
)
t
(
O
)
y
,x
,t(
U
)t
(
L
)
y,x
,t
t(
U
3
XY






     (6.5) 
)t
(
LXY 
is a differential marching operator and is second order in time. To design FD schemes to solve 
(6.1a) we simply redefine 
)t
(
LXY 
by replacing each continuous partial derivative by a FD approximation 
(denoted by x, xy etc.) to give, 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
86 
Extension to Multi-dimensions and Operator Splitting
)
v
v
v
2
v
(
2
t
)
v
v
(t
1
)
(
yy
2
y
xy
y
x
xx
2
x
2
y
y
x
x













t
LXY
     (6.6) 
This is now a 2D difference marching operator. Different FD choices for x, xy etc. give rise to different 
FD time marching schemes.  
The computational domain is 2D so we need a grid of points in x and y directions. We assume a rectangular 
computational domain with constant grid spacing of x and y in the x and y directions respectively. t is the 
time step. Extending our usual notation by using subscript j for the index in the y direction let, 
ui,j
n  U(tn, xi, yj)     (6.7) 
The general 2D FD time marching scheme for the 2D linear advection equation (6.1a) can now be  
written as, 
n
j,i
XY
1
n
j,i
u
)t
(
L
u



     (6.8a) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
87 
Extension to Multi-dimensions and Operator Splitting
Written out in full this is, 
n
j
i,
yy
2
y
xy
y
x
xx
2
x
2
n
j
i,
y
y
x
x
n
j
i,
1
n
j
i,
)u
v
v
v
2
v
(
2
t
)u
v
v
(t
u
u














     (6.8b) 
Some examples of FD schemes are now given. 
6.2.1 Example 1: First Order Upwind (FOU2D) Scheme 
From our FD toolkit we choose, 
y
u
u
u
,
x
u
u
u
n
1
j,i
n
j,i
n
j,i
y
n
j,1
i
n
j,i
n
j,i
x










,
0
u
u
u
n
j,i
xy
n
j,i
yy
n
j,i
xx






. Equation (6.8b) becomes, 




n
1
j,i
n
j,i
y
n
j,1
i
n
j,i
x
n
j,i
1
n
j,i
u
u
C
u
u
C
u
u








     (6.9) 
where,
y
t
v
C
,
x
t
v
C
y
y
x
x






 are the Courant numbers in the x and y directions respectively. This scheme is 
simply the FOU scheme applied to each dimension. 
Notes: 
1.
The scheme is first order in time and first order in each spatial dimension. 
2.
Ghost values are required at the left side and the lower side of the computational domain. This is 
shown in Figure 6.1 for a grid with 5 points in the x direction and 3 points in the y direction. 
3.
The 2D FD scheme (6.9) could simply have been obtained by direct replacement of the partial 
derivatives in the PDE (6.1a) using approximations from the FD toolkit. Our scheme is an example of 
an unsplit scheme because it is obtained directly from the 2D PDE. 
4.
The scheme uses backward differences for the spatial derivatives and is therefore only an upwind 
scheme for positive velocities. When one or more velocities are negative the scheme will fail unless 
forward differences are used appropriately.  
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
88 
Extension to Multi-dimensions and Operator Splitting
5.
The scheme is explicit and will be subject to a stability constraint on the allowable time step. In the 
1D case the heuristic stability approach reasoned that information could not travel across 2 grid 
points in a single time step giving the condition, 
v
/
x
t 


. In 2D it seems reasonable to take, 


y
x
v
/
y
,
v
/
x
min
F
t




     (6.10a) 
where F < 1, is a ‘safety factor’ which can be determined from numerical experiments if necessary. In 
principle it is possible to undertake a stability analysis for a 2D scheme in the same way as for the 
corresponding 1D scheme. This is algebraically complicated. A von Neumann analysis gives, 
1
C
C
y
x


     (6.10b) 
which is a very restrictive condition on t.  
Figure 6.1 2D Computational mesh showing real grid points (black) and ghost grid points (white)  
for the FOU2D scheme 
Code to implement the FOU2D scheme (6.9) may be downloaded from the website. Graphical output from 
the above scheme is given in Figure 6.2. 
j
y
i
x
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
89 
Extension to Multi-dimensions and Operator Splitting
0
50
100
0
50
100
0
0.5
1
x
exact solution to du/dt + vx du/dx + vy du/dy = 0
y
concentration
contour plot of exact solution
x
y
0
20
40
60
80
100
0
20
40
60
80
100
0
50
100
0
50
100
0
0.5
1
x
FOU2D scheme solution to du/dt + vx du/dx + vy du/dy = 0
y
concentration
contour plot of FOU2D scheme solution
x
y
0
20
40
60
80
100
0
20
40
60
80
100
Figure 6.2 Comparison of exact and numerical solutions for the (unsplit) FOU2D scheme 
6.2.2 Example 2: Lax-Friedrichs Scheme in 2D 
From our FD toolkit we choose, 
y
2
u
u
u
,
x
2
u
u
u
n
1
j,i
n
1
j,i
n
j,i
y
n
j,1
i
n
j,1
i
n
j,i
x












,
0
u
u
u
n
j,i
xy
n
j,i
yy
n
j,i
xx






and estimate 
4
u
u
u
u
by
u
n
1
j,i
n
1
j,i
n
j,1
i
n
j,1
i
n
j,i







 (i.e. the mean of surrounding values). Equation (6.8b) 
becomes, 




n
1
j,i
n
1
j,i
y
n
j,1
i
n
j,1
i
x
n
1
j,i
n
1
j,i
n
j,1
i
n
j,1
i
1
n
j,i
u
u
2
C
u
u
2
C
4
u
u
u
u
u

















     (6.11)
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
90 
Extension to Multi-dimensions and Operator Splitting
Notes: 
1.  The scheme is first order in t and in both x and y. 
2.  Ghost values are required at all sides of the computational domain.  
3.  This scheme is less diffusive than the FOU2D scheme and also works for positive and negative 
velocities. 
4. A von Neumann stability analysis gives, 
2
/
1
C
C
2
y
2
x


     (6.12) 
which is a very restrictive time step condition. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
 
  
 
                . 

 
Introductory Finite Difference Methods for PDEs
91 
Extension to Multi-dimensions and Operator Splitting
6.2.3 Example 3: Crank-Nicolson Scheme in 2D 
By an obvious extension of the 1D scheme (6.8b) becomes, 


































2
u
u
2
u
u
2
C
2
u
u
2
u
u
2
C
u
u
1
n
1
j,i
1
n
1
j,i
n
1
j,i
n
1
j,i
y
1
n
j,1
i
1
n
j,1
i
n
j,1
i
n
j,1
i
x
n
j,i
1
n
j,i
     (6.13) 
Notes: 
1.
The scheme is first order in t and second order in both x and y. 
2.
Ghost values are required at all sides of the computational domain.  
3.
The scheme is implicit so values at time level n+1 are found by solving a system of linear equations. 
4.
Von Neumann stability analysis shows that this scheme is unconditionally stable.  
5.
Implementation of the Crank-Nicolson scheme involves solving MN linear equations in MN 
unknowns at teach time step where MN is the number of computational grid points. The matrix can 
be written as a penta-diagonal matrix. For large MN the computational effort at each time step may 
be prohibitive unless an efficient matrix inversion algorithm is used. 
6.2.4 Conclusions 
From the above analysis we can see that FD schemes extend naturally from 1D to 2D (and 3D). The main 
issues are: 
1.
It is often difficult to perform stability analysis. 
2.
For explicit schemes the allowable time step may be prohibitively small. 
3.
For implicit schemes the computational effort at each time step may be prohibitively large.  
4.
It would be nice to be able to exploit the relative simplicity and larger time steps of 1D schemes for 
2D problems. The following analysis shows that we can actually do this and more!  
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
92 
Extension to Multi-dimensions and Operator Splitting
6.3 Operator Splitting (Approximate Factorisation) 
This method replaces a single scheme to solve a complicated PDE by a sequence of simpler schemes 
which solve related PDEs and which together solve the original PDE (up to a specified order of accuracy). 
Operator splitting can be used to split up a PDE by dimension or by components or a combination of both. 
We begin by looking at dimensional splitting. 
6.3.1 Dimensional Splitting  
The basis of this method is to split our N dimensional PDE into N, 1D PDEs and use a sequence of 1D FD 
schemes to solve the problem. For simplicity we will look at the 2D linear advection equation (6.1a). We 
split the (6.1a) into the following 2 PDEs (which are both 1D in space), 
0
U
v
U
x
x
t


     (6.14a) 
0
U
v
U
y
y
t


     (6.14b) 
From our 1D work in Chapter 4 we know that a (second order in time) differential marching operator for 
solving (6.14a) is, 
xx
2
x
2
x
x
X
v
2
t
v
t
1
)t
(
L








     (6.15a) 
Similarly a differential marching operator for solving (6.14b) is, 
yy
2
y
2
y
y
Y
v
2
t
v
t
1
)t
(
L








     (6.15b) 
Consider the operator sequence, 
LY(t) LX(t)     (6.16) 
We show that this sequence is ‘the same’ as LXY defined in (6.4) which we know solves the 2D PDE 
(6.1a). By ‘the same’ it is enough to show that the difference is of an appropriate order of t. Multiplying 
out (6.16) gives, 
)
v
2
t
v
t
1()
v
2
t
v
t
1(
)t
(
L
)t
(
L
xx
2
x
2
x
x
yy
2
y
2
y
y
X
Y















     (6.17a) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
93 
Extension to Multi-dimensions and Operator Splitting
)
t
O(
)
v
v
v
2
v
(
2
t
)
v
v
(t
1
3
yy
2
y
xy
y
x
xx
2
x
2
y
y
x
x















     (6.17b) 
)
t
(
O
)t
(
L
3
XY




      (6.17c) 
Hence the sequence of 1D operators, LY(t) LX(t), is the same as the 2D operator LXY(t) up to O(t3).
This shows that the split scheme, 
]
u
)t
(
L
[)t
(
L
u
n
j,i
X
Y
1
n
j,i




     (6.18) 
can be used to solve (6.1a) instead of the unsplit scheme (6.8a). It is now just a matter of replacing the 
differential operators, by appropriate difference operators like we did before: e.g. LX becomes the 
difference marching operator,  
xx
2
x
2
x
x
X
v
2
t
v
t
1
)t
(
L








.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.mastersopenday.nl
Visit us and find out why we are the best!
Master’s Open Day: 22 February 2014
Join the best at
the Maastricht University
School of Business and
Economics!
Top master’s programmes
• 33rd place Financial Times worldwide ranking: MSc 
International Business
• 1st place: MSc International Business
• 1st place: MSc Financial Economics
• 2nd place: MSc Management of Learning
• 2nd place: MSc Economics
• 2nd place: MSc Econometrics and Operations Research
• 2nd place: MSc Global Supply Chain Management and 
Change
Sources: Keuzegids Master ranking 2013; Elsevier ‘Beste Studies’ ranking 2012; 
Financial Times Global Masters in Management ranking 2012
Maastricht
University is
the best specialist
university in the
Netherlands
(Elsevier)

 
Introductory Finite Difference Methods for PDEs
94 
Extension to Multi-dimensions and Operator Splitting
Notes: 
1.
(6.18) has the same temporal order as (6.8a). 
2.
The time step in (6.18) is the minimum allowable time step for each 1D operator and may be much 
larger than the time step for the unsplit 2D scheme (6.8a) which is one of the advantages of 
dimensional splitting. 
3.
(6.18) is implemented by first applying the LX operator to each row of the grid. This produces new 
values of the dependent variable at each grid point. The LY operator is then applied to the new data 
along each column of the grid. 
4.
The split operator sequence (6.18) is one of many split operator sequences which solve (6.1a).  
5.
LX and LY may be totally different FD schemes (although they should be the same order). 
6.
Our approach is called ‘dimensional splitting’ because a 2D PDE (6.1a) has been split into 2, 1D 
PDEs (6.14a, 6.14b). 
6.3.1.1 Example 4: Split FOU2D Scheme 
The FOU scheme is used for both LX and LY difference operators. i.e. (for positive velocities) we choose,
y
u
u
u
,
x
u
u
u
n
1
j,i
n
j,i
n
j,i
y
n
j,1
i
n
j,i
n
j,i
x










,
0
u
u
n
j,i
yy
n
j,i
xx




. So that, 
y
y
Y
x
x
X
v
t
1
)t
(
L
,
v
t
1
)t
(
L










.
Neglecting terms of O(t2) the split sequence (6.16) is, 
)
v
v
(t
1
)
v
t
1()
v
t
1(
)t
(
L
)t
(
L
y
y
x
x
y
y
x
x
X
Y















Equation (6.18) can be written, 
x sweep: 


n
j,1
i
n
j,i
x
n
j,i
j,i
u
u
C
u
u




     (6.19a) 
y sweep: 


1
j,i
j,i
y
j,i
1
n
j,i
u
u
C
u
u





     (6.19b) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
95 
Extension to Multi-dimensions and Operator Splitting
where,
j,iu
 (‘u bar’) is the new data at the grid point i,j produced by the LX operator and 
y
t
v
C
,
x
t
v
C
x
y
x
x






are the usual Courant numbers. 
Notes: 
1.  (6.19a) corresponds to 
n
j,i
X
j,i
u
)t
(
L
u


 and (6.19b) corresponds to
j,i
Y
1
n
j,i
u
)t
(
L
u



.
2.  












y
x
v
y
,
v
x
min
t
 where 
y
x
v
y
,
v
x 

 are the maximum time steps for the LX and LY operators 
respectively. These expressions were found previously by von Neumann stability analysis of the 1D 
FOU scheme. 
Code to implement the split FOU2D scheme (6.19a, 6.19b) may be downloaded from the website. 
6.3.1.2 Operator Splitting for Stiff Problems 
The allowable time step, t, for an explicit scheme depends on the ‘flow’ velocity and the grid spacing in 
each direction. Ideally we want to time-march with as large a time step as possible for computational 
speed. This cannot always be achieved by the ‘standard’ splitting (6.18) as we will see from the following 
example. Let the allowable time steps in x and y directions be tx and ty respectively. For the split 
FOU2D scheme, 


y
x
t
,
t
min
t




 where 
y
y
x
x
v
y
t
,
v
x
t






. Now suppose that |vx| >> |vy| (>> means 
‘much greater than’) then, assuming that the grid spacings are of the same order,  
tx << ty.
This defines a ‘stiff’ problem: the time scales for each component of the problem are very different. The 
‘standard’ split operator sequence, 
Lx(t) LY(t)     (6.20) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
96 
Extension to Multi-dimensions and Operator Splitting
requires that each operator marches using the same time step which has to be the minimum of tx and ty
for stability. Clearly the time step for LY is being constrained by the much smaller allowable time step in 
the x direction. It might be more efficient if we could change the splitting so that LY could march in steps 
of ty. We can!  
Suppose that ntx = ty where n is an integer. i.e. tx is n times as small as ty. Consider the new split 
operator sequence, 
n
y
X
y
Y
)]
n
/
t
(
L
[)
t
(
L


     (6.21) 
In this sequence LY is marching at its maximum time step, ty, and LX is marching at (1/n) of ty so to 
‘catch up’ we need to use LX n times. The following analysis shows that this approach works. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
97 
Extension to Multi-dimensions and Operator Splitting
From the split FOU2D scheme example,  
y
y
Y
x
x
X
v
t
1
)t
(
L
,
v
t
1
)t
(
L










. Substituting into (6.21) and using the Binomial expansion gives, 






2
x
x
y
y
y
2
x
x
y
y
y
y
2
x
x
y
y
y
y
n
x
x
y
y
y
y
t
O
)
v
v
(
t
1
)
t
O
v
t
1()
v
t
1(
)
t
O
v
/n)
t
(
n
1()
v
t
1(
)
v
/n)
t
(
1()
v
t
1(
































     (6.22) 
which is LY(ty) LX(ty) up to O(t2). This shows that the sequence (6.21) is valid. 
Notes: 
1.
If tx is not exactly a whole number times as small as ty replace ty by ntx where n is the largest 
integer such that ntx < ty.
2.
(6.21) says apply the operator LX to each row of the grid n times using a time step ty/n each time and 
using the updated values of u at each application. Then apply the LY operator to each column of the 
grid once using a time step ty.
3.
Since the multiplication in (6.22) is commutative another valid operator sequence is, 
m
y
X
y
Y
m
n
y
X
)]
n
/
t
(
L
[)
t
(
L
)]
n
/
t
(
L
[




.
4.
If LX and LY are second order (they aren’t in our example) and n is even then the symmetric sequence, 
2
/
n
y
X
y
Y
2
/
n
y
X
)]
n
/
t
(
L
[)
t
(
L
)]
n
/
t
(
L
[



is also second order. Where possible it is almost always better to use symmetric sequences. 
6.3.1.3 Exercise 6a 
1.
Show that (6.1b) is a solution to (6.1a). 
2.
Go through the calculations to get (6.2e). 
3.
Derive (6.3b). 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
98 
Extension to Multi-dimensions and Operator Splitting
4.  Write out (6.8a) in full to get (6.8b). 
5a.  Download ‘linearadvectionFOU2D’ and make sure you understand every line of code. 
5b.  Run ‘linearadvectionFOU2D’ and describe the output for the given parameters. 
5c.  By gradually increasing the safety factor F and running the code find its maximum value for a stable 
scheme based on the heuristic time step formula. 
5d.  Find the maximum time step for the FOU2D scheme based on the von Neumann stability analysis 
result and alter your program to use this time step. 
5e.  Change the sign of the x component of velocity and run the code. What happens to the numerical 
solution and why? 
i)  
Fix the problem so that your code can deal with vx < 0 and vy > 0. Test your program. 
ii) 
Fix the problem so that your code can deal with any velocities. Test your program. 
6. 
Find the expression for the time step based on von Neumann stability analysis for the 2D Lax-
Friedrichs scheme to solve the 2D linear advection equation. 
7. 
Copy ‘linearadvectionFOU2D’ to ‘linearadvectionLF2D’ and change the solver in this new file so 
that it uses the 2D Lax-Friedrichs scheme (don’t forget ghost values) and repeat Q5.  
8. 
By multiplying out and collecting terms, derive 6.17c from 6.17a. 
9. 
Show that LX(t) LY(t), is the same as LXY(t) up to O(t3) and hence write down another operator 
sequence to solve the 2D linear advection equation. 
10. Show that for the 2D linear advection equation with equal velocities in x and y directions, the time 
step for the LXLY split FOU2D scheme is twice that for the unsplit FOU2D scheme when grid 
spacings in x and y directions are equal. 
11. Compare time steps in Q10 when the Lax-Friedrichs scheme is used for all operators. 
12. Using the notation of (6.19ab) write down the FD scheme to solve the 2D linear advection equation 
with the Lax-Friedrichs scheme for all operators using the LXLY sequence. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
99 
Extension to Multi-dimensions and Operator Splitting
13.  Copy a suitable previous code to ‘linearadvectionFOU2Dsplit’ and modify it to solve the 2D linear 
advection equation using the split operator sequence, LY(t) LX(t), using the FOU scheme for each 
operator.  
14.  Copy a suitable previous code to ‘linearadvectionFOU2Dsplit’ and change it to solve the 2D linear 
advection equation using the split operator sequence 
)]
2
/t
(
L
[)t
(
L
)]
2
/t
(
L
[
X
Y
X



 using the Lax-
Friedrichs scheme for each operator.  
6.3.2 Term Splitting  
PDEs may contain several terms corresponding to different physical processes. As an example we use the 
1D advection-diffusion equation (5.1). Rather than solving the advection-diffusion equation directly it 
may be more efficient to use term splitting to solve each part separately and combine solutions. The 
following time step analysis shows why this could be a preferred option. 
Assuming v > 0, using a first order forward difference for the time derivative and a first order backward 
difference for the first space derivative, by previous analysis the time step for pure advection is, 
v
/
x
t A 


     (6.23a) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Get Help Now
Go to www.helpmyassignment.co.uk for more info
Need help with your
dissertation?
Get in-depth feedback & advice from experts in your 
topic area. Find out what you can do to improve
the quality of your dissertation!

 
Introductory Finite Difference Methods for PDEs
100 
Extension to Multi-dimensions and Operator Splitting
Using a first order forward difference for the time derivative and a symmetric difference for the space 
derivative, by previous analysis the time step for pure diffusion is, 
x
2
D
K
2
x
t



     (6.23b) 
Assuming v > 0, the time step for the unsplit scheme for advection-diffusion is, 
x
2
AD
K
2
x
v
x
t





     (6.23c) 
From which we can see that, 
A
AD
t
t



     (6.24a) 
and, 
D
AD
t
t



     (6.24b) 
This leads us to conclude that the corresponding direct (unsplit) scheme will have a smaller allowable time 
step than the split scheme (note also that as x gets smaller tAD becomes much smaller than tA). From 
our previous theory of split schemes we can derive a split scheme for the advection diffusion equation 
(5.1). We replace (5.1) by two PDEs, 
0
U
v
U
x
t


     (6.25a) 
and 
xx
x
t
U
K
U 
     (6.25b) 
(6.25a) is the pure advection equation and (6.25b) is the pure diffusion equation. Let LA(tA) and LD(tD)
be FD operators for solving (6.25a) and (6.25b) respectively. We will show that LD(t) LA(t) is a (term) 
split operator sequence for solving (5.1) where t = min(tA, tD). From the standard Taylor expansion 
with x constant, 
)
t
(
O
U
2
t
U
t
)
x,t(
U
)
x,t
t(
U
3
tt
2
t











     (6.26) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
101 
Extension to Multi-dimensions and Operator Splitting
Firstly we use the advection-diffusion equation (5.1) to replace the time derivatives in (6.26) by spatial 
derivatives. (5.1) can be written, 
U
)
K
v
(
U
xx
x
x
t






     (6.27a)
Hence,
U
)
K
K
v
2
v
(
U
)
K
v
)(
K
v
(
U
)
(
U
xxxx
2
x
xxx
x
xx
2
xx
x
x
xx
x
x
t
t
tt



















     (6.27b) 
Substituting (6.27ab) into (6.26) gives, 
)
t
O(
)U
K
K
2v
(v
2
t
U
)
K
v
(t
x)
U(t,
x)
t,
U(t
3
xxxx
2
x
xxx
x
xx
2
2
xx
x
x


















     (6.28) 
 U(t + t, x) = LAD(t) U(t, x) + O(t3)     (6.29a) 
where LAD(t) is an unsplit differential marching operator to solve the advection-diffusion equation given 
by, 
)
t
(
O
)
K
K
v
2
v
(
2
t
)
K
v
(t
1
)t
(
L
3
xxxx
2
x
xxx
x
xx
2
2
xx
x
x
AD

















     (6.29b) 
(6.29b) is made into a difference marching operator by replacing all partial derivatives by FD 
approximations. By previous work we know that a differential marching operator, LA(t), to solve the 
advection equation (6.25a) is given by, 
)
t
(
O
v
2
t
v
t
1
)t
(
L
3
xx
2
2
x
A










     (6.30) 
We derive a differential marching operator, LD(t), to solve the diffusion equation (6.25b). (6.25b) can be 
written, 
U
K
U
xx
x
t



     (6.31a) 
hence,
U
K
U
)
K
()
K
(
U
U
xxxx
2
x
xx
x
xx
x
t
t
tt









     (6.31b) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
102 
Extension to Multi-dimensions and Operator Splitting
Substituting (5.18ab) into (6.26) gives, 
)
t
(
O
U
K
2
t
U
K
t
)
x
,t(
U
)
x
,t
t(
U
3
xxxx
2
x
2
xx
x











     (6.32) 
U(t + t, x) = LD(t) U(t, x) + O(t3)     (6.33a) 
where LD(t) is an unsplit differential marching operator to solve the diffusion equation given by, 
)
t
(
O
K
2
t
K
t
1
)t
(
L
3
xxxx
2
x
2
xx
x
D










     (6.33b) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
By 2020, wind could provide one-tenth of our planet’s 
electricity needs. Already today, SKF’s innovative know-
how is crucial to running a large proportion of the 
world’s wind turbines. 
Up to 25 % of the generating costs relate to mainte-
nance. These can be reduced dramatically thanks to our 
systems for on-line condition monitoring and automatic 
lubrication. We help make it more economical to create 
cleaner, cheaper energy out of thin air. 
By sharing our experience, expertise, and creativity, 
industries can boost performance beyond expectations. 
Therefore we need the best employees who can 
meet this challenge!
The Power of Knowledge Engineering
Brain power
Plug into The Power of Knowledge Engineering. 
Visit us at www.skf.com/knowledge

 
Introductory Finite Difference Methods for PDEs
103 
Extension to Multi-dimensions and Operator Splitting
(6.33b) is made into a difference marching operator by replacing all partial derivatives by FD 
approximations. It now remains to show that LAD(t) is approximated by the split sequence LD(t) LA(t). 
)
t
(
O
)t
(
L
)
t
(
O
v
2
t
vK
t
v
t
K
2
t
K
t
1
)
t
(
O
v
2
t
v
t
1
)
t
(
O
K
2
t
K
t
1
)t
(
L
)t
(
L
3
AD
3
xx
2
2
xxx
x
2
x
xxxx
2
x
2
xx
x
3
xx
2
2
x
3
xxxx
2
x
2
xx
x
A
D





















































Hence the unsplit operator and the split operator sequence are the same up to O(t3).
Using the previous FD schemes the corresponding split scheme to solve the 1D advection-diffusion 
equation (5.1) is, 
LA:


n
1
i
n
i
n
i
i
u
u
x
t
v
u
u






     (6.34a) 
            LD:


1
i
i
1
i
2
x
n
i
1
n
i
u
u
2
u
x
t
K
u
u









     (6.34b) 
where,
.
K
2
x
,
v
x
min
t
x
2










     (6.35) 
Output is given in Figure 6.3 for the same conditions as for Figure 5.3. It can be seem that the peak 
concentration is in the correct place as before. This was achieved in fewer time steps. However the shape 
of the concentration profile is slightly different to that given by the unsplit scheme - it is higher and 
narrower. Perfect numerical schemes would give the same results for split and unsplit algorithms but no 
scheme is perfect and the effect of numerical diffusion in the advective solvers plays a different role in 
each algorithm.  
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
104 
Extension to Multi-dimensions and Operator Splitting
             
0
10
20
30
40
50
60
70
80
90
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
x
concentration u
advection-diffusion: initial profile (dotted) and split numerical solution (+) at later time, 
Figure 6.3 Initial profile and split numerical solution (+) to the 1D advection-diffusion equation at t = 57s.  
6.3.3 Exercise 6b 
1.
For v > 0 show that, a) 






AD
A
0
x
t
t
lim
, b) 
1
t
t
lim
AD
D
0
x





.
What do you conclude from this? 
2.
Go through the derivation of LAD, LD and LA and show that  
LAD = LD LA + O(t3).
3.
Write a program for the split scheme (6.34ab) and reproduce Figure 5.3. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
105 
Systems of Equations
7. Systems of Equations 
7.1 Introduction 
The world is governed by natural laws many of which can be expressed as systems of PDEs. An important 
example are the Navier-Stokes equations that, together with the Continuity Equation form a system of 6 
coupled PDEs which describe fluid flow in 3D. These equations are difficult to solve even approximately. 
In the following, a relatively simple system of PDEs has been chosen to illustrate the FD approach.   
7.2 The Shallow Water Equations 
The Shallow Water Equations (SWE) may be expressed in 1D or 2D and provide a simplified model of 
water flow which may be used to simulate many situations including river flow and tsunami propagation. 
For simplicity we consider only 1D. This is still useful and there are many 1D SWE software packages 
used by hydraulic engineers to make flow calculations for real life applications. 
The 1D SWE form a system of two coupled non-linear hyperbolic PDEs with independent variables,  
t (time) and x (distance along the flow) and dependent variables h = h(t,x) (flow depth) and v = v(t,x) 
(flow velocity).  
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
106 
Systems of Equations
Using our usual subscript notation to indicate partial differentiation the 1D SWE can be written  
compactly as,  
S(U)
F(U)
U
x
t


     (7.1) 
where,
,
v
h
h
U
U
U
2
1










     (7. 2a) 
,
2
/
h
g
v
h
v
h
F
F
F(U)
2
2
2
1













     (7. 2b) 







f
0 S
S
g
0
S(U)
     (7. 2c) 
where g is the acceleration due to gravity, U is the matrix of dependent variables, F(U) is called the flux 
vector and S(U) is called the matrix of source terms which here only consists of bed slope (So, measured 
positive downwards) and friction (Sf) terms. 
7.3 Solving the Shallow Water Equations 
7.3.1 Theoretical Background 
Explicit FD schemes need a limited time step for stability. Previous stability analyses assume linearity but 
the SWE are not linear and so we cannot use these approaches directly. It is therefore necessary to 
examine the SWE in some detail to determine stable time steps before looking at explicit FD schemes. 
Neglecting source terms and using the Chain-Rule (7.1) can be expressed in quasi-linear form as, 
0
U
J
U
x
t


     (7.3) 
where J is the Jacobian matrix given by, 




























2
2
1
2
2
1
1
1
U
F
U
F
U
F
U
F
U
F
J
.     (7.4) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
107 
Systems of Equations
It is easily shown that,  









v
2
gh
v
1
0
J
2
     (7.5)
J has two real eigenvalues, 
gh
v
,
gh
v
2
1






     (7.6) 
These eigenvalues are real and distinct and therefore give rise to corresponding linearly independent 
eigenvectors q1 and q2 (which we write as column vectors). By standard Linear Algebra theory there is a 
transformation of coordinates that diagonalizes J. This is now shown. Let, T = [ q1 q2 ], then, 
 
 
    J T = J [ q1 q2 ]
= [ J q1 J q2 ]
= [ 1 q1   2 q2 ] (by definition of eigenvalue) 
=











2
1
2
1
0
0
q
q
= T 








2
1
0
0
therefore, 
T-1 J T = 








2
1
0
0
= D     (7.7) 
We introduce a change of variable by defining 





2
1
W
W
W
 by, 
W = T-1 U     (7.8)
Assuming that T-1 is locally constant, then (7.3) becomes, 
0
W
T
J
W
T
x
t


     (7.9a) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
108 
Systems of Equations
Multiplying through on the left by T-1 and using (7.7) gives, 
0
W
D
W
x
t


     (7.9b) 
Since D is a diagonal matrix this system of equations has been decoupled by the change of variable. 
Writing out each row of (7.9b) gives, 
0
x
W
)
gh
v
(
t
W
1
1







     (7.10a) 
0
x
W
)
gh
v
(
t
W
2
2







     (7.10b) 
(7.10a) and (7.10b) are two linear advection equations with two wave speeds 
)
gh
v
(,)
gh
v
(


respectively. Any explicit scheme to solve the SWE must take account of the above wave speeds to ensure 
stability. Note that these wave speeds vary over both space and time.  
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
109 
Systems of Equations
7.3.2 Heuristic Time Step Calculation 
The following is a treatment of the time step calculation for the SWE based on the previous heuristic 
analysis of Appendix C. Suppose that a given explicit scheme to solve the advection equation ut + v ux = 0 
is stable when, 
)
v
5
/(
x
t 


     (7.11) 
where v is the wave speed (assume v > 0) and t and x are the time and space steps respectively. By the 
previous analysis, the same scheme will be stable when solving the SWE if the maximum wave speed 
(chosen over the spatial interval at a given time level) is used in the stability inequality.  
i.e. 


)
gh
v
(
),
gh
v
(
max
5
x
t
i





     (7.12) 
Furthermore, because the wave speeds also vary with time, this constraint must be applied at each  
time step.
7.4 Example Scheme to Solve the SWE 
The SWE (7.1) with S(U)=0 look very similar to the linear advection equation, ut + v ux = 0. We see that 
Ut is replaced by ut and Fx is replaced by v ux. The FOU scheme (Chapter 4) to solve the linear advection 
equation is, 
x
)
u
u
(
v
t
u
u
n
1
i
n
i
n
i
1
n
i







     (7.13a) 
The FOU scheme can be shown to be stable (for v>0) if, 
v
/
x
t 


.     (7.13b) 
We apply the same scheme (in the sense that the time derivative is replaced by the first order forward 
difference approximation and the spatial derivative is replaced by the first order backward difference 
approximation) to solve the SWE giving, 
x
)
F
F
(t
U
U
n
1
i
n
i
n
i
1
n
i







     (7.14a) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
110 
Systems of Equations
By the previous analysis the time step inequality (7.13b) becomes, 


)
gh
v
(
),
gh
v
(
max
x
t
i





     (7.14b)
(7.14b) must be applied at each time step. 
The above analysis shows that a program written to solve the linear advection equation may be modified 
to solve the SWE by appending an extra row to each array variable matrix. Prior to each time step a 
routine to calculate the new time step must be invoked. After each time step h and v are found from U 
(h=U1, v= U2/U1) and then U and F are initialized before the next time step.  
Figure 7.1 shows the Lax-Friedrichs scheme solution to the SWE for a collapsing water column (not 
shown is the graph for the associated water velocity). Initially the water is still and the surface profile is 
given in Figure 7.1. The program was run for 6 seconds using 201 grid points over [0, 200] and a time step 
safety factor of 0.95. Zero-gradient boundary conditions were used for both water height and velocity. 
Note that this problem has discontinuous initial conditions for h that can cause classical schemes problems 
(see the oscillations in Figure 7.1). There exist modern schemes to cope with discontinuities but they are 
beyond the scope of this text. 
0
10
20
30
40
50
60
70
80
90
100
0
2
4
6
8
10
12
x
g
Figure 7.1 Lax-Friedrichs solution to the Shallow Water Equations for a collapsing water column. Initial 
conditions (__), numerical solution (---) at t = 6s. 
h
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
111 
Systems of Equations
Code to implement the above scheme may be downloaded. A Case Study to illustrate the use of the 1D 
SWE is given on the website. This study also gives useful information on how to set up a problem and 
assess results. 
7.5 Exercise 7 
1.
Show that J is as given and use the Chain Rule to express (7.1) in the form of (7.3). 
2.
Find the eigenvalues of J. 
3.
Given that an explicit scheme to solve the linear advection equation with wave speed v is stable for 
)
v
3
/(
x
2
t



 state the (heuristic) stability criteria when this scheme is used to solve the SWE. 
4.
Comment on the sign of the wave speeds for the SWE when the flow is such that v > (gh)1/2.
5.
Modify one of your existing codes to solve the linear advection equation using the Lax-Friedrichs 
algorithm (use previous initial and boundary conditions). Verify your code. 
6.
Modify your program in Q5 to solve the SWE using the conditions of Figure 7.1. Reproduce Figure 
7.1.
7.
Animate the solutions for height and velocity in Q6 for and run until the water passes out of the 
domain. 
8.
Repeat Q7 with solid left and right hand boundary conditions (see Appendix B). 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
112 
Appendix A: Definition and Properties of Order
Appendix A: Definition and Properties of Order 
A.1 Definition of O(hPn
P)
For our purposes, 
f(h) = O(hPn
P)
(pronounced, ‘f of h is order h to the n’) means, 
C
h
)
h
(
f
lim
n
0
h


,     (A.1) 
where C is a non-zero constant. 
e.g. 500 hP6
P + 3 hP4
P - 2 hh
P = O(h) because, 
2
h
h
2
h
3
h
500
lim
4
6
0
h





e.g. 9hP4 = O(hP4
PP) because, 
9
h
h
9
lim
4
4
0
h


Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
EXPERIENCE THE POWER OF 
FULL ENGAGEMENT…
     RUN FASTER.
          RUN LONGER..
                RUN EASIER…
READ MORE & PRE-ORDER TODAY 
WWW.GAITEYE.COM
Challenge the way we run

 
Introductory Finite Difference Methods for PDEs
113 
Appendix A: Definition and Properties of Order
A.2 The Meaning of O(hPn
P)
If f(h) = O(hPn) then, for small h, equation (A.1) gives, 
C
h
)
h
(
f
n

,
    
n
h
C
)
h
(
f

P
(A.2) 
Equation (A.2) says that for small h, an error which is O(hPn) is proportional to hPn. In particular if the error 
is O(hP) then it is proportional to h which means that halving h halves the error. If the error is O(hP2
P) then it 
is proportional to hP2 which means that halving h reduces the error by a factor of 2P2 = 4.   
A.3 Properties of O(hPn
P)
In the analysis of finite difference schemes we will need to use the following properties of Order notation. 
Let f(h) = O(hPn
P), g(h) = O(hPm
P) where 0 < m < n. Let K be a non-zero constant. Then, 
A.3.1. K f(h) = O(hPn
P)
A.3.2. f(h) + g(h) = O(hPm
P)
A.3.3. f(h)/h = O(hPn-1
P)
A.3.4. f(h)/g(h) = O(hPn-m
P)
A.3.5. f(h) g(h) = O(hPn+m
P)
Proof of A.3.3 
By definition of Order we have to show that, 
1
n
0
h
h
h
/)
h
(
f
lim


 is a non-zero constant. 
Since f(h) = O(hn),
C
h
)
h
(
f
lim
n
0
h


, where C is a non-zero constant. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
114 
Appendix A: Definition and Properties of Order
C
h
)
h
(
f
lim
h
h
/)
h
(
f
lim
n
0
h
1
n
0
h






End of proof of A.3.3  
A.4 Explanation of the Properties of O(hPn
P)
A.3.1 says that scaling a function by a constant doesn’t change its order. In particular f(h) and –f(h) have 
the same order. 
A.3.2 says that the order of the sum of two functions of different orders is the smaller of the orders of the 
two functions. e.g.  
O(hP2
P) + O(hP3
P) = O(hP2
P).
A.3.3 says that dividing a function by h reduces its order by 1. A.3.3 is a special case of A.3.4 that says 
that dividing a function by a function of order m reduces its order by m. e.g. O(hP6
P)/ hP2
P = O(hP4
P).  
A.3.5 says that the order of the product of two functions is the sum of their orders. e.g.  
O(hP3
P) O(hP2
P)
P= O(hP5
P). 
A.5 Exercise A 
1.
Find the order of the following functions: 
2.
a) 2x + 5 xP3
P – 3 xP5
P b) 4 xP2
P – 17 xP4
P + 3 xP8
P 
 c) sin(x)  
d) x 
3.
Prove A.3.1) – A.3.5) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
115 
Appendix B: Boundary Conditions
Appendix B: Boundary Conditions 
B.1 Introduction 
When solving a PDE using a finite difference (FD) scheme we may need to specify ghost grid points and 
associated ghost values for the dependent variable at these points.  
e.g. in the FOU scheme to solve the 1D linear advection equation (Chapter 4) we need a ghost point to the
left of the first grid point. This is illustrated in the following diagram: 
Figure B.1 Ghost (white) and grid (black) points for the FOU scheme 
Notes: 
1.
In general for a 1D region on which grid points are indexed by i = 1, 2, … , N, we will index a left 
ghost point by i = 0 and a right ghost point by i = N + 1.  
2.
In many computer languages (e.g. Scilab and Matlab) array indices start at 1 so we must shift indices
when using them to code up a FD scheme with a left ghost point. For example to code the FOU 
scheme we shift grid indices so that the left hand ghost point index is 1 and so indices 2 to N+1 
represent the N computational grid points. If a scheme (e.g. Lax-Friedrichs) requires both left and 
right ghost points then the left ghost point has index 1 and the right ghost point has index N+2. 
x
i 
i 
i
i
i
x
ghost point 
x
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
116 
Appendix B: Boundary Conditions
B.2 Boundary Conditions 
In a computational region (which may be 1, 2 or 3D) ghost points and associated values occur at or 
adjacent to the boundaries of the region. Conditions leading to the prescription of ghost values are called 
boundary conditions. Boundary conditions are derived from the underlying physics of the situation. The 
correct treatment of boundary conditions is vital for accurate problem simulation. This is illustrated by 
considering the grid for a 2D region shown in Figure B.2. Grid points are indexed by i = 1, 2, … , N in the 
x direction and by j = 1, 2, … , M in the y direction. Indices 0, N+1 and M+1 indicate ghost points. To see 
the effect of different boundary conditions we consider the region to represent two different problems 
(modelled by the same PDEs who solution is approximated by a FD scheme requiring the ghost points 
shown).  
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
PDF components for PHP developers
www.setasign.com
SETASIGN
This e-book  
is made with 
SetaPDF

 
Introductory Finite Difference Methods for PDEs
117 
Appendix B: Boundary Conditions
B.2.1 Scenario 1 
Consider the region in Figure B.2 to represent a channel of water viewed from above and flowing from 
left to right. The rows having indices j = 1 and j = M correspond to the right and left sides of the channel 
respectively. If water cannot flow through or over the sides of the channel we must impose solid boundary 
conditions at each side by specifying the values of water depth and velocity at these locations in a special 
way. The columns with indices i = 1 and i =N are at inflow and outflow boundaries respectively and 
require water depths and velocities to be specified according to flow type.  
B.2.2 Scenario 2 
Consider the region in Figure B.2 to be a near-shore area of ocean as viewed from above with waves 
travelling from left to right and impacting on a solid harbour wall that cannot be overtopped. The harbour 
wall, being solid, requires a solid boundary condition be imposed on the column with i = N. The column 
with i = 1 requires a time dependent boundary condition (for water depth and velocity) to generate the 
incoming waves. The rows with j = 1 and j = M are edges of the finite computational domain and require 
transmissive boundary conditions to be imposed there so that waves can pass in and out of the 
computational domain.  
Figure B.2 Ghost (white) and grid (black) points for a 2D region 
( 
( 
(
(0,
(
i
j
(
(
(0,
(0,
(0,
(0,
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
118 
Appendix B: Boundary Conditions
From the two previous scenarios it is clear that changing the boundary conditions changes the problem.  
B.3 Specifying Ghost and Boundary Values 
There are two basic ways to specify values of the dependent variable at ghost points. For clarity we will 
assume that the ghost point is at index i = 0 in a 1D domain and hence i = 1 is the index of the grid point 
on left hand boundary. 
B.3.1 Dirichlet Boundary Conditions 
In Dirichlet boundary conditions the value,
n
0
u , of the dependent variable at a ghost point is specified in 
some way. Examples include: 
a)
t
tan
cons
un
0
. e.g. 
n
0
u  = 0 in the FOU scheme for the 1D linear advection equation (this condition 
indicates that there is no more pollutant entering the river, see Chapter 4). 
b)
)
n
(
f
un
0
, which is a time dependent boundary condition (e.g. a tidal boundary as in the previous 
harbour example). 
c)
n
N
n
0 u
u 
. This is a periodic boundary condition. This means that what passes out of the right 
boundary will pass in from the left boundary as though the two boundaries were joined together. 
B.3.2 Derivative (von Neumann) Boundary Conditions 
As the name suggests derivative boundary conditions specify the rate of change of the dependent variable 
at the grid point adjacent to the ghost point (i.e. at i = 1 in our case). This can be done in two ways: 
B.3.2.1 
)
U
(
f
Ux 
.
Here the derivative of U in the x direction is specified at the boundary grid point i = 1. From this 
information 
n
0
u  can be calculated. One way is to estimate 
x
U  at i = 1 by a central difference giving, 
x
2
u
u
)
U
(
f
U
n
0
n
2
x




     (B.1a) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
119 
Appendix B: Boundary Conditions
which rearranges to give, 
)
U
(
f
x
2
u
u
n
2
n
0



     (B.1b) 
B.3.2.2 
)
U
(
f
Un 
.
Here the derivative of U in the direction of n, the outward pointing normal to the boundary is given at the 
grid point adjacent to the ghost point. Note that this direction is opposite to the x direction at the left hand 
boundary (i = 1). From this information
n
0
u  can be calculated. As before we will use the left hand 
boundary and estimate 
n
U  at i = 1 by a central difference giving, 
x
2
u
u
)
U
(
f
U
n
2
n
0
n




     (B.2a) 
which rearranges to give, 
)
U
(
f
x
2
u
u
n
2
n
0



     (B.2b) 
Notes: 
1.
(B.1b) and (B.2b) are different because the directions of the given derivatives are opposite (the 
formulae would be the same at the right hand boundary). It is more usual to use (B.2b) then (B.1b). 
2.
In the derivative boundary condition examples central differences were used but other estimates 
could easily have been used (e.g. first order backward difference for the left hand ghost value).  
3.
The formal accuracy of a scheme may be reduced if ghost values are calculated on the basis of a 
method whose accuracy is less than the spatial accuracy of the scheme. e.g. a spatially third order 
scheme may drop to second order if a central difference (second order) is used to calculate a ghost 
value.
4.
In many numerical simulations both Dirichlet and von Neumann boundary conditions are used. These 
are called mixed boundary conditions. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
120 
Appendix B: Boundary Conditions
B.4 Common Boundary Conditions 
We give some boundary conditions that are used frequently in problems. 
B.4.1 Transmissive Boundary Conditions 
Computational domains are finite and it may be that we need quantities simply to pass out of a boundary 
when they reach one that is not solid. This is often done by specifying a zero gradient normal to the 
boundary in the variable of interest on the boundary i.e. we use a derivative boundary condition in which 
the derivative is zero. As an example consider Figure B.2 with Scenario 2 in which water height h is a 
dependent variable and the solver requires a ghost value at i = 3, j = 0. Grid point i = 3, j = 1 is on a 
transmissive boundary so we want waves to pass through. To impose the transmissive boundary condition 
on water height, h, we set hy=0 at grid point i = 3, j = 1. Using a first order backward difference 
approximation, 
y
h
h
0
h
n
0,3
n
1,3
x




     (B.3a) 
n
1,3
n
0
,3
h
h


     (B.3b) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
www.sylvania.com
We do not reinvent  
the wheel we reinvent 
light.
Fascinating lighting offers an infinite spectrum of 
possibilities: Innovative technologies and new  
markets provide both opportunities and challenges. 
An environment in which your expertise is in high 
demand. Enjoy the supportive working atmosphere 
within our global group and benefit from international 
career paths. Implement sustainable ideas in close 
cooperation with other specialists and contribute to 
influencing our future. Come and join us in reinventing 
light every day.
Light is OSRAM

 
Introductory Finite Difference Methods for PDEs
121 
Appendix B: Boundary Conditions
B.4.2 Solid (reflective) Boundary Conditions 
There is no flow through a solid boundary. This implies that the normal component of flow velocity at a 
solid boundary is zero. This condition is implemented by copying the normal component of velocity at the 
neighbouring interior grid point to the ghost cell and changing its sign. As an example consider Figure B.2 
with Scenario 1. Grid point i=3, j=1 is on a solid boundary and we wish to find the velocity at the ghost 
point i=3, j=0. Suppose the velocity at neighbouring interior grid point i=3, j=2 has x and y components vx
and vy respectively. The component of velocity normal to the solid boundary is vy so the velocity at the 
ghost point i=3, j=0 has x and y components vx and -vy respectively. Another way of obtaining this result 
is to linearly extrapolate using the normal velocities at i=3, j=2 (i.e. vy) and i=3, j=1 (i.e. 0). Variables 
other than velocity at ghost points next to solid boundaries are usually found by a zero gradient approach. 
B.4.3 Slip and No-Slip Boundary Conditions 
At a solid boundary we have a choice of tangential velocity component. If there is appreciable friction at 
the boundary then it is said to be a no-slip boundary and the tangential velocity component is zero (along 
with the normal component). If friction is not present then the boundary is said to be a slip boundary and 
the tangential component of velocity may be extrapolated from interior tangential components. 
B.5 Exercise B 
1.
A 1D PDE is to be solved numerically. The computational domain consists of N grid points 
numbered 1, 2, … , N. In each case give the indices of the ghost grid points for the following FD 
schemes (which can be found in Chapter 4), 
a.
FTCS scheme, b) Crank-Nicolson, c) Lax-Wendroff, d) Lax-Friedrichs. 
2.
Run the FOU scheme for the 1D linear advection equation (Chapter 4) using a periodic boundary 
condition and describe how the solution evolves in time. (Remember indices start at 1 in Scilab or 
Matlab). 
3.
The computational domain [0, 100] is discretised using 101 points. Initial values are given by  
U(0, x) = sin(x). The FOU scheme is used. Calculate the ghost point and the initial associated u value 
given the following boundary conditions, 
a)
Periodic, b) Dirichlet: 
1.0
u,1.0
u
n
1
N
n
0




 c) Derivative: 
0
Ux ,
d)
Derivative: 
1.0
Un 
. e) Derivative: 
U
Ux 
.
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
122 
Appendix B: Boundary Conditions
4.
Repeat Q3 for the Lax-Friedrichs scheme. 
5.
In Scenario 1 the flow velocity vector at grid point i=2, j=M-1 is (vx, vy) = (4, 8).  
a)
Calculate the flow velocity vector at ghost point i=2, j=M+1. 
b)
Assuming a no-slip boundary find the flow velocity vector at grid point i=2, j=M. 
c)
Repeat b) assuming a slip boundary. 
6.
In Scenario 2 the water height at grid point i=3, j=1 is 8. Find the water height at ghost point i=3, j=0. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
360°
thinking.
© Deloitte & Touche LLP and affiliated entities.
Discover the truth at www.deloitte.ca/careers 

 
Introductory Finite Difference Methods for PDEs
123 
Appendix C: Consistency, Convergence and Stability
Appendix C: Consistency, Convergence and Stability  
C.1 Introduction 
Consistency, convergence and stability are important concepts but much of the theory has only been 
developed for special cases so a combination of theory and numerical experimentation is often the only 
way to proceed (e.g. to find the maximum stable time step). For clarity we restrict our attention to a single 
PDE where there are two independent variables, t and x. The dependent variable is U = U(t, x). In operator 
notation the PDE is written, 
L U = 0      (C.1) 
L is a differential operator and U is the analytical (i.e. exact) solution of (C.1).  
In order to approximate the solution of (C.1) the computational region is discretised into a finite set of grid 
points, xi, where x is the (constant) grid spacing. The approximate solution is found at a set of time levels, 
tn where t is the (variable) spacing between time levels. The analytical (i.e. exact) solution to (C.1) at  
(tn, xi) namely U(tn, xi), is denoted by Ui
n. In operator notation the Finite Difference (FD) scheme to 
approximate the solution of (C.1) is written, 
0
u
D
n
i
x
,t



     (C.2) 
D is a difference operator and ui
n is the solution to the FD scheme at (tn, xi).
Notes: 
1.
The idea of the FD scheme (C.2) is that ui
n approximates Ui
n and the approximation becomes better 
and better as x and t become smaller. Let, 
ei
n = ui
n - Ui
n     (C.3) 
ei
n is called the pointwise error (also called the ‘global error’). 
2.
Initially (i.e. time level 0) U is known at all grid points and ui
0 is taken to be Ui
0 so ei
0 = 0 at all grid 
points. As iterations of the FD scheme introduce errors, in general 
0
en
i 
. It may be that as iterations 
continue errors are compounded and ei
n grows unboundedly making the FD scheme useless. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
124 
Appendix C: Consistency, Convergence and Stability
The following concepts look at properties of the FD scheme with respect to errors. 
C.2 Convergence 
The FD scheme (C.2) for the PDE (C.1) is said to be convergent at (t, x) if the pointwise error at (t, x) 
tends to zero as x and t tend to zero, i.e.  
.
0
x
,t
when
)
x
,t(
)
x
,
t(
as
0
e
i
n
n
i





     (C.4) 
To be useful our FD scheme must be convergent but this is very difficult to prove for many schemes. 
Convergence implies that a solution of the FD scheme approximates a solution of the PDE. 
C.3 Consistency and Scheme Order 
A measure of how well the exact solution of the PDE satisfies the FD scheme is given by the  
truncation error,
n
i
x
,t
U
D


     (C.5) 
The FD scheme (C.2) is consistent with the PDE (C.1) if the truncation error tends to zero as x and t
tend to zero, i.e. 
).
x
,
t(
at
0
x
,t
as
0
U
D
i
n
n
i
x
,t






     (C.6) 
Consistency is necessary for convergence.
The order of the truncation error is obtained by Taylor expansion of its terms about (tn
, xi). In many cases 
the order of the truncation error is the same as the order of the pointwise error so that the truncation error 
is a good (and accessible) guide to the accuracy of a FD scheme. We define the formal order of accuracy 
of a FD scheme by the order of its truncation error. 
C.3.1 Example Calculation of Consistency and Scheme Order 
The 1D linear advection equation is, 
0
U
v
U
x
t


     (C.7) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
125 
Appendix C: Consistency, Convergence and Stability
The FTCS scheme to solve (C.7) is given in Chapter 4. Writing this scheme in the form of (C.2) gives, 
0
x
2
u
u
v
t
u
u
n
1
i
n
1
i
n
i
1
n
i









     (C.8) 
To determine scheme consistency and order we replace u in (C.8) by the exact solution, U, of (C.7) to give 
the truncation error, 
0
x
2
U
U
v
t
U
U
n
1
i
n
1
i
n
i
1
n
i









     (C.9) 
Terms in (C.9) are replaced by their Taylor expansion about the ith spatial point and the nth time level to give, 
)
)
x
(
O
U
2
x
U
x
U
)
x
(
O
U
2
x
U
x
U
(
x
2
v
t
U
)
t
(
O
U
t
U
3
xx
2
x
n
i
3
xx
2
x
n
i
n
i
2
t
n
i





























     (C.10) 
Simplifying (C.10) (using properties of O notation) gives, 
Ut + v Ux + O(Dt) + O(Dx2)     (C.11) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
We will turn your CV into 
an opportunity of a lifetime
Do you like cars? Would you like to be a part of a successful brand?
We will appreciate and reward both your enthusiasm and talent.
Send us your CV. You will be surprised where it can take you.
Send us your CV on
www.employerforlife.com

 
Introductory Finite Difference Methods for PDEs
126 
Appendix C: Consistency, Convergence and Stability
and using (C.7) the truncation error is finally,  
)
x
(
O
)t
(
O
2



     (C.12) 
Clearly the truncation error (C.12) tends to zero as 
0
x
,t



which demonstrates that the FTCS scheme 
(C.8) is consistent with the original PDE (C.7). Furthermore the truncation error is first order in time and 
second order in space so the FTCS scheme is said to be (formally) first order in time and second order in 
space.  
Notes: 
1.  In the Taylor expansions we expanded to second order for t and to third order for x. It doesn’t matter 
if we expand too far as additive order expressions collapse to the term of lowest order. 
2.  Consistency does not imply that a FD scheme is any good! In fact the FTCS doesn’t work for reasons 
we now explore.  
C.4 Stability 
We have seen from numerical results in Chapter 4 that care must be used when choosing the time step, t.
A scheme that produces acceptable results for small t can give results that grow unboundedly as 
iterations continue if too large a t is chosen. In this case the scheme is said to have become unstable. A 
FD scheme is stable if and only if pointwise errors do not grow unboundedly with time which will be the 
case if, after some time level, N, 
.
N
n
,
e
e
n
1
n



     (C.13a) 
Another way of defining stability comes from the following argument. Rewriting (C.3) gives,  
ui
n = Ui
n + ei
n     (C.13b) 
For stability ei
n must not grow unboundedly and since Ui
n is finite, (C.13b) implies that ui
n must also not 
grow unboundedly which is true if, 
.
N
n
,
u
u
n
1
n



     (C.13c) 
The Lax Equivalence Theorem says that for a linear PDE, a consistent FD scheme to approximate its 
solution is convergent if and only if it is stable.  
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
127 
Appendix C: Consistency, Convergence and Stability
C.4.1 Heuristic Stability Analysis 
The following reasoning gives a guide to choosing a stable time step and may be applied to PDEs where 
there is a speed of propagation. We apply our reasoning to the simple 1D linear advection equation of 
Chapter 4 (we will see in Chapter 7 that this reasoning extends to more complicated PDEs). Reasoning 
goes as follows: during time step, t, the concentration profile travels a distance |v|t downstream. To 
capture the solution numerically it seems reasonable not to let the concentration profile move more than 
one grid interval, x, in a single time step, t. This means that, 
x
t
|
v
|



,
|
v
|
x
t 



     (C.14a) 
Inequality (C.14a) gives a heuristic guide to the maximum allowable time step (for the linear advection 
equation). It is often a good idea to multiply this maximum value by a ‘safety factor’ F where, F < 1. 
Numerical experiments can then be used to determine F. It is customary to let, 
x
t
v
c



     (C.14b) 
c is called the Courant number. As we will see, schemes are often stable for c less than or equal to some 
number. (C.14a) implies that, 
1
|
c
|
     (C.14c) 
This is called the CFL condition (after Courant, Friedrichs and Lewy). 
C.4.2 Matrix Stability Analysis 
This is a more mathematical approach to stability analysis but it only applies to linear FD schemes. By 
writing out a linear FD scheme at each grid point and expressing the resulting set of linear equations as a 
single matrix equation, a linear FD scheme with 2 times levels can be written as, 
n
1
n
u
B
u
A


     (C.15) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
128 
Appendix C: Consistency, Convergence and Stability
where,


T
n
N
n
2
n
1
n
u
...,
,
u,
u
u 
and A and B are NxN matrices (A = I for an explicit scheme). If the FD 
scheme is consistent it is satisfied by the exact solution of the PDE (neglecting the vanishing truncation 
error) and so, 
n
i
1
n
i
U
B
U
A


      (C.16) 
Subtracting (C.16) from (C.15) and using (C.3) gives, 
n
1
n
e
B
e
A


     (C.17a) 
n
1
1
n
e
B
A
e



     (C.17b) 
n
1
1
n
e
B
A
e



     (C.17c) 
n
1
1
n
e
B
A
e



     (C.17d) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
AXA Global 
Graduate Program
Find out more and apply

 
Introductory Finite Difference Methods for PDEs
129 
Appendix C: Consistency, Convergence and Stability
Hence by (C.13a) the FD scheme (C.15) is stable if, 
1
B
A 1


     (C.18) 
The matrix norm in (C.18) is induced by the vector norm in (C.13a). Hence the stability of a (linear) FD 
scheme can be investigated by finding the norm of the matrix A-1B. This is the matrix method for stability 
and may be quite difficult to implement. It should be noted that there are many definitions of norms and a 
FD scheme may be stable in one norm but not in another. 
C.4.2.1 Example of Matrix Stability Analysis 
From Chapter 4 the FOU scheme to solve the 1D linear advection equation (C.7) can be written, 
n
i
n
1
i
1
n
i
u
)c
1(
u
c
u





     (C.19) 
Where c is defined in (C.14b). We use matrix stability analysis to find the maximum time step for scheme 
stability. Writing (C.19) out for each grid point, assuming 
0
un
0 
 at all time levels and expressing the 
resulting linear equations in the form of (C.15) gives, 
n
1
n
u
)c
1(
c
...
0
0
...
0
)c
1(
c
0
...
0
)c
1(
c
0
...
0
0
)c
1(
u























     (C.20)
(C.19) is stable if the norm of the above matrix is less than or equal to 1. If we use the infinity norm for 
vectors (which is the maximum absolute value of components) the induced matrix norm is the maximum 
of the sum of all absolute values in each row. For our matrix this is |c| + |1-c|. For 
1
c
0


 (which implies 
that v>0), |c| + |1-c| = c + (1-c) = 1. Hence the FOU scheme is stable for 
1
c
0


 and hence the maximum 
allowable time step for stability is v
x

 which agrees with the previous heuristically derived result. The 
FOU scheme is said to be conditionally stable. 
C.4.3 Von Neumann Stability Analysis 
This analysis of stability is due to von Neumann and is based on (C.13c). We assume that the FD scheme 
is linear and that boundary conditions are periodic. Using the complex version of Fourier’s Theorem and 
rescaling so that u has period 2, we may write, 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
130 
Appendix C: Consistency, Convergence and Stability





k
x
kj
n
k
n
i
i
e
g
u
     (C.21)
where,
1
j


, and 
n
k
g
 is the amplitude of the kth Fourier component.  
By linearity it is enough to examine the behaviour of a single Fourier component so we replace 
ix
kj
n
k
n
i
e
g
by
u
 in (C.13c) and rearrange to get, 
1
g
g
G
n
k
1
n
k



     (C.22) 
This is the von Neumann condition for stability. G is called the amplification factor. Von Neumann 
stability is carried out by the following steps: 
Step 1. Replace each instance of 
n
iu  in the FD scheme by its corresponding single Fourier component. 
Step 2. Rearrange to get G.  
Step 3. Use the constraint (C.22) to obtain the condition for t (this step could be algebraically tricky). If 
(C.22) can never be satisfied for t > 0 the scheme is unconditionally unstable.
C.4.3.1 Von Neumann Stability Analysis: Example 1 
The FTCS scheme for the 1D linear advection equation is, 


n
1
i
n
1
i
n
i
1
n
i
u
u
x
2
t
v
u
u








,     (C.23a)
which can be written compactly as, 


n
1
i
n
1
i
n
i
1
n
i
u
u
2
c
u
u






,      (C.23b)
where c is the usual Courant number defined by (C.14b). 
Step 1: The FD scheme is linear and we assume periodic boundary conditions. Replacing each term in 
(C.23b) by its kth Fourier component gives, 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
131 
Appendix C: Consistency, Convergence and Stability


1
i
1
i
i
i
jkx
n
k
jkx
n
k
jkx
n
k
jkx
1
n
k
e
g
e
g
2
c
e
g
e
g





     (C.24)
Step 2: Noting that xi+1 = xi + x, xi-1 = xi - x , gives, 


)
x
x
(
jk
n
k
)
x
x
(
jk
n
k
jkx
n
k
jkx
1
n
k
i
i
i
i
e
g
e
g
2
c
e
g
e
g








     (C.25)
Dividing through by 
i
jkx
n
ke
g
gives, 


x
jk
x
jk
n
k
1
n
k
e
e
2
c
1
g
g







     (C.26)
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
ibili
because 
e Graduate Programme  
for Engineers and Geoscientists
Month 16
I was a construction
supervisor in 
the North Sea 
advising and 
helping foremen 
solve problems
I was a
he
s
Real work 
International opportunities 

ree work placements
al 
Internationa
or

ree wo
I wanted real responsibili 
 I joined MITAS because 
www.discovermitas.com

 
Introductory Finite Difference Methods for PDEs
132 
Appendix C: Consistency, Convergence and Stability
Step 3: From (C.22) for stability we must have, 

1
e
e
2
c
1
G
x
jk
x
jk







     (C.27) 
Using the well known identity,












j
2
e
e
)
sin(
j
j
(C.27) gives, 
1
x)
sin(k
C
j
1



     (C.28) 
Squaring each side and evaluating the squared modulus gives, 
1
x)
(k
sin
c
1
2
2



     (C.29) 
This inequality can only be satisfied (for all k) if c = 0 which implies that t = 0. i.e. there is no feasible 
value for the time step that makes the scheme stable. i.e. the FTCS scheme for the 1D linear advection 
equation is unconditionally unstable. The FTCS scheme is therefore useless even though we have shown 
that it is consistent! 
C.4.3.2 Von Neumann Stability Analysis: Example 2 
We apply von Neumann stability analysis to the FOU scheme (C.19). 
Step 1: Replacing each term in (C.19) by its kth Fourier component gives, 
1
i
i
i
jkx
n
k
jkx
n
k
jkx
1
n
k
e
g
c
e
g
c)
(1
e
g





     (C.30) 
Noting that xi-1 = xi - x, gives, 
)
x
jk(x
n
k
jkx
n
k
jkx
1
n
k
i
i
i
e
g
c
e
g
c)
(1
e
g






     (C.31)
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
133 
Appendix C: Consistency, Convergence and Stability
Step 2: Dividing through by 
i
jkx
n
ke
g
gives, 
x
jk
-
n
k
1
n
k
e
c
c)
(1
g
g





     (C.32) 
Step 3: For stability we must have, 
1
e
c
c)
(1
G
x
-jk





     (C.33) 
The well-known triangle inequality states that, 
|
b
|
|
a
|
|
b
a
|



,
hence,
c
c)
(1
e
c
c)
(1
e
c
c)
(1
x
-jk
x
-jk










     (C.34)
When 
c
|
c
|
and
c
1
|c
1
|,1
c
0






, therefore (C.34) gives, 
1
c
c)
1(
c
c)
(1
e
c
c)
(1
x
-jk










     (C.35) 
Hence the FOU scheme for the 1D linear advection equation is stable when 
1
c
0


 which means that 
v
x
t



. The FOU scheme is said to be conditionally stable. 
Notes: 
1.  Stability analysis hasn’t been worked out for most non-linear schemes (PDEs). 
2.  Strictly speaking, the von Neumann stability analysis requires periodic boundary conditions but 
seems to work even when this is not the case. 
C.5 Exercise C 
1.  Show that the FOU scheme for the 1D linear advection equation is consistent and find its formal 
order.
2.  Repeat Q1 for a) Lax-Friedrichs b) Lax-Wendroff c) Crank-Nicolson 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
134 
Appendix C: Consistency, Convergence and Stability
3.  Show that the 5-point scheme of Chapter 3 for the 2D Laplace’s Equation is consistent and find its 
formal order. 
4.  Using heuristic analysis, estimate the maximum allowable time step for an explicit scheme to solve 
the 1D linear advection equation for pollution in a river 0.5 km long flowing at 4m/s using 200 grid 
points. 
5.  Use von Neumann stability analysis to show that the FD scheme to solve the linear advection 
equation for v > 0 using first order forward differences in both space and time is unconditionally 
unstable. 
6.  Use von Neumann stability analysis to show that the Crank-Nicolson scheme to solve the 1D linear 
advection equation is unconditionally stable. 
7.  Use von Neumann stability analysis to investigate the stability of the Lax-Friedrichs scheme to solve 
the 1D linear advection equation. 
8.  Repeat Q7 for the Leap-Frog scheme.  
9.  Repeat Q5-Q7 using matrix stability analysis. 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
MASTER IN MANAGEMENT
mim.admissions@ie.edu
Follow us on IE MIM Experience
www.ie.edu/master-management
#10 WORLDWIDE
MASTER IN MANAGEMENT 
FINANCIAL TIMES
55 Nationalities
in class
5 Specializations
Personalize your program 
Length: 1O MONTHS
Av. Experience: 1 YEAR
Language: ENGLISH / SPANISH
Format: FULL-TIME
Intakes: SEPT / FEB
• STUDY IN THE CENTER OF MADRID AND TAKE ADVANTAGE OF THE UNIQUE OPPORTUNITIES
  THAT THE CAPITAL OF SPAIN OFFERS
• PROPEL YOUR EDUCATION BY EARNING A DOUBLE DEGREE THAT BEST SUITS YOUR
  PROFESSIONAL GOALS
• STUDY A SEMESTER ABROAD AND BECOME A GLOBAL CITIZEN WITH THE BEYOND BORDERS
  EXPERIENCE
93%
OF MIM STUDENTS ARE
WORKING IN THEIR SECTOR 3 MONTHS
FOLLOWING GRADUATION

 
Introductory Finite Difference Methods for PDEs
135 
Appendix D: Convergence Analysis for Iterative Methods
Appendix D: Convergence Analysis for Iterative 
Methods
D.1 Introduction 
Iterative schemes for matrix inversion do not necessarily converge so we need to determine conditions for 
convergence. We would also like to know how fast they converge. In the following we assume that the 
reader is familiar with some standard results from Linear Algebra. We are trying to solve the system of 
linear equations (refer back to Equations (3.6), (3.9)), 
A u = b     (D.1) 
where A is an NxN matrix, u is a column vector of N unknowns and b is a column vector of N known 
constants. It is always possible to scale each equation so that every entry on the main diagonal of A is 1. A 
can then be written as, 
A = - L + I – U     (D.2) 
where I is the NxN identity matrix and L and U are NxN lower and upper triangular matrices respectively. 
Substituting (D.2) into (D.1) and rearranging gives, 
u = (L + U) u + b     (D.3) 
Equation (D.3) is the basis for the following analysis. 
Notes: 
1.
Research into computationally efficient ways to invert a matrix continues. Computational efficiency 
is not simply a matter of reducing the number of calculations for a particular class of problem; it also 
depends on computer architecture. It may be that some less sophisticated method is faster than a more 
modern method when run on a parallel computer.  
2.
There are many efficient freely downloadable matrix inversion programs so it is almost never worth 
writing your own. 
3.
There is probably no best solution to computational efficiency. Where speed is an issue it will pay to 
experiment with several methods and tune them (if necessary) by numerical experiments on small 
problems.  
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
136 
Appendix D: Convergence Analysis for Iterative Methods
D.2 Jacobi Iteration 
Equation (D.3) suggests the iterative scheme, 
um+1 = (L + U) um + b     (D.4) 
which is the Jacobi iteration scheme in matrix form. (L + U) is called the iteration matrix. In order to 
analyse convergence of the Jacobi iteration scheme we need to look at how the error behaves between 
iterations. Clearly we want the error to decrease to zero as iterations continue. The exact solution to (D.1) 
is u. Let the error after the mth iteration be em, so, 
em = um – u     (D.5) 
Note that em is a vector in RN whose components are the errors at each grid point after the mth iteration. 
Subtracting (D.3) from (D.4) gives, 
um+1 - u = (L + U) um + b - (L + U) u – b       (D.6) 
em+1 = (L + U) em      (D.7) 
writing e0 for the initial error in the initial (guessed) values for u0, after 1 iteration (D.7) gives, 
e1 = (L + U) e0 . 
A second iteration gives, 
e2 = (L + U) e1
        = (L + U)2 e0 .  
So after n iterations we have 
                            
 
 
         en = (L + U)n e0      (D.8) 
For convergence of the iterative scheme all components of en must approach zero in the limit,  
i.e. 
0
e
lim
n
n




0
e
)
U
L
(
lim
0
n
n




Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
137 
Appendix D: Convergence Analysis for Iterative Methods
Since e0 is a non-zero constant vector we must focus our attention on the behaviour of (L + U)n. We 
assume that (L + U) has n linearly independent eigenvectors, v1, v2, … , vN with corresponding 
eigenvalues, 1, 2, … , N. By a standard result from Linear Algebra (L + U)n has the same eigenvectors 
with corresponding eigenvalues, 1
n, 2
n, … , N
n. The set of eigenvectors form a basis for RN so for some 
constants ai we may write, 
           e0 = a1 v1 + a2 v2 + … + aN vN. 
      (L + U)n e0 = (L + U)n (a1 v1 + a2 v2 + … + aN vN)
= (L + U)n a1 v1 + (L + U)n a2 v2 + … + (L + U)n aN vN
       
 
 
  = a1 (L + U)n v1 + a2 (L + U)n v2 + … + aN (L + U)n vN
  = a1 1
n v1 + a2 2
n v2 + ... + aN N
n vN
which will clearly tend to the zero vector if and only if, 
|i| < 1, for i = 1, 2, …, N. 
Definition: The dominant eigenvalue of a matrix is the eigenvalue with the largest modulus. 
Hence we can say that the Jacobi iterative scheme converges if and only if the dominant eigenvalue of its 
iteration matrix has modulus less than 1. We denote the dominant eigenvalue of the Jacobi iteration matrix 
by .
D.3 Gauss-Seidel Iteration 
Using the previous notation it can be shown that the Gauss-Seidel iterative method can be expressed as, 
um+1 = U um + L um+1 + b     (D.9) 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
138 
Appendix D: Convergence Analysis for Iterative Methods
and a similar analysis to the Jacobi iterative scheme shows that, 
     em+1 = U em + L em+1     (D.10a) 
 em+1 = (I – L)-1 U em     (D.10b) 
    em+1 = ((I – L)-1 U)m e0     (D.10c) 
(I – L)-1 U is called the Gauss-Seidel iteration matrix. By an exactly similar analysis to that for Jacobi 
iteration, the Gauss-Seidel scheme converges if and only if the dominant eigenvalue of its iteration matrix 
has modulus less than 1. It can be shown that the dominant eigenvalue = 2.
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more

 
Introductory Finite Difference Methods for PDEs
139 
Appendix D: Convergence Analysis for Iterative Methods
D.4 SoR Iterative Scheme 
A similar analysis to the above shows that the SoR iteration matrix is, 
(I – w U)-1 ((1 – w) I + w L)     (D.11a) 
It can be shown that its dominant eigenvalue, is, 
1
1
1
2
2 



 (D.11b)
As before the scheme converges if and only if this has modulus less than 1. 
D.4.1 A Special Case for SoR 
For a rectangular px by qy computational region the optimal value of the SoR relaxation parameter can 
be shown to be, 




1
1
2
wo
      (D.12a)
where the dominant eigenvalue, , of the corresponding Gauss-Seidel scheme is, 
4
)
q
cos(
)
p
cos(
2











     (D.12b)
D.5 Theory for Dominant Eigenvalues 
Convergence of iterative schemes depends on the dominant eigenvalue of the associated iteration matrix 
having a modulus less than 1. In general it is difficult and/or computationally expensive to find 
eigenvalues. The following theorem is a quick way to find an upper bound for the modulus of the 
dominant eigenvalue of a matrix. 
D.5.1 Gershgorin’s Theorem 
The modulus of the dominant eigenvalue of a matrix is less than or equal to the sum of the modulii of the 
entries in any row or column. 
e.g. Let 













3.0
1.0
4.0
3.0
2.0
2.0
1.0
1.0
3.0
A
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
140 
Appendix D: Convergence Analysis for Iterative Methods
The sums of the modulii are: 
Row 1: |0.3|+|-0.1|+|0.1| = 0.5, Row 2: |0.2|+|0.2|+|0.3| = 0.7 
Row 3: |0.4|+|0.1| |-0.3| = 0.8, Col 1: |0.3|+|0.2|+|0.4| = 0.9
Col 2: |-0.1|+|0.2|+|0.1| = 0.4, Col 3: |0.1|+|0.3|+|-0.3| = 0.7 
Hence the dominant eigenvalue of A is less than or equal to 0.9. If A were an iteration matrix then the 
iteration scheme would converge. If the maximum value of the sum of the modulii of the row or column 
elements is greater than 1 then the theorem is no use for determining whether the scheme converges. In 
this case we need a way of estimating the dominant eigenvalue. 
D.5.2 Power Method for Estimating Dominant Eigenvalues  
This is an efficient way of estimating the dominant eigenvalue (and associated eigenvector) of a matrix A. 
Start with an arbitrary non-zero vector v0 and define the iterative scheme, 
vi+1 = A vi     (D.13) 
It can be shown that as the iteration index i tends to infinity, vi+1 tends to  vi where  is the dominant 
eigenvalue of A with associated eigenvector vi and where after each iteration the resulting vector, vi+1, is 
scaled by a constant ki (which is the reciprocal of its first entry) so that its first component becomes 1. The 
distance between the scaled versions of vi+1 and vi is found and the iteration stops when this distance is 
less than some predefined tolerance. The resulting estimate for the dominant eigenvalue of A is ki.
D.5.2.1 Example Power Method Calculation 
e.g. 







2
1
1
2
A
. We use the power method with a tolerance of tol = 0.01 to find the dominant eigenvalue  
of A.  
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
141 
Appendix D: Convergence Analysis for Iterative Methods
Let, 






0
1
v
0
. Using the iteration scheme (D.13), 
.
5.0
1
2
1
2
0
1
2
1
1
2
v
1



























.
5.0
1
v
scaled
and
2
k
so
1
1










|
v
v|
0
1
= 0.5 > tol, so the iterations continue, 
,
8.0
1
5.2
2
5.2
5.0
1
2
1
1
2
v
2



































8.0
1
v
scaled
and
5.2
k
so
2
2
Comparing the scaled vectors gives, 


|
v
v|
1
2
= 0.3 > tol so the iterations continue and after 6 iterations we have, 
,
9973
.0
1
9918
.2
v
6















9973
.0
1
v
scaled
and
9918
.2
k
so
6
6
Comparing scaled vectors gives, 


|
v
v|
5
6
 = 0.0055 < tol, so the iterations stop. An estimate for the 
dominant eigenvalue of A is k6 = 2.9918 (with v6 being the corresponding estimated eigenvalue). The 
exact answer is 3. Computer code for this method can be downloaded from the website. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
142 
Appendix D: Convergence Analysis for Iterative Methods
D.6 Rates of Convergence of Iterative Schemes 
The Rate of Convergence (RoC) of an iterative scheme is a measure of the number of iterations needed to 
converge to some given tolerance. It turns out that the RoC of an iterative scheme can be defined as, 
– loge      (D.14)
where  is the dominant eigenvalue of its iteration matrix. 
The relative RoC of two schemes with dominant eigenvaluesand  is, 
2
e
1
e
log
log




     (D.15) 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
“The perfect start 
of a successful, 
international career.”
CLICK HERE 
to discover why both socially 
and academically the University 
of Groningen is one of the best 
places for a student to be 
www.rug.nl/feb/education
Excellent Economics and Business programmes at:

 
Introductory Finite Difference Methods for PDEs
143 
Appendix D: Convergence Analysis for Iterative Methods
We can now compare (convergent) iterative schemes. 
e.g. Given that the point-Jacobi scheme is convergent with dominant eigenvalue  we know that the point-
Gauss-Seidel scheme has dominant eigenvalue 2 and so is also convergent. By (D.15) the relative RoC of 
the Gauss-Seidel scheme to the Jacobi scheme is, 
2
log
log
e
2
e





i.e. the number of iterations to achieve the same level of accuracy using the Gauss-Seidel scheme is 
approximately half that of the Jacobi scheme. 
The relative RoC isn’t the whole story when comparing iterative schemes. It could be that an iterative 
scheme needs many iterations to converge but that each iteration is computationally fast. This could make 
it a faster than a quick converging but computationally slow scheme.  
D.7 Exercise D 
1.
1.
















5.0
5.0
1.0
5.0
1.0
3.0
1.0
3.0
2.0
A
. Use Gershgorin’s theorem to provide an upper bound for the dominant 
eigenvalue of A. If A was an iteration matrix would the iteration converge? 
2.
Find the exact dominant eigenvalue for 






2
1
1
2
 and compare with the results from the power method 
code which you should run with a tolerance of 0.001. 
3.
Adapt the power method code to estimate the dominant eigenvalue for the matrix in Q1. Check your 
answer by using Scilab’s (or Matlab’s) built-in function for finding eigenvalues.  
4.
Given that the Jacobi iterative scheme converges show that the Gauss-Seidel scheme also converges. 
Show that the SoR scheme also converges. 
5.
Find the RoC for an iterative scheme with dominant eigenvalue 0.3. 
6.
Repeat Q5 for a dominant eigenvalue of 0.6. 
Download free eBooks at bookboon.com

 
Introductory Finite Difference Methods for PDEs
144 
Appendix D: Convergence Analysis for Iterative Methods
7.
Given that a Gauss-Seidel iterative scheme has dominant eigenvalue 0.5 find the relative RoC of SoR 
to Gauss-Seidel. 
8.
Iterative scheme 1 has dominant eigenvalue 0.3 and iterative scheme 2 has dominant eigenvalue 0.6. 
Which scheme converges fastest? If scheme 1 takes 20 iterations to converge approximately in how 
many iterations does scheme 2 to converge (with the same tolerance)? 
Download free eBooks at bookboon.com
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
Click on the ad to read more
American online      
LIGS University 
▶▶enroll by September 30th, 2014 and 
▶▶save up to 16% on the tuition!
▶▶pay in 10 installments / 2 years
▶▶Interactive Online education
▶▶visit www.ligsuniversity.com to 
      find out more!
is currently enrolling in the
Interactive Online BBA, MBA, MSc, 
DBA and PhD  programs:
Note: LIGS University is not accredited by any 
nationally recognized accrediting agency listed 
by the US Secretary of Education. 
More info here. 

