DISCRETE
MATHEMATICS
ITS APPLICATIONS
Series Editor
Kenneth H.Rosen, Ph.D.
Charles J.Colbourn and Jeffrey H.Dinitz, The CRC Handbook of Combinatorial
Designs
Charalambos A.Charalambides, Enumerative Combinatorics
Steven Furino, Ying Miao, and Jianxing Yin, Frames and Resolvable Designs:
Uses, Constructions, and Existence
Randy Goldberg and Lance Riek, A Practical Handbook of Speech Coders
Jacob E.Goodman and Joseph O’Rourke, Handbook of Discrete and
Computational Geometry, Second Edition
Jonathan Gross and Jay Yellen, Graph Theory and Its Applications
Jonathan Gross and Jay Yellen, Handbook of Graph Theory
Darrel R.Hankerson, Greg A.Harris, and Peter D.Johnson, Introduction to
Information Theory and Data Compression, Second Edition
Daryl D.Harms, Miroslav Kraetzl, Charles J.Colbourn, and John S.Devitt, Network
Reliability: Experiments with a Symbolic Algebra Environment
David M.Jackson and Terry I.Visentin, An Atlas of Smaller Maps in Orientable
and Nonorientable Surfaces
Richard E.Klima, Ernest Stitzinger, and Neil P.Sigmon, Abstract Algebra
Applications with Maple
Patrick Knupp and Kambiz Salari, Verification of Computer Codes in
Computational Science and Engineering
Donald L.Kreher and Douglas R.Stinson, Combinatorial Algorithms: Generation
Enumeration and Search
Charles C.Lindner and Christopher A.Rodgers, Design Theory
Alfred J.Menezes, Paul C.van Oorschot, and Scott A.Vanstone, Handbook of
Applied Cryptography
Richard A.Mollin, Algebraic Number Theory
Richard A.Mollin, Fundamental Number Theory with Applications
Richard A.Mollin, An Introduction to Cryptography
AND
© 2005 by Chapman & Hall/CRC Press

Richard A.Mollin, Quadratics
Richard A.Mollin, RSA and Public-Key Cryptography
Kenneth H.Rosen, Handbook of Discrete and Combinatorial Mathematics
Douglas R.Shier and K.T.Wallenius, Applied Mathematical Modeling: A
Multidisciplinary Approach
Douglas R.Stinson, Cryptography: Theory and Practice, Second Edition
Roberto Togneri and Christopher J.deSilva, Fundamentals of Information Theory
and Coding Design
Lawrence C.Washington, Elliptic Curves: Number Theory and Cryptography
Kun-Mao Chao and Bang Ye Wu, Spanning Trees and Optimization Problems
Juergen Bierbrauer, Introduction to Coding Theory
William Kocay and Donald L.Kreher, Graphs, Algorithms, and Optimization
Derek F.Holt with Bettina Eick and Eamonn A.O’Brien, Handbook of
Computational Group Theory
Continued Titles
© 2005 by Chapman & Hall/CRC Press

DISCRETE MATHEMATICS AND ITS APPLICATIONS
Series Editor KENNETH H. ROSEN
HANDBOOK OF
COMPUTATIONAL
GROUP THEORY
DEREK F.HOLT
BETTINA EICK
EAMONN A.O’BRIEN
CHAPMAN & HALL/CRC
A CRC Press Company
Boca Raton London New York Washington, D.C.
© 2005 by Chapman & Hall/CRC Press

Visit the CRC Press Web site at www.crcpress.com
© 2005 by Chapman & Hall/CRC Press
No claim to original U.S. Government works
International Standard Book Number 1-58488-372-3
Printed in the United States of America 1 2 3 4 5 6 7 8 9 0
Printed on acid-free paper
This book contains information obtained from authentic and highly regarded sources.
Reprinted material is quoted with permission, and sources are indicated. A wide variety
of references are listed. Reasonable  efforts have been made to publish reliable data and
information, but the author and the publisher cannot assume responsibility for the
validity of all materials or for the consequences of their use.
Neither this book nor any part may be reproduced or transmitted in any form or by any
means, electronic or mechanical, including photocopying, microfilming, and recording,
or by any information storage or retrieval system, without prior permission in writing
from the publisher.
The consent of CRC Press does not extend to copying for general distribution, for
promotion, for creating new works, or for resale. Specific permission must be obtained
in writing from CRC Press for such copying.
Direct all inquiries to CRC Press, 2000 N.W. Corporate Blvd., Boca Raton, Florida 33431.
Trademark Notice: Product or corporate names may be trademarks or registered
trademarks, and are used only for identification and explanation, without intent to
infringe.
Library of Congress Cataloging-in-Publication Data
Catalog record is available from the Library of Congress
© 2005 by Chapman & Hall/CRC Press

v
Preface
This book is about computational group theory, which we shall frequently
abbreviate to CGT. The origins of this lively and active branch of mathematics
can be traced back to the late nineteenth and early twentieth centuries, but
it has been flourishing particularly during the past 30 to 40 years. The aim
of this book is to provide as complete a treatment as possible of all of the
fundamental methods and algorithms in CGT, without straying above a level
suitable for a beginning postgraduate student.
There are currently three specialized books devoted to specific areas of
CGT, namely those of Greg Butler [But91] and Ákos Seress [Ser03] on
algorithms for permutation groups, and the book by Charles Sims [Sim94]
on computation with finitely presented groups. These texts cover their
respective topics in greater detail than we shall do here, although we have
relied heavily on some of the pseudocode presented in [Sim94] in our treatment
of coset enumeration in Chapter 5,
The most basic algorithms in CGT tend to be representation specific; that
is, there are separate methods for groups given as permutation or matrix
groups, groups defined by means of polycyclic presentations, and groups that
are defined using a general finite presentation. We have devoted separate
chapters to algorithms that apply to groups in these different types of
representations, but there are other chapters that cover important methods
involving more than one type. For example, Chapter 6 is about finding
presentations of permutation groups and the connections between coset
enumeration and methods for finding the order of a finite permutation group.
We have also included a chapter (Chapter 11) on the increasing number of
precomputed stored libraries and databases of groups, character tables, etc.
that are now publicly available. They have been playing a major rôle in CGT
in recent years, both as an invaluable resource for the general mathematical
public, and as components for use in some advanced algorithms in CGT. The
library of all finite groups of order up to 2000 (except for order 1024) has
proved to be particularly popular with the wider community.
It is inevitable that our choice of topics and treatment of the individual
topics will reflect the authors’ personal expertise and preferences to some
extent. On the positive side, the final two chapters of the book cover applications
of string-rewriting techniques to CGT (which is, however, treated in much
greater detail in [Sim94]), and the application of finite state automata to the
computation of automatic structures of finitely presented groups. On the
other hand, there may be some topics for which our treatment is more
superficial than it would ideally be.
One such area is the complexity analysis of the algorithms of CGT. During
the 1980s and 1990s some, for the most part friendly and respectful, rivalry
developed between those whose research in CGT was principally directed
towards producing better performance of their code, and those who were
more interested in proving theoretical results concerning the complexity of
© 2005 by Chapman & Hall/CRC Press

vi
the algorithms. This study of complexity began with the work of Eugene
Luks, who established a connection in his 1982 article [Luk82] between
permutation group algorithms and the problem of testing two finite graphs
for isomorphism. Our emphasis in this book will be more geared towards
algorithms that perform well in practice, rather than those with the best
theoretical complexity. Fortunately, Seress’ book [Ser03] includes a very
thorough treatment of complexity issues, and so we can safely refer the
interested reader there. In any case, as machines become faster, computer
memories larger, and bigger and bigger groups come within the range of
practical computation, it is becoming more and more the case that those
algorithms with the more favourable complexity will also run faster when
implemented.
The important topic of computational group representation theory and
computations with group characters is perhaps not treated as thoroughly as
it might be in this book. We have covered some of the basic material in
Chapter 7, but there is unfortunately no specialized book on this topic. For a
brief survey of the area, we can refer the reader to the article by Gerhard
Hiss [His03].
One of the most active areas of research in CGT at the present time, both
from the viewpoint of complexity and of practical performance, is the
development of effective methods for computing with large finite groups of
matrices. Much of this material is beyond the scope of this book. It is, in any
case, developing and changing too rapidly to make it sensible to attempt to
cover it properly here. Some pointers to the literature will of course be provided,
mainly in Section 7.8.
Yet another topic that is beyond the scope of this book, but which is of
increasing importance in CGT, is computational Lie theory. This includes
computations with Coxeter groups, reflection groups, and groups of Lie type
and their representations. It also connects with computations in Lie algebras,
which is an area of independent importance. The article by Cohen, Murray,
and Taylor [CMT04] provides a possible starting point for the interested reader.
The author firmly believes that the correct way to present a mathematical
algorithm is by means of pseudocode, since a textual description will generally
lack precision, and will usually involve rather vague instructions like “carry
on in a similar manner”. So we have included pseudocode for all of the most
basic algorithms, and it is only for the more advanced procedures that we
have occasionally lapsed into sketchy summaries. We are very grateful to
Thomas Cormen who has made his LATEXpackage ‘clrscode’ for displaying
algorithms publicly available. This was used by him and his coauthors in
the well-known textbook on algorithms [CLRS02].
Although working through all but the most trivial examples with procedures
that are intended to be run on a computer can be very tedious, we have
attempted to include illustrative examples for as many algorithms as is
practical.
At the end of each chapter, or sometimes section, we have attempted to
direct the reader’s attention to some applications of the techniques developed
© 2005 by Chapman & Hall/CRC Press

vii
in that chapter either to other areas of mathematics or to other sciences. It is
generally difficult to do this effectively. Although there are many important
and interesting applications of CGT around, the most significant of them
will typically use methods of CGT as only one of many components, and so it
not possible to do them full justice without venturing a long way outside of
the main topic of the book.
We shall assume that the reader is familiar with group theory up to an
advanced undergraduate level, and has a basic knowledge of other topics in
algebra, such as ring and field theory. Chapter 2 includes a more or less
complete survey of the required background material in group theory, but we
shall assume that at least most of the topics reviewed will be already familiar
to readers. Chapter 7 assumes some basic knowledge of group representation
theory, such as the equivalence between matrix representations of a group G
over a field K and KG-modules, but it is interesting to note that many of the
most fundamental algorithms in the area, such as the ‘Meataxe’, use only
rather basic linear algebra.
A number of people have made helpful and detailed comments on draft
versions of the book, and I would particularly like to thank John Cannon,
Bettina Eick, Joachim Neubüser, and Colva Roney-Dougal in this regard.
Most of all, I am grateful to my two coauthors, Bettina Eick and Eamonn
O’Brien for helping me to write parts of the book. The whole of Chapter 8, on
computing in polycyclic groups, was written by Bettina Eick, as were Sections
11.1 and 11.4 on the libraries of primitive groups and of small groups,
respectively. Section 7.8 on computing in matrix groups and Section 9.4 on
computing p-quotients of finitely presented groups were written by Eamonn
O’Brien.
August 2004
Derek Holt
© 2005 by Chapman & Hall/CRC Press

ix
Contents
Notation and displayed procedures 
xvi
1
A Historical Review of Computational Group Theory
1
2
Background Material
9
2.1
Fundamentals
9
2.1.1
Definitions
9
2.1.2
Subgroups
11
2.1.3
Cyclic and dihedral groups
12
2.1.4
Generators
13
2.1.5
Examples—permutation groups and matrix groups
13
2.1.6
Normal subgroups and quotient groups
14
2.1.7
Homomorphisms and the isomorphism theorems
15
2.2
Group actions
17
2.2.1
Definition and examples
17
2.2.2
Orbits and stabilizers
19
2.2.3
Conjugacy, normalizers, and centralizers
20
2.2.4
Sylow’s theorems
21
2.2.5
Transitivity and primitivity
22
2.3
Series
26
2.3.1
Simple and characteristically simple groups
26
2.3.2
Series
27
2.3.3
The derived series and solvable groups
27
2.3.4
Central series and nilpotent groups
29
2.3.5
The socle of a finite group
31
2.3.6
The Frattini subgroup of a group
32
2.4
Presentations of groups
33
2.4.1
Free groups
33
2.4.2
Group presentations
36
2.4.3
Presentations of group extensions
38
2.4.4
Tietze transformations
40
2.5
Presentations of subgroups
41
2.5.1
Subgroup presentations on Schreier generators
41
2.5.2
Subgroup presentations on a general generating set
44
2.6
Abelian group presentations
46
© 2005 by Chapman & Hall/CRC Press

x
2.7
Representation theory, modules, extensions, derivations, and
complements
48
2.7.1
The terminology of representation theory
49
2.7.2
Semidirect products, complements, derivations, and
first cohomology groups
50
2.7.3
Extensions of modules and the second cohomology
group
52
2.7.4
The actions of automorphisms on cohomology groups
54
2.8
Field theory
56
2.8.1
Field extensions and splitting fields
56
2.8.2
Finite fields
58
2.8.3
Conway polynomials
59
3
Representing Groups on a Computer
61
3.1
Representing groups on computers
61
3.1.1
The fundamental representation types
61
3.1.2
Computational situations
62
3.1.3
Straight-line programs
64
3.1.4
Black-box groups
65
3.2
The use of random methods in CGT
67
3.2.1
Randomized algorithms
67
3.2.2
Finding random elements of groups
69
3.3
Some structural calculations
72
3.3.1
Powers and orders of elements
72
3.3.2
Normal closure
73
3.3.3
The commutator subgroup, derived series, and lower
central series
73
3.4
Computing with homomorphisms
74
3.4.1
Defining and verifying group homomorphisms
74
3.4.2
Desirable facilities
75
4
Computation in Finite Permutation Groups
77
4.1
The calculation of orbits and stabilizers
77
4.1.1
Schreier vectors
79
4.2
Testing for Alt() and Sym()
81
4.3
Finding block systems
82
4.3.1
Introduction
82
4.3.2
The Atkinson algorithm
83
4.3.3
Implementation of the class merging process
85
4.4
Bases and strong generating sets
87
4.4.1
Definitions
87
4.4.2
The Schreier-Sims algorithm
90
4.4.3
Complexity and implementation issues
93
4.4.4
Modifying the strong generating set—shallow Schreier
trees
95
© 2005 by Chapman & Hall/CRC Press

xi
4.4.5
The random Schreier-Sims method
97
4.4.6
The solvable BSGS algorithm
98
4.4.7
Change of base
102
4.5
Homomorphisms from permutation groups
105
4.5.1
The induced action on a union of orbits
105
4.5.2
The induced action on a block system
106
4.5.3
Homomorphisms between permutation groups
107
4.6
Backtrack searches
108
4.6.1
Searching through the elements of a group
110
4.6.2
Pruning the tree
113
4.6.3
Searching for subgroups and coset representatives
114
4.6.4
Automorphism groups of combinatorial structures and
partitions
118
4.6.5
Normalizers and centralizers
121
4.6.6
Intersections of subgroups
124
4.6.7
Transversals and actions on cosets
126
4.6.8
Finding double coset representatives
131
4.7
Sylow subgroups, p-cores, and the solvable radical
132
4.7.1
Reductions involving intransitivity and imprimitivity
133
4.7.2
Computing Sylow subgroups
134
4.7.3
A result on quotient groups of permutation groups
137
4.7.4
Computing the p-core
138
4.7.5
Computing the solvable radical
140
4.7.6
Nonabelian regular normal subgroups
141
4.8
Applications
143
4.8.1
Card shuffling
144
4.8.2
Graphs, block designs, and error-correcting codes
145
4.8.3
Diameters of Cayley graphs
147
4.8.4
Processor interconnection networks
148
5
Coset Enumeration
149
5.1
The basic procedure
150
5.1.1
Coset tables and their properties
151
5.1.2
Defining and scanning
152
5.1.3
Coincidences
156
5.2
Strategies for coset enumeration
162
5.2.1
The relator-based method
162
5.2.2
The coset table-based method
165
5.2.3
Compression and standardization
167
5.2.4
Recent developments and examples
168
5.2.5
Implementation issues
170
5.2.6
The use of coset enumeration in practice
171
5.3
Presentations of subgroups
173
5.3.1
Computing a presentation on Schreier generators
173
5.3.2
Computing a presentation on the user generators
178
© 2005 by Chapman & Hall/CRC Press

xii
5.3.3
Simplifying presentations
184
5.4
Finding all subgroups up to a given index
188
5.4.1
Coset tables for a group presentation
189
5.4.2
Details of the procedure
190
5.4.3
Variations and improvements
196
5.5
Applications
198
6
Presentations of Given Groups
199
6.1
Finding a presentation of a given group
199
6.2
Finding a presentation on a set of strong generators
205
6.2.1
The known BSGS case
205
6.2.2
The Todd-Coxeter-Schreier-Sims algorithm
207
6.3
The Sims ‘Verify’ algorithm
208
6.3.1
The single-generator case
209
6.3.2
The general case
213
6.3.3
Examples
217
7
Representation Theory, Cohomology, and Characters
219
7.1
Computation in finite fields
220
7.2
Elementary computational linear algebra
221
7.3
Factorizing polynomials over finite fields
226
7.3.1
Reduction to the squarefree case
228
7.3.2
Reduction to constant-degree irreducibles
229
7.3.3
The constant-degree case
229
7.4
Testing KG-modules for irreducibility—the Meataxe
230
7.4.1
The Meataxe algorithm
230
7.4.2
Proof of correctness
234
7.4.3
The Ivanyos-Lux extension
235
7.4.4
Actions on submodules and quotient modules
235
7.4.5
Applications
236
7.5
Related computations
237
7.5.1
Testing modules for absolute irreducibility
237
7.5.2
Finding module homomorphisms
241
7.5.3
Testing irreducible modules for isomorphism
244
7.5.4
Application—invariant bilinear forms
245
7.5.5
Finding all irreducible representations over a finite
field
246
7.6
Cohomology
248
7.6.1
Computing first cohomology groups
249
7.6.2
Deciding whether an extension splits
253
7.6.3
Computing second cohomology groups
254
7.7
Computing character tables
255
7.7.1
The basic method
256
7.7.2
Working modulo a prime
257
7.7.3
Further improvements
260
© 2005 by Chapman & Hall/CRC Press

xiii
7.8
Structural investigation of matrix groups
264
7.8.1
Methods based on bases and strong generating sets
264
7.8.2
Computing in large-degree matrix groups
268
8
Computation with Polycyclic Groups
273
8.1
Polycyclic presentations
274
8.1.1
Polycyclic sequences
274
8.1.2
Polycyclic presentations and consistency
278
8.1.3
The collection algorithm
280
8.1.4
Changing the presentation
284
8.2
Examples of polycyclic groups
286
8.2.1
Abelian, nilpotent, and supersolvable groups
286
8.2.2
Infinite polycyclic groups and number fields
288
8.2.3
Application—crystallographic groups
289
8.3
Subgroups and membership testing
290
8.3.1
Induced polycyclic sequences
291
8.3.2
Canonical polycyclic sequences
296
8.4
Factor groups and homomorphisms
298
8.4.1
Factor groups
298
8.4.2
Homomorphisms
299
8.5
Subgroup series
300
8.6
Orbit-stabilizer methods
302
8.7
Complements and extensions
304
8.7.1
Complements and the first cohomology group
304
8.7.2
Extensions and the second cohomology group
307
8.8
Intersections, centralizers, and normalizers
311
8.8.1
Intersections
311
8.8.2
Centralizers
313
8.8.3
Normalizers
314
8.8.4
Conjugacy problems and conjugacy classes
316
8.9
Automorphism groups
317
8.10
The structure of finite solvable groups
320
8.10.1 Sylow and Hall subgroups
320
8.10.2 Maximal subgroups
322
9
Computing Quotients of Finitely Presented Groups
325
9.1
Finite quotients and automorphism groups of finite groups
326
9.1.1
Description of the algorithm
326
9.1.2
Performance issues
332
9.1.3
Automorphism groups of finite groups
333
9.2
Abelian quotients
335
9.2.1
The linear algebra of a free abelian group
335
9.2.2
Elementary row operations
336
9.2.3
The Hermite normal form
337
© 2005 by Chapman & Hall/CRC Press

xiv
9.2.4
Elementary column matrices and the Smith normal
form
341
9.3
Practical computation of the HNF and SNF
347
9.3.1
Modular techniques
347
9.3.2
The use of norms and row reduction techniques
349
9.3.3
Applications
352
9.4
p-quotients of finitely presented groups
353
9.4.1
Power-conjugate presentations
353
9.4.2
The p-quotient algorithm
355
9.4.3
Other quotient algorithms
364
9.4.4
Generating descriptions of p-groups
364
9.4.5
Testing finite p-groups for isomorphism
371
9.4.6
Automorphism groups of finite p-groups
371
9.4.7
Applications
372
10 Advanced Computations in Finite Groups
375
10.1
Some useful subgroups
376
10.1.1 Definition of the subgroups
376
10.1.2 Computing the subgroups—initial reductions
377
10.1.3 The O’Nan-Scott theorem
378
10.1.4 Finding the socle factors—the primitive case
379
10.2
Computing composition and chief series
381
10.2.1 Refining abelian sections
381
10.2.2 Identifying the composition factors
382
10.3
Applications of the solvable radical method
383
10.4
Computing the subgroups of a finite group
385
10.4.1 Identifying the TF-factor
386
10.4.2 Lifting subgroups to the next layer
387
10.5
Application—enumerating finite unlabelled structures
390
11
Libraries and Databases
393
11.1
Primitive permutation groups
394
11.1.1 Affine primitive permutation groups
395
11.1.2 Nonaffine primitive permutation groups
396
11.2
Transitive permutation groups
397
11.2.1 Summary of the method
397
11.2.2 Applications
399
11.3
Perfect groups
400
11.4
The small groups library
402
11.4.1 The Frattini extension method
404
11.4.2 A random isomorphism test
405
11.5
Crystallographic groups
407
11.6
The “ATLAS of Finite Groups”
409
© 2005 by Chapman & Hall/CRC Press

xv
12 Rewriting Systems and the Knuth- Bendix Completion
Process
411
12.1
Monoid presentations
412
12.1.1 Monoids and semigroups
412
12.1.2 Free monoids and monoid presentations
415
12.2
Rewriting systems
417
12.3
Rewriting systems in monoids and groups
423
12.4
Rewriting systems for polycyclic groups
426
12.5
Verifying nilpotency
429
12.6
Applications
431
13 Finite State Automata and Automatic Groups
433
13.1
Finite state automata
434
13.1.1 Definitions and examples
434
13.1.2 Enumerating and counting the language of a dfa
437
13.1.3 The use of fsa in rewriting systems
439
13.1.4 Word-acceptors
441
13.1.5 2-variable fsa
442
13.1.6 Operations on finite state automata
442
13.1.6.1
Making an fsa deterministic
443
13.1.6.2
Minimizing an fsa
444
13.1.6.3
Testing for language equality
446
13.1.6.4
Negation, union, and intersection
447
13.1.6.5
Concatenation and star
447
13.1.7 Existential quantification
448
13.2
Automatic groups
451
13.2.1 Definitions, examples, and background
451
13.2.2 Word-differences and word-difference automata
453
13.3
The algorithm to compute the shortlex automatic structures 456
13.3.1 Step 1
457
13.3.2 Step 2 and word reduction
459
13.3.3 Step 3
460
13.3.4 Step 4
462
13.3.5 Step 5
464
13.3.6 Comments on the implementation and examples
466
13.4
Related algorithms
468
13.5
Applications
469
References
471
© 2005 by Chapman & Hall/CRC Press

xvi
Notation and displayed procedures
As is usual, {a, b, c} will denote the (unordered) set with elements a, b, c.
We shall generally use square brackets, as in [a, b, c, c, a], to denote an
ordered set or list, which may of course contain repeated elements. There
is an unfortunate and occasionally serious conflict here with the notation
for commutators of subgroups and elements of a group. If there is a danger
of ambiguity in this respect, then we shall write comm(g, h) rather than [g,
h] for the commutator g¯
1h¯
1gh. Here is some notation used in the book,
which might not be completely standard.
The LATEXpackage ‘clrscode’ has been used for typesetting the displayed
procedures in this book. This is the package used in the book [CLRS02], and
was downloaded from Thomas Cormen’s Web site [Cor].
We shall assume that the meaning of the constructs used in the procedures,
like while, do, if, then, elseif is sufficiently well-known to require no
explanation. Unlike in [CLRS02], however, we use a:=b (rather than a←b)
to denote an assignment. By default, a command break or continue will
cause the procedure to break out of or proceed to the next iteration of the
current innermost loop. We shall, however, occasionally use “continue α”
to mean proceed to the next iteration of the loop “for α ∈ …”.
Procedures may return one or more values. So, if a procedure
MULTIPROC(x) ends with a statement return a, b;, then we access the
two returned values using a statement like y, z:=MULTIPROC(x). If an
argument of a procedure is preceded by a ~ symbol, as in APPEND(~l, x)
then, on calling the procedure, the value of the argument may be changed
within the procedure.
We shall not display code for a number of basic procedures, of which the
meaning is assumed to be obvious. For example, when called with a list l and
an element x, the procedure call APPEND(~l, x) simply appends x to the
end of the list l.
© 2005 by Chapman & Hall/CRC Press

1 
Chapter 1 
A Historical Review of 
Computational Group Theory 
We begin the book with a brief review of the history of CGT. Some of the 
material in this chapter has been taken from Section 2 of the article by 
J.Neubüser [Neu95]. 
Group theory has always been a computational subject. For example, 
there were repeated attempts during the nineteenth century, with varying 
degrees of accuracy, to compile complete lists of the primitive and transitive 
permutation groups of low degree. This work began with Ruffini in 1799 
and continued until about 1912. It was of course all done painstakingly 
using hand calculations. Rather than provide citations here, we refer the 
reader to the extensive bibliography compiled by Short in [Sho92, Appendix 
A] for details. For whatever reason, very little further work was done on 
this particular problem until about 1970, at which time computers could be 
used both to check the results of the older calculations and, over the 
following years, to extend the lists to groups of much higher degree. We 
shall be discussing recent progress in this area in Chapter 11 of this book. 
The first genuine algorithms proposed for solving problems in group 
theory predate the days of mechanical computers. As early as 1911, in 
[Deh11], Dehn formulated the word, conjugacy, and isomorphism problems 
for finitely presented groups, and he devised an algorithm, the Dehn 
algorithm, for solving the word problem in certain types of small cancellation 
groups. Chapters 12 and 13 will explore recent computational work on 
some of these problems. However, problems of this type are usually 
undecidable in general: it was proved by Novikov [Nov55] and then by 
Boone in [Boo59] that the word and conjugacy problems are undecidable, 
and by Adian in [Adi58] and Rabin in [Rab58] that the isomorphism problem 
is undecidable. 
Then, in 1936, Todd and Coxeter described the ‘coset enumeration’ 
procedure, which attempts to calculate the index of a finitely generated 
subgroup of a finitely presented group, on the assumption that this index is 
finite. While the importance of Dehn’s algorithm was more theoretical 
than practical, the Todd-Coxeter method was intended to be used for real 
calculations, which indeed it was. Coset enumeration remains one of the 
most fundamental and important procedures in CGT, and we shall be 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
2 
studying it in detail in Chapter 5. Originally it was used for hand calculations, 
and there were successful enumerations by hand of the cosets of subgroups 
of index several hundred. The current most versatile computer 
implementation, ACE3 [HR99], by George Havas and Colin Ramsay, can 
routinely handle subgroups of index up to at least 108. 
Yet another example from the premachine era was an algorithm for the 
classification of space groups proposed in [Zas48] by Zassenhaus. Some 
time was to elapse before this could be put to practical use; we shall be 
discussing this application in Section 11.5 of Chapter 11. 
Given that group theory had been recognized as an intrinsically 
computational branch of mathematics for over a century, it is not surprising 
that solving problems in group theory was one of the very earliest 
nonnumerical applications of programmable computers to be proposed. 
Indeed, some of these early suggestions were surprisingly ambitious, and 
demonstrated a striking perceptivity for the eventual capabilities of CGT. 
In 1951, M.H.A. Newman [New51] proposed using computers to investigate 
groups of order 256—the complete classification of the 56 092 isomorphism 
types of groups of this order was eventually completed by O’Brien in 1988 
[O’B91]. As another example, there is a quote from A. Turing from 1945, 
which suggests the idea of writing a computer program to enumerate the 
groups of order 720. However, the first reported enumeration of the 840 
isomorphism types of groups of this order was in 1999, as part of the 
systematic construction of all groups of order up to 1000 undertaken by 
Besche and Eick [BE99b]. 
The first implementation of a group-theoretical algorithm was probably 
by B.Hazelgrove, who partially implemented Todd-Coxeter coset 
enumeration on the EDSAC II in Cambridge in 1953. For details of this and 
other early implementations of coset enumeration, see Leech’s article 
[Lee63]. Possibly the first genuinely useful programs were those of Felsch 
and Neubüser [Neu60, Neu61] for computing the subgroup lattices of finite 
permutation groups, and of finite 2-groups given by polycyclic presentations. 
A major breakthrough in the art of computing in finite permutation groups 
came around 1970 with the base and strong generating set methods and the 
Schreier-Sims algorithm introduced by Charles Sims in [Sim70, Sim71a]. 
These methods have formed the backbone of this area of CGT ever since, 
and they now enable detailed structural computations to be carried out 
routinely in permutation groups of degree up to about 107. Indeed, 
computational group theory made the mathematical headlines for the first 
time in 1972, when Sims used his methods as the basis for his proof by 
computer of the existence of the Lyons sporadic simple group [Sim73]. He 
constructed the group as a permutation group of degree 8 835 156. Later 
[Sim80], in 1977, he was able to prove the existence of the Baby Monster in 
a similar fashion; in this case the degree is 13 571 955 000. The groups J3, 
He, and ON were also constructed by computer as permutation groups. 
Computing in finite permutation groups will be covered in Chapter 4 and 
also in several later chapters. More recent work in this area has made use of 
© 2005 by Chapman & Hall/CRC Press

A Historical Review of Computational Group Theory 
3 
the O’Nan-Scott theorem, which describes the detailed structure of a primitive 
permutation group, and of the classification of finite simple groups. 
Other noteworthy developments in the 1970s include the development 
of (a number of variations of) a procedure for computing finite quotients of 
prime power order of finitely presented groups. The resulting algorithm is 
now known as the p-quotient algorithm and will form the main topic of 
Section 9.4 of Chapter 9. In the mid-1970s, versions were developed and 
implemented by Macdonald [Mac74], Wamsley [BKW74], and Havas and 
Newman [New76]. Several new results were discovered using these 
implementations, including the orders of the restricted Burnside groups 
|R(2, 5)|=534 and |R(4, 4)|=2422 (where R(d,n) denotes the largest finite d- 
generator group of exponent n). 
More recently, in 2002, using a special version of the algorithm that 
uses techniques involving Lie algebras, O’Brien and Vaughan-Lee [OVL02] 
proved that |R(2, 7)|=720416. This computation involved about a year of 
CPU-time! 
The p-quotient algorithm outputs finite quotients in the form of a power 
conjugate presentation or polycyclic presentation. Efficient algorithms for 
computing in finite p-groups, and later in finite solvable and general 
polycyclic groups, using this type of presentation as the basic data structure 
for group elements, were first developed around the same period. These 
methods introduced a number of techniques, such as: 
• 
solving a problem from the top down, by solving it successively in larger 
and larger quotients G/N of the group G; 
• 
a divide-and conquer approach that uses group homomorphisms to split 
a problem up into smaller instances of the same problem on the kernel 
and image of the homomorphism; 
which were later generalized to permutation and matrix groups. For 
example, Neubüser and Felsch [FN79] described and implemented a top- 
down approach to computing conjugacy classes and centralizers in p-groups, 
which was used to find a counterexample to an open conjecture, the ‘class- 
breadth’ conjecture. Algorithms for computing in polycyclic groups using 
polycyclic presentations will form the topic of Chapter 8. 
Also worthy of mention from this period are: 
• 
Dixon’s algorithm for computing character tables of finite groups [Dix67]; 
• 
the application of the Zassenhaus algorithm and the subgroup lattice 
algorithms mentioned above to the determination of the 4-dimensional 
space groups [BBN+78]; 
• 
the implementation by Havas of the Reidemeister-Schreier algorithm 
for computing and simplifying a presentation of a subgroup of finite 
index in a finitely presented group; 
• 
a program of Felsch and Neubüser [FN68, FN70] for computing 
automorphism groups of finite groups. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
4 
Computation with characters and representations of finite groups has played 
a significant rôle in CGT and continues to do so. The Dixon algorithm for 
computing character tables was based on a method described by Burnside 
in [Bur11], which was used by John McKay in [McK70] in its original form 
to compute the character tables of the first two Janko sporadic simple 
groups J1 and J2. It was later refined by Schneider in [Sch90b]. These 
methods will be described in Section 7.7. 
As mentioned already, five of the larger sporadic simple groups were proved 
to exist by means of computer constructions as permutation groups. Four 
others, Ru, Th, HN, and J4 were originally constructed computationally as 
matrix groups either over an algebraic number field or over a finite field; for 
example, J4 was constructed by Norton and others as a subgroup of GL(112, 
2) [Nor80]. See Section 2 of [Gor82] or [CCN+85] for details; but be aware 
that the names used in [Gor82] for several of these groups are different from 
the ones we are using here, which are as in [CCN+85]. It should be mentioned 
that several, but not all, of the sporadic simple groups that were originally 
proved to exist by means of a computer calculation now have alternative 
existence proofs as subgroups of the largest such group, the Monster, which 
was constructed by R.L.Griess, without computer assistance, as a group of 
automorphisms of a certain 196 854-dimensional algebra [Gri82]. 
The principal computational tool that has been used for working with 
large groups of matrices over finite fields is a collection of basic linear 
algebra procedures designed principally by Richard Parker [Par84] which, 
among other things, can test large dimensional representations of groups 
over finite fields for irreducibility. This has become known as the ‘Meataxe’ 
algorithm on account of the efficiency with which it can chop modules up 
into their irreducible constituents. These methods will be treated in detail 
in Chapter 7 of this book. Together with other techniques, they were used 
extensively in the construction of Brauer trees by Hiss and Lux in [HL89] 
and of Brauer character tables by Jansen, Lux, Parker, and Wilson in 
[JLPW95]. 
These constructions involved an important additional technique, 
unfortunately beyond the scope of this book, known as condensation (see, 
for example [Ryb90, LMR94, Ryb01]), which can be used to reduce computations 
in large dimensional modules to equivalent computations over smaller 
dimensional modules over a different but Morita equivalent algebra. 
The very earliest computer programs for working with groups, such as 
Hazelgrove’s 1953 implementation of coset enumeration, were written in 
machine code. For later programs, Fortran was for many years the most 
popular choice of language, and more recently ‘C’ and (less often) ‘C++’ have 
been used extensively. There remain a small number of stand-alone programs 
and packages that are in widespread use, such as ACE3 [HR99] for coset 
enumeration, which we have mentioned already, and the most recent stand- 
alone version of the ‘Meataxe’ programs, written mainly by Michael Ringe 
[Rin92]. Sims’ Rutgers Knuth-Bendix Package (rkbp), and the author’s KBMAG 
package for the Knuth-Bendix algorithm in groups and monoids and computing 
© 2005 by Chapman & Hall/CRC Press

A Historical Review of Computational Group Theory 
5 
in automatic groups also spring to mind; the algorithms involved will form 
the subject of Chapters 12 and 13 of this book. 
However, the prevailing philosophy today is that it is nearly always 
preferable to implement algorithms in CGT as a component of an already 
existing package or system. The programmer need not then be concerned 
with much of the underlying functionality required, such as multiplication 
of permutations, and basic matrix operations, because implementations of 
these will already be provided by the system. Indeed, the user can make 
use of or build on top of anything that is already there. So the principal 
objectives of systems of this kind are: 
  (i) 
to provide efficient implementations of a number of basic mathematical 
procedures and data structures; 
 (ii) 
to include the most up-to-date and versatile implementations of the 
fundamental algorithms of CGT; 
(iii) 
to provide a high-level programming or scripting language to allow 
the user either to use one of these algorithms to perform a single 
computation, or to write programs that call one or more of the 
algorithms, possibly repeatedly. 
The programs referred to in (iii) could either be for the purpose of a one-off 
computation or, at the other extreme, they could be designed to extend the 
functionality of the system, in which case they might eventually be 
incorporated into it. 
The first such system for CGT, known as ‘Group’, and written and 
administered by John Cannon in Sydney and Joachim Neubüser in Aachen, 
got off the ground in the mid-1970s, and was written in Fortran. By about 
1980, this had developed into the Sydney-based CAYLEY system. Around 
1993, CAYLEY was superceded by MAGMA, which is written in ‘C’ (see 
[CP93] or the Web site and online manual [Mag04]). 
A number of more specialized packages, such as CAS [NPP84] for 
calculating and manipulating characters of finite groups, were developed 
and maintained in Aachen. They were superceded in 1986 by GAP (‘Groups, 
Algorithms and Programming’); see [GAP04] for detailed information and 
a list of authors. It has been based in St Andrews, Scotland, since 1997, and 
is now developed and maintained by an international development team. 
GAP and MAGMA are the two systems for CGT that currently enjoy the 
most widespread usage, although the large computer algebra systems Maple 
and Mathematica both include some facilities for CGT, including coset 
enumeration and the Schreier-Sims algorithm for permutation groups. Both 
GAP and MAGMA aim to cover the whole of CGT and to keep up with all of 
the latest developments in the area. MAGMA aims for maximal efficiency 
by implementing many fundamental algorithms at the ‘C’ level, whereas 
GAP aims for maximal versatility by having more code written in the GAP 
language, which allows nonexpert users more flexibility in adapting or 
extending it. But for both systems, a large proportion of the new code, 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
6 
particularly for algorithms under development, is written in the language 
of the system. 
Until about 1990, CGT was able to exist more or less in isolation from 
the rest of computer algebra. In more recent years, that situation has been 
slowly but steadily changing, and many of the newer algorithms in CGT 
have required facilities from mainstream computer algebra. For example: 
• 
The best performing Smith and Hermite normal form procedures, which 
will arise in Section 9.2 in connection with computing abelian quotients 
of finitely presented groups, need the LLL and MLLL (modified) lattice 
reduction algorithms. 
• 
The flexible version of the Meataxe algorithm described by Holt and 
Rees in [HR94] uses factorization of polynomials over finite fields. 
• 
The polycyclic quotient algorithm, proposed initially by Baumslag, 
Cannonito, and Miller [BCM81b, BCM81a], is discussed in Chapters 10 
and 11 of [Sim94] for the metabelian case, and has been implemented 
in the general case by Lo [Lo98]. It uses Gröbner bases over group 
rings ZG of polycyclic groups. 
• 
The methods under development by Eick for computing with infinite 
polycyclic groups, which we shall summarize in Subsection 8.2.2 of this 
book, require computational facilities from algebraic number theory. 
We can expect interactions of this kind to become more and more 
commonplace in the future. 
Both GAP and MAGMA have responded to this situation by expanding 
the basic facilities that they provide. GAP is able to do this by means of its 
package mechanism, which allows external code written either in GAP or 
in another language, like ‘C’, to be incorporated into the system by its 
users. 
For example, there is a package of this kind by L.Soicher for computing 
with combinatorial objects, which includes the ‘Nauty’ package of Brendan 
D.McKay for testing finite graphs for isomorphism. A package providing an 
interface to the KANT system for algebraic number theory is also available. 
Since its inception, MAGMA has been steadily increasing its basic remit. 
Although it started life as a successor to the CGT system CAYLEY, it is no 
longer accurate to describe MAGMA as a CGT system. It now offers a 
complete and up-to-date range of facilities in computational algebraic number 
theory, geometry and combinatorics, as well as for computation in groups, 
rings, modules, etc.; indeed the most exciting developments at the present 
time are probably in algebraic geometry. The interaction between CGT 
and other branches of computer algebra has been a two-way affair; for 
example, some computations in algebraic number theory and algebraic 
geometry involve computing with cohomology groups. 
There are or have been a number of other more specialized systems and 
packages that deserve a brief mention. 
© 2005 by Chapman & Hall/CRC Press

A Historical Review of Computational Group Theory 
7 
• 
Derek Holt and Sarah Rees wrote and maintain an interactive graphics 
package QUOTPIC [HR93], which uses the methods to be described in 
Chapter 9 together with other basic algorithms from CGT to compute 
quotients of finitely presented groups. 
• 
The New York Group Theory Cooperative directed by Gilbert Baumslag 
and others maintain and develop an interactive system MAGNUS (see 
the Web site [Mag]) for exploring properties of finitely presented groups. 
It has the interesting feature that several approaches to solving a 
problem can be tried and run in parallel; for example, if the user asks 
whether a group is finite, it will simultaneously run one or more 
programs that attempt to establish finiteness and infiniteness. 
• 
The CHEVIE package of Geck and others for symbolic calculations 
with generic character tables of groups of Lie type, Coxeter groups, 
Iwahori-Hecke algebras, and other related structures; see the Web 
site [Che]. 
• 
SYMMETRICA, DISCRETA, and MOLGEN will be mentioned at the 
end of Section 10.5. 
Other recent historical reviews of CGT have been written by Seress [Ser97] 
and Sims [Sim03]. For a much more detailed account of the early history 
of CGT and the state of the art around 1970, see the article by Neubüser 
[Neu70]. Indeed, there are several papers on CGT in the proceedings of 
the conference on computational problems in abstract algebra, which took 
place in Oxford in 1967 [Lee70]. The first conference exclusively on CGT 
was in Durham, England, in 1982 [Atk84]. Since then, there have been 
four conferences on CGT in Oberwolfach, Germany, but without 
proceedings. There have also been four organized by DIMACS in the United 
States, the first three of which have published proceedings [FK93, FK97, 
KS97]. In addition, a number of special issues of the Journal of Symbolic 
Computation have been devoted to CGT: parts of Volumes 9 (1990), 12 
(1991), and 24 (1997). 
© 2005 by Chapman & Hall/CRC Press

9 
Chapter 2 
Background Material 
In this chapter we shall summarize some algebraic background material, 
generally without proofs or with only outline proofs. We are assuming that 
the reader is already familiar with the majority of the contents of this 
chapter, which is included only as a quick reference guide, and to introduce 
notation. The bulk of this material is from group theory and group 
representation theory, but we have also included a little field theory, 
including the basic theory of finite fields, which plays an important rôle in 
a number of areas of CGT. 
2.1 Fundamentals 
We start by stating some definitions and results from elementary group 
theory; see [Rot94], for example, for discussion and proofs. Many readers 
will want to skip this section entirely, but one of its functions is to introduce 
notation. 
2.1.1 Definitions 
DEFINITION 2.1 A group is a set G together with a binary operation D : 
G×G→G that satisfies the following properties: 
  (i) 
(Closure) For all g, h∈G, gDh∈G; 
 (ii) 
(Associativity) For all g, h, k∈G, (g D h) D k=g D (h D k); 
(iii) 
There exists a unique element e ∈ G satsifying: 
(a) 
(Identity) for all g∈G, g D e=e D g=g; and 
(b) 
(Inverse) for all g∈G there exists a unique h∈G such that 
h D g=g D h=e. 
This definition assumes more than is necessary; for example, the 
uniqueness of the identity and inverse elements can be deduced. See 
Exercise 1 below. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
10 
The number of elements in G is called the order of G and is denoted by 
|G|. The element e∈G satisfying (iii) of the definition is called the identity 
element of G and, for g∈G, the element h that satisfies (iii) (b) of the definition 
(h D g=e) is called the inverse of g. 
DEFINITION 2.2 A group is called abelian or commutative if it satisfies 
the additional property: (Commutativity) for all g, h∈G, gDh=hDg. 
We shall now change notation! The groups in this book will either be: 
• 
multiplicative groups, where we omit the D sign (g D h becomes just 
gh), we denote the identity element by 1 rather than by e, and we 
denote the inverse of g∈G by g-1; or 
• 
additive groups, where we replace o by +, we denote the identity element 
by 0, and we denote the inverse of g by -g. 
If there is more than one group around, and we need to distinguish between 
the identity elements of G and H say, then we will write 1G and 1H (or 0G 
and 0H). 
Additive groups will always be commutative, but multiplicative groups 
may or may not be commutative. Multiplicative notation is the default. 
Note that in a multiplicative group G, we have (gh)-1=h-1g-1 for all g, 
h∈G. The cancellation laws gh=gk⇒h=k and hg=kg⇒h=k are also easily 
deduced. 
In a multiplicative group G, if n∈N and g∈G, then gn is defined inductively 
by g1=g and gn+1=ggn for n≥1. We also define g0 to be the identity element 1, 
and g-n to be the inverse of gn. Then gx+y=gxgy for all x, y∈. In an additive 
group, gn becomes ng, where 0g=g and (-n)g=-(ng). 
Let g∈G. Then the order of g, denoted by |g|, is the least n>0 such that 
gn=1, if such an n exists. If there is no such n, then g has infinite order, and 
we write |g|=∞. Note that if g has infinite order, then the elements gx are 
distinct for distinct values of x. Similarly, if g has finite order n, then the n 
elements g0=1, g1=g,…, gn-1 are all distinct, and for any x∈, gx is equal to 
exactly one of these n elements. Also |g|=1⇔g=1, and if |g|=n then, for 
x∈Z, gx=1⇔n|x. 
If G and H are two (multiplicative) groups, then we define the direct 
product G×H of G and H to be the set {(g, h)|g∈G, h∈H} of ordered pairs of 
elements from G and H, with the obvious component-wise multiplication 
of elements (g1, h1) (g2, h2)=(g1 g2, h1 h2) for g1, g2∈G and h1, h2∈H. 
It is straightforward to check that G×H is a group under this operation. 
If the groups are additive, then it is usually called the direct sum rather 
than the direct product, and written G⊕H. 
More generally, we can define the direct product Gn of n copies of G for 
n≥1, by G1=G and Gn=Gn-1×G for n>1. In particular, the direct product of n 
© 2005 by Chapman & Hall/CRC Press

Background Material 
11 
copies of a cyclic group Cp of order p has order pn and is called an elementary 
abelian p-group. 
In general, if A, B are subsets of a group G, then we define 
  
2.1.2 Subgroups 
DEFINITION 2.3 A subset H of a group G is called a subgroup of G if it 
forms a group under the same operation as that of G. 
For any group G, G and {1} are subgroups. A subgroup other than G is 
called a proper subgroup, and a subgroup other than {1} is called a 
nontrivial subgroup. We often abuse notation and denote the trivial 
subgroup {1} by 1. 
We shall use H⊆G (respectively, H⊂G) to mean that H is a subset 
(respectively proper subset) of G, and H≤G (respectively, H<G) to mean 
that H is a subgroup (respectively, proper subgroup) of G. 
A subgroup H of G is called maximal, if H<G and there are no subgroups 
K with H<K<G. Note that all nontrivial finite groups have maximal 
subgroups, but an infinite group need not have any. 
If H≤G, then it is easy to show that 1H=1G. The following result gives a 
commonly used criterion for deciding whether a subset H of G is a subgroup. 
PROPOSITION 2.4 Let H be a nonempty subset of a group G. Then H is a 
subgroup of G if and only if 
  
Let g∈G. Then the right coset Hg is the subset {hg|h∈H} of G. Similarly, 
the left coset gH is the subset {gh|h∈H} of G. (Warning: Of course, by the 
law of Universal Cussedness, some authors define these the other way round!) 
For additive groups, we write H+g rather than Hg. 
The coset H1 is of course H itself. Two cosets Hg, and Hk are equal if 
and only if g∈Hk, which is the case if and only if gk-1∈H. Otherwise they 
are disjoint. So the distinct right cosets partition G. Hence we have what is 
probably the best-known result in finite group theory: 
THEOREM 2.5 (Lagrange’s theorem) Let G be a finite group and H a 
subgroup of G. Then the order of H divides the order of G. 
The index |G : H| of H in G is defined to be the number of distinct right 
cosets of H in G, which may be finite or infinite in general, and is equal to 
|G|/|H| when G is finite. A system of representatives in G of the right 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
12 
cosets of H in G is called a right transversal of H in G, and a left transversal 
is defined correspondingly. Note that T is a right transversal if and only if T-1 
is a left transversal. 
An easy consequence of Lagrange’s thereom is that, in a finite group G, 
the order |g| of each g∈G divides |G|. 
2.1.3 Cyclic and dihedral groups 
A group G is called cyclic if it consists of the integral powers of a single 
element. In other words, G is cyclic if there exists an element g in G with 
the property that, for all h∈G, there exists x∈Z with gx=h. The element g is 
called a generator of G. 
The most familiar examples of cyclic groups are additive groups rather 
than multiplicative. The group (Z, +) of integers under addition is cyclic, 
because every integer x is equal to x1, and so 1 is a generator. If we fix some 
integer n>0 and let 
 with the operation of addition 
modulo n, then we get a cyclic group of order n, where 1 is once again a 
generator, as is any number in Zn that is coprime to n. Note that in an 
infinite cyclic group, any generator has infinite order, and in a finite cyclic 
group of order n, any generator has order n. 
Let n∈Z with n≥2 and let P be a regular n-sided polygon in the plane. 
The dihedral group of order 2n consists of the isometries of P; that is: 
(i) 
n rotations through the angles 2πk/n (0≤k<n) about the centre of P; 
and 
(ii) n reflections about lines that pass through the centre of P, and either 
pass through a vertex of P or bisect an edge of P (or both). 
Unfortunately, some authors denote this group by Dn and others by D2n, 
which can be confusing! We shall use D2n. 
To study these groups, it is convenient to number the vertices 1, 2,…, n, 
and to regard the group elements as permutations of the vertices. Then the n 
rotations are the powers ak for 0≤k<n, where a=(1, 2, 3,…, n) is a rotation 
through the angle 2π/n. Let b be the reflection through the bisector of P 
that passes through the vertex 1. Then b=(2, n)(3, n-1)(4, n-2)…. For example, 
when n=5, b=(2, 5) (3, 4) and when n=6, b=(2, 6) (3, 5). Notice that there is a 
difference between the odd and even cases. When n is odd, b fixes no vertex 
other than 1, but when n is even, b fixes one other vertex, namely (n+2)/2. 
Now we can see, either geometrically or by multiplying permutations, that 
the n reflections of P are the elements akb for 0≤k<n. Thus we have 
  
In all cases, we have ba=an-1b (=a-1b). 
© 2005 by Chapman & Hall/CRC Press

Background Material 
13 
2.1.4 Generators 
Let A be any subset of a group G. The subgroup of G generated by A, which 
is denoted by 〈A〉, or by x1, x2,…, xr if A={x1, x2,…, xr}, is defined to be the 
intersection of all subgroups of G that contain A. In particular, we say that 
A generates G (or is a generating set for G) if 〈A〉=G. 
An equivalent definition is that 〈A〉 is equal to the set of all elements of 
G that can be written as products x1x2…xr for some r ∈ 
, where each xi is 
in A or in A-1. The empty product (r=0) is defined to be 1G. 
In practice, and particularly in computational applications, a generating 
set {x1, x2,…, xr} often has an ordering that is defined implicitly by the 
subscripts of the xi. It is also convenient to allow for the possibility that 
xi=xj when i≠j, which can result in conflicts with the standard mathematical 
convention that sets may not contain repeated elements. We shall therefore 
frequently refer to generating sequences [x1,…, xk], rather than generating 
sets, where the subgroup generated by the sequence is defined to be the 
subgroup generated by the set consisting of the elements in the sequence. 
2.1.5 Examples—permutation groups and matrix 
groups
 
Let Ω be any set, and let Sym(Ω) denote the set of permutations of Ω; that 
is, the bijections from Ω to itself. Then Sym(Ω) is a group under composition 
of maps. It is known as the symmetric group on Ω. A subgroup of Sym(Ω) is 
called a permutation group on Ω. 
For x∈Ω and g∈Sym(Ω), we shall denote the result of applying g to x by 
xg rather than by the more usual g(x). The composite gh will mean “first 
apply g, then apply h”, and so xgh=(xg)h. 
Let us recall the cyclic notation for permutations. If a1,…, ar are distinct 
elements of Ω, then the cycle (a1, a2,…, ar) denotes the permutation g of Ω 
with  
, and bg=b for b∈Ω\{a1, a2,…, ar}. 
When Ω is finite, any permutation of Ω can be written as a product (or 
composite) of disjoint cycles. Note that a cycle (a1) of length 1 means that 
, and so this cycle can (and normally is) omitted. 
As an example of composition, if Ω={1, 2, 3}, g1=(1, 2, 3) and g2=(1, 2), 
then g1g2=(2, 3), whereas g2g1=(1, 3). The inverse of a permutation can be 
calculated by reversing all of the cycles. For example, the inverse of (1, 5, 
3, 6)(2, 8, 7) is (6, 3, 5, 1) (7, 8, 2)=(1, 6, 3, 5)(2, 7, 8). (The cyclic representation 
is not unique: (a1, a2,…, ar)=(a2, a3,…, ar, a1), etc.) 
A cycle of length 2 is called a transposition. Since any cycle can be written 
as a product of transpositions ( (1, 2, 3,…, n)=(1, 2)(1, 3) (1, 4)…(1, n), for 
example), it follows that any permutation on Ω can be written as a product 
of transpositions. A permutation is called even if it is a product of an even 
number of transpositions, and odd if it is a product of an odd number of 
transpositions. It can be proved that no permutation is both even and odd, 
so the definition makes sense. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
14 
The set H of even permutations forms a subgroup of Sym(Ω). This is 
known as the alternating group on Ω, and is denoted by Alt(Ω). If (x, y) is 
some fixed transposition on Ω then, for any g∈Sym(Ω), one of the two 
permutations g and gx is even and the other is odd. Hence G=H∪H(x,y), so 
|G : H|=2. 
Let K be a field. Then, for any fixed d>0, the set of d×d invertible matrices 
with entries in K forms a group under multiplication. This group is denoted 
by GL(d, K) or GLd(K). 
The d×d matrices over K with determinant 1 also form a group denoted 
by SL(d, K) or SLd(K). This is a subgroup of GL(d, K). when K is a finite 
field Fq of order q, we use the alternative notation GL(d, q), etc. There are 
a number of important subgroups of GL(d, q) known as the classical groups. 
These include the symplectic groups Sp(d, q), the unitary groups GU(d, q), 
SU(d, q), and two types of orthogonal groups GO(d, q). We refer the reader 
to [CCN+85] for definitions, essential properties, and further references. 
2.1.6 Normal subgroups and quotient groups 
DEFINITION 2.6 A subgroup H of a group G is called normal in G if the 
left and right cosets gH and Hg are equal for all g∈G. 
For example, {1} and G are normal subgroups of any group G, and any 
subgroup of index 2 is normal, but the subgroup {1, (1, 2)} of Sym({1, 2, 3}) is 
not normal. 
An equivalent condition, which is often used as the definition, is that H is 
a normal subgroup of G if and only if g-1hg∈H for all h∈H, g∈G. 
The standard notation for “H is a normal subgroup of G” is H  G or H 
G. We shall use H  G to mean that H is a proper normal subgroup of G— 
i.e., H≠G, but this usage is not universal. 
A critical property of normal subgroups N of groups G, which is not shared 
by subgroups in general, is that the product of any element n1g of the coset 
Ng with any element n2h of the coset Nh lies in the coset Ngh. Hence 
(Ng)(Nh)=Ngh, and the set of right cosets Ng of N in G forms a group of 
order |G : N| under multiplication. This group is denoted by G/N and is 
called the quotient group (or sometimes factor group) of G by N. 
A group is called simple if |G|>1 and the only normal subgroups of G are 
{1} and G. For example, cyclic groups of prime order are simple. 
DEFINITION 2.7 Let A be a subset of a group G. The normal closure of A 
in G, which is denoted by 〈AG〉, is defined to be the intersection of all normal 
subgroups of G that contain A. 
Since the intersection of any collection of normal subgroups of G is easily 
shown to be normal in G, 〈AG〉 is the smallest normal subgroup of G 
© 2005 by Chapman & Hall/CRC Press

Background Material 
15 
containing A. An equivalent definition of 〈AG〉 is the subgroup of G generated 
by the set AG:={g-1ag|g∈G, a∈A}. 
2.1.7 Homomorphisms and the isomorphism theorems 
DEFINITION 2.8 Let G and H be groups. A homomorphism ϕ from G to H 
is a map ϕ:G→H such that ϕ(g1g2)=ϕ(g1)ϕ(g2) for all g1, g2∈G. 
It is straightforward to prove that any homomorphism ϕ:G→H maps 1G to 
1H, and that ϕ(g-1)=ϕ(g)-1 for all g∈G. 
A homomorphism ϕ is called, respectively, a monomorphism, an 
epimorphism or an isomorphism, if it is, respectively, an injection, a surjection 
or a bijection. A homomorphism from G to G is called an endomorphism of 
G, and an isomorphism from G to G is called an automorphism of G. 
The automorphisms of G form a group, denoted by Aut(G), under 
composition. This is of course a subgroup of Sym(G), and so we follow our 
convention for permutation groups, and represent the result of applying 
α∈Aut(G) to g∈G by gα rather than by α(g). So, for α, β ∈ Aut(G), αβ means 
first α then β. For any k∈G, the map αk:G→G defined by gαk=k-1gk is an 
automorphism of G. This type of automorphism is known as an inner 
automorphism, and the set of all inner automorphisms forms a normal 
subgroup Inn(G) of Aut(G). 
An automorphism that is not inner is called an outer automorphism and 
the outer automorphism group Out(G) is defined to be the quotient group 
Aut(G)/Inn(G). 
Two groups G and H are called isomorphic, and we write G≅H, if there 
is an isomorphism ϕ:G→H. The inverse of an isomorphism is an 
isomorphism, so G≅H implies H≅G, and G≅H and H≅K imply G≅K. 
In many contexts isomorphic groups are regarded as being the same group. 
It is easy to prove that any two cyclic groups of the same order (finite or 
infinite) are isomorphic, so we talk about the infinite cyclic group, and the 
cyclic group of order n, which we shall denote by Cn in this book. Similarly, 
if Ω, ∆ are sets with |Ω|=|∆|, then Sym(Ω)≅Sym(∆) and Alt(Ω)≅Alt(∆), so, 
for any n>0, we can talk about the symmetric and alternating groups Sym(n) 
and Alt(n) acting on a set of size n. By default, we shall regard these groups 
as acting on the set Ω={1..n}. 
Let ϕ:G→H be any group homomorphism. Then the kernel ker(ϕ) of ϕ is 
defined to be the set of elements of G that map onto 1H; that is, 
  
It can be shown that ker(ϕ) is always a normal subgroup of G, whereas the 
image im(ϕ) of ϕ is a subgroup, but not necessarily a normal subgroup, of 
H. Furthermore, if N is any normal subgroup of G, then there is an 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
16 
epimorphism, known as the natural epimorphism ϕ:G→G/N defined by 
ϕ(g)=Ng. So the set of normal subgroups of G is just the set of kernels of 
homomorphisms with domain G. 
We now state the three isomorphism theorems for groups. The first of 
these is the most important. For the second, note that if H is any subgroup 
and K is a normal subgroup of G, then HK=KH is a subgroup of G. It is a 
normal subgroup if H is. 
THEOREM 2.9 (first isomorphism theorem) Let ϕ:G→H be a 
homomorphism with kernel K. Then G/K≅im(ϕ). More precisely, there is 
an isomorphism 
 defined by 
 for all g∈G. 
THEOREM 2.10 (second isomorphism theorem) Let H be any subgroup and 
let K be a normal subgroup of a group G. Then H∩K is a normal subgroup 
of H and H/(H∩K)≅HK/K. 
THEOREM 2.11 (third isomorphism theorem) Let K⊆H⊆G, where H and 
K are both normal subgroups of G. Then (G/K)/(H/K)≅G/H. 
Note that if αk is the inner automorphism of a group G defined as described 
above by k∈G, then the map G→Aut(G) defined by 
 is a homomorphism 
with image Inn(G). Its kernel is 
, which is 
defined to be the centre Z(G) of G. So, by the first isomorphism theorem, we 
have G/Z(G) Inn(G). 
Exercises 
1. 
Let G be a set endowed with an associative binary operation D:G×G→G 
that contains an element e∈G such that: 
(a) 
for all g∈G, e D g=g; and 
(b) 
for all g∈G there exists h∈G such that h D g=e. 
Prove that G is a group under the operation D. 
2. 
Prove that the number |G : H| of distinct right cosets of a subgroup H 
of a group G is equal to the number of distinct left cosets. (This is easy if 
G is finite, since both numbers are |G|/|H|, but less easy when G is 
infinite.) 
3. 
Let a and b be the generators of the dihedral group D2n, as in Subsection 
2.1.3. Let H be a subgroup of D2n that is contained in the cyclic subgroup 
〈a〉. Show that H is normal in D2n and that either H=〈a〉, or G/H is 
isomorphic to a dihedral group. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
17 
4. 
Prove that the two definitions of the subgroup generated by a subset of 
a group G given in Subsection 2.1.3 are equivalent, and that the two 
definitions of the normal closure of a subset of a group are equivalent. 
5. 
Prove that a cyclic group Cn of order n has exactly Φ(n) generators, 
where Φ(n)=|{m ∈ [1..n]|gcd(m, n)=1}| is the Euler Φ-function. Deduce 
that |Aut(Cn)|=Φ(n). 
6. 
Prove that the cyclic groups of prime order are the only (finite or infinite) 
abelian simple groups. 
2.2 Group actions 
2.2.1 Definition and examples 
DEFINITION 2.12 Let G be a group and Ω a set. An action of G on Ω is 
defined to be a homomorphism ϕ:G→Sym(Ω). 
So, for each g∈G, ϕ(g) is a permutation of Ω. When we are talking about a 
fixed action ϕ, we shall usually just write αg rather than αϕ(g) for the action 
of ϕ(g) on α∈Ω. The fact that ϕ is a homomorphism then translates into the 
property αgh=(αg)h for all g, h∈G, α∈Ω. 
Notice that it is inherent in our notation αg that G is acting on Ω from 
the right. Actions from the left are more common in the literature, largely 
because this is more consistent with the convention of writing functions 
on the left of their arguments. However, both GAP and MAGMA use actions 
from the right, and we shall consistently adopt this convention in this 
book. Similarly, elements of vector spaces over a field K will be represented 
by row vectors v∈Kd, and a linear map Kd→Kd will be represented by a 
d×d matrix α over K, which acts on the vectors from the right; that is, 
. 
The property ϕ(1G)=1Sym(Ω) translates into α1=α for all α∈Ω. In fact, an 
equivalent way of defining a group action is as a map Ω×G→Ω with 
, which satisfies α1=α and αgh=(αg)h for all g, h∈G, α∈Ω. Some 
authors define a group action like this, and call a homomorphism from G 
to Sym(Ω) a permutation representation of G on Ω, but we shall regard the 
expressions “action of G on Ω” and “permutation representation of G on 
Ω” as being synonymous. The image im (ϕ) of the action will be denoted 
by GΩ. 
Two actions ϕ1 and ϕ2 of G on sets Ω1 and Ω2 are said to be equivalent, if 
there is a bijection τ : Ω1→Ω2 such that τ(αg)=τ(α)g, for all α∈Ω1 and g∈G. 
This just says that the actions are the same up to a ‘relabelling’ of the 
elements of the set on which G is acting. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
18 
The kernel K=ker(ϕ) of an action ϕ is equal to the normal subgroup 
  
The action is said to be faithful if K={1}. In this case, Theorem 2.9 says that 
G G/K im (ϕ). 
Example 2.1 
If G is a subgroup of Sym(Ω), then we can define an action of G on Ω simply 
by putting ϕ(g)=g for g∈G. This action is faithful.
Example 2.2 
Let G={1, a, a2, a3, a4, a5, b, ab, a2b, a3b, a4b, a5b}=D12 be the group of isometries 
of a regular hexagon P. In Subsection 2.1.3, we defined a and b to be the 
permutations (1, 2, 3, 4, 5, 6) and (2, 6) (3, 5) of the set {1, 2, 3, 4, 5, 6} of 
vertices of P, and so we have an action of G on this vertex set. 
There are some other related actions, however. We could instead take Ω 
to be the set E={e1, e2, e3, e4, e5, e6} of edges of P, where e1 is the edge joining 
1 and 2, e2 joins 2 and 3, etc. The action ϕ of G on E is then given by 
ϕ(a)=(e1, e2, e3, e4, e5, e6), ϕ(b)=(e1, e6) (e2, e5) (e3, e4). This action is still faithful, 
but is not equivalent to the action on vertices. 
As a third possibility, let D={d1, d2, d3} be the set of diagonals of P, where 
d1 joins vertices 1 and 4, d2 joins 2 and 5, and d3 joins 3 and 6. Then the 
action of G on D is defined by ϕ(a)=(d1, d2, d3), and ϕ(b)=(d2, d3). This action 
is not faithful, and its kernel is the normal subgroup {1, a3} of G. The image 
is isomorphic to D6. 
Example 2.3 
There is a faithful action called the right regular action, which we can 
define for any group G. Here we put Ω to be the underlying set of G and 
simply define αg to be αg for all g∈G, α∈Ω. 
More generally, let H be any subgroup of G, and let Ω be the set of right 
cosets of H in G. Again we can define an action of G on Ω by αg :=αg. This is 
known as a coset action. The right regular action corresponds to the case 
H=1.
The right regular action of a group G is closely related to its Cayley 
graph ΓX(G), which is defined with respect to a generating set X of G. 
DEFINITION 2.13 If G= 〈X〉, then the Cayley graph ΓX(G) is a directed 
labelled graph with vertex set V:={vg|g∈G} in one-one correspondence with 
the set of elements of G and, for each g∈G and x∈X, an edge labelled x from 
vg to vgx. It is customary to identify each such edge with an edge labelled 
x-1 from vgx to vg. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
19 
The edges of the Cayley graph define the action of the generators X in 
the right regular action of G. 
2.2.2 Orbits and stabilizers 
DEFINITION 2.14 Let G act on the set Ω. We define a relation ~ on Ω by 
α~β if and only if there exists a g∈G with β=αg. Then ~ is an equivalence 
relation. The equivalence classes of ~ are called the orbits of G on Ω. In 
particular, the orbit of a specific element α∈Ω, which is denoted by αG, is 
{αg|g∈G}. 
DEFINITION 2.15 Let G act on ∈ and let α∈Ω. Then the stabilizer of α in 
G, which is denoted by Gα or by StabG(α), is {g∈G|αg=α}. 
It is straightforward to check that Gα is a subgroup of G and that the kernel 
of the action is ∩α∈Ω Gα. 
Example 2.4 
Let G act by right multiplication on the set of right cosets of the subgroup 
H, as in Example 2.3 above. Since Hg=Hg for any g∈G, HG=Ω and there is 
only one orbit. The stabilizer of the coset Hg is the subgroup g-1Hg of G, 
and so the kernel of the action is equal to ∩g∈G g-1 Hg. This (normal) subgroup 
of G is called the core of H in G. It is denoted by HG, and is the largest 
normal subgroup of G that is contained in H.
THEOREM 2.16 (the orbit-stabilizer theorem) Let the finite group G act on 
Ω, and let α∈Ω. Then |G|=|αG| |Gα|. 
PROOF Let β∈αG. Then there exists a g∈G with αg=β. If g′∈G with 
=β, then g′g-1∈Gα, so g′∈Gαg, and we see that the elements g′ with 
=β 
are precisely the elements of the coset Hg. But |Hg|=|H|, so for each 
β∈αG, there are precisely |H| elements g′ of G with ∈g=β, and the total 
number of such β∈αG must be |G|/|H|, which proves the result. 
Dually to the stabilizer Gα, for g∈G, we define 
  
to be the fixed point set of g. The following result, which is often known as 
Burnside’s lemma, but was actually known earlier to Cauchy and Frobenius, 
says that the number of orbits of an action is equal to the average number 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
20 
of fixed points of the group elements. This result, together with refinements 
and generalizations, is the basis of countless applications of group theory 
to the enumeration of combinatorial structures. We shall say some more 
about this later in the book (Section 10.5). 
LEMMA 2.17 (the Cauchy-Frobenius lemma) Let the finite group G act on 
Ω. Then the number of orbits of G on Ω is equal to 
. 
PROOF 
  
where the last equality follows from the orbit-stabilizer theorem. But since 
 is the total number of orbits of G on Ω, the result follows.
For future use, we introduce some further notation. 
DEFINITION 2.18 Let G act on Ω and let ∆⊆Ω. Then 
 (i) The setwise stabilizer {g∈G|αg∈∆ for all α∈∆} of ∆ in G is denoted by 
G∆. 
(ii) The pointwise stabilizer {g∈G|αg=α for all α∈∆} of ∆ in G is denoted by 
G(∆). 
2.2.3 Conjugacy, normalizers, and centralizers 
In Example 2.3, a group G was made to act on the set of its own elements 
by multiplication on the right. There is another important action of G on 
Ω=G, which is defined by 
  
This is called conjugation. The orbits of the action are called the conjugacy 
classes of G, and elements in the same conjugacy class are said to be 
conjugate in G. So g, h∈G are conjugate if and only if there exists f∈G with 
h= f-1gf. We shall write ClG(g) for the orbit of g; that is, the conjugacy class 
containing g. Since f-1gf is the image of g under the inner automorphism of 
G defined by f, conjugate elements must have the same order. 
The stabilizer Gg in this action consists of the elements f∈G for which 
gf=g; that is, fg=gf. In other words, it consists of those f that commute with 
g. It is called the centralizer of g in G and is written as CG(g). By applying 
the orbit-stabilizer theorem, we get the well-known formula |ClG(g)|=|G|/ 
|CG(g)| for all g∈G. The kernel K of the action is the centre Z(G) of G, 
which we encountered at the end of Subsection 2.1.7. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
21 
Example 2.5 
Let G=Sym(Ω) and let f, g∈G. Write g in cyclic notation, and suppose that 
one of the cycles of g is (α1, α2,…, αr). Then 
, and so 
 and 
hence 
, and we find that f-1gf has a cycle 
. 
In other words, given a permutation g in cyclic notation, we obtain the 
conjugate f-1gf of g by replacing each element α∈Ω in the cycles of g by αf. 
For example, if Ω={1, 2, 3, 4, 5, 6, 7}, g=(1, 5) (2, 4, 7, 6) and f= (1, 3, 5, 7, 2, 
4, 6), then f-1gf=(3, 7) (4, 6, 2, 1). 
It follows that two permutations of Ω are conjugate in Sym(Ω) if and only 
if they have the same cycle-type; that is, the same number of cycles of each 
length. For example, Sym(4) has five conjugacy classes, with representatives 
1, (1, 2), (1, 2)(3, 4), (1, 2, 3), (1, 2, 3, 4).
We can also take Ω to be the set of subgroups H of G, and use the 
corresponding action Hg=g-1Hg of G on Ω. Again, subgroups in the same 
orbit of this action are called conjugate subgroups. The stabilizer of a 
subgroup H is equal to {g∈G|g-1Hg=H}, which is called the normalizer of H 
in G and denoted by NG(H). Then clearly H  NG(H). By the orbit-stabilizer 
theorem, the number of conjugates of H in G is equal to |G:NG(H)|. 
The centralizer CG(H) of H in G, on the other hand, is defined to be the 
subgroup {g∈G|gh=hg for all h∈H} of G, and so CG(G)=Z(G). 
2.2.4 Sylow’s theorems 
We state Sylow’s theorems as a single theorem. There are many different 
proofs. See, for example, Chapter 4 of [Rot94] and Section 1.5 of [Cam99] 
for two different proofs. If G is a finite group, p is a prime, and |G|=pmq 
with pxq, then a subgroup of G of order pm is called a Sylow p-subgroup of 
G, and the set of all such subgroups is denoted by Sylp(G). In general, a 
group of order a power of a prime p, including the trivial group of order p0, 
is known as a p-group. 
THEOREM 2.19 (Sylow’s theorems.) Let G be a finite group, let p be a 
prime number, and let |G|=pmq where pxq. Then: 
  (i) For any l with 0≤l≤m, the number of subgroups of G of order pl is 
congruent to 1 modulo p. In particular, such subgroups exist for all 
such l, and |Sylp(G)|≡1 mod p. 
 (ii) Any two subgroups in Sylp(G) are conjugate in G, and |Sylp(G)|= |G : 
NG(P)| for any P∈Sylp(G). 
(iii) For 0≤l<m, any subgroup of G of order pl is contained in some subgroup 
of order pl+1. Hence any such subgroup is contained in a Sylow p- 
subgroup. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
22 
We state without proof a couple of easy consequences of Sylow’s 
theorems. 
PROPOSITION 2.20 Let G be a finite group, p a prime, P∈Sylp(G), and H 
a subgroup of G with NG(P)≤H. Then NG(H)=H. 
PROPOSITION 2.21 (the Frattini lemma.) Let G be a finite group, p a 
prime, N a normal subgroup of G and P∈Sylp(N). Then G=NNG(P). 
2.2.5 Transitivity and primitivity 
DEFINITION 2.22 An action of G on a set Ω is called transitive if there is 
a single orbit under the action. That is, for any α, β∈Ω, there exists g∈G 
with αg=β. Otherwise, it is called intransitive. 
Let n∈N with n>0. The action is n-fold transitive (or just n-transitive for 
short) if |Ω|≥n, and for any two ordered lists [α1, α2,…, αn], [β1, β2,…, βn] of 
distinct points in Ω, there exists g∈G with 
. 
Note that 1-transitive is the same as transitive. Also, the condition 
|Ω|≥n for n-fold transitivity ensures that n-transitive actions are (n–1)- 
transitive for n>1. By “GΩ is transitive” we mean “the action of G on Ω is 
transitive”. 
Example 2.6 
If |Ω|=n, then Sym(Ω) is l-transitive for all l with 1≤l≤n, and Alt(Ω) is (l–2)- 
transitive for 3≤l≤n.
The following result says that all transitive actions are equivalent to the 
action described in Example 2.4 for some subgroup H of G. 
PROPOSITION 2.23 
(i) 
Let H be any subgroup of G, and let ϕH be the action of G by right 
multiplication on the right cosets of H in G (Example 2.4). Then ϕH is 
transitive. 
(ii) If ϕ:G→Sym(Ω) is any transitive action of G and α∈Ω, then ϕ is 
equivalent to ϕH, where H=Gα. 
(iii) If H1, H2≤G, then ϕH1 and ϕH2 are equivalent if and only if H1 and H2 are 
conjugate in G. 
PROOF (i) is clear since, for any cosets Hg1 and Hg2 of H, we have (Hg1) 
(g1
-1g2)=Hg2. For (ii), let Σ be the set of right cosets of H in G, with H=Gα. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
23 
For g1, g2∈G, we have αg1=αg2 if and only if Hg1=Hg2, so we can define a 
bijection τ : Σ→Ω by τ(Hg)=αg, and τ is easily seen to be an equivalence 
of actions. For any β∈Ω, we have Gβ=g-1Gαg, where αg=β. It follows from 
(ii) that ϕH1 and ϕH2 are equivalent if and only if H2 is the stabilizer of a 
point in the action ϕH1, which is the case if and only if H1 and H2 are 
conjugate in G.
DEFINITION 2.24 If G acts on Ω, then GΩ is regular if it is transitive and 
Gα=1 for some (and hence all) α∈Ω. 
The right regular action of G on its own underlying set defined in Example 
2.3 is indeed regular. By the orbit-stabilizer theorem, if G is finite and GΩ is 
regular, then |G|=|Ω|. 
If G acts on Ω, then a nonempty subset ∆ of Ω is called a block under the 
action if, for all g∈G, we have ∆g=∆ or ∆g∩∆=φ. The block is called nontrivial 
if |∆|>1 and ∆≠Ω. The orbits of any action are clearly blocks, but we 
normally restrict the consideration of blocks to transitive actions. 
DEFINITION 2.25 A transitive action of G on a set Ω is called primitive if 
there are no nontrivial blocks under the action. Otherwise, it is called 
imprimitive. 
If ∆ is a block under an action, then the distinct translates ∆g of ∆ under 
G partition Ω. The set of translates is known as a block system. So a 
transitive action is primitive if and only if it does not preserve a nontrivial 
partition of Ω. Note also that |∆|=|∆g|, so all blocks in such a partition 
have the same size. Hence if GΩ is transitive and |Ω| is prime, then GΩ is 
primitive. 
Example 2.7 
Let G=D12 act on the vertices of a regular hexagon, as in Example 2.2 
above. Then G preserves two nontrivial block systems, {{1, 3, 5}, {2, 4, 6}} 
and {{1, 4}, {2, 5}, {3, 6}}. 
If G≤Sym(Ω) and we say that G is (n-fold) transitive or primitive, then we 
are referring to the obvious action of G on Ω defined in Example 2.1. 
There is an alternative method of describing block systems, which will 
often be convenient for us to employ. 
DEFINITION 2.26 If G acts on Ω, then an equivalence relation ~ on Ω is 
called a G-congruence if α~β implies αg~βg for all α, β∈Ω and g∈G. 
Assume that GΩ is transitive. It is clear that if GΩ has block system {∆g|g∈G}, 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
24 
then the equivalence relation on Ω defined by α~ß if and only if a and ß lie 
in the same block is a G-congruence. Conversely, the equivalence classes 
defined by any G-congruence on Ω form the blocks of a block system. So, 
for transitive actions, G-congruences and block systems are essentially the 
same thing. 
We remind the reader that, formally speaking, an equivalence 
relation ~ on a set Ω is a subset R of Ω×Ω, where α~β means the same as 
(α, β)∈R. 
DEFINITION 2.27 If S ⊆Ω×Ω, then the G-congruence generated by S is 
defined to be the intersection of all G-congruences that contain S. 
PROPOSITION 2.28 Let S⊆Ω×Ω; and let R be the G-congruence generated 
by S. Call, α, β∈Ω directly equivalent if, for some g∈G, we have α=γg and 
ß=δ g, where either (γ, δ )∈S or (δ , γ)∈S. Then (α, ß)∈R if and only if there 
exist α=α0, α1,…,αr=ß in Ω with r≥0, such that each ai is directly equivalent 
to αi+1. 
PROOF Define the relation ~ on Ω by α~ß if and only if there exists α=α0, 
α1,…,αr=ß as in the statement of the proposition. Then clearly α~ß implies 
that (α, ß) is in any G-congruence containing S, and hence (α, ß)∈R. 
Conversely, it is straightforward to check that ~ is a G-congruence, and the 
result follows. 
Let Ω be the disjoint union of sets ∆1,…,∆m, where each |∆i|=l, and let 
G be the subgroup of Sym(Ω) preserving this partition. Then G is the 
wreath product of the permutation groups Sym(l) and Sym(m), and we 
write 
. It has a normal subgroup H ≅ Sym(l)m that 
fixes all of the ∆i, and G/H ≅ Sym(m). See, for example, Section 5.9 of 
[Hal59] for details of the theory of wreath products of permutation 
groups. 
We shall now give brief proofs of some standard results pertaining to 
transitivity and primitivity. 
PROPOSITION 2.29 
  (i) A 2-fold transitive action is primitive. 
 (ii) Let G act on Ω, and let N G. Then the orbits of NΩ are blocks under the 
action of G. 
(iii) If GΩ is primitive, and NΩ is nontrivial, then NΩ is transitive. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
25 
PROOF Let GΩ be 2-transitive, and let ∆ be a block with |∆|>1. Let 
α, ß∈∆ and α≠γ∈Ω. Then by 2-transitivity, there exists g∈G with αg=α 
and ßg=γ, so α∈∆∩∆g, and hence ∆=∆g, and γ∈∆. Thus ∆=Ω, which 
proves (i). 
Let ∆=αN be an orbit of NΩ, let g∈G, and suppose that α∈∆∩∆g. So α=ßg 
for some ß∈∆. Then for any αh∈∆ with h∈N, normality of N gives gh=h′g 
for some h′∈N, and αh=ßgh=ßh′g∈∆g. So ∆=∆g, proving (ii). (iii) follows easily 
from (ii).
PROPOSITION 2.30 Let GΩ be a transitive action and let α∈Ω. Then 
 (i) If K is a subgroup with Gα≤K≤G, then αK is a block and, conversely, any 
block containing α is equal to αK for some K with Gα≤K≤G. 
(ii) If |Ω|>1; then GΩ is primitive if and only if Gα is a maximal subgroup of 
G. 
PROOF Let Gα≤K≤G and ∆=αK. Suppose that ß∈∆∩∆g for some g∈G. So 
ß=αh=αkg for some h, k∈K. But then kgh-1 ∈ Gα≤K, so g∈K and ∆g=∆. 
Conversely, if ∆ is a block containing α, then let K={g∈G|αg∈∆}. Certainly 
Gα≤K. For any k∈K, we have αk∈∆∩∆k, so ∆=∆k, and hence K={g∈G| 
∆g=∆}, which is a subgroup of G. This proves (i), and (ii) follows immediately 
from (i). 
Exercises 
1. 
Let G act on Ω and let α∈Ω and g∈G. Prove that Gag=g-1 Gag. 
2. 
Find generators of the wreath product 
. 
3. 
Let G be a group of order pn for p prime, and let N be a normal subgroup 
of G with N≠1. By adding up the sizes of the conjugacy classes of G that 
are contained in N, prove that N∩Z(G)≠1. In particular, if n>0, then 
Z(G)≠1. 
4. 
Let H be a subgroup of a group G and let HG be the core of H in G, as 
defined in Example 2.4. Prove that HG≤H and that, if K is any normal 
subgroup of G with K≤H, then K≤HG. 
5. 
Calculate the conjugacy classes of the dihedral group D2n. (The cases 
when n is odd and even are different.) 
6. 
Prove that a normal subgroup of a group G is a union of conjugacy 
classes of G. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
26 
7. 
Let H=Alt(Ω) and G=Sym(Ω), and let g∈H. Show that either CH(g)=CG(g) 
and ClG(g) is the union of two equally-sized conjugacy classes of H, or 
|CG(g):CH(g)|=2 and ClG(g)=ClH(g). Show that Alt(5) has five conjugacy 
classes, with orders 1, 12, 12, 15, 20, and deduce that Alt(5) is a simple 
group. 
2.3 Series 
2.3.1 Simple and characteristically simple groups 
Let G be a group and let Ω be a subgroup of Aut(G). We call G an Ω-group 
for short. A subgroup H of G is called Ω-invariant if gα∈H for all gΩH, α∈Ω. 
So, if Ω=Inn(G), then an O-invariant subgroup is the same thing as a normal 
subgroup. An Aut(G)-invariant subgroup is called a characteristic subgroup. 
For example, the centre Z(G) of G is characteristic in G. We write H char G 
to mean that H is characteristic in G. 
If H K and K G, then it is not necessarily true that H K. However, H 
char K and K G imply H G, and H char K and K char G imply H char G. 
A subgroup H of G is called subnormal in G if there exists a finite chain 
H=H0 H1 …  Hr=G. 
An Ω-group G is called Ω-simple if |G|>1, and G has no proper nontrivial 
Ω-invariant subgroups. So a simple group is the same as an Inn(G)-simple 
group. The celebrated classification of finite simple groups was completed 
around 1980. The finite nonabelian simple groups comprise a number of 
infinite families of groups, including Alt(n) for n≥5, the classical groups and 
the exceptional groups of Lie type, together with the 26 sporadic groups. 
We shall assume that the reader has some basic familiarity with these 
groups, and refer to [CCN+85] or [Car72] for any detailed information that 
we may need about them. 
An Aut(G)-simple group is called characteristically simple. The following 
result, proved in Theorem 5.20 of [Rot94], describes the finite examples. 
THEOREM 2.31 A finite group is characteristically simple if and only if it 
is isomorphic to a direct product of one or more isomorphic simple groups. 
The simple groups in this theorem can be either abelian, in which case the 
group itself is elementary abelian, or nonabelian. 
A normal subgroup N of a group G is called a minimal normal subgroup 
of G if N≠1 and there is no normal subgroup M of G with 1<M<N. A minimal 
normal subgroup must be characteristically simple, and so we have the 
following corollary. 
COROLLARY 2.32 A minimal normal subgroup N of a finite group G is 
© 2005 by Chapman & Hall/CRC Press

Background Material 
27 
isomorphic to a direct product of isomorphic simple groups. In particular, if 
N is abelian, then it is an elementary abelian p-group for some prime p. 
2.3.2 Series 
Let G be an Ω-group, and let 
  
be a finite series of Ω-invariant subgroups in which each group is normal in 
the preceding group. Such a series is called an (Ω-invariant) subnormal 
series of G. It is called an Ω-composition series if each factor Gi/Gi+1 is Ω- 
simple. We shall be mainly interested in the cases Ω={1}, which is an 
ordinary composition series with simple factor groups, and the case 
Ω=Inn(G), where an Ω-composition series is called a chief series for G, and 
the factors Gi/Gi+1 are characteristically simple groups. 
It is clear that finite groups have finite composition series and finite 
chief series. For an infinite group, such finite series may or may not exist, 
and there are generalizations which allow infinite series. But for any group 
G and any Ω≤Aut(G), we have the Jordan-Hölder theorem; see, for example, 
Section 2.10 of [Sco64]. 
THEOREM 2.33 Let G be an Ω-group, and let 
  
and 
  
be two finite Ω-composition series of G. Then r=s and there is a bijection 
ϕ:[1..r]→[1..r] such that Gi-1/Gi and Hj-1/Hj are Ω-isomorphic for 1≤i≤r, 
where j=ϕ(i). 
We generally refer to the collection of isomorphism types of composition 
factors or chief factors of a finite group G simply as the composition/chief 
factors of G. This collection is technically a multiset, because it can have 
repeated elements. 
2.3.3 The derived series and solvable groups 
For g, h∈G, we define the commutator [g,h]:=g-1h-1gh. If H and K are 
subgroups of G, then we define 
. If there is 
a serious danger of confusion with the same notation [g, h] used to mean 
the ordered list of elements g, h∈G, then we shall write comm(g, h) in 
place of [g, h]. The following lemma lists some elementary properties of 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
28 
commutators. Recall that, for x,y∈G, xy is defined to be y-1xy. We denote 
the inverse of xy by x-y. 
LEMMA 2.34 Let x, y, z be elements of a group G and let H, K be subgroups 
of G. Then: 
(i) 
[xy, z]=[x, z]y[y, z] and [x, yz]=[x, z][x, y]z; 
(ii) [H, K] is a normal subgroup of 〈H,K〉; 
(iii) [H, K]=[K, H]; 
(iv) 
(v) [[x, y-1], z]y[[y, z-1], x]z[[z, x-1], y]x=1. 
The proof is left as an exercise. For (ii), notice that (i) implies [x, z]y= [xy, 
z][y, z]-1, and deduce that H≤NG([H, K]). Show K≤NG([H, K]) similarly. For 
(iii), use [x,y]-1=[y, x]. 
The following result will be used for computing commutator 
subgroups. 
PROPOSITION 2.35 If H= 〈X〉 and K= 〈Y〉 are subgroups of a group G, then 
, where Z={[x, y] x∈X, y∈Y}. 
PROOF Let 
. By Lemma 2.34 (ii), 
, so N≤[H, 
K]. By Lemma 2.34 (i), we have [x-1,y]=[x,y]-x-1 and [x, y-1]=[x-1, y-1] for all x, 
y∈G. So, if x∈X, y∈Y, then [x-1, y], [x, y-1] and [x-1, y-1] all lie in N. 
Furthermore, 
it 
follows 
from 
Lemma 
2.34 
(i) 
that 
 and 
. It 
then follows by a straightforward induction argument on word length that 
[h, k] ∈N for all h∈〈X〉=H and all k∈〈Y〉=K, and so [H, K]≤N, which proves 
the result. 
In particular, [G, G], the derived subgroup or commutator subgroup of G, is 
characteristic in G and is the smallest normal subgroup of G with abelian 
quotient group. 
DEFINITION 2.36 A nontrivial group is called perfect if [G, G]=G. 
So, for example, nonabelian simple groups are perfect. The derived series 
of G is the descending series 
  
© 2005 by Chapman & Hall/CRC Press

Background Material 
29 
where G[i]:=[G[i-1], G[i-1]] for i≥1. (We have used G[i] rather than themore 
standard G(i) to avoid clashing with our use of G(i) in Chapter 4 in thecontext 
of stabilizer-chains of permutation groups.) 
Each factor G[i-1]/G[i] in the series is abelian. If there is an r such that 
G[r]={1} or G[r] is perfect, then the series terminates at G[r] and is finite of 
length r. If it terminates with G[r]={1}, then we say that G is solvable (or 
soluble) with derived length r. A group is solvable if and only if it has a 
normal series with abelian factors. A finite group is solvable if and only if it 
has a subnormal series with cyclic factors or, equivalently, if all of its 
composition factors are cyclic of prime order. 
If G[i]=G[i+1] for some i, then we define G[∞]:=G[i], in which case G[∞] is the 
unique smallest normal subgroup of G with solvable quotient group. 
More generally, a group with a finite subnormal series with (possibly 
infinite) cyclic factors is called polycyclic. Equivalently, a polycyclic group 
is a solvable group in which each factor G[i–1]/G[i] is finitely generated. 
Polycyclic groups are important in computational group theory because 
there are efficient algorithms for computing within them. Indeed, algorithms 
for polycyclic groups is the subject of Chapter 8. 
2.3.4 Central series and nilpotent groups 
A normal series 
  
of G is called a central series if Gi–1/Gi≤Z(G/Gi) for 1≤i≤r. A group is called 
nilpotent if it has such a series, and the (nilpotency) class of G is defined to 
be the length r of the shortest central series for G. Clearly every nilpotent 
group is also solvable. 
The lower central series of a group G is the descending series 
  
in which each γi+1 (G):=[G, γi(G)]. It is unfortunate that the lower central 
series begins with G=γ1 (G) while the derived series begins with G=G[0] but 
this is standard notation, so we are stuck with it. The series terminates at 
γr(G), and so has length r-1, if γr(G)=[G, γr(G)]. Since γi-1(G)/γi(G)≤Z(G/γi 
(G)) for all i>1, it is actually a central series for G if and only if it terminates 
with Gr=1 for some r. It is not hard to show that this is the case if and only 
if G is nilpotent of class r–1. 
The upper central series of a group G is the ascending series 
  
where each Zi+1(G) for i≥1 is defined by Zi+1(G)/Zi(G)=Z(G/Zi(G)). The series 
terminates at Zr(G), and so has length r, if G/Zr(G) has trivial centre. It is 
a central series for G if and only if it terminates with Zr(G)=G for some r. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
30 
It is not hard to show that this is the case if and only if G is nilpotent of 
class r. 
It is straightforward to show by induction that, if 
  
is any central series of G, then Gi≥γi+1(G) and Gi≤Zr-i(G) for 0 ≤i≤r. This 
accounts for the names lower and upper central series. 
There are a number of characterizations of finite nilpotent groups, which 
we shall list shortly. First we prove: 
LEMMA 2.37 Let H and K be normal subgroups of a group G with HK=1. 
Then 
 H×K. 
PROOF Using Lemma 2.34 (iv), we have [H, K]≤HK=1, so the map (h, 
k)→hk defines an isomorphism from H×K to HK=
. 
It is customary, in the situation described in the lemma, to say that 
 is equal to (rather than is isomorphic to) the direct product of its 
subgroups H and K, and we shall follow that custom. Those who like to 
avoid ambiguities prefer to call 
 the internal direct product of H 
and K. 
THEOREM 2.38 Let G be a finite group. Then the following are equivalent: 
(i) 
G is nilpotent; 
(ii) |Sylp(G)|=1 for all primes p dividing |G|; 
(iii) G is the direct product of its Sylow p-subgroups; 
(iv) H<NG(H) for all proper subgroups H<G of G; 
(v) All maximal subgroups of G are normal in G. 
PROOF By Sylow’s theorems, (ii) is equivalent to all Sylow p-subgroups 
being normal in G and, under this assumption, (iii) can be proved by repeated 
application of Lemma 2.37. Clearly (iii) implies (ii), so (ii) and (iii) are 
equivalent. Clearly (iv) implies (v). If |Sylp(G)|>1 for some p, and H is a 
maximal subgroup of G that contains NG(P) with P∈Sylp(G), then 
Proposition 2.20 yields H=NG(H). Hence (v) implies (ii). 
By Exercise 1 of Subsection 2.2.3, a nontrivial finite group P of prime 
power order has nontrivial centre. It follows easily by induction on |P| 
that the upper central series of P reaches P, and hence that P is nilpotent. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
31 
It is straightforward to show that a direct product of nilpotent groups is 
nilpotent, so (iii) implies (i). 
(i) implies (iv) is also proved by induction on |G|. For H<G, either Z(G)≤H 
and we apply induction to G/Z(G), or H<HZ(G)≤NG(H). This completes the 
proof. 
2.3.5 The socle of a finite group 
The socle of a finite group plays an important rôle in the more advanced 
structural computations in finite groups that will be discussed in Chapter 
10, and we present its basic properties here. These are well-known, but it 
was not easy to find a convenient reference containing all of the properties 
that we require, so we include proofs here. 
DEFINITION 2.39 The socle soc(G) of a group G is the subgroup generated 
by all minimal normal subgroups of G. 
PROPOSITION 2.40 Let G be a finite group. Then soc(G) is the direct 
product M1×…×Mm of some minimal normal subgroups Mi of G, where 
each Mi is itself a direct product of isomorphic simple groups. 
Furthermore, the nonabelian Mi are the only nonabelian minimal normal 
subgroups of G. 
PROOF Let N G be maximal subject to being a direct product of minimal 
normal subgroups of G. If N≠soc(G), then there is a minimal normal 
subgroup M of G not contained in N. Then minimality of M gives MN=1 
and hence, by Lemma 2.37, 
, which contradicts the 
maximality of N. So N=soc(G), which proves the first assertion, and the 
fact that the Mi are direct products of isomorphic simple groups follows 
from Theorem 2.31. 
Let M be any minimal normal nonabelian subgroup of G. If M is not 
equal to any of the Mi then, by Lemma 2.37 again, [M, Mi]=1 for all i, so [M, 
soc(G)]=1. Since M is nonabelian, this contradicts M≤soc(G). 
COROLLARY 2.41 If G, Mi are as in the proposition, and Mk is nonabelian 
for some k, then the simple direct factors of Mk are permuted transitively 
under the action of G by conjugation on soc(G). 
PROOF By the proposition applied to Mk in place of G, the simple direct 
factors are the only minimal normal subgroups of Mk, so they are permuted 
under conjugation by G. If S is one of these factors, then 
 by 
minimality of Mk, so the action on the simple factors is transitive. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
32 
COROLLARY 2.42 The simple direct factors of the nonabelian minimal 
normal subgroups of a finite group G are precisely the nonabelian simple 
subnormal subgroups of G. 
PROOF Clearly each simple factor of a minimal normal subgroup is 
subnormal in G, so suppose that S is a nonabelian simple subnormal 
subgroup of G. If S G then the result is clear. Otherwise G has a proper 
normal subgroup N containing S and, by induction, we may assume that 
S is a direct factor of a minimal normal subgroup of N. Now soc(N) char 
N implies that soc(N) G, so the conjugates of S under G are all minimal 
normal subgroups of soc(N). Hence 
 is the direct product of these 
conjugates and is a minimal normal subgroup of G, which proves the 
result. 
2.3.6 The Frattini subgroup of a group 
DEFINITION 2.43 The Frattini subgroup Φ(G) of a group G is the 
intersection of its maximal subgroups. 
Clearly Φ(G) is a characteristic subgroup of G. Its principal property is that 
it consists of the so-called nongenerators of G. We shall only be interested 
in this result for finite groups; see, for example, Section 10.4 of [Hal59] for 
a more general treatment. 
PROPOSITION 2.44 If X is a subset of a finite group G with 
G=
. 
PROOF Otherwise 〈X〉 is contained in a maximal subgroup M of G, but 
then Φ(G)≤M and so 
, contradiction. 
We can describe Φ(G) very precisely in the case when G is a finite p-group. 
This topic will arise in Section 9.4 in connection with the p-quotient 
algorithm. 
Let G be a finite p-group for some prime p. By Theorem 2.38, all maximal 
subgroups M of G are normal in G and so they must have index p in G. So, 
for all x, y∈G, we have xp, [x, y]∈M, and hence xp, [x, y]∈Φ(G). In other 
words, G/Φ(G) is elementary abelian. 
On the other hand, if N G with G/N elementary abelian, then the 
intersection of the maximal subgroups of G/N is trivial, so Φ(G)≤N. Hence 
we have: 
PROPOSITION 2.45 If G is a finite p-group, then Φ(G) is equal to the 
smallest normal subgroup N of G such that G/N is elementary abelian. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
33 
Exercises 
1. 
Prove that subgroups, quotient groups, and direct products of solvable, 
nilpotent, or polycyclic groups are solvable, nilpotent, or polycyclic, 
respectively. 
2. 
Prove that if N G and N and G/N are both solvable, then G is solvable. 
Does this remain true with ‘nilpotent’ in place of ‘solvable’? 
3. 
Prove that if N≤Z(G) and G/N is nilpotent then G is nilpotent. 
4. 
Use Lemma 2.34 (v) to prove the three subgroups lemma: if H, K, L≤G 
with [[H, K], L]=[[K, L], H]=1 then [[L, H], K]=1. Deduce that 
[γi(G),γj(G)]≤γi+j(G) for all i, j≥1. 
5. 
Show that the final assertion in Proposition 2.40 may be false for abelian 
direct factors Mi of soc(G). 
6. 
Use the Frattini lemma (Proposition 2.21) together with Proposition 
2.44 to prove that, if G is a finite group and P∈Sylp(Φ(G)), then P G. In 
particular, the Frattini subgroup of a finite group is nilpotent. 
7. 
Let G be a finite p-group, and suppose that G/Φ(G) has order pd. Prove 
that |X|=d for any irredundant generating set X of G. (Hint: Since X 
generates G/Φ(G) modulo Φ(G), we have |X|≥d. If |X|>d, then some 
element x∈X is redundant as a generator of G/Φ(G), and so we can 
write x=wu, where w is a word over X\{x} and u∈Φ(G). Now use 
Proposition 2.44 to show that 
2.4 Presentations of groups 
We include here a rapid treatment of the basic theory of free groups and 
group presentations. The reader could consult [Joh98] for a more leisurely 
account of the same material. 
2.4.1 Free groups 
A free group on a set X is roughly speaking the largest possible group that 
is generated by X. This idea is made precise by the universal property 
described in the following definition. 
DEFINITION 2.46 A group F is free on the subset X of F if, for any group 
G and any map θ:X→G, there is a unique group homomorphism θ:F→G 
with θ(x)=θ(x) for all x∈X. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
34 
It follows directly from the definition that any group G that is generated 
by a set X is an epimorphic image of, and hence isomorphic to a quotient of, 
a free group on X. (We shall see shortly that a free group on X exists.) 
Uniqueness (up to isomorphism) of a free group on a set X is 
straightforward to prove, as is the fact that it depends only on |X|. 
PROPOSITION 2.47 
(i) 
Two free groups on the same set X are isomorphic. 
(ii) Free groups on X1 and X2 are isomorphic if and only if |X1|=|X2|. 
PROOF (i) follows from the ‘if’ part of (ii), so we just need to prove (ii). 
Suppose that F1, F2 are free on X1, X2 with |X1|=|X2| , let ii:Xi→Fi be the 
inclusion maps, for i=1, 2, and let :X1→X2 be a bijection. By the definition 
applied to the maps i2τ:X1→F2 and i1τ-1:X2→F1, we find group 
homomorphisms θ1:F1→F2 and θ2:F2→F1 that restrict to the i2 and i1τ-1 on 
X1 and X2, respectively. So θ2θ1:F1→F1 restricts to the identity on X1, and by 
the uniqueness part of the definition, θ2θ1 is the identity on F1. Similarly 
θ1θ2 is the identity on F2, so θ1,θ2 are mutually inverse and hence are 
isomorphisms. 
Conversely suppose that F1, F2 are free on X1, X2, and F1 and F2 are 
isomorphic. Let G be a group of order 2. Then there are 2|Xi| distinct maps 
from Xi to G for i=1, 2, and hence by the definition there are also 2|Xi| 
homomorphisms from Fi to G. So, for finite X1 and X2, F1 isomorphic to F2 
implies that |X1|=|X2|. The result is also true for infinite generating sets 
because, for infinite X, the cardinality of a free group on X is equal to that 
of X, but we shall only be interested in finite X in this book, so we omit the 
details. 
The cardinality |X| of X is known as the rank of a free group F on X. 
To prove existence, we need to construct a free group on a set X. For 
any set X, we define the set X-1 to be equal to {(x,-1) | x∈X}, but we shall 
write x-1 rather than (x, –1). For y=x-1∈X-1, we define y-1 to be equal to x. We 
define AX (or just A when X is understood) to be XX-1. 
DEFINITION 2.48 For a set A, we define A* to be the set of all strings 
x1x2…xr with each xi∈A. The number r is the length of the string, and for 
σ∈A*, we denote the length of σ by |σ|. The empty string over A of length 
0 is denoted by εA, or just by ε. 
Elements of A* are also known as words in A* or words over A. A subword 
or substring of w=x1… xr∈A* is the empty word, or any word of the form 
xixi+1…xj, with 1≤i≤j≤r. It is called a prefix of w if it is empty or i=1, and it is 
called a suffix of w if it is empty or j=r. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
35 
Let us fix our set X and set A=AX. Call two words v, w over A directly 
equivalent if one can be obtained from the other by insertion or deletion of 
a subword xx-1 with x∈A. For example, if X={x,y}, then xxx-1y and xy are 
directly equivalent, as are xy and y-1yxy. Let ~ be the equivalence relation 
on A* generated by direct equivalence. That is, for v,w∈A*, v~w if and only 
if there is a sequence v=v0,v1,…,vr=w of elements of A*, with r≥0, such that 
vi and vi+1 are directly equivalent for 0≤i<r. 
We denote the equivalence class of w∈A* under ~ by [w]. Let FX be the 
set of equivalence classes of ~. It is clear that u1~v1 and u2~v2 imply u1u2~v1v2 
so we can define a well-defined multiplication on FX by setting [u1][u2]=[u1u2] 
and, since the operation of concatenation of words is clearly associative, 
this multiplication is associative. Furthermore, [ε] is an identity element 
and [x1 x2 …xr] multiplied by 
 is equal to [ε], so FX is a group 
under this multiplication. 
THEOREM 2.49 For any set X, FX is a free group on the set [X]:={[x]|x∈X}, 
and the map x6[x] defines a bijection from X to [X]. 
PROOF Let F=FX and A=AX. Let G be a group and let ϕ:X→G be a map. 
We extend ϕ to a map ϕ:A*→G as follows. Let 
 where 
each xi∈X and i=±1, and let gi=ϕ(xi) for 1≤i≤r. Then we define 
 and of course ϕ(ε)=1G. Since v~w implies ϕ(v)=ϕ(w), 
ϕ induces a well-defined map θ:FX→G, which is clearly a homomorphism. 
To show that FX is free on [X], for a given map θ:[X]→G, we define 
ϕ:X→G by setting ϕ(x)=θ([x]), and then the map θ defined above is a 
homomorphism extending θ, and is clearly the unique such homomorphism. 
To show that the map x6[x] defines a bijection from X to [X], let G be 
any group with |G|≥|X|, and let ϕ:X→G be an injection. Then, since 
θ([x])=ϕ(x) for 
 must define a bijection, as claimed. 
It is customary to write w rather than [w] for elements of F:=FX, and we 
shall do that from now on. This renders the equality of words ambiguous. 
To resolve this, we shall always write w1=F w2 to mean that [w1]=[w2], 
whereas w1=w2 will mean that w1 and w2 are equal as words. The second 
part of Theorem 2.49 enables us to identify X with [X] in FX, which we 
shall do, and we shall also follow the custom of referring to FX as the free 
group on X. Since FX is generated by X, it follows from Proposition 2.47 
and Theorem 2.49 that any free group on X is generated by X. This can 
also be proved directly from the definition of a free group; see Exercise 1, 
below. 
A word in A* is called reduced, if it does not contain xx-1 as a substring 
for any x∈A. We have not used quite the same definition of free groups as 
that given in Chapter 1 of [Joh98], for example, which defines the elements 
of FX to be reduced words over A rather than equivalence classes of words. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
36 
We chose our definition because, as we shall see later in Chapter 12, it 
enables us to regard group presentations as a special case of monoid 
presentations. The following proposition shows that the two definitions 
are essentially the same. 
PROPOSITION 2.50 If X is any set, then each equivalence class in FX 
contains exactly one reduced word. 
PROOF Let ~x be defined as above. Since xx-1 ~x ε for all x∈A=AX, it is 
clear that each equivalence class contains a reduced word. Suppose that a 
class contains two distinct reduced words, u and v. Then there is a sequence 
u=u0, u1,…,ur=v of elements of A* such that ui and vi are directly equivalent 
for 0≤i<r. Choose this sequence to make the sum of the |ui| as small as 
possible. It is clear that directly equivalent elements of A* differ in length 
by two, and they cannot both be reduced words, so we must have r>1. 
Choose i such that |ui| is maximal. Then 0<i<r,|ui–1|=ui+1|=|ui|-2, and 
both ui–1 and ui+1 are derived from ui by deleting a substring of the form xx-1. If 
these two substrings of ui are disjoint, then we can reverse the order of the 
substitutions and obtain another sequence with |ui|=|ui–1|-2, contrary to 
the minimality condition on the sequence. On the other hand, if the two 
substrings xx-1 are not disjoint, then either they are equal, or they are the 
substrings xx-1, x-1x of a substring xx-1x of ui. In both of these cases, we 
have ui–1=ui+1, so we can shorten the sequence and again contradict its 
minimality condition. 
If w=x1 x2…xr∈A* then, for any i with 1≤i≤r, w is conjugate in FX to the 
cyclic permutation wi:=xixi+1…xrx1x2…xi–1 of w. The words w and wi are said 
to be cyclic conjugates of one another. The word w is said to be cyclically 
reduced if it is reduced and x1≠xr. This is equivalent to all of its cyclic 
conjugates being reduced words. Clearly every w is conjugate in F to a 
cyclically reduced word. 
2.4.2 Group presentations 
DEFINITION 2.51 Let X, A=AX be defined as above, and let R be a subset 
of A*. We define the group presentation 
 to be equal to the quotient 
group F/N, where F=FX is the free group on X, and N is the normal closure 
 of R in F. 
Informally, 
 is the ‘largest’ group G that is generated by X in which 
all of the strings v∈R represent the identity element. This idea is expressed 
more precisely by the universal property proved next. This property could 
be used as an alternative definition of a group presentation. 
Notice that this definition does not distinguish properly between the 
© 2005 by Chapman & Hall/CRC Press

Background Material 
37 
presentation itself, which can be thought of as just a set or sequence X 
together with a set R of words in A*, and the group G that is defined by the 
presentation. If we wish to emphasize this distinction, then we shall denote 
the presentation by {X|R}, and the group defined by it by 
. 
THEOREM 2.52 Let X be a set, let A=AX, let R be a subset of A*, and let G 
be a group. For any map θ:X→G, we extend θ to a map θ:A→G by putting 
θ(x-1)=θ(x)-1 for all x∈X. Suppose that θ:X→G is a map with the property 
that, for all w=x1…xr∈R, we have θ(x1)…θ(xr)=1G. Then there exists a unique 
group homomorphism 
 for which θ(xN)=θ(x) for all x∈X, 
where 
=F|N as in the definition above. 
Conversely, if there is a group homomorphism 
 for which 
θ(xN)=θ(x) for all x∈X, then we must have θ(x1)…θ(xr)=1G for all w=x1…xr∈R. 
PROOF Since 
 is generated by the elements xN for x∈X, the 
homomorphism θ is certainly unique if it exists. By the definition of the 
free group F=FX, there is a homomorphism θ:F→G with θ(x)=θ(x) for all 
x∈X. The hypothesis of the theorem then says that w∈ker(θ) for all w∈R, 
and hence N=(RF),≤ker(θ), and so θ induces a homomorphism 
 with the required property. 
Conversely, if θ exists as described, then we must have θ(wN)=θ(w) for 
all w∈F, and so θ(w)=1G for all w∈N. In particular, 
  
for all w=x1…xr∈R. 
We shall further abuse notation by using v to represent the image vN of v 
in 
 for v∈A*. We shall use u=G v to mean that u, v∈A* represent the 
same element of G. 
In general, if G is a group generated by a set X, A=AX, and w∈A* with 
w=G 1G, then we call the word w a relator of G. The elements of R in a 
group presentation 
 are clearly relators of G, and these are 
known as defining relators. If w1,w2∈G with w1=G w2, then we call w1=Gw2 
a relation in G. Of course, this is equivalent to w1w2
-1 being a relator of G. 
It is often convenient to write down group presentations in the alternative 
form 
 where R is a subset of A*×A*, but the element (w1, w2) 
of R is usually written as w1=w2. We formally define this group to be equal 
to 
, where the elements of R are obtained from those of R by 
replacing 
. The elements of R are called defining 
relations of G. 
For example, the group 
, which is dihedral of order 6, 
could be written as 
. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
38 
If the hypotheses of Theorem 2.52 are satisfied and the resulting map 
 
 is an isomorphism, then we often, in practice, identify the 
set X with its image in G under θ, and say that 
 is a presentation of 
G on the generators X of G. For example, if 
, 
then we might say that 
 is a 
presentation of G on the generators x=(1,2), y=(1, 2, 3) of G. 
Using that slight abuse of notation, we can formulate the following version 
of Theorem 2.52, which is computationally useful for testing whether a 
map ϕ from a group G to a group H is a homomorphism. 
THEOREM 2.53 Let 
 be a presentation of a group G, and let θ:X→H 
be a map from X to a group H. Extend θ to θ:X-1→H by putting θ(x-1)=θ(x)-1 
for all x∈X. 
Then θ extends to a homomorphism θ:G→H if and only θ(x1)…θ(xr)=1H 
for all w=x1…xr∈R. This extension is unique if it exists. 
PROOF The uniqueness of the extension follows from the fact that X 
generates G. The statement that 
 is a presentation of a group G 
really means that there is an isomorphism 
, and that we 
are identifying 
 with its image under ϕ. Similarly, the statement 
θ(x1)…θ(xr)=1H for all w=x1…xr∈R means θ(ϕ(x1))…θ(ϕ(xr))=1H for all for all 
w=x1…xr∈R. By Theorem 2.52, this is true if and only if θϕ extends to a 
homomorphism 
. Since ϕ is an isomorphism, the 
existence of ψ is equivalent to the existence of the required homomorphism 
ψϕ-1:G→H. 
2.4.3 Presentations of group extensions 
DEFINITION 2.54 A group G with a normal subgroup N is called a (group) 
extension of N by G/N. It is called a split extension if there is a subgroup 
C of G with NC=G and NC=1. In that case, C is called a complement of N 
in G/N. 
Suppose that the group G has a normal subgroup N, and that we have 
presentations 
 of N and 
 of G/N on generating sets Y and , 
respectively. Here we shall describe a general recipe for constructing a 
presentation of G as an extension of N by G/N. 
For each 
 choose x∈G with 
 and let 
  
Then, for any word 
, we can define 
 with 
, by substituting x or x-1 for each 
 occurring in 
© 2005 by Chapman & Hall/CRC Press

Background Material 
39 
In particular, for each 
 there is a corresponding word r, and then 
 implies that r∈N, so in the group G we have r=G wr, for some 
word wr∈(YY-1)*. Let R be the set 
. 
For each y∈Y and x∈X, we have x-1yx∈N, so x-1yx=G wxy for some word 
wxy∈(YY-1)*. Let T be the set 
. 
PROPOSITION 2.55 With the above notation, 
 is a 
presentation of G. 
PROOF Let F be the group defined by the above presentation. To avoid 
confusion, let us denote the generators of F mapping onto x∈X or y∈Y by 
and  respectively. We have chosen the sets R, S, T to be words that evaluate 
to the identity in G, so Theorem 2.52 tells us that the mapping  →x, →y 
induces a homomorphism θ:F→G. In fact θ is an epimorphism, because 
clearly G is generated by XY. 
Let K be the subgroup 
 of F. Then θ(K)=N. Since, by 
assumption, 
 is a presentation of N, and the relators of S are also 
relators of K, Theorem 2.52 implies that the map y→ induces a 
homomorphism N→K. But this homomorphism is then an inverse to θK, so 
θK:K→N is an isomorphism. 
We now wish to assert that the relators in T imply that 
. This is 
not quite as clear as it may at first sight appear! For it to be clear, we 
would need to know that 
 for all x∈X, y∈Y, in addition to 
. But the fact that N G tells us that each x∈X induces an 
automorphism of N by conjugation, which implies that, for each x∈X, we 
have 
 Since N is isomorphic to K via θK, the 
corresponding statement is true in K for each . So the fact that 
conjugates each word wxy into K implies the desired property 
for all x∈X, y∈Y. 
So we do indeed have K F. Now, by a similar argument to the one above 
for θK, the fact that 
 is a presentation of G/N implies that the induced 
homomorphism θF/K:F/K→G/N is an isomorphism. So, if g∈ker(θ), then 
gK∈ker(θF/K) implies that g∈K, but then g∈ker(θK)=1, so θ is an 
isomorphism, which proves the result. 
In the special case of a split extension, we can choose our inverse images x 
of  to lie in a complement of N in G, in which case we get wr=1 for all r∈R. 
In the even more special case of trivial action of the complement on N, we 
have a direct product, and we get the following well-known result as a 
corollary. 
COROLLARY 2.56 Let 
 and 
 be presentations of groups G 
and H. Then 
 is a presentation of G×H, where T={[x,y] 
|x∈X, y∈Y}. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
40 
2.4.4 Tietze transformations 
There are a number of simple manipulations of a group presentation that 
do not change the group or at least the isomorphism class of the group 
defined by the presentation. These are known as Tietze transformations of 
the presentation. There are four of these, which come in mutually-inverse 
pairs. As before, we denote XX-1 by A. 
TT1 Adjoin an extra relator in 
 to R; 
TT2 Remove a redundant relator w from R where 
; 
TT3 For any word w∈A*, adjoin an extra element x, not already in X, to X, 
and adjoin the element wx-1 to R. 
TT4 If there is a generator x∈X and a relator w∈R such that there is 
exactly one occurrence of x or x-1 in w, and neither x nor x-1 occurs in 
any v∈R\{w}, then remove x from X and w from R. 
It is almost obvious that transformations of type (i) or (ii) do not change the 
group defined by the presentation, and it is not hard to prove that (iii) and 
(iv) replace this group by an isomorphic group. We leave this as an exercise 
for the reader, who could alternatively refer to [Joh98]. 
There are some combinations of these transformations that are used 
very frequently, and we shall mention a few of these here. 
We can always replace a relator in a presentation by its inverse or by a 
conjugate of itself. This is immediately clear from the definition of a group 
presentation, but it could also be regarded as an application of TT1 followed 
by TT2. We shall feel free to carry out such replacements without comment. 
In particular, we often need to replace a relator x1 x2 …xr by a cyclic 
conjugate. This facility also enables us to assume that defining relators are 
cyclically reduced words. 
A slightly less trivial instance is when we have two relators uv,uw∈R, 
where u,v,w∈A* and u≠ε. The common substring u is called a piece. If G=F/N 
as before, then uv, uw∈N implies v-1w∈N, and so we can apply TT1 to adjoin 
v-1w to R. But uv, v-1w∈N implies uw∈N, so we can apply TT2 to remove uw 
from R. The combined effect is to replace uw by v-1w. Let us call this 
combination a common substring replacement. In practical applications, we 
might want to do this if |v-1w|<|uw|, because this shortens the presentation. 
Since we can always replace relators by cyclic conjugates, we can apply common 
substring replacement whenever two elements of R have a common substring 
u, regardless of whether or not u is a prefix of the relators. 
TT4 is more useful when applied in combination with common substring 
replacement. Suppose that we have x∈X and w∈R such that there is exactly 
one occurrence of x or x-1 in w. By replacing r by its inverse and a cyclic 
conjugate if necessary, we can assume that w=xv, where v does not contain 
x or x-1. If there are occurrences of x or x-1 in any other relators in R, then 
© 2005 by Chapman & Hall/CRC Press

Background Material 
41 
we can apply common substring replacements to replace them by v-1 or v, 
thereby eliminating them. We can then apply TT4 and eliminate x from X 
and w from R. We shall refer to this combination of transformations as 
eliminating a generator. One practical problem with doing this is that if v is 
long, then the common substring replacements may render the total relator 
length of the presentation considerably greater than it was before the 
elimination. 
Exercise 
1. 
Prove from the definition of a free group F on a set X that F is generated 
by X. 
2.5 Presentations of subgroups 
Let G be a group generated by a set X, and let A=XX-1. Then G≅F/N for 
some N, where F=FX is the free group on X, and we shall assume that 
G=F/N. Let H=E/N be a subgroup of G, and let T be a set of reduced 
words in A* that form a right transversal of E in F. We shall always assume 
that T contains the empty word ε as the representative of the coset E. 
Hence the images of T in G form a right transversal of H in G. For a word 
w∈A*, we denote the unique element of TEw by . 
2.5.1 Subgroup presentations on Schreier generators 
Let w=x1y2…xr∈A* and, for 0≤i≤r, let 
 where t0=ε. Then we 
have 
(*) 
Define the subset  of E by 
  
Note that the final condition 
 simply has the effect of omitting 
the identity element from . If x∈X, t∈T, and 
, then 
, so 
, which is an element of 
-1 (unless it 
equals 1E). Since 
 for 1≤i≤r, we see that each of the bracketed 
terms 
 in the equation (*) is either equal to 1E, or is an element of 
. If w represents an element of H, then 
, and so we have: 
THEOREM 2.57 (Schreier) The subgroup E of F is generated by . Similarly 
the subgroup H of G is generated by the images of  in G. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
42 
The set  is called the set of Schreier generators of E with respect to the 
group F. 
We now let Y be a set of new symbols corresponding to , where we 
denote the element of Y corresponding to 
 by ytx. To ease the 
notation, we will let ytx denote the empty string ε when 
 The map 
ϕ:Y→F defined by 
 extends to a homomorphism from the 
free group FY on Y to F, and the theorem above says that im(ϕ)=E. For t∈T, 
x∈X, we denote the element of Y-1 that ϕ maps to 
 by ytx-1. 
We define a map ρ:A*→FY by 
  
where w=x1x2…xr, as in the equation (*) above. Of course, ρ and ϕ depend 
on the choice of the transversal T. It is straightforward to check that 
ρ(uxx-1v)=FY ρ(uv) for any u,v∈A*, x∈A, and so ρ induces a well-defined 
map, also denoted by ρ, from F to FY. This map is called a rewriting map. 
More generally, for t∈T and w=x1x2…xr∈A*, we define ρ(t, w) in the 
same way as for ρ(w), but with t0=t; that is, 
  
where 
. 
LEMMA 2.58 (i) 
 for all u, v∈A*. 
(ii) 
 for all u∈A*. 
PROOF (i) is clear from writing down the definition of ρ(uv). For (ii), note 
that ρ(uu-1)=FY 1FY and use (i).
It follows from (i) of this lemma that, if u∈E, then =ε and ρ(uv)=ρ(u)ρ(v), 
so ρ restricts to a homomorphism from E to FY. 
The transversal T is called a Schreier transversal if it is prefix-closed; 
that is, if all prefixes of all elements of T lie in T. To prove that Schreier 
transversals exist, let < be a well-ordering of A* with the property that 
 for all u, v, w∈A*, and choose the elements of T to be the 
least elements of their cosets under this ordering (see the exercises 
below). Examples of orderings of A* with this property are shortlex 
orderings, which are defined below. They are defined with respect to a 
given well-ordering of A and so, if we assume the axiom of choice, then 
they exist for all sets A; but in this book, we are only concerned with finite 
sets A. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
43 
DEFINITION 2.59 Let < be a given well-ordering of a set A. Then, the 
associated lexicographical (dictionary) ordering <L of A*, is defined by 
a1a2…am < b1b2…bn (with ai,bj ∈ A) if, for some k≥0, ai=bi for 1≤i≤k, and 
either k=m<n or ak+1<bk+1. 
The lexicographical ordering satisfies the 
 property, but 
it is not a well-ordering for |A|>1 because, if a, b ∈ A with a>b, then 
 for all i≥0. The shortlex ordering, however, which we shall 
now define, is a well-ordering. 
DEFINITION 2.60 Let < be a given well-ordering of a set A. Then, the 
associated shortlex (also called lenlex) ordering <s of A* is defined by u<s v 
if either |u|<|v|, or if |u|=|v| and u<L v. 
If T is a Schreier transversal and w=t ∈ T, then all of the bracketed terms 
in the equation (*) are equal to 1E, and so ρ(t)=ε. If w=tx with t ∈ T, 
 then all of the bracketed terms are trivial except for 
the last, and so ρ(tx)=ytx and, using Lemma 2.58, we have 
  
So the composite ρϕ is equal to the identity homomorphism on FY. But this 
implies that ϕ is a monomorphism, so we have proved the well-known 
Nielsen-Schreier theorem: 
THEOREM 2.61 If T is Schreier transversal, then the subgroup E of F is a 
free group on the generating set . 
Now suppose that 
 is a presentation of G, and G=F/N with 
. The following theorem will be used later, in Subsection 5.3.1, in 
an algorithm to compute a presentation of the subgroup H of G. 
THEOREM 2.62 Assume that T is a Schreier transversal of E in F, and 
define S:={ρ(twt-1) | t∈T, w∈R}. Then the group H′:=〈Y|S〉 is isomorphic to 
H, and an isomorphism is induced by the map ϕ:FY → E defined above. 
PROOF We saw above that ϕ and ρ|E are inverse isomorphisms. Since 
each twt-1 with t∈T, w∈R lies in N≤E, we have ϕρ(twt-1)=F twt-1 ∈ N, and so 
by Theorem 2.52 ϕ induces an epimorphism  from H to H. 
Now 
 is generated by conjugates uwu-1 of elements w∈R by 
elements u∈A*. For any such u, we have u=F vt, with v∈E and t∈T, and 
then uwu-1=F v(twt-1) v-1 and so 
 is a 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
44 
conjugate of an element of S. It follows that 
 for all z∈N, and 
hence ρ|E induces a homomorphism ρ−:H=E/N→H′. 
We saw above that ρϕ is the identity homomorphism on FY, and 
hence 
 is the identity on H. So ϕ– is an isomorphism, which proves 
the result. 
As a final observation on the above theorem, note that by Lemma 2.58 
we can express the elements ρ(twt-1) of S as 
  
We saw earlier that the fact that T is a Schreier transversal implies that 
ρ(t)=ε, so in fact we have 
  
This form of S is more convenient for use in the algorithm in Subsection 
5.3.1 for computing subgroup presentations. 
2.5.2 Subgroup presentations on a general 
generating set 
We shall now describe a generalization of the results in Subsection 2.5.1, 
which can be used to find a presentation of a subgroup on a given generating 
set, rather than on the set of Schreier generators. This subsection could be 
omitted on a first reading. 
As before, we assume that 
 and G=F/N with F=FX and 
 and that H=E/N is a subgroup of G. Let T be any right transversal 
of E in F (not necessarily a Schreier transversal) consisting of reduced 
words and containing ε and, as before, denote the unique element of T  
Ew by   for w∈A*. Let Y be a set disjoint from X, and suppose that we 
have an epimorphism ϕ:FY → E, and that, for t∈T and x∈X, we are given 
elements ytx ∈ FY satisfying 
 for all t∈T, x∈X. Note that these 
conditions are satisfied by the ϕ and ytx defined in Subsection 2.5.1. For 
t∈T, x ∈ X, we use ytx-1 to denote the inverse of the element yux of FY that 
satisfies ux=G ϕ(yux)t. We define the rewriting map ρ:A* → FY exactly as 
before: for any w∈A*, we put 
  
where w=x1x2…xr as in the equation (*) in Subsection 2.5.1. 
Again the images of equivalent words under ρ are equal, so we can think 
of ρ as mapping F to FY, and Lemma 2.58 is true as before, so again ρ|E is 
a homomorphism. In Subsection 2.5.1, we had 
for all ytx ∈ Y, but this is no longer necessarily the case. So, in Theorem 
2.62, the relators in the set S2 in the theorem below freely reduce to the 
empty word, and can be omitted. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
45 
THEOREM 2.63 With the notation just defined, let S1:={ρ(twt—1)|t∈T, 
w∈R}, and let S2:={ρϕ(y)y1|y ∈ Y}. Then the group H:=  with S=S1  S2 
is isomorphic to H, and an isomorphism is induced by the map ϕ:FY→E. 
PROOF Let w=x1x2…xr ∈ A* and 
 with the ti 
defined as in the equation (*). Since 
 our 
assumption 
 tells us that 
 for 1 ≤i≤r, 
and so we have 
  
In particular, if w∈E, then ϕρ(w)=Gw. From this equation, it follows that 
ϕ(s)∈N for all s∈S1  S2 and so ϕ induces a epimorphism 
. 
It follows exactly as in Theorem 2.62 that ρ|E induces a homomorphism 
 The inclusion of S2 in the set of relators of H ensures 
that ρ(ϕ(y))=H y for all y∈Y, and so 
 is the identity on H, and hence  is 
an isomorphism, which proves the result. 
As in the final paragraph of Subsection 2.5.1, the element ρ(twt-1) of S1 is 
equal to ρ(t)ρ(t, w)ρ(t)-1 in FY. It is no longer necessarily true that ρ(t)=ε, 
but since ρ(t)ρ(t, w)ρ(t)-1 is a conjugate of ρ(t, w), the theorem still remains 
true if we replace S1 by 
  
Exercises 
1. 
Show that the transversal T of E in F defined as the set of least elements 
in their cosets under a well-ordering of A* satisfying 
for all w∈A* is indeed a Schreier transversal. 
2. 
Show that the shortlex ordering <s of A* associated with a given well- 
ordering < of A is a well-ordering and satisfies u<v⇒vw and wu<wv for 
all w∈A*. 
3. 
Let A={x, x-1, y, y-1} and write down the first 20 elements of A* in the 
shortlex ordering of A* defined with respect to the ordering x<y<y-1<x-1 
of A. 
4. 
Show that the normal closure of the subgroup 
 of the free group on 
{x, y} is free on 
. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
46 
2.6 Abelian group presentations 
The theory that we have just developed for group presentations can be 
recast in the framework of abelian groups rather than general groups, 
but much of the material becomes significantly easier in the abelian case. 
In particular, a free abelian group is just a direct sum of copies of an 
infinite cyclic group. We shall quickly run through this basic theory here. 
We shall, however, delay our treatment of the structure theorem for 
finitely generated abelian groups until Section 9.2, because it is more 
convenient to discuss this at the same time as we describe the related 
algorithms. 
DEFINITION 2.64 An abelian group Fab is free abelian on the subset X of 
Fab if, for any abelian group G and any map θ:X→G, there is a unique group 
homomorphism θ′: Fab→G with θ(x)= θ(x) for all x∈X. The set X is known 
as a free basis of Fab. 
Again it follows directly from the definition that any abelian group generated 
by a set X is an epimorphic image of, and hence isomorphic to a quotient of, 
a free abelian group on X. 
Exactly as in Proposition 2.47, we can show that free abelian groups on 
X1 and X2 are isomorphic if and only if |X1|=|X2|, and we call |X| the rank 
of a free abelian group on X. 
We generally prefer to use additive rather than multiplicative notation 
when discussing abelian groups, and we shall do so here. 
For an arbitrary set X, we define 
 to be the direct sum 
 of 
infinite cyclic groups 
 generated by x. As usual, we identify the groups 
with the corresponding component subgroups of the direct sum, and so an 
element 
 has the form 
 where all but finitely 
many of the x are zero. (In this book, X will virtually always be finite, but 
there is no reason not to consider general X at this stage.) 
Many books define the free abelian group on X to be the group 
 and 
we shall now show that this is equivalent to our definition. 
PROPOSITION 2.65 If X is a set, then the group 
 is free abelian on X. 
PROOF For an abelian group G and a map θ:X→G, we define 
 where 
 with all 
but finitely many of the x equal to zero. It is easy to see that θ is a 
homomorphism extending θ. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
47 
It follows that a finitely generated free abelian group is isomorphic to 
for some 
 and we shall generally use 
 as our prototype free abelian 
group. Similarly, any finitely generated abelian group with n generators is 
isomorphic to a quotient group of 
. 
There is an alternative construction of the free abelian group on X as an 
ordinary group presentation. For a set X, we define [X, X] to be the set of 
formal commutators 
  
This is a subset of the set 
 of words over AX, where 
PROPOSITION 2.66 If F is a free group on a set X, then 
 is a 
free abelian group on X. 
PROOF Let θ:X→G be a map, with G an abelian group. By the definition 
of the free group on X, θ extends to a homomorphism θ:F→X. Since G is 
abelian, [X, X] and hence 
 is contained in the kernel of θ, 
so θ induces a homomorphism 
, and the result 
follows. 
We can now define an abelian group presentation. 
DEFINITION 2.67 Let X be a set, let R be a subset of 
 and let N be the 
subgroup of 
 generated by R. Then the abelian group presentation 
 is defined to be equal to the quotient group 
. 
The analogous result to Theorem 2.52 holds for presentations of abelian 
groups, but it is not used so frequently as Theorem 2.52 itself. 
Next we relate abelian group presentations to the abelianizations of 
ordinary group presentations. For a set of words 
 we let R+ denote 
the corresponding set of elements of 
 obtained by writing each element 
of R additively. So, for example, if R={x2yx-1y3x4, y3x-4xy}, then R+={5x+4y, – 
3x+4y}. 
PROPOSITION 2.68 Let 
 be a group presentation. Then 
(i) 
 and 
(ii) 
. 
PROOF Let F be the free group on X. Then G=F/N with 
, and 
 with M=〈(R∪[X,X])F〉. Since each pair of generators 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
48 
commutes in F/M, F/M is abelian, and so (F/N)/(M/N) 
 F/M is an 
abelian quotient of G and hence [G, G] ≤ M/N. But M = 
, 
where 
, so M/N is generated by commutators, and hence [G, 
G] = M/N, which proves (i). 
By Proposition 2.66, F/L is a free abelian group on the set X, and so F/ 
M  (F/L)/(M/L). An element of RF has the form uw for u∈R, w∈F, and 
uw=u[u,w] with [u,w] ∈ [F, F] ⊂ L (since F/L is abelian), so M/L=NL/L is 
generated by the images of the elements u∈R, which proves (ii). 
Exercise 3 in Section 2.5 shows that subgroups of finitely generated groups 
are not themselves finitely generated in general. The following result shows 
that this property does hold for finitely generated abelian groups, from 
which it follows that all finitely generated abelian groups have finite abelian 
group presentations. 
PROPOSITION 2.69 Any subgroup H of a finitely generated abelian group 
G is finitely generated. 
PROOF Let G be generated by x1, …, xn. We use induction on n, the result 
being clear for n=0. Let K:=〈x2, …, xn〉. By induction, K∩H is finitely 
generated, whereas 
 is cyclic, and hence finitely 
generated. The result follows. 
2.7 Representation theory, modules, extensions, 
derivations, and complements 
This section concerns group representation theory, together with the basic 
theory of group extensions of M by G in the case when M is abelian. 
Computation with group representations is a significant subtopic within 
CGT. Some of the methods in this area, particularly those related to group 
representation theory for its own sake involve some rather advanced theory. 
Even for computations that are concerned only with the group-theoretical 
structure of finite groups, some of the more sophisticated algorithms require 
some familiarity with representation theory. 
The basic reason for this is that if a finite group G has normal subgroups 
N<M for which M/N is an elementary abelian p-group for some prime p, 
then the conjugation action of G on M gives rise to a representation of G/ 
M over the field of order p, and properties of that representation translate 
into group-theoretical properties of G. For example, the representation is 
irreducible if and only if M/N is a chief factor of G. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
49 
In this book, mainly in Chapter 7, we shall attempt to cover only those 
parts of computational representation theory that have applications to the 
analysis of the structure of finite groups. This does not require that the 
reader have a very deep knowledge of representation theory, but it does 
involve certain topics that are not always covered by the most elementary 
books on the subject, such as representations over finite fields rather than 
over  so it is not easy to find references at the appropriate level. Two 
possibilities are the books by Isaacs [Isa76] and Rotman [Rot02], which we 
shall use here for references to theoretical results. 
2.7.1 The terminology of representation theory 
Let us briefly review the basic definitions and results from the representation 
theory of finite groups. Let K be a commutative ring with 1, and let G be a 
finite group. The group ring KG of G over K is defined to be the ring of 
formal sums 
  
with the obvious addition and multiplication inherited from that of G. In 
fact KG is an associative algebra with 1 and thus it is a ring with 1 and a 
module over K. It is also known as the group algebra of G over K. 
Let M be a right (unital) KG-module. We shall write m.x (m∈M, x∈KG) 
to represent the module product in M, but when x∈K and we are thinking 
of M primarily as a K-module, then we may write xm rather than m.x. 
Since K is commutative, this does not cause any problems. From the module 
axioms, and the fact that (m.g).g-1=m for m∈M, g∈G, we see that 
multiplication by a group element g∈G defines an automorphism of M as a 
K-module. So we have an associated action ϕ:G→AutK(M), and we shall 
sometimes use the group action notation mg as an alternative to m.g. 
Conversely, if M is a K-module, then any action ϕ:G→AutK(M) can be used 
to make M into an KG-module. 
We shall always assume that M is finitely generated and free as a K- 
module, and so, after fixing on a free basis of M, we can identify M with Kd 
for some d. Then, using the same free basis of M, AutK(M) can be identified 
with the group GL(d, K) of invertible d×d matrices over K. So the action 
homomorphism ϕ is ϕ:G→GL(d, K), which is the standard definition of a 
representation of G of degree d over K. 
According to basic results from representation theory, two KG-modules 
are isomorphic if and only if the associated representations ϕ1, ϕ2 are 
equivalent, which means that they have the same degree and there exists 
∈GL(d, K) with .ϕ2(g)=ϕ1(g). for all g∈G. 
When K is a field, a KG-module and its associated representation is 
called simple or irreducible if it has no proper nonzero KG-submodules. (A 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
50 
slightly different definition of irreducibility is normally used when 
for example.) 
Since we are dealing only with finite-dimensional modules, any such 
module M has a composition series, (that is, an ascending series of submodules 
with simple factor modules), and the Jordan-Hölder theorem (Thereom 8.18 
of [Rot02]) asserts that any two such series have isomorphic factors, counting 
multiplicity, and so we can refer to the composition factors of M. 
For any KG-module M, we can define the K-algebra EndKG(M) of 
endomorphisms of M (= KG-homomorphisms from M to M). This is also 
known as the centralizing algebra of M and its associated representation. It 
contains the scalar automorphisms, which form a subalgebra isomorphic 
to K. When K is a field and M is a simple KG-module, then Schur’s lemma 
(Theorem 8.52 [Rot02] or Lemma 1.5 of [Isa76]) says that EndKG(M) is division 
ring. This can be noncommutative in general, but in this book we shall be 
particularly concerned with the case when K is a finite field, in which case 
a well-known theorem of Wedderburn (Theorem 8.23 of [Rot02]) tells us 
that EndKG(M) is a field, and it can be regarded as an extension field of K. 
When K is a field, the KG-module M is called absolutely irreducible if it 
is irreducible and remains irreducible when regarded as an LG-module for 
any extension field L of K. By Theorem 9.2 of [Isa76], M is absolutely 
irreducible if and only if EndKG (M) consists of scalars only. 
So, if K is a finite field and L=EndKG (M), then we can use the action of L 
on M to make M into an LG-module with dimL(M)|L:K|=dimK(M), and M is 
absolutely irreducible as an LG-module. In particular, there is a finite 
extension L of K for which all irreducible LG-modules are absolutely 
irreducible, and such an L is called a splitting field for G. 
2.7.2 Semidirect products, complements, derivations, 
and first cohomology groups 
This and the following subsection contain a very brief description of the 
first and second cohomology groups of groups acting on modules, insofar as 
they are relevant to the (computational) study of group extensions. For a 
more complete treatment, the reader may consult Chapter 10 of [Rot02], 
particularly Sections 10.2 and 10.3. But, in common with the majority of 
published material on this topic, the account in [Rot02] is in terms of left 
modules, whereas ours uses right modules, so there will be some differences, 
such as in the definitions of cocycles. 
We defined the notion of a (split) extension of one group by another in 
Subsection 2.54. Let G and M be groups, and suppose that we are given a 
homomorphism ϕ:G→Aut(M). We define the semidirect product of M by G 
using ϕ to be the set G×M endowed with the multiplication (g, m)(h, n)= 
(gh, mhn), for g, h∈G, m, n∈M, where, as usual, mh is an abbreviation for 
mϕ(h) The standard notation for a semidirect product is 
 or 
. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
51 
The semidirect product is an extension of M by G, using the maps 
 defined by 
 It is a split 
extension, with complement {(g, 1M)|g∈G}. 
Conversely, if the group E has a normal subgroup M with a complement 
G then any e∈E can be written uniquely as e=gm for g∈G, m∈M, and 
gmhn=ghmhn, so we have: 
PROPOSITION 2.70 Any split extension E of M by G is isomorphic to the 
semidirect product 
 where the action ϕ of G on M is defined by the 
conjugation action of a complement of M in E on M. 
In general, different complements could give rise to different actions ϕ. 
However, if M is abelian, then the actions coming from different 
complements are the same. We shall assume for the remainder of this 
subsection that M is abelian and use additive notation for M. 
We shall also assume that M is a K-module for some commutative ring 
K with 1. This is no loss of generality, because any abelian group can be 
regarded as a ]-module just by defining n.m=nm for n∈], m∈M. In the 
case when M is an elementary abelian p-group, we can take K to be the 
field . 
As we saw in Subsection 2.7.1, an action ϕ:G→AutK(M) of G on the K- 
module M corresponds to endowing M with the structure of a KG-module, 
and so we can talk about the semidirect product 
 of the 
KG-module M with G. The multiplication rule in 
, using additive 
notation in M, is (g, m)(h, n)=(gh, mh+n). 
A general left transversal of the subgroup 
isomorphic to M in 
 has the form T={(g(g)) | g∈G}, for a map :G→M. 
Then T is a complement of 
 in 
 if and only if (g, (g)) (h, 
(h))=(gh,(gh)) for all g, h∈G or, equivalently, 
(†) 
If M is a KG-module, then a map :G→M is called a derivation or a crossed 
homomorphism or a 1-cocycle if (†) holds. Notice that by putting h=1G in 
(†), we see that (1G)=0M for any derivation . 
We denote the set of such derivations by Z1(G, M). By using the obvious 
pointwise addition and scalar multiplication, we can make Z1(G, M) into a 
K-module. We have proved: 
PROPOSITION 2.71 If M is a KG-module, then the set T defined above is 
a complement of 
 in 
 if and only if ∈Z1(G, M). 
Notice that for a fixed m∈M, {(g, 0M)(1,m)=(g, m–mg)|g∈G} is a complement 
of 
 in 
, and so 
 is a derivation. Such a map is called a 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
52 
principal derivation or 1-coboundary. The set of all principal derivations is 
denoted by B1(G, M) and forms a K-submodule of Z1(G, M). 
DEFINITION 2.72 The first cohomology group H1 (G, M) is the quotient 
K-module Z1(G, M)/B1(G, M). 
From the discussion above, it follows that H1 (G, M) is in one-one 
correspondence with the set of conjugacy classes of complements of 
 in 
The following result tells us that derivations are uniquely determined 
by their action on a generating set of a group. 
PROPOSITION 2.73 Suppose that 
 and let  : X → M be a map. If 
 extends to a derivation :G→M, then: 
 (i) 
 for all x∈X. 
(ii) Let g∈G with 
 where each εi=±1. Then 
  
where 
 when εi=1 or –1; respectively. 
PROOF By (†), we have 
 which proves (i). 
(ii) is proved by repeated use of (†). 
In general, given any map :X→M, we can use (i) and (ii) of the above proposition 
to extend  to a derivation FX→M, where FX is the free group on X. 
2.7.3 Extensions of modules and the second 
cohomology group 
Let E be any extension of an abelian group M (regarded as subgroup of E) 
by a group G. So we have an epimorphism ρ : E → G with kernel M. For 
g∈G, choose ∈E with ρ( )=g and, for m∈M, define 
 Since M is 
abelian, this definition is independent of the choice of gl, and it defines an 
action of G on M. In general, this action makes M into a ]G-module, but if 
M happens to be a module over a commutative ring K with 1, and the 
conjugation actions of g∈G define K-automorphisms of M, then M becomes 
a KG-module. In particular, this is true with 
 in the case when M is 
an elementary abelian p-group. 
DEFINITION 2.74 Let G be a group and M a KG-module for some 
commutative ring K. We define a KG-module extension of M by G to be a 
© 2005 by Chapman & Hall/CRC Press

Background Material 
53 
group extension E of M by G in which the given KG-module M is the same 
as the KG-module defined as above by conjugation within E. 
Given E as above, the elements { |g∈G} form a transversal of M in G. For 
g, h∈G, we have 
 for some function :G×G→M, where the 
associative law in E implies that, for all g, h, κ∈G, 
  
A function :G×G→M satisfying this identity is called a 2-cocycle, and the 
additive group of such functions forms a K-module and is denoted by Z2(G, 
M). 
Conversely, it is straightforward to check that, for any ∈Z2(G, M), the 
group E={(g, m) g∈G, m∈M} with multiplication defined by 
  
is a KG-module extension of M by G that defines the 2-cocycle  when we 
choose =(g, 0). 
A general transversal of M in E has the form =(g, (g)) fora function 
:G→M, and it can be checked that this transversal defines the 2-cocycle 
+cx, where c is defined by c(g, h)=(gh)–(g)h-(h). A 2-cocycle of the form 
c for a function :G→M is called a 2-coboundary, and the additive group of 
such functions is a K-module and is denoted by B2(G, M). 
Two KG-module extensions E1 and E2 of a KG-module M by G are said 
to be equivalent if there is an isomorphism from E1 to E2 that maps M1 to 
M2 and induces the identity map on both M and on G. From the above 
discussion, it is not difficult to show that the extensions corresponding to 
the 2-cocycles 1 and 2 are equivalent if and only if 1-2 ∈ B2 (G, M) and, 
in particular, an extension E splits if and only if its corresponding 2-cocycle 
 ∈ B2(G, M). 
DEFINITION 2.75 The second cohomology group H2(G, M) is the quotient 
K-module Z2(G, M)/B2(G, M). 
So H2(G, M) is in one-one correspondence with the equivalence classes of 
KG-module extensions of M by G. 
Checking directly whether a given 2-cocycle is a 2-coboundary can be 
difficult, but there is an alternative approach to deciding whether a KG- 
module extension E splits, which we shall now describe. 
Suppose that we have a finite presentation 
 of G, and let us identify 
G with the group F/N defined by the presentation, where F is the free 
group on X and 
. For each x∈X, choose an element 
 with 
 Then there is a unique homomorphism θ:F→E with 
 for 
all x∈X and, since ρθ(x)=G x, ρθ is the natural map from F to G. Hence 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
54 
ker(ρθ)=N. It follows that ker(θ)≤N in any case and, by Theorem 2.52, 
ker(θ)=N if and only if θ induces 
 in which case 
 is an 
isomorphism and 
 is a complement of M in E. 
Furthermore, ker(θ)=N if and only if θ(w)=1E for all w∈R, so we have proved 
the following lemma. 
LEMMA 2.76 If 
 are chosen with 
 and θ:F→E is defined by 
 then the elements  generate a complement of M in E if and only if 
θ(w)=1E for all w∈R. 
The elements θ(w) for w∈R always lie in ker(ρ)=M. Let 
 
be another choice of the inverse images of x under ρ, where :X→M is a 
map, and let θ:F → E be the associated homomorphism with 
. If we use (i) and (ii) of Proposition 2.73 to extend  to  
: F → M, then a simple calculation shows that θ(w)=θ(w)(w) for all w∈R. 
Since the elements in these equations all lie in M, we can switch to additive 
notation and write them as θ(w)=θ(w)+(w). So we have the following 
result. 
PROPOSITION 2.77 With the above notation, the elements 
 
generate a complement of M in E if and only if (w)= -θ(w) for all w∈R. 
We shall use this result later, in Section 7.6, to help us determine 
computationally whether an extension splits. 
In particular, from the case 
 and 
 for all x∈X, 
Proposition 2.71 yields: 
THEOREM 2.78 If M is a KG-module with 
 then a map :X→M 
extends to a derivation G→M if and only if (w)=0M for all w∈R, where 
:F→M is defined by (i) and (ii) of Proposition 2.73. 
This last result is the analogue of Theorem 2.52 for derivations. It can of 
course be proved directly from the definition of derivations, without involving 
semidirect products. It will be used later in Section 7.6 to help us to compute 
Z1(G, M). 
2.7.4 The actions of automorphisms on cohomology 
groups 
Two KG-module extensions E1 and E2 of M by G can be isomorphic as groups 
without being equivalent as extensions. This remains true even if we 
restrict our attention to isomorphisms that map M to M. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
55 
Example 2.8 
Let 
 with G acting trivially on M. It is 
not difficult to check that there are eight equivalence classes of extensions 
of M by G (in fact H2(G, M)≅C2×C2×C2), in which each of x2, y2 and [x, y] can 
be equal to 1M or t. However, there are only four isomorphism classes of 
groups E that arise, namely C2×C2×C2, C4×C2, D8, and Q8. 
Suppose that :E1→E2 is a group isomorphism mapping M to M, and inducing 
µ ∈ AutK(M). Then, since E1/M  E2/M  G,  also induces v∈Aut(G). We 
have 
 for all m∈M, g∈G, because both expressions result from 
applying α to -1m , where ∈E1 maps onto g∈G. 
DEFINITION 2.79 Let M be a KG-module. If µ∈AutK(M) and v∈Aut(G) are 
isomorphisms satisfying 
 for all m∈M and g∈G, then (v, µ) is 
called a compatible pair. 
This expression was introduced by Robinson [Rob81]. It was first used in 
computational group theory by M.J.Smith in Section 4.2 of [Smi94], in 
connection with the computation of the automorphism groups of solvable 
groups; we shall return to that theme in Section 8.9. 
The set Comp(G, M) of compatible pairs forms a group under composition, 
and is a subgroup of Aut(G)×AutK(M). If ∈Z2(G, M) and (v, µ) is a compatible 
pair, then we can define (ν,µ) by the rule 
  
for all g, h∈G. It is straightforward to check that (ν,µ)∈Z2(G, M). Indeed, the 
mapping 
 defines an automorphism of Z2(G, M) that fixes B2(G, 
M) setwise, and so it induces an automorphism of H2(G, M). 
So Comp(G, M) induces a group of automorphisms of H2(G, M). From 
the above discussion, it can be shown that the isomorphism classes of 
KG-module extensions of M by G (where we are restricting attention to 
isomorphisms that fix M) correspond to the orbits of Comp(G, M) on 
H2(G, M). 
Exercises 
1. 
If G=Cn and 
, then show that the smallest splitting field for G 
containing L is Fqr where r is minimal with qr≡1 (mod n). 
2. 
Let M be an KG-module, where G is finite with |G|=n. 
(i) 
Let ∈Z1(G, M). By considering 
 show that 
n∈B1 (G,M). 
(ii) 
Let ∈Z2(G, M). By considering 
 for h, k∈G, show 
that n∈B2(G, M). 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
56 
(iii) Deduce that if the map 
 of M is an automorphism of M, 
then H1(G, M)=H2(G, M)=0. This holds, for example, when M is finite 
with |M| coprime to n. 
3. 
Calculate Comp(G, M) and its action on H2(G, M) in Example 2.8. 
4. 
Show that Comp(G, M) induces a naturally defined action on H1(G, M). 
5. 
Let M be a KG-module defined via ϕ:G→AutK(M). 
(i) 
If ϕ is a faithful action, then show that Comp 
. 
(ii) If ϕ is trivial, then show that Comp(G, M)=Aut(G)×AutK(M). 
6. 
If M is a KG-module defined via ϕ:G→AutK(M), and ν∈Aut(G), then we 
can define a KG-module M
v via the action 
(i) 
Verify that 
 defines an action of Aut(G) on the set of 
isomorphism classes of KG-modules. 
(ii) Check that (ν,µ)∈Comp(G, M) exactly when µ is a KG-module 
isomorphism from M to Mv. Hence, for ν∈Aut(G), there exists (ν, 
µ)∈Comp(G, M) if and only if 
2.8 Field theory 
For a detailed treatment of the material in this section, see any book on 
abstract algebra. 
2.8.1 Field extensions and splitting fields 
If F is a subfield of K, then K is said to be a (field) extension of F. The degree 
[K:F] of the extension is defined to be the dimension of K as a vector space 
over F. 
If F≤K≤L, then we have [L:F]=[L:K][K:F]. This is proved by showing 
that for bases [ui] 1≤i≤[K:F]] and [vj| 1≤j≤[L:K]] of K over F and L over K, 
[uivj| 1≤i≤[K:F], 1≤j≤[L:K] ] is a basis of L over F. 
An element α∈K is said to be algebraic over F if f(α)=0 for some 
polynomial f∈F[x]. Otherwise α is transcendental over F. If [K:F] is finite, 
then all elements of K satisfy polynomials of degree at most [K:F] over F, 
and so are algebraic over F. 
In any case, F(α) is defined to be the subfield of K generated by F and a; 
that is, the intersection of all subfields of K that contain F and α. The 
elements of F(α) are all quotients f(α)/g(α) with f, g∈F[x], g≠0. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
57 
If α is algebraic over F, then the set of all f∈F[x] with f(α)=0 forms an 
ideal, and hence a principal ideal (p) of F[x], where p can be chosen to be 
monic. Then p is called the minimal polynomial of a over F. Since F has no 
zero divisors, p must be irreducible over F. 
If p is the minimal polynomial over F of α∈K, then (p) is the kernel of 
the ring homomorphism :F[x]→K in which ()= for all ∈F and (x)=α. 
Hence im ()  F[x]/(p). Since p is irreducible, (p) is a maximal ideal of F[x] 
and so F[x]/(p) is a field and 
  
with [F(a):F]=deg(p). 
On the other hand, if F is any field and p∈F[x] is an irreducible 
polynomial, then K:=F[x]/(p) is a field, which can be thought of as an 
extension of F of degree deg(p) by identifying F with its natural image in K. 
If we define α to be the image x+(p) of x in K, then p(α)=0. Hence α is a root 
of p in K, and p factorizes in K as (x–α)q(x) for some q∈K[x]. 
More generally, if f∈F[x] has an irreducible factor p of degree greater 
than 1, then p factorizes nontrivially in the extension field K=F[x]/(p). By 
repeating this construction, we can show by a straightforward induction 
argument on the largest degree of an irreducible factor of f, that there is 
an extension field K of F, with [K:F]≤ n!, in which f factorizes into deg(f) 
linear factors. 
If K has this property, and no proper subfield of K containing F has this 
property, then K is called a splitting field of f over F. 
It is an important result that if K and K are two splitting fields of f 
over F, then there is a field isomorphism from K to K that fixes every 
element of F. Here is a very brief outline of the proof. Use induction on 
the minimum of [K:F] and [K:F], let α∈K, α∈K be roots of the same 
irreducible factor p of f with deg(p)>1, observe that F(α)  F[x]/(p)  F(α), 
and then apply the inductive hypothesis to K and K regarded as splitting 
fields of f over F[x]/(p). 
The characteristic char(F) of a field F is defined to be the smallest integer 
n>0 such that n1F=0F, or zero if there is no such integer n>0. So the familiar 
fields ,  and  all have characteristic zero. If char(F)>0 then, since F has 
no zero divisors, char(F) must be a prime p. 
It is easily shown that a polynomial f∈F[x] has repeated roots (that is, 
repeated linear factors) if and only if gcd (f, f)≠1, where f is the derivative 
of f. If F=K, then gcd(f, f)=1 in F[x] if and only if gcd(f, f)=1 in K[x], so we 
can use this condition in F[x] to check whether f has repeated roots in its 
splitting field. 
If f is irreducible then gcd(f, f)=1 if and only if f≠0, which is certainly the 
case when char(F)=0. If char(F)=p>0, then f=0 if and only if f is a polynomial 
in xp. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
58 
2.8.2 Finite fields 
The main result on finite fields is that all finite fields have prime power 
order and that, for each positive prime power q=pn, there is, up to 
isomorphism, a unique finite field of order q. We shall outline the proof of 
this fact in this subsection. Although it is only defined up to isomorphism, 
and can be constructed in different ways, it is customary to regard ‘the’ 
finite field of order q as a fixed object, and to denote it by 
. 
Let K be a finite field. Then we must have char(K)=p>0, and the subset 
 forms a subfield of K, which is isomorphic 
to the field Fp of integers modulo p. In particular, all fields of order p are 
isomorphic to Fp. 
The degree n:=[K:F] must be finite, and then q:=|K|=pn is a prime power, 
so all finite fields have prime power order. 
The multiplicative group K# of K\{0K} has order q-1, and hence αq–1=1K 
for all α∈K#, and αq-α=0K for all α∈K. So K contains q distinct roots of the 
polynomial xq-x∈F[x]. Clearly no proper subfield of K can have this property, 
so K is a splitting field of xq–x over F. It now follows from the uniqueness of 
splitting fields that all fields of order q are isomorphic. 
To prove the existence of a field of order q for any prime power q=pn, 
let K be the splitting field of xq–x over F:=FP. The derivative of xq–x is–1, 
which is nonzero so, as we saw earlier, xq–x has q distinct roots in K. It is 
easily checked that, if α, ß are roots of xq–x in K then so are α±ß, αß, and 
α/ß if ß≠0K, so the set of these roots form a subfield of K which, by 
minimality of the splitting field, must be equal to K itself. So |K|=q, as 
required. 
PROPOSITION 2.80 Any finite subgroup of the multiplicative group of a 
field K is cyclic. In particular, the multiplicative group of a finite field is 
cyclic. 
The proof of this depends on the following result from group theory. 
The exponent of a group G is defined to be the least common multiple of 
the orders of its elements or, equivalently, the least n>0 such that gn=1 
for all g∈G. 
LEMMA 2.81 If G is a finite abelian group of exponent n, then G has an 
element of order n. 
PROOF Let 
 for distinct primes pi. Then G must have 
elements gi of order 
 for each i. Since G is abelian, g1g2…gr has order n, 
as required. 
Note that the final step in the proof of the lemma is not necessarily true 
for nonabelian groups G, and indeed the lemma itself is not true in general. 
© 2005 by Chapman & Hall/CRC Press

Background Material 
59 
To prove the proposition, let the finite subgroup H in question have 
order n. If H had exponent m<n, then the polynomial xm-1 would be satisfied 
by all elements of H and hence have n>m distinct roots, which is impossible. 
So H has exponent n, and the result follows from the lemma. 
An element a of multiplicative order q-1 in Fq is called a primitive element 
of Fq. Clearly Fq=F(α) with F=Fp, and so the minimal polynomial f of α over 
F must be of degree n, where q=pn. An irreducible polynomial of degree n 
over of which the roots are primitive elements of Fq is called a primitive 
polynomial. 
(This meaning is distinct from and unconnected with the meaning of a 
primitive polynomial over  as one in which the greatest common divisors 
of the coefficients is 1. This clash of meanings is unfortunate, but since the 
concept of a greatest common divisors of field elements is trivial, there is 
probably little danger of confusion.) 
It is easily verified that the map x→xp defines an automorphism of Fq of 
order n (it is called the Frobenius automorphism, and generates the 
automorphism group of Fq, but we shall not need that fact). So, if f is a primitive 
polynomial of degree n over F with root α∈Fq, then the n elements in the set 
 are all roots of f in Fq. Hence Fq is a splitting field of f. 
If w is a primitive element of Fq then, for 0≤k<q-1, wk is primitive if and 
only if gcd(k, q-1)=1, and so the total number of primitive elements is Φ(q- 
1), where Φ is the Euler Phi-function. Each primitive polynomial f has n 
roots in Fq so there are a total of Φ(q-1)/n primitive polynomials. 
2.8.3 Conway polynomials 
Although Fq is unique up to isomorphism, it can, and often does, arise as 
the splitting field of many different irreducible polynomials of degree n 
over Fp. For computational purposes, it is useful to agree on a standard 
primitive polynomial, so that different computer algebra systems can use 
the same representation of the elements of Fq. Unfortunately, there appears 
to be no natural mathematical way of choosing such a standard polynomial. 
The standard that has been generally agreed upon is known as the 
Conway polynomial for Fq. (This is an unfortunate choice of name, because 
there is another meaning of Conway polynomial in knot theory!) They 
were originally introduced by Richard Parker, who also computed many 
examples. To define them, we first need to define an ordering on the set of 
all polynomials of degree n over F=Fp, and it is here that an apparently 
arbitrary choice had to be made. 
We order Fp itself by 0<1<2<…<p–1. Then the polynomial 
  
is mapped onto the word αn-αn-2…α1α0, and the resulting words are ordered 
lexicographically using the above ordering of Fp. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
60 
The Conway polynomial for Fp is defined to be the least primitive 
polynomial of degree 1 under this ordering. In other words, it is x-α, where 
α is the smallest primitive element in Fp. For nonprime fields, there is an 
extra condition. 
It turns out (see exercises below) that Fpm is a subfield of Fpn if and only if 
m divides n. For compatibility between the Conway polynomial f of the 
field Fpn and its subfields, it is required that if a is a root of the Conway 
polynomial f of Fpn then, for all proper divisors m of n, αt with t:=(pn-1)/(pm-1) 
should be a root of the Conway polynomial of Fpm. 
It is a slightly tricky exercise in modular arithmetic to show that a 
primitive polynomial f exists that satisfies this property, where we may 
assume by induction that the Conway polynomials are already defined and 
satisfy the property for all proper subfields of Fpn. A proof can be found in 
the thesis of W. Nickel [Nic88]. We can then define the Conway polynomial 
f of Fpn to be the least polynomial under the ordering defined above that has 
the property. 
For example, for q=2, 4, 8, 16, 32, 3, 9, 27, 5, 25, the Conway polynomials 
are respectively x+1, x2+x+1, x3+x+1, x4+x+1, x5+x2+1, x+1, x2+2x+2, x3+2x+1, 
x+3, x2+4x+2. 
One disadvantage of this definition is that there is nothing much better 
than brute-force algorithms available for calculating Conway polynomials, 
which become rapidly impractical as the field grows larger. On the other 
hand, they only have to be computed once, and some of the calculations 
can be done in parallel. Some recent computations are described by Heath 
and Loehr in [HL04]. For example, they have been computed for fields up 
to order p97 for p≤11, p43 for p≤23, 6731, 1276. Complete lists are available on 
[Con]. 
Exercises 
1. 
Find an example of a nonabelian group having no element of order 
equal to its exponent. 
2. 
If q and r are prime powers, show that Fr occurs as a subfield of Fq if and 
only if q is a power of r, and in that case there is a unique subfield of Fq 
isomorphic to Fr. 
3. 
Prove that Conway polynomials can be defined for all finite fields Fq. 
You may want to use the fact that 
for all positive integers p, m, n. 
© 2005 by Chapman & Hall/CRC Press

61
Chapter 3
Representing Groups on a
Computer
We are now ready to embark upon our study of computational group theory!
Many of the methods in CGT depend on whether the group is represented as
a group of permutations, a group of matrices, or by means of a presentation
using generators and relators. The most fundamental algorithms in CGT
generally apply just to one specific representation type: for example, coset
enumeration can be applied only to a group defined by means of a finite
presentation. Most of the later chapters in the book will be concerned with
algorithms for one particular representation type of groups.
In the current chapter, however, we shall start with some general
considerations about the different ways of representing groups on computers,
and about the properties of a group and its elements that we might hope to be
able to compute in various situations. We shall then go on to introduce a few
basic algorithms and techniques, such as choosing random elements of groups,
which can be studied independently of the representation type.
3.1 Representing groups on computers
3.1.1 The fundamental representation types
There are three methods commonly used to represent groups on a computer,
namely, as groups of permutations of a finite set, groups of matrices over a
ring, and as groups defined by a finite presentation. Most of the algorithms
discussed in this book will concern groups defined using one of these three
methods. Chapter 4 and various sections of later chapters will be devoted to
computing in permutation groups, Section 7.8 will deal specifically with
matrix groups, and Chapters 5, 9, 12, and 13 will be concerned with groups
given by a finite presentation. In addition, Chapter 8 will be concerned with
groups defined by a particular type of finite presentation, namely a polycyclic
presentation.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
62
We generally prefer our permutation groups of degree n to act on the
set {1..n}; that is, we prefer to compute with subgroups of Sym(n). In cases
when the action is given or arises naturally on some different set, we
would normally choose to rename the points as {1..n} before attempting
any further computations. In the case of matrix groups over a ring, we
shall only be concerned with the case where we can carry out the basic
operations of addition and multiplication exactly within the ring. So the
ring might be a finite field, the integers or the rational numbers, or perhaps
an algebraic number field, but not the real or complex numbers.
We may also occasionally want to consider other groups arising from these
basic types, such as quotient groups of permutation or matrix groups, which
cannot always be easily represented in the same way themselves. Examples
are given by P.M. Neumann in [Neu87] of permutation groups of order 8n
and degree 4n, for n≥1, which have quotients for which the smallest degree of
a faithful permutation representation is 22n+1. See the exercise below.
Virtually all of the techniques that have been built up for computing within
groups take as a starting point a finite generating set for the group or groups
concerned, and we shall assume in this book that all of our groups are defined
by means of a finite generating set (or sequence). So, for example, if we were
trying to develop an algorithm to find a Sylow p-subgroup of a finite group,
then our aim would be to output generators for that subgroup.
We want to be able to compute in very large finite groups, and so we try
very hard to avoid algorithms that would require computing a list of all elements
of the group, or even looping over all such elements. This is not always possible.
As we saw in Example 2.3, any finite group whatsoever has a faithful
permutation representation acting by right multiplication on its own elements,
which we called the (right) regular action. Occasionally, we may need to
resort to using this representation, which is tantamount to listing all of the
group elements, although the group elements would be represented by natural
numbers in this situation. For example, if we need a faithful permutation
representation of a proper quotient of an existing permutation or matrix
group, then the only default choice is the regular representation.
3.1.2 Computational situations
As a rough guideline, there are three basic situations that occur in practice, and
which affect our ability to extract information about a group G computationally.
Of course, variations and combinations of them are also possible, but they serve
to give an approximate idea of the possible states of affairs.
1.
Situation A. We can represent every element of G on the computer, and
we have methods to compute representations of inverses and products of
group elements. But we may not be able to decide whether two
representations of group elements define the same element.
Example: a group G defined by a finite presentation 
.
© 2005 by Chapman & Hall/CRC Press

Representing Groups on a Computer
63
2.
Situation B. As in Situation A and, additionally, we can decide whether
two representations of group elements define the same element.
Examples: a permutation group G on a finite set defined by an arbitrary
generating set; a matrix group G over a finite field or an algebraic number
field defined by an arbitrary generating set.
3.
Situation C. As in Situation B and, additionally, we have a special
generating set g1,…, gr of G and an algorithm that can compute for every
element gG a unique word wg with g=wg(g1,…, gr).
Example: a permutation group G with a so-called ‘strong generating set’.
This ‘strong generating set’ is used as the special generating set for G.
For its definition and the corresponding algorithm to compute unique
words wg, we refer to Section 4.4.
In general, the algorithm for computing wg is known as a rewriting
algorithm.
If a certain group is given to the computer, then our first and principal aim
before doing anything else with the group is usually to move into the best
possible computational situation for this group. The methods to move into a
better situation depend (again) on the representation of the given group. For
example:
1.
A group G is defined by a finite presentation 
 and, additionally, it
is known that G is finite. Then for most computational purposes we
would first try to determine a faithful permutation representation for G
and thereby move from Situation A to B. The Todd-Coxeter coset
enumeration algorithm to be discussed in detail in Chapter 5 is most
commonly used for this purpose.
2.
A group G is given by a generating set of permutations. Then for most
computational purposes we would first compute a strong generating set
for G and thereby move from Situation B to C. Algorithms for achieving
this will be described in Section 4.4 and in Chapter 6.
Situation C is our preferred situation for computational purposes. It has
various computational advantages. For example, the words wg used in
Situation C play the role of a normal form for group elements. They allow
us to read off the order of the group G (which may be finite or infinite) as
the number of possible normal forms. Also, in Situation C we can store and
compare elements using their corresponding normal form words, which
is often a computational advantage. Often it enables us also to test a
given element of some superstructure (such as Sym(Ω) for permutation
groups, or the general linear group for matrix groups) for membership
in G.
In some situations, including the base and strong generating set framework
for permutation and matrix groups, and the polycyclic series for polycyclic
groups to be described in Chapter 8, this normal form is derived from a chain
of subgroups
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
64
 
of G, and the normal form itself is 
, where gi lies in a fixed
transversal Ui of G(i+1) in G(i).
3.1.3 Straight-line programs
The most convenient generating set for the normal form words wg that we
discussed above in connection with Situation C is often not the same as the
initial generating set on which the group is defined. For example, for a
permutation group, a strong generating set used for wg is generally a superset
of the initial generators. However, in many situations we need to be able to
relate the generators used for the wg to the initial generators.
For that purpose, we shall introduce a data structure known as a a
straightline program (SLP). It also provides a space-efficient method for
storing elements in groups such as permutation or matrix groups. The
terminology was introduced in computer science as a certain type of program.
Here we shall use it in the following form.
We define an SLP group S of rank k to be a free group of rank k on
generators 
. We shall call the elements of S SLPs or SLP elements.
From a purely mathematical viewpoint, there is no difference between an
SLP group and any other free group. The difference lies in the way that the
SLP elements are stored. They are not, in general, stored as words in the
original , but as words in SLPs that have been previously defined. So, for
example, if k=2, then
 
defines a sequence of SLP elements w1, w2, w3, w4. To avoid the words growing
too long, they are not evaluated as words in the original generators of S, but
stored exactly as they are defined. So, in particular, a product of two existing
SLP elements is stored as that product, and the product is not expanded.
An evaluation  of an SLP group S in a group G is an assignment of the
generators 
 of S to elements xi of G. By definition of a free group, this
defines a unique homomorphism :S→G in which each  is mapped to xi.
The storage method renders the evaluation of (w) for an SLP element
w∈S very easy, and this is the motivation behind these ideas. Since w is
stored as a (usually short) word in SLP elements wi that were defined
earlier, we first calculate the evaluation (wi)∈G of the wi used to define w,
and then we can calculate (w) itself.
So, in the example above, if we take G=Alt(6) and x1=(1, 2, 3), x2= (2, 3, 4,
5, 6), then w1, w2, w3 and w4 evaluate in G respectively to x1, x2, x3:=(2, 5) (4,
6), and x4:=(4, 5, 6).
© 2005 by Chapman & Hall/CRC Press

Representing Groups on a Computer
65
Now it turns out to be much easier to write an arbitrary element of
Alt(6) as a word in x1, x2, x3,x4 than in the original generators x1, x2. (The
reason for this will become clear in Section 4.4, when we define bases and
strong generating sets. In fact x1, x2, x3, x4 is a strong generating set with
respect to the base [1, 3, 2].) For example, 
We
could now, if we wanted to, use the definitions of x3 and x4 coming from the
corresponding SLP elements to evaluate this element as a word in the
original generators. In this example, x3=(x1x2)2 and
so we have
Incidentally, this is not the shortest word possible for (1, 5) (2, 6), which is
, but in large groups there is no satisfactory algorithm for
finding shortest words for elements in the original generators. We shall discuss
this problem later, in Subsection 4.8.3.
In general, we proceed by defining an SLP group on generators 
corresponding to our initial generators xi(1≤i≤k) of G, and the corresponding
evaluation in which  maps to xi. We then define SLP elements w1,…, wr,
usually with 
 for 1≤i≤k, together with their evaluations x1,…, xr in G,
where these elements are chosen in such a way that arbitrary elements
g∈G can be written easily as reasonably short words in the extended
generating set {x1,…, xr}. In the case of permutation and matrix groups, we
extend the initial generating set to a strong generating set (see Section
4.4), which enjoys this particular property. The definitions within the SLP
could, in principal, be used for rewriting group elements as words in the
original generators, but we would avoid doing that if possible. We might
choose to store the elements and their inverses from this extended
generating set explicitly as permutations or matrices, but that is not
essential, because they can always be evaluated when required.
As we shall explain shortly, straight-line programs are of vital importance
in computations involving group homomorphisms.
3.1.4 Black-box groups
We shall not be devoting too much attention to black-box groups in this book,
but the topic is important enough to warrant a mention, if only a brief one.
The term ‘black-box group’ can be confusing, because it does not describe
a particular type of group; it refers rather to a method of representing group
elements within a computer, together with some assumptions on the
availability of algorithms for composing, inverting, and comparing group
elements.
It was introduced by Babai and Szemerédi in [BS84]. The definition is as
follows. A finite alphabet A and an integer N>0 are given. Group elements
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
66
are represented by strings in A* of length at most N. If we have strings
representing g, h∈G, then we can compute in constant time (using an ‘oracle’)
strings that represent g-1 and gh, and we can decide whether g=G h.
Note that we cannot in general decide whether a given string of length at
most N in A* represents a group element. (Deciding that is similar to the
membership testing problem.)
In fact a black-box group is really just a description of Situation B for a
group G, but with a significant additional restriction: the stipulation that
strings have length at most N means that a black-box group is necessarily
finite, with an upper bound of 
 on the group order. Finite
permutation groups and matrix groups over finite fields are important
examples of black-box groups.
An algorithm for black-box groups lends itself readily to complexity analysis
in terms of both time and space, where the time complexity will involve the
number of calls to the oracle.
There is a significant research project in CGT to develop a full collection of
algorithms for finite groups given as black-box groups. The advantage is
that they are independent of the particular type of representation of the group.
The disadvantage is that they cannot make any use of this representation.
For example, this automatically rules out many of the most important
algorithms for permutation groups, which typically rely heavily on the orbit
structure of the group and its subgroups.
There is one other important attraction of black-box group algorithms, which
is that if K is a normal subgroup of G, and we have an algorithm for testing
strings for membership in K, then this algorithm can be used as the oracle
for testing whether an element of G/K is the identity, and then G/K becomes
a black-box group, where the representatives of g∈G become representatives
of gK∈G/K.
Unfortunately, the black-box setting is too restrictive for most purposes.
One major problem is that there is no efficient black-box algorithm for
determining the order of an element g; the only way is to test gk=1, for k=1,
2, ..., which is likely to be too slow if |g| is large. Since there are efficient
ways of finding the order of an element in a permutation group or in a
matrix group (a method for the latter is described by Celler and Leedham-
Green in [CLG97]), a common recourse is to assume that the group is
equipped with a further oracle for determining element orders. But then
the problem of passing to quotient groups reasserts itself!
Perhaps the most important achievement in this area to date is the
development of methods for the constructive recognition of the finite nonabelian
simple groups given as black-box groups. We shall return briefly to this topic
later in the book, in Section 10.3.
© 2005 by Chapman & Hall/CRC Press

Representing Groups on a Computer
67
Exercises
1.
Let G be the direct product of n copies of the dihedral group of order 8.
Show that G has a faithful permutation representation of degree 4n. Let
zi be the central element of order 2 in the i-th copy of D8, and let K be the
subgroup of G generated by 
. So K has order 2n–1, and
G/K is a central product of n copies of D8. Show that the smallest degree
of a faithful permutation representation of G/K is 2n+1 (see [Neu87].)
(Hint: Let the i-th copy of D8 be generated by xi, yi. Then the image in
G/K of the subgroup generated by the xi is abelian of order 2n and is
dis-joint from Z(G/K). Any larger subgroup must include two
noncommuting elements and hence must contain Z(G/K).)
2.
Let 
 be cyclic of order n for some large positive integer n.
Devise a method of representing elements of G efficiently using an SLP
group on the single generator .
3.2 The use of random methods in CGT
Many algorithms in CGT, and indeed in computer algebra in general, depend
critically on making some random choices, such as choosing random elements
of groups. In the first subsection we describe the two principal types of
randomized algorithms that are used in CGT, and in the second we present
one specific method of choosing random elements from a finite group.
3.2.1 Randomized algorithms
A deterministic algorithm is one that depends on its input data alone. So, if
it is run repeatedly with the same input data, it will always proceed in the
identical fashion. A complexity analysis of such an algorithm will provide an
accurate and consistent estimate of its time and space requirements.
A randomized algorithm is one that makes use of a random number
generator during its execution, typically in order to choose random elements
of some group G. Such an algorithm does not depend on its input data alone,
and its performance may vary, sometimes dramatically, from one run to
another with the same input.
It may still be possible to carry out complexity analyses of such algorithms,
but the results will typically merely estimate the average running time and
space requirements of the algorithm. An analysis of this kind will need to
assume that the random number generator being used is working properly,
and is capable of choosing genuinely random integers within a given range
[a..b]. In practice, of course, there is no such thing as a perfect random
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
68
number generator, but this is not the place to explore this interesting
question, and we refer the interested reader to the lengthy treatment by
Knuth in Chapter 3 of [Knu69].
There are two distinct types of randomized algorithm that arise in CGT;
they have become generally known within the trade as Monte Carlo and Las
Vegas algorithms.
A Monte Carlo algorithm is one which may sometimes output a wrong
answer! It is, however, a requirement that one of the input parameters of
such an algorithm should be a real number  with 0<<1, and that the
probability of the answer being wrong should then be less than  for any
values of the remaining input data. The performance will depend on ,
with smaller values of  resulting in longer running times.
Although the first reaction of many traditional mathematicians (who may
in any case be generally suspicious of the use of computers in mathematics)
is to recoil in horror at the idea of a process that has an intrinsic possibility
of generating a false result, these algorithms do have their uses. The best-
known example is primality testing of integers, for which there are Monte
Carlo methods that run significantly faster that the best-known deterministic
methods, and which are adequate, and essential in practice, for their
applications to cryptography.
There are other mathematicians, more in the habit of relying on the
computer to help with their work, who go to the opposite extreme, and argue
that an answer delivered with an error estimate of 10-20, for example, should
simply be regarded as proven correct, because even traditional mathematical
proofs written out in full detail might struggle to acquire a comparable degree
of reliability. Indeed, with any computer calculation, there are small
possibilities of error, such as hardware or compiler error, which are completely
outside the control of the typical mathematical user.
For a mathematical treatment of algorithms, such as the one we are
attempting in this book, it seems desirable, however, to make suitable
simplifying assumptions, such as the absence of hardware or compiler errors,
and the ability to generate genuinely random numbers, and then to treat the
output of a Monte Carlo algorithm exactly for what it is; namely, an answer
with a small, known probability of being wrong.
In most, if not all, of the important Monte Carlo algorithms in CGT, certain
answers are in fact guaranteed correct, whereas other answers come with
the possibility of error. For example, in Section 4.2 we shall describe a Monte
Carlo algorithm for testing whether an input permutation group on  is
Alt() or Sym(). The answer ‘yes’ is guaranteed correct, whereas the answer
‘no’ has a small chance of being wrong. In practice, such algorithms are
often used as filters; we want to check quickly whether the group is very
large (Alt() or Sym()) and, if not, then we plan to analyze it further and
perhaps to calculate its precise order.
A Las Vegas algorithm is one that never delivers an incorrect answer, but
has a probability of at most  of not returning an answer at all. It is again
required that  should be an input parameter.
© 2005 by Chapman & Hall/CRC Press

Representing Groups on a Computer
69
These are much less controversial than Monte Carlo algorithms, because
in practice they can always be made to return a correct answer just by
running them repeatedly with the same , and implementations will often
do this automatically. The only problem is that, if one is unlucky, then one
may have an unexpectedly long wait for an answer. The majority of
randomized algorithms that we shall encounter in this book are of this type.
3.2.2 Finding random elements of groups
Again we shall assume that we can choose random integers within a given
range. This clearly enables us to choose random elements of any indexed list
l, and we shall assume the availability of a function RANDOM(l) that does
this for us.
Many algorithms in CGT depend critically on the ability to generate quickly
uniformly distributed random elements of a group G. There are some cases
where this is relatively easy; for example if G=Sym(n) (see exercise below)
and, more generally, we shall see in Chapter 4 that it is easy for finite
permutation groups G for which a base and strong generating set are known.
However, in some situations we need to be able to generate a sequence of
random elements from a group G for which we are in Situation A or B, as
defined in Subsection 3.1.2 above. For finitely presented groups (Situation
A), all that we can sensibly do is to find a random word for which the length
lies within a given range.
Unfortunately, even for black-box groups, there is no known method of
generating random elements that is completely satisfactory. A method
proposed by Babai in [Bab91] does generate elements that are guaranteed to
be genuinely uniformly distributed, but it is far too slow to be useful in
practice. Here, we shall describe the product replacement algorithm, proposed
in [CLGM+95], which generates a sequence of elements that is not guaranteed
to be uniformly distributed, but which is very fast, and appears to behave
satisfactorily in those algorithms in which it has been used to date. (However,
there are some serious reservations. For example, the behaviour can be
unsatisfactory when the group is a direct product of a large number of copies
of the same finite simple group. See the article of I. Pak [Pak01] for a theoretical
investigation.) We refer the reader to Section 2.2 of [Ser03] for a detailed
discussion and theoretical analysis of both Babai’s method and the (original)
Product Replacement Algorithm.
We maintain a list [x1, x2, …, xr] of elements of G, which generate G. A
suitable value of r has been found in practice to be about 10, but if the given
initial generating sequence X of G has more than this number of elements,
then we must take r=|X|. It is argued in [Pak01] that a larger value of r
would be necessary for guaranteed good theoretical behaviour. If |X|<r, then
we initialize the list to contain the generators in X repeated as many times
as required. In the original version, we repeatedly choose random distinct
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
70
integers s, t∈[1..r], and replace xs by 
 or 
. Notice that the list
still generates G after making this change. After doing this a certain number
of times to get us away from the initial generating set (50 times has been
used as a default in implementations), we start returning the new values
of xs as our random elements.
It is proved in [CLGM+95] that the elements returned will eventually be
uniformly distributed random elements of G, but there is no reasonable
estimate known on how long we will have to wait for this, and it is likely
that the ad hoc default waiting time of 50 changes is not enough. Another
possible problem with the algorithm is that the group elements g1, g2 returned
on successive calls of the algorithm will never be uniformly distributed in
G×G.
The version that we shall present here is a modification due to Leedham-
Green, which involves the use of an accumulator x0 that is always used as
the return value. (As a cricket enthusiast, Leedham-Green likes to take
r=11 and to call x0 the ‘twelfth man’, but we prefer to avoid the gender bias
inherent in that terminology!) There is heuristic evidence that this converges
more quickly than the original version.
To use the method, we must first call the following initialization function
on our generating set X. This sets up the list X=[x0, x1,…, xr], performs the
product replacement process PRRANDOM n times as initialization, and
returns 
. In some applications, we shall need to know exactly how the
random elements returned were derived from the original generators, and so
we shall also maintain SLP elements wi, which express each element xi as a
word in the original generators x1,…, xk of G. As usual, we denote the
generators of the SLP group that evaluate to the xi by .
PRINITIALIZE(X, r, n)
Input: X=[x1,…, xk] generating a black-box group, r, n∈N
Output: List  and associated SLP elements W
1
Let  (1≤i≤ k) be generators of an SLP group;
2
for i∈[1..k] do wi:=
;
3
for i∈[k+1..r] do xi:=xi-k; wi:=wi–k;
4
x0:=1G; w0:=ε;
5
X:=[x0, x1,…, xr]; W:=[w0, w1,…, wr];
6
for i∈[1..n] do PRRANDOM(~X, ~W);
7
return X, W;
We remind the reader that we precede a variable by a ~ symbol in a function
or procedure call when the value of that variable may be be altered by the
function or procedure.
The function PRRANDOM, which outputs random group elements, should
be called for the first time using the lists , W returned by PRINITIALIZE.
Subsequently, it should be called using the altered values of X, W) resulting
from the previous call of PRRANDOM.
© 2005 by Chapman & Hall/CRC Press

Representing Groups on a Computer
71
The reader should be aware that we are omitting the details of the
implementation of SLP groups in the code for PRRANDOM; each SLP
element wi is being defined as a word in existing SLP elements, and so all
of these existing elements would need to be stored in order to allow later
evaluation of the wi. In situations later in the book in which we do not
need the SLP-elements, we shall call PRRANDOM with only one input
parameter, X.
PRRANDOM(~X, ~W)
Input: List X=[x0, x1,…, xr], W=[w0, w1,…wr]
Output: An element of G and corresponding SLP element
1 s:=RANDOM([1..r]);
2 t:=RANDOM([1..r]\[s]);
3 x:=RANDOM([1..2]);
4 e:=RANDOM({-1, 1});
5 if x=1
6
then 
7
8
else
9
10 return x0, w0;
The list [1..r]\[s] in this function can be easily constructed by removing k
from [1..r] and, if s≠r, replacing s by r.
Exercises
1.
Find a method for constructing uniformly distributed random elements
of Sym(n) in time O(n), on the assumption that random elements
from a list of length up to n can be found in constant time. (This
assumption is false for large n, but provided that n is small enough
for the list to be represented on a computer in RAM, then it is a
reasonable practical assumption to make.) It is clear how to start:
choose the image 1g under our random permutation g to be a random
element of {1..n}. But now we have to choose 2g from {1..n}\{1f}, so how
can we manage this by doing only a small constant amount of
reorganization of our data?
2.
If you have access to GAP or MAGMA, then implement the procedures
PRINITIALIZE and PRRANDOM (but leave out the calculations with
SLP elements if you prefer). Try out your functions on the groups
GL(d, q) for various parameter settings, and various d and q. How
many iterations of PRRANDOM in PRINITIALIZE are needed to ensure
that the elements returned by PRRANDOM appear to be random? How
dependent is this number on q?
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
72
3.3 Some structural calculations
In this section, we present examples of some structural computations that
can be carried out in any class of finitely generated groups for which we can
find random group elements, and in which we can test membership of group
elements in finitely generated subgroups. This is typically the case when we
are in Situation C (see Subsection 3.1.2).
3.3.1 Powers and orders of elements
Suppose that we are in Situation B for a group G, and that we need to calculate
gn for some g∈G and 
. The obvious thing to do is just to multiply g by
itself n-1 times. This is fine for small n, but for larger n, there is a much
quicker way, which has complexity O(log(n)) rather than O(n). We calculate
gn as a product of elements 
, where each individual 
 can be calculated
by repeated squaring of g. This is carried out in the following function.
Of course, if we knew in advance that we were going to need to calculate
gn for the same g and for many different values of n, then we could save
time by storing the elements 
 rather than recalculating them each time.
POWER(g, n)
Input: g∈G, 
Output: gn
1
x:=1G;
2
if n mod 2=1 then x:=xg;
3
while n>1
4
do g:=g2;
5
n:=n div 2;
6
if n mod 2=1 then x:=xg;
7
return x;
A well-designed computer algebra system would use this method by default
whenever the user types gn, at least for large values of n.
As we mentioned in Subsection 3.1.4, finding the order of an element in a
black-box group is not so easy in general and, without further information,
all that we can do is to test whether gn=1G for each power gn in turn. In some
situations, however, such as for finite field elements, or matrices over finite
fields, it is possible to find an n such that the order |g| of g divides n.
Provided that we can factorize n (which, unfortunately, may not be completely
straightforward when n is very large), the following function will find the
order of g in time at most O(log(n)3).
© 2005 by Chapman & Hall/CRC Press

Representing Groups on a Computer
73
ORDERBOUNDED(g, n)
Input: gG, 
 with |g| dividing n
Output: |g|
1
if n=1 then return 1;
2
for p PRIMEDIVISORS(n)
3
do if POWER(g, n/p)=1G
4
then return ORDERBOUNDED(g, n/p);
5
return n;
3.3.2 Normal closure
Let 
 be a subgroup of a group 
 with X and Y finite, and
suppose that we want to find the normal closure 
 of H in G. The
obvious way to proceed is to start with N=H, test each yx with yY, xA:=
XX-1 for membership in N, and adjoin it to Y as an extra generator if the
test fails.
Of course, in general, N might not be finitely generated, in which case
this process would not terminate, but usually we will want to do this when at
least |G:H| is finite, in which case termination is guaranteed, and the
above procedure provides us with a deterministic algorithm.
In fact, when |G:H| is large and finite, it is usually faster to adjoin a
number of random conjugates of H by G to the generating set of N, and then
to test whether N is the full normal closure. The procedure
NORMALCLOSURE does this. The random conjugates are added in batches
of size n. In Section 5.1.4 of [Ser03], Seress suggests the value n=10 for
permutation groups.
3.3.3 The commutator subgroup, derived series, and
lower central series
Let 
 and 
 be subgroups of a group G, where X and Y are
finite. By Proposition 2.35, [H, K] is the normal closure in 
 of the set
C:={[h, k] | hX, kY}. This can be computed by the normal closure
algorithm described in Subsection 3.3.2 provided that the appropriate
assumptions on membership testing in subgroups are satisfied.
However, if the generating sets X and Y are large, then it may be expensive
to construct the set C, which has size |X| |Y|, explicitly. In that case, we
might prefer to construct our random elements of the group H in
NORMALCLOSURE as random words in a smaller set of commutators [h,
k], where h and k are themselves random elements in H and K. If we do
this, then we must keep changing the commutators [h, k] used, as well as
the words in these commutators.
These techniques immediately enable us to calculate the derived series
and the lower central series of a group.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
74
NORMALCLOSURE(X, Y, n)
Input: Generating sequences X, Y of groups G, H, n∈ 
Output: Generators of HG
1
Z:=Y; C := false;
2
X:= PRINITIALIZE(X, 10, 20);
3
while not C
4
do Z:=PRINITIALIZE(Z, 10, 10);
(* Add some new random conjugates to Z *)
5
for i∈[1..n]
6
do g:=PRRANDOM(~X);
7
h:=PRRANDOM(~Z);
8
if hg  
 then APPEND(~Z, hg);
(* Test whether 
=HG *)
9
C:=true;
10
for g∈X, h∈Z
11
do if hg   
12
then C:=false;
13
break;
14 return Z;
3.4 Computing with homomorphisms
The ability to compute effectively with group homomorphisms is one of the
most important aspects of CGT. In particular, it allows us to move from one
representation of a group to another, possibly more convenient, representation.
For example, if a group is given initially as a matrix group or finitely presented
group, then we might prefer to perform our computations in an isomorphic
permutation group.
We shall consider some particular types of homomorphisms, such as
mapping to the induced action of a permutation group on a nontrivial block
system in later chapters, but there are some general ideas that are independent
of the particular representation of the group, which we can consider at this
point. The reader should bear in mind that, in certain specific situations,
there may happen to be more efficient solutions to these problems than the
general ones described here.
3.4.1 Defining and verifying group homomorphisms
There are two methods that are commonly used for defining group
homomorphisms ϕ:G→H. The first is by using a general rule for calculating
ϕ(g) for g∈G. The induced action of a permutation group on a block system
is an example of this. The second method is to specify the images ϕ(x)∈H
© 2005 by Chapman & Hall/CRC Press

Representing Groups on a Computer
75
for x in a finite generating set X of G. This will of course uniquely determine
ϕ:G→H if such a ϕ exists, but unless F happens to be free on X, an arbitrary
assignment like this will not usually define a homomorphism at all.
In a particular situation, we might know already that our ϕ does define
a homomorphism, but in general we need a method for testing whether
this is the case. For example, if we are trying to compute the automorphism
group Aut(G) of a finite group G, then we will certainly need to be able to
carry out such a test.
If we know a presentation 
 of G on X, then Theorem 2.53 provides
us with a simple test for this. We assume that ϕ does extend, and then
evaluate its image in H on each of the group relators in R. If these all evaluate
to 1H then ϕ extends, and otherwise it does not.
In some situations, such as when G is a large permutation group, it is not
easy to find a group presentation on the original generators X=[x1,…, xk], but
one can be found efficiently on an extended sequence X′=[x1,…, xr], where
the new generators are defined from the existing ones via an SLP, as
described in Subsection 3.1.3 above. In that case, if we are given ϕ(xi) for
1≤i≤k, then we can simply use the expressions for each xj with j>k as SLP
elements in the earlier xi in turn, to compute ϕ(xj). We can then carry out
our test for ϕ being a homomorphism using the presentation on X′.
3.4.2 Desirable facilities
Ideally, for a group homomorphism ϕ:G→H, we would like to be able to
perform the following operations.
(i)
Compute the image ϕ(g) of any g ∈ G.
(ii) For h ∈ H, test whether h ∈ im(ϕ) and, if so, find a g ∈ G with ϕ(g)=h.
(iii) Find ϕ(K) for a subgroup K of G.
(iv) Find ϕ-1(K) for a subgroup K of H.
(v) Find ker(ϕ).
In some of these cases, it may be unclear what we mean by “Find”. It might
be relatively easy, for example, to find generators of ϕ(K) in (iii), which
would place us in Situation B for ϕ(K), but we would prefer to be in Situation
C, providing us with a rewriting algorithm and membership testing for
ϕ(K).
What is immediately clear is that, if we can solve the rewriting problem
in G, possibly by using extra generators and a SLP, then we can solve (i),
and we can at least find generators of ϕ(K) for finitely generated subgroups
K of G. Similarly, if we can solve the rewriting problem in im(ϕ), then we
can solve (ii), provided that we know inverse images for our chosen
generating set of im(ϕ). To solve (iv), we need to be able to solve (ii) and (v),
because, if K≤H is generated by X, then ϕ-1(K) is generated by ker(ϕ) and
any set of inverse images in G of the elements of X.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
76
Let us assume now that we can solve the rewriting, order, and membership
problems in finitely generated subgroups of both G and H. So we can solve
(i) and (ii) efficiently. The procedure IMAGEKERNEL displayed below is a
very useful general method of finding ker(ϕ) and im(ϕ) which, taken together
with the remarks in the preceding paragraph, allows us to solve all of (i) to
(v).
Although we have not indicated it in the code, we also need to remember
the g  G for which h=ϕ(g) is appended to Z, in order to be able to solve the
inverse image problem (ii).
IMAGEKERNEL(ϕ, X)
Input: G= group homomorphism ϕ:G→H
Output: Generators of ker(ϕ), im(ϕ)
(* Initialize generating sequences Y and Z of kernel and image *)
1 Y:=[]; Z:=[];
2 X := PRINITIALIZE(X, 10, 20);
3 while |
|
|<|G|
4
do g := PRRANDOM(~X);
5
h:=ϕ(g);
6
if h  
7
then APPEND(~Z, h);
8
else k:=ϕ-1(h); (* gk-1  ker(ϕ) *)
9
if gk–1 
 
10
then APPEND(~Y, gk-1);
It is clear why this method works. If g is a random element in G, then ϕ(g)
is a random element of im(ϕ). We also need gk-1 to be a random element of
ker(ϕ). Usually, an algorithm for solving (ii) will always produce the same
inverse image of a given element of im(ϕ), so k depends only on h, and then
gk-1 will indeed be random in ker(ϕ). This would also be the case if the
solution of (ii) resulted in a random inverse image.
Exercise
1.
Show that ORDERBOUNDED has complexity O(log(n)3).
© 2005 by Chapman & Hall/CRC Press

Chapter 4
Computation in Finite
Permutation Groups
This lengthy chapter is devoted to computations within finite permutation
groups. With a few exceptions, which include orbit computations, finding
systems of imprimitivity, and testing whether a group is alternating or
symmetric, all of the algorithms involved rely on first computing a base
and strong generating set (BSGS) for the group G. This topic will be treated
in detail in Section 4.4.
As we shall see in Section 4.6, there is an important subdivision of
algorithms for finite permutation groups into those that run in polynomial-
time, and those that do not; typically, the latter involve backtrack searches
through the elements of the group. The polynomial-time algorithms include
transitivity and primitivity testing, finding a BSGS, finding normal closures
of subgroups, computing commutator subgroups, and finding Sylow
subgroups, although the last of these has not yet been fully implemented
as a polynomial-time algorithm. Polynomial-time algorithms are not
currently known for computing intersections of subgroups, centralizers of
elements, and normalizers of subgroups, for example, and it is conjectured
that none such exist.
The reader’s attention is directed to two existing books on computation
in finite permutation groups. The first, by Butler [But91], provides an
elementary and leisurely introduction to the topic. The second and more
recent book, by Seress [Ser03], is more advanced, particularly in its
treatment of complexity questions, and we shall frequently refer the reader
to this book for details of more advanced topics.
4.1 The calculation of orbits and stabilizers
In this section, we shall suppose that we are given a finite group G defined by
an explicit finite generating sequence X=[x1,…, xr], and that G acts on a
finite set Ω. We shall assume that, for each α∈Ω and x∈X, the image αx under
the action is stored or can be computed, and that we can decide whether two
given elements of Ω are equal.
77
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
78
The most common situation that we shall encounter is where Ω={1..n}
for some 
, and the actions of the generators on Ω are stored as simple
arrays of length n. But there are other possibilities. For example, Ω could
be the set of all subgroups of G where the action is by conjugation, in which
case testing for equality of elements of Ω is a nontrivial process.
We first write down a straightforward function for computing the orbit
αG of a point α∈Ω under G.
ORBIT(α, X)
Input: α∈Ω, X=[x1,…, xr], xi∈Sym(Ω) with 
Output: αG
1 ∆:=[α];
2 for ß∈∆, x∈X do if 
3 
then APPEND (~∆, ßx);
4 return ∆;
To show that the above procedure performs correctly, first observe that all
elements appended to ∆ are images under an element of X of an element
already in ∆, and so by induction we always have 
. Conversely, if
ß=αg for some g∈G then, since X generates G, we have 
with each 
. But since G is finite, the xi all have finite order,
so we can assume that each 
. We can now show by induction on t
that ß∈∆ at the end of the procedure. This is true if t=0, since then ß=α,
and ∆ is initialized to [α]. Otherwise, by inductive hypothesis, we have
∈∆, where 
, and so 
 will be appended to
∆ during the loop in the procedure.
On the assumption that images αx can be looked up or computed in
constant time, and that membership of elements of Ω in ∆ can be tested in
constant time, it is not hard to see that the complexity of ORBIT is O(|∆|r).
From the simple code above, it is not clear that the membership testing
can be achieved in constant time. In the standard situation, where Ω={1..n},
this can be done by maintaining the current characteristic function of ∆ as
a subset of Ω. This is best accomplished by means of a Schreier vector,
which we shall discuss shortly.
In practice, we shall often require not only the orbit itself, but, for each
ß∈αG, an element uß∈G with 
. By the Orbit-Stabilizer theorem, the
set {uß|ß∈αG} is a right transversal of the stabilizer Gα of α in G. By Theorem
2.57, we have
We shall call the elements of this generating set the Schreier generators of
Gα. The function ORBITSTABILIZER returns a list ∆ of pairs (ß, uß) for
ß∈αG, and also a generating sequence Y of Gα.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
79
ORBITSTABILIZER (α, X)
Input: α∈Ω, X=[x1,…, xr], xi∈Sym(Ω) with 
Output: ∆, Y, as described above
1
∆:=[(α, 1G)];
2
Y:=[];
3
for (ß, uß)∈∆, x∈X do if 
4
then APPEND(~∆, (ßx, ußx));
5
else APPEND(∼Y, uβx(uβx)–1);
6
return ∆, Y;
Observe that, if an orbit member is initially introduced into ∆ as ßx, then
, and so the associated Schreier generator 
 is necessarily
trivial, and does not need to be appended to Y. In this case, we shall say
that the Schreier generator is trivial by definition, and write 
. (It
is of course possible to have 
)
4.1.1 Schreier vectors
We now turn to an important alternative approach to handling the
transversal elements uß when Ω={1..n} for some 
. In many situations,
we would like to avoid storing the uß explicitly. We want to be able to
handle permutations acting on as many as 106 or even 107 points. For a
transitive group action, we would have ∆=Ω, and so it would not be practical
to store |∆| permutations of this degree. Even for groups of smaller degree,
where storage is not critical, we may wish to avoid the O(n2r) time
complexity that results from computing all of the uß.
DEFINITION 4.1 A Schreier vector for α∈Ω is a list v of length n with the
following properties.
(i)
v[α]=-1.
(ii) For γ∈αG\{α}, v[γ]∈{1..r}; more precisely, v[γ]=i, where γ is appended
to ∆ as 
 in the function ORBIT.
(iii) 
.
So, in particular, v can be used as a characteristic function of the orbit. The
function ORBITSV displayed below is an amended version of ORBIT, which
computes v. (It could of course be easily modified to compute generators of
Gα as in ORBITSTABILIZER.)
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
80
ORBITSV(α, X)
Input: α∈[1..n], X=[x1,…, xr], xi∈Sym(n), 
Output: αG and Schreier vector v for α
1
for i∈[1..n] do v[i]:=0;
2
∆:=[α]; v[α]:=-1;
3
for ß∈∆, i∈[1..r] do if ßxi ∉∆
4
then APPEND(~∆, ßxi); v[ßxi]:= i;
5
return ∆, v;
Example 4.1
Let n=7 and X=[x1, x2] with x1=(1, 3, 7)(2, 5) and x2=(3, 4, 6, 7), and let us
apply ORBITSV with α=1. Initially ∆=[1] and v=[-1, 0, 0, 0, 0, 0, 0]. Starting
the main loop with ß=1, we have 
, so we append 3 to ∆ and set v[3]=1.
Since 
, we proceed to ß=3. Then 
, so we append 7 to ∆
and put v[7]=1. Also 
, so we append 4 to ∆ and put v[4]=2. Moving
on to ß=7, we have 
 and 
 are already in ∆, so we go on to ß=4.
Then 
 but 
, so we append 6 to ∆ and put v[4]=2.
Both 
 and 
 are in ∆, so the process completes and returns ∆=[1, 3, 7,
4, 6] and v=[-1, 0, 1, 2, 0, 2, 1]. []
ORBITSV has complexity O(nr). The function U-BETA can then be used to
compute a particular uß if required. It returns false if ß is not in αG. We
leave it to the reader to prove that it performs correctly.
U-BETA(ß, v, X)
Input: Schreier vector v for some α∈Ω and ß∈Ω
Output: uß with αuß=ß or false if ß∉αG
1
if v[ß]=0 then return false;
2
u:=1G; k:=v[ß];
3
while k≠−1 do u :=xku; β := βx–1
k ; k:=v[β];
4
return u;
If we call U-BETA with ß=6 in Example 4.1, then we find v[6]=2, so u is set
equal to x2 and ß replaced by 
. Now v[4]=2, so u becomes 
 and ß
becomes 
. Now v[3]=1, so u becomes 
 and ß becomes 
.
We now have v[1]=-1, so the process halts and returns u=(1, 6, 3, 4, 7)(2, 5),
which maps 1 to 6 as required.
Given an orbit αG, a method of computing the associated transversal
elements uß, and also a method for computing random elements of G, we
can easily generate random elements of Gα. We simply choose g random
in G, find ß:=αg, and then 
 is random in Gα. The following function
implements this process using a Schreier vector for the orbit, and the function
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
81
RANDOMSTAB(α, v, X, ~ X)
Input: 
, Schreier vector v for orbit αG
Output: Random element of Gα
1
g :=PRRANDOM(~X);
2
h:=U-BETA(α9, v, X);
3
return gh—1;
PRRANDOM from Section 3.2.2. We assume that the random element list
X has already been initialized by a call of PRINITIALIZE.
4.2 Testing for Alt(Ω) and Sym(Ω)
In this section, we shall describe a fast and easy Monte Carlo algorithm for
testing whether a transitive permutation group on a set Ω is equal to Alt(Ω)
or Sym(Ω) when |Ω| ≥ 8. (For smaller values of |Ω|, there is no need for
this, because the order of the group can be computed easily by the Schreier-
Sims algorithm to be described in Subsection 4.4.2.) A positive answer is
guaranteed to be correct, whereas a negative answer has a small probability
of being wrong. Note that in the event of a positive answer, it easy to
distinguish between Alt(Ω) and Sym(Ω); we simply check whether all of the
group generators are even permutations.
When attempting to analyze an unknown permutation group G on Ω, a
sensible approach is first to test G for transitivity using the methods of the
preceding section and then, if GΩ is indeed transitive, to check whether it is
one of the large groups Alt(Ω) and Sym(Ω). If, as a result of carrying out this
test, we become virtually certain that it is not one of these two groups, then
we can proceed with further analysis, as described in the following sections.
If the result of the Alt/Sym test had actually been wrong, then we would
expect to discover this error later, although we might have wasted considerable
computational effort before this discovery!
The method is based on the following result.
THEOREM 4.2 Let G ≤ Sym(Ω) be transitive on Ω with |Ω|=n, and let p be
a prime number with n/2 <p<n-2. If G contains an element with a cycle of
length p, then G=Alt(Ω) or Sym(Ω).
We shall not prove this theorem here. It follows from an old result of
Jordan (see [Jor73] or Theorem 13.9 of [Wie64]), which says that a primitive
group that contains an element consisting of a single p-cycle for a prime p
with p<n-2 is alternating or symmetric. The extra condition n/2<p in our
theorem ensures primitivity (exercise below).
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
82
The algorithm itself, which we shall call ISALTSYM, is so simple that
we do not need to display its code. It takes two input parameters: G, and
our required upper bound  on the error probability. We use PRRANDOM
to choose some number N(n, ) random elements of G. If one of these
elements contains a p-cycle for a prime p with n/2 <p<n-2, then we stop
immediately and return the answer true. If not, then we return false.
Notice that this will only work for |Ω|=n≥8, since there are no primes
with n/2<p<n-2 when n<8.
By Theorem 4.2, we know that the answer true is correct. It remains for
us to calculate the number N(n, ) that will ensure that an answer false has
a probability of less than  of being wrong. More precisely, we want the
probability of the answer false being returned when the input group is Alt(Ω)
or Sym(Ω) to be less than .
For this, we need to estimate the proportion of elements of Alt(Ω) and
Sym(Ω) that contain a p-cycle for a prime p with n/2<p<n–2. It is proved in
Lemma 10.2.3 of [Ser03] that this proportion is at least
 
which, by standard results in number theory, is approximately log(2)/log(n).
Choose c(n) such that this proportion is at least c(n) log(2)/log(n) and let
d(n) := c(n) log(2)/log(n). (For example, we could choose c(n)=0.34 for 8≤n≤16
and c(n)=0.57 for n>16.)
Now, if G=Alt(Ω) or Sym(Ω), then the probability of choosing k random
elements of G and not encountering an element containing a p-cycle is at
most (1-d(n))k<e
d(n)k. Therefore the choice of N(n, ) := -log()/d(n) random
elements of G will satisfy the required condition on the error probability.
4.3 Finding block systems
4.3.1 Introduction
Let 
 be a subgroup of Sym(n). The algorithms described in
Section 4.1 enable us to decide in time O(nr) whether G is transitive. In
this section, we assume that G is transitive. It is now natural to ask whether
G is primitive (see Subsection 2.2.5), and we address this problem in this
section. Deciding primitivity and finding block systems for G is one of the
few computational problems with permutation groups that can be solved
efficiently without knowing a base and strong generating set for G.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
83
The basic algorithm to be described finds the smallest block of G that
contains k>1 given points α1,…,αk ∈ Ω={1..n}, together with the other blocks
in the associated block system. This is equivalent to finding the G-congruence
generated by { (α1,αi) | 2≤i≤k} (see Definition 2.27). This algorithm is
originally due to Atkinson [Atk75]. It runs in time that is just a tiny bit
slower than O(kn), and for all practical purposes it can be regarded as being
O(kn). It relies on one of the standard algorithms from computer science,
the UNION-FIND algorithm; see, for example, Sections 4.6 and 4.7 of
[AHU74]. We shall encounter what is essentially the same algorithm again
in Section 5.1 in connection with coincidence processing in coset enumeration.
If, as is usually the case, we want to find all minimal block systems
preserved by G (and hence test G for primitivity), it appears at first sight
that we need to run this test n - 1 times, on the pairs of points {1, α} for
2≤α≤n, thereby rendering the complexity of primitivity testing O(kn2).
If α and ß lie in the same orbit of the point stabilizer H := G1 on {2 .. n},
then there exists h ∈ H mapping {1, α} to {1, ß}, and so a block for G contains
{1, α} if and only if it contains {1, ß}. We can therefore reduce the number of
tests by testing only the pairs {1, α} for orbit representatives α of H. If we
already know a base and strong generating set for G then, assuming that the
first base point is 1, we will already know generators for H, and so we can
easily calculate the orbits of H. Even if we do not know H already, then we
can quickly generate a subgroup of H using repeated calls of RANDOMSTAB.
But primitivity testing by this method still has quadratic complexity,
and this will be noticeable when n is large and H is small. A nearly-linear-
time algorithm is described by Beals in [Bea93a]. An alternative version of
complexity O(nlog3 |G|+nk log |G|) due to Schönert and Seress is described
in [SS94] and in [Ser03]; this may be faster for small base groups of large
degree. Here, we shall content ourselves with describing the Atkinson
method, which does seem to perform satisfactorily in practice for degrees
in the millions. It has the advantage of relative simplicity.
4.3.2 The Atkinson algorithm
The displayed function MINIMAL BLOCK manipulates an equivalence
relation ~ on {1.. n}. We start by putting the k given points in the same
equivalence class, and all other points in separate classes. During the
function some of these classes are merged, and the final returned value of
~ is the G-congruence generated by {(α1, αi) | 2≤i≤k}. At any stage in the
algorithm, each equivalence class will have a stored representative.
We shall first present and prove the correctness of the algorithm in this
basic form, and then discuss how the equivalence class merging process
can be implemented efficiently. Representatives of classes that are merged
with other classes and then cease to be representatives are queued in a list
q of length l, and this queue is initialized to contain {αi |2≤i≤k}. The main
‘While’ loop of the procedure processes the points in the queue in turn. The
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
84
equivalence class of α ∈ [1..n] under ~ is denoted by CLASS(α), and the
representative of the class containing α by REP(α). As usual, we denote the
Given generating set of G by X.
MINIMALBLOCK(G, {α1, …, αk})
Input: , 
, G transitive, α1, …, αk ∈ [1. .n]
Output: G-congruence ~ generated by { (α1, αi) |2≤i ≤ k}
1
Initialize ~ with classes {αi|1≤i≤k} with representative α1,
and { {γ} | γ  αi (1≤i≤k)}.
2
for i∈[1.. k-1] do q[i]:=αi+1;
3
l:=k–1; i:=1;
4
while i≤l
5     
do γ:=q[i]; i:=i+1;
6     
for x∈X
7     
do δ:=REP(γ); κ:=REP(γx); λ:=REP(δx);
8     
if κ≠λ
9     
then Merge classes CLASS(κ) and CLASS(λ), and
10     
make κ representative of combined class.
11     
l :=l+1; q[l] := REP(λ);
12 return ~;
Example 4.2
Let n=6 and G=〈x1, x2〉 with x1=(1, 2, 3, 4, 5, 6), x2=(2, 6) (3, 5) (Example 2.2),
and let us run through the algorithm with α1=1, α2=3. We start by making
1 the representative of the class {1, 3} and putting 3 on the queue. Going
into the main loop with γ=3, with x=x1 we get δ=1, κ=4, λ=2, so we
amalgamate classes {2} and {4}, make 4 the representative, and add 2 to the
queue. With x=x2, we get δ=1, κ=5, λ=1, so we amalgamate {1, 3} and {5},
make 5 the representative, and add 1 to the queue. Moving onto the next
element, γ=2, in the queue, with x=x1 we get δ=4, κ=λ=5, but with x=x2 we
get δ=4, κ=6, λ=4, so we amalgamate {2, 4} and {6}, make 6 the representative,
and add 4 to the queue. Then, γ=1, x=x1 gives δ=5, κ=λ=6; γ=1, x=x2 gives
δ=5, κ=λ=5; γ=4, x=x1 gives δ=6, κ=λ=5; and γ=4, x=x2 gives δ=6, κ=λ=6. So
the equivalence classes of the relation returned are {1, 3, 5}, {2,4, 6}, and
these are the blocks of the corresponding block system preserved by G.     
Let us now prove that the algorithm does what is claimed.
THEOREM 4.3 The equivalence relation R returned by MINIMAL BLOCK
is the G-congruence generated by {(α1, αi)|2≤i≤k}.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
85
PROOF We will denote the final returned value of the equivalence relation
~ by ~F, and the G-congruence generated by { (α1, αi) | 2≤i≤k} by ≡. We
have to show that ~F and ≡ are equal. We first show that, at any point in
the algorithm, we have µ~ν implies µ≡ν, for any µ, ν ∈ Ω. This is certainly
true after the initialization stage, when {αi|1≤i≤k} is the only nontrivial ~-
class. Whenever two classes are merged during the course of the algorithm,
they contain the images γx and δx under the group element x of two points
γ and δ for which γ~δ before the merging. We may therefore assume
inductively that γ≡δ. Since ≡ is a G-congruence, we have γx ≡ δx, and so the
property “µ~ν implies µ≡ν” remains true after the merging. Hence it is
true at all times, so ~F⊆≡.
Conversely, to show that ≡⊆~F, it is sufficient to show that ~F is a G-
congruence, because it certainly contains { (α1, αi)|2≤i≤k}. So we must
prove that µ~F ν implies µg~F νg for any g∈G. Clearly it suffices to prove
this for the generators g=x of G. (Since G is finite, we need not worry about
inverses of generators.) Notice that whenever a point λ is added to the
queue q, we have REP(λ)=λ before adding λ to the queue q, and REP(λ)≠λ
immediately afterwards. It is possible that REP(λ) will be redefined again
later in the procedure, but it will always be put equal to an existing class
representative, so it will never equal λ again. Hence, at all times, λ is in the
queue if and only if REP(λ)≠λ. (This argument shows that each element is
added to the queue at most once, and so the procedure must terminate!)
Let lF be the length of the queue at the end of the algorithm. For λ ∈ [1.. n],
define w(λ)=k if q[k]=λ, and w(λ)=lF+1 if λ is not in the queue at the end of
the algorithm. We use induction on z := 2lF+2 –w(µ)–w(ν). If z=0, then
neither µ nor ν is in the queue so, by the remark above, REP(µ)=µ and
REP(ν)=ν. But then µ~F ν implies µ=ν and there is nothing to prove. If z>0,
then at least one of µ, ν, is in the queue, say µ=q[k]. Then, when we reach
i=k in the main loop of the algorithm and consider the action of generator
x, we have γ=µ and δ=REP(γ)≠γ. At this point, δ is a ~-class representative,
so is not in the queue. Hence we must have w(δ)>w(γ). The classes of γx and
δx are now amalgamated, so γx~F δx . Since w(δ)>w(γ), we have δx~F νx by
inductive hypothesis, and the result follows.
4.3.3 Implementation of the class merging process
We now move on to the question of how we implement the ~–equivalence
class merging process. The algorithm for this process (UNION-FIND), which
we shall now describe, is analyzed in detail in Sections 3.6 and 3.7 of [AHU74]
and it follows from that analysis that MINIMAL BLOCK will run in time
that is microscopically longer than O(kn).
The information on the classes under ~ is stored in an array p, defined
on [1. .n], which will always satisfy the properties: 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
86
REP(κ,~p)
Input: κ, ∈ [1..n], array p
Output: Representative of class containing κ,
1
λ:=κ; ρ:=p[λ];
2
while ρ≠λ do λ:=ρ; ρ:=p[λ];
(* Now perform path compression *)
3
µ:=κ; ρ:=p[µ];
4
while ρ≠λ do p[µ]:=λ; µ:=ρ; ρ:=p[µ];
5
return λ;
MERGE(κ, λ,~c,~p,~q,~l)
Input: κ, λ ∈ Ω, c, p, q, l
1
ϕ:=REP(κ, ~p); ψ:=REP(λ, ~p);
2
if ϕ≠ψ
3     
then if c[ϕ]≥c[ψ]
4     
then µ:=ϕ; ν:=ψ;
5     
else µ:=ψ; ν:=ϕ;
6     
p[ν]:=µ; c[µ]:=c[µ]+c[ν];
7     
l:=l+1; q[l]:=ν;
MINIMALBLOCK(G, {α1,…, αk})
Input: G=〈X〉≤Sym(n), G transitive, α1,…, αk ∈ [1. .n]
Output: G-congruence ~ generated by { (α1, αi)|2≤i≤k}
1
for i∈[1..n] do p[i]:=i; c[i]:=1;
2
for i∈[1.. k–1] do p[αi+1]:=α1;
3
for i∈[1..k–1] do q[i]:=αi+1;
4
c[α1]:= k; i:=1; l:=k–1;
5
while i≤l
6     
do γ:=q[i]; i:=i+1;
7     
for x∈X
8     
do δ:=REP(γ, ~p); MERGE(γx, δx, ~c, ~p, ~q, ~l)
9
for i∈[1..n] do REP(i,~p);
10 return p;
for all α∈[1..n]. So, for α∈[1..n], we can find REP(α) by continually replacing
α by p[α] until it becomes constant. It increases the efficiency of later class
representative calculations if, whenever we find REP(α)=ß in this way, we
set p[γ] equal to ß for all γ in the p-chain from α to ß. This process is known
as path compression and is done in the function REP below, which takes
the array p as a (mutable) second argument.
Merging of the two classes with representatives κ and λ can then be
accomplished simply by putting p[κ]:=λ. It turns out to be more efficient to
choose the new representative from the larger of the two classes being
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
87
merged. To do this, we maintain another array c (cardinality) such that, for
class representatives α, c[α] is equal to the size of that class. The procedure
MERGE performs the merging operation, updates the array c, and adds the
deleted class representative to the queue q. The revised MINIMAL BLOCK
function uses REP and MERGE.
The purpose of line 9 in MINIMAL BLOCK is to force path compression
and thereby ensure that the array p returned satisfies p[α]=REP(α) for all α.
There is a further simple improvement that we could easily build in.
Since we are assuming that G is transitive, we know that the any block
system preserved by G has blocks of size dividing n. Let q be the smallest
prime dividing n. Then if ever a class grew larger than n/q, we could
immediately abort the process and make all elements of [1..n] equivalent.
Exercises
1.
Prove Theorem 4.2 assuming the theorem of Jordan.
2.
Work through MINIMAL BLOCK with G as in Example 2.2, first with
input points {1, 4} and then with input points {1, 2}.
3.
Why is the assignment δ :=REP(γ); in line 7 of the first version of MINI-
MALBLOCK (and in line 8 of the second version) inside rather than
outside of the loop over the generators in X? Would the algorithm still
work if it were moved outside?
4.4 Bases and strong generating sets
4.4.1 Definitions
In 1970 [Sim70], Sims introduced a chain of subgroups in a finite permutation
group, which plays a very similar role to that played by the chain of subspaces
defining the echelon form representation of a subspace of a vector space.
We shall now introduce some notation that we shall retain throughout
this section, and indeed throughout the remainder of the book. We
assume that G is a finite permutation group acting on {1..n} and
generated by a finite sequence S of elements of Sym(n). Let B=[ß1,…,ßk]
be a sequence of distinct elements of Ω. Define G(i) := Gß1,…,ßi—1 for
1≤i≤k+1 (so G(1)=G).
Now, for 1≤i≤k+1, let S(i) :=S∩G(i) 
, and 
. We
let U(i) be a right transversal of 
 in H(i); so, by the Orbit-Stabilizer
theorem, we have 
 where 
 maps ßi to ß.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
88
Note that, for given B and S, it is straightforward to compute the subsets
S(i), and then the sets ∆(i) and U(i) can be computed using the orbit
algorithms described in Section 4.1. The transversals U(i) can either be
computed explicitly and stored, or their corresponding Schreier vectors
can be computed. If they are stored explicitly, then we still need to store a
characteristic function of ∆(i) in {1..n}, because we need to be able to test
points for membership in ∆(i). For convenience, we shall use ∆* to denote
the list of orbits ∆(i), together with the chosen data structures for computing
the 
 and testing points for membership in ∆(i).
The sequence B is said to be a base for G if the only element in G that
fixes each of ß1,…,ßk is the identity. That is, if G(k+1)=1, and hence
The sequence S is said to be a strong generating set for G relative to the
base B if it includes generators for each stabilizer G(i) in the chain above;
that is, for 
. Note that this is true by
definition for i=1.
(The expression ‘strong generating set’ is now firmly entrenched in the
CGT literature but, for reasons outlined in Subsection 2.1.4, we prefer to
regard S as an ordered set or sequence.)
For brevity, we shall say that (B, S) is a BSGS for G, if B is a base and S
is a strong generating set relative to B. In that case, G(i) is called the i-th
basic stabilizer, and 
 the i-th basic orbit.
If (B, S) is a BSGS, then the sequence of transversals U(1),…,U(k) provides
us with a convenient normal form for the elements of G, since every
element g∈G has a unique representation 
.
Note that the order of the group can be read off from the transversals, since
If B=[ß1,…,ßk] is a base, and g∈G, then 
 is called the base
image of g (relative to B).
LEMMA 4.4 The base image of g relative to a base B of G uniquely determines
the element g∈G.
PROOF If Bg=Bh for g, h∈G, then 
 and so gh-1=1 by the definition
of a base.     
One of the advantages of representing elements by means of base images
arises from the fact that, for many interesting groups, the size of a base B
may be rather small compared to the degree of the group. Clearly a
permutation group G of degree n with a base of length k satisfies |G|≤nk.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
89
It turns out that the groups in certain important families have permutation
representations with a base of length polylogarithmic in their degree.
Such families are called families of short base groups. They have associated
constants c and d such that log |G|≤dlogc|Ω| for all groups G in the family.
The nonalternating nonabelian finite simple groups, and the primitive
permutation groups that do not have an alternating group as a composition
factor are examples of families of small base groups.
The worst case occurs for the symmetric group Sn: it is clear that a base
must contain n-1 points (and that any n-1 will do); choosing B:=[n, n- 1,…,2],
one finds that G(i)≅Sn—i+1, the full symmetric group acting on the first n-i+1
points (which form the i-th basic orbit).
The usefulness of the concept of a BSGS is supported by the following
(empirical) observations.
Universality: For the great majority of fundamental permutation group
algorithms, a BSGS appears to be the most appropriate way to represent
the group.
Inheritability: Almost all algorithms that are used to construct subgroups
and homomorphic images of a permutation group G have the property that
the subgroup or homomorphic image inherits a BSGS from that of G.
Availability: Effective algorithms can be designed for constructing BSGS
for groups G.
Before turning to the central problem of how we construct a BSGS of a
finite permutation group, we shall assume for the moment that these are
given, and explain how we use them to test membership in our group G of an
arbitrary permutation in Sym(Ω). This is accomplished by the function STRIP.
STRIP(g, B, S, ∆*)
Input: g ∈ Sym(Ω), B, S, ∆* as described above
Output: h ∈ Sym(Ω) and i ∈ [1..k+1]
1
h:=g;
2
for i∈[1..k]
3    
do (* h fixes base points ß1,…,ßi–1 *)
4    
;
5    
if ß ∉∆(i) then return h, i;
6    
Let 
 with 
;
7    
;
8
return h, k+1;
If the element h returned is the identity, then 
, and so
g∈G. Conversely, if g∈G and (B, S) is a BSGS for G, then g has a unique
expression as 
 with 
 and the function will find
these ui and return h=1G. Hence, if (B, S) is a BSGS for G, then g∈G if and
only if h=1G. If an integer i≤k is returned, then the membership test ß∈∆(i)
failed and the function aborted. The output in that situation will be used
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
90
later. The function could also be made to return the elements ui if the
decomposition of g was required. As we shall see later, STRIP can be usefully
applied even when (B,S) is not known to be a BSGS for G.
4.4.2 The Schreier-Sims algorithm
We now present a basic version of the Schreier-Sims algorithm for determining
a base and strong generating set of a permutation group. It is based on the
following simple result.
LEMMA 4.5 Let B, S, S(i) and H(i) be as defined above. Then (B,S) is a
BSGS for G if and only H(k+1)=1 and 
 for 1≤i≤k.
PROOF By definition, (B, S) is a BSGS if and only if G(k+1)=1 and H(i)=G(i)
for 1≤i≤k. Since H(1)=G(1) and 
 for 1≤i≤k, the condition in the
lemma is certainly necessary for (B,S) to be a BSGS. Conversely, if the
condition holds, then we see by induction on i that H(i)= G(i) for 1≤i≤k+1,
and then the assumption H(k+1)=1 implies that G(k+1)=1.     
The Schreier-Sims algorithm displayed in SCHREIERSIMS takes an initial
sequence B (which may be empty) and generating sequence S for G as
input, and extends B and S to a BSGS for G. It starts by extending B if
necessary to ensure that no element of S fixes each point in B, and then
sets up the basic orbits and associated transversals. At this stage we certainly
have H(k+1)=1, and the algorithm proceeds by testing the conditions
 for i = k, k-1,…,1. This is done in the main loop of the
algorithm, starting at line 6. Since 
 by definition, we only need
to test that 
 which we do by testing that generators of  
 lie in
H(i+1).
These generators of 
 are found using Schreier’s theorem (Theorem 2.57), as
described in the algorithm ORBITSTABILIZER in Section 4.1. In an
implementation, we should be careful to consider only those Schreier
generators that are not trivial by definition, as defined in Section 4.1. It is
convenient to do the tests in the order i=k, k-1,…,1 because, by doing that,
we know that, when we are testing a particular i, the required condition is
satisfied for larger i, and so we can use the algorithm STRIP to test the
generators of 
 for membership in H(i+1).
If this membership test fails for some Schreier generator g, then we set
the Boolean variable y to false, and adjoin a new generator h to S(i+1),
thereby replacing H(i+1) by a larger subgroup of G(i+1). (The new generator h
appended is not necessarily g itself, but is rather the element output by
STRIP applied to g.) If h fixes all existing base points, then we adjoin a new
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
91
SCHREIERSIMS(~B,~S)
Input: B and S as defined above.
1 for x∈S do if 
2  
then Let γ∈Ω with γx≠γ; APPEND(~B,γ); k:=k+1;
3 for i∈[1..k]
4  
do S(i):=S∩Gß1…,ßi
1 
; 
;
(* Now H(k+1)=1 *)
5 i:=k;
6 while i≥1
7  
do (* Test condition 
 *)
8  
for ß∈∆(i)
9  
do Find 
 with 
;
10  
for x∈S(i) do if 
11  
then (* Test if Schreier gen. 
 *)
12  
y:=true;
13  
h, j:= STRIP (
);
14  
if j≤k
15  
then (* New strong gen. h at level j *)
16  
y:=false;
17  
elseif h≠1
18  
then (* h fixes all base points *)
19  
y:=false;
20  
Let γ∈Ω with γh≠γ;
21  
APPEND(~B,γ);
22  
k:=k+1; S(k):= ;
23  
if y=false
24  
then for l∈[i+1..j]
25  
do APPEND(~S(l), h);
26  
;
27  
;
28  
i:=j;
29  
continue i;     
(* 
 verified *)     
(* Condition 
 is verified *)
30  
i:=i-1;
31
base point moved by h to B, thereby maintaining the condition H(k+1)=1 of
the lemma.
For a particular i in SCHREIERSIMS, each new generator that we append
to S(i) strictly increases the group H(i), so we can only append generators
finitely many times, and the procedure must terminate. When it does
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
92
terminate, all of the conditions of the lemma have been verified, and so (B, S) is
a BSGS for G.
Notice that we do not maintain the condition S(i)=S∩G(i) throughout the
procedure. It is considerably more efficient if we adjoin new generators
found for a particular i only to S(l) for l>i, because they would be redundant
as generators of H(l) for l≤i, and would significantly increase the time taken
by the loop over the elements of S(l) for l≤i.
Example 4.3
Let n=5 and S=[a,b], with a=(1, 2, 4, 3), b=(1, 2, 5, 4). The default is to start
with B empty, and then the procedure will begin by adjoining 1 to B, so we
have B=[1], k=1, and no element of S fixes B pointwise. Using ORBIT, we
have S(1) = S, and calculate ∆(1)=[1, 2, 4, 5, 3], with
We now enter the main loop of the algorithm at line 6 with i=1. Looping
through ∆(1)=[1, 2, 4, 5, 3], we start with ß=1, 
. Then ßa=2 and
 but ßb=2 and the associated Schreier generator is
. Since k=1, STRIP applied to (2, 5)(3, 4) will
return (2, 5) (3, 4) and 2, so we put c:=(2, 5) (3, 4), append the point 2, moved
by c, to B, increment k to 2, and set S(2) to [c], We also calculate ∆(2)=[2, 5],
with U(2)=[1, c]. (Note that we do not adjoin c to S(1), because H(1) is unchanged,
and c would be redundant as a generator of H(1).)
We now jump back to the beginning of the main loop at line 6 with i=2,
and find that the two associated Schreier generators cc–1 and c2 are both trivial
(the first by definition), so we return to line 6 with i=1. The Schreier generator
 that caused the problem before now strips to the identity, so we move
on to 
. Here both Schreier generators are trivial by definition,
so we can proceed to 
. We have ußa≡ußa, but ßb=1, so the
associated Schreier generator is 
. Since 3=2a2b is not in
∆(2), STRIP applied to a2b returns a2b and 2. So we put d:=a2b and append d to
S(2). We now have S(2)=[c,d] and we recalculate ∆(2)=[2, 5, 3, 4] with U(2)=[1, c,
d, cd].
Again we jump back to line 6 with i=2. The Schreier generators not
trivial by definition are c2 (for ß=5), dc(cd)–1 and d2c–1 (for ß=3), and cdcd–
1 and cd2 (for ß=4), and these are all trivial, so we go back to line 6 with
i=1 for the third time. On the previous pass, we had got as far as ß=4, and
the Schreier generator a2b now strips successfully to a2bd–1=1. Moving on
to 
 we find that the associated Schreier generators are
aba(ab)–1=(2, 3, 5, 4), which strips to aba(ab)–1d–1=1 and ab2a–2 = (2, 3, 5,
4), which again strips to 1. Finally, with 
, the Schreier
generators are a4=1, and a3ba–3=(2, 4, 5, 3), which strips to a3ba–3(cd)–1=.
So the algorithm terminates, and we have shown that G is a group of
order |∆(1)||∆(2)|=20.    
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
93
The observant reader will have noticed an inefficiency in SCHREIERSIMS.
When we return to line 6 with a value of i that has occurred previously then,
if S(i) has not changed since the previous occurrence, we do not need to repeat
the checks for those Schreier generators that have already been tested. Indeed,
even a Schreier generator that failed the test previously will now pass it because
of the new generator that has been appended. It is routine to modify the code to
remember where we have got to on any previous occurrences of each i. Indeed,
in the version given in Algorithm 3, page 136 of [But91], this repetition is
avoided even when S(i) has changed, because the existing orbit and transversal
are extended rather than recalculated.
4.4.3 Complexity and implementation issues
We shall refer the reader to other sources for detailed complexity analyzes of
the Schreier-Sims algorithm. The first major implementation decision is
whether to calculate and store the transversals U(i) explicitly, or whether to
use Schreier vectors. The former method generally results in lower complexity
and faster running times, but the space requirement is much greater. If we
wish to work with groups of degree more than about 1000, then storing the
U(i) becomes impractical.
The running time of a version of Sims’ algorithm that stores the transversals
U(i) was shown by Furst, Hopcroft Luks in [FHL80] to be O(n6+kn2). Using
the so-called labelled branching data structure for the U(i), Jerrum [Jer82]
devised a variant with running time O(n5+kn2). Knuth [Knu81] describes
another version with running time O(n5+kn2). These results are all presented
in Chapter 14 of [But91]. Chapter 4 of [Ser03] contains detailed analyzes of
several variations, including those that use Schreier vectors.
We shall now discuss some features of the algorithm for small base groups.
This is an important case, because many computations with permutation
groups in practice take place in groups with large degree but with a small
base, typically with size less than 10, say. In this situation, we certainly use
Schreier vectors for calculating transversal elements and, what is more, we
must avoid multiplying complete permutations together so far as possible.
To help us avoid multiplying permutations, we introduce a data structure,
which we shall call a permutation word. Theoretically, this is just a list
[g1, g2,…,gr] of permutations, which represents the product g1g2…gr. The
elements of the list are, however, stored as pointers or index numbers of
permutations, so that lists can be manipulated without copying complete
permutations. We adopt the policy of storing inverses of all stored
permutations, including the permutations in the initial generating sequence
S of the group, and any new generators appended during the Schreier-
Sims algorithm. Then a permutation word can be easily inverted by
reversing the list and replacing each entry by its inverse, and two
permutation words can be multiplied simply by concatenating them. The
image of a single point in Ω under a permutation word can be computed in
time proportional to the length r of the word.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
94
Many computations with small base groups, including most of the steps
in the Schreier-Sims algorithm, can be carried out by looking at images of
base points under permutation words. In particular, the algorithm U-BETA
can be easily adapted to output a permutation word with entries in S rather
than a permutation. In Example 4.1, the modified version of U-BETA applied
to ß=6 would return [x1, x2, x2] as a word representing the permutation
(1, 6, 3, 4, 7) (2, 5), which maps 1 to 6. Then STRIP can be modified so that
it takes a permutation word as input and returns a possibly modified
permutation word as output. The Schreier generators in SCHREIERSIMS
can be computed as permutation words. If the integer returned by STRIP
for a Schreier generator is less than k+1, then we need to append the group
element output to S, and in that case we do need to multiply out the word
and store it and its inverse as complete permutations.
The above discussion also shows that each new strong generator that is
appended to S during SCHREIERSIMS arises as a word in the existing
strong generators. It is therefore possible to associate with each strong
generator an SLP element that expresses it as a word in the earlier
generators. An implementation of the algorithm should have the option of
returning these SLP elements because, as we shall see in Section 4.5 below,
they may be needed for calculations involving group homomorphisms. Note
that the modified version of STRIP that we have just described can be used
to express an arbitrary permutation in g as a word in the strong generators
and their inverses; this is also important for homomorphism calculations.
Unfortunately, we also need to multiply out the word when STRIP
returns k+1, because we have to test whether the word represents the
identity. Surprisingly, it is this innocent-looking test at line 17 of
SCHREIERSIMS that takes up nearly all of the time when running it on a
small base group. One consequence is that the complexity of the algorithm
is worse than O(n2) even if the base size is regarded as a constant.
For this reason, it is worth noting that if, for some reason, we already
know that B is base for G, and STRIP returns h and k+1, then h fixes all
base points, so we must have h=1, and we do not need to multiply out the
permutation word for h to check this. A ‘known-base’ version of
SCHREIERSIMS differs only from the standard version in that the test for
h=1 is omitted, but it runs faster by a factor of about n/k in practice. One
common situation where this occurs is when G is a subgroup of some larger
group K≤ Sym(Ω), and we already know a small base B for K. Then B is also
a base of G. This observation enables many computations with subgroups of
a given group to run very fast.
In particular, an SGS for the join 
 of two subgroups H, K≤G for
which a base of G is known is easily computable. We just apply the
‘knownbase’ version of SCHREIERSIMS to the union of the generating
sets of H and K. Unfortunately, the intersection H∩K is much harder to
compute in general. We shall discuss that in Subsection 4.6.6 below.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
95
4.4.4 Modifying the strong generating set—shallow
Schreier trees
(This subsection may be omitted on a first reading.) We are now going to
discuss two apparently contradictory ideas. First we shall consider the
problem of removing redundant strong generators, and then we shall discuss
situations under which it might be a good idea to adjoin some new redundant
ones! In fact it is perfectly sensible to carry out the first of these processes
followed by the second. Redundant strong generators tend to be removed
from S(i) for low values of i, whereas the new ones that we adjoin are more
often for high values of i. We assume throughout the subsection that a
BSGS (B, S) has already been computed for G.
What often happens in SCHREIERSIMS is that new generators appended
to S(i) during the algorithm render some generators of S(j) for j<i redundant
as generators of S(j). If we wish to save some space by removing these,
then we can proceed as in the following outline algorithm:
REMOVEGENS(B, ~S, ~ ∆*)
Input: BSGS data structure for permutation group
1
for i∈[k.. 1 by–1], g∈S(i)\S(i+1)
2
do if 
 then remove g from S;
It is probably advisable in practice to modify the above procedure so that it
does not eliminate the original generators of G. One reason for this is that
images of the original generators are often used to define homomorphism
ϕ: G→H. If the original generating set is inordinately large (which can
sometimes happen for groups computed as Sylow subgroup of larger groups,
for example), then it is preferable to reduce it, redefine G, and recalculate the
strong generating set using a known-base version of SCHREIERSIMS.
Now we turn to the situation where we might adjoin new strong generators.
There is a problem that occasionally arises with Schreier vector calculations
that can adversely affect running times. Typically, for long orbits ∆, the
length of the permutation word returned by ORBITSV (that is, the length of
the coset transversal element returned as a word in S) is of order log(|∆|),
but it can occasionally be as long as ∆ itself. This occurs, for example, when
the group is a large cyclic group and |S|=1, a situation that can arise during
the Schreier-Sims algorithm: whenever we adjoin a new base point, we initially
have a single generator that fixes the other base points but moves the new
one, and so we are potentially in that bad situation for the orbit at the bottom
level. This can result in an extra factor O(n) rather than O(log(n)) in the
complexity of the complete algorithm, and so it is important in practice to
find a way of avoiding it.
The following function seeks to solve this problem by adjoining extra
random chosen generators of the input group G. This approach was first
described and analyzed by Cooperman, Finkelstein, and Sarawagi in [CFS90].
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
96
We have modified it by keeping the original generators X of G, which would
help to reduce storage requirements in an implementation. It requires the
size m of the orbit to be calculated to be known in advance, but in an
implementation we would only wish to use this method for large orbits
with small initial generating sets, and so we would want to precompute m
by using the basic ORBIT algorithm in any case.
SHALLOWORBITSV(α, ~X, m)
Input: α∈[1 . . n], X=[x1,…, xr]⊆Sym(n) with 
Output: αG and Schreier vector v for α
(* The generating sequence X of G may be enlarged *)
1 For i ∈ [1..n] do v[i] := 0;
2 v[α] := -1;
3 ∆ :=[α];
4 for xi ∈ X do if 
5
then APPEND
6 X, W:=PRINITIALIZE(X, 10, 20);
7 while |∆|≠m
8
do repeat g:=PRRANDOM(~ X, ~W)
9
until |∆∪∆g|/|∆| is large;
10
r:=r + 1; xr:=g; ∆:=∆;
11
for xi∈X, ß∈∆ do if 
12
then APPEND(~∆, ßxi); v[ßxi]:=i;
13
∆:=∆;
14 return ∆, v;
Of course, we have not yet specified what we mean by the condition
“|∆∪∆g|/|∆| is large” in this function. The idea is that we only want to
adjoin the new random element as a new generator if it is effective in
increasing the current orbit size. We could use the following specific criterion
from Lemma 4.4.5 of [Ser03]. Let p=0.46. Then ‘large’ means:
 
It is proved in [Ser03] that, with this choice, the probability of a random
element g∈G satisfying this condition is at least p, and so we can expect to
find suitable elements g quickly. Furthermore, we will have |X|≤2 log2(m)+
4+r after a call of SHALLOWORBITSV, where r is the initial value of |X|,
and the length of the words output by calls of U-BETA using the Schreier
vector output by SHALLOWORBITSV will also be at most 2 log2(m)+4+r.
If we were using this function on the basic orbits ∆(i) of a group G, and
appending new strong generators to S(i), then we would also need to store
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
97
any new generators as SLP elements in the existing generators. Since the
function PRRANDOM returns the required SLP element together with
each random element g that it returns, this presents no difficulty, and we
omit the technical details.
A different method for calculating shallow Schreier trees, which was
originally proposed in [BCFS91], is discussed in Section 4.4 of [Ser03].
4.4.5 The random Schreier-Sims method
Let (B, S) be as before, and suppose that we are given a random element
g∈G using a uniform distribution on G. If (B, S) is not a BSGS for G, then
it is not hard to prove that STRIP(g, B, S, ∆*) returns a nonidentity element
h with probability at least 1/2. We can then use the output of STRIP to
extend (B, S), as we did in the Schreier-Sims algorithm.
Furthermore, if (B, S) is not a BSGS and we apply STRIP to w elements
of G, then the probability that the identity is returned each time is at most
2-w. In other words, if STRIP returns the identity on each of, say, 10 random
elements of G, then we can be highly confident that (B, S) is a BSGS for G.
This observation is the basis of the following algorithm, which runs much
more quickly than SCHREIERSIMS and, with high confidence level, yields
a BSGS for G.
It is generally known as the ‘Random Schreier-Sims algorithm’, which
is really a misnomer, because it uses random elements rather than Schreier
generators! The name dates from the first implementation, which was
described by Leon in [Leo80b].
Although we have omitted the details in the displayed procedure
RANDOMSCHREIER, the SLP elements returned as a second value by
PRRANDOM should be stored for the new strong generators appended to S.
One common situation in which a variant of RANDOMSCHREIER is most
useful is when we know the order of G in advance. In that case, we do not
use c and w to determine when we halt; rather, we can stop as soon as the
product of the orders of the basic orbits is equal to |G|. This occurs, for
example, if we start with known generators of a standard group, such as
PGL(n, q), or if G was constructed as a wreath product of two smaller groups.
In general, however, although we can be highly confident that (B, S) is a
BSGS after a call of RANDOMSCHREIER, the consequences of an error
tend to be dire, so we prefer to verify the result. (Our confidence level may
also be decreased by any doubts that we may have about the product
replacement algorithm for producing random elements.) The verification
can be done by calling SCHREIERSIMS on the (B, S) produced by
RANDOMSCHREIER: a run of RANDOMSCHREIER followed by a
verification by SCHREIERSIMS is usually significantly faster than calling
SCHREIERSIMS on the original generating set S with B empty. But, in an
implementation, we would arrange for RANDOMSCHREIER to return the
sets S(i) individually, and pass these on to SCHREIERSIMS, in order to
avoid using redundant generators of H(i).
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
98
RANDOMSCHREIER(~ B, ~ S, w)
Input: B and S as in SCHREIERSIMS, w∈N.
1
X, W:=PRINITIALIZE(S, 10, 20);
2
for x∈S do if x∈Gβ1…βk
3
then Let γ∈Ω with γx≠γ; APPEND(~B, γ); k:=k + 1;
4
for i∈[1.. k]
5
do 
;
(* Now H(k+1) = 1 *)
6
c:=0;
(* c counts the random elements sifted without change to (B, S) *)
7
while c<w
8
do g:=PRRANDOM(~X,~W);
9
h, j:=STRIP(g, B, S, ∆*);
10
y:=true;
11
if j≤k
12
then (* New strong generator h at level j *)
13
y:=false;
14
elseif h≠1
15
then (* New strong generator h fixes all base points *)
16
y:=false;
17
Let γ∈Ω with γh≠γ; APPEND(~B, γ);
18
k:=k + 1; S(k):=[];
19
if y=false
20
then for l∈[2.. j]
21
do APPEND(~S(l), h);
22
 
;
23
c:=0;
24
else c:=c+ 1;
25
For small base groups of large degree, however, there are much quicker ways
of verifying the correctness of (B, S), which we shall discuss in Chapter 6.
4.4.6 The solvable BSGS algorithm
We shall now describe an alternative method of computing a base and
strong generating set in a solvable permutation group G; this method was
described by Sims in [Sim90a]. See also Section 7.1 of [Ser03] for a
complexity analysis; it turns out that, if we use shallow Schreier trees as
described in Subsection 4.4.4, then the algorithm is nearly-linear-time.
Sims observed that his implementation ran significantly faster than the
standard Schreier-Sims. It can safely be used on groups that are not known
for certain to be solvable, because it quickly halts and reports failure when
the input group is not solvable.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
99
A further advantage of the algorithm is that the strong generating sequence
for G that it computes can be reordered to form a polycyclic sequence for G;
that is, a generating sequence [x1,…, xr] with the property that, if Gi
:=
 for 1≤i≤r+1, then Gi+1
Gi for 1≤i≤r.
Polycyclic sequences, and the algorithms that use them and their
associated polycyclic presentations as a framework for computing in
polycyclic groups will form the subject of Chapter 8. Algorithms for finite
solvable groups G defined using a polycyclic presentation of G generally
perform faster than algorithms to carry out the same computations in a
permutation representation of G. So, if we are given a finite solvable
permutation group in which we wish to carry out nontrivial structural
computations, then it is likely to be worthwhile to use the solvable BSGS
algorithm to transfer to a polycyclic presentation of the group.
Another important feature is that the series {Gi} of subnormal subgroups
of G includes a series of normal subgroups of G with abelian factor groups
as a subsequence. This can easily be refined, if required, to a series of
normal subgroups with elementary abelian factors. As we shall see in
Section 8.5, such series are used in structural computations in finite
solvable groups.
We shall describe the method from the bottom up. We start with a
procedure NORMALIZINGGENERATOR, which takes a BSGS (B, S) for a
permutation group N and a permutation g that normalizes N as input, and
extends (B, S) to a BSGS for 
. We shall prove in Proposition 4.9 that g
permutes the orbits of N. So 
 is a union of m orbits of N, including the
first basic orbit 
 where m>0 is minimal such that gm fixes ∆(1).
Let h:=gmu-1, where u∈N satisfies 
 Then 
 
and 
. These considerations justify the
procedure NORMALIZINGGENERATOR. In addition to updating the BSGS,
a list U of the new strong generators appended to S is returned. It is not
hard to show that, if T is a polycyclic sequence for N, then U cat T is a
polycyclic sequence for 
.
The next procedure S-NORMALCLOSURE also takes a BSGS (B, S) for
a permutation group N and a permutation w normalizing N as input. In
addition, it takes generators X of a larger permutation group G as input,
where it is known that 
 and that w∈G\N. It starts to compute the
normal closure 
 of 
 in G. There are two possible
outcomes. If it turns out that M/N is abelian, then the BSGS is extended
to a BSGS for M. In addition, a sequence U containing the new strong
generators is returned and is ordered in such a way that, if T is a polycyclic
sequence for N, then U cat T is a polycyclic sequence for M. If, on the other
hand, M/N is not abelian, then a pair of G-conjugates u and v of w such
that the commutator 
 is returned.
S-NORMALCLOSURE is reasonably self-explanatory. Notice that we make
a copy of the original group N in line 1; this is for the purpose of testing
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
100
NORMALIZINGGENERATOR(g, ~ B, ~ S, ~ ∆*)
Input: BSGS B, S, ∆* for N≤Sym(Ω), g∈NSym(Ω)(N)
Output: B, S, ∆* are updated to a BSGS for 
List U of strong generators appended to S is returned
1
U:=[]; h:=g; i:=0;
2
while h≠1
3
do i:=i+1;
4
if i>k (* Add new base point *)
then Let γ∈Ω with γh≠γ;
5
APPEND(~B, γ); k:=k + 1; S(k):=[];
6
Let m > 0 be minimal with 
 ∈ ∆(i);
7
Let u∈H(i) with 
;
8
if m=1
9
then (* Enlarge S(i) and ∆(i) *)
10
APPEND(~S(i), h); 
 
;
11
APPEND(~ U, h);
12
h:=hmu-1;
13 return U;
membership in N and, in an implementation, we would also need to
remember the original input versions of B, S, ∆*. The list C1 initialized in
line 2 consists of the conjugates of w to be processed, whereas C2 consists
of those that have already been processed. Note also that at line 5, a list [g, h]
of two group elements is returned, not a commutator!
S-NORMALCLOSURE(w, ~B, ~ S, ~ ∆*, X)
Input: BSGS B, S, ∆* for N
G≤Sym(Ω), 〈X〉=G, w∈G\N
Output: Either false, [u, v], where u, v are G-conjugates of w with
; or true, U where B, S, ∆* have been updated to
generate 
 with M/N abelian, and U is a list of the
strong generators that were appended to S.
1
;
2 C1:=[w]; C2:=[]; U:=[];
3 for g ∈ C1 do if 
4
then for h∈C2 do if 
5
then return false, [g, h];
6
V:=NORMALIZINGGENERATOR(g,~ B, ~ S, ~ ∆*);
7
U:=V cat U;
8
APPEND(~C2, g);
9
for x∈X do APPEND(~C1, x-1 gx);
10 return true, U;
We turn now to the solvable BSGS algorithm SOLVABLEBSGS. The
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
101
input consists of a generating set S and a possibly empty partial base B for
a permutation group G.
Throughout the procedure, we maintain a BSGS (B, S) for a normal
subgroup N of G. We attempt to use S-NORMALCLOSURE to update the
current N to M 
 with M/N is abelian. We try this with w equal to
one of the original generators of G. If this fails, then S-NORMALCLOSURE
returns u,v∈G such that 
 and we try again with w
replaced by w. We now have w∈[G, G]=G[1] and, after m successive failures
of S-NORMALCLOSURE, we have w∈G[m] on the next call of S-
NORMALCLOSURE.
By a result proved by Dixon in [Dix68], the derived length of a solvable
permutation group of degree n is at most 5 log3 n/2 so, if we get more than
this number of consecutive failures of S-NORMALCLOSURE, then we can
conclude that the input group G is not solvable and give up. On the other
hand, if G is solvable, then we must eventually succeed in enlarging N, and
so the procedure will succeed. In this event, a polycyclic sequence for G is
returned, which will be a reordering of the strong generating set S of G
that has been computed. Note that we have abbreviated S-
NORMALCLOSURE to S-NCL at line 8.
SOLVABLEBSGS(~B,~S)
Input: Generators S of G and a partial base B for G
Output: Either false, if G is not solvable or
true, T where T is a polycyclic sequence for G.
B and S are updated to form a BSGS for G but, unlike in
SCHREIERSIMS, S is completely recomputed
1 X:=S; S:=[]; T:=[];
2 for x∈X
3
do while 
4
do c:=0; w:=x; a:=false;
5
while a=false
6
do c:=c + 1;
7
if c>5 log3 n/2 then return false;
8
a, U:=S-NCL(w, ~ B, ~ S, ~ ∆*);
9
if a=false
10
then w:=U[1]-1U[2]-1U[1]U[2];
11
T:=U cat T;
12 return true, T;
Let T:=[x1,… , xr] be the polycyclic sequence returned by SOLVABLEBSGS,
and let ri:=|Gi/Gi+1| for 1≤i≤r, where the Gi are as defined earlier. If T is to
be used in the algorithms to be described in Chapter 8, then we will also need
to compute the relations in a polycyclic presentation on this generating set.
As we shall see in Chapter 8, to do this it is sufficient to be able to write any
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
102
element of g∈G as a normal form word 
 where, for 1≤i≤r, we have
0≤ei<ri. This is not difficult. The exponents ei are computed and returned
by the outline function NORMALFORMEXPONENTS.
NORMALFORMEXPONENTS(g, T, B, S, ∆*)
1
E:=[];
2
for i∈[1..r]
(* At this stage g∈Gi *)
3
do Use (B, S, ∆*) to write g as a word w in (S∪S-1)*;
4
Let e be the total exponent count of xi in w;
5
APPEND(~E, e); 
;
6
return E;
For this procedure to work as claimed, it is essential that the word computed
for g∈Gi at line 3 should involve the generators 
 only for j≥i. Provided
that the data structure ∆* is updated from its current value whenever S is
extended during SOLVABLEBSGS rather than being completely recomputed
each time, this property will hold automatically. However, extra care would
need to be taken if extra generators had been adjoined to S in order to achieve
the shallow Schreier trees described in Subsection 4.4.4.
4.4.7 Change of base
As we shall see in the following sections of this chapter, virtually all
algorithms for computing properties of a permutation group G require a
BSGS for G to be known, and in many cases they need, or function more
efficiently with, a base for G that might be different from the one found by
the Schreier-Sims algorithm. For example, if we want to compute the
pointwise stabilizer in G of some points α1,…,αr∈[1..n], then the best way
to proceed is to change the base of G to one beginning with the sequence
[α1,…,αr], and then the required stabilizer is just G(r+1).
The fundamental procedure BASESWAP for carrying out base changes
interchanges two adjacent points ßi and ßi+1 in the existing base B. This is
due to Sims [Sim71b, Sim71a].
To prove correctness of BASESWAP, we need to show that the new S at
the end of the procedure is a strong generating set relative to the new
base. The only member of the stabilizer-chain that has changed is G(i+1),
which needs to be changed to 
, so it is enough to show that the
set T, which is adjoined to S in line 10 of the procedure, generates H.
Initially T=S(i+2), and the only elements appended to T have the form yx,
where y, x∈G(i) and yx fixes ßi+1, so we always have T⊆H.
By the orbit-stabilizer theorem, we have
 
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
103
BASESWAP(~B, ~S, ~∆*, i)
Input: BSGS (B, S) for G≤Sym(n), i∈[1..|B|–1]
1
(* s is the size of |∆(i+1)| after the base change *)
2 T:=S(i+2); Γ:=∆(i)\{ßi, ßi+1};
3 while 
4
do Choose γ∈Γ, x∈U(i) such that 
;
5
if 
6
then 
;
7
else Find y∈G(i+1) with 
;
8
if 
9
then T:=T∪{yx}; 
;
10 S:=S∪T;
11
Swap ßi and ßi+1;
12 Remove redundant generators from S;
13 Recalculate ∆(i), ∆(i+1), Schreier vectors;
so |H|=s|G(i+2)|, where s is as defined in line 1 of the procedure. Hence
. Since 
, and we do not exit the main ‘While’ loop at
line 3 until 
, we must have 
 when we exit the ‘While’ loop,
so the question is whether the elements appended to T during the ‘While’
loop are enough to generate H.
A general element of G(i) can be written as yx for y∈G(i+1) (that is, the
original 
 and x∈U(i). For a given x∈U(i), there exists such an
element yx∈H if and only if there exists y∈G(i+1) with 
, which is
the case if and only if 
. This explains the subdivision
in the ‘If’ statement at line 5.
If y1x and y2x are two elements of H of this form, then (y1x)(y2x)-1=
, and so, for a fixed x, we only need to include one such
element in T, which is what we do in the procedure. Furthermore, we do not
need to adjoin any element yx for which 
 for some t that is already in
; this justifies the removal of the elements of 
 from Γ in line 9.
On the other hand, if there is no element yx∈H for the given x, then
neither can there be such an element of the form yxt for any t already in 
;
this justifies us in removing 
 from Γ in line 6.
A variation on this method of swapping two base points, which is discussed
in [Ser03], is to produce random elements of the subgroup H by calculating a
Schreier vector v for 
, and then applying the algorithm
RANDOMSTAB(ßi+1, v, S(i)) repeatedly. We can use the same halting condition
 as before.
A simpler method of changing bases, also noted by Sims in [Sim71b], is
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
104
simply to conjugate by some g∈G, thereby changing the base from [ß1,…,
ßk] to 
. To make an arbitrary base change, we can proceed as
follows. Suppose that we want to replace ß1 to α for some α. If α∈∆(1),
then 
 for some g∈G, and we can do it by conjugating by g–1.
Otherwise, we can suppose, recursively, that we can replace the second
base point ß2 by α (or, if k=1, simply introduce α as a new redundant
base point ß2), and then we apply BASESWAP(~S, ~B, 1).
In [CF92], Cooperman and Finkelstein describe an algorithm for a cyclic
base change:
 
It has been observed by several authors that, if an initial segment of the
new base is very different from that of the original base, then it can be
better to reconstruct the BSGS data structures from scratch, using
RANDOMSCHREIER. In [CFS90], Cooperman, Finkelstein, and Sarawagi
prove that a random base change algorithm can be described, which has
probability 
 of constructing a ‘short’ Schreier vector data structure
relative to a given base B after processing at most 20 log2 |G| random
elements of G.
A problem that needs to be addressed when base changes are being carried
out is how to keep track of the SLP elements that express the strong generators
as words in the original group generators. If there is enough space available,
then the simplest possibility is always to keep a copy of the BSGS calculated
originally by SCHREIERSIMS or by RANDOMSCHREIER.
Exercises
1.
Assuming the existence of a BSGS (B, S) for G and the data structure ∆*
as described above, write a function which, given a sequence C of k distinct
points of Ω, either finds g∈G with Bg=C, or reports that no such g exists.
2.
Let G≤Sym(Ω), ∆ an orbit of G with |∆|=m, Γ⊆∆ with |Γ|=l, and let
g∈G be random, with uniform distribution on G. Prove that the expected
value of |Γg\Γ| is l(m—l)/m.
3.
Suppose that g∈G is random with uniform distribution on G, H is a
subgroup of G, and T is right transversal of H in G. Denote the element
of T∩Hg by g–. Show that gg––1 is a uniformly distributed random element
of H.
4.
Suppose that (B, S) is not a BSGS for G, and let g∈G be random with
uniform distribution on G. Show that STRIP returns a nonidentity
element with probability at least 1/2.
5.
Prove the claim that, if T is a polycyclic sequence for the input group N
to NORMALIZINGGENERATOR, and U is the sequence returned, then
U cat T is a polycyclic sequence for 
.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
105
4.5 Homomorphisms from permutation groups
In this section, we study computations involving homomorphisms ϕ: G→H,
in the case when G is a finite permutation group. The reader should first
review the general discussion of computation with group homomorphisms in
Section 3.4.
Assuming that we have used SCHREIERSIMS or RANDOMSCHREIER
(and possibly also SHALLOWORBITSV) to compute a BSGS (B, S) for G,
and that we have taken care to store SLP elements that express the strong
generators in S in terms of the original generators X of G, we can define
group homomorphisms ϕ: G→H by specifying the images ϕ(x) for x∈X. The
images ϕ(x) for x∈S\X can then be computed (and stored) by using their
SLP expressions, as described above in Section 3.1.3. Now, the algorithm
STRIP can be used to express an arbitrary group element g∈G as a word in
the strong generators, thereby enabling ϕ(g) to be computed.
If membership testing and rewriting algorithms are available for subgroups
of H, then we can efficiently carry out all of the desirable calculations involving
homomorphisms that were discussed in Subsection 3.4.2. If H is a permutation
group and we are using IMAGEKERNEL to compute the orders of the image
and the kernel, then we can safely use RANDOMSCHREIER without
verification for solving the rewriting and membership problem in im(ϕ),
because IMAGEKERNEL does not terminate until it has checked that
|ker(ϕ)| |im(ϕ)|=|G|, which provides automatic verification that the
order |im(ϕ)| is correct. (If RANDOMSCHREIER returns an incorrect
answer, then it will always report that the group is smaller than it really
is, never larger.)
In addition, if we can compute a presentation of G on S, then we can test
whether the images ϕ(x) for x∈X really do define a homomorphism ϕ: G→H.
Finding such presentations will be handled in detail later, in Chapter 6.
There are, however, two specific and frequently occurring situations in
which we can carry out some of these operations more efficiently than we can
by the general methods. These are the induced action of G on an orbit of GΩ
(or, more generally, on a nonempty union of orbits), and the induced action
of G on a block system preserved by GΩ. Furthermore, there is an alternative
approach to general group homomorphism computations for the case when
H is a permutation group, which is probably no faster than the general
method, but is interesting enough to merit consideration.
4.5.1 The induced action on a union of orbits
Computing with the induced orbit action ϕ: G→ GΨ for a nonempty union Ψ
of orbits of GΩ is straightforward. We first rename the elements of Ψ as 1, 2,
3, …, so that ϕ≤Sym(|Ψ|). Calculating ϕ(g) for g∈G is then just a matter of
applying the renumbering to the action of g on Ψ.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
106
We then change base so as to have as many base points as possible in Ψ.
More precisely, we change to a base [β1, …, βk] in which, for some j, βi∈Ψ if
and only if 1≤i≤ j, and the (j+1)-th basic stabilizer G(j+1) fixes all points of Ψ.
We then have G(j+1)=ker(ϕ). The images ϕ(g) of the strong generators of G
that do not lie in G(j+1) form a strong generating set for im(ϕ) with respect
to the base [ϕ(ß1), …, ϕ(ßj)]. We can therefore test permutations for
membership of im(ϕ). To compute an inverse image ϕ–1 (h) for h∈im(ϕ), we
can use STRIP in im(ϕ) to express h as a word in the strong generators of
im (ϕ), but since these strong generators are just ϕ(g) for g∈S, the same
word defined over S will evaluate to g∈G with ϕ(g)=h. We can therefore
carry out all of the desired types of calculations with ϕ.
4.5.2 The induced action on a block system
Let us turn now to the induced action of a transitive group GΩ on a block
system Γ preserved by GΩ, where Ω={1..n}. We assume that the block system
is defined by an associated partition function p, for which p[α]∈Ω is the
representative point in Ω of the block containing α, so p[p[α]]=p[α] for all
α∈Ω. The function MINIMAL BLOCK returns such a p.
We first want to number the blocks 1,…,m, where m is the number of
blocks. This is accomplished by the following function, which returns m
and lists b, ρ, where for, α∈Ω, b[α] is the number of the block containing α
and, for i∈{1..m}, ρ(i) is the representative in Ω of block number i.
NUMBERBLOCKS(p)
Input: Partition function p as above
Output: m, b, ρ as described above
1
m:=0;
2
for i∈[1..n] do if p[i]=i
3
then m:=m+1; b[i]:=m; ρ[m]:=i;
4
for i∈[1..n] do b[i]:=b[p[i]];
5
return m, b, ρ;
The induced action ϕ: G→GΓ can now be calculated easily by the rule
iϕ(g)=b[ρ[i]g] for i∈{1..m} and g∈G.
PROPOSITION 4.6 Let GΩ preserve block system Γ, let H≤G, α∈Ω; and
let ∆ be the block of Γ containing α. For each ß∈αH
, let uß be an element of
H with αuβ=β. Then the stabilizer H∆ of ∆ in H is generated by Hα together
with {uß\ß∈αH∩∆}.
PROOF Each element of Hα and each uß for ß∈αH∩∆ maps a point in ∆ to a
point in ∆ and hence, by the definition of a block system, it must lie in H∆.
Conversely, if g∈H∆ and αg=ß, then 
 with 
.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
107
     The above result justifies the function BLOCKSTABILIZER for
computing the stabilizer of the block containing α in the subgroup 
of G. It makes use of the array b returned by NUMBERBLOCKS. We start
by changing base of H to have α as the first point. This enables generators of
the stabilizer Ha and the elements uß to be computed by the standard BSGS
functions.
BLOCKSTABILIZER(Y, α, b)
Input: Generators Y of H≤G, α∈Ω, array b for block action
Output: Generators of H∆ for block ∆ containing α
1
Change base of H to make α the first base point;
2
Let Z be the set of generators of Hα;
3
for ß∈αH do if b[ß]=b[α] and 
4
then APPEND(~Z, uß), where uß∈H with 
;
5
return Z;
The function BLOCKIMAGEKERNEL calculates a BSGS (BΓ, SΓ) for im
(ϕ), together with ker(ϕ). It uses a BSGS (B, S) for G.
BLOCKIMAGEKERNEL(G, b)
Input: array b for block action ϕ: G→GΓ
Output: BΓ, SΓ, ker(ϕ)
1
X:=initial generators of G;
2
BΓ:=[]; SΓ:=[ϕ(x)|x∈X, ϕ(x)≠1];
3
i:=1; Choose αi∈Ω;
4
while true
5
do APPEND(~BΓ, b[αi]);
6
Change BSGS (B, S) of G to make αi the i-th base point;
7
Z:=BLOCKSTABILIZER(S(i),αi,b);
8
;
9
if  is empty
10
then return BΓ, SΓ,
;
11
else SΓ:=SΓ cat ; i:=i+1;
12
Choose αi∈Ω with b[αi] not fixed by all 
;
As was the case in IMAGEKERNEL we would also need to keep a record of
which g∈G were used to define the strong generators ϕ(g) of GΓ, since that
information is needed to compute inverse images under ϕ.
4.5.3 Homomorphisms between permutation groups
We now turn to a method for computing with ϕ: G→H when both G and H
are finite permutation groups, and when ϕ(x) is known for x in a generating
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
108
set X of G. This is an alternative to the general methods described in Subsection
3.4.2.
Let ϕ: G→H be a homomorphism, where G≤Sym(Ω) and H≤Sym(Ψ) with
Ω∩Ψ=φ. Let 
The fact that ϕ is a homomorphism implies immediately that  is a subgroup
of Sym(Ω)×Sym(Ψ) with 
, and clearly  is generated by 
:= {(x,
ϕ(x))|x∈X}, where X generates G.
Of course, in practice, we are likely to be given Ω={1..n} and Ψ= {1..m}, for
some m, n, which are not disjoint, but we can easily renumber the points of
Ψ to {n+1..n+m}, and then we can construct the set  explicitly in its natural
action on {1..n+m}. The fact that  generates , which clearly has the same
order as G, and that a base of GΩ is also a base of 
Ω∪Ψ means that we can use
the known base and known order versions of RANDOMSCHREIER to rapidly
compute a BSGS for , assuming that a BSGS is known for G.
The homomorphism ϕ can now be identified with the induced action of 
on the orbit Ψ of 
Ω∪Ψ, and so we can use the methods described above in
Subsection 4.5.1 to perform any desired computations with ϕ.
We may also wish to check that the map ϕ: X→H really does extend to a
homomorphism from G to H. It turns out that this is the case if and only if
a base for GΩ is a base for the subgroup of 
Ω∪Ψ generated by 
; see the
exercise below. We can check this condition using SCHREIERSIMS, but
unfortunately we can no longer use the known base and known order
versions. We could, however, use a version of SCHREIERSIMS that aborted
as soon as it discovered that the initial base for GΩ was not a base for 
.
Exercise
1.
Let 
 with Ω∩Ψ=φ, and let ϕ: X→ H be
any map. Prove that ϕ extends to a homomorphism from G to H if and
only if the subgroup 
satisfies H(Ω)=1. (Hint: Use Theorem 2.52.)
4.6 Backtrack searches
The algorithms to be described in this section potentially involve searching
through all of the elements of a permutation group G of degree n, and so their
complexity is at least O(|G|) in the worst case, which is worse than polynomial
in n in general. It is crucial in designing such algorithms to find methods for
skipping large numbers of the group elements during the search; we do this
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
109
using a technique known as pruning the search tree. In favourable cases,
this can lead to implementations of these algorithms running very fast,
particularly on small examples. So, for example, in the early days of CGT,
when typical examples under consideration had much smaller degrees than
they do today, programs for computing centralizers of elements and
intersections of two subgroups in permutation groups acquired the reputation
of being fast.
Unfortunately, now that we are accustomed to dealing with groups of
larger degree, this worse-than-polynomial behaviour has become noticeable,
and algorithms for computing the centralizer of an element of order 2, for
example, can be very slow. In fact the exponential (or worse) complexity
can mean that a relatively small increase in degree could lead to a doubling
of process times, and so for very large degrees these computations can
become completely impractical. For this reason, considerable effort has
been devoted to finding algorithms that are polynomial of as small degree
as possible in n, for as many problems as possible. Unfortunately, there are
some problems, including centralizers and normalizers of elements and
subgroups, stabilizers of subsets of Ω, and intersections of subgroups, for
which backtrack searching appears to be the only possible approach. Since
these are important problems, we need to devote our efforts to making these
searches run as efficiently as possible.
The reader who is interested in seeing a summary of which calculations
in permutation groups are currently known to be possible in polynomial
time could consult the survey article by Luks [Luk93]. Alternatively, [Ser03]
contains complete information on complexity issues, including detailed
proofs.
Throughout this section, we shall assume that a BSGS (B, S) with B=
[ß1,…, ßk] is known for the permutation group G, and we shall use all of the
notation that was introduced in Subsection 4.4.1. For 0≤l≤k, we shall denote
the initial segment [ß1,…, ßl] of B by B(l).
It is convenient to introduce an ordering  on Ω=[1.. n] in which the base
elements come first, and in order. That is, 
 for i<j, and 
 if α∉Β.
By the definition of a base, an element g∈G is uniquely determined by its
base image 
, and so we can order the elements of G by their
base images. That is, for g, h∈G, we define 
 if Bg precedes Bh in the
lexicographical ordering induced by ≺. To be precise, 
 if and only if, for
some l with 1≤l≤k, we have 
 for 1≤i<l and 
.
Notice that the definition of ≺ ensures that the identity element of G
comes first and, for any l with 1≤l≤k, the elements of the l-th basic stabilizer
G(l) precede those of 
.
Recall from Subsection 4.4.1 that each g∈G has a unique representation
as g=ukuk__1…u1 with ui∈U(i), where U(i) is a right transversal of G(i+1) in G(i)
for 1≤i≤ k. The algorithms to be discussed in this section require us to
consider representations of large numbers of group elements in this form.
The performance of implementations of these algorithms is highly
dependent on a sensible choice of data structure for this representation of g.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
110
If there is enough space available, then the elements of U(i) should be
precomputed rather than recomputed using Schreier vectors each time they
are needed. The elements of U(i) for larger values of i are needed much more
frequently than those for smaller values, so a sensible default decision is to
precompute the U(i) for as many i as there is space available, but starting with
U(k). It is also important to make sensible decisions as to when to keep
permutations g as a permutation word, and when to multiply g out. A possible
strategy here is to multiply g out only when it is to be adjoined as a new
generator of a subgroup being computed, or if it needs to be returned by a
program. But in some cases it may be faster to multiply out the subwords
, for smaller values of l, since these are changed relatively
infrequently during the search algorithms. In our displayed code, we shall
denote 
 by g[l] for 1≤l≤k, without any assumptions about whether
the elements ui or the g[l] are stored as permutation words or as complete
permutations. Note that the images B(l)g of the first l base points are determined
by g[l].
4.6.1 Searching through the elements of a group
We start by presenting a procedure PRINTELEMENTS that merely prints
out each group element. This can be done simply by running through all
possibilities for ulul_1…u1 in turn. Although it complicates the code slightly,
we shall see later that there are significant advantages in generating the
group elements in increasing order of base images; that is, in the order ≺ of
G defined above. In particular, it is important that, for each l, the elements
of G(l) come before those of G\G(l). This same basic method of looping through
the group elements is used for subsequent, more ambitious, procedures.
PRINTELEMENTS(G)
Input: Permutation group G with BSGS (B, S, ∆*)
(* g[l] will always denote the element 
 of G *)
1
l:=1; c[l]:=1; 
; ul:=1G;
2
while true
3
do while l<k
4
do l:=l+1; 
;
5
c[l]:= 1; 
; 
;
6
PRINT g[l];
7
while l>0 and c[l]=|∆(l)| do l:=l-1;
8
if l=0 then return;
9
c[l]:=c[l]+1; 
; 
Notice that 
 as defined on lines 1 and 4 of the procedure, is set equal to
the image of the l-th basic orbit ∆(l) under g[l–1], and is sorted into increasing
order under ≺. This enables us to find ul at line 9 that defines the next group
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
111
element under the ordering ≺; recall from Subsection 4.4.1 that, for γ∈∆(l),
 denotes the element of U(l) which maps ßl to γ.
Example 4.4
Let 
(so 
 has order 16), B=[1, 2, 5], U(1)={(), (1, 2, 3, 4), (1, 3)(2, 4), (1,
4, 3, 2)}, U(2)={(), (2, 4)}, U(3)={(), (5, 6)}. Then the permutations (in vector
format) are output in the order
[123456], [123465], [143256], [143265], [214356], [214365], [234156], [234165],
[321456], [321465], [341256], [341265], [412356], [412365], [432156], [432165].
The diagram below depicts the run of PRINTELEMENTS on this example.
The tree is traversed during the run in order of a depth-first search, starting
at vertex (1,1) (that is, vertex 1 at level 1).
At the top of each iteration of the main ‘While’ loop at line 2, we are at
one of the vertices of the diagram, where the level is specified by l. The
current group element g[l]=ul…u1 is equal to 
...
, where the γi are the
labels on the edges joining the top vertex to the current vertex. At that
point in the procedure, ui is defined only for 1≤i≤l, but this is enough to
specify uniquely the images B(l)g of the first l base elements under any
group element g=uk ...u1 that has these values of ui for 1≤i≤l.
For example, if the current vertex is (2, 5) (that is, vertex number 5 on
level 2), then 
, u2=u4
(2)=(2,4), and u3 is undefined. But,
since u3∈G(3)=G12, we know that 
, and 
 for any
group element g represented by a vertex below (2, 5) in the tree. The vertices
at the bottom layer correspond to the group elements themselves.
An important special case is when G is the full symmetric group Sym(n).
This occurs, for example, when computing automorphism groups of
combinatorial structures, which will be discussed briefly in Subsection 4.6.4,
below.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
112
SYMMETRICGROUPELEMENTS(n)
Input: n∈N
1
for i∈[1..n] do p[i]:=i;
2
while true
3
do PRINT ρ∈Sym(n);
4
i:=n-1;
5
while i>0 and p[i]>p[i+1]
6
do i:=i-1;
7
if i=0 then break;
8
j:=n;
9
while p[i]>p[j]
10
do j:=j-1;
11
s:=p[i]; p[i]:=p[j]; p[j]:=s;
12
i:=i+1; j:=n;
13
while i<j
14
do s:=p[i]; p[i]:=p[j]; p[j]:=s;
15
i:=i+1; j:=j-1;
Here, we do not need to store or use the transversals U(i). We would
like to run through the complete set of permutations of [1..n] in
lexicographical order, starting with the identity [1, 2,…, n] and ending
with the order reversing permutation [n, n-1,…, 1]. This is the same as
the order defined by base images with respect to the base [1,…, n–1] of
G. The problem is to find the permutation immediately following the
current permutation g∈Sym(n) under this ordering. This can be done
efficiently as follows.
Look at ng, (n-1)g, etc., until the sequence stops increasing, at ig, say. For
example, for g=[6147532]∈Sym(7), the images 2, 3, 5, 7, 4 stop increasing
at i=3, where ig=4. We then look again at ng, (n–1)g, until we reach a number
jg larger than ig. In the example, we stop at j=5, where 5g=5>ig. To compute
the permutation g′ immediately following g in the lexicographical ordering,
we replace ig by jg, and then put the images kg′ for k>i into increasing order.
So g′=[6152347] in the example. An efficient way to achieve this is first to
interchange ig and jg, which will have the effect of putting kg for k>i into
decreasing order, and then to reverse that sequence. This is carried out in
the procedure SYMMETRICGROUPELEMENTS. The permutation g is
stored in the array p, and the variable s is used for swapping the values of
p[i] and p[j].
Of course |Sym(n)|=n! grows very rapidly with n, and it would be unusual
to attempt to search through the whole of Sym(n) for n larger than about
12 or 13. As we shall see in the next section, in most applications we try to
avoid searching through all of the elements of a permutation group G, by
making larger jumps forwards during the search. Making that possible
would necessitate modifications to the above procedure.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
113
4.6.2 Pruning the tree
Usually we are looking for a subset of G consisting of elements that satisfy
some specific property P. Often, the group will be much larger than this
subset, so it is essential to find methods of avoiding having to consider
each group element individually. Fortunately, it is often possible to prove
that an element g∈G cannot satisfy P from a knowledge only of αg for a few
values of α. We can use that information by choosing the α in question to be
base points.
More precisely, for l with 1≤l≤k, let us suppose that we have test functions
TEST(g, l) available, such that if TEST(g, l) returns false, then there is no
element h of G satisfying P for which 
 for 1≤i≤l. In other words,
TEST can rule elements out just by considering the first l base images. If
we are at a vertex v at level l of the search tree, then 
 is defined at v for
1≤i≤l, and so we can apply TEST(g, l). If it returns false, then we can
immediately proceed to the next vertex at level l, and we do not need to
consider any of the vertices below v. So we have pruned the tree below v.
We shall call the sequence 
, for some l with 1≤l≤k, a
partial base image. Then TEST(g, l) must work using only a partial base
image for g. We stress that TEST is a negative test only, and is used for
ruling out candidates. If TEST returns true, then it does not imply that
there exists g with these partial base images that satisfies P; it provides no
information on that question.
The next procedure GENERALSEARCH assumes that we have a property
P that can be evaluated on group elements g∈G, together with such tests
TEST(g, l) which are capable of returning false from a knowledge of B(l)g
only. Of course, in practice, such tests might only be available for some
values of l, in which case we would make TEST(g, l) always return true for
other values. Once again, the procedure as written simply prints the
elements that satisfy the property. In some applications, we might only
want a single element satisfying P, in which case we could modify the
procedure to return such an element and stop as soon as it found one.
To take a rather artificial example, suppose, in Example 4.4, that we
only want to print out just those elements g∈G for which 1g=1 or 3, and
2g=2. Then TEST(g, 1) can test for the first of these conditions, and TEST(g,
2) for the second. The vertices of the tree will be traversed in the order
shown in the table below, with the action specified.
Notice that if, instead, we were looking for an element g∈G with 4g=1 or
2, and 3g=3 then, with the base [1, 2, 5] for G, knowledge of partial base
images would not be helpful in pruning the search tree. The solution, of
course, would be to change the base of G to make [4, 3] an initial segment
of the base; B=[4, 3, 5] would be a suitable base. The general point to be made
here is that before embarking on any particular search, the base points of G
should be chosen, in turn, to allow as many negative tests TEST(g, l) as
possible.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
114
GENERALSEARCH(G)
Input: Permutation group G with BSGS, property P, tests TEST(g, l)
(* g[l] will always denote the element ulul-1…u1 of G *)
1
;
2
while true
3
do (* Test if base images are possible at current level *)
4
while l<k and TEST(g, l)
5
do 
;
6
c[l]:=1; 
 ; 
;
7
if l=k and TEST(g, k) and P(g[k]) then PRINT g[k];
8
while l>0 and c[l]=|∆(l)| do l:=l-1;
9
if l=0 then return;
10
c[l]:=c[l]+1; 
; 
;
4.6.3 Searching for subgroups and coset representatives
In many situations, the subset of elements in the group G for which we are
searching forms a subgroup S of G. For example, we might want to find a
Sylow p-subgroup for some prime p, or the centralizer or normalizer of a
given subgroup. In that case, our aim is to find generators of S rather than
each individual element of S.
At any stage during the course of the search of the tree, we will have
found a subgroup K of S. Each time we find a new element g in K, we
replace the current value of K by 〈K, g〉. The order of search ensures that
generators of K(i) will be found before elements of G\G(i) are considered for
2≤i≤k, and so the generating set of K computed will automatically be a strong
generating set.
Since, for k1, k2∈K and g∈G, we have 
, we need only
adjoin a single element of the double coset KgK as a new generator. So we
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
115
can restrict the number of elements that we need to consider during the
search by rejecting all elements g∈G that can be proved not to be minimal in
their double coset KgK under the ordering ≺.
Since, at a node at level l in the search tree, we only know the partial base
image B(l)g of the element g under consideration, we do not usually have
enough information to decide conclusively whether g is minimal in its double
coset. However, some useful tests for nonminimality of g are described in
Sims’ papers [Sim71b, Sim71a]. See also Leon’s paper on automorphism groups
of combinatorial objects, which contains pseudocode, and Section 9.1.1 of
[Ser03]. The proof of the following result is straightforward, and is left to the
reader.
PROPOSITION 4.7 Let K<G≤Sym(Ω), let B:=[ß1,…, ßk] be a base of G, and
let ∆(j) and 
 (1≤j≤k) be the basic orbits of G and K with respect to B. Let
g∈G, let 
 for 1≤j≤k, and let ≺ be the ordering of Ω and of G defined
by the base B, as described above. Then
(i)
g is the ≺-least element of its coset gK if and only if γj is the ≺-least
element of its orbit under 
 for 1≤j≤k;
(ii) g is the ≺-least element of its coset Kg if and only if γj is the ≺-least
element of 
 for 1≤j≤k.
At a vertex at level l in the search tree, we can apply (i) of this result by
checking whether γl is the least element of its 
 orbit. To do this,
we need to continually change the base BK of K to ensure that, at a vertex
at level l, BK has initial segment equal to the current partial base image
B(l)g=[γ1,…, γl]. This enables us to compute the orbits of the basic stabilizer
 of K.
Since changing base carries with it a nontrivial cost, it may, on occasion,
be faster to carry out the base changes and associated minimality test
based on condition (i) only at the higher levels of the search tree, even if
this means traversing more nodes of the tree at the lower levels. Note,
however, that each individual base change involves only a single application
of BASESWAP. In the code for SUBGROUPSEARCH below, we have applied
this minimality test at all levels.
Condition (ii) or Proposition 4.7 can be applied most readily at level l of the
search tree if 
 for some j<l, because then we have 
. So,
if g is least in its coset Kg, then 
, which is a testable condition. In practice,
and in SUBGROUPSEARCH, we test the condition
The following corollary of condition (ii) yields another testable condition.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
116
COROLLARY 4.8 With the notation of Proposition 4.7, if g is the ≺-least
element of its coset Kg, then γl cannot be among the 
≺-largest
elements of its orbit under 
.
PROOF If g is the ≺-least element of Kg then, by Proposition 4.7, γl is the -
least element of 
. Since hg=g(g-1hg) with
g-1hg∈ Gγ1,...γ1_1, all of the elements in 
 lie in the same Gγ1,...γ1_1 orbit.
Hence there must be at least 
 elements of this orbit that are greater
than γl under ≺.
In fact the orbit of γl under has already been calculated and sorted as Λ[l] in
our code, so we can readily apply this test.
The function SUBGROUPSEARCH is rather complicated and will require
careful study by the reader. The second input parameter, H, is intended to
be a known subgroup of the sought subgroup S, and is used to initialize K.
For example, when computing the normalizer in G of a subgroup L of G, we
could put H=L, and when computing the centralizer in G of g∈G, we could put
. If there is no suitable subgroup, then we put 
.
The variable f in SUBGROUPSEARCH is equal to the smallest j for
which 
. The reason for keeping track of f is that, after finding a new
element g∈K, we can reset the current level l in the search to f (line 22).
The search starts with l=f=k rather than with l=1 as in GENERALSEARCH,
and so the initializations are slightly different from those in
GENERALSEARCH.
Since there are two different bases B and BK of K in use, the reader
must be particularly careful to be aware which is being used at which point
in the code. The basic orbits 
 of K (lines 3, 7, 14, 15, 20 and 28) are
always with respect to the base B:=[ß1,…, ßk] of G, which is also the initial
base of K. The basic stabilizers K(j) of K (lines 4, 12, 21 and 27) are always
with respect to BK.
Although it is not actually stated in the code, the orbit representatives
R[l] computed at lines 4, 12, 21 and 27 are chosen to be the ≺-least elements
of these orbits. They are used in applying the test based on condition (i) of
Proposition 4.7 at lines 10 and 17.
The points µ[l] and ν[l] of Ω defined at lines 7, 14, 15, and 28 are used to
apply the tests described above that use condition (ii) of Proposition 4.7 and
Corollary 4.8. The tests are also applied at lines 10 and 17.
In general, when searching for a subgroup K of G with
SUBGROUPSEARCH, the larger K is, the faster the search will run. This
is because the larger K is, the fewer orbits it and its basic stabilizers K(i) will
have, which means fewer orbit representatives, and fewer images to be
considered in the search. The most difficult subgroups to find are the very
small ones.
As in GENERALSEARCH, we will need to make a choice of a base for G
that allows use of the most effective TEST(g, l) for that particular problem. We
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
117
SUBGROUPSEARCH(G, H)
Input: Permutation group G with BSGS, property P, tests TEST(g, l),
subgroup H≤G of some elements satisfying P
Output: Subgroup K of all elements of G satisfying P
(* g[l] will always denote the element ulul-1…u1 of G *)
1 K:=H; f:=k; l:=k;
2 Let B:=[ß1,…, ßk] be the base of G, and BK:=B the base of K;
3 Calculate basic orbits 
 of K;
4 Calculate orbit representatives R[f] of K(f);
(* To avoid getting 1G, remove ßf itself *)
5 Remove ßf from R[f];
6 for i∈[1..k] do c[i]:=1; ui:=1G; 
;
7 µ[l]:=0; 
;
8 while true
9
do (* Test if base images are possible at current level *)
10
while l<k and 
∈R[l] and 
 and 
and TEST(g, l)
11
do Change l-th base point of K in base BK to 
;
12
Calculate orbit reps. R[l+1] of K(l+1) w.r.t. BK;
13
l:=l+1; 
;
14
;
15
;
16
c[l]:=1; 
; 
;
17
if l=k and 
 ∈R[l] and 
 and 
      and TEST(g, l) and P(g[l])
18
then 
;
19
Change base BK of K back to B=[ß1,…, ßk];
20
Calculate basic orbits 
 of K;
21
Recalculate orbit reps. R[f] of K(f) w.r.t. BK;
22
l:=f;
23
while l>0 and c[l]=|∆(l)| do l:=l-1;
24
if l=0 then return K;
25
if l<f
26
then f:=l; c[l]:=1;
27
Calculate orbit reps. R[f] of K(f) w.r.t. BK;
28
µ[l]:=0; 
;
29
c[l]:=c[l]+1; 
; 
;
shall see some specific examples of how this is done later.
Typically, for each subgroup-searching problem, there is a corresponding
problem in which we are looking for a single element that lies in a particular
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
118
coset of an associated subgroup. For example, corresponding to the problem
of finding the centralizer CG(g) of an element g∈G, we have the problem of
testing two elements h and g for conjugacy in G and, when they are conjugate,
finding an element x∈G with x-1hx=g. If this holds for some x∈G, then it
holds for y∈G if and only if y∈xCG(g), which is why we refer to it as a coset
problem. Similarly, to the problem of computing the normalizer of a subgroup,
there corresponds the coset problem of testing two subgroups for conjugacy,
and finding a conjugating element.
Similar partial base image tests will often apply to the subgroup problem
and to the corresponding coset problem. For example, as we shall prove
later, elements in the normalizer of a subgroup H of G must permute the
orbits of H, whereas an element conjugating subgroup K to subgroup H
must map the orbits of K to those of H. Tests can be devised that check
when these conditions cannot hold for the current partial base image.
When attempting to solve a coset problem, it can prove efficient to solve
the corresponding subgroup problem first. If, for example, we are testing
elements h and g for conjugacy in G, then we could compute K=CG(g) first.
This allows the orbits of the basic stabilizers K(i) of K to be used to limit the
search for a conjugating element, in essentially the same way that they
were used in SUBGROUPSEARCH in the test based on condition (i) of
Proposition 4.7. This claim that we should solve the subgroup problem
first is somewhat controversial, because we might of course be lucky and
find a conjugating element much more quickly than it would take to compute
the centralizer.
But in the author’s experience, it is very rare for solving the subgroup
problem first to do more than increase the total time taken for the coset
problem by a very small amount, whereas there are some cases where it
can avoid disasters. The author recalls one particular example, in which G
was a direct product H×K of a small group H and a very large group K, and
the problem was to find a conjugating element for two elements h, g that
were both in H. The large centralizer of g was computed very quickly,
which then allowed the conjugating element to be found almost instantly.
But without this precomputation of the centralizer, the search for a
conjugating element somehow managed to get lost inside of K, and took
many hours!
Exercise
1. Prove Proposition 4.7.
4.6.4 Automorphism groups of combinatorial
structures and partitions
The same method as that of SUBGROUPSEARCH can be used to compute
automorphism groups of combinatorial structures, such as finite directed or
undirected graphs, block designs and error-correcting codes. The corresponding
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
119
coset problem is to test two such objects for isomorphism. There is a good
introductory treatment of this topic by Leon in [Leo84], Later, in Subsection
4.8.2, we shall discuss the opposite problem of using permutation groups to
construct combinatorial objects.
The group G involved when computing Aut(Γ) for a combinatorial object Γ
is usually Sym(Ω) for some underlying set Ω of Γ. The base for G is then an
ordered sequence [α1,…, αn-1] of n-1 points of Ω, where |Ω|=n, but we choose
this ordering to allow as many negative tests based on partial base images as
possible. We can then identify Ω=[α1,…, αn] with [1..n], and use the procedure
SYMMETRICGROUPELEMENTS described in Subsection 4.6.1 as the
underlying looping mechanism. But it must be modified to allow moving on
to the next base image at an arbitrary level l in the search tree, as in
SUBGROUPSEARCH. We leave this modification as an exercise to the reader
(Exercise 2 below).
As an example of a combinatorial structure, an (undirected) graph Γ= (Ω,
E) is a set Ω of vertices, together with a set E of edges, which can be thought
of as a subset of the set Ω{2} of unordered pairs of elements of Ω. An
automorphism of the graph is a permutation α∈Sym(Ω) such that Eα= E.
There is a particularly well-developed and successful program available for
computing automorphism groups of graphs and testing two graphs for
isomorphism. This was written and is maintained by Brendan D. McKay,
and is known as ‘Nauty’; the name comes from the phrase “No
AUTomorphisms, Yes?” See, for example, [McKay81] for a description of
the ideas used in the algorithms involved, or the Nauty Web page for up-to-
date information.
A graph can be made into a metric space with distance function d, in
which an edge {α, ß} is a path of length 1 connecting α to ß. Then, for α,
ß∈Ω, d(α, ß)=r means that there exist α=α0, α1,…, αr=ß with each {αi–1,
αi}∈E, and no shorter path joining α to ß.
A simple way of pruning the search tree in the computation of Aut(Γ) is to
use the fact that g∈Aut(Γ) implies d(α, ß)=α(αg, ßg) for any α, ß∈Ω.
For example, suppose that Ω={1..5}, and Γ is a pentagon, with edges {1, 2},
{2, 3}, {3, 4}, {4, 5}, {5, 1}. Since 2 and 5 are joined to 1, we might choose the
base to be [1, 2, 5, 4, 3] rather than [1, 2, 3, 4, 5], but that is not really
critical in such a small example. Let g∈Aut(Γ). If 1g=1 and 2g=2, then, since
2 and 5 are the only vertices at distance 1 from 1, we get 5g=5, and similarly
we deduce 3g=3 and 4g=4, so the search can proceed at level 2 to 2g=5, which
implies 5g=2, 3g=4, 4g=3. A full test for Eg=E reveals that g1:=(2, 5)(3, 4) really
is in Aut(Γ), so we set set K=〈g1〉. Since 2g=3 and 2g=4 do not preserve
distance from 1 in Γ, we backtrack to level 1, and move on to 1g=2. Trying
first 2g=1, the edge distance 1 constraint forces 5g=3, 4g=4, and we find that
g2=(1, 2)(3, 5)∈Aut(Γ). Now K:=〈g1, g2〉 has order 10 and is transitive on Ω,
so the search completes immediately, with Aut(Γ)=K.
In this example, we discovered quickly that g∈Aut(Γ) and 1g=1, 2g=2 implies
g=1, so [1, 2] is a base for Aut(Γ). Generally, during the initial choice of base
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
120
of an automorphism group calculation, we will look for some, preferably short,
initial sequence [α1,…, αl] of our ordering of Ω, which will be a base for
Aut(Γ). We can then use this fact during the search to deduce αg for the
remaining points α from 
.
A structure that arises naturally in many different combinatorial and
group-theoretical searching algorithms is an ordered partition of the
underlying set Ω. This consists of an ordered sequence P=[Ω1,…, Ωr] of disjoint
subsets of Ω of which the union is the whole of Ω. The individual subsets are
treated as unordered sets in such a structure. An automorphism of P is a
permutation that preserves the ordered structure, and the full automorphism
group is clearly equal to the direct product of the groups Sym(Ωi)
There is an extensive theoretical account of the use of ordered partitions
in backtrack search algorithms by J.S.Leon in [Leo91]. The topic is also
covered in Section 9.2 of [Ser03]. Leon has written some efficient code for
many of these algorithms, which is available from MAGMA and GAP. This
includes basic procedures for computing the stabilizer of an ordered partition
in a given permutation group GΩ, and the associated coset problem of deciding
whether one such partition can be mapped to another.
Notice that the problem of finding the setwise stabilizer GS of a subset S of
Ω in G is a special case of the partition stabilizing problem. In general, this is
significantly more difficult than computing the pointwise stabilizer of S which,
as we saw in Subsection 4.4.7, can be done simply by changing the base of G.
To compute GS, we choose our base [ß1,…, ßk] of G such that ßi∈S for 1≤i≤j
only, with j as large as possible. We then use the fact that, for any g∈GS,
 for 1≤i≤j, and 
 S for j+1≤i≤k in our TEST functions.
In the calculation of Aut(Γ) for a graph Γ=(Ω, E), there are several useful
ordered partitions of Ω. For example, for a∈Ω and r∈N, let v(α,
r):=|{ß∈Ω|d(α, ß)=r}| be the number of vertices at distance r from α and,
for s>0, let Ω(r)s:={α∈Ω|v(α, r)=s}. Then, for each r=1, 2, 3,…, the sets Ω(r)s
define an ordered partition of Ω, and each of these ordered partitions must
be fixed by any g∈Aut(Γ). This information can be used to devise partial
base image tests TEST(g, l). When searching through the basic stabilizer
Sym(Ω)α1 of the first base point 1, further partitions are stabilized, some of
which are refinements of those stabilized by all of Aut(Γ). These ideas can
be used to find a base for Aut(Γ). After considering a succession of basic
stabilizers of [α1,…, αl] in Sym(Ω) and the associated partition refinements,
we hope eventually to find that the finest ordered partition, in which each
subset is a singleton, must be preserved, which is of course equivalent to
[α1,…, αl] being a base for Aut(Γ).
Exercises
1.
It was claimed that testing two combinatorial objects for isomorphism is
a coset problem. What coset of what subgroup, and in what group?
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
121
2.
Write a general version of SUBGROUPSEARCH for which the group G
is Sym(n), using SYMMETRICGROUPELEMENTS as the underlying
method for looping through the group elements.
3.
Consider the so-called ‘Petersen Graph’ Γ below. Show that vertices
can be labelled with unordered pairs {x, y}, x, y∈{1..5}, in such a way
that two vertices are joined by an edge in Γ if and only if their labels
are disjoint sets. Deduce that Aut(Γ) has a subgroup isomorphic to
Sym(5) and hence that |Aut(Γ)|≥120. Find a base for Aut(Γ) consisting
of three vertices of Γ and deduce that |Aut(Γ)|≤120 and hence that
Aut(Γ) ≅ Sym(5).
4.6.5 Normalizers and centralizers
Computing the normalizer NG(H), where H and G are subgroups of Sym(Ω),
together with the corresponding coset problem of testing two subgroups of
Sym(Ω) for conjugacy in G, are among the most difficult problems in CGT
and there are examples of degree less than 100, which will defeat even the
best available implementations at the present time. Usually H is a subgroup
of G, but the algorithms tend not to make use of that fact. Of course, if H≤G,
then we can initialize K to H in SUBGROUPSEARCH, but in general we
could only initialize K to H∩G. All sensible implementations will certainly
use the following well-known result.
PROPOSITION 4.9 Let H, K, G≤Sym(Ω) and let g∈G with Hg=K. Then g
maps each orbit of HΩ to an orbit of KΩ. In particular, NG(H) permutes the
orbits of HΩ.
PROOF We have to show that if α and ß are in the same orbit of HΩ, then αg
and ßg are in the same orbit of KΩ. So, suppose there exists h∈H with αh=ß.
Let k:=g-1hg∈K. Then αgk=αhg=ßg, which proves the result.
So NG(H) permutes the orbits of HΩ and, for an initial segment B(l-1)
of our base B of G and g∈NG(H), g maps the orbits of HB(l-1) to the orbits of
HC(l-1), where C(l-1)=B(l-1) g. To make use of this property in
SUBGROUPSEARCH for l>1, we require that the bases of both H and the
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
122
currently known subgroup of NG(H) have the initial segment C(l–1); we
must therefore carry out frequent base changes while running the
procedure. To make the resulting partial base image tests as effective as
possible, the initial base of G should be chosen such that as many base
points as possible lie in the same orbit of HΩ. An implementation of the
normalizer and conjugacy testing algorithms that uses orbital information
of this type is described by Butler in [But83]
With H, we can associate an ordered partition PH of Ω as follows. Let
d1,…, dr be the distinct sizes of the orbits of HΩ, and let
 
for 1≤i≤r. Then Proposition 4.9 implies that NG(H) preserves PH and, if
Hg=K, then g maps PH to PK. Of course, this fact is only useful
computationally if r>1. But the author has observed that, provided that
r>1, it is often significantly faster with current implementations to compute
L:=NG(PH) first and then to compute NG(H) as NL(H), than it is to compute
NG(H) directly. Similarly, to test H and K for conjugacy in G, first look for
g1∈G with 
 and, if g1 exists, then look for g2∈NG(PK) with 
.
Theoretically it is not surprising that this is a good policy, because the
speed of a backtrack search is heavily dependent on the index of the sought
subgroup in the whole group, and so splitting the problem into two parts
with smaller associated indices is likely to be a good policy.
There are some situations in which none of the above methods provides
any useful information at all. The most extreme case is when HΩ is regular
(see Definition 2.24). In that and similar cases, it is possible to make use of
the fact that elements of NG(H) induce automorphisms of H by conjugation.
For example, if H is a cyclic group with HΩ regular, then the automorphism
induced by g, and hence gΩ, is uniquely determined once 
 and 
 are known,
where 
 for a generator h of H. These properties were used in an
implementation described by Holt in [Hol91]
Another property of normalizers that can be used effectively is that NG(H)
permutes the orbital graphs of HΩ; that is, the orbits of H on the set Ω(2) of
ordered pairs of elements of Ω. This idea was originally proposed by Sims,
and used in an implementation in CAYLEY in the case when HΩ is transitive.
It is also used in the GAP implementation described by Theissen in [The97].
For the calculation of centralizers of elements and of subgroups, a much
stronger result is available.
PROPOSITION 4.10 Let H, G≤Sym(Ω) and let g∈CG(H). Suppose that ∆1
and ∆2 are (not necessarily distinct) orbits of HΩ and that 
. Then
the action of g on the points in ∆1 is uniquely determined by HΩ and the
action of g on any single point a∈∆1.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
123
PROOF Suppose αg=ß∈∆2, and let γ∈∆1. Then there exists h∈H with αh=γ,
and then γg=αhg=αgh=ßh.
Similarly, it can be shown that, if 
 with h1, h2, g∈Sym(Ω), then the
complete action of g on any orbit of 
 is uniquely determined by h1 and the
action of g on a single point in that orbit. As is the case for normalizer
calculations, we should choose as many base points of G as possible in the
same orbit of H or 
. Typically, we can then deduce several base images
 from a single base image 
, and in many examples the calculation of
centralizers is extremely fast.
Example 4.5
Let us compute the centralizer in G:=Alt(8) of h:=(1, 2, 3)(4, 5, 6). The obvious
base B:=[1, 2, 3, 4, 5, 6] of G satisfies the properties of the preceding paragraph.
We can initialize the centralizer K of h in G to be 
. If [1, 2, 3, 4]g=[1, 2, 3,
4], then g=1, so the search will quickly jump back to l=4 and consider g with
[1, 2, 3, 4]g=[1, 2, 3, 5]. Now g∈CG(h) implies that 5g=6 and 6g=4, and we find
g1:=(4, 5, 6)∈CG(h) and adjoin g1 to K. Now K(4)=K[1, 2, 3] has orbits {4, 5, 6}, {7}
and {8} on Ω\{1, 2, 3}. We have already considered g∈K(4) with 4g=5∈{4, 5, 6},
and 4g=7 and 4g=8 are not possible, because g∈CG(h) cannot map an orbit of
h of length 3 to one of length 1. So we backtrack to l=3.
Then 1g=1 implies 2g=2 and 3g=3, so we immediately backtrack to l=1.
Since 1, 2, and 3 are already in 1K, we consider 1g=4, which implies 2g=5 and
3g=6. Now since g permutes the orbits of h, it must map the orbit {4, 5, 6} to
{1, 2, 3}, so we try 4g=1, which implies 5g=2 and 6g=3. Now g∈G is uniquely
determined as g2:=(1, 4)(2, 5)(3, 6)(7, 8) and we find that g2∈CG(h), so we
adjoin g2 to K. Now KΩ has orbits {1, 2, 3, 4, 5, 6} and {7, 8}. But g∈CG(h)
cannot map 1 to 7 or 8, so the search finishes with K=CG(h)=〈h, g1, g2〉,
which has order 18.
[]
The theoretical complexity of this algorithm for centralizer calculation is
exponential in n in general; the worst case in this respect is when |H|=2.
There are some special situations in which polynomial algorithms for CG(H)
can be devised. For example, if HΩ is transitive, then the search will complete
in polynomial time, because g∈CG(H) is uniquely determined by its action
on a single point of Ω.
An important special case is the calculation of the centre Z(G)=CG(G) of
G. For that calculation, we can modify the basic search algorithm to make
it run in polynomial time as follows. Let the orbits of G be Ω1,…, Ωr. Define
G(0):=G and, inductively, for i>0, define G(i) to be the complete inverse
image of the centralizer of GΩi in Z(G(i-1)Ωi). Then Z(G)=G(r) (see Exercise 1
below). Since each GΩi is transitive, each G(i) can be computed from G(i-1) in
polynomial time, and hence so can Z(G).
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
124
More generally, the centralizer in G of any normal subgroup H of G can be
found in polynomial (and even in nearly-linear) time; see [Ser03, Sec. 6.1.4].
The calculation of CG(H) when G=Sym(Ω) can also be accomplished in
polynomial time; see Exercise 2 below or [Ser03, Sec. 6.1.2].
The following corollary of Proposition 4.10 is often useful, and will be
applied in Section 4.7.
COROLLARY 4.11 Let G act on Ω, let H≤G, and suppose that HΩ is transitive
and abelian. Then HΩ is regular and self-centralizing in GΩ.
PROOF Let g∈G such that gΩ centralizes HΩ. Choose any α∈Ω and let
αg=ß. By transitivity of HΩ, there is h∈H with αh=ß. Since H is abelian, hΩ
also centralizes HΩ, and then Proposition 4.10 tells us that gΩ=hΩ, so HΩ is
self-centralizing in GΩ. This also tells us that hΩ is the only element of HΩ
with αh=ß, and in particular, choosing α=ß, we get Hα={1}, so HΩ is
regular.
Exercises
1.
Prove that Z(G)=G(r) in the above discussion of the computation of
Z(G).
2.
Prove that CG(H) can be calculated in polynomial time when H≤G=
Sym(Ω). (Hint: This can be done by computing and testing the groups
HΩi for conjugacy in G, where Ωi are the orbits of HΩ.)
4.6.6 Intersections of subgroups
Suppose that G, H≤K≤Sym(Ω), and we want to compute the intersection
G∩H. Let B=[ß1,…, ßk] be a base for K and, as before, let B(l) be the initial
segment [ß1,…, ßl]. Since elements of K are uniquely determined by their
base images, an element g∈G lies in H if and only if there exists h∈H with
Bg=Bh, in which case g=h.
We proceed by running SUBGROUPSEARCH on G. At any level l in the
search tree, we are considering a candidate g∈G for which B(l–1)g is
known, and we also maintain an element h∈H with B(l-1)h=B(l-1)g.
Initially, g=h=1. Suppose that we are at a vertex at level l in the search
tree, and we are considering g with 
. If h′∈H with B(l–1)h’=B(l–1)g
and 
, then h′=h1h for some h1∈H(l)=HB(l-1), where h is our stored
element of H with B(l–1)h=B(l–1)g. Hence 
 and so 
 must be
in the orbit of ßl under H(l). But this orbit is just the l-th basic orbit of H,
so this condition can be tested immediately. So our function TEST(g, l)
will return false if 
 is not in the orbit. Otherwise, TEST(g, l) will
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
125
return true and, if l<k, then h1 with 
 is computed and the
memorized value of h replaced by h1h. If TEST(g, l) returns true with
l=k, then we know that there exists h∈H with Bh=Bg and so g∈G∩H, and
we can adjoin g to the intersection.
Example 4.6
Let K:=Alt(8) with base [1, 2, 3, 4, 5, 6]. Let
 
be the subgroup of order 18 computed in Example 4.5. We saw that the basic
orbits of G are {1, 2, 3, 4, 5, 6}, {2}, {3}, {4, 5, 6}, {5}, and {6}. Let
 
Then |H|=24, HΩ is transitive and H(2) is generated by (2, 3, 7)(4, 5, 8), so
the basic orbits of H are {1..8}, {2, 3, 7}, {3}, {4}, {5}, and {6}.
In the search through G, at l=4 (the first nontrivial level of G), we find
that 5 and 6 are not in the 4th basic orbit of H, so we backtrack to l=1. We
first try 1g=2. Then TEST(g, 1) returns true because 2 is in the first basic
orbit of H, and stores h=(1, 2)(3, 7)(4, 6)(5, 8) (for example), with 1g=2.
Moving down to level 2 in the tree, we must have 2g=3, and then 
is in the second basic orbit of H, so TEST(g, 2) returns true, and we take
h1=(2, 7, 3)(4, 8, 5) and replace h by h1h=(1, 2, 3)(4, 5, 6). Now we move
down to level 3, where we must have 3g=1, so 
 and TEST(g, 3)
returns true with h unchanged. Moving down to level 4, we have three
choices for 4g. With 4g=4, we get 
, which is not in the fourth basic
orbit {4} of H, so TEST(g, 4) returns false. With 4g=5, however, we get
, so TEST(g, 4) returns true with h unchanged. Now we must
have 5g=6 and 6g=4, and TEST(g, l) returns true for l=5 and 6 and so we
have g1:=g=(1, 2, 3)(4, 5, 6) in G∩H.
The search then backtracks to level 1. Since we have 1, 2, 3 already in
1G∩H, we next try 1g=4, which leads to TEST(g, 1) returning true with h=(1,
4)(2, 6)(3, 8)(5, 7), for example. At level 2, we must have 2g=5, leading to
, and TEST(g, 2) returns true with h replaced by h1h= (1, 4, 3, 6, 2,
5)(7, 8). At level 3, we must have 3g=6, and then 
 so TEST(g, 3)
returns true with h unchanged. At level 4, TEST(g, 4) returns true only for
4g=3, with h unchanged, and this forces 5g=1, 6g=2 at levels 5 and 6, but
TEST(g, l) returns true both times. The only element of G with these base
images is g2:=g=(1, 4, 3, 6, 2, 5)(7, 8), so this is adjoined to the generating set
of G∩H. The search then completes. In fact 
, so g1 is redundant, and
G∩H is cyclic of order 6.
[]
There is a (nearly-linear) polynomial-time algorithm for computing the
intersection G∩H when G≤N(H); see [Ser03, Sec. 6.1.1].
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
126
Exercises
1.
Show that |H|=24 in the example above.
The following exercises are based on Proposition 4.3 of [Luk93]. They show
that the problems of finding setwise stabilizers, centralizers of elements, and
intersections of subgroups are polynomially equivalent. That is, if any one of
them is solvable in polynomial time, then so are all three.
2.
Let G≤Sym(Ω) and 
. Let 
 be the union of two disjoint
copies of Ω where, for α∈Ω, the corresponding points in Ωi will be denoted
by αi for i=1, 2. Let G act diagonally on . (That is, if αg=ß for α, ß∈Ω,
then 
 for i=1, 2.) Define x∈Sym( ) by
 (i)
 for i=1,2 and 
;
(ii)
, 
 for a∈∆.
Prove that G∆=G∩Gx=CG(x) (where we have identified G with 
).
Hence, if either the intersection or the centralizer problem is solvable
in polynomial time, then so is the setwise stabilizer problem.
3.
Let G, H≤Sym(Ω) and let G×H act on Ω×Ω in the natural way. Let
∆={(α, α)|α∈Ω}. Prove that {(g, g)|g∈G∩H}=(G×H)∆. Hence, if the
setwise stabilizer problem is solvable in polynomial time, then so is
the intersection problem.
4.
Let G≤Sym(Ω) and x∈Sym(Ω), and let G and x act diagonally on Ω×Ω.
Prove that {(g, g)|g∈CG(x)}=G∆ with ∆={(α, αx)|α∈Ω}. Hence, if the
setwise stabilizer problem is solvable in polynomial time, then so is the
centralizer problem.
4.6.7 Transversals and actions on cosets
In this subsection, we discuss the problem of computing a transversal of a
subgroup H of a permutation group G, and the related problem of computing
the action of G by right multiplication on the set of right cosets of H in G, as
defined in Example 2.4.
We shall describe two different methods of computing transversals. The
first of these generates the transversal elements one at a time, with very
little storage overheads. It is not well adapted for finding the coset
representative of a given group element, however, so it is not so useful for
computing the action of G on the cosets. The second method has much larger
storage overheads, but is well adapted for locating coset representatives of
group elements. Both methods involve a backtrack search through the
elements of G.
The first method naturally computes left coset rather than right coset
representatives, but this in itself is not significant, because we can move
from a left transversal to a right transversal, if required, simply by inverting
all elements. As the representative of the coset gH, we choose the least
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
127
element in the coset gH under the ordering  defined at the beginning of this
section.
We use Proposition 4.7 (i) to test whether g is the required representative.
We do this in the same way as in SUBGROUPSEARCH: at a vertex at level
l in the search tree, TEST(g, l) checks that 
 is the least element of
its 
 orbit. This requires us to carry out base changes to make
B(l)g the initial segment of the base BH of H that we are using. For a vertex
representing a group element g at the bottom layer k of the tree, we will
have carried out this test for all l with 1≤l≤k, and hence, by Proposition 4.7,
we will know that g is the required coset representative.
Example 4.7
Let G:=Alt(5) and 
, with B:=[1, 2, 3]. So |H|=6
and |G:H|=10. Since H(3)=1, the three elements 1, (3, 4, 5), (3, 5, 4) are all
appended to the (initially empty) transversal T. Moving up to level 2, with
1g=1, the base image 2g=3 is rejected, because that would result in 
3 with h=(2, 3) (4, 5)∈H. (In this example, the ordering of Ω that we are using
is the natural one because the base is [1, 2, 3, 4].) With 2g=4, TEST(g, 2)
returns true, so we descend to level 3, and change base of H from [1, 2] to [1,
4]. Since H[1, 4]=1, all three elements (2, 4, 5), (2, 4) (3, 5), (2, 4, 3) are appended
to T. Now 2g=5 is rejected at level 2, because 
 with h=(2, 3) (4, 5),
so we go up to level 1.
The base images 1g=2 and 1g=3 are rejected, because they would result in
1gh=1 for h=(1, 3, 2) and h=(1, 2, 3), respectively. So we move on to 1g=4,
which is not rejected, change the first base point of H to 4, and go down to
level 2. Now 2g=1 passes the test, as do all three of its descendants, so (1, 4,
5, 3, 2), (1, 4, 3, 5, 2), (1, 4, 2) are appended to T. Base images 2g=2 and 2g=3
are rejected, since then 2gh=1 with h=(1, 3, 2) or (1, 2, 3)∈H4. So we move on
to 2g=5, which is not rejected, because {5} is an orbit of H4. We then change
base of H to make [4, 5] an initial segment, yielding the base [4, 5, 1]. Now
base image 3g=1 is accepted, yielding the final transversal element (1, 4, 2, 5,
3). The complete left transversal is
 
It is possible to find the coset representative of a given element of G, but this
involves base changes to H, so we would not want to have to do this for large
numbers of elements. For example, to find the coset representative of g=(1, 5,
3), choose h∈H to minimize 1gh and replace g by gh. So we could take h=(2, 3)
(4, 5) and replace g by gh=(1, 4, 5, 2, 3). Now change first base point of H to
4 and choose h∈H4 to minimize 2gh. So we take h=(1, 2, 3), and replace g by
gh=(1, 4, 5, 3, 2). Now, make the second base point of H equal to 2g=1, and
we have H4,1=1, so g must now be in the transversal.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
128
We turn now to the second method, in which we compute right coset
representatives of H in G. Unlike the first method, this does not quite
follow the pattern of our standard backtrack search through G. The
procedure takes place in stages corresponding to the base points, which
happen in reverse order k, k - 1,…, 1. Initially, we define 
and then, in stage l, we compute coset representatives, 
, such that
 
is a right transversal of H(l) in G(l). The required transversal is then T(1).
As usual, let U(l) be a right transversal of G(l+1) in G(l). Then an element
of 
=T(l)\T(l+1) will have the form hu for h∈G(l+1) and u∈U(l)\{1}, and we
can clearly assume that h is in T(l+1), which we have already computed. So
the method is to consider all u∈U(l)\{1} in turn, in order of increasing base
image 
 and, for each such u, we consider tu for all t∈T(l+1). We then test
whether tu∈Hg for any g that is already in T(l) and, if not, then we adjoin tu
to 
 and (by definition) to T(l).
Suppose that tu∈Hg with g∈T(l). Then g=t′ u′ for some t′∈T(l+1) and
u′∈U(l). We cannot have u=u′, because in that case t and t′ would be in
distinct cosets of H in G by assumption. So, since we are considering
u∈U(l)\{1} in order of increasing βl
u we must have 
. But
t′u′=htu for some h∈H(l), so 
 for some 
 in the l-th basic
orbit of H. Conversely, if 
 for some such γ, then tu∈Hg for some
g∈T(l). This condition is readily testable from a knowledge of the original
basic orbits of H, and no base changes are needed. We can stop as soon as
|T(l)|=|G(l):H(l)|.
This method is generally a little faster than the first method, because
base changes to H are not necessary. But it has considerably larger memory
requirements. In order to compute 
 we need first to store T(l+1), and so T(2)
will need to be stored in order to complete the computation. If the index is too
large for this to be practical, and we wish to consider the coset representatives
one at a time, then the first method should be used. However, we would not
normally store elements of T(l) as complete permutations, unless they were
all explicitly required. They can be more economically stored as permutation
words in the transversals U(l). Further space can be saved by the use of a
tree structure, which we shall describe below.
Let us carry out this computation on Example 4.7. We choose:
 
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
129
We start with T– (4) = {1} and then H(3)=1 implies that T– (4) = {(3, 4, 5),
(3,5,4)}. Now moving on to Stage 2, we first consider g:=t(2, 3, 4) for t∈T(3).
The second basic orbit of H is {2, 3}, so g will be put into T– (2) if and only if
3g≥3, which is the case for t=1 and t=(3, 5, 4), but not for t=(3, 4, 5). So we
put (2,3,4) and (2,3,5) into T–(2). Next we consider t(2, 4, 5) which is put into
T– (2) only for t=(3, 4, 5), when g=(2,4) (3, 5).
We now have |T(2)|=6=|G(2):H(2)|, so we move on to Stage 1. First we
consider g:=t(1, 2, 3) for t∈T(2). The first basic orbit of H is {1, 2, 3}, so g will
be put into T–(1) if and only if 2g≥2 and 3g≥2. This occurs for t=(3, 4, 5), (3, 5, 4)
and (2, 4)(3, 5), so the corresponding elements (1, 2, 3, 4, 5), (1, 2, 3, 5, 4) and
(1, 2, 4, 3, 5) are put into T– (1). Finally g=t(1, 3, 4) goes into T– (1) only for t=(2,
3, 5), when g=(1, 3, 5, 2, 4), and T(1) then contains 10 elements and is
complete. The resulting right transversal is
 
With this method, we can also identify the coset representative of a given
element of G without having to change base of H. Let us demonstrate how to
do this in the example on g=(1, 4, 2, 3, 5). We first find the element γ in the
first basic orbit {1, 2, 3} of H such that γg is as small as possible. So γ=2, and
we replace g by hg where h∈H with 1h=2; we can take h=(1, 2, 3) and replace
g by (1, 3, 4, 2, 5). Now we know that the required representative is tu,
where t∈T(2) and u∈U(1) with 1u=3; that is, u=(1, 3, 4), and we have to find
the coset representative in T(2) of g2:=gu—1=(2, 5, 4). For this, we look for γ in
the second basic orbit {2, 3} of H with γg2 minimal, so γ=3 and we replace g2
by hg2 with h=(2, 3) (4, 5); that is, by (2, 3, 5). Since H(3) is trivial, we now
have g2∈T(2) so the required coset representative of (1, 4, 2, 3, 5) is g2u=(1, 3,
5, 2, 4).
We can save some space by storing the coset representatives in a tree
structure, as in the diagram below for the above example. This is similar to
the diagram in Subsection 4.6.1 above rotated through 90 degrees, but we
have only shown the branches of the tree that lead to transversal elements.
These are numbered on the right of the diagram, and occur in the same order
as the list above. So, for example, by reading the edge labels of its branch, we
see that element number 8 of T is 
.
Storing this data structure requires two machine words for each node of
the tree: a pointer to the next node at the same level, and a pointer to the
first child at the next level down, or the number of the coset in the case of a
leaf. This is typically significantly less than the |B||G:H| words required
to store the coset representatives as individual permutation words. The
tree structure has the added advantage that we can identify the coset of an
arbitrary group element by tracing its path through the tree, and then we
immediately know the number of coset when we reach its leaf. If we were
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
130
just using permutation words, then we would need to use a hashing algorithm
to attach numbers to transversal elements, which would require yet more
space.
Now let Ω be the set of right cosets of H in G, and let ϕ:G→Sym(Ω) be
the action of G by right multiplication on Ω, as defined in Example 2.4.
Since we can compute the coset representative of any element in G, it is
straightforward to compute ϕ(g) for any g∈G; we just need to find the
coset representative in T of tg for each t∈T. If we need to calculate ϕ(g)
for many g∈G, then there are two possible methods. We could simply do
it for each g, as just described. Or we could calculate ϕ(g) in this manner
just for the generators of G, and then use the general method for group
homomorphisms described in Section 3.4 and Section 4.5 to compute ϕ(g)
for subsequent g∈G. It turns out that the first method is faster if |G:H|
is small, particularly if im(ϕ) is much smaller than G itself, but the second
method can be faster if |G:H| is very large, so this choice of  methods
can be a difficult one.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
131
4.6.8 Finding double coset representatives
DEFINITION 4.12 If H and K are subgroups of a group G, then a double
coset of H and K in G is defined to be a subset of G of the form HgK:={hgk
| h∈H, k∈K} for some fixed g∈G.
As with single cosets, it is straightforward to prove that two double cosets of
H, K in G are either equal or disjoint, and so the double cosets partition G,
and we can define a set of double coset representatives of H, K in G to be a
subset {g1,…,gt} of G such that G is the disjoint union of the double cosets
HgiK (1≤i≤t).
There are a number of algorithms in CGT that require the computation of
sets of double coset representatives; we shall see one later, in Section 9.1.
Unfortunately, no really satisfactory algorithm for solving this problem has
been found to date.
The straightforward approach is as follows. First find representatives of
the set Ω of right coset representatives of H in G, together with the ‘coset
action’ homomorphism ϕ:G→Sym(Ω), as described in the preceding
subsection. Then {g1,…, gt} is a set of double coset representatives of H, K
in G, where Hg1,…, Hgt are representatives of the orbits of the action of
K on Ω defined by ϕ. (We leave the proof of that statement to the reader.)
So we can use the standard orbits procedures described in Section 4.1 to
find them.
The problem, of course, with this method is that it involves calculation of
the set of coset representatives of H in G, which is typically much larger
than the required set of double coset representatives. One simple possibility
for improved performance is to notice that, if K is larger than H, then it is
quicker to compute the transversal and coset action homomorphism using K
rather than H. This will enable us to find representatives {g1,…,gt} of the
double cosets KgH, and then 
 is a set of representatives of the
double cosets HgK.
If H is not a maximal subgroup of G, then the following divide-and-
conquer approach due originally to Laue for solvable groups [Lau82], and
implemented for general finite groups in GAP by Hulpke can be used. Let
X be a subgroup of G with H<X<G. First construct the coset action
homomorphism of G on the set Ω of right cosets of X in G, and use this to
find orbit representatives Xg1,…, Xgt of the action of K on Ω, together with
the corresponding stabilizers K1,…, Kt of Xgi in K. Let Hx1,…Hxs be the
right cosets of H in X and, for 1≤i≤t, compute orbit representatives of the
action of Ki by multiplication on the right on the set {Hx1gi,…Hxsgi}. If
these orbit representatives are 
, then the required double
cosets representatives of H and K in G are the elements 
 for 1≤i≤t and
1≤k≤ui.
More generally, a chain of subgroups H<X1<…<Xk<G can be used in this
manner to reduce the problem to a union of smaller problems.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
132
We also mention a method due to G.Butler for finding a canonical
representative of a given double coset, which is described in [But84], This
is, however, known to be an NP-hard problem in general; see [Luk93].
Exercises
1.
Show that two double cosets of H, K≤G are either equal or disjoint.
2.
Prove that the stabilizer in K of the coset Hg in the action of K by right
multiplication on the right cosets of H in G is equal to 
. Deduce
that |HgK|=|H||K|/
.
4.7 Sylow subgroups, p-cores, and the solvable
radical
Finding the Sylow subgroups of a given finite group is one of the most basic
problems in CGT, and algorithms for solving this and related problems are
among the most frequently used in practice. It is also unusually interesting
as one of the few problems in finite permutation groups that are known to be
solvable in polynomial time, but only by algorithms that rely on the
classification of finite simple groups and on nontrivial properties of the finite
simple groups. These algorithms were devised by Kantor and described in
[Kan85] and [Kan90]. They have not yet been fully implemented, and there
remain significant impediments to an implementation that could efficiently
handle groups having exceptional groups of Lie type as composition factors.
The current implementations in GAP and MAGMA still rely partly on
backtrack searches, so they are not polynomial-time algorithms. The
backtrack searches arise in certain centralizer computations, which
fortunately are very fast in practice much of the time. Much of the work in
developing these methods was by Butler and Cannon, and is described in
[BC91] and various earlier papers, such as [BC89]. Various later ideas for
cutting down the number of situations where one needs to resort to backtracks
searches, as well as the size of the groups involved in these searches are
discussed by P.M.Neumann in [Neu87] and by Cannon, Cox, and Holt in
[CCH97b], and we shall describe some of these techniques in this section.
Current implementations seem to run reasonably quickly on moderately large
examples, but the existence of the backtrack searches means that there
remains a danger of encountering unsatisfactory behaviour whenever we try
to compute with larger examples than previously.
Other subgroups that we should like to be able to compute efficiently include
the p-core Op(G), for a prime p, which is defined to be the largest normal
subgroup of G of order a power of p, and the solvable radical O∞(G), which
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
133
is defined to be the largest normal solvable subgroup of G. Although the p-
core was at one time computed as the intersection of the Sylow p-subgroups
of G, this turned out not to be a good approach, since it involves backtracks
in both the Sylow subgroup and intersection phases.
It is shown, for example, by Luks in [Luk93], that both Op(G) and O∞(G)
are computable in polynomial time, and nearly-linear-time algorithms are
described in Section 6.3.1 of [Ser03]. Fast practical algorithms are also available
for computing these subgroups. The approach that we shall describe here
for Op(G) is due to Unger [Ung02].
We have already (in Subsection 3.1.1) remarked on the unfortunate fact
that we cannot in general find a faithful permutation representation of a
quotient group G/N of a permutation group G of degree comparable to that of
G. However, it turns out that we can find such a representation for G/
Op(G) and for G/O∞(G). This result was first proved by Easdown and Praeger
in [EP88] and is also proved by Holt in [Hol97], where it is shown that the
homomorphisms involved can be computed explicitly. We shall include a
proof of it here. It enables us to compute O∞(G) by first finding some
nontrivial Op(G) and then solving the problem recursively in G/Op(G).
4.7.1 Reductions involving intransitivity and imprimitivity
We can reduce the difficulty of many computational problems in finite
permutation groups by a divide-and-conquer technique using actions on orbits,
in the case of intransitive groups, and actions on blocks, in the case of
imprimitive groups.
Some of these reductions are based on the idea of solving the problem, in
turn, in two proper quotients G/M and G/N of G, where M N=1. More
precisely, we have the following results for Sylow subgroups and Op(G).
LEMMA 4.13 Let G be a finite group having normal subgroups M and N
with M N=1 and let µ:G→G/M and v:G→G/N be the natural epimorphisms.
Let p be a prime.
 (i) Let Q/M∈Sylp(G/M) and Q:=µ-1(Q/M), and let 
and 
 Then P∈Sylp(G).
(ii) Let Q/M=Op(G/M) and Q:=µ-1(Q/M), and let 
 and
 Then P=Op(G).
PROOF (i) Clearly Q contains a Sylow p-subgroup of G and, since M  N=1,
Q N is a p-group. Similarly, R contains a Sylow p-subgroup of Q and hence
of G. Now R=PN, where 
 is a p-group. Furthermore
P N=Q N, so P N and hence P is a p-group, and the result follows.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
134
(ii) As in (i), P N=Q N is a p-group, so P=Op(Q). But Op(G)≤Q, so
Op(G)=Op(Q)=P. 
There are two specific situations in which we will apply this lemma. The first
is when GΩ is intransitive, in which case we can write Ω=Ω1∪Ω2 where G fixes
the nonempty and nonintersecting sets Ω1 and Ω2. As we saw in Subsection
4.5.1, we can compute easily and efficiently with the induced action
homomorphisms 
 and 
. Let M:=ker(µ) and N:=ker(v).
Then, since G is a permutation group on Ω=Ω1∪Ω2, we have M∩N=1.
We can then recursively call our algorithm for computing Op(G) or a
Sylow p-subgroup of G on 
 and 
, which both have
smaller permutation degree than G. Then we can use the recipe in Lemma
4.13 to construct Op(G) or a Sylow p-subgroup of G.
The second situation is when GΩ is imprimitive and has two distinct minimal
block systems Σ1 and Σ2, say. Of course, to apply this reduction, we first need
to apply the algorithms described in Section 4.3 to find all such minimal
block systems. Here, we let 
 and 
 be the induced
action homomorphisms. We saw in Subsection 4.5.2 that we can compute
effectively with these homomorphisms. Again, we must have M∩N=1,
because otherwise the orbits of M∩N would form a block system with blocks
strictly contained in the blocks of Σ1 and Σ2, thereby contradicting their
minimality. So again we can solve our problems by using recursive calls to
smaller examples.
In the case of a unique minimal block system Σ, we can still use recursion
on GΣ, which enables us to assume that GΣ is a p-group, but we cannot make
any immediate further reductions. (A p-group is, by definition, a group of
order pn for some n≥0.)
In the following two subsections, we shall consider in more detail the
cases of computing Sylow p-subgroups and Op(G). It will turn out that, for
Op(G), the unique minimal block system obstacle does not arise.
4.7.2 Computing Sylow subgroups
As explained in the previous subsection, when computing a Sylow p-subgroup
of G, we can assume, by recursion and part (i) of Lemma 4.13, that G is
transitive, and is either primitive, or is imprimitive with a unique minimal
block system Σ such that GΣ is a p-group. We can also assume that |Ω| is
divisible by p, since otherwise we just compute a Sylow p-subgroup of the
smaller group Gα for some α∈Ω.
There are other possible reductions we could make. One approach, which
is advocated in [CCH97b], is to solve the Sylow subgroup finding algorithm
at the same time as solving the problem of finding a conjugating element for
two Sylow subgroups P and Q of G. This allows us to make further reductions
in the imprimitive case, by using mutual recursion between the two
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
135
problems. Another possibility, which we shall mention again in a later
chapter, is to compute O∞(G) and, if it is nontrivial, recursively compute
R/O∞(G)∈Sylp(G/O∞(G)), and then find a Sylow p-subgroup of the solvable
group R, possibly using a PC-representation.
But however many recursions we make, if our group is primitive and
non-abelian simple, then we can make no more of these types of reductions.
In the polynomial-time algorithm of Kantor, we would first need to identify
the isomorphism type of the simple group. This is not difficult and, by
Proposition 10.8, it can nearly always be done just from a knowledge of |G|.
In the few ambiguous cases, there are simple tests to distinguish between
the two possibilities. We then need to set up an isomorphism between G and
the natural representation of the isomorphic simple group. For example, if
, then we would define an epimorphism from the natural
representation of SL(n, q) as a group of d×d matrices over 
 to G. We then
simply ‘write down’ a Sylow subgroup in the natural representation, and
compute a Sylow subgroup of G by using the isomorphism.
There is one situation in which we do this without any further work at all,
namely when G is the alternating or symmetric group on Ω, when it is
straightforward to simply write down a Sylow p-subgroup, so we should
certainly do that.
Otherwise, in the absence of the relatively large amount of machinery
required to implement the Kantor approach, which we have only hinted at
here, we are forced to fall back on backtrack algorithms. The most successful
approach to this has been the method of Butler and Cannon, which we shall
describe here. The backtrack part of the method occurs in the calculation of
centralizers of group elements. Other possible approaches use normalizer
calculations, but they are typically significantly slower than centralizer
calculations.
The basic aim of the Butler-Cannon method is to find an element g∈G of
order p such that C:=CG(g) contains a Sylow p-subgroup of G. Once we have
done that, and calculated C, then we apply recursion to C and thereby assume
that C=G. Now g has order p, so the orbits of g have size 1 or p. Since we are
assuming that GΩ is transitive, and, by Proposition 4.9, G permutes the
orbits of g, all of the orbits of g must have order p, and they form a minimal
block system Σ of GΩ. We are also assuming that GΣ is a p-group. We claim
that G is p-group, and so in fact we are done.
To prove this, we must show that the kernel K of the action of G on Σ is a
p-group. Let Ωi (1≤i≤r) be the orbits of g and, for 1≤i≤ r, let gi be the
permutation of Ω that acts like g on Ωi, and fixes all points of Ωj for j≠i. Then
the elements gi generate an elementary abelian p-group Q of order pr, which
contains g. We claim that K≤Q. To see this, let h∈K. Since K≤C, 
centralizes 
 for each i, and so, by Corollary 4.11, 
 for
some mi with 0≤mi<p. Then 
, which proves the claim.
There remains the problem of finding a suitable element g. We start by
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
136
SYLOW(G, p)
Input: A permutation group G and a prime p
Output: Generators of P∈Sylp(G)
1 if G is a p-group then return G;
2 if GΩ is intransitive then recurse on orbit actions;
3 if p does not divide |Ω| then recurse on Gα;
4 if GΩ is imprimitive with two minimal block systems
5
then recurse on block actions;
6 if GΩ is imprimitive with unique minimal block system Σ and     
GΣ is not a p-group
7   
then recurse on GΣ;
8 if G=Sym(Ω) or Alt(Ω) then return a Sylow p-subgroup;
9 Find an element g of G of order p;
10 if p2 does not divide |G| then return 
;
11
Compute C := CG(g);
12 while C does not contain a Sylow p-subgroup of G
13
do Find S∈Sylp(C) and compute Z :=Z(S);
14
for elements h∈Z with |h|=p do compute Ch:=CG(h)
15
until we find an h such that p divides |Ch/S|;
16
Replace C by Ch;
17 Recurse on C;
looking for any element g of order p. To do this, we choose random elements
h of G until we find one whose order pm is multiple of p, and take g:=hm. In
many groups this works very quickly. There are a few examples in which it
does not; for example, there are groups of order p(p-1) in which only p-1
elements have order a power of p, which is a small proportion when p is
large. In this, and other similar examples, a policy of sometimes choosing h
to be a commutator of random elements already considered will often find the
required element quickly.
Having found g of order p we must then compute C:=CG(g). If C contains
a Sylow p-subgroup of G then we are done. Otherwise, we still compute
S∈Sylp(C). Now, by Sylow’s theorem, S is contained in some P∈Sylp(G),
and P has nontrivial centre, so there exists h∈Z(P) with h of order p. Since
h∈C, we must have h∈S, because otherwise S would be properly contained
in P∩C, contradicting S∈Sylp(C). So we know that there exists an element
g of order p in Z(S) having the required property that CG(g) contains a
Sylow p-subgroup of G.
So we compute Z(S), which is not difficult, and then search through the
elements g of order p (see Exercise 3 below) in Z(S) looking for the required
g. This necessitates computing CG(g) for each such g, and is potentially the
slowest part of the algorithm because, in a bad case, there could be many
such elements g, with only a small proportion of them having the required
centralizer. In practice, if we find any g for which the Sylow p-subgroup of
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
137
CG(g) is larger than S, then we replace S with this new Sylow p-subgroup.
SYLOW is a summary of the complete Sylow p-subgroup algorithm.
4.7.3 A result on quotient groups of permutation groups
In this subsection, we shall prove the following result, which was probably
first proved by Easdown and Praeger in [EP88]. The specific classes of
groups to which we shall apply the result are the classes of all abelian groups,
and of all elementary abelian p-groups for some prime p.
THEOREM 4.14 Let G be a finite permutation group on Ω of degree n. Let
A be a class of finite abelian groups closed under subgroup, quotient, and
direct product, and let N be a normal A-subgroup of G. Then there exists a
permutation representation ϕ of G of degree at most n, such that the kernel
K of ϕ is an A-group that contains N.
PROOF We may clearly assume that N≠1. Let S :=Sym(Ω), let Σ be the set
of orbits of N on Ω, and let Γ be a subset of Ω containing one representative
from each orbit ∆∈Σ. Let L be the subgroup of S consisting of all g∈S such
that g fixes each ∆∈Σ and, for all ∆∈Σ, there exists h∈N with g∆=h∆. Then
L is isomorphic to the direct product of the induced action groups N∆ for
∆∈Σ, and so, by the assumptions on the class A, we ave L∈A. It is easy to
check that L is normalized by G. Let E:=GL, and let K:=G∩L. Then clearly
N≤K, K∈A (since A is subgroup closed), and 
.
Let D:=EΓ be the setwise stabilizer of Γ in E. We claim that E=DL. Let
e∈E. To establish the claim, we shall define an element f∈L such that ef ∈D.
To do this, we need to define f∆ for each ∆∈Σ. Since G permutes the set Σ, we
have 
 and there is a unique point 
. Then γe∈∆, and so
there exists h∈N with γeh equal to the unique point in Γ∩∆. We define f∆ to
be equal to h∆. Then, by definition of L, we have f∈L, and by choice of h, we
have γef∈Γ for all γ∈Γ. Thus ef∈D, and E=DL as required. Since L is abelian,
by Corollary 4.11, any element in L that fixes a point of one of its orbits fixes
the whole orbit pointwise. But L∩D must fix every point in Γ, and hence
L∩D=1, and D is a complement of L in E.
Now we have 
, and since D is a permutation
group of degree n, we can define the required permutation representation ϕ
of G by ϕ(g)=gf∈D, where f is as defined above for e=g. This completes the
proof. 
     
For computational applications, it is important to observe that the proof
allows us easily to compute ϕ(g)=gf for g∈G, and hence we can compute
effectively with the homomorphism ϕ.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
138
COROLLARY 4.15 Let G be a finite permutation group on Ω of degree n.
Then there exist faithful permutation representations of degree at most n of
G/Op(G), for any prime p, and of G/O∞(G).
PROOF The proof is by induction on |G|. The results are all clear if
O∞(G)=1, so assume not, and let N be a minimal normal subgroup of G
contained in Op(G) or in O∞(G), as appropriate. Since O∞(G) is solvable, its
composition factors are all cyclic groups of prime order, and it follows
from Corollary 2.32 that N is an elementary abelian p-group. So, by
Theorem 4.14, there is an abelian group K containing N such that G/K
has a permutation representation of degree at most n, and the result
follows by induction applied to G/K. 
     
Provided that we can compute Op(G) for primes p, which we shall be
explaining how to do in the next subsection, then the representations in
Corollary 4.15 can again be computed explicitly. For the representation of
G/Op(G), we could, for example, first compute Op(G), then N := Z(Op(G)),
then use Theorem 4.14 to find a faithful permutation representation ϕ1 of
G/K1 where N≤K1≤Op(G). Then, if K1≠Op(G), we repeat the process on
im(ϕ1) to get a faithful permutation representation of G/K2 where
K1<K2≤Op(G), and carry on like this until we have the required
representation ϕ of G/Op(G). (Notice that it is neither necessary nor
desirable to choose N to be elementary abelian like we did in the proof of
the corollary.)
To get the faithful representation of G/O∞(G), we first find a prime p
with Op(G)≠1, then find a faithful permutation representation ϕ1 of G/
Op(G), as described above. Then, if Op(G)≠O∞(G), we repeat the process
on im(ϕ1), and carry on until like this until we have found the required
representation.
4.7.4 Computing the p-core
The method that we shall describe here for Op(G) is due to Unger [Ung02].
As was the case for Sylow p-subgroups, we can reduce, by recursion and part
(ii) of Lemma 4.13, to the situation where G is transitive, and is either
primitive, or is imprimitive with a unique minimal block system Σ such
that GΣ is a p-group.
Let us first deal with the unique minimal block system case. Let K be the
kernel of the action of G on Σ. If K=1, then G is a p-group and G=Op(G), so
assume not. We recursively compute Q :=Op(K). Suppose that Q=1. Then
we claim that Op(G)=1. If not, then let N be a minimal normal subgroup of
G contained in Op(G). Since the composition factors of any p-group are
cyclic of order p, it follows from Corollary 2.32 that N is an elementary
abelian p-group. Since Q=1, we have K∩N=1, and hence [K,N]≤K∩N=1, so
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
139
K≤ CG(N). Let ∆ be an orbit of NΩ. Then, by Proposition 2.29, either ∆=Ω,
or ∆ is a block of imprimitivity of GΩ. Since Σ is the unique minimal block
system of GΩ, it is true in either case that ∆ is a union of blocks of Σ. So K
fixes the set ∆, and then Corollary 4.11 implies that K∆≤N∆ and hence K∆
is a p-group. But this is true for all orbits ∆ of K, so K is a p-group,
contradicting Q=1. Hence Op(G)=1 as claimed, and so we may assume that
Q=Op(K)≠1.
Now we compute N:=Z(Q) and use Theorem 4.14 to construct a
epimorphism ϕ:G→H for which M:=ker(ϕ) is a p-group containing N. Then
we can apply recursion to compute Op(H) and hence Op(G):=ϕ—1(Op(H)).
It remains to deal with the case in which GΩ is primitive. In that case, if
Op(G)≠1, then let N be a minimal normal subgroup of G contained in Op(G).
As above, N is elementary abelian, and NΩ is transitive by Proposition 2.29
and regular by Corollary 4.11. So it is an elementary abelian regular normal
subgroup, which is often abbreviated to EARNS, of G.
If N<Op(G), then Z(Op(G))∩ N≠1, but by Corollary 4.11 again, we cannot
have N≤Z(Op(G)), so 1<Z(Op(G)) ∩ N<N, contradicting the minimality of N
as a normal Subgroup of G. Hence N=Op(G).
So the problem reduces to deciding whether a primitive group has an
EARNS. The method that we shall describe for this comes originally from
P.M. Neumann [Neu87]. If the degree n of G is not equal to a prime power pd,
then clearly G has no EARNS, so we may assume that n=pd.
First we need to recall some basic properties of Frobenius groups.
DEFINITION 4.16 A Frobenius group is a transitive permutation group on
a set Ω such that Gα≠1, but Gαß=1 for all distinct α, ß∈Ω.
Let GΩ be a finite Frobenius group of degree n. By a simple counting argument,
we find that there are exactly n-1 elements of G that fix no point of Ω. The
fundamental result of Frobenius, dating from 1901, is that these n-1
elements, together with the identity, form a normal subgroup K of G, known
as the Frobenius kernel of G. The proof uses character theory, and no proof
is currently known that does not use character theory. The stabilizer Gα is
known as the Frobenius complement. Various properties of the Frobenius
complement can be shown without too much difficulty. For example, the
centre is nontrivial, the Sylow p-subgroups are cyclic for p odd, and cyclic or
generalized quaternion for p even, and A5 is the only possible nonabelian
composition factor of a Frobenius complement. A much deeper result, due to
J.G. Thompson (1959), is that the Frobenius kernel is nilpotent. For proofs of
all of these properties see, for example, [Pas68].
Returning to our EARNS algorithm, we first check whether Gαß=1 for all
distinct α, ß∈Ω. If so, then either Gα=1, in which case GΩ primitive implies
that |G|=p, so G itself is the EARNS, or G is a Frobenius group. In that
case, we compute Z=Z(Gα) for some α, which we know is nontrivial, choose
z∈Z\{1}, choose h∈G\Gα, and let g:=[h, z]. Then g≠1 is in the Frobenius
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
140
kernel of G (exercise) and, since GΩ is primitive, we can compute the full
kernel, which is the required EARNS, as the normal closure 
.
So we assume that Gαß≠1 for some distinct α, ß∈Ω. We fix α and then
choose ß from the orbit of Gα on Ω\{α} of the smallest size. This gives the
largest possible |Gαß|, so clearly Gαß≠1 with this choice. Let ∆ be the set of
fixed points of Gαß; that is, 
.
Suppose that G does have an EARNS N. Then, for γ∈∆, there is a (unique)
g∈N with αg=γ. For h∈Gαß, we have g—1hg∈Gγ, so [h, g]∈N∩Gγ=1, and
hence g∈C := CG(Gαß). In particular, N∩C acts regularly on ∆, so if |∆| is
not a power of p, then G has no EARNS, and we are done.
Otherwise, we compute C. This is typically an easy centralizer computation,
but it can be done in polynomial (indeed, in almost linear) time; see Section
6.2.3 of [Ser03] for details. If C does not act transitively on ∆, then again G
has no EARNS, so assume that it does.
For any γ∈∆\{α}, we have Gαß≤Gαγ by definition of ∆, but the the choice
of β forces Gαβ=Gαγ, so Gαγ fixes all points of ∆, and C∆ must be regular or a
Frobenius group. In the latter case, (N∩C)∆ must be the Frobenius kernel.
So we compute this kernel K∆ as described above for the case when GΩ was a
Frobenius group, and then let K be the inverse image of K∆ in C. (There is an
extra complication here, because C∆ might be an imprimitive Frobenius group,
but we can choose further generators of the form g:=[h, z] for z∈Z(Cα) and
random h∈C\Cα until we have generated the whole of K.) If C∆ is regular,
then we just let K=C.
In either case, we now have a subgroup K≤C with K∆ regular which, if
the EARNS N exists at all, satisfies N∩C≤K and (N∩C)∆=K∆. Next we
compute the subgroup P:={x∈Cαβ|xp=1}; see Exercise 3 below. Choose any
x∈C with |x|=p and x∉Cαβ. (Any 1≠x∈N∩C has this property, so if there is
no such x, then G has no EARNS.)
Then x∆=g∆ for some g∈N∩C, so x—1g∈P. Hence we can find g as xh for
some h∈P. For each such xh, we test whether g:=xh∈N by computing 
,
and checking whether it is an EARNS. If we try all h∈P and find no EARNS,
then G has no EARNS. It can be shown (see exercises below) that if N exists,
then |P≤ pd—1 (recall that n=|Ω|=pd), so there are not too many elements to
try! As a refinement, if, on calculating P, we find that |P|>pd—1, then there
can be no EARNS, and we can stop immediately.
P-CORE is a summary of the complete p-core algorithm.
4.7.5 Computing the solvable radical
It is now straightforward to compute the solvable radical O∞(G) of G. We
consider the primes p dividing |G| and compute Op(G) as described above.
If Op(G)=1 for all such p, then O∞(G)=1.
If we find a prime p with Op(G)≠1 then, by Corollary 4.15, we can compute
an explicit epimorphism ϕ:G→H:=G/Op(G). Now we can recursively
compute O∞(H) and hence compute O∞(G):=ϕ-1(O∞(H)).
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
141
P-CORE(G,p)
Input: A permutation group GΩ and a prime p
Output: Generators of Op(G)
1 if G is a p-group then return G;
2 if GΩ is intransitive then recurse on orbit actions;
3 if GΩ is imprimitive with two minimal block systems
4   
then recurse on block actions;
5 if GΩ is imprimitive with unique minimal block system Σ
6
then Compute the kernel K of the action of G on Σ;
7
if K=1 then recurse on GΣ;
8
Compute Q :=Op(K);
9
if Q=1 then return {};
10
Compute N :=Z(Q);
11
Find a permutation representation ϕ of G such that
M:= ker(ϕ) is a p-group with N≤M;
12
Recursively compute L:=Op(im(ϕ));
13
return generators of ϕ—1 (L);
(* Now GΩ is primitive—we use Neumann’s EARNS routine *)
14 if n :=|Ω| is not a power pd of p then return {};
15 Choose α∈Ω;
16 if GΩ is a Frobenius group
17
then Choose 1≠z∈Z(Gα) and h∈G\Gα;
18
return generators of 
;
19 Choose ß in an orbit of Gα on Ω\{α} of minimal length;
20 Compute the fixed point set ∆ of Gαβ;
21 if ∆ is not a power of p then return {};
22 Compute C := CG(Gαβ);
23 If C∆ is not transitive then return {};
24 Compute subgroup R≤C, where R∆ is the regular normal subgroup of
the regular or Frobenius group C∆;
25 Compute P := {x∈Cαβ|xp=1};
26 if |P|>pd—1 then return {};
27 Find x∈R\Caß with |x|=p;
28 for h∈P
29
do Compute 
;
30
if N is an EARNS of G then return generators of N;
31 return {};
4.7.6 Nonabelian regular normal subgroups
In this final section, we shall take note of the fact that Neumann’s EARNS
algorithm can be used almost unchanged to test for the existence of, and find
nonabelian regular normal subgroups in a primitive permutation group GΩ.
We shall be using this in Subsection 10.1.4 as part of an algorithm to find
the socle of a general primitive permutation group.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
142
By Thompson’s result, a Frobenius kernel is nilpotent, and so the Frobenius
kernel of a primitive group is elementary abelian, and hence a primitive
Frobenius group cannot have a nonabelian regular normal subgroup.
As in the EARNS routine, we fix α∈Ω and choose β from the orbit of Gα
on Ω\{α} of the smallest size; then Gαβ≠1. Let ∆ be the set of fixed points of
Gαβ, and compute C:=CG(Gαβ).
As in the EARNS case, for any regular normal subgroup N of G, N∩C acts
regularly on ∆, so if C∆ is not transitive, then there is no such N, and we are
done. By choice of ß, C∆ must either be a Frobenius group or act regularly. In
the first case we find K≤C such that K∆ is the Frobenius kernel, and in the
second case we let K=C.
Choose g∈K of prime order p, with x∆≠1 (if there is no such g, then there
is no regular normal subgroup), and compute the subgroup P consisting of
elements of order 1 or p in Cαβ. Then, as in the EARNS case, a regular
normal subgroup of G is the normal closure of xh for some h∈P, and so we
just try all possible h.
We shall see later, in Theorem 10.1.3, that a primitive group can have one
or two nonabelian regular normal subgroups. If we find one such subgroup
N, then we could either continue the search through h∈P to look for a possible
second subgroup, or use the fact that this second subgroup, if it exists, must
be the centralizer in Sym(Ω) of N.
It can be shown, using the O’Nan-Scott theorem (Theorem 10.1.3), that
|P|<|Ω|, and so this algorithm can be made to run in polynomial time.
Seress points out in Remark 6.2.14 of [Ser03] that it is not almost linear, and
he presents an alternative almost linear Monte Carlo algorithm due to Luks
to find nonabelian regular normal subgroups.
Exercises
Assume that G is finite in these exercises.
1.
Prove that Op(G) is the intersection of the Sylow p-subgroups of G.
2.
Prove that O∞(G)/≠1 if and only if Op(G)≠1 for some prime p.
3.
Let 〈G=〈X〉 be a finite abelian p-group. Devise an algorithm for computing
the subgroup P of G consisting of all elements of order 1 or p.
(Hint: Let 
 with oi≥oi+1 for 1≤i<r, where oi=|xi|. For
each i, if 
, then include 
 as a generator of
P. Otherwise, replace xi by xig for suitable 
 to reduce
|xi|.)
4.
Work out how to write down generators of a Sylow p-subgroup of Sym(n)
using the following steps.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
143
(i)
First write n in base p. That is, 
 with 0≤ai<p. Using
group orders, show that a Sylow p-subgroup of Sym(n) is contained
in the direct product of groups Xi (1≤i≤r), where each Xi is itself
the direct product of ai copies of Sym(pi). This effectively reduces
the problem to the case when n is a power pi of p.
(ii)
When n=pi show that a Sylow p-subgroup of Sym(n) is generated
by a Sylow p-subgroup of Sym(pi—1) acting on the set {1..pi—1}
together with the permutation g∈Sym(n) with jg=j+pi—1 (mod pi)
for 1≤ j≤pi.
(For Pi∈Sylp(Sym(pi)), we have 
 and, for i>1, Pi is the wreath
product 
; see, for example, [Hal59, Sec. 5.9].)
5.
Modify the method of Exercise 4 to write down P∈Syl2(Alt(n)).
6.
Show that there are exactly n-1 fixed-point-free elements in a Frobenius
group of degree n.
7.
In the description of the Op(G) algorithm for Frobenius groups, prove
the claim that the element g defined as [h, z] is a nontrivial element in
the Frobenius kernel.
8.
Let H be any finite group and p a prime with Op(H)=1. Let P be an
abelian p-subgroup of H, and C := CH(P). Prove that |P|≤|H:C|.
(Hint: Use induction on |H:C|. Let Q be a conjugate of P in H that
does not centralize P. Let P* :=P∩CH(Q), C* :=CH(P*), and deduce by
induction that |P*|≤|H:C*|. Assume WLOG that |P*|≥|Q∩CH(P)|,
and deduce |C*:C|≥|P:P*|.)
9.
We saw earlier that, if a primitive group GΩ has an EARNS N, then
N=Op(G) and hence Op(Gα)=1. Taking P to be the elements of order
dividing p in Cαβ with C:=CG(Gαβ) as in P-CORE, apply the result in the
previous exercise to H=Gα to prove that |P|≤pd-1.
4.8 Applications
In this section we briefly review three applications of the methods discussed
in the chapter. The first, to card shuffling, is primarily recreational, but has
some relevance to computer networks. The second is to the construction of
various types of combinatorial objects, including error-correcting codes, which
are important outside of mathematics. The third is another application to
computer networks.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
144
4.8.1 Card shuffling
Consider a deck of 2n cards for some 
 A perfect riffle shuffle is executed
by dividing the deck into two equal piles, and then reassembling it by taking
cards alternately from the two piles. There are two ways of doing this, the
out-shuffle, in which we take the top card of the original deck first, and the
in-shuffle, in which we take the top card of the original deck second when we
re-assemble.
If we number the cards 1,…, 2n from the top downwards in the original
deck, then the permutations go and gi of [1..2n] defined by the out- and in-
shuffles are given by:
 
for 1≤i≤n.
Persi Diaconis, who is one of the few mathematicians who can carry out
perfect riffle shuffles accurately in practice, had been wondering for several
years about the order and structure of the permutation group
 
 generated by the two types of riffle shuffle when,
in the early 1980s he got together with R.L.Graham and W.M.Kantor and
investigated the problem seriously. Eventually they solved the problem
completely [DGK83]. An implementation of the Schreier-Sims algorithm was
used for experimental purposes, and some of the results obtained from these
computations were used in the final proof. Donald E.Knuth was also
involved in these computational experiments, and it was as a direct result
of this application that he carried out his analysis of the Schreier-Sims
algorithm in [Knu81], which was mentioned in Subsection 4.4.3.
It is straightforward to show that {{i, 2n–i+1}| 1≤i≤n} is a system of
imprimitivity preserved by Sh(n), and so Sh(n) is a subgroup of the wreath
product 
 (see Subsection 2.2.5).
It turns out that, for most values of n, Sh(n) has index 1, 2 or 4 in 
Sym(n), depending on the value of n mod 4. For example, in the case n=26
of the standard deck of cards, we have Sh(26)
Sym(n). But there are
some interesting exceptional cases. When n is a power of 2, Sh(n) is much
smaller, and is isomorphic to 
 Furthermore Sh(6) 
 PGL(2, 5)
and, the most interesting exceptional case of all, which was partly what
motivated Diaconis to want to crack the problem, is Sh (12) 
 M12.
Here M12 is one of the five sporadic simple groups discovered in the 19th
century by Mathieu.
This particular problem has applications to the interconnection of
computers in networks for parallel processing, particularly in the case when
n is a power of 2. See also the article of G.Kolata [Kol82] for further
interesting related details, and that of Medvedoff and Morrison87 [MM87]
for generalizations to the situation where the original deck is split into
more than two piles.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
145
4.8.2 Graphs, block designs, and error-correcting
codes
In Subsection 4.6.4, we briefly discussed the use of backtrack searches in
the computation of the automorphism groups of finite combinatorial objects
and testing two such objects for isomorphism. It is also possible to go in the
opposite direction; namely, start with a permutation group G on a finite set Ω
and use it to construct combinatorial structures with vertex set Ω. These
objects will generally contain G in their automorphism group, so it is a useful
technique for finding examples with a relatively large automorphism group.
‘Random’ graphs or designs tend to have trivial or at most very small
automorphism groups.
Later in the book, in Section 10.5, we shall briefly discuss the more
fundamental problems of counting and enumerating all combinatorial
structures of a given type.
The most straightforward construction of a combinatorial structure from
a permutation group produces finite graphs. Usually we choose a transitive
group GΩ, fix α∈Ω, and let ∆ be an orbit of the point stabilizer Gα other than
{α}. Then the graph with vertex set Ω and edge set {(α, ß)g|ß∈∆, g∈G} is
easily seen to be regular of valency |∆|. (That is, each point α is the source
of exactly |∆| edges.) If G contains an element interchanging α and ß for
some ß∈∆, then we will have (α, ß)∈ E if and only if (ß, α)∈E, and so the
graph is undirected. Otherwise, it is directed. Its automorphism group will
always contain G, but it is larger than G in many examples.
In general, a t-(n, k, λ) design on Ω where |Ω|=n is defined to be a set B
of subsets of Ω of size k known as blocks, with the property that any t points
in Ω are contained in exactly λ blocks. (Note: many authors prefer a more
symmetrical definition in which Ω and B are sets with a given incidence
relation between them.) Well-known examples with large t include the 5-
(12,6,1) and 5-(24,8,1) designs, which have the Mathieu groups M12 and M24
as automorphism groups.
Error-correcting codes are used to correct errors introduced during
transmission through noisy communication networks. So techniques for
constructing such codes potentially have technological applications outside
of mathematics. Pless [Ple81] provides an elementary treatment of coding
theory, and Assmus and Key [AK92] describe the connection with designs,
which we shall introduce here.
In general, the codewords to be transmitted will lie in 
, for some q and n.
Since binary bits are universally used in practice, we might prefer to assume
that q=2, but there are some mathematically interesting codes for larger
q. Only words from a fixed subset C of 
, the set of codewords, are
transmitted. For v,w∈
, we define the distance d(v, w) between v and w to
be the number of components in which v and w differ. The minimum
distance d of C is defined to be the minimum of d(v, w) for v, w∈C, with
v≠w. Suppose that codeword v is transmitted, but e of its components are
changed during transmission, so a word v′ is received with d(v, v′)=e. Then,
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
146
provided that 2e+1≤d, v will be the unique element of C with d(v, v′)≤ e,
and so the word v transmitted can be correctly reconstructed from the
word v′ received. In that case C is known as an e-error-correcting code.
There are various desirable properties of a good code. We would like e to
be as large as possible but, for reasons of efficiency, we would also prefer
|C|/qn to be large; unfortunately, these two requirements tend to conflict
with each other! Another important property is the ease of decoding; that is,
for given v′∈
, we need to be able to locate the v∈C with d(v,v′) minimal as
quickly as possible.
A linear code C is one which is a subspace of 
. Most of the codes in
widespread usage are linear, largely because, in favourable examples, decoding
can be accomplished by means of a matrix multiplication. Their minimum
distance is equal to the minimal weight (that is, the number of nonzero
components) of a nonzero vector in C.
The technique that we shall discuss here is to start with a t–(n, k, λ)
design on a set Ω={1..n} with automorphism group containing permutation
group GΩ. Let B be the set of blocks in the design. Now choose a prime p and,
for Β∈B, define vB to be the characteristic function of B as a subset of Ω,
regarded as a vector in 
 Then let C be the subspace of 
 spanned by the
vectors vB with Β∈B. This construction results in some interesting codes.
The two best-known examples are the Golay codes derived in this way from
the 5-(12, 6, 1) design with p=3, and the 5-(24, 8, 1) design with p=2. They
have minimum weights 6 and 8, respectively.
Codes of this kind can be looked for systematically in the following way.
For details of specific examples, see [KMR03] and other recent papers by the
same authors. As in the construction of graphs mentioned above, we start
with a transitive (in fact, primitive) permutation group GΩ with |Ω|=n, fix
α∈Ω and let ∆ be an orbit of Gα other than {α}. (Or, more generally, we can
let ∆ be a union of such orbits.) It turns out that {∆g|g∈G} is a 1-(n, |∆|,
|∆|) design with automorphism group containing G. We can construct
codes from these designs as described above for small primes p.
The MAGMA system is particularly well-suited for carrying out such
computations since, in addition to the standard permutation group machinery,
it contains functions for computing standard properties of designs and codes,
such as their minimum weights and automorphism groups.
As a specific example that was considered by Key and Moori in [KM02],
start with the second Janko group J2. Its primitive permutation
representations correspond to its maximal subgroups, of which there are
nine conjugacy classes. (These maximal subgroups and corresponding
permutation representations acting by right multiplication on their cosets
can also be found quickly by means of standard function calls.) The two
smallest degree primitive representations have degrees 100 and 280.
•
A Gα-orbit ∆ of length 36 in the first of these representations gives rise to
a code of dimension 36 in 
 with minimum weight 16.
© 2005 by Chapman & Hall/CRC Press

Computation in Finite Permutation Groups
147
•
A Gα-orbit ∆ of length 108 in the second representation yields a code of
dimension 14 in 
 with minimum weight 108.
An additional feature and advantage of this type of code is that the
automorphism group can be used to speed up the decoding process; we omit
the details.
4.8.3 Diameters of Cayley graphs
We recall from Definition 2.13 that the Cayley graph Γx(G) of a group G
with respect to a set X of generators of G is a directed labelled graph with
vertex set V:={vg|g∈G} in one-one correspondence with the set of elements
of G and, for each g∈G and x∈X, a directed edge labelled x from vg to vgx
(which is regarded also as being an edge labelled x—1 from vgx to vg). The
group G acts transitively as a group of automorphisms of ΓX(G) by
multiplication on the left.
The diameter of a (connected) graph is defined to be the maximal distance
between two of its vertices, where all edges have length 1. So the diameter
of Γx(G) is equal to max{lx(g)|g∈G}, where lX(g) is the length of the shortest
word in (X∪X—1)* which represents g.
Finding the diameter of Cayley graphs of large finite groups, and the
related problem of finding lX(g) for given g∈G, are among the most basic
problems in CGT. Unfortunately, these problems represent a failure of CGT,
in that no methods have been found for solving them that are significantly
better than a brute-force depth first search through the vertices of ΓX(G)
starting at v1G. The results by Even and Goldreich in [EG81] and by Jerrum
in [Jer85] suggest that this is a fundamentally difficult problem. Some efforts
at finding bounds can be found in the paper of Driscoll and Furst [DF87].
For example, one might have hoped that the monumental effort that has
devoted to developing algorithms for permutation groups would have enabled
us, by now, to compute the diameter of the Cayley graph of the Rubik cube
group on its natural set of 6 generators. This is of course the same as the
maximum number of quarter twists required to restore the cube to its pristine
state starting from an arbitrary position, and is often referred to as the
number of moves in God’s algorithm. Unfortunately, this number is still
unknown; the best-known lower and upper bounds for it are 24 and 42, but
the answer is likely to be closer to 24 than to 42. The order of the group is
43 252 003 274 489 856 000≈4.32×1019.
As we saw in Section 4.4, in a permutation group we can easily express
elements g∈G as words in the strong generators, and hence in the original
generators via straight-line programs, which is adequate for many
computational applications. But this approach, when applied using the output
of the basic Schreier-Sims algorithm, typically results in very long words
for g in (X∪X-1)*, and so it is useless if we really want reasonable length
words for g in the original generators.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
148
The general problem of expressing elements in a permutation group as
moderately short, but not necessarily minimal-length words in the original
generators and their inverses is known as the factorization problem in
permutation groups. In [Min98], Minkwitz describes some heuristic methods
for finding reasonably short words in (X∪X—1)* for the strong generators in
a BSGS that has already been computed. These can then be used to produce
moderately short words for arbitrary group elements in (X∪X-1)*, and thereby
solve the factorization problem. Using this method, he was able to express
arbitrary elements of the Rubik cube group as words of length at most 144 in
its six natural generators. These ideas have been implemented in GAP by
Hulpke, who reports reducing this number to about 100. The use of genetic
algorithms has also been suggested as a novel means of attacking this
problem, and we await future developments in that direction with interest!
4.8.4 Processor interconnection networks
We turn now to a successful application involving diameters of Cayley
graphs and the factorization problem in permutation groups.
A network of processors for parallel computation can be regarded as an
undirected graph in which the vertices are the processors, and two vertices
are joined by an edge if there is a direct connection between the two processors
represented. Let us assume that each processor is connected to the same
number r of other processors; that is, that the graph is regular with valency
r. The physical design of a large network is made more feasible if r is small,
but computations are rendered more efficient if there are short paths
connecting any two vertices (that is, the diameter of the graph should be as
small as possible). Of course, these two requirements tend to conflict with
each other!
In [SS92], Schibbell and Stafford observed that the underlying undirected
graphs of Cayley graphs Γx(G) of certain types of finite groups, particularly
finite nonabelian simple groups, are very suitable for processor interconnection
networks in that they have a smaller diameter for a given valency than
other types of graphs that had been used for this purpose.
The principal problem to be solved in this application is calculating the
shortest path between two given vertices vg and vh for g, h∈G which, in the
notation of the preceding subsection, is equivalent to finding lx(gh-1). When
the network is in use for a large parallel computation, such shortest paths
need to be computed frequently, and it is vital that the calculation of these
paths should require minimal time and space resources, since otherwise
they would impair the performance of the main computation.
In contrast to problems like finding the number of moves required to
restore the Rubik cube, we are free to choose a convenient generating set for
G. In [SS92], the authors achieved excellent results in terms of minimizing
resources, by using a strong generating set in a low-degree permutation
representation of G, and using the algorithm STRIP to calculate the paths.
See also the more recent article by Heydemann [Hey97] for further references.
© 2005 by Chapman & Hall/CRC Press

149 
Chapter 5 
Coset Enumeration 
Most of the natural questions that one might ask about a group G that is 
defined by a finite presentation, such as “is G finite?” or even “is G trivial?” 
have been proved to be theoretically undecidable in general. In particular, 
the basic problem of deciding whether two words in the generators represent 
the same element of the group, which is known as the word problem, was 
proved to be undecidable by Novikov [Nov55], and then by Boone, with a 
simpler proof, in [Boo59]. See the survey article by Miller [Mil92] for a 
detailed discussion and survey of results of this type. 
However, many of these problems are semidecidable, in the following 
sense: although we cannot decide whether G is trivial or finite, if G does 
happen to be trivial or finite, then it is possible to verify (that is, to prove) 
that fact. 
Suppose that G is defined by a finite presentation, and H is a subgroup of 
G, which is specified by words in the generators of G that generate H. The 
procedure to be described in this chapter is known as coset enumeration 
and is one of the most fundamental methods in CGT. 
Its aim is to attempt to verify that |G:H| is finite. It will terminate 
only when |G:H| is finite, and so it cannot correctly be described as an 
algorithm. When the index is infinite, it will run forever in theory, but in 
practice it will usually run out of space. Of course it may also run out of 
space when |G:H| is finite but very large, or even when |G:H| is small, 
but the presentation is a difficult one. So, we learn nothing when this 
happens. However, if the procedure does terminate, then it will have 
verified that |G:H| is finite, and it will return the index, together with a 
complete coset table, which is equivalent to the permutation representation 
of the input group G in its action by right multiplication on the right 
cosets of H. 
The first coset enumeration procedure was described by Todd and Coxeter 
in [TC36], and, for this reason, it is often known as the Todd-Coxeter 
algorithm. At that time, it was intended for computation by hand. The first 
machine implementation, which was probably also the first implementation 
of any procedure in group theory, was by B.Hazelgrove in 1953. For details 
of this and other early implementations, see the article by Leech [Lee63]. 
For a much more detailed treatment of both the theoretical and practical 
aspects of coset enumeration, the reader could consult [Sim94]. For an 
elementary overview of coset table methods and their variations, which 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
150 
nevertheless contains outlines of proofs, the article by Neubüser [Neu82] 
is to be recommended. In this book, we shall take an intermediate approach, 
but we have made extensive use of some of the pseudocode from [Sim94] in 
our own pseudocode. 
Later in the chapter, we shall present some methods derived from coset 
enumeration, including computing presentations of subgroups of finite index 
in a finitely presented group, and finding all subgroups up to a specified 
finite index in a finitely presented group. 
5.1 The basic procedure 
Since even the simplest versions of coset enumeration seem rather 
complicated when we attempt to describe them precisely, we shall start 
with a simple example. The reader can then refer back to the example 
when reading the formal description. 
Example 5.1 
Let 
, and 
. It is hopefully clear 
immediately to the reader that G is a direct product of two cyclic groups of 
order 3, and that |G:H|=3. 
We start by letting the number 1 represent the trivial coset H of H in G. 
Since x∈H, we have Hx=H, and so we write 1x=1. We now define 1y=2 and 
. What this means is that we are using the integers 2 and 3 to 
represent the cosets Hy and Hy–1, respectively. We then have 
 and 
3y=1. 
We now perform a process known as scanning relators under cosets. 
Since relators w represent the identity element of G, we must have w= 
for any coset  and any relator w. This is already true for 
. When we 
scan 1 under y3, however, we find that 1y=2, but 2y is not yet defined, so the 
scan is incomplete. We can also start scanning from the end of the relator, 
and we find that 3y=1, but 
 is undefined. At this stage, the fact that 
, enables us to make the deduction 2y=3. This process is usually 
carried out using a table like the one below. The deduction is underlined. 
  
We also have 
. Scanning 1 and 2 under x–1y–1xy yields the 
deductions 3x=3 and 2x=2: 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
151 
The reader can verify that we now have w= for all =1, 2, 3 and all 
relators w∈R. It is also true that x is defined for =1, 2, 3 and all w∈Ω. It 
is often helpful to write down all of these values in a table known as a coset 
table. 
Since all cosets now scan correctly under all relators, and all entries in the 
coset table are defined, the procedure terminates, and the index of H in G 
is equal to the number of cosets defined, which is 3.
5.1.1 Coset tables and their properties 
Now we are ready to embark upon a more formal description of the 
procedure. The input consists of a finitely presented group 
, 
and a finitely generated subgroup 
. As in Section 2.4 of Chapter 2, 
we define 
. Here R is a set of defining relators for G, and is 
given as a set of words in A*. The set Y of generators of H is also a subset 
of A*. We shall assume that both R and Y consist of reduced words. 
Throughout the procedure, we maintain a coset table  for G. Formally, 
we define a coset table  for a group G with finite generating set X to be a 
quintuple (τ, , p, n, M), where M, n∈ with 1≤n≤M,  is a map from [1.. n] 
to A*, p is a map from [1.. n] to [1.. n] with p()≤ for all , and  is a partial 
map from [1.. n]×A to [1.. n]. However, we shall always write (α, x) as αx, 
and suppress all further reference to . For a given  ∈[1.. n] and x∈A, x 
may or may not be defined. Throughout the remainder of this chapter 
=(τ, , p, n, M) will be a coset table for a fixed group 
. 
The number M represents the largest number of cosets that we allow. 
This is determined in practice by the amount of computer memory available, 
and we shall assume that it is fixed throughout the procedure. The other 
components, τ, , p, and n may change as the coset enumeration is executed. 
The procedures that we shall write down for performing the enumeration 
will usually take  as an argument, and will often alter one or more of these 
components. 
We define the set Ω of live cosets to be {∈[1.. n]| p()=}. We need p, 
because it sometimes turns out during the course of the enumeration that 
the cosets represented by two numbers  and ß with <ß are equal; we 
record this occurrence by setting p[ß]:=, which has the effect of removing 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
152 
ß from the set of live cosets. We shall always have 1∈Ω. The number n 
represents the largest number that has been used so far for a live coset. 
The word τ() is a coset representative of the coset corresponding to ∈Ω. 
We initialize an enumeration by setting n:=1, p[1]:=1, and τ(1):=ε. The coset 
table is called complete if it has no undefined entries on the live cosets; 
that is, if x is defined for all α∈Ω and x∈A. 
In an implementation, the map  will typically be stored as a simple 
rectangular array, as in the example above, with rows indexed by  and 
columns by A, and undefined entries will be set to 0. But there are other 
possibilities. If a very small percentage of the entries are defined, then it 
might use less memory to use some kind of sparse-matrix storage method. 
The coset representatives τ() are not stored explicitly in the 
implementation, because they are not required for the mechanics of carrying 
out the computation, but they are important for the theoretical description. 
We shall now state a number of properties that  will satisfy throughout 
the procedure. Of course, we shall need to prove that these properties are 
maintained by all changes that we make during the course of the procedure. 
Property 1 1∈Ω and τ(1)=. 
Property 2.
Property 3 If x=ß, then Hτ()x=Hτ(ß). 
In other words, the action of A on Ω represents multiplication on the right 
when the elements of Ω are thought of as cosets of H in G. 
For ∈Ω and w=x1x2… xr∈A*, let 0:= and, for 1≤i≤r, let 
 if 
this is defined; otherwise i is undefined. Then, we say that w is defined and 
equal to r whenever the i are all defined for 0≤i≤r. 
Property 4 For all ∈Ω, 1() is defined and is equal to . 
5.1.2 Defining and scanning 
If some x is undefined, then the simplest way of remedying this is to 
adjoin a new element ß to Ω and make that x. This is accomplished by the 
following procedure. The final statement of the procedure, which defines 
τ(ß), is written as a comment, because it is not part of the implementation. 
The procedure starts by checking that we have space available for a new 
definition. If not, then it aborts. 
For ease of notation, in this and other procedures taking a coset table ~
as a modifiable input parameter, we write the components τ, , p, n, M of 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
153 
DEFINE (~ , α, x) 
Input: ∈Ω, x∈A, with x undefined. 
1 
if n=M then abort; 
2 
n:=n+1; ß:=n; p[ß]:=ß; 
3 
αx:=ß; 
; 
4 
(* Set τ(ß) equal to τ()x. *) 
simply as τ, , p, n, M, rather than as .τ, etc. 
It is clear that Properties 1 and 2 remain true after executing this 
procedure. There are only two new entries in the coset table, and we have 
defined τ(ß) to ensure Property 3 holds for these entries. As for Property 4, 
we are assuming that 1()=, so 1(ß)=x is defined and equal to ß. Incidentally, 
the fact that 1()= implies that the word τ() cannot end with x–1, because 
otherwise x would be defined already, contrary to assumption. This ensures 
that τ(ß) is a reduced word. 
Now we turn to the scanning process. There are two situations under 
which we might scan an element ∈Ω under a word w∈A*. The first is 
when =1 and w∈Y, and the second is when  is any element of Ω and w∈R. 
This is because w∈R implies that Hgw=Hg for any g∈G, whereas w∈Y only 
implies that Hw=H. 
To scan  under w, we first locate the largest prefix s of w for which s is 
defined. Of course, s might be empty. Let w=sv, let t be the longest suffix of 
v for which t–1 is defined, and let v=ut. If t=v, then we say that the scan 
completes, and if, in addition, 
, then we say that the scan completes 
correctly. (In fact, because of Property 2, it can only complete correctly 
when s=w, t=.) Before considering the unfortunate situation when the 
scan completes but not correctly, we consider another interesting situation, 
namely where the scan does not complete, but |u|=1; that is, the word u 
consists of a single generator x∈A. In that case, if s=ß and 
, then 
we can set ßx=γ and 
. These assignments are known as a deduction, 
and it is clear that deductions enable the scan to complete correctly. 
Formally, we have: 
PROPOSITION 5.1 Suppose that the assignments ßx= and 
 result 
from a deduction on scanning an element ∈Ω under w∈R, or on scanning 
1 under w∈Y. Then Properties 1, 2, 3, 4 remain true after making these 
deductions. 
PROOF These are all clear except for Property 3. Using the notation of 
the preceding paragraph, we need to prove that Hτ(ß)x=Hτ(γ). Since s=ß 
and τt= before making the deduction, Property 3 implies that Hτ()s=Hτ(ß) 
and Hτ(γ)t=Hτ(). Combining these gives Hτ(ß)x =Hτ(γ)tsx. If sxt∈R, then 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
154 
tsx=G 1, and we have Hτ(ß)x=Hτ(γ), as required. If =1 and w=sxt∈Y, then 
Hτ()=H, so 
  
and again we have Hτ(ß)x=Hτ(γ).
It is time for another example. 
Example 5.2 
Let 
 and 
. In practice, when there is a 
relator x2, we know that 
, and we can save time and space by 
omitting the column for x–1 in the coset table, since its entries can be 
assumed to be the same as those for x. We shall do that here. Define 1x=2. 
So 2x=1. Scanning 1 under the subgroup generator xy yields the deduction 
2y=1, 
. Define 1y=3, 
. Then scanning 1 under y3 yields the 
deduction 3y=2, 
. Define 3x=4, 4x=3. Scanning 2 under (xy)3 leads to 
the deduction 4y=4: 
  
We now find that the coset table is complete (see below), and elements 
of Ω scan correctly under all relators, so we have |G:H|=|Ω|=4. 
We can now prove the correctness of the basic procedure, assuming that 
all of the required properties hold. 
THEOREM 5.2 Assume that: 
  (i) Properties 1–4 all hold; 
 (ii) the coset table is complete; 
(iii) 1 scans correctly under all w∈Y; 
(iv) all ∈Ω scan correctly under all w∈R. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
155 
Then |G:H|=|Ω|. Furthermore, for each x∈A, the map ϕ(x): Ω→Ω defined 
by 
x is a permutation of Ω, and ϕ extends to a homomorphism from G 
to Sym(Ω) which is equivalent to the action of G on the cosets of H by right 
multiplication. 
PROOF Property 2 says that ϕ(x) and ϕ(
) are inverse maps for any 
x∈A, and so ϕ(x) is a permutation. Assumption (iv) says that for any 
w=x1…xr∈R, we have ϕ(x1)ϕ(x2)…ϕ(xr)= for all ∈Ω, so ϕ(x1)ϕ(x2)…ϕ(xr)=1Sym(). 
Now Theorem 2.52 implies that ϕ extends to a group homomorphism. 
To prove the equivalence of ϕ with the action of G on the set C of cosets 
of H, we define :Ω→C by ()=Hτ(). For any v∈A*, assumption (ii) and 
Property 3 imply that 
(1v)=Hv, so 
 is surjective. If 
(α)= (ß), then 
Hτ()=Hτ(ß), so τ()τ(ß)–1∈H, and hence τ()τ(ß)–1 is a product w1…wr 
elements wi∈YY-1. By assumption (iii), we have 1wi=1 for all wi and hence 
 and, using Property 4, α=1()=1(ß)=ß. So  is a bijection. It 
now follows that |G:H|=|Ω| and Property 3 implies that  defines an 
equivalence between ϕ and the action of G on C by right multiplication.
The code for the procedure for scanning ∈Ω under w∈A* is as follows. 
This is called only when either w∈R, or when =1 and w∈Y. 
SCAN(~ , , w) 
Input: ∈Ω, w∈A*. 
(* Scan forwards *) 
1 Let w=x1 x2
…xr, with xi∈A; 
2 f:=; i:=1; 
3 while i≤r and 
 is defined 
4 
do 
; i:=i+1; 
5 if i>r 
6 
then if f then COINCIDENCE (~ , f, ); 
7 
return ; 
(* Forward scan was incomplete. Scan backwards *) 
8 b:=; j:= r; 
9 while j≥i and 
 is defined 
10 
do 
; j:=j–1; 
11 if j<i 
12 
then COINCIDENCE (~ , f, b); 
13 elseif j=i 
14 
then (* Deduction *) 
; 
; 
15 (* Otherwise j > i—scan is incomplete and yields no information *). 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
156 
5.1.3 Coincidences 
The calls to the COINCIDENCE routine, which we have not yet explained, 
occur when a scan completes incorrectly. In the notation of the procedure 
SCAN, this occurs when, for some i with 1≤i≤r+1, we have w=st with 
s=x1x2…xi-1, t=xixi+1…xr, and ß:=s and 
 are defined but unequal. 
This means that ß and γ represent the same coset of H in G. The proof of 
this fact, which is stated in the following proposition, is similar to that of 
Proposition 5.1 and will be left to the reader. 
PROPOSITION 5.3 Suppose that either ∈Ω and w∈W, or =1 and w∈Y. 
Suppose also that w=st, where ß:=s and 
 are both defined. Then 
Hτ(ß)=Hτ(γ). 
We call the eventuality just described a coincidence between ß and γ. By 
Property 3, if ßx and γx are both defined for some x∈A, then Proposition 5.3 
says that Hτ(ß)=Hτ(γ), and then Property 3 implies that Hτ(ßx)=Hτ(γx). By 
induction on w , it follows that the same is true with x replaced by any 
w∈A*. 
Although w is not usually defined for all ∈Ω and w∈A*, we can still use 
Definition 2.26 and call an equivalence relation ~ on Ω a G-congruence if 
~ß implies w~ßw whenever w and ßw are both defined. We can then define 
the G-congruence generated by ⊆Ω×Ω as in Definition 2.27. 
In the coset enumeration procedure, as soon as a coincidence between 
two elements , ß∈Ω is found, we immediately compute ~, the right 
congruence generated by this coincidence. We shall see in the proof of 
Proposition 5.4 below that γ~ implies Hτ(γ)=Hτ(), so we only want to 
keep one representative of each ~-equivalence class in Ω. All other elements 
in the class are removed from Ω. It is also essential that we avoid losing 
information, and to do this, we need to transfer existing coset table entries 
between the deleted elements of Ω to the equivalent ~-class representatives. 
Let us first work through an example. 
Example 5.3 
Let 
 and H:=1 (so Y is empty). Define 1x=2, 2x=3, 
3y=4 and deduce 4y=1 by scanning 1 under x2y2. Then define 3x=5, 5y=6 and 
deduce 6y=2 by scanning 2 under x2y2, deduce 2y=3 by scanning 1 under 
x3y5, and deduce 5x=6 by scanning 3 under x2y2, Now, when we scan 2 under 
x3y5, we find that 
, but 
, so we have an incorrect completed 
scan with the coincidence 6~1. We therefore remove 6 from Ω. When we 
compare the elements 6z with 1z for z∈A, we find that 
 but 
, 
so we have another coincidence 5~4, and we remove 5 from Ω. After this 
there are no further coincidences, and we end up with the complete coset 
table below, with all a∈Ω scanning correctly under all w∈R. So |G|=4. 
Note that x=G y. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
157 
Now we are ready to write down the coincidence procedure. This is very 
similar to the procedure MINIMALBLOCK that we studied in Subsection 
4.3.3, but there are some important differences. There are some extra 
complications resulting from the facts that not all coset table entries ax are 
defined, and that we wish to transfer defined entries on the eliminated 
cosets to their equivalence class representatives. Another difference is that 
when merging two equivalence classes, virtually all implementations of 
coset enumeration to date have chosen to use the smaller of the two (integer) 
representatives as the representative of the merged class, rather than the 
theoretically more efficient choice of the representative from the larger of 
the two classes. The main reason for this is to avoid having to store the 
array c that was used in MINIMAL BLOCK for the size of the classes. In 
coset enumeration, space is much more critical than time and, in any case, 
the time difference resulting from the two possible methods appears not to 
be significant in practice. So we have have adopted that approach here. 
We assume that, before each call of COINCIDENCE, for ∈ [1.. n], we 
have p[]= if and only if ∈Ω. Proposition 5.4 will guarantee that this 
remains true after the call. 
REP( , ~p) 
Input: ∈Ω, array p 
1 
:= ; 	:=p[]; 
2 
while 	 do :=	; 	:=p[]; 
3 
µ:= ; 	:=p[µ]; 
4 
while 	 do p[µ]:=; µ:=	; 	:=p[µ]; 
5 
return ; 
MERGE( , , ~p, ~q, ~l) 
Input: , ∈Ω, ~p, q, l 
(* q is a queue of length l of elements to be deleted from Ω *) 
1 
ϕ:=REP( , ~p); ψ:=REP(, ~p); 
2 
if ϕψ 
3 
then µ:=min(ϕ,ψ); v:=max(ϕ,ψ); 
4 
p[v]:=µ; l:= l+1; q[l]:= v; 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
158 
COINCIDENCE(~ , , ß) 
Input: A coincident pair , ß∈Ω with Hτ()=Hτ(ß) 
1 l:=0; q:= ; MERGE(, ß, ~p, ~q, ~l); i:=1; 
2 while i≤l 
3 
do :=q[i]; i:=i+1; 
4 
Ω:=Ω\{γ}; 
5 
for x∈A do if γx is defined and equal to  
6 
then (* Remove the entry 
 from the coset table *) 
7 
Undefine 
; 
(* Queue new coincidences, and transfer definitions *) 
8 
µ:=REP(γ, ~p); v:=REP(, ~p); 
9 
if µx is defined then MERGE(v, µx, ~p, ~q, ~l); 
10 
elseif 
 is defined 
11 
then MERGE(µ, 
, ~p,~q,~l); 
12 
else µx:=v; 
; 
We now prove that this procedure does what we want it to do. 
PROPOSITION 5.4 After executing COINCIDENCE(~ , , ß), only the 
least representatives of the equivalences classes of the the G-congruence ~ 
generated by (, ß) remain in Ω and, for v∈ [1..n], p[v]=v if and only if v∈Ω. 
Furthermore, if for some x∈A we have x= before executing the procedure, 
then REP(γ)x=REP() afterwards. Finally, Property 1 to Property 4 all 
continue to hold after execution of the procedure. 
PROOF We are assuming that, before the call, for v∈ [1. .n], we have 
p[v]=v if and only if v∈. The value of p[v] is changed only in REP and 
MERGE, and it is only changed in REP when p[v]v. If it is changed in 
MERGE then it is set equal to a value µ<v. It follows by a straightforward 
induction argument that any changes to p[v] in REP decrease its value 
further. Note also that any element v returned by REP satisfies p[v]=v, and 
the v for which p[v] is changed in MERGE has just been returned by REP. 
It follows that, for each v∈Ω, the initial value v of p[v] is changed at most 
once in MERGE, and at that stage it is added to the queue q. Since the 
entries in q are processed and removed from Ω during the main loop of the 
procedure, the procedure must halt, and we have proved the assertion 
that, at the end of the procedure, p[v]=v if and only if v∈Ω. 
As in the proof of Theorem 4.3, we shall denote the equivalence relation 
on  defined by p throughout the procedure by ~, and the final value of ~ at 
the end of the procedure by ~F. The G-congruence generated by (, ß) will 
be denoted by ≡. 
We next show that ~ always implies ≡ and Hτ( )=Hτ(). Note that ~ 
is only changed during calls of MERGE, when two ~-classes are merged. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
159 
The first call of MERGE at line 1 merely makes ~ß, and we are assuming 
that Hτ()=Hτ(ß). Before the other two calls, MERGE(v, µx) on line 9 and 
MERGE(µ, 
) on line 11, we have µ=REP(γ) and v=REP(), where 
γx=, so we can assume inductively that µ~γ, v~, Hτ(µ)= Hτ(γ) and 
Hτ(v)=Hτ(). Hence µx~v, 
 and, by Property 3, Hτ(µx)=Hτ(v), 
and 
 Thus, on any call of MERGE( , ) during the 
COINCIDENCE procedure, we have ≡ and Hτ( )=Hτ(), and so the claim 
that ~ implies ≡, and Hτ( )=Hτ() remains true after the call. Hence it 
is always true. 
Properties 1 and 4 are clearly unaffected by calls of COINCIDENCE. 
The only entries that are removed from the coset table are those of the 
form 
 at line 7, where γ has been removed from Ω at line 4, and 
the only entries to be added are µx:=v; 
; together, at line 12, in 
situations where both were previously undefined. So Property 2 
continues to hold. As we saw in the preceding paragraph, whenever we 
add these entries, we have µx~v and Hτ(µx)=Hτ(v), so Property 3 continues 
to hold. 
At any stage, let us call two coset table entries x=ß and 
equivalent, if 
 and 
 Suppose we have an entry x=ß in the coset 
table before the call of COINCIDENCE. We claim that at all times during 
the procedure, there is an equivalent entry in the coset table. After removing 
an element γ from Ω at line 4, any entries γx= (implicitly, since γ is no 
longer in Ω) and 
 (at line 7) are removed from the coset table. We 
can assume that the claim is true immediately before these entries are 
removed, and we must show that it remains true afterwards. 
On removal of the entries, we set µ:=REP(γ) and v:=REP(), and one of 
three things can happen. If µx is defined and equal to , say, then we call 
MERGE(v, ), making v~. But then the coset table entries γx= and µx= 
become equivalent, as do 
 and 
. The situation is similar 
if 
 is defined. Finally, if neither µx nor 
 is defined, then we add the 
entries µx=v and 
, and these are equivalent to γx= and 
. 
Thus the claim is true. 
At the end of the procedure, the only elements of Ω remaining are those 
with REP(v)=p[v]=v. So, for an initial coset table entry x=ß, the only possible 
equivalent entry at the end is REP()x=REP(ß). 
Finally, we prove that ≡ implies ~F  for all , ∈Ω. Since we have 
already proved the converse, by definition of the G-congruence ≡, it suffices 
to prove that ~F is a G-congruence. So, suppose that ~F  and that 
w and 
w are both defined for some w∈A*. We have to prove that 
w~F w and, by 
induction, it suffices to do this for w=x∈A. (Since G is not necessarily finite, 
we cannot restrict to x∈X, as we could in MINIMALBLOCK!) As we have 
just seen, at the end of the procedure, there are coset table entries that 
are equivalent to the entries for 
x and x. Since these entries have the 
same source REP( )=REP(), they must be the same entry γx=, say, but 
then 
x~F ~F x, which proves the claim. This completes the proof. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
160 
Example 5.4 
This is the example F(2, 5), one of the Fibonacci groups, which have provided 
a much-studied source of examples in combinatorial group theory. See, for 
example, [Joh98]. Let 
and 
. In the computation, we of course rewrite the defining relations 
as relators abc-1, etc. We have 1a=1. Define 1b=2, and deduce 1c=2 by scanning 
1 under abc-1. Then define 2c=3 and deduce 1d=3 from scanning 1 under 
bcd-1, 3e=1 from scanning 1 under dea-1, 3b=1 from scanning 3 under eab-1, 
3d=2 from scanning 3 under bcd-1, 2e=2 from scanning 2 under cde-1, 3a=2 
from scanning 3 under dea-1, 1e=3 from scanning 1 under eab-1. 
Now, when we scan 1 under cde-1, we find that 1c=2, but 
, so we 
have an incorrect completed scan with the coincidence 2~1. Since 2e=2 but 
1e=3, we also get the coincidence 3~2, and then the table is complete with 
1a=1b=1c=1d=1e=1. So we have a complete collapse, and we have shown that 
. This tells us that G is abelian and, using that information, it is not 
hard to use the relations to show directly that G has order 11, and that 
b=a4, c=a5, d=a9, e=a3. 
In the examples that we have worked through so far, we have not explained 
what strategy we have adopted to decide which definitions to make. When 
doing examples by hand, the overriding objective is to avoid having to 
process coincidences, and in fact we have carefully chosen our definitions 
so as to minimize the amount of coincidence checking that needs to be 
done. A variety of strategies can be adopted for this purpose, including trial 
and error. 
When implementing coset enumeration on a computer, we of course 
need to specify precisely a policy for choice of definitions, which means 
that we cannot be quite so flexible as with a hand enumeration. Avoiding 
coincidence processing is still important, since it can reduce overall space 
requirements, but it is not quite so critical as with hand enumeration. We 
shall discuss the policies that have been most commonly used in more 
detail in the next section. 
To complete our theoretical analysis of coset enumeration, we still need 
to prove that, if |G:H| is finite, then the procedure will eventually halt. In 
fact, whether this is true depends on the strategy used for definitions. In 
[War74], J.N.Ward presents a simple example in which |G:H| is finite, but 
in which certain apparently reasonable strategies for choosing definitions 
result in the enumeration never completing. The property that is required 
from our definition strategy is that all images x eventually get defined. 
We also require that 1 is scanned under all subgroup generators, and all  
are scanned under all relators. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
161 
Property 5 Let  be the set of elements of Ω that are not eliminated in any 
call of COINCIDENCE. Then 
(i) 
For each ∈ and each x∈A, x will at some stage be defined; 
(ii) For each w∈Y, SCAN(~ , 1, w) is called at some stage; 
(iii) For each ∈ and each w∈R, SCAN(~ , , w) is called at some 
stage. 
The ingenious idea of using an infinite coset table in the proof of the 
proposition below is taken from Theorem 2 of [Neu82]. There are other 
ways of proving this, which do not involve infinite coset tables, but they 
involve more technicalities. 
THEOREM 5.5 Assume that Property 1 to Property 5 hold throughout a 
coset enumeration of G with respect to the subgroup H, and that |G:H| is 
finite. Then the coset enumeration procedure will eventually terminate. 
PROOF Let  be as in Property 5. Let ∈ and x∈A. By Property 5, x is 
defined at some stage; say x=ß. Since  is not eliminated in any call of 
COINCIDENCE, by Proposition 5.4, we must have p[]= at all times during 
any such call, and also x=p[ß]≤ß at the end of the call. Since x can only 
decrease, it must eventually become stable. Thus  must be infinite, because 
otherwise the coset table would complete with = . 
We can now define an infinite complete coset table, in which the rows 
are indexed by the elements ∈, and the entries x are their stable 
values. Property 5 ensures that the hypotheses of Theorem 5.2 applies to 
this infinite complete coset table, and we can conclude from Theorem 5.2 
that the action of G by right multiplication on the right cosets of H has 
infinite degree. But this contradicts the assumption that |G:H| is 
finite.
Exercises 
1. 
Use coset enumeration to show that the subgroup 
 has index 5 in the free group G on 
{x,y}. 
2. 
Show by coset enumeration with the trivial subgroup that the group 
 has order 8. (It is possible to do this without any 
coincidences occurring.) Show also that G≅Q8. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
162 
5.2 Strategies for coset enumeration 
As was mentioned earlier, the main problem to be resolved when 
implementing the coset enumeration procedure is to specify a strategy for 
making definitions. There are two principal strategies that have been 
employed in the past, and the most recent implementations, such as the 
ACE3 [HR99] package by Havas and Ramsey, allow the user to select a 
combination of these two methods in any desired proportion, together with 
a selection of modifications that have been observed to perform well on 
some examples. 
It is rare for an enumeration to take a very long time without using a 
correspondingly large amount of space, so we regard the space used, and 
specifically the maximum value of |Ω| during the course of the enumeration 
as the principal measure of how well that enumeration is performing. (The 
total number of cosets defined during the enumeration could also be used, 
and would provide an indication of the time requirements as well as the 
space requirements.) Roughly speaking, we regard a particular enumeration 
as performing well if the maximum size of |Ω| is not more than perhaps 
25% larger than |G:H|. 
Fortunately, for many of the examples for which coset enumeration has 
been used in earnest, at least one and often both of the two principal 
strategies performs satisfactorily. But one problem to which coset 
enumeration is often applied is trying to find presentations of a given group 
with the smallest possible number of defining relators, and for an application 
like that, where we are in some sense deliberately trying to make the 
problem as hard as possible, it can be crucial to find the appropriate strategy. 
It seems to be a feature of coset enumeration that, for any single strategy, 
there are examples that will perform badly using that strategy, but will 
perform relatively well using some other strategy. It is also not hard to 
construct presentations, even of the trivial group, in which the maximum 
value of |Ω| is arbitrarily large; this is an inevitable consequence of the 
fact that deciding whether |G:H| is finite is an unsolvable problem in 
general. 
We shall begin by describing the two principal strategies in detail, and 
then discuss some other ideas and modifications that have been used. 
5.2.1 The relator-based method 
This is probably the easier of the two methods to describe and implement, 
and it has often been called the HLT method, after Hazelgrove, Leech 
[Lee63] and Trotter [Tro64], who have all contributed to its development. 
There is a detailed description of an implementation in [CDHW73]. 
The idea is that whenever we call SCAN and the scan is incomplete, 
then we make new definitions to enable the scan to complete; that is, we 
fill in the gaps in the scan of the relator or subgroup generator. This is why 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
163 
we call it the relator-based method. To carry this out, we first need to write 
a modified version of SCAN, which makes the required definitions. Note 
that the ‘While’ loop on line 3 of this procedure is exited as soon as the scan 
completes, when a return statement is executed. 
SCANANDFILL(~ , , w) 
Input: ∈Ω, w∈A*, with ax undefined. 
1 Let w=x1x2…, with xi∈A; 
2 f:=; i:=1; b:=; j:=r; 
3 while true 
4 
do (* Scan forwards *) 
5 
while i≤r and 
 is defined 
6 
do 
; i:=i+1; 
7 
if i>r 
8 
then if f then COINCIDENCE(~ , f, ); 
9 
return; 
(* Forward scan was incomplete. Scan backwards *) 
10 
while j≥i and 
 is defined 
11 
do 
; j:=j-1; 
12 
if j<i 
13 
then COINCIDENCE(~ , f, b); 
14 
elseif j=i 
15 
then (* Deduction *) 
; 
; 
16 
return; 
(* Otherwise j>i and the scan is incomplete. 
Make a new definition and continue with scan. *) 
17 
else DEFINE(~ , f, xi); 
In an implementation, whenever we make a call to DEFINE, as we did 
here, we would need to check whether DEFINE aborted due to lack of 
space and, if so, take some appropriate action. For example, we might give 
up, or we might attempt to reuse any space available from cosets that have 
been eliminated by calls of COINCIDENCE. We shall discuss these 
possibilities later. 
It is now easy for us to write down a function for relator-based coset 
enumeration, which returns the coset table completed. The array p used by 
COINCIDENCE is global to this procedure. Of course, this function can only 
complete if |G:H| is finite. In this and subsequent functions in this subsection, 
we have described a loop over all elements of Ω by using the statement 
  
However, recalling that n is the largest element of Ω that has been defined 
so far, and elements ∈Ω are recognized by the fact that p[]=, this should 
really be coded as 
  
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
164 
COSETENUMERATIONR (
, Y) 
Input: A finite group presentation 
 and a finite subset Y of A* 
1 Initialize a coset table  for 
; 
2 p[1]:=1; n:=1; 
3 for w∈Y do SCANANDFILL(~ , 1, w); 
4 for ∈Ω 
5 
do for w∈R 
6 
do SCANANDFILL(~ , , w); 
(* If  was eliminated during the scan then break *) 
7 
if p[]< then break; 
8 
if p[]< then continue; 
9 
for x∈A 
10 
do if x is undefined then DEFINE(~ , , x); 
11 return ; 
It is clear that the conditions of Property 5 hold for this function, and so 
the results of the last section ensure that it will perform as required. Note 
that the lines 9,10 ensure that Property 5(i) holds. This line has not always 
been included in past implementations, with the consequence that the 
enumeration would not terminate even when |G:H| was finite on certain 
examples, such as those described by Ward in [War74]; see Exercise 3 below. 
The above function is not always optimal in terms of the maximal value 
of |Ω| attained, but it tends to perform satisfactorily in most straightforward 
examples and, provided there is enough memory available, it often completes 
faster than other methods that are more careful about minimizing memory 
usage. In some examples in which it does run out of memory, a modification 
known as HLT+Lookahead, which is described in [CDHW73], enables it to 
complete. The idea is that whenever a call of DEFINE aborts due to lack of 
space available for further definitions, the current value of α is remembered, 
and the procedure below is executed. 
LOOKAHEAD(~ , R) 
1 
for ß∈Ω, w∈R 
2 
do SCAN(~ , ß, w); 
3 
if p[ß]<ß then continue ß; 
This performs a complete scan of all cosets under all relators, but without 
making new definitions. The idea is that space may be recovered as a 
result of cosets being eliminated from Ω in calls of COINCIDENCE. If any 
space is recovered, then we will need to renumber cosets so as to make the 
set Ω of active cosets equal to [1.. n] with n<M. We shall describe this 
renumbering process in more detail in Subsection 5.2.3, below. The main 
function can then be resumed, starting again from the remembered value 
of α. (But of course the implementation will need to be able to deal with the 
case in which this α has been eliminated during LOOKAHEAD!) 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
165 
5.2.2 The coset table-based method 
This has often been called the Felsch method, and was first described in 
[Fel61]. The policy here is to define x where x is the first undefined entry 
in the coset table. By this, we mean we choose the first ∈Ω for which x is 
undefined for some x∈A, and then choose the first x∈A, with respect to 
some fixed ordering of A, for which x is undefined. Notice that this means 
that we are defining elements 1w for w∈A* in order of increasing w in the 
shortlex ordering (Definition 2.60) of A* with respect to the ordering of A 
that we are using. In practice, we number the elements of A before starting 
the enumeration, and this provides our ordering of A. Occasionally examples 
are encountered in which this ordering drastically affects the performance 
of the enumeration, so the implementation should allow the user the 
possibility of setting this ordering. 
The usual practice with the Felsch strategy is to start by calling 
SCANANDFILL(~ , 1, w) for all w∈Y, just as we did in HLT. After doing 
that, the policy is to derive all possible consequences of each definition 
before making any further definitions. The easiest way to do that is simply 
to call the procedure LOOKAHEAD after each definition, but in practice 
that would be very inefficient. A better method is to store all pairs (, x) 
for which a value is assigned to x during a definition or deduction on a 
deduction stack and then, when processing the entries in the stack, we 
only call SCAN(~ , , w) on those  and w for which new information 
could conceivably be deduced from the definition or deduction currently 
being processed. To accomplish this, the code of the procedures DEFINE, 
SCAN, and COINCIDENCE are first modified such that each time the 
value of x is defined or altered for any α and x, the pair (, x) is pushed onto 
this deduction stack. However, since such alterations are always made in 
inverse pairs x:=ß and 
, we only need save the first alteration of 
such a pair. 
Consequences of a particular new assignment x:=ß can only occur for a 
call of SCAN(~ , , w) for which w∈R and w=uxv with either u= or 
. The new information x=ß can then be used to extend this scan, 
which might then result in a new deduction or coincidence. We can obtain 
the same new information by calling SCAN(~ , , xvu) and SCAN(~ , ß, x- 
1u-1v-1) rather than SCAN(~ , , w). 
To implement this idea, it is convenient to start by computing the set Rc 
of all cyclic conjugates of all elements of RR-1, and then, for each x∈A, to 
compute the set Rx
c of all elements of Rc having x as their first symbol. (And 
before doing that, we should replace the elements of R by cyclically reduced 
conjugates if necessary.) We can then look for consequences of the new 
assignment x:=ß by calling SCAN(~ , , w) for all 
 and SCAN(~ , 
ß, w) for all 
. 
In implementations, a fixed amount of space is generally reserved for 
the deduction stack. If this space is exceeded, then rather than processing 
individual deductions as just described, we call LOOKAHEAD, which means 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
166 
that all consequences of all deductions are automatically found. This has 
been found not to be unduly time-consuming, because usually the deduction 
stack does not grow very large and, when it does, it means that there is a 
large number of deductions to process, so we might as well call 
LOOKAHEAD. 
We can now write down the code for coset table-based coset enumeration, 
but we write the code for processing deductions as a separate procedure. 
PROCESSDEDUCTIONS(~ , {
}) 
1 while deduction stack is not empty 
2 
do if deduction stack is full 
3 
then LOOKAHEAD(~ , R); 
4 
Empty deduction stack; 
5 
else 
6 
Pop next pair (, x) from deduction stack; 
7 
if p[]= then for w∈
8 
do SCAN(~ , , w); 
9 
if p[]< then break; 
10 
ß:=x; 
11 
if p[ß]=ß then for w∈
12 
do SCAN(~ , ß, w); 
13 
if p[ß]<ß then break; 
COSETENUMERATIONC(
, Y) 
Input: A finite group presentation 
 and a finite subset Y of A* 
1 Replace all elements of R by their cyclic reductions; 
2 Compute the set Rc of all cyclic conjugates of all elements of RR-1; 
3 for x∈A, 
4 
do compute set 
 of elements of Rc having first letter x; 
5 Initialize a coset table C for ; 
6 p[1]:=1; n:=1; 
7 for w∈Y do SCANANDFILL(~ , 1, w); 
8 PROCESSDEDUCTIONS(~ , {
}); 
(* Make definitions using first undefined element of coset table *) 
9 for ∈Ω, x∈A do if x is undefined 
10 
then DEFINE(~ , , x); PROCESSDEDUCTIONS(~ , {
}); 
11 return ; 
To prove that this procedure works as claimed, we need to verify that the 
conditions of Property 5 are satisfied. The first two conditions of this property 
are clearly satisfied. For the third condition, let ∈Ω, w∈R, and suppose 
that w begins with x. Then x will certainly get defined at some stage, and 
then (, x) (or its inverse assignment) will be put on the deduction stack. 
Then, provided that  remains within Ω, SCAN(~ , , w) will be called 
from the next call of PROCESSDEDUCTIONS. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
167 
5.2.3 Compression and standardization 
The procedure DEFINE always uses n+1 as the next coset number, where 
n is the largest number that has been used to date. Since cosets get 
eliminated during calls of COINCIDENCE, this means that Ω will not always 
equal [1.. |Ω|]. Normally, at the end of an enumeration, and also possibly 
during the enumeration if we run out of space to define new cosets (see 
Subsection 5.2.5 below), we will want to redefine the coset table to make 
Ω=[1..n], where n=|Ω|. The following procedure does exactly that. 
COMPRESS(~ ) 
1 γ:=0; 
2 for ∈ [1.. n] do if p[]= 
3 
then γ:=γ+1; 
4 
if γ 
5 
then (* Replace  by γ in coset table *) 
6 
for x∈A 
7 
do ß:=x; 
8 
if ß= then ß:=γ; 
9 
γx:=ß; 
; 
10 n:=γ; 
11 For ∈ [1.. n] do p[]:=; 
In some situations, it is desirable at the end of an enumeration to permute 
the cosets so that they occur in some sort of standard order. This could be 
used, for example, to test for the equivalence of the permutation actions of 
G defined by two coset tables. It is also convenient, in terms of simplifying 
code, to standardize the coset table before using it as input to the subgroup 
presentation algorithm that will be described in Subsection 5.3.1 below. 
The code below reorders the elements of Ω such that, if we scan the 
coset table first by elements of Ω and then by elements of A, then the 
cosets occur in ascending numerical order. This is the order in which they 
would occur with a coset-based enumeration that completed with no 
coincidences. We shall call the resulting coset table standardized. We 
assume that COMPRESS has been called before STANDARDIZE; that is, 
that Ω=[1..n]. 
SWITCH(~ , ß, γ) 
(* Switch the elements ß, γ of Ω in  *) 
1 
for x∈X 
2 
do z:=γx; γx:=ßx; ßx:=z; 
3 
for a∈Ω 
4 
do if x=ß then x:=γ; 
5 
elseif x=γ then x:=ß 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
168 
STANDARDIZE(~ ) 
Input: A complete coset table ~  on Ω=[1..n] 
1 
γ:=2; 
(* γ is the next entry that we want to encounter in the coset table *) 
2 
for a∈ [1. .n], x∈A 
3 
do ß:=xγ 
4 
if ß≥γ 
5 
then if ß>γ then SWITCH(~ , γ, ß)γ 
6 
γ:=γ+1; 
7 
if γ=n then return; 
As an example, consider the following coset table that was computed in 
Example 5.3: 
When we work through the above procedure, we start with =1, γ=2 
and find x=2=γ, which is correct for a standardized table. So γ is increased 
to 3. We then look at 
, which is not what we want in a standardized 
table. We want the next new entry to be γ=3, so we call SWITCH(3, 4). This 
interchanges 3 and 4 in the coset table, and the modified table is: 
The table is now in fact standardized. This is because the entries 1,2, ... 
n-1 appear in the correct order in the table, and so n must also occur in the 
correct place. Thus, in the procedure, we can interrupt the loop and return 
on observing that the incremented value of γ is n. 
5.2.4 Recent developments and examples 
Although both COSETENUMERATIONR and COSETENUMERATIONC will 
work adequately on most straightforward examples in which |G:H| is 
relatively small compared with the maximum number M of possible cosets, 
there are examples in which one performs significantly better than the other. 
In its present form, and for large indices |G:H|, COSETENUMERATIONR 
tends to be less good when memory is in short supply, even when used in 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
169 
conjunction with LOOKAHEAD. A possibility proposed by Sims in [Sim94] 
is to use the deduction stack and PROCESSDEDUCTIONS in combination 
with COSETENUMERATIONR. 
COSETENUMERATIONC in its pure form can struggle when the 
presentation has very long relators, because there is a danger that 
consequences of such long relators are not derived for a very long time. 
One simple method that has been found to improve the performance of 
COSETENUMERATIONC significantly is the rather strange-sounding 
technique of including the group relators among the subgroup generators; 
that is, by replacing the original Y by YR. This has the effect of ensuring 
that at least SCAN(~ , 1, w) is called immediately for all w∈R. 
We shall now describe the performance of these procedures on a selection 
of examples. We take H to be the trivial subgroup in each case. 
First a straightforward enumeration: M12, of order 95040, has a 
presentation 
  
This completes within a second on a PC using any strategy. It is very 
slightly faster using the relator-based method (HLT+LookAhead), but defines 
a maximum of 125293 and a total of 315238 cosets. With the coset table- 
based method (Felsch), it uses a maximum of 95040, which is optimal, and 
a total of 97060 cosets. 
The remaining examples have been selected for their difficulty. 
Fortunately, in many applications, the straightforward behaviour exhibited 
by the above example M12 is more typical. 
The following deficiency-zero presentations of G=SL(2, p) for p prime 
are defined by Campbell and Robertson in [CR80]: 
  
where k is the integral part of p/3. These are very difficult examples relative 
to the order of the group. The long relator has the effect that they perform 
better with HLT+LookAhead. For example, with p=13, |G|=2184, the Felsch 
method defined over 3 million cosets and took about 5 times longer than 
HLT+LookAhead, which completed using a maximum of 2 million cosets. 
For p=17, |G|=4896, HLT+LookAhead completed with a maximum of 10 
million cosets, whereas Felsch needed more than 40 million. 
The group 
  
is the first of the 14 groups defined in [HNO95]. It has order 6561. It needs 
just over 14000 cosets to complete with Felsch, and more than 86000 to 
complete with HLT+Lookahead, but this decreases to about 40000 if cyclic 
conjugates of relators are included. 
The eighth of these examples, also of order 6561, is 
  
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
170 
This is much harder. It needed 30 million cosets with the Felsch method, 
and failed to complete with 100 million cosets using HLT+Lookahead. 
The most versatile and carefully implemented coset enumeration package 
at the present time is almost certainly ACE3 [HR99] by Havas and Ramsay, 
and includes virtually all possible variations that have ever been suggested 
as user options. There are interfaces to this implementation from both 
GAP and MAGMA. The default mode of running is to alternate between 
the definition strategies of COSETENUMERATIONR and COSETEN- 
UMERATIONC, in the sense that m cosets are defined using the relator- 
based method and then n cosets are defined using the coset table-based 
method, and so on. The values of m and n can either be set directly by the 
user, or are determined by other parameters. Whether or not 
PROCESSDEDUCTIONS is used is optional and, if it is, then the size of 
the deduction stack can be set. By default YR is used in place of Y, as 
suggested above. Another option, which tends to make enumerations much 
slower, but can enable a very difficult enumeration to complete, is to replace 
R by the set Rc of all cyclic conjugates of all relators. The user should 
consult the ACE3 manual for more details or, alternatively, consult the 
section on advanced features of finitely presented groups in the MAGMA 
manual ([BC93] or [Mag04]). 
Finally, we mention the interactive coset enumeration package ITC 
written by V.Felsch, L.Hippe, and J.Neubüser, which is available as a GAP 
package [GAP04]. This allows the user to intervene with specific definitions 
during the course of an enumeration, and also to rerun an enumeration 
retroactively in an attempt to find shorter routes to completion. 
5.2.5 Implementation issues 
Most implementations of coset enumeration to date have started with a 
fixed amount of memory, which the user may specify at runtime, but they 
have not attempted to allocate extra memory in mid-enumeration. This 
means that there will a maximum size M of Ω. 
The coset table is generally stored as a two-dimensional array with rows 
in the range [1..n] representing elements of Ω, and columns representing 
the elements of A in some order that the user might be allowed to specify. 
Then x is equal to the element in row α and column x of the array, where 
a 0 entry means that x is undefined. 
As we have already explained, if DEFINE aborts and some cosets have 
been eliminated by calls of COINCIDENCE, then the procedure COMPRESS 
defined in Subsection 5.2.3 can be used to reclaim lost space. If we are 
using a strategy that involves calling LOOKAHEAD, then we may wish to 
call LOOKAHEAD before calling COMPRESS. 
If we still have M=n after calling COMPRESS, then we have to give up. 
Otherwise, we can resume the enumeration and make a new definition. In 
an implementation, there are some other housekeeping details to be 
handled. For example, when we resume an enumeration after a call of 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
171 
COMPRESS, the value of the main loop variable a in COSETENUME- 
RATIONR or COSETENUMERATIONC needs to be replaced by its new 
value; so this new value needs to be returned by COMPRESS. One way of 
handling this is to introduce an extra component to the coset table itself, 
which would represent the current coset being processed. 
It is also possible to use linked lists to keep track of the integers 
representing live cosets; integers representing cosets to be eliminated can 
easily be unlinked, and the corresponding row in the coset table adjoined 
to another linked list of available coset numbers. This approach is used in 
the implementation described in [CDHW73]. 
The versions of coset enumeration that we have described involve two 
arrays p and 
 that are used in COINCIDENCE, and both of these must 
have space for M integers. We may also need some space, say L, for the 
deduction stack. The total amount of space required for the enumeration 
then amounts to (2+|A|)M+L integers, plus a small amount of space for 
other variables. The implementation described in [CDHW73] uses the same 
space for the arrays p and 
 and for the pointers needed for the linked lists 
described above. 
Since it is important to use space as economically as possible, the more 
recent implementations, such as [HR99] have made use of an idea originally 
outlined by Beetham in [Bee84], which enables the information stored in p 
and 
 to be stored in the first two columns of the coset table. Since rows of 
the table are being continually made free during calls of COINCIDENCE, 
it is reasonable to hope that something of this kind might be possible. It is, 
however, not straightforward to achieve this in practice, because the 
coincidence queue can grow much faster than the rate at which rows of the 
coset table are made free. 
To overcome this difficulty, it is necessary to handle the first two columns 
separately and in a different manner from the other columns when processing 
coincidences. We shall not give any further details here, but refer the reader 
to the Appendix of [Sim94] where the detailed pseudocode for this process 
is included. This means that the total space required for the enumeration 
is reduced to about 2|A|M+L signed integers. (The integers need to be 
signed because, with this approach, eliminated cosets are recognized by the 
fact that their entry in the first column of the coset table is negative.) 
5.2.6 The use of coset enumeration in practice 
After a successful call of COSETENUMERATIONR or COSETENU- 
MERATIONC on a subgroup H of a group G, we can immediately define the 
associated permutation representation of G on Ω, which Theorem 5.2 tells 
us is equivalent to the action of G by multiplication on the right cosets of 
H, as defined in Example 2.3. To do this, it is sensible first to call COMPRESS 
in order to make Ω equal to [1..n], where n=|G:H|. The permutation action 
is then the homomorphism ϕ:G→Sym(Ω) where, for each x∈X, ϕ(x) is the 
permutation defined already by our notation; that is, by 
, for ∈Ω. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
172 
We can therefore perform computations in the permutation group im(ϕ). 
This group is isomorphic to G/ker(ϕ)=G/HG, where HG is the core of H in 
G; see Example 2.4. 
If HG={1}, then we have a permutation group isomorphic to G, and so we 
can easily compute the order of G and its group-theoretical properties. We 
can achieve this by putting H={1}, but is more efficient if we can find a 
larger subgroup with HG={1}. One painless way of attempting this is to try 
 for some v∈A*. This is particularly promising if one of the defining 
relators of G is vm for some m>0. In that case, if ϕ(v) has order exactly m, 
then ϕ|H is clearly an isomorphism and, since ker(ϕ)H, this implies that 
ker(ϕ)={1}. For example, in Example 5.2, we had 
with 
 and we computed the coset table: 
In the associated permutation representation ϕ:G→Sym(), we have 
ϕ(x)=(1,2)(3,4) and ϕ(y)=(1,3,2). Hence ϕ(xy)=(2,3,4) has order 3. Since G 
has a relator (xy)3, we can conclude that xy has order exactly 3 in G and 
hence that |H|=3, and so |G|=12 and ϕ is faithful representation. 
This will not always work, even when there are promising-looking group 
relators. For example, the group 
 has order 16, 
but trying 
, 
 and 
 yields permutation group images of orders 
8, 4, and 8, respectively. And if there are no defining relators that are 
proper powers, then the approach cannot work. There is, however, a slightly 
more sophisticated possibility, which is to choose 
 for some x∈A, 
and also compute a presentation of the subgroup H. Computation of 
presentations of subgroups will be discussed in the next section. Experience 
has shown that, if our aim is to find the order of G, then this technique is 
usually more efficient than choosing H={1}. 
Exercises 
1. 
Let 
. Use coset enumeration to show that 
|G:H|=6, where 
 and use this to prove, using the techniques 
of Subsection 5.2.6, that G≅Sym(4). 
2. 
Let 
 and let 
. 
(i) 
Show by coset enumeration that H has index 5 in G, and that the 
image of the corresponding coset action is Alt(5). 
(ii) Show, by using the group relators, that the elements a:=x and b:= 
yx-1y2 of G satisfy the relations a3=b3=(ab)2=1. 
(iii) Deduce that |H|≤12 and hence that |G|=60 and G≅Alt(5). 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
173 
3. 
This example is from [War74]. Let 
. 
Show without using coset enumeration that |G|=3. 
Suppose that we carry out COSETENUMERATIONR on this group with 
subgroup H=1, but with lines 9 and 10 removed, so that Property 5(i) is 
no longer guaranteed to hold. Show that every application of 
SCANANDFILL on each coset α will define a new coset representing 
 or 
, and hence the procedure will never terminate. 
4. 
We could avoid the problem with the last example by replacing all 
group relators by cyclically reduced conjugates before we start. Find 
an example to show that, even with this modification, the procedure 
cannot be guaranteed to terminate on a finite group if we remove lines 
9 and 10. 
5.3 Presentations of subgroups 
In this section, we shall present two algorithms for computing presentations 
of subgroups H of finite index in a group G defined by a finite presentation. 
The first of these, known generally as the Reidemeister-Schreier algorithm, 
computes a presentation on a set of Schreier generators of H, and the 
second one computes a presentation on the given set Y of generators. The 
reader might wish to review Section 2.5 before reading on. 
Both algorithms are inclined to compute large and unwieldy presentations, 
particularly when |G:H| is large. We shall conclude the section by briefly 
describing ways of using Tietze transformations to simplify large 
presentations by eliminating redundant generators and relators, and by 
shortening long relators. 
5.3.1 Computing a presentation on Schreier generators 
The input for this procedure is a completed coset table for G over H or, 
equivalently (cf Theorem 5.2), the permutation action of G by right 
multiplication on the right cosets of G. The coset table may have been 
computed by coset enumeration or by some alternative method. We shall 
assume, however, that Ω=[1..n], where n=|G:H|, and that the table has 
been standardized by a call of STANDARDIZE if necessary. The latter 
assumption is not strictly necessary, but it renders the details of the code 
simpler. 
Example 5.5 
As we describe the procedure, we shall work through the following example. 
Let 
  
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
174 
Then it is easily checked, using Theorem 2.52, that the map ϕ:X→Sym(Ω) 
with Ω={1, 2, 3, 4, 5, 6} defined by 
  
extends to a homomorphism ϕ:G→Sym(Ω), and ϕ is clearly a transitive 
permutation representation of G. Since ϕ(x)ϕ(y)=ϕ(y)ϕ(x), we have 
|im(ϕ)|=6. Hence the action of G on Ω defined by ϕ is regular, and the 
stabilizer H of 1 in this action is equal to the kernel of the action. In fact it 
is not hard to show that H=[G, G]. Notice that we have not been given 
generators of H in this example. We have chosen ϕ(x) and ϕ(y) such that 
the associated coset table below is already standardized. 
Notice that, although there is a relator x2, we have still included a column 
for 
. This is necessary for the computation of a presentation of H on the 
set of Schreier generators. In fact the relators of H corresponding to 
conjugates of x2 will tell us that some of these Schreier generators are 
trivial in H, and, if we are happy to omit these from the generating set, 
then we could save a little time by not including the column for 
.
As in Section 2.5, let 
 where G=F/N with F=FX and 
, 
and let H=E/N. We start by choosing our Schreier transversal T of E in F 
and defining the set Y of Schreier generators ytx of H with respect to this 
transversal. We can do this by a scan of the coset table. As in Section 5.1, 
we shall denote the element of T representing a∈Ω by τ(), but we do not 
need to store the words τ(). 
The procedure DEFINESCHREIERGENERATORS defines Y, and 
computes a word P[,x] in (YY-1)* for each ∈Ω and x∈A:=XX-1. This 
word satisfies τ()x=F P[, x]τ(x). It is either the empty word (if it arises 
when τ(x) is defined as τ()x), or a Schreier generator in Y (when x∈X), or 
an inverse of a Schreier generator (when x∈X-1). Since each τ(x) is defined 
as τ()x for some existing element τ() of T, it is clear that T is prefix 
closed, and hence a Schreier transversal. 
We regard Y and P as being new components of the coset table , and 
define a modified coset table 
M to be an ordinary coset table endowed with 
these two extra components. 
Let us apply DEFINESCHREIERGENERATORS to Example 5.5. To ease the 
notation, we shall introduce new names a, b, c,… for the Schreier generators. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
175 
DEFINESCHREIERGENERATORS(~C) 
Input: A complete standardized coset table on Ω=[1..n] 
(* τ(1):= *) 
1 Y:={}; γ:=2; 
(* γ is the next new entry that we will find in the standardized table *) 
2 for ∈ [1..n], x∈A 
3 
do ß:=x; 
4 
if ß=γ 
5 
then (* Choose coset representative corresponding to τ *) 
6 
P[, x]:=; P[ß, x-1]:=; γ:=γ++1; 
7 
(* τ (ß):=τ()x *) 
8 
elseif x∈X and P[, x] is undefined 
9 
then (* Adjoin new Schreier generator to Y *) 
10 
Y:=Y{yx}; P[, x]:=yx; 
; 
When =1, we define τ(2):=x, τ(3):=y and τ(4):=y-1, and set P[1, x], P[2, x-1], 
P[1, y], P[1, y-1], P[3, y-1] and P[4, y] equal to . When =2, we introduce the 
Schreier generator a:=y2x and set P[2, x] to a and P[1, x-1] to a-1. The next 
two entries give rise to the definitions τ(5):=τ(2)y=xy and 
, together with the corresponding trivial entries in 
the table P. So we have now completed the definition of T={e, x, y, y-1, xy, 
xy-1}. The remaining entries x give rise to the Schreier generators b:=y3x, 
c:=y3y, d:=y4x, e:=y5x, f:=y5y, and g:=y6x. 
The table below shows both P[, x] and x for ∈Ω, x∈A. This is helpful 
when working through examples by hand, because it emphasizes the 
relationship τ()x=F P[, x]τ(x). 
We saw in the remark following Theorem 2.62 that 
is a set of defining relators for a group H, isomorphic to H, on the generating 
set Y. The function REWRITE computes 	(t, w) for t∈T and w∈W. It takes 
the element ∈Ω with 1t= as an argument. So, to compute S, we just need 
to call REWRITE on all ∈Ω and w∈W. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
176 
REWRITE(
M, , w) 
Input: A complete modified coset table 
M on Ω=[1..n], 
∈Ω, w=x1 x2 … xr∈A*. 
Output: 	(τ(), w). 
1 
v:=; 
2 
for i∈ [1..r] do v:=vP[, xi]; 
; 
3 
return v; 
We shall now use this function to calculate the set S in Example 5.5. Calls 
of REWRITE with =1 and w=x2 or y3 return a and c, respectively. Let us 
work through the call REWRITE(
M, 1, (xy)6) in detail. We start with =1, 
v=. Working through the ‘For’ loop, produces the following sequence of 
assignments: 
So the relator returned is ecdabfg. The complete set of results returned 
by REWRITE(
M, , w) is listed in the following table; we can hopefully 
leave the reader to check these! 
Looking at the complete set S of relators of H, we notice that there is 
some repetition, and also that the relators arising from (xy)6 are all cyclic 
conjugates of each other, and hence only one of them is needed. So the 
presentation on the Schreier generators simplifies to 
We can further simplify this presentation without much effort. The 
generators a, c, f are all trivial and so can be omitted, and we can use the 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
177 
relators be and dg to eliminate the generators e and g by replacing them by 
b-1 and d-1, respectively, as described in Subsection 2.4.4. The result is the 
presentation 
, which defines a free abelian group on two 
generators. Incidentally, we have now proved that H and hence G is an 
infinite virtually abelian group. 
A moment’s thought should convince the reader that the fact that we 
are getting lots of repetition of relators via cyclic conjugates is no accident. 
In general, if we have a relator of the form wr for some r>1, and if 
for some , ß∈Ω and 1≤i<r, then the words returned by REWRITE(
M, , 
wr) and REWRITE(
M, ß, wr) will be cyclic conjugates of one another. Being 
aware of this can save time, particularly when working examples by hand. 
Let us work through another example. 
Example 5.6 
Let 
, and 
. We leave it to 
the reader to carry out a coset enumeration and to calculate that |G:H|=5. 
As a hint, the sequence of definitions 1x=2, 2x=3, 
, 3y=5 will lead to 
the enumeration completing with no coincidences, and the resulting coset 
table, which fortunately is already standardized, is: 
As in the previous example, we call DEFINESCHREIERGENERATORS 
to compute the function P, and the modified coset table is: 
Now, calling REWRITE(
M, , x3) for ∈ [1..5] and omitting cyclic 
conjugates, yields relators a, d3, f3. Doing the same with y5 results in just 
ecb, and with (xy)2 we get b2, acf, and de. So the presentation of 
 on 
the Schreier generators is 
We can immediately eliminate a, e (by replacing e by d-1), and f (by replacing 
f by c-1). We now have 
. Eliminating d, by replacing 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
178 
it by cb, and replacing the relator c-3 by the equivalent c3, we get 
. In fact we have already studied the group defined by this 
presentation, and we saw in Subsection 5.2.6 that it has order 24, so |H|=24 
and |G|=5|H|=60. The image of the associated permutation representation 
, which is generated by ϕ(x)=(1, 2, 3) and ϕ(y)=(1, 4, 3, 5, 2) is Alt(5), so ϕ 
is a monomorphism, and G≅Alt(5).
The algorithm that we have described in this subsection to compute a 
presentation of a subgroup on its Schreier generators is one of the easiest 
algorithms in CGT both to implement and to use to work through examples 
by hand. Such an implementation is described by Havas in [Hav74]. In an 
implementation, elements of Y would typically be represented by positive 
integers, and then P could be a two-dimensional array of integers, where 0 
is used to represent the empty string, and the inverse of the generator 
number i is represented by -i. The disadvantage of the algorithm is that, 
for |G:H|=n, we have |Y|=(n–1)|X|+1 and |S|=n|R|, so the resulting 
presentations can be highly unwieldy when n is large. We shall discuss 
how to simplify such presentations in Subsection 5.3.3 below. 
5.3.2 Computing a presentation on the user generators 
If we are given a finitely presented group 
 and a subgroup 
 of G, then we may wish to compute a presentation of H on its 
given generating set, rather than on the set of Schreier generators. This 
can be done, but it is more complicated than the algorithm described in 
Subsection 5.3.1, and involves a process known as modified coset 
enumeration or the modified Todd-Coxeter procedure in which we carry 
out the coset enumeration using a modified coset table. 
We introduce a new set of symbols Y corresponding to . So we have a 
bijection 
, which extends to a homomorphism ϕ:FY→F, where 
im (ϕ)=E, with G=F/N and H=E/N as in Subsection 5.3.1. Assuming that 
|G:H| is finite, we can use coset enumeration to calculate the associated 
coset table and (implicitly) a transversal T and a bijection :→T. 
In modified coset enumeration, we compute elements ytx of FY with the 
property that 
 for all t∈T, x∈X at the same time as we 
compute the coset table itself. As usual, we will take 
 to be the inverse 
of the element yux, where 
. We first need to describe how to compute 
the words ytx. Once we have done that, computing the presentation of H 
will be straightforward, and will be similar to the method used in Subsection 
5.3.1. 
As in Subsection 5.3.1, we will store ytx as a word 
, 
where t=τ(), but now we will compute these words as we carry out the 
coset enumeration. In fact P[, x] will be defined if and only if x is defined, 
and we will always define P[, x] such that it satisfies the required equation 
τ()x =G ϕ(P[, x])τ(ß). To do this, we need to modify our coset enumeration 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
179 
procedures DEFINE, SCAN, SCANANDFILL and COINCIDENCE so that 
they assign P[, x] whenever they assign x. 
We shall not prove the correctness of what we are doing formally, like 
we did for normal coset enumeration in Section 5.1, although this would 
not be particularly difficult. Instead, we shall attempt to explain what we 
are doing, so that the reader can construct formal proofs if necessary. 
The change needed to DEFINE is easy. Since we are defining τ(ß) to be 
τ()x, we just need to set P[, x] and P[ß, x-1] to be E. The modified coset 
tables CM have an additional component, which is a function pP from [1..n] to 
A*. It is used in connection with the modified coincidence procedure, which 
we shall discuss shortly. 
MODIFIEDDEFINE(~CM, , x) 
Input: ∈, x∈A, with x undefined. 
1 
n:=n+1; ß:=n; p[ß]:=ß; 
2 
x:=ß; 
; 
3 
P[, x]:=E; P[ß, x-1]:=E; pP[ß]:=E; 
4 
(* Set τ(ß) equal to τ()x. *) 
The MODIFIEDSCAN procedure takes arguments α, w, and y. When we 
call it, the extra argument y is put equal to E when w∈R, and to the 
corresponding y∈Y, when =1 and w is a subgroup generator. Thus, in all 
cases, we have ()w=G ϕ(y)τ(α), and the correctness of the procedure 
depends on that fact. The MODIFIEDCOINCIDENCE routine also takes 
three arguments, κ, λ∈Ω and a word w∈Y*, and we call it in situations 
where we know that τ(κ)=G ϕ(w)τ(λ). 
Throughout MODIFIEDSCAN, we maintain words fP and bP along with 
the coset numbers f and b that we encounter as we scan forwards from the 
beginning of the word, and backwards from the end of the word, respectively. 
At a given point we have w=uzv, where u and v are the subwords that have 
been scanned in the forwards and backwards traces, and then f=αu and 
bv=α. The words fP and bP will be defined such that they satisfy τ(α)u=G 
ϕ(fp)τ(f) and 
. 
The point of this is that, if z is a single generator x∈A, then we can make 
the deduction fz=b and 
, and the required property τ(f)z=G 
ϕ(P[f, z])τ(b) follows from the assumption τ(α)w=G ϕ(y)τ(α). On the other 
hand, if z is the empty word, then τ(α)w=G ϕ(y)τ(α) implies that 
. 
We shall not write down a formal proof of correctness, but to do that we 
would simply need to check that the correctness of all of the properties 
that we have asserted in this paragraph is maintained by all of the 
statements in the procedure. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
180 
MODIFIEDSCAN(~CM, α, w, y) 
Input: α∈Ω, w∈A*, y∈ (Y∪Y-1)* with τ(α)w=G ϕ(y)τ(α). 
(* Scan forwards *) 
1 Let w=x1x2…xr, with xi∈A; 
2 f:=α; fp:=ε; i:=1; 
3 while i≤r and 
 is defined 
4 
do fP:=fPP[f, xi]; 
; i:=i+1; 
5 if i>r 
6 
then if fα then MODIFIEDCOINCIDENCE(~CM, f, α, 
); 
7 
return; 
(* Forward scan was incomplete. Scan backwards *) 
8 b:=α; bP:=y; j:=r; 
9 while j≥i and 
 is defined 
10 
do 
; 
; j:=j-1; 
11 if j<i 
12 
then MODIFIEDCOINCIDENCE(~CM, f, b, 
); 
13 elseif j=i 
14 
then (* Deduction *) 
15 
; 
; 
16 
; 
17 (* Otherwise j>i—scan is incomplete and yields no information *). 
In MODIFIEDCOINCIDENCE, as well as the array p used to store the 
right congruence generated by the coincidence, we maintain an array pP 
of words over 
, such that p[α]=ß implies that τ(α)=G ϕ(pP[α])τ(ß). 
Again, we shall not write down a formal correctness proof. To do that, we 
would just need to verify that every assignment to pP[α] or to P[α, x] 
maintains the correctness of the required properties of pP and of P: namely 
that αx=ß implies τ(α)=G ϕ(P[α, x])τ(ß) and that p[α]=ß implies that τ(α)=G 
ϕ(pP[α])τ(ß). 
MODIFIEDCOINCIDENCE uses modified versions M-REP and M-MERGE 
of REP and MERGE. 
M-REp(κ, ~p, ~pP) 
Input: κ∈Ω, arrays p, pP 
1 
λ:=κ; ρ:=p[Ω]; 
(* We introduce a new array s to trace back the compression path *) 
2 
while ρλ do s[ρ]:=λ; λ:=ρ; ρ:=p[λ]; 
3 
ρ:=s[λ]; 
4 
while ρκ 
5 
do µ:=ρ; ρ:=s[µ]; p[ρ]:=λ; pP[ρ]:=pp[ρ]pP[µ]; 
6 
return λ; 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
181 
M-MERGE(κ, λ, w, ~p, ~pP , ~q, ~l) 
Input: κ, λ∈Ω, w∈ (Y∪Y–1)* with τ(κ)=G ϕ(w)τ(λ), p, pP, q, l 
(* q is a queue of length l of elements to be deleted from Ω *) 
1 
ϕ:=REP(κ ~p, ~pP); ψ:=REP(λ, ~p, ~pP); 
2 
If ϕ>ψ 
3 
then p[ϕ]:=ψ; pP[ϕ]:=pP[κ]-1wpP[λ]; 
4 
l:=l+1; q[l]:=ψ; 
5 
elseif ψ>ϕ 
6 
then p[ψ]:=ϕ; pP[ψ]:=pP[λ]-1w-1pP[κ]; 
7 
l:=l+1; q[l]:=ψ; 
MODIFIEDCOINCIDENCE(~CM, α, ß, w) 
Input: A coincident pair α, ß∈Ω, w∈ (Y∪Y–1)* 
with τ(α)=G ϕ(w)τ(ß). 
1 l:=0; M-MERGE(α, ß, w, ~p, ~pP, ~q, ~l); i:=1; 
2 while i≤l 
3 
do γ:=q[i]; i:=i+1; 
4 
for x∈A do if γx is defined and equal to δ 
5 
then (* Remove the entry 
 from the table *) 
6 
Undefine 
; 
(* Queue any new coincidences *) 
7 
µ:=REP(γ, ~p, ~pP); ν:=REP(δ, ~p, ~pP); 
8 
if µx is defined 
9 
then v:=pP[δ]-1 P[γ, x]-1pP[γ]P[µ, x] 
10 
M-MERGE(ν, µx, v, ~p, ~pP, q, ~l); 
11 
elseif 
 is defined 
12 
then v:=pP[γ]-1 P[γ, x]pP[δ]P[µ, x-1]; 
13 
M-MERGE(µ, 
, v, ~p, ~pP, ~ q, ~ l); 
14 
else µx:=ν; 
; 
15 
v:=pP[γ]-1P[γ, x] pP[δ]; 
16 
P[µ, x]:=v; P[ν, x-1]:=v-1; 
The modifications required in the remaining coset enumeration procedures 
are straightforward: SCANANDFILL requires the changes corresponding 
to those of SCAN; COSETENUMERATIONR, COSETENUMERATIONC, 
and LOOKAHEAD need changing only to call the modified versions of the 
other procedures; COMPRESS and STANDARDIZE, which redefine 
elements of Ω, require corresponding changes to be made to P[α, x] whenever 
αx is redefined. 
We shall now illustrate the modified coset enumeration process by 
working through some examples. As usual, when doing examples by hand, 
we do not make definitions and carry out scans in the precise order specified 
by COSETENUMERATIONR or COSETENUMERATIONC; we prefer to 
select those definitions and scans that result in the enumeration completing 
as quickly as possible. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
182 
Example 5.7 
Let 
 and 
. 
(This was also Example 5.6.) First we introduce the set of new symbols 
Y:={a, b} and define ϕ:FY→F by ϕ(α)=xy, ϕ(b)=x–1y–1xyx. 
When working by hand, it is convenient to use a similar notation as we 
did for displaying modified coset tables, and write αx=wß to mean αx=ß and 
P[α, x]=w. In the following description, and also in subsequent examples, 
we have written MS for MODIFIEDSCAN. 
First define 1x=2, 2x=3, and deduce 3x=1 from MS(~CM, 1, x3, ε). Then 
deduce 2y=a1 from MS(~CM, 1, xy, a). Then define 
, and deduce 
4x=b4 from MS(~CM, 1, x-1y-1xyx, b), and then 1y=b-14 from MS(~CM, 3, (xy)2, 
e). Then define 3y=5 and deduce 5y=ba-12 from MS(~CM, 1, y5, e). Finally, we 
deduce 5x=ab-15 from MS(~CM, 2, (xy)2), and then all other scans complete 
consistently. The complete modified coset table is: 
The procedure for computing the relations from the modified coset 
table is derived from Theorem 2.63 and the remark following it. The set 
of relators, {ρ(t, w)|t∈T, w∈R}, is computed exactly as in Subsection 5.3.1 
by applying REWRITE(CM, α,w) to all α∈Ω and w∈R. Unlike in Subsection 
5.3.1, however, we must include the additional relators coming from the 
set S2 of Theorem 2.63. These are computed as REWRITE(CM, 1, ϕ(y))y-1 
for y∈Y. 
Carrying this out in the example above, the two relators in S2 both freely 
reduce to ε, so we do not need them. We find that REWRITE(CM, 4, x3), 
REWRITE(CM, 5, x3) and REWRITE(CM, 1, (xy)2) yield relators b3, (ab-1)3, 
and a2, respectively. All other relators in S1 freely reduce to ε, so the 
presentation computed for H is 
. By replacing b by b-1 
in the presentation, we can replace the third relator by (ab)3, and so we 
now have the same presentation for H as we computed in Subsection 5.3.1. 
(Strictly speaking, replacing b by b-1 also involves changing the relator b3 to 
b-3, but this is equivalent to b3 anyway!)
By applying modified coset enumeration in the case H=G, we can compute 
a presentation of G on an arbitrary generating set of G. This technique is 
illustrated in the following example, which also provides an easy application 
of MODIFIEDCOINCIDENCE. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
183 
Example 5.8 
Let 
 and 
. 
(Easy exercise: show directly that H=G.) As in the preceding example, 
put Y={a, b}, ϕ(a)=xy, ϕ(b)=xy-1. Define 1x=2, and deduce 2y=a1 from MS(~CM, 
1, xy, a) and 
 from MS(~ CM, 1, xy-1, b). Applying MS(~CM, 1, y3, ε) 
now results in a call of MODIFIEDCOINCIDENCE(~ CM, 2, 1, ba-1b), and 
the completed modified coset table after this call is: 
We find REWRITE(CM, 1, xy)a-1=(ba-1)3 and REWRITE(CM, 1, xy-1)b-1 freely 
reduces to ε. For the relators in S1, we get REWRITE(CM, 1, x3)=(ba-1b)3, 
REWRITE(CM, 1, y3)=(a-1b)3, and REWRITE(CM, 1, (xy)3)=(ba-1ba-1b)3. We see 
that (a-1b)3 is a cyclic conjugate of (ba-1)3, and (ba-1ba-1b)3 simplifies to a3 
using (ba-1)3, so the computed presentation simplifies to 
One of the difficulties with modified coset enumeration in practice, which 
is not apparent from the small examples that we have worked through, is 
that the words P[α, x] can grow very long during the course of the 
enumeration. A number of methods have been tried for keeping the lengths 
of these words down in practical implementations. For example, a method 
involving storing the words implicitly using a tree structure is discussed in 
[AMW82]; see [Neu82] for references to other implementations of this 
method. Another possibility is to collect the relators in the subgroup 
presentation during the enumeration itself, rather than at the end of the 
enumeration, and to attempt to use known relators to shorten the words 
P[α, x]. 
One situation in which modified coset enumeration is frequently applied 
is when H has a single generator. We mentioned this possibility in 
Subsection 5.2.6 in connection with finding the order of a finitely presented 
group G. In this case, the problem of long words P[α, x] can be ameliorated 
by storing these words as the integral exponent of the single generator. 
Example 5.9 
Let 
 and 
. 
We put Y={a} with ϕ(a)=x. Then MS(~CM, 1, x, a) results in the deduction 
1x=a1. Define 1y=2 and 
. Then MS(~CM, 1, x3y-3, ε) and MS(~CM, 1, 
(xy-1)2, ε) yield the deductions 2y=a33 and 3x=a-12. Define 2x=4. Then MS(~CM, 
2, x3y-3, ε) and MS(~CM, 2, (xy-1)2, ε) give the deductions 4x=a43 and 4y=a4. 
The table is now complete, and the remaining scans produce no coincidences. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
184 
The relator in S2 is trivial, REWRITE(CM, i, (xy)3)=a6 for i∈ [1..4], and the 
other relators in S1 reduce to ε. Hence H is cyclic of order 6 and |G|=24. 
This is probably the easiest way of calculating |G|. We could also run 
a normal coset enumeration with 
, but then we would have 
|G:H|=8.
5.3.3 Simplifying presentations 
As a measure of the complexity of a group presentation, we formally define its 
size to be the triple (|X|, |R|, l), where l is the total relator length; that is, 
. 
Let n:=|G:H|. Then the presentation 
 for the group 
 on 
the set of Schreier generators as described in Subsection 5.3.1 has size ((n– 
1)|X|+1, n|R|, nl). In practice, we replace relators by cyclically reduced 
conjugates and omit trivial relators and repetitions of relators (including 
repetition by cyclic conjugates), so the numbers n|R| and nl are upper 
bounds. Such simplifications do not change the group H. 
The presentation described in Subsection 5.3.2 on the set of user-defined 
generators  has size ( , n|R|, ?). Although  is typically much smaller 
than the number (n-1)|X|+1 of Schreier generators, when n is large, it 
often happens that the total relator length is much larger and less predictable 
than nl. For this reason, if, as is often the case, the generating set for H is 
not of particular importance to the user, then for subgroups of large index, 
it can turn out to be more effective or feasible to compute the presentation 
on the Schreier generators. 
But in either case the user will usually want to attempt to simplify the 
initially computed presentation, by shortening the total relator length, 
removing redundant relators and, for presentation on Schreier generators, 
eliminating generators. Simplifying presentations in this manner is the 
subject of this subsection. These methods are most often applied to the 
output of subgroup presentation programs, but they can be applied in 
principal to any group presentation, so we shall denote the presentation to 
be simplified by 
. This technique is used frequently in certain 
applications of CGT, which we shall discuss later in Subsection 9.3.3. 
Implementations of these methods are generally known as Tietze 
transformation programs. One such implementation is described by Havas 
in [Hav74]. Unfortunately, they are rather difficult to implement, because 
they involve moderately complicated string searching and manipulation, 
and the programmer needs to bear in mind that computer memory may be 
at a premium. One might be tempted, for example, to compute and store 
all the inverses and all cyclic conjugates of all of the defining relators, but 
this could prove fatally extravagant for a presentation with total relator 
length equal to a seven-figure number. We shall not go deeply into 
implementation issues here, but we shall mention a few ideas that have 
proved useful. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
185 
The processes of eliminating generators and performing common 
substring replacement were defined in Subsection 2.4.4 in terms of the 
basic Tietze transformations. There are three principal subroutines that 
are required in a Tietze transformation program, namely: 
1. 
use relators of length 1 and 2 to eliminate redundant generators; 
2. 
eliminate some generators; 
3. 
perform common substring replacement to shorten the total relator 
length and remove redundant relators. 
We shall refer to these subroutines, respectively, as elimination by short 
relators, elimination, and simplification. The first is of course a special 
case of the second, but it is used more frequently than general elimination. 
Elimination by short relators always reduces all three parameters in 
the presentation size. General elimination reduces |X| and |R|, but 
will typically increase the total relator length. Simplification which, 
unlike elimination, does not change the group defined by the presentation, 
leaves |X| unchanged, but reduces the total relator length and possibly 
also |R|. 
A flexible implementation, such as the ones in GAP and MAGMA, will 
allow the user to call these three subroutines in any desired order, and will 
also provide some default calling sequences, but still with some optional 
parameters. We shall assume that all relators are always cyclically reduced; 
that is, that whenever a relator is changed, it is immediately replaced by 
its cyclic reduction. 
As we shall see shortly, simplification is performed in a series of 
simplification rounds. A typical calling sequence TIETZE(e, m, p), say, is to 
repeat the following two steps as many times as possible. Here e and m are 
positive integers, and 0≤p≤1. So a possible call of this would be TIETZE(100, 
100000, 0.01). 
(i) 
Eliminate generators until e generators have been eliminated, or until 
the total relator length exceeds m. 
(ii) Perform rounds of simplification until the percentage decrease in total 
relator length resulting from a round is less that 100p. Perform 
elimination by short relators after each simplification round. 
This process would stop when neither (i) nor (ii) could be performed. The 
user might also want to put an upper bound on the number of generators 
eliminated altogether, or to limit the number of times that (i) and (ii) are 
repeated. 
Let us now describe the elimination and simplification subroutines in 
more detail. Eliminating a generator consists of locating a word w∈R, such 
that some cyclic conjugate of w or w-1 has the form x1
-1x2…xr, where x:=x1 
∈X, and xix±1 for 2≤i≤r. We then delete this relator from R, replace all 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
186 
occurrences of x±1 by (x2…xr)±1 in all other relators, and delete x from X. 
When the relator has length 1 or 2, this process decreases all three 
parameters of the presentation, and there is every advantage in carrying it 
out immediately. This is why we use elimination by short relators more 
frequently than general elimination. 
Other eliminations typically increase the total relator length. Usually, 
and particularly early on in the process of simplifying a large presentation, 
there will be a large number of candidates for x and w, and it is of critical 
importance to choose the right one. Examples have been encountered of 
large presentations that can be simplified down to a very small size by the 
correct choices of generators to eliminate, and which remain completely 
unmanageable with other choices. In fact this choice is probably much more 
crucial than the choice of the parameters e, m, p in TIETZE. Unfortunately, 
there seem to be very few satisfactory heuristics known for guiding the 
choice. The increase in the total relator length resulting from the elimination 
of x1 using w as described above is at most (r–2) (o(x1)-1)-r, where o(x1) is the 
total number of occurrences of the generator x1 in all relators (including w 
itself). The standard default approach is to choose x1 and w so as to minimize 
this increase. For this we need to know o(x) for all x∈X, but it is not difficult 
to calculate these values initially and then to adjust them each time that 
the presentation is changed. In any event, the user should be allowed to 
specify a particular elimination to make at any stage. 
A round of simplification consists of looking at each pair {v,w} of distinct 
elements of R in turn and, assuming that |v|≤|w|, checking whether we 
can write cyclic conjugates of v and w or of their inverses as uv1 and uw1, 
respectively, where |u|>|v1|. If so, then we do this with u as long as 
possible, and replace w by 
. If this results in w freely reducing to ε, 
then we remove it from R. 
A casual implementation of this process is likely to run very slowly, 
because there is a lot of checking of matching substrings to be done. There 
a number of simple ways of speeding this up. Before each round, the relators 
should be sorted into length-increasing order. For each relator, two one-bit 
flags should be maintained, recording whether this relator was changed 
during the previous simplification round, and whether it has been changed 
in the current round. If a particular pair {v, w} was checked for matching 
substrings in the last round and neither v nor w has changed since that 
check, then it is not necessary to check that pair again. Suppose that we 
are about to check a particular pair {v,w} with |v|≤|w| for matching 
substrings, let v=x1x2…xr, and let s:=[(r+2)/2]. If a cyclic conjugate of v can 
be written as uv1 with |u|≥|v1|, then u must contain at least one of the 
generators x1 and xs in v. Similarly, for a cyclic conjugate of v-1, u must 
contain at least one of 
 and 
. Thus, when searching for matching 
substrings, we can begin our searches of v and v-1 at x1, xs, and 
, 
 and 
work outwards in both directions from these starting points. In particular, 
if w contains none of x1, xs, 
, 
, then there is no possibility of a 
simplification. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
187 
In the simplification process, there are situations where it is 
advantageous to replace w=uw1 by 
 even when |u|=|v1|, and the 
user should have some control as to whether or not this is done. Of course 
it should not be done on every possible occasion, or the process will go 
into an infinite loop! There is one specific situation where this should 
happen by default, and this is when |v|=4 and v is a commutator of two 
generators. This means that, for some x, y∈X, we have xy=G yx. Then, 
whenever x±1 and y±1 are adjacent in a relator, they should always be put 
into the same order, which would usually be to put the lower-numbered 
generator, x, say, before the higher-numbered generator y. Then any 
subword of any relator involving only x and y and their inverses would be 
put in the normal form xiyj, for i, 
. 
There are even some situations where it would turn out to be a good 
idea to substitute longer strings for shorter strings, but it is probably not 
feasible to hope to be able to recognize such situations in a computer 
implementation. For example, if three generators x, y, z satisfy relations 
[y, x]=G z, xz=G zx, yz=G zy (which implies that they generate a nilpotent 
subgroup), then it might be a good idea to use the standard normal form 
xiyjzk for nilpotent groups for subwords involving just these generators, 
but that would involve replacing yx by xyz, resulting in a lengthening of 
the relators. In general, it is probably fair to say that Tietze transformation 
programs do not work very successfully on presentations that involve 
polycyclic-type relators. 
For presentations that are not too large, there is an alternative approach 
to the manipulation of group presentations involving rewriting systems 
and the Knuth-Bendix completion process. That will be the main topic of 
Chapter 12. It involves systematically generating all consequences of the 
relations in a group presentation, and so in principal it can eventually find 
any short relations that hold in the presentation, and determine whether 
any of the defining relators are redundant. But it is incapable of handling 
the very large presentations, with perhaps hundreds of thousands of 
generators and relators, to which we typically apply Tietze transformation 
programs. 
Exercises 
1. 
Let 
, as in Exercise 2 at the end of Section 
5.1. Show by using the modified coset enumeration procedure with 
, that |G:H|=2 and that H is cyclic of order 4. 
2. 
Let 
. 
(i) 
Show that G/[G,G]=C2×C4. 
(ii) Find a presentation of the subgroup [G, G] of G and use it to show 
that [G, G] is a free abelian group of rank 2. 
(iii) Write down the generators used in your presentation of [G, G] 
(after eliminating any redundant generators) as words in the 
generators of G and their inverses. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
188 
3. 
Let 
 and 
. 
(i) 
Show by coset enumeration that |G:H|=7. 
(ii) Calculate a presentation of H. 
(iii) Show by eliminating generators from this presentation, and then 
manipulating it, that H is isomorphic to a quotient group of the 
group 
 
, and hence |H|≤24 and |G|≤168. 
(iv) Show by using the permutation representation arising from (i) that 
|G|≥168, and so |G|=168. (Hint: In the permutation 
representation, show that H=G1 is transitive on Ω\{1}, hence 
|H|=6|G12|, and consider (xz)2 and xz(xzx)2 with z:=y-1xy2 to get 
|G12|≥4.) 
5.4 Finding all subgroups up to a given index 
In the final section of this chapter, we address a problem that is, in some 
respects, the converse of the basic problem of coset enumeration. Rather 
than finding the index of a given subgroup H of a finitely presented group 
G, we want to find all subgroups H such that the index |G:H| is at most a 
specified number N>0. This has traditionally been known as the low-index 
subgroups problem. For many presentations, particularly for groups with 
more than two defining generators, solving this problem only seems to be 
feasible for rather small values of N, which explains the name. 
To give the reader an immediate rough idea of the current scope of 
algorithms to solve this problem, we observe that the (2, 3, 7)-triangle 
group 
 is an easy example, in which the subgroups up to 
index about 50 or 60 can be found within 10 seconds, whereas the Heineken 
group 
  
is a difficult example. Even after simplifying the presentation and removing 
a redundant generator, it takes about 60 seconds to find the subgroups up 
to index 10, and over 1000 seconds to do this while working with the initial 
3-generator presentation. Of course, these times depend on which 
implementation one is using on which computer, and they are only intended 
to give an idea of the scope of the methods. In general, the observed 
behaviour of all current implementations is that, for a given example, the 
growth of the time required is more than exponential in N, so we expect 
there to be a critical value of N beyond which it is not practical to proceed. 
There is, however, considerable scope for further research into 
improvements of low-index subgroup algorithms. 
The first practical methods for solving the low-index problem were 
developed independently by Dietze, Schaps [DS74], and Sims [Sim74]. For 
many years, the principal implementations, such as those used in CAYLEY 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
189 
and GAP were based on the ideas described in these papers. The method 
consists in running coset enumeration, initially over the identity subgroup, 
but allowing only f(N) cosets to be defined, where f(N) must satisfy f(N)≥N, 
and usually f(N)≤2N. Then coincidences are systematically imposed between 
the defined cosets; each such coincidence is equivalent to adjoining a new 
generator to the subgroup H over which the coset enumeration is taking 
place. After a forced coincidence, the coset enumeration is resumed, but 
still allowing only f(N) cosets to be defined. Whenever an enumeration 
completes with at most N cosets, a subgroup of index at most N has been 
found. Each forced coincidence corresponds to a node in a tree, and the 
complete procedure consists of a backtrack search through the nodes. 
More recently, a rather different method has been proposed by Sims; it 
still involves a backtrack search, but over incomplete coset tables rather 
than over forced coincidences. This newer method is described in Section 
5.6 (plus some earlier sections) of [Sim94], and has been implemented in 
MAGMA. Since the current evidence suggests that (with one caveat, which 
we shall mention later) it performs better on most typical examples than 
the earlier method, we shall describe the newer method of Sims here, and 
refer the reader to [Neu82] for an accessible description of the forced 
coincidence approach. 
5.4.1 Coset tables for a group presentation 
As usual, let 
 and let 
. Let us call a complete coset 
table with columns indexed by A in which Property 2 (
) 
holds, and in which all α∈Ω scan correctly under all w∈R, a complete coset 
table for G. As in the proof of Theorem 5.2, it follows from Theorem 2.52 that 
a complete coset table for G is equivalent to a transitive action of G on the 
set Ω of cosets in the coset table. 
By Proposition 2.23, this action is equivalent to the action of G by right 
multiplication on the cosets of H:=G1. Conversely, for any subgroup H of G 
of finite index, the action of G by right multiplication on the cosets of H 
defines a complete coset table for G in which H=G1. By Proposition 2.23, if 
we have two group actions in which H=G1, then the actions are equivalent 
under an equivalence that fixes the point 1. Now a standardized coset table, 
as defined in Subsection 5.2.3, provides us with a canonical representative 
of such an equivalence class. Summing up, we have: 
PROPOSITION 5.6 For any n>0, there is a one-one correspondence between 
standardized complete coset tables for G with |Ω|=n and subgroups of G of 
index n, in which the subgroup H corresponding to a coset table C is the 
stabilizer G1 in the group action corresponding to C. 
Our algorithm for producing subgroups of index up to N will proceed by 
systematically constructing a list of all complete standardized coset tables 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
190 
for G with |Ω|≤N. In practice, we save space and time with no genuine 
loss of information if we return coset tables corresponding to representatives 
of the conjugacy classes of subgroups of G rather than all subgroups. To do 
this, we shall make use of the fact that the conjugates of H are just the 
stabilizers Gα of the points α∈Ω in the associated group action. (See proof of 
Proposition 2.23.) 
If generators are required for the subgroups H=G1 corresponding to the 
coset tables, then the Schreier generators, as defined in Subsection 5.3.1, 
can easily be computed. A presentation of H on these generators could also 
be computed, which could then be used, as described in Subsection 5.3.3, to 
eliminate redundant Schreier generators if a smaller generating set were 
deemed to be desirable. 
5.4.2 Details of the procedure 
We have been using ‘bottom-up’ descriptions of our algorithms so far in this 
chapter, starting with the lower-level routines. So, to make a change, we 
shall describe the procedure from the the top down, and use recursion to 
avoid the details of the backtrack search. 
Sims suggests splitting the group relators R into two parts R1 and R2, 
where R1 consists of shorter relators and R2 of longer relators. The relators 
of R1 will be used in the inner parts of the process to prune branches of the 
search tree, whereas those of R2 will be only be checked at the last step for 
complete coset tables. During most parts of the search, the coset tables 
being manipulated are incomplete, and experience has shown that time is 
wasted by scanning the longer relators frequently on incomplete coset tables, 
because the scans rarely complete, and so no information is gained. 
Unfortunately there appear to be currently no reliable heuristics for deciding 
exactly how short is short! 
Our top-level procedure performs this subdivision and computes the sets 
 of the cyclic conjugates w of the relators in R1 for which w has x as 
its first letter. These will be required for input to the procedure 
PROCESSEDEDUCTIONS, which was described in Subsection 5.2.2. The 
main task is then passed over to the procedure DESCENDANTSUB- 
GROUPS, which will be called recursively. The complete standardized 
coset tables to be returned eventually will be kept throughout in the 
list S. 
Our base point for the search is the empty coset table with a single 
coset 1, and no transitions defined. Unlike in previous sections in this 
chapter, we shall be manipulating more than one coset table C, and so 
we shall denote the set Ω and the array p associated with C by ΩC and pC, 
and transitions αx=ß in C by 
. Since we shall never allow cosets to 
be eliminated as a result of coincidences, we shall always have Ωc=[1.. 
nC] for some nC≤N. All of the coset tables will be with respect to the same 
set A of generators. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
191 
LOWINDEXSUBGROUPS
Input: A finite group presentation 
Output: Coset tables for representatives of classes of subgroups 
of index at most N in G 
1 Initialize a coset table C for 
; 
2 pC[1]:=1; nC:=1; 
3 Let 
 with ‘short’ relators in R1 and ‘long’ relators in R2; 
4 Replace all elements of R1 by their cyclic reductions; 
5 Compute the set 
 of all cyclic conjugates of all elements of R1; 
6 for x∈A 
7 
do compute set 
 of elements of 
 having first letter x; 
8 S:= ; 
9 DESCENDANTSUBGROUPS(~ S, C, {
}, R2, N); 
10 return S; 
The next procedure, DESCENDANTSUBGROUPS, takes a complete or 
incomplete coset table C with nC≤N as input. It first checks whether C is 
complete; that is, whether αx is defined for all α∈ΩC and x∈A. 
If C is complete then, as will be explained in detail later, we shall know 
already that α scans correctly under all w∈R1 and also that, if C is a coset 
table for G, then the corresponding subgroup G1 is a canonical 
representative of its conjugacy class of subgroups. So it only remains to 
test whether all α∈ΩC scan correctly under all w∈R2. If so, then we adjoin C 
to the list S. If not, then we discard C and return. 
To check whether α scans correctly under w, we have used a procedure 
SCANCHECK, which we have not displayed, since it is a straightforward 
modification of SCAN. SCANCHECK returns false (rather than calling 
COINCIDENCE) if the scan completes incorrectly; otherwise it returns 
true. 
If C is incomplete, then we locate the first undefined entry 
. We then 
need to try all possible values for 
. These will consist of all ß∈ΩC such that 
 is undefined, and also a new coset nC+1 provided that nC is not equal to 
N. We pass the problem of trying out each individual possibility for 
 over 
to the next procedure TRYDESCENDANT. 
The current coset table C, represents a node in the search tree, and its 
descendants are the coset tables resulting from assigning the various 
possible values to the first undefined entry 
. We do not want to alter C 
itself, so the procedure TRYDESCENDANT starts by making a copy D of C, 
and then assigning the new entries 
 and 
 in D. 
Furthermore, in the case ß=nC+1, we need to increment nD. 
We then want to check that these new entries are consistent with the 
requirement that all α∈ΩD scan correctly under all w∈R1, and to insert any 
new deductions into D that follow from that requirement. The procedure 
PROCESSDEDUCTIONS defined in Subsection 5.2.2 does exactly that, once 
we have put (α, x) onto the deduction stack. (We use the deduction stack only 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
192 
DESCENDANTSUBGROUPS(S, C, {
}, R2, N) 
1 
if C is complete 
2 
then (* Check whether relators in R2 are satisfied *) 
3 
for w ∈ R2, α∈ΩC do if not SCANCHECK(C, α, w) 
4 
then return; 
(* Relators in R2 are satisfied *) 
5 
APPEND(~S, C); 
6 
else Let 
 be the first undefined entry in C; 
7 
for ß∈ΩC ∪{nC+1} do if ß≤N and 
 is undefined 
8 
then TRYDESCENDANT (~S, C, {
}, R2, N, α, x, ß); 
at this stage, so all of the coset tables being manipulated can share the 
same deduction stack provided that it is emptied after use!) 
However, since we do not want to call COINCIDENCE, we use an 
(undisplayed) variation of PROCESSDEDUCTIONS, which we shall call 
PROCESSDEDUCTIONSCHECK. This calls SCANCHECK wherever 
PROCESSDEDUCTIONS calls SCAN. If SCANCHECK returns false, then 
it records that we have encountered an inconsistency, which means that 
this particular coset table D can be abandoned. Let us assume, just for the 
convenience of writing down the code for TRYDESCENDANT, that 
PROCESSDEDUCTIONSCHECK records the fact that SCANCHECK has 
returned false by setting nD to 0 and aborting. 
If no inconsistency is encountered, then we run a function 
FIRSTINCLASS, to be described later, which checks whether the subgroup 
H=G1 corresponding to D could possibly be the canonical representative of 
its conjugacy class. This test will be conclusive if D is complete. If 
FIRSTINCLASS returns false, then no descendant of D can have that 
property, and so we can abandon D. If it returns true, then we need to 
process further the node of the search tree corresponding to D, and so we 
call DESCENDANTSUBGROUPS recursively on D. 
TRYDESCENDANT(~S, C, {
}, R2, N, α, x, ß) 
1 
D:=C; 
2 
if ß=nD+1 then nD:=nD+1; 
3 
4 
Push (α, x) onto the deduction stack; 
5 
PROCESSDEDUCTIONSCHECK(D, {
}); 
6 
if nD=0 then return; 
7 
if FIRSTINCLASS(D) 
8 
then DESCENDANTSUBGROUPS(~S, D, {
}, R2, N); 
It remains to describe FIRSTINCLASS, which is the most complicated of 
our procedures. For a given n>0, let us order the set of all possibly 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
193 
incomplete coset tables C with ΩC=[1..n] and a fixed ordered generating set 
A lexicographically by their transition matrix. For this purpose, we will 
think of undefined entries 
 as being equal to 0. 
To be precise, if C1 and C2 are two such coset tables, then we define C1<C2 if, 
for some α∈[1..n] and some generator x∈A, we have 
 for all y ∈ A 
and 1≤ß<α and 
 for all y∈A with y<x, but 
. 
Then, from the discussion preceding Proposition 5.6, we see that a 
standardized complete coset table C for G is the least complete table under 
this ordering that corresponds to a particular subgroup H=G1 of G of index 
nc. It is natural to choose as canonical representative of a conjugacy class 
of subgroups the least complete coset table for G under this ordering that 
corresponds to a subgroup in that class. This representative will necessarily 
be standardized. 
For a possibly incomplete coset table C, we want to decide whether it is 
possible that a complete extension of C might be the required canonical 
representative, and we would like this test to be conclusive whenever C is 
complete. Now, if the complete standardized coset table C for G corresponds 
to the subgroup H=G1, then the conjugates of H are just the stabilizers Hα of 
the points α∈[1..nC]. 
So we proceed as follows. We call two coset tables with Ω=[1..n] equivalent 
if one can be obtained from the other by renumbering the points of Ω. For 
each 1α∈ [1..nC], we start by constructing the equivalent standardized 
coset table Cα corresponding to Hα. We stop if two corresponding entries  
and 
 of C and Cα are either unequal or are not both defined. 
If either of these two entries are undefined, then we cannot draw any 
conclusions, so we move onto the next α∈[1..nC]. We do the same if 
, 
since that indicates that C is definitely less than Cα. If 
 however, 
then Cα<C, so C is not the required canonical representative, and we can exit 
the function immediately and return false. 
The code below is taken directly from the function on page 208 of [Sim94]. 
For α∈ΩC, ν[α] is the point in 
 corresponding to α and, for 
, µ[α] 
is the point in ΩC corresponding to α. In other words, ν and µ are the 
mutually-inverse equivalence maps between ΩC and 
. At any time λ is 
the largest numbered point in 
 which is currently defined. 
Sims points out in [Sim94] that performance can be improved by 
remembering some of the information computed by FIRSTINCLASS. If 
the “continue α” statement is executed at line 14, then the same thing will 
happen for that value of α in any descendant of the table C, and so the 
values the values of α for which this occurs could profitably be stored and 
passed through to the descendants of C. Of course this would make the 
code more complicated. 
As is usual with backtrack searches, working through examples by hand 
is very tedious, but we shall nevertheless do this with a small example. 
FIRSTINCLASS(C) 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
194 
1 n:=nc; λ:=0; 
2 for α∈[1.. n] do ν[α]:=0; 
3 for α ∈ [2 ..n] 
4 
do (* Reset ν to 0 after previous value of α *) 
5 
for ß∈[1..λ] do ν[µ[ß]]:=0; 
(* Try α as the new point 1 in 
 *) 
6 
µ[1]:=α; ν[α]:= 1; λ:=1; 
(* Compare corresponding entries in C and Cα *) 
7 
for ß∈[1..n], x∈A 
8 
do If 
 or 
 is undefined then continue α; 
9 
10 
if ν[δ]=0 
11 
then (* δ becomes the next point in 
 *) 
12 
λ:=λ+1; ν[δ]:=λ; µ[λ]:=δ; 
13 
if ν[δ]<γ then return false; 
14 
if ν[δ]>γ then continue α; 
15 return true; 
Example 5.10 
Let 
 and N:=4. It is not hard to prove that G ≅ 
Sym(4)—indeed, the reader will presumably have already proved this while 
working through the exercises at the end of Section 5.2! But we shall not 
be making any use of that fact. 
Because of the relator x2, we take A:={x, y, y-1}, and we shall use the 
obvious ordering x<y<y-1 of A. The root of the search tree is the empty 
coset table C0 with a single coset. We shall denote the descendants of C0 by 
C1, C2,…, and then the descendants of C1 by C11, C12,…, and so on. The 
algorithm, as presented above, carries out a depth-first search through the 
search tree, which is sensible, because it minimizes the number of coset 
tables that need to be stored at any particular time. We shall do the same 
here. 
Let us put x2 and y3 into R1 and (xy)4 into R2. This means, of course, that 
we are really finding all subgroups of 
 up to index 4, and then 
just checking which of these map onto subgroups of G. 
In the first descendant C1, we set 1x=1, and then in C11 we set 1y=
, 
which yields the complete standardized coset table corresponding to G=H. 
(The same thing will happen initially for any group G.) So we have found 
our first subgroup. 
In C12, we set 1y=2, 
. If we set 
 then 1 does not scan 
correctly under y3, so in C121 we set 
, 3y=1, and then scanning 1 
under y3 yields the deduction 2y=3, 
. 
Now, in C1211 we put 2x=2 and in C12111 we put 3x=3. We now have a complete 
standardized coset table for which FIRSTINCLASS returns true, but then 
we find that 1 scans incorrectly under the relator (xy)4 ∈R2. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
195 
In C12112, we put 3x=4, 4x=3, and, since we now have nC=4, the only 
possibility in C121121 is to put 
. This gives us the following 
complete standardized coset table, for which FIRSTINCLASS returns true, 
and for which 1 scans correctly under the relator (xy)4∈R2, so we have 
found our second subgroup of G. 
Now we backtrack to C121 and put 2x=3, 3x=2 in C1212. This yields the 
following complete table, and our third subgroup of G. 
In C1213, we set 2x=4, 4x=2, and then in C12131 we are forced to put 3x=3, 
but then FIRSTINCLASS returns false when we substitute 1 for 3. In 
fact C1213 completes to a standardized table equivalent to but greater than 
C121121. 
At this stage, we backtrack all the way to C0 and set 1x=2, 2x=1 in C2. 
Then we put 
 in C21, and 
 in C211, yielding the 
following complete table, and our fourth subgroup of G. 
Next we put 2y=3, 
 in C212. Putting 
 leads to an incorrect 
scan, so we are forced to put 
, 4y=2 in C2121, which leads to the deduction 
3y=4, 
. If we put 3x=3 then FIRSTINCLASS returns false on replacing 
3 by 1, so we must put 3x=4, 4x=3, which gives the complete following complete 
standardized coset table C21211, for which FIRSTINCLASS returns true. But 
2 scans incorrectly under (xy)4, so this does not correspond to a subgroup 
of G. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
196 
Now we backtrack to C2 and put 1y=2, 
 in C22. To get a correct 
scan of 1 under y3, we must put 
, 3y=1 in C221, and deduce 2y=1, 
. As before, FIRSTINCLASS returns false if we put 3x=3, so we put 
3x=4, 4x=3 in C2211, and we are forced to put 
 in C22111, and now 
FIRSTINCLASS returns false when we replace 4 by 1. In fact, C22111 is 
equivalent to C21211, which did not correspond to a subgroup of G anyway! 
Backtracking again to C2, we put 1y=3, 
 in C23. In C231, we set 
, 2y=1, but then FIRSTINCLASS returns false when we replace 2 
by 1. Finally, in C232, we put 
, 4y=1, and deduce 3y=4, 
 and 
then we are forced to put 
 in C2321, but then FIRSTINCLASS 
returns false on replacing 2 by 1. 
This completes the search, and we have four conjugacy classes of 
subgroups of G up to index 4, one each of index 1, 2, 3 and 4.
5.4.3 Variations and improvements 
One commonly encountered variant of the basic low-index subgroups problem 
is to ask for all subgroups of index at most N that contain a given finitely 
generated subgroup 
 of G. It is straightforward to adapt the code in the 
preceding subsection to handle this variant. We have to pass the list Y of 
subgroup generators as an extra parameter to the procedures. In 
TRYDESCENDANT, immediately before the call of FIRSTINCLASS, we 
reject a coset table D for which no subgroup corresponding to a completion 
of D could possibly contain 
, by inserting the line: 
In FIRSTINCLASS, we only want to reject our current table in favour of 
a preceding table in the ordering in which 1 is replaced by α, if the subgroup 
Gα corresponding to this preceding table definitely contains the given 
subgroup 
. We therefore insert the line 
immediately after line 4 of FIRSTINCLASS. No other modifications are 
required. 
A less frequently encountered variant is a request for subgroups that do 
not contain a particular element or elements. There seems to be no easy 
way of incorporating such conditions into the body of the search, so the 
only way to handle this seems to be to carry out such tests on the complete 
coset tables in DESCENDANTSUBGROUPS. 
The performance of LOWINDEXSUBGROUPS has been observed to be 
satisfactory for ‘straightforward’ group presentations where, by a 
presentation that is not straightforward, we mean one in which there are 
relatively short group relators that cannot be derived easily from the defining 
relators. 
© 2005 by Chapman & Hall/CRC Press

Coset Enumeration 
197 
For example, a nonobvious presentation of the trivial group, such as the 
well-known presentation of B.H.Neumann: 
is not straightforward in this sense. 
Our procedure does not perform optimally on such examples, because it 
is unable to make any use of these hidden group relators. In fact the older 
low-index subgroups algorithm, which uses standard coset enumeration, 
may perform better on such examples, particularly as N grows larger, 
because it might discover these hidden relators in the course of the coset 
enumeration. If the derivation of the hidden relators is not inordinately 
difficult, and can be accomplished by a short run of coset enumeration, 
then we can attempt to remedy this deficiency as follows. 
In TRYDESCENDANT, immediately after the run of PROCESSDEDUC- 
TIONS, we carry out a short run of normal coset enumeration of G over 
the trivial subgroup (or over the subgroup 
 discussed at the beginning 
of this sub-section). We start with the current table D. The code for this 
enumeration needs to be modified such that it aborts immediately if any 
two cosets in ΩD=[1..nD] ever become coincident, because we want to reject 
D if that happens. After this enumeration, all cosets other than those in 
the original ΩD are removed. The point of this is that the coset enumeration 
might have discovered new coset table entries within the original ΩD. 
To the author’s knowledge, there has been little if any experimentation 
with this approach to date, and so it is difficult to assess its usefulness. 
Presumably the effort devoted to the coset enumeration should be restricted 
by imposing a rather small limit f(N), perhaps f(N)=2N, on the maximum 
number of cosets allowed. 
There is certainly a danger that on straightforward examples it would 
simply waste time without achieving much! On the other hand, a coset 
table-based coset enumeration needs a maximum of about 160 cosets to 
prove that the example above is trivial, whereas a relator-based enumeration 
requires about 1600, so if the restrictions imposed on the coset enumeration 
were too harsh, then it would achieve nothing, even in this example. 
Exercise 
1. 
Four subgroups were found in Example 5.10. Find a set of Schreier 
generators for each of these subgroups, and then show that the 
subgroups are 〈x, y〉 (index 1), 
 (index 4), 
 (index 3), and 
 (index 2). 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
198 
5.5 Applications 
The low-index subgroups, Reidemeister-Schreier and Tietze transformations 
algorithms have found many applications to other areas of mathematics, 
particularly to topology. Some of these applications also involve computing 
abelian quotients, which we shall be discussing later, in Section 9.2, so we 
shall defer consideration of these particular applications until Subsection 
9.3.3. 
The low-index subgroups algorithm can be used in the enumeration of 
certain types of finite graphs, and we shall now give a brief description of 
this process. See the paper by Conder and Dobcsányi [CD05] for the general 
theory and an overview, or [CD02] for more details. 
The application is to the enumeration of undirected graphs that are 
arctransitive; that is, graphs for which the automorphism group is transitive 
on directed edges. Such graphs are necessary regular, which means that 
every vertex has the same valency. Regular graphs of valencies 1 or 2 are 
easily described (exercise), so the first interesting case is valency 3. It has 
been known for some time that the automorphism group of every finite 
arc-transitive trivalent graph is a factor group of one of a known list of 
seven finitely presented groups and that, conversely, any finite 
nondegenerate homomorphic image of one of these seven groups acts arc- 
transitively on a suitable arc-transitive trivalent graph. 
So the classification of these graphs is essentially equivalent to finding 
the low-index subgroups of these groups. For example, one of the groups is 
  
As is explained in the above papers, it turns out that the stabilizer of a 
point in the automorphism group of one of the associated graphs is the 
homomorphic image of the subgroup 
 of G3, which is of order 12 
and isomorphic to Sym(3)×C2. Conder and Dobcsányi found that the most 
effective approach to finding all arc-transitive trivalent graphs up to valency 
n was to search for low-index normal subgroups K of G3 up to index 12n. 
Then, for any such K with |G:K|=12|G:HK|, G/K arises as a group of 
automorphisms of such a graph with degree |G:HK|. To do this, they 
adapted the low-index subgroups procedure to enumerate only normal 
subgroups, and also saved time by implementing a parallel version of the 
program. They were thereby enabled to enumerate all such graphs having 
degree up to 768. 
Exercise 
1. Classify finite regular graphs that are regular with valency one or two. 
© 2005 by Chapman & Hall/CRC Press

199 
Chapter 6 
Presentations of Given Groups 
To progress further in our study of algorithms for finite groups and, in 
particular, for finite permutation groups, we need to be able to compute a 
presentation of a given finite group. We have already seen, in Subsection 
3.4.1, that a presentation of a group G is necessary, in general, for checking 
whether a map ϕ from a generating set X of G to another group H extends 
to a homomorphism G→H. An alternative method for doing this when G 
and H are both permutation groups was described in Subsection 4.5.3 but, 
even in that situation, it is more efficient to use a presentation of G on the 
generating set X if one is available. 
For permutation groups G of large degree, there are also dramatic 
improvements possible in the Schreier-Sims algorithm for computing a base 
and strong generating set (BSGS) of G, which involve a presentation for G. 
The idea is first to use RANDOMSCHREIER to compute a candidate BSGS, 
and then to compute and use a presentation of G to verify that it really is a 
BSGS for G. 
In the first section of this chapter, we shall describe algorithms for finding 
presentations of a finite group that is defined by means of a ‘concrete’ 
representation, such as a permutation or matrix group. The basic method 
works by adjoining new relators repeatedly to a candidate presentation, and 
applying coset enumeration to check whether we really do have a presentation 
of the group. In the following section, we explain how a closely related method, 
known as Todd-Coxeter Schreier-Sims, can be used to improve the basic 
Schreier-Sims algorithm. Then we discuss an alternative method for the 
same problem, the Sims Verify algorithm in which, under certain conditions, 
the relators in a suitable presentation can be calculated theoretically, without 
recourse to coset enumeration. 
6.1 Finding a presentation of a given group 
A method for finding a presentation of a finite group G given by its Cayley 
graph (or, equivalently, its regular permutation representation; see Definition 
2.13) was described by John Cannon in [Can72] and [Can73]. Since the regular 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
200 
permutation representation of G needs to be stored, this method is limited 
to groups of order up to about 107. 
For larger groups, Cannon described a two-step version of the algorithm. 
For the two-step version, we assume that a presentation 
 of a suitable 
subgroup H of 
 has already been calculated, and we assume also 
that words wy that express the elements of Y as words in (
)* are 
known. We aim to find a presentation 
 of G on the generating set 
. We will choose 
, where R2={y-1wy|y∈Y}, and R1 is a 
set of additional relators, which will suffice to prove, using coset enumeration, 
that the index of 
 in is 
 |G:H|. 
Since the presentation already contains a presentation of H on Y, we know 
that the subgroup 
 of 
 has order at most |H| and so, provided 
that the relators in R1 map onto relators of G, this will prove that 
really is a presentation of G. If we want to, then we can use the relators in R2 
to eliminate the generators in Y from the presentation, to give a presentation 
on the original generators X of G, although that might result in an increased 
total relator length. 
The method is most effective when |G| is approximately equal to |H|2, 
because then we are dividing the work involved in solving the overall problem 
equally between the two subtasks of finding the presentation of H, and then 
finding the presentation of G over the subgroup H. For groups that are even 
larger, we could derive the presentation of H using a multistep version. 
Here, we shall describe an algorithm that can be thought of as a mild 
generalization of Cannon’s two-step process. To simplify the description, we 
shall assume that the generating set Y of the subgroup H is already a subset 
of X. Then we do not need the relators in R2, because they would all be trivial. 
As we shall see later, this method is tailor-made for application to 
presentations of permutation groups on strong generating sets. 
So, let 
 be a finite group, let 
 with 0≤s≤r, 
let n:=|G:H|, and suppose that we are able to compute a complete coset 
table C on Ω:=[1.. n] corresponding to the action of G by right multiplication 
on the right cosets of H in G. For example, if G is a finite permutation group, 
then we could do this by the methods described in Subsection 4.6.7. We 
assume that we can solve the rewriting problem for H; that is, that we are 
able to write elements of H as words in the generators xi (1≤i≤s) of H and 
their inverses. 
Now we let 
 be a finitely presented group. The set R of 
defining relators will be increased during the algorithm, but the map ϕ with 
 for 1≤i≤r will always satisfy the hypothesis of Theorem 2.52 (that 
is, it will map all elements of R to the identity in G), and so it will always 
define an epimorphism, which we shall also denote byϕ, from  to G. Initially, 
R consists of a set of words in the generators 
 and their inverses 
only, with the property that the restriction of ϕ to the subgroup 
 of  is an isomorphism. 
The setup that we have described is the input to the algorithm and it is 
© 2005 by Chapman & Hall/CRC Press

Presentations of Given Groups 
201 
assumed that 
 is an isomorphism. Since, we never remove 
relators from R during the algorithm, we will always have |
|≤|H| and 
so, if we can show by coset enumeration that | :
|=n, then we will have 
shown that | |≤|G|. But since ϕ is an epimorphism, that will prove that 
ϕ is an isomorphism, and we will be done. This proves the correctness of 
the answer returned. 
We shall now describe the algorithm itself. It a good idea to start by applying 
the procedure STANDARDIZE from Subsection 5.2.3 to C. This means that 
entries corresponding to short words will be encountered first when we scan 
C in its natural order, which will tend to make the relators in the resulting 
presentation shorter. 
We then proceed to initialize a coset table  for a coset enumeration of 
over the subgroup 
, and we can immediately set 
 for the 
generators 
 of . 
Let X:={x1,…, xr} and A:=XX-1. Next we define a right transversal 
of H in G consisting of words (ß)∈A*, where (1)=ε and 1τ(ß)=ß 
in C for 1≤ß≤n. This is done in the same way as in the procedure 
DEFINESCHREIERGENERATORS in Section 5.3. The words (β) can 
either be stored explicitly as words, or else a Schreier vector for 1G can be 
computed, enabling the (ß) to be recomputed when required. Each time 
that we define a new transversal element (ß) as (α)x for some 1≤α<ß 
and x∈A, we make the corresponding definition 
 in . This ensures 
that the transversal elements 
 associated with  are mapped by ϕ to 
(ß) for 1≤ß≤n. 
Now we proceed to the main part of the algorithm. This consists of a loop, 
which is repeated until we exit with the required presentation. Assuming 
that r>s, we certainly do not have a presentation of G initially, because none 
of the relators in R involve any  for i>s. (Initially  is the free product of 
 with the free group on 
 so it is infinite.) So we start the 
main loop by adjoining a new relator. 
Whenever we need to adjoin a new relator to R, we proceed as follows. We 
scan the coset tables C and  together, in their standard order, first by 
elements of , and then by elements of A. We must, at some stage, encounter 
a difference where ßx in C is not equal to the corresponding 
 in  for some 
ß with 1≤ß≤n and x∈A, because otherwise  would be complete with n 
cosets, and we are assuming that it is not. 
The difference could be either because 
 is undefined, or because it is 
defined but equal to some >n. In either case, we now write the Schreier 
generator (or inverse) 
 of H as a word u over the generators xi 
(1≤i≤s) of H, and let 
 be the word over the  that is 
mapped to 
 by ϕ. This word w is adjoined to R as a new 
relator of . Since 
, we maintain our hypothesis that 
ϕ maps relators in R to the identity in G. 
Next, we start or resume a coset enumeration on the coset table , with a 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
202 
PRESENTATION(G, H, ~  M) 
Input: 
Group 
. 
Group 
, such that 
; 
Standardized coset table C for G acting on cosets of H in G; 
M∈ with M≥|G:H|; 
Output: 
 with R extended to make 
; 
Notation: Let n:=|G:H|; X:=[x1,…, xr]; 
ϕ: →G with 
1 
if r=s then return ; 
2 
Initialize coset table  of 
 in ; 
3 
In , set 
 for 1≤i≤s; 
4 
Define coset representatives 
 for H in G, and make 
corresponding definitions in ; 
5 
while true 
6 
do Find smallest ß∈[1..n] and first x∈A such that the entries 
ßx in C and 
 in  are different; 
7 
Write 
 as word u over 
 (1≤i≤s); 
8 
Adjoin 
 to R; 
9 
Start or resume coset enumeration on  with maximum 
number of cosets set to M; 
10 
if  is complete with 
11 
then return 
; 
prescribed upper limit of M>n on the number of cosets that can be defined. 
This enumeration should be designed such that the first thing that it does is 
to scan the new relator w under the coset 1. Under the forward scan, 1 will 
be mapped to ß under 
 and under the backwards scan, 1 will be mapped 
to 1 under the word û over the 
 for 1≤i≤s that maps onto u, and then 1 
will be mapped to ßx under 
. So, in the complete scan, either 
 was 
undefined initially, in which case we get the deduction 
, or 
 was 
defined and equal to some >n, in which case we will get a coincidence 
somewhere in the scan. After processing this and any resulting coincidences, 
1 will scan consistently under w, and so we will again have 
. 
If the coset enumeration terminates with a complete coset table with exactly 
n cosets, then we will have shown that | :
|=n, and so, by the remarks 
above, we will have found the required presentation of G, and we can halt. 
Otherwise, if the enumeration either stops because it can go no further with 
the prescribed limit of M cosets, or if it completes but with more than n 
cosets, then we go back to the beginning of the main loop at line 5 of the 
algorithm, and adjoin another new relator. 
© 2005 by Chapman & Hall/CRC Press

Presentations of Given Groups 
203 
In either case, when the coset enumeration process stops, the entries in 
C and  that were different beforehand, and used to define the new relator, 
will be equal. So, eventually, all entries in  for 1≤ß≤n will be the same as 
those in C, and at that stage we will have a complete coset table with n 
cosets. So the algorithm must terminate, and we have an upper bound of 
n(r-1)+1-s, which is half of the number of entries of  that were undefined 
immediately before adjoining the first new relator, on the number of new 
relators that are adjoined to R. 
The displayed procedure PRESENTATION is a summary of the complete 
algorithm. 
Cannon’s original version took M=n, so no extra definitions were allowed 
in the coset enumeration. In that case, it is important to use a coset table 
style enumeration, where all consequences of all deductions are made before 
giving up. An advantage of doing that is that the same storage space can be 
used for both coset tables C and , because an entry in  is either the same 
as the corresponding entry in C or is undefined, so the defined entries in 
can be specified by using a negative integer rather than a positive, for example. 
Example 6.1 
Let G be the quaternion group Q8 of order 8, generated by the permutations 
a:=(1, 2, 6, 3)(4, 8, 5, 7) and b:=(1, 4, 6, 5)(2, 7, 3, 8) of degree 8, and H=1. We 
have carefully numbered the points such that the associated coset table C 
below is already in standard form. 
To limit the proliferation of hats, we shall use x and y rather than â and 
 as our generators of the finitely presented group  in this example. We 
define the coset representatives (ß) for ß∈[1..8] to be 
 respectively, while making the corresponding 
definitions 1x=2, 
, 1y=4, 
, 2a=6, 2b=7, 
 in . 
The first undefined entry in  is 
, and since since 
 in C, we 
adjoin the relator corresponding to 
 which is 
 (or, 
equivalently, x4) to R. 
Coset enumeration yields only the forced deduction 
, so we move 
on to the next undefined entry 3y, and find 
, so we 
adjoin 
 to R. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
204 
This time, coset enumeration results in deductions 3y=8, 4y=6 (from 
scanning 2 under 
), 6y=5 (from scanning 3 under 
), and 
7y=3 (from scanning 6 under 
). The next undefined entry is 4x, with 
, so we adjoin 
 to R. 
Now coset enumeration finds all remaining deductions (check!), and so the 
process halts, and we have proved that 
. 
In fact, the first relator is redundant, and 
. 
It is possible to derive a two-generator presentation of this group by using a 
different ordering of the generators from the one that we have used here; see 
the exercise below. It is a general feature of this algorithm that the earlier 
relators produced often turn out to be redundant. This happens more frequently 
with larger groups, and one is sometimes forced to wait a frustratingly long 
time before a single crucial relator is found by the program. 
Although current implementations do not do this by default, if it is 
important to produce presentations that are as short as possible, then it 
would be a good idea to try repeating the coset enumerations with some of the 
earlier relators omitted, to see whether they are redundant. Of course, the 
user needs to balance the time taken in doing this against the advantage to 
be gained from a shorter presentation. 
If a relator-based method is to be used for the coset enumeration, then it is 
necessary to have M rather larger than n. This approach was studied 
extensively by J.S.Leon, who used it in his implementation of the Todd- 
Coxeter-Schrier-Sims algorithm, which we shall be studying in the next 
section. He reports in [Leo80b, Leo80a] that M=1.2n+50 seems to work well 
for examples with n of order 104. He also found that it is important to choose 
the correct policy when using the LOOKAHEAD algorithm, which differs 
from the policy that one would generally adopt in a standard coset enumeration. 
Given the not totally satisfactory behaviour of current versions of the 
algorithm, which tend to produce many redundant relators with larger groups, 
there would seem to be room for further research in this area. 
Exercises 
1. 
We have Sym(5)= 
, with a1=(1, 2), a2=(2, 3), a3=(3, 4), a4=(4, 
5). Use the algorithm above to compute presentations, in turn, of the 
subgroups 
 of Sym(5), using the 
preceding subgroup as the group H in the algorithm each time. 
2. 
Repeat the calculation of a presentation of Q8, but this time use the order 
of generators 
, for which the standardized coset table 
comes from a:=(1, 2, 6, 4)(3, 8, 5, 7), b:=(1, 3, 6, 5)(2, 7, 4, 8). You should 
get a presentation with just two relators. 
© 2005 by Chapman & Hall/CRC Press

Presentations of Given Groups 
205 
6.2 Finding a presentation on a set of strong 
generators 
In this section, we let G be a permutation group on [1.. n], and let (B, S) be 
either a known BSGS or a candidate for a BSGS of G. We shall show that the 
algorithm described in the previous section can be applied to compute what 
we shall call a strong presentation of G. 
We shall use the notation that we introduced in Section 4.4. In particular, 
, and 
 for 
1≤i≤k+1, where (B, S) is a BSGS for G if and only if G(k+1)=1 and G
(i)=H(i) for 
1≤i≤k. 
DEFINITION 6.1 If (B, S) is a BSGS for G, then a presentation 
of G on S is said to be a strong presentation if, for each i with 1≤i≤k, 
 is a presentation of G(i), where R(i) is defined to be the subset 
of R consisting of those relators in R that involve only generators in S(i) 
and their inverses. 
6.2.1 The known BSGS case 
Suppose first that (B, S) is known to be a BSGS of G. So G(k+1)=1 and 
, where 
 for 1≤i≤k. By Proposition 2.23, 
 is equivalent to the action of G(i) by right multiplication on the 
cosets of G(i+1) in G(i). So we can use 
 to write down the coset table 
of this action, and then we just need to apply the algorithm 
PRESENTATION described in the previous section k times, working up 
the series of basic stabilizers. 
First we run PRESENTATION on G(k) with generators S(k) and trivial 
subgroup. On subsequent runs, we compute a presentation 
 of 
G(i) on generators S(i), using the subgroup G(i+1) on generators S(i+1), with 
R(i) initialized to the relators R(i+1) of G(i+1) computed in the previous run. 
The function PRESENTATION assumes that we can write elements of the 
subgroup as words over the generators of the subgroup, but the STRIP 
algorithm, which is part of the basic BSGS machinery, enables us to do 
precisely that. Notice that our coset representatives 
 of G(i+1) in G(i) are 
the same as the elements 
 defined in Section 4.4. 
Example 6.2 
Let G:=Alt(5) with B:=[1, 2, 3] and S:=[a, b, c], where a:=(1, 2, 3), b:=(2, 3, 
4), c:=(3, 4, 5). In the corresponding finitely presented groups, we shall let 
x, y, z be generators that map onto a, b, c, respectively. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
206 
First, we compute a presentation of G(3) on S(3)=[c]. The coset table 
comes from the action of G(3) on ∆(3)=[3, 4, 5]. To apply PRESENTATION 
in an implementation, we would compute this coset table with the points 
of ∆(3) renumbered as [1, 2, 3], but it makes it clearer while working 
through the example, if we break our normal convention and allow the 
domain of the coset tables C and  to be [3, 4, 5]. Our definitions are 3z=4 
and 
, our first relator is z3, coming from the blank entry 4z in 
and, with that single relator, the coset enumeration completes, so (not 
surprisingly!) we get the presentation 
 of G(3) with 
R(3)={z3}. 
Next we move on to G(2) on S(2)=[b, c], with subgroup G(3) and coset table 
coming from the action of G(2) on ∆(2)=[2, 3, 4, 5]. Our relator set R(2) is 
initialized to R(3). The coset representatives are (2)=ε, (3)=b, 
, with corresponding definitions 2y=3, 
, 
, and we have 
 initially. The first blank entry in  is 
3y, which yields the new relator y3 and deduction 3y=4. The first blank entry 
is now 3z. The corresponding Schreier generator 
. 
We can write this as a word in the generators S(3) of G(3) using STRIP, and 
, so the new relator is the word mapping onto bcbc, which is yzyz. 
The coset enumeration now completes, so we have the presentation 
 of G(2) with 
. 
Finally we want a presentation of G(1) on S(1)=[a, b, c], with subgroup G(2) 
and coset table coming from the action of G(1) on 
. Our 
relator set R(1) is initialized to R(2). The coset representatives are (1)=ε, 
 with corresponding 
definitions 1x=2, 
, 
, 
 and we have 1y=1z=1 initially. 
The first blank entry in  is 2x, which yields the new relator x3 and deduction 
2x=3. The first blank entry is now 2y. The corresponding Schreier generator 
, which rewrites, using STRIP to 
, 
yielding the new relator xyxy. This results in deductions 2y=3, 3y=4 and 
4x=4. Now the first blank entry is 2c, with corresponding Schreier generator 
, which rewrites with STRIP to cb-1, so we 
adjoin the new relator 
. The coset enumeration now completes, so 
we have the final presentation 
 of G=G(1) with 
.
This method is generally effective and, when combined with the BSGS 
facilities already described, it enables us to check whether a map ϕ from a 
permutation group G to a group H defined on the initial generators of G 
extends to a homomorphism. First we compute a BSGS for G, and use the 
resulting SLPs as described in Section 4.5 to compute the images of the 
putative extension of ϕ on the strong generators S of G. We can then check 
whether ϕ satisfies the relators of a strong presentation computed as above. 
It suffers from the general problem of PRESENTATION mentioned 
earlier, that the relators that are found early on often turn out to be 
redundant, although this does not happen in the example above. The relator 
© 2005 by Chapman & Hall/CRC Press

Presentations of Given Groups 
207 
y3 is actually redundant in the presentation 
 of G but, if we 
removed y3 from R, then we would no longer have a strong presentation, 
because 
 would not be a presentation of G(2). If we leave out 
either (but not both!) of (xy)2 or (yz)2, then we are left with a presentation of 
the group Alt(5)×C3 of order 180. 
6.2.2 The Todd-Coxeter-Schreier-Sims algorithm 
Suppose now that (B, S) is a suspected rather than a known BSGS of the 
permutation group G on . So we are not certain that G(k+1)=1 or that H(i)=G(i) 
for all i with 1≤i≤k+1. In this case, by using essentially the same approach 
as the one described in the previous subsection, we can simultaneously 
calculate a strong presentation of G and check that (B, S) really is a BSGS of 
G. This procedure is known as the Todd-Coxeter-SchreierSims (TCSS) 
algorithm, because it combines coset enumeration with the basic Schreier- 
Sims method. Implementations by Leon using relator-based coset 
enumeration are described in detail in [Leo80b] and [Leo80a]. The current 
MAGMA implementation uses coset table-based coset enumeration, however. 
If it turns out that, if (B, S) is not a BSGS then, as in SCHREIERSIMS, 
a new strong generator and possibly a new base point, will be found, and so 
we can update (B, S) and restart. However, this method runs much more 
effectively when (B, S) really is a BSGS, so the best policy is to run 
RANDOMSCHREIER first to calculate a probable BSGS rather than trying 
to run TCSS on the initial generating set. 
We adopt exactly the same method as in the previous subsection, and 
apply PRESENTATION to H(i) with the subgroup H(i+1) for i=k, k–1,…. 
However, when we need to add a new relator w to R(i), we check that the 
image ϕ(w) of w in H(i) is equal to the identity in H(i). This was true by 
hypothesis in Subsection 6.2.1, but that is no longer the case. In fact, if the 
new relator arises from the entry 
 in , then we apply STRIP to the element 
 of H(i) in an attempt to write this element as a word in the 
generators of H(i+1). 
We are doing exactly the same thing here as we did in line 13 of 
SCHREIERSIMS; the coset representative (ß) is the same as the uß there. 
Just as in SCHREIERSIMS, if STRIP returns h, j with j≤k, then h needs to 
be added as a new strong generator to S(j), whereas if j=k+1 and h1, then 
we need to add a new base point to B as well as adding h to S. If B is already 
known to be a base of G, perhaps because G is a subgroup of a larger subgroup 
of Sym() with base B, then we can omit the check that h=1, thereby 
producing a faster version in the known-base case. 
Eventually, it will happen that ϕ(w) evaluates to the identity for all new 
relators w that we adjoin to R(i), and the coset enumeration will complete 
with 
. Since 
, this proves that 
 and, if this is true for 1≤i≤k, then we have proved, by Lemma 
4.5, that (B, S) is a BSGS for G. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
208 
The TCSS algorithm carries out the same tests as in line 13 of 
SCHREIERSIMS, but for far fewer pairs (uß, x). In the example in the 
previous subsection, we would carry out this test using STRIP once for 
each new relator used; that is, 6 times altogether. If we apply 
SCHREIERSIMS to this example, then 18 such checks will be made, 
corresponding to the total numbers of Schreier generators that are not 
trivial by definition; that is, 2 checks for i=3, 5 checks for i=2, and 11 
checks for i=1. Of course, extra time is taken by the coset enumeration. For 
permutation degrees of degree less than about 100, the overhead resulting 
from the coset enumeration often makes it faster to use SCHREIERSIMS 
than TCSS but, for examples with larger degrees, TCSS is typically 
significantly faster. 
6.3 The Sims ‘Verify’ algorithm 
The algorithm VERIFY to be described in this section is an alternative 
to the use of PRESENTATION for calculating a strong presentation of a 
finite permutation group. As was the case in Section 6.2, we can use this 
method both in the situation when (B, S) is already known to be a BSGS 
of G, and when it is only suspected of being a BSGS. In the latter case, 
just as with the Todd-Coxeter-Schreier-Sims (TCSS) algorithm, it can be 
used to verify that (B, S) really is a BSGS. (This is the reason for the 
name VERIFY.) 
Rather than use coset enumeration to find the presentation, we use the 
orbit structure of the subgroups H(i) to write down a presentation of H(i) on 
the generators S(i), on the assumption that such a presentation is already 
known for H(i+1) on S(i+1). As in TCSS, if we need to verify that (B, S) is a 
BSGS, then we need to check that the images in H(i) of the relators of the 
presentation are all equal to the identity. If this check fails, then (B, S) is 
not a BSGS, and we have a new strong generator in H(i+1). We then need to 
interrupt the algorithm and resume the computation of a BSGS, which (as 
in TSCC) is inefficient, so it is preferable only to apply VERIFY when we are 
reasonably sure that (B, S) is a BSGS. 
VERIFY formed the basis of the methods used by Sims to prove the 
existence of the finite simple groups Ly and BM (see [Sim73] and [Sim80].) 
It is interesting to note that the calculation of the order of the Lyons 
group now can be done in a few hours in MAGMA, by a call of a standard 
function. 
As with TCSS, we apply VERIFY to each H(i) separately, in reverse 
order, starting with i=k. In fact, provided that we process the i in this 
order, we can use TCSS for some values of i and VERIFY for others (see 
Example 6.4 below). 
Since we shall be concerned with a fixed i in our description of VERIFY, 
© 2005 by Chapman & Hall/CRC Press

Presentations of Given Groups 
209 
we set H:=H(i), K:=H(i+1), α:=ßi and ∆:=∆(i)=αH. In addition, let X:=S(i), 
Y:=S(i+1), 
, and 
. As in PRESENTATION 
and TCSS, we let 
 be a finitely presented group with generators Xˆ and a 
bijection 
 inducing an epimorphism, ϕ:
→H, and we suppose 
that we already have a presentation of K; that is, we have a set R of words 
in such that ϕ induces an isomorphism 
. 
Our objective is to decide whether Hα=K. If so, then we want to extend the 
set R to make 
 a presentation of G. If not, then we want to output an 
element of Hα\K, so that we can extend our strong generating sequence of G 
and restart the BSGS verification. 
6.3.1 The single-generator case 
We shall first discuss the case in which X\Y consists of a single generator 
z, so 
, and deal with the general case later. Let 
. (It will 
become clear in the proof of Theorem 6.2 why we use z-1 rather than z.) 
We start by calculating ßK. We then know the order |K|/|ßK| of Kß, so 
we can find generators for Kß quickly by using RANDOMSTAB, and we 
choose orbit representatives [1,…,m] of Kß on =H. These representatives 
include  and ß, which we assume to be 1 and 2, respectively. The number 
m of orbits of Kß on  is critical for the performance of the algorithm, with 
larger values of m corresponding to slower running times. 
We also need orbit representatives of K on . We choose ß0:= and ß1:=ß to 
be the first two of these. Then, in general, if, for some i≥1, orbit 
representatives ßj have been chosen for 0≤j≤i and 
, we choose 
ßi+1 to be z for some 
 with j≤i. Let the complete set of orbit 
representatives of K on ∆ be [ß0, ß1,…,ßl]. 
As was the case with the function PRESENTATION, we choose a 
transversal {()|∈} of H in H, where each () is stored, either explicitly 
or via a Schreier vector, as a word in A*, and ()=. This transversal is 
chosen slightly differently from the method used in ORBITSTABILIZER. 
As usual, we start with ():=ε, and we put (ß):=z-1. After defining (ßi) 
for any i with 1≤i≤l, we apply the generators in Y to ßi, so that all () with 
 have the form (ßi)w, with w∈B*. For 1≤i<l, we define (ßi+1):=()z, 
where  was used, as described above, to define ßi+1=z. In practice, we would 
define the coset representatives () and the orbit representatives ßi 
together, rather than in separate stages as we have described it. 
Now we are ready to write down the relations in our presentation of H. 
Our final relator set R will be a union of three sets R1, R2, R3, where R1 is the 
initial set of relators of K, and R2 and R3 are two sets of relators that we 
append to R during the algorithm. 
First we describe R2. For each ßi with 1≤i≤l, we compute generators 
y1,…, yt of Kßi. In fact we have already done this for ß=ß1 and, as was the 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
210 
VERIFY(H, K, ~
, z, a) 
Input: 
Groups 
 with H∆ transitive, 
Group 
, with 
, 
a∈ with K≤H and z∉H. 
Output: true if K=H, otherwise false 
If true, then 
with R extended to make 
. 
If false, then an element of Hα\K. 
Notation: Let X:=[x1,…,xs, z]; 
; 
Y:=[x1,…,xs]; 
; 
ϕ:
→H with 
. 
1 
; 
2 
Choose orbit representatives =ß0, ß=ß1, ß2,…,ßl of K on ∆, and 
orbit representatives 1,…,m of Kß on ∆ such that, for 1≤i<l, 
we have 
 for some 
 with 1≤j≤i; 
(* Now choose coset reps. () (∈∆) of H in H as words in A* *) 
3 
():=ε; (ß)=z-1; 
4 
for i∈[1..l] 
5 
do for 
, choose ():=(ßi)w, for some w∈B*; 
6 
if i<l then choose (ßi+1):=(k)z for the appropriate 
 with 0≤j≤i; 
7 
for i∈[1..l] 
8 
do Find generators y1,…,yt of Kßi; 
9 
for j∈[1..t] 
10 
do if 
11 
then return false, 
; 
12 
Write 
 as word u in generators of K; 
13 
APPEND 
; 
14 for i∈[1..m] 
15 
do if 
16 
then return false, 
; 
17 
Write 
 as word u in generators of K; 
18 
APPEND 
; 
19 return true, 
; 
case there, the fact that |K| and 
 are known allows us to do this easily 
by using RANDOMSTAB. In order to compute inverse images of the yi in 
under ϕ, we need the yi as words in B*, but that presents no problem, because 
we are assuming that Y is a strong generating set for K. 
Now, for each such 
 fixes α. We test this element for 
membership of K and, if it is not in K, then we return false together with 
the offending element. If it is in K, then we can write it as a word u∈B*, so 
 evaluates to 1H and we adjoin its inverse image 
 to R2. 
© 2005 by Chapman & Hall/CRC Press

Presentations of Given Groups 
211 
Now we describe R3. For each γk with 1≤k≤m, the Schreier generator 
 fixes . Once again, we test this element for membership of 
K and, if it is not in K, then we return false together with the element. If it 
is in K, then we can write it as a word u∈B*, so 
 evaluates 
to 1H and we put its inverse image 
 into R3. 
(Technical note: We gain a small increase in the efficiency of the algorithm 
if we choose our orbit representatives ßi of K on Γ for i>1 as 
 for some γk. We 
leave it as an exercise for the reader to prove that this is possible. If we do 
that, then we have 
, and the associated Schreier generator 
 is trivial by definition, and does not need to be tested for 
membership of K.) 
The displayed function VERIFY is a summary of the algorithm. Let us 
prove its correctness. 
THEOREM 6.2 With the notation and assumptions of this subsection, if 
VERIFY returns true; then H=K and 
 is an 
isomorphism. 
PROOF From the definitions of R2 and R3 we have ϕ(w)=1H for all w∈R2R3, 
and this is true by assumption for w∈R1, so ϕ:
→H is certainly an 
epimorphism. 
Let n:=|∆| and let  be the subgroup of  generated by . If we can prove 
that 
 then, since ϕ(Κ)=Κ, we will have |H:K|≤n. But K≤H by 
assumption, and |H:H|=n by the orbit-stabilizer theorem, so we will then 
have H=K with |H:K|=n. Since 
 by assumption, 
 will 
also imply |
|≤|H| and so ϕ will then be an isomorphism with |
|=|H|. 
So it suffices to prove that 
. 
For ∈∆, let 
 be the inverse image in 
 under ϕ of (); that is, 
is the word in Â* corresponding to the word in A* for (). Let 
0 be the 
union of the n cosets 
 of 
 in 
. It is enough to prove that 
0=
 and, to do that, it is obviously enough to prove that uw∈
0 for all 
u∈
0 and w∈
. By induction on |w|, it suffices to do this for w∈Â. But if 
this is true for some w∈
 then, since there are only finitely many cosets 
in 
0, the action on 
0 by right multiplication by w must permute these 
cosets, and so the same will be true for w-1. Hence it suffices to show that 
uw∈
0 for all u∈
0 and 
. 
First suppose that  is in the set 
 of generators of 
. From the way 
that we defined the elements () as (ßi)v for a word v∈B* with 
, we 
have 
 with u0, 
 and 
=v. Since 
, we have 
 for some 
 with 
. Hence vx=H v0v1, with 
v0∈Kßi. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
212 
We are assuming that our relators of 
 contain defining relators for K, 
and so we have the the corresponding equality 
, 
where
  and 
. 
Now v0∈Kßi can be written as a word in the generators y1,…,yt of Kßi and 
their inverses that we computed in the algorithm. It follows once again from 
the assumption that  contains defining relators for K, that  is equal in 
to the corresponding word in the elements  and their inverses with ϕ(
)=yj. 
But for each such 
, there is a relator in R2 of the form 
with 
, and so 
 and 
. We can 
use these relations to write 
 in 
 as 
 with 
, and we 
have now expressed 
as claimed. 
The other case is when 
. As in the previous case, let 
with v∈B*. Let k be the orbit representative of 
, and let y1,…,yt be the 
generators of Kß=Kß1 that we used in the definition of R2. Then 
 for 
some word v0 in the generators y1,…,yt and their inverses. Since 
, we 
have 
 with v1∈B* and v1v0=K v. We can once again use our 
assumption that 
 contains defining relators for K to infer that 
, where vˆ0 is a word over 
1,…,
t with 
. 
Since (ß) was chosen to be z-1, there are relations in R2 of the form 
 for each such 
j, and so we can use these to write 
with 
. Then we can use a relator in R3 to write 
for some 
 and ∈∆ and so, putting all of this together, we have 
 with u0, 
. It follows now from the previous 
case, 
, that this element lies in 
0. This completes the proof.
Example 6.3 
Let H≤Sym(10) be generated by the permutations 
a:=(3, 4) (5, 8) (6, 7) (9, 10), 
b:=(2, 5, 8) (3, 7, 9) (4, 10, 6), 
c:=(1, 2) (3, 4) (5, 6) (7, 8), 
  
let Κ:= 〈a, b〉, and let :=1. Then :=[1..10]. The generator c corresponds to z 
in the algorithm but, at the risk of causing confusion, we shall use x, y, and 
z as generators of our finitely presented group mapping on to a, b, and c, 
respectively. In fact H  Alt (5). 
We see easily that K is dihedral of order 6, so we take our initial set of 
relators, which is used as input for VERIFY and is assumed to be a set of 
defining relators for K, as R3:={x2, y3, (xy)2}. Now we let 
. Then 
Kß has the single generator a, and we can choose 1, 2, 3, 5, 6, 9 as our orbit 
representatives k of Kß. We have 
, we choose ß2:=5c= 6, and 
find that 
, so , ß1, ß2 are orbit representatives 
of K on ∆. Following the method described above, we choose 
© 2005 by Chapman & Hall/CRC Press

Presentations of Given Groups 
213 
  
Since Kβ1 has a single generator a and Kβ2=01, we get only one relator in 
R2. To calculate this, first we check whether 
 and find that this 
is true, with 
 so we put 
into R2. 
The relators in R3 correspond to the k. From k=1, we get z2∈R3, whereas 
the Schreier generators coming from k=2 and 5 are trivial by definition. 
When 2=6, we get the relator 
. If we use the fact that z2 is already 
a relator, then this becomes trivial; in fact, in general, when the generator z 
has order 2, the relators coming from k=ßi for i>1 will collapse in this way, 
and this feature could be used in an implementation. For k=9 and 3 we get 
nontrivial new relators. In the first case, 9c=9, so the Schreier generator is 
  
so we append 
 to R3. Similarly, for k=3 we append 
 to R3, yielding the complete presentation 
 
Surprisingly, neither of the two long relators is redundant (omitting 
either of them results in a group of order 120), but z2 and 
 are 
both redundant, and both can be removed from the presentation. TCSS 
produces a presentation with the same number of relators, but with the 
final two relators slightly shorter.
6.3.2 The general case 
In the general case, we have Y=[x1,…,xt], X=[x1,…,xr] with r-t>1. The 
algorithm in this case reduces to t-r applications of the single-generator case 
and, for the most part, we shall just describe how this is done, without going 
into technical details. There is one step in the algorithm, however, in which 
we need to test whether a subset of  is a block, and this will require more 
detailed explanation. 
For t≤s≤r, define 
; in particular, K(t)=K and K(r)=H. 
For s:= t, t+1,…, r–1 in turn, we test whether K(s+1)=K. If so, then we also 
extend our set of defining relators R(s) of K(s) on [x1,…,xs] to a set of defining 
relators R(s+1) of K(s+1) on [x1,…,xs+1]. We are assuming here that the set 
R(t) is given. 
If the test fails for some s, then we output an element of K(s+1)\K, 
which must be appended to the strong generating set of G. Whenever this 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
214 
happens, we abort and restart the complete verification procedure on G, so 
it is important only to apply this procedure only when we are confident 
that our candidate BSGS really is a BSGS for G. 
Let 
  for t≤s≤r; so (t)={} and (r)=. Suppose, for some 
s≥t, that we have successfully checked that K(j)=K and calculated the 
relators R(j) for all j with t≤j≤s. This assumption is valid for s=t, because 
. Let L:=K(s). We shall now describe how to carry out the 
test that 
. 
Suppose first that 
. Let 
. Then there exists 
(ß)∈L with 
, and hence 
. We test 
 for membership of K by using STRIP in the usual way. If this 
test fails, then the word output by STRIP is an element of 
to be appended to the SGS of G. If it succeeds, then we have proved that 
K(s+1)=L, and hence that K(s+1)=K. We can then write 
 as a 
word u in the generators of K, and we adjoin the corresponding relator 
 to R(s+1). Since this relator expresses 
 in terms 
of the lower-numbered generators, it provides us with the required 
presentation of 
. 
So we can suppose that ∆(s) is properly contained in ∆(s+1). If ∆(s)=[], 
which is certainly the case when s=t, then we just apply the single-generator 
case of VERIFY to the action of K(s+1) on ∆(s+1), and this yields the required 
result for K(s+1). 
Otherwise, 
 and La<L. So, if the condition 
 that 
we are trying to verify holds, then 
 and, by Proposition 2.30, 
L=∆(s) is a block for the action of K(s+1) on ∆(s+1). 
The verification proceeds in two stages. In the first stage, we check 
whether ∆(s) really is a block for K(s+1) on ∆(s+1). We shall describe the 
details of that check shortly. First, we shall describe the second and easier 
stage of the verification. 
So suppose that we have checked that ∆(s) is a block for K(s+1) on 
∆(s+1), and that we have calculated the induced action K(s+1)Σ of K(s+1) 
on the block system Σ containing ∆(s). Then, in this induced action, LΣ≤ 
 and we apply the single-generator case of VERIFY to K(s+1)Σ to 
test whether 
. If so then, since K(s+1) certainly fixes the 
block ∆(s) and we already know that Lα=K, we have 
, as 
required, and the relators R(s+1) computed by VERIFY will define a 
presentation of K(s+1). If not, then we will find a new element of the strong 
generating set of G. 
Note that, although we are applying VERIFY to an induced action on a 
block system Σ, at the places in the algorithm where we need to test an 
element for membership of L and, if possible, write it as a word in the 
generators of L, we carry out our computations in K(s+1) rather than in its 
induced action K(s+1)Σ. This can be done using standard homomorphism 
machinery, and presents no problem. These computations can be facilitated 
© 2005 by Chapman & Hall/CRC Press

Presentations of Given Groups 
215 
by replacing  by Σ, which enables the action on the block system to be 
handled in the same way as an action on an orbit, as is done in the algorithm 
displayed above for the one generator case. 
Now we turn to the problem of checking whether ∆(s) is a block for the 
action of K(s+1) on ∆(s+1). Of course, if we are in the situation where we 
know already that (B, S) is a BSGS for G, and we just want to compute a 
presentation, then we know already that ∆(s) is a block. So MINIMAL 
BLOCK can be used to compute the complete block system, and then the 
method described in Subsection 4.5.2 can be used to find the induced action. 
In fact MINIMAL BLOCK can also be used to test whether ∆(s) is a 
block; but if it should turn out not to be a block, then we need to calculate 
an element of K(s+1)\K, which MINIMAL BLOCK does not do as it stands. 
So we shall write a new function to accomplish this. 
Since ∆(s)=L, the blocks of Σ (if it exists) are all of the form Lw for 
elements w∈K(s+1). We proceed by constructing these blocks and calculating 
the induced action of the generators of K(s+1) on the block system at the 
same time. 
For each point  in each block, we define a word uγ over the generators of 
K(s+1) with 
 and, as usual, these words uγ can either be stored 
explicitly or by means of a Schreier vector. We choose these words uγ so that 
they satisfy the following property: the block containing γ is 
 and, if γ 
and  are points in the same block, then 
. 
We start by defining uγ as words over the generators of L for all γ in the 
first block ∆(s). At this stage, the property above is clearly satisfied by all uγ 
that have been defined so far. 
In the main body of the algorithm, we consider each block Γ that has been 
defined so far in turn; so we start with Γ=∆(s). Let ß be the first point in Γ. 
Then, for each generator xi of K(s+1), we check whether 
 is in a block 
that has been defined already. If not, then  becomes the first point in a new 
block, and we put 
. In any case, we then apply xi to all other points 
γ∈Γ. 
If we defined a new block, and none of these 
 are in an existing block, 
then they become the other points in the new block, and we define 
for each such 
 We may assume inductively that the property defined 
above for the words uγ is satisfied for points γ in the existing blocks, and so 
we know that the block Γ containing ß is 
, and that Luγ=Luß for all γ∈Γ. 
So the property is also satisfied by the words u in the new block. 
If we did not define a new block containing 
 then the points 
 should 
all be in the same existing block as 
. 
There are two ways in which it could emerge that ∆(s) is not a block. Let 
ß be the first point and γ some other point in the block Γ to which we are 
applying the generator xi. We might define a new block containing 
 but 
then find that 
 is in an existing block. Alternatively, we might find that 
 is in an existing block, but that 
 is either in no existing block or is in a 
different existing block. If neither of these eventualities occurs at any stage, 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
216 
BLOCKVERIFY(H, L, ) 
Input: L=〈x1, …, xs 〉 <H=〈x1, …, xr 〉≤ Sym(), ∈ 
Output: true if L is a block of 
, false if not. 
If true, then induced actions  of xi on blocks. 
If false, then an element of H\L. 
1 
∆:=H; 
2 
for ß∈∆ do p[ß]:=0; 
3 
B[1]:=ORBIT(, [x1, …, xs]); 
4 
for ß∈B[1] do p[ß]:=1; 
5 
for ß∈B[1] do define uß∈L with uß=ß; 
6 
ρ:=1; m:=1; 
7 
while ≤m 
8 
do ß:=B[][1]; 
9 
for i∈[1..r] 
10 
do δ:=ßxi; σ:=p[δ]; 
11 
if σ=0 
12 
then (* New block *) 
13 
m:=m+1; σ:=m; uδ:=ußxi; 
14 
p[δ]:=σ; B[σ]:=[δ]; 
15 
for j∈[2..|B[ρ]|] 
16 
do γ:=B[ρ][j]; δ:=γxi; 
17 
if p[δ]=0 
18 
then uδ:=uxi; p[δ]:=σ; 
19 
APPEND(~B[σ], δ); 
20 
else return false, 
; 
21 
else (* Image in existing block *) 
22 
for j∈[2..|B[ρ]|] 
23 
do if p[B[ρ][j]xi]σ 
24 
then return false, 
; 
25 
; 
26 return true, 
; 
then we will successfully compute the complete block system Σ containing 
∆(s) together with the induced actions of the xi on Σ, which will verify that 
∆(s) is a block. 
In the two negative situations above, we need to compute an element of 
K(s+1)\K. Suppose first that ßxi is in a new block, but δ:=xi is in an existing 
block, where ß and  are in the same existing block Γ. Then 
∈K(s+1). By our assumed property of the words uγ, Luδ is the existing 
block that contains δ, so 
. Hence 
. By the 
assumed property again, we have Luß=Lu, so 
 and 
. 
Hence we can return 
 as our element in K(s+1)\K. 
By a similar, argument, in the second situation, where :=ßxi is in an 
existing block but some xi is not in that block, we can return 
. 
© 2005 by Chapman & Hall/CRC Press

Presentations of Given Groups 
217 
The algorithm is displayed as BLOCKVERIFY, which we apply with 
L:=K(s), H:=K(s+1) and r=s+1. In the code, the blocks being constructed 
are B[1], …,B[m], where m is the current number of blocks, p[ß] is the 
number of the block containing ß∈∆, and  is the number of the block to 
which we are currently applying the generators xi. 
6.3.3 Examples 
We shall now describe some statistical details of applications of VERIFY to 
two large permutation groups. In the first example, we also compare the 
performances of VERIFY and TCSS. 
Example 6.4 
Let G be the O’Nan sporadic simple group of order 460 815 505 920 as a 
permutation group of degree 122 760 on :=[1..122 760], let K=Gα with =1 
be the point stabilizer, and suppose that we are applying VERIFY to check 
that G really is equal to our current candidate subgroup K≤G. 
Then, assuming that K=G as suspected, K has five orbits on \{} of 
lengths 5586, 6384, 52 136, 58 653. The corresponding two-point stabilizers 
have orders 672, 588, 72, 64, and the number of their orbits on  is 252, 261, 
1779, 2076, respectively. The first three of these two-point stabilizers are 
two-generator groups, and the fourth one is a three-generator group, but 
RANDOMSTAB will frequently output three rather than two generators in 
the first three cases. So, when applying the single extra generator version of 
VERIFY listed above in Subsection 6.3.1, there will be about 12 elements in 
R2, and either 252, 261, 1779, or 2076 elements in R3. For each word in 
R2  R3, an element of H is checked for membership in K. So, if 
 is in the 
orbit of G of length 5586, then the algorithm will complete about 8 times 
more quickly than if it is in the orbit of length 58 653. 
We found that TCSS took between 40 and 100 times longer than VERIFY 
to verify that G=H. The set R1 of relators computed by TCSS consisted of 
272 relators of total length 8160 (this varied slightly from run to run), which 
is similar to that produced by VERIFY when 
 is in a short orbit of G. 
However, if we choose our second base point to be in the shortest orbit of 
G, of length 5586, then the verification at the second level of the 
stabilizerchain was about three times faster with TCSS than with VERIFY. 
With the second base point in one of the two longer orbits of G, TCSS was 
faster by a much larger factor. This is generally because the stabilizers of 
three points in G are small and have very large numbers of orbits. 
So, the optimal policy for the verification process on G is to use VERIFY 
for the first level and TCSS for the other levels of the stabilizer-chain.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
218 
Example 6.5 
Let G be the Lyons simple group of order 51 765 179 004 000 000 and 
degree 8 835 156. The orbit lengths of K:=G are 19 530, 968 750, 2 034 375, 
and 5 812 500. The associated two-point stabilizers have orders 300 000, 
6048, 2880, 1008, and have 66, 1613, 3366, and 9127 orbits. All of the two- 
point stabilizers are 2-generator groups.
Unfortunately, if z is a random element of G\G in Example 6.5, then 
is about 10 times more likely to be in one of the two longer orbits of G, so 
there appears to be a significant weakness in the default algorithm. 
Fortunately, there is a remedy. We simply choose a new element z′ with az′ 
in the shortest orbit of Gα on ∆\{}, where =G, and use that in place of z. In 
Example 6.5, G is primitive, so we would have 
 but, in general, 
 might not be transitive on . 
In that case, we proceed as in Subsection 6.3.2, and apply the single extra 
generator case of VERIFY u times, until we have 
, where 
each of the generators  is selected to make the image of a lie in a shortest 
orbit. If each such application is successful, then we finish by applying STRIP 
to the original generators zi in G\H to check that they can be rewritten as 
words in the new generators. 
One minor disadvantage of this approach is that the choice of the new 
tends to result in a larger number of strong generators of G being required 
than there were initially. But experience shows that this disadvantage is 
by far outweighed on average by the gain in speed that comes from having 
fewer orbits of the two-point stabilizers. In any case, many of the longest 
and most difficult applications are to primitive groups, where only a single 
new generator is required. 
There are some other housekeeping details that need to be taken care of 
with this approach, but these are routine. If, as is usually the case, we are 
computing a strong presentation of G for use with homomorphism algorithms, 
then we will need to store words for the new generators  in the existing 
generators, so that they can be stored as SLP elements; see Subsection 3.4.1. 
If the original extra generators zi were defining generators of G, then we will 
not want to discard them from the presentation, in which case we will also 
need to include relations that express these old generators as words in the 
new generators as part of the strong presentation of G. 
Exercise 
1. In the single-generator case of the VERIFY algorithm, when we need to 
choose a new orbit representative ßi+1 (i≥1) of K on ∆, prove that there 
must exist an orbit representative k of Kß such that 
 for some j 
with 1≤j≤i, and 
. 
© 2005 by Chapman & Hall/CRC Press

219
Chapter 7
Representation Theory,
Cohomology, and Characters
This substantial chapter is devoted to computations involving
representations and characters of finite groups, and computation within
finite matrix groups. Apart from the computation of character tables, we
shall be concerned almost entirely with representations over finite fields.
This is mainly because the methods are much more highly developed for
this case. Computing with representations over fields of characteristic zero,
and over algebraic number fields in particular, is currently an active area
of research, but there a number of formidable problems that do not arise
over finite fields, and so this topic must unfortunately remain beyond the
scope of this book.
After a short section devoted to computing in finite fields, we shall review
some fundamental algorithms for basic linear algebra. It turns out that
many of the most important techniques in computational representation
theory over finite fields, including the fundamental ‘Meataxe’ algorithm,
rely almost entirely on linear algebra, and involve very little knowledge of
group representation theory. (A complexity analysis of these methods, which
we shall not attempt to carry out here, does, however, require more theory.)
Later in the chapter, we shall discuss how to carry out some basic
cohomological computations for group modules over finite fields. The
Meataxe-based methods and the cohomological computations are important
not just in their own right, but also as components of more advanced
algorithms for structural computations in finite groups. For example, as
we shall see in Sections 8.5 and 10.2, the Meataxe is used in the computation
of the elementary abelian layers in chief series of finite groups, and in
Section 10.4 we shall study an application of cohomological methods to the
computation of the subgroups of a finite group.
The final section of the chapter, on computation in matrix groups over
finite fields, will explain how the base and strong generator set methods
introduced for permutation groups in Section 4.4 can be extended to matrix
groups. This section will also discuss and provide references for further
reading on recent work in this area, which is one of the most lively areas of
current research in CGT.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
220
7.1 Computation in finite fields
In general, if F is some field in which we can compute effectively, and K:= F(α)
is a simple algebraic extension of degree n over F for which the minimal
polynomial f of a over F is known, then we can also compute effectively within
K. Elements can be represented as polynomials of degree at most n-1 over F,
and then addition is straightforward, multiplication is done modulo f, and
multiplicative inverses can be computed by using the Euclidean algorithm.
This approach can be used for computing in finite extensions of Q (that
is, in algebraic number fields) and in finite fields, which can all be defined
as simple extensions of a suitable prime field Fp.
It has a disadvantage when used for finite fields however. As we saw in
Subsection 2.8.2, the multiplicative group of the finite field Fq of order q is
cyclic, and is generated by a primitive element α. Let us assume that we
can factorize q-1 easily. (It is well-known that factorizing very large integers
is not easy; indeed modern cryptography systems are based on that fact.
However, many factorizations of q-1 for large prime powers pn have been
precomputed and the results stored by computer algebra systems, so this
assumption is not unreasonable.) Since the multiplicative order of any α∈
divides q-1, we can use the function ORDERBOUNDED displayed in
Subsection 3.3.1 to compute the multiplicative order of g. Because a
reasonably high proportion (Φ(q-1)/(q-1)) of elements of 
 are primitive
elements, we can expect to find a primitive element α quickly by trying
random elements of 
.
However, the problem of expressing an arbitrary ß∈
 as a power αn of
our primitive element α, which is known as the discrete log problem, is a
notoriously difficult one, and is the main stumbling block for many
computations involving large finite fields. See [SWD96] for details of recent
methods for solving this problem.
The systems GAP and MAGMA avoid the discrete log problem for smaller
fields by representing and storing field elements as powers of a primitive
element α, rather than as polynomials. The element α is chosen to be a
root of the Conway polynomial (see Subsection 2.8.3) for the particular Fq.
With this method of representing field elements, we have the problem that
addition of field elements is not straightforward. But, since αi+αj=αi(1+αj-i)
when j≥i, this problem reduces immediately to evaluating 1+αi for 0≤i<q
as a power of α. For reasonably sized q (up to about 106), it is feasible to
precompute and store all of these values in lookup tables. These are known
as Zech logarithms.
For larger finite fields, for which no such tables are stored, it is necessary
to use the polynomial representation for field elements, and to put up with
the difficulty of solving the discrete log problem.
For more details on computation in finite fields, the reader may consult
the book by Shparlinski92 [Shp92].
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
221
Exercise
1. The Conway polynomials for the finite fields of orders 4, 8, and 9 are,
respectively, x2+x+1, x3+x+1 and x2+2x+2. Calculate the tables of Zech
logarithms for these fields with respect to the primitive elements defined
by these polynomials.
7.2 Elementary computational linear algebra
In this section, we present straightforward procedures for performing the
basic operations of linear algebra over a field K. This is intended to provide
ourselves with the required functionality for use in later sections in this
chapter on modules over algebras.
We are mainly interested in finite fields K in this chapter, but the basic
algorithms are for the most part independent of K. There are, however, a
number of problems involved in calculations over infinite fields, which do
not arise for finite fields. For exact computations over the rationals or over
an algebraic number field, there is the problem that the integers involved
can grow very large and unwieldy in the course of straightforward
manipulations. For calculations in the real or complex field on the other
hand, there is the problem of floating point error.
The algorithms presented here will be straightforward, and will not be
concerned with finer points of computational efficiency, but a few remarks
on such issues are in order.
The systems MAGMA and GAP both include efficient implementations
of basic linear algebra over finite fields. We mention also the stand-alone
package [Rin92], which was implemented mainly by M.Ringe and is based
on an earlier FORTRAN implementation by Parker (see [Par84]). A
fundamental objective of this package is to manipulate very large matrices
using as little core memory as possible, so matrices are stored in files and
read in only when they are needed.
Another feature of the package, which is also present in MAGMA and
GAP, is that matrix entries are packed as efficiently as possible into
machine words; so, for example, a vector or matrix over the field of order
2 is stored using a single bit for each each entry. Furthermore,
multiplication of matrices is speeded up by using moderately large stored
lookup tables for the scalar products of all pairs of vectors up to some
length that depends on |K|.
Divide-and-conquer methods for matrix multiplication, as introduced
originally by Strassen, which reduce the complexity of this and other
fundamental matrix manipulations from the standard O(n3) field operations,
are used in the MAGMA implementation. See, for example, the paper by
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
222
Coppersmith and Winograd [CW90]. Experiments show that these methods
lead to significant gains in running times for about n≥100.
To simplify our pseudocode, we shall adopt a number of conventions
that would require more careful handling in a real implementation. Any
sequence [a1, a2,…, ad] of length d containing elements of the field K can be
regarded as a vector (a1, a2,…, ad)∈Kd, and any sequence of c such sequences,
all of the same length d, can be regarded as a c×d matrix over K. We allow
the empty sequence to represent a vector or matrix over any field. We use
numbers like 0, 1, 2, to represent the corresponding elements of any field
K; so, we rarely need to refer explicitly to K in the pseudocode. We use the
symbol ⋅ to represent vector or matrix multiplication. As explained earlier,
in Section 2.2, we regard matrices as acting on vectors from the right. So,
if v∈Kd, and A is a d×c matrix, then vA is the same as v⋅A. We denote the
length of a vector v by |v|; so |v|=d for v∈Kd.
We shall not write out code for straightforward manipulations such as
matrix multiplication, but the reader should bear in mind the above
remarks about how these operations might be implemented in practice.
For v :=[a1,…, ad]∈Kd, we denote the subsequence [ac, ac+1,…, ac+e] in Ke+1
by v[c..c+e]. Similarly, for a matrix α, α[c..c+e][d..d+f] represents the
(e+1)×(f+1) submatrix with top-left entry α[c][d]. For c×d and c×e matrices
α, ß, HORIZONTALJOIN(α, ß) represents the c×(d+e) matrix formed by
writing ß to the right of α, and VERTICALJOIN(α, ß) is defined similarly
for c×e and d×e matrices α, β.
For c×d and e×f matrices α, ß, DIRECT-SUM(α, ß), or equivalently α⊕ß,
is defined to be the (c+e)×(d+f) matrix γ with γ[1..c][1..d]=α,
γ[c+1..c+e][d+1..d+f]=β and all other entries zero. These three functions
are all associative, and can also be applied to lists of matrices of compatible
dimensions. The transpose of a matrix α is written as αT.
We shall store a subspace W of V=Kd as a record W with two components,
β and γ, with the following properties:
(i)
β is a basis of W;
(ii) the leading nonzero coefficient of each vector in β  is 1;
(iii) the leading nonzero coefficients of the vectors in β  all occur in different
positions;
(iv) γ is a list of these positions.
For example, β :=[[0, 0, 1, 2, 0], [1, 1, 2, 0, -1], [0, 0, 0, 0, 1]], γ :=[3, 1, 5]
satisfies these conditions for a subspace of dimension 3 in K5. Notice that
by suitably permuting the vectors in β we could get an echelonized matrix,
but this is not usually necessary in our applications.
Our first function locates the leading nonzero coefficient a of a vector
and returns its position and a itself, or 0, 0 if the vector is zero.
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
223
DEPTHVECTOR(v)
1
for i∈[1.. |v|] do if v[i]0 then return i, v[i];
2
return 0,0;
The next function, VECTORINSUBSPACE tests whether a vector v∈Kd
lies in a subspace W with associated record W; it returns true or false,
accordingly. If the third argument ‘add’ is true and v∉W, then W is enlarged
to 〈W, v〉 by adjoining an extra vector to ß. If v∈W or ‘add’ is true, then the
function also returns a list c of coefficients, which satisfies
 
where β  is the (possibly extended) basis sequence of W.
VECTORINSUBSPACE(~W, v, add)
1 β :=V.β; γ:=V.γ;
2 c :=[];
3 for i∈[1..|γ|]
4
do a :=v[γ[i]]; APPEND(~c, a);
5
if a0 then v :=v-aβ[i];
6 d, a := DEPTHVECTOR(v);
7 if d=0 then return true, c;
8 if add
9
then APPEND(~V.β, a-1v); APPEND(~V.γ, d); APPEND(~c, a);
10
return false, c;
11
return false;
For completeness, we have written out code for inverting a matrix. This
follows the well-known method of reducing the matrix to the identity using
elementary row operations, while simultaneously performing the identical
row operations, but starting with the identity matrix.
Next, we turn to the calculation of the nullspace of a d×c matrix A; that
is, the subspace of Kd consisting of those v∈Kd for which v⋅A=0. The method
involves performing elementary column operations on A, which do not
change the nullspace of A. But, since we prefer to use row operations in
our code, we replace A by the c×d matrix B := AT, and then calculate the
space of v∈Kd such that B⋅vT=0.
We do this by transforming B to reduced echelon form, while maintaining
a list l of the positions in which the leading nonzero entries of the rows of
B occur. For example, if the echelonized form C of B is 
then l=[1, 3, 5].
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
224
INVERTMATRIX(A)
Input: An invertible square matrix A
Output: A-1
1 d :=|A[1]|;
2 I :=IDENTITY-MATRIX(FIELD(A), d);
3 for c∈[1.. d]
4
do for s∈[c..d]
5
do if A[s][c]0
6
then I[s] :=A[s][c]-1⋅I[s]; A[s] :=A[s][c]-1⋅A[s];
7
for t∈[1..c-1] cat [s+1..d]
8
do I[t] :=I[t]-A[t][c]⋅I[s];
9
A[t] :=A[t]–A[t][c]⋅A[s];
10
if cs
11
    then z :=I[s]; I[s] :=I[c]; I[c] :=z;
12
z :=A[s]; A[s] :=A[c]; A[c] :=z;
13
continue c;
14
Error “Matrix is not Invertible!”;
15 return I;
The rank of A is equal to the number |l| of nonzero rows of C, and so the
nullity of A is d-|l|. For each s∈[1..|d|] with s∉l, it is straightforward to
write down a vector vs of the nullspace of A with vs[S]=1, vs[t]=0 for all t>s,
and also vs[t]=0 for all t with ts and t∉l. These d-|l| vectors vs are linearly
independent, and so they form a basis of the nullspace of A.
In the example above, the column numbers not in l are 2, 4, and 6, and
we can choose the corresponding vectors vs to be v2 :=[-2, 1, 0, 0, 0, 0], v4 :=
[-1, 0, -2, 1, 0, 0], and v6 :=[-1, 0, -2, 0, -2, 1].
In the code below, we calculate the vectors in the nullspace during the
echelonization process rather than at the end of it, and we keep the nullspace
itself in the subspace record W.
Now we consider the calculation of the minimal polynomial of a d×d
matrix A over a field K. Let v be any nonzero vector in Kd. Then, if the
vectors v⋅Aj are linearly independent for 0≤j<r, but 
for some ai∈K, then clearly ρv(x) :=xr-ar-1xr-1-…-a1x-a0 is the unique monic
polynomial of minimal degree over K such that v⋅ρv(A)=0. The matrix of A
restricted to the subspace of Kd spanned by v⋅Aj (0≤j<r) and with respect to
this basis of the subspace is 
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
225
NULLSPACE(α, X)
Input: Matrix A
Output: A record W defining the nullspace of A
1 d :=|A|; c :=|A[1]|;
2
;
3 B := AT; (*B is a c×d matrix *)
4 r :=1; l :=[];
5 for t∈[1..d]
6
do for s∈[r..c]
7
do if B[s][t]0
8
then B[s] :=B[s][t]-1⋅B[s];
9
for k∈[1..r–1] cat [s+1..c]
10
do B[k] := B[k]-B[k][t]⋅B[s];
11
if rs
12
    then z :=B[s]; B[s] :=B[r]; B[r] := z;
13
l[r] := t; r := r+1;
14
continue t;
(*This t will not occur in l. Calculate vector in nullspace*)
15
v:=[0:i∈[1..d]]; v[t] :=1
16
for s∈[1..r–1] do v[l[s]] := –B[s][t];
17
VECTORINSUBSPACE(~W, v, true);
18 return W;
This is known as the companion matrix of the polynomial ρv.
To compute ρv, we need to express v⋅Ar as a linear combination of v⋅Aj
for 0≤j<r. The function VECTORINSUBSPACE does not do exactly that;
rather, it computes v⋅Ar as a linear combination of the echelonized basis of
the subspace. But we can perform this computation by storing the lists
returned by VECTORINSUBSPACE, which express each v⋅Aj in terms of
the echelonized basis. The lists are stored in µ in lines 7, 12 of
MINIMALPOLYNOMIAL, which is used in lines 16, 17 to compute the
required list w of coefficients of v⋅Aj.
For a polynomial ρ∈K[x], we have v⋅ρ(A)=0 for all v∈Kd if and only if
vi⋅ρ(A)=0 for all vi in a basis of Kd, so we can compute the minimal polynomial
ρ of A as the least common multiple of the polynomials ρvi over a basis. But
we do not usually need to compute for ρvi all i. We start by computing ρvi.
Since v⋅ρ(A)=0 implies v⋅σ(A)⋅ρ(A)=0 for any σ∈K[x], if any vi is in the
subspace spanned by v1⋅Aj (j≥0), then viρvi(A)=0, and we do not need to
compute ρvi. In general, if vi is in the subspace spanned by vk⋅Aj (j≥0) for all
k<i, then we do not need to compute ρvi. So, in the code below, we keep
track of this subspace.
The function MINIMALPOLYNOMIAL uses three other straightforward
undisplayed functions with the following specifications: BASIS(Kd) returns the
natural basis of Kd; FILL-VECTOR (~l, r) appends r–|l| zeros to the vector l, to
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
226
MINIMALPOLYNOMIAL(A)
Input: Square matrix A
Output: The minimal polynomial of A
1 d :=|A|; K := FIELD(A);
2 ρ :=POLYNOMIAL([1K]);
(* We accumulate the whole subspace spanned so far in W *)
3
;
4 for b∈BASIS(Kd)
5
do if not VECTORINSUBSPACE(~W, b, false)
6
then (* Calculate ρb and take LCM with ρ *)
7
v :=b; µ :=[];
8
;
9
while true
10
do a, c :=VECTORlNSUBSPACE(~X, v, true);
11
if a then break;
12
APPEND (~µ, c);
13
VECTORINSUBSPACE(~W, v, true);
14
v :=v⋅A;
15
r :=|µ|;
(*Get the vector c in terms of b⋅Aj (0≤j<r)*)
16
B :=[FILL-VECTOR (µ[i], r) : i∈[1.. r]];
17
w := c⋅B-1;
18
ρ :=LCM(ρ, POLYNOMIAL (–w cat [1K]));
19 return ρ;
produce a vector in Kr; POLYNOMIAL(v), with v=[a0, a1,…, ad]∈Kd+1, returns
the polynomial a0+a1x+…+ adxd.
The algorithm for computing the characteristic polynomial of a
matrix A is quite similar. But when considering a basis vector vi which
is not in the subspace W of Kd spanned by vk⋅Aj for k<i, j≥0, we compute
ρvi for the action of A on Kd modulo W rather than on Kd, and multiply
the resulting polynomials together, rather than taking their least
common multiple. We leave the justification of this process as an
exercise for the reader.
7.3 Factorizing polynomials over finite fields
The Meataxe algorithm for testing modules for irreducibility, which we
shall be describing in detail in the next section, involves factorizing the
characteristic polynomial of a matrix over a finite field. Polynomial
factorization over finite fields, and also over other rings allowing exact
computation, such as Z, Q, and algebraic number fields, is one of the central
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
227
CHARACTERISTICPOLYNOMIAL(A)
Input: Square matrix A
Output: The characteristic polynomial of A
1 d := |A|; K := FIELD (A);
2 ρ:= POLYNOMIAL([1K]);
(*We accumulate the whole subspace spanned so far in W*)
3
;
4 d := 0; (*d is just the dimension of W*)
5 for b∈BASIS(Kd)
6
do if not VECTORINSUBSPACE(~W, b,false)
7
then (*Calculate ρb on Kd mod W and multiply by ρ*)
8
v := b; µ :=[];
9
while true
10
do a, c := VECTORINSUBSPACE(~W, v, true);
11
if a then break;
12
APPEND(~µ, c[d+1.. |c|]);
13
v:=v⋅A:
14
r := |µ|;
15
B := [FILL-VECTOR (µ[i], r) : i∈[1.. r]];
16
w := c⋅B-1;
17
ρ := ρ×POLYNOMIAL(-w cat [1K]);
18
d := d+r;
19 return ρ;
problems in computer algebra; for a detailed treatment of this topic see,
for example, [GCL92, Chapter 8] or [Coh73, Chapter 3].
The algorithms for factorizing polynomials over infinite domains such
as Z, all involve reducing modulo one or more primes and then factorizing
over the resulting finite field, so the finite field case is particularly important.
There are two methods in common use, the Berlekamp algorithm [Ber67,
Ber70] and the Cantor-Zassenhaus algorithm [CZ81]. Both of these are
discussed in the two books cited above. The Berlekamp method is generally
faster for very small fields and, by borrowing some of the ideas of the
Cantor-Zassenhaus algorithm, which involves probabilistic methods, it can
be adapted to perform well also for large finite fields.
A detailed treatment of this topic here would be straying too far from
the main theme of this book but, since the Cantor-Zassenhaus algorithm is
relatively easy to describe, we shall summarize it, but without giving any
proofs. Programming the Euclidean and greatest common divisor algorithms
for polynomials over finite fields is straightforward, so we shall assume
that these facilities are available. The Cantor-Zassenhaus algorithm breaks
up into three steps, which we shall describe in the following three
subsections.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
228
7.3.1 Reduction to the squarefree case
Let f=f (x) ∈ 
 with q a power of the prime p, and suppose that
, where the fi(x) are distinct irreducibles in 
. We say that
f is squarefree if αi=1 for 1≤i≤r. The first step in the factorization algorithm
is to reduce to the case when f is squarefree. This step is common to the
Berlekamp and Cantor-Zassenhaus methods.
The basic idea is to divide f by the greatest common divisor gcd(f, f) of f
with its formal derivative, f. In characteristic zero, this would yield the
squarefree polynomial f1…fr. There is a complication with finite fields,
however, because the derivative of the p-th power gp of any 
 is
zero, and the reader can verify that f/gcd(f, f) is the product of those fi for
which p does not divide αi. In particular, if p|αi for all i, then f=gp is a p-th
power, f= 0 and this gets us nowhere! (Note that the gcd of any polynomial
f with 0 is f.)
But, if 
, then 
.
Since aq=a for all 
, we have 
 and so am can easily be
calculated from 
, and hence g can be calculated from gp.
So, we can proceed as follows. Calculate f. If f=0, then compute g := f1/p,
which reduces the problem to factorizing g. Otherwise, f is the product of the
squarefree polynomial f/gcd(f, f) and gcd(f, f). Since gcd(f, f) has lower
degree than f, this effectively reduces the factorization problem to the
squarefree case.
The following procedure does this a little more cleverly. It outputs a list
of pairs (fi, αi), such that 
 and each fi is squarefree, although
not necessarily irreducible.
REDUCETOSQUAREFREE(f)
Input: 
 with q a power of prime p
Output: List L of pairs (fi, αi) as described above
1 L:=[]; e :=1;
2 g:=gcd (f, f);
3 w:=f/g;
4 while w1
5     
do y:=gcd(w, g) z:=w/y;
6     
APPEND(~L, (z,e));
7     
e:= e+1;
8     
w:=y; g:=g/y;
9 if g1
10
then (*g is a p-th power*)
11
for t∈REDUCETOSQUAREFREE(g1/p)
12
do APPEND(~L, (t[1], pt[2]));
13 return L;
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
229
7.3.2 Reduction to constant-degree irreducibles
Having reduced to the case when the polynomial f∈
q[x] to be factorized is
squarefree, the next step is to reduce to the situation where f=f1…fr, and
the fi are all irreducible of the same known degree.
Let e≥1, and let g be any irreducible polynomial of degree e over 
q.
Then 
 where α is a root of g. Since α∈
qe implies αqe=α, and g is
the minimal polynomial of α over 
q, we have 
. On the other
hand, since 
 factorizes into qe linear factors over 
qe, its roots all
have degree at most e over 
q, and so all of its irreducible factors have
degree at most e over 
q.
So, if f∈
q[x] is squarefree, then f1 := gcd(f, xq-x) is the product of all of
the linear irreducible factors of f, 
 is the product of
all irreducible factors of degree 2, and so on. This gives rise to the following
algorithm for reducing to the constant-degree case. Note that we do not
need to work explicitly with the large-degree polynomials 
. It suffices
to compute them modulo f.
REDUCETOCONSTANTDEGREE(f)
Input: f∈
q[x], f squarefree
Output: List L=[f1, f2,…, fs], where f=f1…fs and, for 1≤d≤s, all irreducible
factors of fd have the same degree d
1 L :=[]; e :=1;
2 w := xq mod f;
3 while e≤deg(f)
4
do g := gcd(f, w-x);
5
APPEND(~L, g);
6
f := f/g;
7
w := wq mod f;
8
e := e+1;
9 return L;
7.3.3 The constant-degree case
So now we may assume that f=f1…fr, where each fi is irreducible of the
same known degree d. If deg(f)=d, then f is irreducible and we are done.
Otherwise, we use a probabilistic method. We choose random polynomials
g∈
q[x] with deg(g)≤2d–1. If the characteristic p of the field is odd, then it
turns out that, with probability almost 1/2, gcd((q–1)/2–1, f) is a nontrivial
proper factor of f; for a proof, see [GCL92, Theorem 8.11]. For p=2, q=pk,
the same is true, but with 
 in place of g(q–1)/2–1. So
we have the following procedure for the final splitting.
Note that, in line 8, CDF is an abbreviation for a recursive call of the
procedure CONSTANTDEGREEFACTORIZATION.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
230
CONSTANTDEGREEFACTORIZATION(f, d)
Input: f∈
q[x], f squarefree, deg(fi)=d for all irreducible factors of f
Output: List of irreducible factors of f
1
if deg(f)=d then return [f];
2
while true
3
do Choose random g∈
q[x] with deg(g)≤2d–1;
4
if q is odd
5
then g := g(q–1)/2–1;
6
else 
;
7
g :=gcd(f, g);
8
if 0<deg(g)<deg(f) then return CDF(g)cat CDF(f/g);
Exercises
1.
Improve REDUCETOCONSTANTDEGREE by showing that no further
calculations are necessary once 2e<deg(f).
2.
Apply the Cantor-Zassenhaus algorithm to factorize the polynomial
x6+x5+2x4+4x3+x2+4x+2 over F5.
7.4 Testing KG-modules for irreducibility—the
Meataxe
Let G be a finite group and K a field. We turn now to the fundamental
problem of deciding whether a finite-dimensional module over the group
algebra KG is irreducible, and of finding an explicit submodule when it is
reducible. We shall restrict our attention to the case when K=Fq is a finite
field. It is proved by Rònyai in [Rón90] that this problem can be solved in
time polynomial in d log(q), where d is the dimension of the module, but
the method described there does not lend itself to efficient implementation
for large d.
7.4.1 The Meataxe algorithm
An algorithm that has become universally known as the ‘Meataxe’ was
described by Parker in [Par84]. It turned out to be usable for very large
values of d (in the thousands) for small fields, and was particularly suitable
for computing explicit irreducible representations of the finite simple
groups. In this section, we shall describe a generalization of Parker’s
original algorithm due to Holt and Rees [HR94]. The range of applicability
of this version is less restricted in terms of the size of the field and the
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
231
structure of the group involved. In fact, it works for modules over any
finite-dimensional matrix algebra over a finite field.
Let A be an associative algebra over a finite field K, and suppose that A
has r generators x1,…, ,xr. We are particularly interested in the case when
A is a group algebra KG and the xi are generators of the finite group G.
A representation ϕ of degree d of A is a homomorphism from A to the
algebra of d×d matrices over K. We shall assume that such representations
are defined by means of a list Λ := [α1,…, αr] of d×d matrices over K, where
αi=ϕ(xi). These matrices specify the action of the generators of A on the
(right) module M associated with the representation where, as vector space,
M=Kd, and the action of the matrices on M is given by multiplication on the
right. We shall call them the action matrices of the module, and we shall
call the algebra that they generate the matrix algebra of the module. (It is
also known as the enveloping algebra.)
Let 
  be the transposes of the matrices in Λ, and let
MD be the corresponding right module. This is called the dual module of M.
(Since (α⋅β)T=βT⋅αT, MD is actually a module for the opposite algebra A° of A
rather than an A-algebra.) For a submodule L of M of dimension c, the
orthogonal complement L⊥ := {v∈Kd|w⋅vT=0w∈L} has dimension d-c, and
it is straightforward to check that L⊥ is a submodule of MD.
As we gather information about a module, we wish to store it. We shall
therefore introduce a module record-type. Such a record M for a module
M will have as components a finite field K=Fq, a degree d, and a list Λ of r
d×d matrices over K that generate the algebra A over which M is defined.
The list ΛT of transposes of the generators may also be stored.
Before proceeding to the main MEATAXE function, we need a function
for computing the submodule of M generated by a given nonzero vector.
We compute this in the function SPINBASIS, by maintaining a basis of the
submodule spanned so far, using a subspace record W as defined in Section
7.2, and applying each algebra generator to each basis vector in this subspace.
SPINBASIS(Λ, v)
Input: List Λ of matrices defining module M, vector v ∈ M
Output: Submodule of M generated by v
1
;
2
VECTORINSUBSPACE(~W,v,true);
3
r :=1;
4
while r≤|W.β|
5
do w:=W.β[r];
6
for α∈Λ do VECTORINSUBSPACE(~W,w⋅α,true);
7
r := r+1;
8
return W;
The MEATAXE function displayed below is probabilistic of the Las Vegas
type; see Subsection 3.2.1. An answer may or may not be returned on any
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
232
iteration of the main loop at line 2, and we shall prove later that a returned
answer is always correct. An analysis of the algorithm should include an
estimate of the probability that an answer is returned on a specific iteration,
but for this we refer the reader to [HR94].
The expression RANDOMALGELT(~M) in line 3 of MEATAXE, denotes
a random element of the matrix algebra of M. In practice, we choose this to
be a random linear combination of a small number (usually just two or
three) of products of matrices from M.Λ calculated using the product
replacement algorithm (see Subsection 3.2.2). Although we have not made
this explicit in the code, if M is irreducible, then the formula that defines
θ as a function of the matrices in M.Λ is stored along with θ as a record
component of M at line 28. We shall need this formula later, in Subsection
7.5.2, when computing module homomorphisms with domain M.
MEATAXE(~M)
(* Decide whether the module M defined by ~M is irreducible *)
1
d:=dim(M);
2
while true
3
do θ:=RANDOMALGELT(~M);
4     
:=CHARACTERISTICPOLYNOMIAL(θ);
5     
for π∈ IRREDUCIBLEFACTORS()
6     
do ξ:=π(θ);
7     
N:=NULLSPACE(ξ);
8     
Let v∈N\{0};
9     
W:=SPINBASIS(M.Λ,v);
10     
if |W.ß|<d
11     
then (* Proper submodule found *)
12     
M.W:=W;
13     
return false;
14     
elseif deg(π)=DIMENSION(N)
15     
then (* Try transposing *)
16     
Compute M.ΛT:=ΛT if not already done;
17     
NT:=NULLSPACE(ξT);
18     
Let w∈NT\{0};
19     
W:=SPINBASIS(M.ΛT, w);
20     
if |W.β|<d
21     
then (* Proper submodule found *)
22     
Let w∈
23     
ORTHOGONALCOMPLEMENT(W);
24     
W:=SPINBASIS(M.Λ, w);
25     
M.W:=W;
26     
return false;
27     
(* The module is irreducible *)
28     
M.θ:=θ; M.π:=π; M.v:=v;
29     
return true;
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
233
On the other hand, if the module turns out to be reducible, then a subspace
record W of a proper submodule is stored as a record component of M.
For clarity, we have written DIMENSION(N) for the dimension of the
N, but in fact, with our implementation of subspaces as records, this could
be coded as |N.β|, where N is the subspace record corresponding to N.
Similarly, we could code “let v be a nonzero vector in N” by v:=N.β[1].
In the ‘For’ loop at line 5 over the irreducible factors of , we choose
factors in order of increasing degree. This makes the Cantor-Zassenhaus
method of polynomial factorization described in Section 7.3 particularly
appropriate, because it computes the irreducible factors in order of increasing
degree. Among those factors with a given degree, we give preference to
those that are unrepeated factors π of , because they are guaranteed to
have degree equal to the dimension of the nullspace of π(θ).
Example 7.1
Before proving correctness of MEATAXE, let us work through a small
example. We let M be a 5-dimensional module over K=F3 in which A has
the two generating matrices: 
This algebra is a representation of the group algebra KG, where G=Sym(4),
and the matrices are the images of the permutations (1, 2, 3, 4) and (1, 2).
As our random element, we choose
The characteristic polynomial is =x5+x3+x2+1, which factorizes over K to
(x+1)3(x2+1). The first factor (x+1) yields no result in MEATAXE; we might in
any case prefer to use the second factor (x2+1), because it is a nonrepeated
factor and therefore certain to yield a result. So, putting π:=x2+1, we find that
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
234
of which the nullspace is generated by the vectors (1, 2, 0, 0, 0), (0, 0, 1, 2,
2). Applying SPINBASIS to the first of these vectors, yields the proper
submodule M with basis [ (1, 2, 0, 0, 0), (0, 0,1, 2, 2), (0, 0, 0, 1, 0) ], and it is
not hard to check directly that this is indeed a submodule.   
7.4.2 Proof of correctness
We shall now prove that, if MEATAXE returns an answer, then it is correct;
that is, the answer true means that the module is irreducible, and false
means that it is reducible. MEATAXE returns false only when it has found
a submodule, so correctness is clear in that case. So assume that true is
returned.
Now true is only returned when the degree of the polynomial π is equal
to the dimension of the nullspace N of ξ:=π(θ). So, in order to prove
correctness, we need only show that, if M is reducible, then a submodule of
M will be found by MEATAXE in that situation. So assume that deg(π)=dim(N)
and that M has a proper nonzero submodule L.
Since N is the nullspace of ξ=π(θ) and π is irreducible, the minimal
polynomial of the restriction θ|N of θ to N must be π. But then dim(N)=deg(π)
implies that θ|N acts irreducibly on N. It follows that the subspace 
 of
Kd, which is fixed by θ, must either be zero or equal to the whole of N. In
the latter case, the chosen nonzero vector v∈N lies in L, and so a proper
submodule of M (contained in L) will be found and the answer false returned
at line 13.
Suppose, on the other hand, that 
, and that we proceed to
line 16, where ΛT and ξT are calculated. Let e1, e2,…, ed be a basis of M such
that e1,…, ec is a basis of L, and let P be the d×d matrix with rows e1, e2,…,
ed. Then, writing ξ and ξT with respect to the basis e1, e2,…, ed, we get
where Q:=(P-1)T, and ζ(1), ζ(2) and ζ(3) are, respectively, c×c, (d-c)×c, and
(d-c)×(d-c) matrices.
Now L∩N={0} implies rank ζ(1)=c, and so nullity ζ(3) T=nullity ξT. Thus all
vectors in the nullspace of QξTQ-1 lie in a proper submodule of the module
for the algebra defined by the matrices 
. Equivalently,
all vectors in the nullspace of ξT lie in a proper submodule of MD. So a
proper submodule of MD will be found at line 19, a vector in the orthogonal
complement of this submodule will lie in a proper submodule of M, and
false will be returned at line 26.
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
235
7.4.3 The Ivanyos-Lux extension
We have proved that any answer returned by MEATAXE is correct, and the
proof is valid for any field K. However, it is only for finite fields that the
probability of an answer being returned at all is reasonably high. It is proved
in [HR94] that, for a finite field K, in almost all circumstances, an answer is
returned for a particular choice of θ with probability at least 0.144.
There is unfortunately one exceptional configuration in which an
answer is returned with very low probability, and that is when M is
reducible, all compositions factors of M are isomorphic to the same
irreducible module L, and the centralizing field of L is large compared
with the base field K. This situation has occasionally been observed to
arise in chief factors of solvable groups, so it needs to be dealt with. Two
remedies have been proposed, an unpublished one by C.R. Leedham-
Green, and one by Ivanyos and Lux in [IL00], which includes a proof
that an answer will result from their modification in the exceptional
situation with probability at least 0.08.
The Ivanyos-Lux extension is easy to describe, so we shall do so now,
briefly, and without detailed explanations. If the first few (perhaps three or
four) values of θ in MEATAXE produce no answer, then we proceed as follows,
maintaining the current choice for θ, and with π equal to an irreducible
factor of minimal degree of the characteristic polynomial  of θ. Suppose that
=πl ρ, where π does not divide ρ, find polynomials σ, τ such that 1=σπl+τρ,
and let ι:=τρ (mod ). (Then ι modulo  is a primitive idempotent of the
algebra K[x]/.) Choose another random element η∈A and a random vector
v∈M, and calculate the submodule L of M spanned by v⋅[θ, ι(θ)ηι(θ)] where
[α, β] means αß-ßα. If L is a proper submodule of M then return false.
7.4.4 Actions on submodules and quotient modules
If a module turns out to be reducible, then we might want to calculate matrices
for the actions on the associated submodule and quotient module. Doing this
is straightforward, and we shall briefly describe the method, without displaying
detailed code. By iterating the process, we can then find a composition series,
and all irreducible composition factors of the original module.
When MEATAXE returns false on a module with record M, it sets a
component W of M, which contains a subspace record for a proper submodule.
Let ß:=W.β be the basis returned for this subspace. We extend this to a basis,
which we shall also denote by β, of Kd by appending those natural basis vectors
of Kd for which the position of their nonzero entry does not occur in W.γ.
Let Λ:=M.Λ. Then we compute the list Λβ:=[β⋅α⋅β-1|α∈Λ] of matrices for
the module with respect to the basis β, and we obtain matrices for the
actions on the submodule and quotient module as [ α[1..c] [1..c]|α∈Λß] ]
and [α[c+1..d][c+1..d]|α∈Λß], respectively, where c is the dimension of the
submodule.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
236
In Example 7.1 above, we get 
so the lists of matrices for the action on the submodule and quotient module
are, respectively,
7.4.5 Applications
Applications of the Meataxe algorithm are mostly within group theory and
representation theory. It was used extensively in the construction of Brauer
trees by Hiss and Lux in [HL89] and of Brauer character tables by Jansen,
Lux, Parker, and Wilson in [JLPW95].
For the larger representations that arise in this type of computation, an
additional technique, known as condensation is required; see, for example,
the papers of Ryba, Lux, and Müller [Ryb90, LMR94, Ryb01]. The general
idea is to replace the original module M by a condensed version MC, say,
which is of much smaller dimension and defined over a different algebra
from C. In favourable circumstances, the irreducible constituents of M can
be recovered from those of MC. This approach has been developed mainly for
the cases when M is a permutation module and when it is defined as a tensor
product of pairs of smaller dimensional modules. For example, in [MNRW02],
in order to compute the Brauer tree of the Lyons sporadic simple groups for
the primes p=37 and 67, the authors were able to condense a permutation
module of dimension 1 113 229 656 to one of dimension 3207.
The Meataxe is also used as a component in a number of structural
grouptheoretical computations. As we shall see in Sections 8.5 and 10.2, it
is used to to refine elementary abelian sections when computing chief series
of finite groups. It plays a rôle in a number of other computations, such as
the computation of automorphism groups of p-groups, which will be discussed
briefly in Subsection 9.4.6.
Exercises
1.
Prove that, if L is a submodule of M, then L⊥ is a submodule of MD.
2.
Assume that MEATAXE returns false on a module record M. Write some
code to compute the matrices for the action on the submodule directly,
without performing the basis change described in Subsection 7.4.4
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
237
7.5 Related computations
In the following subsections, we describe some algorithms for KG-
modules with K and G finite, which follow on naturally from the Meataxe
procedure.
7.5.1 Testing modules for absolute irreducibility
Our next problem is to take a module M over a finite field K=
q that has
been proved irreducible by a call of MEATAXE, and to compute its
centralizing algebra C. As was explained in Subsection 2.7.1, C is isomorphic
to an extension field 
qe of K=
q, and M is absolutely irreducible if and only
if e=1. Let λ be a d×d matrix over K that generates C as an algebra or,
equivalently, as a field. Then the minimal polynomial µ of λ has degree e.
Let W be a nonzero λ-invariant subspace of Kd of minimal dimension; so
λ|W is irreducible. Then, for any matrix α in the matrix algebra of M, Wα is
also λ-invariant and, by minimality of W, we have either W=Wα or W∩Wα={0}.
Using this fact and the irreducibility of M, it is straightforward to show
that Kd can be written as a direct sum of some subspaces Wα, where the
minimal polynomial of λ|Wα is the same for each Wα. So this minimal
polynomial must be µ, and hence dim(W)=e and e|d.
Since we are assuming that M was proved irreducible using MEATAXE,
we know that the following objects used in the proof have been stored as
components of the module record M:
(i)
the element θ;
(ii)
the irreducible factor π of the characteristic polynomial  of θ;
(iii)
a nonzero vector v in the nullspace N of π(θ), where dim(N)=deg(π).
Let dim(N)=c. Our centralizing matrix λ must leave N invariant, and so N
can also be written as a direct sum of translates Wα of W, and hence e|c.
Since θ|N acts irreducibly on N, the centralizing algebra D, say, of θ|N is
isomorphic to 
qe, and includes C|N, so C|N is the unique subfield of D
isomorphic to 
q
e. So, if we choose any element κ of D, then κf∈C|N, where
f:=(pc-1)/(pe-1), and for a suitable choice of κ (for example, a generator of the
multiplicative group of D), κf will generate the field C|N.
These considerations justify our algorithm for finding C, which proceeds
as follows. We start by calculating the basis β:=[v.θ i| i∈[0..c–1] ] of N, with
respect to which the matrix γ of θ|N is the companion matrix of π. It easy to
write down random elements κ of the centralizing algebra D of θ|N with
respect to this basis. The reader can verify that we get such a centralizing
matrix by letting the first row of κ be an arbitrary vector in Kc (of which
there are |D|=qc), and then the remaining rows of κ are determined by
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
238
κ[i]=κ[i-1]⋅γ for 2≤i≤ c. Although we have not done this in the code below, it
can save time to choose θ|N itself as the first choice for κ.
We consider the common divisors e of d and c in decreasing order and,
for each e, we decide whether C includes the field 
qe. An affirmative answer
will then imply that  
. If we reach e=1 then we have proved that M
is absolutely irreducible.
For a fixed value of e and an element κ∈D, we calculate λN:=κf, where
f:=(qc-1)/(qe-1) as above, and check whether λN generates the subfield 
qe of
D. This last condition is equivalent to the degree of the minimal polynomial
µ of λN being e, which we can check. If not, then we keep trying new
matrices κ until we find λN:=κf such that the condition holds.
From the theory above, we know that, if |C|=qe, then this λN is the
restriction to N of λ for a suitable λ∈C, so we just have to check whether
this is the case.
If so, then Kd is the direct sum of translates of a minimal C-invariant
subspace W, and we can take W to be a minimal λN-invariant subspace of
N. In the code below, we first calculate a basis βλ of W in terms of the
basis β of N. This is because our matrix λN is written with respect to β.
We get βλ simply by applying powers 
 of λΝ for 0≤ j<e to the vector
w=[1, 0,…, 0] of K
c. We can then write βλ with respect to the original basis
for the module by replacing βλ by βλβ. The matrix of λN|W with respect to
the basis βλ of W is then just the companion matrix v of the minimal
polynomial µ of λ.
The subroutine COMPLETEBASIS attempts to construct Kd as such a
direct sum of translates of W. It may fail as a result of some translate Wα of
W being neither contained in nor disjoint from the direct sum found so far.
If that happens, then we know that |C|qe, so we can proceed to the next
candidate for e. If COMPLETEBASIS succeeds then it extends the basis βλ
of W to a basis, also denoted by βλ, of Kd, with respect to which the matrix
for λ is the direct sum νd/e of d/e copies of ν. We then get the matrix of λ
with respect to the original basis of the module as 
. Now, it
only remains to check whether the generating matrices of the module all
commute with λ. If so, then we have verified that |C|=qe and, if not, we
can proceed to the next e. Note that VECTORINSUBSPACE has been
abbreviated to VIS in COMPLETEBASIS.
ABSOLUTELYIRREDUCIBLE must only be called on a module M for
which MEATAXE(M) has already been called and returned true. The positive
integer e, such that |C|=qe will be set as a record component of the module,
which is absolutely irreducible if and only if e=1. If e>1, then the d×d
matrix λ that generates C is also stored. (Note that λ will not necessarily
have multiplicative order qn-1; that is, it will not necessarily generate the
multiplicative group of C. But if such a matrix is required, then it can be
found later by choosing random elements of C.)
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
239
COMPLETEBASIS(~ßλ, d, e, Λ)
Input: Partial basis ßλ for centralizing element
(* Set up a subspace record B for the basis *)
1
;
2
for v∈βλ do VIS(~B,v,true);
3
for i∈[1..d/e], α∈Λ
4     
do if not VIS(~B,βλ[(i–1)e+1]⋅α, false)
5     
then for j∈[(i–1)e+1..ei]
6     
do VIS(~B,βλ[j]⋅α, true);
7
if |B.ß| mod e0 then return false;
8
βλ:=βλ cat [βλ[j]⋅α|j∈[e(i-1)+1. .ei]];
9
if |βλ| = d then return true;
ABSOLUTELYIRREDUCIBLE(~M)
(* Is the irreducible module M absolutely irreducible? *)
1 θ:=M.θ; π:=M.π; v:=M.v; d:= dim(M);
(* The components θ, π, v have been set by MEATAXE *)
2 c:=deg(π); γ:=COMPANIONMATRIX(π);
3 β:=[v.θ i|i∈[0..c-1]];
4 Let l be the list of common divisors of c and d in decreasing order;
5 for e∈l (* Test whether |C(M)|=qe *)
6
do M.e:=e;
7
if e=1 then return true;
8
f:=(qc-1)/(qe-1);
9
while true
10
do (* Choose a random c×c matrix centralizing γ *)
11
κ:=[RANDOMVECTOR(K, c)];
12
for i∈[2..c] do κ[i]:=κ[i-1]⋅γ;
13
λN:=κf; µ:=MINIMALPOLYNOMIAL(λN);
14
if deg(µ)=e then break;
15
w:=[1] cat [0:i∈[1..c-1]];
16
; 
17
βλ:=βλ⋅β;
18
if COMPLETEBASIS(~βλ,d,e, M.Λ)
19
then (* Test directly if we have a centralizing element *)
20
ν:=COMPANIONMATRIX (µ);
21
νd/e:=DIRECTSUM([ν|i∈[1..d/e]]);
(* Put νd/e into the original basis *)
22
;
23
for α∈Λ do if α⋅λ≠λ⋅α
24
then continue e;
(* Centralizing element found *)
25
M.λ:=λ; return false;
26
else continue e;
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
240
Example 7.2
Let M be a 4-dimensional module over K=F2 in which A has the two
generating matrices:
(It is just a coincidence that λN=α2.) Now the minimal polynomial µ of λN is
x2+x+1, which has degree e=2, so we can use this λN to test whether C=F22.
The two vectors of βλ with respect to the basis β are [1, 0, 0, 0] and [1, 0, 0,
0] ⋅λN=[0, 0, 1, 1], and hence the two vectors with respect to the original
basis are [1, 0, 0, 0], [1, 1, 0, 1]. Now applying COMPLETEBASIS to this
pair of vectors successfully completes the pair to the basis with matrix
The algebra is an irreducible representation of the group algebra KG with
G=Alt(5), where α1 and α2 are the images of (1, 2, 3) and (1,4, 5).
Suppose that the random element of A chosen in the call of MEATAXE is
Then θ has characteristic polynomial x4+x3+x2+x+1, which is irreducible
over K, and can be used by MEATAXE to prove that M is irreducible.
In the test for absolute irreducibility, we first calculate the basis β of the
companion matrix of θN, which is the list of rows of the matrix:
The candidates for e are 4, 2, and 1. When e=4, f=1, and we can take
λN:=κ:=γ at line 13, which results in λ=θ at line 22. Since θ does not commute
with α1, this rules out e=4.
So next we try e=2. Here f:=(24-1)/(22-1)=5. Since γ 5 is the identity, we
cannot use κ=γ. A suitable random matrix κ that centralizes the matrix γ of
θ with respect to the base β is
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
241
We can check that this last matrix λ does indeed commute with α1 and α2, so
we have proved that e=2. So this module is not absolutely irreducible, and
has 
4 as centralizing field.
7.5.2 Finding module homomorphisms
We shall now consider the problem of finding a basis over K of the vector
space of algebra homomorphisms HomA(M, L) where M and L are modules
over the same K-algebra A. We shall write out detailed code for the case
when M is irreducible. By choosing M=L, we could use this approach for
finding the endomorphism algebra of M although, when M is irreducible,
the algorithm described in Subsection 7.5.1 is significantly more efficient.
The method for computing HomA(M, L) for general M and L that springs
to mind is the following. Find a sequence of vectors [v1,…, vk] that generate
M as an A-module, with k as small as possible. Let [w1,…, wt] be a K-basis of
L. Then the images of vi under a homomorphism 
 can be written
as linear combinations of the wj, where the coefficients are unknowns in K.
So we have a total of kt unknowns, and the condition that ϕ should be an
algebra homomorphism results in a system of homogeneous linear equations
in these unknowns. We solve this system by finding the nullspace of the matrix
of coefficients, which gives us our basis of HomA(M, L).
Let s:=dim(M) and t:=dim(L). To construct the system of linear equations,
we first apply the matrices in A to the vectors v1,…, vk to build up a basis
v1,…, vs of M, and apply the same operations in L to find the images of the
complete basis of M in terms of our kt unknowns. We then apply each
algebra matrix αi (1≤i≤r) to each basis vector vj of M. For each i and j, the
algebra homomorphism condition 
 is an equality between
two vectors in L, and yields t equations in the kt unknowns. This results in
a system of rst equations in kt unknowns, which is unpleasantly large,
even over a finite field, if s and t are more than about 100.
There are better methods available when the dimensions are large, but
we shall not discuss them any further here. One such method was proposed
Now the companion matrix ν of µ is the 2×2 matrix with rows [1, 0],
[1, 1], and if we let ν2 be the direct sum of two copies of ν, then we find that
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
242
by Schneider in [Sch90a], and further unpublished ideas have been proposed
by C.R.Leedham-Green, and are used in the MAGMA implementation. In
the same paper, Schneider shows how similar methods may be applied to
test a module M for indecomposability.
In the special case when M is irreducible, significant improvements can
be made to the basic idea described above, and we shall discuss these now.
So, suppose that we have module records M, L for the A-modules M and L,
and that M has been proved irreducible by a call of MEATAXE(~ M). The
algorithm for computing a K-basis of HomA(M, L) is displayed in the function
MODULEHOMOMORPHISMS below. Elements of this K-basis are output
as s×t-matrices over K, where s:=dim(M) and t:=dim(L).
Since M is irreducible, it is generated as an A-module by any of its nonzero
vectors, and we choose the generator v1 (in the notation above) to be the
vector M.v in the nullspace of M.ξ.
In a module homomorphism ϕ:M→L, ϕ(v1) must lie in the nullspace of
the element ξL in the matrix algebra of L corresponding to ξ. As we
mentioned earlier, a formula for calculating M.θ from the list of action
matrices M.Λ of M is stored by MEATAXE as a component of M, and so we
can apply the same formula to the action matrices L.Λ of L to get the
element θL corresponding to θ. We have called the function for doing this
COPYTHETA in line 1 of MODULEHOMOMORPHISMS, and we set
ξL:=M.π(θL).
Next we calculate the subspace record N of the nullspace N of ξL, and
put d:=dim(N). Let wλ:=N.β be the basis of N returned by NULLSPACE.
Then a module homomorphism ϕ must map v1 to a vector in N; that, is,
there exist λ1,…, λd∈K with 
.
In MODULEHOMOMORPHISMS, we construct a basis of M as the list
β:=V.β in a subspace record V, and simultaneously define d lists of vectors
τλ[1],…, τλ[d] in L with the property that 
, for each
β [i] in the list β. The subroutine PVIS (which stands for ‘parallelized vector in
subspace’) takes as arguments a vector v∈M and a list  of d vectors in L,
which are known to satisfy the equation 
.
PVIS starts by applying the code of VECTORINSUBSPACE to test
membership of v in the subspace V that has been constructed so far. As it
subtracts multiples of vectors in ß from v, it simultaneously subtracts the
same multiples of the corresponding vectors in τλ[j] from [j] for 1≤j≤d,
thereby maintaining the relationship 
.
If v turns out not to be in V, then a new basis vector is appended to V.β
and the corresponding vectors [j] are appended to τλ [j] for 1≤j≤d. On the
other hand, if v is in V already, then v will be reduced to 0, and then we
must also have 
, which yields t=dim(L) linear equations
over K that are satisfied by λ1,…,λd. The coefficients of these linear
equations are stored as the columns of the matrix , and any extra
equations discovered in a call of PVIS are appended to  by a call of
HORIZONTALJOIN.
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
243
In the function MODULEHOMOMORPHISMS, we initialize V and τλ by
calling
PVIS(v, ω, ~ V,~τλ, ~ χ)
Input: v∈M, list  of vectors in L
1 d:=|w|; β:=V.β; :=V.γ;
2 for i∈[1..|γ|]
3     
do a:=v[γ[i]];
4     
if a≠0
5     
then v:=v-a⋅ß[i];
6
for j∈[1.. d] do [j]:=[j]-a⋅τλ[j][i];
7 c, a:=DEPTHVECTOR(v);
8 if c≠0
9
then APPEND(~V.β, a-1⋅v); APPEND(~V., c);
10
for j∈[1.. d] do APPEND(~τλ[j], a-1⋅[j]);
11
else χ:=HORIZONTALJOIN(χ, );
MODULEHOMOMORPHISMS(M, L)
Input: Module records M, L with M proved irreducible by MEATAXE
Output: A K-basis of HomA(M, L)
1 ξL:=M.π(COPYTHETA(M, L));
2 N:=NULLSPACE(ξ); d:=|N.β|;
3 if d=0 then return [];
4 ΛM:=M.Λ; ΛL:=L.Λ;
5 wλ:=[N.β[j]:j∈[1..d]];
6
; τλ:=[[]:j∈[1..d] ]; χ:=[];
7 PVIS(M.v, wλ, ~V, ~τλ, ~χ);
8 i:=1;
9 while i≤|V.β|
10
do for k in [1..|ΛM|] do PVIS(
11
     V.β [i]⋅ΛM[k],[τλ[j][i]⋅ΛL[k]|j∈[1..d]], ~M, ~τλ, ~χ);
12     
i:=i+1;
13 N:=NULLSPACE(χ); µ:=(V.β)-1; h:=[];
14 for u∈N.β
15
do 
16
APPEND(~h,µ⋅v);
17 return h;
PVIS(M.v.wλ, ~V, ~τλ, ~χ) at line 7. Let M.Λ:=[α1,…, αr] and L.Λ:=
[δ1,…, δr] be the lists of action matrices of M and L, respectively. Then the
condition for ϕ to be a module homomorphism is that
 
for all V.β [i]∈V.β, and 1≤k≤r. We enforce these conditions by making the
corresponding calls of PVIS at line 11. Some of these calls will have the effect
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
244
of appending a new basis element to V.β and the remainder will yield dim(L)
linear equations satisfied by λ1,…, λd.
When this process is complete, we solve this system of linear equations
in the λj by calculating the nullspace of χ at line 13. A basis of this nullspace
can then be used to calculate and return a basis, called h in the code, of
HomA(M, L).
One problem with the code as it stands is that we may generate a very
large number of equations, and so the matrix χ can grow correspondingly
large. We can avoid this by keeping χ in column-echelonized form throughout.
Then it will never have more than d columns (or rather d+dim(N) columns
before echelonization) and, in fact, if it should ever have d columns after
echelonization, then we can conclude that the nullspace is trivial, which
means that there are no nonzero module homomorphisms, and we can abort.
7.5.3 Testing irreducible modules for isomorphism
Testing two modules M and L over an algebra A for isomorphism is not
straightforward in general because, even if we can compute HomA(M, L), it
is not clear how to check whether this contains a surjective homomorphism.
Some unpublished ideas for solving this problem have been proposed by
C.R.Leedham-Green and implemented in MAGMA, but we shall not discuss
them further here. In the situation where at least one of the modules to be
tested, say M, has been proved to be irreducible by a call of MEATAXE,
then there is an efficient test for isomorphism that is very similar to the
function MODULEHOMOMORPHISMS in the preceding section.
Before applying this method, we call ABSOLUTELYIRREDUClBLE(M)
to calculate the degree e of the centralizing field of M. The method only
works if the dimension d of the nullspace of M.π(M.θ) (which is the same
as deg(M.π)) is equal to e (we saw in Subsection 7.5.1 that d|e). So, if d≠e,
then we choose new random elements θ from the matrix algebra of M and
new irreducible factors π of the characteristic polynomial of θ  until we find
θ and π such that d=e. It is proved in [HR94] that the probability of a
random θ giving rise to π with this property is at least 0.144, and so we can
expect to find θ and π reasonably quickly. We shall assume for the remainder
of this subsection that this has been done.
The point of having this condition satisfied is that it ensures that, for
any two nonzero vectors in the nullspace NM of M.π(M.θ), there is an
element of the centralizing field of M mapping v to w and hence, if M and L
are isomorphic, then the same property holds for the corresponding elements
in L. Let NL be the corresponding nullspace in L. Then, if ϕ:M→L is a
module isomorphism, we must have ϕ(NM)=NL and, for any v∈NM\{0} and
w∈NL\{0}, we can assume, by composing ϕ with a suitable module
endomorphism of L, that ϕ(v)=w. This means that we do not need to maintain
d separate lists τλ[1],…,τλ[d] of possible images of vectors in M under ϕ, as
we did in MODULEHOMOMORPHISMS. We can also forget the
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
245
PVIS-I(v,w, ~V, ~τ)
Input: Vectors v in M, w in L
1 β:=V.β; γ:=V.γ;
2 for i∈[1.. |γ|]
3     
do a:=v[γ[i]];
4     
if a≠0
5     
then v:=v-a⋅ß[i]; w:=w-a⋅τ[i];
6 c, a:=DEPTHVECTOR(v);
7 if c≠0
8
then APPEND(~ V.β, a-1⋅v); APPEND(~V.γ, c);
9
APPEND (~ τ, a-1 ⋅w);
10 elseif w≠0 then return false;
11
return true;
MODULEISOMORPHISM(M, L)
Input: Module records M, L with M proved irreducible by MEATAXE
and M.e=deg(M.π)
Output: true or f alse; if true, a module isomorphism M→L
1 if dim(M)≠dim(N) then return false;
2 ΛM:=M.Λ; ΛL:=L.Λ;
3 ξL:=M.π(COPYTHETA(M, L));
4 N:=NULLSPACE(ξL); d:=|N.β|;
5 if d≠deg(M.π) then return false;
6 w:=N.β [1]; 
; τ:=[];
7 PVIS-I(M.v,w, ~V, ~τ);
8 i:=1;
9 while i≤|V.ß|
10
do for k∈[1..|ΛM|]
11     
do if not PVIS-I(V.ß[i]⋅ΛM[k],τ[i]⋅ΛL[k], ~V, ~τ)
12     
then return false;
13     
i:=i+1;
14 return true, (V.β-1)⋅τ;
coefficients λ1,…,λd and just work with a single basis of image vectors in L. If
we encounter a contradiction of any kind, then we can conclude that M and L
are not isomorphic. Otherwise, the function MODULEISOMORPHISM
computes and outputs an explicit module isomorphism from M to L.
7.5.4 Application—invariant bilinear forms
An easy but important application of isomorphism testing is to the
determination of invariant bilinear, sesquilinear, and quadratic forms for
matrix groups over finite fields. As we shall see later in this chapter, in
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
246
Subsection 7.8.2, computing with large classical groups in their natural
representation over a finite field is one of the more challenging cases to be
handled in the development of algorithms for finite matrix groups, mainly
because the groups involved are very large.
The best approach seems to be first to identify the isomorphism type of
the group G≤GL(d, q) with high probability, perhaps by doing some kind of
statistical analysis on the orders of its elements. We might then be
reasonably certain that G is the symplectic group Sp(d, q), for example.
But this only identifies G up to conjugacy in GL(d, q) and to progress further,
we need to identify the symplectic bilinear form fixed by G. Then we can, if
we wish, easily conjugate G to a group that fixes a standard symplectic
form, such as the antidiagonal matrix with entries αi,d+1—i=1 for 1≤i≤d/2
and αi,d+1—i=-1 for d/2+1≤i≤d.
The matrix A of the bilinear form fixed by G satisfies gAgT=A or,
equivalently, gA=A(g-1)T, for all g∈G. But this just says that A is a module
isomorphism from the d-dimensional module M over Fq defined by G to its
dual module MD. We can therefore find A by using the methods described in
Subsection 7.5.3. Provided that G acts absolutely irreducibly on M, A will
be uniquely determined up to a scalar multiple. We can use similar methods
to find sesquilinear and quadratic forms that are fixed by absolutely
irreducible matrix groups over finite fields.
7.5.5 Finding all irreducible representations over a
finite field
There are situations in which we need to find explicitly certain irreducible
representations of a finite group G over a finite field K. We might want to
find representatives of all irreducibles up to isomorphism, or all irreducibles
of degree less than a given bound. These may be required, for example,
when compiling various databases of groups, such as the perfect groups
databases and small groups databases to be discussed in Chapter 11.
Or perhaps, we know that a certain representation of some specific degree
exists, and we want to find it explicitly. Indeed, the Meataxe algorithm was
developed initially by Parker and others with this application in mind; the
aim was typically to construct a specific representation of a sporadic simple
group, usually over a very small finite field.
We shall briefly discuss some general methods for solving this problem
here. It should be pointed out that, for finite solvable groups, alternative
approaches are available (see Plesken’s article [Ple87]), which probably
perform better in practice if all representations are required.
The methods that we shall discuss here are based on an old result of
Burnside (see Section 226 of [Bur02]), which has become known as the
Burnside-Brauer theorem. This says that, if M is a faithful KG-module for
a finite group G over a field K, then any irreducible KG-module occurs as a
composition factor of the κ-th tensor power of M⊗k for some κ∈N. Since, for
KG-modules M, N, the composition factors of M⊗N all occur as composition
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
247
factors of Mi⊗Nj as Mi, Nj range over the composition factors of M and N,
this immediately suggests the following algorithm for finding all irreducible
KG-modules.
Start with a small collection of KG-modules Mi, at least one of which is
faithful. The easiest way to construct the Mi is as permutation modules coming
from low-degree (faithful) permutation representations of G. More generally,
they may be constructed as induced modules from small-degree representations
of subgroups of G. Use the Meataxe and isomorphism testing algorithms to
find all irreducible constituents of the Mi, and make a list of distinct irreducible
KG-modules. Various related irreducibles, such as duals and conjugates under
field automorphisms of the existing ones, can also be added to the list
immediately. Then, for each pair Ni, Nj of irreducibles found, find the irreducible
constituents of Ni⊗Nj and adjoin any new irreducibles to the list. Repeat
these steps until no new irreducibles are found.
This approach can be adequate when a specific representation is being
sought, or when the degrees of all of the irreducible modules are reasonably
small. But if some of the irreducibles have large degree, then we wish to
avoid tensoring these together whenever possible, because it becomes very
expensive and possibly impractical to use the Meataxe on modules of very
large degree (its complexity is at least O(d3)).
As a first improvement, we can make use of the following standard result
in modular representation theory; see, for example, Corollary 15.11 of
[Isa76]. An element g∈G is called p-regular if its order is coprime to p. Let
L≥K be a splitting field for G (see Subsection 2.7.1). Then the total number
of irreducible LG-modules is equal to the number of conjugacy classes of p-
regular elements of G.
In many applications, it is relatively inexpensive to compute the conjugacy
classes of G, and hence to determine in advance how many irreducible LG-
modules there are. Let us assume that we can do that.
For each KG-irreducible module M that we find, we use the procedure
ABSOLUTELYIRREDUCIBLE to calculate its centralizing field
C:=EndKG(M). It is easy to see that M corresponds to |C:K| distinct
absolutely irreducible CG-modules, and hence also to |C:K| distinct LG-
irreducibles. We get one of these by making M into a CG-module just by
using the action of C on M. The others are conjugates of this under the
|C:K| elements of AutK(C), where the matrices for a conjugate are obtained
by applying the field automorphism to the original matrices. These CG-
modules can easily be computed explicitly from the output of
ABSOLUTELYIRREDUCIBLE if required.
But whether or not we do this, we can keep count of the number of LG-
irreducibles that we have found so far, and hence we will know when we
have found them all. At that point, we will also have found all irreducible
KG-modules, and we can stop. Note that there is no need to determine L
explicitly, although it could be chosen to be the smallest finite field containing
all of the centralizing fields C that have arisen.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
248
Example 7.3
Let G:=Alt(7) and K:=F3. There are 6 classes of p-regular elements, with
representatives (), (1, 2) (3, 4), (1, 2) (3, 4, 5, 6), (1, 2, 3, 4, 5), (1, 2, 3, 4, 5, 6,
7), (1, 7, 6, 5, 4, 3, 2). We start with the natural 7-dimensional permutation
module M over K. The irreducible constituents of M are M1 and M6, where
the subscript indicates the dimension, and both are absolutely irreducible.
We find that M6⊗M6 has irreducible constituents M1, M6, M13, and M15, the
last two of which are new. Then M6⊗M13 has a new KG-irreducible
constituent M20 but this has centralizing field C:=F9, and so this corresponds
to two conjugate absolutely irreducible CG-modules, both of dimension 10.
So we have now found 6 absolutely irreducible LG-modules, with L=F9, and
we are done. Of course, we could check this by applying the Meataxe to the
other tensor products Mi⊗Mj, but this would be a waste of effort.
Unfortunately, there is no general result corresponding to the theorem
that, in characteristic 0, the sums of the squares of the degrees of the
absolutely irreducible representations is equal to |G|. So we have no
information that might help us to predict the degrees of the LG-modules.
There are further ways of improving this algorithm, however, and this
is still an ongoing area of research. One approach is to precompute the
Brauer character table of G with respect to the characteristic p of K. The
Brauer characters of the absolutely irreducible representations found so
far can then be computed, and it becomes possible to predict in advance
whether a given tensor product of irreducibles will yield new irreducibles.
The condensation methods mentioned in Subsection 7.4.5 can sometimes
be used on tensor products of large dimension. We omit the details, which
have not yet been published. It is not always completely clear that the
extra computations involving the Brauer characters will consume less
resources than the unnecessary Meataxe applications that are avoided,
but the indications are promising that this can be adapted into a worthwhile
general-purpose approach.
7.6 Cohomology
The cohomology groups Hn (G, M) for a group G acting on a KG-module M
for some ring K are defined for all integers n≥0, but the groups H1(G, M)
and H2(G, M) are the most relevant to group theory itself. As we saw in
Section 2.7, H1 (G, M) arises in connection with complements in semidirect
products, whereas H2(G, M) is intimately connected with group extensions
by abelian groups. For these reasons, it is important to have algorithms
available to compute H1 (G, M) and H2(G, M), at least for finite G and M.
Such algorithms are the topic of this section.
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
249
7.6.1 Computing first cohomology groups
Let G be a group acting on a KG-module M, where K is a commutative ring
with identity. We shall assume that M is free and finitely generated of
rank d as a K-module, so the action of an element g∈G on M can be
represented as an element ϕ (g)∈GL(d, K), where matrices are written
with respect to a fixed free basis [b1,…, bd] of M. We shall assume that the
module is defined by a list Λ of action matrices for a generating sequence
X=[x1,…, xr] of G; so Λ[i]=ϕ (xi) for 1≤i≤ r. Elements of M will be represented
as row vectors in Kd.
In this subsection, we shall describe a straightforward algorithm to
compute the first cohomology group H1 (G, M) as a K-module; see Subsection
2.7.2. Usually K is either a finite field or the integers Z. The former case
arises frequently in algorithms for investigating the structure of finite
groups: in automorphism group computation (Section 8.9) and in the
computation of all subgroups (Section 10.4), for example.
Occasionally, there is a need to carry out this calculation in cases when
M is not free as a K-module; for example, when K=Z and M is a finite
abelian group with invariant factors of different orders. The methods to be
described can be generalized to handle that situation, but we shall not
discuss it further here.
We shall compute H1 (G, M) as the quotient Z1(G, M)/B1(G, M). Let us
start with the computation of the K-module Z1(G, M) of crossed
homomorphisms (or derivations) G→M.
For this calculation, we need G to be defined by a finite presentation.
This is no problem if G is given as a PC-group (see Definition 8.7 below).
For a permutation or matrix group G, we can use the methods described in
Section 6.1 to compute a presentation, either on the original generating
set X of G or, for larger groups, on a strong generating set. In the latter
case, we can use the definition of the strong generators as SLPs in the
original generators to compute the required matrices ϕ(gi) for the strong
generators gi. But, in any case, let us assume from now on that G=〈X|R〉 is
given as a finitely presented group, where X=[x1,…, xr] and R=[w1,…, ws].
Example 7.4
As an example, we shall use the presentation 
of the group Alt(4) (generators x, y correspond to (1, 3, 2), (2, 3, 4) ∈ Alt(4))
acting on the permutation module over F3. So
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
250
By Proposition 2.73, a crossed homomorphism χ: G→M is specified
uniquely by the images χ(xj) of the generators of G in M. We shall represent
r-tuples of module elements (m1,…,mr) (mj∈M) by vectors v∈Krd, where,
for 1≤j≤r, the components of v in positions d(j-1)+1..dj define mj; that is,
v[d(j-1)+1..dj]=mj, written with respect to our fixed basis of M. In
particular, we shall represent χ∈Z1(G,M) by the corresponding vector in
Krd for (χ(x1),…,χ(xr)).
For an arbitrary such r-tuple (m1,…, mr), we need to test whether there
exists χ∈Z1(G,M) with χ(xj)=mj for 1≤j≤r. We saw in Proposition 2.73 that
such a χ must satisfy 
and, for a general element
 ∈G with each εi=±1,
where 
 when εi=1 or -1, respectively.
Furthermore, by Theorem 2.78, χ∈Z1(G,M) if and only if the above
expression evaluates to 0 for each w∈R.
Let mj=(zj1,…, zjd)∈Kd for 1≤j≤r. Then, for a word w, the condition χ(w)=0
reduces to a system of d equations in the rd unknowns:
To see this, let α(i)∈GL(d,K) be the matrix ϕ (gi) in the above expression (†)
for χ(w). Then 
 is just the vector mki⋅α(i), of which the i2-th component
(for 1≤i2≤d) is 
.
So, since there are s relators, each giving rise to d equations, the K-
module Z1(G,M) is given by the solution set of a system of sd equations in
rd unknowns; that is, by the nullspace of a certain rd×sd matrix Γ1. over K.
The function Z1-MATRIX calculates and returns this matrix Γ1. For 1≤k≤s,
the d equations arising from the relator wk∈R occupy the columns d(k-
1)+1..dk of Γ1. For each individual wk, we add the coefficients to Γ1 arising
from the terms 
 in the expression (†) in reverse order, i:=l, l-1,…, 1.
This allows us to compute the action matrix α:=α(i) as we go along.
We compute Z1(G,M) as the nullspace of the matrix Z returned by Z1-
MATRIX. If the ring K over which M is defined is a field, then we can use
the function NULLSPACE presented in Section 7.2 to do this. Another
case that arises frequently is K=Z. The nullspace in that case can be
computed from the matrix that transforms Z into Hermite normal form;
see Proposition 9.6 below.
In Example 7.4, Z will be an 8×12 matrix over F3. Let us work through
the computation on the third relator x-1yx-1y of G, which will define
columns 9..12 of this matrix. The loop beginning at line 12 of the
algorithm will have the effect of adding a certain 4×4 matrix to the
submatrix Z[1..4][9..12]
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
251
Z1-MATRIX(G, K, Λ)
Input: 
commutative ring K;
list Λ of r matrices over K defining KG-module
Output: Matrix with nullspace equal to Z1(G, M).
1
2 Z:=ZERO-MATRIX(K, dr, ds);
3 for k∈[1..s]
4     
do (* Fill in columns 
 of Z for relator wk *)
5     
c:=d( k-1);
6     
α:=IDENTITY-MATRIX(K, d);
     
(* Scan relator  k from right to left *)
7     
Suppose 
 with ε[i]=+1;
8     
for i∈[l..1 by -1]
9     
do j:ki; e:=ε[i]
10     
if e=-1 then α:=Λ[j] −1⋅α;
     
(* add α entries to Z in rows 
11     
r:=d(j-1);
12     
for i1 ∈[1..d], i2 ∈[1..d]
13     
do 
;
14     
if e=1 then α:=Λ[j]⋅α;
15 return Z;
(when j=1) or Z[5..8] [9..12] (when j=2) of Z, so let us denote these
submatrices as Z1 and Z2, respectively.
The i-loop at line 8 of the algorithm starts with i=4, and the fourth
generator of the relator is y, so we get j=2, e=1. The acting matrix a is the
identity, so the loop at line 12 adds the identity matrix to the Z2. We then
multiply a on the left by Λ[2] to give α=λ[2]. Moving back to i=3, we have
j=1, e=-1, so we multiply a on the left by Λ[1]−1, to give
and add -α to Z1. Proceeding to i=2, we have j=2, e=1 again, and so we add the
same α to Z2, before multiplying α on the left by Λ[2]. Finally, with i=1, we
have j=1, e=-1, so we multiply α on the left by Λ[1]_1 to give α=I4, and we add
–α to Z1.
We have now defined columns 9..12 of Z. Columns 1..4 and 5..8 are
defined similarly using the first two relators x3 and y3, and the complete
matrix Z over F3 returned is as shown below. The nullspace of Z is easily
computed and is spanned by the rows of the matrix N below.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
252
Returning to the general case, the K-module B1(G, M) is spanned by the
derivations 
, where [b1,…,bd] is our fixed K-basis
of M. So it is equal to the row-space of the d×dr matrix B, where the
entries in columns d(j-1)+1..dj of the i-th row of B define the element 
of M. In other words, B is just the horizontal join of the matrices Id-Λ[j] for
1≤j≤r. The following function returns B.
B1-GM(G, K, Λ)
Input: 
, X=[x1,…,xr], R=[w1,…,ws];
commutative ring K;
list Λ of r matrices over K defining KG-module M
Output: Matrix with row-space B1(G, M)
1
2
B:=ZERO-MATRIX(K, d, dr);
3
for j∈[1.. r]
4
do c:=d(j–1);
5
for 
6
do if i1=i2 then 
;
7
else 
;
8
return B;
In Example 7.4, the matrix B returned is as below; we have also calculated a
row echelonized matrix BE with the same row-space as B:
 
We see now that 
 has dimension 1 over
; that is, it has order 3. The derivation χ∈Z1(G, M) defined by the third
row of N, for which χ(x)=(0,0,0,1) and χ(y)=(1,0,2,1), maps onto a generator
of H1(G, M).
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
253
7.6.2 Deciding whether an extension splits
We can use methods that are very similar to those described in the previous
subsection to decide whether a given KG-module extension E of M by G splits.
Indeed, we use the matrix Z returned by Z1-MATRIX once more.
As in Subsection 2.7.3, we assume that the extension E contains M as a
subgroup, and that we have an epimorphism ρ:E→G with kernel M. We
shall assume that G and M are defined in the same way as in Subsection
7.6.1; that is, we have a finite presentation 
 of G, and a list of matrices
for the generators of G that define the module M. We assume also that we
can carry out basic computations with elements of E, and that we can readily
compute images and inverse images of elements under ρ.
In practice, E might be a finite permutation group with 
 and M an
elementary abelian p-group, in which case we take K=Fp. We could then
work with a generating set 
 of E, where X generates E modulo M, and
Y=[b1,…,bd] is a minimal generating sequence of M. A presentation of the
quotient group G=E/M could be computed by finding a presentation of E on
and 
 then adding the generators of M as relators. The map ρ would
then just map x∈
 to the corresponding generator x of G, and would
map all elements of Y to 1G. The action matrices Λ[i] for xi∈X could be
computed easily by expressing the elements yx, for x∈X, x∈Y, as words in Y.
This technique will be used as an essential part of our algorithm to find the
conjugacy classes of subgroups of a finite permutation groups, which will
be described in Section 10.4.
In any case, we start by choosing elements ∈E with 
 for all
x∈X. As in Subsection 2.7.3, let F be the free group on X and let θ:F→E be
the homomorphism defined by 
 for x∈X. Then we can compute the
elements θ(w) for w∈R and, since ρ(θ(w))=1G, we have θ(w)∈M for all w∈R,
so we can compute each θ(w) as a vector in M with respect to the free basis
[b1,…,bd] of M. Let 
 be defined by setting 
 to be
equal to θ(wk) for 1≤k≤s, where R=[w1,…,ws].
Let χ:X→M be a map. Then we can use (i) and (ii) of Proposition 2.73 to
extend χ to a derivation χ:F→M. By Proposition 2.77, the elements
 of E generate a complement of M in E if and only if
χ(w)=–θ(w) for all w∈R.
Let Z be the dr×ds matrix over K returned by Z1-MATRIX(G, K, Λ). In
Subsection 7.6.1, we saw that the maps χ:X→M for which χ(w)=0 for all
w∈R correspond to elements of the nullspace of Z. In the same way, the
maps χ satisfying χ(w)=–θ(w) for all w∈R are given by the solutions u, if
any, of the system of linear equations –vE=u⋅Z. As before, such solutions
are elements u∈Rrd, where 
 for 1≤j≤r. If u is one
such solution, then the general solution is of the form u+z for z in the
nullspace of Z. If there is no solution, then the extension does not split.
So deciding whether an extension splits can be done in a very similar
manner to finding all complements in a semidirect product. If K is a field,
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
254
then this is just elementary linear algebra. Solving a system of linear
equations –vE=u⋅Z over Z is also possible, and can be done by first finding
the Hermite normal form of Z. See Exercise 2 at the end of Section 9.2.
Example 7.5
Consider the following two subgroups of Sym(8). Let
and let E=〈x1, x2, x3, x4 〉, 
.
The reader can readily verify that both E and E′ contain the group M=
 as a normal elementary abelian subgroup of order 8, where 
. Furthermore 
 and 
 both
lie in M, so |E|=|E’|=16. Hence, if 
, then we can define
epimorphisms ρ:E→G and ρ′:E′→G by setting 
 and
 for 2≤i≤4.
In both cases, we have r=s=1. The matrix Λ[1], and the matrices Z and B
returned by Z1-MATRIX and B1-GM are as follows:
 
The nullspace of Z is spanned by B and (0, 0, 1), so H1(G, M) has dimension
1. In E, we have 
, so complements are given by solutions u of the
equation –vE=u⋅Z with vE=–vE=(1, 1, 0). One such solution is u=(1, 0, 0), so
there is a complement generated by x1x2. In E’, however, we have 
and the corresponding equation with 
 has no solution, so the
extension is nonsplit.
[]
7.6.3 Computing second cohomology groups
To determine all of the KG-module extensions of a KG-module M by a
group G, we need to compute H2(G, M). This problem is considerably more
difficult than computing H1(G, M). The immediate difficulty is that a 2-
cocycle τ:G×G→M is determined uniquely by its values τ(x, g) for x∈X (a
generating set of G) and g∈G, but not by τ(x, y) for x, y∈X. This means that
the underlying vector space for a straightforward attempt to compute Z2(G,
M) has dimension r|G|d, where |X|=r and d=dim(M), which makes such
a method impractical, even for groups of moderately large order.
Various applications, such as the algorithms to compile complete lists of
perfect groups and all groups up to a specified order to be described in Sections
11.3 and 11.4, depend on the ability to compute H2(G, M), so it is important
to devise practical methods for doing this.
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
255
Algorithms to solve this problem when and G is a finite permutation group
and K=Fp are described in the three papers of Holt [Hol84, Hol85a, Hol85b],
These are beyond the scope of this book. According to a standard result,
H2(G, M) is isomorphic to a certain subgroup of H2(P, M) for P∈Sylp(G), and
the algorithms first compute H2(P, M) and then proceed to identify the
appropriate subgroup. They were used heavily in the compilation of the lists
of perfect groups; see Section 11.3.
There is also an efficient algorithm to compute H2(G, M) when G is a
finite PC-group. This will be described later in Subsection 8.7.2. It is
essentially the same method as that used to compute H2(P, M) in the
preceding paragraph. It was used in the construction of the library of small
groups; see Section 11.4.
In both of the above applications, to help solve the isomorphism problem
beween the groups constructed, the action of Comp(G, M) on H2(G, M) as
defined in Subsection 2.7.4 was computed. This will also be discussed further
in the polycyclic groups context in Section 8.9.
The author is currently actively working on the development of some more
general methods to solve this problem, and some experimental
implementations in MAGMA exist already. The group G must still be finite,
but there is considerably more flexibility allowed for the module M.
7.7 Computing character tables
The first algorithm for computing character tables of finite groups was
described by Burnside in [Bur11], although it could not really be thought of
as a practical method at that time. He demonstrated it by using it to compute
the character table of the dihedral group D10, and even that was a tedious
computation. An implementation by John McKay is described in [McK70];
he was able it to apply it in earnest to compute the character tables of the
first two Janko sporadic simple groups J1 and J2. Improvements were
introduced by Dixon in [Dix67] and later by Schneider in [Sch90b].
The resulting algorithm remains today the best general-purpose method
available, although there are many improvements possible for skilled users
who know how to make use of additional information that may be available.
The Aachen-based CAS system [NPP84] was designed to give the user
maximum flexibility with calculations involving group characters, although
in recent years it has been superseded by GAP.
Here we shall content ourselves with providing a straightforward account
of the Burnside-Dixon-Schneider algorithm. We shall assume that the reader
has some familiarity with the rudiments of the character theory of finite
groups, and we shall use [Isa76] as our main reference.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
256
7.7.1 The basic method
Let C1,…,Cr be the conjugacy classes of the finite group G with representatives
gj∈Cj, and let hj:=|Cj|=G:CG(gj)|. We choose g1:=1, so h1=1.
We shall assume that the elements gj and their centralizers CG(gj) and
hence also the integers hj have been computed. There are efficient methods
for doing this in solvable groups defined by a PC-presentation, which will be
discussed in Subsection 8.8.4. For permutation groups, the gj were traditionally
computed by choosing random elements of G and testing them for conjugacy
with the elements already in the list until a complete set of class
representatives had been found. Conjugacy testing of elements and computing
centralizers was done using the methods described in Subsection 4.6.5. A
newer method for finding class representatives, which uses the methodology
to be discussed in Chapter 10, is described by Cannon and Souvignier in
[CS97].
We must also assume that the class map of G is easily computable. That
is, given g∈G, we must be able to quickly find the unique gj that is conjugate
to g in G. We do not, however, need to find a conjugating element, so in many
cases this can be done quickly by considering the order |g| of g or perhaps,
if G is a permutation group, the cycle-type of g. In more difficult cases, it
might be necessary to test g explicitly for conjugacy with some of the gj that
have the same order or cycle-type as g. Since large numbers of applications of
the class map will generally be necessary for the computation of the class
matrices Mj to be described below, if there is enough space available then it is
worthwhile to precompute and store its values on all elements of G.
Let 1,…,r be the irreducible characters of G, and let 
 for
1≤i, j≤r. Let 
 be the degree of i. For 1≤j, k, l≤r, fix z∈Cl, and let cjkl
be the number of pairs (x, y)∈Cj×Ck with xy=z. Then it is proved in
Proposition 3.7 of [Isa76] that, for 1≤i, j, k≤r,
(7.1)
For 1≤j≤r, let Mj be the r×r matrix whose (k, l)-entry is cjkl. Then the
Equations 7.1 say that, for each 1≤i≤r and each 1≤j≤r, the column vector
 is a right eigenvector of Mj.
In the Burnside and the Dixon versions of the algorithm, the Mj and their
eigenvectors are computed, from which the values of 
 can be found. It
is then not difficult to compute the di and, since the hj are already known, we
can find the required character values 
.
Schneider, however, found it more convenient to use a slightly different
version of the Equations 7.1, so we shall do that here, too. Throughout this
section, whenever j∈[1..r], we shall use j′  to denote the integer in [1..r] such
that 
; so 
. Since |Cl|=hl, the total number of triples
 with xy=z is equal to hlcjkl But this is also equal to
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
257
the total number of such triples with y=x—1z, and so hlcjkl=hkcj’lk. Making this
substitution in the right-hand side of the Equations 7.1, simplifying, and
then interchanging j and j′ yields
(7.2)
for 1≤i, j, k≤r, which says that the row vectors 
 are left eigen-
vectors of Mj for 1≤i, j≤r.
We compute the matrices Mj column by column. To get column l of Mj, we
fix z=gl and determine the conjugacy class of y=x-1z, for each x∈Cj. Then
the (k, l)-entry of Mj is just the number of these y that are in Ck. This
calculation requires a large number of applications of the class map, which
can be slow. As we shall see later, we can often avoid computing more than
the first column of some of the Mj. To find all of the elements of Cj, we need
a right transversal of CG(gj) in G, which we would normally compute and
store at the same time as we find the gj and CG(gj) themselves.
7.7.2 Working modulo a prime
A disadvantage of the original method as described by Burnside and as
implemented by McKay [McK70] is that it involves floating point computations
over the complex numbers, and the character values are returned as floating
point approximations. If the character χ of G has degree d and g∈G, then
χ(g) is a sum of d |g|-th roots of unity, and it is considerably more convenient
to have it returned in that form. It would be possible in principal to perform
the calculations exactly in an appropriate algebraic number field, but it
turns out that the desired results can be found much more efficiently by
performing the eigenvector computations modulo a suitable prime p, and
then lifting the result back to the complex numbers. This was the principal
improvement introduced by Dixon in [Dix67], and we shall describe it briefly
in this subsection.
Let e be the least common multiple of the orders of the elements g∈G.
Then, if ζ is a complex e-th root of unity, all character values 
 lie in the
ring 
. By [Isa76, Theorem 3.7], the numbers 
 are algebraic integers.
Since they lie in |ζ|, of which 
 is the ring of integers [ST02, Theorem
3.5], we have 
. Hence the Equations 7.2 are equations in 
.
Now choose a prime p with e|p-1 and p>2di for 1≤i≤r. Of course, we do
not know the di yet but, since 
 [Isa76, Theorem 3.7], we can
satisfy this condition by choosing 
. Since e|p–1, the field Fp has
an element ω with multiplicative order e, and the mapping
 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
258
defines a ring homomorphism Θ:Z[ζ]→Fp. Then, by applying Θ to the
Equations 7.2, we obtain a corresponding system of equations over Fp.
Let X be the r×r matrix with (i, j)-entry equal to 
—so X is the
character table of G—and let Y be the r×r matrix with (j, i)-entry equal
to 
. Then, by the orthogonality relations of character theory [Isa76,
(2.18)], we have XY=|G|Ir. In particular, the rows 
 of X
which, by the Equations 7.2 are eigenvectors of each matrix Mj for 1≤i,
j≤r, are linearly independent. Since all primes q dividing |G| divide e
and e|p–1, p does not divide |G|, and so the vectors Θ(X[i]) are also
linearly independent over Fp.
For two rows X[i] and X[i′] of X, the corresponding eigenvalues 
and 
, cannot be equal for all j, for otherwise columns i and i’ of Y
would be linearly dependent. Again the same applies to their images under
Θ. So the vectors Θ(X[i]) are uniquely determined up to scalar multiples as r
linearly independent common eigenvectors of the matrices Θ(Mj) (1≤j≤r).
Assuming that we have calculated the class matrices Mj for 1≤j≤r, we
can apply Θ to obtain images Θ(Mj) over Fp. We can use the methods
described in Sections 7.2 and 7.3 to compute and factorize the characteristic
polynomials of the Θ(Mj) to obtain their eigenvalues, and then find their
eigenvectors. We can thus obtain r linearly independent common
eigenvectors υ1,…, υr over Fp of the matrices Θ(Mj). We shall return to this
part of the computation in the next subsection, where we shall see that it
is normally unnecessary to evaluate all of the Mj.
Let us normalize the υi to make υi[1]=1 for all i. Each υi is a scalar multiple
of some row of Θ(X), which we can assume to be Θ(X[i]). Since
, we have υi=Θ(X[i])/di, and hence
 
We can evaluate the left-hand side of this equation, and the fact that p>2di
enables us to determine di uniquely from the value of  modulo p. So we can
find Θ(X[i])=diυi and hence the matrix Θ(X).
The final step of the algorithm is to recover X from Θ(X). Since each 
 is
a sum of di powers of ζ, we have 
 for integers mijk satisfying
, and we need to find the mijk. The key to achieving this objective
is the following lemma.
LEMMA 7.1 Let 
. Then
(7.3)
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
259
PROOF For any l∈Z, we have 
. Substituting in
the right-hand side of Equation 7.3 yields the expression
 
Since 
, the inner sum evaluates to e if k′=k and to 0 otherwise,
and the result follows.
Let us denote the number of the conjugacy class containing  by j(l); so
. Then applying Θ to Equation 7.3 yields
 
Hence we can evaluate mijk modulo p but, since 0≤mijk≤di<p, this is
sufficient to find the mijk themselves.
Here is a summary of the complete algorithm.
1. Let e:=lcm({|gj||1≤j≤r}).
2. Choose a prime p with e|p–1 and 
.
3. Calculate the matrices Mj for 1≤j≤r and let Θ(Mj) be Mj reduced
mod p.
4. Find r linearly independent common eigenvectors [υ1,…,υr of the
matrices Θ(Mj), with υi[1]=1 for 1≤i≤r.
5. For 1≤i≤r, let di be the unique integer with 1≤di<p/2 that satisfies
 (mod p).
6. Compute the character values 
 from 
 as described
above.
Example 7.6
Let G:=Alt(4), and choose class representatives g1=1, g2=(1, 2)(3, 4), g3=(1, 2,
3), g4=(1, 3, 2), with h1=1, h2=3, h3=h4=4. Then e=6, and we can choose p=7
and w=3.
The first matrix M1 is always the identity matrix, and so is not useful for
calculation of eigenvectors. The remaining Mj are
 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
260
Now M2 has an eigenvalue 3 with multiplicity 3, which is not very useful
for finding linearly independent eigenvalues. The characteristic polynomial
of M3 (and also of M4) is x4+6x, which factorizes to x(x+3) (x+5) (x+6) and so
we can use M3 alone to find the required eigenvectors. (We shall see in the
next subsection that we cannot always use a single Mj for this purpose.) The
normalized eigenvectors corresponding to eigenvalues 0, -3, -5, -6 are
 
from which we calculate d1=3, d2=d3=d4=1. We can now use the lemma to
compute the character table X, which yields
 
where ζ is a primitive complex 6th root of unity, and we have replaced ζ3 by
-1. Of course, this character table would normally be printed with the unit
character, which is X[2], as the first row.
[]
With small examples like this, it is not really necessary to use the lemma to
lift character values from Fp to Z[ζ]. The knowledge that 
 is a sum of di
|gj|-th roots of unity allows us to guess the lifted value very quickly.
7.7.3 Further improvements
The algorithm as described so far is essentially that of Dixon [Dix67], except
that we have followed Schneider in calculating characters as left row eigen-
vectors of the matrices Mj. Now we shall describe some of the improvements
introduced in [Sch90b].
The bulk of the computing time goes into the calculation of the class matrices
Mj, and so we aim to compute as few as these as possible and to avoid
evaluating all columns of a particular Mj. (As explained earlier, we compute
Mj a column at a time.) Notice that the first column of Mj has the single
nonzero entry hj in row j′, so all first columns are known already.
The improvements to be discussed affect only Steps 3 and 4 of the
algorithm. We do not compute all of the Mj in advance; rather, we compute
them (completely or partially) one-by-one and, after each such computation,
we attempt to complete Step 4 using only the Mj found so far. (A heuristic
is suggested in [Sch90b] for deciding the order in which to compute the Mj.)
We maintain the notation of the previous subsection. So X is the matrix of
character values, ζ is complex e-th root of unity with e the exponent of G,
and Θ:Z[ζ]→Fp is a ring homomorphism for a suitably chosen prime p. We
define a character space to be a subspace of Fr
p spanned by some of the
rows of the matrix Θ(X).
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
261
We start by choosing some j>1 and evaluating Mj. Since 
r is spanned by
the eigenvectors of Θ(Mj), we have 
Vt, where the Vi are the
distinct eigenspaces of Θ(Mj). Notice that the Vi are all character spaces.
They are the nullspaces of Θ(Mj)—λiIr for the eigenvalues λi of Θ(Mj), and
we compute echelonized bases of the Vi using NULLSPACE from
Section 7.2.
If dim(Vi)=1 for all i, then we have completed Step 4 of the algorithm. In
general, however, we will have dim(Vi)>1 for some Vi, and then we need to
use a different Mj to split Vi into smaller dimensional character spaces.
The following lemma from [Sch90b] shows that we can decide whether a
particular Mj will split Vi just from the first column of Mj, which is already
known. So we need never evaluate an Mj unnecessarily.
LEMMA 7.2 Let b1,…, bs be an echelonized basis of a character space V, and
let W be the subspace of V spanned by b2,..., bs. Then V is contained in a
single eigenspace of Θ(Mj) if and only if W is fixed by Θ(Mj).
PROOF If W lies in a single eigenspace of Θ(Mj), then all nonzero vectors
of W are eigenvectors of Θ(Mj), so clearly W is fixed by Θ(Mj).
Conversely, suppose that W is fixed by Θ(Mj) but that V is not contained
in a single eigenspace of Θ(Mj). So V contains eigenvectors v1 and v2 for
distinct eigenvalues λ1 and λ2 of Θ(Mj). Now the intersection of V with an
eigenspace of Θ(Mj) is a character space and so it is spanned by rows of
Θ(X), all of which have a nonzero first entry. Since b1 is the only basis
vector of V with nonzero first entry, we may assume that v1=b1+w1 with
w1∈W1 and similarly v2=b1+w2. Hence v1Θ(Mj)=λ1v1=λ1b1+λ1w1 and, since W
is fixed by Θ(Mj), b1Θ(Mj) must have 1 as its first component. But, by the
same argument applied to v2, b1 Θ(Mj) must have λ2 as its first component,
contradicting λ1≠λ2.
So the character space Vi lies in a single eigenspace of Mj if and only if each
of its echelonized basis vectors b2,..., bs has zero in position j′. If not, then
we can use Mj to decompose Vi into smaller character spaces. In fact, if the
first nonzero entries of b1,..., bs are in columns k1,…, ks then, to calculate
the induced action of Θ(Mj) on Vi, we only need columns k1,…, ks of Mj and
so we need only evaluate these columns. Of course, if the same Mj is used
to decompose more than one Vi, then the different Vi may require the
evaluation of different columns of Mj.
Here is the modified version of Steps 3 and 4 of the algorithm in
Subsection 7.7.2.
3. Calculate Mj for some j with 1<j≤r.
4. Compute the set V:={V1,…,Vt} of eigenspaces of Θ(Mj) and an
echelonized basis of each Vi.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
262
While there exists i with dim(Vi)>1 repeat the following:
3'. Find a j such that Vi is not contained in a single eigenspace of Θ(Mj).
Calculate the columns of Mj corresponding to the positions of the leading
entries in the echelonized bases of each Vi that has this property.
4'. For each Vi not contained in a single eigenspace of Θ(Mj), compute
the eigenspaces Vi1,…, Viti of Θ(Mj) on Vi together with their
echelonized bases, and replace Vi by Vi1,…, Viti in V.
Example 7.7
Let 
 Then |G|=12. There are 6
conjugacy classes, and we choose g1=1, g2=x2, g3=y, g4=x, g5=x-1, g6=x2y, so
h1=h2=1, h3=h6=2, h4=h5=3. Note that 4'=5 and j=j′ for j=1,2,3,6. We have
e=12, so we can choose p=13.
Let us start with
 
The characteristic polynomial of Θ(M6) factorizes over the ring 
 as
(x+1)(x+2)(x+11)(x+12), and the matrices of the echelonized bases of the
corresponding eigenspaces (which we also denote by Vi) are
 
Now, for i=2 and 3, we see that the second basis vector b2 of Vi has a
nonzero in position j for j=4 or 5, which means that we can use either of
M4 or M5 to split these two subspaces. Let us use
 
(Note that we need only the first and fourth columns of M4 to compute its
action on V2 and V3.) We find that the eigenspaces of M4 on V2 are spanned by
vectors (1, 12, 1, 8, 5, 12) and (1, 12, 1, 5, 8, 12), whereas those on V3 are
spanned by (1, 1, 1, 1, 1, 1) and (1, 1, 1, 12, 12, 1). This completes the
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
263
decomposition of 
 into one-dimensional character spaces. Using Step 5
of the original algorithm, we can calculate the degrees di (which are
2,1,1,1,1,2) and thereby find Θ(X). Then we can use Step 6 to compute X.
Choosing 2 as our element ω of order 12 in 
, we get the result:
 
If we happen to know some of the irreducible characters of G before we
start the computation, then we can use these to improve the algorithm.
Define an inner product 〈,〉 on  by 
. Then the matrix
equation XY=|G|Id implies that the rows of Θ(X) are mutually orthogonal
under this inner product. So we can compute the subspace V of 
 of vectors
that are orthogonal to all of the known characters (or rather their images
under Θ), and carry out our eigenspace computations in V rather than in 
.
In particular, it is generally worthwhile to compute the linear characters
of G in advance, and then to apply the main algorithm within the orthogonal
complement of the space that they span. The linear characters are just the
homomorphisms from G/[G, G] to the multiplicative group 
 of the nonzero
complex numbers, and these can be easily computed as follows. Express
G/[G, G] as a direct product of cyclic groups 
. Then
 
where Hom
 is cyclic of order ri, and is generated by the
homomorphism mapping a generator of 
 to a primitive complex ri-th
root of unity.
Here is another trick to avoid having to calculate class matrices. If, after
an intermediate pass of the algorithm, we have found one or more one-
dimensional character spaces Vi, then we will have found some corresponding
irreducible characters χi with dim(χi)>1. Then the tensor product of two
not necessarily distinct such characters 
 is a (generally reducible)
character of G given by 
. By computing the inner
product 
 for the already known irreducible characters χ of G,
we can subtract from 
 all of its irreducible components that are known
characters, and hope that what remains will be a single new irreducible.
Schneider reports in [Sch90b] that this does not happen sufficiently often for
it to be worthwhile to do it by default, but it can occasionally be very effective
in interactive implementations of the algorithm, which allow the user to
choose a strategy after each pass.
[]
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
264
Finally, we note that a character space of dimension two can very often
be split without calculating a further class matrix; see [Sch90b] for details.
Exercise
1.
Show that the dihedral and quaternion groups of order 8 both have 5
conjugacy classes. Calculate their class matrices, show that they are the
same for D8 and Q8, and deduce that D8 and Q8 have the same character
tables. Compute this character table.
7.8 Structural investigation of matrix groups
As we discussed in Chapter 3, there are three basic methods of representing
groups on a computer: groups of permutations of a finite set, groups of matrices
over a ring, and groups defined by a finite presentation. Chapter 4 is devoted
to computing in permutation groups, whereas algorithms for computing with
groups defined by a finite presentation are handled in Chapter 5 and also in
several later chapters of the book. That leaves matrix groups, which are the
topic of this section.
As we shall see in the first subsection, finite matrix groups of moderate
order and degree can be handled satisfactorily either by converting them explicitly
to permutation groups acting on vectors or subspaces of their underlying vector
space or, better, by extending the notion of base and strong generating set from
permutation groups to matrix groups. This approach does not work for larger
matrix groups, and it is only during the past decade that attempts have been
made to develop effective algorithms in this area. This is currently an active
area of research in CGT, and a detailed discussion lies outside the scope of this
book, but we shall provide a summary of the methods developed together with
pointers to the literature.
7.8.1 Methods based on bases and strong generating sets
Recall from Chapter 4 that a base and strong generating set (BSGS) is a key
concept in investigating the structure of a permutation group. See Section
4.4 for definitions, and for a descriptions of the Schreier-Sims and random
Schreier-Sims algorithms for computing a BSGS in a finite permutation
group.
We now outline how this concept of fundamental computational importance
for permutation groups has been adapted to matrix groups defined over finite
fields.
There is of course a natural action of a matrix group G≤GL(d, q) on the
underlying vector space. Let V denote the d-dimensional space of row vectors
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
265
over the field F=
q. We define the action of g∈G on v∈V by vg=v⋅g. This
action is clearly faithful, so G can be considered as a permutation group
acting on the vectors of V.
We can now apply the Schreier-Sims algorithm to G and construct a
BSGS for its action on the vectors of V, where we take the base points to be
standard basis vectors for V.
A central component in constructing a BSGS is the computation of the
basic orbits—namely, the orbits of the base points ßi under G(i) for i=1,…, k.
The performance and range of application of the technique depends greatly
on the sizes of these basic orbits.
Observe that the size of V is qd and so grows exponentially with d. Hence
the basic orbits obtained can be very large; with simple groups in particular,
the first basic index is often the order of the group.
One technique for finding smaller basic orbits is to consider the action of
G on a set other than the vectors of V; for example, the set of subspaces of V
having a specified dimension. Often this action is not faithful, but we can
ensure that it becomes so by adding some vectors as additional base points.
The first application of the Schreier-Sims algorithm to matrix groups
defined over a finite field was by Butler [But76, But79]. In an attempt to
reduce the size of the basic orbits, he considered the action of G on the
onedimensional subspaces of V. The use of these subspaces may reduce the
size of the basic orbits by a factor of up to q–1. Since the action of G on the
subspaces need not be faithful, each subspace in the base is followed by a
nonzero vector contained in it.
Murray and O’Brien [MO95] developed and investigated a more general
strategy for selecting base points for matrix groups, which we expect a
priori to have ‘small’ orbits under the action of a subgroup in the stabilizer
chain of a matrix group. In summary, the strategy selects some common
eigenvectors for a collection of elements of the group and then uses them
and related spaces to obtain a base.
We now consider this strategy in more detail. Let A be a generator of G
and let g(x) be a factor of the characteristic polynomial of A that is irreducible
over 
q. We call v∈V a generalized eigenvector if v⋅g(A)=0, but throughout
this section we shall refer to such a v simply as an eigenvector. The subspace
of all such eigenvectors is the eigenspace of A corresponding to g(x). We do
not require that g(x) be linear. If g(x) has degree m, the size of the
corresponding orbit is bounded by qm–1. Hence we choose as base points
eigenvectors corresponding to a factor that has as small a degree as possible.
Now suppose that g(x)=xm–λ, for some λ∈
q. Then the orbit 
 contains
at most m(q–1) points, since 
 and λq-1=1. Investigations suggest
that it is also useful to choose as base points eigenvectors corresponding to
a factor that has as few nonzero terms as possible.
An eigenvector of one generator need not have a small orbit under the
action of a member of the stabilizer-chain. However, we can improve the
probability of finding a small orbit by using a base point that is an eigenvector
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
266
of more than one group element. First we calculate the set of eigenspaces
of the generators and add to it all of the nontrivial intersections of these
spaces. We order the elements of this set by considering the polynomial
factors corresponding to each subspace and giving precedence to those spaces
whose factors have the lowest degree and the smallest number of nonzero
terms. We now choose as our good base points one vector from each of the
list of spaces. When we select a vector as a base point, we always precede
it in the base by the corresponding one-dimensional subspace. An alternative
is to choose the complete subspaces, rather than selecting a vector from
each. Occasionally, this can result in a reduction in orbit size sufficient to
compensate for the increased time taken to calculate images.
One problem with this strategy is that the generating set for G usually
contains very few elements; for example, every sporadic simple group can
be generated by two elements. We can greatly improve our chances of
finding a small orbit by also calculating eigenvectors of a number of random
elements of the group. This not only improves our chances of finding a
‘good’ eigenvector, but also allows us to choose base points that are
simultaneously eigenvectors of a larger number of group elements.
An additional criterion that proved useful is the sparseness of a row-
space, defined as the number of zeros in the row-reduced matrix of basis
vectors divided by the dimension of the space. Hence, we used sparseness
as one of the criteria for ordering the intersections.
The algorithm to select base points is summarized below. The eigenspaces
and intersections are sorted according to five criteria. Only the first of
these has theoretical justification; the inclusion and order of the remaining
criteria is largely based on experimentation.
GOODBASEPOINTS(G)
Input: Group G≤GL(d,q)
Output: List L of base points of G for use with Schreier-Sims
1
Construct a number of random group elements;
2
Calculate eigenspaces of the generators and random elements;
3
Calculate all nontrivial intersections of the eigenspaces;
4
Let L be the resulting list of eigenspaces and intersections;
5
Order L by the following criteria:
6
Smallest degrees of corresponding factors,
7
Smallest numbers of nonzero terms in corresponding factors,
8
Largest number of eigenspaces intersected,
9
Greatest sparseness,
10
Smallest dimension;
11
Return L;
In seeking to order the collection of subspaces, we first order the eigenspaces
according to the first two criteria, and then choose the best from the relevant
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
267
factors as the corresponding factor for an intersection. Now we can sort all
of the subspaces according to the five criteria.
Example 7.8
We illustrate by a simple example that the choice of base points is significant.
Consider the first Janko simple group J1 of order 175560, which has an
irreducible representation of degree 14 over 
11. Two generating matrices
for this representation of J1 are displayed below.
Let V be the natural vector space of degree 14 over 
11 on which G acts.
If the first base point is chosen to be either the first standard basis vector
V.1 or the one-dimensional subspace 〈V.1〉, then the first basic orbit has
length 175 560, the order of G. 
Let g be the following random element of G:  
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
268
All nonzero elements of 
11 occur as eigenvalues of g, where 1, 2, 6, 10
havemultiplicity 2. The eigenspace for 3 is the 1-dimensional space
If we choose as the base points 
 then the basic orbits have lengths
8778 and 20. Of course, we achieved a smaller basic orbit at the cost of
computing and storing images of a 2-dimensional space. If we choose the
other eigenspaces of g (or random vectors from these spaces) as the first
base point for G, we observe identical behaviour.
The first generator of G has an eigenvalue 1 with multiplicity 6. Random
vectors from its 6-dimensional eigenspace have orbits under the action of
G of length 87 780; the eigenspace itself has an orbit of length only 1540.
Again we must compare the relative cost of computing and storing images
of spaces of dimension 1 or 6.
Of course, it is possible that all of the computed characteristic polynomials
are irreducible and the resulting intersection is the complete space. If this
occurs, our method will choose a base consisting of standard basis vectors:
it defaults to Butler’s strategy of choosing subspaces of dimension one,
where each subspace is followed by a spanning vector.
By choosing base points that give shorter basic orbits, we extend
significantly the range of application of the Schreier-Sims. These algorithms
are the most important component of the current machinery for structural
investigation of matrix groups. Implementations are available in GAP and
MAGMA. While this model borrows heavily from permutation groups,
algorithms in MAGMA do not rely on writing down an explicit permutation
representation for the matrix group. Instead they use, as a central component,
the (permutation group) concept of a stabilizer-chain, where one stabilizer
has ‘moderate’ index in its predecessor. Some of these algorithms mimic
their counterparts for permutation groups, in making use of the stabilizer-
chain. For details of the algorithm to construct, for example, centralizers of
elements of matrix groups, see the paper by Butler and Cannon [BC82].
7.8.2 Computing in large-degree matrix groups
In practice, many structural questions cannot be answered for an arbitrary
matrix group, because a stabilizer-chain having ‘moderate indices’ simply
does not exist (or, less commonly, cannot be found).
Critical to the successful application of the Schreier-Sims algorithm is
the index |G(i):G(i+1)|. Since Sn has a subgroup Sn-1 of index n, we obtain a
If we choose as the base points [E, 〈V.1〉], then the basic orbits have lengths
17556 and 10. The eigenspace for 1 is the 2-dimensional space
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
269
where the leading index is qd-1 and so grows exponentially with d.
In practice, many matrix groups may have no ‘small-degree’ permutation
representation and so no useful stabilizer-chain. For example, the largest
maximal subgroup of the sporadic simple group J4≤GL(112, 2) has index
173 067 389.
Thus, in many cases, the stabilizer-chain approach is limited to matrix
groups of degree up to about 10; however, any such claim is highly dependent
on the defining field.
Hence, it is frequently impossible to study the structure of a matrix
group of relatively small dimension. In particular it may be impossible to
answer such a fundamental question as the order of the group. Indeed, it is
only recently that the order of a single matrix can be found efficiently,
using the algorithm of Celler and Leedham-Green [CLG97].
The paucity of effective tools for their study has prompted a major ongoing
international research program to develop effective algorithms for structural
investigations of matrix groups.
One of the competing approaches seeks to investigate instead whether a
matrix group G satisfies certain natural and inherent properties in its action
on the underlying vector space. If we can decide these questions, then we
exploit this additional insight to assist us in analyzing the group structure.
A classification of the maximal subgroups of GL(d, q) by Aschbacher
[Asc84] underpins this approach. Let Z denote the group of scalar matrices
of G. We say that G is almost simple modulo scalars if there is a nonabelian
simple group T such that T≤G/Z≤Aut(T), the automorphism group of T.
We can summarize Aschbacher’s classification as follows: a matrix group
preserves some natural linear structure in its action on the underlying
space and has a normal subgroup related to this structure, or it is almost
simple modulo scalars. More formally, we can paraphrase the theorem as
follows.
THEOREM 7.3 Let V be the vector space of row vectors on which GL(d, q)
acts, let G be a subgroup of GL(d, q), and let Z be the subgroup of scalar
matrices of G. Then one of the following is true:
1.
G acts reducibly.
2.
G acts imprimitively: G preserves a decomposition of V as a direct
sum 
 of r>1 subspaces of dimension s, which are
permuted transitively by G, and so G≤GL(s, q) U Sym(r).
‘nice’ subgroup chain, and hence the algorithm performs well even for large
values of n. However, the ‘optimal’ subgroup chain for GL(d, q) is
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
270
3.
G acts on V as a group of semilinear automorphisms of a space of
dimensional d/e over the extension field 
qe for some e>1, and so
G embeds in ΓL(d/e, qe). (This covers the class of ‘absolutely
reducible’ matrix groups, where G embeds in GL(d/e, qe).)
4.
G preserves a decomposition of V as a tensor product U⊗W of
spaces of dimensions d1, d2>1 over F. Then G is a subgroup of a
central product of GL(d1, q) and GL(d2, q).
5.
G is definable modulo scalars over a subfield: for some proper
subfield 
q´ of 
q, Gg≤GL(d, q).Z for some g∈GL(d, q).
6.
For some prime r, d=rm and G/Z is contained in the normalizer
of an extraspecial group of order r2m+1, or of a group of order 22m+2
and symplectic type.
7.
G is tensor-induced: it preserves a decomposition of V as
 Vm, where each Vi has dimension r>1 and the set of
Vi is permuted by G, and so G/Z≤PGL(r, q) U Sym(m).
8.
G normalizes a classical group in its natural representation.
9.
G is almost simple modulo scalars.
Of course, the nine Aschbacher categories are not mutually exclusive.
In broad outline, this theorem suggests that a first step in investigating
a matrix group G is to determine (at least one of) its categories in the
Aschbacher classification. If a category of G can be recognized, then we can
investigate its structure more completely using algorithms designed
specifically for members of this category. Sometimes, this investigation
will be greatly facilitated because we have reduced the size and nature of
the problem. For example, if G acts imprimitively, then we obtain a
permutation representation of degree at most d for G; if G is a tensor
product, we now consider two matrix groups of smaller degree. Where a
relevant normal subgroup N exists, (as it does for the first 7 cases), we
recognize G/N recursively, ultimately obtaining a composition series for
the group. If a composition series can be constructed for G, then we expect
that many questions about the structure of G can be answered by solving
first the problem for the composition factors of G.
What can we say about the almost simple groups? Liebeck [Lie85] proved
that the maximal nonclassical subgroups of GL(d, q) have order at most
q3d. Since these are small by comparison with GL(d, q) (which has order
, it may be possible to identify these groups using variations of
stabilizer-chain techniques.
We provide here only a top-level summary of the substantial work carried
out on certain parts of this project.
© 2005 by Chapman & Hall/CRC Press

Representation Theory, Cohomology, and Characters
271
1.
The Meataxe, initially developed by Parker [Par84] and later
generalized and analyzed by Holt and Rees [HR94] can decide if
matrix groups, having degrees up to the high hundreds, are
reducible. This was described in detail in Section 7.4.
2.
An algorithm to decide whether a group acts imprimitively is
presented in [HLGOR96b].
3.
An algorithm to decide whether a group is ‘absolutely reducible’
is presented in [HR94]. The general case of semilinear groups is
considered in [HLGOR96a].
4.
An algorithm to decide whether a matrix group preserves a
tensor-decomposition of the underlying vector space is presented
by Leedham-Green and O’Brien in [LGO97b, LGO97a].
5.
An algorithm to decide if a group is conjugate to one defined
over a smaller field was developed by Glasby and Howlett in
[GH97].
6.
An algorithm to recognize whether a given subgroup G of GL
(r, q) contains a normal extraspecial r-group of order r3 and odd
prime exponent r is presented by Niemeyer in [Nie]. (This is the
extraspecial normalizer case for m=1.)
7.
An algorithm to decide if a matrix group is tensor-induced is
presented by Leedham-Green and O’Brien in [LGO02].
As part of the research program, two major types of algorithms have been
developed.
•
Nonconstructive recognition algorithms identify or ‘name’ a
group.
•
Constructive recognition algorithms ‘name’ the group G, provide
a constructive homomorphism from the group to a ‘useful’ (or
natural) representation H of G, and permit an arbitrary element
of G to be written as a word in the generators of G.
A seminal paper by Neumann and Praeger [NP92], which presents a
nonconstructive algorithm for the special linear group in its natural
representation, provided much of the impetus for the Aschbacher-based
research program. Algorithms to recognize other classical groups in their
natural representation are developed by Niemeyer and Praeger in
[NP98].
Constructive recognition algorithms for black-box groups isomorphic to
the alternating and symmetric groups are presented by Bratus and Pak in
[BP00] and by Beals, Leedham-Green, Niemeyer, Praeger, and Seress in
[BLGN+02].
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
272
If a simple group is known to be sporadic, then it can be named readily,
usually by considering element orders. Various constructive recognition
algorithms have been developed for these groups. The Schreier-Sims
algorithms can exploit known chains of subgroups described via the standard
generators for such groups defined by Wilson in [Wil96]. An alternative
approach reduces the problem of writing g∈G as a word in its generators to
writing related elements of G as words in the generators of centralizers of
involutions; see [HLO+04].
The classical groups in their natural representation and the groups of
Lie type in arbitrary representations constitute the most difficult
outstanding cases.
If the group is a classical or exceptional group of Lie type in an arbitrary
representation where the defining characteristic is known, then the
polynomial-time Monte Carlo algorithm described in [BKPS02] names the
group. More generally, it names the nonabelian composition factor of a
quasi-simple group of Lie type.
A constructive recognition algorithm for SL(d, q) in its natural
representation is described by Celler and Leedham-Green in [CLG98];
algorithms for the other classical groups in their natural representation
are developed by Brooksbank in [Bro03].
More generally, recognition algorithms for the classical groups in black-
box representations have been developed by Kantor and Seress in [KS01].
The complexity of these algorithm involved a factor of q. In [CLGO], a
discrete log oracle is used to obtain a constructive Las Vegas algorithm for
a group isomorphic to PSL(2, q) in any irreducible representation in
characteristic dividing q, running in time that is polynomial in the input
length. This ‘base-case’ solution has been further exploited in [BK01] to
obtain better constructive recognition algorithms for certain classical
families.
Constructive recognition algorithms for the exceptional groups in black-
box representations are under development by Kantor and Magaard (2004).
Babai and Beals [BBR93, BB99] have developed an alternative and
powerful theoretical framework for the study of matrix groups defined over
finite fields. They focus on a characteristic series for a black-box group,
whose smallest nontrivial term is the solvable radical; they use this series
to develop randomized algorithms that solve many problems for linear
groups in polynomial time.
Deterministic polynomial-time algorithms for nilpotent and solvable
linear groups, which exploit their special structure. are developed by Luks
in [Luk92].
Most of these algorithms assume that random elements of the group
can be obtained efficiently; see Subsection 3.2.2. In many cases, the
theoretical analysis of (the performance of) the algorithms employed in
matrix recognition relies on detailed knowledge of the distributions of
elements in the groups.
© 2005 by Chapman & Hall/CRC Press

273
Chapter 8
Computation with Polycyclic
Groups
In this chapter, we shall discuss methods for computing with polycyclic groups
that are defined by a very particular type of group presentation, known as a
polycyclic presentation. Unlike a general group presentation, a polycyclic
presentation allows efficient structural computation within the group.
A group G is said to be polycyclic if it has a descending chain of subgroups
G=G1≥G2≥…≥Gn+1=1 in which each Gi+1 is a normal subgroup of Gi, and the
quotient group Gi/Gi+1 is cyclic. Such a chain of subgroups is called a polycyclic
series.
Every finitely generated nilpotent or abelian group is polycyclic and every
polycyclic group is solvable. The polycyclic groups can also be defined as
those solvable groups in which every subgroup is finitely generated. In
particular, every polycyclic group is finitely generated. Further, the class of
polycyclic groups is closed under taking subgroups, factor groups, extensions,
and finite direct products. The classes of finite solvable and finite polycyclic
groups are the same.
Polycyclic presentations are certain finite presentations of polycyclic groups,
which reflect the polycyclic structure of the groups they define. Polycyclic
presentations allow effective computations with their underlying groups, as
we shall show in this chapter. For example, we shall observe that the word
problem is effectively solvable for polycyclically presented groups.
In the first part of this chapter we shall introduce the basic background
for computing with polycyclic groups and we shall recall the definition and
the elementary properties of polycyclic presentations. Then we shall discuss
some special classes of polycyclic groups and we shall provide some examples
of polycyclic groups. The remainder of this chapter is then devoted to the
introduction of various methods to compute with polycyclic presentations.
This part of the chapter is restricted to finite polycyclic groups only, as this
simplifies the outline of the methods significantly.
As we observed in Subsection 4.4.6, if we wish to perform detailed structural
computations in a solvable finite permutation group, then it is usually
worthwhile to use the methods described there to transfer to a polycyclic
presentation of the group, and to use the methods to be described in this
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
274
chapter to perform the computations in that context. The same applies to
finite solvable matrix groups.
For background on the theory of polycyclic groups we refer the reader to
Segal’s book [Seg83]. An introduction to the fundamentals for computations
with polycyclic groups can also be found in Sims’ book [Sim94]. Further,
extensions of the methods for finite polycyclic groups to arbitrary polycyclic
groups are described by Eick in [Eic01a].
8.1 Polycyclic presentations
In this section, we shall introduce polycyclic sequences and polycyclic
presentations together with an outline of their elementary features. This
also includes a description of the collection algorithm, which can be used to
solve the word problem for polycyclic presentations.
8.1.1 Polycyclic sequences
Let G be a polycyclic group with a polycyclic series G=G1≥G2≥…= Gn+1≥1. As
Gi/Gi+1 is cyclic, there exist elements xi∈G with 
 Gi/Gi+1 for every
index i.
DEFINITION 8.1 A sequence of elements X=[x1, …, xn] such that
 for 1≤i≤n is called a polycyclic sequence for G.
It is straightforward to show that every tail-sequence Xi=[xi,…, xn] is a
polycyclic sequence for the subgroup Gi. This feature will be used frequently
for induction arguments and algorithmic methods.
It is also easy to verify that the subgroups of the polycyclic series are
exhibited by the polycyclic sequence X as Gi= 〈xi,…, xn〉. In particular, the
group G is generated by the elements in the sequence X. Moreover, this
yields that the polycyclic series G=G1≥…≥Gn+1=1 is uniquely determined
by X.
In the literature, there are various names that have been used to
describe polycyclic sequences: for example, they are called polycyclic
generating sequences in [Sim94] and they have been denoted as AG-
systems in [LNS84].
DEFINITION 8.2 Let X be a polycyclic sequence for G. The sequence
R(X):=(r1, …, rn) defined by 
 is called the sequence
of relative orders for X. The set {i∈{1..n}|ri finite} is denoted by I(X).
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
275
The sequence R(X) and the set I(X) depend on the underlying polycyclic
series G1, …, Gn of X only. Hence if Y is another polycyclic sequence for G
defining the same polycyclic series as X, then R(X)=R(Y) and I(X)=I(Y).
The relative orders exhibit some basic information about the group G. For
example, the group G is finite if and only if every entry in R(X) is finite or,
equivalently if and only if I(X)={1..n}. If G is finite, then |G|=r1…rn, the
product of the entries in R(X).
Example 8.1
Let 
 the dihedral group of order 8. We shall
introduce a variety of polycyclic sequences for this group G. Using this
example, we note that the length of a polycyclic sequence for G is not uniquely
defined by G. Also, we observe that different polycyclic sequences of G may
define the same polycyclic series.
a)
Let 
. Then the chain G=G1≥G2≥G3=1 is a polycyclic
series for G. This series allows several different polycyclic sequences.
For example, the sequences X:=[(1,3), (1,2,3,4)] and Y:=[(2,4), (1,4,3,2)]
are polycyclic sequences defining this series. They have the relative
orders R(X)=R(Y)=(2,4) and the finite orders set I(X)=I(Y)={1,2}.
b)
Let 
 and 
.
Then the chain G= G1≥G2≥G3≥G4=1 is a polycyclic series for G. This
series also allows several different polycyclic sequences. For example,
the sequences X:=[(2,4), (1, 2) (3, 4), (1, 3) (2, 4)] and Y:= [(1, 2, 3, 4),
(1, 2) (3, 4), (1, 3) (2, 4)] are polycyclic sequences defining this series.
They have the relative orders R(X)=R(Y)=(2, 2, 2) and the finite orders
I(X)=I(Y)={1, 2, 3}.
We note that 8=|G|=2.2.2=2.4 is the product of the relative orders in all
cases.
Example 8.2
Let 
 with
 
Then G≅ D, the infinite dihedral group. As above, we shall describe a
variety of polycyclic sequences for G. They will show that an infinite
polycyclic group can have polycyclic sequences of unbounded length.
a)
A shortest polycyclic sequence for G is the sequence X:=[a, ab] with the
relative orders R(X)=(2, ) and the finite orders I(X)={1}. This sequence
exhibits the structure of G as a semidirect product of an infinite cyclic
group 
 with a cyclic group 
 of order 2.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
276
b)
The group G has many other polycyclic sequences. In fact, the group G
has infinitely many polycyclic sequences of almost arbitrary length and
almost arbitrary relative orders. To observe this, let l∈ and let ni∈
with ni≠1 for 1≤i≤l. Then Y:=[a, ab, (ab)n1, …, (ab)n1…nl] is a polycyclic
sequence with relative orders R(Y)=(2, n1, …, nl, ).
The number of infinite entries in the relative orders sequences is the same in
both cases. It is known that this number of infinite entries in R(X) is an
invariant for G, which is called the Hirsch length or the rank of G; see
[Rob82], 5.4.13.
We shall now investigate an elementary, but important feature of polycyclic
sequences.
LEMMA 8.3 Let X=[x1, …, xn] be a polycyclic sequence for G with the relative
orders R(X)=(r1, …, rn). Then for every g∈G there exists a unique sequence
(e1, …, en), with ei∈ for 1≤i≤n and 0≤ei<ri if i∈I(X), such that 
.
PROOF Since 
, we find that 
 for some e1∈.
If i∈I(X), then r1< and we can choose ei∈{0..r1-1}. With this additional
property, we find that ei is unique. Let 
. By induction on the
length of a polycyclic sequence, we can assume that we have found an
expression of the desired form for h; that is, 
. This yields
 as desired.
DEFINITION 8.4 The expression 
 of Lemma 8.3 is called the
normal form of G with respect to X. The sequence (e1, … , en) is the exponent
vector of g with respect to X. We shall write expX(g)=(e1, …, en).
It is standard notation to neglect leading trivial entries in a normal form
expression; that is, if e1=…=ei–1=0, then it is standard to write 
as a normal form for g. But the exponent vector is always written as a vector
of length n.
Lemma 8.3 and Definition 8.4 yield an injective map 
from G into the additive group of 
. It is important to note that this is not
a group homomorphism and the structure of the polycyclic group G is in
general not closely related to an abelian lattice! Nonetheless, the exponent
vectors form the basic underlying structure for computations in polycyclic
groups, and many algorithms for polycyclic groups generalize methods for
abelian lattices in a noncommutative form.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
277
DEFINITION 8.5 Let G be a polycyclic group with polycyclic sequence X
and let g∈G with g≠1 and expX(g)=(e1, …, en).
a)
The depth of g is defined by:
depX(g)=i, if e1=…= ei-1=0 and ei≠0.
b)
The leading exponent of g is defined by:
ledX(g)=ei, if depX(g)=i
If g∈G with g=1, then expX(g)=(0, …, 0). In this case we define depX(g)=n+1
and we leave the leading exponent undefined.
The depth of an element g∈G describes how far down in the polycyclic
series the elements g lies. Thus depX(g)=i is equivalent to g∈Gi\Gi+1. In
turn, this implies that the normal form for g is of the form 
.
Example 8.3
Consider the polycyclic sequence X:=[(1, 3), (1, 2, 3, 4)]=[x1, x2] for the dihedral
group G. Let g:=(1, 3)(2, 4)∈G. Then g has the normal form 
and the exponent vector expX(g)=(0, 2). Thus depX(g)=2 and led X(g)=2.
The exponent vectors of elements in a polycyclic group can be used to describe
relations for G in its generators X. These relations are the first and
fundamental step towards a polycyclic presentation for G.
LEMMA 8.6 Let X=[x1, …, xn] be a polycyclic sequence for G with relative
orders R(X)=(r1, …, rn).
a)
Let i∈I(X). Then the normal form of a power 
 is of the form
.
b)
Let 1≤j<i≤n. Then the normal form of a conjugate 
 is of the form
.
c)
Let 1≤j<i≤n. Then the normal form of a conjugate 
 is of the form
.
PROOF a) As ri=|Gi:Gi+1, we have that 
 and thus depX(
)>i.
Thus the normal form expression for this power has the form described
in a).
b+c) Since j<i, we have xi∈Gj+1. As Gj+1 is normal in Gj, this yields that
the conjugates 
 and 
 are contained in Gj+1. Thus their depths
are at least j+1 and their normal form expressions are of the form given in
b) and c), respectively.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
278
These relations are called polycyclic relations. The first type are the power
relations and the second and third types are the conjugate relations. And S
is called the sequence of power exponents of the presentation.
Conjugate relations of the form 
 are called
trivial polycyclic relations. They are often omitted from a polycyclic
presentation to simplify the notation. This means that polycyclic presentations
have to be distinguished from arbitrary finite presentations. For this purpose
we denote them with
 
A group that is defined as and represented by a polycyclic presentation is
known as a PC-group.
If a polycyclic presentation has n generators and k finite entries in S, then it
has k+n(n-1)=O(n2) relations. This set of relations is usually highly redundant
as a set of defining relations, but we shall observe in the following that it is
useful for computational purposes.
We consider the special case of a polycyclic presentation on a single generator
in the following example.
Example 8.4
Let 
 be a group defined by a polycyclic presentation on one
generator; that is, X=[x1]. Then there are only two possibilities for R:
a)
 In this case G is the infinite cyclic group.
b)
R contains a single power relation. In this case this relation is of the
form 
 and thus G is a finite cyclic group of order s1.
Every polycyclic group G has a polycyclic sequence X and every such sequence
induces a complete set of polycyclic relations as outlined in Lemma 8.6. The
power exponents S of the presentation equal the relative orders R(X) in
8.1.2 Polycyclic presentations and consistency
DEFINITION 8.7 A presentation 〈x1, …, xn|R〉 is called a polycyclic
presentation if there exists a sequence S=(s1, …, sn) with 
 and
integers ai,k, bi,j,k, Ci,j,k such that R consists of the following relations:
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
279
this case. It is straightforward to prove that the resulting set of polycyclic
relations defines G as a group. This is summarized in the following.
THEOREM 8.8 Every polycyclic sequence determines a (unique) polycyclic
presentation. Thus every polycyclic group can be defined by a polycyclic
presentation.
Example 8.5
Let 
 with polycyclic sequence X:=[(1, 3), (1, 2, 3, 4)]
and relative orders R(X)=(2, 4). The polycyclic presentation defined by this
sequence has the generators x1, x2, the power exponents s1=2 and s2=4 and its
relations are 
 and 
.
Vice versa, we shall observe that every polycyclic presentation defines a
polycyclic group.
THEOREM 8.9 Let 
 be a polycyclic presentation and let G
be the group defined by this presentation. Then G is polycyclic and
X=[x1, …, xn] is a polycyclic sequence for G. Its relative orders R(X)= (r1, …, rn)
fulfil ri≤ si for 1≤i≤ n.
PROOF We define Gi:=〈xi, …, xn〉≤G. Then the conjugate relations in R
enforce that Gi+1 is normal in Gi for 1≤i≤n. By construction, Gi/Gi+1 is cyclic
and hence G is polycyclic. As 
 by definition, it follows that X is
a polycyclic sequence for G. Finally, the power relations enforce that
ri=|Gi:Gi+1|≤si for 1≤i≤n.
Example 8.6
We consider the group G defined by the following polycyclic presentation
with power exponents S=(3, 2, ).
 
By convention, this implies that the trivial polycyclic relations 
 hold in G.
By Theorem 8.9, this yields that X=[x1, x2, x3] is a polycyclic sequence for
G with relative orders R(X)≤(3, 2, ). Using, for example, the methods of
Chapter 5, it is straightforward to determine the precise relative orders as
R(X)=(3, 2, 1).
Hence this example shows that the power exponents in a polycyclic
presentation give an upper bound for the relative orders only. It is not even
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
280
possible to read off from the power exponents whether the given group is
finite or infinite.
Those polycyclic presentations for which the power exponents S and the
relative orders R(X) coincide play a central role in the algorithmic theory
of polycyclic groups. In fact, computations with polycyclic groups are usually
performed in such presentations.
DEFINITION 8.10 A polycyclic presentation 
 with power
exponents S is called consistent (or confluent) if R(X)=S.
It is straightforward to observe that every polycyclic group has a consistent
polycyclic presentation by using the same ideas as in Theorem 8.8. We
summarize this as follows.
THEOREM 8.11 Every polycyclic sequence determines a consistent
polycyclic presentation. Thus every polycyclic group can be defined by a
consistent polycyclic presentation.
An effective method to check whether a given polycyclic presentation is
consistent or to modify a given polycyclic presentation to an equivalent
consistent one is outlined in Section 12.4.
8.1.3 The collection algorithm
Collection is a method that can be used to determine the normal form for an
element in a group given by a consistent polycyclic presentation. Thus, in
particular, collection can be used to solve the word problem in a group given
by a consistent polycyclic presentation.
Collection can also be applied in the more general context of arbitrary
polycyclic presentations and our outline in this section covers this more general
case also. Hence we consider a group G defined by a polycyclic presentation
 with power exponents S.
LEMMA 8.12 Let 
 be a polycyclic presentation with power
exponents S. For every element g in G there exists a word representing g of
the form 
 with  ei∈ and 0≤ei<si if si≠.
PROOF This follows readily from Lemma 8.3 using that R(X)≤S.
DEFINITION 8.13 Words of the type considered in Lemma 8.12 are called
collected words.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
281
If the considered presentation 
 is consistent, then R(X)=S and
the collected words coincide with the normal forms with respect to X. In this
case there exists a unique collected word for every element in the given group
G and thus we can solve the word problem.
The underlying group G is given as a finitely presented group (defined by
a polycyclic presentation). Hence elements in G are usually described as
words in the generators X. We use the following notation to deal with this
situation.
DEFINITION 8.14 Let X be a set of abstract generators. In general, we
write a (nonempty) word w in X as a string 
 with aj∈. We
assume that ij≠ij+1 for 1≤j≤r–1 and aj≠0 for 1≤j≤r.
a)
A word w is called collected, if 
 with i1<i2<…<ir and aj∈
{1.. sj–1} if sj≠. Otherwise w is uncollected.
b)
A word v in X is a minimal uncollected subword of the word w if v is a
subword of w and it has one of the following forms:
i)
 for ij > ij+1,
ii)
 for ij > ij+1,
iii)
.
Note that a reduced word is collected if and only if it does not contain a
minimal uncollected subword.
A central idea of the collection algorithm is to successively eliminate
minimal uncollected subwords in a given word by applying the polycyclic
relations. Before we introduce the formal outline of the collection algorithm,
we give an example to illustrate the idea.
Example 8.7
Let 
 and let
, a word representing an element of G. We can find two different
minimal uncollected subwords in 
 and 
.
a)
We consider the minimal uncollected subword 
 first. We modify ω by
applying the power relation 
 and thus we obtain 
 
.
(Here ‘≡’ denotes equality in the group G.) Now w′ is a minimal uncollected
subword itself. We modify this word by applying a conjugate relation in
the following form: 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
282
The result in both cases is the same collected word (as it should be, because
the presentation considered is consistent). We can also note at this stage
already that in the first case we have to do significantly fewer applications of
the polycyclic relations.
We now give a more formal description of the collection process. The following
contains a broad outline.
COLLECTED WORD (X, R, w)
Input: A polycyclic presentation 
, a word w in X
Output: A collected word equivalent to w
1
while there exists a minimal uncollected subword in w
2
do choose a minimal uncollected subword v in w;
3
if 
4
then 
5
if 
6
then 
;
7
if 
8
then 
9
10
return w;
In each step of this method we replace w by an equivalent word, since we
only apply relations of R for the modifications of w. Hence, if the method
terminates, then it returns a collected word equivalent to w. We shall now
prove that this always happens.
b)
We consider the minimal uncollected subword 
 first. We modify w by
applying a conjugate relation and thus we obtain 
. Iterating this process and applying a power
relation as a final step yields 
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
283
THEOREM 8.15 The collection algorithm terminates.
PROOF We use induction on the number n of generators in X for this purpose.
It is obvious that the method terminates if n=1. (See Example 8.4 also.) Thus
we assume by induction that the method terminates for all polycyclic
presentations on n-1 generators. The given polycyclic presentation 
contains a polycyclic presentation 
 where X2= [x2, …, xn] and R2
consists of those relations in R that involve generators in X2 only. By induction,
the collection method terminates in this presentation 
. Hence
the collection method terminates on every word that consists of generators in
X2 only.
Now let w be an arbitrary word in X. Then w contains only finitely many
occurrences of x1 and thus 
 where v1, …, vr are
words in X2. Since the collection method terminates on v1, …, vr, we find
that after finitely many steps, the collection method considers a minimal
uncollected subword involving x1. This minimal uncollected subword is
eliminated by the algorithm and a word in X2 is introduced for it. This
process is iterated.
Since the method never introduces new occurrences of x1, but only
eliminates minimal uncollected subwords involving x1, we find that after
finitely many steps the word w is replaced by the equivalent word
, where v is a word in X2. By induction, the collection
algorithm terminates on v and hence it terminates on w also.
The collection algorithm was implemented first by Neubüser [Neu61]. Since
then, there have been several implementations and also various improvements
and refinements of this algorithm. We shall briefly discuss some of these
improvements and refinements here.
The most obvious refinement is in trying to find a good choice in Step 2 of
the algorithm. This refinement has been considered in detail by Leedham-
Green and Soicher in [LGS90]. As a result, the collection-from-the-left strategy
is usually used for Step 2. This strategy chooses the first occurrence of a
minimal uncollected subword by parsing through w from the left.
Another refinement of the general outline is to allow more complicated
words as minimal uncollected subwords and to try to eliminate such words
in a single collection step. For example, one can consider all subwords of the
type 
 with ij>ij+1.
To collect such a subword, we rewrite it as
 
where ϕ is the isomorphism induced by the conjugation action of on 
. It then remains to determine the image of 
 under the aj+1
- st power
of the isomorphism ϕ. This image can be obtained effectively by evaluating
the isomorphism ϕ.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
284
Finally, it remains to mention that for special types of polycyclic
presentations there are other methods available to determine collected words.
The ‘Deep-Thought’ technique introduced by Leedham-Green and Soicher in
[LGS98] is an example for such an alternative method. Deep-Thought applies
to certain polycyclic presentations for nilpotent groups and it uses polynomial
functions to determine collected words.
8.1.4 Changing the presentation
Usually, a polycyclic group G has several different polycyclic presentations.
The number of generators and relations in these presentations can vary and
some of these presentations may be more useful for effective computations
than others. Hence we briefly consider the question how to modify a given
polycyclic presentation to a computationally more useful one. The following
lemma yields an obvious reduction.
LEMMA 8.16 Let 
 be a polycyclic presentation with power
exponents S. If there exists an exponent si=1, then the generator xi is
redundant in the polycyclic presentation and can be eliminated.
PROOF If si=1, then there exists a relation xi=Ri,i and Ri,i is a word in the
generators xi+1, …, xn. Hence we can eliminate xi from the list of generators
and we replace each occurrence of xi in a relation in R by Ri,i. Then we use
the collection algorithm to determine collected words for all modified right-
hand sides in relations in R.
Suppose that 
 is a finite group defined by a consistent
polycyclic presentation with power exponents S. Computations with G are
often easier if the entries in S are all primes. This can always be achieved as
the following lemma shows.
LEMMA 8.17 Let 
 be a group defined by a consistent
polycyclic presentation with power exponents S. Then there exists another
polycyclic presentation 
 with power exponents S’ such that
each finite entry in S′ is a prime.
PROOF Let xi be a generator with power exponent si. Suppose that si is
finite and not a prime; that is, si=ab with a, b∈ and a, b≠1. Let 
.
Then we add this new generator to the sequence X. This yields a new polycyclic
sequence X′. This new sequence defines a polycyclic presentation that expands
the given one. Iterating this process eventually yields a polycyclic presentation
of the desired type.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
285
DEFINITION 8.18 We call a polycyclic presentation 
 whose power
exponents S are all primes a refined polycyclic presentation.
The refined consistent polycyclic presentations will be used throughout for
computations in finite polycyclic groups. The following lemma shows that
these presentations yield a certain standardized form for finite groups.
LEMMA 8.19 Let G be a finite polycyclic group. Then all refined consistent
polycyclic presentations for G have the same number of generators and
thus all these presentations have the same number of relations.
PROOF The number of generators in a refined consistent polycyclic
presentation for a finite group G equals the number of prime factors of |G|.
Hence this number is an invariant for G. The number of relations in a refined
consistent polycyclic presentation depends on the number of generators only
and hence it is also an invariant for G.
Finding good polycyclic presentations for infinite groups is significantly more
difficult than for finite groups. For finite groups, we mostly work with refined
consistent polycyclic presentations. There are various more advanced
reductions and improvements available for these groups also. We refer to
[CELG04] for a further discussion.
The relations in a polycyclic presentation depend on the generators and
the power exponents only. Usually, the set of relations obtained is highly
redundant. In the following lemma we observe that some of the polycyclic
relations can always be omitted from a presentation, since they can be
computed from the remaining relations.
LEMMA 8.20 Let 
 be a consistent polycyclic presentation with
power exponents S. If sj≠. Then the relation 
 is a consequence
of the relations 
 and 
 for j+1≤k≤n.
PROOF We note that 
 and 
. Thus
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
286
Exercises
1.
Show that X=[x1, x2, x3, x4]:=[(1, 2), (1, 2, 3), (1, 2)(3, 4), (1, 3)(2, 4)] is a
polycyclic generating sequence for G:=Sym(4) and that, for g∈G,
.
Calculate the polycyclic presentation of G defined by X, and use the
collection algorithm to write the element x4x3x2x1 in normal form.
2.
Let 
. Is G solvable? Is G polycyclic?
3.
For which values of m∈ is 〈x, y | y-1 xy = xm〉 polycyclic?
8.2 Examples of polycyclic groups
In this section we shall outline some examples and discuss some special
types of polycyclic presentations. Also, we include an application of the
algorithmic theory of polycyclic groups to crystallographic groups.
8.2.1 Abelian, nilpotent, and supersolvable groups
Every finitely generated abelian group is polycyclic and hence has a polycyclic
presentation. The following elementary lemma observes that the polycyclic
presentations for abelian groups are easy to describe, and we can read off
from a given polycyclic presentation whether the group defined by this
presentation is abelian.
LEMMA 8.21 Let 
 be a group defined by a consistent
polycyclic presentation. Then G is abelian if and only if all conjugate relations
in R are trivial.
Every finitely generated nilpotent group is polycyclic and hence has a polycyclic
presentation. In fact, a finitely generated nilpotent group always has a
polycyclic presentation of a special form, which we introduce in the following.
DEFINITION 8.22 A polycyclic presentation 
 with power
exponents S is called a nilpotent presentation if the conjugate relations R
have the following form:
  
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
287
Thus the right-hand sides of the conjugate relations Ri,j and Rj,i in a nilpotent
presentation have depth i and leading exponent 1. In an arbitrary polycyclic
presentation these relations can have smaller depth and arbitrary leading
exponent.
LEMMA 8.23
a)
Every finitely generated nilpotent has a consistent nilpotent presentation
defining it.
b)
Every consistent nilpotent presentation defines a finitely generated
nilpotent group.
c)
If G is finitely generated nilpotent and torsion-free, then there exists a
consistent nilpotent presentation defining G whose power exponents
are all infinite. The number of generators in such a presentation is
minimal for a polycyclic presentation of G.
PROOF a) By Theorem 8.11 and Lemma 8.6, it is sufficient to show that G
has a polycyclic sequence that induces the desired type of relations. This
follows readily if we choose a polycyclic series G=G1>…>Gn+1=1 which refines
a central series of G and we choose X as a polycyclic sequence defining this
series.
b) The generators X of a consistent nilpotent presentation form a
polycyclic sequence that can be seen, from the relations, to be a central series
by the relations for the group.
c) If G is torsion-free, then the factors of the upper central series are also
torsion-free (exercise). Hence there exists a polycyclic series for G which
refines a central series and has infinite factors only.
In contrast to the abelian case, a finitely generated nilpotent group can also
have consistent polycyclic presentations that are not nilpotent presentations.
Example 8.8
Let 
. Then G is nilpotent and hence G has a
nilpotent presentation. To compute such a presentation for G, we first
determine a central series for G. For example, we can use the lower central
series 
 for this purpose. Then, we choose a polycyclic
sequence whose polycyclic series refines the determined central series. For
example, the sequence X:=[(1, 3), (1, 2, 3, 4), (1, 3)(2, 4)] is of this type.
Finally, we compute the polycyclic presentation induced by X:
 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
288
However, the group G also has polycyclic presentations that are not
nilpotent presentations. To obtain such a presentation, we choose a polycyclic
sequence whose polycyclic series does not refine a central series. For example,
X:=[(1, 3), (1, 2, 3, 4)] is of this type. The presentation induced by X reads:
 
Yet another special case of polycyclic groups are the supersolvable groups,
which are defined to be groups having a polycyclic series consisting of normal
subgroups of G. A supersolvable group always has a polycyclic presentation
of a special form.
DEFINITION 8.24 A polycyclic presentation 
 with power
exponents S is called a supersolvable presentation, if the relations R have
the following special form:
 
Thus the right-hand sides of the conjugate relations Ri,j and Rj,i in a
supersolvable presentation have depth i, while in an arbitrary polycyclic
presentation they can have a smaller depth. The following lemma is proved
in a similar way to Lemma 8.23.
LEMMA 8.25
a)
Every supersolvable group has a supersolvable presentation defining it.
b)
Every supersolvable presentation defines a supersolvable group.
8.2.2 Infinite polycyclic groups and number fields
Algebraic number fields can be used to construct interesting types of infinite
polycyclic groups. We give a brief introduction to this construction here.
First, we recall the underlying notations and definitions. We refer to [ST02]
for background on algebraic number theory.
DEFINITION 8.26 An algebraic number field F is an extension of  of
finite degree [F: ]. Further, we have the following.
a)
The maximal order O(F) of an algebraic number field F is defined as
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
289
b)
The unit group U(F) of an algebraic number field F is defined as
 
We collect a number of folklore results on algebraic number fields in the
following.
THEOREM 8.27 Let F be an algebraic number field and let d:=[F : ].
a)
The maximal order O(F) forms a ring whose additive group is isomorphic
to 
.
b)
(Dirichlet) Let d=s+2t, where s and 2t are the numbers of real and
complex field monomorphisms F→. Then the unit group U(F) is a
finitely generated abelian group of the form 
 where
.
The unit group U(F) acts by multiplication from the right on the additive
group of the maximal order O(F). Thus we can form the split extension of
these two groups and we obtain an interesting type of polycyclic group.
LEMMA 8.28 Let F be an algebraic number field with degree d≠1. Then
 is an infinite polycyclic group.
The resulting polycyclic groups are nonnilpotent (because -1 ∈ U(F) inverts
all elements of O(F)), and they have a complex structure. Computations
with such groups translate directly to computations with algebraic number
fields. These types of polycyclic groups are a major reason why computations
with infinite polycyclic groups are much more complex than computations
with finite polycyclic groups.
8.2.3 Application—crystallographic groups
Crystallographic groups are the symmetry groups of crystals. These
symmetry groups have various applications in chemistry and physics, and
it is in this context that the crystallographic groups were first studied.
Let C be a crystal with symmetry group G. What motions can we do with
C without changing the crystal? There are two basic motions: the translation
by an integer vector and the rotation of C in place. The symmetry group G
contains all combinations of these two types of movements. The set of
translations forms a normal subgroup T in G whose factor group corresponds
to the motions in place and thus is finite. This leads to the following definition.
DEFINITION 8.29 An (affine) crystallographic group G is a subgroup of
the group of all euclidean motions of d-dimensional space 
 such that the
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
290
set T of all of its pure translations is a discrete normal subgroup of finite
index. The factor group G/T is called the point group of G.
The translations T form a free abelian normal subgroup in a crystallographic
group G and its rank is at most d. If the rank of T is d, then the group G is
also called a space group.
Not all crystallographic groups are polycyclic, but many of them are. The
following lemma indicates this. We refer to [BBN+78] for background.
LEMMA 8.30
a)
A crystallographic group is polycyclic if and only if its point group is
polycyclic.
b)
All space groups of dimension at most 3 are polycyclic.
The algorithmic theory for polycyclic groups can be used to compute with
polycyclic crystallographic groups. For this purpose we first need to determine
a polycyclic presentation for a given crystallographic group. Since these groups
usually arise naturally as affine subgroups of GL(d+1, ), we use the affine
structure for this purpose. We also note that various other methods to compute
with crystallographic groups are outlined in [OPS98] and [EGN97].
We shall return to this topic in Section 11.5, where we shall be discussing
the enumeration of space groups.
Exercises
1.
Prove the claim in Lemma 8.23 that the factors in the upper central
series of a torsion-free nilpotent group are torsion-free. Does the same
property necessarily hold for the lower central series?
2.
For the number field 
, we have 
 and
. Find a polycyclic presentation of 
,
and show that this group has no nilpotent subgroup of finite index.
8.3 Subgroups and membership testing
Let G be a finite polycyclic group defined by the refined consistent polycyclic
presentation 
. Suppose that U≤G is a subgroup described by a set
of generators 
.
In the first part of this section we shall describe how to determine a
polycyclic sequence for U. The sequence that is determined by the methods
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
291
in this section is closely related to the sequence X, and thus it will be called
an induced polycyclic sequence with respect to X.
The induced polycyclic sequences are the major tool for computing with
subgroups in a polycyclically presented group G. For example, they allow us
to compute a consistent refined polycyclic presentation for U and they facilitate
an effective membership test for U.
In the second part of this section we describe a method to solve the subgroup
problem for subgroups of G; that is, we introduce a method to check whether
U=V for two subgroups U, V≤G. For this purpose we determine polycyclic
sequences for U and for V, which are canonical with respect to X.
8.3.1 Induced polycyclic sequences
Let G=G1>…>Gn+1=1 be the polycyclic series defined by the polycyclic
sequence X of G. Then, with Ui:=GiU, we obtain the induced polycyclic
series U=U1≥…=Un+1≥1 for U. This induced series is a natural choice for a
polycyclic series of U.
As G is defined by a refined presentation, the factors of the polycyclic
series for G are nontrivial factors of prime order. The induced polycyclic
series for a proper subgroup U contains trivial factors. Hence a polycyclic
sequence for U defining the induced polycyclic series does not define a
refined presentation. For computational purposes we want to remedy this
situation.
First we investigate the situation in more detail. Since |Ui:Ui+1| divides
|Gi:Gi+1|=ri and ri is a prime, we have |Ui: Ui+1|=1 or |Ui:Ui+1|=ri. Let
i1<…<im denote those indices in {1..n} with 
. Then
. is a polycyclic series for U with
factors of prime order. This series leads to the following definition.
DEFINITION 8.31 Y=[y1, …, ym] is an induced polycyclic sequence for U
with respect to X if Y defines the series 
; that is, if
 for 1≤j≤m.
Thus an induced polycyclic sequence for a subgroup U is a polycyclic sequence
for U, which defines the natural induced polycyclic series of U. In the following
we shall investigate induced polycyclic sequences in more detail.
LEMMA 8.32 Let U be a subgroup of G and let Y=[y1, …, ym] be an induced
polycyclic sequence for U defining the series 
. Then
a)
Y is a polycyclic sequence for U.
b)
depX(yj)=ij and thus depX(y1)<…<depX(ym).
c)
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
292
PROOF a) is obvious from the definition.
b) We find that 
 and hence depX(yj)≥ij. Suppose that
depX(yj)>ij. Then 
 and thus 
 by construction.
But 
 generates the nontrivial factor 
 and this yields a
contradiction. Hence depX(yj)=ij.
c) The sequence Y defines the series 
.
Hence its relative orders are 
 for 1≤j≤m.
Let Y be an induced polycyclic sequence with respect to X and let B be the
matrix whose rows consists of the exponent vectors of the elements in Y; that
is,
 
Then Lemma 8.32 b) says that B is a matrix in upper triangular form.
LEMMA 8.33 Let U be a subgroup of G and let Y=[y1, …, ym] be an induced
polycyclic sequence for U. Define 
. Then
a)
depX(u) ∈ d for every u ∈ U.
b)
T := {g ∈ G|expX(g)j=0 j ∈ d} is a left transversal for U in G, where
expX(g)j is the j-th entry in the exponent vector of g.
PROOF a) Let u ∈ U. If u=1, then depX(u)=n+1∈d. If u≠1, then
 such that 
 for some j. As depX(yk)>depX(yj) for
k>j, we have depX(u)=depX(yj) ∈ d.
b) The set T contains 
 elements and thus |T|=|G:U|. It remains
to show that two different elements in T lie in different left cosets. Thus let s,
t ∈ T and suppose that sU=tU. We assume w.l.o.g. that depX(s)≥depX(t). We
use induction on depX(t) to prove s=t. Suppose that depX(t)=n+1. In this
case t=1 and thus s ∈ U. By a) we have that 
 and thus s=1. Hence
s=t.
Now suppose that the claim has been proved for all s, t ∈ T with depX(s)≥
depX(t)≥j+1 for some j≤n. Suppose that depX(t)=j. Then s, t≠1 and depX(s),
depX(t) 
 d. Let u ∈ U with s=tu. As depX(u) ∈d by a), we find that
depX(t)≠depX(u) If depX(u)<depX(t), then depX(s)=depX(tu)= depX(u) ∈ d which
is a contradiction. Thus we have that depX(u)>depX(t) and
depX(s)=depX(tu)=depX(t). As s=tu, we obtain ledX(s)=ledX(t) in this case.
Hence 
 and 
 for e=ledX(t) and  s′, t′ ∈ T with depX(t′)>j and
s′U=t′U. By induction, we have s′=t′ and thus s=t.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
293
In the following we describe an alternative characterization of the induced
polycyclic sequence. This characterization is more technical, but it will be
more useful for computational purposes.
LEMMA 8.34 A sequence Y=[y1, …, ym] is an induced polycyclic sequence for
a subgroup U with respect to X if and only if:
a)
〈y1, …, ym〉=U.
b)
with ij:=depX(yj), we have i1<…< im.
c)
d)
PROOF : Since Y is an induced polycyclic sequence, it is also a polycyclic
sequence for U and thus a), c) and d) follow from Lemma 8.6. Part b) follows
from Lemma 8.32.
⇐: Put i0:=0 and im+1:=n|1. Let Hj:=〈y1, …, ym〉 for 1≤j≤m+1 and Ui:=GiU
for 1≤i≤n+1. Our aim is to prove 
 
 for 1≤j≤m+1.
First, d) implies that Hj+1 is normal in Hj for every j. By the construction
of the subgroups Hj this yields that the series H1>…>Hm+1=1 is a polycyclic
series for H1 and Y is a polycyclic sequence defining this series. By a) we have
that H1=U and Y is a polycyclic sequence for U.
By a) and b) we have that 
. Let 
. As Y is a polycyclic
sequence for U, we find that u can be written in the form 
. Let
ek be the first nonzero exponent. Then depX(u)=depX(yk)=ik. Since 
,
we have k≥j and thus 
. This yields that u ∈ Hj. In summary,
we now have Hj= for 1≤j≤m+1.
Now let H=Uk with ij<k<ij+1. Then Hj≤H≤Hj+1. Note that Hj≠Hj+1 by b) and
thus |Hj:Hj+1|=rij by c), since rij is a prime. Thus we have H=Hj or H=Hj+1.
Further, we find that yj  Gk by b) and hence H≠Hj. This yields that H=Hj+1
as desired.
Lemma 8.34 translates into an algorithm to compute an induced polycyclic
sequence for a subgroup U. The basic idea of the algorithm is to complete a
partial induced polycyclic sequence for U stepwise until it fulfils the criteria
of Lemma 8.34. As a preparation for this algorithm, we introduce a method
to sift an element through a partial induced sequence. For technical purposes,
we define a partial induced sequence as a sequence of length n, which contains
at place i either the trivial element of G or an element of depth i.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
294
SIFT(Z, g)
Input:
A sequence Z=[z1, …, zn] with zi=1 or depX(zi)=i, an element g
∈ G
Output: An element h ∈ G of maximal depth d=depX(h) such that
 with 0≤ei<ri
1
h:= g;
2
d:= depX(h);
3
while d<n+1 and zd≠1
4
do k:= zd;
5
e:= ledX(h) . ledX(k)-1 mod rd;
6
h:= k-e . h;
7
d:= depX(h);
8
return h;
We note that the depth depX(h) increases in every pass through the ‘While’
loop in the function SIFT. Hence SIFT terminates and the returned element
h has at least the depth of g.
Now we can introduce an outline of the algorithm to compute an induced
polycyclic sequence for a subgroup U that is given by generators {u1, …, ut}.
The algorithm is based on Lemma 8.34 and the method used in SIFT.
INDUCEDPOLYCYCLICSEQUENCE({u1, …, Ut})
Input: Generators {u1, …, ut} for a subgroup U
Output: An induced polycyclic sequence Y for U
1
Initialize Z as a sequence of length n with all entries 1;
2
Initialize := {u1, …, ut};
3
while ≠
4
do select g from G and delete g from ;
5
h:= SIFT(Z, g);
6
d:= depX(h);
7
if d<n+1
8
then add hrd to ;
9
add [h, z] to  for all z ∈ Z;
10
Z[d]:= h;
11
Let Y be the sequence of the nontrivial entries of Z;
12
return Y;
LEMMA 8.35 The algorithm INDUCEDPOLYCYCLICSEQUENCE
terminates and it returns an induced polycyclic sequence for U.
PROOF First we prove that the algorithm terminates. For this purpose we
have to show that the set  is empty at some stage in the algorithm. In each
pass through the ‘While’ loop of the algorithm, the set  is reduced by one
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
295
element in line 4 and it is extended by a finite number of elements in lines 8
and 9. Whenever a new element u is added to  in lines 8 or 9, then we have
that depX(u)>depX(g) where g is the original element selected in line 4. Hence
after finitely many steps there is at most the element of maximal depth n+1
left in the set . This element is eliminated at the next pass through the
‘While’ loop without further changes to G. At this stage the algorithm
terminates.
Next we prove that Y is an induced polycyclic sequence for U. For this
purpose we show that Y fulfils the criteria of Lemma 8.34. Since any nontrivial
elements Z[d] always have depth d, condition b) is satisfied, and condition
c) and d) follow from the fact that the powers and commutators of these
nontrivial elements are adjoined to  for later processing in lines 8 and 9.
It remains to prove condition a).
For this purpose we show that 
 at every step of the algorithm
after the initialization. Clearly, 
 at line 3. Whenever we take an
element from G and eliminate it from this set, then we sift it through Z and
add the result to Z if it is nontrivial. Hence the property 
 remains
unchanged through the algorithm. As G is empty at the end of the algorithm,
it follows that the elements in Z and Y generate U at line 11.
In the theory of vector spaces, a basis of a subspace can be computed by the
Gauss algorithm. Due to this analogy, the algorithm INDUCED
POLYCYCLICSEQUENCE has also been called the ‘Noncommutative Gauss
algorithm’ by Laue, Neubüser, and Schoenwaelder in [LNS84].
The algorithm INDUCEDPOLYCYCLICSEQUENCE can be extended in
such a form that it works for arbitrary (not necessarily refined) consistent
polycyclic presentations of finite or infinite polycyclic groups. We refer to
Eick’s thesis [Eic01a] for further background.
Using a modification of the algorithm SIFT we can test membership of
elements in a subgroup U and determine the exponent vector of an element
u ∈ U with respect to an induced polycyclic sequence Y for U. This is done
in the function CONSTRUCTIVEMEMBERSHIPTEST.
Example 8.9
We consider the following polycyclic presentation (trivial polycyclic relations
and conjugation relations with inverse generators are omitted):
 
Let 
 Applying the algorithm INDUCEDPOLYCYCLIC-
SEQUENCE
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
296
Hence U has the induced polycyclic sequence Y=[x2, x3, x4].
8.3.2 Canonical polycyclic sequences
In this subsection we outline a method to solve the subgroup problem in
polycyclically presented groups. That is, for two given subgroups U and V of
a polycyclic presented group G, we want to check whether U=V. For this
purpose we introduce canonical polycyclic sequences for subgroups of the
polycyclically presented group G. They will yield that two subgroups are
equal if and only if they have the same canonical polycyclic sequence.
DEFINITION 8.36 Let Y=[y1, …, ym] be an induced polycyclic sequence
with respect to X for U≤G. Put bi:=expX(yi)=(bi1, …, bin) and let di:= depX(yi)
for 1≤i≤m. Then Y is called a canonical polycyclic sequence for U if
a)
bi,di=1 for 1≤i≤m, and
b)
bi,dj=0 for 1≤i<j≤m.
CONSTRUCTIVEMEMBERSHIPTEST(Y, g)
Input: An induced polycyclic sequence Y=[y1, …, ym] for a subgroup U,
an element g ∈ G
Output: The exponent vector expY (g) if g ∈ U and false otherwise
1
Let e be a list of length m containing 0’s;
2
h:= g;
3
d:= depX(h);
4
while there exists j with depX(yj)=d
5
do f:= ledX(h) . ledX(yj)-1 mod rd;
6
7
e[j]:= f;
8
d:= depX(h);
9
if h=1
10
then return e;
11
else return false;
yields the following assignments in the passes through the ‘While’ loop:  
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
297
Let Y be a canonical polycyclic sequence with respect to X. Then the m×n-
matrix B whose rows consist of the exponent vectors expX(yi) for 1≤i≤m is a
matrix in upper triangular form with leading entries in each row equal to 1,
and 0’s above these leading entries. This is an alternative way to characterize
the canonical polycyclic sequences.
It is straightforward to modify a given induced polycyclic sequence to a
canonical polycyclic sequence by adjusting the elements in the sequence. We
give an outline of the method in the following function.
CANONICALPOLYCYCLICSEQUENCE(Y)
Input: An induced polycyclic sequence Y=[y1, …, ym]
Output: A modified sequence Y which is canonical
1
d:= [depX(y1), …, depX(ym)];
2
for i ∈ [m..1 by -1]
3
do 
4
for j ∈ [i+1..m]
5
do 
6
return Y;
The following theorem shows that canonical polycyclic sequences can be used
to solve the subgroup problem.
THEOREM 8.37 Every subgroup of G has a unique canonical polycyclic
sequence with respect to X.
PROOF Let U be a subgroup of G. It is straightforward to observe that U
has a canonical polycyclic sequence; for example, the algorithm
CANONICALPOLYCYCLICSEQUENCE can be used to determine such a
sequence. It remains to prove that, given two canonical polycyclic sequences
Y and Z for U, the equality Y=Z holds.
By induction, we assume that every subgroup of G2 has a unique canonical
polycyclic sequence with respect to X2:= [x2, …, xn]. If U≤G2, then Y and Z are
two canonical polycyclic sequences with respect to X2 and the theorem is
proved. Thus we assume that 
. Then 
 and 
are two canonical polycyclic sequences with respect to X2 for 
.
Hence Y2=Z2 and it remains to prove y1=z1. We observe that
depX(y1)=depX(z1)=1 and ledX (y1)=ledX(z1)=1. Suppose that y1≠z1 and let j be
the smallest position in which expX(y1) and expX(z1) differ. Then j>1 and j 
{depX(y)|y ∈ Y2}. Let 
. Then depX(u)=j. But Y is an induced
polycyclic sequence of U and thus all the elements in U have depths in
 by Lemma 8.33. This is a contradiction and so
y1=z1.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
298
Exercises
1.
Calculate the canonical polycyclic sequence of the subgroup 
of G=Sym(4) with respect to the polycyclic sequence of G defined in
Exercise 1 of Section 8.1.
2.
Show that the set T in Lemma 8.33 is not necessarily a right transversal
of U in G. (Hint: Let 
.)
8.4 Factor groups and homomorphisms
Factor groups and homomorphisms of groups are closely connected to each
other. In this section we shall describe algorithms to compute with them.
For this purpose we assume that G is a finite polycyclic group defined by the
refined consistent polycyclic presentation 
. Let X=[x1, …, xn] and
R(X)=(r1, …, rn).
8.4.1 Factor groups
Let N be a normal subgroup of G. As usual, denote the polycyclic series
defined by X by G=G1>…>Gn+1=1. Then the sequence X/N:= [x1N, …, xnN] is
a polycyclic sequence for the quotient group G/N, which defines the induced
polycyclic sequence G/N=G1N/N≥…≥Gn+1N/N= N/N.
This induced series for G/N contains trivial factors if N is a nontrivial
subgroup. Then X/N forms a polycyclic sequence for G/N, but this sequence
does not define a refined consistent polycyclic presentation. The following
lemma shows how to determine a polycyclic sequence for G/N that yields a
refined consistent polycyclic presentation.
LEMMA 8.38 Let Y be an induced polycyclic sequence for 
 with respect
to X. Let d:={depX(y)|y ∈ Y} and Z:=[xi|i  d]. Then Z/N is a polycyclic
sequence for G/N that induces a refined consistent polycyclic presentation
for G/N.
PROOF The normal subgroup N covers all the factors Gi/Gi+1 with i ∈ d
by Lemma 8.33 and N avoids the remaining factors of the polycyclic series
of G. Hence Z/N is a polycyclic sequence for G/N that defines a properly
descending polycyclic series. Hence Z/N also defines a refined consistent
polycyclic presentation for G/N.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
299
It is straightforward to determine the exponent vector of an element gN ∈
G/N with respect to the sequence Z/N of Lemma 8.38. Using this, we can
then also determine a refined consistent polycyclic presentation for the factor
group G/N.
8.4.2 Homomorphisms
Let 
 be another polycyclic group defined by a refined consistent
polycyclic presentation. A homomorphism from G to H can be defined by
describing the images of a generating set {g1, …, gl} of G:
 
Given a homomorphism in this form, the following problems are of interest
(cf Section 3.4):
(1) Compute the image of g ∈ G under ϕ.
(2) Determine the image I of ϕ.
(3) Compute a preimage of h ∈ I under ϕ.
(4) Determine the kernel K of ϕ.
All of these problems can be solved effectively in the given situation. As a
first step, we introduce two precomputations for the solutions.
(I) Compute images for the polycyclic sequence X: We compute
Y:=INDUCEDPOLYCYCLICSEQUENCE({g1,…,gl}) 
and 
then
Z:=CANONICALPOLYCYCLIC SEQUENCE (Y). Additionally, in this
process we perform all computations with {g1,…, gl} simultaneously also
with {h1,…,hl}. Since X is the unique canonical polycyclic sequence of G, we
obtain Z=X and we determine [ϕ(x)|x ∈ X].
(II) Compute preimages for an induced polycyclic sequence of I: We compute
Y′:= INDUCED POLYCYCLIC SEQUENCE({h1,…,hl}) to determine an
induced polycyclic sequence for I. Additionally, in this process we perform all
computations with {h1,…,hl} simultaneously also with {g1,…,gl}. This yields
a sequence of preimages [ϕ-1 (y)|y ∈ Y′].
These two precomputations yield effective solutions to some of the above
problems. First, problem (1) can be solved effectively, since all elements in G
are given as collected words in X and hence it is straightforward to translate
a collected word from X to ϕ(X).
Then, an induced polycyclic sequence for I is determined by (II) and hence
problem (2) is solved. Similarly, we can compute preimages using (II), since
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
300
we can translate collected words in an induced polycyclic sequence Y′ for I to
their preimages under ϕ.
Finally, it remains to discuss problem (4). Normal subgroup generators
for the kernel can be computed by evaluating the relations of the image I.
Thus, using (II) we can determine normal subgroup generators for the kernel
K readily. It then remains to determine the normal closure of the subgroup
generated by the normal subgroup generators. Note that we can read off the
order of the source G and the order of the image I from their polycyclic
sequences. Hence we know a priori the order of the kernel K, which is useful
as a stopping criterion for the kernel computation.
Exercises
1.
Let X be the polycyclic sequence for G:=Sym(4) defined in Exercise 1 of
Section 8.1, and let ϕ:G→G be the homomorphism defined by
 Use the methods
described above to compute (X), and to find generators of ker(ϕ).
2.
Let G be a group defined by a refined polycyclic presentation, let H be
a second (black-box) group, let {g1,…,gl} be a set of generators of G, and
let h1,…,hl be elements of H. How would you test whether the map ϕ: gi
 hi extends to a homomorphism G→H. (You might want to refer back
to the general discussion in Subsection 3.4.1.)
8.5 Subgroup series
In this section we shall discuss the determination of various subgroup series
for the finite polycyclic group G. First, we note that, if X is the polycyclic
generating sequence associated with a refined consistent polycyclic
presentation of G, then the polycyclic series G=G1>…>Gn+1=1 defined by X is
a composition series for G, since |Gi:Gi+1|=ri is a prime for every i.
In many algorithmic methods for polycyclic groups, a normal series with
elementary abelian factors is used for induction purposes. For some algorithms
it is also of interest to have a characteristic series of this type or a chief
series. In the remainder of this section we describe methods to compute such
series in G.
A key to many of these series is the determination of a commutator
subgroup 
; that is, we want to determine an
induced polycyclic sequence for [U, V] from induced polycyclic sequences
for U and V. This is addressed in the following elementary lemma. Note
that the first part follows from Proposition 2.35, and the second part is
proved similarly.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
301
LEMMA 8.39 Let Y and Z be induced polycyclic sequences for U and V,
respectively.
a)
[U, V] is generated as a normal subgroup of 
 by the set [Y, Z]:= {[y,
z]|y ∈ Y, z ∈ Z}.
b)
If U and V normalize each other, then [U, V] is generated as a subgroup
by [Y, Z].
By iterating the commutator subgroup computation, we can calculate induced
polycyclic sequences for each of the subgroups in the derived series
 and in the lower central series 
. Hence we can also determine the lower nilpotent
series 
. where Li+1 is defined as the smallest
normal subgroup in Li with Li/Li+1 nilpotent; that is, Li+1 is the last term in
the lower central series of Li. This series can be refined to a series with
abelian factors using the lower central series of its factors. Thus we define
Lij/Li+1=j(Li/Li+1) and we obtain 
, a series with
central factors. Combining this with the lower nilpotent series yields the
refined lower nilpotent series 
.
Some properties of this series are summarized in the following lemma.
For a proof and for a more efficient algorithm to determine the refined lower
nilpotent series of G, we refer to the recent article by Cannon, Eick, and
Leedham-Green [CELG04].
LEMMA 8.40 The refined lower nilpotent series of G is a characteristic
series with abelian factors. Its factor Li,j-1/Li,j is central in Li/Li,j and its
factor L/Li2 splits over Li/Li2.
Suppose that 
 is a normal (or characteristic)
series with abelian factors. Our next aim is to refine this series to a normal
(or characteristic) series with elementary abelian factors. For this purpose
we use the methods of Section 8.4 to compute with the factors A=Ni/Ni+1.
Each of these factors A is a finite abelian group and we can read off the order
|A| from a polycyclic sequence for A. For a prime p dividing |A| we can
then determine Ap:={ap|a ∈ A} and thus obtain a characteristic subgroup
with elementary abelian factor A/Ap. Iterating this approach yields a normal
(or characteristic) series with elementary abelian factors through A.
Combining all of these refinements we obtain a normal (or characteristic)
Series with elementary abelian factors for G.
Suppose that 
 is a normal series with
elementary abelian factors. Our next aim is to refine this series to a chief
series for G. Let A:=Ni/Ni+1 be a factor in this series. Then A is an elementary
abelian p-group of rank d, say. The group G acts on A by conjugation. We
identify A with the additive group of the vector space 
 and switch to additive
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
302
notation. The conjugation action yields a homomorphism 
 in
this setting. Using the methods of Section 7.4 we can compute a composition
series of 
 as a G-module. This translates to a series A=A1>…>Ar>1 such
that each Aj is invariant under the action of G and irreducible as a 
 G-
module. If we refine every factor in the original series of G by such a module
composition series, then we obtain a chief series for G.
8.6 Orbit-stabilizer methods
Let G be a finite group defined by a refined consistent polycyclic
presentation and suppose that G acts on a finite set Ω. Then one can
determine orbits and stabilizers of elements in Ω using the methods of
Section 4.1. But in the special case that G is polycyclic, there is a more
efficient method to determine orbits and stabilizers available. This method
will be outlined in this section.
Let 
 be the defining presentation of G. Then X= [x1,…,
xn] is a polycyclic sequence. Its relative orders R(X)=(r1,…, rn) are primes and
they coincide with the power exponents of the presentation. For ω ∈ Ω, we
want to determine the orbit ωG={ωg|g ∈ G} and an induced polycyclic sequence
for the stabilizer StabG(ω)={g ∈ G|ωg=ω}.
We start by considering the special case when the polycyclic sequence X
has length 1; so G is cyclic of prime order r1. Then there are two possibilities:
(a) ωx1=ω. In this case StabG(ω)=G and thus StabG(ω) has the induced
polycyclic sequence [x1]. Further, we have ωG={ω}.
(b) ωx1≠ω. In this case StabG(ω)={1} and StabG(ω) has the induced polycyclic
sequence []. Further, we have 
.
Thus to determine the orbit and the stabilizer in this special case it is sufficient
to check whether ωx1=ω holds. The result can then be read off.
The central idea of the polycyclic orbit-stabilizer algorithm is to generalize
this method for the cyclic group to polycyclic groups. We use induction on the
length of X for this purpose. Recall that 
 has the polycyclic
sequence X2=[x2,…, xn] of length n–1. We assume by induction that we have
computed the orbit ∆:=ωG2 and that we have an induced polycyclic sequence
Y=[y1,…, ym] for the stabilizer S:=StabG2 (ω).The following lemma shows
how to extend these results to G.
LEMMA 8.41 Let ∆:=ωG2 and S:=StabG2 (ω) with induced polycyclic sequence
Y=[y1,…, ym] and relative orders R(Y)=(z1,…, zm). We distinguish the following
two cases.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
303
a)
In this case there exists an element g∈G2 with 
. Then [x1 g—1,
y1,…, ym] is an induced polycyclic sequence for StabG(ω) and its relative
orders are (r1, z1,…, zm). Further, we have ωG=∆.
b)
In this case we have StabG(w)=S and thus it has the induced polycyclic
sequence Y with relative orders R(Y). Further, we have
 
PROOF Let T:= StabG(ω) to shorten notation. First, we note that |G:G2|=r1
is a prime. As TG2=S, either |T:S|=r1 or T=S. Since
, we find that
.
In case a), the element g∈G2 exists by construction, since ∆ is the orbit of
ω under the action of G2. This yields that x1g—1∈T. Since x1g—1 ∉ G2, we have
x1g—1∈T\S and hence T≠S. By the above argument, this yields that |T:S|=r1
and ωG=∆. Further, we can extend the induced polycyclic sequence Y by an
arbitrary element of T\S to obtain an induced polycyclic sequence for T.
Hence x1g—1 is suitable for this purpose.
In case b), ωG≠∆. By the above argument, we have T=S and |ωG|=r1|∆|.
Since G2 is normal in G, the orbit ∆ is a block for the action of G; that is,
∆g=∆ or 
 for every g∈G. As ∆x1≠∆, we have 
. Similarly,
we find that the sets 
 are pairwise disjoint and thus their
union is the orbit ωG.
     
Lemma 8.41 allows us to extend orbits and stabilizers from G2 to G readily
and hence this lemma yields the inductive step in an orbit-stabilizer algorithm
for polycyclic groups. It only remains to discuss how to find the element g in
Lemma 8.41 a). An outline of the complete algorithm is presented in
POLYCYCLICORBITSTABILIZER.
It remains to discuss line 6 of this algorithm: the determination of the
element g. In the general orbit-stabilizer algorithm of Section 4.1, such an
element is computed either by storing a transversal of the orbit, or by
storing a Schreier vector for the orbit. In the polycyclic orbit-stabilizer
algorithm a transversal is not computed or stored. However, by line 10 of
the algorithm, the construction of ∆ is set up in such a way that we know
how each orbit point has been obtained without storing a transversal. This
can be used to determine g efficiently. This method is similar to the Schreier
vector method, but we do not store all of the powers 
 that arise in line
10; we just store the xi, and then the values of j and the powers 
 are
computed when required.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
304
POLYCYCLICORBITSTABILIZER(ω)
Input: ω∈Ω.
Output: An induced polycyclic sequence Y for StabG(ω), and ωG
1
Initialize ∆:=[ω];
2
Initialize Y:= [];
3
for i∈[n..1 by -1]
4     
do 
;
5     
if α∈∆
6    
then find g∈G2 with α=ωg;
7    
 
8   
else Γ:= [];
9     
for j∈[1..ri-1]
10     
do 
;
11     
∆:= ∆ cat Γ;
12
return Y and ∆;
8.7 Complements and extensions
In this section we shall describe effective methods to determine the conjugacy
classes of complements of a normal subgroup and to compute the equivalence
classes of extensions for finite polycyclic groups.
Complements are a frequently used tool in the theory of polycyclic groups.
The complement method outlined here was described first by Celler, Neubüser,
and Wright in [CNW90] and it is based on the algorithm to compute the first
cohomology group presented in Subsection 7.6.1.
Extensions are an important tool for constructing and describing polycyclic
groups. Here, we shall provide an effective method to compute the equivalence
classes of extensions of an elementary abelian G-module by a polycyclic group
G. This algorithm is based on the determination of the second cohomology
group, which is also outlined below.
Throughout the section we shall assume that 
 is a
finite group defined by a refined consistent polycyclic presentation with
X= [x1,…, xn].
8.7.1 Complements and the first cohomology group
Let 
 be a normal subgroup of G. We shall describe a method to
determine the conjugacy classes of complements of N in G. Every conjugacy
class is described by a conjugacy class representative U and its normalizer
NG(U) in G. Note that we do not work with full lists of subgroups in a
conjugacy class, as this would be too space consuming. We denote a
conjugacy class with representative U by UG.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
305
As a first step towards this aim, we determine a G-invariant series with
elementary abelian factors 
. For example, a
characteristic series with elementary abelian factors of N would be suitable
for this purpose; see Section 8.5. The next lemma observes that we can use
induction down this series to determine the conjugacy classes of complements
of N in G.
LEMMA 8.42 Let M≤N≤G with M, 
. Let L1/M,…, Lr/M be a set of
representatives for the conjugacy classes of complements of N/M in G/M
and let Ri/M:=NG/M(Li/M) be their normalizers. For 1≤i≤r let Ui1,…, Uili be
a set of representatives for the Ri-classes of complements of M in Li and let
Sij:=StabRi(Uij)=NRi(Uij). Then
a)
The set {Uij|1≤i≤r, 1≤j≤li} is a complete and irredundant set of
representatives of the conjugacy classes of complements of N in G.
b)
The normalizer in G of a conjugacy class representative can be obtained
as Sij:=NG(Uij) for 1≤i≤r and 1≤j≤li.
PROOF a) Let U be a complement of N in G. Then UM/M is a complement
of N/M in G/M. Thus U/M is conjugate to Li/M for some i; that is, there
exists g∈G with Ug/M=Li/M. Hence Ug is a complement of M in Li and thus
Ug is conjugate to Uij for some j; that is, there exists h∈Ri with Ugh=Uij. So
the set {Uij|i, j} is complete.
Now suppose that two representatives Uij and Ukl are conjugate. Then the
quotients UijM/M and UklM/M are also conjugate. By construction, we have
UijM/M=Li/M and UklM/M=Lk/M. As Li/M and Lk/M are either equal or
not conjugate, we have UijM=Li=Lk=UklM, and Uij and Ukl are two conjugate
complements of M in Li. Then they have to be conjugate under Ri, since M is
normal in G. This yields Uij=Ukl by construction.
b) This can be proved in a similar way to a) and we omit the proof.
     
Choose M=Nl in Lemma 8.42 and assume by induction that we have
determined the conjugacy classes of complements of N/M in G/M. Let L/M
be a representative for such a class and let R/M be its normalizer. It remains
to determine the R-conjugacy classes of complements of M in L.
First, using the methods of Section 7.6, we check whether there exists a
complement to M in L. If such a complement exists, then we determine one
such complement U explicitly and we compute the cohomology groups Z1
(L/M, M) and B1 (L/M, M). Then the elements of the factor group H1(L/M,
M)=Z1(L/M, M)/B1(L/M, M) correspond one-to-one to the L-conjugacy
classes of complements of M in L.
We digress at this point to introduce the concept of an affine action of a
group on a vector space, which we shall need here and also later in the
chapter, in Subsections 8.8.1 and 8.8.2.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
306
where, for 
.
The following lemma is the first step towards determining the R-
conjugacy classes of complements of M in L.
LEMMA 8.44 Let U be a complement of M in L and let R:=NG(L).
a)
For r∈R and γ∈Z1(L/M, M) we define
Then γϕ(r)∈Z1(L/M, M) and γ→γϕ(r) defines a linear action ϕ of R on
Z1(L/M, M).
b)
Every g∈L can be written uniquely as g=u(g)m(g) with u(g)∈U and
m(g)∈M. For r∈R we define
 
Then 
 is a derivation.
c)
By combining the linear action of a) and the derivation of b), we obtain
an affine action a of R on Z1(L/M, M) given by 
 for
r∈R and ζ∈Z1(L/M,M).
PROOF All three parts of the lemma are straightforward to prove. We refer
to [CNW90] or to [Eic02] for further information.
      
The setup provided by Lemma 8.44 can be used to determine the R-conjugacy
classes of complements of M in L as follows.
DEFINITION 8.43 Let 
 be a finite-dimensional vector space over a
field K, let ϕ:G→ HomK(V, V) be a linear action of a group G on V, and let
δ:G→V be a derivation with respect to the action ϕ. Then the map
α:G→Sym(V) defined by vα(g)=vø(g)+δ(g) is called an affine action of G on V.
It is straightforward to check that a is a homomorphism, so an affine action
is an action of G on the set V, but not a linear action unless δ=0.
If we identify V with Kn and HomK(V, V) with GL(n, K), then the affine
action a corresponds to the homomorphism :G→GL(n+1, K), given by  
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
307
THEOREM 8.45 Let U be a complement of M in L. We consider the affine
action α of R:=NG(L) on Z1(L/M, M) defined in Lemma 8.44 c).
a)
The orbits of R on Z1(L/M, M) are in one-to-one correspondence with
the R-conjugacy classes of complements of M in L.
b)
If γ∈ Z1(L/M, M), then StabR(γ)=NR(U).
PROOF If V is a complement corresponding to γ∈Z1(L/M, M), then the
complement Vr corresponds to the cocycle γr where R acts affinely on Z1(L/
M, M).
Hence it remains to determine the orbits and the stabilizers of the elements
in the elementary abelian p-group Z1(L/M, M) under the affine action of R
to determine the R-conjugacy classes of complements of M in L. We identify
the elementary abelian p-group Z1(L/M, M) with the additive group of 
and we switch to additive notation. As we remarked above, the affine action
a of R corresponds to a homomorphism 
. Now it
remains to calculate the orbits and stabilizers of the elements of the affine
space under the action of R via . This can be achieved effectively using
the orbit-stabilizer methods of Section 8.6.
Finally, we note that, as a further reduction, we can use the fact that the
group B1(L/M, M) is the orbit of the trivial cocycle under the affine action
of L, and thus B1(L/M, M) is a block for the action of R on Z1(L/M, M).
Hence it is sufficient to determine orbits and stabilizers under the action of
R on H1(L/M, M) and then to lift the results to Z1(L/M, M).
8.7.2 Extensions and the second cohomology group
Let M be an elementary abelian group having the structure of a G-module.
We shall describe an algorithm to determine the equivalence classes of
extensions of M by G. Every extension of M by G is a polycyclic group and we
want to determine a refined consistent polycyclic presentation for each
equivalence class representative. It is well-known that the equivalence classes
of extensions are in a one-to-one correspondence with the second cohomology
group H2(G, M)=Z2(G, M)/B2(G, M). Hence our algorithm provides a method
to determine this cohomology group also.
First, we introduce some notation. Let M be an elementary abelian p-
group of rank d, and let Y=[y1,…, yd] be a polycyclic sequence for M. We
describe the G-module structure of M by giving the action of every generator
xi on M. Since M can be considered as the additive group of the vector
space 
, we describe the action of xi on M by a matrix 
. We
denote the inverse of Xi by 
Next, we analyze the refined consistent polycyclic presentations of an
extension E of M by G. We identify M with its corresponding normal subgroup
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
308
The relations of type (R3) are the polycyclic relations of M, and the trivial
conjugation relations are omitted from them. The relations of type (R2) reflect
the action of E on M and thus are determined by the G-module structure of M
only. The interesting relations are those of type (R1). These relations exhibit
the relations of the quotient group G of E and the tails ti,j of these relations
determine the extension E. These tails are of the form
 
Hence every tail ti,j(y1,…, yd) can be identified with an element of M. For
l:=n2 we denote by t:=(ti,j|1≤i, j≤n)∈Ml the tail-vector consisting of all tails
ti,j.
DEFINITION 8.46 The polycyclic presentation
 
is called the polycyclic presentation for the tail-vector t∈Ml.
Let E be an extension of M by G that is defined by the cocycleγ∈Z2(G, M).
Then E has the polycyclic sequence [x1,…, xn, y1,…, yd] and this sequence
induces a polycyclic presentation P(t) for some t∈Ml. Hence we obtain a
mapping
 
The following lemma investigates the mapping ϕ.
LEMMA 8.47 The map ϕ is a homomorphism of abelian groups with
ker(ϕ)≤B2(G, M). Thus H2(G, M) ≅ Z2(G, M)ϕ/B2(G, M)ϕ.
in E and we also identify G with the corresponding quotient E/M. Using
this setup, it follows that E has a polycyclic sequence [x1,…, xn, y1,…, yd]. If
R(X)=(r1,…, rn), then this polycyclic sequence has the relative orders (r1,…,
rn, p,…, p). Thus it induces a refined consistent polycyclic presentation and
the polycyclic relations of this presentation have the following form: 
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
309
PROOF Let γ1, γ2∈Z2(G, M). Then, using additive notation for Z2(G, M)
and M, we have (γ1+γ2)(g, h)=γ1(g, h)+γ2(g, h) for g, h∈G, and so Eγ1+γ2 has a
polycyclic presentation of the type P(t1+t2) with 
 for i=1, 2. Thus
 and ϕ is a homomorphism. Now let γ∈ker(ϕ).
Then t=γϕ=0. Thus P(t) defines a split extension of M by F. Hence γ∈B2(F,
M).
     
The group H2(G, M) describes the equivalence classes of extensions of M by
G and our aim is to determine a basis for this elementary abelian group.
For this purpose we determine bases for Z2(G, M)ϕ and B2(G, M)ϕ. A basis
for B2(G,M)ϕ can be determined as the rows-pace of the matrix returned by
Z1-MATRIX as described in Section 7.6. In the following, we consider the
computation of Z2(G, M)ϕ. The following lemma yields a characterization of
this group.
LEMMA 8.48 We have t∈Z2(G, M)ϕ if and only if P(t) is a consistent polycyclic
presentation.
PROOF If t∈Z2(G, M)ϕ, then there exists γ∈Z2(G, M) with γϕ=t. The
extension Eγ induces the presentation P(t) and thus P(t) is consistent.
Conversely, if P(t) is consistent, then it defines an extension E of M by G.
The extension E is defined by a cocycle γ∈Z2(G, M) and γϕ=t.
Let T=(Ti, j|1≤i, j≤n) be a vector of n2 different indeterminates that can take
values in M. Then we can consider the (parameterized) polycyclic
presentation P(T). We determine the values for t∈Ml with P(t) consistent
by performing a consistency check in P(T).
DEFINITION 8.49 A word is collected with respect to P(T) if it is of the form
 
where 0≤ei<ri for 1≤i≤n and 0≤ei<p for m+1≤i≤m+d and 
 for 1≤i,
j≤n.
The collection algorithm of Section 8.1.3 generalizes readily to the
determination of collected words in P(T). Hence we can assume that we
can compute a collected word that is equivalent to an arbitrary word in
P(T) effectively. Using this collection algorithm we can perform the
consistency check of Chapter 12 in a symbolic form in P(T). This yields
equations of the type
 
for 
 and 
 Since G is given by a consistent
polycyclic presentation, we have 
 Hence the equation
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
310
can be rewritten as
 
The elements t∈Ml for which P(t) is consistent are exactly the solutions
of these resulting equations for T. It remains to solve this system of equations
over the elementary abelian group M. For this purpose we identify 
and switch to additive notation. Using the explicit G-module structure of M,
we can translate each coefficient 
 to a d×d matrix over 
.
Thus the system of equations obtained translates into a homogeneous system
of linear equations over 
. This can be solved readily.
Example 8.10
Let 
 and let 
 be a G-module via
 
Then we obtain the parameterized polycyclic presentation (where conjugation
with inverses is omitted):
 
To evaluate the consistency relations in P(T), we compute
 
and thus we obtain the relation
 
We have to find all possible solutions in M for this equation. To find these
solutions we switch to additive notation and consider T11 as a vector in 
.
Then x1 acts by conjugation as X1 and hence we have to find the nullspace of
X1–1. This nullspace can be computed readily as 
. This yields that
 and, translated back to the multiplicative setting, it yields
that we have to choose 
.
Similarly, we can determine that B2(G, M)ϕ={0} in this example. Hence
. So there are three equivalence
classes of extensions of M by G. Their refined consistent polycyclic
presentations can be obtained by choosing t11=1, or t11=y1y2, or 
.
We note here (without proof) that the two nonsplit extensions are
inequivalent as extensions, but they are isomorphic as groups. Thus the
method outlined here does not provide isomorphism classes of extensions.
     
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
311
8.8 Intersections, centralizers, and normalizers
In this section we shall outline three algorithms for finite polycyclic groups:
methods for computing intersections of subgroups, centralizers of elements,
and normalizers of subgroups. Also, we observe that similar methods can be
used to solve the conjugacy problems for elements and subgroups and to
determine all conjugacy classes of elements or subgroups.
The outlines in this section are overviews of the basic ideas of the algorithms
considered. More detailed discussions and more background on the methods
can be found in the papers by Mecky and Neubüser [MN89], Felsch and
Neubüser [FN70], Glasby and Slattery [GS90], and by Celler, Neubüser, and
Wright [CNW90]. For the larger class of infinite polycyclic groups we refer to
papers of Eick and Ostheimer [EO03, Eic02, Eic01b, Eic01a].
The algorith mic problems discussed in this section could all be solved by
straightforward applications of the orbit-stabilizer algorithm of Section 8.6.
The methods introduced in this section provide a refinement for this orbit-
stabilizer approach. Their basic idea is typical for algorithms in polycyclic
groups: they proceed by induction downwards along a normal series with
elementary abelian factors.
Throughout the section let 
 be defined by a refined consistent
polycyclic presentation and let 
 be a normal series
with elementary abelian factors; see Section 8.5.
8.8.1 Intersections
We shall introduce a method to compute 
 for two subgroups U and V of
G. We assume that U and V are both given by induced polycyclic sequences
and we want to determine an induced polycyclic sequence for 
. The
following elementary lemma shows that 
 could be computed by the
orbit-stabilizer algorithm of Section 8.6.
LEMMA 8.50 The subgroup U acts by multiplication from the right on the
right cosets 
.
However, the orbit arising in the computation of StabU(V) has the length
[
] and hence it can be large. Therefore, the application of the orbit-
stabilizer method can be time and space consuming. We want to investigate
refinements of this approach.
First, we consider the special case of a normalized subgroup in the
following elementary lemma. In this special case we can compute 
using the Kernel algorithm of Section 8.4.2. This is usually the most effective
approach to determine an intersection if it applies.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
312
LEMMA 8.51 If U is normalized by V, then 
 is the kernel of the natural
homomorphism ϕ:V→VU/U.
Now, we shall introduce a method to compute 
 in the general case. This
method refines the orbit-stabilizer approach of Lemma 8.50 and it uses the
special case of Lemma 8.51. The basic idea of the method is an induction
downwards along a normal series of G with elementary abelian factors. Let
N=Nl be the last nontrivial subgroup in such a series and suppose that N is
a p-group of rank d, say. By induction, we assume that the intersection in
the factor G/N is already computed; that is, we are given an induced polycyclic
sequence for 
. Thus we can read off an
induced polycyclic sequence for 
 using the preimages method of
Section 8.4.
LEMMA 8.52 Let ϕ:U→UN/N be the natural homomorphism. Then
.
PROOF This follows directly from 
.
Thus 
, and 
 can be computed effectively as
preimages of the subgroup 
 using the methods of Section 8.4.2.
We note that 
 holds, and it remains to determine the latter
intersection.
LEMMA 8.53 Let 
. Then:
a)
M is normalized by K and thus K acts on N/M by conjugation.
b)
Every k∈K can be written as k=vknk for vk∈V and nk∈N and the coset
nkM is uniquely defined by k.
c)
 is a well-defined derivation.
PROOF a) First we note that 
. Thus
M is normalized by V, since N is normal in G. Also, M is normalized by N,
since N is abelian. Thus M is normalized by VN and hence by K≤VN.
b) As K≤VN, we can write every element in K as product in VN. Clearly,
this factorization is unique modulo 
.
c) By b) it follows that δ is a well-defined mapping. Clearly, we have that
δ(1)=M. Further, since
 
we have δ(kh)=δ(k)hδ(h).
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
313
Note that this affine action can be computed effectively by its definition.
It yields the following characterization of 
.
LEMMA 8.54 
 where K acts via α on 
.
PROOF We noted already that 
 By Lemma 8.50 we have that
 where K acts by multiplication on the right on the cosets
L\G. We prove that StabK(L)=StabK(v) for 
. First, let
k∈StabK(L). Then k∈KL and thus k∈V. Hence nkM=M and δ(k)=0.
Therefore k∈StabK(v). Now, let k∈StabK(v). Then δ(k)=0 and thus nk∈M. As
, we have k∈L. Thus 
.
Hence we obtain an effective method to compute the intersection 
. Similar
to the method proposed by Lemma 8.50, this algorithm is also based on the
orbit-stabilizer algorithm of Section 8.6. But instead of computing one large
orbit of right cosets and its corresponding stabilizer, it determines several
smaller orbits of vectors and their corresponding stabilizers. This is usually
much more efficient.
8.8.2 Centralizers
We shall introduce a method of computing CG(g)={h∈G hg=gh} for an element
g∈G. We assume that g is given as a collected word in the generators of G
and we aim to determine an induced polycyclic sequence for CG(g).
The centralizer CG(g) is the stabilizer of g under the conjugation action
of G on its elements. Hence CG(g) can be computed using the orbit-stabilizer
algorithm of Section 8.6. However, the orbit of gG needs to be computed and
We note that the subgroup M of N can be computed by Lemma 8.51,
since N is a normal subgroup of G. We also note that N and thus also N/M
are elementary abelian p-groups and thus we can identify N/M with the
additive group of 
 where e is the rank of N/M. Using this identification
and switching to additive notation, we can write the conjugation action of
K on N/M as a homomorphism 
 and we consider δ as a
derivation of the form 
. This yields the following homomorphism
corresponding to the affine action (see Definition 8.43) of ϕ and δ on N/M: 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
314
This affine action yields the following characterization of CG(g).
LEMMA 8.56 CG(g)=StabC((0,…, 0, 1)) where C acts on 
 via α.
PROOF The stabilizer in C of (0,…, 0, 1) under the action of α is the kernel
of the derivation δ. By the definition of δ, we have ker(δ)=CC(g). As CG(g)≤C,
we have that CC(g)=CG(g) which completes the proof.
Hence we obtain an effective method to compute CG(g). Similar to the
method using a single orbit-stabilizer application, this algorithm is also
based on the orbit-stabilizer algorithm of Section 8.6. But this induction
method computes several relatively small orbits of vectors instead of one
relatively large orbit of elements in a polycyclic group. Thus the induction
method is usually more effective than the single orbit-stabilizer application.
8.8.3 Normalizers
For a given subgroup U≤G, we now introduce a method of computing its
normalizer NG(U):={h∈G|hU=Uh}. We assume that U is given by an induced
stored explicitly in this approach. This can be time and space consuming.
We introduce a more effective approach in the following.
The basic idea of the method is an induction downwards along a normal
series with elementary abelian factors. Let N=Nl be the last nontrivial term
in such a series and suppose that N is a p-group of rank d, say. By induction,
we assume that the centralizer in the factor group G/N is already computed;
that is, we have given an induced polycyclic sequence for C/N=CG/N(gN).
So we can read off an induced polycyclic sequence for C. The following
lemma is elementary.
LEMMA 8.55 The mapping 
 is a
derivation.
Now we identify N with the additive group of 
 and we switch to additive
notation. Then we can write the conjugation action of C on N as a
homomorphism 
 and we can consider δ as a derivation of
the form 
. These can be combined to give an affine action: 
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
315
polycyclic sequence and we aim to compute an induced polycyclic sequence
for NG(U).
The normalizer NG(U) is the stabilizer of U under the conjugation action
of G on its subgroups. Hence NG(U) can be computed using the orbit-stabilizer
algorithm of Section 8.6. However, the orbit UG needs to be computed and
stored explicitly in this approach. This can be time and space consuming.
Thus we introduce a refinement of this approach that is usually more efficient.
Once again, we use an induction downwards along a normal series with
elementary abelian factors. Let N=Nl be the last nontrivial term in such a
series such that N is an elementary abelian p-group of rank d, say. By
induction, we assume that the normalizer in the factor group G/N is already
computed; that is, we know an induced polycyclic sequence for R/N:=NG/N
(UN/N), and we can read off an induced polycyclic sequence for R. Now we
proceed in several steps.
As a first step we determine 
 using the idea of Lemma 8.51.
This is a usually very effective preliminary computation. As a second step,
we then compute S:=StabR(M). For this purpose we identify N with the
additive group of 
 and we switch to additive notation. Then the conjugation
action of R on N translates to a homomorphism 
 and we
have to compute the stabilizer of the subspace of N corresponding to M
under the matrix action of R on N.
The following lemma investigates M and S further.
LEMMA 8.57 Let S:=StabR(M) with 
. Then:
a)
M is normal in UN and thus UN≤S. Further, U/M is a complement
to N/M in UN/M.
b)
NG(U)=StabS(U/M) where S acts on the set of complements to N/M in
UN/M by conjugation.
PROOF a) M is normal in U, since N is normal in G, and M is normal in N,
since N is abelian. Thus M is normal in UN. As 
, it follows that
U/M is a complement to N/M in (U/M)(N/M)=UN/M.
b) NG(U) normalizes UN and 
, since N is normal in G. Thus
NG(U)≤S and hence we find that NG(U)=NS(U). As S normalizes M, we
have NS(U)=NS(U/M)=StabS(U/M), where S acts by conjugation on the set
of complements.
Hence it remains to determine the stabilizer of U/M under the conjugation
action of S on the complements to N/M in UN/M. This situation has already
been discussed in Section 8.7.1. There we showed in Lemma 8.44 that S
acts affinely on Z1(UN/N, N/M). Using this action, we can describe the S-
conjugacy class of U/M in S/M as an orbit under this affine action; see
Theorem 8.45.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
316
Thus as a third step in our algorithm, we determine the elementary
abelian p-group Z1(UN/N, N/M) and the affine action of S on this group.
Then, we identify the elementary abelian p-group Z1(UN/N, N) with the
additive group of 
 and we switch to additive notation. The affine action of
S translates into an action homomorphism 
. Now it
remains to calculate a stabilizer of the trivial affine vector under this action
of S. This is summarized in the following lemma.
LEMMA 8.58 NG(U)=StabS((0,…, 0, 1)) where S acts on 
 via the affine
action of Lemma 8.44.
Hence we obtain an effective method to compute NG(U). The induction
downwards along the normal series with elementary abelian factors splits
the computation into a sequence of induction steps. In each induction step we
have to perform a variety of computations. In particular, each induction step
requires two applications of the orbit-stabilizer algorithm. These two
applications are usually the time and space consuming parts of the algorithm.
8.8.4 Conjugacy problems and conjugacy classes
There are various related problems to the determination of centralizers
and normalizers. For example, with g, h∈G and U, V≤G there are the
following problems.
(1) Determine the conjugacy class gG or UG explicitly.
(2) Check whether there exists x∈G with gx=h or Ux=V.
(3) Determine all conjugacy classes of elements or subgroups in G.
All these problems can be solved by minor modifications of the algorithms in
the Sections 8.8.2 and 8.8.3. We discuss these problems for the elements of G
here briefly and we show that they can be solved by variations of the centralizer
algorithm. The corresponding problems for subgroups can be solved by similar
variations of the normalizer algorithm.
Problem (1) can be solved directly by the centralizer algorithm. If an induced
polycyclic sequence for CG(g) is given, then a transversal T for CG(g) in G
can be read off from Lemma 8.33. This yields that gG={gt|t∈T}.
Problem (2) requires a variation of the centralizer algorithm. In each
induction step of this algorithm a stabilizer computation is performed. To
solve Problem (2) we also compute its underlying orbit and check whether
the element induced by h is contained in this orbit. If not, then g and h are
not conjugate. If so, then we modify h to its conjugate hy such that hy
induces the same element as g in the considered factor. Then we proceed
to the next induction step.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
317
Problem (3) also requires a variation of the centralizer algorithm. In
each induction step of this algorithm a stabilizer computation of a given
element is performed. To solve Problem (3) we have to compute the orbits
and the stabilizer of all possible elements and then use all these elements
and their orbits and stabilizer in the next induction steps.
On a historical note, computing centralizers and conjugacy classes in finite
p-groups using the downwards induction method with polycyclic presentations
was introduced by V.Felsch and J.Neubüser in [FN79]. They used an
implementation of the algorithm to find a counterexample of order 234 to the
‘class-breadth’ conjecture. The conjecture was that, for a finite p-group G,
c(G)≤b(G)+1, where c(G) is the nilpotency class and b(G) is the size of the
largest conjugacy class of G.
Exercises
1.
Use the algorithm described above to compute the centralizer of (2, 3)
in G:=Sym(4), using the normal series with 
.
2.
Devise an alternative algorithm for computing the centralizer and
conjugacy class of an element g in a polycyclic group G, which works by
computing CGi(g) and gGi for i=n, n-1,…, 1, where G=G1≥G2≥…≥Gn+1=1
is a polycyclic sequence for G.
8.9 Automorphism groups
Let 
 be a polycyclic group defined by a refined consistent
polycyclic presentation. In this section we shall outline an algorithm to
compute the automorphism group Aut(G); that is, we want to determine
generators for Aut(G) and the order |Aut(G)|.
The method that is outlined here was first described by D.J.S.Robinson in
[Rob81] and an implementation has been investigated and outlined in detail
by M.J.Smith in [Smi94]. We note at this point that a dual approach can be
used to check isomorphism between two polycyclically presented groups. We
remark also that the methods for solving these problems in the special case
of finite p-groups, which will be discussed later in Subsections 9.4.5 and
9.4.6, are generally more efficient than those to be discussed here.
The basic approach of this method is to use induction downwards along a
characteristic series with elementary abelian factors; see Section 8.5. Thus
let 
 be such a series and let N=Nl be the last
nontrivial term in this series. Then N is an elementary abelian p-group of
rank d, say. By induction, we assume that we know generators and the
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
318
order of Aut(G/N) and we aim to determine generators and the order of
Aut(G). As N is characteristic in G, there exists a mapping
 
where αG/N and aN denote the induced actions of a on G/N and N. We
determine Aut(G) by computing the kernel and the image of ϕ. The kernel
can be obtained from the following lemma.
LEMMA 8.59 Let N be an elementary abelian p-group.
a)
Each element γ∈Z1(G/N, N) defines an automorphism αγ∈ Aut(G) by
gaγ:=gγ(gN) for g∈G.
b)
The mapping 
 is a monomorphism
with im( )=ker(ϕ).
c)
We have ker(ϕ)Z1(G/N, N).
PROOF a) is obvious and c) follows directly from b).
b) It is straightforward to prove that ψ is a monomorphism. It remains to
show that im(ψ)=ker(ϕ). Let α∈im(ψ). Then there exists γ∈Z1(G/N, N) such
that α=αγ. By the definition of αγ, α induces the identity on G/N and N.
Hence α∈ker(ϕ). Conversely, let α∈ker(ϕ). Then α induces the identity on
G/N and hence for each g∈G there exists ng∈N with gα=gng. As α induces
the identity on N, the function 
 is constant on cosets of N
and thus it is in fact a function of G/N. It is straightforward to check that δ
is a derivation of G/N and thus δ∈Z1(G/N, N). Hence α∈im(ψ) as desired.
Hence generators and the order of ker(ϕ) can be computed readily using
the methods of Section 7.6 and Lemma 8.59.
It remains to determine im(ϕ). First, we note that generators and the
order of Aut(G/N)×Aut(N) are available, since for Aut(G/N) this information
is known by induction and Aut(N)GL(d, p). Our aim is to determine
generators and the order for im(ϕ) from Aut(G/N)×Aut(N).
DEFINITION 8.60 Let 
 denote the action
homomorphism corresponding to the conjugation action of G/N on N. Then
we define the set of compatible pairs Comp(G, N) as
 
The following lemma notes that Comp(G, N) is a subgroup of Aut(G/N)×
Aut(N) and it also exhibits the connection between Comp(G, N) and the
image im(ϕ).
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
319
LEMMA 8.61 im(ϕ)≤Comp(G, N)≤Aut(G/N)×Aut(N).
PROOF It is straightforward to check that Comp(G, N) is closed under
multiplication; so it is a subgroup of Aut(G/N)×Aut(N). Let (v, µ)∈im(ϕ).
Then there exists α∈Aut(G) with αG/N=v and αN=µ. For h∈G/N, we have
.
Next, we describe a method of computing Comp(G, N) from Aut(G/N)
and Aut(N). Let 
 be the kernel and the image
of the conjugation action of G/N on N. Then K/N=CG/N(N) and I(G/
N)/(K/N)G/K. Let S:=StabAut(G/N)(K/N) and T:=NAut(N)(I). Then Comp(G,
N)≤S×T.
Generators and the orders of S and T can be computed from Aut(G/N)
and Aut(N) using the methods of Section 4.1 and thus we can also obtain
generators and the order of S×T. The group S×T acts on the set Hom(G/
N, Aut(N)) of all homomorphisms from G/N to Aut(N) via
 
and the compatible pairs form the stabilizer of ψ under this action. Hence
generators and the order of Comp(G, N) can be computed from S×T using
the orbit-stabilizer method of Section 4.1.
DEFINITION 8.62 For γ∈Z2(G/N, N) and (v, µ)∈Comp(G, N) we define
 
It is straightforward to observe that this induces an action of Comp(G,
N) on the group of 2-cocycles Z2(G/N, N). The subgroup B2(G/N, N) is
setwise invariant under this action. Thus we obtain an induced action of
Comp(G, N) on the second cohomology group H2(G/N, N).
DEFINITION 8.63 Let γ∈Z2(G/N, N) be a cocycle defining the extension
G of N by G/N. Then we define the set of inducible pairs as Indu(G,
N)=StabComp(G, N)(γB2(G/N, N)).
By definition, the inducible pairs form a subgroup of the compatible pairs,
and they can be computed using the orbit-stabilizer algorithm of Section
4.1. This yields an algorithm to compute the image im(ϕ) by the following
theorem.
THEOREM 8.64 im(ϕ)=Indu(G, N).
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
320
PROOF The proof of this theorem is straightforward, but technical. We
refer to [Rob81].
Theorem 8.64 yields that we can compute im(ϕ) as the stabilizer of a cocycle
coset γB2(G/N, N) under the action of the group of the compatible pairs
Comp(G, N). Hence we can compute generators and the order of im(ϕ)
using the methods of Section 4.1.
8.10 The structure of finite solvable groups
The structure of the finite solvable groups is well investigated and subgroups
such as Sylow and Hall subgroups and maximal subgroups play a major rôle
in this theory. The finite solvable groups are exactly the finite polycyclic
groups and hence every finite solvable group can be defined by a refined
consistent polycyclic presentation.
In this section we shall describe methods to compute such structure
theoretic subgroups in a group G that is defined by a refined consistent
polycyclic presentation 
. For further details and more advanced
methods of a similar nature we refer to papers by Cannon, Eick, Leedham-
Green, and Wright [CELG04, Eic93, Eic97, EW02]. For background on the
underlying theory of finite solvable groups see [DH92].
8.10.1 Sylow and Hall subgroups
DEFINITION 8.65 Let p be a prime and let π be a set of primes. Write
 for distinct primes p1,…, pr.
a)
A Sylow p-subgroup S of G is a subgroup of p-power order such that
; that is, |G:S| is coprime to |S|.
b)
A Hall π-subgroup H of G is a subgroup such that all prime divisors of
|H| are contained in π and |G:H| is coprime to |H|.
c)
A Sylow system of G is a set of Sylow subgroups {S1,…, Sr} such that Si
is a Sylow pi-subgroup and SiSj=SjSi holds for each i≠j.
d)
A complement system of G is a set of subgroups {C1,…, Cr} such that
|G:Ci| is a pi-power and |G:Ci| is coprime to |Ci| for 1≤i≤r. The
group Ci is called a pi-complement.
It is well-known that every finite solvable group has a Sylow system and a
complement system. In fact, this existence can be used to characterize the
solvable groups among the finite groups. A complement system gives rise to
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
321
Hall subgroups for every possible set of primes π and it also gives rise to a
Sylow system, as the following lemma recalls. We refer to [Hup67], VI 1.5
and VI 2.2 for a proof.
LEMMA 8.66 Let {C1,…, Cr} be a complement system of G.
a)
Then 
 is a Hall π-subgroup in G.
b)
The set {S1,…, Sr} with 
 forms a Sylow system for G.
It is the aim of this section to outline an algorithm for computing a complement
system in the finite polycyclic group G. For this purpose we use induction
downwards along a normal series with elementary abelian factors
. Thus let N=Nl be the last nontrivial term in
this series. Then N is an elementary abelian p-group of rank d, say.
By induction, we assume that we have determined a q-complement C/N
of G/N for some prime q. We want to compute a q-complement of G. We
have to distinguish two cases on p and q as outlined in the following lemma.
LEMMA 8.67 Let C/N be a q-complement in G/N for a p-group N.
a)
If p≠q, then C is a q-complement of G.
b)
If p=q, then there exists a complement to N in C and every such
complement is a q-complement of G.
PROOF a) In this case we have that |G:C| is a q-power and |C|=|C/
N||N| is coprime to q. Thus C is a q-complement in G.
b) In this case we have that |C/N| is coprime to q=p and thus |C/N|
and |N| are coprime. Hence there exists a complement to N in C by the
Schur-Zassenhaus theorem [Rot94, Theorem 7.24]. Let K be such a
complement. Then |K|=|C/N| is coprime to q and |G:K|=|G:C||N| is
a q-power. Thus K is a q-complement in G.
Lemma 8.67 yields a method to determine a q-complement by the methods of
Section 7.6. However, in this special situation, we can determine complements
with a more effective method. We give a brief outline of this improvement
in the following. It makes use of the fact that, in case b) of the lemma,
every complement of N in a subgroup of C is contained in a complement of
N in C. This follows from the other part of the Schur-Zassenhaus theorem,
which says that, when |C/N| and |N| are coprime, then all complements
of N in C are conjugate.
Let p=q and let Y:=[c1,…, cr, n1,…, nd] be a polycyclic sequence for C such
that 
 and such that the relative orders R(Y)=(s1,…, sr, p,…,
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
322
p) are all primes. Then every complement T of N in C has a polycyclic
sequence of the form [c1l1,…, crlr] for certain elements li∈N. Our aim is to
determine such elements l1,…, lr. The following lemma yields a
characterization of these elements.
LEMMA 8.68 Let Z:=[c1l1,…, crlr] for l1,…, lr∈N. Then Z is an induced
polycyclic sequence for a complement to N in C with respect to Y if and only
if (cjlj)sj and the commutators [cjlj, cklk] can be written as normal words in Z
for 1≤j<k≤r.
PROOF This follows directly from Lemma 8.34.
By induction, we assume that the elements lj+1,…, lr have already been
determined and we want to compute lj. Let bk:=cklk for j+1≤k≤r, and let
Y′:=[c1,…, cj, bj+1,…, br, n1,…, nd]. Then Y′ is an induced polycyclic sequence
for C. Therefore, by Lemma 8.34, we find that the power 
 and the
commutators [bk, cj] for j+1≤k≤r can be written as normal words in Y′ of
the form
 
The following lemma yields a method to determine lj from this setup.
LEMMA 8.69 Let C be a group and 
 an abelian normal subgroup.
a)
Let c,b∈C with [b, c]=wv for v∈N. Then, for 
 if and
only if lα=v with a=bw-1.
b)
Let c∈C with cs=wv for v∈N. Then, for 
 if and only if
lb=v with 
.
PROOF The proof is an elementary computation. We refer to [CELG04] for
an outline.
8.10.2 Maximal subgroups
In this section we shall give an outline of an effective algorithm to compute
the conjugacy classes of maximal subgroups of G.
DEFINITION 8.70
a)
N/L is called a normal factor of G if L, 
 with L≤N.
© 2005 by Chapman & Hall/CRC Press

Computation with Polycyclic Groups
323
b)
K is called a complement to the normal factor N/L if 
 and
KN=G.
Thus K is a complement to the normal factor N/L if L≤K and K/L is a
complement to N/L in G/L. Complements to chief factors can be used to
determine maximal subgroups, as the following lemma shows.
LEMMA 8.71 Let 
 be a chief series of G. The
conjugacy classes of maximal subgroups in G coincide with the conjugacy
classes of complements of the normal factors Ni/Ni+1 for 1≤i≤l.
PROOF Let M be a maximal subgroup of G and let i be minimal with
Ni+1≤M. Then i≥1, since M is a proper subgroup of G and thus 
. And
i≤l, since Nl+1={1}≤M. Since M is maximal in G and 
, we obtain that
MNi=G. Further, we find that 
 and 
 is normal in G. As
Ni/Ni+1 is a chief factor, this yields 
 and M complements Ni/
Ni+1. Using similar arguments, one can prove readily that every complement
to a chief factor Ni/Ni+1 is a maximal subgroup in G.
Lemma 8.71 yields a method of computing the conjugacy classes of maximal
subgroups of G. We first determine a chief series of G as described in
Section 8.5. Then we consider every factor of this series in turn and
compute its conjugacy classes of complements with the method outlined
in Section 7.6.
When applying this method it often happens that many of the chief factors
do not have any complement at all. Hence this method incorporates a lot of
redundant work in this case. This can be avoided with the second approach,
which is outlined briefly in the remainder of this section.
We consider the lower nilpotent series 
 and, as
in Section 8.5, we define Li2 as the commutator subgroup by Li2/Li+1:=(Li/
Li+1)′. As noted in Lemma 8.40, there exists a complement Ki to the normal
factor Li/Li2 in G. Also, we note that every maximal subgroup M of G covers
all but one of the factors of the lower nilpotent series of G. This setup allows
us to describe the conjugacy classes of maximal subgroups in G as follows.
THEOREM 8.72 For 1≤i≤r, let Ki be a complement to Li/Li2 in G and let
Ai1/Li2,…, Aiki/Li2 be a set of maximal G-normal subgroups in Li/Li2.
a)
The set 
 is a complete set of conjugacy class
representatives for the maximal subgroups of G.
b)
We have NG(KiAij)=G if i=1, and NG(KiAij)=KiAij otherwise.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
324
PROOF We refer to [CELG04].
Hence we obtain an algorithm to compute the conjugacy classes of maximal
subgroups. First, we determine the refined lower nilpotent series as in Section
8.5. Then we consider each factor Li/Li2 in turn and determine its G-normal
maximal subgroups. As Li/Li2 is abelian, the G-normal maximal subgroups
translate to maximal G-submodules of this factors and hence they can be
computed by an application of the Meataxe; see Section 7.4. Finally, we need
to determine a complement Ki to Li/Li2 in G. This can be done with a
straightforward application of the methods in Section 8.7.1. We note here
that a more effective approach for this purpose is described in [CELG04] and
it follows similar ideas to the methods in Section 8.10.1.
Exercise
1.
Use the methods described in this section to compute the maximal
subgroups of Sym(4).
© 2005 by Chapman & Hall/CRC Press

325 
Chapter 9 
Computing Quotients of 
Finitely Presented Groups 
If we have a finitely presented group G, what can we discover about the 
structure of G? Unfortunately, as we remarked at the beginning of Chapter 
5, most of the natural questions that we might be inclined to ask are 
provably undecidable in general. 
In Chapters 12 and 13, we shall study general algorithms, which approach 
such problems by attempting to compute a normal form for the elements 
of G. They are only successful for certain specific types of groups, but when 
they do succeed, they enable many questions about G to be answered, such 
as “is G finite?”. 
In this chapter, we shall investigate and describe algorithms that aim to 
compute quotients of G of specific types. In many cases, these are 
theoretically guaranteed to succeed given adequate computational 
resources. Specifically, we shall study algorithms that compute general 
finite quotients, abelian quotients, and quotients that are finite p-groups. 
Particularly when used in combination with each other, these methods can 
on occasion be used to prove that G is infinite; see Subsection 9.3.3. A 
summary of other quotient algorithms that have been proposed or 
implemented, including nilpotent, solvable, and polycyclic quotient 
algorithms, will be given in Subsection 9.4.3. 
Many of the algorithms to be described in this chapter are implemented 
within the interactive graphics package QUOTPIC [HR93], by Holt and 
Rees. This enables the user to plot and visualize quotients computed so far, 
and then to decide which further calculations to undertake. 
In some cases, the algorithms to be described lead on naturally to other 
algorithms of central importance in CGT. The finite quotient algorithm 
can be easily adapted to compute automorphism groups of finite groups 
and to test pairs of finite groups for isomorphism. The algorithm to compute 
finite p-quotients can be adapted and further developed to enumerate 
representatives of the isomorphism classes of all finite p-groups up to a 
specified order, and this in turn gives rise to algorithms to compute 
automorphism groups of finite p-groups and to test pairs of finite p-groups 
for isomorphism. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
326 
9.1 
Finite quotients and automorphism groups 
of finite groups 
The low-index subgroups algorithm discussed in Section 5.4 finds 
representatives H of the conjugacy classes of subgroups of a finitely 
presented group F up to a given index n. For each such subgroup H, there 
is a related action of F by multiplication on the right cosets of H, and the 
low-index subgroups algorithm in fact finds the coset table of H in F, which 
defines the generator images in this action. So, effectively, 
LOWINDEXSUBGROUPS finds all homomorphisms F→Sym(n), and it can 
be regarded as a method of finding the finite quotient groups of F. 
The performance of LOWINDEXSUBGROUPS deteriorates rapidly with 
increasing n (experiments suggest that the complexity is worse than 
exponential in n), however, and so it can only find finite quotients that have 
a permutation representation of low degree. There is an alternative approach 
to finding finite quotients, which we shall discuss in the this section, in which 
we fix a target group G and search specifically for homomorphisms (or, more 
usually, for epimorphisms) F→G. Like LOWINDEXSUBGROUPS, its 
performance deteriorates rapidly with the number of generators of F, but 
otherwise its running time is a polynomial function of |G| and does not rely 
on G having a low-degree permutation representation. 
This method also provides a reasonably efficient approach to computing 
automorphism groups of finite groups G and testing two finite groups G 
and H for isomorphism, provided that Aut(G)/Inn(G) is not too large. The 
algorithm, together with the application to automorphism group 
computation is described by Hulpke in [Hul96, V.5]. It has been implemented 
in GAP by Hulpke and as a stand-alone program and in MAGMA by Holt. 
Both LOWINDEXSUBGROUPS and the EPIMORPHISMS algorithm 
are indispensable tools for finding finite quotients of finitely presented 
groups. The former will be much more effective for quotients such as Alt(n) 
and Sym(n), but the latter is needed for relatively small target groups, 
such as the simple group J1 of order 175560, which have no small-degree 
faithful permutation representation; the smallest such representation of 
J1 has degree 266, which is usually much too large for LOWINDEX- 
SUBGROUPS. 
9.1.1 Description of the algorithm 
Let 
 be a group defined by a finite presentation, where X= 
[x1,…, xr], and let G be a finite group. The problem to be discussed in this 
section is that of finding homomorphisms from F to G. 
Often we are mainly interested in epimorphisms rather than in all 
homomorphisms, so we shall make our main algorithm return a list of 
epimorphisms, but in fact it will only check the surjectivity of a 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
327 
homomorphism found at the final stage, and so it can be modified to find all 
homomorphisms simply by leaving out this final check. 
Sometimes we are only interested in finding a single epimorphism, but 
let us assume that we require a complete list of all such epimorphisms. If 
ϕ:F→G is a homomorphism, and :G→G is an automorphism, then the 
composite ϕ′:=ϕ is another epimorphism, and we say that ϕ and ϕ′ are 
equivalent modulo Aut(G). It is not hard to show that epimorphisms ϕ and 
ϕ′ from F to G are equivalent modulo Aut(G) if and only if ker(ϕ)=ker(ϕ′), 
and so the distinct quotient groups of F that are isomorphic to G correspond 
exactly to the equivalence classes modulo Aut(G) of epimorphisms F→G. 
For this reason, and also in order to save time and space, it makes sense 
to ask for a list of representatives of these equivalence classes, rather than 
of all epimorphisms; that is, we would like a list of epimorphisms from F to 
G up to equivalence modulo Aut(G). However, we do not normally want to 
make the computation of Aut(G) an integral and necessary part of the 
algorithm, and so we shall design it to take three input parameters, F, G 
and A, where G must be a normal subgroup of A, and a list of epimorphisms 
F→G up to equivalence modulo conjugation by elements of A is returned. 
That is, epimorphisms ϕ and ϕ′ are defined to be equivalent if one is the 
composite of the other and the conjugation action of an element α∈A on G. 
The user will usually want to choose A such that A induces all of Aut(G) 
on G; for example, G=PSL(2, q) and A=PL(2, q). But a lazy user can just 
use the default of A=G, and get a possibly longer list of epimorphisms that 
are equal up to equivalence modulo Inn(G). 
The basic idea is simple-minded. We consider all r-tuples (g1,…, gr)∈Gr, 
and use the criterion in Theorem 2.52 to test whether the map ϕ:X→G 
defined by ϕ(xi)=gi for 1≤i≤r extends to a homomorphism ϕ:F→G. Let us 
refer to this process as considering (g1,…, gr) as an image. 
In the case when R= and F is free, all such maps define homomorphisms, 
and so we cannot improve much on this. However, in general, considering 
|G|r such r-tuples as images will be hopelessly slow except for very small 
groups G and small values of r, so we should try and use backtrack search 
methods to prune the search tree. 
According to the ideas presented in Section 4.6, to prune the search 
tree, we should try to find methods of ruling out k-tuples (g1,…, gk) as 
initial subsequences of possible images (g1,…, gr), for k<r. This can be done 
if some of the relators in R only involve the generators x1,…, xk and their 
inverses, because then we can apply the criterion of Theorem 2.52 to those 
relators, using only g1,…, gk. If the criterion fails, then we can prune the 
search tree by ruling out the initial subsequence (g1,…, gk). If the criterion 
succeeds with k<r, however, then we need to descend to the next level and 
consider possible images gk+1. If the criterion succeeds with k=r, then we 
have found a homomorphism ϕ:F→G, and to test whether it is an 
epimorphism, we just check whether 〈g1,…, gr〉=G. 
To make these tests as effective as possible, we begin by reordering the 
generating sequence [x1,…, xr] of F so as to make the subsets Rk of R 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
328 
consisting of those relators that only involve x1,…, xk and their inverses as 
large as possible. We shall not attempt here to define precisely what we 
mean by that, or to present the algorithm for doing this. In unfavourable 
cases, we might find that all relators involve all of the generators, in which 
case we have no means of pruning the search tree. 
Many, but by no means all, presentations that arise in practice contain 
relators of the form xn for some x∈X, n∈N, which provides an upper bound 
on the order of x in F. In this situation, x can only be mapped by a 
homomorphism ϕ:F→G to an element of G of order dividing n. 
Guided partly by this idea, we have designed the algorithm such that it 
starts by finding representatives h1,…, hc of the conjugacy classes of A that 
lie G. For 1≤i≤r, we then define Ii to be the subset of {h1,…, hc} consisting of 
those hj that are possible images of xi in a homomorphism ϕ:F→G; that is, 
those hj for which ϕ(xi)=hj is not ruled out by its order and a relator of F of 
the form 
. Then we take each r-tuple of elements (g1,…, gr) with each 
gi∈Ii in turn, and consider the r-tuples 
 for elements ai∈A as 
images. This splits up the search into a number of subsearches, one for 
each such r-tuple (g1,…, gr) with each gi∈Ii. 
Experiments and experience indicate that doing that usually speeds up 
running times, particularly when there are relators of the form gn. 
Unfortunately, in some examples, particularly those in which there are no 
relators of the form gn and (even more so) those in which all relators involve 
all elements of X, it is quicker simply to run through all r-tuples of group 
elements in the naive manner. This makes it difficult to design a single 
algorithm that performs as well as possible on all examples. 
In order to get each conjugate gi
i only once in the r-tuples 
, 
we restrict the i to lie in a transversal Ti of CA(gi) in A. 
We have not yet discussed how we find epimorphisms only up equivalence 
modulo conjugation by elements of A. For this, we want to consider not all 
 as images, but only orbit representatives of the action of A on 
the set of all such r-tuples defined by 
for ∈A. 
To find such representatives, we apply the following easy proposition 
and corollary, of which we leave the proofs to the reader. 
PROPOSITION 9.1 Suppose that a group G acts on sets 1 and 2. Let 
1,…, t be representatives of the orbits of G on 1 and, for 1≤i≤t, let 
 be representatives of the orbits of Gi on 2. Then 
is a set of orbit representatives of G in its induced action on 1×2. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
329 
COROLLARY 9.2 Suppose that G acts on sets i for 1≤i≤r. Then we can 
find a set R of representatives (1,…, r) of G in its induced action on 
1×…×r, such that the following is true for all 1≤k≤r. The initial 
subsequences (1,…, k) of elements (1,…, r)∈R form a set of representatives 
of the induced action of G on 1×…×k, and, for each such (1,…, k), the 
sequences (r+1,…, r) such that (1,…, r)R form a set of orbit representatives 
in the induced action of 
 on k+1×…×r. 
In our application, the set i in Corollary 9.2 is the A-conjugacy class 
, 
and the action is conjugation by A, which is transitive. So, by choosing k=1 
in this corollary, we see that we only need to consider r-tuples 
(
) beginning with g1. 
More generally, for 2≤k≤r, suppose that we are considering r-tuples 
with initial subsequence (
). Then the intersection of the 
stabilizers in A of the 
 is equal to 
 (where 1=1). So we 
need to compute orbit representatives of the action of C by conjugation on 
. These are given by 
, for 1≤j≤l, where ß1,…, ßl are representatives of 
the double cosets CA(gk)jC in A. 
It is convenient to compute these double coset representatives during 
the backtrack procedure for considering images. We discussed the 
computation of double coset representatives in Subsection 4.6.8, and we 
shall assume the availability of a function DCR that does this. 
The function for finding epimorphisms of F onto G up to conjugation in 
A is displayed in EPIMORPHISMS. 
This is a tricky function to understand. Here is an explanation of some 
of the variables that are used in the function. 
k is the current level in the search; that is, the component in the r-tuples 
(
) that we are currently considering. 
[j] stores the intersection of centralizers 
; recall that [k-1] 
was denoted by C in the explanation above. 
[k] is a list of representatives of the double cosets CA(gk)g[k-1] of CA(gk), 
[k-1] in A. 
µ[k] is the index such that [k][µ[k]] is the double coset representative in 
the list [k] currently being considered. 
im[k], which represents the component 
 in the r-tuple being currently 
considered, should be interpreted as being an alias for 
; that is, 
the conjugate of gk under the µ[k]-th element in the list of double coset 
representatives discussed above. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
330 
EPIMORPHISMS(F, G, A) 
Input: F=〈X|R〉, finite groups G, A with G  A 
Output: List of epimorphisms F→G up to conjugation by A 
Remark: im[k] is an alias for 
. 
1 Reorder generators x1,…, xr of F such that the subsets Rk⊆R of relators 
that involve just 
 for 1≤i≤k are as large as possible. 
2 Calculate representatives hi(1≤i≤c) of the conjugacy classes of A that lie 
in G. 
3 for i∈[1..r] 
4 
do if there is a relator 
 in R with t>0 
5 
then Ii:={hi|1≤i≤r, t mod |hi|=0}; 
6 
else Ii:={hi|1≤i≤r}; 
7 H:=[]; (* the list of epimorphisms to be computed *) 
8 for each (g1,…, gr)∈I1×…×Ir 
9 
do (* Consider images 
 for suitable hij∈A *) 
10 
[1]:=CA(g1); f:=false; k:=2; 
11 
while k>1 
12 
do if not f then [k]:=DCR(A, CA(gk), [k-1]); 
13 
µ[k]:=1; f:=false; b:=true; 
14 
while b and k>1 
15 
do b:=false; 
16 
while µ[k]≤|[k]| 
17 
do if not TESTRELS(k, im[1],…, im[k]) 
18 
then µ[k]:=µ[k]+1; 
19 
if µ[k]>|[k]| 
20 
then b:=true; k:=k-1; 
21 
if k>1 then µ[k]:=µ[k]+1; 
(* Relations are satisfied by images at level k *) 
22 
if k>1 
23 
then if k<r 
24 
then [k]:=C[k-1](im[k]); 
25 
k:=k+1; 
26 
else f:=true; 
27 
if im[1],…, im[k]=G 
28 
then APPEND(~H, im); 
29 
µ[k]:=µ[k]+1; 
30 return H; 
TESTRELS(k, im[1],…, im[k]) at line 17 checks whether the first k 
components of the current r-tuple being considered satisfy the relators 
in Rk. If so, then the code proceeds to line 23 and we move down to the 
next level, k+1, except when k=r, in which case we have found a 
homomorphism F→G. If not, then this k-tuple is not part of a possible 
image, so we move on to the next conjugate of gk at the same level. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
331 
We have not written out the details of TESTRELS, and the overall 
performance depends critically on an efficient implementation of it, so 
we shall discuss this matter later. 
b (for backtrack) is set to be true at line 13 (the top of the main loop in the 
backtracking process), and also when we have just decreased k. 
f (for found) is set to be true when we have just found a homomorphism 
from F to G. 
Example 9.1 
As an example, let 
, let G:=PSL(2, 8) and let 
A:=PΓL(2, 8). Then |A:G|=3 and A ≅ Aut(G). We use the natural 
permutation representation of G and A on 9 points. Representatives of the 
five conjugacy classes of A that lie in G are 
From the relators x2 and y3, we find that the sets I1 and I2 of conjugacy 
class representatives of possible targets of x and y in a homomorphism F→G 
are I1={1G, (1, 6)(3, 7)(4, 5)(8, 9)} and I2={1G, (1, 3, 2)(4, 7, 8) (5, 6, 9)}. So there 
are four possibilities for (g1, g2)∈I1×I2 in the outer ‘For’ loop beginning at line 
8 of EPIMORPHISMS. 
Of these, g1=g2=1 defines a homomorphism but not an epimorphism. It 
is immediately clear to us that, if g1=1 or g2=1 but not both, then the image 
of the relator (xy)7 cannot be satisfied in G, and so no homomorphism is 
possible with these images. The function itself is not so clever, and will 
have to eliminate these possibilities by running through the search, but 
this will not be unduly time-consuming. 
So let us consider g1=(1,6)(3, 7)(4, 5)(8, 9), g2=(1,3, 2)(4, 7, 8)(5, 6, 9). At 
the top of the ‘While’ loop at line 11, we have k=2 and Λ[k-1]=CA(g1). We 
then go on to calculate representatives of the double cosets CA(g2)gCA(g1) in 
A. It turns out that |A:CA(g2)|=56, but there are just 3 orbits of the 
corresponding right coset action of CA(g1) (which has order 24), and so there 
are three double coset representatives: 
The function then applies TESTRELS with 
for i=1, 2, 3. We find that 
 and 
, so TESTRELS fails on 
the relators (xy)7 and returns false. But 
 and 
, so 
TESTRELS returns true for 3. We now have k=2=r, so Theorem 2.52 
tells us that the map 
 extends to a 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
332 
homomorphism F→G, which is in fact an epimorphism. The search is now 
complete, so this epimorphism is unique up to conjugation by A, which proves 
that F has a unique quotient group F/K that is isomorphic to PSL(2, 8).     [] 
The example above is very quick and easy, and the corresponding 
epimorphism could have been found equally quickly by running the low- 
index subgroups algorithm up to index 9. It does raise one interesting 
question, however: could we have done anything to avoid executing the 
searches in which one of g1 and g2 was 1, in view of the fact that it was so 
obvious to us that they were doomed to be fruitless. 
There is a possibility of this nature, which has been tried in 
implementations, and would enable us to avoid the fruitless searches in the 
example. For each generator xi of F and each order ni of a potential image gi 
of xi in G, we append the new relator 
 to F and run a coset enumeration 
program over the trivial subgroup of the modified group presentation 
 for a very short time. If this enumeration completes 
and shows that |F′|<|G|, then there can be no epimorphism ϕ:F≤G in which 
ϕ(xi) has order dividing ni (proof left to the reader!). Hence we can remove 
any gi whose order divides ni from the set Ii of possible targets. 
9.1.2 Performance issues 
The performance, in terms of running time, and hence the overall usefulness 
of the above algorithm depends critically on its implementation. We shall 
briefly discuss some of the issues involved here. 
It helps to start with an approximate idea of the feasible range of 
applicability. It is generally not the most appropriate algorithm to use when 
the target group G is abelian or even sol vable. In that case, it is usually 
more sensible to employ the quotient algorithms to be discussed in later 
sections of this chapter. 
EPIMORPHISMS is most often used when G is close, in some way, to 
being a nonabelian simple group, so we can expect the number of 
conjugacy classes of G to be significantly smaller than |G|. This means 
that we have relatively few targets to consider for the first generator x1 of 
F. In that situation, for 2-generator groups F, we would hope to be able to 
use EPIMORPHISMS for groups G up to order about 107 or 108. For 3- 
generator groups F, this drops to about |G|≤1000 and it becomes rapidly 
unusable with still larger numbers of generators of F. The range tends to 
increase for presentations F with one or more relators of the form xn
i, and 
for which the subsets Rk of R are large. 
A consequence of the above situation is that for the groups G involved, 
the computations within G, such as conjugacy class representatives, and 
even the double coset representative calculations are likely to account for 
a very small proportion of the overall running time. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
333 
The double coset representative calculations can be made most efficient 
by calculating and storing the transversals Ti of CA(gi) together with the 
associated coset action homomorphisms A→Sym(i) (see Subsection 4.6.7) 
before entering the ‘While’ loop at line 11. For groups G within the practical 
range of the algorithm there is likely to be enough memory available to do 
this, and it avoids having to recompute them with every call of DCR. As we 
saw in Subsection 4.6.8, double coset representatives are computed as orbit 
representatives on these transversals under the coset actions. 
A high proportion of the running time will typically be used within the 
calls of TESTRELS, and so it is vital to implement TESTRELS as efficiently 
as possible. For this, we need to check whether the condition in Theorem 
2.52 is satisfied for the current generator images under consideration, which 
entails evaluating the group relators on the current images. If, as is 
generally the case, G is given as a finite permutation group, then this 
amounts to checking whether the associated permutations obtained by 
substituting the current generator images in the group relators evaluate 
to 1G. If a base of G is known (see Subsection 4.4.1) then, to do this, we 
need only check whether the base points are fixed by the permutation 
word. So, we should endeavour to use a permutation representation of G 
having a small base, and then we can avoid multiplying out the complete 
permutations within the word. 
It is unclear whether we should evaluate the generator images im[k]= 
 as permutations, or whether we should leave them as permutation 
words; this is one reason why we have chosen to use im[k] as an alias. 
Experiments suggest, but not completely conclusively, that we might obtain 
the fastest times by evaluating im[k] for k<r, and leaving them as words at 
the bottom level k=r. 
It is also interesting to observe that the EPIMORPHISMS algorithm 
seems to be highly parallelizable, and running times could undoubtedly be 
reduced by using a parallel version spread across several machines, but to 
the author’s knowledge this has not yet been attempted. 
9.1.3 Automorphism groups of finite groups 
Methods for computing Aut(G) and for testing two groups G and H for 
isomorphism for finite solvable groups and finite p-groups are described in 
Sections 8.9 and 9.4.5, respectively. These problems can be solved for finite 
permutation groups G (respectively G and H) by application of 
EPIMORPHISMS with F=G for the automorphism group and F=H for the 
isomorphism testing computation. A finite presentation is required for F, 
but such a presentation can easily be calculated if necessary by use of the 
methods described in Section 6.1. This application is described in more 
detail by Hulpke in [Hul96, V.5]. 
Before embarking upon such a computation, it is worthwhile to devote 
some effort to selecting a suitable generating set for F, for this can 
significantly affect the time taken by the main computation. It is vital that 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
334 
this set should be as small as possible. The minimal number ra of generators 
for the abelianized group F/[F, F] is equal to the number of its invariant 
factors, which can easily be computed by the abelian quotient algorithm, to 
be described in the next section. 
If [F, F]=1 and ra=1, then F is cyclic, and we can find a single generator, 
so suppose not. Then starting with r equal to min(2, ra), we make some 
effort to find a generating set of F of size r. If we fail, then we replace r by 
r+1 and try again. In [Hul96, V.5], Hulpke advocates using a short run of 
EPIMORPHISMS itself, but with F equal to the free group of rank r and G 
equal to the permutation group G or H, in an attempt to find such a 
generating set of size r. 
For a given list [x1,…, xr] of generators of F and an isomorphism ϕ:F→G, 
each ϕ(xi) must lie in a conjugacy class of G that has the same size as the 
class xF
i of xi in F. This enables us to estimate in advance the number of 
images of [x1,…, xr] that will need to be tested in EPIMORPHISMS and, 
subject always to r being as small as possible, it is worthwhile to attempt to 
select the xi from conjugacy classes that minimize this search space. 
In this particular application, we will generally not know Aut(G) in 
advance, and so we run EPIMORPHISMS with A=G. (But of course, if we 
do happen to know a group A with G<A in which A induces outer 
automorphisms of G by conjugation, then it could be worthwhile to use 
this A.) If we put A=G, then EPIMORPHISMS will find an element of each 
coset of Inn(G) in Aut(G); it has no possibility of using methods like those of 
Subsection 4.6.3 to work relative to intermediate subgroups found during 
the search. This means that the method will not work effectively unless 
Aut(G)/Inn(G) is reasonably small, and this is the principal disadvantage of 
the method. 
Hulpke points out in [Hul96, V.5] that the most common examples of 
groups for which Aut(G)/Inn(G) is large are solvable groups, and for such 
groups the methods of Section 8.9 should be used instead, after using the 
method described in Subsection 4.4.6 to move from a permutation 
representation to a presentation of G as a PC-group if necessary. There is 
some truth in this, but of course one can conjure up awkward examples 
just by taking a direct product of a small nonsolvable group, such as Alt(5), 
with a solvable group with large automorphism group, such as an 
elementary abelian p-group. 
An alternative method for computing Aut(G) for general groups G, which 
is a generalization of the algorithm of Section 8.9 and is not so dependent 
on Aut(G)/Inn(G) being small, is described by Cannon and Holt in [CH03]. 
This is still inferior to the p-group method, however. 
Exercises 
1. 
Show that epimorphisms ϕ and ϕ′ from F to G are equivalent modulo 
Aut(G) if and only if ker(ϕ)=ker(ϕ′). 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
335 
2. 
Prove Proposition 9.1 and Corollary 9.2. 
3. 
Prove that the use of coset enumeration, as described at the end of 
Subsection 9.1.1, to eliminate some possible generator images in 
EPIMORPHISMS, works as intended. 
9.2 Abelian quotients 
We saw in Proposition 2.68 that it is straightforward to write down an 
abelian presentation for the largest abelian quotient G/[G, G] of a finitely 
presented group G. We simply write the relators of the presentation of G in 
additive notation. 
In this section, we consider the problem of computing the structure of 
this abelianized presentation. The reader is probably already familiar with 
the fundamental theorem of finitely generated abelian groups, which states 
that each such group is isomorphic to a direct sum of cyclic groups. We 
shall prove this result at the same time as we describe an algorithm to 
compute such an isomorphism explicitly from an abelian group presentation. 
We saw in Proposition 2.65 that a free abelian group of rank n is isomorphic 
to Zn, and it is obvious how to write down G/[G, G] as a quotient of Zn. 
Example 9.2 
Let 
then 
  
which is isomorphic to the quotient of Z3 by its subgroup generated by 
[] 
So we need to study subgroups and quotients of the group Zn. Much of the 
theory here is very similar to basic linear algebra over a field, although there 
are some differences. We shall first present a rapid overview of this theory. 
9.2.1 The linear algebra of a free abelian group 
The free abelian group Zn has the natural free basis e1,…, en, where ei is the 
vector with 1 in the i-th component and 0 elsewhere. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
336 
A homomorphism from Zm to Zn can be represented by an m×n matrix M 
with integer entries, where the i-th row of M is the image of ei. The image 
of a general element v∈Zn is then given by v.M. 
If m=n, then M represents an automorphism of Zn if and only if M is 
invertible over the integers; that is, if M-1 has integral entries. In this case 
det(M) det(M-1)=1, so det(M)=±1, and conversely, if det(M)=±1, then the 
standard adjoint matrix formula for M-1 shows that M-1 has integral entries. 
Such matrices are called unimodular. The set of all unimodular matrices 
forms a group GL(n, Z) under multiplication, and the subgroup SL(n, Z) of 
matrices with determinant 1 has index 2 in GL(n, Z). 
Clearly an automorphism of Zn maps one free basis of Zn onto another, 
and the uniqueness up to isomorphism of a free abelian group shows that, 
for any two free bases of Zn, there is an automorphism of Zn mapping one 
to the other. So the free bases of Zn are given by the rows of the matrices 
in GL(n, Z). 
A free basis of Zn is also characterized by the property that it is linear 
independent over Z and spans (generates) Zn . Unlike in linear algebra over 
a field, a linear independent set of n elements Zn of need not be a free basis of 
Zn, but a spanning set of size n is a free basis (exercise: this will be easily 
deducible from the structure theorem of finitely generated abelian groups). 
We saw in Proposition 2.69 that any subgroup of Zn is finitely generated, 
so we can represent any such subgroup by an m×n matrix M with integral 
entries in which the rows generate the subgroup; that is, the subgroup is 
the row-space of M. 
This row-space is not changed if we replace M by AM for A∈GL(m, Z). If 
we replace M by MB with B∈GL(n, Z), however, then we are replacing the 
subgroup by its image under an automorphism of Zn. 
9.2.2 Elementary row operations 
There are three types of unimodular elementary row operations that we 
can perform on an integral m×n matrix M. These are 
(i) 
Add an integral multiple of one row of M to another. 
(ii) Interchange two rows on M. 
(iii) Multiply a row of M by –1 . 
These operations can also be achieved by replacing M be EM, where E is 
the corresponding m×m elementary matrix, which is obtained by applying 
the corresponding row operation to the identity matrix Im. We have det(E)=1, 
–1, and –1 respectively in the three cases, so E is unimodular in each case. 
Let us denote these m×m elementary matrices E∈GL(m, Z) in cases (i), 
(ii) and (iii), respectively, by 1(m, i, j, t) (1≤i, j≤m, i	j, t∈Z), 2(m, i, j) (1≤i, 
j≤m, i	j), and 3(m, i) (1≤i≤m), where: 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
337 
Multiplying an m×n matrix M on the left by 1(m, i, j, k), 2 (m, i, j), 3(m, 
i) has the effect of adding k times row j of M to row i of M, interchanging 
rows i and j of M, and multiplying row i of M by –1, respectively. 
9.2.3 The Hermite normal form 
DEFINITION 9.3 The integral m×n matrix M is said to be in (row) Hermite 
normal form (HNF) if the following conditions hold. 
(i) 
There is an r with 0≤r≤m such that the first r rows of M are nonzero 
and the remaining m–r rows are zero. 
(ii) For each i with 1≤i≤r, let Miji be the first nonzero entry in the i-th row 
of M. Then j1<j2<…<jr. 
(iii) Miji>0 for 1≤i≤r. 
(iv) For 1≤i≤r, we have 
 for k < i. 
For example, the matrix: 
(i) 
1(m,i,j,t)ij=t; 
(ii) 2(m, i, j)ij=2(m, i, j)ji=1 and 2(m, i, j)ii=2(m, i, j)jj=0; 
(iii) 3(m, i)ii=–1; 
and, in each case, all entries of the matrix not specified are the same as 
those in Im. For example: 
is in Hermite normal form with j1=1, j2=4, j3=6. 
There are various minor variants of this definition in the literature. 
The column HNF can be defined analogously and [Coh73], for example, 
has the zero columns of the matrix coming first rather than last. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
338 
THEOREM 9.4 Let M be an m×n matrix over Z. Then we can put M into 
HNF by applying a sequence of elementary unimodular row operations to 
M. Hence there exists an A∈GL(m, Z) such that AM is in HNF. 
We shall prove this theorem by presenting an algorithm that puts M into 
Hermite normal form. The algorithm below returns both the HNF N of M 
and A∈GL(m, Z) with AM=N. 
HERMITEFORM(M) 
Input: m×n integral matrix M 
Output: Matrix N in HNF and A∈GL(m, Z) with AM=N 
1 
m:=|M|; n:=|M[1]|; i:=1; j:=1; A:=Im; 
2 
while i≤m and j≤n 
3 
do (* Are there ≥2 nonzero entries Msj with s∈[i.. m]? *) 
4 
while ∃ s, t with i≤s 	t≤m and 0<|Msj|≤|Mtj| 
5 
do (* Yes. Reduce |Mtj| *) 
6 
Let c∈Z with |Mtj+cMsj|≤|Msj|/2; 
7 
A:=1(m, t, s, c).A; M:=1(m, t, s, c).M; 
(* Move a nonzero entry Msj with s∈[i.. m] to Mij *) 
8 
if Mij=0 and Msj	0 with i<s≤m 
9 
then A:=2(m, i, s).A; M:=2(m,i, s).M; 
10 
if Mij<0 
11 
then (* Make Mi
12 
A:=
j positive *) 
3(m, i).A; M:=3(m, i).M; 
13 
if Mij>0 
14 
then (* Put the entries Msj with s∈[1.. i–1] 
into the range [0 .. Mij–1] *) 
15 
for s∈[1..i–1] 
16 
do Let c∈Z with 0≤Msj+cMij<Mij; 
17 
A:=1(m, s, i, c).A; M:=1(m, s, i, c).M; 
18 
i:=i+1; 
19 
j:=j+1; 
20 return M, A; 
We have not specified precisely how we choose s and t in line 4, but |Mtj| is 
decreased in lines 6 and 7 for the chosen value of t. So eventually there will 
be at most one nonzero Msj with i≤s≤m, and then we exit this loop. Since 
either i, j, or both is incremented with each pass of the main ‘While’ loop at 
line 2, the function must terminate. 
The nonzero entries Mij encountered at line 13 are the entries Miji in 
the HNF. When we reach line 10, all entries Msj with s>i are zero. So 
Property (ii) of the HNF definition holds. Also, we only increment i when 
we have a nonzero entry at line 10 and, if r is maximal with the property 
that we encounter a nonzero entry at line 13 then the entries Mkj for k>r 
and all columns j are zero, and hence Property (i) holds. The code following 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
339 
lines 10 and 13 ensures that Properties (iii) and (iv) hold, so the function 
performs as intended, and we have proved Theorem 9.4. 
The most obvious way to choose s and t in line 4 is to choose s such that 
|Msj| is minimal, and then choose t such that Mtj is some other nonzero 
entry. In fact, it has been observed in practice that better performance is 
achieved by choosing s and t such that |Mtj| and |Msj| are the largest and 
second largest possible entries, measured by absolute value. 
Example 9.3 
Let 
Starting at i=j=1. Let us adopt the obvious strategy at line 4 of choosing 
s such that |Msj| is minimal. So we choose s=1 and t=2, 3, 4, 5 in turn, and 
we multiply M on the left by 1(5, 2, 1, 1), 1(5, 3, 1, –1), 1(5, 4, 1, –1), 1(5, 
5, 1, –4) in turn. At this stage, we have: 
Now we move on to i=j=2. Since Mis=0 for 2≤i≤5, we move on to j=3. The 
smallest Msj occurs with s=4 and taking t=2, 3, we multiply A and M by 1(5, 
2, 4, 2) and 1(5, 3, 4, 2). Then, at line 9, we multiply them by 2(5, 2, 4) to 
move Msj to Mij and, at line 17, we multiply them by 1(5, 1, 2, 1). Now we 
have: 
We then move on to i=3, j=4 and immediately to j=5. Choosing s=3, we 
multiply M and A on the left by 1(5, 4, 3, –1), 1(5, 5, 3, –1), 1(5, 1, 3, -1) and 
1(5, 2, 3, -1) to give 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
340 
Finally, we proceed to i=4, j=6, and multiply A, M on the left by 1(5, 4, 5, 
-2), 1(5, 5, 4, 2), 1(5, 1, 4, 4), 1(5, 2, 4, 3), 1(5, 3, 4, -5), to give: 
and M is now in HNF.
[] 
The r nonzero rows of a matrix in HNF are clearly linearly independent 
over Z, and there at most n of them. Since replacing M by AM with 
A∈GL(m, Z) does not change the row-space of M, we have proved: 
PROPOSITION 9.5 Any subgroup of a free abelian group of rank n is free 
abelian of rank at most n. 
The HNF provides a canonical description of the image or row-space of an 
integral matrix M. The following proposition, of which we leave the proof 
as an exercise, provides a description of the kernel or nullspace. 
PROPOSITION 9.6 If AM is in HNF and AM has r nonzero rows, then the 
rows r+1 to m of A form a free basis of the nullspace of M. 
The next result proves that the HNF of an integral matrix is determined 
by its row-space. So, in particular, the HNF of a matrix is unique. 
THEOREM 9.7 Suppose that the m×n matrices M and N over Z have the 
same row-space, and that AM and BN are in Hermite normal form, with A, 
B∈GL(m, Z). Then AM=BN. 
PROOF We proceed by induction on m+n, starting with the case m=n=0, 
which is trivial. Let C:=AM, D:=BN be in HNF with A, B∈GL(m, Z). Then 
the row-spaces of C and D are both equal to the row-space U of M and N. 
Let e1,…, en be the natural free basis of Zn, and let 
 be the subspace 
spanned by e2,…, en. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
341 
We have U≤V if and only if M and N have zero first column, in which 
case C11=D11=0, and the result follows by induction applied to M and N with 
their first columns removed. 
Otherwise C11 and D11 are nonzero, and U∩V is spanned by the rows of C 
or of D other than the first. But then the matrices obtained by removing 
the first rows from C and from D have the same row-space and are both in 
HNF so, by inductive hypothesis, they are equal. 
So we just need to prove that C and D have the same first rows C[1] and 
D[1]. Let v:=C[1]–D[1]. Since C11 and D11 are positive integers, they must 
both be equal to |Zn:U+V|, so v[1]=C11–D11=0. Hence v∈U∩V, and v is in 
the space spanned by rows 2 to m of C. 
Let C (and hence also D) have r nonzero rows, with first nonzero entries 
Ciji for 1≤i≤r. Then v=a2C[2]+…+arC[r] for some a2,…, ar∈Z, and hence 
 for 2≤i≤r. But, by condition (iv) in the definition of the HNF, we 
have 
 and hence 
 for 2≤i≤r. So we must have 
ai=0 for 2≤i≤r, and hence v=0 and we are done.
9.2.4 Elementary column matrices and the Smith 
normal form 
The unimodular elementary column operations are defined analogously to 
the corresponding row operations. They can be achieved by replacing the 
m×n matrix M be ME, where E is the corresponding n×n elementary matrix, 
which is obtained by applying the corresponding column operation to the 
identity matrix In. 
We denote these n×n matrices E by γ1 (n, i, j, t) (1≤i, j≤n, i	j, t∈Z), γ2(n, 
i, j) (1≤i, j≤n, i	j), and γ3(n, i) (1≤i≤n), where multiplying an m×n matrix M 
on the right by γ1(n, i, j, t), γ2(n, i, j), or γ3(n, i) has the effect of adding t 
times column j of M to column i of M, interchanging columns i and j of M, 
or multiplying column i of M by –1, respectively. Their definition is: 
(i) 
γ1(n, i, j, k)ji=c; 
(ii) γ2(n, i, j)ij=γ2(n, i, j)ji=1 and γ2(n, i, j)ii=γ2(n, i, j)jj=0; 
(iii) γ3(n, i)ii=–1. 
and, in each case, all entries of the matrix not specified are the same as in In. 
DEFINITION 9.8 The integral m×n matrix M is said to be in Smith normal 
form (SNF) if the following conditions hold. 
(i) 
Mij=0 whenever i	j. 
(ii) Mii≥0 for 1≤i≤min(m, n). 
(iii) For 1≤i≤min(m, n), we have Mii|Mi+1,i+1. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
342 
THEOREM 9.9 Let M be any m×n matrix over Z. Then we can put M into 
SNF by applying a sequence of elementary unimodular row and column 
operations to M. Hence there exists an A∈GL(m, Z) and B∈GL(n, Z) such 
that AMB is in SNF. 
Again we shall prove the theorem by presenting an algorithm that puts M 
into Smith normal form. The function SMITHFORM returns both the SNF 
N of M and A∈GL(m, Z), B∈GL(n, Z) with AMB=N. 
The entry Mij that is selected at line 4 is called the pivot entry for that 
iteration of the main loop at line 2. It has not been specified exactly how 
the pivot entry is selected, and the algorithm is only guaranteed to terminate 
if we adopt a suitable policy for choosing it. The easiest policy that guarantees 
termination is to select the pivot entry Mij such that |Mij| is as small as 
possible subject to being nonzero. This does not always lead to the best 
performance, and we shall consider other strategies later, but let us use 
this policy for the purposes of proving correctness and hence Theorem 9.9. 
If the Boolean variable a is set to false at line 9 or 13, then |Msj| or 
|Mit| will be nonzero, but smaller than |Mij|, and so f will be unchanged. 
But, since we are choosing pivot entries with minimal absolute value, this 
absolute value will be smaller on the next iteration of the main loop. Hence 
a will eventually be true at line 14. 
Then, if the ‘If’ condition holds at line 16, there will again be a smaller 
pivot entry with f unchanged on the next iteration of the main loop, and so 
this condition will eventually fail to hold, and then the code following line 
21 will be executed. 
At this stage, the pivot entry Mij is the only nonzero entry in its row and 
in its column, and it divides all other entries in the submatrix M[f.. m][f.. n] 
of M. The pivot entry is then moved to position Mf f and made positive if 
necessary. At this stage, all off-diagonal entries in rows and columns 1 to f 
will be zero, and the diagonal entries will be nonnegative, so conditions (i) 
and (ii) of the SNF will hold when the function terminates. 
All subsequent row and column operations take place on rows f+1 to m 
or columns f+1 to n of M, and so Mf f is not altered again, and the property 
that it divides all other entries in M[f.. m][f.. n] is maintained. Hence 
condition (iii) in the definition of the SNF holds at the end of the function. 
After moving the pivot entry to Mf f, f is incremented, so the function must 
eventually terminate. 
For example, the following matrix is in Smith normal form: 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
343 
SMITHFORM(M) 
Input: m×n integral matrix M 
Output: Matrix N in SNF, 
A∈GL(m, Z), B∈GL(n, Z) with AMB=N 
1 m:=|M|; n:=|M[1]|; f:=1; A:=Im; B:=In; 
2 while f≤m and f≤n 
3 
do if Mij=0 for all i∈[f .. m] and j∈[f .. n] then break; 
(* Select pivot entry Mij *) 
4 
Choose i, j with i∈[f .. m], j∈[f .. n], Mij	0; 
5 
a:=true; 
(* Reduce entries in column j using row operations *) 
6 
for s∈[f .. m]\[i] 
7 
do let c∈Z with |Msj+cMij|≤|Mij|/2; 
8 
A:=1(m, s, i, c).A; M:=1(m, s, c).M; 
9 
if Msj	0 then a:=false; 
(* Reduce entries in row i using column operations *) 
10 
for t∈[f..n]\[j] 
11 
do let c∈Z with |Mit+cMij|≤|Mij|/2; 
12 
B:=B.γ1(m, t, j, c); M:=M.γ1(m, t, j, c); 
13 
if Mit	0 then a:=false; 
14 
if a 
15 
then (* All other entries in row i and column j are zero *) 
16 
if ∃ s ∈[f..m], t∈[f..n]:Mst mod Mij	0 
17 
then (* Mij X Mst– 
make Msj:=Mst and reduce it *) 
18 
B:=B.γ1(n, j, 1); M:=M.γ1(n, j, 1); 
19 
Let c∈Z with |Msj+cMij|≤|Mij|/2; 
20 
A:=ρ1(m, s, i, c).A; M:=ρ1(m, s, i, c).M; 
21 
else 
(* Move Mij to Mf f and make it >0 *) 
22 
if f	i 
23 
then A:=ρ2(m, i, f).A; 
24 
M:=ρ2(m, i, f).M; 
25 
if f	j 
26 
then B:=B.γ2(n, j, f); 
27 
M:=M.γ2(n, j, f); 
28 
if Mf f <0 
29 
then A:=ρ3(m, f).A; 
30 
M:=ρ3(m, f).M; 
31 
f:=f+1; 
32 return M, A, B; 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
344 
We choose M44=–1 as our next pivot. We multiply M on the left by ρ1(5, 2, 
4, 2), ρ1(5, 3, 4, 2), and on the right by γ1(6, 3, 4, 2), γ1(6, 5, 4, 2), γ1(6, 6, 4, 11) 
to clear the rest of row 4 and column 4. Then we multiply on the left by 
ρ2(5, 2, 4) and on the right by γ2(6, 2, 4) to bring the pivot entry to M22, and 
then we multiply on the left by ρ3(5, 2) to make it positive. We now have 
Let us work through the SNF algorithm using Example 9.3. We start with 
the pivot entry M11=1. As before, we multiply M on the left by ρ1(5, 2, 1, 1), 
ρ1(5, 3, 1, –1), ρ1(5, 4, 1, –1), ρ1(5, 5, 1, –4), but now we also multiply on the 
right by γ1(6, 2, 1, 2), γ1(6, 3, 1, 1), γ1(6, 4, 1, –1), γ1(6, 5, 1, -1) and γ1(6, 6, 1, 
3), to reduce the rest of row 1 to zero. At this stage, we have 
The remaining operations are as follows. First we multiply on the left 
by ρ1(5, 4, 3, –1), ρ1(5, 5, 3, –1), then on the right by γ1(6, 6, 5, -11), γ2(6, 3, 5), 
then on the left by ρ1(5, 4, 5, –2), ρ1(5, 5, 4, 2), and finally on the right by 
γ2(6, 4, 6). We now have 
and M is in SNF. 
Once again, we have a uniqueness result. 
THEOREM 9.10 Let M be an m×n matrix over Z. If AMB and CMD are 
both in Smith normal form, with A, C∈GL(m, Z) and B, D∈GL(n, Z), then 
AMB=CMD. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
345 
Rather than prove this theorem directly, we prefer to interpret the theory 
of Smith normal forms in terms of finitely generated abelian groups, and 
then derive the theorem from a result about abelian groups. 
We saw in Section 2.6 that any finitely generated abelian group G is 
isomorphic to a quotient 
 for some subgroup K of a free abelian group 
Zn where, by Proposition 2.69, K is finitely generated. We can represent K 
by an m×n integral matrix M, where K is spanned by the rows of M and, 
conversely, we can associate the finitely generated abelian group 
with the m×n matrix M. 
As we remarked at the end of Subsection 9.2.1, if we replace M by AM 
for A∈GL(m, Z), then we do not change the row-space K of M. If we replace 
M by MB for B∈GL(n, Z), however, then the row-space of M is replaced by 
ϕ(K), where ϕ is the automorphism of Zn defined by B. But 
. Hence, for any A∈GL(m, Z) and B∈GL(n, Z), the finitely 
generated abelian groups associated with M and AMB are isomorphic. 
Recall that, for an abelian group G and n∈Z, nG is defined to be the 
subgroup { ng | g∈G } of G. Suppose that M is in SNF with Mii=di for 
1≤i≤min(m, n), and define di=0 for min(m, n)<i≤n. Then the row-space of M 
is the subgroup 
of Zn, and so 
In general, some of the di may be zero, in which case the nonzero di will all 
precede the zero di. In any case, 
 is a finite cyclic group of order di if 
di>0, and an infinite cyclic group if di=0. Moreover, some of the di may 
equal 1, and they come first in the list; the corresponding quotients 
are trivial and can be omitted from the direct sum decomposition of G. 
DEFINITION 9.11 An abelian group G has type (d1,…, dn), for di∈N0 if it is 
isomorphic to the direct sum of cyclic groups 
 . We say that (d1,…, dn) 
satisfies the divisibility condition if di	1 for 1≤i≤n, and di|di+1 for 1≤i<n. 
The above discussion and Theorem 9.9 together prove the existence part 
of the fundamental theorem of finitely generated abelian groups. 
THEOREM 9.12 A finitely generated abelian group has type (d1,…, dn) for 
some di∈N0 that satisfy the divisibility criterion. 
We shall now prove the uniqueness part of the fundamental theorem, which 
(exercise) also proves Theorem 9.10. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
346 
THEOREM 9.13 Suppose that the abelian group G has type (d1,…, dn) and 
also has type (c1,…, cm), where (d1,…, dn) and (c1,…, cm) both satisfy the 
divisibility condition. Then m=n and di=ci for 1≤i≤n. 
PROOF If p is prime and H is a cyclic group of order n, then |H:pH|=p if 
p|n, and otherwise |H:pH|=1. So |G/pG|=pn if p|d1 and |G/pG|<pn 
otherwise. Since the same applies to c1, this proves that m=n and that the 
same primes divide d1 as c1. 
If d1=0 then all primes divide d1, so c1=0 and the result follows. Otherwise 
we use induction on n and, for a fixed n, on d1. The result is true for n=1, 
since d1=c1=|G| in that case. If n>1, then let p be a prime dividing d1 and 
c1. Then G/pG is abelian of type (d1/p,…, dn/p) and of type (c1/p,…, cn/p). 
These types both satisfy the divisibility condition after removing any leading 
1’s, and so by inductive hypothesis we have di/p=ci/p for 1≤i≤n, and the 
result follows immediately. 
Without the divisibility condition, the result no longer holds, and even the 
number n of factors is not uniquely determined by G. For example, abelian 
groups of types (4, 3, 5), (12, 5), (4, 15), (3, 20), and (60) are all isomorphic 
to each other, but only the last of these types satisfies the divisibility 
condition. 
The principal use of the SNF algorithm in CGT is for finding the abelian 
invariants of G/[G,G] in a finitely presented group G. So, in Example 9.2, 
the matrix M of the abelianized presentation is 
and we easily calculate the SNF N with AMB=N, where 
So G/[G, G] is an infinite group of type (2, 6, 0). 
The matrix A is of no particular interest in this regard, but the matrix B 
is important, since its rows define the images of the epimorphism µ from G 
to 
. To be specific, if a, b, c denote the generators of 
the three direct summands of H, then the homomorphism is defined by 
µ(x)=a-b+c, µ(y)=b, µ(Z)=c. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
347 
Exercises 
1. 
Prove Proposition 9.6. 
2. 
Describe a method of solving a system v=z.M of linear equations over 
Z, where M is an integral m×n matrix, v∈Zn is a fixed vector, and 
z∈Zm is an unknown vector. (Hint: First show how to do this when M 
is in HNF. In general, let AM be in HNF and solve the system v= 
(z.A_1).(AM).) 
3. 
Show that any set of n elements of Zn that span Zn form a free basis of Zn. 
4. 
Show that the HNF of a matrix in M∈GL(m, Z) is equal to Im. Deduce 
that M is equal to a product of unimodular elementary row matrices. 
5. 
Prove that, if a, b∈N, then abelian groups of types (a, b) and (ab) are 
isomorphic if and only if a and b are coprime. 
6. 
Prove that Theorem 9.10 follows from Theorem 9.13. 
9.3 Practical computation of the HNF and SNF 
In Example 9.3, the largest absolute value of an entry in M is 9, and in the 
Hermite and Smith forms for M it is 4. However, the number 22 appeared 
in M during the course of the both of these calculations, and there is a 25 in 
the final transformation matrix B. 
This might not seem particularly extreme or remarkable, but with larger 
matrices, the problem of integer entry explosion becomes a serious obstacle 
to satisfactory performance of the algorithms. In this section, we shall briefly 
discuss methods that can and have been used to alleviate this problem. We 
shall not go into much detail here, and we shall direct the reader to other 
sources for a more complete discussion. We shall concentrate more on the 
SNF calculation, because it is more important than the HNF in applications 
to CGT. 
Some recent papers on the computation of the HNF and SNF, and on 
the closely related extended greatest common divisor problem for sets of 
integers, are those by Storjohann and Labahn [SL96] and [Sto98], by Havas, 
Majewski, and Matthews [HMM98, HMM99], and by Lübeck [Lüb02]. The 
HNF is more important in applications to computational algebraic number 
theory, and is discussed in Section 2.4 of [Coh73]. 
9.3.1 Modular techniques 
Modular techniques involve performing all calculations modulo some fixed 
positive integer m. The advantage of this, of course, is that no integers larger 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
348 
than m will arise during the computations. The main ideas involved were 
introduced by Havas and Sterling in [HS79]. There is also a complete treatment 
in Section 8.4 of [Sim94]. This approach provides an efficient polynomial- 
time algorithm for finding the SNF of an integral matrix, and hence the type 
of a finitely presented abelian group. The more recent paper of Lübeck [Lüb02], 
which we shall not discuss here, also makes partial use of modular methods. 
The main disadvantage of modular methods is that they do not, in general, 
allow us to find the transformation matrices A and B as matrices over Z 
and, in particular, for finite presentations of infinite abelian groups G, they 
do not allow us to compute an explicit isomorphism from G to the 
corresponding direct sum of cyclic groups. If the transformation matrices 
are not required explicitly, then modular techniques probably provide the 
most efficient method for finding the SNF. 
Calculating the SNF modulo a positive integer m is done in almost exactly 
the same way as over the integers, but working modulo m. As transformation 
matrices, we can use any A and B that are invertible modulo m, and hence, 
for the third type of elementary row and column operation, we may multiply 
a row or a column by any integer (mod m) that is invertible modulo m. 
By Theorem 9.9, we can use elementary row and column operations to 
reduce an m×n matrix M modulo m to a matrix in SNF. We can then write 
each nonzero diagonal entry Mii as diei where di|m and gcd(ei,m)=1. So, by 
multiplying row i by the inverse of ei modulo m, we can replace Mii by di. 
So, modulo m, we can reduce M to a matrix in SNF in which each Mii 
divides m, and we then say that M in SNF modulo m. It is not hard to show, 
as in Theorem 9.7, that the SNF modulo m is uniquely determined by M. 
The idea of the modular methods is to find an integer m that is divisible 
by and larger than each of the nonzero entries in the SNF of our integral 
matrix M. For such an m, it is clear that the SNF of M can be obtained 
from the SNF of M modulo m by replacing any entries equal to m by 0. 
Let r be the rank of M, and let m be the gcd of the determinants of the 
r×r nonsingular submatrices of M. It can be shown (see, for example, Section 
8.4 of [Sim94]), that m is not changed when we perform unimodular row or 
column operations on M, and so m is just the product of the nonzero entries 
in the SNF of M. Hence 2m satisfies the condition in the preceding 
paragraph but, in fact, assuming that we know r, we also know the number 
of nonzero entries in the SNF of M, and so it suffices to calculate the SNF 
modulo m. 
The algorithm proceeds by first finding r, and then finding a small number 
of nonsingular r×r submatrices of M and using the gcd of their determinants 
for m. In practice, this will typically be a very small multiple of, and often 
equal to, the gcd of all nonsingular r×r submatrices of M. 
Finding r is the most difficult part of this process. Notice that the 
associated finitely presented abelian group G is finite if and only if dn>0, 
where (d1,…, dn) is the type of G, and this is the case if and only if r=n. So 
a knowledge of r decides the finiteness of G which, in many applications, is 
exactly what we want to know! 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
349 
If p is prime, then it is straightforward, by working modulo p in the 
finite field Fp,to find the rank of M modulo p, which is a lower bound for r. 
The rank modulo p is equal to r for all primes p that do not divide any of 
the positive entries in the SNF of M; that is, for almost all primes p. So, in 
practice, we just need to calculate the rank modulo p for three or four 
moderately sized (within the range [50.. 100] is usually adequate) random 
primes, and the value of r will be clear. 
However, mathematicians understandably prefer to have mathematically 
substantiated proofs of the correctness of such calculations, even when the 
likelihood of error is vanishingly small. In fact, there is a well-known bound, 
the Hadamard bound, on the determinant of a square matrix, which enables 
us to choose primes p1,…, ps such that the maximum of the ranks of M modulo 
pi for 1≤i≤s is guaranteed to be equal to r: it is sufficient to choose them such 
that 
See [Sim94] for further details. 
Although it is too small and easy an example to warrant the use of 
modular techniques, let us consider Example 9.3. We have H(M)≤32409, 
and M has rank 4 modulo primes 59, 61, 67, for example, of which the 
product exceeds H(M), so we can conclude that M has rank 4. The 4×4 
submatrices of M consisting of rows 1–4 and columns 3–6, and of rows 2–5 
and columns 3–6 have determinants –24 and 56, respectively, where gcd(24, 
56)=8, so we can find the SNF by calculating the SNF modulo 8. 
9.3.2 The use of norms and row reduction techniques 
The remaining methods to be discussed allow us to calculate the 
transforming matrices A and B as well as the SNF of M. The first polynomial- 
time algorithm for the SNF and the HNF was due to Kannan and Bachem 
[KB79]. We shall not discuss this method in detail here. We shall, however, 
briefly discuss some methods described by Havas, Holt, and Rees in [HHR93], 
which perform very well in practice, particularly during the earlier stages 
of the reduction of large sparse matrices, which arise frequently in the 
applications that we shall discuss in Subsection 9.3.3 below. 
Further improvements, which use the lattice reduction (LLL) algorithm 
for square matrices and the modified lattice reduction (MLLL) algorithm for 
nonsquare matrices, were introduced by Havas and Majewski in [HM97]. 
The LLL and MLLL algorithms play a central rôle in many areas of computer 
algebra, but they are beyond the scope of this book. The reader could consult 
Section 8.6 of [Sim94] for further details of their application to CGT. 
The idea of the norm-based methods studied in [HHR93] is to choose a 
pivot entry that is likely to result in changes to the other entries of the 
matrix that are as small as possible when we perform row and column 
reduction using this pivot. To achieve this, we choose the pivot such that 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
350 
the other entries in its row and column are small. The size of these other 
entries can be measured by using any one of a number of possible norms; 
for example, we could use the largest entry, or the average of the absolute 
values of all of these entries. 
The best results in terms of restricting the size of intermediate entries, 
however, were obtained by choosing Mij such that the product of E(i, j) of 
the standard Euclidean lengths of row i and column j of M is as small as 
possible. To be precise, 
In order to ensure termination of SMITHFORM if a is f alse at line 9 or 13, 
or if the ‘If’ condition at line 14 holds, on the next iteration of the main loop, 
we choose our pivot entry to be either in the same row or in the same column 
as the current pivot. That ensures that the next pivot entry will be smaller in 
absolute value than the current one, and so after finitely many iterations of 
the main loop, we will get through to line 16, and then f will be incremented. 
Example 9.4 
Here is a 10×12 integral matrix. This was chosen at random, subject to all 
entries having absolute value at most 15. 
The rank is 10, and the nonzero entries in the SNF of M are 1 (8 times), 
2 and 260. (Randomly chosen integral matrices typically have most of their 
diagonal entries equal to 1, and also have one such entry that is much 
larger than the others.) 
If we use SMITHFORM and choose the pivot with minimal |Mij|, then the 
largest entry in an intermediate M is 607 590, whereas the largest entries in 
A and B are 2 864 915 944 860 487 and 101 232 331 673 348, respectively. 
With the choice of pivot based on minimal E(i, j), as discussed above, the 
largest entry in an intermediate M is 47 838, whereas the largest entries in A 
and B are 4 338 759 921 705 589 and 111 961 267 948, respectively. So the 
matrix A has not improved but B has, as has the largest intermediate entry 
in M. 
[] 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
351 
The effectiveness of the norm-based method in the example above is perhaps 
not spectacular, but calculating and using this norm is very fast, so it adds 
virtually no time or space overheads to the algorithm, and its effect becomes 
more noticeable as the matrices get larger. 
More dramatic improvements were obtained at the cost of a more 
significant increase in running time by the following simple technique, 
which we shall call row simplification. It can be thought of as a simple- 
minded but very effective alternative to the rather complicated MLLL- 
based methods. 
From time to time, we interrupt the main algorithm, and attempt to 
reduce the size of the entries in M as follows. We consider each ordered 
pair of distinct rows (M[i], M[j]) of M and, if the sum of the absolute values 
of the entries in row M[i] can be reduced by adding M[j] or—M[j] to M[i], 
then we perform the corresponding row operation, and multiply M and A 
on the left by 1(m, i, j,±1). We repeat this process until no further reductions 
can be obtained for any pair of rows of M. 
The more often that we carry out such reductions, the greater will be 
the effectiveness in terms of reducing the size of the matrix entries but, 
since it is relatively expensive in terms of running time, we do not want to 
do it more than necessary. The function can usefully be given a parameter 
t, which means carry out the row simplification process once every t 
iterations of the main loop. 
In the example above with t=1, the largest entry in an intermediate M 
was 1300, whereas the largest entries in A and B were 1 696 131 and 448, 
respectively. Row simplification increased the running time by about 33%. 
Row simplification can also be used to limit the size of matrix entries in 
HERMITEFORM. The HNF of the matrix M of Example 9.4 is displayed below. 
Running HERMITEFORM on M with s and t chosen with the ‘largest 
and second largest |Msj| and |Mtj| in column j’ strategy, resulted in largest 
entry in an intermediate M and largest entry in A equal to 10 915 109 187 
628 210 751 and 1 151 887, respectively. If we use row simplification on 
every iteration of the main loop, then the largest entry in an intermediate 
M is reduced to 28 703 427 346 369, but at the cost of more than doubling 
the running time. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
352 
9.3.3 Applications 
One of the oldest and most popular applications of CGT to other areas of 
mathematics relies on the following methodology. We are given one or 
more finitely presented groups G. First we look for suitable subgroups H of 
G of low finite index, using the methods described in Section 5.4 or 9.1. 
Next we compute presentations of these subgroups using the Reidemeister- 
Schreier algorithm described in Section 5.3. We then use the SNF algorithm 
to compute the abelian invariants of H/[H, H]. 
When the index |G:H| is large, the presentation of G has a large number 
of generators and relators. It is then advisable (and often essential) to use 
the Tietze transformation simplification techniques described in Subsection 
5.3.3 to reduce the size of the presentation before constructing the matrix 
for the SNF computation. Experience shows that the best strategy is to 
simplify the presentation for as long as its total presentation length is 
decreasing. 
Many of the applications based on these techniques are to topology, which 
is not surprising, given that finitely presented groups arise naturally in a 
variety of topological contexts, such as knot groups and fundamental groups. 
An early application of this nature is described by Havas and Kovács in 
[HK84], where the authors prove that the knot groups of 11 specific knots 
are not isomorphic; this immediately implies that the knots are all distinct. 
Often, the principal aim is to find an H with infinite abelianization. This 
has long been a popular approach to proving that a finitely presented group is 
infinite, but it has a more specific topological significance. Under certain 
connectivity assumptions, the conjugacy classes of subgroups H of the 
fundamental group G of a topological space X are in one-one correspondence 
with the covering spaces X~ of X, where the fundamental group of X~ is isomorphic 
to the corresponding subgroup H, and subgroups of finite index correspond 
to finite covers. See, for example, Theorem 10.2 of Chapter V of [Mas91]. 
So the search for low-index subgroups H of G corresponds to the search 
for finite covers X~ of X. It is proved in Theorem 7.1 of Chapter VIII of 
[Mas91] that the subgroup H has infinite abelianization, if and only if the 
homology group H1(X~) is infinite. 
Specific applications are typically to manifold groups. We shall give only 
brief details here. A 3-manifold is defined to be Haken if it contains a 
topologically essential surface. The Virtual Haken Conjecture, due to 
F.Waldhausen, says that every irreducible 3-manifold with infinite 
fundamental group has a finite cover that is Haken. It turns out that a 3- 
manifold whose fundamental group has infinite abelianization is Haken, so 
a stronger form of the conjecture says that, for every irreducible 3-manifold 
with infinite fundamental group G, G has a finite index subgroup with 
infinite abelianization. 
This conjecture was verified computationally by Dunfield and Thurston 
for a set of 10986 small-volume closed hyperbolic 3-manifolds, using the 
techniques outlined above; see [DT03]. While many of the examples were 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
353 
settled using subgroups H of reasonably small index, a few were more 
difficult, and over a year of CPU-time, mainly using GAP and occasionally 
also MAGMA, was consumed in the complete exercise. Subgroups of index 
at most 6 worked for 40% of the examples, whereas index at most 200 
worked 98% of the time. 
There are applications of a similar nature in [Rei95], which describes 
the construction of the first explicit example of a nonHaken hyperbolic 3- 
manifold that has a finite cover which fibres over the circle, and in [CFJR01], 
as part of the authors’ proof that the Weeks manifold is the smallest volume 
arithmetic hyperbolic 3-manifold. 
An application in which the subgroup H is proved infinite by a different 
method, not involving H/[H, H], will be described in Subsection 9.4.7. 
Finally, we mention the paper of Havas, Holt, and Newman [HHN01], 
in which the use of these techniques on a small number of examples enabled 
the authors to notice a pattern, and thereby prove the infiniteness of all 
groups in an infinite family of examples. These groups had been originally 
investigated by Johnson, Kim, and O’Brien [JKO99]. 
Exercise 
1. 
Prove that, for m>0, the SNF modulo m of an integral matrix M is 
uniquely determined by M. 
9.4 p-quotients of finitely presented groups 
Substantial progress at an algorithmic and computational level has been 
made over the past thirty years in the study of various types of quotients of 
a finitely presented group. In particular, we can construct polycyclic 
presentations for those quotients of the group that have prime power order 
or are nilpotent or solvable. 
Here we discuss in detail the commonly-used algorithm to compute such 
a presentation for a p-quotient; that is, a quotient that is a finite p-group 
for a prime p. We also study the p-group generation algorithm, used to 
generate descriptions of p-groups. Finally we report on some related 
algorithms, including computing automorphism groups of finite p-groups, 
and testing pairs of such groups for isomorphism. 
9.4.1 Power-conjugate presentations 
Recall from Chapter 8 that a group G is polycyclic if it has a sequence of 
subgroups 
where Gi+1 Gi and Gi/Gi+1 is cyclic. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
354 
where the Wij, 
 are words involving only ai+1,…, an and their inverses. 
Now G has a polycyclic presentation {A|R}. 
These presentations have proved of central importance in allowing 
effective computation with such groups. In [Syl72], it is proved that every 
group of order pn has such a presentation on n generators; Jürgensen first 
introduced them for finite solvable groups in [Jür70]. 
While every finitely generated nilpotent group and every finite solvable 
group is polycyclic, this need not be true for an arbitrary finitely generated 
solvable groups. 
Some significant progress has been made in constructing polycyclic 
presentations for arbitrary solvable quotients of a finitely presented group. 
Assume we have a finite presentation for a group G and a polycyclic 
presentation for a quotient, G/N. In [BCM81b, BCM81a], Baumslag, 
Cannonito, and Miller describe a theoretical algorithm that can decide 
whether or not G/N′ is polycyclic and, if so, obtain a polycyclic presentation 
for G/N′. In [Sim90b], Sims developed practical aspects of this algorithm to 
compute metabelian quotients of a finitely presented group. 
This work is extended to the general case by Lo in [Lo98]. Let G[n] denote 
the nth term of the derived series of G. Then, given as input the finite 
presentation for G and n>1, Lo’s algorithm decides whether G/G[n] is 
polycyclic and, if so, returns a polycyclic presentation for G/G[n]. 
As we learned in Subsection 8.1.1, a critical feature of a polycyclic 
presentation is that every element of the presented group may be written 
in a normal form 
, where each ai is an integer and 0≤i<i if 
i∈I. If this normal form is unique, then the presentation is consistent. See 
Subsection 8.1.3 for a discussion of collection algorithms—these rewrite 
an arbitrary word in the generators as a normal word equivalent to it 
using the power-conjugate presentation. 
Most of the algorithms to construct a polycyclic presentation for a 
quotient of a finitely presented group G have a common structure. Each 
uses a chain of (sub)normal subgroups 
Theorem 8.8 states that every polycyclic group G has a polycyclic 
presentation. In summary, we can associate with G a particular presentation 
as follows. We choose elements ai where 
. The sequence of 
generators A:=[a1,…,an] is a polycyclic generating sequence for G. Let I⊆{1,…, 
n} denote the set of subscripts where Gi/Gi+1 is finite and has order i. Let 
R denote the set of defining relations 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
355 
and works down this chain, using the polycyclic presentation constructed 
for G/Gi to write down a presentation for G/Gi+1. We write down a 
presentation for a group that is a (downward) extension of G/Gi and has 
G/Gi+1 as a quotient. 
The input for one iteration of such an algorithm usually includes a finite 
presentation {X|S} for a finitely presented group, G, and a polycyclic 
presentation for H:=G/Gi, where Gi is the i-th term of the relevant series, 
and an epimorphism from G to H. The output includes a polycyclic 
presentation for K:=G/Gi+1 and an epimorphism from G to K. 
We now focus on the algorithm used to construct a polycyclic presentation 
for a finite p-group. In this context, we usually refer to power-conjugate 
presentations and list relations as commutators rather than conjugates. 
9.4.2 The p-quotient algorithm 
Recall from Subsection 2.3.4 that the lower central series of a group G is 
the sequence of subgroups 
where γi(G)=[γi–1(G), G] fori>1. 
The p-quotient algorithm uses a variation of the lower central series 
known as the lower exponent-p central series, where p is a prime. This is 
the descending sequence of subgroups 
where Pi(G)=[Pi–1(G),G]Pi–1(G)p for i≥1. 
If G is a finite p-group then the series terminates in the identity. If 
Pc(G)=1 and c is the smallest such integer then G has exponent-p class c. 
For the remainder of this section, class means exponent-p class. 
We saw in Lemma 8.20 that the relations in a power-conjugate 
presentation of the type 
are redundant in a finite group, and can be omitted from the presentation. 
We shall do this for the remainder of this section. 
Example 9.5 
Let G be the dihedral group of order 16 described as 
(Recall this notation from Subsection 8.1.2; trivial polycyclic relations are 
omitted from the presentation. In the context of polycyclic presentations of 
finite p-groups, we also omit trivial relations of the form 
.) The lower 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
356 
exponent-p central series of G is the sequence of subgroups P0(G)=G, 
, 
 and P3(G)=1, so G has exponent-2 class 3.   [] 
We first describe a number of basic but important properties of the lower 
exponent-p central series. The proofs of these results are similar to the 
analogous statements for the lower central series. 
THEOREM 9.14 If G is a d-generator group, then G/P1(G) is elementary 
abelian of order at most pd. If G is a finite p-group then P1(G)=Φ(G), the 
Frattini subgroup of G. 
Note that P1(G) is, by definition, the smallest normal subgroup of G having 
an elementary abelian quotient group, and so P1(G)=Φ(G) by Proposition 
2.45. 
LEMMA 9.15 If θ is a homomorphism of G then θ(Pi(G))=Pi(θ(G)). 
Consequently each term of the lower exponent-p central series is a 
characteristic subgroup of G. In particular, if N is a normal subgroup of G 
then Pi(G/N)=Pi(G)N/N. 
LEMMA 9.16 If N G and G/N has class c then Pc(G)≤N. 
LEMMA 9.17 For positive integers i, j, [Pi(G), Pj(G)]≤Pi+j+1(G). 
This last lemma can be proved by using the three subgroups lemma; see 
Exercise 4 at the end of Section 2.3. The following result establishes that a 
finite p-group has a largest central elementary abelian extension. 
THEOREM 9.18 Let G be a d-generator finite p-group. Then there exists a 
d-generator finite p-group, G*, with the property that every d-generator 
group H having a central elementary abelian p-subgroup, Z, such that H/Z 
is isomorphic to G, is a homomorphic image of G*. 
PROOF Let F be the free group of rank d freely generated by a1,…,ad, and 
let R be the kernel of a homomorphism θ from F onto G. Define R* to be 
[R, F]Rp and G* to be F/R*. Then G* has d generators and, since R F, we 
have R*≤R. Since H is a d-generator group and has a quotient, H/Z, which 
is isomorphic to G, the homomorphism, θ, may be factored through H and 
the resulting homomorphism, ψ, of F onto H maps R into Z. Since Z is 
elementary abelian and central, ψ maps both Rp and [R,F] to the identity in 
H. Thus, ψ(R*)=1 and H is a homomorphic image of F/R*. Since R/R* is 
an elementary abelian p-group, G* is a finite p-group.
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
357 
We call G* the p-covering group of G. It has some similarities to Schur 
covering groups, but critically its isomorphism type depends only on G and 
is independent of the chosen presentation. 
LEMMA 9.19 The isomorphism type of G* depends only on G and not 
on R. 
PROOF Let R1 and R2 be normal subgroups of F; let F/R1=G1 and F/R2=G2 
where G1≅G2. Following the notation of Theorem 9.18, we define 
, 
, 
, 
and 
. Then 
 is isomorphic to 
, since each is a homomorphic image of 
the other.
If F/R has class c, then G* has class at most c+1. Further, if G is a class k 
quotient of F/R, then a quotient of F/R having class k+1 is isomorphic to 
a quotient of G*. 
Example 9.6 
The 2-covering group G* of the dihedral group G of order 16 defined in 
Example 9.5 has power-conjugate presentation 
Observe that Z=〈a5, a6, a7〉 is elementary abelian and G*/Z≅G.     [] 
The next result describes generating sets for successive terms of the lower 
exponent-p central series. Its proof is similar to the corresponding statement 
for the lower central series. 
THEOREM 9.20 If G/P1(G) is generated by the images of a1,…, ad, then 
P1(G)/P2(G) is generated by the images of 
 where 1≤i≤d and [aj, ai] where 
1≤i<j≤d. More generally, for k>0, let S be a subset of G which generates G 
modulo P1(G) and let T generate Pk(G) modulo Pk+1(G). Then Pk+1(G) is 
generated modulo Pk+2(G) by [s,t] for s∈S, t∈T and tp for t∈T. 
Let G be a d-generator p-group of order pn and class c. Every refined normal 
series of G gives rise to a power-conjugate presentation and so usually 
every p-group has many power-conjugate presentations. 
In practice, we construct a power-conjugate presentation for G arising 
from a normal series that refines the lower exponent-p central series of G. 
Hence, the power-conjugate presentation {A|R} for G has additional 
structure. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
358 
Let A:=[a1,…,an]. Then the assumption that the normal series associated 
with A refines the lower exponent-p central series of G together with 
Theorem 9.14 implies that P1(G)=Φ(G)=〈ad+1,…,an〉. It follows from 
Proposition 2.44 that {a1,…,ad} is a generating set for G, and hence the 
remaining generators can be expressed as words in {a1,…,ad}. 
Define a function ω from A to {1..c} that maps g∈A to k if g∈Pk–1(G)\Pk(G). 
Then ω is a weight function and ω(g) is the weight of g. The assumption 
that the normal series associated with A refines the lower exponent-p central 
series of G means that ω(aj)≥ω(ai) for j≥i. 
Now the relations in R have the form: 
A power-conjugate presentation that satisfies the above conditions is called 
a weighted power-conjugate presentation. That a finite p-group G has a 
weighted power-conjugate presentation follows from Theorem 9.20. 
For each ak, in {ad+1,…,an}, we require that there is at least one relation 
whose right-hand side is wak, where w is a (possibly empty) word in 
generators a1,…,ak–1. One of these relations is designated the definition of 
ak, and we say that the power-conjugate presentation has definitions. 
Example 9.7 
Consider once more the power-conjugate presentation for the dihedral group 
G of order 16: 
Observe that 
 and [a2, a1]=a3, [a3, a1]=a4. The weights of a1, a2, 
a3, a4 are 1, 1, 2, 3, respectively. The definition of a3 is [a2, a1], and we 
choose [a3, a1] as the definition of a4.    [] 
Now we can more precisely summarize: the p-quotient algorithm takes as 
input a finite presentation {X | S}, for a group G, a prime p, and a positive 
integer c. The output is a weighted consistent power-conjugate presentation 
with definitions for G/Pc(G) and an epimorphism of G onto this quotient. 
The algorithm works down the lower exponent-p central series, using 
the power-conjugate presentation constructed for G/Pt–1(G) to write down 
a presentation for G/Pt(G), where t>0. All power-conjugate presentations 
in what follows are weighted and with definitions. A single iteration of the 
algorithm takes as input: 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
359 
1. 
the finite presentation {X|S} for G; 
2. 
a consistent power-conjugate presentation for the factor group H:=G/ 
Pt_1(G); 
3. 
an epimorphism θ from G to H. 
The output of this iteration is 
1. 
a consistent power-conjugate presentation for the factor group K:=G/ 
Pt(G); 
2. 
an epimorphism ϕ from K to H; 
3. 
an epimorphism τ from G to K where ϕτ=θ. 
The first iteration of the algorithm computes a consistent power-conjugate 
presentation for G/P1(G)=G/Φ(G). If G/Φ(G) has order pd (and so G has 
Frattini rank d), then this presentation is on d generators that commute 
pairwise, and each has order p. This is done by Gaussian elimination using 
the relators of G, where G/P1(G) is regarded as a vector space over GF(p). 
Each subsequent iteration has two principal steps: 
(i) 
Let H:=G/Pt_1(G) for some t>1. Write down a consistent power- 
conjugate presentation for H*, the p-covering group of H. 
(ii) Evaluate the images of the defining relators of G in H* to obtain the 
kernel of the homomorphism from H* to K. 
The first of these steps is performed by a p-covering group algorithm: it 
takes as input a consistent power-conjugate presentation {A|R} for a group 
H and produces a power-conjugate presentation {A*|R*} for its p-covering 
group, H*. The generating set A* contains A as a subset; the elements of 
A*\A are new generators. Each relation in R* ends in a (possibly empty) 
word in the new generators. If we make all new generators trivial, then 
the resulting presentation is just that input to the algorithm. 
We shall now discuss step (i) in more detail. Consider the supplied power- 
conjugate presentation {A|R} for H. Recall that for each ak in {ad+1,…, an}, 
there is at least one relation whose right-hand side is wak, where w is a 
(possibly empty) word in generators a1,…, ak–1. One of these relations is 
designated the definition of ak. Hence there are precisely 
 remaining 
(nondefinition) relations. 
In order to write down a power-conjugate presentation for H*, a total of 
 new generators, an+1,…, an+q, are introduced together with 
relations that make them central and of order p. We next add the tails: 
each of the remaining (nondefinition) relations is modified by inserting one 
of these new generators at the end of its right-hand side. The modified 
relation is now viewed as the definition of the new generator. 
We now summarize an algorithm to construct a power-conjugate 
presentation for the p-covering group of H. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
360 
P-COVERINGGROUP(H) 
Input: Consistent power-conjugate presentation for p-group H 
Output: Power-conjugate presentation for its covering group H* 
1 
Initialize A* to be A; 
2 
Initialize R* to consist of all relations from R which are definitions; 
3 
Modify each nondefining relation 
 to be a
p
i=wiiar 
or [aj, ai]=wi,jar respectively for r∈{n+1..n+q} where different 
nondefining relations are modified by different ar; 
4 
Add each ar to A*; 
5 
Add a
p
i=1 to R* for r∈{n+1..n+q}; 
6 
Add [ar, ai]=1 to R* for r∈{n+1..n+q} and i∈{1..r–1}; 
7 
return H*=A*|R*; 
This is a simplified version of the p-covering group algorithm; see the article 
by Newman, Nickel and Niemeyer [NNN98] for a detailed description and 
proof of the following result. 
THEOREM 9.21 The presentation {A*|R*} produced by the covering group 
algorithm is a power-conjugate presentation for H*. 
This power-conjugate presentation {A*|R*} on 
 generators is 
usually not consistent when t>2. 
The task of deciding whether a given presentation is consistent and, if 
not, its modification to produce a consistent one will be considered in Section 
12.4 of Chapter 12. We briefly consider the topic here. In [Wam74], Wamsley 
proved that it is sufficient to establish that certain test words collected in 
two different ways evaluate to the same normal word to ensure that the 
presentation is consistent. Associativity of course dictates that the two 
normal words obtained must be identical; if they are not, then their quotient 
is a new relation that must hold. In [VL84], Vaughan-Lee significantly 
reduced the number of words that need to be evaluated. We summarize 
their results, which exploit the weights assigned to generators. 
THEOREM 9.22 A weighted power-conjugate presentation on [a1,…, am] of 
a finite p-group of class c is consistent if the following words collect to the 
trivial word: 
where words in inner parentheses are collected first. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
361 
For a proof of this theorem see Section 9.9 of [Sim94]. We apply this 
theorem in the p-covering group algorithm to the group H*, where m=n+q 
with 
. The weight conditions in the theorem imply, in particular, 
that the tests need only be carried out on the generators [a1,…, an]. On the 
t-th iteration of the p-quotient algorithm we have H=G/Pt–1(G), and H* has 
class at most t, so we have c=t in the theorem. 
As we observed above, if the presentation is consistent, then associativity 
implies that all of these words evaluate to the identity. Hence the application 
of this theorem gives a set of new relations that are consequences of R*. 
We add these to R*. The words involve the new generators only, since 
{A*|R*} extends the existing consistent presentation {A|R}. 
We now consider briefly the second principal step of an iteration of the 
p-quotient algorithm. Let M:=〈an+1,…an+q〉 and let N be the kernel of the 
natural homomorphism from K onto H; then N is a homomorphic image 
M/L of M. In order to obtain a power-conjugate presentation for K, we 
must compute the kernel L of the map from M to N. 
This is done by evaluating the images of the relators of G in M. To be 
more precise, we first lift θ to a homomorphism  from the free group on 
the generating set X of G to H*, and then evaluate (r) for each defining 
relator r∈S of G. The elements (r) lie in M and generate L. The 
epimorphism τ:G→K to be returned by the algorithm is induced by , and 
ϕ:K→H is just the natural homomorphism with kernel N=M/L. 
There is an additional technicality involved in lifting θ to , which we 
shall describe briefly. There will in practice be specific generators x1,…, xd 
of X such that θ(xi)=ai and, after the iteration, we will have τ(xi)=ai, and so 
this property is maintained. For all other generators x∈X, we have (x)=θ(x)ax 
where ax is an unknown element of M. The elements ax will be determined 
modulo L during the evaluation of (r) for r∈S. In practice, they can be 
introduced as new temporary generators of M, which will be eliminated 
during the Gaussian elimination process described below. For further 
discussion of this aspect, see [HN80]. 
THEOREM 9.23 The result of collecting the set of words in {a1,…, an} listed 
in Theorem 9.22 in the power-conjugate presentation for H* is a set U of 
elements of M; the result of evaluating the relators of G in the images of the 
generators of G under  in the power-conjugate presentation for H* is a set 
V of elements of M; and N is isomorphic to M/〈U∪V〉. 
Critical to practical computation is the realization that M can be viewed as 
a vector space over the field of p elements. A basis [n1,…, nr] for N=M/L 
can be computed using Gaussian elimination. Let Â be A∪{n1,…, nr}. The 
image of each element an+i can be expressed in this basis of N, and we 
replace its occurrence in R* by this image to obtain Rl . 
Hence, on the t-th iteration of the p-quotient algorithm, we obtain a 
consistent power-conjugate presentation 
 for G/Pt(G)=K and an 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
362 
epimorphism τ from G to K. We can now extend the weight function ω to 
 by defining ω(ni):=t. This completes the construction of a consistent 
powerconjugate presentation 
 for the class t p-quotient of G. 
We now summarize the p-quotient algorithm. 
P-QUQTIENT(Q, p, c) 
Input: Finitely presented group Q=〈X|S〉, prime p, positive integer c 
Output: Consistent power-conjugate presentation for the largest class 
c p-quotient of Q 
1 
Calculate G=〈A|R〉, the largest elementary abelian p-quotient of Q; 
2 
for t∈[2 .. c] 
3 
do H:=P-COVERINGGROUP (G); 
4 
Apply consistency tests to H; 
5 
Evaluate defining relations for G; 
6 
Eliminate redundant generators from H; 
7 
if |H|=|G| then return G; 
8 
G:=H; 
9 
return G; 
Example 9.8 
As an example, we construct the class 3 2-quotient of the finitely presented 
group 
 (where [y, x, x]:=[[y,x],x]). 
Its class 1 quotient is G=C2×C2 which has power-conjugate presentation 
where the epimorphism θ maps x to a1 and y to a2, and each generator has 
weight 1. 
To write down its 2-covering group G*, we introduce new generators as 
right-hand sides of the three nondefining relations. We also add relations 
to ensure that these new generators are central and of order 2. Hence G* 
has power-conjugate presentation 
Is this presentation consistent? For example, is a1(a1a1)=(a1a1)a1? Observe 
that a1(a1a1)=a1a5 and (a1a1)a1=a5a1=a1a5 and so we obtain only the trivial 
relation. If we enforce all of the consistency tests, we deduce no new 
relations and so the listed power-conjugate presentation for G* is indeed 
consistent. (In fact, it follows from Theorem 9.22 that any weighted 
powerconjugate presentation of a p-group of class 2 is consistent so, in 
general, we do not need to carry out any consistency checks on the second 
iteration of the p-quotient algorithm.) 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
363 
Now we enforce relations: θ([y, x, x])=θ(x2) implies that 1=a4 whereas 
θ((xyx)4)=1 gives the trivial relation. Hence we factor G* by 〈a4〉 and rename 
a5 as a4 to obtain the class 2 2-quotient G having consistent power- 
conjugate presentation 
The unique relations having right-hand sides a3, a4 are chosen as the 
definitions of these generators, both having weight 2; the epimorphism θ 
from Q to G maps x to a1 and y to a2. 
To construct the class 3 2-quotient of Q, we first construct a power- 
conjugate presentation for G* by introducing new generators as right-hand 
sides of all 8 nondefining relations. We also add relations to ensure that 
the new generators are central and of order 2. Hence G* is 
We apply Theorem 9.22 to decide if this power-conjugate presentation is 
consistent. 
1. 
Is a2(a2a2)=(a2a2)a2? Observe that a2(a2a2)=a2a4 and (a2a2)a2=a4a2=a2a4a8. 
Hence a8 is trivial. 
2. 
Is a2(a1a1)=(a2a1)a1? Observe that (a2a1)a1=a2a5a11a12 and a2(a1a1)=a2a12. 
Hence a5a11 is trivial. 
3. 
Is a2(a2a1)=(a2a2)a1? Observe that a2(a2a1)=a1a4a6a11 and that 
(a2a2)a1=a1a4a7. Hence a6a7a11 is trivial. 
4. 
Is a3(a2a2)=(a3a2)a2? Observe that a3(a2a2)=a3a4 and (a3a2)a2 = a3a4a9. Hence 
a9 is trivial. 
We leave as an exercise to verify that there are no other independent 
consequences of consistency. 
Hence, we factor G* by 〈a8, a9, a5a11, a6, a7, a11〉 and deduce that G* has 
consistent power-conjugate presentation 
Now we enforce relations: θ([y, x, x])=θ(x2) implies that a7=a8 and 
θ((xyx)4)=1 implies that a6=1. Hence we factor G* by 
 to obtain the 
class 3 2-quotient 
[] 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
364 
9.4.3 Other quotient algorithms 
The first description of a p-quotient algorithm was by Macdonald in [Mac74]. 
Other algorithms are presented in [Mac87]. The version of the p-quotient 
algorithm that we described above was introduced by Newman in [New76]; 
for additional details and applications of the algorithm, see [HN80] and [NO96]. 
Sims, in [Sim87, Sim90b, Sim94], discusses computing certain quotients 
of finitely presented groups; his book [Sim94] is the most comprehensive 
source available on the topic. Nickel, in [Nic95], presents an algorithm to 
construct nilpotent quotients of a finitely presented group; his 
implementation is available in GAP and MAGMA. 
A number of algorithms for computing finite solvable quotients of finitely 
presented groups have been proposed. They include that of Wamsley 
[Wam77], Leedham-Green [LG84], Plesken [Ple87], and Niemeyer [Nie93]. 
H. Brückner further developed and implemented a version of Plesken’s 
algorithm; it is available in MAGMA. Niemeyer’s algorithm is available in 
GAP V3. 
In [Lo98], Lo describes an infinite polycyclic algorithm which constructs 
a polycyclic presentation for G/G[n], where G[n] is the nth term of the derived 
series of a finitely presented group G; it is available in GAP V3. A new 
infinite polycyclic quotient algorithm has recently been developed by Eick, 
Niemeyer and Panaia in [ENP]; it generalises the approach taken by 
Niemeyer in [Nie93]; an implementation is available in GAP. 
9.4.4 Generating descriptions of p-groups 
The p-group generation algorithm calculates power-conjugate presentations 
for particular extensions of a finite p-group. 
Let G be a finite d-generator p-group of class c. A group H is a descendant 
of G if H is d-generator and the quotient H/Pc(H) is isomorphic to G. A 
group is an immediate descendant of G if it is a descendant of G and has 
class c+1. 
In summary, the p-group generation algorithm takes as input a p-group, 
G, and produces as output a complete and irredundant list of the immediate 
descendants of G: all isomorphism types occur in the list and no two 
elements have the same isomorphism type. 
We now describe the algorithm in more detail. Observe, from Theorem 
9.18, that every immediate descendant of G=F/R is isomorphic to a quotient 
of G*=F/R*. The factor group R/R* is the p-multiplicator of G and the 
group Pc(G*) is called the nucleus of G. (Both the p-multiplicator and nucleus 
are elementary abelian p-groups.) An allowable subgroup is a subgroup of 
the p-multiplicator which is the kernel of a homomorphism from G* onto 
an immediate descendant of G. 
If we wish to construct the immediate descendants of G efficiently, then 
we must characterize the required quotients of G*. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
365 
THEOREM 9.24 A subgroup is allowable if and only if it is a proper subgroup 
of the p-multiplicator of G which supplements the nucleus. 
PROOF Let M/R* be an allowable subgroup—that is, the kernel of a map 
from F/R* onto an immediate descendant H of G. Since G has class c and 
H has class c+1, it is clear that M is a proper subgroup of R. Lemma 9.16 
shows that Pc(F) is a subgroup of R and M is also a subgroup of R and, 
hence, MPc(F) is a subgroup of R. Following Theorem 9.18, ψ(R) is a subgroup 
of Pc(H). Since F/R has class c, Pc(ψ(F)) is also a subgroup of ψ(R) showing 
that ψ(R) equals Pc(H). But ψ(R) also equals R/M and Pc(H)=Pc(F)M/M. 
Therefore R/M=Pc(F)M/M giving R=Pc(F)M. Hence, R* can be factored 
out showing that (M/R*)Pc(F)R*/R*=R/R*. Lemma 9.15 now gives the 
required statement. 
Conversely, let M/R* be a proper subgroup of the p-multiplicator that 
supplements the nucleus. Then Pc(F)M/R*=R/R* and hence Pc(F)M/M = 
R/M. Lemma 9.15 gives Pc(F/M)=R/M. Since F/M is a quotient of F/R*, 
it has generator number d and the quotient (F/M)/Pc(F/M) is isomorphic 
to G showing that F/M is a descendant of G. But Pc(F/M)=R/M which is 
nontrivial; hence F/M has class c+1 and is an immediate descendant of G. 
Figure 9.1 illustrates the situation, where N/R* represents the nucleus 
and M/R* is an allowable subgroup. 
Example 9.9 
The 2-covering group G* of the dihedral group G of order 16 has power- 
conjugate presentation 
Figure 9.1: Various subgroups of the p-covering group. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
366 
The 2-multiplicator is 
 and the nucleus is 
. The subgroups 
 are allowable and the corresponding immediate 
descendants have order 32. The subgroup 
 is also allowable, but 
the resulting quotient is isomorphic to the quotient of G* by 
.    [] 
If G has immediate descendants, it is called capable; otherwise, it is called 
terminal Clearly, G is capable if and only if G* has class exactly c+1. In 
particular, if G has order pn and its nucleus has rank m, then G has immediate 
descendants of order pn+s where 1≤s≤m. 
If G is capable then, on taking factor groups of G* by allowable subgroups, 
a complete list of immediate descendants is obtained; this list usually contains 
redundancies. We define an obvious equivalence relation: two allowable 
subgroups M1/R* and M2/R* are equivalent if and only if their quotients 
F/M1 and F/M2 are isomorphic. 
A complete and irredundant set of immediate descendants of G can be 
obtained by factoring G* by one representative of each equivalence class. 
In practice, this definition is useful only because the equivalence relation 
can be given a different characterization by using the automorphism group, 
Aut(G), of G. 
In summary, we now describe an extension of each automorphism, α, of 
G to an automorphism, α*, of G*. The action of α* when restricted to the p- 
multiplicator of G is uniquely determined by α, and α* induces a permutation 
of the allowable subgroups. Finally we prove that the equivalence classes of 
allowable subgroups are exactly the orbits of the allowable subgroups under 
the action of these permutations. 
THEOREM 9.25 Let M1/R* and M2/R* be allowable subgroups of F/R* 
which are contained in R/R*, and let ϕ be an isomorphism from F/M1 to 
F/M2. Then there exists an automorphism, α*, of G* which maps M1/R* to 
M2/R* and the map from F/M1 to F/M2 induced by α* agrees with ϕ. 
PROOF For each i∈{1.. d}, let bi be a word in F such that ϕ(aiM1) = biM2. 
Lemma 9.15 implies that 
Therefore ϕ induces an automorphism, α, on F/R. 
For each automorphism, α, of F/R we shall now describe how to define 
an automorphism α* of F/R*. For each i∈{1..d}, choose a representative 
ui in F of the coset (aiR)α; then (aiR)α=uiR. Let v(a1,…, ad) be a word in F; 
then (v(a1,…, ad)R)α=v(u1,…, ud)R. If v(a1,…, ad) is an element of R, then 
Rα=v(u1,…, ud)R. But Rα=R and so v(u1,…, ud) is in R. Since R*=[R, 
F]Rp, it follows that if w(a1,…, ad)∈R* then w(u1,…, ud) is also an element 
of R*. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
367 
Assume that w1(a1,…, ad)R*=w2(a1,…, ad)R* where each wi is a word in F. 
Then w2(a1,…, ad)-1w1(a1,…, ad)∈R*. Hence w1(u1,…, ud)R*=w2(u1,…, ud)R*. 
We can now define the mapping α* as follows: for each word w(a1,…, ad) in 
F, put 
Clearly, α* is a homomorphism and it remains to show that it is onto. 
But α is an automorphism of F/R and (aiR)α=uiR; therefore, F/R* is 
generated by {u1R*,…, udR*,R/R*}. Since R/R*≤P1(F/R*), it follows that 
Hence α* is an automorphism of F/R*. 
While α* is not uniquely determined by a, its restriction to R/R* is. 
Assume that (aiR)α=uiR=uiriR=viR for some ri∈R. Then there are two 
automorphisms,  and  where 
 and 
. Since each 
 is an automorphism, 
. Restricting both automorphisms to R/R* shows 
that both w(u1,…, ud) and w(v1,…, vd) are elements of R. But words in R are 
products of pth powers and commutators; since [vj,vi]R*=[uj,ui]R* and 
, it follows that w(u1,…, ud)R*=w(v1,…, vd)R*. Hence the 
restriction of α* to R/R* is uniquely determined by α. 
It remains to establish that (M1/R*)α* is equal to M2/R*. Let w(a1,…, ad) 
be an element of M1 and αl* let denote the restriction of α* to R/R*; then 
Further 
It follows that 
 is a subgroup of M2/R* and, since both have the 
same index in F/R*, they are equal.
We have the immediate corollary. 
COROLLARY 9.26 Every automorphism α of F/R extends to an 
automorphism α* of F/R* and the restriction of α* to R/R* is uniquely 
determined by α. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
368 
PROOF The results follows from Theorem 9.25, where both M1/R* and 
M2/R* are chosen to be R/R*.
The automorphism α* is an extended automorphism. We now show that it 
permutes the allowable subgroups. 
LEMMA 9.27 Each extended automorphism α* induces a permutation of 
the allowable subgroups. 
PROOF The nucleus, Pc(F/R*), of G is characteristic in G and the p- 
multiplicator, R/R*, is fixed by α*. Let M/R* be an allowable subgroup. 
Then 
showing that 
 is an allowable subgroup. Clearly the mapping is 
one-to-one and onto.
The permutation α′ of the allowable subgroups induced by α* depends only 
on the automorphism α of G. Let P be the permutation group generated by 
the α′. Then the mapping α6α′ is a homomorphism from Aut G onto P. 
We now establish the critical result about equivalence classes of the 
allowable subgroups. 
THEOREM 9.28 The orbits of the allowable subgroups under the action of 
P are exactly the equivalence classes of the allowable subgroups. 
PROOF Let M1/R* and M2/R* be allowable subgroups in the same 
equivalence class; then F/M1 and F/M2 are isomorphic. By Theorem 9.25, 
there exists an automorphism, α*, of F/R* which maps M1/R* to M2/R* 
and α* induces a permutation α′ of the allowable subgroups. Thus, (M1/ 
R*)α′=M2/R* showing that M1/R* and M2/R* lie in the same orbit. 
In order to establish the converse, it is simpler to use the following 
general result, which can be established easily. Let N be a normal subgroup 
of a group H and let γ be an automorphism of H; then 
. Now 
let M1/R* and M2/R* be allowable subgroups that are elements of the 
same orbit under P. Then there exists a permutation, α′, of the allowable 
subgroups such that (M1/R*)α′=M2/R*. This permutation is induced by an 
automorphism, α*, of F/R* where (M1/R*)α*=M2/R*. We use the general 
result to deduce that there is an isomorphism from F/M1 to F/M2.
In summary, the p-group generation algorithm takes as input a consistent 
power-conjugate presentation for a p-group and a generating set for its 
automorphism group. It produces consistent power-conjugate presentation 
for representatives of the isomorphism classes of immediate descendants of 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
369 
the group. (In practice, concurrently, we construct the automorphism groups 
of the immediate descendants, hence permitting recursion. See Section 9.4.6 
for more details.) In applying the algorithm, there is a natural division of the 
calculation of the immediate descendants according to their order. A top- 
level outline of the algorithm is the following. 
GENERATE-P-GROUPS(G, A, S) 
Input: Group G of order pn, its automorphism group A, s∈N 
Output: Immediate descendants of G having order pn+s 
1 Construct a consistent power-conjugate presentation for the p-covering 
group G* of G; 
2 Initialize L to be the empty list; 
3 if the order of the nucleus of G is less than ps then return L; 
4 for each generator α of A 
5 
do Calculate its extended automorphism α*; 
6 
Calculate the permutation α′ of the allowable subgroups 
of index pn+s in G* induced by α*; 
7 Calculate orbits of the group generated by the permutations a′; 
8 for each orbit 
9 
do Choose a representative; 
10 
Factor G* by the representative allowable subgroup to obtain 
an immediate descendant H; 
11 
Append H to L; 
12 return L; 
Example 9.10 
We construct the immediate descendants of the elementary abelian group 
G=C2×C2 having power-conjugate presentation 
Its 2-covering group G* is 
The 2-multiplicator 〈a3, a4, a5〉 is elementary abelian and it coincides with 
the nucleus. Hence every proper subgroup of the 2-multiplicator supplements 
the nucleus and so is allowable. 
The automorphism group of G is of course isomorphic to GL(2, 2) and we 
choose as its generators 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
370 
The extensions of these automorphisms to G* are: 
Assume we wish to construct the immediate descendants of order 8. 
Then the seven allowable subgroups each have rank 2 and are 
The orbits of the allowable subgroups induced by α*
1 and α*
2 are 
We choose one representative from each orbit and factor it from G* to 
obtain three immediate descendants: 
These immediate descendants are, of course, well-known: the dihedral and 
quaternion groups of order 8, and the abelian group C2×C4, respectively. 
Now we consider the construction of the immediate descendants of C2×C2 
having order 16. Generators for the seven cyclic allowable subgroups are 
where each of δ, γ, ζ is 0 or 1. The orbits of the allowable subgroups induced 
by α*
1 and α*
2 are 
We choose one representatives from each orbit to obtain 3 immediate 
descendants of order 16. If, for example, we factor G* by a3 then we obtain 
the immediate descendant 
which is C4×C4. 
Observe that C2×C2 has just one immediate descendant of order 25, 
obtained by factoring G* by the trivial allowable subgroup.
A detailed description of the algorithm appears in the articles by Newman 
[New77] and O’Brien [O’B90]. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
371 
9.4.5 Testing finite p-groups for isomorphism 
The isomorphism problem of determining whether two given presentations 
present the same group was introduced by Tietze in [Tie08] and formulated 
by Dehn in [Deh11]. It is proved by Adian in [Adi58] and by Rabin in [Rab58] 
that the isomorphism problem for finitely presented groups is unsolvable, 
by exhibiting its unsolvability for a particular class of examples. However, 
Segal proves in [Seg90] that there is an algorithm to decide the isomorphism 
of two polycyclic-by-finite groups given by finite presentations. 
In [HR92], Holt and Rees seek to establish isomorphism by running a 
Knuth-Bendix procedure on the supplied group presentations, in an attempt 
to generate a normal form algorithm for words in the generators. 
Concurrently, they attempt to establish nonisomorphism of the two groups 
by finding the number of finite quotients each has of a particular order. 
In [O’B94], O’Brien describes an algorithm that solves the problem for 
finite p-groups. He defines a standard presentation for each p-group and 
provides an algorithm for its construction. Hence, given two p-groups 
presented by arbitrary finite presentations, the determination of their 
isomorphism is essentially the same problem as the construction of their 
standard presentations and the easy comparison of these presentations. 
One view of the p-group generation algorithm is that it is a method for 
constructing a particular power-conjugate presentation for a given p-group, 
G. If G has Frattini rank d and class c, then G/P1 (G) is the elementary 
abelian group of order pd; further G is a descendant of this elementary 
abelian group and G/Pi+1(G) is an immediate descendant of G/Pi(G) for i<c. 
Assume we now construct the immediate descendants of G/P1(G). Among 
these immediate descendants is the class two quotient, G/P2(G), of G. It is 
now possible to calculate the immediate descendants of G/P2(G) in order to 
obtain a power-conjugate presentation for the class three quotient of G. 
We may iterate this construction until we construct the class c quotient of 
G. Therefore it is possible to construct G by iterating a method for calculating 
immediate descendants, starting with the elementary abelian group of rank 
d. We designate the presentation obtained by constructing a power-conjugate 
presentation for a given p-group using the p-group generation algorithm in 
this way as the standard presentation for this group. For a detailed 
description of the algorithm, see [O’B94]. 
An alternative approach for p-groups, involving modular group algebra 
techniques, is described by Wursthorn in [Wur93]. 
9.4.6 Automorphism groups of finite p-groups 
The automorphism group of a p-group can be constructed by induction 
down the lower exponent-p central series of a p-group G; that is, we 
successively compute Aut(G/Pi(G)). For a detailed description of the 
algorithm, see the paper by Eick, Leedham-Green, and O’Brien [ELGO02]. 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
372 
9.4.7 Applications 
The Burnside problem, first posed by W.Burnside in 1902, asks whether a 
finitely generated torsion group is necessarily finite and, more specifically, 
whether the Burnside group 
is finite. It is now known that B(d, n) is finite for n=2, 3, 4, 6 and is infinite for 
d≥2 and sufficiently large n. Indeed, this is the case for all n≥8000 and for 
odd n≥665; see [Adi79, Iva94, Lys96]. However, despite intensive investigation, 
much of it computational, it is not yet known if B(2, 5) is finite. 
One early motivation for the development of the p-quotient algorithm 
was the restricted Burnside problem, which asks if the order of a finite 
group with d generators and exponent n is bounded by a function of d and 
n; that is, whether there is an upper bound on the order of the finite 
quotients of B(d,n). Results of P. Hall and G. Higman [HH56] reduced this 
to the case when n=pe is a prime power. In [Zel91a, Zel91b], using Jordan 
algebra techniques, Zel’manov provided a positive answer to the question; 
Vaughan-Lee [VL93] obtains similar results using Lie algebras. 
Hence, given d and n, there exists a finite group R(d,n), the restricted 
Burnside group with d generators and exponent n, such that all other finite 
groups with at most d generators and exponent dividing n are homomorphic 
images of R(d,n). A natural question is: what is the order (and structure) of 
this group? While this remains a very hard problem, we are able to construct 
consistent power-conjugate presentations for some of the groups and so deduce 
structural information in these limited cases. The property xn=1 for all 
x∈R(d, n) can be enforced via a finite list of relations which the p-quotient at 
each successive class must satisfy. In summary, the Higman lemma (see 
[Hig59], or [Sim94, Sec. 11.7] for a practical realization) states that a group of 
class c described by a consistent power-conjugate presentation has exponent 
pm if every normal word of weight at most c has order dividing pm. 
In Table 9.1 we record the orders of R(d,n) for selected values of d and n. 
The order of R(2, 4)=B(2, 4) was determined by S.J.Tobin in 1954; in 1902, 
Burnside proved in [Bur02] that its order divided 212. Early constructions of 
power-conjugate presentations by machine were for R(3,4) in [BKW74] and 
R(2, 5) in [HWW74]. As one indicator of the difficulty involved in obtaining 
such descriptions, a consistent power-conjugate presentation for R(2, 7) 
was constructed by O’Brien and Vaughan-Lee [OVL02] only after using a 
special purpose implementation of the p-quotient algorithm and 
approximately one year of CPU time. 
M.F.Newman has been the driving force in the development and application 
of the p-quotient algorithm to this problem. In work spanning more than 30 
years, and with various collaborators, including Havas, O’Brien, and Vaughan- 
Lee, he established the remaining results cited in Table 9.1 and many others. 
For a survey of the known results, see [VLZ99]. 
© 2005 by Chapman & Hall/CRC Press

Computing Quotients of Finitely Presented Groups 
373 
Newman also used the p-quotient algorithm to prove that F(2, 9) is infinite. 
The Fibonacci group F(2, n) is generated by {a1, a2,…, an} with defining 
relations aiai+1=ai+2, i∈{1..n}, with subscripts read modulo n. These groups 
were introduced by J.H.Conway in 1965, who asked whether F(2, 5) is cyclic 
of order 11. By 1988, the (in) finiteness of all F(2, n) except F(2, 9) had been 
decided. In [New90], Newman introduced a refinement of the famous Golod- 
Shafarevich bound (which states that the number of defining relations needed 
for a finite p-group defined minimally on d generators is larger than d2/4) 
and combined this with the result of p-quotient calculations to deduce that 
F(2, 9) is infinite. 
In more detail, he applied the p-quotient with prime 5 to a subgroup of 
index 152 in F(2, 9). As with the applications of the abelian quotient algorithm 
discussed in Subsection 9.3.3, the first parts of this calculation involved 
applying the low-index subgroups and Reidemeister-Schreier algorithms. 
In their construction of a counterexample to the class-breadth conjecture 
(see [LGNW69]), Felsch and Neubüser [FN79] used the p-quotient algorithm 
extensively to construct presentations for finite 2-quotients of infinite finitely 
presented groups. 
In contrast to (some of) the Burnside computations, most applications of 
the p-quotient algorithm are very routine and take almost no resources in 
time or space to compute a consistent power-conjugate presentation for a 
p-quotient of a finitely presented group. The Havas, Newman, and O’Brien 
implementation is available in MAGMA, GAP, and as a stand-alone. For 
more details of the current algorithm and its implementation, see [NO96] 
and [NNN98]. 
The p-group generation algorithm has been applied successfully to 
determine the p-groups of orders up to 2000. It has also played an important 
role in verifying (and usually correcting) results of various theoretical 
classifications. In Table 9.2 we report the number of 2-groups of orders 2k 
for k∈{1.. 10}; these were first obtained using the p-group generation 
algorithm. Further details on the classification of all groups of order up to 
2000 will be given in Section 11.4. 
The p-group generation algorithm has also been an important tool in 
obtaining insight into the the structure of p-groups, particularly those of 
Table 9.1: Orders of R(d, e) 
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory 
374 
fixed coclass. It played a fundamental role in shaping the conjectures of 
Leedham-Green and Newman in their seminal study [LGN80] of p-groups 
of given co-class; and it was also used by Newman and O’Brien [NO99] in 
their study of 2-groups of coclass 3. 
The most significant limiting factor in applications of the p-group 
generation algorithm is the degree of the permutation group defined by 
the action of the automorphism group on the allowable subgroups: this 
grows very rapidly with the prime and Frattini rank. Various practical 
steps are taken to reduce this limitation: these include exploiting the 
characteristic subgroup structure of the p-multiplicator. For further details 
see the papers of O’Brien [O’B90, O’B91]. The algorithm is an important 
tool for investigating small Frattini-rank p-groups. Implementations of the 
p-group generation algorithm are available in GAP and MAGMA. 
Certain variations of the p-group generation algorithm, which make use 
of the Cauchy-Frobenius formula (Lemma 2.17) to count the precise number 
up to isomorphism of p-groups of a given order, have also been developed; 
see the article by Eick and O’Brien [EO99] for further details. 
Table 9.2: The number of groups for selected orders 
© 2005 by Chapman & Hall/CRC Press

375
Chapter 10
Advanced Computations in
Finite Groups
In this chapter, we shall be introducing a particular approach to some more
advanced and sophisticated types of computations in finite groups, such as
finding all subgroups of a particular type, or calculating automorphism groups.
While most of these applications, such as automorphism groups, lie beyond
the scope of this book, we shall illustrate the techniques involved with a
reasonably detailed description of a method for finding representatives of the
conjugacy classes of subgroups in a finite group.
The approach does not yet have a standard name, but for the purpose of
the discussion in this chapter, we shall call it the solvable radical method,
since the first step is always to find the solvable radical of the group.
We shall, for the most part, restrict our attention to permutation groups,
but it is a feature of the method that it is to a large extent independent of the
representation type of the finite group, provided that the more basic facilities
are available for computing within that representation type.
In summary, we compute the solvable radical L:=O(G) of G, and a series
 
of subgroups Ni of L for which each 
 and Ni/Ni-1 is elementary abelian.
We then solve our problem first in G/L=G/Nr, and then, successively, we
solve it in G/Ni, for i=r-1,…, 1, 0.
For finite solvable groups defined by PC-presentations, the method can
generally be used, but with the added simplification that L=G, and so the
solution of the problem in G/L is generally trivial! Indeed, some of the
examples, such as computing maximal subgroups or automorphism groups,
can be seen as direct generalizations of the methods already described for
solving those problems in solvable groups in Chapter 8. It should be noted,
however, that the methods described there have been more carefully designed
and optimized in the PC-presentation context, and so they will generally
perform more efficiently in that setting than the general-purpose methods to
be described in this chapter.
Some applications of the solvable radical method involve two other
characteristic subgroups of G, in addition to L. In the first section, we shall
define these subgroups, and then describe how to compute them.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
376
In the following section, we shall describe how these subgroups can be
used as a step towards computing chief and composition series of a finite
permutation group. Another important ingredient of the chief series algorithm
is the ‘Meataxe’ algorithm that was introduced in Section 7.4 for finding a
composition series of a module for a group over a finite field.
It is interesting to observe that our approach is slightly different from
that described by Seress in Chapter 6 of [Ser03], who advocates computing a
composition series first, before computing subgroups such as Op(G).
We shall then give a brief overview of the current range of algorithms that
use the solvable radical method, and a more detailed description of the
conjugacy classes of subgroups application.
10.1 Some useful subgroups
10.1.1 Definition of the subgroups
The author has used the following nonstandard terminology in a number
of his recent papers, and will continue to do so here!
DEFINITION 10.1 A group is called a TF-group if it has no solvable normal
subgroup.
Equivalently, a TF-group is one with no nontrivial nilpotent normal subgroup,
which is equivalent to its having trivial Fitting subgroup; hence the name.
For a finite group G, let L:=O(G) be the largest normal solvable subgroup
of G. Then G/L is a TF-group.
Let M/L:=soc(G/L) be the socle of G/L (Definition 2.39). Then, since
M/L is a TF-group, it has no abelian minimal normal subgroups, and
Proposition 2.40 tells us that M/L is the direct product of the minimal
normal subgroups M1/L, M2/L,…, Mm/L of G/L. Furthermore, each Mi/L is
itself the direct product of isomorphic finite nonabelian simple groups Sij
(1≤j≤mi) which, by Corollary 2.41, are permuted transitively under the
conjugation action of G/L, and hence of G, on Mi/L.
In other words, if we let ∆ be the set containing all of the groups Sij, then
conjugation by G defines an action :G→Sym(∆) of G on ∆ in which the
orbits are the sets {Sij|1≤j≤im} for 1≤i≤m.
Let K:=ker(). Since M/L is a direct product of nonabelian simple groups,
we have Z(M/L)=1, and hence CG/L(M/L)=1, because otherwise CG/L(M/L)
would contain minimal normal subgroups of G/L disjoint from M/L. So
conjugation by G also induces a monomorphism α:G→Aut(M/L), and α(K)
is contained in the subgroup of Aut(M/L) that fixes all of the Sij. Hence
© 2005 by Chapman & Hall/CRC Press

Advanced Computations in Finite Groups
377
α(K) is contained in the direct product of the groups Aut(Sij), and α(K)/α(M)
is contained in the direct product of the groups Out(Sij).
Now the Schreier conjecture, which states that the outer automorphism
group of any nonabelian finite simple group is solvable, was confirmed by the
classification of finite simple groups, and so K/M≅α(K)/α(M) is solvable.
10.1.2 Computing the subgroups—initial reductions
In this and the following two sections, we shall describe an algorithm for
computing the subgroups that we have just defined in the case when G is a
permutation group on a finite set Ω. There are a number of slightly different
approaches to this problem. We shall take the easiest possible route here,
although the algorithm to be described runs in polynomial time and is
reasonably efficient in practice. Some parts of it are similar to the method
described by Beals in [Bea93b].
In this subsection, we reduce the problem to that of finding a nontrivial
proper normal subgroup in a primitive TF-group. We use the algorithm
described in Subsection 4.7.5 to compute L=O(G) and then, by Corollary
4.15, we can compute an epimorphism ρ:G→H, where H≅G/L and H is a
permutation group of degree at most ||. This effectively reduces the
problem to the TF-case, so we shall assume for the rest of the section
that O(G)=1.
Now, provided that we can find the set ∆ of the direct factors Sij of
soc(G), we can immediately compute the group M that they generate, and
it is straightforward to compute the homomorphism :G→Sym(∆) and its
kernel K. We can also compute the minimal normal subgroups Mi of G
since, by Corollary 2.41, these correspond to the orbits of the action of G on
the socle factors.
So we have now reduced the problem of finding the subgroups defined in
Subsection 10.1.1 to that of finding the simple factors of the socle of a TF-
group G.
LEMMA 10.2 Let G be a TF-group and let 
. Then soc(G)=
soc(N)×soc(CG(soc(N))).
PROOF By Corollary 2.42, the simple factors of soc(G) and of soc(N) are
just the simple subnormal subgroups of G and of N, respectively. Hence
soc(N)≤soc(G) and similarly soc(CG(soc(N)))≤G. Any simple factors of soc(G)
that are not in soc(N) lie in CG(soc(N)) and, since soc(N)  soc(CG(soc(N)))=1,
the result follows.
So, if we can find any proper nontrivial normal subgroup of G, then we can
apply our algorithm recursively to N to compute the simple factors of soc(N)
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
378
and then compute CG(SOC(N)) and the simple factors of its socle, thereby
solving the problem in G. (As we remarked in Subsection 4.6.5, the centralizer
in a permutation group G of a normal subgroup H of G can be found in
polynomial time; see [Ser03, Sec. 6.1.4].)
This enables us to reduce immediately first to the case when G is transitive,
and then to the case when G is primitive. If, for example, G is intransitive
and  is a nontrivial orbit, then either G is faithful and we can replace G by
the transitive group G, or the kernel of G is a proper nontrivial normal
subgroup of G. The reduction to a primitive action is similar.
Before presenting the algorithm in the primitive case, we digress to discuss
an important theorem.
10.1.3 The O’Nan-Scott theorem
The O’Nan-Scott theorem is a classification of finite primitive permutation
groups according to the type and action of their minimal normal subgroups.
It was first stated and proved by Scott in [Sco80]. There are many versions,
which differ slightly in the subdivision of the cases, and in how much detail
they describe the permutation actions involved.
DEFINITION 10.3 A group G with S≤G≤Aut(S) for some finite nonabelian
simple group S is called almost simple.
So case (ii) (a) with d=1 in our statement of the theorem below occurs when
G is almost simple, and this is often singled out as a separate case. Detailed
discussions and proofs can be found, for example, in Chapter 4 of [DM96] and
in Chapter 4 of [Cam99].
THEOREM 10.4 (the O’Nan-Scott theorem) Let G be a finite primitive
permutation group on . Then one of the following holds.
(i)
G has an elementary abelian regular normal subgroup M, and M is
the only minimal normal subgroup of G.
(ii)
G has a unique minimal normal subgroup M, and M is nonabelian
and isomorphic to S1×…×Sd for some d≥1, where the Si are
isomorphic simple groups. Furthermore, one of the following holds
for α∈.
(a) Mα=H1×…×Hd, where each Hi=(Si)α, and the Hi are isomorphic
to each other with NG(Hi) maximal in NG(Si). We have
||=|S1:H1|d.
(b) We have ||=|S1|(a—1)b, for integers a, b with ab=m, a>1 and
b≥1, Mα=D1×…×Db where Di is a diagonal subgroup of
© 2005 by Chapman & Hall/CRC Press

Advanced Computations in Finite Groups
379
, and G acts imprimitively by conjugation
on 
 with minimal block system
(c)
M acts regularly on , so ||=|M|. We have d≥6 in this case.
(iii)
G has exactly two minimal normal subgroups M1 and M2, which
are nonabelian, isomorphic to each other, and act regularly on .
This theorem has played an important rôle in the recent development of
algorithms for analyzing the structure of permutation groups. Generally,
one tries to reduce to the primitive case, and then to use the O’Nan-Scott
theorem.
For our immediate purposes, we shall just need the following easy corollary.
We leave the proof as an exercise.
COROLLARY 10.5 If G is a finite primitive permutation group on  with
no regular normal subgroup, then we are in case (ii) (a) or (ii) (b) of Theorem
10.4. Furthermore, if soc(G)=G, then we are in case (ii) (a) with d=1, and G
is simple.
10.1.4 Finding the socle factors—the primitive case
Our algorithm for finding the socle factors in a primitive group G depends
on the O’Nan-Scott theorem and the following lemma, which is a simplified
version of Lemma 6.2.22 of [Ser03].
LEMMA 10.6 Let G be primitive with α∈, let M be either a solvable normal
subgroup or a minimal normal subgroup of Gα, and assume that 
.
Then
(i) If M is solvable then G/soc(G) is solvable.
(ii) If M is not solvable then either soc(G)=G or 
.
PROOF Since G is primitive, soc(G) is transitive, so M soc(G) is normal
in G, and hence 
 implies that M soc(G)=G. So G/soc(G) is
isomorphic to the quotient group M/(M soc(G)) of M, which proves (i).
From M soc(G)=G we have M soc(G)α=Gα. If M≤soc(G), then soc(G)=G.
Otherwise, since M is minimal normal in Gα, M∩soc(G)α=1, so Gα=M×soc(G)α
in which case 
.
Now let G be primitive. We are assuming that O(G)=1, so we cannot be in
case (i) of the O’Nan-Scott theorem. As explained earlier, it suffices to find
any proper nontrivial normal subgroup of G, or to prove that G is simple.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
380
Now G cannot be regular so, if we can find a regular normal subgroup of
G, then we are done. We can use the method described in Subsection 4.7.6
to test for the existence of such a subgroup, and to find such a subgroup if
it exists.
So we may assume that G has no regular normal subgroup, in which case
Corollary 10.5 tells us that we are in case (ii) (a) or (ii) (b) of the O’Nan-Scott
theorem. We now use the algorithm P-CORE in Subsection 4.7.4 to decide
whether Op(Gα)≠1 for any prime p.
If so, choose such a prime p, let M:=Op(Gα), let 
, compute the
final term N:=K in the derived series of K, and return N. To justify this
step, we need to show that either N<G, or N=G and G is simple. So assume
that N=G. Then K=G and, by the lemma above, K/soc(G) is solvable. Since
K=K, K has no nontrivial solvable quotients, so G=K=soc(G), and then G
is simple by Corollary 10.5.
So we may assume that O(Gα)=1; that is, Ga is a TF-group. We observed
in Subsection 10.1.2 that, once we have found the socle factors of a TF-group,
it is straightforward to compute its minimal normal subgroups. So we can
apply our socle factor algorithm recursively to find a minimal normal
subgroup M of Gα.
Again we compute 
. If K≠G, then we can just return K.
Otherwise, by the lemma above, either soc(G)=G or 
.
In any case, we return 
. If this group is also equal to G then, as
before, G=soc(G) is simple.
We shall now summarize the algorithm.
NORMALSUBGROUP(G)
Input: Primitive permutation group G≤Sym(Ω) with O∞(G)=1
Output: N with 
 and N<G unless G is simple
1
Using the algorithm described in Subsection 4.7.6, decide whether G has
a regular normal subgroup N;
If so, then return N;
2
Let α∈Ω; Using the algorithm pCore in Subsection 4.7.4 decide
whether Op(Gα)≠1 for any prime p;
If so, then let 
 and return 
;
3
Now O(Gα)=1; Let M be a minimal normal subgroup of Gα;
4
if 
, then return 
;
5
return 
;
In an implementation, the performance can be improved considerably by
imposing a limit on the degree |Ω| of G and keeping a table of the degrees
that can actually occur in the different cases of the O’Nan-Scott theorem.
For example, the current MAGMA implementation, which works for
permutation degrees up to 107, is described by Cannon and Holt in [CCH97a],
and the current GAP implementation is described in Section 6.2.5 of [Ser03].
By using results of Kantor from [Kan91], a list of the degrees up to 107 that
© 2005 by Chapman & Hall/CRC Press

Advanced Computations in Finite Groups
381
can occur in case (ii) (a) was computed. The smallest degree for which case
(ii)(c) occurs is 606, so this can be ignored and, in cases (ii) (b) and (iii), the
degree must be a power of the order of a finite simple group.
Exercise
1.
Prove Corollary 10.5.
10.2 Computing composition and chief series
In this section, we address the question of how to compute composition
and chief series of a finite permutation group G≤Sym(Ω). We shall assume
that the subgroups L, M, Mi, Sij, K of G that were defined in Subsection
10.1.1 have been computed already, together with their associated
homomorphisms :G→H and :G→Sym(), where H≅G/L is a permutation
group of the same degree as G, and ker()=K.
The groups L, M, and K are characteristic in G, and so the problem reduces
to finding composition or chief series of the sections L, M/L, K/M and G/K
of G. Now 
 is a permutation group of degree ||, which is
always much smaller than ||, so can handle G/K by recursion. As for M/
L, the subgroups Mi and Sij can be used in the obvious way to construct a
chief or composition series, respectively.
The remaining sections L and K/M of G are abelian, so we need to refine
these sections appropriately.
10.2.1 Refining abelian sections
Let A<B be normal subgroups of a permutation group G with B/A abelian.
Refining B/A to elementary abelian sections is straightforward. We just
compute the derived series of B (cf. Subsection 3.3.3) and use this to compute
the descending series.
 .
We can stop when we reach A, and remove any duplicate terms from this
series. We have then refined B/A to a series with abelian sections.
So we may assume that B/A is abelian. Now just choose a prime p dividing
|B/A| and compute C:=ABp, where 
. Then
B/C is elementary abelian and, by repeating this process with B replaced by
C, we can refine B/A to elementary abelian sections.
So now we may assume that B/A is an elementary abelian p-group for
some prime p. For some applications, it is important to observe that, since
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
382
we have been using characteristic subgroups of G during the refinement
process, B and A are still normal subgroups of G, and indeed they are
characteristic subgroups if the original B and A were.
If our aim is to find a composition series of G, then it is now easy to refine
B/A to factors of order p. We simply adjoin generators of B to A one at a time
to produce the subnormal subgroups of G in the refinement. So we end up
with 
, where |B/A|=pd.
If we want a chief series, then we can use the following result to convert
our problem into a problem about  G-modules. The proof is straightforward,
and is left as an exercise.
PROPOSITION 10.7 Let A<B be normal subgroups of a group G, where B/
A is an elementary abelian p-group of order pd for some prime p. Then B/A
can be regarded as a vector space of dimension d over 
, and the action of G
on B/A induced by conjugations makes B/A into an 
 G-module.
Furthermore, if A≤C≤ B, then C/A is an 
 G-submodule of B/A if and only if
.
To make the correspondence between B/A and the associated 
 G-module
explicit, we let 
. We change generators of B to a set containing
generators of A together with the elements x1,…, xd defined above, and define
a homomorphism :B→V from the multiplicative group B to the additive
group V with A=ker(), and (gi) equal to the i-th standard basis vector of V.
To make V into an 
 G-module, we need to compute the d×d matrices
α1,…,αr that define the action of the generators g1,…, gr of G on V. This is
straightforward since, for each gi, the j-th row of αi is given by 
.
Since normal subgroups C/A of B/A correspond to 
 G-submodules of V,
to calculate a refinement of B/A for a chief series of G, we need to find a
composition series
 
of the 
 G-module V, and then the groups 
 for 1≤i<s will be the
required normal subgroups of G in the refinement.
The composition series of the module can be found by repeated use of
the MEATAXE algorithm, as described in Section 7.4. Since the dimension
d of the module is typically rather small when considered as a problem in
module theory, this calculation will generally be very fast and efficient.
10.2.2 Identifying the composition factors
We have now described how to find composition and chief series of each of
the sections L, M/L, K/M and G/K of G, so we have completed our description
of an algorithm to find such series for any finite permutation group G.
© 2005 by Chapman & Hall/CRC Press

Advanced Computations in Finite Groups
383
We have made no use in this algorithm of the classification of finite
simple groups although, as we remarked at the end of Section 10.1, the
MAGMA and GAP implementations use lists of possible permutation degrees,
which do depend upon the classification.
For most of the more advanced applications of these techniques, however,
we want to make use of known properties, often stored in databases, of the
various types of finite simple groups. In order to do this, we must first identify
the isomorphism types of the nonabelian composition factors as abstract finite
simple groups.
The result below makes this problem a great deal easier than one might
have expected! It says that, with the exception of one infinite family of examples
and one isolated example, a finite characteristically simple group is determined
up to isomorphism by its order. This was proved for the classical finite simple
groups by Artin in [Art55] and extended to all finite characteristically simple
groups using the classification of finite simple groups by D.N.Teague (see
Note (ii) at the end of Cameron’s paper [Cam81]).
PROPOSITION 10.8 Let G1 and G2 be finite characteristically simple groups
with |G1|=|G2|. Then one of the following holds:
(i)
, 
, with {i, j}={1, 2};
(ii)
, 
 for some m≥3 and odd q, with
{i, j}={1, 2};
(iii)
G1G2.
The extension from simple to characteristically simple groups is not actually
needed in the methods that we have been describing, because we find the
nonabelian composition factors at the same time as we find the chief factors.
But, in practice, it can be used to speed things up, since in some situations
we find the socle of a primitive TF-group before its direct factors, and it can
be helpful to know the orders of these direct factors in advance.
Exercise
1.
Prove Proposition 10.7.
10.3 Applications of the solvable radical method
The solvable radical method has been used in algorithms for solving the
following problems for a finite group G:
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
384
•
Finding representatives of the conjugacy classes of elements
of G: Cannon and Souvignier [CS97].
•
Finding all normal subgroups of G: Cannon and Souvignier
[CS98].
•
Finding representatives of the conjugacy classes of all subgroups
of G: Cannon, Cox, and Holt [CCH01] (for permutation groups)
and Hulpke [Hul99a] (for PC-groups).
•
Finding representatives of conjugacy classes of maximal
subgroups of G: Cannon and Holt [CH04] and Eick and Hulpke
[EH01a].
•
Computing Aut(G): Cannon and Holt [CH03] (for permutation
groups) and Smith [Smi94] (for PC-groups).
For the first two of these, it is not necessary to identify the isomorphism type
of the TF-group G/L. As we shall see in the next section, the algorithm for
finding representatives of the classes of all subgroups is only designed for
groups in which |G/L| is moderately small (|G/L|<216000 in the current
implementation in MAGMA). We first identify the isomorphism type of G/L,
and then set up an isomorphism between G/L and a standard isomorphic
copy stored in a database, and extract all of the necessary information about
the subgroups of G/L from this database.
The applications for computing maximal subgroups, automorphism groups,
and testing groups for isomorphism are rather more complicated, and are
designed to work with much larger groups G/L. The details of these
applications are beyond the scope of this book but, for the lower dimensional
families of simple groups of Lie type, such as PSL(d, q) for d≤5, we aim to
be able to handle all groups in that family that arise as composition factors
of G/L in a uniform fashion. These applications generalize the corresponding
algorithms for finite solvable groups described in Sections 8.10 and 8.9
respectively, in the sense that their ‘lifting through the elementary layers’
parts are very similar to those for solvable groups.
As we saw above, identifying the isomorphism types of simple groups is
not a problem; the difficult part of the problem is to find an explicit isomorphism
from the given simple group to a standard copy of the group.
Fortunately, there is some prospect of this problem being solved in a
satisfactory fashion for all finite simple groups within the next few years.
This will be as a particular case of the project to identify finite simple groups
given as black-box groups (see Subsection 3.1.4). An advantage is that the
methods will apply equally well to finite groups in representations other
than permutation groups, such as matrix groups over finite fields.
Methods for the black-box recognition of symmetric and alternating groups
are described by Bratus and Pak in [BP00] and for the classical groups by
Kantor and Seress in [KS01]. Certain difficult cases, such as the unitary
groups and exceptional groups of Lie types, are currently being studied in
detail, and improved methods are being developed for them.
© 2005 by Chapman & Hall/CRC Press

Advanced Computations in Finite Groups
385
10.4 Computing the subgroups of a finite group
In this section, as an example of the solvable radical method, we shall
describe, in some detail, an algorithm for computing representatives of the
conjugacy classes of subgroups of a finite group G. This description is taken
mainly from the paper by Cannon, Cox, and Holt [CCH01]. We shall describe
the algorithm for a finite permutation group G. Essentially the identical
method for PC-groups is described by Hulpke in [Hul99a], but of course the
computations in G/L do not arise in the PC-group setting.
As another important ingredient, this application makes use of the
cohomological algorithms described in Section 7.6.
Previously, the only genuinely feasible approach to finding all subgroups
of a group was based on the cyclic extension method. This is one of the oldest
existing group theoretical algorithms, first introduced by Neubüser in [Neu60].
The idea is to start by finding all cyclic subgroups of prime order, which we
regard as forming the first layer in the lattice. The subgroups H in subsequent
layers are formed from those K in the previous layer as 
, where
K  H. Clearly only the solvable subgroups will be found by this method. The
insolvable subgroups can be constructed in a corresponding manner by using
the perfect subgroups as the first layer. For this, a complete stored list of the
isomorphism classes of finite perfect groups up to a given order n is required,
and the subgroup lattice found by this method can only be guaranteed correct
for groups of order up to n. Chapter 6 of Butler’s book [But91] gives a detailed
description of this approach and further references.
The cyclic extension method is fast for most groups of order up to 1000,
and is tolerable for many groups up to order 10000. One major barrier to
extending the range of applicability of the cyclic extension method is the
policy of storing all perfect groups, which becomes impractical with increasing
order. There are 66 isomorphism classes of perfect groups of order up to
10000. These were categorized by Sandlöbes in [San81], and they are stored
in the latest implementations that use this approach. There are a further
163 perfect groups up to order 50 000, but at order 61440, the exact number
becomes unknown. (See Chapter 5 of the book by Holt and Plesken [HP89]
for tables of finite perfect groups.)
In the method to be described here, we start by computing L:=O(G) together
with the homomorphism :G→H, where H is a TF-group isomorphic to G/L.
As described in Subsection 10.2.1, we can then refine L to a series
 
of normal subgroups of G in which each Ni+1/Ni is elementary abelian. It is
not absolutely necessary for the factors Ni+1/Ni to be chief factors of G,
although the algorithm becomes impractical if they are too large (28 is
about the limit for the prime 2, for example), so we may sometimes need to
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
386
use the module-theoretical methods described in Subsection 10.2.1 to further
refine elementary abelian sections.
For TF-groups, we either store representatives of the conjugacy classes
of all subgroups (after computing them once and for all, usually using the
cyclic extension method) or, for larger groups, where this would be expensive
in storage space, we store this information just for the maximal subgroups.
In the latter case, we can find representatives of all classes when required,
by applying the algorithm recursively to the maximal subgroups, and then
testing for conjugacy of the resulting subgroups in G. This information is all
stored in a database of TF-groups.
In the current MAGMA implementation, all subgroups or just the maximal
subgroups are stored for each of the 154 TF-groups of order less than 216
000. For larger groups, more sophisticated methods are now available for
finding maximal subgroups, which can be used in a recursive computation of
all subgroups.
Having found class representatives of subgroups of G/Nr, we lift these
successively through the layers, finding conjugacy class representatives of
subgroups of G/Ni__1 from those of G/Ni.
The cohomological calculations involved in the lifting process require a
finite presentation for each subgroup in the previous layer that is being lifted.
These need to be stored along with the subgroups themselves for the TF-
groups, and we need to be able to compute presentations of the lifted subgroups
of G/Ni__1 from those of G/Ni. The stored presentations of the subgroups of
the TF-groups were computed using Cannon’s algorithm, which was described
in Section 6.1.
In the following two subsections, we shall describe how we identify the
TF-factor G/L and extract its subgroups from the database, and how we find
the subgroups of G/Ni__1 from those of G/Ni.
10.4.1 Identifying the TF-factor
To use the information for the TF-group isomorphic to G/L that is stored
in the database, we first need to identify the isomorphism type of H≅G/L
and then to define an explicit isomorphism between our group H and the
group in the database.
For the isomorphism type, knowledge of the order is sufficient in most
cases. There are a few orders, however, for which there are many distinct
TF-groups. For example, there are 10 of order 120960. We found that the
sum of the orders of the conjugacy classes (see paper by Cannon and Souvignier
[CS97]) was a useful and easily calculated invariant, which successfully
distinguishes between isomorphism types in all cases up to order 216000.
Assuming we have located the correct group X in the database, we now
need to construct an isomorphism :X→H. For a conjugacy class xX of X, let
us call the order |x| of x and the length |xX| of the class the parameters of
© 2005 by Chapman & Hall/CRC Press

Advanced Computations in Finite Groups
387
that class. Each TF-group X in the database is stored as a finitely presented
group, and the parameters of the classes of the generators of X are also
recorded. (In fact, X has just two generators in all cases with |X|<216000
except Sym(5)×PΓL(2, 9), for which three are necessary.) The first generator
x1 of X has always been selected such that there is a unique class of X having
the parameters of 
. This means that (x1) can be chosen as a representative
of the unique class in H having the same parameters as 
.
For the images of the remaining generators xi (i>1) of X, we choose random
members of those conjugacy classes in H that have the same parameters as
, and for each such choice we check to see whether the defining relators of
X are satisfied by the selected images ϕ(xi) in H. If so, then we must also
check that the ϕ(xi) generate H. If this is the case then, by Theorem 2.52,
we have found the required isomorphism ϕ:X→H. The generators xi(i>1)
of X have been selected in such a way as to minimize the expected searching
time for an isomorphism.
For small and moderately large examples, the database contains generators
and defining relators for a representative of each conjugacy class of subgroups
of X. These generators are stored as words in the xi and their inverses, and
we apply the map ϕ to each of these words to give us elements that generate
the corresponding subgroups of H. The inverse images of these subgroups in
G, which are needed as the initial input to the lifting part of the algorithm to
find the subgroups of G, can then be found by using the map :G→H
mentioned above.
For larger examples, space is saved by storing only the representatives of
the conjugacy classes of maximal subgroups Y of X. The main algorithm can
then be applied recursively to the subgroups ϕ(Y) of L. After doing this for
each such Y, we have a collection of subgroups S of H which includes conjugacy
class representatives of all subgroups of H. Some of these may be conjugate
to each other, so we have to test each such subgroup for conjugacy with the
earlier subgroups in the list of the same order.
10.4.2 Lifting subgroups to the next layer
In this subsection, we assume that G is a group with normal subgroups N
and M, such that N<M and M/N is an elementary abelian p-group of order
pd for some prime p and some integer d>0. We assume that conjugacy class
representatives of the subgroups of G/M are known, together with finite
presentations for each of these subgroups on suitable generating sets.
More precisely, for each such subgroup S/M of G/M, we have elements
gi∈G such that 
, together with a set of words in the gi and
their inverses which, taken modulo M, form a set of defining relators for S/
M. These words evaluate in G to elements of M. We shall describe our
algorithm for computing the same information for G/N.
As described in Subsection 10.2.1, we can regard V:=M/N as the d-
dimensional vector space over 
, and 
, then make V into an 
 G-module
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
388
via the conjugation action of G on M. Since M acts trivially on V, we can
equivalently regard V as an 
 G/M-module.
In fact, it is convenient to start by numbering all subgroups of M/N (or,
equivalently, subspaces of V) in some standard fashion, and setting up a
permutation action of G acting by conjugation on these subgroups.
Clearly, if two subgroups T1/N and T2/N of G/N are conjugate in G/N,
then T1M/M and T2M/M are conjugate in G/M. It therefore suffices to take
each class representative S/M of G/M in turn, and to compute class
representatives of those subgroups T/N of G/N for which TM/N=S/M. From
now on, we shall therefore take S/M to be a fixed subgroup of G/M, where
.
Although the computations relate to the quotient group S/M, they are all
carried out using the subgroup S of G, and there is no need to construct the
quotient group explicitly.
We first compute R:=NG(S); so R/M is the normalizer of S/M in G/M.
The idea then is to find all possible intersections J:=TM for subgroups T/
N with TM=S, and then to take each such J in turn, and to find all T that
have that particular intersection. Of course J/N must be normalized by S/
N and, since we are only looking for conjugacy class representatives of
subgroups, we must only consider one such group J from each orbit of the
action of R/M on the S/N-invariant subgroups of M/N.
To find the groups J to be considered, we use the permutation action of G
on the subgroups of M/N computed earlier, and then take our subgroups
J/N to be orbit representatives of the orbits of R on the fixed points of S. So,
from now on, we can fix our attention on a particular subgroup J/N of M/
N normalized by S/N, and we shall look for those subgroups T/N of G/N
such that TM=S and T∩M=J. We denote the stabilizer of J in R (that is,
NR(J)) by Q.
The required subgroups T are precisely the complete inverse images in
G of the complements T/J of M/J in S/J (if any). These are found using
the cohomology calculations described in Subsections 7.6.1 and 7.6.2. Of
course, we must first set up the section W:=M/J as an 
 S/M-module, but
we have already seen how to do that.
In fact, these calculations give us conjugacy class representatives of the
complements under conjugation by M/J. If the subgroups T1/N and T2/N of
G/N resulting from two such representatives T1/J and T2/J are conjugate
in G/N by an element gN, then g must normalize S and J, and so g∈Q. We
therefore need to compute the conjugation action of Q on the set of these
complements.
We experimented with two approaches to this calculation. The first, and
simpler, is to test all such pairs T1 and T2 for conjugacy within the permutation
group Q, by using the standard default backtrack search method. The second
is to use a cohomological calculation.
The chief disadvantage of this second method is that it appears to
necessitate doing calculations within the regular representation of the
© 2005 by Chapman & Hall/CRC Press

Advanced Computations in Finite Groups
389
quotient group S/M, and so we are forced to form this representation
explicitly. (Of course, this is only necessary when Q is strictly larger than
S. If, as often happens, Q=S, then we omit this part of the calculation.)
However, our current experience indicates that this second approach is
superior in general, mainly because the direct conjugacy test occasionally
takes a very long time indeed.
The cohomological method of testing for conjugacy is rather technical,
and the following brief description could be safely omitted by the reader.
We start by finding a set of elements hj of Q such that the elements hjS
generate Q/S. This set should be as small as possible. For each such hj and
each of the generators gk (1≤k≤m) of S modulo M, we need to calculate a
word σjk(gi) in the elements gi and their inverses, such that 
. It is to calculate these words that we need to construct the regular
permutation representation of S/M.
Note that, if we conjugate back again by 
, then we get equations of
the form 
 (1≤k≤m) for elements yjk of M that we can
calculate.
We now take each of our complements T/J in turn. Our aim is to compute
and identify the complement 
 for each hj. The complement T/J is
defined by its corresponding one-cocycle in Z1(S/M, M/J), which consists
essentially of vectors wi∈W:=M/J for 1≤i≤m, such that T/J is generated by
giwi. Since the elements σjk(gi)M (1≤k≤m) generate S modulo M, if we
substitute giwi for gi in the words σjk (gi) for 1≤k≤m, then we obtain another
set of generators for T/J, which have the form σjk (gi)wjk, for certain vectors
wjk∈W that we can calculate.
If we now conjugate this new set of generators by hj
–1, then we obtain
generators for hjThj
–1 modulo J, in the form 
 (1≤k≤m), where 
∈W and, modulo J, 
 and 
. Note that
the vectors 
 are obtained simply by taking the elements yjk defined in
the last subsection modulo J, and do not depend on the particular
complement T/J, whereas the vectors 
 are obtained by applying the
matrix for the action of 
 on W to the vectors wjk.
We now have generators for the conjugated complement 
in the form  
, for vectors 
. Then, as described in Subsection
7.6.1, the vectors 
 can be combined to form a single row
vector in 
, where |W|=pd, and this vector is used in the cohomology
algorithms to represent the element of Z1(T/M, W) corresponding to the
complement T′/J. Hence we can identify the element of H1(T/M, W)
defined by this complement.
These calculations enable us to set up the permutation action, induced
by conjugation, of the group Q/S on the set of conjugacy class represe-
ntatives under M of complements of M/J in S/J. Orbit representatives of
this permutation action provide us with the required conjugacy class
representatives in G of those subgroups T/N of G/N with TM=S and
TM=J.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
390
As the final part of the lifting process, we need to calculate
presentations of the lifted subgroups T/N of S/M. As before, let gi be the
generators of S modulo M. Then the generators of T will consist of giwi
and vj, where wi are elements of M that are computed in the cohomology
calculation, and vj generate J modulo N. (So the vj form a basis of J/N
regarded as a subspace of V=M/N.)
The defining relators of T/N are constructed as specified in Proposition
2.55, where T/N is regarded as an extension of J/N by S/M. They fall into
three classes. The first consist of commutators and p-th powers of the vj, to
force them to generate an elementary abelian subgroup. The second specify
the conjugation action of the gi on the vj; these are routine to calculate. For
the third, we take each defining relator r of S/M and evaluate r in G, using
giwi in place of giM in r. The resulting element lies in J, and so it can be
written (modulo N) as a word v(r) in the generators vj. Then we take rv(r)__1
as the corresponding defining relator of T/N.
Exercise
1.
Use the method described above to compute the conjugacy classes of
subgroups of the symmetric group Sym(4).
10.5 Application - enumerating finite unlabelled
structures
In Subsection 4.8.2, we discussed some techniques for using permutation
groups G to construct examples of combinatorial structures that contain G
in their automorphism groups. Here we shall briefly discuss the more general
problem of counting and enumerating all such structures of a given type. We
shall only have space to scratch the surface of this active and important area
of research. Fortunately, there is an up-to-date book by Adalbert Kerber
[Ker99] to which we can refer the reader for full details.
This area of research has important applications outside of mathematics,
principally to the systematic enumeration of chemical isomers; that is,
chemical compounds with the same formula, such as C3H7OH, but with
different molecular structures. Within mathematics, the techniques have
been used to construct many examples of 7-designs, and even some 8-
designs (t–(n, k, 	) designs were defined in Subsection 4.8.2).
The fundamental result on which much of the theory is based is the
Cauchy-Frobenius lemma, Lemma 2.17. Here is a simple and well-known
example of how it is applied. Consider necklaces, consisting of n coloured
beads spaced at regular intervals around a circular band. A natural question
to ask, is how many different types of necklace can be made using n beads
© 2005 by Chapman & Hall/CRC Press

Advanced Computations in Finite Groups
391
with r possible colours. Two necklaces are the same if one can be
transformed into another by rotating it or turning it over (reflecting it).
We approach the problem as follows. Before considering the effect of
rotations and reflections, we can make rn different necklaces. Let  be a
set containing exactly these rn different necklaces. Now we define an action
of the dihedral group D2n on , which is induced in the obvious way from its
natural action as the symmetry group of a regular n-sided polygon. So, for
example, a rotation  through an angle 2
/n will map a necklace in α∈ to
the necklace obtained by applying  to α. Then the distinct necklaces
correspond exactly to the orbits of D2n on , and we can apply Lemma 2.17
to count the number of such orbits. This calculation still requires some
combinatorial analysis, which we omit. The number is
 
when n is odd and even, respectively, where  is the Euler -function.
Let us now focus on a specific aspect of this topic in which computational
group theory plays a significant rôle. In general, if the group G acts on the
set Ω then, for α∈Ω and g∈G, we have 
 (Exercise 1, Section
2.2). Hence the stabilizers of the points in a particular orbit of G form a
conjugacy class of subgroups of G. In many applications, we wish to know
not only the total number of orbits, but the total number of orbits for which
the point stabilizers lie in some specified conjugacy class of subgroups of G.
This information is related to the size of the orbit, and the automorphism
group of the members of these orbits.
It can be computed as follows. This method was introduced originally by
Burnside. Let the conjugacy classes of subgroups of G be 
 where
 has a representative subgroup Ui≤G and, for 1≤i, j≤d, let (Ui, Uj) denote
the total number of conjugates 
 of Uj for which Ui≤
. Define
mij:=|NG(Uj):Uj|(Ui, Uj). The d×d matrix M(G) with entries mij was called
the table of marks of G by Burnside. Note that its entries are nonnegative
integers. It has also been called the super character table of G.
For an action of G on Ω and a subgroup H≤G, define
. 
Let vO be the d×1 column vector in which the i-th component is the number
of orbits of G with stabilizers in 
, and let vF be the d×1 column vector in
which the i-th component is |ΩUi|. Then Burnside’s lemma, which is proved
in detail Section 4.1 of [Ker99], states that M(G).vO=vF, so vO can be computed
as M(G)-1.vF.
To compute the table of marks, we first need to find the conjugacy classes
of subgroups of G, which was the topic of Section 10.4.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
392
Computations with characters of the symmetric group is another area
of CGT that is important in this topic. We should also mention here some
specialized computer algebra packages that are available.
•
SYMMETRICA is devoted to the representation theory and
combinatorics of finite symmetric groups.
•
DISCRETA is for constructing t–(n, k, 	) designs with prescribed
automorphism group.
•
MOLGEN is for computing structural formulae of chemicals.
Exercise
1.
Prove the formula displayed above for the number of necklaces that can
be made with n beads of r possible colours. If this is too difficult, try it
first when the n is prime.
© 2005 by Chapman & Hall/CRC Press

Chapter 11
Libraries and Databases
The classification of groups with the aid of computers and the electronic
publication of the resulting libraries and databases form an important
part of computational group t heory. ‘Classification’ of groups here
means that the groups with certain properties or parameters are
determined up to conjugacy or isomorphism. The algorithms used for
these purposes frequently use a large part of the available machinery
from CGT.
In this chapter, we shall discuss four such databases in some detail,
which currently contain:
• all primitive permutation groups up to degree 1000;
• all transitive permutation groups up degree 30;
• all perfect groups of order up to 106, but with seven missing orders;
• all finite groups up to order 2000, excluding the order 1024, but
including the 408641 062 groups of order 1536.
In the final section of this chapter, we shall briefly describe and discuss the
vast quantity of data that has been collected together or computed by the
authors of the “ATLAS of Finite Groups” [CCN+85] and in its sequel, “An
Atlas of Brauer Characters” [JLPW95].
The four databases listed above, and also much of the data printed in the
“ATLAS” volumes, are available from both GAP and MAGMA. As one would
expect from databases, some facilities are also provided to help the user
search for groups in the lists with specified properties, and to locate the
isomorphic or conjugate copy in the library of a corresponding user-supplied
group.
Among the resources that have been provided by the CGT community
in recent years, these databases, particularly the list of small groups,
probably constitute the facility that is most frequently used by the general
mathematical and scientific community. Of course, it is difficult to know
exactly how often and by whom they are used, given that many such
applications remain unrecorded. The lists are almost certain to be extended
in the future; for example, work is already in progress to find the primitive
permutation groups up to degree 2500.
The history of group classifications is long, and many publications in
this area have mistakes. Of course, the earlier classifications and list
© 2005 by Chapman & Hall/CRC Press
393

Handbook of Computational Group Theory
394
compilations, many of which date back to the late 19th century, were
undertaken by hand rather than by machine. We refer the reader to the
extensive bibliography compiled by Short in [Sho92, Appendix A] for more
details on the history of primitive and transitive group classification, and
to the article by Besche, Eick, and O’Brien [BEO02] for a history of
classifications of groups of small order.
11.1 Primitive permutation groups
The primary aim in the classification of primitive groups is to determine a
complete and irredundant list of conjugacy class representatives for the
primitive subgroups of Sym(n) for a given degree n. The generally used
approach towards this aim is based on the O’Nan-Scott theorem, which we
stated earlier as Theorem 10.4. This theorem divides the primitive
permutation groups into two classes: the affine (case (i) of Theorem 10.4)
and the nonaffine groups (cases (ii) and (iii) of Theorem 10.4). This is the
primary invariant used to classify the primitive permutation groups of a
given degree; see Sections 11.1.1 and 11.1.2.
Currently, the primitive permutation groups of degree less than 1000
and the solvable primitive permutation groups of degree less than 6561
have been classified. We shall give a very brief overview of the history of
the determination of primitive groups in the following. We refer the reader
to [Sho92] for details.
In [Sim70], a list of all primitive permutation groups up to degree 20 is
published and Sims also circulated a correct list of groups up to degree 50.
The solvable primitive permutation groups of degree less than 256 were
listed in [Sho92], with two omissions. This list has been corrected and
extended to the solvable primitive permutations groups of degree less than
6561 in [EH03]. The solvable primitive permutation groups are affine and
an overview of a method to determine these groups is included in Section
11.1.1.
There is a description of examples in [DM88] and also in Appendix B
of [DM96] with one or two omissions, and without detailed classification
of affine examples with EARNS. This uses O’Nan-Scott and the
classification of finite simple groups. A list in electronic form was
described by Theissen in [The97] and made for GAP. This includes the
examples from Dixon and Mortimer’s list, and the affine examples of
degree less than 256.
The remaining affine groups of degrees 256, 625, and 729 were classified
by Roney-Dougal and Unger in [RDU03], who also rechecked the entire list
of primitive permutation groups of degree less than 1000.
© 2005 by Chapman & Hall/CRC Press

Libraries and Databases
395
11.1.1 Affine primitive permutation groups
First, we recall the definition and some elementary results on the affine
primitive groups.
DEFINITION 11.1 Let G be a primitive permutation group and let S be its
socle. If S is solvable, then G is called an affine primitive group.
The following theorem is folklore for the affine primitive groups. See the
paper by Liebeck, Praeger, and Saxl [LPS88] for background.
THEOREM 11.2 Let G be an affine primitive permutation group with socle
S and degree n.
a) n is a prime power; that is, n=pm for some prime p and m∈.
b) S is an elementary abelian p-group of order pm.
c) The point stabilizer K=G1 is a complement to S in G.
d) The conjugation action of K on S induces an embedding K→GL(m, p)
with irreducible image.
Theorem 11.2 d) implies that every affine primitive permutation group of
degree pm yields an irreducible subgroup of the matrix group GL(m, p).
Conversely, every irreducible subgroup of GL(m, p) determines an affine
primitive permutation group in this form and the conjugacy classes of affine
primitive subgroups in Sym(pm) correspond one-to-one to the conjugacy
classes of irreducible subgroups of GL(m, p). Hence the classification of the
affine primitive permutation groups translates into the classification of the
irreducible subgroups of GL(m, p).
An approach to classifying the irreducible subgroups of GL(m, p) is
provided by Aschbacher’s theorem [Asc84]; see Subsection 7.8.2 for a
statement of the theorem. In particular, an irreducible subgroup G of
GL(m, p) falls into one of the classes (2) to (9) of Aschbacher’s theorem.
The primary approach for constructing all irreducible subgroups of GL(m,
p) is to determine the conjugacy classes of maximal subgroups for each
of the classes (2) to (9). Then each conjugacy class representative is
considered in turn and its conjugacy classes of subgroups are determined
recursively.
This approach lists each conjugacy class representative of the irreducible
subgroups of GL(m, p) at least once. But, since the classes in Aschbacher’s
theorem are not disjoint, it may happen that an irreducible subgroup of
GL(m, p) lies in several of these classes and is therefore constructed several
times.
Hence it remains to reduce the constructed list of subgroups to conjugacy
class representatives. For this purpose we need an effective conjugacy
test for subgroups in GL(m, p). Clearly one can consider GL(m, p) as a
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
396
permutation group on pm-1 points and then use a backtrack approach to
check conjugacy; see Section 4.6. However, this approach has turned out to
be practical for small prime powers pm only. For larger pm there are two
methods available for the conjugacy class test: we refer to the papers by
Eick and Höfling [EH03] and by Roney-Dougal [RD04] for details.
11.1.2 Nonaffine primitive permutation groups
As mentioned earlier, the nonaffine primitive permutation groups of degree
less than 1000 were determined and listed by hand by Dixon and Mortimer
in [DM88]; their list is also available as Appendix B of [DM96]. A few errors
were later discovered by various people, and the results described in [RDU03]
are now generally believed to be correct. (Or rather, almost correct! It has
very recently been discovered that PSL(2, 41) in a primitive representation
of degree 574 on the cosets of a maximal subgroup isomorphic to Alt(5) was
omitted from the table of the total numbers of primitive groups.)
Dixon and Mortimer used the classification of finite simple groups, the
known structure of the automorphism groups of the finite simple groups,
the O’Nan-Scott theorem, and information about the maximal subgroups
of almost simple groups, which was available principally from results of
Cooperstein, Kantor, and Liebeck. In fact nearly all of the information
they needed could be found in the “ATLAS” [CCN
+85].
They proceeded by considering all possible socles, which are direct
products of isomorphic finite simple groups, and collecting together the
groups with a common socle into cohorts. Most, but by no means all, of the
examples have simple socle; this is because other types of examples that
occur in Theorem 10.4 tend to have larger degrees. For this case, one just
needs to know the finite almost simple groups G that have maximal
subgroups H of index less than 1000, and a knowledge of which of the
automorphisms of G fix the conjugacy class of H in G. It is important to be
aware of the fact that 
  is not necessarily a maximal subgroup of
soc(G). Such intersections are listed in the “ATLAS”, and called novelties.
We refer the reader to [DM88] for further details.
Exercises
1.
Prove Theorem 11.2.
2.
Find examples of almost simple groups G having a maximal subgroup
H for which H  soc(G)for which is a proper nonmaximal subgroup of
soc(G).
3.
Let G be a primitive subgroup of Sym(n) for some n with G almost
simple, let S=soc(G), and let N be the normalizer in Sym(n) of G. Prove
that N is isomorphic to a subgroup of the normalizer in Aut(S) of G,
© 2005 by Chapman & Hall/CRC Press

Libraries and Databases
397
and that an element α in NAut(S)(G) lies in N if and only if H
α is conjugate
in N to H, where H:=G1 is a point stabilizer.
11.2 Transitive permutation groups
Many attempts to classify transitive groups of small degree (up to 15) were
carried out in the late 19th and early 20th centuries. See [Sho92] for details
and references. More recently, with assistance from computers, transitive
groups up to degree 11 were listed by Butler and McKay [BM83], degree 12
by Royle [Roy87], and degrees 14 and 15 by Butler [But93]. Finally, transitive
groups of degree less than 32 were listed in [Hul96] by Hulpke. These are
available as libraries in GAP and MAGMA up to degree 30.
There is general confidence that the latest lists are correct, because
they have been checked using a variety of different methods. To give the
reader an idea of the number of classes of groups involved, the largest
number is in degree 24, with (exactly) 25000 groups, and then there are
5712, 2392, 1954, 1854, 1117, and 983 groups of degrees 30, 27, 16, 28, 20,
and 18, respectively.
11.2.1 Summary of the method
Here, we shall summarize the method of classification described in full
detail by Hulpke in [Hul96] or [Hul]. The aim is to list all transitive
permutation groups of a given degree n up to conjugation in Sym(n). As
was observed in Subsection 4.6.5, testing subgroups of Sym(n) for conjugacy
is one of the most difficult computations to perform efficiently, and so it is
essential to avoid having to do this wherever possible. Fortunately, the
methods to be summarized below can be carried out without resort to
direct conjugacy testing except in a few exceptional cases.
Since primitive groups are listed up to much higher degrees, we can
assume that these are known, so we need to find the transitive imprimitive
groups. We can also assume that the transitive groups of degree less than
n are known.
We consider each nontrivial factorization n=lm of n in turn, and list
those groups for which the smallest block of imprimitivity has size l. Let G
be such a group, let B be a block of imprimitivity of size l in a block system
 of size m with 1∈B, let U=G1 and V=GB. Then, by minimality of B, VB is
primitive and so, by Proposition 2.30, U is a maximal subgroup of V. Let
 be the induced action of G on 
 and let
M:=ker(ϕ).
Now we split into two cases, M=1 and M1. The case M=1 is easier,
and the associated imprimitive groups are called inflations of the
isomorphic transitive groups G . We take each transitive group G of degree
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
398
m in turn and then find the maximal subgroups U of its point stabilizer V.
The image of the action of G on the right cosets of U is a (necessarily
faithful) inflation of G of degree n. It can be proved that two such inflations
for the same G are conjugate in Sym(n) if and only if the two corresponding
maximal subgroups U1 and U2 of V are in the same orbit under the action
of Aut(G). This means that Aut(G) needs to be computed. For this, the
methods of Section 8.9 were used for solvable G and of Subsection 9.1.3
for nonsolvable G.
So suppose that M≠1. Clearly M≤V. Since VB is primitive, MB is transitive
by Proposition 2.29, and the maximality of U in V implies that V=MU. Also
the transitivity of GB implies that the group actions are equivalent for all
blocks Bi ∈. Finally, G≤ NSym(n)(M) implies that Nsym(n)(M) is transitive.
The first and most time-consuming part of the classification procedure
in this case is to list all possible groups M≤Sym(n) that have all of the
properties listed in the preceding paragraph. That is, they have m orbits,
B1,…,Bm each of length l, the actions MBi are all permutation equivalent,
and NSym(n)(M) is transitive. The theory of how this is achieved is technical,
and involves the theory of subdirect products. We shall not give any further
details here, except to observe that we only need to consider those transitive
groups H of degree l for which NSym(l) (H) is primitive as candidates for 
 .
Now we process each individual candidate group M in turn. First, we
compute N:=NSym(n)(M), which is transitive by assumption. Furthermore, by
Proposition 4.9, N permutes the set  of orbits of M, and so  is a system of
imprimitivity for N of the required type. As before, we let 
 be the induced action on , and compute R:=ϕ(N) and
K:=ker(ϕ). So R is transitive.
For each group G that we are seeking, ϕ(G) is a transitive subgroup of
R, so the next step is to compute representatives T of the conjugacy classes
of transitive subgroups of R, and consider each of these in turn as candidates
for ϕ(G). This is potentially a difficult computation, but it turns out that,
most of the time, R is either small enough for it to create no difficulties, or
R is a subgroup of low index in either Sym(m) or a wreath product
 with m=rs (see Subsection 2.2.5). If |Sym(m):R| is small,
then we can use the already available list of transitive subgroups of Sym(m),
and efficient methods can also be developed to handle the wreath product
case.
For each candidate group T, we compute the inverse image S:=ϕ-1(T) of
T in N, so we are looking for G≤S with ϕ(G)=ϕ(S). Since, by assumption,
, this means that G/M is a complement of K/M in S/M
and, conversely, all such complements satisfy the required conditions for
G. So we need to find representatives of these complements up to conjugation
in NN(S). This is a cohomological calculation, and can be carried out in a
similar way to the computations of complements described in Subsection
10.4.2 in connection with finding the subgroups of a finite group.
The final problem in the classification of transitive groups of degree n
arises from the fact that such a group G can have more than one block system
© 2005 by Chapman & Hall/CRC Press

Libraries and Databases
399
of minimal size, in which case it will be found several times, once for each
such block system. To eliminate such repetitions, all block systems with
blocks of size l are computed for each G, and considerable effort is devoted to
ordering these block systems in such a way that there is a unique ‘minimal’
block system under this ordering; in that case G is kept on the list if and only
if the block system for which it arose is the minimal one. There were, however,
a few cases in which no such unique canonical system could be defined, and it
was occasionally necessary to resort to direct conjugacy tests in Sym(n) to
decide equivalence of some of the groups G.
11.2.2 Applications
The most important application of the lists of transitive groups is to the
calculation of Galois groups Gal( ) of irreducible polynomials  over the
rationals. The most effective practical methods in current use require a
complete list of such subgroups of degree equal to deg( ); so, at the present
time, they can only be applied when deg( )≤31.
We can assume that 
 with  monic. Let n:=deg(f). We consider
Gal( ) as a subgroup of Sym(n) in its action on the n roots α1,…, αn of . We
have an action of Sym(n) on the polynomial ring 
 where
permutations act by permuting the variables xi; i.e. 
 for ∈Sym(n).
Very roughly, for each transitive group G of degree n, we need to find a
polynomial in n variables x1,…,xn which is invariant under all g∈G, but not
under all elements of any overgroup of G in Sym(n). For example,
 
is invariant under ∈Alt(n) but not under ∈Sym(n)\Alt(n).
By computing complex approximations of the roots αi, we can decide
whether this polynomial evaluated with αi in place of xi yields a result in .
If so then, under certain additional hypotheses, we can conclude that
Gal( )≤G. So, for example, we have Gal(f)≤Alt(n) if and only if the discriminant
 
is a square in .
The algorithm proceeds by working downwards through a descending
chain of subgroups of Sym(n) and halts when we find a subgroup G with
Gal(f)≤G but 
 for all maximal subgroup H of G. So, in addition to
the list of transitive groups of the given degree n, we require information
on containment between the subgroups on the list, which is not completely
straightforward because the list only contains subgroups up to conjugacy
in Sym(n).
The above description is unfortunately too brief and approximate to be
of much use to readers who are seriously interested! A detailed treatment
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
400
of degrees n≤7 can be found in [Coh73, Section 6.3]. Another useful reference
for practical computations of Galois groups is the article by Soicher and
McKay [SM85]. In [Hul99b], Hulpke introduces some new ideas in Galois
group computation, which aim to avoid the necessity of a complete list of
transitive subgroups of Sym(n).
The lists of transitive groups of degree n have also been used by Royle
and others in [RP89] and [RM90] for enumerating graphs of degree n with
transitive automorphism group. The enumerations proceed essentially by
considering all candidates for this automorphism group.
11.3 Perfect groups
We recall from Definition 2.36 that a nontrivial group is said to be perfect if
it is equal to its own derived subgroup. A list of representatives of the
isomorphism classes of finite perfect groups of order at most 10000 was
compiled by Sandlöbes, and published in [San81]. This list was recomputed
and extended up to the order 1000000 by Holt and Plesken in [HP89], but
there are seven orders for which their list is incomplete, the smallest of
these being 210.60 = 61440. Their list agrees with that of Sandlöbes up to
order 10000.
The perfect groups in the library are stored by means of finite
presentations. This provides a compact method of storage, but is not the
most useful for subsequent computations with the groups. The library
therefore contains information that enables the user to construct faithful
permutation representations of the groups.
In most cases, this information consists of generators for a core-free
subgroup of reasonably small index, from which a permutation
representation can be found by coset enumeration. For some examples,
however, there are faithful intransitive permutation representations of
significantly smaller degree than the smallest-degree transitive
representation; in these cases, generators for the point-stabilizers of each
orbit in these intransitive representations are stored.
If a finite group G has M:=Op(G)1 and N:=Oq(G)≠1 for two distinct primes
p, q, then G is a subdirect product of G/M and G/N (see Exercise 1 below).
From a knowledge of G/M, G/N, and Aut(G/MN), it is straightforward to
reconstruct the possible groups G. In general, there could be more than one
isomorphism class of such groups, although this does not happen with perfect
groups of order up to a million. It therefore suffices to find the perfect groups
in which Op(G)≠1 for at most one prime p.
The first step is to write down all of the perfect groups up to the
required order n for which Op(G)=1 for all primes p; that is, the perfect
groups with trivial solvable radical. From the known list of simple
groups, it is easy to show that the smallest such group that is not a
direct product of finite nonabelian simple groups has order 606, which is
© 2005 by Chapman & Hall/CRC Press

Libraries and Databases
401
considerably larger than the orders with which we are concerned. So,
this step is straightforward.
We now, recursively, take each perfect group F in turn and, for each
prime p with p|F|≤ n and OP(F)=1, we construct those perfect groups G for
which 
. For such a group G, the terms in the lower central
series of Op(G) are characteristic in Op(G) and hence normal in G. It follows
that the chief factors M/N of G for which N<M≤Op(G) are all centralized
under the induced action of Op(G), and so they can be regarded as 
F-
modules, where the module action is induced by conjugation in G.
So we can find the groups G as follows. First, we use the methods of
Subsection 7.5.5 to find all irreducible 
 F-modules for which the dimension
d satisfies |F|pd≤n. We then initialize the list of groups G to [F] and
recursively consider each group G in the list in turn. Then, for each
irreducible 
F-module M of dimension d for which |G|pd≤n, we regard M
as an 
G-module in which Op(G) acts trivially, and compute the second
cohomology group H2(G, M). The corresponding extensions provide us with
a complete list of extensions of M by G up to equivalence of extensions. We
use the action of the compatible pairs in Aut(G)×Aut(M) on H2(G, M), as
discussed in Section 8.9 in the context of soluble groups, to refine this to a
collection of extensions that are mutually nonisomorphic as groups. These
can be added to the list of groups G with 
, provided that they
are not isomorphic to any group that is already on the list.
In fact, we know that each isomorphism type of group G will arise once
for each of its minimal normal subgroups contained in Op(G), and in practice
we can use this fact to avoid getting repetitions in the list. We do not need
to resort to explicit isomorphism testing between groups.
The principal difficulty that we encountered in carrying out the above
program was that, in order to use the author’s cohomology programs to
compute H2(G, M), we needed to find a reasonably small-degree permutation
representation of the groups G. Unfortunately, the extensions computed
by the cohomology programs are output as presentations, and so these
permutation representations needed to be found individually for each group.
Although this was done with the aid of a coset enumeration program, it
required human expertise to find the appropriate subgroups for the coset
enumerations.
For two of the classes of extensions, namely F=Alt(5) and F=PSL(3, 2),
both with p=2, there were simply too many groups arising for it to be
practical to complete the lists up to order a million. The lists were
successfully computed up to a million for all other classes.
In fact, as the orders grow larger, finding extensions of p-groups by a
relatively small perfect group like Alt(5) starts to acquire similar
characteristics to finding all p-groups. As we saw in Subsection 9.4.4, finding
all p-groups can be undertaken completely mechanically, using the p-group
generation program, and it might be possible to generalize these methods so
that they can be applied to extensions of p-groups by a small fixed finite
group.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
402
Exercises
1.
A subdirect product of two groups is defined to be a subgroup of their
direct product that projects surjectively onto both factors. Show that, if
G is a group with normal subgroups M and N with 
 , then G
is isomorphic to a subdirect product of G/N and G/M.
Find an example of two nonisomorphic groups Gi with normal
nonintersecting subgroups Mi and Ni (i=1, 2), such that 
and 
. (Hint: There is an example of order 273.)
2.
Show that the smallest degree of a faithful permutation representation
of the group 
 is 24.
3.
Show that the group defined by the presentation
 
which is perfect of order 1920 and is a split extension of an irreducible
module of order 16 by SL(2, 5), has a faithful intransitive permutation
representation of degree 40.
11.4 The small groups library
The small groups library, which was compiled principally by Besche, Eick,
and O’Brien, provides a classification of all groups of certain ‘small’ orders.
The groups in this library are listed up to isomorphism; that is, for each of
the available orders a complete and irredundant list of isomorphism type
representatives of the groups is given. At the present time, the library
contains all groups of orders:
• at most 2000 except 1024 (423 164 062 groups);
• pn where p is an odd prime and n≤6;
• pnq where pn divides 28, 36, 55 or 74, and p≠q are primes;
• orders that factorize into at most 3 primes.
The first of these covers an explicit range of orders. The last three provide
access to infinite families of groups having orders of certain types; see
[BE01, NOVL04] for background. In this section we shall discuss the
algorithmic methods that were used to determine the groups of order at
most 2000 except 1024; see also the papers by O’Brien, Besche, and Eick:
[O’B89, BE99b] for first partial results, [BEO01] for an overview, and [BEO02]
for more details.
© 2005 by Chapman & Hall/CRC Press

Libraries and Databases
403
The vast majority of groups of order up to 2000 are solvable, and are
stored in the library by means of polycyclic presentations. In fact, given
the very large number of groups involved, it was necessary to store them
in a highly compressed format. The insolvable groups are stored as
permutation groups.
We shall outline an algorithm to determine up to isomorphism the groups
of order n for some given n. As a first step, we split the groups of order n
into three natural classes: the nilpotent groups, the solvable nonnilpotent
groups, and the nonsolvable groups.
We saw in Theorem 2.38 that a finite group is nilpotent if and only if it is
the direct product of p-groups for primes p. Thus the construction of the
nilpotent groups is based on the determination up to isomorphism of the
pgroups of order pe. In turn, the p-groups of order pe can be constructed by
the p-group generation algorithm; see Subsection 9.4.4.
Effective methods to construct up to isomorphism the solvable
nonnilpotent groups of a given order n were introduced by Besche and Eick
[BE99a, BE01]. There are two different methods involved: the Frattini
extension method and the coprime split extension method. We shall give
an outline of the Frattini extension method below. This method is the
more general of the two algorithms, as it applies to all possible orders,
while the coprime split extension method applies to orders of the type pnq
only, but is more efficient for this particular type of order.
It remains to discuss the construction up to isomorphism of the
nonsolvable groups of a given order n. We refer to [BE99a] for an outline
and to the thesis of Archer [Arc02] for a more efficient approach to this
problem.
If G is a nonsolvable group of order n, and we put N:=G[∞], the last term
in the derived series of G as defined in Subsection 2.3.3, then N is perfect
and H:=G/N is solvable. We use the list of nontrivial perfect groups of
order m dividing n as described in Section 11.3 above, and the list of solvable
groups of order n/m as constructed with the methods described in this
section, to determine the candidates for N and H. Then, given a perfect
group N of order m and a solvable group H of order n/m, our aim is to
determine up to isomorphism the groups G that are extensions of N by H.
Since H is solvable, it has a subnormal series in which the factors are
cyclic of prime order. This enables the problem to be reduced to the so-
called cyclic extension problem: given a finite group N and a prime p
,
determine up to isomorphism all groups G having a normal subgroup N
with |G/N|=p.
To solve this, we first need to determine Aut(N) (see Section 9.1 or 10.3).
Then we find all pairs (α, n) such that α ∈ Aut(N), n ∈ N, and αp is equal to
the inner automorphism of N defined by conjugation by n. It can be proved
that, for any such pair, there is a cyclic extension G of N with |G/N|=p in
which  G=〈N, α〉 and αp=n, and that all such extensions arise in this fashion.
Finally, we need to determine which of the cyclic extensions constructed
in this fashion are isomorphic to each other. As with other enumeration
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
404
problems, this is the lengthiest part of the computation. It can be done using
the general-purpose isomorphism tests discussed in Section 9.1 or 10.3, but
there are various methods that can be used to reduce the number of such
tests that are necessary in this particular situation; we omit the details.
11.4.1 The Frattini extension method
The Frattini extension method can be used to determine all or certain solvable
groups of a given order n. First, we recall from Subsection 2.3.6 that the
Frattini subgroup Φ(G) is the intersection of all maximal subgroups of the
finite group G. Further, a group H is called a Frattini extension of G if there
exists 
 with N ≤ Φ(H) such that 
 Thus each group G is a
Frattini extension of its Frattini factor G/Φ(G).
We use the following general approach to construct groups of order n:
(1) Determine up to isomorphism candidates F for the Frattini factors of
the groups of order n.
(2) For each candidate F:
(a)
Compute the Frattini extensions of order n of F.
(b)
Reduce the resulting list of extensions to isomorphism type
representatives.
For any finite group G, if 
 and N≤Φ(G), then Φ(G/N)=Φ(G)/N (exercise),
and in particular Φ(G/Φ(G)) is trivial. So a candidate F for a Frattini factor
will always have a trivial Frattini subgroup. Hence the Frattini extensions
computed in 2 (a) will have F as their Frattini factor.
It follows from the following theorem that the solvability or nilpotence
of a group G can be read off from its Frattini factor (see exercise below for
proof). Hence the above outline can easily be modified to determine the
solvable or the solvable nonnilpotent groups of a given order n only.
THEOREM 11.3 Let G be a finite group. Then:
a) G is solvable if and only if G/Φ(G) is solvable;
b) G is nilpotent if and only if G/Φ(G) is abelian.
In the following we discuss the steps of the above approach in more detail.
Step (1): Finding the candidates for the solvable Frattini factors F relies on
the work of Gaschütz [Gas53]. Let G be a solvable group of order n and
F:=G/Φ(G). Then |F| divides n and each prime divisor of n divides |F|.
Further, the socle soc(F) is a direct product of elementary abelian groups
and has a complement K in F. The socle complement K acts faithfully on
soc(F) and each Sylow p-subgroup of soc(F) is a semisimple 
 K-module.
© 2005 by Chapman & Hall/CRC Press

Libraries and Databases
405
We determine candidates for the Frattini factors F of the desired solvable
groups by considering all direct products of elementary abelian groups of
order dividing n as possible socles S for F. We then construct up to conjugacy
all subgroups K of Aut(S) that have suitable order and act semisimply on S.
Finally, we obtain the desired candidates F as 
 This yields a very
effective solution for Step (1).
Step (2a): We compute the Frattini extensions of a candidate F using a
recursive approach. Let H be a Frattini extension of F, where |H| divides
n. Then every Frattini extension of H is also a Frattini extension of F. Let
p be a prime dividing n/|H|. Then we compute the irreducible Fp H-modules
M up to equivalence; see Plesken’s paper [Ple87] for an effective algorithm.
For each module M we calculate H2(H, M) as described in Section 8.7.2.
Since M is irreducible, the nontrivial elements of H2(H, M) correspond one-
to-one with the equivalence classes of Frattini extensions of H by M.
This approach yields every Frattini extension of F of order n at least
once. However, the iterated computation of equivalence classes of
extensions usually produces redundancy, since equivalence of extensions
is weaker than group isomorphism. We use the action of the compatible
pairs in Aut(H)×Aut(M) on H2(H, M) as discussed in Section 8.9 to eliminate
some of this redundancy.
Step (2b): We reduce the list of groups computed by the above steps to
representatives of distinct isomorphism types. One could use a general-purpose
isomorphism test at this stage; for example, the automorphism group method
of Section 8.9 can be modified to an isomorphism test for two solvable groups.
However, in this particular setting it turned out that such an approach would
not be efficient enough for the desired applications. We shall now introduce a
more effective method, designed for this particular application only.
11.4.2 A random isomorphism test
Suppose that a list G1,…, Gr of groups of order n is given and we want to
determine a subset of this list such that every group Gi in the list is isomorphic
to exactly one of the groups in the subset. In the application to the
determination of groups of small order, the number of groups r is often
large, say several thousand, and their order n is small, say at most 2000.
Also, there are typically only relatively few different isomorphism types
contained in the list G1, ..., Gr. Our approach for this purpose uses two steps:
(1) ‘Fingerprinting’: For every group G1,…, Gr evaluate various
isomorphism-invariant properties. Split the list up into several sublists
such that every sublist contains the groups with certain properties
only.
(2) ‘Random reduction’: Take one of the sublists of (1) and search randomly
for isomorphisms between the groups in the list. Whenever an
isomorphism is found, discard one of the isomorphic copies from the list.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
406
The hope is that the fingerprinting in Step (1) splits the given list up into
sublists that contain few (hopefully just one) isomorphisms types only;
that is, Step (1) should get close to finding all isomorphism types. The
invariants need to be chosen suitably for this purpose. Step (2) is then a
verification of the result of Step (1) and the hope is that in Step (2) almost
all groups are discarded from the given list. If Step (2) reduces a given list
to a list of length one, then an isomorphism type representative has been
obtained.
Step (1): For this step it is most important to find isomorphism-invariant
properties of groups that can be evaluated extremely fast in a small group.
The invariants used in the construction of the small groups library are
based on unions of certain conjugacy classes and power maps. For a more
detailed description we refer to [BE99a].
Step (2): This step is the time-critical step in our algorithm. We include
a brief and simplified outline here only; the actual implementation of
this algorithm is technical and incorporates many heuristic
optimizations, so it would go beyond the scope of this book to describe it
in detail.
As a precomputation, we determine for each group in the given list a
collection of minimal generating sets. These collections of minimal
generating sets are chosen in such a form that if two groups G and H in
the list are isomorphic, then G and H both have a minimal generating set
XG and XH in the collection such that XG maps onto XH under an
isomorphism. Also, the collections should be as short as possible with
this property.
Then, we iterated over the given list of groups. In each pass through the
loop we select randomly one of the minimal generating sets for each of the
groups. The chosen minimal generating set is then enlarged to a polycyclic
sequence. As observed in Section 8.1, such a polycyclic sequence defines a
unique polycyclic presentation and we encode the relations of this polycyclic
presentation as a single integer and store this code with the group.
Whenever a new code is determined, then we compare the new code with
all known codes. There are two interesting cases:
(1) The new code has already been determined for a different group in the
list. Then these two groups have the same polycyclic presentation and
hence they are isomorphic. We discard one of the groups and add its
codes to the stored codes of the other group.
(2) The new code has already been determined for the same group. Then
the group has two minimal generating sets that define the same
presentation. Thus we obtain an automorphism of the considered group.
We store this automorphism.
We run this loop until either only one group remains or a known code
has been determined for every group in the remaining list at least l
times for a given value of l. At this stage we use the counting argument
© 2005 by Chapman & Hall/CRC Press

Libraries and Databases
407
based on the automorphism groups of the considered groups as described
in [BE01], 5.3, and thus split the remaining list up further. Finally, if
lists of length greater than one still remain, then we compute more
expensive invariants or we try to prove isomorphisms between the groups
using a deterministic isomorphism test for finite solvable groups; see
Section 8.9.
We conclude the section with a few final remarks on the method. First,
we note that the parameter l controls the probability of finding all possible
isomorphisms in the given list. If l=0, then no isomorphism is found. If l
tends to infinity, then all isomorphisms are found. For a more detailed
analysis of the probabilistic nature of the method we refer to [BE01].
Secondly, we note that the random reduction algorithm performs well when
many of the groups in the given list are isomorphic, since in this case the
limit l has to be reached for only a few groups. Thus the preceding
computation of invariants in Step (1) is important for the performance of
the method. Also, it is critical for the performance of this algorithm that
the groups are constructed as Frattini extensions, since this ensures that
minimal generating sets are exhibited.
Exercises
1.
Let N be a finite group, p ∈  and (α, n)∈(Aut(N), N) such that αp is the
inner automorphism of N induced by n. Show that there is a cyclic
extension G of N with |G/N|=p in which 
 and αp=n.
2.
For any finite group G, verify that, if 
 and N≤Φ(G), then
Φ(G/N)=Φ(G)/N.
3.
Prove Theorem 11.3. (Hint: For part a), use the Frattini lemma
(Proposition 2.21) to show that, if M/N is a nonsolvable chief factor of
G, then 
. For part b), use Theorem 2.38.)
11.5 Crystallographic groups
Crystallographic groups are the symmetry groups of crystals. They are
used in the study of crystals in chemistry and physics. Classifications
and enumerations of these groups are particularly interesting in this
context.
The basic theory of crystallographic groups was introduced in Section
8.2.3. They can be defined as the subgroups G of the group of all Euclidean
motions of d-dimensional space 
 such that the set of translations T in G
is a discrete normal subgroup of G of finite index. Thus the translations T
form a free abelian normal subgroup in a crystallographic group G. The
corresponding factor group G/T is called the point group of G.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
408
We call a crystallographic group G a space group if the rank of its
translation subgroup T is maximal; that is, if rank(T)=d. The parameter d
is also known as the dimension of a space group G. The following theorem
analyzes the structure of a space group.
THEOREM 11.4
a) A group G is a space group if and only if there exists a free abelian
normal subgroup T in G with G/T finite and CG(T)=T.
b) If G is a space group of dimension d, then its point group G/T embeds
into GL(d, ).
c) If G is a space group of dimension d, then G embeds as an affine group
into GL(d+1, ).
By Bieberbach’s famous theorems, there exist only finitely many conjugacy
classes of space groups of dimension d, and two space groups are conjugate
if and only if they are isomorphic. Hence one can ask for a classification of
the space groups of dimension d, at least for small dimensions d. Such
classifications are available for d≤4 in [BBN+78].
There is a well-known algorithm due to Zassenhaus [Zas48], implemented
by H. Brown [Bro69], which can be used to classify the d-dimensional space
groups. This algorithm proceeds in the following two steps:
(1) Determine up to conjugacy the finite subgroups P of GL(d, ) and
their normalizers 
.
(2) For each such finite subgroup P, determine up to isomorphism the
extensions of 
 by P.
Step (1) requires a detailed analysis of the finite subgroups of GL(d, )
using the notion of Bravais groups and automorphism groups of lattices.
Currently, the irreducible maximal finite subgroups of GL(d, ) have been
determined up to dimension d≤31; see Nebe [Neb95], and the article by
Nebe and Plesken [NP95] for further information. Step (2) can be achieved
using a dimension-shifting process, as described in the following theorem.
THEOREM 11.5 Let P≤GL(d, 
) with P finite, 
,
 and 
. Then:
a) P acts naturally on T and thus also on V and on V/T. Further, there
exists a dimension-shifting isomorphism 
.
b) N acts on 
. The
isomorphism types of extensions of T by P correspond one-to-one with
the N-orbits on the elements of the finite group H1(P, V/T).
© 2005 by Chapman & Hall/CRC Press

Libraries and Databases
409
We also mention an interesting generalization of the crystallographic groups:
the almost crystallographic groups. These are groups in which the translation
subgroup may be any torsion-free nilpotent group, and they are significantly
more difficult to classify. An approach towards such a classification is
described by Dekimpe in [Dek96]. A library of such groups, maintained by
Eick and Dekimpe, is available as the ACLIB package in GAP.
11.6 The “ATLAS of Finite Groups”
The “ATLAS of Finite Groups” [CCN+85], by Conway, Curtis, Norton, Parker,
and Wilson, has become one of the most widely cited sources for information
about the finite simple groups and their close relatives. It was published in
1985, but the enormous amount of work involved in collecting together
and computing the data contained therein had been going on for more than
10 years prior to that time.
Its sequel, “An Atlas of Brauer Characters” [JLPW95], by Jansen, Lux,
Parker and Wilson, was published 10 years later and, in addition to the
Brauer character tables, contains amendments and additions to the original
“ATLAS”.
Although these are printed volumes, the vast majority of the data that
they contain was computed by machine, using many of the techniques that
have been discussed in this book, but also many one-off special-purpose
programs written to help complete the computation of the large character
tables.
The principal groups covered by the “ATLAS” include all of the 26 sporadic
simple groups, and also the smaller members in the infinite families of
finite simple groups, the aim of the authors being to include sufficiently
many of the small groups to indicate the generic behaviour of groups in
that family.
The information on these groups includes a variety of constructions of
the groups with information about isomorphism and containment between
them, presentations of the groups using generators and relations, their
automorphism groups and Schur multipliers, their maximal subgroups
(where known), and their character tables. The character tables include
information on conjugacy classes, power maps, and the fusion of the classes
and characters under group automorphisms. All of this information is printed
not only for the simple groups themselves, but also for closely related
groups, such as extensions of the simple groups by automorphisms, and
cyclic perfect central extensions of the simple groups.
Virtually all of the data in the two “ATLAS” volumes, and much more
besides, is now freely available to the mathematical community in electronic
form by means of a number of convenient interfaces, including GAP and
MAGMA.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
410
Thomas Breuer maintains a library of ordinary and modular character
tables of finite groups, which is accessed via GAP. It contains all character
tables in the “ATLAS”, and many others, including the maximal subgroups
of the groups in the “ATLAS”; see the Web site [GAP]. A library of table of
marks (see Section 10.5) of various finite groups is also available in GAP.
Wilson, Parker, and Bray provide an extensive online library of
permutation and matrix representations of the finite simple groups and
their variations, featuring explicit matrices and permutations for the group
generators; see the Web site [ATL]. Information is also provided on standard
generators for the groups, which were discussed in Subsection 7.8.2 in
connection with setting up isomorphisms between a standard copy of the
group G in question and an arbitrary group known to be isomorphic to G.
This database is now also available via MAGMA.
As was mentioned in Section 10.3, MAGMA also has an internal library
containing information about the finite simple groups and their variations
of order up to about 107, including their (maximal) subgroups and outer
automorphisms.
© 2005 by Chapman & Hall/CRC Press

411
Chapter 12
Rewriting Systems and the
Knuth-Bendix Completion
Process
Coset enumeration, which was studied in detail in Chapter 5, is designed to
provide information about the finite quotients of a finitely presented group. It
can be used to prove that such a group is finite, but rarely to prove that it is
infinite. The algorithms described in Chapter 9 can tell us about other types
of quotients of finitely presented groups, such as abelian, nilpotent, or
polycyclic quotients, from which we can, on occasion, deduce that the group
is infinite.
The methods to be discussed in the final two chapters of this book provide
a completely different approach to computing with finitely presented groups.
Their principal aim is to find a normal form for group elements, together
with an algorithm for putting words in the group generators into normal
form. When successful, they enable us to determine the finiteness or
infiniteness of the group (and often the finiteness or infiniteness of the orders
of elements of the group), since we can generally count the number of distinct
normal forms. They may also enable us to compute neighborhoods of the
origin in the Cayley graph of the group, and possibly to compute the growth
function of the group.
Of course, we can only achieve these aims if the group has a solvable word
problem and, as we noted at the beginning of Chapter 5, this is not the case
in general. Fortunately, many of the interesting classes of finitely presented
groups that arise in practice, particularly those, such as knot groups, that
arise from topology or geometry, do turn out to have a solvable word problem.
Furthermore, as we shall see in Chapter 13, many of these are automatic
groups and are consequently amenable to the computational methods to be
described there.
In this chapter we shall present the basic theory of rewriting systems over
a fixed finite alphabet, together with its applications to CGT. We shall come
to that in Section 12.2. First we need to generalize the basic theory of finitely
presented groups to semigroups and monoids.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
412
12.1 Monoid presentations
The basic theory of monoid presentations follows the same lines as that of
group presentations, which we dealt with in Section 2.4 and, as we shall see,
a group presentation can be regarded as a special case of a monoid
presentation. However, the method of defining a group presentation using
the normal closure of a set of relators in a free group does not carry over
directly to monoids; instead, we need to use the idea of a congruence on a
monoid. Some of the material in this and later sections of this chapter is
based on the presentation in Sims’ book [Sim94].
12.1.1 Monoids and semigroups
Roughly, a monoid is a group without inverses, and a semigroup is a group
without inverses or an identity. More formally:
DEFINITION 12.1 A semigroup is a set S equipped with an associative
binary operation ; that is, x(yz)=(xy)z for all x, y, z∈S.
DEFINITION 12.2 A monoid is a set M equipped with an associative binary
operation o, together with an identity element e∈M that satisfies ex=xe=x
for all x∈M.
As we did for groups, we shall generally omit the o symbol, and write xy
instead of xy, and we shall write 1 rather than e for the identity element,
or 1M for the identity of M. For additive examples, we use 0 for the identity.
In fact, we shall not be very much concerned with semigroups here,
although the theory of finitely presented semigroups is not really very different
from that of monoids. From any semigroup we can immediately define a
monoid simply by adjoining an identity element.
A subsemigroup of a semigroup S is a subset of S that is itself closed
under the binary operation of S, and a submonoid of a monoid M is a subset
that is closed under the binary operation and contains the identity element
of M.
Here are some examples of semigroups and monoids. The nonnegative
integers 
 form a monoid under addition with identity 0. The nonzero natural
numbers  form a subsemigroup but not a submonoid of  under addition.
The elements of any ring form a semigroup under multiplication in the
ring and, if the ring has a unit element 1, then they form a monoid.
Recall that, if X and Y are sets, then a relation from X to Y is simply a
subset of X×Y, and the relation R is called a function if, for each x∈X, there
is a unique y∈Y with (x, y)∈R. The composition RS of a relation R from X
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
413
to Y and a relation S from Y to Z is defined by
 
If X is a fixed set, then the set Rel(X) of all relations from X to X forms a
monoid under composition, and the set Fun(X) of all functions from X to X
forms a submonoid of Rel(X). The identity element is of course the identity
function {(x, x)|x∈X}. The set Sym(X) of all bijections from X to X is a
submonoid, and indeed a subgroup, of Fun(X).
From now on we shall discuss monoids only. The reader should have no
difficulty in formulating analogous results for semigroups.
If X is a subset of a monoid M, then the submonoid of M generated by X is
defined to be the intersection of all submonoids of M that contain X, and this
can easily be shown to be equal to the set of all elements of M that can be
written as strings x1…xr with each xi∈X. We allow the empty string ε,
which is defined to represent the identity 1M. A monoid M is said to be
finitely generated if there exists a finite set X generating M.
Monoid homomorphisms are defined as you might expect. For monoids M
and N, a monoid homomorphism from M to N is a function f:M→N satisfying
f(xy)=f(x)f(y) for all x, y∈M and f(1M)=1N.
Notice that there is a difference here from group theory in that, for monoids,
the property f(1M)=1N does not follow from f(xy)=f(x)f(y) for all x, y∈M, and
so we can have a map f:M→N that is a semigroup homomorphism but not
a monoid homomorphism. For example, let M=N={0, 1} under multiplication,
and let f(0)=f(1)=0. It is easily checked that the image im(f) of any monoid
homomorphism f:M→N is a submonoid of N.
Now we come to a significant difference from group theory. The kernel of
a group homomorphism ϕ is a particular type of subgroup, from which we
can form a quotient group that is isomorphic to im(ϕ).
We can do something similar for monoids, but not by using a special type
of submonoid. The problem is that, although the set of elements x∈M with
f(x)=1N forms a submonoid of M, unlike in the group case, the pairs x, y∈M
for which f(x)=f(y) are not uniquely determined by this subgroup. We need
to replace the idea of a special type of subgroup by a certain type of
equivalence relation, known as a congruence on the monoid.
DEFINITION 12.3 A congruence on a monoid M is an equivalence relation
~ on M with the property that x~y implies xz~yz and zx~zy for all x, y, z∈M.
PROPOSITION 12.4 Let f:M→N be a monoid homomorphism and define
~ on M by 
. Then ~ is a congruence on M.
The proof is straightforward. The congruence ~ defined in this proposition is
called the kernel ker(f) of the homomorphism f. From a congruence ~ on
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
414
M, we can form the quotient structure M/~ in which the elements are the
equivalence classes under ~, with the multiplication [x][y]=[xy], where [x]
denoted the equivalence class of x∈M. Notice that, if x~x′ and y~y′ then, by
definition of a congruence, xy~x′y~x′y′, so this multiplication is well-defined,
and M/~ clearly has the identity element [1M]. The map M→M/~ defined by
 is a monoid homomorphism.
Monomorphisms, epimorphisms and isomorphisms of monoids are defined
in the same way as for groups. The analogue of the first isomorphism theorem
for monoids is:
THEOREM 12.5 Let f:M→N be a monoid homomorphism with kernel~.
Then the map 
 defines a monoid isomorphism from M/~ to im(f).
PROOF It is routine to verify that this map is a well-defined monoid
homomorphism that is injective and surjective. 
Of course, a group is just a special case of a monoid, so we would hope that
this theory of equivalences and quotient monoids would correspond properly
when applied to a monoid that happens to be a group. This is indeed the case.
When M and N are groups, and f:M→N is a homomorphism, and ~ is the
kernel of f as we have defined it for monoid homomorphisms, then x~y if and
only if x and y are in the same coset of K, where K is the kernel as it would
be defined for a group homomorphism. So, although we have two distinct
definitions for the kernel of f in this situation, each of them is derived easily
from the other.
The normal closure of a subset X of a group G was defined in Definition 2.7
to be the smallest normal subgroup of G containing X. There is an analogous
idea for monoids. An equivalence relation on any set M is, by definition, a
subset of M×M, and so we can talk about the intersection of a collection of
equivalence relations, and it is routine to check that the result is itself an
equivalence relation. (In the case of an empty collection, the intersection is
defined to be M×M.) It is equally routine to check that the intersection of a
collection of congruences on a monoid M is itself a congruence. So for any
subset  of M×M, we can define the congruence on M generated  by to be
the intersection of all congruences that contain .
PROPOSITION 12.6 Let M be a monoid, let 
⊆M×M, and let ~ be the
congruence generated by 
. Let us call m, n∈M directly equivalent if we
have m=uvw, n=uv′w, for some u,v,v′,w∈M with (v,v′) ∈ 
 or (v′, v) ∈ 
.
Then, for m,n∈M, (m, n)∈~ if and only if there is a sequence m=m0, m1,…,
mr=n of elements of M, with r≥0, such that mi and mi+1 are directly equivalent
for 0≤i<r.
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
415
PROOF Define ~′ on M by (m, n) ∈~′ if and only if the condition defined in
the proposition holds. It is routine to check that ~′ is a congruence on M that
contains 
. Further, by definition of a congruence, any congruence on M
that contains ~ must contain ~′, so we have ~=~′.
12.1.2 Free monoids and monoid presentations
DEFINITION 12.7 A monoid F is free on the subset X of F if, for any
monoid M and any map :X→M, there exists a unique monoid
homomorphism ′:F→M with ′(x)=(x) for all x∈X.
The proof of the following result is identical to that of the equivalent result
for free groups, Proposition 2.47.
PROPOSITION 12.8 (i) Two free monoids on the same set X are isomorphic.
(ii) Free monoids on X1 and X2 are isomorphic if and only if |X1|=|X2|.
Existence is much easier to prove than is the case for free groups. Recall
from Definition 2.48 that, for any set X, X* is defined to be the set of all
strings or words over X. It is obvious that X* forms a monoid with identity
element εX under the operation of concatenation of strings.
PROPOSITION 12.9 For any set X, the monoid X* is free on X.
PROOF For a monoid M and a map :X→M, the unique monoid
homomorphism X*→M that restricts to  on X is the map sending x1…xr to
(x1)…(xr).
We can now define a monoid presentation.
DEFINITION 12.10 Let X be a set, and let  be a subset of X*×X*. Then
 is defined to be the quotient monoid X*/σ, where σ is the
congruence on X* generated by 
. This is also called the monoid with
generating set X and defining relations .
The elements of  are called the defining relations of the presentation. A
relation (u,v)∈ is usually written as u=v. A monoid M is said to be finitely
presented (or sometimes, more accurately, finitely presentable) if M is
isomorphic to 
 with X and  both finite. In specific examples,
if X={x1,…, xn} and ={(u1, v1),…, (um, vm)}, then we shall often write
 rather than 
.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
416
For a set X, let A:=XX-1 as in Subsection 2.4.1. Let 
 be the subset
 of A*×A*, and let ~x be the congruence generated
by 
. Then the reader can check that the free group F(X) defined in
Subsection 2.4.1 is equal to the quotient monoid 
.
We have the following analogue of Theorem 2.52.
THEOREM 12.11 Let X be a set, let 
 be a subset of X*×X*, let M be a
monoid, and let :X→M be a map with the property that, for all (u, v)∈
,
we have (x1)…(xr)=(y1)…(ys), where u=x1…xr, v= y1…ys, and xi,yj∈X.
Then there exists a unique monoid homomorphism 
for which ′([x])=(x) for all x∈X, where [x] represents the equivalence class
of x in 
.
PROOF If ′ is to be a homomorphism, then it must satisfy ([u])=
(x1)…(xr) for all u=x1…xr∈X*, and so we have uniqueness.
By definition of a free monoid and Proposition 12.9, there exists a
homomorphism ′′:X*→M with ′′(x)=(x) for all x∈X. The assumption on 
says precisely that each element of  is in the kernel of ′′, and so ker(′′)
is a congruence on X* that contains . Hence it also contains the congruence
~ on X* generated by 
, and so ′′(u)=′′(v) whenever u~v. But this says
precisely that the map 
 defined by
′[(u)]=(x1)…(xr) for all u=x1…xr∈X* is well-defined, and it is clearly a
monoid homomorphism satisfying ′([x])=(x) for all x∈X.
Example 12.1
Let 
. The reader can verify that the congruence
generated by 
 consists of 
 for all r, s∈
 with
r≥2, and that 
.           
As we did for groups, we shall generally denote an element [w] in a
finitely presented monoid simply by w, and use v=M w to mean [v]=[w]. The
following theorem shows that, as an alternative to Definition 2.4, we could
define a group presentation as a special case of a monoid presentation.
THEOREM 12.12 Let X be a set, let A:=XX-1, and let 
 be a subset of
A*×A*. Then the group defined by the presentation 
 is equal to the
monoid defined by the presentation 
.
PROOF The elements of 
 and of 
 are equivalence
classes of A* under congruences ~1 and ~2, respectively, and we have to show
that ~1=~2. Let R be the set of words uv-1 corresponding to elements (u, v)∈
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
417
 and let 
 with F the free group on X. Then, by definition, for w1,
w2∈A*, we have w1 ~1 w2 if and only if w1N=w2N. This is certainly the case
if 
 and, since ~2 is the congruence generated by 
, it
follows that w1 ~2 w2 implies w1 ~1 w2. Conversely, since N is generated as a
subgroup of F by the elements g-1uv-1g with (u, v)∈
, w1 ~1 w2 implies that
w1=F w2w, where w is a product of some of these generators of N and their
inverses. Since 
, this implies w1 ~2 w2w. But if (u, v)∈
, then u ~2 v
and hence uv-1 ~2 ε and 
. Since ~2 is a congruence, we have
w2w ~2 w2 and hence w1 ~2 w2.
Exercises
1.
Prove that, if the finitely generated monoid M is generated by X, then
X has a finite subset that generates M.
2.
Find an example of monoids M, N and a submonoid of M that can occur
as 
 for more than one monoid homomorphism
f:M→N.
3.
Complete the details of the proof that the intersection of the congruences
on M containing a given subset X of M×M is itself a congruence on M
that contains X.
4.
Let M be a group, let  be a subset of M×M, and let ~ be the congruence
generated by . Show that x~y if and only if xy-1 is in the normal closure
in M of the set 
.
5.
Prove directly from the definition that, if a monoid M is free on X, then X
generates M.
6.
Prove that any monoid that is generated by a single element is defined
by a presentation with a single defining relation.
12.2 Rewriting systems
We turn now to the theory of rewriting systems over a fixed finite alphabet.
There is a large body of literature on this topic, which has applications to
all branches of algebra. For a historical account, with an extensive
bibliography, we refer the reader to the article by Buchberger [Buc87]. One
of the earliest papers describing the use of critical pairs and the completion
process in a very general setting is that of Knuth and Bendix [KB70], after
whom this process is usually named. Applications to group theory are
described in the two papers of Gilman: [Gil79] and [Gil84]. There is also an
extensive treatment of this topic, with details of algorithms and their
implementation in [Sim94],
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
418
We let A be a finite set, known as the alphabet, and let A* be the free
monoid of strings over A. A rewriting system on A* is a set  of ordered
pairs (w1, w2), with w1, w2∈A*. The elements of  are called rewrite-rules,
and w1 and w2 are called, respectively, the left- and right-hand sides of the
rule. The idea is that we can replace occurrences of w1 in a string by w2. We
shall assume throughout that no two distinct rules have the same left-
hand sides.
For u, v∈A*, we write u→S v if there exist strings x, y, w1, w2∈A* such
that u=xw1y, v=xw2y and (w1, w2)∈; in other words, if v is obtained from u
by making a single substitution using a rewrite-rule. We shall omit the
subscript  when there is no danger of ambiguity.
DEFINITION 12.13 A string u∈A* is said to be ( -)irreducible or ( -)reduced
if there is no string v∈A* with u→v.
We denote the reflexive, transitive closure of → by →*. Hence u→*v if and
only if, for some n≥0, there exist u=u0, u1,…, un=v∈A* with ui→ui+1 for
0≤i<n. The symmetric closure of →* is denoted by 
*. Thus u
*v if and
only if, for some n≥0, there exist u=u0, u1,…, un=v with
(†)
The system  is called Noetherian (or terminating) if there is no infinite
chain of strings ui(i>0) with ui→ui+1 for all i. This implies that for any u∈A*
there exists an irreducible v∈A* with u→*v.
We call  confluent if, whenever u, v1, v2∈A* with u→*v1 and u→*v2,
there exists w∈A* with vi→*w and v2→*w, and we call  complete if it is
Noetherian and confluent.
It is called  locally confluent if whenever u, v1, v2∈A* with u→v1 and
u→v2, there exists w∈A* with v1→*w and v2→*w.
The following sequence of lemmas demonstrates that completeness is a
highly desirable property for rewriting-systems to possess. For u∈A*, we
define the set desc(u) of descendants of u to be 
. So
u is irreducible if and only if desc(u) is empty.
LEMMA 12.14 Suppose that  is Noetherian. Then desc(u) is finite for all
u∈A*.
PROOF Suppose that desc(u) is infinite. Since no two rules in  have the
same left-hand side, there are only finitely many w with u→w. Thus there
exists u2∈A* with u→u2 and desc(u2) infinite. Similarly, there exists u3 with
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
419
u2→u3 and desc(u3) infinite, and we get an infinite chain {ui} with ui→ui+1,
contradicting the assumption that  is Noetherian.
LEMMA 12.15 Suppose that  is Noetherian and locally confluent. Then 
is complete.
PROOF We shall prove that, under the given hypotheses, for all u∈A*
there is a unique irreducible w with u→*w. The result clearly follows
from this. The proof is by induction on |desc(u)|, the result being clear
for |desc(u)|=0. Suppose that u=u0→u1→…→um and 
, with um and 
, irreducible. By local confluence, there exists v
with u1→*v and 
. Let v→*w with w irreducible. Since 
, it follows by inductive hypothesis that,
 which completes the proof.
LEMMA 12.16 If  is Noetherian and locally confluent, then each equivalence
class under 
* contains a unique -irreducible element.
PROOF Let u and v be irreducible strings with u
*v. Then there exist
u=u0, u1,…, un=v∈A* satisfying the equation (†) above. We have to prove
that u=v. This is clear if n=0, so we use induction on n. By Lemma 12.15 
is confluent, so there exists w∈A* with u→*w and u2→*w. Since u is
irreducible, we must have u=w, and so we can replace u2 by u in the diagram,
and the result follows by induction.
The systems that we shall be considering will all be Noetherian, but they
will not always be confluent. The following lemma provides a method of
checking confluence (and hence completeness) constructively, at least when
 is finite.
LEMMA 12.17 The system  is locally confluent if and only if the following
conditions are satisfied for all pairs of rules (u1, t1), (u2, t2)∈.
(i)
If u1=rs and u2=st with r, s, t∈A* and sε, then there exists w∈A* with
t1t→*w and rt2→*w.
(ii) If u1=rst and u2=s with r, s, t∈A* and sε, then there exists w∈A* with
t1→*w and rt2t→*w.
PROOF First assume that  is locally confluent. Then in both cases,
the existence of w follows by applying the definition of local confluence
to the string rst. Conversely, assume that the conditions (i) and (ii) are
valid, and let u be a string with u→v1 and u→v2. Then u must have two
substrings u1 and u2 such that there exist rules (u1, t1), (u2, t2)∈  that are
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
420
used in the reductions to v1 and and v2. If u1 and u2 do not overlap in u,
then we have u=ru1su2t for some strings r, s, t and v1=rt1su2t, v2=ru1st2t.
Thus v1→w and v2→w, with w=rt1st2t. Otherwise, u1 and u2 overlap in ,
and (after interchanging the rules if necessary) we must have one of the
two situations postulated in conditions (i) and (ii) of the lemma. It then
follows by assumption that there exists w∈A* with v1→*w and v2→*w, so 
is locally confluent.
A pair of rules satisfying either of the two conditions of the lemma is called
a critical pair. If one of these conditions fail (so  is not confluent), we end
up with two distinct irreducible strings w1 and w2 that are irreducible and
equivalent under 
*. We can resolve this instance of incompleteness by
adjoining either (w1, w2) or (w2, w1) to  as a new rule. We can then continue
with the check for local confluence.
We shall assume from now on that  is finite unless explicitly stated
otherwise.
The procedure of examining critical pairs and adjoining new rules to  if
necessary is known as the Knuth-Bendix completion process. It may happen
that this process eventually terminates with a finite complete set , which
is what we would like. In many cases, however, the process does not
complete, but it does, in principal, generate an infinite complete set of
rules. In a few examples, as we shall see, such an infinite set can have a
very transparent structure, which can make it almost as useful as a finite
complete set.
In general, it can be difficult to decide which of (w1, w2) or (w2, w1) to adjoin
to  in order to resolve a critical pair. In the applications that we shall be
considering, we resolve this problem by imposing a well-ordering ≤ on A*
that has the property that u≤v implies uw≤vw and wu≤wv for all w∈A*.
Such an ordering is known as a reduction ordering. Then we make the
larger of w1 and w2 the left-hand side of the new rule.
The assumption on the ordering ensures that u→*v implies u≥v and,
since it is a well-ordering,  will necessarily be Noetherian. Thus, if  is
complete, then the irreducible elements correspond to the least representatives
in the 
* equivalence classes.
One of the most commonly used examples of a reduction ordering is a
shortlex ordering, as defined in Definition 2.60. For example, if A={a, b, c}
and (just to be awkward) we decide to order A by b<c<a, then the first few
strings in the associated shortlex order are
 
From now on, we shall assume that the rules are ordered according to some
such well-ordering, although not necessarily a shortlex ordering. (A completely
different well-ordering, appropriate for polycyclic groups, will be considered
in Section 12.4.)
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
421
DEFINITION 12.18 A string u∈A* is called ( -)minimal if it is the least
element in its 
* equivalence class
Then clearly minimal strings are irreducible, and Lemma 12.16 says that
 is complete if and only if all irreducible strings are minimal.
A rewrite-rule (w1, w2) in  is called ( -)irreducible if w2 and all proper
substrings of w1 are -irreducible. If all rules are irreducible, then we say
that  is irreducible or reduced.
If a rule (w1, w2) is not irreducible, then we can use the other rules in 
to simplify it, without changing the relation →*. The rule may either turn
out to be redundant, or we may replace it by an irreducible rule 
 (or
) in which 
. (Of course, 
 then becomes a
new rule of .)
The new rules that we adjoin to  during the Knuth-Bendix completion
process will always be irreducible, but they may sometimes destroy the
irreducibility of some existing rules. It is generally efficient to simplify 
by replacing all rules by irreducible rules at regular intervals. This
simplification process does not change the relation →*.
We shall not go further here into the algorithmic details of the Knuth-
Bendix procedure, but we shall assume that, for any two rewrite-rules that
are in  at any stage, either one or both of them will get removed or
replaced during simplification, or the pair of rules will be checked for being
a critical pair (bearing in mind that the same pair can be a critical pair in
more than one way). We shall also assume that any rule that is not -
reduced will at some stage be removed during rule simplification.
DEFINITION 12.19 A pair of strings (w1, w2) is called an ( -)essential rule
if w1
*w2, and w2 and all proper substrings of w1 are ( -)minimal.
So any essential rule in  is reduced and, if  is complete, then the reduced
rules in  are essential. We have not said anything about essential rules
being rules of , but the following proposition says that they will be if we
run Knuth-Bendix on  for long enough.
PROPOSITION 12.20 (i) Let w∈A* and suppose that v∈A* is minimal
with w
*v. After running the Knuth-Bendix completion process on  for
sufficiently long, we will have 
.
(ii) Let (w1, w2) be an -essential rule. After running the Knuth-Bendix
completion process on  for sufficiently long, (w1, w2) will be a rewrite-rule
of .
PROOF Let  be the (possibly infinite) set of all rewrite-rules that are in 
at some stage during the Knuth-Bendix completion process, and are not
subsequently removed as a result of simplification of the existing rule set.
We shall show first that the rules in  form a complete rewriting system.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
422
By the assumption that we made above about the Knuth-Bendix
procedure, any pair of rules from  will at some stage be checked for being
a critical pair, after which the hypotheses of Lemma 12.17 will hold in  for
that pair of rules. Indeed, since simplification of the rule set does not change
the relation →*, the hypotheses of Lemma 12.17 will continue to hold for
that pair of rules, and since eventually all rules not in  that are involved
in the associated word reductions will be removed from , the hypotheses
of Lemma 12.17 hold in . It follows from Lemma 12.17 that  is locally
confluent, and hence complete.
So, if w, v are as in (i), then 
. Since all of the rules in 
 are
eventually in , this proves (i). If (w1, w2) is an essential rule then, by (i), we
will eventually have 
. Since all proper substrings of w1 are minimal,
w1 must then be the left-hand side of some rule 
 in . Then 
and so, by (i) again, eventually we will have 
. Then, the next time
that the rules are simplified, 
 will be replaced by (w1, w2), which
proves (ii).
COROLLARY 12.21 If there are only finite many 
* equivalence classes,
then the Knuth-Bendix completion process will halt with a finite complete
set of rewrite-rules.
PROOF If there are only finitely many 
*-classes, then there are only
finitely many -minimal words, and hence only finitely many essential rules.
By the proposition, these will eventually all be in , at which stage  will
be complete.
Implementing the Knuth-Bendix completion process efficiently on a computer
is difficult. To be seriously useful it needs to be able to handle very large rewriting
systems, possibly with millions of rewrite-rules. So the implementation needs
to be efficient in terms of both time and space. The two critical components of
an implementation are the search for critical pairs of , and the reduction of
words to 
-irreducible words. Experiments indicate that in typical
implementations, most of the time is taken up with word reduction.
We shall not go into implementation details here. There is much discussion
and analysis of the various issues involved in Chapters 2 and 3 of [Sim94]. The
word-reduction process can be made to run fast by using a certain type of finite
state automaton, and we shall describe that method later in Subsection 13.1.3.
There are also a number of algorithmic issues that need to be decided,
such as how often do we carry out rule simplification, and in what order do
we consider pairs of rewrite-rules in the search for critical pairs. For example,
we might consider them in the order in which they are found, or in order of
increasing length. A flexible implementation would allow the user to choose
from a range of strategies of this kind.
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
423
Exercises
1.
Show that the set  defined in the proof of Proposition 12.20 is equal to
the set of all -essential rules.
2.
Let A={c, o, z, e} and  ={ze→ce, zc→oz, oc→cz}.
(i) Show that is confluent with respect to the shortlex ordering of A*
with c<o<z<e.
(ii) Show that, for 
, and that this reduction involves
3.2n-2n-3 applications of rules in .
12.3 Rewriting systems in monoids and groups
We turn now to the applications of rewriting systems to finitely presented
monoids and groups. The word problem in a monoid M defined by a
presentation with generating set A is the problem of deciding whether two
words u,v∈A* represent the same element of M; that is, whether u=M v. If
M is a group, then this is equivalent to deciding whether uv-1=M 1
M. The
word problem is known to be undecidable in some finitely presented
monoids and groups. However, we can attempt to use the Knuth-Bendix
completion process to solve this problem in specific examples.
If  is a rewriting system over A, then 
* is precisely the congruence on
A* generated by , and so A*/
* is equal to the monoid defined by the
presentation Mon〈A| 〉. Lemmas 12.15 and 12.16 say that, if  is complete,
then the -irreducible words are the -minimal words, and form a set of
representatives for the 
*-classes on A*. Thus, if  is finite and complete,
then we can solve the word problem in the monoid by using the rules in  to
reduce the two words u and v to irreducible words, and then we just check
whether these reductions are equal words. When M is finite, Corollary 12.21
tells us that the completion process is guaranteed to terminate eventually
with a finite complete set of rules. This also happens occasionally when M is
infinite, but not typically. It can also happen that there is a complete set of
rules that is infinite but has a very regular pattern, and so it can still be
used to solve the word problem.
If 
 is a group presentation, where R or 
 is,
respectively, a set of relators or relations then, as we described in Theorem
12.12, we can construct a monoid presentation 
 for
the group, where A:=XX-1. Then we can apply the completion process to
this monoid presentation, which might enable us to solve the word problem
in G.
In particular, if R (or ) is empty, then G is a free group on X and = .
Then the only critical pairs are those resulting from pairs of rules (xx-1, ε)
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
424
and (x-1x, ε) for x∈A, where we have the overlap x-1 between the two left-
hand sides. But both of the possible reductions of xx-1x are equal to x, so it
follows from Lemma 12.17 that  is already confluent. Hence the -reduced
words are precisely those that contain no adjacent mutually-inverse
generators; that is, the reduced words as defined in Subsection 2.4.1. This
is precisely what Proposition 2.50 asserts, and in fact the proof that we
gave of that result in Chapter 2 was essentially the same as the proof that
we have given here, but applied to that particular situation.
By default, we use a shortlex ordering on A* to decide on the left- and
righthand sides of the rules but, as we shall see in the next section, in particular
situations other orderings may be more effective.
In examples, we shall frequently use the so-called ‘inversion by case-change’
convention, which means that the inverses of generators x, y, etc., are denoted
by X, Y. This has proved to be very convenient on many occasions.
Unfortunately, there is a conflict with the use of X for the generating set,
which we hope will not cause too much confusion!
Example 12.2
Let 
 be the dihedral group of order
6. Then A={x, X, y, Y}, and (using the order x<X<y<Y on A) we can start
with
 
(When each generator has an inverse generator and we are using a shortlex
ordering, then we can always rewrite our rules so that the length of the
lefthand side is greater than the right-hand side by at most 2, and it is
generally efficient to do this.)
One critical pair, for example, is (Xx, ε), (xx, X) with the overlap x. This
leads to the word Xxx reducing in two different ways to x and XX, and to
resolve this we adjoin the rule (XX, x) to S.
It is extremely tedious to examine all such critical pairs by hand, but easy
for a computer, and we end up with the complete set of rules:
 
We now observe that the rules (yY, ε) and (Yy, ε) are not irreducible, since
the word Y is reducible. In fact they are both redundant, and if we remove
them, we are left with the set of all essential rules.
Most of the time, if G is an infinite group, then the Knuth-Bendix procedure
will not terminate, but there are some examples in which it does. There does
not seem to be any satisfactory theory that will predict when this will
happen; in many examples, termination depends on the correct choice of
ordering of A*, and even of A when a shortlex ordering is used.
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
425
Example 12.3
Let 
 be the free abelian group on two generators.
If we use the ordering x<X<y<Y of A, then we end up with the finite
complete set of rules:
 
If we use the ordering x<y<X<Y, however, then we generate the infinite
complete set of rules:
 
In Example 12.3, the infinite complete set is regular (in the sense of regular
languages) and can be used effectively to reduce words to normal form.
The infinite examples for which finite complete rewriting systems have
been found for some choice of generators and ordering include polycyclic groups,
the two-dimensional surface groups, the von Dyck groups 
(by I.Wanless), many Coxeter groups (by Hermiller [Her94]), and a number
of isolated examples, such as 
. Many of these finite complete
rewriting systems are catalogued by LeChenadec in [LeC86].
Finally, it is worth noting that there are certain similarities between the
Knuth-Bendix procedure and Todd-Coxeter coset enumeration over the trivial
subgroup. Both are in some sense looking systematically for consequences of
the defining relations of the group. Of course the Todd-Coxeter algorithm can
only complete for finite groups, but it appears to be more efficient than Knuth-
Bendix for most straightforward examples.
There are exceptions, however. Knuth-Bendix works very well for certain
Coxeter groups, such as the groups Sym(n), which have a large order and
relatively small complete rewriting systems (about (n–1)2 equations).
For certain pathological examples, such as the presentation
 
of the trivial group, due to B.H.Neumann, Knuth-Bendix succeeds eventually,
whereas no implementation of coset enumeration has done so to date.
It is also possible to find a string-rewriting analogue of coset enumeration
over a nontrivial subgroup H of G. We shall not go into details here. This
topic is covered in Sections 2.8 and 3.10 of [Sim94].
Efficient implementations of the Knuth-Bendix algorithm for groups and
monoids are available in the Rutgers Knuth-Bendix Package (rkbp) written
by Charles Sims and available from him, and the KBMAG package by Holt.
Both offer a wide choice of controlling parameters and word orderings.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
426
Exercises
1.
Show that the dihedral group D2n has a complete rewriting system
with three rules on a monoid generating set containing two elements
of order two.
2.
Find a complete rewriting system for the symmetric group Sym(4) on
three monoid generators of order two.
3.
Let 
, and use the shortlex ordering of A*
with a<b. Show that there is an infinite complete rewriting system
consisting of the rules bab→aba and ban+1ba→aba2bn for all n≥1.
12.4 Rewriting systems for polycyclic groups
In this section, we shall give a brief exposition of the theory of polycyclic
groups in the context of string-rewriting and Knuth-Bendix completion.
Let us first quickly recall the basic definitions from Section 8.1. A group
G is polycyclic if it has a series of subgroups G=G1>G2>…>Gn+1=1 in which
each 
 and Gi/Gi+1 is cyclic.
Any such group has a polycyclic generating sequence set X=[x1,…,
xn], where xi∈Gi and xiGi+1 generates Gi/Gi+1. As usual, we define our
alphabet to be the set 
, which generates G as
a monoid.
We let I(X)=I be the subset of {1, 2,…, n} consisting of those i for which
Gi/Gi+1 is finite, and let ri:=|Gi/Gi+1| for i∈I.
We may, if we wish, use the smaller set of monoid generators
 
It is easy to show (by induction on n-i) that the elements 
 for i∈I can be
expressed, in G, as products of the generators in A, and so A generates G
as a monoid. In particular, if G is finite, then we may dispose of the inverse
generators altogether.
By Lemma 8.3, each g∈G has a unique normal form word in (A)* of the
form 
, where each 
 and 0≤ei<ri if i∈I.
We should like to find a reduction ordering of the words in A* for
which the normal form for each group element 
 is the least word
representing . Since the normal form may be far from being the shortest
word for 
, orderings based on length are not suitable. In fact, the
appropriate ordering is an instance of a wreath-product ordering, as defined
on page 48 of [Sim94].
A wreath-product ordering on B*, for an alphabet B={z1,… zm} is defined
as follows. First we assign levels, which must be positive integers, to the
letters zi. The idea is that a single occurrence of a generator at a higher
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
427
level renders a word larger than any number of generators at lower levels.
For words involving generators of the same level only, we use some other
standard ordering, which may, for example, be a shortlex ordering.
To be precise, suppose, inductively, that for some r>0, we know how to
order words involving only generators of level less than r. Then distinct
words v, w involving generators of level at most r are ordered as follows.
First remove all generators of level less than r from v and w, and compare
the two resulting words v, w in the level r generators. If they are distinct
and, say, v>w, then we define v>w.
On the other hand, if 
, say, then we have v=
 and 
 where, for 1≤k≤l+1, tk
and uk are words involving only generators of level less than r. We define
v<w if t1<u1 or, for some k≤l, ti=ui for 1≤i≤k, but tk+1<uk+1.
It is routine to check that this is a well-ordering and that u≤v implies
uw≤vw and wu≤wv for all u, v, w∈A*, which are the required conditions
for a reduction ordering.
In the application to polycyclic groups, we give each of the monoid
generators distinct levels, with 
 having the highest level, followed by x1,
 then then x2, and so on, with xn having the lowest level. (These orderings
are also referred to as recursive path orderings in the literature.)
Now G has a monoid presentation in which the relations have the form:
 
where, for all i and j, wi, wij, 
, and 
 are words in normal form in
, and 
. (Note that
 is equal in G to the inverse of wij.)
We call such a presentation a polycyclic monoid presentation of G, and
the reader can verify that this is almost identical to a polycyclic group
presentation of G as defined in Subsection 8.1.2.
Notice that, in each of these equations, the left-hand side is greater
than the right-hand side in the wreath-product ordering just defined, and
so we can define a corresponding rewriting system  in which the left- and
right-hand sides of the rules are given by the left- and right-hand sides of
the relations in the presentation.
It can be seen that the words in normal form are precisely those that do
not have the left-hand side of any of these equations as a subword; that is,
they are the irreducible words with respect to the ordering. Since distinct
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
428
irreducible words represent distinct elements of G, they cannot be
equivalent in ↔*, and so S is complete, and it is clear that all of its rules
are minimal and hence essential. The process of using the rewrite-rules to
reduce a word to normal form is exactly the collection process as defined in
Subsection 8.1.3.
Conversely, suppose that we are given an arbitrary monoid presentation
of the above form, over the alphabet A. Then we can define the rewriting
system  as in the preceding paragraph.
We should start by checking that the words 
 and 
 reduce to the
identity in  for all i∈I. If this is the case, then the presentation defines a
group G, in which the inverse generators are what they seem.
It is not difficult to see that if, for 1≤i≤n+1, we define Gi to be the
subgroup of G generated by {xj|j≥i}, then Gi+1 is normal in Gi with Gi/Gi+1
cyclic for all i, so G is certainly polycyclic. Furthermore, the rewriting
system  is Noetherian, and the set of reduced words is as before.
However, the order 
 may be less than the number ri given
in the presentation when i∈I, or  may be finite when 
. In fact, this
occurs if and only if some group element has more than one irreducible
representative word; that is, if and only if  is not confluent. The confluence
(and hence also the completeness) of  is equivalent to its consistency, as
defined in Definition 8.10.
Lemma 12.17 provides us with a method for testing for confluence. This
method was first used and justified by Wamsley for the case of nilpotent
groups in [Wam70] (although not in the context of critical pair completion).
The equations arising from the critical pairs that have to be checked include:
 
(This is only a proper subset of all such equations, but it is proved by Sims
in Proposition 8.3, Chapter 9 of [Sim94] that it suffices to check the listed
equations only in order to check consistency.)
For large n, the set of equations in the final line of this list is the largest,
and contains up to n(n-1)(n-2)/6 equations. In the nilpotent case, many more
of these checks can be shown to be redundant by assigning weights to the
generators according to how far down the lower central series of G they
lie. In the case of finite p-groups, it is proved by Vaughan-Lee in [VL84]
that it is sufficient to test approximately n2d/2 equations, where d is the
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
429
minimal number of generators of the group. This result was stated as
Theorem 9.22 in Subsection 9.4.1.
Exercises
1.
The construction described in this exercise is the rewriting system
analogue of Proposition 2.55. The complete presentations of polycyclic
groups described above come from repeated applications of this
construction.
Let G be a group with normal subgroup N, and suppose that G/N and
N have complete rewriting systems 
,  on finite monoid generating
sets  and B, respectively. Let A⊆G with 
 and each a∈A mapping
onto some 
.
By using a wreath-product ordering in which the generators in A
have higher weights than those in B, show that G has a complete
rewriting system on A∪B with rules R∪S∪T, where rules in R have
the form u→vw for a rule 
 and an S-reduced word w∈B*,
and those in T have the form ba→aw for a∈A, b∈B and an -reduced
word w∈B*.
2.
The Baumslag-Solitar groups are defined by their presentations B(m,
n):=
. Use a wreath-product ordering on A={x, X, y,
Y}, where X=x-1, Y=y–1 and x, X, y, Y have levels 1, 2, 3, 4, to show that
B(m, n) has a complete rewriting system consisting of the four inverse
rules together with the four rules:
 
12.5 Verifying nilpotency
It is of course undecidable whether a given presentation defines a polycyclic
group but, if it does, then it is possible to verify this fact. The method of
doing this to be described here, which makes use of a computer
implementation of the Knuth-Bendix completion algorithm, was first
proposed by Sims, and is described in Chapter 11 of [Sim94]. It requires the
use of a polycyclic quotient algorithm (PQA); see Subsection 9.4.3. But if
we are trying to verify nilpotency, then a nilpotent quotient algorithm
(NQA) suffices.
Let 
 be the given finitely presented
group. If G is polycyclic, then it certainly has a largest polycyclic quotient
G/K, and so we can use the PQA (or NQA, if we want to verify nilpotency)
to compute G/K. Then G is polycyclic if and only if K=1, and the objective
is to verify that K=1.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
430
The output of the PQA consists of a consistent polycyclic presentation of
G/K on a generating set X={x1,…, xn}, together with the images of the yj in
G/K, given as words uj in normal form in the generators xi and 
.
We can then use the relations in this polycyclic presentation to express
each xi as a word vi in Y∪{xj|j<i} and inverses. (In the existing
implementations of the NQA, at least, the output is in such a form as to
make this process straightforward.)
Let 
. Then the presentation 
 defines a group isomorphic to G. (This is because the relators in D
can be used to eliminate the generators in X using Tietze transformations.)
Now let 
 be the complete set
of monoid generators of G, and define a wreath-product ordering on A* (as
defined in Section 12.4), in which the list of generators, in decreasing order
of levels, is
 
We run the Knuth-Bendix completion algorithm on the presentation 
using this ordering.
If K=1 and G/K=G, then the relations 
 for 1≤j≤
m, together with each of the relations in the xi and their inverses, which
constitute the consistent polycyclic presentation of G/K, will all hold in 
and it is easily seen that they form a complete rewriting system for  with
respect to the specified ordering of A*.
These relations are all essential (at least after writing 
 in normal
form), and will therefore inevitably be generated by the Knuth-Bendix
process provided that we run it for long enough. On the other hand, if
these relations are generated by the Knuth-Bendix process, then it follows
immediately that G is polycyclic. Hence we can, in principal, verify the
polycyclicity of G.
Example 12.4
Let us now work through a moderately straightforward example to illustrate
this process. For group elements , h, the commutator [ , h] is defined to
be 
-1h-1 h, and we define [ , h, k]:=[[ , h], k], etc. The following group
was proved nilpotent theoretically by Heineken in [Hei61].
 
Running the NQA (using the implementation by Nickel described in [Nic93])
reveals that G has a largest nilpotent quotient of class 4, with 6 polycyclic
generators x1,…, x6, I={6} and r6=2.
Since a maps to x1 and b to x2 we have u1=x1, u2=x2, and so we can take
v1=a, v2=b. In fact, in an example like this, we can simplify matters by
identifying a and b with x1 and x2, and we shall rename the generators
x1,…, x6 as a, b, c, d, e, f, respectively.
© 2005 by Chapman & Hall/CRC Press

Rewriting Systems and the Knuth-Bendix Completion Process
431
The relations in the full polycyclic presentation are
 
where we have omitted relations between pairs of commuting generators.
Of these, we can take c=[b, a], d=[c, a], e=[c, b] and f=[d, b] as definitions
of d, e and f, respectively, and so we have
 
and use this as input to the Knuth-Bendix algorithm, with the wreath-
product ordering defined above. In this example, the relations in the
polycyclic presentation were produced very rapidly, thereby verifying
nilpotency.          
Although this particular example was very easy, with more challenging
examples the Knuth-Bendix process can struggle and get itself tied up with
very long words if the implementation is too simplistic. There is a lengthy
discussion of possible techniques for improving the performance in Chapters
2 and 3 of [Sim94], together with implementation details.
For example, it can be a good idea only to store relatively short reduction
equations in the early stages of the process. Although this means that the
resulting set of stored equations may not be complete at the end, it is
relatively easy to verify completeness later by restarting on the enlarged
set of rules, once the polycyclic relations have all been deduced.
A slightly more difficult example is
 
which turned out to be nilpotent of class 7, with 8 polycyclic generators.
12.6 Applications
Applications of the Knuth-Bendix completion procedure within group theory
include verification of nilpotency, as described in the preceding section,
and a recent, more spectacular application by Charles Sims, using his rkbp
package, in which he shows that the Burnside group B(2, 6)=R(2, 6) (cf
Subsection 9.4.7) can be defined with a presentation on 2 generators and
about 60000 relators, all of which are sixth powers. The previous upper
bound on the number of sixth-power relators had been 2124, which was
derived from a careful analysis of the original finiteness proof of B(2, 6) by
Marshall Hall.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
432
The Knuth-Bendix procedure can also be used to help prove that two
finitely presented groups G1 and G2 are isomorphic, and this has led to
some applications outside of group theory. By Theorem 2.52, if we are
given a map θ from the generators of G1 to G2 then, if we can prove that the
images in G2 of the defining relators of G1 are equal to the identity in G2,
then we will have proved that θ extends to a homomorphism from G1 to G2.
By running Knuth-Bendix on the presentation of G2, we may be able to
collect enough reduction equations in G2 to carry this out. It is not necessary
to obtain a complete rewriting system for G2 for this purpose. Indeed, if θ
really does extend to a homomorphism then, if we run Knuth-Bendix for
long enough, we will be able to verify this fact. If θ happens to extend to an
isomorphism from G1 to G2, then we can also verify this fact, by constructing
its inverse map from G2 to G1 and checking that this is also a homomorphism.
The above process is described in more detail by Holt and Rees in [HR92],
together with the authors’ implementation of a procedure that attempts to
prove that G1 and G2 are isomorphic by systematically searching for an
isomorphism θ. Because of the huge search-space involved, this process
can only succeed if the images of the generators of G1 under θ are short
words in the generators of G2 but, even so, it has on occasion been
successfully applied.
One such application occurred in the classification of flat 4-manifold groups
by Hillman in Section 8.4 of [Hil02]. For example, for
 
and
 
it was proved that
 
extends to an isomorphism G1→G2 with
© 2005 by Chapman & Hall/CRC Press

433
Chapter 13
Finite State Automata and
Automatic Groups
In this final chapter, we shall describe the principal algorithms for computing
automatic structures associated with automatic groups. For some types of
infinite finitely presented group, they provide the only computational tool
that is currently capable of deciding important structural properties, such
as the finiteness or infiniteness of the groups concerned.
The algorithms have been implemented as the major component of Holt’s
KBMAG package. An earlier version was programmed by Holt, in
collaboration with David Epstein and Sarah Rees. The papers [EHR91] and
[Hol95] describe the procedure and this earlier implementation.
These methods involve finite state automata, which we shall abbreviate,
in both singular and plural, as fsa. For background information on the
theory of fsa and the related theory of regular languages, the reader should
consult a textbook on formal language theory, such as [HMU01]. Here, we
shall be concerned with algorithms for constructing and manipulating them,
and with their applications to CGT, of which there are several. For example,
they can be used to reduce words to their S-reduced form with respect to a
finite rewriting system S.
The definition of the class of automatic groups evolved in the mid-1980s
following the appearance of a paper by Jim Cannon on groups acting discretely
and cocompactly on a hyperbolic space [Can84]. Thurston noticed that some
of the properties that were proved about these groups could be reformulated
in terms of finite state automata, which gave rise to the definition that is
currently in use. The most comprehensive reference on automatic groups is
by D.B.A.Epstein and coauthors in the six-author book [ECH+92], and we refer
the reader to that book for further information and references.
From the viewpoint of CGT, what is important is that there are
procedures, which take a finite group presentation as input, and attempt
to construct a collection of finite state automata that form an automatic
structure for the presentation. These procedures involve the use of the
Knuth-Bendix completion process described in the previous chapter, but
they are capable of succeeding even when Knuth-Bendix alone does not
terminate with a complete set of rewrite rules, and they also involve the
construction and manipulation of various fsa.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
434
If successful, then they prove that the group is automatic, and they enable
words in the group generators to be reduced to a normal form. This in turn,
allows various important properties of the group to be decided or calculated.
For example, the finiteness or infiniteness of the group can be decided, and
its growth function can be computed. So the methods provide a new
computational tool for handling infinite finitely presented groups which, in
several examples, has been successful where all other known methods, both
theoretical and computational, have failed.
In this chapter, we shall give the definition of an automatic group, and
summarize the known properties and examples of these groups. Then, we
shall provide a moderately detailed description (but without going down to
the level of precise pseudocode) of the procedures mentioned above. These
descriptions are taken and adapted from [EHR91] and [Hol95].
13.1 Finite state automata
We start with an account of the algorithms for manipulating finite state
automata that we shall require for the automatic group programs.
13.1.1 Definitions and examples
Let us first collect all of the basic definitions together.
DEFINITION 13.1 For a finite set A is a finite set, we define A′:= A{ε},
where it is assumed that ε  A. A finite state automaton (fsa) M is a quintuple
(Σ, A, , S, F)=(ΣM, AM, M, SM, FM) where Σ (the set of states) and A (the
alphabet) are finite sets, S (the set of start states) and F (the set of final or
accept states) are subsets of A, and  (the set of transitions) is a subset of
Σ×A′×Σ.
A transition (σ1, a, σ2)∈ can also be thought of as an arrow labelled a
from state σ1 to state σ2. It is called an ε-transition if a=ε.
For w=a1a2…ar∈(A)*, a path of arrows labelled w from state σ0 to state
σr is a sequence of transitions (σi–1, ai, σi) for 1≤i≤r.
For w∈(A)* let us denote the word w ∈ A* obtained by deleting all
occurrences of ε from w by ρ(w).
The language L(M)  A* of M is defined as follows. For w∈A*, w∈L(M) if
and only if there exists w∈(A)* with ρ(w)=w, and a path of arrows labelled
w from a start state of A to a final state of A.
Two fsa M1 and M2 with the same alphabet A are called equivalent if
L(M1)=L(M2).
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
435
The fsa M is called (partial) deterministic if |S|≤1, there are no ε-
transitions and, for each σ1∈S and a∈A, there is at most one transition
(σ1, a, σ2)∈τ. We shall abbreviate “deterministic finite state automaton
(automata)” as dfa.
It is called complete deterministic if |S|=1, there are no ε-transitions
and, for each σ1∈S and a∈A, there is exactly one transition (σ1, a, σ2)∈.
Notice that we can convert a partial dfa into an equivalent complete dfa by
adjoining an extra state  to Σ with 
, and adjoining (σ, a, σ) to  for all
σ∈Σ{σ} and a∈A such that there is no transition (σ, a, σ)∈ already. We
put σ∈S if and only if S is empty to begin with.
We shall generally assume throughout this section that |S|=1 for a dfa,
and leave the reader to contemplate any changes needed for the trivial
case when S is empty, in which case L(M) is also empty.
For a dfa M, σ∈Σ and w∈A*, there is at most one state σ such that there
is a path of arrows from σ to σ labelled w, and we define σ
w=σ if σ exists and
say that σ
w is undefined otherwise.
The new state σ used to complete a partial dfa has the property that there
is no word w∈A* with (σ)w∈F; that is, we cannot reach an accept state from
σ. Such a state is called a dead state. Dead states can be removed from a dfa,
yielding an equivalent partial dfa.
Finite state automata are normally studied as part of formal language
theory. The fundamental result in this area about fsa is that a subset of A*
is the language of an fsa (or, equivalently, of a dfa) if and only if it is a
regular language, which means that it can be defined by means of a regular
expression. We refer the reader to Chapter 1 of [ECH+92] or, for a detailed
treatment, to Chapter 3 of [HMU01] for the definitions and a proof of this
theorem. In fact our treatment of fsa and of automatic groups in this chapter
will not involve regular languages.
Example 13.1
A coset table, as defined in Chapter 5, would become a (partial or complete)
dfa with Σ=Ω if we were to specify the sets S and F. The obvious choice for
S is {1}. If we put F={i} for some i∈Ω, then the language is a subset of the
coset Hg corresponding to i, and is the whole of that coset if the table is
complete.
[]
For demonstration purposes, an fsa can be represented by a diagram in
which the states are circles (single circles for nonaccept states and double
circles for accept states), where a start state σ is represented by a small
unlabelled arrow with no source, and target σ. An example with A={x, X,
y, Y} is displayed below. Notice that there are no arrows labelled Y. The
language L(M) of M is finite in this example, and is equal to {ε, x, X, y,
xy, Xy}.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
436
Example 13.2
[]
An alternative method of describing M (which is the one that we used
for coset tables in Chapter 5), is to list the transitions as a table, known as
the transition table of M, where rows are labelled by states, columns are
labelled by alphabet members, and the entry in row σ and column a is σa if
it is defined. If it is undefined, we can either leave the entry blank or put a
0 there. (This is assuming that M is a dfa. For a general fsa, we would need
a column for ε, and table entries would be the subset of all targets of arrows
with source σ and label a.)
In Example 13.2, the table is:
DEFINITION 13.2 Let M=(Σ, A, , {σ0}, F) be a dfa. A state σ∈Σ is said to be
accessible if it can be reached from the start state; that is, if there exists
w∈A* with 
.
Dually, σ∈Σ is said to be coaccessible if there exists w∈A* such that σw∈F.
The dfa M is said to accessible (respectively coaccessible) if all of its states
are accessible (respectively coaccessible).
We say that M is trim if it is both accessible and coaccessible.
Finding the accessible states is easy and can be done using a method similar
to that used in ORBIT in Section 4.1. Inaccessible states can be removed,
together with all of their transitions, to yield an equivalent accessible dfa,
which will be complete if the original dfa was complete.
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
437
We can also remove states that are not coaccessible without changing the
language, but, if we do that, then we may end up with a partial dfa.
Furthermore, locating these states is not as straightforward as for accessible
states so, if we require an equivalent trim automaton, then it is probably
easiest to use the dfa minimization algorithm, which will be discussed in
Subsection 13.1.6. The function FSA-COUNT described in the next
subsection requires a trim dfa as input.
Note also that, if L(M) is empty, then there are no coaccessible states,
and so the only trim fsa that accepts the empty language is one with no
states. (That is the reason why we allowed S to be empty in the definition
of a dfa; many books stipulate that |S|=1 for a dfa.)
13.1.2 Enumerating and counting the language of a dfa
One of the standard operations that one can perform on a dfa M is to enumerate
its language L(M). The following function does this, but lists only those words
w∈L(M) up to a specified length n. The code can easily be modified to remove
this restriction on length, but then it would run forever whenever L(M) was
infinite. It works using a straightforward backtrack search through the words
in A*. With the alphabet A numbered as A=[a1,…, ar], the current word
during the search is ag[1]ag[2]…ag[l], and the states [i] for 1≤i≤l+1 reached
when M reads the prefix of this word of length i–1 are also stored. We interpret
σa=0 to mean that the transition σa is undefined.
FS A-ENUMERATE(M, n)
Input: dfa M=(Σ, A=[a1,…, ar], , {α}, F), 
Output: List L of words w∈L(M) with |w|≤n
1
L:=[]; l:=0; g:=[]; ς[1]:=α;
2
repeat
3
if ς[l+1]∈F then APPEND(~L, ag[1]ag[2]…ag[l]);
4
ß:=(l=n);
5
if not ß
6     
then l:=l+1; g[l]:=0; ß:=true;
7
while ß and l>0
8     
do ß:=false;
9     
    g[l]:=g[l]+1;
10     
while 
11     
if g[l]≤r
12     
     then 
;
13     
     else l:=l–1; ß:=true;
14
until l=0;
The search through A* undertaken by FSA-ENUMERATE is known as a
depth first search, which means that the words in A* are considered in
increasing order using the ‘lexicographical order’ (see Definition 2.59) with
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
438
respect to the ordering a1<a2<…<ar of A. Hence the words occur in this order
in the list returned.
We may prefer to have the words ordered according to the shortlex ordering
(corresponding to a breadth first search through A*), in order to get all of the
shorter words occurring before longer words. We can achieve this by modifying
FSA-ENUMERATE such that it outputs only those words that have length
exactly n, and then running FSA-ENUMERATE(M, k) for k=0, 1, 2,…, n.
This will take a little longer than for the ‘lexicographical order’, but since the
running time of FSA-ENUMERATE(M, k) is usually exponential in k, the
increase in time is rarely critical.
If we are only interested in the cardinality |L(M)| of the accepted
language, then we can compute this much more quickly than by
enumerating L(M), although the function below requires the input dfa M
to be trim.
FSA-COUNT(M, n)
Input: Trim dfa M=(Σ, A, , {α}, F)
Output: |L(M)|
1
for σ∈Σ do δσ:=|{(σ, a, σ)∈ | σ ∈ Σ, a∈A}|;
2
ς[1]:=α;
3
if δ[1]>0 then return ;
4
k:=1; c:=1;
5
while k≤c
6
do for a∈A
7
do if σ:=ς[k]a is defined
8
then δσ:=δσ–1;
9
if δσ=0 then c:=c+1; ς[c]:=σ;
10
k:=k+1;
11
if c<|Σ| then return ;
12 for k∈[c..1 by –1]
13
do σ:=ς[c];
14
if σ∈F then γσ:=1; else γσ:= 0;
15
for a∈A
16
do if σ:=σ
a is defined then γσ:=γσ+ γσ’;
17 return γ[1];
The above function requires some explanation! Since M is trim, if M contains
a circuit of arrows—that is, a nonempty word w and a state α with σ
w=σ—
then L(M) is infinite, because w1wnw2∈L(M) for all n≥0, where w1 is a word
sending the start state to σ and w2 is a word sending σ to a final state.
The algorithm consists of three main steps. In the first step, at line 1,
for each σ∈Σ we calculate the number δσ of arrows of M with target σ. If this
is nonzero for the start state, then, since M is trim, M has a circuit based at
the start state and L(M) is infinite.
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
439
In the second step, starting at line 4, we attempt to order the states in Σ as
ς[1], ς[2],… such that ς[1] is the start state, and i<j for all arrows (ς[i], a, ς[j])
of M. Initially, only ς[1] is defined. We then consider ς[i], for i=1, 2,… in turn,
and for each arrow (ς[i], a, σ) with source ς[i], we subtract one from δσ. If this
reduces δσ to 0, then we know that all arrows with target σ have been accounted
for, and their sources must all be in the currently defined list ς. Hence we
can append σ to the end of the list of defined states ς[i], and the required
property will hold for ς.
After the ‘While’ loop at line 5 exits, if the list ς does not contain all
states of Σ, and Γ is the set of states not in ς, then δσ>0 for each σ∈Γ (since
otherwise it would have been appended to ς), and so there must be at least
one arrow with target σ and with its source in Γ. (All arrows with source in
the list ζ were subtracted off from δσ during the ‘While’ loop.) This implies
that there is a circuit of arrows within Γ, and so L(M) is infinite. (To see
that there must be a circuit within Γ, choose σ∈Γ and trace a path of arrows
backwards, starting from σ. We must eventually reach a state that we have
already visited.)
So suppose that ς contains all states of Σ after completing the ‘While’ loop
at line 5. Then we have succeeded in ordering the states of Σ with the property
described above. In the third main step, starting at line 12, for each state σ,
we count the number γσ of words w∈A* such that σ
w∈F. This is clearly equal
to the sum of the numbers γσ over all arrows (σ, a, σ) with source σ plus an
extra one, for w=ε, if σ∈F. Since all arrows go from ς[i] to ς[j] with i<j, we
can calculate γς[i] for all i by running through the list ς in reverse order,
and then |L(M)|=γς[1], which is finite in this situation.
13.1.3 The use of fsa in rewriting systems
In practice, in implementations of the Knuth-Bendix completion process on
finite rewriting systems S over A*, most of the time is taken up in reducing
words to equivalent irreducible words using the rules in S. This process can
be rendered much more efficient by the use of a certain dfa Ms, which we
shall describe briefly in this section.
The alphabet of Ms is A and Σ=Σs is defined to be the set of all prefixes of
all left-hand sides of rules in S. The start state is ε. The set F of final states
is the set of proper prefixes of left-hand sides of rules. For σ∈F and a∈A, σa is
defined to be the longest suffix of σa that lies in Σ. For σ ∈Σ\F, σ
a is undefined
for all a∈A. So the nonaccept states, all of which are complete left-hand sides
of rules, are dead states.
It is straightforward to show by induction on |w| that, when M reads a
word w∈A*, then εw is either undefined or is equal to the longest suffix v of w
with v∈Σ.
Let us assume that S is reduced, and hence that no left-hand side of any
rule of S is a proper substring of any other left-hand side. Then the nonfinal
states of MS are exactly the left-hand sides of rules. Furthermore, if
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
440
w=w1w2w3, where w2 is the left-hand side of a rule, and is the first occurrence
of the left-hand side of a rule in w, then after reading the prefix w1w2 of w,
M will be in the dead state w2. So L(MS) is equal to the set of S-irreducible
words.
To use S to reduce words, we read w into MS, and if we find εw
1
w
2=w2 is a
dead state for a prefix w1w2 of w, then we locate the rule (w2, v2)∈S, replace w2
by v2 in w, and restart the process. (Or, for greater efficiency, if we remember
the ‘state history’ of M reading w1w2, then we can restart reading the modified
word w into M after w1 and before v2.)
For example, consider the complete rewriting system for the dihedral
group of order 6 with A={x, X, y, Y} that we considered in Example 12.2. Let
us number the states Σ of MS as follows:
 
So F={1, 2, 3 ,4} and the dead states are those with negative numbers. The
transitions are as follows:
Notice that this is the same as Example 13.2, except that we have replaced
the undefined transitions by transitions to numbered dead states. This
type of fsa is sometimes called an index automaton because the dead states
provides an index to the reduction rules of S.
For example, let us use this fsa to reduce the word w=yxYX. On reading
the first letter y of W, M moves from state 1 to 1y=4, and then 4x is the dead
state –8, which represents the left-hand side of the rule (yx, Xy)∈S, so Ww
is replaced by XyY X. We then get 1Xy=4, 4Y=–1, so we use (Y,y)∈S to replace
Y by y, giving w=XyyX. Then 1Xy=4, 4y=–6, and we use (yy, ε)∈S and replace
w by XX. Finally, 1X=3, 3X=–5, and we use (XX, x)∈S, and replace w by x.
Now 1w=1x=2, an accept state, so w is irreducible.
If S is not reduced, then MS may sometimes fail to notice a substring w2
of w which is a left-hand side of a rule but is also a proper substring of the
left-hand side of another rule. Hence it may accept and fail to reduce some
S-reducible words. This is not disastrous provided that S is reduced at
regular intervals during the Knuth-Bendix completion process.
We shall not go into the details of the algorithm for constructing MS
from S here, and refer the reader to Section 3.5 of Sims’ book [Sim94] for
the code for doing this. During the Knuth-Bendix completion process, the
set S of rules is continually changing, and so MS needs to be reconstructed
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
441
very frequently. It is therefore vital to use an efficient implementation of
the construction of MS. The fsa MS can also be used to speed up the search
for critical pairs; this usage is also discussed in detail in Section 3.5 of
[Sim94],
A disadvantage of using MS for word reduction is that MS will often use
more memory than S itself. There are other methods of string reduction,
such as one using the Rabin-Karp string-matching algorithm, which are
slower but use much less memory.
13.1.4 Word-acceptors
DEFINITION 13.3 If 
 is a finitely presented group and A:=
X∪X–1, then a finite state automaton W with input alphabet A is called a
word-acceptor for G if it accepts at least one word in A* for each group
element. It is called a unique word-acceptor for G if it accepts a unique
word for each group element.
We could define (unique) word-acceptors in the same way for finite monoid
presentations, but we shall be concerned almost exclusively with groups in
this book.
Suppose that S is a rewriting system for a finitely presented group, as
described in Section 12.3. The rules in S all have the form (w1, w2) where
w1=G w2 and w1>w2 in the reduction ordering on A* used to define S. Let us
say that a word w is <-minimal (for the ordering <) if there is no v∈A* with
v<w and v=G w. So the <-minimal words are precisely the minimal elements
of the classes of the equivalence relation ↔* defined on A* by S.
The <-minimal words are certainly S-irreducible, and so they lie in L(MS),
where the fsa MS is defined as in the preceding subsection. Hence MS is
word-acceptor for G. If S is complete, then L(MS) contains only the <-minimal
words, and then MS is a unique word-acceptor for G.
If W is a unique word-acceptor for a group, such as the fsa MS for a finite
complete rewriting system S for the group, and we apply FSA-ENUMERATE
to W, then we get exactly one representative for each group element. In
that case, we can calculate the order of G, and hence decide whether G is
finite or infinite, by applying FSA-COUNT to W.
If W is a word-acceptor but not a unique one, then we get more than one
representative for some group elements but, in the case of W=MS, if we
have run the Knuth-Bendix process for a long time, then it may well happen
that there is no repetition of group elements on short words. Some of the
most important applications that this subject has found have been outside
of group theory, and in fields such as hyperbolic geometry and ergodic
theory. In these applications, all that is required is to enumerate the group
elements with as little repetition as possible.
A further application worth mentioning is to the calculation of growth
functions. For an fsa M, let α(n) denote the number of accepted words of M
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
442
of length n. Then the function 
 is called the growth function
of M, and it turns out that this is a rational function of t that can be calculated
from M. We shall not discuss this algorithm here, but refer the interested
reader to [EIFZ96].
If W is a unique word-acceptor for a group, and all accepted words are
shortest possible for the group element that they represent, then the growth
function for W is the same as that for G. This can be calculated if we can
find a finite complete set S using a shortlex ordering on A*.
Unfortunately, it is only rarely that we can find a complete rewriting
system for an infinite group. In Section 13.2 below, we shall study a different
possibility for constructing a unique word-acceptor for G.
13.1.5 2-variable fsa
The theory of automatic groups involves fsa that read two words w1, w2∈A*
simultaneously. We can almost do this by using a fsa with alphabet A×A,
but this does not work if |w1|≠|w2|. To deal with words of unequal length,
we introduce an extra alphabet symbol $, known as a padding symbol,
which is assumed not to be in A, and use it to pad the shorter of the two
words at the end, so that the resulting padded word has the same length as
the longer word.
To be precise, let A+:=AU{$}, and let w1, w2∈A* with w1=a1a2…al and
w2=b1b2…bm with each ai, bi∈A. Then we define (w1, w2)+∈ (A+×A+)* to be the
word (α1, ß1) (α2, ß2)…(αn, ßn), where n:=max(l, m), and
(i)
αi=ai for 1≤i≤l and αi=$ for l<i≤n;
(ii) ßi=bi for 1≤i≤m and ßi=$ for m<i≤n.
For example, if w1=abc and w2=d, then (w1, w2)+=(a, d) (b, $) (c, $).
We define a 2-variable fsa M over the alphabet A to be a fsa with alphabet
A+×A+ with the property that all words in L(M) are of the form (w1, w2)+ for
words w1, w2∈A*. Notice that ($, $) never occurs in an accepted word of M, so
we could, if we wished, take the alphabet to be A+×A+\{($, $)}, and some
authors do this.
We can define an n-variable fsa over A for any n>1 in a similar way. In
fact, the construction of the composite of two 2-variable fsa, which we shall
discuss below in Subsection 13.1.7, involves a 3-variable fsa.
13.1.6 Operations on finite state automata
The procedures for computing the fsa for automatic structures of automatic
groups that we shall be describing in Section 13.2 involve two main
components. The first is the Knuth-Bendix completion process, which we
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
443
have already discussed, and the second is the use of various operations on
fsa, which we shall describe in this and the following subsection.
We shall assume that all fsa arising in this subsection have the same
fixed alphabet A. The general idea is that we are given one or more fsa as
input, from which we want to construct another fsa. The first two algorithms
construct a dfa equivalent to the input fsa. Given a general fsa we describe
how to construct an equivalent dfa, and given a dfa, we describe how to
construct an equivalent dfa with the smallest possible number of states.
This minimization algorithm also enables us to test two dfa for equivalence.
The other algorithms all take one or two dfa M1 (and M2) as input. They
output a dfa whose language is one of various simple functions of L(M1) and
L(M2). These include ¬L(M1):=A*\L(M1), L(M1)∩L(M2), L(M1)L(M2),
L(M1)L(M2) and L(M1)*. The last two of these are defined as follows.
DEFINITION 13.4 If L, L1, L2  A*, then
(i)
L1L2:={w1 w2| w1∈L1, w2∈L2};
(ii)
L0:={ε} and Ln:=LLn–1 for n>0;
(iii)
.
We shall merely explain how these algorithms work, without writing out
detailed code for them. One reason for this is that the code in a practical
implementation involves techniques such as hashing (see, for example the
detailed treatment by Knuth in [Knu73]), which we do not want to discuss
in detail here. We shall, however, make some general comments on
implementation questions later on.
13.1.6.1 Making an fsa deterministic
Let us start with the algorithm for finding a dfa equivalent to a general fsa.
Computations with dfa are generally much more efficient than those with
equivalent fsa, and all of the other algorithms to be discussed require a dfa
as input. Unfortunately this gain in efficiency comes at a price. For an fsa
with state-set Σ, the state-set of the equivalent dfa that we shall construct
is a subset of the power set P(Σ) of Σ. (By definition, P(Σ) is the set of all
subsets of Σ.) So, if the original fsa has n states, then the equivalent dfa can
have up to 2n states, and there are examples (see exercise below) in which
the minimal possible number of states of an equivalent dfa is 2n–1. This
exponential blowup in the number of states is the underlying reason why
many fsa algorithms, including those for computing with automatic groups,
can have very large memory requirements.
If the fsa M with state-set Σ has no ε-transitions, then we proceed as
follows. We define M with state-set P(Σ), put SM':={SM}, and let FM' be the
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
444
set of all elements of P(Σ) that contain a set in FM. For ϒ∈P(Σ) and a∈A, we
define
 
It is straightforward to show that L(M′)=L(M).
If M has ε-transitions, then we make the following modification. For each
ϒ∈P(Σ), define the ε-closure ε(ϒ) of ϒ as follows. Let ε0 (ϒ):=ϒ and, for n>0,
let
.
This is an ascending sequence of subsets of Σ, and we define ε (ϒ) to be the
largest subset in the sequence.
The state-set of M′ is now defined to be {ε (ϒ)|ϒ∈P(Σ)}, the start state of
M′ is set equal to ε(SM), and the transition ϒa of M′ is defined to be the
ε-closure of ϒa as defined above.
Allowing ε-transitions is an extra complication for the determinization
algorithm, but it is worthwhile, because the constructions of the fsa cat(M1,
M2) and M* to be described in Subsubsection 13.1.6.5 below would be
considerably more complicated without ε-transitions.
In practice, we would begin by constructing the start state of M′, and
then define new states as required as the targets of transitions from states
already defined, using code like that in ORBIT in Section 4.1. Then we
would only ever need to define and store the accessible states of M′; in
many examples, including those arising in the automatic groups procedures,
only a small number of the elements of P(Σ) are accessible; indeed, if that
were not the case, then these methods would be totally impractical!
13.1.6.2 Minimizing an fsa
The next algorithm to be discussed is one for finding a dfa with a minimal
number of states that is equivalent to a given dfa M. We shall see that this
minimal dfa is unique up to the naming and ordering of its states. We start
by summarizing the theory of the method. The reader could consult Section
4.4 of [HMU01] for a more detailed and leisurely treatment.
For a subset L of A* and w∈A*, define L(w):={v∈A*|wv∈L}. We say that
w1, w2∈A* are L-equivalent and write w1~L w2 if L(w1)=L(w2). Notice that
w1~L w2 
 w1a~L w2a for all a∈A, so ~L is a right congruence on A*.
If there are only finitely many L-equivalence classes, then we can define
a complete dfa ML with language L, as follows. Let [w] denote the ~L-class
of w∈A*. The states of ML are the L-equivalence classes, the start state is
[ε], and [w] is a final state if and only if w∈L (note that w∈L iff ε∈L(w), so
this is well-defined). The transitions are defined by [w]a=[wa]; these are well-
defined because ~L is a right congruence. To see that L(ML)=L just note that
[ε]w=[w] for all w∈A*.
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
445
Suppose now that M=(Σ, A, , {σ0}, F) is a complete accessible dfa with
L(M)=L. For σ∈Σ, define L(σ):={v∈A*|σv∈F}. Then L(σ)=L(w) for any w∈A*
with 
. Hence all such words w are L-equivalent. We say that σ1, σ2∈Σ
are L-equivalent, if words w1, w2 with 
 are L-equivalent (w1, w2
exist because we are assuming that M is accessible.) Then each L-equivalence
class of states corresponds to an L-equivalence class of words in A*, and all
such L-equivalence classes of words occur in this way. Hence each state of
ML corresponds to an L-equivalence class of Σ. This shows that ML is the
unique (up to naming of states) complete dfa with a minimal number of
states and language L.
Since ML has at most one dead state, consisting of those w with L(w)
empty, we get the unique minimal partial dfa with language L by removing
this dead state if it exists. We would do this if we wanted an equivalent
trim dfa; as input for FSA-COUNT, for example.
We now describe an algorithm to construct ML when M=(Σ, A, τ, {σ0}, F)
is a given dfa with L(M)=L. By adding a dead state if necessary, we can
assume that M is complete and, by removing inaccessible states, we can
assume that M is accessible. The problem is then to decide which states of
M are L-equivalent. The cases F=φ and F=Σ, corresponding to L=φ and
L=A* are easy: ML has a single state in those cases. So let us assume that
F is a proper nonempty subset of Σ.
If σ1 ~L σ2, then 
 for all a∈A, so ~L is a right congruence.
Furthermore, if σ ∈F and 
, then 
. In other words, ~L is a
refinement of the equivalence relation ~F on Σ that has just the two classes
F and Σ\F.
Let ~ be any right congruence on Σ that is a refinement of ~F. We claim
that ~ is a refinement of ~L. To see this, observe that σ1~σ2 implies 
for any w∈A* and hence 
 iff 
, so σ1~L σ2.
So our task is to compute the coarsest (or largest) right congruence on Σ
that is a refinement of ~F. Note that this is the dual of the problem considered
in Sections 4.3 (finding block systems of permutation groups) and 5.1 (the
coincidence routine in coset enumeration), where we wanted the smallest
right congruence that contained a given equivalence relation.
The most straightforward way of computing ~L is as follows. We start by
putting σ:=σF. The method consists of a sequence of passes. On each pass,
we check whether σ is a right congruence. If not, we replace it by a proper
refinement σR with the property that any right congruence refining σ must
also refine σR, and perform another pass. This process must clearly
terminate with σ=σL. The refinement σR is defined from σ as follows. For
σ1, σ2∈Σ, σ1~R σ2 if and only if σ1~σ2 and 
 for all a∈A.
Example 13.3
Let A=[a, b], Σ={1.. 9} S={1}, F={6, 7, 8, 9}, where the transitions of S are as
follows:
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
446
 
Then L(M) consists of all words that contain at least one of aba, abb, baa,
bab as a substring. It has been constructed in a similar way to the construction
of MS as defined in Subsection 13.1.3. The states 1.. 9 correspond to the
word w read so far having the suffix ε, a, b, ab, ba, aba, abb, baa, bab,
respectively, but we have put σa=σb=σ for all σ∈F.
At the beginning of the first pass, we have two σ-classes, {1, 2, 3, 4, 5} and
{6, 7, 8, 9}. After the first pass, the first of these splits into {1, 2, 3} and {4, 5}.
During the second pass, the first of these splits into three separate classes,
{1}, {2} and {3}. The third pass reveals that we now have a right congruence,
so the algorithm terminates after three passes, with 5 L-classes.
The resulting minimized dfa has 5 states {1.. 5} corresponding to the
classes {1}, {2}, {3}, {4, 5}, and {6, 7, 8, 9} of M. We have S={1}, F={5}, and the
transitions are:
[]
One problem with this algorithm is that its complexity is Θ(|A|n2), where
n=|Σ|. This is because each pass has complexity Θ(|A|n), and there are
examples that require n–1 passes (see exercise below). It is, however, very
efficient in terms of space requirements: the total memory used is typically
less than twice that taken by the input dfa M and, since the transition table
of M is always accessed sequentially during a given pass, it can be kept in
a file on disk if necessary and read in as required. In applications to the
automatic groups procedures, we need to minimize some very large fsa
that have typically arisen through determinizing a nondeterministic fsa,
and memory constraints tend to be more critical than time constraints.
Furthermore, the number of passes required in typical applications is much
less than n.
An O(|A|n log(n)) algorithm for solving this problem is described in
[Hop71] by J.E.Hopcroft, but its memory requirements are unclear to the
author. Even a requirement of twice the space taken by the original fsa
would be unacceptably large for the automatic groups applications.
13.1.6.3 Testing for language equality
We have just seen that, for a given language L of an fsa, there is a complete
dfa ML with a minimal number of states having that language, which is
unique up to the labelling of the states. So, if we number the states 1.. n
with n=|Σ|, then ML is unique up to the order of the states.
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
447
We now recall the procedure STANDARDIZE that we introduced in
Subsection 5.2.3 to standardize the order of the cosets in a coset table. We
can apply STANDARDIZE to the transition table of a dfa to permute the
states so that they occur in a standard order, corresponding to the order in
which they would occur if we applied ORBIT to the initial state of M. This
produces a canonical complete dfa for L.
So, if we wish to test whether L(M1)=L(M1) for two dfa M1 and M2, then
we minimize and standardize both, and then just check whether the
resulting dfa are identical.
13.1.6.4 Negation, union, and intersection
Given a complete dfa M, it is very easy indeed to define a dfa with language
¬L(M)=A*\L(M). We simply replace FM by ΣM\FM.
Given dfa M1 and M2, we can define dfa with languages L(M1) ∪L(M2) and
L(M1)∩L(M2) as follows. In both cases, we define the state-set to be 
,
the set of start states to be 
, and the set of transitions to be
 
.
A state (σ1, σ2)∈ 
 is defined to be a final state of L(M1)∪L(M2) if
 or 
; and it is a final state of L(M1)∩L(M2) if 
 and
. We leave readers to convince themselves that the dfa that we
have defined have the required language.
As was the case for the subset construction of dfa from a general fsa defined
in Subsubsection 13.1.6.1, when we construct the dfa for L(M1)∪L(M2) and
L(M1)∩L(M2), in practice, we do not explicitly define the whole set 
initially. Instead, we begin with just the start state and then construct those
states in 
 that are accessible from the start state.
13.1.6.5 Concatenation and star
Let M1 and M2 be fsa. We define an fsa cat(M1, M2) with accepted language
L(M1)L(M2) as follows. By renaming the states of M2 if necessary, we assume
that 
 and 
 are disjoint, and define 
where 
 We define 
 and 
The transitions of cat(M1, M2) consist of those of M1 and M2, together with
e-transitions from the final states of M1 to σ, and ε-transitions from σ to the
start states of M2. That is:
 
.
So a path of arrows for a word accepted by cat(M1, M2) has the form
p1p2p3p4, where p1 is a path of arrows for an accepted word through M1, p2 is
an ε-arrow from a state in 
 to σ, p3 is an ε-arrow from σ to a state in 
,
and p4 is a path of arrows for an accepted word through M2. Hence L(cat(M1,
M2))=L(M1)L(M2), as required.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
448
Of course, if we want a dfa with language L(M1)L(M2), then we will need to
apply the algorithm described in Subsubsection 13.1.6.1 to cat(M1, M2).
Let M be a fsa. The construction of an fsa M* with language L(M*) is of
a similar nature to that for L(M1)L(M2). The state-set of M* is ΣM∪{σ}, where
σ  ΣM. The additional state σ is the only start state and the only final state;
that is 
 The transitions of M* include all transitions of
M and, in addition, ε-transitions from σ to the start states of M and from the
final states of M to σ. That is:
. 
13.1.7 Existential quantification
Let M be a 2-variable dfa over A. It is straightforward to construct an fsa 
over A with language {w∈A*|
 ∈A*×A*:(w, v)+∈L(M)}. To do this, we let
the state-set, the start states, and the final states be the same for 
 as for
M. We replace a transition (σ1, (a, ß), σ2) of M by a transition (σ1, a′, σ2) of 
,
where ′= if ∈A and ′=ε if =$.
Then, for any accepting path of arrows of 
 with label 
 there is a
corresponding accepting path of M with label (1, ß1)…(r,ßr) for some ßi∈A+.
By definition of a 2-variable fsa, M accepts only words of the form (w1, w2)+ for
w1, w2∈A*, and so any occurrences of ε in the path 
 must occur at the
end of the word. The corresponding accepted word of ε is then just 
with any trailing ε symbols removed, which is precisely the word w1 for which
(1, ß1)…(r, ßr)=(w1, w2)+. Hence the language of 
 is as required.
As was the case for cat(M1, M2) and for M*, the fsa 
 is nondeterministic
in general, and so we need to apply the subset construction from
Subsubsection 13.1.6.1 to get an equivalent dfa. This process often results
in a substantial increase in the number of states. In practice, even the
minimized version of an equivalent dfa for 
 can have very many more
states than the original nondeterministic version; see exercise below.
An fsa 
 with language {w∈A*|
∈A*×A*:(w, v)+∈L(M)} could be
constructed if required by using the fact that 
, where M′
is a 2-variable fsa with language ¬L(M).
In some applications, for a given 2-variable fsa M and a word w∈A*, we
need to test whether w∈L(ME) and, if so, to find a specific word v with (w,
v)+ ∈L(M). The following function achieves this aim. A brief explanation of
the algorithm will follow the function itself, but the reader needs to be
aware of one point of notation. A list S is constructed, where each S[i] is
itself a list of triples (σ, a, ρ), where σ and ρ are states of M, and ∈A{ε}.
Within the function, the notation S[i][3] should be understood as meaning
. 
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
449
EXISTSWORD(M, w)
Input: 2-variable dfa M=(Σ, A, τ, {σ0}, F), w=a1a2…an∈A*
Output: v∈A* with (w, v)+ ∈L(M), or false if no such v exists
1
for i∈[1.. n]
2
do if i-1 then S:=[σ0]; else S:=S[i–1][3];
3
S[i]:=[];
4
for (σ, a)∈S×A+
5
do if 
6
then 
;
7
if S[i]= [] then return false;
8
i:=n;
9
if i=0 then f:=(σ0∈F); else 
;
10 while S[i] ≠ [] and not f
11
do S:=S[i][3]; i:=i+1; S[i]:=[];
12
for (σ, a)∈S×A
13
do if 
14
then APPEND(~S[i], (s, a, s($,a)));
15
;
16 if not f then return false;
17 Choose σ ∈S[i][3]∩F;
18 v:=ε;
19 for j∈[i..1 by –1]
20
do Find (ρ, a)∈S×A with (ρ, a, σ)∈S[j];
21
v:=av; σ:=ρ;
22 return v;
In the ‘For’ loop of the function beginning at line 1, we read the input word
w=a1…an and, for each prefix wi:=a1…ai, we store a list S[i] of triples (σ, a,
ρ). The third components of these triples are those ρ∈ΣM for which
 for some word 
. The first two components specify
the relevant transition of M of which ρ is the target, and enable the word 
to be reconstructed later.
At the end of the ‘For’ loop, if S[n] contains a success state, then there
exists v with (w,v)∈L(M) and we set the variable f to true. Otherwise it is
still possible that there is v∈A* with |v|>|w| and (w, v)+∈L(M). In the
‘While’ loop at line 10, we test for this by appending the padding symbol to
the end of w until no new states appear in the S list. (This is similar to the
process of computing the ε-closure of a subset of states when we determinize
a nondeterministic fsa.)
At the end of this loop, if we have found a success state as a third
component of a triple in S[i] for some i≥n, then there exists v∈A* with (w,
v)+∈L(M), and f is set to true. The word v is reconstructed in reversed
order in the section of the function beginning at line 18, by using the triples
in S[i] to trace back through the transitions in v in 
.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
450
We shall also require a related but slightly more complicated construction.
Let M1 and M2 be two 2-variable dfa over A. Then we define their composite
M12 to be a 2-variable fsa with language
 
To construct M12, we first construct a 3-variable fsa 
 with language
 
The state-set of 
 is Σm1×Σm2; the start state is (σ1, σ2), where σ1 and σ2
are the start states of M1 and M2, respectively; the final states are (σ1, σ2),
where σ1 and σ2 are final states of M1 and M2, respectively; and the transitions
are 
 where the transitions in the right-hand side
are transitions of M1 and M2, respectively. There are some additional
technicalities concerning the padding symbol that need to be got right, and
which we leave to the reader! We then construct M12 from 
, by quantifying
over the second variable, in the same way that we defined ME from M.
Of course, we only actually define those states of 
 that are accessible
from the start state but, even so, it will generally have many more states
than M1 and M2. The determinization of the nondeterministic fsa M12
resulting from the quantification can then result in the equivalent dfa having
a very large number of states.
Exercises
1.
If L is the language of an fsa, show that there is an fsa with the reversed
language LR:={anan–1 …a1|a1a2…an∈L}.
(Hint: Reverse the direction of all arrows, and interchange S and F.)
2.
Let A:={0, 1} and, for n>0, define Ln:=A*{1}An–1. In other words, Ln consists
of all words in A* that have length at least n and have a 1 in the n-th
position before the end. Show that there is an fsa M with n+1 states and
L(M)=Ln, but that any dfa having language Ln has at least 2n states.
(Hint: For the second part, show that there are 2n distinct sets Ln(w):=
{v∈A*|wv∈Ln}, one for each w∈A* with |w|=n.)
3.
Let n∈ and define a dfa Mn with A={a}, Σ=[1. .n], S=F={1}, and ia=i+1
mod n for i∈Σ. So L(M)=(an)*. In fact Mn already has a minimal number
of states, but show that the minimization procedure described in
Subsubsection 13.1.6.2 takes n–1 passes to prove this.
4.
Use the example in Exercise 2 to construct a 2-variable dfa M over {0, 1}
with n+1 states, with the property that any dfa with language equal to
 has at least 2n states.
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
451
13.2 Automatic groups
We are now ready to proceed to the main topic of this chapter, automatic
groups.
13.2.1 Definitions, examples, and background
DEFINITION 13.5 Let G be a group that is generated as a monoid by the
set A. Then G is said to be automatic (with respect to A), if there exist fsa
W, and Mx for each x ∈ A ∪ {ε}, such that:
(i) W has input alphabet A, and is a word-acceptor for G (cf Definition
13.3);
(ii) Each Mx is a 2-variable fsa over A and, for v, w ∈ A*, (v, w)+ ∈ L(Mx) if
and only if v, w ∈ L(W) and vx =G w.
The collection of automata W and Mx is known as an automatic structure
for G. The Mx are known as the multiplier automata.
It is called an automatic structure with uniqueness if W is a unique
word-acceptor for G.
The idea is that the fsa Mx recognizes multiplication on the right by x in
L(W). We have not insisted that W should be a unique word-acceptor for G;
this is not necessary in general, because the fsa Mε can be used to decide
whether two words in L(W) represent the same element of G. Note that W
is a unique word-acceptor if and only if L(Mε)={ (w, w) | w ∈ L(W)}.
There are a number of equivalent definitions of automatic groups, and
some other related definitions such as asynchronously automatic groups,
in which the two words in Mx may be read at different speeds, and
biautomatic groups in which multiplication by a generator on the left in
L(W) can also be recognized by an fsa. See [ECH+92] for details.
It is proved in Theorem 2.4.1 of [ECH+92] that automaticity is a property
of G and does not depend on A; that is, if G is automatic with respect to one
monoid generating set, then it is automatic with respect to any other. We
can therefore unambiguously say that G is an automatic group. We shall
assume for the remainder of this section that A is chosen to be X ∪ X–1 for
some set X of group generators of G.
The algorithms that we shall be describing are only able to compute
shortlex automatic structures, which we shall now define.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
452
DEFINITION 13.6 The group 
 is said to be shortlex automatic
with respect to X, if it has a shortlex automatic structure. That is, an
automatic structure W, Mx(x ∈ A ∪ {ε}) with uniqueness in which W accepts
precisely the minimal words for the group elements under some shortlex
ordering of A*. (See Definition 2.60. Such an ordering will of course depend
on a given ordering of A.)
In other words,
 
where ≤s is the shortlex ordering of A* derived from the given ordering of A.
Unfortunately, for a given A, a group can be automatic, but not shortlex
automatic with respect to any ordering of A; see Section 3.5 of [ECH+92] for
an example. A group can also be shortlex automatic with respect to one
ordering of A but not with respect to a different ordering; see exercise
below. It is unknown whether every automatic group is shortlex automatic
with respect to some ordering of some monoid generating set of G.
Here is a quick summary of some of the basic properties of automatic
groups and some of the known classes of examples. See [ECH+92] for details
unless otherwise indicated.
All automatic groups have finite presentations. The word problem is
solvable in quadratic time in an automatic group. It is not known whether
the conjugacy problem is solvable in automatic groups in general, but it is
known to be solvable in biautomatic groups. It is also unknown whether all
automatic groups are biautomatic.
The hyperbolic groups considered by Jim Cannon in [Can84] are
automatic; in fact, word-hyperbolic groups, as defined by Gromov, are
shortlex automatic and are biautomatic with any any ordering of any finite
generating set. This class includes free groups, and various small
cancellation groups. See the multiauthor paper [ABC+91] or the book by
Ghys and de la Harpe [GdlH90] for further details on word-hyperbolic groups.
Other groups satisfying various small cancellation hypotheses are also
automatic; see the paper by Gersten and Short [GS91].
Euclidean groups (that is, extensions of torsion-free finitely generated
abelian groups by finite groups) are biautomatic, but nonabelian torsion-
free nilpotent groups are not automatic. This result has now been
generalized in [Har], where it is proved that nonabelian torsion-free
polycyclic groups are not automatic.
Braid groups, geometrically finite groups, and Artin groups of finite type
(proved by Charney in [Cha95]) are biautomatic. It is proved by Brink and
Howlett in [BH93] that Coxeter groups are shortlex automatic using the
natural generating set, but it is still not known whether all Coxeter groups
are biautomatic.
The class of automatic groups is closed under direct products, free
products with finite amalgamated subgroup, and HNN-extensions with finite
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
453
conjugated subgroup. Free factors of automatic groups are automatic, but it
has not been proved that direct factors are.
If H has finite index in G, then G is automatic if and only if H is.
13.2.2 Word-differences and word-difference
automata
The word-differences associated with two words w,v ∈ A* play a vital rôle in
the algorithms for computing automatic structures. If w=a1…an with
ai ∈ A then, for 0≤i≤n, we denote the prefix a1…ai of length i of w by wi, and
we let wi=w for i≥n.
DEFINITION 13.7 The set of word-differences associated with a pair of
words (w, v) ∈ A*×A* is 
, regarded as a subset of G.
The set of word-differences associated with a set P of pairs of words (w,v)
∈ A*×A* is the union of the sets of word-differences associated with the
pairs (w,v) ∈ P.
Although we appear to have defined infinitely many word-differences for a
given pair (w,v), there are of course at most max (|w|,|v|)+1 distinct
word-differences associated with (w,v).
The word-differences are the group elements represented by the paths
joining corresponding vertices in the paths labelled w and v that start at
the origin in the Cayley graph ΓX(G) of 
 (Definition 2.13). So, in
Fig. 13.1, the group element represented by the path u is a word-difference.
The following result, which is equivalent to [ECH+92, Lemma 2.3.2] is
fundamental in the theory of automatic groups. Its proof is easy, so we
include it here.
THEOREM 13.8 Suppose that the fsa W and Mx (x ∈ A∪ {ε}) form an
automatic structure for G, and let D be the set of word-differences associated
with the set of all (w,v) ∈ A*×A* for which (w, v)+ ∈ L(Mx) for some x ∈ A ∪
{ε}. Then D is finite.
Figure 13.1: Word-differences.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
454
PROOF An element of D has the form 
 for some i ∈ 
, where
(w, v)+ ∈ L(Mx) for some x ∈ A ∪ {ε}. Let w′, v′ ∈ A* satisfy w=wiw′, v=viv′.
Then (wi,vi)+(w′,v′)+ ∈ L(Mx) so, if σ0 is the start state of Mx, then there is a
path of arrows in Mx from 
 to a success state. By removing closed
circuits from this path, we can choose such a path of length at most the
number of states in Mx. Hence, if K is the maximum number of states of
any of the fsa Mx, then we can choose w′′,v′′∈ A* with |w′′|,|v′′|≤K and
(wi, vi)+(w′′, v′′)+∈ L(Mx). Then, by definition of L(Mx), we have wiw′′x =G
viv′′ and so 
We have now proved that any word-difference in D is equal in G to a
word of length at most 2K+1. Since there are only finitely many elements
of G with that property, this proves the result.
Geometrically, this result says that the lengths of the paths u in the Cayley
graph, as shown in Fig. 13.1, is uniformly bounded for pairs (w,v) such that
(w, v)+ ∈ L(Mx) for some x, even though the words w and v themselves can
be arbitrarily long. This property of the sets L(Mx) is known as the fellow-
traveller property. It is not hard to show (see exercises below) that this
property can be used as an alternative definition of an automatic group.
DEFINITION 13.9 An accessible two-variable dfa Z with start state σ0 is
called a word-difference automaton for G, if there is a function δ:ΣZ→G
such that
(i)
δ(σ0)=1G;
(ii) For all a, b ∈ A+:=A ∪ {$} and σ ∈ Σz such that σ(a,b) is defined, we have
δ(σ(a, b)=G a-1δ(σ)b.
Here and elsewhere, if we need to interpret the padding symbol $ as an
element of G, then $ evaluates to 1G.
Let Z be a word-difference machine with start state σ0 . Since we are
assuming that Z is accessible, for all σ ∈ ΣZ there exist v, w ∈ A* with
 and then (i) and (ii) imply that δ(σ)=G v-1w. Hence the map δ is
determined by the group G and the transitions of Z.
The above definition says nothing about the accepting states of Z, but
the following result follows immediately from the definition.
LEMMA 13.10 If Z is a word-difference machine and there exists g ∈  G
such that δ(σ)=g for all accepting states σ of Z, then wg=G v for all w,v ∈ A*
with (w, v)+ ∈ L(Z).
For an automatic structure W, Mx (x ∈ A ∪ {ε}) of G, we can define
associated word-difference dfa Zx as follows. There is one of these for each
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
455
x ∈ A ∪ {ε}, but they differ only in their accepting states. First we give a
version that is not quite correct.
The state-set 
 is the set D defined and proved to be finite in Theorem
13.8, δ is the identity map, and 1G is the unique start state. For σ ∈ D and
x, y ∈ A+, we define σ(x, y)=ρ if x-1σy=G ρ ∈ D, and otherwise σ(x,y) is undefined.
The unique final state is x.
The definition is not quite right as it stands, because the dfa defined
might accept words in (A+×A+)* that are not padded words of the form
(w, v)+, and that would violate our definition of a 2-variable fsa. To remedy
this, adjoin two extra copies DL and DR of D to 
. Transitions labelled
(a, $) for a ∈ A are only defined when the source state is in D or DL and
when the target is in DL, and these are the only transitions defined with
target in DL. Similarly, transitions labelled ($, a) are only defined when the
source state is in D or DR and when the target is in DR, and these are the
only transitions defined with target in DR. The element 1G ∈ D remains the
only start state of Zx, and we make Zx accessible by removing any
inaccessible states. There are now (up to) three final states, namely the
elements representing x in D, DL and DR.
PROPOSITION 13.11 For each x ∈ A ∪ {ε}, we have wx=G v for all (w, v)+ ∈
L(Zx), and (w, v)+ ∈ L(Zx) for all (w, v)+ ∈ L(Mx).
PROOF The first statement follows from Lemma 13.10, and the second
statement follows from the definitions of D and of Zx. 
In Fig. 13.2, we illustrate Zx accepting a pair (w, v)+ with (w,v) ∈ L(Mx).
The arrow labels g1 and g2 are states of Zx, and there is a transition g1
(a,b)=g2
of Zx, where a–1g1
b=G g2.
Figure 13.2: A transition in Zx.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
456
DEFINITION 13.12 A collection of word-difference dfa 
 for
G is said to be correct for an automatic structure W, Mx of G, if the Zx
satisfy Proposition 13.11.
Constructing correct word-difference dfa forms an important component of
our automatic structure algorithm. The following result follows immediately
from the definitions of an automatic structure and of correctness. It will be
used in the algorithm to construct the Mx from W and the Zx.
PROPOSITION 13.13 If the collection of word-difference dfa Zx is correct
for an automatic structure W, Mx of G, then, for each 
, we
have
 
13.3 The algorithm to compute the shortlex
automatic structures
In this section, we shall describe a procedure for computing shortlex
automatic structures for groups G defined by a finite presentation. As
mentioned earlier, this has been implemented in the author’s KBMAG
package. Although it should, in principal, be possible to extend the
procedure to handle general automatic structures, there are a number of
features of the shortlex situation, principally the fact that words accepted
by W are the shortest representatives of the associated group elements,
which make this special case suitable for relatively efficient
implementation. The only current extension of the methods to
nonshortlex structures is described by Sarah Rees in [Ree98] and has
been implemented by her as GAP procedures that call programs from
KBMAG.
Let 
 with X, R finite, where a total order < has been specified
on A:=X∪X_1. We shall use < also to denote the corresponding shortlex ordering
on A*. If G is shortlex automatic with respect to this ordering then, given
sufficient time and space, the procedure is guaranteed to compute the
corresponding automatic structure and to verify its correctness. So we do not
need to know in advance whether the group is shortlex automatic; indeed,
these methods have proved most useful when applied to groups about which
very little was known. If the group is not shortlex automatic, then the
procedure will not complete.
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
457
There are five main steps in the procedure, which we shall describe in
detail in separate subsections. For the remainder of this section, when we
talk about the word-acceptor W or the multipliers Mx of G, we shall mean
the corresponding fsa in the putative shortlex automatic structure of G. Of
course, we do not know in advance whether G has such a structure. If not,
then the procedures will fail and, in practice, they may fail as a result of
insufficient memory even when G is shortlex automatic. We shall say that
a candidate W′ for W or 
 for Mx is correct if L(W′)=L(W) or =L(
)=L(Mx),
respectively.
Step 1. Use Knuth-Bendix completion to compute word-difference dfa 
 for G.
Step 2. Use 
 to compute a candidate W′ for the word acceptor W of G.
Step 3. Use the 
 and W′ to compute candidates 
 for the multiplier
automata of G. If it transpires during the course of this construction
that L(W′)L(W), then redefine the dfa 
 and go back to Step 2.
Step 4. Carry out correctness tests on the 
 If it turns out that 
 for some x, then redefine the dfa 
 and go back to Step 3.
Step 5. Carry out full correctness tests on W′ and 
 to decide whether
We shall explain later exactly how the looping involved in Step 2 to Step 4
works.
The final step (Step 5) of the algorithm, which returns just true or f alse,
attempts to verify that these candidates are all correct; that is, that they
are equal to the fsa of a shortlex automatic structure of G. In practice, it
has been observed that, unless one deliberately runs the procedure with
very silly parameter settings, if the tests in Step 4 complete successfully,
then so does the full test in Step 5. It is frustrating that Step 5 can often
take up the bulk of the time and space requirements for the whole procedure,
and at the end it merely reports true! In principle, if Step 5 returned f alse,
then we could repeat the whole procedure again with larger parameter
settings in Step 1.
13.3.1 Step 1
As already explained, we shall assume throughout (possibly erroneously!)
that G is shortlex automatic, with automatic structure W, 
.
Let D be the finite set of word-differences defined in Theorem 13.8 for the
shortlex automatic structure of G.
By Theorem 12.12, there is an associated monoid presentation 
 of G. As described in Section 12.3, we can use this monoid presentation
to define a rewriting system S, using our shortlex ordering < on A*, and
we can run the Knuth-Bendix completion process on S.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
458
According to Definition 12.18, the S-minimal strings in A* are the minimal
elements in their 
* equivalence classes, which are the minimal
representatives of group elements under <. So L(W) is equal to the set of S-
minimal strings in A*.
In Definition 12.19, we defined an S-essential rule (w,v) to be a pair of
words w,v∈A* where w
*v, and v and all proper substrings of w are (S-)
minimal. Or, equivalently, w =G v, and v and all proper substrings of w are
in L(W).
Let D0 be the set of word-differences associated with the set of all S-essential
rules. If (w,v) is such a rule, then w=ux, where x∈A and u,v∈L(W). Hence,
by the definition of an automatic structure, we have (w,v) ∈ L(Mx). Since
|w|≥ v|, all word-differences associated with (ux,v) are also associated
with (u,v), and hence 
 and D0 is finite.
So, although there will normally be infinitely many S-essential rules,
there will only be finitely many associated word-differences.
We can now describe Step 1. We run Knuth-Bendix on S, as already
mentioned. At any stage in the procedure, for w∈A*, let r(w) be the current
S-reduction of w, which can be computed from S using the method described
in Subsection 13.1.3. So r(w)=G w. From time to time we interrupt the
Knuth-Bendix procedure and, for each rule (w,v) in S, we calculate
 
and let 
 be the union of these sets over all rules currently in S. (It is
convenient to make this calculation immediately after we have carried out
the simplification process on the current rule set, because that tends to
avoid getting superfluous elements of 
.)
To be more precise, for i≥1, we compute 
 in the above expression
as 
, where a and b are the i-th letters of w and v,
respectively. The proof of the proposition below depends on this method of
computing the 
; the observant reader will have noticed that, since
S is not generally confluent, the value of r(w) calculated can depend on the
method used to S-reduce w.
When 
 appears to have become stable (more on this later!), we compute
and output word-difference dfa 
 as follows. The states of
 are the elements of 
, ε is the unique start state, and r(x) is the unique
accepting state of 
 . For 
 and 
, we define the
transition 
, and σ(a,b) is undefined
otherwise. We also modify 
 as described above for D to ensure that 
accepts only padded strings. Then it is clear that 
 satisfies the
requirements of Definition 13.9 for a word-difference fsa where, for
 is defined to be the element of G represented by w.
PROPOSITION 13.14 Provided that the Knuth-Bendix process is run for
sufficiently long before computing and outputting the 
, we will have
 for all S-essential rules (w,v).
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
459
PROOF Since D0 is finite, the elements of D0 all occur as word-differences
of a finite subset  of the set of all essential rules. By Proposition 12.20, if
we run the Knuth-Bendix process for sufficiently long, then all rules in 
will be rules in S. Furthermore, if we run it for long enough then, for all
 and all minimal words w representing elements of D0, the S-
reduction r(w) of a–1wb will be equal to the minimal representative of a–1wb.
At that stage, 
 will contain all minimal words representing elements
of D0, and also all possible transitions σ(a,b) for 
. Since the word-
differences associated with essential rules (w, v) all lie in D0, we will then
have 
.
There remains the problem of deciding when to interrupt the Knuth-Bendix
process or, in other words, how to judge when 
 has become stable. No
completely satisfactory solution to this has been found to date. A strategy
that works well on many straightforward examples is to stop when the number
of rules in S is at least some minimum size, and has also doubled without 
changing.
Unfortunately, in some difficult examples, a small number of elements
of 
 take a very long time to appear, and we may decide to stop Step 1
before 
 is complete. But on the other hand this does not always matter,
because the missing word-differences may be found during Step 2 to Step 4.
Another problem is that in some examples additional word-differences arise
from rules that later turn out not to be reduced. Although superfluous
worddifferences do not prevent the procedure from functioning correctly,
they are a nuisance, since they can make it difficult to decide, particularly
mechanically, whether 
 has become stable.
One nice feature of the procedure is that in many examples that are not
shortlex automatic, the number of elements in 
 increases steadily without
stabilizing, so it becomes rapidly clear that the process is doomed to failure.
13.3.2 Step 2 and word reduction
The remaining steps of the procedure do not involve the Knuth-Bendix
process, and consist entirely of constructions involving fsa. Since some of
these fsa may have large numbers of states, it is important that for each
fsa that we construct, we always compute an equivalent dfa if necessary,
and that we always compute an equivalent dfa with a minimal number of
states. We routinely standardize each dfa computed, as described in
Subsubsection 13.1.6.3, so that we can easily test two dfa for equivalence.
For a shortlex ordering < on A*, it is straightforward to construct a 2-
variable fsa over A with language {(w, v)+∈(A+×A+)*|v<w}; see exercise
below. It is interesting to note, however, that for various other familiar
orderings on A*, such as the wreath-product orderings defined in Section
12.4, the set defined above is not the language of an fsa. This is the main
reason why the methods for constructing shortlex automatic structures do
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
460
not readily generalize to other orderings. A method of carrying out such
generalizations was, however, proposed in [Ree98].
It follows from the above remark and the results and constructions
described in Subsection 13.1.6 that we can construct a dfa W′ with language
, where
 
and 
 was computed in Step 1. Step 2 consists of this construction of W′.
PROPOSITION 13.15 L(W′) is prefix-closed with 
. If the dfa
 returned in Step 1 accepts all essential rules, then L(W′)=L(W).
PROOF It follows immediately from 
 that L(W′) is prefix-
closed. If u∈A*\L(W′) then u∈A*LA*, so u=u1wu2 where there exists v∈A*
with 
. But Proposition 13.10 implies that w=G v,
so u=G u1vu2 with u>u1vu2, and hence 
. Thus 
.
Conversely, suppose that u∈A*\L(W). Then u is not minimal. Choose w
to be a substring of u, which is shortest subject to being not minimal. Then
there exists a minimal v∈A* with w=G v, and all proper substrings of w are
minimal, so (w, v) is an essential rule. Hence, if Z′ε accepts all essential
rules, then 
 and so 
, which completes the proof.
During the remaining steps of the procedure, we shall sometimes need to
replace a word u∈A* by a word u′ with 
 and u′∈L(W′). We can do
that as follows.
If 
, then find a substring w of u of minimal length with 
. Then, from the way that W′ was constructed, we know that there
exists v∈A* with 
. We can find such a word v by using the
procedure EXISTSWORD described in Subsection 13.1.7. We then substitute
v for w in u and repeat. Since each such substitution replaces u by a smaller
word in the shortlex ordering, this process must eventually terminate with
u∈L(W′).
In fact, if 
, then 
 for all u1∈A* (see
exercise below). So it suffices to find a shortest prefix w of u with 
,
which is easy: since L(W′) is prefix closed, when reading u into W′, we will
have read the shortest prefix not in L(W′) as soon as we reach a failure state.
13.3.3 Step 3
In Proposition 13.13, we saw that, if the dfa 
 are correct for
the automatic structure as defined in Definition 13.12, then for each
, we have
 
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
461
In Step 3, we construct our candidate multiplier dfa 
 with language
equal to the right-hand side of this equality, but using our candidate dfa
W′ and 
 in place of W and Zx. Of course we do not know yet whether
the 
 really are correct and, as we shall explain later, they will not
necessarily be correct after the first application of Step 2, even if
L(W′)=L(W).
To be more precise, Mx is constructed as follows. (This construction is also
described in Definition 2.3.3 of [ECH+92].) The set 
 of states of Mx is
 
the start state is (σ0, σ0, ρ0), where σ0 and ρ0 are the start states of W′ and 
,
and a state is accepting if σ1 and σ2 are accepting states of W′ and ρ is an
accepting state of 
.
We need to extend the definition of W′ to allow transitions labelled by $.
We define σ$=σ if s is an accepting state of W′, and σ$ is undefined otherwise.
The transitions of Mx are derived from those of W′ and 
, and are
 
for a, b∈A+, where the transition is undefined if any of the components on
the right-hand side are undefined.
It is easy to see, and left as an exercise to the reader, that
 
as required.
We shall need the following straightforward properties of L(M′x) later.
PROPOSITION 13.16 (i) For all w, v∈A* with 
, we have w,
v∈L(W′) and wx=G v.
(ii) If a1a2… an∈L(W′) with n>0, then
 
.
PROOF By definition of the word-difference dfa Z′x, we have δ(σ)=G x for all
accepting states σ of Z′x, so (i) follows from Lemma 13.10.
By Proposition 13.15, a1a2…an∈L(W′) implies a1a2…an–1∈L(W′), so to prove
(ii) we just need to prove that 
 
. If σ0 is
the start state of 
 then, by definition of 
, we have 
=σ0 for all a∈A.
Hence
 
so 
.
As is usual with fsa constructions, when we construct 
 in practice, we calculate
the transitions beginning with the start state, and we only need to define those
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
462
states that are accessible from the start state. As was the case with the Z′x, we
can store all of the M′x as a single dfa, and just allow the final states to vary to
provide the individual M′x. It is even possible to do the dfa minimization using
this single dfa, but we shall not go into details about that here.
Notice that, if 
 with w>v, then w is in the language L
defined in Step 2 and so, by definition of W′, we cannot have w∈L(W′).
Hence, if we apply Step 3 immediately after Step 2, then we cannot have
 with w>v. However, as we shall see in the next subsection,
we sometimes reapply Step 3 after a redefinition of the Z′x in Step 4. When
that happens, it is possible to find 
 with w>v and indeed
this occurs not infrequently in practice.
This tells us that 
 and so W′ is incorrect, and typically there
will be word-differences associated with the pair (w, v) that are not in the
set 
 used to construct the Z′x in Step 1. So we calculate the word-differences
associated with (w, v) just as in Step 1, except that we now use the algorithm
described at the end of Subsection 13.3.2 to reduce words to a word in
L(W′). We adjoin these new word-differences to our set 
, recalculate the
dfa Z′x, and then repeat Step 2. It is possible to design the algorithm so that
we find such pairs (w, v) as soon as they arise during the construction of
the Mx, so we can then abort the construction.
13.3.4 Step 4
In general, the set D0, defined in Subsection 13.3.1, of word-differences
arising from the essential equations is a proper subset of the set D, defined
in Theorem 13.8, of all word-differences arising from the sets L(Mx).
Proposition 13.14 guarantees that, if we run the Knuth-Bendix process in
Step 1 for long enough, then the states of the Z′x will contain minimal
representatives of all elements of D0. But they will not, in general, contain
representatives of all elements in D, and so the Z′x will not necessarily be
correct after Step 3, and hence neither will the M′x.
Let us assume for the moment that W′ is correct; that is, L(W)=L(W′).
From the construction of M′x, we have 
 implies 
, and hence wx=G v. So, if some 
 is not correct, then there exist
w, v∈L(W′) with wx=G v and 
. But, by the construction of
M′x again, if 
 for some v′∈A*, then w,v′∈L(W′)=L(W) with
wx=G v′, and hence v=v′. So, if 
 is not correct, then there exists
w∈L(W′) such that there is no v∈A* with 
.
In Step 4, we use the method described in Subsection 13.1.7 to construct,
for each x∈A∪{ε}, an fsa Ex with language
 
If L(Ex)=A* for all x∈A∪{ε} and L(W)=L(W′), then the argument above shows
that 
 for all x, and so we have successfully calculated the
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
463
automatic structure. But we do yet know that L(W)=L(W′), and we proceed to
Step 5 for the final correctness verification.
Otherwise, L(Ex)≠A* for some x, in which case we use the algorithm FSA-
ENUMERATE presented in Subsection 13.1.2 to find some words
w∈¬L(Ex). For each such w, we use the method described in Subsection
13.3.2 to find v∈L(W′) with wx =G v. As in Steps 1 and 3, we then calculate
words in L(W′) that represent the word-differences associated with the pairs
(w, v), adjoin them to our set D′0, recalculate the fsa Z′x (for all x), and
return to Step 3.
We can now prove that, if G is shortlex automatic, then it is possible to
calculate the shortlex automatic structure by Step 1 to Step 4.
THEOREM 13.17 If the Knuth-Bendix process is run for sufficiently long in
Step 1 and G is shortlex automatic, then the associated shortlex structure
will be successfully computed in Step 2 to Step 4.
PROOF By Propositions 13.14 and 13.15, if we run Knuth-Bendix for long
enough, then we will have L(W)=L(W′) after Step 2, so let us assume that
to be the case.
We also assume that we run Knuth-Bendix for long enough to ensure
that, for all a, b∈A∪{ε} and all minimal words w representing elements of
D, the S-reduction r(a-1wb) of a-1wb is equal to the minimal representative
of a–1wb. (In the proof of Proposition 13.14 we just needed that property for D0
rather than D.) Then, after Step 2, the minimal representative of each such
a–1wb will be the unique representative of that word in L(W′)=L(W), and so
the algorithm for finding representatives of words in L(W′) described at the
end of Section 13.3.2 will successfully replace all of these words a–1wb by
their minimal representatives.
So, if our set D′0 contains minimal representatives of all elements of D,
then the fsa Z′x computed will be correct and then, by Proposition 13.13,
the M′x computed in Step 3 will be correct, the sets Ex computed in Step 4
will all satisfy L(Ex)=A*, and we will proceed to Step 5.
Otherwise, in Step 4 we will find pairs (w, v) with w, v∈L(W′), wx=G v and
 and hence 
. Since (w, v)+∈L(Mx), its
associated word-differences lie in D and so, by our assumption, they will all
be correctly reduced to their minimal representatives. If these minimal
representatives were all already in D′0, then we would have 
,
which is not the case. So, when we redefine the fsa Z′x, D′0 will contain
minimal representatives of more elements of D than previously. Since D is
finite, the looping process must eventually terminate, at which stage the
automatic structure will have been successfully calculated.
As we saw in the proof, Propositions 13.14 and 13.15 ensure that, if we run
Knuth-Bendix for long enough in Step 1, then we will get L(W)=L(W′) in
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
464
Step 2, and then we will never need to repeat Step 2. It is important to stress
once again, however, that even if we make a mistake and fail to get L(W)=L(W′)
on the first application of Step 2, it is still possible that W′ will be corrected
after one or more applications of Steps 3 and 4. There is no obvious theoretical
reason why this should happen, but in the more difficult examples, this
feature has turned out to be essential in practice for the whole procedure to
complete successfully.
13.3.5 Step 5
In Step 5, we decide whether W′ and the M′x constructed in Step 2 to Step 4
form a shortlex automatic structure for G. The method depends on the
following theorem, which is Theorem 2.5 of [EHR91] and Theorem 6.1.2 of
[ECH+92]. We recall from Theorem 12.12 that, for a group presentation
 there is an associated monoid presentation 
 of
G, where
 
THEOREM 13.18 Let 
 be a finite group presentation and let
 be the associated monoid presentation of G. Suppose that
W is a fsa over A and Mx (x∈A∪{ε}) are 2-variable fsa over A, which satisfy
the following hypotheses:
(i)
If (w, v)+∈L(Mx) for some w,v∈A* and x∈A∪{ε}, then w,v∈ L(W) and
wx=Gv.
(ii)
L(W) is nonempty and, if a1 a2…an∈L(W) with n>0, then a1a2…an–1
∈L(W) and 
.
(iii)
Let w=w0∈L(W) and 
. Then, for a word
wn∈L(W), there exist elements w1,w2,…,wn–1∈L(W) satisfying
 for 1≤i≤n if and only if w=wn.
Then W and the Mx form an automatic structure for G with uniqueness.
PROOF Suppose that the three hypotheses hold. Let x∈A and w∈ L(W).
Then, by hypothesis, we have (xx-1,ε), (x-1x,ε)∈. By applying hypothesis
(iii) to w and xx–1, we deduce that there exists w′∈L(W) with (w, w′)+∈L(Mx)
and (w′, w)+∈L(Mx—1). By applying hypothesis (iii) to w′ and x–1x, we find
that w′ is the unique word with this property. Hence we can define a
map ϕ(x): L(W)→L(W) that maps w to w′ and, since ϕ(x) and ϕ(x–1) are
mutually-inverse maps, ϕ(x) is a bijection; that is, ϕ(x)∈ Sym((L(W)).
Furthermore, hypothesis (iii) implies that, for any 
,
the permutation ϕ(a1)ϕ(a2)…ϕ(an) of L(W) is the identity, and so by
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
465
Theorem 12.11, ϕ extends to a monoid (and hence also a group)
homomorphism from G to Sym(L(W)).
Now let g∈G and let a1a2…an∈A* represent g. Note that ε∈L(W) by
hypothesis (ii), and hypothesis (i) implies that the image of ε under the
permutation ϕ(a1)ϕ(a2)…ϕ(an) also represents g. So L(W) contains at least
one word representing g, which we may as well assume to be a1a2…an.
Let b1b2…bm∈L(W) represent g. Then, since ϕ is a homomorphism, we
have
 
But hypothesis (ii) implies that ϕ(a1)ϕ(a2)…ϕ(an) and ϕ(b1)ϕ(b2)…ϕ(bm) map
ε to a1a2…an and b1b2…bm, respectively, so a1a2…an=b1b2…bm. This proves
that W is a unique word-acceptor for G.
We know from hypothesis (i) that, for x∈A∪{ε}, (w, v)+∈L(Mx) implies
w,v∈L(W) and wx=G v. Conversely, for w∈L(W) and x∈A∪{ε}, we saw above
that there is a unique v∈A* with (w, v)+∈L(Mx), so v must be the unique
element of L(W) with wx=G v. Hence w, v∈L(W) and wx=G v implies that (w,
v)+∈L(Mx), so W and the Mx form an automatic structure for G with
uniqueness.     
We wish to apply this theorem to W′ and the M′x computed in Step 2 to Step
4. By Proposition 13.15, L(W′) contains the shortlex minimal representative of
each group element so, if the hypotheses of the above theorem holds, then W′ and
the 
 form the shortlex automatic structure for G.
Now hypothesis (i) holds by Proposition 13.16 (i). By Proposition 13.15
L(W′) is prefix-closed and contains the shortlex minimal representative of
each group element, so we certainly have ε∈L(W′). Also, if a1…an∈L(W′) with
n>0, then, by Proposition 13.16 (ii), we have 
.
So hypotheses (i) and (ii) are definitely satisfied, and we just have to check
whether hypothesis (iii) holds. (We leave it to the reader to verify that, if W′
and 
 form the shortlex automatic structure for G, then hypothesis (iii)
must hold.)
In order to check hypothesis (iii), we use the construction of the composite
fsa defined in Subsection 13.1.7. The composite operation is easily seen to
be associative so, for a word u=a1a2…an∈A*, we can unambiguously define
a multiplier fsa Mu to be the composite of 
. Then
 
So, hypothesis (iii) says exactly that L(Mu)={(w, w)|w∈L(W′)} for all
. The right-hand side of this equation is equal to the language
of a 2-variable fsa that can easily be constructed from W′, so we can carry out
these checks as required.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
466
13.3.6 Comments on the implementation and examples
We start with a few extra comments on various steps in the the above
procedure, some of which relate to the implementation in KBMAG.
Although we have described the fsa constructions in Step 2 to Step 5 in
terms of the standard operations introduced in Sections 13.1.6 and 13.1.7,
in the implementation in KBMAG, we have written separate stand-alone
programs for each of the main processes; this has resulted in faster running
times and smaller memory requirements than we would get by using
combinations of the basic operations.
Since 
 the set D of word-differences
is closed under inversion. The subset D0 is not necessarily inverse-closed
but, since we eventually need to extend D0 to D, we can substantially reduce
the amount of looping required in Step 2 to Step 4 by adjoining r(w–1) to D′0
for each w∈ D′0 in Step 1. We do this by default in the implementation and,
whenever we need to extend the set D′0 in Step 3 or Step 4, we always adjoin
word-differences r(w) and r(w–1) together.
On a related point, we said above that, in Step 3, we abort and return to
Step 2 if we find 
. In fact we do this if we find
any 
 with w ≠ v and hence, if we complete Step 3 without
aborting, then it is guaranteed that 
. Thus,
in the testing of hypothesis (iii) in Step 5, we can use 
 for the language
equality tests.
In principal, if the test in hypothesis (iii) failed, then we could find (w,
v)+∈ L(Mu) for some u with 
 and w ≠ v. Then we would have
w=G v and we could adjoin the word-differences associated with (w, v) to 
,
redefine the Z′x and go back to Step 2. In fact, we have not implemented
this process, mainly because, in all examples that we have run in practice,
the test in Step 5 has never failed, except when we have deliberately run
the Knuth-Bendix process in Step 1 for an absurdly short time.
In difficult examples, the construction of the composite dfa in Step 5 is
the most expensive in memory requirements, because the dfa Mu can have
large numbers of states. Of course, we always minimize them immediately
after constructing them. Generally, the longer the word u, the larger will Mu
be. We always start by checking hypothesis (iii) for the short words u=xx–1
with x∈A. Once we have done this, if u=u1u2∈R, then checking that
L(Mu)=L(Mε) is easily seen to be equivalent to checking that
, and we can improve performance somewhat by doing
this with u1 chosen to have about half the length of u.
To give the reader an idea of the difficulty of the procedure, we shall now
present some statistics on successful computations of automatic structures
using KBMAG, on a collection of examples of increasing difficulty. The
programs were run on a Sun Ultra 80 Workstation with 4 GigaBytes RAM.
There are some very straightforward examples, such as the triangle
groups 
, for which the complete procedure typically
takes less than a second.
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
467
The following moderately easy example is a symmetry group of a certain
tesselation of 3-dimensional hyperbolic space into dodecahedra. As in previous
examples, we use the case-change for inverses convention, A=a—1, despite
the clash with our notation for the alphabet!
Example 13.4
 
In Step 1, Knuth-Bendix was interrupted with 2000 rewrite-rules and 
=49, after 
 had remained constant while the final 1000 rules were found.
After closing under inversion, 
=53. In Step 2, W′ had 438 and 47 states
before and after minimization. Steps 3 and 4 were executed three times each.
On the third and final iteration, the multipliers 
 had 2293 and 385 states
before and after minimization, with |D′|=75, after which the correctness
test in Step 4 was passed. In fact |D0|=49 and |D|=75, so the computed sets
are exactly right. Since all the group relators have length 4, it was only
necessary to compute Mw for various words w with |w|=2. For example, Mab
had 1264 and 291 states before and after minimization. The complete procedure
took just over 4 seconds to run.
Example 13.5
 
This example, due to Heineken, was mentioned earlier, in Section 5.4. It was
proposed as a possible candidate for 3-generator, 3-relator finite group, and
was motivated by the fact that the group with the simpler presentation
 was known to be trivial. By
means of the low-index subgroup and p-quotient algorithms, it was
established relatively easily that G has a finite quotient of order 60.224, but
for many years nothing further was discovered about it.
It was finally proved to be automatic and infinite using KBMAG. It is
even word-hyperbolic (see Section 13.4 below). In Step 1, Knuth-Bendix
was interrupted with about 40000 rewrite-rules and 
=71, after 
 had
remained constant while the final 20000 rules were found. After closing
under inversion, we still had 
=171. In Step 2, W′ had 33114 and 1106
states before and after minimization. Steps 3 and 4 were executed only
once, and the multipliers M′a had 49158 and 2428 states before and after
minimization. Step 5 was also reasonably straightforward, and the complete
computation took about 110 seconds to run.
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
468
Example 13.6
 
This is the Fibonacci group F(2, 9), and is a difficult example. Step 1 halted
at 500 000 equations after 9574 seconds, with 
=541 and fluctuating
around 541 for the final 120000 equations.
On the first run of Step 2, W′ had 124003 states initially, which minimized
to 8543. But W′ was not correct at this stage. Step 2 was executed three
times in all, and on the third time W′ had 129 169 states initially, minimizing
to 3251. Steps 3 and 4 were executed 7 times altogether. On the final run of
Step 3, the multipliers M′a had 872 309 and 25 741 states before and after
minimization, with |D′|=665, after which the correctness test in Step 4
was passed. Steps 2 to 4 took about 7568 seconds altogether.
Step 5 took 3042 seconds to verify the correctness of the final versions of
D′, W′, and the M′a. All the group relators have length 3 so, as with the
previous example, it was only necessary to compute Mw for various words
w with |w|=2. For example, Mab had 1 137 648 and 25 555 states before and
after minimization. In fact Step 5 is relatively undemanding in this particular
case. In examples with long relators, Step 5 can dominate the total time
and memory requirements.
After the automatic structure had been successfully computed, it was
not difficult to use it to calculate the correct value of |D0|, which is 563. So
we were missing 22 word-differences when we halted Step 1, but these
were found without undue difficulty during Steps 2 to 4.
13.4 Related algorithms
There are a number of other procedures that are related to and extend the
methods that we have described for automatic groups. We shall mention
them briefly here, and refer the reader elsewhere for details.
A group is defined to be word-hyperbolic if geodesic triangles in its Cayley
graph are uniformly thin. See [ABC+91] or the book by Ghys and de la
Harpe [GdlH90] for details. All such groups are shortlex automatic with
any choice of generators, so we can use the procedures described above to
find their automatic structures.
If a group is word-hyperbolic, then the geodesics between any two
vertices in the Cayley graph have the fellow-traveller property; that is,
they remain within a bounded distance of each other. It has been proved
by Papasoglu in [Pap95] that the converse is true; that is, if the geodesics
in the Cayley graph have the fellow-traveller property, then the group is
word-hyperbolic.
© 2005 by Chapman & Hall/CRC Press

Finite State Automata and Automatic Groups
469
Starting from the shortlex automatic structure, it is possible and not
difficult to attempt to verify that the geodesics in the Cayley graph have
the fellow-traveller property. If we succeed then, by Papasoglu’s result,
we will have proved that the group is word-hyperbolic. As usual in this
area, if we do not succeed, then we gain no further information. (As far as
we know, it is not known whether it is decidable whether a group known
to be shortlex automatic is word-hyperbolic.) This procedure is described
by Epstein and Holt in [EH01b] and is implemented in KBMAG. For
example, Examples 13.4 and 13.5 above above word-hyperbolic. It takes
only a few seconds to verify this in the first of these examples, and to
calculate a word-acceptor with 63 states that accepts all geodesic words,
and a geodesic word-difference machine with 91 states (= word-differences).
More recently, in a computation taking about two weeks of cpu-time, we
have verified that Examples 13.6 is wordhyperbolic. The geodesic word-
acceptor and word-difference machine have 7688 and 1730 states,
respectively.
One can also attempt to compute the thinness constant for hyperbolic
triangles in a word-hyperbolic group, but that is significantly more
difficult. An algorithm for this is also described in [EH01b]. This, in
turn, gives rise to algorithms for solving the conjugacy problem in these
groups.
It is possible to generalize the notion of an automatic group to a group
that is automatic with respect to a subgroup. Some procedures for
constructing the related coset automatic structures are described in detail
by Holt and Hurt in [HH99]. They follow the same lines as the procedure
for finding standard shortlex automatic structures. For example, in Step 1,
the Knuth-Bendix process is run for the group relative to the subgroup.
The remaining steps involve the manipulation of an interesting class of fsa
that may have more than one start state, but are otherwise deterministic.
When successful, these procedures provide the possibility of proving
that a subgroup H has infinite index in G and, in some examples, they
represent the only currently known method of doing this. They may also
be used to compute a finite presentation of H. These methods are
implemented in KBMAG.
13.5 Applications
A number of applications of the automatic group programs within group
theory have been mentioned already. They were used to prove the
infiniteness of various groups, including the Heineken group (Example
13.5), and to prove that the generators of the Fibonacci group F(2, 9)
(Example 13.6) have infinite order.
As was mentioned in Subsection 13.1.4, the use of the programs to
construct unique word-acceptors for various groups has led to applications
© 2005 by Chapman & Hall/CRC Press

Handbook of Computational Group Theory
470
outside of group theory. These applications are based on the simple fact
that a unique word-acceptor allows one to use FSA-ENUMERATE to rapidly
enumerate unique shortest representatives of the elements of the group.
The simplest applications of this type involve drawing pictures of geometric
objects. Some of the scenes in the Geometry Center movie “Not Knot”
[GM92] were made with the help of automatic groups software: Example
13.4 above was one of the groups used. One of the posters depicting a
frame from the fly-through of hyperbolic space from “Not Knot” used a list
of over 100,000 group elements; this list took only a few minutes to compute
using the word-acceptor. Without it, the same list would have required
hours of computation. Another advantage of the method is its extremely
low memory requirements; without it, the full list of group elements would
have to be kept in memory, as matrices, throughout the computation.
For a more sophisticated application, to the drawing of limit sets of
Kleinian groups, see the article by McShane, Parker, and Redfern [MPR94].
Exercises
1.
Let 
 Show that G is shortlex
automatic with respect to the ordering x<x–1<y<y–1<a<a–1 of A, but not
with respect to the ordering a<a—1<x<x–1<y <y–1.
2.
Suppose that W is a word-acceptor for the group G and that the set of
word-differences associated with the union of the sets
 
for x∈A∪{ε} is finite. Prove that each Lx is the language of an fsa, and
hence that G is automatic.
3.
Let < be a shortlex ordering on A*. Show how to construct a 2-variable
dfa with four states and language { (w, v)+∈(A+×A+)*|v<w}.
4.
In the construction of W′ described in Subsection 13.3.2 show that, if
(w,v)∈L, then (u1w,u1v) ∈L for any u1∈A*. Deduce that L(W′)= ¬(LA*).
(This fact enables us to construct W′ slightly more efficiently.)
5.
Show that the fsa 
 constructed in Subsection 13.3.3 have the language
claimed.
© 2005 by Chapman & Hall/CRC Press

471
References
[ABC+91]
J.M.Alonso, T.Brady, D.Cooper, V.Ferlini, M.Lustig,
M.Mihalik, M.Shapiro, and H.Short. Notes on word hyperbolic
groups. In A.Haefliger É.Ghys and A.Verjovsky, editors, Group
Theory from a Geometrical Viewpoint (Trieste, 1990), pages
3–63. World Sci. Publishing Co., Inc., River Edge, NJ, 1991.
[Adi58]
S.I.Adian. On algorithmic problems in effectively complete
classes of groups. Doklady Akad. Nauk. SSR, 123:13–16, 1958.
[Adi79]
S.I.Adian. The Burnside Problem and Identities in Groups.
Springer-Verlag, Berlin, 1979. Translated from the Russian
by John Lennox and James Wiegold.
[AHU74]
A.V.Aho, A.V.Hopcroft, and J.D.Ullman. The Design and
Analysis of Computer Algorithms. Reading: Addison-Wesley,
1974.
[AK92]
E.F.Assmus, Jr. and Jenny Key. Designs and Their Codes,
volume 103 of CUP Tracts in Mathematics. Cambridge
University Press, 1992.
[AMW82]
D.G.Arrell, S.Manrai, and M.F.Worboys. A procedure for
obtaining simplified defining relations for a subgroup. In C.M.
Campbell and E.F.Robertson, editors, Groups—St Andrews
1981, volume 71 of London Math. Soc. Lecture Note Ser.,
pages 155–159, Cambridge, 1982. Cambridge University Press.
[Arc02]
Claude Archer. Classification of group extensions. PhD thesis,
Université Libre de Bruxelles, 2002.
[Art55]
E.Artin. The orders of the classical simple groups. Comm.
Pure Appl. Math., 8:455–472, 1955.
[Asc84]
M.Aschbacher. On the maximal subgroups of the finite classical
groups. Invent. Math., 76:469–514, 1984.
[Atk75]
M.D.Atkinson. An algorithm for finding the blocks of a
permutation group. Math. Comp., 29:911–913, 1975.
[Atk84]
Michael D.Atkinson, editor. Computational Group Theory,
London, New York, 1984. (Durham, 1982), Academic Press.
[ATL] 
ATLAS of Finite Group Representations. http://
web.mat.bham.ac.uk/atlas/index.html.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
472
[Bab91]
László Babai. Local expansion of vertex-transitive graphs
and random generation in finite groups. In Theory of
Computing, pages 164–174, New York, 1991. (Los Angeles,
1991), Association for Computing Machinery.
[BB99]
L.Babai and R.Beals. A polynomial-time theory for black box
groups I. In Groups St Andrews 1997 in Bath, volume 261 of
London Math. Soc. Lecture Note Ser., pages 30–64,
Cambridge, 1999. Cambridge University Press.
[BBN+78]
Harold Brown, Rolf Bülow, Joachim Neubüser, Hans
Wondratschek, and Hans Zassenhaus. Crystallographic
Groups of Four-Dimensional Space. Wiley-Interscience, New
York, Chicester, Brisbane, Toronto, 1978.
[BBR93]
László Babai, Robert Beals, and Daniel Rockmore. Deciding
finiteness of matrix groups in deterministic polynomial time.
In Proc. of International Symposium on Symbolic and
Algebraic Computation ISSAC ’93, pages 117–126. (Kiev), ACM
Press, 1993.
[BC82]
Gregory Butler and John J.Cannon. Computing in permutation
and matrix groups I: Normal closure, commutator subgroups,
series. Math. Comp., 39:663–670, 1982.
[BC89]
Gregory Butler and John J.Cannon. Computing in permutation
and matrix groups III: Sylow subgroups. J. Symbolic Comput.,
8:241–252, 1989.
[BC91]
Gregory Butler and John J.Cannon. Computing Sylow
subgroups using homomorphic images of centralizers. J.
Symbolic Comput., 12:443–458, 1991.
[BC93]
Wieb Bosma and John Cannon. Handbook of MAGMA
Functions. School of Mathematics and Statistics, University
of Sydney, 1993.
[BCFS91]
László Babai, Gene Cooperman, Larry Finkelstein, and Ákos
Seress. Nearly linear time algorithms for permutation groups
with a small base. In Proc. of International Symposium on
Symbolic and Algebraic Computation ISSAC ’91, pages 200–
209. (Bonn), ACM Press, 1991.
[BCM81a]
G.Baumslag, F.B.Cannonito, and C.F.Miller III. Computable
algebra and group embeddings. J. Algebra, 69:186–212, 1981.
[BCM81b]
G.Baumslag, F.B.Cannonito, and C.F.Miller III. Some
recognizable properties of solvable groups. Math. Z., 178:289–
295, 1981.
[BE99a]
Hans Ulrich Besche and Bettina Eick. Construction of finite
groups. J. Symbolic Comput., 27:387–404, 1999.
© 2005 by Chapman & Hall/CRC Press

References
473
[BE99b]
Hans Ulrich Besche and Bettina Eick. The groups of order at
most 1000 except 512 and 768. J. Symbolic Comput., 27:405–
413, 1999.
[BE01]
Hans Ulrich Besche and Bettina Eick. The groups of order
qn . p. Comm. Algebra, 29:1759–1772, 2001.
[Bea93a]
Robert M.Beals. Computing blocks of imprimitivity for small-
base groups in nearly linear time. In Finkelstein and Kantor
[FK93], pages 17–26.
[Bea93b]
Robert M.Beals. An elementary algorithm for computing the
composition factors of a permutation group. In Proc. of
International Symposium on Symbolic and Algebraic
Computation ISSAC ’93, pages 127–134. Kiev, ACM Press,
1993.
[Bee84]
M.J.Beetham. Space saving in coset enumeration. In Atkinson
[Atk84], pages 19–25.
[BEO01]
Hans Ulrich Besche, Bettina Eick, and E.A.O’Brien. The
groups of order at most 2000. Electronic Research
Announcements of the AMS, 7:1–4, 2001.
[BEO02]
Hans Ulrich Besche, Bettina Eick, and E.A.O’Brien. A
millennium project: constructing small groups. Internat. J.
Algebra Comput., 12:623–644, 2002.
[Ber67]
E.R.Berlekamp. Factoring polynomials over finite fields. Bell
System Technical Journal, 46:1853–1859, 1967.
[Ber70]
E.R.Berlekamp. Factoring polynomials over large finite fields.
Math. Comp., 24:713–735, 1970.
[BH93]
Brigitte Brink and Robert B.Howlett. A finiteness property
and an automatic structure for Coxeter groups. Math. Ann.,
296:179–190, 1993.
[BK01]
P.A.Brooksbank and W.M.Kantor. On constructive recognition
of a black box PSL(d,q). In Kantor and Seress [KS97], pages
95–111.
[BKPS02]
L.Babai, W.M.Kantor, P.Pálfy, and Á.Seress. Black-box
recognition of finite simple groups of Lie type by statistics of
element orders. J. Group Theory, 5:383–401, 2002.
[BKW74]
A.J.Bayes, J.Kautsky, and J.W.Wamsley. Computation in
nilpotent groups (application). In Proc. Second Internat. Conf.
Theory of Groups, volume 372 of Lecture Notes in Math.,
pages 82–89, Berlin, Heidelberg, New York, 1974. (Canberra,
1973), Springer-Verlag.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
474
[BLGN+02]
R.Beals, C.R.Leedham-Green, A.C.Niemeyer, C.E.Praeger,
and A.Seress. Permutations with restricted cycle structure
and an algorithmic application. Combin. Probab. Comput.,
11:447–464, 2002.
[BM83]
G.Butler and J.McKay. The transitive groups of degree up to
11. Comm. Algebra, 11:863–911, 1983.
[Boo59]
W.W.Boone. The word problem. Annals of Mathematics,
70:207–265, 1959.
[BP00]
S.Bratus and I.Pak. Fast constructive recognition of a black
box group isomorphic to Sn or An using Goldbach’s conjecture.
J. Symbolic Comput., 29:33–57, 2000.
[Bro69]
Harold Brown. An algorithm for the determination of space
groups. Math. Comp., 23:499–514, 1969.
[Bro03]
P.A.Brooksbank. Constructive recognition of classical groups
in their natural representation. J. Symbolic Comput., 35:195–
239, 2003.
[BS84]
László Babai and Endre Szemerédi. On the complexity of
matrix group problems, I. In Proc. 25th IEEE Sympos.
Foundations Comp. Sci., pages 229–240, 1984.
[Buc87]
B.Buchberger. The history and basic features of the critical-
pair/completion procedure. J. Symbolic Comput., 3:3–38, 1987.
[Bur02]
W.Burnside. On an unsettled question in the theory of
discontinuous groups. Quart. J. Pure Appl. Math, 33:230–
238, 1902.
[Bur11]
W.Burnside. Theory of Groups of Finite Order. Cambridge
University Press. Reprinted by Dover 1955, New York, 2nd
edition, 1911.
[But76]
Gregory Butler. The Schreier algorithm for matrix groups. In
SYMSAC ’76, Proc. ACM Sympos. Symbolic and Algebraic
Computation, pages 167–170, New York, 1976. (New York,
1976), Association for Computing Machinery.
[But79]
Gregory Butler. Computational Approaches to Certain
Problems in the Theory of Finite Groups. PhD thesis,
University of Sydney, 1979.
[But83]
Gregory Butler. Computing normalizers in permutation
groups. J. Algorithms, 4:163–175, 1983.
[But84]
Gregory Butler. On computing double coset representatives
in permutation groups. In Atkinson [Atk84], pages 283–290.
© 2005 by Chapman & Hall/CRC Press

References
475
[But91]
Gregory Butler. Fundamental Algorithms for Permutation
Groups, volume 559 of Lecture Notes in Comput. Sci.
Springer-Verlag, Berlin, Heidelberg, New York, 1991.
[But93]
Gregory Butler. The transitive groups of degree fourteen
and fifteen. J. Symbolic Comput., 16:413–422, 1993.
[Cam81]
P.J.Cameron. Finite permutation groups and finite simple
groups. Bull. Lon. Math. Soc., 13:1–22, 1981.
[Cam99]
Peter J.Cameron. Permutation Groups, volume 45 of London
Math. Soc. Stud. Texts. Cambridge University Press,
Cambridge, 1999.
[Can72]
John J.Cannon. Graphs and defining relations. In Proc. First
Australian Conf. on Combinatorial Mathematics, pages 215–
233. (Newcastle, 1972), 1972.
[Can73]
John J.Cannon. Construction of defining relators for finite
groups. Discrete Math., 5:105–129, 1973.
[Can84]
James W.Cannon. The combinatorial structure of cocompact
discrete hyperbolic group. Geom. Dedicata, 296:123–148, 1984.
[Car72]
Roger W.Carter. Simple Groups of Lie Type. John Wiley &
Sons, London, New York, Sydney, Toronto, 1972.
[CCH97a]
J.J.Cannon, B.C.Cox, and D.F.Holt. Computing chief series,
composition series and socles in large permutation groups. J.
Symbolic Comput., 24:285–301, 1997.
[CCH97b]
J.J.Cannon, B.C.Cox, and D.F.Holt. Computing Sylow
subgroups of permutation groups. J. Symbolic Comput.,
24:303–316, 1997.
[CCH01]
J.J.Cannon, B.C.Cox, and D.F.Holt. Computing the subgroups
of a permutation group. J. Symbolic Comput., 31:149–161,
2001.
[CCN+85]
J.H.Conway, R.T.Curtis, S.P.Norton, R.A.Parker, and R.A.
Wilson. Atlas of Finite Groups. Clarendon Press, Oxford, 1985.
[CD02]
M.Conder and P.Dobcsányi. Trivalent symmetric graphs on
up to 768 vertices. J. Combin. Math. Combin. Comput., 40:41–
63, 2002.
[CD05]
M.Conder and P.Dobcsányi. Applications and adaptations of
the low index subgroups procedure. Math. Comp., 74:485–
497, 2005.
[CDHW73]
John J.Cannon, Lucien A.Dimino, George Havas, and Jane
M.Watson. Implementation and analysis of the Todd-Coxeter
algorithm. Math. Comp., 27:463–490, 1973.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
476
[CELG04]
John Cannon, Bettina Eick, and Charles Leedham-Green.
Special polycyclic generating sequences for finite soluble groups.
To appear in J. Symbolic Comput., 2004.
[CF92]
Gene Cooperman and Larry Finkelstein. A fast cyclic base
change for permutation groups. In Proceedings of
International Symposium on Symbolic and Algebraic
Computation ISSAC ’92, pages 224–232. ACM Press, 1992.
[CFJR01]
T.Chinburg, E.Friedman, K.N.Jones, and A.W.Reid. The
arithmetic hyperbolic 3-manifold of smallest volume. Ann.
Scuola Norm. Sup. Pisa Cl. Sci. (4), 30:1–40, 2001.
[CFS90]
G.Cooperman, L.Finkelstein, and N.Sarawagi. A random
base change algorithm for permutation groups. In Proc. of
International Symposium on Symbolic and Algebraic
Computation ISSAC ’90, pages 161–168. (Kiev), ACM Press,
1990.
[CH03]
John J.Cannon and Derek F.Holt. Automorphism group
computation and isomorphism testing in finite groups. J.
Symbolic Comput., 35:241–267, 2003.
[CH04]
John J.Cannon and Derek F.Holt. Computing maximal
subgroups of finite groups. J. Symbolic Comput., 37:589–609,
2004.
[Cha95]
R.Charney. Geodesic automation and growth functions for
Artin groups of finite type. Math. Ann., 301:307–324, 1995.
[Che]
The CHEVIE Homepage. http://www.math.rwth-aachen.de/
homes/CHEVIE/.
[CLG97]
F.Celler and C.R.Leedham-Green. Calculating the order of an
invertible matrix. In Finkelstein and Kantor [FK97], pages
55–60.
[CLG98]
F.Celler and C.R.Leedham-Green. A constructive recognition
algorithm for the special linear group. In The Atlas of Finite
Groups: Ten Years On, volume 249 of London Mathemtical
Society Lecture Note Series, pages 11–26, 1998.
[CLGM+95]
Frank Celler, Charles R.Leedham-Green, Scott H.Murray,
Alice C.Niemeyer, and E.A.O’Brien. Generating random
elements of a finite group. Comm. Algebra, 23:4931–4948,
1995.
[CLGO]
M.D.E.Conder, C.R.Leedham-Green, and E.A.O’Brien.
Constructive recognition of PSL(2, q). To appear in Trans.
Amer. Math. Soc.
© 2005 by Chapman & Hall/CRC Press

References
477
[CLRS02]
Thomas H.Cormen, Charles E.Leiserson, Ronald L.Rivest, and
Clifford Stein. Introduction to Algorithms. MIT Press,
Cambridge, MA, London, 2nd edition, 2002.
[CMT04]
Arjeh M.Cohen, Scott H.Murray, and D.E.Taylor. Computing
in groups of Lie type. Math. Comp., 73:1477–1498, 2004.
[CNW90]
Frank Celler, Joachim Neubüser, and Charles R.B.Wright.
Some remarks on the computation of complements and
normalizers in soluble groups. Acta Applicandae Mathema-
ticae, 21:57–76, 1990.
[Coh73]
Henri Cohen. A Course in Computational Algebraic Number
Theory, volume 138 of Graduate Texts in Math. Springer-
Verlag Inc., New York, 1973.
[Con] 
Conway polynomials for finite fields. http://www.math.rwth-
aachen.de/~Frank.Luebeck/ConwayPol/.
[Cor] 
The clrscode Package for LaTeX2e. http://www.cs.dartmouth.
edu/~thc/clrscode/.
[CP93]
John Cannon and Catherine Playoust. An Introduction to
MAGMA. School of Mathematics and Statistics, University of
Sydney, 1993.
[CR80]
C.M.Campbell and E.F.Robertson. A deficiency zero
presentation for SL(2, p). Bull. Lon. Math. Soc., 12:17–20,
1980.
[CS97]
J.J.Cannon and B.Souvignier. On the computation of conjugacy
classes in permutation groups. In W.Küchlin, editor,
Proceedings of International Symposium on Symbolic and
Algebraic Computation, Maui, July 21–23, 1997, pages
392–399. Association for Computing Machinery, 1997.
[CS98]
J.J.Cannon and B.Souvignier. On the computation of normal
subgroups in permutation groups. unpublished, 1998.
[CW90]
D.Coppersmith and S.Winograd. Matrix multiplication via
arithmetic progressions. J. Symbolic Comput., 8:251–280,
1990.
[CZ81]
D.G.Cantor and H.Zassenhaus. A new algorithm for factoring
polynomials over a finite field. Math. Comp, 36:587–592, 1981.
[Deh11]
M.Dehn. Über unendliche diskontinuierliche Gruppen. Math.
Ann., 71:116–144, 1911.
[Dek96]
Karel Dekimpe. Almost-Bieberbach Groups: Affine and
Polynomial Structures, volume 1639 of Lecture notes in Math.
Springer, 1996.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
478
[DF87]
J.R.Driscoll and M.L.Furst. Computing short generating
sequences. Info. and Comput., 72:117–132, 1987.
[DGK83]
P.Diaconis, R.L.Graham, and W.M.Kantor. The mathematics
of perfect shuffles. Adv. in Appl. Math., 4:175–196, 1983.
[DH92]
Klaus Doerk and Trevor Hawkes. Finite Solvable Groups. De
Gruyter, 1992.
[Dix67]
John D.Dixon. High speed computation of group characters.
Numer. Math., 10:446–450, 1967.
[Dix68]
John D.Dixon. The solvable length of a solvable linear group.
Math. Z., 107:151–158, 1968.
[DM88]
John D.Dixon and Brian Mortimer. The primitive permutation
groups of degree less than 1000. Math. Proc. Camb. Phil.
Soc., 103:213–238, 1988.
[DM96]
John D.Dixon and Brian Mortimer. Permutation Groups,
volume 163 of Graduate Texts in Math. Springer-Verlag, New
York, Heidelberg, Berlin, 1996.
[DS74]
Anke Dietze and Mary Schaps. Determining subgroups of a
given finite index in a finitely presented group. Canad. J.
Math., 26:769–782, 1974.
[DT03]
N.M.Dunfield and W.P.Thurston. The virtual Haken
conjecture: experiments and examples. Geom. Topol., 7:399–
441, 2003.
[ECH+92]
David B.A.Epstein, J.W.Cannon, D.F.Holt, S.V.F.Levy,
M.S.Paterson, and W.P Thurston. Word Processing in Groups.
Jones and Bartlett, Boston, 1992.
[EG81]
S.Even and O.Goldreich. The minimum length generator
problem is NP-hard. J. Algorithms, 2:311–313, 1981.
[EGN97]
Bettina Eick, F.Gähler, and W.Nickel. Computing maximal
subgroups and Wyckoff positions of space groups. Acta Cryst.
A, 53:467–474, 1997.
[EH01a]
Bettina Eick and A.Hulpke. Computing the maximal
subgroups of a permutation group I. In Kantor and Seress
[KS97], pages 155–168.
[EH01b]
D.B.A.Epstein and D.F.Holt. Computation in word-hyperbolic
groups. Internat. J. Algebra Comput., 11:467–487, 2001.
[EH03]
Bettina Eick and Burkhard Höfling. The solvable primitive
permutation groups of degree at most 6560. LMS J. Comput.
Math., 6:29–39, 2003.
© 2005 by Chapman & Hall/CRC Press

References
479
[EHR91]
D.B.A.Epstein, D.F.Holt, and S.E.Rees. The use of Knuth-
Bendix methods to solve the word problem in automatic groups.
J. Symbolic Comput., 12:397–414, 1991.
[Eic93]
Bettina Eick. Spezielle PAG-Systeme im Computera-
lgebrasystem GAP. Diplomarbeit, RWTH Aachen, 1993.
[Eic97]
Bettina Eick. Special presentations for finite soluble groups
and computing (pre-)Frattini subgroups. In Finkelstein and
Kantor [FK97], pages 101–112.
[Eic01a]
Bettina Eick. Algorithms for polycyclic groups.
Habilitationsschrift, Universität Kassel, 2001.
[Eic01b]
Bettina Eick. Computing with infinite polycyclic groups. In
Kantor and Seress [KS97], pages 139–153.
[Eic02]
Bettina Eick. Orbit-stabilizer problems and computing
normalizers for polycyclic groups. J. Symbolic Comput., 34:1–
19, 2002.
[EIFZ96]
D.B.A.Epstein, A.R.Iano-Fletcher, and U.Zwick. Growth
functions and automatic groups. Experimental Math., 5:297–
315, 1996.
[ELGO02]
Bettina Eick, C.R.Leedham-Green, and E.A.O’Brien.
Constructing automorphism groups of p-groups. Comm.
Algebra, 30:2271–2295, 2002.
[ENP]
Bettina Eick, A.C.Niemeyer, and O.Panaia. An infinite
polycyclic quotient algorithm. Submitted.
[EO99]
Bettina Eick and E.A.O’Brien. Enumerating p-groups. J.
Austral. Math. Soc. Ser. A, 67:191–205, 1999.
[EO03]
Bettina Eick and Gretchen Ostheimer. On the orbit stabilizer
problem for integral matrix actions of polycyclic groups. Math.
Comp., 72:1511–1529, 2003.
[EP88]
D.Easdown and C.E.Praeger. On minimal faithful permutation
representations of finite groups. Bull. Aust. Math. Soc., 38:207–
220, 1988.
[EW02]
Bettina Eick and Charles R.B.Wright. Computing subgroups
by exhibition in finite solvable groups. J. Symbolic Comput.,
33:129–143, 2002.
[Fel61]
H.Felsch. Programmierung der Restklassenabzählung einer
Gruppe nach Untergruppen. Numer. Math., 3:250–256, 1961.
[FHL80]
M.Furst, J.Hopcroft, and E.Luks. Polynomial-time algorithms
for permutation groups. In Proc. 21st IEEE Sympos.
Foundations Comp. Sci., pages 36–41, 1980.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
480
[FK93]
Larry Finkelstein and William M.Kantor, editors. Groups
and Computation, volume 11 of Amer. Math. Soc. DIMACS
Series. (DIMACS, 1991), 1993.
[FK97]
Larry Finkelstein and William M.Kantor, editors. Groups
and Computation II, volume 28 of Amer. Math. Soc. DIMACS
Series. (DIMACS, 1995), 1997.
[FN68]
V.Felsch and J.Neubüser. Über ein Programm zur
Berechnung der Automorphismengruppe einer endlichen
Gruppe. Numer. Math., 11:277–292, 1968.
[FN70]
V.Felsch and J.Neubüser. On a programme for the determination
of the automorphism group of a finite group. In Computational
Problems in Abstract Algebra, pages 59–60, Oxford, London,
Edinburgh, 1970. (Oxford, 1967), Pergamon Press.
[FN79]
V.Felsch and J.Neubüser. An algorithm for the computation
of conjugacy classes and centralizers in p-groups. In Edward
W.Ng, editor, Symbolic and Algebraic Computation, volume
72 of Lecture Notes in Comput. Sci., pages 452–465, Berlin,
Heidelberg, New York, 1979. (Marseille, 1979), Springer-
Verlag.
[GAP] 
The GAP Character Table Library. http://www.math.rwth-
aachen. de/~Thomas.Breuer/ctbllib/.
[GAP04]
The GAP Group. GAP—Groups, Algorithms, and
Programming, Version 4.4, 2004. (http://www.gap-
system.org).
[Gas53]
Wolfgang Gaschütz. Über die ø-Untergruppe endlicher
Gruppen. Math. Z., 58:160–170, 1953.
[GCL92]
K.O.Geddes, S.R.Czapor, and G.Labahn. Algorithms for
Computer Algebra. Kluwer Academic Publishers, 1992.
[GdlH90]
E.Ghys and P.de la Harpe., editors. Sur les groupes
hyperboliques d’après Mikhael Gromov, volume 83 of Progress
in Mathematics. Birkhäuser Boston, Inc., Boston, MA, 1990.
[GH97]
S.P.Glasby and R.B.Howlett. Writing representations over
minimal fields. Comm. Algebra, 25:1703–1711, 1997.
[Gil79]
R.H.Gilman. Presentations of groups and monoids. J. Algebra,
57:544–554, 1979.
[Gil84]
R.H.Gilman. Enumerating infinitely many cosets. In Atkinson
[Atk84], pages 267–274.
[GM92]
C.Gunn and D.Maxwell. Not knot. Video, ISBN 0–86720–240–
8, published by AKPeters, Natick, MA, 1992.
© 2005 by Chapman & Hall/CRC Press

References
481
[Gor82]
Daniel Gorenstein. Finite Simple Groups. An Introduction
to Their Classification. The University Series in Mathematics.
Plenum Press, New York and London, 1982.
[Gri82]
R.L.Griess. The friendly giant. Invent. Math., 69:1–102, 1982.
[GS90]
S.P.Glasby and Michael C.Slattery. Computing intersections
and normalizers in soluble groups. J. Symbolic Comput.,
9:637–651, 1990.
[GS91]
S.M.Gersten and H.Short. Small cancellation theory and
automatic groups, II. Invent. Math., 105(3):641–662, 1991.
[Hal59]
Marshall Hall, Jr. The Theory of Groups. Macmillan Co.,
New York, 1959.
[Har]
A.Harkins. Polycyclic groups are not automatic. Submitted.
[Hav74]
George Havas. A Reidemeister-Schreier program. In
Proceedings of the Second Internat. Conf. Theory of Groups,
volume 322 of Lecture Notes in Mathematics, pages 347–356,
Berlin, Heidelberg, New York, 1974. (Canberra, 1973),
Springer-Verlag.
[Hei61]
Hermann Heineken. Engelsche Elemente der Länge drei. Illi-
nois J. Math., 5:681–707, 1961.
[Her94]
Susan M.Hermiller. Rewriting systems for Coxeter groups.
J. of Pure and Applied Algebra, 92:137–148, 1994.
[Hey97]
M-C.Heydemann. Cayley graphs and interconnection
networks. In Graph Symmetry (Montreal 1996), volume 497
of NATO ASI Ser. C, Math. Phys. Sci., pages 167–224. Kluwer
Academic Publishers, 1997.
[HH56]
P.Hall and Graham Higman. On the p-length of p-soluble
groups and reduction theorems for Burnside’s problem. Proc.
London Math. Soc. (3), 6:1–42, 1956.
[HH99]
Derek F.Holt and Darren F.Hurt. Computing automatic coset
systems and subgroup presentations. J. Symbolic Comput.,
27:1–19, 1999.
[HHN01]
G.Havas, D.F.Holt, and M.F.Newman. Certain cyclically
presented groups are infinite. Comm. Algebra, 29:5175–5178,
2001.
[HHR93]
George Havas, Derek F.Holt, and Sarah Rees. Recognizing
badly presented Z-modules. Linear Algebra Appl., 192:137–
163, 1993.
[Hig59]
Graham Higman. Some remarks on varieties of groups. Quart.
J. Math. Oxford Ser. (2), 10:165–178, 1959.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
482
[Hil02]
J.A.Hillman. Four-Manifolds, Geometries and Knots, volume
5 of Geometry and Topology Monographs. Geometry and
Topology Publications, Mathematics Institute, University of
Warwick, 2002.
[His03]
G.Hiss. Algorithms of representation theory. In Computer
Algebra Handbook: Foundations, Applications, Systems,
pages 84–88. Springer-Verlag, 2003.
[HK84]
George Havas and L.G.Kovács. Distinguishing eleven crossing
knots. In Atkinson [Atk84], pages 367–373.
[HL89]
G.Hiss and K.Lux. Brauer Trees of Sporadic Groups. Oxford
University Press, 1989.
[HL04]
L.S.Heath and N.A.Loehr. New algorithms for generating
Conway polynomials over finite fields. J. Symbolic Comput.,
38:1003–1024, 2004.
[HLGOR96a] Derek F.Holt, C.R.Leedham-Green, E.A.O’Brien, and Sarah
Rees. Computing matrix group decompositions with respect
to a normal subgroup. J. Algebra, 184:818–838, 1996.
[HLGOR96b] Derek F.Holt, C.R.Leedham-Green, E.A.O’Brien, and Sarah
Rees. Testing matrix groups for primitivity. J. Algebra,
184:795–817, 1996.
[HLO+04]
P.E.Holmes, S.A.Linton, E.A.O’Brien, A.J.E.Ryba, and
R.A.Wilson. Constructive membership testing in black-box
groups. Preprint, 2004.
[HM97]
George Havas and Bohdan S.Majewski. Integer matrix
diagonalization. J. Symbolic Comput., 24:399–408, 1997.
[HMM98]
G.Havas, Bohdan S.Majewski, and K.R.Matthews. Extended
GCD and Hermite normal form algorithms via lattice basis
reduction. Experimental Math., 7:125–136, 1998.
[HMM99]
G.Havas, Bohdan S.Majewski, and K.R.Matthews. Extended
GCD and Hermite normal form algorithms via lattice basis
reduction (addenda and errata). Experimental Math., 8:205,
1999.
[HMU01]
J.E.Hopcroft, R.Motwani, and J.D.Ullman. Introduction to
Automata Theory, Languages, and Computation. Addison-
Wesley, 2nd edition, 2001.
[HN80]
George Havas and M.F.Newman. Application of computers to
questions like those of Burnside. In Burnside Groups, volume
806 of Lecture Notes in Math., pages 211–230, Berlin,
Heidelberg, New York, 1980. (Bielefeld, 1977), Springer-Verlag.
© 2005 by Chapman & Hall/CRC Press

References
483
[HNO95]
George Havas, M.F.Newman, and E.A.O’Brien. Groups of
deficiency zero. In G.Baumslag et al., editors, Geometric and
Computational Perspectives on Infinite Groups, volume 25 of
Amer. Math. Soc. DIMACS Series, pages 53–67. (DIMACS,
1994), 1995.
[Hol84]
D.F.Holt. The calculation of the Schur multiplier of a
permutation group. In Atkinson [Atk84], pages 307–318.
[Hol85a]
D.F.Holt. A computer program for the calculation of a covering
group of a finite group. J. Pure Appl. Algebra, 35:287–295,
1985.
[Hol85b]
D.F.Holt. The mechanical computation of first and second
cohomology groups. J. Symbolic Comput., 1:351–361, 1985.
[Hol91]
D.F.Holt. The computation of normalizers in permutation
groups. J. Symbolic Comput., 12:499–516, 1991.
[Hol95]
Derek F.Holt. The Warwick automatic group software. In
G.Baumslag et al., editors, Geometric and Computational
Perspectives on Infinite Groups, volume 25 of Amer. Math.
Soc. DIMACS Series, pages 69–82. (DIMACS, 1994), 1995.
[Hol97]
Derek F.Holt. Representing quotients of permutation groups.
Quart. J. Math. (Oxford), 48:347–350, 1997.
[Hop71]
J.E.Hopcroft. An n log n algorithm for minimizing the states
in a finite automaton. In Z.Kohavi, editor, The Theory of
Machines and Computations, pages 189–196, New York, 1971.
Academic Press.
[HP89]
Derek F.Holt and W.Plesken. Perfect Groups. Clarendon
Press, Oxford, 1989.
[HR92]
Derek F.Holt and Sarah Rees. Testing for isomorphism
between finitely presented groups. In Groups, Combinatorics
and Geometry, volume 165 of London Math. Soc. Lecture
Note Ser., pages 459–475, London, 1992. Durham, 1989,
Cambridge University Press.
[HR93]
Derek F.Holt and Sarah Rees. A graphics system for displaying
finite quotients of finitely presented groups. In Finkelstein
and Kantor [FK93], pages 113–126.
[HR94]
Derek F.Holt and Sarah Rees. Testing modules for
irreducibility. J. Austral. Math. Soc. Ser. A, 57:1–16, 1994.
[HR99]
George Havas and Colin Ramsay. Coset enumeration: ACE
version 3. (http://www.csee.uq.edu.au/~cram/ce.html), 1999.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
484
[HS79]
George Havas and L.S.Sterling. Integer matrices and abelian
groups. In Symbolic and Algebraic Computation, volume 72
of Lecture Notes in Comput. Sci., pages 431–451, Berlin,
Heidelberg, New York, 1979. (Marseille, 1979), Springer-
Verlag.
[Hul]
Alexander Hulpke. Constructing transitive permutation
groups. To appear in J. Symbolic Comput.
[Hul96]
Alexander Hulpke. Konstruktion transitiver Permutati-
onsgruppen. PhD thesis, RWTH Aachen, 1996.
[Hul99a]
A.Hulpke. Computing subgroups invariant under a set of
automorphisms. J. Symbolic Comput., 27:415–427, 1999.
[Hul99b]
A.Hulpke. Galois groups through invariant relations. In
Groups St Andrews 1997 in Bath, volume 261 of London
Math. Soc. Lecture Note Ser., pages 379–393, Cambridge,
1999. Cambridge University Press.
[Hup67]
B.Huppert. Endliche Gruppen I, volume 134 of Grundlehren
Math. Wiss. Springer-Verlag, Berlin, Heidelberg, New York,
1967.
[HWW74]
George Havas, G.E.Wall, and J.W.Wamsley. The two generator
restricted Burnside group of exponent five. Bull. Austral. Math.
Soc., 10:459–470, 1974.
[IL00]
Gábor Ivanyos and Klaus Lux. Treating the exceptional cases
of the Meataxe. Experimental Math., 9:373–381, 2000.
[Isa76]
I.M.Isaacs. Character Theory of Finite Groups, volume 69 of
Pure and Applied Mathematics. Academic Press, Berlin,
Heidelberg, New York, 1976.
[Iva94]
Sergei V.Ivanov. The free Burnside groups of sufficiently large
exponents. Internat. J. Algebra Comput., 4(1–2) :ii+308, 1994.
[Jer82]
M.Jerrum. A compact representation for permutation groups.
In Proc. 23rd IEEE Sympos. Foundations Comp. Sci., pages
126–133, 1982.
[Jer85]
M.Jerrum. The complexity of finding minimum length
generator sequences. Theoretical Computer Science, 36:256–
289, 1985.
[JKO99]
D.L.Johnson, A.C.Kim, and E.A.O’Brien. Certain cyclically
presented groups are isomorphic. Comm. Algebra, 27:3531–
3536, 1999.
[JLPW95]
Christoph Jansen, Klaux Lux, Richard Parker, and Robert
Wilson. An Atlas of Brauer Characters, volume 11 of London
© 2005 by Chapman & Hall/CRC Press

References
485
Math. Soc. Monographs (New Series). Clarendon Press,
Oxford, 1995.
[Joh98]
D.L.Johnson. Presentations of Groups, Second Edition,
volume 15 of London Math. Soc. Stud. Texts. Cambridge
University Press, Cambridge, 1998.
[Jor73]
C.Jordan. Sur la limite de transitivité des groupes non alternés.
Bull. Soc. Math. France, 1:40–71, 1873.
[Jür70]
H.Jürgensen. Calculation with the elements of a finite group
given by generators and defining relations. In Leech [Lee70],
pages 47–57.
[Kan85]
William M.Kantor. Sylow’s theorem in polynomial time. J.
Comp. Syst. Sci., 30:359–394, 1985.
[Kan90]
William M.Kantor. Finding Sylow normalizers in polynomial
time. J. Algorithms, 11:523–563, 1990.
[Kan91]
William M.Kantor. Finding composition factors of permutation
groups of degree n≤106. J. Symbolic Comput., 12:517–526,
1991.
[KB70]
D.E.Knuth and P.B.Bendix. Simple word problems in
universal algebras. In Leech [Lee70], pages 263–297.
[KB79]
R.Kannan and A.Bachem. Polynomial algorithms for
computing the Smith and Hermite normal forms of an integer
matrix. SIAM J. Computing, 9:499–507, 1979.
[Ker99]
Adalbert Kerber. Applied finite group actions, volume 19 of
Algorithms and Combinatorics. Springer-Verlag, New York,
Heidelberg, Berlin, 2nd edition, 1999.
[KM02]
J.D.Key and J.Moori. Codes, designs and graphs from the
Janko groups J1 and J2. J. Combin. Math. Combin. Comput.,
40:143–159, 2002.
[KMR03]
J.D.Key, J.Moori, and B.G.Rodrigues. On some designs and
codes from primitive representations of some finite simple
groups. J. Combin. Math. Combin. Comput., 45:3–19, 2003.
[Knu69]
Donald E.Knuth. The Art of Computer Programming. Volume
2: Seminumerical 
Algorithms. 
Addison-Wesley,
Massachusetts, 1969.
[Knu73]
Donald E.Knuth. The Art of Computer Programming. Volume
3: Sorting and Searching. Addison-Wesley, Massachusetts,
1973.
[Knu81]
D.Knuth. Notes on efficient representation of perm groups.
1981.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
486
[Kol82]
G.Kolata. Perfect shuffles and their relation to math. Science,
216:505–506, 1982.
[KS97]
William M.Kantor and Ákos Seress, editors. Groups and
Computation III, volume 8 of Ohio State University Research
Institute Publications, Berlin, New York, 1997. (DIMACS,
1999), Walter de Gruyter.
[KS01]
W.M.Kantor and Á.Seress. Black box classical groups.
Memoirs Amer. Math. Soc., 149, No. 708, 2001.
[Lau82]
Reinhard Laue. Computing double coset representatives for
the generation of solvable groups. In Jacques Calmet, editor,
Computer algebra : EUROCAM ’82, European Computer
Algebra Conference, Marseille, France, 5–7 April 1982, volume
144 of Lecture Notes in Comput. Sci., pages 65–70, Berlin,
1982. Springer.
[LeC86]
P.LeChenadec. A catalogue of complete presentations. J.
Symbolic Comput., 2:363–381, 1986.
[Lee63]
John Leech. Coset enumeration on digital computers. Proc.
Camb. Phil. Soc., 59:257–267, 1963.
[Lee70]
J.Leech, editor. Computational problems in abstract algebra,
Oxford, 1970. (Oxford, 1967), Pergamon Press.
[Leo80a]
Jeffrey S.Leon. Finding the order of a permutation group. In
Bruce Cooperstein and Geoffrey Mason, editors, Finite Groups,
volume 37 of Proc. Sympos. Pure Math., pages 511–517,
Providence, RI, 1980. (Santa Cruz, 1979), Amer. Math. Soc.
[Leo80b]
Jeffrey S.Leon. On an algorithm for finding a base and strong
generating set for a group given by generating permutations.
Math. Comp., 20:941–974, 1980.
[Leo84]
Jeffrey S.Leon. Computing automorphism groups of
combinatorial objects. In Atkinson [Atk84], pages 321–335.
[Leo91]
Jeffrey S.Leon. Permutation group algorithms based on
partitions, I: Theory and algorithms. J. Symbolic Comput.,
12:533–583, 1991.
[LG84]
C.R.Leedham-Green. A soluble group algorithm. In Atkinson
[Atk84], pages 85–101.
[LGN80]
C.R.Leedham-Green and M.F.Newman. Space groups and
groups of prime-power order I. Arch. Math. (Basel), 35:193–
202, 1980.
[LGNW69]
C.R.Leedham-Green, P.M.Neumann, and J.Wiegold. The
breadth and the class of a finite p-group. J. London Math.
Soc. (2), 1:409–420, 1969.
© 2005 by Chapman & Hall/CRC Press

References
487
[LGO97a]
C.R.Leedham-Green and E.A.O’Brien. Recognising tensor
products of matrix groups. Internat. J. Algebra Comput.,
7:541–559, 1997.
[LGO97b]
C.R.Leedham-Green and E.A.O’Brien. Tensor products are
projective geometries. J. Algebra, 189:514–528, 1997.
[LGO02]
C.R.Leedham-Green and E.A.O’Brien. Recognising tensor-
induced matrix groups. J. Algebra, 253:14–30, 2002.
[LGS90]
C.R.Leedham-Green and L.H.Soicher. Collection from the
left and other strategies. J. Symbolic Comput., 9:665–675,
1990.
[LGS98]
C.R.Leedham-Green and L.H.Soicher. Symbolic collection
using Deep Thought. LMS J. Comput. Math., 1:9–24, 1998.
[Lie85]
Martin W.Liebeck. On the orders of maximal subgroups of
the finite classical groups. Proc. London Math. Soc. (3), 50:426–
446, 1985.
[LMR94]
Klaus Lux, Jürgen Müller, and Michael Ringe. Peakword
condensation and submodule lattices: an application of the
Meat-Axe. J. Symbolic Comput., 17:529–544, 1994.
[LNS84]
R.Laue, J.Neubüser, and U.Schoenwaelder. Algorithms for
finite soluble groups and the SOGOS system. In Atkinson
[Atk84], pages 105–135.
[Lo98]
Eddie H.Lo. A polycyclic quotient algorithm. J. Symbolic
Comput., 25:61–97, 1998.
[LPS88]
Martin W.Liebeck, Cheryl E.Praeger, and Jan Saxl. On the
O’Nan-Scott theorem for finite primitive permutation groups.
J. Austral. Math. Soc. (Series A), 44:389–396, 1988.
[Lüb02]
Frank Lübeck. Computation of elementary divisors of integer
matrices. J. Symbolic Comput., 33:57–65, 2002.
[Luk82]
Eugene M.Luks. Isomorphism of graphs of bounded valence
can be tested in polynomial time. J. Comp. Syst. Sci., 25:42–
65, 1982.
[Luk92]
Eugene M.Luks. Computing in solvable matrix groups. In
Proc. 33rd IEEE Sympos. Foundations Comp. Sci., pages
111–120, 1992.
[Luk93]
Eugene M.Luks. Permutation groups and polynomial-time
computation. In Finkelstein and Kantor [FK93], pages 139–
175.
[Lys96]
I.G.Lysënok. Infinite Burnside groups of even period. Izv. Ross.
Akad. Nauk Ser. Mat., 60(3):3–224, 1996.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
488
[Mac74]
I.D.Macdonald. A computer application to finite p-groups. J.
Austral. Math. Soc. Ser. A, 17:102–112, 1974.
[Mac87]
I.D.Macdonald. Nilpotent quotient algorithms. In Proceedings
of Groups—St Andrews 1985, volume 121 of London Math.
Soc. Lecture Note Ser., pages 268–272, Cambridge, 1987.
Cambridge University Press.
[Mag] 
New York Group Theory Cooperative at CCNY. http://www.
grouptheory.org/.
[Mag04]
Computational Algebra Group, School of Mathematics and
Statistics, University of Sydney. The Magma Computational
Algebra System for Algebra, Number Theory and Geometry,
2004. (http://magma.maths.usyd.edu.au/magma/).
[Mas91]
William S.Massey. A Basic Course in Algebraic Topology,
volume 127 of Graduate Texts in Math. Springer-Verlag Inc.,
New York, 1991.
[McK70]
John McKay. The construction of the character table of a finite
group from generators and relations. In Leech [Lee70], pages
89–100.
[Mil92]
C.F.Miller III. Decision problems for groups—survey and
reflections. In G.Baumslag and C.F.Miller III, editors,
Algorithms and Classification in Combinatorial Group
Theory, volume 23 of MSRI publications, pages 1–60. Springer-
Verlag, 1992.
[Min98]
Torsten Minkwitz. An algorithm for solving the factorization
problem in permutation groups. J. Symbolic Comput., 26:89–
95, 1998.
[MM87]
S.Medvedoff and K.Morrison. Groups of perfect shuffles. Math.
Mag., 60:3–14, 1987.
[MN89]
M.Mecky and J.Neubüser. Some remarks on the computation
of conjugacy classes of soluble groups. Bull. Austral. Math.
Soc., 40:281–292, 1989.
[MNRW02]
Jürgen Müller, Max Neunhöffer, Frank Röhr, and Robert
Wilson. Completing the Brauer trees for the sporadic simple
Lyons group. LMS J. Comput. Math., 5:18–33, 2002.
[MO95]
Scott H.Murray and E.A.O’Brien. Selecting base points for
the Schreier-Sims algorithm for matrix groups. J. Symbolic
Comput., 19:577–584, 1995.
[MPR94]
G.McShane, J.Parker, and I.Redfern. Drawing limit sets of
Kleinian groups using finite state automata. Experimental
Math., 3:153–172, 1994.
© 2005 by Chapman & Hall/CRC Press

References
489
[Neb95]
Gabrielle Nebe. Endliche rationale Matrixgruppen vom Grad
24, volume 12 of Aachener Beiträge zur Mathematik. RWTH
Aachen, 1995.
[Neu60]
J.Neubüser. Untersuchungen des Untergruppenverbandes
endlicher Gruppen auf einer programmgesteuerten
elektronischen Dualmaschine. Numer. Math., 2:280–292,
1960.
[Neu61]
J.Neubüser. Bestimmung der Untergruppenverbände
endlicher p-Gruppen auf einer programmgesteuerten
elektronischen Dualmaschine. Numer. Math., 3:271–278,
1961.
[Neu70]
J.Neubüser. Investigations of groups on computers. In Leech
[Lee70], pages 1–19.
[Neu82]
J.Neubüser. An elementary introduction to coset table methods
in computational group theory. In Groups—St Andrews 1981,
volume 71 of London Math. Soc. Lecture Note Ser., pages 1–
45, Cambridge, 1982. Cambridge University Press.
[Neu87]
Peter M.Neumann. Some algorithms for computing with finite
permutation groups. In E.F.Robertson and C.M.Campbell,
editors, Proceedings of Groups—St Andrews 1985, volume
121 of London Math. Soc. Lecture Note Ser., pages 59–92,
Cambridge, 1987. Cambridge University Press.
[Neu95]
J.Neubüser. An invitation to computational group theory. In
C.M.Campbell, T.C.Hurley, E.F.Robertson, S.J.Tobin, and
J.J.Ward, editors, Groups’ 93—Galway/St. Andrews, volume
212 of London Math. Soc. Lecture Note Ser., pages 457–475.
Cambridge University Press, 1995.
[New51]
M.H.A.Newman. The influence of automatic computers on
mathematical methods. In Manchester University Computer
Inaugural Conference, pages 13–15, 1951.
[New76]
M.F.Newman. Calculating presentations for certain kinds of
quotient groups. In SYMSAC ’76, Proc. ACM Sympos.
Symbolic and Algebraic Computation, pages 2–8, New York,
1976. (New York, 1976), Association for Computing Machinery.
[New77]
M.F.Newman. Determination of groups of prime-power order.
In Group Theory, volume 573 of Lecture Notes in Math., pages
73–84, Berlin, Heidelberg, New York, 1977. (Canberra, 1975),
Springer-Verlag.
[New90]
M.F.Newman. Proving a group infinite. Arch. Math., 54:209–
211, 1990.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
490
[Nic88]
Werner Nickel. Endliche Körper in dem Gruppentheoretischen
Programmsystem GAP. Diplomarbeit, RWTH, Aachen, 1988.
[Nic93]
Werner Nickel. Central extensions of polycyclic groups. PhD
thesis, Australian National University, Australian National
University, 1993.
[Nic95]
Werner Nickel. Computing nilpotent quotients of finitely
presented groups. In G.Baumslag et al., editors, Geometric
and Computational Perspectives on Infinite Groups, volume
25 of Amer. Math. Soc. DIMACS Series, pages 175–191.
(DIMACS, 1994), 1995.
[Nie]
A.C.Niemeyer. Constructive recognition of normalisers of small
extra-special matrix groups. To appear in Internat. J. Algebra
Comput.
[Nie93]
Alice C.Niemeyer. Computing Presentations for Soluble
Groups. PhD thesis, Australian National University, 1993.
[NNN98]
M.F.Newman, Werner Nickel, and Alice C.Niemeyer.
Descriptions of groups of prime-power order. J. Symbolic
Comput., 25:665–682, 1998.
[NO96]
M.F.Newman and E.A.O’Brien. Application of computers to
questions like those of Burnside, II. Internat. J. Algebra
Comput., 6:593–605, 1996.
[NO99]
M.F.Newman and E.A.O’Brien. Classifying 2-groups by co-
class. Trans. Amer. Math. Soc., 351:131–169, 1999.
[Nor80]
Simon Norton. The construction of J4. In Bruce Cooperstein
and Geoffrey Mason, editors, Proc. Santa Cruz Conference on
Finite Groups, pages 271–277. Amer. Math. Soc., 1980.
[Nov55]
P.S.Novikov. On the algorithmic unsolvability of the word
problem in group theory. Trudy Math. Inst. im. Stevlov, 44:1–
143, 1955.
[NOVL04]
M.F.Newman, E.A.O’Brien, and M.R.Vaughan-Lee. Groups
and nilpotent Lie rings whose order is the sixth power of a
prime. J. Algebra, 278:383–401, 2004.
[NP92]
Peter M.Neumann and Cheryl E.Praeger. A recognition
algorithm for special linear groups. Proc. London Math. Soc.
(3), 65:555–603, 1992.
[NP95]
G.Nebe and W.Plesken. Finite rational matrix groups.
Memoirs Amer. Math. Soc., 116, No. 556, 1995.
[NP98]
Alice C.Niemeyer and Cheryl E.Praeger. A recognition
algorithm for classical groups over finite fields. Proc. London
Math. Soc., 77:117–169, 1998.
© 2005 by Chapman & Hall/CRC Press

References
491
[NPP84]
J.Neubüser, H.Pahlings, and W.Plesken. CAS; design and
use of a system for the handling of characters of finite groups.
In Atkinson [Atk84], pages 145–183.
[O’B89]
E.A.O’Brien. The groups of order dividing 256. Bull. Austral.
Math. Soc., 39:159–160, 1989.
[O’B90]
E.A.O’Brien. The p-group generation algorithm. J. Symbolic
Comput., 9:677–698, 1990.
[O’B91]
E.A.O’Brien. The groups of order 256. J. Algebra, 143(1):219–
235, 1991.
[O’B94]
E.A.O’Brien. Isomorphism testing for p-groups. J. Symbolic
Comput., 17:133–147, 1994.
[OPS98]
J.Opgenorth, W.Plesken, and T.Schulz. Crystallographic
algorithms and tables. Acta. Cryst., A54:517–531, 1998.
[OVL02]
E.A.O’Brien and M.R.Vaughan-Lee. The 2-generator restricted
Burnside group of exponent 7. Internat. J. Algebra Comput.,
12:575–592, 2002.
[Pak01]
I.Pak. What do we know about the product replacement
algorithm? In Kantor and Seress [KS97], pages 301–347.
[Pap95]
P.Papasoglu. Strongly geodesically automatic groups are
hyperbolic. Invent. Math., 121(2):323–334, 1995.
[Par84]
R.A.Parker. The computer calculation of modular characters
(the Meat-Axe). In Atkinson [Atk84], pages 267–274.
[Pas68]
D.Passman. Permutation Groups. W.A.Benjamin, New York,
Amsterdam, 1968.
[Ple81]
Vera Pless. Introduction to the Theory of Error-Correcting
Codes. Wiley-Interscience Series in Discrete Mathematics.
John Wiley & Sons Inc, 1981.
[Ple87]
W.Plesken. Towards a soluble quotient algorithm. J. Symbolic
Comput., 4:111–122, 1987.
[Rab58]
M.O.Rabin. Recursive unsolvability of group theoretic
problems. Ann. Math., 67:172–194, 1958.
[RD04]
C.M.Roney-Dougal. Conjugacy of subgroups of the general
linear group. Experimental Math., 13:151–163, 2004.
[RDU03]
C.M.Roney-Dougal and W.R.Unger. The affine primitive
permutation groups of degree less than 1000. J. Symbolic
Comput., 35:421–439, 2003.
[Ree98]
Sarah Rees. Automatic groups associated with word orders
other than shortlex. Internat. J. Algebra Comput., 8:575–
598, 1998.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
492
[Rei95]
Alan W.Reid. A non-Haken hyperbolic 3-manifold covered by
a surface bundle. Pacific J. Math., 167:163–182, 1995.
[Rin92]
Michael Ringe. The C MeatAxe. Lehrstuhl D für Mathematik,
RWTH, Aachen, 1992.
[RM90]
G.F.Royle and B.D.McKay. The transitive graphs with at most
26 vertices. Ars Combin., 30:161–176, 1990.
[Rob81]
Derek J.Robinson. Applications of cohomology to the theory of
groups. In C.M.Campbell and E.F.Robertson, editors,
Groups—St Andrews 1981, volume 71 of London Math. Soc.
Lecture Note Ser., pages 46–80. Cambridge University Press,
1981.
[Rob82]
Derek J.Robinson. A Course in the Theory of Groups, volume
80 of Graduate Texts in Math. Springer-Verlag, New York,
Heidelberg, Berlin, 1982.
[Rón90]
Lajos Rónyai. Computing the structure of finite algebras. J.
Symbolic Comput., 9:355–373, 1990.
[Rot94]
Joseph J.Rotman. An Introduction to the Theory of Groups.
Springer-Verlag, Berlin and Heidelberg, 4th edition, 1994.
[Rot02]
Joseph J.Rotman. Advanced Modern Algebra. Prentice-Hall,
Pearson Education, NJ, 2002.
[Roy87]
Gordon F.Royle. The transitive groups of degree twelve. J.
Symbolic Comput., 4:255–268, 1987.
[RP89]
G.F.Royle and C.E.Praeger. Constructing the vertex-transitive
graphs of order 24. J. Symbolic Comput., 8:309–326, 1989.
[Ryb90]
A.J.E.Ryba. Computer condensation of modular
representations. J. Symbolic Comput., 9:591–600, 1990.
[Ryb01]
A.J.E.Ryba. Condensation of symmetrized tensor powers. J.
Symbolic Comput., 32:273–289, 2001.
[San81]
G.Sandlöbes. Perfect groups of order less than 104. Comm.
Algebra, 9:477–490, 1981.
[Sch90a]
Gerhard J.A.Schneider. Computing with endomorphism rings
of modular representations. J. Symbolic Comput., 9:607–636,
1990.
[Sch90b]
Gerhard J.A. Schneider. Dixon’s character table algorithm
revisited. J. Symbolic Comput., 9:601–606, 1990.
[Sco64]
W.R.Scott. Group Theory. Dover Publications, Inc., Mineola,
NY, 1964.
© 2005 by Chapman & Hall/CRC Press

References
493
[Sco80]
L.L.Scott. Representations in characteristic p. In Bruce
Cooperstein and Geoffrey Mason, editors, Finite Groups,
volume 37 of Proc. Sympos. Pure Math., pages 319–331,
Providence, RI, 1980. (Santa Cruz, 1979), Amer. Math. Soc.
[Seg83]
Daniel Segal. Polycyclic Groups. Cambridge University Press,
Cambridge, 1983.
[Seg90]
Dan Segal. Decidable properties of polycyclic groups. Proc.
London Math. Soc. (3), 61:497–528, 1990.
[Ser97]
Ákos Seress. An introduction to computational group theory.
Notices Amer. Math. Soc., 44:671–679, 1997.
[Ser03]
Ákos Seress. Permutation Group Algorithms. Cambridge
Tracts in Mathematics 152. Cambridge University Press,
2003.
[Sho92]
M.W.Short. The Primitive Soluble Permutation Groups of
Degree Less than 256, volume 1519 of Lecture Notes in Math.
Springer-Verlag, Berlin, Heidelberg, New York, 1992.
[Shp92]
Igor Shparlinski. Computational and Algorithmic Problems
in Finite Fields, volume 1519. Kluwer Academic Publishers,
1992.
[Sim70]
Charles C.Sims. Computational methods in the study of
permutation groups. In Leech [Lee70], pages 169–183.
[Sim71a]
Charles C.Sims. Computation with permutation groups. In
Proc. Second Symp. on Symbolic and Algebraic Manipulation.
ACM Press, 1971.
[Sim71b]
Charles C.Sims. Determining the conjugacy classes of
permutation groups. In Garret Birkhoff and Marshall Hall,
Jr., editors, Computers in Algebra and Number Theory,
volume 4 of Proc. Amer. Math. Soc., pages 191–195,
Providence, RI, 1971. (New York, 1970), Amer. Math. Soc.
[Sim73]
Charles C.Sims. The existence and uniqueness of Lyons’ group.
In T.Hagen, M.P.Hale, and E.E.Shult, editors, Finite Groups
’72, pages 138–141. North Holland, 1973.
[Sim74]
Charles C.Sims. Some algorithms based on coset enumeration.
Unpublished notes, Rutgers University, New Brunswick, NJ,
1974.
[Sim80]
Charles C.Sims. How to construct a baby monster. In M.J.
Collins, editor, Finite Simple Groups II, pages 339–345.
(Durham 1978), Academic Press, 1980.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
494
[Sim87]
Charles C.Sims. Verifying nilpotence. J. Symbolic Comput.,
3:231–247, 1987.
[Sim90a]
Charles C.Sims. Computing the order of a solvable
permutation group. J. Symbolic Comput., 9:699–705, 1990.
[Sim90b]
Charles C.Sims. Implementing the Baumslag-Cannonito-
Miller polycyclic quotient algorithm. J. Symbolic Comput.,
9:707–723, 1990.
[Sim94]
Charles C.Sims. Computation with Finitely Presented
Groups. Cambridge University Press, 1994.
[Sim03]
Charles C.Sims. Computational group theory. In Computer
Algebra Handbook: Foundations, Applications, Systems,
pages 65–83. Springer-Verlag, 2003.
[SL96]
A.Storjohann and G.Labahn. Asymptotically fast computation
of Hermite normal forms of integer matrices. In Proc. of
International Symposium on Symbolic and Algebraic
Computation ISSAC ’96, pages 259–266. (Zürich), ACM Press,
1996.
[SM85]
L.H.Soicher and J.McKay. Computing Galois groups over the
rationals. J. Number Theory, 20:273–281, 1985.
[Smi94]
Michael J.Smith. Computing automorphisms of finite soluble
groups. PhD thesis, Australian National University, 1994.
[SS92]
S.T.Schibell and R.M.Stafford. Processor interconnection
networks and Cayley graphs. Discrete Applied Mathematics,
40:337–357, 1992.
[SS94]
M.Schönert and Á.Seress. Finding blocks of imprimitivity in
small-base groups in nearly linear time. In Proc. of
International Symposium on Symbolic and Algebraic
Computation ISSAC ’94, pages 154–157. (Oxford), ACM Press,
1994.
[ST02]
Ian Stewart and David Tall. Algebraic Number Theory and
Fermat’s Last Theorem. A.K.Peters, 2002.
[Sto98]
Arne Storjohann. Computing Hermite and Smith normal forms
of triangular integer matrices. Linear Algebra Appl., 282:
25–45, 1998.
[SWD96]
O.Schirokauer, D.Weber, and Th. F.Denny. Discrete
logarithms: the effectiveness of the index calculus method. In
Algorithmic Number Theory—ANTS II, volume 1122 of
Lecture Notes in Comput. Sci., pages 337–361, Berlin, 1996.
Springer.
© 2005 by Chapman & Hall/CRC Press

References
495
[Syl72]
L.Sylow. Théorèmes sur les groupes de substitutions. Math.
Ann., 5:584–594, 1872.
[TC36]
J.A.Todd and H.S.M.Coxeter. A practical method for
enumerating cosets of a finite abstract group. Proc. Edinburgh
Math. Soc., 5:26–34, 1936.
[The97]
Heiko Theißen. Eine Methode zur Normalisatorberechnung
in Permutationsgruppen mit Anwendungen in der
Konstruktion primitiver Gruppen. PhD thesis, RWTH
Aachen, 1997.
[Tie08]
H.Tietze. 
Über 
die 
topologischen 
Invarianten
mehrdimensionalen Mannigfaltigkeiten. Monatsh. f. Math.
u. Physik, 19:1–118, 1908.
[Tro64]
H.F.Trotter. A machine program for coset enumeration.
Canad. Math. Bull., 7:357–368, 1964.
[Ung02]
W.R.Unger. Computing the solvable radical of a permutation
group. In preparation, 2002.
[VL84]
M.R.Vaughan-Lee. An aspect of the nilpotent quotient
algorithm. In Atkinson [Atk84], pages 76–83.
[VL93]
M.R.Vaughan-Lee. The Restricted Burnside Problem, volume
5 of London Math. Soc. Monographs (New Series). Oxford
University Press, Oxford, 2nd edition, 1993.
[VLZ99]
M.R.Vaughan-Lee and E.I.Zel’manov. Bounds in the restricted
Burnside problem. J. Austral. Math. Soc. Ser. A, 67:261–
271, 1999.
[Wam70]
J.W.Wamsley. The deficiency of metacyclic groups. Proc.
Amer. Math. Soc., 24:724–726, 1970.
[Wam74]
J.W.Wamsley. Computation in nilpotent groups (theory). In
Proc. Second Internat. Conf. Theory of Groups, volume 372
of Lecture Notes in Math., pages 691–700, Berlin, Heidelberg,
New York, 1974. (Canberra, 1973), Springer-Verlag.
[Wam77]
J.W.Wamsley. Computing soluble groups. In A.Dold and B.
Eckmann, editors, Group Theory, volume 573 of Lecture Notes
in Math., pages 118–125, Berlin, Heidelberg, New York, 1977.
(Canberra, 1975), Springer-Verlag.
[War74]
J.N.Ward. A note on the Todd-Coxeter algorithm. In R.A.
Bryce, J.Cossey, and M.F.Newman, editors, Group Theory,
volume 573 of Lecture Notes in Mathematics, pages 126–129,
Berlin, 1974. Springer.
© 2005 by Chapman & Hall/CRC Press

Handbook Of Computational Group Theory
496
[Wie64]
Helmut Wielandt. Finite Permutation Groups. Academic
Press, New York, 1964.
[Wil96]
Robert A.Wilson. Standard generators for sporadic simple
groups. J. Algebra, 184:505–515, 1996.
[Wur93]
Martin Wursthorn. Isomorphisms of modular group algebras:
an algorithm and its application to groups of order 26. J.
Symbolic Comput., 15:211–227, 1993.
[Zas48]
H.Zassenhaus. Über einen Algorithmus zur Bestimmung der
Raumgruppen. Comment. Math. Helv., 21:117–141, 1948.
[Zel91a]
E.I.Zel’manov. Solution of the restricted Burnside problem
for 2-groups (Russian). Math. Sb., 182:568–592, 1991.
[Zel91b]
E.I.Zel’manov. Solution of the restricted Burnside problem
for groups of odd exponent. Math. USSR-Izv., 36:41–60, 1991.
© 2005 by Chapman & Hall/CRC Press

