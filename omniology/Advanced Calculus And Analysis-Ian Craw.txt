Department of
Mathematical Sciences
Advanced Calculus and Analysis
MA1002
Ian Craw

ii
April 13, 2000, Version 1.3
Copyright 2000 by Ian Craw and the University of Aberdeen
All rights reserved.
Additional copies may be obtained from:
Department of Mathematical Sciences
University of Aberdeen
Aberdeen AB9 2TY
DSN: mth200-101982-8

Foreword
These Notes
The notes contain the material that I use when preparing lectures for a course I gave from
the mid 1980’s until 1994; in that sense they are my lecture notes.
”Lectures were once useful, but now when all can read, and books are so nu-
merous, lectures are unnecessary.”
Samuel Johnson, 1799.
Lecture notes have been around for centuries, either informally, as handwritten notes,
or formally as textbooks. Recently improvements in typesetting have made it easier to
produce “personalised” printed notes as here, but there has been no fundamental change.
Experience shows that very few people are able to use lecture notes as a substitute for
lectures; if it were otherwise, lecturing, as a profession would have died out by now.
These notes have a long history; a “ﬁrst course in analysis” rather like this has been
given within the Mathematics Department for at least 30 years. During that time many
people have taught the course and all have left their mark on it; clarifying points that have
proved diﬃcult, selecting the “right” examples and so on. I certainly beneﬁted from the
notes that Dr Stuart Dagger had written, when I took over the course from him and this
version builds on that foundation, itslef heavily inﬂuenced by (Spivak 1967) which was the
recommended textbook for most of the time these notes were used.
The notes are written in LATEX which allows a higher level view of the text, and simpliﬁes
the preparation of such things as the index on page 101 and numbered equations. You
will ﬁnd that most equations are not numbered, or are numbered symbolically. However
sometimes I want to refer back to an equation, and in that case it is numbered within the
section. Thus Equation (1.1) refers to the ﬁrst numbered equation in Chapter 1 and so on.
Acknowledgements
These notes, in their printed form, have been seen by many students in Aberdeen since
they were ﬁrst written. I thank those (now) anonymous students who helped to improve
their quality by pointing out stupidities, repetitions misprints and so on.
Since the notes have gone on the web, others, mainly in the USA, have contributed
to this gradual improvement by taking the trouble to let me know of diﬃculties, either
in content or presentation. As a way of thanking those who provided such corrections,
I endeavour to incorporate the corrections in the text almost immediately. At one point
this was no longer possible; the diagrams had been done in a program that had been
‘subsequently “upgraded” so much that they were no longer useable. For this reason I
had to withdraw the notes. However all the diagrams have now been redrawn in “public
iii

iv
domaian” tools, usually xfig and gnuplot. I thus expect to be able to maintain them in
future, and would again welcome corrections.
Ian Craw
Department of Mathematical Sciences
Room 344, Meston Building
email: Ian.Craw@maths.abdn.ac.uk
www: http://www.maths.abdn.ac.uk/~igc
April 13, 2000

Contents
Foreword
iii
Acknowledgements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
iii
1
Introduction.
1
1.1
The Need for Good Foundations
. . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
The Real Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.3
Inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.4
Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.5
Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
1.6
Neighbourhoods
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.7
Absolute Value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.8
The Binomial Theorem and other Algebra . . . . . . . . . . . . . . . . . . .
8
2
Sequences
11
2.1
Deﬁnition and Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.1.1
Examples of sequences . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.2
Direct Consequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
2.3
Sums, Products and Quotients
. . . . . . . . . . . . . . . . . . . . . . . . .
15
2.4
Squeezing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
17
2.5
Bounded sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
2.6
Inﬁnite Limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
19
3
Monotone Convergence
21
3.1
Three Hard Examples
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
3.2
Boundedness Again . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
3.2.1
Monotone Convergence
. . . . . . . . . . . . . . . . . . . . . . . . .
22
3.2.2
The Fibonacci Sequence . . . . . . . . . . . . . . . . . . . . . . . . .
26
4
Limits and Continuity
29
4.1
Classes of functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
4.2
Limits and Continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
4.3
One sided limits
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
4.4
Results giving Coninuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
4.5
Inﬁnite limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
4.6
Continuity on a Closed Interval . . . . . . . . . . . . . . . . . . . . . . . . .
38
v

vi
CONTENTS
5
Diﬀerentiability
41
5.1
Deﬁnition and Basic Properties . . . . . . . . . . . . . . . . . . . . . . . . .
41
5.2
Simple Limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
5.3
Rolle and the Mean Value Theorem
. . . . . . . . . . . . . . . . . . . . . .
44
5.4
l’Hˆopital revisited . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
47
5.5
Inﬁnite limits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
48
5.5.1
(Rates of growth) . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
5.6
Taylor’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
6
Inﬁnite Series
55
6.1
Arithmetic and Geometric Series . . . . . . . . . . . . . . . . . . . . . . . .
55
6.2
Convergent Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
6.3
The Comparison Test
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
6.4
Absolute and Conditional Convergence . . . . . . . . . . . . . . . . . . . . .
61
6.5
An Estimation Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
64
7
Power Series
67
7.1
Power Series and the Radius of Convergence . . . . . . . . . . . . . . . . . .
67
7.2
Representing Functions by Power Series . . . . . . . . . . . . . . . . . . . .
69
7.3
Other Power Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
7.4
Power Series or Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
7.5
Applications* . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
7.5.1
The function ex grows faster than any power of x . . . . . . . . . . .
73
7.5.2
The function log x grows more slowly than any power of x . . . . . .
73
7.5.3
The probability integral
R α
0 e−x2 dx . . . . . . . . . . . . . . . . . .
73
7.5.4
The number e is irrational . . . . . . . . . . . . . . . . . . . . . . . .
74
8
Diﬀerentiation of Functions of Several Variables
77
8.1
Functions of Several Variables . . . . . . . . . . . . . . . . . . . . . . . . . .
77
8.2
Partial Diﬀerentiation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
8.3
Higher Derivatives
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
84
8.4
Solving equations by Substitution . . . . . . . . . . . . . . . . . . . . . . . .
85
8.5
Maxima and Minima . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
8.6
Tangent Planes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
8.7
Linearisation and Diﬀerentials . . . . . . . . . . . . . . . . . . . . . . . . . .
91
8.8
Implicit Functions of Three Variables . . . . . . . . . . . . . . . . . . . . . .
92
9
Multiple Integrals
93
9.1
Integrating functions of several variables . . . . . . . . . . . . . . . . . . . .
93
9.2
Repeated Integrals and Fubini’s Theorem
. . . . . . . . . . . . . . . . . . .
93
9.3
Change of Variable — the Jacobian . . . . . . . . . . . . . . . . . . . . . . .
97
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
101
Index Entries
101

List of Figures
2.1
A sequence of eye locations. . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.2
A picture of the deﬁnition of convergence
. . . . . . . . . . . . . . . . . . .
14
3.1
A monotone (increasing) sequence which is bounded above seems to converge
because it has nowhere else to go! . . . . . . . . . . . . . . . . . . . . . . . .
23
4.1
Graph of the function (x2 −4)/(x −2) The automatic graphing routine does
not even notice the singularity at x = 2. . . . . . . . . . . . . . . . . . . . .
31
4.2
Graph of the function sin(x)/x. Again the automatic graphing routine does
not even notice the singularity at x = 0. . . . . . . . . . . . . . . . . . . . .
32
4.3
The function which is 0 when x < 0 and 1 when x ≥0; it has a jump
discontinuity at x = 0. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
4.4
Graph of the function sin(1/x). Here it is easy to see the problem at x = 0;
the plotting routine gives up near this singularity. . . . . . . . . . . . . . . .
33
4.5
Graph of the function x. sin(1/x). You can probably see how the discon-
tinuity of sin(1/x) gets absorbed. The lines y = x and y = −x are also
plotted.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
5.1
If f crosses the axis twice, somewhere between the two crossings, the func-
tion is ﬂat. The accurate statement of this “obvious” observation is Rolle’s
Theorem.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
5.2
Somewhere inside a chord, the tangent to f will be parallel to the chord.
The accurate statement of this common-sense observation is the Mean Value
Theorem.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
46
6.1
Comparing the area under the curve y = 1/x2 with the area of the rectangles
below the curve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
57
6.2
Comparing the area under the curve y = 1/x with the area of the rectangles
above the curve . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
6.3
An upper and lower approximation to the area under the curve . . . . . . .
64
8.1
Graph of a simple function of one variable . . . . . . . . . . . . . . . . . . .
78
8.2
Sketching a function of two variables . . . . . . . . . . . . . . . . . . . . . .
78
8.3
Surface plot of z = x2 −y2. . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
8.4
Contour plot of the surface z = x2 −y2. The missing points near the x - axis
are an artifact of the plotting program. . . . . . . . . . . . . . . . . . . . . .
80
8.5
A string displaced from the equilibrium position
. . . . . . . . . . . . . . .
85
8.6
A dimensioned box . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
vii

viii
LIST OF FIGURES
9.1
Area of integration. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
9.2
Area of integration. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
96
9.3
The transformation from Cartesian to spherical polar co-ordinates. . . . . .
99
9.4
Cross section of the right hand half of the solid outside a cylinder of radius
a and inside the sphere of radius 2a
. . . . . . . . . . . . . . . . . . . . . .
99

Chapter 1
Introduction.
This chapter contains reference material which you should have met before. It is here both
to remind you that you have, and to collect it in one place, so you can easily look back and
check things when you are in doubt.
You are aware by now of just how sequential a subject mathematics is. If you don’t
understand something when you ﬁrst meet it, you usually get a second chance. Indeed you
will ﬁnd there are a number of ideas here which it is essential you now understand, because
you will be using them all the time. So another aim of this chapter is to repeat the ideas.
It makes for a boring chapter, and perhaps should have been headed “all the things you
hoped never to see again”. However I am only emphasising things that you will be using
in context later on.
If there is material here with which you are not familiar, don’t panic; any of the books
mentioned in the book list can give you more information, and the ﬁrst tutorial sheet is
designed to give you practice. And ask in tutorial if you don’t understand something here.
1.1
The Need for Good Foundations
It is clear that the calculus has many outstanding successes, and there is no real discussion
about its viability as a theory. However, despite this, there are problems if the theory is
accepted uncritically, because naive arguments can quickly lead to errors. For example the
chain rule can be phrased as
df
dx = df
dy
dy
dx,
and the “quick” form of the proof of the chain rule — cancel the dy’s — seems helpful. How-
ever if we consider the following result, in which the pressure P, volume V and temperature
T of an enclosed gas are related, we have
∂P
∂V
∂V
∂T
∂T
∂P = −1,
(1.1)
a result which certainly does not appear “obvious”, even though it is in fact true, and we
shall prove it towards the end of the course.
1

2
CHAPTER 1. INTRODUCTION.
Another example comes when we deal with inﬁnite series. We shall see later on that
the series
1 −1
2 + 1
3 −1
4 + 1
5 −1
6 + 1
7 −1
8 + 1
9 −1
10 . . .
adds up to log 2. However, an apparently simple re-arrangement gives

1 −1
2

−1
4 +
1
3 −1
6

−1
8 +
1
5 −1
10

. . .
and this clearly adds up to half of the previous sum — or log(2)/2.
It is this need for care, to ensure we can rely on calculations we do, that motivates
much of this course, illustrates why we emphasise accurate argument as well as getting the
“correct” answers, and explains why in the rest of this section we need to revise elementary
notions.
1.2
The Real Numbers
We have four inﬁnite sets of familiar objects, in increasing order of complication:
N — the Natural numbers are deﬁned as the set {0, 1, 2, . . . , n, . . . }. Contrast these
with the positive integers; the same set without 0.
Z — the Integers are deﬁned as the set {0, ±1, ±2, . . . , ±n, . . . }.
Q — the Rational numbers are deﬁned as the set {p/q : p, q ∈
Z, q ̸= 0}.
R — the Reals are deﬁned in a much more complicated way. In this course you will start
to see why this complication is necessary, as you use the distinction between
R and
Q.
Note: We have a natural inclusion
N ⊂
Z ⊂
Q ⊂
R, and each inclusion is proper. The
only inclusion in any doubt is the last one; recall that
√
2 ∈
R \
Q (i.e. it is a real number
that is not rational).
One point of this course is to illustrate the diﬀerence between
Q and
R. It is subtle:
for example when computing, it can be ignored, because a computer always works with
a rational approximation to any number, and as such can’t distinguish between the two
sets. We hope to show that the complication of introducing the “extra” reals such as
√
2
is worthwhile because it gives simpler results.
Properties of
R
We summarise the properties of
R that we work with.
Addition: We can add and subtract real numbers exactly as we expect, and the usual
rules of arithmetic hold — such results as x + y = y + x.

1.2. THE REAL NUMBERS
3
Multiplication: In the same way, multiplication and division behave as we expect, and
interact with addition and subtraction in the usual way. So we have rules such as
a(b + c) = ab + ac. Note that we can divide by any number except 0. We make no
attempt to make sense of a/0, even in the “funny” case when a = 0, so for us 0/0
is meaningless. Formally these two properties say that (algebraically)
R is a ﬁeld,
although it is not essential at this stage to know the terminology.
Order As well as the algebraic properties,
R has an ordering on it, usually written as
“a > 0” or “≥”. There are three parts to the property:
Trichotomy For any a ∈
R, exactly one of a > 0, a = 0 or a < 0 holds, where we
write a < 0 instead of the formally correct 0 > a; in words, we are simply saying
that a number is either positive, negative or zero.
Addition The order behaves as expected with respect to addition: if a > 0 and
b > 0 then a + b > 0; i.e. the sum of positives is positive.
Multiplication The order behaves as expected with respect to multiplication: if
a > 0 and b > 0 then ab > 0; i.e. the product of positives is positive.
Note that we write a ≥0 if either a > 0 or a = 0. More generally, we write a > b
whenever a −b > 0.
Completion The set
R has an additional property, which in contrast is much more mys-
terious — it is complete. It is this property that distinguishes it from
Q. Its eﬀect is
that there are always “enough” numbers to do what we want. Thus there are enough
to solve any algebraic equation, even those like x2 = 2 which can’t be solved in
Q.
In fact there are (uncountably many) more - all the numbers like π, certainly not
rational, but in fact not even an algebraic number, are also in
R. We explore this
property during the course.
One reason for looking carefully at the properties of
R is to note possible errors in ma-
nipulation. One aim of the course is to emphasise accurate explanation. Normal algebraic
manipulations can be done without comment, but two cases arise when more care is needed:
Never divide by a number without checking ﬁrst that it is non-zero.
Of course we know that 2 is non zero, so you don’t need to justify dividing by 2, but
if you divide by x, you should always say, at least the ﬁrst time, why x ̸= 0. If you don’t
know whether x = 0 or not, the rest of your argument may need to be split into the two
cases when x = 0 and x ̸= 0.
Never multiply an inequality by a number without checking ﬁrst that the number
is positive.
Here it is even possible to make the mistake with numbers; although it is perfectly
sensible to multiply an equality by a constant, the same is not true of an inequality. If
x > y, then of course 2x > 2y. However, we have (−2)x < (−2)y. If multiplying by an
expression, then again it may be necessary to consider diﬀerent cases separately.
1.1. Example. Show that if a > 0 then −a < 0; and if a < 0 then −a > 0.

4
CHAPTER 1. INTRODUCTION.
Solution.
This is not very interesting, but is here to show how to use the properties
formally.
Assume the result is false; then by trichotomy, −a = 0 (which is false because we know
a > 0), or (−a) > 0. If this latter holds, then a + (−a) is the sum of two positives and
so is positive. But a + (−a) = 0, and by trichotomy 0 > 0 is false. So the only consistent
possibility is that −a < 0. The other part is essentially the same argument.
1.2. Example. Show that if a > b and c < 0, then ac < bc.
Solution. This also isn’t very interesting; and is here to remind you that the order in which
questions are asked can be helpful. The hard bit about doing this is in Example 1.1. This is
an idea you will ﬁnd a lot in example sheets, where the next question uses the result of the
previous one. It may dissuade you from dipping into a sheet; try rather to work through
systematically.
Applying Example 1.1 in the case a = −c, we see that −c > 0 and a −b > 0. Thus
using the multiplication rule, we have (a −b)(−c) > 0, and so bc −ac > 0 or bc > ac as
required.
1.3. Exercise. Show that if a < 0 and b < 0, then ab > 0.
1.3
Inequalities
One aim of this course is to get a useful understanding of the behaviour of systems. Think
of it as trying to see the wood, when our detailed calculations tell us about individual trees.
For example, we may want to know roughly how a function behaves; can we perhaps ignore
a term because it is small and simplify things? In order to to this we need to estimate —
replace the term by something bigger which is easier to handle, and so we have to deal with
inequalities. It often turns out that we can “give something away” and still get a useful
result, whereas calculating directly can prove either impossible, or at best unhelpful. We
have just looked at the rules for manipulating the order relation. This section is probably
all revision; it is here to emphasise the need for care.
1.4. Example. Find {x ∈
R : (x −2)(x + 3) > 0}.
Solution. Suppose (x −2)(x + 3) > 0. Note that if the product of two numbers is positive
then either both are positive or both are negative. So either x −2 > 0 and x + 3 > 0, in
which case both x > 2 and x > −3, so x > 2; or x −2 < 0 and x + 3 < 0, in which case
both x < 2 and x < −3, so x < −3. Thus
{x : (x −2)(x + 3) > 0} = {x : x > 2} ∪{x : x < −3}.
1.5. Exercise. Find {x ∈
R : x2 −x −2 < 0}.
Even at this simple level, we can produce some interesting results.
1.6. Proposition (Arithmetic - Geometric mean inequality). If a ≥0 and b ≥0
then
a + b
2
≥
√
ab.

1.4. INTERVALS
5
Solution. For any value of x, we have x2 ≥0 (why?), so (a −b)2 ≥0. Thus
a2 −2ab + b2 ≥0,
a2 + 2ab + b2 ≥4ab.
(a + b)2 ≥4ab.
Since a ≥0 and b ≥0, taking square roots, we have a + b
2
≥
√
ab. This is the arithmetic
- geometric mean inequality. We study further work with inequalities in section 1.7.
1.4
Intervals
We need to be able to talk easily about certain subsets of
R. We say that I ⊂
R is an open
interval if
I = (a, b) = {x ∈
R : a < x < b}.
Thus an open interval excludes its end points, but contains all the points in between. In
contrast a closed interval contains both its end points, and is of the form
I = [a, b] = {x ∈
R : a ≤x ≤b}.
It is also sometimes useful to have half - open intervals like (a, b] and [a, b). It is trivial
that [a, b] = (a, b) ∪{a} ∪{b}.
The two end points a and b are points in
R.
It is sometimes convenient to
allow also the possibility a = −∞and b = +∞; it should be clear from the
context whether this is being allowed. If these extensions are being excluded,
the interval is sometimes called a ﬁnite interval, just for emphasis.
Of course we can easily get to more general subsets of
R. So (1, 2) ∪[2, 3] = (1, 3] shows
that the union of two intervals may be an interval, while the example (1, 2) ∪(3, 4) shows
that the union of two intervals need not be an interval.
1.7. Exercise. Write down a pair of intervals I1 and I2 such that 1 ∈I1, 2 ∈I2 and
I1 ∩I2 = ∅.
Can you still do this, if you require in addition that I1 is centred on 1, I2 is centred on
2 and that I1 and I2 have the same (positive) length? What happens if you replace 1 and
2 by any two numbers l and m with l ̸= m?
1.8. Exercise. Write down an interval I with 2 ∈I such that 1 ̸∈I and 3 ̸∈I. Can you
ﬁnd the largest such interval? Is there a largest such interval if you also require that I is
closed?
Given l and m with l ̸= m, show there is always an interval I with l ∈I and m ̸∈I.
1.5
Functions
Recall that f : D ⊂
R →T is a function if f(x) is a well deﬁned value in T for each x ∈D.
We say that D is the domain of the function, T is the target space and f(D) = {f(x) :
x ∈D} is the range of f.

6
CHAPTER 1. INTRODUCTION.
Note ﬁrst that the deﬁnition says nothing about a formula; just that the result must be
properly deﬁned. And the deﬁnition can be complicated; for example
f(x) =
 0
if x ≤a or x ≥b;
1
if a < x < b.
deﬁnes a function on the whole of
R, which has the value 1 on the open interval (a, b), and
is zero elsewhere [and is usually called the characteristic function of the interval (a, b).]
In the simplest examples, like f(x) = x2 the domain of f is the whole of
R, but even
for relatively simple cases, such as f(x) = √x, we need to restrict to a smaller domain, in
this case the domain D is {x : x ≥0}, since we cannot deﬁne the square root of a negative
number, at least if we want the function to have real - values, so that T ⊂
R.
Note that the domain is part of the deﬁnition of a function, so changing the domain
technically gives a diﬀerent function. This distinction will start to be important in this
course. So f1 :
R →
R deﬁned by f1(x) = x2 and f2 : [−2, 2] →
R deﬁned by f2(x) = x2
are formally diﬀerent functions, even though they both are “x2” Note also that the range
of f2 is [0, 4]. This illustrate our ﬁrst use of intervals. Given f :
R →
R, we can always
restrict the domain of f to an interval I to get a new function. Mostly this is trivial, but
sometimes it is useful.
Another natural situation in which we need to be careful of the domain of a function
occurs when taking quotients, to avoid dividing by zero. Thus the function
f(x) =
1
x −3
has domain {x ∈
R : x ̸= 3}.
The point we have excluded, in the above case 3 is sometimes called a singularity of f.
1.9. Exercise. Write down the natural domain of deﬁnition of each of the functions:
f(x) =
x −2
x2 −5x + 6
g(x) =
1
sin x.
Where do these functions have singularities?
It is often of interest to investigate the behaviour of a function near a singularity. For
example if
f(x) =
x −a
x2 −a2 =
x −a
(x −a)(x + a)
for x ̸= a.
then since x ̸= a we can cancel to get f(x) = (x + a)−1. This is of course a diﬀerent
representation of the function, and provides an indication as to how f may be extended
through the singularity at a — by giving it the value (2a)−1.
1.6
Neighbourhoods
This situation often occurs. We need to be able to talk about a function near a point: in
the above example, we don’t want to worry about the singularity at x = −a when we are
discussing the one at x = a (which is actually much better behaved). If we only look at the
points distant less than d for a, we are really looking at an interval (a −d, a + d); we call
such an interval a neighbourhood of a. For traditional reasons, we usually replace the

1.7. ABSOLUTE VALUE
7
distance d by its Greek equivalent, and speak of a distance δ. If δ > 0 we call the interval
(a −δ, a + δ) a neighbourhood (sometimes a δ - neighbourhood) of a. The signiﬁcance of a
neighbourhood is that it is an interval in which we can look at the behaviour of a function
without being distracted by other irrelevant behaviours. It usually doesn’t matter whether
δ is very big or not. To see this, consider:
1.10. Exercise. Show that an open interval contains a neighbourhood of each of its points.
We can rephrase the result of Ex 1.7 in this language; given l ̸= m there is some
(suﬃciently small) δ such that we can ﬁnd disjoint δ - neighbourhoods of l and m. We use
this result in Prop 2.6.
1.7
Absolute Value
Here is an example where it is natural to use a two part deﬁnition of a function. We write
|x| =
 x
if x ≥0;
−x
if x < 0.
An equivalent deﬁnition is |x| =
√
x2. This is the absolute value or modulus of x. It’s
particular use is in describing distances; we interpret |x −y| as the distance between x and
y. Thus
(a −δ, a + δ) = {X ∈
R : |x −a| < δ},
so a δ - neighbourhood of a consists of all points which are closer to a than δ.
Note that we can always “expand out” the inequality using this idea. So if |x −y| < k,
we can rewrite this without a modulus sign as the pair of inequalities −k < x −y < k.
We sometimes call this “unwrapping” the modulus; conversely, in order to establish an
inequality involving the modulus, it is simply necessary to show the corresponding pair of
inequalities.
1.11. Proposition (The Triangle Inequality.). For any x, y ∈
R,
|x + y| ≤|x| + |y|.
Proof. Since −|x| ≤x ≤|x|, and the same holds for y, combining these we have
−|x| −|y| ≤x + y ≤|x| + |y|
and this is the same as the required result.
1.12. Exercise. Show that for any x, y, z ∈
R, |x −z| ≤|x −y| + |y −z|.
1.13. Proposition. For any x, y ∈
R,
|x −y| ≥
|x| −|y|
.

8
CHAPTER 1. INTRODUCTION.
Proof. Using 1.12 we have
|x| = |x −y + y| ≤|x −y| + |y|
and so |x| −|y| ≤|x −y|. Interchanging the rˆoles of x and y, and noting that |x| = | −x|,
gives |y| −|x| ≤|x −y|. Multiplying this inequality by −1 and combining these we have
−|x −y| ≤|x| −|y| ≤|x −y|
and this is the required result.
1.14. Example. Describe {x ∈
R : |5x −3| > 4}.
Proof. Unwrapping the modulus, we have either 5x −3 < −4, or 5x −3 > 4. From one
inequality we get 5x < −4 + 3, or x < −1/5; the other inequality gives 5x > 4 + 3, or
x > 7/5. Thus
{x ∈
R : |5x −3| > 4} = (−∞, −1/5) ∪(7/5, ∞).
1.15. Exercise. Describe {x ∈
R : |x + 3| < 1}.
1.16. Exercise. Describe the set {x ∈
R : 1 ≤x ≤3} using the absolute value function.
1.8
The Binomial Theorem and other Algebra
At its simplest, the binomial theorem gives an expansion of (1+x)n for any positive integer
n. We have
(1 + x)n = 1 + nx + n.(n −1)
1.2
x2 + . . . + n.(n −1).(n −k + 1)
1.2. . . . .k
xk + . . . + xn.
Recall in particular a few simple cases:
(1 + x)3 = 1 + 3x + 3x2 + x3,
(1 + x)4 = 1 + 4x + 6x2 + 4x3 + x4,
(1 + x)5 = 1 + 5x + 10x2 + 10x3 + 5x4 + x5.
There is a more general form:
(a + b)n = an + nan−1b + n.(n −1)
1.2
an−2b2 + . . . + n.(n −1).(n −k + 1)
1.2. . . . .k
an−kbk + . . . + bn,
with corresponding special cases. Formally this result is only valid for any positive integer
n; in fact it holds appropriately for more general exponents as we shall see in Chapter 7
Another simple algebraic formula that can be useful concerns powers of diﬀerences:
a2 −b2 = (a −b)(a + b),
a3 −b3 = (a −b)(a2 + ab + b2),
a4 −b4 = (a −b)(a3 + a2b + ab2 + b3)

1.8. THE BINOMIAL THEOREM AND OTHER ALGEBRA
9
and in general, we have
an −bn = (a −b)(an−1 + an−2b + an−3b2 + . . . + abn −1 + bn−1).
Note that we made use of this result when discussing the function after Ex 1.9.
And of course you remember the usual “completing the square” trick:
ax2 + bx + c = a

x2 + b
ax + b2
4a2

+ c −b2
4a
= a

x + b
2a
2
+

c −b2
4a

.

10
CHAPTER 1. INTRODUCTION.

Chapter 2
Sequences
2.1
Deﬁnition and Examples
2.1. Deﬁnition. A (real inﬁnite) sequence is a map a :
N →
R
Of course if is more usual to call a function f rather than a; and in fact we usually start
labeling a sequence from 1 rather than 0; it doesn’t really matter. What the deﬁnition
is saying is that we can lay out the members of a sequence in a list with a ﬁrst member,
second member and so on. If a :
N →
R, we usually write a1, a2 and so on, instead of the
more formal a(1), a(2), even though we usually write functions in this way.
2.1.1
Examples of sequences
The most obvious example of a sequence is the sequence of natural numbers. Note that the
integers are not a sequence, although we can turn them into a sequence in many ways; for
example by enumerating them as 0, 1, −1, 2, −2 . . . . Here are some more sequences:
Deﬁnition
First 4 terms
Limit
an = n −1
0, 1, 2, 3
does not exist (→∞)
an = 1
n
1, 1
2, 1
3, 1
4
0
an = (−1)n+1
1, −1, 1, −1
does not exist (the sequence oscillates)
an = (−1)n+1 1
n
1, −1
2, 1
3, −1
4
0
an = n −1
n
0, 1
2, 2
3, 3
4
1
an = (−1)n+1
n −1
n

0, −1
2, 2
3, −3
4
does not exist (the sequence oscillates)
an = 3
3, 3, 3, 3
3
A sequence doesn’t have to be deﬁned by a sensible “formula”. Here is a sequence you may
recognise:-
3,
3.1,
3.14,
3.141,
3.1415,
3.14159,
3.141592 . . .
11

12
CHAPTER 2. SEQUENCES
where the terms are successive truncates of the decimal expansion of π.
Of course we can graph a sequence, and it sometimes helps.
In Fig 2.1 we show a
sequence of locations of (just the x coordinate) of a car driver’s eyes.
The interest is
whether the sequence oscillates predictably.
52
54
56
58
60
62
64
66
0
5
10
15
20
25
30
35
Figure 2.1: A sequence of eye locations.
Usually we are interested in what happens to a sequence “in the long run”, or what
happens “when it settles down”. So we are usually interested in what happens when n →∞,
or in the limit of the sequence. In the examples above this was fairly easy to see.
Sequences, and interest in their limits, arise naturally in many situations. One such
occurs when trying to solve equations numerically; in Newton’s method, we use the standard
calculus approximation, that
f(a + h) ≈f(a) + h.f ′(a).
If now we almost have a solution, so f(a) ≈0, we can try to perturb it to a + h, which is a
true solution, so that f(a + h) = 0. In that case, we have
0 = f(a + h) = f(a) + h.f ′(a)
and so
h ≈f(a)
f ′(a).
Thus a better approximation than a to the root is a + h = a −f(a)/f ′(a).
If we take f(x) = x3 −2, ﬁnding a root of this equation is solving the equation x3 = 2,
in other words, ﬁnding
3√
2 In this case, we get the sequence deﬁned as follows
a1 = 1whilean+1 = 2
3an +
2
3a2n
if n > 1.
(2.1)
Note that this makes sense: a1 = 1, a2 = 2
3.1 +
2
3.12 etc. Calculating, we get a2 = 1.333,
a3 = 1.2639, a4 = 1.2599 and a5 = 1.2599 In fact the sequence does converge to
3√
2; by
taking enough terms we can get an approximation that is as accurate as we need. [You can
check that a3
5 = 2 to 6 decimal places.]
Note also that we need to specify the accuracy needed. There is no single approximation
to
3√
2 or π which will always work, whether we are measuring a ﬂower bed or navigating a
satellite to a planet. In order to use such a sequence of approximations, it is ﬁrst necessary
to specify an acceptable accuracy. Often we do this by specifying a neighbourhood of the
limit, and we then often speak of an ϵ - neighbourhood, where we use ϵ (for error), rather
than δ (for distance).

2.1. DEFINITION AND EXAMPLES
13
2.2. Deﬁnition. Say that a sequence {an} converges to a limit l if and only if, given
ϵ > 0 there is some N such that
|an −l| < ϵ
whenever
n ≥N.
A sequence which converges to some limit is a convergent sequence.
2.3. Deﬁnition. A sequence which is not a convergent sequence is divergent. We some-
times speak of a sequence oscillating or tending to inﬁnity, but properly I am just inter-
ested in divergence at present.
2.4. Deﬁnition. Say a property P(n) holds eventually iﬀ∃N such that P(n) holds for
all n ≥N. It holds frequently iﬀgiven N, there is some n ≥N such that P(n) holds.
We call the n a witness; it witnesses the fact that the property is true somewhere at
least as far along the sequence as N. Some examples using the language are worthwhile. The
sequence {−2, −1, 0, 1, 2, . . . } is eventually positive. The sequence sin(n!π/17) is eventually
zero; the sequence of natural numbers is frequently prime.
It may help you to understand this language if you think of the sequence of days in
the future1. You will ﬁnd, according to the deﬁnitions, that it will frequently be Friday,
frequently be raining (or sunny), and even frequently February 29. In contrast, eventually
it will be 1994, and eventually you will die. A more diﬃcult one is whether Newton’s work
will eventually be forgotten!
Using this language, we can rephrase the deﬁnition of convergence as
We say that an →l as n →∞iﬀgiven any error ϵ > 0 eventually an is closer
to l then ϵ. Symbolically we have
ϵ > 0
∃N
s.t.
|an −l| < ϵ
whenever
n ≥N.
Another version may make the content of the deﬁnition even clearer; this time we use
the idea of neighbourhood:
We say that an →l as n →∞iﬀgiven any (acceptable) error ϵ > 0 eventually
an is in the ϵ - neighbourhood of l.
It is important to note that the deﬁnition of the limit of a sequence doesn’t have a
simpler form. If you think you have an easier version, talk it over with a tutor; you may
ﬁnd that it picks up as convergent some sequences you don’t want to be convergent. In
Fig 2.2, we give a picture that may help. The ϵ- neighbourhood of the (potential) limit l is
represented by the shaded strip, while individual members an of the sequence are shown as
blobs. The deﬁnition then says the sequence is convergent to the number we have shown
as a potential limit, provided the sequence is eventually in the shaded strip: and this must
be true even if we redraw the shaded strip to be narrower, as long as it is still centred on
the potential limit.
1I need to assume the sequence is inﬁnite; you can decide for yourself whether this is a philosophical
statement, a statement about the future of the universe, or just plain optimism!

14
CHAPTER 2. SEQUENCES
n
Potential Limit
Figure 2.2: A picture of the deﬁnition of convergence
2.2
Direct Consequences
With this language we can give some simple examples for which we can use the deﬁnition
directly.
• If an →2 as n →∞, then (take ϵ = 1), eventually, an is within a distance 1 of 2. One
consequence of this is that eventually an > 1 and another is that eventually an < 3.
• Let an = 1/n. Then an →0 as n →∞. To check this, pick ϵ > 0 and then choose N
with N > 1/ϵ. Now suppose that n ≥N. We have
0 ≤1
n ≤1
N < ϵ
by choice of N.
• The sequence an = n −1 is divergent; for if not, then there is some l such that
an →l as n →∞. Taking ϵ = 1, we see that eventually (say after N) , we have
−1 ≤(n −1) −l < 1, and in particular, that (n −1) −l < 1 for all n ≥N. thus
n < l + 2 for all n, which is a contradiction.
2.5. Exercise. Show that the sequence an = (1/√n) →0 as n →∞.
Although we can work directly from the deﬁnition in these simple cases, most of the
time it is too hard. So rather than always working directly, we also use the deﬁnition to
prove some general tools, and then use the tools to tell us about convergence or divergence.
Here is a simple tool (or Proposition).
2.6. Proposition. Let an →l as n →∞and assume also that an →m as n →∞. Then
l = m. In other words, if a sequence has a limit, it has a unique limit, and we are justiﬁed
in talking about the limit of a sequence.
Proof. Suppose that l ̸= m; we argue by contradiction, showing this situation is impossible.
Using 1.7, we choose disjoint neighbourhoods of l and m, and note that since the sequence
converges, eventually it lies in each of these neighbourhoods; this is the required contradic-
tion.
We can argue this directly (so this is another version of this proof). Pick ϵ = |l −m|/2.
Then eventually |an −l| < ϵ, so this holds e.g.. for n ≥N1. Also, eventually |an −m| < ϵ,

2.3. SUMS, PRODUCTS AND QUOTIENTS
15
so this holds eg. for n ≥N2. Now let N =
max(N1, N2), and choose n ≥N. Then both
inequalities hold, and
|l −m|
=
|l −an + an −m|
≤
|l −an| + |an −m|
by the triangle inequality
<
ϵ + ϵ = |l −m|
2.7. Proposition. Let an →l ̸= 0 as n →∞. Then eventually an ̸= 0.
Proof. Remember what this means; we are guaranteed that from some point onwards, we
never have an = 0. The proof is a variant of “if an →2 as n →∞then eventually an > 1.”
One way is just to repeat that argument in the two cases where l > 0 and then l < 0. But
we can do it all in one:
Take ϵ = |l|/2, and apply the deﬁnition of “an →l as n →∞”. Then there is some N
such that
|an −l|
<
|l|/2
for all n ≥N
Now
l
=
l −an + an.
Thus
|l|
≤
|l −an| + |an|,
so
|l| ≤|l|/2 + |an|,
and
|an|
≥
|l|/2 ̸= 0.
2.8. Exercise. Let an →l ̸= 0 as n →∞, and assume that l > 0. Show that eventually
an > 0. In other words, use the ﬁrst method suggested above for l > 0.
2.3
Sums, Products and Quotients
2.9. Example. Let an = n + 2
n + 3. Show that an →1 as n →∞.
Solution. There is an obvious manipulation here:-
an = n + 2
n + 3 = 1 + 2/n
1 + 3/n.
We hope the numerator converges to 1 + 0, the denominator to 1 + 0 and so the quotient
to (1 + 0)/(1 + 0) = 1. But it is not obvious that our deﬁnition does indeed behave as we
would wish; we need rules to justify what we have done. Here they are:-
2.10. Theorem. (New Convergent sequences from old) Let an →l and bn →m as
n →∞. Then
Sums: an + bn →l + m as n →∞;
Products: anbn →lm as n →∞; and

16
CHAPTER 2. SEQUENCES
Inverses: provided m ̸= 0 then an/bn →l/m as n →∞.
Note that part of the point of the theorem is that the new sequences are convergent.
Proof. Pick ϵ > 0; we must ﬁnd N such that |an + bn −(l + m) < ϵ when n ≥N. Now
because First pick ϵ > 0. Since an →l as n →∞, there is some N1 such that |an −l| < ϵ/2
whenever n > N1, and in the same way, there is some N2 such that |bn −m| < ϵ/2 whenever
n > N2. Then if N = max(N1, N2), and n > N, we have
|an + bn −(l + m)| < |an −l| + |bn −m| < ϵ/2 + ϵ/2 = ϵ.
The other two results are proved in the same way, but are technically more diﬃcult.
Proofs can be found in (Spivak 1967).
2.11. Example. Let an = 4 −7n2
n2 + 3n. Show that an →−7 as n →∞.
Solution.
A helpful manipulation is easy. We choose to divide both top and bottom by
the highest power of n around. This gives:
an = 4 −7n2
n2 + 3n =
4
n2 −7
1 + 3
n
.
We now show each term behaves as we expect. Since 1/n2 = (1/n).(1/n) and 1/n →0 as
n →∞, we see that 1/n2 →0 as n →∞, using “product of convergents is convergent”.
Using the corresponding result for sums shows that
4
n2 −7 →0 −7 as n →∞. In the same
way, the denominator →1 as n →∞. Thus by the “limit of quotients” result, since the
limit of the denominator is 1 ̸= 0, the quotient →−7 as n →∞.
2.12. Example. In equation 2.1 we derived a sequence (which we claimed converged to
3√
2)
from Newton’s method. We can now show that provided the limit exists and is non zero,
the limit is indeed
3√
2.
Proof. Note ﬁrst that if an →l as n →∞, then we also have an+1 →l as n →∞. In the
equation
an+1 = 2
3an +
2
3a2n
we now let n →∞on both sides of the equation. Using Theorem 2.10, we see that the
right hand side converges to 2
3l + 2
3l2 , while the left hand side converges to l. But they are
the same sequence, so both limits are the same by Prop 2.6. Thus
l = 2
3l + 2
3l2
and so l3 = 2.
2.13. Exercise. Deﬁne the sequence {an} by a1 = 1, an+1 = (4an + 2)/(an + 3) for n ≥1.
Assuming that {an} is convergent, ﬁnd its limit.
2.14. Exercise. Deﬁne the sequence {an} by a1 = 1, an+1 = (2an + 2) for n ≥1. Assuming
that {an} is convergent, ﬁnd its limit. Is the sequence convergent?

2.4. SQUEEZING
17
2.15. Example. Let an = √n + 1 −√n. Show that an →0 as n →∞.
Proof. A simple piece of algebra gets us most of the way:
an
=
 √
n + 1 −√n

.
 √n + 1 + √n

 √n + 1 + √n

=
(n + 1) −n
 √n + 1 + √n
 =
1
 √n + 1 + √n
 →0
as
n →∞.
2.4
Squeezing
Actually, we can’t take the last step yet. It is true and looks sensible, but it is another case
where we need more results getting new convergent sequences from old. We really want a
good dictionary of convergent sequences.
The next results show that order behaves quite well under taking limits, but also shows
why we need the dictionary. The ﬁrst one is fairly routine to prove, but you may still ﬁnd
these techniques hard; if so, note the result, and come back to the proof later.
2.16. Exercise. Given that an →l and bn →m as n →∞, and that an ≤bn for each n,
then l ≤m.
Compare this with the next result, where we can also deduce convergence.
2.17. Lemma. (The Squeezing lemma) Let an ≤bn ≤cn, and suppose that an →l
and cn →l as n →∞. The {bn} is convergent, and bn →l as n →∞.
Proof. Pick ϵ > 0. Then since an →l as n →∞, we can ﬁnd N1 such that
|an −l| < ϵ
for
n ≥N1
and since cn →l as n →∞, we can ﬁnd N2 such that
|cn −l| < ϵ
for
n ≥N2.
Now pick N = max(N1, N2), and note that, in particular, we have
−ϵ < an −l
and
cn −l < ϵ.
Using the given order relation we get
−ϵ < an −l ≤bn −l ≤cn −l < ϵ,
and using only the middle and outer terms, this gives
−ϵ < bn −l < ϵ
or
|bn −l| < ϵ
as claimed.

18
CHAPTER 2. SEQUENCES
Note: Having seen the proof, it is clear we can state an “eventually” form of this result.
We don’t need the inequalities to hold all the time, only eventually.
2.18. Example. Let an = sin(n)
n2
. Show that an →0 as n →∞.
Solution.
Note that, whatever the value of sin(n), we always have −1 ≤sin(n) ≤1. We
use the squeezing lemma:
−1
n2 < an < 1
n2 .
Now
1
n2 →0,
so
sin(n)
n2
→0
as
n →∞.
2.19. Exercise. Show that
r
1 + 1
n →1 as n →∞.
Note: We can now do a bit more with the √n + 1 −√n example. We have
0 ≤
1
√n + 1 + √n ≤
1
2√n,
so we have our result since we showed in Exercise 2.5 that (1/√n) →0 as n →∞.
This illustrates the need for a good bank of convergent sequences. In fact we don’t have
to use ad-hoc methods here; we can get such results in much more generality. We need the
next section to prove it, but here is the results.
2.20. Proposition. Let f be a continuous function at a, and suppose that an →a as
n →∞. Then f(an) →f(a) as n →∞.
Note: This is another example of the “new convergent sequences from old” idea. The
application is that f(x) = x1/2 is continuous everywhere on its domain which is {x ∈
R :
x ≥0}, so since n−1 →0 as n →∞, we have n−1/2 →0 as n →∞; the result we proved
in Exercise 2.5.
2.21. Exercise. What do you deduce about the sequence an = exp (1/n) if you apply this
result to the continuous function f(x) = ex?
2.22. Example. Let an =
1
n log n for n ≥2. Show that an →0 as n →∞.
Solution. Note that 1 ≤log n ≤n if n ≥3, because log(e) = 1, log is monotone increasing,
and 2 < e < 3. Thus n < n log n < n2, when n ≥3 and
1
n2 <
1
n log n < 1
n.
Now
1
n →0
and
1
n2 →0,
so
1
n log n →0
as
n →∞.
Here we have used the “eventually” form of the squeezing lemma.
2.23. Exercise. Let an =
1
√n log n for n ≥2. Show that an →0 as n →∞.

2.5. BOUNDED SEQUENCES
19
2.5
Bounded sequences
2.24. Deﬁnition. Say that {an} is a bounded sequence iﬀthere is some K such that
|an| ≤K for all n.
This deﬁnition is correct, but not particularly useful at present. However, it does provide
good practice in working with abstract formal deﬁnitions.
2.25. Example. Let an =
1
√n log n for n ≥2. Show that {an} is a bounded sequence. [This
is the sequence of Exercise 2.23].
2.26. Exercise. Show that the sum of two bounded sequences is bounded.
2.27. Proposition. An eventually bounded sequence is bounded
Proof. Let {an} be an eventually bounded sequence, so there is some N, and a bound K
such that |an| ≤K for all n ≥N. Let L = max{|a1|, |a2, . . . |aN−1|, K}. Then by deﬁnition
|a1| ≤L, and indeed in the same way, |ak| ≤L whenever k < N. But if n ≥N then
|an| ≤K ≤L, so in fact |an| ≤L for all n, and the sequence is actually bounded.
2.28. Proposition. A convergent sequence is bounded
Proof. Let {an} be a convergent sequence, with limit l say. Then there is some N such
that |an −l| < 1 whenever n ≥N. Here we have used the deﬁnition of convergence, taking
ϵ, our pre-declared error, to be 1. Then by the triangle inequality,
|an| ≤|an −l| + |l| ≤1 + |l|
for all n ≥N.
Thus the sequence {an} is eventually bounded, and so is bounded by Prop 2.27.
And here is another result on which to practice working from the deﬁnition. In order to
tackle simple proofs like this, you should start by writing down, using the deﬁnitions, the
information you are given. Then write out (in symbols) what you wish to prove. Finally
see how you can get from the known information to what you need. Remember that if a
deﬁnition contains a variable (like ϵ in the deﬁnition of convergence), then the deﬁnition is
true whatever value you give to it — even if you use ϵ/2 (as we did in 2.10) or ϵ/K, for any
constant K. Now try:
2.29. Exercise. Let an →0 as n →∞and let {bn} be a bounded sequence. Show that
anbn →0 as n →∞. [If an →l ̸= 0 as n →∞, and {bn} is a bounded sequence, then in
general {anbn} is not convergent. Give an example to show this.]
2.6
Inﬁnite Limits
2.30. Deﬁnition. Say that an →∞as n →∞iﬀgiven K, there is some N such that
an ≥K whenever n ≥N.
This is just one deﬁnition; clearly you can have an →−∞etc. We show how to use
such a deﬁnition to get some results rather like those in 2.10. For example, we show
an = n2 + 5n
3n + 2 →∞
as
n →∞.

20
CHAPTER 2. SEQUENCES
Pick some K. We have an = n.
 n + 5
3n + 2

= n.bn
(say).
Using results from 2.10, we see
that bn →1/3 as n →∞, and so, eventually, bn > 1/6 (Just take ϵ = 1/6 to see this).
Then for large enough n, we have an > n/6 > K, providing in addition n > 6K. Hence
an →∞
as
n →∞.
Note: It is false to argue that an = n.(1/3) →∞; you can’t let one part of a limit
converge without letting the other part converge! And we refuse to do arithmetic with ∞
so can’t hope for a theorem directly like 2.10.

Chapter 3
Monotone Convergence
3.1
Three Hard Examples
So far we have thought of convergence in terms of knowing the limit. It is very helpful to
be able to deduce convergence even when the limit is itself diﬃcult to ﬁnd, or when we can
only ﬁnd the limit provided it exist. There are better techniques than we have seen so far,
dealing with more diﬃcult examples. Consider the following examples:
Sequence deﬁnition of e: Let an =

1 + 1
n
n
; then an →e as n →∞.
Stirling’s Formula: Let an =
n!
√n(n/e)n ; then an →
√
2π as n →∞.
Fibonacci Sequence: Deﬁne p1 = p2 = 1, and for n ≥1, let pn+2 = pn+1 + pn.
Let an = pn+1
pn
; then an →1 +
√
5
2
as n →∞.
We already saw in 2.12 that knowing a sequence has a limit can help to ﬁnd the limit.
As another example of this, consider the third sequence above. We have
pn+2
pn+1
= 1 +
pn
pn+1
and so
an+1 = 1 + 1
an
.
(3.1)
Assume now that an →l as n →∞; then as before in 2.12, we know that an+1 →l
as n →∞(check this formally)! Using 2.10 and equation 3.1, we have l = 1 + 1/l, or
l2 −l −1 = 0. Solving the quadratic gives
an = 1 ±
√
5
2
,
and so these are the only possible limits. Going back to equation 3.1, we see that since
a1 = 1, we have an > 1 when n > 1. Thus by 2.16, l ≥1; we can eliminate the negative
root, and see that the limit, if it exists, is unique. In fact, all of the limits described above
are within reach with some more technique, although Stirling’s Formula takes quite a lot
of calculation.
21

22
CHAPTER 3. MONOTONE CONVERGENCE
3.2
Boundedness Again
Of course not all sequences have limits. But there is a useful special case, which will take
care of the three sequences described above and many more. To describe the result we need
more deﬁnitions, which describe extra properties of sequences.
3.1. Deﬁnition. A sequence {an} is bounded above if there is some K such that an ≤K
for all n. We say that K is an upper bound for the sequence.
• There is a similar deﬁnition of a sequence being bounded below.
• The number K may not be the best or smallest upper bound. All we know from the
deﬁnition is that it will be an upper bound.
3.2. Example. The sequence an = 2 + (−1)n is bounded above.
Solution. Probably the best way to show a sequence is bounded above is to write down an
upper bound – i.e. a suitable value for K. In this case, we claim K = 4 will do. To check
this we must show that an ≤4 for all n. But if n is even, then an = 2 + 1 = 3 ≤4, while if
n is odd, an = 2 −1 = 1 ≤4. So for any n, we have an ≤4 and 4 is an upper bound for
the sequence {an}. Of course 3 is also an upper bound for this sequence.
3.3. Exercise. Let an = 1
n + cos
 1
n

. Show that {an} is bounded above and is bounded
below. [Recall that | cos x| ≤1 for all x.]
3.4. Exercise. Show that a sequence which is bounded above and bounded below is a
bounded sequence (as deﬁned in 2.24).
3.2.1
Monotone Convergence
3.5. Deﬁnition. A sequence {an} is an increasing sequence if an+1 ≥an for every n.
• If we need precision, we can distinguish between a strictly increasing sequence, and
a (not necessarily strictly) increasing sequence.
This is sometime called a non-
decreasing sequence.
• There is a similar deﬁnition of a decreasing sequence.
• What does it mean to say that a sequence is eventually increasing?
• A sequence which is either always increasing or always decreasing is called a mono-
tone sequence. Note that an “arbitrary” sequence is not monotone (it will usually
sometimes increase, and sometimes decrease).
Nevertheless, monotone sequences do happen in real life. For example, the sequence
a1 = 3
a2 = 3.1
a3 = 3.14
a4 = 3.141
a5 = 3.1415 . . .
is how we often describe the decimal expansion of π. Monotone sequences are important
because we can say something useful about them which is not true of more general sequences.

3.2. BOUNDEDNESS AGAIN
23
3.6. Example. Show that the sequence an =
n
2n + 1 is increasing.
Solution.
One way to check that a sequence is increasing is to show an+1 −an ≥0, a
second way is to compute an+1/an, and we will see more ways later. Here,
an+1 −an
=
n + 1
2(n + 1) + 1 −
n
2n + 1
=
(2n2 + 3n + 1) −(2n2 + 3n)
(2n + 3)(2n + 1)
=
1
(2n + 3)(2n + 1) > 0
for all n
and the sequence is increasing.
3.7. Exercise. Show that the sequence an = 1
n −1
n2 is decreasing when n > 1.
If a sequence is increasing, it is an interesting question whether or not it is bounded
above.
If an upper bound does exist, then it seems as though the sequence can’t help
converging — there is nowhere else for it to go.
Upper bound
n
Figure 3.1: A monotone (increasing) sequence which is bounded above seems to converge
because it has nowhere else to go!
In contrast, if there is no upper bound, the situation is clear.
3.8. Example. An increasing sequence which is not bounded above tends to ∞(see deﬁni-
tion 2.30).
Solution.
Let the sequence be {an}, and assume it is not bounded above. Pick K; we
show eventually an > K. Since K is not an upper bound for the sequence, there is some
witness to this. In other words, there is some aN with aN > K. But in that case, since the
sequence is increasing monotonely, we have an ≥aN ≥K for all n ≥N. Hence an →∞as
n →∞.
3.9. Theorem (The monotone convergence principle). Let {an} be an increasing se-
quence which is bounded above; then {an} is a convergent sequence. Let {an} be a decreasing
sequence which is bounded below; then {an} is a convergent sequence
Proof. To prove this we need to appeal to the completeness of
R, as described in Section 1.2.
Details will be given in third year, or you can look in (Spivak 1967) for an accurate deduction
from the appropriate axioms for
R.

24
CHAPTER 3. MONOTONE CONVERGENCE
This is a very important result. It is the ﬁrst time we have seen a way of deducing
the convergence of a sequence without ﬁrst knowing what the limit is. And we saw in 2.12
that just knowing a limit exists is sometimes enough to be able to ﬁnd its value. Note
that the theorem only deduces an “eventually” property of the sequence; we can change a
ﬁnite number of terms in a sequence without changing the value of the limit. This means
that the result must still be true of we only know the sequence is eventually increasing and
bounded above. What happens if we relax the requirement that the sequence is bounded
above, to be just eventually bounded above? (Compare Proposition 2.27).
3.10. Example. Let a be ﬁxed. Then an →0 as n →∞if |a| < 1, while if a > 1, an →∞
as n →∞.
Solution.
Write an = an; then an+1 = a.an. If a > 1 then an+1 < an, while if 0 < a < 1
then an+1 < an; in either case the sequence is monotone.
Case 1
0 < a < 1; the sequence {an} is bounded below by 0, so by the monotone
convergence theorem, an →l as n →∞. As before note that an+1 →l as n →∞. Then
applying 2.10 to the equation an+1 = a.an, we have l = a.l, and since a ̸= 1, we must have
l = 0.
Case 2
a > 1; the sequence {an} is increasing. Suppose it is bounded above; then
as in Case 1, it converges to a limit l satisfying l = a.l.
This contradiction shows the
sequence is not bounded above. Since the sequence is monotone, it must tend to inﬁnity
(as described in 3.9).
Case 3
|a| < 1; then since −|an| ≤an ≤|an|, and since |an| = |a|n →0 as n →∞,
by squeezing, since each outer limit →0 by case 1, we have an →0 as n →∞whenever
|a| < 1.
3.11. Example. Evaluate lim
n→∞
2
3
n
and lim
n→∞
−2
3
n
+
4
5
n
.
Solution.
Using the result that if |a| < 1, then an →0 as n →∞, we deduce that
(−2/3)n →0 as n →∞, that (4/5)n →0 as n →∞, and using 2.10, that the second limit
is also 0.
3.12. Exercise. Given that k > 1 is a ﬁxed constant, evaluate lim
n→∞

1 −1
k
n
. How does
your result compare with the sequence deﬁnition of e given in Sect 3.1.
3.13. Example. Let a1 = 1, and for n ≥1 deﬁne an+1 = 6(1 + an)
7 + an
. Show that {an} is
convergent, and ﬁnd its limit.
Solution. We can calculate the ﬁrst few terms of the sequence as follows:
a1 = 1,
a2 = 1.5
a3 = 1.76
a4 = 1.89 . . .
and it looks as though the sequence might be increasing. Let
f(x) = 6(1 + x)
7 + x ,
so
f(an) = an+1.
(3.2)

3.2. BOUNDEDNESS AGAIN
25
By investigating f, we hope to deduce useful information about the sequence {an}. We
have
f ′(x) = (7 + x).6 −6(1 + x)
(7 + x)2
=
36
((7 + x)2 > 0.
Recall from elementary calculus that if f ′(x) > 0, then f is increasing; in other words, if
b > a then f(b) > f(a). We thus see that f is increasing.
Since a2 > a1, we have f(a2) > f(a1); in other words, a3 > a2. Applying this argument
inductively, we see that an+1 > an for all n, and the sequence {an} is increasing.
If x is large, f(x) ≈6, so perhaps f(x) < 6 for all x.
6 −f(x) = 6(7 + x) −6 −6x
7 + x
=
36
7 + x > 0
if
x > −7
In particular, we see that f(x) ≤6 whenever x ≥0. Clearly an ≥0 for all n, so f(an) =
an+1 ≤6 for all n, and the sequence {an} is increasing and bounded above. Hence {an} is
convergent, with limit l (say).
Since also an+1 →l as n →∞, applying 2.10 to the deﬁning equation gives l = 6(1 + l)
7 + l ,
or l2 + 7l = 6 + 6l. Thus l2 + l −6 = 0 or (l + 3)(l −2) = 0. Thus we can only have limits
2 or −3, and since an ≥0 for all n, necessarily l > 0. Hence l = 2.
Warning: There is a diﬀerence between showing that f is increasing, and showing that
the sequence is increasing. There is of course a relationship between the function f and the
sequence an; it is precisely that f(an) = an+1. What we know is that if f is increasing,
then the sequence carries on going the way it starts; if it starts by increasing, as in the
above example, then it continues to increase. In the same way, if it starts by decreasing,
the sequence will continue to decrease. Show this for yourself.
3.14. Exercise. Deﬁne the sequence {an} by a1 = 1, an+1 = (4an + 2)/(an + 3) for n ≥1.
Show that {an} is convergent, and ﬁnd it’s limit.
3.15. Proposition. Let {an} be an increasing sequence which is convergent to l (In other
words it is necessarily bounded above). Then l is an upper bound for the sequence {an}.
Proof. We argue by contradiction. If l is not an upper bound for the sequence, there is
some aN which witnesses this; i.e. aN > l. Since the sequence is increasing, if n ≥N, we
have an ≥aN > l. Now apply 2.16 to deduce that l ≥aN > l which is a contradiction.
3.16. Example. Let an =

1 + 1
n
n
; then {an} is convergent.
Solution.
We show we have an increasing sequence which is bounded above.
By the
binomial theorem,

1 + 1
n
n
=
1 + n
n + n(n −1)
2!
. 1
n2 + n(n −1)(n −2)
3!
. 1
n3 + · · · + 1
nn
≤
1 + 1 + 1
2! + 1
3! + · · ·
≤
1 + 1 + 1
2 + 1
2.2 +
1
2.2.2 + · · · ≤3.

26
CHAPTER 3. MONOTONE CONVERGENCE
Thus {an} is bounded above. We show it is increasing in the same way.

1 + 1
n
n
=
1 + n
n + n(n −1)
2!
. 1
n2 + n(n −1)(n −2)
3!
. 1
n3 + · · · + 1
nn
=
1 + 1 + 1
2!

1 −1
n

+ 1
3!

1 −1
n
 
1 −2
n

+ . . .
from which it clear that an increases with n. Thus we have an increasing sequence which is
bounded above, and so is convergent by the Monotone Convergence Theorem 3.9. Another
method, in which we show the limit is actually e is given on tutorial sheet 3.
3.2.2
The Fibonacci Sequence
3.17. Example. Recall the deﬁnition of the sequence which is the ratio of adjacent terms of
the Fibonacci sequence as follows:- Deﬁne p1 = p2 = 1, and for n ≥1, let pn+2 = pn+1 +pn.
Let an = pn+1
pn
; then an →1 +
√
5
2
as n →∞. Note that we only have to show that this
sequence is convergent; in which case we already know it converges to 1 +
√
5
2
.
Solution. We compute the ﬁrst few terms.
n
1
2
3
4
5
6
7
8
Formula
pn
1
1
2
3
5
8
13
21
pn+2 = pn + pn+1
an
1
2
1.5
1.67
1.6
1.625
1.61
1.62
an = pn+1/pn
On the basis of this evidence, we make the following guesses, and then try to prove them:
• For all n, we have 1 ≤an ≤2;
• a2n+1 is increasing and a2n is decreasing; and
• an is convergent.
Note we are really behaving like proper mathematicians here; the aim is simply to use
proof to see if earlier guesses were correct. The method we use could be very like that in
the previous example; in fact we choose to use induction more.
Either method can be used on either example, and you should become familiar
with both techniques.
Recall that, by deﬁnition,
an+1 = pn+1
pn
= = 1 + 1
an
.
(3.3)
Since pn+1 ≥pn for all n, we have an ≥1. Also, using our guess,
2 −an+1 = 2 −

1 + 1
an

= 1 −1
an
≥0,
and
an ≤2.

3.2. BOUNDEDNESS AGAIN
27
The next stage is to look at the “every other one” subsequences. First we get a relationship
like equation 3.3 for these. (We hope these subsequences are going to be better behaved
than the sequence itself).
an+2 = 1 +
1
an+1
= 1 +
1
1 +
1
an
= 1 +
an
1 + an
.
(3.4)
We use this to compute how the diﬀerence between successive terms in the sequence behave.
Remember we are interested in the “every other one” subsequence. Computing,
an+2 −an
=
an
1 + an
−
an−2
1 + an−2
=
an + anan−2 −an−2 −anan−2
(1 + an)(1 + an−2)
=
an −an−2
(1 + an)(1 + an−2)
In the above, we already know that the denominator is positive (and in fact is at least 4
and at most 9). This means that an+2 −an has the same sign as an −an−2; we can now use
this information on each subsequence. Since a4 < a2 = 2, we have a6 < a4 and so on; by
induction, a2n forms a decreasing sequence, bounded below by 1, and hence is convergent
to some limit α. Similarly, since a3 > a1 = 1, we have a5 > a3 and so on; by induction
a2n forms an increasing sequence, bounded above by 2, and hence is convergent to some
limit β.
Remember that adjacent terms of both of these sequences satisﬁed equation 3.4, so as
usual, the limit satisﬁes this equation as well. Thus
α = 1 +
α
1 + α,
α + α2 = 1 + 2α,
α2 −α −1 = 0
and
α = 1 ± √1 + 4
2
Since all the terms are positive, we can ignore the negative root, and get α = (1 +
√
5)/2.
In exactly the same way, we have β = (1 +
√
5)/2, and both subsequences converge to the
same limit. It is now an easy deduction (which is left for those who are interested - ask if
you want to see the details) that the Fibonacci sequence itself converges to this limit.

28
CHAPTER 3. MONOTONE CONVERGENCE

Chapter 4
Limits and Continuity
4.1
Classes of functions
We ﬁrst met a sequence as a particularly easy sort of function, deﬁned on
N, rather than
R. We now move to the more general study of functions. However, our earlier work wasn’t
a diversion; we shall see that sequences prove a useful tool both to investigate functions,
and to give an idea of appropriate methods.
Our main reason for being interested in studying functions is as a model of some beha-
viour in the real world. Typically a function describes the behaviour of an object over time,
or space. In selecting a suitable class of functions to study, we need to balance generality,
which has chaotic behaviour, with good behaviour which occurs rarely. If a function has
lots of good properties, because there are strong restrictions on it, then it can often be
quite hard to show that a given example of such a function has the required properties.
Conversely, if it is easy to show that the function belongs to a particular class, it may be
because the properties of that class are so weak that belonging may have essentially no
useful consequences. We summarise this in the table:
Strong restrictions
Weak restrictions
Good behaviour
Bad behaviour
Few examples
Many examples
It turns out that there are a number of “good” classes of functions which are worth
studying. In this chapter and the next ones, we study functions which have steadily more
and more restrictions on them. Which means the behaviour steadily improves; and at the
same time, the number of examples steadily decreases. A perfectly general function has
essentially nothing useful that can be said about it; so we start by studying continuous
functions, the ﬁrst class that gives us much theory.
In order to discuss functions sensibly, we often insist that we can “get a good look” at
the behaviour of the function at a given point, so typically we restrict the domain of the
function to be well behaved.
4.1. Deﬁnition. A subset U of
R is open if given a ∈U, there is some δ > 0 such that
(a −δ, a + δ) ⊆U.
In fact this is the same as saying that given a ∈U, there is some open interval containing
a which lies in U. In other words, a set is open if it contains a neighbourhood of each of its
29

30
CHAPTER 4. LIMITS AND CONTINUITY
points. We saw in 1.10 that an open interval is an open set. This deﬁnition has the eﬀect
that if a function is deﬁned on an open set we can look at its behaviour near the point a of
interest, from both sides.
4.2
Limits and Continuity
We discuss a number of functions, each of which is worse behaved than the previous one.
Our aim is to isolate an imprtant property of a function called continuity.
4.2. Example.
1. Let f(x) = sin(x). This is deﬁned for all x ∈
R.
[Recall we use radians automatically in order to have the derivative of sin x being
cos x.]
2. Let f(x) = log(x). This is deﬁned for x > 0, and so naturally has a restricted domain.
Note also that the domain is an open set.
3. Let f(x) = x2 −a2
x −a
when x ̸= a, and suppose f(a) = 2a.
4. Let f(x) =
( sin x
x
when x ̸= 0,
= 1
if x = 0.
5. Let f(x) = 0 if x < 0, and let f(x) = 1 for x ≥0.
6. Let f(x) = sin 1
x when x ̸= 0 and let f(0) = 0.
In each case we are trying to study the behaviour of the function near a particular
point. In example 1, the function is well behaved everywhere, there are no problems, and
so there is no need to pick out particular points for special care. In example 2, the function
is still well behaved wherever it is deﬁned, but we had to restrict the domain, as promised
in Sect. 1.5. In all of what follows, we will assume the domain of all of our functions is
suitably restricted.
We won’t spend time in this course discussing standard functions. It is assumed that
you know about functions such as sin x, cos x, tan x, log x, exp x, tan−1 x and sin−1 x, as
well as the “obvious” ones like polynomials and rational functions — those functions of
the form p(x)/q(x), where p and q are polynomials. In particular, it is assumed that you
know these are diﬀerentiable everywhere they are deﬁned. We shall see later that this is
quite a strong piece of information. In particular, it means they are examples of continuous
functions. Note also that even a function like f(x) = 1/x is continuous, because, wherever
it is deﬁned (ie on
R \ {0}), it is continuous.
In example 3, the function is not deﬁned at a, but rewriting the function
x2 −a2
x −a
= x + a
if x ̸= a,
we see that as x approaches a, where the function is not deﬁned, the value of the function
approaches 2a. It thus seems very reasonable to extend the deﬁnition of f by deﬁning
f(a) = 2a. In fact, what we have observed is that
lim
x→a
x2 −a2
x −a
= lim
x→a(x + a) = 2a.

4.2. LIMITS AND CONTINUITY
31
We illustrate the behaviour of the function for the case when a = 2 in Fig 4.1
-2
-1
0
1
2
3
4
5
6
-4
-3
-2
-1
0
1
2
3
4
Figure 4.1: Graph of the function (x2 −4)/(x −2) The automatic graphing routine does
not even notice the singularity at x = 2.
In this example, we can argue that the use of the (x2 −a2)/(x −a) was perverse; there
was a more natural deﬁnition of the function which gave the “right” answer. But in the
case of sin x/x, example 4, there was no such deﬁnition; we are forced to make the two part
deﬁnition, in order to deﬁne the function “properly” everywhere. So we again have to be
careful near a particular point in this case, near x = 0. The function is graphed in Fig 4.2,
and again we see that the graph shows no evidence of a diﬃculty at x = 0
Considering example 5 shows that these limits need not always exist; we describe this
by saying that the limit from the left and from the right both exist, but diﬀer, and the
function has a jump discontinuity at 0. We sketch the function in Fig 4.3.
In fact this is not the worst that can happen, as can be seen by considering example 6.
Sketching the graph, we note that the limit at 0 does not even exists. We prove this in
more detail later in 4.23.
The crucial property we have been studying, that of having a deﬁnition at a point which
is the “right” deﬁnition, given how the function behaves near the point, is the property of
continuity. It is closely connected with the existence of limits, which have an accurate
deﬁnition, very like the “sequence” ones, and with very similar properties.
4.3. Deﬁnition. Say that f(x) tends to l as x →a iﬀgiven ϵ > 0, there is some δ > 0
such that whenever 0 < |x −a| < δ, then |f(x) −l| < ϵ.
Note that we exclude the possibility that x = a when we consider a limit; we are only
interested in the behaviour of f near a, but not at a. In fact this is very similar to the
deﬁnition we used for sequences. Our main interest in this deﬁnition is that we can now
describe continuity accurately.
4.4. Deﬁnition. Say that f is continuous at a if limx→a f(x) = f(a). Equivalently, f
is continuous at a iﬀgiven ϵ > 0, there is some δ > 0 such that whenever |x −a| < δ, then
|f(x) −f(a)| < ϵ.

32
CHAPTER 4. LIMITS AND CONTINUITY
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
-8
-6
-4
-2
0
2
4
6
8
Figure 4.2: Graph of the function sin(x)/x. Again the automatic graphing routine does
not even notice the singularity at x = 0.
x
y
Figure 4.3: The function which is 0 when x < 0 and 1 when x ≥0; it has a jump
discontinuity at x = 0.
Note that in the “epsilon - delta” deﬁnition, we no longer need exclude the case when
x = a. Note also there is a good geometrical meaning to the deﬁnition. Given an error
ϵ, there is some neighbourhood of a such that if we stay in that neighbourhood, then f is
trapped within ϵ of its value f(a).
We shall not insist on this deﬁnition in the same way that the deﬁnition of the con-
vergence of a sequence was emphasised. However, all our work on limts and continuity of
functions can be traced back to this deﬁnition, just as in our work on sequences, everything
could be traced back to the deﬁnition of a convergent sequence. Rather than do this, we
shall state without proof a number of results which enable continuous functions both to be
recognised and manipulated. So you are expected to know the deﬁnition, and a few simply
ϵ – δ proofs, but you can apply (correctly - and always after checking that any needed
conditions are satisﬁed) the standard results we are about to quote in order to do required
manipulations.
4.5. Deﬁnition. Say that f : U(open) →
R is continuous if it is continuous at each point

4.2. LIMITS AND CONTINUITY
33
-1
-0.5
0
0.5
1
0
0.05
0.1
0.15
0.2
0.25
0.3
Figure 4.4: Graph of the function sin(1/x). Here it is easy to see the problem at x = 0;
the plotting routine gives up near this singularity.
a ∈U.
Note: This is important. The function f(x) = 1/x is deﬁned on {x : x ̸= 0}, and
is a continuous function. We cannot usefully deﬁne it on a larger domain, and so, by the
deﬁnition, it is continuous. This is an example where the naive “can draw it without taking
the pencil from the paper” deﬁnition of continuity is not helpful.
4.6. Example. Let f(x) = x3 −8
x −2 for x ̸= 2. Show how to deﬁne f(2) in order to make f
a continuous function at 2.
Solution. We have
x3 −8
x −2 = (x −2)(x2 + 2x + 4)
(x −2)
= (x2 + 2x + 4)
Thus f(x) →(22 + 2.2 + 4) = 12 as x →2. So deﬁning f(2) = 12 makes f continuous at
2, (and hence for all values of x).
[Can you work out why this has something to do with the derivative of f(x) = x3 at
the point x = 2?]
4.7. Exercise. Let f(x) =
√x −2
x −4
for x ̸= 4. Show how to deﬁne f(4) in order to make f
a continuous function at 4.
Sometimes, we can work out whether a function is continuous, directly from the deﬁn-
ition. In the next example, it looks as though it is going to be hard, but turns out to be
quite possible.
4.8. Example. Let f(x) =



x sin
1
x

if x ̸= 0,
0
if x = 0.
Then f is continuous at 0.

34
CHAPTER 4. LIMITS AND CONTINUITY
Solution. We prove this directy from the deﬁnition, using that fact that, for all x, we have
| sin(x) ≤1|. Pick ϵ > 0 and choose δ = ϵ [We know the answer, but δ = ϵ/2, or any value
of δ with 0 < δ ≤ϵ will do]. Then if |x| < δ,
x sin 1
x −0
 =
x sin 1
x
 = |x|.
sin 1
x
 ≤|x| < δ ≤ϵ
as required. Note that this is an example where the product of a continuous and a discon-
tinuous function is continuous. The graph of this function is shown in Fig 4.5.
-0.25
-0.2
-0.15
-0.1
-0.05
0
0.05
0.1
0.15
0
0.05
0.1
0.15
0.2
0.25
0.3
Figure 4.5: Graph of the function x. sin(1/x). You can probably see how the discontinuity
of sin(1/x) gets absorbed. The lines y = x and y = −x are also plotted.
4.3
One sided limits
Although sometimes we get results directly, it is usually helpful to have a larger range of
techniques. We give one here and more in section 4.4.
4.9. Deﬁnition. Say that limx→a−f(x) = l, or that f has a limit from the left iﬀgiven
ϵ > 0, there is some δ > 0 such that whenever a −δ < x < a, then |f(x) −f(a)| < ϵ.
There is a similar deﬁnition of “limit from the right”, writen as limx→a+ f(x) = l
4.10. Example. Deﬁne f(x) as follows:-
f(x) =



3 −x
if x < 2;
2
if x = 2;
x/2
if x > 2.
Calculate the left and right hand limits of f(x) at 2.

4.4. RESULTS GIVING CONINUITY
35
Solution.
As x →2−, f(x) = 3 −x →1+, so the left hand limit is 1. As x →2+,
f(x) = x/2 →1+, so the right hand limit is 1. Thus the left and right hand limits agree
(and disagree with f(2), so f is not continuous at 2).
Note our convention: if f(x) →1 and always f(x) ≥1 as x →2−, we say that f(x)
tends to 1 from above, and write f(x) →1+ etc.
4.11. Proposition. If limx→a f(x) exists, then both one sided limts exist and are equal.
Conversely, if both one sided limits exits and are equal, then limx→a f(x) exists.
This splits the problem of ﬁnding whether a limit exists into two parts; we can look on
either side, and check ﬁrst that we have a limit, and second, that we get the same answer.
For example, in 4.2, example 5, both 1-sided limits exist, but are not equal. There is now
an obvious way of checking continuity.
4.12. Proposition. (Continuity Test) The function f is continuous at a iﬀboth one
sided limits exits and are equal to f(a).
4.13. Example. Let f(x) =
 x2
for x ≤1,
x
for x ≥1.
Show that f is continuous at 1. [In fact f
is continuous everywhere].
Solution. We use the above criterion. Note that f(1) = 1. Also
lim
x→1−f(x) = lim
x→1−x2 = 1
while
lim
x→1+ f(x) = lim
x→1+ x = 1 = f(1).
so f is continuous at 1.
4.14. Exercise. Let f(x) =
( sin x
x
for x < 0,
cos x
for x ≥0.
Show that f is continuous at 0. [In fact
f is continuous everywhere]. [Recall the result of 4.2, example 4]
4.15. Example. Let f(x) = |x|. Then f is continuous in
R.
Solution.
Note that if x < 0 then |x| = −x and so is continuous, while if x > 0, then
|x| = x and so also is continuous. It remains to examine the function at 0. From these
identiﬁcations, we see that limx→0−|x| = 0+, while limx→0+ |x| = 0+. Since 0+ = 0−=
0 = |0|, by the 4.12, |x| is continuous at 0
4.4
Results giving Coninuity
Just as for sequences, building continuity directly by calculating limits soon becomes hard
work. Instead we give a result that enables us to build new continuous functions from old
ones, just as we did for sequences. Note that if f and g are functions and k is a constant,
then k.f, f + g, fg and (often) f/g are also functions.
4.16. Proposition. Let f and g be continuous at a, and let k be a constant. Then k.f,
f + g and fg are continuous at f. Also, if g(a) ̸= 0, then f/g is continuous at a.

36
CHAPTER 4. LIMITS AND CONTINUITY
Proof. We show that f + g is continuous at a. Since, by deﬁnition, we have (f + g)(a) =
f(a) + g(a), it is enough to show that
lim
x→a(f(x) + g(x)) = f(a) + g(a).
Pick ϵ > 0; then there is some δ1 such that if |x−a| < δ1, then |f(x)−f(a)| < ϵ/2. Similarly
there is some δ2 such that if |x −a| < δ2, then |g(x) −g(a)| < ϵ/2. Let δ = min(δ1, δ2), and
pick x with |x −a| < δ. Then
|f(x) + g(x) −(f(a) + g(a))| ≤|f(x) −f(a)| + |g(x) −g(a)| < ϵ/2 + ϵ/2 = ϵ.
This gives the result. The other results are similar, but rather harder; see (Spivak 1967)
for proofs.
Note: Just as when dealing with sequences, we need to know that f/g is deﬁned in some
neighbourhood of a. This can be shown using a very similar proof to the corresponding
result for sequences.
4.17. Proposition. Let f be continuous at a, and let g be continuous at f(a). Then g ◦f
is continuous at a
Proof. Pick ϵ > 0. We must ﬁnd δ > 0 such that if |x −a| < δ, then g(f(x)) −g(f(a))| < ϵ.
We ﬁnd δ using the given properties of f and g. Since g is continuous at f(a), there is
some δ1 > 0 such that if |y −f(a)| < δ1, then |g(y) −g(f(a))| < ϵ. Now use the fact that f
is continuous at a, so there is some δ > 0 such that if |x −a| < δ, then |f(x) −f(a)| < δ1.
Combining these results gives the required inequality.
4.18. Example. The function in Example 4.8 is continuous everywhere.
When we ﬁrst
studied it, we showed it was continuous at the “diﬃcult” point x = 0. Now we can deduce
that it is continuous everywhere else.
4.19. Example. The function f : x 7−→sin3 x is continuous.
Solution.
Write g(x) = sin(x) and h(x) = x3. Note that each of g and h are continuous,
and that f = g ◦h. Thus f is continuous.
4.20. Example. Let f(x) = tan
x2 −a2
x2 + a2

. Show that f is continuous at every point of its
domain.
Solution.
Let g(x) = x2 −a2
x2 + a2 . Since −1 < g(x) < 1, the function is properly deﬁned
for all values of x (whilst tan x is undeﬁned when x = (2k + 1)π/2 ), and the quotient is
continuous, since each term is, and since x2 + a2 ̸= 0 for any x. Thus f is continuous, since
f = tan ◦g.
4.21. Exercise. Let f(x) = exp
1 + x2
1 −x2

. Write down the domain of f, and show that f
is continuous at every point of its domain.
As another example of the use of the deﬁnitions, we can give a proof of Proposition 2.20

4.5. INFINITE LIMITS
37
4.22. Proposition. Let f be a continuous function at a, and let an →a as n →∞. Then
f(an) →f(a) as n →∞.
Proof. Pick ϵ > 0 we must ﬁnd N such that |an −f(a)| < ϵ whenever n ≥N. Now since
f is continuous at a, we can ﬁnd δ such that if |x −a| < δ, then |f(x) −f(a)| < ϵ. Also,
since an →a as n →∞there is some N (taking δ for our epsilon — but anything smaller,
like δ = ϵ/2 etc would work) such that |an −a| < δ whenever n ≥N. Combining these we
see that if n ≥N then |an −f(a)| < ϵ, as required.
We can consider the example f(x) = sin(1/x) with this tool.
4.23. Example. Suppose that limx→0 sin(1/x) = l; in other words, assume, to get a con-
tradiction, that the limit exists. Let xn = 1/(πn); then xn →0 as n →∞, and so by
assumption, sin(1/xn) = sin(nπ) = 0 →l as n →∞. Thus, just by looking at a single se-
quence, we see that the limit (if it exists) can only be l. But instead, consider the sequence
xn = 2/(4n+1)π, so again xn →0 as n →∞. In this case, sin(1/xn) = sin((4n+1)π/2) = 1,
and we must also have l = 1. Thus l does not exist.
Note: Sequences often provide a quick way of demonstrating that a function is not
continuous, while, if f is well behaved on each sequence which converges to a, then in fact
f is continuous at a. The proof is a little harder than the one we have just given, and is
left until next year.
4.24. Example. We know from Prop 4.22 together with Example 4.8 that if an →0 as
n →∞, then
an sin
 1
an

→0
as
n →∞.
Prove this directly using squeezing.
Solution. The proof is essentially the same as the proof of Example 4.8. We have
0 ≤
an sin 1
an
 = |an|.
sin 1
an
 ≤|an| →0
as
n →∞.
4.5
Inﬁnite limits
There are many more deﬁnitions and results about limits. First one that is close to the
sequence deﬁnition:
4.25. Deﬁnition. Say that limx→∞f(x) = l iﬀgiven ϵ > 0, there is some K such that
whenever x > K, then |f(x) −l| < ϵ.
4.26. Example. Evaluate lim
x→∞
x2 + 3
3x2 + 2x + 1.
Solution. The idea here should be quite familiar from our sequence work. We use the fact
that 1/x →0 as x →∞. Thus
x2 + 3
3x2 + 2x + 1 =
1 + 3/x2
3 + 2/x + 1/x2 →1
3
as
x →∞.

38
CHAPTER 4. LIMITS AND CONTINUITY
4.27. Deﬁnition. Say that limx→∞f(x) = ∞iﬀgiven L > 0, there is some K such that
whenever x > K, then f(x) > L.
The reason for working on proofs from the deﬁnition is to be able to check what results
of this type are trivially true without having to ﬁnd it in a book. For example
4.28. Proposition. Let g(x) = 1/f(x). Then g(x) →0+ as x →∞iﬀf(x) →∞as
x →∞. Let y = 1/x. Then y →0+ as x →∞; conversely, y →∞as x →0+
Proof. Pick ϵ > 0. We show there is some K such that if x > K, then 0 < y < ϵ; indeed,
simply take K = 1/ϵ. The converse is equally trivial.
4.6
Continuity on a Closed Interval
So far our results have followed because f is continuous at a particular point. In fact we get
the best results from assuming rather more. Indeed the results in this section are precisely
why we are interested in discussing continuity in the ﬁrst place. Although some of the
results are “obvious”, they only follow from the continuity property, and indeed we present
counterexamples whenever that fails. So in order to be able to use the following helpful
results, we must ﬁrst be able to check our functions satisfy the hypothesis of continuity.
That task is of course what we have just been concentrating on.
4.29. Deﬁnition. Say that f is continuous on [a, b] iﬀf is continuous on (a, b), and if, in
addition, limx→a+ f(x) = f(a), and limx→b−f(x) = f(b).
We sometimes refer to f as being continuous on a compact interval. Such an f has
some very nice properties.
4.30. Theorem (Intermediate Value Theorem). Let f be continuous on the compact
interval [a, b], and assume that f(a) < 0 and f(b) > 0. Then there is some point c with
a < c < b such hat f(c) = 0.
Proof. We make no attempt to prove this formally, but sketch a proof with a pair of
sequences and a repeated bisection argument.
It is also noted that each hypothesis is
necessary.
4.31. Example. Show there is at least one root of the equation x −cos x = 0 in the interval
[0, 1].
Proof. Apply the Intermediate Value Theorem to f on the closed interval [0, 1]. The func-
tion is continuous on that interval, and f(0) = −1, while f(1) = 1−cos(1) > 0. Thus there
is some point c ∈(0, 1) such that f(c) = 0 as required.
4.32. Exercise. Show there is at least one root of the equation x −e−x = 0 in the interval
(0, 1).
4.33. Corollary. Let f be continuous on the compact interval [a, b], and assume there is
some constant h such that f(a) < h and f(b) > h. Then there is a point c with a < c < b
such that f(c) = h.

4.6. CONTINUITY ON A CLOSED INTERVAL
39
Proof. Apply the Intermediate Value Theorem to f −h on the closed interval [0, 1]. Note
that by considering −f + h we can cope with the case when f(a) > h and f(b) < h.
Note: This theorem is the reason why continuity is often loosely described as a function
you can draw without taking your pen from the paper. As we have seen with y = 1/x, this
can give an inaccurate idea; it is in fact more akin to connectedness.
4.34. Theorem. (Boundedness) Let f be continuous on the compact interval [a, b].
Then there are constants M and m such that m < f(x) < M for all x ∈[a, b]. In other
words, we are guaranteed that the graph of f is bounded both above and below.
Proof. This again uses the completeness of
R, and again no proof is oﬀered. Note also that
the hypotheses are all needed.
4.35. Theorem. (Boundedness) Let f be continuous on the compact interval [a, b].
Then there are points x0 and x1 such that f(x0) < f(x) < f(x1) for all x ∈[a, b]. In
other words, we are guaranteed that the graph of f is bounded both above and below, and
that these global extrema are actually attained.
Proof. This uses the completeness of
R, and follows in part from the previous result. If M is
the least upper bound given by theorem 4.34. Consider the function g(x) = (M −f(x))−1.
This is clearly continuous. If there is some point at which f(y) = M, there is nothing to
prove; otherwise g(x) is deﬁned everywhere, and is continuous, and hence bounded. This
contradicts the fact that M was a least upper bound for f.
Note also that the hypotheses are all needed.

40
CHAPTER 4. LIMITS AND CONTINUITY

Chapter 5
Diﬀerentiability
5.1
Deﬁnition and Basic Properties
In This section we continue our study of classes of functions which are suitably restricted.
Again we are passing from the general to the particular. The next most particular class
of function we study after the class of continuous functions is the class of diﬀerentiable
functions. We discuss the deﬁnition, show how to get “new functions from old” in what by
now is a fairly routine way, and prove that this is a smaller class: that every diﬀerentiable
function is continuous, but that there are continuous functions that are not diﬀerentiable.
Informally, the diﬀerence is that the graph of a diﬀerentiable function may not have any
sharp corners in it.
As with continuous functions, our aim is to show that there are many attractive prop-
erties which hold for diﬀerentiable functions that don’t hold in general for continuous func-
tions. One we discuss in some detail is the ease with which certain limits can be evaluated,
by introducing l’Hˆopital’s rule. Although we don’t prove this, the corresponding results are
false for continuous functions.
We take the view that much of this material has already been discussed last year, so we
move fairly quickly over the basics.
5.1. Deﬁnition. Let U be an open subset of
R, and let f : U →
R. We say that f is
diﬀerentiable at a ∈U iﬀ
lim
x→a
f(x) −f(a)
x −a
or equivalently,
lim
h→0
f(a + h) −f(a)
h
exists.
The limit, if it exists, is written as f ′(a).
We say that f is diﬀerentiable in U if and only if it is diﬀerentiable at each a in U.
Note that the Newton quotient is not deﬁned when x = a, nor need it be for the
deﬁnition to make sense. But the Newton quotient, if it exists, can be extended to be
a continuous function at a by deﬁning its value at that point to be f ′(a).
Note also
the emphasis on the existence of the limit. Diﬀerentiation is as much about showing the
existence of the derivative, as calculating the value of the derivative.
5.2. Example. Let f(x) = x3. Show, directly from the deﬁnition, that f ′(a) = 3a2. Com-
pare this result with 4.6.
41

42
CHAPTER 5. DIFFERENTIABILITY
Solution.
This is just another way of asking about particular limits, like 4.2; we must
compute
lim
x→a
x3 −a3
x −a
= lim
x→a
(x −a)(x2 + xa + a2)
x −a
= lim
x→a(x2 + 2xa + a2) = 3a2.
5.3. Exercise. Let f(x) = √x. Show, directly from the deﬁnition, that f ′(a) = 1/2√a
when a ̸= 0. What function do you have to consider in the particular case when a = 4?
Just as with continuity, it is impractical to use this deﬁnition every time to compute
derivatives; we need results showing how to diﬀerentiate the usual class of functions, and
we assume these are known from last year. Thus we assume the rules for diﬀerentiation
of sums products and compositions of functions, together with the known derivatives of
elementary functions such as sin, cos and tan; their reciprocals sec, cosec and cot; and exp
and log.
5.4. Proposition. Let f and g be diﬀerentiable at a, and let k be a constant. Then k.f,
f + g and fg are diﬀerentiable at f. Also, if g(a) ̸= 0, then f/g is diﬀerentiable at a. Let
f be diﬀerentiable at a, and let g be diﬀerentiable at f(a). Then g ◦f is diﬀerentiable at a.
In addition, the usual rules for calculating these derivatives apply.
5.5. Example. Let f(x) = tan
x2 −a2
x2 + a2

for a ̸= 0. Show that f is diﬀerentiable at every
point of its domain, and calculate the derivative at each such point.
Solution.
This is the same example we considered in 4.20. There we showed the domain
was the whole of
R, and that the function was continuous everywhere. Let g(x) = x2 −a2
x2 + a2 .
Then g is properly deﬁned for all values of x, and the quotient is diﬀerentiable, since each
term is, and since x2 + a2 ̸= 0 for any x since a ̸= 0. Thus f is diﬀerentiable using the
chain rule since f = tan ◦g, and we are assuming known that the elementary functions like
tan are diﬀerentiable.
Finally to actually calculate the derivative, we have:-
f ′(x)
=
sec2
x2 −a2
x2 + a2

.(x2 + a2).2x −((x2 −a2).2x)
(x2 + a2)2
=
4a2x
(x2 + a2)2 . sec2
x2 −a2
x2 + a2

.
5.6. Exercise. Let f(x) = exp
1 + x2
1 −x2

. Show that f is diﬀerentiable at every point of its
domain, and calculate the derivative at each such point.
The ﬁrst point in our study of diﬀerentiable functions is that it is more restrictive for
a function to be diﬀerentiable, than simply to be continuous.
5.7. Proposition. Let f be diﬀerentiable at a. Then f is continuous at a.

5.2. SIMPLE LIMITS
43
Proof. To establish continuity, we must prove that limx→a f(x) = f(a). Since the Newton
quotient is known to converge, we have for x ̸= a,
f(x) −f(a) = f(x) −f(a)
x −a
.(x −a) →f ′(a).0
as x →a.
Hence f is continuous at a.
5.8. Example. Let f(x) = |x|; then f is continuous everywhere, but not diﬀerentiable at 0.
Solution.
We already know from Example 4.15 that |x| is continuous. We compute the
Newton quotient directly; recall that |x| = x if x ≥0, while |x| = −x if x < 0. Thus
lim
x→0+
f(x) −f(0)
x −0
= lim
x→0+
x −0
x −0 = 1,
while
lim
x→0−
f(x) −f(0)
x −0
= lim
x→0−
−x −0
x −0 = −1.
Thus both of the one-sided limits exist, but are unequal, so the limit of the Newton quotient
does not exist.
5.2
Simple Limits
Our calculus of diﬀerentiable functions can be used to compute limits which otherwise prove
troublesome.
5.9. Proposition (l’Hˆopital’s rule: simple form). Let f and g be functions such that
f(a) = g(a) = 0 while f ′(a) and g′(a) both exits and g′(a) ̸= 0. Then
lim
x→a
f(x)
g(x) = f ′(a)
g′(a) .
Proof. Since f(a) = g(a) = 0, provided x ̸= a, we have
f(x)
g(x) = f(x) −f(a)
g(x) −g(a) = f(x) −f(a)
x −a
x −a
g(x) −g(a) →f ′(a)
g′(a)
as
x →a,
where the last limit exists, since g′(a) ̸= 0.
5.10. Remark. If f ′(a) and g′(a) exist, computing lim
x→a
f(x)
g(x) is easy by 4.16, since f and g
must be continuous at a by Proposition 5.7, unless we get an indeterminate form 0/0 or
∞/∞for the formal quotient. In fact l’Hˆopitals rule helps in both cases, although we need
to develop stronger forms.
5.11. Example. Show that lim
x→0
3x −sin x
x
= 2.
Solution.
Note ﬁrst that we cannot get the result trivially from 4.16, since since g(a) = 0
and so we get the indeterminate form 0/0. However, we are in a position to apply the
simple form of l’Hˆopital, since x′ = 1 ̸= 0. Applying the rule gives
lim
x→0
3x −sin x
x
= lim
x→0
3 −cos x
1
= 2.

44
CHAPTER 5. DIFFERENTIABILITY
5.12. Example. Show that lim
x→0
√1 + x −1
x
= 1/2.
Solution.
Note again that we cannot get the result trivially from
4.16, since this gives
the indeterminate 0/0 form, because g(a) = 0. However, we are in a position to apply the
simple form of l’Hˆopital, since x′ = 1 ̸= 0. Applying the rule gives
lim
x→0
√1 + x −1
x
= lim
x→0
2−1(1 + x)−1/2
1
= 1/2.
5.13. Exercise. Evaluate lim
x→0
log(1 + x)
sin x
.
5.14. Example. (Spurious, but helps to remember!) Show that lim
x→0
sin x
x
= 1.
Solution. This is spurious because we need the limit to calculate the derivative in the ﬁrst
place, but applying l’Hˆopital certainly gives the result.
5.3
Rolle and the Mean Value Theorem
We can combine our deﬁnition of derivative with the Intermediate Value Theorem to give
a useful result which is in fact the basis of most elementary applications of the diﬀeren-
tial calculus. Like the results on continuous functions, it is a global result, and so needs
continuity and diﬀerentiability on a whole interval.
5.15. Theorem (Rolle’s Theorem). Let f be continuous on [a, b], and diﬀerentiable on
(a, b), and suppose that f(a) = f(b).
Then there is some c with a < c < b such that
f ′(c) = 0.
Note: The theorem guarantees that the point c exists somewhere. It gives no indication
of how to ﬁnd c. Here is the diagram to make the point geometrically:
x
c
f’(c) = 0
a
b
Figure 5.1: If f crosses the axis twice, somewhere between the two crossings, the function
is ﬂat. The accurate statement of this “obvious” observation is Rolle’s Theorem.
Proof. Since f is continuous on the compact interval [a, b], it has both a global maximum
and a global minimum. Assume ﬁrst that the global maximum occurs at an interior point
c ∈(a, b). In what follows, we pick h small enough so that c + h always lies in (a, b). Then

5.3. ROLLE AND THE MEAN VALUE THEOREM
45
If h > 0, f(c + h) −f(c)
h
≤0, and so lim
h→0+
f(c + h) −f(c)
h
≤0, since we know the limit
exists.
Similarly, if h < 0, f(c + h) −f(c)
h
≥0, and so
lim
h→0+
f(c + h) −f(c)
h
≥0, since we
know the limit exists. Combining these, we see that f ′(c) = 0, and we have the result in
this case.
A similar argument applies if, instead, the global minimum occurs at the interior point
c. The remaining situation occurs if both the global maximum and global minimum occur
at end points; since f(a) = f(b), it follows that f is constant, and any c ∈(a, b) will do.
5.16. Example. Investigate the number of roots of each of the polynomials
p(x) = x3 + 3x + 1
and
q(x) = x3 −3x + 1.
Solution.
Since p′(x) = 3(x2 + 1) > 0 for all x ∈
R, we see that p has at most one root;
for if it had two (or more) roots there would be a root of p′(x) = 0 between them by Rolle.
Since p(0) = 1, while p(−1) = −3, there is at least one root by the Intermediate Value
Theorem. Hence p has exactly one root.
We have q′(x) = 3(x2 −1) = 0 when x = ±1. Since q(−1) = 3 and q(1) = −1, there is
a root of q between −1 and 1 by the Intermediate Value Theorem. Looking as x →∞and
as x →−∞shows here are three roots of q.
5.17. Exercise. Show that the equation x −e−x = 0 has exactly one root in the inter-
val (0, 1).
Our version of Rolle’s theorem is valuable as far as it goes, but the requirement that
f(a) = f(b) is suﬃciently strong that it can be quite hard to apply sometimes. Fortunately
the geometrical description of the result — that somewhere the tangent is parallel to the
axis, does have a more general restatement.
5.18. Theorem (The Mean Value Theorem). Let f be continuous on [a, b], and dif-
ferentiable on (a, b). Then there is some c with a < c < b such that
f(b) −f(a)
b −a
= f ′(c)
or equivalently
f(b) = f(a) + (b −a)f ′(c).
Proof. We apply Rolle to a suitable function; let
h(x) = f(b) −f(x) −f(b) −f(a)
b −a
(b −x).
Then h is continuous on the interval [a, b], since f is, and in the same way, it is diﬀerentiable
on the open interval (a, b). Also, f(b) = 0 and f(a) = 0. We can thus apply Rolle’s theorem
to h to deduce there is some point c with a < c < b such that h′(c) = 0. Thus we have
0 = h′(c) = −f ′(c) + f(b) −f(a)
b −a
,
which is the required result.

46
CHAPTER 5. DIFFERENTIABILITY
b
c
A
B
a
Figure 5.2: Somewhere inside a chord, the tangent to f will be parallel to the chord. The
accurate statement of this common-sense observation is the Mean Value Theorem.
5.19. Example. The function f satisﬁes f ′(x) =
1
5 −x2 and f(0) = 2. Use the Mean Value
theorem to estimate f(1).
Solution. We ﬁrst estimate the given derivative for values of x satisfying 0 < x < 1. Since
for such x, we have 0 < x2 < 1, and so 4 < 5 −x2 < 5. Inverting we see that
1
5 < f ′(x) < 1
4
when
0 < x < 1.
Now apply the Mean Value theorem to f on the interval [0, 1] to obtain some c with 0 < c < 1
such that f(1) −f(0) = f ′(c). From the given value of f(0), we see that 2.2 < f(1) < 2.25
5.20. Exercise. The function f satisﬁes f ′(x) =
1
5 + sin x and f(0) = 0. Use the Mean
Value theorem to estimate f(π/2).
Note the “common sense” description of what we have done. If the derivative doesn’t
change much, the function will behave linearly. Note also that this gives meaning to the
approximation
f(a + h) ≈f(a) + hf ′(a).
We now see that the accurate version of this replaces f ′(a) by f ′(c) for some c between a
and a + h.
5.21. Theorem. (The Cauchy Mean Value Theorem) Let f and g be both continuous
on [a, b] and diﬀerentiable on (a, b). Then there is some point c with a < c < b such that
g′(c)

f(b) −f(a)

= f ′(c)

g(b) −g(a)

.

5.4. L’H ˆOPITAL REVISITED
47
In particular, whenever the quotients make sense, we have
f(b) −f(a)
g(b) −g(a) = f ′(c)
g′(c) .
Proof. Let h(x) = f(x)

g(b) −g(a)

−g(x)

f(b) −f(a)

, and apply Rolle’s theorem
exactly as we did for the Mean Value Theorem. Note ﬁrst that since both f and g are
continuous on [a, b], and diﬀerentiable on (a, b), it follows that h has these properties. Also
h(a) = f(a)g(b) −g(a)f(b) = h(b). Thus we may apply Rolle to h, to deduce there is some
point c with a < c < b such that h′(c) = 0. But
h′(c) = f ′(c)

g(b) −g(a)

−g′(c)

f(b) −f(a)

Thus
f ′(c)

g(b) −g(a)

= g′(c)

f(b) −f(a)

This is one form of the Cauchy Mean Value Theorem for f and g. If g′(c) ̸= 0 for any
possible c, then the Mean Value theorem shows that g(b) −g(a) ̸= 0, and so we can divide
the above result to get
f(b) −f(a)
g(b) −g(a) = f ′(c)
g′(c) ,
giving a second form of the result.
Note: Taking g(x) = x recovers the Mean Value Theorem.
5.4
l’Hˆopital revisited
We can get a much more useful form of l’Hˆopital’s rule using the Cauchy Mean Value
Theorem, rather than working, as we did in 5.9, directly from the deﬁnition of the derivative.
5.22. Proposition (l’Hˆopital’s rule: general form). . Let f and g be functions such
that f(a) = g(a) = 0, and suppose that f and g are diﬀerentiable on an open interval I
containing a, and that g′(x) ̸= 0, except perhaps at a. Then
lim
x→a
f(x)
g(x) = lim
x→a
f ′(x)
g′(x) ,
provided the second limit exists.
Proof. Pick x > a and apply the Cauchy Mean Value Theorem to the interval [a, x], to ﬁnd
c with a < c < x such that
f(x)
g(x) = f(x) −f(a)
g(x) −g(a) = f ′(c)
g′(c) .
Then lim
x→a+
f(x)
g(x) = lim
c→a+
f ′(c)
g′(c) = lim
x→a+
f ′(x)
g′(x) , since we know the actual limit (not just the
one sided limit) exists. Now repeat with x < a to get the result.

48
CHAPTER 5. DIFFERENTIABILITY
5.23. Example. Evaluate lim
x→0
1 −cos x
x2
= 1
2.
Solution. We have
lim
x→0
1 −cos x
x2
= lim
x→0
sin x
2x
= 1
2,
where the use of l’Hˆopital is justiﬁed since the second limit exists. Note that you can’t
diﬀerentiate top and bottom again, and still expect to get the correct answer; one of the
hypotheses of l’Hˆopital is that the ﬁrst quotient is of the 0/0 form.
5.24. Example. Use l’Hˆopital to establish the following:
lim
x→0
√1 + x −1 −x/2
x2
= −1
8.
Solution. We have
lim
x→0
√1 + x −1 −x/2
x2
= lim
x→0
(1/2)(1 + x)−1/2 −1/2
2x
= lim
x→0
(1/2)(−1/2)(1 + x)−3/2
2
= −1
8 ,
The use of l’Hˆopital is justiﬁed the second time, since the third limit exists; since we now
know the second limit exists, the use of l’Hˆopital is justiﬁed the ﬁrst time.
5.25. Exercise. Evaluate lim
x→0

1
sin x −1
x

= lim
x→0
x −sin x
x sin x .
5.5
Inﬁnite limits
We can use Proposition 4.28 to get results about inﬁnite limits.
5.26. Example. Evaluate lim
x→∞x log

1 + 1
x

.
Solution.
lim
x→∞x log

1 + 1
x

=
lim
x→∞
log(1 + y)
y
writing y = 1/x,
=
lim
y→0+
log(1 + y)
y
=
lim
y→0
log(1 + y)
y
= 1.
The last step is valid, since the ﬁnal limit exists by l’Hˆopital; note also that this gives
another way of ﬁnding an = (1 + 1/n)n.
5.27. Exercise. Evaluate lim
x→∞x sin
1
x

.
5.28. Proposition (l’Hˆopital’s rule: inﬁnite limits). Let f and g be functions such
that limx→∞f(x) = limx→∞g(x) = ∞, and suppose that lim
x→∞
f ′(x)
g′(x) exists. Then
lim
x→∞
f(x)
g(x) = lim
x→∞
f ′(x)
g′(x) .

5.6. TAYLOR’S THEOREM
49
Proof. (Sketch for interest — not part of the course). Pick ϵ > 0 and choose a such that
lim
x→∞

f ′(x)
g′(x) −l
 < ϵ
for all x > a.
Then pick K such that if x > K, then g(x) −g(a) ̸= 0. By Cauchy,
f ′(c)
g′(c) = f(x) −f(a)
g(x) −g(a)
for all x > K.
Note that although c depends on x, we always have c > a. Then
f(x)
g(x)
=
f(x) −f(a)
g(x) −g(a) .
f(x)
f(x) −f(a).g(x) −g(a)
g(x)
,
→
l.1.1
as x →∞.
5.5.1
(Rates of growth)
One interest in these results is to see how fast functions grow as x →∞. This is explored
further in the exercises. But important results are:
• The function ex increases faster than any power of x.
• xα increases faster than any power of log x if α > 0.
5.6
Taylor’s Theorem
We have so far explored the Mean Value theorem, which can be rewritten as
f(a + h) = f(a) + hf ′(c)
where c is some point between a and a + h. [By writing the deﬁnition of c in this way,
we have a statement that works whether h > 0 or h < 0.]
We have already met the
approximation
f(a + h) ∼f(a) + hf ′(a)
when we studied the Newton - Raphson method for solving an equation, and have already
observed that the Mean Value Theorem provides a more accurate version of this. Now
consider what happens when f is a polynomial of degree n
f(x) = a0 + a1x + a2x2 + . . . + an−1xn−1 + anxn.
Note that f(0) = a0. Diﬀerentiating gives
f ′(x) = a1 + 2a2x + 3a3x2 . . . + (n −1)an−1xn−2 + nanxn−1,
and so f ′(0) = a1. Again, we have
f ′′(x) = 2a2 + 3.2a3x . . . + (n −1)(n −2)an−1xn−3 + n(n −1)anxn−2,

50
CHAPTER 5. DIFFERENTIABILITY
and f ′′(0) = 2a2. After the next diﬀerentiation, we get f ′′′(0) = 3!a3, while after k diﬀer-
entiations, we get, f (k)(0) = k!ak, provided k ≤n. Thus we can rewrite the polynomial,
using its value, and the value of its derivatives at 0, as
f(x) = f(0) + f ′(0)x + f ′′(0)
2!
x2 + f ′′′(0)
3!
x3 + . . . + f (n−1)(0)
(n −1)! xn−1 + f (n)(0)
n!
xn.
This opens up the possibility of representing more general functions than polynomials
in this way, and so getting a generalisation of the Mean Value Theorem.
5.29. Theorem (Taylors Theorem - Lagrange form of Remainder). Let f be con-
tinuous on [a, x], and assume that each of f ′, f ′′, . . . , f (n+1) is deﬁned on [a, x]. Then we
can write
f(x) = Pn(x) + Rn(x),
where Pn(x), the Taylor polynomial of degree n about a, and Rn(x), the corresponding
remainder, are given by
Pn(x)
=
f(a) + f ′(a)(x −a) + f ′′(a)
2!
(x −a)2 + f (n)(a)
n!
(x −a)n,
Rn(x)
=
f (n+1)(c)
(n + 1)! (x −a)n+1,
where c is some point between a and x.
We make no attempt to prove this, although the proof can be done with the tools we
have at our disposal. Some quick comments:
• the theorem is also true for x < a; just restate it for the interval [x, a] etc;
• if n = 0, we have f(x) = f(a) + (x −a)f ′(c) for some c between a and x; this is a
restatement of the Mean Value Theorem;
• if n = 1, we have
f(x) = f(a) + (x −a)f ′(x) + f ′′(c)
2!
(x −a)2
for some c between a and x; this often called the Second Mean Value Theorem;
• in general we can restate Taylor’s Theorem as
f(x) = f(a) + (x −a)f ′(x) + . . . + f (n)(a)
2!
(x −a)n + f (n+1)(c)
(n + 1)! (x −a)n+1,
for some c between a and x;
• the special case in which a = 0 has a special name; it is called Maclaurin’s The-
orem;
• just as with Rolle, or the Mean Value Theorem, there is no useful information about
the point c.

5.6. TAYLOR’S THEOREM
51
We now explore the meaning and content of the theorem with a number of examples.
5.30. Example. Find the Taylor polynomial of order n about 0 for f(x) = ex, and write
down the corresponding remainder term.
Solution.
There is no diﬃculty here in calculating derivatives — clearly f (k)(x) = ex for
all k, and so f (k)(0) = 1. Thus by Taylor’s theorem,
ex = 1 + x + x2
2! + x2
2! + . . . xn
n! +
xn+1
(n + 1)! ec
for some point c between 0 and x. In particular,
Pn(x) = 1 + x + x2
2! + x2
2! + . . . xn
n!
and
Rn(x) =
xn+1
(n + 1)! ec .
We can actually say a little more about this example if we recall that x is ﬁxed. We
have
ex = Pn(x) + Rn(x) = Pn(x) +
xn+1
(n + 1)! ec
We show that Rn(x) →0 as n →∞, so that (again for ﬁxed x), the sequence Pn(x) →ex
as n →∞. If x < 0, ec < 1, while if x ≥1, then since c < x, we have ec < ex. thus
|Rn(x)| =

xn+1
(n + 1)! ec
 ≤|x|n+1
(n + 1)! max(ex, 1) →0
as n →∞.
We think of the limit of the polynomial as forming a series, the Taylor series for ex. We
study series (and then Taylor series) in Section 7.
5.31. Example. Find the Taylor polynomial of order 1 about a for f(x) = ex, and write
down the corresponding remainder term.
Solution. Using the derivatives computed above, by Taylor’s theorem,
ex = ea +(x −a) ea +(x −a)2
2!
ec
for some point c between a and x. In particular,
P1(x) = ea +(x −a) ea
and
R1(x) = (x −a)2
2!
ec .
5.32. Example. Find the Maclaurin polynomial of order n > 3 about 0 for f(x) = (1+ x)3,
and write down the corresponding remainder term.
Solution. We have
f(x) = (1 + x)3
f ′(x) = 3(1 + x)2
f ′′(x) = 6(1 + x)
f ′′′(x) = 6
f (n)(x) = 0
if n > 3.
f(0) = 1
f ′(x) = 3
f ′′(x) = 6
f ′′′(x) = 6

52
CHAPTER 5. DIFFERENTIABILITY
and so, by Taylor’s theorem
(1 + x)3 = 1 + 3x + 6
2!x2 + 6
3!x3,
a result we could have got directly, but which is at least reassuring.
5.33. Example. Find the Taylor polynomial of order n about 0 for f(x) = sin x, and write
down the corresponding remainder term.
Solution. There is no diﬃculty here in calculating derivatives — we have
f(x) = sin x
f ′(x) = cos x
f ′′(x) = −sin x
f ′′′(x) = −cos x
f (4)(x) = sin x
and so on.
f(0) = 0
f ′(x) = 1
f ′′(x) = 0
f ′′′(x) = −1.
Thus by Taylor’s theorem,
sin x = x −x3
3! + x5
5! + . . . + (−1)n+1
x2n+1
(2n + 1)! + . . .
Writing down the remainder term isn’t particularly useful, but the important point is that
|R2n+1(x)| ≤

x2n+3
(2n + 3)!
 →0
as n →∞.
5.34. Exercise. Recall that cosh x = ex + e−x
2
, and that sinh x = ex −e−x
2
. Now check the
shape of the following Taylor polynomials:
cos x
=
1 −x2
2! + x4
4! + . . . + (−1)n x2n
2n! + . . .
sinh x
=
x + x3
3! + x5
5! + . . . +
x2n+1
(2n + 1)! + . . .
cosh x
=
1 + x2
2! + x4
4! + . . . + x2n
2n! + . . .
5.35. Example. Find the maximum error in the approximation
sin(x) ∼x −x3
3!
given that |x| < 1/2.
Solution.
We use the Taylor polynomial for sin x of order 4 about 0, together with the
corresponding remainder. Thus
sin x = x −x3
3! + x5
5! cos c

5.6. TAYLOR’S THEOREM
53
for some c with 0 < c < 1/2 or −1/2 < c < 0. In any case, since |x| < 1/2,

x5
5! cos c
 ≤

x5
5!
 ≤

1
25.5!
 ≤
1
120.32.
Warning: The Taylor polynomial always exists, providing f is suitably diﬀerentiable.
But it need not be useful. Consider the example
f(x) =
 exp(−1/x2)
if x > 0;
0
if x ≤0.
The interest in f is at 0; it is well behaved everywhere else. It turns out that
f(0) = f ′(0) = f ′′(0) = . . . = f (n)(0) = . . . = 0.
So the Taylor polynomial of degree n for f about 0 is Pn(x) = 0+0x+0x2 +. . .+0.xn = 0,
and so for every n, Rn(x) = f(x). Clearly in this case, Pn tells us nothing useful about the
function.
5.36. Example. Find the Taylor polynomial of order n about 0 for f(x) = (1+x)α, and note
that this gives a derivation of the binomial theorem. In fact, the remainder |Rn(x)| →0 as
n →∞, provided |x| < 1.
Solution. There is again no diﬃculty here in calculating derivatives — we have
f(x) = (1 + x)α
f ′(x) = α(1 + x)α−1
f ′′(x) = α(α −1)(1 + x)α−2
f ′′′(x) = α(α −1)(α −2)(1 + x)α−3
and in general
f (n)(x) = α(α −1) . . . (α −n + 1)(1 + x)α−n
f(0) = 1
f ′(x) = α
f ′′(x) = α(α −1)
f ′′′(x) = α(α −1)(α −2)
f (n) = α(α −1) . . . (α −n + 1).
Thus by Taylor’s theorem,
(1 + x)α = 1 + αx −α(α −1)
2!
x2 + α(α −1)(α −2)
3!
x3 +
. . . + α(α −1) . . . (α −n + 1)
n!
xn + . . . .
The remainder is not hard to deal with, but we omit the proof; in fact |Rn(x)| →0 when
n →∞.
Note also that if α > 0 is an integer, say α = n then |Rn(x)| = 0 and f(x) = Pn(x).
This is another way to get the Binomial theorem described in Section 1.8.

54
CHAPTER 5. DIFFERENTIABILITY

Chapter 6
Inﬁnite Series
In this section we return to study a particular kind of sequence, those built by adding up
more and more from a given collection of terms. One motivation comes from section 5.6,
in which we obtained a sequence of approximating polynomials {Pn} to a given function.
It is more natural to think of adding additional terms to the polynomial, and as such we
are studying series. However, there is a closely related sequence; the sequence of partial
sums.
6.1
Arithmetic and Geometric Series
Consider the sum
a + (a + r) + (a + 2r) + · · · + (a + nr)
We are trying to add up the terms in an arithmetic progression. A small amount of
notation makes the addition easy.
Let Sn
=
a + (a + r) + (a + 2r) + · · · + (a + nr),
Sn
=
(a + nr) + (a + (n −1)r) + · · · + (a + r) + a,
so 2Sn
=
(2a + nr) + (2a + nr) + · · · + (2a + nr), and
Sn
=
(n + 1).(a + (a + nr))
2
.
Note that if r > 0 then Sn →∞as n →∞, while if r < 0 then Sn →−∞as n →∞.
We next consider a geometric progression (or series):
Let Sn
=
a + ar + ar2 + · · · + arn,
rSn
=
ar + ar2 + ar3 + · · · + arn+1,
so (1 −r)Sn
=
a(1 −rn+1), and
Sn
=
a(1 −rn+1)
1 −r
if
r ̸= 1.
Note that if |r| < 1, then Sn →
a
1 −r as n →∞.
55

56
CHAPTER 6. INFINITE SERIES
If r > 1, say r = 1 + k,
Sn
=
a
(1 + k)n+1 −1
k

,
>
a
k
 1 + (n + 1)k −1

> a(n + 1) →∞
if
a > 0.
6.1. Example. Find
∞
X
n=1
 1
2n + 1
3n

.
Solution.
X  1
2n + 1
3n

=
X 1
2n +
X 1
3n = 1
2 + 1
4 + 1
8 + · · · + 1
3 + 1
9 + · · ·
= 1 + 1
3

1
1 −1/3

= 3
2.
6.2. Exercise. Find
∞
X
n=1

7 1
3n −4 1
2n

.
6.2
Convergent Series
6.3. Deﬁnition. Let {an} be a sequence, and let
Sn = a1 + a2 + · · · + an,
the nth partial sum.
If lim
n→∞Sn exists, we say that
X
an is a convergent series, and write lim
n→∞Sn =
X
an.
Thus a series is convergent if and only if it’s sequence of partial sums is convergent.
The limit of the sequence of partial sums is the sum of the series. A series which is not
convergent, is a divergent series.
6.4. Example. The series
X
rn is convergent with sum 1/(1 −r), provided that |r| < 1.
For other values of r, the series is divergent; in particular, the series
X
(−1)n is divergent.
Solution.
We noted above that when |r| < 1, Sn →a/(1 −r) as n →∞; note particular
cases;
∞
X
n=1
1
2n = 1
or equivalently,
1
2 + 1
4 + 1
8 + · · · = 1.
6.5. Example. The sum
X
1
n(n + 1) is convergent with sum 1.
Solution. We can compute the partial sums explicitly:
Sn =
n
X
k=1
1
k(k + 1) =
n
X
k=1
1
k −
1
k + 1

= 1 −
1
n + 1 →1
as
n →∞.

6.2. CONVERGENT SERIES
57
6.6. Example. The sum
X 1
n is divergent.
Solution. We estimate the partial sums:
Sn
=
1
1 + 1
2 +
1
3 + 1
4

+
1
5 + · · · + 1
8

+
1
9 + · · · + 1
15

+ · · · + 1
n
>
1 + 1
2 + 2
4 + 4
8 > 21
2
if n ≥15
>
1 + 1
2 + 2
4 + 4
8 + 8
16 > 3
if n ≥31
→
∞
as
n →∞.
6.7. Example. The sum
X 1
n2 is convergent. [Actually the sum is π2/6, but this is much
harder.]
2
1
3
4
n-1
n
1/16
1/9
1/4
y = 1/x^2
1/n2
Figure 6.1: Comparing the area under the curve y = 1/x2 with the area of the rectangles
below the curve
Solution.
We estimate the partial sums. Since 1/n2 > 0, clearly {Sn} is an increasing se-
quence. We show it is bounded above, whence by the Monotone Convergence Theorem (3.9),
it is convergent. From the diagram,
1
22 + 1
32 + · · · + 1
n2
<
Z n
1
d x
x2 ,
and so
Sn
<
1 +

−1
x
n
1
≤2 −1
n.
Thus Sn < 2 for all n, the sequence of partial sums is bounded above, and the series is
convergent.
6.8. Proposition. Let P an be convergent. Then an →0 as n →∞.
Proof. Write l = limn→∞Sn, and recall from our work on limits of sequences that Sn−1 →l
as n →∞. Then
an = (a1 + a2 + . . . an) −(a1 + a2 + . . . an−1) = Sn −Sn−1 →l −l
as
n →∞.

58
CHAPTER 6. INFINITE SERIES
6.9. Remark. This gives a necessarycondition for the convergence of a series; it is not
suﬃcient. For example we have seen that P 1/n is divergent, even though 1/n →0 as
n →∞.
6.10. Example. The sum
X 1
n is divergent (Graphical method).
Solution.
We estimate the partial sums. Since 1/n > 0, clearly {Sn} is an increasing
sequence. We show it is not bounded above, whence by the note after 3.9, the sequence of
partial sums →∞as n →∞.
2
1
3
4
n-1
n
y = 1/x
x
y
Figure 6.2: Comparing the area under the curve y = 1/x with the area of the rectangles
above the curve
From the diagram,
1 + 1
2 + · · · + 1
n >
Z n
1
d x
x > 1
2 + · · · + 1
n.
Writing Sn = 1 + 1
2 + · · · + 1
n, we have Sn > log n > Sn −1, or equivalently 1 + log n >
Sn > log n for all n. Thus Sn →∞and the series is divergent. [There is a much better
estimate; the diﬀerence Sn −log n →γ as n →∞, where γ is Euler’s constant.]
6.11. Proposition. Let P an and P bn be convergent. Then P(an + bn) and P c.an are
convergent.
Proof. This can be checked easily directly from the deﬁnition; it is in eﬀect the same proof
that the sum of two convergent sequences is convergent etc.
6.3
The Comparison Test
We have already used the Monotone Convergence Theorem in studying simple series. In
fact it is a lot more useful. When we know the behaviour of some simple series, we can
deduce many more results by comparison as follows.
6.12. Theorem. (The Comparison Test) Assume that 0 ≤an ≤bn for all n, and
suppose that P bn is convergent. Then P an is convergent.
Proof. Deﬁne
Sn
=
a1 + a2 + · · · + an,
Tn
=
b1 + b2 + · · · bn.

6.3. THE COMPARISON TEST
59
Then by hypothesis, 0 ≤Sn ≤Tn. Since {Tn} is a convergent sequence, it is a bounded
sequence by Prop 2.28. In particular, it is bounded above, so there is some K such that
Tn ≤K for all n. Thus Sn ≤K for all n, so {Sn} is a sequence that is bounded above; since
an ≥0, Sn+1 = Sn + an ≥Sn and {Sn} is an increasing sequence. Thus by the Monotone
Convergence Theorem, it is a convergent sequence
.
6.13. Example. Let an =
2n
3n3 −1 and let bn = 1
n2 . Then P an is convergent
Solution. For n ≥1, n3 ≥1, so 3n3 −1 ≥2n3. Thus
an =
2n
3n3 −1 ≤2n
2n3 = bn.
Since we know that P bn is convergent, so is P an.
6.14. Remark. The conclusions of Theorem 6.12 remain true even if we only have an ≤bn
eventually; for if it holds for n ≥N, we replace the inequality by
Sn ≤Tn + a1 + a2 + · · · + aN
and this then holds for all n.
6.15. Example. Let an = log n
n
, and compare with bn = 1
n.
Solution.
Note that if n ≥3, then log n > 1. We can thus use the “eventually” form of
the comparison test; we have
an = log n
n
> 1
n = bn,
We deduce divergence, for if P an were convergent, it follows that that P bn was convergent,
which it isn’t!
6.16. Corollary (Limiting form of the Comparison Test). Suppose that an > 0 and
bn > 0, and that there is some constant k such that lim
n→∞
an
bn
= k > 0. Then P an is
convergent iﬀP bn is convergent.
Proof. Assume ﬁrst that P bn is convergent. Since an/bn →k as n →∞, eventually (take
ϵ = k > 0), we have an ≤2kbn, which is convergent by 6.11. Hence P an is convergent
by 6.12. To get the converse, note that bn/an →1/k as n →∞, so we can use the same
argument with an and bn interchanged.
6.17. Example. Let an =
n
n2 + 1 and let bn = 1
n. Then P an is divergent by the limiting
form of the comparison test.
Solution. Note that the terms are all positive, so we try to apply the limiting form of the
comparison test directly.
an
bn
=
n
n2 + 1.n
1 =
n2
n2 + 1 →1
as n →∞.

60
CHAPTER 6. INFINITE SERIES
Since the limit is non-zero, the use of the limiting form of the comparison test is valid, and
we see that P an is divergent.
Note also we need our work on sequences in Section 2 to evaluate the required limit.
This is all very well, but as with the “new sequences from old” programme, we need a
few reference sequences before we can get further. One set is the geometric series, which
we have already met.
6.18. Exercise. Let an = 2n + 7
3n −1 and let bn =
2
3
n
. Use the limiting form of the compar-
ison test to show that P an is convergent.
We also know about P 1/nα, at least when α ≥2 when it converges, by comparison
with P 1/n2, and when α ≤1 when it diverges, by comparison with P 1/n.
6.19. Proposition. The sum
X 1
nα is convergent when α > 1.
Solution.
Assume α > 1; we estimate the partial sums. Since 1/nα > 0, clearly {Sn} is
an increasing sequence. Let Sn = 1 + 1
2α + · · · + 1
nα , and consider the graph of y = 1/xα,
noting that y is a decreasing function of x (which is where we use that fact that α > 1).
From a diagram which is essentially the same as that of Fig 6.1,
shaded area
<
Z n
1
d x
xα
1
2α + · · · + 1
nα <

1
1 −α
1
xα−1
n
1
Sn −1 <
1
α −1

1 −
1
nα−1

Sn <
1
α −1 + 1
Thus the sequence of partial sums is bounded above, and the series converges.
6.20. Exercise. Let an =
n
√
n5 + n + 1
and let bn =
1
n3/2 . Use the limiting form of the
comparison test to show that P an is convergent.
We can consider the method of comparing with integrals as an “integral test” for the
convergence of a series; rather than state it formally, note the method we have used.
6.21. Theorem (The Ratio Test). Let P an be a series, and assume that lim |an+1|
|an|
→
r as n →∞. Then if r < 1, the series is convergent, if r > 1, the series is divergent, while
if r = 1, the test gives no information.
Proof. A proof follows by comparing with the corresponding geometric series with ratio r.
Details will be given in full in the third year course.
6.22. Example. Let an = 2n(n!)2
(2n)! . Then P an is convergent.

6.4. ABSOLUTE AND CONDITIONAL CONVERGENCE
61
Solution. We look the ratio of adjacent terms in the series (of positive terms).
(n + 1)st term
nth term
= an+1
an
= 2n+1(n + 1)!(n + 1)!
(2n + 2)!
(2n)!
2nn!n!
=
2(n + 1)2
(2n + 2)(2n + 1) = n + 1
2n + 1 →1
2
as n →∞.
Since the ratio of adjacent terms in the series tends to a limit which is < 1, the series
converges by the ratio test.
6.4
Absolute and Conditional Convergence
So far most of our work has been with series all of whose terms are positive. There is a
good reason for this; there is very little we can say about series with mixed signs. Indeed
there is just one useful result at this level, which is the topic of this section.
The easiest case occurs when the series really can be thought of as a series of positive
terms.
6.23. Deﬁnition. The series P∞
n=1 an is absolutely convergent iﬀthe series P∞
n=1 |an|
is convergent.
6.24. Deﬁnition. The series P∞
n=1 an is conditionally convergent if and only if the
series P∞
n=1 an is convergent but not absolutely convergent.
6.25. Example. Show that the series
∞
X
n=1
(−1)n+1
n2
is absolutely convergent.
Solution. We have
∞
X
n=1

(−1)n+1
n2
 =
∞
X
n=1
1
n2 and this is convergent by 6.19. So
∞
X
n=1
(−1)n+1
n2
is absolutely convergent.
Note: We choose to work with the sign (−1)n+1 rather than (−1)n simply for tidiness;
it is usual to start a series with a positive term, so the coeﬃcient of a1 is chosen to be +.
Thus that of a2 must be −etc if the series is to alternate.
6.26. Exercise. Show that the series
∞
X
n=2
(−1)n
n2 log n is absolutely convergent.
6.27. Exercise. Show that the series
∞
X
n=1
sin n
n2
is absolutely convergent. [Hint: note that
| sin n| ≤1, and use the comparison test.]
Our interest in absolutely convergent series starts by observing that they are in fact all
convergent. Indeed this is the easiest way to show a series is convergent if the terms are
not all positive.
6.28. Proposition. An absolutely convergent series is convergent.

62
CHAPTER 6. INFINITE SERIES
Proof. Assume that P∞
n=1 an is absolutely convergent, and deﬁne
a+
n =
 an
if an > 0
0
if an ≤0
and
a−
n =
 |an|
if an < 0
0
if an ≥0
The point of this deﬁnition is that
0 ≤a+
n ≤|an|
and
0 ≤a−
n ≤|an|
for all n,
(6.1)
so we have two new series of positive terms, while
|an| = a+
n + a−
n
and
an = a+
n −a−
n .
Using equation 6.1 to compare with the convergent series P∞
n=1 |an|, we see that each of
∞
X
n=1
a+
n
and
∞
X
n=1
a−
n
is a convergent series of positive terms. Thus
∞
X
n=1
an =
∞
X
n=1
a+
n −a−
n =
∞
X
n=1
a+
n +
∞
X
n=1
a−
n
is also convergent using 6.11.
This gives one way of proving that a series is convergent even if the terms are not
all positive, and so we can’t use the comparison test directly. There is essentially only
one other way, which is a very special, but useful case known as Leibniz theorem, or the
theorem on alternating signs, or the alternating series test. We give the proof because
the argument is so like the proof of the convergence of the ratio of adjacent terms in the
Fibonacci series 3.1.
Warning: Note how we usually talk about the “Fibonacci series”, even though it is a
sequence rather than a series. Try not to be confused by this popular but inaccurate usage.
6.29. Theorem. Leibniz Theorem Let {an} be a decreasing sequence of positive terms
such that an →0 as n →∞. Then the series
∞
X
n=1
(−1)n+1an
is convergent.
Proof. Write Sn for the nth partial sum of the series
∞
X
n=1
(−1)n+1an. We show this sequence
has the same type of oscillating behaviour that the corresponding sequence of partial sums
in the Fibonacci example. By deﬁnition, we have
s2n+1 = a1 −a2 + a3 −. . . + a2n−1 −a2n + a2n+1
s2n−1 = a1 −a2 + a3 −. . . + a2n−1

6.4. ABSOLUTE AND CONDITIONAL CONVERGENCE
63
and so, subtracting, we have
s2n+1 = s2n−1 −a2n + a2n+1.
Since {an} is a decreasing sequence, a2n > a2n+1 and so s2n+1 < s2n−1. Thus we have a
decreasing sequence
s1 > s3 > s5 > . . . > s2n−1 > s2n+1 > . . . .
Similarly s2n > s2n−2 and we have an increasing sequence
s2 < s4 < s6 . . . < s2n−2 < s2n < . . . .
Also
s2n+1 = s2n + a2n+1 > s2n
Thus
s2 < s4 < s6 . . . < s2n−2 < s2n < s2n+1 < s2n−1 < . . . s5 < s3 < s1
and the sequence s1, s3, s5, . . . is a decreasing sequence which is bounded below (by s2),
and so by 3.9 is convergent to α (say). Similarly s2, s4, s6, . . . is an increasing sequence
which is bounded above (by s1), and so by 3.9 is convergent to β (say) also
s2n+1 −s2n = a2n+1
and so letting n →∞
α −β = 0
So α = β, and all the partial sums are tending to α, so the series converges.
6.30. Example. Show that the series
∞
X
n=1
(−1)n+1
n
is conditionally convergent.
Solution.
We have
∞
X
n=1

(−1)n+1
n
 =
∞
X
n=1
1
n and this is divergent by 6.19; thus the series is
not absolutely convergent. We show using 6.29 that this series is still convergent, and so is
conditionally convergent.
Write an = 1/n, so an > 0, an+1 < an and an →0 as n →∞. Thus all the conditions
of Leibniz’s theorem are satisﬁed, and so the series
∞
X
n=1
(−1)n+1
n
is convergent.
6.31. Proposition (Re-arranging an Absolutely convergent Series). Let P∞
n=1 an
be an absolutely convergent series and suppose that {bn} is a re-arrangement of {an}. Then
P∞
n=1 bn is convergent, and
∞
X
n=1
bn =
∞
X
n=1
an.

64
CHAPTER 6. INFINITE SERIES
Proof. See next year, or (Spivak 1967); the point here is that we need absolute convergence
before series behave in a reasonable way.
Warning: It is not useful to re-arrange conditionally convergent series (remember the
rearrangement I did in section 1.1). There is a result which is an extreme form of this:
Pick x ∈
R, and let P∞
n=1 an be a conditionally convergent series. then there is
a re-arrangement {bn} of {an} such that P∞
n=1 bn = x!
In other words, we can re-arrange to get any answer we want!
6.5
An Estimation Problem
This section shows how we can use a lot of the earlier ideas to produce what is often wanted
in practice — results which are an approximation, together with an indication of how good
the approximation is.
Find how accurate the approximation obtained by just using the ﬁrst ten terms
is, to
∞
X
n=1
1
n2 .
Again we are going to use geometrical methods for this. Our geometric statement follows
from the diagram, and is the assertion that the area of the rectangles below the curve is less
than the area under the curve, which is less than the area of the rectangles which contain
the curve.
N
N+1
N+2
M-1
M
y = 1/x2
Figure 6.3: An upper and lower approximation to the area under the curve
Writing this out geometrically gives the statement:
M
X
n=N+1
1
n2 ≤
Z M
N
dx
x2 ≤
M−1
X
n=N
1
n2
We can evaluate the middle integral:
Z M
N
dx
x2 =

−1
x
M
N
= 1
N −1
M .

6.5. AN ESTIMATION PROBLEM
65
For convenience, we deﬁne
S =
∞
X
n=1
1
n2
and
SN =
N
X
n=1
1
n2 .
We can now express our inequality in these terms:
SM −SN ≤1
N −1
M ≤SM−1 −SN−1
Next, let M →∞, so SM →S, and 1/M →0. We have
S −SN ≤1
N ≤S −SN−1
Replacing N by N + 1, gives another inequality, which also holds, namely
S −SN+1 ≤
1
N + 1 ≤S −SN,
and combining these two, we have
S −SN+1 ≤
1
N + 1 ≤S −SN ≤1
N ≤S −SN−1.
In particular, we have both upper and lower bounds for S −SN, as
1
N + 1 ≤S −SN ≤1
N .
To make the point that this is a useful statement, we now specialise to the case when
N = 10. Then
1
11 ≤S −S10 ≤1
10
or
0 ≤S −

S10 + 1
11

≤1
10 −1
11 =
1
110.
Our conclusion is that although S10 is not a very good approximation, we can describe the
error well enough to get a much better approximation.

66
CHAPTER 6. INFINITE SERIES

Chapter 7
Power Series
7.1
Power Series and the Radius of Convergence
In Section 5.6, we met the idea of writing f(x) = Pn(x) + Rn(x), to express a function in
terms of its Taylor polynomial, together with a remainder. We even saw in 5.30 that, for
some functions, the remainder Rn(x) →0 as n →∞for each ﬁxed x. We now recognise
this as showing that certain series converge.
We have more eﬀective ways of showing that such a series converges — we can use that
ratio test. But note that such a test will only show that a series converges, not that it
converges to the function used to generate it in the ﬁrst place. We saw an example of such
a problem in the Warning before Example 5.36.
To summarise the results we had in Section 5.6,
7.1. Proposition. The following series converge for all values of x to the functions shown:
ex = 1 + x + x2
2! + x2
2! + . . . xn
n! + . . .
sin x = x −x3
3! + x5
5! + . . . + (−1)n+1
x2n+1
(2n + 1)! + . . .
cos x = 1 −x2
2! + x4
4! + . . . + (−1)n x2n
2n! + . . .
sinh x = x + x3
3! + x5
5! + . . . +
x2n+1
(2n + 1)! + . . .
cosh x = 1 + x2
2! + x4
4! + . . . + x2n
2n! + . . .
These are all examples of the subject of this section; they are real power series, which
we can use to deﬁne functions. The corresponding functions are the best behaved of all the
classes of functions we meet in this course; indeed are as well behaved as could possibly
be expected. We shall see in this section that this class of functions are really just “grown
up polynomials”, and that almost any manipulation valid for polynomials remains valid for
this larger class of function.
7.2. Deﬁnition. A real power series is a series of the form P anxn, where the an are
real numbers, and x is a real variable.
67

68
CHAPTER 7. POWER SERIES
We are thus dealing with a whole collection of series, one for each diﬀerent value of x.
Our hope is that there is some coherence; that the behaviour of series for diﬀerent values
of x are related in some sensible way.
7.3. Example. The geometric series
∞
X
n=0
xn is another example of a power series we have
already met. We saw this series is convergent for all x with |x| < 1.
It turns out that a power series is usually best investigated using the ratio test, The-
orem 6.21. And the behaviour of power series is in fact very coherent.
7.4. Theorem (Radius of Convergence). Suppose P anxn is a power series.
Then
one of the following happens:
• P anxn converges only when x = 0; or
• P anxn converges absolutely for all x; or
• there is some number R > 0 such that P anxn converges absolutely for all x with
|x| < R, and diverges for all x with |x| > R.
No statement is made in the third case about what happens when x = R.
7.5. Deﬁnition. The number R described above is called the radius of convergence of
the power series. By allowing R = 0 and R = ∞, we can consider every power series to
have a radius of convergence.
Thus every power series has a radius of convergence. We sometimes call the interval
(−R, R), where the power series is guaranteed to converge, the interval of convergence.
It is characterised by the fact that the series converges (absolutely) inside this interval and
diverges outside the interval.
• The word “radius” is used, because in fact the same result is true for complex series,
and then we have a genuine circle of convergence, with convergence for all (complex)
z with |z| < R, and guaranteed divergence whenever |z| > R.
• Note the power of the result; we are guaranteed that when |x| > R, the series diverges;
it can’t even converge “accidentally” for a few x′s with |x| > R. Only on the circle
of convergence is there ambiguity.
This regularity of behaviour makes it easy to investigate the radius of convergence of a
power series using the ratio test.
7.6. Example. Find the radius of convergence of the series
X nxn
2n+1 .
Solution.
Recall that the ratio test only applies to series of positive terms, so we look at
the ratio of the moduli.
|(n + 1)st term|
|nth term|
=
(n + 1)|x|n+1
2n+2
2n+1
n|x|n
=
(n + 1)|x|
n.2
→|x|
2
as n →∞.

7.2. REPRESENTING FUNCTIONS BY POWER SERIES
69
Thus the given series diverges if |x| > 2 and converges absolutely (and so of course con-
verges) if |x| < 2. Hence it has radius of convergence 2.
7.7. Example. Find the radius of convergence of the series
X (−1)nn!xn
nn
.
Solution.
This one is a little more subtle than it looks, although we have met the limit
before. Again we look at the ratio of the moduli of adjacent terms.
|(n + 1)st term|
|nth term|
=
(n + 1)!|x|n+1
(n + 1)n+1
nn
n!|x|n = (n + 1).|x|.
nn
(n + 1)(n+1)
=
nn
(n + 1)n |x| =

n
n + 1
n
|x|
=
|x|
n + 1
n
n →|x|
e
as n →∞.
Here we have of course used the result about e given in Section 3.1 to note that

1 + 1
n
n
→e
as n →∞.
Thus the given series diverges if |x| > e and converges absolutely (and so of course converges)
if |x| < e. Hence it has radius of convergence e.
7.8. Exercise. Find the radius of convergence of the series
∞
X
n=0
xn
n2 + 1
We noted that the theorem gives no information about what happens when x = R,
i.e. on the circle of convergence. There is a good reason for this — it is quite hard to
predict what happens. Consider the following power series, all of which have radius of
convergence 2.
∞
X
n=1
xn
2n
∞
X
n=1
xn
n2n
∞
X
n=1
xn
n22n .
The ﬁrst is divergent when x = 2 and when x = −2, the second converges when x = −2,
and diverges when x = 2, while the third converges both when x = 2 and when x = −2.
These results are all easy to check by direct substitution, and using Theorem 6.29.
7.2
Representing Functions by Power Series
Once we know that a power series has a radius of convergence, we can use it to deﬁne
a function. Suppose the power series P anxn has radius of convergence R > 0, and let
I = (−R, R). We now deﬁne a function f on this open interval I as follows:
f(x) =
∞
X
n=1
anxn
for x ∈I.

70
CHAPTER 7. POWER SERIES
It turns out that this is the last, and best behaved of the classes of functions we study
in this course.
In fact all of what we say below remains true when R = ∞, provided we interpret the
open interval I as
R.
7.9. Theorem. Let P anxn be a power series with radius of convergence R > 0. Let I
be the open interval (−R, R), and deﬁne f(x) = P anxn for x ∈I. Then P nanxn−1 has
radius of convergence R, f is diﬀerentiable on I, and
f ′(x) =
∞
X
n=1
nanxn−1
for x ∈I.
We summarise this result by saying that we can diﬀerentiate a power series term - by -
term everywhere inside the circle of convergence. If R = ∞, then this can be done for all x.
Proof. Quite a lot harder than it looks; we need to be able to re-arrange power series, and
then use the Mean Value Theorem to estimate diﬀerences, and show that even when we
add an inﬁnite number of errors, they don’t add up to too much. It can be found e.g. in
(Spivak 1967).
7.10. Corollary. Let f and I be deﬁned as 7.9. Then f has an indeﬁnite integral deﬁned
on I, given by
G(x) =
∞
X
n=0
an
(n + 1)xn+1
for x ∈I.
Proof. Apply 7.9 to G to see that G′(x) = f(x), which is the required result.
7.3
Other Power Series
We now derive some further power series to add to the collection described in 7.1. Starting
with the geometric series
1
1 −x = 1 + x + x2 + x3 + . . . + xn + . . .
for |x| < 1,
(7.1)
we replace x by −x to get
1
1 + x = 1 −x + x2 −x3 + . . . + (−1)nxn + . . .
for |x| < 1.
Integrating both sides then gives
log(1 + x) = K + x −x2
2 + x3
3 + . . . + (−1)n xn+1
n + 1 + . . .
for |x| < 1,
where K is a constant of integration. Evaluating both sides when x = 0 shows that K = 0,
and so we get the series
log(1 + x) =
∞
X
n=0
(−1)nxn+1
n + 1
valid for |x| < 1.
(7.2)

7.3. OTHER POWER SERIES
71
Note: It is easy to get this result directly from the Taylor Series. The next one is not
quite so easy.
We return to equation 7.1, and replace x by −x2 to get
1
1 + x2 = 1 −x2 + x4 −x6 + . . . + (−1)nx2n + . . .
for |x| < 1.
Again integrating both sides, we have
arctan(x) = K + x −x3
3 + x5
5 + . . . + (−1)n x2n+1
2n + 1 + . . .
for |x| < 1,
where K is a constant of integration. Again putting x = 0 shows that K = 0, and so
arctan(x) =
∞
X
n=0
(−1)nx2n+1
2n + 1
valid for |x| < 1.
(7.3)
7.11. Example. Find the radius of convergence R of the power series
x2
2 −x3
3.2 + x4
4.3 −x5
5.4 · · · + (−1)nxn
n(n −1) + · · ·
By diﬀerentiation or otherwise, ﬁnd the sum of the series for |x| < R.
[You may assume, without proof, that
Z
log(1 + x) dx = K + x log(1 + x) −x + log(1 + x),
for some constant of integration K.]
Solution. Apply the ratio test to the given power series. Then

an+1
an
 =

xn+1n(n −1)
xnn(n + 1)
 →|x|
as
n →∞.
Thus the new series has radius of convergence 1. Denote its sum by f(x), deﬁned for |x| < 1.
Inside the circle of convergence, it is permissible to diﬀerentiate term - by - term, and thus
f ′(x) = log(1 + x) for |x| < 1, since they have the same power series. Hence
f(x)
=
Z
log(1 + x) dx = K + x log(1 + x) −
Z x + 1 −1
1 + x
dx
(7.4)
=
K + x log(1 + x) −x + log(1 + x).
(7.5)
Putting x = 0 shows that K = 0 and so f(x) = (1 + x) log(1 + x) −x.
We have now been able to derive a power series representation for a function without
working directly from the Taylor series, and doing the diﬀerentiations — which can often
prove very awkward. Nevertheless, we have still found the Taylor coeﬃcients.
7.12. Proposition. Let P anxn be a power series, with radius of convergence R > 0, and
deﬁne
f(x) =
∞
X
n=0
anxn
for |x| < R.
Then an = f (n)(0)
n!
, so the given series is the Taylor (or Maclaurin) series for f

72
CHAPTER 7. POWER SERIES
Proof. We can diﬀerentiate n times by 7.9 and we still get a series with the same radius
of convergence. Also, calculating exactly as in the start of Section 5.6, we see that the
derivatives satisfy f (n)(0) = n!an, giving the uniqueness result.
7.13. Example. Let f(x) =
1
1 −x3 . Calculate f (n)(0).
Solution. We use the binomial theorem to get a power series expansion about 0,
1
1 −x3 = 1 + x3 + x6 + x9 + . . . + x3n + . . .
valid for |x| < 1.
We now read oﬀthe various derivatives. Clearly f (n)(0) = 0 unless n is a multiple of 3,
while f (3k)(0) = (3k)! by 7.12.
7.4
Power Series or Function
We have now seen that when a power series is used to deﬁne a function, then that function
is very well behaved, and we can manipulate it by manipulating, in the obvious way,
the corresponding power series. However there are snags. A function has one deﬁnition
which works everywhere it makes sense (at least for simple functions), whereas the power
series corresponding to a function depends also on the point about which the expansion is
happening. An example will probably make this clearer than further discussion.
7.14. Example. Give the power series expansions for the function f(x) =
1
1 −x.
Solution. We can already do this about 0 by the Binomial Theorem; we have:
1
1 −x = 1 + x + x2 + x3 + . . . + xn + . . .
for |x| < 1.
To expand about a diﬀerent point, e.g. about 3, write y = x −3. Then
1
1 −x =
1
1 −(y + 3) =
1
−2 −y = −1
2.
1
1 −y/2,
and again using the Binomial Theorem on the last representation, we have
1
1 −x = −1
2
 1 + y/2 + y2/4 + y3/9 + . . . + yn/2n + . . .

for |y/2| < 1.
Writing this in terms of x gives
1
1 −x = −1
2

1 + x −3
2
+ (x −3)2
4
+ . . . + (x −3)n
2n
+ . . .

for |x −3| < 2.
It should be no surprise that this is the Taylor series for the same function about the
point 3. And it is in fact not an accident that the radius of convergence of the new series
is 2. More investigation (quite a lot more - mainly for complex functions) shows the radius
of convergence is always that of the largest circle that can be ﬁtted into the domain of
deﬁnition of the function. And that is why it is of interest to sometimes consider power
series as complex power series. The power series expansion for (1 + x2)−1 has radius of
convergence 1. This seems implausible viewed with real spectacles, but totally explicable
when it is realised that the two points i and −i are stopping the expansion from being valid
in a larger circle.

7.5. APPLICATIONS*
73
7.5
Applications*
This section will not be formally examined, but is here to show how we can get more
interesting results from power series.
7.5.1
The function ex grows faster than any power of x
Speciﬁcally, we claim that for any α ∈
R, limx→∞x−α ex = ∞.
We have
ex =
∞
X
n=0
xn
n!
and so
x−α ex =
∞
X
n=0
xn
n! .
Given α, we can always ﬁnd some N such that N −α ≥1. Next note that provided x > 0,
each term in the series for x−α ex is positive, and hence the sum is greater than any given
term. So in particular,
x−α ex > xN−α
N!
≥x
N!
if x > 1.
In particular, since N is ﬁxed, x
N! →∞as x →∞, giving the result claimed.
7.5.2
The function log x grows more slowly than any power of x
Speciﬁcally, we claim that for any β > 0, limx→∞x−β log x = 0.
We are interested in what happens when x →∞, so we will restrict to the situation
when x > 0. Put y = β log x, noting this is possible since x > 0. Thus y/β = log x, or
equivalently, x = ey/b. Thus we have xβ = ey, and so
x−β log x = y
β . e−y
when y = β log x.
(7.6)
Since β > 0, as x →∞, so y →∞.
But from our previous result, as y →∞, so
βy−1 eY →∞, which is the same as saying that y
β . e−y →0 as y →∞. this is the required
result by equation 7.6.
7.5.3
The probability integral
R α
0 e−x2 dx
The normal distribution is a very common model throughout the whole of science for the
situation when things occur “at random”. In particular, probability theory attempts to
predict what will happen “on average”, perhaps for computing risks and premiums on life
insurance; in so doing one is often led to consider an integral of the form
I =
Z α
0
e−x2 dx.
It turns out that this integral cannot be evaluated using the usual tricks — substitution,
integration by parts etc. But a power series representation and Corollary 7.10 can help.

74
CHAPTER 7. POWER SERIES
Thus
ex =
∞
X
n=0
xn
n!
e−x2 =
∞
X
n=0
(−1)n (−x2)n
n!
=
∞
X
n=0
(−1)n x2n
n!
and we can integrate this term-by term, by Corollary 7.10, to get
Z
e−x2 dx = K +
∞
X
n=0
(−1)nx2n+1
(2n + 1)n! .
Performing a deﬁnite integral removes the constant of integration, to give
Z α
0
e−x2 dx =
∞
X
n=0
(−1)nα2n+1
(2n + 1)n! .
The partial sums of the power series on the right can be computed, and converge quite
quickly, so we have a practical method of evaluating the integral, even thought we can’t
“do” the integral.
7.5.4
The number e is irrational
We use a power series argument, together with a proof by contradiction, as was done to
show that
√
2 was irrational. So assume, to get our contradiction, that e is rational, so
it can be written in the form e = a/b, where a and b are integers. Note that this means
e−1 = b/a. From the exponential series,
b
a = e−1 =
∞
X
n=0
(−1)n
n!
and so, multiplying through by a!,
b
a.a! = e−1 =
∞
X
n=0
(−1)n.a!
n!
.
Thus, we have
b(a −1)! = a! −a!
1! + a!
2! −a!
3! + . . .
= a! −a!
1! + a!
2! −a!
3! + . . . + (−1)aa!
a!
+ (−1)a+1

1
a + 1 −
1
(a + 1)(a + 2) +
1
(a + 1)(a + 2)(a + 3) −. . .

.
The left hand side is an integer, as is each of the terms in the sum
a! −a!
1! + a!
2!
a!
3! + . . . + (−1)aa!
a!
;

7.5. APPLICATIONS*
75
it follows that the rest of that equation is an integer, so
(−1)a+1

1
a + 1 −
1
(a + 1)(a + 2) +
1
(a + 1)(a + 2)(a + 3) −. . .

is an integer. But this is an alternating sequence of positive terms, which decreases to 0,
and so by 6.29, is convergent to a sum which lies between the ﬁrst two partial sums. The
ﬁrst partial sum is
1
a + 1 while the second is
1
a + 2 (check this). So there must be an integer
between
1
a + 1 and
1
a + 2. Since there is not, this contradiction demonstrates our initial
assertion.

76
CHAPTER 7. POWER SERIES

Chapter 8
Diﬀerentiation of Functions of
Several Variables
We conclude with two chapters which are really left over from last year’s calculus course,
and which should help to remind you of the techniques you met then. We shall mainly be
concerned with diﬀerentiation and integration of functions of more than one variable. We
describe
• how each process can be done;
• why it is interesting, in terms of applications; and
• how to interpret the process geometrically.
In this chapter we concentrate on diﬀerentiation, and in the last one, move on to integration.
8.1
Functions of Several Variables
Last year, you did a signiﬁcant amount of work studying functions, typically written as
y = f(x), which represented the variation that occurred in some (dependent) variable y, as
another (independent) variable, x, changed. For example you might have been interested
in the height y after a given time x, or the area y, enclosed by a rectangle with sides x and
10 −x. Once the function was known, the usual rules of calculus could be applied, and
results such as the time when the particle hits the ground, or the maximum possible area
of the rectangle, could be calculated. In the earlier part of the course, we have extended
this work by taking a more rigorous approach to a lot of the same ideas.
We are going to do the same thing now for functions of several variables. For example the
height y of a particle may depend on the position x and the time t, so we have y = f(x, t);
the volume V of a cylinder depends on the radius r of the base and its height h, and
indeed, as you know, V = πr2h; or the pressure of a gas may depend on its volume V and
temperature T, so P = P(V, T). Note the trick I have just used; it is often convenient to
use P both for the (defendant) variable, and for the function itself: we don’t always need
separate symbols as in the y = f(x) example.
When studying the real world, it is unusual to have functions which depend solely on a
single variable. Of course the single variable situation is a little simpler to study, which is
77

78 CHAPTER 8. DIFFERENTIATION OF FUNCTIONS OF SEVERAL VARIABLES
-4
-2
0
2
4
6
8
10
-2
-1
0
1
2
3
4
Graph of $y = x^2 - 3x$.
Figure 8.1: Graph of a simple function of one variable
why we started with it last year. And just as last year, we shall usually have a “standard”
function name; instead of y = f(x), we often work with z = f(x, y), since most of the extra
complications occur when we have two, rather than one (independent) variable, and we
don’t need to consider more general cases like w = f(x, y, z), or even y = f(x1, x2, . . . , xn).
Graphing functions of Several Variables
One way we tried to understand the function y = f(x) was by drawing its graph, as shown
in Fig 8.1. We then used such a graph to pick out points such as the local minimum at
x = 3/2, and to see how we could get the same result using calculus.
Working with two or more independent variables is more complicated, but the ideas are
familiar. To plot z = f(x, y) we think of z as the height of the function f at the point
(x, y), and then try to sketch the resulting surface in three dimensions. So we represent a
function as a surface rather than a curve.
8.1. Example. Sketch the surface given by z = 2 −x/2 −2y/3
Solution.
We know the surface will be a plane, because z is a linear function of x and y.
Thus it is enough to plot three points that the plane passes through. This gives Fig. 8.2.
y
z
x
(0,3,0)
(4,0,0)
(0,0,2)
Figure 8.2: Sketching a function of two variables
Of course it is easy to sketch something as simple as a plane.
There are graphical

8.1. FUNCTIONS OF SEVERAL VARIABLES
79
diﬃculties when dealing with more complicated functions, which make sketching and visu-
alisation rather harder than for functions of one variable. And if there are three or more
independent variables, there is really no good way of visualising the behaviour of the func-
tion directly. But for just two independent variables, there are some tricks.
8.2. Example. Sketch the surface given by z = x2 −y2.
Solution. We can represent the surface directly by drawing it as shown in Fig. 8.3.
-4
-3
-2
-1
0
1
2
3
4
-4 -3 -2 -1 0 1 2 3 4
-20
-15
-10
-505
10
15
20
Figure 8.3: Surface plot of z = x2 −y2.
Such a representation is easy to create using suitable software and Fig. 8.3 shows the
resulting surface.
We now describe how to looking at similar examples without such a
program. One approach is to draw a contour map of the surface, and then use the usual
tricks to visualise the surface.
For the surface z = x2 −y2, the points where z = 0 lie on x2 = y2, so form the lines
y = x and y = −x. We can continue in this way, and look at the points where z = 1; so
x2−y2 = 1. This is one of the hyperbolae shown Fig. 8.4; indeed, ﬁxing z at diﬀerent values
shows the contours (lines of constant height or z value) are all the same shape, but with
diﬀerent constants. We this get the alternative representation as a contour map shown in
Fig. 8.4.
A ﬁnal way to conﬁrm that you have the right view of the surface is to section it in
diﬀerent planes. So far we have looked at the intersection of the planes z = k with the
surface z = x2 −y2 for diﬀerent values of the constant k. If instead we ﬁx x, at the value a,
then z = a2 −y2. Each of these curves is a parabola with its vertex upwards, at the point
y = 0, z = a2.
8.3. Exercise. By looking at the curves where z is constant, or otherwise, sketch the surface
given by z =
p
x2 + y2.

80 CHAPTER 8. DIFFERENTIATION OF FUNCTIONS OF SEVERAL VARIABLES
-4
-3
-2
-1
0
1
2
3
4
-4
-3
-2
-1
0
1
2
3
4
Figure 8.4: Contour plot of the surface z = x2 −y2. The missing points near the x - axis
are an artifact of the plotting program.
Continuity
As you might expect, we say that a function f of two variables is continuous at (x0, y0) if
lim
x→x0,y→y0 f(x, y) = f(x0, y0).
The only complication comes when we realise that there are many diﬀerent ways if which
x →x0 and y →y0. We illustrate with a simple example.
8.4. Example. Investigate the continuity of f(x, y) =
2xy
x2 + y2 at the point (0, 0).
Solution.
Consider ﬁrst the case when x →0 along the x-axis, so that throughout the
process, y = 0. We have
f(x, 0) =
2x.0
x2 + 0 = 0 →0
as x →0.
Next consider the case when x →0 and y →0 on the line y = x, so we are looking at the
special case when x = y. We have
f(x, x) =
2x2
x2 + x2 = 1 →1
as x →0.
Of course f is only continuous if it has the same limit however x →0 and y →0, and we
have now seen that it doesn’t; so f is not continuous at (0, 0).
Although we won’t go into it, the usual “putting together” theorems show that f is
continuous everywhere else.

8.2. PARTIAL DIFFERENTIATION
81
8.2
Partial Diﬀerentiation
The usual rules for diﬀerentiation apply when dealing with several variables, but we now
require to treat the variables one at a time, keeping the others constant. It is for this reason
that a new symbol for diﬀerentiation is introduced. Consider the function
f(x, y) =
2y
y + cos x
We can consider y ﬁxed, and so treat it as a constant, to get a partial derivative
∂f
∂x =
2y sin x
(2y + cos x)2
where we have diﬀerentiated with respect to x as usual. Or we can treat x as a constant,
and diﬀerentiate with respect to y, to get
∂f
∂y = (2y + cos x).2 −2y.2
(2y + cos x)2
=
2 cos x
(2y + cos x)2 .
Although a partial derivative is itself a function of several variables, we often want to
evaluate it at some ﬁxed point, such as (x0, y0). We thus often write the partial derivative
as
∂f
∂x(x0, y0).
There are a number of diﬀerent notations in use to try to help understanding in diﬀerent
situations. All of the following mean the same thing:-
∂f
∂x(x0, y0),
f1(x0, y0),
fx(x0, y0)
and
D1F(x0, y0).
Note also that there is a simple deﬁnition of the derivative in terms of a Newton quotient:-
∂f
∂x = lim
δx→0
f(x0 + δx, y0) −f(x0, y0)
δx
provided of course that the limit exists.
8.5. Example. Let z = sin(x/y). Compute x∂z
∂x + y ∂z
∂y.
Solution. Treating ﬁrst y and then x as constants, we have
∂z
∂x = 1
y cos
x
y

and
∂z
∂y = −x
y2 cos
x
y

.
thus
x∂z
∂x + y ∂z
∂y = x
y cos
x
y

−x
y cos
x
y

= 0.
Note: This equation is an equation satisﬁed by the function we started with, which
involves both the function, and its partial derivatives. We shall meet a number of examples
of such a partial diﬀerential equation later.

82 CHAPTER 8. DIFFERENTIATION OF FUNCTIONS OF SEVERAL VARIABLES
8.6. Exercise. Let z = log(x/y). Show that x∂z
∂x + y ∂z
∂y = 0. The fact that the last two
function satisfy the same diﬀerential equation is not a co-incidence. With our next result,
we can see that for any suitably diﬀerentiable function f, the function z(x, y) = f(x/y)
satisﬁes this partial diﬀerential equation.
8.7. Exercise. Let z = f(x/y), where f is suitably diﬀerentiable. Show that x∂z
∂x+y ∂z
∂y = 0.
Because the deﬁnitions are really just version of the 1-variable result, these examples
are quite typical; most of the usual rules for diﬀerentiation apply in the obvious way to
partial derivatives exactly as you would expect. But there are variants. Here is how we
diﬀerentiate compositions.
8.8. Theorem. Assume that f and all its partial derivatives fx and fy are continuous,
and that x = x(t) and y = y(t) are themselves diﬀerentiable functions of t. Let
F(t) = f(x(t), y(t)).
Then F is diﬀerentiable and
dF
dt = ∂f
∂x
dx
dt + ∂f
∂y
dy
dt .
Proof. Write x = x(t), x0 = x(t0) etc. Then we calculate the Newton quotient for F.
F(t) −F(t0)
=
f(x, y) −f(x0, y0)
=
f(x, y) −f(x0, y) + f(x0, y) −f(x0, y0)
=
∂f
∂x(ξ, y)(x −x0) + ∂f
∂y (x0, η)(y −y0)
Here we have used the Mean Value Theorem (5.18) to write
f(x, y) −f(x0, y) = ∂f
∂x(ξ, y)(x −x0)
for some point ξ between x and x0, and have argued similarly for the other part. Note that
ξ, pronounced “Xi” is the Greek letter “x”; in the same way η, pronounced “Eta” is the
Greek letter “y”. Thus
F(t) −F(t0)
t −t0
= ∂f
∂x(ξ, y)(x −x0)
t −t0
+ ∂f
∂y (x0, η)(y −y0)
t −t0
Now let t →t0, and note that in this case, x →x0 and y →y0; and since ξ and η are
trapped between x and x0, and y and y0 respectively, then also ξ →x0 and η →y0. The
result then follows from the continuity of the partial derivatives.
8.9. Example. Let f(x, y) = xy, and let x = cos t, y = sin t. Compute df
dt when t = π/2.
Solution. From the chain rule,
df
dt = ∂f
∂x
dx
dt + ∂f
∂y
dy
dt = −y(t) sin t + x(t) cos t = −1. sin(π/2) = −1.
The chain rule easily extends to the several variable case; only the notation is complic-
ated. We state a typical example

8.2. PARTIAL DIFFERENTIATION
83
8.10. Proposition. Let x = x(u, v), y = y(u, v) and z = z(u, v), and let f be a function
deﬁned on a subset U ∈
R3, and suppose that all the partial derivatives of f are continuous.
Write
F(u, v) = f(x(u, v), y(u, v), z(u, v)).
Then
∂F
∂u = ∂f
∂x
∂x
∂u + ∂f
∂y
∂y
∂u + ∂f
∂z
∂z
∂u
and
∂F
∂v == ∂f
∂x
∂x
∂v + ∂f
∂y
∂y
∂v + ∂f
∂z
∂z
∂v.
The introduction of the domain of f above, simply to show it was a function of three
variables is clumsy. We often do it more quickly by saying
Let f(x, y, z) have continuous partial derivatives
This has the advantage that you are reminded of the names of the variables on which f acts,
although strictly speaking, these names are not bound to the corresponding places. This is
an example where we adopt the notation which is very common in engineering maths. But
note the confusion if you ever want to talk about the value f(y, z, x), perhaps to deﬁne a
new function g(x, y, z).
8.11. Example. Assume that f(u, v, w) has continuous partial derivatives, and that
u = x −y,
v = y −z
w = z −x.
Let
F(x, y, z) = f(u(x, y, z), v(x, y, z), w(x, y, z)).
Show that
∂F
∂x + ∂F
∂y + ∂F
∂z = 0.
Solution. We apply the chain rule, noting ﬁrst that from the change of variable formulae,
we have
∂u
∂x
= 1,
∂u
∂y
= −1,
∂u
∂z
= 0,
∂v
∂x
= 0,
∂v
∂y
= 1,
∂v
∂z
= −1,
∂w
∂x
= −1,
∂w
∂y
= 0,
∂w
∂z
= 1.
Then
∂F
∂x
=
∂f
∂u.1 + ∂f
∂v .0 + ∂f
∂w. −1 = ∂f
∂u −∂f
∂w
∂F
∂y
=
∂f
∂u. −1 + ∂f
∂v .1 + ∂f
∂w.0 = −∂f
∂u + ∂f
∂v
∂F
∂z
=
∂f
∂u.0 + ∂f
∂v . −1 + ∂f
∂w.1 = −∂f
∂v + ∂f
∂w
Adding then gives the result claimed.

84 CHAPTER 8. DIFFERENTIATION OF FUNCTIONS OF SEVERAL VARIABLES
8.3
Higher Derivatives
Note that a partial derivative is itself a function of two variables, and so further partial
derivatives can be calculated. We write
∂
∂x
∂f
∂x = ∂2f
∂x2 ,
∂
∂x
∂f
∂y = ∂2f
∂x∂y,
∂
∂y
∂f
∂x = ∂2f
∂y∂x,
∂
∂y
∂f
∂y = ∂2f
∂y2 .
This notation generalises to more than two variables, and to more than two derivatives in
the way you would expect. There is a complication that does not occur when dealing with
functions of a single variable; there are four derivatives of second order, as follows:
∂2f
∂x2 ,
∂2f
∂x∂y ,
∂2f
∂y∂x
and
∂2f
∂y2 .
Fortunately, when f has mild restrictions, the order in which the diﬀerentiation is done
doesn’t matter.
8.12. Proposition. Assume that all second order derivatives of f exist and are continu-
ous. Then the mixed second order partial derivatives of f are equal. i.e.
∂2f
∂x∂y = ∂2f
∂y∂x.
8.13. Example. Suppose that f(x, y) is written in terms of u and v where x = u + log v
and y = u −log v. Show that, with the usual convention,
∂2f
∂u2 = ∂2f
∂x2 + 2 ∂2f
∂x∂y + ∂2f
∂y2
and
v2 ∂2f
∂v2 = ∂f
∂y −∂f
∂x + ∂2f
∂x2 + 2 ∂2f
∂x∂y + ∂2f
∂y2
You may assume that all second order derivatives of f exist and are continuous.
Solution. Using the chain rule, we have
∂f
∂u = ∂f
∂x
∂x
∂u + ∂f
∂y
∂y
∂u = ∂f
∂x + ∂f
∂y
and
∂f
∂v = ∂f
∂x
∂x
∂v + ∂f
∂y
∂y
∂v = 1
v
∂f
∂x −1
v
∂f
∂y .
Thus using both these and their operator form, we have
∂2f
∂u2
=
∂
∂u
∂f
∂x + ∂f
∂y

= ∂
∂x + ∂
∂y
∂f
∂x + ∂f
∂y

= ∂2f
∂x2 + ∂2f
∂x∂y + ∂2f
∂y∂x + ∂2f
∂y2 ,
while diﬀerentiating with respect to v, we have
∂2f
∂v2
=
∂
∂v
1
v
∂f
∂x −1
v
∂f
∂y

= −1
v2
∂f
∂x + 1
v
∂
∂v
∂f
∂x

+ 1
v2
∂f
∂y −1
v
∂
∂v
∂f
∂y

=
−1
v2
∂f
∂x + 1
v
1
v
∂2f
∂x2 −1
v
∂2f
∂y∂x

+ 1
v2
∂f
∂y −1
v
1
v
∂2f
∂x∂y −1
v
∂2f
∂y2

=
1
v2
∂f
∂y −∂f
∂x + ∂2f
∂x2 −2 ∂2f
∂x∂y + ∂2f
∂y2

.

8.4. SOLVING EQUATIONS BY SUBSTITUTION
85
8.4
Solving equations by Substitution
One of the main interests in partial diﬀerentiation is because it enables us to write down
how we expect the natural world to behave. We move away from 1-variable results as soon
as we have properties which depend on e.g. at least one space variable, together with time.
We illustrate with just one example, designed to whet the appetite for the whole subject
of mathematical physics.
Assume the displacement of a length of string at time t from its rest position is described
by the function f(x, t). This is illustrated in Fig 8.4. The laws of physics describe how the
string behaves when released in this position, and allowed to move under the elastic forces
of the string; the function f satisﬁes the wave equation
∂2f
∂t2 = c2 ∂2f
∂x2 .
f(x,t)
a
b
Figure 8.5: A string displaced from the equilibrium position
8.14. Example. Solve the equation
∂2F
∂u∂v = 0.
Solution.
Such a function is easy to integrate, because the two variables appear inde-
pendently. So ∂F
∂v = g1(v), where g1 is an arbitrary (diﬀerentiable) function. since when
diﬀerentiated with respect to u we are given that ∂2F
∂u∂v = 0. Thus we can integrate with
respect to v to get
F(u, v) =
Z
g1(v)dv + h(u) = g(v) + h(u),
where h is also an arbitrary (diﬀerentiable) function.
8.15. Example. Rewrite the wave equation using co-ordinates u = x −ct and v = x + ct.
Solution.
Write f(x, t) = F(u, v) and now in principle confuse F with f, so we can tell
them apart only by the names of their arguments. In practice we use diﬀerent symbols to
help the learning process; but note that in a practical case, all the F’s that appear below,
would normally be written as f’s By the chain rule
∂
∂x =
 ∂
∂u

.1 +
 ∂
∂v

.1
and
∂
∂t =
 ∂
∂u

.(−c) +
 ∂
∂v

.c.

86 CHAPTER 8. DIFFERENTIATION OF FUNCTIONS OF SEVERAL VARIABLES
diﬀerentiating again, and using the operator form of the chain rule as well,
∂2f
∂t2
=

c ∂
∂v −c ∂
∂u
 
c∂F
∂v −c∂F
∂u

=
c2 ∂2F
∂v2 −c2 ∂2F
∂u∂v −c2 ∂2F
∂v∂u + c2 ∂2F
∂u2
=
c2
∂2F
∂v2 + ∂2F
∂u2

−2c2 ∂2F
∂u∂v
and similarly
∂2f
∂x2
=
∂2F
∂v2 + ∂2F
∂u2

+ 2 ∂2F
∂u∂v .
Substituting in the wave equation, we thus get
4c2 ∂2F
∂u∂v = 0,
an equation which we have already solved. Thus solutions to the wave equation are of the
form f(u) + g(v) for any (suitably diﬀerentiable) functions f and g. For example we may
have sin(x −ct). Note that this is not just any function; it must be constant when x = ct.
8.16. Exercise. Let F(x, t) = log(2x + 2ct) for x > −ct, where c is a ﬁxed constant. Show
that
∂2F
∂t2 −c2 ∂2F
∂x2 = 0.
Note that this is simply checking a particular case of the result we have just proved.
8.5
Maxima and Minima
As in one variable calculations, one use for derivatives in several variables is in calculating
maxima and minima. Again as for one variable, we shall rely on the theorem that if f is
continuous on a closed bounded subset of
R2, then it has a global maximum and a global
minimum. And again as before, we note that these must occur either at a local maximum or
minimum, or else on the boundary of the region. Of course in
R, the boundary of the region
usually consisted of a pair of end points, while in
R2, the situation is more complicated.
However, the principle remains the same. And we can test for local maxima and minima
in the same way as for one variable.
8.17. Deﬁnition. Say that f(x, y) has a critical point at (a, b) if and only if
∂f
∂x(a, b) = ∂f
∂y (a, b) = 0.
It is clear by comparison with the single variable result, that a necessary condition that
f have a local extremum at (a, b) is that it have a critical point there, although that is not
a suﬃcient condition. We refer to this as the ﬁrst derivative test.

8.5. MAXIMA AND MINIMA
87
We can get more information by looking at the second derivative. Recall that we gave
a number of diﬀerent notations for partial derivatives, and in what follows we use fx rather
than the more cumbersome ∂f
∂x etc. This idea extends to higher derivatives; we shall use
fxx
instead of
∂2f
∂x2 ,
and
fxy
instead of
∂2f
∂x∂y
etc.
8.18. Theorem (Second Derivative Test). Assume that (a, b) is a critical point for f.
Then
• If, at (a, b), we have fxx < 0 and fxxfyy −f 2
xy > 0, then f has a local maximum at
(a, b).
• If, at (a, b), we have fxx > 0 and fxxfyy −f 2
xy > 0, then f has a local minimum at
(a, b).
• If, at (a, b), we have fxxfyy −f 2
xy < 0, then f has a saddle point at (a, b).
The test is inconclusive at (a, b) if fxxfyy −f 2
xy = 0, and the investigation has to be
continued some other way.
Note that the discriminant is easily remembered as
∆=

fxx
fxy
fyx
fyy
 = fxxfyy −f 2
xy
A number of very simple examples can help to remember this. After all, the result of the
test should work on things where we can do the calculation anyway!
8.19. Example. Show that f(x, y) = x2 + y2 has a minimum at (0, 0).
Of course we know it has a global minimum there, but here goes with the test:
Solution.
We have fx = 2x; fy = 2y, so fx = fy precisely when x = y = 0, and this is the
only critical point. We have fxx = fyy = 2; fxy = 0, so ∆= fxxfyy −f 2
xy = 4 > 0 and there
is a local minimum at (0, 0).
8.20. Exercise. Let f(x, y) = xy. Show there is a unique critical point, which is a saddle
point
Proof. We give an indication of how the theorem can be derived — or if necessary how it
can be remembered. We start with the two dimensional version of Taylor’s theorem, see
section 5.6. We have
f(a + h, b + k) ∼f(a, b) + h∂f
∂x(a, b) + k∂f
∂y (a, b) + 1
2

h2 ∂2f
∂x2 + 2kh ∂2f
∂x∂y + k2 ∂2f
∂y2

where we have actually taken an expansion to second order and assumed the corresponding
remainder is small.
We are looking at a critical point, so for any pair (h, k), we have h∂f
∂x(a, b)+k∂f
∂y (a, b) =
0 and everything hinges on the behaviour of the second order terms. It is thus enough to
study the behaviour of the quadratic Ah2 + 2Bhk + Ck2, where we have written
A = ∂2f
∂x2 ,
B = ∂2f
∂x∂y,
and
C = ∂2f
∂y2 .

88 CHAPTER 8. DIFFERENTIATION OF FUNCTIONS OF SEVERAL VARIABLES
Assuming that A ̸= 0 we can write
Ah2 + 2Bhk + Ck2 = A

h + Bk
A
2
+

C −B2
A

k2
= A

h + Bk
A
2
+
∆
A

k2
where we write ∆= CA −B2 for the discriminant. We have thus expressed the quadratic
as the sum of two squares. It is thus clear that
• if A < 0 and ∆> 0 we have a local maximum;
• if A > 0 and ∆> 0 we have a local minimum; and
• if ∆< 0 then the coeﬃcients of the two squared terms have opposite signs, so by
going out in two diﬀerent directions, the quadratic may be made either to increase or
to decrease.
Note also that we could have completed the square in the same way, but starting from the
k term, rather than the h term; so the result could just as easily be stated in terms of C
instead of A
8.21. Example. Let f(x, y) = 2x3 −6x2 −3y2 −6xy. Find and classify the critical points of
f. By considering f(x, 0), or otherwise, show that f does not achieve a global maximum.
Solution. We have fx = 6x2 −12x−6y and fy = −6y−6x. Thus critical points occur when
y = −x and x2 −x = 0, and so at (0, 0) and (1, −1). Diﬀerentiating again, fxx = 12x −12,
fyy = −6 and fxy = −6. Thus the discriminant is ∆= −6.(12x −12) −36. When x = 0,
∆= 36 > 0 and since fxx = −12, we have a local maximum at (0, 0).
When x = 1,
∆= −36 < 0, so there is a saddle at (1, −1).
To see there is no global maximum, note that f(x, 0) = 2x3(1 −3/x) →∞as x →∞,
since x3 →∞as x →∞.
8.22. Exercise. Find the extrema of f(x, y) = xy −x2 −y2 −2x −2y + 4.
8.23. Example. An open-topped rectangular tank is to be constructed so that the sum of
the height and the perimeter of the base is 30 metres. Find the dimensions which maximise
the surface area of the tank. What is the maximum value of the surface area? [You may
assume that the maximum exists, and that the corresponding dimensions of the tank are
strictly positive.]
Solution. Let the dimensions of the box be as shown.
Let the area of the surface of the material be S. Then
S = 2xh + 2yh + xy,
and since, from our restriction on the base and height,
30 = 2(x + y) + h,
we have
h = 30 −2(x + y).
Substituting, we have
S = 2(x + y)

30 −2(x + y)

+ xy = 60(x + y) −4(x + y)2 + xy,

8.5. MAXIMA AND MINIMA
89
x
y
h
Figure 8.6: A dimensioned box
and for physical reasons, S is deﬁned for x ≥0, y ≥0 and x + y ≤15.
A global maximum (which we are given exists) can only occur on the boundary of the
domain of deﬁnition of S, or at a critical point, when ∂S
∂x = ∂S
∂y = 0. On the boundary of
the domain of deﬁnition of S, we have x = 0 or y = 0 or x + y = 15, in which case h = 0.
We are given that we may ignore these cases. Now
S
=
−4x2 −4y2 −7xy + 60x + 60y,
so
∂S
∂x
=
−8x −7y + 60 = 0,
∂S
∂y
=
−8y −7x + 60 = 0.
Subtracting gives x = y and so 15x = 60, or x = y = 4. Thus h = 14 and the surface area
is S = 16(−4 −4 −7 + 15 + 15) = 240 square metres. Since we are given that a maximum
exists, this must be it. [If both sides of the surface are counted, the area is doubled, but
the critical proportions are still the same.]
Sometimes a function necessarily has an absolute maximum and absolute minimum —
in the following case because we have a continuous function deﬁned on a closed bounded
subset of
R2, and so the analogue of 4.35 holds. In this case exactly as in the one variable
case, we need only search the boundary (using ad - hoc methods, which in fact reduce to
1-variable methods) and the critical points in the interior, using our ability to ﬁnd local
maxima.
8.24. Example. Find the absolute maximum and minimum values of
f(x, y) = 2 + 2x + 2y −x2 −y2
on the triangular plate in the ﬁrst quadrant bounded by the lines x = 0, y = 0 and y = 9−x
Solution.
We know there is a global maximum, because the function is continuous on a
closed bounded subset of
R2. Thus the absolute max will occur either in the interior, at
a critical point, or on the boundary. If y = 0, investigate f(x, 0) = 2 + 2x −x2, while if
x = 0, investigate f(0, y) = 2 + 2y −y2. If y = 9 −x, investigate
f(x, 9 −x) = 2 + 2x + 2(9 −x) −x2 −(9 −x)2

90 CHAPTER 8. DIFFERENTIATION OF FUNCTIONS OF SEVERAL VARIABLES
for an absolute maximum. In fact extreme may occur when (x, y) = (0, 1) or (1, 0) or (0, 0)
or (9, 0) or (0, 9), or (9/2, 9/2). At these points, f takes the values −41/2, 2, 3, −61.
Next we seek critical points in the interior of the plate,
fx = 2 −2x = 0
and
fy = 2 −2y = 0.
so (x, y) = (1, 1) and f(1, 1) = 4, so this must be the global maximum. Can check also
using the second derivative test, that it is a local maximum.
8.6
Tangent Planes
Consider the surface F(x, y, z) = c, perhaps as z = f(x, y), and suppose that f and F have
continuous partial derivatives. Suppose now we have a smooth curve on the surface, say
φ(t) = (x(t), y(t), z(t)). Then since the curve lies in the surface, we have
F(x(t), y(t), z(t)) = c,
and so, applying the chain rule, we have
dF
dt = ∂F
∂x
dx
dt + ∂F
∂y
dy
dt + ∂F
∂z
dz
dt = 0.
or, writing this in terms of vectors, we have
∇F.v(t) =
∂F
∂x , ∂F
∂z , ∂F
∂z

.
dx
dt , dy
dt , dz
dt

= 0.
Since the RH vector is the velocity of a point on the curve, which lies on the surface, we
see that the left hand vector must be the normal to the curve.
Note that we have deﬁned the gradient vector ∇F associated with the function F by
∇F =
∂F
∂x , ∂F
∂z , ∂F
∂z

.
8.25. Theorem. The tangent to the surface F(x, y, z) = c at the point (x0, y0, z0) is given
by
∂F
∂x (x −x0) + ∂F
∂y (y −y0) + ∂F
∂z (z −z0) = 0.
Proof. This is a simple example of the use of vector geometry. Given that (x0, y0, z0) lies
on the surface, and so in the tangent, then for any other point (x, y, z) in the tangent plane,
the vector (x−x0, y−y0, z−z0) must lie in the tangent plane, and so must be normal to the
normal to the curve (i.e. to ∇F). Thus (x −x0, y −y0, z −z0) and ∇F are perpendicular,
and that requirement is the equation which gives the tangent plane.
8.26. Example. Find the equation of the tangent plane to the surface
F(x, y, z) = x2 + y2 + z −9 = 0
at the point P = (1, 2, 4).

8.7. LINEARISATION AND DIFFERENTIALS
91
Solution. We have ∇F|(1,2,4) = (2, 4, 1), and the equation of the tangent plane is
2(x −1) + 4(y −2) + (z −4) = 0.
8.27. Exercise. Show that the tangent plane to the surface z = 3xy −x3 −y3 is horizontal
only at (0, 0, 0) and (1, 1, 1).
8.7
Linearisation and Diﬀerentials
We obtained a geometrical view of the function f(x, y) by considering the surface z =
f(x, y), or F(x, y, z) = z −f(x, y) = 0. Note that the tangent plane to this surface at the
point (x0, yo, f(x0, y0)) lies close to the surface itself. Just as in one variable, we used the
tangent line to approximate the graph of a function, so we shall use the tangent plane to
approximate the surface deﬁned by a function of two variables.
The equation of our tangent plane is
∂F
∂x (x −x0) + ∂F
∂y (y −y0) + ∂F
∂z (z −f(x0, y0)) = 0,
and writing the derivatives in terms of f, we have
∂f
∂x(x0, y0)(x −x0) + ∂f
∂y (x0, y0)(y −y0) + (−1)(z −f(x0, y0)) = 0,
or, writing in terms of z, the height of the tangent plane above the ground plane,
z = f(x0, y0) + ∂f
∂x(x0, y0)(x −x0) + ∂f
∂y (x0, y0)(y −y0).
Our assumption that the tangent plane lies close to the surface is that z ≈f(x, y), or that
f(x, y) ≈f(x0, y0) + ∂f
∂x(x0, y0)(x −x0) + ∂f
∂y (x0, y0)(y −y0).
We call the right hand side the linear approximation to f at (x0, y0).
We can rewrite this with h = x −x0 and k = y −y0, to get
f(x, y) −f(x0, y0) ≈h∂f
∂x(x0, y0) + k∂f
∂y (x0, y0),
or
df ≈h ∂f
∂x

(x0,y0)
+ k ∂f
∂y

(x0,y0)
This has applications; we can use it to see how a function changes when its independent
variables are subjected to small changes.
8.28. Example. A cylindrical oil tank is 25 m high and has a radius of 5 m. How sensitive
is the volume of the tank to small variations in the radius and height.
Solution.
Let V be the volume of the cylindrical tank of height h and radius r. Then
V = πr2H, and so
dV
=
∂V
∂r

(r0,h0)
dr + ∂V
∂h

(r0,h0)
dh,
=
250πdr + 25πdh.
Thus the volume is 10 times as sensitive to errors in measuring r as it is to measuring h.
Try this with a short fat tank!

92 CHAPTER 8. DIFFERENTIATION OF FUNCTIONS OF SEVERAL VARIABLES
8.29. Example. A cone is measured. The radius has a measurement error of 3%, and the
height an error of 2%. What is the error in measuring the volume?
Solution.
The volume V of a cone is given by V = πr2h/3, where r is the radius of the
cone, and h is the height. Thus
dV
=
2
3πrh dr + 1
3πr2 dh
=
2.(0.03).πr2h
3
+ πr2h
3
.(0.02) = V (0.06 + 0.02)
Thus there is an 8% error in measuring the volume.
8.30. Exercise. The volume of a cylindrical oil tank is to be calculated from measured
values of r and h. What is the percentage error in the volume, if r is measured with an
accuracy of 2%, and h measured with an accuracy of 0.5%.
8.8
Implicit Functions of Three Variables
Finally in this section we discuss another application of the chain rule. Assume we have
variables x, y and z, related by the equation F(x, y, z) = 0. Then assuming that Fz ̸= 0,
there is a version of the implicit function theorem which means we can in principle, write
z = z(x, y), so we can “solve for z”. Doing this gives
F(x, y, z(x, y)) = 0.
Now diﬀerentiate both sides partially with respect to x. We get
0 = ∂
∂xF(x, y, z(x, y)) = ∂F
∂x
∂x
∂x + ∂F
∂y
∂y
∂x + ∂F
∂z
∂z
∂x,
and so since ∂y
∂x ̸= 0,
0 = ∂F
∂x + ∂F
∂z
∂z
∂x
and
∂z
∂x = −
∂F
∂x
∂F
∂z
Now assume in the same way that Fx ̸= 0 and Fy ̸= 0, so we can get two more relations
like this, with x = x(y, z) and y = y(z, x). Then form three such equations,
∂z
∂x.∂x
∂y .∂y
∂z = −



∂F
∂x
∂F
∂z







∂F
∂y
∂F
∂x








∂F
∂z
∂F
∂y



= −1!
We met this result as Equation 1.1 in Chapter 1, when it seemed totally counter-intuitive!

Chapter 9
Multiple Integrals
9.1
Integrating functions of several variables
Recall that we think of the integral in two diﬀerent ways. In one way we interpret it as the
area under the graph y = f(x), while the fundamental theorem of the calculus enables us
to compute this using the process of “anti-diﬀerentiation” — undoing the diﬀerentiation
process.
We think of the area as
X
f(xi) dxi =
Z
f(x) dx,
where the ﬁrst sum is thought of as a limiting case, adding up the areas of a number of
rectangles each of height f(xi), and width dxi. This leads to the natural generalisation to
several variables: we think of the function z = f(x, y) as representing the height of f at the
point (x, y) in the plane, and interpret the integral as the sum of the volumes of a number
of small boxes of height z = f(x, y) and area dxidyj. Thus the volume of the solid of height
z = f(x, y) lying above a certain region R in the plane leads to integrals of the form
Z Z
R
=
n
X
i=1
m
X
j=1
f(xi, yj)dxidyj = lim Smn.
We write such a double integral as
Z Z
R
f(x, y) dA.
9.2
Repeated Integrals and Fubini’s Theorem
As might be expected from the form, in which we can sum over the elementary rectangles
dx dy in any order, the order does not matter when calculating the answer. There are two
important orders — where we ﬁrst keep x constant and vary y, and then vary x; and the
opposite way round. This gives rise to the concept of the repeated integral, which we write
as
Z Z
R
f(x, y) dx

dy
or
Z Z
R
f(x, y) dy

dx.
93

94
CHAPTER 9. MULTIPLE INTEGRALS
Our result that the order in which we add up the volume of the small boxes doesn’t matter
is the following, which also formally shows that we evaluate a double integral as any of the
possible repeated integrals.
9.1. Theorem (Fubini’s theorem for Rectangles). Let f(x, y) be continuous on the
rectangular region R : a ≤x ≤b; c ≤y ≤d. Then
Z Z
R
f(x, y) dA =
Z d
c
Z b
a
f(x, y) dx

dy =
Z b
a
Z d
c
f(x, y) dy

dx
Note that this is something like an inverse of partial diﬀerentiation.
In doing the
ﬁrst inner (or repeated) integral, we keep y constant, and integrate with respect to x.
Then we integrate with respect to y. Of course if f is a particularly simply function, say
f(x, y) = g(x)h(y), then it doesn’t matter which order we do the integration, since
Z Z
R
f(x, y) dA =
Z b
a
g(x) dx
Z d
c
h(y) dy.
We use the Fubini theorem to actually evaluate integrals, since we have no direct way
of calculating a double (as opposed to a repeated) integral.
9.2. Example. Integrate z = 4 −x −y over the region 0 ≤x ≤2 and 0 ≤y ≤1. Hence
calculate the volume under the plane z = 4 −x −y above the given region.
Solution. We calculate the integral as a repeated integral, using Fubini’s theorem.
V =
Z 2
x=0
Z 1
y=0
(4 −x −y) dy dx =
Z 2
x=0

(4y −xy −y2/2)
1
0 dx =
Z 2
x=0
(4 −x −1/2) dx etc.
From our interpretation of the integral as a volume, we recognise V as volume under the
plane z = 4 −x −y which lies above {(x, y) | 0 ≤x ≤2; 0 ≤y ≤1}.
9.3. Exercise. Evaluate
Z 3
0
Z 2
0
(4 −y2) dy dx, and sketch the region of integration.
In fact Fubini’s theorem is valid for more general regions than rectangles. Here is a pair
of statements which extend its validity.
9.4. Theorem (Fubini’s theorem — Stronger Form). Let f(x, y) be continuous on
a region R
• if R is deﬁned as a ≤x ≤b; g1(x) ≤y ≤g2(x). Then
Z Z
R
f(x, y) dA =
Z b
a
 Z g2(x)
g1(x)
f(x, y) dy
!
dx
• if R is deﬁned as c ≤y ≤d; h1(y) ≤x ≤h2(y). Then
Z Z
R
f(x, y) dA =
Z d
c
 Z h2(y)
h1(y)
f(x, y) dx
!
dy

9.2. REPEATED INTEGRALS AND FUBINI’S THEOREM
95
1
2
2
1
x
y
Figure 9.1: Area of integration.
Proof. We give no proof, but the reduction to the earlier case is in principle simple; we just
extend the function to be deﬁned on a rectangle by making it zero on the extra bits. The
problem with this as it stands is that the extended function is not continuous. However,
the diﬃculty can be ﬁxed.
This last form enables us to evaluate double integrals over more complicated regions by
passing to one of the repeated integrals.
9.5. Example. Evaluate the integral
Z 2
1
Z 2
x
y2
x2 dy

dx
as it stands, and sketch the region of integration.
Reverse the order of integration, and verify that the same answer is obtained.
Solution. The diagram in Fig.9.1 shows the area of integration.
We ﬁrst integrate in the given order.
Z 2
1
Z 2
x
y2
x2 dy

dx
=
Z 2
1
 y3
3x2
2
x
dx =
Z 2
1
 8
3x2 −x
3

dx
=

−8
3x −x2
6
2
1
=

−4
3 −2
3

−

−8
3 −1
6

= 5
6.
Reversing the order, using the diagram, gives
Z 2
1
Z y
1
y2
x2 dx

dy
=
Z 2
1

−y2
x
y
1
dy =
Z 2
1
 −y + y2
dy
=

−y2
2 −y3
3
2
1
=

−2 + 8
3

−

−1
2 + 1
3

= 5
6.
Thus the two orders of integration give the same answer.
Another use for the ideas of double integration just automates a procedure you would
have used anyway, simply from your knowledge of 1-variable results.

96
CHAPTER 9. MULTIPLE INTEGRALS
1
1
x
y
Figure 9.2: Area of integration.
9.6. Example. Find the area of the region bounded by the curve x2 + y2 = 1, and above
the line x + y = 1.
Solution.
We recognise an area as numerically equal to the volume of a solid of height 1,
so if R is the region described, the area is
Z Z
R
1 dx dy =
Z 1
0
 Z y=
√
1−x2
y=1−x
dy
!
dx =
Z 1
0
p
1 −x2 −(1 −x) dx = . . . .
And we also ﬁnd that Fubini provides a method for actually calculating integrals; some-
times one way of doing a repeated integral is much easier than the other.
9.7. Example. Sketch the region of integration for
Z 1
0
Z 1
y
x2 exy dx

dy.
Evaluate the integral by reversing the order of integration.
Solution. The diagram in Fig.9.2 shows the area of integration.
Interchanging the given order of integration, we have
Z 1
0
Z 1
y
x2 exy dx

dy =
Z 1
0
Z x
0
x2 exy dy

dx
=
Z 1
0
x2 exy
x
x
0
dx
=
Z 1
0
x ex2 dx −
Z 1
0
x dx
=
1
2 ex2 −x2
2
1
0
= 1
2 (e −2) .
9.8. Exercise. Evaluate the integral
ZZ
R
(√x −y2) dy dx,
where R is the region bounded by the curves y = x2 and x = y4.

9.3. CHANGE OF VARIABLE — THE JACOBIAN
97
9.3
Change of Variable — the Jacobian
Another technique that can sometimes be useful when trying to evaluate a double (or triple
etc) integral generalise the familiar method of integration by substitution.
Assume we have a change of variable x = x(u, v) and y = y(u, v). Suppose that the
region S′ in the uv - plane is transformed to a region S in the xy - plane under this
transformation. Deﬁne the Jacobian of the transformation as
J(u, v) =

∂x
∂u
∂x
∂v
∂y
∂u
∂y
∂v

= ∂(x, y)
∂(u, v).
It turns out that this correctly describes the relationship between the element of area dx dy
and the corresponding area element du dv.
With this deﬁnition, the change of variable formula becomes:
Z Z
S
f(x, y) dx dy =
Z Z ′
S
f(x(u, v), y(u, v)) |J(u, v)| du dv.
Note that the formula involves the modulus of the Jacobian.
9.9. Example. Find the area of a circle of radius R.
Solution. Let A be the disc centred at 0 and radius R. The area of A is thus
Z Z
A
dx dy. We
evaluate the integral by changing to polar coordinates, so consider the usual transformation
x = r cos θ, y = r sin θ between Cartesian and polar co-ordinates. We ﬁrst compute the
Jacobian;
∂x
∂r = cos θ,
∂y
∂r = sin θ,
∂x
∂θ = −r sin θ,
∂y
∂θ = r cos θ.
Thus
J(r, θ) =

∂x
∂r
∂x
∂θ
∂y
∂r
∂y
∂θ

=

cos θ
−r sin θ
sin θ
r cos θ
 = r(cos2 θ + sin2 θ) = r.
We often write this result as
dA = dx dy = r dr dθ
Using the change of variable formula, we have
Z Z
A
dx dy =
Z Z
A
|J(r, θ)| dr dθ =
Z R
0
Z 2π
0
r dr dθ = 2πR2
2 .
We thus recover the usual area of a circle.
Note that the Jacobian J(r, θ) = r > 0, so we did indeed take the modulus of the
Jacobian above.
9.10. Example. Find the volume of a ball of radius 1.

98
CHAPTER 9. MULTIPLE INTEGRALS
Solution.
Let V be the required volume. The ball is the set {(x, y, z) | x2 + y2 + z2 ≤1}.
It can be thought of as twice the volume enclosed by a hemisphere of radius 1 in the upper
half plane, and so
V = 2
Z
D
p
1 −x2 −y2 dx dy
where the region of integration D consists of the unit disc {(x, y) | x2 + y2 ≤1}. Although
we can try to do this integration directly, the natural co-ordinates to use are plane polars,
and so we instead do a change of variable ﬁrst. As in 9.9, if we write x = r cos θ, y = r sin θ,
we have dx dy = r dr dθ. Thus
V = 2
Z
D
p
1 −x2 −y2 dx dy
=
2
Z
D
(
p
1 −r2) r dr dθ
=
2
Z 2π
0
dθ
Z 1
0
p
1 −r2 dr
=
4π
"
−(1 −r2)3/2
3
#1
0
=
4π
3 .
Note that after the change of variables, the integrand is a product, so we are able to do the
dr and dθ parts of the integral at the same time.
And ﬁnally, we show that the same ideas work in 3 dimensions. There are (at least) two
co-ordinate systems in
R3 which are useful when cylindrical or spherical symmetry arises.
One of these, cylindrical polars is given by the transformation
x = r cos θ,
y = r sin θ,
z = z,
and the Jacobian is easily calculated as
∂(x, y, z)
∂(r, θ, z) = r
so
dV = dx dy dz = r dr dθ dz.
The second useful co-ordinate system is spherical polars with transformation
x = r sin φ cos θ,
y = r sin φ sin θ,
z = r cos φ.
The transformation is illustrated in Fig 9.3.
It is easy to check that Jacobian of this transformation is given by
dV = r2 sin φ dr dφ dθ = dx dy dz.
9.11. Example. The moment of inertia of a solid occupying the region R, when rotated
about the z - axis is given by the formula
I =
Z Z Z
R
(x2 + y2)ρ dV.
Calculate the moment of inertia about the z-axis of the solid of unit density which lies
outside the cylinder of radius a, inside the sphere of radius 2a, and above the x −y plane.

9.3. CHANGE OF VARIABLE — THE JACOBIAN
99
r
x
z
y
θ
ϕ
Figure 9.3: The transformation from Cartesian to spherical polar co-ordinates.
z
x
a
r
2a
Figure 9.4: Cross section of the right hand half of the solid outside a cylinder of radius a
and inside the sphere of radius 2a
Solution.
Let I be the moment of inertia of the given solid about the z-axis. A diagram
of a cross section of the solid is shown in Fig 9.4.
We use cylindrical polar co-ordinates (r, θ, z); the Jacobian gives dx dy dz = r dr dθ dz,
so
I
=
Z 2π
0
dθ
Z 2a
a
r dr
Z √
4a2−r2
0
r2 dz
=
2π
Z 2a
a
r3p
4a2 −r2 dr.
We thus have a single integral. Using the substitution u = 4a2 −r2, you can check that the
integral evaluates to 22
√
3πa5/5.
9.12. Exercise. Show that
Z Z Z
z2 dxdydz = 4
15π
(where the integral is over the unit ball x2 + y2 + z2 ≤1) ﬁrst by using spherical polars,
and then by doing the z integration ﬁrst and using plane polars.

100
CHAPTER 9. MULTIPLE INTEGRALS

Bibliography
Spivak, M. (1967), Calculus, W. A. Benjamin.
Index Entries
absolute value, 7
absolutely convergent, 61
alternating series test, 62
arithmetic - geometric mean
inequality, 5
arithmetic progression, 55
Binomial Theorem, 8
bounded above, 22
bounded below, 22
closed interval, 5
Comparison Test, 59
completeness of
R, 3
completing the square, 9
conditionally convergent, 61
continuity, 30, 31
continuous, 29, 32, 80
convergent series, 56
critical point, 86
cylindrical polars, 98
divergent series, 56
domain, 5
double integral, 93
Fibonacci sequence, 26
ﬁrst derivative test, 86
from above, 35
Fubini’s Theorem, 93
function, 5
geometric
progression
(or
series), 55
gradient, 90
half - open, 5
implicit functions, 92
increasing, 22
inequalities, 4
integers, 2
integral test, 60
Intermediate
Value
The-
orem, 38
interval of convergence, 68
intervals, 5
Jacobian, 97
l’Hˆopital’s
rule:
general
form, 47
l’Hˆopital’s rule: inﬁnite lim-
its, 48
l’Hˆopital’s rule: simple form,
43
Leibniz Theorem, 62
limit from the left, 34
linear approximation, 91
local maximum, 87
local minimum, 87
Maclaurin’s Theorem, 50
Mean Value Theorem, 45
modulus, 7
Monotone Convergence Prin-
ciple, 23
natural numbers, 2
neighbourhood, 6
Newton quotient, 41
numbers, 2
open, 29
open interval, 5
ordering of
R, 3
partial diﬀerential equation,
81
positive integers, 2
power series, 67
properties of
R, 2
radius of convergence, 68
range, 5
Ratio Test, 60
rational numbers, 2
real numbers, 2
real power series, 67
repeated integral, 94
Rolle’s Theorem, 44
saddle point, 87
second derivative test, 87
Second
Mean
Value
The-
orem, 50
series, 55
singularity, 6
101

102
BIBLIOGRAPHY
spherical polars, 98
sum of the series, 56
surface, 78
tangent planes, 90
target space, 5
Taylor series, 51
Taylor’s Theorem, 49, 50
teacher
redundant, iii
tends to, 31
Triangle Inequlaity, 7
trichotomy, 3
upper bound, 22

