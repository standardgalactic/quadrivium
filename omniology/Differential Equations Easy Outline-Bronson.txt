
SCHAUM’S Easy OUTLINES
DIFFERENTIAL
EQUATIONS

Other Books in Schaum’s
Easy Outlines Series Include:
Schaum’s Easy Outline: Calculus
Schaum’s Easy Outline: College Algebra
Schaum’s Easy Outline: College Mathematics
Schaum’s Easy Outline: Discrete Mathematics
Schaum’s Easy Outline: Elementary Algebra
Schaum’s Easy Outline: Geometry
Schaum’s Easy Outline: Linear Algebra
Schaum’s Easy Outline: Mathematical Handbook 
of Formulas and Tables
Schaum’s Easy Outline: Precalculus
Schaum’s Easy Outline: Probability and Statistics
Schaum’s Easy Outline: Statistics
Schaum’s Easy Outline: Trigonometry
Schaum’s Easy Outline: Business Statistics
Schaum’s Easy Outline: Principles of Accounting
Schaum’s Easy Outline: Principles of Economics
Schaum’s Easy Outline: Biology
Schaum’s Easy Outline: Biochemistry
Schaum’s Easy Outline: Molecular and Cell Biology
Schaum’s Easy Outline: College Chemistry
Schaum’s Easy Outline: Genetics
Schaum’s Easy Outline: Human Anatomy 
and Physiology
Schaum’s Easy Outline: Organic Chemistry
Schaum’s Easy Outline: Physics
Schaum’s Easy Outline: Applied Physics
Schaum’s Easy Outline: Programming with C++
Schaum’s Easy Outline: Programming with Java
Schaum’s Easy Outline: Basic Electricity
Schaum’s Easy Outline: Electromagnetics
Schaum’s Easy Outline: Introduction to Psychology
Schaum’s Easy Outline: French
Schaum’s Easy Outline: German  
Schaum’s Easy Outline: Spanish
Schaum’s Easy Outline: Writing and Grammar

SCHAUM’S Easy OUTLINES
DIFFERENTIAL
EQUATIONS
Ba s e d  o n  S c h a u m ’ s
Outline of Theory and Problems of 
Differential Equations, Second Edition
b y  R i c h a r d  B r o n s o n,  Ph.D.
A b r i d g e m e n t  E d i t o r
E r i n  J .  B r e d e n s t e i n e r ,  Ph.D.
SCHAUM’S OUTLINE SERIES
M c G R AW- H I L L
New York
Chicago
San Francisco
Lisbon
London
Madrid
Mexico City
Milan
New Delhi
San Juan
Seoul
Singapore
Sydney
Toronto

Copyright © 2003 by The McGraw-Hill Companies, Inc. All rights reserved. Manufactured in the United States of
America. Except as permitted under the United States Copyright Act of 1976, no part of this publication may be repro-
duced or distributed in any form or by any means, or stored in a database or retrieval system, without the prior writ-
ten permission of the publisher. 
0-07-142846-1
The material in this eBook also appears in the print version of this title: 0-07-140967-X 
All trademarks are trademarks of their respective owners. Rather than put a trademark symbol after every occur-
rence of a trademarked name, we use names in an editorial fashion only, and to the benefit of the trademark owner,
with no intention of infringement of the trademark. Where such designations appear in this book, they have been
printed with initial caps. 
McGraw-Hill eBooks are available at special quantity discounts to use as premiums and sales promotions, or for
use in corporate training programs. For more information, please contact George Hoare, Special Sales, at
george_hoare@mcgraw-hill.com or (212) 904-4069. 
TERMS OF USE
This is a copyrighted work and The McGraw-Hill Companies, Inc. (“McGraw-Hill”) and its licensors reserve all
rights in and to the work. Use of this work is subject to these terms. Except as permitted under the Copyright Act
of 1976 and the right to store and retrieve one copy of the work, you may not decompile, disassemble, reverse engi-
neer, reproduce, modify, create derivative works based upon, transmit, distribute, disseminate, sell, publish or sub-
license the work or any part of it without McGraw-Hill’s prior consent. You may use the work for your own non-
commercial and personal use; any other use of the work is strictly prohibited. Your right to use the work may be
terminated if you fail to comply with these terms. 
THE WORK IS PROVIDED “AS IS”. McGRAW-HILL AND ITS LICENSORS MAKE NO GUARANTEES OR
WARRANTIES AS TO THE ACCURACY, ADEQUACY OR COMPLETENESS OF OR RESULTS TO BE
OBTAINED FROM USING THE WORK, INCLUDING ANY INFORMATION THAT CAN BE ACCESSED
THROUGH THE WORK VIA HYPERLINK OR OTHERWISE, AND EXPRESSLY DISCLAIM ANY WAR-
RANTY, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO IMPLIED WARRANTIES OF MER-
CHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. McGraw-Hill and its licensors do not warrant
or guarantee that the functions contained in the work will meet your requirements or that its operation will be unin-
terrupted or error free. Neither McGraw-Hill nor its licensors shall be liable to you or anyone else for any inaccu-
racy, error or omission, regardless of cause, in the work or for any damages resulting therefrom. McGraw-Hill has
no responsibility for the content of any information accessed through the work. Under no circumstances shall
McGraw-Hill and/or its licensors be liable for any indirect, incidental, special, punitive, consequential or similar
damages that result from the use of or inability to use the work, even if any of them has been advised of the possi-
bility of such damages. This limitation of liability shall apply to any claim or cause whatsoever whether such claim
or cause arises in contract, tort or otherwise.
DOI: 10.1036/0071428461

Contents
v
Chapter 1 
Basic Concepts and Classifying
Differential Equations
1
Chapter 2
Solutions of First-Order 
Differential Equations
8
Chapter 3
Applications of First-Order 
Differential Equations
20
Chapter 4
Linear Differential Equations: 
Theory of Solutions
29
Chapter 5 
Solutions of Linear Homogeneous
Differential Equations with 
Constant Coefﬁcients
33
Chapter 6
Solutions of Linear 
Nonhomogeneous Equations 
and Initial-Value Problems
39
Chapter 7
Applications of Second-Order 
Linear Differential Equations
47
Chapter 8
Laplace Transforms and Inverse
Laplace Transforms
55
Chapter 9
Solutions by Laplace Transforms
65
Chapter 10
Matrices and the Matrix 
Exponential
69
Chapter 11
Solutions of Linear Differential
Equations with Constant 
Coefﬁcients by Matrix Methods
78
For more information about this title, click here.
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Chapter 12
Power Series Solutions
85
Chapter 13
Gamma and Bessel Functions
98
Chapter 14
Numerical Methods
104
Chapter 15
Boundary-Value Problems 
and Fourier Series
115
Appendix
Laplace Transforms
124
Index
133
vi DIFFERENTIAL EQUATIONS

Chapter 1
Basic Concepts
and Classifying
Differential
Equations
In This Chapter:
✔
Differential Equations
✔
Notation
✔
Solutions
✔
Initial-Value and Boundary-Value
Problems
✔
Standard and Differential Forms
✔
Linear Equations
✔
Bernoulli Equations
✔
Homogeneous Equations
✔
Separable Equations
✔
Exact Equations
1
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Differential Equations
Adifferential equation is an equation involving an unknown function and
its derivatives.
Example 1.1: The following are differential equations involving the un-
known function y.
(1.1)
(1.2)
(1.3)
(1.4)
(1.5)
Adifferential equation is an ordinary differential equation if the unknown
function depends on only one independent variable. If the unknown func-
tion depends on two or more independent variables, the differential equa-
tion is a partial differential equation. In this book we will be concerned
solely with ordinary differential equations.
Example 1.2: Equations 1.1 through 1.4 are examples of ordinary differ-
ential equations, since the unknown function y depends solely on the vari-
able x. Equation 1.5 is a partial differential equation, since y depends on
both the independent variables t and x.
∂
∂
−
∂
∂
=
2
2
2
2
4
0
y
t
y
x
d y
dx
y dy
dx
y
dy
dx
x
2
2
3
7
3
2
3
5



+



+




=
4
5
0
3
3
2
2
d y
dx
x d y
dx
xy
+
+
=
(sin )
e d y
dx
dy
dx
y
2
2
2
2
1
+ 



=
dy
dx
x
=
+
5
3
2 DIFFERENTIAL EQUATIONS

Note!
The order of a differential equation is the order of
the highest derivative appearing in the equation.
Example 1.3: Equation 1.1 is a ﬁrst-order differential equation; 1.2, 1.4,
and 1.5 are second-order differential equations. (Note in 1.4 that the or-
der of the highest derivative appearing in the equation is two.) Equation
1.3 is a third-order differential equation.
Notation
The expressions 
are often used to represent, re-
spectively, the ﬁrst, second, third, fourth, . . ., nth derivatives of y with re-
spect to the independent variable under consideration. Thus, 
repre-
sents 
if the independent variable is x, but represents 
if the independent variable is p. Observe that parenthesis are used in y(n)
to distinguish it from the nth power, yn. If the independent variable is
time, usually denoted by t, primes are often replaced by dots. Thus,
represent, 
respectively.
Solutions
A solution of a differential equation in the unknown function y and the
independent variable x on the interval  is a function y(x) that satisﬁes
the differential equation identically for all x in .
Example 1.4: Is 
, where c1 and c2 are arbi-
trary constants, a solution of
?
Differentiating y, we ﬁnd y = 2c1cos2x −2c2 sin2x and y =
. Hence,
−
−
c
x
c
x
4
2
4
2
1
2
sin
cos
′′ +
=
y
y
4
0
y x
c
x
c
x
( )
sin
cos
=
+
1
2
2
2
dy dt d y dt
d y dt
/
,
/
,
/
,
2
2
3
3
and
˙, ˙˙,
˙˙˙
y y
y
and
d y dp
2
2
/
d y dx
2
2
/
′′
y
′
′′
′′′
y y
y
y
y n
,
,
,
,...,
( )
( )
4
CHAPTER 1: Basic Concepts and Classiﬁcation 3

Thus, 
satisﬁes the differential equation for all
values of x and is a solution on the interval 
.
Example 1.5: Determine whether 
is a solution of 
.
Note that the left side of the differential equation must be nonnegative for
every real function y(x) and any x, since it is the sum of terms raised to
the second and fourth powers, while the right side of the equation is neg-
ative. Since no function y(x) will satisfy this equation, the given differ-
ential equation has no solutions.
We see that some differential equations have inﬁnitely many solu-
tions (Example 1.4), whereas other differential equations have no solu-
tions (Example 1.5). It is also possible that a differential equation has ex-
actly one solution. Consider 
, which for reasons identical
to those given in Example 1.5 has only one solution 
.
You Need to Know 
A particular solution of a differential equation is any
one solution. The general solution of a differential
equation is the set of all solutions.
Example 1.6: The general solution to the differential equation in Ex-
ample 1.4 can be shown to be (see Chapters Four and Five) 
. That is, every particular solution of the differential
equation has this general form. A few particular solutions are: (a) 
(choose 
and 
), (b) 
(choose
and 
), and (c) 
(choose 
).
c
c
1
2
0
=
=
y ≡0
c2
0
=
c1
1
=
y
x
= sin2
c2
3
= −
c1
5
=
x
x
−
5
2
3
2
sin
cos
y =
c
x
c
x
+
1
2
2
2
sin
cos
y =
y ≡0
(
)′
+
=
y
y
4
2
0
= −1
(
)′
+
y
y
4
2
y
x
=
−
2
1
(
,
)
−∞∞
y
c
x
c
x
=
+
1
2
2
2
sin
cos
′′ +
=
−
−
+
+
=
−
+
+ −
+
=
y
y
c
x
c
x
c
x
c
x
c
c
x
c
c
x
4
4
2
4
2
4
2
2
4
4
2
4
4
2
0
1
2
1
2
1
1
2
2
(
sin
cos
)
(
sin
cos
)
(
)sin
(
)cos
4 DIFFERENTIAL EQUATIONS

The general solution of a differential equation cannot always be ex-
pressed by a single formula. As an example consider the differential equa-
tion 
, which has two particular solutions 
and 
.
Initial-Value and Boundary-Value Problems
A differential equation along with subsidiary
conditions on the unknown function and its de-
rivatives, all given at the same value of the in-
dependent variable, constitutes an initial-value
problem. The subsidiary conditions are initial
conditions. If the subsidiary conditions are giv-
en at more than one value of the independent
variable, the problem is a boundary-value prob-
lem and the conditions are boundary conditions.
Example 1.7: The problem 
is an initial
value problem, because the two subsidiary conditions are both given at
. The problem 
is a boundary-value
problem, because the two subsidiary conditions are given at x = 0 and 
x = 1.
A solution to an initial-value or boundary-value problem is a func-
tion y(x) that both solves the differential equation and satisﬁes all given
subsidiary conditions.
Standard and Differential Forms
Standard form for a ﬁrst-order differential equation in the unknown func-
tion y(x) is
(1.6)
where the derivative 
appears only on the left side of 1.6. Many, but
not all, ﬁrst-order differential equations can be written in standard form
by algebraically solving for 
and then setting f(x,y) equal to the right
side of the resulting equation.
′y
′y
′ =
y
f x y
( , )
′′ +
′ =
=
=
y
y
e
y
y
x
2
0
1
1
1
; ( )
, ( )
x = p
′′ +
′ =
=
′
=
y
y
e
y
y
x
2
1
2
; ( )
,
( )
p
p
y ≡0
y
x
= 1/
′ +
=
y
y2
0
CHAPTER 1: Basic Concepts and Classiﬁcation 5

The right side of 1.6 can always be written as a quotient of two oth-
er functions M(x,y) and −N(x,y). Then 1.6 becomes
which is equivalent to the differential form 
(1.7)
Linear Equations
Consider a differential equation in standard form 1.6. If f(x,y) can be writ-
ten as 
(that is, as a function of x times y, plus an-
other function of x), the differential equation is linear. First-order linear
differential equations can always be expressed as
(1.8)
Linear equations are solved in Chapter Two.
Bernoulli Equations
A Bernoulli differential equation is an equation of the form
(1.9)
where n denotes a real number. When n = 1 or n = 0, a Bernoulli equation
reduces to a linear equation. Bernoulli equations are solved in Chapter
Two.
Homogeneous Equations
A differential equation in standard form (1.6) is homogeneous if
(1.10)
for every real number t. Homogeneous equations are solved in Chapter
Two.
f tx ty
f x y
( ,
)
( , )
=
′ +
=
y
p x y
q x yn
( )
( )
′ +
=
y
p x y
q x
( )
( )
f x y
p x y
q x
( , )
( )
( )
= −
+
M x y dx
N x y dy
( , )
( , )
+
= 0
N x y
( , ),
−
dy dx
M x y
/
( , ) /
=
6 DIFFERENTIAL EQUATIONS

Note!
In the general framework of differential equations,
the word “homogeneous” has an entirely different
meaning (see Chapter Four). Only in the context 
of ﬁrst-order differential equations does “homoge-
neous” have the meaning deﬁned above.
Separable Equations
Consider a differential equation in differential form (1.7). If M(x,y) = A(x)
(a function only of x) and N(x,y) = B(y) (a function only of y), the differ-
ential equation is separable, or has its variables separated. Separable
equations are solved in Chapter Two.
Exact Equations
A differential equation in differential form (1.7) is exact if
(1.11)
Exact equations are solved in Chapter Two (where a more precise deﬁni-
tion of exactness is given).
∂
∂
= ∂
∂
M x y
y
N x y
x
( , )
( , )
CHAPTER 1: Basic Concepts and Classiﬁcation 7

Chapter 2 
Solutions of
First-Order
Differential
Equations
In This Chapter:
✔
Separable Equations
✔
Homogeneous Equations
✔
Exact Equations
✔
Linear Equations
✔
Bernoulli Equations
✔
Solved Problems
Separable Equations
General Solution
The solution to the ﬁrst-order separable differential equation (see Chap-
ter One). 
(2.1)
A x dx
B y dy
( )
( )
+
= 0
8
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

is
(2.2)
where c represents an arbitrary constant.
(See Problem 2.1)
The integrals obtained in Equation 2.2 may be, for all practical pur-
poses, impossible to evaluate. In such case, numerical techniques (see
Chapter 14) are used to obtain an approximate solution. Even if the indi-
cated integrations in 2.2 can be performed, it may not be algebraically
possible to solve for y explicitly in terms of x. In that case, the solution is
left in implicit form.
Solutions to the Initial-Value Problem
The solution to the initial-value problem
(2.3)
can be obtained, as usual, by ﬁrst using Equation 2.2 to solve the differ-
ential equation and then applying the initial condition directly to evalu-
ate c.
Alternatively, the solution to Equation 2.3 can be obtained from
(2.4)
where s and t are variables of integration.
Homogeneous Equations
The homogeneous differential equation
(2.5)
having the property f(tx, ty) = f(x, y) (see Chapter One) can be trans-
formed into a separable equation by making the substitution
dy
dx
f x y
=
( , )
A s ds
B t dt
x
x
y
y
( )
( )
+
=
∫
∫
0
0
0
A x dx
B y dy
y x
y
( )
( )
;
(
)
+
=
=
0
0
0
A x dx
B y dy
c
( )
( )
+
=
∫
∫
CHAPTER 2: Solutions of First-Order Differential Equations 9

y = xv
(2.6)
along with its corresponding derivative
(2.7)
The resulting equation in the variables v and x is solved as a separable
differential equation; the required solution to Equation 2.5 is obtained by
back substitution.
Alternatively, the solution to 2.5 can be obtained by rewriting the dif-
ferential equation as
(2.8)
and then substituting
x = yu
(2.9)
and the corresponding derivative 
(2.10)
into Equation 2.8. After simplifying, the resulting differential equation
will be one with variables (this time, u and y) separable.
Ordinarily, it is immaterial which method of solution is used. Occa-
sionally, however, one of the substitutions 2.6 or 2.9 is deﬁnitely superi-
or to the other one. In such cases, the better substitution is usually appar-
ent from the form of the differential equation itself.
(See Problem 2.2)
Exact Equations
Deﬁning Properties
A differential equation
M(x, y)dx + N(x, y)dy = 0
(2.11)
dx
dy
u
y du
dy
=
+
dx
dy
f x y
=
1
( , )
dy
dx
v
x dv
dx
=
+
10 DIFFERENTIAL EQUATIONS

is exact if there exists a function g(x, y) such that
dg(x, y) = M(x, y)dx + N(x, y)dy
(2.12)
Note! 
Test for exactness: If M(x,y) and N(x,y) are con-
tinuous functions and have continuous ﬁrst partial
derivatives on some rectangle of the xy-plane, then
Equation 2.11 is exact if and only if 
(2.13)
Method of Solution
To solve Equation 2.11, assuming that it is exact, ﬁrst solve the equations
(2.14)
(2.15)
for g(x, y). The solution to 2.11 is then given implicitly by
g(x, y) = c
(2.16)
where c represents an arbitrary constant.
Equation 2.16 is immediate from Equations 2.11 and 2.12. If 2.12 is
substituted into 2.11, we obtain dg(x, y(x)) = 0. Integrating this equation
(note that we can write 0 as 0 dx), we have 
, which,
in turn, implies 2.16.
Integrating Factors
In general, Equation 2.11 is not exact. Occasionally, it is possible to trans-
form 2.11 into an exact differential equation by a judicious multiplica-
tion. A function I(x, y) is an integrating factor for 2.11 if the equation
dg x y x
dx
( , ( )) = ∫
∫
0
∂
∂
g x y
y
N x y
( , )
( , )
=
∂
∂
g x y
x
M x y
( , )
( , )
=
∂
∂
∂
∂
M x y
y
N(x,y)
x
( , ) =
CHAPTER 2: Solutions of First-Order Differential Equations 11

I(x, y)[M(x, y)dx + N(x, y)dy] = 0
(2.17)
is exact. A solution to 2.11 is obtained by solving the exact differential
equation deﬁned by 2.17. Some of the more common integrating factors
are displayed in Table 2.1 and the conditions that follow:
If 
, a function of x alone, then
(2.18)
If 
, a function of y alone, then
(2.19)
If M = yf(xy) and N = xg(xy), then
(2.20)
In general, integrating factors are difﬁcult to uncover. If a differential
equation does not have one of the forms given above, then a search for
an integrating factor likely will not be successful, and other methods of
solution are recommended.
(See Problems 2.3–2.6)
Linear Equations
Method of Solution
A ﬁrst-order linear differential equation has the form (see Chapter One)
(2.21)
An integrating factor for Equation 2.21 is 
(2.22)
I x
e
p x dx
( )
( )
= ∫
′ +
=
y
p x y
q x
( )
( )
I x y
xM
yN
( , ) =
−
1
I x y
e
h y dy
( , )
( )
=
∫
−
1
M
M
y
N
x
h y
∂
∂
∂
∂
−



≡( )
I x y
e
g x dx
( , )
( )
= ∫
1
N
M
y
N
x
g x
∂
∂
∂
∂
−



≡( )
12 DIFFERENTIAL EQUATIONS

which depends only on x and is independent of y. When both sides of 2.21
are multiplied by I(x), the resulting equation
(2.23)
is exact. This equation can be solved by the method described previous-
ly. A simpler procedure is to rewrite 2.23 as
d yI
dx
Iq x
(
)
( )
=
I x y
p x I x y
I x q x
( )
( ) ( )
( ) ( )
′ +
=
CHAPTER 2: Solutions of First-Order Differential Equations 13
Table 2.1

integrate both sides of this last equation with respect to x, and then solve
the resulting equation for y. The general solution for Equation 2.21 is
where c is the constant of integration.
(See Problem 2.7)
Bernoulli Equations
A Bernoulli differential equation has the form
(2.24)
where n is a real number. The substitution
(2.25)
transforms 2.24 into a linear differential equation in the unknown func-
tion z(x).
(See Problem 2.8)
Solved Problems
Solved Problem 2.1 Solve 
This equation may be rewritten in the differential form
which is separable with A(x) = x2 + 2 and B(y) = −y. Its solution is 
or
1
3
2
1
2
3
2
x
x
y
c
+
−
=
(
)
x
dx
ydy
c
2
2
+
−
=
∫
∫
(
)
x
dx
ydy
2
2
0
+
−
=
dy
dx
x
y
=
+
2
2 .
z
y
n
=
−
1
′ +
=
y
p x y
q x yn
( )
( )
y
I x q x dx
c
I x
=
+
∫( ) ( )
( )
14 DIFFERENTIAL EQUATIONS

Solving for y, we obtain the solution in implicit form as
with k = −2c. Solving for y explicitly, we obtain the two solutions
Solved Problem 2.2 Solve 
This differential equation is not separable. Instead it has the form
with
where
so it is homogeneous. Substituting Equations 2.6 and 2.7 into the equa-
tion, we obtain
which can be algebraically simpliﬁed to
This last equation is separable; its solution is
which, when evaluated, yields 
or
(2.26)
where we have set 
and have noted that
Finally, substituting v = y/x back into 2.26, we obtain the solution to the
given differential equation as y
x
kx
=
ln |
|.
ln |
|
ln |
|
ln |
|.
x
k
xk
+
=
c
k
= −ln |
|
v
kx
= ln |
|
v
x
c
=
−
ln |
|
,
1
x dx
dv
c
∫
∫
−
=
x dv
dx
x dx
dv
=
−
=
1
1
0
or
v
x dv
dx
xv
x
x
+
=
+
f tx ty
ty
tx
tx
t y
x
tx
y
x
x
f x y
( ,
)
(
)
( , )
=
+
=
+
=
+
=
f x y
y
x
x
( , ) =
+
′ =
y
f x y
( , ),
′ =
+
y
y
x
x
.
y
x
x
k
y
x
x
k
=
+
+
= −
+
+
2
3
4
2
3
4
3
3
and
y
x
x
k
2
3
2
3
4
=
+
+
CHAPTER 2: Solutions of First-Order Differential Equations 15

Solved Problem 2.3 Solve 
.
This equation has the form of Equation 2.11 with M(x, y) = 2xy and 
N(x, y) = 1 + x2. Since 
the differential equation
is exact. Because this equation is exact, we now determine a function 
g(x, y) that satisﬁes Equations 2.14 and 2.15. Substituting M(x, y) = 2xy
into 2.14, we obtain 
Integrating both sides of this equation
with respect to x, we ﬁnd
or
(2.27)
Note that when integrating with respect to x, the constant (with respect to
x) of integration can depend on y.
We now determine h(y). Differentiating 2.27 with respect to y, we
obtain 
(y) Substituting this equation along with N(x, y) =
1 + x2 into 2.15, we have
Integrating this last equation with respect to y, we obtain h(y) = y + c1
(c1 = constant). Substituting this expression into 2.27 yields
g(x, y) = x2y + y + c1
The solution to the differential equation, which is given implicitly by
2.16 as g(x, y) = c, is 
x2y + y = c2        (c2 = c − c1)
Solving for y explicitly, we obtain the solution as y = c2/(x2 + 1).
Solved Problem 2.4 Determine whether the differential equation ydx −
xdy = 0 is exact.
x
h y
x
h y
2
2
1
1
+ ′
= +
′
=
( )
( )
or
∂
∂=
+ ′
g
y
x
h
/
2
g x y
x y
h y
( , )
( )
=
+
2
∂
∂
=
∫
∫
g
x dx
xydx
2
∂
∂=
g
x
xy
/
.
2
∂
∂= ∂
∂=
M
y
N
x
x
/
/
,
2
2
1
0
2
xydx
x
dy
+
+
=
(
)
16 DIFFERENTIAL EQUATIONS

This equation has the form of Equation 2.11 with M (x, y) = y and N (x, y)
= −x. Here
which are not equal, so the differential equation is not exact.
Solved Problem 2.5 Determine whether −1/x2 is an integrating factor
for the differential equation ydx −xdy = 0.
It was shown in Problem 2.4 that the differential equation is not exact.
Multiplying it by −1/x2, we obtain
(2.28)
Equation 2.28 has the form of Equation 2.11 with M (x, y) = −y/x2 and 
N (x, y) = 1/x. Now
so 2.28 is exact, which implies that −1/x2 is an integrating factor for the
original differential equation.
Solved Problem 2.6 Solve ydx −xdy = 0.
Using the results of Problem 2.5, we can rewrite the given differential
equation as
which is exact. Equation 2.28 can be solved using the steps described in
Equations 2.14 through 2.16.
Alternatively, we note from Table 2.1 that 2.28 can be rewritten as 
d (y/x) = 0. Hence, by direct integration, we have y/x = c, or y = xc, as
the solution.
Solved Problem 2.7 Solve ′ +
=
y
x y
x
( / )
.
4
4
xdy
ydx
x
−
=
2
0
∂
∂
= ∂
∂
−



= −= ∂
∂



= ∂
∂
M
y
y
y
x
x
x
x
N
x
2
2
1
1
−
−
=
−
+
=
1
0
1
0
2
2
x
ydx
xdy
y
x
dx
x dy
(
)
or
∂
∂
=
∂
∂
= −
M
y
N
x
1
1
and
CHAPTER 2: Solutions of First-Order Differential Equations 17

The differential equation has the form of Equation 2.21, with p(x) = 4/x
and q(x) = x4, and is linear. Here
so 2.22 becomes
(2.29)
Multiplying the differential equation by the integrating factor de-
ﬁned by 2.29, we obtain
Integrating both sides of this last equation with respect to x, we obtain
Solved Problem 2.8 Solve 
This equation is not linear. It is, however, a Bernoulli differential equa-
tion having the form of Equation 2.24 with p(x) = q(x) = x, and n = 2. We
make the substitution suggested by 2.25, namely z = y1−2 = y−1, from
which follow
Substituting these equations into the differential equation, we obtain
This last equation is linear for the unknown function z(x). It has the form
of Equation 2.21 with y replaced by z and p(x) = q(x) = −x. The integrat-
ing factor is 
Multiplying the differential equation by I(x), we obtain
I x
e
e
x dx
x
( )
(
)
/
= ∫
=
−
−
2 2
−
′ +
=
′ −
= −
z
z
x
z
x
z
z
xz
x
2
2
or
y
z
y
z
z
=
′ = −
′
1
2
and
′ +
=
y
xy
xy2.
yx
x
c
y
c
x
x
4
9
4
5
1
9
1
9
=
+
=
+
or
x y
x y
x
d
dx yx
x
4
3
8
4
8
4
′ +
=
=
or
(
)
I x
e
e
x
p x dx
x
( )
( )
ln
= ∫
=
=
4
4
p x dx
x dx
x
x
( )
ln |
|
ln
∫
∫
=
=
=
4
4
4
18 DIFFERENTIAL EQUATIONS

or
Upon integrating both sides of this last equation, we have
whereupon
The solution of the original differential equation is then
y
z
cex
=
=
+
1
1
1
2 2
/
z x
cex
( )
/
=
+
2 2
1
ze
e
c
x
x
−
−
=
+
2
2
2
2
/
/
d
dx ze
xe
x
x
−
−
(
) = −
2
2
2
2
/
/
e
dz
dx
xe
z
xe
x
x
x
−
−
−
−
= −
2
2
2
2
2
2
/
/
/
CHAPTER 2: Solutions of First-Order Differential Equations 19

Chapter 3
Applications 
of First-Order
Differential
Equations
In This Chapter:
✔
Growth and Decay Problems
✔
Temperature Problems
✔
Falling Body Problems
✔
Dilution Problems
✔
Electrical Circuits
✔
Orthogonal Trajectories
✔
Solved Problems
Growth and Decay Problems
Let N(t) denote the amount of substance (or popula-
tion) that is either growing or decaying. If we assume
that dN/dt, the time rate of change of this amount of
substance, is proportional to the amount of substance
present, then dN/dt = kN, or
20
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

(3.1)
where k is the constant of proportionality. 
We are assuming that N(t) is a differentiable, hence continuous, func-
tion of time. For population problems, where N(t) is actually discrete and
integer-valued, this assumption is incorrect. Nonetheless, 3.1 still pro-
vides a good approximation to the physical laws governing such a sys-
tem.
Temperature Problems
Newton’s law of cooling, which is equally applicable to heating, states
that the time rate of change of the temperature of a body is proportional
to the temperature difference between the body and its surrounding medi-
um. Let T denote the temperature of the body and let Tm denote the tem-
perature of the surrounding medium. Then the time rate of change of the
temperature of the body is dT/dt, and Newton’s law of cooling can be for-
mulated as dT/dt = −k(T −Tm), or as
(3.2)
where k is a positive constant of proportionality. Once k is chosen posi-
tive, the minus sign is required in Newton’s law to make dT/dt negative
in a cooling process, when T is greater than Tm, and positive in a heating
process, when T is less than Tm.
Falling Body Problems
Consider a vertically falling body of mass m that is being inﬂuenced only
by gravity g and an air resistance that is proportional to the velocity of
the body. Assume that both gravity and mass remain constant and, for
convenience, choose the downward direction as the positive direction.
dT
dt
kT
kTm
+
=
dN
dt
kN
−
= 0
CHAPTER 3: Applications of Differential Equations 21

You Need to Know 
Newton’s second law of motion: The net force
acting on a body is equal to the time rate of change
of the momentum of the body; or, for constant
mass,
(3.3)
where F is the net force on the body and v is the
velocity of the body, both at time t.
For the problem at hand, there are two forces acting on the body: the force
due to gravity given by the weight w of the body, which equals mg, and
the force due to air resistance given by −kv, where k ≥0 is a constant of
proportionality. The minus sign is required because this force opposes the
velocity; that is, it acts in the upward, or negative, direction (see Figure
3-1). The net force F on the body is, therefore, F = mg −kv. Substituting
this result into 3.3, we obtain
or
(3.4)
as the equation of motion for the body.
If air resistance is negligible or nonexistent, then k = 0 and 3.4 sim-
pliﬁes to
(3.5)
When k > 0, the limiting velocity vl is deﬁned by
(3.6)
v
mg
k
l =
dv
dt
g
=
dv
dt
k
m v
g
+
=
mg
kv
m dv
dt
−
=
F
m dv
dt
=
22 DIFFERENTIAL EQUATIONS

Caution: Equations 3.4, 3.5, and 3.6 are valid only if the given con-
ditions are satisﬁed. These equations are not valid if, for example, air re-
sistance is not proportional to velocity but to the velocity squared, or if
the upward direction is taken to be the positive direction.
Dilution Problems
Consider a tank which initially holds V0 gal of brine that contains a lb of
salt. Another solution, containing b lb of salt per gallon, is poured into the
tank at the rate of e gal/min while simultaneously, the well-stirred solu-
tion leaves the tank at the rate of f gal/min (Figure 3-2). The problem is
to ﬁnd the amount of salt in the tank at any time t.
Let Q denote the amount (in pounds) of salt in the
tank at any time. The time rate of change of Q, dQ/dt,
equals the rate at which salt enters the tank minus the rate
at which salt leaves the tank. Salt enters the tank at the
rate of be lb/min. To determine the rate at which salt
leaves the tank, we ﬁrst calculate the volume of brine 
in the tank at any time t, which is the initial volume V0
plus the volume of brine added et minus the volume of brine removed ft.
Thus, the volume of brine at any time is 
CHAPTER 3: Applications of Differential Equations 23
Figure 3-1

(3.7)
The concentration of salt in the tank at any time is 
from
which it follows that salt leaves the tank at the rate of
lb/min
Thus, 
or 
(3.8)
dQ
dt
f
V
e
f t Q
be
+
+
−
=
0
(
)
dQ
dt
be
f
Q
V
et
ft
=
−
+
−




0
f
Q
V
et
ft
0 +
−




Q
V
et
ft
/ (
),
0 +
−
V
et
ft
0 +
−
24 DIFFERENTIAL EQUATIONS
Figure 3-2
e gal/min
V0 gal
f gal/min

Electrical Circuits
The basic equation governing the amount of current I (in amperes) in a
simple RL circuit (see Figure 3-3) consisting of a resistance R (in ohms),
an inductor L (in henries), and an electromotive force (abbreviated emf)
E (in volts) is 
(3.9)
For an RC circuit consisting of a resistance, a capacitance C (in farads),
an emf, and no inductance (Figure 3-4), the equation governing the
amount of electrical charge q (in coulombs) on the capacitor is
(3.10)
dq
dt
RC q
E
R
+
=
1
dI
dt
R
L I
E
L
+
=
CHAPTER 3: Applications of Differential Equations 25
Figure 3-3
Figure 3-4

The relationship between q and I is 
(3.11)
For more complex circuits see Chapter Seven.
Orthogonal Trajectories
Consider a one-parameter family of curves in the xy-plane deﬁned by
F(x, y, c) = 0
(3.12)
where c denotes the parameter. The problem is to ﬁnd another one-pa-
rameter family of curves, called the orthogonal trajectories of the fami-
ly of curves in 3.12 and given analytically by
G(x, y, k) = 0
(3.13)
such that every curve in this new family 3.13 intersects at right angles
every curve in the original family 3.12.
We ﬁrst implicitly differentiate 3.12 with respect to x, then eliminate
c between this derived equation and 3.12. This gives an equation con-
necting x, y, and 
which we solve for 
to obtain a differential equa-
tion of the form
(3.14)
The orthogonal trajectories of 3.12 are the solutions of
(3.15)
For many families of curves, one cannot explicitly solve for dy/dx
and obtain a differential equation of the form 3.14. We do not consider
such curves in this book.
Solved Problems
Solved Problem 3.1 A bacteria culture is known to grow at a rate pro-
portional to the amount present. After one hour, 1000 strands of the bac-
dy
dx
f x y
= −
1
( , )
dy
dx
f x y
=
( , )
′y
′y ,
I
dq
dt
=
26 DIFFERENTIAL EQUATIONS

teria are observed in the culture; and after four hours, 3000 strands. Find
(a) an expression for the approximate number of strands of the bacteria
present in the culture at any time t and (b) the approximate number of
strands of the bacteria originally in the culture.
(a) Let N(t) denote the number of bacteria strands in the culture at
time t. From Equation 3.1, dN/dt −kN = 0, which is both linear and sep-
arable. Its solution is 
N(t) = cekt
(3.16)
At t = 1, N = 1000; hence,
1000 = cek
(3.17)
At t = 4, N = 3000; hence.
3000 = ce4k
(3.18)
Solving 3.17 and 3.18 for k and c, we ﬁnd
and c = 1000e−k = 693
Substituting these values of k and c into 3.16, we obtain
N(t) = 693e0.3662t
(3.19)
(b) We require N at t = 0. Substituting t = 0 into 3.19, we obtain N(0)
= 693e(0.3662)(0) = 693.
Solved Problem 3.2 A tank initially holds 100 gal of a brine solution
containing 20 lb of salt. At t = 0, fresh water is poured into the tank at the
rate of 5 gal/min, while the well-stirred mixture leaves the tank at the
same rate. Find the amount of salt in the tank at any time t.
Here, V0 = 100, a = 20, b = 0, and e = f = 5. Equation 3.8 becomes
dQ
dt
Q
+
=
1
20
0
k =
≈
1
3
3
0 3662
ln
.
CHAPTER 3: Applications of Differential Equations 27

The solution of this linear equation is 
Q = ce−t/20
(3.20)
At t = 0, we are given that Q = a = 20. Substituting these values into 3.20,
we ﬁnd that c = 20, so that 3.20 can be rewritten as Q = 20e−t /20. Note
that as t → ∞, Q → 0 as it should, since only fresh water is being added.
28 DIFFERENTIAL EQUATIONS

Chapter 4
Linear
Differential
Equations:
Theory of
Solutions
In This Chapter:
✔
Linear Differential Equations
✔
Linearly Independent Solutions
✔
The Wronskian
✔
Nonhomogeneous Equations
Linear Differential Equations
An nth-order linear differential equation has the form
(4.1)
where g(x) and the coefﬁcients bj(x) ( j = 0,1,2,..., n) de-
pend solely on the variable x. In other words, they do
not depend on y or any derivative of y.
b
x y
b
x y
b x y
b
x y
g x
n
n
n
n
( )
( )
( )
( )
( )
( )
(
)
+
+
+
′ +
=
−
−
1
1
1
0
L
29
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

If g(x) = 0, then Equation 4.1 is homogeneous; if not, 4.1 is nonho-
mogeneous. A linear differential equation has constant coefﬁcients if all
the coefﬁcients bj(x) in 4.1 are constants; if one or more of these coefﬁ-
cients is not constant, 4.1 has variable coefﬁcients.
Theorem 4.1. Consider the initial-value problem given by the linear dif-
ferential equation 4.1 and the n initial conditions
(4.2)
If g(x) and bj(x) ( j = 0,1,2,..., n) are continuous in some interval  con-
taining x0 and if bn(x) ≠0 in , then the initial-value problem given by
4.1 and 4.2 has a unique (only one) solution deﬁned throughout .
When the conditions on bn(x) in Theorem 4.1 hold, we can divide
Equation 4.1 by bn(x) to get 
(4.3)
where aj(x) = bj(x)/bn(x) ( j = 0,1,2,..., n − 1) and f(x) = g(x)/bn(x).
Let us deﬁne the differential operator L(y) by
(4.4)
where ai(x) (i = 0,1,2,..., n − 1) is continuous on some interval of interest.
Then 4.3 can be rewritten as
L(y) = f(x)
(4.5)
and, in particular, a linear homogeneous differential equation can be ex-
pressed as
L(y) = 0
(4.6)
L( )
( )
( )
( )
( )
( )
(
)
y
y
a
x y
a
x y
a x y
a
x y
n
n
n
≡
+
+
+
′′ +
′ +
−
−
1
1
2
1
0
L
y
a
x y
a
x y
a x y
a
x y
x
n
n
n
( )
(
)
( )
( )
( )
( )
( )
+
+
+
′′ +
′ +
=
−
−
1
1
2
1
0
L
f
y x
c
y x
c
y
x
c
y
x
c
n
n
(
)
,
(
)
,
(
)
,
,
(
)
(
)
0
0
0
1
0
2
1
0
1
=
′
=
′′
=
=
−
−
K
30 DIFFERENTIAL EQUATIONS

Linearly Independent Solutions
A set of functions {y1(x), y2(x),...,yn(x)} is linearly dependent on a ≤x ≤b
if there exist constants c1,c2,...,cn not all zero, such that
(4.7)
on a ≤x ≤b.
Example 4.1: The set {x,5x,1,sin x}is linearly dependent on [−1,1] since
there exist constants c1 = −5, c2 = 1, c3 = 0, and c4 = 0, not all zero, such
that 4.7 is satisﬁed. In particular,
−5 ⋅x + 1 ⋅5x + 0 ⋅1 + 0 ⋅sin x = 0
Note that c1 = c2 = … cn = 0 is a set of constants that always satis-
ﬁes 4.7. A set of functions is linearly dependent if there exists another set
of constants, not all zero, that also satisﬁes 4.7. If the only solution to 4.7
is c1 = c2 = … cn = 0, then the set of functions {y1(x), y2(x),...,yn(x)} is
linearly independent on a ≤x ≤b.
Theorem 4.2. The nth-order linear homogeneous differential equation
L(y) = 0 always has n linearly independent solutions. If y1(x),y2(x),...,yn(x)
represent these solutions, then the general solution of L(y) = 0 is
y(x) = c1y1(x) + c2y2(x) +…+ cnyn(x)
(4.8)
where c1,c2,...,cn denote arbitrary constants.
The Wronskian
The Wronskian of a set of functions {z1(x), z2(x),..., zn(x)} on the interval
a ≤x ≤b, having the property that each function possesses n − 1 deriva-
tives on this interval, is the determinant
W z z
z
z
z
z
z
z
z
z
z
z
z
z
z
n
n
n
n
n
n
n
n
( ,
,
,
)
(
)
(
)
(
)
1
2
1
2
1
2
1
2
1
1
2
1
1
K
L
L
L
M
M
L
M
L
=
′
′
′
′′
′′
′′
−
−
−
c y x
c y
x
c y
x
n n
1 1
2 2
0
( )
( )
( )
+
+
+
≡
L
CHAPTER 4: Linear Differential Equations 31

Theorem 4.3. If the Wronskian of a set of n functions deﬁned on the in-
terval a ≤x ≤b is nonzero for at least one point in this interval, then the
set of functions is linearly independent there. If the Wronskian is identi-
cally zero on this interval and if each of the functions is a solution to the
same linear differential equation, then the set of functions is linearly de-
pendent.
Caution: Theorem 4.3 is silent when the Wronskian is identically
zero and the functions are not known to be solutions of the same linear
differential equation. In this case, one must test directly whether Equa-
tion 4.7 is satisﬁed.
Nonhomogeneous Equations
Let yp denote any particular solution of Equation 4.5 (see Chapter One)
and let yh (henceforth called the homogeneous or complementary solu-
tion) represent the general solution of the associated homogeneous equa-
tion L(y) = 0.
Theorem 4.4. The general solution to L(y) = f(x) is
y = yh + yp
(4.9)
Don’t Forget
The general solution is the sum of
the homogeneous and particular so-
lutions.
32 DIFFERENTIAL EQUATIONS

Chapter 5
Solutions 
of Linear
Homogeneous
Differential
Equations with
Constant
Coefﬁcients
In This Chapter:
✔
The Characteristic Equation
✔
General Solution for Second-Order
Equations
✔
General Solution for nth-Order
Equations
✔
Solved Problems
33
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

The Characteristic Equation
Second-Order Equations
Corresponding to the differential equation 
(5.1)
in which a1 and a0 are constants, is the algebraic equation
(5.2)
which is obtained by substituting y = elx (assuming x to be the indepen-
dent variable) into Equation 5.1 and simplifying. Note that Equation 5.2
can be easily obtained by replacing 
and y by l2, l1, and, l0 = 1,
respectively. Equation 5.2 is called the characteristic equation of 5.1.
Example 5.1 The characteristic equation of 
is l2 + 3l
−4 = 0; the characteristic equation of 
is l2 −2l + 1 = 0.
Characteristic equations for differential equations having dependent
variables other than y are obtained analogously, by replacing the jth de-
rivative of the dependent variable by l j (j = 0,1,2).
nth-Order Equations
Similarly, the characteristic equation of the differential equation
(5.3)
with constant coefﬁcients aj (j = 0,1,..., n −1) is 
(5.4)
The characteristic equation 5.4 is obtained from 5.3 by replacing y(j) by  
l j (j = 0,1,..., n). Characteristic equations for differential equations hav-
ing dependent variables other than y are obtained analogously, by 
replacing the jth derivative of the dependent variable by lj (j = 0,1,..., 
n).
l
l
l
n
n
n
a
a
a
+
+
+
+
=
−
−
1
1
1
0
0
L
y
a
y
a y
a y
n
n
n
( )
(
)
+
+
+
′ +
=
−
−
1
1
1
0
0
L
′′ −
′ +
=
y
y
y
2
0
′′ +
′ −
=
y
y
y
3
4
0
′′
′
y
y
,
,
l
l
2
1
0
0
+
+
=
a
a
′′ +
′ +
=
y
a y
a y
1
0
0
34 DIFFERENTIAL EQUATIONS

Example 5.2. The characteristic equation of 
is
l4 −3l3 + 2l2 −1 = 0. The characteristic equation of
is
Caution! 
Characteristic equations are only deﬁned for linear
homogeneous differential equations with constant
coefﬁcients.
General Solution for Second-Order Equations
The characteristic equation (5.2) can be factored into
(5.5)
Note!
The roots of the characteristic polynomial deter-
mine the solution of the differential equation.
There are three cases to consider.
Case 1. l1 and l2 both real and distinct. Two linearly indepen-
dent solutions are 
and 
, and the general solution is (Theo-
rem 4.2)
e
x
l2
e
x
l1
(
)(
)
l
l
l
l
−
−
=
1
2
0
l
l
l
5
3
3
5
7
0
−
+
−
=
d x
dt
d x
dt
dx
dt
x
5
5
3
3
3
5
7
0
−
+
−
=
y
y
y
y
( )
4
3
2
0
−
′′′ +
′′ −
=
CHAPTER 5: Linear Homogeneous Differential Equations 35

(5.6)
In the special case l2 = −l1, the solution 5.6 can be rewritten as y =
k1 cosh l1x + k2 sinh l1x.
Case 2. l1 = a + ib, a complex number. Since a1 and a0 in 5.1 and
5.2 are assumed real, the roots of 5.2 must appear in conjugate pairs;
thus, the other root is l2 = a − ib. Two linearly independent solutions
are 
, and 
, and the general complex solution is
(5.7)
which is algebraically equivalent to
(5.8)
Case 3. l1 = l2.  Two linearly independent solutions are 
and
and the general solution is 
(5.9)
Warning: The above solutions are not valid if the differential equa-
tion is not linear or does not have constant coefﬁcients. Consider, for ex-
ample, the equation 
. The roots of the characteristic equa-
tion are l1 = x and l2 = −x, but the solution is not
Linear equations with variable coefﬁcients are considered in Chapter
Twelve.
General Solution for nth-Order Equations
The general solution of 5.3 is obtained directly from the roots of 5.4. If
the roots l1, l2,..., lnare all real and distinct, the solution is 
(5.10)
y
c e
c e
c e
x
x
n
x
n
=
+
+
+
1
2
1
2
l
l
l
L
y
c e
c e
c e
c e
x x
x x
x
x
=
+
=
+
−
−
1
2
1
2
2
2
( )
(
)
′′ −
=
y
x y
2
0
y
c e
c xe
x
x
=
+
1
2
1
1
l
l
xe
x
l1 ,
e
x
l1
y
c e
bx
c e
bx
ax
ax
=
+
1
2
cos
sin
y
d e
d e
a ib x
a ib x
=
+
+
−
1
2
(
)
(
)
e a ib x
(
)
−
e a ib x
(
)
+
y
c e
c e
x
x
=
+
1
2
1
2
l
l
36 DIFFERENTIAL EQUATIONS

If the roots are distinct, but some are com-
plex, then the solution is again given by 5.10.
As in the second-order equation, those terms
involving complex exponentials can be com-
bined to yield terms involving sines and co-
sines. If lk is a root of multiplicity p [that is, if
(l − lk)p is a factor of the characteristic equa-
tion, but (l − lk) p+1 is not] then there will be
p linearly independent solutions associated
with lk given by 
. These solutions are
combined in the usual way with the solutions associated with the other
roots to obtain the complete solution.
In theory it is always possible to factor the characteristic equation,
but in practice this can be extremely difﬁcult, especially for differential
equations of high order. In such cases, one must often use numerical tech-
niques to approximate the solutions. See Chapter Fourteen.
Solved Problems
Solved Problem 5.1 Solve
The characteristic equation is l2 −l −2 = 0, which can be factored
into (l −2)(l + 1) = 0. Since the roots l1 = 2 and l2 = −1 are real and dis-
tinct, the solution is given by 5.6 as
Solved Problem 5.2 Solve 
The characteristic equation is 
which can be fac-
tored into (l −4)2 = 0. The roots l1 = l2 = 4 are real and equal, so the gen-
eral solution is given by 5.9 as
Solved Problem 5.3 Solve
The characteristic equation l3 −6l2 + 2l + 36 = 0, has roots  l1 =
−2, 
and 
The solution is
l3
4
2
=
−i
.
l2
4
2
=
+ i
,
′′′ −
′′ +
′ +
=
y
y
y
y
6
2
36
0.
y
c e
c xe
x
x
=
+
1
4
2
4
l
l
2
8
16
0
−
+
=
′′ −
′ +
=
y
y
y
8
16
0.
y
c e
c e
x
x
=
+
−
1
2
2
′′ −′ −
=
y
y
y
2
0.
e
xe
x e
x
e
k
k
k
k
x
x
x
p
x
l
l
l
l
,
,
,
,
2
1
K
−
CHAPTER 5: Linear Homogeneous Differential Equations 37

which can be rewritten, using Euler’s relations 
as
Note that this form of the solution corresponding to the complex roots
can be easily formulated using Equation 5.8.
y
c e
d e
e
d e
e
y
c e
d e
x
i
x
d e
x
i
x
y
c e
d
d e
x
i d
d e
x
y
c e
c e
x
x i
x
x
i
x
x
x
x
x
x
x
x
=
+
+
=
+
+
+
−
=
+
+
+
−
=
+
−
−
−
−
−
1
2
2
4
2
3
4
2
1
2
2
4
3
4
1
2
2
3
4
2
3
4
1
2
2
2
2
2
2
2
2
(cos
sin
)
(cos
sin
)
(
)
cos
(
)
sin
4
3
4
2
2
x
x
x
c e
x
cos
sin
+
e
bx
i
bx
e
bx
i
bx
ibx
ibx
=
+
=
−
−
cos
sin
cos
sin
and
y
c e
d e
d e
x
i
x
i
x
=
+
+
−
+
−
1
2
2
4
2
3
4
2
(
)
(
)
38 DIFFERENTIAL EQUATIONS

Chapter 6
Solutions 
of Linear
Nonhomogeneous
Equations and
Initial-Value
Problems
In This Chapter:
✔
The Method of Undetermined
Coefﬁcients
✔
Variation of Parameters
✔
Initial-Value Problems
✔
Solved Problems
The general solution to the linear differential equa-
tion L(y) = f(x) is given by Theorem 4.4 as y = yh +
yp where yp denotes one solution to the differential
equation and yh is the general solution to the asso-
ciated homogeneous equation, L(y) = 0. Methods
39
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

for obtaining yh when the differential equation has constant coefﬁcients
are given in Chapter Five. In this chapter, we give methods for obtaining
a particular solution yp once yh is known.
The Method of Undetermined Coefﬁcients
Simple Form of the Method
The method of undetermined coefﬁcients is applicable only if f(x) and all
of its derivatives can be written in terms of the same ﬁnite set of linearly
independent functions, which we denote by {y1(x), y2(x),..., yn(x)}. The
method is initiated by assuming a particular solution of the form
where A1, A2,..., An denote arbitrary multiplicative constants. These arbi-
trary constants are then evaluated by substituting the proposed solution
into the given differential equation and equating the coefﬁcients of like
terms.
Case 1. f(x) = pn(x), an nth-degree polynomial in x. Assume a so-
lution of the form 
(6.1)
where Aj ( j = 0,1,2,..., n) is a constant to be determined.
Case 2. f(x) = keax where k and a are known constants. Assume
a solution of the form
yp = Aeax
(6.2)
where A is a constant to be determined.
Case 3. f(x) = k1 sin bx + k2 cos bx where k1, k2, and b are known
constants. Assume a solution of the form 
yp = A sin bx + B cos bx
(6.3)
where A and B are constants to be determined.
y
e
A x
A
x
A x
p
x
n
n
n
n
=
+
+
+
+
−
−
a (
1
1
1
L
y
x
A y x
A y
x
A y
x
p
n n
( )
( )
( )
( )
=
+
+
+
1
1
2 2
L
40 DIFFERENTIAL EQUATIONS

CHAPTER 6: Linear Nonhomogeneous Equations 41
Don’t Forget
yp = A sin bx + B cos bx in its entirety is assumed
for f(x) = k1 sin bx + k2 cos bx even when k1 or k2
is zero, because the derivatives of sines or cosines
involve both sines and cosines.
Generalizations
If f(x) is the product of terms considered in Cases 1 through 3, take yp to
be the product of the corresponding assumed solutions and algebraically
combine arbitrary constants where possible. In particular, if f(x) = eax pn(x)
is the product of a polynomial with an exponential, assume
(6.4)
where Aj is as in Case 1. If, instead, f(x) = eax pn(x) sin bx is the product
of a polynomial, exponential, and sine term, or if f(x) = eax pn(x) cos bx
is the product of a polynomial, exponential, and cosine term, then assume
(6.5)
where Aj and Bj ( j = 0,1,2,..., n) are constants which still must be deter-
mined.
If f(x) is the sum (or difference) of terms already considered, then
y
e
x A x
A
x
A x
A
e
x B x
B
x
B x
B
p
x
n
n
n
n
x
n
n
n
n
=
+
+
+
+
+
+
+
+
+
−
−
−
−
a
a
b
b
sin
(
)
cos
(
)
1
1
1
0
1
1
1
0
L
L
y
e
A x
A
x
A x
A
p
x
n
n
n
n
=
+
+
+
+
−
−
a (
)
1
1
1
0
L

we take yp to be the sum (or difference) of the corresponding assumed so-
lutions and algebraically combine arbitrary constants where possible.
Modiﬁcations
If any term of the assumed solution, disregarding multiplicative con-
stants, is also a term of yh (the homogeneous solution), then the assumed
solution must be modiﬁed by multiplying it by xm, where m is the small-
est positive integer such that the product of xm with the assumed solution
has no terms in common with yh.
Limitations of the Method
In general, if f(x) is not one of the types of functions considered above,
or if the differential equation does not have constant coefﬁcients, then the
following method is preferred.
Variation of Parameters
Variation of parameters is another method for ﬁnding a particular solu-
tion of the nth-order linear differential equation
(6.6)
once the solution of the associated homogeneous equation L(y) = 0 is
known. Recall from Theorem 4.2 that if y1(x), y2(x),..., yn(x) are n linear-
ly independent solutions of L(y) = 0, then the general solution of L(y) =
0 is 
(6.7)
The Method
A particular solution of L(y) = f(x) has the form 
(6.8)
where yi = yi(x) (i = 1,2,..., n) is given in Equation 6.7 and vi (i = 1,2,...,
n) is an unknown function of x which still must be determined.
y
v y
v y
v y
p
n n
=
+
+
+
1 1
2 2
L
y
c y x
c y
x
c y
x
h
n n
=
+
+
+
1 1
2 2
( )
( )
( )
L
L( )
( )
y
x
= f
42 DIFFERENTIAL EQUATIONS

To ﬁnd vi, ﬁrst solve the following linear equations simultaneously
for 
:
(6.9)
Then integrate each 
to obtain vi, disregarding all constants of integra-
tion. This is permissible because we are seeking only one particular so-
lution.
Example 6.1: For the special case n = 3, Equations 6.9 reduce to 
(6.10)
For the case n = 2, Equations 6.9 become
(6.11)
and for the case n = 1, we obtain the single equation
(6.12)
Since y1(x), y2(x),..., yn(x) are n linearly independent solutions of the same
equation L(y) = 0, their Wronskian is not zero (Theorem 4.3). This means
that the system 6.9 has a nonzero determinant and can be solved unique-
ly for 
.
Scope of the Method
The method of variation of parameters can be applied to all linear differ-
ential equations. It is therefore more powerful than the method of unde-
termined coefﬁcients, which is restricted to linear differential equations
with constant coefﬁcients and particular forms of f(x). Nonetheless, in
′
′
′
v x v
x
v
x
n
1
2
( ),
( ),
,
( )
K
′
=
v y
x
1 1
f( )
′
+ ′
=
′ ′ + ′ ′ =
v y
v y
v y
v y
x
1 1
2 2
1 1
2 2
0
f( )
′
+ ′
+ ′
=
′ ′ + ′ ′ + ′ ′ =
′ ′′+ ′ ′′+ ′ ′′ =
v y
v y
v y
v y
v y
v y
v y
v y
v y
x
1 1
2 2
3 3
1 1
2 2
3 3
1 1
2 2
3 3
0
0
f( )
′vi
′
+ ′
+
+ ′
=
′ ′ + ′ ′ +
+ ′ ′ =
′
+ ′
+
+ ′
=
′
+ ′
+
+ ′
=
−
−
−
−
−
−
v y
v y
v y
v y
v y
v y
v y
v y
v y
v y
v y
v y
n n
n n
n
n
n n
n
n
n
n n
n
1 1
2 2
1 1
2 2
1 1
2
2 2
2
2
1 1
1
2 2
1
1
0
0
0
L
L
M
L
L
(
)
(
)
(
)
(
)
(
)
(
)
f( )
x
′vi
CHAPTER 6: Linear Nonhomogeneous Equations 43

those cases where both methods are applicable, the method of undeter-
mined coefﬁcients is usually the more efﬁcient and, hence, preferable.
As a practical matter, the integration of 
may be impossible to
perform. In such an event other methods (in particular, numerical tech-
niques) must be employed.
Initial-Value Problems
Initial-value problems are solved by applying the initial conditions to the
general solution of the differential equation. It must be emphasized that
the initial conditions are applied only to the general solution and not to
the homogeneous solution yh that possesses all the arbitrary constants that
must be evaluated. The one exception is when the general solution is the
homogeneous solution; that is, when the differential equation under con-
sideration is itself homogeneous. 
Solved Problems
Solved Problem 6.1 Solve 
From Problem 5.1, yh = c1e2x + c2e−x. Here f(x) = 4x2, a second degree
polynomial. Using Equation 6.1, we assume that
(6.13)
Thus, 
and 
Substituting these results into the
differential equation, we have
or, equivalently,
Equating the coefﬁcients of like powers of x, we obtain
−
=
−
−
=
−
−
=
2
4
2
2
0
2
2
0
2
2
1
2
1
0
A
A
A
A
A
A
(
)
(
)
(
)
( )
−
+ −
−
+
−
−
=
+
+
2
2
2
2
2
4
0
0
2
2
2
1
2
1
0
2
A
x
A
A x
A
A
A
x
x
2
2
2
4
2
2
1
2
2
1
0
2
A
A x
A
A x
A x
A
x
−
+
−
+
+
=
(
)
(
)
′′ =
y
A
p
2
2.
′ =
+
y
A x
A
p
2
2
1
y
A x
A x
A
p =
+
+
2
2
1
0
′′ −′ −
=
y
y
y
x
2
4
2.
′v x
i( )
44 DIFFERENTIAL EQUATIONS

Solving this system, we ﬁnd that A2 = −2, A1 = 2, and A0 = −3. Hence
Equation 6.13 becomes 
and the general solution is
Solved Problem 6.2 Solve 
Again by Problem 5.1, 
Here f(x) has the form dis-
played in Case 3 with k1 = 1, k2 = 0, and b = 2. Using Equation 6.3, we
assume that 
(6.14)
Thus, 
Substi-
tuting these results into the differential equation, we have
or, equivalently,
Equating coefﬁcients of like terms, we obtain
−6A + 2B = 1
−2A −6B = 0
Solving this system, we ﬁnd that A = −3/20 and B = 1/20. Then from
Equation 6.14,
and the general solution is
y
x
x
p = −
+
3
20
2
1
20
2
sin
cos
(
)sin
(
)cos
( )sin
( )cos
−
+
+ −
−
=
+
6
2
2
6
2
2
1
2
0
2
A
B
x
B
A
x
x
x
(
sin
cos
)
(
cos
sin
)
( sin
cos
)
sin
−
−
−
−
−
+
=
4
2
4
2
2
2
2
2
2
2
2
2
A
x
B
x
A
x
B
x
A
x
B
x
x
′ =
−
′′ = −
−
y
A
x
B
x
y
A
x
B
x
p
p
2
2
2
2
4
2
4
2
cos
sin
sin
cos
.
and
y
A
x
B
x
p =
+
sin
cos
2
2
y
c e
c e
h
x
x
=
+
−
1
2
2
.
′′ −′ −
=
y
y
y
x
2
2
sin
.
y
y
y
c e
c e
x
x
h
p
x
x
=
+
=
+
−
+
−
−
1
2
2
2
2
2
3
y
x
x
p = −
+
−
2
2
3
2
CHAPTER 6: Linear Nonhomogeneous Equations 45

Solved Problem 6.3 Solve 
This is a third-order equation with
It follows from Equation 6.8 that
(6.15)
Here y1 = 1, y2 = cos x, y3 = sin x, and f(x) = sec x, so Equation 6.10 be-
comes
Solving this set of equations simultaneously, we obtain
and 
Thus, 
Substituting these values into Equation 6.15, we obtain
The general solution is therefore
y
y
y
c
c
x
c
x
x
x
x
x
x
x
h
p
=
+
=
+
+
+
+
−
+
1
2
3
cos
sin
ln | sec
tan
|
cos
(sin )ln | cos
|
y
x
x
x
x
x
x
p =
+
−
+
ln | sec
tan
|
cos
(sin )ln | cos
|
v
v dx
xdx
x
x
v
v dx
dx
x
v
v dx
xdx
x
x dx
x
1
1
2
2
3
3
1
=
′
=
=
+
=
′
=
−
= −
=
′
=
−
= −
=
∫
∫
∫
∫
∫
∫
∫
sec
ln | sec
tan
|
tan
sin
cos
ln | cos
|
′ = −
v
x
3
tan .
′ = −
v2
1,
′ =
v
x
1
sec ,
′
+ ′
+ ′
=
′
+ ′ −
+ ′
=
′
+ ′ −
+ ′ −
=
v
v
x
v
x
v
v
x
v
x
v
v
x
v
x
x
1
2
3
1
2
3
1
2
3
1
0
0
0
0
( )
(cos )
(sin )
( )
( sin )
(cos )
( )
( cos )
( sin )
sec
y
v
v
x
v
x
p =
+
+
1
2
3
cos
sin
y
c
c
x
c
x
h =
+
+
1
2
3
cos
sin
′′′ + ′ =
y
y
x
sec .
y
c e
c e
x
x
x
x
=
+
−
+
−
1
2
2
3
20
2
1
20
2
sin
cos
46 DIFFERENTIAL EQUATIONS

Chapter 7
Applications of
Second-Order
Linear
Differential
Equations
In This Chapter:
✔
Spring Problems
✔
Electrical Circuit Problems
✔
Buoyancy Problems
✔
Classifying Solutions
✔
Solved Problems
Spring Problems
The simple spring system shown in Figure 7-1 consists of a mass m at-
tached to the lower end of a spring that is itself suspended vertically from
a mounting. The system is in its equilibrium position when it is at rest.
The mass is set in motion by one or more of the following means: dis-
placing the mass from its equilibrium position, providing it with an ini-
tial velocity, or subjecting it to an external force F(t).
47
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Hooke’s law: The restoring force F of a spring is equal and opposite to
the forces applied to the spring and is proportional to the extension (con-
traction) l of the spring as a result of the applied force; that is, F = −kl,
where k denotes the constant of proportionality, generally called the
spring constant.
Example 7.1. A steel ball weighing 128 lb is suspended from a spring,
whereupon the spring is stretched 2 ft from its natural length. The applied
force responsible for the 2-ft displacement is the weight of the ball, 128 lb.
Thus, F = −128 lb. Hooke’s law then gives −128 = −k(2), or k = 64 lb/ft.
For convenience, we choose the downward direction as the positive
direction and take the origin to be the center of gravity of the mass in the
equilibrium position. We assume that the mass of the spring is negligible
and can be neglected and that air resistance, when present, is proportion-
al to the velocity of the mass. Thus, at any time t, there are three forces
acting on the system: (1) F(t), measured in the positive direction; (2) a
restoring force given by Hooke’s law as Fs = −kx, k > 0; and (3) a force
due to air resistance given by Fa = −ax˙, a > 0, where a is the constant of
48 DIFFERENTIAL EQUATIONS
Figure 7-1

proportionality. Note that the restoring force Fs always acts in a direction
that will tend to return the system to the equilibrium position: if the mass
is below the equilibrium position, then x is positive and −kx is negative;
whereas if the mass is above the equilibrium position, then x is negative
and −kx is positive. Also note that because a > 0 the force Fa due to air
resistance acts in the opposite direction of the velocity and thus tends to
retard, or damp, the motion of the mass.
It now follows from Newton’s second law (see Chapter Three) that
, or
(7.1)
If the system starts at t = 0 with an initial velocity v0 and from an initial
position x0, we also have the initial conditions
(7.2)
The force of gravity does not explicitly appear in 7.1, but it is pres-
ent nonetheless. We automatically compensated for this force by mea-
suring distance from the equilibrium position of the spring. If one wish-
es to exhibit gravity explicitly, then distance must be measured from the
bottom end of the natural length of the spring. That is, the motion of a vi-
brating spring can be given by
if the origin, x = 0, is the terminal point of the unstretched spring before
the mass m is attached.
Electrical Circuit Problems
The simple electrical circuit shown in Figure 7-2 consists of a resistor R
in ohms; a capacitor C in farads; an inductor L in henries; and an elec-
tromotive force (emf) E(t) in volts, usually a battery or a generator, all
connected in series. The current I ﬂowing through the circuit is measured
in amperes and the charge q on the capacitor is measured in coulombs.
˙˙
˙
( )
x
a
m x
k
m x
g
F t
m
+
+
=
+
x
x
x
v
( )
˙( )
0
0
0
0
=
=
˙˙
˙
( )
x
a
m x
k
m x
F t
m
+
+
=
mx
kx
ax
F t
˙˙
˙
( )
= −
−
+
CHAPTER 7: Second-Order Linear Differential Equations 49

Kirchhoff’s loop law: The algebraic sum of the voltage drops in a sim-
ple closed electric circuit is zero.
It is known that the voltage drops across a resistor, a capacitor, and
an inductor are respectively RI, (1/C)q, and L(dI/dt) where q is the charge
on the capacitor. The voltage drop across an emf is −E(t). Thus, from
Kirchhoff’s loop law, we have
(7.3)
The relationship between q and I is 
(7.4)
Substituting these values into Equation 7.3, we obtain
(7.5)
The initial conditions for q are
(7.6)
To obtain a differential equation for the current, we differentiate
Equation 7.3 with respect to t and then substitute Equation 7.4 directly
into the resulting equation to obtain
(7.7)
d I
dt
R
L
dI
dt
LC I
L
dE t
dt
2
2
1
1
+
+
=
( )
q
q
dq
dt
I
I
t
( )
( )
0
0
0
0
0
=
=
=
=
d q
dt
R
L
dq
dt
LC q
L E t
2
2
1
1
+
+
=
( )
I
dq
dt
dI
dt
d q
dt
=
=
2
2
RI
L dI
dt
C q
E t
+
+
−
=
1
0
( )
50 DIFFERENTIAL EQUATIONS
Figure 7-2

The ﬁrst initial condition is I(0) = I0. The second initial condition is ob-
tained from Equation 7.3 by solving for dI/dt and then setting t = 0. Thus,
(7.8)
An expression for the current can be gotten either by solving Equation
7.7 directly or by solving Equation 7.5 for the charge and then differ-
entiating that expression.
Buoyancy Problems
Consider a body of mass m submerged either partially or totally in a liq-
uid of weight density r. Such a body experiences two forces, a downward
force due to gravity and a counter force governed by: 
Archimedes’ principle: A body in liquid experiences a buoyant upward
force equal to the weight of the liquid displaced by that body.
Equilibrium occurs when the buoyant force of the displaced liquid
equals the force of gravity on the body. Figure 7-3 depicts the situation
for a cylinder of radius r and height H where h units of cylinder height
are submerged at equilibrium. At equilibrium, the volume of water dis-
dI
dt
L E
R
L I
LC q
t=
=
−
−
0
0
0
1
0
1
( )
CHAPTER 7: Second-Order Linear Differential Equations 51
Figure 7-3

placed by the cylinder is pr2h, which provides a buoyant force of pr2hr
that must equal the weight of the cylinder mg. Thus,
(7.9)
Motion will occur when the cylinder is displaced from its equilibri-
um position. We arbitrarily take the upward direction to be the positive
x-direction. If the cylinder is raised out of the water by x(t) units, as shown
in Figure 7-3, then it is no longer in equilibrium. The downward or neg-
ative force on such a body remains mg but the buoyant or positive force
is reduced to pr2[h −x(t)]r. It now follows from Newton’s second law
that
Substituting 7.9 into this last equation, we can simplify it to 
or 
(7.10)
Classifying Solutions
Vibrating springs, simple electrical circuits, and ﬂoating bodies are all
governed by second-order linear differential equations with constant co-
efﬁcients of the form
(7.11)
For vibrating spring problems deﬁned by Equation 7.1, a1 = a/m, a0 =
k/m, and f(t) = F(t)/m. For buoyancy problems deﬁned by Equation 7.10,
a1 = 0, a0 = pr2r/m, and f(t) ≡0. For electrical circuit problems, the in-
dependent variable x is replaced either by q in Equation 7.5 or I in Equa-
tion 7.7.
The motion or current in all of these systems is classiﬁed as free and
˙˙
˙
( )
x
a x
a x
f t
+
+
=
1
0
˙˙x
r
m
x
+
=
p
r
2
0
mx
r x t
˙˙
( )
= −p
r
2
mx
r
h
x t
mg
˙˙
[
( )]
=
−
−
p
r
2
p
r
r h
mg
2
=
52 DIFFERENTIAL EQUATIONS

undamped when f(t) ≡0 and a1 = 0. It is classi-
ﬁed as free and damped when f(t) is identically
zero but a1 is not zero. For damped motion,
there are three separate cases to consider, ac-
cording as the roots of the associated character-
istic equation (see Chapter Five) are (1) real and
distinct, (2) equal, or (3) complex conjugate.
These cases are respectively classiﬁed as (1)
overdamped, (2) critically damped, and (3) os-
cillatory damped (or, in electrical problems, underdamped). If f(t) is not
identically zero, the motion or current is classiﬁed as forced.
A motion or current is transient if it “dies out” (that is, goes to zero)
as t →∞. A steady-state motion or current is one that is not transient and
does not become unbounded. Free damped systems always yield transient
motions, while forced damped systems (assuming the external force to be
sinusoidal) yield both transient and steady-state motions.
Free undamped motion deﬁned by Equation 7.11 with a1 = 0 and 
f(t) ≡0 always has solutions of the form
(7.12)
which deﬁnes simple harmonic motion. Here c1, c2, and w are constants
with w often referred to as circular frequency. The natural frequency f is 
and it represents the number of complete oscillations per time unit un-
dertaken by the solution. The period of the system of the time required to
complete one oscillation is 
Equation 7.12 has the alternate form
(7.13)
where the amplitude 
, the phase angle f = arctan(c2/c1),
and k is zero when c1 is positive and unity when c1 is negative.
A
c
c
=
+
1
2
2
2
x t
A
t
k
( )
(
)
cos(
)
= −
−
1
w
f
T
f
= 1
f = w
p
2
x t
c
t
c
t
( )
cos
sin
=
+
1
2
w
w
CHAPTER 7: Second-Order Linear Differential Equations 53

Solved Problems
Solved Problem 7.1 A 10-kg mass is attached to a spring, stretching it
0.7 m from its natural length. The mass is started in motion from the 
equilibrium position with an initial velocity of 1 m/sec in the upward di-
rection. Find the subsequent motion, if the force due to air resistance is
N.
Taking g = 9.8m/sec2, we have w = mg = 98 N and k = w/l = 140 N/m.
Furthermore, a = 90 and F(t) ≡0 (there is no external force). Equation 7.1
becomes 
(7.14)
The roots of the associated characteristic equation are l1 = −2 and l2 = 
−7, which are real and distinct; hence this problem is an example of over-
damped motion. The solution of 7.14 is 
The initial conditions are x(0) = 0 (the mass starts at the equilibrium 
position) and x˙(0) = −1 (the initial velocity is in the negative direction).
Applying these conditions, we ﬁnd that 
, so that x =
Note that x →0 as t →∞; thus, the motion is transient.
Solved Problem 7.2 Determine whether a cylinder of radius 4 in, height
10 in, and weight 15 lb can ﬂoat in a deep pool of water of weight densi-
ty 62.5 lb/ft3.
Let h denote the length (in feet) of the submerged portion of the
cylinder at equilibrium. With
ft, it follows from Equation 7.9 that 
Thus, the cylinder will ﬂoat with 10 −8.25 = 1.75 in of length above the
water at equilibrium.
h
mg
r
t
=
=
≈
=
p
r
p
2
1
3
2
15
62 5
0 688
8 25
( )
.
.
.
f
in
r = 1
3
e
e
t
t
−
−
−
1
5
7
2
(
).
c
c
1
2
1
5
= −
= −
x
c e
c e
t
t
=
+
−
−
1
2
2
7
˙˙
˙
x
x
x
+
+
=
9
14
0
−90 ˙x
54 DIFFERENTIAL EQUATIONS

Chapter 8
Laplace
Transforms and
Inverse Laplace
Transforms
In This Chapter:
✔
Deﬁnition of the Laplace Transform
✔
Properties of Laplace Transforms
✔
Deﬁnition of the Inverse Laplace
Transform
✔
Manipulating Denominators
✔
Manipulating Numerators
✔
Convolutions
✔
Unit Step Function
✔
Translations
✔
Solved Problems
55
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Deﬁnition of the Laplace Transform
Let f(x) be deﬁned for 0 ≤x < ∞and let s denote an arbitrary real vari-
able. The Laplace transform of f(x), designated by either  {f(x)} or F(s),
is
(8.1)
for all values of s for which the improper integral converges. Conver-
gence occurs when the limit
(8.2)
exists. If this limit does not exist, the improper integral diverges and f(x)
has no Laplace transform. When evaluating the integral in Equation 8.1,
the variable s is treated as a constant because the integration is with re-
spect to x.
The Laplace transforms for a number of elementary functions are
given in Appendix A.
Properties of Laplace Transforms
Property 8.1 (Linearity). If { f(x)} = F(s) and {g(x)} = G(s), then
for any two constants c1 and c2
{c1 f(x) + c2g(x)} = c1{f(x)} + c2{g(x)}
(8.3)
= c1F(s) + c2G(s)
Property 8.2. If { f(x)} = F(s), then for any constant a
{eaxf(x)} = F(s −a)
(8.4)
Property 8.3. If { f(x)} = F(s), then for any positive integer n
(8.5)
{
( )}
(
)
[ ( )]
x f x
d
ds
F s
n
n
n
n
= −1
lim
( )
R
sx
R
e
f x dx
→∞
−
∫
0
{ ( )}
( )
( )
f x
F s
e
f x dx
sx
=
=
−
∞
∫
0
56 DIFFERENTIAL EQUATIONS

Property 8.4. If { f(x)} = F(s) and if 
exists, then
(8.6)
Property 8.5. If { f(x)} = F(s), then
(8.7)
Property 8.6. If f(x) is periodic with period w, that is, f(x + w) = f(x), then
(8.8) 
Functions of Other Independent Variables
For consistency only, the deﬁnition of the Laplace transform and its prop-
erties, Equations 8.1 through 8.8, are presented for functions of x. They
are equally applicable for functions of any independent variable and are
generated by replacing the variable x in the above equations by any vari-
able of interest. In particular, the counter part of Equation 8.1 for the
Laplace transform of a function of t is
Deﬁnition of the Inverse Laplace Transform
An inverse Laplace transform of F(s) designated by −1{F(s)}, is an-
other function f(x) having the property that {f(x)} = F(s). 
The simplest technique for identifying inverse Laplace transforms is
to recognize them, either from memory or from a table such as in the Ap-
pendix. If F(s) is not in a recognizable form, then occasionally it can be
{ ( )}
( )
( )
f t
F s
e
f t dt
st
=
=
−
∞
∫
0
{ ( )}
( )
f x
e
f x dx
e
sx
s
=
−
−
−
∫
0
1
w
w

f t dt
s F s
x
( )
( )
0
1
∫






=
 1
x f x
F t dt
s
( )
( )


=
∞
∫
lim
( )
x
x
f x
x
→
>
0
0
CHAPTER 8: Laplace Transforms and Inverse Transforms 57

transformed into such a form by algebraic manipulation. Observe from
the Appendix that almost all Laplace transforms are quotients. The rec-
ommended procedure is to ﬁrst convert the denominator to a form that
appears in the Appendix and then the numerator.
Manipulating Denominators
The method of completing the square converts a quadratic polynomial
into the sum of squares, a form that appears in many of the denominators
in the Appendix. In particular, for the quadratic
where k = b/2a and 
.
The method of partial fractions transforms a function of the form
a(s)/b(s), where both a(s) and b(s) are polynomials in s, into the sum of
other fractions such that the denominator of each new fraction is either a
ﬁrst-degree or a quadratic polynomial raised to some power. The method
requires only that the degree of a(s) be less than the degree of b(s) (if this
is not the case, ﬁrst perform long division, and consider the remainder
term) and b(s) be factored into the product of distinct linear and quadrat-
ic polynomials raised to various powers.
The method is carried out as follows. To each factor of b(s) of the
form (s −a)m, assign a sum of m fractions, of the form
To each factor of b(s) of the form (s2 + bs + c)p, assign a sum of p frac-
tions, of the form
B s
C
s
bs
c
B s
C
s
bs
c
B s
C
s
bs
c
p
p
p
1
1
2
2
2
2
2
2
+
+
+
+
+
+
+
+
+
+
+
+
(
)
(
)
L
A
s
a
A
s
a
A
s
a
m
m
1
2
2
−
+
−
+
+
−
(
)
(
)
L
h
c
b
a
=
−(
/
)
2
4
as
bs
c
a s
b
a s
c
a s
b
a s
b
a
c
b
a
a s
b
a
c
b
a
a s
k
h
2
2
2
2
2
2
2
2
2
2
4
2
4
+
+
=
+



+
=
+
+ 








+
−






=
+



+
−




=
+
+
(
)
58 DIFFERENTIAL EQUATIONS

Here Ai, Bj, and Ck (i = 1,2,..., m; j, k = 1,2,..., p) are constants which still
must be determined.
Set the original fraction a(s)/b(s) equal to the sum of the new frac-
tions just constructed. Clear the resulting equation of fractions and then
equate coefﬁcients of like powers of s, thereby obtaining a set of simul-
taneous linear equations in the unknown constants Ai, Bj, and Ck. Final-
ly, solve these equations for Ai, Bj, and Ck. 
Manipulating Numerators
A factor s −a in the numerator may be written in terms of the factor s −
b, where both a and b are constants, through the identity s −a = (s −b) +
(b −a). The multiplicative constant a in the numerator may be written ex-
plicitly in terms of the multiplicative constant b through the identity
Both identities generate recognizable inverse Laplace transforms when
they are combined with:
Property 8.7 (Linearity). If the inverse Laplace transforms of two func-
tions F(s) and G(s) exist, then for any constants c1 and c2, 
Convolutions 
The convolution of two functions f(x) and g(x) is
(8.9)
Theorem 8.1. f(x) * g(x) = g(x) * f(x).
Theorem 8.2. (Convolution Theorem). If {f(x)} = F(s) and {g(x)}
= G(s), then {f(x) * g(x)} = {f(x)} {g(x)} = F(s)G(s)
f x
g x
f t g x
t dt
x
( )
( )
( ) (
)
∗
=
−
∫
0



−
−
−
+
=
+
1
1
2
1
1
2
1
{
( )
( )}
{ ( )}
{ ( )}
c F s
c G s
c
F s
c
G s
a
a
b b
=
( )
CHAPTER 8: Laplace Transforms and Inverse Transforms 59

You Need to Know 
The inverse Laplace transform of a product is
computed using a convolution.
(8.10)
If one of the two convolutions in Equation 8.10 is simpler to calculate,
then that convolution is chosen when determining the inverse Laplace
transform of a product.
Unit Step Function
The unit step function u(x) is deﬁned as
As an immediate consequence of the deﬁnition, we have for any num-
ber c, 
The graph of u(x −c) is given in Figure 8-1.
u x
c
x
c
x
c
(
)
−
=
<
≥


0
1
u x
x
x
( ) =
<
≥


0
0
1
0
 −
=
∗
=
∗
1{ ( ) ( )}
( )
( )
( )
( )
F s G s
f x
g x
g x
f x
60 DIFFERENTIAL EQUATIONS
Figure 8-1

Theorem 8.3.
Translations
Given a function f(x) deﬁned for x ≥0, the function
represents a shift, or translation, of the function f(x) by c units in the pos-
itive x-direction. For example, if f(x) is given graphically by Figure 8-2,
then u(x −c)f(x −c) is given graphically by Figure 8-3.
u x
c f x
c
x
c
f x
c
x
c
(
) (
)
(
)
−
−
=
<
−
≥



0
{ (
)}
.
u x
c
s e cs
−
=
−
1
CHAPTER 8: Laplace Transforms and Inverse Transforms 61
Figure 8-2
Figure 8-3

Theorem 8.4. If F(s) = {f(x)}, then
Conversely, 
Solved Problems
Solved Problem 8.1 Find {eax}.
Using Equation 8.1, we obtain
Note that when s ≤a, the improper integral diverges. (See also entry 7 in
the Appendix.)
Solved Problem 8.2 Find {xe4x}.
This problem can be done three ways.
(a) Using entry 14 of the Appendix with n = 2 and a = 4, we have
directly that 
(b) Set f(x) = x. Using Property 8.2 with a = 4 and entry 2 of the Ap-
pendix, we have
{
}
(
)
xe
s
x
4
2
1
4
=
−
F s
e
e
dx
e
dx
e
a
s
e
a
s
s
a
s
a
sx
ax
R
a s x
R
R
a s x
x
x R
R
a s R
( )
lim
lim
lim
(for
)
(
)
(
)
(
)
=
=
=
−






=
−
−






=
−
>
−
∞
→∞
−
→∞
−
=
=
→∞
−
∫
∫
0
0
0
1
1
 −
−
=
−
−
=
<
−
≥



1
0
{
( )}
(
) (
)
(
)
e
F s
u x
c f x
c
x
c
f x
c
x
c
cs
{ (
) (
)}
( )
u x
c f x
c
e
F s
cs
−
−
=
−
62 DIFFERENTIAL EQUATIONS

and 
(c) Set f(x) = e4x. Using Property 8.3 with n = 1 and the results of
Problem 8.1, or alternatively, entry 7 of the Appendix with a = 4
we ﬁnd that
and 
Solved Problem 8.3 Use partial fractions to decompose
To the linear factors s −2 and s + 1, we associate respectively the
fractions A/(s −2) and B/(s + 1). We set
and, upon clearing fractions, obtain
(8.11)
To ﬁnd A and B, we substitute s = −1 and s = 2 into 8.11, we immediate-
ly obtain A = 5/3 and B = −2/3. Thus,
Solved Problem 8.4 Find  −
+
−
+




1
3
2
1
s
s
s
(
)(
) .
s
s
s
s
s
+
−
+
≡
−
−
+
3
2
1
5 3
2
2 3
1
(
)(
)
/
/
s
A s
B s
+
≡
+
+
−
3
1
2
(
)
(
)
s
s
s
A
s
B
s
+
−
+
≡
−
+
+
3
2
1
2
1
(
)(
)
s
s
s
+
−
+
3
2
1
(
)(
) .
{
}
( )
(
)
xe
F s
d
ds
s
s
x
4
2
1
4
1
4
= −′
= −
−



=
−
F s
f x
e
s
x
( )
{ ( )}
{
}
=
=
=
−


4
1
4
{
}
(
)
(
)
e
x
F s
s
x
4
2
4
1
4
=
−
=
−
F s
f x
x
s
( )
{ ( )}
{ }
=
=
=


1
2
CHAPTER 8: Laplace Transforms and Inverse Transforms 63

No function of this form appears in the Appendix. Using the results
of Problem 8.3 and Property 8.7, we obtain



−
−
−
−
+
−
+






=
−


−
+


=
−
1
1
1
2
3
2
1
5
3
1
2
2
3
1
1
5
3
2
3
s
s
s
s
s
e
e
x
x
(
)(
)
64 DIFFERENTIAL EQUATIONS

Chapter 9
Solutions 
by Laplace
Transforms
In This Chapter:
✔
Laplace Transforms of Derivatives
✔
Solutions of Linear Differential
Equations with Constant
Coefﬁcients
✔
Solutions of Linear Systems
✔
Solved Problems
Laplace Transforms of Derivatives
Denote {y(x)} by Y(s). Then under very broad conditions, the Laplace
transform of the nth-derivative (n = 1,2,3,...) of y(x) is
(9.1)
If the initial conditions on y(x) at x = 0 are given by 
(9.2)
y
c
y
c
y
c
n
n
( )
,
( )
,
,
( )
(
)
0
0
0
0
1
1
1
=
′
=
=
−
−
K
 d y
dx
s Y s
s
y
s
y
sy
y
n
n
n
n
n
n
n






=
−
−
′
−
−
−
−
−
−
−
( )
( )
( )
( )
( )
(
)
(
)
1
2
2
1
0
0
0
0
L
65
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

then (9.1) can be rewritten as
(9.3)
For the special cases of n = 1 and n = 2, Equation 9.3 simpliﬁes to
(9.4)
(9.5)
Note!
Laplace transforms convert differential equations
into algebraic equations.
Solutions of Linear Differential Equations 
with Constant Coefﬁcients
Laplace transforms are used to solve initial-value problems given by the
nth-order linear differential equation with constant coefﬁcients
(9.6)
together with the initial conditions speciﬁed in Equation 9.2. First, take
the Laplace transform of both sides of Equation 9.6, thereby obtaining an
algebraic equation for Y(s). Then solve for Y(s) algebraically, and ﬁnal-
ly take inverse Laplace transforms to obtain y(x) = −1{Y(s)}. 
Unlike previous methods, where ﬁrst the
differential equation is solved and then the
initial conditions are applied to evaluate 
the arbitrary constants, the Laplace trans-
form method solves the entire initial-value
problem in one step. There are two excep-
tions: when no initial conditions are speci-
ﬁed and when the initial conditions are not
at x = 0. In these situations, c0 through cn−1
in Equations 9.2 and 9.3 remain arbitrary
b d y
dx
b
d
y
dx
b dy
dx
b y
g x
n
n
n
n
n
n
+
+
+
+
=
−
−
−
1
1
1
1
0
L
( )
{
( )}
( )
′′
=
−
−
y
x
s Y s
c s
c
2
0
1
{ ( )}
( )
′
=
−
y x
sY s
c0
 d y
dx
s Y s
c s
c s
c
s
c
n
n
n
n
n
n
n






=
−
−
−
−
−
−
−
−
−
( )
0
1
1
2
2
1
L
66 DIFFERENTIAL EQUATIONS

and the solution to differential equation 9.6 is found in terms of these con-
stants. They are then evaluated separately when appropriate subsidiary
conditions are provided.
Solutions of Linear Systems
Laplace transforms are useful for solving systems of linear differential
equations; that is, sets of two or more differential equations with an equal
number of unknown functions. If all of the coefﬁcients are constants, then
the method of solution is a straightforward generalization of the one de-
scribed above. Laplace transforms are taken of each differential equation
in the system; the transforms of the unknown functions are determined
algebraically from the resulting set of simultaneous equations; inverse
transforms for the unknown functions are calculated with the help of the
Appendix.
Solved Problems
Solved Problem 9.1 Solve 
y(0) = 0.
Taking the Laplace transform of both sides of this differential equation
and using Property 8.1, we ﬁnd that
Then, us-
ing the Appendix and Equation 9.4 with c0 = 0, we obtain 
from which 
Finally, taking the inverse Laplace transform of Y(s), we obtain
(see Appendix, entry 14).
Solved Problem 9.2 Solve the system
′′ +
+
=
′ + ′ =
=
′
=
=
y
z
y
z
y
y
y
z
0
0
0
0
0
0
0
1
 
;
( )
,
( )
,
( )
y x
Y s
s
xe x
( )
{ ( )}
(
)
=
=
−






=
−
−


1
1
2
5
1
5
Y s
s
( )
(
)
=
−
1
5 2
[
( )
]
( )
sY s
Y s
s
−
−
=
−
0
5
1
5



{ }
{ }
{
}.
′ −
=
y
y
e x
5
5
′ −
=
y
y
e x
5
5 ;
CHAPTER 9: Solutions by Laplace Transforms 67

Denote {y(x)} and {z(x)} by Y(s) and Z(s) respectively. Then,
taking the Laplace transforms of both differential equations, we obtain
or
Solving this last system for Y(s) and Z(s), we ﬁnd that 
Thus, taking inverse transforms, we conclude that
y x
x
z x
x
( )
( )
= −
= +
1
2
1
1
2
2
2
Y s
s
Z s
s
s
( )
( )
= −
=
+
1
1
1
3
3
(
) ( )
( )
( )
( )
s
Y s
Z s
Y s
Z s
s
2
1
0
1
+
+
=
+
=
[
( )
( )
( )]
( )
( )
[
( )
]
[
( )
]
s Y s
s
Z s
Y s
sZ s
sY s
2
0
0
0
1
0
0
−
−
+
+
=
−
+
−
=
68 DIFFERENTIAL EQUATIONS

Chapter 10
Matrices and 
the Matrix
Exponential
In This Chapter:
✔
Matrices and Vectors
✔
Matrix Addition
✔
Scalar and Matrix Multiplication
✔
Powers of a Square Matrix
✔
Differentiation and Integration 
of Matrices
✔
The Characteristic Equation 
of a Matrix
✔
Deﬁnition of the Matrix Exponential 
eAt
✔
Computation of the Matrix
Exponential eAt
✔
Solved Problems
69
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Matrices and Vectors
A matrix (designated by an uppercase boldface letter) is a rectangular ar-
ray of elements arranged in horizontal rows and vertical columns. In this
book, the elements of matrices will always be numbers or functions of
the variable t. If all the elements are numbers, then the matrix is called a
constant matrix.
Example 10.1.
are all matrices. In particular, the ﬁrst matrix is a constant matrix, where-
as the last two are not.
A general matrix A having p rows and n columns is given by
where aij represents that element appearing in the ith row and jth column. 
Note!
Amatrix is square if it has the same number of rows
and columns.
A vector (designated by a lowercase boldface letter) is a matrix having
only one column or one row. (The third matrix given in Example 10.1 is
a vector.)
A =[ ] =












a
a
a
a
a
a
a
a
a
a
ij
n
n
p
p
pn
11
12
1
21
22
2
1
2
L
L
M
M
M
L
1
2
3
4
1
2
1
1
1
2




−






[
]
,
,
cos
e
t
t
t
t
and
70 DIFFERENTIAL EQUATIONS

Matrix Addition
The sum A + B of two matrices A = [aij] and B = [bij] having the same
number of rows and the same number of columns is the matrix obtained
by adding the corresponding elements of A and B. That is,
Matrix addition is both associative and commutative. Thus, 
and
Scalar and Matrix Multiplication
If l is either a number or a function of t, then lA (or, equivalently, Al) is
deﬁned to be the matrix obtained by multiplying every element of A by
l. That is,
Let A = [aij] and B = [bij] be two matrices such that A has r rows and n
columns and B has n rows and p columns. Then the product AB is de-
ﬁned to be the matrix C = [cij] given by 
The element cij is obtained by multiplying the elements of the ith row of
A with the corresponding elements of the jth column of B and summing
the results.
Matrix multiplication is associative and distributes over addition; 
in general, however, it is not commutative. Thus, 
A(BC) = (AB)C, A(B + C) = AB + AC, and (B + C)A = BA + CA.
Important! 
In general, AB ≠BA.
c
a b
i
r j
p
ij
ik
kj
k
n
=
=
=
=∑
1
1 2
1 2
(
, ,
, ;
, ,
, )
K
K
l
l
l
A =
=
[
]
[
]
a
a
ij
ij
A
B
B
A
+
=
+
.
A
B
C
=
+
+
(
)
A
B
C
+
+
(
)
A
B
+
=
+
=
+
[
]
[
]
[
]
a
b
a
b
ij
ij
ij
ij
CHAPTER 10: Matrices and the Matrix Exponential 71

Powers of a Square Matrix
If n is a positive integer and A is a square matrix, then
In particular, A2 = AA and A3 = AAA. By deﬁnition, A0 = I, where
is called an identity matrix. For any square matrix A and identity matrix
I of the same size
AI = IA = A
Differentiation and Integration of Matrices
The derivative of A = [aij] is the matrix obtained by differentiating each
element of A; that is, 
Similarly, the integral of A, either deﬁnite or indeﬁnite, is obtained by in-
tegrating each element of A. Thus, 
A
A
dt
a dt
dt
a dt
ij
a
b
a
b
ij
=








=








∫
∫
∫
∫
and
d
dt
da
dt
ij
A = 



I =


















1
0
0
0
0
0
1
0
0
0
0
0
1
0
0
0
0
0
1
0
0
0
0
0
1
L
L
L
M
O
M
L
L
A
AA
A
n
n
times
=
L
12
4
3
4
72 DIFFERENTIAL EQUATIONS

The Characteristic Equation of a Matrix
The characteristic equation of a square matrix A is the polynomial equa-
tion in l given by
det(A − lI) = 0
(10.1)
where det( ) stands for “the determinant of.” Those values of l which sat-
isfy 10.1, that is, the roots of 10.1, are the eigenvalues of A, a k-fold root
being called an eigenvalue of multiplicity k. 
Theorem 10.1. (Cayley-Hamilton theorem). Any square matrix satis-
ﬁes its own characteristic equation. That is, if
then                
.
Deﬁnition of the Matrix Exponential eAt
For a square matrix A, 
(10.2)
The inﬁnite series 10.2 converges for every A and t, so that eAt is deﬁned
for all square matrices.
Computation of the Matrix Exponential eAt
For actually computing the elements of eAt, 10.2 is not generally useful.
However, it follows (with some effort) from Theorem 10.1, applied to the
matrix At, that the inﬁnite series can be reduced to a polynomial in t.
Thus:
Theorem 10.2. If A is a matrix having n rows and n columns, then
(10.3)
e
t
t
t
t
n
n
n
n
n
n
A
A
A
A
I
=
+
+
+
+
−
−
−
−
−
−
a
a
a
a
1
1
1
2
2
2
1
0
L
e
t
t
n
t
t
n n
n
A
I
A
A
A
≡
+
+
+
=
=
∞
∑
1
1
1
2
1
2 2
0
!
!
!
L
b
b
b
b
b
n
n
n
n
A
A
A
A
I
0
+
+
+
+
+
=
−
−
1
1
2
2
1
0
L
det(
)
A
I
−
=
+
+
+
+
+
−
−
l
l
l
l
l
b
b
b
b
b
n
n
n
n
1
1
2
2
1
0
L
CHAPTER 10: Matrices and the Matrix Exponential 73

where a0, a1,...,an − 1 are functions of t which must be determined for
each A.
Example 10.2. When A has two rows and two columns, then n = 2 and 
(10.4)
When A has three rows and three columns, then n = 3 and
(10.5)
Theorem 10.3. Let A be as in Theorem 10.2, and deﬁne
(10.6)
Then if li is an eigenvalue of At,
(10.7)
Furthermore, if li is an eigenvalue of multiplicity k, k > 1, then the fol-
lowing equations are also valid:
(10.8)
Note that Theorem 10.3 involves the eigenvalues of At; these are t
times the eigenvalues of A. When computing the various derivatives in
10.8, one ﬁrst calculates the appropriate derivatives of the expression
10.6 with respect to l, and then substitutes l = li. The reverse procedure
of ﬁrst substituting l = li (a function of t) into 10.6, and then calculating
the derivatives with respect to t can give erroneous results.
e
d
d r
e
d
d
r
e
d
d
r
i
i
i
i
i
i
k
k
l
l l
l
l l
l
l l
l
l
l
l
l
l
=
=
=
=
=
−
−
=
( )
( )
( )
2
2
1
1
LLLLLLL
e
r
i
i
l
l
= (
)
r
n
n
n
n
( )
l
a
l
a
l
a l
a l
a
≡
+
+
+
+
+
−
−
−
−
1
1
2
2
2
2
1
0
L
e
t
t
t
A
A
A
I
=
+
+
a
a
a
2
2 2
1
0
e
t
t
A
A
I
=
+
a
a
1
0
74 DIFFERENTIAL EQUATIONS

Example 10.3. Let A have four rows and four columns and let l = 5t and
l = 2t be eigenvalues of At of multiplicities three and one, respectively.
Then n = 4 and 
Since l = 5t is an eigenvalue of multiplicity three, it follows that e5t =
r(5t), e5t = r(5t) and e5t = r(5t). Thus, 
Also, since l = 2t is an eigenvalue of multiplicity one, it follows that e2t
= r(2t), or
Notice that we now have four equations in four unknown a’s.
Method of computation: For each eigenvalue li of At, apply Theorem
10.3 to obtain a set of linear equations. When this is done for each eigen-
value, the set of all equations so obtained can be solved for a0,a1,...,
an − 1. These values are then substituted into Equation 10.3 which, in turn,
is used to compute eAt.
Solved Problems
Solved Problem 10.1 Find AB and BA for
Since A has three columns and B has two rows, the product AB is not de-
ﬁned. But
A
B
= 



=
−




1
2
3
4
5
6
7
0
8
1
,
.
e
t
t
t
t
2
3
3
2
2
1
0
2
2
2
=
+
+
+
a
a
a
a
(
)
(
)
(
)
e
t
t
t
e
t
t
e
t
t
t
t
5
3
3
2
2
1
0
5
3
2
2
1
5
3
2
5
5
5
3
5
2
5
6
5
2
=
+
+
+
=
+
+
=
+
a
a
a
a
a
a
a
a
a
(
)
(
)
(
)
(
)
(
)
(
)
r
r
r
( )
( )
( )
l
a l
a l
a l
a
l
a l
a l
a
l
a l
a
=
+
+
+
′
=
+
+
′′
=
+
3
3
2
2
1
0
3
2
2
1
3
2
3
2
6
2
CHAPTER 10: Matrices and the Matrix Exponential 75

Solved Problem 10.2 Find the eigenvalues of 
We have
Hence, 
The characteristic equation of A is l2 −3l −10 = 0, which can be factored
into (l −5)(l + 2) = 0. The roots of the equation are l1 = 5 and l2 = −2,
which are the eigenvalues of A.
Solved Problem 10.3 Find eAt for 
Here n = 2. From Equation 10.4,
(10.9)
and from Equation 10.6, r(l) = a1l + a0. The eigenvalues of At are l1 =
4t and l2 = −2t, which are both of multiplicity one. Substituting these val-
ues successively into Equation 10.7, we obtain the two equations
e
t
e
t
t
t
4
1
0
2
1
0
4
2
=
+
= −
+
−
a
a
a
a
e
t
t
t
t
t
t
A
A
I
=
+
=
+
+




a
a
a
a
a
a
a
a
1
0
1
0
1
1
1
0
9
A = 



1
1
9
1 .
det(
)
det
(
)(
)
( )( )
A
I
−
=
−
−




=
−
−
−
=
−
−
l
l
l
l
l
l
l
1
3
4
2
1
2
3 4
3
10
2
A
I
−
= 


+ −




= 


+ −
−



=
−
−




l
l
l
l
l
l
1
3
4
2
1
0
0
1
1
3
4
2
0
0
1
3
4
2
(
)
A = 



1
3
4
2 .
BA =
−








=
+
+
+
+ −
+ −
+ −




= 



7
0
8
1
1
2
3
4
5
6
7 1
0 4
7 2
0 5
7 3
0 6
8 1
1 4
8 2
1 5
8 3
1 6
7
14
21
4
11
18
( )
( )( )
( )
( )( )
( )
( )( )
( )
(
)( )
( )
(
)( )
( )
(
)( )
76 DIFFERENTIAL EQUATIONS

Solving these equations for a1 and a0, we ﬁnd that
Substituting these values into 10.9 and simplifying, we have
Solved Problem 10.4 Find eAt for 
Since n = 2, it follows from Equations 10.4 and 10.6 that
(10.10)
and r(l) = a1l + a0. The eigenvalues of At are l1 = 2t and l2 = −4t, which
are both of multiplicity one. Substituting these values successively into
Equation 10.7, we obtain 
Solving these equations for a1 and a0, we ﬁnd that
Substituting these values into 10.10 and simplifying, we have
e
e
e
e
e
e
e
e
e
t
t
t
t
t
t
t
t
t
A =
+
−
−
+






−
−
−
−
1
6
4
2
8
8
2
4
2
4
2
4
2
4
2
4
a
a
1
2
4
0
2
4
1
6
1
3 2
=
−
=
+
−
−
t e
e
e
e
t
t
t
t
(
)
(
)
and
e
t
e
t
t
t
2
1
0
4
1
0
2
4
=
+
=
−
+
−
a
a
a
a
(
)
(
)
e
t
t
t
t
t
A
A
I
=
+
=
−
+




a
a
a
a
a
a
a
1
0
0
1
1
1
0
8
2
A =
−




0
1
8
2 .
e
e
e
e
e
e
e
e
e
t
t
t
t
t
t
t
t
t
A =
+
−
−
+






−
−
−
−
1
6
3
3
9
9
3
3
4
2
4
2
4
2
4
2
a
a
1
4
2
0
4
2
1
6
1
3
2
=
−
=
+
−
−
t e
e
e
e
t
t
t
t
(
)
(
)
and
CHAPTER 10: Matrices and the Matrix Exponential 77

Chapter 11
Solutions 
of Linear
Differential
Equations with
Constant
Coefﬁcients by
Matrix Methods
In This Chapter:
✔
Reduction of Linear Differential
Equations to a First-Order System
✔
Solution of the Initial-Value Problem
✔
Solution with No Initial Conditions
✔
Solved Problems
78
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Reduction of Linear Differential Equations 
to a First-Order System
Reduction of One Equation
Every initial-value problem of the form
(11.1)
(11.2)
with bn(t) ≠0, can be reduced to the ﬁrst-order matrix system
(11.3)
where A(t), f(t), c, and the initial time t0 are known. The method of re-
duction is as follows.
Step 1. Rewrite 11.1 so that dnx/dtn appears by itself. Thus,
(11.4)
where aj(t) = −bj(t)/bn(t) ( j = 0,1,..., n − 1) and f(t) = g(t)/bn(t).
Step 2. Deﬁne n new variables (the same number as the order of the orig-
inal differential equation), x1(t), x2(t),..., xn(t), by the equations
(11.5)
These new variables are interrelated by the equations
x t
x t
x
t
dx t
dt
x t
d x t
dt
x
t
d
x t
dt
n
n
n
1
2
3
2
2
1
1
( )
( ),
( )
( ) ,
( )
( ) ,
,
( )
( )
=
=
=
=
−
−
K
d x
dt
a
t d
x
dt
a t x
a
t x
f t
n
n
n
n
n
=
+
+
+
+
−
−
−
1
1
1
1
0
( )
( ) ˙
( )
( )
L
˙( )
( ) ( )
( )
( )
x
A
x
f
x
c
t
t
t
t
t
=
+
=
0
x t
c
x t
c
x
t
c
n
n
( )
,
˙( )
,
,
( )
(
)
0
0
0
1
1
0
1
=
=
=
−
−
K
b t d x
dt
b
t d
x
dt
b t x
b t x
g t
n
n
n
n
n
n
( )
( )
( ) ˙
( )
( );
+
+
+
+
=
−
−
−
1
1
1
1
0
L
CHAPTER 11: Solutions by Matrix Methods 79

(11.6)
Step 3. Express dx
n/dt in terms of the new variables. Proceed by ﬁrst dif-
ferentiating the last equation of 11.5 to obtain
Then, from Equations 11.4 and 11.5,
For convenience, we rewrite this last equation so that x1(t) appears before
x2(t), etc. Thus, 
(11.7)
Step 4. Equations 11.6 and 11.7 are a system of ﬁrst-order linear differ-
ential equations in x1(t), x2(t),..., xn(t). This system is equivalent to the
single matrix equation x˙(t) = A(t)x(t) + f(t) if we deﬁne
(11.8)
(11.9)
f( )
( )
t
f t
≡
















0
0
0
M
x( )
( )
( )
( )
t
x t
x
t
x
t
n
≡












1
2
M
˙ ( )
( )
( )
( )
( )
( )
( )
( )
x
t
a
t x t
a t x
t
a
t x
t
f t
n
n
n
=
+
+
+
+
−
0
1
1
2
1
L
˙ ( )
( )
( )
( ) ˙( )
( ) ( )
( )
( )
( )
( )
( )
( )
( )
( )
x
t
a
t d
x t
dt
a t x t
a
t x t
f t
a
t x
t
a t x
t
a
t x t
f t
n
n
n
n
n
n
=
+
+
+
+
=
+
+
+
+
−
−
−
−
1
1
1
1
0
1
1
2
0
1
L
L
˙ ( )
( )
( )
x
t
d
dt
d
x t
dt
d x t
dt
n
n
n
n
n
=





=
−
−
1
1
˙ ( )
( )
˙ ( )
( )
˙ ( )
( )
˙
( )
( )
x t
x
t
x
t
x t
x t
x
t
x
t
x
t
n
n
1
2
2
3
3
4
1
=
=
=
=
−
LLLLLL
80 DIFFERENTIAL EQUATIONS

(11.10)
Step 5. Deﬁne
Then the initial conditions (11.2) can be given by the matrix (vector)
equation x(t0) = c. This last equation is an immediate consequence of
Equations 11.8, 11.5, and 11.2, since
Observe that if no initial conditions are prescribed, Steps 1 through 4 by
themselves reduce any linear differential equation 11.1 to the matrix
equation x˙(t) = A(t)x(t) + f(t).
Reduction of a System
Aset of linear differential equations with initial conditions also can be re-
duced to system 11.3. The procedure is nearly identical to the method for
reducing a single equation to matrix form; only Step 2 changes. With a
system of equations, Step 2 is generalized so that new variables are de-
ﬁned for each of the unknown functions in the set. 
x
c
( )
( )
( )
( )
( )
˙( )
( )
(
)
t
x t
x
t
x
t
x t
x t
x
t
c
c
c
n
n
n
0
1
0
2
0
0
0
0
1
0
0
1
1
=












=












=












≡
−
−
M
M
M
c =












−
c
c
cn
0
1
1
M
A( )
( )
( )
( )
( )
( )
t
a
t
a t
a
t
a t
a
t
n
≡


















−
0
1
0
0
0
0
0
1
0
0
0
0
0
1
0
0
0
0
0
1
0
1
2
3
1
L
L
L
M
M
M
M
M
L
CHAPTER 11: Solutions by Matrix Methods 81

Solution of the Initial-Value Problem
By the procedure described above, any initial-value problem in which the
differential equations are all linear with constant coefﬁcients, can be re-
duced to the matrix system
(11.11)
where A is the matrix of constants. The solution to Equation 11.11 is
(11.12)
or equivalently
(11.13)
In particular, if the initial-value problem is homogeneous [i.e., f(t) = 0],
then both equations 11.12 and 11.13 reduce to
(11.14)
In the above solutions, the matrices 
, e−As, and eA(t−s) are easily
computed from eAt by replacing the variable t by t − t0, −s, and t −s, re-
spectively. Usually x(t) is obtained quicker from 11.13 than from 11.12,
since the former equation involves one less matrix multiplication. How-
ever, the integrals arising in 11.13 are generally more difﬁcult to evalu-
ate than those in 11.12.
Solution with No Initial Conditions
If no initial conditions are prescribed, the solution of x˙(t) = Ax(t) + f(t) is 
(11.15)
or, when f(t) = 0,
x
k
f
A
A
A
( )
( )
t
e
e
e
t dt
t
t
t
=
+
−
∫
A(
)
e
t t
−0
x
c
A
( )
(
)
t
e
t t
=
−0
x
c
f
A
A
( )
( )
(
)
(
)
t
e
e
s ds
t t
t s
t
t
=
+
−
−
∫
0
0
x
c
f
A
A
A
( )
( )
(
)
t
e
e
e
s ds
t t
t
s
t
t
=
+
−
−
∫
0
0
˙( )
( )
( );
( )
x
Ax
f
x
c
t
t
t
t
=
+
=
0
82 DIFFERENTIAL EQUATIONS

(11.16)
where k is an arbitrary constant vector. All constants of integration can
be disregarded when computing the integral in Equation 11.15, since they
are already included in k.
Solved Problems
Solved Problem 11.1 Put the initial-value problem
into the form of System 11.3.
Following Step 1, we write x¨ = −2x˙ + 8x; hence a1(t) = −2, a0(t) = 8, and
f(t) = 0. Then, deﬁning x1(t) = x and x2(t) = x˙ (the differential equation is
second-order, so we need two new variables), we obtain x˙1 = x2. Follow-
ing Step 3, we ﬁnd
Thus,
These equations are equivalent to the matrix equation x˙(t) = A(t)x(t) + f(t)
if we deﬁne
The differential equation is then equivalent to the matrix equation x˙(t) =
A(t)x(t) + f(t), or simply x˙(t) = A(t)x(t), since f(t) = 0. The initial condi-
tions can be given by x(t0) = c, if we deﬁne t0 = 1 and 
Solved Problem 11.2  Solve x¨ + 2x˙ −8x = 0; x(1) = 2, x˙(1) = 3.
c = 



2
3 .
x
A
f
( )
( )
( )
( )
( )
t
x t
x
t
t
t
≡



≡
−




≡



1
2
0
1
8
2
0
0
˙
˙
x
x
x
x
x
x
1
1
2
2
1
2
0
1
8
2
=
+
=
−
˙
˙
x
d x
dt
x
x
x
x
2
2
2
2
1
2
8
2
8
=
= −
+
= −
+
˙˙
˙
;
( )
,
˙( )
x
x
x
x
x
+
−
=
=
=
2
8
0
1
2
1
3
x
k
A
( )t
e t
=
CHAPTER 11: Solutions by Matrix Methods 83

From Problem 11.1, this initial-value problem is equivalent to Equation
11.11 with
The solution to this system is given by Equation 11.14. For this A, eAt is
given in Problem 10.4; hence, 
Therefore,
and the solution to the original initial-value problem is
x t
x t
e
e
t
t
( )
( )
(
)
(
)
=
=
+
−
−
−
1
2
1
4
1
11
6
1
6
x
c
A
( )
(
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
t
e
e
e
e
e
e
e
e
e
e
e
t
t
t
t
t
t
t
t
t
t
=
=
+
−
−
+










=
+
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
1
2
1
4
1
2
1
4
1
2
1
4
1
2
1
4
1
2
1
1
6
4
2
8
8
2
4
2
3
1
6
2 4
2
4
1
2
1
4
1
2
1
4
1
2
1
4
1
2
1
4
1
2
1
4
1
3
2 8
8
3 2
4
11
6
1
6
22
6
4
6
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
+
−
−
+
+






=
+
−
)










e
e
e
e
e
e
e
e
e
e
t t
t
t
t
t
t
t
t
t
t
A
A
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
−
−
−
−
−
−
−
−
−
−
−
−
−
−
=
=
+
−
−
+






0
1
2
1
4
1
2
1
4
1
2
1
4
1
2
1
4
1
1
6
4
2
8
8
2
4
x
A
f
0
c
( )
( )
( )
( )
( )
t
x t
x
t
t
t
t
≡



≡
−




=
= 



=
1
2
0
0
1
8
2
2
3
1
84 DIFFERENTIAL EQUATIONS

Chapter 12
Power Series
Solutions
In This Chapter:
✔
Second-Order Linear Equations 
with Variable Coefﬁcients
✔
Analytic Functions and Ordinary
Points
✔
Solutions Around the Origin of
Homogenous Equations
✔
Solutions Around the Origin of
Nonhomogeneous Equations
✔
Initial-Value Problems
✔
Solutions Around Other Points
✔
Regular Singular Points 
✔
The Method of Frobenius
✔
Solved Problems
85
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Second-Order Linear Equations 
with Variable Coefﬁcients
A second-order linear differential equation
(12.1)
has variable coefﬁcients when b2(x), b1(x), and b0(x) are not all constants
or constant multiples of one another. If b2(x) is not zero in a given inter-
val, then we can divide by it and rewrite Equation 12.1 as
(12.2)
where P(x) = b1(x)/b2(x), Q(x) = b0(x)/b2(x), and f(x) = g(x)/b2(x). In this
chapter, we describe procedures for solving many equations in the form
of 12.1 and 12.2. These procedures can be generalized in a straightfor-
ward manner to solve higher-order linear differential equations with vari-
able coefﬁcients.
Analytic Functions and Ordinary Points
A function f(x) is analytic at x0 if its Taylor series about x0,
converges to f(x) in some neighborhood of x0.
You Need to Know!
Polynomials, sin x, cos x, and ex are analytic every-
where. 
Sums, differences, and products of polynomials, sin x, cos x, and ex are
also analytic everywhere. Quotients of any two of these functions are an-
alytic at all points where the denominator is not zero.
f
x
x
x
n
n
n
n
( )(
)(
)
!
0
0
0
−
=
∞
∑
′′ +
′ +
=
y
P x y
Q x y
x
( )
( )
( )
f
b
x y
b x y
b
x y
g x
2
1
0
( )
( )
( )
( )
′′ +
′ +
=
86 DIFFERENTIAL EQUATIONS

The point x0 is an ordinary point of the differential equation 12.2 if
both P(x) and Q(x) are analytic at x0. If either of these functions is not an-
alytic at x0, then x0 is a singular point of 12.2.
Solutions Around the Origin of Homogeneous
Equations
Equation 12.1 is homogeneous when g(x) ≡0, in which case Equation
12.2 specializes to 
(12.3)
Theorem 12.1. If x = 0 is an ordinary point of Equation 12.3, then the
general solution in an interval containing this point has the form
(12.4)
where a0 and a1 are arbitrary constants and y1(x) and y2(x) are linearly in-
dependent functions analytic at x = 0.
To evaluate the coefﬁcients an in the solution furnished by Theorem 12.1,
use the following ﬁve-step procedure known as the power series method.
Step 1. Substitute into the left side of the homogeneous differential
equation the power series
(12.5)
together with the power series for 
(12.6)
and
′ =
+
+
+
+
+
+
+
+
+
+
−
+
+
+
y
a
a x
a x
a x
na x
n
a
x
n
a
x
n
n
n
n
n
n
1
2
3
2
4
3
1
1
2
1
2
3
4
1
2
L
L
(
)
(
)
y
a x
a
a x
a x
a x
a x
a x
a
x
a
x
n
n
n
n
n
n
n
n
n
=
=
+
+
+
+
+
+
+
+
+
=
∞
+
+
+
+
∑
0
0
1
2
2
3
3
4
4
1
1
2
2
L
L
y
a x
a y x
a y
x
n
n
n
=
=
+
=
∞
∑
0
0 1
1 2
( )
( )
′′ +
′ +
=
y
P x y
Q x y
( )
( )
0
CHAPTER 12: Power Series Solutions 87

(12.7)
Step 2. Collect powers of x and set the coefﬁcients of each power of
x equal to zero.
Step 3. The equation obtained by setting the coefﬁcient of xn to zero
in Step 2 will contain aj terms for a ﬁnite number of j values. Solve
this equation for the aj term having the largest subscript.  The re-
sulting equation is known as the recurrence formula for the given
differential equation.
Step 4. Use the recurrence formula to sequentially determine aj(j =
2,3,4,...) in terms of a0 and a1.
Step 5. Substitute the coefﬁcients determined in Step 4 into Equa-
tion 12.5 and rewrite the solution in the form of Equation 12.4.
The power series method is only applica-
ble when x = 0 is an ordinary point. Although
the differential equation must be in the form
of Equation 12.2 to determine whether x = 0 is
an ordinary point, once this condition is veri-
ﬁed, the power series method can be used on
either form 12.1 or 12.2. If P(x) or Q(x) in 12.2
are quotients of polynomials, it is often sim-
pler ﬁrst to multiply through by the lowest
common denominator, thereby clearing frac-
tions, and then to apply the power series method to the resulting equation
in the form of Equation 12.1.
Solutions Around the Origin of
Nonhomogeneous Equations
If f(x) in Equation 12.2 is analytic at x = 0, it has a Taylor series expan-
sion around that point and the power series method given above can be
modiﬁed to solve either Equation 12.1 or 12.2. In Step 1, Equations 12.5
through 12.7 are substituted into the left side of the nonhomogeneous
equation; the right side is written as a Taylor series around the origin.
′′ =
+
+
+
+
−
+
+
+
+
+
+
−
+
−
+
y
a
a x
a x
n n
a x
n
n a
x
n
n
a
x
n
n
n
n
n
n
2
6
12
1
1
2
1
2
3
4
2
2
1
1
2
L
L
(
)
(
)( )
(
)(
)
88 DIFFERENTIAL EQUATIONS

Steps 2 and 3 change so that the coefﬁcients of each power of x on the
left side of the equation resulting from Step 1 are set equal to their coun-
terparts on the right side of that equation.  The form of the solution in Step
5 becomes
which has the form speciﬁed in Theorem 4.4. The ﬁrst two terms com-
prise the general solution to the associated homogeneous differential
equation while the last function is a particular solution to the nonhomo-
geneous equation.
Initial-Value Problems
Important!
Solutions to initial-value problems are obtained by
ﬁrst solving the given differential equation and then
applying the speciﬁed initial conditions. 
Solutions Around Other Points
When solutions are required around the ordinary point x0 ≠0, it general-
ly simpliﬁes the algebra if x0 is translated to the origin by the change of
variables t = x −x0. The solution of the new differential equation that re-
sults can be obtained by the power series method about t = 0. Then  the
solution of the original equation is easily gotten by  back-substitution.
Regular Singular Points 
The point x0 is a regular singular point of the second-order homogeneous
linear differential equation
(12.8)
′′ +
′ +
=
y
P x y
Q x y
( )
( )
0
y
a y x
a y
x
y
x
=
+
+
0 1
1 2
3
( )
( )
( )
CHAPTER 12: Power Series Solutions 89

if x0 is not an ordinary point but both (x −x0)P(x) and (x −x0)2Q(x) are
analytic at x0. We only consider regular singular points at x0= 0; if this is
not the case, then the change of variables t = x −x0 will translate x0 to the
origin.
Method of Frobenius
Theorem 12.2. If x0= 0 is a regular singular point of 12.8, then the equa-
tion has at least one solution of the form
where l and an(n = 0,1,2,...) are constants. This solution is valid in an in-
terval 0 < x < R for some real number R.
To evaluate the coefﬁcients an and l in Theorem 12.2, one proceeds as in
the power series method described above.  The inﬁnite series
(12.9)
with its derivatives
(12.10)
and
(12.11)
′′ =
−
+
+
+
+
+
+
+
+
−
+
−
+
+
+
−
+
+
+
+
+
−
−
−
+ −
+ −
+
+ −
y
a x
a x
a x
n
n
a
x
n
n
a x
n
n a
x
n
n
n
n
n
n
l l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
l
(
)
(
)( )
(
)(
)
(
)(
)
(
)(
)
(
)(
)
1
1
2
1
1
2
1
1
0
2
1
1
2
1
3
2
1
1
L
L
′ =
+
+
+
+
+
+
+
−
+
+
+
+
+
+
−
+
−
+ −
+ −
+
+
y
a x
a x
a x
n
a
x
n a x
n
a
x
n
n
n
n
n
n
l
l
l
l
l
l
l
l
l
l
l
l
0
1
1
2
1
1
2
1
1
1
2
1
1
(
)
(
)
(
)
(
)
(
)
L
L
y
x
a x
a x
a x
a x
a x
a
x
a x
a
x
n
n
n
n
n
n
n
n
n
n
n
n
=
=
=
+
+
+
+
+
+
+
=
∞
+
=
∞
+
+
−
+ −
+
+
+ +
∑
∑
l
l
l
l
l
l
l
l
0
0
0
1
1
2
2
1
1
1
1
L
L
y
x
a x
n
n
n
=
=
∞
∑
l
0
90 DIFFERENTIAL EQUATIONS

are substituted into Equation 12.8. Terms with like powers of x are col-
lected together and set equal to zero. When this is done for xn the result-
ing equation is a recurrence formula. Aquadratic equation in l, called the
indicial equation, arises when the coefﬁcient of x0 is set to zero and a0 is
left arbitrary.
The two roots of the indicial equation can be real or complex. If com-
plex they will occur in a conjugate pair and the complex solutions that
they produce can be combined (by using Euler’s relations and the identi-
ty 
) to form real solutions. In this book we shall, for
simplicity, suppose that both roots of the indicial equation are real. Then,
if l is taken as the larger indicial root, l = l1 ≥l2, the method of Frobe-
nius always yields a solution 
(12.12)
to Equation 12.8. [We have written an(l1) to indicate the coefﬁcients pro-
duced by the method when l = l1.]
If P(x) and Q(x) are quotients of polynomials, it is usually easier ﬁrst
to multiply 12.8 by their lowest common denominator and then to apply
the method of Frobenius to the resulting equation. 
General Solution
The method of Frobenius always yields one solution to Equation 12.8 of
the form 12.12. The general solution  (see Theorem 4.2) has the form y =
c1y1(x) + c2y2(x) where c1 and c2 are arbitrary constants and y2(x) is a sec-
ond solution of 12.8 that is linearly independent from y1(x). The method
for obtaining this second solution depends on the relationship between
the two roots of the indicial equation.
Case 1. If l1 −l2, is not an integer, then
(12.13)
where y2(x) is obtained in an identical manner as y1(x) by the method
of Frobenius, using l2 in place of l1.
Case 2. If, l1 = l2, then
(12.14)
y
x
y x
x
x
b
x
n
n
n
2
1
1
0
2
( )
( )ln
(
)
=
+
=
∞
∑
l
l
y
x
x
a
x
n
n
n
2
2
0
2
( )
(
)
=
=
∞
∑
l
l
y x
x
a
x
n
n
n
1
1
0
1
( )
(
)
=
=
∞
∑
l
l
x
x e
a ib
a
ib
x
±
±
=
ln
CHAPTER 12: Power Series Solutions 91

To generate this solution, keep the recurrence formula in terms of l
and use it to ﬁnd the coefﬁcients an (n ≥1) in terms of both l and a0,
where the coefﬁcient a0 remains arbitrary. Substitute these an into
Equation 12.9 to obtain a function y(l, x) which depends on the vari-
ables l and x. Then
(12.15)
Case 3. If l1 −l2 = N, a positive integer, then
(12.16)
To generate this solution, ﬁrst try the method of Frobenius with l2.
If it yields a second solution, then this solution is y2(x), having the
form of 12.16 with d−1 = 0. Otherwise, proceed as in Case 2 to gen-
erate y(l, x), whence
(12.17)
Solved Problems
Solved Problem 12.1 Determine whether x = 0 is an ordinary point of
the differential equation
Here P(x) = −x and Q(x) = 2 are both polynomials; hence they are
analytic everywhere.  Therefore, every value of x, in particular x = 0, is
an ordinary point.
Solved Problem 12.2 Find a recurrence formula for the power series so-
lution around x = 0 for the differential equation given in Problem 12.1.
It follows from Problem 12.1 that x = 0 is an ordinary point of the given
equation, so Theorem 12.1 holds. Substituting Equations 12.5 through
12.7 into the left side of the differential equation, we ﬁnd
′′ −
′ +
=
y
xy
y
2
0
y
x
x
y
x
2
2
2
( )
[(
) ( , )]
= ∂
∂
−
=
l
l
l
l l
y
x
d
y x
x
x
d
x
n
n
n
2
1 1
2
0
2
( )
( )ln
(
)
=
+
−
=
∞
∑
l
l
y
x
y
x
2
1
( )
( , )
= ∂
∂
=
l
l
l l
92 DIFFERENTIAL EQUATIONS

Combining terms that contain like powers of x, we have
The last equation holds if and only if each coefﬁcient in the left-hand side
is zero. Thus, 
In general, 
which is the recurrence formula for this problem.
Solved Problem 12.3 Find the general solution near x = 0 of y −xy +
2y = 0.
Successively evaluating the recurrence formula obtained in Problem 12.2
for n = 0,1,2,..., we calculate
(12.18)
a
a
a
a
a
a
a
a
a
2
0
3
1
4
5
3
1
1
1
6
0
1
20
1
20
1
6
1
120
= −
= −
=
=
=
−



= −
(
)(
)
(
)
,
,
(
)
(
)(
)
n
n
a
n
a
a
n
n
n
a
n
n
n
n
+
+
−
−
=
=
−
+
+
+
+
2
1
2
0
2
2
1
2
2
or
2
2
0
6
0 12
0
20
0
2
0
3
1
4
5
3
a
a
a
a
a
a
a
+
=
+
=
=
−
=
…
,
,
,
,
(
)
(
)
(
)
(
)
[(
)(
)
]
2
2
6
12
20
2
1
2
0
0
0
0
0
2
0
3
1
2
4
3
5
3
2
2
3
a
a
x
a
a
x
a
x
a
a
x
n
n
a
na
a
x
x
x
x
n
n
n
n
n
+
+
+
+
+
−
+
+
+
+
−
+
+
=
+
+
+
+
+
+
+
L
L
L
L
[
(
)
(
)( )
]
[
(
)
]
[
2
6
12
1
1
2
3
1
2
2
3
4
2
2
1
1
1
2
3
2
1
1
0
1
2
2
3
3
a
a x
a x
n n
a x
n
n a
x
x a
a x
a x
na x
n
a
x
a
a x
a x
a x
a x
a
n
n
n
n
n
n
n
n
n
n
+
+
+
+
−
+
+
+
−
+
+
+
+
+
+
+
+
+
+
+
+
+
+
−
+
−
−
+
L
L
L
L
L
n
n
x
+
+ +
=
1
1
0
L]
CHAPTER 12: Power Series Solutions 93

Note that since a4 = 0, it follows from the recurrence formula that all the
even coefﬁcients beyond a4 are also zero. Substituting 12.18 into Equa-
tion 12.5 we have
If we deﬁne
then the general solution can be rewritten as y = a0y1(x) + a1y2(x).
Solved Problem 12.4 Determine whether x = 0 is a regular singular point
of the differential equation
Dividing by 8x2, we have
Neither of these functions is deﬁned at x = 0, so this point is a singular
point.  Furthermore, both
xP x
x Q x
x
( )
( )
(
)
=
=
−
5
4
1
8
1
2
and
P x
x
Q x
x
x
( )
( )
=
=
−
5
4
1
8
1
8
2
and
8
10
1
0
2
x y
xy
x
y
′′ +
′ +
−
=
(
)
y x
x
y
x
x
x
x
x
1
2
2
3
5
7
1
1
6
1
120
1
1680
( )
( )
= −
=
−
−
−
−
and
L
y
a
a x
a x
a x
x
a x
x
a x
a
x
a
x
x
x
x
=
+
−
−
+
−
+
−
−
=
−
+
−
−
−
−




0
1
0
2
1
3
4
1
5
6
1
7
0
2
1
3
5
7
1
6
0
1
120
0
1
1680
1
1
6
1
120
1
1680
L
L
(
)
a
a
a
a
a
a
a
a
6
4
7
5
1
1
8
6
2
30
1
15 0
3
42
1
14
1
120
1
1680
4
56
1
14 0
0
=
=
=
=
−



= −
=
=
=
( )
( )
LLLL
94 DIFFERENTIAL EQUATIONS

are analytic everywhere: the ﬁrst is a constant and the second a polyno-
mial. Hence, both are analytic at x = 0, and this point is a regular singu-
lar point.
Solved Problem 12.5 Use the method of Frobenius to ﬁnd one solution
near x = 0 of 
.
Here P(x) = −1/x and Q(x) = 1/x2, so x = 0 is a regular singular point
and the method of Frobenius is applicable. Substituting Equations 12.9
through 12.11 into the left side of the differential equation, as given and
combining coefﬁcients of like powers of x, we obtain
Thus, 
(12.19)
and, in general, 
(12.20)
From Equation 12.19, the indicial equation is (l − 1)2 = 0, which has roots
l1 = l2 = 1. Substituting l = 1 into Equation 12.20 we obtain n2an = 0,
which implies that an = 0, n ≥1. Thus, y1(x) = a0x.
Solved Problem 12.6 Find the general solution near x = 0 of 
.
Here P(x) = −1/(3x) and Q(x) = 1/(3x2); hence, x = 0, is a regular sin-
gular point and the method of Frobenius is applicable. Substituting Equa-
tions 12.9 through 12.11 into the differential equation and simplifying,
we have
Dividing by xl and equating all coefﬁcients to zero, we ﬁnd
x
a
x
a
x
n
n
a
n
n
l
l
l
l
l
l
l
l
l
[
]
[
]
[ (
)
(
)
]
3
4
1
3
2
3
4
1
0
2
0
1
2
1
2
−
+
+
+
+
+
+
−
+
+
+
=
+
+
L
L
0
xy
y
′ +
=
3
2
x y′′ −
[(
)
(
)
]
l
l
+
−
+
+
=
n
n
an
2
2
1
0
(
)
l −
=
1
0
2
0
a
x
a
x
a
x
n
n
a
n
n
l
l
l
l
l
l
l
(
)
[
]
[(
)
(
)
]
−
+
+
+
+
−
+
+
+
=
+
+
1
2
1
0
2
0
1
2
1
2
L
L
x y
xy
y
2
0
′′ −
′ +
=
CHAPTER 12: Power Series Solutions 95

(12.21)
and 
(12.22)
From 12.21, we conclude that the indicial equation is 3l2 −4l + 1 = 0,
which has roots l1 = 1 and l2 = 1/3. Since l1 −l2 = 2/3, the solution is
given by Equations 12.12 and 12.13. Note that for either value of l, Equa-
tion 12.22 is satisﬁed by simply choosing an = 0, n ≥1. Thus,
and the general solution is 
where k1 = c1a0 and k2 = c2a0.
Solved Problem 12.7 Use the method of Frobenius to ﬁnd one solution
near x = 0 of 
Here 
and 
; so, x = 0 is a regular singular
point and the method of Frobenius is applicable.  Substituting Equations
12.9 through 12.11 into the left side of the differential equation, as giv-
en, and combining coefﬁcients of like powers of x, we obtain
Dividing by xl, factoring the coefﬁcient of an, and equating the coefﬁ-
cient of each power of x to zero, we obtain
(12.23)
(
)
l
l
2
0
3
2
0
−
+
=
a
x
a
x
a
a
x
n
n
a
n
a
n
n
n
l
l
l
l
l
l
l
l
l
l
l
[(
)
]
[(
)
]
{[(
)
(
)
]
(
)
}
2
0
1
2
1
0
2
1
3
2
3
2
1
0
−
+
+
−
+
+
+
+
−
+
+
+
+
−
+
=
+
+
−
L
L
Q x
x
( ) = 2
2
P x
x
( ) = −
1
2
x y
x
x y
y
2
2
2
2
0
′′ +
−
′ +
=
(
)
.
y
c y x
c y
x
k x
k x
=
+
=
+
1 1
2 2
1
2
1 3
( )
( )
/
y
x
x
a x
a x
n
n
n
2
1 3
0
0
1 3
( )
/
/
=
=
=
∞
∑
y x
x
a x
a x
n
n
n
1
1
0
0
( ) =
=
=
∞
∑
[ (
)
(
)
]
3
4
1
0
1
2
l
l
+
−
+
+
=
≥
n
n
a
n
n
(
)
3
4
1
0
2
0
l
l
−
+
=
a
96 DIFFERENTIAL EQUATIONS

and, in general, 
or,
(12.24)
From 12.23, the indicial equation is l2 −3l + 2 = 0, which has roots l1
= 2 and l2 = 1. Since l1 −l2 = 1, a positive integer, the solution is given
by Equations 12.12 and 12.16. Substituting l = 2 into 12.24, we have an
= −(1/n)an−1, from which we obtain
and, in general, 
Thus, 
y x
a x
n
x
a x e
n
n
n
x
1
0
2
0
0
2
1
( )
(
)
!
=
−
=
=
∞
−
∑
a
k
a
k
k
= −
(
)
!
.
1
0
a
a
a
a
a
a
a
a
a
1
0
2
1
0
3
2
0
0
1
2
1
2
1
3
1
3
1
2
1
3
= −
= −
=
= −
= −
= −
!
!
!
a
n
a
n
n
n
= −
+
−
≥
−
1
2
1
1
l
(
)
[(
)
][(
)
]
(
)
,
l
l
l
+
−
+
−
+
+
−
=
−
n
n
a
n
a
n
n
2
1
1
0
1
CHAPTER 12: Power Series Solutions 97

Chapter 13
Gamma 
and Bessel
Functions
In this Chapter:
✔
Gamma Function
✔
Bessel Functions
✔
Algebraic Operations on Inﬁnite
Series
✔
Solved Problems
Gamma Function
The gamma function, G(p), is deﬁned for any positive real number p by
(13.1)
Consequently, G(1) = 1 and for any positive real number p,
(13.2)
Furthermore, when p = n, a positive integer,
(13.3)
Γ(
)
!
n
n
+
=
1
Γ
Γ
(
)
( )
p
p
p
+
=
1
Γ( )
p
x
e
dx
p
x
=
−
−
∞
∫
1
0
98
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Thus, the gamma function (which is deﬁned on all positive real numbers)
is an extension of the factorial function (which is deﬁned only on the non-
negative integers).
Equation 13.2 may be rewritten as 
(13.4)
which deﬁnes the gamma function iteratively for all nonintegral negative
values of p. G(0) remains undeﬁned, because
and
It then follows from Equation 13.4 that G(p) is undeﬁned for negative in-
teger values of p.
Table 13.1 lists values of the gamma function in the interval 1 ≤p <
2. These tabular values are used with Equations 13.2 and 13.4 to gener-
ate values of G(p) in other intervals.
Bessel Functions
Let p represent any real number. The Bessel function of the ﬁrst kind of
order p, Jp(x), is 
(13.5)
The function Jp(x) is a solution near the regular singular point x = 0 of
Bessel’s differential equation of order p:
(13.6)
In fact, Jp(x) is that solution of Equation 13.6 guaranteed by Theorem
12.2.
x y
xy
x
p
y
2
2
2
0
′′ +
′ +
−
=
(
)
J
x
x
k
p
k
p
k
k
p
k
p
k
( )
(
)
! (
)
=
−
+
+
+
+
=
∞
∑
1
2
1
2
2
0
Γ
lim
( )
lim
(
)
p
p
p
p
p
→
→
−
−
=
+
= −∞
0
0
1
Γ
Γ
lim
( )
lim
(
)
p
p
p
p
p
→
→
+
+
=
+
= ∞
0
0
1
Γ
Γ
Γ
Γ
( )
(
)
p
p
p
=
+
1
1
CHAPTER 13: Gamma and Bessel Functions 99

100 DIFFERENTIAL EQUATIONS
Table 13.1

Algebraic Operations on Inﬁnite Series
Changing the dummy index. The dummy index in an inﬁnite series can
be changed at will without altering the series. For example,
Change of variables. Consider the inﬁnite series 
If we make
the change of variables j = k + 1, or k = j −1, then
Note that a change of variables generally changes the limits on the sum-
mation. For instance, if j = k + 1, it follows that j = 1 when k = 0, j = ∞,
when k = ∞, and, as k runs from 0 to ∞, j runs from 1 to ∞.
The two operations given above are often used in concert. For ex-
ample,
Here, the second series results from the change of variables j = k + 2 in
the ﬁrst series, while the third series is the result of simply changing the
dummy index in the second series from j to k. Note that all three series
equal
Solved Problems
Solved Problem 13.1  Prove that G(p + 1) = pG(p), p > 0.
Using Equation 13.1 and integration by parts, we have
1
1
1
2
1
3
1
4
1
!
!
!
!
+
+
+
+
=
−
L
e
1
1
1
1
1
1
0
2
2
(
)!
(
)!
(
)!
k
j
k
k
j
k
+
=
−
=
−
=
∞
=
∞
=
∞
∑
∑
∑
1
1
1
0
1
(
)!
!
k
j
k
j
+
=
=
∞
=
∞
∑
∑
1
1
0 (
)!.
k
k
+
=
∞
∑
1
1
1
1
1
1
1
1
1
2
1
3
1
4
1
5
0
0
0
(
)!
(
)!
(
)!
!
!
!
!
!
k
n
p
k
n
p
+
=
+
=
+
=
+
+
+
+
+
=
∞
=
∞
=
∞
∑
∑
∑
L
CHAPTER 13: Gamma and Bessel Functions 101

The result 
is easily obtained by ﬁrst writing rpe−r as rp/er
and using L’Hôpital’s rule.
Solved Problem 13.2 Use the method of Frobenius to ﬁnd one solution
of Bessel’s equation of order p:
Substituting Equations 12.9 through 12.11 into Bessel’s equation and
simplifying, we ﬁnd that 
Thus,
(13.7)
and, in general, 
or
(13.8)
The indicial equation is l2 −p2 = 0, which has roots l1 = p and l2 = −p
(p nonnegative). Substituting l = p into 13.7 and 13.8 and simplifying,
we ﬁnd that a1 = 0 and
a
n
p
n a
n
n
n
= −
+
≥
−
1
2
2
2
(
)
(
)
a
n
p a
n
n
n
= −
+
−
≥
−
1
2
2
2
2
(
)
(
)
l
[(
)
]
,
l +
−
+
=
−
n
p
a
a
n
n
2
2
2
0
(
)
[(
)
]
l
l
2
2
0
2
2
1
0
1
0
−
=
+
−
=
p
a
p
a
x
p
a
x
p
a
x
p
a
a
x
n
p
a
a
n
n
n
l
l
l
l
l
l
l
l
(
)
[(
)
]
{[(
)
]
}
{[(
)
]
}
2
2
0
1
2
2
1
2
2
2
2
0
2
2
2
1
2
0
−
+
+
−
+
+
+
−
+
+
+
+
−
+
+
=
+
+
+
−
L
L
x y
xy
x
p
y
2
2
2
0
′′ +
′ +
−
=
(
)
lim
r
p
r
r e
→∞
−= 0
Γ
Γ
(
)
lim
lim
lim(
)
( )
(
)
p
x
e
dx
x e
dx
x e
px
e
dx
r e
p x
e
dx
p
p
p
x
r
p
x
r
r
p
x r
p
x
r
r
p
r
p
x
+
=
=
=
−
+








=
−
+
+
=
+
−
−
∞
→∞
−
→∞
−
−
−
→∞
−
−
−
∞
∫
∫
∫
∫
1
0
1
1
0
0
0
1
0
1
0
102 DIFFERENTIAL EQUATIONS

Hence, 
and
and, in general, 
Thus, 
It is customary to choose the arbitrary constant a0 as 
Then bringing a0xp inside the brackets and summation, combining, and
ﬁnally using Problem 13.1, we obtain
y x
p
x
x
k
p
k
x
k
p
k
J
x
p
p
k
k
p
k
p
k
k
k
p
k
p
p
k
1
2
2
1
2
2
0
1
2
1
1
2
1
1
2
1
( )
(
)
(
)
! (
)
(
)
! (
)
( )
=
+
+
−
+
+
=
−
+
+
≡
+
+
=
∞
+
+
=
∞
∑
∑
Γ
Γ
Γ
a
p
p
0
1
2
1
=
+
Γ(
) .
=
+
−
+
+
−
+
+






=
∞
∑
a x
x
k p
k
p
k
p
p
p
k
k
k
k
0
2
2
1
1
1
2
1
2
1
(
)
!(
)(
)
(
)(
)
L
a
k p
k
p
k
p
p
a
k
y x
x
a x
x
a
a
x
k
k
k
n
n
n
p
k
k
k
2
2
0
1
0
0
2
2
1
1
2
1
2
1
1
=
−
+
+
−
+
+
≥
=
=
+






=
∞
=
∞
∑
∑
(
)
!(
)(
)
(
)(
)
(
)
( )
L
l
a
p
a
a
p
a
p
p
a
a
p
a
p
p
p
a
2
2
0
4
2
2
4
0
6
2
4
6
0
1
2 1
1
1
2 2
2
1
2 2
2
1
1
2 3
3
1
2 3
3
2
1
=
−
+
= −
+
=
+
+
= −
+
=
−
+
+
+
!(
)
(
)
!(
)(
)
(
)
!(
)(
)(
)
0
1
3
5
7
=
=
=
=
=
a
a
a
a
L
CHAPTER 13: Gamma and Bessel Functions 103

Chapter 14
Numerical
Methods for
First-Order
Differential
Equations
In This Chapter:
✔
Direction Fields
✔
Euler’s Method
✔
General Remarks Regarding
Numerical Methods
✔
Modiﬁed Euler’s Method
✔
Runge-Kutta Method
✔
Adams-Bashforth-Moulton Method
✔
Milne’s Method
✔
Order of a Numerical Method
✔
Numerical Methods for Systems
✔
Solved Problems
104
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Direction Fields
Graphical methods produce plots of solutions to ﬁrst-order differential
equations of the form 
(14.1)
where the derivative appears only on the left side of the equation.
Example 14.1 (a) For the problem y = −y + x + 2, we have f(x, y) = −y
+ x + 2. (b) For the problem y = y + 1, we have f(x, y) = y2 + 1. (c) For
the problem y = 3, we have f(x, y) = 3. Observe that in a particular prob-
lem, f(x, y) may be independent of x, of y, or of x and y.
Equation 14.1 deﬁnes the slope of the solution curve y(x) at any point 
(x, y) in the plane. A line element is a short line segment that begins at the
point (x, y) and has a slope speciﬁed by 14.1; it represents an approxi-
mation to the solution curve through that point. A collection of line ele-
ments is a direction ﬁeld. Note that direction ﬁelds are tedious to draw by
hand, but they can be easily created by many computer algebra systems.
The graphs of solutions to 14.1 are generated from direction ﬁelds by
drawing curves that pass through the points at which line elements are
drawn and also are tangent to those line elements.
Note!
A direction ﬁeld can be used to graphically deter-
mine the behavior of the solution.
If the left side of Equation 14.1 is set equal to a constant, the graph of the
resulting equation is called an isocline. Different constants deﬁne differ-
ent isoclines, and each has the property that all elements emanating from
points on that isocline have the same slope, a slope equal to the constant
that generated the isocline. When they are simple to draw, isoclines yield
many line elements at once which are useful for constructing direction
ﬁelds.
′ =
y
f x y
( , )
CHAPTER 14: Numerical Methods 105

Euler’s Method
If an initial condition of the form
y(x0) = y0
(14.2)
is also speciﬁed, then the only solution curve of Equation 14.1 of inter-
est is the one that passes through the initial point (x0, y0).
To obtain a graphical approximation to
the solution curve of Equations 14.1 and
14.2, begin by constructing a line element at
the initial point (x0, y0) and then continuing
it for a short distance. Denote the terminal
point of this line element as (x1, y1). Then
construct a second line element at (x1,y1) and
continue it a short distance. Denote the ter-
minal point of this second line element as (x2,
y2). Follow with a third line element con-
structed at (x2, y2) and continue it a short distance. The process proceeds
iteratively and concludes when enough of the solution curve has been
drawn to meet the needs of those concerned with the problem.
If the difference between successive x values are equal, that is, if for
a speciﬁed constant h, h = x1 −x0 = x2 −x1 = x3 −x2 = …, then the graph-
ical method given above for a ﬁrst-order initial-value problem is known
as Euler’s method. It satisﬁes the formula
(14.3)
for n = 1,2,3,.... This formula is often written as
(14.4)
where
(14.5)
as required by Equation 14.1.
′ =
y
f x
y
n
n
n
(
,
)
y
y
hy
n
n
n
+ =
+
′
1
y
y
hf x
y
n
n
n
n
+ =
+
1
(
,
)
106 DIFFERENTIAL EQUATIONS

Stability
The constant h in Equations 14.3 and 14.4 is called the step-size, and its
value is arbitrary. In general, the smaller the step-size, the more accurate
the approximate solution becomes at the price of more work to obtain that
solution. Thus, the ﬁnal choice of h may be a compromise between ac-
curacy and effort. If h is chosen too large, then the approximate solution
may not resemble the real solution at all, a condition known as numeri-
cal instability. To avoid numerical instability, Euler’s method is repeat-
ed, each time with a step-size one-half its previous value, until two suc-
cessive approximations are close enough to each other to satisfy the needs
of the solver. 
General Remarks Regarding 
Numerical Methods
A numerical method for solving an initial-value problem is a procedure
that produces approximate solutions at particular points using only the
operations of addition, subtraction, multiplication, division, and func-
tional evaluations. In this chapter, we consider only ﬁrst-order initial-val-
ue problems of the form 
(14.6)
Generalizations to higher-order problems are given later in this chapter.
Each numerical method will produce approximate solutions at the points
x0,x1,x2,..., where the difference between any two successive x-values is
a constant step-size h; that is xn+1 −xn = h (n = 0,1,2,...). Remarks made
previously in this chapter on the step-size remain valid for all the nu-
merical methods presented. 
The approximate solution at xn will be designated by y(xn), or sim-
ply yn. The true solution at xn will be denoted by either Y(xn) or Yn. Note
that once yn is known, Equation 14.6 can be used to obtain y′n as
(14.7)
The simplest numerical method is Euler’s method, described earlier
in this chapter. 
′ =
y
f x
y
n
n
n
(
,
)
′ =
=
y
f x y
y x
y
( , );
(
)
0
0
CHAPTER 14: Numerical Methods 107

A predictor-corrector method is a set of two equations for yn+1. The
ﬁrst equation, called the predictor, is used to predict (obtain a ﬁrst ap-
proximation to) yn+1; the second equation, called the corrector, is then
used to obtain a corrected value (second approximation) to yn+1. In gen-
eral, the corrector depends on the predicted value.
Modiﬁed Euler’s Method
This is a simple predictor-corrector method that uses Euler’s method as
the predictor and then uses the average value of y′ at both the left and right
end points of the interval [xn, xn+1] (n = 0,1,2,...) as the slope of the line
element approximation to the solution over that interval. The resulting
equations are:
For notational convenience, we designate the predicted value of yn+1 by
pyn+1. It then follows from Equation 14.7 that 
(14.8)
The modiﬁed Euler’s method becomes
(14.9)
Runge-Kutta Method
(14.10)
where 
k
hf x
y
k
hf x
h y
k
k
hf x
h y
k
k
hf x
h y
k
n
n
n
n
n
n
n
n
1
2
1
3
2
4
3
1
2
1
2
1
2
1
2
=
=
+
+
=
+
+
=
+
+
(
,
)
(
,
)
(
,
)
(
,
)
y
y
k
k
k
k
n
n
+ =
+
+
+
+
1
1
2
3
4
1
6
2
2
(
)
predictor
corrector
:
:
(
)
py
y
hy
y
y
h py
y
n
n
n
n
n
n
n
+
+
+
=
+
′
=
+
′
+ ′
1
1
1
2
py
f x
py
n
n
n
′
=
+
+
+
1
1
1
(
,
)
predictor
corrector
:
:
(
)
y
y
hy
y
y
h y
y
n
n
n
n
n
n
n
+
+
+
=
+
′
=
+
′
+ ′
1
1
1
2
108 DIFFERENTIAL EQUATIONS

This is not a predictor-corrector method.
Adams-Bashforth-Moulton Method
(14.11)
Milne’s Method
(14.12)
Starting Values
The Adams-Bashforth-Moulton method and Milne’s method require in-
formation at y0, y1, y2, and y3 to start. The ﬁrst of these values is given by
the initial condition in Equation 14.6. The other three starting values are
gotten by the Runge-Kutta method.
Order of a Numerical Method
A numerical method is of order n, where n is a positive
integer, if the method is exact for polynomials of de-
gree n or less. In other words, if the true solution of an
initial-value problem is a polynomial of degree n or
less, then the approximate solution and the true solu-
tion will be identical for a method of order n.
In general, the higher the order, the more accurate the method.
Euler’s method, Equation 14.4, is of order one, the modiﬁed Euler’s
method, Equation 14.9, is of order two, while the other three, Equations
14.10 through 14.12, are fourth-order methods.
predictor
corrector
:
(
)
:
(
)
py
y
h
y
y
y
y
y
h py
y
y
n
n
n
n
n
n
n
n
n
n
+
−
−
−
+
−
+
−
=
+
′ −′
+
′
=
+
′
+
′ + ′
1
3
1
2
1
1
1
1
4
3
2
2
3
4
predictor
corrector
:
(
)
:
(
)
py
y
h
y
y
y
y
y
y
h
py
y
y
y
n
n
n
n
n
n
n
n
n
n
n
n
+
−
−
−
+
+
−
−
=
+
′ −
′
+
′
−
′
=
+
′
+
′ −
′
+ ′
1
1
2
3
1
1
1
2
24 55
59
37
9
24 9
19
5
CHAPTER 14: Numerical Methods 109

Numerical Methods for Systems
First-Order Systems
Numerical methods for solving ﬁrst-order initial-value problems, includ-
ing all of those described previously in this chapter, are easily extended
to a system of ﬁrst-order initial-value problems. These methods are also
applicable to most higher-order initial-value problems, in particular
those that can be transformed to a system of ﬁrst-order differential equa-
tions by the reduction process described in Chapter Eleven.
Standard form for a system of two equations is
(14.13)
We note that, with 
with system 14.13 represents the
second-order initial-value problem
Standard form for a system of three equations is 
(14.14)
If, in such a system, f(x, y, z, w) = z, and g(x, y, z, w) = w, then system
14.14 represents the third-order initial-value problem
The formulas that follow are for systems of two equations in stan-
dard form (14.13). Generalizations to systems of three equations in stan-
dard form (14.14) or systems with four or more equations are straight-
forward.
′′′ =
=
′
=
′′
=
y
r x y z w
y x
y
y x
z
y
x
w
( , , ,
);
(
)
,
(
)
,
(
)
0
0
0
0
0
0
′ =
′ =
′ =
=
=
=
y
f x y z w
z
g x y z w
w
r x y z w
y x
y
z x
z
w x
w
( , , ,
)
( , , ,
)
( , , ,
);
(
)
,
(
)
,
(
)
0
0
0
0
0
0
′′ =
′
=
′
=
y
g x y y
y x
y
y x
z
( , ,
);
(
)
,
(
)
0
0
0
0
′ =
=
y
f x y z
z
( , , )
,
′ =
′ =
=
=
y
f x y z
z
g x y z
y x
y
z x
z
( , , )
( , , );
(
)
,
(
)
0
0
0
0
110 DIFFERENTIAL EQUATIONS

Euler’s Method
(14.15)
Runge-Kutta Method
(14.16)
where
Adams-Bashforth-Moulton Method
(14.17)
Corresponding derivatives are calculated from system 14.13. In particu-
lar,
predictors:
correctors:
py
y
h
y
y
y
y
pz
z
h
z
z
z
z
y
y
h
py
y
y
y
z
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
+
−
−
−
+
−
−
−
+
+
−
−
=
+
′ −
′
+
′
−
′
=
+
′ −
′
+
′
−
′
=
+
′
+
′ −
′
+ ′
1
1
2
3
1
1
2
3
1
1
1
2
24 55
59
37
9
24 55
59
37
9
24 9
19
5
(
)
(
)
(
)
+
+
−
−
=
+
′
+
′ −
′
+ ′
1
1
1
2
24 9
19
5
z
h
pz
z
z
z
n
n
n
n
n
(
)
k
hf x
y
z
l
hg x
y
z
k
hf x
h y
k z
l
l
hg x
h y
k z
l
k
hf x
h y
k
z
l
l
hg
n
n
n
n
n
n
n
n
n
n
n
n
n
n
n
1
1
2
1
2
1
2
1
1
2 1
2
1
2
1
2
1
1
2 1
3
1
2
1
2
2
1
2 2
3
=
=
=
+
+
+
=
+
+
+
=
+
+
+
=
(
,
,
)
(
,
,
)
(
,
,
)
(
,
,
)
(
,
,
)
(x
h y
k
z
l
k
hf x
h y
k z
l
l
hg x
h y
k z
l
n
n
n
n
n
n
n
n
n
+
+
+
=
+
+
+
=
+
+
+
1
2
1
2
2
1
2 2
4
3
3
4
3
3
,
,
)
(
,
,
)
(
,
,
)
y
y
k
k
k
k
z
z
l
l
l
l
n
n
n
n
+
+
=
+
+
+
+
=
+
+
+
+
1
1
2
3
4
1
1
2
3
4
1
6
2
2
1
6
2
2
(
)
(
)
y
y
hy
z
z
hz
n
n
n
n
n
n
+
+
=
+
′
=
+
′
1
1
CHAPTER 14: Numerical Methods 111

(14.18)
The derivatives associated with the predicted values are obtained simi-
larly, by replacing y and z in Equation 14.18 with py and pz, respective-
ly. As in the previous section, four sets of starting values are required for
the Adams-Bashforth-Moulton method. The ﬁrst set comes directly from
the initial conditions; the other three sets are obtained from the Runge-
Kutta method.
Solved Problems
Solved Problem 14.1 Draw two solution curves to the differential equa-
tion 
A direction ﬁeld for this equation is given by Figure 14-1. Two solution
curves are also shown, one that passes through the point (0,0) and a sec-
ond that passes through the point (0,2). Observe that each solution curve
follows the ﬂow of the line elements in the direction ﬁeld.
′ =
−
y
y
x
2
.
′
=
′
=
+
+
+
+
+
+
+
+
y
f x
y
z
z
g x
y
z
n
n
n
n
n
n
n
n
1
1
1
1
1
1
1
1
(
,
,
)
(
,
,
)
112 DIFFERENTIAL EQUATIONS
Figure 14-1

Solved Problem 14.2 Find y(1) for 
y(0) = 2, using Euler’s
method with 
For this problem, x0 = 0, y0 = 2, and f(x, y) = y −x; so Equation 14.5 be-
comes 
Because 
Using Equation 14.4 with n = 0,1,2,3 successively, we now compute the
corresponding y-values.
n = 0: y1 = y0 + hy′0
But y′0 = f(x0, y0) = y0 −x0 = 2 −0 = 2
Hence, 
n = 1: y2 = y1 + hy′1
But y′1 = f(x1, y1) = y1 −x1 =
Hence, y2 =
n = 2: y3 = y2 + hy′2
But y′2 = f(x2, y2) = y2 −x2 =
Hence, y3 =
n = 3: y4 = y3 + hy′3
But y′3 = f(x3, y3) = y3 −x3 =
Hence,y4=
Thus,
Note that the true solution is Y(x) = ex + x + 1, so that 
If we plot (xn, yn) for n = 0,1,2,3, and 4, and then connect successive
points with straight line segments, as done in Figure 14-2, we have an ap-
proximation to the solution curve on [0,1] for this initial-value problem.
Y( )
.
.
1
4 718
≈
y
y
( )
.
1
4 441
4
1137
256
≈
=
≈
237
64
1
4
189
64
1137
256
+
=
(
)
−
=
237
64
3
4
189
64
49
16
1
4
41
16
237
64
+
=
(
)
−
=
49
16
1
2
41
16
5
2
1
4
9
4
49
16
+
=
( )
−
=
5
2
1
4
9
4
y1
1
4
5
2
2
2
=
+
=
( )
x
x
h
x
x
h
x
x
h
x
x
h
1
0
1
4
2
1
1
2
3
2
3
4
4
3
1
=
+
=
=
+
=
=
+
=
=
+
=
h = 1
4 ,
′ =
−
y
y
x
n
n
n.
h = 1
4 .
′ =
−
y
y
x;
CHAPTER 14: Numerical Methods 113

114 DIFFERENTIAL EQUATIONS
Figure 14-2

Chapter 15
Boundary-Value
Problems and
Fourier Series
In This Chapter:
✔
Second-Order Boundary-Value
Problems
✔
Eigenvalue Problems
✔
Sturm-Liouville Problems
✔
Eigenfunction Expansions
✔
Fourier Sine Series
✔
Fourier Cosine Series
✔
Solved Problems
Second-Order Boundary-Value Problems
Standard Form
A boundary-value problem in standard form consists of the second-order
linear differential equation
(15.1)
′′ +
′ +
=
y
P x y
Q x y
x
( )
( )
( )
f
115
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

and the boundary conditions
(15.2)
where P(x), Q(x), and f(x) are continuous in [a, b] and a1, a2, b1, b2, g1,
and g2 are all real constants. Furthermore, it is assumed that a1 and b1 are
not both zero, and also that a2 and b2 are not both zero.
The boundary-value problem is said to be homogeneous if both the
differential equation and the boundary conditions are homogeneous (i.e.,
f(x) ≡0 and g1 = g2 = 0). Otherwise the problem is nonhomogeneous.
Thus a homogeneous boundary-value problem has the form
(15.3)
A somewhat more general homogeneous boundary-value problem than
15.3 is one where the coefﬁcients P(x) and Q(x) also depend on an arbi-
trary constant l. Such a problem has the form
(15.4)
Both 15.3 and 15.4 always admit the trivial solution y(x) ≡0.
Solutions
A boundary-value problem is solved by ﬁrst obtaining the general solu-
tion to the differential equation, using any of the appropriate methods pre-
sented heretofore, and then applying the boundary conditions to evaluate
the arbitrary constants.
Theorem 15.1. Let y1(x) and y2(x) be two linearly independent solutions
of
′′ +
′ +
=
y
P x y
Q x y
( )
( )
0
′′ +
′ +
=
+
′
=
+
′
=
y
P x
y
Q x
y
y a
y a
y b
y b
( , )
( , )
;
( )
( )
( )
( )
l
l
a
b
a
b
0
0
0
1
1
2
2
′′ +
′ +
=
+
′
=
+
′
=
y
P x y
Q x y
y a
y a
y b
y b
( )
( )
;
( )
( )
( )
( )
0
0
0
1
1
2
2
a
b
a
b
a
b
g
a
b
g
1
1
1
2
2
2
y a
y a
y b
y b
( )
( )
( )
( )
+
′
=
+
′
=
116 DIFFERENTIAL EQUATIONS

Nontrivial solutions (i.e., solutions not identically equal to zero) to the
homogeneous boundary-value problem 15.3 exist if and only if the de-
terminant
(15.5)
equals zero.
Theorem 15.2. The nonhomogeneous boundary-value problem deﬁned
by 15.1 and 15.2 has a unique solution if and only if the associated ho-
mogeneous problem 15.3 has only the trivial solution.
In other words, a nonhomogeneous problem has a unique solution
when and only when the associated homogeneous problem has a unique
solution.
Eigenvalue Problems
When applied to the boundary-value problem 15.4, Theorem 15.1 shows
that nontrivial solutions may exist for certain values of l but not for oth-
er values of l.
You Need to Know 
Those values of l for which nontrivial solutions do
exist are called eigenvalues; the corresponding
nontrivial solutions are called eigenfunctions.
Sturm-Liouville Problems
A second-order Sturm-Liouville problem is a homogeneous boundary-
value problem of the form
(15.6)
[ ( )
]
( )
( )
;
p x y
q x y
w x y
′ ′ +
+
=
l
0
a
b
b
a
b
b
1 1
1 1
1 2
1 2
2 1
2 1
2 2
2 2
y a
y a
y
a
y
a
y b
y b
y
b
y
b
( )
( )
( )
( )
( )
( )
( )
( )
+
′
+
′
+
′
+
′
α
α
CHAPTER 15: Boundary-Value Problems and Fourier Series 117

(15.7)
where p(x), p′(x), q(x), and w(x) are continuous on [a, b], and both p(x)
and w(x) are positive on [a, b].
Equation 15.6 can be written in standard form 15.4 by dividing
through by p(x). Form 15.6, when attainable, is preferred, because Sturm-
Liouville problems have desirable features not shared by more general
eigenvalue problems. The second-order differential equation
(15.8)
where a2(x) does not vanish on [a, b], is equivalent to Equation 15.6 if
and only if a′2(x) = a1(x). This condition can always be forced by multi-
plying Equation 15.8 by a suitable factor.
Properties of Sturm-Liouville Problems
Property 15.1. The eigenvalues of a Sturm-Liouville problem are real
and nonnegative.
Property 15.2. The eigenvalues of a Sturm-Liouville problem can be
arranged to form a strictly increasing inﬁnite sequence; that is, 0 ≤l1 <
l2 < l3 < …. Furthermore, ln → ∞as n → ∞.
Property 15.3. For each eigenvalue of a Sturm-Liouville problem, there
exists one and only one linearly independent eigenfunction.
[By Property 15.3 there corresponds to each eigenvalue ln a unique
eigenfunction where the coefﬁcient on the lead term is one; we denote
this eigenfunction by en(x).]
Property 15.4. The set of eigenfunctions {e1(x), e2(x),...} of a Sturm-
Liouville problem satisﬁes the relation
(15.9)
for n ≠m, where w(x) is given in Equation 15.6.
w x e
x e
x dx
n
m
a
b
( )
( )
( )
∫
= 0
a
x y
a x y
a
x y
r x y
2
1
0
0
( )
( )
( )
( )
′′ +
′ +
+
=
l
a
b
a
b
1
1
2
2
0
0
y a
y a
y b
y b
( )
( )
( )
( )
+
′
=
+
′
=
118 DIFFERENTIAL EQUATIONS

Eigenfunction Expansions
A wide class of functions can be represented by inﬁnite series of eigen-
functions of a Sturm-Liouville problem.
Deﬁnition: A function f(x) is piecewise continuous on the open interval
a < x < b if (1) f(x) is continuous everywhere in a < x < b with the possi-
ble exception of at most a ﬁnite number of points x1, x2,..., xn, and (2) at
these points of discontinuity, the right- and left-hand limits of f(x) re-
spectively 
and 
exist ( j = 1,2,..., n).
(Note that a continuous function is piecewise continuous.)
Deﬁnition: A function f(x) is piecewise continuous on the closed inter-
val a ≤x ≤b if (1) it is piecewise continuous on the open interval a < x < b,
(2) the right-hand limit of f(x) exists at x = a and (3) the left-hand limit
of f(x) exists at x = b.
Deﬁnition: A function f(x) is piecewise smooth on [a, b] if both f(x) and
f′(x) are piecewise continuous on [a,b].
Theorem 15.3. If f(x) is piecewise smooth on [a, b] and if {en(x)} is the
set of all eigenfunctions of a Sturm-Liouville problem (see Property
15.3), then
(15.10)
where
(15.11)
The representation 15.10 is valid at all points in the open interval (a, b)
where f(x) is continuous. The function w(x) in 15.11 is given by Equa-
tion 15.6.
c
w x f x e
x dx
w x e
x dx
n
n
a
b
n
a
b
=
∫
∫
( ) ( )
( )
( )
( )
2
f x
c e
x
n n
n
( )
( )
=
=
∞
∑
1
lim
( ),
x
x
x x
j
j
f x
→
<
lim
( )
x
x
x x
j
j
f x
→
>
CHAPTER 15: Boundary-Value Problems and Fourier Series 119

Because different Sturm-Liouville problems usually generate differ-
ent sets of eigenfunctions, a given piecewise smooth function will have
many expansions of the form 15.10. The basic features of all such ex-
pansions are exhibited by the trigonometric series discussed below.
Fourier Sine Series
The eigenfunctions of the Sturm-Liouville problem y″ + ly = 0; y(0) = 0,
y(L) = 0, where L is a real positive number, are en(x) = sin(npx/L) (n =
1,2,3,...). Substituting these functions into 15.10, we obtain
(15.12)
For this Sturm-Liouville problem, w(x) ≡1, a = 0, and b = L; so that 
and 15.11 becomes
(15.13)
The expansion 15.12 with coefﬁcients given by 15.13 is the Fourier sine
series for f(x) on (0, L). 
Fourier Cosine Series
The eigenfunctions of the Sturm-Liouville problem  y″ + ly = 0; y′(0) =
0, y(L) = 0, where L is a real positive number, are e0(x) = 1 and en(x) =
cos(npx/L) (n = 1,2,3,...). Here l = 0 is an eigenvalue with correspond-
ing eigenfunction e0(x) = 1. Substituting these functions into 15.10,
where because of the additional eigenfunction e0(x) the summation now
begins at n = 0, we obtain
(15.14)
f x
c
c
n x
L
n
n
( )
cos
=
+
=
∞
∑
0
1
p
c
L
f x
n x
L dx
n
L
=
∫
2
0
( )sin p
w x e
x dx
n x
L dx
L
n
a
b
L
( )
( )
sin
2
2
0
2
∫
∫
=
=
p
f x
c
n x
L
n
n
( )
sin
=
=
∞
∑
p
1
120 DIFFERENTIAL EQUATIONS

For this Sturm-Liouville problem, w(x) ≡1, a = 0, and b = L; so that 
and
Thus 15.11 becomes
(15.15)
The expansion 15.14 with coefﬁcients given by 15.15 is the Fourier co-
sine series for f(x) on (0, L). 
Solved Problems
Solved Problem 15.1 Solve y″ + 2y′ −3y = 9x; y(0) = 1, y′(1) = 2.
This is a nonhomogeneous boundary-value problem of forms 15.1
and 15.2, where f(x) = 9x, g1 = 1, and g2 = 2. The general solution to the
homogeneous differential equation is y = c1e−3x + c2ex. If we apply ho-
mogeneous boundary conditions, we ﬁnd that c1 = c2 = 0; hence the so-
lution to the homogeneous problem is y ≡0. Since the associated homo-
geneous problem has only the trivial solution, it follows from Theorem
15.2 that the given problem has a unique solution. Solving the differential
equation by the method of Chapter Six, we obtain
Applying the boundary conditions, we ﬁnd 
y
c e
c e
x
x
x
=
+
−
−
−
1
3
2
3
2
c
L
f x dx
c
L
f x
n x
L dx
n
L
n
L
0
0
0
1
2
1 2
=
=
=
∫
∫
( )
( )cos
(
, ,
)
p
K
w x e
x dx
n x
L dx
L
n
a
b
L
( )
( )
cos
2
2
0
2
∫
∫
=
=
p
w x e
x dx
dx
L
a
b
L
( )
( )
0
2
0
∫
∫
=
=
CHAPTER 15: Boundary-Value Problems and Fourier Series 121

whence
Finally, 
Solved Problem 15.2 Find the eigenvalues and eigenfunctions of 
The coefﬁcients of the given differential equation are constants (with
respect to x); hence, the general solution can be found by use of the char-
acteristic equation. We write the characteristic equation in terms of the
variable m, since l now has another meaning. Thus we have m2 −4lm +
4l2 = 0, which has the double root m = 2l; the solution to the differential
equation is y = c1e2lx + c2xe2lx. Applying the boundary conditions and
simplifying, we obtain
c1 = 0       c1(1 + 2l) + c2(2 + 2l) = 0
It now follows that c1 = 0 and either c2 = 0 or l = −1. The choice 
c2 = 0 results in the trivial solution y = 0; the choice l = −1 results in the
nontrivial solution y = c2xe2x, c2 arbitrary. Thus, the boundary-value
problem has the eigenvalue l = −1 and the eigenfunction y = c2xe2x.
Solved Problem 15.3 Find a Fourier sine series for 
on
(0,3).
Using Equation 15.13 with L = 3, we obtain
c
f x
n x dx
n x dx
n x dx
n
n x
n
n
n
n
x
x
=
=
+
=
+
−




=
−




∫
∫
∫
=
=
2
3
3
2
3
0
3
2
3
2
3
0
4
3
3
3
4
2
3
0
3
0
2
2
3
2
3
( )sin
( )sin
( )sin
cos
cos
cos
p
p
p
p
p
p
p
p
f x
x
x
( ) =
≤
>


0
2
2
2
′′ −
′ +
=
=
+ ′
=
y
y
y
y
y
y
4
4
0
0
0
1
1
0
2
l
l
;
( )
,
( )
( )
y
e
e
e
e
e
e
x
x
x
=
−
+
+
+
−
−
−
−
−
(
)
(
)
3
5
5
9
3
3
2
3
3
3
c
e
e
e
c
e
e
e
1
3
2
3
3
3
5
3
5
9
3
=
−
+
=
+
+
−
−
−
c
c
c e
c e
1
2
1
3
2
2
1
3
3
2
+
−
=
−
+
−
=
−
122 DIFFERENTIAL EQUATIONS

Thus Equation 15.12 becomes
Furthermore, 
Hence, 
Since f(x) is piecewise smooth on [0,3] and continuous everywhere in
(0,3) except at x = 2, it follows from Theorem 15.3 that this equality is
valid everywhere in (0,3) except at x = 2.
f x
x
x
x
( )
sin
sin
sin
=
−
+
−




4
1
2
3
3
4
2
3
2
3
3
3
π
p
p
p
L
cos
, cos
, cos
,
2
3
1
2
4
3
1
2
6
3
1
p
p
p
= −
= −
=
K
f x
n
n
n x
n
n
( )
cos
(
)
sin
=
−−




=
∞
∑
4
2
3
1
3
1 p
p
p
CHAPTER 15: Boundary-Value Problems and Fourier Series 123

Appendix
Laplace
Transforms
124
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

APPENDIX: Laplace Transforms 125

126 DIFFERENTIAL EQUATIONS

APPENDIX: Laplace Transforms 127

128 DIFFERENTIAL EQUATIONS

APPENDIX: Laplace Transforms 129

130 DIFFERENTIAL EQUATIONS

APPENDIX: Laplace Transforms 131

132 DIFFERENTIAL EQUATIONS

Index
Adams-Bashforth-Moulton
method, 109, 111–112
Amplitude, 53
Analytic functions, 86–87
Archimedes’ principle, 51
Bernoulli equations, 6, 14
Bessel functions, 99–100
Boundary-value problems, 5,
115–120
Buoyancy problems, 51–52
Characteristic equations, 34–35,
73
Circular frequency, 53
Classifying solutions, 52–53
Coefﬁcients. See constant coefﬁ-
cients; undetermined coefﬁ-
cients; variable coefﬁcients
Completing the square, 58
Constant coefﬁcients, 30
Laplace transforms solutions,
66–67
linear equations, 79–83
Constant matrix, 70
Convolutions, 59–60
Critically damped motion, 53
Damped motion, 53
Decay problems, 20–21
Deﬁning properties, 10–11
Denominators, 58–59
Derivatives, 65–66, 72
Differential equations. See also
linear differential equations
applications, 20–26
classifying, 5–7
deﬁnitions, 2–5
ﬁrst-order, 8–14, 20–26, 105–
112
general solutions, 4–5
notation, 3
order, 3
particular solutions, 4
solutions, 3–5, 8–14
Differential forms, 5–6
Dilution problems, 23–25
Direction ﬁelds, 105
Dummy index, 101
Eigenfunctions, 117, 119–120
Eigenvalue problems, 117
Eigenvalues, 117
Electrical circuit problems, 49–
51
Electrical circuits, 25–26
Equations. See also differential;
linear differential
Bernoulli, 6, 14
characteristic, 34–35, 73
exact, 7, 10–12
homogeneous, 6–7, 9–10, 30,
87–88
indicial, 91
nonhomogeneous, 32, 39–44,
88–89
133
Copyright 2003 by The McGraw-Hill Companies, Inc. Click Here for Terms of Use.

Equations (cont.)
n-th order, 34–35
ordinary differential, 2
partial differential, 2–3
second-order, 34, 35–36
separable, 7
Equilibrium position, 47
Euler’s method, 106, 108, 111
Exact equations, 7, 10–12
Falling body problems, 21–22
First-order differential equations,
8–14
applications, 20–26
numerical methods, 105–112
First-order systems, 79–83, 110
Forced motion, 53
Fourier series, 120–121
Free motion, 52–53
Froebenius, method of, 90–91
Functions
Bessel, 99–100
gamma, 98–99
Gamma functions, 98–99
General solutions, 4–5, 32
Growth problems, 20–21
Homogeneous equations, 6–7, 9–
10, 30, 87–88. See also linear
differential equations
Hooke’s law, 48–49
Identity matrix, 72
Independent variables, 57
Indicial equation, 91
Initial-value problems, 5, 9, 44,
82, 89
Integral, 72
Integrating factors, 11–12
Inverse Laplace transforms, 57–
58
Isoclines, 105
Kirchhoff’s law, 50
Laplace transforms, 56–62, 124–
132
inverse, 57–58
solutions by, 65–67
Laws
Hooke’s, 48–49
Kirchhoff’s, 50–51
Newton’s of cooling, 21
Newton’s second of motion, 22
Linear differential equations, 6,
12–14
ﬁrst-order, 105–112
homogeneous, 30, 34–37, 39–
44
nonhomogeneous, 39–44
reduction to ﬁrst-order system,
79–83
second-order, 47–53, 86, 115–
117
solutions, 34–37, 79–83
theory of solutions, 29–32
Linearly dependent solutions, 31
Linearly independent solutions,
31
Linear systems, 67
Line elements, 105
Matrices, 70–75
Matrix addition, 71
Matrix exponential, 73–75
Matrix multiplication, 71
Matrix solution methods, 79–83
134 DIFFERENTIAL EQUATIONS

Method of Frobenius, 90–91
Method of undetermined coefﬁ-
cients, 40–42
Methods
Adams-Bashforth-Moulton,
109, 111–112
Euler’s, 106, 108, 111
Frobenius, 90–91
modiﬁed Euler’s, 108
numerical for ﬁrst-order equa-
tions, 105–112
predictor-corrector, 108
Runge-Kutta, 108–109, 111
undetermined coefﬁcients, 40–
42
Modiﬁed Euler’s method, 108
Motion, 52–53
Natural frequency, 53
Natural length, 49
Newton’s law of cooling, 21
Newton’s second law of motion,
22
Nonhomogeneous equations, 32,
39–44, 88–89
Notation, 3
nth-order equations, 34–36
Numerators, 59
Numerical instability, 107
Numerical methods, 105–112
Ordinary differential equations, 2
Ordinary points, 87
Orthogonal trajectories, 26
Oscillatory damped motion, 53
Overdamped motion, 53
Partial differential equation, 2–3
Partial fractions, 58–59
Particular solutions, 4
Period, 53
Phase angle, 53
Power series, 86–92
Power series method, 87–88
Predictor-corrector method, 108
Problems
boundary-value, 5, 115–120
buoyancy, 51–52
decay, 20–21
dilution, 23–25
eigenvalue, 117
electrical circuit, 49–51
falling body, 21–22
growth, 20–21
initial-value, 44, 82
spring, 47–49
Sturm-Liouville, 117–118
temperature, 21
Recurrence formula, 88
Regular singular points, 89–90
Runge-Kutta method, 108–109,
111
Scalar multiplication, 71
Second-order equations, 34, 35–
36
Second-order linear differential
equations, 47–53, 86, 115–
117
Separable equations, 7
Simple harmonic motion, 53
Solutions, 3–5
classifying, 52–53
ﬁrst-order differential equa-
tions, 8–14
initial-value problems, 82
Laplace transforms, 65–67
INDEX 135

Solutions (cont.)
linear differential, 34–37, 79–
83
linearly dependent, 31
linearly independent, 31
linear systems, 67
matrix methods, 79–83
no initial conditions, 82–83
particular, 4
power series, 86–92
theory of, 29–32
Spring problems, 47–49
Square matrix, 70
Standard forms, 5–6
Steady-state motion, 53
Step sizes, 107
Sturm-Liouville problems, 117–
118
Temperature problems, 21
Transient motion, 53
Translations, 61–62
Undamped motion, 53
Underdamped motion, 53
Undetermined coefﬁcients, 40–42
Unit step function, 60–61
Variable coefﬁcients, 30, 86
Variation of parameters, 42–44
Vectors, 70
Wronskian, the, 31–32
136 DIFFERENTIAL EQUATIONS

