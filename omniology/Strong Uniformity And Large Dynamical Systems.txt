

Strong Uniformity and 
Large Dynamical Systems

Strong Uniformity and 
Large Dynamical Systems
Jozsef Beck
Rutgers University, USA

Published by
World Scientific Publishing Co. Pte. Ltd.
5 Toh Tuck Link, Singapore 596224
USA office: 27 Warren Street, Suite 401-402, Hackensack, NJ 07601
UK office: 57 Shelton Street, Covent Garden, London WC2H 9HE
Library of Congress Control Number: 2017017762
British Library Cataloguing-in-Publication Data A catalogue record for this book is available from the
British Library.
STRONG UNIFORMITY AND LARGE DYNAMICAL SYSTEMS
Copyright © 2018 by World Scientific Publishing Co. Pte. Ltd.
All rights reserved. This book, or parts thereof, may not be reproduced in any form or by any means,
electronic or mechanical, including photocopying, recording or any information storage and retrieval
system now known or to be invented, without written permission from the publisher.
For photocopying of material in this volume, please pay a copying fee through the Copyright Clearance
Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, USA. In this case permission to photocopy is not
required from the publisher.
ISBN 978-981-4740-74-6

Typeset by Stallion Press 
Email: enquiries@stallionpress.com
Printed in Singapore

Preface
Why does the typical time evolution of a “large” mechanical system (i.e., a
system with many degrees of freedom, like gas in a container), starting from
“off-equilibrium”, approach “equilibrium” in a short time, and remain in
“equilibrium” for a very, very long time? In what sense does “equilibrium”
reflect “randomness”? Basically the same questions were raised in physics in the
second half of the 19th century when Maxwell, Boltzmann and Gibbs developed
the foundations of statistical mechanics. In this book we study the same general
global questions about large (= many-particle) systems, but our approach is
completely different from the well-known probabilistic machinery of statistical
mechanics.
We also use probability theory, but it is not our primary tool. What we do is
at the crossroads of number theory/uniform distribution and dynamical
systems/quantitative ergodic theory. It is pure mathematics with rigorous proofs;
nevertheless, we borrow some motivations and intuitions from physics.
Consider the following concrete (idealized) mechanical model that we may
call “off-equilibriun ideal gas” (or off-equilibrium Bernoulli model of gases).
Assume that there are N particles moving around in a cubic container, bouncing
back and forth on the walls like billiard balls. Let N be large — e.g., in the range
of the Avogadro number, roughly 1024 — so the system imitates the motion of
gas molecules in a box. Assume that the time evolution of the system starts from
an explicit far-from-equilibrium initial point configuration; say, “Big Bang”
where all particles start from the same point, or something similar to Big Bang.
The particles move on straight lines like point billiards until they hit a wall
(“elastic collision”). Two typical point-particles in the 3-space do not collide; so,

we assume that there is no particle–particle interaction. To determine the time
evolution of the system, we have to say something about the initial velocities of
the particles. We consider the most important velocity distribution in physics:
assume that the particles have 3-dimensional Gaussian (= normal) initial velocity
distribution (physicists call it Maxwellian distribution). The initial point
configuration is explicitly given (like Big Bang); the intial velocities of different
particles are chosen independently — this defines a measure (in fact, a product
measure, due to independence) that makes it possible to talk about the “typical”
time evolution of this large billiards-in-a-box system. (This is just the simplest
model; we also study far more general models that mimick “energy dispersal” on
a microscopic level, see Sec. 10; and completely different “closed orbit
systems”, see Secs. 6–7, etc.)
We focus on the following global questions: In what precise sense does the
typical time evolution of this large system (= off-equilibrium ideal gas) approach
“equilibrium”? How fast is the approach to “equilibrium”? Does the system
really remain in “equilibrium” for a very long time? In what precise sense does
“equilibrium” exhibit “randomness”?
Here “equilibrium” means spatial equilibrium, since the Gaussian initial
velocity distribution is already the equilibrium velocity distribution, as it was
discovered by Maxwell.
Statistical mechanics has a complete theory for the probabilistic model of the
equilibrium ideal gas, based on the partition function. Unfortunately it is not
clear at all — to say the least — how to extend that theory for the non-
equilibrium case. Especially that our model is mainly deterministic, due to the
billiard orbits, and only partly random, due to the independent choice of
velocities. This is why we wrote this book.
(Note that there is a large literature of studying the motion of a single
particle, or a few particles, as part of the large system — like the Lorentz gas
models and other scattering billiards (see e.g. in [Ch-Ma2006]). What we do
here is completely different: we focus on the whole system, answering global
questions.)
Here is a brief summary of Boltzmann’s answer to the basic questions.
According to Boltzmann, the first step is to switch from the 3-dimensional cubic
container — that we like to call the “particle space” — to the 6N-dimensional
phase space (each particle has 3 space coordinates and 3 moments), where a
single point represents the microstate of the whole N -particle system at a given

time instant t. Boltzmann introduced the concept of macrostate: macrostates are
the “observable states” — a macrostate is basically a “large set of microstates
that look the same”. Boltzmann’s key insight was that the “equilibrium
macrostate” must contain vastly more microstates than any “off-equilibrium
macrostate”. Thus, it is a reasonable expectation that a system starting from off-
equilibrium — which represents an atypical microstate — evolves through
macrostates occupying progressively larger volumes in phase space, and
eventually reaching the “equilibrium macrostate”. Boltzmann’s explanation why
the system remains in the “equilibrium macrostate” for a very long time was to
combine the so-called Probability Postulate with the fact that the “equilibrium
macrostate” represents the overwhelming majority of the phase space.
Boltzmann’s Probability Postulate states that “the larger the macrostate, the
greater the probability of finding a microstate in it”. And it is complemented
with Boltzmann’s classical definition that “the entropy of the system is the
logarithm of the probability of its macrostate”, carved on Boltzmann’s grave-
stone. (In fact, “Boltzmann’s entropy formula” was formulated by Planck. Note
that in physics literature “probability” is often replaced by the “number of
microstates that look the same for a macroscopic observer”, which is simply the
frequency interpretation of probability.)
Well, this is a great insight/intuition. Many physicists find Boltzmann’s
argument a perfectly convincing explanation that settles the issue.
Mathematicians, on the other hand, point out that Boltzmann’s argument is
nowhere near to a mathematical proof, and call it a framework, a first step
toward the solution. This is what the distinguished mathematician A.I. Khinchin
wrote in 1943 in his book Mathematical Foundations of Statistical Mechanics:
“All existing attempts to give a general proof of this postulate (= Probability
Postulate, including Boltzmann’s definition of entropy) must be considered as an
aggregate of logical and mathematical errors superimposed on a general
confusion in the definition of the basic quantities”; see p. 142 in the English
translation [Kh49]. Unfortunately most physics textbooks and lectures repeat the
old intuition, claiming that it is well-established — there is no need for any
rigorous mathematical theorem. (This is quite troubling, since many physicists
consider Boltzmann’s formula Entropy = k log W the second most important
formula in physics after Einstein’s E = mc2.) The low level of mathematics in
general, or the lack of it, was our main motivation to write this book.
The first logical difficulty in Boltzmann’s argument is that in physics
macrostates are well-defined only in equilibrium. When the system is far from
equilibrium, it is not clear at all how to define macrostates. (This is why we do

not use the concept of macrostate at all; in this book “state of a system” always
means a microstate, which is simply all positions and all velocities at a time
instant.)
The second difficulty is that it basically ignores the dynamical aspect. To put
it in a nutshell: if a system is in an atypical microstate, it does not automatically
evolve into an equilibrium macrostate just because the latter is typical! Indeed,
for a simple pure mathematical illustration consider the sequence Tn(x) = x(n+2)/2
for n ≥ 0, i.e., x, x3/2, x2, x5/2, x3, . . . , which represents the “time evolution” of a
real number x > 0. If x ≥ 2 is a non-square integer, the members of this sequence
are alternately integers and irrational numbers. The integers represent a
negligible (countable) subset of the real numbers, so it is plausible to call the
integers “atypical” and the irrationals “typical”. So if x ≥ 2 is a non-square
integer, in the corresponding sequence the “atypical” members have the same
density as the “typical” members. In other words, starting from an “atypical
microstate” (= non-square integer), the sequence does not evolve into the
“majority macrostate” of “typical microstates”, i.e., the set of irrationals —
instead, it oscillates between the typical and atypical microstates.
A second example comes from the “time evolution” of human society, which
contradicts Boltzmann’s argument. Indeed, a typical country consists of a usually
small upper class (“rich people”), a usually not so small middle class, and a large
lower class (“poor people”); see for example India. If a system is a “large
family” (in a broad sense), and we define “entropy” as the negative of the total
family fortune (e.g., the negative of the total bank accounts, using modern
financial terms), then Boltzmann’s argument would predict entropy increase in
the form that an upper class family (a small minority) would quickly turn into a
middle class family, and later would quickly become a lower class family (like
the overwhelming majority of families), since to be poor is “typical”.
Nevertheless, as history teaches us, upper class families do not evolve: they
usually remain upper class for a long time; there is no entropy increase; there is
no fast approach to equilibrium.
These two examples demonstrate the absurdity of Boltzmann’s argument in
general without any extra condition. So, we definitely need some extra condition.
To solidify Boltzmann’s argument, we have to identify properties of the
dynamics of the system that guarantee the evolution of how atypical (= unlikely)
microstates evolve into typical (= very likely) microstates. We have to answer
the question “why does a probability argument work for the short-time dynamics

of the system?” It means to justify the Probability Postulate on a realistic time
scale, i.e., to justify the following kind of approximation “phase-space
average”≈“short-time average” in a quantitative form. We may call it the “short-
time ergodic problem”.
We may summarize this long book in one sentence: the typical time
evolution of a large off-equilibrium system of non-interacting particles
represents a “kind of” uniquely ergodic time-flow in the configuration space, and
to justify the Probability Postulate, we solve the “short-time ergodic problem” by
proving, and repeatedly applying, “short-time ergodic theorems”. (Of course we
will clarify what “kind of” means.)
Perhaps this surprises the reader, since at first sight traditional ergodic theory
seems to be the perfect tool to handle this kind of problem. So, the reader is
probably wondering: why do we need new “short-time ergodic theorems”?
Before addressing this question, here we briefly elaborate on ergodicity,
including a short historic sketch. The first “ergodic hypothesis” was stated by
Boltzmann, who also was the first to use the terminology. The “naive ergodic
hypothesis” of Boltzmann stated that each surface of constant energy in the
phase space consists of a single trajectory of the system. It was found out soon
that the naive hypothesis was false, since no curve with well-defined arclength
can fill out a whole many dimensional surface of constant energy (a curve with
well-defined arclength has zero 2-dimensional Lebesgue measure).
After this failed attempt, Boltzmann replaced the naive hypothesis with the
“quasi-ergodic hypothesis”, according to which every trajectory of the system,
although not filling completely out the energy surface on which it is situated,
constitutes at least a dense subset of the surface. That is, it gets arbitrarily close
to every point of the surface. However, the quasi-ergodic hypothesis turned out
to be weak to derive the coincidence of the time and the phase-space averages,
so it was eventually rejected.
A mathematical breakthrough came from the proofs of the first so-called
“ergodic theorems” (J. von Neumann and G.D. Birkhoff), which started the
subject of “ergodic theory”; see e.g. the books [Wal82] and [C-F-S82].
Let us return now to the “short-time ergodic problem”, and answer the
question of “how come traditional ergodic theory, and in particular Birkhoff’s
theorem, does not solve the short-time ergodic problem?” Indeed, the message of
Birkhoff’s well-known individual ergodic theorem is exactly the equality
“phase-space average” = “asymptotic time average”. Well, the first problem with

traditional ergodic theory is that “asymptotic time average” means to take the
infinite time limit (i.e., t → ∞), and because Birkhoff’s theorem does not give
any estimation on the error term, it does not say anything about the realistic time
scale.
The second problem is that (traditional measure-theoretic) ergodic theory
ignores zero measure sets, and a fixed initial point configuration (Big Bang, say)
represents a zero set in the phase space.
To solve the “short-time ergodic problem” we do not use traditional ergodic
theory: we develop our own tools (mostly) from scratch. Our key concept is
“strong (and robust) uniformity in the configuration space” that we briefly
explain here as follows. First note that in our models there is no particle–particle
interaction — this is why it suffices to study the 3N-dimensional configuration
space instead of the 6N-dimensional phase space. Note that “robust uniformity”
actually means “dimension-free, complexity-free and start-free strong
uniformity”. The property of “dimension-free” is absolutely crucial here, since
the dimension of the configuration space is extremely high. Moreover,
“complexity-free strong uniformity” means that our theorems hold for arbitrarily
complicated measurable “test sets” in the configuration space. This is equally
important, since as it turns out, even the simplest properties of “equilibrium” and
“randomness” in the particle space (= gas container) are represented by
extremely complicated “test sets” in the configuration space (to be explained
later). Finally, “start-free” is obviously needed, because we want to prove
theorems that hold for arbitrary fixed initial point configurations, representing a
concrete off-equilibrium configuration; e.g., Big Bang. We give the detailed
precise definitions later. (We may say, the starting point of this book was a result
in Uniform Distribution: our solution of the continuous version of Khinchin’s
strong uniformity conjecture; see Sec. 2.)
Another shortcoming of Boltzmann’s argument is that it is basically “soft”;
so, it needs a “hard” quantitative upgrading. We prove quantitative theorems,
which guarantee — under mild condition — that the typical time evolution of
the system exhibits robust uniformity in a short time. The main part of this book
is about the applications of these “short-time ergodic theorems” for large classes
of “kind of” uniquely ergodic time-flows in the configuration space. These
applications can be summarized in four sentences as follows.
From Non-Equilbrium to Equilibrium and Randomness, and beyond. The
family of time evolutions of a large system with noninteracting particles, starting

from off-equilibrium, exhibits robust uniformity in a short time. It means that the
typical time evolution quickly reaches configuration space equilibrium,
demonstrating “advanced randomness”, and the system stays in this state for a
very, very long time (long-term stability). By using our “short-time ergodic
theorems”, we prove both static and dynamic “advanced randomness”; we call
them, respectively, snapshot randomness and time-lapse randomness.
These applications of our “short-time ergodic theorems” for large classes of
“kind of” uniquely ergodic systems explain why the typical time evolution of a
large system, starting from off-equilibrium, quickly reaches equilibrium in such a
way that the laws of equilibrium statistical mechanics “set in” instantly, and hold
on for a very, very long time.
We complete our nutshell summary of this book by the following diagram:
Square Root Fluctuation Equilibrium, CLT and Poisson Snapshot
Equilibrium, where CLT stands for the central limit theorem.
The subject of this book is on the borderline of number theory (in fact,
uniform distribution), dynamical systems (dynamical systems of many non-
interacting particles, mimicking off-equilibrium ideal gas and “energy
spreading” in liquids and solids), and ergodic theory (unique ergodicity on the
high-dimensional torus). Also, the extremely high dimension of the
configuration space requires the application of nontrivial combinatorics. We do
not study hyperbolic systems; nevertheless, our models still exhibit advanced
randomness — snapshot randomness and time-lapse randomness. And
everything happens on a realistic time scale! The message is that we do not
necessarily need hyperbolicity to demonstrate quick approach to advanced
randomness.

Our main tools are Fourier analysis and combinatorics; we also apply some
classical results from probability theory.
This book is written, above all, for the mathematician, but because the
motivation comes from physics, hopefully some physicists — especially those
who are working in non-equilibrium physics — will also find it useful.
The notation is rather standard. We use log for the natural (base e) logarithm,
use log2 for the binary (base 2) logarithm, and for a (usually finite) set A we use
|A| to denote the number of elements of A. For simplicity the d-dimensional
Lebesgue measure in the familiar low dimensions d = 1, 2, and 3 is called,
respectively, length, area, and volume. The d-dimensional Lebesgue measure
with d > 3 is usually denoted by vold. We use 
, 
, and {x} for the lower
integral part, the upper integral part, and the fractional part of a real number x in
this order (so x = 
 + {x}), and we frequently use ||x|| to denote the distance of x
from the nearest integer. We often say “x modulo one”, which (usually) means
the fractional part {x}.

Contents
Preface
Chapter 1.
From Uniform Distribution to the Time-Evolution of Large
Off-Equilibrium Systems
1.
Traditional Uniform Distribution and Weyl’s Criterion
2.
Strong Uniformity
3.
High-Dimensional Configuration Space of Large Systems and
Unrealistic Time Scale
4.
Dimension-Free Strong Uniformity on a Realistic Time Scale
5.
Rapid Approach and Long-Term Stability of Square-Root Equilibrium
6.
Non-ergodic Time-flow: Closed Orbit Spherical Systems
7.
Closed Orbit Polar Systems
8.
Snapshot Randomness (I): Poisson
9.
Proofs of Theorems 4.2 and 4.3
Chapter 2.
General Models
10.
General Model: Unique Ergodicity via Typical Rotations
11.
Asymptotic Time-Lapse Randomness
12.
Short-Term Time-Lapse Randomness: Multiple Mixedupness (I)

13.
Extensions of Theorem 4.2 beyond the Gaussian Case
14.
Extensions of Theorem 4.2 to Nonlinear Curves on the Plane
Chapter 3.
More Applications of Theorem 4.2
15.
Snapshot Randomness (II): Central Limit Theorem
16.
Snapshot Randomness (III) Case of Closed Orbits
17.
Time-Lapse Randomness vs. Snapshot Randomness (I): A Fundamental
Difference
18.
Time-Lapse Randomness vs. Snapshot Randomness (II): A Fundamental
Difference
19.
CLT Time-Lapse Randomness: Upper Bound 246
Chapter 4.
More Results about Randomness and Stability in Equilibrium
20.
Simultaneous Square-Root Equilibrium Relative to Nice Sets (I)
21.
Simultaneous Square-Root Equilibrium Relative to Nice Sets (II)
22.
Simultaneous Square-Root Equilibrium Relative to Nice Sets (III)
23.
On the Square-Root Logarithmic Threshold in the Gaussian Case
24.
Beyond the Applications of Theorem 4.2
25.
The Case of Singular Underlying Measure
Chapter 5.
More Proofs
26.
Proof of Theorem 4.1
27.
Starting the Proofs of Theorems 13.1–13.4
28.
Completing the Proof of Lemma 27.2
29.
Finishing the Proofs of Theorems 13.1–13.4
30.
Starting the Proof of Theorem 14.1
31.
Finishing the Proof of Theorem 14.1
32.
Proof of Theorem 14.2
33.
Multiple Mixedupness (II): Proof of Lemma 12.2

34.
Multiple Mixedupness (III): Proof of Theorem 12.2
References
Index

Chapter 1
From Uniform Distribution to the
Time-Evolution of Large Off-
Equilibrium Systems
1. Traditional Uniform Distribution and Weyl’s
Criterion
We can briefly summarize the book by the following diagram
To explain what the diagram means, we have to begin with Uniform Distribution
(see Secs. 1 and 2) and the high-dimensional configuration space of a large
system (see Sec. 3).
The single most important theorem in Uniform Distribution is (arguably) the
Kronecker–Weyl equidistribution theorem, which is an upgrading of
Kronecker’s density theorem. Kronecker’s density theorem answers a basic
question raised by Dirichlet’s simultaneous diophantine approximation theorem,
and Dirichlet’s theorem is historically the first recurrence type result (i.e., the
first weak ergodic type result). So, the starting point is in fact Dirichlet’s
classical theorem, which goes as follows. Let d ≥ 1 be an arbitrary integer, let α1,
. . . , αd be an arbitrary sequence of d real numbers, let N0 be an arbitrarily large
but fixed integer, and let ε > 0 be an arbitrarily small but fixed real. Then there
are infinitely many positive integers n0 = n0(α1, . . . , αd; ε) such that 
where ||x|| denotes the distance of a real x from the nearest integer. The well-
known pigeonhole principle proof gives the quantitative upper bound 

for the smallest positive integer n0 satisfying (1.1) (here, as usual, 
 denotes the
upper integral part of a real). The qualitative form of Dirichlet’s theorem is
equivalent to the following recurrence type statement: the infinite arithmetic
progression na = (nα1, . . . , nαd), n ≥ 0, starting from the origin 0 ∈ Rd of the d-
space, and taken modulo one, returns arbitrarily close to the origin.
A far-reaching generalization of the recurrence phenomenon was formulated
by Poincaré. Let U be a measure-preserving transformation of a probability
space (Ω, A, µ) (i.e., µ(Ω) = 1). If A ∈ A is an arbitrary measurable subset of Ω
with positive measure, µ(A) > 0, then there is some point x ∈ A and an integer n
≥ 1 with Unx ∈ A. In fact, “almost every” x ∈ A is good in the sense that the set
of bad x’s has µ-measure zero. By choosing Ω to be the d-dimensional unit torus
[0, 1)d, U = U(a) to be the translation by the vector a = (α1, . . . , αd), and A to be
a small ball centered at the origin, Poincaré’s Recurrence Theorem — a
forerunner of the ergodic theorem — clearly implies the qualitative form of
Dirichlet’s theorem.
The next big step is to move from Recurrence to Density. Let b = (β1, . . . ,
βd) ∈ [0, 1)d be an arbitrary point in the d-dimensional unit cube. Under what
condition can we guarantee that the infinite arithmetic progression na = (nα1, . . .
, nαd), n ≥ 0, taken modulo one (i.e., we take the fractional parts of the
coordinates), gets arbitrarily close to b? A simple sufficient and necessary
condition was discovered by Kronecker in 1884. Kronecker’s famous theorem
says that, the infinite arithmetic progression na = (nα1, . . . , nαd), n ≥ 0, taken
modulo one, is dense in the unit torus [0, 1)d if and only if the d + 1 real numbers
1, α1, . . . , αd are linearly independent over the rationals. The latter means that 
The continuous version of Kronecker’s theorem is about the straight line ta, t
≥ 0 modulo one. The continuous version says that ta, t ≥ 0 modulo one (i.e., the
torus line starting from the origin) is dense in the unit torus [0, 1)d if and only if
α1, . . . , αd are independent over the rationals. (Note that [0, 1)d can be
interpreted in two slightly different ways: (1) the half-open unit cube, and (2) the
unit torus. We often mix up the two interpretations; we hope this minor
ambiguity does not confuse the reader.) Since we apply the continuous
Kronecker theorem in Sec. 3 (see Theorem 3.1), we include the following
beautiful proof, due to Bohr. The basic idea is shockingly simple: It suffices to

show that, under the condition of linear independence of α1, . . . , αd, the
complex 
exponential 
sum 
(where 
of 
course 
i 
= 
) 
To prove (1.3), we just take a very high power of the left-hand side sum in (1.3),
evaluate a related integral defined over a very long interval 0 ≤ t ≤ T, and (1.3)
follows via routine calculations.
The first step in the proof of (1.3) is to apply the multinomial theorem
Notice that the condition of linear independence of α1, . . . , αd implies the
following “irreducibility” property of the sum in the last line of (1.4): if (k0(ℓ), k1(ℓ),
. . . , kd
(ℓ) ∈ Zd+1, ℓ = 1, 2 are two distinct (d + 1)-dimensional integral vectors
such that 
then
It is well known from elementary combinatorics that the multinomial theorem in
(1.4) has 
 different multinomial coefficients, and by the “irreducibility”
property (1.5) we cannot reduce the last line in (1.4) to a sum of less than 
terms.
Let

denote the largest multinomial coefficient in the last line of (1.4).
Clearly
We rewrite (1.4) in the short form
where the γr’s are all different and (see (1.6) and (1.7))
Next we consider the following integral related to (1.8)
We use the elementary fact from calculus that for an arbitrary real c ≠ 0,
which implies
Combining (1.10) and (1.11) we obtain that

for all T ≥ T∗, where T∗ is a sufficiently large threshold.
By taking the limit T → ∞ in (1.12), and using (1.9),
Next we take the limit N → ∞; then (1.13) implies
It follows from (1.14) that, given any T0 > 0 and ε > 0, there exists a t > T0 such
that
which completes the proof of the continuous version of Kronecker’s theorem.
Note that the continuous form of Kronecker’s theorem easily implies the
discrete form. Indeed, we can assume, without loss of generality, that in the
discrete form α1, . . . , αd are all between 0 and 1. Let N0 > 0 be arbitrarily large
but fixed. Applying the continuous form for the d + 1 linearly independent
numbers 1, α1, . . . , αd, there exists a real t0 > N0 + 1 such that 

Let n0 denote the nearest integer to t0. Then by (1.15), n0 > N0, and by the
triangle inequality
completing the proof of the discrete version of Kronecker’s theorem.
In the original form of Kronecker’s theorem the starting point was the origin.
Since the torus is translation invariant, Kronecker’s theorem remains true if we
replace the origin with any other starting point in the torus.
The next big step is to upgrade Kronecker’s Density Theorem to Uniformity.
This was done by H. Weyl, who in the process created — almost single-handedly
— the theory of Uniform Distribution (see [We16], and also the books [Ku-
Ni74] and [Dr-Ti97]). Weyl introduced the following basic definition: an infinite
sequence of points x1, x2, x3, . . . in the d-space Rd is said to be uniformly
distributed modulo one if for every axis-parallel box (Cartesian product of
intervals) in the unit cube B = I1 × · · · × Id ⊂ [0, 1)d
where vold denotes the d-dimensional volume.
The proof of Kronecker’s theorem, using complex exponential sums, already
demonstrated the power of Fourier analysis. Weyl formulated 3 criteria for
sequences uniformly distributed modulo one. The most important is criterion (c),
which emphasizes the close relation between Uniform Distribution and Fourier
Analysis. (Fourier Analysis remains a key tool throughout the book.) Weyl’s
criterion. An infinite sequence of points x1, x2, x3, . . . in the d-space Rd is
uniformly distributed modulo one if and only if any of the following three criteria
holds: (a) for all real-valued Riemann-integrable functions f : Id → R with Id =
[0, 1]d, the corresponding Riemann sums converge to the integral 
(b) for all real-valued continuous functions f : Id → R (1.17) holds;
(c) for all complex exponential functions

(1.17) holds.
Here {z} = ({z1}, . . . , {zd}) denotes the vector in [0, 1)d formed by the
fractional parts of the coordinates of a vector z ∈ Rd, dV stands for integration
with respect to the d-dimensional Lebesgue measure, i = 
, and finally n · y =
n1y1 + · · · + ndyd stands for the usual dot product of vectors.
The message of Weyl’s criterion is that there are 4 equivalent ways to
characterize the infinite sequences of points that are uniformly distributed
modulo one (the 4 equivalent ways are (1.16), (a), (b) and (c)).
The proof of Weyl’s criterion is based on a subtle approximation argument,
where the key ingredient is Weierstrass’s well-known approximation theorem
with trigonometric sums (for any ε > 0, every continuous 1-periodic function can
be uniformly ε-approximated by a finite sum of complex exponential functions
fn(y) = e2πin·y, n ∈ Zd). For the details of the proof; see e.g. Drmota–Tichy [Dr-
Ti97].
It is easy to reformulate Weyl’s criterion (c) in the following more familiar
form: an infinite sequence of points x1, x2, x3, . . . in the d-space Rd is uniformly
distributed modulo one if and only if 
for all nonzero lattice points n ∈ Zd \ 0. (Notice that (1.3) was also a complex
exponential sum.)
It is the form (1.18) that most authors call Weyl’s criterion.
The Weyl’s criterion can be easily extended to the continuous case; it was
done by Weyl himself. Let r(t) ∈ Rd be an arbitrary continuous parametrized
curve defined for all 0 ≤ t < ∞. Choosing the analog of (1.17) as our definition,
we say that the curve r(t) ∈ Rd is uniformly distributed modulo one if for every
Riemann integrable function f = f(x1, . . . , xd) defined on the unit torus Id = [0,
1)d we have 
In the special case of the characteristic function f = χS, where S ⊂ Id is a Jordan
measurable subset, the left-hand side of (1.19) is the frequency of the time t the
parametrized curve r(t) — representing the motion of a particle — spends in the
given subset S, and the right-hand side is the volume of S.

(Note that for the class of bounded sets in Rd the following 3 properties are
equivalent: (1) S is Jordan measurable, (2) f = χS is Riemann integrable, (3) the
boundary of S has d-dimensional Lebesgue measure zero.) The curve version of
Weyl’s criterion is the perfect analog of the discrete case (1.18) : (1.19) is
equivalent to
for all n ∈ Zd \ 0.
Note that (1.19) is also equivalent to the alternative weaker requirement that
(1.19) holds for every f = χB, where B runs over the axis-parallel boxes in the
unit cube [0, 1]d (analog of (1.16)), and of course f is defined on the unit torus Id
= [0, 1)d.
A striking illustration of the power of Weyl’s criterion is Weyl’s upgrading of
Kronecker’s density theorem to uniform distribution modulo one; see (1.22) and
(1.23) below. To give due credit to both mathematicians, we refer to it as the
Kronecker–Weyl equidistribution theorem. The Kronecker–Weyl theorem has
two parts: the continuous part and the discrete part, and they both work in every
dimension. For simplicity we start with the 2-dimensional continuous case. Then
the problem is to describe the distribution of a straight line in the plane modulo
one, i.e., the distribution of a torus line in the unit torus, [0, 1)2. If the slope of
the line is rational, then of course the torus line in the unit torus is periodic. On
the other hand, if the slope is irrational (and this is the hard part), then the torus
line is dense in the unit torus [0, 1)2 (proved by Kronecker in 1884), and this was
upgraded in 1916 by H. Weyl to the more subtle property of uniform
distribution.
One may argue that the Kronecker–Weyl equidistribution theorem is an
“ergodic” theorem: it makes a precise statement about the equality of the time-
average and the space-average. (There is, however, a crucial technical difference:
the traditional measure-theoretic ergodic theorems are expressed in terms of the
Lebesgue integral; the Kronecker–Weyl theorem, on the other hand, is restricted
to the Riemann integral. It is true, however, that the Kronecker–Weyl theorem is
the first, and arguably the most important, example of what we call now unique
ergodicity. We will return to unique ergodicity in Sec. 10.) Unlike Birkhoff’s
individual ergodic theorem, which does not have a quantitative form, the
Kronecker–Weyl theorem has quantitative versions (see e.g. the Erdős–Turán–

Koksma inequality in (3.21)).
The general d-dimensional continuous form of the Kronecker–Weyl
equidistribution theorem goes as follows. Let α1, . . . , αd be arbitrary reals, and
write a = (α1, . . . , αd). Consider the straight line ta, −∞ < t < ∞ in the d-space Rd
passing through the origin 0; this straight line modulo one is a torus line in the d-
dimensional unit torus [0, 1)d, d ≥ 2. The continuous Kronecker–Weyl theorem
says that, if α1, . . . , αd are linearly independent over the rationals, then the
straight line ta, 0 < t < ∞ is uniformly distributed modulo one in the d-
dimensional unit torus [0, 1)d. That is, for every Riemann integrable function f
defined 
on 
the 
unit 
torus 
Id 
= 
[0, 
1)d, 
If f = χS, where χS is the 0,1 valued characteristic function of a “not too ugly”
subset S ⊂ [0, 1)d, then the integral on the right-hand side of (1.21) becomes the
(d-dimensional) volume of S. Here the word “not too ugly” is a warning: S
cannot be an arbitrary Lebesgue measurable subset of the d-dimensional unit
cube, and in general, (1.21) is trivially false for Lebesgue integrable f (instead of
Riemann integrable). The reason is very simple: the straight line ta, 0 < t < ∞
modulo one has d-dimensional Lebesgue measure zero (if d ≥ 2), so by removing
the torus line from an arbitrary test set S ⊂ [0, 1)d of positive Lebesgue measure,
we obtain a subset S0 of S, which has the same positive Lebesgue measure as S,
and the torus line does not intersect S0 at all — this contradicts (1.21) with the
choice f = χS0.
The precise meaning of “not too ugly” above is Jordan measurable.
It is important to point out that (1.21) remains true if the torus line ta, 0 < t <
∞ is replaced by any translated copy w + ta, 0 < t < ∞. Indeed, we just use the
function g(x) = f(x − w) instead of f, and note that g and f have the same integral.
The beauty of the Weyl’s criterion is that it implies the d-dimensional
Kronecker–Weyl theorem in one line. Indeed, in the continuous case
and because n · a ≠ 0 (due to the linear independence of the coordinates of a =
(α1, . . . , αd) over the rationals), (1.20) applies, and the proof is complete.

In the discrete case the integral of the exponential function is replaced by a
geometric series, so its evaluation is just as simple: again with a = (α1, . . . , αd)
we have 
and because 1 ≠ e2πin·a (due to the linear independence of 1, α1, . . . , αd over the
rationals), (1.18) applies, and the proof is complete.
Similarly to Kronecker’s theorem, in the original form of the Kronecker–
Weyl theorem the starting point was the origin. Since the torus is translation
invariant, the Kronecker–Weyl theorem remains true if we replace the origin
with any other starting point in the torus.
Weyl’s criterion is a qualitative result, and due to its central role in uniform
distribution, we often need a quantitative (or finite) version. A nearly optimal
quantitative version for the class of axis-parallel boxes B ⊂ [0, 1)d is the Erdős–
Turán–Koksma Inequality — it covers both the discrete and continuous cases.
We will formulate the general continuous version in Sec. 3; see (3.21).
2. Strong Uniformity
Traditional Uniform Distribution — which is built around Weyl’s criterion and
“nice” test sets such as axis-parallel rectangles and boxes — does not go beyond
Riemann integral. Strong uniformity (in a broad sense) refers to the extension
from Riemann integral to Lebesgue measure/integral. It seems like a minor
change, but it has surprisingly far-reaching consequences. First of all, we have
the issue of “nice vs. ugly” test sets. An axis-parallel box is certainly “nice”, and
a Lebesgue measurable sets can be arbitrarily complicated (“ugly”) — the latter
motivates the concept of complexity-free strong uniformity. In fact, we discuss
three different aspects of strong uniformity: start-free strong uniformity,
complexity-free strong uniformity, and dimension-free strong uniformity. The
three different aspects are all crucial to achieve our goal: to describe the fast
approach to equilibrium in large off-equilibrium systems (see e.g. the Remarks
after Theorem 5.1). The combination of the three concepts is what we are going
to call later in Sec. 4 as robust uniformity. Sections 2 and 3 are preparations for
Sec. 4, where we formulate a main result, Theorem 4.2, our first “short-time
ergodic theorem”. Sections 5–8 are the first applications of Theorem 4.2 (and
many more come later).

As far as we know the subject of strong uniformity started with the following
old conjecture of Khinchin [Kh23] from 1923, involving Lebesgue measure.
Prove that, given a Lebesgue measurable set S ⊂ [0, 1], the sequence α, 2α, 3α, .
. . modulo one is uniformly distributed with respect to S for almost every α.
Formally, 
the 
conjecture 
states 
that 
Here, as usual, 0 ≤ {x} < 1 denotes the fractional part of a real number x, and
length stands for the one-dimensional Lebesgue measure.
Khinchin’s conjecture remained among the most famous open problems in
the subject of Uniform Distribution for several decades. The likely reason why
the conjecture resisted every attack is that researchers were convinced about its
truth, and wanted to prove a positive result.
Researchers were convinced about the positive solution, because there were
(at least) three somewhat related positive results, suggesting that Khinchin’s
conjecture was “quite plausable”.
The first one is the well-known one-dimensional equidistribution theorem,
which states that (2.1) holds for every irrational α if S = [a, b) is an arbitrary
subinterval of [0, 1). Formally, 
holds for every 0 < a < b < 1 and every irrational α.
A second related positive result comes from replacing the sequence α, 2α, 3α,
. . . by the translated copy β + α, β + 2α, β + 3α, . . . , translated by a typical real
number β, that is, if we start from a typical β instead of 0. More precisely, for
every Lebesgue measurable set S ⊂ [0, 1] and for every irrational α, we have 
Notice that (2.3) is a special case of Birkhoff’s well-known individual
ergodic theorem.
A third positive result was proved by Raikov [Ra36]: (2.1) holds if the linear
sequence kα is replaced by the exponential sequence 2kα, or in general, by any
sequence qkα, where q is a fixed integer greater than one (k = 1, 2, 3, . . .). (Later
F. Riesz noticed that Raikov’s theorem is another special case of Birkhoff’s
theorem; see [Ri45].) However, despite the three related positive results
mentioned above (see (2.2), (2.3) and Raikov’s theorem), conjecture (2.1) turned

out to be false. In 1970 Marstrand [Mar70] proved that there exists an open set S
⊂ [0, 1] with length(S) < 1 such that 
The fact that open sets are the simplest in the Borel hierarchy makes Marstrand’s
negative result even more suprising. Marstrand’s result demonstrates that
Khinchin was too optimistic.
The good news is that recently we succeeded to “save” Khinchin’s
conjecture in the continuous case, i.e., we could prove a positive result by
switching from a sequence (arithmetic progression) to the continuous torus line.
Of course, we also have to increase the dimension of the underlying set. That is,
we replace the unit interval [0, 1) modulo one with the 2-dimensional unit torus
[0, 1)2 = I2, and replace the arithmetic progression α, 2α, 3α, . . . starting from 0
with the straight line (t cos θ, t sin θ), t ≥ 0 starting from the origin (0, 0) with
angle θ. The positive solution of the continuous Khinchin’s conjecture represents
the starting point of this book.
But before formulating the positive solution in the continuous case, it is
natural to recall the 2-dimensional continuous version of the Kronecker–Weyl
theorem. It says that the torus line (t cos θ, t sin θ), t ≥ 0 modulo 1 is uniformly
distributed with respect to every axis-parallel rectangle S in the unit square [0,
1]2 = I2 if and only if the slope tan θ is irrational. This raises the question: What
happens if one replaces the rectangle S with an arbitrary Lebesgue measurable
test set S ⊂ [0, 1]2? Can one prove uniformity with respect to S for almost every
angle θ? This is what it means to prove “strong uniformity” in the continuous
case.
The adjective “strong” in “strong uniformity” is justified by the fact that
Lebesgue measurable sets form the largest class of sets for which we can define
measure, and uniformity is meaningless without a measure.
Strong uniformity in the narrow sense means that it must work for every
starting point, not just for almost every (which is the main difference between
Khinchin’s conjecture and Birkhoff’s ergodic theorem). We refer to the extra
property of “it works for every starting point” later as start-free.
As we said above, we proved strong uniformity in the continuous case.
Actually we proved much more: the error term turned out to be
polylogarithmically small! To emphasize the surprisingly small error term we
refer to this as “superuniformity”.

Here is the precise statement. Let S ⊂ [0, 1]2 = I2 be an arbitrary Lebesgue
measurable set in the unit square, and assume that 0 < area(S) < 1, where area
denotes the 2-dimensional Lebesgue measure. Let θ ∈ [0, 2π) be an arbitrary
angle, and consider the straight line (t cos θ, t sin θ), t ≥ 0 starting from the
origin (0, 0) with angle θ. Let TS(θ) denote the time the line (t cos θ, t sin θ)
modulo one spends in the given set S as 0 ≤ t ≤ T (straight line modulo one =
torus line). Formally, 
Note that it may happen that the set {t ∈ [0, T] : ({t cos θ}, {t sin θ}) ∈ S} is not
measurable for some particular angle θ ∈ [0, 2π), and so TS(θ) is not defined.
But this technical nuisance happens only for a negligible set of angles: TS(θ) is
certainly well-defined for almost every θ ∈ [0, 2π). This follows from some
general results in Lebesgue Integral. We are referring to Fubini’s theorem and
what we call the change of variables in multiple integrals, applied in the special
case of polar coordinates. (The relevance of polar coordinates is clear from the
fact that the lines (t cos θ, t sin θ) are passing through the origin.) Uniformity of
the torus line (t cos θ, t sin θ) modulo one relative to S means that
We could replace the factor of T in the denominator of (2.4) with the much
smaller (log T)3+ε for almost every θ. (We recall that log x and log2 x denote,
respectively, the natural and the binary logarithm of x.) Theorem A1. (see Beck
[Be2015]) Let S ⊂ [0, 1)2 be an arbitrary Lebesgue measurable set in the unit
square with 0 < area(S) < 1. Then for every ε > 0, 
for almost every angle θ.
(We mention Theorems A, B, C without proofs; they are not applied in the
rest of the book. We use them to illustrate the concepts of complexity-free and
start-free.) We can of course rewrite Theorem A1 in the equivalent form
for almost every angle θ. Notice that the polylogarithmic error term is
shockingly small compared to the linear main term area(S)T. This is why we call
Theorem A1 a superuniformity result.
It is well possible that the already small error term in (2.5) can be further
improved.
What makes the continuous superuniformity result Theorem A1 particularly
interesting is the sharp contrast with the discrete Khinchin’s conjecture, where

there is no uniformity at all!
Here is a simple intuitive argument which may help to explain the striking
difference between the discrete and continuous versions of Khinchin’s
conjecture. The well-known Weyl’s criterion applied to a torus line (“contnuous
case”) leads to the integral 
where the coordinates of a = (α1, α2) are linearly independent over the rationals.
The discrete analog is the sum
where 1, α1, α2 are linearly independent over the rationals. Note that
(where ||u|| is the distance from the nearest integer), that is,
The problem of “small denominator” in the discrete case means that ||n · a|| is
“small,” and the analog problem of “small denominator” in the continuous case
means that |n · a| is “small”. We have the trivial inequality ||n · a|| ≤ |n · a|, but
the converse is obviously false: here the right-hand side can be much larger than
the left-hand side. This quantitative difference between ||n · a|| and |n · a| gives
an intuitive explanation for the fundamental difference between the discrete and
continuous cases of Khinchin’s conjecture.
In [Be2015] we derived Theorem A1 from a more general quantitative result.
Theorem A2. Let f ∈ L2 be an arbitrary real-valued Lebesgue square integrable
function on the unit square [0, 1)2 = I2. Then for every ε > 0 there is a subset A =
A(f; ε) of the interval [0, 2π) such that 
and for every θ ∈ A and T ≥ 8,

where
is the “variance” of f.
To derive Theorem A1 from Theorem A2, choose f = χs, ε = 2−n, n = 1, 2, 3, .
. . , and consider the union set
Then length (A) = 2π; and by Theorem A2, for every ε > 0 and every θ ∈ A,
proving Theorem A1.
Note that the upper bound in Theorem A2 must contain a function of 1/ε.
Indeed, if the slope of the torus line is close to a rational with small denominator,
then a not too long line segment of such a torus line is far from being uniform.
In Theorems A1 and A2 the starting point of the torus line can be any
specific point (since the torus is translation-invariant). We may say that these
theorems are start-free.
Here is an interesting remark about the concept of start-free. Theorem A2 is
start-free in the following precise sense: given an arbitrary ε > 0, an arbitrary
starting point s = (s1, s2) ∈ [0, 1)2, and an arbitrary Lebesgue measurable test set
S ⊂ [0, 1)2, there is a subset A = A(S; s; ε) of the interval [0, 2π) such that 
and for every θ ∈ A and T ≥ 8,

where the constant factor c0(ε) depends only on ε > 0. It raises the following
natural question. Can we upgrade this result as follows: given an arbitrary ε > 0,
and an arbitrary Lebesgue measurable test set S ⊂ [0, 1)2, there is a subset A =
A(S; ε) of the interval [0, 2π) such that 
and for every θ ∈ A and T ≥ 8,
holds simultaneously for all starting points s = (s1, s2) ∈ [0, 1)2? In other words,
can we upgrade start-free to simultaneously start-free? Well, the answer is no.
Any similar conjecture about simultaneously start-free is completely destroyed
by the existence of the following “Besicovitch type set” S∗ ⊂ [0, 1)2 of the 2-
dimensional unit torus: (1) S∗ has 2-dimensional Lebesgue measure zero, and (2)
for every integer n ≥ 1, S∗ contains a torus line segment of length n in every
direction θ ∈ [0, 2π). To construct such a set S∗, we recall a well-known theorem
of Besicovitch, which states that there exists a plane set S0 ⊂ R2 of 2-
dimensional Lebesgue measure zero with the property that S0 contains a unit line
segment in every direction θ ∈ [0, 2π). Replacing “unit line segment” with “line
segment of length k” for every positive integer k = 1, 2, 3, . . . , and taking the
union, we obtain a plane set S1 ⊂ R2 of 2-dimensional Lebesgue measure zero
with the property that for every integer n ≥ 1, S1 contains a line segment of
length n in every direction θ ∈ [0, 2π). Next we take S1 modulo one with respect
to both coordinates; thus we obtain the desired subset S∗ ⊂ [0, 1)2 of the 2-
dimensional unit torus.
Probably the reader is wondering what happens in higher dimensions, i.e.,
replacing the unit square with the unit cube [0, 1]d, d ≥ 3. Again we study the
“strong” uniformity of a typical torus lines starting from the origin (“strong”
means that the test set is an arbitrary measurable set).
Let S ⊂ [0, 1]d = Id be an arbitrary Lebesgue measurable set in the unit cube
of dimension d ≥ 3, and assume that 0 < vold(S) < 1, where vold denotes the d-
dimensional Lebesgue measure. Let e ∈ Sd−1 be an arbitrary unit vector in the d-
dimensional Euclidean space Rd; Sd−1 denotes the unit sphere in Rd. Consider

the straight line te, t ≥ 0 starting from the origin 0 ∈ Rd. Let TS(e) denote the
time the line te modulo one spends in the given set S as 0 ≤ t ≤ T (line modulo
one = torus line).
Uniformity of the torus line te (mod 1) relative to S means that
In the 3-dimensional case we can replace the factor of T in the denominator of
(2.7) with the substantially smaller T1/4(log T)3+ε for almost every direction e ∈
S2 in the 3-space. In the d-dimensional case with d ≥ 4 we can replace the factor
of T in the denominator of (2.7) with 
(log T)3+ε for almost every
direction e ∈ Sd−1 in the d-space Rd.
Theorem B1. (see [Be2015]) (a) Let S ⊂ [0, 1)3 be an arbitrary Lebesgue
measurable set in the unit cube with 0 < vol(S) < 1. Then for every ε > 0, 
for almost every direction e ∈ S2 in the 3-space.
(b) In the d-dimensional case S ⊂ [0, 1)d with d ≥ 4, we have the perfect
analog of (2.8) where the factor of T1/4 in (2.8) is replaced by 
 for almost
every direction e ∈ Sd−1 in the d-space Rd.
Theorem B1 can be derived from the following quantitative result exactly the
same way as we derived Theorem A1 from Theorem A2.
Theorem B2. (a) Let f ∈ L2 be an arbitrary real-valued Lebesgue square
integrable function on the unit cube [0, 1)3 = I3. Then for every ε > 0 there is a
subset A = A(f; ε) of the unit sphere S2 such that 
and for every direction e ∈ A and T ≥ 8,
where again

is the “variance” of f .
(b) In the d-dimensional case with d ≥ 4, we have the perfect analog of (2.9)
where the factor of T1/4 in (2.9) is replaced by c0(d)
, and c0(d) is a
positive absolute constant that depends only on the dimension.
If we make the choice d = 2 in Theorem B1 (or B2) then we obtain Theorem
A1 (or A2). Perhaps the reader is wondering, why did we formulate two separate
theorems if the first one is the special case of the second one in the 2-
dimensional case. Well, the answer is that we wanted to emphasize
superuniformity — meaning strong uniformity with polylogarithmic error term
— which is not the case in dimensions d ≥ 3. This follows from the next result,
which tells that Theorem B1 (and B2) is best possible apart from
polylogarithmic factor: the exponent 
 of T in the error term of Theorem
B1 (and B2) is best possible.
We point out the crucial fact that in the results mentioned so far in this
section, the upper bound on the error does not depend on the complexity (=
ugliness) of the test set S or test function f. We may call them complexity-free
and start-free strong uniformity results.
Note that both Theorems A1 and B1 are about the torus line, which is the
simplest curve on the torus. We can define a simple motion on the torus by
assuming that a particle moves on the torus line with unit speed. Theorem C
below is a general result about the limitations of the time discrepancy of a
motion of a particle in the unit torus [0, 1)d, d ≥ 3.
Let
be an arbitrary (continuous) parametrized curve on the d-dimensional unit torus
[0, 1)d, d ≥ 2 with total time T; here each coordinate xj(t), 1 ≤ j ≤ d is a
continuous function of t, and {x} denotes, as usual, the fractional part of a real
number x. Note that the parametrized curve Γ in (2.10) represents the motion of a
particle on the torus, and we constantly use this interpretation below; we refer to
T as the “total traveling time”. Let S ⊂ [0, 1)d be an arbitrary measurable subset,
and let vol(S) denote the volume, i.e., the d-dimensional Lebesgue measure. Let
TS(Γ) denote the time the particle spends in the given set S; formally, 

We call TS(Γ) the actual time, and we compare it to the expected time, which —
assuming perfect uniformity — is proportional to the volume expected time = T ·
vol(S). The difference of the actual time and the expected time is called time
discrepancy; formally, 
To prove a non-trivial result, we need an extra assumption. We assume that
“T = total traveling time = arclength,” which is equivalent to the requirement that
the average speed is one.
Theorem C. For every integer d ≥ 3 and real T > 1, there exists an integer m =
m(d, T) ≥ 2 such that we can construct m measurable subsets S1, . . . , Sm of the
unit torus [0, 1)d with the following property: given any parametrized curve 
of arclength T on the torus [0, 1)d (i.e., the average speed is one)
holds for at least two-thirds of the m subsets S1, . . . , Sm. Here c1(d) > 0 is a
constant depending only on the dimension d ≥ 3. In particular, c1(3) = 1/500 is a
good choice for d = 3.
Theorem C implies, via a standard averaging argument, that Theorem B2 is
best possible apart from polylogarithmic factor of T. The explanation goes as
follows. First note that every torus line in Theorem B2 is determined by its
direction e ∈ Sd−1, and using the ((d − 1)-dimensional) surface area on the unit
sphere Sd−1, it is meaningful to talk about the “majority of torus lines,” or more
precisely, about “1 − ε part of all torus lines passing through the origin”. Now
assume that, for some d ≥ 3 and T > 1, there exists a continuous family of
parametrized curves 
on the torus [0, 1)d such that there is a probability measure µ on the index-set Ω
(i.e., µ(Ω) = 1, so it is meaningful to talk about 1 − ε part), and the family of
curves in (2.14) beats Theorem B2 in the following quantitative sense: Given
any measurable subset S ⊂ [0, 1)d, 
holds for at least two-thirds of the curves Γω, ω ∈ Ω, in the sense of the µ-
measure.
We show that this contradicts Theorem C. Indeed, we apply (2.15) for the m
= m(d, T) ≥ 2 sets Sj, 1 ≤ j ≤ m whose existence is guaranteed by Theorem C.
Thus for every 1 ≤ j ≤ m there exists a (measurable) subset Ωj of the index-set
such that µ(Ωj) ≥ 2/3, and 

holds for all ω ∈ Ωj. The fact
immediately implies that there must exist an index ω0 ∈ Ω which is contained
by at least 2m/3 of the m sets Ωj, 1 ≤ j ≤ m. In other words, there is a curve Γω0
such that (see (2.15)) 
holds for at least two-thirds of the m sets S1, . . . , Sm. But (2.16) clearly
contradicts Theorem C, and this contradiction proves that Theorem B2 is nearly
best possible in every dimension d ≥ 3: we cannot replace the error term 
For the proofs of the results mentioned in this section, we refer the reader to
[Be2015].
In the book we sharply distinguish between two concepts of “space”: the
low-dimensional particle space (= intuitively the “gas container”), which is
usually 3-dimensional, and the high-dimensional configuration space, where the
whole system is represented by a single point. To describe the time evolution of
large off-equilibrium systems, it is natural to work in the high-dimensional
configuration space. Then the time evolution of the system means a motion of
this single point, i.e., a parametrized curve.
(Note in advance that we will also sharply distinguish between two concepts
of “equilibrium”: equilibrium in the particle space; see square-root equilibrium,
and equilibrium in the configuration space; see conf-space equilibrium — see
Secs. 4 and 5.) In an off-equilibrium real life gas model the number of particles
N is typically in the range of the Avogadro number (close to 1024), and the time
scale is just a few seconds. Therefore, it is natural to ask what happens if the
dimension d is much larger than the time parameter T (in seconds, say). We
answer this question in Sec. 4. But first in Sec. 3 we elaborate on the concept of
configuration space.
3. High-Dimensional Configuration Space of Large
Systems and Unrealistic Time Scale
In the “off-equilibrium ideal gas” model N point particles are moving around in a
cubic container — say, the unit cube [0, 1]3 — bouncing back and force on the
walls like billiard balls. To study the time evolution of such a large billiard

system, we use the geometric trick of unfolding that converts a billiard orbit (=
zig-zag) into a torus line (unfolding was introduced in [Kö-Sz13]).
The figure shows the 2-dimensional case. It illustrates the geometric trick of
unfolding the billiard orbit (= “reflecting ray”) inside the unit square to a straight
line in the entire plane. The transformation of unfolding simply means that we
keep reflecting the square itself in the respective side and unfold the piecewise
linear billiard path to a straight line.
Fig. 3.1
Two (straight) lines in the plane correspond to the same billiard path if and
only if they differ by a translation through an integral vector where both
coordinates are even, i.e., where the vector is from the “double” square lattice
2Z × 2Z. In other words, the problem of the long-term distribution of a billiard
path in the unit square is equivalent to the distribution of the corresponding
torus-line in the 2 × 2 square.
The law of reflection implies that there are at most four different directions
along the billiard path (the initial direction is preserved modulo π/2, which is
one-fourth of the whole angle 2π; the same holds for any rectangle). If we use
unit speed, then of course arclength and time are the same.
Formally, a billiard path in the unit square [0, 1]2 has the form

where a = (α1, α2) is a nonzero vector, and ||z|| denotes the distance of a real
number z from the nearest integer. Here y = (y1, y2) is the starting point, and a
gives the initial direction; so θ = arctan  (“inverse tangent”) is the initial angle.
Fig. 3.2
It follows from unfolding that a billiard path in the unit square intersects a
given test set S at time t exactly when the corresponding torus-line in the 2 × 2
square intersects the union set S1 ∪ S2 ∪ S3 ∪ S4 (see Fig. 3.2).
Indeed, unfolding defines four reflected copies S1, S2, S3, S4 of S (each of the
four unit squares on the figure above contains a reflected copy of the given test
set S). In the last step we shrink the underlying 2 × 2 square to the unit square I2
= [0, 1)2.
Of course, the test set S can be upgraded to any “not too ugly” periodic
function f, i.e., f(x, y) is a Riemann integrable periodic complex-valued function
with period one in both variables. In the case of the figure, f means the 0, 1
valued characteristic function of the union S1 ∪ S2 ∪ S3 ∪ S4 of the four half-
size reflected copies of the given subset S ⊂ I2 = [0, 1)2.
Note that the unfolding of the billiard path in the h-dimensional unit cube [0,
1]h with h ≠ 2 can be defined in the analog way. Formally, unfolding means the
map 
where 0 ≤ {x} < 1 denotes the fractional part of a real number x (i.e., x = 
 +
{x} where 
 is the largest integer ≤ x).

We use the fact that for every set S ⊂ [0, 1),
where
It follows from unfolding that a billiard path in the h-dimensional unit cube
[0, 1]h intersects a given test set S ⊂ [0, 1]h at time t exactly when the
corresponding torus-line in the h-dimensional 2 × · · · × 2 (hyper)cube intersects
the union of the 2h reflected copies of S. (Note that each of the 2h unit
(hyper)cubes contains a reflected copy of the given test set S.) In the last step we
shrink the h-dimensional 2 × · · · × 2 (hyper)cube to the unit (hyper)cube Ih = [0,
1)h.
A constant speed piecewise linear point billiard motion in Ih is defined by the
equation
where y = (y1, . . . , yh) is the starting point and the nonzero vector a = (α1, . . . ,
αk) is the initial direction.
Next we study the time evolution of a large off-equilibrium system of N
point-billiards in a cube [0, 1]h, and assume that the hN velocity coordinates are
linearly independent over the rationals.
To demonstrate the power of the concept of configuration space, we prove a
surprising “superdiscrepancy” result, which is a simple application of
Kronecker’s well-known density theorem in the configuration space. We start
with a special case: let S be the right half [ , 1] × [0, 1] · · ·× [0, 1] of the unit
cube [0, 1]h (let, say, h = 3). Whatever initial point configuration we had at the
start, if we wait long enough, it will happen that all N particles will be in S at the
same time. And what is more, the system will return to this “absurd” state
infinitely many times.
We call it “absurd,” because in real life such a 3-dimensional cubic container
would collapse, due to the outside pressure.
It is easy to upgrade this to an even more absurd result. Under the same
condition (“linear independence”) it will happen that, given any rational box

(i.e., Cartesian product of closed intervals that have rational endpoints, and the
volume is positive), all N particles will be in this box at the same time, and the
system will return to each rational box infinitely many times. (The set of rational
boxes is countable, and every box of positive volume contains a rational box.)
The most general result of this type is the following.
Theorem 3.1. (Superdiscrepancy) Assume that the hN initial velocity
coordinates of a point-billiard system in the h-dimensional unit cube Ih = [0, 1]h
are linearly independent over the rationals. Then the time evolution of the system
exhibits the following property that we call superdiscrepancy. Given any
sequence B1, B2, . . . , BN of N rational boxes in Ih and any ordering of the N
particles, starting from an arbitrary initial point configuration, it will happen
that the first particle will be in the first rational box B1, the second particle will
be in the second rational box B2, and so on, the Nth particle will be in the Nth
rational box BN, all at the same time, and the system will return to each such
(B1, . . . , BN)-configuration infinitely many times.
The superdiscrepancy result is somewhat similar to the classical Zermelo–
Poincaré paradox in statistical mechanics. Both say, very roughly speaking, that
if one waits long enough, “crazy things will happen”.
Theorem 3.1 explains why we cannot expect convergence to “snapshot
equilibrium” as t → ∞ for the individual time evolution of large off-equilibrium
systems. We have to downgrade it to approach to snapshot equilibrium,
emphasizing the temporary nature of the static aspects of (snapshot) equilibrium
on the individual level.
We show that Theorem 3.1 is a straightforward corollary of Kronecker’s
density theorem. Indeed, if the motion of the kth point billiard in Ih = [0, 1]h is
described by xk(t), 0 ≤ t < ∞ in (3.5), then the time-evolution of the whole
system is represented by the following parametrized curve in the hN-dimensional
cube [0, 1]d = [0, 1]hN that we call the trajectory of the system 
Here [0, 1]d = [0, 1]hN is the configuration space, Γ(0) = Y = {y1, . . . , yN} is the

initial configuration, and Γ′(0) = V = (v1, . . . , vN) describes the initial velocities.
Let
be the Cartesian product of N rational boxes in this order; the index C indicates
that SC(B) ⊂ Id is a subset of the configuration space.
Applying d-dimensional unfolding, we see that the distribution of the (d-
dimensional) billiard path Γ(t), 0 ≤ t ≤ T (see (3.6)) with respect to the test set
SC(Δ) (see (3.7)) is equivalent to the distribution of the corresponding d-
dimensional 
torus 
line 
(with 
d 
= 
hN; 
see 
(3.2)) 
with starting point Γ(0) and direction vector Γ′(0) (“derivative”) with respect to
the union
of the 2hN “reflected halves” of SC(B).
By hypothesis the hN coordinates vi,j, 1 ≤ i ≤ N, 1 ≤ j ≤ h of the direction
vector Γ′(0) are linearly independent over the rationals, so we can apply the
Kronecker’s density theorem to any of the 2hN “reflected halves” of SC(B), and
Theorem 3.1 follows.
Next we repeat the proof of the Superdiscrepancy result (Theorem 3.1) by
replacing 
Kronecker’s 
density 
theorem 
with 
the 
Kronecker–Weyl
equidistribution theorem (continuous version), and obtain an “asymptotic CLT”
(central limit theorem).
For simplicity assume h = 3, i.e., we study a system of N point billiards in the
unit cube [0, 1]3, where the motion of the kth point billiard in [0, 1]3 is described
by xk(t), 0 ≤ t < ∞. As in (1.6), the time-evolution of the system is represented by
the parametrized curve in the 3N-dimensional cube [0, 1]d = [0, 1]3N (=
configuration 
space) 
that 
we 
call 
the 
trajectory 
of 
the 
system 

where Γ(0) = Y = {y1, . . . , yN} is the initial configuration, and Γ′(0) = V = (v1, .
. . , vN) describes the initial velocities.
Let S ⊂ [0, 1]3 be an arbitrary but fixed Jordan measurable subset of the unit
cube with volume 0 < vol(S) < 1. Let NS(t) = NS(Y; V; t) denote the point-
counting function 
First we prove the following asymptotic binomial distribution type result.
Theorem 3.2. (asymptotic binomial distribution) Consider the N-particle
billiard model in the 3-dimensional unit cube [0, 1]3 defined in (3.10). Assume
that the 3N initial velocity coordinates 
in (3.10) are linearly independent over the rationals. Then
for all Jordan measurable subsets S ⊂ [0, 1]3 of the unit cube, p = vol(S) denotes
the volume, q = 1 − p, the point-counting function NS(t) is defined in (3.11), and
length simply means the one-dimensional Lebesgue measure.
Proof of Theorem 3.2. We show that, applying the Kronecker–Weyl theorem in
the configuration space, and combining it with unfolding (as we did in the proof
of Theorem 3.1), (3.12) follows.
Following the proof of Theorem 3.1, let S(1) = S ⊂ [0, 1]3, and let S(0) = [0,
1]3 \ S be the complement of S, and for every N-dimensional vector Δ = (δ1, δ2, .
. 
. 
, 
δN) 
with 
coordinates 
δi 
= 
0 
or 
1, 
let 
be the Cartesian product of the N sets S(δi), 1 ≤ i ≤ N in this order (the index C
indicates the configuration space). If the vector Δ has n coordinates with 1 and N
− n coordinates with 0, then 
where vold stands for the d = 3N-dimensional Lebesgue measure.

We repeat the argument of (3.8) and (3.9): the distribution of the billiard path
Γ(t), 0 ≤ t ≤ T with respect to a test set SC(Δ) (see (3.13)) is equivalent — via
unfolding 
— 
to 
the 
distribution 
of 
the 
corresponding 
torus 
line 
with starting point Γ(0) and direction vector Γ′(0) with respect to the union
of the 23N “reflected halves” of SC(Δ). In other words, by using the notation
S∗(Δ) 
⊂ 
[0, 
1]3N 
for 
this 
union 
set, 
we 
have 
Clearly (see (3.14))
By hypothesis the coordinates vi,j, 1 ≤ i ≤ N, 1 ≤ j ≤ 3 of the direction vector Γ
′(0) (“derivative”) are linearly independent over the rationals, so we can apply
the Kronecker–Weyl equidistribution theorem (continuous form) to the 0, 1
valued characteristic function of a set S∗(Δ) ⊂ [0, 1]3N, and obtain 
where in the last step we used (3.16), and Γ∗(t) is defined in (3.15). By (3.17),
which proves Theorem 3.2.
Remark. Under the condition of Theorem 3.2 the flow Γ′(0)t in the torus [0,

1)3N (see (3.15)) is ergodic, so we can apply Birkhoff’s individual ergodic
theorem. It says that in Theorem 3.2 we can replace the class of Jordan
measurable sets S ⊂ [0, 1]3 with an arbitrary but fixed Lebesgue measurable test
set S ⊂ [0, 1]3. The disadvantage is that it works only for almost every initial
configuration Γ(0) = Y = {y1, . . . , yN}, and a typical initial configuration
represents equilibrium at the start. Since our main goal is to study the approach
to equilibrium starting from an arbitrary far-from-equilibrium initial
configuration, this corollary of Birkhoff’s theorem is not particularly useful for
us.
Combining Theorem 3.2 with the classical DeMoivre–Laplace theorem with
error term, we obtain the following result (CLT stand for the central limit
theorem).
Theorem 3.3. (asymptotic CLT) Under the conditions of Theorem 3.2, with NS(t)
= NS(Y; V; t), 
where p = vol(S) and q = 1 − p.
Note that the error term O(1/
) in (3.18) is the inevitable discrepancy
between the (continuous) standard normal distribution and the (discrete)
normalized binomial distribution with parameters N and 0 < p < 1.
Theorems 3.1–3.3 are asymptotic results, describing the (very!) long-term
time evolution of a large N-particle system, starting from an arbitrary initial
point configuration (e.g., “Big Bang,” where all particles start from the same
point). In particular, Theorem 3.3 says that a large billiard system exhibits
asymptotic time-lapse randomness as t → ∞.
If the volume p = vol(S) of the test set S is very small — say, it is around 1/N
— then of course (3.18) becomes useless (since the error term O(1/
) is in
the range of 1). However, Theorem 3.2 still works, and implies the following
result.
Theorem 3.4. (asymptotic Poisson law) Write λ = pN = vol(S)N. Under the
conditions of Theorem 3.2, for every integer ℓ ≥ 0,

Notice that the probability distribution
on the right-hand side of (3.19) is the familiar Poisson distribution with
parameter λ > 0.
Note that (3.19) immediately follows from Theorem 3.2 combined with the
simple approximation
If λ = pN = vol(S)N is in the “constant range” (i.e., the volume of the test set
S is very small), then by (3.19), the point-counting function NS(t) has Poisson
distribution with negligible error (since the error term O(λ2/N) is very small).
The requirement in Theorem 3.2 — linear independence of the 3N velocity
coordinates — is easily satisfied by choosing a typical velocity distribution, i.e.,
almost all choices satisfy linear independence.
Perhaps the simplest explicit example of arbitrarily large finite sets of real
numbers that are linearly independent over the rationals is the following:
Explicit Example: 
 where p denotes primes.
The linear independence of this example easily follows from the well-known
fact from algebra and number theory that the exponentially long symmetric
product of 2d factors 
assuming (h1, . . . , hd) ∈ Zd \ 0.
This corollary of the Kronecker–Weyl theorem is very elegant and
interesting, but, unfortunately, it has a fundamental shortcoming: it do not say
anything about the crucial question of how long does it take to reach CLT-
equilibrium? In most real life experiments, the transition from nonequilibrium to
equilibrium is very fast, and this is not reflected in the statement.
The underlying problem is that the Weyl’s criterion is a qualitative result,
since in the limit process, where we approximate a “nice” function with a finite

Fourier series, we lose control over the quantitative aspects of the error term.
This is why in Theorem 3.3 we cannot provide any quantitative answer to
question of how long does it take to reach CLT-equilibrium.
In fact, we cannot even expect any explicit error term for the trivial reason
that the class of Jordan measurable test sets is far too large. Indeed, let T be
large, and let L0(e, T) denote the line segment {te : 0 ≤ t ≤ T} modulo one. Given
any Jordan measurable test set A ⊂ Id = [0, 1)d in the configuration space Id with
positive measure, the difference A1 = A\L0(e, T) is still Jordan measurable, and
has the same measure (d-dimensional volume) as A. Let f = χA1, then 
 and 
Since T can be arbitrarily large, this explains why we cannot expect any explicit
error term o(1) tending to zero as T → ∞.
Since the class of Jordan measurable test sets A ⊂ [0, 1)d (meaning f = χS) is
far too large, we may consider a much smaller class. The simplest class — the
most natural choice used since the beginning of Uniform Distribution — is the
class of axis-parallel boxes B in [0, 1)d, i.e., the Cartesian products B = I1 × I2 × ·
· · × Id of subintervals Ii ⊂ [0, 1). For this class there is a “quantitative
continuous Weyl’s criterion”; see e.g., in [Dr-Ti97].
Continuous Erdős–Turán–Koksma Inequality: Let r(t) : [0, T] → [0, 1)d = Id be
an arbitrary continuous curve and H ≥ 1 be an arbitrary integer; then with f = χB,
where B denotes axis-parallel boxes and of course f is defined on the unit torus
Id, we have 
where of course i = 
,
is the maximum norm of the vector h = (h1, . . . , hd) ∈ Zd, and
An obvious weakness of the Erdős–Turán–Koksma inequality is the factor
(3/2)d, which makes it totally useless in large dimensions (e.g., when d is around

the Avogadro number). But even if we assume that someone could get rid of the
exponentially large factor (3/2)d, there remains another, less obvious, but just as
dangerous problem with (3.21). The Kronecker–Weyl theorem is the special case
r(t) 
= 
te 
with 
some 
e 
= 
(α1, 
. 
. 
. 
, 
αd), 
and 
we 
have 
Of course we have the trivial upper bound
but, because the infinite sum
is clearly divergent, we need a nontrivial upper bound in (3.22), which requires a
nontrivial lower bound for the absolute value of the linear combination
in the denominator on the right-hand side of (3.22), where α1, . . . , αd are
linearly independent over the rationals.
Unfortunately, the quantitative aspects of linear independence of concrete
sets of real numbers, even for such a simple case as the Explicit Example (see
before (3.20)), lead to notoriously difficult number-theoretic problems that are
considered hopeless for contemporary research. To give a nutshell illustration,
note that the linear independence of the Explicit Example says that (pj stands for
primes, and hj are integers) 
Even for the simplest family of axis-parallel d-dimensional boxes, we need a
quantitative lower bound on the distance between a linear combination 
and 
0. 
(3.20) 
implies 
the 
lower 
bound 
but, unfortunately, lower bound (3.23) is extremely weak for large d — due to the
double exponential nature of the right-hand side. This shows that, even for such
a simple set of linearly independent real numbers as the Explicit Example, and
even for such a simple test set as a box in the configuration space, we do not

have a satisfying quantitative result. (Note that W.M. Schmidt proved a lower
bound that is asymptotically much better than (3.23), but, unfortunately, his deep
result is ineffective — a notorious, and very annoying, technical problem. This
prevents us from using Schmidt’s theorem: to prove results on a “realistic time
scale” we need effective estimations.) Another illustration of how little we know
about linear independence of explicit sets of reals is the more than 100 years old
open problem that whether or not the pair π, e of the two most famous special
numbers is linearly independent over the rationals.
This forces us to switch from studying the time evolution of a large off-
equilibrium system with explicit initial velocities — where we cannot prove
anything about realistic time scale — to typical initial velocities (and arbitrary
Lebesgue measurable test sets in the configuration space, i.e., strong uniformity
in high dimensions), where we can prove many interesting results about realistic
time scale — this is exactly the subject of this book. To define typical, we need a
probability distribution. In this book typical means that the initial velocities are
taken independently (for each particle) from the 3-dimensional normal (=
Gaussian) distribution.
We conclude this section with a short discussion about the (multi-
dimensional) Gaussian (velocity) distribution. The 3-dimensional Gaussian
velocity distribution is isotropic, and it is determined by the following density
function for the speed: 
for all y ≥ 0, where the physical meaning of parameter σ > 0 is σ = 
 here
m is the mass, T is the absolute temperature, and k0 is the Boltzmann’s constant.
(Physicists call (3.24) the Maxwellian speed distribution; it reflects physical
reality for gas particles in thermal equilibrium — first discovered by Maxwell.)
Using the substitution x = y/σ in (3.24) we have
which implies that the Gaussian speed distributions in (3.24) are basically the
same. So, in the rest we assume that σ = 1:
To define a large system of N point billiards with Gaussian initial velocites,
we assume that ρj (representing “radius”), 1 ≤ j ≤ N are N independent,
identically distributed positive random variables, with common distribution 

for all positive u > 0 (here the function e−y2/2 comes from the standard normal
distribution, and y2 is motivated by the surface area 4πy2 of a sphere of radius y
> 0). We also assume that uj (= direction), 1 ≤ j ≤ N are N identically distributed
random variables, where each uj is uniformly distributed on the unit sphere S2,
and the 2N random variables uj, ρj, 1 ≤ j ≤ N are mutually independent. Formally,
we 
consider 
the 
product 
measure 
on 
the 
Cartesian 
product 
set 
where the factor measure is a probability measure (we divide the surface area on
the unit sphere by 4π). So, the product measure, denoted by ProdMeasGauss, is
also a probability measure on ([0, ∞) × S2)N = ΩGauss.
The key fact is that ProdMeasGauss is a d-dimensional Gaussian distribution
with d = 3N.
The actual speed of the jth particle is a constant (depending on the particle)
|x′j(t)| = vj(t) = ρj, 0 ≤ t ≤ T, and the whole billiard-path (piecewise linear zig-zag)
is determined by the initial velocity x′j(0) = vj(0) = ρjuj. (In fact, the piecewise
linear path is determined by the unit vector uj alone.) Let us return to (3.26);
using integration by parts, we have
that is,
Typical Gaussian distribution precisely means (1 − ε)-part with some small
but fixed ε > 0 (say, ε = 10−2 means 99%) of the product set ΩGauss = ([0,
∞)×S2)N, equiped with the product measure ProdMeasGauss. Formally, 
We also need the Gaussian speed distribution for arbitrary dimension d ≥ 1.
In the one-dimensional case we have the density function

and 0 otherwise; and in general, for every odd dimension d ≥ 3 we have the
density function
and 0 otherwise (here we use the well-known notation k!! = k(k − 2) (k − 4) · · ·,
where the last factor is 1 or 2 depending on the parity of k). Finally, for every
even 
d 
≥ 
2, 
we 
have 
the 
density 
function 
and 0 otherwise.
The disadvantage of definition (3.28)–(3.29) (describing the speed
distribution) is that it comes without any a priori motivation for the “weird”
constant factors in (3.28)–(3.29). An equivalent alternative definition — which
is certainly more instructive — is to describe the Gaussian velocity distribution v
= 
(v1, 
. 
. 
. 
, 
vd) 
with 
its 
multivariate 
density 
function 
Since (3.30) is the product of the factors 
 the coordinates v1, . . . , vd of
the velocity v are independent random variables with standard normal
distribution each. This is why (3.30) is called the density function of the d-
dimensional standard normal distribution.
We can rewrite (3.30) in the form
where 
 is the usual Euclidean distance. So (3.31) implies that
the distribution of the velocity v — i.e., the distribution of the d-dimensional
standard normal distribution — is isotropic. Since |v| is the speed, by (3.31) the
density 
function 
of 
the 
speed 
distribution 
is 
where Sd−1(y) = {x ∈ Rd : |x| = y} is the sphere in the d-space of radius y, and
SurfArea(Sd−1(y)) stands for its surface area.
The next step is to show that (3.32) gives back (3.28)–(3.29), and thus it
explains, in retrospect, the geometric meaning of the ad hoc constant factors in
(3.28)–(3.29). Since a solid sphere (= ball) is the union of concentric spheres, we
can express SurfArea(Sd−1(y)) in terms of the derivative of the volume (warning:
 
indicates 
derivative 
and 
d 
is 
the 
dimension) 

where C∗(d) is the (hyper)volume of the d-dimensional unit ball. A well-known
recurrence formula on trigonometric integrals gives that C∗(d) is equal to the
ratio 
of 
πd/2 
and 
the 
Gamma 
function 
at 
 
+ 
1, 
i.e., 
if d is even or odd (in the odd case 
 and 
 denote the upper and lower integral
parts of a real number x). Combining (3.32), (3.33) and (3.34), we obtain,
respectively, (3.28) and (3.29). This proves the equivalence of the two
definitions of the multi-dimensional Gaussian distribution.
4. Dimension-Free Strong Uniformity on a Realistic
Time Scale
We study strong uniformity in very high dimensions; e.g., when the dimension is
in the range of the Avogadro number (around 1024). Note that Theorem B2(b) is
about arbitrary dimension d, but, unfortunately, it does not help, because of the
unspecified constant factor c0(d) in the upper bound for the discrepancy. Our
proof of Theorem B2(b) in [Be2015] gives a very weak exponential upper bound
on c0(d), which makes it totally useless in high dimensional applications. It
would be most useful, therefore, to have an upper bound on the discrepancy that
does not depend on the dimension. And indeed, in this section we are able to
formulate a result that is basically dimension-free.
Note that the diameter of the d-dimensional unit cube [0, 1]d is 
.
Moreover, it is an easy exercise in probability theory to prove that the distance
between two randomly chosen points in [0, 1]d is 
 + o(
) with probability
close to one if d is large. These two facts explain why it is natural to modify the
time-discrepancy 
in Theorem B2(b) by replacing t with t
, and to study
instead of (4.1), where e ∈ Sd−1is a d-dimensional unit vector. The effect of the
switch from (4.1) to (4.2) is modest in small dimensions, but it becomes

substantial in very large dimensions.
In fact, we need the following slightly more general notation: for 0 ≤ T1 < T2
and v ∈ Rd \ 0 write (vold is the d-dimensional Lebesgue measure) 
So (4.3) is the special case Df(
e; 0, T).
For simplicity, in Theorem 4.1 below we just consider the case of test sets f =
χS, where S ⊂ [0, 1)d. Write
Notice that Theorem B1(b) immediately implies the following soft
qualitative result. Let S ⊂ [0, 1)d be an arbitrary Lebesgue measurable set with 0
< vold(S) < 1; then for almost every direction e ∈ Sd−1 in the d-space 
The following is a “dimension-free” (to be explained below) quantitative
version of this qualitative result.
Theorem 4.1. Let S ⊂ [0, 1)d be an arbitrary measurable test set in the d-
dimensional unit torus with d ≥ 103. Let p = vold(S) be the d-dimensional
Lebesgue measure of S. Let T = T0 = T0(d) > 0 be the solution of the equation 
Note that
where o(1) = od(1) → 0 as d → ∞.
Given any 0 < ε < 1, there exists a measurable subset A = A(d; ε) ⊂ Sd−1 of
the (hyper)sphere such that the normalized surface area of A is > 1 − ε, and 
holds for every e ∈ A and every T1 > max{3T0, 10}.

Remarks. It is easy to extend Theorem 4.1 for square-integrable test functions f
∈ L2; we leave it to the reader.
The requirement d ≥ 103 is purely technical. Theorem 4.1 should be true for
all dimensions less than 103.
The crucial fact here is that the upper bound on the error in (4.5) does not
depend on the dimension d. This is why we call Theorem 4.1 a dimension-free
result (despite the fact that the threshold T0 = T0(d) does depend on the
dimension).
Also the upper bound on the error in (4.5) does not depend on the complexity
(= ugliness) of the test set S. The common starting point of the torus lines t
e, t
≥ 0 is the origin, but of course we could choose any other common starting point
(since the torus is translation invariant). The order of the error term 
is nearly square-root size, which is basically best possible. Indeed, as we said
above, the error term in Theorem B2
is best possible (apart from a polylogarithmic factor), and 
 converges to 
 as d → ∞. Square-root size upper bound for the error term is very good, since
uniformity requires much less: any sublinear upper bound suffices. These facts
justify the claim that Theorem 4.1 is a dimension-free, start-free and complexity-
free strong uniformity result. For brevity we combine these properties into a
single concept that we call robust uniformity. Thus we say that Theorem 4.1
exhibits 
robust 
uniformity, 
where 
The only dependence on the dimension d in Theorem 4.1 is in the threshold
T0 = T0(d), which is an extremely weak dependence. Indeed, T0(d) is shockingly
small: it is a square-root logarithmic function of d. For example, if d = 101000
then T0 ≤ 25.
Perhaps the reader is wondering whether or not we need the strange
threshold T0 = T0(d) in Theorem 4.1 (in Theorem B2 we do not have such a
threshold). It is natural to ask the question: why do we ignore the initial part 
of the torus lines? Is it really necessary? The answer is yes: we have to ignore an

initial part. In Sec. 23 we prove why it is impossible to expect any kind of
uniformity 
in 
the 
slightly 
shorter 
interval 
Note that interval (4.8) is more than one-third of (4.7); they have the same order 
.
We may call T0 = T0(d) in Theorem 4.1 the threshold for configuration space
equilibrium, or conf-space equilibrium in short. It is the threshold when the
typical time evolution of a system with N = d/3 particles and Gaussian initial
velocity distribution reaches equilibrium in the configuration space. (Note that 
 in (4.5) represents the best possible square-root fluctuation.) We derive
Theorem 4.1 from a more general result Theorem 4.2; see below (we carry out
the deduction in Sec. 26). Theorem 4.2 is about the “Gaussian” square-integral
of (4.3) 
where dSA (e) denotes the integration with respect to the normalized surface
area 
on 
the 
sphere 
e 
∈ 
Sd−1, 
i.e., 
SA (Sd−1) 
= 
1, 
and 
with
where in (4.10) we use the well-known notation k!! = k(k − 2)(k − 4) · · ·, and
the last factor is 1 or 2 depending on the parity of k. In (4.9) the vector v = ρe has
d-dimensional standard normal (= Gaussian) distribution. This explains the use
of “Gauss” in Δ2
f(Gauss; T1, T2) (see (4.29)). Note that (4.9)–(4.11) immediately
follow from (3.32)–(3.34) at the end of Sec. 3; in particular, ρd−1/Cd is the
surface area of the sphere of radius ρ in Rd.
Theorem 4.2. Let 1 ≤ U < W be real numbers and d ≥ 2 be an integer such that
Then for every test function f ∈ L2(Id) with Id = [0, 1)d,

where
noting that in the special case of a characteristic function f = χS, S ⊂ Id,
Note that Theorem 4.2 is a main result that we apply a lot — Theorem 4.1 is
just an interesting corollary. Theorem 4.2 goes far beyond being a “strong
uniformity” result: it is a dimension-free, complexity-free and start-free strong
uniformity result; or using (4.6), we may say that Theorem 4.2 exhibits robust
uniformity. Sections 5–8 are all about the applications of Theorem 4.2 in the
very high dimensional configuration space (and many more come later).
The value of the constant 10 is of course accidental, and it is basically
irrelevant in the applications.
Note that Δ2
f(Gauss; U, W) is the average square-error, and, intuitively
speaking, we may refer to
as the “inevitable random error”.
Condition (4.12) is equivalent to
The square-root-logarithmic (4.14) is the (shockingly small!) threshold for conf-
space equilibrium. It is the threshold when the typical time evolution of a system
with N = d/3 particles and Gaussian initial velocity distribution reaches
equilibrium in the configuration space. (Note that Theorem 4.2 implies the best
possible square-root fluctuation; see Theorem 4.3 below.) We apply Theorem 4.2
as a “short-time ergodic theorem”: it justifies the approximation “configuration
space average” ≈ “short-time average” in a quantitative form. These applications

can be summarized in the following vague statement.
Metatheorem. The typical time evolution of a large system with non-interacting
particles, starting from an arbitrary (off-equilibrium) initial configuration,
reaches conf-space equilibrium on a realistic time scale, exhibiting robust
uniformity in the configuration space. In this equilibrium state the system
demonstrates “advanced randomness,” and stays in this state for a very, very
long time (long-term stability).
This book is an attempt to turn the vague Metatheorem into precise
theorems.
What happens if the Gaussian initial velocity distribution is replaced by other
initial velocity distribution? Can we still prove an analog of Theorem 4.2? We
return to this important question in Secs. 13 and 14.
Theorem 4.2 is complemented with the following result.
Theorem 4.3. Let n0 be one of the six lattice points (±1, 0, 0), (0, ±1, 0), (0, 0,
±1) in the neighborhood of the origin, and let f0(u) = e2πin0·u. Then for every 0 ≤
U < W < ∞, 
In view of Theorem 4.3 the upper bound in (4.13) is sharp apart from a
constant factor. What makes it particularly interesting is that the test function f0
is analytic, i.e., it is as nice as it gets.
We postpone the proofs of the theorems in this section to Secs. 9 and 26.
5. Rapid Approach and Long-Term Stability of Square-
Root Equilibrium
We recall the key diagram from the Preface:

where CLT stands for the central limit theorem. Our goal is to work out the
missing details. In Sec. 4 we already formulated our first theorem about robust
uniformity in the configuration space, see Theorems 4.2, and as the diagram
shows, we are going to apply it, and its extensions in Secs. 13–14, as a “short-
time ergodic theorem”. According to the diagram, the term “short-time ergodic
theorem” refers to the approximation property “conf-space average” ≈ “short-
time average”. The key point here is that we replace the “long-time average” in
ergodic theorem (which usually means unrealistic time scale) with realistic
“short-time average”. We demonstrate how this approximation property implies
fast approach to a state of “randomness” and its long-term stability.
Motivated by Theorem 3.3 (asymptotic CLT), it is a natural intuition to
visualize “snapshot equilibrium” in the particle space (=“gas container”) as a
state where the system exhibits square-root fluctuation. More precisely, given a
test set, the point-counting function (see (3.11)) should differ from the expected
value (i.e., N times the volume) by O(
). In other words, it is a good intuition
to visualize “snapshot equilibrium” as a square-root fluctuation equilibrium in
the particle space, or simply square-root equilibrium.
Warning: Using square-root equilibrium as the definition of “snapshot
equilibrium,” the statement “once the system reaches (snapshot) equilibrium (in
the particle space), it stays in (snapshot) equilibrium forever” is certainly untrue
for the unlimited time evolution of a typical trajectory of the system (i.e., t →
∞).
Perhaps the reader’s first reaction to justify this claim would be to recall the
well-known Zermelo–Poincaré paradox. Well, it has the right message, but,
strictly speaking, the Poincaré recurrence theorem does not apply here. Indeed,
the Poincaré recurrence theorem is about the time evolution starting from almost
every initial condition, and what we study here is the time evolution starting
from an arbitrary explicit initial point configuration, which represents a zero set
in the space of all initial conditions. What we can use instead is Theorem 3.1

(“superdiscrepancy”) in the point billiard model, which gives a rigorous proof.
Indeed, it tells us that, given an arbitrary initial configuration of starting points,
if the initial velocity coordinates are linearly independent over the rationals
(representing “typical” directions), then the time evolution of this individual
trajectory of the system eventually violates square-root equilibrium in the worst
possible way. In fact, it violates square-root equilibrium (in the particle space)
infinitely many times.
In this section we focus on the following natural question: after reaching
“square-root equilibrium in the particle space”(= “snapshot equilibrium”), how
long does the time evolution of a typical individual trajectory (of the point
billiard system) stay in “square-root equilibrium?”
Proving long-term stability of square-root equilibrium in the particle space with
respect to an arbitrary but fixed measurable test set. The N-point-billiard model
in the cube can be reduced to the torus-billiard model with N point-billiards
moving on torus lines via unfolding. We study the simplest model where the
particles independently have Gaussian initial velocity distribution in the 3-space.
That is, the set of the N particles in the particle space I3 = [0, 1)3 at time t is 
where
is the N-element set of initial point configuration, and the initial velocities of the
particles are independent random variables having the same speed distribution
with density 
 which is the density of the speed
distribution of the 3-dimensional Gaussian velocity distribution (see the end of
Sec. 3). So, the trajectory of the kth particle is yk + ρktek ∈ R3 modulo one, 1 ≤ k
≤ N, where Pr[ρk ≤ u] = 
Warning: In the last line of (5.1) we used the slightly ambiguous notation
where the outside {. . .} represents a set, and the inside {. . .} represents
fractional part applied for the three coordinates, clarifying the meaning of
modulo one; we hope this minor ambiguity does not confuse the reader.
Now we switch to the configuration space: the curve in the configuration
space Id = [0, 1)d with d = 3N, representing the time evolution of the whole
system (5.1), is the following straight line in Rd modulo one: 

where
and
As we explained at the end of Sec. 3, the product space ΩGauss is equipped with
the product measure ProdMeasGauss, where the half-line [0, ∞) has the
probability density function 
 Here the arrow on top of 
indicates the 3N-dimensional vector 
formed from the N-element initial point configuration Y ⊂ [0, 1]3.
Key Fact: since the particles independently have Gaussian initial velocity
distribution in the 3-space, ProdMeasGauss is a d-dimensional Gaussian
distribution with d = 3N.
Let B ⊂ I3 = [0, 1)3 be an arbitrary but fixed measurable test set in the
particle space (=“gas container”), where vol(B) denotes the 3-dimensional
Lebesgue measure. Assume that N is large; we study the following question. Is it
true that, once a typical time evolution of the Gaussian torus-billiard system
reaches square-root equilibrium in the particle space, then it stays in that state in
the 
quantitative 
sense 
of 
factor 
30 
(say) 
for an extremely long time (with the possible exception of a totally negligible set
of t’s)? Of course, the choice of 30 in (5.5) is accidental.
Note that square-root equilibrium is clearly the best that we can hope for.
Indeed, it immediately follows from the time-lapse central limit theorem
Theorem 3.3, which gives a precise description of the (typical) square-root size
fluctuations.
(Note that the square-root equilibrium in the particle space
see (5.5), can be upgraded to the sharper inequality
For the sake of simplicity we work with the former concept (5.5). We return to
the latter at the end of this section.)

By using Theorem 4.2 (a “robust uniformity” result; see (4.13)) we give a
positive answer to this question. This is the first application of Theorem 4.2
where it acts like a short-time ergodic theorem in the configuration space (more
applications come in the next sections). It means that “the configuration space
average nearly equals the short-term time average”. The good news is that the
configuration space average can be easily computed with direct application of
probability theory (since the configuration space is a product space with product
measure; see the application of Bernstein’s Large Deviation Inequality in (5.9)
below). Moreover, Theorem 4.2 has the advantage that it works for arbitrary off-
equilibrium initial configuration (unlike Birkhoff’s ergodic theorem that works
only for typical initial condition, and a typical initial condition represents
equilibrium — which is the trivial case, since we study off-equilibrium
dynamics). Theorem 4.2 has an explicit error term (unlike the ergodic theorem
that does not have an explicit error term), and we can use it to describe the time
evolution in realistic short-term time scale. The details go as follows.
As usual, we employ the notation
(where Y = {y1 , . . . , yN} is the given N-set of initial point configuration) to
denote the corresponding point in the configuration space Id = [0, 1)3N.
The family of time evolutions Y(Gauss; ω; t), ω ∈ ΩGauss of the 3-
dimensional Gaussian torus-billiard model (in the particle space I3) is
represented 
by 
the 
family 
of 
torus 
lines 
(see 
(5.2)) 
in the configuration space Id, all starting from the same point  ∈ Id.
For an arbitrary γ > 0 define the following — very complicated and “ugly”!
— test set in the configuration space
where
with zk = (z3k−2, z3k−1, z3k), 1 ≤ k ≤ N.
We recall Bernstein’s inequality (see e.g. in [F71], a well-known large
deviation type inequality in probability theory, which will be applied several
times in this book.

Bernstein inequality. Let X1, . . . , Xn be real-valued independent random
variables with zero expectation EXi = 0 and |Xi| ≤ M, 1 ≤ i ≤ n. Then, for all
positive τ, 
In the important case of Pr[Xi = 1 or 0] = pi or qi = 1 − pi, the general result
implies for every positive γ, 
In the special case of the binomial distribution Pr[Xi = 1 or 0] = p or q = 1 − p,
we have for every positive γ,
where 
 is the standard deviation of the binomial distribution.
In the symmetric case p = q = 1/2 we have the particularly simple upper
bound for every positive γ > 0:
By using (5.9) with p = vol(B) we have
where the last inequality comes from the fact p(1 − p) ≤ 1/4. The reason why we
could apply Bernstein’s inequality is that vold is a product measure, and so the d
= 3N-dimensional volume vold(S(B; γ)) represents a large deviation probability
for N independent random variables.
For example,

which is extremely small. The long-term stability of (say) 30-square-root
equilibrium (in the particle space) is based on this numerical fact. More
precisely, we make use of (5.1)–(5.12) via Theorem 4.2 as follows.
Since the torus Id is translation invariant, we apply Theorem 4.2 with f = χS
where S is the translated copy S = S(B; γ) −  of S(B; γ) in the torus Id.
By (5.11),
and using it in Theorem 4.2 with W = 2kU, we obtain
assuming of course U ≥ 1 and eπ2U2/2 ≥ 3dU. By (5.6)–(5.7) and using S = S(B; γ)
− , we have 
where length stands for the one-dimensional Lebesgue measure.
Combining (5.13) and (5.14), we obtain the following result.

Theorem 5.1. Let Y(Gauss; ω; t), ω ∈ ΩGauss be the 3-dimensional Gaussian
torus-billiard model, and let B ⊂ [0, 1)3 be a measurable test with 3-dimensional
Lebesgue measure vol(B). Assume that 
Then for every γ > 0 and every integer k ≥ 1,
where
Remarks. In the proof we used all three aspects — start-free, complexity-free,
dimension-free — of Robust Uniformity in Theorem 4.2. Indeed, we needed
start-free, since the starting point 
of the torus line (5.2) in the configuration space Id = [0, 1)3N was arbitrary. We
also needed, complexity-free, since the test set (5.7) was extremely complicated.
Finally, we needed dimension-free, since for a large system the configuration
space has high dimension.
Probably the reader does not find Theorem 5.1 very pretty, but it is an
extremely powerful result. To illustrate the power of Theorem 5.1, let γ = 30, U
= 4, k = 100, and N = 1027; so d = 3N = 3·1027. Then by (5.12) and (5.15), 
Let ΩGauss(bad) be the set of those ω ∈ ΩGauss for which

We claim that (5.16) implies
Indeed, otherwise
which contradicts (5.16). In the last step we used the fact
Note that the choice of N = 1027 was “realistic” in the sense that there are
roughly 1027 gas molecules in a cubic box of volume 1m3. In the classical
Bernoulli gas model the gas molecules are represented by point billiards. Using
unfolding (see the beginning of Sec. 3) we can reduce the billiards-in-a-box
model to a torus-billiard model. The threshold U = 4 represents — roughly
speaking — the relaxation distance, i.e., the necessary number of “jumps” per
particle in the torus-billiard model (which is half of the number of bounces in the
billiards-in-a-box model) to reach square-root equilibrium (in the particle space)
for the typical time evolution of the Gaussian case. Assume that the gas
molecules have average speed 103 meter per second. For this Gaussian system it
takes only a few milliseconds to reach square-root equilibrium. Now (5.17) and
(5.18) have the following interpretation. Choosing an arbitrary (measurable) test
set B ⊂ [0, 1)3 in the “gas container” (= particle space) and an arbitrary N-
element initial point configuration Y, for the totally overwhelming majority of

the initial velocities (Gaussian distribution), the number of particles in B remains
very close to the expected value vol(B)N for an extremely long time, with the
possible exception of a totally negligible set of times t.
Indeed, for every (measurable) test set B ⊂ [0, 1)3 and every N = 1027-
element initial point configuration Y ⊂ [0, 1)3, there exists a subset ΩGauss(good)
where 
with
(see (5.18)), representing a totally overwhelming majority, such that for every ω
∈ ΩGauss(good),
holds for every 4 ≤ t ≤ 4 · 2100 with the possible exception of a set of times t of
total length < 10−220, see (5.17). The latter actually represents less than 10−223
seconds, which is a ridiculously short time.
Note that 4 ≤ t ≤ 4 · 2100 represents a time interval of length about 1027
seconds, which is an incredibly long time: it is roughly billion times the age of
the universe.
Finally, by (5.20)
which can be interpreted as almost constant density for an incredibly long time.
What happens if we increase the number N of particles? To answer the
question, we replace N = 1027 with N = 1080 (say). We keep γ = 30 and W = 2kU
with k = 100, and switch to U = 7, N = 1080; it follows that d = 3 · 1080. Note
that 1080 is around the estimated number of particles in the observable universe.
Then 
we 
have 
the 
perfect 
analogue 
of 
(5.16) 
Similarly, let ΩGauss(bad) be the set of those ω ∈ ΩGauss for which

Then we have the analogue of (5.18)
So again, for every (measurable) test set B ⊂ [0, 1)3 and every N = 1080-element
initial point configuration Y ⊂ [0, 1)3, there exists a subset ΩGauss(good) ⊂
ΩGauss with 
(see (5.24)), representing a totally overwhelming majority, such that for every ω
∈ ΩGauss(good)
holds for every 7 ≤ t ≤ 7 · 2100 with the possible exception of a set of times t of
total length <10−220, see (5.23). The only difference is that by (5.22) 
which is much sharper than (5.21). That is, the larger the N, the closer we get to
constant density.
Definition (5.7)
becomes useless for “small” test sets B with
A natural way to overcome this technical restriction is to replace the square-root
equilibrium concept (5.5)
with the sharper relative square-root equilibrium concept
It means, we replace (5.26) with the following modified set in the configuration
space
where p = vol(B) ≤ 1/2 and q = 1 − p ≥ 1/2. Simply repeating the argument
above — using an appropriate form of the Large Deviation Theorem in

probability theory (usually a tail probability estimation of the binomial
distribution) — we can easily prove useful relative square-root discrepancy even
for test sets as small as 
where C is a “large” absolute constant. Note that (5.29) describes a much larger
family of test sets than
and (5.29) is best possible in the sense that it is the largest class for which the
relative square-root discrepancy estimation is still useful.
What happens if we want to prove long-term stability of square-root
equilibrium with respect to a whole family of nice sets (instead of a fixed
measurable test set)? Of course we cannot expect that a system stays in square-
root equilibrium with respect to all measurable test sets simultaneously. Indeed,
this follows from a well-known measure-theoretic argument: the union of the N
trajectories of the N particles has volume zero, so the system does not visit the
complement of the union at all, despite the fact that the complement has volume
one, so the majority of the particles should be in the complement in the
overwhelming majority of the time.
Of course long-term stability does not mean that the system stays in
equilibrium forever. Indeed, the “superdiscrepancy” result Theorem 3.1 implies
that, given any kind of equilibrium state, the system will leave this equilibrium
for an infinite sequence of times tending to infinity.
6. Non-ergodic Time-flow: Closed Orbit Spherical
Systems
Closed orbit systems represent, in some sense, the complete opposite of the
box/torus billiard models that we have been studying so far. Note that closed
orbits already show up in the 2-dimensional billiard: it is the case of rational
slope at the start. But what we study is the typical time evolution of a large off-
equilibrium system, and a typical point billiard path in the unit square [0,1]2 has
irrational slope. Irrational slope implies (via the Kronecker–Weyl theorem) that
the billiard path is uniformly distributed in the unit square. The two cases —
irrational vs. rational slope — lead to diametrically opposite behaviors:
uniformity vs. periodicity.
In this section we switch from the box/torus billiard models to spherical
billiard models, where every orbit is closed. Indeed, the geodesics in the

(algebraic) torus are the torus lines, and the geodesics on the sphere S2 ⊂ R3 are
the great circles, which are closed orbits. The obvious difference is that a great
circle is certainly not uniformly distributed on the sphere. We may say,
somewhat loosely speaking, that the typical timeflow of the torus-billiard system
is ergodic (and what is more, uniquely ergodic); on the other hand, the time-flow
of the spherical billiard system is not ergodic. (Of course a closed orbit is still a
torus — a one-dimensional torus — but its dimension is less than the dimension
of the particle space.) Despite this fundamental difference between the (at least
two-dimensional) box/torus billiard systems and the closed orbit spherical
billiard systems, we can still prove similar results about the approach to
equilibrium, and its stability. First we define the Gaussian GreatCircle model,
which is an analog of the 2-dimensional Gaussian torus-billiard model. Let Y ⊂
S2 be an arbitrary N-element point set on the unit sphere — it represents the
initial configuration of a spherical system of N particles. Let yk ∈ Y be the
starting point of the kth particle. The plane passing through the origin and being
perpendicular to the (yk, −yk)-diameter (where −yk is the antipodal point of yk)
intersects the unit sphere S2 in a great circle that we call the yk-equator. (If yk is
the North or South Pole (0, 0, ±1), then we get back the usual Equator.) Each
half great circle in S2 going from yk to −yk intersects the yk-equator in one point;
this gives a natural parametrization of the family of great circles passing through
yk. The parameter, denoted by αk , runs between 0 and 2π. We may refer to
parameter αk as the angle. We choose a great circle in the family by choosing an
angle αk with uniform distribution in the interval [0, 2π). The kth particle moves
with constant speed on this great circle. Gaussian means that we choose the
speed vk (here the speed can be positive and negative) of the kth particle by the
one-dimensional normal distribution, that is, the density function of the
distribution of the speed v = vk is (2π)−1/2 e−v/2 (negative speed means that the
particle moves in the opposite direction). The pair (αk, vk) of the angle and the
speed determine the initial velocity. Finally, we choose the N initial velocites (αk,
vk), 1 ≤ k ≤ N independently of each other. This means that 
is the initial velocity space. Let
denote the corresponding product measure. Here of course volN stands for the N-

dimensional Lebesgue measure and GaussN is the N-dimensional Gauss measure
in the N-space RN with density function 
representing the N-dimensional standard normal distribution.
Next we define a second spherical model, which is motivated by
Archimedes’s famous discovery that the surface area of a spherical belt depends
only on the “height” of the belt. The “height” is exactly the length of the
projection on the perpendicular diameter. This is why in the second spherical
model the speed of the motion of the kth particle on the corresponding great
circle is not constant. Instead it is the motion of the projection on the (yk, −yk)-
diameter that has constant speed (where −yk is the antipodal point of yk).
Constant projection speed on the diameter with endpoints yk and −yk means that
the actual speed of the kth particle on the great circle (= orbit) depends on the
arclength distance from yk. Indeed, if 0 ≤ β ≤ π denotes the arclength, then the
actual speed of the kth particle on its orbit is uk/ sin β, where uk is the constant
projection speed. Notice that the actual speed is infinite at yk and −yk.
More precisely, we define the Gaussian GreatCircleDiameter model as
follows. As usual, let Y ⊂ S2 be an arbitrary N-element point set on the unit
sphere — it represents the initial configuration of a spherical system of N
particles. Let yk ∈ Y be the starting point of the kth particle. Again we choose a
great circle in S2 passing through yk the same way by choosing an angle αk with
uniform distribution in the interval [0, 2π). The kth particle moves on this great
circle in such a way that its projection on the (yk, −yk)-diameter has constant
speed uk (positive or negative; −yk is the antipodal point of yk). We refer to this
constant speed as the projection-speed. We choose the projection-speed uk of the
kth particle by the one-dimensional normal distribution, that is, the density
function of the distribution of the projection-speed u = uk is (2π)−1/2 e−u2/2. The
pair (αk, uk) of the angle and the projection-speed determine the initial velocity.
Finally, we choose the N initial velocites (αk, uk), 1 ≤ k ≤ N independently of
each other. This means that the Gaussian GreatCircleDiameter system has
exactly the same initial velocity space and product measure as the Gaussian
GreatCircle system. Nevertheless, to emphasize the difference in the
interpretation (constant speed vk versus constant projection-speed uk) we write an
extra 
D 
(= 
Diameter) 
as 
follows: 

where
denotes the corresponding product measure.
We study how the two spherical models, the (Gaussian) GreatCircle model
and the GreatCircleDiameter model, approach equilibrium and stay in
equilibrium. Again we use Theorem 4.2 to describe the long-term stability of
equilibrium (in the particle space = sphere).
Despite the fact that the GreatCircle model is simpler and more natural, the
GreatCircleDiameter model has the simpler and more elegant result. So we start
with the latter.
Again let B ⊂ S2 be an arbitrary but fixed measurable test set; here SA∗(B)
denotes the normalized surface area (so SA∗(S2) = 1), and let Yω;t denote the
(Gaussian) GreatCircleDiameter model with initial configuration Y ⊂ S2 and 
where
We ask the same question as for the (at least 2-dimensional) torus-billiard model.
Assume that N is large; is it true that, once a typical time evolution of the system
reaches square-root equilibrium (in the particle space), then it stays in that state
for an extremely long time (with the possible exception of a totally negligible set
of t’s)? We give a positive answer to this question by applying Theorem 4.2 as a
short-time ergodic theorem in the configuration space (in fact, it works as a
“large deviation theorem”).
For every ω∗ ∈ [0, 2π)N, let GCk = GCk(ω∗) denote the orbit of the kth
particle: it is a great circle containing the antipodal points yk ∈ Y and −yk with
angle αk. Since the projection of the motion on the (yk, −yk)-diameter has
constant speed, we replace the motion of the kth particle on the great circle GCk
= GCk(ω) with the constant speed motion in the interval [0,4) interpreted as a 1-
dimensional torus (“projection”). Of course [0,4) comes from the fact that we
double-count the diameter: first we go from yk to −yk, and the second part is the
reverse trip going back from −yk to yk . For notational convenience we divide by
4 in the sense that we replace the constant speed motion in the 1-dimensional

torus [0, 4) with the constant speed motion in the 1-dimensional unit torus [0, 1).
This means that, for every fixed ω∗ ∈ [0, 2π)N, the family of time evolutions
Yω;t, 
ω 
= 
(ω∗, u) 
∈ 
Ω(Gauss; 
GCDsphere) 
of 
the 
(Gaussian)
GreatCircleDiameter model with initial configuration Y ⊂ S2 is represented by
the family of torus lines in the configuration space IN = [0, 1)N, all starting from
the origin 0 ∈ IN.
The great circle GCk = GCk(ω∗) (i.e., the orbit of the kth particle) intersects
the given 2-dimensional measurable test set B ⊂ S2 in a one-dimensional
measurable set for almost every ω∗ ∈ [0, 2π)N (set of initial angles). This is
Fubini’s theorem in the theory of Lebesgue measure. Consider the projection of
the intersection GCk(ω∗) ∩ B on the double copy of the (yk, −yk)-diameter,
where the latter is represented as the interval [0, 4). Let Bk = Bk(ω∗) ⊂ [0, 4)
denote this projection, and again we apply the natural division by 4: 
Write bk(ω∗) = length(Bk(ω∗)), where, as usual, length stands for the 1-
dimensional Lebesgue measure. The mean value of bk(ω∗), ω∗ ∈ [0, 2π)N is
clearly equal to the normalized surface area of the test set B ⊂ S2; formally, 
(where dω∗ represents the N-dimensional Lebesgue measure).
Write
Of course, we could choose here any other “large deviation factor” γ (like we did
in Theorem 5.1). Note that γ = 30 is a good choice for the illustration below.
Since the initial velocities are chosen independently, we can apply
Bernstein’s large deviation inequality (5.8)
Let ω∗ ∈ [0, 2π)N be fixed, and write

Again using Bernstein’s large deviation inequality (5.8), we obtain
which corresponds to (5.11)–(5.12), where we used (5.9). (Here in (6.6) we use
(5.8) in a trivial way, and to compensate for that loss, we replace the factor 30
with 60.)
We apply Theorem 4.2 with γ = 60 and f = χS where S = S(B; ω∗) ⊂ IN. Thus,
for every ω∗ ∈ [0, 2π)N, integer k ≥ 1 and U ≥ 1 satisfying eπ2U2/2 > 3UN, 
where
To illustrate the power of (6.7) (combined with (6.4)), let
Then by (6.7), for every ω∗ ∈ [0, 2π)N,

Let RN(ω∗; bad) be the set of those u ∈ RN for which
where
We claim that (6.11) implies
Indeed, otherwise

which contradicts (6.10). Here we used
Again the threshold U = 4 represents — roughly speaking — the necessary
number of “rounds” per particle in the (Gaussian) GreatCircleDiameter model to
reach square-root equilibrium (in the particle space for the typical time
evolution). Assume that the average projection-speed is 103 meter per second.
For this system it takes only a few milliseconds to reach square-root equilibrium
(in the particle space). Now (6.3)–(6.4) and (6.11)–(6.12) have the following
interpretation. Choosing an arbitrary (measurable) test set B ⊂ S2 on the unit
surface with normalized surface area SA∗(B) and an arbitrary N-element initial
point configuration Y, for the totally overwhelming ma jority of the initial
velocities (Gaussian distribution), the number of particles in B remains very
close to the expected value SA∗(B)N for an extremely long time, with the
possible exception of a totally negligible set of times t.
Indeed, for every (measurable) test set B ⊂ S2 and every N = 1027-element
initial 
point 
configuration 
Y 
⊂ 
S2 
, 
there 
exists 
a 
subset 
with
(see (6.3)–(6.4) and (6.12); in particular, we used the numerical fact that

holds for N = 1027) representing a totally overwhelming majority, such that for
every ω ∈ Ω(Gauss; GCDsphere; good),
(where 90 comes from 90 = 30 + 60; see (6.3) and the definition of RN(ω∗; bad))
holds for every 4 ≤ t ≤ 4 · 2100 with the possible exception of a set of times t of
total length < 10−220, see (6.11). The latter represents less than 10−223 seconds —
a ridiculously short time.
Note that 4 ≤ t ≤ 4 · 2100 represents an incredibly long time interval: it is
roughly billion times the age of the universe.
Finally, by (6.13)
which can be interpreted as almost constant density for an incredibly long time.
Summarizing, once a typical time evolution of this (Gaussian)
GreatCircleDiameter system reaches square-root equilibrium, then it stays in that
state 
in 
the 
quantitative 
sense 
of 
90-square-root 
equilibrium 
for an incredibly long time (with the possible exception of a totally negligible set
of t’s).
Here is a nutshell summary of what we did in Secs. 5–6 so far. Despite the
fundamental difference between the (at least 2-dimensional) torus-billiard model
and the GreatCircleDiameter model on the sphere (a typical torus line is
uniformly distributed, but a great circle — a closed orbit — is certainly not
uniform on the sphere) the two systems show striking similarities. Both Gaussian
billiard systems reach square-root equilibrium (in the particle space)
superexponentially fast, and stay in square-root equilibrium for an incredibly
long time.
What about the (simpler) GreatCircle model on the sphere? Well, we show
that it is similar to the GreatCircleDiameter model with one substantial
difference: the normalized surface area is replaced by another measure which
depends on the initial configuration Y ⊂ S2.
The details go as follows. We repeat the argument of the case of the
(Gaussian) GreatCircleDiameter model with some necessary changes. Let e ∈ S2

be an arbitrary point on the unit sphere; the first novelty is that we need to define
an inhomogeneous probability measure SA∗e(...) on the unit sphere that depends
on the given point e (and also SA∗e(S2) = 1). By symmetry, we can assume that e
= e0 = (0, 0, 1) is the North Pole, and we use the spherical coordinates 
to parametrize the unit sphere. For an arbitrary measurable set A ⊂ S2 let
where area stands for the 2-dimensional Lebesgue measure. For a general e ∈ S2
different from the North Pole, let Rote ∈ SO(3) be a rotation moving e to the
North Pole e0 = (0, 0, 1), and define the measure SAe
∗∗(...) as 
Let B ⊂ S2 be an arbitrary but fixed measurable test set, and let Yω;t denote
the (Gaussian) GreatCircle model with initial configuration Y ⊂ S2 and 
where
We ask the usual question. Assume that N is large; is it true that, once a typical
time evolution of the system reaches square-root equilibrium, then it stays in that
state for an extremely long time (with the possible exception of a totally
negligible set of t’s)? Again we use Theorem 4.2 to give a positive answer.
For every ω∗ ∈ [0, 2π)N, let GCk = GCk(ω∗) denote the orbit of the kth
particle: it is a great circle containing the antipodal points yk ∈ Y and −yk with
angle αk. The motion of the kth particle on the great circle GCk = GCk(ω) is
equivalent to a motion in the interval [0, 2π) interpreted as a 1-dimensional
torus. For notational convenience we divide by 2π in the sense that we replace
the constant speed motion in the 1-dimensional torus [0, 2π) with the constant
speed motion in the 1-dimensional unit torus [0, 1). This means that, for every
fixed ω∗ ∈ [0, 2π)N, the family of time evolutions Yω;t, ω = (ω∗, v) ∈ Ω(Gauss;
GCsphere) of the Gaussian GreatCircle model with initial configuration Y ⊂ S2

is represented by the family of torus lines in the configuration space IN = [0, 1)N,
all starting from the origin 0 ∈ IN.
The great circle GCk = GCk(ω∗) (i.e., the orbit of the kth particle) intersects
the given 2-dimensional measurable test set B ⊂ S2 in a 1-dimensional
measurable set for almost every ω∗ ∈ [0, 2π)N (Fubini’s theorem). Write 
(length stands for the 1-dimensional Lebesgue measure). The mean value of
bk(ω∗), ω∗ ∈ [0, 2π)N is clearly equal to the 
-measure (see (6.15)–(6.16)) of
the test set B ⊂ S2; formally, 
Again we choose γ = 30 as the “large deviation factor,” and write
Since the initial velocities are chosen independently, by Bernstein’s large
deviation inequality (5.8),
a perfect analog of (6.4).
Let ω∗ ∈ [0, 2π)N be fixed, and write
Again using Bernstein’s large deviation inequality (5.8), we obtain
which is the perfect analogue of (6.6). Again we apply Theorem 4.2 with f = χS
where S = S(B; ω∗) ⊂ IN, and obtain the perfect analogue of (5.14): let k ≥ 1 be
an 
integer, 
for 
every 
ω∗ 
∈ 
[0, 
2π)N, 

where
Again for illustration we choose U = 4, k = 100 and N = 1027. Then by
(6.23), for every ω∗ ∈ [0, 2π)N,
Again let RN(ω∗; bad) be the set of those v ∈ RN for which
where
Again we have
which is the perfect analog of (6.12).
Again the threshold U = 4 represents — roughly speaking — the necessary

number of “rounds” per particle in the Gaussian GreatCircle model to reach
square-root equilibrium (in the particle space for the typical time evolution). The
only difference is that in the definition of square-root equilibrium we replace the
homogeneous measure (= surface area) with an inhomogeneous measure that
depends 
on 
the 
initial 
configuration 
Y 
= 
{y1,..., 
yN}: 
see (6.15) and (6.16)
Again assume that the average speed is 103 meter per second. Again it takes
only a few milliseconds to reach square-root equilibrium with respect to the
inhomogeneous measure 
 (see (6.27)). Similarly to (6.3)–(6.4) and (6.11)–
(6.12), we have the following interpretation of (6.5)–(6.6) and (6.11)–(6.12).
Choosing an arbitrary (measurable) test set B ⊂ S2 on the unit surface and an
arbitrary N-element initial point configuration Y, for the totally overwhelming
ma jority of the initial velocities (Gaussian distribution), the number of particles
in B remains very close to 
(B)N for an extremely long time, with the possible
exception of a totally negligible set of times t.
This proves long-term stability of square-root equilibrium with respect to an
arbitary (possibly “ugly”) but fixed measurable test set B ⊂ S2.
Summarizing, we showed that the (Gaussian) GreatCircle model and the
GreatCircleDiameter model are very similar. The concrete numerical values
remain exactly the same; the only change is the appearance of the
inhomogeneous measure 
 in the first model, replacing the normalized surface
area SA∗ in the second model.
In the next section we study models where the closed orbits are line
segments.
7. Closed Orbit Polar Systems
We know a lot about the asymptotic behavior of the billiard path in a box, but,
unfortunately, we know much, much less about the billiard motion in a general
underlying set. It is quite humiliating how little we know about the simplest and
most natural problems about billiards. For example, let ∆ be an arbitrary triangle:
is it true that the billiard in triangle ∆ is uniform for almost every initial
condition (= starting point and direction)? We just have a very modest goal here:
all what we want is the weakest quantitative form of uniformity: is it true or not

that, as T → ∞, for almost every initial condition, the actual time the (constant
speed) billiard path spends in a given nice subset of ∆ as t runs in 0 < t < T
equals the expected time (= T · relative area) plus o(T)? Shockingly, this
innocent-looking question is a famous long-standing open problem. All what we
know is that the answer to this question is affirmative in the narrow special case
where the triangle is “rational,” meaning that the angles are rational multiples of
π. The proof of this special case is already difficult; see [Ke-Ma-Sm86]
(unfortunately this proof technique does not seem to work in higher dimension).
Also, this special case is a “soft” qualitative result, and does not give any
reasonable quantitative estimation on the speed of convergence to uniformity.
For comparison, note that replacing the triangle with a rectangle, we have
superuniformity(!); see Theorems A1–A2 in Sec. 2. On the other hand, for many
other natural shapes the billiard is very bad, uniformity clearly fails. For
example, if the billiard table is a circular disk (= solid circle), then no infinite
billiard path is uniformly distributed inside the circular disk. (Here of course we
talk about uniformity in the traditional sense of Weyl, i.e., with respect to all
Riemann integrable test functions, or equivalently, all Jordan measurable test
sets.) As far as we know, the only other cases beyond the rectangle billiard,
where we have satisfying quantitative results, are the equilateral triangle billiard,
π/3-right-triangle billiard, π/4-right-triangle billiard, and finally, the geodesic
flow on an equifacial tetrahedron. We briefly elaborate on this. At the beginning
of Sec. 3 we explained how unfolding converts the square billiard orbit (= zig-
zag) into a straight line on the plane. This raises the following question: For
what other shapes can the unfolding used in Sec. 3 (= iterated reflection across a
line) convert the billiard orbit (= zig-zag) into a straight line on the plane? Well,
it is clearly necessary that the process of unfolding applied to the given shape (=
billiard table) gives a perfect tiling of the plane. Let us start with triangles; let T
be a triangle. In Sec. 3 unfolding of T means the infinite process where we select
a side of T, and reflect T across this side; we obtain a new polygon T1; next we
select a side of T1, and reflect T1 in this side; we obtain another polygon T2; and
so on — we keep doing this in all possible ways. When does the complete
infinite sequence T, T1 , T2,... of congruent triangles tile the whole plane? We
clearly need that the angles of T have the form 2π/k1, 2π/k2, 2π/k3, where ki are
positive integers. Since reflection across a line changes the orientation of a

triangle, we also need that every ki is even, i.e. ki = 2ℓi, 1 ≤ i ≤ 3. Since the sum
of degrees in a triangle is 180 (or π), we need to find the positive integer
solutions of the equation 
with ℓi ≥ 2. We can assume 2 ≤ ℓ1 ≤ ℓ2 ≤ ℓ3. Clearly ℓ1 ≤ 3, so either ℓ1 = 3 or ℓ1
= 2. If ℓ1 = 3 then (3, 3, 3) is the only solution of (7.1). If ℓ1 = 2 then (2, 3, 6) and
(2, 4, 4) are the only solutions of (7.1). This gives a very short list of special
triangles: (1) equilateral triangle, (2) right triangle with angle π/3 (= half of an
equilateral triangle). (3) isosceles right triangle (= half of a square).
If we switch from triangles to quadrilaterals, then Eq. (7.1) changes to
which has only one integer solution with ℓi ≥ 2; namely, ℓ1 = ℓ2 = ℓ3 = ℓ4 = 2,
representing the rectangle.
If we switch from quadrilaterals to polygons of r ≥ 5 sides, then Eq. (7.2)
changes to
which has no integer solution with ℓi ≥ 2. Indeed,
So far everything was based on reflection across a line; but in geometry there
is also a different kind of reflection called “reflection in a point”. Reflection
across a line led to the disappointingly short list of the three special triangles
mentioned above. In sharp contrast, using reflection in a point we have far more
freedom: we can tile the plane with any triangle. Indeed, we simply start with an
arbitrary parallelogram lattice, and split every parallelogram into two congruent
triangles by means of the same diagonal (i.e., the diagonals are all parallel).
Neighboring triangles that share a side are congruent via reflection in the
midpoint of the common side.
Next we explain how this triangle tiling of the plane with an arbitrary (acute)
triangle helps to describe the uniformity of the geodesics on an equifacial
tetrahedron surface. Equifacial means that the four faces of the tetrahedron are
congruent triangles; the simplest special case is the regular tetrahedron.
It is easy to see that polygon billiards and geodesics on a flat surface are
basically the same. Indeed, we may look at a polygon billiard as a geodesic on a

two-face polygon: with top face and bottom face. Indeed, when a point billiard
on the top face hits a side, it goes under to the bottom face, keeping the linear
orbit. (And of course the other way around for the bottom face.) Consider a
triangle tiling of the plane with an acute triangle ∆. We can easily fold ∆ into an
equifacial tetrahedron surface in the 3-space. First we obtain four congruent half
triangles by considering the midpoints; formally, if A, B, C are the vertices of ∆,
then let C1, A1, B1 be the midpoints of the sides AB, BC, CA of ∆ in this order.
Next we simply fold along the three line segments in ∆ which join the midpoints
A1, B1, C1 of two of the three sides. Then the three vertices A, B, C come
together in a point D in the 3-space, and we obtain an equifacial tetrahedron
surface TetS = TetS(∆) with vertices A1, B1, C1, D. (This is where we use the fact
that ∆ is acute: starting with a right triangle ∆, A1, B1, C1, D turn out to be
coplanar, providing a pathological tetrahedron. The case of obtuse ∆ is even
“more pathological”.) Note that this way the boundary points of the triangle ∆
glue together in pairs; for example, B1A becomes identical to B1C via the
reflection in the midpoint B1.
The simplest equifacial tetrahedron is of course the regular tetrahedron.
Let L be a straight line in the plane that contains triangle ∆. For simplicity,
assume that L intersects the inside of ∆; let Q ∈ L ∩ ∆ be such a common point.
It is easy to see that the whole straight line L in the plane is wrapped up as a
geodesic on the equifacial tetrahedron surface 
Fig. 7.1
Note that in general, a geodesic on a polyhedron surface consists of straight line
segments that fit together to a straight line at the boundary, where the line

segment hits an edge: the consecutive line segments become collinear when we
turn the two neighboring faces (that share the edge) into coplanar position.
The geometric explanation why a straight line L in the plane is wrapped up
as a geodesic on the equifacial tetrahedron surface
is based on the effect of reflection in a point. Indeed, moving from point Q along
the line L in one direction, we reach a congruent neighbor ∆1 of ∆ in the triangle
lattice, and the fact that ∆1 is congruent to ∆ via reflection in the midpoint of the
common side means that the part of L in ∆1 corresponds exactly to the next part
of the geodesic on the tetrahedron surface TetS. Similarly, when moving further
along L we reach a neighbor ∆2 of ∆1 in the triangle lattice, then the part of L in
∆2 corresponds exactly to the next part of the geodesic on the tetrahedron surface
TetS, and so on.
An alternative way to say the same thing in terms of the smaller half
triangles goes as follows. We label the midpoint triangle A1 B1 C1 with 0, label
AC1 B1 with 1, label BA1 C1 with 2, and label CB1 A1 with 3; this way the four
faces of tetrahedron surface TetS are labeled with 0,1,2,3. Next we divide every
congruent copy of ∆ in the triangle lattice into four congruent half triangles
(“halves”), and extend the labeling of the four halves of ∆ to the whole plane by
using the following simple rule: the midpoint triangles all have the same label 0,
and if two half triangles have exactly one common vertex, then they have the
same label (1 or 2 or 3). Now wrapping-up-a-line means that, if a motion on a
straight line L in the plane is in a midpoint triangle labeled i, then the
corresponding motion on the geodesic (= wrapped up line) is on the face of the
tetrahedron surface 
with the same label i (i = 0, 1, 2, 3).
The next figure illustrates reflection of ∆ = ABC in point A1, where the latter
is rrepresented by the dot in the middle.
Figure 7.2 illustrates the extension of “reflection in a point” over the whole
plane.
Here g1 g2 is a geodesic of the tetrahedron surface, where g2 is the directed
continuation of g1, obtained by reflection of the dashed line segment with arrow
(= linear extension of g1) in A1 (= dot in the middle). This illustrates how
geodesics are unfolded into straight lines.

Let S be an arbitrary measurable subset of triangle ∆ = ABC. Again let A1
denote the midpoint of BC, and let ∆1 denote the reflection of ∆ in the midpoint
A1. Similarly, let S∗ denote the reflection of S in the midpoint A1, and let A2
denote the reflection of A in the midpoint A1. Let P denote the parallelogram
with vertices A, B, A2, C, and let L = L(∆) denote the parallelogram lattice on
the plane with fundamental parallelogram P.
Fig. 7.2
Fig. 7.3
In Fig. 7.3 the four big dots are the vertices of fundamental parallelogram P,

and the dashed straight line with arrow is an unfolded geodesic of the equifacial
tetrahedron. (Since every midpoint triangle has label 0, in the last figure we
omitted — for notational simplicity — the midpoint triangles.) The geometric
method of “wrapping up a straight line to a geodesic on an equifacial tetrahedron
surface” explains why the uniformity of a straight line L (see the dashed straight
line with arrow) modulo P in the plane with respect to test set 
 is
equivalent to the uniformity of the corresponding geodesic (= wrapped up copy
of line L) on the equifacial tetrahedron surface TetS = TetS(∆) with respect to
test set S.
The uniformity of a straight line L modulo P is analogous to the problem of
the uniformity of a torus line modulo [0, 1)2 . Indeed, every parallelogram lattice
L in the plane can be mapped to the integer square lattice Z2 via some linear
transformation of the plane. This means, whatever result is available on the
uniformity of a 2-dimensional torus line, it also applies (with straightforward
modification) for the uniformity of the geodesic flow on any equifacial
tetrahedron surface.
This “transference principle” comes from unfolding via reflection in a point.
It is an analog of the “transference principle” that comes from unfolding via
reflection across a line. Applying the latter guarantees that, whatever result is
available on the uniformity of a 2-dimensional torus line, it also applies for the
uniformity of a square/rectangle billiard orbit. Similarly, whatever result is
available on the uniformity of a 2-dimensional torus line, it also applies for the
uniformity of the three special triangle billiard orbits: (1) equilateral triangle, (2)
right triangle with angle π/3, (3) isosceles right triangle.
It is very surprising that this geometric argument — wrapping up a straight
line via reflection in a point — which works so well for the (say) regular
tetrahedron surface, does not seem to work for the seemingly equally simple
cube surface. In fact, we do not know any other polyhedron, or any other
“reasonable” surface, for which this method works.
Physicists call a dynamical system “integrable” if it is (in some natural way)
equivalent to the torus line in a square. The short list — (1) rectangle billiard, (2)
equilateral triangle billiard, (3) π/3-right-triangle billiard, (4) π/4-right-triangle
billiard, (5) equifacial tetrahedron geodesic — represents the known cases of
“integrable” billiard/geodesic dynamical systems. Is the list complete? This is a
very interesting open problem. These are the only cases when we have good

quantitative results.
The disappointing (or even humiliating!) lack of quantitative results for
general billiards/geodesics motivates the introduction of the following drastic
simplification of the billiard model that we call the PolarBilliard model. Let A ⊂
Rh be an arbitrary bounded closed convex set in the h-space (noting that our
favorite dimensions are h = 2 and 3). Let P ∈ A be an arbitrary point in A, and let
 be a half-line starting from P. By definition the intersection  ∩ A is a line
segment; we denote it by IA(P; ), or IA(P; e), where e ∈ Sh−1 is the direction of
the half-line . The PolarBilliard motion simply means that a particle moves
with constant speed (to be specified later), starting from P, on the line segment
IA(P; ) back and forth like a 1-dimensional billiard, i.e., it bounces back when it
hits the boundary of A and also when it hits P. The advantage of this simplified
billiard model is that we can describe the approach to equilibrium, and the
stability of equilibrium.
Let Y = {y1,..., yN} be an arbitrary N-element set in the convex set A; it
represents the initial configuration of the N-particle PolarBilliard model. The kth
particle starts from yk, and moves with constant speed vk on a line segment IA(yk;
ek) back and forth like a 1-dimensional billiard. Here ek ∈ Sh−1 is a unit vector
on the unit sphere, and the speed vk = vk(yk; ek) depends on both yk and ek (see
below). We assume that every ek is uniformly distributed on the sphere Sh−1, and
every vk has the form 
where uk has standard normal distribution. (So the speed can be negative,
meaning that the particle goes backward — notice that it is exactly the same
motion as the forward motion!) Moreover, we assume that e1,..., eN, u1,..., uN are
2N 
independent 
random 
variables. 
In 
other 
words, 
is the initial velocity space (of the whole system) with the product measure
where SA∗ denotes the normalized surface area on Sh−1 (i.e., SA∗(Sh−1) = 1),
and, as usual, GaussN denotes the N-dimensional Gauss measure (= N-
dimensional standard normal distribution). The initial configuration Y, the vector
and Eq. (7.4) determine the time evolution of the N-particle PolarBilliard

system; as usual, we denote it by Yω,t. We refer to it as the Gaussian
PolarBilliard model.
There is some similarity between the (Gaussian) GreatCircle model and the
PolarBilliard model. In both models each particle moves on its own closed orbit
(great circle or line segment) with its own constant speed (depending on the
particle).
We study the usual problem. Assume that N is large; is it true that, once a
typical time evolution of the system (= Gaussian PolarBilliard model) reaches
square-root equilibrium (in the particle space), then it stays in that state for an
extremely long time (with the possible exception of a totally negligible set of
t’s)? We recall that in the GreatCircle model the equilibrium was defined in
terms of an inhomogeneous measure that depends on the inital configuration Y.
We show — by using Theorem 4.2 as a short-time ergodic theorem in the
configuration space (in fact, it works as a “large deviation theorem”) — that,
similarly to the GreatCircle model, the PolarBilliard model exhibits long-term
stability in equilibrium, and the equilibrium is defined in terms of an
inhomogeneous measure that depends on the initial configuration Y.
In Sec. 6 we also introduced a second — at first sight less natural —
spherical model, the (Gaussian) GreatCircleDiameter model, which turned out to
exhibit a simpler time evolution. Indeed, in the second spherical model the
equilibrium is defined in terms of a homogeneous measure independent of the
inital configuration Y. This raises the natural question: Is there a Polar model for
which the equilibrium is defined in terms of a measure independent of the initial
configuration Y?
The answer is yes: we show that the PolarSpeedUp model (to be defined
below) has the desired property. Note that the PolarSpeedUp model is similar to
the PolarBilliard model, but there are two crucial changes: (1) the speed of the
kth particle on the line segment IA(yk; ek) is not constant; (2) the direction vector
ek is not necessarily uniformly distributed on the unit sphere Sh−1. The details go
as follows.
Again we need a bounded closed convex set in the h-space A ⊂ Rh — it is
the underlying set. Again let Y = {y1, . . . , yN} be an arbitrary N-element set in

the convex set A; it represents the initial configuration of the N-particle
PolarSpeedUp model. Again the kth particle starts from yk, and moves on a line
segment IA(yk; ek) until it hits the boundary of A, back and forth like a 1-
dimensional billiard. Again ek ∈ Sh−1 is a unit vector on the unit sphere. The
(absolute 
value 
of 
the) 
speed 
of 
the 
kth 
particle 
is 
where r is the distance of the particle from the starting point yk, ak =
length(IA(yk; ek)), and uk is a real number to be specified later.
As we said above, ek is not necessarily uniformly distributed on the sphere Sh
−1. To describe the distribution, we define a measure measA;yk on Sh−1, which
depends on both A and yk. For an arbitrary measurable subset W ⊂ Sh−1, let 
where SA∗ is the normalized surface area.
We assume that the direction of the kth particle ek is measA;yk-uniformly
distributed on the sphere Sh−1 (see (7.8)), and every uk has standard normal
distribution. Moreover, we assume that e1, . . . , eN, u1, . . . , uN are 2N
independent 
random 
variables. 
In 
other 
words, 
is the initial velocity space (of the whole system) with the product measure
similarly to (7.5)–(7.6). The initial configuration Y, the vector
and Eq. (7.7) determine the time evolution of the N-particle PolarSpeedUp
system; as usual, we denote it by Yω,t. We refer to it as the Gaussian
PolarSpeedUp model.
It is not an accident that in (7.7) we used the letter r familiar from polar
coordinates. The motivation for the mysterious equation (7.7) comes from the
volume formula

where dSA(e), e ∈ Sh−1 represents the surface area, dSA∗(e) represents the
normalized surface area (i.e., SA∗(Sh−1) = 1), and 
Note that (7.11) means to compute the volume of the translated copy A−yk of A
(i.e., yk moves to the origin) by switching to the polar coordinates.
Similarly to Sec. 6, first we study the typical time evolution of the
(Gaussian) PolarSpeedUp model, which is somewhat similar to the (Gaussian)
GreatCircleDiameter model. Indeed, in both models the kth particle has infinite
speed whenever it returns to the starting point yk. We closely follow the
argument in Sec. 6.
Again let B ⊂ A be an arbitrary but fixed measurable test set. Let Yω;t denote
the (Gaussian) ChordSpeedUp model with initial configuration Y ⊂ A and 
where
For every ω∗ ∈ (Sh−1)N, let
denote the orbit of the kth particle: it is a line segment starting from yk in the
direction ek ∈ Sh−1 until it hits the boundary of A.
For notational convenience write Ik = Ik(ω∗) = [0, ak], where
and 0 ∈ Ik represents the starting point yk of the motion of the kth particle. By
(7.7) 
the 
motion 
of 
the 
kth 
particle 
has 
speed 
meaning the absolute value of the speed. So, the kth particle starts from 0 with
infinite speed, goes (by slowing down) to the right endpoint ak, where it bounces
back by reversing the velocity vector. It keeps speeding up to infinite speed at 0,

where it bounces back reversing the velocity vector, and so on. This is a (varying
speed) billiard motion. To obtain a (verying speed) torus motion, we apply the
trick 
of 
unfolding 
in 
its 
simplest 
1-dimensional 
form. 
Let 
denote the interval twice as long as Ik, and we extend the motion on Ik to 
by taking the reflection. That is, just like the motion on Ik, the kth particle starts
from 0 with infinite speed, and goes (by slowing down) to the right endpoint ak;
then it keeps going to the right speeding up to infinite speed at 2ak. Then it
jumps back to 0, where it keeps going to the right slowing down; and so on,
extending periodically, always going to the right. In the torus motion on 
 the
speed of the kth particle is 
Consider the function
The derivative of fk is
The function fk maps the interval [0, ak] to the unit interval Jk = [0, 1]. Consider
a particle moving with constant speed uk from the left endpoint of Jk to its right
endpoint. The motion induced by the inverse mapping fk
−1 represents a varying
speed motion on the interval [0, ak] from left to right: at x ∈ [0, ak] the induced
speed is (the reciprocal in (7.15)) 
which is exactly (7.12).
Next we extend the mapping fk : Ik = [0, ak] → Jk = [0, 1] by the usual trick
of reflection to convert the billiard motion to a torus motion (“unfolding”). Thus
we obtain 
Consider now a torus motion of a particle moving with constant speed uk
from the left endpoint 0 of 
 to its right endpoint 2. Then the motion induced by
the inverse mapping fk
−1 represents a varying speed torus motion from left to right
on the interval , where the speed is exactly (7.13).
Since 
 has length 2, and for the application of Theorem 4.2 it is convenient
to work with the unit torus, we “divide by 2” to obtain a torus motion with
constant speed uk in the unit interval [0, 1).
This means that, for every fixed ω∗ ∈ (Sh−1)N, the family of time evolutions

Yω;t, ω = (ω∗, u) ∈ Ω(Gauss; A; PolSU) of the Gaussian Polar-SpeedUp model
with initial configuration Y ⊂ A is represented by the family of torus lines in the
configuration space [0, 1)N, all starting from the origin 0 ∈ [0, 1)N.
The line sement Ik(yk; ek), i.e., the orbit of the kth particle that we prefer to
represent in the form [0, ak (ek)], intersects the given (measurable) h-dimensional
test set B ⊂ A in a 1-dimensional measurable set for almost every ω∗ ∈ (Sh−1)N
(N-tuple of directions). This is Fubini’s theorem. Let 
represent the intersection Ik(yk; ek) ∩ B as a subset of [0, ak(ek)]; let 
be the induced normalized one-dimensional measure of Bk(ω∗), induced by the
mapping fk.
The measA;yk-mean value (i.e., a weighted average) of bk(ω∗), ω∗ ∈ (Sh−1)N
is 
where in the last step we used the polar coordinate volume formula (7.11).
By similarity we can assume that volh(A) = 1. Then (7.18) implies that the
measA;yk-mean value of bk(ω∗), ω∗ ∈ (Sh−1)N is volh(B).
Write
Of course, we could choose here a general “large deviation factor” γ (like we did
in Theorem 5.1). Note that γ = 30 is a good choice for our usual illustration (see
below).
Let 
 denote the product measure on the product space (Sh−1)N (i.e.,
each factor Sh−1 has the same measure measA;yk).

Since the initial velocities are chosen independently, by Bernstein’s large
deviation inequality (5.8),
Let ω∗ ∈(Sh−1)N be fixed, and write
Using Bernstein’s large deviation inequality (5.8), we obtain
Like in Secs. 5–6, we apply Theorem 4.2 with γ = 60 and f = χS where S = S(B;
ω∗) ⊂ [0, 1)N. Thus, we obtain the following perfect analog of (6.7): for every
ω∗ ∈ [0, 2π)N, integer k ≥ 1 and U ≥ 1 satisfying eπ2U2/2 > 3UN, 
where
As usual, to illustrate (7.23), we choose U = 4, k = 100 and N = 1027. Then
we obtain the perfect analogue of (6.10)–(6.12).
Summarizing, the threshold U = 4 represents — roughly speaking — the
necessary number of zig-zags per particle in the (Gaussian) PolarSpeedUp model
to reach square-root equilibrium (in the particle space for the typical time
evolution). As usual, assume that the average speed is 103 meter per second. For
this system it takes only a few milliseconds to reach square-root equilibrium.
Choosing an arbitrary (measurable) test set B ⊂ A — where A is an h-

dimensional convex set of volume volh(A) = 1 with h ≥ 2 — and an arbitrary N-
element initial point configuration Y, for the totally overwhelming majority of
the initial velocities (Gaussian distribution), the number of particles in B remains
very close to the expected value volh(B)N for an extremely long time, with the
possible exception of a totally negligible set of times t.
Indeed, for every (measurable) test set B ⊂ A and every N = 1027-element
initial point configuration Y ⊂ A, there exists a subset Ω(Gauss; A; PolSU; good)
⊂ Ω(Gauss; A; PolSU) with 
representing a totally overwhelming majority, such that for every initial
condition ω ∈ Ω(Gauss; A; PolSU; good),
(where 90 comes from 90 = 30 + 60) holds for every 4 ≤ t ≤ 4 · 2100 with the
possible exception of a set of times t of total length < 10−220. The possible
exception represents less than 10−223 seconds — a ridiculously short time.
Note that 4 ≤ t ≤ 4 · 2100 represents an incredibly long time interval: it is
roughly billion times the age of the universe.
That is, once a typical time evolution of this (Gaussian) PolarSpeedUp
system reaches square-root equilibrium (in the particle space), then it stays in
that 
state 
in 
the 
quantitative 
sense 
of 
90-square-root 
equilibrium 
for an incredibly long time (with the possible exception of a totally negligible set
of t’s).
What about the seemingly simpler (Gaussian) PolarBilliard model? Exactly
like in Sec. 6, it is similar to the PolarSpeedUp model with the usual difference:
the (normalized) volume is replaced by another probability measure volA;Y
which depends on the initial configuration Y ⊂ A.
To define the measure volA;Y, let P ∈ A be an arbitrary point. For every
direction e ∈ Sh−1 let I(P; e) denote the line segment starting from P ∈ A, and
going in the direction e until it hits the boundary of A. Let W ⊂ A be an arbitrary
measurable set, and write 

Given an initial configuration Y = {y1, . . . , yN}, let
It defines a measure that depends on the initial configuration Y.
We can simply repeat the argument of the case of the (Gaussian) Polar-
SpeedUp model. The only difference is that in the PolarBilliard model the
definition of square-root equilibrium (in the particle space) requires the
inhomogeneous measure volA;Y (see (7.24)) instead of the normalized volume.
This proves long-term stability of square-root equilibrium with respect to an
arbitary (possibly “ugly”) but fixed measurable test set B ⊂ A (where A is an h-
dimensional bounded convex set).
Finally note that, similarly to Sec. 5, we can easily extend the results in Sec.
6–7 from test set size ≥ C · N −1/2 to the much smaller (and best possible!) size ≥
C · N−1; see the argument of (5.26)–(5.29) at the end of Sec. 5.
8. Snapshot Randomness (I): Poisson
Time-lapse randomness versus snapshot randomness. Theorems 3.3 and 3.4
have the following common message. The (extremely!) long-term time evolution
of a large system with noninteracting particles exhibits “asymptotic randomness”
(central limit theorem, Poisson law). These “soft” results express the dynamic
aspects of randomness on an unlimited time scale, i.e., where the time t runs in a
very, very long interval. We call it time-lapse randomness on an infinite time
scale. This raises the natural question: What can we say about the short-term
time-evolution? Do we have any kind of time-lapse randomness on a realistic
time scale? The answer is yes; we will give a detailed discussion starting in Sec.
17.
What we study here is the completely different static aspect of randomness,
meaning that t is fixed — we call it snapshot randomness. We prove that the
overwhelming majority of the time evolutions of a Gaussian system achieves
nearly perfect snapshot randomness superexponentially fast, and stays in that
state for an incredibly long time.
The best way to explain snapshot randomness is to introduce a game, an

Alice–Bob type game. In fact, it is an “Alice–Wicky–Bob game”: in this version
Alice has a sister called Wicky. Bob is a superman, and the two sisters are
superwomen. Alice is a nice girl, and Wicky is a wicked girl (to be explained
below). Superhumans have no “complexity limitation”; e.g., either one can carry
out a case-study of size 10101000 (say) in a split second. Alice, the nice girl, is
honest, and Wicky, the wicked girl, is an unpredictable liar. Wicky and Bob are
adversaries; Alice is neutral to Bob. They are in three different rooms, separated
by doors that are locked. Each sister has an N-element point set of her own in the
unit cube [0, 1]3 (N = 10100, say). Alice’s N-set is “truly random”: Alice created
her N-set in [0, 1]3 in the hard way by honestly carrying out N independent trials
with uniform distribution each (as a superwoman, she can do it in a split second).
Wicky claims that her N-set is also “truly random,” but, because she is an
unpredictable liar, nobody knows what Wicky actually did; nobody knows
whether Wicky’s N-set is “truly random” or not. Now we open the door between
the two sisters: Alice and Wicky put their N-sets into a black box. Next we open
Bob’s door, and give the black box to Bob, who pulls out one of the two N-sets
(despite being superman, he does not know which one is due to Alice and which
one is due to Wicky). Bob has to decide whether the N-set he picked is “truly
random” or not. He can perform one test (say). Note that Bob’s test can be
arbitrarily complex (since he is a superman). The sisters do not know in advance
Bob’s test, and Bob does not know what Wicky actually did. All what Bob
knows is that Alice created an honest random N-set (with uniform distribution),
and the other sister — Wicky, Bob’s adversary — tries to fool him. What test
should Bob perform? What test would help him to make a reliable decision on
the status of his N-set (“truly random” or not)? On the other hand, what is the
optimal strategy for Wicky to fool Bob?
We think these are very interesting questions of fundamental theoretical
importance in both complexity theory and probability theory. Unfortunately, we
know very little about this. All what we can say are some suggestions for Bob.
The two most important limit theorems in probability theory are the central limit
theorem (CLT) and the Poisson limit theorem. These limit theorems motivate
two tests: the CLT-partition test and the Poisson partition test.
Intuitively speaking, we say that the time evolution of the system exhibits
“complete CLT or Poisson randomness” if the bell-shaped curve (standard
normal distribution) or the Poisson distribution shows up with striking precision
(we want optimal, or nearly optimal, error term).
The Poisson partition test is somewhat simpler, so, first we discuss the

Poisson test. We will return to the CLT test in Sec. 15.
We employ the standard notation: given an N-element set in the 3-
dimensional unit cube
let
denote the corresponding point in the configuration space Id = [0, 1)d of
dimension d = 3N.
Poisson partition test. Bob makes a partition [0, 1]3 = B1 ∪ B2 ∪ . . . ∪ BN of
the unit cube where each Bi is measurable and vol(Bi) = 1/N (3-dimensional
Lebesgue measure). Let 
be an arbitrary N-element set in the 3-dimensional unit cube. Let 
 denote
the number of points of the given N-set  that are contained in Bi, and consider
the distribution of the N nonnegative integers 
, 1 ≤ i ≤ N. Let 
denote 
the 
number 
of 
bi’s 
that 
are 
equal 
to 
k: 
We compare the empirical distribution in (8.1) to the Poisson distribution with
parameter one:
Since N−1/2 is the “random error,” if the error in (8.2) satisfies the upper bound
then we say that the N-set  is ε-close to maximum snapshot randomness with
respect to the Poisson-partition test.
Note that Alice’s honest random N-set certainly satisfies (8.3) with
probability extremely close to one (see Lemma 8.2 below). Since the two sisters
(Alice and Wicky) do not know Bob’s partition, and the error term (8.3) is nearly
optimal (N−1/2 is the optimum), if Bob’s N-set happens to satisfy (8.3), then Bob
has a good reason to believe that his N-set is “truly random”. For example, if N =
10100 and ε = 2 · 10−2 (say), then 
is an extremely small error. Such an extremely small (and nearly optimal)
error is very convincing: it suggests “complete randomness”.

For the usual application of Theorem 4.2, we need to know the volume of the
subset
in the configuration space Id = [0, 1)d, d = 3N, where γ > 0 is arbitrary.
The d-dimensional volume
is exactly a large deviation type probability related to Alice’s random N-set. It
actually leads us to a classical occupancy problem. There is, however, a (luckily
minor) technical problem: (8.5) is a large deviation type probability for
dependent random variables (see (8.6) below).
A simple combinatorial/probabilistic argument about the occupation
numbers. The empirical distribution of Alice’s honestly constructed random N-
element point set (with uniform distribution) in Bob’s N-partition of the unit
cube is equivalent to the following N-balls-to-N-bins problem. Suppose that we
have thrown N balls independently and uniformly into N bins. That is, the
probability that the ith ball goes to the jth bin is 1/N, and for different balls we
make independent choices. Let Yj denote the number of balls in the jth bin at the
end of the distribution process.
Let X0 denote the number of empty bins, and in general, for any integer k ≥
0, let Xk be the number of j’s such that Yj = k. We know that the expectation of X0
is N/e, and in general, the expectation of Xk is N/(k!e).
In view of (8.4) and (8.5),
Thus we need an upper bound on the large deviation probability
Xk is expressed in terms of the underlying random variables Yj, 1 ≤ j ≤ N, but,
unfortunately, the random variables Yj are not independent (for example, their
sum is N, which is deterministic), so we cannot directly apply Bernstein’s large
deviation type inequality. One way to overcome this technical problem is to

introduce some auxiliary random variables Wj, 1 ≤ j ≤ N that are independent.
Let Wj, 1 ≤ j ≤ N be independent random variables, all having Poisson
distribution with parameter one, i.e., Pr[Wj = k] = (k!e)−1, k = 0, 1, 2, 3,. . . . We
study the connection between the system of the old random variables Yj, 1 ≤ j ≤
N and the system of the new independent random variables Wj, 1 ≤ j ≤ N.
We call a sequence of N integers ℓ1, ℓ2, . . . , ℓN satisfying 
 with ℓj
≥ 0 a relevant sequence. Given a relevant sequence ℓ1, ℓ2, . . . , ℓN, we compare
the two probabilities Pr[Yj = ℓj, 1 ≤ j ≤ N] and Pr[Wj = ℓj, 1 ≤ j ≤ N].
Lemma 8.1. For every relevant sequence ℓ1, ℓ2, . . . , ℓN,
Remark. We emphasize the crucial fact that the ratio is independent of the
sequence ℓ1, ℓ2, . . . , ℓN.
Proof of Lemma 8.1. We apply elementary combinatorics
On the other hand,
Taking the ratio of the two probabilities, Lemma 8.1 follows.
Now we are ready to estimate the large deviation probability (8.7). We prove
Lemma 8.2. For every real γ > 0
Remark. Probably the reader is wondering why we have the extra factor of 
here. This factor turns out to be harmless in the application below. Nevertheless,

it is an interesting question whether or not there is a version of Lemma 8.2
without the extra factor 
. We return to this question at the end of the section
in the Concluding Remark.
Proof of Lemma 8.2. We need the well-known Stirling’s formula; in fact, we
use the following refinement
By Lemma 8.1,
Let Wj
∗ = 1 if Wj = k and Wj
∗ = 0 if Wj ≠ k, and let Zk = 
. Since Wj, 1 ≤ j ≤
N are independent, Wj
∗, 1 ≤ j ≤ N are also independent.
By (8.9),
Similarly,
Combining (8.10) and (8.11),
Since Zk = 
 is a sum of N independent Bernoulli variables with
probability p = pk = (k!e)−1, we can apply Bernstein’s inequality (5.9) 

Combining (8.8), (8.12) and (8.13), we conclude
where we used the fact that pk = (k!e)−1 is extremely small if k is large. This
completes the proof of Lemma 8.2. 0
Applying Theorem 4.2 as a short-time ergodic theorem in the configuration
space. Let B = {B1, B2, . . . , BN} be an arbitrary but fixed measurable partition
of the unit cube [0, 1]3 = B1 ∪ B2 ∪ . . . ∪ BN such that vol(Bi) = 1/N, 1 ≤ i ≤ N
(Bob’s partition). Given an N-element set in the 3-dimensional unit cube 
let 
 denote the number of points of  that are contained in Bi, and
consider the distribution of the N nonnegative integers 
, 1 ≤ i ≤ N.
Like in (8.1), let 
 denote the number of bi’s that are equal to k: 
Like in (8.2), we compare this empirical distribution to the Poisson distribution
with parameter one
If (8.14) is “close” to N−1/2 (“random error”) then we say the N-element set 
exhibits “complete Poisson snapshot randomness” (with respect to the given
partition B).
We recall (8.4): for every γ > 0 let

Consider the usual 3-dimensional Gaussian torus-billiard model Yω;t =
Y(Gauss; ω; t), ω ∈ ΩGauss.
We study the following question. Assume that N is large; is it true that the
overwhelming majority of the time evolutions of this Gaussian billiard system
reaches “complete Poisson snapshot randomness” superexponentially fast, and
stays in this state for an incredibly long time (with the possible exception of a
totally negligible set of t’s)? By using Theorem 4.2 we give a positive answer.
We basically repeat the argument in Sec. 5.
The family of time evolutions Yω;t, ω ∈ ΩGauss of the 3-dimensional
Gaussian torus-billiard model is represented by the family of torus lines 
in the configuration space Id = [0, 1)3N (= d-dimensional unit torus), all starting
from the same point 
.
Since the torus Id is translation invariant, we can apply Theorem 4.2 with f =
χS where S is the translated copy
of S(error ≥ γN−1/2) (see (8.15)) in the torus Id. Thus, if U ≥ 1 and eπ2U2/2 > 3dU,
then 
for 
every 
integer 
j 
≥ 
1, 
where S = S(B; γ) (see (8.16)).
By (8.6) and Lemma 8.2,

To illustrate the power of (8.17)–(8.18), we choose the usual numerical
values γ = 30, U = 4, j = 340 and N = 1027; it follows that d = 3 · 1027. Then by
(8.17)–(8.18), 
Let ΩGauss (bad) be the set of those ω ∈ ΩGauss for which
Repeating the proof in (5.18)–(5.19), we obtain
Again we study the classical Bernoulli gas model where the gas molecules
are represented by point billiards (N = 1027 is a realistic number). Using the trick
of unfolding we reduce the billiards-in-a-box model to the torus-billiard model.
The threshold U = 4 represents — roughly speaking — the relaxation distance,
i.e., the necessary number of “jumps” per particle in the Gaussian torus-billiard
model (which is the half of the number of bounces in the analog billiards-in-a-
box model) to reach “complete Poisson snapshot randomness”. As usual, assume
that the gas molecules have average speed 103 meter per second. For this system
it takes only a few milliseconds to reach “complete Poisson snapshot
randomness”. Now (8.20) and (8.21) have the following interpretation. Choosing
an arbitrary (measurable) Poisson partition B = {B1, B2, . . . , BN} of the unit
cube [0, 1]3 = B1 ∪ B2 ∪ . . . ∪ BN such that vol(Bi) = 1/N, 1 ≤ i ≤ N and an
arbitrary N-element initial point configuration Y, for the totally overwhelming
majority of the initial velocities (= Gaussian distribution), the distribution of the
particles in the partition B remains very close to the Poisson distribution with
parameter one for an extremely long time, with the possible exception of a
totally negligible set of times t.

Indeed, for every Poisson partition B = {B1, B2, . . . , BN} and every N =
1027-element initial point configuration Y ⊂ [0, 1)3, there exists a subset
ΩGauss(good) where 
with
(see (8.21)), representing a totally overwhelming majority, such that for every ω
∈ ΩGauss(good),
holds for every 4 ≤ t ≤ 4 · 2340 with the possible exception of a set of times t of
total length < 10−200, see (8.20). The latter actually represents less than 10−203
seconds, which is a ridiculously short time.
Note that 4 ≤ t ≤ 4 · 2340 represents a time interval of length about 1097
seconds, which is a ridiculously long time (the estimated age of the universe,
starting from Big Bang, is less than 1020 seconds).
Summarizing, the typical time evolution of this system reaches “complete
Poisson snapshot randomness” (see (8.22)) in a few milliseconds (even starting
from Big Bang!), and then it remains in the state of “complete Poisson snapshot
randomness” for an incredibly long time (with the possible exception of a totally
negligible set of t’s).
What happens if we replace N = 1027 with N = 10100 (say)? Everything
remains the same, the only change is that (8.22) is replaced by
That is, independently of the initial configuration, after a few milliseconds the
system exhibits the Poisson distribution with striking, and nearly optimal,
precision (see (8.23)). This is why we may say that the system is completely
random.
In the next section we define and study the CLT-partition test (where CLT
stands for the central limit theorem).
Concluding Remark. The proof of Lemma 8.2 was based on Lemma 8.1 and

Bernstein’s large deviation inequality. We show that, replacing Lemma 8.1 with
a martingale approach (and, consequently, replacing Bernstein’s inequality with
the Azuma–Hoeffding inequality), we can get rid of the extra factor 
.
A martingale is a sequence U0, U1, . . . , Un of random variables so that for 0
≤ i < n, E(Ui+1|Ui) = Xi. (Here E(U|V) denotes the conditional expectation of U
given V; we could also write E(U|V) = E(U|V), where V is the σ-algebra
generated by the random variable V.) In the application we use the so-called
Doob-martingale. Let U be a random variable on the probability space (Ω, F, µ)
(F is a σ-algebra and µ is a positive measure such that µ(Ω) = 1). Let 
be an increasing sequence of sub-σ-algebras of F (“filter”), then Ui = E(U|Fi), 0
≤ i ≤ n is a (Doob-)martingale (generated by the filter F0 ⊂ . . . ⊂ Fn).
Azuma–Hoeffding inequality (see e.g. [Gr-St92]) Let U0, U1, . . . , Un be a
martingale with |Ui+1 − Ui| ≤ M for 0 ≤ i < n. Then for every τ > 0, 
We apply this martingale tail inequality for the N-balls-to-N-bins occupancy
problem (we place N balls independently and uniformly into N bins). Let Zk = j if
the kth ball goes to the jth bin. Let X(0) denote the number of empty bins at the
end (for simplicity we just study this special case). We can view X(0) as a
function f(Z1, . . . , ZN). We prove the following result.
Lemma 8.3. We have
Note that
Before deriving Lemma 8.3 from the Azuma–Hoeffding inequality, we want to
compare Lemma 8.3 with (8.24) to Lemma 8.2 (the latter in the special case of
empty bins, i.e., k = 0). An advantage of Lemma 8.3 is that the extra factor 
in the upper bound is gone. An advantage of Lemma 8.2 is that in the exponent
we have 2γ2 instead of γ2/2, which makes a big difference. For example, in the

applications above with N = 1027 or N = 10100 and γ = 30, Lemma 8.2 gives a
much better upper bound than Lemma 8.3. On the other hand, choosing (say) N
= 10100 and γ = 6, Lemma 8.2 becomes useless (the upper bound is greater than
1); on the other hand, Lemma 8.3 still gives a fairly good bound. Summarizing,
we may say that, Lemma 8.2 is better if γ is relatively large, and Lemma 8.3 is
better if γ is relatively small.
It remains to derive Lemma 8.3 from the Azuma–Hoeffding inequality. Let
time t refer to the point at which the first t balls have been thrown. Let Ft be the
σ-algebra generated by the random choice of bins for the first t balls, i.e., the σ-
algebra generated by the independent random variables Z1, . . . , Zt. Let Ut =
E(X(0)|Ft), that is, the expected number of empty bins given Z1, . . . , Zt. The
random variables U0, U1, . . . , UN form a martingale with 
Notice that moving the kth ball from one bin to another can change the number
of empty bins by at most one. This implies that |Ui+1 − Ui| ≤ 1 for 0 ≤ i < N.
Applying the Azuma–Hoeffding inequality with M = 1, n = N and τ = γ, Lemma
8.3 follows.
9. Proofs of Theorems 4.2 and 4.3
For technical reasons it is convenient to prove first a special case with an upper
bound on the ratio W/U.
Theorem 9.1. Let f ∈ L2(Id) be a test function, where Id = [0, 1)d. If 1 ≤ U < V ≤
2U and eπ2U2/2 ≥ 3dU, then 
Note in advance that the technical restriction U < V ≤ 2U in Theorem 9.1 can
be easily eliminated by a routine application of the Cauchy–Schwarz inequality;
for the details see the end of the section. (Needless to say the factor 9 is an
accidental constant.) Proof of Theorem 9.1. We use Fourier analysis in the
configuration space Id = [0, 1)d, which has very high dimension in our
applications for large off-equilibrium systems. The possibility of high dimension
leads to technical difficulties that are combinatorial in nature.
Let f ∈ L2(Id) be a Lebesgue square-integrable function in the d-dimensional

unit torus (i.e., we extend f over the whole d-space Rd periodically), and consider
the Fourier expansion of f: 
where
are the Fourier coefficients, and of course v · w = v(1)w(1) + ··· + v(d)w(d) denotes
the dot product of v = (v(1), . . . , v(d)) and w = (w(1), . . . , w(d)).
Clearly
where we used Parseval’s formula.
By (9.1) we have
where e ∈ Sd−1 is a unit vector in the d-space.
Here we briefly interrupt the proof, and insert a technical remark. Notice that
(9.3) is an informal equality: the infinite sum on the right-hand side may be
divergent for some unit vector e ∈ Sd−1 in the d-space. One possible way — the
very hard way! — to make (9.3) precise is to prove pointwise convergence by
using deep results from Fourier analysis (Carleson, C. Fefferman, and others).
But we do not really need any deep result from Fourier analysis; for us it
would be equally good to replace pointwise convergence with Cesaro
summability (Fejér kernel), which has a much simpler classical proof, and works
better under more general conditions.
What we actually do to avoid this kind of technical nuisance is a yet different
third way, which is based on the fact that the trigonometric polynomials are
dense in the L2-space. We proceed in two steps. The first step is to prove the
theorem in the special case where f is a trigonometric polynomial (in d
variables). Then it is trivial to carry out the usual manipulations, e.g., changing
the order of finite summation and integration. The second step is the routine
limit process: the class of trigonometric polynomials forms a dense subset of the
Hilbert space L2(Id), and we can complete the proof in the general case with a
routine application of Lebesgue’s Dominated Convergence Theorem.

By (4.29)–(4.31) and (9.3) we have
where
We need
Lemma 9.1. For every d-dimensional vector w = (w1, w2, . . . , wd) we have
where as usual 
 denotes the Euclidean norm.
Proof. In the integral
the vector ρe = v = (v1, . . . , vd) has d-dimensional standard normal (= Gaussian)
distribution. 
Thus 
we 
have 
where in the argument we used the well-known facts that the coordinates v1, . . . ,
vd of v are independent random variables having standard normal distribution
each, and the Fourier transform of e−x2/2 is itself. This completes the proof of
Lemma 9.1.

Let us return to (9.4) and (9.5). Applying Lemma 9.1 it is easy to prove the
following lemma.
Lemma 9.2. For every −∞ ≤ W′ < W″ ≤ ∞, we have
Proof. Using the trivial fact
in (9.4), we have
Applying (9.6) in (9.5), we obtain
By Lemma 9.1 we can evaluate the inner integral at the end of (9.7):

and using this in (9.7), Lemma 9.2 follows.
Now we are ready to prove Theorem 9.1. The proof is an elementary brute
force combinatorial argument. For every n = (n1, . . . , nd) ∈ Zd \ 0 write L(n) =
{1 ≤ i ≤ d : ni ≠ 0}. Applying the simple inequality 
 in
Lemma 
9.2, 
we 
have 
We fix t1 ∈ [U, V], n1 ∈ Zd \ 0, L1,2 ⊆ L(n1) and λ2, and focus on the inner
integral at the end of (9.8).
Write
(where, as usual, |A| denotes the number of elements of a finite set A).
Let k1(n2) denote the number of coordinates n2,i = ±1 of n2 which also satisfy

n1,i = 0; let k2(n2) denote the number of coordinates n2,i = ±2 of n2 which also
satisfy n1,i = 0; let k3(n2) denote the number of coordinates n2,i = ±3 of n2 which
also 
satisfy 
n1,i 
= 
0; 
and 
so 
on. 
Note 
that 
Let h0(t2; n2) denote the number of coordinates j ∈ L1,2 such that |t1n1,j −
t2n2,j| < U/2; let h1(t2; n2) denote the number of coordinates j ∈ L1,2 such that
U/2 ≤ |t1n1,j − t2n2,j| < 3U/2; let h2(t2; n2) denote the number of coordinates j ∈
L1,2 such that 3U/2 ≤ |t1n1,j − t2n2,j| < 5U/2; let h3(t2; n2) denote the number of
coordinates j ∈ L1,2 such that 5U/2 ≤ |t1n1,j − t2n2,j| < 7U/2; and so on. Note that 
By definition
By using (9.12) and the definitions of ki(n2), hi(t2; n2), we have
We estimate the long sum at the end of (9.13). By using the definitions of ki(n2),
hi(t2; 
n2), 
(9.10) 
and 
(9.11), 
we 
obtain 
the 
upper 
bound 

Note that (9.14) includes the pathological case λ2−λ1,2 = 0 with the natural
convention that the summation means the single term (k1, . . . , kr) = (0), and
similarly, if λ1,2 = 0 then (h0, h1, . . . , hr) is just the single term (0).
By using the trivial upper bound
and applying the multinomial theorem to the end-sum in (9.14)

we have
Next we use (9.14)–(9.17) in (9.13):
Let us return now to (9.8); we have the decomposition
where

is characterized by the property λ1 < λ2,
is characterized by the property λ1 > λ2, and finally, we split the case λ1 = λ2 into
two 
subcases 
according 
as 
L(n1) 
≠ 
L(n2) 
or 
L(n1) 
= 
L(n2): 
and

To estimate the last part (9.23), we are going to use a simple but important
lemma. First a definition: given real numbers C and C′, consider the set
We give an upper bound on the 1-dimensional Lebesgue measure (i.e., the
length) of the set BU(C; C′).
Lemma 9.3. For arbitrary real numbers C, C′ with |C| ≥ U ≥ 1 and 0 < C′ < U/2,
Proof. We can assume without loss of generality that C > 0. Clearly
so
where the summation 
 is extended over all n’s such that
Note that
and
Thus we have
where we used the well-known fact that
for all 0 < A < B. Since log 6 < 2, the proof of Lemma 9.3 is complete.

Applying (9.18) in (9.20), we have
By hypothesis
and using it we have
By using (9.25)–(9.26) in (9.24), we obtain

where we used the substitution j = λ2 − λ1.
Using (9.25) in (9.27), we have
since V − U ≤ U.
Next we use (9.18) in (9.21):

where in the last steps we used (9.25) and the trivial upper bound
Applying (9.25) in (9.29), we obtain

where we used the substitution j = λ1 + λ2 − 2λ1,2, the assumption V − U ≤ U,
and the simple fact
Next we apply (9.18) in (9.22):

Using (9.30) in (9.32), we have
Using (9.25) in (9.33), we obtain

where we used the substitution j = λ1 − λ1,2 and the hypothesis V − U ≤ U.
Finally we estimate (9.23). We have
where
and
We start with Part Four A, and use the notation λ1 = |L(n1)|. In this special case

the argument of (9.13)–(9.18) simplifies to the following upper bound (note that
here λ1 = λ2 = λ1,2) 
where the term −1 at the end is explained by the restriction h0 < λ1, i.e., the term
−1 is due to the fact that in the application of the multinomial theorem we have
an almost complete sum, where the single missing case is h0 = λ1.
By (9.38)
since
Note that in (9.39) we used Parseval’s formula and the simple inequalities 1+x ≤
ex ≤ 1+2x for 0 ≤ x ≤ 1; and of course (9.40) follows from (9.25).
Applying (9.25) in (9.39), we have
since V − U ≤ U.

To estimate (9.37)
we make use of the fact that for every given triple (t1, n1, t2) with t1 ∈ [U, V], n1
∈ Zd \ 0 and t2 ∈ [U, V], there is at most one term in the endsum 
of (9.42). Indeed, it follows from the definition of h0(t2; n2) that for every given
triple (t1, n1, t2) the inequality |t1n1,j − t2n2,j| < U/2 has at most one integer
solution n2,j, and because h0(t2; n2) = |L(n1)| and L(n2) = L(n1), there is at most
one n2 ∈ Zd \ 0 satisfying the requirements. Let n∗
2 ∈ Zd \ 0, n∗
2 = n∗
2(t1, n1, t2)
denote this single integer lattice point, if it exists. Thus we can rewrite (9.42) as
follows: 
where n∗2 = n∗2(t1, n1, t2), if it exists.
Let j0 = j0(n1) be an arbitrary but fixed element of the set L(n1); then we have
the 
following 
trivial 
upper 
bound 
for 
(9.43): 
Given (t1, n1), we consider the following decomposition of the interval U ≤
t2 ≤ V (≤ 2U):
where j0 = j0(n1) and n∗
2 = n∗
2(t1, n1, t2).

Using decomposition (9.45) in (9.44), we obtain the upper bound
where Iℓ = Iℓ(t1, n1). Applying Lemma 9.3 with C = t1n1,j0 and C′ = ℓ, we obtain
the upper bound 
and using it in (9.46), we have
Using (9.28), (9.31), (9.34), (9.41), (9.47) and Parseval’s formula in (9.19),
we conclude
This completes the proof of Theorem 9.1.
To complete the proof of Theorem 4.2, we have to eliminate the technical
restriction U < V ≤ 2U in Theorem 9.1. It goes by a routine application of the
Cauchy–Schwarz inequality as follows.
Deduction of Theorem 4.2 from Theorem 9.1. Given 1 ≤ U < W, let k ≥ 1
denore the integer such that 2k−1U < W ≤ 2kU. It is easy to find a sequence 1 ≤
W0 = U < W1 < · · · < Wk = W such that Wi < Wi+1 ≤ 2Wi for all 0 ≤ i < k. By
using the Cauchy–Schwarz inequality and Theorem 9.1, we have 

Since k = log2 (W/U)  (upper integral part), the proof of Theorem 4.2 is
complete.
Finally, we turn to Theorem 4.3.
Proof of Theorem 4.3. Clearly
since the off-diagonal part is empty by definition. We give a lower bound to the
inner 
integral 
in 
(9.48) 
(t1 
is 
fixed, 
and 
t2 
is 
the 
variable): 

where we used the simple facts
and
(z+ denotes the positive part of z, i.e., z+ = z if z > 0 and 0 otherwise).
Using (9.49) in (9.48), we have
which completes the proof of Theorem 4.3.

Chapter 2
General Models
10. General Model: Unique Ergodicity via Typical
Rotations
In Chapter 1 we studied the simplest model of large systems: the torus-billiard
system. Here we study a far reaching generalization of the torus-billiard model.
Assume that every particle has its own type of trajectory described by a
parametrized space curve in the h-space Rh, h ≥ 2. It means that the actual
trajectory xk(t) of the kth particle in the torus model is in fact a translated and
rotated copy of rk(t) modulo one, where rk(0) = 0, 1 ≤ k ≤ N (see (10.2) below).
We assume that the parametrized space curves are continuous, but beyond that
they can be (almost) arbitrary: straight lines, bending lines, twisted lines, any
kind of general helix, spiral, wave, and so on (of course, in the torus model we
take the space curves modulo one). The only condition that we require is that the
parametrized space curves rk(t) ⊂ Rh have a tendency of “drifting away from the
start”.
A constant speed motion on a straight line is obviously drifting away from
the start rather fast. What we require here is much less. A natural quantitative
way to define “drifting away from the start” is the following. Let Ih + w, w ∈ Rh
be an arbitrary but fixed axis-parallel h-dimensional cube of side length one (i.e.,
a shifted copy of the unit cube Ih = [0, 1)h), and consider the total time t in the
interval 0 ≤ t ≤ T that the curve rk(t) spends in Ih + w: 
We say that the system is drifting away if there exist two constants α > 0 and 0 ≤
β < 1 such that

uniformly for all 1 ≤ k ≤ N and all T ≥ 1.
Here we interrupt our mathematical discussion, and give some real life
motivation for introducing arbitrary space curves rk(t). In a constant magnetic
field B, there is a force on a moving charged particle, say a proton. The force is
the cross product F = v × B, where v is the velocity of the proton. Since F is
perpendicular to v, the proton travels on a helix like r(t) = (cos t, sin t, t), instead
of a straight line. Of course, an uncharged particle still travels on a straight line.
A second motivation is that particle–particle collision leads to random-walk-
like chaotic zig-zag trajectories, and by allowing arbitrary space curves rk(t), we
attempt to imitate particle–particle collision. Of course a random-walk-like
trajectory is completely different from a straight line; nevertheless, it still
exhibits a tendency of “drifting away from the start” (see (10.1)), which is
included in our general model.
A third real life motivation for arbitrary space curves is that it mimicks the
basic mechanism of the Second Law of Thermodynamics: “energy dispersal” on
a microscopic level. “Energy dispersal” is far more complicated than particle–
particle collision for gas-in-a-box; it also applies for fluids and solids, it applies
for all real life many-particle systems. We feel that our general torus model with
arbitrary space curves is a reasonable mathematical model for “energy dispersal”
on a microscopic level.
Let us return to mathematics: by using the Weyl’s criterion, we can prove a
result describing the typical long-term time evolution of a general torus model. It
is an analog of the Kronecker–Weyl equidistribution theorem. We may call it a
“Weak Uniformity” Theorem (by contrast, Theorems 4.1-2 are “strong
uniformity” theorems).
We use xk(t) to denote the trajectory of the kth particle in the torus Ih = [0, 1)h
(1 ≤ k ≤ N). We allow arbitrary initial point configuration xk(0) = yk ∈ Ih, 1 ≤ k ≤
N. Let rk(t) ⊂ Rh, 1 ≤ k ≤ N be an arbitrary family of N continuous parametrized
space curves in the h-dimensional space with rk(0) = 0, and satisfying
requirement (10.1), i.e., “the system is drifting away” with parameters α > 0 and
0 ≤ β < 1.
We know that rk(t) describes the type of the trajectory of the kth particle, and
xk(0) = yk ∈ Ih is the starting point, but we also need the “initial direction”,
which actually means a rotation of the h-space Rh. Consider e.g., the case h = 3:

a general space curve — a helix, say — is a proper 3-dimensional object: unlike
a straight line, a helix spans the 3-space. So, in dimension h ≥ 3, for a general h-
dimensional space curve rk(t) ⊂ Rh we must choose a rotation ϑk ∈ SO(h)
(“special orthogonal group”) of the h-space (1 ≤ k ≤ N).
For comparison note that the 2-dimensional case is simpler: the rotation of
the plane is the same as choosing a point on the unit circle S1, or equivalently, to
choose an angle 0 ≤ θ < 2π. Formally, SO(2) is the additive group of the reals
modulo 2π, so SO(2) is commutative. On the other hand, SO(h) is
noncommutative for every h ≥ 3. (This fundamental difference between SO(2)
and SO(h), h ≥ 3 is the source of many technical problems; see later.) The choice
of the N rotations ϑk, 1 ≤ k ≤ N in the 3-space makes the initial condition
complete: the real trajectory of the kth particle in the general torus model is 
which describes the time evolution of the whole N-particle system for all time 0
≤ t < ∞.
To talk about typical directions we need a measure. We assume that ϑ1, ϑ2, . .
. , ϑN are N independent random variables, where ϑ1, ϑ2, . . . , ϑN are all
uniformly distributed in the rotation group SO(h) (= special orthogonal group of
all proper rotations of the h-space) with respect to the Haar measure. This means
we use the corresponding product measure on the product space 
Let ProdMeas denote the normalized version of this product measure on the set
Ω, and for notational simplicity write dω = dProdMeas. That is, 
We refer to the huge product space Ω as the “initial direction space” (somewhat
vaguely speaking).
The 
trajectory 
Γ(t) 
= 
Y,ω(t) 
of 
the 
whole 
system 
is 
where t is the time,
is the initial point configuration,

is a (vector) family of parametrized h-dimensional curves “drifting away” with
parameters α > 0 and 0 ≤ β < 1 (see (10.1)). Since ϑkrk(t) ∈ Rh, 1 ≤ k ≤ N, Y,ω(t)
in (10.4) is a curve in the hN-dimensional unit torus (= configuration space).
Theorem 10.1. (Weak Uniformity Theorem: “kind of ” unique ergodicity via
typical rotations) Consider the h-dimensional general torus model Y,ω(t) = (Y;
; ω; t) with h ≥ 2, drifting away from the start; see definitions (10.1)–(10.4).
For 
almost 
every 
vector 
of 
rotations 
for all Jordan measurable subsets S of the d = hN-dimensional unit cube Id = [0,
1]d (= configuration space), and in general, for every Riemann integrable
function f defined on Id, 
where length is the 1-dimensional Lebesgue measure, and vold is the d-
dimensional Lebesgue measure.
Remarks. The Weak Uniformity Theorem is similar to the Kronecker–Weyl
theorem. There is, however, a crucial difference: in the Kronecker–Weyl theorem
we have an explicit characterization of the set of “good” directions (linear
independence of the direction coordinates over the rationals); in the Weak
Uniformity Theorem, on the other hand, we do not know any criterion to decide
that 
a 
given 
explicit 
vector 
of 
rotations 
is “good” or “bad”. This is certainly a disadvantage. It is compensated by the
fact that the Weak Uniformity Theorem is far more general: it extends the
limited class of constant speed motions on straight lines to (basically) arbitrary
parametrized curves.
It is interesting to point out that, for a fixed
and
the time flow defined by (10.4) does not necessarily satisfy the composition

property (“group action”) Tt1Tt2 = Tt1+t2, or equivalently, 
The composition property (“group action”) holds in the special case of constant
speed motion of the particles on straight lines, but it fails for varying speed
motions, especially for nonlinear curves. The violation of the group action
means that in the general case we are beyond the framework of traditional
dynamical systems (= describing the solution of autonomous systems of
differential equations) and ergodic theory. Nevertheless, we keep the “ergodic
viewpoint”.
The “ergodic viewpoint” explains why we refer to Theorem 10.1 as a result
exhibiting “kind of” unique ergodicity. We recall a key result in topological
ergodic theory (= topological dynamical systems), often called Unique
Ergodicity Theorem. For simplicity we discuss the discrete time evolution (the
continuous case of a time-flow is a straightforward analog). Let X be a compact
metric space, let B denote the σ-algebra of Borel subsets of X, let T : X → X be a
continuous map of X to itself, and let µ be a measure such that (X, B, µ) is a
probability space, and T is µ-measure-preserving. We say that x0 ∈ X is a generic
point 
for 
the 
quadruple 
(X, 
B, 
µ, 
T) 
if 
for every continuous function f defined on X. Birkhoff’s ergodic theorem implies
that, if T is ergodic then µ-almost-every point x0 ∈ X is generic. It raises the
natural question: under what condition can we upgrade µ-almost-every to every?
It turns out that this question has a surprisingly elegant answer.
Unique Ergodicity Theorem. The following four statements are equivalent:
(a) every point x ∈ X is generic for the quadruple (X, B, µ, T);
(b) µ is the only probability measure on the Borel σ-algebra B such that (X, B,
µ) is a probability space and T is µ-measure-preserving; (c) for every
continuous function f defined on X we have the pointwise convergence to a
constant
where the constant c(f) depends only on f (i.e., it is independent of x);

(d) for every continuous function f defined on X
uniformly in x ∈ X.
A pair (X, T) (= topological dynamical system) is called uniquely ergodic if
(b) holds, i.e., if there is only one probability measure µ such that (X, B, µ) is a
probability space and T is µ-measure-preserving. The bad news is that it is not
easy to decide whether or not a topological dynamical system (X, T) is uniquely
ergodic.
Note that the proof of the Unique Ergodicity Theorem is substantially
simpler than that of Birkhoff’s ergodic theorem. Unfortunately both theorems are
“soft”: they do not say anything about the speed of convergence. This is why we
do not use any of them in the rest of the book.
Notice that (10.6) is a “kind of” time-flow analog of part (c) in the Unique
Ergodicity Theorem (where µ is of course the ordinary Lebesgue measure).
Thus, Theorem 10.1 implies that, under the “drifting away” condition (10.1)–
(10.4), the time-flow (10.4) on the torus is “kind of” uniquely ergodic for almost
every vector of rotations 
We can summarize this book from the viewpoint of ergodic theory as
follows. We prove and apply “short-time” ergodic type theorems for “kind of”
uniquely ergodic time-flows in the configuration space. Such a time-flow
describes the typical short-term time evolution of a large system of non-
interacting particles, starting from off-equilibrium.
Proof of Theorem 10.1. Write d = hN. According to the curve Weyl’s criterion
(2.5), it suffices to verify (10.6) for the complex exponential functions f(z) =
fn(z) = e2πin·z with n ∈ Zd \ 0. We show that, given any ε > 0, there is a subset
Ω(ε) ⊂ Ω such that ProdMeas(Ω(ε)) < ε, and for every ω ∈ Ω \ Ω(ε) 
holds for all
Choosing ε → 0, (10.13)–(10.14) imply that (10.6) holds for all f(z) = fn(z), n ∈
Zd\0 for almost every vector of rotations ω ∈ Ω — this completes the proof of

the theorem.
We start the proof of (10.13)–(10.14) by introducing a notation: for T > 0
write
We study the big average of the square of the absolute value of Dfn(Y; ; ω; T): 
where dϑ denotes the normed Haar measure on the special orthogonal group
SO(h), i.e., ∫SO(h) dϑ = 1.
First we prove the theorem in the special case h = 3. It is based on the
following lemma.
Lemma 10.1. For every T > 0 and every complex exponential function fn(z) =
e2πin·z, where n = (n1, . . . , nd) ∈ Zd \ 0 is a nonzero d-dimensional lattice point
and d = 3N, we have 
with n(k) = (n3k−2, n3k−1, n3k).
Proof of Lemma 10.1. Using the trivial general fact
in (10.15), we have
and so we obtain

Since
we have
where ϑk
−1 ∈ SO(3) denotes the inverse of ϑk.
Inserted Remark. In view of (10.17)–(10.18) the initial point configuration Y =
{y1, . . . , yN} cancels out in the proof. This is perfectly natural, since the torus is
translation invariant.
To evaluate the last integral in (10.18), we need the following lemma.
Lemma 10.2. Let w be an arbitrary 3-dimensional vector. Then
where dSA(v) represents the surface area.
Proof of Lemma 10.2. The special case w = 0 is trivial: the left side is equal to

1, and the right side tends to 1 as w tends to 0; so we may assume that w ≠ 0. We
need a well-known geometric fact about the surface area of some special
spherical domains. Let e ∈ S2 be an arbitrary but fixed unit vector, and let 0 < δ
< 1 be an arbitrary real number. Consider the “spherical belt” (often called the
“spherical zone”): 
On one hand, it is trivial that the surface area of the “belt” S2(e; δ) is
independent of the choice of the unit vector e; on the other hand, it is a very
surprising nontrivial fact — discovered by Archimedes — that the dependence
on δ is just plain linear 
(10.20) implies that, for any nonzero 3-dimensional vector w and any real
number  with 0 <  < |w|, 
By using (10.21), we have
which proves (10.19).
By (10.19),
with
Lemma 10.1 follows from (10.17), (10.18) and (10.22).
We are now ready to complete the proof of the theorem for h = 3. Let n =
(n1, . . . , nd) ∈ Zd \ 0 be fixed. Then there is a j such that n(j) = (n3j−2, n3j−1, n3j)
≠ 0, so |n(j)| ≥ 1. Thus by Lemma 10.1 we have the trivial upper bound 
We want to estimate the inner integral in the last line of (10.23) (so t1 is fixed,

and t2 is a variable). Let A1 denote the aligned unit size cube I3 + w centered at
rj(t1), and consider the tiling of the 3-space R3 with aligned unit size cubes
where A1 is a member of the tiling. Let A2, A3, . . . , A27 be the first neighborhood
of A1 in this tiling, let A28, A29, . . . , A125 be the second neighborhood of A1, and
in general, let 
be the kth neighborhood of A1 in this tiling (k ≥ 1).
If Ai is in the kth neighborhood of A1 and r ∈ Ai, then |rj(t1) − r| ≥ (2k − 1)/2,
and by (10.1), 
Let K be the largest integer with (2K + 1)3 ≤ T1−β. We have the following trivial
upper bound for the inner integral in the last line of (10.23): 
where k indicates the running index 1 ≤ k ≤ K.
We rewrite (10.24) in the shorter form
where K is the largest integer with (2K + 1)3 ≤ T1−β.
Clearly

Moreover,
since (2K + 3)3 > T1−β and π(2K + 1) > 2K + 3.
Combining (10.23) and (10.25)–(10.27), we have
Now it is just a routine calculation to finish the proof of the theorem, i.e., to
prove (10.13)–(10.14) for h = 3. Given ε > 0, define the sparse sequence 
Let
Combining (10.15)–(10.16) and (10.28)–(10.30), we have
Let
where the threshold C0 = C0(ε, α, β) will be specified later.
Now let
Then

If ω ∈ Ω(good) then by (10.30)
and using it in (10.33), we have (log stands for the natural logarithm)
where
Since β < 1, the inequality
holds for all sufficiently large integers n, i.e., for all n > C0, where C0 = C0(ε, α,
β) is some appropriate absolute constant. We also assume that C0 > 1/ε. Since 
by (10.31)–(10.32) we have
Finally, by (10.34) and (10.35), for all ω ∈ Ω(good),
Notice that (10.36)–(10.37) prove (10.13)–(10.14) for h = 3, completing the
proof of the Weak Uniformity Theorem in the special case h = 3.
The proof of the cases h = 2 and h ≥ 4 goes along the same lines. The only
change is that we need the analog of Lemma 10.2 for arbitrary dimension.
Lemma 10.3. Let h ≥ 2 be an integer, and let SA denote the surface area in the
h-space Rh. For every h-dimensional vector w, we obtain with w = |w|, 

depending on whether h ≥ 2 is even or odd, accordingly. Here Jν(z) is the well-
known Bessel function, and, as usual, k!! = k(k − 2)(k − 4) · · · , where the last
factor is 1 or 2 depending on the parity of k, and 0!! = 1.
Remarks. Note that the Bessel functions arise as solutions of some important
differential equations, but here we define the Bessel function (of the first kind)
Jν(z) (where ν is called the order) in an equivalent shortcut way via power series 
where Gamma(z) is Euler’s Gamma function.
If ν ≥ 0 is a half-integer, then Jν(z) has a finite form, e.g.,
but for ν ≥ 0 integer the Bessel function Jν(z) does not have a finite expression.
What we can still use is an asymptotic expression — called Hankel’s formula —
that works for all ν ≥ 0; see later.
The unusual notation Gamma(s) for the Gamma function is explained by our
preference to save letter Γ = Γ(t) for the trajectory in the configuration space,
describing the time evolution of a system.
Proof of Lemma 10.3. We need information about the surface area of a
“spherical belt” in arbitrary dimension. We recall that Sm = {u ∈ Rm+1 : |u| = 1}
denotes the unit sphere in the (m + 1)-dimensional space. Let v ∈ Sm be an
arbitrary but fixed unit vector, and let β < γ be real. We need to know the surface
area of the “spherical belt”
The special case m = 2 is particularly simple: we have the elegant formula
for −1 ≤ β < γ ≤ 1. Formula (10.39) was used in the proof of Lemma 10.2.
Unfortunately, the elegant linear formula (10.39) breaks down in dimensions
m ≠ 2. Nevertheless, we have a (less elegant) general integral formula, which
suffices for our purposes. Since the surface area of Sm(v; β, γ) is independent of

the choice of the unit vector v, in the following lemma we drop v, and simply
write Sm(β, γ).
Lemma 10.4. If m ≥ 1 then for any −1 ≤ β < γ ≤ 1, we have
Unfortunately this technical result is not well known, so for the sake of
completeness, we include a short proof at the end of the section.
Let h ≥ 2 be an arbitrary dimension with h ≠ 3, and let w ∈ Rh be an
arbitrary but fixed vector. By using Lemma 10.4 with m = h − 1, we are ready
now 
to 
evaluate 
the 
critical 
integral 
(let 
w 
= 
|w|) 
The good news is that integral (10.40) can be expressed in terms of the classical
Bessel function Jν(z). Indeed, we make use of the Poisson representation formula
(see 
e.g. 
formula 
(8) 
on 
p. 
48 
in 
Watson 
[Wat58]) 
which holds for all ν > −1/2 and complex z.
Combining (10.4) and (10.5) with ν = (h − 2)/2 and z = w = |w|, we obtain
It remains to evaluate the factor
The integral 
(1 − y2)(h−3)/2 dy in the denominator can be easily evaluated by a
simple recurrence formula. Indeed, let 
then A(0) = π, A(1) = 2, A(2) = π/2, and
Furthermore, we have

Gamma(s) = (s − 1)Gamma(s − 1), Gamma(1/2) = 
, Gamma(1) = 1.
Combining these formulas, we obtain the recurrence relation C(h) = (h − 2)!!C(h
− 2). Since C(2) = 1 and C(3) = 
, for h ≥ 3 we obtain 
depending on whether h is even or odd, accordingly. Using (10.43) in (10.42),
Lemma 10.3 follows.
Switching from h = 3 to an arbitrary dimension h ≥ 2, h ≠ 3 the crucial
change is that the key function 
 in Lemma 10.1 is replaced by 
depending on whether h ≥ 2 is even or odd, accordingly.
If ν ≥ 0 is a half-integer, then Jν(z) has a finite form. For ν ≥ 0 integer the
Bessel function Jν(z) does not have a finite expression, but we can still use an
asymptotic expression — called Hankel’s formula — that works for all ν ≥ 0,
covering both cases. For our purposes it suffices to apply the first order
approximation 
in 
Hankel’s 
formula 
and
where the implicit constants in the O-notations depend only on the value of ν ≥
0.
By using Lemma 10.3, (10.45′) and (10.45″), we can complete the proof of
the general case h ≥ 2, h ≠ 3 exactly the same way as we completed the case of h
= 3 via Lemma 10.1.
As we promised, we conclude Sec. 10 by including a proof of Lemma 10.4.
Proof of Lemma 10.4. For notational convenience, we use v = e1 = (1, 0, . . . , 0)
in (10.38). The special case m = 1 gives the unit circle S1, and then we have the
elementary result 
Since

(10.46) proves Lemma 10.4 in the special case m = 1.
It remains to prove the case m ≥ 3. In higher dimension we use an analytic
formula. If an m-dimensional surface (“manifold”) is given in the graph xm+1 =
f(x1, . . . , xm), then the (m-dimensional) surface area is expressed in terms of the
partial 
derivatives 
fxj 
of 
f 
as 
a 
multiple 
integral: 
By symmetry we can assume that 0 ≤ β < γ ≤ 1. For the upper hemisphere we use
the particular function
which, via simple calculations, gives the following form of (10.47):
m-dimensional surface area of the spherical belt
More precisely, for 0 ≤ β < γ ≤ 1 we have
The inner integral
in (10.49) is defined on the (m − 1)-dimensional ball (= solid sphere) of radius 
. By decomposing this ball into concentric spheres of radius r, 0 < r

< R, we have 
where SA means the surface area, and we applied the substitution r = Rsin θ with
.
Combining (10.49) and (10.50), for 0 ≤ β < γ ≤ 1 we have
Using (10.51) in the special case β = 0 and γ = 1 (“hemisphere”):
Taking the ratio of (10.51) and (10.52), the first factors cancel out, and only the
integrals with respect to x1 survive. This proves Lemma 10.4 for 0 ≤ β < γ ≤ 1.
The general case follows by symmetry.
Thus the proof of Theorem 10.1 is complete.
11. Asymptotic Time-Lapse Randomness
Consider now the 3-dimensional general torus model introduced in (10.1)–
(10.4), and let us go back to the proof of Theorem 3.2. Replacing the application
of the Kronecker–Weyl theorem to the characteristic function of a set S*(∆) ⊂
[0, 1]3N with an application of Theorem 10.1 (“Weak Uniformity Theorem”), we
obtain the following analog of Theorem 3.2.

Theorem 11.1. (another asymptotic binomial distribution) Consider the 3-
dimensional general N-particle torus model drifting away from the start; see
(10.1)–(10.4). Then for almost every vector of rotations ω = (ϑ1, ϑ2, . . . , ϑN) ∈
Ω = (SO(3))N,
where
is the corresponding point-counting function, the perfect analog of (3.11).
Applying the classical DeMoivre–Laplace theorem with error term, Theorem
11.1 implies the following result (CLT stand for the central limit theorem).
Theorem 11.2. (asymptotic CLT) (a) Under the conditions of Theorem 11.1, with
NS(t) = NS(Y; ; ω; t), 
where p = vol(S) and q = 1 − p.
Note that the error term 
 in (11.1) is the inevitable discrepancy
between the (continuous) standard normal distribution and the (discrete)
normalized binomial distribution with parameters N and 0 < p < 1.
These are asymptotic results, describing the (very!) long-term time evolution
of a large N-particle system, starting from an arbitrary initial point configuration
(e.g., “Big Bang”, where all particles start from the same point). Theorem 11.2
has the message of asymptotic time-lapse randomness as t → ∞.
The same argument proves a far-reaching generalization of Theorems 11.1
and 11.2, extending the binomial distribution to the multinomial distribution.
Theorem 11.3. (multinomial version) Let k ≥ 2 be an integer, and let S1, S2, . . . ,
Sk be arbitrary pairwise disjoint Jordan measurable subsets of the unit cube [0,
1]3. Let 0 < pi = vol(Si) < 1, 1 ≤ i ≤ k.

(a) Under the condition of Theorem 3.2, with NSi(t) = NSi(Y; V; t), 
(b) Similarly, under the condition of Theorem 11.1, with NSi(t) = NSi(Y; 
; ω; t),
we have the perfect analog of (11.2).
Indeed, to prove Theorem 11.3 we just apply either the Kronecker–Weyl
theorem (via unfolding) or the Weak Uniformity Theorem in the configuration
space.
The same argument gives the generalization of Theorem 11.1 where different
particles may have different masses. Let µk, 1 ≤ k ≤ N denote the mass of the kth
particle. For simplicity we assume that average mass is one, i.e., 
.
Then the point-counting function NS(t) is replaced by the mass-counting function
NS(mass; t): 
It is natural to expect that, when the time evolution of the system reaches
“equilibrium”, the mass-counting function NS(mass; t) gets very close to pN, and
the discrepancy exhibits “random fluctuation” with “standard deviation” 
as 
t 
runs 
in 
a 
long 
time 
interval; 
here 
Again the Kronecker–Weyl theorem and the Weak Uniformity Theorem
justify this intuition; see (11.7) below. The first step is the following perfect
analog of Theorem 11.3 (the proof is the same).
Theorem 11.4. (mass-counting version) Consider the general case of arbitrary
masses; see (11.3)−(11.4).
(a) Under the conditions of Theorem 3.2, for every real number −∞ < y < ∞,

where p = vol(S), q = 1 − p, and |I| denotes the number of elements of a finite set
I.
(b) Under the conditions of Theorem 11.1, we have the perfect analog of (11.5).
The right-hand side of (11.5) is the distribution of the sum 
 of N
independent random variables Xk, 1 ≤ k ≤ N such that Pr[Xk = µk] = p and Pr[Xk =
0] = q. Then the expectation of Y is pN, and the variance of Y is σ2pqN. The well-
known Berry–Esseen inequality in probability theory (see e.g., in [F71]) says
that 
Combining (11.5) and (11.6), we obtain
Let us return to Theorem 11.2. If the volume p = vol(S) of the test set S is
very small — say, it is around 1/N — then of course (11.1) becomes useless
(since the error term 
 is in the range of 1). However, Theorem 11.1 still
works, and implies the following analog of Theorem 3.4.
Theorem 11.5. (asymptotic Poisson law) Write λ = pN = vol(S)N. Under the
conditions 
of 
Theorem 
11.1, 
for 
every 
integer 
ℓ 
≥ 
0, 
Note that (11.8) immediately follows from Theorem 11.1 combined with the
simple approximation

If λ = pN = vol(S)N is in the “constant range” (i.e., the volume of the test set
S is very small), then by (11.8), the point-counting function NS(t) has Poisson
distribution with negligible error (since the error term O(λ2/N) is very small).
In the general case, where there are several sets S1, S2, . . . , Sk, k ≥ 2, the
multinomial Theorem 11.3 gives the following result.
Theorem 11.6. (multinomial Poisson) Let k ≥ 2 be an integer, and let S1, S2, . . . ,
Sk be k small pairwise disjoint Jordan measurable subsets of the unit cube [0, 1]3
such that 0 < λi = piN = vol(Si)N, 1 ≤ i ≤ k are all in the constant range.
(a) Under the conditions of Theorem 3.2,
where the implicit constant in the error term O(1/N) depends only on the given
constants λ1, . . . , λk .
(b) Similarly, under the conditions of Theorem 11.3, we have the perfect analog
of (11.9).
The product at the beginning of the last line in (11.9) tells us that the long-
term time evolution of the system exhibits “asymptotic independence” of “very
small” disjoint test sets Si, 1 ≤ i ≤ k (of course we are talking about statistical
independence).
Notice that “asymptotic independence” certainly fails for “large” subsets Si.
The simplest example is when we have two sets, and they are complements S2 =
[0, 1]3 \ S1. Then we have a deterministic relation between the number of point
billiards in S1 and in S2 (the sum is constant), which contradicts (statistical)
independence.

What happens if the disjoint test sets Si, 1 ≤ i ≤ k are still “small” but not
“very small”?
Here is a positive result. Assume that the volumes pi = vol(Si), 1 ≤ i ≤ k are
all in the range of 
 (i.e., each test set is expected to contain around 
 point
billiards), then 
for all fixed constants −∞ < y1, y2 < ∞, where log stands for the natural (base e)
logarithm and N(y) denotes the normal distribution: 
Note that (11.10) follows easily from Theorem 11.3 via routine estimation.
We outline this simple — but somewhat long — estimation in the special case of
two disjoint midsize sets S1 and S2 (i.e., k = 2) with pi = vol(Si) ≈ 1/
, i = 1, 2.
In 
view 
of 
Theorem 
11.3 
we 
have 
to 
estimate 
the 
ratio 
where the product in the denominator of (11.11) represents independence. To
prove (11.10) (for k = 2), it suffices to show that the ratio (11.11) is 
Indeed, the binomial distribution is close to the normal distribution if Npi is
“large” (see the denominator of (11.11)), and |ni − piN| > 
 represents a
“large deviation” with probability around 
which is superpolynomially small in terms of N, so it is totally negligible.
We have

where of course exp(x) = ex. Using the Taylor series
we have
Estimating the Riemann sum with the integral, we have
Using (11.14) in (11.13), we have

By using the condition
(see (11.12)) in (11.15), we conclude
which is exactly what we wanted to prove (see (11.12)).
Consider now the 3-dimensional general torus model introduced in (10.1)–
(10.4). Replacing the application of the Kronecker theorem in the proof of
Theorem 3.1 with an application of Theorem 10.1 (“Weak Uniformity
Theorem”), we obtain the following analog of Theorem 3.1.
Theorem 11.7. (another superdiscrepancy result) Consider the 3-dimensional
general N-particle torus model drifting away from the start; see (10.1)–(10.4).
Then for almost every vector of rotations 
the time evolution of the system exhibits the (B1, . . . , BN)-type superdiscrepancy
described in Theorem 3.1.
The next result shows that some application of the superdiscrepancy result
Theorem 3.1 does require ridiculously large time, i.e., in some cases unrealistic
time is inevitable. Assume that the 3N initial velocity coordinates of an N-
particle point-billiard system are linearly independent over the rationals; let B ⊂
[0, 1]3 be an arbitrary box in the unit cube; and, finally, let I ⊂ {1, 2, . . . , N} be
an arbitrary subset. Here is a simple corollary of Theorem 3.1: starting from an
arbitrary initial point configuration (t = 0), it will eventually happen at some time
instant t > 0 that the ith particle is in B if and only if i ∈ I. That is, the index-set I
is exactly the set of particles in B at time t.
For simplicity assume that the box B ⊂ [0, 1]3 has volume 1/2. For a typical
time instant t the number of particles in B is expected to be close to N/2. This

leads us to the following natural question: How long does it take to have all
possible N/2-element subsets to show up as the set of particles in B? We prove
that, under very mild conditions, the required time is exponentially large in terms
of N.
More precisely, we say that the time evolution of an N-particle billiard
system is (B; N/2)-complete in a time interval [0, T] (where t = 0 is the start), if
for every N/2-element subset I ⊂ {1, 2, . . . , N} there exists a time instant 0 ≤
t(I) ≤ T such that the ith particle is in B at time t(I) if and only if i ∈ I.
Let B0 denote the cube of volume 1/2 centered at (1/2, 1/2, 1/2)
Theorem 11.8. Assume that at least 99% of the speeds of an N-particle point-
billiard system {xk(t) : 1 ≤ k ≤ N} are less than 100, and the time evolution is (B0
; N/2)-complete in a time interval [0, T], where B0 is the cube defined in (11.16).
Then 
The same holds for torus lines instead of billiard paths.
Remarks. The crucial fact here is that the lower bound is exponential in N. So, if
N is in the range of the Avogadro number N = 1024, or larger, then the lower
bound gives a totally unrealistic, absurd time scale.
The choice of the constants “99%” and “100” are accidental. We could
choose basically any other constants, and the proof still works providing an
exponential lower bound.
On an intuitive level Theorem 11.8 is perfectly plausible, almost trivial.
Indeed, since there are 
 N/2-element subsets of the set of N
particles, and the particles have constant speed, the exponential (in terms of N)
lower bound for the necessary time T is not surprising at all. The precise proof of
Theorem 11.8 is also simple; see below.
It is a trivial by-product of Theorem 11.8 that perfect time-lapse randomness,
or even nearly perfect time-lapse randomness, requires the same totally
unrealistic, exponential time scale. Indeed, let S ⊂ [0, 1]3 be a Jordan
measurable subset in the unit cube with volume 1/2. If the 3N initial velocity
coordinates of the point-billiard system are linearly independent over the
rationals, then for every 1 > ε > 0 there is a finite threshold T0 — depending on

the 
initial 
velocity 
coordinates, 
on 
S, 
and 
on 
ε 
— 
such 
that 
holds for any two different N/2-element subsets Ii ⊂ {1, 2, . . . , N}, i = 1, 2 and
for every T ≥ T0. We say that the time evolution of a billiard system exhibits
nearly perfect time-lapse randomness if (11.17) holds for some 1 > ε > 0 and T0.
The message of Theorem 11.8 is that it is impossible to have nearly perfect time-
lapse randomness on a realistic time scale. Indeed, for every 1 > ε > 0, Theorem
11.8 applies and gives the lower bound 
which is exponential in N, i.e., totally unrealistic.
This negative result raises the natural question: what kind of randomness can
we prove on a realistic time scale? In the physical world most systems reach
equilibrium very fast; if nearly perfect randomness is unrealistic, how can we
still justify the physicist’s intuition equilibrium = randomness? We will address
this very interesting problem with rigorous theorems later in Chap. 3. For
example, Theorem 19.1 can be interpreted as a “realistic time version” of the
CLT-result Theorem 11.2. We also prove that large billiard systems demonstrate
time-lapse randomness in the form of exhibiting a “multiple mixing” type
property on a constant time scale (independent of N); see multiple mixedupness
in Sec. 12.
Proof of Theorem 11.8. We show that, under the condition
there exists a time interval [a, b] ⊂ [0, T] with b − a ≤ 10−3 and a particle — the
ith particle, say — that has speed less than 100, and in the time interval a ≤ t ≤ b
the ith particle makes the following in-out-in motion: at time t = a it is in B0,
later at some time t = c ∈ (a, b) it is outside of B0, and finally at time t = b it is
again in B0. A slow particle (= billiard) with speed less than 100 simply cannot
do this in-out-in motion in such a short time, which is a contradiction. Indeed, B0
is relatively far from the six faces (“walls”) of the unit cube, the distance is >
1/10 — so, leaving B0 at some instant t with tj1 ≤ t ≤ t(Ij2), and moving toward the
“walls”, a slow billiard does not have the time to bounce back from the walls to
be in B0 again (since b − a ≤ 10−3).
First consider the special case where every particle has speed ≤ 100. Assume

that the particles are labelled 1, 2, . . . , N, let I be an arbitrary N/2-element
subset of {1, 2, . . . , N} and let t(I) ∈ [0, T] be a time instant such that at time t =
t(I) the index set of particles in B0 is exactly I. We write these times in increasing
order 
and accordingly we define the following 0,1 matrix A of m rows and N columns.
The entry ai,j ∈ A of the matrix is 1 if at time t = ti the jth particle is in B0, and 0
otherwise. A vertical 1-block in A is a maximal line-segment of consequtive 1’s
in a column; formally, ai,j = 1 for some interval k ≤ i ≤ ℓ such that either ak−1,j =
0, aℓ+1, = 0, or k = 1, or ℓ = m (j is arbitrary). It is easy to see that the number of
vertical 1-blocks in A is ≥ m = 
. Indeed, for every row i there is an entry ai,j
= 1 such that either ai−1,j = 0 or i = 1, so ai,j = 1 is the top member of a vertical 1-
block in A. Since there are N columns, there is a column i0 that contains at least 
/N vertical 1-blocks. If T < 10−3
/N then by the pigeonhole principle there
exist 1 ≤ j1 < j2 ≤ m = 
 with j2 − j1 ≥ 2 such that (see (11.18)) tj2 − tj1 ≤ 10−3,
ai0,j1 = 1 is the top member of a vertical 1-block in A, and ai0,j2 = 1 is the top
member of another vertical 1-block in A. It follows that the i0th particle makes
the following in-out-in motion: at time t = tj1 it is in B0, later at time t = tj2−1 it is
outside of B0, and finally at time t = tj2 it is again in B0 — a contradiction. The
contradiction proves the lower bound T ≥ 10−3
/N, which is exponential in N.
Next we explain how to modify the argument in the general case. By
hypothesis, there are at least N1 ≥ 99N/100 “slow” particles with speed ≤ 100.
Throwing out the “fast” particles, we can repeat the previous argument with 
, and obtain the lower bound 
Clearly

where in the last steps we applied the elementary facts 
 ≥ 2n/n and 1 + x ≤
ex. Using (11.20) in (11.19), Theorem 11.8 follows.
We conclude Sec. 11 with a generalization of Theorem 11.8. A key step in
the proof of Theorem 11.8 was the impossibility of the “in-out-in motion” by a
point billiard. This argument breaks down if the point billiards are replaced by
tiny solid balls (“hardcore model”), since the balls can collide, and the trajectory
of a single billiard ball is more like a chaotic zig-zag than a curve of wall-to-wall
line segments. The average speed is one, so in unit time a typical point billiard
moves from wall to wall on a line segment. A tiny billiard ball, on the other
hand, has many particle–particle collisions in unit time. In gas models, the
number of collisions in unit time is subtantially less than N (= the number of
particles in the box). This fact motivates the following definition. Assume that
every particle has a piecewise linear continuous trajectory in the unit cube [0, 1]3
such that (1) the particle moves with constant speed on a linear piece, where the
speed depends on the piece, and
(2) the particle travels less than N2 linear pieces in unit time.
We refer to a system with properties (1) and (2) as a collision-like system. When
a particle moves from one linear piece to another linear piece, we call it a break
(it imitates a particle–particle collision).
Of course, the choice of N2 is accidental; we could also write N10, say. Note
that the upper bound N2 is already “very generous”.
Generalization of Theorem 11.8. Consider a collision-like N-particle system.
Assume that the time evolution of the system in a time interval [0, T] is (B0; N/2)-
complete, where B0 is the cube of volume 1/2 in Theorem 11.8. Moreover, assume
that for every time instant t in 0 ≤ t ≤ T at least 99% of the speeds are less than
100N2. Then 

Remark. Again the choices of 100N2 and 99% are accidental; we could choose
other constants and also a higher power of N. Again the lower bound is
ridiculously large if N is in the range of the Avogadro number (or larger).
Proof. We repeat the proof of Theorem 11.8 with some minor modifications at
the end. The first modification is that we change b − a ≤ 10−3 to b − a ≤ 10−3N−2.
Since the system is collision-like satisfying properties (1) and (2) above, and
the length of the time-interval a ≤ t ≤ b is less than one, there are at most H < N ·
N2 = N3 breaking points 
such that at time t = t(h) the trajectory of some particle breaks. This explains the
first extra factor N3 in the denominator of the lower bound. The second extra
factor N2 in the denominator comes from replacing b−a ≤ 10−3 to b − a ≤ 10−3N
−2.
This is why we have the extra factor N5 = N3 · N2, replacing N2 in the
denominator of the lower bound in Theorem 11.8 with N7 = N5 · N2.
Again we apply the pigeonhole principle, noting that in “break-free” time
intervals we can save the basic idea: a slow particle with speed less than 100N2
simply cannot do the in-out-in motion in a short “break-free” time interval.
12. Short-Term Time-Lapse Randomness: Multiple
Mixedupness (I)
We discuss a “time-lapse randomness” type result motivated by (statistical)
independence (= product rule); we call it multiple ε-mixedupness. For
comparison, first we recall the concept of ε-perfect time-lapse randomness
introduced in Sec. 11; see (11.17). The Kronecker–Weyl equidistribution
theorem implies (via unfolding) the following result: If the initial velocity
coordinates of an N-particle point-billiard system {xk(t) : 1 ≤ k ≤ N} are linearly
independent over the rationals, and S ⊂ [0, 1]3 is a Jordan measurable subset of
the unit cube with volume 0 < p = vol(S) < 1, then for every 1 > ε > 0 there is a
finite threshold T0 — depending on the initial velocity coordinates, on S, and on
ε — such that 
holds for every subset I ⊂ {1, 2, . . . , N} and for every T ≥ T0. Equation (12.1)
has the interpretation that the time evolution of a billiard system exhibits ε-

perfect time-lapse randomness for all T ≥ T0.
Theorem 11.8 implies that it is impossible to have ε-perfect time-lapse
randomness on a realistic time scale. Indeed, for every 1 > ε > 0, Theorem 11.8
applies, and yields the lower bound 
which is exponential in N, i.e., totally unrealistic.
In sharp contrast with this “extremely long-term time-lapse randomness”
result (exponential time in terms of N), in this section we prove a “short-term
time-lapse randomness” result that goes as follows. Starting from an arbitrary
initial configuration, the majority of the time evolutions of a point billiard
system exhibits multiple ε-mixedupness in constant time independent of the
number of particles N (it depends only on ε > 0). Constant time is certainly
realistic.
The formal definition of multiple ε-mixedupness is the following. For
simplicity we start with the special case where the test sets are axis-parallel
boxes; we switch to the general case of arbitrary measurable test sets at the end
of the section. Let k ≥ 1 be an arbitrary integer, let Bj ⊂ [0, 1]3, 1 ≤ j ≤ k be an
arbitrary sequence of k axis-parallel boxes in the unit cube such that 0 < vol(Bj)
= pj < 1, 1 ≤ j ≤ k, and let 0 < t1 < t2 < · · · < tk be k times in increasing order.
Given an ε > 0, we say that the time evolution of a point billiard system, starting
from a given initial configuration Y = {y1, . . . , yN} at t = 0 with some given
initial velocities, exhibits multiple ε-mixedupness at 0 < t1 < t2 < · · · < tk with
respect to the sequence Bj ⊂ [0, 1]3, 1 ≤ j ≤ k of the given test sets, if the number
of particles that are simultaneously in Bj at t = tj for every j = 1, 2, . . . , k is
between 
The concept of multiple ε-mixedupness is motivated by the physical act of
stirring a liquid, and the product form of the density 
 represents “perfect
stirring”: perfect time-lapse independence via the product rule.
Notice that (12.1) demonstrates ε-approximation of the product rule (= time-
lapse statistical independence) in a very strong sense. On the other hand, (12.2)
demonstrates ε-approximation of the product rule (= time-lapse statistical
independence) in a different weaker sense. This explains the dramatic drop from
exponential time to constant time in the required time scale.

What we can actually prove is the typicality of multiple ε-mixedupness. Here
is the precise statement of what we prove. Let ε be a positive real with 0 < ε < 1
and k ≥ 1 be an integer. Then there exist absolute constants C1(ε; k) and C2(ε; k),
both depending only on ε and k, such that, given an arbitrary real T ≥ C1(ε; k),
given an arbitrary sequence Bj ⊂ [0, 1]3, 1 ≤ j ≤ k of k axis-parallel boxes
satisfying 
given an arbitrary initial configuration Y = {y1, . . . , yN} ⊂ [0, 1]3 with N ≥
C2(ε; k), and given an arbitrary real T0 ≥ 0, for at least 1 − ε part of all choices of
k times t1 < · · · < tk with 
the time evolution for at least 1 − ε part of the initial velocities of an N-particle
billiard system — starting from Y at t = 0 — exhibits multiple ε-mixedupness at
t1, t2, . . . , tk (see (12.3)) with respect to the given sequence Bj ⊂ [0, 1]3, 1 ≤ j ≤
k of test sets.
Here at least 1 − ε part of all choices of k times t1 < · · · < tk with 
precisely means that we choose a point in the k-dimensional cube [0, T]k with
uniform distribution, and its jth coordinate gives tj−T0−(j−1)T, 1 ≤ j ≤ k. Of
course, at least 1 − ε part refers to the normalized k-dimensional volume (=
Lebesgue measure), i.e., we divide by Tk.
We picked the name mixedupness because multiple mixedupness shows some
formal similarity to the concept of multiple mixing measure-preserving
transformation in ergodic theory. But they are not the same: mixing is a “soft”
long-term property, which is perfectly meaningful even for one particle;
mixedupness, on the other hand, is a “hard” quantitative property, which is
meaningful for many-particle systems only, and it is used to describe the realistic
short term time evolution of a (large) system. At the end of the section — after
formulating Theorems 12.1 and 12.2 — we return to the question of comparing
our mixedupness to the concept of mixing in ergodic theory. We show that the
time-flow of our model is not mixing; nevertheless it exhibits multiple
mixedupness in a constant time scale.
As usual, we apply unfolding (see Sec. 3) to convert the time evolution of a

billiards-in-a-box system to that of a torus-billiard system. We use the general
continuous Erdős–Turán–Koksma inequality (see (3.21)) in the special case
where the continuous curves are torus lines. That is, we study the straight line
r(t) = tv, where v = (v1, . . . , vd) ∈ Rd is the direction vector (and of course we
take the straight line modulo one).
Erdős–Turán–Koksma Inequality for torus lines: Let tv, 0 ≤ t ≤ T (v ∈ Rd \ 0 is
fixed) be a straight line and H ≥ 1 be an arbitrary integer; then with f = χB, where
B denotes axis-parallel boxes and, as usual, f is defined on the unit torus Id = [0,
1)d (i.e., f is periodic), 
where 
 is an arbitrary integer,
is the maximum norm of the vector h = (h1, . . . , hd) ∈ Zd, and 
In the special case of torus lines we can explicitly evaluate the key integral
which implies the upper bound
Using (12.7) in (12.4), we have with f = χB,
where of course

is the relative time the torus line spends in box B, and
is the (d-dimensional) volume of the box, representing the expected relative time.
We recall Archimedes’s theorem (10.21): for any 3-dimensional unit vector
w 
and 
any 
real 
number 
 
with 
0 
< 
 
< 
1 
= 
|w|, 
It follows from (12.11) that, if w ∈ S2 is fixed and v* ∈ S2 is a random variable
uniformly distributed on the unit sphere, then the dot product w · v* is uniformly
distributed in the interval [−1, 1]. We refer to this remarkable geometric fact as
the “uniformity property of the sphere”.
Let w ∈ S2 be a fixed unit vector, and let 
 be N independent
random variables uniformly distributed on the unit sphere. For a given integer ℓ,
let 
E1(w; 
ℓ; 
6 
log 
N) 
denote 
the 
event 
that 
the 
interval 
contains at least 6 log N dot products w · v*k, 1 ≤ k ≤ N ; and for given integers ℓ
and r with 2r ≥ N1/3, let E2(w; ℓ; r) denote the event that the interval 
contains at least 2r dot products w · v*k, 1 ≤ k ≤ N.
Combining independence with the “uniformity property of the sphere”, we
can estimate the probability of event E1(w; ℓ; 6 log N) by using the binomial
distribution 
as 
follows: 
where we applied the weak form of Stirling’s formula m! ≥ (m/e)m.
Similarly, we can estimate the probability of event E2(w; ℓ; r) from above as
follows:

To estimate (12.15), we use the well-known large deviation inequality for the
binomial distribution: if X1, . . . , Xn are independent random variables with
common distribution Pr[Xi = 1 or 0] = p or q = 1 − p, then for every positive γ, 
where 
 is the standard deviation of the binomial distribution. We apply
(12.16) with n = N, p = 3 · 2r−2/N (so p ≤ 1/2, implying p ≤ 1/2 ≤ q = 1 − p), and 
which implies (note that 2r ≥ N1/3)
and
Using (12.16)–(12.19), we obtain the following upper bound for the end sum of
(12.15)
Assume that w runs over the special unit vectors of the form

where M = M(N) will be specified later. Consider the two union events
and
By using (12.14) in (12.22), we have the upper bound
Similarly, by using (12.15) and (12.20) in (12.23), we have
We say that a sequence v1, v2, . . . , vN ∈ S2 of N unit vectors on the unit
sphere satisfies the Separation Condition if for every nonzero lattice point h ∈
Z3 \ 0 we have the following two properties: (1) for every integer −N ≤ ℓ ≤ N − 1
the interval 
contains less than 6 log N dot products h · vk, and (2) for every integer ℓ and
integer r with 2r ≥ N1/3, the interval 
contains less than 2r dot products h · vk, where 1 ≤ k ≤ N.
Lemma 12.1. Let N ≥ 1015; then the set of unit vectors v1, v2, . . . , vN ∈ S2 that

satisfy the Separation Condition (12.26)–(12.27) represents an over-whelming
majority: it is at least 1 − N−10 part of the total.
Proof. Let w = (w1, w2, w3) ∈ S2 be an arbitrary unit vector. By Dirichlet’s
simultaneous approximation theorem, there exist integers n1, n2, n3 such that 
Let v1, v2, . . . , vN ∈ S2 be an arbitrary sequence of N unit vectors. With n = (n1,
n2, n3) we have for every 1 ≤ k ≤ N, 
where we used (12.28).
Again by (12.28),
By (12.28) and (12.30),
Notice that n/|n| in (12.31) has the special form of (12.21) with M = 2N. Thus by
(12.24)
Moreover, by (12.25)
Combining (12.32) and (12.33), we have
where

Finally, by (12.31)
and so we have the implication
Combining (12.12)–(12.13) with (12.35), and also using (12.34), Lemma 12.1
follows.
We now fix a sequence v1, v2, . . . , vN ∈ S2 of N unit vectors on the unit
sphere that satisfies the Separation Condition (12.26)–(12.27). Let J ⊆ {1, 2, 3, .
. 
. 
, 
N} 
be 
a 
subset, 
and 
consider 
the 
torus-billiard 
system 
where of course modulo one means the fractional part applied coordinatewise, 0
≤ 
t 
≤ 
U 
refers 
to 
the 
time 
evolution, 
and 
is the initial configuration (i.e., a |J|-element point set in the unit torus I3 = [0,
1)3). Let B ⊂ [0, 1)3 be an axis-parallel box; we study the square integral
(“variance”) 
where
We need the following key lemma.
Lemma 12.2. Let v1, v2, . . . , vN ∈ S2 be a sequence of N unit vectors on the unit
sphere that satisfies the Separation Condition (12.26)−(12.27). Then for every
subset J ⊆ {1, 2, 3, . . . , N}, every initial configuration (12.37), every axis-
parallel 
box B 
⊂ 
[0, 
1)3, and 
every 
real 
number 
U 
≥ 
10, 

The proof is basically a straightforward application of the Erdős–Turán–
Koksma Inequality for torus lines (see (12.4)). Despite the simplicity of the basic
idea of the proof, the technical details are rather long and complicated, so we
decided to postpone it to Sec. 33.
Next we repeatedly apply Lemma 12.2 the same way as we usually apply
Chebyshev’s inequality in probability theory. We choose an arbitrary sequence
v1, v2, . . . , vN ∈ S2 of N unit vectors on the unit sphere that satisfies the
Separation Condition (12.26)–(12.27); in applications of Lemma 12.2 we use the
short notation (see (12.36)) 
We choose a sequence B1, . . . , Bk of k axis-parallel boxes in the unit cube [0,
1)3; choose a positive ε such that 
choose an initial configuration
and choose a real number T0 > 0. We apply Lemma 12.2 with B = B1,
representing the initial configuration, and obtain the upper bound for every real
U1 ≥ 10
For every η1 > 0 let
Combining (12.42) and (12.43), we have
Next we choose an arbitrary τ1 ∈ [0, U1] \ S1(U1; η1), and define 

By definition
By (12.43) and (12.46),
Next we apply Lemma 12.2 with the initial configuration
and obtain the upper bound for every real U2 ≥ 10
For every η2 > 0 let
Combining (12.48) and (12.49), we have
length (S2(τ1; U2; η2))
Next we choose an arbitrary τ2 ∈ [0, U2] \ S1(τ1 : U2; η2), and define 
where we used (12.45). By definition
By (12.49) and (12.52),
and combining it with (12.47), we have

Next we apply Lemma 12.2 with the initial configuration
and obtain the upper bound for every real U3 ≥ 10
For every η3 > 0 let
Combining (12.55) and (12.56), we have
Next we choose an arbitrary τ3 ∈ [0, U3] \ S2(τ1; τ2; U3; η3), and define 
where we used (12.51). By definition
By (12.56) and (12.59),
and combining it with (12.53), we have

which is the analog of (12.53).
We keep repeating this argument until we cover all k given test sets B1, . . . ,
Bk. At the end of the process we obtain a subset of J0 = {1, 2, 3, . . . , N}
with
(a generalization of (12.60)), where pi = vol(Bi) (see (12.40)),
and (see (12.57) for i = 3)
for i ≥ 2, and (see (12.44))
Since
holds for every 1 ≤ h ≤ k, by (12.64) we have for i ≥ 2

Next we specify the parameters Ui and ηi: let
Since 0 < ε < 1, we have
Using (12.68) in (12.62), we have
Next we use (12.67) and (12.68) in (12.66), and also use
(see (12.40)); thus we obtain
Finally, simple calculation gives that the inequality
holds if
and
Thus by (12.70)–(12.73) we have

which implies
Combining the Separation Condition (see (12.26)–(12.27)) with (12.61), (12.63),
(12.69) and (12.74), we obtain the following theorem with T0 < t1 = τ1 < T0 + T,
T0 + T < t2 = τ1 + τ2 < T0 + 2T, T0 + 2T < t3 = τ1 + τ2 + τ2 < T0 + 3T, and so on
with 
at the end.
Theorem 12.1. Let ε be a positive real with 0 < ε < 1 and k ≥ 1 be an integer.
Given an arbitrary real
given an arbitrary sequence Bj ⊂ [0, 1]3, 1 ≤ j ≤ k of k axis-parallel boxes
satisfying
given an arbitrary initial configuration Y = {y1, . . . , yN}⊂ [0, 1]3 with 
and given an arbitrary real T0 ≥ 0, for at least 1 − ε part of all choices of k times
t1 < · · · < tk with 
the time evolution of an N-particle billiard system, starting from Y at t = 0, and
with initial velocities v1, v2, . . . , vN ∈ S2 satisfying the Separation Condition
(12.26)−(12.27), exhibits multiple ε-mixedupness at t1, t2, . . . , tk with respect to
the given sequence Bj ⊂ [0, 1]3, 1 ≤ j ≤ k of test sets. That is, the number of
particles that are simultaneously in Bj at t = tj for every j = 1, 2, . . . , k is
between 
ε-approximating the product rule of statistical independence. Moreover, “at least
1−ε part of all choices of t1 < · · · < tk” precisely means that we choose a point in
the k-dimensional cube [0, T]k with uniform distribution, the jth coordinate of
this point gives tj − T0 − (j − 1)T, 1 ≤ j ≤ k, and we take the normalized k-

dimensional volume (i.e., we divide by Tk). Finally, by Lemma 12.1, the set of
initial velocities v1, v2, . . . , vN ∈ S2 that satisfy the Separation Condition
(12.26)–(12.27) represents an overwhelming majority: it is at least 1 − N−10 part
of the total.
Remarks. The main point here is that the thresholds C1(ε; k) and C2(ε; k) are
constants in the sense that they are independent of the number N of the particles.
It is very likely that the explicit formulas given in (12.72)–(12.73) can be
substantially improved.
Theorem 12.1 is about N-particle billiard systems where the initial velocities
are unit vectors, i.e., the particles have the same constant speed (like photons).
Note that we did not really use this fact in the proof. The proof of Theorem 12.1
actually works for any other isotropic initial velocity distribution (for example,
the 3-dimensional normal, or Gaussian, distribution; physicists often call it the
Maxwellian distribution).
Next we give a result that can be considered — in some sense — a far-
reaching extension of Theorem 12.1. We are motivated by the following natural
question: What happens if one replaces the “nice” test sets of k axis-parallel
boxes Bi ⊂ [0, 1]3, 1 ≤ i ≤ k with “ugly” test sets Ai ⊂ [0, 1]3, 1 ≤ i ≤ k, where Ai
are arbitrary Lebesgue measurable sets? Can one still prove an analog of
Theorem 12.1? In general — without any extra condition — the answer is no,
but we can still prove multiple ε-mixedupness in the following modified form. ε-
mixedupness holds with respect to the majority of the translated sequences Ai +
xi, 1 ≤ i ≤ k, xi ∈ [0, 1)3 (where of course the translation is taken modulo one,
i.e., we are on the unit torus).
Theorem 12.2. Let ε be a positive real with 0 < ε < 1 and k ≥ 1 be an integer.
Given an arbitrary real
given an arbitrary sequence Aj ⊂ [0, 1]3 = I3, 1 ≤ j ≤ k of k Lebesgue measurable
sets satisfying 

given an arbitrary initial configuration Y = {y1, . . . , yN}⊂ [0, 1]3 with 
and given an arbitrary real T0 ≥ 0, for at least 1 − ε part of all choices of the k
pairs (tj, wj), 1 ≤ j ≤ k consisting of translations wj ∈ I3 and times t1 < · · · < tk
with 
the time evolution of an N-particle billiard system, starting from Y at t = 0, and
with initial velocities v1, v2, . . . , vN ∈ S2 satisfying the Separation Condition
(12.26)−(12.27), exhibits multiple ε-mixedupness at t1, t2, . . . , tk with respect to
the translated sequence Aj + wj, 1 ≤ j ≤ k. That is, the number of particles that
are simultaneously in Aj + wj at t = tj for every j = 1, 2, . . . , k is between 
ε-approximating the product rule of statistical independence. Moreover, “at least
1 − ε part of all choices of the k pairs (tj, wj), 1 ≤ j ≤ k” precisely means that we
choose a point in the 4k-dimensional box [0, T]k × (I3)k with uniform
distribution, the jth coordinate of this point with 1 ≤ j ≤ k gives tj−T0−(j−1)T, the
remaining 3k coordinates give w1, . . . , wk in this order, and we take the
normalized 4k-dimensional volume (i.e., we divide by Tk). Finally, by Lemma
12.1, the set of initial velocities v1, v2, . . . , vN ∈ S2 that satisfy the Separation
Condition (12.26)–(12.27) represents an overwhelming majority: it is at least 1 −
N−10 part of the total.
Remarks. We postpone the proof of Theorem 12.2 to Sec. 34.
Similarly to Theorem 12.1, the main point here is that the thresholds C3(ε; k)
and C4(ε; k) are constants in the sense that they are independent of the number N
of the particles. It is very likely that the explicit formulas for C3(ε; k) and C4(ε;
k) can be substantially improved.
Similarly to Theorem 12.1, Theorem 12.2 is about N-particle billiard systems
where the initial velocities
are unit vectors, i.e., the particles have the same constant speed (like photons).
Note that we did not really use this fact in the proof. The proof of Theorem 12.2
actually works for any other isotropic initial velocity distribution.

A major difference between Theorems 12.1 and 12.2 is the appearance of
translations in the latter. We emphasize that without translation one cannot
expect any positive result, not even for a single test set A1, due to the
overwhelming generality of the Lebesgue measure. Indeed, choosing an arbitrary
but fixed initial configuration Y = {y1, . . . , yN}⊂ [0, 1]3 and choosing an
arbitrary but fixed set of initial velocities v1, v2, . . . , vN ∈ S2 satisfying the
Separation Condition (12.26)–(12.27), the time evolution of this N-particle
billiard system is described by N infinite smooth curves in the unit cube I3. The
union of these N infinite smooth curves has volume (= 3-dimensional Lebesgue
measure) zero, so choosing A1 to be the complement of this zero set, we obtain a
shocking “anti-uniformity” property of the time evolution of the system in the
following sense. No particle will ever enter A1 ⊂ I3, despite the fact that its
measure is one! This simple argument explains why we need some extra
condition (e.g., to involve typical translation, what we did in Theorem 12.2).
Both Theorems 12.1 and 12.2 are about mixedupness (in constant time).
What about mixing? What is the relation of the two concepts? We start with the
definition; for notational simplicity we just consider the case of discrete time
evolution (the continuous case is a straightforward analog). Given a probability
space (X, A, µ) and a µ-measure-preserving transformation T : X → X, we call T
mixing (or strongly mixing in some books) if for any two measurable sets A, B ∈
A 
In this section we were studying the translation-flow on the d-dimensional torus
Id = [0, 1)d. The discrete version of the translation-flow is Ta : x → x + a modulo
one (of course we mean it coordinatewise); and so Tk
a : x → x + ka modulo one
for every integer k ∈ Z. We know that Ta is ergodic if x and only if 1, α1, . . . , αd
are linearly independent over the rationals, where a = (α1, . . . , αd). We show that
Ta is not mixing for any of the vectors a = (α1, . . . , αd). Indeed, consider two
disjoint 
congruent 
balls 
in 
Id 
= 
[0, 
1)d; 
for 
example, 
let 
and

By Dirichlet’s simultaneous approximation theorem for every ε > 0 there exists
an 
infinite 
set 
S 
of 
positive 
integers 
n 
such 
that 
Note that the distance between B1 and B2 is 1/10; so, if ε > 0 is sufficiently small,
for n ∈ S the balls T−nB1 and B1 almost coincide, implying that T−nB1 and B2 are
disjoint, where T = Ta. It follows that 
which contradicts mixing.
In the traditional theory of dynamical systems the concepts of mixing and
hyperbolicity play a key role. The message of Sec. 12 is that, despite the lack of
mixing, the time evolution of our systems exhibit multiple mixedupness, and
other forms of short-term advanced randomness, including snapshot randomness
and time-lapse randomness (see the next chapters). We may say that, mixing — a
“soft” asymptotic property — is not necessary in the study of realistic short-term
time evolution of large systems toward “advanced randomness”. Similarly, as
our results demonstrate, we do not necessarily need hyperbolicity to demonstrate
“advanced randomness” in the short-term time evolution of large systems.
13. Extensions of Theorem 4.2 beyond the Gaussian
Case
To generalize Theorem 4.2 for arbitrary initial velocities beyond the Gaussian,
we have to point out a simple necessary condition for Configuration
Equilibrium. It comes from a “dimension argument”, which provides a trivial
obstacle that prevents us from proving Configuration Equilibrium for some
speed distributions. We call this obstacle the dimension deficit for the family of
corresponding curves in the configuration space. For example, consider the
simplest case, where the particles move on straight lines (modulo one, i.e., the
torus-billiard model), and the velocity distribution for each particle is isotropic
with constant unit speed (like photons). In this case the family of all possible
system-trajectories in the configuration space (starting from a fixed initial point
configuration, e.g., from the origin of the configuration space) has dimension 2N
+ 
1. 
Indeed, 
the 
initial 
directions 
are 
determined 
by 
a 
vector 
where (S2)N is a 2N-dimensional manifold, and the time evolution 0 ≤ t < ∞

gives the last extra dimension. On the other hand, the configuration space [0,
1)3N is of course 3N-dimensional, and the inequality 2N + 1 < 3N represents a
clear-cut case of dimension deficit. The union of the corresponding family of
curves (= all system-trajectories) in the configuration space (describing the time
evolution of the system starting from a fixed initial point configuration) has
dimension (at most) 2N + 1, so the 3N-dimensional Lebesgue measure of this
union set is zero. By choosing the test set S to be the complement of this union
set in [0, 1]3N, it is obvious why Configuration Equilibrium is impossible: this
particular test set has 3N-dimensional Lebesgue measure one, so the system-
trajectory should be in S most of the time. But what we have here is the complete
opposite: the system-trajectory will never ever enter this particular test set!
We conclude, therefore, that “photon like” systems with isotropic constant
speed cannot reach Configuration Equilibrium — there is no analog of Theorem
4.2. In a typical “photon like” system with isotropic constant speed the initial
velocity coordinates are linearly independent, so the Kronecker–Weyl theorem
still applies. But it is impossible to upgrade this “weak uniformity result” to a
“strong uniformity result” in the configuration space.
On the other hand, if every particle has an initial speed distribution with
“sufficiently smooth” density function, then there is no dimension deficit, and
we can indeed prove an analog of Theorem 4.2. In our first extension of
Theorem 4.2 we consider a general torus model where the particles move on
torus lines with (possibly) varying speeds, and every particle has its own (almost
arbitrary) smooth initial speed distribution. (In Sec. 14 we will discuss a
generalization of Theorem 4.2 for the case where the particles move on
nonlinear trajectories — that case is more complicated.) The curve of the whole
system 
in 
the 
configuration 
space 
is 
denoted 
by 
where t is the time,
is the vector (= point in the configuration space) formed from the set
of the initial point configuration at the start t = 0,

represents a family of functions such that
and
where α0 ≥ 1, 0 < α ≤ α1 are some absolute constants. (We also need a family of
probability density functions 
where gk defines the distribution of ρk by the integral Pr[ρk ≤ u] = 
 gk(y) dy; we
elaborate on G later.) Moreover, let I denote an arbitrary finite interval of
positive length. Assume that
uniformly for all T ≥ β0, where β0 ≥ 1 and 0 ≤ β < 1 are absolute constants.
Note that it is easy to satisfy conditions (13.4)–(13.6). For example, consider
the forward motions where the speeds 
 of the particles satisfy the inequalities
which hold for some absolute constants 0 ≤ ζ1 < 1 and ζ2 ≥ 0.
Of course, there are many other ways, mixing forward and backward
motions of the particles, such that (13.4)–(13.6) are still satisfied.
We focus on the most natural case where the particle space (= “gas
container”) is 3-dimensional, i.e., d = 3N. Notice that the curve (13.1) of the
whole system is in the d-dimensional unit torus Id = [0, 1)d, which is the
configuration space.
The trajectory of the kth particle is yk + ρkrk(t)ek ∈ R3, 1 ≤ k ≤ N modulo
one, representing a (possibly) varying speed motion on a torus line in the
direction ek. For the set of N particles at time t we use the notation 
Comparing (13.7) to (13.1), we see that the switch from the point set in the
particle space (= “gas container”) to the point in the configuration space is
indicated by an extra arrow  on the top of Y.
Let d = 3N, and let f ∈ L2(Id), Id = [0, 1)d be a complex-valued Lebesgue

square-integrable function in the d-dimensional unit torus (i.e., we extend f over
the 
whole 
d-space 
Rd 
periodically). 
Write 
Since the torus is translation invariant, it suffices to study the time discrepancy
of 
the 
-independent 
part 
(t) 
in 
(13.1): 
where (t) = (R; ρ1, e1, . . . , ρN, eN; t) and 0 < T1 < T2.
Let us discuss now the family
of probability density functions. The kth function gk defines the initial speed
distribution Pr[ρk ≤ u] = 
 gk(y) dy of the kth particle (1 ≤ k ≤ N). We assume
that 
where the last requirement in (13.10) means that the “expectation = mean-speed
is 
finite”. 
The 
corresponding 
initial 
velocity 
space 
is 
equipped with the product measure ProdMeasG, where the kth factor [0, ∞) × S2
in (13.11) has the normed surface area for the unit sphere S2 ⊂ R3 and has the
probability density function gk for [0, ∞).
By using (13.11), we can rewrite the time discrepancy (13.9) as follows:
where
and 0 < T1 < T2.
To extend Lemma 9.1 in the general case, we need to define the so-called 3-
dimensional “isotropic Fourier transform” of g = gk, 1 ≤ k ≤ N : 

where w is an arbitrary 3-dimensional vector, dSA(v) represents the surface area.
Fg(w) defines a real-valued function depending only on the length w = |w| of the
input vector, and we have 
By the Riemann–Lebesgue theorem Fg(w) → 0 as w → ∞.
Write
and
So both Fg
(sup)(w) and FG
(sup)(w) are monotone decreasing positive functions
tending to 0 as w → ∞.
Technical Condition: polynomial decay. Assume that there exist real numbers
γ > 3 and γ0 ≥ 1 such that
(We need the condition γ > 3 to avoid a “divergence problem” later in the proof
of Theorem 13.1; see below.)
Condition (13.15) with γ > 3 is easily satisfied if g = gk is “sufficiently
smooth”. This is the message of the following lemma.
Lemma 13.1. Let g(u) be a probability density function in [0, ∞) with g(0) = 0,
and extend it over the whole real line as an even function: g(−u) = g(u). Let k ≥
2, assume that g(u), −∞ < u < ∞ is k-times continuously differentiable, also
assume that for every integer 1 ≤ j ≤ k, the jth derivative g(j)(u) → 0 as u → ∞,
and finally assume 
Then the 3-dimensional “isotropic Fourier transform”

with w = |w| satisfies the upper bound
Note that dSA(v) represents the surface area.
Proof of Lemma 13.1. Let ĝ(x) denote the (ordinary) Fourier transform of g. By
hypothesis we can apply integration by parts k times in the definition 
of the Fourier transform, and thus we have
and so
We also need the following lemma.
Lemma 13.2. Let g(u) be a probability density function in [0, ∞), let us extend g
over the whole real line as an even function g(−u) = g(u). The 3-dimensional
“isotropic Fourier transform″ Fg(w) (defined in (13.13)) can be expressed in
terms 
of 
the 
Fourier 
transform 
ĝ(x) 
of 
g 
as 
follows: 
Moreover, if g(y) is continuous at y = 0 then
and so we can rewrite Fg(w) as
We are now ready to finish the proof of Lemma 13.1. By Lemma 13.2,
and by using (13.16), we conclude

completing the proof of Lemma 13.1. 0
It remains to prove Lemma 13.2. We need another lemma.
Lemma 13.3. Let w be an arbitrary 3-dimensional vector. Then
Proof of Lemma 13.3. The special case w = 0 is trivial: the left side is equal to
1, and the right side tends to 1 as w tends to 0; so we may assume that w ≠ 0. We
need a well-known geometric fact about the surface area of some special
spherical domains. Let e ∈ S2 be an arbitrary but fixed unit vector, and let 0 < δ
< 1 be an arbitrary real number. Consider the “spherical belt” (often called the
“spherical zone”): 
On one hand, it is trivial that the surface area of the “belt” S2(e; δ) is
independent of the choice of the unit vector e; it is a very surprising fact, on the
other hand, that the dependence on δ is just plain linear (discovered by
Archimedes) 
(13.17) implies that, for any nonzero 3-dimensional vector w and any real
number  with 0 <  < |w|, 
By using (13.18), we have
proving Lemma 13.3.
We are now ready to finish the proof of Lemma 13.2. By Lemma 13.3,
implying
Since g(−x) = g(x), we can rewrite (13.19):

We recall some well-known facts from the theory of Fourier transform:
denotes the Fourier transform of f, and we have the similar inversion formula
It follows from (13.21)–(13.22) that the Fourier inverse of f(x) is (−t).
We also need the fact
which is a corollary of the Parseval–Plancherel formula. Note that (13.21)–
(13.23) hold under mild conditions; for example, they hold if the functions are in
the space L2(R).
If χw(x) denotes the 0, 1 valued characteristic function of the interval [−w, w],
then 
(13.21) 
gives 
via 
simple 
calculations 
Since χw(x) is an even function, the Fourier transform of
is χw(x). Combining this fact with (13.23), we have
Note that g is not necessarily in the L2(R)-space; nevertheless, (13.23) applies in
(13.25), since 
 dx is a “safe” finite integral.
By (13.20) and (13.25),
Thus the proof of Lemma 13.2 is complete.
Let us return to (13.12); we take the square of the absolute value of the time
discrepancy

and study the following average (d = 3N)
where dSA*(e) means the normed surface area on the unit sphere S2, i.e., SA*
(S2) = 1.
Here we make a brief detour to explain that ∆f2(Gauss; T1, T2) in (6.29)
represents the special case of (13.26) where every particle moves on some torus
line with some constant speed (both depending on the particle), and the particles
have the same speed distribution with density g(u) = 
, 0 ≤ u < ∞
(which is the density of the speed distribution of the 3-dimensional Gaussian
velocity distribution). In this special case the trajectory of the kth particle is yk +
ρktek ∈ R3, 1 ≤ k ≤ N modulo one, where Pr[ρk ≤ u] = 
 dz; and the
set 
of 
the 
N 
particles 
at 
time 
t 
is 
(see 
(13.7)) 
The fact that (6.29) is a special case of (13.26) can formally be expressed as
follows:
in the definitions of R and G, respectively.
In this special case the curve 
(ω; t), t ≥ 0 of the whole system in the
configuration space is a straight line in the d-space (with d = 3N) modulo one: 

where (see (13.11))
and the product space ΩGauss is equipped with the product measure
ProdMeasGauss; here the half-line [0, ∞) has the probability density function g(u)
= 
 (see (13.28)). We refer to this special case as the simplest Gaussian
torus-billiard model (in the 3-space).
We leave now the Gaussian case, and formulate the first extension of
Theorem 4.2 in the case of the “polynomial decay”.
Theorem 13.1. Assume R satisfies (13.4)–(13.6), G satisfies the “polynomial
decay” condition (13.15) for the 3-dimensional “isotropic Fourier transforms”
Fgk, and 
Then
The upper bound (13.32) is quite complicated; nevertheless, it is very simple
to apply Theorem 13.1. In the applications N is very large (say, N is around the
Avogadro number), so we have to choose U in such a way that N2U1−αγ = O(1).
We will use Theorem 13.1 to extend the application of Theorem 4.2 about

advanced randomness and its long-term stability for large classes of smooth
initial velocity distributions far beyond the Gaussian case.
The proof of Theorem 13.1 goes along the same lines as that of Theorem 4.2,
but the details are more complicated; see Secs. 27–29.
The Class of Exponential Decay. The technical condition (13.15) represents a
polynomial decay of tending to zero (for the tail of the “isotropic Fourier
transform”).
A simple sufficient condition — formulated in Lemma 13.1 — is that the
density function of the speed distribution is “relatively smooth”.
On the other hand, the Gaussian distribution represents a superexponential
decay tending to zero (for the tail of the “isotropic Fourier transform”); see
Lemma 9.1. We show that there is a whole class of probability distributions such
that the corresponding “isotropic Fourier transform” tends to zero (at least)
exponentially fast. For this “exponential decay class” we can prove a stronger
version of Theorem 13.1.
We need the following “Paley–Wiener type” result in complex variables.
Lemma 13.4. Let f(z) be a function analytic in the horizontal strip on the
complex plane where the imaginary part of z has absolute value ≤ a, and let 
Then the tail of the (ordinary) Fourier transform has the decay
where Cb = c(f; b) is a positive constant independent of z ∈ C.
For a proof, we refer the reader to Reed and Simon, Methods of Modern
Mathematical Physics, Vol. 2, Theorem IX.14.
For illustration, consider the function f(z) = e−z4, which is analytic on the
whole complex plane. (We picked this function, because, unlike the case of e−z2,
for f(z) = e−z4 we do not know the explicit form of the (ordinary) Fourier
transform.) 
With 
z 
= 
x 
+ 
iy 
the 
function 
and so

for every a > 0. Since (13.33) holds for arbitrarily large a, it follows that | (z)|
tends to zero exponentially fast as |z| → ∞ on the complex plane. (In fact, we
may call it superexponentially fast since a is arbitrarily large.) The ordinary
Fourier transform is just an intermediate step; what we are really interested in is
the 
3-dimensional 
“isotropic Fourier 
transform” (see Lemma 
13.2) 
of the probability density function g(u) defined in [0, ∞) (noting that on the
right-hand side of (13.34) g is extended over the whole real line as an even
function g(−u) = g(u)).
If g(y) is continuous at y = 0 and g(0) = 0, then (13.34) simplifies to
Suppose that g also satisfies the condition of Lemma 13.4 with some a > 0; then
by 
Lemma 
13.4 
for 
every 
0 
< 
b 
< 
a, 
which implies
Consider now the following class of even functions g(y) with g(0) = 0. The
class consists of
Notice that (13.36) is an “exponential decay class”. Indeed, the application of
Lemma 13.4 for f(z) = e−z4 above can be repeated for every member g(y) of the
class (13.36). Thus we obtain that the ordinary Fourier transform |ĝ(z)| tends to
zero exponentially fast as |z| → ∞ on the complex plane. Combining this fact
with (13.35), we conclude that for every member g(y) of the class (13.36), the

“isotropic Fourier transform”
also tends to zero exponentially fast as w → ∞.
Theorem 13.2. Assume R satisfies (13.4)–(13.6), G satisfies the “exponential
decay” condition 
for the 3-dimensional “isotropic Fourier transforms” Fgk, and
Then
Next we switch from the case of “exponential decay” to the case of
generalized Gaussian case, i.e., we assume that G exhibits “superexponential
decay”. The advantage of the next result over Theorem 4.2 is that here the
particles may move with varying speeds on their own torus lines.
Theorem 
13.3. 
Assume 
R 
satisfies 
(13.4)–(13.6), 
G 
satisfies 
the
“superexponential decay” condition 
for the 3-dimensional “isotropic Fourier transforms” Fgk, and
Then

Next we switch from the “superexponential decay” to “vanishing”, which
implies instant conf-space equilibrium; for the details, see Sec. 25.
The Class of Vanishing Property. The probability density function g(y)
(defined on 0 ≤ y ≤ ∞) satisfies the “vanishing property” if there exists a constant
C > 0 such that the “isotropic Fourier transform” Fg(w) is zero for w > C. In
view of Lemma 13.2, it suffices to guarantee that g(y) is even, g(y) is continuous
at y = 0 with g(0) = 0, and ĝ(x) = 0 for x > C.
We explain now how to construct such a probability density functions g(y);
see (13.49). The first step is to introduce the so-called “roof function”
The roof function f2(y) is familiar from probability theory: it is the density
function of the convolution (denoted as usual by ∗) of the uniform distribution
in [−1, 1] with itself; formally, 
where
is the probability density function of the uniform distribution in [−1, 1].
It is a standard exercise in probability theory to compute the higher
convolution powers of the uniform distribution in [−1, 1]. For example, a routine
calculation gives 
and

In general, let κ ≥ 2 be an arbitrary integer, and consider the κth convolution
power of f1:
It is not very hard to prove by induction on κ the following generalization of
(13.37) 
and 
(13.39)–(13.40) 
(see 
e.g. 
Rényi’s 
book 
[Re62]): 
and 0 if |y| > κ. Note that fκ(y) is (κ − 2)-times differentiable, and consists of a
few generalized parabola arcs of degree κ − 2 (due to the jumps of the lower
integral part function (κ + y)/2  as y runs in 0 ≤ y ≤ κ) that smoothly fit together
at the endpoints if κ ≥ 3.
We need the Fourier transform of f1:
We use the well-known fact that the Fourier transform of a convolution is the
product of the Fourier transforms; formally,
By (13.43) and (13.44) we have
Write
Then by (13.45) and (13.46),

and so 
(y) = 0 for all |y| ≥ κ + 1.
If κ ≥ 2 is an even integer, then gκ(u) ≥ 0, so cκgκ(u) defines a probability
density function in 0 ≤ u < ∞ with the constant factor cκ satisfying 
Let κ = 4; then by (13.40) we have
Combining these facts we obtain that
defines a probability density function in 0 ≤ u < such that ĝ(y) = 0 for all |y| ≥ 5,
g(y) is continuous at y = 0 with g(0) = 0, and g(y) is even.
It easily follows from (13.49) that
that is, the first two moments of the corresponding random variable are both
finite. (The reason why we did not choose κ = 2 is that the corresponding
expected value 
 uc2g2(u) du is infinite!) By choosing κ = 4 in (13.49), the first
two moments of the corresponding random variable are finite (see (13.50)), but
the third moment is infinite. By choosing a larger even number κ (i.e., g(u) =
cκgκ(u)) we can guarantee that many more higher moments are finite. In fact, the
first κ − 2 moments of the corresponding random variable are finite.
Theorem 13.4. Assume R satisfies (13.4)–(13.6), G satisfies the “vanishing
property”
for the 3-dimensional “isotropic Fourier transforms” Fgk, and

Then
For the proofs of Theorems 13.1–13.4; see Secs. 27–29.
14. Extensions of Theorem 4.2 to Nonlinear Curves on
the Plane
In Theorems 4.2 and 13.1–13.4 all particles stay on torus lines, and the only
difference is whether the particles move with constant speeds or with varying
speeds. This raises the natural question: does there exist a generalization where
the orbits of the particles are arbitrary non-linear space curves (like in Theorem
10.1)?
The bad news is that we do not know how to extend Theorem 4.2 to the case
of arbitrary space curves in the 3-space (or in higher dimensions), i.e., we do not
know when the particle space (= “gas container”) has dimension ≥3. The good
news is that in the 2-dimensional case we can prove some positive results. If the
particle space is the 2-dimensional unit torus [0, 1)2, then the curve of the whole
system 
in 
the 
configuration 
space 
has 
the 
form 
where t is the time,
is the vector (= point in the configuration space) formed from the set
of the initial point configuration at the start t = 0, ϑk ∈ SO(2) are 2-dimensional
rotations (i.e., we could also write ϑk ∈ [0, 2π)), and finally 
represents a family of parametrized curves on the plane. Notice that the one-
dimensional rk(t) in (13.3) is replaced by the 2-dimensional rk(t) in (14.3); we

indicate this dimension increase by putting an arrow on the top of R.
(We also need to specify a family of probability density functions G = (g1, g2,
. . . , gN), where gk is the distribution of the “magnification factor” ρk by the
integral Pr[ρk ≤ u] = 
 gk(y) dy; see (14.7) later.) Here we briefly interrupt the
discussion 
to 
point 
out 
a 
basic 
geometric 
difference 
between
magnifying/shrinking a straight line and a general nonlinear curve from one of
its own points. If we magnify/shrink a straight line from a point contained by the
line, then the image of the line is the same line (as a set of points), but the image
of a non-linear curve is a different (but similar) curve (as a set of points).
We assume that
where 1 + κ > α > 0, α0 ≥ 1, κ ≥ 0, and r′k(x) is the derivative of the parametrized
curve rk(x).
Moreover, let C(c; ) denote an arbitrary circle centered at c ∈ R2 with radius
, and assume that 
uniformly for all T ≥ β0 (note that 1 + κ > α > 0, α0 ≥ 1, κ ≥ 0, κ0, β0 ≥ 1 and 0 ≤
β < 1 are absolute constants).
Since (14.1) is a curve in the 2N-dimensional unit torus (= configuration
space), here we work with d = 2N instead of the usual d = 3N.
We need to specify a family of probability density functions G = (g1, g2, . . . ,
gN), where gk is the distribution of the “magnification factor” ρk, i.e., Pr[ρk ≤ u] =
 gk(y) dy. For simplicity consider first the simplest 2-dimensional Gaussian
distribution, i.e., 
We indicate condition (14.7) by replacing G with “Gauss”.
To formulate a curve analog of Lemma 9.2, we choose a Lebesgue square-
integrable test function f ∈ L2(Id) in the d-dimensional unit torus Id = [0, 1)d (i.e.,

we extend f over the whole d-space Rd periodically), and consider the Fourier
expansion of f: 
where
and of course v · w denotes the dot product.
If f is real-valued, the Fourier coefficients corresponding to the pair n, −n of
indices are complex conjugates of each other.
Write
Clearly
where we used Parseval’s formula.
Consider the integral
We study the (2-dimensional) Gaussian average of the square of the absolute
value of
which goes as follows:
where dϑ refers to the normed measure on SO(2) = [0, 2π), i.e., length/(2π).
Using the trivial fact

in (14.9), we have
where, as usual,  = x − iy denotes the complex conjugate of a complex number z
= x + iy.
Applying (14.11) in (14.10), we obtain
For n = (n1, n2, . . . , nd), d = 2N, let n(k) = (n2k−1, n2k) denote the kth block of
consecutive pairs of the coordinates (1 ≤ k ≤ N = d/2). Since 
we have

Given t1 and t2, write
where e1, e2 are 2-dimensional unit vectors. Thus we have rk(t1) = rk(t1)e1 and
rk(t2) = rk(t2)e2, where rk(t1) = |rk(t1)| and rk(t2) = |rk(t2)|. Let θk;t1→t2 ∈ SO(2)
denote the rotation of the plane that maps e1 to e2, i.e., e2 = θk;t1→t2 e1.
Since the dot product is rotation invariant, by using e2 = θk;t1→t2e1, we have 
where θk;t2→t1 ∈ SO(2) denotes the inverse of θk;t1→t2 ∈ SO(2). We emphasize the
key step in (14.14): 
which follows from the fact that SO(2) is commutative. This step breaks down in
higher dimension, since SO(h) is not commutative for h ≥ 3.
Using (14.14) in (14.13), we have

where e is an arbitrary but fixed 2-dimensional unit vector, and in the last step
we used the 2-dimensional special case of Lemma 9.1.
Combining (14.12)–(14.15), we obtain the following lemma.
Lemma 14.1. For 2-dimensional curves
we have
Lemma 14.1 is a curve analog of Lemma 9.2 in the 2-dimensional case. We
do not know how to generalize Lemma 14.1 in higher dimensions.
By using Lemma 14.1 we can prove the following 2-dimensional curve
version of Theorem 4.2.
Theorem 14.1. Let f ∈ L2(Id) be a test function, where Id = [0, 1)d with d = 2N.
Under 
the 
condition 
of 
(14.4)–(14.6) 
for 
2-dimensional 
curves 
and also assuming (14.7) and exp(π2U2α/2) ≥ 10UN, for W > U ≥ max{α0, β0, 1}

we have 
with k = log2(W/U)  (upper integral part).
For the proof of Theorem 14.1; see Secs. 30–31.
Next we switch from the 2-dimensional Gaussian distribution (14.7) to the
general 2-dimensional case of probability density functions G = (g1, g2, . . . , gN);
here gk defines the distribution of the “magnification factor” ρk by the integral
Pr[ρk ≤ u] = 
 gk(y) dy.
We need the 2-dimensional “isotropic Fourier transform” of g = gk, 1 ≤ k ≤
N; 
it 
is 
the 
perfect 
analog 
of 
(13.13): 
where w is an arbitrary 2-dimensional vector, S1 is the unit circle of
circumference 2, and ∫v∈S1 . . . dv stands for the arclength. Fg(w) defines a real-
valued function depending only on the length w = |w| of the input vector, and we
have 
By the Riemann–Lebesgue theorem Fg(w) → 0 as w → ∞.
The 2-dimensional case of Lemma 9.1 states that the 2-dimensional
“isotropic Fourier transform” of g(u) = ue−u2/2 is Fg(w) = e−w2/2. This explicit
formula was the key step in the proof of (14.15), and Theorem 14.1 is based on
(14.15) via Lemma 14.1. Besides g(u) = ue−u2/2 there are many more “Gaussian
type” probability density functions in 0 ≤ u < ∞ for which the 2-dimensional
“isotropic Fourier transform” has a similar explicit form of superexponential
decay. For illustration, consider the probability density function g3(u) = u3e−u2/2,
0 ≤ u < ∞. To determine the 2-dimensional “isotropic Fourier transform” of g3,
we 
basically 
repeat 
the 
proof 
of 
Lemma 
9.1. 
We 
have 

where the vector ρe = v = (v1, v2) has 2-dimensional standard normal (=
Gaussian) distribution, and we used the well-known fact that the coordinates v1,
v2 of v are independent random variables having standard normal distribution
each. Note that 
Moreover,
Combining (14.17)–(14.19), we have
Similarly, we can replace the function u3e−u2/2 with any probability density
function of the form 
Of course we need g(u) ≥ 0, which can be guaranteed e.g. if all coefficients ci are

nonnegative. The cases in (14.21) are basically the same in the sense that they all
have an explicit 2-dimensional “isotropic Fourier transform” (where the factor (1
− |w|2/2) in (14.20) is replaced by another polynomial of |w|2), exhibiting
superexponentially fast asymptotic decay.
Write
So Fg(sup)(w) is a monotone decreasing positive function tending to 0 as w → ∞.
Next we switch from the superexponentially fast decay of Fg(sup)(w), w → ∞
in the class (14.21) to the class of much slower polynomial decay.
Condition of polynomial decay. Assume that there exist real numbers γ > 2 and
γ0 ≥ 1 such that
(We need the condition γ > 2 to avoid a “divergence problem” later in the proof
of Theorem 14.2; see below.)
We now face the following problem: under what condition about the
probability density function g can we guarantee that its 2-dimensional “isotropic
Fourier transform” Fg satisfies the polynomial decay condition (14.23)? The
following lemma provides a sufficient condition. It is some sort of analog of
Lemma 13.1.
Lemma 14.2. Let g(u) be a probability density function in [0, ∞) such that g(m)
(0) = 0 for some integer m ≥ 2 (where g(m) is the mth derivative of g). We extend
g over the whole real line as an even function: g(−u) = g(u). Let ℓ ≥ 2, assume
that g(u), −∞ < u < ∞ is ℓ-times continuously differentiable, also assume that for
every integer 1 ≤ j ≤ ℓ, the j-th derivative g(j)(u) → 0 as u → ∞, and finally
assume 
Then the 2-dimensional “isotropic Fourier transform” of g has the upper bound
with some explicit constant γ0, where

Remarks. The condition γ > 2 in (14.23) is easily satisfied; for example, let m ≥
2 and ℓ ≥ 5.
Notice that
so, if both m and ℓ are large, then γ = γ(m; ℓ) is also large.
Proof of Lemma 14.2. The unit circle is formally defined as the set S1 = {u ∈
R2 : |u| = 1}. Let v ∈ S1 be an arbitrary but fixed 2-dimensional unit vector, let
−1 ≤ β < γ ≤ 1 be reals, and consider the subset 
of the unit circle. The arclength of S1(v; β, γ) is independent of the choice of the
unit vector v, so, we can simply write ArcLength(S1(β, γ)). We have the
elementary result 
The proof of (14.24) is based on the facts that
and
Using (14.24) in (14.16), we have
Similarly to Sec. 13 (see Lemma 13.1), we extend the probability density
function g(u), 0 ≤ u < ∞ over the whole real line as an even function: g(−u) =
g(u). Using the extended even function g(u), −∞ < u < ∞ in (14.25), we have 

since the Fourier transform ĝ of g is also even.
For every fixed 0 < c < 1, the binomial series
is absolutely convergent in the interval 0 ≤ x ≤ c. Note that
By using (14.27) and (14.28), we have
since ĝ is an even function.
Applying the substitution y = xw, we have

assuming the infinite integrals are convergent. We recall the well-known general
fact from Fourier analysis
where g(j)(u) denotes the jth derivative of g(u). (Notice that (14.19) is a special
case of (14.31) with k = 1.) Using (14.31) in (14.30), we obtain the upper bound 
Moreover, we have the trivial upper bound
We recall that the probability density function g(u), u ∈ [0, ∞) is extended over
the whole real line as an even function: g(−u) = g(u). Let ℓ ≥ 2, assume that g(u),
−∞ < u < ∞ is ℓ-times continuously differentiable, also assume that for every
integer 1 ≤ j ≤ ℓ, the jth derivative g(j)(u) → 0 as u → ∞, and finally assume 
Then by (13.16)
If ℓ ≥ 2k + 2, then by (14.34)
Assume that g(m)(0) = 0, that is, g has the form
Using (14.35) and (14.36) in (14.32), for 0 ≤ k ≤ min{m/2, (ℓ − 2)/2} we have

Combining (14.26), (14.29) and (14.37), we obtain
where in the last line we used (14.33) and (14.34).
Let n0 = min{m/2, (ℓ − 2)/2}; then we can rewrite (14.38) as follows:
We choose the value of c ∈ (0, 1) in such a way that
Using (14.40) in (14.39), we have
if w is larger than some explicit constant γ0. By definition 2n0 + 2 = min{m + 2,
ℓ}, 
so 
we 
can 
rewrite 
(14.41) 
in 
the 
form 
where

This completes the proof of Lemma 14.2.
We conclude Sec. 14 with formulating an analog of Theorem 14.1, where the
Gaussian superexponential decay is replaced by the polynomial decay (14.23).
Theorem 14.2. Let f ∈ L2(Id) be a test function, where Id = [0, 1)d with d = 2N.
Under 
the 
condition 
of 
(14.4)–(14.6) 
for 
2-dimensional 
curves 
and also assuming the polynomial decay condition (14.23), for
we have
For the proof of Theorem 14.2; see Sec. 32.
In Chap. 3 we show more applications of our “sort-time ergodic theorems”.
To make it as simple and as transparent as possible, we just apply the simplest
such result, Theorem 4.2, and explain the general case later in Sec. 24

Chapter 3
More Applications of Theorem 4.2
15. Snapshot Randomness (II): Central Limit Theorem
In Sec. 8 we discussed the Poisson partition test. Here we continue Sec. 8 by
replacing the Poisson limit law with the central limit theorem.
CLT partition test. Bob makes a partition [0, 1]3 = H1 ∪ H2 ∪ . . . ∪ Hn of the
unit cube with n = 
 parts (for simplicity assume that N is a complete square),
where each Hi is measurable and vol(Hi) = 1/n. (We choose n = 
 for
simplicity; any other choice n = 
 with 0 < c < 1 would be fine.) Let hi = hi
(Z) denote the number of points of a given N-set 
(representing Bob’s N-set) that are in Hi, and consider the n real numbers 
We compare the empirical distribution function of the set (15.1) to the standard
normal distribution:
Since n−1/2 is the “random error”, if the error in (15.2) satisfies the upper bound
then we say that the N-set Z is -close to exhibiting maximum snapshot
randomness with respect to the CLT-partition test H = {H1, . . . , Hn}.

Note that Alice’s honest random N-set certainly satisfies (15.3) with
probability extremely close to one. Since the two sisters (Alice and Wicky) do
not know Bob’s partition H, and the error term (15.3) is nearly optimal, if Bob’s
N-set Z happens to satisfy (15.3), then Bob has every reason to believe that his
N-set is “truly random”. For example, if N = 10100 and ε = 4 · 10−2 (say), then 
is a very small error. Such a very small error indicates “complete CLT snapshot
randomness”.
For the sake of brief notation, write
for the standard normal distribution.
For the usual application of Theorem 4.2, we need information about the
volume of the subset
in the configuration space Id = [0, 1)d, d = 3N, where β > 0 is arbitrary. Our goal
is to prove the upper bound (5.15); see below.
We need to estimate the d-dimensional volume
Like in Sec. 8, the d-dimensional volume in (15.6) is exactly the analog
probability about the distribution of Alice’s honestly constructed random N-
element point set in Bob’s 
-partition of the unit cube. And again (15.6) can be
expressed in terms of a large deviation type probability for dependent random
variables (see (15.20) below).
We reduce (15.6) to a problem of the N-balls-to-N -bins setup introduced in
Sec. 8, and a key step in the argument is again an application of the simple
Lemma 8.1. In order to do that, we divide every set Hi of volume 1/n into n
measurable parts Hi,j, 1 ≤ j ≤ n such that vol(Hi,j) = n−2 = 1/N. We rename the
sets: let B(i−1)n+j = Hi,j, and let bl = bl(Z) denote the number of points of the

given 
N-set 
Z 
that 
are 
contained 
in 
Bl. 
So 
Since there are N sets B(i−1)n+j (1 ≤ i, j ≤ n = 
) of the same volume 1/N, we
can use what we know about the N-balls-to-N-bins problem. We place N balls
independently and uniformly into N bins. Again let Yl denote the number of balls
in the lth bin Bl. (This represents the number of elements of the N-set Z in Hi,j
where l = (i − 1)n + j.) Again we make use of the auxiliary random variables Wl,
1 ≤ l ≤ N that are independent. Let Wl, 1 ≤ l ≤ N be independent random
variables, all having Poisson distribution with parameter one, i.e., Pr[Wl = k] =
(k!e)−1, k = 0, 1, 2, 3, . . ..
For later applications we need information about the first three moments of
the 
Poisson 
distribution. 
We 
have 
and
Combining (15.8) and (15.9), we obtain the variance
Let Y(i) = Y(i−1)n+1 + · · · + Yin denote the number of balls in the union of the
n bins Bl, (i − 1)n + 1 ≤ l ≤ in. For every 1 ≤ i ≤ n, write W(i) = W(i−1)n+1 + · · · +
Win; it is a sum of n independent, identically distributed random variables with
Poisson distribution of parameter one. For every −∞ < λ < ∞ write 
(Note that p(λ) is independent of the value of i.) We need a quantitative form of

the central limit theorem with an explicit error term. We formulate a slightly
more general result where the random components are not necessarily identically
distributed (the proof is almost the same; see e.g. in Feller’s well-known book
[F71]).
Central Limit Theorem: Berry–Esseen version. Let Z1, . . . , Zn be
independent random variables with zero expectation EZi = 0, and finite first
three moments EZ2i < ∞, E|Zi|3 < ∞, 1 ≤ i ≤ n, and write 
Then for every real λ
where N(λ) is the standard normal distribution, see (15.4).
By (15.8)–(15.13),
By repeating the proof of Lemma 8.2, we show that for β > 6
To prove (15.15), first we introduce some notation: for every 1 ≤ i ≤ n, let
Y∗(i; λ) = 1 or 0 depending on whether 
and similarly, for every 1 ≤ i ≤ n, let W∗(i; λ) = 1 or 0 depending on whether 
Let
where W∗(λ) is a sum of n 0, 1 valued independent Bernoulli variables with p =
p(λ).
By using (15.14) and Lemma 8.1, for every λ and γ > 0,

Since W∗(λ) = ∑ni=1 W∗(i; λ) is a sum of n 0, 1 valued independent Bernoulli
variables 
with 
p 
= 
p(λ), 
by 
Bernstein’s 
inequality 
(12.9) 
where we used the trivial fact p(1 − p) ≤ 1/4.
Moreover, by (8.8)
Combining (15.16)–(15.18),
We recall (15.5)–(15.6)

Combining (15.19) and (15.20), (15.15) follows.
Applying Theorem 4.2 as a short-time ergodic theorem in the configuration
space (in fact, it works as a “large deviation theorem”). Like in Sec. 8, let Yω;t,
ω ∈ ΩGauss denote the 3-dimensional Gaussian torus-billiard model, where the
initial configuration is Y ⊂ I 3 = [0, 1)3. Let H = {H1, . . ., Hn} be an arbitrary
but fixed CLT-partition (n = 
). Assume that N is large; is it true that the
overwhelming majority of the time evolutions of this system reaches “complete
CLT snapshot randomness” superexponentially fast, and stays in this state for an
incredibly long time (with the possible exception of a totally negligible set of
t’s)? By using Theorem 4.2 we give a positive answer. Again we basically repeat
the argument of Sec. 5, or what is the same, the argument in Sec. 8. The only
(trivial) novelty is that the new parameter λ runs through a finite set of values (to
be specified below).
The family of time evolutions Yω;t, ω ∈ ΩGauss of this Gaussian torusbilliard
model is represented by the family of torus lines 
 in the configuration space Id
= [0, 1)d with d = 3N, all starting from the same point 
.
Since the torus Id is translation invariant, we can apply Theorem 4.2 with f =
χS where S is the translated copy 
of S(λ) = S(Errorλ ≥ βN−1/2) in the torus Id. Thus, we obtain the following analog
of (8.17): if U ≥ 1 and eπ2U2/2 > 3Ud then for every integer j ≥ 1, 
To illustrate the power of (15.15) and (15.22), we choose the numerical
values β = 36, U = 8, j = 340 and N = 10100 ; it follows that d = 3 · 10100. Then
by 
(15.15) 
and 
(15.22), 
for 
every 
λ, 

Let ΩGauss(λ; bad) be the set of those ω ∈ ΩGauss for which
Repeating the proof in (12.18)–(12.19), we obtain
So far λ was an unspecified parameter: an arbitrary but fixed real number. In the
application λ runs through the members of the following discrete sequence. For
every integer 1 ≤ l ≤ log n and every integer m with 0 ≤ m ≤ 20
/l2 let 
There are (at most)
numbers λl,m and λ−l,−m defined in (15.26). Arrange the numbers λl,m and λ−l,−m
defined 
in 
(15.26) 
in 
increasing 
order, 
including 
±∞: 
where M ≤ 80
 (see (15.27)). It follows from (15.26) and (15.4) that 
Now we return to (15.24) and (15.25). Let
and
It follows that for every ω ∈ ΩGauss(good)
By (15.31) we have that for every ω ∈ ΩGauss(good)
since n = 
 = 1050.
Moreover, by (15.25) and (15.27),

We recall (15.5) (and the choice β = 36)
where hi(Z) denotes the number of points of the given N-set 
(representing Bob’s N-set) that are in Hi (where Hi ∈ H is a member of the given
CLT-partition [0, 1]3 = H1 ∪ H2 ∪ . . . ∪ Hn).
By using (15.34), we can rewrite (15.32) as follows: for every ω ∈
ΩGauss(good)
Let λj < λ < λj+1; then clearly
where in the last step we used (15.29). Similarly,
Using (15.36)–(15.37) in (15.35), we obtain that for every ω ∈ ΩGauss(good)

Again we study the classical Bernoulli gas model where the gas molecules
are represented by N = 10100 point billiards. Unfolding reduces the billiards-in-a-
box model to the torus-billiard model. The threshold U = 8 represents — roughly
speaking — the necessary number of “jumps” per particle in the Gaussian torus-
billiard model (which is the half of the number of bounces in the analog
billiards-in-a-box model) to reach “complete CLT snapshot randomness”. As
usual, assume that the gas molecules have average speed 103 meter per second.
For this system it takes only a few milliseconds to reach “complete CLT
snapshot randomness”. Now (15.33) and (15.38) have the following
interpretation. Choosing an arbitrary (measurable) CLT partition H = {H1, H2, . .
. , Hn} of the unit cube [0, 1]3 = H1 ∪ H2 ∪ . . . ∪ Hn such that vol(Hi) = 1/n, 1
≤ i ≤ n = 
 = 1050 and an arbitrary N = 10100-element initial point
configuration Y ⊂ [0, 1)3, for the totally overwhelming majority of the initial
velocities (Gaussian distribution), the normalized distribution of the particles in
the partition H remains very close to the standard normal distribution for an
extremely long time, with the possible exception of a totally negligible set of
times t.
Indeed, for every CLT partition H = {H1, H2, . . . , Hn} and every N = 10100-
element initial point configuration Y, there exists a subset ΩGauss(good) with 
(see (15.33)), representing a totally overwhelming majority, such that for every
ω ∈ ΩGauss(good), 
holds for every 8 ≤ t ≤ 2343 with the possible exception of a set of times t of total
length < 10−193, see (15.38). The latter actually represents less than 10−196
seconds, which is a ridiculously short time.
Note that 8 ≤ t ≤ 2343 represents a time interval of length about 1097 seconds,
which is a ridiculously long time (the estimated age of the universe, starting

from Big Bang, is less than 1020 seconds).
Summarizing, the typical time evolution of this system reaches “complete
CLT snapshot randomness” (see (15.39); noting that N(λ) denotes the left tail
probability of the standard normal distribution, see (15.4)) in a few milliseconds
(even starting from Big Bang!), and then it remains in the state of “complete
CLT snapshot randomness” for an incredibly long time (with the possible
exception of a totally negligible set of t’s).
The approximation of the famous bell-shaped curve — standard normal
distribution — with error term 3.7 · 10−24 in (15.39) represents a striking, and
nearly optimal, precision (here 10−25 = n−1/2 = N −1/4 is the inevitable “random
error”). This is why we may say that the system is completely random.
Another illustration. We conclude this section with another choice of the key
parameters; this example will be used later in Sec. 17. In the crucial inequalities
(15.15) and (15.22) we choose β = 6 + log N, 
, j = 10 log2 N with N ≥
1020 (of course d = 3N). Then by (15.15) and (15.22), for every λ, 
where
noting that n = 
.
Let ΩGauss(λ; bad) be the set of those ω ∈ ΩGauss for which
Repeating the proof in (12.17)–(12.18), we obtain

Again λ runs through the members of the sequence defined in (15.26). Repeating
the argument between (15.27) and (15.37), we obtain the following analogue of
(15.33) 
and 
(15.38): 
for 
every 
ω 
∈ 
ΩGauss(good) 
where
Again we study the classical Bernoulli gas model where the gas molecules
are represented by N ≥ 1020 point billiards, and we employ unfolding to reduce
the billiards-in-a-box model to the torus-billiard model. The threshold 
represents — roughly speaking — the necessary number of “jumps” per particle
in the Gaussian torus-billiard model (which is the half of the number of bounces
in the analog billiards-in-a-box model) to reach “complete CLT snapshot
randomness”. As usual, assume that the gas molecules have average speed 103
meter per second. In view of the threshold U = 
, this Gaussian system
reaches “complete CLT snapshot randomness” superexponentially fast. Now
(15.44) and (15.45) have the following interpretation. For every CLT partition H
= {H1, H2, . . . , Hn} and every N-element initial point configuration Y, there
exists a subset ΩGauss(good) with 
(see (15.45)), representing an overwhelming majority, such that for every ω ∈
ΩGauss(good), 
holds for every t in the time interval 
 ≤ t ≤ 
N10 with the possible
exception of a set of times t of total length < N −23, see (15.44). The latter
represents less than 10−3N−23 seconds, which is an extremely short time. Notice
that 
 ≤ t ≤ 
N10 is an extremely long time interval.
The approximation of the standard normal distribution with error term

in (15.46) represents a nearly optimal precision. Indeed, n−1/2 = N−1/4 is the
inevitable “random error”.
16. Snapshot Randomness (III) Case of Closed Orbits
Red-Blue-CLT test. In Sec. 8 and 15 we studied two aspects — Poisson and
CLT — of nearly complete snapshot randomness of Gaussian (at least 2-
dimensional) box/torus billiard systems. What about the snapshot randomness of
the very different Gaussian closed orbit systems introduced in Secs. 6 and 7?
Here we show how the CLT partition test can be adapted for these closed orbit
systems. Since this case is substantially harder, for the sake of simplicity, we just
consider the spherical GreatCircleDiameter model, for which the underlying
measure is the (normalized) surface area.
First we point out a trivial difference between the (at least two dimensional)
box/torus (billiard) models and the spherical models: for the spherical models
CLT time-lapse randomness fails, unless there is some extra condition. Indeed,
assume that all N particles start from the North Pole (0, 0, 1) of the unit sphere
S2 (“spherical Big Bang”), and the CLT partition H = {H1, . . . , Hn}, n = 
 is
defined in terms of the great circles passing through the two poles (0, 0, ±1) as
follows: assume that for every i consists of two great circles passing through (0,
0, ±1). the boundary of Hi Then, for every choice of the initial velocities, the
number of particles in Hi is a time-independent constant, which is the complete
opposite of the fluctuation described by the central limit theorem.
To avoid this kind of trivial nuisance, we choose test sets that cannot contain
a whole great circle. For example, if the test set is in the (open) upper
hemisphere 
then of course the test set cannot contain more than half of a great circle. Here
we focus on CLT snapshot randomness instead of time-lapse randomness;
nevertheless, roughly speaking, “we stay in the upper hemisphere” in the sense
that we distinguish between the two hemispheres in such a way that a particle is
considered positive or negative depending on whether it is in the upper or lower
hemisphere. What we study here is the distribution of the ±-discrepancy, or
equivalently, the red-blue–discrepancy. This way the surface area cancels out —
to be explained below.
The definition of the Gaussian ±GreatCircleDiameter model is almost the

same as that of the ordinary GreatCircleDiameter model. Again let 
be an arbitrary N-element point set on the unit sphere — it represents the initial
configuration. As usual, yk ∈ Y is the starting point of the kth particle. Again for
every point yk, 1 ≤ k ≤ N we choose a great circle in S2 passing through yk by
choosing an angle αk with uniform distribution in the interval [0, 2π). The kth
particle moves on this great circle in such a way that its projection on the (yk,
−yk)-diameter has constant speed uk (positive or negative; −y is the antipodal
point of y). We refer to this constant speed as the projection-speed. Again we
choose the projection-speed uk of the kth particle by the one-dimensional normal
distribution, that is, the density function of the distribution of the projection-
speed u = uk is (2π)−1/2e−u /2. The pair (αk, uk) of the angle and the projection-
speed determine the initial velocity of the kth particle. Finally, we choose the
initial velocites in such a way that αk, uk, 1 ≤ k ≤ N are 2N independent random
variables. This means that the ±GreatCircleDiameter system (±GCD system, in
short) of the first kind has the following initial velocity space and product
measure: 
The first novelty is that a particle is considered positive or negative
depending on whether it is in the upper or lower hemisphere. This leads to the
“red-blue Alice–Wicky–Bob game”, where red represents 1 and blue represents
−1. In the “red-blue Alice–Wicky–Bob game” both sisters have a 2-colored (red
and blue) N-element point set in the upper hemisphere S2(+). Again Alice’s 2-
colored N-set is “truly random” with Pr[red] = Pr[blue] = 1/2, and again Wicky
claims that her 2-colored N-set is also “truly random”, but, because she is a liar,
nobody knows what Wicky actually did. Again we open the door between the
two sisters: Alice and Wicky put their 2-colored N-sets into a black box, and we
give the black box to Bob, who pulls out one of the two 2-colored N-sets (despite
being superman, he does not know which one is due to Alice and which one is
due to Wicky). Bob has to decide whether the 2-colored N-set he picked is “truly
random” or not. He can perform one test (say).
The Red-Blue-CLT test in this spherical system means that Bob makes a
partition S2(+) = H1∪H2∪. . .∪Hn of the upper hemisphere with n = 
 parts,
where each Hi is measurable and they have the same surface area SA∗(Hi) =

1/2n (SA∗ is the normalized surface area, and the sisters have zero information
about the partition).
Consider a 2-colored N-set in the upper hemisphere: it is represented by a
pair (Z; κ), where 
is the point set, and
is the 2-coloring. The pair (Z; κ) represents the 2-colored N-set picked by Bob.
Let ∆i = ∆i(H; Z; κ) denote the color discrepancy (or combinatorial discrepancy)
in Hi : 
Consider the n real numbers
We compare the empirical distribution function of the set (16.5) to the standard
normal distribution:
where, similarly to Sec. 15,
denotes the left tail probability of the standard normal distribution.
The “random error” is n−1/2. Unlike in Sec. 15, here we cannot prove the
sharp upper bound for the error. What we can prove is about the square root of
the conjectured optimal result: 
Nevertheless, if (16.8) holds, then we can still safely say that the 2-colored N-set
Z exhibits advanced snapshot randomness with respect to the Red-Blue-CLT
test H = {H1, . . . , Hn} in the upper hemisphere S2(+). It would be very
interesting to prove the optimal result by doubling the exponent in (16.8).
Let Yω;t denote the Gaussian ±GCD model with initial configuration 

and
is the vector of the angles of the orbits of the particles, and finally,
where uk denotes the projection-speed of the kth particle. If a particle is in the
lower hemisphere, then its antipodal point is in the upper hemisphere; we call the
antipodal a blue point, and it has weight −1. If a particle is in the upper
hemisphere, then of course it is a red point and it has weight 1. This way in
every time instant t the ±GCD model of the first kind Yω;t generates a 2-colored
N-set in the upper hemisphere. We refer to this 2-coloring as the North–South 2-
coloring κ0 = ±1: the point is red, meaning κ0 = 1, if the point is in the upper
hemishere (i.e., it is closer to the North Pole), and the point is blue, meaning κ0 =
−1, if the point is in the lower hemishere (i.e., it is closer to the South Pole).
Note that the Equator is a zero measure set, so its contribution is irrelevant.
Assume that N is large; is it true that the overwhelming majority of the time
evolutions of the system with the North-South 2-coloring κ0 = ±1 reaches
advanced Red-Blue-CLT snapshot randomness superexponentially fast, and then
it stays in that state for an extremely long time (with the possible exception of a
totally negligible set of t’s)? By using Theorem 4.2 and a critical volume
estimation (see Lemma 16.1 below), we give a positive answer to this question.
Like in Sec. 6, for every ω∗ ∈ [0, 2π)N, let GCk = GCk(ω∗) (1 ≤ k ≤ N)
denote the common orbit of the kth particles: it is a great circle containing the
antipodal points yk ∈ Y and −yk with angle αk. Since the projection of the motion
on the (yk, −yk)-diameter has constant speed, we replace the motion of the kth
particle on the great circle GCk = GCk(ω) with the constant speed motion in the
interval [0, 4) interpreted as a 1-dimensional torus (“projection”). Again we
divide by 4 in the sense that we replace the constant speed motion in the 1-
dimensional torus [0, 4) with the constant speed motion in the 1-dimensional
unit torus [0, 1). This means that, for every fixed ω∗ ∈ [0, 2π)N, the family of
time evolutions Yω;t, ω = (ω∗, u) ∈ ΩGauss(±GCD) of the ±GCD model of the
first kind with initial configuration Y ⊂ S2 is represented by the family of torus
lines in the configuration space IN = [0, 1)N, all starting from the origin 0 ∈ IN.

Let −H = {−H1, . . . , −Hn} be the antipodal extension of the partition H of
the (open) upper hemisphere S2(+) to the (open) lower hemisphere S2(−).
Formally, 
The great circle GCk = GCk(ω∗) (i.e., the orbit of the kth particle) intersects
the ith member Hi ⊂ S2(+) (and similarly −Hi ⊂ S2(−)) of the given partition H
(and similarly −H) in a 1-dimensional measurable set for almost every ω∗ ∈ [0,
2π)N — this is Fubini’s theorem. Consider the projection of the intersection
GCk(ω∗) ∩ Hi (and similarly GCk(ω∗) ∩ (−Hi)) on the double copy of the (yk,
−yk)-diameter, where the latter is represented as the interval [0, 4). Let Hk,i(+) =
Hk,i
(+)(ω∗) ⊂ [0, 4) (and similarly Hk,i
(−) = Hk,i
(−)(ω∗) ⊂ [0, 4)) denote this
projection, 
and 
again 
we 
apply 
the 
usual 
division 
by 
4: 
Write hk,i(ω∗) = length(Hk,i(±)(ω∗)) (1-dimensional Lebesgue measure). The
mean value of hk,i(ω∗), ω∗ ∈ [0, 2π)N is clearly equal to the normalized surface
area of Hi; formally, 
(dω∗ represents the N-dimensional Lebesgue measure).
Write
We apply Bernstein’s large deviation inequality (11.8) for the sequence Zk, where
0 ≤ Zk ≤ 1, EZk = SA(Hi) = n−1 /2 = N−1/2 /2, 1 ≤ k ≤ N ; thus (24.34) gives the
upper bound 
Estimating a critical volume in the configuration space. Let
be arbitrary but fixed. To apply Theorem 4.2, we need information about the

volume of the subset 
in the configuration space IN = [0, 1)N, where β > 0 is arbitrary. Our goal is to
prove the following lemma (unfortunately its proof is surprisingly long).
Lemma 16.1. Under the condition (16.14), for every β > 20
 and N = n2 ≥
1010, 
Proof of Lemma 16.1. Like in Sec. 8 (or Sec. 15), the N-dimensional volume 
can be expressed in terms of a large deviation type probability for dependent
random variables (see (16.17) below). This time we make use of a 2-colored N-
balls-to-2
-bins occupation number problem. We place N balls independently
into n = 
 red bins and n = 
 blue bins; another novelty is that the placement
is not necessarily uniform.
More precisely, we study the following particular occupancy problem. We
place the kth ball into the ith red bin (ith blue bin) with probability 
Let Zk = i if the kth ball is in the ith red bin, and let Zk = −i if the kth ball is in the
ith blue bin; we assume that Z1, . . . , ZN are N independent random variables. Let
Yi
(+) denote the number of balls in the ith red bin, and let Yi
(−) denote the number
of 
balls 
in 
the 
ith 
blue 
bin. 
Thus 
we 
have 
(see 
(16.15)) 
The estimation of (16.17) is a more difficult occupancy problem. Similarly to the
proof of Lemma 8.3 at the end of Sec. 8, we make use of martingales, and apply
the Azuma–Hoeffding inequality.
Let time t refer to the point at which the first t balls have been thrown. Let Ft
be the σ-algebra generated by the random choice of bins for the first t balls, i.e.,
the σ-algebra generated by the independent random variables Z1, . . . , Zt. For

every real γ let 
where (w)+ denotes the positive part of a real w, i.e., (w)+ = w if w > 0 and 0
otherwise. We refer to Xγ as the γ-sum.
Next let Ut = E(Xγ |Ft). The random variables U0, U1, . . . , UN form a
martingale with 
Notice that moving the kth ball from one bin to another can change the γ-sum by
at most one. This implies that |Ui+1 − Ui| ≤ 1 for 0 ≤ i < N. Applying the Azuma–
Hoeffding inequality with M = 1, for every α > 0
Motivated by (16.17), we define the empirical distribution function
By (16.18) and (16.20),
where in the last step we used integration by parts.
Next we focus on EXγ.
Lemma 16.2. Under the condition of (16.14), for N = n2 ≥ 1010, 
Proof of Lemma 16.2. For every 1 ≤ i ≤ n let
By (16.18), (16.22), and using the linearity of the expectation,
where in the last step we used integration by parts.

We study (16.23). For 1 ≤ i ≤ n, let Zk,i = ±1 if Zk = ±i and 0 otherwise; then 
is a sum of N independent 0, ±1 valued random variables with expectation
Applying the Berry–Esseen version of the Central Limit Theorem (15.13) for the
sum (16.24), we have
where
We recall (16.14)
Thus by (16.12) and (16.16),
By (16.26) and (16.28),
By (16.29),
assuming N ≥ 1010.
For every real number u, let τ1 = τ1 (u) and τ2 = τ2 (u) be defined as follows: 
Combining (16.22), (16.25), (16.30) and (16.31), for u < 0 we have

and similarly, for u < 0,
By (16.31), for u < 0,
which implies that,
assuming N ≥ 1010. Of course (16.34) remains true for u ≥ 0 as well.
Similarly,
Combining (16.32)–(16.35), we have for every real u,
which implies

assuming N ≥ 1010.
Moreover, by (16.24), (16.31), (16.33) and Bernstein’s inequality, for u < 0
and N ≥ 1010, 
Similarly, for u ≥ 0,
Furthermore, for u < 0 we clearly have
Combining (16.36)–(16.39), for every γ < 0 we have
and similarly, for every γ ≥ 0,
By (16.40) and (16.41),
Using (16.42) in (16.23), we obtain
which completes the proof of Lemma 16.2.
Let α > 200, then by (16.19), (16.21) and Lemma 16.2,

Let γj = j/n, where the numerator j runs over the integers in the interval −nN
= −n3 < j < nN = n3. Since the common denominator n is “large”, the sequence γj
is “very dense” in the relevant interval −N < γj < N.
Consider the following events: let
and 
for 
every 
integer 
j 
in 
−n3 
< 
j 
< 
n3, 
let 
where γj = j/n. We show that
Indeed, let
Assume 
first 
that 
∆(λ0) 
> 
N(λ0). 
Let 
, 
then 
In the interval λ0 ≤ u ≤ λ1 = λ0 + ε we can find γ′ = γj1 = j1/n and γ″ = γj2 = j2/n
such 
that 
γ″ 
− 
γ′ 
≥ 
 
ε, 
so 
by 
(16.47), 
By (16.48),
which proves (16.46) for ∆(λ0) > N(λ0). If ∆(λ0) < N(λ0), then we repeat the
argument with the interval λ0 − ε ≤ u ≤ λ0.
Combining (16.43)–(16.46), we have for every α > 200,

By (16.20) and (16.49), for β > 20
Combining (16.17) and (16.50), Lemma 16.1 follows.
Applying Theorem 4.2 as a short-time ergodic theorem in the configuration
space. We study the usual question: assume that N is large; is it true that the
overwhelming majority of the time evolutions of the system with the North-
South 2-coloring reaches advanced Red-Blue-CLT snapshot randomness
superexponentially fast, and then it stays in that state for an extremely long time
(with the possible exception of a totally negligible set of t’s)? Applying Theorem
4.2 and Lemma 16.1, we give a positive answer.
As usual, we take advantage of the fact that, for every fixed ω∗ ∈ [0, 2π)N,
the family of time evolutions Yω;t, ω = (ω∗, u) ∈ ΩGauss(±GCD) of the Gaussian
±GCD model with initial configuration Y ⊂ S2 is represented by the family of
torus lines in the configuration space IN = [0, 1)N, all starting from the origin 0 ∈
IN.
Let
be arbitrary but fixed. We apply Theorem 4.2 with f = χS where S is
Thus we obtain the following analog of (8.17) (or (15.22)): if U ≥ 1 and eπ2U2/2 >
3UN 
then 
for 
every 
integer 
j 
≥ 
1, 

where
and by Lemma 16.1,
holds for β > 20
 and N ≥ 1010.
To illustrate the power of (16.53)–(16.54), let U = 6, j = 340, N = 10200 and β
= 
60. 
Then 
by 
(16.53)–(16.54), 
for 
every 
ω∗ 
∉ 
BadSet, 
Let 
RN(bad; 
ω∗) 
be 
the 
set 
of 
those 
u 
∈ 
RN 
for 
which 
holds for ω = (ω∗, u). Repeating the proof of (11.17)–(11.18), we obtain
Again the threshold U = 6 represents — roughly speaking — the necessary
number of “rounds” per particle in the Gaussian ±GCD model to reach advanced
Red-Blue-CLT snapshot randomness (for the typical time evolution). As usual
assume that the average projection-speed is 103 meter per second. For this
system it takes only a few milliseconds to reach advanced snapshot randomness.
Now (16.13) and (16.56)–(16.57) have the following interpretation. Choosing an
arbitrary (measurable) CLT partition H = {H1, H2, . . . , Hn} of the upper
hemisphere S2(+) = H1 ∪ H2 ∪ . . . ∪ Hn such that SA(Hi) = 1/2n, 1 ≤ i ≤ n = 
 = 10100 and an arbitrary N = 10200-element initial point configuration Y ⊂
S2, for the totally overwhelming majority of the initial velocities (Gaussian
distribution), the normalized distribution of the signed particle counting number
(1 if the particle is in the upper hemisphere and −1 if the antipodal is in the upper

hemisphere) in the partition H remains very close to the standard normal
distribution for an extremely long time, with the possible exception of a totally
negligible set of times t.
Indeed, for every CLT partition H = {H1, H2, . . . , Hn} and every N = 10200-
element 
initial 
point 
configuration 
Y, 
there 
exists 
a 
subset 
with (see (16.13) and (16.57))
representing a totally overwhelming majority, such that for every ω ∈
Ω1(±GCD; good),
holds for every 6 ≤ t ≤ 2342 with the possible exception of a set of times t of total
length < 10−400, see (16.56). The latter actually represents less than 10−403
seconds, which is a ridiculously short time.
Note that 6 ≤ t ≤ 2342 represents a time interval of length about 1097 seconds,
which is a ridiculously long time. (The estimated age of the universe, starting
from Big Bang, is less than 1020 seconds.) Summarizing, the typical time
evolution of this Gaussian system reaches “advanced Red-Blue-CLT snapshot
randomness” (see (16.58)) in a few milliseconds (even starting from Big Bang!),
and then it remains in the state of “advanced randomness” for an incredibly long
time (with the possible exception of a totally negligible set of t’s).
The approximation of the standard normal distribution — see CLT in (16.58)
and (16.6)—with error ≤6 · 10−24 represents a striking precision, justifying the
term “advanced randomness”.
17. Time-Lapse Randomness vs. Snapshot Randomness
(I): A Fundamental Difference

We already studied snapshot randomness on a realistic time scale. The common
message of Secs. 8 and 15 can be summarized in a nutshell as follows. The
overwhelming majority of the time evolutions of a Gaussian system reaches
“complete snapshot randomness” superexponentially fast, and then it remains in
the state of “complete randomness” for an incredibly long time (with the
possible exception of a totally negligible set of times t). We talk about “complete
randomness” in the sense that the error term is (nearly) optimal.
For illustration, we recall the example at the end of Sec. 15; see “Another
illustration”. We emphasize that in CLT snapshot randomness we must work
with a partition that consists of a large number of parts. For a single test set, or
test function, CLT snapshot randomness does not make any sense. On the other
hand, as we demonstrate later, CLT time-lapse randomness is perfectly
meaningful for a single test set, or test function.
As usual, we consider the classical Bernoulli gas model where the gas
molecules are represented by N ≥ 1020 point billiards. By using unfolding we can
reduce the billiards-in-a-box model to the simplest torus-billiard model Yω;t; and
again we assume Gaussian initial velocity distribution. The threshold 
represents the necessary number of “jumps” per particle in the Gaussian torus
model (which is half of the number of bounces in the analog billiard model) to
reach “complete CLT snapshot randomness” — it is superexponentially fast. As
usual, we assume that the gas molecules have average speed 103 meter per
second. Equations (15.44) and (15.45) have the following interpretation. For
every CLT partition H = {H1, H2, . . . , Hn} with n = 
 and every N-element
initial point configuration Y, there exists a subset ΩGauss(good) with 
(see (15.45)), representing an overwhelming majority, such that for every ω ∈
ΩGauss(good), 
holds for every t in the extremely long time interval 
 ≤ t ≤ 
N10 with
the possible exception of a set of times t of total length < N−23, see (15.44). The
latter represents less than 10−3N−23 seconds, which is an extremely short time.
Since n−1/2 = N−1/4 is the inevitable “random error”, the approximation of the
standard normal distribution with error term 

in (17.2) is nearly optimal.
Similarly to snapshot randomness, our basic intuition for time-lapse
randomness goes as follows. We say that the time evolution of the system
exhibits “complete CLT time-lapse randomness” if the bell-shaped curve
(standard normal distribution) shows up with striking precision. We want
optimal, or nearly optimal, error term Nε−1/2 with some small ε > 0.
This leads to the following natural question. What happens if we switch from
snapshot randomness to time-lapse randomness? Is it true that the overwhelming
majority of the time evolutions of a Gaussian system reaches “complete CLT
time-lapse randomness” superexponentially fast?
We show that the answer to the question is no: we do not have an analogue
of (17.1)–(17.2) for time-lapse randomness. The overwhelmimg majority — like
in (17.1) — of the time evolutions of a system of the first kind reaches
“complete CLT time-lapse randomness” (like in (17.2)) very slowly. This fact
represents a fundamental difference between snapshot randomness and time-
lapse randomness.
To prove such a “slow approach” result, we need a simple but important
inequality; see (17.19) below.
For later application, we switch from the simplest torus-billiard model to the
general torus model. That is, similarly to Sec. 10, we assume that every particle
has its own type of trajectory described by a parametrized space curve: the
trajectory of the kth particle is rk(t) modulo one, where rk(0) = 0, 1 ≤ k ≤ N.
We of course assume that each parametrized space curve is continuous and
has arclength (rectifiable), but beyond that they are almost arbitrary (straight
line, bending line, twisted line, any kind of general helix, spiral, etc.). We
require, however, that the parametrized space curves rk(t) have a tendency of
“drifting away from the start 0”. A parametrized curve modulo one describes the
motion of a particle in the torus, and |rk (t)| denotes the Euclidean distance in the
whole space (not in the torus!) from the start rk (0) = 0 at time t. We emphasize
that here we do not take rk(t) modulo one yet; for example, on a straight line te,
where e is a unit vector, the distance of te from the start 0 is t.
In the rest, if we do not specify it, it should always be clear from the context
of the sentence that the distance between two points x, y ∈ Rd is the usual Rd-
distance (= Euclidean distance) 
 or the “unit torus distance” 

 (where ||z|| is the distance of z from the nearest integer).
We use xk(t) to denote the trajectory of the kth particle on the torus I3 = [0,
1)3 (1 ≤ k ≤ N). For simplicity assume that every particle starts from the origin
(“Big Bang”), i.e., xk(0) = 0 ∈ I3, 1 ≤ k ≤ N. Let rk(t), 1 ≤ k ≤ N be an arbitrary
family of N continuous parametrized space curves with rk(0) = 0, and write 
We know that rk(t) describes the type of the trajectory of the kth particle (of
course for the torus we take rk(t) modulo one), and xk(0) = 0 is the starting point,
but we also need the initial velocity. We assume Gaussian initial velocity
distribution: we choose a scale ρk in 0 < ρk < ∞ with distribution 
for all positive u > 0 (the speed distribution of the 3-dimensional normal
distribution; note that the factor y2 comes from the surface area 4πy2 of a sphere
of radius y > 0). We also choose a “direction”, which here actually means a
rotation of the 3-space. The reason is that a general space curve (say a helix) is a
proper 3-dimensional object (unlike a straight line), so we must choose a rotation
of the 3-space ϑk ∈ SO(3).
(For comparison, note that the 2-dimensional case is simpler: the rotation of
the plane simply means to choose a point on the unit circle S1, or equivalently, to
choose an angle 0 ≤ θ < 2π.) The choice of the scale ρk and the rotation ϑk in the
3-space make the initial condition complete (1 ≤ k ≤ N). So, starting from Big
Bang, 
the 
real 
trajectory 
of 
the 
kth 
particle 
is 
which describes the time evolution of the whole N-point system.
To define typical, we need a measure. As usual, we assume that ρ1, ϑ1, ρ2, ϑ2,
. . . , ρN, ϑN are 2N independent random variables, where ρ1, ρ2, . . . , ρN have the
same Gaussian distribution described by (17.4), and ϑ1, ϑ2, . . . , ϑN are all
uniformly distributed in the rotation group SO(3) (= special orthogonal group of
all 3 × 3 real matrices) with respect to the Haar measure. This means we use the
corresponding product measure, denoted by ProdMeasGauss, on the product space
We 
have 
, 
where 
for 
notational 
simplicity 
dω 
=
dProdMeasGAUSS(ω).
We refer to this as the general 3-dimensional Gaussian torus model (starting

from Big Bang). We refer to the huge product space ΩGauss as the “initial
velocity space”.
Note that the Haar measure on SO(3) is equivalent to a simple product
measure: the product of the surface area on the unit sphere S2 and the arclength
on the unit circle S1. This follows from the well-known fact that every nontrivial
rotation in the 3-space can be specified by an axis of rotation together with an
angle of rotation about this axis (more precisely, one also needs to specify
orientations), which leads to a measure-theoretic isomorphism between SO(3)
and S2 × S1.
Given a family of parametrized curves
and given an initial condition
write
for the curve of the (Gaussian general torus) system in the configuration space;
(17.7) represents the time evolution of the system.
We use the test function
where 
n0 
= 
(1, 
0, 
0) 
and 
z 
= 
(z1, 
z2, 
z3). 
Write 
and
where in (17.10) we used (17.9).
By (17.10) we have

Next we integrate (17.11) over the big “initial velocity space” ΩGAUSS = ([0, ∞)
× 
SO(3))N 
(see 
(17.6)); 
we 
have 
where we used the fact that for every 3-dimensional vector w and unit vector e ∈

S2, 
and the last step in (17.13) follows from Lemma 9.1 with d = 3.
The crucial fact in (17.12) is that the terms on the right-hand side are all
positive. Thus we obtain the trivial lower bound (we just keep the last line in
(17.12)) 
Consider now the simplest torus model rk(t) = tn0 with n0 = (1, 0, 0), 1 ≤ k ≤ N.
Then 
(17.7) 
simplifies 
to 
the 
torus 
line 
where
In this special case (17.14) gives (for notational simplicity dω =
dProdMeasGauss(ω)) 
By (14.21) (which is basically the proof of Theorem 4.3)
Combining (17.17) and (17.18),
By using (17.19), we can derive a lower bound as follows — see (17.23)
below.
Theorem 17.1. Consider the simplest N -particle (N ≥ 1020) Gaussian 3-
dimensional torus model in I3 = [0, 1)3 with all particles starting from the origin
(“Big Bang”); see (17.15)–(17.16). We use the “nice” test function g0 defined in
(17.8). Assume that there is a time interval U ≤ t ≤ W with U ≥ 
 and W − U
≥ 1 (where t = 0 represents the Big Bang in the origin) such that 

(representing overwhelming majority in the polynomial sense of (17.1)) we have
for some constant 1/4 > ε > 0, where
Then
Remark. This shows that we do not have an analogue of (17.1)–(17.2) for time-
lapse randomness. Indeed, for the overwhelmimg majority (see (17.20)) of the
time evolutions of a system of the first kind it takes nearly linear time (see
(17.23), assuming ε is small) to reach nearly perfect CLT time-lapse randomness
(see (17.21)). Nearly linear time N1−o(1) is strikingly different from the much
smaller threshold 
 in snapshot randomness.
Proof of Theorem 17.1. By using the first line in (17.10) in the special case of
the 
simplest 
3-dimensional 
torus 
model, 
we 
have 
where the last two integrals with
are Lebesgue–Stieltjes integrals, and in the last step we used the well-known fact
that the expectation of the standard normal distribution is zero, i.e., 

Applying integration by parts in (17.24), we have
By (17.25),
To estimate the last two lines in (17.26), we basically repeat the argument of Sec.
5: it is the usual application of Theorem 4.2. We carry out the details in the next
section; see (18.13)–(18.14).
18. Time-Lapse Randomness vs. Snapshot Randomness
(II): A Fundamental Difference
We make use of the fact that the family of time evolutions (see (17.15); let n0 =
(1, 0, 0)) 
ω ∈ ΩGauss of the simplest 3-dimensional Gaussian torus model is represented

by a family of torus lines in the configuration space Id starting from the origin 0
∈ Id (since the system started from Big Bang 0 ∈ I3).
For an arbitrary γ > 0 write
where
and zk = (z3k−2, z3k−1, z3k), 1 ≤ k ≤ N.
By the general form of Bernstein’s large deviation inequality (see Sec. 5)
with n = N and 
, 
We apply Theorem 4.2 with f = χS where S = S(g0 ; γ). Thus we obtain 
where the integer k ≥ 1 comes from 2k−1U < W ≤ 2k U, and in the last step we
used (18.3).
Note that

We 
recall 
that 
U 
≥ 
 
and 
N 
≥ 
1020, 
and 
we 
choose 
Then
and so by (18.4)–(18.7),
For every integer j ≥ 1, let Ω(bad; j) be the set of those ω ∈ ΩGauss for which 
We claim that (18.8) implies
Indeed, otherwise

which contradicts (18.8). In the last step we used vold(S(g0; 2j log N)) ≤ N−90j
(see (18.7)).
Let
Then by (18.10),
Let
then by (18.9)
Now we are ready to estimate the last two lines in (17.26). Under the condition
of 
(18.13), 
by 
(18.14) 
we 
have 

Moreover, by (17.20) and (17.21),
except for a set ω ∈ Ω(defective) with
Combining (17.26) and (18.15)–(18.17), we obtain
for all
with (see also (18.12))
Write
Combining (18.18)–(18.21), we have

where we used the trivial upper bound |T(ω; g0; U, W)| ≤ (W − U)N (see (17.10)).
On the other hand, by (17.19),
Comparing (18.22) and (18.23), we have
which implies (17.23)
This completes the proof of Theorem 17.1.
Probably the reader is wondering: Why does it take so long to reach nearly
optimal CLT time-lapse randomness? It seems like a “plausible explanation” that
perhaps the N torus lines (representing the trajectories of the individual particles
in the simplest torus model) are “too simple”, and if the particles move on more
complicated random walk like zig-zag trajectories then perhaps it takes much
shorter time to reach nearly optimal CLT time-lapse randomness. Well, it turns
out that this “plausible explanation” is completely wrong.
In Theorem 17.1 we studied the simplest 3-dimensional torus model rk(t) =
(t, 0, 0), 1 ≤ k ≤ N. Consider now the most general case where rk(t), 1 ≤ k ≤ N are
arbitrary 
with 
only 
one 
natural 
restriction 
(18.24) simply means that the speed is bounded (it certainly holds for particle–
particle collision of hard-core particles). Under the condition (18.24), Eq.

(17.14) 
implies 
the 
same 
lower 
bound 
as 
in 
(17.17) 
Since (18.25) is the same as (17.17), we can basically repeat the whole argument
above in the general case with some necessary changes (we omit the details).
Thus we obtain the same nearly linear lower bound for the time interval as in
(17.23). In other words, complicated zig-zag trajectories do not speed up the
approach to nearly optimal CLT time-lapse randomness.
We have to admit that we do not know any simple intuitive explanation why
the approach to nearly optimal CLT time-lapse randomness is so time-
consuming.
19. CLT Time-Lapse Randomness: Upper Bound
We recall that in computational complexity theory, an algorithm with (worst-
case) polynomial running time (in terms of the input data) is considered
tractable, and exponential running time is considered intractable.
We use the same distinction here: polynomial time (in terms of N) is still
considered realistic, and exponential time — what we have e.g. for nearly
perfect time-lapse randomness (see Theorem 11.8 and after in the Remarks) — is
considered unrealistic.
We complement the lower bound (17.23) in Theorem 17.1 with a positive
result showing that polynomial time — i.e., realistic time — is sufficient to
exhibit optimal CLT time-lapse randomness for the overwhelming majority of
the time evolutions. The proof is another application of Theorem 4.2; again we
use it as a short-time ergodic theorem in the configuration space.
For simplicity, we formulate this upper bound theorem for test sets B ⊂ [0,
1)3 in the particle space instead of the most general case of test functions.
Theorem 19.1. Let Yω;t, ω ∈ ΩGauss be the simplest 3-dimensional Gaussian

torus model with N-element initial point configuration Y ⊂ [0, 1)3. Let N ≥ 1020,
and let B ⊂ [0, 1)3 be an arbitrary but fixed measurable test where p = vol(B)
denotes the 3-dimensional Lebesgue measure.
Then for every η > 0 there exists a subset Ω(bad; η) ⊂ ΩGauss such that 
and for every ω ∉ Ω(bad; η), and every real number T ≥ 2
 + 2 (we also
use 
the 
notation 
q 
= 
1 
− 
p), 
where of course N(y) denotes the normal distribution:
Remarks. For example, let η = N−4 and T ≥ N7. Then the upper bound 
implies that
represents an overwhelming majority of the initial velocities, and for this
overwhelming majority of ω ∈ Ω(good; η), (19.1) gives the upper bound 
where the last line is the optimal CLT error apart from an absolute constant
factor (the error is the discrepancy between the discrete binomial distribution
and the continuous standard normal distribution). The lower bound T ≥ N7 is
polynomial in N, so it is still considered a realistic time scale.
On the other hand, if T is in the much smaller polylogarithmic range of (log
N)4++o(1), then the right-hand side of (19.1) (= error term) is already o(1) (for an
appropriate η = o(1)). That is, polylogarithmic threshold suffices to prove a non-
trivial CLT type result.

Returning to polynomial time: as we said above, it is still interpreted as a
realistic time scale; nevertheless, the approach to time-lapse randomness is
undoubtedly very slow; see (17.23). In sharp contrast, the approach to snapshot
randomness is extremely fast, reflected by the threshold 
, which holds
even for starting from Big Bang.
We may call Theorem 19.1 a quantitative/realistic version of Theorem 3.3.
Similarly, by a straightforward modification of the proof of Theorem 19.1, one
can easily prove a “hard” analogue of the “weak” Poisson Law, Multinomial
CLT, and Multinomial Poisson Law in Secs. 3 and 11. We could also have a
CLT-partition like in Sec. 15, and a Poisson-partition like in Sec. 8. The basic
idea is always the same: replace the application of the Kronecker–Weyl theorem
in the configuration space with the use of Theorem 4.2.
Also, we can easily extend Theorem 19.1 (i.e., CLT time-lapse randomness
in realistic time) for the closed orbit models introduced in Secs. 6 and 17.
Proof of Theorem 19.1. As usual, given an N-element point set Y = {y1, . . . ,
yN} ⊂ I3, we use the vector notation 
for the corresponding point in the configuration space Id = [0, 1)3N. The family
of time evolutions Yω;t, ω ∈ ΩGauss of the simplest 3-dimensional torus model of
the first kind is represented by the family of torus lines 
in the configuration space Id, all starting from the same point  ∈ Id. For −∞ ≤ γ1
< 
γ2 
≤ 
∞, 
write 
with 
q 
= 
1 
− 
p, 
where
with zk = (z3k−2, z3k−1, z3k), 1 ≤ k ≤ N.
We have
where p = vol(B) and q = 1 − p.
By using the Berry–Esseen form of the Central Limit Theorem in the special
case of the binomial distribution with parameter p = vol(B), we have 

Since the torus Id is translation invariant, we can apply Theorem 4.2 with f = χS
where S is the translated copy 
of 
S(B; 
γ1, 
γ2) 
in 
the 
torus 
Id. 
Thus 
we 
obtain: 
if 
then
Note that
where, for notational convenience, dω = dProdMeasGauss(ω).
Let
We apply a standard binary decomposition trick. We call an interval [m, m +
2r) special if m, r ≥ 0 are nonnegative integers and m is divisible by 2r.
Let T ≥ 2
 + 2 = 2N0 + 2 be an arbitrary integer, and consider its binary
representation 
Then the interval [N0, T) can be decomposed into at most 1 + log2T intervals as
follows: 

Note that the intervals on the right-hand side of (19.11) are all special except the
first one.
Similarly, let 0 ≤ λ ≤ 1 + log N be a binary rational number of the form
Then
Let (R, r; l) be a triple of integers such that
For η > 0, let Ω(R, r; l; bad; η) be the set of those ω ∈ ΩGauss for which 
where l0 = log2(1 + log N).
By using (19.7) and (19.8) (noting that in view of (19.9)–(19.10) condition
(19.6) is satisfied), we obtain that for every triple (R, r; l) of integers satisfying

(19.14), 
Combining (19.15) and (19.16), we obtain the upper bound
By 
(19.17), 
with 
N0 
= 
 
and 
l0 
= 
log2(1 
+ 
log 
N), 

Let
Then by (19.18),
If ω ∉ Ω(+; bad; η), then by (19.15),
holds for every triple of integers (R, r; l) satisfying (19.14).
We recall (19.10)–(19.13): Let T ≥ 2
 + 2 = 2N0 + 2 be an arbitrary
integer 
with 
binary 
representation 
and let 0 ≤ λ ≤ 1 + log N be a binary rational number of the form
Then the interval [N0, T) has the decomposition
and similarly,
where S(γ1, γ2) = S(B; γ1, γ2) − .
If ω ∉ Ω(+; bad; η), then by using first the triangle inequality, using second
the Cauchy–Schwarz inequality, and finally using (19.21), we obtain for every
integer T ≥ 2N0 + 2 = 2
 + 2 and every binary rational λ of the form (19.12)
in 
the 
interval 
0 
≤ 
λ 
≤ 
1 
+ 
log 
N, 


Using (19.3) in (19.22), we obtain that for ω ∉ Ω1(+; bad; η),
For every real number 0 ≤ β ≤ log N there exist two binary rationals 0 ≤ λ1 ≤ β ≤
λ2 
≤ 
1 
+ 
log 
N 
of 
the 
form 
(19.12) 
such 
that 
We have

where
and in the last step of (19.26) we used (19.24). Combining (19.23) and (19.25)–
(19.26), 
we 
have 
for 
ω 
∉ 
Ω(+; 
bad; 
η), 
where N0 = 
.
Moreover, we have

Using (19.27) with β = log N in (19.28), we have for ω ∉ Ω(+; bad; η),
By (19.9),

Combining (19.27) and (19.29)–(19.30), for ω ∉ Ω(+; bad; η),
where by (19.20),
(19.31)–(19.32) settle the case of positive β’s. Repeating the same argument, we
can settle the missing case of negative β’s. That is, there exists a subset 
such that
and for ω ∉ Ω(−; bad; η),
Let
then by (19.32)–(19.33),
and for ω ∉ Ω(bad; η),
for all integers T ≥ 2N0 + 2 = 2
 + 2.
It immediately follows from (19.37) that, for every ω ∉ Ω(bad; η) and every
real 
number 
T 
≥ 
2
 
+ 
2, 

Dividing (19.38) by T, Theorem 19.1 follows.

Chapter 4
More Results about Randomness and
Stability in Equilibrium
20. Simultaneous Square-Root Equilibrium Relative to
Nice Sets (I)
As the title of the section suggests, we are going to prove long-term stability of
square-root equilibrium in the particle space (= “gas container”). It means
uniformity with square-root error simultaneously for a whole family of nice test
sets (in the particle space). Of course we have to clarify what nice sets mean.
Aligned and rotated boxes, tetrahedrons, balls, ellipsoids are certainly nice, and
they are all convex. Since we study isotropic (= rotation-invariant) velocity
distributions, it is natural to consider a rotation-invariant family of test sets. A
plausible choice is to consider the family of all convex sets.
What we do here is basically a continuation of Sec. 5 working with the 3-
dimensional torus model, but the proof also works for the closed orbit models
discussed in Secs. 6–7.
We employ a geometric approximation argument, and Sec. 20 is devoted to
the technical discussion of this. To make the somewhat cumbersome details as
simple as possible, we explain the idea in the 2-dimensional case. It means that
we replace the 3-dimensional torus model with the 2-dimensional version, and
the family of nice test sets is the family of all convex sets in the unit square [0,
1]2.
We approximate plane convex sets with inscribed polygons. We apply a well-
known area approximation theorem of Sas [Sa39] that goes as follows. For every
integer n ≥ 3, every plane convex set of area one contains an inscribed polygon
of n vertices (= n-gon) whose area is at least as large as the area of the largest n-
gon inscribed in a circle of area one. Since the area of the regular n-gon on the

unit circle is exactly n sin(2π/n), Sas’s theorem implies that every plane convex
set of area one contains an inscribed n-gon such that the area of the set-
difference 
(= 
area 
of 
the 
convex 
set 
minus 
the 
n-gon) 
is 
where we used the well-known inequality sin x ≥ x − x3/6.
Let B ⊂ [0, 1]2 be a convex set in the unit square, and let 2 ≤ j < k be
integers. We define the set B(k; j) as follows. Let P(B; k) denote the largest area
inscribed polygon in B with 2k vertices; let P(B; k; k − 1) = P(P(B; k); k − 1)
denote the largest area inscribed polygon in P(B; k) with 2k−1 vertices; let P(B; k;
k − 2) = P(P(B; k; k − 1); k − 2) denote the largest area inscribed polygon in P(B;
k; k − 1) with 2k−2 vertices; and so on. That is, P(B; k; k − ℓ) = P(P(B; k; k − ℓ +
1); k − ℓ) denotes the largest area inscribed polygon in P(B; k; k−ℓ+1) with 2k−ℓ
vertices, where 1 ≤ ℓ ≤ k−2 (and of course P(B; k; k) = P(B; k)). Finally, we
define B(k; j) as the set-difference 
Thus for every 2 ≤ i < k we have
(Note in advance that in the application later we will choose the concrete value i
= 5.)
By (20.1) we have the area estimations
It follows from the construction of the sets P(B; k; j), B(k; j) that B(k; j) is the
disjoint union of at most 2j+1 triangles, whose vertices are the vertices of the two
polygons P(B; k; j) and P(B; k; j + 1). More precisely, we have exactly 2j+1
triangles if the vertices of the two polygons P(B; k; j) and P(B; k; j + 1) are
different; and in general the number of triangles is 2j+1 − c if the polygons P(B;
k; j) and P(B; k; j + 1) have c common vertices. Indeed, every decomposition of
a polygon of 2j + 2j+1 − c vertices into triangles has 2j + 2j+1 − c − 3 triangles,
and from this number we have to subtract the 2j − 3 triangles that come from
P(B; k; j).
Let ∆ = ∆(B; k; j) denote one of these triangles. We approximate triangle ∆
with a special triangle. Consider the following square lattice in the unit square 

We refer to the square lattice (20.5) as the M-lattice, and call its elements M-
lattice-points.
We need the following almost trivial geometric lemma.
Lemma 20.1. Let ∆* ⊂ [0, 1]2 be a triangle in the unit square with area ≥ 2/M.
Then ∆* contains an M-lattice-point.
Proof. We use the well-known fact in elementary geometry
where r = r(∆*) denotes the radius of the largest inscribed circle in ∆*. Clearly
which follows from the well-known inequality that, if B1 ⊂ B2 are two bounded
plane convex sets then 
Combining the hypothesis of the lemma with (20.6) and (20.7), we have
which implies that the largest inscribed circle in ∆* must contain an aligned
square of side length 1/M, and every such square contains an M-lattice-point (see
(20.5)). This completes the proof of Lemma 20.1.
Let us return now to the triangle ∆ = ∆(B; k; j) defined above. By using its
three midpoints, we can decompose triangle ∆ into four congruent subtriangles
that are “half copies” of ∆. Similarly, for every integer i ≥ 2 we can divide each
side of triangle ∆ into i equal parts (by using i − 1 points), and joining the
corresponding points with line segments, we can divide triangle ∆ into i2
congruent subtriangles of order i such that each subtriangle is similar to ∆ with
the ratio 1 : i. Let ∆(i; ℓ), 1 ≤ ℓ ≤ i2 denote these congruent subtriangles of order
i.
Assume that ∆ = ∆(B; k; j) satisfies the area condition
Under the condition (20.9), let i0 = i0(∆(B; k; j)) ≥ 4 be the largest integer such
that 
Let ∆(i0; 1), ∆(i0; 2) and ∆(i0; 3) denote the three congruent subtriangles of ∆ of
order i0 which contain the three vertices of ∆. In view of Lemma 20.1 and

(20.10), each subtriangle ∆(i0; ℓ), 1 ≤ ℓ ≤ 3 contains an M-lattice-point with M =
4jN; let vℓ = vℓ(∆(B; k; j)), 1 ≤ ℓ ≤ 3 denote these three 4jN-lattice-points (if there
are many in a subtriangle, we choose the nearest one to the corresponding vertex
of 
∆). 
A 
simple 
geometric 
consideration 
shows 
that 
Indeed, the v1v2v3-triangle clearly contains a congruent copy of ∆ that consists
of (i0 − 3)2 congruent subtriangles of order i0.
We refer to the v1v2v3-triangle as the inscribed approximation of triangle ∆ =
∆(B; k; j) using 4jN-lattice-points.
If the area condition (20.9) is violated, i.e., if ∆ = ∆(B; k; j) has the property
then we choose i0 = i0(∆(B; k; j)) = 3, and of course (20.11) remains true in a
trivial way by choosing v1v2v3 to be the empty set (“empty triangle”).
We recall that B(k; j) is the disjoint union of at most 2j+1 triangles ∆ = ∆(B; k;
j), whose vertices are the vertices of the two polygons P(B; k; j) and P(B; k; j +
1). For each of these triangles ∆ = ∆(B; k; j) we take the corresponding v1v2v3-
triangle (i.e., inscribed approximation using 4jN-lattice-points), and finally, we
take the union of these v1v2v3-triangles. Let IN(B(k; j)) denote this union set. We
refer to IN(B(k; j)) as the inscribed approximation of B(k; j) using 4jN-lattice-
points.
Since IN (B(k; j)) is the union of at most 2j+1 triangles whose vertices are
4jN-lattice-points, we have the following trivial upper bound.
Fact 1: The total number of sets IN(B(k; j)), where j is fixed, k > j, and B ⊂ [0,
1]2 runs over all convex subsets of the unit square, is at most 
Exactly the same way as we defined the inscribed approximation IN(B(k; k −
1)) of B(k; k − 1) using 4k−1N-lattice-points, we can define the inscribed
approximation IN(P(B; k)) of P(B; k) using 4k−1N-lattice-points. Indeed, the only
minor difference is that IN(B(k; k − 1)) is the union of at most 2k triangles whose
vertices are 4k−1N-lattice-points, and IN(P(B; k)) is the union of exactly 2k
triangles whose vertices are 4k−1N-lattice-points, but this difference is irrelevant

in the corresponding arguments. Thus we obtain the perfect analog of Fact 1.
Fact 2: The total number of sets IN(P(B; k)), where k is fixed and B ⊂ [0, 1]2
runs over all convex subsets of the unit square, is at most 
Next we describe the circumscribed approximation of B(k; j) using 4jN-
lattice-points — it is a simpler construction. For every triangle ∆ = ∆(B; k; j)
consider its three vertices, and for each vertex consider the elementary 4jN-
square in (20.5) containing this vertex. An elementary 4jN-square in (20.5) has
four 
vertices 
of 
the 
form 
and this elementary 4jN-square is clearly determined by its lower left corner
point
which is of course a 4jN-lattice-point.
The circumscribed approximation of triangle ∆ = ∆(B; k; j) using 4jN-lattice-
points is defined as the convex hull of the three elementary 4jN-squares in (20.5)
containing the three vertices of the triangle.
It follows from the construction that the area of the set-difference (i.e., the
area of the circumscribed approximation of ∆ = ∆(B; k; j) minus the area of ∆) is
estimated 
from 
above 
by 
the 
sum 
We know that B(k; j) is the disjoint union of at most 2j+1 triangles ∆ = ∆(B; k;
j) (whose vertices are the vertices of the two polygons P(B; k; j) and P(B; k; j +
1)); for each of these triangles ∆ = ∆(B; k; j) we take the corresponding
circumscribed approximation of the triangle, and finally we take the union of
these sets. Let OUT(B(k; j)) denote this union set. We refer to OUT(B(k; j)) as
the circumscribed approximation of B(k; j) using 4jN-lattice-points.
Note that OUT(B(k; j)) is the union of at most 2j+1 parts, where each part is
the convex hull of three elementary 4jN-squares in (20.5). Since every
elementary 4jN-square in (20.5) is determined by its lower left corner point,

repeating the proof of Fact 1 we obtain the following result.
Fact 3: The total number of set-difference sets OUT(B(k; j)) \ IN(B(k; j)) where j
is fixed, k > j, and B ⊂ [0, 1]2 runs over all convex subsets of the unit square, is
at most 
Clearly
By (20.15),
where the upper bound 4 + 4 comes from combining the facts P(B; k; j) ⊂ [0, 1]2
and P(B; k; j + 1) ⊂ [0, 1]2 with (20.8).
Next we switch to the inscribed approximation “error”. By (20.11) we have,
Under the condition (20.9), (20.10) implies
so
Since i0 ≥ 3, by (20.19) we have
and using it in (20.18), we obtain
assuming ∆ = ∆(B; k; j) satisfies (20.9). Combining (20.12) and (20.20) with the
Cauchy–Schwarz 
inequality, 
we 
have 

where in the last step we used (20.4).
Repeating the argument of (20.21) with j = k − 1, we obtain the following
analog upper bound:
Note that the whole argument between (20.2) and (20.22) was based on
(20.1) and P(B; k) (= largest area inscribed polygon of the plane convex set B ⊂
[0, 1]2 with 2k vertices). Next we switch to the circumscribed approximation of B
⊂ [0, 1]2. For circumscribed approximation we do not know a sharp result like
Sas’s theorem; nevertheless, it is easy to prove a “quadratic approximation” type
result like (20.1); see (20.25) below. Let S be a plane convex set of area one; by
Sas’s theorem for every m ≥ 3 there exists an inscribed m-gon Pm(S) ⊂ S such
that (see (20.1)) 
Let P+
m(S) ⊃ S be the circumscribed polynomial such that the sides of P+
m(S) are
parallel to the sides of Pm(S). The sides of P+
m(S) are tangent lines of S; we also
consider the tangent lines of S at the vertices of Pm(S). These 2m tangent lines
have angles 
It might happen that there is an exceptionally large jump among these angles in

the precise sense that θi+2 − θi > π for some 1 ≤ i ≤ 2m (where θ2m+1 = θ1 + 2π
and θ2m+2 = θ2 + 2π). We can easily eliminate the “exceptionally large jump” by
including an extra angle either between θi and θi+1 or between θi+1 and θi+2. If
we also take the corresponding tangent line with this possible extra angle, we
obtain at most 2m + 1 tangent lines of S, and they define a circumscribed
polynomial P+2m+1(∗; S) ⊃ S of the convex set S.
Lemma 20.2. For every integer m ≥ 3 and plane convex set S of area one.
Proof. We use the following simple geometric fact. Consider the trapezoid with
vertices v1 = (0, 0), v2 = (a, 0), v3 = (b, h), v4 = (c, h) such that a ≥ b − c > 0 and
h > 0. We refer to the side v1v2 of the trapezoid as the longer base. Let S′ be a
convex subset of the v1v2v3v4-trapezoid such that S′ contains the whole v1v2-line-
segment, and S′ intersects the v3v4-line-segment. Then the area of S′ is at least
half of the area of the v1v2v3v4-trapezoid.
The proof of this “trapezoid fact” is almost trivial. Indeed, let w be a point of
S′ on the v3v4-line-segment. Then S′ contains the v1v2w-triangle, which has area
ah/2. 
On 
the 
other 
hand, 
the 
v1v2v3v4-trapezoid 
has 
area 
proving the “trapezoid fact”.
The proof of the lemma is a straightforward application of the “trapezoid
fact” to m trapezoids such that the longer base runs through every side of the
inscribed polygon Pm(S).
Combining (20.23) with Lemma 20.2, we obtain the upper bound
For k ≥ 4, let P+(B; k) denote the smallest area circumscribed polygon of B in
the unit square with 2k vertices. (That is, P+(B; k) ⊂ [0, 1]2, which means that
we may include four more tangent lines of B — parallel to the sides of the unit
square — to define the circumscribed polygon of B.) By (20.25) we have the
area estimation 
We define the circumscribed approximation OUT(P+(B; k)) of P+(B; k) using
4kN-lattice-points the same way as we defined the circumscribed approximation

OUT(B(k; j)) of B(k; j) using 4jN-lattice-points. That is, for each vertex of P+(B;
k) consider the elementary 4kN-square in (20.5) containing this vertex. We recall
that an elementary 4kN-square in (20.5)) has four vertices of the form (20.13)
with j = k, and this elementary 4kN-square is clearly determined by its lower left
corner point (see (20.14) with j = k), which is of course a 4kN-lattice-point.
OUT(P+(B; k)) is defined as the convex hull of the 2k elementary 4kN-squares in
(20.5) containing the vertices of P+(B; k).
We have the analog of (20.17):
Moreover, combining Fact 2 with the usual counting argument, we have the
following.
Fact 4: The total number of set-difference sets OUT(P+(B; k)) \ OUT(P(B; k)),
where k is fixed and B ⊂ [0, 1]2 runs over all convex subsets of the unit square,
is at most 
By (20.3) we have for every 2 ≤ i < k,
and
The last step in the approximation process is to define an inscribed and
circumscribed approximation of the “beginning” P(B; k; i) in (20.28)–(20.29).
We do it in the usual way by using M-lattice-points with the novel choice M =
N4/3. First we define the circumscribed approximation: for each vertex of P(B; k;

i) consider the elementary N4/3-square in (20.5) containing this vertex. OUT(P(B;
k; i)) is defined as the convex hull of the 2i elementary N4/3-squares in (20.5)
containing the vertices of P(B; k; i).
To define the inscribed approximation, we start, as usual, with a triangle
decomposition: we decompose P(B; k; i) into 2i triangles. Let ∆ = ∆(P(B; k; i))
denote one of these triangles. We approximate triangle ∆ with a special triangle
by repeating the arguments of (20.9)–(20.12) with M = N4/3 instead of M = 4jN,
Assume that ∆ = ∆(P(B; k; i)) satisfies the area condition
Under the condition (20.30), let i0 = i0(∆(P(B; k; i))) ≥ 4 be the largest integer
such that 
Let ∆(i0; 1), ∆(i0; 2) and ∆(i0; 3) denote the three congruent subtriangles of ∆ of
order i0 which contain the three vertices of ∆. In view of Lemma 20.1 and
(20.31), each subtriangle ∆(i0; ℓ), 1 ≤ ℓ ≤ 3 contains an M-lattice-point with M =
N4/3; let vℓ = vℓ(∆(B; k; j)), 1 ≤ ℓ ≤ 3 denote these three N4/3-lattice-points (if
there are many in a subtriangle, we choose the nearest one to the corresponding
vertex 
of 
∆). 
We 
have 
the 
analog 
of 
(20.11): 
We refer to the v1v2v3-triangle as the inscribed approximation of triangle ∆ =
∆(P(B; k; i)) using N4/3-lattice-points.
If the area condition (20.30) is violated, i.e., if ∆ = ∆(P(B; k; i)) has the
property
then we choose i0 = i0(∆P(B; k; i)) = 3, and of course (20.32) remains true in a
trivial way by choosing v1v2v3 to be the empty set (“empty triangle”).
Note that P(B; k; i) is the disjoint union of 2i triangles ∆ = ∆(P(B; k; i)), and
for each of these triangles ∆ we take the corresponding v1v2v3-triangle (i.e.,
inscribed approximation using N4/3-lattice-points), and finally, we take the union
of these v1v2v3-triangles. Let IN(P(B; k; i)) denote this union set. We refer to
IN(P(B; k; i)) as the inscribed approximation of P(B; k; i) using N2/3-lattice-
points.

We have the following trivial upper bounds.
Fact 5: (a) The total number of sets OUT(P(B; k; i)), where i is fixed, k ≥ i, and B
⊂ [0, 1]2 runs over all convex subsets of the unit square, is at most 
(b) The total number of sets IN(P(B; k; i)), where i is fixed, k ≥ i, and B ⊂ [0, 1]2
runs over all convex subsets of the unit square, is at most 
We also have the following analogs of (20.17) and (20.21) with M = N4/3
instead of M = 4jN: 
and
We conclude the approximation process by involving IN(P(B; k; i)) and
OUT(P(B; k; i)) in (20.28)–(20.29): for every 2 ≤ i < k, we have 
and
We have the following area estimations: by (20.16) and (20.21),
by (20.4), (20.22), (20.26) and (20.27),

and by (20.34) and (20.35),
Finally, we choose the integers i and k as follows:
21. Simultaneous Square-Root Equilibrium Relative to
Nice Sets (II)
The family of time evolutions Y(Gauss; ω; t), ω ∈ ΩGauss of the simplest 2-
dimensional Gaussian torus model is represented by the family of torus lines (see
(5.2)) 
in the configuration space Id = [0, 1)d with d = 2N, all starting from the same
point 
(where, as usual, Y = {y1, . . . , yN} denotes the given N-set of initial point
configuration in the unit square [0, 1)2).
For an arbitrary measurable test set A ⊂ [0, 1)2 and γ > 0 define the
following 
(very 
complicated!) 
set 
in 
the 
configuration 
space 
where
with zk = (z2k−1, z2k), 1 ≤ k ≤ N.
Inserted Remark. Similarly to definition (5.7) in Sec. 5, definition (21.2)
becomes useless for “small” test sets A with 
Replacing (21.2) with the following modified set in the configuration space
where p = area(A) ≤ 1/2 and q = 1 − p ≥ 1/2, we can easily prove useful relative
square-root discrepancy even for test sets as small as 
where C is a “large” absolute constant. Note that area(A) ≥ C · N−1 describes a
much larger family of test sets than area(A) ≥ C · N−1/2, and it is best possible in

the sense that it is the largest class for which the relative square-root discrepancy
estimation is still useful.
We need the 2-dimensional analog of Theorem 5.1 (see (5.15); the proof is
exactly the same: combining Theorem 4.2 with Bernstein’s inequality (5.9)).
Lemma 21.1 (2-dimensional analog of Theorem 5.1) Let Y(Gauss; ω; t), ω ∈
ΩGauss be the simplest 2-dimensional Gaussian torus model, and let A ⊂ [0, 1)2
be a measurable test with 2-dimensional Lebesgue measure area(A). Assume that
Then for every γ > 0 and every integer ℓ ≥ 1,
where
and
The notation Var in (21.4) indicates that the square integral (21.4) is basically
a “variance”.
What we actually need is the following average
where Ga, le, ar and Me stand, respectively, for Gauss, length, area and measure.

By using the well-known inequality between the L1-norm and the L2-norm,
we have
if
Combining this with Lemma 21.1, we obtain the following lemma.
Lemma 21.2. Under the condition of Lemma 21.1, for every γ > 0 and every
integer ℓ ≥ 1,
if
Motivated by (20.36)–(20.37), we define the following families of subsets of
the unit square. Let j ≥ 2 be an integer such that 8j ≤ N; then Aj
(1) denotes the
family of all sets of the form IN(B(k; j)), and similarly, let Aj(2) denote the family
of all sets of the form OUT(B(k; j)) \ IN(B(k; j)), where j < k, k is defined in
(20.41), and B ⊂ [0, 1]2 runs over all convex subsets of the unit square. Let Ak
(3)
denote the family of all sets of the form OUT(P+(B; k)) \ IN(P(B; k)), where B ⊂
[0, 1]2 runs over all convex subsets of the unit square. We recall that i = 5; see

(20.41). Let A5(4) denote the family of all sets of the form OUT(P(B; k; 5)) \
IN(P(B; k; 5)), and let A5(5) denote the family of all sets of the form IN(P(B; k;
5)), where k is defined in (20.41) and, as usual, B ⊂ [0, 1]2 runs over all convex
subsets of the unit square.
We recall (20.4),
Combining Fact 1, Lemma 21.2 and (21.7), we obtain the following inequality:
under the condition (21.3), for every γ > 0 and every integer ℓ ≥ 1, 
assuming (21.6) holds, i.e.,
Applying the trivial inequality 
 ≤ nm, we have
Using (21.10) in (21.8), we obtain the following: under the condition (21.3), for
every 
γ 
> 
0 
and 
every 
integer 
ℓ 
≥ 
1, 
assuming
Note that (21.11) is a key step in the polygon-approximation technique. To

illustrate the power of (21.11), we specify the parameters as follows: let 
which implies d = 2 · 1027, and notice that with the choice (21.13) condition
(21.3) 
is 
satisfied; 
moreover, 
let 
We are going to use the simple fact
(Indeed, in view of the identity 
, (21.15) is a telescopic sum.)
To motivate the choice of the parameters in (21.13), we recall that there are
roughly 1027 gas molecules in a cubic box of volume 1 m3, and realistic gas
molecules have average speed in the range of 103 meter per second. For
technical reasons in Secs. 20 and 21 we restrict ourselves to the 2-dimensional
case, which means that here we replace the cubic box of volume 1 m3 (= “gas
container”) with a square of area 1 m2; nevertheless, we still assume that the
average speed of the N = 1027 particles is in the range of 103 meter per second.
In the 2-dimensional Bernoulli gas model the gas molecules are represented by
point billiards, and as usual, we apply the geometric trick of unfolding (see Sec.
3); thus we reduce the billiards-in-a-square model to the torus-billiard model. In
fact, what we have here is the simplest 2-dimensional Gaussian torus model. We
will show that the threshold U = 4 represents — roughly speaking — the
“relaxation distance for simultaneous convex equilibrium in the particle space”.
Let us return now to (21.11). Using (21.13)–(21.15) in (21.11), we see that
(21.12) is satisfied, and we have the following upper bound via trivial numerical
calculations: 
It is based on the fact that the infinite sum is dominated by its first few terms
(and also N ≥ 8j).

Next we switch to the family A5(5), i.e., the family of all sets of the form
IN(P(B; k; 5)), where k is defined in (20.41) and B ⊂ [0, 1]2 runs over all convex
subsets of the unit square.
Combining Fact 5(b) and Lemma 21.2 with p(1 − p) ≤ 1/4, we obtain the
following inequality: under the condition (21.3) and (21.6), for every γ > 0 and
every integer ℓ ≥ 1, 
Let
Applying (21.13) and (21.18) in (21.17), we have the following upper bound via
trivial numerical calculation:
where we used that
is totally negligible.
Next we switch to Aj(2), i.e., the family of all sets of the form OUT(B(k; j)) \
IN(B(k; j)), where B ⊂ [0, 1]2 runs over all convex subsets of the unit square. By
(20.38), 
Combining Fact 3, Lemma 21.2 and (21.20), we obtain the following
inequality: under the condition (21.3) and (21.6), for every γ > 0 and every

integer ℓ ≥ 1, 
Let
Applying (21.13) and (21.22) in (21.21), we have the following upper bound via
trivial numerical calculations:
where we used that log N = 27 log 10 < 70 and 1027 = N ≥ 8j.
Next we study the family Ak
(3), i.e., the family of all sets of the form OUT(P+
(B; k)) \ IN(P(B; k)), where k is defined in (20.41) and B ⊂ [0, 1]2 runs over all
convex 
subsets 
of 
the 
unit 
square. 
By 
(20.39) 
and 
(20.41), 
Combining Fact 4, Lemma 21.2 and (21.24), we obtain the following inequality:
under the condition (21.3) and (21.6), for every γ > 0 and every integer ℓ ≥ 1, 

Let
Using (21.13) and (21.26) in (21.25), we have the following upper bound via
trivial numerical calculations:
Finally we study the family Ai
(4) with i = 5, i.e., the family of all sets of the
form OUT(P(B; k; 5)) \ IN(P(B; k; 5)), where k is defined in (20.41) and, as
always, B ⊂ [0, 1]2 runs over all convex subsets of the unit square. By (20.40)
with i = 5, 
since N = 1027. Combining Fact 5, Lemma 21.2 and (21.28), we obtain the
following inequality: under the condition (21.3) and (21.6), for every γ > 0 and
every integer ℓ ≥ 1, 
Let

Using (21.13) and (21.30) in (21.29), we have the following upper bound via
trivial numerical calculations:
Combining (21.16), (21.19), (21.23), (21.27) and (21.31), we have
We recall (21.5) with the choice N = 1027, U = 4, ℓ = 100 (see (21.13)):
where Ga, le, ar and Me stand, respectively, for Gauss, length, area and Measure.
What we do next is a routine application of the simple Markov’s inequality
(see (21.38) below). Let

where k is defined by (20.41). Let ΩGauss(bad) be the set of those ω ∈ ΩGauss
such that
where
according as
Combining (21.32)–(21.37), we obtain the upper bound
Let
By (21.38)
representing a totally overwhelming majority. By (21.35), for every ω ∈
ΩGauss(good)
Let ω ∈ ΩGauss(good) be fixed. Then for every real number 0 < α < e−1000,
let Z(α) = Z(ω; α) denote the number of pairs (A, m) with A ∈ A0 and 0 ≤ m <
(2102 
− 
4)e1000 
integer 
such 
that 
holds with γ(A) defined by (21.36)–(21.37). A standard double counting
argument gives the equality
By (21.41)–(21.43) we have

which implies that Z(α) = 0 for some 0 < α < e−1000. That is, for every ω ∈
ΩGauss(good) there exists a real number 0 < α = α(ω) < e−1000 such that 
holds simultaneously for every set A ∈ A0 and every integer 0 ≤ m < (2102 −
4)e1000, and γ(A) is defined by (21.36)–(21.37).
22. Simultaneous Square-Root Equilibrium Relative to
Nice Sets (III)
For every convex set B ⊂ [0, 1]2, let
denote the inscribed approximation of B (see (20.36) with i = 5, and k is
determined 
by 
(20.41)), 
and 
let 
denote the circumscribed approximation of B (see (20.37)).
Let ω ∈ ΩGauss(good) be fixed, and let 0 < α = α(ω) < e−1000 be the
corresponding real number in (21.44). Since (22.1) is a disjoint union, by (21.44)
we 
have 
for 
all 
integers 
0 
≤ 
m 
< 
(2102 
− 
4)e1000, 

and repeating the same argument in the other direction,
where we used (21.14), (21.15) and (21.18).
Similarly, by (22.2), (22.4) and (21.44) we have

where
and we used the numerical fact
By (21.20), (21.24) and (21.28),

and using it in (22.6), we have
By (22.4) and (22.7),
and similarly, by (22.5) and (22.7), and repeating the same argument in the other
direction,
Combining (21.40), (22.8), (22.9) we obtain the following lemma.
Lemma 22.1. Let Y(Gauss; ω; t), ω ∈ ΩGauss be the simplest 2-dimensional
Gaussian torus model with N = 1027 particles. Then there exists a (measurable)
subset ΩGauss(good) of ΩGauss, representing an overwhelming majority in the
quantitative sense 
which satisfies the following property. For every ω ∈ ΩGauss(good) there is a
real 
number 
0 
< 
α 
= 
α(ω) 
< 
e−1000 
such 
that 
holds simultaneously for all convex sets B ⊂ [0, 1]2 and all integers 0 ≤ m <
(2102 − 4)e1000.

We recall that the average speed of a particle in our model is 103 m/s, and the
particle space is the unit square [0, 1]2 of side length 1 m. Then the time interval
4 ≤ t ≤ 4 · 2100 is about 1027 seconds, which is an incredibly long time: it is
roughly billion times the age of the universe. The sequence 4 + α + me−1000,
where m runs over the integers in 0 ≤ m < (2102 − 4)e1000, is an extremely dense
arithmetic progression of time points in the very long interval 4 ≤ t ≤ 4 · 2100.
The message of Lemma 22.1 is that, starting from an arbitrary initial
configuration, the overwhelming majority of the time evolutions of the 2-
dimensional Gaussian torus model with N = 1027 particles (see (22.10)) reaches
“simultaneous convex equilibrium in the particle space” very fast. Indeed, the
threshold U = 4 represents (roughly speaking) the “relaxation distance for
simultaneous convex equilibrium”. This equilibrium is in fact a square-root
equilibrium (see (22.11)), and the system stays in this square-root equilibrium
for a very long time (billion times the age of the universe).
The last almost trivial step is to upgrade “every time point of an extremely
dense arithmetic progression in the very long time interval 4 ≤ t ≤ 4 · 2100” to
“every time point in the very long time interval 4 ≤ t ≤ 4 · 2100”, that is, to
extend the discrete sequence to the whole interval. It is a routine approximation
argument that goes as follows. Given a compact plane set A ⊂ R2 and an
arbitrary real number δ > 0, let 
and similarly, let
It is a well-known fact that if A is convex then both A(−δ) and A(δ) are convex.
(Indeed, the statements are almost trivial for convex polygons, and we can finish
by taking limit.) Now let ω ∈ ΩGauss(good), and also assume the extra
requirement that no particle has speed ≥ e500 meter per second. Since the average
speed is 103 meter per second, and the tail of the Gaussian velocity distribution
is superexponentially small, it means the exclusion of a tiny part of ΩGauss such
that its ProdMeasGauss-measure is much less than e−2000. Let A ⊂ [0, 1]2 be an
arbitrary convex set, and let t′ ∈ [4, 2102] be an arbitrary time instant. There is a
member tm = 4 + α + me−1000 (with some 0 < α = α(ω) < e−1000 and 0 ≤ m < (2102
− 4)e1000 integer) of the arithmetic progression in Lemma 22.1 such that |t′ − tm|
< e−1000. Choosing δ = e−500, consider the subset A(−δ) of A. We have the trivial
area estimation 

By Lemma 22.1 and (22.14),
If a particle is in A(−δ) at t = tm but not at t = t′, then that particle must have
exceptionally large speed. Indeed, since |t′ − tm| < e−1000 and δ = e−500, that
particle must travel a distance ≥ δ = e−500 meter in a time interval of less than e
−1000 seconds, implying a speed ≥ e500, which is impossible by hypothesis. Thus
we have 
Repeating the argument with A(δ) instead of A(−δ), we obtain the other direction
This implies the following upgrading of Lemma 22.1.
Lemma 22.2. Let Y(Gauss; ω; t), ω ∈ ΩGauss be the simplest 2-dimensional
Gaussian torus model with N = 1027 particles. Then there exists a (measurable)
subset ΩGauss(good) of ΩGauss, representing an overwhelming majority in the
quantitative sense 
which satisfies the following property. For every ω ∈ ΩGauss(good)
holds simultaneously for all convex sets B ⊂ [0, 1]2 and all times 4 ≤ t ≤ 2102.
Of course the message is exactly the same as that of Lemma 22.1. Again the
threshold U = 4 represents the surprisingly short “relaxation distance for
simultaneous convex equilibrium”, and this equilibrium is a square-root
equilibrium. The system stays in this square-root equilibrium for a very long
time (billion times the age of the universe). The relatively large constant factor
500 is basically accidental. It comes from the complexity of the approximation
technique, and with more work one should be able to substantially reduce its
value.
What happens if we increase the number N of particles? If we replace N =
1027 with an arbitrary large N, then, repeating the proof above, the upper bound
500
 (with N = 1027) in Lemma 22.2 is replaced by c0
 and the
threshold U = 4 is replaced by U = c1
, where c0 > 0 and c1 > 0 are some

absolute constants independent of N. This justifies the term simultaneous convex
square-root equilibrium.
Note that Lemma 22.2 has a straightforward analog for the closed orbit
models discussed in Secs. 12–13 (the same proof works).
The 2-dimensional approximation argument above can be generalized for the
3-space, and a key step in the proof is to replace Sas’s theorem by the following
result of Macbeath in higher dimensions; see [Mac51]. For every dimension d ≥
3 and integer n ≥ d + 1, among all d-dimensional convex bodies of volume one,
the only extremal sets that minimize the volume of the largest inscribed
polytopes with n vertices are the spheres and the ellipsoids. We apply Macbeath
theorem in the 3-space. A novelty of the 3-space is that there is no analog of the
regular n-gon inscribed in a circle in higher dimensions. Instead we choose a
random n-element point set on the unit sphere with uniform distribution (with
respect to the surface area), and consider the convex hull of this point set. This
defines a “random n-polyhedron”, which can succesfully replace the regular n-
gon in many cases. It is easy to see that the volume of the set-difference = ball of
unit volume minus its inscribed “random n-polyhedron” is O(1/n) (instead of
O(1/n2) on the plane), which is just(!) enough for our purposes. The rest is a
more-or-less straightforward generalization of the 2-dimensional approximation
argument above; we omit the details. The price that we pay for the weaker
approximation in the 3-space (O(1/n) instead of O(1/n2)) is an extra factor of log
N-power, which is basically negligible. More precisely, in the 3-dimensional
case the “simultaneous convex equilibrium” is still a square-root equilibrium
apart from a log N-power (like 
 is replaced by 
(log N)2).
What makes dimensions 2 and 3 special is that in dimension d ≥ 4 the
“simultaneous convex equilibrium” is not a square-root equilibrium, due to an
inevitable discrepancy of size N(d−1)/d+1) (note that (d − 1)/(d + 1) ≥ 3/5 > 1/2 for
d ≥ 4). The “inevitable discrepancy” comes from the following result (see
Schmidt [Sch75]).
Schmidt’s discrepancy theorem for convex sets. Given an arbitrary set X =
{x1, x2, . . . , xN} of N points in the d-dimensional unit cube [0, 1]d, there exists a
convex set A ⊂ [0, 1]d such that 
where the constant factor c0(d) > 0 depends only on the dimension.
For the sake of completeness we include the simple but ingeneous proof of

Schmidt’s theorem. We can summarize the proof in one sentence: we start with a
ball, consider many disjoint solid spherical caps of certain size, and enforce large
discrepancy by a process of removing or keeping a solid spherical cap depending
on whether it is “rich” (contains a point from X) or “poor” (does not contain a
point from X); what is left at the end of the removal process is clearly a convex
set.
Here comes the detailed proof. Let B be the ball of diameter one contained in
[0, 1]d, and let S denote its surface. Let C1 be a solid spherical cap of B such that
its d-volume is 1/2N (a solid spherical cap is a solid bounded by the sphere and a
(d − 1)-dimensional hyperplane in the d-space). We now pick as many pairwise
disjoint solid spherical caps of B with d-volume 1/2N as possible, say C1, C2, . . .
, Cm. Elementary calculation gives 
Indeed, if the “radius” of a small solid cap of B is r, then its surface area is
around rd−1 and its “height” is around r2, so the volume is around rd+1. For Ci we
have rd+1 ≈ 1/2N, which implies that r is around N−1/d+1, so C1 has surface area
around N−(d−1)/(d+1), and the disjointness of the caps finishes the proof of (22.18).
Given a sequence ε1 ∈ {±1}, ε2 ∈ {±1}, . . . , εm ∈ {±1}, we define a convex
subset of B by removing the solid spherical caps Ci with εi = −1: 
We clearly hav
But
which is either −1/2 or ≥ 1/2. Thus we can choose εi ∈ {±1} such that
for every 1 ≤ i ≤ m, and using it in (22.19), we have

And so either A = B(ε1, ε2, . . . , εm) or A = B(−ε1, −ε2, . . . , −εm) has the property 
where in the last step we used (22.18). This completes the proof of Schmidt’s
theorem.
We conclude Sec. 22 with the following long-term problem.
What can we say about the alternation of equilibrium and off-equilibrium
states? To answer this question, we consider the simplest 3-dimensional
Gaussian torus model (r1(t) = · · · = rN(t) = (t, 0, 0)), and let ε > 0 be a fixed
small positive constant (e.g. ε = 1/10 or 1/100). We modify the concept of
square-root equilibrium (in the particle space) by replacing N1/2 with N(1+ε)/2. We
say that at time t the system is in (1 + ε)/2-power box-equilibrium if for every
rotated box in the unit cube, the number of particles in the box is very close to
the expected value (= N times the volume of the box) in the quantitative sense
that the difference has absolute value less than N(1+ε)/2. (That is, we replace
square-root with (1 + ε)/2-power, and restrict the test sets to rotated boxes.)
Since rotated boxes are convex sets, the results of Secs. 20–22 imply the
following. Starting from an arbitrary initial configuration Y = {y1, y2, . . . , yN},
the typical individual time evolution of the system reaches the state of (1 + ε)/2-
power box-equilibrium extremely fast in time less than 
, and the system
stays in the state of (1 + ε)/2-power box-equilibrium for an exponentially long
time in the range of 
In view of Theorem 3.1, the individual time evolution of the system eventually
leaves the state of (1 + ε)/2-power box-equilibrium, but of course later it goes
back to the “majority state” of (1 + ε)/2-power box-equilibrium again, and we
have this infinite alternation of equilibrium and off-equilibrium states. In a
sufficiently long time interval 0 ≤ t ≤ T, the total length of the times t for which
the system is not in (1 + ε)/2-power box-equilibrium is an exponentially small
part of T in the range of 
Here is a nutshell description of a typical time evolution: if the system is in off-
equilibrium, then it goes back very fast to (1 + ε)/2-power box-equilibrium, and
the system stays in this state for an exponentially long time in the range of
(22.20); later in view of Theorem 3.1, the system eventually leaves the state of

(1 + ε)/2-power box-equilibrium, then it goes back again from off-equilibrium to
(1 + ε)/2-power box-equilibrium, and the system stays in this state for an
exponentially long time in the range of (22.20), and so on. A typical time
evolution has infinitely many alternations of long time intervals of (1 + ε)/2-
power box-equilibrium separated by short off-equilibrium intervals. The
equilibrium blocks are exponentially long in the range of (22.20), and the off-
equilibrium blocks are much shorter. For example, starting from off-equilibrium,
the typical time evolution goes back to equilibrium extremely fast in time less
than 
. We can prove, however, that if we wait long enough, there will be
relatively long off-equilibrium blocks, much longer than 
. This follows
from a combination of Theorem 3.1 (“superdiscrepancy”) and the following
result. For the details of the deduction, see the Remarks below.
Theorem 22.1. Consider the simplest 3-dimensional Gaussian torus model kind
(Y; ΩGauss) where r1(t) = · · · = rN(t) = (t, 0, 0) (i.e., each particle moves on a
straight line with constant speed; different particles have different speed). Let 1
> ε > 0 be arbitrary but fixed. Then there is a subset Ω∗Gauss ⊂ ΩGauss such that
ProdMeasGauss(Ω∗1) > 9/10, and for every 
there is an initial configuration Z = Z(ε; ω) = {z1, . . . , zN} such that, starting
from (Z, ω) at t = 0, in the interval 
the time evolution of the system does not reach any (1 + ε)/2-power box-
equilibrium state, assuming N is large enough in terms of ε. What is more, if t is
in the interval (35.18), then the number of particles in the left half [0, 1/2]×[0,
1]×[0, 1] of the unit cube is more than N/2+N(1+ε)/2 (assuming N is large enough
in terms of ε).
Remarks. First note that there is an analog result for the closed orbit models
introduced in Secs. 6–7 (the proof is the same).
The existence of relatively long off-equilibrium blocks (in the sense of being
much longer than 
) can be deduced from Theorem 3.1 and Theorem 22.1
as follows. We can clearly assume that for ω ∈ Ω∗
1 the 3N initial velocity
coordinates are linearly independent over the rationals (since the complement set
has zero ProdMeas1-measure). Therefore, starting from (Y, ω), if we wait long
enough, the Kronecker–Weyl equidistribution theorem implies that the system

will get arbitrarily close to (Z, ω) with Z = Z(ε; ω) = {z1, . . . , zN}. More
precisely, given any δ > 0, it will happen that the image of yi gets δ-close to zi, 1
≤ i ≤ N. Since δ > 0 can be arbitrarily small, Theorem 22.1 applies, and
guarantees the existence of an off-equilibrium block much longer than 
 (=
length of the initial off-equilibrium block); namely, the length is polynomial in
N, see (22.22). In fact, the maximum length can be close to 
 if ε > 0 is small.
On the other hand, we mention (without proof) that for typical time evolution
the maximum length of the off-equilibrium blocks is certainly less than N,
independently of the initial configuration.
Next consider the (1 + ε)/2-power box-equilibrium blocks. The average
length is in the exponential range of (22.20). On the other hand, we can prove
(but omit the proof) that, for typical time evolution the maximum length of the
equilibrium blocks is less than some exponential function of N, independently of
the initial configuration.
Proof of Theorem 22.1. Let
It is trivial from the definition of the Gaussian/Maxwellian velocity distribution
that
assuming N is large enough in terms of ε > 0.
Let ω ∈ Ω∗
Gauss be arbitrary. By rearranging the indices, we can assume that
For every 1 ≤ j ≤ N1 = N − 2N(1+ε)/2, let ξj be a random variable uniformly
distributed in the unit interval, and assume that ξj, 1 ≤ j ≤ N1 are independent.
Since the torus is translation invariant, for notational convenience we can switch
from the interval [0, 1/2) to [1/4, 3/4), i.e., we translate the left half of the unit
cube to the right by 1/4. The product form of the test set explains why it suffices
to study the first coordinates of the particles.
Let η = N−3/4, and write

For 1 ≤ j ≤ N1, let
where {y} stands for the fractional part of a real number y. Notice that for a fixed
t, ζj(t), 1 ≤ j ≤ N1 are independent 0-1 valued Bernoulli random variables with p
= length(I1) = 1/2 − 2η. Using Bernstein’s large deviation inequality, 
holds for every fixed time instant t. Let
be fixed. We apply (22.26) with λ = Nε/2 for every t of the form 0 < t = k/N ≤ T,
k integer (which represents TN time points). By (22.27) 
so by (22.26), for every t of the form 0 < t = k/N ≤ T, k integer, there exist real
numbers ξj(0) ∈ [0, 1), 1 ≤ j ≤ N1 such that 
holds for at least
indices j in the interval 1 ≤ j ≤ N1 (in the last step of (22.28) we used that N is
large enough). Since no particle has speed ≥ N1/4, if a particle was in the box B1
= I1 × [0, 1) × [0, 1) at time t = k/N, then this particle stays in the larger box B2 =
I2 × [0, 1) × [0, 1) in the whole time interval k/N ≤ t < (k + 1)/N.
Now we are ready to specify the desired point configuration Z = {z1, . . . ,
zN} for the box B2. Let ξj(0) be the first coordinate of zj for 1 ≤ j ≤ N1, and let 1/2
be the first coordinate of zj for N0 < j ≤ N (the second and third coordinates can
be chosen freely).
Then it follows from (22.28) that the box B2 = [1/4, 3/4) × [0, 1) × [0, 1)
contains more than 
particles with index j in 1 ≤ j ≤ N1 during 0 ≤ t ≤ T, assuming (22.27) holds.

On the other hand, by (22.24),
Choosing
and combining the fact
with (22.29), it follows that the box B2 = [1/4, 3/4) × [0, 1) × [0, 1) contains
every particle with index j in N1 < j ≤ N during 0 ≤ t ≤ T0 (see (22.30), and use
the fact that 1/2 is the first coordinate of the starting point zj for N1 < j ≤ N).
Comparing (22.27) and (22.30), we see that T0 satisfies (22.27) assuming N
is large enough in terms of ε > 0.
Summarizing, the box B2 = [1/4, 3/4) × [0, 1) × [0, 1) contains more than N
− N(1+ε)/2 + (N − N1) = N − N(1+ε)/2 + 2N(1+ε)/2 = N + N(1+ε)/2 particles during 0
≤ t ≤ T0, which completes the proof of Theorem 22.1.
23. On the Square-Root Logarithmic Threshold in the
Gaussian Case
The majority of sections so far were all applications of Theorem 4.2. Theorem
4.2 has a somewhat peculiar “square-root logarithmic threshold” in the following
sense. The key condition in (4.12) 
is equivalent to
The square-root-logarithmic (23.1) is the (shockingly small!) threshold for
“conf-space equilibrium”. We may say that it is the threshold when the typical
time evolution of a system with N = d/3 particles and Gaussian initial velocity
distribution reaches equilibrium in the configuration space.
We have the same threshold in Theorem 4.1 where the threshold is denoted
by T0 = T0(d). Theorems 4.1–4.2 are both dimension-free, complexity-free and
start-free results. The only dependence on the dimension d is in the square-root

logarithmic threshold — it represents an extremely weak dependence. For
example, 
choosing 
d 
= 
101000 
in 
Theorem 
4.1, 
we 
have 
Perhaps the reader is wondering: why do we need the strange threshold T0 =
T0(d) in Theorem 4.1? Or equivalently: why do we ignore the initial part 
of the torus lines? Iss it really necessary? The answer is yes: we have to ignore
the initial part, because we certainly cannot expect any kind of uniformity in the
slightly shorter interval 
Notice that interval (23.2) is basically twice longer than (23.3), so they have the
same order 
.
In this section we explain why we cannot expect any kind of uniformity in
the interval (23.3). Consider the simplest 3-dimensional Gaussian torus model
starting from the origin (Big Bang). The curve ΓBB;ω(t) of the whole system in
the configuration space Id is a straight line in the d-space (with d = 3N) modulo
one: 
where
and
Note that BB in 
BB;ω(t) refers to Big Bang, and the product space ΩGauss is
equipped with the usual (Gaussian) product measure ProdMeasGauss.
Omitting the arrow in 
BB;ω(t), we obtain the N-element point set in the
particle 
space 
I3 
= 
[0, 
1)3 
(3-dimensional 
unit 
torus): 
Consider the following very simple “nice” test function in the particle space
We claim that, for every t in the time interval
(which is the same as (23.3)), we have the following lower bound for the integral

where (23.10) holds for the majority of ω ∈ ΩGauss. More precisely, we prove
the following lemma.
Lemma 23.1. For every t ∈ [0, T], where T is defined in (23.8), there exists a
(measurable) 
subset 
Ω*(t) 
⊂ 
ΩGauss 
with 
(say) 
such that the integral
has the lower bound
which holds for every ω ∈ Ω*(t).
Remark. The choices of the constants 60 and 99.99% are accidental. With an
appropriate choice of “−o(1)” in (23.8) if N is large, we could upgrade 99.99% to
99.9999%, and so on. As the proof below shows, this is just a matter of routine
calculation.
Proof of Lemma 23.1. First we evaluate the integral I[ω; f0; t]; see (23.8) and
(23.10). By using the well-known fact 
for all n ∈ Z3 except the trivial case n = 0, we have with n1 = (1, 0, 0), 
Next we integrate (23.11) over the big initial velocity space ΩGauss = ([0, ∞) ×

S2)N: 
Applying Lemma 9.1 with d = 3 in (23.12), we obtain
The next step in the proof of the lemma is to estimate the “variance”
where for simplicity we write dω = dProdMeasGauss(ω).
By using (23.11) we have
Integrating (23.15) over ΩGauss, and using again Lemma 9.1 with d = 3, we have

where
which 
corresponds 
to 
the 
case 
(k1, ℓ1) 
= (k2, 
ℓ2) 
in 
(23.15), 
which corresponds to the case (k1, ℓ1) = (ℓ2, k2) in (23.15) (where the factor four
comes 
from 
the 
fact 
that 
4n1 
= 
(4, 
0, 
0)), 
which corresponds to the case k1 = k2, ℓ1 ≠ ℓ2 in (23.15) (notice that S3 has
coefficient 2 in (23.16) due to the symmetric case k1 ≠ k2, ℓ1 = ℓ2 that has exactly
the same contribution), 
which corresponds to the case k1 = ℓ2, ℓ1 ≠ k2 in (23.15) (again S4 has coefficient
2 in (23.16) due to the symmetric case k2 = ℓ1, ℓ2 ≠ k1 that has exactly the same
contribution), and finally, 
which corresponds to the case where k1, ℓ1, k2, ℓ2 are all different.
On the other hand, (by (23.13)
Combining (23.14)–(23.22), we have

Let
By (23.23), (23.24) and Chebyshev’s inequality, we obtain
Let t = T > 0 be the solution of the equation
that is, with d = 3N,
Clearly
so, we can write
which justifies the choice of T in (23.9).
By (23.13),

Combining (23.24) and (23.27), for 0 ≤ t ≤ T and ω ∈ Ω1(t) we have
which implies that
Clearly
and combining this fact with (23.28), we obtain that for every 0 ≤ t ≤ T and every
ω ∈ Ω1(t) 
where in the last step we used (23.26). Since 106/2 > 60, by choosing Ω*(t) =
Ω1(t), Lemma 23.1 follows from (23.25) and (23.29).
Next write
where Ω*(t) is defined in Lemma 23.1.
Using Lemma 23.1 we can easily derive the lower bound
Indeed, let
Then by Lemma 23.1, (23.30) and Fubini’s theorem (“double-counting
argument”)
which implies (23.31).

Given an N-element set in the 3-dimensional unit cube
let (d = 3N)
denote the corresponding point in the configuration space.
Let S = S(f0; 60) ⊂ [0, 1)d, d = 3N be the set of those points 
in the configuration space which have average square-discrepancy > 60N with
respect to the test function f0 defined in (23.8) (the motivation for the factor 60
comes 
from 
Lemma 
20.1). 
Formally, 
We claim that
where vold stands for the d-dimensional Lebesgue measure.
To prove (23.33), we introduce the following auxiliary subsets of the
configuration space: for every k ≥ 1 let
Notice that the union of the sets Sk covers S(f0; 60):
Indeed, for
we have

implying that  ∉ S(f0; 60).
On the other hand, it is easy to estimate the measure of the set Sk from above.
Indeed, 
for 
a 
fixed 
translation 
w 
we 
have 
the 
upper 
bound 
We show that (23.36) follows from Bernstein’s large deviation type inequality in
probability theory. Indeed, since vold is a product measure, the sum in (23.36)
(see also (23.8)) 
with
represents two sums of independent random variables, where f1 and f2 are real
valued.
To prove (23.36), we apply the general form of Bernstein’s inequality (see
the upper bound before (11.8)) for fj, j = 1, 2 with n = N, M = 1, τ = 
,
|f1| 
≤ 
1 
and 
|f2| 
≤ 
1, 
and 
obtain 
the 
upper 
bound 
In the last step we used τ ≤ N, since otherwise 4(k + 2)N > N2, implying that the
volume in (23.36) is trivially zero.
Since (see (23.37)–(23.38))

(23.39) implies (23.36).
Applying (23.36) in (23.34), we have
Combining (23.35) and (23.40),
which proves (23.33).
Summarizing, by (23.31) the majority of the torus lines in the configuration
space [0, 1)d (d = 3N) starting from the origin — representing the time evolution
of the Gaussian system (see (23.7) and (23.30)) ΓBB;ω(t), ω ∈ Ω∗∗ starting from
Big Bang — spend at least 99% of the time 0 ≤ t ≤ T (see (23.30)) in the small
subset S(f0; 60), which is less than 1% (see (23.33)) of the configuration space.
The huge discrepancy between the 99% actual time and the 1% expected time
contradicts uniformity in the initial time interval (23.3). This proves what we
claimed at the beginning of the section: in the Gaussian case the square-root
logarithmic threshold is unavoidable.
In the next section we show, among others, that, by replacing the Gaussian
initial velocity distribution with some other velocity distributions, the already
shockingly small square-root logarithmic threshold can be upgraded to an even
better absolute constant (independent of the number of particles, or equivalently,
independent of the dimension of the configuration space). This means that,
independently of the initial point configuration, the typical time evolution of the
system reaches conf-space equilibrium at time t0, where t0 is less than an
absolute constant. We may say, therefore, that the (typical) time evolution of
such a system exhibits instant conf-space equilibrium.
24. Beyond the Applications of Theorem 4.2
The message of Theorem 4.2 is that the typical time evolution of an off-
equilibrium Bernoulli gas model with Gaussian initial velocity distribution

reaches equilibrium in the configuration space — state of Configuration
Equilibrium — very quickly: superexponentially fast. We briefly recall some of
the consequences of Theorem 4.2 that we discussed so far.
In Sec. 5 we studied the classical Bernoulli gas model, where the gas
molecules are represented by point billiards, and assumed Gaussian initial
velocities (via unfolding this Bernoulli billiards-in-a-box model can be reduced
to the simplest Gaussian torus-billiard model). We proved that, starting from an
arbitrary initial configuration, for the typical time evolution the relaxation
distance to reach square-root equilibrium in the particle space — i.e., the
necessary number of “jumps” per particle in the torus model, which is half of the
number of bounces in the billiard model — is about 
, that is, square-root
logarithmic in terms of the number of particles. Moreover, the system stays in
square-root equilibrium (meaning an arbitrary but fixed measurable test set in
the unit cube) for a very long time; say, in the range of NlogN, with the possible
exception of a totally negligible set of times t.
In Secs. 6 and 7 we proved similar long-term stability results for two
spherical and two polar models (closed orbit systems). Again the relaxation
distance to reach square-root equilibrium was the same surprisingly small 
.
In Secs. 8 and 15 we proved that in the simplest 3-dimensional Gaussian
torus model the relaxation distance to reach snapshot randomness (Poisson and
CLT) is the same 
, and again we have long-term stability. Section 16 is an
illustration of how to extend these results to closed orbit systems.
In Secs. 20–22 we proved that in the simplest (at least 2-dimensional)
Gaussian torus model the relaxation distance to reach simultaneous square-root
equilibrium relative to nice sets is the usual 
, and again we have long-term
stability.
The common feature of these results (all based on Theorem 4.2) is the
square-root logarithmic threshold for the relaxation distance in the Gaussian
case, and the long-term stability of the equilibrium. The square-root logarithmic
threshold represents a superexponentially fast approach to equilibrium, and as
we proved in Sec. 24, in the Gaussian case the square-root logarithmic threshold
is best possible — it cannot be improved.
Superexponentially fast approach to equilibrium is already very impressive,
but as it turns out, we can do even better. Replacing Theorem 4.2 with Theorem
13.4 in the proofs of the results listed above, we can reduce the threshold 
to an absolute constant independent of N.

Instant conf-space equilibrium. To give an illustration, we derive an analog of
Theorem 5.1 by replacing Theorem 4.2 with Theorem 13.4 (one can obtain
exactly the same way the analogs of the rest of the corollaries of Theorem 4.2
mentioned above). According to Sec. 13 (and in particular to Theorem 13.4) we
consider now a more general torus model where the particles move on torus lines
with (possibly) varying speeds, and every particle has its own (almost arbitrary)
smooth initial speed distribution. The curve of the whole system in the
configuration 
space 
is 
denoted 
by 
where t is the time,
is the vector (= point in the configuration space) formed from the set
of the initial point configuration at the start t = 0,
represents a family of functions such that
and
where α0 ≥ 1, 0 < α ≤ α1 are some absolute constants.
Moreover, let I denote an arbitrary finite interval of positive length. Assume
that
uniformly for all T ≥ β0, where β0 ≥ 1 and 0 ≤ β < 1 are absolute constants.
(About the question of how to satisfy conditions (24.4)–(24.6); see the beginning
of Sec. 13.) The trajectory of the kth particle is yk + ρkrk(t)ek ∈ R3, 1 ≤ k ≤ N
modulo one, representing a (possibly) varying speed motion on a torus line in the

direction ek. For the set of N particles at time t we use the notation 
(as usual, the switch from the point set in the particle space to the point in the
configuration space is indicated by an extra arrow  on top of Y).
Let d = 3N, let f ∈ L2(Id), Id = [0, 1)d is the d-dimensional unit torus (i.e., we
extend f over the whole d-space Rd periodically), and, as usual, write 
Since the torus is translation invariant, it suffices to study the time discrepancy
of 
the 
-independent 
part 
(t) 
in 
(24.1): 
where (t) = (R; ρ1, e1, . . . , ρN, eN; t) and 0 < T1 < T2.
We turn now to the family
of probability density functions, where the kth function gk defines the initial
speed distribution Pr[ρk ≤ u] = 
 gk(y) dy of the kth particle (1 ≤ k ≤ N). We
assume that 
where the last requirement means that the “expectation = mean-speed is finite”.
The corresponding initial velocity space is
equipped with the product measure ProdMeasG, where the kth factor [0, ∞)×S2 in
(24.9) has the normed surface area for the unit sphere S2 ⊂ R3 and has the
probability density function gk for [0, ∞).
By using (24.9), we can rewrite the time discrepancy (24.8) as follows:
where

and 0 < T1 < T2.
We take the square of the absolute value of the time discrepancy
and study the following average (d = 3N)
where dSA (e) means the normed surface area on the unit sphere S2, i.e., SA
(S2) = 1.
We recall the definition of the so-called 3-dimensional “isotropic Fourier
transform” 
of 
g 
= 
gk, 
1 
≤ 
k 
≤ 
N: 
where w is an arbitrary 3-dimensional vector, dSA(v) represents the surface area.
Fg(w) defines a real-valued function depending only on the length w = |w| of the
input 
vector, 
and 
we 
have 
By the Riemann–Lebesgue theorem Fg(w) → 0 as w → ∞.
We recall Theorem 13.4.
Theorem 13.4. Assume R satisfies (24.4)–(24.6), G satisfies the “vanishing
property”
for the 3-dimensional “isotropic Fourier transforms” Fgk (for concrete examples

of 
such 
probability 
distributions, 
see 
(13.46)–(13.49)), 
and 
Then
Let B ⊂ I3 = [0, 1)3 be an arbitrary but fixed measurable test set in the
particle space (= unit cube), where vol(B) denotes the 3-dimensional Lebesgue
measure.
Consider now a 3-dimensional torus model Y(R; ω; t) (in the particle space
I3) satisfying the hypothesis of Theorem 13.4. The family of time evolutions ω ∈
ΩG of this torus model is represented by the family of curves lines (see (24.2)) 
in the configuration space Id, all starting from the same point  = (y1, . . . , yN) ∈
Id.
Repeating (5.7), for an arbitrary τ > 0 write
where
with zk = (z3k−2, z3k−1, z3k), 1 ≤ k ≤ N.
Since the torus Id is translation invariant, we apply Theorem 13.4 with f = χS
where S is the translated copy S = S(B; τ) −  of S(B; τ) in the torus Id. Note that
in the special case of a characteristic function f = χS, S ⊂ Id, 
We recall the upper bound in (11.11):
and using it in Theorem 13.4 with W = 2kU, (24.13) yields

assuming
By (24.14), (24.15), and using S = S(B; τ) − , we have
where, as usual, length stands for the 1-dimensional Lebesgue measure.
Combining (24.16) and (24.17), we obtain the following result.
Theorem 24.1. Let Y(R; ω; t), ω ∈ ΩG be a 3-dimensional torus model
satisfying the hypothesis of Theorem 13.4, and let B ⊂ [0, 1)3 be a measurable
test 
with 
3-dimensional 
Lebesgue 
measure 
vol(B). 
Assume 
that 
Then for every τ > 0 and every integer k ≥ 1,
where

Similarly to Theorem 5.1, Theorem 24.1 is an extremely powerful result, due
to the same reason: the superexponentially small factor 
This guarantees the long-term stability exactly the same way as we demonstrated
on examples in Sec. 11.
The crucial difference between Theorems 5.1 and 24.1 is that the threshold 
 
in 
the 
former 
is 
reduced 
to 
a 
constant 
in the latter, where the constant threshold (24.19) does not depend on N. This is
why we say that the (typical) time evolution of a system in Theorem 24.1
exhibits instant conf-space equilibrium.
Note that Theorem 24.1 has another advantage over Theorem 5.1: it is about
a more general torus model where the particles move on torus lines with
(possibly) varying speeds, and every particle has its own, possible different,
smooth initial speed distribution. The two crucial requirements for instant conf-
space equilibrium are: (1) the “vanishing property”, and (2) the constant
exponent β in (24.6) satisfies the inequality β < 1.
Beyond Theorems 4.2 and 13.4. Of course in the proof of Theorem 24.1 we can
replace Theorem 13.4 with Theorem 13.1 or with Theorem 13.2 or with
Theorem 13.3. Thus we obtain three analogs of Theorem 24.1 with the following
thresholds: (1) if R satisfies (24.4)–(24.6), G satisfies the “polynomial decay”
condition 
and γ > 3, αγ > 1, β < 1,
(2) if R satisfies (24.4)–(24.6), G satisfies the “exponential decay” condition 
and β < 1,

and finally,
(3) if R satisfies (24.4)–(24.6), G satisfies the “superexponential decay”
condition 
and β < 1,
In view of Lemma 13.1 we may say that the threshold depends mainly on the
smoothness of the probability density functions gk, 1 ≤ k ≤ N.
Two-dimensional case where the particles move on general non-linear
curves. In Theorems 4.2 and 13.1–13.4 all particles stay on torus lines, and the
only difference is whether the particles move with constant speeds or with
varying speeds. In Sec. 14 we explained how to extend Theorems 13.1–13.4
from torus lines to arbitrary non-linear curves in the 2-dimensional case (the case
of dimension d ≥ 3 is an open problem).
We recall the notation of Sec. 14: in the 2-dimensional case the particle space
is the unit torus [0, 1)2 = I2, and the curve of the whole system in the
configuration 
space 
has 
the 
form 
where t is the time,
is the vector (= point in the configuration space) formed from the set
of the initial point configuration at the start t = 0, ϑk ∈ SO(2) are 2-dimensional
rotations 
(we 
could 
simply 
write 
ϑk 
∈ 
[0, 
2π)), 
and 
finally 
represents a family of parametrized curves on the plane. Note that the 1-
dimensional rk(t) in (24.3) is replaced by the 2-dimensional rk(t) in (24.25); the
dimension increase is indicated by putting an arrow on top of R.

We assume that
where 1 + κ > α > 0, α0 ≥ 1, κ ≥ 0, and r′k(x) is the derivative of the parametrized
curve rk(x).
Moreover, let C(c; ) denote an arbitrary circle centered at c ∈ R2 with radius
, and assume that 
uniformly for all T ≥ β0 (note that 1 + κ > α > 0, α0 ≥ 1, κ ≥ 0, κ0, β0 ≥ 1 and 0 ≤
β < 1 are absolute constants).
We also need a family of probability density functions G = (g1, g2, . . . , gN),
where gk is the distribution of the “magnification factor” ρk, i.e., Pr[ρk ≤ u] = 
gk(y) dy. An interesting special case is the simplest 2-dimensional Gaussian
distribution 
We indicate condition (24.29) by replacing G with “Gauss”.
Let us return now to Theorem 24.1. If in the proof of Theorem 24.1 we
replace Theorem 13.4 with Theorem 14.1, we obtain an analog of Theorem 24.1
with the following threshold: (4) assuming 
 satisfies (24.26)–(24.28), G
satisfies (24.29), and α > β + κ, 
Next we switch from the 2-dimensional Gaussian distribution (24.29) to the
(still 2-dimensional) case of general probability density functions G = (g1, g2, . . .
, gN).
Condition of polynomial decay. Assume that there exist real numbers γ > 2 and
γ0 ≥ 1 such that 
Note that Lemma 14.2 provides a sufficient condition for a probability density
function g to guarantee that its 2-dimensional “isotropic Fourier transform” Fg
satisfies the polynomial decay condition (24.31).
If in the proof of Theorem 24.1 we replace Theorem 13.4 with Theorem

14.2, we obtain an analog of Theorem 24.1 with the following threshold: (5)
assuming  satisfies (24.26)–(24.28), G satisfies (24.31), γ > 2, αγ > 1, α > β + κ,
Finally, note that Theorem 24.1 and its analogs guarantee the long-term
stability of equilibrium exactly the same way as Theorem 5.1 did in the
illustrations/examples in Sec. 5.
25. The Case of Singular Underlying Measure
The simplest example of singular underlying measure is the class of models that
we call compound systems with circles, or simply circles system. These closed
orbit models can be considered as a far-reaching generalization of the spherical
Great-Circle system introduced in Sec. 6. The singularity of the underlying
measure (relative to the Lebesgue measure) comes from the fact that the closed
orbits are 1-dimensional curves, i.e., they have lower dimension than the particle
space. (Another source of singularity where each particle is restricted to a
surface, and the particle space is 3-dimensional.) Let C1, C2, C3, . . . , CN be N
not necessarily different circles (we mean the curves, not the disks) in the 3-
space R3, and suppose that there are N particles such that the kth particle orbits
on Ck, 1 ≤ k ≤ N. For simplicity assume that kth particle orbits on Ck with
constant speed, where the speed depends only on k (1 ≤ k ≤ N). More precisely,
assume that the relative speed of the kth particle is vk, that is, in a time interval T
≤ t ≤ T + ℓ of length ℓ the kth particle travels arclength distance 2πRkvkℓ, where
Rk is the radius of Ck.
Let yk ∈ Ck denote the starting point of the kth particle at t = 0. For every
circle we choose an orientation, and assume that the relative constant speeds vk,
1 ≤ k ≤ N are chosen independently by the 1-dimensional normal (= Gaussian)
distribution 
(Negative speed means that the particle goes backward following the negative
orientation.)
As usual, let
denote the initial configuration at t = 0. We refer to the system (C; Y; Gauss) as a

circles system.
For simplicity assume that the N circles Ck, 1 ≤ k ≤ N are all in the unit cube
[0, 1]3, and we define the following measure on the family B of Borel sets in the
unit cube [0, 1]3: 
where Rk is the radius of Ck. We refer to MeasC as the underlying measure of the
circles system (C; Y; Gauss).
We study the usual questions: given an arbitrary initial configuration
with yk ∈ Ck, what can we say about the typical time evolution of the circles
system (C; Y; Gauss)? How long does it take to reach equilibrium? What can we
say about the stability of equilibrium?
The novelty of the circles system is that the underlying measure — the key
concept to define equilibrium — is completely different from the usual
(homogeneous) Lebesgue measure: the underlying measure is singular. In other
words, it is not absolutely continuous with respect to Lebesgue measure; so, we
do not have a corresponding density function (= Radon–Nikodym derivative).
Note that the inhomogeneous underlying measures of the closed orbit systems in
Secs. 12–13 were absolutely continuous with respect to the corresponding
Lebesgue measure (= surface area for spherical systems).
To be very precise, we explain why MeasC is a well-defined measure (i.e., σ-
additive) on the Borel σ-algebra B. The proof is a straightforward application of
a basic Extension Theorem from measure theory. First we need some standard
definitions. An elementary set in the 3-space R3 means a union of a finite
number of axis-parallel (bounded) boxes (including all possibilities of open,
closed, half-open, etc.). Let E denote the family of elementary sets in R3.
A finite, nonnegative, additive set function ϕ defined on E is said to be
regular if for every A ∈ E and every ε > 0 there exist sets F, G ∈ E such that F is
closed, G is open, F ⊂ A ⊂ G, and 

Let ϕ be a finite, regular, nonnegative additive set function defined on E.
Then we can define the ϕ-outer measure ϕ* on the family of all subset E ⊂ R3 as
follows: 
where every An ∈ E is open.
Extension Theorem. Let ϕ be a finite, regular, nonnegative additive set function
defined on E. Then ϕ*(A) = ϕ(A) for every A ∈ E; moreover, ϕ* is a measure (=
σ-additive) on a σ-algebra that contains the Borel sets. More precisely, ϕ* is a
measure on the smallest σ-algebra that contains the Borel sets and the sets E ⊂
R3 with ϕ*(E) = 0.
It is easy to check that MeasC is a finite, regular, nonnegative, additive set
function on the family of elementary sets E. So, the Extension Theorem applies,
and gives that MeasC is a measure on the Borel σ-algebra B.
We explain why we can trivially repeat the argument of Sec. 5 for the circles
system (C; Y; Gauss), and obtain long-term stability of square-root equilibrium
in the particle space [0, 1]3 with respect to an arbitrary but fixed Borel test set.
The only change that we need to make is that in the definition of square-root
equilibrium we have to replace the 3-dimensional Lebesgue measure with the
singular measure MeasC. (We talk about Borel sets instead of Lebesgue
measurable sets, because MeasC is singular: singularity implies that the σ-algebra
of MeasC-zero sets is different from the σ-algebra of Lebesgue-zero sets.) Of
course the 3-dimensional torus system of Sec. 5 is completely different from the
circles system (C; Y; Gauss) here, but the curve in the configuration space Id =
[0, 1)d with d = N, representing the time evolution of the whole circles system, is
the same. Indeed, it is again a straight line in Rd modulo one (in fact, here the
lines can start from the origin) 
where

The product space ΩGauss is equipped with the product measure ProdMeasGauss,
where the real line (−∞, ∞) has the probability density function 
(“1-dimensional normal distribution”). Notice that (25.4)–(25.5) is the perfect
analog of (11.2)–(11.3) with the minor change that d = 3N is reduced to d = N
(which just makes the case of “circles systems” slightly simpler).
Since the curve of the system in the configuration space is the same, we can
repeat the rest of Sec. 5 with the natural modifications mentioned above. That is,
again let B ⊂ I3 = [0, 1)3 be an arbitrary but fixed test set in the particle space [0,
1]3, but now B has to be Borel measurable (instead of Lebesgue measurable),
and the 3-dimensional Lebesgue measure vol(B) is replaced by the singular
measure MeasC(B).
Again the application of Theorem 4.2 in the configuration space yields a
perfect analog of Theorem 5.1, and the same holds for the rest of Sec. 5.
What happens if we want to prove long-term stability of square-root
equilibrium with respect to a whole family of nice sets (instead of a fixed Borel
test set)? Since the curve of the system in the configuration space is the same, a
straightforward repetition of the arguments in Secs. 20–22 give the analog
results as follows. Starting from an arbitrary but fixed initial configuration Y,
after the circles system reaches conf-space equilibrium, the typical time
evolution of the circles system stays in square-root equilibrium in the particle
space with respect to all nice test sets (say, all boxes) simultaneously for a very,
very long time, without any violator time instant t.
Of course long-term stability does not mean that the circles system stays in
equilibrium forever. Indeed, the “superdiscrepancy” result Theorem 3.1 implies
that, given any kind of equilibrium state, the system will leave this equilibrium
for an infinite sequence of times tending to infinity.
Moreover, since the curve of the system in the configuration space is the
same, we also have snapshot randomness results for the circles systems. Thus we
have an analog of Poisson randomness in Sec. 8, have an analog of CLT
randomness in Sec. 15, and so on. The same proof works.
Also, we can extend the class of compund systems with circles much further
by relaxing the restriction of constant speed motions, and allowing general
motions of the particles. For example, we can assume that the motion of the kth
particle on Ck is general in the sense of (13.4)–(13.6). More precisely, again let

ck denote the center, let Rk denote the radius, let nk denote a unit normal vector
of Cj, and finally, let sk ∈ Ck denote the starting point of the kth particle. The
“standard 
circle 
of 
radius 
Rk” 
is 
given 
in 
the 
xy-plane 
Let ϑk ∈ SO(3) denote the rotation that maps (Rk, 0, 0) to sk − ck and maps (0, 0,
1) 
to 
nk, 
then 
by 
(25.6) 
we 
have 
Constant speed motion on the circle Cj means that θ = θ(t) = ct in (25.7) with
some fixed constant c. We study the general case where the kth particle moves
with (possibly) varying speed on the circle Ck, and the limitations are similar to
(13.4)–(13.6) as follows.
Assume that the motion of the kth particle is detemined by a function θ =
ρkθk(t) in (25.7), where ρk is a constant (depending on k) to be specified later, and
and
where α0 ≥ 1, 0 < α ≤ α1 are some absolute constants.
Moreover, let I denote an arbitrary finite interval of positive length. We also
assume that
uniformly for all T ≥ β0, z where β0 ≥ 1 and 0 ≤ β < 1 are absolute constants.
Note that it is easy to satisfy conditions (25.8)–(25.10). For example,
consider the forward motions where the speed r′k(t) of the kth particle satisfies the
inequalities 
which hold for some absolute constants 0 ≤ ζ1 < 1 and ζ2 ≥ 0.
Also there are many other ways, where we mix forward and backward
motion of the kth particle, such that (25.8)–(25.10) are still satisfied.
Since we already defined the starting point sk ∈ Ck of the kth particle, and we
assume that (25.8)–(25.10) hold for all particles 1 ≤ k ≤ N, the last step is to
specify the constant parameter ρk (depending on k) in θ = ρkθk(t); see (25.7). We
assume that the constant parameters ρk, 1 ≤ k ≤ N are chosen independently by

the 
1-dimensional 
normal 
(= 
Gaussian) 
distribution 
Let (C; ; Y; Gauss) denote the system defined by the family of N circles 
by the family of functions
satisfying (25.8)–(25.10), by the initial configuration
with sk ∈ Ck, and the constant parameters ρk (where θ = ρkθk(t) in (25.7)) chosen
independently by the probability distribution (25.11).
We study the usual questions: given an arbitrary initial configuration
with sk ∈ Ck, what can we say about the typical time evolution of the system (C; 
 Y; Gauss)? How long does it take to reach equilibrium? What can we say
about the stability of equilibrium?
Well, we can easily prove results similar to the above-mentioned results in
the special case of constant speed motions. The only difference is that we apply
Theorem 13.3 instead of Theorem 4.2.
Another generalization is to replace the circles with other closed orbits like
ellipse, or any other “reasonable closed curve”.
So far we have been studying closed orbit models, where the orbits are
closed curves (= 1-dimensional torus). Another possible generalization is to
switch from closed curves to closed surfaces (for example, 2-dimensional torus).
For motivation note that in some physical problems the perturbation of a
periodic closed orbit motion of a particle becomes a quasi-periodic motion on a
geometric torus surface (e.g., a donut surface). This means upgrading the 1-
dimensional torus to a 2-dimensional torus. We can also go beyond the donut
surface. For example, we can study the geodesic flow on a regular tetrahedron
surface or in general on any equifacial tetrahedron surface, i.e., a particle moves
along a (piecewise linear) geodesic of the tetrahedron surface (see the beginning
of Sec. 7). And so on.
Again we can prove similar results. Since the closed curve orbits are

replaced by closed surface orbits, we have to apply the results of Sec. 14
(replacing Theorem 4.2 and the results of Sec. 13).
Finally, we can combine these constructions to obtain even more general
compound models. Assume that some particles orbit on circles and other closed
curves, some other particles move on closed surfaces (like the donut surface, the
tetrahedron surface, and so on). Finally, assume that some particles move inside
a few disjoint boxes like point billiards. The union system is what we call a
general compound model.
We study the usual questions: given an arbitrary initial configuration Y, what
can we say about the typical time evolution of the general compound model?
How long does it take to reach equilibrium? What can we say about the stability
of equilibrium?
The class of general compound models is the largest class for which we can
answer these questions by proving results similar to the results up to this point,
employing the machinery of short-time ergodic theorems.

Chapter 5
More Proofs
26. Proof of Theorem 4.1
This section is devoted to the deduction of Theorem 4.1 from Theorem 9.1. The
somewhat strange definition of the threshold T0 = T0(d) in Theorem 4.1 becomes
well motivated by the key condition (4.12) in Theorem 4.2 (which is repeated in
Theorem 9.1). Indeed, the equation 
guarantees that we can apply Theorem 9.1 for every U ≥ T0, where T0 = T0(d) is
the 
solution 
of 
(26.1). 
Note 
that 
(26.1) 
implies 
that 
where o(1) = od(1) → 0 as d → ∞.
For every ρ > 0 we have the equality (trivial via substitution)
At a later stage of the proof we specify the value of ρ = ρ0 in the interval 
− 1 ≤ ρ ≤ 
 + 1 as the solution of an optimization problem (see (26.20)). For
the application of Theorem 9.1, it is convenient to decompose the interval [T0
/
ρ, T1
/ρ) into “simple” subintervals, where we call an interval [U, V) simple if 0
< U < V ≤ 2U. Since we do not know in advance which value of ρ ∈ [
 − 1,
≤ 
 + 1] will turn out to be the optimal value, we have to define the
decomposition in such a way that the simple subintervals that we use are from a
“universal” family. This “universal” family should work equally well for every
choice of ρ in the interval 
 − 1 ≤ ρ ≤ 
 + 1.
Clearly

and motivated by this fact, write
where T0 is defined in (26.1)–(26.2).
Thus we have the decomposition into subintervals
where
The intervals [Wk,Wk+1), 0 ≤ k ≤ ℓ are all simple, and they are also independent
of the choice of ρ ∈ [
 − 1, 
 + 1].
The first interval in (26.6) [
T0/ρ, W0) has length (see (26.1)–(26.2)) 
which is clearly ≤ 1 if d ≥ 103.
The last interval in (26.6) [Wℓ+1, 
T1/ρ) is not necessarily simple, but it is
“almost simple”; see (26.7) (we will explain this later).
To handle the last interval in (26.6), we consider the following basically
binary decomposition. Let k = (k1, . . . , kr) ∈ Zr, r ≥ 2 be an arbitrary at least 2-
dimensional integer vector such that the coordinates are strictly decreasing k1 > ·
· · > kr, and let I(k) denote the interval (note that W0 = 
T0/(
 − 1) is
defined in (26.5)) 
Note that I(k) has length 2kr W0, where kr is the last coordinate of the vector k.
For notational coherence, write
Note that (26.9) and (26.10) are all simple intervals.
Write (see (26.2))

Note that
We are now ready to apply Theorem 9.1: we have
Fixing the first coordinate k1 ≥ 0, we have
Using (26.14) in (26.13), we have

We recall the definition of the Gaussian square-integral (since at the end we
choose f = χS, we can assume that f is real-valued; 0 ≤ W′ < W″ are arbitrary) 
where
and dSA  stands for the normalized surface area.
Lemma 
26.1. 
For 
d 
≥ 
103 
and 
0 
≤ 
W′ 
< 
W″ 
we 
have 
Proof. Notice that inequality (26.18) immediately follows from the lower bound
To prove (26.19), we use Stirling’s formula (for the definition of Cd, see (6.30)–
(6.31)) 
which gives

and using ρ = 
 + c, −1 ≤ c ≤ 1 and exp(x) = ex, we obtain 
if |c| ≤ 1 and d ≥ 103, and (26.19) immediately follows via simple calculation.
This completes the proof of Lemma 26.1.
Combining (26.15)–(26.17) and Lemma 26.1, we have

Assume that the minimum for ρ ∈ [
 − 1, 
 + 1] in the last line of
(26.20) 
is 
attained 
at 
ρ 
= 
ρ0. 
Then 
(26.20) 
gives 
By (26.17) and (26.21),
holds for every k ≥ 0. Similarly,

holds for every k1 ≥ 0.
It immediately follows from (26.22) and the definition of integral
(“Markov’s inequality”) that for every k ≥ 0 there exists a measurable subset of
the (hyper)sphere A1,k ⊂ Sd−1 such that the normalized surface area 
(i.e., 
SA (Sd−1) 
= 
1) 
and 
Similarly, by (26.23) for every k1 ≥ 0 there exists a measurable subset of the
(hyper)sphere A2,k1 ⊂ Sd−1 such that 
and
Let
By (26.24), (26.26) and (26.28), the normalized surface area
Let e ∈ A be arbitrary.
We recall (26.3) with ρ = ρ0 [
 − 1, 
 + 1]
By (26.6)–(26.10),

where
Since
by (26.32) we have two cases for d ≥ 103:
We just discuss the first case; the second case goes similarly.
Case 1:
Consider the binary expansion
where ℓ2 > ℓ3 > ℓ4 > · · · is a strictly decreasing sequence of integers. In Case 1
we have ℓ + 1 < ℓ2.
Using (26.34) in (26.31), we have

It follows from the definition of c0(d) in (26.11) that Itail is an interval of length
less than 2.
Next we use the Cauchy–Schwarz inequality: combining (26.25), (26.27) and
(26.35), we have
Using the facts (d ≥ 103)
(see (26.32)) and c0(d) = log2W0 (see (26.11)) in (26.36), we obtain 
which implies
By (26.30), (26.35) and (26.37), for every e ∈ A,

where Itail is an interval of length less than 2 and [T0
/ρ0, W0) is an interval of
length ≤ 1 (see (26.8)).
In the special case f = χS where S ⊂ [0, 1)d is a measurable test set we have
the trivial upper bound 
and similarly, |Df(ρ0e; Itail)| ≤ 2. Combining these facts with (26.37)–(26.38), we
have 
which holds for every e ∈ A, where the normalized surface area of A ⊂ Sd−1 is
> 1 − ε. In the special case f = χS we have σ2
0(f) = p(1 − p) where p = vold(S), and
thus (26.39) completes the deduction of Theorem 4.1 from Theorem 9.1.
27. Starting the Proofs of Theorems 13.1–13.4
The proofs of Theorems 13.1–13.4 have the same beginning, which is very
similar to the argument in Sec. 9. We recall the notation that the curve Γ(t) = (t)
of 
the 
whole 
system 
in 
the 
configuration 
space 
is 
where t is the time,

is a (vector) family of functions such that
and
where α0 ≥ 1, 0 < α ≤ α1 are some absolute constants.
Moreover, let I denote an arbitrary finite interval of positive length. Assume
that 
uniformly for all T ≥ β0, where β0 ≥ 1 and 0 ≤ β < 1 are absolute constants.
Since ρkrk(t)ek ∈ R3, 1 ≤ k ≤ N, (27.1) is a curve in the 3N - dimensional unit
torus Id = [0, 1)d, which is the configuration space.
Let d = 3N. Let f ∈ L2(Id) be a complex-valued Lebesgue square-integrable
function in the d-dimensional unit torus (i.e., we extend f over the whole d-space
Rd periodically), and consider the Fourier expansion of f: 
where
and v · w = v(1)w(1) + · · · + v(d)w(d) denotes the usual dot product.
Write
Clearly
where we used Parseval’s formula.
Combining the Fourier series of f and the curve
of the whole system, we have

Consider the integral
where (t) = (R; ρ1, e1, . . . , ρN, eN; t) and 0 < T1 < T2.
The corresponding initial velocity space is
where
is the vector of probability density functions gk that define the initial speed
distribution 
 of the kth particle (1 ≤ k ≤ N). ΩG is equipped
with the product measure such that for the kth factor [0, ∞) × S2 in (27.6) we
have the probability density function gk for [0, ∞) and the normalized surface
area for the sphere S2.
Write
where
is the “isotropic Fourier transform”. Fg(w) defines a real-valued function
depending only on the length w = |w| of the input vector, and we repeatedly
make 
use 
of 
the 
facts 
that 
and Fg
(sup) (w) is a monotone decreasing positive function tending to zero as w →
∞.
We take the square of the absolute value of

and study the following average
where, as usual, dSA (e) denotes the normed surface area on the unit sphere S2,
i.e., 
We need the following simple lemma.
Lemma 27.1. For nj = (nj,1, nj,2, . . . , nj,d), j = 1, 2, let nj(k) = (nj,3k−2, nj,3k−1,
nj,3k) denote the kth block of triples of the coordinates, 1 ≤ k ≤ d/3 = N. We have 
Proof of Lemma 27.1. Using the trivial fact
in (27.5), we have
where, as usual,  = x − iy denotes the complex conjugate of a complex number z
= x + iy.
Applying (27.12) in (27.10), we obtain

Since
applying (27.8) we have
where N = d/3. Combining (27.13) and (27.14), Lemma 27.1 follows.
By Lemma 27.1
and first we estimate it from above under the condition that 1 ≤ U < V ≤ 2U. The

next lemma is brute force combinatorics.
Lemma 27.2. Let 1 ≤ U < V ≤ 2U, and write
Under the condition of (27.2)−(27.4) and
we have
Proof. For every n = (n1, . . . , nd) = (n(1), . . . , n(N)) ∈ Zd \ 0 (d = 3N) write
L(n) = {1 ≤ i ≤ N : n(i) = (n3i−2, n3i−1, n3i) ≠ 0}. Applying the simple inequality 
 
in 
(27.15), 
and 
using 
(27.7) 
we 
have 

We fix t1 ∈ [U, V], n1 ∈ Zd \ 0, L1,2 ⊆ L(n1) and λ2, and focus on the inner
integral at the end of (27.16).
Write
Let k1(n2) denote the number of indices i such that the coordinatetriple n2(i)
of n2 satisfies 1 ≤ |n2(i)| < 2 and n1(i) = 0; let k2(n2) denote the number of
indices i such that the coordinate-triple n2(i) of n2 satisfies 2 ≤ |n2(i)| < 4 and
n1(i) = 0; let k3(n2) denote the number of indices i such that the coordinate-triple
n2(i) of n2 satisfies 4 ≤ |n2(i)| < 8 and n1(i) = 0; and so on, keeping up the
doubling. Note that 
Let h0(t2; n2) denote the number of indices j ∈ L1,2 such that |rj(t1)n1(j) −
rj(t2)n2(j)| < U1/2; let h1(t2; n2) denote the number of indices j ∈ L1,2 such that
U1/2 ≤ |rj(t1)n1(j) − rj(t2)n2(j)| < U1; let h2(t2; n2) denote the number of indices j

∈ L1,2 such that U1 ≤ |rj(t1)n1(j)−rj(t2)n2(j)| < 2U1; let h3(t2; n2) denote the
number of indices j ∈ L1,2 such that 2U1 ≤ |rj(t1)n1(j) − rj(t2)n2(j)| < 4U1; and so
on, 
keeping 
up 
the 
doubling. 
Note 
that 
By 
using 
the 
definitions 
of 
ki(n2) 
and 
hi(t2; 
n2), 
we 
have 
We estimate the long sum at the end of (27.20). By using the definitions of
ki(n2), hi(t2; n2), (27.18) and (27.19), we obtain the upper bound EndSum of
(27.20)

Note that (27.21) includes the pathological case λ2 − λ1,2 = 0 with the natural
convention that the summation means the single term (k1, . . . , kr) = (0), and
similarly, if λ1,2 = 0 then (h0, h1, . . . , hr) is just the single term (0). Moreover, to
explain the binomial coefficient factor 
 in (27.21), we note that for every
given half-open axis-parallel cube Q of side length U1, there is at most one
integer lattice point m2 ∈ Z3 such that rk(t2)m2 ∈ Q (see the definition of U1 in
Lemma 27.2). The same argument explains the next binomial coefficient factor 

 in (27.21), and so on. The extra factor ((2+1)3)h1 is a generous upper
bound: it comes from the contribution of the first neighborhood of size (2 + 1)3 −
1 of a lattice point m2 ∈ Z3; and so on. The same argument explains the factors 
in (27.21).
Applying the multinomial theorem twice in (27.21) the same way as we did
in (13.15)–(13.16), we have the very generous upper bound (where the extra
factors of N come from the trivial upper bound 
Next we use (27.21)–(27.22) in (27.20):
Let us return now to (27.16); we have the following decomposition into four
parts: 
where

is characterized by the property λ1 < λ2,
is characterized by the property λ1 > λ2, and finally, we split the case λ1 = λ2 into
two 
subcases 
according 
as 
L(n1) 
≠ 
L(n2) 
or 
L(n1) 
= 
L(n2): 
and

To estimate (27.28), we are going to use a simple but important lemma,
which is an analog of Lemma 9.3. First a definition: given real numbers C, C′
and 
a 
positive 
function 
r(x), 
consider 
the 
set 
We give an upper bound on the 1-dimensional Lebesgue measure (i.e., the
length) of the set BU(r; C; C′).
Lemma 27.3. Assume that
and
uniformly for all U ≥ β0, where the supremum in (27.30) is taken over all finite
intervals I ⊂ R of positive length, and β0 ≥ 1, 0 ≤ β < 1 are absolute constants.
Then 
Proof. We can assume without loss of generality that C ≥ 0. Clearly
so by (27.30)
where the summation 
 is extended over all positive integers n such that 

By (27.29)
and
To estimate the sum
we distinguish two cases. If 0 ≤ C < U1 then ξ2 ≤ 3/2, and so we have the trivial
upper bound 
If C ≥ U1, then
and so
Combining (27.31)–(27.36), we conclude
which completes the proof of Lemma 27.3.
28. Completing the Proof of Lemma 27.2
Applying (27.23) in (27.25), we have

By hypothesis
and using it we have

since
By using (28.2)–(28.3) in (28.1), we obtain

By using the substitution i = λ2 − λ1 ≥ 1 in (28.4), we obtain the upper bound 
where in the last step we used Parseval’s formula.
Next we apply (27.23) in (27.26):

where in the middle of the argument we used the trivial inequality
and at the end we used (28.2).

Using the substitution i = λ1 + λ2 − 2λ1,2 in (28.6), we have 
where in the last step we used Parseval’s formula.
Next we apply (27.23) in (27.27): Part Three
Using (28.7), (28.2) and the substitution i = λ1 − λ1,2 in (28.9), we have 

where in the last step we used Parseval’s formula.
Finally we estimate (27.28). We have
where
and

We start with Part Four A, and use the notation λ1 = |L(n1)|. In this special case
the argument of (27.20)–(27.23) simplifies to the following upper bound (note
that 
here 
λ1 
= 
λ2 
= 
λ1,2) 

where the term −1 at the end is explained by the restriction h0 < λ1, i.e., the term
−1 is due to the fact that in the application of the multinomial theorem we have
an almost complete sum, where the single missing case is h0 = λ1.
By (28.14)

if
Note that in (28.15) we used Parseval’s formula and the simple inequalities 1 + x
≤ ex ≤ 1 + 2x for 0 ≤ x ≤ 1; and of course (28.16) follows from the stronger
condition (28.2).
To estimate (28.13)
we make use of the fact that for every given triple (t1, n1, t2) with t1 ∈ [U, V], n1
∈ Zd \ 0 and t2 ∈ [U, V], there is at most one term in the endsum 
of (28.17). Indeed, it follows from the definition of h0(t2; n2) that for every given
triple (t1, n1, t2) the inequality |rj(t1)n1(j) − rj(t2)n2(j)| < U1/2 has at most one
solution n2(j) ∈ Z3, and because h0(t2; n2) = |L(n1)| and L(n2) = L(n1), there is at

most one n2 ∈ Zd \ 0 satisfying the requirements. Let n2 ∈ Zd \ 0, n2 = n2(t1, n1,
t2) denote this single integer lattice point, if it exists. Thus we can rewrite (28.17)
as follows: 
where n2 = n2(t1, n1, t2), if it exists.
Let j0 = j0(n1) be an arbitrary but fixed element of the set L(n1); then we have
the 
following 
trivial 
upper 
bound 
for 
(28.18): 
Given (t1, n1), we consider the following decomposition of the interval U ≤
t2 ≤ V(≤2U): 
where j0 = j0(n1) and n2 = n2(t1, n1, t2).
Using decomposition (28.20) in (28.19), we obtain the upper bound
where Iℓ = Iℓ(t1, n1). To estimate the length of Iℓ = Iℓ(t1, n1), we use Lemma 27.3.
First note that n2(j0) ∈ Z3 \ 0, so it has a nonzero coordinate n2,3j0−i0 with some i0
∈ {0, 1, 2}. Applying Lemma 27.3 with C = rj0 (t1)n1,3j0−i0 and C′ = ℓ, we obtain
the upper bound 
see (27.3). On the other hand, by (27.2)
Combining (28.22) and (28.23), we have

Using (28.24) and Parseval’s formula in (28.21), we obtain
Combining (27.24), (28.5), (28.8), (28.10), (28.11), (28.15) and (28.25), we
have
By using V − U ≤ U and (28.2) in (28.26), we obtain the shorter upper bound 
which completes the proof of Lemma 27.2.

29. Finishing the Proofs of Theorems 13.1–13.4
We distinguish four cases according to Theorems 13.1–2-3-4.
Case 1. F(sup)(w) ≤ w−γ for all w ≥ γ0 ≥ 1
First we estimate the critical sum in Lemma 27.2: for 2πU1 ≥ γ0 and γ > 3
Moreover, for U ≥ β0 we have
Using (29.1) and (29.2) in Lemma 27.2, under the condition of Case 1, we have
assuming
By hypothesis (27.2)
Using (29.5) in (29.3)–(29.4), under the condition of Case 1 we have

assuming
Now we are ready to complete the proof of Theorem 13.1. We repeat the
Cauchy–Schwarz argument of the deduction of Theorem 4.2 from Theorem 9.1
(see the end of Sec. 9). Let 2k−1U < W ≤ 2kU. It is easy to find a sequence W0 =
U < W1 < · · · < Wk = W such that Wi < Wi+1 ≤ 2Wi for all 0 ≤ i < k. Assume that
αγ > 1. Combining the Cauchy–Schwarz inequality and (29.6) with the choice U
= Wi and V = Wi+1, 0 ≤ i < k, and using the simple fact that x1−αγ is a monotone
decreasing 
function 
of 
x 
(since 
αγ 
> 
1), 
we 
have 

assuming
Since 
 (upper integral part), (29.8)–(29.9) complete the proof of
Theorem 13.1.
Next we replace the polynomial decay in Case 1 with the exponential decay.
Case 2. F(sup) (w) ≤ e−γw for all w ≥ γ0
Again we estimate the critical sum in Lemma 27.2: for 2πU1 ≥ γ0

and similarly,
Using (29.10)–(29.11) in Lemma 27.2, under the condition of Case 2 we have
assuming
By using hypothesis (27.3), we can replace condition (29.13) with
By using (29.12) we complete the proof of Theorem 13.2 the same way as
we completed the proof of Theorem 13.1 in Case 1 above. First we need an
elementary fact from calculus. It is a routine derivative calculation that the
function 
and g0(x) is monotone decreasing for x > x0. Now let 2k−1U < W ≤ 2kU. It is easy
to find a sequence W0 = U < W1 < · · · < Wk = W such that Wi < Wi+1 ≤ 2Wi for
all 0 ≤ i < k. Combining the Cauchy–Schwarz inequality and (29.12) with the
choice U = Wi and V = Wi+1, 0 ≤ i < k, using the fact that g0(x) is monotone
decreasing for x > x0 (see (29.15)), and finally repeating the argument of (29.8),

we have 
assuming
Since 
 (29.16)–(29.17) complete the proof of Theorem 13.2.
Next we replace the exponential decay in Case 2 with the superexponential
decay of the normal distribution.
Case 3. F(sup) (w) ≤ e−γw2 for all w ≥ γ0
As usual, first we estimate the critical sum in Lemma 27.2: for 2πU1 ≥ γ0
and
Using (29.18)–(29.19) in Lemma 27.2, under the condition of Case 3 we obtain

assuming
We complete the proof of Theorem 13.3 the same way as we completed the
proofs of Theorems 13.1 and 13.2 in Case 1 and Case 2 above. We use the
elementary 
fact 
from 
calculus 
that 
the 
function 
and g1(x) is monotone decreasing for x > x1. Let 2k−1U < W ≤ 2kU; it is easy to
find a sequence W0 = U < W1 < · · · < Wk = W such that Wi < Wi+1 ≤ 2Wi for all 0
≤ i < k. Combining the Cauchy–Schwarz inequality and (29.20) with the choice
U = Wi and V = Wi+1, 0 ≤ i < k, using the fact that g1(x) is monotone decreasing
for x > x1 (see (29.22)), and finally repeating the argument of (29.8), we have 

assuming
Since 
 (29.23)–(29.24) complete the proof of Theorem 13.3.
Finally we replace the superexponential decay in Case 3 with the “vanishing
property”.
Case 4. F(sup)(w) = 0 for w ≥ γ0
For 2πU1 ≥ γ0 the critical sum in Lemma 27.2 vanishes:
and similarly
Using these facts in Lemma 27.2, under the condition of Case 4 we have
assuming
We complete the proof of Theorem 13.4 the usual way. Let 2k−1U < W ≤ 2kU;
it is easy to find a sequence W0 = U < W1 < · · · < Wk = W such that Wi < Wi+1 ≤
2Wi for all 0 ≤ i < k. Combining the Cauchy–Schwarz inequality and (29.25)
with the choice U = Wi and V = Wi+1, 0 ≤ i < k, and again repeating the argument
of (29.8), we have 

assuming
Since 
 (29.27)–(29.28) complete the proof of Theorem 13.4.
30. Starting the Proof of Theorem 14.1
It is convenient to prove first a special case with an upper bound on the ratio
W/U.
Theorem 30.1. Let f ∈ L2(Id) be a test function, where Id = [0, 1)d with d = 2N.
Under the condition of (14.4) − (14.6) for 2-dimensional curves 
and also assuming eπ2U1
2/2 ≥ 10UN with 
for 
2U 
≥ 
V 
> 
U 
≥ 
max{α0, 
β0, 
1} 
we 
have 
Remark. The technical restriction U < V ≤ 2U in Theorem 30.1 can be easily
eliminated by a routine application of the Cauchy–Schwarz inequality — for the
details, see the end of Sec. 31.
Proof of Theorem 30.1. As usual, we apply Fourier analysis in the configuration
space Id = [0, 1)d with d = 2N. We use the Fourier expansion of the given
Lebesgue square-integrable test function f ∈ L2(Id) (defined in the d-dimensional
unit torus, i.e., we extend f over the whole d-space Rd periodically): 
Clearly
where we used Parseval’s formula.
We recall some notation from Sec. 14. For every n = (n1, . . . , nd) ∈ Zd \ 0,

write n(k) = (n2k−1, n2k), 1 ≤ k ≤ N = d/2.
Given t1 and t2, write
where e1, e2 are 2-dimensional unit vectors. Thus we have rk(t1) = rk(t1)e1 and
rk(t2) = rk(t2)e2, where rk(t1) = |rk(t1)| and rk(t2) = |rk(t2)|. We use θk;t1→t2 ∈ SO(2)
to denote the rotation of the plane that maps e1 to e2, i.e., e2 = θk;t1→t2e1; and
similarly, θk;t2→t1 ∈ SO(2) denotes the inverse of θk;t1→t2, i.e., e1 = θk;t2→t1e2.
We recall Lemma 14.1 from Sec. 14.
Lemma 14.1 For 2-dimensional curves
we have
Lemma 14.1 is a curve analog of Lemma 9.2 in the 2-dimensional case. In
the rest of the proof we closely follow the brute force combinatorial arguments
in Sec. 9, and the similar arguments in Sec. 27–28.
For every n = (n1, . . . , nd) ∈ Zd \ 0 write L(n) = {1 ≤ i ≤ N = d/2 : ni ≠ 0}.
Applying the simple inequality 
 Lemma 14.1, we have 

We fix t1 ∈ [U, V], n1 ∈ Zd \ 0, L1,2 ⊆ L(n1) and λ2, and focus on the inner

integral at the end of (30.3) 
Let k1(n2) denote the number of indices i such that the coordinate-pair n2(i)
of n2 satisfies 1 ≤ |n2(i)| < 2 and n1(i) = 0; let k2(n2) denote the number of
indices i such that the coordinate-pair n2(i) of n2 satisfies 2 ≤ |n2(i)| < 4 and n1(i)
= 0; let k3(n2) denote the number of indices i such that the coordinate-pair n2(i)
of n2 satisfies 4 ≤ |n2(i)| < 8 and n1(i) = 0; and so on, keeping up the doubling.
Note that 
Let h0(t2; n2) denote the number of indices j ∈ L1,2 such that 
let h1(t2; n2) denote the number of indices j ∈ L1,2 such that 
let h2(t2; n2) denote the number of indices j ∈ L1,2 such that 
let h3(t2; n2) denote the number of indices j ∈ L1,2 such that 
and so on, keeping up the doubling. Note that
By 
using 
the 
definitions 
of 
ki(n2) 
and 
hi(t2; 
n2), 
we 
have 
We estimate the long sum at the end of (30.6). By using the definitions of

ki(n2), hi (t2; n2), (30.4) and (30.5), we obtain the upper bound 
Note that (30.7) includes the pathological case λ2 − λ1,2 = 0 with the natural
convention that the summation means the single term (k1, . . . , kr) = (0), and
similarly, if λ1,2 = 0 then (h0, h1, . . . , hr) is just the single term (0). Moreover, to

explain the binomial coefficient factor 
 in (30.7), we note that for every
given half-open axis-parallel square Q of side length U1, there is at most one
integer lattice point m2 ∈ Z2 such that rk(t2)m2 ∈ Q (see the definition of U1 in
Theorem 30.1). The same argument explains the next binomial coefficient factor 
 in (30.7), and so on. The extra factor ((2 + 1)2)h1 is a generous upper
bound: it comes from the contribution of the first neighborhood of size (2 + 1)2 −
1 of a lattice point m2 ∈ Z2; and so on. The same argument explains the factors 
in (30.7).
Applying the multinomial theorem twice in (30.7) the same way as we did it
in (13.15)–(13.16) (or in (27.22)), we have the very generous upper bound (the
extra factor of N comes from the trivial upper bound 
Next we use (30.7)–(30.8) in (30.6):

since R(inf)(U) = U1 ≥ 1 and |L(n1) \ L1,2| = λ1 − λ1,2.
Let us return now to (30.3); we have the following decomposition into four
parts:
where

is characterized by the property λ1 < λ2,
is characterized by the property λ1 < λ2, and finally, we split the case λ1 = λ2 into
two 
subcases 
according 
as 
L(n1) 
≠ 
L(n2) 
or 
L(n1) 
= 
L(n2): 
and

To estimate (30.14), we are going to use a lemma, which is somewhat similar
to Lemmas 9.3 and 27.3.
Lemma 30.1. Assume that
where α0 ≥ 1, κ ≥ 0, and r′(x) is the derivative of the parametrized curve r(x).
Moreover, let C(c; ) denote an arbitrary circle centered at c ∈ R2 with
radius , and assume that 
uniformly for all T ≥ β0 (note that α0 ≥ 1, κ ≥ 0, κ0, β0 ≥ 1 and Let U ≥ {α0, β0,
1}; then for every fixed t1 ∈ [U, 2U], m1 ∈ Z2 \ 0 and 0 < C′ ≥ U1/16
If U1/16 < C′ < U1/2 then the upper bound in (30.18) can be replaced by the
trivial upper bound U.
Proof of Lemma 30.1. We study the inequality
Applying the inverse θt1→t2 of θt1→t2, and dividing by r(t2), we rewrite (30.19) in
the equivalent form 
Let mi = |mi| ≥ 1, i = 1, 2, and let  ∈ SO(2) denote the rotation such that 

Using (30.21) in (30.20), we can rewrite (30.20) in the equivalent form
since
Applying the inverse 
−1 of  and dividing (30.22) with m1r(t1), we have 
By hypothesis (30.15), r(t2) ≥ U1. It follows that inequality (30.24)–(30.25)
below implies (30.23), where 
with
Inequality (30.23)–(30.25) motivates the use of the following simple geometric
lemma.
Lemma 
30.2. 
Let 
w 
∈ 
R2 
and 
0 
< 
ε 
< 
|w|/2, 
then 
with
Proof of Lemma 30.2. Let Tinv denote the transformation of inversion on the
plane 
where the radius of inversion is 1, and the center of inversion is the origin 0 ∈
R2. Note that an inversion transformation is its own inverse (which provides a
good reason for the name of the transformation).
Given w ∈ R2 \ 0 and 0 < ε < |w|/2, consider the circle centered at w and
having radius ε: 

It is well known that the image under inversion of a circle not passing through
the center of inversion is a circle. Let C(c; ) denote the Tinv- image of C(w; ε),
where of course c is the center and  is the radius. By definition (30.26) 
which implies
Since 0, w, c are collinear, we obtain
Combining (30.26), (30.27) and (30.28), Lemma 30.2 follows.
We also need the following simple fact. Given two lattice points n = (n1, n2),
m = (m1, m2) ∈ Z2, we say that n and m are neighbors, if |n1 − m1| ≤ 1 and |n2 −
m2| ≤ 1. So, a lattice point on the plane has eight neighbors.
Let n, m ∈ Z2 \ 0 be two nonzero lattice points that are neighbors, and let 0 <
ε 
< 
δ/2. 
Trivial 
computation 
shows 
that 
After these preparations we are ready to complete the proof of Lemma 30.1.
Let k ≥ 0 be a fixed integer, and let
where m2 = |m2|.
Applying Lemma 30.2 in (30.30), we have
where

By using 0 < ε < δ/2 in (30.32),
where in the last step we applied (30.33) and 2k ≤ m2.
Using (30.34) in (30.31), we obtain
where
with
Combining (30.29) and (30.32), we see that the centers c(m2) of the circles
C(c(m2); 
(k)) listed in (30.36) are separated from each other by a distance 
since m2 < 2k+1.
If C′ ≤ U1/16, then by (30.37) and (30.38) the radius 
(k) is at most one-
third of the distance between the centers of the circles C(c(m2); 
(k)) listed in
(30.36). This implies that these circles are disjoint, and they are separated from
each other by a distance 
It follows that the part of the curve r(t), U ≤ t ≤ 2U intersects at most 
circles C(c(m2); 
(k)) listed in (30.36). Indeed, the upper bound (30.16) on the
speed of the parametrized curve r(t) implies that the arclength of the part of the
curve 
r(t), 
U 
≤ 
t 
≤ 
2U 
is 
at 
most 
(using 
U 
≥ 
α0) 
and thus we just divide (30.41) with the lower bound (30.39) of the distance
between the disjoint circles C(c(m2); (k)) listed in (30.36).
By hypothesis (30.17), the curve r(t), U ≤ t ≤ 2U spends at most 
(k)(2U)β
time in a circle of radius (k) (here we use U ≥ β0). By (30.37) 

and combining these facts with (30.40), we obtain the upper bound (see (30.35)
and (30.36))
To finish the proof of Lemma 30.1, we apply (30.42) in (30.23) as follows. Since
(30.24)–(30.25) implies (30.23), and (30.23) is equivalent to (30.19), we have 
where 0 ≤ k1 < k2 are some appropriate integers (see (30.30)).
To estimate the difference k2 − k1 (see (30.43)), we recall hypothesis (30.16),
which implies 
Moreover, by (30.15),
Assume that m2 ∈ Z2 \ 0 satisfies (30.19); then by (30.44) and (30.45), 
and similarly,
Thus we have
k1 is the largest integer such that
and k2 is the smallest integer such that

It follows that (log2 denotes the binary logarithm)
Combining (30.42), (30.43) and (30.47), we conclude
length {t2 ∈ [U, 2U] : there exists m2 ∈ Z2 \ 0 such that (30.19) holds}
which completes the proof of Lemma 30.1.
31. Finishing the Proof of Theorem 14.1
Applying (30.9) in (30.11), we have

By hypothesis
and using it we have
since
By using (31.2)–(31.3) in (31.1), we obtain

By using the substitution i = λ2 − λ1 ≥ 1 in (31.4), we obtain the upper bound 
where in the last step we used Parseval’s formula, (31.2) and V − U ≤ U.
Next we apply (30.9) in (30.12):

where in the last steps we used (31.2) and the trivial upper bound
Applying (31.2) in (31.6), we obtain

where we used the substitution j = λ1 + λ2 − 2λ1,2, the assumption V − U ≤ U, the
simple fact 
and Parseval’s formula.
Next we apply (30.9) in (30.13):

Using (31.7) in (31.9), we have
Using (31.2) in (31.10), we obtain
where we used the substitution j = λ1 − λ1,2, the hypothesis V − U ≤ U and
Parseval’s formula.
Finally we estimate (30.14). We have
where

and
We start with Part Four A, and use the notation λ1 = |L(n1)|. In this special case
we obtain the following analog of (14.15) (note that here λ1 = λ2 = λ1,2) 

where the term −1 at the end is explained by the restriction h0 < λ1, i.e., the term
−1 is due to the fact that in the application of the multinomial theorem we have
an almost complete sum, where the single missing case is h0 = λ1.
By (31.15)
since
Note that in (31.16) we used Parseval’s formula and the simple inequalities 1+x
≤ ex ≤ 1 + 2x for 0 ≤ x ≤ 1; and of course (31.17) follows from (31.2).
Applying (31.2) in (31.16), we have

since V − U ≤ U.
To estimate (31.14)
we make use of the fact that for every given triple (t1, n1, t2) with t1 ∈ [U, V], n1
∈ Zd \ 0 and t2 ∈ [U, V], there is at most one term in the endsum 
of (31.19). Indeed, it follows from the definition of h0(t2; n2) that for every given
triple (t1, n1, t2) the inequality 
has at most one integer lattice point solution n2(k) ∈ Z2, and because h0(t2; n2) =
|L(n1)| and L(n2) = L(n1), there is at most one n2 ∈ Zd \ 0 satisfying the
requirements. Let n∗2 ∈ Zd \ 0, n∗2 = n∗2(t1, n1, t2) denote this single integer lattice
point, 
if 
it 
exists. 
Thus 
we 
can 
rewrite 
(31.19) 
as 
follows: 
where n∗
2 = n∗
2(t1, n1, t2), if it exists.
Let j0 = j0(n1) be an arbitrary but fixed element of the set L(n1); then we have
the 
following 
trivial 
upper 
bound 
for 
(31.20): 

Given (t1, n1), we consider the following decomposition of the interval U ≤
t2 
≤ 
V 
(≤ 
2U): 
for 
ℓ 
= 
1, 
2, 
3, 
. 
. 
. 
let 
where j0 = j0(n1) and n∗2 = n∗2(t1, n1, t2).
Using decomposition (31.22) in (31.21), we obtain the upper bound
where Iℓ = Iℓ(t1, n1). Applying Lemma 30.1 with C′ = ℓ, we obtain the upper
bound 
if ℓ ≤ U1/16 and
if U1/16 < ℓ < U1/2. Using (31.24), (31.25) and Parseval’s formula in (31.23), we
have 
Combining (30.10), (31.12), (31.5), (31.8), (31.11), (31.18) and (31.26),

since by hypothesis U ≥ max{α0, β0, 1}. (31.27) completes the proof of Theorem
30.1.
Now we are ready to complete the proof of Theorem 14.1. By hypothesis
and using this fact in (31.27), we have
We repeat the usual Cauchy–Schwarz argument (like the deduction of Theorem
4.2 from Theorem 9.1; see the end of Sec. 9). Let 2k−1U < W ≤ 2kU. It is easy to
find a sequence W0 = U < W1 < · · · < Wk = W such that Wi < Wi+1 ≤ 2Wi for all 0
≤ i < k. Combining the Cauchy–Schwarz inequality and (31.28) with the choice
U = Wi and V = Wi+1, 0 ≤ i < k, and using 0 < α ≤ 1 + κ, we have 

under the condition
Since k = log2(W/U)  (upper integral part), (31.29)–(31.30) complete the proof
of Theorem 14.1.
32. Proof of Theorem 14.2
It is a straightforward adaptation of the arguments in Secs. 27–31. For the sake

of completeness we include — or rather outline — the details. The following
lemma is an analog of Lemma 27.2.
Lemma 32.1. Let 1 ≤ U < V ≤ 2U, and write
Under the condition of (30.15)–(30.17) and
we have
Proof. For every n = (n1, . . . , nd) = (n(1), . . . , n(N)) ∈ Zd \ 0 (d = 2N) write
L(n) = {1 ≤ i ≤ N : n(i) = (n2i−1, n2i) ≠ 0}. Applying the simple inequality 
 we have the following analog of (27.16) (and (30.3)): 

We fix t1 ∈ [U, V], n1 ∈ Zd \ 0, L1,2 ⊆ L(n1) and λ2, and focus on the inner
integral at the end of (32.1).
Write
We define ki(n2) and hi(t2; n2) the same way as in Sec. 27 with the
straightforward modification that |rj(t1)n1(j)−rj(t2)n2(j)| is replaced with
|rk(t1)n1(k) − rk(t2)θk;t2→t1n2(k)|, and of course dimension 3 is reduced to
dimension 2; see (30.4) and (30.5). Then we obtain the following analog of
(27.20) 
(and 
(30.6)): 
Next we estimate the long sum at the end of (32.3) the same way as we
estimated the long sum at the end of (27.20); we obtain the following analog of
(27.21) (and (30.7)): EndSum of (32.3)

Applying the multinomial theorem twice in (32.4) the same way as we did it in
(27.22), we have the very generous upper bound (where the extra factors of N
come from the trivial upper bound 
EndSum of (32.3)

which is an analog of (27.22) (and (30.8)). Next we use (32.4)–(32.5) in (32.3),
and 
obtain 
the 
following 
analog 
of 
(27.23) 
(and 
(30.9)): 
Let us return now to (32.1); we have the following decomposition into four
parts 
(an 
analog 
of 
(27.24)–(27.28); 
see 
also 
(30.10)–(30.14)): 
where

is 
characterized 
by 
the 
property 
λ1 
< 
λ2, 
is characterized by the property λ1 > λ2, and finally, we split the case λ1 = λ2 into
two 
subcases 
according 
as 
L(n1) 
≠ 
L(n2) 
or 
L(n1) 
= 
L(n2): 
and

Applying (32.6) in (32.8), and repeating the argument of (28.1)–(28.4), we
have 
the 
following 
analog 
of 
(28.5) 
(and 
(31.5)): 
Next we apply (32.6) in (32.9), and repeat the argument of (28.6)–(28.8):
which is an analog of (28.8) (and (31.8)).
Similarly, we apply (32.6) in (32.10), and repeat the argument of (32.9)–
(32.10):
which is an analog of (28.10) (and (31.11)).
Finally we estimate (32.11). Similarly to (28.11)–(28.13) (and (31.12)–
(31.14)), we have
where

and
By repeating the argument of (28.14)–(28.16) (and (31.15)–(31.18)), we have
To estimate (32.17)
we make use of the fact that for every given triple (t1, n1, t2) with t1 ∈ [U, V], n1
∈ Zd \ 0 and t2 ∈ [U, V], there is at most one term in the endsum 

of (32.19). Indeed, it follows from the definition of h0(t2; n2) that for every given
triple (t1, n1, t2) the inequality 
has at most one solution n2(j) ∈ Z2, and because h0(t2; n2) = |L(n1)| and L(n2) =
L(n1), there is at most one n2 ∈ Zd \ 0 satisfying the requirements. Let n∗2 ∈ Zd \
0, n∗2 = n∗2(t1, n1, t2) denote this single integer lattice point, if it exists. Thus we
can 
rewrite 
(32.19) 
as 
follows: 
where n∗2 = n∗2(t1, n1, t2), if it exists.
Let k0 = k0(n1) be an arbitrary but fixed element of the set L(n1); then we
have 
the 
following 
trivial 
upper 
bound 
for 
(32.20): 
Note that (32.21) is an analog of (28.19) (and (31.20)).
Given (t1, n1), we consider the following decomposition of the interval U ≤
t2 ≤ V(≤ 2U): 
with ℓ = 1, 2, 3, . . . , where k0 = k0(n1) and n∗
2 = n∗
2(t1, n1, t2).
Using decomposition (32.22) in (32.21), we obtain the upper bound
where Iℓ = Iℓ(t1, n1). To estimate the length of Iℓ = Iℓ(t1, n1), we apply Lemma
30.1 
with 
C′ 
= 
ℓ, 
and 
obtain 
the 
upper 
bound 
if ℓ ≤ U1/16 and

if U1/16 < ℓ < U1/2. Using (32.24), (32.25) and Parseval’s formula in (32.23), we
have 
which is an analog of (31.26).
Combining (32.7), (32.12), (32.13), (32.14), (32.15), (32.18) and (32.26), we
have
By 
using 
V 
− 
U 
≤ 
U, 
we 
obtain 
the 
shorter 
upper 
bound 

which completes the proof of Lemma 32.1.
We recall the hypothesis of Theorem 14.2:
First we estimate the critical sum in Lemma 32.1: by using (32.28), for 2πU1
≥ 
γ0 
and 
γ 
> 
2 
we 
have 
Moreover, for U ≥ β0 we have
Using (32.29) and (32.30) in Lemma 32.1, under the condition of (32.28) we

have 
assuming
By hypothesis
Using (32.33) in (32.31)–(32.32), under the condition of (32.28) we have
assuming
Now we are ready to complete the proof of Theorem 14.2 by using the usual
Cauchy–Schwarz argument (see e.g. the deduction of Theorem 4.2 from
Theorem 9.1 at the end of Sec. 9). Let 2k−1U < W ≤ 2kU. It is easy to find a
sequence W0 = U < W1 < · · · < Wk = W such that Wi < Wi+1 ≤ 2Wi for all 0 ≤ i <
k. Assume that αγ > 1. Combining the Cauchy–Schwarz inequality and (32.34)
with the choice U = Wi and V = Wi+1, 0 ≤ i < k, and using the simple fact that
x1−αγ is a monotone decreasing function of x (since αγ > 1), we have 

assuming
Since k = log2(W/U)  (upper integral part), (32.36)–(32.37) complete the proof
of Theorem 14.2.

33. Multiple Mixedupness (II): Proof of Lemma 12.2
By (12.38) and (12.39) we have
By using (12.8)–(12.10) in the 3-dimensional case, we have
where Hj ≥ 1 are arbitrary integers, and (see (12.39))
If j1 ≠ j2 then

We can clearly rewrite (33.3) in an equivalent form about 6-dimensional torus
line
where, for given vectors u = (u1, . . . , ud1) and w = (w1, . . . , wd2), we use the
notation 
Applying (12.8)–(12.10) for the 6-dimensional box B × B of 6-dimensional
volume (vol(B))2, we have 
where Hj1,j2 ≥ 1 are arbitrary integers.
We estimate the sums (33.2) and (33.5) by using the Separation Condition
(12.26)–(12.27). We start with (33.2); let Hj = N1/3. Then by (33.2) 

For every lattice point h ∈ Z3 with 1 ≤ ||h||∞ ≤ N1/3, let r(h) = r(h; U ; N) denote
the smallest integer such that 
To estimate (33.6) we distinguish two cases.
Case 1: 
Then 
(33.7) 
and 
||h||∞ 
≥ 
|h| 
imply 
Applying (12.27) with ℓ = −1 and 0, (33.8) gives that the interval
contains less than 2r + 2r = 2r+1 dot products h · vk, 1 ≤ k ≤ N (with r = r(h)).
Combining this information with (33.7) and (33.9), we obtain the upper bound 
where in the last step we used the following consequence of (33.7):

Using the definition (12.6) of Λ(h) and the trivial inequality
for all h ∈ Z3 \ 0, we can easily estimate the infinite sum 
Combining (33.10) and (33.12), in Case 1 we obtain the upper bound
which will be used later in the estimation of (33.6).
Next we estimate the last sum in (33.6) — as usual, we assume Case 1.
Again 
(33.8) 
gives 
that 
every 
interval 
contains less than 2r(h) dot products h · vk, 1 ≤ k ≤ N. Notice that (33.7) implies |
ℓ| ≤ πU|h|.
Similarly to (33.10), (33.14) yields the upper bound
where again we used (33.11).
Using the fact

we have
Applying (33.16) in (33.15), we obtain
Repeating the argument of (33.12), and using the simple inequality
we have
Next we use (33.18) and (33.12) in (33.17):
Applying (33.13) and (33.18) in (33.16), we obtain the upper bound

assuming Case 1.
Next we estimate (33.6) under the condition that Case 1 fails.
Case 2: 
We repeat the argument of (33.7)–(33.20) with the minor change that we use
(12.26) instead of (12.27), which gives an extra factor of 6 log N. Thus we
obtain 
the 
following 
analog 
of 
(33.20): 
assuming Case 2.
Note that in Case 2 we have the upper bound log N ≤ 4 log U, and using it in
(33.21), 
Combining (33.20) and (33.22), we obtain the upper bound
which holds in both Case 1 and Case 2.
Next we estimate the sum (33.5). Again we use the Separation Condition
(12.26)–(12.27), and again let Hj1,j2 = N1/3. Then by (33.5) we obtain the
following 
analog 
of 
(33.6): 

Note that
where h = (h1, h2, . . . , h6), h(1) = (h1, h2, h3) and h(2) = (h4, h5, h6).
By using (33.25) and (12.6), we can rewrite a critical part of (33.24) as
follows:
To estimate (33.26) we distinguish two cases.
Case 1: 
We recall (33.7) and (33.8): for every 3-dimensional lattice point h′ ∈ Z3
with 1 ≤ ||h′||∞ ≤ N1/3, let r(h′) = r(h′; U; N) denote the smallest integer such that 

and in Case 1 we have the lower bound
Moreover, for every unit vector vj ∈ S2, 1 ≤ j ≤ N there is an integer ℓ = ℓ(vj)
such that 
and
where the latter follows from (33.27).
Combining (12.27) and (33.28), we obtain that the interval
contains less than 2r(h′) dot products h′ · vk, 1 ≤ k ≤ N. Using (33.29)–(33.31) we
obtain 
the 
following 
analog 
of 
(33.10): 

where we used that for every h(1) · vj1 there are at most 4 · 2r(h(2)) dot products
h(2) · vj2 such that 
at the end of (33.32) we used the following consequence of (33.27):
and finally, we used
By (33.32) we have the upper bound

Using the definition (12.6) of Λ(h) and the trivial inequality
for 
h 
∈ 
Z3 
\ 
0, 
we 
can 
easily 
estimate 
the 
infinite 
sum 
Combining (33.33) and (33.34), in Case 1 we have
Let us return to (33.26); we clearly have
where in the last step we used (33.35) and (33.13). Note that (33.36) holds under
the condition of Case 1.
Next we estimate the last sum in (33.24). The same way as we derived
(33.15) from (33.10), we can derive the following inequality from (33.32): 

where the upper end πU |h(2)| in the last sum comes from (33.30) with the choice
h′ = h(2).
Using the fact
we have
and applying it for the end part of (33.37), we obtain

where we used the fact that the function
Using the definition (12.6) of Λ(h) and the simple inequalities
and

for h = (h1, h2, h3) ∈ Z3 \ 0, we can easily estimate the infinite sum 
Combining (33.37)–(33.39) and (33.34), in Case 1 we have
Clearly
where in the last step we used (33.40) and (33.19). Note that (33.41) holds under

the condition of Case 1.
Applying (33.36) and (33.41) in (33.24), we obtain the upper bound
assuming Case 1.
Next we estimate (33.6) under the condition that Case 1 fails.
Case 2: 
Just like before, we can repeat the argument of Case 1 with the minor change
that we use (12.26) instead of (12.27), which gives an extra factor of 6 log N.
Thus 
we 
obtain 
the 
following 
analog 
of 
(33.42): 
assuming Case 2.
Note that in Case 2 we have the upper bound log N ≤ 4 log U, and using it in
(33.43), 
Combining (33.41) and (33.44), we obtain the upper bound
which holds in both Case 1 and Case 2.
Finally, combining (33.1), (33.23) and (33.45), we conclude

which completes the proof of Lemma 12.2.
34. Multiple Mixedupness (III): Proof of Theorem 12.2
Similarly to the proof of Lemma 12.2 (see (12.36)–(12.39)), we fix a sequence
v1, v2, . . . , vN ∈ S2 of N unit vectors on the unit sphere that satisfies the
Separation Condition (12.26)–(12.27). Let J ⊆ {1, 2, 3, . . . , N} be a subset, and
consider 
the 
3-dimensional 
torus 
system 
where of course modulo one means the fractional part applied coordinate-wise, 0
≤ 
t 
≤ 
U 
refers 
to 
the 
time 
evolution, 
and 
is the initial configuration (i.e., a |J|-element point set in the unit torus I3 = [0,
1)3). Let A ⊂ [0, 1)3 be a Lebesgue measurable set; we study the integral 

where
We need the following simple lemma.
Lemma 34.1. For every Lebesgue measurable test set A ⊂ [0, 1)3 = I3 with
vol(A) 
= 
p 
and 
q 
= 
1 
− 
p, 
we 
have 
where
Proof. For notational convenience we work with the test function f = χA instead
of the test set A; we define f on the torus I3 (i.e., we extend f periodically), and
consider 
its 
Fourier 
expansion 
where of course n · z = n1z1 + n2z2 + n3z3 and i = 
. Clearly a0 = ∫I3 f dV =
vol(A).
If f is replaced with a translated function fw(z) = f(z − w) (i.e., f is translated
modulo one by a fixed vector w ∈ I3), then the corresponding Fourier coefficient
changes as follows: 
By (34.5) and (34.6) we have

By squaring (34.7) we have
where, as usual,  = x − iy denotes the complex conjugate of a complex number z
= x + iy.
Next we integrate (34.8) as t runs from 0 to U, and divide the integral by U: 
Since
for all n ∈ Z3 except the trivial case n = 0, by (34.9) and (34.10) we have 

Applying Parseval’s formula for the function f = χA, we have
Finally note that
Lemma 34.1 follows from (34.11), (34.12) and (34.13).
We estimate the critical sum in Lemma 34.1 by distinguishing three cases
according as
Formally,
where

and
We start with Part Two; we rewrite (34.17) as follows:
We have the trivial implication
We recall (12.26): for every nonzero lattice point n ∈ Z3 \ 0 and every integer
−N ≤ ℓ ≤ N − 1, 
The hypothesis of Part Two
implies

Using (34.20)–(34.23), we can estimate the end sum of (34.19) as follows:
since by (34.22),
Using (34.24) in (34.19), we have
where we used Parseval’s formula (see (34.12))
Next we switch to Part Three. Then
and we have the following analog of (34.19)–(34.25):

where we used (34.26), (34.27) and the equality
Finally, we estimate Part One, i.e., we assume
For every lattice point n ∈ Z3 satisfying (34.29), let r(n) = r(n; U; N) denote the
smallest integer such that 
By (34.29) and (34.30),
(12.27) and (34.31) give that every interval
contains less than 2r dot products n · vk, 1 ≤ k ≤ N (with r = r(n)). Combining
this information with (34.30) and (34.32), we obtain the upper bound 

where at the end we used (34.26).
Combining Lemma 34.1, (34.15), (34.25), (34.28) and (34.33), we have
if U ≥ 10 and N ≥ 106. Thus we obtain the following analog of Lemma 12.2.
Lemma 34.2. Let v1, v2, . . . , vN ∈ S2 be a sequence of N ≥ 106 unit vectors on
the unit sphere that satisfies the Separation Condition (12.26)– (12.27). Then for
every subset J ⊆ {1, 2, 3, . . . , N}, every initial configuration (12.37), every
Lebesgue measurable subset A ⊂ [0, 1)3 with vol(A) = p and q = 1 − p, and
every 
real 
number 
U 
≥ 
10, 
we 
have 

We derive Theorem 12.2 from Lemma 34.2 the same way — by repeated
application — as we derived Theorem 12.1 from Lemma 12.2. Again we choose
an arbitrary sequence v1, v2, . . . , vN ∈ S2 of N unit vectors on the unit sphere
that satisfies the Separation Condition (12.26)–(12.27); in the applications of
Lemma 34.2 we use the short notation 
We choose a sequence A1, . . . , Ak of k Lebesgue measurable sets in the unit cube
[0, 
1)3; 
choose 
a 
positive 
ε 
such 
that 
(and so qi = 1 − pi), choose an initial configuration
and choose a real number T0 > 0. We apply Lemma 34.2 with A = A1, 
representing the initial configuration, and obtain the upper bound for every real
U1 ≥ 10
For every η1 > 0 let
Combining (34.36) and (34.37), we have the following upper bound for the 4-
dimensional 
Lebesgue 
measure 
Next we choose an arbitrary (τ1, w1) ∈ [0, U1] × I3 \ S1(U1; η1), and define 
By definition

By (34.37) and (34.40),
Next we apply Lemma 34.2 with the initial configuration
and obtain the upper bound for every real U2 ≥ 10
For every η2 > 0 let
Combining (34.42) and (34.43), we have
Next we choose an arbitrary (τ2, w2) ∈ [0, U2] × I3 \ S1(τ1; w1: U2; η2), and
define 
where we used (34.39). By definition
By (34.43) and (34.46),
and combining it with (34.41), we have

Next we apply Lemma 34.2 with A = A3 and the initial configuration
and obtain the upper bound for every real U3 ≥ 10
For every η3 > 0 let
Combining (34.49) and (34.50), we have
Next we choose an arbitrary (τ3; w3) ∈ [0, U3]×I3\S2(τ1; w1; τ2; w2; U3; η3), and
define 
where we used (34.45).
By definition
By (34.50) and (34.53),

and combining it with (34.47), we have
which is the analog of (34.47).
We keep repeating this argument until we cover all k given measurable test
sets A1, . . . , Ak. At the end of the process we obtain a subset of J0 = {1, 2, 3, . . .
, N}
with
(a 
generalization 
of 
(34.54)), 
where 
pi 
= 
vol(Ai) 
(see 
(34.34)), 
and (see (34.51) for i = 3)
for i ≥ 2, and (see (34.38))
Since
holds for every 1 ≤ h ≤ k, by (34.58) we have for i ≥ 2

Next we specify the parameters Ui and ηi : let
which implies (see (12.68))
and so by (34.56),
Next we use (34.61) and (34.62) in (34.60), and also use
(see (34.34)): thus we obtain
Finally, simple calculation gives that the inequality
holds if
and
Thus by (34.54)–(34.67), we have

for 1 ≤ i ≤ k, which implies
Combining the Separation Condition (see (12.26)–(12.27)) with (34.55), (34.57)
and 
(34.68), 
Theorem 
12.2 
follows 
with 
the 
choice 
Thus the proof of Theorem 12.2 is complete.

References
[Be2015] J. Beck, From Khinchin’s conjecture on strong uniformity to superuniform motions, Mathematika
61 (2015) 591–707.
[Ch-Ma2006] N. Chernov and R. Makarian, Chaotic Billiards, Mathematical Surveys and Monographs, Vol.
127 (Amer. Math. Soc., 2006).
[C-F-S82] I. P. Cornfeld, S. V. Fomin and Ya. G. Sinai, Ergodic Theory (Springer Verlag, 1982).
[Dr-Ti97] M. Drmota and R. F. Tichy, Sequences, Discrepancies and Applications, Lecture Notes in Math.
Vol. 1651 (Springer Verlag, 1997).
[F71] W. Feller, An Introduction to Probability Theory and its Applications, Vols. 1–2, 2nd edition (Wiley,
1971).
[Gr-St92] G. R. Grimmett and D. R. Stirzaker, Probability and Random Processes, 2nd edition (Clarendon
Press, 1992).
[Ke-Ma-Sm86] S. Kerckhoff, H. Masur and J. Smillie, Ergodicity of billiard flows and quadratic
differentials, Annals of Math. 124 (1986) 293–311.
[Kh23] A. Khinchin, Eins Satz über Kettenbrüche mit arithmetischen Adwendungen, Math. Z. 18 (1923)
289–306.
[Kh49] A. Khinchin, Mathematical Foundations of Statistical Mechanics (Dover Publ., 1949).
[Kö-Sz13] D. König and A. Szücs, Mouvement d’un point abandonne a l’interier d’un cube, Rend. Circ.
Mat. Palermo 36 (1913) 79–90.
[Ku-Ni74] L. Kuipers and H. Niederreiter, Uniform Distribution of Sequences (Wiley-Interscience, 1974).
[Mac51] A. M. Macbeath, An extremal property of the hypersphere, Math. Proc. Cambridge Phil. Soc. 47
(1951) 245–247.
[Mar70] J. M. Marstrand, On Khinchin’s conjecture about strong uniform distribution, Proc. London Math.
Soc. 21 (1970) 540–556.
[Ra36] D. A. Raikov, On some arithmetical properties of summable functions, Mat. Sbornik 1 (1936) 377–
384.
[Re62] A. Renyi, Wahrscheinlichkeitsrechnung, (Probability Theory in German) (Deutscher Verlag der
Wissenschaften, 1962).
[Ri45] F. Riesz, Sur la théorie ergodique, Comment. Math. Helv. 17 (1945) 221–239.
[Sa39] E. Sas, Über eine Extremumeigenshaft der Ellipsen, Compositio Math. 6 (1939) 468–470.
[Sch75] W. M. Schmidt, Irregukarities of distribution. IX, Acta Arithmetica 27 (1975) 385–396.
[Wal82] P. Walters, An Introduction to Ergodic Theory, Graduate Texts in Math. Vol. 79, (Springer, 1982).
[Wat58] G. N. Watson, A Treatise of Bessel Functions (Cambridge Univ. Press, 1958).
[We16] H. Weyl, Über die Gleichverteilung von Zahlen mod Eins, Math. Ann. 77 (1916) 313–352.

Index
(1 + ε)/2-power box-equilibrium, 9, 291
all convex sets, 259
alternation of equilibrium and off-equilibrium states, 291
asymptotic CLT, 30, 138
asymptotic Poisson law, 31, 140
asymptotic time-lapse randomness, 31, 137
Bernstein inequality, 49
Bessel function, 132
Birkhoff’s individual ergodic theorem, 9
case of closed orbits, 216
case of singular underlying measure, 316
Central Limit Theorem: Berry–Esseen version, 30, 208
circles system, 316
CLT, 30
CLT partition test, 205
complexity-free and start-free strong uniformity, 19
complexity-free strong uniformity, 11
compound systems with circles, 316, 320
conf-space equilibrium, 22 configuration space, 22
conjecture of Khinchin, 11
continuous Erdős–Turán–Koksma inequality, 33, 152
curve r(t) ∈ Rd is uniformly distributed modulo one, 8
d-dimensional continuous form of the Kronecker–Weyl equidistribution theorem, 9
dimension-free strong uniformity, 11
dimension-free strong uniformity on a realistic time scale, 39
Dirichlet’s simultaneous diophantine approximation theorem, 1
exponential decay, 181
extension theorem, 318
extensions of theorem 4.2 beyond the Gaussian case, 170

fast approach to configuration space equilibrium, xi
Fourier transform, 178
general compound models, 323
general model, 119
great circle diameter model, 217
Hankel’s formula, 135
instant conf-space equilibrium, 305, 307
isotropic Fourier transform, 337
Jordan measurable, 8
Kronecker’s density theorem, 1
Kronecker–Weyl equidistribution theorem, 1
large deviation type inequality in probability theory, 49
linearly independent over the rationals, 2
long term stability of different forms of equilibria, xi
Macbeath theorem in the 3-space, 288
Maxwellian speed distribution, 35
metatheorem, 44
(multi-dimensional) Gaussian (velocity) distribution, 35
multinomial Poisson, 141
multinomial theorem, 355, 372, 387
multiple mixedupness, 405, 420
non-ergodic time-flow: closed orbit spherical systems, 56
nonlinear curves on the plane, 188
Parseval’s formula, 336, 351, 356, 383, 423
Parseval–Plancherel formula, 178
particle space, xi, 22
Poincaré recurrence theorem, 2
Poisson representation formula, 133
polylogarithmic error term, 15
polynomial decay, 175
ProdMeasGauss, 36
product measure, 36
randomness and stability in equilibrium, 259
Red-Blue-CLT test, 216
relaxation distance for simultaneous convex equilibrium, 286
robust uniformity, xi, 11, 41
Sas’s theorem, 260
Schmidt’s discrepancy theorem for convex sets, 289
short-term time-lapse randomness: multiple mixedupness, 149
short-time ergodic theorems, ix, 45, 48
simultaneous convex equilibrium in the particle space, 286
simultaneous square-root equilibrium relative to nice sets, 259
snapshot randomness, 205, 216

spherical great-circle system, 316
square-root equilibrium, 22, 45
square-root fluctuation equilibrium in the particle space, 45
square root fluctuation equilibrium, CLT and Poisson snapshot equilibrium, xii, 45
square-root logarithmic threshold in the Gaussian case, 295
standard normal distribution, 38
start-free strong uniformity, complexity-free strong uniformity, 11
start-free, 17
Stirling’s formula, 329
strong (and robust) uniformity in the configuration space, x
strong uniform distribution, 437
strong uniformity, 11, 437
superdiscrepancy, 26, 144
superuniformity, 15
threshold for configuration space equilibrium, 42
time discrepancy, 20
two-dimensional case where the particles move on general non-linear curves, 314
unfolding, 22
uniformly distributed modulo one, 6
uniformity with square-root error simultaneously for a whole family of nice test sets (in the particle space),
259
unique ergodicity, 45
unique ergodicity theorem, 124
vanishing property, 185
weak uniformity theorem, 122
Weyl’s criterion, 7

