E.S. Gopi
Multi-Disciplinary 
Digital Signal 
Processing
A Functional Approach Using Matlab

Multi-Disciplinary Digital Signal Processing

E.S. Gopi
Multi-Disciplinary Digital
Signal Processing
A Functional Approach Using Matlab
123

E.S. Gopi
Department of ECE
National Institute of Technology,
Tiruchirappalli
Trichy, Tamil Nadu
India
ISBN 978-3-319-57429-5
ISBN 978-3-319-57430-1
(eBook)
DOI 10.1007/978-3-319-57430-1
Library of Congress Control Number: 2017938129
© Springer International Publishing AG 2018
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made. The publisher remains neutral with regard to
jurisdictional claims in published maps and institutional afﬁliations.
Printed on acid-free paper
This Springer imprint is published by Springer Nature
The registered company is Springer International Publishing AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Dedicated to my wife G. Viji, my son
A.G. Vasig, and my daughter A.G. Desna.

Acknowledgements
I
would
like
to
thank
Prof.
Dr.
Mini
Shaji
Thomas
(Director,
NITT),
Prof. M. Chidambaram (IITM, Chennai), Prof. K.M.M. Prabhu (IITM, Chennai),
Prof. S. Soundararajan (Former Director, NIT, Trichy), Prof P. Palanisamy,
Prof. B. Venkataramani, and Prof. S. Raghavan (NIT, Trichy) for their support.
I would also like to thank those who helped directly or indirectly in bringing out
this book successfully. Special thanks to my parents Mr. E. Sankara Subbu and
Mrs. E.S. Meena.I thankthe researchscholars Ms. C. Florintina and Ms. G.JayaBrinda
for their assistance in proof reading the ﬁnal manuscript.
Thanks,
E.S. Gopi
vii

Contents
1
Sampling and Reconstruction of Signals . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Sampling of Sinusoidal Signal . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Fourier Series (FS). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
1.2.1
Dirichlet Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.3
Fourier Transformation (FT) . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.4
Discrete Time Fourier Transformation (DTFT) and Sampling
Theorem. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
1.5
Discrete Fourier Transformation (DFT)
(Sampling the Frequency Domain). . . . . . . . . . . . . . . . . . . . . . . .
18
1.5.1
Vector Space Interpretation of DFT . . . . . . . . . . . . . . . .
20
1.5.2
Fast Fourier Transformation . . . . . . . . . . . . . . . . . . . . . .
21
1.5.3
Sub-band Discrete Fourier Transformation . . . . . . . . . . .
25
1.6
Continous System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
1.7
Laplace Transformation (s-Transformation) . . . . . . . . . . . . . . . . .
30
1.7.1
Properties of the ROC of the Laplace Transformation
for the Right Sided Sequence . . . . . . . . . . . . . . . . . . . . .
30
1.7.2
Inverse Laplace Transformation . . . . . . . . . . . . . . . . . . .
31
1.8
Geometrical Interpretation of Computation of Magnitude
Response of the Filter Using Pole-Zero Plot
of s-Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
1.9
Discrete System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
1.10
Z-Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
35
1.10.1
Properties of the ROC of the Z-Transformation
for the Right-Sided Sequence . . . . . . . . . . . . . . . . . . . . .
35
1.10.2
Inverse Z-Transformation . . . . . . . . . . . . . . . . . . . . . . . .
36
1.11
Response of the Digital Filter with the Typical Transfer
Function (Obtained Using DTFT) to the Periodic Sequence . . . .
37
1.12
Geometrical Interpretation of Computation of Magnitude
Response of the Filter Using Pole-Zero Plot
of z-Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
ix

2
Inﬁnite Impulse Response (IIR) Filter. . . . . . . . . . . . . . . . . . . . . . . . .
43
2.1
Impulse-Invariant Mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
2.2
Bilinear Transformation Mapping . . . . . . . . . . . . . . . . . . . . . . . .
44
2.2.1
Frequency Pre-warping . . . . . . . . . . . . . . . . . . . . . . . . . .
45
2.2.2
Design of Digital IIR Filter using Butterworth
Analog Filter and Impulse-Invariant Transformation. . . .
47
2.2.3
Design of Digital IIR Filter using Butterworth
Analog Filter and Bilinear Transformation . . . . . . . . . .
47
2.2.4
Design of Digital IIR Filter Using Chebyshev
Analog Filter and Impulse-Invariant Transformation. . . .
49
2.2.5
Design of Digital IIR Filter Using Chebyshev
Analog Filter and Bilinear Transformation . . . . . . . . . . .
49
2.2.6
Comments on Fig. 2.7 and Fig. 2.8 . . . . . . . . . . . . . . . .
58
2.2.7
Design of High-Pass, Bandpass, and Band-Reject IIR
Filter. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
59
2.3
Realization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
2.3.1
Direct Form 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
2.3.2
Direct Form 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
2.3.3
Illustration. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
3
Finite Impulse Response Filter (FIR Filter) . . . . . . . . . . . . . . . . . . . .
77
3.1
Demonstration of Four Types of FIR Filter . . . . . . . . . . . . . . . . .
78
3.2
Design of Linear Phase FIR Filter-Windowing Technique . . . . . .
90
3.2.1
Design of Low-Pass Filter . . . . . . . . . . . . . . . . . . . . . . .
90
3.2.2
Design of High-Pass Filter . . . . . . . . . . . . . . . . . . . . . . .
97
3.2.3
Design of Band Pass and Band Reject Filter . . . . . . . . .
97
3.2.4
Windows Used to Circumvent Ripples
in the Magnitude Response. . . . . . . . . . . . . . . . . . . . . . .
105
3.3
FIR Filters that Have Identical Magnitude Response . . . . . . . . . .
113
4
Multirate Digital Signal Processing . . . . . . . . . . . . . . . . . . . . . . . . . . .
121
4.1
Sampling Rate Conversion by the Factor M
N . . . . . . . . . . . . . . . . .
121
4.1.1
Upsampling (with N ¼ 1) . . . . . . . . . . . . . . . . . . . . . . . .
121
4.1.2
Downsampling (with M ¼ 1) . . . . . . . . . . . . . . . . . . . . .
122
4.1.3
Comments on the Fig. 4.1 . . . . . . . . . . . . . . . . . . . . . . .
123
4.2
Poly-phase Realization of the Filter for Interpolation. . . . . . . . . .
125
4.3
Poly-phase Realization of the Filter for Decimation. . . . . . . . . . .
130
4.4
Quadrature Mirror Filter. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
137
4.5
Transmultiplexer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
142
5
Statistical Signal Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
5.1
Introduction to Random Process . . . . . . . . . . . . . . . . . . . . . . . . .
147
5.1.1
Illustration on W.S.S.R.P and Nonstationary Random
Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
x
Contents

5.2
Auto Regressive (AR), Moving Average (MA) and Auto
Regressive Moving Average (ARMA) Modeling . . . . . . . . . . . . .
150
5.2.1
Linear Prediction Model . . . . . . . . . . . . . . . . . . . . . . . . .
151
5.3
Adaptive Filter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
157
5.3.1
System Model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
157
5.3.2
Filtering Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
163
5.4
Spectral Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
166
5.4.1
Eigen Decomposition Method
for Spectral Estimation . . . . . . . . . . . . . . . . . . . . . . . . . .
166
5.4.2
Pisarenko Harmonic Decomposition . . . . . . . . . . . . . . . .
168
5.4.3
MUSIC (Multiple Signal Classiﬁcation) Method . . . . . .
169
5.4.4
ESPRIT (Estimation of Signal Parameters
Via Rotational Invariance Technique). . . . . . . . . . . . . . .
170
6
Selected Applications in Multidisciplinary Domain . . . . . . . . . . . . . .
177
6.1
Multipath Transmission in Wireless Communication . . . . . . . . . .
177
6.2
Cyclic Preﬁx in Orthogonal Frequency Division Multiplexing
(OFDM). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
180
6.3
Projection Slice Theorem for Computed Tomography
Imaging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
182
6.4
Warped Discrete Fourier Transformation for Speech Signal. . . . .
185
6.5
Nonuniform Discrete Fourier Transformation
for the Compressive Sensing Applications . . . . . . . . . . . . . . . . . .
187
6.6
Nonuniform Sampling of Real Data in Multidisciplinary
Applications-Linear Model for Regression . . . . . . . . . . . . . . . . . .
187
6.6.1
Maximum Likelihood Estimation . . . . . . . . . . . . . . . . . .
188
6.6.2
Least Square Estimation . . . . . . . . . . . . . . . . . . . . . . . . .
189
6.6.3
Bayes Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
190
6.6.4
Kernel Smoothing Function for Regression . . . . . . . . . .
191
List of m-ﬁles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
199
Contents
xi

Chapter 1
Sampling and Reconstruction of Signals
1.1
Sampling of Sinusoidal Signal
Consider the signal x(t) = sin(2πfit), where i=1,2,3 with f1 = 1 Hz, f2 = 11Hz and
f3 = 21Hz that are sampled with the identical sampling frequency fs = 10Hz to
obtain the discrete sequence x(nTs) = sin(2πfinTs) (refer Fig.1.1). From the ﬁgure,
we observe that amplitude of the discrete sequence obtained from all the three signals
ends up with identical values. In fact, we get the identical sequence for inﬁnite
number of sinusoidal signals with frequencies given as fr = f1 + rfs. The discrete
sequences obtained from the signal x1(t) = sin(2πf1t) and x2(t) = sin(2πfrt), with
fr = f1 + rfs, where fs is the identical sampling frequency used to sample both the
signals are obtained as follows.
x1(t) = sin(2πf1 ∗t)
(1.1)
⇒x1(nTs) = sin(2πf1 ∗nTs)
(1.2)
Also the discrete sequence obtained from the signal x2(t) is obtained as follows.
x2(t) = sin(2πfr ∗t)
(1.3)
⇒x2(nTs) = sin(2π(f1 + rfs) ∗nTs) = sin(2π(f1 ∗nTs)
(1.4)
Thus we observed that the identical sequences are obtained by sampling the signals
x1(t) and x2(t) when sampled using the identical sampling frequency. Intuitively we
understand that the frequency content of the discrete sequence obtained are f1 + rfs,
i.e., the spectrum is periodic with the period fs. If the analog low pass ﬁlter
h1(t) = sinc( t
Ts
)
(1.5)
© Springer International Publishing AG 2018
E.S. Gopi, Multi-Disciplinary Digital Signal Processing,
DOI 10.1007/978-3-319-57430-1_1
1

2
1
Sampling and Reconstruction of Signals
(a)
(b)
Fig. 1.1 Illustrating sampling of three sinusoidal signals (with different frequencies) with ﬁxed
sampling frequency ends up with identical sequence
Fig. 1.2 a Impulse response of the Low pass ﬁlter sinc( t
Ts) (that allows 1 Hz) used to reconstruct
the signal back from the discrete sequence generated in the Fig.1.1. b Corresponding magnitude
response

1.1 Sampling of Sinusoidal Signal
3
Fig. 1.3 a Impulse response of the Band pass ﬁlter constructed using the low pass ﬁlter used in
Fig.1.2 (that allows 11 and 9 Hz) used to reconstruct the signal back from the discrete sequence
generated in the Fig.1.1. b Corresponding magnitude response
Fig. 1.4 a Impulse response of the Band pass ﬁlter constructed using the low pass ﬁlter used in
Fig.1.2 (that allows 19 and 21 Hz) used to reconstruct the signal back from the discrete sequence
generated in the Fig.1.1. b Corresponding magnitude response

4
1
Sampling and Reconstruction of Signals
Fig. 1.5 a, b and c are the reconstructed signals obtained using the ﬁlter used in Figs.1.2, 1.5 and
1.6 respectively. d, e and f shows the corresponding spectrum
Fig. 1.6 a Impulse response of the narrow Band pass ﬁlter (that allows 11 Hz) used to reconstruct
the signal back from the discrete sequence generated in the Fig.1.1. b Corresponding magnitude
response

1.1 Sampling of Sinusoidal Signal
5
Fig. 1.7 a Impulse response of the narrow Band pass ﬁlter (that allows 21 Hz) used to reconstruct
the signal back from the discrete sequence generated in the Fig.1.1. b Corresponding magnitude
response
Fig. 1.8 a, c and e Are the continuous signals reconstructed from the samples using the ﬁlter
described in Figs.1.2, 1.6 and 1.7 respectively. b, d and f Shows the corresponding spectrum

6
1
Sampling and Reconstruction of Signals
Fig. 1.9 Demonstrating nonoverlapping of spectrum in DTFT domain when Fmax < Fs
2 . a Low
pass signal with the maximum frequency content of 0.1 Hz in time domain. b Corresponding
spectrum. c Discrete version of the signal in (a) with Fs = 1 Hz. d Corresponding spectrum obtained
using DTFT. e Low pass signal with the maximum frequency content of 0.3 Hz in time domain. f
Corresponding spectrum. g Discrete version of the signal in (e) with Fs = 1 Hz. h Corresponding
spectrum using DTFT

1.1 Sampling of Sinusoidal Signal
7
Fig. 1.10 Demonstrating marginal overlapping of spectrum in DTFT domain when Fmax = Fs
2 . a
Low pass signal with the maximum frequency content of 0.5 Hz in time domain. b Corresponding
spectrum. c Discrete version of the signal in (a) with Fs = 1 Hz. d Corresponding spectrum obtained
using DTFT
(refer Fig.1.2) that allow 1 Hz signal is used to reconstruct the sequence x1(nTs),
we get the sinusoidal signal with frequency 1 Hz. If the identical sequence is recon-
structed using the band pass analog ﬁlter with mid-band frequency 11 Hz
h2(t) = 1
2sinc( t
Ts
)e−j2π11t + sinc( t
Ts
)ej2π11t;
(1.6)
(refer Fig.1.3), we get two sinusoidal signal with frequencies 9 and 11 Hz. Note
that the bandwidth is constructed such that it allows both 9 and 11 Hz. Similarly if
the identical sequence is reconstructed using the narrow band pass analog frequency
with mid-band frequency 21 Hz
h2(t) = 1
2sinc( t
Ts
)e−j2π21t + sinc( t
Ts
)Tsej2π21t;
(1.7)
(refer Fig.1.4), we get two sinusoidal components with frequencies 19 and 21 Hz.
Figure1.5 demonstrates the reconstruction of three different single tone signals
using three different ﬁlters from the identical discrete sequence. But if we have two
narrow Band pass ﬁlters that allow 11 Hz ( 1
2sinc(
t
10Ts )e−j2π11t + sinc(
t
10Ts )ej2π11t),

8
1
Sampling and Reconstruction of Signals
Fig. 1.11 Demonstrating Overlapping of spectrum in DTFT domain when Fmax > Fs
2 . a Low
pass signal with the maximum frequency content of 0.7 Hz in time domain. b Corresponding
spectrum. c Discrete version of the signal in (a) with Fs = 1 Hz. d Corresponding spectrum obtained
using DTFT. e Low pass signal with the maximum frequency content of 0.9 Hz in time domain. f
Corresponding spectrum. g Discrete version of the signal in (e) with Fs = 1 Hz. h Corresponding
spectrum using DTFT

1.1 Sampling of Sinusoidal Signal
9
21 Hz ( 1
2sinc(
t
10Ts )e−j2π11t + sinc(
t
10Ts )ej2π11t) frequency, we get the corresponding
sinusoidal components as the output of the ﬁlters (refer Figs.1.6, 1.7 and 1.8). Ideally
we would like to use the analog ﬁlter to reconstruct the samples back to the continu-
ous domain. But to demonstrate this, we simulate reconstruction in discrete domain.
The resolution to represent the impulse response of the analog ﬁlter is 1/1000s. It
is noted that it is not the actual sampling frequency used to sample the signal to get
the discrete sequence (as described above). The spectrum of the low pass, bandpass
ﬁlters used to demonstrate the reconstruction involves the periodic spectrum of 1000
Hz. This is due to discrete ﬁlter used to reconstruct the signal back. We reconstruct
the signal back with the resolution 1/1000s. In reality, the reconstruction is done
using the analog ﬁlter to obtain the continuous signal.
function [res]=demonstratereconstruction(option)
%option=1: Using the
band pass filters constructed
%using the low pass reconstruction filter
%opition=2: Using 10 times narrow band pass filters
figure
subplot(2,1,1)
t=-2:1/1000:2;
x1=sin(2*pi*1*t);
plot(t,x1,’r’)
hold on
x2=sin(2*pi*11*t);
plot(t,x2,’b’)
hold on
x3=sin(2*pi*21*t);
plot(t,x3,’k’)
Ts=1/10;
n=-20:1:20;
hold on
xn1=sin(2*pi*1*n*Ts);
plot(n*Ts,sin(2*pi*1*n*Ts),’m*’)
subplot(2,1,2)
stem(n*Ts,sin(2*pi*1*n*Ts),’m*’)
switch option
case 1
%Reconstruction using low pass filter
%Reconstruction using band pass filter 1
%Reconstruction using band pass filter 2
t1=-2:1/1000:2;
h1=sinc(t1/Ts);
w=window(@hamming,length(h1));
h1=h1.*w’;
h2=(sinc(t1/Ts).*exp(-j*2*pi*11*t1)+sinc(t1/Ts).* ...
exp(j*2*pi*11*t1))/2;
h2=h2.*w’;
h3=(sinc(t1/Ts).*exp(-j*2*pi*21*t1)+sinc(t1/Ts).*...
exp(j*2*pi*21*t1))/2;
h3=h3.*w’;
figure
subplot(2,1,1)
plot(-2:1/1000:2,h1)
subplot(2,1,2)

10
1
Sampling and Reconstruction of Signals
plot(linspace(0,1000,length(h1)),abs(fft(h1)))
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%OR%
case 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Reconstruction using low pass filter
%Reconstruction using 10 times narrow band pass filter 1
%Reconstruction using 10 times narrow band pass filter 2
t1=-2:1/1000:2;
h1=sinc(t1/Ts);
w=window(@hamming,length(h1));
h1=h1.*w’;
h2=(sinc(t1/10*Ts).*exp(-j*2*pi*11*t1)+sinc(t1/10*Ts).* ...
exp(j*2*pi*11*t1))/2;
h2=h2.*w’;
h3=(sinc(t1/10*Ts).*exp(-j*2*pi*21*t1)+sinc(t1/10*Ts).* ...
exp(j*2*pi*21*t1))/2;
h3=h3.*w’;
figure
subplot(2,1,1)
plot(-2:1/1000:2,h1)
subplot(2,1,2)
plot(linspace(0,1000,length(h1)),abs(fft(h1)))
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
end
figure
subplot(2,1,1)
plot(-2:1/1000:2,h2)
subplot(2,1,2)
plot(linspace(0,1000,length(h2)),abs(fft(h2)))
figure
subplot(2,1,1)
plot(-2:1/1000:2,h3)
subplot(2,1,2)
plot(linspace(0,1000,length(h3)),abs(fft(h3)))
%Inserting zeros
temp=[];
for i=1:1:41
temp=[temp xn1(i) zeros(1,99)];
end
temp=temp(1:1:4001);
temp=temp.*window(@hamming,length(temp))’;
y1=conv(temp,h1);
y2=conv(temp,h2);
y3=conv(temp,h3);
figure
subplot(2,3,1)
plot([-4:1/1000:4],y1,’b’)
subplot(2,3,2)
plot([-4:1/1000:4],y2,’b’)
subplot(2,3,3)
plot([-4:1/1000:4],y3,’b’)
temp1=[];
temp2=[];
temp3=[];
t=-4+(1/1000):(1/1000):4-(1/1000);

1.1 Sampling of Sinusoidal Signal
11
%Trapezoidal rule
temp1=[];
temp2=[];
for f=0:1/231:50
temp1= [temp1 abs(y1(1)*(exp(-j*2*pi*f*(-4))+ ...
sum(y1(2:1:length(y1)-1).*exp(-j*2*pi*f*t))+ ...
y1(length(y1))*exp(-j*2*pi*f*(4))))];
temp2=[temp2 abs(y2(1)*(exp(-j*2*pi*f*(-4))+ ...
sum(y2(2:1:length(y2)-1).*exp(-j*2*pi*f*t))+ ...
y2(length(y2))*exp(-j*2*pi*f*(4))))];
temp3=[temp3 abs(y3(1)*(exp(-j*2*pi*f*(-4))+ ...
sum(y3(2:1:length(y3)-1).*exp(-j*2*pi*f*t))+ ...
y3(length(y3))*exp(-j*2*pi*f*(4))))];
end
f=0:1/231:50;
subplot(2,3,4)
plot(f, temp1)
subplot(2,3,5)
plot(f, temp2)
subplot(2,3,6)
plot(f,temp3)
1.2
Fourier Series (FS)
Any periodic signal (satisfying Dirichlet conditions) x(t) with time period T0 = 1
f0
(f0 is the fundamental frequency) can be represented as the summation of sinusoid,
cosines, and constant amplitude signal as follows.
x(t) = a0 +
k=∞

k=1
aksin(2πkf0t) +
k=∞

k=1
bkcos(2πkf0t)
(1.8)
As the signal is periodic, we consider the signal for one time period T0 (represented
as xT(t)) as the vector. Also, we represent the set of sine and cosine signals in (1.8)
for one period as follows.
ST,k(t) = sin(2πkf0t), CT,k(t) = cos(2πkf0t)
(1.9)
The vector xT(t) is viewed as the vector in the space spanned by the orthonormal
basis vectors
2
T0 ST,k(t),
2
T0 CT,k(t) and
1
T0 (constant over the period 0 to T0) and we
obtain the co-efﬁcients a0, ak and bk (k = 1, 2 · · · ) as follows.
a0 = 1
T0
 T0
0
xT(t)dt = 1
T0
 T0
0
x(t)dt
(1.10)
ak = 2
T0
 T0
0
xT(t)ST,k(t)dt = 2
T0
 T0
0
x(t)sin(2πkf0t)dt
(1.11)

12
1
Sampling and Reconstruction of Signals
bk = 2
T0
 T0
0
xT(t)CT,k(t)dt = 2
T0
 T0
0
x(t)cos(2πkf0t)dt
(1.12)
1.2.1
Dirichlet Conditions
• x(t) is absolutely integrable.
• x(t) should have ﬁnite number of extrema in any given bounded interval.
• x(t) must have ﬁnite number of discontinuities in any given bounded interval.
In this case, the signal in time domain is continuous and periodic and the frequency
domain is discrete.
1.3
Fourier Transformation (FT)
Consider the aperiodic signal x(t). It is assumed that the signal xT0(t) is periodic with
period T0 = 1
f0 and limT0→∞xT0(t) = x(t). Rewriting the Fourier series to represent
the signal xT0(t) as follows.
xT0(t) =
k=∞

k=−∞
ckej2πkf0t
(1.13)
The co-efﬁcient ck is obtained as follows.
ck = 1
T0

T0
2
−T0
2
xT0(t)e−j2πkf0tdt
(1.14)
Let ckT0 = X(kf0)
Rewriting (1.13) using X(kf0), we get the following.
xT0(t) = 1
T0
k=∞

k=−∞
X(kf0)ej2πkf0t
(1.15)
By applying the limit limT0→∞on both sides of (1.15), we get the following.
x(t) =
 ∞
−∞
X(f )ej2πftdf
(1.16)
(1.16) implies,

1.3 Fourier Transformation (FT)
13
X(f ) =
 ∞
−∞
x(t)e−j2πftdt
(1.17)
In this case, time domain is non-periodic and continuous.
1.4
Discrete Time Fourier Transformation (DTFT)
and Sampling Theorem
The continuous time domain signal is sampled to obtain the discrete sequence. Based
on the discussion in the Sect. (1.1), we understand that the corresponding frequency
domain is periodic with the period of sampling frequency Fs. We also see that the
amplitude of the frequency domain obtained with sampling is scaled by the factor
Fs. Thus in the case of DTFT, time domain is discrete and the frequency domain is
continuous and periodic. The DTFT pair is as given below.
X(f ) =
n=∞

n=−∞
x(nTs)e−j2πfnTs
(1.18)
x(nTs) = x(n) = 1
Fs

Fs
2
−Fs
2
X(f )ej2πfnTsdf
(1.19)
The spectrum (DTFT) of the discrete sequences sampled with the sampling fre-
quency of 1Hz from the continous signal whose maximum frequency is gradually
increased from 0.1Hz to 0.9Hz is illustrated in the Figs.1.9, 1.10, 1.11. It is seen
in Fig.1.9, there is no overlapping of spectrum occur in the case when Fmax < Fs
2 .
Figure1.10 illustrates the spectrum when Fmax = Fs
2 and in Fig.1.11 illustrates the
overlappingof oneperiodof thespectrumwithneighbor occur that leads tothealiased
component. This indicate that when the sampling frequency is chosen greater than
or equal to twice the maximum frequency content of the signal, overlapping of one
period of the spectrum does not occur (Aliased component will not get introduced)
(Figs. 1.9, 1.10, 1.11).
Let the Fourier transformation of the signal x(t) be represented as X(f ) and is
zero if | f | > W
2 . If the signal x(t) is sampled with the sampling frequency Fs, we
get the spectrum that is periodic with Fs. From the Fig.1.11, it is observed that if
Fig. 1.12 Illustration of
sampling points between 0 to
2π in DTFT domain to
obtain DFT

14
1
Sampling and Reconstruction of Signals
Fs < 2 W
2 , overlapping of one period of the spectrum with the neighbor period occur.
This is circumvented by choosing Fs ≥2 W
2 . This is known as sampling theorem. It
is possible to reconstruct the signal x(t) from the discrete samples x(nTs) by ﬁltering
Fig. 1.13 a DFT computed using DIT. b DFT computed using the direct method (It is seen that
both are identical)
Fig. 1.14 a Time required to compute DFT using DIT method. b Time required to compute DFT
using the direct method as the function of N

1.4 Discrete Time Fourier Transformation (DTFT) and Sampling Theorem
15
Fig. 1.15 a DFT computed using DIF. b DFT computed using the direct method (It is seen that
both are identical)
Fig. 1.16 a Time required to compute DFT using DIF method. b Time required to compute DFT
using the direct method as the function of N
the discrete samples through the ideal low pass ﬁler with cutoff frequency = Fs
2 . This
is equivalently represented in time domain (using sinc function based interpolation)
as follows.

16
1
Sampling and Reconstruction of Signals
Fig. 1.17 Magnitude response computed using 1024-DFT using. a Direct method. b One level
Sub-band decomposition. c Two-level Sub-band decomposition. (It is seen that all are identical)
%samplingtheorem.m
Demonstration of non-overlapping of spectrum in DTFT
m=1;
for cutoff=0.1:0.2:0.9
figure(m)
h=fir1(1000,cutoff);
Fs=2;
Ts=1/Fs;
%Assuming fmax=1 Hz
%(satisfying the sampling theorem)
n=0:1:length(h)-1;
subplot(4,1,1)
plot(n*Ts,h)
subplot(4,1,2)
m1=[];
for f=-6*Fs:0.01:6*Fs
m1=[m1 abs(sum(h.*exp(-j*2*pi*f*n*Ts)))];
end
f=-6*Fs:0.01:6*Fs;

1.4 Discrete Time Fourier Transformation (DTFT) and Sampling Theorem
17
Fig. 1.18 Magnitude response: a 256 points of 1024-point DFT computed (0.2514s) using the
direct method. b 256-points of 1024-point DFT computed (0.0057s) using Two-level sub-band
decomposition
Fig. 1.19 a s-Plane with the shaded ROC. b z-Plane with the shaded ROC
plot(f,m1)
Ts1=2*Ts;
Fs1=Fs/2;
h1=h(1:2:1001)
n=0:1:length(h1)-1;
subplot(4,1,3)
stem(n*Ts1,h1)
m2=[];
for f=-2*6*Fs1:0.01:2*6*Fs1
m2=[m2 abs(sum(h1.*exp(-j*2*pi*f*n*Ts1)))];

18
1
Sampling and Reconstruction of Signals
Fig. 1.20 Illustration of the Geometrical method of computing magnitude and phase response of
the continous system transfer function H(s)
end
Fs1=1/Ts1;
f=-2*6*Fs1:0.01:2*6*Fs1;
%(Not satisfying the sampling theorem)
subplot(4,1,4)
plot(f,m2)
m=m+1;
end
x(t) =
n=∞

n=−∞
x(nTs)sinc( t
Ts
−n)
(1.20)
DTFT can also be viewed as the dual property of Fourier series. In case of Fourier
series, time domain is periodic in nature and the frequency domain is discrete. Sim-
ilarly in the case of DTFT, the time domain is discrete and the frequency domain is
periodic in nature.
1.5
Discrete Fourier Transformation (DFT) (Sampling
the Frequency Domain)
The spectrum of the discrete samples (DTFT) is periodic with sampling frequency
Fs. DFT is obtained by sampling the DTFT for one period. Let us assume N = 11
number of samples are obtained from one period of the frequency domain DTFT.
DTFT is represented as shown below.

1.5 Discrete Fourier Transformation (DFT) (Sampling the Frequency Domain)
19
X(ejw) =
k=∞

k=−∞
x(n)e−jwn
(1.21)
DFT sequence is obtained by sampling X(ejw) for the duration 0 ≤w ≤2π once in
2 π
N and is represented as follows.
X(k) =
n=N−1

n=0
x(n)e−j 2π
N nk
(1.22)
The sequence x(n) is obtained from the sequence X(k) as x(n) = 1
N
k=N−1
k=0
X(k)ej 2π
N nk
and
the
proof
is
as
shown
below.
Substitute
(1.22)
in
x(n) = 1
N
k=N−1
k=0
X(k)ej 2π
N nk, we get the following.
1
N
k=N−1

k=0
l=N−1

l=0
x(l)e−j 2π
N lkej 2π
N nk
= 1
N
l=N−1

l=0
x(l)
k=N−1

k=0
e−j 2π
N lkej 2π
N nk
= 1
N
l=N−1

l=0
x(l)
k=N−1

k=0
e−j 2π
N (l−n)k
= 1
N x(0)
k=N−1

k=0
e−j 2π
N (0−n)k + x(1)
k=N−1

k=0
e−j 2π
N (1−n)k + · · · +
x(n)
k=N−1

k=0
e−j 2π
N (n−n)k + · · ·
+x(N −1)
k=N−1

k=0
e−j 2π
N (N−1−n)k
⇒x(n) = 0 + 0 + · · · + Nx(n) + 0 + · · · + 0
= x(n)
Hence proved. In this case, both time domain and frequency domain are discrete.

20
1
Sampling and Reconstruction of Signals
1.5.1
Vector Space Interpretation of DFT
The typical DFT matrix DN for arbitrary N is as shown below.
⎛
⎜⎜⎜⎜⎜⎜⎜⎝
1
1
1
· · ·
1
1
W 1∗1
N
W 1∗2
N
· · ·
W 1∗(N−1)
N
1
W 2∗1
N
W 2∗2
N
· · ·
W 2∗(N−1)
N
1
W 3∗1
N
W 3∗2
N
· · ·
W 3∗(N−1)
N
· · ·
· · ·
· · ·
· · ·
· · ·
1 W (N−1)∗1
N
W (N−1)∗2
N
· · · W (N−1)∗(N−1)
N
⎞
⎟⎟⎟⎟⎟⎟⎟⎠
where, WN = e
j2π
N is the twiddle fac-
tor.ThecolumnsoftheDFTmatrixDN isorthogonaltoeachother,i.e.,DH
N DN = NIN,
where IN is the identity matrix of size N × N. Also DFT matrix is the unitary matrix,
i.e., DH
NDN = DNDH
N = NIN. The arbitrary vector v ∈Cn is represented as the linear
combinations of the columns of the DFT matrix, i.e., v = 1
N DNu. The corresponding
co-efﬁcients are obtained as u = DH
Nv. The vector u is known as DFT coefﬁcients
and are obtained using DFT. The method of obtaining v is known as IDFT. Prop-
erties of the DFT matrix is summarized below. The frequency in radians and in Hz
corresponding to the sample number in DFT domain is illustrated in Fig.1.12.
1. The columns of the scaled DFT matrix 1
N is orthogonal to each other. To make it
as the orthonormal vectors, they are scaled with
1
√(N). Let it be SDN = 1
N
2. The eigenvectors of the DFT matrix takes the value i, −i or 1
3. Circulant matrix (A (say)) is diagonalized using DFT matrix as SDNASDH
N =
1
N DNADH
N = D, D is the diagonal matrix.
This implies A = 1
N DH
NDDN. The vector y = Ax (A as the circulant matrix) is the
circular convolution of the vector x and the ﬁrst column of the matrix A and is
computed as 1
N DH
NDDNx. In this DNx is viewed as computing the DFT OF the
vector x (say z1). DDNx is viewed as the scaled version of the vector z1, with
the diagonal elements of the matrix D (say z2). Further 1
N DH
NDDNx is viewed as
the IDFT of the vector z2. It is also observed that the diagonal elements of the
matrix D is the DFT of the ﬁrst column of the matrix A.
4. Demonstration with A =
⎛
⎜⎜⎝
1 4 3 2
2 1 4 3
3 2 1 4
4 3 2 1
⎞
⎟⎟⎠.
x =
5 6 7 8 
we get the following.
DN =
⎛
⎜⎜⎝
1.0000
1.0000
1.0000
1.0000
1.0000 0.0000 + 1.0000i −1.0000 + 0.0000i −0.0000 −1.0000i
1.0000 −1.0000 + 0.0000i 1.0000 −0.0000i −1.0000 + 0.0000i
1.0000 −0.0000 −1.0000i −1.0000 + 0.0000i 0.0000 + 1.0000i
⎞
⎟⎟⎠
z1 =
⎛
⎜⎜⎝
1 4 3 2
2 1 4 3
3 2 1 4
4 3 2 1
⎞
⎟⎟⎠

1.5 Discrete Fourier Transformation (DFT) (Sampling the Frequency Domain)
21
D =
⎛
⎜⎜⎝
26.0000
0
0
0
0
−2.0000 + 2.0000i
0
0
0
0
−2.0000 −0.0000i
0
0
0
0
−2.0000 −2.0000i
⎞
⎟⎟⎠
z2 =
⎛
⎜⎜⎝
10.0000
−2.0000 + 2.0000i
−2.0000 −0.0000i
−2.0000 −2.0000i
⎞
⎟⎟⎠
z3 =
⎛
⎜⎜⎝
66.0000 + 0.0000i
68.0000 + 0.0000i
66.0000 + 0.0000i
60.0000 −0.0000i
⎞
⎟⎟⎠
The z3 thus obtained is the circular convolution of the vector x and the ﬁrst column
of the matrix A, which is obtained as Ax.
%circconvusingDFT.m
%Circular convolution of a with b using DFT-IDFT
a=[1 2 3 4]’;
b=[5 6 7 8]’;
%Constructing DFT matrix
twf=exp(j*2*pi/4);
n=0:1:3;
k=[0:1:3]’;
DN=[twf.ˆn; twf.ˆn; twf.ˆn; twf.ˆn];
DN=[DN(:,1).ˆk DN(:,2).ˆk DN(:,3).ˆk DN(:,4).ˆk]
%DFT of a
z1=DN’*a;
temp=DN’*b;
D=diag(temp);
z2=D*z1;
z3=(1/4)*DN*z2;
%Constructing circulant matrix
C=[1 2 3 4;4 1 2 3;3 4 1 2;2 3 4 1]’;
%Circular convolution of two sequence
z3_direct=C*b;
1.5.2
Fast Fourier Transformation
The number of computations to compute DFT is reduced by the algorithm namely
Fast Fourier Transformation as described below.
1.5.2.1
Decimation in Time for N-Point DFT
The DFT of the sequence x(n) is decomposed as the summation of two terms as
described below.

22
1
Sampling and Reconstruction of Signals
X(k) =
n=N−1

n=0
x(n)e
−j2πnk
N
(1.23)
=
n= N
2 −1

n=0
x(2n)e
−jπ2nk
N
2
+ e
−j2πk
N
n= N
2 −1

n=0
x(2n + 1)e
−j2πnk
N
2
(1.24)
This is realized using recursive technique. Refer Figs.1.13 and 1.14 for illustration.
%dit.m
function [res]=dit(x,N)
%Decimation in time
k=1;
if(N˜=2)
part1=x(1:2:length(x));
part2=x(2:2:length(x));
N=N/2;
k=0:1:N-1;
res1=dit(part1,N)+dit(part2,N).*exp(-j*2*pi*k/(2*N));
res2=dit(part1,N)-dit(part2,N).*exp(-j*2*pi*k/(2*N));
res=[res1 res2];
else
res1=x(1)+x(2);
res2=x(1)-x(2);
res=[res1 res2];
end
%executedit
OPTIONN=[2 4 8 16 32 64 128 256 512 1024];
time1=[];
time2=[];
for i=1:length(OPTIONN)
N=OPTIONN(i);
x=rand(1,N);
tic
res=dif(x,N);
n=0:1:N-1;
c=dec2bin(n);
p=bin2dec([c(:,size(c,2):-1:1)]);
DIFR=res(p+1);
time1=[time1 toc];
tic
for k=0:1:length(x)-1
sum=0;
for n=0:1:length(x)-1
sum=sum+x(n+1)*exp(-j*2*pi*n*k/N);
end
RES(k+1)=sum ;
end
time2=[time2 toc];
end
figure
subplot(2,1,1)
stem(0:1:length(x)-1,abs(DIFR))
subplot(2,1,2)

1.5 Discrete Fourier Transformation (DFT) (Sampling the Frequency Domain)
23
stem(0:1:length(x)-1,abs(RES))
figure
stem(time1)
hold on
stem(time2,’r’)
function [res]=dif(x,N)
Decimation in frequency
part1=x(1:1:(N/2));
part2=x((N/2)+1:1:N);
if(N˜=2)
n=0:1:(N/2)-1;
temp1=part1+part2;
temp2=(part1-part2).*exp(-j*2*pi*n/(N))
N=N/2;
part1=dif(temp1,N);
part2=dif(temp2,N);
res=[part1 part2]
else
res(1)=part1+part2;
res(2)=part1-part2;
end
1.5.2.2
Decimation in Frequency for N-Point DFT
The DFT of the sequence x(n) is decomposed as the summation of two terms as
described below.
X(k) =
n=(N−1)

n=0
x(n)e
−j2πnk
N
(1.25)
=
n= N
2 −1

n=0
x(n)e
−j2πnk
N
+
n=(N−1)

n= N
2
x(n)e
−j2πnk
N
(1.26)
Consider the second term n=N−1
n= N
2
x(n)e
−j2πnk
N
.
Let m = n −N
2 , we get the following m= N
2 −1
m=0
x(m + N
2 )e
−j2π(m+ N
2 )k
N
. Thus X(k) is
computed as the following.
X(k) =
n= N
2 −1

n=0
x(n)e
−j2πnk
N
+ e
−j2π(N/2)k
N
m= N
2 −1

m=0
x(m + N
2 )e
−j2πmk
N
(1.27)
Replacing k = 2k′, we get the following.

24
1
Sampling and Reconstruction of Signals
X(2k′) =
n= N
2 −1

n=0
(x(n) + x(n + N
2 ))e
−j2πnk′
N/2
(1.28)
Similarly k = 2k′ + 1, we get the following.
X(2k′ + 1) =
n= N
2 −1

n=0
(x(n) −x(n + N
2 ))e
−j2πnk′
N/2 e
−j2πn
N
(1.29)
This is realized using the recursive method (refer m-ﬁle). The order in which the
DFT is obtained is in the bit reversal order, i.e., decimated in the frequency domain
and hence this method is known as Decimation in frequency. Refer Figs.1.15 and
1.16 for illustration.
%dif.m
Decimation in frequency
function [res]=dif(x,N)
part1=x(1:1:(N/2));
part2=x((N/2)+1:1:N);
if(N˜=2)
n=0:1:(N/2)-1;
temp1=part1+part2;
temp2=(part1-part2).*exp(-j*2*pi*n/(N))
N=N/2;
part1=dif(temp1,N);
part2=dif(temp2,N);
res=[part1 part2]
else
res(1)=part1+part2;
res(2)=part1-part2;
end
%executedif.m
OPTIONN=[2 4 8 16 32 64 128 256 512 1024];
time1=[];
time2=[];
for i=1:length(OPTIONN)
N=OPTIONN(i);
x=rand(1,N);
tic
res=dif(x,N);
n=0:1:N-1;
c=dec2bin(n);
p=bin2dec([c(:,size(c,2):-1:1)]);
DIFR=res(p+1);
time1=[time1 toc];
tic
for k=0:1:length(x)-1
sum=0;
for n=0:1:length(x)-1
sum=sum+x(n+1)*exp(-j*2*pi*n*k/N);
end

1.5 Discrete Fourier Transformation (DFT) (Sampling the Frequency Domain)
25
RES(k+1)=sum ;
end
time2=[time2 toc];
end
figure
subplot(2,1,1)
stem(0:1:length(x)-1,abs(DIFR))
subplot(2,1,2)
stem(0:1:length(x)-1,abs(RES))
figure
subplot(2,1,1)
stem(log2(OPTIONN),time1)
subplot(2,1,2)
stem(log2(OPTIONN),time2,’r’)
1.5.3
Sub-band Discrete Fourier Transformation
Suppose the spectrum of the given sequence occupies only the particular band
between 0 to 2π radians (corresponding to Fmax Hz). It is not efﬁcient to compute
the DFT for the complete range between 0 to 2π. Sub-band DFT paves the way to
compute the DFT in the intended region of the complete spectrum. This is illustrated
with an example as follows.
• Let the given sequence be represented as [X0 X1 X2 · · · X1023] that occupies the
spectrum ranging from 0 to π
2 . 1024 −point DFT occupies the complete range
of frequency from 0 to 2π. Sub-band DFT to compute DFT points related to the
range 0 to π
4 is computed using two-level decomposition as follows.
• g1 = [X0 X2 · · · X1022] + [X1 X3 · · · X1023]
• g2 = [X0 X2 · · · X1022] −[X1 X3 · · · X1023]
• g11 = [g0 g2 · · · g510] + [g1 g3 · · · g510]
• g12 = [g0 g2 · · · g510] −[g1 g3 · · · g510]
• g21 = [g1 g3 · · · g511] + [g1 g3 · · · g511]
• g22 = [g1 g3 · · · g511] −[g1 g3 · · · g511]
• Compute DFT of the sequence g11 to obtain G11 Similarly construct Gij, for i =
1, 2 and j = 1, 2.
• The actual DFT sequence of the given signal over the region 0 to π
2 (256-point FFT)
is computed as the following. X(k) = [1 e
−j2πk
1024 e
−j2π2∗k
1024
e
−j3π2∗k
1024 ] 1
4[1111]GT
11(K).
This is computed for k = 0 to k = 255 to obtain the 256-point DFT.
• DFT points from 256 to 512 are computed as the following. X(k) = [1 e
−j2πk
1024
e
−j2π2∗k
1024
e
−j3π2∗k
1024 ] 1
4[1 −1 1 −1]GT
21(K) for k = 0 to k = 255
• Similarly DFT points from 513 to 768 (256-points) are computed respectively as
the following. X(k) = [1 e
−j2πk
1024 e
−j2π2∗k
1024
e
−j3π2∗k
1024 ] 1
4[1 1 −1 −1]GT
12(K) for k = 0
to k = 255 and

26
1
Sampling and Reconstruction of Signals
• Similarly DFT points from 769 to 1023 (256-points) are computed respectively as
the following. X(k) = [1 e
−j2πk
1024 e
−j2π2∗k
1024
e
−j3π2∗k
1024 ] 1
4[1 −1 −11]GT
22(K) for k = 0 to
k = 255
• The vectors [1 1 1 1], [1 −1 1 −1], [1 1 −1 −1], [1 −1 −1 1] (used in the
computation) form the rows of the 4 × 4 hadamard matrix.
• Figure1.17 illustrates the magnitude response of the DFT computed using FFT,
Sub-band ﬁrst-level decomposition, Sub-band second-level decomposition. Also
Fig.1.18 demonstrates that the ﬁrst 256 samples of the 1024-point DFT computed
using 1024-point FFT and two-level sub-band DFT are identical. It is also observed
that the time required to compute ﬁrst 256 samples of the 1024-point DFT are
0.2514 and 0.0057s when the direct method and the sub-band DFT methods are
used respectively.
• Thus Sub-band DFT helps in obtaining the intended parts of the DFT sequence
without calculating all the samples (like FFT)
• This can also be generalized to obtain the higher level sub-band decomposition.
%subband.m
%Subband Discrete Fourier Transform
X=fir2(1023,linspace(0,1,1024),[2*ones(1,256) zeros(1,512) 4*ones(1,255) 0]);
[H,W]=freqz(X);
figure
plot(W,abs(H));
%First level representation
temp=reshape(X,2,512);
g1=(1/2)*(temp(1,:)+temp(2,:));
G1=fft(g1);
g2=(1/2)*(temp(1,:)-temp(2,:));
G2=fft(g2);
i=0:1:1;
TF=exp(-j*2*pi*i/1024)’;
%Construct matrix
M=[];
for k=0:1:1023
M=[M TF.ˆk];
end
M=M’;
G=[G1’ G2’]’;
G=repmat(G,1,2);
RES=M*inv(hadamard(2))*G;
figure(1)
subplot(2,1,1)
plot(abs(diag(RES)))
subplot(2,1,2)
plot(abs(fft(X)))
%second level representation
temp1=reshape(g1,2,256);
temp2=reshape(g2,2,256);
g11=(1/2)*(temp1(1,:)+temp1(2,:));
G11=fft(g11);
g12=(1/2)*(temp1(1,:)-temp1(2,:));
G12=fft(g12);
g21=(1/2)*(temp2(1,:)+temp2(2,:));

1.5 Discrete Fourier Transformation (DFT) (Sampling the Frequency Domain)
27
G21=fft(g21);
g22=(1/2)*(temp2(1,:)-temp2(2,:));
G22=fft(g22);
%Construction of DFT matrix
i=0:1:3;
TF=exp(-j*2*pi*i/1024)’;
%Construct matrix
M=[];
for k=0:1:1023
M=[M TF.ˆk];
end
M=M’;
G=[G11’ G21’ G12’ G22’]’;
G=repmat(G,1,4);
RES=M*inv(hadamard(4))*G;
figure(2)
subplot(2,1,1)
plot(abs(diag(RES)))
subplot(2,1,2)
plot(abs(fft(X)))
tic
N=1024;
for k=0:1:255
s=0;
for n=0:1:1023
s=s+X(n+1)*exp(-j*2*pi*n*k/N);
end
res1(k+1)=s;
end
time1=toc
tic
RES=M(1:1:256,:)*inv(hadamard(4))*G(:,1:1:256);
res2=diag(RES);
time2=toc
figure
subplot(2,1,1)
plot(abs(res1))
subplot(2,1,2)
plot(abs(res2),’r’)
1.6
Continous System
• Impulse response of the system: The response of the system to the impulse signal as
the input is the impulse response h(t) of the system. The impulse signal δ(t)for the
continuous case is as described below.
 ∞
−∞δ(t)dt =
 Δ
−Δ dt = 1 for every values
of Δ > ε > 0. The sifting property of the impulse is given as the following.
 ∞
−∞
f (t)δ(t −t0)dt = f (t0)
 t+
0
t−
0
δ(t −t0)dt = f (t0)
(1.30)

28
1
Sampling and Reconstruction of Signals
• Response to the eigensignal to the linear system: If the signal ej2πf0t is the input
to the linear system with impulse response h(t) (with transfer function H(f ), the
outputofthesystemisgivenasej2πf0tH(f0).Thegeneralizedinputsignalx(t)isrep-
resented using Inverse Fourier Transformation as
 ∞
−∞X(f )ej2πftdf and hence the
corresponding output signal y(t) is given as y(t) =
 ∞
−∞X(f )H(f )ej2πftdf . Hence
Y(f ) = X(f )H(f ). By taking IFT on both sides, we obtain, y(t) =
 ∞
−∞h(τ)x(t −
τ)dτ ).This is deﬁned as the convolution of x(t) with h(t)
• Linearity: Let xi(t) be the input to the system and the corresponding output of
the system is yi(t). The system is said to be linear if the output of the system is
N
i=1 aiyi(t) corresponding to N
i=1 aixi(t) as the input to the system.
• Causality: Two arbitrary inputs x1(t) and x2(t) are identical, i.e., x1(t) = x2(t) for
t ≤t0, then the corresponding outputs satisfy y1(t) = y2(t) for t ≤t0 for all x1, x2
and t0. The necessary and sufﬁcient condition for system to be causal is h(t) = 0
for t < 0.
Proof:Consider the impulse response of the system be h(t). Let x1(t) and x2(t) are
identical for t ≤t0. For t ≤t0
y1(t0) =
 t0
−∞
h(τ)x1(t −τ)dτ
⇒y1(t) =
 t0
0
h(τ)x1(t −τ)dτ
y2(t0) =
 t0
−∞
h(τ)x2(t −τ)dτ
⇒y2(t) =
 t0
0
h(τ)x1(t −τ)dτ
⇒y1(t0) = y2(t0)
Thus if h(t) = 0 for t ≤0, the system is the causal system. Consider the system
with h(−5) ̸= 0 and let x1(t) = 0 ∀t and x2(t) = δ(t −5). It is observed that the
values of x1(t) and x2(t) are identical upto t ≤0, the values for y1(0) and y2(0)
are computed as follows.
y1(0) =
 ∞
−∞
x1(−τ)h(τ)d(τ) = 0
y2(0) =
 ∞
−∞
x2(−τ)h(τ)d(τ) = x2(5)
y1(0) ̸= y2(0) and hence h(t) is causal only if h(t) = 0 for t ≤0. Hence proved.
• Stability: A signal is bounded if its magnitude is limited to a ﬁnite value at all
times. If the bounded input gives bounded output (BIBO), it is the stable system.
The system with impulse response h(t) is BIBO stable if and only

1.6 Continous System
29
 ∞
−∞
|h(τ)|dτ ≤∞
(1.31)
Proof: Using Schwartz inequality,
y(t) =
 ∞
−∞
h(τ)x(t −τ)dτ
|y(t)| ≤
 ∞
−∞
|h(τ)|dτ
 ∞
−∞
x(t −τ)|dτ
≤K
 ∞
−∞
|h(τ)|dτ
Thus if
 ∞
−∞|h(τ)|dτ ≤∞, |y(t)| ≤∞, i.e., stable system.
Suppose that h(t) is not satisfying
 ∞
−∞|h(τ)|dτ ≤∞and let for instance, there
exists some ﬁnite t0 such that
 t0
−∞|h(τ)|dτ = ∞. Consider the case the input
satisfy x(t −τ) = −1 for h(τ) ≥0 and x(t −τ) = −1 for h(τ) ≤0. This implies
the following.
y(t0) =
 t0
−∞
h(τ)x(t −τ)dτ =
 t0
−∞
|h(τ)|dτ = ∞
Thus the system is stable only if
 ∞
−∞|h(τ)|dτ ≤∞. Hence proved.
• Time in-variant system: Let y(t) is the output corresponds to the signal x(t), then
the system is said to time in-variant if y(t −t0) is the output corresponds to the
input x(t −t0)
• Memory system: If the output of the system y(t) depends on x(t + t0) and/or
y(t + t0), with t0 = 0, then the system is said to memory-less system.
• Linear phase of the system: Let the transfer function of the system is represented
as |H(f )|ejφ(f ). The magnitude response is given as |H(f )| and the phase response
is given as φ(f ), Let the output signal corresponding to the input signal x(t) =
a1ej2πf1t| + a2ej2πf2t| is obtained as a1ej2πf1t|H(f1)|ejφ(f1) + a2ej2πf2t|H(f2)|ejφ(f2)
respectively. Suppose the input signal is delayed by t0, the corresponding out-
put is given as the following.
a1ej2πf1(t−t0)|H(f1)|ejφ(f1) + a2ej2πf2(t−t0)|H(f2)|ejφ(f2)
which may be equal to y(t −t0). But suppose if we choose φ(f ) = −2πτf , where
τ is constant, we get the output as the following.
a1ej2πf1(t−t0)|H(f1)|ejφ(f1) + a2ej2πf2(t−t0)|H(f2)|ejφ(f2)
a1ej2πf1(t−t0)|H(f1)|e−j2πτf1 + a2ej2πf2(t−t0)|H(f2)|ej2πτf2
a1ej2πf1(t−t0−τ)|H(f1)| + a2ej2πf2(t−t0−τ)|H(f2)|
y(t −t0)

30
1
Sampling and Reconstruction of Signals
Thus if the phase response is linear, we get undistorted delayed version of the
output signal if the linear combinations of the delayed eigensignals are given as
the input to the linear system.
1.7
Laplace Transformation (s-Transformation)
The Laplace transformation of the right-sided signal x(t), i.e. x(t) = 0 for t < 0 is
given as
X(s) =
 ∞
0−
x(t)e−stdtX(s) =
 ∞
0−
x(t)e−σte−jωtdt
(1.32)
where s = σ + jω. The set of all values of s for which X(s) (for the particular x(t)) is
ﬁnite is the region of convergence (ROC). It helps in computing the inverse laplace
transformation. For instance consider x(t) = e−atu(t), where u(t) is the unit step
function. we compute the Laplace transformation as shown below.
X(s) =
 ∞
0
e−ate−σte−jωtdt =
 ∞
0
e−(a+σ+jω)tdt =
e−(a+σ+jω)∞
−(a + σ + jω) −
e−(a+σ+jω)0
−(a + σ + jω)
(1.33)
The value of the ﬁrst term is zero if a + σ > 0 and ∞if a + σ < 0 and not deﬁned
for a + σ = 0. Hence to make X(s) to exist, we assume a + σ > 0 and compute the
Laplace transformation as the following.
X(s) =
1
s + a
(1.34)
Thus the value of X(s) is ﬁnite if a + σ > 0. This is the ROC. (refer Fig.1.19)
The s-plane is the complex plane with each point represents the complex number
represented in the rectangular form. It is observed that if σ = 0, Laplace transfor-
mation becomes Fourier transformation. Hence if X(s) is ﬁnite for all values of ω
with σ = 0, we conclude that Fourier transformation exists. In other words, Fourier
transformation exists if the ROC includes the jω axis. Thus Fourier tansformation
can be viewed as the special case of Laplace transformation with σ = 0. The set of
all values of s for which X(s) = 0 are the zeros of the laplace transformation X(s).
Similarly, the set of all values of s for which X(s) = ∞are the poles of the X(s).
1.7.1
Properties of the ROC of the Laplace Transformation
for the Right Sided Sequence
1. ROC is of the inﬁnite length vertical rectangular strip shape in the s-plane.

1.7 Laplace Transformation (s-Transformation)
31
2. For the Right Sided Sequence (R.S.S), ROC is in the right side of the vertical
strip passes through the poles of the H(s).
3. Hence to include jw axis in the ROC, all the poles of the Laplace transformation
should lie in the left side of the jw axis. In this context, the transfer function H(s)
is said to be stable if all the poles lie in the left of the jw axis
4. ROC does not contain poles of H(s).
5. Thus to identify the causal real system (with impulse response h(t) = 0 for t < 0)
described by the Laplace transformation H(s) is stable or not, ROC should include
jw axis, This will happen if all the poles should lie in the left of the s-plane.
1.7.2
Inverse Laplace Transformation
The inverse laplace transformation is computed as x(t) =
1
2πj
 c+j∞
c−j∞X(s)estds for
t ≥0. x(t) is either ±∞, notdeﬁned or ﬁnitevalue by properly choosing the value for
c. If c = Re(s) is chosen in the ROC, x(t) is ﬁnite for t ≥0. Consider the computation
of Laplace transformation of the signal deﬁned as δ(t) + e−3t for t ≥0. The laplace
transformation is computed as follows:
X(s) =
 ∞
0−
(δ(t) + e−3t)e−stdt
1 + ( e−(s+3)t
−(s + 3))∞−( e−(s+3)t
−(s + 3))0−
1 + (e−(σ+jω+3)t
(−(s + 3)))∞−(e−(σ+jω+3)t
−(s + 3) )0−
If (σ + 3) is chosen greater than zero, then ( e−(σ+jω+3)t
−(s+3) )∞= 0 and ( e−(σ+jω+3)t
−(s−3) )∞=
1
−(s+3) Thus X(s) is computed as 1 + 0 −( −1
s+3) = 1 +
1
s+3, provided (σ + 3) > 0.
This is the region of convergence. Thus inverse laplace transformation of 1 +
1
s+3 is
given as the following.
1
2πj
 c+j∞
c−j∞
(1 +
1
s + 3)estds = δ(t) + e−3t
(1.35)
for t ≥0 provided c is chosen as greater than −3.

32
1
Sampling and Reconstruction of Signals
1.8
Geometrical Interpretation of Computation
of Magnitude Response of the Filter Using Pole-Zero
Plot of s-Transformation
The magnitude and the phase response of the given transfer function H(s) at s = jw
using geometrical measurement is computed as follows:
1. Let the zeros be represented as z1, z2 · · · zm and the poles be represented as
p1p2p3 · · · pm.
2. Compute the euclidean distance between (0, w) and the point described by z1.
Let it be dz1. This is repeated to obtain dz2, dz3, dz4, · · · dzm
3. Similarly the euclidean distance between (0, w) and the point described by p1.
Let it be dp1. This is repeated to obtain dp2, dp3, dp4, · · · dzm are computed.
4. Magnitude response of the transfer function at (0, w) is computed as πk=m
k=1 dzk
πl=n
l=1 dpl
5. Consider the line joining the point (0, w) and the point described by zero zi makes
an angle θzi with the real line of the pole-zero plot. Let it be. Similarly line joining
the point (0, w) and the point described by pole pi makes an angle θpi with the
real line of the pole-zero plot
6. Similar to magnitude response, the phase response of the transfer function at
(0, w) is computed as k=m
k=1 θzk −k=n
k=1 θpk
The geometrical method of computing the magnitude response of the transfer
function of the form H(z) = (z−a)
z
is illustrated in Fig.1.20.
1.9
Discrete System
• Impulse response of the system: The response of the system to the impulse signal
as the input is the impulse response h(n) of the system. The impulse signal δ(n)for
the discrete case is as described below.
δ(n) = 1, n = 0
δ(n) = 0, ∀n ̸= 0
• Response to the eigensignal to the linear system: If the signal ejw0n is the input
to the linear system with impulse response h(n) (with transfer function H(ejwd)),
the output of the system is given as ejw0nH(jw0). The generalized input signal
x(n) is represented using Inverse DTFT as
 2π
0
X(ejwd)ejwddwd and hence the
corresponding output signal y(n) is given as y(n) =
 2π
0
X(ejwd)H(ejwd)ej2πftdwd.
Hence Y(ejwd) = X(ejwd)H(ejwd). By taking IFT on both sides, we obtain, y(n) =
∞
k=−∞h(k)x(n −k). This is deﬁned as the convolution of the sequence x(n) and
h(n)

1.9 Discrete System
33
• Linearity: Let xi(n) be the input to the system and the corresponding output of
the system is yi(n). The system is said to be linear if the output of the system is
N
i=1 aiyi(n) corresponding to N
i=1 aixi(n) as the input to the system.
• Causality: Two arbitrary inputs x1(n) and x2(n) are identical, i.e., x1(n) = x2(n)
for t ≤n0, then the corresponding outputs satisfy y1(n) = y2(n) for n ≤n0 for all
x1, x2 and n0. The necessary and sufﬁcient condition for system to be causal is
h(n) = 0 for n < 0.
Proof: Consider the impulse response of the system be h(t). Let x1(n) and x2(n)
are identical for n ≤n0. For n ≤n0
y1(n0) =
n0

k=−∞
h(k)x1(n −k)
⇒y1(n) =
n0

k=−∞
h(k)x1(n −k)
y2(n0) =
n0

k=−∞
h(k)x2(n −k)
⇒y2(n0) =
n0

k=0
h(k)x2(n −k)
⇒y1(n0) = y2(n0)
Thus if h(k) = 0 for k ≤0, the system is the causal system. Consider the system
with h(−5) ̸= 0 and let x1(n) = 0 ∀n and x2(n) = δ(n −5). It is observed that the
values of x1(n) and x2(n) are identical upto n ≤0, the values for y1(0) and y2(0)
are computed as follows.
y1(0) =
0

k=−∞
h(k)x1(−k) = 0
y2(0) =
0

k=−∞
h(k)x2(−k) = x2(5)
y1(0) ̸= y2(0) and hence h(k) is causal only if h(k) = 0 for k ≤0. Hence proved.
• Stability: A signal is bounded if its magnitude is limited to a ﬁnite value at all
times. If the bounded input gives bounded output (BIBO), it is the stable system.
The system with impulse response h(n) is BIBO stable if and only
k=∞

k=−∞
|h(k)|d ≤∞
(1.36)

34
1
Sampling and Reconstruction of Signals
Proof: Using Schwartz inequality,
y(k) =
k=∞

k=−∞
h(k)x(n −k)
|y(k)| ≤
k=∞

k=−∞
|h(k)|
k=∞

k=−∞
|x(n −k)|
≤K
 ∞
−∞
|h(k)|
Thus if k=∞
k=−∞|h(k)|d ≤∞, |y(k)| ≤∞, i.e., stable system.
Suppose that h(k) is not satisfying k=∞
k=−∞|h(k)|d ≤∞and let for instance, there
exists some ﬁnite n0 such that n0
k=−∞|h(k)| = ∞. Consider the case the input sat-
isfy x(n −n0) = −1 for h(n) ≥0 and x(n −n0) = −1 for h(n) ≤0. This implies
the following.
y(n0) =
k=n0

k=−∞
h(k)x(n −k) =
k=n0

k=−∞
|h(k)| = ∞
Thus the system is stable only if ∞
−∞|h(k)| ≤∞. Hence proved.
• Time in-variant system: Let y(n) is the output corresponds to the signal x(n), then
the system is said to time in-variant if y(n −n0) is the output corresponds to the
input x(n −n0)
• Memory system: If the output of the system y(n) depends on x(n + n0) and/or
y(n + n0), with n0 = 0, then the system is said to memory-less system.
• Linear phase of the system: Let the transfer function of the system is repre-
sented as |H(ejwd)|ejφ(wd). The magnitude response is given as |H(ejwd)| and the
phase response is given as φ(wd), Let the output signal corresponding to the
input signal x(n) = a1ejwd1n + a2ejwd2n is obtained as a1ejwd1n|H(ejwd1 )|ejφ(wd1) +
a2ejwd2n|H(ejwd2 )|ejφ(wd2) respectively. Suppose the input signal is delayed by n0,the
corresponding output is given as the following.
a1ejwd1(n−n0)|H(ejwd1 )|ejφ(wd1) + a2ejwd2(n−n0)|H(ejwd2 )|ejφ(wd2)
which may not be equal to y(n −n0). But suppose if we choose φ(wd) = −τwd,
where τ is the integer constant, we get the output as the following.
a1ejwd1(n−n0)|H(ejwd1 )|ejφ(wd1) + a2ejwd2(n−n0)|H(ejwd2 )|ejφ(wd2)
= a1ejwd1(n−n0−τ)|H(ejwd1 )| + a2ej2πf2(n−n0−τ)|H(ejwd2 )|
= y(n −n0)

1.9 Discrete System
35
Thus if the phase response is linear, we get undistorted delayed version of the
output signal if the linear combinations of the delayed eigensignals are given as
the input to the linear system.
1.10
Z-Transformation
The z-transformation of the right-sided sequence is given as the following.
X(z) =
k=∞

k=0
x(k)z−k
(1.37)
where z = reiwd. The z-plane is the complex plane with each point represents the
complex number represented in the polar form. The set of all values of z for which
X(z) (Computed for the particular sequence) is ﬁnite is the region of convergence
(ROC). Let us consider computing the z-transformation for anu(n), where u(n) is the
unit step function as shown below.
X(z) =
k=∞

k=0
akz−k = 1 + (az−1) + (az−1)2 + · · ·
(1.38)
The above equation converges if |az−1| < 1 and the corresponding z-transformation
is given as (1 −az−1)−1 =
z
z−a. The region |z| > |a| is known as region of conver-
gence (ROC) (refer Fig.1.19). It is observed that if r = 1, z-transformation becomes
Discrete Time Fourier transformation. Hence if X(z) is ﬁnite for all values of wd
with r = 1, we conclude that Discrete Fourier transformation exists. In other words,
Discrete Time Fourier transformation exists if the ROC includes the r = 1 circle.
Thus Discrete Time Fourier tansformation can be viewed as the special case of z-
transformation with r = 1. The set of all values of z for which X(z) = 0 are the zeros
of the z-transformation X(z). Similarly, the set of all values of z for which X(z) = ∞
are the poles of the X(z).
1.10.1
Properties of the ROC of the Z-Transformation
for the Right-Sided Sequence
1. ROC is of the circular strip shape in the z-plane.
2. For the Right Sided Sequence (R.S.S), ROC is in the outside the circle passes
through the poles of the z-plane.

36
1
Sampling and Reconstruction of Signals
3. Hence to include r = 1 circle in the ROC, all the poles of the z-transformation
should lie inside the unit circle. In this context, the transfer function H(z) is said
to be stable if all the poles lie inside the unit circle.
4. ROC does not contain the poles of H(z).
5. Thus to identify the causal real system (with impulse response h(n) = 0 for n < 0)
described by the z-transformation H(z) is stable or not, ROC should include jw
axis, this will happen if all the poles should lie in the left of the z-plane.
1.10.2
Inverse Z-Transformation
The inverse z-transformation of the X(z) is obtained as the contour integration as
given below.
1
2πj

X(z)zk−1dz
(1.39)
for k ≥0. With the contour selected as the circle with 0 as the origin and lies in the
region of convergence. Consider the z-transformation of the sequence x(n) = 0.5n
for n ≥0. The z-transformation is obtained as the following.
X(z) =
k=∞

k=0
x(k)z−k
=
k=∞

k=0
0.5kz−k
=
k=∞

k=0
(0.5z−1)k
= 1 + 0.5z−1 + (0.5z−1)2 + · · ·
If |0.5z−1| < 1,i.e., |z| = |rejwd| = |r| > 0.5 we get the following. 1 + 0.5z−1 +
(0.5z−1)2 + · · · = (1 −0.5z−1)−1 =
z
z−0.5. Thus the inverse z-transformation of
z
z−0.5 is computed as the following.
1
2πj

z
z −0.5zk−1dz = 0.5n
(1.40)
for n ≥0, provided the contour is chosen as the circle with the radius greater than
0.5.

1.11 Response of the Digital Filter with the Typical Transfer Function…
37
1.11
Response of the Digital Filter with the Typical
Transfer Function (Obtained Using DTFT)
to the Periodic Sequence
Let the magnitude response of the digital ﬁlter be represented as H(ejwd). The
response of the ﬁlter to the periodic sequence x(n) is obtained as follows.
x(n) = 1
N
k=N−1

k=0
X(k)e
j2πnk
N
(1.41)
The response to the eigensignal e
j2πnk
N
is obtained as e
j2πnk
N
H(e
j2πk
N ). As the system is
linear, the response to the periodic sequence x(n) is obtained as the following.
y(n) = 1
N
k=N−1

k=0
X(k)e
j2πnk
N H(e
j2πk
N )
(1.42)
This is demonstrated using the ﬁlter coefﬁcients h (refer Fig.1.22b) and the cor-
responding transfer function is given in the Fig.1.21. The response of the system
described by the impulse response h to the input periodic signal x (Fig.1.22a) is
obtainedastheconvolutionofperiodicsequencex andtheﬁlercoefﬁcientsh asshown
in Fig.1.22c. Let X(k) be the DFT sequence corresponding to the input sequence
x(n). Then the nth value of the output sequence y is also obtained by computing the
linear combinations of the samples given in the Fig.1.21 (H(e
j2πk
N )) and the sequence
X(k)e
j2πnk
N
(computed for the typical value of n) as shown in Fig.1.22d. It is observed
that the output obtained in the Fig.1.22 c, d are identical.
Fig. 1.21 Magnitude response of the system used for the demonstration. The samples used to obtain
the response of the periodic sequence are indicated in red color

38
1
Sampling and Reconstruction of Signals
Fig. 1.22 a Periodic input sequence. b Impulse response of the ﬁlter. c Output sequence computed
using convolution. d Output sequence computed using linear combinations of samples mentioned
in the Fig.1.21
Fig. 1.23 Illustration of the Geometrical method of computing magnitude and phase response of
the discrete system transfer function H(z)

1.11 Response of the Digital Filter with the Typical Transfer Function…
39
Fig. 1.24 Illustration of the Geometrical method of computing magnitude and phase response of
the discrete system transfer function H(z) (contd.)
%responsetoperiodicsequence.m
%Response to the periodic sequence
h=fir1(11,0.3);
t=0:1:511;
POINTS=512;
N=8;
[H,W]=freqz(h,1,2*pi*t/POINTS);
input=1:1:8;
y=fft(input);
output1=[];
for n=1:1:32
temp=0;
for i=0:1:7
temp=temp+ y(i+1)*exp(j*2*pi*n*i/N)*HRES(2*pi*i/N,h);
end
output1=[output1 temp/(N)];
end
%Considering four period
I=[input input input input]
output2=conv(h,I)
figure
subplot(4,1,1)
stem(I)
subplot(4,1,2)
stem(h)
subplot(4,1,3)
stem(real(output1))
subplot(4,1,4)

40
1
Sampling and Reconstruction of Signals
stem(output2,’r’)
k=1;
temp1=[];
temp2=[];
for i=0:1:7
temp1=[temp1 2*pi*i/N];
temp2=[temp2 HRES(2*pi*i/N,h)];
end
SAMPLE=temp1;
VALUE=temp2;
figure
plot(W,abs(H));
hold on
stem(SAMPLE,abs(VALUE),’r’)
function [res]=HRES(w,h)
n=0:1:length(h)-1;
res=sum(h.*exp(-j*w*n));
1.12
Geometrical Interpretation of Computation
of Magnitude Response of the Filter Using Pole-Zero
Plot of z-Transformation
The magnitude and the phase response of the given transfer function H(z) at z = ejw
using geometrical measurement is computed as follows:
1. Let the zeros be represented as z1, z2 · · · zm and the poles be represented as
p1p2p3 · · · pm. If the system is all zero system, pole at orgin is considered. Simi-
larly if the system is all pole system, zero at orgin is considered
2. Compute the euclidean distance between (cos(w), sin(w)) and the point described
by z1. Let it be dz1. This is repeated to obtain dz2, dz3, dz4, · · · dzm
3. Similarly the euclidean distance between (cos(w), sin(w)) and the point described
by p1. Let it be dp1. This is repeated to obtain dp2, dp3, dp4, · · · dzm are computed.
4. Magnitude response of the transfer function at (cos(w), sin(w)) is computed as
πk=m
k=1 dzk
πl=n
l=1 dpl
5. Consider the line joining the point (cos(w), sin(w)) and the point described by
zero zi makes an angle θzi with the real line of the pole-zero plot. Let it be.
Similarly line joining the point (cos(w), sin(w)) and the point described by pole
pi makes an angle θpi with the real line of the pole-zero plot
6. Similar to magnitude response, the phase response of the transfer function at
(cos(w), sin(w)) is computed as k=m
k=1 θzk −k=n
k=1 θpk
The geometrical method of computing the magnitude response and phase response
of the transfer function of the form H(z) = (z−a)
z
is illustrated in Figs.1.23, 1.24 and
1.25.

1.12 Geometrical Interpretation of Computation of Magnitude …
41
Fig. 1.25 Column 1 indicate the actual magnitude response of continuous curve in the typical ﬁlter.
Column 2 indicate the cos of the phase response of the ﬁlter. Column 3 indicate the sine of the phase
response of the ﬁlter. The stem in all the subplots indicate the corresponding values computed using
the Geometrical method
%complexplanegeometry.m
%Demonstration of the geometrical method of computing magnitude
and phase response
z1=1.4+ 2.5*j;
z2=1/z1’;
[mag1,mag2,phase1,phase2]=magrespzplot1(z1,z2);
[H1,W1]=freqz([1 -z1],1);
[H2,W2]=freqz(1,[1 -z2]);
w=linspace(0,pi,6);
figure
subplot(3,3,1)
plot(W1, abs(H1))
hold on
stem(w,mag1,’r’)
subplot(3,3,2)
plot(W2, abs(H2))
hold on
stem(w,mag2,’r’)
subplot(3,3,3)
plot(W1, cos(angle(H1)))
hold on
stem(w,cos(phase1),’r’)
subplot(3,3,4)
plot(W2, cos(angle(H2)))
hold on
stem(w,cos(phase2),’r’)

42
1
Sampling and Reconstruction of Signals
subplot(3,3,5)
plot(W1, sin(angle(H1)))
hold on
stem(w,sin((phase1)),’r’)
subplot(3,3,6)
plot(W2, sin(angle(H2)))
hold on
stem(w,sin(phase2),’r’)
subplot(3,3,7)
plot(W1, abs(H1).*abs(H2))
hold on
stem(w,mag1.*mag2,’r’)
subplot(3,3,8)
plot(W2, cos(angle(H1)-angle(H2)))
hold on
stem(w,cos(phase1-phase2),’r’)
subplot(3,3,9)
plot(W2, sin(angle(H1)-angle(H2)))
hold on
stem(w,sin(phase1-phase2),’r’)
function [MAG1,MAG2,PHASE1,PHASE2]=magrespzplot(z,p)
%The zero at orgin is considered when the phase response is
%computed for pole at p
%The pole at orgin is considered when the phase response is
%computed for zero at z
MAG1=[];
MAG2=[];
PHASE1=[];
PHASE2=[]
f=1;
for w=linspace(0,pi,6)
figure(1)
subplot(2,6,f)
zplane(z,p)
hold on
subplot(2,6,f+6)
zplane(z,p)
hold on
w1=exp(j*w);
figure(1)
subplot(2,6,f)
[real(z) imag(z)];
plot([real(w1) real(z)],[imag(w1) imag(z)],’b-’);
hold on
figure(1)
subplot(2,6,f+6)
[real(w1),imag(w1)];
[real(p) imag(p)];
plot([real(w1),real(p)],[imag(w1) imag(p)],’r-’);
hold on
MAG1=[MAG1 sqrt(abs((w1-z).ˆ2))];
MAG2=[MAG2 1./sqrt(abs((w1-p).ˆ2))];
PHASE1=[PHASE1 angle(w1-z)-angle(w1)];
PHASE2=[PHASE2 angle(w1)-angle(w1-p)];
f=f+1;
end

Chapter 2
Inﬁnite Impulse Response (IIR) Filter
2.1
Impulse-Invariant Mapping
The generalized transfer function of the system can be represented in Laplace trans-
formation as given below:
Ha(s) =
k=N

k=1
Ak
(S −pk).
(2.1)
The corresponding impulse response of the causal system is obtained as
ha(t) =
k=N

k=1
Ake−jwtu(t),
(2.2)
where u(t) is the unit step function. Sampling the impulse response ha(t) = h(t),
we get the discrete version of the system as given below:
ha(nTs) = h(n) =
k=N

k=1
Ake−jwnTs,
(2.3)
for n = 0 1 . . .. Taking z-transformation of the sequence h(n), we get the following
(Fig. 2.1):
H(z) =
n=∞

n=0
h(n)z−n
=
n=∞

n=0
k=N

k=1
Ake−jwnTs
© Springer International Publishing AG 2018
E.S. Gopi, Multi-Disciplinary Digital Signal Processing,
DOI 10.1007/978-3-319-57430-1_2
43

44
2
Inﬁnite Impulse Response (IIR) ﬁlter
Fig. 2.1 Illustration on the
computation of the area
under the curve using
Trapezoidal rule
=
k=N

k=1
Ak
n=∞

n=0
e−jwnTsz−n
=
k=N

k=1
Ak
n=∞

n=0
(e−jwTsz−1)n
=
k=N

k=1
Ak(1 −e−jwTsz−1)−1
=
k=N

k=1
Ak
1 −e−jwTsz−1 .
By substituting
Ak
(S−pk) with
Ak
1−e−jwTs z−1 , we convert the continuous domain to discrete
domain, i.e., we obtain the discrete sequence h(n) from the continuous impulse
response h(t). This the impulse-invariant method of mapping S to Z domain.
2.2
Bilinear Transformation Mapping
The sampling frequency Fs = 1
Ts used in (2.3) needs to be ﬁxed as greater than twice
the maximum frequency content of h(t) (Sampling theorem), which is not usually
known. Suppose if Fs is chosen not satisfying the sampling theorem associated
with the impulse response, overlapping in the spectrum occurs. In particular, if the
spectrum of h(t) is high-pass nature, it suffers a lot. This is circumvented using the
technique known as bilinear transformation as described below. The area under the
curve of the impulse response xa(t) = dh(t)
dt
for (n −1)Ts ≤t ≤nTs is computed
(refer Fig. 2.1) as

2.2 Bilinear Transformation Mapping
45
 nTs
(n−t)Ts
dh(t)
dt
dt = (h((n −1)Ts) −h(nTs)).
(2.4)
This is computed using the trapezoidal approximation (refer Fig. 2.1) as follows:
Ts
2 (xnTs + x(n−1)Ts).
(2.5)
Taking Laplace transformation on both sides of x(t) = dh(t)
dt , we get X(s) = sH(s).
Taking z-transformation of (2.4) and (2.5), we get the following: H(z)(1 −z−1) =
Ts
2 X(z)(1 + z−1). Thus equating the ratio X(s)
H(s) with X(z)
H(z), we get the following:
s = 2
Ts
1 −z−1
1 + z−1 .
(2.6)
Substituting s = jw and z = e jwd in (2.6), we get w = 2
Ts tan(wd/2), where w is the
analog frequency and wd is the digital frequency. This method of mapping s-domain
to z-domain is called Bilinear transformation. Even when w tends to ∞, wd tends to
the value π. As π corresponds to the maximum frequency content of the signal after
sampling, maximum frequency of the content of the signal is bounded to ∞. This
is equivalent to obtaining the scaled down version of the spectrum of h(t) such that
maximum frequency is bounded to Fs
2 , irrespective of actual value of the Fs. Thus
overlapping of spectrum never occur. Hence, this is suitable for high-pass ﬁltering.
But the drawback is the shrinkage of the spectrum.
2.2.1
Frequency Pre-warping
The relationship between the digital frequency wd and the analog frequency w
(rad/sec) is linear (wd = wTs) in the case of impulse-invariant mapping. But if Ts is
not properly chosen to obtain the discrete version of the analog ﬁlter, overlapping
occurs. This is circumvented using Bilinear transformation given as w =
2
T s tan( wd
2 ).
This guarantees that even when the maximum analog frequency content of the
impulse response is ∞, the corresponding digital frequency is bounded to π. But the
relationship is nonlinear (refer Fig 2.2). Suppose if would like to design the low-pass
ﬁlter with cutoff frequency wc in rad/sec (equivalently wc
Fs in digital domain), we get
the digital ﬁlter with cutoff frequency 2 wTs
2 tan−1(w). This is undesired property of
Bilinear transformation. This is circumvented as follows.
• Suppose we need the low-pass ﬁlter with cutoff frequency wc in rad/sec (equiv-
alently wc
Fs in digital domain), we obtain the pre-warped frequency pwc =
2
Ts tan
( wcTs
2 ). The plot between wc and pwc is given in the bandpass ﬁlter as shown in
Fig. 2.3.

46
2
Inﬁnite Impulse Response (IIR) ﬁlter
Fig. 2.2 Relationship between digital and analog frequency using bilinear transformation
Fig. 2.3 Relationship between the actual analog frequency and the prewarped analog frequency
(refer (2.2.1))
• Design the analog ﬁlter with the prewarped frequency pwc in rad/sec.
• If the mapping is done from s to z using bilinear transformation for the designed
analog ﬁlter, we get the digital ﬁlter with the desired cutoff frequency wc
Fs .
• This is known as frequency pre-warping.

2.2 Bilinear Transformation Mapping
47
2.2.2
Design of Digital IIR Filter using Butterworth Analog
Filter and Impulse-Invariant Transformation
• The generalized transfer function of the IIR analog low-pass ﬁlter is computed as
follows:
Ha(s) = π
k= N
2
k=1
Bkw2
c
S2 + bkwcs + ckw2c
(2.7)
for N as even.
Ha(s) = π
k= N−1
2
k=1
Bkw2
c
S2 + bkwcs + ckw2c
B0wc
s + c0wc
(2.8)
for N as odd.
• The magnitude response of the Butterworth ﬁlter is given as follows:
|H( jw)| =
A
[1 + ( w
wc )2N]
1
2 .
(2.9)
Refer Fig.2.4 for the typical magnitude response plot for various orders of the
Butterworth ﬁlter with wc = 1 rad/sec and A = 1.
• GiventhemagnituderesponseoftheButterworthﬁlteratw = 0 (say A),magnitude
of the transfer function is lesser than m at the stop band frequency (ws in rad/sec),
and the order of the ﬁlter N is computed as follows: N =
A2
m2 −1
2log( ws
wc ), where wc is the
cutoff of the Butterworth ﬁlter whose magnitude response is
A
√
2 at wc.
• For the typical value of N as even, the values for bk are computed as bk =
sin( (2k−1)π
2N
), ck = 1, Bk = A
2
N for k = 1 · · ·
N
2 .
• For the typical value of N as odd, the values for bk are computed as bk =
sin( (2k−1)π
2N
), ck = 1, Bk = A
2
N for k = 1 · · ·
N−1
2
and B0 = 1 and c0 = 1.
• Mapping from the s-domain to z-domain (H(S) to H(z)) is obtained by sub-
stituting the term of the form
Ak
(S−pk) of Ha(s) with
Ak
1−e−jwTs z−1 . This is done by
representing
Bkw2
c
S2+bkwcs+ckw2c as the summation of two partial fractions for every k.
• Thus the digital Butterworth impulse-invariant ﬁlter H(z) is obtained.
2.2.3
Design of Digital IIR Filter using Butterworth Analog
Filter and Bilinear Transformation
• The magnitude response of the Butterworth ﬁlter is given as follows (2.9):

48
2
Inﬁnite Impulse Response (IIR) ﬁlter
Fig. 2.4 Magnitude response plot for various orders of the Butterworth ﬁlter with wc = 1 rad/sec
and A = 1
• GiventhemagnituderesponseoftheButterworthﬁlteratw = 0 (say A),magnitude
of the transfer function is lesser than m at the stop band frequency (ws in rad/sec),
cutoff frequency (wc in rad/sec), and sampling frequency Fs, and the order of the
ﬁlter N is computed as follows.
• Obtain the prewarped frequency corresponding to ws and wc as pws and pwc as
follows:
wcd = wc
Fs ; wsd = ws
Fs ;
pwc = 2
T s tan(wcd
2 ); pws = 2
T s tan(wsd
2 );
• The order of the ﬁlter N is computed as N =
A2
m2 −1
2log( pws
pwc ).
• For the typical value of N as even, the values for bk are computed as bk =
sin( (2k−1)π
2N
), ck = 1, Bk = A
2
N for k = 1 · · ·
N
2 .
• For the typical value of N as odd, the values for bk are computed as bk =
sin( (2k−1)π
2N
), ck = 1, Bk = A
2
N for k = 1 · · ·
N−1
2
and B0 = 1 and c0 = 1. Thus
the analog ﬁlter Ha(s) is obtained (refer (1.7) and (1.8)).
• Mapping from the s-domain to z-domain (H(S) to H(z)) is obtained by substitut-
ing s =
2
T s
1−z−1
1+z−1 .
• Thus the bilinear transformation-based Butterworth ﬁlter H(z) is obtained.

2.2 Bilinear Transformation Mapping
49
2.2.4
Design of Digital IIR Filter Using Chebyshev Analog
Filter and Impulse-Invariant Transformation
• Butterworth ﬁlter has the smooth magnitude response, but the cutoff is not usually
very sharp. This is circumvented using the chebyﬁlter analog ﬁlter.
• The magnitude response of the Chebyshev ﬁlter is given as follows:
|H( jw)| =
A
[1 + ε2CN( w
wc )]
1
2 ,
(2.10)
where CN(x) = cos(Ncos−1x) for x ≤1 and CN(x) = cosh(Ncosh−1x) for
x > 1 (refer Fig. 2.5 for the typical magnitude response plot for various orders
(red color for N odd and blue color for N as even) is of the Chebyshev ﬁlter with
wc = 2 rad/sec, A = 1 and ε = 0.2. Also, Fig. 2.6 shows the case when ε = 2.
• Given the ripple width R, maximum amplitude of the transfer function A, pass
band cutoff frequency wp = wc (magnitude at wc is given as
A
√
1+ε2)), where (A −
A
√
1+ε2 ) is the ripple width R and the magnitude of the transfer function at the
stop band frequency (ws in rad/sec) is lesser than m, the order of the ﬁlter N is
computed as follows:
ε =

R
A −R ;r = ws
wp
; C =

1 −m2
m2ε2 ; N = acosh(C)
acosh(r) .
• For the typical value of N, the values for bk are computed as bk = 2YNsin( (2k−1)π
2N
),
ck = (YN)2 + cos2( (2k−1)π
2N
), where YN = 1
2([ 1
ε
2 + 1
ε]
1
N + [ 1
ε
2 −1
ε]
−1
N ) and Bk is
chosen by choosing the required amplitude (either A for N = odd or
A
(1+ε2)
1
2 for
N = even at w = 0).
• Mapping from the s-domain to z-domain (H(S) to H(z)) is obtained by sub-
stituting the term of the form
Ak
(S−pk) of Ha(s) with
Ak
1−e−jwTs z−1 . This is done by
representing
Bkw2
c
S2+bkwcs+ckw2c as the summation of two partial fractions for every k.
• Thus the digital Butterworth impulse-invariant ﬁlter H(z) is obtained.
2.2.5
Design of Digital IIR Filter Using Chebyshev Analog
Filter and Bilinear Transformation
• Butterworth ﬁlter has the smooth magnitude response, but the cutoff is not usually
very sharp. This is circumvented using the chebyshev analog ﬁlter.
• The magnitude response of the Chebyshev ﬁlter is given as (2.10).

50
2
Inﬁnite Impulse Response (IIR) ﬁlter
Fig. 2.5 Magnitude response plot for various orders (red color for N odd and blue color for N as
even) is of the Chebyshev ﬁlter with wc = wp = 2 rad/sec (refer Sects. 2.2.4 and 2.2.5), A = 1 and
ε = 0.2
Fig. 2.6 Magnitude response plot for various orders (red color for N odd and blue color for N as
even) is of the Chebyshev ﬁlter with wc = wp = 2 rad/sec, A = 1 and ε = 2

2.2 Bilinear Transformation Mapping
51
• Given the ripple width R, maximum amplitude of the transfer function A, pass band
cutoff frequency wp = wc (magnitude at wc is given as
A
√
1+ε2), where (A −
A
√
1+ε2 )
is the ripple width R and the magnitude of the transfer function at the stop band
frequency (ws in rad/sec) is lesser than m), the order of the ﬁlter N is computed
as follows.
• Obtain the prewarped frequency corresponding to ws and wc as pws and pwc as
follows:
wcd = wc
Fs ; wsd = ws
Fs ;
pwc = 2
T s tan(wcd
2 ); pws = 2
T s tan(wsd
2 );
ε =

R
A −R ;r = pws
pwp ; C =

1 −m2
m2ε2 ; N = acosh(C)
acosh(r) .
• For the typical value of N, the values for bk are computed as bk = 2YNsin( (2k−1)π
2N
),
ck = (YN)2 + cos2( (2k−1)π
2N
), where YN = 1
2([ 1
ε
2 + 1
ε]
1
N + [ 1
ε
2 −1
ε]
−1
N ) and Bk is
chosen by choosing the required amplitude (either A for N = odd or
A
(1+ε2)
1
2 ) for
N = even at w = 0).
• Mappingfromthes-domainto z-domain(H(S)to H(z))isobtainedbysubstituting
s =
2
Ts
1−z−1
1+z−1 .
• Thus the bilinear transformation-based Chebyshev ﬁlter H(z) is obtained.
%plotbuttermag.m
%Magnitude response of the Butterworth filter
function [res]=plotbuttermag(A,fc)
figure
for N=3:1:11
f=0:0.1:5;
M=A./(1+(f/fc).ˆ(2*N)).ˆ(1/2);
plot(f,M)
hold on
end
%plotchebymag.m
function [res]=plotchebymag(A,fc,epsilon)
figure
subplot(2,1,1)
%Magnitude response of the Chebyshev filter
for N=3:2:11
M=[];
for f=0:0.01:5;
M=[M A./(1+(epsilonˆ2)*CN(f/fc,N)ˆ2)ˆ(1/2)];
end
plot(0:0.01:5,M)
hold on
end

52
2
Inﬁnite Impulse Response (IIR) ﬁlter
for N=2:2:11
M=[];
for f=0:0.01:5;
M=[M A./(1+(epsilonˆ2)*CN(f/fc,N)ˆ2)ˆ(1/2)];
end
plot(0:0.01:5,M,’r’)
hold on
end
subplot(2,1,2)
for N=3:2:11
M=[];
for f=0:0.01:2;
M=[M A./(1+(epsilonˆ2)*CN(f/fc,N)ˆ2)ˆ(1/2)];
end
plot(0:0.01:2,M)
hold on
end
for N=2:2:11
M=[];
for f=0:0.01:2;
M=[M A./(1+(epsilonˆ2)*CN(f/fc,N)ˆ2)ˆ(1/2)];
end
plot(0:0.01:2,M,’r’)
hold on
end
%CN.m
function [res]=CN(f,N)
switch f<1
case 0
res=cos(N*acos(f));
case 1
res=cosh(N*acosh(f));
end
%butterworthorder.m
function [N]=butterworthorder(A,wc,ws,m)
%Let the maximum frequency content is set as 10000 Hz
%A is the magnitude at w=0
%wc is the cut-off frequency at which
%the magnitude is A/sqrt(2)in rad/sec
%ws is the stop band cutoff frequency
%(in rad/sec) at which the magnitude expected is lesser than m
N=log(((Aˆ2)/(mˆ2))-1)/(2*log(ws/wc));
N=ceil(N);
fc=wc/(2*pi);
f=0:1:10000;
M=A./(1+(f/fc).ˆ(2*N)).ˆ(1/2);
figure
plot(f,M)
%digitalbutterworth.m
function [NUM,DEN,H]=digitalbutterworth(A,wc,ws,m,Fs,option)
%option 1: Impulse-invariant technique
%option 2: Bilinear transformation technique

2.2 Bilinear Transformation Mapping
53
switch option
case 1
[N]=butterworthorder(A,wc,ws,m);
N
Ts=1/Fs;
order=mod(N,2);
if(order==0)
N1=N;
else
N1=N-1;
end
b=0;
for k=1:1:(N1/2)
b(k)=2*sin((2*k-1)*pi/(2*N))
end
Ck=1;
Bk=(A)ˆ(2/N);
B0=1;
c0=1;
%Converting s domain to z-domain
if(N˜=1)
for k=1:1:length(b)
[NU,DE]=impulses2z(Bk,Ck,b(k),wc,Fs)
res1{k}=NU;
res2{k}=DE;
end
H=1;
NUM1=res1;
DEN1=res2;
for k=1:1:(N1/2)
[H1,W]=freqz(NUM1{k},DEN1{k});
H=H.*H1;
end
end
if(N==1)
H=1;
end
if(order==1)
[H2,W]=freqz([B0*wc],[1 -exp(-c0*wc*Ts)])
H=H.*H2;
end
H=abs(H)/max(abs(H))*A;
figure
plot((W*Fs)/(2*pi),H)
if(N==1)
NUM{1}=[B0*wc];
DEN{1}=[1 -exp(-c0*wc*Ts)];
else
NUM=NUM2;
DEN=DEN2;
end

54
2
Inﬁnite Impulse Response (IIR) ﬁlter
case 2
%Frequency prewarping
%Needs to design the digital filter with cutoff frequency
wcd=(wc/Fs);
wsd=(ws/Fs);
Ts=1/Fs;
pwc=(2/Ts)*tan(wcd/2);
pws=(2/Ts)*tan(wsd/2);
[N]=butterworthorder(A,pwc,pws,m);
N
order=mod(N,2);
if(order==0)
N1=N;
else
N1=N-1;
end
b=0;
for k=1:1:(N1/2)
b(k)=2*sin((2*k-1)*pi/(2*N));
end
Ck=1;
Bk=(A)ˆ(2/N);
B0=1;
c0=1;
if(N˜=1)
for k=1:1:length(b)
[NU,DE]=bilinears2z(Bk,Ck,b(k),pwc,Fs);
res1{k}=NU;
res2{k}=DE;
end
NUM2=res1;
DEN2=res2;
H=1;
for k=1:1:(N1/2)
[H1,W]=freqz(NUM2{k},DEN2{k});
H=H.*H1;
end
else
H=1;
end
if(order==1)
[H2,W]=freqz([B0*pwc*Ts B0*pwc*Ts],[(2+c0*pwc*Ts) -2+c0*pwc*Ts]);
H=H.*H2;
end
H=abs(H)/max(abs(H))*A;
figure
plot((W*Fs)/(2*pi),H)
if(N==1)
NUM{1}=[B0*pwc*Ts B0*pwc*Ts];
DEN{1}=[(2+c0*pwc*Ts) -2+c0*pwc*Ts];
else
NUM=NUM2;
DEN=DEN2;
end
end

2.2 Bilinear Transformation Mapping
55
%impulses2z.m
function [NUM,DEN]=impulses2z(Bk,Ck,bk,wc,Fs)
Ts=1/Fs;
vector=[1 bk*wc Ck*(wcˆ2)];
[p]=roots(vector);
NUM=[0 (exp(p(1)*Ts)-exp(p(2)*Ts))];
NUM=NUM*Bk*(wcˆ2)/(p(1)-p(2));
DEN=conv([1 -1*exp(p(1)*Ts)],[1 -1*exp(p(2)*Ts)]);
%bilinears2z.m
function [NUM,DEN]=bilinears2z(Bk,Ck,bk,wc,Fs)
Ts=1/Fs;
NUM=[Bk*(wcˆ2)*(Tsˆ2) 2*Bk*(wcˆ2)*(Tsˆ2) Bk*(wcˆ2)*(Tsˆ2)];
DEN=[4-2*bk*wc*Ts+Ck*(wcˆ2)*(Tsˆ2) ...
-8+2*Ck*(wcˆ2)*(Tsˆ2) 4+2*bk*wc*Ts+Ck*(wcˆ2)*(Tsˆ2)];
%digitalchebyshev.m
function [NUM,DEN,H]=digitalchebyshev(A,R,wp,ws,m,Fs,option)
%option 1: Impulse invariant technique
%option 2: Bilinear transformation technique
switch option
case 1
[N]=chebyshevorder(A,R,wp,m,ws)
N
Ts=1/Fs;
order=mod(N,2);
if(order==0)
N1=N;
else
N1=N-1;
end
epsilon=sqrt(R/(A-R));
t=(((1/epsilonˆ2)+1)ˆ(1/2)+(1/epsilon));
Y= (1/2)*(tˆ(1/N)-tˆ(-1/N));
b=0;
for k=1:1:(N1/2)
b(k)=2*Y*sin((2*k-1)*pi/(2*N));
C(k)=Yˆ2+(cos((2*k-1)*pi/(2*N)))ˆ(2);
end
Bk=(A)ˆ(2/N);
B0=Bk;
C0=Y;
wc=wp;
%Converting s domain to z domain
if(N˜=1)
for k=1:1:length(b)
[NU,DE]=impulses2z(Bk,C(k),b(k),wc,Fs)
res1{k}=NU;
res2{k}=DE;
end
H=1;
NUM1=res1;
DEN1=res2;
for k=1:1:(N1/2)
[H1,W]=freqz(NUM1{k},DEN1{k});
H=H.*H1;

56
2
Inﬁnite Impulse Response (IIR) ﬁlter
end
else
H=1;
end
if(order==1)
[H2,W]=freqz([B0*wc],[1 -exp(-C0*wc*Ts)]);
H=H.*H2;
end
H=abs(H)/max(abs(H))*A;
figure
plot((W*Fs)/(2*pi),H)
if(N==1)
NUM{1}=[B0*wc];
DEN{1}=[1 -exp(-C0*wc*Ts)];
else
NUM=NUM1;
DEN=DEN1;
end
case 2
%Frequency prewarping
%Needs to design the digital filter with cutoff frequency
wpd=(wp/Fs);
wsd=(ws/Fs);
Ts=1/Fs;
pwp=(2/Ts)*tan(wpd/2);
pws=(2/Ts)*tan(wsd/2);
[N]=chebyshevorder(A,R,pwp,m,pws)
N
order=mod(N,2);
if(order==0)
N1=N;
else
N1=N-1;
end
epsilon=sqrt(R/(A-R));
t=(((1/epsilonˆ2)+1)ˆ(1/2)+(1/epsilon));
Y= (1/2)*(tˆ(1/N)-tˆ(-1/N));
b=0;
for k=1:1:(N1/2)
b(k)=2*Y*sin((2*k-1)*pi/(2*N));
C(k)=Yˆ2+(cos((2*k-1)*pi/(2*N)))ˆ(2);
end
Bk=(A)ˆ(2/N);
B0=Bk;
C0=Y;
pwc=pwp;
if(N˜=1)
for k=1:1:length(b)
[NU,DE]=bilinears2z(Bk,C(k),b(k),pwc,Fs);
res1{k}=NU;
res2{k}=DE;
end
NUM2=res1;

2.2 Bilinear Transformation Mapping
57
DEN2=res2;
H=1;
for k=1:1:(N1/2)
[H1,W]=freqz(NUM2{k},DEN2{k});
H=H.*H1;
end
else
H=1;
end
if(order==1)
[H2,W]=freqz([B0*pwc*Ts B0*pwc*Ts],[(2+C0*pwc*Ts) -2+C0*pwc*Ts]);
H=H.*H2;
end
H=abs(H)/max(abs(H))*A;
figure
plot((W*Fs)/(2*pi),H)
if(N==1)
NUM{1}=[B0*pwc*Ts B0*pwc*Ts];
DEN{1}=[(2+C0*pwc*Ts) -2+C0*pwc*Ts];
else
NUM=NUM2;
DEN=DEN2;
end
end
%chebyshevorder.m
function [N]=chebyshevorder(A,R,wp,m,ws)
%Let the maximum frequency content is set as 10000 Hz
%R is the ripple width
%A/sqrt(2) is the amplitude expected at wp=wc in rad/sec
%The amplitude expected at stopband cutoff frequency ws in rad/sec is lesser
%than m
epsilon=sqrt(R/(A-R));
r=ws/wp;
C=sqrt(((1/(mˆ2))-1)/(epsilonˆ2));
N=ceil(acosh(C)/acosh(r));
fc=wp/(2*pi);
M=[];
for f=0:1:10000;
M=[M A./(1+(epsilonˆ2)*CN(f/fc,N)ˆ2)ˆ(1/2)];
end
figure
plot(0:1:10000,M)

58
2
Inﬁnite Impulse Response (IIR) ﬁlter
2.2.6
Comments on Fig. 2.7 and Fig. 2.8
1. Figure 2.7a shows the intended magnitude response of the Butterworth low-pass
ﬁlter, which is obtained by plotting (2.9) for the typical values of N and wc.
Figure 2.7b shows the magnitude response of the actually designed Butterworth
ﬁlter. This is obtained by mapping Ha(s) (refer (2.7) and (2.8)) to H(z), followed
by computing the magnitude response of the transfer function H(z). It is seen
that the intended magnitude response and the magnitude response of the designed
ﬁlter are almost identical.
2. Figure 2.8a shows the intended magnitude response of the Chebyshev low-pass
ﬁlter, which is obtained by plotting the (2.10) for the typical values of N, wc, and
ε. Figure 2.8c shows the magnitude response of the actually designed Chebyshev
ﬁlter. This is obtained by mapping Ha(s) (refer (2.7) and (2.8)) to H(z), followed
by computing the magnitude response of the transfer function H(z). It is seen
that the intended magnitude response and the magnitude response of the designed
ﬁlter are almost identical.
3. For the bilinear transformation, we need to get the prewarped speciﬁcation to
design the intended low-pass ﬁlter that has the magnitude response as shown in
Fig. 2.7a (Butterworth ﬁlter) and Fig. 2.8a (Chebyshev ﬁlter). The magnitude
Fig. 2.7 Magnitude response of the designed Butterworth IIR low-pass ﬁlter (with magnitude
response less than 0.1 at f s = 3000 Hz (stop band frequency) and 3dB cutoff at f c = 500 Hz
(refer Sects. 2.2.2 and 2.2.3). The sampling frequency is Fs = 20000 Hz. a Intended low-pass
ﬁlter. b Actually designed ﬁlter using impulse-invariant technique. c Speciﬁcation after frequency
prewarping. d Actual designed ﬁlter using bilinear transformation

2.2 Bilinear Transformation Mapping
59
Fig. 2.8 Magnitude response of the designed Chebyshev IIR low-pass ﬁlter (with magnitude
response less than 0.1 at f s = 3000 Hz (stop band frequency), f c = 500 Hz (refer Sects.2.2.4 and
2.2.5)and Ripplewidth(R) = 0.2.Thesamplingfrequencyis Fs = 20000Hz.a Intendedlow-pass
ﬁlter. b Speciﬁcation after frequency pre-warping. c Actually designed ﬁlter using impulse-invariant
technique. d Actual designed ﬁlter using bilinear transformation
response of the IIR ﬁlter with the prewarped frequency speciﬁcations is shown in
Fig. 2.7c (Butterworth ﬁlter) and Fig. 2.8b (Chebyshev ﬁlter) and the magnitude
response of the actually designed IIR ﬁlter using bilinear transformation is shown
in Fig. 2.7d (Butterworth ﬁlter) and Fig. 2.8d (Chebyshev ﬁlter). It is seen that
amplitude of the magnitude response of the ﬁlter after transformation is lesser than
the corresponding value in the prewarped speciﬁcation. This helps in avoiding
overlapping of spectrum.
2.2.7
Design of High-Pass, Bandpass, and Band-Reject IIR
Filter
2.2.7.1
High-Pass Filter
Given the low-pass ﬁlter transfer function H(e jwd) with cutoff wc radians, the high-
pass ﬁlter is obtained as H(e j(π−wd)) with cutoff π −wc. This is equivalent to
replacing z with −z in the z-transformation corresponding to LPF to obtain the
HPF z-transform. Digital Butterworth high-pass ﬁlter using impulse invariant trans-

60
2
Inﬁnite Impulse Response (IIR) ﬁlter
Fig. 2.9 Magnitude response of the Butterworth high-pass ﬁlter using impulse-invariant mapping
formation and bilinear transformation with pass band cutoff 8π rad/sec, stop band
cutoff frequency 2π rad/sec, and sampling frequency Fs = 10 Hz is illustrated in
Figs. 2.9 and 2.10, respectively. It is seen from Fig. 2.9 that the Aliasing occur at
the lower frequencies. It is also noted that there exists nonzero amplitude at DC (0
Hz). This is the undesirable characteristics and hence impulse-invariant mapping is
not usually used to design high-pass ﬁlter. This is circumvented using the bilinear
transformation and is illustrated in Fig. 2.10.
%ButterworthHPFdemo.m
%Digital Butterworth high-pass filter using
%Impulse invariant and bilinear transformation with pass band cutoff
%2*pi*4 rad/sec, stop band cutoff frequency 2*pi*1 rad/sec
%magnitude at the stop band lesser than 0.1 and the sampling frequency 10 Hz
[NUM,DEN,H]=digitalbutterworthHPF(1,2*pi*4,2*pi*1,0.1,10,1)
[NUM,DEN,H]=digitalbutterworthHPF(1,2*pi*4,2*pi*1,0.1,10,1)
%digitalbutterworthHPF.m
function [NUM,DEN,H]=digitalbutterworthHPF(A,wc,ws,m,Fs,option)
wc=(pi-(wc/Fs))*Fs
ws=(pi-(ws/Fs))*Fs
%option 1: Impulse invariant technique
%option 2: Bilinear transformation technique
switch option
case 1
[N]=butterworthorder(A,wc,ws,m);
N
Ts=1/Fs;
order=mod(N,2);

2.2 Bilinear Transformation Mapping
61
Fig. 2.10 Magnitude response of the Butterworth high-pass ﬁlter using bilinear transformation
mapping
if(order==0)
N1=N;
else
N1=N-1;
end
b=0;
for k=1:1:(N1/2)
b(k)=2*sin((2*k-1)*pi/(2*N))
end
Ck=1;
Bk=(A)ˆ(2/N);
B0=1;
c0=1;
%Converting s domain to z domain
if(N˜=1)
for k=1:1:length(b)
[NU,DE]=impulses2z(Bk,Ck,b(k),wc,Fs)
L1=length(NU)
if(mod(L1,2)==1)
L=(L1+1)/2;
s1=[ones(1,L/2);zeros(1,L/2)]*2-1
s1=reshape(s1,1,size(s1,1)*size(s1,2))
s1=[s1 1];
else
L=L1/2;
s1=[ones(1,L);zeros(1,L)]*2-1
s1=reshape(s1,1,size(s1,1)*size(s1,2))
end
res1{k}=NU.*s1;
L2=length(DE);
if(mod(L2,2)==1)

62
2
Inﬁnite Impulse Response (IIR) ﬁlter
L=(L2+1)/2;
s2=[ones(1,L/2);zeros(1,L/2)]*2-1;
s2=reshape(s2,1,size(s2,1)*size(s2,2));
s2=[s2 1];
else
L=L2/2;
s2=[ones(1,L);zeros(1,L)]*2-1;
s2=reshape(s2,1,size(s2,1)*size(s2,2));
end
res2{k}=DE.*s2
end
H=1;
NUM1=res1;
DEN1=res2;
for k=1:1:(N1/2)
[H1,W]=freqz(NUM1{k},DEN1{k})
H=H.*H1;
end
else
H=1;
end
if(order==1)
[H2,W]=freqz([B0*wc],[1 exp(-c0*wc*Ts)]);
H=H.*H2;
end
H=abs(H)/max(abs(H))*A;
figure
plot((W*Fs)/(2*pi),H)
if(N==1)
NUM{1}=[B0*wc];
DEN{1}=[1 exp(-c0*wc*Ts)];
else
NUM=NUM1;
DEN=DEN1;
end
case 2
%Frequency prewarping
%Needs to design the digital filter with cutoff frequency
wcd=(wc/Fs);
wsd=(ws/Fs);
Ts=1/Fs;
pwc=(2/Ts)*tan(wcd/2);
pws=(2/Ts)*tan(wsd/2);
[N]=butterworthorder(A,pwc,pws,m);
N
order=mod(N,2);
if(order==0)
N1=N;
else
N1=N-1;
end
b=0;
for k=1:1:(N1/2)
b(k)=2*sin((2*k-1)*pi/(2*N));
end
Ck=1;

2.2 Bilinear Transformation Mapping
63
Bk=(A)ˆ(2/N);
B0=1;
c0=1;
if(N˜=1)
for k=1:1:length(b)
[NU,DE]=bilinears2z(Bk,Ck,b(k),pwc,Fs)
L1=length(NU);
if(mod(L1,2)==1)
L=(L1+1)/2;
s1=[ones(1,L/2);zeros(1,L/2)]*2-1;
s1=reshape(s1,1,size(s1,1)*size(s1,2));
s1=[s1 1];
else
L=L1/2;
s1=[ones(1,L/2);zeros(1,L/2)]*2-1;
s1=reshape(s1,1,size(s1,1)*size(s1,2));
end
res1{k}=NU.*s1;
L2=length(DE);
if(mod(L2,2)==1)
L=(L2+1)/2;
s2=[ones(1,L/2);zeros(1,L/2)]*2-1;
s2=reshape(s2,1,size(s2,1)*size(s2,2));
s2=[s2 1];
else
L=L2/2;
s2=[ones(1,L);zeros(1,L)]*2-1;
s2=reshape(s2,1,size(s2,1)*size(s2,2));
end
res2{k}=DE.*s2;
end
NUM2=res1;
DEN2=res2;
H=1;
for k=1:1:(N1/2)
[H1,W]=freqz(NUM2{k},DEN2{k});
H=H.*H1;
end
else
H=1;
end
if(order==1)
[H2,W]=freqz([B0*pwc*Ts -B0*pwc*Ts],[(2+c0*pwc*Ts) 2-c0*pwc*Ts]);
H=H.*H2;
end
H=abs(H)/max(abs(H))*A;
figure
plot((W*Fs)/(2*pi),H)
if(N==1)
NUM{1}=[B0*pwc*Ts -B0*pwc*Ts]
DEN{1}=[(2+c0*pwc*Ts) 2-c0*pwc*Ts]
else
NUM=NUM2;
DEN=DEN2;
end
end

64
2
Inﬁnite Impulse Response (IIR) ﬁlter
%chebyshevHPFdemo.m
%Digital Chebyshev high-pass filter using
%Impulse invariant and Bilinear transformation with pass band cutoff
%2*pi*4 rad/sec, stop band cutoff frequency 2*pi*1 rad/sec, Ripple width 0.5
%magnitude at the stop band lesser than 0.1 and the sampling frequency 10 Hz
[NUM,DEN,H]=digitalchebyshevHPF(1,0.5,2*pi*4,2*pi*1,0.1,10,1)
[NUM,DEN,H]=digitalchebyshevHPF(1,0.5,2*pi*4,2*pi*1,0.1,10,2)
%digitalchebyshevHPF.m
function [NUM,DEN,H]=digitalchebyshevHPF(A,R,wp,ws,m,Fs,option)
wp=(pi-(wp/Fs))*Fs
ws=(pi-(ws/Fs))*Fs
%option 1: Impulse invariant technique
%option 2: Bilinear transformation technique
switch option
case 1
[N]=chebyshevorder(A,R,wp,m,ws)
N
Ts=1/Fs;
order=mod(N,2);
if(order==0)
N1=N;
else
N1=N-1;
end
epsilon=sqrt(R/(A-R));
t=(((1/epsilonˆ2)+1)ˆ(1/2)+(1/epsilon));
Y= (1/2)*(tˆ(1/N)-tˆ(-1/N));
b=0;
for k=1:1:(N1/2)
b(k)=2*Y*sin((2*k-1)*pi/(2*N));
C(k)=Yˆ2+(cos((2*k-1)*pi/(2*N)))ˆ(2);
end
Bk=(A)ˆ(2/N);
B0=Bk;
C0=Y;
wc=wp;
%Converting s domain to z domain
if(N˜=1)
for k=1:1:length(b)
[NU,DE]=impulses2z(Bk,C(k),b(k),wc,Fs)
L1=length(NU)
if(mod(L1,2)==1)
L=(L1+1)/2;
s1=[ones(1,L/2);zeros(1,L/2)]*2-1
s1=reshape(s1,1,size(s1,1)*size(s1,2))
s1=[s1 1];
else
L=L1/2;
s1=[ones(1,L);zeros(1,L)]*2-1
s1=reshape(s1,1,size(s1,1)*size(s1,2))
end
res1{k}=NU.*s1;
L2=length(DE);
if(mod(L2,2)==1)
L=(L2+1)/2;
s2=[ones(1,L/2);zeros(1,L/2)]*2-1;

2.2 Bilinear Transformation Mapping
65
s2=reshape(s2,1,size(s2,1)*size(s2,2));
s2=[s2 1];
else
L=L2/2;
s2=[ones(1,L);zeros(1,L)]*2-1;
s2=reshape(s2,1,size(s2,1)*size(s2,2));
end
res2{k}=DE.*s2
end
H=1;
NUM1=res1;
DEN1=res2;
for k=1:1:(N1/2)
[H1,W]=freqz(NUM1{k},DEN1{k});
H=H.*H1;
end
else
H=1;
end
if(order==1)
[H2,W]=freqz([B0*wc],[1 exp(-C0*wc*Ts)]);
H=H.*H2;
end
H=abs(H)/max(abs(H))*A;
figure
plot((W*Fs)/(2*pi),H)
if(N==1)
NUM{1}=[B0*wc];
DEN{1}=[1 exp(-C0*wc*Ts)];
else
NUM=NUM1;
DEN=DEN1;
end
case 2
%Frequency prewarping
%Needs to design the digital filter with cutoff frequency
wpd=(wp/Fs);
wsd=(ws/Fs);
Ts=1/Fs;
pwp=(2/Ts)*tan(wpd/2);
pws=(2/Ts)*tan(wsd/2);
[N]=chebyshevorder(A,R,pwp,m,pws)
N
order=mod(N,2);
if(order==0)
N1=N;
else
N1=N-1;
end
epsilon=sqrt(R/(A-R));
t=(((1/epsilonˆ2)+1)ˆ(1/2)+(1/epsilon));
Y= (1/2)*(tˆ(1/N)-tˆ(-1/N));
b=0;
for k=1:1:(N1/2)
b(k)=2*Y*sin((2*k-1)*pi/(2*N));
C(k)=Yˆ2+(cos((2*k-1)*pi/(2*N)))ˆ(2);

66
2
Inﬁnite Impulse Response (IIR) ﬁlter
end
Bk=(A)ˆ(2/N);
B0=Bk;
C0=Y;
pwc=pwp;
if(N˜=1)
for k=1:1:length(b)
[NU,DE]=bilinears2z(Bk,C(k),b(k),pwc,Fs);
L1=length(NU)
if(mod(L1,2)==1)
L=(L1+1)/2;
s1=[ones(1,L/2);zeros(1,L/2)]*2-1
s1=reshape(s1,1,size(s1,1)*size(s1,2))
s1=[s1 1];
else
L=L1/2;
s1=[ones(1,L);zeros(1,L)]*2-1
s1=reshape(s1,1,size(s1,1)*size(s1,2))
end
res1{k}=NU.*s1;
L2=length(DE);
if(mod(L2,2)==1)
L=(L2+1)/2;
s2=[ones(1,L/2);zeros(1,L/2)]*2-1;
s2=reshape(s2,1,size(s2,1)*size(s2,2));
s2=[s2 1];
else
L=L2/2;
s2=[ones(1,L);zeros(1,L)]*2-1;
s2=reshape(s2,1,size(s2,1)*size(s2,2));
end
res2{k}=DE.*s2;
end
NUM2=res1;
DEN2=res2;
H=1;
for k=1:1:(N1/2)
[H1,W]=freqz(NUM2{k},DEN2{k});
H=H.*H1;
end
else
H=1;
end
if(order==1)
[H2,W]=freqz([B0*pwc*Ts -B0*pwc*Ts],[(2+C0*pwc*Ts) 2-C0*pwc*Ts]);
H=H.*H2;
end
H=abs(H)/max(abs(H))*A;
figure
plot((W*Fs)/(2*pi),H)
if(N==1)
NUM{1}=[B0*pwc*Ts -B0*pwc*Ts ];

2.2 Bilinear Transformation Mapping
67
DEN{1}=[(2+C0*pwc*Ts) 2-C0*pwc*Ts ];
else
NUM=NUM2;
DEN=DEN2;
end
end
2.2.7.2
Bandpass Filter
Bandpass ﬁlter is obtained as the cascade of low-pass ﬁlter with cutoff frequency wc2
and high-pass ﬁlter with cutoff frequency wc1 (Figs. 2.11 and 2.12). The bandpass
ﬁlter with wc1 = 2π rad/sec and wc2 = 8π rad/sec is illustrated in Fig. 2.13a–c
(Butterworth ﬁlter) and Fig. 2.13d–f (Chebyshev ﬁlter) using bilinear transformation
technique. It is constructed using the cascade connection of low-pass ﬁlter (with
cutoff frequency wc2 = 8π rad/sec and stop band cutoff frequency ws2 = 2π0.1 Fs
2
rad/sec), followed by the high-pass ﬁlter (with cutoff frequency wc1 = 2π rad/sec
and ws1 = 2π0.9 Fs
2 rad/sec). Impulse-invariant (lead to overlapping) is not usually
chosen to design other than low-pass ﬁlter. Hence, illustration of bandpass ﬁlter using
bilinear transformation is demonstrated.
Fig. 2.11 Magnitude response of the Chebyshev high-pass ﬁlter using impulse-invariant mapping.
It is seen that the magnitude is nonzero at f = 0Hz. This is due to overlapping of spectrum

68
2
Inﬁnite Impulse Response (IIR) ﬁlter
Fig. 2.12 Magnitude response of the Chebyshev high-pass ﬁlter using bilinear transformation
mapping
%IIRBPFDEMO.m
A=1;
wc1=2*pi*1;
wc2=2*pi*4;
m=0.001;
Fs=10;
Ripple=0.5;
%Using Butterworth filter and impulse-invariant transformation
[NUM,DEN,H]=digitalBPF(1,Ripple,wc1,wc2,m,Fs,1,2);
figure;
plot(linspace(0,Fs/2,length(H)),abs(H));
%Using Chebyshevfilter and bilinear transformation
[NUM,DEN,H]=digitalBPF(1,Ripple,wc1,wc2,m,Fs,2,2);
figure
plot(linspace(0,Fs/2,length(H)),abs(H));
function [NUM,DEN,H]=digitalBPF(A,R,wc1,wc2,m,Fs,option1,option2)
%R is the ripple width used in case of Chebyshev filter
%A is the maximum amplitude of the filter
%H is the normalized magnitude response of the designed filter
%wc1 and wc2 are the cutoff frequencies in rad/sec
%option1:1->Butterworth 2->Chebyshev filter
%option2: 1->Impulse invariant 2->Bilinear
Fmax=Fs/2;

2.2 Bilinear Transformation Mapping
69
Fig. 2.13 Bandpass ﬁlter using bilinear transformation. a Butterworth low-pass ﬁlter. b Butterworth
high-pass ﬁlter. c Corresponding Butterworth bandpass ﬁlter as the cascade of low-pass and high-
pass ﬁlter. d Chebyshev low-pass ﬁlter. e Chebyshev high-pass ﬁlter. f Corresponding Chebyshev
bandpass ﬁlter as the cascade of low-pass and high-pass ﬁlter
ws1=2*pi*0.1*(Fmax);
ws2=2*pi*0.9*(Fmax);
switch option1
case 1
switch option2
case 1
[N1,D1,H1]=digitalbutterworth(A,wc2,ws2,m,Fs,1);
[N2,D2,H2]=digitalbutterworthHPF(A,wc1,ws1,m,Fs,1);
case 2
[N1,D1,H1]=digitalbutterworth(A,wc2,ws2,m,Fs,2);
[N2,D2,H2]=digitalbutterworthHPF(A,wc1,ws1,m,Fs,2);
end
case 2
switch option2
case 1
[N1,D1,H1]=digitalchebyshev(A,R,wc2,ws2,m,Fs,1);
[N2,D2,H2]=digitalchebyshevHPF(A,R,wc1,ws1,m,Fs,1);
case 2
[N1,D1,H1]=digitalchebyshev(A,R,wc2,ws2,m,Fs,2);
[N2,D2,H2]=digitalchebyshevHPF(A,R,wc1,ws1,m,Fs,2);
end
end
temp1=1;
temp2=1;
temp3=1;

70
2
Inﬁnite Impulse Response (IIR) ﬁlter
for i=1:1:length(N1)
temp1=conv(temp1,N1{i})
temp2=conv(temp2,D1{i})
end
for i=1:1:length(N2)
temp1=conv(temp1,N2{i})
temp2=conv(temp2,D2{i})
end
NUM=temp1;
DEN=temp2;
H=H1.*H2;
2.2.7.3
Band-reject Filter
Band-reject ﬁlter is obtained as the parallel connection of low-pass ﬁlter with cutoff
frequency wc1 and the high-pass ﬁlter with cutoff frequency wc2. The band-reject
ﬁlter with wc1 = 2π rad/sec and wc2 = 8π rad/sec is illustrated in Fig. 2.14a–c
(Butterworth ﬁlter) and Fig. 2.14d–f (Chebyshev ﬁlter) using bilinear transformation
technique. It is constructed using the parallel connection of low-pass ﬁlter (with
cutoff frequency wc1 = 2π rad/sec and stop band cutoff frequency ws1 = 2π0.9 Fs
2 ),
followed by the high-pass ﬁlter (with cutoff frequency wc2 = 2π rad/sec and ws2 =
2π0.1 Fs
2 ). Impulse-invariant (lead to overlapping) is not usually chosen to design
other than low-pass ﬁlter. Hence, realization using the bilinear transformation is
demonstrated.
%IIRBRFdemo.m
A=1;
wc1=2*pi*1;
wc2=2*pi*4;
m=0.001;
Fs=10;
Ripple=0.5;
%Using Butterworth filter and impulse-invariant transformation
[NUM,DEN,H]=digitalBRF(1,Ripple,wc1,wc2,m,Fs,1,2);
figure;
plot(linspace(0,Fs/2,length(H{1})),(1/2)*(abs(H{1})+abs(H{2})));
%Using Chebyshev filter and bilinear transformation
[NUM,DEN,H]=digitalBRF(1,Ripple,wc1,wc2,m,Fs,2,2);
figure
plot(linspace(0,Fs/2,length(H{1})),(1/2)*(abs(H{1})+abs(H{2})));
%digitalBRF.m
function [NUM,DEN,H]=digitalBRF(A,R,wc1,wc2,m,Fs,option1,option2)
%option1:1->Butterworth 2->Chebyshev filter
%option2: 1->Impulse invariant 2->Bilinear
%R is the ripple width used in case of Chebyshev filter
Fmax=Fs/2;
ws1=2*pi*0.9*(Fmax);
ws2=2*pi*0.1*(Fmax);
switch option1
case 1

2.2 Bilinear Transformation Mapping
71
Fig. 2.14 Band-reject ﬁlter using bilinear transformation. a Butterworth low-pass ﬁlter. b But-
terworth high-pass ﬁlter. c Corresponding band-reject ﬁlter as the parallel summation of low-pass
and high-pass ﬁlter. d Chebyshev low-pass ﬁlter. e Chebyshev high-pass ﬁlter. f Corresponding
Chebyshev band-reject ﬁlter as the parallel summation of low-pass and high-pass ﬁlter
switch option2
case 1
[N1,D1,H1]=digitalbutterworth(A,wc1,ws1,m,Fs,1);
figure
[N2,D2,H2]=digitalbutterworthHPF(A,wc2,ws2,m,Fs,1);
case 2
[N1,D1,H1]=digitalbutterworth(A,wc1,ws1,m,Fs,2);
[N2,D2,H2]=digitalbutterworthHPF(A,wc2,ws2,m,Fs,2);
end
case 2
switch option2
case 1
[N1,D1,H1]=digitalchebyshev(A,R,wc1,ws1,m,Fs,1);
[N2,D2,H2]=digitalchebyshevHPF(A,R,wc2,ws2,m,Fs,1);
case 2
[N1,D1,H1]=digitalchebyshev(A,R,wc1,ws1,m,Fs,2);
[N2,D2,H2]=digitalchebyshevHPF(A,R,wc2,ws2,m,Fs,2);
end
end
NUM=N1;
DEN=D1;
H{1}=H1;
H{2}=H2;

72
2
Inﬁnite Impulse Response (IIR) ﬁlter
2.3
Realization
Let the transfer function of the typical IIR ﬁlter is given as follows:
H(z) = a0 + a1z−1 + a2z−2 + · · · apz−p
b0 + b1z−1 + b2z−3 + · · · bqz−q .
(2.11)
Realization of the IIR ﬁlter is the method of obtaining the output sequence y(n)
corresponding to the input sequence x(n) to the linear IIR ﬁlter h(n). This is done
as follows.
2.3.1
Direct Form 1
Let X(z), Y(z) be the z-transformation of the sequence x(n) and y(n), respectively:
Y(z)
X(z) =
a0 + a1z−1 + a2z−2 + a3z−3 + · · · apz−p
b0 + b1z−1 + b2z−2 + b3z−3 + · · · + bqz−q .
(2.12)
Taking inverse z-transformation, we get the following difference equations:
y(n) = a0
b0
x(n) + a1
b0
x(n −1) + a2
b0
x(n −2) + · · · + ap
b0
x(n −p)
−b1
b0
y(n −1) −b2
b0
y(n −2) −· · · −bq
b0
y(n −q).
2.3.2
Direct Form 2
Let
Y(z)
X(z) = Y(z)
W(z)
W(z)
X(z) ,
Y(z)
W(z) = a0 + a1z−1 + a2z−2 + · · · apz−p
and
W(z)
X(z) =
1
b0+b1z−1+b2z−2+···bqz−q . Taking inverse z-transformation, we get the following
difference equations:
w(n) = −1
b0
x(n) −b1
b0
w(n −1) −b2
b0
w(n −2)
y(n) = a0w(n) + a1w(n −1) + a2w(n −2).
We see that to realize IIR ﬁlter using Direct form I, we need number of (p + q)
number of taps. But to realize using Direct form II, we need only max(p, q) number
of taps at the cost of time required for the computation.

2.3 Realization
73
2.3.3
Illustration
Consider the input signal x(t) = k=3
k=1 Aksin(2π fkt) is sampled using the sampling
frequency Fs to obtain the discrete sequence x(n) = k=3
k=1 sin(2π fknT s). The dig-
ital impulse-invariant Butterworth IIR ﬁlter is designed to ﬁlter f3 as given below.
1. Let A1 = 1, A2 = 1 and A3 = 1, f1 = 10, f2 = 15 and f3 = 200.
2. The speciﬁcation is obtained as follows: Butterworth low-pass ﬁlter is designed
with A = 1, wc = 2 ∗pi ∗30, ws = 2 ∗pi ∗100, Fs = 500 and the amplitude
is lesser than 0.1 at ws.
3. The transfer function of the ﬁlter is obtained as
H(z) =
53.7905Z−1
1 −1.4779Z−1 + 0.5868Z−2 .
(2.13)
4. Direct form 1: For the input sequence x(n), the corresponding output sequence is
obtained as follows: y(n) = 53.79x(n −1) −1.477y(n −1) −0.5868y(n −2).
5. Direct form 2: For the input sequence x(n), the corresponding output sequence is
obtainedasfollows:w(n) = −x(n) + 1.477w(n −1) −0.5868w(n −2), y(n) =
53.79w(n −1).
6. The number of taps needed for realization of the ﬁlter is 3 for Direct form I (DF1)
and 2 for Direct form II (DF2). The elapsed time required for DF1 and DF2
realization is given as 0.005619 and 0.009127 s, respectively.
7. Figure 2.15 illustrates the realization of IIR ﬁlter using Direct form I and are
identical with that of the magnitude response realized using Direct form II.
Figure 2.16 illustrates the magnitude response of IIR ﬁlter corresponding to the
transfer function (2.13).
%realizeiir.m
A1=1;
A2=1;
A3=1;
f1=10;
f2=15;
f3=200;
A=1;
wc=2*pi*30;
ws=2*pi*100;
Fs=500;
Ts=1/Fs;
m=0.1;
n=0:1:1000;
S=A1*sin(2*pi*f1*n*Ts)+A2*sin(2*pi*f2*n*Ts)+A3*sin(2*pi*f3*n*Ts);
[NUM,DEN,H]=digitalbutterworth(A,wc,ws,m,Fs,1);
NUM{1}
DEN{1}
temp1=1;
temp2=1;
for k=1:1:length(NUM)
temp1=conv(temp1,NUM{k});

74
2
Inﬁnite Impulse Response (IIR) ﬁlter
Fig. 2.15 Demonstration on the Direct form I realization of IIR ﬁlter using a input signal, b Filtered
signal, c spectrum of the input signal, d spectrum of the ﬁltered signal
Fig. 2.16 Magnitude response of the IIR ﬁlter used to ﬁlter the input signal (refer Fig. 2.15)

2.3 Realization
75
end
for k=1:1:length(DEN)
temp2=conv(temp2,DEN{k});
end
temp1=temp1+eps;
[H,W]=freqz(temp1,temp2);
figure
plot(Fs*W/(2*pi),abs(H)/max(abs(H)))
%Direct form I realization
y=zeros(1,length(temp2)+1);
tic
for n=length(y)+1:1:1000
temp=0;
for r=0:1:length(temp1)-1
temp=temp+temp1(r+1)*S(n-r);
end
for s=1:1:length(temp2)-1
temp=temp-1*temp2(s+1)*y(n-s);
end
temp=temp/temp2(1);
y=[y temp];
end
toc
S=S/max(S);
y=y/max(y);
FRS=abs(fft(S))/max(abs(fft(S)));
FRy=abs(fft(y))/max(abs(fft(y)));
figure
subplot(2,2,1)
plot(S)
subplot(2,2,2)
plot(y)
subplot(2,2,3)
plot(linspace(0,Fs,length(S)),FRS)
subplot(2,2,4)
plot(linspace(0,Fs,length(y)),FRy)
%Directform II realization
M=max(length(temp1),length(temp2));
y=zeros(1,M+1);
w=zeros(1,M+1);
tic
for n=length(w):1:1000
temp=0;
temp=S(n);
for r=1:1:length(temp2)-1
temp=temp-temp2(r+1)*w(n-r);
end
w(n)=temp/temp2(1);
temp=0;
for s=0:1:length(temp1)-1
temp=temp+temp1(s+1)*w(n-s);
end
y=[y temp];
end
toc
S=S/max(S);
y=y/max(y);

76
2
Inﬁnite Impulse Response (IIR) ﬁlter
FRS=abs(fft(S))/max(abs(fft(S)));
FRy=abs(fft(y))/max(abs(fft(y)));
figure
subplot(2,2,1)
plot(S)
subplot(2,2,2)
plot(y)
subplot(2,2,3)
plot(linspace(0,Fs,length(S)),FRS)
subplot(2,2,4)
plot(linspace(0,Fs,length(y)),FRy)

Chapter 3
Finite Impulse Response Filter (FIR Filter)
The impulse response of the linear phase FIR ﬁlter satisﬁes the condition h(n) =
±h(N −n −1), with h(n) nonzero for n = 0 · · · (N −1). The magnitude and the
phase response of linear phase FIR ﬁlter are summarized below.
1. Type 1: N is odd (consider N = 5) with h(n) = h(N −1 −n)
H(e jwd ) = h(0) + h(1)e−jwd + h(2)e−j2wd + h(3)e−j3wd + h(4)e−j4wd
⇒H(e jwd ) = e−j2wd (h(0)e j2wd + h(1)e jwd + h(2) + h(3)e−jwd + h(4)e−j2wd )
⇒e−j2wd (h(0)e j2wd + h(1)e jwd + h(2) + h(1)e−jwd + h(0)e−j2wd )
⇒e−j2wd (h(2) + 2h(0)cos(2wd) + 2h(1)cos(wd))
2. Type2: N isodd(consider N = 5)withh(n) = −h(N −1 −n)withh( N−1
2 ) = 0
H(e jwd ) = h(0) + h(1)e−jwd + h(2)e−j2wd + h(3)e−j3wd + h(4)e−j4wd
⇒H(e jwd ) = e−j2wd (h(0)e j2wd + h(1)e jwd + h(2) + h(3)e−jwd + h(4)e−j2wd )
⇒e−j2wd (h(0)e j2wd + h(1)e jwd + h(2) −h(1)e−jwd −h(0)e−j2wd )
⇒e−j2wd e j π
2 (2h(0)sin(2wd) + 2h(1)sin(wd))
3. Type 3: N is even (consider N = 4) with h(n) = h(N −1 −n)
Consider the transfer function of the Type 3 FIR ﬁlter with N = 4.
H(e jwd) = h(0) + h(1)e−jwd + h(2)e−j2wd + h(3)e−j3wd
⇒H(e jwd) = e−j 3wd
2 (h(0)e j 3wd
2 + h(1)e j wd
2 + h(1)e−j wd
2 + h(0)e−j 3wd
2 )
⇒e−j 3wd
2 (2h(0)cos(wd
2 ) + 2h(1)cos(3wd
2 ))
4. Type 4: N is even (consider N = 4) with h(n) = −h(N −1 −n)
© Springer International Publishing AG 2018
E.S. Gopi, Multi-Disciplinary Digital Signal Processing,
DOI 10.1007/978-3-319-57430-1_3
77

78
3
Finite Impulse Response Filter (FIR Filter)
H(e jwd) = h(0) + h(1)e−jwd + h(2)e−j2wd + h(3)e−j3wd
⇒H(e jwd) = e−j 3wd
2 (h(0)e j 3wd
2 h(1)e j wd
2 −h(1)e−j wd
2 −h(0)e−j 3wd
2 )
⇒e−j 3wd
2 (2 jh(0)sin(wd
2 ) + 2 jh(1)sin(3wd
2 ))
⇒e−j 3wd
2 e j π
2 (2h(0)sin(wd
2 ) + 2h(1)sin(3wd
2 ))
3.1
Demonstration of Four Types of FIR Filter
Given the sequence of impulse response of the FIR ﬁlter be represented as h(n), the
magnitude and the phase response of the ﬁlter is obtained as
M = abs(
N−1

n=0
h(n)e−jwdn)
P = angle(
N−1

n=0
h(n)e−jwdn)
In particular, the generalized expressions for the four types of FIR ﬁlter with an
arbitrary value of N are summarized below. Let τ = N−1
2 . The transfer function of
the ith type of FIR ﬁlter is obtained as Mie−j Pi, where
M1 = h(0) +
N−1
2

n=1
2h(n)cos((τ −n + 1)wd)
(3.1)
P1 = −τwd
(3.2)
M2 =
N−1
2

n=1
2h(n)sin((τ −n + 1)wd)
(3.3)
P2 = −τwd + π
2
(3.4)
M3 = h(0) +
N−1
2

n=1
2h(n)cos((τ −n + 1)wd)
(3.5)
P3 = −τwd
(3.6)
M4 =
N−1
2

n=1
2h(n)sin((τ −n + 1)wd)
(3.7)
P4 = −τwd + π
2
(3.8)

3.1 Demonstration of Four Types of FIR Filter
79
Fig. 3.1 Demonstration of Type 1 FIR ﬁlter. a M1, b abs(M1), c abs(M) computed for Type 1
ﬁlter, d P1, e S = sign of M1, f P H1 = (S −1) −π
2 + P1, g P computed for Type 1 ﬁlter, h cos(P),
i cos(P H1)
Figures3.1, 3.2, 3.3 and 3.4 demonstrates the computation of magnitude and the
phase response of the four types of FIR ﬁlter with the following speciﬁcations.
• Type 1: N = 11, h(n) =
sin(wc(n−(N−1)
2
))
π(n−(N−1)
2
)
for n = 0 · · · (N−1)
2
, h(n) = h(N −n −1)
• Type 2: N = 11, h(n) =
sin(wc(n−(N−1)
2
))
π(n−(N−1)
2
)
for n = 0 · · · (N−1)
2
, h(n) = −h(N −n −
1), h( N−1
2 ) = 0
• Type 3: N = 10, h(n) =
sin(wc(n−(N−1)
2
))
π(n−(N−1)
2
)
for n = 0 · · · N
2 , h(n) = h(N −n −1)
• Type 4: N = 10, h(n) =
sin(wc(n−(N−1)
2
))
π(n−(N−1)
2
)
for n = 0 · · · N
2 , h(n) = −h(N −n −1).
The details on the Pole-zero plot (refer Fig.3.5) are summarized below.
1. The generalized expression for the polynomial H(z) is given as H(z) = h(0) +
h(1)z−1 + h(2)z−2 + · · · + h(N −1)z−(N−1).
2. For the real coefﬁcients [h(0) h(1) · · · h(N −1)], the roots of the polynomial
H(z) are available as the complex conjugate pair.
3. For Type 2 with N = 5, we get the polynomial as H(z) = h(0) + h(1)z−1 +
h(2)z−2 −h(1)z−3 −h(0)z−4 with h(2) = 0. From the expression, we observe
that H(z) = 0 for z = 1 and z = −1. This implies zeros lie on the unit circle at
wd = 0 and wd = π or wd = −π.

80
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.2 Demonstration of Type 2 FIR ﬁlter. a M2, b abs(M2), c abs(M) computed for Type 2
ﬁlter, d P2, e S = sign of M2, f PH2 = (S −1) −π
2 + P2, g P computed for Type 2 ﬁlter, h cos(P),
i cos(PH2)
Fig. 3.3 Demonstration of Type 3 FIR ﬁlter. a M3, b abs(M3), c abs(M) computed for Type 3
ﬁlter, d P3, e S = sign of M3, f P H3 = (S −1) −π
2 + P3, g P computed for Type 3 ﬁlter, h cos(P),
i cos(P H3)

3.1 Demonstration of Four Types of FIR Filter
81
Fig. 3.4 Demonstration of Type 4 FIR ﬁlter. a M4, b abs(M4), c abs(M) computed for Type 4
ﬁlter, d P4, e S = sign of M4, f P H4 = (S −1) −π
2 + P4, g P computed for Type 4 ﬁlter, h cos(P),
i cos(PH4)
4. For Type 3 with N = 4, we get the polynomial as H(z) = h(0) + h(1)z−1 +
h(1)z−2 + h(0)z−3. In this case, we observe that H(z) = 0 for z = −1. This
implies zero lies on the unit circle at wd = π.
5. For Type 4 with N = 4, we get the polynomial as H(z) = h(0) + h(1)z−1 −
h(1)z−2 −h(0)z−3. In this case, we observe that H(z) = 0 for z = 1. This
implies zero lies on the unit circle at wd = 0.
6. It is observed from Fig.3.1b, magnitude values are zero at 6 positions between
−π to π. These are due to 6 zeros present as shown in Fig.3.5a.
7. It is observed from Fig.3.3b, magnitude values are zero at 6 positions between
−π to π. These are due to 5 zeros present as shown in the Fig.3.5c and one at
π or −π.
8. It is observed from Fig.3.2b, the magnitude response is Band pass in nature
(These are due to presence of zeros at 0 and π) and from Fig.3.4b, the magnitude
response is High pass in nature (These are due to presence of zeros at 0). Hence
Type 2 and Type 4 are not suitable for Low-pass ﬁlter design.
9. FIR ﬁlters with real coefﬁcients (four zeros occur as the complex conjugate) that
has the identical magnitude response and different phase response is illustrated
in the Figs.3.6 and 3.7.
10. If all the zeros of the transfer function H(z) lie within the unit circle, it is known
as minimum phase ﬁlter. If all the zeros of the transfer function H(z) lie outside
the unit circle, it is known as minimum phase ﬁlter.

82
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.5 Pole zero plot: a Type 1 FIR ﬁlter, b Type 2 FIR ﬁlter, c Type 3 FIR ﬁlter, d Type 4 FIR
ﬁlter
11. From Figs.3.6b, d and 3.7b, d, it is observed that the minimum phase FIR ﬁlter
can be represented as the product of maximum phase FIR ﬁlter and the stable
all pass ﬁlter (refer Fig.3.8) (refer Sect.3.3 for further details).
%FIRdemo.m
%FIR demonstration
N=11;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Type 1: h(n)=h(N-1-n), N->Odd
wc=pi/2;
tau=(N-1)/2;
n=0:1:N-1;
h=sin(wc*(n-tau))./(pi*(n-tau));
u=isnan(h);
[p,q]=find(u==1);
h(q)=wc/pi;
temp1=[];
temp2=[];
for w=-pi:0.001:pi;
[s,a]=firtype1(N,h,w);
temp1=[temp1 s];
temp2=[temp2 a];
end

3.1 Demonstration of Four Types of FIR Filter
83
Fig. 3.6 Pole-zero plot of four ﬁlters that have identical magnitude response
Fig. 3.7 Magnitude and phase response corresponding to the FIR ﬁlters mentioned in Fig.3.6

84
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.8 Illustration of the pole-zero plot of the All pass ﬁlter that converts minimum phase ﬁlter
to maximum phase ﬁlter
figure(1)
subplot(3,3,1)
plot(-pi:0.001:pi,temp1)
subplot(3,3,2)
plot(-pi:0.001:pi,abs(temp1))
m=[];
p=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
p=[p angle(sum(h.*exp(-j*w*n)))];
end
subplot(3,3,3)
plot(-pi:0.001:pi,m)
subplot(3,3,4)
plot(-pi:0.001:pi,temp2)
subplot(3,3,5)
plot(-pi:0.001:pi,sign(temp1))
temp=sign(temp1);
temp3=(temp-1)*(-pi/2);
subplot(3,3,6)
plot(-pi:0.001:pi,temp2+temp3)
subplot(3,3,7)
plot(-pi:0.001:pi,p)
subplot(3,3,8)
plot(-pi:0.001:pi,cos(p))
subplot(3,3,9)
plot(-pi:0.001:pi,cos(temp2+temp3))
figure(5)
subplot(2,2,1)

3.1 Demonstration of Four Types of FIR Filter
85
zplane(h)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Type 2: h(n)=-h(N-1-n), N->Odd
N=11;
wc=pi/2;
tau=(N-1)/2;
n=0:1:N-1;
h=sin(wc*(n-tau))./(pi*(n-tau));
u=isnan(h);
[p,q]=find(u==1);
h(q)=wc/pi;
h(q)=0;
for i=((N+1)/2+1):1:N
h(i)=-1*h(i);
end
temp1=[];
temp2=[];
for w=-pi:0.001:pi;
[s,a]=firtype2(N,h,w);
temp1=[temp1 s];
temp2=[temp2 a];
end
figure(2)
subplot(3,3,1)
plot(-pi:0.001:pi,temp1)
subplot(3,3,2)
plot(-pi:0.001:pi,abs(temp1))
m=[];
p=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
p=[p angle(sum(h.*exp(-j*w*n)))];
end
subplot(3,3,3)
plot(-pi:0.001:pi,m)
subplot(3,3,4)
plot(-pi:0.001:pi,temp2)
subplot(3,3,5)
plot(-pi:0.001:pi,sign(temp1))
temp=sign(temp1);
temp3=(temp-1)*(-pi/2);
subplot(3,3,6)
plot(-pi:0.001:pi,temp2+temp3)
subplot(3,3,7)
plot(-pi:0.001:pi,p)
subplot(3,3,8)
plot(-pi:0.001:pi,cos(p))
subplot(3,3,9)
plot(-pi:0.001:pi,cos(temp2+temp3))
figure(5)
subplot(2,2,2)
zplane(h)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

86
3
Finite Impulse Response Filter (FIR Filter)
%Type 3: h(n)=h(N-1-n)
N=10;
wc=pi/2;
tau=(N-1)/2;
n=0:1:N-1;
h=sin(wc*(n-tau))./(pi*(n-tau));
u=isnan(h);
[p,q]=find(u==1);
h(q)=wc/pi;
temp1=[];
temp2=[];
for w=-pi:0.001:pi;
[s,a]=firtype3(N,h,w);
temp1=[temp1 s];
temp2=[temp2 a];
end
figure(3)
subplot(3,3,1)
plot(-pi:0.001:pi,temp1)
subplot(3,3,2)
plot(-pi:0.001:pi,abs(temp1))
m=[];
p=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
p=[p angle(sum(h.*exp(-j*w*n)))];
end
subplot(3,3,3)
plot(-pi:0.001:pi,m)
subplot(3,3,4)
plot(-pi:0.001:pi,temp2)
subplot(3,3,5)
plot(-pi:0.001:pi,sign(temp1))
temp=sign(temp1);
temp3=(temp-1)*(-pi/2);
subplot(3,3,6)
plot(-pi:0.001:pi,temp2+temp3)
subplot(3,3,7)
plot(-pi:0.001:pi,p)
subplot(3,3,8)
plot(-pi:0.001:pi,cos(p))
subplot(3,3,9)
plot(-pi:0.001:pi,cos(temp2+temp3))
figure(5)
subplot(2,2,3)
zplane(h)
%Type 4: h(n)=-h(N-1-n)
N=10;
wc=pi/2;
tau=(N-1)/2;

3.1 Demonstration of Four Types of FIR Filter
87
n=0:1:N-1;
h=sin(wc*(n-tau))./(pi*(n-tau));
u=isnan(h);
[p,q]=find(u==1);
h(q)=wc/pi;
for i=((N/2)+1):1:N
h(i)=-1*h(i);
end
temp1=[];
temp2=[];
for w=-pi:0.001:pi;
[s,a]=firtype4(N,h,w);
temp1=[temp1 s];
temp2=[temp2 a];
end
figure(4)
subplot(3,3,1)
plot(-pi:0.001:pi,temp1)
subplot(3,3,2)
plot(-pi:0.001:pi,abs(temp1))
m=[];
p=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
p=[p angle(sum(h.*exp(-j*w*n)))];
end
subplot(3,3,3)
plot(-pi:0.001:pi,m)
subplot(3,3,4)
plot(-pi:0.001:pi,temp2)
subplot(3,3,5)
plot(-pi:0.001:pi,sign(temp1))
temp=sign(temp1);
temp3=(temp-1)*(-pi/2);
subplot(3,3,6)
plot(-pi:0.001:pi,temp2+temp3)
subplot(3,3,7)
plot(-pi:0.001:pi,p)
subplot(3,3,8)
plot(-pi:0.001:pi,cos(p))
subplot(3,3,9)
plot(-pi:0.001:pi,cos(temp2+temp3))
figure(5)
subplot(2,2,4)
zplane(h)
%firtype1.m
function [s,a]=firtype1(N,h,w)
s=0;
tau=(N-1)/2;
for m=1:1:tau
s=s+2*h(m)*cos((tau-m+1)*w);
end
s=s+h(tau+1);
a=-tau*w;

88
3
Finite Impulse Response Filter (FIR Filter)
firtype2.m
function [s,a]=firtype2(N,h,w)
s=0;
tau=(N-1)/2;
for m=1:1:tau
s=s+2*h(m)*sin((tau-m+1)*w);
end
s=s+h(tau+1);
a=-tau*w+(pi/2);
firtype3.m
function [s,a]=firtype3(N,h,w)
s=0;
tau=(N-1)/2;
for m=1:1:(N/2)
s=s+2*h(m)*cos((tau-m+1)*w);
end
a=-tau*w;
firtype4.m
function [s,a]=firtype4(N,h,w)
s=0;
tau=(N-1)/2;
for m=1:1:(N/2)
s=s+2*h(m)*sin((tau-m+1)*w);
end
a=-tau*w+(pi/2);
%minmaxFIR.m
%Demonstration of minimum phase FIR filter
%and maximum phase FIR filter
z1=0.3+0.7j;
z2=1.2+1.4j;
z3=z1’;
z4=z2’;
%h=(z-z1)(z-z2)(z-z1’)(z-z2’)
h1=conv([1 -z1],[1 -z2]);
h2=conv(h1,[1 -z1’] );
h3=conv(h2,[1 -z2’] );
figure(1)
subplot(2,2,1)
zplane(h3,1)
h=h3;
mag=[];
phase=[];
n=0:1:length(h3)-1;
for w=-pi:0.001:pi;
mag=[mag abs(sum(h.*exp(-j*w*n)))];
phase=[phase angle(sum(h.*exp(-j*w*n)))];
end
figure(2)
subplot(4,2,1)
plot(-pi:0.001:pi,abs(mag)/max(abs(mag)))
subplot(4,2,2)
plot(-pi:0.001:pi,abs(phase))
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%h=(z-z1)(z-z1’)(z-1/z2’)(z-(1/z2’)’)
h1=conv([1 -z1],[1 -1/z2]);

3.1 Demonstration of Four Types of FIR Filter
89
h2=conv(h1,[1 -z1’] );
h3=conv(h2,[1 (-1/z2)’] );
h=h3;
figure(1)
subplot(2,2,2)
zplane(h3,1)
mag=[];
phase=[];
for w=-pi:0.001:pi;
mag=[mag abs(sum(h.*exp(-j*w*n)))];
phase=[phase angle(sum(h.*exp(-j*w*n)))];
end
figure(2)
subplot(4,2,3)
plot(-pi:0.001:pi,abs(mag)/max(abs(mag)))
subplot(4,2,4)
plot(-pi:0.001:pi,abs(phase))
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%h=(z-1/z1)(z-(1/z1’)’)(z-1/z2’)(z-(1/z2’)’)
h1=conv([1 -1/z1],[1 (-1/z1)’]);
h2=conv(h1,[1 -1/z2’] );
h3=conv(h2,[1 (-1/z2’)’] );
h=h3;
figure(1)
subplot(2,2,3)
zplane(h3,1)
mag=[];
phase=[];
for w=-pi:0.001:pi;
mag=[mag abs(sum(h.*exp(-j*w*n)))];
phase=[phase angle(sum(h.*exp(-j*w*n)))];
end
figure(2)
subplot(4,2,5)
plot(-pi:0.001:pi,abs(mag)/max(abs(mag)))
subplot(4,2,6)
plot(-pi:0.001:pi,abs(phase))
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%h=(z-1/z1’)(z-(1/z1’)’)(z-z2)(z-z2’)
h1=conv([1 -1/z1’],[1 (1/-z1’)’]);
h2=conv(h1,[1 -z2] );
h3=conv(h2,[1 -z2’] );
h=h3;
figure(1)
subplot(2,2,4)
zplane(h3,1)
mag=[];
phase=[];
for w=-pi:0.001:pi;
mag=[mag abs(sum(h.*exp(-j*w*n)))];
phase=[phase angle(sum(h.*exp(-j*w*n)))];
end
figure(2)
subplot(4,2,7)
plot(-pi:0.001:pi,abs(mag)/max(abs(mag)))
subplot(4,2,8)
plot(-pi:0.001:pi,abs(phase))

90
3
Finite Impulse Response Filter (FIR Filter)
3.2
Design of Linear Phase FIR Filter-Windowing
Technique
3.2.1
Design of Low-Pass Filter
Non-causal IIR ﬁlter is obtained by computing inverse discrete Fourier transforma-
tion (IDFT) of the transfer function Hd(e jwd) = 1, for −wc ≤wd ≤wc, 0, otherwise.
hd(n) for n = · · · , −2, −1, 0, 1, 2, · · · is computed as follows.
hd(n) = 1
2π
 π
−π
Hd(e jwd)e jwdndwd
(3.9)
= 1
2π
 wc
−wc
e jwdndwd = 1
2π (e jwcn
jn
−e−jwcn
jn
)
(3.10)
= 1
2π
2 jsin(wcn)
jn
= 1
2π
2sin(wcn)
n
= sin(wcn)
πn
(3.11)
FIR ﬁlter impulse response (h(n)) is obtained by truncating the impulse response of
the IIR ﬁlter (hd(n) for −10 ≤n ≤10). This is obtained by multiplying IIR ﬁlter
with the rectangular window w(n) = 1 for −10 ≤n ≤10 and 0, otherwise. The
truncated IIR ﬁlter impulse response and the corresponding magnitude and phase
response is illustrated in Fig.3.9.
h(n) = hd(n)w(n)
(3.12)
⇒H(e jwd) = Hd(e jwd) ∗W(e jwd)
(3.13)
Figure3.10 demonstrates that the ripples are introduced in the transfer function
H(e jwd) due to the convolution of Hd(e jwd) and W(e jwd). The graph is plotted for
−π ≤wd ≤π and the amplitude is normalized to 1. The impulse response h(n) is
made causal (hc(n)) by shifting the impulse response sequence toward right, such
that is zero for n < 0. From (3.11), for N = 21, causal impulse response hc(n) is
given as the
hc(n) = sin(wc(n −(N−1)
2
))
π(n −(N−1)
2
)
(3.14)
This forms the Type 1 FIR ﬁlter as described in the Sect.3.1. h(n) can be viewed
as sampling h(t) = sin(wct)
wct
for the duration −(N−1)Ts
2
≤t ≤(N−1)Ts
2
, with N as odd.
It is made causal by shifting the impulse response toward right. The method of
obtaining Type 1 and Type 3 FIR ﬁlter by sampling the impulse response of the
truncated FIR ﬁlter is illustrated in Fig.3.11. The corresponding magnitude and
phase response is given in Fig.3.12. Similarly, the method of obtaining Type 2,

3.2 Design of Linear Phase FIR Filter-Windowing Technique
91
Fig. 3.9 a Impulse response of the truncated ﬁlter. b Transfer function of the truncated ﬁlter. c
Magnitude response of the truncated ﬁlter. d Cosine of the phase response of the truncated ﬁlter.
(It is noted that the value is 1, if the sign of the transfer function is positive and the value is −1
corresponding to the case when the transfer functional value is negative.)
Fig. 3.10 a Transfer function of the rectangular pulse W(e jwd ). b Transfer function of the ideal
low pass ﬁlter Hd(e jwd ). c Magnitude response of the truncated ﬁlter H(e jwd )
Type 4 FIR ﬁlter by modifying the samples obtained from truncated h(t), satisfying
the h(n) = −h(N −n −1) is illustrated in Fig.3.13. The corresponding magnitude
and phase response is given in Fig.3.14. Note that the magnitude response of Type
2 and Type 4 ﬁlter is of High pass in nature.

92
3
Finite Impulse Response Filter (FIR Filter)
%effectoftruncation.m
%Demonstration of magnitude response of the truncated filter
n=-10:1:10;
wc=pi/2;
h=sin(wc*n)./(pi*n);
h(11)=wc/pi;
figure
subplot(2,2,1)
stem(n,h)
title(’Impulse response of the truncated filter’)
m1=[];
m2=[];
p=[];
for w=-pi:0.001:pi;
m1=[m1 sum(h.*exp(-j*w*n))];
m2=[m2 abs(sum(h.*exp(-j*w*n)))];
p=[p angle(sum(h.*exp(-j*w*n)))];
end
temp=sign(m1);
w=-pi:0.001:pi
subplot(2,2,2)
plot(w,real(m1))
title(’Transfer function of the truncated filter’)
subplot(2,2,3)
plot(w,real(m2))
title(’Magnitude response of the truncated filter’)
subplot(2,2,4)
plot(w,cos(p))
title(’Cosine of the phase response of the truncated filter’)
energy=sum(h.ˆ2);
rw=sqrt(energy/21);
rw=ones(1,21)*rw;
tfrw=[];
for w=-2*pi:0.001:2*pi;
tfrw=[tfrw sum(rw.*exp(-j*w*n))];
end
s1=-2*pi:0.001:(-3*pi/2);
s2=s1(length(s1))+0.001:0.001:(-pi/2);
s3=s2(length(s2))+0.001:0.001:pi/2;
s4=s3(length(s3))+0.001:0.001:(3*pi/2);
s5=s4(length(s4))+0.001:0.001:2*pi;
Hdw=[ones(1,length(s1)) zeros(1,length(s2)) ones(1,length(s3)) ...
zeros(1,length(s4)) ones(1,length(s5))];
res=conv(real(tfrw),Hdw);
res=(res/max(res))*21;
figure
subplot(3,1,1)
L1=length(-2*pi:0.001:2*pi); L2=length(-2*pi:0.001:-pi-0.001);
plot(-pi:0.001:pi,
real(tfrw(L2+1:1:L1-L2-1)/max(tfrw(L2+1:1:L1-L2-1))));
title(’Transfer function of the rectangular pulse W(eˆ{jw_{d}})’)
subplot(3,1,2) plot(-pi:0.001:pi, Hdw(L2+1:1:L1-L2-1));
title(’Transfer function of the ideal low-pass filter H_{d}(eˆ{jw_{d}})’)

3.2 Design of Linear Phase FIR Filter-Windowing Technique
93
Fig. 3.11 a Impulse response of the truncated Low-pass ﬁlter (with the speciﬁc cutoff frequency)
with the samples shown corresponding to half the sampling time. b Illustration of samples corre-
sponding to the integer multiples of the sampling time (red) and integer multiples of the half the
sampling time (blue). c Red samples are collected to obtain the impulse response of the type 1 FIR
ﬁlter. d Blue samples are collected to obtain the impulse response of the corresponding type 3 FIR
ﬁlter
subplot(3,1,3)
L3=length(-4*pi:0.001:4*pi);
L4=length(-4*pi:0.001:-pi-0.001);
plot(-pi:0.001:pi, res(L4+1:1:L3-L4-1)/max(res(L4+1:1:L3-L4-1)));
title(’Magnitude response of the truncated filter H(eˆ{jw_{d}}))
%truncimpLPF2FIR1FIR3.m
%Illustration of obtaining the filter ...
%coefficients for FIR 1 and FIR 3 filter from ...
%the truncated impulse response of the ideal Low-pass filter
t=-10:0.01:10;
wc=pi/2;
ht=sin(wc*t)./(pi*t);
ht(1001)=wc/pi;
figure
subplot(4,1,1)
plot(t,ht)
hold on
n1=-10:0.5:10;
wc=pi/2;
h=sin(wc*n1)./(pi*n1);
h(21)=wc/pi;
hold on
stem(n1,h)
subplot(4,1,2)
stem(n1,h)
hold on

94
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.12 Magnitude and phase response of the Impulse response mentioned in Fig.3.11c, d.
Subplot a, b corresponds to Type 1 FIR ﬁlter. Subplot c, d corresponds to Type 3 FIR ﬁlter
n2=n1(1:2:41);
stem(n2,h(1:2:41),’r’)
subplot(4,1,3)
stem(0:1:20,h(1:2:41),’r’)
subplot(4,1,4)
stem(0:1:19,h(2:2:41))
h1fir=h(1:2:41);
h3fir=h(2:2:41);
n=0:1:length(h1fir)-1;
mag1=[];
phase1=[];
for w=-pi:0.001:pi;
mag1=[mag1 abs(sum(h1fir.*exp(-j*w*n)))];
phase1=[phase1 angle(sum(h1fir.*exp(-j*w*n)))];
end
n=0:1:length(h3fir)-1;
mag2=[];
phase2=[];
for w=-pi:0.001:pi;
mag2=[mag2 abs(sum(h3fir.*exp(-j*w*n)))];
phase2=[phase2 angle(sum(h3fir.*exp(-j*w*n)))];
end
figure
subplot(2,2,1)
plot(-pi:0.001:pi,mag1)
subplot(2,2,2)
plot(-pi:0.001:pi,phase1)
subplot(2,2,3)
plot(-pi:0.001:pi,mag2)
subplot(2,2,4)
plot(-pi:0.001:pi,phase2)

3.2 Design of Linear Phase FIR Filter-Windowing Technique
95
Fig. 3.13 a Impulse response of the truncated Low-pass ﬁlter (with the speciﬁc cutoff frequency)
with the samples shown corresponding to half the sampling time. b Illustration of samples corre-
sponding to the integer multiples of the sampling time (red) and integer multiples of the half the
sampling time (blue). c Red samples are collected to obtain the impulse response of the type 2 FIR
ﬁlter. d Blue samples are collected to obtain the impulse response of the corresponding type 4 FIR
ﬁlter
%truncimpLPF2FIR2FIR4.m
%Illustration of obtaining the filter ...
%coefficients for FIR 2 and FIR 4 filter from ...
%the truncated impulse response of the ideal Low-pass filter
t=-10:0.01:10;
wc=pi/2;
ht=sin(wc*t)./(pi*t);
ht(1001)=wc/pi;
figure
subplot(4,1,1)
plot(t,ht)
hold on
n1=-10:0.5:10;
wc=pi/2;
h=sin(wc*n1)./(pi*n1);
h(21)=wc/pi;
hold on
stem(n1,h)
subplot(4,1,2)
stem(n1,h)
hold on
n2=n1(1:2:41);
stem(n2,h(1:2:41),’r’)
%Type 2 filter
fir2h=h(1:2:41);
fir2h(11)=0;
for i=12:1:21
fir2h(i)=-fir2h(21-i+1);
end
%Type 4 filter
fir4h=h(2:2:41);

96
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.14 Magnitude and phase response of the Impulse response mentioned in Fig.3.13c, d.
Subplot a, b corresponds to Type 2 FIR ﬁlter. Subplot c, d corresponds to Type 4 FIR ﬁlter
for i=11:1:20
fir4h(i)=-fir4h(20-i+1);
end
subplot(4,1,3)
stem(0:1:20,fir2h,’r’)
subplot(4,1,4)
stem(0:1:19,fir4h,’b’)
n=0:1:length(fir2h)-1;
mag1=[];
phase1=[];
for w=-pi:0.001:pi;
mag1=[mag1 abs(sum(fir2h.*exp(-j*w*n)))];
phase1=[phase1 angle(sum(fir2h.*exp(-j*w*n)))];
end
n=0:1:length(fir4h)-1;
mag2=[];
phase2=[];
for w=-pi:0.001:pi;
mag2=[mag2 abs(sum(fir4h.*exp(-j*w*n)))];
phase2=[phase2 angle(sum(fir4h.*exp(-j*w*n)))];
end
figure
subplot(2,2,1)
plot(-pi:0.001:pi,mag1)
subplot(2,2,2)
plot(-pi:0.001:pi,phase1)
subplot(2,2,3)
plot(-pi:0.001:pi,mag2)
subplot(2,2,4)
plot(-pi:0.001:pi,phase2)

3.2 Design of Linear Phase FIR Filter-Windowing Technique
97
3.2.2
Design of High-Pass Filter
The ideal magnitude response of the High-pass ﬁlter is obtained by shifting the plot
of the magnitude response of the ideal low-pass ﬁlter (refer Fig.3.9b, say HL P(e jwd))
toward right by π. This is obtained by replacing wd by wd −π in HL P(e jwd) of the
low-pass ﬁlter as follows.
HL P(e jwd) = h(0) + h(1)e−jwd + h(2)e−j2wd + · · · + h(N −1)e−j(N−1)wd
HH P(e jwd) = HL P(e j(wd−π))
= h(0) −h(1)e−jwd + h(2)e−j2wd + · · · −h(N −1)e−j(N−1)wd
⇒h H P(n) = (−1)nh(n)
where, h(n) =
sin(wc(n−(N−1)
2
))
π(n−(N−1)
2
)
and it satisﬁes h H P(n) = −h H P(N −n −1). This
can also be obtained by subtracting the impulse response of two low-pass ﬁlter
sin(π(n−(N−1)
2
))
π(n−(N−1)
2
)
(with cutoff frequency π radians) and
sin(wc(n−(N−1)
2
))
π(n−(N−1)
2
)
(with cutoff fre-
quency wc radians). Hence the impulse response of the high-pass ﬁlter is given as
the following.
(sin(π(n −(N−1)
2
))
π(n −(N−1)
2
)
) −(sin(wc(n −(N−1)
2
))
π(n −(N−1)
2
)
)
(3.15)
As the phase response of the individual low-pass ﬁlters are linear in nature, the
phase response of the high-pass ﬁlter constructed using the low-pass ﬁlter is also
linear. Refer Fig.3.16 to see the magnitude and phase response of HPF with cutoff
frequency π
2 obtained using the Type 1 and Type 3 LPF. It is observed from the ﬁgure
that number of zero crossings in the magnitude response is larger for the Type 1 LPF
based design.
3.2.3
Design of Band Pass and Band Reject Filter
1. Band pass ﬁlter with pass band frequencies ranging from w1 to w2 (with w1 ≤
w2) is obtained as the cascade connection of two ﬁlters (refer Fig.3.15b), i.e.,
Low-pass ﬁlter with cutoff w2 radians, followed by High pass ﬁlter with cutoff
frequency w1 radians.
2. Similarly, Band reject ﬁlter with the stop band frequencies ranging from w1tow2
(withw1 ≤w2)isobtainedastheparallelrealizationoftwoﬁlters(referFig.3.15a),
i.e., Low-pass ﬁlter with cutoff w1 radians, and the High-pass ﬁlter with cutoff
frequency w2 radians.

98
3
Finite Impulse Response Filter (FIR Filter)
3. Figure3.17a illustrates the typical magnitude response of the band pass ﬁlter
obtained as the cascade of Type 1 LPF and Type 1 HPF. Figure3.17b illustrates
the typical magnitude response of the band pass ﬁlter obtained as the cascade
of Type 3 LPF and Type 3 HPF. Figure3.17c illustrates the typical magnitude
response of the band pass ﬁlter obtained as the cascade of Type 3 LPF and Type
1 HPF. Finally Fig.3.17d illustrates the typical magnitude response of the band
pass ﬁlter obtained as the cascade of Type 1 LPF and Type 3 HPF. It is observed
that the number of zero crossings in the pass band of the band pass ﬁlter is larger
when the identical types are used for LPF and HPF.
4. Figure3.18a illustrates the typical magnitude response of the band reject ﬁlter
obtained as the parallel realization of Type 1 LPF and Type 1 HPF. Figure3.18b
illustrates the typical magnitude response of the band reject ﬁlter obtained as
the parallel realization of Type 3 LPF and Type 3 HPF. Figure3.18d illustrates
the typical magnitude response of the band reject ﬁlter obtained as the parallel
realization of Type 3 LPF and Type 1 HPF. Finally Fig.3.18c illustrates the typical
magnitude response of the band reject ﬁlter obtained as the parallel realization of
Type 1 LPF and Type 3 HPF. It is observed that the number of zero crossings in
the pass band of the band pass ﬁlter is larger when the identical types are used
for LPF and HPF.
5. The impulse response of the Band reject ﬁlter with stop band range from wc1 to
wc2 is given as
h Bandreject(n) = h1(n) + h2(n)
h1(n) = sin(wc1(n −(N−1)
2
))
π(n −(N−1)
2
)
h2(n) = sin(π(n −(N−1)
2
))
π(n −(N−1)
2
)
−sin(wc2(n −(N−1)
2
))
π(n −(N−1)
2
)
6. The impulse response of the Band pass ﬁlter with pass range wc1 to wc2, is given
as
h Bandpass = h1(n) ∗h2(n)
h1(n) = sin(π(n −(N−1)
2
))
π(n −(N−1)
2
)
−sin(wc2(n −(N−1)
2
))
π(n −(N−1)
2
)
h2(n) = sin(wc1(n −(N−1)
2
))
π(n −(N−1)
2
)

3.2 Design of Linear Phase FIR Filter-Windowing Technique
99
Fig. 3.15 a Block diagram to realize band reject ﬁlter. b Block diagram to realize band pass ﬁlter
Fig. 3.16 a Magnitude response of the HPF using Type 1 LPF. b Phase response of the HPF using
Type 1 LPF. c Magnitude response of the HPF using Type 3 LPF. d Phase response of the HPF
using Type 3 LPF
%HPFtype1.m
%HPF: Designed using Type 1 (h(n)=h(N-1-n), N->Odd LPF)
N=11;
wc=pi/2;
tau=(N-1)/2;
n=0:1:N-1;
h=sin(wc*(n-tau))./(pi*(n-tau));
u=isnan(h);
[p,q]=find(u==1);
h(q)=wc/pi;
h=((-1*ones(1,length(h))).ˆn).*h;
m=[];
p=[];
for w=-pi:0.001:pi;

100
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.17 a Magnitude response of the BPF (Cascade of Type 1 LPF and Type 1 HPF). b Magnitude
response of the BPF (Cascade of Type 3 LPF and Type 3 HPF). c Magnitude response of the BPF
(Cascade of Type 3 LPF and Type 1 HPF). d Magnitude response of the BPF (Cascade of Type 1
LPF and Type 3 HPF)
Fig. 3.18 a Magnitude response of the BRF (Cascade of Type 1 LPF and Type 1 HPF), b magnitude
response of the BRF (Cascade of Type 3 LPF and Type 3 HPF), c magnitude response of the BRF
(Cascade of Type 1 LPF and Type 3 HPF), d magnitude response of the BPF (Cascade of Type 3
LPF and Type 1 HPF)

3.2 Design of Linear Phase FIR Filter-Windowing Technique
101
m=[m abs(sum(h.*exp(-j*w*n)))];
p=[p angle(sum(h.*exp(-j*w*n)))];
end
figure
subplot(2,2,1)
plot(-pi:0.001:pi,m)
subplot(2,2,2)
plot(-pi:0.001:pi,p)
%HPFtype3.m
%HPF: Designed using Type 3 LPF (h(n)=h(N-1-n), N->Even)
N=10;
wc=pi/2;
tau=(N-1)/2;
n=0:1:N-1;
h=sin(wc*(n-tau))./(pi*(n-tau));
u=isnan(h);
[p,q]=find(u==1);
h(q)=wc/pi;
h=((-1*ones(1,length(h))).ˆn).*h;
m=[];
p=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
p=[p angle(sum(h.*exp(-j*w*n)))];
end
subplot(2,2,3)
plot(-pi:0.001:pi,m)
subplot(2,2,4)
plot(-pi:0.001:pi,p)
%BPFT1LPFT1HPF.m
% BPF: Designed as the cascade of Type 1 LPF (h(n)=h(N-1-n),
%N->Odd) and
HPF (obtained using Type 1 LPF)with
%pass band between pi/8 and 3*pi/8
N=11;
wc1=pi-pi/8;
wc2=3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc2/pi;
n=0:1:N-1;
h2=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc1/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;
h=conv(h1,h2);
n=0:1:length(h)-1;
m=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
end
figure

102
3
Finite Impulse Response Filter (FIR Filter)
subplot(2,2,1)
plot(-pi:0.001:pi,m)
%BPFT3LPFT3HPF.m
%BPF: Designed as the cascade realization of Type 3 LPF
%(h(n)=h(N-1-n), N->Even) and HPF (obtained using Type 3 LPF)
%with pass band between pi/8 and 3*pi/8
N=10;
wc1=pi-pi/8;
wc2=3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc2/pi;
n=0:1:N-1;
h2=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc1/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;
h=conv(h1,h2);
m=[];
n=0:1:length(h)-1;
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
end
subplot(2,2,2)
plot(-pi:0.001:pi,m)
%BPFT3LPFT1HPF.m
%BPF: Designed as the cascade realization of Type 3 LPF
%(h(n)=h(N-1-n), N->Even) and HPF (obtained using
%Type 1 LPF (h(n)=h(N-1-n), N->Odd) )
%with pass band between pi/8 and 3*pi/8
N=10;
wc1=pi-pi/8;
wc2=3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc2/pi;
N=11;
n=0:1:N-1;
h2=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc1/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;
h=conv(h1,h2);
m=[];
n=0:1:length(h)-1;
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];

3.2 Design of Linear Phase FIR Filter-Windowing Technique
103
end
subplot(2,2,3)
plot(-pi:0.001:pi,m)
%BPFT1LPFT3HPF.m
%BPF: Designed as the cascade realization of Type 1 LPF (h(n)=h(N-1-n),
N->Odd) and
% HPF (obtained using Type 3 LPF (h(n)=h(N-1-n), N->Even) )
%with pass band between pi/8 and 3*pi/8
N=11;
wc1=pi-pi/8;
wc2=3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc2/pi;
N=10;
n=0:1:N-1;
h2=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc1/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;
h=conv(h1,h2);
m=[];
n=0:1:length(h)-1;
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
end
subplot(2,2,4)
plot(-pi:0.001:pi,m)
%BRFT1LPFT1HPF.m
%BRF: Designed as the parallel realization of Type 1
%LPF (h(n)=h(N-1-n), N->Odd) and
% HPF (obtained using Type 1 LPF) with
%stop band between pi/8 and 3*pi/8
N=11;
wc1=pi/8;
wc2=3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc1/pi;
n=0:1:N-1;
h2=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc2/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;
h=h1+h2;
m=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];

104
3
Finite Impulse Response Filter (FIR Filter)
end
figure
subplot(2,2,1)
plot(-pi:0.001:pi,m)
%BRFT3LPFT3HPF.m
%BRF: Designed as the parallel realization of Type 1
%LPF (h(n)=h(N-1-n), N->Even) and
% HPF (obtained using Type 3 LPF h(n)=h(N-1-n), N->Even)
% with stop band between pi/8 and 3*pi/8
N=10;
wc1=pi/8;
wc2=3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc1/pi;
n=0:1:N-1;
h2=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc2/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;
m=[];
n=0:1:length(h)-1;
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
end
subplot(2,2,2)
plot(-pi:0.001:pi,m)
%BRFT1LPFT3HPF.m
%BRF: Designed as the parallel realization of Type 1 LPF
%(h(n)=h(N-1-n), N->Odd) and HPF (obtained using Type 3 LPF)
%with stop band between pi/8 and 3*pi/8
N=11;
wc1=pi/8;
wc2=3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc1/pi;
N=10;
n=0:1:N-1;
h2=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc2/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;
h=h1+[h2 0];
m=[];
n=0:1:length(h)-1;
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];

3.2 Design of Linear Phase FIR Filter-Windowing Technique
105
end
subplot(2,2,3)
plot(-pi:0.001:pi,m)
%BRFT3LPFT1HPF.m
%BRF: Designed as the parallel realization of Type 3 LPF
%(h(n)=h(N-1-n), N->Even) and HPF (obtained using Type 1 LPF
%h(n)=h(N-1-n), N->Odd) with stop band between pi/8 and 3*pi/8
N=10;
wc1=pi/8;
wc2=3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc1/pi;
N=11;
n=0:1:N-1;
h2=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc2/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;
h=[h1 0]+h2;
m=[];
n=0:1:length(h)-1;
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
end
subplot(2,2,4)
plot(-pi:0.001:pi,m)
3.2.4
Windows Used to Circumvent Ripples in the Magnitude
Response
Truncated FIR ﬁlter is viewed as the product of the impulse response of the ideal
FIR ﬁlter with the rectangular window. We also have observed that the ripples are
introduced in the magnitude response of the truncated FIR ﬁlter (LPF, HPF, BPF and
BRF). This is due to the convolution of ideal magnitude response and the magnitude
response of the rectangular window (refer Fig.3.10 for LPF). This is circumvented
using other types of windows w(n) (for the causal FIR ﬁlter obtained by shifting
the noncausal impulse response toward right) as listed below (refer Fig.3.19). The
magnitude response (with N = 101) of the Low-pass ﬁlters, High-pass ﬁlter and Band
pass ﬁlters and the Band reject ﬁlters are shown in the Figs.3.21, 3.22, 3.23 and 3.24
respectively. It is seen from the ﬁgure that ripples in the magnitude response gets
reduced if windowing (other than rectangular window) is used. Figure3.20 shows
the magnitude response for various windows with N = 101.

106
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.19 Window functional values a Rectangular window. b Hamming window. c Hanning win-
dow. d Blackmannwindow1. e Blackmannwindow2. f Barlettwindow
• Rectangular window: w(n) = 1 for 0 ≤n ≤N −1
• Hamming window: w(n) = 0.54 −0.46cos( 2πn
N ) for 0 ≤n ≤N −1
• Hanning window: w(n) = 0.5 −0.5cos( 2πn
N ) for 0 ≤n ≤N −1
• Blackmann window 1: h(n) = 0.423 −0.498cos( 2πn
N ) + 0.079cos( 4πn
N ) for 0 ≤
n ≤N −1
• Blackmann window 2: h(n) = 0.359 −0.488cos( 2πn
N ) + 0.141cos( 4πn
N ) −0.012
cos( 6πn
N ) for 0 ≤n ≤N −1
• Barlett window: w(n) = 1 −
2|n−N−1
2 |
(N−1) , for 0 ≤n ≤N −1
%reduceripplesLPF.m
%Illustration of usage of window in reducing the ripples in Low-pass filter
N=101;
wc=pi/4;
tau=(N-1)/2;
n=0:1:N-1;
h=sin(wc*(n-tau))./(pi*(n-tau));
u=isnan(h);
[p,q]=find(u==1);
h(q)=wc/pi;
m=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
end
%Windowing
rectwindow=ones(1,N);
hammingwindow= 0.54-0.46*cos(2*pi*n/N);
hanningwindow= 0.5-0.5*cos(2*pi*n/N);
blackmannwindow1= 0.423-0.498*cos(2*pi*n/N)+...
0.079*cos(4*pi*n/N);

3.2 Design of Linear Phase FIR Filter-Windowing Technique
107
Fig. 3.20 Magnitude response of the Window function corresponding to Fig.3.19 a Rectangular
window. b Hamming window. c Hanning window. d Blackmannwindow1. e Blackmannwindow2.
f Barlettwindow
Fig. 3.21 Magnitude response of the corresponding (refer Fig.3.20) low-pass ﬁlters (with cutoff
frequency π
4 ) using a Rectangular window, b Hamming window, c Hanning window, d Blackman-
nwindow1, e Blackmannwindow2, f Barlettwindow

108
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.22 Magnitude response of the corresponding (refer Fig.3.20) high-pass ﬁlter (with cutoff
frequency π
2 ) using a Rectangular window, b Hamming window, c Hanning window, d Blackman-
nwindow1, e Blackmannwindow2, f Barlettwindow
Fig. 3.23 Magnitude response of the corresponding (refer Fig.3.20) band pass ﬁlter (with pass
band range from π
8 to 3π
8 ) using a Rectangular window, b Hamming window, c Hanning window,
d Blackmannwindow1, e Blackmannwindow2, f Barlettwindow

3.2 Design of Linear Phase FIR Filter-Windowing Technique
109
Fig. 3.24 Magnitude response of the corresponding (refer Fig.3.20) band reject ﬁlter (with stop
band range from π
8 to 3π
8 ) using a Rectangular window, b Hamming window, c Hanning window,
d Blackmannwindow1, e Blackmannwindow2, f Barlettwindow
blackmannwindow2= 0.359-0.488*cos(2*pi*n/N)+...
0.141*cos(4*pi*n/N)-0.012*cos(6*pi*n/N);
barlettwindow=1-2*abs((n-(N-1)/2))/(N-1);
%Magnitude response of various windows
Mrect=[];
Mhamm=[];
Mhann=[];
Mblack1=[];
Mblack2=[];
Mbarlett=[];
for w=-pi:0.001:pi;
Mrect=[Mrect abs(sum(rectwindow.*exp(-j*w*n)))];
Mhamm=[Mhamm abs(sum(hammingwindow.*exp(-j*w*n)))];
Mhann=[Mhann abs(sum(hanningwindow.*exp(-j*w*n)))];
Mblack1=[Mblack1 abs(sum(blackmannwindow1.*exp(-j*w*n)))];
Mblack2=[Mblack2 abs(sum(blackmannwindow2.*exp(-j*w*n)))];
Mbarlett=[Mbarlett abs(sum(barlettwindow.*exp(-j*w*n)))];
end
figure
subplot(3,2,1)
plot(rectwindow);
subplot(3,2,2)
plot(hammingwindow);
subplot(3,2,3)
plot(hanningwindow);
subplot(3,2,4)
plot(blackmannwindow1);
subplot(3,2,5)
plot(blackmannwindow2);
subplot(3,2,6)
plot(barlettwindow);

110
3
Finite Impulse Response Filter (FIR Filter)
figure
subplot(3,2,1)
plot(-pi:0.001:pi,Mrect);
subplot(3,2,2)
plot(-pi:0.001:pi,Mhamm);
subplot(3,2,3)
plot(-pi:0.001:pi,Mhann);
subplot(3,2,4)
plot(-pi:0.001:pi,Mblack1);
subplot(3,2,5)
plot(-pi:0.001:pi,Mblack2);
subplot(3,2,6)
plot(-pi:0.001:pi,Mbarlett);
hamm=h.*hammingwindow;
hann=h.*hammingwindow;
black1=h.*blackmannwindow1;
black2=h.*blackmannwindow2;
barlett=h.*barlettwindow;
mhamm=[];
mhann=[];
mblack1=[];
mblack2=[];
mbarlett=[];
for w=-pi:0.001:pi;
mhamm=[mhamm abs(sum(hamm.*exp(-j*w*n)))];
mhann=[mhann abs(sum(hann.*exp(-j*w*n)))];
mblack1=[mblack1 abs(sum(black1.*exp(-j*w*n)))];
mblack2=[mblack2 abs(sum(black2.*exp(-j*w*n)))];
mbarlett=[mbarlett abs(sum(barlett.*exp(-j*w*n)))];
end
figure
subplot(3,2,1)
plot(-pi:0.001:pi,m);
subplot(3,2,2)
plot(-pi:0.001:pi,mhamm);
subplot(3,2,3)
plot(-pi:0.001:pi,mhann);
subplot(3,2,4)
plot(-pi:0.001:pi,mblack1);
subplot(3,2,5)
plot(-pi:0.001:pi,mblack2);
subplot(3,2,6)
plot(-pi:0.001:pi,mbarlett);
%reduceripplesLPF.m
%Illustration of usage of window in
%reducing the ripples in High-pass filter
N=101;
wc=pi/2;
tau=(N-1)/2;
n=0:1:N-1;
h=sin(wc*(n-tau))./(pi*(n-tau));
u=isnan(h);
[p,q]=find(u==1);
h(q)=wc/pi;
h=((-1*ones(1,length(h))).ˆn).*h;

3.2 Design of Linear Phase FIR Filter-Windowing Technique
111
hamm=h.*hammingwindow;
hann=h.*hammingwindow;
black1=h.*blackmannwindow1;
black2=h.*blackmannwindow2;
barlett=h.*barlettwindow;
m=[];
mhamm=[];
mhann=[];
mblack1=[];
mblack2=[];
mbarlett=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
mhamm=[mhamm abs(sum(hamm.*exp(-j*w*n)))];
mhann=[mhann abs(sum(hann.*exp(-j*w*n)))];
mblack1=[mblack1 abs(sum(black1.*exp(-j*w*n)))];
mblack2=[mblack2 abs(sum(black2.*exp(-j*w*n)))];
mbarlett=[mbarlett abs(sum(barlett.*exp(-j*w*n)))];
end
figure
subplot(3,2,1)
plot(-pi:0.001:pi,m);
subplot(3,2,2)
plot(-pi:0.001:pi,mhamm);
subplot(3,2,3)
plot(-pi:0.001:pi,mhann);
subplot(3,2,4)
plot(-pi:0.001:pi,mblack1);
subplot(3,2,5)
plot(-pi:0.001:pi,mblack2);
subplot(3,2,6)
plot(-pi:0.001:pi,mbarlett);
%reduceripplesBPF.m
%Illustration of usage of window
%in reducing the ripples in Band pass
%filter between pi/8 and 3pi/8
N=101;
wc1=pi-pi/8;
wc2=3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc2/pi;
hammh1=h1.*hammingwindow;
hannh1=h1.*hammingwindow;
black1h1=h1.*blackmannwindow1;
black2h1=h1.*blackmannwindow2;
barletth1=h1.*barlettwindow;
N=101;
n=0:1:N-1;
h2=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc1/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;

112
3
Finite Impulse Response Filter (FIR Filter)
hammh2=h2.*hammingwindow;
hannh2=h2.*hammingwindow;
black1h2=h2.*blackmannwindow1;
black2h2=h2.*blackmannwindow2;
barletth2=h2.*barlettwindow;
h=conv(h1,h2);
hamm=conv(hammh1,hammh2);
hann=conv(hannh1,hannh2);
black1=conv(black1h1,black1h2);
black2=conv(black2h1,black2h2);
barlett=conv(barletth1,barletth2);
n=0:1:length(h)-1;
m=[];
mhamm=[];
mhann=[];
mblack1=[];
mblack2=[];
mbarlett=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
mhamm=[mhamm abs(sum(hamm.*exp(-j*w*n)))];
mhann=[mhann abs(sum(hann.*exp(-j*w*n)))];
mblack1=[mblack1 abs(sum(black1.*exp(-j*w*n)))];
mblack2=[mblack2 abs(sum(black2.*exp(-j*w*n)))];
mbarlett=[mbarlett abs(sum(barlett.*exp(-j*w*n)))];
end
figure
subplot(3,2,1)
plot(-pi:0.001:pi,m);
subplot(3,2,2)
plot(-pi:0.001:pi,mhamm);
subplot(3,2,3)
plot(-pi:0.001:pi,mhann);
subplot(3,2,4)
plot(-pi:0.001:pi,mblack1);
subplot(3,2,5)
plot(-pi:0.001:pi,mblack2);
subplot(3,2,6)
plot(-pi:0.001:pi,mbarlett);
%reduceripplesBRF.m
%Illustration of usage of window in
%reducing the ripples in Band reject
%filter between pi/8 and 3*pi/8
N=101;
wc1=pi/8;
wc2=pi-3*pi/8;
tau=(N-1)/2;
n=0:1:N-1;
h1=sin(wc1*(n-tau))./(pi*(n-tau));
u=isnan(h1);
[p,q]=find(u==1);
h1(q)=wc1/pi;
hammh1=h1.*hammingwindow;
hannh1=h1.*hammingwindow;
black1h1=h1.*blackmannwindow1;
black2h1=h1.*blackmannwindow2;
barletth1=h1.*barlettwindow;

3.2 Design of Linear Phase FIR Filter-Windowing Technique
113
N=101;
n=0:1:N-1;
h2=sin(wc2*(n-tau))./(pi*(n-tau));
u=isnan(h2);
[p,q]=find(u==1);
h2(q)=wc2/pi;
h2=((-1*ones(1,length(h2))).ˆn).*h2;
hammh2=h2.*hammingwindow;
hannh2=h2.*hammingwindow;
black1h2=h2.*blackmannwindow1;
black2h2=h2.*blackmannwindow2;
barletth2=h2.*barlettwindow;
h=h1+h2;
hamm=hammh1+hammh2;
hann=hannh1+hannh2;
black1=black1h1+black1h2;
black2=black2h1+black2h2;
barlett=barletth1+barletth2;
n=0:1:length(h)-1;
m=[];
mhamm=[];
mhann=[];
mblack1=[];
mblack2=[];
mbarlett=[];
for w=-pi:0.001:pi;
m=[m abs(sum(h.*exp(-j*w*n)))];
mhamm=[mhamm abs(sum(hamm.*exp(-j*w*n)))];
mhann=[mhann abs(sum(hann.*exp(-j*w*n)))];
mblack1=[mblack1 abs(sum(black1.*exp(-j*w*n)))];
mblack2=[mblack2 abs(sum(black2.*exp(-j*w*n)))];
mbarlett=[mbarlett abs(sum(barlett.*exp(-j*w*n)))];
end
figure
subplot(3,2,1)
plot(-pi:0.001:pi,m);
subplot(3,2,2)
plot(-pi:0.001:pi,mhamm);
subplot(3,2,3)
plot(-pi:0.001:pi,mhann);
subplot(3,2,4)
plot(-pi:0.001:pi,mblack1);
subplot(3,2,5)
plot(-pi:0.001:pi,mblack2);
subplot(3,2,6)
plot(-pi:0.001:pi,mbarlett);
3.3
FIR Filters that Have Identical Magnitude Response
LetthezerosoftheFIRﬁlter(H1(z))withrealcoefﬁcientsarerepresentedas z1, z∗
1, z2
and z∗
2. Note that the roots are available as conjugate the pair. The other three FIR
ﬁlter with real coefﬁcients that has identical magnitude response as that of the H1(z)

114
3
Finite Impulse Response Filter (FIR Filter)
are listed below.
Roots of H2(z) : z1, z∗
1, 1
z2
and 1
z∗
2
Roots of H3(z) : z1, z∗
1, 1
z2
and 1
z∗
2
Roots of H4(z) : 1
z1
, 1
z∗
1
, 1
z2
and 1
z∗
2
The typical example of the Transfer function of four FIR ﬁlters (with z1 = 1.5 +
1.5 j, z2 = 2.5 + 2.5 j) that havetheidentical magnituderesponseanddifferent phase
responses are listed below.
H1(z) = 1 −8z−132z−2 −60z−356.2500z−4
H2(z) = 1 −3.4z−1 + 5.78z−2 −2.04z−356.2500z−4
H3(z) = 1 −5.67z−1 + 16.05z−2 −9.44z−3 + 2.778z−4
H4(z) = 1 −8z−132z−2 −60z−356.2500z−4
The corresponding pole-zero plot are shown in the Fig.3.25. From Figs.3.26 and
3.27, it is observed that the magnitude response of the four FIR ﬁlters are identical
and the corresponding phase responses are distinct.
It is also observed that the magnitude response of the FIR ﬁlter with zero rz is
having identical magnitude response with that of the FIR ﬁlter with zero
1
r∗z (refer
Fig.3.28).
%identicalmagresfilters.m
r1=1.5+1.5j; r2=2.5+2.5j;
h1=[r1 r1’ r2 r2’];POLY1=poly(h1);
figure(1)
subplot(2,2,1)
zplane(POLY1,1)
figure(2)
subplot(2,2,1)
plot(abs(fft(POLY1,1000)))
figure(3)
subplot(2,2,1)
plot(angle(fft(POLY1,1000)))
h2=[r1 r1’ 1/r2 1/r2’];
POLY2=poly(h2);
roots(POLY2)
figure(1)
subplot(2,2,2)
zplane(POLY2,1)
figure(2)
subplot(2,2,2)
plot(abs(fft(POLY2,1000)))
figure(3)

3.3 FIR Filters that Have Identical Magnitude Response
115
Fig. 3.25 Pole-zero plot of four FIR ﬁlters with real coefﬁcient that have identical magnitude
response
subplot(2,2,2)
plot(angle(fft(POLY2,1000)))
h3=[1/r1 1/r1’ r2 r2’];
POLY3=poly(h3);
figure(1)
subplot(2,2,3)
zplane(POLY3,1)
figure(2)
subplot(2,2,3)
plot(abs(fft(POLY3,1000)))
figure(3)
subplot(2,2,3)
plot(angle(fft(POLY3,1000)))
h4=[1/r1 1/r1’ 1/r2 1/r2’];
POLY4=poly(h4);
figure(1)
subplot(2,2,4)
zplane(POLY4,1)
figure(2)
subplot(2,2,4)
plot(abs(fft(POLY4,1000)))
figure(3)
subplot(2,2,4)
plot(angle(fft(POLY4,1000)))

116
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.26 The corresponding magnitude response of the four FIR ﬁlters (refer Fig.3.25)
Fig. 3.27 The corresponding phase response of the four FIR ﬁlters (refer Fig.3.25)
It is seen from the Fig.3.28d (H4(z)), that all the zeros lie within the unit circle.
This corresponds to minimum phase ﬁlter. Also from Fig.3.28a (H1(z)), that all
the zeros lie outside the unit circle. This corresponds to maximum phase ﬁlter. The
transfer function H1(z) (min-phase) and H2(z) (max-phase) are related using the all
pass ﬁlter Hallpass(z) as described below.
H2(z) = H1(z)Hallpass(z)
(3.16)

3.3 FIR Filters that Have Identical Magnitude Response
117
Fig. 3.28 a Pole-zero plot with zero at 2 + 2 j, b Corresponding magnitude response, c Pole-zero
plot with zero at
1
2+2 j , d Corresponding magnitude response
The pole-zero plot of the All pass ﬁlter, Minimum phase ﬁlter and the Maximum
phase ﬁlter are given in the Fig.3.29 and the corresponding magnitude response is
given in Fig.3.30.
r1=1.5+1.5j; r2=2.5+2.5j;
h=[r1 r1’ r2 r2’];
APFzeros=[1/r1 1/r1’ 1/r2 1/r2’];
APFpoles=[r1 r1’ r2 r2’];
POLY1NUM=poly(APFpoles);
POLY1DEN=poly(APFzeros);
figure(1)
subplot(1,3,2)
zplane(POLY1NUM,POLY1DEN)
figure(2)
subplot(1,3,2)
[H,W]=freqz(POLY1NUM,POLY1DEN);
plot(W,abs(H))
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
h4=[1/r1 1/r1’ 1/r2 1/r2’];
POLY4=poly(h4);
figure(1)
subplot(1,3,3)
zplane(POLY4,1)
figure(2)

118
3
Finite Impulse Response Filter (FIR Filter)
Fig. 3.29 Pole zero plot: a maximum phase ﬁlter, b all pass ﬁlter, c minimum phase ﬁlter
Fig. 3.30 Magnitude response corresponding to Fig.3.29 a maximum phase ﬁlter, b all pass ﬁlter,
c minimum phase ﬁlter

3.3 FIR Filters that Have Identical Magnitude Response
119
subplot(1,3,3)
[H,W]=freqz(POLY4,1);
plot(W,abs(H))
%%%%%%%%%%%%%%%%%%%%%%%%%%%
h1=[r1 r1’ r2 r2’];
POLY1=poly(h1);
figure(1)
subplot(1,3,1)
zplane(POLY1,1)
figure(2)
subplot(1,3,1)
[H,W]=freqz(POLY1,1);
plot(W,abs(H))
%%%%%%%%%%%%%%%%%%%%%%%%%%

Chapter 4
Multirate Digital Signal Processing
4.1
Sampling Rate Conversion by the Factor M
N
Let the band limited signal x(t) is sampled with the sampling frequency Fs to
obtain the sequence x(n). The method of getting the new sequence yn obtained by
sampling the signal x(t) with sampling frequency Fsnew = M
N Fs is called sampling
rate conversion. This is done by the following.
4.1.1
Upsampling (with N = 1)
Let the sequence x(n) be represented as [x(0) x(1) x(2) x(3) x(4) x(5) x(6) · · · ].
The output sequence after up sampling is given by
y = [x(0) 0 x(1) 0 x(2) 0 x(3) 0 x(4) 0 x(5) 0 x(6) · · · ]. Let the z-transformation
of the sequence x(n) be represented as X(z). The z-transformation of the sequence
y(n) is obtained as follows:
X(z) = x(0) + x(1)z−1 + x(2)z−2 + x(3)z−3 + x(4)z−4 + x(5)z−5 + x(6)z−6 · · ·
Y(z) = y(0) + y(1)z−2 + y(2)z−2 + y(3)z−3 + y(4)z−4 + y(5)z−5 · · ·
⇒Y(z) = x(0) + 0z−1 + x(1)z−2 + 0z−3 + x(2)z−4 + 0z−5 + x(3)z−6 + · · ·
⇒Y(z) = X(z2).
In general, the z-transformation of the Y(z) with arbitrary M with N = 1 is given
as Y(z) = X(zM).
© Springer International Publishing AG 2018
E.S. Gopi, Multi-Disciplinary Digital Signal Processing,
DOI 10.1007/978-3-319-57430-1_4
121

122
4
Multirate Digital Signal Processing
4.1.2
Downsampling (with M = 1)
Let the sequence x(n) be represented as [x(0) x(1) x(2) x(3) x(4) x(5) x(6) · · · ].
The output sequence after down sampling is given by y(n) = [x(0) x(2) x(4) x(6) ].
Let the z-transformation of x(n) is X(z) and the z-transformation of the sequence
y(n) is computed as follows.
Y(z) = y(0) + y(1)z−1 + y(2)z−2 + y(3)z−3 + y(4)z−4 + y(5)z−5 + y(6)z−6 + y(7)z−7 + · · ·
⇒Y(z) = x(0) + x(2)z−1 + x(4)z−2 + x(6)z−3 + x(8)z−4 + x(10)z−5 + x(12)z−6 + x(14)z−6 · · ·
Consider the new sequence w(n) = x(n)z(n), where z(n) = [1 · · · 0 · · · 1 · · ·
0 · · · ] and hence w(n) is obtained as follows:
W(z) = w(0) + w(1)z−1 + w(2) + z−2 +
⇒W(z) = x(0) + 0z−1 + x(2)z−2 + · · ·
W(z1/2) = x(0) + x(2)z−1 + x(4)z−2 + · · ·
= Y(z).
Thus if W(z) is computed, then Y(z) is obtained as Y(z) = W(z1/2). Using IDFT,
we represent w(n) as follows.
w(n) = x(n)1
2
k=1

k=0
e
j2πkn
2
(4.1)
The z-transformation is obtained as follows:
W(z) =
n=∞

n=0
w(n)z−n
(4.2)
=
n=∞

n=0
x(n)1
2
k=1

k=0
e
j2πkn
2 z−n
(4.3)
= 1
2
k=1

k=0
n=∞

n=0
x(n)e
j2πkn
2 z−n
(4.4)
= 1
2
k=1

k=0
n=∞

n=0
x(n)(e−j2πk
2 z)−n
(4.5)
= 1
2
k=1

k=0
X(e−j2πk
2 z)
(4.6)
= 1
2(X(z) + X(−z)).
(4.7)

4.1 Sampling Rate Conversion by the Factor M
N
123
Thus Y(z) is computed as follows:
Y(z) = W(z1/2) = 1
2(X(z1/2) + X(−z1/2)).
(4.8)
In general for arbitrary value of N, with M = 1, we get the following:
Y(z) = 1
N
k=N−1

k=0
X(e
j2πk
N z
1
N )
(4.9)
= 1
N
k=N−1

k=0
X(e
j2πk
N e
jw
N )
(4.10)
= 1
N
k=N−1

k=0
X(e
j(2πk+w)
N
).
(4.11)
4.1.3
Comments on the Fig.4.1
1. The graph is plotted between frequency in radians in the x-axis and the corre-
sponding magnitude in the y-axis.
2. Subplot 1: In the ﬁrst subplot, 2π in the x-axis corresponds to Fs =
Fmax
2
Hz,
where Fmax is the allowed maximum frequency content (satisfying the sampling
theorem) of the signal. F1 is the actual maximum frequency content of the signal
3. Subplot 2: In the second subplot, 2π in the x-axis corresponds to Fs
2 = Fmax
4
Hz,
where Fmax is the allowed maximum frequency content (satisfying the sampling
theorem) of the signal. F1 is the actual maximum frequency content of the signal.
Note that the maximum frequency allowed in this case has been reduced from
Fmax
2
to Fmax
4 . Suppose if the actual F1 is greater than Fmax
2 , overlapping occur. This
is circumvented by passing the signal through the Low-pass ﬁlter with cutoff
frequency Fmax
2
= π
2 (corresponding to the ﬁrst subplot), before subjected to down
sampling.
4. Subplot 3: In the third subplot, 2π in the x-axis corresponds to 2Fs = Fmax Hz,
where Fmax is the allowed maximum frequency content (satisfying the sampling
theorem) of the signal. F1 is the actual maximum frequency content of the sig-
nal. Note that the maximum frequency allowed in this case has been increased
from Fmax
2
to Fmax. Hence there is no need to ﬁlter the signal before performing
down sampling. But there exist the mirror image of the original spectrum (shaded
region). Hence the spectrum looks like the with cutoff frequency π
2 (corresponding
to the third subplot).

124
4
Multirate Digital Signal Processing
Fig. 4.1 Illustration of decimation and interpolation. a Spectrum of the signal under consideration.
b Spectrum of the signal after down sampling by the factor 2. c Spectrum of the corresponding
signal after up sampling by the factor 2
%multiratedemo.m
%Generating the input sequence
x=fir1(1000,0.3);
MAG=[];
n=0:1:1000;
for w=0:0.01:2*pi
s=sum(x.*exp(-j*w*n));
MAG=[MAG s];
end
%Downsampling by 2
y=dyaddown(x,2);
n=0:1:length(y)-1;
MAGD=[];
for w=0:0.01:2*pi
s=sum(y.*exp(-j*w*n));
MAGD=[MAGD s];
end
%upsampling by 2
z=dyadup(x,2);
n=0:1:length(z)-1;
MAGU=[];
for w=0:0.01:2*pi
s=sum(z.*exp(-j*w*n));
MAGU=[MAGU s];
end

4.1 Sampling Rate Conversion by the Factor M
N
125
Fig. 4.2 Block diagram illustrating the steps involved in sampling rate conversion by the factor M
N
figure
subplot(3,1,1)
plot(linspace(0,2*pi,length(MAG)),abs(MAG),’-’)
subplot(3,1,2)
plot(linspace(0,2*pi,length(MAG)),abs(MAGD),’-’)
subplot(3,1,3)
plot(linspace(0,2*pi,length(MAG)),abs(MAGU),’-’)
In general, the steps involved in getting the sequence yn (that is obtained by
sampling the signal x(t) with the sampling frequency Fsnew =
M
N Fs) from the
sequence xn (that is obtained by sampling the signal x(t) with the sampling frequency
Fsnew = M
N Fs) are summarized below (refer Fig. 4.2).
1. Up sample the sequence by inserting (M −1) zeros in between every samples.
2. The obtained sequence is subjected to the high-pass ﬁltering with cutoff frequency
π
M to get the interpolated sequence.
3. The up sampled sequence is further passed through low-pass ﬁlter with cutoff
frequency π
N .
4. The sequence obtained is further down sampled by removing (N −1) samples
once in N samples.
5. The two low-pass ﬁlters used in this sampling rate conversion can be combined
as the single Low-pass ﬁlter with cutoff frequency chosen as the minimum of π
M
and π
N .
4.2
Poly-phase Realization of the Filter for Interpolation
Interpolation by M is obtained by up sampling the sequence by M, i.e., inserting
(M −1) zeros between the samples to get the new sequence. It is followed by
passing the sequence through the Low-pass FIR ﬁlter with cutoff pi
M . This is realized
by constructing the M poly-phase ﬁlters as described below (with M = 3).
1. Consider the order of the ﬁlter (say 6) as the integer multiples of M = 3.
2. The impulse response of the ﬁlter is given as h = [h0 h1 h2 h3 h4 h5. Note that
the cutoff frequency is pi
M =
pi
3 . Obtain the three (in general M) polyﬁlters as
poly1 = [h0 h3], poly2 = [h1 h4], and poly3 = [h2 h5].
3. It is observed that the poly1, poly2, and poly3 are the downsampled version of
the ﬁlter h.

126
4
Multirate Digital Signal Processing
Fig. 4.3 Illustration of interpolation by 3 using the Interpolator ﬁlter (order 3). a Direct method.
b Efﬁcient method. c Practical implementation of the efﬁcient method. d Poly-phase method. e The
order in which the output is obtained in the poly-phase method
4. We have already identiﬁed that if the ﬁlter coefﬁcients are downsampled, we get
the average of shifted and scaled up version of the M original magnitude response
(refer (4.11)). In particular if the cutoff frequency of the ﬁlter is π
M , we get the
magnitude response as the ﬂat (All pass).
5. Thus poly1, poly2, and poly3 are having ﬂat magnitude response (All pass ﬁl-
ter) (refer Fig. 4.5b–d)with different phase response. Hence the ﬁlter is named
as poly-phase ﬁlter. The actual magnitude response of the ﬁlter is given in
Fig. 4.5a.
6. Filtering the sequence (obtained after up sampling) through the FIR ﬁlter is iden-
tical with ﬁltering through three poly-phase ﬁlters and collecting the outputs in the
cyclic manner (refer Figs. 4.3 and 4.4). The order in which the output is collected
is illustrated in Figs. 4.3e and 4.4e.
7. The spectrum of the sequence before and after interpolation using the direct
ﬁltering method and using poly-phase technique Fig.4.5 is illustrated in Fig. 4.6.

4.2 Poly-phase Realization of the Filter for Interpolation
127
Fig. 4.4 Illustration of interpolation by 3 using the Interpolator ﬁlter (order 6). a Direct method.
b Efﬁcient method. c Practical implementation of the efﬁcient method. d Poly-phase method. e The
order in which the output is obtained in the poly-phase method
%interpolyphase.m
%Polyphase realization of sampling rate conversion
%(Interpolation) by the factor 3
%Generating the input sequence
x=fir1(1000,1/6); %Not the filter coefficients.
MAG=[];
n=0:1:1000;
for w=0:0.01:2*pi
s=sum(x.*exp(-j*w*n));
MAG=[MAG s];
end
%Interpolation by the factor 3
z=[x;zeros(2,length(x))]
z=reshape(z,1,size(z,1)*size(z,2));

128
4
Multirate Digital Signal Processing
Fig. 4.5 a Magnitude response of the FIR ﬁlter used in the interpolation (direct method). b Magni-
tude response of the poly-phase ﬁlter 1. c Magnitude response of the poly-phase ﬁlter 2. d Magnitude
response of the poly-phase ﬁlter 3. e–h Are the phase response corresponding to (a)–(d), respectively
%We need to filter the obtained sequence
%using low-pass filter with cutoff
%frequency pi/3;
h=fir1(212,1/3);
y=conv(z,h)
%Realization using poly-phase filter.
hdyad=reshape(h,3,length(h)/3);
h1=hdyad(1,:);
h2=hdyad(2,:);
h3=hdyad(3,:);
y1=conv(x,h1);
y2=conv(x,h2);
y3=conv(x,h3);
ypoly=[y1;y2;y3];
ypoly=reshape(ypoly,1,size(ypoly,1)*size(ypoly,2));
%Magnitude response using the direct method and the poly-phase method
MAGx=[];
MAGz=[];
MAGy=[];
MAGPOLY=[];
n1=0:1:length(x)-1;
n2=0:1:length(z)-1;
n3=0:1:length(y)-1;

4.2 Poly-phase Realization of the Filter for Interpolation
129
Fig. 4.6 Spectrum a Input signal b Signal after upsampling (inserting zeros) by 3 (Shaded region
shows the mirror image). c Interpolated signal obtained by direct ﬁltering using FIR ﬁlter with
cutoff π
3 . d Interpolated signal obtained using three poly-phase ﬁlters
n4=0:1:length(ypoly)-1;
for w=0:0.01:2*pi
s1=sum(x.*exp(-j*w*n1));
s2=sum(z.*exp(-j*w*n2));
s3=sum(y.*exp(-j*w*n3));
s4=sum(ypoly.*exp(-j*w*n4));
MAGx=[MAGx s1];
MAGz=[MAGz s2];
MAGy=[MAGy s3];
MAGPOLY=[MAGPOLY s4];
end
figure
subplot(2,2,1)
plot(linspace(0,2*pi,length(MAG)),abs(MAGx),’-’)
subplot(2,2,2)
plot(linspace(0,2*pi,length(MAG)),abs(MAGz),’-’)
subplot(2,2,3)
plot(linspace(0,2*pi,length(MAG)),abs(MAGy),’-’)
subplot(2,2,4)
plot(linspace(0,2*pi,length(MAG)),abs(MAGPOLY),’-’)
%Magnitude and Phase response of the efficient filter constructed
M=[];
P=[];
PPF1M=[];

130
4
Multirate Digital Signal Processing
PPF1P=[];
PPF2M=[];
PPF2P=[];
PPF3M=[];
PPF3P=[];
n=0:1:length(h)-1;
n1=0:1:length(h1)-1;
n2=0:1:length(h2)-1;
n3=0:1:length(h3)-1;
for w=0:0.01:2*pi
s=sum(h.*exp(-j*w*n));
s1=sum(h1.*exp(-j*w*n1));
s2=sum(h2.*exp(-j*w*n2));
s3=sum(h3.*exp(-j*w*n3));
M=[M abs(s)];
P=[P angle(s)];
PPF1M=[PPF1M abs(s1)];
PPF1P=[PPF1P angle(s1)];
PPF2M=[PPF2M abs(s2)];
PPF2P=[PPF2P angle(s2)];
PPF3M=[PPF3M abs(s3)];
PPF3P=[PPF3P angle(s3)];
end
figure
subplot(4,2,1)
plot(linspace(0,2*pi,length(M)), M)
subplot(4,2,3)
plot(linspace(0,2*pi,length(PPF1M)), PPF1M)
subplot(4,2,5)
plot(linspace(0,2*pi,length(PPF2M)), PPF2M)
subplot(4,2,7)
plot(linspace(0,2*pi,length(PPF3M)), PPF3M)
subplot(4,2,2)
plot(linspace(0,2*pi,length(P)), P)
subplot(4,2,4)
plot(linspace(0,2*pi,length(PPF1P)), PPF1P)
subplot(4,2,6)
plot(linspace(0,2*pi,length(PPF2P)), PPF2P)
subplot(4,2,8)
plot(linspace(0,2*pi,length(PPF3P)), PPF3P)
4.3
Poly-phase Realization of the Filter for Decimation
Decimation by the factor N is obtained by ﬁltering the input sequence with the FIR
ﬁlter with the cutoff π
N and followed by down sampling the sequence (Removing
(M −1) samples between two consecutive samples). The corresponding poly-phase
realization is as described below.

4.3 Poly-phase Realization of the Filter for Decimation
131
1. Consider the order of the ﬁlter (say 6) as the integer multiples of M = 3.
2. The impulse response of the ﬁlter is given as h = [h0 h1 h2 h3 h4 h5. Note that
the cutoff frequency is pi
M = pi
3 . Obtain the three (in general M) polyﬁlters as
poly1 = [h0 h3], poly2 = [h1 h4], and poly3 = [h2 h5].
3. It is observed that the poly1, poly2, and poly3 are the downsampled version of
the ﬁlter h.
4. We have already identiﬁed that if the ﬁlter coefﬁcients are downsampled, we
get the average of shifted and scaled up version of the M original magnitude
response (refer (1.11)). In particular if the cutoff frequency of the ﬁlter is π
M , we
get the magnitude response as the ﬂat (All pass).
5. Thus poly1, poly2, and poly3 are having ﬂat magnitude response (All pass ﬁl-
ter) (refer Fig. 4.5b–d)with different phase response. Hence the ﬁlter is named as
poly-phase ﬁlter. The actual magnitude response of the ﬁlter is given in Fig. 4.6a.
6. The input sequence [X0 X1 X2 X3 · · · ] is splitted into three sequences (In gen-
eral N sequences) with the ﬁrst sequence ﬁlled up with the elements collected
as S1 = [X0 X3 X6 · · · ]. The second sequence is given as S2 = [X1 X4 X5 · · · ]
and the third sequence is given as S3 = [X2 X5 X8 · · · ].
7. The sequence S1 is ﬁltered using poly-phase ﬁlter 1 namely poly1 to obtain out1.
The sequence S2 is ﬁltered using poly-phase ﬁlter 3 namely poly3 to obtain out2.
Similarly, the sequence S3 is ﬁltered using poly-phase ﬁlter 2 namely poly2 to
obtain out2. The actual output is obtained as out1 + out2 + out3.
8. In general, the input sequence is divided into N sequences as described below.
(a) Keeping ﬁrst element of the input sequence as the ﬁrst element of the new
sequence and collecting one sample once in N samples gives the ﬁrst sequence.
(b) Keeping second element of the input sequence as the ﬁrst element of the
new sequence and collecting one sample once in N samples gives the second
sequence. This is repeated to obtain N sequences (say S1, S2, · · · SN).
9. This method is applied to the impulse response of the decimator ﬁlter (with ﬁlter
coefﬁcient multiples of N) to obtain N poly-phase ﬁlter. (Say poly1, poly2,
poly3, · · · , polyN−1 and polyN).
10. The output sequences out1 = S1∗poly1, out2 = S2∗polyN, out3 = S3∗polyN−1
· · · outN = SN ∗poly2 is computed. The ﬁnal output sequence is obtained as
out = out1 + out2 + · · · outN.
11. Trick to perform M
N using poly-phase technique. (1) In the case M > N, choose
the order of the ﬁlter as the multiples of M. Realize the poly-phase interpolation
ﬁlter with cutoff frequency π
M (refer Figs. 4.3, 4.4). This is followed by deci-
mation by N. (2) In the case M < N, perform the interpolation by the factor
N. Choose the order of the ﬁlter as the multiples of N with cutoff frequency π
N
and implement the poly-phase realization (refer Figs. 4.7, 4.8) of the decimation
ﬁlter to obtain the ﬁnal sequence (Figs. 4.9, 4.10, 4.11, 4.12).

132
4
Multirate Digital Signal Processing
Fig. 4.7 Illustration of decimation by 3 using the decimator ﬁlter (order 3). a Direct method. b
Poly phase method
%decimatepolyphase.m
%Decimation by 1/3
%Polyphase realization of sampling rate conversion
%by the factor 1/3
%Generating the input sequence
x=fir1(1000,3/4); %Not the filter coefficients.
MAG=[];
n=0:1:1000;
for w=0:0.01:2*pi
s=sum(x.*exp(-j*w*n));
MAG=[MAG s];
end
%Direct method (Decimation by the factor 3 )
x=x(1:1:999);
z=reshape(x,3,333);
z=z(1,:);

4.3 Poly-phase Realization of the Filter for Decimation
133
Fig. 4.8 Illustration of decimation by 3 using the decimator ﬁlter (order 6). a Direct method. b
Poly-phase method
Fig. 4.9 a Spectrum of the input signal with the maximum frequency content as 3π
4 . b Filter used
before decimation with cutoff frequency π
3 . c Spectrum of the output signal after ﬁltering before
subjected to decimation

134
4
Multirate Digital Signal Processing
Fig. 4.10 a Spectrum of the input signal. b Spectrum of the decimated signal without ﬁltering
(overlapping occurs because maximum frequence 3π
4 exceeds π
3 ). c Spectrum of the decimated
signal after ﬁltering using the direct method. d Spectrum of the decimated signal after ﬁltering
using poly-phase method
Fig. 4.11 a Spectrum of the input signal with the maximum frequency content as π
6 . b Filter used
before decimation with cutoff frequency π
3 . c Spectrum of the output signal after ﬁltering before
subjected to decimation (Identical with the spectrum of the input signal)

4.3 Poly-phase Realization of the Filter for Decimation
135
Fig. 4.12 a Spectrum of the input signal. b Spectrum of the decimated signal without ﬁltering
(overlapping does not occurs because maximum frequency π
6 does not exceed π
3 ). c Spectrum of
the decimated signal after ﬁltering using the direct method. d Spectrum of the decimated signal
after ﬁltering using poly-phase method
Fig. 4.13 Block diagram.
a Quadrature mirror ﬁlter.
b transmultiplexer
h=fir1(212,1/3);
y1=conv(x,h);
MAGx=[];
MAGh=[];
MAGy1=[];
n1=0:1:length(x)-1;
n2=0:1:length(h)-1;
n3=0:1:length(y1)-1;
for w=0:0.01:2*pi
s1=sum(x.*exp(-j*w*n1));
s2=sum(h.*exp(-j*w*n2));
s3=sum(y1.*exp(-j*w*n3));

136
4
Multirate Digital Signal Processing
MAGx=[MAGx s1];
MAGh=[MAGh s2];
MAGy1=[MAGy1 s3];
end
figure
subplot(3,1,1)
plot(0:0.01:2*pi,abs(MAGx))
subplot(3,1,2)
plot(0:0.01:2*pi,abs(MAGh))
subplot(3,1,3)
plot(0:0.01:2*pi,abs(MAGy1))
y=y1(1:1:1209);
y=reshape(y,3,403);
y=y(1,:);
x=[0 0 x];
x=x(1:1:999);
x1=reshape(x,3,333);
%Realization using poly-phase filter.
hdyad=reshape(h,3,length(h)/3);
h1=hdyad(1,:);
h2=hdyad(2,:);
h3=hdyad(3,:);
y1=conv(x1(1,:),h3);
y2=conv(x1(2,:),h2);
y3=conv(x1(3,:),h1);
ypoly=y1+y2+y3;
%Magnitude response using the direct method and the poly-phase method
MAGx=[];
MAGz=[];
MAGy=[];
MAGPOLY=[];
n1=0:1:length(x)-1;
n2=0:1:length(z)-1;
n3=0:1:length(y)-1;
n4=0:1:length(ypoly)-1;
for w=0:0.01:2*pi
s1=sum(x.*exp(-j*w*n1));
s2=sum(z.*exp(-j*w*n2));
s3=sum(y.*exp(-j*w*n3));
s4=sum(ypoly.*exp(-j*w*n4));
MAGx=[MAGx s1];
MAGz=[MAGz s2];
MAGy=[MAGy s3];
MAGPOLY=[MAGPOLY s4];
end
figure
subplot(2,2,1)
plot(linspace(0,2*pi,length(MAG)),abs(MAGx),’-’)
subplot(2,2,2)
plot(linspace(0,2*pi,length(MAG)),abs(MAGz),’-’)
subplot(2,2,3)
plot(linspace(0,2*pi,length(MAG)),abs(MAGy),’-’)
subplot(2,2,4)

4.3 Poly-phase Realization of the Filter for Decimation
137
plot(linspace(0,2*pi,length(MAG)),abs(MAGPOLY),’-’)
%Magnitude and Phase response of the efficient filter constructed
M=[];
P=[];
PPF1M=[];
PPF1P=[];
PPF2M=[];
PPF2P=[];
PPF3M=[];
PPF3P=[];
n=0:1:length(h)-1;
n1=0:1:length(h1)-1;
n2=0:1:length(h2)-1;
n3=0:1:length(h3)-1;
for w=0:0.01:2*pi
s=sum(h.*exp(-j*w*n));
s1=sum(h1.*exp(-j*w*n1));
s2=sum(h2.*exp(-j*w*n2));
s3=sum(h3.*exp(-j*w*n3));
M=[M abs(s)];
P=[P angle(s)];
PPF1M=[PPF1M abs(s1)];
PPF1P=[PPF1P angle(s1)];
PPF2M=[PPF2M abs(s2)];
PPF2P=[PPF2P angle(s2)];
PPF3M=[PPF3M abs(s3)];
PPF3P=[PPF3P angle(s3)];
end
figure
subplot(4,2,1)
plot(linspace(0,2*pi,length(M)), M)
subplot(4,2,3)
plot(linspace(0,2*pi,length(PPF1M)), PPF1M)
subplot(4,2,5)
plot(linspace(0,2*pi,length(PPF2M)), PPF2M)
subplot(4,2,7)
plot(linspace(0,2*pi,length(PPF3M)), PPF3M)
subplot(4,2,2)
plot(linspace(0,2*pi,length(P)), P)
subplot(4,2,4)
plot(linspace(0,2*pi,length(PPF1P)), PPF1P)
subplot(4,2,6)
plot(linspace(0,2*pi,length(PPF2P)), PPF2P)
subplot(4,2,8)
plot(linspace(0,2*pi,length(PPF3P)), PPF3P)
4.4
Quadrature Mirror Filter
Quadrature Mirror Filter consists of L-channel analysis ﬁlter bank at the input and
L-channel synthesis ﬁlter at the output end (refer Fig.4.13a). Consider L = 2. Let
the transfer function of the two-channel QMF (analysis (H) and synthesis (G)) ﬁlter

138
4
Multirate Digital Signal Processing
are as shown below:
H0(z) = 1
2(A0(z2) + z−1A1(z2))
H1(z) = 1
2(A0(z2) −z−1A1(z2))
G0(z) = 1
2(A0(z2) + z−1A1(z2))
G1(z) = 1
2(z−1A1(z2) −A0(z2)).
where A0(z) and A1(z) are the all pass ﬁlter. Let the z-transformation of the signal
after analysis ﬁlter be represented as U0(z), U1(z) and are computed as follows:
U0(z) = 1
2(H0(z1/2) + H0(−z1/2))
U0(z) = 1
4(A0(z) + z−1/2 A1(z) + A0(z) −z−1/2 A1(z) = 1
2 A0(z))
U1(z) = 1
2(H1(z1/2) + H1(−z1/2))
U1(z) = 1
4(A0(z) −z−1/2 A1(z) + A0(z) + z−1/2 A1(z)) = 1
2 A0(z).
It is upsampled before given to the synthesis ﬁlter and hence the overall transfer
function is given as
U0(z2)G0(z) + U1(z2)G1(z)
= 1
4 A0(z2)G0(z) + 1
4 A0(z2)G1(z)
= 1
8(A0(z2) + z−1A1(z2))A0(z2) + 1
8(z−1A1(z2) −A0(z2))A0(z2)
= 1
4 A0(z2)A1(z2)z−1.
The typical analysis ﬁlters and the synthesis ﬁlters are constructed using the
all pass ﬁlters as given in (4.12 and 4.13). Figure 4.14 shows the magnitude and
phase response of the constructed ﬁlters. The speech signal is decomposed using the
constructed analysis ﬁlters and are reconstructed using the typical synthesis ﬁlters
are shown in Fig. 4.15.
A0(z) = 0.10557281 + z−2
1 + 0.1055781z−2
(4.12)
A1(z) = 0.527864045 + z−2
1 + 0.527864045z−2
(4.13)

4.4 Quadrature Mirror Filter
139
Fig. 4.14 Typical QMF ﬁlters. a Magnitude response of H0(z) and H1(z). b Phase response of
H0(z) and H1(z). c Magnitude response of G0(z) and G1(z). d Phase response of G0(z) and G1(z)
Fig. 4.15 a Input speech signal. b Output of low-pass decomposition ﬁlter. c Output of high pass
decomposition ﬁlter. d Signal reconstructed with low pass and high-pass reconstruction ﬁlter

140
4
Multirate Digital Signal Processing
%QMFdemo.m
clear all
close all
a0d=0.10557281;
a1d=0.10557281;
b0d=0.527864045;
b1d=0.527864045;
a0r=0.10557281;
a1r=0.10557281;
b0r=0.527864045;
b1r=0.527864045;
i=2;
QMF
part1=recons;
save part1 part1
clear all
a0d=0.10557281;
a1d=0.10557281;
b0d=-0.527864045;
b1d=0.527864045;
a0r=-0.10557281;
a1r=0.10557281;
b0r=0.527864045;
b1r=0.527864045;
i=3;
QMF
part2=recons;
load part1
part=(part1+part2)/2;
subplot(2,2,1)
plot(speechdata)
subplot(2,2,4)
plot(part)
coef1=a0d;
coef2=b1d;
%A0
[H1,W]=freqz([coef1 0 1],[1 0 coef1]);
%z-1A1
[H2,W]=freqz([0 coef2 0 1],[1 0 coef2]);
figure
subplot(2,2,1)
plot(W,abs(H1+H2)/2)
subplot(2,2,2)
plot(W,angle(H1+H2)/2)
subplot(2,2,3)
plot(W,abs(H1+H2)/2)
subplot(2,2,4)
plot(W,angle(H1+H2)/2)
%-z-1A1
[H3,W]=freqz([-0 -coef2 -0 -1],[1 0 coef2]);
subplot(2,2,1)
hold on
plot(W,abs(H1+H3)/2,’r’)
subplot(2,2,2)
hold on

4.4 Quadrature Mirror Filter
141
plot(W,angle(H1+H3)/2,’r’)
%-A0
[H4,W]=freqz([-coef1 -0 -1],[1 0 coef1]);
subplot(2,2,3)
hold on
plot(W,abs(H2+H4)/2,’r’)
subplot(2,2,4)
hold on
plot(W,angle(H2+H4)/2,’r’)
%QMF.m
%Called by the script QMFdemo.m
load SPEECHDATA
%A0(0.10557281+zˆ{-2})/(1+0.10557281zˆ{-2});
%A1=(0.527864045+zˆ{-2})/(1+0.527864045zˆ{-2});
%Decomposition
speechdata=speechdata(2000:1:3000);
x=speechdata;
y=zeros(1,3);
for n=4:1:length(speechdata)
y(n)=a0d*x(n)+sign(a1d)*x(n-2)-a1d*y(n-2);
end
output1=y;
x=speechdata;
y=zeros(1,3);
for n=4:1:length(x)
y(n)=b0d*x(n-1)+sign(b0d)*x(n-3)-b1d*y(n-2);
end
output2=y;
z=output1+output2;
%Downsampling
L=fix(length(z)/2);
z=z(1:1:2*L);
output=reshape(z,2,L);
output=output(1,:);
subplot(2,2,i)
plot(output)
%Upsampling
output=[output;zeros(1,length(output))];
p=reshape(output,1,size(output,1)*size(output,2));
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Reconstruction
x=p;
y=zeros(1,3);
for n=4:1:length(x)
y(n)=a0r*x(n)+sign(a0r)*x(n-2)-a1r*y(n-2);
end
output1=y;
x=p;
y=zeros(1,3);
for n=4:1:length(x)
y(n)=b0r*x(n-1)+sign(b0r)*x(n-3)-b1r*y(n-2);
end
output2=y;
recons=output1+output2;

142
4
Multirate Digital Signal Processing
4.5
Transmultiplexer
Time division multiplexing involves allotting alternative time slots to the individual
sequencestosharethechannel.Frequencydivisionmultiplexing(FDM)isthemethod
of allotting different bandwidths for the individual sequences to share the common
channel. Trans-multiplexer (refer Fig. 4.13b) helps to get the new sequence from the
actual two sequences to be transmitted through the channel that converts TDM to
FDM sharing of the channel.
Consider two sequences in Fig. 4.16a, b to be transmitted through the channel. The
spectrum of these two sequences is given in Fig. 4.17a, b, respectively. We obtain the
new sequence as shown in Fig. 4.16c whose spectrum is given in Fig. 4.19c. In this
case the spectrum occupied by the individual sequence are identiﬁed at different slots.
This is achieved by interpolating the two sequences individually and followed by the
corresponding decomposition ﬁlters (Fig.4.18a, b). The spectrum of the sequence 1
after subjected to interpolation, followed by low-pass decomposition ﬁlter is given
in Fig. 4.19a. Similarly, the spectrum of the sequence 2 after subjected to interpo-
lation,followed by high-pass decomposition ﬁlter is given in Fig. 4.19b. This shows
how the spectrum of the channel is shared between the two sequences. The received
sequence (assuming ideal channel), is passed through the low-pass reconstruction
ﬁlter Fig.4.18c, d, followed by down sampling to obtain the sequence 1. Similarly,
the received sequence is passed through the high-pass reconstruction ﬁlter, followed
by down sampling to obtain the sequence 2.
%transmultiplexer.m
X00=fir2(100,linspace(0,1,1000),triang(1000)’);
X11=fir2(100,linspace(0,1,1000),(1-triang(1000))’);
%G0z=zˆ{-1}+zˆ{-2};
%G1z=zˆ{-1}-zˆ{-2};
%H0z=1+zˆ{-1};
%H1z=1-zˆ{-1};
%TDM2FDM
X0=[X00;zeros(1,length(X00))];
X0=reshape(X0,1,size(X0,1)*size(X0,2));
X1=[X11;zeros(1,length(X11))];
X1=reshape(X1,1,size(X1,1)*size(X1,2));
X0=[zeros(1,2) X0];
X1=[zeros(1,2) X1];
for n=3:1:length(X0)
Y0(n)= X0(n-1)+X0(n-2);
Y1(n)=X1(n-1)-X1(n-2);
end
Y=Y0+Y1;
n=0:1:length(Y0)-1;
m0=[];
m1=[];
m=[];
for w=-pi:0.001:pi;
m0=[m0 abs(sum(Y0.*exp(-j*w*n)))];
m1=[m1 abs(sum(Y1.*exp(-j*w*n)))];

4.5 Transmultiplexer
143
Fig. 4.16 a Sequence 1 in the transmitter. b Sequence 2 in the transmitter. c Sequence transmitted
through the channel. d Sequence 1 in the receiver. e Sequence 2 in the receiver
Fig. 4.17 a Actual spectrum occupied by the sequence 1 before transmission. b Actual spectrum
occupied by the sequence 2 before transmission. c Actual spectrum occupied by the sequence 1 in
the receiver. d Actual spectrum occupied by the sequence 2 in the receiver

144
4
Multirate Digital Signal Processing
Fig. 4.18 Magnitude response: a Low-pass decomposition ﬁlter. b High-pass decomposition ﬁlter.
c Low-pass reconstruction ﬁler. d High-pass reconstruction ﬁlter
Fig. 4.19 a Bandwidth occupied by the sequence 1 in the channel. b Bandwidth occupied by the
sequence 2 in the channel. c Bandwidth occupied by both the sequence in the channel

4.5 Transmultiplexer
145
m=[m abs(sum(Y.*exp(-j*w*n)))];
end
figure
subplot(3,1,1)
plot(-pi:0.001:pi,m0)
subplot(3,1,2)
plot(-pi:0.001:pi,m1,’r’)
subplot(3,1,3)
plot(-pi:0.001:pi,m,’g’)
%FDM2TDM
Y=[zeros(1,2) Y];
for n=3:1:length(Y)
XR0(n)=Y(n)+Y(n-1);
XR1(n)=Y(n)-Y(n-1);
end
XR00=dyaddown(XR0,1);
XR11=dyaddown(XR1,1);
m0=[];
m1=[];
m2=[];
m3=[];
n1=0:1:length(XR00)-1;
n2=0:1:length(X00)-1;
for w=-pi:0.001:pi;
m0=[m0 abs(sum(XR00.*exp(-j*w*n1)))];
m1=[m1 abs(sum(XR11.*exp(-j*w*n1)))];
m2=[m2 abs(sum(X00.*exp(-j*w*n2)))];
m3=[m3 abs(sum(X11.*exp(-j*w*n2)))];
end
figure
subplot(4,1,1)
plot(-pi:0.001:pi,m0)
subplot(4,1,2)
plot(-pi:0.001:pi,m1,’r’)
subplot(4,1,3)
plot(-pi:0.001:pi,m2)
subplot(4,1,4)
plot(-pi:0.001:pi,m3,’r’)
figure
subplot(5,1,1)
stem(X00)
subplot(5,1,2)
stem(X11)
subplot(5,1,3)
stem(Y)
subplot(5,1,4)
stem(XR00)
subplot(5,1,5)
stem(XR11)

146
4
Multirate Digital Signal Processing
figure
[H1,W1]=freqz([0 1 1],1);
subplot(2,2,1)
plot(W1,abs(H1))
[H2,W2]=freqz([0 1 -1],1);
subplot(2,2,2)
plot(W2,abs(H2))
[H3,W3]=freqz([1 1],1);
subplot(2,2,3)
plot(W1,abs(H1))
[H4,W4]=freqz([1 -1],1);
subplot(2,2,4)
plot(W2,abs(H2))

Chapter 5
Statistical Signal Processing
5.1
Introduction to Random Process
The outcome of the experiments is mapped to the function of time and is known as
random process. Random process is analyzed by obtaining the random variable Xt
tapped across the process at some time instant t. The random process is said to be
strictly stationary random process (S.S.R.P) with ﬁrst order if F Xt = F Xt+τ for all
t and τ.
The random process is said to be strictly stationary random process with second
order if F Xt1, t2 = F Xt1+τ, t2+τ for all t1, t2 and τ.
In practice, identifying whether the given random process is S.S.R.P is difﬁcult.
Henceweidentifytheparticularsetofrandomprocessknownaswidesensestationary
random process (W.S.S.R.P), which satisﬁes the following conditions:
1. E(Xt) = constant
2. E(Xt+τ Xt) = RX(τ).
5.1.1
Illustration on W.S.S.R.P and Nonstationary
Random Process
The discrete random process Xn is generated with the outcome of Xn satisﬁes the
following conditions:
1. The outcome of Xn takes the value 1, 2, 3 or 4
2. Xn is identically distributed for all n
3. Xn1 and Xn2 are independent for all n1 and n2.
© Springer International Publishing AG 2018
E.S. Gopi, Multi-Disciplinary Digital Signal Processing,
DOI 10.1007/978-3-319-57430-1_5
147

148
5
Statistical Signal Processing
Fig. 5.1 Illustration of random process. a W.S.S.R.P 1. b W.S.S.R.P 2. c N.S.R.P
Hundred outcomes are stacked row wise to form the image and are displayed in the
ﬁrst row of Fig. 5.1a, b. The corresponding estimated mean across the process for
everyn isplottedintheFig.5.1a,b(secondrow),respectively.Further,theexperiment
is repeated with nonuniform distribution for all n. Fig. 5.1c (ﬁrst row and second
row) shows the image representation of the random process and the corresponding
estimated mean. Also the sample outcome of the random process under each cases
is displayed in the Fig. 5.2. It is seen from Fig. 5.1, the estimated mean is almost
constantin(a)and(b)andhavelargevariationin(c).ThisdemonstratestheW.S.S.R.P
(subplot a and b) and nonstationary random process (subplot c).
%wssrp.m
clear all
PR=rand(1,4);
PR=PR/sum(PR);
R=cumsum(PR);
DATA=[];
for i=1:1:100
D=[];
for j=1:1:1000
P=R-rand;
[U,V]=find(P>0);
D=[D;V(1)];
end
DATA=[DATA repmat(D,1,10)];
end
FINALDATA=[];
for i=1:1:1000
t=round(rand*9);
FINALDATA=[FINALDATA ;...
zeros(1,t) DATA(i,:) zeros(1,10-t)];

5.1 Introduction to Random Process
149
Fig. 5.2 a 500th row of W.S.S.R.P 1. b 500th row of W.S.S.R.P 2. c 500th row of N.S.R.P
end
temp=FINALDATA(:,11:1:100);
figure(1)
subplot(2,3,1)
imagesc(temp)
subplot(2,3,4)
plot(mean(temp))
figure(2)
subplot(3,1,1)
plot(temp(500,:))
clear all
PR=rand(1,4);
PR=PR/sum(PR);
R=cumsum(PR);
DATA=[];
for i=1:1:100
D=[];
for j=1:1:1000
P=R-rand;
[U,V]=find(P>0);
D=[D;V(1)];
end
DATA=[DATA repmat(D,1,10)];
end
FINALDATA=[];
for i=1:1:1000
t=round(rand*9);
FINALDATA=[FINALDATA ;...
zeros(1,t) DATA(i,:) zeros(1,10-t)];
end
temp=FINALDATA(:,11:1:100);
figure(1)

150
5
Statistical Signal Processing
subplot(2,3,2)
imagesc(temp)
subplot(2,3,5)
plot(mean(temp))
figure(2)
subplot(3,1,2)
plot(temp(500,:))
clear all
DATA=[];
for i=1:1:100
D=[];
PR=rand(1,4);
PR=PR/sum(PR);
R=cumsum(PR);
for j=1:1:1000
P=R-rand;
[U,V]=find(P>0);
D=[D;V(1)];
end
DATA=[DATA repmat(D,1,10)];
end
FINALDATA=[];
for i=1:1:1000
t=round(rand*9);
FINALDATA=[FINALDATA ;...
zeros(1,t) DATA(i,:) zeros(1,10-t)];
end
temp=FINALDATA(:,11:1:100);
figure(1)
subplot(2,3,3)
imagesc(temp)
subplot(2,3,6)
plot(mean(temp))
figure(2)
subplot(3,1,3)
plot(temp(500,:))
5.2
Auto Regressive (AR), Moving Average (MA) and Auto
Regressive Moving Average (ARMA) Modeling
The W.S.S. random process Wn is said to be white if it satisﬁes the following:
γτ = 1 f orτ = 0 = 0,
otherwise
(5.1)
and the spectral density is ﬂat as given below:
Sw( f ) = 1
(5.2)
for all f .

5.2 Auto Regressive (AR), Moving average (MA) …
151
Let the Wide Sense Stationary (WSS) random process, which is white Wn (with
variance σ 2
w) is given as the input to the system H(z) and the spectral density of
the corresponding output is given as Sx(z) = σ 2
wH(z)H(1/z) with r1 < |z| < r2.
Given the spectral density of the W.S.S. random process Xn, obtaining H(z) that
generates the outcome of random process Xn with the input W.S.S. white random
process Wn with the identiﬁed variance σ 2
w is known as wold representation. This
is used to model the generation of typical W.S.S. random process (such as speech
signal) with the speciﬁc spectral density. Let H(z) is represented as follows:
H(z) = b0 + b1z−1 + b2z−2 + b3z−3
1 + a1z−1 + a2z−2 + a3z−3
(5.3)
The input W.S.S. random process Wn and the output W.S.S. random process Xn are
related as follows.
Xn = b0Wn + b1Wn−1 + b2Wn−2 + b3WN−3 −a1Xn−1 −a2Xn−2 −a3Xn−3. (5.4)
This is known as ARMA (Auto regressive, Moving Average model). If we choose
a1 = a2 = 0, the model is known as MA (Moving Average model). If we choose
b1 = b2 = 0 and b0 = 1, the model is known as AR (Auto regressive model). The
coefﬁcients are obtained as follows.
5.2.1
Linear Prediction Model
We see the expression Xn = a1Xn−1 + a2Xn−2 + a3Xn−3 as the prediction of the
nth sample of the random process Xn using the previous samples. This is known as
forward prediction. It is also observed that Wn = Xn −a1Xn−1−a2Xn−2−a3Xn−3 =
is the error involved in predicting the nth. Thus the coefﬁcients are obtained by
minimizing the mean squared error E((Wn)2). (Note that we are considering only
the real signals.) We obtain the coefﬁcients such that E((Xn + a1Xn−1 + a2Xn−2 +
a3Xn−3)2) is minimized. Differentiating with respect to a1, a2, a3 and equate to zero,
we get the following:
E(−2(Xn −a1Xn−1 −a2Xn−2 −a3Xn−3)(Xn−1)) = 0
⇒γx(1) = a1γx(0)a2γx(−1)a3γx(−2)
E(−2(Xn −a1Xn−1 −a2Xn−2 −a3Xn−3)(Xn−2)) = 0
⇒γx(2) = a1γx(1)a2γx(0)a3γx(−1)
E(−2(Xn −a1Xn−1 −a2Xn−2 −a3Xn−3)(Xn−3)) = 0
⇒γx(2) = a1γx(1)a2γx(0)a3γx(0)

152
5
Statistical Signal Processing
Rewriting in the matrix form we get the following:
⎡
⎣
γx(0)
γx(−1)
γx(−2)
γx(1)
γx(0)
γx(−1)
γx(2)
γx(1)
γx(0)
⎤
⎦
⎡
⎣
a1
a2
a3
⎤
⎦=
⎡
⎣
γx(1)
γx(2)
γx(3)
⎤
⎦
It is noted that a1, a2 and a3 are AR coefﬁcients. Suppose that we represent
b0Xn + b1Xn−1 + b2Xn−2 as the prediction of the Xn−3 of the random process Xn.
We would like to obtain the coefﬁcients b0, b1 and b2 that minimizes.
E((Xn−3 −b0Xn −b1Xn−1 −b2Xn−2)2)
(5.5)
Differentiating (5.5) with respect to b0, b1 and b2 and equate to zero, we get the
following:
E(−2(Xn−3 −b0Xn −b1Xn−1 −b2Xn−2)X(n)) = 0
(5.6)
⇒γx(−3) = b0γx(0) + b1γx(−1) + b2γx(−2) = 0
(5.7)
E(−2(Xn−3 −b0Xn −b1Xn−1 −b2Xn−2)X(n −1)) = 0
(5.8)
⇒γx(−2) = b0γx(1) + b1γx(0) + b2γx(−1) = 0
(5.9)
E(−2(Xn−3 −b0Xn −b1Xn−1 −b2Xn−2)X(n −2)) = 0
(5.10)
⇒γx(−1) = b0γx(2) + b1γx(1) + b2γx(0) = 0
(5.11)
Representing in the matrix form, we get the following:
⎡
⎣
γx(0)
γx(−1)
γx(−2)
γx(1)
γx(0)
γx(−1)
γx(2)
γx(1)
γx(0)
⎤
⎦
⎡
⎣
b1
b2
b3
⎤
⎦=
⎡
⎣
γx(−3)
γx(−2)
γx(−1)
⎤
⎦
⇒
⎡
⎣
γx(2)
γx(1)
γx(0)
γx(1)
γx(0)
γx(−1)
γx(0)
γx(−1)
γx(−2)
⎤
⎦
⎡
⎣
b1
b2
b3
⎤
⎦=
⎡
⎣
γx(−1)
γx(−2)
γx(−3)
⎤
⎦
Let us represent
⎡
⎣
γx(1)
γx(2)
γx(3)
⎤
⎦as the following:
a1
⎡
⎣
γx(0)
γx(1)
γx(2)
⎤
⎦+ a2
⎡
⎣
γx(−1)
γx(0)
γx(1)
⎤
⎦+ a3
⎡
⎣
γx(−2)
γx(−1)
γx(0)
⎤
⎦
(5.12)
Similarly we represent
⎡
⎣
γx(−1)
γx(−2)
γx(−3)
⎤
⎦as the following:
b1
⎡
⎣
γx(2)
γx(1)
γx(0)
⎤
⎦+ b2
⎡
⎣
γx(1)
γx(0)
γx(−1)
⎤
⎦+ b3
⎡
⎣
γx(0)
γx(−1)
γx(−2)
⎤
⎦
(5.13)

5.2 Auto Regressive (AR), Moving average (MA) …
153
Fig. 5.3 Illustration of the a
forward prediction, b
backward prediction (The
yellow sample is predicted
using the red samples)
From (5.12) and (5.13), we observe bm = a4−m, where 4 is the number of coefﬁcients
+1 used. In general for complex samples and with r number of coefﬁcients, we get
bm = a∗
r−m. The coefﬁcients am are known as forward predication coefﬁcients and
bm are known as backward prediction coefﬁcients.
5.2.1.1
Forward and Backward Prediction
In general, we represent the prediction of Xn using one previous sample as X f,1
n
=
a f,1
1 Xn−1 and the corresponding forward prediction error is given as e f,1
n
= Xn −
a1
f,1Xn−1. Similarly, the prediction of Xn using two previous samples are given as
X f,2
n
= a2
f,1Xn−1 + a2
f,2Xn−2. In general, the prediction of Xn using previous M
samples and the corresponding forward prediction error is given as the following:
X f,M
n
=
k=M

k=1
aM
f,k Xn−k
e f,M
n
= Xn −
k=M

k=1
aM
f,k Xn−k
=
k=M

k=0
cM
f,k Xn−k
with cM
f,k = 1 for k = 0, cM
f,k = −bM
f,k for k ̸= 0 and k = 1 · · · M.
In the same fashion, we represent the prediction of Xn−1 using one next sample
and it is given as Xb,1
n−1 = ab,1
1 Xn and the corresponding backward prediction error
is given as the following: eb,1
n
= Xn−1 −ab,1
1 Xn. In general, the prediction of Xn−M
using next M samples and the corresponding backward prediction error is given as
the following:
Xb,M
n−M =
k=M−1

k=0
aM
b,k Xn−k

154
5
Statistical Signal Processing
Fig. 5.4 Signal used to compute forward and backward prediction coefﬁcients
eb,M
n
= Xn−M −
k=M

k=1
aM
b,k Xn−k
eb,M
n
=
k=M

k=0
cM
b,k X M
n−k
with cM
b,k = 1 for k = M, cM
b,k = −aM
b,k for k ̸= M and k = 1 · · · M −1.
It is noted that e f,M
n
is the error involved in estimating Xn using M previous
samples and e f,M
n
is the error involved in estimating Xn−M using the next M samples.
They are, respectively, forward prediction error and the backward prediction error
(Figs. 5.3, 5.4, 5.5, 5.6, 5.7, 5.8).
5.2.1.2
Methodology Used to Obtain the Coefﬁcients cM
b,k and cM
f,k Using
the Coefﬁcients cM−1
b,k
and cM−1
f,k
From Sect. 5.2.1.1, we get cM
f,k =
∗
cb,M−k
M
. In z-transformation, we get the following:
cM
f (z) = cM
b (1
z )z−M
We represent the following:

5.2 Auto Regressive (AR), Moving average (MA) …
155
Fig. 5.5 a Forward prediction coefﬁcient computed directly by constructing toeplitz matrix.
b Forward prediction coefﬁcient computed using recursive techniques. Number of co-efﬁcients
are increasing from left to right
Fig. 5.6 a Backward prediction coefﬁcient computed directly by constructing toeplitz matrix.
b Backward prediction coefﬁcient computed using recursive techniques. Number of co-efﬁcients
are increasing from left to right
cM
f,k = cM−1
f,k
+ KMcM−1
b,k−1
cM
b,k = K ∗
McM−1
f,k
+ cM−1
b,k−1
where KM = cM
f,M is the reﬂection coefﬁcient. Taking z-transformation, we get the
following:

156
5
Statistical Signal Processing
Fig. 5.7 Reﬂection coefﬁcients obtained for the signal in Fig.5.4
C M
f (z) = cM−1
f
(z) + z−1KMC M−1
b
C M
b = K ∗
MC M−1
f
(z) + z−1cM−1
b
%forbackcoef.m
%Computation of Forward, Backward prediction coefficients and the
%reflection
%Generation of signal
n=0:1:1000;
f1=1;
f2=2;
Ts=1/10;
X=sin(2*pi*f1*n*Ts)+sin(2*pi*f2*n*Ts);
figure(1)
plot(X(1:1:400))
title(’Signal used to obtain AR coefficients’)
R=xcorr(X);
for recur=0:1:101
m1=toeplitz(R(1001:1:1001+recur));
%Computing forward coefficients
v1=[R(1002:1:1002+recur)];
forwardcoef{recur+1}=[1; -1*(inv(m1)*v1’)];
backwardcoef{recur+1}=forwardcoef{recur+1}...
(length(forwardcoef{recur+1}):-1:1);
K(recur+1)=forwardcoef{recur+1}...
(length(forwardcoef{recur+1}));
end
F{1}=forwardcoef{1};
B{1}=backwardcoef{1};
for i=4:1:101
%Computing forwardcoef and backwardcoef recursively
F{i}=[F{i-1};0]+K(i)*[0; B{i-1}];

5.2 Auto Regressive (AR), Moving Average (MA) …
157
B{i}=[K(i)*F{i-1};0]+[0; B{i-1}];
end
figure
title(’Computation of forward coefficients ...
using direct and the recursive method’)
for i=1:1:5
subplot(2,5,i)
stem(F{i+3})
subplot(2,5,i+5)
stem(forwardcoef{i+3})
end
figure
title(’Computation of backward coefficients ...
using direct and the recursive method’)
for i=1:1:5
subplot(2,5,i)
stem(B{i+3})
subplot(2,5,i+5)
stem(backwardcoef{i+3})
end
figure
stem(K)
title(’Reflection coefficients’)
Errorsignal=conv(F{101},X);
v=var(Errorsignal,1);
NOISE=sqrt(v)*rand(1,1000);
RES=[zeros(1,101) X(2)];
for i=1:1:1000
temp1=RES(length(RES):-1:length(RES)-100);
temp2=NOISE(i)-sum(temp1’.*F{101}(2:1:length(F{101})));
RES=[RES temp2];
end
figure
subplot(3,1,1)
plot(NOISE(101:1:200))
title(’Input white noise signal with variance 0.0044’)
subplot(3,1,2)
plot(X(1:1:100))
title(’Actual signal used to obtain coefficients’)
subplot(3,1,3)
plot(RES(101:1:200))
title(’Output of the AR model’)
5.3
Adaptive Filter
5.3.1
System Model
Let the Wide Stationary Stationary random process associated with the input to the
unknown system is represented as Xn and the corresponding output random process
is represented as Yn. We would like to model the system using FIR ﬁlter. Let the ﬁlter
coefﬁcients be represented as h = [h1 h2 · · · hN−1]T . The relationship between Yn
and Xn is as given below.

158
5
Statistical Signal Processing
Fig. 5.8 Demonstration of generation of AR random process with white noise as the input
Fig. 5.9 Adaptive ﬁlter to
model the unknown system
Yn =
N−1

k=0
hk Xn−k
We would like to optimize the FIR ﬁlter coefﬁcients such that
ε = E((Yn −
N−1

k=0
hk Xn−k)2)
(5.14)
is minimized (Fig.5.9).
Differentiating (5.14), with respect to hr and equate to zero, we get the following:
for r = 1 · · · N −1.

5.3 Adaptive Filter
159
E(2(Yn −
N−1

k=0
hk Xn−k)Xn−r) = 0
(5.15)
γyx(r) =
N−1

k=0
hkγx(r −k)
(5.16)
⇒γyx = Γxhoptimum
(5.17)
⇒hoptimum = Γ −1
x
γyx
(5.18)
The above is the Wiener–Hopf equation. To solve (5.18), we need the joint pdf
fYn Xn(α, β), which is usually not available. Hence iterative technique based on the
steepest-descent algorithm is used and the outline of the algorithm is described below:
We would like to get the optimal solution for the variable x such that the function
f (x) is minimized. Steepest-descent algorithm starts with randomly chosen initial
value and (xcurrent). The slope of the function f (x) at xcurrent is computed. From
the ﬁgure, it is seen that the if the slope is negative, the next best choice (xnext) is
greater than xinitial and is given xnext = xcurrent −α d f (x)
dx , where α is the learning
constant. It is noted that if the slope is negative, the xnext is greater than xcurrent and
vice versa. In case of higher dimension, the iterative equation to obtain the minima
point is represented as xnext = xcurrent −∇f, where ∇f is the gradient of the function
f . Note that x used in this paragraph is the unknown variable/vector to be optimized
using steepest-descent algorithm (Fig. 5.10).
The steepest-descent algorithm to optimize h in (5.14) is obtained by computing
the gradient of (5.14) as follows. Let x = [xn xn−1 · · · xn−N+1]T and (5.14) is written
as the following:
ε = E((Yn −
N−1

k=0
hk Xn−k)2) = E((Yn −hT x)2)
(5.19)
Fig. 5.10 Illustration of the
steepest-descent algorithm

160
5
Statistical Signal Processing
Differentiating (5.19) with respect to h, we get the following:
∇ε = E(−2(Yn −hT x)x)
∇ε = E(−2enx) = −2E(enx)
Thus the steepest-descent iterative equation is as follows.
ht+1 = ht −1
2α ∇ε = ht + αE(enx)
(5.20)
where t is the tth iteration. The difference between the ht+1 −hoptimum is the error
vector (Δt+1), which denote how the vector attained in the (t + 1)th iteration (ht+1)
is deviated from the hoptimum.
ht+1 −hoptimum
= ht + αE(enx) −hoptimum
= ht + αE((Yn −ht
T x)x) −hoptimum
= ht + αE((Yn −xT ht)x) −hoptimum
= ht + α(γyx −Γxht) −hoptimum
= (I −αΓx)ht + αΓxhoptimum −hoptimum = (I −αΓx)ht −(I −αΓx)hoptimum
= (I −αΓx)(ht −hoptimum)
Let the deviation in the tth iteration is represented as Δt = ht −hoptimum.
Δt+1 = (I −αΓx)Δt
(5.21)
⇒Δt+1 = (E I E H −αE DE H)Δt
(5.22)
⇒Δt+1 = E(I −αD)E HΔt
(5.23)
⇒E HΔt+1 = (I −αD)E HΔt
(5.24)
Let Ut = E HΔt+1 and hence Ut is solved as given below.
Ut+1 = (I −αD)Ut
(5.25)
Ut = (I −αD)tU0
(5.26)
The squared magnitude of the vector E HΔt is computed as
(E HΔt)H(E HΔt) = ΔH
t E E HΔt = ΔH
t Δt
Itisnotedthatthemagnitudeofthevector E HΔt isidenticalwiththatofthevectorΔt.

5.3 Adaptive Filter
161
Hence minimizing the kth element of the error vector Δt is identical with mini-
mizing the kth element of the vector Ut, i.e., Ut(k).
Ut(k) = (1 −αλk)tU0(k)
If |1−αλk| ≤1, Ltt→∞(1−αλk)tU0(k) = 0. This implies that for the convergence,
α is chosen satisfying 0 ≤α ≤
1
λk for k = 0 · · · N −1, which in further implies that
the α satisﬁes 0 ≤α ≤
1
λmax .
It is observed from (5.20) that the update equation requires E(enx), which in
further requires, joint density function of the random variable X. This is rarely
available in the real time applications. Hence the estimate of the E(enx) is used. It
is computed as follows. Considering the L outcomes of the along the process such
that en, en−1, · · · en−L+1 and the corresponding random vectors are represented as
xn, xn−1, · · · xn−L+1 are used to estimate E(enx) as follows.
E(enx) =
l=L−1

l=0
en−lxn−l
For the special case whenl = 0, the estimate is computed as enxn = enx. The iterative
equation (5.20) is modiﬁed by replacing the actual Expectation with the estimation
to obtain the least mean square (LMS) algorithm. Thus the iterative equation for the
LMS algorithm is given as the following:
ht+1 = ht + αenx
(5.27)
It is noted that the Expectation of the estimate enx gives the actual gradient used in
the steepest-descent algorithm. Hence the estimate is unbiased with the value used
in the steepest-descent algorithm. We also understand intuitively that as an average
LMS algorithm behaves like the steepest-descent algorithm. Taking Expectation on
both sides of (5.27), we get the following:
E(ht+1) = E(ht) + αE(enx)
= E(ht) + αE((Yn −hT
t x)x)
= E(ht) + αγyx −αΓx E(ht)
The difference between ht and hoptimum is represented as Δt. i.e,
Δt+1 = ht+1 −hoptimum
⇒E(Δt+1) = E(ht+1) −E(hoptimum) = E(ht+1) −hoptimum

162
5
Statistical Signal Processing
Fig. 5.11 Demonstration of adaptive ﬁlter to identify the unknown system
From (5.23), we get the following:
E(Δt+1) = E(ht) + αγyx −αΓx E(ht) −hoptimum
E(Δt+1) = E(Δt) + αΓxhoptimum −αΓx E(ht)
E(Δt+1) = E(Δt) + αΓx(hoptimum −E(ht))
E(Δt+1) = E(Δt) −αΓx E(Δt)
E(Δt+1) = (I −αΓx)E(Δt)
E(Δt+1) = (vvH −αvΛvH)E(Δt)
E(Δt+1) = (v(I −αΛ)vH)E(Δt)
vHE(Δt+1) = (I −αΛ)V H E(Δt)
Let uH = vHE(Δt+1), we get the following:
uH
t+1 = (I −αΛ)uH
t
(5.28)
⇒uH
t+1 = (I −αΛ)tuH
0
(5.29)
The kth element of the vector uHt+1 is represented as uH
t+1,k = (1 −αλk)tuH0,k,
where uH0,k is the kth element of the vector uH
0 . The value of uH
t+1,k tends to zero
as t tends to ∞for every k, provided |αλk| ≤1. This implies |α| ≤
 1
λk
 for all
k. It is also important to note that the random vector h and x are assumed as the
independent random vector. Figure 5.11 demonstrates the adaptive ﬁlter used to
identify the unknown system.

5.3 Adaptive Filter
163
%adapsysiden.m
%Adaptive filter
%Identifying the unknown system
%Generation of signal
load speechdata
X=speechdata(2000:1:4999)
Ts=1/8000;
%Let the sysem be represented as h
h=rand(1,11);
%Frequency response of the system under consideration
%Noisy observation is given as the following:
Y=conv(X,h);
%System model using LMS algorithm
X1=reshape(X,100,30);
C=cov(X1);
[E,D]=eig(C);
lambda=diag(D);
lambdamax=lambda(30);
%Fix the learning constant
alpha=1/lambdamax;
%Actual LMS algorithm starts
hlms=rand(1,11);
E=[];
for n=11:1:length(X)
out=X(n-10)*hlms(11)+X(n-9)*hlms(10)+X(n-8)*hlms(9)+ ...
X(n-7)*hlms(8)+ X(n-6)*hlms(7)+ X(n-5)*hlms(6)+...
X(n-4)*hlms(5)+X(n-3)*hlms(4)+X(n-2)*hlms(3)+...
X(n-1)*hlms(2)+X(n)*hlms(1);
error= Y(n)-out;
E=[E error];
hlms=hlms+alpha*error*X(n);
end
Z=conv(X,hlms);
figure(1)
subplot(2,1,1)
plot(X,’r’)
hold on
plot(Y,’g’)
hold on
plot(Z,’b’)
subplot(2,1,2)
plot(X(1:1:100),’r’)
hold on
plot(Y(1:1:100),’g’)
hold on
plot(Z(1:1:100),’b’)
5.3.2
Filtering Noise
Consider the random process Yn = Xn + Wn, where Xn and Wn are independent.
We would like to estimate Wn by ﬁltering the Yn−l using the linear ﬁlter hk. The
ﬁlter coefﬁcients are optimized using steepest-descent algorithm by minimizing the
objective function as described below:

164
5
Statistical Signal Processing
J = E((Xn −Xn)2)
(5.30)
E((Xn −
k=N−1

k=0
hkYn−k−l)2)
(5.31)
Minimizing J is equivalent to minimizing E((Yn−	k=N−1
k=0
hkYn−k−l)2) as described
below:
E((Yn −
k=N−1

k=0
hkYn−k−l)2)
= E((Xn + Wn −
k=N−1

k=0
hkYn−k−l)2)
= E((Xn −
k=N−1

k=0
hkYn−k−l)2) + E((Wn)2) −2E((Wn −
k=N−1

k=0
hkYn−k−l)Wn)
The second term is constant Consider the third term.
E((Wn −
k=N−1

k=0
hkYn−k−l)Wn)
(5.32)
= E(WnWn) −E(
k=N−1

k=0
hk(Xn−k−l + Wn−k−l)Wn)
(5.33)
= E(W 2
n ) −E(
k=N−1

k=0
hk(Xn−k−lWn)) + E(Wn−k−lWn)
(5.34)
As Xn and Wn are independent with E(Wn) = 0, E(	k=N−1
k=0
hk(Xn−k−lWn)) = 0.
Also considering E(Wn−k−lWn) = 0, we get the third term as constant as E(W 2
n ).
Thus the optimal h(k) that minimizes E((Xn −	k=N−1
k=0
hkYn−k−l)2) is equivalent to
minimizing E((Yn −	k=N−1
k=0
hkYn−k−l)2). Thus the adaptive ﬁlter to ﬁlter the noise
is constructed as given in the Fig. 5.12 and the corresponding illustration is given in
Fig.5.13.
Fig. 5.12 Adaptive ﬁlter
constructed to ﬁlter the
additive noise

5.3 Adaptive Filter
165
Fig. 5.13 Demonstration of noise removal using the adaptive ﬁlter
%adapfiltnoise.m
f=1;
Ts=1/100;
n=0:1:1999;
X=sin(2*pi*f*n*Ts);
Y=X+0.1*randn(1,length(X));
Z=0.1*[randn(1,10) Y ];
hadapt=rand(1,11);
for n=12:1:length(Y)
output=hadapt(11)*Z(n-10)+hadapt(10)*Z(n-9)+hadapt(9)*Z(n-8)+...
hadapt(8)*Z(n-7)+hadapt(7)*Z(n-6)+hadapt(6)*Z(n-5)+hadapt(5)*Z(n-4)+
hadapt(4)*Z(n-3)+hadapt(3)*Z(n-2)++hadapt(2)*Z(n-1)+hadapt(1)*Z(n);
error=output-Y(n);
hadapt=hadapt-0.1*error*Z(n);
end
OUTPUT=[];
for n=12:1:length(Y)
output=hadapt(11)*Z(n-10)+hadapt(10)*Z(n-9)+hadapt(9)*Z(n-8)+...
hadapt(8)*Z(n-7)+hadapt(7)*Z(n-6)+hadapt(6)*Z(n-5)+hadapt(5)*Z(n-4)+
hadapt(4)*Z(n-3)+hadapt(3)*Z(n-2)++hadapt(2)*Z(n-1)+hadapt(1)*Z(n);
OUTPUT=[OUTPUT output];
end
figure(2)
plot(X(900:1:1500),’r’)
hold on
plot(Y(900:1:1500),’g’)
plot(OUTPUT(900:1:1500),’b’)

166
5
Statistical Signal Processing
5.4
Spectral Estimation
5.4.1
Eigen Decomposition Method for Spectral Estimation
Let the outcome of the discrete random process with linear combinations of P com-
plex single tone signals is represented as the following:
xn =
m=P

m=1
Ame( j2π fmn −φm)
(5.35)
where Am is the coefﬁcient of the complex single tone signal with frequency fm and
φm is uniformly distributed between 0 to 2π. The auto-correlation of the discrete
random process xn represented as Rx(k) is computed as follows.
Rx(k) = E(xn+kx∗
n)
⇒Rx(k) = E(
r=P

r=1
Are j(2π fr(n+k)−φr)
s=P

s=1
A∗
se−j(2π fs(n)−φs))
⇒Rx(k) = E(
r=P

r=1
s=P

s=1
Ar A∗
se j(2π fr(n+k)−φr)e−j(2π fs(n)−φs))
⇒Rx(k) = E(
r=P

r=1
s=P

s=1
Ar A∗
se j(2π fr(n+k)−φr)e−j(2π fs(n)−φs))
Consider the term with r ̸= s, E(Ar A∗
se j(2π fr(n+k)−φr)e−j(2π fs(n)−φs)) is computed
as follows.
E(Ar A∗
se j(2π fr(n+k)−φr)e−j(2π fs(n)−φs))
⇒E(Ar A∗
se j(2π fr(n+k)−φr−2π fs(n)+φs))
Let φ = φs −φr is distributed as shown in the Fig.5.14. This implies the following:
E(Ar A∗
se j(2π fr(n+k)+φ−2π fs(n)))
= E(Ar A∗
se j(2π( fr−fs)n+2π frk+φ))
This is solved by obtaining the expectation by ﬁxing φ and followed by computing
expectation over φ (for r ̸= s) as follows.
Ar As

 2π
−2π
e j(2π( fr−fs)n+2π frk+φ)dφ = 0

5.4 Spectral Estimation
167
Considering the term with r = s, we get the following:
E(Ar A∗
r e j(2π fr(n+k)−φr)e−j(2π fr(n)−φr))
⇒|Ar|2e j(2π frk)
Thus Rx(k) computed for the discrete random process Xn in (5.35) is obtained as
Rx(k) =
m=P

m=1
|Am|2e j(2π fmk)
(5.36)
It is also noted that discrete random process xn in (5.35) is the W.S.S. Random
process. Given the typical values for f ′
ms, Rx(k)′s, and P, we obtain |Am|2 using
(5.36).
The random process xn which is the linear combinations of complex single tone
frequency signals with different phase and amplitude can be generated as
xn = −
m=P

m=1
vmxn−m
(5.37)
Let us deﬁne the random process yn = xn +wn, where wn is the additive white noise
with variance σ 2
w. The signal space and the noise space are obtained as follows:
m=P

m=0
vmxn−m = 0
(5.38)
⇒
m=P

m=0
vm(yn−m −wn−m)
⇒
m=P

m=0
vm yn−m =
m=P

m=0
vmwn−m
⇒[yn yn−1 · · · yn−P][v0 v1 · · · vP]T = [wn wn−1 · · · wn−P][v0 v1 · · · vP]T
Let y = [yn yn−1 · · · yn−P]T , w = [wn wn−1 · · · wn−P]T and v = [v0 v1 · · · vP]T
and x = [xn xn−1 · · · xn−P]T , we get the following:
yT v = wT v
yyT v = ywT v
Taking Expectations on both sides (Note that the mean of the random vectors y
and w are identically zero)

168
5
Statistical Signal Processing
Cyv = Cywv
Cyv = σ 2
wIv
Cyv = σ 2
wv
Thus the vector v (with ﬁrst element normalized to 1) is the Eigen vector of the
matrix Cy corresponding to the Eigen value σ 2
w. The random vector y = x + w. This
implies the following:
Cy = Cx + Cw
(5.39)
Cx + σ 2
wI
(5.40)
From (5.35), we represent x = 	i=P
i=1 Aie j2π fin−φisi, where
si = [1 e−j2π fi e−j4π fi · · · e−j2Pπ fi ]T
(5.41)
Thus we understand that the rank of the symmetric matrix Cx is P (note that the
size of the matrix is (P + 1) × (P + 1)) and hence we get P nonzero Eigenvalues
(λ1, λ2, · · · λP) and 1 zero Eigenvalue. Thus the Eigen values of the matrix Cy are
given as λ1 + σ 2
w, λ2 + σ 2
w, · · · λP + σ 2
w, σ 2
w. Let the corresponding Eigenvectors
are represented as e1, e2, · · · eP+1. From (5.39) and (5.40), we understand that the
elements of the Eigenvector of the matrix Cy corresponding to the Eigenvalue σ 2
w
satisfy (5.40). The space spanned by the Eigenvectors e1, e2, · · · eP is the signal
space and the space spanned by the Eigenvector eP+1 is the noise space. Note that
the Eigenvector eP+1 satisﬁes CxeP+1 = 0. It can also be interpreted as the column
space of the matrix Cx forms the signal space and the null space of the matrix Cx
forms the noise space. It is also understood, the Eigenvector eP+1 corresponding to
the eignvalue 0 of the matrix Cx is identical with that of the Eigenvector of the matrix
Cy corresponding to the Eigenvalue σ 2
w and hence eP+1 = v. Thus the Eigenvector
v, which is in the noise space is orthogonal to the all the vectors in the signal space.
Hence si Hv = 0 for all i. i.e,
k=P

k=0
e−j2πk fi vk = 0
(5.42)
where vk is the (k + 1)th element of the vector v with v0 = 1.
5.4.2
Pisarenko Harmonic Decomposition
In (5.35), xn is viewed as the prediction value at the nth sample instant using the
linear combinations of previous P samples. The difference between the actual value
and the predicted value is represented as en = xn + 	m=P
m=1 vmxn−m. Assuming the

5.4 Spectral Estimation
169
Fig. 5.14 Probability
density function of the
random variable φ
en is the input to the system and xn as the corresponding output of the system (AR
system), we get the recursive system function as given below (Fig. 5.14).
X(z)
E(z) =
1
1 + 	m=P
m=1 vmz−m
From (5.37) and (5.40), we understand that the elements of the Eigenvector with
leading element 1 of the matrix Cy corresponding to the Eigenvalue σ 2
w satisﬁes the
polynomial 1 + 	m=P
m=1 vmz−m = 0. Thus the method of estimating the frequencies
are summarized below:
1. Assuming that the given signal is the linear combination of p number of complex
single tone signals with additive noise.
2. Estimate the covariance matrix Cy of size (p + 1) × (p + 1).
3. Obtain the lowest Eigenvalue and the corresponding vector, with the ﬁrst element
made it as 1. Let it be v.
4. Formulate the polynomial 1 + 	m=P
m=1 vmz−m and the P roots of this polynomial
are treated as the estimate of P single tone frequencies present in the given noisy
signal.
5.4.3
MUSIC (Multiple Signal Classiﬁcation) Method
Suppose that the covariance matrix is constructed with size m × m with m > P, the
dimension of the signal space is P. The Eigen vectors corresponding to the largest
P Eigenvalues correspond to the signal space. The remaining Eigen vectors corre-
sponding to m −P Eigenvalues correspond to the noise space. Let the Eigen vectors
corresponding to the lowest m −P Eigenvalues are represented as vP+1vP+2 · · · vm.
The ﬁrst element of the individual Eigen vectors are made 1. The Eigen vectors vk
with k = P + 1 · · · m satisfy the polynomial 1 + 	r=m−1
r=1
vk,re−j2π
f
f s r = 0, where
vk,r is the rth element of the kth Eigen vector. From (4) in Pisarenko Harmonic De-
composition technique, the roots of the polynomial 1 + 	r=m−1
r=1
vk,re−j2π
f
f s r = 0

170
5
Statistical Signal Processing
are the estimate of the P single tone frequencies present in the given noisy signal,
if m = P + 1. Hence the estimate of the P single tone frequencies present in the
given noisy signal are also obtained by identifying the values for f (frequencies)
corresponding to the ﬁrst P largest magnitude of the polynomial given below:
1
	m
k=P+1
(1 + 	r=m−1
r=1
vk,re−j2π
f
f s r)

2 .
(5.43)
5.4.4
ESPRIT (Estimation of Signal Parameters Via
Rotational Invariance Technique)
Consider the following with P = 2.
x = [xn xn−1 xn−2]T
y = x + w
z = [xn+1 xn xn−1]T + [wn+1 wn wn−1]T
Using x = 	i=2
i=1 Aie( j2π fin−φi)si, we get the following:
x = [s1 s2]
 A1e−jφ1e j2π f1n
A2e−jφ1e j2π f2n

= Sp
where s1 and s2 are given by (5.41). Similarly, [xn+1 xn xn−1]T is computed as fol-
lows:
[xn+1 xn xn−1]T = S
 e j2π f1
0
0
e j2π f2

p
Sφp
Let w1 = [wn+1 wn wn−1]T Rewriting the expression as the following:
y = Sp + w
z = Sφp + w1
⇒Cy = E(yyH) = E((Sp + w)(Sp + w)H)
= SE(P P H)SH + E(w(w)H)
= SΓ SH + σ 2
wI
We also compute Cyz as follows:

5.4 Spectral Estimation
171
E((Sp + w)(Sφp + w1)h)
= SE(P P H)(φ)HSH + E((w)(w1)H)
= SΓ φHSH + Γw
Let A = Cy −σ 2
wI = SΓ SH and B = Cyx −Γw = SΓ φHSH. It is noted that SΓ SH
is the covariance matrix computed for the vector x and hence the rank of the matrix
SΓ SH is 2. It is also noted that the rank of the matrix SΓ φHSH is 2.
Consider the following:
A −λB
= SΓ SH −λSΓ φHSH
= SΓ (I −λφH)SH
The set of vectors vi satisfying (A−λB)vi = 0 are the generalized Eigen vectors.
The size of the matrix (A −λB) is 3 × 3 and it’s rank is 2. As the rank of the matrix
A is 2, there exist the generalized Eigen vector v1 corresponding to the Eigenvalue
λ = 0. To obtain the generalized Eigen vector, we need to choose value for λ that
makes the rank of the matrix (A −λB) 2. If λ = e j2π f1, we represent the matrix
SΓ (I −λφH)SH as follows.
SΓ
0
0
0 1 −e j2π f1e−j2π f2

SH
Fig. 5.15 Generated signal to demonstrate eigen decomposition method for spectral estimation

172
5
Statistical Signal Processing
Fig. 5.16 Illustration of Pisarenko method for spectral estimation
Fig. 5.17 Illustration of Pisarenko method for spectral estimation (continued)
Thus there exists the generalized Eigen vectors v2 and v3 corresponding to the Eigen-
values, λ = e j2π f1 and λ = e j2π f2. Thus the procedure to estimate the frequencies
using the ESPRIT technique is summarized below.
• Estimate the matrix A and B.
• Compute (A −λB).
• Compute the generalized Eigenvalues (with magnitude 1) of the matrix (A −λB),
i.e., (A −λB)v = 0.

5.4 Spectral Estimation
173
Fig. 5.18 Illustration of MUSIC algorithm
Fig. 5.19 Illustration of ESPRIT algorithm
• Thus the obtained Eigenvalues corresponds to the estimated frequencies. Figures
5.15, 5.16, 5.17, 5.18, 5.19 demonstrates the ESPRIT algorithm.
%pisarenko-music-esprit.m
%Demonstration of Pisarenko Harmonic Decomposition method,
%MUSIC
and ESPRIT algorithm
%Generation of linear combinations of sinusoidal signals

174
5
Statistical Signal Processing
%Y=X+W model
close all
%Input frequency in Hz
f1=10;
f2=15;
f3=20;
f4=25;
F=[f1 f2 f3 f4];
%Amplitude of the input signal
A1=1;
A2=2;
A3=3;
A4=4;
A=[A1 A2 A3 A4];
n=0:1:99998;
fs=80;
ts=1/fs;
%Input frequency in radians
W=(F/fs)*2*pi
%Input
phi1=rand*2*pi;
phi2=rand*2*pi;
phi3=rand*2*pi;
phi4=rand*2*pi;
Y=A1*sin(2*pi*f1*n*ts-phi1)+A2*sin(2*pi*f2*n*ts-phi2)+...
A3*sin(2*pi*f3*n*ts-phi3)+...
A4*sin(2*pi*f4*n*ts-phi4)+sqrt(1)*randn(1,length(n));
figure
subplot(2,1,1)
plot(Y)
title(’Summation of three sinusoidal signals with additive gaussian noise’)
subplot(2,1,2)
plot(linspace(0,2*pi,length(Y)),abs(fft(Y)))
title(’Corresponding spectrum in frequency domain’)
%Pisarenko Harmonic Decomposition Method
DATA=reshape(Y,9,11111);
C=cov(DATA’,1);
[E,D]=eig(cov(DATA’,1));
%Eigen vector in the null space of columns of the covariance matrix C
V=E(:,1);
Z=roots(V);
freqestimation=angle(Z(1:2:length(Z)));
freqestimation=mod(freqestimation,pi)
figure
bar([sort(unwrap(W));sort(unwrap(freqestimation))’]’)
title(’Actual and the Estimatated frequencies using ...
Pisarenko Harmonic Decomposition Method’)
MATRIX=[];
for i=1:1:4
MATRIX=[MATRIX; cos(i*W(1)) cos(i*W(2)) cos(i*W(3)) cos(i*W(4))];
end
temp=C(1,:);
GAMMAYY=temp(2:1:5);
powestimation=pinv(MATRIX)*GAMMAYY’
ampestimation=sqrt(abs(2*powestimation));
figure(2)
bar([sort(A);sort(ampestimation)’]’)
title(’Actual and the Estimatated amplitudes using ...

5.4 Spectral Estimation
175
Pisarenko Harmonic Decomposition Method’)
%Multiple Signal Classification (MUSIC) algorithm
Y1=Y(1:1:90000);
DATA=reshape(Y1,9,10000);
C=cov(DATA’,1);
[E,D]=eig(cov(DATA’,1));
%Eigen vector in the null space of columns of the covariance matrix C
FINAL=0;
for k1=1:1:1
temp1=E(:,k1);
TEMP=[];
for f=0:1:39
s=0;
for k2=0:1:length(temp1)-1
s=s+temp1(k2+1)*exp(-j*(2*pi*f/fs)*k2);
end
TEMP=[TEMP s];
end
FINAL=FINAL+(abs(TEMP).ˆ2);
end
FINAL=1./FINAL;
figure(3)
plot(log(FINAL))
title(’Four peaks corresponds to the estimated frequencies’)
%ESPRIT(Estimation of signal parameters via rotational invariance techniques)
DATA=Y(1:1:99900);
DATAY=reshape(DATA,9,11100);
DATAY=DATAY(:,2:1:size(DATAY,2));
DATA1=[0 Y(1:1:99900)];
DATA1=DATA1(1:1:99900);
DATAZ=reshape(DATA1,9,11100);
DATAZ=DATAZ(:,2:1:size(DATAZ,2));
RY=cov(DATAY’,1);
[E,D]=eig(RY);
sigmaw2=1;
RYZ=cov([DATAY; DATAZ]’,1);
RYZ=RYZ(1:1:9,10:1:size(RYZ,2));
CYY=RY-diag(ones(1,size(RY,1))*sigmaw2);
Q=[diag(ones(1,size(CYY,2))); zeros(1,size(CYY,2))];
Q=[zeros(size(Q,1),1) Q];
Q=Q(1:1:9,1:1:9);
CYZ=RYZ-Q*sigmaw2;
[E,D]=eig(CYY,CYZ);
[P,Q]=sort(abs(abs(diag(D))-1));
D1=diag(D);
freqestimation=angle(D1(Q(1:2:8)));
freqestimation=mod(freqestimation,pi)
figure(4)
bar([sort(unwrap(W));sort(unwrap(freqestimation))’]’)
title(’Actual and the Estimated frequencies using ESPRIT algorithm’)

Chapter 6
Selected Applications in Multidisciplinary
Domain
6.1
Multipath Transmission in Wireless Communication
Let the signal e j2π f t be transmitted through the multi-path channel. The received
signal corresponding to the jth path is obtained as β j(t)e j2π f (t−τ j). The channel is
assumed as the linear and hence the output (received signal) corresponding to the
individual paths are combined to obtain the ﬁnal output as given below.
y(t) =
j=J

j=1
β j(t)e j2π f (t−τ j(t))
The response of the time-varying system described by the transfer function H( f, t)
to the eigensignal e j2π f t is given as y(t) = H( f, t)e j2π f t. Hence H( f, t) is identiﬁed
as the following:
H( f, t) =
j=J

j=1
β j(t)e−j2π f τ j(t)
⇒h(τ, t) =
j=J

j=1
β j(t)δ(τ −τ j(t))
The h(τ, t) is reconstructed using the samples of h(τ, t) as described below. Let
the signal x(t) be sampled using the sampling frequency Fs to obtain the sequence
x(nTs). The signal x(t) is reconstructed back using the discrete samples as described
below.
x(t) =
k=∞

k=−∞
x(kTs)sinc( t
Ts
−k)
© Springer International Publishing AG 2018
E.S. Gopi, Multi-Disciplinary Digital Signal Processing,
DOI 10.1007/978-3-319-57430-1_6
177

178
6
Selected Applications in Multidisciplinary Domain
The response of the time-varying channel to the input signal x(t) is obtained as
y(t) =
 ∞
−∞
h(τ, t)x(t −τ)
y(t) =
 ∞
−∞
j=J

j=1
β j(t)δ(τ −τ j(t))
k=∞

k=−∞
x(kTs)sinc(t −τ
Ts
−k)
y(t) =
j=J

j=1
β j(t)
k=∞

k=−∞
x(kTs)sinc(t −τ j(t)
Ts
−k)
Let the received signal y(t) be sampled to obtain the discrete sequence y(nTs) that
is obtained as follows:
y(nTs) =
j=J

j=1
k=∞

k=−∞
β j(nTs)x(kTs)sinc(nTs −τ j(nTs)
Ts
−k)
y(nTs) =
k=∞

k=−∞
x(kTs)
j=J

j=1
β j(nTs)sinc(n −k −τ j(nTs)
Ts
)
Let m = n −k, we get the following.
y(nTs) =
m=∞

m=−∞
x((n −m)Ts)
j=J

j=1
β j(nTs)sinc(m −τ j(nTs)
Ts
)
y(n) =
m=∞

m=−∞
xn−mhn,m
Thus hn,m is the linear time-varying discrete wireless channel and is given as the
following.
hm,n =
j=J

j=1
β j(nTs)sinc(m −τ j(nTs)
Ts
)
(6.1)
%timevaryingfiltercoef.m
%Let the number of taps be 10;
%Let the sampling frequency be 4000000 Hz.
for n=0:1:1000
for m=1:1:11
for j=1:1:100
h(m,n+1)=((rand*2-1)/2)*sinc(m-((rand*2-1)/2)/4000);
end
end
end
figure

6.1 Multipath Transmission in Wireless Communication
179
for i=1:1:11
subplot(4,3,i)
hist(h(i,:))
end
The snapshots of the time-varying discrete channel at various time instants n and
the corresponding histogram plots are illustrated in Figs.6.1 and 6.2 respectively.
Fig. 6.1 Typical time-varying ﬁlter coefﬁcients
Fig. 6.2 Histogram plot of 11 ﬁlter coefﬁcients of the time-varying ﬁlter (refer Fig.6.1)

180
6
Selected Applications in Multidisciplinary Domain
6.2
Cyclic Preﬁx in Orthogonal Frequency Division
Multiplexing (OFDM)
Let the sequence to be transmitted through the channel be represented as [x0 x1 x2
x3 · · · x6 x7] and the impulse response of the channel be represented as h0, h1, h2.
In the case of OFDM, we divide the input sequence into blocks (let us consider
the block of four samples) and IFFT of the individual blocks are taken and are
transmitted through the channel. Let the sequence after taking block IFFT be rep-
resented as [X0 X1 X2 X3 · · · X6 X7]. In this [X0 X1 X2 X3] is the ﬁrst block and
the [X4 X5 X6 X7]. The output sequence corresponding to the block transmission
without cyclic preﬁx is obtained as follows.
y0 = h0X0 + h1X−1 + h2X−2, y1 = h0X1 + h1X0 + h2X−1, y2 = h0X2 + h1X1 + h2X0,
y3 = h0X3 + h1X2 + h2X1, y4 = h0X4 + h1X3 + h2X2, y5 = h0X5 + h1X4 + h2X3,
y6 = h0X6 + h1X5 + h2X4, y7 = h0X7 + h1X6 + h2X5, y8 = h0X7 + h1X6 + h2X5,
y9 = h0X8 + h1X7 + h2X6
Theﬁrstblockandthesecondblockaftercyclicpreﬁxberepresentedasthefollowing.
[X2 X3 X0 X1 X2 X3] is the ﬁrst block and the [X6 X7 X4 X5 X6 X7]. The output
sequence corresponding to the block transmission after cyclic preﬁx are obtained as
follows.
y0 = h0X2 + h1X−1 + h2X−2, y1 = h0X3 + h1X2 + h2X−1, y2 = h0X0 + h1X3 + h2X2,
y3 = h0X1 + h1X0 + h2X3, y4 = h0X2 + h1X1 + h2X0, y5 = h0X3 + h1X2 + h2X1,
y6 = h0X6 + h1X3 + h2X2, y7 = h0X7 + h1X6 + h2X3, y8 = h0X4 + h1X7 + h2X6,
y9 = h0X5 + h1X4 + h2X3, y10 = h0X6 + h1X5 + h2X4, y11 = h0X7 + h1X6 + h2X5,
Consider the circular convolution of [X0 X1 X2 X3] with the channel impulse
response, we get the following.
p0 = h0X0 + h1X3 + h2X2, p1 = h0X1 + h1X0 + h2X3, p2 = h0X2 + h1X1 + h2X0,
p3 = h0X3 + h1X2 + h2X1
Comparing the equations, we get the following.
p0 = y2, p1 = y3, p2 = y4, p3 = y5
Similarly, let q be the sequence obtained by computing the circular convolution of
[X6 X7 X4 X5 X6 X7] and the ﬁlter coefﬁcients, we get the following.
q0 = y8, q1 = y9, q2 = y10, q3 = y11
Actual transmission through the channel involves linear convolution of the sequence
with the ﬁlter co-efﬁcients. But we observe that when transmission is done with
cyclic preﬁx, the sequence p and q are obtained as the circular convolution of the

6.2 Cyclic Preﬁx in Orthogonal Frequency Division Multiplexing (OFDM)
181
Fig. 6.3 Demonstration of importance of cyclic preﬁx in OFDM
individual blocks with the ﬁlter coefﬁcient. Let the DFT of the ﬁlter coefﬁcients h
and p be represented as the sequence Hand P = xblock1H respectively. Hence we
obtain the transmitted sequence corresponding to block 1 as P
H =
xblock1H
H
= xblock1.
Similarly the transmitted sequence corresponding to block 2 is obtained as
P
H =
xblock2H
H
) = xblock2. We simply take DFT of the received sequence and divide the
individual samples with the corresponding DFT of the ﬁlter coefﬁcients (after zero
padding).
This is equivalently saying that the ﬂat fading is achieved for the individual block
(Fig. 6.3).

182
6
Selected Applications in Multidisciplinary Domain
%cyclicprefix.m
%Cyclic prefix in OFDM
%Number of blocks=It is seen outputpart1 and outputpart2 are identical. This demonstrates
%the need for cyclic prefix in OFDM
for i=1:1:5
xblock{i}=(i-1)*8+1:1:(i-1)*8+8;
xblockcp{i}=[xblock{i}(7) xblock{i}(8) xblock{i}];
end
h=[1 2 3];
%Linear convolution with xblockcp
output1=conv([cell2mat(xblockcp)],h);
output1=output1(1:1:50);
output1=reshape(output1,10,5);
outputbefore=reshape(output1,1,size(output1,1)*size(output1,2))
%After ignoring first two columns
output1=output1(3:1:size(output1,1),:);
outputpart1=reshape(output1,1,40)
%Circular convolution with xblock
for i=1:1:5
temp{i}=ifft(fft(xblock{i}).*fft(h,8))
end
outputpart2=cell2mat(temp)
figure
subplot(5,1,1)
stem(cell2mat(xblock))
title(’input sequence without cyclic prefix’)
subplot(5,1,2)
stem(cell2mat(xblockcp))
title(’input sequence after cyclic prefix’)
subplot(5,1,3)
stem(outputbefore)
title(’Received sequence without removing the first two samples in each block’)
subplot(5,1,4)
stem(outputpart1)
title(’Received sequence after removing the first two samples in each block’)
subplot(5,1,5)
stem(outputpart2)
title(’Sequence obtained using circular convolution’)
6.3
Projection Slice Theorem for Computed
Tomography Imaging
It is the method of obtaining the cross section of the object with the array of sources
of X-ray and the array of detectors kept at the other side of the object. It is equivalent
to obtaining the integration along the lines across the objects to obtain 1D signals.
This is repeated by rotating the object by an angle θ and line integration is done
to obtain to 1D signal. This is repeated by rotating the object by an angle θ that
varies from 0 to 360◦. Thus number of 1D signals obtained are 360◦
theta . This is known
as Radon transformation. The method of getting the cross section using these 1D
signals are known as Inverse Radon Transformation.
Let the cross-section be assumed as the 2D continuous image data represented as
f (x, y) (with origin in the middle). Set of parallel lines drawn on the image f (x, y)
inclined with an angle θ are represented as xcos(θ) + ysin(θ) = k, where k is the
constant. Let θ = 0, then the set of parallel lines are represented as x + y = k for all k
ranges from −∞to ∞. These are the set of vertical lines drawn on the image f (x, y).

6.3 Projection Slice Theorem for Computed Tomography Imaging
183
The line integration computed along the lines of these images are represented as the
following.
r(θ,l) =
 ∞
−∞
 ∞
∞
f (x, y)δ(xcos(θ) + ysin(θ) −l)dxdy
The method of obtaining f (x, y) from r(θ,l) is the inverse Radon transformation as
described below. Taking Fourier transformation of the 2D image f (x, y) is computed
as the following.
F(U, V ) =
 ∞
−∞
 ∞
−∞
f (x, y)e−j2πxUe−j2πxV dxdy
Let r(l) be the function of l for the ﬁxed θ. The Fourier transformation of the function
r(l) is computed as R(L) as follows.
R(L) =
 ∞
−∞
r(l)e−j2π Lldl
R(L) =
 ∞
−∞
 ∞
−∞
 ∞
∞
f (x, y)δ(xcos(θ) + ysin(θ) −l)dxdye−j2π Lldl
R(L) =
 ∞
−∞
 ∞
−∞
f (x, y)e−j2π L(xcos(θ)+ysin(θ))dxdy
Let U = Lcos(θ) and V = Lsin(θ), we get the following.
R(L) =
 ∞
−∞
 ∞
−∞
f (x, y)e−j2πUx+V ydxdy
= F(U, V )
R(L) is the 1D function of L obtained from the 2D Fourier transformation of f (x, y)
with U = Lcos(θ) and V = Lsin(θ). Let us assume θ = 0, we get U = L and
V = 0. This the vertical line passing through zero in the 2D Fourier transforma-
tion. This corresponds to computing R(L) as the following. The value at R(L) is
equivalent to F(U, V ) at U = L and V = 0 with θ = 0. Thus the Fourier transfor-
mation of the random transformation r(l) is obtained as the functional values on the
2D Fourier transformation of f (x, y) along the line U = Lcos(θ), V = Lsin(θ),
which is equivalent to the line described by UCos(θ) + V sin(θ) −L. This is known
as Projection-slice theorem (refer Fig.6.4). Thus f (x, y) is computed as follows.
f (x, y) =
 ∞
−∞
 ∞
∞
F(U, V )e j2πUxe j2πV ydUdV

184
6
Selected Applications in Multidisciplinary Domain
Fig. 6.4 Illustration of projection-slice theorem
Let U = Lcos(θ) and V = Lsin(θ), we get
f (x, y) =
 2π
0
 ∞
0
F(Lcos(θ), Lsin(θ))|L|e j2π Lcos(θ)xe j2π Lsin(θ)ydLdθ
and hence
f (x, y) =
 π
0
 ∞
0
F(Lcos(θ), Lsin(θ))|L|e j2π Lcos(θ)xe j2π Lsin(θ)ydLdθ+
 2π
π
 ∞
0
F(Lcos(θ), Lsin(θ))|L|e j2π Lcos(θ)xe j2π Lsin(θ)ydLdθ
(6.2)
Let φ = θ −π, we get the following.

6.3 Projection Slice Theorem for Computed Tomography Imaging
185
−
 −π
0
 ∞
0
F(Lcos(φ + π), Lsin(φ + π))|L|e j2π Lcos(φ+π)xe j2π Lsin(φ+π)ydLdφ
=
 −π
0
 ∞
0
F(Lcos(φ), −Lsin(φ))|L|e−j2π Lcos(φ)xe−j2π Lsin(φ)ydLdφ
=
 π
0
 ∞
0
F(Lcos(θ), Lsin(θ))|L|e j2π Lcos(φ)xe j2π Lsin(φ)ydLdφ
= 1
2
 π
0
 ∞
−∞
F(Lcos(θ), Lsin(θ))|L|e j2π Lcos(φ)xe j2π Lsin(φ)ydLdφ
Combining ﬁrst and second term of (6.2), we get the following.
 π
0
 ∞
−∞
F(Lcos(θ), Lsin(θ))|L|e j2π Lcos(θ)xe j2π Lsin(θ)ydLdθ
Fortheﬁxedθ,
 ∞
−∞F(Lcos(θ), Lsin(θ))|L|e j2π Lcos(θ)xe j2π Lsin(θ)ydL istheinverse
radon transformation and is given as r(l, θ) ∗I FT (|L|) and hence
f (x, y) =
 π
0
I FT (R(L, θ) ∗|L|dL
(6.3)
6.4
Warped Discrete Fourier Transformation
for Speech Signal
DFT-based frequency components usually suffer with the leakage problem. Hence
warped DFT is used to view the frequency domain. In this technique, DFT is obtained
by sampling the DTFT in the warped frequency scale. The relationship between the
warped frequency wd and the conventional frequency w is given as the following,
where α is the warping parameter. Figure demonstrates the better resolution when
warped scale is used to compute samples of DTFT (Figs. 6.5 and 6.6).
cos(wd) + jsin(wd) =
cos(w) −sin(w) + α
1 −αcos(w) −αsin(w))
(6.4)
%WarpedDFT.m
load speech
%Warping parameter
wp=0.6;
x=SPEECH(5000:6023);
%w2 is the warped frequency
RES1=[];
RES2=[];
W1=[];
W2=[];
for w=-pi:0.01:0

186
6
Selected Applications in Multidisciplinary Domain
Fig. 6.5 Relationship between the conventional frequency and the warped frequency
Fig. 6.6 a DTFT computed using the conventional scale. b DTFT computed using the warped scale
w1=angle(cos(w)-j*sin(w));
w2=angle((cos(w)-j*sin(w)+wp)/(1-wp*(cos(w)-j*sin(w))));
s1=0;
s2=0;
for n=0:1:1023
s1=s1+x(n+1)*exp(-j*w1*n);
s2=s2+x(n+1)*exp(-j*w2*n);
end
RES1=[RES1 s1];
RES2=[RES2 s2];

6.4 Warped Discrete Fourier Transformation …
187
W1=[W1 w1];
W2=[W2 w2];
end
w=0:0.01:pi;
figure
subplot(2,1,1)
plot(W1,abs(RES1))
subplot(2,1,2)
plot(W2,abs(RES2))
figure
plot(W1,W2)
6.5
Nonuniform Discrete Fourier Transformation
for the Compressive Sensing Applications
There are applications involved in which the samples are captured in frequency
domain (Example:MRI imaging). It is the time-consuming process if all the DFT
points are captured in all the frequency points in the frequency. This can be circum-
vented by capturing the data only for few number of DFT points. This is known as
compressive sensing. Given M samples in the N-point DFT, N-point IDFT needs
to be computed. This is obtained by interpolating N-point DFT using the available
M-point DFT and IDFT is computed to obtain the samples in the time domain. Let
the rth sample of N-point DFT sequence of the sequence x be computed directly
as k=N−1
k=0
x(k)e
−j2πrk
N
. The values for r are randomly chosen between 0 to N −1
(say r1 r2 · · ·rM) and the number of samples are chosen as M < N. The continu-
ous spectrum X(w) computed using the M samples are computed using Lagrange
interpolation technique is as follows:
1. Obtain wrk = 2πrk
N
2. Compute X(w) = p=r
p=1 πq=r
q=1,q̸=p
(w−wrq)
wp−wrq X(wrp)
3. Sample X(w) to obtain the uniform sampling in frequency domain (DFT) with
equally spaced frequencies wk = 2πk
N
4. IDFT of the samples are computed to obtain the time sequence.
6.6
Nonuniform Sampling of Real Data
in Multidisciplinary Applications-Linear
Model for Regression
Consider the noisy observation of samples be represented as t′
ks corresponding to the
input tuning parameter xk. We would like to estimate the value for the random variable
t corresponding to the outcome of the random variable x. The estimate based on
MMAE, MMSE, and MAP are obtained as the conditional median, conditional mean,
and condition mode. The conditional mean estimate based on MMSE is represented
as the following.

188
6
Selected Applications in Multidisciplinary Domain
ˆt = E(t/X = x)
This can also be solved using the parametric method. In this technique, t is modelled
as follows.
t = w0φ1(x) + w1φ2(x) + · · · + wM−1φM−1 + ε
t = W T Φ(x) + ε
In this, ε is the random variable associated with noise. It is usually assumed as the
Gaussian distributed with mean zero and constant variance v. w0, w1, · · · wM−1 are
the unknown weight coefﬁcients to be estimated. φ is the kernel function. List of
commonly used kernel functions are listed below.
• Gaussian basis: φ j(x) = exp−
(x−μ j )2
2s2
• Sigmoidal basis:
1
1+exp−
x−μ j
s
Thus we have identiﬁed that t is the random variable with Gaussian distributed
with mean W T Φ(x) and variance v. Once we get the best estimate for w, to get the
estimate of t as the following.
ˆt = w0φ1(x) + w1φ2(x) + · · · + wM−1φM−1
(6.5)
The MMSE estimate for w is given as E(w/t). This needs the posterior density
function f (w/t), which is not usually available. Hence we estimate w by maximiz-
ing the posterior density function with prior density function assumed as uniform
distributed. The posterior density function is represented as follows:
f (w/t) = f (t/w)) f (w)
f (t)
6.6.1
Maximum Likelihood Estimation
In this f (w) is the prior density function (which is assumed as uniform distributed)
and f (t) is the density function associated with the random variable t (which does
not contribute to maximize the posterior density function). Hence w is estimated by
maximizing the likelihood function f (t/w). This estimation is known as maximum
likelihood estimation. Given the experimental exited values xk and the corresponding
observation tk, the weight vector W is obtained using the likelihood estimation as
follows. Each observation is viewed as the noisy observation and hence each obser-
vations are treated as the random variable with mean W T Φ(xk) and variance v. As
the observations are independent, we get the joint density function of the random
variables t1, t2,· · · tN (N is the number of observations) as the product of the individ-
ual density functions. It is noted that the joint density function is also Gaussian with

6.6 Nonuniform Sampling of Real Data in Multidisciplinary …
189
mean zero and covariance matrix vI, where I is the identity matrix. The optimal w
that maximizes this likelihood function is obtained by differentiating the likelihood
function with respect to w and equate to zero. Hence we obtain w as the following:
1. Construct the matrix M =
φ1(x1) φ2(x1)
· · ·
φM−1(x1)
φ1(x2) φ2(x2)
· · ·
φM−1(x2)
· · ·
· · ·
· · · · · ·
φ1(xN) φ2(xN)
· · ·
φM−1(xN)
2. Construct the vector t = [t1t2 · · · tN]T ].
3. The maximum likelihood estimate of column vector W is obtained W =
(MT M)−1MT t.
6.6.2
Least Square Estimation
We can construct the objective function to estimate W as the one that minimizes
||MW −t||2. This is known as least square technique. The solution to the least square
estimation is identical with that of the maximum likelihood estimate provided that
the noise ε is Gaussian. In other words, least square estimation is the maximum
likelihood estimate when noise is assumed as Gaussian.
6.6.2.1
M MSEerror = Bias2 + V ar + Noise
The estimate value of W depends upon the observation set. To see its consistent,
we estimate the vector W using different observation set. Let us assume Wk is the
weight vector estimated using the observation set Dk and the corresponding regres-
sion equation is obtained as W T
k Φ(X). We compute mean of all the curves (obtained
using the possible complete range for x); it is obtained using d number of data set
to obtain the mean regression curve.
1. If the individual curves are closer to each other, the variance associated with the
regression obtained using various data sets is said to be minimum. It is computed
for all the possible complete range for x. Let it be Var.
2. MMSE estimate of t, i.e., E(t/x) gives the curve when computed for the possible
complete range for x.
3. To see how far the mean curve obtained is closer to the one what we get using
MMSE. The mean squared error between the mean curve and the curve obtained
using MMSE is the Bias2.
4. It can be that MMSE error obtained using MMSE estimate, i.e. E(t/x) =
Bias2 + Var + Noise.

190
6
Selected Applications in Multidisciplinary Domain
6.6.2.2
Regularization Constant
When we have large number of observations, we divide them into many datasets and
the weight vector W is estimated corresponding the individual dataset and the mean
regression curve is declared as the ﬁnal equation. If we have limited dataset, we use
regularization factor to avoid over training. This is explained as follows.
It has been seen that maximum likelihood estimate with Gaussian noise model
ends up with the least square problem as ||MW −t||2. Now the objective function
is redeﬁned with the inclusion of regularization parameter λ as follows. ||MW −
t||2 + λ W T W
2
Differentiating (MW −t)T (MW −t) + λ W T W
2
with respect to W, we
get the following.
(MT M + λI)W = Mt
= W = (MT M + λI)−1t
It is noted that when λ = 0, the estimate is the maximum likelihood estimate (Assum-
ing noise as Gaussian) and also least square estimate (Assuming noise as gaussian).
Thus in practice, regularization is done with various λ and we choose λ corre-
sponding to the minimum value of Bias2 + Var (refer Fig.6.7).
6.6.3
Bayes Estimation
We estimate W by maximizing the likelihood function assuming that the prior den-
sity function is uniformly distributed. Suppose if we choose W to the Gaussian
distributed with mean zero (required to get sparse W) and covariance matrix uI,
where I is the identity matrix and u is the constant. The posterior density function
f (w/t) = f (t/w) f (w)
f (t)
is also Gaussian with mean MP covariance matrix SP given as
the following.
MP = 1
v SPMT t
(6.6)
S−1
P = 1
u + 1
v MT
(6.7)
As f (w/t) is Gaussian distributed, MAP (maximizing a posterior density function)
estimate of W is obtained as the mean vector of f (w/t), i.e., MP, which is given
as (MT M + v
u I)−1MT t. Thus the Bayes estimate is the regularized estimate with
regularization constant given as v
u , where v is the variance of the noise and u is the
variance of the circularly symmetric prior density function of w, i.e., f (w).

6.6 Nonuniform Sampling of Real Data in Multidisciplinary …
191
Fig. 6.7 Demonstration of importance of the regularization factor
6.6.4
Kernel Smoothing Function for Regression
Using the Bayes technique, we obtain the estimate for W as given as the conditional
mean vector 1
v SP MT t. Thus the estimate of t given the arbitrary x is given as the
following. (refer (6.4) for MP and Sect.6.6.1 for M).
ˆt = (1
v SPMT t)T Φ(x)
= 1
v (Φ(x))T (SPMT t)
=
k=N

k=1
1
v Φ(x)T SPΦ(xk)tk
Let k(x, xk) = 1
vΦ(x)T SPΦ(xk), we get the following.

192
6
Selected Applications in Multidisciplinary Domain
ˆt =
k=N

k=1
k(x, xk)tk
(6.8)
Given the arbitrary x, the estimate of t is obtained as the linear combinations of the
observation scalars tk (training set) and the corresponding kernel functional value
k(x, xk). The valid kernel function k(x1, x2) is the one that can be represented as the
following:
k(x1, x2) = 1
v Φ(x1)T SPΦ(x2)
(6.9)
%Biasvar.m
k=1;
VAR=[];
BIASSQUARE=[];
for lambda=linspace(0,10,25)
yestmean=0;
for iteration=1:1:1000
x=rand(1,158)*(pi/2);
x=sort(x);
y=sin(x)+2*randn(1,length(x));
x1=linspace(0,pi/2,158);
z=sin(x1);
x=x’;
M=[x x.ˆ2 x.ˆ3 x.ˆ4 x.ˆ5 x.ˆ6 x.ˆ7 x.ˆ8 x.ˆ9];
weights=pinv(lambda*diag(ones(1,size(M,2)))+ M’*M)*M’*y’;
yest=M*weights;
figure(1)
subplot(5,5,k)
plot(z,’b’)
hold on
plot(yest,’r’)
YEST{iteration}=yest;
yestmean=yestmean+yest;
end
yestmean=yestmean/1000;
variance=0;
biassquare=0;
for iteration=1:1:1000
variance=variance+(YEST{iteration}-yestmean).ˆ2;
end
variance=sum(variance)/(1000*158);
VAR=[VAR variance];
figure(2)
biassquare=(yestmean-z’).ˆ2;
plot(yestmean,’r’)
hold on
plot(z,’b’)
biassquare=sum(biassquare)/158;
BIASSQUARE=[BIASSQUARE
biassquare];
k=k+1;
end
figure
plot(VAR)
title(’Variance versus regularization constant’)
figure
plot(BIASSQUARE)
title(’Bias square versus regularization constant’)

6.6 Nonuniform Sampling of Real Data in Multidisciplinary …
193
The list of commonly used kernel functions k(x1, x2) (Applicable for vectors) are
listed below.
1. Inner product kernel: xT
1 x2
2. Gaussian kernel: e
−||x1−x)2||2
c1
3. Polynomial kernel: (xT
1 x2 + c2)c3
4. Power exponential: (e
−||x1−x2||2
c4
)c5
5. Hyperbolic tangent: tan(c6(xT
1 x2) + c7)
6. Cauchy:
1
1+ ||x1−x||2
c8
7. Inverse multiquadric:
1
√
||x1−x2||2+c2
9

List of m-ﬁles
demonstratereconstruction.m Reconstruction of sampled signals.
samplingtheorem.m Nonoverlapping of spectrum in DTFT.
circconvusingDFT.m Circular convolution using DFT.
dit.m Decimation in Time FFT.
executedit.m Comparison of time required to compute DFT using the direct method
and using DIT.
dif.m Decimation in Frequency FFT.
executedif.m Comparison of time required to compute DFT using the direct method
and using DIT.
subband.m Sub-band ﬁlters.
responsetoperiodicsequence.m Response of the discrete system to the periodic
sequence.
complexgeometry.m Demonstration of the geometrical interpretation of computa-
tion of magnitude and phase response of the discrete transfer function.
magrespzplot.m Called by the m-ﬁle complexgeometry.m.
plotbuttermag.m Plot the magnitude response of the Butterworth analog ﬁlter.
plotchebymag Plot the magnitude response of the Chebyshev analog ﬁlter.
CN.m Called by plotchbymag.m.
butterworthorder.m Compute the order of the Butterworth ﬁlter.
digitalbutterworth.m Converts analog Butterworth ﬁlter to digital ﬁlter.
impulses2z.m Impulse invariant mapping.
bilinears2z.m Bilinear transformation mapping.
© Springer International Publishing AG 2018
E.S. Gopi, Multi-Disciplinary Digital Signal Processing,
DOI 10.1007/978-3-319-57430-1
195

196
List of m-ﬁles
digitalchebyshev.m Converts analog Chebyshev ﬁlter to digital ﬁlter.
chebyshevorder.m Compute the order of the Chebyshev ﬁlter.
ButterworthHPFdemo.m Demonstration of digital Butterworth high-pass ﬁlter.
digitalbutterworthHPF.m Function called by ButterworthHPFdemo.m.
chebyshevHPFdemo.m Demonstration of digital Chebyshev high-pass ﬁlter.
digitalchebyshevHPF.m Function called by chebyshevHPFdemo.m.
IIRBPFDEMO.m Demonstration of digital bandpass ﬁlter.
digitalBPF.m Function called by IIRBPFDEMO.m.
IIRBRFdemo.m Demonstration of digital bandpass ﬁlter.
digitalBRF.m Function called by IIRBRFDEMO.m.
realizeiir.m Realization of IIR ﬁlter using Directform-1 and Directform-II.
FIRdemo.m FIR ﬁlter demonstration
ﬁrtype1.m Called by FIRdemo.m.
ﬁrtype2.m Called by FIRdemo.m.
ﬁrtype3.m Called by FIRdemo.m.
ﬁrtype4.m Called by FIRdemo.m.
minmaxFIR.m Demonstration of relationship between min-phase, max-phase, and
all pass FIR ﬁlters.
effectoftruncation.m Demonstration of magnitude response of the truncated ﬁlter.
truncimpLPF2FIR1FIR3.m Illustration of obtaining the low-pass ﬁlter coefﬁcients
for FIR 1 and FIR 3 ﬁlter from the truncated impulse response of the ideal low-pass
ﬁlter.
truncimpLPF2FIR2FIR4.m Illustration of obtaining the low-pass ﬁlter coefﬁcients
for FIR 2 and FIR 4 ﬁlter from the truncated impulse response of the ideal low-pass
ﬁlter.
HPFtype1.m Illustration of obtaining the Type 1 high-pass ﬁlter coefﬁcients.
HPFtype3.m Illustration of obtaining the Type 3 high-pass ﬁlter coefﬁcients.
BPFT1LPFT1HPF.m Bandpass ﬁlter constructed using Type 1 LPF and Type 1
LPF.
BPFT3LPFT3HPF.m Bandpass ﬁlter constructed using Type 3 LPF and Type 3
LPF.
BPFT3LPFT1HPF.m Bandpass ﬁlter constructed using Type 3 LPF and Type 1
LPF.

List of m-ﬁles
197
BPFT1LPFT3HPF.m Bandpass ﬁlter constructed using Type 1 LPF and Type 3
LPF.
BRFT1LPFT1HPF.m Band-reject ﬁlter constructed using Type 1 LPF and Type 1
HPF.
BRFT3LPFT3HPF.m Band-reject ﬁlter constructed using Type 3 LPF and Type 3
HPF.
BRFT1LPFT3HPF.m Band-reject ﬁlter constructed using Type 1 LPF and Type 3
HPF.
BRFT3LPFT1HPF.m Band-reject ﬁlter constructed using Type 3 LPF and Type 1
HPF.
reduceripplesLPF.m Windowing technique to reduce ripples for FIR low-pass ﬁlter.
reduceripplesHPF.m Windowing technique to reduce ripples for FIR high-pass
ﬁlter.
reduceripplesBPF.m Windowing technique to reduce ripples for FIR bandpass ﬁlter.
reduceripplesBRF.m Windowing technique to reduce ripples for FIR band-reject
ﬁlter.
identicalmagresﬁlters.m FIR ﬁlters having identical magnitude responses.
multiratedemo.m Demonstration of decimation and interpolation.
interpolyphase.m Interpolation using polyphase realization.
decimatepolyphase.m Decimation using polyphase realization.
QMFdemo.m Quadrature mirror ﬁlter demonstration.
QMF.m Called by QMFdemo.m.
transmultiplexer.m Demonstration of transmultiplexer.
wssrp.m Demonstration of wide sense stationary random process.
forbackcoef.m Computation of forward and backward prediction coefﬁcients.
adapsysiden.m Adaptive ﬁlter for system identiﬁcation.
adapﬁltnoise.m Adaptive ﬁlter for noise removal.
pisarenko-music-esprit.m Demonstration of Pisarenko, MUSIC, and ESPRIT algo-
rithms for spectral estimation.
timevaryingﬁltercoef.m Time-varying ﬁlter coefﬁcients of the wireless channel.
cyclicpreﬁx.m Demonstrating importance of cyclic preﬁx in OFDM.
WarpedDFT.m Usage of warped DFT for signal analysis.
Biasvar.m Demonstration of importance of regularization factor in regression.

Index
A
Adaptive ﬁlter, 157
All pass ﬁlter, 82, 116–118, 126, 131, 138
Auto regressive (AR), 150–152, 156, 158,
169
Auto regressive moving average (ARMA),
150, 151
B
Band pass ﬁlter, 67
Band pass FIR ﬁlter, 81, 97–99, 105, 108
Band-reject ﬁlter, 70
Band reject FIR ﬁlter, 97–99, 105, 109
Bilinear transformation, 44–49, 51, 58–61,
67–71
Butterworth ﬁlter, 47–49, 59, 70
C
Chebyshev ﬁlter, 49–51, 58, 59, 67, 70
Cyclic preﬁx nonuniform DFT, 180, 181,
187
D
Decimation, 124, 130–134
Decimation in frequency-FFT, 23, 24
Decimation in time-FFT, 21
Direct form 1, 72–74
Direct form 2, 72, 73
Dirichlet conditions, 12
Discrete Fourier transformation (DFT), 18,
25, 35, 185, 187
Discrete
time
Fourier
transformation
(DTFT), 13, 35
E
Eigen decomposition, 166, 171
ESPRIT method, 170, 172
Estimation of signal parameters via rota-
tional invariance technique, 170
F
Finite impulse response (FIR), 77–83, 90,
93–96, 105, 113–116
Fourier series (FS), 11
Fourier transformation, 12, 13, 21, 30, 183
G
Geometrical interpretation of pole-zero plot,
32, 40, 79, 114, 115, 117
H
High-pass ﬁlter, 59
High-pass FIR ﬁlter, 81, 91, 97, 105, 108
I
Identical magnitude response, 113
IIR ﬁlter, 47, 49, 59, 72–74, 90
Impulse-invariant mapping, 43
Impulse-invariant transformation, 47, 49
Interpolation, 15, 124–128, 131, 142, 187
K
Kernel smoothing function, 191
L
Laplace transformation, 30, 31, 43, 45
© Springer International Publishing AG 2018
E.S. Gopi, Multi-Disciplinary Digital Signal Processing,
DOI 10.1007/978-3-319-57430-1
199

200
Index
Linear prediction model, 151
Low-pass FIR ﬁlter, 1–3, 9, 15, 81, 90, 91,
93, 95, 97, 105, 107, 123, 125, 131,
139, 144
M
Moving average (MA), 150, 151
Multiple signal classiﬁcation (MUSIC), 169
N
Nonstationary random process, 147
P
Pisarenko Harmonic decomposition, 168,
169, 171
Poly-phase realization, 125–127, 130
Projection-slice theorem, 183
Q
Quadrature mirror ﬁlter, 135, 137
S
Sampling frequency, 1, 2, 9, 13, 18, 44, 48,
58–60, 73, 121, 125, 177
Sinusoidal signal, 1
Sub-band DFT, 25, 26
System model, 157
T
Transmultiplexer, 135, 142
V
Vector space interpretation of DFT, 20
W
Warped-DFT, 185
Windowing technique, 90
Z
Z-transformation, 35, 36, 40, 43, 45, 59, 72,
121, 122, 138, 154, 155

