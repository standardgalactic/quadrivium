Fundamentals of Signal Enhancement and
Array Signal Processing
www.ebook3000.com

Fundamentals of Signal Enhancement and
Array Signal Processing
Jacob Benesty
INRS, University of Quebec
Montreal, Canada
Israel Cohen
Technion, Israel Institute of Technology
Haifa, Israel
Jingdong Chen
Northwestern Polytechnical University
Xi’an, China

This edition ﬁrst published 
© John Wiley & Sons Singapore Pte. Ltd
All rights reserved. No part of this publication may be reproduced, stored in a retrieval system, or
transmitted, in any form or by any means, electronic, mechanical, photocopying, recording or otherwise,
except as permitted by law. Advice on how to obtain permission to reuse material from this title is available
at http://www.wiley.com/go/permissions.
The right of Jacob Benesty, Israel Cohen, and Jingdong Chen to be identiﬁed as the authors of this work has
been asserted in accordance with law.
Registered Oﬃces
John Wiley & Sons, Inc., River Street, Hoboken, NJ , USA
John Wiley & Sons Singapore Pte. Ltd, Fusionopolis Walk, #-Solaris South Tower, Singapore 
Editorial Oﬃce
The Atrium, Southern Gate, Chichester, West Sussex, POSQ, UK
For details of our global editorial oﬃces, customer services, and more information about Wiley products
visit us at www.wiley.com.
Wiley also publishes its books in a variety of electronic formats and by print-on-demand. Some content that
appears in standard print versions of this book may not be available in other formats.
Limit of Liability/Disclaimer of Warranty
While the publisher and authors have used their best eﬀorts in preparing this work, they make no
representations or warranties with respect to the accuracy or completeness of the contents of this work and
speciﬁcally disclaim all warranties, including without limitation any implied warranties of merchantability
or ﬁtness for a particular purpose. No warranty may be created or extended by sales representatives, written
sales materials or promotional statements for this work. The fact that an organization, website, or product is
referred to in this work as a citation and/or potential source of further information does not mean that the
publisher and authors endorse the information or services the organization, website, or product may
provide or recommendations it may make. This work is sold with the understanding that the publisher is not
engaged in rendering professional services. The advice and strategies contained herein may not be suitable
for your situation. You should consult with a specialist where appropriate. Further, readers should be aware
that websites listed in this work may have changed or disappeared between when this work was written and
when it is read. Neither the publisher nor authors shall be liable for any loss of proﬁt or any other
commercial damages, including but not limited to special, incidental, consequential, or other damages.
Library of Congress Cataloging-in-Publication data applied for
Hardback ISBN: 
Cover Design by Wiley
Cover Image: © naqiewei/Gettyimages
Set in /pt Warnock by SPi Global, Pondicherry, India










www.ebook3000.com

v
Contents
Preface
xi
About the Companion Website
xiii
1
Introduction

.
Signal Enhancement

..
Speech Enhancement and Noise Reduction

..
Underwater Acoustic Signal Enhancement

..
Signal Enhancement in Radar Systems

..
Signal Enhancement in Ultrasound Systems

.
Approaches to Signal Enhancement

.
Array Signal Processing

.
Organization of the Book

.
How to Use the Book

References

Part I
Signal Enhancement

2
Single-channel Signal Enhancement in the Time Domain

.
Signal Model and Problem Formulation

.
Wiener Method

..
Linear Filtering

..
Performance Measures

..
Optimal Filters

.
Spectral Method

..
Joint Diagonalization and Reformulation of the Problem

..
Noise Reduction with Gains

..
Performance Measures

..
Determination of the Gains from the Fullmode Output SNR

Problems

References

3
Single-Channel Signal Enhancement in the Frequency Domain

.
Signal Model and Problem Formulation

.
Noise Reduction with Gains


vi
Contents
.
Performance Measures

.
Optimal Gains

.
Constraint Wiener Gains

.
Implementation with the Short-time Fourier Transform

Problems

References

4
Multichannel Signal Enhancement in the Time Domain

.
Signal Model and Problem Formulation

.
Conventional Method

..
Joint Diagonalization

..
Linear Filtering

..
Performance Measures

..
Optimal Filtering Matrices

.
Spectral Method

..
Temporal Joint Diagonalization and Reformulation of the Problem

..
Spatial Joint Diagonalization

..
Spatial Linear Filtering

..
Performance Measures

..
Optimal Filters

.
Case of a Rank Deﬁcient Noise Correlation Matrix

..
Eigenvalue Decompositions

..
Maximization of the Output SNR

..
Minimization of the Output SNR

Problems

References

5
Multichannel Signal Enhancement in the Frequency Domain

.
Signal Model and Problem Formulation

.
Linear Filtering

.
Performance Measures

..
Input SNR

..
Output SNR

..
Noise Rejection and Desired Signal Cancellation

..
Desired Signal Distortion Index

..
MSE Criterion

.
Optimal Filters

..
Maximum SNR

..
Wiener

..
MVDR

..
Tradeoﬀ

..
LCMV

.
Generalized Sidelobe Canceller Structure

.
A Signal Subspace Perspective

..
Joint Diagonalization

..
Estimation of the Desired Signal

www.ebook3000.com

Contents
vii
.
Implementation with the STFT

Problems

References

6
An Exhaustive Class of Linear Filters

.
Signal Model and Problem Formulation

.
Linear Filtering for Signal Enhancement

.
Performance Measures

.
Optimal Filters

..
Wiener

..
MVDR

..
Tradeoﬀ

..
LCMV

..
Maximum SINR

..
Maximum SIR

.
Filling the Gap Between the Maximum SINR and Wiener Filters

Problems

References

Part II
Array Signal Processing

7
Fixed Beamforming

.
Signal Model and Problem Formulation

.
Linear Array Model

.
Performance Measures

.
Spatial Aliasing

.
Fixed Beamformers

..
Delay and Sum

..
Maximum DF

..
Superdirective

..
Robust Superdirective

..
Null Steering

.
A Signal Subspace Perspective

..
Joint Diagonalization

..
Compromising Between WNG and DF

Problems

References

8
Adaptive Beamforming

.
Signal Model, Problem Formulation, and Array Model

.
Performance Measures

.
Adaptive Beamformers

..
Wiener

..
MVDR

..
Tradeoﬀ

..
Maximum Array Gain

..
LCMV


viii
Contents
.
SNR Estimation

.
DOA Estimation

.
A Spectral Coherence Perspective

..
Deﬁnitions

..
Derivation of Optimal Beamformers

Problems

References

9
Differential Beamforming

.
Signal Model, Problem Formulation, and Array Model

.
Beampatterns

.
Front-to-back Ratios

.
Array Gains

.
Examples of Theoretical Diﬀerential Beamformers

.
First-order Design

..
Principle

..
Design Examples

.
Second-order Design

..
Principle

..
Design Examples

.
Third-order Design

..
Principle

..
Design Examples

.
Minimum-norm Beamformers

..
Principle

..
Design Examples

Problems

References

10
Beampattern Design

.
Beampatterns Revisited

.
Nonrobust Approach

.
Robust Approach

.
Frequency-invariant Beampattern Design

.
Least-squares Method

.
Joint Optimization

Problems

References

11
Beamforming in the Time Domain

.
Signal Model and Problem Formulation

.
Broadband Beamforming

.
Performance Measures

.
Fixed Beamformers

..
Delay and Sum

..
Maximum DF

..
Distortionless Maximum DF

www.ebook3000.com

Contents
ix
..
Superdirective

..
Null Steering

.
Adaptive Beamformers

..
Wiener

..
MVDR

..
Tradeoﬀ

..
Maximum SNR

..
LCMV

.
Diﬀerential Beamformers

..
First Order

..
Second Order

..
General Order

..
Hypercardioid

..
Supercardioid

Problems

References

Index


xi
Preface
Signal enhancement and array signal processing concern the problems of signal
estimation, restoration, parameter estimation, and decision-making. These topics lie at
the heart of many fundamental applications, such as hands-free voice communications,
sonar, radar, ultrasound, seismology, autonomous cars, robotics, and so on. This book
is designed as a textbook and its principal goal is to provide a uniﬁed introduction
to the theory and methods of signal enhancement and array signal processing. The
targeted readers are advanced undergraduate and graduate students who are taking – or
instructors who are teaching – courses in signal enhancement, array signal processing,
and their applications. Of course, practitioners and engineers can also use this book as
a reference in designing signal-enhancement and/or array systems.
Since the primary users of this book may come from many diﬀerent ﬁelds, with
diﬀerent background knowledge, we choose to focus on the key principles, theory and
methods of signal enhancement and array signal processing from a signal processing
perspective without discussing in detail the introductory material related to speciﬁc
applications. Students are encouraged to read background material from the specialized
academic books and research papers in their own ﬁeld while studying this book.
In most, if not all, application systems, signals are acquired in the time domain.
Therefore, comprehensive coverage of the formulation, methods, and algorithms of
signal enhancement and array beamforming is provided for this domain. Likewise, thor-
ough coverage of the material in the frequency domain is also presented as the formula-
tion, derivation, analysis, and implementation of signal-enhancement and beamforming
algorithms are often carried out in this domain. Readers are assumed to be familiar
with Fourier transforms and the short-time Fourier transform (STFT) by which a time-
domain signal is mapped to an equivalent sequence in the frequency domain. Readers
are also assumed to have some prior knowledge on discrete-time linear systems, linear
algebra, statistical signal processing, and stochastic processes.
A solid theoretical understanding always goes hand-in-hand with practical imple-
mentations. Therefore, this textbook includes a large number of examples to illustrate
important concepts and show how the major algorithms work. MATLAB functions for
all the examples can be found on the authors’ websites. Besides examples, exercises and
problems are provided at the end of every chapter to challenge readers and facilitate
their comprehension of the material.
www.ebook3000.com

xii
Preface
With the long experience of the authors (especially the ﬁrst one) in both the industry
and academia, we hope that this book has been written in such a way that it is easy and
pleasant to read without compromising on the rigor of the mathematical developments.
Jacob Benesty
Israel Cohen
Jingdong Chen

xiii
About the Companion Website
Don’t forget to visit the companion website for this book:
www.wiley.com/go/benesty/arraysignalprocessing
There you will ﬁnd valuable material designed to enhance your learning, including:
) Matlab codes used in the book
) Slides for lectures
Scan this QR code to visit the companion website
www.ebook3000.com

1
1
Introduction
Signal enhancement is a process to either restore a signal of interest or boost the relevant
information embedded in the signal of interest and suppress less relevant information
from the observation signals. Today, there is almost no ﬁeld of technical endeavor that
is not impacted in some way by this process.
Array signal processing manipulates the signals picked up by the sensors that form
an array in order to estimate some speciﬁc parameters, enhance a signal of interest, or
make a particular decision. The main purpose of this chapter is to:
●deﬁne the scope of the ﬁeld that we call signal enhancement
●present a brief historic overview of this topic
●give some examples of ﬁelds where signal enhancement is needed and used
●discuss brieﬂy the principal approaches to signal enhancement
●explain how array signal processing works.
1.1
Signal Enhancement
We human beings rely on our senses to sense the environment around us. Based on
this information we build and expand intelligence in our brain to help make decisions
and take actions. Similarly, we strive to build systems to help us “see” or “hear” distant
events that cannot be reached by our senses. For example, nowadays, sonar systems
can hear ships across hundreds of miles of ocean, radar devices can see airplanes from a
thousand miles over the horizon, telecommunication systems can connect two or more
users from diﬀerent corners of the world, and high-deﬁnition cameras can see events
happening on our planet from space. These systems use sensors to measure the physical
environment of interest. Signal processing is then applied to extract as much relevant
information as possible from the sensors’ outputs. Generally, sensors’ outputs consist of
the signal of interest, which carries very important information, and also a composition
of unwanted signals, which is generally termed “noise”. This does not contain useful
information but interferes with the desired signal. To extract the useful information in
the presence of noise, signal enhancement is needed, the objective of which is to:
●enhance the signal-to-noise ratio (SNR)
●restore the signal of interest
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing

2
Fundamentals of Signal Enhancement and Array Signal Processing
●boost the relevant information while suppressing less relevant information
●improve the performance of signal detection and parameter estimation.
Signal enhancement is a specialized branch of signal processing that has been around
for many decades and has profound impact on many ﬁelds. In the following subsections,
we describe a few areas that routinely use signal enhancement techniques, particularly
those developed in the following chapters of this text. Note that we can only cover a few
applications, but this should leave the reader with no doubt as to the importance and
breadth of application of signal enhancement techniques.
1.1.1
Speech Enhancement and Noise Reduction
In applications related to speech acquisition, processing, recognition, and communica-
tions, the speech signal of interest (generally called the “desired speech”) can never be
recorded in a pure form; it is always immersed in noise. The noise can come from very
diﬀerent sources. For example, microphones that we use to convert acoustic pressure
into electronic signals have self-noise, even though the noise ﬂoor of popularly used
capacitor microphones has been dropping signiﬁcantly over the years. The associ-
ated digital signal processing boards, including preampliﬁers, analog-to-digital (A/D)
converters, and processors for processing the signals, may also generate noise. Most
importantly, noise comes from ambient sources; the environment where we live is full
of diﬀerent kinds of sounds. While the sensors’ self and circuit noise is generally white
in spectrum, the noise from sound sources in the surrounding environment can vary
signiﬁcantly from one application scenario to another.
Commonly, noise from acoustic environments can be divided into the following four
basic categories depending on how the noise is generated:
●Additive noise can come from various sources, such as cooling fans, air conditioners,
slamming doors, and passing traﬃc.
●Echoes occur due to the coupling between loudspeakers and microphones.
●Reverberation is the result of multipath propagation and is introduced by reﬂections
from enclosure surfaces.
●Interference comes from concurrent sound sources. In some communication appli-
cations, such as teleconferencing, it is possible that each communication site has
multiple participants and loudspeakers, so there can be multiple competing sound
sources.
Combating these four categories of noise has led to the development of diverse acoustic
signal processing techniques. They include noise reduction (or speech enhancement),
echo cancellation and suppression, speech dereverberation, and source separation, each
of which is a rich subject of research [–]. This text presents many methods, algo-
rithms, and techniques that are useful in dealing with additive noise, reverberation, and
interference while its major focus, particularly the signal enhancement part from
Chapter to Chapter , is on reducing additive noise.
Additive noise and the desired speech signal are in general statistically independent.
While the noise does not modify the speech characteristics directly, the characteristics
of the observation signal are very diﬀerent from those of the desired speech since it
is a mixture of the desired speech signal and noise. Figure .plots a speech signal
recorded in an anechoic (quiet and non-reﬂective) environment and the same speech
www.ebook3000.com

Introduction
3
–0.5
0.5
(a)
–1.0
1.0
0.0
–0.5
0.5
(b)
–1.0
1.0
0.0
0.0
2.0
4.0
1.0
3.0
5.0
Amplitdue
Amplitdue
Figure 1.1 (a) A speech signal recorded by a microphone in an anechoic environment and (b) the
same speech signal recorded by the same microphone but in a conference room.
signal but recorded in a conference room. The spectrograms of these two signals are
shown in Figure .. As can be seen, both the waveform and the spectrogram of the noisy
signal are dramatically diﬀerent from those of the clean speech. The eﬀect of noise may
dramatically aﬀect the listener’s perception and also machine processing of the observed
speech. It is therefore generally required to “clean” the observation signal before it is
stored, transmitted, or played (through a loudspeaker, for example). This problem is
generally referred to as either noise reduction or speech enhancement.
1.1.2
Underwater Acoustic Signal Enhancement
Over the last few decades, ocean exploration activity for both military and civilian
interests has been steadily increasing. As a result, there has been growing demand
for underwater communication and signal detection and estimation technologies.
Electromagnetic and light waves do not propagate over long distances under water
(particularly sea water). In contrast, acoustic waves may propagate across tens or even
hundreds of miles under the sea. Therefore, acoustic waves have played an important
role in underwater communication and signal detection and estimation. For example,
passive sonar systems can detect a submarine from tens of miles away by listening
to the sound produced by the submarine, such as from the propellers, engine, and
pumps; active sonars transmit sound pulses into the water and listen to the echoes,
thereby detecting underwater features such as the location of ﬁsh, sunken objects,
vessels, and submarines. Underwater wireless communication systems modulate useful
information on acoustic carriers with frequencies between a few kilohertz and a few
tens of kilohertz and transmit the modulated signal from one end to another through
underwater acoustic channels.

4
Fundamentals of Signal Enhancement and Array Signal Processing
(a)
0.0
1.0
2.0
3.0
4.0
0.0
0.5
1.0
(b)
0.0
1.0
2.0
4.0
3.0
5.0
0.0
1.0
2.0
3.0
4.0
0.0
0.5
1.0
Frequency (kHz)
Frequency (kHz)
Time (s)
Figure 1.2 (a) The spectrogram of the speech signal in Figure 1.1a; (b) the spectrogram of the speech
signal in Figure 1.1b.
However, processing underwater acoustic signals is by no means an easy task. First
of all, underwater acoustic channels are generally known as one of the most diﬃcult
communication media in use today. Underwater acoustic propagation suﬀers from the
time-varying multipath eﬀect (due to sound reﬂection at the surface, bottom, and any
objects in the vicinity, and also sound refraction in the water), frequency-dependent
attenuation (due to absorption and signal spreading loss), and a severe Doppler eﬀect
(due to the low speed of sound and motion of the transmitter or receiver or the objects
to be detected). Secondly, the ocean is ﬁlled with sounds, which interfere with the
acoustic signal we are interested in. Underwater sounds are generated by both natural
sources, such as marine animals, breaking waves, rain, cracking sea ice, and undersea
earthquakes, as well as man-made sources, such as ships, submarines, and military
sonars.
Marine animals use sound to obtain detailed information about their surroundings.
They rely on sound to communicate, navigate, and feed. For example, dolphins can
detect individual prey and navigate around objects underwater by emitting short pulses
of sound and listening to the echo. Marine mammal calls can increase ambient noise
levels by –dB in some locations at certain times of year. Blue and ﬁn whales
produce low-frequency moans at frequencies of –Hz, with estimated source levels
of up to dB at m. Sounds generated by human activities are also an important
part of the total ocean noise. Undersea sound is used for many valuable purposes,
including communication, navigation, defense, research and exploration, and ﬁshing.
www.ebook3000.com

Introduction
5
–0.5
0.5
–1.0
1.0
0.0
–0.5
0.5
(a)
(b)
–1.0
1.0
0.0
0.00
0.01
0.02
0.03
0.04
0.05
Time (s)
Amplitdue
Amplitdue
Figure 1.3 A linear frequency modulated signal: (a) emitted by a transmitter of an underwater
acoustic communication system and (b) received by a hydrophone six miles away from the transmitter
in an underwater environment.
Sounds generated by human activities cover a wide range of frequencies, from a few
hertz up to several hundred kilohertz, and a wide range of source levels.
The underwater channel condition and noise sets the ultimate limit on the minimum
detectable signal in detection and communication systems. To illustrate how challeng-
ing it is to process underwater signals for extracting the useful information, Figure .
plots a linear frequency modulation chirp signal transmitted by an acoustic antenna
and the signal received by a hydrophone placed six miles away from the transmitter. The
magnitude spectra of these two signals are plotted in Figure .. As seen, the transmitted
signal is dramatically distorted by the acoustic channel and noise. Sophisticated signal
enhancement techniques, such as those developed in this text, are needed to extract
the important parameters or information embedded in the transmitted signal from the
received signal.
1.1.3
Signal Enhancement in Radar Systems
A radar system has a transmitter that emits electromagnetic waves (called radar signals)
in look directions. When these waves come into contact with an object, they are usually
reﬂected or scattered in many directions. Receivers (usually, but not always, in the same
location as the transmitter) are then used to receive the echoes. Through processing the
echoes, the radar can determine the range, angle, or velocity of the objects of interest.
The invention of the radar dates back to the late th century. Such systems are now
used in a broad range of applications, including air defense, traﬃc control, aircraft
anticollision, ocean surveillance, geological observations, meteorological precipitation
monitoring, and autonomous cars. In order to estimate the range, angle, or velocity of

6
Fundamentals of Signal Enhancement and Array Signal Processing
−40
−20
20
40
60
(a)
0
−40
−20
20
40
60
(b)
0
0
2
4
6
8
10
Frequency (kHz)
Magnitude spectrum (dB)
Magnitude spectrum (dB)
Figure 1.4 The power spectrum of the signal in Figure 1.3a; (b) the power spectrum of the signal in
Figure 1.3b.
the objects of interest, radar systems must overcome unwanted signals, which can be
divided into the following three categories.
●Additive noise is generated by both internal sources (electronics) and external sources
(the natural thermal radiation of the background surrounding the target of interest).
In modern radar systems, the internal noise is generally lower than the external noise.
●Clutter is a term used for echoes returned from targets that are not useful to the radar
system user. Clutters can be generated by irrelevant targets, natural objects such as the
ground, sea, atmospheric turbulence, ionospheric reﬂections, and man-made objects
such as buildings, as illustrated in Figure ..
●Jamming refers to signals received by the radar on its own frequency band but emitted
from outside sources. Jamming may be intentional, as with an electronic warfare
tactic, or unintentional, as with friendly forces’ using equipment that transmits using
the same frequency range. It is problematic to radar since the jamming signal only
needs to travel one way – from the jammer to the radar receiver – whereas the radar
echoes travel two ways – from radar to target and to radar – and are therefore
signiﬁcantly reduced in power by the time they return to the radar receiver. Therefore,
jammers can eﬀectively mask targets along the line of sight from the jammer to the
radar, even when they are much less powerful than the jammed radars.
www.ebook3000.com

Introduction
7
Wanted echo from aircraft
Clutter from clouds
Echo reflected by the cloud
Unwanted echo and self protection jamming
Clutter from trees
Unwanted echo from ground targets
Unwanted echo from ground targets
Unwanted echo from ground targets
Figure 1.5 An illustration of a radar system and its environments.
−20
−40
−60
0
0
200
400
600
800
1000
1200
1400
Range unit
Magnitude (dB)
Figure 1.6 Normalized magnitude of an echo received by a pulse radar.
Figure .plots the magnitude of a signal received by a pulse radar where the transmitted
signal is a short pulse. The received signal is composed of an echo returned from a
target of interest, two unwanted echoes, and some noise. Figure .shows a radar
image directly mapped from the received signals without using any signal enhancement
techniques. Without signal enhancement, it is diﬃcult to determine the position of
one target, let alone track multiple targets with high resolution. Therefore, signal

8
Fundamentals of Signal Enhancement and Array Signal Processing
Figure 1.7 Illustration of an image displayed in a radar screen without using signal enhancement.
enhancement techniques, particularly those developed in Chapters –, are needed
to deal with additive noise, clutter, and jamming in radar systems. This is done by
estimating the important parameters embedded in the radar echo signals.
1.1.4
Signal Enhancement in Ultrasound Systems
Ultrasound refers to sound waves with frequencies greater than kHz, a level which is
commonly accepted to be the upper limit of human hearing. This type of high-frequency
sound wave is used in many ﬁelds for a wide range of applications, such as non-intrusive
testing of products and structures, invisible ﬂaw detection, distance measurement, and
medical diagnosis, to name just a few. One of the best known ultrasound systems is the
sonography instrument that is used in medicine to examine many of the body’s internal
organs, including – but not limited to – the heart and blood vessels, liver, gallbladder,
pancreas, kidneys, and uterus, as well as unborn children (fetus) in pregnant patients.
Typically, a sonography device consists of an array of transmitters, which send
short, high-frequency (generally between and MHz) sound pulses into the body.
Beamforming is applied to the transmitted pulses so that the ultrasound waves are
focused towards a particular point. As the beamformed waves travel toward the desired
focal point, they propagate through materials with diﬀerent densities. With each change
in density, reﬂected waves are produced, some of which propagate back. They are then
www.ebook3000.com

Introduction
9
collected by an array of receivers (the transmitters typically become sensors to receive
signals once they have ﬁnished generating their respective sound waves). The signal
received by each receiver is composed of the wanted echoes and noise. Commonly, noise
in sonography is one of two major types:
●Additive noise is generated from the sensors, ampliﬁers, A/D converters, and other
electronic system components. It can also come from sources such as background
tissues, other organs and anatomical inﬂuences, and breathing motion. Generally, this
type of noise is independent (or weakly dependent) on the echo signals and is often
modeled mathematically as a white Gaussian noise process.
●Speckle is the result of three sound scattering eﬀects: specular, diﬀusive, and diﬀrac-
tive. Specular scattering occurs when the scattering object is large compared to
the sound wavelength; diﬀusive scattering happens when the scattering object is
small relative to the wavelength; diﬀractive scattering occurs mostly for medium-size
scattering objects. Unlike additive noise, speckles are generally correlated with the
wanted echo signals.
To deal with additive noise and speckles in sonography, beamforming, noise reduction,
speckle reduction, and many other enhancement processes are applied to the received
signals before high-resolution two-dimensional images are formed to display the dis-
tances and intensities of the echoes on the screen.
1.2
Approaches to Signal Enhancement
Signal enhancement is one of the most interesting and appealing yet challenging areas
of signal processing. Its objective is generally problem oriented, ranging from simply
improving the SNR, boosting relevant information, restoring the signal of interest, to
improving measures of which only human subjects can judge the quality. As a result,
there is no general rule as what method is optimal and it is quite common that a method
that produces the best enhancement result for one application may not be very useful
for another. In general, signal enhancement techniques can be classiﬁed into one of four
broad categories, depending on how the information embedded in the signal and noise
are used:
●time-domain methods, which directly use temporal information
●frequency-domain approaches, which operate on spectra (obtained using the Fourier
transform or other time-to-frequency-domain transformations) of a signal
●spatial-domain techniques, which acquire and process a signal of interest using an
array of sensors
●combinational methods, which use temporal, spectral, and spatial information.
Time-domain methods typically achieve signal enhancement by applying a ﬁnite-
impulse-response ﬁlter to the noisy signal that is observed at a sensor. So, the core prob-
lem of enhancement is converted to one of designing an optimal ﬁlter that can attenuate
noise as much as possible while keeping the signal of interest relatively unchanged.
The history of this class of methods dates back to the seminal work by Wiener [], in
which the optimal ﬁlter from a second-order-statistics viewpoint is achieved through
the optimization of the classical mean-squared error (MSE) criterion. The Wiener ﬁlter

10
Fundamentals of Signal Enhancement and Array Signal Processing
is well known, and has been intensively investigated for signal enhancement [–].
However, while it is optimal from the MSE point of view, it introduces signal distortion
if the signal to be enhanced is broadband. The amount of signal distortion may not
be acceptable for some applications. If this is the case, one may consider using some
suboptimal ﬁlters that minimize the MSE criterion under certain constraints [, ].
The Wiener technique, by its assumption, can only deal with stationary signals. One
popularly used approach to extending the Wiener ﬁlter to deal with nonstationary
signals is to relax the stationarity assumption to one of short-time stationarity. Then,
the Wiener ﬁlter is computed using signals within only a short-time, sliding window.
In this case, the length of the short-time window plays an important role on the tradeoﬀ
between the nonstationarity and performance within the short-time window. There
are, of course, other ways to deal with signal enhancement of nonstationary signals,
for example, combining the Kalman ﬁlter and the linear-prediction-coding method [].
Comprehensive coverage of signal enhancement using temporal information will be
given in Chapter .
Frequency-domain methods, as the name indicates, explicitly operate on the spectra
of the signal to be processed. The root of this class of methods can be traced back
to the s, when low-pass, high-pass, and band-pass ﬁlters were invented to ﬁlter
out noise that occupies diﬀerent frequency bands to the signal of interest. Today, the
basic principle of band-pass ﬁltering is still widely used in signal enhancement, but
often in more complicated forms, such as comb ﬁlters [] and binary masking [].
Band-pass ﬁltering, comb ﬁltering, and binary masking are hard-decision methods
in the sense that, given a narrow frequency band, they either completely remove the
signal component or keep it unchanged. In comparison, a soft decision can be achieved
through the spectral enhancement method, which was ﬁrst developed in the s using
analog circuits []. A digital-domain version of this method, which is called “spectral
subtraction”, was then developed in the late s []. While it is very useful and is
often used as a benchmark against which other techniques are compared, the spec-
tral substraction method has no optimality properties associated with it. An optimal
spectral enhancement framework was developed in the early s []. This uniﬁed
a broad class of enhancement algorithms, including spectral substraction, frequency-
domain Wiener ﬁltering, and maximum likelihood envelope estimator. Following this
work, an optimal spectral amplitude estimator using statistical estimation theory was
developed in the early s. Following this work, many statistical spectral estimators
were developed, including the minimum mean-squared error (MMSE) estimator [],
the MMSE log-spectral amplitude estimator, the maximum-likelihood (ML) spectral
amplitude estimator, the ML spectral power estimator, and the maximum a posteriori
(MAP) spectral amplitude estimator. Today, there are still tremendous eﬀorts to ﬁnd
better spectral amplitude estimators, inspired by the work of McAulay and Malpass
[] and Ephraim and Malah []. A broad coverage of frequency-domain methods will
be given in Chapter .
When multiple sensors are used, the spatial information embedded in the sensors’
outputs can be exploited to enhance the signal of interest and reduce unwanted noise.
This can be done in a straightforward way by extending the single-channel methods of
Chapters and to the multichannel cases (see, respectively, Chapters and ). It can
also be done in a diﬀerent way through array beamforming, which will be discussed in
the next section.
www.ebook3000.com

Introduction
11
1.3
Array Signal Processing
An array consists of a set of sensors positioned at known locations with reference to
a common point. The sensors collect signals from sources in their own ﬁeld of view
and the output of each sensor is composed of these source components as well as
noise. By processing the sensors’ outputs, two groups of functionalities can be achieved:
estimation of important parameters of sources and enhancement of some signals of
interest.
The history of array signal processing dates back to World War II. Early eﬀorts in this
ﬁeld were mainly focused on parameter estimation: estimating the range, angle, and
velocity of the sources of interest. A wide range of processing methods were developed
to this end, including ﬁxed beamforming (or spatial ﬁltering), matched ﬁltering, Capon’s
adaptive beamforming, the MUSIC (Multiple SIgnal Classiﬁcation) method and its
varieties, and the ESPRIT (Estimation of Signal Parameters by Rotational Invariance
Techniques) algorithm, to name but a few. The reader is referred to the literature for an
in-depth consideration of the problem of array parameter estimation and the associated
methods [–]. In this book, we choose to focus on the signal enhancement problem
with the use of sensor arrays.
The basic principle of signal enhancement using an array of sensors can be illustrated
in Figure .. Consider a simple example with a uniformly spaced linear array of M
sensors and assume that there is a single source in the farﬁeld such that its spherical
wavefront appears planar at the array. If we neglect the propagation attenuation, the
signals received at the M sensors can be written as
Ym( f ) = Xm( f ) + Vm( f )
(.)
= X( f )e−𝚥𝜋f (t+𝜏m−) + Vm( f )
= X( f )e−𝚥𝜋f 𝜏m−+ Vm( f ), m = , , … , M,
X ( f)
θ
δ
(M−1) δ cos θ
Plane
wavefront
Y1( f)
V1(f)
Y2( f)
YM(f)
VM(f)
Figure 1.8 Illustration of an array system for signal enhancement.

12
Fundamentals of Signal Enhancement and Array Signal Processing
where f is frequency, t is the propagation time from the source X(f ) to sensor (the
reference sensor), X( f ) = X( f )e−𝚥𝜋ft is the signal component at sensor , 𝜏m−is
the relative time delay between the mth sensor and the reference one, and 𝚥=
√
−is
the imaginary unit. It is assumed that X( f ) is uncorrelated with Vm( f ), m = , , … , M.
With a uniform linear array (ULA) and a farﬁeld source, the delay 𝜏m−can be expressed
in the following form according to the geometry shown in Figure .:
𝜏m−= (m −)𝛿cos 𝜃∕c, m = , , … , M,
(.)
where 𝛿is the spacing between two neighboring sensors, c represents velocity of wave
propagation, and 𝜃is the signal incidence angle.
Now let us consider processing the M signals Ym(f ), m = , , … , M, to extract the
source signal X(f ) (up to a delay) and reduce the eﬀect of Vm(f ). A straightforward way
of doing this is to multiply Ym(f ) by e𝚥𝜋f 𝜏m−, and then average the results. This gives an
output:
Z(f ) = 
M
M
∑
m=
Ym(f )e𝚥𝜋f 𝜏m−
(.)
= X(f ) + 
M
M
∑
m=
Vm(f )e𝚥𝜋f 𝜏m−.
To check whether the output Z(f ) is less noisy than the input, let us compare the input
and output SNRs. The input SNR, according to the signal model given in (.), is deﬁned
as the SNR at the reference sensor:
iSNR(f ) =
𝜙X(f )
𝜙V(f ),
(.)
where 𝜙X(f ) = E
[
|X(f )|]
and 𝜙V(f ) = E
[
|V(f )|]
are the variances of X(f ) and
V(f ) respectively, and E[⋅] denotes mathematical expectation.
The output SNR – the SNR of the Z(f ) signal – is written as
oSNR(f ) =
𝜙X(f )

ME
[|||
∑M
m=Vm(f )e𝚥𝜋f 𝜏m−|||
].
(.)
Now, if all the noise signals Vm(f ), m = , , … , M, are uncorrelated with each other
and have the same variance, it is easy to check that
E
⎡
⎢
⎢⎣
||||||
M
∑
m=
Vm(f )e𝚥𝜋f 𝜏m−
||||||
⎤
⎥
⎥⎦
= M × E
[
||V(f )||
]
.
(.)
It follows immediately that oSNR(f ) = M × iSNR(f ). Thus, a simple phase shifting
and averaging operation of the sensors’ outputs results in an SNR improvement by
a factor of M, the number of sensors. The underlying physical principle behind the
www.ebook3000.com

Introduction
13
SNR improvement can be explained as follows. Through appropriate phase shifting, the
signal components from the source of interest have been coherently combined while
the noise signals from diﬀerent sensors add only incoherently as they are uncorrelated
with each other, yielding a gain for the overall output signal compared to the noise.
Of course, the above example is only a particular case. More generally, an estimate
of the source signal X(f ) can be obtained through weighted linear combination of the
sensors’ outputs:
Z(f ) =
M
∑
m=
H∗
m(f )Ym(f ),
(.)
where Hm(f ), m = , , … , M, are complex weighting coeﬃcients. The process of
ﬁnding the appropriate values of Hm(f ) so that Z(f ) is a good estimate of X(f ) is
called beamforming. Therefore, the coeﬃcients Hm(f ) are also called beamforming
coeﬃcients and the vector that consists of all the coeﬃcients is called the beamforming
ﬁlter or beamformer.
Beamforming has been the central problem of array signal processing ever since
sensor arrays were invented, and a large number of algorithms has been developed and
described in the literature. By and large, the developed algorithms fall into two major
categories – ﬁxed or adaptive beamforming – depending on whether the noise or signal
statistics are considered in forming the beamforming ﬁlters.
In ﬁxed beamforming, the beamforming ﬁlters are designed explicitly using the array
geometry information as well as the assumed knowledge of the look direction and
noise statistics. Once computed, the coeﬃcients of the beamforming ﬁlters will be ﬁxed
regardless of the particular application environment. It is for this reason that this design
process is called ﬁxed beamforming. The representative algorithms include the delay-
and-sum beamformer, the maximum directivity factor beamformer, and the superdi-
rective beamformer. The reader may ﬁnd a discussion of these algorithms in diﬀerent
contexts and applications in the literature [, –]. The basic theory and methods
for designing ﬁxed beamformers from a narrowband perspective will be covered in
Chapter . While the principles presented in this chapter are rather general, in designing
optimal ﬁxed beamformers, the resulting beamformers may be insuﬃcient to deal with
broadband signals as their beampatterns may vary with frequency. Chapters and 
are also concerned with ﬁxed beamforming, but with focus on processing broadband
signals where beampatterns are expected to be the same across a band of frequencies.
In comparison with ﬁxed beamforming, adaptive beamforming algorithms consider
using either the noise statistics or the statistics of the array observation data to optimize
the beamforming ﬁlters. The performance of adaptive beamforming can be more opti-
mal than its ﬁxed counterpart as long as the signal statistics are correctly estimated. The
representative algorithms in this category include the minimum variance distortionless
response (MVDR) beamformer, which is also known as the Capon’s beamformer [],
the linearly constrained minimum variance (LCMV) beamformer, which is also called
the Frost’s beamformer [], and the generalized sidelobe canceller [, ]. Many
applications of adaptive beamforming can be found in the literature [–, , ].
The fundamental theory and methods for adaptive beamforming from a frequency-
domain perspective will be covered in Chapter .

14
Fundamentals of Signal Enhancement and Array Signal Processing
While one may see that most discussion on beamforming in both the literature and
this text concerns the frequency domain, it is also possible to formulate this problem
in the time domain. Chapter is devoted to a time-domain framework for array
beamforming, which can be used to design both ﬁxed and adaptive beamformers as
well as narrowband and broadband beamformers.
1.4
Organization of the Book
This book attempts to cover the most basic concepts, fundamental principles, and prac-
tical methods of signal enhancement and array beamforming. The material discussed
occupies ten chapters, which are divided into two parts.
The ﬁrst part, Signal Enhancement, consists of ﬁve chapters: from Chapter to
Chapter . We start to discuss the signal enhancement problem in the time domain
with a single sensor in Chapter . With a single sensor, we show how to exploit the
temporal information so as to reduce the level of the additive noise from the sensor’s
output, thereby enhancing the signal of interest. This chapter presents two fundamental
approaches: one deals with the problem from the Wiener ﬁltering perspective and the
other from a spectral mode perspective based on the joint diagonalization of the corre-
lation matrices of the signal of interest and the noise. In both approaches, we present the
problem formulation and performance measures that can be used to evaluate the signal
enhancement performance. Diﬀerent cost functions are also presented, and based on
these we discuss how to derive useful optimal enhancement ﬁlters.
Chapter continues the investigation of the single-channel signal enhancement
problem, but in the frequency domain. The frequency-domain approach is equivalent
to the spectral method discussed in Chapter in the sense that the observation signal
at each frequency band can be processed independently from the others. The advantage
of the algorithms in this chapter is that they can all be implemented eﬃciently thanks
to the use of the fast Fourier transform. Again, we start from problem formulation
and then discuss how to perform signal enhancement with just simple gains at each
frequency band. Relevant performance measures are deﬁned and we show how to derive
several kinds of enhancement gain, some of which can achieve a compromise between
distortion of the desired signal and reduction of the additive noise.
Chapter is basically an extension of Chapter . The fundamental diﬀerence is that
in this chapter we consider the signal enhancement problem with the use of multiple
sensors, which are located at distinct positions in the space. In this case, every sensor
picks up the signal of interest and noise from its own viewpoint. Now, in addition to
the temporal information, the spatial information from the multiple sensors can also
be exploited to enhance the signal of interest. As a result, either a better enhancement
performance or more ﬂexibility to compromise between noise reduction and desired
signal distortion can be achieved, as compared to the single-channel scenario. Similar
to Chapter , we also discuss two approaches: the Wiener ﬁltering one and the one
based on the joint diagonalization of the correlation matrices of the signal of interest
and noise.
Chapter deals with the problem of signal enhancement with multiple sensors in the
frequency domain. As in Chapter , the spatial information embedded in the multiple
sensors is exploited to enhance the signal of interest, but in a way that is easier to
www.ebook3000.com

Introduction
15
comprehend. Just like the material in the previous chapters, we present the signal model,
problem formulation, and performance measures, and show how to derive diﬀerent
optimal ﬁlters. We also discuss the problem in a subspace framework, which is an
alternative way to approach the enhancement problem.
Chapter is a uniﬁcation of the material presented from Chapter to Chapter .
A general framework is presented here so that the signal enhancement problem in either
the time or the frequency domain, with either one sensor or multiple sensors, is treated
in a uniﬁed framework. Within this framework, we derive a class of optimal linear ﬁlters,
some of which are well known and some can achieve output signal-to-interference-plus-
noise ratios (SINRs) that are between those of the conventional maximum SINR ﬁlter
and the Wiener ﬁlter. This chapter also serves as a bridge between the problem of noise
reduction in the previous chapters and the following chapters, on beamforming.
The second part, Array Signal Processing, is about beamforming, and also consists
of ﬁve chapters, from Chapter to Chapter . We start in Chapter by discussing
the theory and methods of beamforming from ﬁxed beamformers, which are spatial
ﬁlters that have the ability to form a main beam pointing in the direction of the signal of
interest, while placing sidelobes and nulls in directions other than the look direction. By
“ﬁxed”, we mean that the beamforming ﬁlters are designed before the deployment of the
array system and the ﬁlters’ coeﬃcients do not depend on the array output. Generally,
the design of ﬁxed beamformers requires the array geometry information, such as the
number of sensors or the location of every sensor relative to a reference point, and the
look direction. It is helpful if the directions of interference sources are known as well. To
simplify the presentation of the main results, we consider in Chapter only ULAs, and
study a number of popularly used ﬁxed beamformers. Note that the generalization of
the algorithms in this chapter from ULAs to other geometries is not diﬃcult, in general.
Fixed beamformers are generally robust and easy to implement; but they are at
best suboptimal in terms of noise and interference rejection, as neither the statistics
of the signal of interest nor those of noise and interference are considered in the
beamformer design process. One way to improve the performance of ﬁxed beamformers
is through using the statistics of the array outputs or a priori information about the
source or noise signals, leading to the so-called “adaptive” beamformers, which will be
studied in Chapter . This chapter discusses several interesting adaptive beamformers,
including their derivation, underlying principles, as well as their equivalent forms from
a theoretical viewpoint.
In processing broadband signals such as audio and speech, it is desirable, if not a must,
to use beamformers that have frequency-invariant beampatterns. One way to achieve
this is through diﬀerential beamforming, which will be studied in Chapter . Diﬀerential
beamforming is a particular kind of ﬁxed beamforming. It diﬀers from those beamform-
ers in Chapter in that it attempts to measure the diﬀerential pressure ﬁeld of diﬀerent
orders, instead of designing a special beampattern. Besides the property of frequency-
invariant beampatterns, diﬀerential beamforming can achieve the maximum directivity
factor, leading to the highest gains in diﬀuse noise. As a matter of fact, the so-called
“superdirective” beamformer is a particular case of the diﬀerential beamformer. In this
chapter, we present the fundamental principles underlying diﬀerential beamforming, as
well as approaches to designing diﬀerential beamformers of diﬀerent orders. One main
drawback of diﬀerential beamforming as compared to those beamformers in Chapter 
is white noise ampliﬁcation. We will present a method that can deal with this problem.

16
Fundamentals of Signal Enhancement and Array Signal Processing
Beampattern design is the most fundamental and important problem in array
beamforming. Chapter is dedicated to this issue. Again, for simplicity of presentation,
a ULA is assumed. Since we are interested in frequency-invariant beampatterns, the
spacing between neighboring sensors must be small, which is assumed here, as it is
in Chapter . In this chapter, we revisit the deﬁnitions of the beampatterns and show
some relationships. We then present diﬀerent techniques for beampattern design. Note
that the beampatterns designed in this chapter are similar to the ones obtained with
diﬀerential sensor arrays in Chapter . This makes sense, as most assumptions used in
this chapter are the same as those in Chapter .
Finally, in Chapter , we address the beamforming problem in the time domain.
The approach depicted here is broadband in nature. We ﬁrst describe the time-domain
signal model that we adopt, and explain how broadband beamforming works. Then
we deﬁne several performance measures, some relevant for ﬁxed beamforming while
others are more relevant for adaptive beamforming. Finally we show how to derive in
great detail three classes of beamformers: ﬁxed, adaptive, and diﬀerential. As the reader
can see, the algorithms presented in this chapter are more intuitive than the frequency-
domain beamformers discussed in previous chapters.
1.5
How to Use the Book
Signal enhancement and array signal processing is a broad subject that ﬁnds appli-
cations in many diﬀerent ﬁelds. The background description or even the formulation
of the problem in the literature is generally ﬁeld-oriented, typically starting from the
physics of wave propagation. Thus many students have been deterred from approaching
the subject as it requires confronting, often for the ﬁrst time, both the physics of
wave propagation and the theory of signal processing and optimization. This book is
designed as a textbook and it is written with students and instructors from diﬀerent
backgrounds in mind. To help students from the very diﬀerent backgrounds to quickly
get insight into the problem, we choose to focus on the theory, principles, and meth-
ods of signal enhancement and array signal processing from a purely signal process-
ing perspective. Readers can then enjoy studying the fundamentals of the problem
instead of enduring the introductory material on wave propagation in diﬀerent types
of media.
The material is designed for both advanced undergraduate students and graduate
students. A one-semester advanced graduate course can cover virtually all of the text.
However, there are also a few other ways to break the material into short courses for
teaching advanced undergraduate or junior graduate students. First, a straightforward
way is to break the material into two courses: from Chapter to Chapter for a
course on signal enhancement and from Chapter to Chapter for a course on array
signal processing. Chapter serves as the basis for comprehending the material in
Chapters , , and . A short course on signal enhancement and array beamforming
in the time domain can be designed using the material presented in Chapters , ,
, and , and the rest of the material can be considered optional. Alternatively, a
short course on signal enhancement and array beamforming can be taught based on
all the material related to the frequency-domain theory and methods, in Chapters , ,
and –.
www.ebook3000.com

Introduction
17
References
1 Y. Huang, J. Benesty, and J. Chen, Acoustic MIMO Signal Processing. Berlin, Germany:
Springer-Verlag, .
2 J. Benesty, M. M. Sondhi, and Y. Huang, Eds., Springer Handbook of Speech Processing.
Berlin, Germany: Springer-Verlag, .
3 J. Benesty, J. Chen, and Y. Huang, Microphone Array Signal Processing. Berlin,
Germany: Springer-Verlag, .
4 N. Wiener, Extrapolation, Interpolation, and Smoothing of Stationary Time Series.
New York: Wiley, .
5 J. Benesty, J. Chen, Y. Huang, and S. Doclo, “Study of the Wiener ﬁlter for noise
reduction,” in Speech Enhancement, J. Benesty, S. Makino, and J. Chen (eds). Berlin,
Germany: Springer-Verlag, , Chapter , pp. –.
6 J. Chen, J. Benesty, Y. Huang, and S. Doclo, “New insights into the noise reduction
Wiener ﬁlter,” IEEE Trans. Audio, Speech, Language Process., vol. , pp. –, Jul.
.
7 J. Benesty and J. Chen, Optimal Time-domain Noise Reduction Filters – A Theoretical
Study. Springer Briefs in Electrical and Computer Engineering, .
8 J. Benesty, J. Chen, Y. Huang, and I. Cohen, Noise Reduction in Speech Processing.
Berlin, Germany: Springer-Verlag, .
9 K. K. Paliwal and A. Basu, “A speech enhancement method based on Kalman ﬁltering,”
in Proc. IEEE ICASSP, , pp. –.
10 J. S. Lim (ed.), Speech Enhancement. Englewood Cliﬀs, NJ: Prentice-Hall, .
11 D. L. Wang, “On ideal binary mask as the computational goal of auditory scene
analysis,” in Speech Separation by Humans and Machines, P. Divenyi (ed.). Norwell, MA:
Kluwer, pp. –.
12 M. R. Schroeder, “Apparatus for suppressing noise and distortion in communication
signals,” U.S. Patent No. ,,, ﬁled Dec. , issued Apr. .
13 S. F. Boll, “Suppression of acoustic noise in speech using spectral subtraction,” IEEE
Trans. Acoust., Speech, Signal Process., vol. ASSP-, pp. –, Apr. .
14 R. J. McAulay and M. L. Malpass, “Speech enhancement using a soft-decision noise
suppression ﬁlter,” IEEE Trans. Acoust., Speech, Signal Process., vol. ASSP-, pp.
–, Apr. .
15 Y. Ephraim and D. Malah, “Speech enhancement using a minimum mean-square error
short-time spectral amplitude estimator,” IEEE Trans. Acoust., Speech, Signal Process.,
vol. ASSP-, pp. –, Dec. .
16 H. L. van Trees, Detection, Estimation, and Modulation Theory, Optimum Array
Processing (Part IV). Hoboken, NJ: Wiley-Interscience, .
17 D. H. Johnson and D. E. Dudgeon, Array Signal Processing: Concepts and Techniques.
Upper Saddle River, NJ: Prentice Hall, .
18 S. Haykin, Array Signal Processing. Upper Saddle River, NJ: Prentice-Hall, .
19 M. Sullivan, Practical Array Processing. New York: McGraw-Hill Education, .
20 M. A. Richards, Fundamentals of Radar Signal Processing, nd edn. New York:
McGraw-Hill, .
21 P. S. Naidu, Sensor Array Signal Processing, nd edn. Boca Raton, FL: CRC Press, .
22 S. Haykin and K. J. R. Liu, Handbook on Array Processing and Sensor Networks.
Hoboken, NJ: Wiley & Sons, .

18
Fundamentals of Signal Enhancement and Array Signal Processing
23 H. Krim and M. Viberg, “Two decades of array signal processing research: the
parametric approach,” IEEE Sig. Process. Mag., vol. , pp. –, Jul. .
24 J. Benesty and J. Chen, Study and Design of Diﬀerential Microphone Arrays. Berlin,
Germany: Springer-Verlag, .
25 J. Benesty, J. Chen, and I.Cohen, Design of Circular Diﬀerential Microphone Arrays.
Switzerland: Springer, .
26 M. Brandstein and D. Ward (eds), Microphone Arrays: Signal Processing Techniques and
Applications. Berlin, Germany: Springer-Verlag, .
27 J. Capon, “High resolution frequency-wavenumber spectrum analysis,” Proc. IEEE,
vol. , pp. –, Aug. .
28 O. L. Frost, III, “An algorithm for linearly constrained adaptive array processing,” Proc.
IEEE, vol. , pp. –, Aug. .
29 L. J. Griﬃths and C. W. Jim, “An alternative approach to linearly constrained adaptive
beamforming,” IEEE Trans. Antennas Propag., vol.AP-, pp. –, Jan. .
30 H. Cox, R. M. Zeskind, and M. M. Owen, “Robust adaptive beamforming,” IEEE Trans.
Acoust., Speech, Signal Process., vol. ASSP-, pp. –, Oct. .
31 D. G. Manolakis, D. Manolakis, V. K. Ingle, and S. M. Kogon, Statistical and Adaptive
Signal Processing: Spectral Estimation, Signal Modeling, Adaptive Filtering and Array
Processing. Norwood, MA: Artech House, .
32 W. Herbordt, Sound Capture for Human/Machine Interfaces: Practical Aspects of
Microphone Array Signal Processing. Berlin, Germany: Springer, .
www.ebook3000.com

19
Part I
Signal Enhancement

21
2
Single-channel Signal Enhancement in the Time Domain
This chapter is dedicated to the study of the signal enhancement problem in the time
domain with a single sensor. We show how to fully exploit the temporal information
in order to reduce the level of the additive noise from the observations. It is divided
into two parts. In the ﬁrst half, we study this fundamental problem from the classical
Wiener ﬁltering perspective. In the second half, we develop a spectral approach,
which is based on the joint diagonalization of the desired and noise signal correlation
matrices. For both methods, the problem is clearly formulated, performance measures
are deﬁned, and useful optimal ﬁlters are derived. Examples are also given to show the
beneﬁts of both approaches.
2.1
Signal Model and Problem Formulation
In this chapter, we are concerned with the signal enhancement (or noise reduction)
problem, in which the desired time-domain signal, x(t), with t being the discrete-time
index, needs to be recovered from the noisy observation (sensor signal) [–]:
y(t) = x(t) + v(t),
(.)
where v(t) is the unwanted additive noise signal, which is assumed to be uncorrelated
with x(t). All signals are considered to be real, zero mean, stationary, and broadband.
The signal model given in (.) can be put into a vector form by considering the L most
recent successive time samples:
𝐲(t) = 𝐱(t) + 𝐯(t),
(.)
where
𝐲(t) =
[ y(t)
y(t −)
⋯
y(t −L + ) ]T
(.)
is a vector of length L, superscriptT denotes transpose of a vector or a matrix, and
𝐱(t) and 𝐯(t) are deﬁned in a similar way to 𝐲(t) from (.). Since x(t) and v(t) are
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing
www.ebook3000.com

22
Fundamentals of Signal Enhancement and Array Signal Processing
uncorrelated by assumption, the correlation matrix (of size L × L) of the noisy signal
can be written as
𝐑𝐲= E [𝐲(t)𝐲T(t)]
(.)
= 𝐑𝐱+ 𝐑𝐯,
where E[⋅] denotes mathematical expectation, and 𝐑𝐱=E
[
𝐱(t)𝐱T(t)
]
and 𝐑𝐯=E [𝐯(t)
𝐯T(t)] are the correlation matrices of 𝐱(t) and 𝐯(t), respectively. We always assume
in this chapter that the noise correlation matrix is full rank; in other words,
rank
(
𝐑𝐯
)
= L.
The objective of single-channel noise reduction in the time domain is to ﬁnd a “good”
estimate of the sample x(t) from the vector 𝐲(t) []. By good, we mean that the additive
noise, v(t), is signiﬁcantly reduced while the desired signal, x(t), is not much distorted.
In the following, we develop two important approaches: the conventional one, which
is based on the fundamental Wiener ﬁltering, and the spectral approach, which is based
on the spectrum of the desired and noise signals.
2.2
Wiener Method
This section is concerned with the fundamental Wiener ﬁltering theory, which fully
exploits the second-order statistics of the signals through the optimization of the
classical mean-squared error criterion.
2.2.1
Linear Filtering
We try to estimate the desired signal sample, x(t), by applying a real-valued linear ﬁlter
to the observation signal vector, 𝐲(t):
z(t) =
L
∑
l=
hly(t + −l)
(.)
= 𝐡T𝐲(t),
where z(t) is the estimate of x(t) and
𝐡= [ h
h
⋯
hL
]T
(.)
is a ﬁlter of length L (see Figure .). This procedure is called single-channel signal
enhancement in the time domain.
Using (.), we can express (.) as
z(t) = 𝐡T [𝐱(t) + 𝐯(t)]
(.)
= xfd(t) + vrn(t),
where
xfd(t) = 𝐡T𝐱(t)
(.)

Single-channel Signal Enhancement in the Time Domain
23
+
v(t)
hT
x(t)
y(t)
z(t)
Figure 2.1 Block diagram of linear filtering in the time domain.
is the ﬁltered desired signal and
vrn(t) = 𝐡T𝐯(t)
(.)
is the residual noise.
Since the estimate of the desired signal at time t is the sum of two terms that are
uncorrelated, the variance of z(t) is
𝜎
z = E
[
z(t)
]
(.)
= 𝐡T𝐑𝐲𝐡
= 𝜎
xfd + 𝜎
vrn,
where
𝜎
xfd = 𝐡T𝐑𝐱𝐡
(.)
is the variance of the ﬁltered desired signal and
𝜎
vrn = 𝐡T𝐑𝐯𝐡
(.)
is the variance of the residual noise. The variance of z(t) is useful in some of the
deﬁnitions of the performance measures.
2.2.2
Performance Measures
The ﬁrst attempts to derive relevant and rigorous measures in the context of sig-
nal enhancement can be found in the literature [, , ]. These references are the
main inspiration for the derivation of measures in the studied context throughout
this work.
We are now ready to deﬁne the most important performance measures in the general
context of signal enhancement described in Section .. We can divide these measures
into two distinct but related categories. The ﬁrst category evaluates the noise reduction
performance while the second one evaluates the distortion of the desired signal. We also
discuss the very convenient mean-squared error criterion and show how it is related to
the performance measures.
www.ebook3000.com

24
Fundamentals of Signal Enhancement and Array Signal Processing
One of the most fundamental measures in all aspects of signal enhancement is the
signal-to-noise ratio (SNR). The input SNR is a second-order measure, which quantiﬁes
the level of the noise present relative to the level of the desired signal. It is deﬁned as
iSNR =
tr
(
𝐑𝐱
)
tr (𝐑𝐯
)
(.)
=
𝜎
x
𝜎
v
,
where tr(⋅) denotes the trace of a square matrix, and 𝜎
x = E [x(t)] and 𝜎
v = E [v(t)]
are the variances of the desired and noise signals, respectively.
The output SNR helps quantify the level of the noise remaining in the ﬁlter output
signal. The output SNR is obtained from (.):
oSNR (𝐡) =
𝜎
xfd
𝜎
vrn
(.)
= 𝐡T𝐑𝐱𝐡
𝐡T𝐑𝐯𝐡.
Basically, (.) is the variance of the ﬁrst signal (ﬁltered desired signal) from the right-
hand side of (.) over the variance of the second signal (ﬁltered noise). The objective
of the signal enhancement ﬁlter is to make the output SNR greater than the input SNR.
Consequently, the quality of the ﬁltered output signal, z(t), is enhanced compared to the
noisy signal, y(t).
For a particular ﬁlter of length L:
𝐢i = [ 

⋯
]T ,
(.)
we have
oSNR (𝐢i
) = iSNR.
(.)
With the identity ﬁlter, 𝐢i, the SNR cannot be improved.
The noise reduction factor quantiﬁes the amount of noise being rejected by the ﬁlter.
This quantity is deﬁned as the ratio of the power of the noise at the sensor over the
power of the noise remaining at the ﬁlter output:
𝜉n (𝐡) =
𝜎
v
𝐡T𝐑𝐯𝐡.
(.)
The noise reduction factor is expected to be lower bounded by ; otherwise, the ﬁlter
ampliﬁes the noise received at the sensor. The higher the value of the noise reduction
factor, the more noise is rejected. While the output SNR is upper bounded, the noise
reduction factor is not.

Single-channel Signal Enhancement in the Time Domain
25
Since the noise is reduced by the ﬁltering operation, so is, in general, the desired
signal. This desired signal reduction (or cancellation) implies, in general, distortion. The
desired signal reduction factor, the deﬁnition of which is somewhat similar to the noise
reduction factor, is deﬁned as the ratio of the variance of the desired signal at the sensor
over the variance of the ﬁltered desired signal:
𝜉d (𝐡) =
𝜎
x
𝐡T𝐑𝐱𝐡.
(.)
The closer the value of 𝜉d (𝐡) is to , the less distorted is the desired signal.
It is easy to verify that we have the following fundamental relation:
oSNR (𝐡)
iSNR
= 𝜉n (𝐡)
𝜉d (𝐡).
(.)
This expression indicates the equivalence between gain/loss in SNR and distortion (of
both the desired and noise signals).
Another way to measure the distortion of the desired signal due to the ﬁltering
operation is via the desired signal distortion index, which is deﬁned as the mean-
squared error between the desired signal and the ﬁltered desired signal, normalized
by the variance of the desired signal:
𝜐d (𝐡) =
E
{[
xfd(t) −x(t)
]}
E
[
x(t)
]
(.)
=
(𝐡−𝐢i
)T 𝐑𝐱
(𝐡−𝐢i
)
𝜎
x
.
The desired signal distortion index is close to if there is no distortion and will be
greater than when distortion occurs.
Error criteria play a critical role in deriving optimal ﬁlters. The mean-squared error
(MSE) [] is, by far, the most practical one. We deﬁne the error signal between the
estimated and desired signals as
e(t) = z(t) −x(t)
(.)
= xfd(t) + vrn(t) −x(t),
which can be written as the sum of two uncorrelated error signals:
e(t) = ed(t) + en(t),
(.)
where
ed(t) = xfd(t) −x(t)
(.)
=
(
𝐡−𝐢i
)T 𝐱(t)
www.ebook3000.com

26
Fundamentals of Signal Enhancement and Array Signal Processing
is the desired signal distortion due to the ﬁlter and
en(t) = vrn(t)
(.)
= 𝐡T𝐯(t)
represents the residual noise. Therefore, the MSE criterion is
J (𝐡) = E
[
e(t)
]
(.)
= 𝜎
x −𝐡T𝐑𝐱𝐢i + 𝐡T𝐑𝐲𝐡
= Jd (𝐡) + Jn (𝐡) ,
where
Jd (𝐡) = E [e
d(t)]
(.)
= (𝐡−𝐢i
)T 𝐑𝐱
(𝐡−𝐢i
)
= 𝜎
x𝜐d (𝐡)
and
Jn (𝐡) = E [e
n(t)]
(.)
= 𝐡T𝐑𝐯𝐡
=
𝜎
v
𝜉n (𝐡).
We deduce that
J (𝐡) = 𝜎
v
[
iSNR × 𝜐d (𝐡) +

𝜉n (𝐡)
]
(.)
and
Jd (𝐡)
Jn (𝐡) = iSNR × 𝜉n (𝐡) × 𝜐d (𝐡)
(.)
= oSNR (𝐡) × 𝜉d (𝐡) × 𝜐d (𝐡) .
We observe how the MSEs are related to the diﬀerent performance measures.
2.2.3
Optimal Filters
In this subsection, we derive the most important Wiener and Wiener-type ﬁlters that
can help mitigate the level of the noise picked up by the sensor.
The Wiener ﬁlter is derived by taking the gradient of the MSE, J (𝐡) from Equa-
tion (.), with respect to 𝐡and equating the result to zero:
𝐡W = 𝐑−
𝐲𝐑𝐱𝐢i.
(.)

Single-channel Signal Enhancement in the Time Domain
27
This optimal ﬁlter can also be expressed as
𝐡W =
(
𝐈L −𝐑−
𝐲𝐑𝐯
)
𝐢i,
(.)
where 𝐈L is the identity matrix of size L × L. The above formulation is more useful than
(.) in practice, since it depends on the second-order statistics of the observation
and noise signals. The correlation matrix 𝐑𝐲can be immediately estimated from the
observation signal while the other correlation matrix, 𝐑𝐯, is often known or can be
indirectly estimated. In speech applications, for example, this matrix can be estimated
during silences.
Let us deﬁne the normalized correlation matrices:
𝚪𝐯= 𝐑𝐯
𝜎
v
,
𝚪𝐱= 𝐑𝐱
𝜎
x
,
𝚪𝐲=
𝐑𝐲
𝜎
y
.
Another way to write the Wiener ﬁlter is
𝐡W =
(
𝐈L
iSNR + 𝚪−
𝐯𝚪𝐱
)−
𝚪−
𝐯𝚪𝐱𝐢i
(.)
= 𝜌(x, y)𝚪−
𝐲𝚪𝐱𝐢i
=
[
𝐈L −𝜌(v, y)𝚪−
𝐲𝚪𝐯
]
𝐢i,
where
𝜌(x, y) =
E[x(t)y(t)]
𝜎
x𝜎
y
(.)
=
𝜎
x
𝜎
y
=
iSNR
+ iSNR
is the squared Pearson correlation coeﬃcient (SPCC) between x(t) and y(t), and
𝜌(v, y) =
E[
v(t)y(t)
]
𝜎
v𝜎
y
(.)
=
𝜎
v
𝜎
y
=

+ iSNR
www.ebook3000.com

28
Fundamentals of Signal Enhancement and Array Signal Processing
is the SPCC between v(t) and y(t). We can see from (.) that
lim
iSNR→∞𝐡W = 𝐢i,
(.)
lim
iSNR→𝐡W = 𝟎,
(.)
where 𝟎is the zero vector. Clearly, the Wiener ﬁlter can have a disastrous eﬀect at very
low input SNRs since it may remove both noise and desired signals.
Hence, the estimate of the desired signal with the Wiener ﬁlter is
zW(t) = 𝐡T
W𝐲(t).
(.)
We now describe a fundamental property, which was ﬁrst shown by Chen et al. [].
Property ..
With the optimal Wiener ﬁlter (.), the output SNR is always greater
than or equal to the input SNR: oSNR (𝐡W
) ≥iSNR.
Proof. There are diﬀerent ways to show this property. Here, we do so with the help of
the diﬀerent SPCCs []. We recall that for any two zero-mean random variables a(t) and
b(t), we have
≤𝜌(a, b) ≤.
(.)
It can be checked that
𝜌(x, z) = 𝜌(x, xfd
) × 𝜌(xfd, z) ≤𝜌(xfd, z) ,
(.)
where
𝜌(
xfd, z
)
=
oSNR (𝐡)
+ oSNR (𝐡).
(.)
As a result, we have
𝜌(
x, zW
)
≤
oSNR (𝐡W
)
+ oSNR (𝐡W
).
(.)
Let us evaluate the SPCC between y(t) and zW(t):
𝜌(y, zW) =
(
𝐢T
i 𝐑𝐲𝐡W
)
𝜎
y𝐡T
W𝐑𝐲𝐡W
=
𝜎
x
𝜎
y
×
𝜎
x
𝐢T
i 𝐑𝐱𝐡W
= 𝜌(x, y)
𝜌(x, zW).

Single-channel Signal Enhancement in the Time Domain
29
Therefore,
𝜌(x, y) = 𝜌(y, zW) × 𝜌(x, zW) ≤𝜌(x, zW).
(.)
Substituting (.) and (.) into (.), we get
iSNR
+ iSNR ≤
oSNR (𝐡W
)
+ oSNR (𝐡W
),
which we can slightly rearrange to give:

+

iSNR
≤

+

oSNR (𝐡W
)
,
which implies that

iSNR ≥

oSNR (𝐡W
).
Consequently, we have
oSNR
(
𝐡W
)
≥iSNR.
■
The minimum MSE (MMSE) is obtained by replacing (.) in (.):
J (𝐡W
) = 𝜎
x −𝐢T
i 𝐑𝐱𝐑−
𝐲𝐑𝐱𝐢i
(.)
= 𝜎
v −𝐢T
i 𝐑𝐯𝐑−
𝐲𝐑𝐯𝐢i,
which can be rewritten as
J
(
𝐡W
)
= 𝜎
x
[
−𝜌(x, zW)
]
(.)
= 𝜎
v
[−𝜌(v, y −zW)] .
Clearly, we always have
J (𝐡W
) ≤J (𝐡) , ∀𝐡
(.)
and, in particular,
J (𝐡W
) ≤J (𝐢i
) = 𝜎
v.
(.)
The diﬀerent performance measures with the Wiener ﬁlter are
oSNR
(
𝐡W
)
=
𝐢T
i 𝐑𝐱𝐑−
𝐲𝐑𝐱𝐑−
𝐲𝐑𝐱𝐢i
𝐢T
i 𝐑𝐱𝐑−
𝐲𝐑𝐯𝐑−
𝐲𝐑𝐱𝐢i
≥iSNR,
(.)
www.ebook3000.com

30
Fundamentals of Signal Enhancement and Array Signal Processing
𝜉n
(
𝐡W
)
=
𝜎
v
𝐢T
i 𝐑𝐱𝐑−
𝐲𝐑𝐯𝐑−
𝐲𝐑𝐱𝐢i
≥,
(.)
𝜉d
(
𝐡W
)
=
𝜎
x
𝐢T
i 𝐑𝐱𝐑−
𝐲𝐑𝐱𝐑−
𝐲𝐑𝐱𝐢i
≥,
(.)
𝜐d
(𝐡W
) =
(
𝐑−
𝐲𝐑𝐱𝐢i −𝐢i
)T
𝐑𝐱
(
𝐑−
𝐲𝐑𝐱𝐢i −𝐢i
)
𝜎
x
≤.
(.)
Example ..
Suppose that the desired signal is a harmonic random process:
x(t) = A cos (𝜋ft + 𝜙) ,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly distributed on
the interval from to 𝜋. This signal needs to be recovered from the noisy observation
y(t) = x(t) + v(t), where v(t) is additive white Gaussian noise – in other words, v(t) ∼
(, 𝜎
v
) – that is uncorrelated with x(t).
The input SNR is
iSNR = log A∕
𝜎
v
(dB).
The correlation matrix of 𝐯(t) is 𝐑𝐯
=
𝜎
v𝐈L, and the elements of the correlation
matrix of 𝐱(t) are
[
𝐑𝐱
]
i,j = 
Acos
[
𝜋f(i −j)
]
. Since the desired and noise signals are
uncorrelated, the correlation matrix of the observation signal vector 𝐲(t) is 𝐑𝐲= 𝐑𝐱+𝐑𝐯.
The optimal ﬁlter 𝐡W is obtained from (.). The output SNR and the MMSE are
obtained by substituting 𝐡W into (.) and (.), respectively.
To demonstrate the performance of the Wiener ﬁlter, we choose A = ., f= .,
and 𝜎
v = .. The input SNR is −.dB. Figure .shows the eﬀect of the ﬁlter length,
L, on the gain in SNR, (𝐡W) = oSNR (𝐡W
) ∕iSNR, and the MMSE, J(𝐡W). As the length
of the ﬁlter increases, the Wiener ﬁlter better enhances the harmonic signal, in terms
of higher gain in SNR and lower MMSE. If we choose a ﬁxed ﬁlter length, L = ,
and change 𝜎
v so that iSNR varies from to dB, then Figure .shows plots of the
output SNR and the MMSE as a function of the input SNR. Figure .shows plots of
the noise reduction factor, 𝜉n
(𝐡W
), the desired signal reduction factor, 𝜉d
(𝐡W
), and the
desired signal distortion index, 𝜐d
(
𝐡W
)
, as a function of the input SNR. Figure .shows
a realization of the noise corrupted and ﬁltered sinusoidal signals for iSNR = dB.
■
The objective of the Wiener ﬁlter is to minimize the MSE; therefore, it leads to the
MMSE. However, this optimal ﬁlter is inﬂexible since it is not possible to compromise
between desired signal distortion and noise reduction. It is instructive to observe
that the MSE as given in (.) is the sum of two other MSEs. One depends on the
desired signal distortion while the other depends on the noise reduction. Instead of
minimizing the MSE with respect to 𝐡as already done to ﬁnd the Wiener ﬁlter, we
can instead minimize the distortion-based MSE subject to the constraint that the
noise-reduction-based MSE is equal to some desired value. Mathematically, this is
equivalent to

Single-channel Signal Enhancement in the Time Domain
31
10
20
30
40
50
60
0
5
10
15
(a)
(b)
10
20
30
40
50
60
−22
−20
−18
−16
−14
−12
−10
L
L
J (hW) (dB)
 (hW) (dB)
Figure 2.2 (a) The gain in SNR and (b) the MMSE of the Wiener filter as a function of the filter length.
0
5
10
15
20
10
15
20
25
30
35
(a)
(b)
0
5
10
15
20
−45
−40
−35
−30
−25
−20
iSNR (dB)
iSNR (dB)
oSNR (hW) (dB)
J (hW) (dB)
Figure 2.3 (a) The output SNR and (b) the MMSE of the Wiener filter as a function of the input SNR.
min
𝐡Jd (𝐡)
subject to Jn (𝐡) = ℵ𝜎
v,
(.)
where < ℵ< to ensure that we have some noise reduction. If we use a Lagrange
multiplier, 𝜇, to adjoin the constraint to the cost function, (.) can be rewritten as
𝐡T,𝜇= arg min
𝐡(𝐡, 𝜇),
(.)
with
(𝐡, 𝜇) = Jd (𝐡) + 𝜇[Jn (𝐡) −ℵ𝜎
v
]
(.)
and 𝜇≥. From (.), we easily derive the tradeoﬀﬁlter:
𝐡T,𝜇=
(
𝐑𝐱+ 𝜇𝐑𝐯
)−𝐑𝐱𝐢i
(.)
=
[
𝐑𝐲+ (𝜇−)𝐑𝐯
]−(
𝐑𝐲−𝐑𝐯
)
𝐢i,
www.ebook3000.com

32
Fundamentals of Signal Enhancement and Array Signal Processing
0
5
10
15
20
(a)
(b)
(c)
0
5
10
15
20
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0
5
10
15
20
−70
−60
−50
−40
−30
−20
iSNR (dB)
iSNR (dB)
iSNR (dB)
ξn (hW) (dB)
ξd (hW) (dB)
υd (hW) (dB)
11.7
11.8
11.9
12
12.1
12.2
12.3
12.4
Figure 2.4 (a) The noise reduction factor, (b) the desired signal reduction factor, and (c) the desired
signal distortion index of the Wiener filter as a function of the input SNR.
0
100
200
300
400
500
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
1
0
100
200
300
400
500
−1
−0.5
0
0.5
t
t
(a)
(b)
Amplitude
Amplitude
Figure 2.5 Example of (a) noise-corrupted and (b) Wiener-filtered sinusoidal signals.

Single-channel Signal Enhancement in the Time Domain
33
where the Lagrange multiplier, 𝜇, satisﬁes Jn
(𝐡T,𝜇
) = ℵ𝜎
v, which implies that
𝜉n
(𝐡T,𝜇
) = 
ℵ> .
(.)
In practice it is not easy to determine the optimal 𝜇. Therefore, when this parameter
is chosen in a heuristic way, we can see that for
●𝜇= , 𝐡T,= 𝐡W, which is the Wiener ﬁlter
●𝜇= , 𝐡T,= 𝐢i, which is the identity ﬁlter
●𝜇> results in a ﬁlter with low residual noise at the expense of high desired signal
distortion
●𝜇< results in a ﬁlter with low desired signal distortion and small amount of noise
reduction.
We are now ready to give a fundamental property about the tradeoﬀﬁlter.
Property ..
With the tradeoﬀﬁlter given in (.), the output SNR is always
greater than or equal to the input SNR: oSNR (𝐡T,𝜇
) ≥iSNR, ∀𝜇≥.
Proof. The SPCC between x(t) and x(t) + √𝜇v(t) is
𝜌(
x, x +
√
𝜇v
)
=
𝜎
x
𝜎
x
(𝜎
x + 𝜇𝜎
v
)
=
iSNR
𝜇+ iSNR.
The SPCC between x(t) and 𝐡T
T,𝜇𝐱(t) + √𝜇𝐡T
T,𝜇𝐯(t) is
𝜌(
x, 𝐡T
T,𝜇𝐱+
√
𝜇𝐡T
T,𝜇𝐯
)
=
(
𝐡T
T,𝜇𝐑𝐱𝐢i
)
𝜎
x𝐡T
T,𝜇
(
𝐑𝐱+ 𝜇𝐑𝐯
)
𝐡T,𝜇
=
𝐡T
T,𝜇𝐑𝐱𝐢i
𝜎
x
.
Another way to write the same SPCC is the following:
𝜌(
x, 𝐡T
T,𝜇𝐱+
√
𝜇𝐡T
T,𝜇𝐯
)
=
(
𝐡T
T,𝜇𝐑𝐱𝐢i
)
𝜎
x𝐡T
T,𝜇𝐑𝐱𝐡T,𝜇
×
oSNR
(
𝐡T,𝜇
)
𝜇+ oSNR
(
𝐡T,𝜇
)
= 𝜌(
x, 𝐡T
T,𝜇𝐱
)
×
𝜌(
𝐡T
T,𝜇𝐱, 𝐡T
T,𝜇𝐱+
√
𝜇𝐡T
T,𝜇𝐯
)
≤
oSNR (𝐡T,𝜇
)
𝜇+ oSNR (𝐡T,𝜇
).
www.ebook3000.com

34
Fundamentals of Signal Enhancement and Array Signal Processing
Now, let us evaluate the SPCC between x(t) + √𝜇v(t) and 𝐡T
T,𝜇𝐱(t) + √𝜇𝐡T
T,𝜇𝐯(t):
𝜌(
x +
√
𝜇v, 𝐡T
T,𝜇𝐱+
√
𝜇𝐡T
T,𝜇𝐯
)
=
[
𝐡T
T,𝜇
(𝐑𝐱+ 𝜇𝐑𝐯
) 𝐢i
]
(𝜎
x + 𝜇𝜎
v
) 𝐡T
T,𝜇
(𝐑𝐱+ 𝜇𝐑𝐯
) 𝐡T,𝜇
=
𝜎
x
𝜎
x + 𝜇𝜎
v
×
𝜎
x
𝐡T
T,𝜇𝐑𝐱𝐢i
=
𝜌(x, x + √𝜇v)
𝜌
(
x, 𝐡T
T,𝜇𝐱+ √𝜇𝐡T
T,𝜇𝐯
).
Therefore,
𝜌(x, x +
√
𝜇v) =
iSNR
𝜇+ iSNR
= 𝜌(
x +
√
𝜇v, 𝐡T
T,𝜇𝐱+
√
𝜇𝐡T
T,𝜇𝐯
)
×
𝜌(
x, 𝐡T
T,𝜇𝐱+
√
𝜇𝐡T
T,𝜇𝐯
)
≤𝜌(
x, 𝐡T
T,𝜇𝐱+
√
𝜇𝐡T
T,𝜇𝐯
)
≤
oSNR
(
𝐡T,𝜇
)
𝜇+ oSNR
(
𝐡T,𝜇
).
As a result,
oSNR (𝐡T,𝜇
) ≥iSNR.
■
Example ..
Consider a desired signal, x(t), with the autocorrelation sequence:
E [x(t)x(t′)] = 𝛼|t−t′|,
−< 𝛼< ,
which is corrupted by additive white Gaussian noise v(t) ∼(, 𝜎
v
)
that is uncor-
related with x(t). The desired signal needs to be recovered from the noisy observation
y(t) = x(t) + v(t).
The input SNR is
iSNR = log 
𝜎
v
(dB).
The correlation matrix of 𝐯(t) is 𝐑𝐯= 𝜎
v𝐈L, and the elements of the correlation matrix of
𝐱(t) are
[
𝐑𝐱
]
i,j = 𝛼|i−j|. Since the desired signal and the noise signal are uncorrelated, the

Single-channel Signal Enhancement in the Time Domain
35
0
5
10
15
20
4.8
5
5.2
5.4
5.6
0
5
10
15
20
−4
−3.8
−3.6
−3.4
−3.2
−3
−2.8
−2.6
−2.4
0
5
10
15
20
11
12
13
14
15
16
0
5
10
15
20
6
6.5
7
7.5
8
8.5
9
9.5
10
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(a)
(b)
(c)
(d)
ξn hT,μ  (dB)
ξd hT,μ  (dB)
J hT,μ  (dB)
hT,μ  (dB)
Figure 2.6 (a) The gain in SNR, (b) the MSE, (c) the noise reduction factor, and (d) the desired signal
reduction factor of the tradeoff filter as a function of the input SNR for several values of ℵ: ℵ= −12 dB
(solid line with circles), ℵ= −13 dB (dashed line with asterisks), ℵ= −14 dB (dotted line with squares),
and ℵ= −15 dB (dash-dot line with triangles).
correlation matrix of observation signal vector 𝐲(t) is 𝐑𝐲= 𝐑𝐱+ 𝐑𝐯. The tradeoﬀﬁlter
𝐡T,𝜇is obtained from (.), where the Lagrange multiplier, 𝜇, satisﬁes Jn
(
𝐡T,𝜇
)
= ℵ𝜎
v.
To demonstrate the performance of the tradeoﬀﬁlter, we choose 𝛼= ., a ﬁlter
length L = , and several values of ℵ. Figure .shows plots of the gain in SNR,

(
𝐡T,𝜇
)
, the MSE, J
(
𝐡T,𝜇
)
, the noise reduction factor, 𝜉n
(
𝐡T,𝜇
)
, and the desired signal
reduction factor, 𝜉d
(
𝐡T,𝜇
)
, as a function of the input SNR, for several values of ℵ.
Figure .c shows that the tradeoﬀﬁlter satisﬁes 𝜉n
(𝐡T,𝜇
) = −log(ℵ) dB.
■
Both Wiener and tradeoﬀﬁlters always distort the desired signal since 𝜉d
(
𝐡T,𝜇
)
≠,
∀𝜇≥. It is fair to ask if it is possible to derive a distortionless ﬁlter that can mitigate the
level of the noise. The answer is positive so long as the desired signal correlation matrix is
rank deﬁcient. Let us assume that rank
(
𝐑𝐱
)
= P ≤L. Using the well-known eigenvalue
decomposition [], the desired signal correlation matrix can be diagonalized as
𝐐T
𝐱𝐑𝐱𝐐𝐱= 𝚲𝐱,
(.)
www.ebook3000.com

36
Fundamentals of Signal Enhancement and Array Signal Processing
where
𝐐𝐱= [ 𝐪𝐱,
𝐪𝐱,
⋯
𝐪𝐱,L
]
(.)
is an orthogonal matrix (in other words, 𝐐T
𝐱𝐐𝐱= 𝐐𝐱𝐐T
𝐱= 𝐈L) and
𝚲𝐱= diag (𝜆𝐱,, 𝜆𝐱,, … , 𝜆𝐱,L
)
(.)
is a diagonal matrix. The orthonormal vectors 𝐪𝐱,, 𝐪𝐱,, … , 𝐪𝐱,L are the eigenvectors
corresponding, respectively, to the eigenvalues 𝜆𝐱,, 𝜆𝐱,, … , 𝜆𝐱,L of the matrix 𝐑𝐱, where
𝜆𝐱,≥𝜆𝐱,≥⋯≥𝜆𝐱,P > and 𝜆𝐱,P+= 𝜆𝐱,P+= ⋯= 𝜆𝐱,L = . Let
𝐐𝐱= [ 𝐐′
𝐱
𝐐′′
𝐱
] ,
(.)
where the L × P matrix 𝐐′
𝐱contains the eigenvectors corresponding to the nonzero
eigenvalues of 𝐑𝐱and the L×(L−P) matrix 𝐐′′
𝐱contains the eigenvectors corresponding
to the null eigenvalues of 𝐑𝐱. It can be veriﬁed that
𝐈L = 𝐐′
𝐱𝐐′T
𝐱+ 𝐐′′
𝐱𝐐′′T
𝐱.
(.)
Notice that 𝐐′
𝐱𝐐′T
𝐱and 𝐐′′
𝐱𝐐′′T
𝐱
are two orthogonal projection matrices of rank P and
L −P, respectively. Hence, 𝐐′
𝐱𝐐′T
𝐱is the orthogonal projector onto the desired signal
subspace (where all the energy of the desired signal is concentrated) or the range of 𝐑𝐱.
𝐐′′
𝐱𝐐′′T
𝐱
is the orthogonal projector onto the null subspace of 𝐑𝐱. Using (.), we can
write the desired signal vector as
𝐱(t) = 𝐐𝐱𝐐T
𝐱𝐱(t)
(.)
= 𝐐′
𝐱𝐐′T
𝐱𝐱(t).
We deduce from (.) that the distortionless constraint is
𝐡T𝐐′
𝐱= 𝐢T
i 𝐐′
𝐱,
(.)
since, in this case,
𝐡T𝐱(t) = 𝐡T𝐐′
𝐱𝐐′T
𝐱𝐱(t)
(.)
= 𝐢T
i 𝐐′
𝐱𝐐′T
𝐱𝐱(t)
= x(t).
Now, from the minimization of the criterion:
min
𝐡Jn (𝐡)
subject to 𝐡T𝐐′
𝐱= 𝐢T
i 𝐐′
𝐱,
(.)
we ﬁnd the minimum variance distortionless response (MVDR) ﬁlter:
𝐡MVDR = 𝐑−
𝐯𝐐′
𝐱
(𝐐′T
𝐱𝐑−
𝐯𝐐′
𝐱
)−𝐐′T
𝐱𝐢i.
(.)

Single-channel Signal Enhancement in the Time Domain
37
It can be shown that Equation .can also be expressed as
𝐡MVDR = 𝐑−
𝐲𝐐′
𝐱
(
𝐐′T
𝐱𝐑−
𝐲𝐐′
𝐱
)−
𝐐′T
𝐱𝐢i.
(.)
It can be veriﬁed that, indeed, Jd
(𝐡MVDR
) = . Of course, for P = L, the MVDR ﬁlter
degenerates to the identity ﬁlter: 𝐡MVDR = 𝐢i. As a consequence, we can state that the
higher the dimension of the nullspace of 𝐑𝐱, the more the MVDR ﬁlter is eﬃcient in
terms of noise reduction. The best scenario corresponds to P = . For a white noise
signal – in other words, for 𝐑𝐯= 𝜎
v𝐈L – the MVDR ﬁlter simpliﬁes to
𝐡MVDR = 𝐐′
𝐱𝐐′T
𝐱𝐢i,
(.)
which is the minimum-norm solution of (.).
Property ..
With the MVDR ﬁlter given in Equation ., the output SNR is always
greater than or equal to the input SNR: oSNR (𝐡MVDR
) ≥iSNR.
Example ..
Consider a desired signal that is a sum of harmonic random processes:
x(t) =
K
∑
k=
Ak cos (𝜋fkt + 𝜙k
) ,
with ﬁxed amplitudes
{
Ak
}
and frequencies
{
fk
}
, and independent and identically
distributed (IID) random phases {𝜙k
}, uniformly distributed on the interval from 
to 𝜋. This signal needs to be recovered from the noisy observation y(t) = x(t) + v(t),
where v(t) is additive white Gaussian noise, v(t) ∼(, 𝜎
v
), which is uncorrelated
with x(t).
The input SNR is
iSNR = log
∑K
k=A
k
𝜎
v
(dB).
The correlation matrix of 𝐯(t) is 𝐑𝐯= 𝜎
v𝐈L and the elements of the correlation matrix of
𝐱(t) are [𝐑𝐱
]
i,j = 

∑K
k=A
k cos [𝜋fk(i −j)]. The rank of this matrix is rank (𝐑𝐱
) = K.
The MVDR ﬁlter, 𝐡MVDR, for the case of white noise is obtained from (.).
To demonstrate the performance of the MVDR ﬁlter, we choose Ak = .(k =
, … , K), fk = .k (k = , … , K), a ﬁlter length of L = , and several values of K. The
dimension of the nullspace of 𝐑𝐱is L −K. Figure .shows plots of the gain in SNR,

(
𝐡MVDR
)
, the MSE, J
(
𝐡MVDR
)
, the noise reduction factor, 𝜉n
(
𝐡MVDR
)
, and the desired
signal reduction factor, 𝜉d
(𝐡MVDR
), as a function of the input SNR, for several values
of K. Clearly, the desired signal reduction factor is zero, and the higher the dimension
of the nullspace of 𝐑𝐱(smaller K), the higher the noise reduction factor.
■
www.ebook3000.com

38
Fundamentals of Signal Enhancement and Array Signal Processing
0
5
10
15
20
2
4
6
8
10
12
0
5
10
15
20
−50
−40
−30
−20
−10
0
0
5
10
15
20
2
4
6
8
10
12
0
5
10
15
20
−1
−0.5
0
0.5
1
iSNR (dB)
iSNR (dB)
iSNR (dB)
(c)
(d)
(a)
(b)
J (hMVDR) (dB)
   (hMVDR) (dB)
iSNR (dB)
ξd(hMVDR) (dB)
ξn(hMVDR) (dB)
Figure 2.7 (a) The gain in SNR, (b) the MSE, (c) the noise reduction factor, and (d) the desired signal
reduction factor of the MVDR filter as a function of the input SNR for several desired signals with
different values of K: K = 1 (solid line with circles), K = 2 (dashed line with asterisks), K = 4 (dotted line
with squares), and K = 8 (dash-dot line with triangles).
With the eigenvalue decomposition of 𝐑𝐱, the correlation matrix of the observation
signal vector can be written as
𝐑𝐲= 𝐐′
𝐱𝚲′
𝐱𝐐′T
𝐱+ 𝐑𝐯,
(.)
where
𝚲′
𝐱= diag
(
𝜆𝐱,, 𝜆𝐱,, … , 𝜆𝐱,P
)
.
(.)
Determining the inverse of 𝐑𝐲from (.) with the Woodbury’s identity, we get
𝐑−
𝐲= 𝐑−
𝐯−𝐑−
𝐯𝐐′
𝐱
(𝚲′−
𝐱
+ 𝐐′T
𝐱𝐑−
𝐯𝐐′
𝐱
)−𝐐′T
𝐱𝐑−
𝐯.
(.)
Substituting (.) into (.), leads to another useful formulation of the Wiener ﬁlter:
𝐡W = 𝐑−
𝐯𝐐′
𝐱
(𝚲′−
𝐱
+ 𝐐′T
𝐱𝐑−
𝐯𝐐′
𝐱
)−𝐐′T
𝐱𝐢i.
(.)

Single-channel Signal Enhancement in the Time Domain
39
This formulation shows how the MVDR and Wiener ﬁlters are closely related. In the
same way, we can express the tradeoﬀﬁlter as
𝐡T,𝜇= 𝐑−
𝐯𝐐′
𝐱
(𝜇𝚲′−
𝐱
+ 𝐐′T
𝐱𝐑−
𝐯𝐐′
𝐱
)−𝐐′T
𝐱𝐢i.
(.)
This ﬁlter is strictly equivalent to the tradeoﬀﬁlter given in (.), except for 𝜇= ,
where the two give diﬀerent results when 𝐑𝐱is not full rank; the one in (.) leads to
the identity ﬁlter while the one in (.) leads to the MVDR ﬁlter. In fact, the ﬁlter given
in (.) is not deﬁned for 𝜇= and when 𝐑𝐱is not full rank.
So far, we have shown how to exploit the MSE criterion to derive all kinds of useful
optimal ﬁlters. However, we can also exploit the deﬁnition of the output SNR to derive
the so-called maximum SNR ﬁlter. Let us denote by 𝜆the maximum eigenvalue of the
matrix 𝐑−
𝐯𝐑𝐱and by 𝐭the corresponding eigenvector. The maximum SNR ﬁlter, 𝐡max,
is obtained by maximizing the output SNR as given in (.), from which we recognize
the generalized Rayleigh quotient []. It is well known that this quotient is maximized
with the eigenvector corresponding to the maximum eigenvalue of 𝐑−
𝐯𝐑𝐱. Therefore,
we have
𝐡max = 𝜍𝐭,
(.)
where 𝜍≠is an arbitrary real number. We deduce that
oSNR (𝐡max
) = 𝜆.
(.)
Clearly, we always have
oSNR (𝐡max
) ≥iSNR
(.)
and
oSNR
(
𝐡max
)
≥oSNR (𝐡) , ∀𝐡.
(.)
While the maximum SNR ﬁlter maximizes the output SNR, it leads to large distortions
of the desired signal.
Let us consider the very particular case of a matrix 𝐑−
𝐯𝐑𝐱that has a maximum
eigenvalue 𝜆with multiplicity P ≤L. We denote by 𝐭, 𝐭, … , 𝐭P the corresponding
eigenvectors. It is not hard to see that the maximum SNR ﬁlter is now
𝐡max =
P
∑
p=
𝜍p𝐭p,
(.)
since
oSNR (𝐡max
) = 𝜆,
(.)
where 𝜍p, p = , , … , P are real numbers with at least one of them diﬀerent from .
www.ebook3000.com

40
Fundamentals of Signal Enhancement and Array Signal Processing
Table 2.1 Optimal linear filters for single-channel signal enhancement in
the time domain.
Filter
Wiener
𝐡W = 𝐑−
𝐲𝐑𝐱𝐢i
Tradeoﬀ
𝐡T,𝜇= (𝐑𝐱+ 𝜇𝐑𝐯
)−𝐑𝐱𝐢i, 𝜇≥
MVDR
𝐡MVDR = 𝐑−
𝐯𝐐′
𝐱
(𝐐′T
𝐱𝐑−
𝐯𝐐′
𝐱
)−𝐐′T
𝐱𝐢i
Maximum SNR
𝐡max = 𝜍𝐭, 𝜍≠
To summarize the performance of all the optimal ﬁlters derived in this subsection, we
can state that for 𝜇< ,
oSNR
(
𝐡max
)
≥oSNR
(
𝐡W
)
≥oSNR
(
𝐡T,𝜇
)
≥oSNR
(
𝐡MVDR
)
,
(.)
and for 𝜇> ,
oSNR (𝐡max
) ≥oSNR (𝐡T,𝜇
) ≥oSNR (𝐡W
) ≥oSNR (𝐡MVDR
) .
(.)
In Table ., we summarize all the optimal ﬁlters described in this subsection.
Example ..
Consider a desired signal consisting of four harmonic random pro-
cesses:
x(t) =

∑
k=
Ak cos (𝜋fkt + 𝜙k
) ,
with ﬁxed amplitudes
{
Ak
}
and frequencies
{
fk
}
, and IID random phases
{
𝜙k
}
,
uniformly distributed on the interval from to 𝜋. This signal needs to be recovered
from the noisy observation y(t) = x(t) + v(t), where v(t) is additive white Gaussian
noise, v(t) ∼
(
, 𝜎
v
)
, which is uncorrelated with x(t).
The input SNR is
iSNR = log
∑
k=A
k
𝜎
v
(dB).
The correlation matrix of 𝐯(t) is 𝐑𝐯= 𝜎
v𝐈L and the elements of the correlation matrix
of 𝐱(t) are [𝐑𝐱
]
i,j = 

∑
k=A
k cos [𝜋fk(i −j)]. The rank of this matrix is rank (𝐑𝐱
) = .
To demonstrate the performances of the optimal ﬁlters, we choose Ak = .
(k = , … , ), fk = .+ .(k −) (k = , … , ), and a ﬁlter length of L = .
The value of 𝜍in (.) is chosen to minimize the MSE. Substituting (.) into (.)
we have
J (𝐡max
) = 𝜎
x −𝜍𝐭T
𝐑𝐱𝐢i + 𝜍𝐭T
𝐑𝐲𝐭.

Single-channel Signal Enhancement in the Time Domain
41
Taking the derivative of the MSE with respect to 𝜍and equating the result to zero,
we get
𝜍=
𝐭T
𝐑𝐱𝐢i
𝐭T
𝐑𝐲𝐭
.
Figures .and .show plots of the gain in SNR, (𝐡), the MSE, J (𝐡), the noise
reduction factor, 𝜉n (𝐡), and the desired signal reduction factor, 𝜉d (𝐡), as a function
of the input SNR, for all the optimal ﬁlters derived in this subsection: the maximum
SNR, Wiener, MVDR, and tradeoﬀﬁlters. In Figure .the Lagrange multiplier of the
tradeoﬀﬁlter is 𝜇= ., whereas in Figure ., 𝜇= . Clearly, (.) is satisﬁed in
Figure .a, whereas (.) is satisﬁed in Figure .a. Speciﬁcally, the maximum oSNR
is obtained with 𝐡max, the minimum oSNR is obtained with 𝐡MVDR, and oSNR is larger
when applying the Wiener ﬁlter than the tradeoﬀﬁlter if 𝜇< , while the opposite is
true if 𝜇> . Furthermore, the MSE is minimal for the Wiener ﬁlter, and the desired
−10
−5
0
5
10
1
2
3
4
5
6
7
−10
−5
0
5
10
−20
−15
−10
−5
0
5
10
0
5
10
15
20
25
30
35
−5
0
5
10
15
20
25
30
iSNR (dB)
−10
−5
0
5
10
−10
−5
0
5
10
iSNR (dB)
iSNR (dB)
iSNR (dB)
(d)
(a)
(b)
(c)
J (h) (dB)
ξn (h) (dB)
ξd (h) (dB)
  (h) (dB)
Figure 2.8 (a) The gain in SNR, (b) the MSE, (c) the noise reduction factor, and (d) the desired signal
reduction factor as a function of the input SNR for different optimal filters: 𝗵max (solid line with circles),
𝗵W (dashed line with asterisks), 𝗵MVDR (dotted line with squares), and 𝗵T,𝜇with 𝜇= 0.5 (dash-dot line
with triangles).
www.ebook3000.com

42
Fundamentals of Signal Enhancement and Array Signal Processing
−10
−5
0
5
10
1
2
3
4
5
6
7
−10
−5
0
5
10
−20
−15
−10
−5
0
5
10
−10
−5
0
5
10
0
5
10
15
20
25
30
35
−10
−5
0
5
10
−5
0
5
10
15
20
25
30
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(a)
(b)
(c)
(d)
J (h) (dB)
ξn (h) (dB)
ξd (h)(dB)
  (h) (dB)
Figure 2.9 (a) The gain in SNR, (b) the MSE, (c) the noise reduction factor, and (d) the desired signal
reduction factor as a function of the input SNR for different optimal filters: 𝗵max (solid line with circles),
𝗵W (dashed line with asterisks), 𝗵MVDR (dotted line with squares), and 𝗵T,𝜇with 𝜇= 5 (dash-dot line
with triangles).
signal reduction factor is dB for the MVDR ﬁlter, since the desired signal correlation
matrix is rank deﬁcient.
Suppose that we wish to design a tradeoﬀﬁlter, 𝐡T,𝜇, that satisﬁes 𝜉n
(𝐡T,𝜇
) = dB.
A plot of the Lagrange multiplier, 𝜇, that satisﬁes this constraint is shown in Figure ..
Plots of the gain in SNR, the MSE, the noise reduction factor, and the desired signal
reduction factor, under this constraint, are shown in Figure .. In this scenario, 𝜇< 
for iSNR < −.dB, and 𝜇> for iSNR > −.dB. Hence, oSNR (𝐡W
) ≥oSNR (𝐡T,𝜇
)
for iSNR < −.dB, and oSNR
(
𝐡W
)
≤oSNR
(
𝐡T,𝜇
)
for iSNR > −.dB.
■
2.3
Spectral Method
In this section, we give a spectral perspective of the single-channel signal enhancement
problem and try to unify several known approaches. To this end, we use the joint
diagonalization technique.

Single-channel Signal Enhancement in the Time Domain
43
−10
−3.61
0
5
10
10−1
100
101
102
iSNR (dB)
μ
Figure 2.10 The Lagrange multiplier, 𝜇, of the tradeoff filter, 𝗵T,𝜇, as a function of the input SNR, which
yields a constant noise reduction factor 𝜉n
(𝗵T,𝜇
) = 10 dB.
1
2
3
4
5
6
7
−20
−15
−10
−5
0
5
10
−10
−5
0
5
10
0
5
10
15
20
25
30
35
−5
0
5
10
15
20
25
30
iSNR (dB)
−10
−5
0
5
10
iSNR (dB)
−10
−5
0
5
10
iSNR (dB)
−10
−5
0
5
10
iSNR (dB)
(a)
(b)
(c)
(d)
J (h) (dB)
ξn (h) (dB)
ξd (h) (dB)
   (h) (dB)
Figure 2.11 (a) The gain in SNR, (b) the MSE, (c) the noise reduction factor, and (d) the desired signal
reduction factor as a function of the input SNR for different optimal filters: 𝗵max (solid line with circles),
𝗵W (dashed line with asterisks), 𝗵MVDR (dotted line with squares), and 𝗵T,𝜇with 𝜇that satisfies
𝜉n
(𝗵T,𝜇
) = 10 dB (dash-dot line with triangles).
www.ebook3000.com

44
Fundamentals of Signal Enhancement and Array Signal Processing
2.3.1
Joint Diagonalization and Reformulation of the Problem
The use of the joint diagonalization is going to be very useful in the rest of this chapter
and will help us reformulate the original time-domain problem to the spectral domain,
so we now brieﬂy explain how it works. The two symmetric matrices 𝐑𝐱and 𝐑𝐯can be
jointly diagonalized as follows []:
𝐓T𝐑𝐱𝐓= 𝚲,
(.)
𝐓T𝐑𝐯𝐓= 𝐈L,
(.)
where 𝐓is a full-rank square matrix (of size L × L) and 𝚲is a diagonal matrix the main
elements of which are real and nonnegative. The procedure for jointly diagonalizing 𝐑𝐱
and 𝐑𝐯consists of two steps:
i) Calculate 𝚲and 𝐓′, the eigenvalue and eigenvector matrices, respectively, of 𝐑−
𝐯𝐑𝐱:
𝐑−
𝐯𝐑𝐱𝐓′ = 𝐓′𝚲.
(.)
ii) Normalize the eigenvectors of 𝐑−
𝐯𝐑𝐱such that (.) is satisﬁed. Denoting by 𝐭′
l , l =
, … , L the eigenvectors of 𝐑−
𝐯𝐑𝐱, we need to ﬁnd the constants cl such that 𝐭l = cl𝐭′
l
satisfy 𝐭T
l 𝐑𝐯𝐭l = . Hence,
cl =

√
𝐭′T
l 𝐑𝐯𝐭′
l
, l = , … , L.
(.)
Thus, we have
𝐓= 𝐓′𝐂,
(.)
where 𝐂is a diagonal normalization matrix with the elements {c, … , cL
} on its main
diagonal.
The eigenvalues of 𝐑−
𝐯𝐑𝐱can be ordered as 𝜆≥𝜆≥⋯≥𝜆L ≥. We also denote
by 𝐭, 𝐭, … , 𝐭L, the corresponding eigenvectors. Therefore, the noisy signal correlation
matrix can also be diagonalized as
𝐓T𝐑𝐲𝐓= 𝚲+ 𝐈L.
(.)
By left multiplying both sides of (.) by 𝐭T
l , we get the lth spectral mode of the noisy
signal:
y(t; l) = 𝐭T
l 𝐲(t)
(.)
= x(t; l) + v(t; l),
where x(t; l) = 𝐭T
l 𝐱(t) and v(t; l) = 𝐭T
l 𝐯(t) are the lth spectral modes of the desired and
noise signals, respectively. We deduce that the variance of y(t; l) is
𝜎
y(; l) = E
[
y(t; l)
]
(.)
= 𝐭T
l 𝐑𝐲𝐭l

Single-channel Signal Enhancement in the Time Domain
45
= 𝜆l + 
= 𝜎
x(; l) + 𝜎
v(; l),
where 𝜎
x(; l) = 𝜆l and 𝜎
v(; l) = are the variances of x(t; l) and v(t; l), respectively. Now,
we consider (.) as our new signal model and, therefore, our aim is to recover x(t; l)
given y(t; l).
We end this part by giving two useful properties.
Property ..
Let 𝜆≥𝜆≥⋯≥𝜆L ≥. We have
∑L
i=𝛼
i 𝜆i
∑L
i=𝛼
i
≤
∑L−
i=𝛼
i 𝜆i
∑L−
i=𝛼
i
≤⋯≤
∑
i=𝛼
i 𝜆i
∑
i=𝛼
i
≤𝜆,
(.)
where 𝛼i, i = , , … , L are arbitrary real numbers with at least one of them diﬀerent
from .
Proof. These inequalities can be easily shown by induction.
■
Property ..
Let 𝜆≥𝜆≥⋯≥𝜆L ≥. We have
𝜆L ≤
∑
i=𝛽
L+−i𝜆L+−i
∑
i=𝛽
L+−i
≤⋯≤
∑L−
i=𝛽
L+−i𝜆L+−i
∑L−
i=𝛽
L+−i
≤
∑L
i=𝛽
L+−i𝜆L+−i
∑L
i=𝛽
L+−i
,
(.)
where 𝛽L+−i, i = , , … , L are arbitrary real numbers with at least one of them diﬀerent
from .
Proof. These inequalities can be easily shown by induction.
■
2.3.2
Noise Reduction with Gains
The simplest way to perform noise reduction is, as shown in Figure ., by applying a
real-valued gain, h(; l), to the observation, y(t; l):
z(t; l) = h(; l)y(t; l)
(.)
= xfd(t; l) + vfn(t; l),
+
h(;l)
x(t;l)
y(t;l)
z(t;l)
(t;l)
Figure 2.12 Block diagram of noise reduction with gains.
www.ebook3000.com

46
Fundamentals of Signal Enhancement and Array Signal Processing
where z(t; l) can be either the estimate of x(t; l) or v(t; l),
xfd(t; l) = h(; l)x(t; l)
(.)
is the ﬁltered desired signal, and
vfn(t; l) = h(; l)v(t; l)
(.)
is the ﬁltered noise. If z(t; l) is the estimate of v(t; l), then the estimate of x(t; l) is
̂x(t; l) = y(t; l) −z(t; l).
(.)
The technique in (.) is equivalent to the frequency-domain methods, where a gain
is also used at each frequency to reduce noise (see Chapter ). The variance of z(t; l) is
then
𝜎
z (; l) = h(; l)𝜎
y(; l)
(.)
= 𝜎
xfd(; l) + 𝜎
vfn(; l),
where
𝜎
xfd(; l) = h(; l)𝜎
x(; l)
(.)
= h(; l)𝜆l
and
𝜎
vfn(; l) = h(; l)𝜎
v(; l)
(.)
= h(; l)
are the variances of xfd(t; l) and vfn(t; l), respectively.
Eventually, the vector of length L:
𝐳(t) = [ z(t)
z(t)
⋯
zL(t) ]T ,
(.)
which can be either the estimate of 𝐱(t) or 𝐯(t), is obtained as follows (see Figure .):
𝐳(t) = 𝐁diag [𝐡(; )] 𝐓T𝐲(t)
(.)
=
[ L
∑
l=
h(; l)𝐛l𝐭T
l
]
𝐲(t),
where
𝐁= 𝐓−T
(.)
=
[ 𝐛
𝐛
⋯
𝐛L
]

Single-channel Signal Enhancement in the Time Domain
47
+
h(;1)
h(;L)
bL
+
z(t;L)
z(t)
tT
1
tT
L
b1
v(t)
x(t)
y(t)
y(t;L)
y(t;1)
z(t;1)
Figure 2.13 Block diagram of spectral mode linear filtering.
and diag [𝐡(; )] is an L × L diagonal matrix whose diagonal elements are equal to the
components of the vector of length L:
𝐡(; ) = [ h(; )
h(; )
⋯
h(; L) ]T ,
(.)
which contains all the spectral mode gains.
2.3.3
Performance Measures
In this subsection, we consider that the ﬁlter 𝐡(; ) is for the estimation of 𝐓T𝐱(t); in other
words, 𝐳(t) is an estimate of 𝐱(t).
We deﬁne the lth spectral mode input SNR:
iSNR(; l) =
𝜎
x(; l)
𝜎
v(; l)
(.)
= 𝜆l
and the fullmode input SNR:
iSNR(; ) =
∑L
l=𝜎
x(; l)
∑L
l=𝜎
v(; l)
(.)
= tr (𝚲)
L
=
tr (𝐑−
𝐯𝐑𝐱
)
L
.
It can be seen that
iSNR(; L) ≤iSNR(; ) ≤iSNR(; ).
(.)
In words, the fullmode input SNR can never exceed the maximum spectral mode input
SNR and can never go below the minimum spectral mode input SNR. Notice that
the deﬁnition of the fullmode input SNR is slightly diﬀerent from the conventional
deﬁnition of the input SNR, as set out in Equation .. However, for white noise, it
www.ebook3000.com

48
Fundamentals of Signal Enhancement and Array Signal Processing
is easy to check that iSNR(; ) = iSNR. The spectral mode input SNR is similar to the
narrowband input SNR used in the frequency-domain approaches (see Chapter ).
The lth spectral mode output SNR is
oSNR [h(; l)] =
𝜎
xfd(; l)
𝜎
vfn(; l)
(.)
= iSNR(; l).
Therefore, the spectral mode output SNR cannot be improved. The fullmode output
SNR is
oSNR [𝐡(; )] =
∑L
l=𝜎
xfd(; l)
∑L
l=𝜎
vfn(; l)
(.)
= 𝐡T(; )𝚲𝐡(; )
𝐡T(; )𝐡(; ) .
Clearly, we always have
iSNR(; L) ≤oSNR [𝐡(; )] ≤iSNR(; ), ∀𝐡(; ).
(.)
Therefore, our aim is to ﬁnd the L spectral mode gains, h(; l), l = , , … , L, in such
a way that the fullmode output SNR is greater than the fullmode input SNR; in other
words, oSNR [𝐡(; )] > iSNR(; ).
It is not hard to show that the lth spectral mode and fullmode noise reduction factors
are, respectively,
𝜉n
[
h(; l)
]
=

h(; l)
(.)
and
𝜉n [𝐡(; )] =
L
𝐡T(; )𝐡(; ).
(.)
For optimal spectral mode gains, we should have 𝜉n
[
h(; l)
]
≥and 𝜉n [𝐡(; )] ≥. Large
values of the noise reduction factors imply good noise reduction.
In the same way, we deﬁne the lth spectral mode and fullmode desired signal
reduction factors as, respectively,
𝜉d
[h(; l)] =

h(; l)
(.)
and
𝜉d [𝐡(; )] =
tr (𝚲)
𝐡T(; )𝚲𝐡(; ).
(.)

Single-channel Signal Enhancement in the Time Domain
49
For optimal spectral mode gains, we should have 𝜉d
[h(; l)] ≥and 𝜉d [𝐡(; )] ≥.
The closer are the values of the desired signal reduction factors to one, the less distorted
is the desired signal.
We deduce the following important relation:
oSNR [𝐡(; )]
iSNR(; )
= 𝜉n [𝐡(; )]
𝜉d [𝐡(; )].
(.)
It is easy to derive the lth spectral mode desired signal distortion index:
𝜐d
[
h(; l)
]
=
[
h(; l) −
]
(.)
and the fullmode desired signal distortion index:
𝜐d [𝐡(; )] =
∑L
l=𝜆l
[h(; l) −]
tr (𝚲)
.
(.)
For completeness, we deﬁne the fullmode MSE for any ﬁlter 𝐡(; ) as
J [𝐡(; )] = E
{[𝐓T𝐱(t) −diag [𝐡(; )] 𝐓T𝐲(t)]T
× [𝐓T𝐱(t) −diag [𝐡(; )] 𝐓T𝐲(t)]}
(.)
= tr (𝐓T𝐑𝐱𝐓) −tr {diag [𝐡(; )] 𝐓T𝐑𝐱𝐓}
+ tr
{
diag [𝐡(; )] 𝐓T𝐑𝐲𝐓diag [𝐡(; )]
}
= tr (𝚲) −𝐡T(; )𝚲𝟏+ 𝐡T(; )𝚲𝐡(; ) + 𝐡T(; )𝐡(; )
= [𝟏−𝐡(; )]T 𝚲[𝟏−𝐡(; )] + 𝐡T(; )𝐡(; )
= tr (𝚲) 𝜐d [𝐡(; )] +
L
𝜉n [𝐡(; )]
= Jd [𝐡(; )] + Jn [𝐡(; )] ,
where 𝟏is a vector of length L with all its elements equal to , which is also the fullmode
identity ﬁlter since, with it, the fullmode output SNR is equal to the fullmode input SNR.
This deﬁnition of the fullmode MSE is clearly connected to all the fullmode performance
measures.
2.3.4
Determination of the Gains from the Fullmode Output SNR
There are two approaches to ﬁnd the gains from the fullmode output SNR in order
to perform noise reduction. The ﬁrst one considers the largest spectral mode input
SNRs. In this case, we get the estimate of the desired signal directly. The second method
considers the smallest spectral mode input SNRs. As a result, we get the estimate of the
noise signal, from which we deduce the estimate of the desired signal.
2.3.4.1
Maximization of the Fullmode Output SNR
The ﬁlter 𝐡(; ) that maximizes the fullmode output SNR given in (.) is simply the
eigenvector corresponding to the maximum eigenvalue of the matrix 𝚲. Since this
www.ebook3000.com

50
Fundamentals of Signal Enhancement and Array Signal Processing
matrix is diagonal, its maximum eigenvalue is its largest diagonal element, 𝜆. As a
consequence, the maximum SNR ﬁlter is
𝐡𝛼(; ) = 𝛼𝐢,
(.)
where 𝛼≠is an arbitrary real number and 𝐢is the ﬁrst column of 𝐈L. Equivalently,
we can write (.) as
{ h𝛼(; ) = 𝛼
h(; i) = , i = , , … , L .
(.)
With (.), we get the maximum possible fullmode output SNR, which is
oSNR [𝐡𝛼(; )] = 𝜆≥iSNR(; ).
(.)
As a result,
oSNR
[
𝐡𝛼(; )
]
≥oSNR [𝐡(; )] , ∀𝐡(; ).
(.)
We deduce that the estimate of the desired signal is
{ ̂x𝛼(t; ) = h𝛼(; )y(t; )
̂x(t; i) = , i = , , … , L
(.)
and the estimate of 𝐱(t) is
̂𝐱𝛼(t) =
[
h𝛼(; )𝐛𝐭T

]
𝐲(t)
(.)
as illustrated in Figure ..
Now, we need to determine 𝛼. There are at least two ways to ﬁnd this parameter. The
ﬁrst one is from the MSE between x(t; ) and ̂x𝛼(t; ):
J [h𝛼(; )] = E
{[x(t; ) −h𝛼(; )y(t; )]}
.
(.)
The second possibility is to use the desired signal distortion-based MSE:
Jd
[h𝛼(; )] = E
{[x(t; ) −h𝛼(; )x(t; )]}
.
(.)
+
v(t)
tT
1
hα1(;1)
b1
x(t)
y(t)
y(t;1)
z(t;1)
xα1(t)
Figure 2.14 Estimation of the desired signal using the maximum SNR filter.

Single-channel Signal Enhancement in the Time Domain
51
The minimization of J [h𝛼(; )] leads to the Wiener gain at the spectral mode :
hW(; ) =
iSNR(; )
+ iSNR(; ),
(.)
while the minimization of Jd
[h𝛼(; )] gives the unitary gain at the spectral mode :
hU(; ) = .
(.)
Notice that hW(; l), l = , , … , L resembles the Wiener gain approach in frequency-
domain noise reduction, which will be discussed in the next chapter. It is obvious that
≤hW(; ) ≤.
Even though this method maximizes the fullmode output SNR, it is expected to
introduce a large amount of distortion to the desired signal, since all its spectral modes
are set to except at . A much better approach when we deal with broadband signals
is to form the ﬁlter from a linear combination of the eigenvectors corresponding to the
P(≤L) largest eigenvalues of 𝚲:
𝐡𝛼∶P(; ) =
P
∑
p=
𝛼p𝐢p,
(.)
where 𝛼p, p = , , … , P are arbitrary real numbers with at least one of them diﬀerent
from , and 𝐢p is the pth column of 𝐈L. We can also express (.) as
{ h𝛼p(; p) = 𝛼p, p = , , … , P
h(; i) = , i = P + , P + , … , L .
(.)
Hence, the estimate of the desired signal is
{ ̂x𝛼p(t; p) = h𝛼p(; p)y(t; p), p = , , … , P
̂x(t; i) = , i = P + , P + , … , L
(.)
and the estimate of 𝐱(t) is
̂𝐱𝛼∶P(t) =
[ P
∑
p=
h𝛼p(; p)𝐛p𝐭T
p
]
𝐲(t).
(.)
To ﬁnd the various 𝛼p, we can optimize either J
[
h𝛼p(; p)
]
or Jd
[
h𝛼p(; p)
]
. The ﬁrst one
leads to the Wiener gains at the spectral modes p, p = , , … , P:
hW(; p) =
iSNR(; p)
+ iSNR(; p), p = , , … , P,
(.)
while the second one gives the unitary gains at the spectral modes p, p = , , … , P:
hU(; p) = , p = , , … , P.
(.)
www.ebook3000.com

52
Fundamentals of Signal Enhancement and Array Signal Processing
The ﬁlters (of length L) corresponding to (.) and (.) are, respectively,
𝐡W,P(; ) = [ hW(; )
⋯
hW(; P)
⋯]T
(.)
and
𝐡U,P(; ) = [ 
⋯

⋯]T .
(.)
For P = L, 𝐡W,L(; ) corresponds to the classical Wiener approach and 𝐡U,L(; ) is the
identity ﬁlter, which does not aﬀect the observations. Indeed, it is easy to check that
̂𝐱W(t) = 𝐑𝐱𝐑−
𝐲𝐲(t),
(.)
̂𝐱U(t) = 𝐲(t).
(.)
Clearly, 𝐡U,P(; ) corresponds to the ideal binary mask [], since the spectral mode
observation signals with the P largest spectral mode input SNRs are not aﬀected
while the L −P others with the smallest spectral mode input SNRs are set to .
This is also equivalent to the subspace approach, where the desired signal-plus-noise
subspace is not processed while the (dominant) noise subspace is cancelled [–].
The corresponding estimator is
̂𝐱U,∶P(t) =
( P
∑
p=
𝐛p𝐭T
p
)
𝐲(t).
(.)
We should always have
oSNR
[
𝐡U,P(; )
]
≤oSNR
[
𝐡W,P(; )
]
.
(.)
From Property .., we deduce that
iSNR(; ) ≤oSNR [𝐡W,L(; )] ≤oSNR [𝐡W,L−(; )]
≤⋯≤oSNR
[
𝐡W,(; )
]
= 𝜆
(.)
and
iSNR(; ) = oSNR [𝐡U,L(; )] ≤oSNR [𝐡U,L−(; )]
≤⋯≤oSNR
[
𝐡U,(; )
]
= 𝜆.
(.)
Example ..
Consider a desired signal consisting of ﬁve harmonic random pro-
cesses:
x(t) =

∑
k=
Ak cos (𝜋fkt + 𝜙k
) ,
with ﬁxed amplitudes
{
Ak
}
and frequencies
{
fk
}
, and IID random phases
{
𝜙k
}
,
uniformly distributed on the interval from to 𝜋. This signal needs to be recovered

Single-channel Signal Enhancement in the Time Domain
53
1
2
3
4
5
6
7
8
9
10
0
0.5
1
1.5
2
2.5
3
3.5
4
1
2
3
4
5
6
7
8
9
10
7
8
9
10
11
12
P
P
(a)
(b)
Gain in SNR (dB)
MSE (dB)
Figure 2.15 (a) The fullmode gain in SNR, [𝗵W,P(; )] (circles) and [𝗵U,P(; )] (asterisks), as a function of
P; (b) the fullmode MSE, J [𝗵W,P(; )] (circles) and J [𝗵U,P(; )] (asterisks), as a function of P.
from the noisy observation y(t) = x(t) + v(t), where v(t) is colored noise that is
uncorrelated with x(t), whose correlation matrix is
[
𝐑𝐯
]
i,j = 𝜎
v𝛼|i−j| (−< 𝛼< ).
To demonstrate the performances of the spectral mode gains 𝐡W,P(; ) and 𝐡U,P(; ), we
choose Ak = .∕k (k = , … , ), fk = .+ .(k −) (k = , … , ), 𝜎= ., 𝛼= .,
and L = . The two symmetric matrices 𝐑𝐱and 𝐑𝐯are jointly diagonalized as in (.)
and (.). The fullmode input SNR is iSNR(; ) = log [tr (𝚲) ∕L] = .dB.
Figure .shows plots of the fullmode gain in SNR and MSE for the two
spectral mode gains, 𝐡W,P(; ) and 𝐡U,P(; ), as a function of P. Figure .a veriﬁes
that both oSNR [𝐡W,P(; )] and oSNR [𝐡U,P(; )] are decreasing functions of P, and
that oSNR [𝐡U,P(; )]
≤
oSNR [𝐡W,P(; )]. Figure .b shows that the fullmode
MSE for the Wiener gains, J [𝐡W,P(; )], is a decreasing function of P, and that
J [𝐡W,P(; )] ≤J [𝐡U,P(; )].
■
2.3.4.2
Minimization of the Fullmode Output SNR
It is clear that the ﬁlter 𝐡(; ) that minimizes the fullmode output SNR given in (.)
is the eigenvector corresponding to the minimum eigenvalue of the matrix 𝚲, which is
𝜆L. Therefore, the minimum SNR ﬁlter is
𝐡𝛽L(; ) = 𝛽L𝐢L,
(.)
where 𝛽L ≠is an arbitrary real number and 𝐢L is the Lth column of 𝐈L. Equivalently,
we can write (.) as
{ h(; i) = , i = , , … , L −
h𝛽L(; L) = 𝛽L
.
(.)
With (.), we get the minimum possible fullmode output SNR, which is
oSNR [𝐡𝛽L(; )] = 𝜆L ≤iSNR(; ).
(.)
www.ebook3000.com

54
Fundamentals of Signal Enhancement and Array Signal Processing
As a result,
oSNR [𝐡𝛽L(; )] ≤oSNR [𝐡(; )] , ∀𝐡(; ).
(.)
We deduce that the estimates of the noise and desired signals are, respectively,
{ ̂v(t; i) = , i = , , … , L −
̂v𝛽L(t; L) = h𝛽L(; L)y(t; L)
(.)
and
{ ̂x(t; i) = y(t; i), i = , , … , L −
̂x𝛽L(t; L) = h′
𝛽L(; L)y(t; L)
,
(.)
where
h′
𝛽L(; L) = −h𝛽L(; L)
(.)
is the equivalent gain for the estimation of x(t; L). The equivalent ﬁlter is then
𝐡′
𝛽L(; ) = 𝟏−𝐡𝛽L(; ).
(.)
The fullmode output SNR corresponding to 𝐡′
𝛽L(; ) is
oSNR
[
𝐡′
𝛽L(; )
]
=
𝐡′T
𝛽L (; )𝚲𝐡′
𝛽L(; )
𝐡′T
𝛽L (; )𝐡′
𝛽L(; )
.
(.)
It can be shown that oSNR
[
𝐡′
𝛽L(; )
]
≥iSNR(; ) if and only if [−h𝛽L(; L)]≤. We also
see that the estimate of 𝐯(t) is
̂𝐯𝛽L(t) = [h𝛽L(; L)𝐛L𝐭T
L
] 𝐲(t).
(.)
The MSE between v(t; L) and ̂v𝛽L(t; L) is
J
[
h𝛽L(; L)
]
= E
{[
v(t; L) −h𝛽L(; L)y(t; L)
]}
(.)
= h
𝛽L(; L)𝜆L + [−h𝛽L(; L)]
= Jd
[h𝛽L(; L)] + Jn
[h𝛽L(; L)] .
From the previous expression, we see that there are at least two ways to ﬁnd h𝛽L(; L) or
h′
𝛽L(; L). The minimization of J [h𝛽L(; L)] and using the relation (.) lead to
h′
W(; L) =
iSNR(; L)
+ iSNR(; L)
(.)
= hW(; L),

Single-channel Signal Enhancement in the Time Domain
55
which is the Wiener gain at the spectral mode L. The minimization of the power of the
residual noise, Jn
[h𝛽L(; L)] and using the relation (.) give
h′
N(; L) = ,
(.)
which is the null gain at the spectral mode L.
Obviously, the approach presented above is not meaningful for broadband signals,
since only one spectral mode is processed while all the others are not aﬀected at all.
This is far from enough as far as noise reduction is concerned, even though very little
distortion is expected. A more practical approach is to form the ﬁlter from a linear
combination of the eigenvectors corresponding to the Q(≤L) smallest eigenvalues of 𝚲:
𝐡𝛽L−Q+∶L(; ) =
Q
∑
q=
𝛽L−Q+q𝐢L−Q+q,
(.)
where 𝛽L−Q+q, q = , , … , Q are arbitrary real numbers with at least one of them
diﬀerent from and 𝐢L−Q+q is the (L −Q + q)th column of 𝐈L. Therefore, the equivalent
ﬁlter for the estimation of the desired signal at the diﬀerent spectral modes is
𝐡′
𝛽L−Q+∶L(; ) = 𝟏−𝐡𝛽L−Q+∶L(; ).
(.)
We can also express (.) as
{ h′(; i) = , i = , , … , L −Q
h′
𝛽L−Q+q(; L −Q + q) = −𝛽L−Q+q, q = , , … , Q .
(.)
Hence, the estimate of the desired signal is
⎧
⎪
⎨
⎪⎩
̂x(t; i) = y(t; i), i = , , … , L −Q
̂x𝛽L−Q+q(t; L −Q + q) = h′
𝛽L−Q+q(; L −Q + q)y(t; L −Q + q)
q = , , … , Q
.
(.)
Following the same steps as above, we deduce the two ﬁlters of interest:
𝐡′
W,Q(; ) = [ 
⋯

hW(; L −Q + )
⋯
hW(; L) ]T
(.)
and
𝐡′
N,Q = [ 
⋯


⋯
]T .
(.)
For Q = L, 𝐡′
W,L(; ) = 𝐡W,L(; ) corresponds to the classical Wiener approach and 𝐡′
N,L(; ) =
𝟎is the null ﬁlter, which completely cancels the observations. The ﬁlter 𝐡′
W,Q(; ) can be
seen as a combination of the ideal binary mask and Wiener, where the observations with
large spectral mode input SNRs are not aﬀected while the ones with small spectral mode
www.ebook3000.com

56
Fundamentals of Signal Enhancement and Array Signal Processing
input SNRs are processed with Wiener gains. The ﬁlter 𝐡′
N,Q(; ) is, obviously, the ideal
binary mask. The estimator corresponding to 𝐡′
W,Q(; ) is then
̂𝐱W,Q(t) =
(L−Q
∑
i=
𝐛i𝐭T
i +
Q
∑
q=
𝜆L−Q+q
+ 𝜆L−Q+q
𝐛L−Q+q𝐭T
L−Q+q
)
𝐲(t).
(.)
We should always have
oSNR
[
𝐡′
N,Q(; )
]
≥oSNR
[
𝐡′
W,Q(; )
]
.
(.)
We can also deduce that
oSNR
[
𝐡′
N,L−(; )
]
≥⋯≥oSNR
[
𝐡′
N,(; )
]
≥iSNR(; ).
(.)
Example ..
Returning to Example .., Figure .shows plots of the fullmode
gain in SNR and MSE for the two spectral mode gains, 𝐡′
W,Q(; ) and 𝐡′
N,Q(; ), as a function
of Q. Figure .a demonstrates that oSNR
[
𝐡′
N,Q(; )
]
is an increasing function of Q and
that oSNR
[
𝐡′
N,Q(; )
]
≥oSNR
[
𝐡′
W,Q(; )
]
. Figure .b shows that the fullmode MSE
for the Wiener gains, J
[
𝐡′
W,Q(; )
]
, is a decreasing function of Q and that J
[
𝐡′
W,Q(; )
]
≤
J
[
𝐡′
N,Q(; )
]
.
■
1
2
3
4
5
6
7
8
9
10
0
0.5
1
1.5
2
2.5
3
3.5
4
1
2
3
4
5
6
7
8
9
10
7
8
9
10
11
12
Q
Q
(a)
(b)
Gain in SNR (dB)
MSE (dB)
Figure 2.16 (a) The fullmode gain in SNR, 
[
𝗵′
W,Q(; )
]
(circles) and 
[
𝗵′
N,Q(; )
]
(asterisks), as a function
of Q. (b) Plots of the fullmode MSE, J
[
𝗵′
W,Q(; )
]
(circles) and J
[
𝗵′
N,Q(; )
]
(asterisks), as a function of Q.

Single-channel Signal Enhancement in the Time Domain
57
Problems
2.1 Show that the MSEs, J (𝐡), Jd (𝐡), and Jn (𝐡), are related to the diﬀerent performance
measures by
J (𝐡) = 𝜎
v
[
iSNR × 𝜐d (𝐡) +

𝜉n (𝐡)
]
and
Jd (𝐡)
Jn (𝐡) = iSNR × 𝜉n (𝐡) × 𝜐d (𝐡)
= oSNR (𝐡) × 𝜉d (𝐡) × 𝜐d (𝐡) .
2.2 Show that taking the gradient of the MSE:
J (𝐡) = 𝜎
x −𝐡T𝐑𝐱𝐢i + 𝐡T𝐑𝐲𝐡,
with respect to 𝐡and equating the result to zero yields the Wiener ﬁlter:
𝐡W = 𝐑−
𝐲𝐑𝐱𝐢i.
2.3 Show that the Wiener ﬁlter can be expressed as
𝐡W =
[
𝐈L −𝜌(v, y)𝚪−
𝐲𝚪𝐯
]
𝐢i.
2.4 Prove that zW(t), the estimate of the desired signal with the Wiener ﬁlter, satisﬁes
𝜌(x, zW
) ≤
oSNR
(
𝐡W
)
+ oSNR
(
𝐡W
).
2.5 Prove that with the optimal Wiener ﬁlter, the output SNR is always greater than
or equal to the input SNR; in other words, oSNR (𝐡W
) ≥iSNR.
2.6 Show that the MMSE can be expressed as
J
(
𝐡W
)
= 𝜎
x
[
−𝜌(x, zW)
]
= 𝜎
v
[−𝜌(v, y −zW)] .
2.7 Show that the performance measures with the Wiener ﬁlter are
oSNR (𝐡W
) =
𝐢T
i 𝐑𝐱𝐑−
𝐲𝐑𝐱𝐑−
𝐲𝐑𝐱𝐢i
𝐢T
i 𝐑𝐱𝐑−
𝐲𝐑𝐯𝐑−
𝐲𝐑𝐱𝐢i
,
𝜉n
(
𝐡W
)
=
𝜎
v
𝐢T
i 𝐑𝐱𝐑−
𝐲𝐑𝐯𝐑−
𝐲𝐑𝐱𝐢i
,
www.ebook3000.com

58
Fundamentals of Signal Enhancement and Array Signal Processing
𝜉d
(𝐡W
) =
𝜎
x
𝐢T
i 𝐑𝐱𝐑−
𝐲𝐑𝐱𝐑−
𝐲𝐑𝐱𝐢i
,
𝜐d
(
𝐡W
)
=
(
𝐑−
𝐲𝐑𝐱𝐢i −𝐢i
)T
𝐑𝐱
(
𝐑−
𝐲𝐑𝐱𝐢i −𝐢i
)
𝜎
x
.
2.8 Assume an harmonic random process:
x(t) = A cos (𝜋ft + 𝜙) ,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly dis-
tributed on the interval from to 𝜋. Show that the elements of the correlation
matrix of 𝐱(t) are [𝐑𝐱
]
i,j = 
Acos [𝜋f(i −j)].
2.9 Show that the tradeoﬀﬁlter 𝐡T,𝜇can be expressed as
𝐡T,𝜇=
[
𝐑𝐲+ (𝜇−)𝐑𝐯
]−(
𝐑𝐲−𝐑𝐯
)
𝐢i,
where 𝜇is a Lagrange multiplier that satisﬁes Jn
(
𝐡T,𝜇
)
= ℵ𝜎
v.
2.10 Show that the squared Pearson correlation coeﬃcient between x(t) and x(t) +
√𝜇v(t) is
𝜌(x, x +
√
𝜇v) =
iSNR
𝜇+ iSNR.
2.11 Show that the squared Pearson correlation coeﬃcient between x(t) and 𝐡T
T,𝜇𝐱(t)+
√𝜇𝐡T
T,𝜇𝐯(t) satisﬁes
𝜌(
x, 𝐡T
T,𝜇𝐱+
√
𝜇𝐡T
T,𝜇𝐯
)
≤
oSNR (𝐡T,𝜇
)
𝜇+ oSNR (𝐡T,𝜇
).
2.12 Show that the squared Pearson correlation coeﬃcient between x(t) + √𝜇v(t) and
𝐡T
T,𝜇𝐱(t) + √𝜇𝐡T
T,𝜇𝐯(t) satisﬁes
𝜌(
x +
√
𝜇v, 𝐡T
T,𝜇𝐱+
√
𝜇𝐡T
T,𝜇𝐯
)
=
𝜌(
x, x + √𝜇v
)
𝜌
(
x, 𝐡T
T,𝜇𝐱+ √𝜇𝐡T
T,𝜇𝐯
).
2.13 Show that the squared Pearson correlation coeﬃcient between x(t) and x(t) +
√𝜇v(t) satisﬁes
𝜌(
x, x +
√
𝜇v
)
≤
oSNR (𝐡T,𝜇
)
𝜇+ oSNR (𝐡T,𝜇
).

Single-channel Signal Enhancement in the Time Domain
59
2.14 Show that with the tradeoﬀﬁlter, the output SNR is always greater than or equal
to the input SNR; in other words, oSNR (𝐡T,𝜇
) ≥iSNR, ∀𝜇≥.
2.15 Let us denote the matrix 𝐐′
𝐱containing the eigenvectors corresponding to the
nonzero eigenvalues of 𝐑𝐱. Show that the distortionless constraint 𝐡T𝐱(t) = x(t)
can be expressed as
𝐡T𝐐′
𝐱= 𝐢T
i 𝐐′
𝐱.
2.16 Prove that the MVDR ﬁlter is
𝐡MVDR = 𝐑−
𝐯𝐐′
𝐱
(𝐐′T
𝐱𝐑−
𝐯𝐐′
𝐱
)−𝐐′T
𝐱𝐢i.
2.17 Show that the MVDR ﬁlter can be expressed as
𝐡MVDR = 𝐑−
𝐲𝐐′
𝐱
(
𝐐′T
𝐱𝐑−
𝐲𝐐′
𝐱
)−
𝐐′T
𝐱𝐢i.
2.18 Verify that the MVDR ﬁlter satisﬁes Jd
(𝐡MVDR
) = .
2.19 Show that with the MVDR ﬁlter, the output SNR is always greater than or equal
to the input SNR; in other words, oSNR (𝐡MVDR
) ≥iSNR.
2.20 Show that the inverse of 𝐑𝐲can be expressed as
𝐑−
𝐲= 𝐑−
𝐯−𝐑−
𝐯𝐐′
𝐱
(𝚲′−
𝐱
+ 𝐐′T
𝐱𝐑−
𝐯𝐐′
𝐱
)−𝐐′T
𝐱𝐑−
𝐯.
2.21 Show that the Wiener ﬁlter 𝐡W can be written as
𝐡W = 𝐑−
𝐯𝐐′
𝐱
(𝚲′−
𝐱
+ 𝐐′T
𝐱𝐑−
𝐯𝐐′
𝐱
)−𝐐′T
𝐱𝐢i.
2.22 Show that the tradeoﬀﬁlter 𝐡T,𝜇can be expressed as
𝐡T,𝜇= 𝐑−
𝐯𝐐′
𝐱
(
𝜇𝚲′−
𝐱
+ 𝐐′T
𝐱𝐑−
𝐯𝐐′
𝐱
)−𝐐′T
𝐱𝐢i.
2.23 Let 𝜆denote the maximum eigenvalue of the matrix 𝐑−
𝐯𝐑𝐱, and let 𝐭denote the
corresponding eigenvector.
a) Show that the ﬁlter that maximizes the output SNR is given by
𝐡max = 𝜍𝐭,
where 𝜍≠is an arbitrary real number.
b) Show that the MSE obtained with the maximum SNR ﬁlter is
J (𝐡max
) = 𝜎
x −𝜍𝐭T
𝐑𝐱𝐢i + 𝜍𝐭T
𝐑𝐲𝐭.
www.ebook3000.com

60
Fundamentals of Signal Enhancement and Array Signal Processing
c) Show that the maximum SNR ﬁlter, 𝐡max, that minimizes the MSE is given by
𝐡max =
𝐭T
𝐑𝐱𝐢i
𝐭T
𝐑𝐲𝐭
𝐭.
2.24 Assume that the matrix 𝐑−
𝐯𝐑𝐱has a maximum eigenvalue 𝜆with multiplicity
P ≤L, and denote by 𝐭, 𝐭, … , 𝐭P the corresponding eigenvectors. Show that the
maximum SNR ﬁlter 𝐡max is given by
𝐡max =
P
∑
p=
𝜍p𝐭p,
where 𝜍p, p = , , … , P are real numbers with at least one of them diﬀerent
from .
2.25 Show that the output SNRs of the optimal ﬁlters are related by
a) for 𝜇< ,
oSNR (𝐡max
) ≥oSNR (𝐡W
) ≥oSNR (𝐡T,𝜇
) ≥oSNR (𝐡MVDR
) ,
b) and for 𝜇> ,
oSNR (𝐡max
) ≥oSNR (𝐡T,𝜇
) ≥oSNR (𝐡W
) ≥oSNR (𝐡MVDR
) .
2.26 Prove that the fullmode input SNR can never exceed the maximum spectral mode
input SNR and can never go below the minimum spectral mode input SNR; in
other words,
iSNR(; L) ≤iSNR(; ) ≤iSNR(; ).
2.27 Prove that the fullmode output SNR can never exceed the maximum spectral
mode input SNR and can never go below the minimum spectral mode input SNR;
in other words,
iSNR(; L) ≤oSNR [𝐡(; )] ≤iSNR(; ), ∀𝐡(; ).
2.28 Show that the fullmode desired signal distortion index, 𝜐d [𝐡(; )], can be expressed
as
𝜐d [𝐡(; )] =
∑L
l=𝜆l
[
h(; l) −
]
tr (𝚲)
.
2.29 Show that the fullmode MSE is given by
J [𝐡(; )] = [𝟏−𝐡(; )]T 𝚲[𝟏−𝐡(; )] + 𝐡T(; )𝐡(; ).

Single-channel Signal Enhancement in the Time Domain
61
2.30 Show that the fullmode output SNR obtained with the Wiener gains at the spectral
modes p, p = , , … , P, i.e., oSNR [𝐡W,P(; )], satisﬁes
oSNR
[
𝐡W,L(; )
]
≤oSNR
[
𝐡W,P(; )
]
≤oSNR
[
𝐡W,(; )
]
,
for all P, ≤P ≤L.
2.31 Show that the fullmode output SNR corresponding to 𝐡′
𝛽L(; ) is
oSNR
[
𝐡′
𝛽L(; )
]
=
𝐡′T
𝛽L (; )𝚲𝐡′
𝛽L(; )
𝐡′T
𝛽L (; )𝐡′
𝛽L(; )
.
2.32 Show that the estimator corresponding to 𝐡′
W,Q(; ) is
̂𝐱W,Q(t) =
(L−Q
∑
i=
𝐛i𝐭T
i +
Q
∑
q=
𝜆L−Q+q
+ 𝜆L−Q+q
𝐛L−Q+q𝐭T
L−Q+q
)
𝐲(t).
2.33 Show that:
a) the fullmode output SNR corresponding to 𝐡′
N,Q(; ) is not smaller than that
corresponding to 𝐡′
W,Q(; ); in other words,
oSNR
[
𝐡′
N,Q(; )
]
≥oSNR
[
𝐡′
W,Q(; )
]
,
b) the fullmode output SNR corresponding to 𝐡′
N,Q(; ) is a decreasing function of
Q for ≤Q ≤L −; in other words,
oSNR
[
𝐡′
N,L−(; )
]
≥⋯≥oSNR
[
𝐡′
N,(; )
]
≥iSNR(; ).
References
1 J. Benesty, J. Chen, Y. Huang, and I. Cohen, Noise Reduction in Speech Processing.
Berlin, Germany: Springer-Verlag, .
2 P. Vary and R. Martin, Digital Speech Transmission: Enhancement, Coding and Error
Concealment. Chichester, England: John Wiley & Sons Ltd, .
3 P. Loizou, Speech Enhancement: Theory and Practice. Boca Raton, FL: CRC Press, .
4 J. Benesty and J. Chen, Optimal Time-domain Noise Reduction Filters – A Theoretical
Study. Springer Briefs in Electrical and Computer Engineering, .
5 J. Benesty, J. Chen, Y. Huang, and S. Doclo, “Study of the Wiener ﬁlter for noise
reduction,” in Speech Enhancement, J. Benesty, S. Makino, and J. Chen (eds). Berlin,
Germany: Springer-Verlag, .
6 J. Chen, J. Benesty, Y. Huang, and S. Doclo, “New insights into the noise reduction
Wiener ﬁlter,” IEEE Trans. Audio, Speech, Language Process., vol. , pp. –,
Jul. .
www.ebook3000.com

62
Fundamentals of Signal Enhancement and Array Signal Processing
7 S. Haykin, Adaptive Filter Theory, th edn. Upper Saddle River, NJ: Prentice-Hall, .
8 J. Benesty, J. Chen, and Y. Huang, “On the importance of the Pearson correlation
coeﬃcient in noise reduction,” IEEE Trans. Audio, Speech, Language Process., vol. ,
pp. –, May .
9 G. H. Golub and C. F. van Loan, Matrix Computations, rd edn. Baltimore, MD: The
Johns Hopkins University Press, .
10 J. Franklin, Matrix Theory. Englewood Cliﬀs, NJ: Prentice-Hall, .
11 D. Wang, “On ideal binary mask as the computational goal of auditory scene analysis,”
in Speech Separation by Humans and Machines, Pierre Divenyi (ed). Boston, MA:
Kluwer, .
12 M. Dendrinos, S. Bakamidis, and G. Carayannis, “Speech enhancement from noise:
a regenerative approach,” Speech Commun., vol. , pp. –, Jan. .
13 Y. Ephraim and H. Van Trees, “A signal subspace approach for speech enhancement,”
IEEE Trans. Speech Audio Process., vol. , pp. –, Jul. .
14 S. H. Jensen, P. C. Hansen, S. D. Hansen, and J. A. Sørensen, “Reduction of broad-band
noise in speech by truncated QSVD,” IEEE Trans. Speech Audio Process., vol. ,
pp. –, Nov. .

63
3
Single-Channel Signal Enhancement in the Frequency Domain
In this chapter, we continue our investigation of the single-channel signal enhancement
problem but, this time, in the frequency domain. In many respects, the frequency-
domain approach is equivalent to the spectral method discussed in the previous
chapter. The advantages of the frequency-domain technique are twofold. First, it is very
ﬂexible, in the sense that the observation signal at each frequency can be processed
independently of the others. Second, thanks to the fast Fourier transform, all algorithms
can be implemented very eﬃciently. We start by formulating the problem. We then
explain how to perform noise reduction with just simple gains. We give all relevant
performance measures. We also derive all kinds of optimal gains and show how we
can compromise between distortion of the desired signal and reduction of the additive
noise. Finally, we explain how these gains can be implemented in the short-time Fourier
transform domain.
3.1
Signal Model and Problem Formulation
We recall from Chapter that the observation signal in the time domain is
y(t) = x(t) + v(t),
(.)
where x(t) and v(t) are the desired and noise signals, respectively. In the frequency
domain, (.) can be written as []:
Y( f ) = X( f ) + V( f ),
(.)
where Y( f ), X( f ), and V( f ) are the frequency-domain representations of y(t), x(t), and
v(t), respectively, at the frequency index f . Obviously, X( f ) and V( f ) are, respectively,
the desired and noise signals in the frequency domain. Since the zero-mean signals X( f )
and V( f ) are assumed to be uncorrelated, the variance of Y( f ) is
𝜙Y( f ) = E
[
|Y( f )|]
(.)
= 𝜙X( f ) + 𝜙V( f ),
where 𝜙X( f ) = E
[
|X( f )|]
and 𝜙V( f ) = E
[
|V( f )|]
are the variances of X( f ) and V( f ),
respectively.
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing
www.ebook3000.com

64
Fundamentals of Signal Enhancement and Array Signal Processing
The objective of single-channel noise reduction in the frequency domain is then to
ﬁnd an estimate of X( f ) from Y( f ).
3.2
Noise Reduction with Gains
An estimate of X( f ) can be obtained by multiplying Y( f ) with a complex gain, H( f ), as
illustrated in Figure .:
Z( f ) = H( f )Y( f )
(.)
= H( f )
[
X( f ) + V( f )
]
= Xfd( f ) + Vrn( f ),
where Z( f ) is the frequency-domain representation of the signal z(t),
Xfd( f ) = H( f )X( f )
(.)
is the ﬁltered desired signal, and
Vrn( f ) = H( f )V( f )
(.)
is the residual noise. The variance of Z( f ) can then be written as
𝜙Z( f ) = E [
|Z( f )|]
(.)
= |H( f )|𝜙Y( f )
= 𝜙Xfd( f ) + 𝜙Vrn( f ),
where
𝜙Xfd( f ) = |H( f )|𝜙X( f )
(.)
is the variance of the ﬁltered desired signal and
𝜙Vrn( f ) = |H( f )|𝜙V( f )
(.)
is the variance of the residual noise.
+
V(f)
X ( f)
Y ( f )
H( f )
Z (f)
Figure 3.1 Block diagram of noise reduction with gains in the frequency domain.

Single-Channel Signal Enhancement in the Frequency Domain
65
3.3
Performance Measures
In this section, we discuss both the narrowband and broadband performance measures.
In a similar way to the spectral mode input SNR, we deﬁne the narrowband input
SNR as
iSNR( f ) = 𝜙X( f )
𝜙V( f ).
(.)
The broadband input SNR is obtained by simply integrating over all frequencies the
numerator and denominator of iSNR( f ). We get
iSNR =
∫f 𝜙X( f )df
∫f 𝜙V( f )df
.
(.)
After noise reduction with the frequency-domain model given in (.), the narrow-
band output SNR can be written as
oSNR [H( f )] =
𝜙Xfd( f )
𝜙Vrn( f )
(.)
= iSNR( f ).
It is important to observe that the narrowband output SNR is not inﬂuenced by H( f ).
We deduce that the broadband output SNR is
oSNR (H) =
∫f 𝜙Xfd( f )df
∫f 𝜙Vrn( f )df
(.)
=
∫f |H( f )|𝜙X( f )df
∫f |H( f )|𝜙V( f )df
.
It is essential to ﬁnd the complex gains H( f ) at all frequencies in such a way that
oSNR(H) > iSNR.
Other important measures in noise reduction are the noise reduction factors.
We deﬁne the narrowband and broadband noise reduction factors as, respectively,
𝜉n
[
H( f )
]
=

|H( f )|
(.)
and
𝜉n (H) =
∫f 𝜙V( f )df
∫f |H( f )|𝜙V( f )df
.
(.)
The larger the values of the noise reduction factors, the more the noise is reduced.
www.ebook3000.com

66
Fundamentals of Signal Enhancement and Array Signal Processing
In the same way, we deﬁne the narrowband and broadband desired signal reduction
factors as, respectively,
𝜉d
[H( f )] =

|H( f )|
(.)
and
𝜉d (H) =
∫f 𝜙X( f )df
∫f |H( f )|𝜙X( f )df
.
(.)
The larger the values of the desired signal reduction factors, the more the desired signal
is distorted.
We always have
oSNR (H)
iSNR
= 𝜉n (H)
𝜉d (H).
(.)
This means that the gain in SNR comes with the distortion of the desired and noise
signals.
Another way to quantify distortion is via the narrowband desired signal distortion
index:
𝜐d
[H( f )] =
E [
|H( f )X( f ) −X( f )|]
𝜙X( f )
(.)
= |−H( f )|
and the broadband desired signal distortion index:
𝜐d (H) =
∫f E
[
|H( f )X( f ) −X( f )|]
df
∫f 𝜙X( f )df
(.)
=
∫f |−H( f )|𝜙X( f )df
∫f 𝜙X( f )df
=
∫f 𝜐d
[H( f )] 𝜙X( f )df
∫f 𝜙X( f )df
.
The desired signal distortion index has a lower bound of and an upper bound of for
optimal gains.
We deﬁne the error signal between the estimated and desired signals at frequency f as
( f ) = Z( f ) −X( f )
(.)
= H( f )Y( f ) −X( f ).

Single-Channel Signal Enhancement in the Frequency Domain
67
This error can also be put into the form:
( f ) = d( f ) + n( f ),
(.)
where
d( f ) = [H( f ) −] X( f )
(.)
is the desired signal distortion due to the complex gain and
n( f ) = H( f )V( f )
(.)
represents the residual noise. The narrowband MSE criterion is then
J
[
H( f )
]
= E
[
|( f )|]
(.)
= 𝜙X( f ) + |H( f )|𝜙Y( f ) −H( f )𝜙X( f ) −H∗( f )𝜙X( f )
= |−H( f )|𝜙X( f ) + |H( f )|𝜙V( f ),
where the superscript ∗is the complex-conjugate operator. The narrowband MSE is also
J [H( f )] = E
[
||d( f )||
]
+ E
[
||n( f )||
]
(.)
= Jd
[
H( f )
]
+ Jn
[
H( f )
]
,
where
Jd
[H( f )] = 𝜙X( f )𝜐d
[H( f )]
(.)
and
Jn
[H( f )] =
𝜙V( f )
𝜉n
[
H( f )
].
(.)
We deduce that
J [H( f )] = 𝜙V( f )
{
iSNR( f ) × 𝜐d
[H( f )] +

𝜉n
[
H( f )
]
}
(.)
and
Jd
[
H( f )
]
Jn
[
H( f )
] = iSNR( f ) × 𝜉n
[H( f )] × 𝜐d
[H( f )]
(.)
= oSNR [H( f )] × 𝜉d
[H( f )] × 𝜐d
[H( f )] ,
www.ebook3000.com

68
Fundamentals of Signal Enhancement and Array Signal Processing
showing how the narrowband MSEs are related to the diﬀerent narrowband performance
measures.
The extension of the narrowband MSE to the broadband case is straightforward.
We deﬁne the broadband MSE criterion as
J (H) = ∫f
J [H( f )] df
(.)
= ∫f
|−H( f )|𝜙X( f )df + ∫f
|H( f )|𝜙V( f )df
= Jd (H) + Jn (H) ,
where
Jd (H) = 𝜐d (H) ∫f
𝜙X( f )df
(.)
and
Jn (H) =
∫f 𝜙V( f )df
𝜉n (H)
.
(.)
These expressions show how the broadband MSEs are fundamentally equivalent to the
broadband performance measures.
3.4
Optimal Gains
Now, we focus our attention on the derivation and analysis of some important gains for
noise reduction. Taking the gradient of J
[
H( f )
]
(from Equation .) with respect to
H∗( f ) and equating the result to leads to
−E
{
Y ∗( f )
[
X( f ) −HW( f )Y( f )
]}
= .
(.)
Hence,
𝜙Y( f )HW( f ) = 𝜙XY( f ),
(.)
where
𝜙XY( f ) = E [X( f )Y ∗( f )]
(.)
= 𝜙X( f )
is the the cross-correlation between X( f ) and Y( f ), which simpliﬁes to the variance of
X( f ) in this particular model. Therefore, the optimal Wiener gain can be put into the
following forms:

Single-Channel Signal Enhancement in the Frequency Domain
69
HW( f ) = 𝜙X( f )
𝜙Y( f )
(.)
= −𝜙V( f )
𝜙Y( f )
=
iSNR( f )
+ iSNR( f ).
We observe that this gain is always real, positive, and smaller than one. Another way
to write the Wiener gain is with the magnitude squared coherence functions (MSCFs).
Indeed, it is easy to see that
HW( f ) = |||𝜌[X( f ), Y( f )]|||

(.)
= −|||𝜌[V( f ), Y( f )]|||

,
where
|||𝜌[X( f ), Y( f )]|||

=
|||E [X( f )Y ∗( f )]|||

E [
|X( f )|] E [
|Y( f )|]
(.)
=
||𝜙XY( f )||

𝜙X( f )𝜙Y( f )
=
iSNR( f )
+ iSNR( f )
is the MSCF between X( f ) and Y( f ), and
|||𝜌[V( f ), Y( f )]|||

=
||𝜙VY( f )||

𝜙V( f )𝜙Y( f )
(.)
=

+ iSNR( f )
is the MSCF between V( f ) and Y( f ). When the level of the noise is high at frequency
f , |||𝜌[V( f ), Y( f )]|||

≈, then HW( f ) is close to since there is a large amount of
noise that needs to be removed. When the level of the noise is low at frequency f ,
|||𝜌[V( f ), Y( f )]|||

≈, then HW( f ) is close to and this gain is not going to greatly
aﬀect the signals since there is little noise that needs to be removed.
Now, let us deﬁne the complex number:
𝜚
[
X( f ), V( f )
]
= 𝜌
[
X( f ), Y( f )
]
+ 𝚥𝜌
[
V( f ), Y( f )
]
(.)
= cos 𝜃( f ) + 𝚥sin 𝜃( f ),
Notice that both 𝜌[X( f ), Y( f )] and 𝜌[V( f ), Y( f )] are real numbers.
www.ebook3000.com

70
Fundamentals of Signal Enhancement and Array Signal Processing
where 𝚥=
√
−is the imaginary unit and 𝜃( f ) is the phase of 𝜚
[
X( f ), V( f )
]
whose
modulus is equal to . On the complex plane, 𝜚[X( f ), V( f )] is on the unit circle. Since
≤𝜌[X( f ), Y( f )] ≤and ≤𝜌[V( f ), Y( f )] ≤, therefore ≤𝜃( f ) ≤𝜋
. We can
then rewrite the Wiener gain as a function of the angle 𝜃( f ):
HW( f ) = cos𝜃( f )
(.)
= −sin𝜃( f ).
Hence,
lim
𝜃( f )→HW( f ) = ,
(.)
lim
𝜃( f )→𝜋

HW( f ) = .
(.)
The MMSE is obtained by replacing (.) in (.):
J [HW( f )] = 𝜙X( f ) −
𝜙
X( f )
𝜙Y( f )
(.)
= 𝜙V( f ) −
𝜙
V( f )
𝜙Y( f ),
which can be rewritten as
J [HW( f )] = 𝜙X( f )
{
−|||𝜌[X( f ), Y( f )]|||
}
(.)
= 𝜙V( f )
{
−|||𝜌[V( f ), Y( f )]|||
}
= HW( f )𝜙V( f )
= [−HW( f )] 𝜙X( f ).
We deduce all the narrowband performance measures with the Wiener gain:
𝜉n
[HW( f )] =

cos𝜃( f ) ≥,
(.)
𝜉d
[HW( f )] =

cos𝜃( f ) ≥,
(.)
𝜐d
[HW( f )] = sin𝜃( f ) ≤.
(.)
We recall that the narrowband output SNR is equal to the narrowband input SNR.
Figure .shows plots of the optimal Wiener gain, HW( f ), the angle, 𝜃( f ), the
narrowband noise reduction factor, 𝜉n
[HW( f )], and the narrowband desired signal
distortion index, 𝜐d
[
HW( f )
]
, as a function of the narrowband input SNR. As the input
SNR increases, the Wiener gain increases, since there is less noise to suppress. As a
result, both the noise reduction factor and the desired signal distortion index decrease.
We now give a fundamental property about the broadband output SNR with the
Wiener gain.

Single-Channel Signal Enhancement in the Frequency Domain
71
−10
−5
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
1.2
1.4
0
5
10
15
20
25
30
−50
−40
−30
−20
−10
0
iSNR( f) (dB)
−10
−5
0
5
10
15
20
iSNR( f )  (dB)
−10
−5
0
5
10
15
20
iSNR( f) (dB)
−10
−5
0
5
10
15
20
iSNR( f )  (dB)
(a)
(b)
(c)
(d)
HW( f )
θ( f )  (rad)
ξn [HW( f ) ] (dB)
υd [HW( f ) ] (dB)
Figure 3.2 (a) The optimal Wiener gain, (b) the angle, (c) the narrowband noise reduction factor, and
(d) the narrowband desired signal distortion index as a function of the narrowband input SNR.
Property ..
With the optimal Wiener gain given in (.), the broadband output
SNR is always greater than or equal to the broadband input SNR; in other words,
oSNR (HW
) ≥iSNR.
Proof. The broadband MSCF, which is equivalent to the SPCC, between the two zero-
mean random variables A( f ) and B( f ), which are the frequency-domain representations
of the time-domain real signals a(t) and b(t), is deﬁned as
|𝜌(A, B)|=
||||
E
[
∫f A( f )B∗( f )df
]||||

E
[
∫f |A( f )|df
]
E
[
∫f |B( f )|df
]
(.)
=
|||∫f 𝜙AB( f )df |||

[
∫f 𝜙A( f )df
] [
∫f 𝜙B( f )df
]
=
E[
a(t)b(t)
]
𝜎
a𝜎
b
= 𝜌(a, b) .
www.ebook3000.com

72
Fundamentals of Signal Enhancement and Array Signal Processing
Let us evaluate the broadband MSCF between Y( f ) and ZW( f ) = HW( f )Y( f ):
|||𝜌
(
Y, ZW
)|||

=
[
∫f HW( f )𝜙Y( f )df
]
[
∫f 𝜙Y( f )df
] [
∫f H
W( f )𝜙Y( f )df
]
=
∫f 𝜙X( f )df
∫f 𝜙Y( f )df
×
∫f 𝜙X( f )df
∫f HW( f )𝜙X( f )df
=
|𝜌(X, Y)|
|||𝜌(X, ZW
)|||
.
Therefore,
|𝜌(X, Y)|= |||𝜌
(
Y, ZW
)|||

× |||𝜌
(
X, ZW
)|||

≤|||𝜌
(
X, ZW
)|||

.
(.)
On the other hand, it can be shown that
|𝜌(X, Y)|=
iSNR
+ iSNR
and
|||𝜌(X, ZW
)|||

≤
oSNR
(
HW
)
+ oSNR
(
HW
).
Substituting the two previous expressions into (.), we obtain
iSNR
+ iSNR ≤
oSNR
(
HW
)
+ oSNR
(
HW
).
As a result, we have
oSNR (HW
) ≥iSNR.
■
Example ..
Consider a desired signal, X( f ), with the variance:
𝜙X( f ) =
⎧
⎪
⎨
⎪⎩
𝛼,
|f | ≤

,

≤|f | ≤

,
which is corrupted with additive noise, V( f ), with the variance:
𝜙V( f ) = 𝛽(−|f |
) , −
≤|f | ≤
.

Single-Channel Signal Enhancement in the Frequency Domain
73
The desired signal is uncorrelated with the noise, and needs to be recovered from the
noisy observation, Y( f ) = X( f ) + V( f ).
The narrowband input SNR is
iSNR( f ) = 𝜙X( f )
𝜙V( f )
=
⎧
⎪
⎨
⎪⎩
𝛼
𝛽
(−|f |
)−,
|f | ≤

,

≤|f | ≤

and the broadband input SNR is
iSNR =
∫f 𝜙X( f )df
∫f 𝜙V( f )df
= 𝛼
𝛽.
The optimal Wiener gain is given by
HW( f ) =
iSNR( f )
+ iSNR( f )
=
⎧
⎪
⎨
⎪⎩
𝛼
𝛽
(
𝛼
𝛽+ −|f |
)−
,
|f | ≤

,

≤|f | ≤

.
The broadband output SNR, oSNR (HW
), is computed using (.), and the broadband
gain in SNR is obtained using (HW
) = oSNR (HW
) ∕iSNR. Figure .shows plots
of the broadband gain in SNR, the broadband MSE, J
(
HW
)
, the broadband noise
reduction factor, 𝜉n
(HW
), and the broadband desired signal reduction factor, 𝜉d
(HW
),
as a function of the broadband input SNR. As the input SNR increases, the less the
noise that needs to be suppressed, and the less the distortion that is introduced into the
ﬁltered desired signal.
■
Example ..
Suppose that the desired signal is a harmonic pulse of T samples:
x(t) =
{
A sin
(
𝜋ft + 𝜙
)
,
≤t ≤T −
,
t < , t ≥T
,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly distributed on
the interval from to 𝜋. This signal needs to be recovered from the noisy observation,
y(t) = x(t) + v(t), where v(t) is additive white Gaussian noise; in other words, v(t) ∼
(, 𝜎
v
), which is uncorrelated with x(t).
www.ebook3000.com

74
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
1.25
1.3
1.35
1.4
1.45
1.5
−5
0
5
10
15
−25
−20
−15
−10
−5
−5
0
5
10
15
0
2
4
6
8
10
12
−5
0
5
10
15
0
2
4
6
8
10
12
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(a)
(b)
(c)
(d)
J (HW) (dB)
ξn (HW) (dB)
ξd (HW) (dB)
(HW) (dB)
Figure 3.3 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise reduction
factor, and (d) the broadband desired signal reduction factor of the Wiener gain as a function of the
broadband input SNR.
The frequency-domain representation of the desired signal is given by
X( f ) =
∞
∑
t=−∞
x(t)e𝚥𝜋ft
=
T−
∑
t=
A sin (𝜋ft + 𝜙) e𝚥𝜋ft
= A
𝚥e𝚥𝜙+𝚥𝜋(f +f)(T−)DT
[𝜋(f + f
)]
+ A
𝚥e−𝚥𝜙+𝚥𝜋(f −f)(T−)DT
[𝜋(f −f
)] ,
where the function DT(x) is the Dirichlet kernel, deﬁned as
DT(x) = sin (Tx)
sin (x) .

Single-Channel Signal Enhancement in the Frequency Domain
75
Hence, the variance of X( f ) is
𝜙X( f ) = A
D
T
[𝜋(f + f
)] + A
D
T
[𝜋(f −f
)] .
The frequency-domain representation of the noise signal is
V( f ) =
T−
∑
t=
v(t)e𝚥𝜋ft.
Hence, the variance of V( f ) is 𝜙V( f ) = T𝜎
v. The narrowband input SNR is
iSNR( f ) = 𝜙X( f )
𝜙V( f )
=
A
T𝜎
v
D
T
[𝜋(f + f
)] +
A
T𝜎
v
D
T
[𝜋(f −f
)]
and the broadband input SNR is
iSNR =
∫f 𝜙X( f )df
∫f 𝜙V( f )df
=
∑
t E [
|x(t)|]
∑
t E [
|v(t)|]
= A
𝜎
v
,
where we have used Parseval’s identity. The optimal Wiener gain is obtained from (.).
To demonstrate the performance of the Wiener gain, we choose A = ., f= .,
and T = . Figure .shows plots of the broadband gain in SNR, the broadband
MSE, J (HW
), the broadband noise reduction factor, 𝜉n
(HW
), and the broadband
desired signal reduction factor, 𝜉d
(HW
), as a function of the broadband input SNR.
Figure .shows a realization of the noise corrupted and ﬁltered sinusoidal signals for
iSNR = dB.
■
An important gain can be designed by minimizing the desired signal-distortion-based
MSE with the noise-reductionraint that the noise-reduction-based MSE is equal to a
positive number smaller than the level of the original noise. This optimization problem
can be translated mathematically as
min
H( f ) Jd
[H( f )]
subject to Jn
[H( f )] = ℵ𝜙V( f ),
(.)
where
Jd
[H( f )] = |−H( f )|𝜙X( f ),
(.)
www.ebook3000.com

76
Fundamentals of Signal Enhancement and Array Signal Processing
−4
−2
0
2
4
6
8
8
10
12
14
16
18
20
8
10
12
14
16
18
20
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
−5
0
5
10
15
−5
0
5
10
15
−5
0
5
10
15
−5
0
5
10
15
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(a)
(b)
(c)
(d)
J (HW) (dB)
ξn (HW) (dB)
ξd (HW) (dB)
(HW) (dB)
Figure 3.4 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise reduction
factor, and (d) the broadband desired signal reduction factor of the Wiener gain as a function of the
broadband input SNR.
Jn
[H( f )] = |H( f )|𝜙V( f ),
(.)
and < ℵ< to ensure that we have some noise reduction at frequency f . If we use
a Lagrange multiplier, 𝜇( f ) ≥, to adjoin the constraint to the cost function, we easily
ﬁnd the tradeoﬀgain:
HT,𝜇( f ) =
𝜙X( f )
𝜙X( f ) + 𝜇( f )𝜙V( f )
(.)
=
𝜙Y( f ) −𝜙V( f )
𝜙Y( f ) +
[
𝜇( f ) −
]
𝜙V( f )
=
iSNR( f )
𝜇( f ) + iSNR( f ).
This gain can be seen as a Wiener gain with an adjustable input noise level 𝜇( f )𝜙V( f ).
Obviously, the particular case of 𝜇( f ) = corresponds to the Wiener gain.

Single-Channel Signal Enhancement in the Frequency Domain
77
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
0
20
40
60
80
100
120
140
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
0
20
40
60
80
100
120
140
0
100
200
300
400
500
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
0
100
200
300
400
500
−1
−0.5
0
0.5
1
f
f
t
t
|Y( f )|
|Z( f )|
z(t)
y(t)
(a)
(b)
(c)
(d)
Figure 3.5 Example of noise corrupted and Wiener filtered sinusoidal signals for iSNR = 0 dB.
(a) Magnitude of frequency-domain observation signal, |Y( f)|, (b) magnitude of frequency-domain
estimated signal, |Z( f)|, (c) time-domain observation signal, y(t), and (d) time-domain estimated
signal, z(t).
We can also ﬁnd the optimal 𝜇( f ) corresponding to a given value of ℵ. Substituting
HT,𝜇( f ) from (.) into the constraint in (.), we get
Jn
[HT,𝜇( f )] = |||HT,𝜇( f )|||

𝜙V( f )
(.)
= ℵ𝜙V( f ).
From the previous expression, we easily ﬁnd that
𝜇( f ) = iSNR( f )−
√
ℵ
√
ℵ
(.)
and the tradeoﬀsimpliﬁes to a constant gain:
HT,ℵ=
√
ℵ.
(.)
www.ebook3000.com

78
Fundamentals of Signal Enhancement and Array Signal Processing
In the rest, we assume that 𝜇( f ) is a constant, so it does not depend on frequency and
we can drop the variable f . Usually, the value of 𝜇is given by design.
The MSCF between the two signals X( f ) and X( f ) + √𝜇V( f ) at frequency f is
|||𝜌
[
X( f ), X( f ) +
√
𝜇V( f )
]|||

=
iSNR( f )
𝜇+ iSNR( f ).
(.)
The MSCF between the two signals V( f ) and X( f ) + √𝜇V( f ) at frequency f is
|||𝜌[V( f ), X( f ) +
√
𝜇V( f )]|||

=
𝜇
𝜇+ iSNR( f ).
(.)
Therefore, we can write the tradeoﬀgain as a function of these two MSCFs:
HT,𝜇( f ) = |||𝜌[X( f ), X( f ) +
√
𝜇V( f )]|||

(.)
= −|||𝜌[V( f ), X( f ) +
√
𝜇V( f )]|||

.
Now, let us deﬁne the complex number:
𝜚𝜇
[X( f ), V( f )] = 𝜌[X( f ), X( f ) +
√
𝜇V( f )]
+ 𝚥𝜌
[
V( f ), X( f ) +
√
𝜇V( f )
]
= cos 𝜃𝜇( f ) + 𝚥sin 𝜃𝜇( f ),
(.)
where 𝜃𝜇( f ) is the phase of 𝜚𝜇
[
X( f ), V( f )
]
whose modulus is equal to . On the complex
plane, 𝜚𝜇
[X( f ), V( f )] is on the unit circle. Since ≤𝜌[X( f ), X( f ) + √𝜇V( f )] ≤and
≤𝜌
[
V( f ), X( f ) + √𝜇V( f )
]
≤, therefore ≤𝜃𝜇( f ) ≤𝜋
. We can then rewrite the
tradeoﬀgain as a function of the angle 𝜃𝜇( f ):
HT,𝜇( f ) = cos𝜃𝜇( f )
(.)
= −sin𝜃𝜇( f ).
We deduce all the narrowband performance measures with the tradeoﬀgain:
oSNR
[
HT,𝜇( f )
]
= iSNR( f ),
(.)
𝜉n
[HT,𝜇( f )] =

cos𝜃𝜇( f ) ≥,
(.)
𝜉d
[HT,𝜇( f )] =

cos𝜃𝜇( f ) ≥,
(.)
𝜐d
[HT,𝜇( f )] = sin𝜃𝜇( f ) ≤.
(.)
Notice that both 𝜌
[
X( f ), X( f ) + √𝜇V( f )
]
and 𝜌
[
V( f ), X( f ) + √𝜇V( f )
]
are real numbers.

Single-Channel Signal Enhancement in the Frequency Domain
79
−10
−5
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
0
0.5
1
1.5
0
5
10
15
20
25
30
−50
−40
−30
−20
−10
0
iSNR(f) (dB)
−10
−5
0
5
10
15
20
iSNR(f) (dB)
−10
−5
0
5
10
15
20
iSNR( f ) (dB)
−10
−5
0
5
10
15
20
iSNR( f ) (dB)
(a)
(b)
(c)
(d)
HT,μ ( f )
θμ ( f ) (rad)
υn [HT,µ ( f )] (dB)
ξn [HT,µ ( f )] (dB)
Figure 3.6 (a) The tradedoff gain, (b) the angle, (c) the narrowband noise reduction factor, and (d) the
narrowband desired signal distortion index as a function of the narrowband input SNR for different
values of 𝜇: 𝜇= 0.5 (dashed line with asterisks), 𝜇= 1 (solid line with circles), 𝜇= 2 (dotted line with
squares), and 𝜇= 5 (dash-dot line with triangles).
Figure .shows plots of the tradedoﬀgain, HT,𝜇( f ), the angle, 𝜃𝜇( f ), the narrowband
noise reduction factor, 𝜉n
[
HT,𝜇( f )
]
, and the narrowband desired signal distortion index,
𝜐d
[
HT,𝜇( f )
]
, as a function of the narrowband input SNR for diﬀerent values of 𝜇. For a
given input SNR, the higher the value of 𝜇, the lower the tradedoﬀgain. Hence, both the
noise reduction factor and the desired signal distortion index monotonically increase
as a function of 𝜇.
We give the following fundamental property about the broadband output SNR with
the tradeoﬀgain.
Property ..
With the tradeoﬀgain given in (.), the broadband output
SNR is always greater than or equal to the broadband input SNR; in other words,
oSNR (HT,𝜇
) ≥iSNR, ∀𝜇≥.
www.ebook3000.com

80
Fundamentals of Signal Enhancement and Array Signal Processing
Proof. The broadband MSCF between the two variables X( f ) and X( f ) + √𝜇V( f ) is
|||𝜌(X, X +
√
𝜇V)|||

=
[
∫f 𝜙X( f )df
]
[
∫f 𝜙X( f )df
] [
∫f 𝜙X( f )df + 𝜇∫f 𝜙V( f )df
]
=
iSNR
𝜇+ iSNR.
The broadband MSCF between the two variables X( f ) and HT,𝜇( f )X( f ) + √𝜇HT,𝜇( f )
V( f ) is
|||𝜌(X, HT,𝜇X +
√
𝜇HT,𝜇V)|||

=
[
∫f HT,𝜇( f )𝜙X( f )df
]
[
∫f 𝜙X( f )df
] [
∫f H
T,𝜇( f )𝜙X( f )df + 𝜇∫f H
T,𝜇( f )𝜙V( f )df
]
=
∫f HT,𝜇( f )𝜙X( f )df
∫f 𝜙X( f )df
.
Another way to write the same broadband MSCF is as follows:
|||𝜌(X, HT,𝜇X +
√
𝜇HT,𝜇V)|||

=
[
∫f HT,𝜇( f )𝜙X( f )df
]
[
∫f 𝜙X( f )df
] [
∫f H
T,𝜇( f )𝜙X( f )df
]
×
oSNR (HT,𝜇
)
𝜇+ oSNR (HT,𝜇
)
= |||𝜌(X, HT,𝜇X)|||

× |||𝜌(HT,𝜇X, HT,𝜇X +
√
𝜇HT,𝜇V)|||

≤
oSNR (HT,𝜇
)
𝜇+ oSNR (HT,𝜇
).
Now, let us evaluate the broadband MSCF between the two variables X( f ) + √𝜇V( f )
and HT,𝜇( f )X( f ) + √𝜇HT,𝜇( f )V( f ):
|||𝜌
(
X +
√
𝜇V, HT,𝜇X +
√
𝜇HT,𝜇V
)|||

=
∫f 𝜙X( f )df
∫f 𝜙X( f )df + 𝜇∫f 𝜙V( f )df
×
∫f 𝜙X( f )df
∫f HT,𝜇( f )𝜙X( f )df
=
|||𝜌(X, X + √𝜇V)|||

|||𝜌
(
X, HT,𝜇X + √𝜇HT,𝜇V
)|||
.

Single-Channel Signal Enhancement in the Frequency Domain
81
Therefore,
|||𝜌(X, X +
√
𝜇V)|||

=
iSNR
𝜇+ iSNR
= |||𝜌(X +
√
𝜇V, HT,𝜇X +
√
𝜇HT,𝜇V)|||

× |||𝜌(X, HT,𝜇X +
√
𝜇HT,𝜇V)|||

≤|||𝜌
(
X, HT,𝜇X +
√
𝜇HT,𝜇V)|||

≤
oSNR (HT,𝜇
)
𝜇+ oSNR (HT,𝜇
).
As a result, we have
oSNR (HT,𝜇
) ≥iSNR.
■
Example ..
Returning to Example .., Figure .shows plots of the broadband
gain in SNR, (HT,𝜇
), the broadband MSE, J (HT,𝜇
), the broadband noise reduction
factor, 𝜉n
(
HT,𝜇
)
, and the broadband desired signal reduction factor, 𝜉d
(
HT,𝜇
)
, as a
function of the broadband input SNR for diﬀerent values of 𝜇. Figure .shows similar
plots for the signals in Example ...
For a given broadband input SNR, the higher the value of 𝜇, the higher the broadband
SNR gain and noise reduction, but at the expense of higher broadband desired signal
reduction.
■
Some applications may need aggressive noise reduction while others may require
minimal desired signal distortion (and so less aggressive noise reduction). An easy way
to control the compromise between noise reduction and signal distortion is via the
parametric Wiener gain[, ]:
H𝜇,𝜇( f ) =
[
−sin𝜇𝜃( f )
]𝜇,
(.)
where 𝜇and 𝜇are two positive parameters that allow for control of this compromise.
For (𝜇, 𝜇) = (, ), we get the Wiener gain developed previously. Taking (𝜇, 𝜇) =
(, ∕), leads to
Hpow( f ) =
√
−sin𝜃( f )
(.)
= cos 𝜃( f ),
There is nothing optimal about the parametric Wiener gain but, for convenience of presentation, we
included it in this section.
www.ebook3000.com

82
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
1.25
1.3
1.35
1.4
1.45
1.5
1.55
1.6
1.65
−25
−20
−15
−10
−5
0
5
10
15
20
25
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
(a)
(c)
(b)
ξn (HT,µ) (dB)
0
5
10
15
20
25
(d)
ξd (HT,µ) (dB)
(HT,µ) (dB)
J (HT,µ) (dB)
Figure 3.7 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise reduction
factor, and (d) the broadband desired signal reduction factor of the tradeoff gain as a function of the
broadband input SNR for different values of 𝜇: 𝜇= 0.5 (dashed line with asterisks), 𝜇= 1 (solid line
with circles), 𝜇= 2 (dotted line with squares), and 𝜇= 5 (dash-dot line with triangles).
which is the power subtraction method [–]. The pair (𝜇, 𝜇) = (, ) gives the
magnitude subtraction method [–]:
Hmag( f ) = −sin 𝜃( f )
(.)
= −
√
−cos𝜃( f ).
We can verify that the narrowband noise reduction factors for the power subtraction
and magnitude subtraction methods are
𝜉n
[Hpow( f )] =

cos𝜃( f ),
(.)
𝜉n
[
Hmag( f )
]
=

[
−sin 𝜃( f )
],
(.)

Single-Channel Signal Enhancement in the Frequency Domain
83
−5
0
5
10
15
6
8
10
12
14
16
18
20
22
−4
−2
0
2
4
6
8
5
10
15
20
25
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
(a)
(c)
(b)
ξn (HT,µ) (dB)
0.4
0.2
0
0.6
0.8
1
1.2
1.4
(d)
ξd (HT,µ) (dB)
J (HT,µ) (dB)
 (HT,µ) (dB)
Figure 3.8 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise reduction
factor, and (d) the broadband desired signal reduction factor of the tradeoff gain as a function of the
broadband input SNR for different values of 𝜇: 𝜇= 0.5 (dashed line with asterisks), 𝜇= 1 (solid line
with circles), 𝜇= 2 (dotted line with squares), and 𝜇= 5 (dash-dot line with triangles).
and the corresponding narrowband desired signal distortion indices are
𝜐d
[
Hpow( f )
]
=
[
−cos 𝜃( f )
],
(.)
𝜐d
[Hmag( f )] = sin𝜃( f ).
(.)
We can also easily check that
𝜉n
[Hmag( f )] ≥𝜉n
[HW( f )] ≥𝜉n
[Hpow( f )] ,
(.)
𝜐d
[Hpow( f )] ≤𝜐d
[HW( f )] ≤𝜐d
[Hmag( f )] .
(.)
These two inequalities are very important from a practical point of view. They show
that, of the three methods, magnitude subtraction is the most aggressive as far as noise
reduction is concerned, a very well-known fact in the literature [] but, at the same
time, it is the one that will likely distort the desired signal the most. The smoothest
approach is power subtraction while the Wiener gain is between the two others in
www.ebook3000.com

84
Fundamentals of Signal Enhancement and Array Signal Processing
−10
−5
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
0
5
10
15
20
25
30
−10
−5
0
5
10
15
20
−50
−40
−30
−20
−10
0
−10
−5
0
5
10
15
20
(a)
(b)
(c)
Hμ1,μ2 ( f )
ξn [Hμ1,μ2( f )] (dB)
υd [Hμ1,μ2( f )] (dB)
iSNR(f) (dB)
iSNR( f ) (dB)
iSNR( f ) (dB)
Figure 3.9 (a) The parametric Wiener gain, (b) the narrowband noise reduction factor, and (c) the
narrowband desired signal distortion index as a function of the narrowband input SNR for different
values of (𝜇1, 𝜇2): magnitude subtraction with (𝜇1, 𝜇2) = (1, 1) (dashed line with asterisks), Wiener
gain with (𝜇1, 𝜇2) = (2, 1) (solid line with circles), and power subtraction with (𝜇1, 𝜇2) = (2, 1∕2)
(dotted line with squares).
terms of desired signal distortion and noise reduction. Several other variants of these
algorithms can be found in the literature [–].
Figure .shows plots of the parametric Wiener gain, H𝜇,𝜇( f ), the narrowband noise
reduction factor, 𝜉n
[H𝜇,𝜇( f )], and the narrowband desired signal distortion index,
𝜐d
[
H𝜇,𝜇( f )
]
, as a function of the narrowband input SNR for diﬀerent values of the pair
(𝜇, 𝜇). For a given input SNR, HW( f ) is larger than Hmag( f ) and smaller than Hpow( f ).
Hence the magnitude subtraction method is associated with higher noise reduction and
desired signal distortion than the Wiener method, while the power subtraction method
is associated with less noise reduction and desired signal distortion than the Wiener
method.
Example ..
Returning to Example .., Figure .shows plots of the broadband
gain in SNR, (H𝜇,𝜇
), the broadband MSE, J (H𝜇,𝜇
), the broadband noise reduction
factor, 𝜉n
(
H𝜇,𝜇
)
, and the broadband desired signal reduction factor, 𝜉d
(
H𝜇,𝜇
)
, as a
function of the broadband input SNR for diﬀerent values of (𝜇, 𝜇). Figure .shows
similar plots for the signals in Example ...

Single-Channel Signal Enhancement in the Frequency Domain
85
1.25
1.3
1.35
1.4
1.45
1.5
1.55
1.6
−25
−20
−15
−10
−5
−5
0
5
10
15
0
5
10
15
20
0
2
4
6
8
10
12
14
16
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
(a)
(b)
(c)
(d)
J (Hμ1 ,μ2) (dB)
ξn (Hμ1 ,μ2) (dB)
ξd (Hμ1 ,μ2) (dB)
   (Hμ1 ,μ2) (dB)
Figure 3.10 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise
reduction factor, and (d) the broadband desired signal reduction factor of the parametric Wiener gain
as a function of the broadband input SNR for different values of (𝜇1, 𝜇2): magnitude subtraction with
(𝜇1, 𝜇2) = (1, 1) (dashed line with asterisks), Wiener gain with (𝜇1, 𝜇2) = (2, 1) (solid line with circles),
and power subtraction with (𝜇1, 𝜇2) = (2, 1∕2) (dotted line with squares).
For a given broadband input SNR, the magnitude subtraction method is associated
with higher broadband SNR gain and noise reduction than the Wiener method, but
at the expense of higher broadband desired signal reduction. On the other hand, the
power subtraction method is associated with lower broadband desired signal reduction
than the Wiener method, but at the expense of lower broadband SNR gain and noise
reduction.
■
3.5
Constraint Wiener Gains
In this section, we slightly change the notation for convenience. From the previous
section, we know that the traditional way to estimate the desired signal, X( f ), is by
applying a gain, HX( f ), to the observation, Y( f ):
̂X( f ) = Y( f )HX( f ).
(.)
www.ebook3000.com

86
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
6
8
10
12
14
16
18
20
22
−4
−2
0
2
4
6
8
−5
0
5
10
15
6
8
10
12
14
16
18
20
22
0
0.5
1
1.5
2
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
iSNR (dB)
(a)
(b)
ξn (Hμ1 ,μ2) (dB)
ξd (Hμ1 ,μ2) (dB)
J (Hμ1 ,μ2) (dB)
  (Hμ1 ,μ2) (dB)
(c)
(d)
Figure 3.11 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise
reduction factor, and (d) the broadband desired signal reduction factor of the parametric Wiener gain
as a function of the broadband input SNR for different values of (𝜇1, 𝜇2): magnitude subtraction with
(𝜇1, 𝜇2) = (1, 1) (dashed line with asterisks), Wiener gain with (𝜇1, 𝜇2) = (2, 1) (solid line with circles),
and power subtraction with (𝜇1, 𝜇2) = (2, 1∕2) (dotted line with squares).
One reasonable way to ﬁnd this gain is via the MSE criterion given by
JX
[HX( f )] = E
[|||
̂X( f ) −X( f )|||
]
.
(.)
The minimization of the last expression leads to the conventional Wiener gain given in
(.), which we now denote by HX,W( f ). Therefore, the optimal estimate (in the MMSE
sense) of X( f ) and the MMSE are, respectively,
̂XW( f ) = HX,W( f )Y( f )
(.)
and
JX
[
HX,W( f )
]
= 𝜙X( f ) −𝜙̂XW( f ),
(.)

Single-Channel Signal Enhancement in the Frequency Domain
87
where
𝜙̂XW( f ) =
𝜙
X( f )
𝜙Y( f )
(.)
is the variance of ̂XW( f ).
Alternatively, we can also estimate the noise signal, V( f ), by applying a gain, HV( f ),
to the observation, Y( f ):
̂V( f ) = Y( f )HV( f ).
(.)
By using the MSE criterion:
JV
[
HV( f )
]
= E
[|||
̂V( f ) −V( f )|||
]
,
(.)
we easily ﬁnd that the optimal gain and estimator are, respectively,
HV,W( f ) = 𝜙V( f )
𝜙Y( f )
(.)
=

+ iSNR( f )
and
̂VW( f ) = HV,W( f )Y( f ).
(.)
We also ﬁnd that the MMSE is
JV
[HV,W( f )] = 𝜙V( f ) −𝜙̂VW( f ),
(.)
where
𝜙̂VW( f ) =
𝜙
V( f )
𝜙Y( f )
(.)
is the variance of ̂VW( f ). Now that we have the optimal estimate of V( f ), we can estimate
X( f ) as follows:
̂XW,( f ) = Y( f ) −̂VW( f )
(.)
= ̂XW( f ).
Obviously, the two methods are strictly equivalent here. It is easy to show that
JX
[HX,W( f )] = JV
[HV,W( f )]
(.)
= E
[
̂XW( f )̂V ∗
W( f )
]
= 𝜙X( f )𝜙V( f )
𝜙Y( f )
,
www.ebook3000.com

88
Fundamentals of Signal Enhancement and Array Signal Processing
which is the conditional variance of X( f ) given Y( f ) or the conditional variance of V( f )
given Y( f ). Also, it is interesting to observe that the sum of the estimated desired and
noise signals is equal to the observation; that is,
̂XW( f ) + ̂VW( f ) = Y( f ),
(.)
which is equivalent to
HX,W( f ) + HV,W( f ) = ,
(.)
assuming that Y( f ) ≠. Then we can state that the Wiener gains are derived in such a
way that (.) is veriﬁed. However, the sum of the variances of the estimated desired
and noise signals is not equal to the variance of the observation:
𝜙̂XW( f ) + 𝜙̂VW( f ) =
𝜙
X( f ) + 𝜙
V( f )
𝜙Y( f )
(.)
≥𝜙Y( f ).
This is due to the fact that ̂XW( f ) and ̂VW( f ) are correlated, as shown in (.). At
ﬁrst glance, this may come as a surprise to some readers since X( f ) and V( f ) are
uncorrelated but this result actually makes sense.
Let us deﬁne the MSE criterion:
J [HX( f ), HV( f )] = JX
[HX( f )] + JV
[HV( f )]
(.)
= E
[
||HX( f )Y( f ) −X( f )||
]
+ E
[
||HV( f )Y( f ) −V( f )||
]
.
The minimization of J [HX( f ), HV( f )] without any constraint or with the constraint that
̂X( f ) + ̂V( f ) = Y( f ) – in other words that HX( f ) + HV( f ) = – leads to HX,W( f )
and HV,W( f ). Another interesting possibility is to minimize J
[
HX( f ), HV( f )
]
with the
constraint that the sum of the variances of the estimated desired and noise signals is
equal to the variance of the observation:
𝜙̂X( f ) + 𝜙̂V( f ) = 𝜙Y( f )
(.)
or, equivalently,
||HX( f )||
+ ||HV( f )||
= .
(.)
By using the Lagrange multiplier technique, we easily ﬁnd that the constraint Wiener
gains for the estimation of the desired and noise signals are, respectively,
HX,cW( f ) =
𝜙X( f )
√
𝜙
X( f ) + 𝜙
V( f )
(.)
=
√
iSNR( f )
+ iSNR( f )

Single-Channel Signal Enhancement in the Frequency Domain
89
and
HV,cW( f ) =
𝜙V( f )
√
𝜙
X( f ) + 𝜙
V( f )
(.)
=
√

+ iSNR( f )
.
Then, we deduce two diﬀerent estimators for X( f ):
̂XcW( f ) = HX,cW( f )Y( f )
(.)
and
̂XcW,( f ) = Y( f ) −̂VcW( f )
(.)
= Y( f ) −HV,cW( f )Y( f )
= HX,cW,( f )Y( f ),
where
̂VcW( f ) = HV,cW( f )Y( f )
(.)
and
HX,cW,( f ) = −HV,cW( f ).
(.)
Now, contrary to the conventional Wiener approach, ̂XcW( f ) ≠̂XcW,( f ). It can be
veriﬁed that
E
[
̂XcW( f )̂V ∗
cW( f )
]
≥E
[
̂XW( f )̂V ∗
W( f )
]
(.)
and
HX,cW,( f ) ≤HX,W( f ) ≤HX,cW( f ).
(.)
As a consequence, we can state that ̂XcW( f ) [resp. ̂XcW,( f )] is more (resp. less) noisy
but less (resp. more) distorted than ̂XW( f ) = ̂XW,( f ).
Figure .shows plots of the constraint gains, HX,cW( f ) and HX,cW,( f ), the narrow-
band noise reduction factor, and the narrowband desired signal distortion index as a
function of the narrowband input SNR. The plots for the Wiener gain, HX,W( f ), are also
included as a reference. For a given input SNR, the Wiener gain is larger than HX,cW,( f )
and smaller than HX,cW( f ). Hence, HX,cW,( f ) is associated with higher noise reduction
and desired signal distortion than the Wiener gain, while HX,cW( f ) is associated with
less noise reduction and desired signal distortion than the Wiener gain.
www.ebook3000.com

90
Fundamentals of Signal Enhancement and Array Signal Processing
−10
−5
0
5
10
15
20
0
0.2
0.4
0.6
0.8
1
−10
−5
0
5
10
15
20
0
5
10
15
20
25
30
−10
−5
0
5
10
15
20
−50
−40
−30
−20
−10
0
iSNR( f) (dB)
iSNR( f) (dB)
iSNR( f) (dB)
(a)
(b)
(c)
H (f )
ξn [H ( f )] (dB)
υd [H (f )] (dB)
Figure 3.12 (a) The gain, (b) the narrowband noise reduction factor, and (c) the narrowband desired
signal distortion index as a function of the narrowband input SNR for different optimal gains: HX,cW,2( f)
(dashed line with asterisks), HX,W( f) (solid line with circles), and HX,cW( f) (dotted line with squares).
Example ..
Returning to Example .., Figure .shows plots of the broadband
gain in SNR, (H), the broadband MSE, J (H), the broadband noise reduction factor,
𝜉n (H), and the broadband desired signal reduction factor, 𝜉d (H), as a function of the
broadband input SNR for diﬀerent optimal gains: HX,cW,( f ), HX,W( f ), and HX,cW( f ).
Figure .shows similar plots for the signals in Example ...
For a given broadband input SNR, HX,cW,( f ) is associated with higher broadband
SNR gain and noise reduction than HX,cW( f ), but at the expense of higher broadband
desired signal reduction.
■
In Table ., we summarize all the optimal gains studied in this section and the
previous one.
3.6
Implementation with the Short-time Fourier Transform
In this section, we show how to implement the diﬀerent gains in the short-time Fourier
transform (STFT) domain.

Single-Channel Signal Enhancement in the Frequency Domain
91
1.3
1.4
1.5
1.6
1.7
1.8
1.9
2
−25
−20
−15
−10
−5
−5
0
5
10
15
0
5
10
15
20
25
0
5
10
15
20
25
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
(a)
(b)
(c)
(d)
J (H ) (dB)
ξn (H) (dB)
ξd (H) (dB)
  (H) (dB)
Figure 3.13 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise
reduction factor, and (d) the broadband desired signal reduction factor as a function of the
broadband input SNR for different optimal gains: HX,cW,2( f) (dashed line with asterisks), HX,W( f)
(solid line with circles), and HX,cW( f) (dotted line with squares).
The signal model given in (.) can be put into a vector form by considering the L most
recent successive time samples:
𝐲(t) = 𝐱(t) + 𝐯(t),
(.)
where
𝐲(t) =
[ y(t)
y(t −)
⋯
y(t −L + ) ]T
(.)
is a vector of length L, and 𝐱(t) and 𝐯(t) are deﬁned in a similar way to 𝐲(t) from (.).
A short-time segment of the measured signal – that is, 𝐲(t) – is multiplied with an
analysis window of length L:
𝐠= [ g()
g()
⋯
g(L −) ]T
(.)
www.ebook3000.com

92
Fundamentals of Signal Enhancement and Array Signal Processing
6
8
10
12
14
16
18
20
22
−4
−2
0
2
4
6
8
−5
0
5
10
15
6
8
10
12
14
16
18
20
22
−5
0
5
10
15
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
iSNR (dB)
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
(a)
(b)
(c)
(d)
J (H) (dB)
ξn (H) (dB)
ξd (H) (dB)
  (H) (dB)
Figure 3.14 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise
reduction factor, and (d) the broadband desired signal reduction factor as a function of the
broadband input SNR for different optimal gains: HX,cW,2( f) (dashed line with asterisks), HX,W( f)
(solid line with circles), and HX,cW( f) (dotted line with squares).
and transformed into the frequency domain by using the discrete Fourier transform
(DFT). Let 𝐖denote the DFT matrix of size L × L, with
[𝐖]i,j = exp
(
−𝚥𝜋ij
L
)
, i, j = , … , L −.
(.)
Then, the STFT representation of the measured signal is deﬁned as []:
𝐘(t) = 𝐖diag (𝐠) 𝐲(t),
(.)
where
𝐘(t) = [ Y(t, )
Y(t, )
⋯
Y(t, L −) ]T .
(.)
In practice, the STFT representation is decimated in time by a factor R (≤R ≤L) []:
𝐘(rR) = 𝐘(t) ||t=rR
(.)
= [ Y(rR, )
Y(rR, )
⋯
Y(rR, L −) ]T , r ∈Z.

Single-Channel Signal Enhancement in the Frequency Domain
93
Table 3.1 Optimal gains for single-channel signal enhancement in the
frequency domain.
Gain
Wiener
HW( f ) =
iSNR( f )
+ iSNR( f )
Tradeoﬀ
HT,𝜇( f ) =
iSNR( f )
𝜇+ iSNR( f ), 𝜇≥
Parametric Wiener
H𝜇,𝜇( f ) = [−sin𝜇𝜃( f )]𝜇, 𝜇, 𝜇≥
Constraint Wiener
HX,cW( f ) =
√
iSNR( f )
+ iSNR( f )
HX,cW,( f ) = −
√

+ iSNR( f )
+
v(t)
diag (g)
W
↓R
x(t)
y(t)
Y (t)
Y (rR)
Figure 3.15 STFT representation of the measured signal.
Figure .shows the STFT representation of the measured signal. Therefore, in the
STFT domain, (.) can be written as
Y(rR, k) = X(rR, k) + V(rR, k),
(.)
where k = , … , L −denotes the frequency index, and X(rR, k) and V(rR, k) are the
STFT representations of x(t) and v(t), respectively. Since the zero-mean signals X(rR, k)
and V(rR, k) are assumed to be uncorrelated, the variance of Y(rR, k) is
𝜙Y(rR, k) = E
[
|Y(rR, k)|]
(.)
= 𝜙X(rR, k) + 𝜙V(rR, k),
where 𝜙X(rR, k) = E
[
|X(rR, k)|]
and 𝜙V(rR, k) = E
[
|V(rR, k)|]
are the variances of
X(rR, k) and V(rR, k), respectively.
An estimate of X(rR, k) can be obtained by multiplying Y(rR, k) with a gain H(rR, k),
as illustrated in Figure .:
Z(rR, k) = H(rR, k)Y(rR, k)
(.)
= H(rR, k) [X(rR, k) + V(rR, k)]
= Xfd(rR, k) + Vrn(rR, k),
www.ebook3000.com

94
Fundamentals of Signal Enhancement and Array Signal Processing
+
V(rR, k)
H(rR, k)
Y (rR, k)
X (rR, k)
Z (rR, k)
Figure 3.16 Block diagram of noise reduction in the STFT domain.
where Z(rR, k) is the STFT representation of the signal z(t),
Xfd(rR, k) = H(rR, k)X(rR, k)
(.)
is the ﬁltered desired signal, and
Vrn(rR, k) = H(rR, k)V(rR, k)
(.)
is the residual noise.
A short-time segment of z(t) can be reconstructed in the time domain by applying the
inverse DFT to the vector:
𝐙(rR) = [ Z(rR, )
Z(rR, )
⋯
Z(rR, L −) ]T
(.)
and multiplying the result with a synthesis window of length L:
̃𝐠= [ ̃g()
̃g()
⋯
̃g(L −) ]T .
(.)
That is,
𝐳(rR) = diag (̃𝐠) 𝐖H𝐙(rR),
(.)
where the superscript H denotes conjugate-transpose of a vector or a matrix. The
estimate z(t) of the desired signal can be reconstructed in the time domain by the
overlap-add method []; in other words, summing the values at time t of all the short-
time segments that overlap at time t:
z(t) =
∑
r
𝐢T
rR−t+𝐳(rR),
(.)
where 𝐢i (≤i ≤L) is the ith column of 𝐈L and the summation is over integer values of
r in the range t
R ≤r ≤t+L−
R
. The inverse STFT is illustrated in Figure ..
The synthesis window ̃𝐠must satisfy a condition for exact reconstruction of x(t) when
H(rR, k) = and V(rR, k) = for all (r, k) []. Speciﬁcally, from (.) we have
𝐗(rR) = 𝐖diag(𝐠) 𝐱(rR).
(.)
For exact reconstruction of z(t) = x(t) using (.) and (.), we require
x(t) =
∑
r
𝐢T
rR−t+diag (̃𝐠) 𝐖H𝐗(rR).
(.)

Single-Channel Signal Enhancement in the Frequency Domain
95
WH
diag (g)
Overlap-add
Z(rR)
z (rR)
z(t)
Figure 3.17 Block diagram of the inverse STFT.
Substituting (.) into (.), we get
x(t) =
∑
r
𝐢T
rR−t+diag (̃𝐠) diag (𝐠) 𝐱(rR),
(.)
for all signals x(t) and for all t. Therefore, the condition for exact reconstruction is
∑
r
̃g(𝓁+ rR)g(𝓁+ rR) = , ∀𝓁∈{, … , R −}.
(.)
Property ..
For a given analysis window 𝐠of length L > R, there are inﬁnite
solutions ̃𝐠that satisfy (.). A synthesis window of a minimal norm that satisﬁes
(.) is given by []
̃g(𝓁) =
g(𝓁)
∑
r g(𝓁+ rR), 𝓁= , … , L −.
(.)
Proof. Deﬁne
𝐠𝓁=
[ ⋯
g(𝓁−R)
g(𝓁)
g(𝓁+ R)
⋯]T ,
̃𝐠𝓁= [ ⋯
̃g(𝓁−R)
̃g(𝓁)
̃g(𝓁+ R)
⋯]T .
Then condition (.) can be written as
𝐠T
𝓁̃𝐠𝓁= , ∀𝓁∈{, … , R −}.
(.)
The minimum-norm solution to this equation is the pseudo inverse of 𝐠𝓁:
̃𝐠𝓁= 𝐠𝓁
(
𝐠T
𝓁𝐠𝓁
)−,
(.)
which is equivalent to (.).
■
In a similar way to the frequency-domain input SNR, we deﬁne the narrowband input
SNR as
iSNR(rR, k) = 𝜙X(rR, k)
𝜙V(rR, k).
(.)
The optimal gains, summarized in Table ., are employed in the STFT domain by
replacing iSNR( f ) with iSNR(rR, k).
www.ebook3000.com

96
Fundamentals of Signal Enhancement and Array Signal Processing
The broadband input SNR is obtained by summing over all time-frequency indices
the numerator and denominator of iSNR(rR, k). We get
iSNR =
∑
r,k 𝜙X(rR, k)
∑
r,k 𝜙V(rR, k).
(.)
Similarly, the broadband output SNR is
oSNR (H) =
∑
r,k 𝜙Xfd(rR, k)
∑
r,k 𝜙Vrn(rR, k)
(.)
=
∑
r,k |H(rR, k)|𝜙X(rR, k)
∑
r,k |H(rR, k)|𝜙V(rR, k)
,
the broadband noise reduction and desired signal reduction factors are, respectively,
𝜉n (H) =
∑
r,k 𝜙V(rR, k)
∑
r,k |H(rR, k)|𝜙V(rR, k)
(.)
and
𝜉d (H) =
∑
r,k 𝜙X(rR, k)
∑
r,k |H(rR, k)|𝜙X(rR, k)
,
(.)
and the broadband MSE is deﬁned as
J (H) =
∑
r,k
J [H(rR, k)]
(.)
=
∑
r,k
|−H(rR, k)|𝜙X(rR, k) +
∑
r,k
|H(rR, k)|𝜙V(rR, k).
Example ..
Consider a speech signal, x(t), sampled at kHz, that is corrupted
with uncorrelated additive white Gaussian noise, v(t) ∼(, 𝜎
v
). The observed signal,
y(t), given by y(t) = x(t) + v(t), is transformed into the STFT domain, multiplied at
each time-frequency bin by a spectral gain H(rR, k), and transformed back into the time
domain using (.) and (.).
To demonstrate noise reduction in the STFT domain, we choose a Hamming window
of length L = as the analysis window, a decimation factor R = L∕= , and the
Wiener gain in the STFT domain:
HW(rR, k) =
iSNR(rR, k)
+ iSNR(rR, k).
(.)
An estimate for the noise variance ̂𝜙V(rR, k) can be simply obtained by averaging past
spectral power values of the noisy measurement during speech inactivity:
̂𝜙V(rR, k) =
{ 𝛼̂𝜙V
[(r −)R, k] + (−𝛼) |Y(rR, k)|, X(rR, k) = 
̂𝜙V
[(r −)R, k] , X(rR, k) ≠
,
(.)

Single-Channel Signal Enhancement in the Frequency Domain
97
0
2
4
6
8
0
0.5
1
1.5
2
Time (s)
Amplitude    Frequency (kHz)
Figure 3.18 Speech spectrogram and waveform of a clean speech signal, x(t): “This is particularly true
in site selection.”
4
6
8
10
12
14
16
18
−5
0
5
10
15
iSNR (dB)
(a)
(b)
(c)
(d)
−45
−40
−35
−30
−25
−20
−5
0
5
10
15
iSNR (dB)
J (HW) (dB)
5
10
15
20
−5
0
5
10
15
iSNR (dB)
ξn (HW) (dB)
0
0.5
1
1.5
2
2.5
−5
0
5
10
15
iSNR (dB)
ξd (HW) (dB)
  (HW) (dB)
Figure 3.19 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise reduction
factor, and (d) the broadband desired signal reduction factor of the Wiener gain as a function of the
broadband input SNR for different oversubtraction factors 𝛽: 𝛽= 1 (solid line with circles), 𝛽= 2
(dashed line with asterisks), 𝛽= 3 (dotted line with squares), and 𝛽= 4 (dash-dot line with triangles).
www.ebook3000.com

98
Fundamentals of Signal Enhancement and Array Signal Processing
where 𝛼(< 𝛼< ) denotes a smoothing parameter. This method requires a voice
activity detector, but there are alternative and more eﬃcient methods that are based on
minimum statistics [, ].
Finding an estimate for 𝜙X(rR, k) is a much more challenging problem [, ]. In
this example, for simplicity, we smooth |Y(rR, k)|in both time and frequency axes and
subtract an estimate of the noise that is multiplied by an oversubtraction factor 𝛽(𝛽≥):
̂𝜙X(rR, k) = max
{
̂𝜙Y(rR, k) −𝛽̂𝜙V(rR, k), 
}
,
(.)
where ̂𝜙Y(rR, k) is obtained as a two-dimensional convolution between |Y(rR, k)|
and a smoothing window w(rR, k). Here, the smoothing window is a two-dimensional
Hamming window of size × , normalized to ∑
r,k w(rR, k) = .
Figure .shows the spectrogram (magnitude of the STFT representation) and
waveform of the clean speech signal, x(t). Figure .shows plots of the broadband
gain in SNR, the broadband MSE, J (HW
), the broadband noise reduction factor,
𝜉n
(HW
), and the broadband desired signal reduction factor, 𝜉d
(HW
), as a function of
the broadband input SNR for diﬀerent values of the oversubtraction factor 𝛽. Figure .
shows a realization of the noise corrupted and ﬁltered speech signals for diﬀerent values
0
2
4
6
8
0
0.5
1
1.5
2
0
2
4
6
8
Time (s)
0
0.5
1
1.5
2
Time (s)
0
0.5
1
1.5
2
Time (s)
0
0.5
1
1.5
2
Time (s)
(a)
(c)
Amplitude
Frequency (kHz)
Amplitude
Frequency (kHz)
0
2
4
6
8
0
2
4
6
8
(b)
(d)
Amplitude
Frequency (kHz)
Amplitude
Frequency (kHz)
Figure 3.20 Speech spectrograms and waveforms of (a) noisy speech signal, y(t), (b) filtered signal,
z(t), using an oversubtraction factor, 𝛽= 1, (c) filtered signal, z(t), using an oversubtraction factor,
𝛽= 2, and (d) filtered signal, z(t), using an oversubtraction factor, 𝛽= 3.

Single-Channel Signal Enhancement in the Frequency Domain
99
of 𝛽. For larger values of 𝛽, there is less residual musical noise, but at the expense of larger
distortion of weak speech components.
Note that more useful algorithms for enhancing noisy speech signals in the STFT
domain are presented in [, , ].
■
Problems
3.1 Show that the narrowband MSE is given by
J [H( f )] = |−H( f )|𝜙X( f ) + |H( f )|𝜙V( f ).
3.2 Show that the narrowband MSE is related to the diﬀerent narrowband perfor-
mance measures by
J [H( f )] = 𝜙V( f )
{
iSNR( f ) × 𝜐d
[H( f )] +

𝜉n
[
H( f )
]
}
.
3.3 Show that the narrowband MSEs Jd
[
H( f )
]
and Jn
[
H( f )
]
are related to the
diﬀerent narrowband performance measures by
Jd
[H( f )]
Jn
[H( f )] = iSNR( f ) × 𝜉n
[
H( f )
]
× 𝜐d
[
H( f )
]
= oSNR
[
H( f )
]
× 𝜉d
[
H( f )
]
× 𝜐d
[
H( f )
]
.
3.4 Show that the Wiener gain is is given by
HW( f ) =
iSNR( f )
+ iSNR( f ).
3.5 Show that the Wiener gain is equal to the MSCF between X( f ) and Y( f ); in other
words:
HW( f ) = |||𝜌[X( f ), Y( f )]|||

.
3.6 Show that the MMSE can be expressed as
J
[
HW( f )
]
=
[
−HW( f )
]
𝜙X( f ).
3.7 Show that with the Wiener gain, the broadband output SNR is always greater than
or equal to the broadband input SNR: oSNR (HW
) ≥iSNR.
www.ebook3000.com

100
Fundamentals of Signal Enhancement and Array Signal Processing
3.8 Consider a desired signal, X( f ), with the variance:
𝜙X( f ) =
⎧
⎪
⎨
⎪⎩
𝛼,
|f | ≤

,

≤|f | ≤

,
which is corrupted with additive noise, V( f ), with the variance:
𝜙V( f ) = 𝛽
(
−|f |
)
, −
≤|f | ≤
.
a) Show that the broadband input SNR is
iSNR = 𝛼
𝛽.
b) Show that the optimal Wiener gain is given by
HW( f ) =
⎧
⎪
⎨
⎪⎩
𝛼
𝛽
(
𝛼
𝛽+ −|f |
)−
,
|f | ≤

,

≤|f | ≤

.
3.9 Consider a narrowband desired signal, X( f ), with the variance:
𝜙X( f ) =
{
𝛼,
||f −f|| ≤𝛽
,
otherwise
,
where 𝛽≪fand 𝛽+ f< 
. The desired signal is corrupted with additive noise,
V( f ), with the variance:
𝜙V( f ) = N,
which is uncorrelated with X( f ).
a) Compute the broadband input SNR.
b) Show that the optimal Wiener gain is given by
HW( f ) =
{
𝛼
𝛼+ N
,
||f −f|| ≤𝛽
,
otherwise
.
c) Show that the MMSE is given by
J
[
HW( f )
]
= N𝛼𝛽
𝛼+ N
.

Single-Channel Signal Enhancement in the Frequency Domain
101
d) Show how the MMSE changes if the variance of the noise is
𝜙V( f ) =
{
N,
||f −f|| ≤𝛽
,
otherwise
.
3.10 Consider a harmonic pulse of T samples:
x(t) =
{
A sin
(
𝜋ft + 𝜙
)
,
≤t ≤T −
,
t < , t ≥T
,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly dis-
tributed on the interval from to 𝜋.
a) Show that the variance of X( f ) is
𝜙X( f ) = A
D
T
[𝜋(f + f
)] + A
D
T
[𝜋(f −f
)] .
b) Assume that x(t) is corrupted with additive white Gaussian noise v(t) ∼

(
, 𝜎
v
)
, that is uncorrelated with x(t). Using Parseval’s identity, show that
the broadband input SNR is
iSNR = A
𝜎
v
.
3.11 Show that the tradeoﬀgain, at frequency f , is equal to the MSCF between the two
signals X( f ) and X( f ) + √𝜇V( f ):
HT,𝜇( f ) = |||𝜌
[
X( f ), X( f ) +
√
𝜇V( f )
]|||

.
3.12 Show that the broadband MSCF between the two variables X( f ) and X( f ) +
√𝜇V( f ) is
|||𝜌(X, X +
√
𝜇V)|||

=
iSNR
𝜇+ iSNR.
3.13 Show that the broadband MSCF between the two variables X( f ) and HT,𝜇( f )X( f )+
√𝜇HT,𝜇( f )V( f ) satisﬁes
|||𝜌(X, HT,𝜇X +
√
𝜇HT,𝜇V)|||

≤
oSNR
(
HT,𝜇
)
𝜇+ oSNR
(
HT,𝜇
).
3.14 Show that the broadband MSCF between the two variables X( f ) and X( f ) +
√𝜇V( f ) satisﬁes
|||𝜌
(
X, X +
√
𝜇V
)|||

≤
oSNR (HT,𝜇
)
𝜇+ oSNR (HT,𝜇
).
www.ebook3000.com

102
Fundamentals of Signal Enhancement and Array Signal Processing
3.15 Show that with the tradeoﬀgain, the broadband output SNR is always greater than
or equal to the broadband input SNR: oSNR (HT,𝜇
) ≥iSNR, ∀𝜇≥.
3.16 Prove that the diﬀerent performance measures obtained with the Wiener gain and
the power subtraction and magnitude subtraction methods are related by
𝜉n
[Hmag( f )] ≥𝜉n
[HW( f )] ≥𝜉n
[Hpow( f )] ,
𝜐d
[Hpow( f )] ≤𝜐d
[HW( f )] ≤𝜐d
[Hmag( f )] .
3.17 Prove that the MMSE obtained with HX,W( f ) is the same as that obtained with
HV,W( f ):
JX
[HX,W( f )] = JV
[HV,W( f )] .
3.18 Show that ̂XW( f ) + ̂VW( f ) = Y( f ), but 𝜙̂XW( f ) + 𝜙̂VW( f ) ≥𝜙Y( f ). Explain this
result.
3.19 Show that minimization of J [HX( f ), HV( f )] with the constraint that 𝜙̂X( f ) +
𝜙̂V( f ) = 𝜙Y( f ) yields
HX,cW( f ) =
√
iSNR( f )
+ iSNR( f )
.
3.20 Show that ̂XcW( f ) is more noisy but less distorted than ̂XW( f ), and that ̂XcW,( f )
is less noisy but more distorted than ̂XW( f ):
HX,cW,( f ) ≤HX,W( f ) ≤HX,cW( f ).
3.21 Let 𝐠and ̃𝐠be, respectively, analysis and synthesis windows of the STFT. Show
that the condition for exact reconstruction with the inverse STFT is
∑
r
̃g(𝓁+ rR)g(𝓁+ rR) = , ∀𝓁∈{, … , R −}.
3.22 Show that for a given analysis window 𝐠of length L > R, the synthesis window of
a minimal norm that satisﬁes the condition of exact reconstruction is given by
̃g(𝓁) =
g(𝓁)
∑
r g(𝓁+ rR), 𝓁= , … , L −.
References
1 J. Benesty, J. Chen, Y. Huang, and I. Cohen, Noise Reduction in Speech Processing.
Berlin, Germany: Springer-Verlag, .

Single-Channel Signal Enhancement in the Frequency Domain
103
2 W. Etter and G. S. Moschytz, “Noise reduction by noise-adaptive spectral magnitude
expansion,” J. Audio Eng. Soc., vol. , pp. –, May .
3 J. S. Lim and A. V. Oppenheim, “Enhancement and bandwidth compression of noisy
speech,” Proc. IEEE, vol. , pp. –, Dec. .
4 Y. Ephraim and D. Malah, “Speech enhancement using a minimum mean-square error
short-time spectral amplitude estimator,” IEEE Trans. Acoust., Speech, Signal Process.,
vol. ASSP-, pp. –, Dec. .
5 R. J. McAulay and M. L. Malpass, “Speech enhancement using a soft-decision noise
suppression ﬁlter,” IEEE Trans. Acoust., Speech, Signal Process., vol. ASSP-,
pp. –, Apr. .
6 M. M. Sondhi, C. E. Schmidt, and L. R. Rabiner, “Improving the quality of a noisy
speech signal,” Bell Syst. Techn. J., vol. , pp. –, Oct. .
7 M. Berouti, R. Schwartz, and J. Makhoul, “Enhancement of speech corrupted by
acoustic noise,” in Proc. IEEE ICASSP, , pp. –.
8 S. F. Boll, “Suppression of acoustic noise in speech using spectral subtraction,” IEEE
Trans. Acoust., Speech, Signal Process., vol. ASSP-, pp. –, Apr. .
9 M. R. Schroeder, “Apparatus for suppressing noise and distortion in communication
signals,” US Patent No. ,,, ﬁled Dec. , , issued Apr. , .
10 M. R. Schroeder, “Processing of communication signals to reduce eﬀects of noise,” US
Patent No. ,,, ﬁled May , , issued Sept. , .
11 M. R. Weiss, E. Aschkenasy, and T. W. Parsons, “Processing speech signals to attenuate
interference,” in Proc. IEEE Symposium on Speech Recognition, , pp. –.
12 E. J. Diethorn, “Subband noise reduction methods for speech enhancement,” in Audio
Signal Processing for Next-Generation Multimedia Communication Systems, Y. Huang
and J. Benesty, (eds), Boston, MA, USA: Kluwer, .
13 J. H. L. Hansen, “Speech enhancement employing adaptive boundary detection and
morphological based spectral constraints,” in Proc. IEEE ICASSP, , pp. –.
14 Y. Lu and P. C. Loizou, “A geometric approach to spectral subtraction,” Speech
Communication, vol. , pp. –, Jun. .
15 B. L. Sim, Y. C. Tong, J. S. Chang, and C. T. Tan, “A parametric formulation of the
generalized spectral subtraction method,” IEEE Trans. Speech, Audio Process., vol. ,
pp. –, Jul. .
16 J. Wexler and S. Raz, “Discrete Gabor expansions,” Speech Process., vol. , pp. –,
Nov. .
17 S. Qian and D. Chen, “Discrete Gabor transform,” IEEE Trans. Signal Process., vol. ,
pp. –, Jul. .
18 R. E. Crochiere and L. R. Rabiner, Multirate Digital Signal Processing. Englewood Cliﬀs,
NJ: Prentice-Hall, .
19 R. Martin, “Noise power spectral density estimation based on optimal smoothing and
minimum statistics,” IEEE Trans. Speech and Audio Process., vol. , pp. –, Jul.
.
20 I. Cohen, “Noise spectrum estimation in adverse environments: improved minima
controlled recursive averaging,” IEEE Trans. Speech and Audio Process., vol. ,
pp. –, Sep. .
21 I. Cohen, “Relaxed statistical model for speech enhancement and a priori SNR
estimation,” IEEE Trans. Speech and Audio Process., vol. , pp. –, Sep. .
www.ebook3000.com

104
Fundamentals of Signal Enhancement and Array Signal Processing
22 I. Cohen, “Speech spectral modeling and enhancement based on autoregressive
conditional heteroscedasticity models,” Signal Process., vol. , pp. –, Apr. .
23 I. Cohen and B. Berdugo, “Speech enhancement for non-stationary noise
environments,” Signal Process., vol. , pp. –, Nov. .
24 I. Cohen and S. Gannot, “Spectral enhancement methods,” in J. Benesty, M. M. Sondhi
and Y. Huang (eds), Springer Handbook of Speech Processing, Springer, .

105
4
Multichannel Signal Enhancement in the Time Domain
The time-domain multichannel signal enhancement problem is an important general-
ization of the single-channel case described in Chapter . The fundamental diﬀerence
is that now we take the spatial information into account thanks to the multiple sensors,
which are in diﬀerent positions in the space. Each sensor has its own perspective on
the desired and noise signals. This rich diversity can be exploited in order to derive
much better ﬁlters than those in the single-channel scenario in terms of reduction of
the additive noise and distortion of the desired signal. In other words, we have much
more ﬂexibility to compromise between noise reduction and distortion of the desired
signal thanks to the space-time processing. In this chapter, we explore two diﬀerent,
although roughly equivalent, apparent avenues and derive many useful optimal ﬁlters
for signal enhancement in a variety of contexts.
4.1
Signal Model and Problem Formulation
We consider the conventional signal model in which an array of M sensors with an
arbitrary geometry captures a convolved desired source signal in some noise ﬁeld. The
received signals, at the discrete-time index t, are expressed as [–]:
ym(t) = gm(t) ∗x(t) + vm(t)
(.)
= xm(t) + vm(t), m = , , … , M,
where gm(t) is the impulse response from location of the unknown desired source,
x(t), to the mth sensor, ∗stands for linear convolution, and vm(t) is the additive
noise at sensor m. We assume that the signals xm(t) = gm(t) ∗x(t) and vm(t) are
uncorrelated, zero mean, stationary, real, and broadband. By deﬁnition the convolved
signals, xm(t), m = , , … , M, are coherent across the array while the noise terms,
vm(t), m = , , … , M, are typically only partially coherent across the array. The signal
model given in (.) corresponds to the multichannel signal enhancement (or noise
reduction) problem.
By processing the data in blocks of L successive time samples, the signal model given
in (.) can be put into a vector form as
𝐲m(t) = 𝐱m(t) + 𝐯m(t), m = , , … , M,
(.)
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing
www.ebook3000.com

106
Fundamentals of Signal Enhancement and Array Signal Processing
where
𝐲m(t) = [ ym(t)
ym(t −)
⋯
ym(t −L + ) ]T
(.)
is a vector of length L, and 𝐱m(t) and 𝐯m(t) are deﬁned similarly to 𝐲m(t) from (.). It is
more convenient to concatenate the M vectors 𝐲m(t), m = , , … , M, together as
𝐲(t) =
[ 𝐲T
(t)
𝐲T
(t)
⋯
𝐲T
M(t) ]T
= 𝐱(t) + 𝐯(t),
(.)
where the vectors 𝐱(t) and 𝐯(t) of length ML are deﬁned in a similar way to 𝐲(t). Since
xm(t) and vm(t) are uncorrelated by assumption, the correlation matrix (of size ML×ML)
of the observations is
𝐑𝐲= E
[
𝐲(t)𝐲T(t)
]
(.)
= 𝐑𝐱+ 𝐑𝐯,
where 𝐑𝐱= E [𝐱(t)𝐱T(t)] and 𝐑𝐯= E [𝐯(t)𝐯T(t)] are the correlation matrices of 𝐱(t) and
𝐯(t), respectively. From now on, unless stated otherwise, it is assumed that rank
(
𝐑𝐱
)
=
P < ML while rank
(
𝐑𝐯
)
= ML. In other words, 𝐑𝐱is rank deﬁcient while 𝐑𝐯is full rank.
In this chapter, we consider the ﬁrst sensor as the reference, so everything will be
deﬁned with respect to this sensor. In this case, the desired signal is the whole vector
𝐱(t) of length L. Our problem then may be stated as follows: given M mixtures of two
uncorrelated signals xm(t) and vm(t), our aim is to preserve 𝐱(t) while minimizing the
contribution of the noise signal vector, 𝐯(t), at the array output. To achieve this goal,
we develop two diﬀerent approaches in the next two sections, which are fundamentally
equivalent. The two methods give diﬀerent perspectives on how things work. In the last
section, we explore the case where the noise correlation matrix does not have full rank.
4.2
Conventional Method
In this section, we develop some important optimal ﬁltering matrices for multichannel
noise reduction in the time domain. In order to unify these diﬀerent algorithms, we
propose to use the joint diagonalization technique, which seems to be a natural thing to
do to tackle this fundamental problem.
4.2.1
Joint Diagonalization
Since 𝐑𝐯has full rank, the two symmetric matrices 𝐑𝐱and 𝐑𝐯can be jointly diagonalized
as follows []:
𝐓T𝐑𝐱𝐓= 𝚲,
(.)
𝐓T𝐑𝐯𝐓= 𝐈ML,
(.)

Multichannel Signal Enhancement in the Time Domain
107
where 𝐓is a full-rank square matrix (of size ML × ML), 𝚲is a diagonal matrix the
main elements of which are real and nonnegative, and 𝐈ML is the ML × ML identity
matrix. Furthermore, 𝚲and 𝐓are the eigenvalue and eigenvector matrices, respectively,
of 𝐑−
𝐯𝐑𝐱; that is,
𝐑−
𝐯𝐑𝐱𝐓= 𝐓𝚲.
(.)
The eigenvalues of 𝐑−
𝐯𝐑𝐱can be ordered as 𝜆≥𝜆≥⋯≥𝜆P > 𝜆P+= ⋯= 𝜆ML = .
We denote by 𝐭, 𝐭, … , 𝐭ML, the corresponding eigenvectors. Therefore, the noisy signal
correlation matrix can also be diagonalized as
𝐓T𝐑𝐲𝐓= 𝚲+ 𝐈ML.
(.)
It can be veriﬁed from (.) and (.) that
𝐭T
i 𝐱(t) = , i = P + , P + , … , ML
(.)
and
𝐑−
𝐯=
ML
∑
i=
𝐭i𝐭T
i .
(.)
4.2.2
Linear Filtering
Since we want to estimate the desired signal vector, 𝐱(t), of length L, from the
observation signal vector, 𝐲(t), of length ML, a real-valued rectangular ﬁltering matrix,
𝐇, of size L × ML should be used, as follows (see Figure .):
𝐳(t) = 𝐇𝐲(t)
(.)
= 𝐱fd(t) + 𝐯rn(t),
where 𝐳(t), a vector of length L, is the estimate of 𝐱(t),
𝐱fd(t) = 𝐇𝐱(t)
(.)
is the ﬁltered desired signal, and
𝐯rn(t) = 𝐇𝐯(t)
(.)
is the residual noise. This procedure is called the multichannel signal enhancement
problem in the time domain.
We can always express 𝐇as
𝐇= 𝐀𝐓T,
(.)
where 𝐀is the transformed rectangular ﬁltering matrix, also of size L × ML. Instead
of manipulating 𝐇directly, we can, equivalently, manipulate 𝐀, since 𝐓(or 𝐓T) is a
www.ebook3000.com

108
Fundamentals of Signal Enhancement and Array Signal Processing
+
v(t)
H
x(t)
y(t)
z(t)
Figure 4.1 Block diagram of multichannel linear filtering in the time domain.
full-rank square matrix. So when 𝐀is estimated, we can easily ﬁnd 𝐇from (.). In
this section, we will mostly work with 𝐀for convenience. Consequently, we can write
(.) as
𝐳(t) = 𝐀𝐓T𝐲(t).
(.)
We deduce that the correlation matrix of 𝐳(t) is
𝐑𝐳= E [𝐳(t)𝐳T(t)]
(.)
= 𝐀
(
𝚲+ 𝐈ML
)
𝐀T
= 𝐑𝐱fd + 𝐑𝐯rn,
where
𝐑𝐱fd = 𝐀𝚲𝐀T
(.)
is the correlation matrix of the ﬁltered desired signal and
𝐑𝐯rn = 𝐀𝐀T
(.)
is the correlation matrix of the residual noise.
4.2.3
Performance Measures
In this subsection, we deﬁne some fundamental measures that ﬁt well in the multiple
sensor case and with a linear ﬁltering matrix. We recall that sensor is the reference, so
all measures are derived with respect to this sensor.
The input SNR is deﬁned as
iSNR =
tr (𝐑𝐱
)
tr (𝐑𝐯
),
(.)
where 𝐑𝐱= E [𝐱(t)𝐱T
(t)] and 𝐑𝐯= E [𝐯(t)𝐯T
(t)] are the correlation matrices of 𝐱(t)
and 𝐯(t), respectively. This deﬁnition of the input SNR is straightforwardly obtained
from the correlation matrix of 𝐲(t), which is 𝐑𝐲= 𝐑𝐱+ 𝐑𝐯.

Multichannel Signal Enhancement in the Time Domain
109
The output SNR is easily derived from (.):
oSNR
(
𝐇
)
=
tr
(
𝐑𝐱fd
)
tr (𝐑𝐯rn
)
(.)
=
tr
(
𝐀𝚲𝐀T)
tr (𝐀𝐀T)
= oSNR
(
𝐀)
.
It is clear that we always have
oSNR (𝐀) ≤𝜆,
(.)
showing how the output SNR is always upper bounded as long as 𝐑𝐯has full rank.
The noise reduction factor is given by
𝜉n
(𝐇) =
tr (𝐑𝐯
)
tr (𝐀𝐀T)
(.)
= 𝜉n
(
𝐀
)
.
For optimal ﬁltering matrices, we should have 𝜉n
(𝐀) ≥.
Since the desired signal may be distorted by the ﬁltering matrix, we deﬁne the desired
signal reduction factor as
𝜉d
(𝐇) =
tr
(
𝐑𝐱
)
tr (𝐀𝚲𝐀T)
(.)
= 𝜉d
(𝐀) .
For optimal ﬁltering matrices, we generally have 𝜉d
(
𝐀
)
≥. The closer the value of
𝜉d
(𝐀) is to , the less distorted is the desired signal.
Obviously, we have the fundamental relationship:
oSNR (𝐀)
iSNR
=
𝜉n
(𝐀)
𝜉d
(𝐀),
(.)
which, basically, states that nothing comes for free.
We can also evaluate distortion via the desired signal distortion index:
𝜐d
(𝐇) =
E
{[
𝐱fd(t) −𝐱(t)
]T [
𝐱fd(t) −𝐱(t)
]}
tr
(
𝐑𝐱
)
(.)
= 𝜐d
(𝐀) .
For optimal ﬁltering matrices, we should have 𝜐d
(𝐀) ≤.
www.ebook3000.com

110
Fundamentals of Signal Enhancement and Array Signal Processing
We deﬁne the error signal vector between the estimated and desired signals as
𝐞(t) = 𝐳(t) −𝐱(t)
(.)
= 𝐀𝐓T𝐲(t) −𝐱(t)
= 𝐞d(t) + 𝐞n(t),
where
𝐞d(t) = 𝐱fd(t) −𝐱(t)
(.)
= (𝐀𝐓T −𝐈i
) 𝐱(t)
is the desired signal distortion due to the ﬁltering matrix with
𝐈i = [ 𝐈L
𝟎L×(M−)L
]
(.)
being the identity ﬁltering matrix of size L × ML, 𝐈i𝐱(t) = 𝐱(t), and
𝐞n(t) = 𝐯rn(t)
(.)
= 𝐀𝐓T𝐯(t)
is the residual noise. We deduce that the MSE criterion is
J (𝐀) = tr {E [𝐞(t)𝐞T(t)]}
(.)
= tr
[
𝐑𝐱−𝐀𝐓T𝐑𝐱𝐈T
i + 𝐀(𝚲+ 𝐈ML
) 𝐀T]
= Jd
(
𝐀
)
+ Jn
(
𝐀
)
,
where
Jd
(
𝐀
)
= tr
{
E
[
𝐞d(t)𝐞T
d (t)
]}
(.)
= tr
(
𝐑𝐱−𝐀𝐓T𝐑𝐱𝐈T
i + 𝐀𝚲𝐀T)
= tr (𝐑𝐱
) 𝜐d
(𝐀)
and
Jn
(𝐀) = tr {E [𝐞n(t)𝐞T
n (t)]}
(.)
= tr (𝐀𝐀T)
=
tr (𝐑𝐯
)
𝜉n
(𝐀) .

Multichannel Signal Enhancement in the Time Domain
111
As a result, we have
Jd
(
𝐀
)
Jn
(
𝐀
) = iSNR × 𝜉n
(𝐀) × 𝜐d
(𝐀)
(.)
= oSNR (𝐀) × 𝜉d
(𝐀) × 𝜐d
(𝐀) ,
showing how the diﬀerent performance measures are related to the MSEs.
4.2.4
Optimal Filtering Matrices
From the diﬀerent MSEs, we now show how to derive diﬀerent optimal ﬁltering matrices
for multichannel signal enhancement and how to compromise between noise reduction
and desired signal distortion in a very ﬂexible way.
The Wiener ﬁltering matrix is derived from the minimization of the MSE criterion,
J (𝐀
). From this optimization, we obtain
𝐀W = 𝐈i𝐑𝐱𝐓(𝚲+ 𝐈ML
)−
(.)
= 𝐈i𝐓−T𝚲
(
𝚲+ 𝐈ML
)−.
We deduce that the Wiener ﬁltering matrix is
𝐇W = 𝐀W𝐓T
(.)
= 𝐈i𝐑𝐱
ML
∑
i=
𝐭i𝐭T
i
+ 𝜆i
= 𝐈i𝐑𝐯
ML
∑
i=
𝜆i
+ 𝜆i
𝐭i𝐭T
i .
Obviously, we can also express 𝐇W as
𝐇W = 𝐈i𝐑𝐱𝐑−
𝐲.
(.)
Property ..
With the optimal Wiener ﬁltering matrix given in (.), the output
SNR is always greater than or equal to the input SNR: oSNR (𝐇W
) ≥iSNR.
Example ..
Consider an array of M sensors located on a line with a uniform
spacing d, as shown in Figure .. Such an array is known as a uniform linear array
(ULA). Suppose that a desired signal impinges on the ULA from the broadside direction
(𝜃= ◦), and that an interference impinges on the ULA from the endﬁre direction
(𝜃= ◦). Assume that the desired signal is a harmonic random process:
x(t) = A cos (𝜋ft + 𝜙) ,
www.ebook3000.com

112
Fundamentals of Signal Enhancement and Array Signal Processing
x(t)
θ
d
y1(t)
y2(t)
yM(t)
M
2
1
(M−1) d cos θ
Plane
wavefront
1(t)
M(t)
Figure 4.2 Illustration of a uniform linear array for signal capture in the farfield.
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly distributed
on the interval from to 𝜋. Assume that the interference u(t) is white Gaussian noise,
u(t) ∼(, 𝜎
u
), which is uncorrelated with x(t). In addition, the sensors contain
thermal white Gaussian noise, wm(t) ∼(, 𝜎
w
), the signals of which are mutually
uncorrelated. The desired signal needs to be recovered from the noisy received signals,
ym(t) = xm(t) + vm(t), m = , … , M, where vm(t) = um(t) + wm(t), m = , … , M are the
interference-plus-noise signals.
Since the desired source is in the broadside direction and the interference source is in
the endﬁre direction, we have for i = , … , M:
xi(t) = x(t),
(.)
ui(t) = u
(t −𝜏i
) ,
(.)
where
𝜏i = (i −)d
cTs
(.)
is the relative time delay in samples between the ith sensor and the ﬁrst sensor for
an endﬁre source, c is the speed of wave propagation, and Ts is the sampling interval.
Assuming that the sampling interval satisﬁes Ts = d
c , then the delay 𝜏i = i −becomes
an integer and, therefore, (.) and (.) can be written as
[𝐱(t)]
l+(m−)L = [𝐱(t)]
l ,
(.)
[𝐮(t)]
l+(m−)L = [𝐮(t)]
l+m−,
(.)
for l = , … , L, m = , … , M, and l + m −≤L. Hence, the correlation matrix of 𝐱(t) is
𝐑𝐱= 𝟏M ⊗𝐑𝐱,

Multichannel Signal Enhancement in the Time Domain
113
10
20
30
40
50
60
0
10
20
30
40
50
10
20
30
40
50
60
−50
−40
−30
−20
−10
0
L
L
(a)
(b)
(HW) (dB) 
J (HW)/L (dB) 
Figure 4.3 (a) The gain in SNR and (b) the MMSE per sample of the Wiener filtering matrix as a
function of the filter length, L, for different numbers of sensors, M: M = 1 (circles), M = 2 (asterisks),
M = 5 (squares), and M = 10 (triangles).
where ⊗is the Kronecker product, 𝟏M is an M×M matrix of all ones, and the elements of
the correlation matrix of 𝐱(t) are [𝐑𝐱
]
i,j = 
Acos [𝜋f(i −j)]. The correlation matrix
of 𝐯(t) is 𝐑𝐯= 𝐑𝐮+ 𝜎
w𝐈LM, where the elements of the LM × LM matrix 𝐑𝐮are
[
𝐑𝐮
]
i+(m−)L,j+(m−)L = 𝜎
u 𝛿(i + m−j −m
) ,
i, j = , … , L, m, m= , … , M.
The input SNR is
iSNR = log
A∕
𝜎
u + 𝜎
w
(dB).
The optimal ﬁlter 𝐇W is obtained from (.).
To demonstrate the performance of the Wiener ﬁltering matrix, we choose A = .,
f= ., 𝜎
u = ., and 𝜎
w = .𝜎
u. The input SNR is −.dB. Figure .shows
the eﬀect of the ﬁlter length, L, and the number of sensors, M, on the gain in SNR,
(𝐇W
) = oSNR (𝐇W
) ∕iSNR, and the MMSE per sample, J (𝐇W
) ∕L. As the length of
the ﬁlter increases, or as the number of sensors increases, the Wiener ﬁltering matrix
better enhances the harmonic signal, in terms of higher gain in SNR and lower MMSE
per sample. If we choose a ﬁxed ﬁlter length, L = , and change 𝜎
u so that iSNR varies
from −to dB, then Figure .shows plots of the gain in SNR, the MMSE, the noise
reduction factor, and the desired signal reduction factor, as a function of the input SNR
for diﬀerent numbers of sensors, M. For a given input SNR, as the number of sensors
increases, the gain in SNR and the noise reduction factor increase, while the MMSE and
the desired signal reduction factor decrease.
Figure .shows a realization of the noise corrupted signal received at the ﬁrst sensor,
y(t), and ﬁltered signals for iSNR = −dB and diﬀerent numbers of sensors. The
ﬁltered signal, z(t), is obtained by taking, at each t, the ﬁrst element of 𝐳(t) = 𝐇W 𝐲(t).
www.ebook3000.com

114
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
10
15
20
25
30
35
40
45
10
15
20
25
30
35
40
45
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
(a)
(c)
(HW) (dB)
ξn (HW) (dB)
−60
−50
−40
−30
−20
−10
0
0
0.5
1
1.5
2
(b)
(d)
J (HW) (dB)
ξd (HW) (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
Figure 4.4 (a) The gain in SNR, (b) the MMSE, (c) the noise reduction factor, and (d) the desired signal
reduction factor of the Wiener filtering matrix as a function of the input SNR for different numbers of
sensors, M: M = 1 (solid line with circles), M = 2 (dashed line with asterisks), M = 5 (dotted line with
squares), and M = 10 (dash-dot line with triangles).
Obviously, as the number of sensors increases, the Wiener ﬁltering matrix better
enhances the harmonic signal.
■
From the formulation given in (.), we propose a variable span (VS) Wiener ﬁltering
matrix [, ]:
𝐇W,Q = 𝐈i𝐑𝐱
Q
∑
q=
𝐭q𝐭T
q
+ 𝜆q
,
(.)
where ≤Q ≤ML. We see that 𝐇W,ML = 𝐇W and, for Q = , we obtain the maximum
SNR ﬁltering matrix with minimum MSE:
𝐇max,= 𝐈i𝐑𝐱
𝐭𝐭T

+ 𝜆
,
(.)

Multichannel Signal Enhancement in the Time Domain
115
100
200
300
400
500
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
−1
−0.5
0
0.5
1
−1
−0.5
0
0.5
1
−1
−0.5
0
0.5
1
t
100
200
300
400
500
t
100
200
300
400
500
t
100
200
300
400
500
t
(a)
(b)
(c)
(d)
Amplitude
Amplitude
Amplitude
Amplitude
Figure 4.5 Example of noise corrupted and filtered sinusoidal signals for different numbers of sensors,
M: (a) noise corrupted signal received at the first sensor, y1(t) (iSNR = −5 dB), and filtered signals for
(b) M = 1 [oSNR (𝗛W
) = 6.76 dB], (c) M = 2 [oSNR (𝗛W
) = 19.68 dB], and (d) M = 5
[oSNR (𝗛W
) = 31.09 dB].
since
oSNR
(
𝐇max,
)
= 𝜆.
(.)
Example ..
Returning to Example .., we now assume a desired signal, x(t), with
the autocorrelation sequence:
E
[
x(t)x(t′)
]
= 𝛼|t−t′|, −< 𝛼< .
The desired signal needs to be recovered from the noisy observation, 𝐲(t) = 𝐱(t) + 𝐯(t).
Since the desired source is at the broadside direction, the correlation matrix of 𝐱(t) is
𝐑𝐱= 𝟏M ⊗𝐑𝐱,
www.ebook3000.com

116
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
21.5
22
22.5
23
23.5
24
24.5
6.5
7
7.5
8
8.5
9
9.5
24
26
28
30
32
34
2
3
4
5
6
7
8
9
10
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
(a)
(b)
(c)
(d)
(HW,Q) (dB)
J (HW,Q) (dB)
ξn (HW,Q) (dB)
ξd (HW,Q) (dB)
Figure 4.6 (a) The gain in SNR, (b) the MSE, (c) the noise reduction factor, and (d) the desired signal
reduction factor of the VS Wiener filtering matrix as a function of the input SNR for several values of Q:
Q = 1 (solid line with circles), Q = 2 (dashed line with asterisks), Q = 5 (dotted line with squares), and
Q = 9 (dash-dot line with triangles).
where [𝐑𝐱
]
i,j = 𝛼|i−j|. The input SNR is
iSNR = log

𝜎
u + 𝜎
w
(dB).
The optimal ﬁlter 𝐇W,Q is obtained from (.).
To demonstrate the performance of the VS Wiener ﬁltering matrix, we choose 𝛼=
., L = , and M = . Figure .shows plots of the gain in SNR, 
(
𝐇W,Q
)
, the MSE,
J
(
𝐇W,Q
)
, the noise reduction factor, 𝜉n
(
𝐇W,Q
)
, and the desired signal reduction factor,
𝜉d
(
𝐇W,Q
)
, as a function of the input SNR for several values of Q. For a given input SNR,
the higher the value of Q, the lower are the MSE and the desired signal reduction factor,
but at the expense of lower gain in SNR and lower noise reduction factor.
■

Multichannel Signal Enhancement in the Time Domain
117
We can also try to minimize the distortion-based MSE. Taking the gradient of Jd
(𝐀)
with respect to 𝐀and equating the result to zero, we get
𝐀𝚲= 𝐈i𝐑𝐱𝐓.
(.)
Since 𝚲is not invertible, we can take its pseudo-inverse. Then, the solution to (.) is
𝐀MVDR = 𝐈i𝐑𝐱𝐓𝚲′−,
(.)
where
𝚲′−= diag (𝜆−
, 𝜆−
, … , 𝜆−
P , , … , ) .
(.)
Therefore, the MVDR ﬁltering matrix is
𝐇MVDR = 𝐀MVDR𝐓T
(.)
= 𝐈i𝐑𝐱
P
∑
p=
𝐭p𝐭T
p
𝜆p
= 𝐈i𝐑𝐯
P
∑
p=
𝐭p𝐭T
p .
Now, let us show that (.) is the MVDR ﬁltering matrix. With 𝐇MVDR, the ﬁltered
desired signal vector is
𝐱fd(t) = 𝐈i𝐑𝐯
P
∑
p=
𝐭p𝐭T
p 𝐱(t)
(.)
= 𝐈i
(
𝐈ML −𝐑𝐯
ML
∑
i=P+
𝐭i𝐭T
i
)
𝐱(t)
= 𝐱(t) −𝐈i𝐑𝐯
ML
∑
i=P+
𝐭i𝐭T
i 𝐱(t)
= 𝐱(t),
where, in the previous expression, we have used (.) and (.). Then, it is clear that
𝜐d
(
𝐇MVDR
)
= ,
(.)
proving that, indeed, 𝐇MVDR is the MVDR ﬁltering matrix.
Property ..
With the MVDR ﬁltering matrix given in (.), the output SNR is
always greater than or equal to the input SNR: oSNR (𝐇MVDR
) ≥iSNR.
www.ebook3000.com

118
Fundamentals of Signal Enhancement and Array Signal Processing
From the MVDR ﬁltering matrix, we can derive the controlled distortion (CD)
ﬁltering matrix:
𝐇CD,P′ = 𝐈i𝐑𝐱
P′
∑
p′=
𝐭p′𝐭T
p′
𝜆p′
,
(.)
where ≤P′ ≤P. We observe that 𝐇CD,P = 𝐇MVDR and, for P′ = , we obtain the
maximum SNR ﬁltering matrix with minimum distortion:
𝐇max,= 𝐈i𝐑𝐱
𝐭𝐭T

𝜆
,
(.)
since
oSNR
(
𝐇max,
)
= 𝜆.
(.)
Example ..
Returning to Example .., we now employ the CD ﬁltering matrix,
𝐇CD,P′, given in (.). Figure .shows plots of the gain in SNR, 
(
𝐇CD,P′
)
, the MSE,
J
(
𝐇CD,P′
)
, the noise reduction factor, 𝜉n
(
𝐇CD,P′
)
, and the desired signal reduction
factor, 𝜉d
(
𝐇CD,P′
)
, as a function of the input SNR for several values of P′. For a given
input SNR, the higher the value of P′, the lower are the MSE and the desired signal
reduction factor, but at the expense of lower gain in SNR and a lower noise reduction
factor.
■
Another practical approach that can give a compromise between noise reduction and
desired signal distortion is the tradeoﬀﬁltering matrix, which is obtained from:
min
𝐀Jd
(𝐀)
subject to Jn
(𝐀) = ℵtr (𝐑𝐯
) ,
(.)
where < ℵ< to ensure that ﬁltering achieves some degree of noise reduction. We
ﬁnd that the optimal ﬁltering matrix is
𝐇T,𝜇= 𝐈i𝐑𝐱
ML
∑
i=
𝐭i𝐭T
i
𝜇+ 𝜆i
,
(.)
where 𝜇≥is a Lagrange multiplier. For 𝜇= , we get the Wiener ﬁltering matrix.
Property ..
With the tradeoﬀﬁltering matrix given in (.), the output SNR is
always greater than or equal to the input SNR: oSNR
(
𝐇T,𝜇
)
≥iSNR, ∀𝜇≥.
Example ..
Returning to Example .., we now employ the tradeoﬀﬁltering
matrix, 𝐇T,𝜇, given in (.). Figure .shows plots of the gain in SNR, 
(
𝐇T,𝜇
)
,

Multichannel Signal Enhancement in the Time Domain
119
23
23.2
23.4
23.6
23.8
24
24.2
24.4
−5
0
5
10
15
7.5
8
8.5
9
9.5
26
27
28
29
30
31
32
33
34
3
4
5
6
7
8
9
10
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
(a)
(b)
(c)
(d)
J (HCD, P′) (dB)
ξd (HCD, P′) (dB)
ξn (HCD, P′) (dB)
(HCD, P′) (dB)
Figure 4.7 (a) The gain in SNR, (b) the MSE, (c) the noise reduction factor, and (d) the desired signal
reduction factor of the CD filtering matrix as a function of the input SNR for several values of P′: P′ = 1
(solid line with circles), P′ = 2 (dashed line with asterisks), P′ = 3 (dotted line with squares), and P′ = 4
(dash-dot line with triangles).
the MSE, J
(
𝐇T,𝜇
)
, the noise reduction factor, 𝜉n
(
𝐇T,𝜇
)
, and the desired signal reduc-
tion factor, 𝜉d
(
𝐇T,𝜇
)
, as a function of the input SNR for several values of 𝜇. For a given
input SNR, the higher the value of 𝜇, the higher are the gain in SNR and the noise
reduction factor, but at the expense of a higher desired signal reduction factor.
■
From what we have seen so far, we can propose a very general subspace (GS) noise
reduction ﬁltering matrix []:
𝐇𝜇,Q = 𝐈i𝐑𝐱
Q
∑
q=
𝐭q𝐭T
q
𝜇+ 𝜆q
,
(.)
where ≤Q ≤ML. This form encompasses most known optimal ﬁltering matrices.
Indeed, it is clear that
www.ebook3000.com

120
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
11
12
13
14
15
16
17
−20
−15
−10
−5
0
5
18
10
12
14
16
18
20
0.5
0
1
1.5
2
2.5
3
3.5
22
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
(a)
(b)
(d)
(c)
J (HT, μ) (dB)
ξn (HT, μ) (dB)
ξd (HT, μ) (dB)
(HT, μ) (dB)
Figure 4.8 (a) The gain in SNR, (b) the MSE, (c) the noise reduction factor, and (d) the desired signal
reduction factor of the tradeoff filtering matrix as a function of the input SNR for several values of 𝜇:
𝜇= 0.5 (solid line with circles), 𝜇= 1 (dashed line with asterisks), 𝜇= 2 (dotted line with squares), and
𝜇= 5 (dash-dot line with triangles).
●𝐇,ML = 𝐇W
●𝐇,Q = 𝐇W,Q
●𝐇,= 𝐇max,
●𝐇,P = 𝐇MVDR
●𝐇,P′ = 𝐇CD,P′
●𝐇,= 𝐇max,
●𝐇𝜇,ML = 𝐇T,𝜇.
In Table ., we present all the optimal ﬁltering matrices developed in this subsection,
showing how they are closely related.
4.3
Spectral Method
In this section, we show how to exploit the spectrum of each one of the sensors’ signals.
Thanks to this formulation, we better see the eﬀect of the spatial information, which
plays a critical role in multichannel signal enhancement when compared to the single-
channel case.

Multichannel Signal Enhancement in the Time Domain
121
Table 4.1 Optimal linear filtering matrices for multichannel signal
enhancement in the time domain.
Filter
Wiener
𝐇W = 𝐈i𝐑𝐱
ML
∑
i=
𝐭i𝐭T
i
+ 𝜆i
VS Wiener
𝐇W,Q = 𝐈i𝐑𝐱
Q
∑
q=
𝐭q𝐭T
q
+ 𝜆q
, ≤Q ≤ML
MVDR
𝐇MVDR = 𝐈i𝐑𝐱
P
∑
p=
𝐭p𝐭T
p
𝜆p
CD
𝐇CD,P′ = 𝐈i𝐑𝐱
P′
∑
p′=
𝐭p′𝐭T
p′
𝜆p′
, ≤P′ ≤P
Maximum SNR
𝐇max,𝜇= 𝐈i𝐑𝐱
𝐭𝐭T

𝜇+ 𝜆
, 𝜇≥
Tradeoﬀ
𝐇T,𝜇= 𝐈i𝐑𝐱
ML
∑
i=
𝐭i𝐭T
i
𝜇+ 𝜆i
, 𝜇≥
GS
𝐇𝜇,Q = 𝐈i𝐑𝐱
Q
∑
q=
𝐭q𝐭T
q
𝜇+ 𝜆q
, 𝜇≥, ≤Q ≤ML
4.3.1
Temporal Joint Diagonalization and Reformulation of the Problem
We recall that the temporal correlation matrix (of size L × L) of the mth sensor signal
can be written as
𝐑𝐲m = E
[
𝐲m(t)𝐲T
m(t)
]
(.)
= 𝐑𝐱m + 𝐑𝐯m,
where 𝐑𝐱m = E [𝐱m(t)𝐱T
m(t)] and 𝐑𝐯m = E [𝐯m(t)𝐯T
m(t)] are the temporal correlation
matrices of 𝐱m(t) and 𝐯m(t), respectively. The noise temporal correlation matrix, 𝐑𝐯m, is
assumed to be full rank: rank (𝐑𝐯m
) = L.
The joint diagonalization [] of the two symmetric matrices 𝐑𝐱m and 𝐑𝐯m is
𝐓T
m𝐑𝐱m𝐓m = 𝚲m,
(.)
𝐓T
m𝐑𝐯m𝐓m = 𝐈L,
(.)
where
𝐓m =
[ 𝐭m,
𝐭m,
⋯
𝐭m,L
]
(.)
is a full-rank square matrix (of size L × L),
𝚲m = diag (𝜆m,, 𝜆m,, … , 𝜆m,L
)
(.)
www.ebook3000.com

122
Fundamentals of Signal Enhancement and Array Signal Processing
is a diagonal matrix with 𝜆m,≥𝜆m,≥⋯≥𝜆m,L ≥, and 𝐈L is the L×L identity matrix.
Also, we have
𝐑−
𝐯m𝐑𝐱m𝐓m = 𝐓m𝚲m.
(.)
In other words, 𝚲m and 𝐓m are the eigenvalue and eigenvector matrices of 𝐑−
𝐯m𝐑𝐱m,
respectively. The mth noisy signal temporal correlation matrix is then diagonalized as
𝐓T
m𝐑𝐲m𝐓m = 𝚲m + 𝐈L.
(.)
By left multiplying both sides of (.) by 𝐭T
m,l, we get the lth spectral mode of the mth
sensor signal:
ym(t; l) = 𝐭T
m,l𝐲m(t)
(.)
= xm(t; l) + vm(t; l),
where xm(t; l) = 𝐭T
m,l𝐱m(t) and vm(t; l) = 𝐭T
m,l𝐯m(t) are the lth spectral modes of
the convolved desired and noise signals, respectively. We deduce that the variance of
ym(t; l) is
𝜎
ym(; l) = E [y
m(t; l)]
(.)
= 𝐭T
m,l𝐑𝐲m𝐭m,l
= 𝜆m,l + 
= 𝜎
xm(; l) + 𝜎
vm(; l),
where 𝜎
xm(; l) = 𝜆m,l and 𝜎
vm(; l) = are the variances of xm(t; l) and vm(t; l), respectively.
Now, (.) can be considered as the new signal model and, as such, the aim is to recover
the desired signal, x(t; l), given ym(t; l), m = , , … , M. When the elements x(t; l), l =
, , … , L are correctly estimated, it is easy to determine the estimate of 𝐱(t) by pre-
multiplying the vector of length L containing the estimates of x(t; l), l = , , … , L
by 𝐓−T
.
4.3.2
Spatial Joint Diagonalization
We will again the joint diagonalization, but this time on the spatial correlation matrices.
Let us deﬁne the stacked vector of length M:
𝐲(t; l) = [ y(t; l)
y(t; l)
⋯
yM(t; l) ]T
= 𝐱(t; l) + 𝐯(t; l),
(.)

Multichannel Signal Enhancement in the Time Domain
123
where 𝐱(t; l) and 𝐯(t; l) are deﬁned in a similar way to 𝐲(t; l). The vector 𝐲(t; l) is the
spatial information of the observations at the lth spectral mode. The spatial correlation
matrix (of size M × M) of 𝐲(t; l) is then
𝐑𝐲(; l) = E [𝐲(t; l)𝐲T(t; l)]
(.)
= 𝐑𝐱(; l) + 𝐑𝐯(; l),
where 𝐑𝐱(; l) = E
[
𝐱(t; l)𝐱T(t; l)
]
and 𝐑𝐯(; l) = E
[
𝐯(t; l)𝐯T(t; l)
]
are the spatial corre-
lation matrices of 𝐱(t; l) and 𝐯(t; l), respectively. Since the convolved desired signal is
coherent at the sensors, the matrix 𝐑𝐱(; l) should be rank deﬁcient. We assume that this
rank is equal to Pl ≤M. Since the noise is only partially coherent, 𝐑𝐯(; l) is full rank.
The two spatial correlation matrices 𝐑𝐱(; l) and 𝐑𝐯(; l) can also be jointly diagonalized
as
𝐒T(; l)𝐑𝐱(; l)𝐒(; l) = 𝛀(; l),
(.)
𝐒T(; l)𝐑𝐯(; l)𝐒(; l) = 𝐈M,
(.)
where
𝐒(; l) =
[ 𝐬(; l)
𝐬(; l)
⋯
𝐬M(; l) ]
= [ 𝐒′(; l)
𝐒′′(; l) ]
(.)
is a full-rank square matrix (of size M ×M), 𝐒′(; l) and 𝐒′′(; l) contain the ﬁrst Pl and last
M −Pl columns of 𝐒(; l), respectively,
𝛀(; l) = diag
[
𝜔(; l), 𝜔(; l), … , 𝜔M(; l)
]
,
(.)
with 𝜔(; l) ≥𝜔(; l) ≥⋯≥𝜔Pl(; l) > 𝜔Pl+(; l) = ⋯= 𝜔M(; l) = , and 𝐈M is the M ×M
identity matrix. Obviously, 𝛀(; l) and 𝐒(; l) are the eigenvalue and eigenvector matrices
of 𝐑−
𝐯(; l)𝐑𝐱(; l), respectively:
𝐑−
𝐯(; l)𝐑𝐱(; l)𝐒(; l) = 𝐒(; l)𝛀(; l)
(.)
and
𝐒T(; l)𝐑𝐲(; l)𝐒(; l) = 𝛀(; l) + 𝐈M.
(.)
Furthermore, it can be veriﬁed from (.) and (.) that
𝐒′′T(; l)𝐱(t; l) = 𝟎
(.)
and
𝐑−
𝐯(; l) = 𝐒′(; l)𝐒′T(; l) + 𝐒′′(; l)𝐒′′T(; l).
(.)
www.ebook3000.com

124
Fundamentals of Signal Enhancement and Array Signal Processing
4.3.3
Spatial Linear Filtering
The conventional way to perform multichannel noise reduction is to apply a ﬁlter to the
spatial observation signal vector, as illustrated in Figure .:
z(t; l) = 𝐡T(; l)𝐲(t; l)
(.)
= 𝐡T(; l)
[
𝐱(t; l) + 𝐯(t; l)
]
= xfd(t; l) + vrn(t; l),
where z(t; l) is the estimate of x(t; l),
𝐡(; l) = [ h(; l)
h(; l)
⋯
hM(; l) ]T
(.)
is a spatial linear ﬁlter of length M at the lth spectral mode, xfd(t; l) = 𝐡T(; l)𝐱(t; l) is the
ﬁltered desired signal, and vrn(t; l) = 𝐡T(; l)𝐯(t; l) is the residual noise. We deduce that
the variance of z(t; l) is
𝜎
z (; l) = E [z(t; l)]
(.)
= 𝐡T(; l)𝐑𝐲(; l)𝐡(; l)
= 𝜎
xfd(; l) + 𝜎
vrn(; l),
where
𝜎
xfd(; l) = 𝐡T(; l)𝐑𝐱(; l)𝐡(; l)
(.)
and
𝜎
vrn(; l) = 𝐡T(; l)𝐑𝐯(; l)𝐡(; l)
(.)
are the variances of xfd(t; l) and vrn(t; l), respectively.
+
v1(t)
tT
1,l
+
vM(t)
tT
M,l
vector stack
hT(;l)
x1(t)
xM(t)
z(t;l)
y1(t)
yM(t)
y1(t; l)
yM(t; l)
y(t;l)
Figure 4.9 Block diagram of multichannel spatial linear filtering.

Multichannel Signal Enhancement in the Time Domain
125
4.3.4
Performance Measures
Performance measures are an important area of the signal enhancement problem.
Without them, there is no way to know how a ﬁlter really performs. In this section,
we explain the most intuitive ones, as we did in Section ... We start by deriving
measures related to the noise reduction. Then we discuss the evaluation of the desired
signal distortion. Finally, we present the MSE criterion, which is very convenient to use
in signal enhancement applications.
4.3.4.1
Noise Reduction
Since the ﬁrst sensor is the reference, we deﬁne the lth spectral mode input SNR as
iSNR(; l) =
𝜎
x(; l)
𝜎
v(; l)
(.)
= 𝜆,l.
We deduce that the fullmode input SNR is
iSNR(; ) =
∑L
l=𝜎
x(; l)
∑L
l=𝜎
v(; l)
(.)
=
tr (𝚲
)
L
=
tr
(
𝐑−
𝐯𝐑𝐱
)
L
.
It is clear that
iSNR(; L) ≤iSNR(; ) ≤iSNR(; ).
(.)
In other words, the fullmode input SNR can never exceed the maximum spectral mode
input SNR and can never go below the minimum spectral mode input SNR.
From (.), we deﬁne the lth spectral mode output SNR:
oSNR [𝐡(; l)] = 𝐡T(; l)𝐑𝐱(; l)𝐡(; l)
𝐡T(; l)𝐑𝐯(; l)𝐡(; l)
(.)
and it can be veriﬁed that it is upper bounded:
oSNR
[
𝐡(; l)
]
≤𝜔(; l).
(.)
The fullmode output SNR is
oSNR [𝐡(; ∶)] =
∑L
l=𝐡T(; l)𝐑𝐱(; l)𝐡(; l)
∑L
l=𝐡T(; l)𝐑𝐯(; l)𝐡(; l)
.
(.)
www.ebook3000.com

126
Fundamentals of Signal Enhancement and Array Signal Processing
It can be shown that
oSNR [𝐡(; ∶)] ≤max
l
𝜔(; l).
(.)
Then, the objective is to ﬁnd the spatial ﬁlters, 𝐡(; l), l = , , … , L, in such a way that
oSNR [𝐡(; l)] ≥iSNR(; l) and oSNR [𝐡(; ∶)] > iSNR(; ).
The lth spectral mode and fullmode noise reduction factors are given by, respectively,
𝜉n
[𝐡(; l)] =

𝐡T(; l)𝐑𝐯(; l)𝐡(; l)
(.)
and
𝜉n [𝐡(; ∶)] =
L
∑L
l=𝐡T(; l)𝐑𝐯(; l)𝐡(; l)
.
(.)
For optimal ﬁlters, the noise reduction factors are greater than . The higher the value
of 𝜉n, the more noise reduction there is.
4.3.4.2
Desired Signal Distortion
The distortion of the desired signal vector can be measured with the lth spectral mode
desired signal reduction factor:
𝜉d
[
𝐡(; l)
]
=
𝜆,l
𝐡T(; l)𝐑𝐱(; l)𝐡(; l)
(.)
and the fullmode desired signal reduction factor:
𝜉d [𝐡(; ∶)] =
tr
(
𝚲
)
∑L
l=𝐡T(; l)𝐑𝐱(; l)𝐡(; l)
.
(.)
For optimal ﬁlters, the desired signal reduction factors are greater than . The higher
the value of 𝜉d, the more the distortion of the desired signal.
It is obvious that we always have
oSNR [𝐡(; l)]
iSNR(; l)
=
𝜉n
[𝐡(; l)]
𝜉d
[𝐡(; l)],
(.)
oSNR [𝐡(; ∶)]
iSNR(; )
= 𝜉n [𝐡(; ∶)]
𝜉d [𝐡(; ∶)].
(.)
Another way to measure distortion is via the lth spectral mode desired signal distor-
tion index:
𝜐d
[𝐡(; l)] =
E
{[xfd(t; l) −x(t; l)]}
𝜆,l
.
(.)

Multichannel Signal Enhancement in the Time Domain
127
We deduce that the fullmode desired signal distortion index is
𝜐d [𝐡(; ∶)] =
∑L
l=E
{[xfd(t; l) −x(t; l)]}
tr (𝚲
)
.
(.)
This index should be lower than for optimal ﬁlters; the higher its value, the more
distorted the desired signal.
4.3.4.3
MSE Criterion
The error signal between the estimated and desired signals is
e(t; l) = z(t; l) −x(t; l)
(.)
= 𝐡T(; l)𝐲(t; l) −x(t; l)
= ed(t; l) + en(t; l),
where
ed(t; l) = xfd(t; l) −x(t; l)
(.)
and
en(t; l) = vrn(t; l)
(.)
are the errors quantifying distortion and residual noise, respectively. We deduce that
the MSE criterion is
J
[
𝐡(; l)
]
= E
[
e(t; l)
]
(.)
= 𝜆,l + 𝐡T(; l)𝐑𝐲(; l)𝐡(; l) −𝐡T(; l)𝐑𝐱(; l)𝐢i,
where 𝐢i, the identity ﬁlter, is the ﬁrst column of 𝐈M. Since E [ed(t; l)en(t; l)] = , J [𝐡(; l)]
can also be expressed as
J [𝐡(; l)] = E [e
d(t; l)] + E [e
n(t; l)]
(.)
= Jd
[𝐡(; l)] + Jn
[𝐡(; l)] ,
where
Jd
[
𝐡(; l)
]
= 𝜆,l + 𝐡T(; l)𝐑𝐱(; l)𝐡(; l) −𝐡T(; l)𝐑𝐱(; l)𝐢i
(.)
= 𝜆,l𝜐d
[𝐡(; l)]
and
Jn
[𝐡(; l)] = 𝐡T(; l)𝐑𝐯(; l)𝐡(; l)
(.)
=

𝜉n
[𝐡(; l)].
www.ebook3000.com

128
Fundamentals of Signal Enhancement and Array Signal Processing
Finally, we have
Jd
[
𝐡(; l)
]
Jn
[
𝐡(; l)
] = iSNR(; l) × 𝜉n
[𝐡(; l)] × 𝜐d
[𝐡(; l)]
(.)
= oSNR [𝐡(; l)] × 𝜉d
[𝐡(; l)] × 𝜐d
[𝐡(; l)] ,
showing how the MSEs are related to the most fundamental lth spectral mode perfor-
mance measures.
4.3.5
Optimal Filters
In this subsection, we derive some fundamental ﬁlters that can help reduce the level of
the noise. We will see how these optimal ﬁlters are very closely related, thanks to the
joint diagonalization formulation.
4.3.5.1
Maximum SNR
In the deﬁnition of the lth spectral mode output SNR (see Equation .), we recognize
the generalized Rayleigh quotient []. It is well known that this quotient is maximized
with the maximum eigenvector, 𝐬(; l), of the matrix 𝐑−
𝐯(; l)𝐑𝐱(; l). Therefore, the
maximum SNR ﬁlter is
𝐡max(; l) = 𝜍(; l)𝐬(; l),
(.)
where 𝜍(; l) ≠is an arbitrary real number. With this ﬁlter, we have the maximum
possible lth spectral mode output SNR:
oSNR [𝐡max(; l)] = 𝜔(; l).
(.)
Clearly,
oSNR
[
𝐡max(; l)
]
≥iSNR(; l)
(.)
and
≤oSNR
[
𝐡(; l)
]
≤oSNR
[
𝐡max(; l)
]
, ∀𝐡(; l).
(.)
Now, we need to determine 𝜍(; l). The best way to do so is by minimizing distortion.
Substituting (.) into the distortion-based MSE, we get
Jd
[
𝐡max(; l)
]
= 𝜆,l + 𝜍(; l)𝜔(; l) −𝜍(; l)𝐬T
(; l)𝐑𝐱(; l)𝐢i
(.)
and, minimizing the previous expression with respect to 𝜍(; l), we ﬁnd
𝜍(; l) =
𝐬T
(; l)𝐑𝐱(; l)𝐢i
𝜔(; l)
.
(.)

Multichannel Signal Enhancement in the Time Domain
129
Plugging this optimal value into (.), we obtain the optimal maximum SNR ﬁlter
with minimum desired signal distortion:
𝐡max(; l) =
𝐬(; l)𝐬T
(; l)
𝜔(; l)
𝐑𝐱(; l)𝐢i
(.)
= 𝐬(; l)𝐬T
(; l)𝐑𝐯(; l)𝐢i.
Example ..
Consider a ULA of M sensors, as shown in Figure .. Suppose that a
desired signal impinges on the ULA from the broadside direction (𝜃= ◦), and that
interference impinges on the ULA from the endﬁre direction (𝜃= ◦). Assume that the
desired signal is a sum of harmonic random processes:
x(t) =
K
∑
k=
Ak cos
(
𝜋fkt + 𝜙k
)
,
with ﬁxed amplitudes {Ak
} and frequencies {fk
}, and IID random phases {𝜙k
},
uniformly distributed on the interval from to 𝜋. Assume that the interference u(t) is
colored noise that is uncorrelated with x(t), with the autocorrelation sequence:
E [u(t)u(t′)] = 𝜎
u 𝛼|t−t′|, −< 𝛼< .
In addition, the sensors contain thermal white Gaussian noise, wm(t) ∼(, 𝜎
w
), the
signals of which are mutually uncorrelated. The desired signal needs to be recovered
from the noisy received signals, ym(t) = xm(t) + vm(t), m = , … , M, where vm(t) =
um(t) + wm(t), m = , … , M are the interference-plus-noise signals.
As in Example .., we choose a sampling interval Ts that satisﬁes Ts = d
c . Hence, we
have for i = , … , M:
xi(t) = x(t),
(.)
ui(t) = u(t −i + ) .
(.)
Therefore, the correlation matrix of 𝐱i(t) is
𝐑𝐱i = 𝐑𝐱,
where the elements of the L × L correlation matrix of 𝐱(t) are
[
𝐑𝐱
]
i,j = 

∑K
k=A
k cos
[
𝜋fk(i −j)
]
. The correlation matrix of 𝐯m(t) is
𝐑𝐯m = 𝐑𝐮+ 𝜎
w𝐈L,
where the elements of the L × L correlation matrix of 𝐮(t) are [𝐑𝐮
]
i,j = 𝜎
u 𝛼|i−j|. The
fullmode input SNR is
iSNR(; ) = log
∑K
k=A
k
(𝜎
u + 𝜎
w)
(dB).
www.ebook3000.com

130
Fundamentals of Signal Enhancement and Array Signal Processing
After joint diagonalization of 𝐑𝐱m and 𝐑𝐯m for all m = , … , M using (.) and (.),
we compute the M × M matrices 𝐑𝐱(; l) and 𝐑𝐯(; l) for all l = , … , L:
[𝐑𝐱(; l)]
m,m= 𝐭T
m,l𝐑𝐱m,𝐱m𝐭m,l,
[
𝐑𝐯(; l)
]
m,m= 𝐭T
m,l𝐑𝐯m,𝐯m𝐭m,l,
where 𝐑𝐱m,𝐱m= E
[
𝐱m(t)𝐱T
m(t)
]
and 𝐑𝐯m,𝐯m= E
[
𝐯m(t)𝐯T
m(t)
]
are L × L spatiotem-
poral correlation matrices of the desired and noise signals, respectively. In this example,
since the desired source is in the broadside direction and the interference source is in
the endﬁre direction, we have
𝐑𝐱m,𝐱m= 𝐑𝐱,
[
𝐑𝐯m,𝐯m
]
i,j = 𝜎
u 𝛼|i−j+m−m| + 𝜎
w 𝛿(m−m
) 𝛿(i −j) .
After joint diagonalization of 𝐑𝐱(; l) and 𝐑𝐯(; l) for all l = , … , L using (.) and (.),
the optimal maximum SNR ﬁlter 𝐡max(; l) is obtained from (.).
To demonstrate the performance of the maximum SNR ﬁlter, we choose Ak
=
.∕k, k = , … , , fk = .+.(k−), k = , … , , 𝛼= ., L = , 𝜎
w = .𝜎
u, and
several values of M. Figure .shows plots of the fullmode gain in SNR, [𝐡max(; ∶)],
the fullmode MSE, J
[
𝐡max(; ∶)
]
, the fullmode noise reduction factor, 𝜉n
[
𝐡max(; ∶)
]
, and
the fullmode desired signal reduction factor, 𝜉d
[𝐡max(; ∶)], as a function of the fullmode
input SNR for diﬀerent numbers of sensors, M. For a given fullmode input SNR, as the
number of sensors increases, the fullmode gain in SNR and the fullmode noise reduction
factor increase, while the fullmode MSE decreases.
■
4.3.5.2
Wiener
Taking the gradient of the MSE criterion, J [𝐡(; l)], with respect to 𝐡(; l) and equating
the result to zero, we ﬁnd the Wiener ﬁlter:
𝐡W(; l) = 𝐑−
𝐲(; l)𝐑𝐱(; l)𝐢i,
(.)
which we can also express as
𝐡W(; l) =
M
∑
m=
𝐬m(; l)𝐬T
m(; l)
+ 𝜔m(; l) 𝐑𝐱(; l)𝐢i
(.)
=
M
∑
m=
𝜔m(; l)
+ 𝜔m(; l)𝐬m(; l)𝐬T
m(; l)𝐑𝐯(; l)𝐢i.
From this formulation, we see clearly how 𝐡W(; l) and 𝐡max(; l) are related. Besides a
(slight) diﬀerent weighting factor, 𝐡W(; l) considers all directions where the desired
signal and noise are present, while 𝐡max(; l) relies only on the direction where the
maximum of the desired signal energy is found.

Multichannel Signal Enhancement in the Time Domain
131
2
4
6
8
10
12
14
−4
−2
0
2
4
6
8
2
4
6
8
10
12
14
−1
−0.5
0
0.5
1
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
iSNR(;) (dB)
(a)
(b)
(c)
(d)
−5
0
5
10
15
−5
0
5
10
15
[hmax (;:)] (dB)
J [hmax (;:)] (dB)
ξn [hmax (;:)] (dB)
ξd [hmax (;:)] (dB)
Figure 4.10 (a) The fullmode gain in SNR, (b) the fullmode MSE, (c) the fullmode noise reduction
factor, and (d) the fullmode desired signal reduction factor of the maximum SNR filter as a function of
the fullmode input SNR for different numbers of sensors, M: M = 2 (solid line with circles), M = 5
(dashed line with asterisks), M = 10 (dotted line with squares), and M = 20 (dash-dot line with
triangles).
Obviously, we have
oSNR
[
𝐡W(; l)
]
≤oSNR
[
𝐡max(; l)
]
(.)
and, in general,
𝜐d
[
𝐡W(; l)
]
≤𝜐d
[
𝐡max(; l)
]
.
(.)
Example ..
Returning to Example .., we now employ the Wiener ﬁlter, 𝐡W(; l),
given in (.). Figure .shows plots of the fullmode gain in SNR, 
[
𝐡W(; ∶)
]
, the
fullmode MSE, J [𝐡W(; ∶)], the fullmode noise reduction factor, 𝜉n
[𝐡W(; ∶)], and the
fullmode desired signal reduction factor, 𝜉d
[
𝐡W(; ∶)
]
, as a function of the fullmode input
SNR for diﬀerent numbers of sensors, M. For a given fullmode input SNR, as the number
of sensors increases, the fullmode gain in SNR and the fullmode noise reduction factor
increase, while the fullmode MSE and the fullmode desired signal reduction factor
decrease.
■
www.ebook3000.com

132
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
2
4
6
8
10
12
16
14
−4
−2
0
2
4
6
8
0
2
4
6
8
10
2
4
6
8
10
12
16
14
iSNR(;) (dB)
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
(a)
(b)
(c)
(d)
[hW (; :)] (dB)
J [hW (; :)] (dB)
ξn [hW (;:)] (dB)
ξd [hW (;:)] (dB)
−5
0
5
10
15
Figure 4.11 (a) The fullmode gain in SNR, (b) the fullmode MSE, (c) the fullmode noise reduction
factor, and (d) the fullmode desired signal reduction factor of the Wiener filter as a function of the
fullmode input SNR for different numbers of sensors, M: M = 2 (solid line with circles), M = 5 (dashed
line with asterisks), M = 10 (dotted line with squares), and M = 20 (dash-dot line with triangles).
4.3.5.3
MVDR
Here, we show how to derive a ﬁlter that does not distort the desired signal. This
approach exploits the nullspace of 𝐑𝐱(; l).
By using (.) and (.), the ﬁltered desired signal can be expressed as
xfd(t; l) = 𝐡T(; l)𝐱(t; l)
(.)
= 𝐡T(; l)𝐑𝐯(; l)𝐑−
𝐯(; l)𝐱(t; l)
= 𝐡T(; l)𝐑𝐯(; l)
[
𝐒′(; l)𝐒′T(; l) + 𝐒′′(; l)𝐒′′T(; l)
]
𝐱(t; l)
= 𝐡T(; l)𝐑𝐯(; l)𝐒′(; l)𝐒′T(; l)𝐱(t; l).
We see from (.) that in order to completely recover the desired signal, x(t; l), we
must use the constraint:
𝐡T(; l)𝐑𝐯(; l)𝐒′(; l) = 𝐢T
i 𝐑𝐯(; l)𝐒′(; l).
(.)

Multichannel Signal Enhancement in the Time Domain
133
Therefore, it is desired to minimize the residual noise subject to (.):
min
𝐡(;l) 𝐡T(; l)𝐑𝐯(; l)𝐡(; l) subject to
𝐡T(; l)𝐑𝐯(; l)𝐒′(; l) = 𝐢T
i 𝐑𝐯(; l)𝐒′(; l),
(.)
from which we ﬁnd the MVDR ﬁlter:
𝐡MVDR(; l) = 𝐒′(; l)𝐒′T(; l)𝐑𝐯(; l)𝐢i
(.)
=
Pl
∑
p=
𝐬p(; l)𝐬T
p (; l)𝐑𝐯(; l)𝐢i.
Another formulation of this ﬁlter is
𝐡MVDR(; l) =
Pl
∑
p=
𝐬p(; l)𝐬T
p (; l)
𝜔p(; l)
𝐑𝐱(; l)𝐢i.
(.)
For Pl = M, the MVDR ﬁlter degenerates to the identity ﬁlter: 𝐡MVDR(; l) = 𝐢i, which
does not aﬀect the observations. For Pl = , the MVDR ﬁlters becomes the maximum
SNR ﬁlter. Therefore, we can state that the higher the dimension of the nullspace of
𝐑𝐱(; l), the more noise reduction there is using the MVDR ﬁlter.
The lth spectral mode output SNR of the MVDR ﬁlter is
oSNR [𝐡MVDR(; l)] =
𝜆,l
𝐢T
i 𝐑𝐯(; l)𝐒′(; l)𝐒′T(; l)𝐑𝐯(; l)𝐢i
(.)
=
𝜆,l
−𝐢T
i 𝐑𝐯(; l)𝐒′′(; l)𝐒′′T(; l)𝐑𝐯(; l)𝐢i
.
As a result,
oSNR [𝐡MVDR(; l)] ≥𝜆,l = iSNR (; l) .
(.)
We always have
oSNR
[
𝐡MVDR(; l)
]
≤oSNR
[
𝐡W(; l)
]
.
(.)
4.3.5.4
Controlled Distortion
From the obvious relationship between the MVDR and maximum SNR ﬁlters, we can
deduce a whole class of controlled distortion (CD) ﬁlters:
𝐡CD,P′
l(; l) =
P′
l
∑
p′=
𝐬p′(; l)𝐬T
p′(; l)𝐑𝐯(; l)𝐢i,
(.)
www.ebook3000.com

134
Fundamentals of Signal Enhancement and Array Signal Processing
where ≤P′
l ≤Pl. We observe that 𝐡CD,(; l) = 𝐡max(; l) and 𝐡CD,Pl(; l) = 𝐡MVDR(; l).
Also, we always have
oSNR [𝐡CD,Pl(; l)] ≤oSNR [𝐡CD,Pl−(; l)] ≤⋯≤oSNR [𝐡CD,(; l)]
(.)
and
= 𝜐d
[
𝐡CD,Pl(; l)
]
≤𝜐d
[
𝐡CD,Pl−(; l)
]
≤⋯≤𝜐d
[
𝐡CD,(; l)
]
.
(.)
Example ..
Returning to Example .., the desired signal now impinges on the
ULA from 𝜃= ◦, rather than from the broadside direction. The interference and
thermal noise remain the same as in Example ... We assume that the desired signal
is the sum of three harmonic random processes:
x(t) =

∑
k=
Ak cos (𝜋fkt + 𝜙k
) ,
with Ak = .∕k, k = , … , , fk = .+ .(k −), k = , … , , and IID random
phases {𝜙k
}, uniformly distributed on the interval from to 𝜋.
The desired signal at sensor m is a delayed version of the desired signal at the ﬁrst
sensor:
xm(t) = x
(t −𝜏m
) ,
(.)
where
𝜏m = (m −)d cos 𝜃
cTs
(.)
= (m −) cos 𝜃, m = , , … , M
is the relative time delay in samples (not necessarily an integer number) between the mth
sensor and the ﬁrst one. Therefore, the elements of the L×L spatiotemporal correlation
matrix 𝐑𝐱m,𝐱m= E
[
𝐱m(t)𝐱T
m(t)
]
are
[
𝐑𝐱m,𝐱m
]
i,j = 


∑
k=
A
k cos [𝜋fk(i −j + 𝜏m−𝜏m)].
The fullmode input SNR is
iSNR(; ) = log
∑
k=A
k
(𝜎
u + 𝜎
w)
(dB).
After joint diagonalization of 𝐑𝐱(; l) and 𝐑𝐯(; l) for all l = , … , L using (.) and (.),
the controlled distortion ﬁlter, 𝐡CD,P′
l(; l), is obtained from (.).

Multichannel Signal Enhancement in the Time Domain
135
−5
0
5
10
15
2
3
4
5
6
7
8
0
5
10
15
20
25
2
4
6
8
10
12
0
0.5
1
1.5
2
2.5
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
(a)
(b)
(c)
(d)
 [hCD,P′l (; :)] (dB)
J [hCD,P′l (; :)] (dB)
ξn [hCD,P′l (; :)] (dB)
ξd [hCD,P′l (; :)] (dB)
Figure 4.12 (a) The fullmode gain in SNR, (b) the fullmode MSE, (c) the fullmode noise reduction
factor, and (d) the fullmode desired signal reduction factor of the controlled distortion filter as a
function of the fullmode input SNR for several values of P′
l: P′
l = 1 (solid line with circles), P′
l = 2
(dashed line with asterisks), P′
l = 3 (dotted line with squares), and P′
l = 4 (dash-dot line with triangles).
Figure .shows plots of the fullmode gain in SNR, 
[
𝐡CD,P′
l(; ∶)
]
, the fullmode MSE,
J
[
𝐡CD,P′
l(; ∶)
]
, the fullmode noise reduction factor, 𝜉n
[
𝐡CD,P′
l(; ∶)
]
, and the fullmode
desired signal reduction factor, 𝜉d
[
𝐡CD,P′
l(; ∶)
]
, as a function of the fullmode input SNR
for several values of P′
l. For a given fullmode input SNR, as the value of P′
l increases, the
fullmode desired signal reduction factor decreases, at the expense of lower fullmode
gain in SNR and a lower fullmode noise reduction factor.
■
4.3.5.5
Tradeoff
Another way to compromise between noise reduction and desired signal distortion is to
minimize the desired signal distortion index with the constraint that the noise reduction
factor is equal to a positive value that is greater than . Mathematically, this is equivalent
to
min
𝐡(;l) Jd
[𝐡(; l)]
subject to Jn
[𝐡(; l)] = ℵ,
(.)
www.ebook3000.com

136
Fundamentals of Signal Enhancement and Array Signal Processing
where < ℵ< . We easily ﬁnd the tradeoﬀﬁlter:
𝐡T,𝜇(; l) =
M
∑
m=
𝜔m(; l)
𝜇+ 𝜔m(; l)𝐬m(; l)𝐬T
m(; l)𝐑𝐯(; l)𝐢i,
(.)
where 𝜇≥is a Lagrange multiplier. We observe that 𝐡T,(; l) = 𝐡W(; l). We have
oSNR [𝐡T,𝜇(; l)] ≥iSNR(; l), ∀𝜇≥.
(.)
For 𝜇greater (resp. less) than , the tradeoﬀﬁlter reduces more (resp. less) noise than
the Wiener ﬁlter but introduces more (resp. less) distortion.
Example ..
Returning to Example .., we now employ the tradeoﬀﬁlter, 𝐡T,𝜇(; l),
given in (.). Figure .shows plots of the fullmode gain in SNR, [𝐡T,𝜇(; ∶)], the
fullmode MSE, J [𝐡T,𝜇(; ∶)], the fullmode noise reduction factor, 𝜉n
[𝐡T,𝜇(; ∶)], and the
fullmode desired signal reduction factor, 𝜉d
[
𝐡T,𝜇(; ∶)
]
, as a function of the fullmode
input SNR for several values of 𝜇. For a given fullmode input SNR, as the value of 𝜇
increases, the fullmode gain in SNR and the fullmode noise reduction factor increase,
at the expense of a higher fullmode desired signal reduction factor.
■
4.3.5.6
General Subspace
Let f
[
𝜔m(; l)
]
be a function of 𝜔m(; l), where ≤f
[
𝜔m(; l)
]
≤. A general subspace
(GS) approach for multichannel noise reduction is
𝐡GS(; l) =
M′
∑
m′=
f [𝜔m′(; l)] 𝐬m′(; l)𝐬T
m′(; l)𝐑𝐯(; l)𝐢i,
(.)
where ≤M′ ≤M. It can be veriﬁed that the general form given in (.) encompasses
all the ﬁlters derived in the previous subsections. Obviously, many other ﬁlters can be
derived too.
In Table ., we summarize all the ﬁlters described in this subsection, showing how
they are closely related.
4.4
Case of a Rank Deficient Noise Correlation Matrix
So far, for both the single-channel and multichannel noise reduction problems, we have
assumed that the noise correlation matrix has full rank. What happens if this is not
the case? Many good optimal linear ﬁlters, such as the Wiener ﬁlter, are guaranteed
to behave well only if the noise correlation matrix is full rank. However, in some
applications, it may be that the noise is narrowband []. In such situations, classical
linear ﬁlters for noise reduction may not function correctly. In this section, we show
how to derive some very eﬃcient linear ﬁlters in the particular case of a rank deﬁcient
noise correlation matrix.

Multichannel Signal Enhancement in the Time Domain
137
−5
0
5
10
15
4
5
6
7
8
9
10
(a)
(b)
(c)
(d)
1
2
3
4
5
6
7
8
4
6
8
10
12
14
16
18
20
0
2
4
6
8
10
12
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
−5
0
5
10
15
iSNR(;) (dB)
 [hT,μ (;:)] (dB)
J [hT,μ (;:)] (dB)
ξn [hT,μ (;:)] (dB)
ξd [hT,μ (;:)] (dB)
Figure 4.13 (a) The fullmode gain in SNR, (b) the fullmode MSE, (c) the fullmode noise reduction
factor, and (d) the fullmode desired signal reduction factor of the tradeoff filter as a function of the
fullmode input SNR for several values of 𝜇: 𝜇= 0.5 (solid line with circles), 𝜇= 1 (dashed line with
asterisks), 𝜇= 2 (dotted line with squares), and 𝜇= 5 (dash-dot line with triangles).
4.4.1
Eigenvalue Decompositions
From here on, it is assumed that rank
(
𝐑𝐱
)
= P < ML while rank
(
𝐑𝐯
)
= Q < ML.
Using the convenient eigenvalue decomposition [], the noise correlation matrix can be
diagonalized as
𝐐T
𝐯𝐑𝐯𝐐𝐯= 𝚲𝐯,
(.)
where
𝐐𝐯=
[ 𝐪𝐯,
𝐪𝐯,
⋯
𝐪𝐯,ML
]
(.)
is an orthogonal matrix: 𝐐T
𝐯𝐐𝐯= 𝐐𝐯𝐐T
𝐯= 𝐈ML and
𝚲𝐯= diag
(
𝜆𝐯,, 𝜆𝐯,, … , 𝜆𝐯,ML
)
(.)
www.ebook3000.com

138
Fundamentals of Signal Enhancement and Array Signal Processing
Table 4.2 Optimal linear filters for multichannel signal enhancement in
the spectral domain.
Filter
Maximum SNR
𝐡max(; l) = 𝐬(; l)𝐬T
(; l)𝐑𝐯(; l)𝐢i
Wiener
𝐡W(; l) =
M
∑
m=
𝜔m(; l)
+ 𝜔m(; l)𝐬m(; l)𝐬T
m(; l)𝐑𝐯(; l)𝐢i
MVDR
𝐡MVDR(; l) =
Pl
∑
p=
𝐬p(; l)𝐬T
p (; l)𝐑𝐯(; l)𝐢i
CD
𝐡CD,P′
l (; l) =
P′
l
∑
p′=
𝐬p′(; l)𝐬T
p′(; l)𝐑𝐯(; l)𝐢i
Tradeoﬀ
𝐡T,𝜇(; l) =
M
∑
m=
𝜔m(; l)
𝜇+ 𝜔m(; l)𝐬m(; l)𝐬T
m(; l)𝐑𝐯(; l)𝐢i
GS
𝐡GS(; l) =
M′
∑
m′=
f [𝜔m′(; l)] 𝐬m′(; l)𝐬T
m′(; l)𝐑𝐯(; l)𝐢i
is a diagonal matrix. The orthonormal vectors 𝐪𝐯,, 𝐪𝐯,, … , 𝐪𝐯,ML are the eigenvectors
corresponding, respectively, to the eigenvalues 𝜆𝐯,, 𝜆𝐯,, … , 𝜆𝐯,ML of the matrix 𝐑𝐯,
where 𝜆𝐯,≥𝜆𝐯,≥⋯≥𝜆𝐯,Q > and 𝜆𝐯,Q+= 𝜆𝐯,Q+= ⋯= 𝜆𝐯,ML = . In the
same way, the desired signal correlation matrix can be diagonalized as
𝐐T
𝐱𝐑𝐱𝐐𝐱= 𝚲𝐱,
(.)
where the orthogonal and diagonal matrices 𝐐𝐱and 𝚲𝐱are deﬁned in a similar way to
𝐐𝐯and 𝚲𝐯, respectively, with 𝜆𝐱,≥𝜆𝐱,≥⋯≥𝜆𝐱,P > and 𝜆𝐱,P+= 𝜆𝐱,P+= ⋯=
𝜆𝐱,ML = . The two previous decompositions will be extensively used in the rest of this
section for the purpose of deriving optimal linear ﬁlters.
4.4.2
Maximization of the Output SNR
In this part, we show how to exploit the nullspace of the noise correlation matrix in order
to derive noise reduction ﬁlters. Thanks to this nullspace, we can completely cancel the
noise; this leads to inﬁnite noise reduction ﬁltering matrices.
Let
𝐐′′
𝐯=
[ 𝐪𝐯,Q+
𝐪𝐯,Q+
⋯
𝐪𝐯,ML
]
(.)
be the matrix of size ML × (ML −Q) containing the eigenvectors corresponding to the
null eigenvalues of 𝐑𝐯. We are interested in the linear ﬁltering matrices of the form:
𝐇= 𝐀𝐐′′T
𝐯,
(.)

Multichannel Signal Enhancement in the Time Domain
139
where 𝐀≠𝟎is a matrix of size L × (ML −Q). Since 𝐑𝐯𝐐′′
𝐯= 𝟎and assuming that
𝐑𝐱𝐐′′
𝐯≠𝟎, which is reasonable since 𝐑𝐱and 𝐑𝐯cannot be diagonalized by the same
orthogonal matrix unless one of the two signals is white, we have
oSNR (𝐇) =
tr
(
𝐇𝐑𝐱𝐇T)
tr
(
𝐇𝐑𝐯𝐇T)
(.)
=
tr
(
𝐀𝐐′′T
𝐯𝐑𝐱𝐐′′
𝐯𝐀T)
tr
(
𝐀𝐐′′T
𝐯𝐑𝐯𝐐′′
𝐯𝐀T)
= ∞.
As a consequence, the estimate of 𝐱(t) is
̂𝐱(t) = 𝐇𝐲(t)
(.)
= 𝐀𝐐′′T
𝐯𝐱(t) + 𝐀𝐐′′T
𝐯𝐯(t)
= 𝐀𝐐′′T
𝐯𝐱(t).
We observe from the previous expression that this approach completely cancels the
noise. Now, we need to ﬁnd 𝐀. The best way to ﬁnd this matrix is by minimizing the
distortion of the estimated desired signal.
The distortion-based MSE is
Jd
(𝐀) = E
{[̂𝐱(t) −𝐱(t)]T [̂𝐱(t) −𝐱(t)]}
(.)
= tr
(
𝐑𝐱−𝐀𝐐′′T
𝐯𝐑𝐱𝐈T
i + 𝐀𝐐′′T
𝐯𝐑𝐱𝐐′′
𝐯𝐀T)
.
From the minimization of Jd
(𝐀) and (.), we easily deduce the optimal inﬁnite noise
reduction ﬁltering matrix:
𝐇∞= 𝐈i𝐑𝐱𝐐′′
𝐯
(
𝐐′′T
𝐯𝐑𝐱𝐐′′
𝐯
)−
𝐐′′T
𝐯.
(.)
It is very important to see from (.) that for 𝐇∞to be unique, we must have P ≥
ML−Q. It is worth noticing that the larger the dimension of the nullspace of 𝐑𝐯: ML−Q,
the less distorted the desired signal, since the the number of columns of 𝐀and hence
the number of degrees of freedom to minimize distortion are larger. The worst case is
when Q = ML −. Indeed, while the output SNR is still equal to inﬁnity, distortion may
be very high, since 𝐀simpliﬁes to a vector, which may not be enough to reduce this
distortion.
www.ebook3000.com

140
Fundamentals of Signal Enhancement and Array Signal Processing
Let us consider the particular case: P = ML −Q. We can always express the estimate
of 𝐱(t) as
̂𝐱(t) = 𝐀𝐐′′T
𝐯𝐱(t)
(.)
= 𝐀𝐐′′T
𝐯𝐐′
𝐱𝐐′T
𝐱𝐱(t),
where
𝐐′
𝐱= [ 𝐪𝐱,
𝐪𝐱,
⋯
𝐪𝐱,P
]
(.)
is the matrix of size ML × P containing the eigenvectors corresponding to the nonnull
eigenvalues of 𝐑𝐱. We see from (.) that in order to recover the desired signal, 𝐱(t),
we must have
𝐀𝐐′′T
𝐯𝐐′
𝐱= 𝐈i𝐐′
𝐱.
(.)
Therefore, since 𝐐′′T
𝐯𝐐′
𝐱is a square invertible matrix, we have a unique solution for
(.). As a result, the optimal ﬁltering matrix for this particular case is
𝐇∞= 𝐈i𝐐′
𝐱
(
𝐐′′T
𝐯𝐐′
𝐱
)−
𝐐′′T
𝐯.
(.)
This ﬁlter perfectly recovers the desired signal: it completely cancels the noise without
any distortion.
Another interesting scenario is when P < ML−Q. One reasonable approach is to take
the minimum-norm solution of (.). Therefore, the ﬁltering matrix becomes
𝐇∞= 𝐈i𝐐′
𝐱
(
𝐐′T
𝐱𝐐′′
𝐯𝐐′′T
𝐯𝐐′
𝐱
)−
𝐐′T
𝐱𝐐′′
𝐯𝐐′′T
𝐯.
(.)
This ﬁltering matrix cancels the noise but some distortion of the desired signal is
expected.
4.4.3
Minimization of the Output SNR
The approach in this subsection involves two successive stages. We get an estimate of
the noise in the ﬁrst stage. Then, this estimate is used in the second stage by subtracting
it from the observation signal. This will lead to the estimation of the desired signal [].
Also, we exploit the nullspace of the desired signal correlation matrix. We will see that,
thanks to this nullspace, we can derive distortionless ﬁltering matrices.
Let
𝐐′′
𝐱=
[
𝐪𝐱,P+
𝐪
𝐱,P+
⋯
𝐪𝐱,ML
]
(.)
be the matrix of size ML × (ML −P) containing the eigenvectors corresponding to the
null eigenvalues of 𝐑𝐱. In this part, we are interested in the ﬁltering matrices of the form:
𝐇𝐯= 𝐀𝐯𝐐′′T
𝐱,
(.)

Multichannel Signal Enhancement in the Time Domain
141
where 𝐀𝐯≠𝟎is a matrix of size L × (ML −P). We assume that 𝐑𝐯𝐐′′
𝐱≠𝟎. Therefore,
we have
oSNR
(
𝐇𝐯
)
=
tr
(
𝐇𝐯𝐑𝐱𝐇T
𝐯
)
tr
(
𝐇𝐯𝐑𝐯𝐇T
𝐯
)
(.)
=
tr
(
𝐀𝐯𝐐′′T
𝐱𝐑𝐱𝐐′′
𝐱𝐀T
𝐯
)
tr
(
𝐀𝐯𝐐′′T
𝐱𝐑𝐯𝐐′′
𝐱𝐀T
𝐯
)
= ,
since 𝐑𝐱𝐐′′
𝐱= 𝟎. As a consequence, the estimate of 𝐯(t) is
̂𝐯(t) = 𝐇𝐯𝐲(t)
(.)
= 𝐀𝐯𝐐′′T
𝐱𝐱(t) + 𝐀𝐯𝐐′′T
𝐱𝐯(t)
= 𝐀𝐯𝐐′′T
𝐱𝐯(t),
from which we deduce the estimate of 𝐱(t):
̂𝐱(t) = 𝐲(t) −̂𝐯(t)
(.)
= 𝐱(t) + 𝐯(t) −𝐀𝐯𝐐′′T
𝐱𝐯(t)
= 𝐇𝐲(t),
where
𝐇= 𝐈i −𝐀𝐯𝐐′′T
𝐱
(.)
is the equivalent ﬁltering matrix for the estimation of 𝐱(t). The output SNR with this
ﬁltering matrix is then
oSNR (𝐇) =
tr
(
𝐇𝐑𝐱𝐇T)
tr
(
𝐇𝐑𝐯𝐇T).
(.)
It is important to notice that the estimator given in (.) does not introduce any
distortion to the desired signal, since it is not ﬁltered at all.
Now, we need to determine 𝐀𝐯. The best way to do so is from the MSE of the residual
noise:
Jn
(
𝐇
)
= tr
(
𝐇𝐑𝐯𝐇T)
(.)
= tr
(
𝐑𝐯−𝐀𝐯𝐐′′T
𝐱𝐑𝐯𝐈T
i + 𝐀𝐯𝐐′′T
𝐱𝐑𝐯𝐐′′
𝐱𝐀T
𝐯
)
= Jn
(
𝐀𝐯
)
.
www.ebook3000.com

142
Fundamentals of Signal Enhancement and Array Signal Processing
From the minimization of Jn
(
𝐀𝐯
)
and (.), we ﬁnd the optimal distortionless
ﬁltering matrix:
𝐇DL = 𝐈i −𝐈i𝐑𝐯𝐐′′
𝐱
(
𝐐′′T
𝐱𝐑𝐯𝐐′′
𝐱
)−
𝐐′′T
𝐱.
(.)
It is very important to see from (.) that for 𝐇DL to be unique, we must have Q ≥
ML −P. For this ﬁltering matrix to be useful as far as noise reduction is concerned, the
number of columns of 𝐀𝐯should be large enough, which implies that the dimension of
the nullspace of 𝐑𝐱should also be large.
Let us consider the particular case: Q = ML −P. We can always express the estimate
of 𝐯(t) as
̂𝐯(t) = 𝐀𝐯𝐐′′T
𝐱𝐐′
𝐯𝐐′T
𝐯𝐯(t),
(.)
where
𝐐′
𝐯= [ 𝐪𝐯,
𝐪𝐯,
⋯
𝐪𝐯,Q
]
(.)
is the matrix of size ML × Q containing the eigenvectors corresponding to the nonnull
eigenvalues of 𝐑𝐯. We see from (.) that in order to recover the noise, 𝐯(t), we must
have
𝐀𝐯𝐐′′T
𝐱𝐐′
𝐯= 𝐈i𝐐′
𝐯.
(.)
Therefore, since 𝐐′′T
𝐱𝐐′
𝐯is a square invertible matrix, we have a unique solution for
(.). As a result, the optimal distortionless ﬁltering matrix for this particular case is
𝐇DL = 𝐈i −𝐈i𝐐′
𝐯
(
𝐐′′T
𝐱𝐐′
𝐯
)−
𝐐′′T
𝐱.
(.)
This ﬁltering matrix perfectly recovers the desired signal: it completely cancels the noise
without any distortion.
Another interesting scenario is when Q < ML −P. One reasonable approach is to
take the minimum-norm solution of (.). We then get another distortionless ﬁltering
matrix for this particular case:
𝐇DL = 𝐈i −𝐈i𝐐′
𝐯
(
𝐐′T
𝐯𝐐′′
𝐱𝐐′′T
𝐱𝐐′
𝐯
)−
𝐐′T
𝐯𝐐′′
𝐱𝐐′′
𝐱.
(.)
Problems
4.1 Show that if two symmetric matrices 𝐑𝐱and 𝐑𝐯are jointly diagonalized:
𝐓T𝐑𝐱𝐓= 𝚲,

Multichannel Signal Enhancement in the Time Domain
143
𝐓T𝐑𝐯𝐓= 𝐈ML,
then 𝚲and 𝐓are, respectively, the eigenvalue and eigenvector matrices of 𝐑−
𝐯𝐑𝐱:
𝐑−
𝐯𝐑𝐱𝐓= 𝐓𝚲.
4.2 Denote by 𝐭, 𝐭, … , 𝐭ML, the eigenvectors of 𝐑−
𝐯𝐑𝐱. Show that
𝐑−
𝐯=
ML
∑
i=
𝐭i𝐭T
i .
4.3 Show that the MSE can be written as
J (𝐀) = tr
[
𝐑𝐱−𝐀𝐓T𝐑𝐱𝐈T
i + 𝐀(𝚲+ 𝐈ML
) 𝐀T]
.
4.4 Show that the diﬀerent performance measures are related to the MSEs by
Jd
(𝐀)
Jn
(
𝐀
) = iSNR × 𝜉n
(𝐀) × 𝜐d
(𝐀)
= oSNR (𝐀) × 𝜉d
(𝐀) × 𝜐d
(𝐀) .
4.5 Show that the Wiener ﬁltering matrix can be written as
𝐇W = 𝐈i𝐑𝐯
ML
∑
i=
𝜆i
+ 𝜆i
𝐭i𝐭T
i .
4.6 Prove that with the optimal Wiener ﬁltering matrix, the output SNR is always
greater than or equal to the input SNR: oSNR (𝐇W
) ≥iSNR.
4.7 Consider a ULA of M sensors with interelement spacing d. Assume that the
desired signal is a harmonic random process:
x(t) = A cos
(
𝜋ft + 𝜙
)
,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly dis-
tributed on the interval from to 𝜋.
a) Suppose that the desired signal impinges on the ULA from the broadside
direction. Compute the correlation matrix of 𝐱(t).
b) Assume that the sampling interval satisﬁes Ts = d∕c. Compute the correlation
matrix of 𝐱(t) when the desired signal impinges on the ULA from the endﬁre
direction.
c) Compute the correlation matrix of 𝐱(t) in the general case, when the desired
signal impinges on the ULA from the direction 𝜃.
d) Repeat the above for white Gaussian noise: x(t) ∼(, 𝜎).
www.ebook3000.com

144
Fundamentals of Signal Enhancement and Array Signal Processing
e) Repeat the above for a desired signal, x(t), that has a autocorrelation sequence:
E [x(t)x(t′)] = 𝛼|t−t′|, −< 𝛼< .
4.8 Show that the maximum SNR ﬁltering matrix with minimum MSE is given by
𝐇max,= 𝐈i𝐑𝐱
𝐭𝐭T

+ 𝜆
.
4.9 Show that taking the gradient of Jd
(𝐀) with respect to 𝐀and equating the result
to zero yields the MVDR ﬁltering matrix:
𝐇MVDR = 𝐈i𝐑𝐱
P
∑
p=
𝐭p𝐭T
p
𝜆p
.
4.10 Prove that with the MVDR ﬁltering matrix, there is no distortion in the ﬁltered
signal:
𝜐d
(𝐇MVDR
) = .
(.)
4.11 Show that with the MVDR ﬁltering matrix, the output SNR is always greater than
or equal to the input SNR: oSNR (𝐇MVDR
) ≥iSNR.
4.12 Show that with the tradeoﬀﬁltering matrix 𝐇T,𝜇, the output SNR is always greater
than or equal to the input SNR: oSNR
(
𝐇T,𝜇
)
≥iSNR, ∀𝜇≥.
4.13 Show that by jointly diagonalizing the two spatial correlation matrices 𝐑𝐱(; l) and
𝐑𝐯(; l), we obtain
𝐒′′T(; l)𝐱(t; l) = 𝟎
and
𝐑−
𝐯(; l) = 𝐒′(; l)𝐒′T(; l) + 𝐒′′(; l)𝐒′′T(; l).
4.14 Show that the fullmode input SNR can never exceed the maximum spectral mode
input SNR and can never go below the minimum spectral mode input SNR:
iSNR(; L) ≤iSNR(; ) ≤iSNR(; ).
4.15 Show that the MSE is given by
J [𝐡(; l)] = 𝜆,l + 𝐡T(; l)𝐑𝐲(; l)𝐡(; l) −𝐡T(; l)𝐑𝐱(; l)𝐢i.

Multichannel Signal Enhancement in the Time Domain
145
4.16 Show that the MSEs are related to the lth spectral mode performance measures
by
Jd
[𝐡(; l)]
Jn
[𝐡(; l)] = iSNR(; l) × 𝜉n
[𝐡(; l)] × 𝜐d
[𝐡(; l)]
= oSNR
[
𝐡(; l)
]
× 𝜉d
[
𝐡(; l)
]
× 𝜐d
[
𝐡(; l)
]
.
4.17 Show that the optimal maximum SNR ﬁlter with minimum desired signal distor-
tion is given by
𝐡max(; l) =
𝐬(; l)𝐬T
(; l)
𝜔(; l)
𝐑𝐱(; l)𝐢i
= 𝐬(; l)𝐬T
(; l)𝐑𝐯(; l)𝐢i.
4.18 Consider a desired signal that is a sum of harmonic random processes:
x(t) =
K
∑
k=
Ak cos
(
𝜋fkt + 𝜙k
)
,
with ﬁxed amplitudes {Ak
} and frequencies {fk
}, and IID random phases {𝜙k
},
uniformly distributed on the interval from to 𝜋. Assume that the interference
u(t) is colored noise that is uncorrelated with x(t), with the autocorrelation
sequence:
E [u(t)u(t′)] = 𝜎
u 𝛼|t−t′|, −< 𝛼< .
a) Compute the fullmode input SNR.
b) Assume that the desired signal impinges on the ULA from the broadside
direction. Describe the steps to ﬁnd the correlation matrix 𝐑𝐱m.
c) Assume that the desired signal impinges on the ULA from the direction 𝜃.
Describe the steps to ﬁnd the correlation matrix 𝐑𝐱m.
d) Assume that the sampling interval satisﬁes Ts = d∕c, and the interference
impinges on the ULA from the endﬁre direction. Describe the steps to ﬁnd
the correlation matrix 𝐑𝐮m.
4.19 Show that the Wiener ﬁlter can be expressed as
𝐡W(; l) =
M
∑
m=
𝐬m(; l)𝐬T
m(; l)
+ 𝜔m(; l) 𝐑𝐱(; l)𝐢i
=
M
∑
m=
𝜔m(; l)
+ 𝜔m(; l)𝐬m(; l)𝐬T
m(; l)𝐑𝐯(; l)𝐢i.
www.ebook3000.com

146
Fundamentals of Signal Enhancement and Array Signal Processing
4.20 Show that the MVDR ﬁlter can be expressed as
𝐡MVDR(; l) = 𝐒′(; l)𝐒′T(; l)𝐑𝐯(; l)𝐢i
=
Pl
∑
p=
𝐬p(; l)𝐬T
p (; l)𝐑𝐯(; l)𝐢i.
4.21 Show that the MVDR ﬁlter can be expressed as
𝐡MVDR(; l) =
Pl
∑
p=
𝐬p(; l)𝐬T
p (; l)
𝜔p(; l)
𝐑𝐱(; l)𝐢i.
4.22 Show that the lth spectral mode output SNR of the MVDR ﬁlter is not larger than
that of the Wiener ﬁlter:
oSNR [𝐡MVDR(; l)] ≤oSNR [𝐡W(; l)] .
4.23 Show that with the controlled distortion ﬁlters, we have
oSNR [𝐡CD,Pl(; l)] ≤oSNR [𝐡CD,Pl−(; l)] ≤⋯≤oSNR [𝐡CD,(; l)]
and
= 𝜐d
[
𝐡CD,Pl(; l)
]
≤𝜐d
[
𝐡CD,Pl−(; l)
]
≤⋯≤𝜐d
[
𝐡CD,(; l)
]
.
4.24 Show that the tradeoﬀﬁlter is given by
𝐡T,𝜇(; l) =
M
∑
m=
𝜔m(; l)
𝜇+ 𝜔m(; l)𝐬m(; l)𝐬T
m(; l)𝐑𝐯(; l)𝐢i,
where 𝜇≥is a Lagrange multiplier.
4.25 Show that in the case of a rank deﬁcient noise correlation matrix,
a) the distortion-based MSE can be written as
Jd
(𝐀) = tr
(
𝐑𝐱−𝐀𝐐′′T
𝐯𝐑𝐱𝐈T
i + 𝐀𝐐′′T
𝐯𝐑𝐱𝐐′′
𝐯𝐀T)
b) and the minimization of Jd
(
𝐀
)
yields the optimal inﬁnite noise reduction
ﬁltering matrix:
𝐇∞= 𝐈i𝐑𝐱𝐐′′
𝐯
(
𝐐′′T
𝐯𝐑𝐱𝐐′′
𝐯
)−
𝐐′′T
𝐯.

Multichannel Signal Enhancement in the Time Domain
147
4.26 Show that in the case of a rank deﬁcient noise correlation matrix,
a) the MSE of the residual noise can be written as
Jn
(𝐇) = tr
(
𝐑𝐯−𝐀𝐯𝐐′′T
𝐱𝐑𝐯𝐈T
i + 𝐀𝐯𝐐′′T
𝐱𝐑𝐯𝐐′′
𝐱𝐀T
𝐯
)
b) and the minimization of Jn
(𝐇) yields the optimal distortionless ﬁltering
matrix:
𝐇DL = 𝐈i −𝐈i𝐑𝐯𝐐′′
𝐱
(
𝐐′′T
𝐱𝐑𝐯𝐐′′
𝐱
)−
𝐐′′T
𝐱.
References
1 J. Benesty, J. Chen, and Y. Huang, Microphone Array Signal Processing. Berlin,
Germany: Springer-Verlag, .
2 M. Brandstein and D. B. Ward, Eds., Microphone Arrays: Signal Processing Techniques
and Applications. Berlin, Germany: Springer-Verlag, .
3 J. Benesty and J. Chen, Optimal Time-Domain Noise Reduction Filters – A Theoretical
Study. Springer Briefs in Electrical and Computer Engineering, .
4 J. N. Franklin, Matrix Theory. Englewood Cliﬀs, NJ: Prentice-Hall, .
5 J. Benesty, M. G. Christensen, and J. R. Jensen, Signal Enhancement with Variable Span
Linear Filters. Berlin, Germany: Springer-Verlag, .
6 J. R. Jensen, J. Benesty, and M. G. Christensen, “Noise reduction with optimal variable
span linear ﬁlters,” IEEE/ACM Trans. Audio, Speech, Language Process., vol. , pp.
–, Apr. .
7 J. Benesty, J. R. Jensen, M. G. Christensen, and J. Chen, Speech Enhancement – A Signal
Subspace Perspective. Academic Press, .
8 P. C. Hansen and S. H. Jensen, “Prewhitening for rank-deﬁcient noise in subspace
methods for noise reduction,” IEEE Trans. Signal Process., vol. , pp. –, Oct.
.
9 G. H. Golub and C. F. Van Loan, Matrix Computations, rd edn. Baltimore, MD: The
Johns Hopkins University Press, .
10 S. M. Nørholm, J. Benesty, J. R. Jensen, and M. G. Christensen, “Single-channel noise
reduction using uniﬁed joint diagonalization and optimal ﬁltering,” EURASIP J.
Advances Signal Process., vol. , pp. –, .
www.ebook3000.com

149
5
Multichannel Signal Enhancement in the Frequency Domain
Signal enhancement with multiple sensors or multichannel signal enhancement in the
frequency domain is an important part of array signal processing. This chapter deals
with this topic. As in the previous chapter, the spatial information is fully exploited
here and in a much more obvious way. We explain the signal model and state the
problem we wish to solve with the conventional linear ﬁltering technique. We then
derive the performance measures and show how to obtain the most well-known optimal
linear ﬁlters. Finally, we give a signal subspace perspective, which can be an instructive
alternative way to look at the problem at hand.
5.1
Signal Model and Problem Formulation
We consider the signal model of the previous chapter, i.e.,
ym(t) = gm(t) ∗x(t) + vm(t)
(.)
= xm(t) + vm(t), m = , , … , M,
where ym(t), xm(t), and vm(t) are, respectively, the observation, convolved desired, and
additive noise signals at the mth sensor, with M being the number of sensors and
the array geometry is completely arbitrary. In the frequency domain, at the frequency
index f , (.) can be expressed as [–]
Ym( f ) = Gm( f )X( f ) + Vm( f )
(.)
= Xm( f ) + Vm( f ), m = , , … , M,
where Ym( f ), Gm( f ), X( f ), Vm( f ), and Xm( f ) = Gm( f )X( f ) are the frequency-domain
representations of ym(t), gm(t), x(t), vm(t), and xm(t) = gm(t) ∗x(t), respectively. It is
clear that Xm( f ) and Vm( f ), which are assumed to be zero mean and uncorrelated, are
the frequency-domain desired and noise signals, respectively. Sensor is the reference,
so the objective of multichannel noise reduction in the frequency domain is to estimate
the desired signal, X( f ), from the M observations Ym( f ), m = , , … , M, in the best
possible way.
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing

150
Fundamentals of Signal Enhancement and Array Signal Processing
It is more convenient to write the M frequency-domain sensors’ signals in a vector
notation:
𝐲( f ) = 𝐠( f )X( f ) + 𝐯( f )
(.)
= 𝐱( f ) + 𝐯( f )
= 𝐝( f )X( f ) + 𝐯( f ),
where
𝐲( f ) = [ Y( f )
Y( f )
⋯
YM( f ) ]T ,
𝐱( f ) =
[ X( f )
X( f )
⋯
XM( f ) ]T
= X( f )𝐠( f ),
𝐠( f ) =
[ G( f )
G( f )
⋯
GM( f ) ]T ,
𝐯( f ) = [ V( f )
V( f )
⋯
VM( f ) ]T ,
and
𝐝( f ) =
[

G( f )
G( f )
⋯
GM( f )
G( f )
]T
(.)
= 𝐠( f )
G( f ).
Expression (.) depends explicitly on the desired signal, X( f ); as a result, (.) is the
frequency-domain signal model for noise reduction. The vector 𝐝( f ) can be seen as
the steering vector for noise reduction [] since the acoustic impulse responses ratios
from the broadband source to the aperture convey information about the position of
the source.
There is another useful way to write (.). First, it is easy to see that
Xm( f ) = 𝛾∗
XXm( f )X( f ), m = , , … , M,
(.)
where
𝛾XXm( f ) =
E [X( f )X∗
m( f )]
E
[
||X( f )||
]
(.)
=
G∗
m( f )
G∗
( f ) , m = , , … , M
is the partially normalized [with respect to X( f )] coherence function between X( f )
and Xm( f ). Using (.), we can rewrite (.) as
𝐲( f ) = 𝜸∗
X𝐱( f )X( f ) + 𝐯( f ),
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
151
where
𝜸X𝐱( f ) = [ 
𝛾XX( f )
⋯
𝛾XXM( f ) ]T
(.)
=
E
[
X( f )𝐱∗( f )
]
E
[
||X( f )||
]
= 𝐝∗( f )
is the partially normalized [with respect to X( f )] coherence vector (of length M)
between X( f ) and 𝐱( f ). In the rest, 𝜸∗
X𝐱( f ) and 𝐝( f ) will be used interchangeably.
By deﬁnition, the signal X( f ) is completely coherent across all sensors [see eq. (.)];
however, V( f ) is usually partially coherent with the noise components, Vm( f ), at the
other sensors. Therefore, any noise term Vm( f ) can be easily decomposed into two
orthogonal components, i.e.,
Vm( f ) = 𝛾∗
VVm( f )V( f ) + V ′
m( f ), m = , , … , M,
(.)
where 𝛾VVm( f ) is the partially normalized [with respect to V( f )] coherence function
between V( f ) and Vm( f ) and
E [V ∗
( f )V ′
m( f )] = , m = , , … , M.
(.)
The vector 𝐯( f ) can then be written as the sum of two other vectors: one coherent with
V( f ) and the other incoherent with V( f ), i.e.,
𝐯( f ) = 𝜸∗
V𝐯( f )V( f ) + 𝐯′( f ),
(.)
where
𝜸V𝐯( f ) = [ 
𝛾VV( f )
⋯
𝛾VVM( f ) ]T
(.)
is the partially normalized [with respect to V( f )] coherence vector (of length M)
between V( f ) and 𝐯( f ) and
𝐯′( f ) = [ 
V ′
( f )
⋯
V ′
M( f ) ]T .
If V( f ) is incoherent with Vm( f ), where m ≠, then 𝛾VVm( f ) = .
Another convenient way to write the sensors’ signals vector is
𝐲( f ) = 𝜸∗
X𝐱( f )X( f ) + 𝜸∗
V𝐯( f )V( f ) + 𝐯′( f ).
(.)
We see that 𝐲( f ) is the sum of three mutual incoherent components. Therefore, the
correlation matrix of 𝐲( f ) is
𝚽𝐲( f ) = E [𝐲( f )𝐲H( f )]
(.)

152
Fundamentals of Signal Enhancement and Array Signal Processing
= 𝜙X( f )𝐝( f )𝐝H( f ) + 𝚽𝐯( f )
= 𝜙X( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f ) + 𝜙V( f )𝜸∗
V𝐯( f )𝜸T
V𝐯( f ) + 𝚽𝐯′( f ),
where the superscript H is the conjugate-transpose operator, 𝜙X( f ) = E
[
||X( f )||
]
and
𝜙V( f ) = E
[
||V( f )||
]
are the variances of X( f ) and V( f ), respectively, and 𝚽𝐯( f ) =
E [𝐯( f )𝐯H( f )] and 𝚽𝐯′( f ) = E [𝐯′( f )𝐯′H( f )] are the correlation matrices of 𝐯( f ) and
𝐯′( f ), respectively. The matrix 𝚽𝐲( f ) is the sum of three other matrices: the ﬁrst two
are of rank equal to and the last one (correlation matrix of the incoherent noise) is
assumed to be of rank equal to M −.
5.2
Linear Filtering
In the frequency domain, conventional multichannel noise reduction is performed by
applying a complex weight to the output of each sensor, at frequency f , and summing
across the aperture (see Figure .):
Z( f ) =
M
∑
m=
H∗
m( f )Ym( f )
(.)
= 𝐡H( f )𝐲( f ),
where Z( f ) is the estimate of X( f ) and
𝐡( f ) =
[ H( f )
H( f )
⋯
HM( f ) ]T
(.)
is a ﬁlter of length M containing all the complex gains applied to the sensors’ outputs at
frequency f .
+
V1 (f)
+
+
...
...
Y1( f )
*
H1 ( f )
*
HM ( f )
Z ( f)
YM ( f )
VM (f)
X1 (f)
XM (f)
Figure 5.1 Block diagram of multichannel linear filtering in the frequency domain.
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
153
We can express (.) as a function of the steering vector, i.e.,
Z( f ) = 𝐡H( f )
[
𝜸∗
X𝐱( f )X( f ) + 𝐯( f )
]
(.)
= Xfd( f ) + Vrn( f ),
where
Xfd( f ) = X( f )𝐡H( f )𝜸∗
X𝐱( f )
(.)
is the ﬁltered desired signal and
Vrn( f ) = 𝐡H( f )𝐯( f )
(.)
is the residual noise. This procedure is called the multichannel signal enhancement
problem in the frequency domain.
The two terms on the right-hand side of (.) are incoherent. Hence, the variance of
Z( f ) is also the sum of two variances:
𝜙Z( f ) = 𝐡H( f )𝚽𝐲( f )𝐡( f )
(.)
= 𝜙Xfd( f ) + 𝜙Vrn( f ),
where
𝜙Xfd( f ) = 𝜙X( f ) |||𝐡H( f )𝜸∗
X𝐱( f )|||

,
(.)
𝜙Vrn( f ) = 𝐡H( f )𝚽𝐯( f )𝐡( f ).
(.)
The diﬀerent variances in (.) are important in the deﬁnitions of the performance
measures.
5.3
Performance Measures
In the frequency domain, we must diﬀerentiate between the narrowband (i.e., single fre-
quency) measures and the broadband (i.e., across the entire frequency range) measures.
In this section, we deﬁne the most useful ones from the signal enhancement perspective.
We recall that sensor is our reference.
5.3.1
Input SNR
The input SNR gives an idea on the level of the noise as compared to the level of the
desired signal at the reference sensor. From (.), it is obvious that the narrowband input
SNR is
iSNR( f ) =
𝜙X( f )
𝜙V( f ).
(.)

154
Fundamentals of Signal Enhancement and Array Signal Processing
From (.), we deduce the broadband input SNR:
iSNR =
∫f 𝜙X( f )df
∫f 𝜙V( f )df
.
(.)
Notice that
iSNR ≠∫f
iSNR( f )df .
(.)
5.3.2
Output SNR
The output SNR quantiﬁes the SNR after performing noise reduction. From (.), we
deduce the narrowband output SNR:
oSNR
[
𝐡( f )
]
=
𝜙Xfd( f )
𝜙Vrn( f )
(.)
=
𝜙X( f ) ||𝐡H( f )𝐝( f )||

𝐡H( f )𝚽𝐯( f )𝐡( f )
and the broadband output SNR:
oSNR (𝐡) =
∫f 𝜙X( f ) ||𝐡H( f )𝐝( f )||
df
∫f 𝐡H( f )𝚽𝐯( f )𝐡( f )df
.
(.)
It is clear that
oSNR (𝐡) ≠∫f
oSNR [𝐡( f )] df .
(.)
Assume that the matrix 𝚽𝐯( f ) is nonsingular. In this case, for the two vectors 𝐡( f )
and 𝐝( f ), we have
|||𝐡H( f )𝐝( f )|||

≤[𝐡H( f )𝚽𝐯( f )𝐡( f )] [𝐝H( f )𝚽−
𝐯( f )𝐝( f )] ,
(.)
with equality if and only if 𝐡( f ) ∝𝚽−
𝐯( f )𝐝( f ). Using the inequality (.) in (.), we
deduce an upper bound for the narrowband output SNR:
oSNR [𝐡( f )] ≤𝜙X( f ) × 𝐝H( f )𝚽−
𝐯( f )𝐝( f ), ∀𝐡( f ).
(.)
For the particular ﬁlter of length M:
𝐡( f ) = 𝐢i =
[ 

⋯
]T ,
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
155
we have
oSNR
[
𝐢i( f )
]
= iSNR( f ),
(.)
oSNR (𝐢i
) = iSNR.
(.)
With the identity ﬁlter, 𝐢i, the output SNRs cannot be improved and
oSNR [𝐢i( f )] ≤𝜙X( f ) × 𝐝H( f )𝚽−
𝐯( f )𝐝( f ),
(.)
which implies that
𝜙V( f ) × 𝐝H( f )𝚽−
𝐯( f )𝐝( f ) ≥.
(.)
Our objective is then to ﬁnd the ﬁlter, 𝐡( f ), within the design constraints, in such
a way that oSNR [𝐡( f )] > iSNR( f ). While the narrowband output SNR is important
when we deal with narrowband and broadband signals, the broadband output SNR is
even more important when we deal with broadband signals such as speech. Therefore,
we also need to make sure ﬁnding 𝐡( f ) in such a way that oSNR (𝐡) > iSNR.
5.3.3
Noise Rejection and Desired Signal Cancellation
The output SNR does not give any hint on the distortion of the desired signal introduced
by the ﬁltering process. Thus, this subsection introduces two measures which treat noise
reduction and signal distortion individually.
The noise reduction factor or noise rejection factor quantiﬁes the amount of noise
being rejected by the ﬁlter. This quantity is deﬁned as the ratio of the power of the noise
at the reference sensor over the power of the noise remaining at the ﬁlter output. We
provide the following deﬁnitions:
●the broadband noise reduction factor,
𝜉n (𝐡) =
∫f 𝜙V( f )df
∫f 𝐡H( f )𝚽𝐯( f )𝐡( f )df
(.)
●and the narrowband noise reduction factor,
𝜉n
[𝐡( f )] =
𝜙V( f )
𝐡H( f )𝚽𝐯( f )𝐡( f ).
(.)
The broadband noise reduction factor is expected to be lower bounded by ; otherwise,
the ﬁlter ampliﬁes the noise received at the senors. The higher the value of the noise
reduction factor, the more the noise is rejected.
In practice, most ﬁltering algorithms distort the desired signal. In order to quantify
the level of this distortion, we deﬁne the desired signal reduction factor or desired signal
cancellation factor as the ratio of the variance of the desired signal at the reference

156
Fundamentals of Signal Enhancement and Array Signal Processing
sensor over the variance of the ﬁltered desired signal at the ﬁlter output. It is easy to
deduce the following mathematical deﬁnitions:
●the broadband desired signal reduction factor,
𝜉d (𝐡) =
∫f 𝜙X( f )df
∫f 𝜙X( f ) ||𝐡H( f )𝐝( f )||
df
(.)
●and the narrowband desired signal reduction factor,
𝜉d
[
𝐡( f )
]
=

||𝐡H( f )𝐝( f )||
.
(.)
Once again, note that
𝜉n (𝐡) ≠∫f
𝜉n
[𝐡( f )] df ,
(.)
𝜉d (𝐡) ≠∫f
𝜉d
[𝐡( f )] df .
(.)
Another key observation is that the design of ﬁlters that do not cancel the broadband
desired signal requires the constraint:
𝐡H( f )𝐝( f ) = .
(.)
Thus, the desired signal reduction factor is equal to if there is no cancellation and
expected to be greater than when cancellation happens.
Lastly, by making the appropriate substitutions, one can derive the following relation-
ships between the output and input SNRs, noise reduction factor, and desired signal
reduction factor:
oSNR (𝐡)
iSNR
= 𝜉n (𝐡)
𝜉d (𝐡),
(.)
oSNR [𝐡( f )]
iSNR( f )
=
𝜉n
[𝐡( f )]
𝜉d
[𝐡( f )].
(.)
5.3.4
Desired Signal Distortion Index
Another useful way to measure the distortion of the desired signal is via the desired
signal distortion index, which is deﬁned as the MSE between the desired signal and
its estimate, normalized by the power of the desired signal. We have the following
deﬁnitions:
●the broadband desired signal distortion index,
𝜐d (𝐡) =
∫f 𝜙X( f ) |||𝐡H( f )𝜸∗
X𝐱( f ) −|||

df
∫f 𝜙X( f )df
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
157
●and the narrowband desired signal distortion index,
𝜐d
[𝐡( f )] =
E
[
||Xfd( f ) −X( f )||
]
𝜙X( f )
(.)
= |||𝐡H( f )𝜸∗
X𝐱( f ) −|||

.
It is interesting to point out that the broadband desired signal distortion index is a linear
combination of the narrowband desired signal distortion indices as the denominator is
simply a scaling factor, i.e.,
𝜐d (𝐡) =
∫f 𝜙X( f )𝜐d
[
𝐡( f )
]
df
∫f 𝜙X( f )df
.
(.)
The distortionless constraint implies that 𝜐d
[
𝐡( f )
]
= , ∀f .
5.3.5
MSE Criterion
We deﬁne the error signal between the estimated and desired signals at frequency f as
(f ) = Z( f ) −X( f )
(.)
= 𝐡H( f )𝐲( f ) −X( f )
= Xfd( f ) + Vrn( f ) −X( f ).
This error can also be expressed as
(f ) = d
(f ) + n
(f ) ,
(.)
where
d
(f ) =
[
𝐡H( f )𝜸∗
X𝐱( f ) −
]
X( f )
(.)
is the desired signal distortion due to the complex ﬁlter and
n
(f ) = 𝐡H( f )𝐯( f )
(.)
represents the residual noise. The error signals d
(f ) and n
(f ) are incoherent. The
narrowband MSE is then
J [𝐡( f )] = E
[|||(f )|||
]
(.)
= 𝜙X( f ) + 𝐡H( f )𝚽𝐲( f )𝐡( f ) −𝜙X( f )𝐡H( f )𝜸∗
X𝐱( f )
−𝜙X( f )𝜸T
X𝐱( f )𝐡( f ),

158
Fundamentals of Signal Enhancement and Array Signal Processing
which can be rewritten as
J
[
𝐡( f )
]
= E
[|||d
(
f
)|||
]
+ E
[|||n
(
f
)|||
]
(.)
= Jd
[𝐡( f )] + Jn
[𝐡( f )] ,
where
Jd
[𝐡( f )] = 𝜙X( f ) |||𝐡H( f )𝜸∗
X𝐱( f ) −|||

(.)
= 𝜙X( f )𝜐d
[
𝐡( f )
]
and
Jn
[
𝐡( f )
]
= 𝐡H( f )𝚽𝐯( f )𝐡( f )
(.)
=
𝜙V( f )
𝜉n
[
𝐡( f )
].
We deduce that
Jd
[𝐡( f )]
Jn
[𝐡( f )] = iSNR( f ) × 𝜉n
[
𝐡( f )
]
× 𝜐d
[
𝐡( f )
]
(.)
= oSNR [𝐡( f )] × 𝜉d
[𝐡( f )] × 𝜐d
[𝐡( f )] .
We observe how the narrowband MSEs are related to the narrowband performance
measures.
Sometimes, it is also important to examine the MSE from the broadband point of
view. We deﬁne the broadband MSE as
J (𝐡) = ∫f
J
[
𝐡( f )
]
df
(.)
= ∫f
Jd
[𝐡( f )] df + ∫f
Jn
[𝐡( f )] df
= Jd (𝐡) + Jn (𝐡) .
It is easy to show the relations between the broadband MSEs and the broadband
performance measures:
Jd (𝐡)
Jn (𝐡) = iSNR × 𝜉n (𝐡) × 𝜐d (𝐡)
= oSNR (𝐡) × 𝜉d (𝐡) × 𝜐d (𝐡) .
(.)
5.4
Optimal Filters
After our discussion on the performance measures and diﬀerent error criteria, we now
have all the necessary tools to begin our search for reliable and practical multichannel
noise reduction ﬁlters. We start with the maximum SNR ﬁlter. Interestingly, this is the
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
159
only optimal ﬁlter that is not derived from an MSE point of view. Nevertheless, it is
strongly related to the other optimal ﬁlters.
5.4.1
Maximum SNR
Let us rewrite the narrowband output SNR:
oSNR [𝐡( f )] =
𝜙X( f )𝐡H( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f )𝐡( f )
𝐡H( f )𝚽𝐯( f )𝐡( f )
.
(.)
The maximum SNR ﬁlter, 𝐡max( f ), is obtained by maximizing the output SNR as
given above. In (.), we recognize the generalized Rayleigh quotient []. It is well
known that this quotient is maximized with the maximum eigenvector of the matrix
𝜙X( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f ). Let us denote by 𝜆( f ) the maximum eigenvalue corre-
sponding to this maximum eigenvector. Since the rank of the mentioned matrix is equal
to , we have
𝜆( f ) = tr
[
𝜙X( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f )
]
(.)
= 𝜙X( f )𝜸T
X𝐱( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f ).
As a result,
oSNR
[
𝐡max( f )
]
= 𝜆( f )
(.)
= oSNRmax( f ),
which corresponds to the maximum possible narrowband output SNR.
Obviously, we also have
𝐡max( f ) = 𝜍( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f ),
(.)
where 𝜍( f ) is an arbitrary frequency-dependent complex number diﬀerent from zero.
While this factor has no eﬀect on the narrowband output SNR, it has on the broadband
output SNR and on the desired signal distortion. In fact, all the ﬁlters (except for the
LCMV) derived in the rest of this section are equivalent up to this complex factor. These
ﬁlters also try to ﬁnd the respective complex factors at each frequency depending on
what we optimize. It is important to understand that while the maximum SNR ﬁlter
maximizes the narrowband output SNR, it certainly does not maximize the broadband
output SNR whose value depends quite a lot on 𝜍( f ).
Let us denote by oSNR(m)
max( f ) the maximum narrowband output SNR of an
array with m sensors. By virtue of the inclusion principle [] for the matrix
𝜙X( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f ), we have
oSNR(M)
max( f ) ≥oSNR(M−)
max ( f ) ≥⋯≥oSNR()
max( f ) ≥
oSNR()
max( f ) = iSNR( f ).
(.)

160
Fundamentals of Signal Enhancement and Array Signal Processing
This shows that by increasing the number of sensors, we necessarily increase the
narrowband output SNR. If there is one sensor only, the narrowband output SNR cannot
be improved as expected.
Example ..
Consider a ULA of M sensors, as shown in Figure .. Suppose that
a desired signal impinges on the ULA from the direction 𝜃, and that an interference
impinges on the ULA from the endﬁre direction (𝜃= ◦). Assume that the desired
signal is a harmonic pulse of T samples:
x(t) =
{
A sin (𝜋ft + 𝜙) ,
≤t ≤T −
,
t < , t ≥T
,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly distributed
on the interval from to 𝜋. Assume that the interference u(t) is white Gaussian noise,
i.e., u(t) ∼(, 𝜎
u
), uncorrelated with x(t). In addition, the sensors contain thermal
white Gaussian noise, wm(t) ∼(, 𝜎
w
), that are mutually uncorrelated. The desired
signal needs to be recovered from the noisy received signals, ym(t) = xm(t) + vm(t),
m = , … , M, where vm(t) = um(t) + wm(t), m = , … , M are the interference-plus-
noise signals.
As in Example .., we choose a sampling interval Ts that satisﬁes Ts = d
c . Hence,
the desired signal at sensor m is a delayed version of the desired signal at the ﬁrst sensor:
xm(t) = x
(t −𝜏m
) ,
where
𝜏m = (m −)d cos 𝜃
cTs
= (m −) cos 𝜃, m = , , … , M
is the relative time delay in samples (not necessarily an integer number) between the
mth sensor and the ﬁrst one. The frequency-domain representation of the desired signal
received at the ﬁrst sensor is given by
X( f ) =
∞
∑
t=−∞
x(t)e𝚥𝜋ft
= A
𝚥e𝚥𝜙+𝚥𝜋(f +f)(T−)DT
[𝜋(f + f
)]
+ A
𝚥e−𝚥𝜙+𝚥𝜋(f −f)(T−)DT
[𝜋(f −f
)] ,
where
DT(x) = sin (Tx)
sin (x) .
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
161
Therefore, the variance of X( f ) is
𝜙X( f ) = A
D
T
[𝜋(f + f
)] + A
D
T
[𝜋(f −f
)] .
Using the vector notation (.), we have
𝐱( f ) = 𝐝( f )X( f ),
𝚽𝐱( f ) = 𝜙X( f )𝐝( f )𝐝H( f ),
where
𝐝( f ) = [

e−𝚥𝜋f 𝜏
e−𝚥𝜋f 𝜏
⋯
e−𝚥𝜋f 𝜏M ]T .
The interference signal at sensor m is also a delayed version of the interference signal
at the ﬁrst sensor:
um(t) = u(t −m + ) .
The frequency-domain representation of the interference signal received at the ﬁrst
sensor is given by
U( f ) =
T−
∑
t=
u(t)e𝚥𝜋ft.
Hence, the variance of U( f ) is 𝜙U( f ) = T𝜎
u. Using the vector notation (.), we have
𝐯( f ) = 𝜸∗
U𝐮( f )U( f ) + 𝐰( f ),
𝚽𝐯( f ) = 𝜙U( f )𝜸∗
U𝐮( f )𝜸T
U𝐮( f ) + T𝜎
w𝐈M,
where
𝜸∗
U𝐮( f ) = [

e−𝚥𝜋f
e−𝚥𝜋f 
⋯
e−𝚥𝜋f (M−) ]T
and 𝐈M is the M × M identity matrix.
The narrowband and broadband input SNRs are, respectively,
iSNR( f ) =
𝜙X( f )
𝜙V( f )
=
A
T
(
𝜎
u + 𝜎
w
)D
T
[𝜋(f + f
)]
+
A
T
(
𝜎
u + 𝜎
w
)D
T
[𝜋(f −f
)]

162
Fundamentals of Signal Enhancement and Array Signal Processing
and
iSNR =
∫f 𝜙X( f )df
∫f 𝜙V( f )df
=
∑
t E
[
||x(t)||
]
∑
t E
[
||v(t)||
]
=
A
(𝜎
u + 𝜎
w
),
where we have used Parseval’s identity. The maximum SNR ﬁlter, 𝐡max( f ), is obtained
from (.). Using (.), we can write the narrowband gain in SNR as
[𝐡max( f )] =
oSNR
[
𝐡max( f )
]
iSNR( f )
= 𝐝H( f )
[
𝜎
u
𝜎
u + 𝜎
w
𝜸∗
U𝐮( f )𝜸T
U𝐮( f ) +
𝜎
w
𝜎
u + 𝜎
w
𝐈M
]−
𝐝( f ).
To demonstrate the performance of the maximum SNR ﬁlter, we choose 𝜎
w = .𝜎
u.
Figure .shows the eﬀect of the number of sensors, M, on the narrowband gain in SNR,

[
𝐡max( f )
]
, for diﬀerent incidence angles of the desired signal and diﬀerent frequencies.
For a single sensor (M = ), there is no narrowband gain in SNR. As the number of
sensors increases, the narrowband gain in SNR increases.
■
5.4.2
Wiener
The Wiener ﬁlter is found by minimizing the narrowband MSE, J [𝐡( f )] [eq. (.)].
We get
𝐡W( f ) = 𝜙X( f )𝚽−
𝐲( f )𝜸∗
X𝐱( f ).
(.)
Let
𝚪𝐲( f ) =
𝚽𝐲( f )
𝜙Y( f )
(.)
be the pseudo-coherence matrix of the observations, we can rewrite (.) as
𝐡W( f ) =
iSNR( f )
+ iSNR( f )𝚪−
𝐲( f )𝜸∗
X𝐱( f )
(.)
= HW( f )𝚪−
𝐲( f )𝜸∗
X𝐱( f ),
where
HW( f ) =
iSNR( f )
+ iSNR( f )
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
163
5
10
15
20
0
10
20
30
40
50
60
(a)
(b)
(c)
(d)
5
10
15
20
0
10
20
30
40
50
60
5
10
15
20
0
10
20
30
40
50
60
5
10
15
20
0
10
20
30
40
50
60
M
M
M
M
 [hmax(f)] (dB)
 [hmax(f)] (dB)
 [hmax(f)] (dB)
 [hmax(f)] (dB)
Figure 5.2 Narrowband gain in SNR of the maximum SNR filter as a function of the number of sensors,
M, for different incidence angles of the desired signal and different frequencies: 𝜃0 = 30◦(circles),
𝜃0 = 50◦(asterisks), 𝜃0 = 70◦(squares), and 𝜃0 = 90◦(triangles); (a) f = 0.01, (b) f = 0.05, (c) f = 0.1,
and (d) f = 0.2.
is the (single-channel) Wiener gain and 𝚪−
𝐲( f )𝜸∗
X𝐱( f ) is the spatial information vector.
The decomposition in (.) is very useful; it shows separately the inﬂuence of the
spectral and spatial processing on multichannel signal enhancement.
We can express (.) diﬀerently, i.e.,
𝐡W( f ) = 𝚽−
𝐲( f )E
[
𝐱( f )X∗
( f )
]
(.)
= 𝚽−
𝐲( f )𝚽𝐱( f )𝐢i
=
[
𝐈M −𝚽−
𝐲( f )𝚽𝐯( f )
]
𝐢i.
In this form, the Wiener ﬁlter relies on the second-order statistics of the observation
and noise signals.
We can write the general form of the Wiener ﬁlter in another way that will make it
easier to compare to other optimal ﬁlters. We know that
𝚽𝐲( f ) = 𝜙X( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f ) + 𝚽𝐯( f ).
(.)

164
Fundamentals of Signal Enhancement and Array Signal Processing
Determining the inverse of 𝚽𝐲( f ) from the previous expression with the Woodbury’s
identity, we get
𝚽−
𝐲( f ) = 𝚽−
𝐯( f ) −
𝚽−
𝐯( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f )𝚽−
𝐯( f )
𝜙−
X( f ) + 𝜸T
X𝐱( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )
.
(.)
Substituting (.) into (.) gives
𝐡W( f ) =
𝜙X( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )
+ 𝜙X( f )𝜸T
X𝐱( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )
,
(.)
that we can rewrite as
𝐡W( f ) =
𝚽−
𝐯( f ) [𝚽𝐲( f ) −𝚽𝐯( f )]
+ tr {𝚽−
𝐯( f ) [𝚽𝐲( f ) −𝚽𝐯( f )]}𝐢i
(.)
=
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
−M + tr [𝚽−
𝐯( f )𝚽𝐲( f )]𝐢i.
Comparing (.) with (.), we see that in the former, we invert the correlation matrix
of the observations, while in the latter, we invert the correlation matrix of the noise.
We can express 𝐡W( f ) as a function of the narrowband input SNR and the pseudo-
coherence matrices, i.e.,
𝐡W( f ) =
[
+ iSNR( f )
]
𝚪−
𝐯( f )𝚪𝐲( f ) −𝐈M
−M + [+ iSNR( f )] tr [𝚪−
𝐯( f )𝚪𝐲( f )]𝐢i,
(.)
where
𝚪𝐯( f ) = 𝚽𝐯( f )
𝜙V( f ).
(.)
From (.), we deduce that the narrowband output SNR is
oSNR [𝐡W( f )] = 𝜆( f )
(.)
= tr [𝚽−
𝐯( f )𝚽𝐲( f )] −M
and, obviously,
oSNR [𝐡W( f )] ≥iSNR( f ),
(.)
since the Wiener ﬁlter maximizes the narrowband output SNR.
The desired signal distortion indices are
𝜐d
[
𝐡W( f )
]
=

[+ 𝜆( f )],
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
165
𝜐d
(𝐡W
) =
∫f 𝜙X( f ) [+ 𝜆( f )]−df
∫f 𝜙X( f )df
.
(.)
The higher the value of 𝜆( f ) (and/or the number of sensors), the less the desired signal
is distorted.
It is also easy to ﬁnd the noise reduction factors:
𝜉n
[
𝐡W( f )
]
=
[+ 𝜆( f )]
iSNR( f ) × 𝜆( f ),
(.)
𝜉n
(
𝐡W
)
=
∫f 𝜙X( f )iSNR−( f )df
∫f 𝜙X( f )𝜆( f ) [+ 𝜆( f )]−df
,
(.)
and the desired signal reduction factors:
𝜉d
[𝐡W( f )] =
[+ 𝜆( f )]
𝜆
( f )
,
(.)
𝜉d
(𝐡W
) =
∫f 𝜙X( f )df
∫f 𝜙X( f )𝜆
( f )
[
+ 𝜆( f )
]−df
.
(.)
The broadband output SNR of the Wiener ﬁlter is
oSNR (𝐡W
) =
∫f
𝜙X( f )
𝜆
( f )
[
+ 𝜆( f )
]df
∫f
𝜙X( f )
𝜆( f )
[+ 𝜆( f )]df
.
(.)
Property ..
With the frequency-domain multichannel Wiener ﬁlter given in
(.), the broadband output SNR is always greater than or equal to the broadband
input SNR, i.e., oSNR (𝐡W
) ≥iSNR.
Proof. See Subsection ...
It is interesting to see that the two ﬁlters 𝐡W( f ) and 𝐡max( f ) diﬀer only by a real-valued
factor. Indeed, taking
𝜍( f ) =
𝜙X( f )
+ 𝜆( f )
(.)
in (.) (maximum SNR ﬁlter), we ﬁnd (.) (Wiener ﬁlter).
■
Example ..
Returning to Example .., we now employ the Wiener ﬁlter, 𝐡W( f ),
given in (.). To demonstrate the performance of the Wiener ﬁlter, we choose A = .,
f= ., T = , 𝜃= ◦, and 𝜎
w = .𝜎
u. Figure .shows plots of the broadband

166
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
5
10
15
20
25
30
35
(a)
(b)
(c)
(d)
−5
0
5
10
15
−25
−20
−15
−10
−5
0
5
10
−5
0
5
10
15
5
10
15
20
25
30
35
−5
0
5
10
15
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
 (hW) (dB)
J (hW) (dB)
ξd (hW) (dB)
ξn (hW) (dB)
Figure 5.3 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise reduction
factor, and (d) the broadband desired signal reduction factor of the Wiener filter as a function of the
broadband input SNR, for different numbers of sensors, M: M = 1 (solid line with circles), M = 2
(dashed line with asterisks), M = 5 (dotted line with squares), and M = 10 (dash-dot line with
triangles).
gain in SNR, (𝐡W
), the broadband MSE, J (𝐡W
), the broadband noise reduction factor,
𝜉n
(𝐡W
), and the broadband desired signal reduction factor, 𝜉d
(𝐡W
), as a function of the
broadband input SNR, for diﬀerent numbers of sensors. For a given broadband input
SNR, as the number of sensors increases, the broadband gain in SNR and the broadband
noise reduction factor increase, while the broadband MMSE and the broadband desired
signal reduction factor decrease.
Figure .shows a realization of the frequency-domain noise corrupted signal
received at the ﬁrst sensor, ||Y( f )||, and the error signals |||
(
f
)||| = ||Z( f ) −X( f )|| for
iSNR = −dB and diﬀerent numbers of sensors. Figure .shows the corresponding
time-domain observation signal at the ﬁrst sensor, y(t), and the time-domain estimated
signals, z(t). Obviously, as the number of sensors increases, the Wiener ﬁlter better
enhances the desired signal.
■
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
167
−0.5 −0.4 −0.3 −0.2 −0.1
0
f
f
f
f
0.1 0.2 0.3 0.4 0.5
0
20
40
60
80
100
120
140
(a)
(b)
(c)
(d)
−0.5 −0.4 −0.3 −0.2 −0.1
0
0.1
0.2
0.3
0.4
0.5
0
5
10
15
20
−0.5 −0.4 −0.3 −0.2 −0.1
0
0.1
0.2
0.3
0.4
0.5
0
5
10
15
20
−0.5 −0.4 −0.3 −0.2 −0.1
0
0.1
0.2
0.3
0.4
0.5
0
5
10
15
20
|Y1( f )|
|Ɛ ( f )|
|Ɛ (f )|
|Ɛ (f )|
Figure 5.4 Example of frequency-domain noise corrupted and error signals of the Wiener filter for
different numbers of sensors, M: (a) magnitude of the frequency-domain observation signal at the
first sensor, ||Y1( f)|| (iSNR = −5 dB), and magnitude of the frequency-domain error signals,
|(f)| = ||Z( f) −X1( f)|| for (b) M = 1 [oSNR (𝗵W
) = 14.2 dB], (c) M = 2 [oSNR (𝗵W
) = 19.2 dB], and
(d) M = 5 [oSNR (𝗵W
) = 25.5 dB].
5.4.3
MVDR
The well-known MVDR ﬁlter proposed by Capon [, ] is easily derived by minimizing
the narrowband MSE of the residual noise, Jn
[𝐡( f )], with the constraint that the desired
signal is not distorted. Mathematically, this is equivalent to
min
𝐡( f ) 𝐡H( f )𝚽𝐯( f )𝐡( f ) subject to 𝐡H( f )𝜸∗
X𝐱( f ) = ,
(.)
for which the solution is
𝐡MVDR( f ) =
𝚽−
𝐯( f )𝜸∗
X𝐱( f )
𝜸T
X𝐱( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )
.
(.)

168
Fundamentals of Signal Enhancement and Array Signal Processing
0
100
200
300
400
500
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
(a)
(b)
(c)
(d)
0
100
200
300
400
500
−1
−0.5
0
0.5
1
0
100
200
300
400
500
−1
−0.5
0
0.5
1
0
100
200
300
400
500
−1
−0.5
0
0.5
1
t
y1 (t)
z (t)
z (t)
z (t)
t
t
t
Figure 5.5 Example of time-domain noise corrupted and Wiener filtered sinusoidal signals for
different numbers of sensors, M: (a) time-domain observation signal at the first sensor, y1(t)
(iSNR = −5 dB), and time-domain estimated signal, z(t), for (b) M = 1 [oSNR (𝗵W
) = 14.2 dB], (c) M = 2
[oSNR (𝗵W
) = 19.2 dB], and (d) M = 5 [oSNR (𝗵W
) = 25.5 dB].
Using the fact that 𝚽𝐱( f ) = 𝜙X( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f ), the explicit dependence of the above
ﬁlter on the steering vector is eliminated to obtain the following forms:
𝐡MVDR( f ) =
𝚽−
𝐯( f )𝚽𝐱( f )
𝜆( f )
𝐢i
(.)
=
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
tr [𝚽−
𝐯( f )𝚽𝐲( f )] −M
𝐢i
=
[+ iSNR( f )] 𝚪−
𝐯( f )𝚪𝐲( f ) −𝐈M
[
+ iSNR( f )
]
tr
[
𝚪−
𝐯( f )𝚪𝐲( f )
]
−M
𝐢i.
Alternatively, we can also write the MVDR as
𝐡MVDR( f ) =
𝚽−
𝐲( f )𝜸∗
X𝐱( f )
𝜸T
X𝐱( f )𝚽−
𝐲( f )𝜸∗
X𝐱( f )
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
169
=
𝚪−
𝐲( f )𝜸∗
X𝐱( f )
𝜸T
X𝐱( f )𝚪−
𝐲( f )𝜸∗
X𝐱( f )
.
Taking
𝜍( f ) =
𝜙X( f )
𝜆( f )
(.)
in (.) (maximum SNR ﬁlter), we ﬁnd (.) (MVDR ﬁlter), showing how the maxi-
mum SNR and MVDR ﬁlters are equivalent up to a real-valued factor.
The Wiener and MVDR ﬁlters are simply related as follows:
𝐡W( f ) = CW( f )𝐡MVDR( f ),
(.)
where
CW( f ) = 𝐡H
W( f )𝜸∗
X𝐱( f )
(.)
=
𝜆( f )
+ 𝜆( f )
can be seen as a single-channel frequency-domain Wiener gain. In fact, any ﬁlter of the
form:
𝐡( f ) = C( f )𝐡MVDR( f ),
(.)
where C( f ) is a real number, with < C( f ) < , removes more noise than the MVDR
ﬁlter at the price of some desired signal distortion, which is
𝜉d
[𝐡( f )] =

C( f )
(.)
or
𝜐d
[𝐡( f )] = [C( f ) −].
(.)
It can be veriﬁed that we always have
oSNR [𝐡MVDR( f )] = oSNR [𝐡W( f )] ,
(.)
𝜐d
[
𝐡MVDR( f )
]
= ,
(.)
𝜉d
[𝐡MVDR( f )] = ,
(.)
and
𝜉n
[𝐡MVDR( f )] ≤𝜉n
[𝐡W( f )] ,
(.)
𝜉n
(
𝐡MVDR
)
≤𝜉n
(
𝐡W
)
.
(.)

170
Fundamentals of Signal Enhancement and Array Signal Processing
The MVDR ﬁlter rejects the maximum level of noise allowable without distorting the
desired signal at each frequency.
While the narrowband output SNRs of the Wiener and MVDR are strictly equal, their
broadband output SNRs are not. The broadband output SNR of the MVDR is
oSNR (𝐡MVDR
) =
∫f 𝜙X( f )df
∫f 𝜙X( f )𝜆−
( f )df
(.)
and
oSNR (𝐡MVDR
) ≤oSNR (𝐡W
) .
(.)
Property ..
With the frequency-domain MVDR ﬁlter given in (.), the broad-
band output SNR is always greater than or equal to the broadband input SNR, i.e.,
oSNR (𝐡MVDR
) ≥iSNR.
Proof. See Subsection ...
■
Example ..
Returning to Example .., we now employ the MVDR ﬁlter,
𝐡MVDR( f ), given in (.). Figure .shows plots of the broadband gain in SNR,
(𝐡MVDR
), the broadband MSE, J (𝐡MVDR
), the broadband noise reduction factor,
𝜉n
(
𝐡MVDR
)
, and the broadband desired signal reduction factor, 𝜉d
(
𝐡MVDR
)
, as a function
of the broadband input SNR, for diﬀerent numbers of sensors. For a given broadband
input SNR, as the number of sensors increases, the broadband gain in SNR and the
broadband noise reduction factor increase, while the broadband MSE decreases.
■
5.4.4
Tradeoff
As we have learned from the previous subsections, not much ﬂexibility is associated
with the Wiener and MVDR ﬁlters in the sense that we do not know in advance by
how much the narrowband output SNR will be improved. However, in many practical
situations, we wish to control the compromise between noise reduction and desired
signal distortion, and one possible way to do this is via the so-called tradeoﬀﬁlter.
In the tradeoﬀapproach, we minimize the narrowband desired signal distortion index
with the constraint that the narrowband noise reduction factor is equal to a positive
value that is greater than . Mathematically, this is equivalent to
min
𝐡( f ) Jd
[𝐡( f )]
subject to Jn
[𝐡( f )] = ℵ𝜙V( f ),
(.)
where < ℵ< to ensure that we get some noise reduction. By using a Lagrange
multiplier, 𝜇> , to adjoin the constraint to the cost function, we easily deduce the
tradeoﬀﬁlter:
𝐡T,𝜇( f ) = 𝜙X( f )
[
𝚽𝐱( f ) + 𝜇𝚽𝐯( f )
]−𝜸∗
X𝐱( f )
(.)
=
𝜙X( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )
𝜇+ 𝜙X( f )𝜸T
X𝐱( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
171
−5
0
5
10
15
0
5
10
15
20
25
(a)
(c)
(d)
(b)
−5
0
5
10
15
−20
−10
0
10
20
30
−5
0
5
10
15
−5
0
5
10
15
20
25
−5
0
5
10
15
−1
−0.5
0
0.5
1
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
J (hMVDR) (dB)
ξn (hMVDR) (dB)
ξd (hMVDR) (dB)
 (hMVDR) (dB)
Figure 5.6 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise reduction
factor, and (d) the broadband desired signal reduction factor of the MVDR filter as a function of the
broadband input SNR, for different numbers of sensors, M: M = 1 (solid line with circles), M = 2
(dashed line with asterisks), M = 5 (dotted line with squares), and M = 10 (dash-dot line with
triangles).
=
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
𝜇−M + tr
[
𝚽−
𝐯( f )𝚽𝐲( f )
]𝐢i,
where the Lagrange multiplier, 𝜇, satisﬁes
Jn
[
𝐡T,𝜇( f )
]
= ℵ𝜙V( f ).
(.)
However, in practice it is not easy to determine the optimal 𝜇. Therefore, when this
parameter is chosen in a heuristic way, we can see that for
●𝜇= , 𝐡T,( f ) = 𝐡W( f ), which is the Wiener ﬁlter;
●𝜇= , 𝐡T,( f ) = 𝐡MVDR( f ), which is the MVDR ﬁlter;
●𝜇> , results in a ﬁlter with low residual noise at the expense of high desired signal
distortion (as compared to Wiener); and
●𝜇< , results in a ﬁlter with high residual noise and low desired signal distortion (as
compared to Wiener).

172
Fundamentals of Signal Enhancement and Array Signal Processing
Note that the MVDR cannot be derived from the ﬁrst line of (.) since by taking
𝜇= , we have to invert a matrix that is not full rank.
It can be observed that the tradeoﬀ, Wiener, and maximum SNR ﬁlters are equivalent
up to a real-valued number. As a result, the narrowband output SNR of the tradeoﬀﬁlter
is independent of 𝜇and is identical to the narrowband output SNR of the maximum SNR
ﬁlter, i.e.,
oSNR [𝐡T,𝜇( f )] = oSNR [𝐡max( f )] , ∀𝜇≥.
(.)
We have
𝜐d
[𝐡T,𝜇( f )] =
[
𝜇
𝜇+ 𝜆( f )
]
,
(.)
𝜉d
[
𝐡T,𝜇( f )
]
=
[
+
𝜇
𝜆( f )
]
,
(.)
𝜉n
[𝐡T,𝜇( f )] =
[
𝜇+ 𝜆( f )
]
iSNR( f ) × 𝜆( f ).
(.)
The tradeoﬀﬁlter is useful from several perspectives since it encompasses both the
Wiener and MVDR ﬁlters. It is then useful to study the broadband output SNR and the
broadband desired signal distortion index of the tradeoﬀﬁlter.
It can be veriﬁed that the broadband output SNR of the tradeoﬀﬁlter is
oSNR
(
𝐡T,𝜇
)
=
∫f
𝜙X( f )
𝜆
( f )
[𝜇+ 𝜆( f )]df
∫f
𝜙X( f )
𝜆( f )
[
𝜇+ 𝜆( f )
]df
.
(.)
We propose the following [].
Property ..
The broadband output SNR of the tradeoﬀﬁlter is an increasing
function of the parameter 𝜇.
Proof. We need to show that
doSNR
(
𝐡T,𝜇
)
d𝜇
≥.
(.)
The proof showing (.) is identical to the one given in []. But for completeness, we
show it here again.
We have
doSNR (𝐡T,𝜇
)
d𝜇
= Num(𝜇)
Den(𝜇) ,
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
173
where
Num(𝜇) = −∫f
𝜙X( f )𝜆( f )
[
𝜇+ 𝜆( f )
]df ∫f
𝜙X( f )𝜆
( f )
[
𝜇+ 𝜆( f )
]df +
∫f
𝜙X( f )𝜆
( f )
[
𝜇+ 𝜆( f )
]df ∫f
𝜙X( f )𝜆( f )
[
𝜇+ 𝜆( f )
]df
(.)
and
Den(𝜇) =
{
∫f
𝜙X( f )𝜆( f )
[𝜇+ 𝜆( f )]df
}
.
(.)
We only focus on the numerator of the above derivative to see the variations of the
broadband output SNR since the denominator is always positive. Multiplying and
dividing by 𝜇+ 𝜆( f ), this numerator can be rewritten as
Num(𝜇) = −∫f
𝜙X( f )𝜆( f ) [𝜇+ 𝜆( f )]
[𝜇+ 𝜆( f )]
df ∫f
𝜙X( f )𝜆
( f )
[𝜇+ 𝜆( f )]df
+ ∫f
𝜙X( f )𝜆
( f )
[
𝜇+ 𝜆( f )
]
[𝜇+ 𝜆( f )]
df ∫f
𝜙X( f )𝜆( f )
[𝜇+ 𝜆( f )]df
= −
{
∫f
𝜙X( f )𝜆
( f )
[𝜇+ 𝜆( f )]df
}
−𝜇∫f
𝜙X( f )𝜆( f )
[𝜇+ 𝜆( f )]df ∫f
𝜙X( f )𝜆
( f )
[𝜇+ 𝜆( f )]df
+ ∫f
𝜙X( f )𝜆
( f )
[𝜇+ 𝜆( f )]df ∫f
𝜙X( f )𝜆( f )
[𝜇+ 𝜆( f )]df
+ 𝜇∫f
𝜙X( f )𝜆( f )
[𝜇+ 𝜆( f )]df ∫f
𝜙X( f )𝜆
( f )
[𝜇+ 𝜆( f )]df
= −
{
∫f
𝜙X( f )𝜆
( f )
[𝜇+ 𝜆( f )]df
}
+ ∫f
𝜙X( f )𝜆
( f )
[
𝜇+ 𝜆( f )
]df ∫f
𝜙X( f )𝜆( f )
[
𝜇+ 𝜆( f )
]df .
(.)
As far as 𝜇, 𝜆( f ), and 𝜙X( f ) are positive ∀f , we can use the Cauchy-Schwarz inequality:
∫f
𝜙X( f )𝜆
( f )
[𝜇+ 𝜆( f )]df ∫f
𝜙X( f )𝜆( f )
[𝜇+ 𝜆( f )]df

174
Fundamentals of Signal Enhancement and Array Signal Processing
≥
⎧
⎪
⎨
⎪⎩
∫f
√
√
√
√𝜙X( f )𝜆
( f )
[
𝜇+ 𝜆( f )
]
√
√
√
√𝜙X( f )𝜆( f )
[
𝜇+ 𝜆( f )
]df
⎫
⎪
⎬
⎪⎭

=
{
∫f
𝜙X( f )𝜆
( f )
[
𝜇+ 𝜆( f )
]df
}
.
(.)
Substituting (.) into (.), we conclude that
doSNR (𝐡T,𝜇
)
d𝜇
≥,
(.)
proving that the broadband output SNR is increasing with respect to 𝜇.
■
From Property .., we deduce that the MVDR ﬁlter gives the smallest broadband
output SNR.
While the broadband output SNR is upper bounded, it is easy to see that the
broadband noise reduction factor and broadband desired signal reduction factor are
not. So when 𝜇goes to inﬁnity, so are 𝜉n
(
𝐡T,𝜇
)
and 𝜉d
(
𝐡T,𝜇
)
.
The broadband desired signal distortion index is
𝜐d
(
𝐡T,𝜇
)
=
∫f
𝜙X( f )
𝜇
[𝜇+ 𝜆( f )]df
∫f 𝜙X( f )df
.
(.)
Property ..
The broadband desired signal distortion index of the tradeoﬀﬁlter is
an increasing function of the parameter 𝜇.
Proof. It is straightforward to verify that
d𝜐d
(𝐡T,𝜇
)
d𝜇
≥,
(.)
which ends the proof.
■
It is clear that
≤𝜐d
(𝐡T,𝜇
) ≤, ∀𝜇≥.
(.)
Therefore, as 𝜇increases, the broadband output SNR increases at the price of more
distortion to the desired signal.
Property ..
With the frequency-domain tradeoﬀﬁlter given in (.), the broad-
band output SNR is always greater than or equal to the broadband input SNR, i.e.,
oSNR (𝐡T,𝜇
) ≥iSNR, ∀𝜇≥.
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
175
Proof. We know that
𝜆( f ) ≥iSNR( f ),
(.)
which implies that
∫f
𝜙V( f )iSNR( f )
𝜆( f ) df ≤∫f
𝜙V( f )df ,
(.)
and, hence,
oSNR
(
𝐡T,
)
=
∫f 𝜙X( f )df
∫f
𝜙V( f )iSNR( f )
𝜆( f ) df
≥
∫f 𝜙X( f )df
∫f 𝜙V( f )df
= iSNR.
(.)
But from Proposition .., we have
oSNR (𝐡T,𝜇
) ≥oSNR (𝐡T,
) , ∀𝜇≥.
(.)
As a result,
oSNR
(
𝐡T,𝜇
)
≥iSNR, ∀𝜇≥,
(.)
which ends the proof.
■
From the previous results, we deduce that for 𝜇≥,
iSNR ≤oSNR (𝐡MVDR
) ≤oSNR (𝐡W
) ≤oSNR (𝐡T,𝜇
) ,
(.)
= 𝜐d
(𝐡MVDR
) ≤𝜐d
(𝐡W
) ≤𝜐d
(𝐡T,𝜇
) ,
(.)
and for ≤𝜇≤,
iSNR ≤oSNR (𝐡MVDR
) ≤oSNR (𝐡T,𝜇
) ≤oSNR (𝐡W
) ,
(.)
= 𝜐d
(
𝐡MVDR
)
≤𝜐d
(
𝐡T,𝜇
)
≤𝜐d
(
𝐡W
)
.
(.)
Example ..
Returning to Example .., we now employ the tradeoﬀﬁlter, 𝐡T,𝜇( f ),
given in (.). We assume M = sensors. Figure .shows plots of the broadband
gain in SNR, (𝐡T,𝜇
), the broadband desired signal distortion index, 𝜐d
(𝐡T,𝜇
), the
broadband noise reduction factor, 𝜉n
(𝐡T,𝜇
), and the broadband desired signal reduction
factor, 𝜉d
(
𝐡T,𝜇
)
, as a function of the broadband input SNR, for several values of 𝜇.
For a given broadband input SNR, the higher is the value of 𝜇, the higher are the
broadband gain in SNR and the broadband noise reduction factor, but at the expense of
higher broadband desired signal distortion index and higher broadband desired signal
reduction factor.
■

176
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
18
20
22
24
26
28
30
32
34
(a)
(b)
(c)
(d)
−5
0
5
10
15
−45
−40
−35
−30
−25
−20
−5
0
5
10
15
18
20
22
24
26
28
30
32
34
−5
0
5
10
15
0
0.02
0.04
0.06
0.08
0.1
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(hT, μ) (dB)
(hT, μ) (dB)
(hT, μ) (dB)
ξn
(hT, μ) (dB)
ξd
d
Figure 5.7 (a) The broadband gain in SNR, (b) the broadband desired signal distortion index, (c) the
broadband noise reduction factor, and (d) the broadband desired signal reduction factor of the
tradeoff filter as a function of the broadband input SNR, for several values of 𝜇: 𝜇= 0.5 (solid line with
circles), 𝜇= 1 (dashed line with asterisks), 𝜇= 2 (dotted line with squares), and 𝜇= 5 (dash-dot line
with triangles).
5.4.5
LCMV
In the Wiener, MVDR, and tradeoﬀﬁlters, we have fully exploited the structure of
the desired signal vector, 𝐱( f ). In this subsection, we are going to exploit as well the
structure of the noise signal vector, 𝐯( f ), in order to derive the linearly constrained
minimum variance (LCMV) ﬁlter [–], which can handle more than one constraint.
Our problem this time is the following. We wish to perfectly recover our desired signal,
X( f ), and completely remove the coherent components, 𝜸∗
V𝐯( f )V( f ) [see eq. (.)].
Thus, the two constraints can be put together in a matrix form as
𝐂H
XV( f )𝐡( f ) =
[


]
,
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
177
where
𝐂XV( f ) =
[
𝜸∗
X𝐱( f )
𝜸∗
V𝐯( f )
]
(.)
is our constraint matrix of size M×. Then, our optimal ﬁlter is obtained by minimizing
the energy at the ﬁlter output, with the constraints that the coherent noise components
are cancelled and the desired signal is preserved, i.e.,
𝐡LCMV( f ) = arg min
𝐡( f ) 𝐡H( f )𝚽𝐲( f )𝐡( f ) subject to
𝐂H
XV( f )𝐡( f ) =
[


]
.
(.)
The solution to (.) is given by
𝐡LCMV( f ) = 𝚽−
𝐲( f )𝐂XV( f )
[
𝐂H
XV( f )𝚽−
𝐲( f )𝐂XV( f )
]−[


]
.
(.)
We always have
oSNR (𝐡LCMV
) ≤oSNR (𝐡MVDR
) ,
(.)
𝜐d
(
𝐡LCMV
)
= ,
(.)
𝜉d
(𝐡LCMV
) = ,
(.)
and
𝜉n
(𝐡LCMV
) ≤𝜉n
(𝐡MVDR
) ≤𝜉n
(𝐡W
) .
(.)
The LCMV structure can be an useful solution in practical applications where the
coherent noise is more problematic than the incoherent one.
Example ..
Returning to Example .., we now employ the LCMV ﬁlter,
𝐡LCMV( f ), given in (.). We assume M = sensors. Figure .shows plots of the
broadband gain in SNR, (𝐡LCMV
), the broadband MSE, J (𝐡LCMV
), the broadband
noise reduction factor, 𝜉n
(
𝐡LCMV
)
, and the broadband desired signal reduction factor,
𝜉d
(𝐡LCMV
), as a function of the broadband input SNR, for several values of 𝛼= 𝜎
w ∕𝜎
u.
For a given broadband input SNR, as the ratio between the coherent to incoherent
noise increases (𝛼decreases), the LCMV ﬁlter yields higher broadband gain in SNR and
higher broadband noise reduction factor.
■
The LCMV ﬁlter shown above can, obviously, be extended to any number of linear
constraints Mc
≤
M. The constraint equation, which includes the distortionless
constraint, can be expressed as
𝐂H( f )𝐡( f ) = 𝐢c,
(.)

178
Fundamentals of Signal Enhancement and Array Signal Processing
(a)
(b)
(c)
(d)
−5
0
5
10
15
5.6
5.62
5.64
5.66
5.68
5.7
−5
0
5
10
15
−5
0
5
10
15
20
−5
0
5
10
15
5.6
5.62
5.64
5.66
5.68
5.7
−5
0
5
10
15
−1
−0.5
0
0.5
1
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
ξn (hLCMV) (dB)
ξd (hLCMV) (dB)
(hLCMV) (dB)
J (hLCMV) (dB)
Figure 5.8 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise reduction
factor, and (d) the broadband desired signal reduction factor of the LCMV filter as a function of the
broadband input SNR, for several values of 𝛼= 𝜎2
w ∕𝜎2
u: 𝛼= 0.03 (solid line with circles), 𝛼= 0.1
(dashed line with asterisks), 𝛼= 0.3 (dotted line with squares), and 𝛼= 1 (dash-dot line with triangles).
where
𝐂( f ) = [ 𝐝( f )
𝐜( f )
⋯
𝐜Mc( f ) ]
(.)
is a matrix of size M × Mc whose Mc columns are linearly independent and 𝐢c is a
vector of length Mc whose ﬁrst component is equal to and the other components
are some chosen real numbers to satisfy the constraints on the ﬁlter. Generally, these
constraints are null ones where it is desired to completely cancel some interference
sources. Following the same steps as above, we easily ﬁnd the LCMV ﬁlter:
𝐡LCMV( f ) = 𝚽−
𝐲( f )𝐂( f )
[
𝐂H( f )𝚽−
𝐲( f )𝐂( f )
]−
𝐢c.
(.)
For Mc = , 𝐡LCMV( f ) simpliﬁes to 𝐡MVDR( f ).
In Table ., we summarize all the optimal ﬁlters studied in this section.
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
179
Table 5.1 Optimal linear filters for multichannel signal enhancement in
the frequency domain.
Filter
Maximum SNR
𝐡max( f ) = 𝜍( f )𝚽−
𝐯( f )𝐝( f ), 𝜍( f ) ≠
Wiener
𝐡W( f ) =
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
−M + tr [𝚽−
𝐯( f )𝚽𝐲( f )]𝐢i
MVDR
𝐡MVDR( f ) =
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
tr [𝚽−
𝐯( f )𝚽𝐲( f )] −M
𝐢i
Tradeoﬀ
𝐡T,𝜇=
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
𝜇−M + tr [𝚽−
𝐯( f )𝚽𝐲( f )]𝐢i, 𝜇≥
LCMV
𝐡LCMV( f ) = 𝚽−
𝐲( f )𝐂( f )
[
𝐂H( f )𝚽−
𝐲( f )𝐂( f )
]−
𝐢c
5.5
Generalized Sidelobe Canceller Structure
The generalized sidelobe canceller (GSC) structure solves exactly the same problem
as the LCMV approach by dividing the ﬁlter vector 𝐡LCMV( f ) into two components
operating on orthogonal subspaces [–]:
𝐡LCMV( f ) = 𝐡MN( f ) −𝐁𝐂( f )𝐰GSC( f ),
(.)
where
𝐡MN( f ) = 𝐂( f ) [𝐂H( f )𝐂( f )]−𝐢c
(.)
is the minimum-norm solution of (.), 𝐁𝐂( f ) is the so-called blocking matrix that
spans the nullspace of 𝐂H( f ), i.e.,
𝐂H( f )𝐁𝐂( f ) = 𝟎Mc×(M−Mc),
(.)
and 𝐰GSC( f ) is a weighting vector derived as explained below. The size of 𝐁𝐂( f ) is M ×
(M −Mc), where M −Mc is the dimension of the nullspace of 𝐂H( f ). Therefore, the
length of the vector 𝐰GSC( f ) is M −Mc. The blocking matrix is not unique and the most
obvious choice is the following:
𝐁𝐂( f ) = 𝐏𝐂( f )
[
𝐈M−Mc
𝟎Mc×(M−Mc)
]
,
(.)
where
𝐏𝐂( f ) = 𝐈M −𝐂( f ) [𝐂H( f )𝐂( f )]−𝐂H( f )
(.)
is a projection matrix whose rank is equal to M −Mc and 𝐈M−Mc is the (M −Mc
) ×
(M −Mc
) identity matrix.

180
Fundamentals of Signal Enhancement and Array Signal Processing
+
v(f)
y(f )
H
+
H
wGSC ( f )
H
x(f)
X1( f)
‸
−
hMN ( f )
BC ( f )
Figure 5.9 Block diagram of the generalized sidelobe canceller.
To obtain the ﬁlter 𝐰GSC( f ), the GSC approach is used, which is formulated as the
following unconstrained optimization problem:
min
𝐰( f )
[
𝐡MN( f ) −𝐁𝐂( f )𝐰( f )
]H 𝚽𝐲( f )
[
𝐡MN( f ) −𝐁𝐂( f )𝐰( f )
]H ,
(.)
for which the solution is
𝐰GSC( f ) =
[
𝐁H
𝐂( f )𝚽𝐲( f )𝐁𝐂( f )
]−𝐁H
𝐂( f )𝚽𝐲( f )𝐡MN( f ).
(.)
Deﬁne the error signal, which is also the estimate of the desired signal, between the
outputs of the two ﬁlters 𝐡MN( f ) and 𝐁𝐂( f )𝐰( f ):
̂X( f ) = 𝐡H
MN( f )𝐲( f ) −𝐰H( f )𝐁H
𝐂( f )𝐲( f ).
(.)
It is easy to see that the minimization of E
[|||
̂X( f )|||
]
with respect to 𝐰( f ) is equivalent
to (.). A block diagram of the GSC is illustrated in Figure ..
Now, we need to check if indeed the two ﬁlters LCMV and GSC are equivalent, i.e.,
𝐢T
c
[
𝐂H( f )𝚽−
𝐲( f )𝐂( f )
]−
𝐂H( f )𝚽−
𝐲( f )
= 𝐡H
MN( f )
{
𝐈M −𝚽𝐲( f )𝐁𝐂( f ) [𝐁H
𝐂( f )𝚽𝐲( f )𝐁𝐂( f )]−𝐁H
𝐂( f )
}
.
(.)
For that, we are going to follow the elegant proof given in []. The matrix in brackets
in the second line of (.) can be rewritten as
𝐈M −𝚽𝐲( f )𝐁𝐂( f ) [𝐁H
𝐂( f )𝚽𝐲( f )𝐁𝐂( f )]−𝐁H
𝐂( f )
= 𝚽∕
𝐲( f ) [𝐈M −𝐏( f )] 𝚽−∕
𝐲
( f ),
(.)
where
𝐏( f ) = 𝚽∕
𝐲( f )𝐁𝐂( f ) [𝐁H
𝐂( f )𝚽𝐲( f )𝐁𝐂( f )]−𝐁H
𝐂( f )𝚽∕
𝐲( f )
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
181
is a projection operator onto the subspace spanned by the columns of 𝚽∕
𝐲( f )𝐁𝐂( f ).
We have
𝐁H
𝐂( f )𝐂( f ) = 𝐁H
𝐂( f )𝚽∕
𝐲( f )𝚽−∕
𝐲
( f )𝐂( f )
= 𝟎(M−Mc)×Mc.
(.)
This implies that the rows of 𝐁H
𝐂( f ) are orthogonal to the columns of 𝐂( f ) and the
subspace spanned by the columns of 𝚽∕
𝐲( f )𝐁𝐂( f ) is orthogonal to the subspace
spanned by the columns of 𝚽−∕
𝐲
( f )𝐂( f ). Since 𝐁𝐂( f ) has a rank equal to M −Mc
where Mc is the rank of 𝐂( f ), then the sum of the dimensions of the two subspaces is
M and the subspaces are complementary. This means that
𝐏( f ) + 𝐏( f ) = 𝐈M,
(.)
where
𝐏( f ) = 𝚽−∕
𝐲
( f )𝐂( f )
[
𝐂H( f )𝚽−
𝐲( f )𝐂( f )
]−
𝐂H( f )𝚽−∕
𝐲
( f ).
(.)
When this is substituted and the constraint 𝐢T
c = 𝐡H
MN( f )𝐂( f ) is applied, (.) becomes
𝐢T
c
[
𝐂H( f )𝚽−
𝐲( f )𝐂( f )
]−
𝐂H( f )𝚽−
𝐲( f )
= 𝐡H
MN( f )𝚽∕
𝐲( f )𝐏( f )𝚽−∕
𝐲
( f )
= 𝐡H
MN( f )𝚽∕
𝐲( f ) [𝐈M −𝐏( f )] 𝚽−∕
𝐲
( f )
= 𝐡H
MN( f )
{
𝐈M −𝚽𝐲( f )𝐁𝐂( f )
[
𝐁H
𝐂( f )𝚽𝐲( f )𝐁𝐂( f )
]−𝐁H
𝐂( f )
}
.
(.)
Hence, the LCMV and GSC ﬁlters are strictly equivalent.
5.6
A Signal Subspace Perspective
In this section, we give a signal subspace perspective of some of the optimal ﬁlters
derived in Section .by using the joint diagonalization.
5.6.1
Joint Diagonalization
The two Hermitian matrices 𝚽𝐱( f ) and 𝚽𝐯( f ) can be jointly diagonalized as follows []:
𝐓H( f )𝚽𝐱( f )𝐓( f ) = 𝚲( f ),
(.)
𝐓H( f )𝚽𝐯( f )𝐓( f ) = 𝐈M,
(.)
where
𝐓( f ) = [ 𝐭( f )
𝐭( f )
⋯
𝐭M( f ) ]
(.)

182
Fundamentals of Signal Enhancement and Array Signal Processing
is a full-rank square matrix (of size M × M),
𝐭( f ) =
𝚽−
𝐯( f )𝐝( f )
√
𝐝H( f )𝚽−
𝐯( f )𝐝( f )
(.)
is the ﬁrst eigenvector of the matrix 𝚽−
𝐯( f )𝚽𝐱( f ),
𝚲( f ) = diag [𝜆( f ), , … , ]
(.)
is a diagonal matrix (of size M × M), and
𝜆( f ) = 𝜙X( f )𝐝H( f )𝚽−
𝐯( f )𝐝( f )
(.)
is the only nonnull eigenvalue of 𝚽−
𝐯( f )𝚽𝐱( f ), whose corresponding eigenvector is
𝐭( f ). Also, the noisy signal correlation matrix can be diagonalized as
𝐓H( f )𝚽𝐲( f )𝐓( f ) = 𝚲( f ) + 𝐈M.
(.)
It can be checked from (.) that
𝐭H
i ( f )𝐝( f ) = , i = , , … , M.
(.)
5.6.2
Estimation of the Desired Signal
As explained in Section ., the desired signal, X( f ), can be estimated with
Z( f ) = 𝐡H( f )𝐲( f ),
(.)
where 𝐡( f ) is a complex-valued linear ﬁlter of length M. From (.), we easily ﬁnd the
variance of Z( f ):
𝜙Z( f ) = 𝜙X( f ) |||𝐡H( f )𝐝( f )|||

+ 𝐡H( f )𝚽𝐯( f )𝐡( f ),
(.)
from which we deduce the narrowband output SNR:
oSNR [𝐡( f )] =
𝜙X( f ) ||𝐡H( f )𝐝( f )||

𝐡H( f )𝚽𝐯( f )𝐡( f )
≤𝜆( f ).
(.)
We deﬁne the narrowband white noise gain (WNG) as
[𝐡( f )] =
||𝐡H( f )𝐝( f )||

𝐡H( f )𝐡( f ) .
(.)
We will show next how to use this measure to derive a class of ﬁlters.
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
183
Let us deﬁne the matrix of size M × N:
𝐓∶N( f ) =
[ 𝐭( f )
𝐭( f )
⋯
𝐭N( f ) ]
,
(.)
with ≤N ≤M. We consider multichannel noise reduction ﬁlters that have the form:
𝐡∶N( f ) = 𝐓∶N( f )𝐚( f ),
(.)
where
𝐚( f ) =
[ A( f )
A( f )
⋯
AN( f ) ]T ≠𝟎
(.)
is a vector of length N. Then, the narrowband WNG can be expressed as
[𝐡∶N( f )] =
|||𝐚H( f )𝐓H
∶N( f )𝐝( f )|||

𝐚H( f )𝐓H
∶N( f )𝐓∶N( f )𝐚( f )
(.)
= [𝐚( f )] .
It is clear that the vector 𝐚( f ) that maximizes 
[
𝐚( f )
]
is
𝐚( f ) = 𝜍( f ) [𝐓H
∶N( f )𝐓∶N( f )]−𝐓H
∶N( f )𝐝( f ),
(.)
where 𝜍( f ) ≠is an arbitrary complex number. As a result, the ﬁlter 𝐡∶N( f ) that
maximizes [𝐡∶N( f )] is
𝐡∶N( f ) = 𝜍( f )𝐏𝐓∶N( f )𝐝( f ),
(.)
where
𝐏𝐓∶N( f ) = 𝐓∶N( f ) [𝐓H
∶N( f )𝐓∶N( f )]−𝐓H
∶N( f )
(.)
is a projection matrix whose rank is equal to N. With (.), the narrowband WNG is
[𝐡∶N( f )] = 𝐝H( f )𝐏𝐓∶N( f )𝐝( f )
(.)
= 𝜆( f )
𝜙X( f )𝐢T [
𝐓H
∶N( f )𝐓∶N( f )
]−𝐢,
where 𝐢is the ﬁrst column of the N × N identity matrix, 𝐈N, with

[
𝐡∶( f )
]
=
𝜆( f )
𝜙X( f )𝐭H
( f )𝐭( f )
,
(.)
[𝐡∶M( f )] = 𝐝H( f )𝐝( f ),
(.)
and
[𝐡∶( f )] ≤[𝐡∶( f )] ≤⋯≤[𝐡∶M( f )] .
(.)

184
Fundamentals of Signal Enhancement and Array Signal Processing
Example ..
Consider a ULA of M = sensors. Suppose that a desired signal,
x(t), impinges on the ULA from the direction 𝜃x. Assume that the desired signal is a
harmonic pulse of T samples:
x(t) =
{
A sin
(
𝜋ft + 𝜙
)
,
≤t ≤T −
,
t < , t ≥T
,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly distributed
on the interval from to 𝜋. Assume that the interference um(t) is a diﬀuse noise
uncorrelated with x(t). In addition, the sensors contain thermal white Gaussian noise,
wm(t) ∼(, 𝜎
w
), that are mutually uncorrelated. The desired signal needs to be
recovered from the noisy received signals, ym(t) = xm(t) + vm(t), m = , … , M, where
vm(t) = um(t) + wm(t), m = , … , M are the interference-plus-noise signals.
As in Example .., we choose a sampling interval Ts that satisﬁes Ts = d
c . Hence,
the variance of X( f ) is
𝜙X( f ) = A
D
T
[𝜋(f + f
)] + A
D
T
[𝜋(f −f
)]
and the correlation matrix of 𝐱( f ) is
𝚽𝐱( f ) = 𝜙X( f )𝐝( f )𝐝H( f ),
where
𝐝( f ) = [

e−𝚥𝜋f 𝜏x,
e−𝚥𝜋f 𝜏x,
⋯
e−𝚥𝜋f 𝜏x,M ]T ,
𝜏x,m = (m −) cos 𝜃x, m = , , … , M.
The correlation matrix of 𝐯( f ) is
𝚽𝐯( f ) = T𝜎
u𝚪𝐮( f ) + T𝜎
w𝐈M,
where
[
𝚪𝐮( f )
]
i,j =
sin (𝜋f |i −j|)
𝜋f |i −j|
= sinc (f |i −j|)
is the normalized coherence between the ith and jth sensors for the diﬀuse noise.
The narrowband input SNR is
iSNR( f ) =
𝜙X( f )
𝜙V( f )
=
A
T (𝜎
u + 𝜎
w
)D
T
[𝜋(f + f
)]
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
185
2
4
6
8
10
12
−4
−2
0
2
4
6
8
10
12
2
4
6
8
10
0
2
4
6
8
10
12
14
N
N
(a)
(b)
 [h1:N ( f )]
 [h1:N ( f )]
Figure 5.10 (a) Narrowband white noise gain and (b) narrowband gain in SNR of 𝗵1∶N( f) as a function
of N for different incidence angles of the desired signal: 𝜃x = 0◦(circles), 𝜃x = 30◦(asterisks), 𝜃x = 60◦
(squares), and 𝜃x = 90◦(triangles).
+
A
T
(
𝜎
u + 𝜎
w
)D
T
[𝜋(f −f
)] .
To demonstrate the performance of the ﬁlter 𝐡∶N( f ) in (.), we choose A = .,
f= ., 𝜎
w = .𝜎
u, 𝜎
u = ., and T = . Figure .shows the eﬀect of N on
the WNG, [𝐡∶N( f )], and on the narrowband gain in SNR, [𝐡∶N( f )], for diﬀerent
incidence angles of the desired signal and for f = f. For N = , the WNG is minimal.
As N increases, the WNG increases.
■
Now, we need to determine 𝜍( f ). There are at least three diﬀerent useful approaches
for that.
The ﬁrst idea to ﬁnd 𝜍( f ) is from the distortionless constraint, i.e.,
𝐡H
∶N( f )𝐝( f ) = .
(.)
Substituting (.) into (.), we get
𝜍( f ) =

𝐝H( f )𝐏𝐓∶N( f )𝐝( f ).
(.)
Consequently, we obtain a class of distortionless ﬁlters:
𝐡∶N,DL( f ) =
𝐏𝐓∶N( f )𝐝( f )
𝐝H( f )𝐏𝐓∶N( f )𝐝( f ),
(.)
with
𝐡∶,DL( f ) =
𝐭( f )
𝐝H( f )𝐭( f )
(.)

186
Fundamentals of Signal Enhancement and Array Signal Processing
=
𝚽−
𝐯( f )𝐝( f )
𝐝H( f )𝚽−
𝐯( f )𝐝( f )
= 𝐡MVDR( f )
being the MVDR ﬁlter (see Section .) and
𝐡∶M,DL( f ) =
𝐝( f )
𝐝H( f )𝐝( f )
(.)
= 𝐡MN( f )
being the minimum-norm ﬁlter, which can be directly derived from (.). We should
always have
𝜆( f ) = oSNR [𝐡∶,DL( f )] ≥oSNR [𝐡∶,DL( f )] ≥
⋯≥oSNR [𝐡∶M,DL( f )] .
(.)
Example ..
Returning to Example .., we assume the ULA contains M = 
sensors, and that the desired signal impinges on the ULA from the direction 𝜃x =
◦. Now, we employ the distortionless ﬁlter, 𝐡∶N,DL( f ), given in (.). Figure .
shows plots of the narrowband gain in SNR, [𝐡∶N,DL( f )], the narrowband MSE,
J
[
𝐡∶N,DL( f )
]
, the narrowband noise reduction factor, 𝜉n
[
𝐡∶N,DL( f )
]
, and the narrow-
band desired signal reduction factor, 𝜉d
[𝐡∶N,DL( f )], as a function of the narrowband
input SNR, for f = fand several values of N. For N = , the narrowband gain in SNR
is maximal. As N increases, the narrowband gain in SNR and the narrowband noise
reduction factor decrease, while the narrowband MSE increases.
■
Let us deﬁne the error signal between the estimated and desired signals at frequency f :
( f ) = Z( f ) −X( f )
(.)
= 𝐡H
∶N( f )𝐲( f ) −X( f ).
Then, the MSE is
J
[
𝐡∶N( f )
]
= E
[
|( f )|]
(.)
= |𝜍( f )|𝐝H( f )𝐏𝐓∶N( f )𝚽𝐲( f )𝐏𝐓∶N( f )𝐝( f ) + 𝜙X( f )
−𝜍∗( f )𝜙X( f )𝐝H( f )𝐏𝐓∶N( f )𝐝( f )
−𝜍( f )𝜙X( f )𝐝H( f )𝐏𝐓∶N( f )𝐝( f ).
The minimization of J [𝐡∶N( f )] with respect to 𝜍∗( f ) leads to
𝜍( f ) =
𝜙X( f )𝐝H( f )𝐏𝐓∶N( f )𝐝( f )
𝐝H( f )𝐏𝐓∶N( f )𝚽𝐲( f )𝐏𝐓∶N( f )𝐝( f ).
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
187
−5
0
5
10
15
2.6
2.8
3
3.2
3.4
3.6
(a)
(b)
(c)
(d)
−5
0
5
10
15
20
25
30
35
40
45
−5
0
5
10
15
2.6
2.8
3
3.2
3.4
3.6
−5
0
5
10
15
−1
−0.5
0
0.5
1
ξn [h1:N,DL( f )] (dB)
ξd [h1:N,DL( f )] (dB)
[h1:N,DL( f )] (dB)
[h1:N,DL( f )] (dB)
iSNR(f) (dB)
iSNR( f ) (dB)
iSNR(f) (dB)
iSNR( f ) (dB)
Figure 5.11 (a) The narrowband gain in SNR, (b) the narrowband MSE, (c) the narrowband noise
reduction factor, and (d) the narrowband desired signal reduction factor of the distortionless filters as
a function of the narrowband input SNR, for several values of N: N = 1 (solid line with circles), N = 2
(dashed line with asterisks), N = 3 (dotted line with squares), and N = 4 (dash-dot line with triangles).
We deduce a class of Wiener ﬁlters:
𝐡∶N,W( f ) =
𝜙X( f )𝐏𝐓∶N( f )𝐝( f )𝐝H( f )𝐏𝐓∶N( f )𝐝( f )
𝐝H( f )𝐏𝐓∶N( f )𝚽𝐲( f )𝐏𝐓∶N( f )𝐝( f )
,
(.)
with
𝐡∶,W( f ) =
𝜙X( f )𝐭H
( f )𝐝( f )
+ 𝜆( f )
𝐭( f )
(.)
= 𝜙X( f )𝚽−
𝐲( f )𝐝( f )
=
𝜆( f )
+ 𝜆( f )𝐡MVDR( f )
= 𝐡W( f )

188
Fundamentals of Signal Enhancement and Array Signal Processing
being the classical multichannel Wiener ﬁlter (see Section .) and
𝐡∶M,W( f ) =
𝜙X( f )𝐝H( f )𝐝( f )
𝐝H( f )𝚽𝐲( f )𝐝( f ) 𝐝( f )
(.)
= 𝐡MN,2( f )
being another (distorted) form of the minimum-norm ﬁlter. We should always have
𝜆( f ) = oSNR [𝐡∶,W( f )] ≥oSNR [𝐡∶,W( f )] ≥
⋯≥oSNR
[
𝐡∶M,W( f )
]
.
(.)
Example ..
Returning to Example .., we now employ the Wiener ﬁlter,
𝐡∶N,W( f ), given in (.). Figure .shows plots of the narrowband gain in
SNR, 
[
𝐡∶N,W( f )
]
, the narrowband MSE, J
[
𝐡∶N,W( f )
]
, the narrowband noise
reduction factor, 𝜉n
[𝐡∶N,W( f )], and the narrowband desired signal reduction factor,
𝜉d
[
𝐡∶N,W( f )
]
, as a function of the narrowband input SNR, for f
= fand several
values of N. For N = , the narrowband gain in SNR is maximal. As N increases, the
narrowband gain in SNR and the narrowband noise reduction factor decrease, while the
narrowband MSE and the narrowband desired signal reduction factor increase.
■
We deﬁne the error signal between the estimated and reference microphone signals
at frequency f as
′( f ) = Z( f ) −Y( f )
(.)
= 𝐡H
∶N( f )𝐲( f ) −Y( f )
and the corresponding MSE is
J′ [𝐡∶N( f )] = E
[
||′( f )||
]
.
(.)
The minimization of J′ [
𝐡∶N( f )
]
with respect to 𝜍∗( f ) gives
𝜍( f ) =
𝐝H( f )𝐏𝐓∶N( f )𝚽𝐲( f )𝐢i
𝐝H( f )𝐏𝐓∶N( f )𝚽𝐲( f )𝐏𝐓∶N( f )𝐝( f ).
(.)
Therefore, we ﬁnd a class of tradeoﬀﬁlters:
𝐡∶N,T( f ) =
𝐏𝐓∶N( f )𝐝( f )𝐝H( f )𝐏𝐓∶N( f )𝚽𝐲( f )𝐢i
𝐝H( f )𝐏𝐓∶N( f )𝚽𝐲( f )𝐏𝐓∶N( f )𝐝( f ) ,
(.)
with
𝜆( f ) = oSNR [𝐡∶,T( f )] ≥oSNR [𝐡∶,T( f )] ≥
⋯≥oSNR [𝐡∶M,T( f )] .
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
189
−5
0
5
10
15
2.6
2.8
3
3.2
3.4
3.6
(a)
(b)
(c)
(d)
−5
0
5
10
15
20
25
30
35
40
−5
0
5
10
15
2
4
6
8
10
12
−5
0
5
10
15
0
4
2
6
8
10
iSNR( f) (dB)
iSNR( f ) (dB)
iSNR(f) (dB)
iSNR( f ) (dB)
[h1:N, W( f )] (dB)
J
[h1:N, W( f )] (dB)
ξn [h1:N, W( f )] (dB)
ξd [h1:N, W ( f )] (dB)
Figure 5.12 (a) The narrowband gain in SNR, (b) the narrowband MSE, (c) the narrowband noise
reduction factor, and (d) the narrowband desired signal reduction factor of the Wiener filters as a
function of the narrowband input SNR, for several values of N: N = 1 (solid line with circles), N = 2
(dashed line with asterisks), N = 3 (dotted line with squares), and N = 4 (dash-dot line with triangles).
Example ..
Returning to Example .., we now employ the tradeoﬀﬁlter,
𝐡∶N,T( f ), given in (.). Figure .shows plots of the narrowband gain in SNR,
[𝐡∶N,T( f )], the narrowband MSE, J [𝐡∶N,T( f )], the narrowband noise reduction
factor, 𝜉n
[𝐡∶N,T( f )], and the narrowband desired signal reduction factor, 𝜉d
[𝐡∶N,T( f )],
as a function of the narrowband input SNR, for f = fand several values of N. For
N = , the narrowband gain in SNR is maximal. As N increases, the narrowband gain
in SNR and the narrowband noise reduction factor decrease, while the narrowband
MSE increases.
■
5.7
Implementation with the STFT
In this section, we show how to implement the optimal ﬁlters in the STFT domain.

190
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
2.6
2.8
3
3.2
3.4
3.6
−5
0
5
10
15
20
25
30
35
40
45
−5
0
5
10
15
2.8
3
3.2
3.4
3.6
3.8
−5
0
5
10
15
−0.2
0
0.2
0.4
0.6
0.8
1
iSNR(f) (dB)
iSNR(f ) (dB)
iSNR(f) (dB)
iSNR(f ) (dB)
(a)
(b)
(c)
(d)
[h1:N, T ( f )] (dB)
J
[h1:N, T ( f )] (dB)
ξn [h1:N, T ( f )] (dB)
ξn [h1:N, T ( f )] (dB)
Figure 5.13 (a) The narrowband gain in SNR, (b) the narrowband MSE, (c) the narrowband noise
reduction factor, and (d) the narrowband desired signal reduction factor of the tradeoff filters as a
function of the narrowband input SNR, for several values of N: N = 1 (solid line with circles), N = 2
(dashed line with asterisks), N = 3 (dotted line with squares), and N = 4 (dash-dot line with triangles).
The signal model given in (.) can be put into a vector form by considering the L
most recent successive time samples, i.e.,
𝐲m(t) = 𝐱m(t) + 𝐯m(t), m = , , … , M,
(.)
where
𝐲m(t) =
[ ym(t)
ym(t −)
⋯
ym(t −L + ) ]T
(.)
is a vector of length L, and 𝐱m(t) and 𝐯m(t) are deﬁned in a similar way to 𝐲m(t) from
(.). A short-time segment of the observation [i.e., 𝐲m(t)], is multiplied with an
analysis window of length L:
𝐠a = [ ga()
ga()
⋯
ga(L −) ]T
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
191
+
vm (t)
diag (ga)
W
R
xm (t)
ym (t)
Ym (t)
Ym (rR)
↑
Figure 5.14 STFT representation of the measured signal at the mth sensor.
and transformed into the frequency domain by using the discrete Fourier transform
(DFT). Let 𝐖denote the DFT matrix of size L × L, with
[𝐖]i,j = exp
(
−𝚥𝜋ij
L
)
, i, j = , … , L −.
(.)
Then, the STFT representation of the observation is deﬁned as []
𝐘m(t) = 𝐖diag (𝐠a
) 𝐲m(t),
(.)
where
𝐘m(t) = [ Ym(t, )
Ym(t, )
⋯
Ym(t, L −) ]T .
(.)
In practice, the STFT representation is decimated in time by a factor R (≤R ≤L) []:
𝐘m(rR) = 𝐘m(t) ||t=rR
(.)
= [ Ym(rR, )
Ym(rR, )
⋯
Ym(rR, L −) ]T , r ∈Z.
Figure .shows the STFT representation of the measured signal at the mth sensor.
Therefore, in the STFT domain, (.) can be written as
Ym(rR, k) = Xm(rR, k) + Vm(rR, k),
(.)
where k = , … , L −denotes the frequency index, and Xm(rR, k) and Vm(rR, k) are
the STFT representations of xm(t) and vm(t), respectively. Assuming that L, the length
of the analysis window 𝐠a, is suﬃciently larger than the eﬀective support of the acoustic
impulse response gm(t) [], we can apply the multiplicative transfer function (MTF)
approximation [] and write the convolved desired signal at the mth sensor as
Xm(rR, k) = Gm(k)X(rR, k),
(.)
where X(rR, k) is the STFT representation of the desired signal, x(t), and Gm(k) is the
DFT of gm(t).
Writing the M STFT representations of the sensors’ signals in a vector notation, we
have
𝐲(rR, k) = 𝐠(k)X(rR, k) + 𝐯(rR, k)
(.)

192
Fundamentals of Signal Enhancement and Array Signal Processing
= 𝐱(rR, k) + 𝐯(rR, k)
= 𝐝(k)X(rR, k) + 𝐯(rR, k),
where
𝐲(rR, k) = [ Y(rR, k)
Y(rR, k)
⋯
YM(rR, k) ]T ,
𝐱(rR, k) =
[ X(rR, k)
X(rR, k)
⋯
XM(rR, k) ]T
= X(rR, k)𝐠(k),
𝐠(k) =
[ G(k)
G(k)
⋯
GM(k) ]T ,
𝐯(rR, k) = [ V(rR, k)
V(rR, k)
⋯
VM(rR, k) ]T ,
and
𝐝(k) =
[

G(k)
G(k)
⋯
GM(k)
G(k)
]T
(.)
= 𝐠(k)
G(k).
The correlation matrix of 𝐲(rR, k) is
𝚽𝐲(rR, k) = E [𝐲(rR, k)𝐲H(rR, k)]
(.)
= 𝜙X(rR, k)𝐝(k)𝐝H(k) + 𝚽𝐯(rR, k),
where 𝜙X(rR, k) = E
[
||X(rR, k)||
]
is the variance of X(rR, k) and 𝚽𝐯(rR, k) =
E [𝐯(rR, k)𝐯H(rR, k)] is the correlation matrix of 𝐯( f ).
In the STFT domain, conventional multichannel noise reduction is performed by
applying a complex weight to the output of each sensor, at time-frequency bin (rR, k),
and summing across the aperture (see Figure .):
Z(rR, k) =
M
∑
m=
H∗
m(rR, k)Ym(rR, k)
(.)
= 𝐡H(rR, k)𝐲(rR, k),
where Z(rR, k) is the estimate of X(rR, k) and
𝐡(rR, k) = [ H(rR, k)
H(rR, k)
⋯
HM(rR, k) ]T
(.)
is a ﬁlter of length M containing all the complex gains applied to the sensors’ outputs at
time-frequency bin (rR, k).
We can express (.) as a function of the steering vector, i.e.,
Z(rR, k) = 𝐡H(rR, k) [𝐝(k)X(rR, k) + 𝐯(rR, k)]
(.)
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
193
+
V1 (rR, k)
H1(rR, k)
+
VM (rR, k)
HM (rR, k)
+
...
...
X1 (rR, k)
XM (rR, k)
Z (rR, k)
Y1(rR, k)
*
*
YM (rR, k)
Figure 5.15 Block diagram of multichannel linear filtering in the STFT domain.
= Xfd(rR, k) + Vrn(rR, k),
where
Xfd(rR, k) = X(rR, k)𝐡H(rR, k)𝐝(k)
(.)
is the ﬁltered desired signal and
Vrn(rR, k) = 𝐡H(rR, k)𝐯(rR, k)
(.)
is the residual noise. This procedure is called multichannel signal enhancement in the
STFT domain.
The two terms on the right-hand side of (.) are incoherent. Hence, the variance
of Z(rR, k) is the sum of two variances:
𝜙Z(rR, k) = 𝐡H(rR, k)𝚽𝐲(rR, k)𝐡(rR, k)
(.)
= 𝜙Xfd(rR, k) + 𝜙Vrn(rR, k),
where
𝜙Xfd(rR, k) = 𝜙X(rR, k) |||𝐡H(rR, k)𝐝(k)|||

,
(.)
𝜙Vrn(rR, k) = 𝐡H(rR, k)𝚽𝐯(rR, k)𝐡(rR, k).
(.)
In a similar way to the frequency-domain input SNR, we deﬁne the narrowband input
SNR as
iSNR(rR, k) =
𝜙X(rR, k)
𝜙V(rR, k).
(.)

194
Fundamentals of Signal Enhancement and Array Signal Processing
The broadband input SNR is obtained by summing over all time-frequency indices the
numerator and denominator of iSNR(rR, k). We get
iSNR =
∑
r,k 𝜙X(rR, k)
∑
r,k 𝜙V(rR, k).
(.)
Similarly, the broadband output SNR is
oSNR (𝐡) =
∑
r,k 𝜙Xfd(rR, k)
∑
r,k 𝜙Vrn(rR, k)
(.)
=
∑
r,k 𝜙X(rR, k) ||𝐡H(rR, k)𝐝(k)||

∑
r,k 𝐡H(rR, k)𝚽𝐯(rR, k)𝐡(rR, k),
the broadband noise reduction and desired signal reduction factors are, respectively,
𝜉n (𝐡) =
∑
r,k 𝜙V(rR, k)
∑
r,k 𝐡H(rR, k)𝚽𝐯(rR, k)𝐡(rR, k)
(.)
and
𝜉d (𝐡) =
∑
r,k 𝜙X(rR, k)
∑
r,k 𝜙X(rR, k) ||𝐡H(rR, k)𝐝(k)||
,
(.)
the broadband desired signal distortion index is
𝜐d (𝐡) =
∑
r,k 𝜙X(rR, k) ||𝐡H(rR, k)𝐝(k) −||

∑
r,k 𝜙X(rR, k)
,
(.)
and the broadband MSE is deﬁned as
J (𝐡) =
∑
r,k
J [𝐡(rR, k)]
(.)
=
∑
r,k
[
𝜙X(rR, k) |||𝐡H(rR, k)𝐝(k) −|||

+ 𝐡H(rR, k)𝚽𝐯(rR, k)𝐡(rR, k)] .
The optimal ﬁlters, summarized in Table ., are employed in the STFT domain by
replacing 𝚽𝐲( f ), 𝚽𝐯( f ), and 𝐝( f ) with 𝚽𝐲(rR, k), 𝚽𝐯(rR, k), and 𝐝(k), respectively.
Example ..
Consider a ULA of M sensors, as shown in Figure .. Suppose that
a desired speech signal, x(t), impinges on the ULA from the direction 𝜃x, and that
an interference u(t) impinges on the ULA from the direction 𝜃u. Assume that the
interference u(t) is white Gaussian noise, i.e., u(t) ∼(, 𝜎
u
), uncorrelated with x(t).
In addition, the sensors contain thermal white Gaussian noise, wm(t) ∼(, 𝜎
w
),
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
195
that are mutually uncorrelated. The desired speech signal needs to be recovered from
the noisy received signals, ym(t) = xm(t) + vm(t), m = , … , M, where vm(t) =
um(t) + wm(t), m = , … , M are the interference-plus-noise signals.
Assume that the sampling frequency is kHz, and that the sampling interval Ts
satisﬁes Ts = d
c . We have
xm(t) = x
(
t −𝜏x,m
)
,
um(t) = u
(t −𝜏u,m
) ,
where
𝜏x,m = (m −)d cos 𝜃x
cTs
= (m −) cos 𝜃x,
𝜏u,m = (m −)d cos 𝜃u
cTs
= (m −) cos 𝜃u.
In the STFT domain, we obtain
𝐱(rR, k) = X(rR, k)𝐝(k),
𝐮(rR, k) = U(rR, k)𝜸∗
U𝐮(k),
where
𝐝(k) =
[

e−𝚥𝜋k𝜏x,∕L
e−𝚥𝜋k𝜏x,∕L
⋯
e−𝚥𝜋k𝜏x,M∕L ]T ,
𝜸∗
U𝐮(k) = [

e−𝚥𝜋k𝜏u,∕L
e−𝚥𝜋k𝜏u,∕L
⋯
e−𝚥𝜋k𝜏u,M∕L ]T .
To demonstrate noise reduction in the STFT domain, we choose 𝜃x = ◦, 𝜃u = ◦,
𝜎
w = .𝜎
u, a Hamming window of length L = as the analysis window, a decimation
factor R = L∕= , and the Wiener ﬁlter in the STFT domain:
𝐡W(rR, k) = 𝜙X(rR, k) [𝜙X(rR, k)𝐝(k)𝐝H(k) + 𝚽𝐯(rR, k)]−𝐝(k).
(.)
An estimate for the correlation matrix of 𝐯(rR, k) can be obtained by averaging past
cross-spectral power values of the noisy measurement during speech inactivity:
̂𝚽𝐯(rR, k) =
{
𝛼̂𝚽𝐯
[(r −)R, k] + (−𝛼)𝐲(rR, k)𝐲H(rR, k),
X(rR, k) = 
̂𝚽𝐯
[(r −)R, k] ,
X(rR, k) ≠,
(.)

196
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
8
0
0.5
1
1.5
2
2.5
3
Time (s)
Frequency (kHz)
Amplitude
Figure 5.16 Speech spectrogram and waveform of a clean speech signal received at the first sensor,
x1(t): “Draw every outer line first, then fill in the interior.”
−5
0
5
10
15
5
10
15
20
25
(a)
(b)
(c)
(d)
−5
0
5
10
15
0
5
10
15
20
25
30
35
−5
0
5
10
15
6
8
10
12
14
16
18
20
22
−5
0
5
10
15
0
0.5
1
1.5
2
2.5
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(hW) (dB)
ξn (hW) (dB)
ξd (hW) (dB)
J (hW) (dB)
Figure 5.17 (a) The broadband gain in SNR, (b) the broadband MSE, (c) the broadband noise
reduction factor, and (d) the broadband desired signal reduction factor of the Wiener filter as a
function of the broadband input SNR, for different numbers of sensors, M: M = 1 (solid line with
circles), M = 2 (dashed line with asterisks), M = 5 (dotted line with squares), and M = 10 (dash-dot line
with triangles).
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
197
0
2
4
6
8
0
0.5
1
1.5
2
2.5
3
0
2
4
6
8
0
0.5
1
1.5
2
2.5
3
0
2
4
6
8
0
0.5
1
1.5
2
2.5
3
0
2
4
6
8
0
0.5
1
1.5
2
2.5
3
Time (s)
Time (s)
Time (s)
Time (s)
Amplitude
Frequency (kHz)
Amplitude
Frequency (kHz)
Amplitude
Frequency (kHz)
Amplitude
Frequency (kHz)
(a)
(b)
(d)
(c)
Figure 5.18 Speech spectrograms and waveforms of (a) noisy speech signal received at the first
sensor, y1(t) (iSNR = −5 dB), and the estimated signal, z(t), for (b) M = 1 [oSNR (𝗵W
) = 6.64 dB], (c)
M = 2 [oSNR (𝗵W
) = 8.72 dB], and (d) M = 5 [oSNR (𝗵W
) = 13.34 dB].
where 𝛼(< 𝛼< ) denotes a smoothing parameter. This method requires a voice
activity detector (VAD), but there are also alternative and more eﬃcient methods that
are based on minimum statistics [, ].
Finding an estimate for 𝜙X(rR, k) is a much more challenging problem [, ]. In
this example, for simplicity, we smooth ||Y(rR, k)||
in both time and frequency axes and
subtract an estimate of the noise, i.e.,
̂𝜙X(rR, k) = max
{
̂𝜙Y(rR, k) −̂𝜙V(rR, k), 
}
,
where ̂𝜙Y(rR, k) is obtained as a two-dimensional convolution between ||Y(rR, k)||

and a smoothing window w(rR, k). Here, the smoothing window is a two-dimensional
Hamming window of size × , normalized to ∑
r,k w(rR, k) = .
Figure .shows the spectrogram and waveform of the clean speech signal received
at the ﬁrst sensor, x(t). Figure .shows plots of the broadband gain in SNR, (𝐡W
),
the broadband MSE, J (𝐡W
), the broadband noise reduction factor, 𝜉n
(𝐡W
), and the
broadband desired signal reduction factor, 𝜉d
(𝐡W
), as a function of the broadband

198
Fundamentals of Signal Enhancement and Array Signal Processing
input SNR, for diﬀerent numbers of sensors, M. Figure .shows a realization of the
observation signal at the ﬁrst sensor, y(t), and the estimated signals, z(t), for diﬀerent
numbers of sensors, M. Clearly, as the number of sensors increases, the Wiener ﬁlter
better enhances the desired speech signal in terms of higher SNR and noise reduction,
and lower MSE and desired signal reduction.
Note that more useful algorithms for enhancing noisy speech signals in the STFT
domain are presented in [, , ].
■
Problems
5.1 Assume that the matrix 𝚽𝐯( f ) is nonsingular. Show that
|||𝐡H( f )𝐝( f )|||

≤[𝐡H( f )𝚽𝐯( f )𝐡( f )] [𝐝H( f )𝚽−
𝐯( f )𝐝( f )] ,
with equality if and only if 𝐡( f ) ∝𝚽−
𝐯( f )𝐝( f ).
5.2 Show that the narrowband output SNR is upper bounded by
oSNR
[
𝐡( f )
]
≤𝜙X( f ) × 𝐝H( f )𝚽−
𝐯( f )𝐝( f ), ∀𝐡( f ).
5.3 Show that
oSNR [𝐢i( f )] ≤𝜙X( f ) × 𝐝H( f )𝚽−
𝐯( f )𝐝( f ).
5.4 Show that
𝜙V( f ) × 𝐝H( f )𝚽−
𝐯( f )𝐝( f ) ≥.
5.5 Show that the narrowband desired signal distortion index is given by
𝜐d
[
𝐡( f )
]
= |||𝐡H( f )𝜸∗
X𝐱( f ) −|||

.
5.6 Show that the narrowband MSE can be written as
J
[
𝐡( f )
]
= 𝜙X( f ) + 𝐡H( f )𝚽𝐲( f )𝐡( f ) −𝜙X( f )𝐡H( f )𝜸∗
X𝐱( f )−
𝜙X( f )𝜸T
X𝐱( f )𝐡( f ).
5.7 Show that the narrowband MSEs are related to the narrowband performance
measures by
Jd
[𝐡( f )]
Jn
[𝐡( f )] = iSNR( f ) × 𝜉n
[
𝐡( f )
]
× 𝜐d
[
𝐡( f )
]
= oSNR [𝐡( f )] × 𝜉d
[𝐡( f )] × 𝜐d
[𝐡( f )] .
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
199
5.8 Show that the broadband MSEs are related to the broadband performance mea-
sures by
Jd (𝐡)
Jn (𝐡) = iSNR × 𝜉n (𝐡) × 𝜐d (𝐡)
= oSNR (𝐡) × 𝜉d (𝐡) × 𝜐d (𝐡) .
5.9 Show that the narrowband output SNR can be written as
oSNR [𝐡( f )] =
𝜙X( f )𝐡H( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f )𝐡( f )
𝐡H( f )𝚽𝐯( f )𝐡( f )
.
5.10 Show that the maximum eigenvalue corresponding to the eigenvector of the
matrix 𝜙X( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )𝜸T
X𝐱( f ) is given by
𝜆( f ) = 𝜙X( f )𝜸T
X𝐱( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f ).
5.11 Show that the maximum SNR ﬁlter is given by
𝐡max( f ) = 𝜍( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f ),
where 𝜍( f ) is an arbitrary frequency-dependent complex number diﬀerent from
zero.
5.12 Denote by oSNR(m)
max( f ) the maximum narrowband output SNR of an array with
m sensors. Show that
oSNR(M)
max( f ) ≥oSNR(M−)
max ( f ) ≥⋯≥oSNR()
max( f ) ≥
oSNR()
max( f ) = iSNR( f ).
5.13 Consider a desired signal that is a harmonic pulse of T samples:
x(t) =
{
A sin
(
𝜋ft + 𝜙
)
,
≤t ≤T −
,
t < , t ≥T
,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly dis-
tributed on the interval from to 𝜋. Suppose that the desired signal impinges on
a ULA of M sensors from the direction 𝜃.
a) Show that the variance of 𝐱( f ) is
𝚽𝐱( f ) = 𝜙X( f )𝐝( f )𝐝H( f ),
where
𝜙X( f ) = A
D
T
[𝜋(f + f
)] + A
D
T
[𝜋(f −f
)] ,
𝐝( f ) = [

e−𝚥𝜋f 𝜏
e−𝚥𝜋f 𝜏
⋯
e−𝚥𝜋f 𝜏M ]T .

200
Fundamentals of Signal Enhancement and Array Signal Processing
b) Assume an interference u(t) ∼(, 𝜎
u
) that impinges on the ULA from the
endﬁre direction. Show that
𝚽𝐮( f ) = 𝜙U( f )𝜸∗
U𝐮( f )𝜸T
U𝐮( f ).
c) Compute the narrowband and broadband input SNRs.
d) Show that with the maximum SNR ﬁlter the narrowband gain in SNR can be
written as
[𝐡max( f )] =
oSNR [𝐡max( f )]
iSNR( f )
= 𝐝H( f )
[
𝜎
u
𝜎
u + 𝜎
w
𝜸∗
U𝐮( f )𝜸T
U𝐮( f ) +
𝜎
w
𝜎
u + 𝜎
w
𝐈M
]−
𝐝( f ).
5.14 Show that by minimizing the narrowband MSE, J [𝐡( f )], we obtain the Wiener
ﬁlter:
𝐡W( f ) = 𝜙X( f )𝚽−
𝐲( f )𝜸∗
X𝐱( f ).
5.15 Show that the Wiener ﬁlter can be expressed as
𝐡W( f ) =
iSNR( f )
+ iSNR( f )𝚪−
𝐲( f )𝜸∗
X𝐱( f ).
5.16 Show that the Wiener ﬁlter can be written as
𝐡W( f ) =
[
𝐈M −𝚽−
𝐲( f )𝚽𝐯( f )
]
𝐢i.
5.17 Show that the Wiener ﬁlter can be written as
𝐡W( f ) =
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
−M + tr [𝚽−
𝐯( f )𝚽𝐲( f )]𝐢i.
5.18 Show that with the Wiener ﬁlter, the narrowband output SNR is
oSNR
[
𝐡W( f )
]
= tr
[
𝚽−
𝐯( f )𝚽𝐲( f )
]
−M.
5.19 Show that with the Wiener ﬁlter, the broadband output SNR is always greater than
or equal to the broadband input SNR, i.e., oSNR (𝐡W
) ≥iSNR.
5.20 Show that by minimizing the narrowband MSE of the residual noise, Jn
[𝐡( f )],
with the constraint that the desired signal is not distorted yields
𝐡MVDR( f ) =
𝚽−
𝐯( f )𝜸∗
X𝐱( f )
𝜸T
X𝐱( f )𝚽−
𝐯( f )𝜸∗
X𝐱( f )
.
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
201
5.21 Show that the MVDR ﬁlter can be written as
𝐡MVDR( f ) =
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
tr [𝚽−
𝐯( f )𝚽𝐲( f )] −M
𝐢i.
5.22 Show that the MVDR ﬁlter can be written as
𝐡MVDR( f ) =
[
+ iSNR( f )
]
𝚪−
𝐯( f )𝚪𝐲( f ) −𝐈M
[+ iSNR( f )] tr [𝚪−
𝐯( f )𝚪𝐲( f )] −M
𝐢i.
5.23 Show that the MVDR ﬁlter can be written as
𝐡MVDR( f ) =
𝚽−
𝐲( f )𝜸∗
X𝐱( f )
𝜸T
X𝐱( f )𝚽−
𝐲( f )𝜸∗
X𝐱( f )
.
5.24 Show that the Wiener and MVDR ﬁlters are related by
𝐡W( f ) = C( f )𝐡MVDR( f ),
where C( f ) is a real number, with < C( f ) < .
5.25 Show that
a) oSNR [𝐡MVDR( f )] = oSNR [𝐡W( f )],
b) 𝜐d
[𝐡MVDR( f )] = ,
c) 𝜉d
[𝐡MVDR( f )] = ,
d) 𝜉n
[
𝐡MVDR( f )
]
≤𝜉n
[
𝐡W( f )
]
,
e) 𝜉n
(𝐡MVDR
) ≤𝜉n
(𝐡W
).
5.26 Show that with the MVDR ﬁlter, the broadband output SNR is always greater than
or equal to the broadband input SNR, i.e., oSNR (𝐡MVDR
) ≥iSNR.
5.27 Show that by minimizing the narrowband desired signal distortion index with the
constraint that the narrowband noise reduction factor is equal to a positive value

ℵwe obtain the tradeoﬀﬁlter:
𝐡T,𝜇( f ) =
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
𝜇−M + tr [𝚽−
𝐯( f )𝚽𝐲( f )]𝐢i,
where 𝜇is a Lagrange multiplier.
5.28 Show that for
a) 𝜇= , 𝐡T,( f ) = 𝐡W( f ),
b) 𝜇= , 𝐡T,( f ) = 𝐡MVDR( f ),
c) 𝜇> , 𝐡T,𝜇( f ) results in a ﬁlter with low residual noise at the expense of high
desired signal distortion (as compared to Wiener), and

202
Fundamentals of Signal Enhancement and Array Signal Processing
d) 𝜇< , 𝐡T,𝜇( f ) results in a ﬁlter with high residual noise and low desired signal
distortion (as compared to Wiener).
5.29 Show that the tradeoﬀ, Wiener, and maximum SNR ﬁlters are equivalent up to a
real-valued number.
5.30 Show that the narrowband output SNR of the tradeoﬀﬁlter is independent of 𝜇
and is identical to the narrowband output SNR of the maximum SNR ﬁlter, i.e.,
oSNR [𝐡T,𝜇( f )] = oSNR [𝐡max( f )] , ∀𝜇≥.
5.31 Show that
𝜐d
[𝐡T,𝜇( f )] =
[
𝜇
𝜇+ 𝜆( f )
]
,
𝜉d
[𝐡T,𝜇( f )] =
[
+
𝜇
𝜆( f )
]
,
𝜉n
[𝐡T,𝜇( f )] =
[𝜇+ 𝜆( f )]
iSNR( f ) × 𝜆( f ).
5.32 Show that the broadband output SNR of the tradeoﬀﬁlter is an increasing
function of the parameter 𝜇.
5.33 Show that the broadband desired signal distortion index of the tradeoﬀﬁlter is an
increasing function of the parameter 𝜇.
5.34 Show that with the tradeoﬀﬁlter, the broadband output SNR is always greater
than or equal to the broadband input SNR, i.e., oSNR (𝐡T,𝜇
) ≥iSNR, ∀𝜇≥.
5.35 Show that for 𝜇≥,
iSNR ≤oSNR (𝐡MVDR
) ≤oSNR (𝐡W
) ≤oSNR (𝐡T,𝜇
) ,
= 𝜐d
(𝐡MVDR
) ≤𝜐d
(𝐡W
) ≤𝜐d
(𝐡T,𝜇
) ,
and for ≤𝜇≤,
iSNR ≤oSNR (𝐡MVDR
) ≤oSNR (𝐡T,𝜇
) ≤oSNR (𝐡W
) ,
= 𝜐d
(
𝐡MVDR
)
≤𝜐d
(
𝐡T,𝜇
)
≤𝜐d
(
𝐡W
)
.
5.36 Show that by minimizing the energy at the ﬁlter output, with the constraints that
the coherent noise components are cancelled and the desired signal is preserved,
yields the LCMV ﬁlter:
𝐡LCMV( f ) = 𝚽−
𝐲( f )𝐂XV( f )
[
𝐂H
XV( f )𝚽−
𝐲( f )𝐂XV( f )
]−[


]
.
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
203
5.37 Show that
a) oSNR (𝐡LCMV
) ≤oSNR (𝐡MVDR
),
b) 𝜐d
(𝐡LCMV
) = ,
c) 𝜉d
(𝐡LCMV
) = ,
d) 𝜉n
(
𝐡LCMV
)
≤𝜉n
(
𝐡MVDR
)
≤𝜉n
(
𝐡W
)
.
5.38 Show that the LCMV ﬁlter can be split into two components operating on
orthogonal subspaces:
𝐡LCMV( f ) = 𝐡MN( f ) −𝐁𝐂( f )𝐰GSC( f ).
5.39 Show that the ﬁlter 𝐰GSC( f ) is given by
𝐰GSC( f ) =
[
𝐁H
𝐂( f )𝚽𝐲( f )𝐁𝐂( f )
]−𝐁H
𝐂( f )𝚽𝐲( f )𝐡MN( f ).
5.40 Show that the minimization of E
[|||
̂X( f )|||
]
with respect to 𝐰( f ) yields the ﬁlter
𝐰GSC( f ).
5.41 Show that the two ﬁlters LCMV and GSC are equivalent, i.e.,
𝐢T
c
[
𝐂H( f )𝚽−
𝐲( f )𝐂( f )
]−
𝐂H( f )𝚽−
𝐲( f )
= 𝐡H
MN( f )
{
𝐈M −𝚽𝐲( f )𝐁𝐂( f ) [𝐁H
𝐂( f )𝚽𝐲( f )𝐁𝐂( f )]−𝐁H
𝐂( f )
}
.
5.42 Consider multichannel noise reduction ﬁlters that have the form 𝐡∶N( f ) =
𝐓∶N( f )𝐚( f ). Show that
a) the narrowband WNG can be expressed as
[𝐡∶N( f )] =
|||𝐚H( f )𝐓H
∶N( f )𝐝( f )|||

𝐚H( f )𝐓H
∶N( f )𝐓∶N( f )𝐚( f )
,
b) the vector 𝐚( f ) that maximizes [𝐚( f )] is
𝐚( f ) = 𝜍( f ) [𝐓H
∶N( f )𝐓∶N( f )]−𝐓H
∶N( f )𝐝( f ),
where 𝜍( f ) ≠is an arbitrary complex number,
c) the MSE is given by
J [𝐡∶N( f )] = |𝜍( f )|𝐝H( f )𝐏𝐓∶N( f )𝚽𝐲( f )𝐏𝐓∶N( f )𝐝( f ) + 𝜙X( f )
−𝜍∗( f )𝜙X( f )𝐝H( f )𝐏𝐓∶N( f )𝐝( f )
−𝜍( f )𝜙X( f )𝐝H( f )𝐏𝐓∶N( f )𝐝( f ),

204
Fundamentals of Signal Enhancement and Array Signal Processing
d) and the minimization of J [𝐡∶N( f )] leads to
𝜍( f ) =
𝜙X( f )𝐝H( f )𝐏𝐓∶N( f )𝐝( f )
𝐝H( f )𝐏𝐓∶N( f )𝚽𝐲( f )𝐏𝐓∶N( f )𝐝( f ).
References
1 J. Benesty, J. Chen, and Y. Huang, Microphone Array Signal Processing. Berlin,
Germany: Springer-Verlag, .
2 J. Benesty, J. Chen, Y. Huang, and I. Cohen, Noise Reduction in Speech Processing.
Berlin, Germany: Springer-Verlag, .
3 J. Benesty, J. Chen, and E. Habets, Speech Enhancement in the STFT Domain. Springer
Briefs in Electrical and Computer Engineering, .
4 J. P. Dmochowski and J. Benesty, “Microphone arrays: fundamental concepts,” in Speech
Processing in Modern Communication–Challenges and Perspectives, I. Cohen, J.
Benesty, and S. Gannot, Eds., Berlin, Germany: Springer-Verlag, , Chapter , pp.
–, .
5 J. N. Franklin, Matrix Theory. Englewood Cliﬀs, NJ: Prentice-Hall, .
6 J. Capon, “High resolution frequency-wavenumber spectrum analysis,” Proc. IEEE, vol.
, pp. –, Aug. .
7 R. T. Lacoss, “Data adaptive spectral analysis methods,” Geophysics, vol. , pp.
–, Aug. .
8 M. Souden, J. Benesty, and S. Aﬀes, “On the global output SNR of the parameterized
frequency-domain multichannel noise reduction Wiener ﬁlter,” IEEE Signal Process.
Lett., vol. , pp. –, May .
9 J. Benesty, J. Chen, Y. Huang, and J. Dmochowski, “On microphone-array beamforming
from a MIMO acoustic signal processing perspective,” IEEE Trans. Audio, Speech,
Language Process., vol. , pp. –, Mar. .
10 A. Booker and C. Y. Ong, “Multiple constraint adaptive ﬁltering,” Geophysics, vol. ,
pp. –, June .
11 O. Frost, “An algorithm for linearly constrained adaptive array processing,” Proc. IEEE,
vol. , pp. –, Jan. .
12 M. Er and A. Cantoni, “Derivative constraints for broad-band element space antenna
array processors,” IEEE Trans. Acoust., Speech, Signal Process., vol. , pp. –,
Dec. .
13 L. J. Griﬃths and C. W. Jim, “An alternative approach to linearly constrained adaptive
beamforming,” IEEE Trans. Antennas Propagat., vol. AP-, pp. –, Jan. .
14 K. M. Buckley, “Broad-band beamforming and the generalized sidelobe canceller,” IEEE
Trans. Acoust., Speech, Signal Process., vol. ASSP-, pp. –, Oct. .
15 K. M. Buckley and L. J. Griﬃths, “An adaptive generalized sidelobe canceller with
derivative constraints,” IEEE Trans. Antennas Propagat., vol. AP-, pp. –, Mar.
.
16 S. Werner, J. A. Apolinário, Jr., and M. L. R. de Campos, “On the equivalence of RLS
implementations of LCMV and GSC processors,” IEEE Signal Process. Lett., vol. , pp.
–, Dec. .
www.ebook3000.com

Multichannel Signal Enhancement in the Frequency Domain
205
17 B. R. Breed and J. Strauss, “A short proof of the equivalence of LCMV and GSC
beamforming,” IEEE Signal Process. Lett., vol. , pp. –, June .
18 J. Wexler and S. Raz, “Discrete Gabor expansions,” Speech Process., vol. , pp. –,
Nov. .
19 S. Qian and D. Chen, “Discrete Gabor transform,” IEEE Trans. Signal Process., vol. ,
pp. –, July .
20 Y. Avargel and I. Cohen, “On multiplicative transfer function approximation in the
short-time Fourier transform domain,” IEEE Signal Process. Lett., vol. , pp. –,
May .
21 R. E. Crochiere and L. R. Rabiner, Multirate Digital Signal Processing. Englewood Cliﬀs,
New Jersey: Prentice-Hall, .
22 R. Martin, “Noise power spectral density estimation based on optimal smoothing and
minimum statistics,” IEEE Trans. Speech, Audio Process., vol. , pp. –, July .
23 I. Cohen, “Noise spectrum estimation in adverse environments: improved minima
controlled recursive averaging,” IEEE Trans. Speech, Audio Process., vol. , pp.
–, Sept. .
24 I. Cohen, “Relaxed statistical model for speech enhancement and a priori SNR
estimation,” IEEE Trans. Speech, Audio Process., vol. , pp. –, Sept. .
25 I. Cohen, “Speech spectral modeling and enhancement based on autoregressive
conditional heteroscedasticity models,” Signal Process., vol. , pp. –, Apr. .
26 I. Cohen and B. Berdugo, “Speech enhancement for non-stationary noise
environments,” Signal Process., vol. , pp. –, Nov. .
27 I. Cohen and S. Gannot, “Spectral enhancement methods,” in J. Benesty, M. M. Sondhi,
and Y. Huang (Eds.), Springer Handbook of Speech Processing, Springer-Verlag, ,
Part H, Chapter , pp. –.

207
6
An Exhaustive Class of Linear Filters
This chapter is a generalization of the four previous chapters but presented in a more
uniﬁed framework. Therefore the signal enhancement problem in the time or frequency
domain, with one sensor or multiple sensors, looks very similar. Within this framework,
we derive a very large class of well-known optimal linear ﬁlters as well as a category of
ﬁlters whose output signal-to-interference-plus-noise ratios (SINRs) are between the
conventional maximum SINR and Wiener ﬁlters. With this very ﬂexible approach, any
kind of ﬁlter can be designed in order to make a compromise, in a very precise manner,
between interference-plus-noise reduction and desired signal distortion. This chapter
will also serve as a bridge between the problem of noise reduction studied so far and
the forthcoming chapters on beamforming.
6.1
Signal Model and Problem Formulation
We consider the very general signal model of an observed signal’s vector of length M:
𝐲=
[ y
y
⋯
yM
]T
= 𝐱+ 𝐯+
N
∑
n=
𝐯n
= 𝐱+ 𝐯+ 𝐯,
(.)
where 𝐱is the desired signal vector, 𝐯is the additive white noise signal vector, 𝐯n, n =
, , … , N are N interferences, and 𝐯= ∑N
n=𝐯n. All vectors on the right-hand side
of (.) are deﬁned in a similar way to the noisy signal vector, 𝐲. The entries of 𝐲can
be, for example, the signals picked up by M sensors. All signals are considered to be
random, complex, circular, zero mean, and stationary. Furthermore, the vectors 𝐱, 𝐯,
and 𝐯n, n = , , … , N are assumed to be mutually uncorrelated: E (𝐱𝐯H

) = E (𝐱𝐯H
n
) =
E
(
𝐯𝐯H
n
)
= E
(
𝐯i𝐯H
j
)
= 𝟎, ∀i ≠j, i, j = , , … , N. In this context, the correlation
matrix (of size M × M) of the observations can be written as
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing
www.ebook3000.com

208
Fundamentals of Signal Enhancement and Array Signal Processing
𝚽𝐲= E
(
𝐲𝐲H)
(.)
= 𝚽𝐱+ 𝚽𝐯+
N
∑
n=
𝚽𝐯n
= 𝚽𝐱+ 𝚽𝐯+ 𝚽𝐯
= 𝚽𝐱+ 𝚽in,
where 𝚽𝐱= E (𝐱𝐱H), 𝚽𝐯= E (𝐯𝐯H

), and 𝚽𝐯n = E (𝐯n𝐯H
n
) are the correlation
matrices of 𝐱, 𝐯, and 𝐯n, respectively, 𝚽𝐯= ∑N
n=𝚽𝐯n, and 𝚽in = 𝚽𝐯+ 𝚽𝐯is
the interference-plus-noise correlation matrix. Since 𝐯is assumed to be white, its
correlation matrix simpliﬁes to 𝚽𝐯= 𝜙v𝐈M, where 𝜙v= E
(
||v||
)
is the variance of v,
the ﬁrst component of 𝐯. In the rest of this chapter, the desired signal and interference
correlation matrices are assumed to have the following ranks: rank (𝚽𝐱
) = Rx ≤M and
rank (𝚽𝐯n
) = Rvn < M. Let Rv = min
(∑N
n=Rvn, M
)
. We deduce that rank (𝚽𝐯
) = Rv
and, obviously, rank
(
𝚽in
)
= M. Then, the objective of signal enhancement (or noise
reduction) is to estimate the ﬁrst element of 𝐱, x(the desired signal sample), from
the diﬀerent second-order statistics available from (.) in the best possible way. This
should be done in such a way that the noise and the interference are reduced as much
as possible, with little or no distortion of the desired signal. The matrix 𝚽𝐲can be easily
estimated from the observations, but 𝚽𝐯and 𝚽𝐯are more tricky to estimate. However,
in many applications, it is still possible to get reliable estimates of these matrices [, ],
which will be assumed here.
A very important particular case of the model described above is the conventional
beamforming problem, which can be formulated as [, ]:
𝐲= 𝐝x+ 𝐯+ 𝐯,
(.)
where 𝐝is the steering vector of length M, the ﬁrst entry of which is equal to . This
vector can be deterministic or random. In the former case, the desired signal correlation
matrix is 𝚽𝐱= 𝜙x𝐝𝐝H (the rank of which is, indeed, equal to ), where 𝜙x= E
(
||x||
)
is
the variance of x. When the steering vector is random, the rank of 𝚽𝐱is no longer [].
Some decompositions of the diﬀerent matrices are necessary in order to fully exploit
the structure of the signals. Using the well-known eigenvalue decomposition [], the
desired signal correlation matrix can be diagonalized as
𝐐H
𝐱𝚽𝐱𝐐𝐱= 𝚲𝐱,
(.)
where
𝐐𝐱=
[ 𝐪𝐱,
𝐪𝐱,
⋯
𝐪𝐱,M
]
(.)
is a unitary matrix: 𝐐H
𝐱𝐐𝐱= 𝐐𝐱𝐐H
𝐱= 𝐈M, and
𝚲𝐱= diag
(
𝜆𝐱,, 𝜆𝐱,, … , 𝜆𝐱,M
)
(.)

An Exhaustive Class of Linear Filters
209
is a diagonal matrix. The orthonormal vectors 𝐪𝐱,, 𝐪𝐱,, … , 𝐪𝐱,M are the eigenvectors
corresponding, respectively, to the eigenvalues 𝜆𝐱,, 𝜆𝐱,, … , 𝜆𝐱,M of the matrix 𝚽𝐱,
where 𝜆𝐱,≥𝜆𝐱,≥⋯≥𝜆𝐱,Rx > and 𝜆𝐱,Rx+= 𝜆𝐱,Rx+= ⋯= 𝜆𝐱,M = . In the
same way, the nth interference correlation matrix can be diagonalized as
𝐐H
𝐯n𝚽𝐯n𝐐𝐯n = 𝚲𝐯n,
(.)
where the unitary and diagonal matrices 𝐐𝐯n and 𝚲𝐯n are deﬁned in a similar way to 𝐐𝐱
and 𝚲𝐱, respectively, with 𝜆𝐯n,≥𝜆𝐯n,≥⋯≥𝜆𝐯n,Rvn > and 𝜆𝐯n,Rvn+= 𝜆𝐯n,Rvn+=
⋯= 𝜆𝐯n,M = . It may also be useful to diagonalize the matrix 𝚽𝐯as well; that is,
𝐐H
𝐯𝚽𝐯𝐐𝐯= 𝚲𝐯,
(.)
where 𝐐𝐯and 𝚲𝐯are similarly deﬁned to 𝐐𝐱and 𝚲𝐱, respectively, with 𝜆𝐯,≥𝜆𝐯,≥
⋯≥𝜆𝐯,Rv > and 𝜆𝐯,Rv+= 𝜆𝐯,Rv+= ⋯= 𝜆𝐯,M = . All these decompositions will be
extensively used in the rest of this chapter.
6.2
Linear Filtering for Signal Enhancement
By far, the most convenient and practical way to perform signal enhancement – to
estimate the desired signal, x– is by applying a linear ﬁlter to the observation signal
vector, 𝐲, as illustrated in Figure .:
z = 𝐡H𝐲
(.)
= 𝐡H (𝐱+ 𝐯+ 𝐯)
= xfd + vrn + vri,
where z is the estimate of xor the ﬁlter output signal,
𝐡= [ h
h
⋯
hM
]T
(.)
is a complex-valued ﬁlter of length M,
xfd = 𝐡H𝐱
(.)
is the ﬁltered desired signal,
vrn = 𝐡H𝐯
(.)
is the residual noise, and
vri = 𝐡H𝐯
(.)
is the residual interference. We deduce that the variance of z is
𝜙z = E (
|z|)
(.)
= 𝜙xfd + 𝜙vrn + 𝜙vri,
www.ebook3000.com

210
Fundamentals of Signal Enhancement and Array Signal Processing
+
v
v0
hH
x
y
Figure 6.1 Block diagram of linear filtering.
where
𝜙xfd = 𝐡H𝚽𝐱𝐡,
(.)
𝜙vrn = 𝜙v𝐡H𝐡,
(.)
𝜙vri = 𝐡H𝚽𝐯𝐡.
(.)
6.3
Performance Measures
Performance measures are not only useful for the derivation of diﬀerent kinds of optimal
ﬁlters but also for their evaluation. These measures can be divided into two distinct
but related categories. The ﬁrst category evaluates the noise reduction performance
while the second evaluates the desired signal distortion. We will use, as before, the MSE
criterion.
One of the most fundamental measures in our context is the signal-to-interference-
plus-noise ratio (SINR). The input SINR is a second-order measure, which quantiﬁes
the level of the interference-plus-noise present relative to the level of the desired signal.
By taking the ﬁrst element of 𝐲as the reference, this measure is deﬁned as
iSINR =
𝜙x
𝜙v+ 𝜙v
,
(.)
where 𝜙v is the variance of v = ∑N
n=vn, with vnbeing the ﬁrst entry of 𝐯n. Another
useful measure is the input signal-to-interference ratio (SIR):
iSIR =
𝜙x
𝜙v
.
(.)
The output SINR helps quantify the level of the interference-plus-noise remaining in
the ﬁlter output signal. The output SINR is obtained from (.):
oSINR (𝐡) =
𝜙xfd
𝜙vrn + 𝜙vri
(.)

An Exhaustive Class of Linear Filters
211
= 𝐡H𝚽𝐱𝐡
𝐡H𝚽in𝐡.
Basically, (.) is the variance of the ﬁrst signal (ﬁltered desired) from the right-hand
side of (.) over the variance of the two other signals (residual interference-plus-
noise). Since the matrix 𝚽in in the denominator of (.) is full rank, the output SINR
is upper bounded. The objective of the signal enhancement ﬁlter is to make the output
SINR greater than the input SINR. Consequently, the quality of the ﬁlter output signal
may be enhanced compared to the noisy signal. It is straightforward to see that the
output SIR is
oSIR (𝐡) = 𝐡H𝚽𝐱𝐡
𝐡H𝚽𝐯𝐡.
(.)
Since the matrix 𝚽𝐯in the denominator of (.) may not be full rank, the output SIR
may not be upper bounded.
For the particular ﬁlter of length M:
𝐢i =
[ 

⋯
]T ,
(.)
we have
oSINR (𝐢i
) = iSINR,
(.)
oSIR (𝐢i
) = iSIR.
(.)
With the identity ﬁlter, 𝐢i, neither the SINR nor the SIR can be improved.
Since the noise and interference are reduced by the ﬁltering operation, so, in general,
is the desired signal. This implies distortion, which we can measure with the desired
signal distortion index, which is deﬁned as the MSE between the desired signal and the
ﬁltered desired signal, normalized by the variance of the desired signal:
𝜐(𝐡) =
E
(
||xfd −x||
)
E
(
||x||
)
(.)
=
(
𝐡−𝐢i
)H 𝚽𝐱
(
𝐡−𝐢i
)
𝜙x
.
The desired signal distortion index is close to if there is little distortion and greater
than when distortion occurs.
Error criteria play a critical role in deriving optimal ﬁlters. The MSE [], as we already
know, is, by far, the most practical one. We deﬁne the error signal between the estimated
and desired signals as
e = z −x
(.)
= xfd + vrn + vri −x,
www.ebook3000.com

212
Fundamentals of Signal Enhancement and Array Signal Processing
which can be written as the sum of three mutually uncorrelated error signals:
e = ed + en + ei,
(.)
where
ed = xfd −x
(.)
= (𝐡−𝐢i
)H 𝐱
is the desired signal distortion due to the ﬁlter,
en = vrn = 𝐡H𝐯
(.)
is the residual noise, and
ei = vri = 𝐡H𝐯
(.)
is the residual interference. Therefore, the MSE criterion is
J (𝐡) = E
(
|e|)
(.)
= 𝜙x+ 𝐡H𝚽𝐲𝐡−𝐡H𝚽𝐱𝐢i −𝐢T
i 𝚽𝐱𝐡
= Jd (𝐡) + Jn (𝐡) + Ji (𝐡) ,
where
Jd (𝐡) = E
(
||ed||
)
(.)
=
(
𝐡−𝐢i
)H 𝚽𝐱
(
𝐡−𝐢i
)
= 𝜙x𝜐(𝐡) ,
Jn (𝐡) = E
(
||en||
)
= 𝜙v𝐡H𝐡,
(.)
Ji (𝐡) = E
(
||ei||
)
= 𝐡H𝚽𝐯𝐡.
(.)
6.4
Optimal Filters
In this section, we derive a large class of well-known optimal linear ﬁlters by fully
exploiting the structure of the signals, which was not really done before. To that end,
the performance measures described in the previous section are of great help.
6.4.1
Wiener
The Wiener ﬁlter is derived from the MSE, J (𝐡), in (.), by taking its gradient with
respect to 𝐡and equating the result to zero:
𝐡W = 𝚽−
𝐲𝚽𝐱𝐢i.
(.)

An Exhaustive Class of Linear Filters
213
This optimal ﬁlter can also be expressed as
𝐡W =
(
𝐈M −𝚽−
𝐲𝚽in
)
𝐢i.
(.)
The above formulation is more useful than (.) in practice since it depends on
the second-order statistics of the observation and interference-plus-noise signals. The
correlation matrix 𝚽𝐲can be estimated from the observation signal while the other
correlation matrix, 𝚽in, is often known or can be indirectly estimated. In speech
applications, for example, this matrix can be estimated during silences.
Let
𝐐𝐱= [ 𝐐′
𝐱
𝐐′′
𝐱
] ,
(.)
where the M × Rx matrix 𝐐′
𝐱contains the eigenvectors corresponding to the nonzero
eigenvalues of 𝚽𝐱and the M × (M −Rx) matrix 𝐐′′
𝐱contains the eigenvectors corre-
sponding to the null eigenvalues of 𝚽𝐱. It can be veriﬁed that
𝐈M = 𝐐′
𝐱𝐐′H
𝐱+ 𝐐′′
𝐱𝐐′′H
𝐱.
(.)
Notice that 𝐐′
𝐱𝐐′H
𝐱
and 𝐐′′
𝐱𝐐′′H
𝐱
are two orthogonal projection matrices of rank Rx
and M −Rx, respectively. Hence 𝐐′
𝐱𝐐′H
𝐱
is the orthogonal projector onto the desired
signal subspace (where all the energy of the desired signal is concentrated) or the range
of 𝚽𝐱, and 𝐐′′
𝐱𝐐′′H
𝐱
is the orthogonal projector onto the null subspace of 𝚽𝐱. With
the eigenvalue decomposition of 𝚽𝐱, the correlation matrix of the observations’ signal
vector can be written as
𝚽𝐲= 𝐐′
𝐱𝚲′
𝐱𝐐′H
𝐱+ 𝚽in,
(.)
where
𝚲′
𝐱= diag
(
𝜆𝐱,, 𝜆𝐱,, … , 𝜆𝐱,Rx
)
(.)
is a diagonal matrix of size Rx × Rx. Determining the inverse of 𝚽𝐲from (.) with the
Woodbury identity, we get
𝚽−
𝐲= 𝚽−
in −𝚽−
in 𝐐′
𝐱
(𝚲′−
𝐱
+ 𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝚽−
in .
(.)
Substituting (.) into (.), leads to another useful formulation of the Wiener ﬁlter:
𝐡W = 𝚽−
in 𝐐′
𝐱
(𝚲′−
𝐱
+ 𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝐢i.
(.)
It can be shown that with the optimal Wiener ﬁlter given in (.), the output SINR
is always greater than or equal to the input SINR: oSINR (𝐡W
) ≥iSINR [].
Example ..
Consider a ULA of M sensors, as shown in Figure .. Suppose that
a desired signal impinges on the ULA from the direction 𝜃x and that an interference
www.ebook3000.com

214
Fundamentals of Signal Enhancement and Array Signal Processing
impinges on the ULA from the direction 𝜃v. Assume that the desired signal received at
the ﬁrst sensor is a complex harmonic random process:
x(t) = A exp
(
𝚥𝜋ft + 𝚥𝜑
)
,
with ﬁxed amplitude A and frequency f, and random phase 𝜑, uniformly distributed
on the interval from to 𝜋. Assume that the interference received at the ﬁrst sensor,
v(t), is a random process with the autocorrelation sequence:
E [v(t)v(t′)] = 𝛼|t−t′|, −< 𝛼< .
In addition, the sensors contain thermal white Gaussian noise, with correlation matrix
𝚽𝐯= 𝜙v𝐈M. The desired signal needs to be recovered from the noisy observation,
𝐲(t) = 𝐝x(t) + 𝐯+ 𝐯, where 𝐝is the steering vector of the desired signal.
Since the desired source impinges on the ULA from the direction 𝜃x, we have for
m = , … , M:
xm(t) = x
(t −𝜏x,m
) = e−𝚥𝜋f𝜏x,mx(t) ,
where
𝜏x,m = (m −)d cos 𝜃x
cTs
is the relative time delay in samples between the desired signals xm(t) and x(t) received
at the mth sensor and the ﬁrst one, and Ts is the sampling interval. Hence, 𝐱(t) = 𝐝x(t),
where
𝐝= [

e−𝚥𝜋f𝜏x,
e−𝚥𝜋f𝜏x,
⋯
e−𝚥𝜋f𝜏x,M ]T .
Similarly,
um(t) = u
(t −𝜏v,m
) ,
where
𝜏v,m = (m −)d cos 𝜃v
cTs
is the relative time delay in samples between the interferences received at the mth
sensor and the ﬁrst one. Assuming that the sampling interval satisﬁes Ts = d
c , we have
𝜏x,m = (m −) cos 𝜃x and 𝜏v,m = (m −) cos 𝜃v. The desired signal correlation matrix is
𝚽𝐱= 𝜙x𝐝𝐝H, where 𝜙x= A. The elements of the M × M correlation matrix of the
interference are
[
𝚽𝐯
]
i,j = 𝛼|𝜏v,i−𝜏v,j|.
The input SINR is
iSINR = log
A
𝜙v+ 
(dB).

An Exhaustive Class of Linear Filters
215
−5
0
5
10
15
1
2
3
4
5
6
7
8
9
−5
0
5
10
15
−30
−25
−20
−15
−10
−5
−5
0
5
10
15
−50
−40
−30
−20
−10
0
iSINR (dB)
iSINR (dB)
iSINR (dB)
(a)
(b)
(c)
 (hW) (dB)
 J (hW) (dB)
 (hW) (dB)
Figure 6.2 (a) The gain in SINR, (b) the MSE, and (c) the desired signal distortion index of the Wiener
filter as a function of the input SINR for different numbers of sensors, M: M = 10 (solid line with circles),
M = 20 (dashed line with asterisks), M = 50 (dotted line with squares), and M = 100 (dash-dot line
with triangles).
The optimal ﬁlter 𝐡W is obtained from (.).
To demonstrate the performance of the Wiener ﬁlter, we choose f= ., 𝜃x = ◦,
𝜃v = ◦, 𝛼= ., and 𝜙v= .. Figure .shows plots of the gain in SINR, 
(
𝐡W
)
=
oSINR
(
𝐡W
)
∕iSINR, the MSE, J
(
𝐡W
)
, and the desired signal distortion index, 𝜐
(
𝐡W
)
,
as a function of the input SINR for diﬀerent numbers of sensors, M. The gain in SINR is
always positive. For a given input SINR, as the number of sensors increases, the gain in
SINR increases, while the MMSE and the desired signal distortion index decrease.
■
6.4.2
MVDR
In this subsection, we derive a distortionless ﬁlter, which is able to reduce the
interference-plus-noise, by exploiting the nullspace of 𝚽𝐱. Using (.), we can write
the desired signal vector as
𝐱= 𝐐𝐱𝐐H
𝐱𝐱
(.)
= 𝐐′
𝐱𝐐′H
𝐱𝐱.
www.ebook3000.com

216
Fundamentals of Signal Enhancement and Array Signal Processing
We deduce from (.) that the distortionless constraint is
𝐡H𝐐′
𝐱= 𝐢T
i 𝐐′
𝐱,
(.)
since, in this case,
𝐡H𝐱= 𝐡H𝐐′
𝐱𝐐′H
𝐱𝐱
(.)
= 𝐢T
i 𝐐′
𝐱𝐐′H
𝐱𝐱
= x.
Now, from the minimization of the criterion:
min
𝐡
[Jn (𝐡) + Ji (𝐡)
]
subject to 𝐡H𝐐′
𝐱= 𝐢T
i 𝐐′
𝐱,
(.)
which is the minimization of the residual interference-plus-noise subject to the distor-
tionless constraint, we ﬁnd the MVDR ﬁlter:
𝐡MVDR = 𝚽−
in 𝐐′
𝐱
(
𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝐢i.
(.)
It is interesting to compare this ﬁlter with the form of the Wiener ﬁlter given in (.).
It can be shown that (.) can also be expressed as
𝐡MVDR = 𝚽−
𝐲𝐐′
𝐱
(
𝐐′H
𝐱𝚽−
𝐲𝐐′
𝐱
)−
𝐐′H
𝐱𝐢i.
(.)
It can be veriﬁed that, indeed, Jd
(
𝐡MVDR
)
= . Of course, for Rx = M, the MVDR ﬁlter
simpliﬁes to the identity ﬁlter: 𝐡MVDR = 𝐢i. As a consequence, we can state that the
higher the dimension of the nullspace of 𝚽𝐱, the more the MVDR ﬁlter is eﬃcient in
terms of noise reduction. The best scenario corresponds to Rx = , which is the form
of the MVDR ﬁlter that is well known in the literature. The case Rx > was discovered
only recently [, ].
It can be shown that with the MVDR ﬁlter given in (.), the output SINR is always
greater than or equal to the input SINR: oSINR(𝐡MVDR) ≥iSINR [].
Example ..
Returning to Example .., we now employ the MVDR ﬁlter, 𝐡MVDR,
given in (.). Figure .shows plots of the gain in SINR, (𝐡MVDR
), and the MSE,
J (𝐡MVDR
), as a function of the input SINR for diﬀerent numbers of sensors, M. The
desired signal distortion index, 𝜐(𝐡MVDR
), is zero. The gain in SINR is always positive.
For a given input SINR, as the number of sensors increases, the gain in SINR increases,
while the MSE decreases.
■
6.4.3
Tradeoff
We are now going to derive a ﬁlter that can compromise between interference-
plus-noise reduction and desired signal distortion. For that, we need to minimize
the distortion-based MSE subject to the constraint that the interference-plus-
noise reduction-based MSE is equal to some desired value. Mathematically, this is
equivalent to

An Exhaustive Class of Linear Filters
217
–5
0
5
10
15
1
2
3
4
5
6
7
8
9
–5
0
5
10
15
–30
–25
–20
–15
–10
–5
0
iSINR (dB)
iSINR (dB)
(a)
(b)
J (hMVDR) (dB)
 (hMVDR) (dB)
Figure 6.3 (a) The gain in SINR and (b) the MSE of the MVDR filter as a function of the input SINR for
different numbers of sensors, M: M = 10 (solid line with circles), M = 20 (dashed line with asterisks),
M = 50 (dotted line with squares), and M = 100 (dash-dot line with triangles).
min
𝐡Jd (𝐡)
subject to Jn (𝐡) + Ji (𝐡) = ℵ
(
𝜙v+ 𝜙v
)
,
(.)
where < ℵ< to ensure that we have some noise reduction. If we use a Lagrange
multiplier, 𝜇, to adjoin the constraint to the cost function, (.) can be rewritten as
𝐡T,𝜇= arg min
𝐡(𝐡, 𝜇),
(.)
with
(𝐡, 𝜇) = Jd (𝐡) + 𝜇[Jn (𝐡) + Ji (𝐡) −ℵ(𝜙v+ 𝜙v
)]
(.)
and 𝜇> . From (.), we easily derive the tradeoﬀﬁlter:
𝐡T,𝜇=
(
𝚽𝐱+ 𝜇𝚽in
)−𝚽𝐱𝐢i
(.)
=
[
𝚽𝐲+ (𝜇−)𝚽in
]−(
𝚽𝐲−𝚽in
)
𝐢i,
where the Lagrange multiplier, 𝜇, satisﬁes Jn
(
𝐡T,𝜇
)
+ Ji
(
𝐡T,𝜇
)
= ℵ
(
𝜙v+ 𝜙v
)
.
In practice it is not easy to determine the optimal 𝜇. Therefore, when this parameter
is chosen in a heuristic way, we can see that for
●𝜇= , 𝐡T,= 𝐡W, which is the Wiener ﬁlter
●𝜇= [if rank (𝚽𝐱
) = M], 𝐡T,= 𝐢i, which is the identity ﬁlter
●𝜇> results in a ﬁlter with low residual interference-plus-noise at the expense of
high desired signal distortion
●𝜇< results in a ﬁlter with low desired signal distortion and small amount of
interference-plus-noise reduction.
It can be shown that with the tradeoﬀﬁlter given in (.), the output SINR is always
greater than or equal to the input SINR: oSINR(𝐡T,𝜇) ≥iSINR, ∀𝜇≥[].
www.ebook3000.com

218
Fundamentals of Signal Enhancement and Array Signal Processing
With the eigenvalue decomposition of 𝚽𝐱and the Woodbury identity, we can express
the tradeoﬀﬁlter as
𝐡T,𝜇= 𝚽−
in 𝐐′
𝐱
(𝜇𝚲′−
𝐱
+ 𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝐢i.
(.)
This ﬁlter is strictly equivalent to the tradeoﬀﬁlter given in (.), except for 𝜇= ;
indeed, the one in (.) is not deﬁned while the one in (.) leads to the MVDR ﬁlter.
Example ..
Returning to Example .., we now employ the tradeoﬀﬁlter, 𝐡T,𝜇,
given in (.). Figures .and .show plots of the gain in SINR, (𝐡T,𝜇
), the MSE,
J (𝐡T,𝜇
), and the desired signal distortion index, 𝜐(𝐡T,𝜇
), as a function of the input SINR
for diﬀerent numbers of sensors, M, for 𝜇= .and 𝜇= , respectively. The gain in
SINR is always positive. For a given input SINR, as the number of sensors increases,
the gain in SINR increases, while the MSE and the desired signal distortion index
decrease.
■
–5
0
5
10
15
1
2
3
4
5
6
7
8
9
–5
0
5
10
15
–30
–25
–20
–15
–10
–5
–5
0
5
10
15
–60
–50
–40
–30
–20
–10
0
(a)
(b)
(c)
iSINR (dB)
iSINR (dB)
iSINR (dB)
 (hT,μ) (dB)
 J (hT,μ) (dB)
 (hT,μ) (dB)
Figure 6.4 (a) The gain in SINR, (b) the MSE, and (c) the desired signal distortion index of the tradeoff
filter as a function of the input SINR for different numbers of sensors, M, and 𝜇= 0.5: M = 10 (solid line
with circles), M = 20 (dashed line with asterisks), M = 50 (dotted line with squares), and M = 100
(dash-dot line with triangles).

An Exhaustive Class of Linear Filters
219
–5
0
5
10
15
1
2
3
4
5
6
7
8
9
–5
0
5
10
15
–30
–25
–20
–15
–10
–5
–5
0
5
10
15
–35
–30
–25
–20
–15
–10
–5
0
iSINR (dB)
iSINR (dB)
iSINR (dB)
(a)
(b)
(c)
 (hT,μ) (dB)
 J (hT,μ) (dB)
 (hT,μ) (dB)
Figure 6.5 (a) The gain in SINR, (b) the MSE, and (c) the desired signal distortion index of the tradeoff
filter as a function of the input SINR for different numbers of sensors, M, and 𝜇= 5: M = 10 (solid line
with circles), M = 20 (dashed line with asterisks), M = 50 (dotted line with squares), and M = 100
(dash-dot line with triangles).
6.4.4
LCMV
In this approach, we would like to ﬁnd a ﬁlter that completely cancels one interference,
let’s say 𝐯, without any distortion to the desired signal, and attenuates as much as
possible the rest of the interference-plus-noise signal.
Let
𝐐𝐯=
[
𝐐′
𝐯
𝐐′′
𝐯
]
,
(.)
where the M × Rvmatrix 𝐐′
𝐯contains the eigenvectors corresponding to the nonzero
eigenvalues of 𝚽𝐯and the M × (M −Rv) matrix 𝐐′′
𝐯contains the eigenvectors
corresponding to the null eigenvalues of 𝚽𝐯. We can write the interference 𝐯as
𝐯= 𝐐𝐯𝐐H
𝐯𝐯
(.)
= 𝐐′
𝐯𝐐′H
𝐯𝐯.
www.ebook3000.com

220
Fundamentals of Signal Enhancement and Array Signal Processing
We deduce that the constraint to cancel this interference is
𝐡H𝐐′
𝐯= 𝟎T,
(.)
where 𝟎is the zero vector of length Rv. Combining this constraint with the distortion-
less one, we get
𝐡H𝐂𝐱𝐯= [ 𝐢T
i 𝐐′
𝐱
𝟎T ]
(.)
= 𝐢H
c ,
where
𝐂𝐱𝐯=
[
𝐐′
𝐱
𝐐′
𝐯
]
(.)
is the constraint matrix of size M × (Rx + Rv) and 𝐢c is a vector of length Rx + Rv. Now,
the criterion to optimize is
min
𝐡
[
Jn (𝐡) + Ji (𝐡)
]
subject to 𝐡H𝐂𝐱𝐯= 𝐢H
c ,
(.)
which leads to the celebrated LCMV ﬁlter:
𝐡LCMV = 𝚽−
in 𝐂𝐱𝐯
(
𝐂H
𝐱𝐯𝚽−
in 𝐂𝐱𝐯
)−
𝐢c.
(.)
It is clear from (.) that for this ﬁlter to exist, we must have M ≥Rx + Rv. An
equivalent way to express (.) is
𝐡LCMV = 𝚽−
𝐲𝐂𝐱𝐯
(
𝐂H
𝐱𝐯𝚽−
𝐲𝐂𝐱𝐯
)−
𝐢c.
(.)
While, with this ﬁlter, we can completely cancel the interference 𝐯, there is no guarantee
that the rest of the interference-plus-noise can be attenuated; in fact, it can even be
ampliﬁed. This depends on how M is larger than Rx +Rv. As the diﬀerence of these two
integers increases, so is the attenuation of the rest of the interference-plus-noise signal.
Example ..
Returning to Example .., we now assume two uncorrelated com-
plex harmonic random processes as interferences, 𝐯and 𝐯, impinging on the ULA
from the directions 𝜃v= ◦and 𝜃v= ◦, respectively. We employ the LCMV ﬁlter,
𝐡LCMV, given in (.). Figure .shows plots of the gain in SINR, (𝐡LCMV
), the
MSE, J
(
𝐡LCMV
)
, and the desired signal distortion index, 𝜐
(
𝐡LCMV
)
, as a function of
the input SINR for diﬀerent numbers of sensors, M. The desired signal distortion index,
𝜐(𝐡LCMV
), is zero. The gain in SINR is always positive. For a given input SINR, as the
number of sensors increases, the gain in SINR increases, while the MSE decreases.
■
The generalization of this approach to the cancellation of more than one interference
is straightforward. Let’s say that we want to cancel the two interferences 𝐯and 𝐯.
First, we take the correlation matrix of the signal 𝐯+ 𝐯. We perform the eigenvalue

An Exhaustive Class of Linear Filters
221
–5
0
5
10
15
20
22
24
26
28
30
32
34
–5
0
5
10
15
–55
–40
–45
–50
–35
–30
–25
–20
(a)
(b)
iSINR (dB)
iSINR (dB)
 (hLCMV) (dB)
 J (hLCMV) (dB)
Figure 6.6 (a) The gain in SINR, (b) the MSE, and (c) the desired signal distortion index of the LCMV
filter as a function of the input SINR for different numbers of sensors, M: M = 10 (solid line with circles),
M = 20 (dashed line with asterisks), M = 50 (dotted line with squares), and M = 100 (dash-dot line
with triangles).
decomposition of this matrix as we did for 𝚽𝐯. Then, the derivation of the correspond-
ing LCMV ﬁlter is as described above. The only thing that changes is the condition of
the ﬁlter existing, which is now M ≥Rx + Rv+ Rv.
Another interesting way to derive the LCMV ﬁlter is the following. Let us consider
the ﬁlters that have the form:
𝐡= 𝐐′′
𝐯𝐚,
(.)
where 𝐚≠𝟎is a shorter ﬁlter of length M −Rv. It is easy to observe that
𝐡H𝐯= 𝐚H𝐐′′H
𝐯𝐯= 𝟎,
(.)
since 𝐐′′H
𝐯𝐐′
𝐯
=
𝟎. By its nature, the ﬁlter 𝐡in (.) cancels the interference.
Substituting (.) into Jn (𝐡) + Ji (𝐡), we obtain
Jn (𝐡) + Ji (𝐡) = 𝜙v𝐚H𝐚+ 𝐚H𝐐′′H
𝐯𝚽𝐯𝐐′′
𝐯𝐚
(.)
= 𝐚H𝚽′
in𝐚
= Jn (𝐚) + Ji (𝐚) ,
where
𝚽′
in = 𝜙v𝐈M−Rv+ 𝐐′′H
𝐯𝚽𝐯𝐐′′
𝐯,
(.)
with 𝐈M−Rvbeing the (M −Rv) × (M −Rv) identity matrix. Then, from the criterion:
min
𝐚
[
Jn (𝐚) + Ji (𝐚)
]
subject to 𝐚H𝐐′′H
𝐯𝐐′
𝐱= 𝐢T
i 𝐐′
𝐱,
(.)
www.ebook3000.com

222
Fundamentals of Signal Enhancement and Array Signal Processing
we ﬁnd that
𝐚LCMV = 𝚽′−
in 𝐐′′H
𝐯𝐐′
𝐱
(
𝐐′H
𝐱𝐐′′
𝐯𝚽′−
in 𝐐′′H
𝐯𝐐′
𝐱
)−
𝐐′H
𝐱𝐢i.
(.)
As a result, another formulation of the LCMV ﬁlter is
𝐡LCMV = 𝐐′′
𝐯𝚽′−
in 𝐐′′H
𝐯𝐐′
𝐱
(
𝐐′H
𝐱𝐐′′
𝐯𝚽′−
in 𝐐′′H
𝐯𝐐′
𝐱
)−
𝐐′H
𝐱𝐢i.
(.)
6.4.5
Maximum SINR
The maximum SINR ﬁlter is obtained by maximizing the output SINR as given in (.),
from which we recognize the generalized Rayleigh quotient []. Since 𝚽in is full rank,
it is well known that this quotient is maximized with the eigenvector corresponding to
the maximum eigenvalue of 𝚽−
in 𝚽𝐱. Let us denote by 𝜆the maximum eigenvalue of
this matrix and by 𝐭the corresponding eigenvector. Therefore, we have
𝐡mSINR = 𝜍𝐭,
(.)
where 𝜍≠is an arbitrary complex number. We deduce that
oSINR
(
𝐡mSINR
)
= 𝜆.
(.)
Clearly, we always have
oSINR
(
𝐡mSINR
)
≥iSINR
(.)
and
oSINR
(
𝐡mSINR
)
≥oSINR (𝐡) , ∀𝐡.
(.)
Now we need to determine 𝜍. One possible way to ﬁnd this parameter is by minimizing
distortion. Substituting (.) into Jd (𝐡), we get
Jd
(𝐡mSINR
) = 𝜙x+ 𝜆|𝜍|−𝜍∗𝐭H
𝚽𝐱𝐢i −𝜍𝐢T
i 𝚽𝐱𝐭.
(.)
The minimization of the previous expression with respect to 𝜍∗gives
𝜍=
𝐭H
𝚽𝐱𝐢i
𝜆
.
(.)
We deduce that the maximum SINR ﬁlter with minimum distortion is
𝐡mSINR =
𝐭𝐭H
𝚽𝐱𝐢i
𝜆
(.)
= 𝐭𝐭H
𝚽in𝐢i.

An Exhaustive Class of Linear Filters
223
–5
0
5
10
15
1
2
3
4
5
6
7
9
8
–5
0
5
10
15
–30
–15
–20
–25
–10
0
–5
(a)
(b)
iSINR (dB)
iSINR (dB)
 (hmSINR) (dB)
 J (hmSINR) (dB)
Figure 6.7 (a) The gain in SINR and (b) the MSE of the maximum SINR filter as a function of the input
SINR for different numbers of sensors, M: M = 10 (solid line with circles), M = 20 (dashed line with
asterisks), M = 50 (dotted line with squares), and M = 100 (dash-dot line with triangles).
Example ..
Returning to Example .., we now employ the maximum SINR ﬁlter,
𝐡mSINR, given in (.). Figure .shows plots of the gain in SINR, (𝐡mSINR
), and
the MSE, J (𝐡mSINR
), as a function of the input SINR for diﬀerent numbers of sensors,
M. The desired signal distortion index, 𝜐(𝐡mSINR
), is zero. The gain in SINR is always
positive. For a given input SINR, as the number of sensors increases, the gain in SINR
increases, while the MSE decreases.
■
6.4.6
Maximum SIR
In the denominator of the output SIR appears the matrix 𝚽𝐯, which can be either
full rank or rank deﬁcient. In the ﬁrst case, it is easy to derive the maximum SIR
ﬁlter, which is the eigenvector corresponding to the maximum eigenvalue of 𝚽−
𝐯𝚽𝐱.
Fundamentally, this scenario is equivalent to what was done in the previous subsection
for the maximization of the SINR. Therefore, we are only interested in the second case,
where we assume that rank (𝚽𝐯
) = Rv < M.
Let
𝐐𝐯= [ 𝐐′
𝐯
𝐐′′
𝐯
] ,
(.)
where the M × Rv matrix 𝐐′
𝐯contains the eigenvectors corresponding to the nonzero
eigenvalues of 𝚽𝐯and the M × (M −Rv) matrix 𝐐′′
𝐯contains the eigenvectors corre-
sponding to the null eigenvalues of 𝚽𝐯. We are interested in the linear ﬁlters of the form:
𝐡= 𝐐′′
𝐯𝐚,
(.)
where 𝐚is a vector of length M −Rv. Since 𝚽𝐯𝐐′′
𝐯= 𝟎and assuming that 𝚽𝐱𝐐′′
𝐯≠𝟎,
which is reasonable since 𝚽𝐱and 𝚽𝐯cannot be diagonalized by the same orthogonal
matrix unless at least one of the two signals xand v is white, we have
oSIR (𝐡) = oSIR
(
𝐐′′
𝐯𝐚
)
= ∞.
(.)
www.ebook3000.com

224
Fundamentals of Signal Enhancement and Array Signal Processing
As a consequence, the estimate of xis
̂x= 𝐡H𝐲
(.)
= 𝐚H𝐐′′H
𝐯𝐱+ 𝐚H𝐐′′H
𝐯𝐯+ 𝐚H𝐐′′H
𝐯𝐯
= 𝐚H𝐐′′H
𝐯𝐱+ 𝐚H𝐐′′H
𝐯𝐯.
We observe from the previous expression that this approach completely cancels the
interference. Now, we need to ﬁnd 𝐚. The best way to ﬁnd this vector is by minimizing
the MSE criterion. Substituting (.) into (.), we get
J (𝐚) = 𝜙x+ 𝐚H𝐐′′H
𝐯𝚽𝐲𝐐′′
𝐯𝐚−𝐚H𝐐′′H
𝐯𝚽𝐱𝐢i −𝐢T
i 𝚽𝐱𝐐′′
𝐯𝐚.
(.)
The minimization of the previous expression leads to
𝐚mSIR = (𝐐′′H
𝐯𝚽𝐲𝐐′′
𝐯
)−𝐐′′H
𝐯𝚽𝐱𝐢i.
(.)
As a result, the maximum SIR ﬁlter with minimum MSE is
𝐡mSIR = 𝐐′′
𝐯
(𝐐′′H
𝐯𝚽𝐲𝐐′′
𝐯
)−𝐐′′H
𝐯𝚽𝐱𝐢i.
(.)
Example ..
Returning to Example .., we now employ the maximum SIR ﬁlter,
𝐡mSIR, given in (.). Figure .shows plots of the gain in SINR, (𝐡mSIR
), the MSE,
J
(
𝐡mSIR
)
, and the desired signal distortion index, 𝜐
(
𝐡mSIR
)
, as a function of the input
SINR for diﬀerent numbers of sensors, M. The gain in SINR is always positive. For a
given input SINR, as the number of sensors increases, the gain in SINR increases, while
the MSE and the desired signal distortion index decrease.
■
All the optimal ﬁlters derived in this section are summarized in Table ..
6.5
Filling the Gap Between the Maximum SINR and Wiener Filters
In this section, we revisit the maximum SINR and Wiener ﬁlters. We show how they are
related, and from this we derive a new class of ﬁlters.
The fact that the correlation matrix of the observation signal vector is the sum of the
correlation matrices of the desired and interference-plus-noise signal vectors will make
the analysis of potential ﬁlters easy if we jointly diagonalize these two matrices. Since 𝚽in
is full rank, the two Hermitian matrices 𝚽𝐱and 𝚽in can indeed be jointly diagonalized,
as follows []:
𝐓H𝚽𝐱𝐓= 𝚲,
(.)
𝐓H𝚽in𝐓= 𝐈M,
(.)
where 𝐓is a full-rank square matrix (of size M × M) and 𝚲is a diagonal matrix whose
main elements are real and nonnegative. Furthermore, 𝚲and 𝐓are the eigenvalue and
eigenvector matrices, respectively, of 𝚽−
in 𝚽𝐱:
𝚽−
in 𝚽𝐱𝐓= 𝐓𝚲.
(.)

An Exhaustive Class of Linear Filters
225
–5
0
5
10
15
20
22
24
26
28
30
32
34
–5
0
5
10
15
–55
–40
–45
–50
–35
–30
–25
–20
–5
0
5
10
15
–100
–90
–80
–70
–60
–50
–40
–30
(a)
(b)
(c)
iSINR (dB)
iSINR (dB)
iSINR (dB)
 (hmSIR) (dB)
 J (hmSIR) (dB)
 (hmSIR) (dB)
Figure 6.8 (a) The gain in SINR, (b) the MSE, and (c) the desired signal distortion index of the
maximum SIR filter as a function of the input SINR for different numbers of sensors, M: M = 10 (solid
line with circles), M = 20 (dashed line with asterisks), M = 50 (dotted line with squares), and M = 100
(dash-dot line with triangles).
Table 6.1 Optimal linear filters for signal enhancement.
Filter
Wiener
𝐡W = 𝚽−
in 𝐐′
𝐱
(𝚲′−
𝐱
+ 𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝐢i
MVDR
𝐡MVDR = 𝚽−
in 𝐐′
𝐱
(𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝐢i
Tradeoﬀ
𝐡T,𝜇= 𝚽−
in 𝐐′
𝐱
(𝜇𝚲′−
𝐱
+ 𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝐢i
LCMV
𝐡LCMV = 𝐐′′
𝐯𝚽′−
in 𝐐′′H
𝐯𝐐′
𝐱×
(
𝐐′H
𝐱𝐐′′
𝐯𝚽′−
in 𝐐′′H
𝐯𝐐′
𝐱
)−
𝐐′H
𝐱𝐢i
Maximum SINR
𝐡mSINR = 𝐭𝐭H
𝚽in𝐢i
Maximum SIR
𝐡mSIR = 𝐐′′
𝐯
(𝐐′′H
𝐯𝚽𝐲𝐐′′
𝐯
)−𝐐′′H
𝐯𝚽𝐱𝐢i
Since the rank of the matrix 𝚽𝐱is equal to Rx, the eigenvalues of 𝚽−
in 𝚽𝐱can be ordered
as 𝜆≥𝜆≥⋯≥𝜆Rx
> 𝜆Rx+= ⋯= 𝜆M = . In other words, the last
M −Rx eigenvalues of the matrix product 𝚽−
in 𝚽𝐱are exactly zero, while its ﬁrst Rx
www.ebook3000.com

226
Fundamentals of Signal Enhancement and Array Signal Processing
eigenvalues are positive, with 𝜆being the maximum eigenvalue. We also denote by
𝐭, 𝐭, … , 𝐭Rx, 𝐭Rx+, … , 𝐭M, the corresponding eigenvectors. A consequence of this joint
diagonalization is that the noisy signal correlation matrix can also be diagonalized as
𝐓H𝚽𝐲𝐓= 𝚲+ 𝐈M.
(.)
It is always possible to write the ﬁlter 𝐡in a basis formed from the vectors 𝐭m, m =
, , … , M:
𝐡= 𝐓𝐚,
(.)
where the components of
𝐚= [ a
a
⋯
aM
]T
(.)
are the coordinates of 𝐡in the new basis. Now, instead of estimating the coeﬃcients
of 𝐡as in conventional approaches, we can estimate, equivalently, the coordinates
am, m = , , … , M. When 𝐚is estimated, it is then straightforward to determine 𝐡from
(.). From here onwards, we will refer to 𝐡and 𝐚as the direct and transformed ﬁlters,
respectively. Both ﬁlters may be used interchangeably. Consequently, we can express
(.) as
z = 𝐚H𝐓H𝐲.
(.)
We deduce that the variance of z is
𝜙z = 𝐚H𝚲𝐚+ 𝐚H𝐚.
(.)
The output SINR can then be expressed as
oSINR (𝐚) = 𝐚H𝚲𝐚
𝐚H𝐚
(.)
=
∑Rx
i=||ai||
𝜆i
∑M
m=||am||

and, clearly,
oSINR (𝐚) ≤𝜆, ∀𝐚.
(.)
We deﬁne the transformed identity ﬁlter as
𝐢𝐓= 𝐓−𝐢i.
(.)
The particular ﬁlter 𝐢𝐓does not aﬀect the observations since z = 𝐢H
𝐓𝐓H𝐲= yand
oSINR (𝐢𝐓
) = iSINR. As a result, we have
iSINR ≤𝜆.
(.)

An Exhaustive Class of Linear Filters
227
In the same way, we can express the MSE criterion as
J (𝐚) = E
(
||z −x||
)
(.)
= 𝜙x−𝐚H𝐓H𝚽𝐱𝐢i −𝐢T
i 𝚽𝐱𝐓𝐚+ 𝐚H (𝚲+ 𝐈M
) 𝐚
= 𝜙x−𝐚H𝚲𝐢𝐓−𝐢H
𝐓𝚲𝐚+ 𝐚H (
𝚲+ 𝐈M
)
𝐚
= (𝐚−𝐢𝐓
)H 𝚲(𝐚−𝐢𝐓
) + 𝐚H𝐚.
With the transformed identity ﬁlter, we have J
(
𝐢𝐓
)
= 𝐢H
𝐓𝐢𝐓.
We observe that the output SINR and MSE criteria are very diﬀerent. A ﬁlter that
gives a large output SINR does not necessarily imply a small MSE and a ﬁlter that leads
to a small MSE does not mean that the output SINR is large (or strictly larger than the
input SNR) []. Key questions that one may ask are:
●How are these two ﬁlters related?
●How to capture the best from the two criteria?
From (.), it is easy to see that the maximum SINR ﬁlter is
𝐚mSINR,2 = a𝐢i,
(.)
where a≠is an arbitrary complex number. Obviously, we have
oSINR (𝐚mSINR,2
) = 𝜆≥iSINR
(.)
and
oSINR (𝐚) ≤oSINR (𝐚mSINR,2
) , ∀𝐚.
(.)
We need to determine a. One reasonable way to ﬁnd this parameter is from an
MSE perspective. Indeed, substituting 𝐚mSINR,2 into the MSE criterion of (.) and
minimizing J
(
𝐚mSINR,2
)
with respect to a, we easily get
a=
𝜆
+ 𝜆
𝐢T
i 𝐢𝐓
(.)
=
𝜆
+ 𝜆
𝐢T
i 𝐓−𝐢i
=
𝜆
+ 𝜆
𝐭H
𝚽in𝐢i.
As a result, the transformed and direct maximum SINR ﬁlters are, respectively,
𝐚mSINR,2 =
𝜆
+ 𝜆
𝐢i𝐢T
i 𝐓−𝐢i
(.)
www.ebook3000.com

228
Fundamentals of Signal Enhancement and Array Signal Processing
and
𝐡mSINR,2 =
𝜆
+ 𝜆
𝐭𝐭H
𝚽in𝐢i.
(.)
This ﬁlter is, obviously, very close to 𝐡mSINR; the two ﬁlters are equivalent up to a scaling
factor. We then deduce that
J (𝐚mSINR,2
) = 𝐢H
𝐓𝚲𝐢𝐓−
𝜆

+ 𝜆
|||𝐢H
𝐓𝐢i|||

(.)
=
𝜆
+ 𝜆
|||𝐢H
𝐓𝐢i|||

+
Rx
∑
i=
𝜆i |||𝐢H
𝐓𝐢i|||

,
where 𝐢i is the ith column of 𝐈M. It is not guaranteed that J (𝐚mSINR,2
) ≤J (𝐢𝐓
).
Example ..
Returning to Example .., we now assume that the desired signal
impinges on the ULA from the direction 𝜃x = ◦and that the desired signal received
at the ﬁrst sensor is the sum of four complex harmonic random processes:
x(t) = A

∑
k=
exp (𝚥𝜋fkt + 𝚥𝜑k
),
with ﬁxed amplitude A and frequencies {fk = .k}, and IID random phases {𝜑k
},
uniformly distributed on the interval from to 𝜋.
The desired signal correlation matrix is
𝚽𝐱= A

∑
k=
𝐝k𝐝H
k
where
𝐝k = [

e−𝚥𝜋fk𝜏x,
e−𝚥𝜋fk𝜏x,
⋯
e−𝚥𝜋fk𝜏x,M ]T .
The rank of 𝚽𝐱is Rx = . The input SINR is
iSINR = log
A
𝜙v+ 
(dB).
The maximum SINR ﬁlter, 𝐡mSINR,2, is obtained from (.).
Figure .shows plots of the gain in SINR, (𝐡mSINR,2
), the MSE, J (𝐡mSINR,2
), and the
desired signal distortion index, 𝜐
(
𝐡mSINR,2
)
, as a function of the input SINR for diﬀerent
numbers of sensors, M. The gain in SINR is always positive. For a given input SINR,
as the number of sensors increases, the gain in SINR increases. However, the three
criteria – gain in SINR, MSE, and desired signal distortion index – are very diﬀerent. A
ﬁlter that gives a large gain in SINR does not necessarily imply a small MSE or a small

An Exhaustive Class of Linear Filters
229
–5
0
5
10
15
10
12
14
16
18
20
–5
0
5
10
15
–2
–1.5
–1
–0.5
–5
0
5
10
15
–2
–1.8
–1.6
–1.4
–1.2
–1
–0.8
–0.6
(a)
(b)
(c)
iSINR (dB)
iSINR (dB)
iSINR (dB)
 (hmSINR,2) (dB)
 J (hmSINR,2) (dB)
 (hmSINR,2) (dB)
Figure 6.9 (a) The gain in SINR, (b) the MSE, and (c) the desired signal distortion index of the
maximum SINR filter as a function of the input SINR for different numbers of sensors, M: M = 10 (solid
line with circles), M = 20 (dashed line with asterisks), M = 50 (dotted line with squares), and M = 100
(dash-dot line with triangles).
desired signal distortion index, and a ﬁlter that leads to a small MSE or a small desired
signal distortion index does not mean that the gain in SINR is large.
■
The classical Wiener ﬁlter is derived by minimizing J (𝐚) with respect to 𝐚. We obtain
𝐚W = (𝚲+ 𝐈M
)−𝚲𝐢𝐓
(.)
=
Rx
∑
i=
𝜆i
+ 𝜆i
𝐢i𝐢T
i 𝐓−𝐢i.
Therefore, another way to write the Wiener ﬁlter is
𝐡W =
Rx
∑
i=
𝜆i
+ 𝜆i
𝐭i𝐭H
i 𝚽in𝐢i.
(.)
It is of great interest to compare (.) to (.). For Rx = , we see that 𝐡mSINR,2 = 𝐡W,
as we should expect. In the general case of Rx ≥, we can see clearly that the two
www.ebook3000.com

230
Fundamentals of Signal Enhancement and Array Signal Processing
ﬁlters are still closely connected. While the maximum SINR ﬁlter only takes into account
the direction in which the energy of the desired signal is maximal, the Wiener ﬁlter
takes into account the whole space in which the desired signal is present. This is the
reason why the two ﬁlters work so diﬀerently in practice, even if they look similar. This
result, although obvious, was never really shown in a such explicit way in the literature.
Substituting (.) into J (𝐚), we ﬁnd the MMSE:
J (𝐚W
) = 𝐢H
𝐓𝚲𝐢𝐓−
Rx
∑
i=
𝜆
i
+ 𝜆i
|||𝐢H
𝐓𝐢i|||

(.)
=
Rx
∑
i=
𝜆i
+ 𝜆i
|||𝐢H
𝐓𝐢i|||

and J
(
𝐚W
)
≤J
(
𝐢𝐓
)
. Obviously, we always have
J (𝐚W
) ≤J (𝐚) , ∀𝐚.
(.)
From this treatment, we can conclude that while the maximum SINR ﬁlter maximizes
the output SINR, it may not improve its MSE compared to the variance of the noise.
On the other hand, the Wiener ﬁlter can improve the output SINR while giving the
minimum MSE.
Example ..
Returning to Example .., we now employ the Wiener ﬁlter, 𝐡W,
given in (.). Figure .shows plots of the gain in SINR, (𝐡W
), the MSE, J (𝐡W
),
and the desired signal distortion index, 𝜐
(
𝐡W
)
, as a function of the input SINR for
diﬀerent numbers of sensors, M. The gain in SINR is always positive. For a given input
SINR, as the number of sensors increases, the gain in SINR increases, while the MSE
and the desired signal distortion index decrease.
■
Now, we derive a class of ﬁlters that naturally ﬁlls the gap between the two fundamen-
tal ﬁlters studied above. For that purpose, let us ﬁrst give the following property.
Property ..
Let 𝜆≥𝜆≥⋯≥𝜆M ≥. We have
∑M
i=||ai||
𝜆i
∑M
i=||ai||

≤
∑M−
i=||ai||
𝜆i
∑M−
i=||ai||

≤⋯≤
∑
i=||ai||
𝜆i
∑
i=||ai||

≤𝜆,
(.)
where ai, i = , , … , M are arbitrary complex numbers with at least one of them
diﬀerent from .
Proof. The previous inequalities can be easily shown by induction.
Property ..suggests that we can deﬁne a class of ﬁlters that have the form:
𝐚Q =
Q
∑
q=
𝜆q
+ 𝜆q
𝐢q𝐢T
q 𝐓−𝐢i
(.)

An Exhaustive Class of Linear Filters
231
–5
0
5
10
15
0
2
4
6
10
12
8
14
–5
0
5
10
15
–30
–10
–15
–20
–25
–5
0
–5
0
5
10
15
–60
–50
–40
–30
–20
–10
0
(a)
(b)
(c)
iSINR (dB)
iSINR (dB)
iSINR (dB)
 (hW) (dB)
 J (hW) (dB)
 (hW) (dB)
Figure 6.10 (a) The gain in SINR, (b) the MSE, and (c) the desired signal distortion index of the Wiener
filter as a function of the input SINR for different numbers of sensors, M: M = 10 (solid line with circles),
M = 20 (dashed line with asterisks), M = 50 (dotted line with squares), and M = 100 (dash-dot line
with triangles).
or, equivalently,
𝐡Q =
Q
∑
q=
𝜆q
+ 𝜆q
𝐭q𝐭H
q 𝚽in𝐢i,
(.)
where ≤Q ≤Rx. We see that 𝐡= 𝐡mSINR,2 and 𝐡Rx = 𝐡W.
From Property .., it is immediate obvious that
iSNR ≤oSNR
(
𝐚Rx
)
≤oSNR
(
𝐚Rx−
)
≤⋯≤oSNR
(
𝐚
)
= 𝜆.
(.)
It is straightforward to compute the MSE:
J
(
𝐚Q
)
= 𝐢H
𝐓𝚲𝐢𝐓−
Q
∑
q=
𝜆
q
+ 𝜆q
|||𝐢H
𝐓𝐢q|||

(.)
=
Q
∑
q=
𝜆q
+ 𝜆q
|||𝐢H
𝐓𝐢q|||

+
Rx
∑
i=Q+
𝜆i |||𝐢H
𝐓𝐢i|||

.
www.ebook3000.com

232
Fundamentals of Signal Enhancement and Array Signal Processing
We deduce from (.) that
J
(
𝐚Rx
)
≤J
(
𝐚Rx−
)
≤⋯≤J (𝐚
) .
(.)
We see from (.) and (.) that the class of ﬁlters proposed here can give a
compromise, in a very smooth way, between large values of the output SINR and small
values of the MSE. This compromise depends, of course, on the rank of 𝚽𝐱. For a value
of Rx close to , the number of possibilities is very small but this is ﬁne since, in this case,
the two ﬁlters are very close to each other. For large values of Rx, we have many more
options and this is desirable, since 𝐡mSINR,2 and 𝐡W now behave very diﬀerently.
■
Example ..
Returning to Example .., we now employ the ﬁlter, 𝐡Q, given in
(.). Figure .shows plots of the gain in SINR, 
(
𝐡Q
)
, the MSE, J
(
𝐡Q
)
, and the
desired signal distortion index, 𝜐(𝐡Q
), as a function of the input SINR for M = 
sensors and diﬀerent values of Q. For Q = , 𝐡Q reduces to 𝐡mSINR,2. For Q = Rx = , 𝐡Q
reduces to 𝐡W. Clearly, the gain in SINR is always positive. For a given input SINR, as
–5
0
5
10
15
2
4
6
10
12
8
14
–5
0
5
10
15
–20
–10
–15
–5
0
–5
0
5
10
15
–35
–30
–25
–20
–15
–10
–5
0
(a)
(b)
(c)
iSINR (dB)
iSINR (dB)
iSINR (dB)
 (h   ) (dB)
 (h   ) (dB)
J (h   ) (dB)
Figure 6.11 (a) The gain in SINR, (b) the MSE, and (c) the desired signal distortion index of the filter 𝗵Q
as a function of the input SINR for different values of Q: Q = 1 (solid line with circles), Q = 2 (dashed
line with asterisks), Q = 3 (dotted line with squares), and Q = 4 (dash-dot line with triangles).

An Exhaustive Class of Linear Filters
233
the value of Q decreases, the gain in SINR increases, at the expense of higher MSE and
a higher desired signal distortion index.
■
Following the same steps as above, it is easy to derive another class of linear ﬁlters
that ﬁll the gap between the maximum SINR and MVDR ﬁlters:
𝐡′
Q =
Q
∑
q=
𝐭q𝐭H
q 𝚽in𝐢i,
(.)
where ≤Q ≤Rx. It is obvious that 𝐡′
= 𝐡mSINR and it can be shown that 𝐡′
Rx = 𝐡MVDR.
Problems
6.1 Show that the Wiener ﬁlter can be expressed as
𝐡W =
(
𝐈M −𝚽−
𝐲𝚽in
)
𝐢i.
6.2 Using Woodbury’s identity, show that
𝚽−
𝐲= 𝚽−
in −𝚽−
in 𝐐′
𝐱
(𝚲′−
𝐱
+ 𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝚽−
in .
6.3 Show that the Wiener ﬁlter can be expressed as
𝐡W = 𝚽−
in 𝐐′
𝐱
(
𝚲′−
𝐱
+ 𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝐢i.
6.4 Show that the MVDR ﬁlter is given by
𝐡MVDR = 𝚽−
in 𝐐′
𝐱
(
𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝐢i.
6.5 Show that the MVDR ﬁlter can be expressed as
𝐡MVDR = 𝚽−
𝐲𝐐′
𝐱
(
𝐐′H
𝐱𝚽−
𝐲𝐐′
𝐱
)−
𝐐′H
𝐱𝐢i.
6.6 Show that the tradeoﬀﬁlter is given by
𝐡T,𝜇= (𝚽𝐱+ 𝜇𝚽in
)−𝚽𝐱𝐢i
= [𝚽𝐲+ (𝜇−)𝚽in
]−(𝚽𝐲−𝚽in
) 𝐢i,
where 𝜇is a Lagrange multiplier.
6.7 Show that the tradeoﬀﬁlter can be expressed as
𝐡T,𝜇= 𝚽−
in 𝐐′
𝐱
(𝜇𝚲′−
𝐱
+ 𝐐′H
𝐱𝚽−
in 𝐐′
𝐱
)−𝐐′H
𝐱𝐢i.
www.ebook3000.com

234
Fundamentals of Signal Enhancement and Array Signal Processing
6.8 Show that the LCMV ﬁlter is given by
𝐡LCMV = 𝚽−
in 𝐂𝐱𝐯
(
𝐂H
𝐱𝐯𝚽−
in 𝐂𝐱𝐯
)−
𝐢c.
6.9 Show that the LCMV ﬁlter can be expressed as
𝐡LCMV = 𝚽−
𝐲𝐂𝐱𝐯
(
𝐂H
𝐱𝐯𝚽−
𝐲𝐂𝐱𝐯
)−
𝐢c.
6.10 Show that the LCMV ﬁlter can be expressed as
𝐡LCMV = 𝐐′′
𝐯𝚽′−
in 𝐐′′H
𝐯𝐐′
𝐱
(
𝐐′H
𝐱𝐐′′
𝐯𝚽′−
in 𝐐′′H
𝐯𝐐′
𝐱
)−
𝐐′H
𝐱𝐢i.
6.11 Show that the maximum SINR ﬁlter with minimum distortion is given by
𝐡mSINR =
𝐭𝐭H
𝚽𝐱𝐢i
𝜆
= 𝐭𝐭H
𝚽in𝐢i.
6.12 Show that the maximum SIR ﬁlter with minimum MSE is given by
𝐡mSIR = 𝐐′′
𝐯
(𝐐′′H
𝐯𝚽𝐲𝐐′′
𝐯
)−𝐐′′H
𝐯𝚽𝐱𝐢i.
6.13 Show that the output SINR can be expressed as
oSINR (𝐚) = 𝐚H𝚲𝐚
𝐚H𝐚
=
∑Rx
i=||ai||
𝜆i
∑M
m=||am||
.
6.14 Show that the transformed identity ﬁlter, 𝐢𝐓, does not aﬀect the observations:
z = 𝐢H
𝐓𝐓H𝐲= yand oSINR (𝐢𝐓
) = iSINR.
6.15 Show that the MSE can be expressed as
J (𝐚) = 𝜙x−𝐚H𝚲𝐢𝐓−𝐢H
𝐓𝚲𝐚+ 𝐚H (
𝚲+ 𝐈M
)
𝐚.
6.16 Show that the MSE can be expressed as
J (𝐚) = (𝐚−𝐢𝐓
)H 𝚲(𝐚−𝐢𝐓
) + 𝐚H𝐚.
6.17 Show that the maximum SINR ﬁlter with minimum MSE is given by
𝐡mSINR,2 =
𝜆
+ 𝜆
𝐭𝐭H
𝚽in𝐢i.

An Exhaustive Class of Linear Filters
235
6.18 Show that with the maximum SINR ﬁlter, 𝐡mSINR,2, the minimum MSE is given by
J (𝐡mSINR,2
) =
𝜆
+ 𝜆
|||𝐢H
𝐓𝐢i|||

+
Rx
∑
i=
𝜆i |||𝐢H
𝐓𝐢i|||

.
6.19 Show that the Wiener ﬁlter can be expressed as
𝐡W =
Rx
∑
i=
𝜆i
+ 𝜆i
𝐭i𝐭H
i 𝚽in𝐢i.
6.20 Show that with the Wiener ﬁlter 𝐡W, the MMSE is given by
J (𝐡W
) = 𝐢H
𝐓𝚲𝐢𝐓−
Rx
∑
i=
𝜆
i
+ 𝜆i
|||𝐢H
𝐓𝐢i|||

=
Rx
∑
i=
𝜆i
+ 𝜆i
|||𝐢H
𝐓𝐢i|||

.
6.21 Let 𝜆≥𝜆≥⋯≥𝜆M ≥and let am, m = , , … , M denote arbitrary complex
numbers with at least one of them diﬀerent from . Prove that
∑M
i=||ai||
𝜆i
∑M
i=||ai||

≤
∑M−
i=||ai||
𝜆i
∑M−
i=||ai||

≤⋯≤
∑
i=||ai||
𝜆i
∑
i=||ai||

≤𝜆.
6.22 Show that the class of ﬁlters 𝐚Q makes a compromise between large values of the
output SINR and small values of the MSE; that is,
a) iSNR ≤oSNR
(
𝐚Rx
)
≤oSNR
(
𝐚Rx−
)
≤⋯≤oSNR (𝐚
) = 𝜆,
b) J
(
𝐚Rx
)
≤J
(
𝐚Rx−
)
≤⋯≤J (𝐚
) .
6.23 Show that the class of linear ﬁlters 𝐡′
Q satisﬁes 𝐡′
= 𝐡mSINR and 𝐡′
Rx = 𝐡MVDR.
References
1 J. Benesty, J. Chen, Y. Huang, and I. Cohen, Noise Reduction in Speech Processing.
Berlin, Germany: Springer-Verlag, .
2 J. Benesty and J. Chen, Optimal Time-domain Noise Reduction Filters – A Theoretical
Study. Springer Briefs in Electrical and Computer Engineering, .
3 P. Stoica and R. L. Moses, Introduction to Spectral Analysis. Englewood Cliﬀs, NJ:
Prentice-Hall, .
4 B. D. Van Veen and K. M. Buckley, “Beamforming: A versatile approach to spatial
ﬁltering,” IEEE Acoust., Speech, Signal Process. Mag., vol. , pp. –, Apr. .
5 S. Shahbazpanahi, A. B. Gershman, Z.-Q. Luo, and K. M. Wong, “Robust adaptive
beamforming for general-rank signal models,” IEEE Trans. Signal Process., vol. ,
pp. –, Sep. .
www.ebook3000.com

236
Fundamentals of Signal Enhancement and Array Signal Processing
6 G. H. Golub and C. F. Van Loan, Matrix Computations, rd edn. Baltimore, MD: The
Johns Hopkins University Press, .
7 S. Haykin, Adaptive Filter Theory, th edn. Upper Saddle River, NJ: Prentice-Hall, .
8 J. Chen, J. Benesty, Y. Huang, and S. Doclo, “New insights into the noise reduction
Wiener ﬁlter,” IEEE Trans. Audio, Speech, Language Process., vol. , pp. –,
Jul. .
9 J. R. Jensen, J. Benesty, M. G. Christensen, and J. Chen, “A class of optimal rectangular
ﬁltering matrices for single-channel signal enhancement in the time domain,” IEEE
Trans. Audio, Speech, Language Process., vol. , pp. –, Dec. .
10 J. Benesty, J. R. Jensen, M. G. Christensen, and J. Chen, Speech Enhancement – A Signal
Subspace Perspective. Oxford, England: Academic Press, .
11 S. M. Nørholm, J. Benesty, J. R. Jensen, and M. G. Christensen, “Single-channel noise
reduction using uniﬁed joint diagonalization and optimal ﬁltering,” EURASIP J.
Advances Signal Process., vol. , pp. –.
12 J. N. Franklin, Matrix Theory. Englewood Cliﬀs, NJ: Prentice-Hall, .
13 Y. Rong, Y. C. Eldar, and A. B. Gershman, “Performance tradeoﬀs among adaptive
beamforming criteria,” IEEE J. Selected Topics Signal Process., vol. , pp. –,
Dec. .

237
Part II
Array Signal Processing
www.ebook3000.com

239
7
Fixed Beamforming
A ﬁxed beamformer is a spatial ﬁlter that has the ability to form a main beam in the
direction of the desired signal and, possibly, place nulls in the directions of interferences
without the knowledge of the data picked up by the array or the statistics of the desired
and noise signals; as a consequence, the coeﬃcients of this ﬁlter are ﬁxed and do
not depend on the changes of the wave propagation environment in which the array
performs. However, ﬁxed beamforming uses information about the location of the
sensors in space and the directions of the desired and interference sources through the
steering vectors. Therefore, the geometry of the array needs to be known. In this chapter,
we derive and study a large class of ﬁxed beamformers in tandem with uniform linear
arrays (ULAs), where the sensors are located along a line with uniform spacing. In the
rest of this text, only ULAs are considered. This simpliﬁes the presentation of the main
results. Generalization to other geometries is not diﬃcult in general.
7.1
Signal Model and Problem Formulation
We consider a plane wave, in the farﬁeld – that is, far enough from the array –
that propagates in an anechoic environment at speed c, and impinges on a uniform
linear sensor array consisting of M omnidirectional sensors. The distance between two
successive sensors is equal to 𝛿and the direction of the source signal to the array is
parameterized by the azimuth angle 𝜃(see Figure .). In this context, the steering vector
(of length M) is given by [–]:
𝐝
(
f , cos 𝜃
)
=
[ 
e−𝚥𝜋f 𝜏cos 𝜃
⋯
e−𝚥(M−)𝜋f 𝜏cos 𝜃]T ,
(.)
where 𝚥=
√
−is the imaginary unit, f > is the temporal frequency, and 𝜏= 𝛿∕c is
the delay between two successive sensors at the angle 𝜃= . We denote by 𝜔= 𝜋f the
angular frequency and by 𝜆= c∕f the wavelength. Since cos 𝜃is an even function, so is
𝐝
(
f , cos 𝜃
)
. Therefore, the study is limited to angles 𝜃∈[, 𝜋].
For example, the speed of sound in the air is c = m/s.
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing

240
Fundamentals of Signal Enhancement and Array Signal Processing
X( f)
θd
δ
Y1(f)
Y2(f)
YM(f)
M
2
1
(M−1) δ cos θd
Plane
wavefront
V1(f)
VM( f )
Figure 7.1 A uniform linear array with M sensors.
Assume that the desired signal propagates from the angle 𝜃d. Using the signal model
of Chapter , the observation signal vector (of length M) is
𝐲( f ) = [ Y( f )
Y( f )
⋯
YM( f ) ]T
= 𝐱( f ) + 𝐯( f )
= 𝐝
(
f , cos 𝜃d
)
X( f ) + 𝐯( f ),
(.)
where Ym( f ) is the mth sensor signal, 𝐱( f ) = 𝐝
(
f , cos 𝜃d
)
X( f ), X( f ) is the desired
signal, 𝐝( f , cos 𝜃d
) is the steering vector at 𝜃= 𝜃d (direction of the desired source), and
𝐯( f ) is the additive noise signal vector deﬁned similarly to 𝐲( f ). Then, the correlation
matrix of 𝐲( f ) is
𝚽𝐲( f ) = E
[
𝐲( f )𝐲H( f )
]
(.)
= 𝜙X( f )𝐝( f , cos 𝜃d
) 𝐝H ( f , cos 𝜃d
) + 𝚽𝐯( f ),
where 𝜙X( f ) is the variance of X( f ) and 𝚽𝐯( f ) is the correlation matrix of 𝐯( f ).
Our objective in this chapter is to design beamformers, independent of the statistics of
the signals, which are able to form a main beam in the direction of the desired signal, 𝜃d,
in order to extract it undistorted while attenuating signals coming from other directions.
7.2
Linear Array Model
Usually, the array processing or beamforming is performed by applying a temporal ﬁlter
to each sensor signal and summing the ﬁltered signals. In the frequency domain, this is
equivalent to adding a complex weight to the output of each sensor and summing across
the aperture []:
www.ebook3000.com

Fixed Beamforming
241
Z( f ) =
M
∑
m=
H∗
m( f )Ym( f )
(.)
= 𝐡H( f )𝐲( f )
= Xfd( f ) + Vrn( f ),
where Z( f ) is the beamformer output signal,
𝐡( f ) = [ H( f )
H( f )
⋯
HM( f ) ]T
(.)
is the beamforming weight vector, which is suitable for performing spatial ﬁltering at
frequency f ,
Xfd( f ) = X( f )𝐡H( f )𝐝( f , cos 𝜃d
)
(.)
is the ﬁltered desired signal, and
Vrn( f ) = 𝐡H( f )𝐯( f )
(.)
is the residual noise.
Since the two terms on the right-hand side of (.) are incoherent, the variance of
Z( f ) is the sum of two variances:
𝜙Z( f ) = 𝐡H( f )𝚽𝐲( f )𝐡( f )
(.)
= 𝜙Xfd( f ) + 𝜙Vrn( f ),
where
𝜙Xfd( f ) = 𝜙X( f ) |||𝐡H( f )𝐝
(
f , cos 𝜃d
)|||

,
(.)
𝜙Vrn( f ) = 𝐡H( f )𝚽𝐯( f )𝐡( f ).
(.)
In the context of ﬁxed beamforming, the distortionless constraint is desired:
𝐡H( f )𝐝
(
f , cos 𝜃d
)
= ,
(.)
meaning that any signal arriving along 𝐝
(
f , cos 𝜃d
)
will pass through the beamformer
undistorted. Consequently, all beamformers will be derived by taking (.) into
account.
7.3
Performance Measures
In ﬁxed beamforming, it is customary to focus on narrowband performance measures
only. As in the previous chapters, the ﬁrst sensor is considered the reference.
Each beamformer has a pattern of directional sensitivity: it has diﬀerent sensitivities
from sounds arriving from diﬀerent directions. The beampattern or directivity pattern

242
Fundamentals of Signal Enhancement and Array Signal Processing
describes the sensitivity of the beamformer to a plane wave (source signal) impinging
on the array from the direction 𝜃. Mathematically, it is deﬁned as
[𝐡( f ), cos 𝜃] = 𝐝H ( f , cos 𝜃) 𝐡( f )
(.)
=
M
∑
m=
Hm( f )e𝚥(m−)𝜋f 𝜏cos 𝜃.
Usually, |||
[
𝐡( f ), cos 𝜃
]|||

, which is the power pattern [], is illustrated with a polar plot.
The (narrowband) input SNR is
iSNR( f ) = 𝜙X( f )
𝜙V( f ),
(.)
where 𝜙V( f ) = E
[
||V( f )||
]
is the variance of V( f ), which is the ﬁrst element of 𝐯( f ).
The (narrowband) output SNR is deﬁned as
oSNR [𝐡( f )] = 𝜙X( f )
|||𝐡H( f )𝐝( f , cos 𝜃d
)|||

𝐡H( f )𝚽𝐯( f )𝐡( f )
(.)
= 𝜙X( f )
𝜙V( f ) ×
|||𝐡H( f )𝐝
(
f , cos 𝜃d
)|||

𝐡H( f )𝚪𝐯( f )𝐡( f )
,
where
𝚪𝐯( f ) = 𝚽𝐯( f )
𝜙V( f )
(.)
is the pseudo-coherence matrix of 𝐯( f ). From the previous deﬁnitions of the SNRs, we
deduce the array gain:
[𝐡( f )] =
oSNR [𝐡( f )]
iSNR( f )
(.)
=
|||𝐡H( f )𝐝
(
f , cos 𝜃d
)|||

𝐡H( f )𝚪𝐯( f )𝐡( f )
.
The most convenient way to evaluate the sensitivity of the array to some of its
imperfections, such as sensor noise, is via the so-called (narrowband) white noise gain
(WNG) (already used in Chapter ), which is deﬁned by taking 𝚪𝐯( f ) = 𝐈M in (.),
where 𝐈M is the M × M identity matrix:
[𝐡( f )] =
|||𝐡H( f )𝐝
(
f , cos 𝜃d
)|||

𝐡H( f )𝐡( f )
.
(.)
www.ebook3000.com

Fixed Beamforming
243
Using the Cauchy–Schwarz inequality,
|||𝐡H( f )𝐝
(
f , cos 𝜃d
)|||

≤𝐡H( f )𝐡( f ) × 𝐝H (
f , cos 𝜃d
)
𝐝
(
f , cos 𝜃d
)
,
(.)
we easily deduce from (.) that
[𝐡( f )] ≤M, ∀𝐡( f ).
(.)
As a result, the maximum WNG is
max = M,
(.)
which is frequency independent. Let
cos [𝐝( f , cos 𝜃d
) , 𝐡( f )] =
𝐝H (
f , cos 𝜃d
)
𝐡( f ) + 𝐡H( f )𝐝
(
f , cos 𝜃d
)
‖‖‖𝐝( f , cos 𝜃d
)‖‖‖‖𝐡( f )‖
(.)
be the cosine of the angle between the two vectors 𝐝( f , cos 𝜃d
) and 𝐡( f ), with ‖⋅‖
denoting the 𝓁norm. Assuming the distortionless constraint, we can rewrite the
WNG as

[
𝐡( f )
]
= max cos[
𝐝
(
f , cos 𝜃d
)
, 𝐡( f )
]
.
(.)
Another important measure, which quantiﬁes how the sensor array performs in the
presence of reverberation, is the (narrowband) directivity factor (DF). Considering the
spherically isotropic (diﬀuse) noise ﬁeld, the DF is deﬁned as []:
[𝐡( f )] =
|||[𝐡( f ), cos 𝜃d
]|||


∫
𝜋

|||
[
𝐡( f ), cos 𝜃
]|||

sin 𝜃d𝜃
(.)
=
|||𝐡H( f )𝐝( f , cos 𝜃d
)|||

𝐡H( f )𝚪,𝜋( f )𝐡( f ) ,
where
𝚪,𝜋( f ) = 
∫
𝜋

𝐝( f , cos 𝜃) 𝐝H ( f , cos 𝜃) sin 𝜃d𝜃.
(.)
It can be veriﬁed that the elements of the M × M matrix 𝚪,𝜋( f ) are
[𝚪,𝜋( f )]
ij =
sin
[
𝜋f (j −i)𝜏
]
𝜋f (j −i)𝜏
(.)
= sinc
[
𝜋f (j −i)𝜏
]
,

244
Fundamentals of Signal Enhancement and Array Signal Processing
with [𝚪,𝜋( f )]
mm = , m = , , … , M. Again, by invoking the Cauchy–Schwarz
inequality,
|||𝐡H( f )𝐝
(
f , cos 𝜃d
)|||

≤𝐡H( f )𝚪,𝜋( f )𝐡( f ) ×
𝐝H (
f , cos 𝜃d
)
𝚪−
,𝜋( f )𝐝
(
f , cos 𝜃d
)
,
(.)
we ﬁnd from (.) that

[
𝐡( f )
]
≤𝐝H (
f , cos 𝜃d
)
𝚪−
,𝜋( f )𝐝
(
f , cos 𝜃d
)
, ∀𝐡( f ).
(.)
As a result, the maximum DF is
max
( f , cos 𝜃d
) = 𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)
(.)
= tr
[
𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
) 𝐝H ( f , cos 𝜃d
)]
≤Mtr
[
𝚪−
,𝜋( f )
]
,
which is frequency and (desired signal) angle dependent. Let
cos
[
𝚪−∕
,𝜋( f )𝐝
(
f , cos 𝜃d
)
, 𝚪∕
,𝜋( f )𝐡( f )
]
=
𝐝H ( f , cos 𝜃d
) 𝐡( f ) + 𝐡H( f )𝐝( f , cos 𝜃d
)
‖‖‖𝚪−∕
,𝜋( f )𝐝( f , cos 𝜃d
)‖‖‖
‖‖‖𝚪∕
,𝜋( f )𝐡( f )‖‖‖
(.)
be the cosine of the angle between the two vectors 𝚪−∕
,𝜋( f )𝐝( f , cos 𝜃d
) and 𝚪∕
,𝜋( f )𝐡( f ).
Assuming the distortionless constraint, we can express the DF as
[𝐡( f )] = max
( f , cos 𝜃d
) cos[
𝚪−∕
,𝜋( f )𝐝( f , cos 𝜃d
) , 𝚪∕
,𝜋( f )𝐡( f )
]
.
(.)
7.4
Spatial Aliasing
We discuss here the spatial aliasing problem encountered in array processing; it is
similar to the temporal aliasing that occurs when a continuous-time signal is sampled
at a rate lower than twice its highest frequency.
Let 𝜃and 𝜃be two diﬀerent angles; that is, 𝜃≠𝜃. Spatial aliasing occurs when
𝐝( f , cos 𝜃
) = 𝐝( f , cos 𝜃
), implying an ambiguity in source locations. Let
www.ebook3000.com

Fixed Beamforming
245
cos 𝜃= c
f 𝛿+ cos 𝜃
(.)
= 𝜆
𝛿+ cos 𝜃,
or, equivalently,
𝛿
𝜆=

cos 𝜃−cos 𝜃
.
(.)
It is straightforward to see that
e−𝚥(m−)𝜋f 𝜏cos 𝜃= e−𝚥(m−)𝜋f 𝜏cos 𝜃, m = , , … , M.
(.)
As a consequence,
𝐝( f , cos 𝜃
) = 𝐝( f , cos 𝜃
) ,
(.)
meaning that spatial aliasing takes place.
Since |cos 𝜃| ≤, we always have
||cos 𝜃−cos 𝜃|| ≤,
(.)
or, equivalently,

||cos 𝜃−cos 𝜃||
≥
.
(.)
We conclude from (.) that to prevent aliasing, one needs to ensure that
𝛿
𝜆< 
,
(.)
which is the classical narrowband aliasing criterion.
7.5
Fixed Beamformers
In this section, we derive several useful ﬁxed beamformers from the WNG and the DF,
which can also be viewed as meaningful criteria as the MSE criterion and not only as
performance measures.
7.5.1
Delay and Sum
The most well-known ﬁxed beamformer is the so-called delay-and-sum (DS), which is
derived by maximizing the WNG:
min
𝐡( f ) 𝐡H( f )𝐡( f ) subject to 𝐡H( f )𝐝( f , cos 𝜃d
) = .
(.)

246
Fundamentals of Signal Enhancement and Array Signal Processing
We easily get the optimal ﬁlter:
𝐡DS
( f , cos 𝜃d
) =
𝐝
(
f , cos 𝜃d
)
𝐝H (
f , cos 𝜃d
)
𝐝
(
f , cos 𝜃d
)
(.)
=
𝐝( f , cos 𝜃d
)
M
.
Therefore, with this beamformer, the WNG and the DF are, respectively,
[𝐡DS
( f , cos 𝜃d
)] = M = max
(.)
and
[𝐡DS
( f , cos 𝜃d
)] =
M
𝐝H (
f , cos 𝜃d
)
𝚪,𝜋( f )𝐝
(
f , cos 𝜃d
).
(.)
Since,
𝐝H ( f , cos 𝜃d
) 𝚪,𝜋( f )𝐝( f , cos 𝜃d
) ≤Mtr [𝚪,𝜋( f )] = M,
(.)
we have 
[
𝐡DS
(
f , cos 𝜃d
)]
≥. While the DS beamformer maximizes the WNG, it
never ampliﬁes the diﬀuse noise since [𝐡DS
( f , cos 𝜃d
)] ≥.
We ﬁnd that the beampattern is
|||[𝐡DS
( f , cos 𝜃d
) , cos 𝜃]|||

=

M
|||𝐝H ( f , cos 𝜃) 𝐝( f , cos 𝜃d
)|||

(.)
=

M
||||||
M
∑
m=
e𝚥(m−)𝜋f 𝜏(cos 𝜃−cos 𝜃d)
||||||

=

M
|||||
−e𝚥M𝜋f 𝜏(cos 𝜃−cos 𝜃d)
−e𝚥𝜋f 𝜏(cos 𝜃−cos 𝜃d)
|||||

,
with |||
[
𝐡DS
(
f , cos 𝜃d
)
, cos 𝜃
]|||

≤. The beampattern of the DS beamformer is very
frequency dependent.
Another interesting way to express (.) is []:

[
𝐡DS
(
f , cos 𝜃d
)]
= max
(
f , cos 𝜃d
)
× cos[
𝚪∕
,𝜋(f )𝐝(f , cos 𝜃d
) , 𝚪−∕
,𝜋(f )𝐝(f , cos 𝜃d
)]
,
(.)
where
cos
[
𝚪∕
,𝜋( f )𝐝( f , cos 𝜃d
) , 𝚪−∕
,𝜋( f )𝐝( f , cos 𝜃d
)]
=
𝐝H ( f , cos 𝜃d
) 𝐝( f , cos 𝜃d
)
√
𝐝H ( f , cos 𝜃d
) 𝚪,𝜋( f )𝐝( f , cos 𝜃d
)√
𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
) (.)
www.ebook3000.com

Fixed Beamforming
247
is the cosine of the angle between the two vectors 𝚪∕
,𝜋( f )𝐝( f , cos 𝜃d
) and 𝚪−∕
,𝜋( f )𝐝
( f , cos 𝜃d
). Let 𝜎( f ) and 𝜎M( f ) be the maximum and minimum eigenvalues of 𝚪,𝜋( f ),
respectively. Using the Kantorovich inequality []:
cos[
𝚪∕
,𝜋( f )𝐝
(
f , cos 𝜃d
)
, 𝚪−∕
,𝜋( f )𝐝
(
f , cos 𝜃d
)]
≥
𝜎( f )𝜎M( f )
[
𝜎( f ) + 𝜎M( f )
],
(.)
we deduce that
𝜎( f )𝜎M( f )
[
𝜎( f ) + 𝜎M( f )
]≤
[𝐡DS
( f , cos 𝜃d
)]
max
( f , cos 𝜃d
)
≤.
(.)
Example ..
Consider a ULA of M sensors, as shown in Figure .. Suppose that a
desired signal impinges on the ULA from the direction 𝜃d. Figure .shows plots of the
WNG, [𝐡DS
( f , cos 𝜃d
)], as a function of frequency, for diﬀerent numbers of sensors,
M. Figure .shows plots of the DF, 
[
𝐡DS
(
f , cos 𝜃d
)]
, as a function of frequency, for
diﬀerent numbers of sensors, M, and several values of 𝜃d and 𝛿. As the number of sensors
increases, both the WNG and the DF of the DS beamformer increase. Figures .–.
show beampatterns, |||
[
𝐡DS
(
f , cos 𝜃d
)
, cos 𝜃
]|||, for M = , several values of 𝜃d and 𝛿,
and several frequencies. The main beam is in the direction of the desired signal, 𝜃d. As
the frequency increases, the width of the main beam decreases. As 𝛿∕𝜆increases, we
may observe spatial aliasing, as shown in Figure .d.
■
0
2
4
6
8
3
4
5
6
7
8
9
10
f (kHz)
[hDS ( f, cos θd)] (dB)
Figure 7.2 WNG of the DS beamformer as a function of frequency, for different numbers of sensors, M:
M = 2 (solid line with circles), M = 4 (dashed line with asterisks), M = 6 (dotted line with squares), and
M = 8 (dash-dot line with triangles).

248
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
(c)
8
0
2
4
6
8
10
12
(a)
(b)
0
2
4
6
8
0
2
4
6
8
10
12
0
2
4
6
8
0
2
4
6
8
10
12
f (kHz)
f (kHz)
f (kHz)
 [hDS ( f , cos θd)] (dB)
 [hDS ( f , cos θd)] (dB)
 [hDS ( f , cos θd)] (dB)
Figure 7.3 DF of the DS beamformer as a function of frequency, for different numbers of sensors, M,
and several values of 𝜃d and 𝛿: M = 2 (solid line with circles), M = 4 (dashed line with asterisks), M = 6
(dotted line with squares), and M = 8 (dash-dot line with triangles). (a) 𝜃d = 90◦, 𝛿= 3 cm, (b) 𝜃d = 0◦,
𝛿= 1 cm, and (c) 𝜃d = 0◦, 𝛿= 3 cm.
7.5.2
Maximum DF
The maximum DF beamformer, as the name implies, maximizes the DF:
min
𝐡( f ) 𝐡H( f )𝚪,𝜋( f )𝐡( f ) subject to 𝐡H( f )𝐝( f , cos 𝜃d
) = .
(.)
Then, the maximum DF beamformer is
𝐡mDF
( f , cos 𝜃d
) =
𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)
𝐝H (
f , cos 𝜃d
)
𝚪−
,𝜋( f )𝐝
(
f , cos 𝜃d
).
(.)
We deduce that the WNG and the DF are, respectively,

[
𝐡mDF
(
f , cos 𝜃d
)]
=
[
𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)]
𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)
(.)
www.ebook3000.com

Fixed Beamforming
249
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.4 Beampatterns of the DS beamformer for several frequencies with M = 8, 𝜃d = 90◦, and
𝛿= 3 cm: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
and
[𝐡mDF
( f , cos 𝜃d
)] = 𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)
(.)
= max
(
f , cos 𝜃d
)
.
It is not hard to see that the beampattern is
|||
[
𝐡mDF
(
f , cos 𝜃d
)
, cos 𝜃
]|||

=
|||𝐝H ( f , cos 𝜃) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)|||

[
𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)].
(.)
We can express the WNG as []:
[𝐡mDF
( f , cos 𝜃d
)] = max cos[
𝐝( f , cos 𝜃d
) , 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)]
,
(.)

250
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.5 Beampatterns of the DS beamformer for several frequencies with M = 8, 𝜃d = 0◦, and
𝛿= 1 cm: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
where
cos
[
𝐝( f , cos 𝜃d
) , 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)]
=
𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)
√
𝐝H (
f , cos 𝜃d
)
𝐝
(
f , cos 𝜃d
)√
𝐝H (
f , cos 𝜃d
)
𝚪−
,𝜋( f )𝐝
(
f , cos 𝜃d
)
(.)
is the cosine of the angle between the two vectors 𝐝( f , cos 𝜃d
) and 𝚪−
,𝜋( f ) ( f , cos 𝜃d
).
Again, by invoking the Kantorovich inequality, we ﬁnd that
𝜎( f )𝜎M( f )
[
𝜎( f ) + 𝜎M( f )
]≤
[𝐡mDF
( f , cos 𝜃d
)]
max
≤.
(.)
www.ebook3000.com

Fixed Beamforming
251
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.6 Beampatterns of the DS beamformer for several frequencies with M = 8, 𝜃d = 0◦, and
𝛿= 3 cm: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
We can see from (.) that the WNG may be smaller than , which implies white noise
ampliﬁcation.
It is interesting to observe that

𝐡H
mDF
( f , cos 𝜃d
) 𝐡DS
( f , cos 𝜃d
) = max
(.)
and

𝐡H
mDF
(
f , cos 𝜃d
)
𝚪,𝜋( f )𝐡DS
(
f , cos 𝜃d
) = max
( f , cos 𝜃d
) .
(.)
We also give the obvious relationship between the DS and maximum DF beamformers:
max
( f , cos 𝜃d
) 𝚪,𝜋( f )𝐡mDF
( f , cos 𝜃d
) = max𝐡DS
( f , cos 𝜃d
) .
(.)

252
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
8
−100
−80
−60
−40
−20
0
20
(a)
(b)
(c)
0
2
4
6
8
−100
−80
−60
−40
−20
0
20
0
2
4
6
8
−100
−80
−60
−40
−20
0
20
f (kHz)
f (kHz)
f (kHz)
[hmDF ( f , cos θd)] (dB)
[hmDF ( f , cos θd)] (dB)
[hmDF ( f , cos θd)] (dB)
Figure 7.7 WNG of the maximum DF beamformer as a function of frequency, for different numbers of
sensors, M, and several values of 𝜃d and 𝛿: M = 2 (solid line with circles), M = 4 (dashed line with
asterisks), M = 6 (dotted line with squares), and M = 8 (dash-dot line with triangles). (a) 𝜃d = 90◦,
𝛿= 3 cm, (b) 𝜃d = 0◦, 𝛿= 1 cm, and (c) 𝜃d = 0◦, 𝛿= 3 cm.
Example ..
Returning to Example .., we now employ the maximum DF beam-
former,
𝐡mDF
(
f , cos 𝜃d
)
,
given
in
(.).
Figure
.
shows
plots
of
the
WNG, [𝐡mDF
( f , cos 𝜃d
)], as a function of frequency, for diﬀerent numbers of
sensors, M, and several values of 𝜃d and 𝛿. Figure .shows plots of the DF,

[
𝐡mDF
(
f , cos 𝜃d
)]
, as a function of frequency, for diﬀerent numbers of sensors, M,
and several values of 𝜃d and 𝛿. Compared to the DS beamformer, the maximum DF
beamformer obtains higher DF, but lower WNG (cf. Figures .and .). Generally,
for high frequencies, as the number of sensors increases, both the DF and the WNG
of the maximum DF beamformer increase. However, for low frequencies the WNG of
the maximum DF beamformer is signiﬁcantly lower than dB, which implies that the
maximum DF beamformer ampliﬁes the white noise at low frequencies.
Figures .–.show beampatterns, |||[𝐡mDF
( f , cos 𝜃d
) , cos 𝜃]|||, for M = , several
values of 𝜃d and 𝛿, and several frequencies. The main beam is in the direction of the
desired signal, 𝜃d. As the frequency increases, the width of the main beam decreases.
As 𝛿∕𝜆increases, we may observe spatial aliasing, as shown in Figure .d.
■
www.ebook3000.com

Fixed Beamforming
253
0
2
4
6
8
0
5
10
15
20
(a)
(c)
(b)
0
5
10
15
20
0
2
4
6
8
0
5
10
15
20
f (kHz)
0
2
4
6
8
f (kHz)
f (kHz)
 [hmDF ( f , cos θd)] (dB)
 [hmDF ( f , cos θd)] (dB)
 [hmDF ( f , cos θd)] (dB)
Figure 7.8 DF of the maximum DF beamformer as a function of frequency, for different numbers of
sensors, M, and several values of 𝜃d and 𝛿: M = 2 (solid line with circles), M = 4 (dashed line with
asterisks), M = 6 (dotted line with squares), and M = 8 (dash-dot line with triangles). (a) 𝜃d = 90◦,
𝛿= 3 cm, (b) 𝜃d = 0◦, 𝛿= 1 cm, and (c) 𝜃d = 0◦, 𝛿= 3 cm.
7.5.3
Superdirective
Let us evaluate the maximum DF, which is also the DF of the maximum DF beamformer,
for M = . After simple algebraic manipulations, we ﬁnd that
max
(
f , cos 𝜃d
)
= 
−sinc (𝜋f 𝜏
) cos (𝜋f 𝜏cos 𝜃d
)
−sinc(𝜋f 𝜏
)
.
(.)
Using in (.) the approximations:
sinc x ≈−x
,
(.)
cos x ≈−x
,
(.)

254
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.9 Beampatterns of the maximum DF beamformer for several frequencies with M = 8,
𝜃d = 90◦, and 𝛿= 3 cm: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
we obtain
max
( f , cos 𝜃d
) ≈

[
cos𝜃d + −
(
𝜋f 𝜏
)cos𝜃d
]
−(𝜋f 𝜏
)
.
(.)
First, for 𝛿very small, the previous expression can be further approximated by
max
(
f , cos 𝜃d
)
≈cos𝜃d + ,
(.)
which is frequency independent. Second, it is clear from (.) that the maximum DF
is maximized for 𝜃d = or 𝜋(endﬁre direction). The minimum of the maximum DF
is obtained for 𝜃d = 𝜋∕(broadside direction). From this simple example, we can
conclude that the best arrays, as far the DF is concerned, are endﬁre arrays with a small
interelement spacing. Broadside arrays do not perform very well in general. A deeper
www.ebook3000.com

Fixed Beamforming
255
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.10 Beampatterns of the maximum DF beamformer for several frequencies with M = 8,
𝜃d = 0◦, and 𝛿= 1 cm: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
study [] draws the same conclusions. Other experimental studies show the beneﬁts of
endﬁre arrays []. In fact, it can be shown that []:
lim
𝛿→max
( f , ) = M.
(.)
This high DF is called supergain in the literature.
The well-known superdirective beamformer is just a particular case of the maximum
DF beamformer, where 𝜃d = and 𝛿is small. It is given by []:
𝐡SD( f ) =
𝚪−
,𝜋( f )𝐝
(
f , 
)
𝐝H ( f , ) 𝚪−
,𝜋( f )𝐝( f , ).
(.)

256
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−30 dB
−40 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.11 Beampatterns of the maximum DF beamformer for several frequencies with M = 8,
𝜃d = 0◦, and 𝛿= 3 cm: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
While the superdirective beamformer maximizes the DF, it may amplify the white noise;
in other words, the WNG may be smaller than , especially at low frequencies (see
Figures .b and .c].
7.5.4
Robust Superdirective
It is well known that the superdirective beamformer is sensitive to spatially white noise,
so it lacks robustness. In order to deal with this important problem, Cox et al. proposed
maximizing the DF [, ]:
[𝐡( f )] =
|||𝐡H( f )𝐝
(
f , 
)|||

𝐡H( f )𝚪,𝜋( f )𝐡( f ),
(.)
www.ebook3000.com

Fixed Beamforming
257
subject to a constraint on the WNG:
[𝐡( f )] =
|||𝐡H( f )𝐝( f , )|||

𝐡H( f )𝐡( f )
.
(.)
This is equivalent to minimizing ∕[𝐡( f )] with a constraint on ∕[𝐡( f )]; in other
words, minimizing

[𝐡( f )] + 𝜖

[𝐡( f )] =
𝐡H( f ) [𝚪,𝜋( f ) + 𝜖𝐈M
] 𝐡( f )
|||𝐡H( f )𝐝
(
f , 
)|||

,
(.)
where 𝜖≥is a Lagrange multiplier. Using the distortionless constraint, we easily ﬁnd
that the optimal solution is
𝐡R,𝜖( f ) =
[𝚪,𝜋( f ) + 𝜖𝐈M
]−𝐝( f , )
𝐝H ( f , ) [𝚪,𝜋( f ) + 𝜖𝐈M
]−𝐝( f , ).
(.)
It is clear that (.) is a regularized version of (.), where 𝜖is the regularization
parameter. This parameter tries to ﬁnd a good compromise between a supergain and
white noise ampliﬁcation. A small 𝜖leads to a large DF and a low WNG, while a large
𝜖gives a low DF and a large WNG. We have 𝐡R,( f ) = 𝐡SD( f ) and 𝐡R,∞( f ) = 𝐡DS( f , ).
In practice, since white noise ampliﬁcation is much worse at low frequencies than
at high frequencies, it is better to make 𝜖frequency dependent. Therefore, (.) is
rewritten as
𝐡R,𝜖( f ) =
[𝚪,𝜋( f ) + 𝜖( f )𝐈M
]−𝐝( f , )
𝐝H (
f , 
) [
𝚪,𝜋( f ) + 𝜖( f )𝐈M
]−𝐝
(
f , 
).
(.)
An equivalent way to express (.) is
𝐡R,𝛼( f ) =
𝚪−
𝛼( f )𝐝( f , )
𝐝H (
f , 
)
𝚪−
𝛼( f )𝐝
(
f , 
),
(.)
where
𝚪𝛼( f ) = [−𝛼( f )] 𝚪,𝜋( f ) + 𝛼( f )𝐈M,
(.)
with 𝛼( f ) being a real number and ≤𝛼( f ) ≤. It can be checked that the relationship
between 𝛼( f ) and 𝜖( f ) is
𝜖( f ) =
𝛼( f )
−𝛼( f ).
(.)
The robust superdirective beamformer given in (.) may be preferable in practice to
the equivalent form given in (.) since 𝛼( f ) is set between and in the former

258
Fundamentals of Signal Enhancement and Array Signal Processing
while 𝜖( f ) is can be from to ∞in the latter. We ﬁnd that the WNG and the DF are,
respectively,
[𝐡R,𝛼( f )] =
[
𝐝H (
f , 
)
𝚪−
𝛼( f )𝐝
(
f , 
)]
𝐝H (
f , 
)
𝚪−
𝛼( f )𝐝
(
f , 
)
(.)
and
[𝐡R,𝛼( f )] =
[
𝐝H (
f , 
)
𝚪−
𝛼( f )𝐝
(
f , 
)]
𝐝H (
f , 
)
𝚪−
𝛼( f )𝚪,𝜋( f )𝚪−
𝛼( f )𝐝
(
f , 
).
(.)
Using the geometrical interpretation, the last two expressions become
[𝐡R,𝛼( f )] = max cos[𝐝( f , ) , 𝚪−
𝛼( f )𝐝( f , )]
(.)
and
[𝐡R,𝛼( f )] = max
( f , )
× cos[
𝚪∕
,𝜋( f )𝚪−
𝛼( f )𝐝
(
f , 
)
, 𝚪−∕
,𝜋( f )𝐝
(
f , 
)]
.
(.)
The beampattern of the robust superdirective beamformer is
|||[𝐡R,𝛼( f ), cos 𝜃]|||

=
|||𝐝H (
f , cos 𝜃
)
𝚪−
𝛼( f )𝐝
(
f , 
)|||

[𝐝H ( f , cos ) 𝚪−
𝛼( f )𝐝( f , )].
(.)
Example ..
Returning to Example .., we now use the robust superdirective
beamformer, 𝐡R,𝛼( f ), given in (.). To demonstrate the performance of the robust
superdirective beamformer, we choose 𝛿= cm.
Figure .shows plots of the WNG, 
[
𝐡R,𝛼( f )
]
, as a function of frequency, for
diﬀerent numbers of sensors, M, and several values of 𝛼. Figure .shows plots of the
WNG, [𝐡R,𝛼( f )], as a function of 𝛼, for diﬀerent numbers of sensors, M, and several
frequencies.
Figure .shows plots of the DF, [𝐡R,𝛼( f )], as a function of frequency, for diﬀerent
numbers of sensors, M, and several values of 𝛼. Figure .shows plots of the DF,

[
𝐡R,𝛼( f )
]
, as a function of 𝛼, for diﬀerent numbers of sensors, M, and several
frequencies.
For given frequency and 𝛼, as the number of sensors increases, the DF of the robust
superdirective beamformer increases. For given frequency and M, as the value of 𝛼
increases, the WNG of the robust superdirective beamformer increases at the expense
of a lower DF.
Figures .–.show beampatterns, |||
[
𝐡R,𝛼( f ), cos 𝜃
]|||, for M = , several values
of 𝛼, and several frequencies. The main beam is in the direction of the desired signal:
𝜃d = ◦. For a given 𝛼, as the frequency increases, the width of the main beam decreases.
For a given frequency, as the value of 𝛼increases, the width of the main beam increases
(lower DF).
■
www.ebook3000.com

Fixed Beamforming
259
0
2
4
6
8
−20
−15
−10
−5
0
5
10
f (kHz)
[h   , α( f )] (dB)
0
2
4
6
8
−20
−15
−10
−5
0
5
10
f (kHz)
(b)
(a)
(c)
(d)
0
2
4
6
8
−20
−15
−5
0
5
10
f (kHz)
0
2
4
6
8
−20
−15
−10
−5
0
5
10
f (kHz)
[h   ,α( f )] (dB)
[h   , α( f )] (dB)
[h   ,α( f )] (dB)
−10
Figure 7.12 WNG of the robust superdirective beamformer as a function of frequency, for different
numbers of sensors, M, and several values of 𝛼: M = 2 (solid line with circles), M = 4 (dashed line with
asterisks), M = 6 (dotted line with squares), and M = 8 (dash-dot line with triangles). (a) 𝛼= 0.001,
(b) 𝛼= 0.01, (c) 𝛼= 0.1, and (d) 𝛼= 1.
Let 𝐀and 𝐁be two invertible square matrices. If 𝜖is small compared to 𝐀and 𝐁,
then []:
(𝐀+ 𝜖𝐁)−≈𝐀−−𝜖𝐀−𝐁𝐀−.
(.)
Using the previous approximation in 𝚪𝛼( f ), we get
𝚪𝛼( f ) ≈(−𝛼)−𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f )
(.)
for ≤𝛼≤., and
𝚪𝛼( f ) ≈−𝛼−𝚪𝛼−( f )
(.)
for .< 𝛼≤, where
𝚪𝛼−( f ) =
[
−𝛼( f )
]
𝚪,𝜋( f ) −𝛼( f )𝐈M.
(.)

260
Fundamentals of Signal Enhancement and Array Signal Processing
−10
10–2
10–1
100
−5
0
5
10
(a)
[h   ,  ( f )] (dB)
−10
10–2
10–1
100
−5
0
5
10
(b)
[h   ,  ( f )] (dB)
−1010–2
10–1
100
10–2
10–1
100
−5
0
5
10
(c)
[h   , ( f )] (dB)
−10
−5
0
5
10
(d)
[h   , ( f )] (dB)
Figure 7.13 WNG of the robust superdirective beamformer as a function of 𝛼, for different numbers of
sensors, M, and several frequencies: M = 2 (solid line with circles), M = 4 (dashed line with asterisks),
M = 6 (dotted line with squares), and M = 8 (dash-dot line with triangles). (a) f = 1 kHz, (b) f = 2 kHz,
(c) f = 4 kHz, and (d) f = 8 kHz.
As a result, the robust beamformer becomes
𝐡R,𝛼≤.( f ) =
𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f )𝐝( f , )
𝐝H ( f , ) 𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f )𝐝( f , ),
(.)
𝐡R,𝛼>.( f ) =
𝚪𝛼−( f )𝐝( f , )
𝐝H ( f , ) 𝚪𝛼−( f )𝐝( f , ).
(.)
We deduce that the WNG and the DF are, respectively,

[
𝐡R,𝛼≤.( f )
]
=
[
𝐝H ( f , ) 𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f )𝐝( f , )]
𝐝H ( f , ) 𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f )𝐝( f , ),
(.)
[𝐡R,𝛼>.( f )] =
[
𝐝H (
f , 
)
𝚪𝛼−( f )𝐝
(
f , 
)]
𝐝H ( f , ) 𝚪
𝛼−( f )𝐝( f , ) ,
(.)
www.ebook3000.com

Fixed Beamforming
261
0
2
4
6
8
0
5
10
15
(a)
(b)
(c)
(d)
0
2
4
6
8
0
5
10
15
0
2
4
6
8
0
5
10
15
0
2
4
6
8
0
5
10
15
[h   , α( f )] (dB)
[h   , α( f )] (dB)
[h   ,α( f )] (dB)
[h   ,α( f )] (dB)
f (kHz)
f (kHz)
f (kHz)
f (kHz)
Figure 7.14 DF of the robust superdirective beamformer as a function of frequency, for different
numbers of sensors, M, and several values of 𝛼: M = 2 (solid line with circles), M = 4 (dashed line with
asterisks), M = 6 (dotted line with squares), and M = 8 (dash-dot line with triangles). (a) 𝛼= 0.001,
(b) 𝛼= 0.01, (c) 𝛼= 0.1, and (d) 𝛼= 1.
and

[
𝐡R,𝛼≤.( f )
]
=
[
𝐝H (
f , 
)
𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f )𝐝
(
f , 
)]
𝐝H (
f , 
)
𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f )𝐝
(
f , 
),
(.)
[𝐡R,𝛼>.( f )] =
[
𝐝H (
f , 
)
𝚪𝛼−( f )𝐝
(
f , 
)]
𝐝H (
f , 
)
𝚪𝛼−( f )𝚪,𝜋( f )𝚪𝛼−( f )𝐝
(
f , 
).
(.)
The good thing about this approximation is that for a desired WNG or DF, we can ﬁnd
the corresponding value of 𝛼( f ).

262
Fundamentals of Signal Enhancement and Array Signal Processing
0
0
10–2
10–1
100
5
10
15
5
10
15
0
5
10
15
0
5
10
15
(b)
(a)
(c)
(d)
100
10–2
10–1
100
10–2
10–1
100
10–2
10–1
[h   , α( f )] (dB)
[h   , α( f )] (dB)
[h   ,α( f )] (dB)
[h   ,α( f )] (dB)
Figure 7.15 DF of the robust superdirective beamformer as a function of 𝛼, for different numbers of
sensors, M, and several frequencies: M = 2 (solid line with circles), M = 4 (dashed line with asterisks),
M = 6 (dotted line with squares), and M = 8 (dash-dot line with triangles). (a) f = 1 kHz, (b) f = 2 kHz,
(c) f = 4 kHz, and (d) f = 8 kHz.
7.5.5
Null Steering
In this subsection, we assume that we have N sources, with N
< M, impinging
on the array from the directions 𝜃≠𝜃≠⋯≠𝜃N
≠𝜃d. These sources are
considered as interferences that we would like to completely cancel; in other words we
want to put nulls in the directions 𝜃n, n = , , … , N, with a beamformer 𝐡( f ), and,
meanwhile, recover the desired source coming from the direction 𝜃d. Combining all
these constraints together, we get the constraint equation:
𝐂H (
f , 𝜃d, 𝜃∶N
)
𝐡( f ) = 𝐢c,
(.)
where
𝐂
(
f , 𝜃d, 𝜃∶N
)
=
[
𝐝
(
f , 𝜃d
)
𝐝
(
f , 𝜃
)
⋯
𝐝
(
f , 𝜃N
) ]
(.)
www.ebook3000.com

Fixed Beamforming
263
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.16 Beampatterns of the robust superdirective beamformer for 𝛼= 0.01 and several
frequencies: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
is the constraint matrix of size M×(N +) whose N +columns are linearly independent
and
𝐢c = [ 

⋯
]T
(.)
is a vector of length N + .
Depending on what it is desired, we have at least two diﬀerent approaches to ﬁnding
the optimal ﬁlter, which are based on the WNG and the DF as criteria. The ﬁrst obvious
beamformer is obtained by maximizing the WNG and by taking (.) into account:
min
𝐡( f ) 𝐡H( f )𝐡( f ) subject to 𝐂H (
f , 𝜃d, 𝜃∶N
)
𝐡( f ) = 𝐢c.
(.)
From this criterion, we ﬁnd the minimum-norm (MN) beamformer:
𝐡MN
( f , cos 𝜃d
) = 𝐂( f , 𝜃d, 𝜃∶N
) [𝐂H ( f , 𝜃d, 𝜃∶N
) 𝐂( f , 𝜃d, 𝜃∶N
)]−𝐢c,
(.)

264
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.17 Beampatterns of the robust superdirective beamformer for 𝛼= 0.1 and several
frequencies: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
which is also the minimum-norm solution of (.). Clearly, we always have
[𝐡MN
( f , cos 𝜃d
)] ≤[𝐡DS
( f , cos 𝜃d
)] .
(.)
The other beamformer is obtained by maximizing the DF and by taking (.) into
account:
min
𝐡( f ) 𝐡H( f )𝚪,𝜋( f )𝐡( f ) subject to 𝐂H ( f , 𝜃d, 𝜃∶N
) 𝐡( f ) = 𝐢c.
(.)
We then easily ﬁnd the null-steering (NS) beamformer:
𝐡NS
( f , cos 𝜃d
) = 𝚪−
,𝜋( f )𝐂( f , 𝜃d, 𝜃∶N
)
×
[
𝐂H ( f , 𝜃d, 𝜃∶N
) 𝚪−
,𝜋( f )𝐂( f , 𝜃d, 𝜃∶N
)]−
𝐢c.
(.)
www.ebook3000.com

Fixed Beamforming
265
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.18 Beampatterns of the robust superdirective beamformer for 𝛼= 1 and several frequencies:
(a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
Obviously, we always have

[
𝐡NS
(
f , cos 𝜃d
)]
≤
[
𝐡mDF
(
f , cos 𝜃d
)]
.
(.)
A straightforward way to reach a compromise between the WNG and the DF with
the null-steering approach is the following beamformer:
𝐡𝛼
(
f , cos 𝜃d
)
= 𝚪−
𝛼( f )𝐂
(
f , 𝜃d, 𝜃∶N
)
× [𝐂H ( f , 𝜃d, 𝜃∶N
) 𝚪−
𝛼( f )𝐂( f , 𝜃d, 𝜃∶N
)]−𝐢c,
(.)
where 𝚪𝛼( f ) is deﬁned in (.). We observe that 𝐡
( f , cos 𝜃d
) = 𝐡NS
( f , cos 𝜃d
) and
𝐡
( f , cos 𝜃d
) = 𝐡MN
( f , cos 𝜃d
).

266
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
8
−40
−30
−20
−10
0
10
20
0
2
4
6
8
−40
−30
−20
−10
0
10
(a)
(b)
(c)
(d)
20
0
2
4
6
8
−40
−30
−20
−10
0
10
20
0
2
4
6
8
−40
−30
−20
−10
0
10
20
f (kHz)
f (kHz)
f (kHz)
f (kHz)
[hα ( f, cosθd)] (dB)
[hα ( f, cosθd)] (dB)
[hα ( f, cosθd)] (dB)
[hα ( f, cosθd)] (dB)
Figure 7.19 WNG of the MN/NS beamformer as a function of frequency, for different numbers of
sensors, M, and several values of 𝛼: 𝛼= 1e −5 (solid line with circles), 𝛼= 1e −3 (dashed line with
asterisks), and 𝛼= 1 (dotted line with squares). (a) M = 6, (b) M = 8, (c) M = 10, and (d) M = 12. As a
reference, [𝗵DS
( f, cos 𝜃d
)] is also plotted in the figures (dash-dot line with triangles).
Example ..
Returning to Example .., we now employ the MN/NS beamformer,
𝐡𝛼
( f , cos 𝜃d
), given in (.). To demonstrate the performance of the MN/NS beam-
former, we choose 𝜃d
= ◦, 𝜃
= ◦, 𝜃
= ◦, and 𝛿= cm. Figure .
shows plots of the WNG, 
[
𝐡𝛼
(
f , cos 𝜃d
)]
, as a function of frequency, for diﬀerent
numbers of sensors, M, and several values of 𝛼. As a reference, the WNG of the DS
beamformer, [𝐡DS
( f , cos 𝜃d
)], is also plotted. For given frequency and M, as the
value of 𝛼increases, the WNG of the MN/NS beamformer increases, and is upper
bounded by the WNG of the DS beamformer.
Figure .shows plots of the DF, [𝐡𝛼
( f , cos 𝜃d
)], as a function of frequency, for
diﬀerent numbers of sensors, M, and several values of 𝛼. As a reference, the DF of the
maximum DF beamformer, [𝐡mDF
( f , cos 𝜃d
)], is also plotted. For given frequency
and M, as the value of 𝛼increases, the DF of the MN/NS beamformer decreases, and is
upper bounded by the WNG of the maximum DF beamformer.
Figures .–.show beampatterns, |||
[
𝐡𝛼
(
f , cos 𝜃d
)
, cos 𝜃
]|||, for M = , several
values of 𝛼, and several frequencies. The main beam is in the direction of the desired
signal, 𝜃d. Compared to the previous beamformers, here the width of the main beam is
less sensitive to frequency.
■
In Table ., we summarize all the ﬁxed beamformers described in this section.
www.ebook3000.com

Fixed Beamforming
267
0
2
4
6
8
−10
−5
0
5
10
15
20
25
0
2
4
6
8
−10
−5
0
5
10
15
20
25
0
2
4
6
8
−10
−5
0
5
10
15
20
25
0
2
4
6
8
−10
−5
0
5
10
15
20
25
(a)
(b)
(c)
(d)
f (kHz)
f (kHz)
f (kHz)
f (kHz)
[hα ( f, cosθd)] (dB)
[hα ( f, cosθd)] (dB)
[hα ( f, cosθd)] (dB)
[hα ( f, cosθd)] (dB)
Figure 7.20 DF of the MN/NS beamformer as a function of frequency, for different numbers of
sensors, M, and several values of 𝛼: 𝛼= 1e −5 (solid line with circles), 𝛼= 1e −3 (dashed line with
asterisks), and 𝛼= 1 (dotted line with squares). (a) M = 6, (b) M = 8, (c) M = 10, and (d) M = 12. As a
reference, [𝗵mDF
( f, cos 𝜃d
)] is also plotted in the figures (dash-dot line with triangles).
7.6
A Signal Subspace Perspective
In this section, we give a signal subspace perspective of the superdirective beamformer
by using joint diagonalization []. This approach leads to a class of beamformers that
can better compromise between the WNG and the DF. It is assumed that 𝜃d = ; that
is, the desired signal is at the endﬁre.
7.6.1
Joint Diagonalization
The correlation matrix of 𝐱( f ) is 𝚽𝐱( f ) = 𝜙X( f )𝐝( f , ) 𝐝H ( f , ). Therefore, its pseudo-
coherence matrix is
𝚪𝐱( f ) = 𝚽𝐱( f )
𝜙X( f )
(.)
= 𝐝
(
f , 
)
𝐝H (
f , 
)
,
which does not depend on X( f ).

268
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.21 Beampatterns of the MN/NS beamformer for several frequencies with M = 8 and
𝛼= 1e −5: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
The two Hermitian matrices 𝚪𝐱( f ) and 𝚪,𝜋( f ) can be jointly diagonalized as fol-
lows []:
𝐓H( f )𝚪𝐱( f )𝐓( f ) = 𝚲( f ),
(.)
𝐓H( f )𝚪,𝜋( f )𝐓( f ) = 𝐈M,
(.)
where
𝐓( f ) =
[ 𝐭( f )
𝐭( f )
⋯
𝐭M( f ) ]
(.)
is a full-rank square matrix (of size M × M),
𝐭( f ) =
𝚪−
,𝜋( f )𝐝
(
f , 
)
√
𝐝H ( f , ) 𝚪−
,𝜋( f )𝐝( f , )
(.)
=
√
max
( f , )𝐡SD( f )
www.ebook3000.com

Fixed Beamforming
269
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.22 Beampatterns of the MN/NS beamformer for several frequencies with M = 8 and
𝛼= 1e −3: (a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
is the ﬁrst eigenvector of the matrix 𝚪−
,𝜋( f )𝚪𝐱( f ),
𝚲( f ) = diag [𝜆( f ), , … , ]
(.)
is a diagonal matrix (of size M × M), and
𝜆( f ) = 𝐝H ( f , ) 𝚪−
,𝜋( f )𝐝( f , )
(.)
= max
(
f , 
)
is the only nonnull eigenvalue of 𝚪−
,𝜋( f )𝚪𝐱( f ), whose corresponding eigenvector is 𝐭( f ).
It is important to observe that neither 𝐓( f ) nor 𝜆( f ) depend on the statistics of the
signals. It can be checked from (.) that
𝐭H
i ( f )𝐝( f , ) = , i = , , … , M.
(.)

270
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
Figure 7.23 Beampatterns of the MN/NS beamformer for several frequencies with M = 8 and 𝛼= 1:
(a) f = 1 kHz, (b) f = 2 kHz, (c) f = 4 kHz, and (d) f = 8 kHz.
7.6.2
Compromising Between WNG and DF
Let us deﬁne the matrix of size M × N:
𝐓∶N( f ) = [ 𝐭( f )
𝐭( f )
⋯
𝐭N( f ) ] ,
(.)
with ≤N ≤M. We consider beamformers that have the form:
𝐡∶N( f ) = 𝐓∶N( f )𝐚( f ),
(.)
where
𝐚( f ) =
[ A( f )
A( f )
⋯
AN( f ) ]T ≠𝟎
(.)
www.ebook3000.com

Fixed Beamforming
271
Table 7.1 Fixed beamformers.
Beamformer
DS
𝐡DS
( f , cos 𝜃d
) =
𝐝( f , cos 𝜃d
)
M
Maximum DF
𝐡mDF
( f , cos 𝜃d
) =
𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)
𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)
Superdirective
𝐡SD( f ) =
𝚪−
,𝜋( f )𝐝( f , )
𝐝H ( f , ) 𝚪−
,𝜋( f )𝐝( f , )
Robust SD
𝐡R,𝛼( f ) =
𝚪−
𝛼( f )𝐝( f , )
𝐝H ( f , ) 𝚪−
𝛼( f )𝐝( f , )
Minimum
norm
𝐡MN
( f , cos 𝜃d
) =
𝐂( f , 𝜃d, 𝜃∶N
) [𝐂H ( f , 𝜃d, 𝜃∶N
) 𝐂( f , 𝜃d, 𝜃∶N
)]−𝐢c
Null steering
𝐡NS
( f , cos 𝜃d
) = 𝚪−
,𝜋( f )𝐂( f , 𝜃d, 𝜃∶N
)
×
[
𝐂H ( f , 𝜃d, 𝜃∶N
) 𝚪−
,𝜋( f )𝐂( f , 𝜃d, 𝜃∶N
)]−
𝐢c
MN/NS
𝐡𝛼
( f , cos 𝜃d
) = 𝚪−
𝛼( f )𝐂( f , 𝜃d, 𝜃∶N
)
× [𝐂H ( f , 𝜃d, 𝜃∶N
) 𝚪−
𝛼( f )𝐂( f , 𝜃d, 𝜃∶N
)]−𝐢c
is a vector of length N. Substituting (.) into (.), we ﬁnd that
Z( f ) = 𝐚H( f )𝐓H
∶N( f )𝐝( f , ) X( f ) + 𝐚H( f )𝐓H
∶N( f )𝐯( f )
(.)
= A∗
( f )
√
𝜆( f )X( f ) + 𝐚H( f )𝐓H
∶N( f )𝐯( f ).
Since the distortionless constraint is desired, it is clear from the previous expression
that we always choose
A( f ) =

√
𝜆( f )
.
(.)
Now, we need to determine the other elements of 𝐚( f ).
With the beamformer given in (.), the WNG and the DF are, respectively,
[𝐡∶N( f )] =
|||𝐡H
∶N( f )𝐝
(
f , 
)|||

𝐡H
∶N( f )𝐡∶N( f )
(.)
=
|||𝐚H( f )𝐓H
∶N( f )𝐝( f , )|||

𝐚H( f )𝐓H
∶N( f )𝐓∶N( f )𝐚( f )

272
Fundamentals of Signal Enhancement and Array Signal Processing
and
[𝐡∶N( f )] =
|||𝐡H
∶N( f )𝐝
(
f , 
)|||

𝐡H
∶N( f )𝚪,𝜋( f )𝐡∶N( f )
(.)
=
|||𝐚H( f )𝐓H
∶N( f )𝐝( f , )|||

𝐚H( f )𝐓H
∶N( f )𝚪,𝜋( f )𝐓∶N( f )𝐚( f )
=
|||𝐚H( f )𝐓H
∶N( f )𝐝( f , )|||

𝐚H( f )𝐚( f )
.
The maximization of the DF or, equivalently, the minimization of 𝐡H
∶N( f )𝚪,𝜋( f )
𝐡∶N( f ) subject to 𝐡H
∶N( f )𝐝( f , )
=
, leads to the conventional superdirective
beamformer:
𝐡SD( f ) =
𝐓∶N( f )𝐓H
∶N( f )𝐝( f , )
𝐝H ( f , ) 𝐓∶N( f )𝐓H
∶N( f )𝐝( f , )
(.)
=
𝐭( f )𝐭H
( f )𝐝( f , )
|||𝐭H
( f )𝐝( f , )|||

=
𝚪−
,𝜋( f )𝐝( f , )
𝐝H ( f , ) 𝚪−
,𝜋( f )𝐝( f , ).
The most useful subspace beamformer is derived by maximizing the WNG. This is
equivalent to minimizing 𝐡H
∶N( f )𝐡∶N( f ) subject to 𝐡H
∶N( f )𝐝( f , ) = . We easily ﬁnd
𝐡∶N( f ) =
𝐏𝐓∶N( f )𝐝
(
f , 
)
𝐝H ( f , ) 𝐏𝐓∶N( f )𝐝( f , ),
(.)
where
𝐏𝐓∶N( f ) = 𝐓∶N( f ) [𝐓H
∶N( f )𝐓∶Nf ]−𝐓H
∶N( f ).
(.)
For N = , we get
𝐡∶( f ) =
𝐭( f )
𝐝H ( f , ) 𝐭( f )
(.)
= 𝐡SD( f ),
which is the conventional superdirective beamformer, and for N = M, we obtain
𝐡∶M( f ) =
𝐝
(
f , 
)
𝐝H (
f , 
)
𝐝
(
f , 
)
(.)
= 𝐡DS
( f , ) ,
www.ebook3000.com

Fixed Beamforming
273
which is the DS beamformer. Therefore, by playing with N, we obtain diﬀerent
beamformers whose performances are in between the performances of 𝐡SD( f ) and
𝐡DS
(
f , 
)
. To make matters a bit more complicated, we can also make N frequency
dependent. Indeed, at high frequencies, it may be desirable to take values of N lower
than at low frequencies.
With the proposed beamformer, the WNG is
[𝐡∶N( f )] = 𝐝H ( f , ) 𝐏𝐓∶N( f )𝐝( f , )
(.)
= 𝜆( f )𝐢T [
𝐓H
∶N( f )𝐓∶N( f )
]−𝐢,
where 𝐢is the ﬁrst column of the N × N identity matrix, 𝐈N, with
[𝐡∶( f )] =
|||𝐭H
( f )𝐝( f , )|||

𝐭H
( f )𝐭( f )
(.)
=
𝜆( f )
𝐭H
( f )𝐭( f )
=
[
𝐝H ( f , ) 𝚪−
,𝜋( f )𝐝( f , )]
𝐝H ( f , ) 𝚪−
,𝜋( f )𝐝( f , )
≤M
and
[𝐡∶M( f )] = M.
(.)
The DF is
[𝐡∶N( f )] =
[𝐝H ( f , ) 𝐏𝐓∶N( f )𝐝( f , )]
𝐝H (
f , 
)
𝐏𝐓∶N( f )𝚪,𝜋( f )𝐏𝐓∶N( f )𝐝
(
f , 
)
= 𝜆( f )
{
𝐢T [𝐓H
∶N( f )𝐓∶N( f )]−𝐢
}
𝐢T [𝐓H
∶N( f )𝐓∶N( f )]−𝐢
,
(.)
with
[𝐡∶( f )] = 𝜆( f ) ≤M
(.)
and
[𝐡∶M( f )] =
[𝐝H ( f , ) 𝐝( f , )]
𝐝H ( f , ) 𝚪,𝜋( f )𝐝( f , )
(.)
=
M
𝐝H ( f , ) 𝚪,𝜋( f )𝐝( f , ) ≥.

274
Fundamentals of Signal Enhancement and Array Signal Processing
2
3
4
5
6
7
8
−100
−80
−60
−40
−20
0
20
f (kHz)
[h1:N (f)] (dB)
Figure 7.24 WNG of the subspace beamformer as a function of frequency, for several values of N:
N = 1 (solid line with circles), N = 2 (dashed line with asterisks), N = 4 (dotted line with squares), and
N = 8 (dash-dot line with triangles).
2
3
4
5
6
7
8
0
5
10
15
20
f (kHz)
[h1:N (f)] (dB)
Figure 7.25 DF of the subspace beamformer as a function of frequency, for several values of N: N = 1
(solid line with circles), N = 2 (dashed line with asterisks), N = 4 (dotted line with squares), and N = 8
(dash-dot line with triangles).
We also deduce a useful relationship between the WNG and the DF:
[𝐡∶N( f )]

[
𝐡∶N( f )
] =
𝐢T [
𝐓H
∶N( f )𝐓∶N( f )
]−𝐢
𝐢T [𝐓H
∶N( f )𝐓∶N( f )]−𝐢
,
(.)
where

M ≤
[𝐡∶N( f )]
[𝐡∶N( f )] < ∞.
(.)
We should always have
M≥[𝐡∶( f )] ≥[𝐡∶( f )] ≥⋯≥[𝐡∶M( f )]
(.)
www.ebook3000.com

Fixed Beamforming
275
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 7.26 Beampatterns of the subspace beamformer for N = 1 and several frequencies:
(a) f = 2 kHz, (b) f = 4 kHz, (c) f = 6 kHz, and (d) f = 8 kHz.
and
M = 
[
𝐡∶M( f )
]
≥
[
𝐡∶M−( f )
]
≥⋯≥
[
𝐡∶( f )
]
.
(.)
Clearly, the beamformer 𝐡∶N( f ) is much more useful and practical than the beam-
former 𝐡R,𝛼( f ) for control of white noise ampliﬁcation while giving a reasonably
good DF.
Example ..
Returning to Example .., we now employ the subspace beamformer,
𝐡∶N( f ), given in (.). To demonstrate the performance of the subspace beamformer,
we choose M = and 𝛿= cm. Figure .shows plots of the WNG, [𝐡∶N( f )], as
a function of frequency, for several values of N. For a given frequency, as the value of N
increases, the WNG of the subspace beamformer increases, and is upper bounded by
the WNG of the DS beamformer.

276
Fundamentals of Signal Enhancement and Array Signal Processing
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 7.27 Beampatterns of the subspace beamformer for N = 2 and several frequencies:
(a) f = 2 kHz, (b) f = 4 kHz, (c) f = 6 kHz, and (d) f = 8 kHz.
Figure .shows plots of the DF, [𝐡∶N( f )], as a function of frequency, for
several values of N. For a given frequency, as the value of N decreases, the DF of the
subspace beamformer increases, and is upper bounded by the DF of the superdirective
beamformer.
Figures .–.show beampatterns, |||
[
𝐡∶N( f ), cos 𝜃
]|||, for several values of N,
and several frequencies. The main beam is in the direction of the desired signal; in other
words, 𝜃d = ◦.
■
Problems
7.1 Show that, in the distortionless case, the WNG can be written as

[
𝐡( f )
]
= max cos[
𝐝
(
f , cos 𝜃d
)
, 𝐡( f )
]
.
www.ebook3000.com

Fixed Beamforming
277
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 7.28 Beampatterns of the subspace beamformer for N = 4 and several frequencies:
(a) f = 2 kHz, (b) f = 4 kHz, (c) f = 6 kHz, and (d) f = 8 kHz.
7.2 Using the Cauchy–Schwarz inequality, show that the maximum DF is
max
(
f , cos 𝜃d
)
= 𝐝H (
f , cos 𝜃d
)
𝚪−
,𝜋( f )𝐝
(
f , cos 𝜃d
)
= tr
[
𝚪−
,𝜋( f )𝐝
(
f , cos 𝜃d
)
𝐝H (
f , cos 𝜃d
)]
≤Mtr
[
𝚪−
,𝜋( f )
]
.
7.3 Show that, in the distortionless case, the DF can be written as
[𝐡( f )] = max
( f , cos 𝜃d
) cos[
𝚪−∕
,𝜋( f )𝐝( f , cos 𝜃d
) , 𝚪∕
,𝜋( f )𝐡( f )
]
.

278
Fundamentals of Signal Enhancement and Array Signal Processing
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−10 dB
Figure 7.29 Beampatterns of the subspace beamformer for N = 8 and several frequencies:
(a) f = 2 kHz, (b) f = 4 kHz, (c) f = 6 kHz, and (d) f = 8 kHz.
7.4 Show that the condition to prevent spatial aliasing is
𝛿
𝜆< 
.
7.5 Show that the DS beamformer:
𝐡DS
( f , cos 𝜃d
) =
𝐝
(
f , cos 𝜃d
)
M
,
maximizes the WNG:
min
𝐡( f ) 𝐡H( f )𝐡( f ) subject to 𝐡H( f )𝐝( f , cos 𝜃d
) = .
www.ebook3000.com

Fixed Beamforming
279
7.6 Show that with the DS beamformer, the DF is given by

[
𝐡DS
(
f , cos 𝜃d
)]
=
M
𝐝H ( f , cos 𝜃d
) 𝚪,𝜋( f )𝐝( f , cos 𝜃d
).
7.7 Show
that
the
DS
beamformer
never
ampliﬁes
the
diﬀuse
noise:
[𝐡DS
( f , cos 𝜃d
)] ≥.
7.8 Show that the beampattern of the DS beamformer is given by
|||[𝐡DS
( f , cos 𝜃d
) , cos 𝜃]|||

=

M
|||||
−e𝚥M𝜋f 𝜏(cos 𝜃−cos 𝜃d)
−e𝚥𝜋f 𝜏(cos 𝜃−cos 𝜃d)
|||||

.
7.9 Show that the DF of the DS beamformer can be written as
[𝐡DS
( f , cos 𝜃d
)] = max
( f , cos 𝜃d
)
× cos[
𝚪∕
,𝜋( f )𝐝
(
f , cos 𝜃d
)
, 𝚪−∕
,𝜋( f )𝐝
(
f , cos 𝜃d
)]
.
7.10 Let 𝜎( f ) and 𝜎M( f ) be the maximum and minimum eigenvalues of 𝚪,𝜋( f ),
respectively. Show that
𝜎( f )𝜎M( f )
[𝜎( f ) + 𝜎M( f )]≤
[𝐡DS
( f , cos 𝜃d
)]
max
( f , cos 𝜃d
)
≤.
7.11 Show that the beamformer that maximizes the DF is given by
𝐡mDF
(
f , cos 𝜃d
)
=
𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
)
𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
).
7.12 Show that the WNG and the DF of the maximum DF beamformer are given by
[𝐡mDF
( f , cos 𝜃d
)] =
[
𝐝H (
f , cos 𝜃d
)
𝚪−
,𝜋( f )𝐝
(
f , cos 𝜃d
)]
𝐝H (
f , cos 𝜃d
)
𝚪−
,𝜋( f )𝐝
(
f , cos 𝜃d
) ,
[𝐡mDF
( f , cos 𝜃d
)] = 𝐝H ( f , cos 𝜃d
) 𝚪−
,𝜋( f )𝐝( f , cos 𝜃d
) .
7.13 Let 𝜎( f ) and 𝜎M( f ) be the maximum and minimum eigenvalues of 𝚪,𝜋( f ),
respectively. Show that
𝜎( f )𝜎M( f )
[
𝜎( f ) + 𝜎M( f )
]≤
[𝐡mDF
( f , cos 𝜃d
)]
max
≤.
7.14 Show that the DS and maximum DF beamformers are related by
max
( f , cos 𝜃d
) 𝚪,𝜋( f )𝐡mDF
( f , cos 𝜃d
) = max𝐡DS
( f , cos 𝜃d
) .

280
Fundamentals of Signal Enhancement and Array Signal Processing
7.15 Show that for M = sensors and small 𝛿, the maximum DF can be approximated
by
max
( f , cos 𝜃d
) ≈cos𝜃d + .
7.16 Show that minimizing

[𝐡( f )] + 𝜖

[𝐡( f )]
with the distortionless constraint yields the robust superdirective beamformer:
𝐡R,𝜖( f ) =
[𝚪,𝜋( f ) + 𝜖𝐈M
]−𝐝( f , )
𝐝H ( f , ) [𝚪,𝜋( f ) + 𝜖𝐈M
]−𝐝( f , ).
7.17 Show that the robust superdirective beamformer can be expressed as
𝐡R,𝛼( f ) =
𝚪−
𝛼( f )𝐝( f , )
𝐝H ( f , ) 𝚪−
𝛼( f )𝐝( f , ),
where 𝚪𝛼( f ) = [−𝛼( f )] 𝚪,𝜋( f ) + 𝛼( f )𝐈M, and 𝜖( f ) =
𝛼( f )
−𝛼( f ).
7.18 Let 𝚪𝛼−( f ) =
[
−𝛼( f )
]
𝚪,𝜋( f ) −𝛼( f )𝐈M. Show that for ≤𝛼≤.,
𝚪𝛼( f ) ≈(−𝛼)−𝚪−
,𝜋( f )𝚪𝛼−( f )𝚪−
,𝜋( f ),
and for .< 𝛼≤,
𝚪𝛼( f ) ≈−𝛼−𝚪𝛼−( f ).
7.19 Show that maximizing the WNG with the constraint 𝐂H ( f , 𝜃d, 𝜃∶N
) 𝐡( f ) = 𝐢c
yields the MN beamformer:
𝐡MN
( f , cos 𝜃d
) = 𝐂( f , 𝜃d, 𝜃∶N
) [𝐂H ( f , 𝜃d, 𝜃∶N
) 𝐂( f , 𝜃d, 𝜃∶N
)]−𝐢c.
7.20 Show that maximizing the DF with the constraint 𝐂H ( f , 𝜃d, 𝜃∶N
) 𝐡( f ) = 𝐢c yields
the NS beamformer:
𝐡NS
( f , cos 𝜃d
) = 𝚪−
,𝜋( f )𝐂( f , 𝜃d, 𝜃∶N
)
×
[
𝐂H ( f , 𝜃d, 𝜃∶N
) 𝚪−
,𝜋( f )𝐂( f , 𝜃d, 𝜃∶N
)]−
𝐢c.
www.ebook3000.com

Fixed Beamforming
281
7.21 Show that with a beamformer of the form 𝐡∶N( f ) = 𝐓∶N( f )𝐚( f ), the WNG and
the DF are
[𝐡∶N( f )] =
|||𝐚H( f )𝐓H
∶N( f )𝐝( f , )|||

𝐚H( f )𝐓H
∶N( f )𝐓∶N( f )𝐚( f )
,
[𝐡∶N( f )] =
|||𝐚H( f )𝐓H
∶N( f )𝐝
(
f , 
)|||

𝐚H( f )𝐚( f )
.
7.22 Show the following relationship between the WNG and the DF:
[𝐡∶N( f )]
[𝐡∶N( f )] =
𝐢T [𝐓H
∶N( f )𝐓∶N( f )]−𝐢
𝐢T [𝐓H
∶N( f )𝐓∶N( f )]−𝐢
.
7.23 Show that with the beamformer 𝐡∶N( f ), we can control the WNG and the DF by
M≥[𝐡∶( f )] ≥[𝐡∶( f )] ≥⋯≥[𝐡∶M( f )]
and
M = [𝐡∶M( f )] ≥[𝐡∶M−( f )] ≥⋯≥[𝐡∶( f )] .
References
1 B. D. Van Veen and K. M. Buckley, “Beamforming: a versatile approach to spatial
ﬁltering,” IEEE Acoust., Speech, Signal Process. Mag., vol. , pp. –, Apr. .
2 D. H. Johnson and D. E. Dudgeon, Array Signal Processing: Concepts and Techniques.
Signal Processing Series. Englewood Cliﬀs, NJ: Prentice-Hall, .
3 R. A. Monzingo and T. W. Miller, Introduction to Adaptive Arrays. Raleigh, NC:
SciTech, .
4 J. P. Dmochowski and J. Benesty, “Microphone arrays: fundamental concepts,” in Speech
Processing in Modern Communication–Challenges and Perspectives, I. Cohen, J.
Benesty, and S. Gannot, (eds). Berlin, Germany: Springer-Verlag, .
5 H. L. Van Trees, Optimum Array Processing: Part IV of Detection, Estimation, and
Modulation Theory. New York, NY: John Wiley & Sons, Inc., .
6 R. Berkun, I. Cohen, and J. Benesty, “Combined beamformers for robust broadband
regularized superdirective beamforming,” IEEE/ACM Trans. Audio, Speech, Language
Process., vol. , pp. –, May .
7 G. A. F. Seber, A Matrix Handbook for Statisticians. Hoboken, NJ: John Wiley & Sons,
Inc., .
8 C. Pan, J. Chen, and J. Benesty, “Performance study of the MVDR beamformer as a
function of the source incidence angle,” IEEE/ACM Trans. Audio, Speech, Language
Process., vol. , pp. –, Jan. .
9 J. M. Kates and M. R. Weiss, “A comparison of hearing-aid array-processing
techniques,” J. Acoust. Soc. Am., vol. , pp. –, May .

282
Fundamentals of Signal Enhancement and Array Signal Processing
10 A. I. Uzkov, “An approach to the problem of optimum directive antenna design,”
Comptes Rendus (Doklady) de l’Academie des Sciences de l’URSS, vol. LIII, no. ,
pp. –, .
11 H. Cox, R. M. Zeskind, and T. Kooij, “Practical supergain,” IEEE Trans. Acoust., Speech,
Signal Process., vol. ASSP-, pp. –, June .
12 H. Cox, R. M. Zeskind, and M. M. Owen, “Robust adaptive beamforming,” IEEE Trans.
Acoust., Speech, Signal Process., vol. ASSP-, pp. –, Oct. .
13 K. B. Petersen and M. S. Pedersen, The Matrix Cookbook. http://matrixcookbook.com,
.
14 C. Li, J. Benesty, G. Huang, and J. Chen, “Subspace superdirective beamformers based
on joint diagonalization,” in Proc. IEEE ICASSP, , pp. –.
15 J. N. Franklin, Matrix Theory. Englewood Cliﬀs, NJ: Prentice-Hall, .
www.ebook3000.com

283
8
Adaptive Beamforming
In the previous chapter, we developed ﬁxed beamformers, which do not depend on the
statistics of the array data. This was possible because a model for the noise ﬁeld was
used. These beamformers are easy to implement and can work pretty well in diﬀerent
scenarios. However, in very challenging environments with multipath propagation,
the performance of these algorithms, in terms of noise reduction, may be limited.
Therefore, it is necessary to develop optimal linear ﬁlters that take into consideration the
statistics of the incoming data. The resulting beamformers are referred to as adaptive
beamformers. This is what we describe in this chapter. We will see that many useful
adaptive beamformers can be derived, and each one of them can be expressed in
diﬀerent, but equivalent ways, depending on what statistics need to be estimated.
8.1
Signal Model, Problem Formulation, and Array Model
We consider a ULA consisting of M omnidirectional sensors and the signal model of
the previous chapter:
𝐲( f ) = 𝐱( f ) + 𝐯( f )
= 𝐝(f , cos 𝜃d
) X( f ) + 𝐯( f ),
(.)
where 𝐲( f ) is observation signal vector (of length M), 𝐝(f , cos 𝜃d
) is the steering vector
associated with the desired signal, X( f ), impinging on the array from the direction 𝜃d,
and 𝐯( f ) is the noise signal vector. The correlation matrix of 𝐲( f ) is
𝚽𝐲( f ) = 𝚽𝐱( f ) + 𝚽𝐯( f )
(.)
= 𝜙X( f )𝐝(f , cos 𝜃d
) 𝐝H (f , cos 𝜃d
) + 𝚽𝐯( f ),
where 𝚽𝐱( f ) and 𝚽𝐯( f ) are the correlation matrices of 𝐱( f ) and 𝐯( f ), respectively, and
𝜙X( f ) is the variance of X( f ).
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing

284
Fundamentals of Signal Enhancement and Array Signal Processing
Beamforming or linear ﬁltering [] consists of applying a complex-valued linear ﬁlter,
𝐡( f ), of length M to 𝐲( f ):
Z( f ) = 𝐡H( f )𝐲( f )
(.)
= 𝐡H( f )
[
𝐱( f ) + 𝐯( f )
]
= Xfd( f ) + Vrn( f ),
where Z( f ) is, in general, the estimate of the desired signal, and Xfd( f ) and Vrn( f ) are
the ﬁltered desired signal and residual noise, respectively. Assuming that Xfd( f ) and
Vrn( f ) are uncorrelated, the variance of Z( f ) is
𝜙Z( f ) = 𝜙Xfd( f ) + 𝜙Vrn( f )
(.)
= 𝜙X( f ) |||𝐡H( f )𝐝
(
f , cos 𝜃d
)|||

+ 𝐡H( f )𝚽𝐯( f )𝐡( f ).
Our objective in this chapter is to design and describe beamformers that depend on
the statistics of the signals as well as the knowledge of the direction of the desired signal.
These so-called adaptive beamformers can usually adapt fairly quickly to changes in the
environments in which they operate. They do not rely on some model of the noise ﬁeld,
as the ﬁxed beamformers described in Chapter do.
8.2
Performance Measures
In this section, we brieﬂy recall both the main narrowband and broadband performance
measures. The narrowband and broadband input SNRs are, respectively,
iSNR( f ) = 𝜙X( f )
𝜙V( f )
(.)
and
iSNR =
∫f 𝜙X( f )df
∫f 𝜙V( f )df
,
(.)
where 𝜙V( f ) is the variance of V( f ), which is the ﬁrst element of the vector 𝐯( f ).
From (.), we deduce the narrowband output SNR:
oSNR [𝐡( f )] =
𝜙Xfd( f )
𝜙Vrn( f )
(.)
=
𝜙X( f ) |||𝐡H( f )𝐝(f , cos 𝜃d
)|||

𝐡H( f )𝚽𝐯( f )𝐡( f )
www.ebook3000.com

Adaptive Beamforming
285
and the broadband output SNR:
oSNR (𝐡) =
∫f 𝜙X( f ) |||𝐡H( f )𝐝
(
f , cos 𝜃d
)|||

df
∫f 𝐡H( f )𝚽𝐯( f )𝐡( f )df
.
(.)
It follows from the deﬁnitions of the input and output SNRs that the narrowband and
broadband array gains are, respectively,

[
𝐡( f )
]
=
oSNR [𝐡( f )]
iSNR( f )
,
(.)
(𝐡) = oSNR (𝐡)
iSNR
.
(.)
Adaptive beamformers should be designed in such a way that [𝐡( f )] > and (𝐡) > .
Other useful deﬁnitions to quantify noise reduction are the narrowband noise reduc-
tion factor:
𝜉n
[𝐡( f )] =
𝜙V( f )
𝐡H( f )𝚽𝐯( f )𝐡( f )
(.)
and the broadband noise reduction factor:
𝜉n (𝐡) =
∫f 𝜙V( f )df
∫f 𝐡H( f )𝚽𝐯( f )𝐡( f )df
.
(.)
In the distortionless case; in other words,
𝐡H( f )𝐝
(
f , cos 𝜃d
)
= ,
(.)
the noise reduction factor coincides with the array gain for both the narrowband and
broadband measures.
In order to quantify distortion of the desired signal due to the beamforming operation,
we deﬁne the narrowband desired signal reduction factor:
𝜉d
[
𝐡( f )
]
=

|||𝐡H( f )𝐝
(
f , cos 𝜃d
)|||

(.)
and the broadband desired signal reduction factor:
𝜉d (𝐡) =
∫f 𝜙X( f )df
∫f 𝜙X( f ) |||𝐡H( f )𝐝(f , cos 𝜃d
)|||

df
.
(.)
In the distortionless case, we have 𝜉d = , but when distortion occurs, we have 𝜉d > .

286
Fundamentals of Signal Enhancement and Array Signal Processing
An alternative measure to the desired signal reduction factor is the desired signal
distortion index. We have the following deﬁnitions:
●the narrowband desired signal distortion index
𝜐d
[
𝐡( f )
]
= |||𝐡H( f )𝐝
(
f , cos 𝜃d
)
−|||

(.)
●and the broadband desired signal distortion index
𝜐d (𝐡) =
∫f 𝜙X( f ) |||𝐡H( f )𝐝
(
f , cos 𝜃d
)
−|||

df
∫f 𝜙X( f )df
.
(.)
The error signal between the estimated and desired signals at the frequency f is
given by
(f ) = Z( f ) −X( f )
(.)
= Xfd( f ) + Vrn( f ) −X( f )
= d
(
f
)
+ n
(
f
)
,
where
d
(f ) = [𝐡H( f )𝐝(f , cos 𝜃d
) −] X( f )
(.)
is the desired signal distortion due to the beamformer and
n
(
f
)
= 𝐡H( f )𝐯( f )
(.)
represents the residual noise. Assuming that d
(f ) and n
(f ) are incoherent, the
narrowband MSE can be expressed as
J
[
𝐡( f )
]
= E
[|||
(
f
)|||
]
(.)
= E
[|||d
(
f
)|||
]
+ E
[|||n
(
f
)|||
]
= Jd
[𝐡( f )] + Jn
[𝐡( f )]
= 𝜙X( f ) + 𝐡H( f )𝚽𝐲( f )𝐡( f ) −𝜙X( f )𝐡H( f )𝐝(f , cos 𝜃d
)
−𝜙X( f )𝐝H (
f , cos 𝜃d
)
𝐡( f ),
where
Jd
[𝐡( f )] = 𝜙X( f ) |||𝐡H( f )𝐝(f , cos 𝜃d
) −|||

(.)
= 𝜙X( f )𝜐d
[
𝐡( f )
]
www.ebook3000.com

Adaptive Beamforming
287
and
Jn
[
𝐡( f )
]
= 𝐡H( f )𝚽𝐯( f )𝐡( f )
(.)
=
𝜙V( f )
𝜉n
[
𝐡( f )
].
We have the following classical relationships:
Jd
[𝐡( f )]
Jn
[𝐡( f )] = iSNR( f ) × 𝜉n
[𝐡( f )] × 𝜐d
[𝐡( f )]
(.)
= oSNR
[
𝐡( f )
]
× 𝜉d
[
𝐡( f )
]
× 𝜐d
[
𝐡( f )
]
.
8.3
Adaptive Beamformers
In this section, we show how to design diﬀerent kinds of adaptive beamformers. For
each one of them, we give several equivalent formulations, depending on what (second-
order) statistics we want or need to estimate.
8.3.1
Wiener
The Wiener beamformer is found by minimizing J [𝐡( f )], the narrowband MSE from
(.). We can easily obtain
𝐡W
(f , cos 𝜃d
) = 𝜙X( f )𝚽−
𝐲( f )𝐝(f , cos 𝜃d
) .
(.)
In this ﬁlter, we need to estimate 𝜙X( f ) and 𝚽𝐲( f ). The latter quantity is easy to estimate
from the observations, but the former is not. Let
𝚪𝐲( f ) =
𝚽𝐲( f )
𝜙Y( f )
(.)
be the pseudo-coherence matrix of the observations, where 𝜙Y( f ) is the variance of
Y( f ). We can rewrite (.) as
𝐡W
(
f , cos 𝜃d
)
=
iSNR( f )
+ iSNR( f )𝚪−
𝐲( f )𝐝
(
f , cos 𝜃d
)
(.)
= HW( f )𝚪−
𝐲( f )𝐝(f , cos 𝜃d
) ,
where
HW( f ) =
iSNR( f )
+ iSNR( f )
(.)
is the single-channel Wiener gain (see Chapter ). Now, instead of estimating 𝜙X( f )
as in (.), we need to estimate the narrowband input SNR, iSNR( f ) or, equivalently,
HW( f ).

288
Fundamentals of Signal Enhancement and Array Signal Processing
The Wiener ﬁlter can also be expressed as a function of the statistics of the observation
and noise signals:
𝐡W
(
f , cos 𝜃d
)
=
[
𝐈M −𝚽−
𝐲( f )𝚽𝐯( f )
]
𝐢i,
(.)
where 𝐢i is the ﬁrst column of 𝐈M.
Determining the inverse of 𝚽𝐲( f ) from (.) with the Woodbury identity, we get
𝚽−
𝐲( f ) = 𝚽−
𝐯( f ) −
𝚽−
𝐯( f )𝐝
(
f , cos 𝜃d
)
𝐝H (
f , cos 𝜃d
)
𝚽−
𝐯( f )
𝜙−
X ( f ) + 𝐝H (
f , cos 𝜃d
)
𝚽−
𝐯( f )𝐝
(
f , cos 𝜃d
).
(.)
Substituting (.) into (.) gives
𝐡W
(
f , cos 𝜃d
)
=
𝜙X( f )𝚽−
𝐯( f )𝐝(f , cos 𝜃d
)
+ 𝜙X( f )𝐝H (f , cos 𝜃d
) 𝚽−
𝐯( f )𝐝(f , cos 𝜃d
)
=
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
−M + tr [𝚽−
𝐯( f )𝚽𝐲( f )]𝐢i.
(.)
In the second equation of (.), 𝐡W
(
f , cos 𝜃d
)
depends on the statistics of the observa-
tion and noise signals and the matrix 𝚽𝐯( f ) is inverted, while in the formulaton given
in (.), 𝐡W
(f , cos 𝜃d
) depends on the same statistics but the matrix 𝚽𝐲( f ) is inverted.
We already know from the previous chapters that the Wiener beamformer maximizes
the narrowband array gain but does not necessarily maximize the broadband array gain,
but it deﬁnitely makes the latter greater than . Distortion is obviously expected and is
increased when the input SNR is decreased. However, if we increase the number of
sensors, we decrease distortion.
Example ..
Consider a ULA of M sensors, as shown in Figure .. Suppose that
a desired signal impinges on the ULA from the direction 𝜃d, and that two statistically
independent interferences impinge on the ULA from directions 𝜃and 𝜃. Assume that
the desired signal is a harmonic pulse of T samples:
x(t) =
{
A sin (𝜋ft + 𝜙) ,
≤t ≤T −
,
t < , t ≥T
,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly distributed
on the interval from to 𝜋. Assume that the interferences u(t) and u(t) are IID white
Gaussian noise, u(t), u(t) ∼(, 𝜎
u
), uncorrelated with x(t). In addition, the sensors
contain thermal white Gaussian noise, wm(t) ∼(, 𝜎
w
), the signals of which are
mutually uncorrelated. The noisy received signals are given by ym(t) = xm(t) + vm(t),
m = , … , M, where vm(t) = um(t) + wm(t), m = , … , M are the interference-plus-
noise signals.
www.ebook3000.com

Adaptive Beamforming
289
−5
0
5
10
15
−5
0
5
10
15
20
25
30
35
40
(a)
(b)
(c)
(d)
20
25
30
35
40
0
0.01
0.02
0.03
0.04
0.05
−50
−45
−40
−35
−30
−25
iSNR (dB)
iSNR (dB)
−5
0
5
10
15
−5
0
5
10
15
iSNR (dB)
iSNR (dB)
ξn (hW) (dB)
ξd (hW) (dB)
(hW) (dB)
d (hW) (dB)
Figure 8.1 (a) The broadband gain in SNR, (b) the broadband noise reduction factor, (c) the
broadband desired signal reduction factor, and (d) the broadband desired signal distortion index of
the Wiener beamformer as a function of the broadband input SNR, for different numbers of sensors,
M: M = 10 (solid line with circles), M = 20 (dashed line with asterisks), M = 30 (dotted line with
squares), and M = 40 (dash-dot line with triangles).
Following Example .., we choose a sampling interval Ts that satisﬁes Ts = 𝛿∕c.
The variance of X( f ) is given by
𝜙X( f ) = A
D
T
[𝜋(f + f
)] + A
D
T
[𝜋(f −f
)] ,
where
DT(x) = sin (Tx)
sin (x) .
The correlation matrices of 𝐱( f ) and 𝐯( f ) are given by
𝚽𝐱( f ) = 𝜙X( f )𝐝
(
f , cos 𝜃d
)
𝐝H (
f , cos 𝜃d
)
,
𝚽𝐯( f ) = T𝜎
u𝐝
(
f , cos 𝜃
)
𝐝H (
f , cos 𝜃
)
+ T𝜎
u𝐝(f , cos 𝜃
) 𝐝H (f , cos 𝜃
) + T𝜎
w𝐈M.

290
Fundamentals of Signal Enhancement and Array Signal Processing
The narrowband and broadband input SNRs are, respectively,
iSNR( f ) = 𝜙X( f )
𝜙V( f )
=
A
T
(
𝜎
u + 𝜎
w
)D
T
[𝜋(f + f
)]
+
A
T
(
𝜎
u + 𝜎
w
)D
T
[𝜋(f −f
)]
and
iSNR =
∫f 𝜙X( f )df
∫f 𝜙V( f )df
=
∑
t E
[
||x(t)||
]
∑
t E
[
||v(t)||
]
=
A
(𝜎
u + 𝜎
w
),
where we have used Parseval’s identity. The Wiener beamformer, 𝐡W
(f , cos 𝜃d
), is
obtained from (.).
To demonstrate the performance of the Wiener beamformer, we choose A = .,
f= .c∕𝛿, T = , 𝜃d = ◦, 𝜃= ◦, 𝜃= ◦, and 𝜎
w = .𝜎
u. Figure .shows
plots of the broadband gain in SNR, (𝐡W
), the broadband noise reduction factor,
𝜉n
(𝐡W
), the broadband desired signal reduction factor, 𝜉d
(𝐡W
), and the broadband
desired signal distortion index, 𝜐d
(𝐡W
), as a function of the broadband input SNR,
for diﬀerent numbers of sensors, M. For a given broadband input SNR, as the number
of sensors increases, the broadband gain in SNR and the broadband noise reduction
factor increase, while the broadband desired signal reduction factor and the broadband
desired signal distortion index decrease.
Figure .shows beampatterns, |||
[
𝐡W
(
f , cos 𝜃d
)
, cos 𝜃
]|||, for f = fand diﬀerent
numbers of sensors, M. The main beam is in the direction of the desired signal, 𝜃d, and
there are nulls in the directions of the interferences, 𝜃and 𝜃. As the number of sensors
increases, the width of the main beam decreases, and the nulls in the directions of the
interferences become deeper.
■
8.3.2
MVDR
The MVDR beamformer proposed by Capon [, ] is obtained by minimizing the
narrowband MSE of the residual noise, Jr
[𝐡( f )], subject to the distortionless constraint:
min
𝐡( f ) 𝐡H( f )𝚽𝐯( f )𝐡( f ) subject to 𝐡H( f )𝐝(f , cos 𝜃d
) = .
(.)
www.ebook3000.com

Adaptive Beamforming
291
0
30
50
70
90
120
150
180
−100
−80
−60
−40
−20
0
20
(a)
(b)
(c)
(d)
0
30
50
70
90
120
150
180
−100
−80
−60
−40
−20
0
20
−100
−80
−60
−40
−20
0
20
−100
−80
−60
−40
−20
0
20
0
30
50
70
90
120
150
180
0
30
50
70
90
120
150
180
[hW ( f , cos θd), cos θ]∣ (dB)
∣
[hW ( f , cos θd), cos θ]∣ (dB)
∣
[hW (f, cos θd), cos θ]∣ (dB)
∣
[hW (f, cos θd), cos θ]∣ (dB)
∣
θ (deg)
θ (deg)
θ (deg)
θ (deg)
Figure 8.2 Beampatterns of the Wiener beamformer for f = f0 and different numbers of sensors, M:
(a) M = 10, (b) M = 20, (c) M = 30, and (d) M = 40.
The solution to this optimization problem is
𝐡MVDR
(
f , cos 𝜃d
)
=
𝚽−
𝐯( f )𝐝(f , cos 𝜃d
)
𝐝H (f , cos 𝜃d
) 𝚽−
𝐯( f )𝐝(f , cos 𝜃d
),
(.)
which depends on the statistics of the noise only.
Using the Woodbury identity again, it is easy to show that the MVDR beamformer is
also
𝐡MVDR
(f , cos 𝜃d
) =
𝚽−
𝐲( f )𝐝
(
f , cos 𝜃d
)
𝐝H (f , cos 𝜃d
) 𝚽−
𝐲( f )𝐝(f , cos 𝜃d
)
(.)
=
𝚪−
𝐲( f )𝐝
(
f , cos 𝜃d
)
𝐝H (f , cos 𝜃d
) 𝚪−
𝐲( f )𝐝(f , cos 𝜃d
).
This formulation is important and practical, since it depends on the statistics of the
observations only, and these are easy to estimate in practice.

292
Fundamentals of Signal Enhancement and Array Signal Processing
It is clear that the MVDR beamformer maximizes the narrowband array gain.
However, for the broadband array gain, we always have
≤(𝐡MVDR
) ≤(𝐡W
) .
(.)
From a theoretical point of view, it is also clear that we have
𝜐d
[
𝐡MVDR
(
f , cos 𝜃d
)]
= ,
(.)
𝜐d
(𝐡MVDR
) = .
(.)
However, in practice, this is not true in general because of reverberation, which is not
taken into account in our model.
Example ..
Returning to Example .., we now employ the MVDR beamformer,
𝐡MVDR
(f , cos 𝜃d
), given in (.). Figure .shows plots of the broadband gain in SNR,
−5
0
5
10
15
16
18
20
22
24
26
(a)
(b)
(c)
(d)
−5
0
5
10
15
16
18
20
22
24
26
−5
0
5
10
15
−1
−0.5
0
0.5
1
−5
0
5
10
15
−25
−20
−15
−10
−5
0
5
10
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
ξn (hMVDR) (dB)
ξd (hMVDR) (dB)
J (hMVDR) (dB)
(hMVDR) (dB)
Figure 8.3 (a) The broadband gain in SNR, (b) the broadband noise reduction factor, (c) the
broadband desired signal reduction factor, and (d) the broadband MSE of the MVDR beamformer as a
function of the broadband input SNR, for different numbers of sensors, M: M = 10 (solid line with
circles), M = 20 (dashed line with asterisks), M = 30 (dotted line with squares), and M = 40 (dash-dot
line with triangles).
www.ebook3000.com

Adaptive Beamforming
293
0
30
50
70
90
120
150
180
−100
−80
−60
−40
−20
0
20
(a)
(b)
(c)
(d)
0
30
50
70
90
120
150
180
−100
−80
−60
−40
−20
0
20
−100
−80
−60
−40
−20
0
20
−100
−80
−60
−40
−20
0
20
0
30
50
70
90
120
150
180
0
30
50
70
90
120
150
180
θ (deg)
θ (deg)
θ (deg)
θ (deg)
[hMVDR ( f,cos θd), cos θ]∣ (dB)
∣
[hMVDR ( f,cos θd), cos θ]∣ (dB)
∣
[hMVDR ( f,cos θd), cos θ]∣ (dB)
∣
[hMVDR ( f,cos θd), cos θ]∣ (dB)
∣
Figure 8.4 Beampatterns of the MVDR beamformer for f = f0 and different numbers of sensors, M:
(a) M = 10, (b) M = 20, (c) M = 30, and (d) M = 40.
(𝐡MVDR
), the broadband noise reduction factor, 𝜉n
(𝐡MVDR
), the broadband desired
signal reduction factor, 𝜉d
(𝐡MVDR
), and the broadband MSE, J (𝐡MVDR
), as a function of
the broadband input SNR, for diﬀerent numbers of sensors, M. For a given broadband
input SNR, as the number of sensors increases, the broadband gain in SNR and the
broadband noise reduction factor increase, while the broadband MSE decreases.
Figure .shows beampatterns, |||
[
𝐡MVDR
(
f , cos 𝜃d
)
, cos 𝜃
]|||, for f = fand diﬀerent
numbers of sensors, M. The main beam is in the direction of the desired signal, 𝜃d,
and there are nulls in the directions of the interferences, 𝜃and 𝜃. In particular,
|||[𝐡MVDR
(f , cos 𝜃d
) , cos 𝜃]||| is for 𝜃= 𝜃d. As the number of sensors increases, the
width of the main beam decreases, and the nulls in the directions of the interferences
become deeper.
■
8.3.3
Tradeoff
In order to make a better compromise between noise reduction and desired signal
distortion, we can minimize the narrowband desired signal distortion index with the

294
Fundamentals of Signal Enhancement and Array Signal Processing
constraint that the narrowband noise reduction factor is equal to a positive value that
is greater than :
min
𝐡( f ) Jd
[
𝐡( f )
]
subject to Jn
[
𝐡( f )
]
= ℵ𝜙V( f ),
(.)
where < ℵ< to ensure that we get some noise reduction. By using a Lagrange
multiplier, 𝜇> , to adjoin the constraint to the cost function, we get the tradeoﬀ
beamformer:
𝐡T,𝜇
(
f , cos 𝜃d
)
= 𝜙X( f )
[
𝚽𝐱( f ) + 𝜇𝚽𝐯( f )
]−𝐝
(
f , cos 𝜃d
)
(.)
=
𝜙X( f )𝚽−
𝐯( f )𝐝(f , cos 𝜃d
)
𝜇+ 𝜙X( f )𝐝H (f , cos 𝜃d
) 𝚽−
𝐯( f )𝐝(f , cos 𝜃d
)
=
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
𝜇−M + tr [𝚽−
𝐯( f )𝚽𝐲( f )]𝐢i.
We can see that for
●𝜇= , 𝐡T,
(f , cos 𝜃d
) = 𝐡W
(f , cos 𝜃d
), which is the Wiener beamformer
●𝜇= , 𝐡T,
(
f , cos 𝜃d
)
= 𝐡MVDR
(
f , cos 𝜃d
)
, which is the MVDR beamformer
●𝜇> , the result is a beamformer with low residual noise at the expense of high desired
signal distortion (as compared to Wiener)
●𝜇< , the result is a beamformer with high residual noise and low desired signal
distortion (as compared to Wiener).
A more useful way to express the tradeoﬀbeamformer is
𝐡T,𝜇
(
f , cos 𝜃d
)
=
[
(−𝜇)𝐝
(
f , cos 𝜃d
)
𝐝H (
f , cos 𝜃d
)
+ 𝜇+ iSNR( f )
iSNR( f )
𝚪𝐲( f )
]−
× 𝐝(f , cos 𝜃d
) ,
(.)
or, equivalently, with the help of the Woodbury identity:
𝐡T,𝜇
(f , cos 𝜃d
) =
iSNR( f )
+ iSNR( f )
×
𝚪−
𝐲( f )𝐝(f , cos 𝜃d
)
𝜇+ (−𝜇)
iSNR( f )
+ iSNR( f )𝐝H (f , cos 𝜃d
) 𝚪−
𝐲( f )𝐝(f , cos 𝜃d
).
(.)
The previous expression depends only on the estimation of the statistics of the obser-
vations as well as the estimation of the narrowband input SNR. We can simplify (.)
by writing it as a function of HW( f ):
𝐡T,𝜇
(f , cos 𝜃d
) =
HW( f )𝚪−
𝐲( f )𝐝(f , cos 𝜃d
)
𝜇+ (−𝜇)HW( f )𝐝H (f , cos 𝜃d
) 𝚪−
𝐲( f )𝐝(f , cos 𝜃d
).
(.)
www.ebook3000.com

Adaptive Beamforming
295
Obviously, the tradeoﬀbeamformer also maximizes the narrowband array gain,
∀𝜇≥. However, for the broadband array gain, we always have for 𝜇≥,
≤(𝐡MVDR
) ≤(𝐡W
) ≤(𝐡T,𝜇
) ,
(.)
and for ≤𝜇≤,
≤(𝐡MVDR
) ≤(𝐡T,𝜇
) ≤(𝐡W
) .
(.)
Distortion of the desired signal, on the other hand, depends quite a lot on the values
of 𝜇. However, the closer the value of 𝜇is to , the less distorted the desired signal.
Example ..
Returning to Example .., we now employ the tradeoﬀbeamformer,
𝐡T,𝜇
(
f , cos 𝜃d
)
, given in (.). Figure .shows plots of the broadband gain in SNR,

(
𝐡T,𝜇
)
, the broadband noise reduction factor, 𝜉n
(
𝐡T,𝜇
)
, the broadband desired signal
−5
0
5
10
15
25
30
35
40
45
(a)
(b)
(c)
(d)
25
30
35
40
45
−5
0
5
10
15
0
0.005
0.01
0.015
0.02
−5
0
5
10
15
−55
−50
−45
−40
−35
−30
−25
iSNR (dB)
−5
0
5
10
15
iSNR (dB)
iSNR (dB)
iSNR (dB)
(hT,µ) (dB)
ξd (hT,µ) (dB)
υd (hT,µ) (dB)
ξn (hT,µ) (dB)
Figure 8.5 (a) The broadband gain in SNR, (b) the broadband noise reduction factor, (c) the
broadband desired signal reduction factor, and (d) the broadband desired signal distortion index of
the tradeoff beamformer as a function of the broadband input SNR, for M = 30 and several values of
𝜇: 𝜇= 0.5 (solid line with circles), 𝜇= 1 (dashed line with asterisks), 𝜇= 2 (dotted line with squares),
and 𝜇= 5 (dash-dot line with triangles).

296
Fundamentals of Signal Enhancement and Array Signal Processing
0
30
50
70
90
120
150
180
−80
−70
−60
−50
−40
−30
−20
−10
0
10
(a)
(b)
(c)
(d)
0
30
50
70
90
120
150
180
−80
−70
−60
−50
−40
−30
−20
−10
0
10
−80
−70
−60
−50
−40
−30
−20
−10
0
10
−80
−70
−60
−50
−40
−30
−20
−10
0
10
θ (deg)
θ (deg)
0
30
50
70
90
120
150
180
θ (deg)
0
30
50
70
90
120
150
180
θ (deg)
∣[hT,µ ( f, cos θd), cos θ]∣ (dB)
∣[hT,µ ( f, cos θd), cos θ]∣ (dB)
∣[hT,µ ( f, cos θd), cos θ]∣ (dB)
∣[hT,µ ( f, cos θd), cos θ]∣ (dB)
Figure 8.6 Beampatterns of the tradeoff beamformer for f = f0, M = 30 and several values of 𝜇:
(a) 𝜇= 0.5, (b) 𝜇= 1, (c) 𝜇= 2, and (d) 𝜇= 5.
reduction factor, 𝜉d
(𝐡T,𝜇
), and the broadband desired signal distortion index, 𝜐d
(𝐡T,𝜇
),
as a function of the broadband input SNR, for M = and several values of 𝜇. For a given
broadband input SNR, the higher the value of 𝜇, the higher are the broadband gain in
SNR and the broadband noise reduction factor, but at the expense of a higher broadband
desired signal reduction factor and a higher broadband desired signal distortion index.
Figure .shows beampatterns, |||
[
𝐡T,𝜇
(
f , cos 𝜃d
)
, cos 𝜃
]|||, for f = f, M = and
several values of 𝜇. The main beam is in the direction of the desired signal, 𝜃d, and there
are nulls in the directions of the interferences, 𝜃and 𝜃.
■
8.3.4
Maximum Array Gain
We can express the narrowband array gain as

[
𝐡( f )
]
=
𝜙V( f )𝐡H( f )𝐝(f , cos 𝜃d
) 𝐝H (f , cos 𝜃d
) 𝐡( f )
𝐡H( f )𝚽𝐯( f )𝐡( f )
.
(.)
The maximum array gain beamformer, 𝐡max
(
f , cos 𝜃d
)
, is obtained by maximizing the
array gain as given above. In (.), we recognize the generalized Rayleigh quotient [].
www.ebook3000.com

Adaptive Beamforming
297
It is well known that this quotient is maximized with the maximum eigenvector of
the matrix 𝜙V( f )𝚽−
𝐯( f )𝐝(f , cos 𝜃d
) 𝐝H (f , cos 𝜃d
). Let us denote by 𝜆max
(f , cos 𝜃d
) the
maximum eigenvalue corresponding to this maximum eigenvector. Since the rank of
the matrix mentioned is equal to , we have
𝜆max
(f , cos 𝜃d
) = tr [𝜙V( f )𝚽−
𝐯( f )𝐝(f , cos 𝜃d
) 𝐝H (f , cos 𝜃d
)]
(.)
= 𝜙V( f )𝐝H (f , cos 𝜃d
) 𝚽−
𝐯( f )𝐝(f , cos 𝜃d
) .
As a result,
[𝐡max
(f , cos 𝜃d
)] = 𝜆max
(f , cos 𝜃d
)
(.)
= max
(f , cos 𝜃d
) ,
which corresponds to the maximum possible narrowband array gain.
Obviously, we also have
𝐡max
(f , cos 𝜃d
) = 𝜍( f )𝚪−
𝐲( f )𝐝(f , cos 𝜃d
) ,
(.)
where 𝜍( f ) ≠is an arbitrary frequency-dependent complex number. We can observe
that all beamformers derived so far are equivalent up to a scaling factor.
8.3.5
LCMV
Assume that we have N interferences, with N < M, impinging on the array from the
directions 𝜃≠𝜃≠⋯≠𝜃N ≠𝜃d. We would like to place nulls in the directions 𝜃n, n =
, , … , N, with a beamformer 𝐡( f ), and, meanwhile, recover the desired source coming
from the direction 𝜃d. Combining all these constraints together, we get the constraint
equation:
𝐂H (f , 𝜃d, 𝜃∶N
) 𝐡( f ) = 𝐢c,
(.)
where
𝐂
(
f , 𝜃d, 𝜃∶N
)
=
[
𝐝
(
f , 𝜃d
)
𝐝
(
f , 𝜃
)
⋯
𝐝
(
f , 𝜃N
) ]
(.)
is the constraint matrix of size M × (N + ) the N + columns of which are linearly
independent and
𝐢c = [ 

⋯
]T
(.)
is a vector of length N + .
The most convenient way to solve this problem is by minimizing the narrowband MSE
of the residual noise, Jr
[𝐡( f )], subject to (.):
min
𝐡( f ) 𝐡H( f )𝚽𝐯( f )𝐡( f ) subject to 𝐂H (f , 𝜃d, 𝜃∶N
) 𝐡( f ) = 𝐢c.
(.)

298
Fundamentals of Signal Enhancement and Array Signal Processing
The solution to this optimization problem gives the well-known LCMV beamformer
[, ]:
𝐡LCMV
(f , cos 𝜃d
) = 𝚽−
𝐯( f )𝐂(f , 𝜃d, 𝜃∶N
)
× [𝐂H (f , 𝜃d, 𝜃∶N
) 𝚽−
𝐯( f )𝐂(f , 𝜃d, 𝜃∶N
)]−𝐢c,
(.)
which depends on the statistics of the noise only.
It can be shown that a more useful formulation of the LCMV beamformer is
𝐡LCMV
(
f , cos 𝜃d
)
= 𝚪−
𝐲( f )𝐂
(
f , 𝜃d, 𝜃∶N
)
×
[
𝐂H (
f , 𝜃d, 𝜃∶N
)
𝚪−
𝐲( f )𝐂
(
f , 𝜃d, 𝜃∶N
)]−
𝐢c.
(.)
The last expression depends on the statistics of the observations only, and these should
be easy to estimate.
Example ..
Returning to Example .., we now employ the LCMV beamformer,
𝐡LCMV
(f , cos 𝜃d
), given in (.). Figure .shows plots of the broadband gain in SNR,
−5
0
5
10
15
−50
−45
−40
−35
−30
−25
−20
−15
−10
(a)
(b)
(c)
(d)
−5
0
5
10
15
−50
−45
−40
−35
−30
−25
−20
−15
−10
−5
0
5
10
15
−1
−0.5
0
0.5
1
−5
0
5
10
15
10
20
30
40
50
60
70
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(hLCMV) (dB)
ξd (hLCMV) (dB)
ξn (hLCMV) (dB)
J (hLCMV) (dB)
Figure 8.7 (a) The broadband gain in SNR, (b) the broadband noise reduction factor, (c) the
broadband desired signal reduction factor, and (d) the broadband MSE of the LCMV beamformer as a
function of the broadband input SNR, for different numbers of sensors, M: M = 10 (solid line with
circles), M = 20 (dashed line with asterisks), M = 30 (dotted line with squares), and M = 40 (dash-dot
line with triangles).
www.ebook3000.com

Adaptive Beamforming
299
0
30
50
70
90
120
150
180
−100
−80
−60
−40
−20
0
20
(a)
(b)
(c)
(d)
0
30
50
70
90
120
150
180
−100
−80
−60
−40
−20
0
20
−100
−80
−60
−40
−20
0
20
−100
−80
−60
−40
−20
0
20
θ (deg)
θ (deg)
0
30
50
70
90
120
150
180
0
30
50
70
90
120
150
180
θ (deg)
θ (deg)
[hLCMV ( f,cos θd), cos θ]∣ (dB)
∣
[hLCMV ( f,cos θd), cos θ]∣ (dB)
∣
[hLCMV ( f,cos θd), cos θ]∣ (dB)
∣
[hLCMV ( f,cos θd), cos θ]∣ (dB)
∣
Figure 8.8 Beampatterns of the LCMV beamformer for f = f0 and different numbers of sensors, M: (a)
M = 10, (b) M = 20, (c) M = 30, and (d) M = 40.
(𝐡LCMV
), the broadband noise reduction factor, 𝜉n
(𝐡LCMV
), the broadband desired
signal reduction factor, 𝜉d
(
𝐡LCMV
)
, and the broadband MSE, J
(
𝐡LCMV
)
, as a function of
the broadband input SNR, for diﬀerent numbers of sensors, M. For a given broadband
input SNR, as the number of sensors increases, the broadband gain in SNR and the
broadband noise reduction factor increase, while the broadband MSE decreases.
Figure .shows beampatterns, |||[𝐡LCMV
(f , cos 𝜃d
) , cos 𝜃]|||, for f = fand diﬀerent
numbers of sensors, M. The main beam is in the direction of the desired signal, 𝜃d,
and there are nulls in the directions of the interferences, 𝜃and 𝜃. In particular,
|||[𝐡LCMV
(f , cos 𝜃d
) , cos 𝜃]||| is for 𝜃= 𝜃d, and is identically zero for 𝜃= 𝜃and 𝜃= 𝜃.
As the number of sensors increases, the width of the main beam decreases.
■
In Table ., we summarize all the optimal adaptive beamformers described in this
section.
8.4
SNR Estimation
From Table ., we can see that all the beamformers depend on the statistics of the
observations, 𝚪𝐲( f ), while some of them depend also on the narrowband input SNR,
iSNR( f ), or, equivalently, on HW( f ). In practice, while it is easy to get an estimate for

300
Fundamentals of Signal Enhancement and Array Signal Processing
Table 8.1 Adaptive beamformers.
Beamformer
Wiener
𝐡W
(f , cos 𝜃d
) = HW( f )𝚪−
𝐲( f )𝐝(f , cos 𝜃d
)
MVDR
𝐡MVDR
(f , cos 𝜃d
) =
𝚪−
𝐲( f )𝐝(f , cos 𝜃d
)
𝐝H (f , cos 𝜃d
) 𝚪−
𝐲( f )𝐝(f , cos 𝜃d
)
Tradeoﬀ
𝐡T,𝜇
(f , cos 𝜃d
) =
HW( f )𝚪−
𝐲( f )𝐝(f , cos 𝜃d
)
𝜇+ (−𝜇)HW( f )𝐝H (f , cos 𝜃d
) 𝚪−
𝐲( f )𝐝(f , cos 𝜃d
)
Maximum
array gain
𝐡max
(f , cos 𝜃d
) = 𝜍( f )𝚪−
𝐲( f )𝐝(f , cos 𝜃d
) , 𝜍( f ) ≠
LCMV
𝐡LCMV
(f , cos 𝜃d
) = 𝚪−
𝐲( f )𝐂(f , 𝜃d, 𝜃∶N
)
×
[
𝐂H (f , 𝜃d, 𝜃∶N
) 𝚪−
𝐲( f )𝐂(f , 𝜃d, 𝜃∶N
)]−
𝐢c
𝚪𝐲( f ), it is not for iSNR( f ). In this section, we show one possible way to estimate this
SNR. In fact, it is much more straightforward to estimate HW( f ) as explained below.
We can express the pseudo-coherence matrix of the observations as
𝚪𝐲( f ) =
iSNR( f )
+ iSNR( f )𝐝(f , cos 𝜃d
) 𝐝H (f , cos 𝜃d
) +

+ iSNR( f )𝚪𝐯( f )
(.)
= HW( f )𝐝
(
f , cos 𝜃d
)
𝐝H (
f , cos 𝜃d
)
+
[
−HW( f )
]
𝚪𝐯( f ),
where
𝚪𝐯( f ) = 𝚽𝐯( f )
𝜙V( f ).
(.)
Let us assume that we are in the presence of the spherically isotropic noise. In this case,
𝚪𝐯( f ) coincides with 𝚪,𝜋( f ), which is deﬁned in Chapter . Since 𝐲( f ) is observable, it
is easy to estimate 𝚪𝐲( f ). We denote this estimate by ̂𝚪𝐲( f ). By following the approaches
developed in [–], we can write the components of the matrix ̂𝚪𝐲( f ) as
ℜ
{[
̂𝚪𝐲( f )
]
ij
}
= ̂HW( f )ℜ
[
Di
(f , cos 𝜃d
) D∗
j
(f , cos 𝜃d
)]
+
[
−̂HW( f )
] [𝚪,𝜋( f )]
ij ,
(.)
ℑ
{[
̂𝚪𝐲( f )
]
ij
}
= ̂HW( f )ℑ
[
Di
(
f , cos 𝜃d
)
D∗
j
(
f , cos 𝜃d
)]
,
(.)
www.ebook3000.com

Adaptive Beamforming
301
for i ≠j, i, j = , , … , M, where ℜ[⋅] and ℑ[⋅] are the real part and imaginary part
operators, respectively, ̂HW( f ) is the estimate of HW( f ), and Dm
(
f , cos 𝜃d
)
is the mth
element of 𝐝(f , cos 𝜃d
). We deduce from the previous expressions that
̂HW( f ) =
ℜ
{[
̂𝚪𝐲( f )
]
ij
}
−
[
𝚪,𝜋( f )
]
ij
ℜ
[
Di
(f , cos 𝜃d
) D∗
j
(f , cos 𝜃d
)]
−[𝚪,𝜋( f )]
ij
, i ≠j,
(.)
̂HW( f ) =
ℑ
{[
̂𝚪𝐲( f )
]
ij
}
ℑ
[
Di
(f , cos 𝜃d
) D∗
j
(f , cos 𝜃d
)], i ≠j.
(.)
To get a much more reliable estimate, it is better to average (.) and (.) over all
possible sensor combinations [–], resulting in the estimator:
̂HW( f )
=

M(M −)
M−
∑
i=
M
∑
j=i+
ℜ
{[
̂𝚪𝐲( f )
]
ij
}
−[𝚪,𝜋( f )]
ij
ℜ
[
Di
(f , cos 𝜃d
) D∗
j
(f , cos 𝜃d
)]
−[𝚪,𝜋( f )]
ij
+

M(M −)
M−
∑
i=
M
∑
j=i+
ℑ
{[
̂𝚪𝐲( f )
]
ij
}
ℑ
[
Di
(f , cos 𝜃d
) D∗
j
(f , cos 𝜃d
)].
(.)
Obviously, in practice, it is much better to estimate HW( f ) than iSNR( f ) since the
former is bounded (≤HW( f ) ≤) while the latter is not. If the estimate of the Wiener
gain is greater than , then we should force it to , and if it is negative, we should put it
to .
It is possible to estimate the single-channel Wiener gain directly from (.), in a
much simpler way, by pre- and post-multiplying both sides of (.) by 𝐝H (f , cos 𝜃d
)
and 𝐝
(
f , cos 𝜃d
)
, respectively, and by replacing 𝚪𝐲( f ) and 𝚪𝐯( f ) with ̂𝚪𝐲( f ) and 𝚪,𝜋( f ),
respectively. We easily obtain
̂HW( f ) =
𝐝H (
f , cos 𝜃d
) [
̂𝚪𝐲( f ) −𝚪,𝜋( f )
]
𝐝
(
f , cos 𝜃d
)
M−𝐝H (
f , cos 𝜃d
)
𝚪,𝜋( f )𝐝
(
f , cos 𝜃d
)
.
(.)

302
Fundamentals of Signal Enhancement and Array Signal Processing
Example ..
Consider a ULA of M sensors, as shown in Figure .. Suppose that
a desired signal impinges on the ULA from the direction 𝜃d = ◦. Assume that the
desired signal is a harmonic pulse of T samples:
x(t) =
{
A sin (𝜋ft + 𝜙) ,
≤t ≤T −
,
t < , t ≥T
,
with ﬁxed amplitude A and frequency f, and random phase 𝜙, uniformly distributed
on the interval from to 𝜋. Assume that the interference um(t) is a diﬀuse noise
uncorrelated with x(t). In addition, the sensors contain thermal white Gaussian noise,
wm(t) ∼(, 𝜎
w
), the signals of which are mutually uncorrelated. The noisy received
signals are given by ym(t) = xm(t) + vm(t), m = , … , M, where vm(t) = um(t) +
wm(t), m = , … , M are the interference-plus-noise signals.
The pseudo-coherence matrix of the noise can be written as
𝚪𝐯( f ) = (−𝛼) 𝚪,𝜋( f ) + 𝛼𝐈M,
(.)
where 𝛼(≤𝛼≤) is related to the ratio between the powers of the thermal and
diﬀuse noises. Figures .and .show plots of the estimators ̂HW( f ), given by (.)
and (.), respectively, as a function of the narrowband input SNR for several values
of 𝛼and diﬀerent numbers of sensors, M. The theoretical plot is indicated by thick solid
line, and the pseudo-coherence matrix of the observations 𝚪𝐲( f ) is obtained by
𝚪𝐲( f ) =
iSNR( f )
+ iSNR( f )𝐝(f , cos 𝜃d
) 𝐝H (f , cos 𝜃d
)
+
(−𝛼) 𝚪,𝜋( f ) + 𝛼𝐈M
+ iSNR( f )
.
(.)
As the number of sensors is larger and as the value of 𝛼is smaller, the estimators (.)
and (.) are closer to the theoretical values. Generally, the estimator (.) produces
better results than (.).
Now we set 𝛼to ., and estimate the pseudo-coherence matrix of the observations
using K random snapshots:
̂𝚽𝐲( f ) = 
K
K
∑
k=
𝐲k( f )𝐲H
k ( f ),
(.)
̂𝚪𝐲( f ) =
̂𝚽𝐲( f )
̂𝜙Y( f )
,
(.)
where 𝐲k( f ) is a random snapshot of 𝐲( f ). Figures .and .show plots of the esti-
mators ̂HW( f ), given by (.) and (.), respectively, as a function of the narrowband
input SNR for diﬀerent numbers of snapshots, K, and diﬀerent numbers of sensors,
M. The theoretical plot is indicated by thick solid line. As the number of sensors is
larger or as the number of snapshots is larger, the estimators (.) and (.) are closer
to the theoretical values. Generally, the estimator (.) produces better results than
(.).
■
www.ebook3000.com

Adaptive Beamforming
303
−20
−10
0
10
20
−20
−10
0
10
20
−50
−40
−30
−20
−10
0
(a)
(b)
(c)
(d)
−50
−40
−30
−20
−10
0
−50
−40
−30
−20
−10
0
−50
−40
−30
−20
−10
0
iSNR( f ) (dB)
−20
−10
0
10
20
iSNR( f ) (dB)
iSNR( f ) (dB)
iSNR( f ) (dB)
−20
−10
0
10
20
HW ( f ) (dB)
HW ( f ) (dB)
HW ( f ) (dB)
HW ( f ) (dB)
Figure 8.9 The estimator ̂HW( f), given by (8.61), as a function of the narrowband input SNR for several
values of 𝛼and different numbers of sensors, M: (a) 𝛼= 0.001, (b) 𝛼= 0.005, (c) 𝛼= 0.01, and (d)
𝛼= 0.02. Each figure shows the theoretical plot (thick solid line), and estimates for M = 2 (solid line
with circles), M = 5 (dashed line with asterisks), M = 10 (dotted line with squares), and M = 20
(dash-dot line with triangles).
8.5
DOA Estimation
In practice, the direction-of-arrival (DOA) of the desired signal, 𝜃d, may not always be
known. Therefore, it is of great interest to be able to estimate this angle. Obviously,
the literature on this subject is extremely rich [] and many diﬀerent approaches can
be derived, depending on several factors. In this section, we propose a method that
naturally ﬂows from the perspective developed throughout this text.
Let us assume that an estimate of the pseudo-coherence matrix of the observations,
𝚪𝐲( f ), is
̂𝚪𝐲( f ) =
̂𝚽𝐲( f )
̂𝜙Y( f )
(.)
=
iSNR( f )
+ iSNR( f )𝐝(f , cos 𝜃d
) 𝐝H (f , cos 𝜃d
) +

+ iSNR( f )𝚪,𝜋( f ),

304
Fundamentals of Signal Enhancement and Array Signal Processing
−20
−10
0
10
20
−20
−10
0
10
20
−50
−40
−30
−20
−10
0
(a)
(b)
(c)
(d)
−50
−40
−30
−20
−10
0
−50
−40
−30
−20
−10
0
−50
−40
−30
−20
−10
0
iSNR( f ) (dB)
−20
−10
0
10
20
iSNR( f ) (dB)
iSNR( f ) (dB)
iSNR( f ) (dB)
−20
−10
0
10
20
HW ( f ) (dB)
HW ( f ) (dB)
HW ( f ) (dB)
HW ( f ) (dB)
Figure 8.10 The estimator ̂HW( f), given by (8.62), as a function of the narrowband input SNR for
several values of 𝛼and different numbers of sensors, M: (a) 𝛼= 0.001, (b) 𝛼= 0.005, (c) 𝛼= 0.01, and
(d) 𝛼= 0.02. Each figure shows the theoretical plot (thick solid line), and estimates for M = 2 (solid line
with circles), M = 5 (dashed line with asterisks), M = 10 (dotted line with squares), and M = 20
(dash-dot line with triangles).
where ̂𝚽𝐲( f ) and ̂𝜙Y( f ) are estimates of 𝚽𝐲( f ) and 𝜙Y( f ), respectively. In (.), we
explicitly assume that 𝚪,𝜋( f ) is an estimate of 𝚪𝐯( f ).
The pseudo-coherence matrix corresponding to a source signal coming from the
direction 𝜃may be written as
𝚪𝐱
(f , cos 𝜃) = 𝐝(f , cos 𝜃) 𝐝H (f , cos 𝜃) ,
(.)
which is a rank-matrix.
Using the joint diagonalization technique [], the two matrices ̂𝚪𝐲( f ) and 𝚪,𝜋( f ) can
be decomposed as
𝐓H( f )̂𝚪𝐲( f )𝐓( f ) = 𝚲( f ),
(.)
𝐓H( f )𝚪,𝜋( f )𝐓( f ) = 𝐈M,
(.)
www.ebook3000.com

Adaptive Beamforming
305
−20
−10
0
10
20
−20
−10
0
10
20
−50
−40
−30
−20
−10
0
(a)
(b)
(c)
(d)
−50
−40
−30
−20
−10
0
−50
−40
−30
−20
−10
0
−50
−40
−30
−20
−10
0
iSNR( f ) (dB)
−20
−10
0
10
20
iSNR( f ) (dB)
iSNR( f ) (dB)
iSNR( f ) (dB)
−20
−10
0
10
20
HW ( f ) (dB)
HW ( f ) (dB)
HW ( f ) (dB)
HW ( f ) (dB)
Figure 8.11 The estimator ̂HW( f), given by (8.61), as a function of the narrowband input SNR for
different numbers of snapshots, K, and different numbers of sensors, M: (a) K = 103, (b) K = 104,
(c) K = 105, and (d) K = 106. Each figure shows the theoretical plot (thick solid line), and estimates for
M = 2 (solid line with circles), M = 5 (dashed line with asterisks), M = 10 (dotted line with squares),
and M = 20 (dash-dot line with triangles).
where
𝐓( f ) = [ 𝐭( f )
𝐭( f )
⋯
𝐭M( f ) ]
(.)
is a full-rank square matrix and
𝚲( f ) = diag [𝜆( f ), 𝜆( f ), … , 𝜆M( f )]
(.)
is a diagonal matrix with 𝜆( f ) ≥𝜆( f ) ≥⋯≥𝜆M( f ) > . For 𝜃= 𝜃d, we have
𝐓H( f )̂𝚪𝐲( f )𝐓( f ) =
iSNR( f )
+ iSNR( f )𝐓H( f )𝚪𝐱
(f , cos 𝜃d
) 𝐓( f )
+

+ iSNR( f )𝐈M,
(.)

306
Fundamentals of Signal Enhancement and Array Signal Processing
−20
−10
0
10
20
−20
−10
0
10
20
−50
−40
−30
−20
−10
0
(a)
(b)
(c)
−50
−40
−30
−20
−10
0
−50
−40
−30
−20
−10
0
iSNR( f ) (dB)
−20
−10
0
10
20
iSNR( f ) (dB)
iSNR( f ) (dB)
HW ( f ) (dB)
HW ( f ) (dB)
(d)
−50
−40
−30
−20
−10
0
−20
−10
0
10
20
iSNR( f ) (dB)
HW ( f ) (dB)
HW ( f ) (dB)
Figure 8.12 The estimator ̂HW( f), given by (8.62), as a function of the narrowband input SNR for
different numbers of snapshots, K, and different numbers of sensors, M: (a) K = 103, (b) K = 104,
(c) K = 105, and (d) K = 106. Each figure shows the theoretical plot (thick solid line), and estimates for
M = 2 (solid line with circles), M = 5 (dashed line with asterisks), M = 10 (dotted line with squares),
and M = 20 (dash-dot line with triangles).
where 𝐓H( f )𝚪𝐱
(f , cos 𝜃d
) 𝐓( f ) is a diagonal matrix whose ﬁrst diagonal element is
𝜆𝐱,( f ) =
[+ iSNR( f )] 𝜆( f ) −
iSNR( f )
> 
(.)
and the other diagonal elements are zero. However, for 𝜃
≠
𝜃d, the matrix
𝐓H( f )𝚪𝐱
(f , cos 𝜃) 𝐓( f ) is no longer diagonal but its rank is still equal to . Conse-
quently, we can take advantage of this property to estimate the DOA. Indeed, it is easy
to observe that
|||𝐭H
i ( f )𝐝
(
f , cos 𝜃d
)|||

= , i = , , … , M
(.)
but
|||𝐭H
i ( f )𝐝(f , cos 𝜃)|||

> , i = , , … , M, 𝜃≠𝜃d.
(.)
www.ebook3000.com

Adaptive Beamforming
307
As a result, the previous equations may be combined and used as a good criterion for
the estimation of 𝜃d:
̂𝜃d = arg min
𝜃
M
∑
i=
|||𝐭H
i ( f )𝐝(f , cos 𝜃)|||

.
(.)
The last expression corresponds to a narrowband estimation of the desired angle. A
more reliable estimator can be obtained by integrating the criterion over a range of
frequencies:
̂𝜃d = arg min
𝜃∫
f
f
M
∑
i=
|||𝐭H
i ( f )𝐝(f , cos 𝜃)|||

df ,
(.)
which corresponds to a broadband estimation of 𝜃d.
This approach is a generalization of the well-known MUSIC (multiple signal classiﬁ-
cation) algorithm [, ], which was originally developed for spatially white noise, to
the spherically isotropic noise ﬁeld. Obviously, this approach works for more than one
desired angle. But the number of desired angles must be smaller than M.
A byproduct of this method is that the input SNR can be easily estimated. From (.),
we deduce that
𝐭H
i ( f )̂𝚪𝐲( f )𝐭i( f ) =

+ iSNR( f ), i = , , … , M.
(.)
As a result, an estimate of the input SNR is
̂
iSNR( f ) =

M −
M
∑
i=

𝐭H
i ( f )̂𝚪𝐲( f )𝐭i( f )
−.
(.)
Example ..
Returning to Example .., we set the narrowband input SNR to
iSNR( f ) = −dB, compute the pseudo-coherence matrix of the observations, 𝚪𝐲( f ),
using (.), obtain 𝐓( f ) using (.) and (.), and calculate the following function:
R(f , 𝜃) =
M
∑
i=
|||𝐭H
i ( f )𝐝(f , cos 𝜃)|||

.
(.)
According to (.), the minimum of R(f , 𝜃) is obtained for 𝜃= ̂𝜃d. Figure .shows
plots of R(f , 𝜃) as a function of 𝜃for several values of 𝛼and diﬀerent numbers of sensors,
M. The value of 𝜃d is better estimated for smaller values of 𝛼and larger number of
sensors. As the value of 𝛼is smaller, ̂𝜃d can be obtained using a larger number of sensors
with a better accuracy than that obtained with fewer sensors.
Now we set 𝛼to −, and estimate the pseudo-coherence matrix of the observations
using (.) and (.) with K random snapshots. Figure .shows plots of R(f , 𝜃) as
a function of 𝜃for diﬀerent numbers of snapshots, K, and diﬀerent numbers of sensors,
M. For a small number of snapshots, a good estimate of 𝜃d requires a larger number of

308
Fundamentals of Signal Enhancement and Array Signal Processing
40
50
60
70
80
90
100
0
2
4
6
8
10
12
(a)
(b)
(c)
(d)
0
2
4
6
8
10
12
0
2
4
6
8
10
12
0
2
4
6
8
10
12
θ (deg)
40
50
60
70
80
90
100
θ (deg)
40
50
60
70
80
90
100
θ (deg)
40
50
60
70
80
90
100
θ (deg)
( f, θ)
( f, θ)
( f, θ)
( f, θ)
Figure 8.13 The function R(f, 𝜃), given by (8.81), as a function of 𝜃for several values of 𝛼and different
numbers of sensors, M: (a) 𝛼= 10−5, (b) 𝛼= 10−10, (c) 𝛼= 10−15, and (d) 𝛼= 10−20. Each figure shows
plots for M = 3 (solid line with circles), M = 6 (dashed line with asterisks), M = 9 (dotted line with
squares), and M = 12 (dash-dot line with triangles).
sensors. As the number of snapshots is larger, we can estimate 𝜃d using a smaller number
of sensors, but still a better estimate is obtained using a larger number of sensors.
■
8.6
A Spectral Coherence Perspective
The coherence function, which is a bounded function, is a fundamental measure in
linear systems. It describes how two complex signals are linearly related. In this section,
we show how the coherence can be used as an alternative to the MSE criterion to derive
all kinds of adaptive beamformers, since all beamforming techniques discussed in this
text are fundamentally linear ﬁltering. What we propose in the following is far from
exhaustive; much more can be done.
8.6.1
Definitions
It is of great importance to know how much of X( f ) or V( f ) is contained in the
estimator Z( f ). The best second-order statistics based measure to evaluate this is via the
magnitude squared coherence (MSC). We deﬁne the MSC between Z( f ) and X( f ) as
www.ebook3000.com

Adaptive Beamforming
309
40
50
60
70
80
90
100
0
2
4
6
8
10
12
(a)
(b)
(c)
(d)
0
2
4
6
8
10
12
0
2
4
6
8
10
12
0
2
4
6
8
10
12
θ (deg)
40
50
60
70
80
90
100
θ (deg)
40
50
60
70
80
90
100
θ (deg)
40
50
60
70
80
90
100
θ (deg)
( f, θ)
( f, θ)
( f, θ)
( f, θ)
Figure 8.14 The function R(f, 𝜃), given by (8.81), as a function of 𝜃for different numbers of snapshots,
K, and different numbers of sensors, M: (a) K = 30, (b) K = 50, (c) K = 300, and (d) K = 1000. Each
figure shows plots for M = 3 (solid line with circles), M = 6 (dashed line with asterisks), M = 9 (dotted
line with squares), and M = 12 (dash-dot line with triangles).
|||𝛾ZX
[𝐡( f )]|||

=
|||E [Z( f )X∗( f )]|||

E [
|Z( f )|] E [
|X( f )|]
(.)
=
𝜙X( f ) |||𝐡H( f )𝐝(f , cos 𝜃d
)|||

𝐡H( f )𝚽𝐲( f )𝐡( f )
= 𝐡H( f )𝚽𝐱( f )𝐡( f )
𝐡H( f )𝚽𝐲( f )𝐡( f ).
In the same manner, we deﬁne the MSC between Z( f ) and V( f ) as
|||𝛾ZV
[𝐡( f )]|||

=
|||E [Z( f )V ∗
( f )]|||

E
[
|Z( f )|]
E
[
||V( f )||
]
(.)
=
𝜙V( f ) |||𝐡H( f )𝝆𝐯V( f )|||

𝐡H( f )𝚽𝐲( f )𝐡( f )
,

310
Fundamentals of Signal Enhancement and Array Signal Processing
where
𝝆𝐯V( f ) = [ 
𝜌VV( f )
⋯
𝜌VMV( f ) ]T
(.)
=
E
[
𝐯( f )V ∗
( f )
]
E
[
||V( f )||
]
is the partially normalized – with respect to V( f ) – coherence vector (of length M)
between 𝐯( f ) and V( f ). It can be shown that
|||𝛾ZX
[
𝐡( f )
]|||

+ |||𝛾ZV
[
𝐡( f )
]|||

≤.
(.)
We see how the MSCs deﬁned above, which resemble the generalized Rayleigh
quotient [], depend explicitly on the beamformer 𝐡( f ). This observation suggests that
we can use the MSC as a criterion to derive optimal adaptive beamformers.
8.6.2
Derivation of Optimal Beamformers
Intuitively, it makes sense to maximize or minimize the MSC in order to ﬁnd an estimate
of X( f ) or V( f ). For example, it is clear that the maximization of |||𝛾ZX
[
𝐡( f )
]|||

will give
a good estimate of X( f ) since, in this case, the coherence between Z( f ) and X( f ) will
be maximal, implying that Z( f ) is close to X( f ).
8.6.2.1
Coherence Between Beamformer Output and Desired Signal
Here, we consider the MSC between Z( f ) and X( f ), which is deﬁned in (.). A
maximal (resp. minimal) MSC implies that Z( f ) is an estimate of X( f ) [resp. V( f )].
It is obvious that the maximization of (.) leads to an estimate of the desired signal.
In (.), we recognize the generalized Rayleigh quotient [], which is maximized with
the maximum eigenvector, 𝐭
(f , cos 𝜃d
), of the matrix 𝚽−
𝐲( f )𝚽𝐱( f ). Let us denote by
𝜆
(f , cos 𝜃d
) the maximum eigenvalue corresponding to 𝐭
(f , cos 𝜃d
). Since the rank of
the mentioned matrix is equal to , we have
𝐭
(
f , cos 𝜃d
)
=
𝚽−
𝐲( f )𝐝
(
f , cos 𝜃d
)
√
𝐝H (
f , cos 𝜃d
)
𝚽−
𝐲( f )𝐝
(
f , cos 𝜃d
),
(.)
𝜆
(
f , cos 𝜃d
)
= tr
[
𝚽−
𝐲( f )𝚽𝐱( f )
]
(.)
= 𝜙X( f )𝐝H (
f , cos 𝜃d
)
𝚽−
𝐲( f )𝐝
(
f , cos 𝜃d
)
,
and the maximum coherence is
|||𝛾ZX,max
(
f , cos 𝜃d
)|||

= 𝜆
(
f , cos 𝜃d
)
.
(.)
As a result, the optimal ﬁlter is
𝐡𝛼
(f , cos 𝜃d
) = 𝛼( f )𝚽−
𝐲( f )𝐝(f , cos 𝜃d
) ,
(.)
www.ebook3000.com

Adaptive Beamforming
311
where 𝛼( f ) ≠is an arbitrary complex number. Hence, the estimate of X( f ) is
̂X𝛼( f ) = 𝐡H
𝛼
(f , cos 𝜃d
) 𝐲( f ).
(.)
The narrowband output SNR is then
oSNR [𝐡𝛼
(f , cos 𝜃d
)] =
𝐡H
𝛼
(f , cos 𝜃d
) 𝚽𝐱( f )𝐡𝛼
(f , cos 𝜃d
)
𝐡H
𝛼
(f , cos 𝜃d
) 𝚽𝐯( f )𝐡𝛼
(f , cos 𝜃d
)
(.)
and it is not hard to ﬁnd how it is related to the MSC:
𝜆
(
f , cos 𝜃d
)
=
oSNR [𝐡𝛼
(f , cos 𝜃d
)]
+ oSNR [𝐡𝛼
(f , cos 𝜃d
)].
(.)
Since the MSC is maximized, so is the narrowband output SNR. We deduce that
oSNR [𝐡𝛼
(f , cos 𝜃d
)] =
𝜆
(
f , cos 𝜃d
)
−𝜆
(
f , cos 𝜃d
) ≥iSNR( f ).
(.)
Now, we need to determine 𝛼( f ). There are at least two ways to ﬁnd this parameter.
The ﬁrst one is from the MSE between X( f ) and ̂X𝛼( f ):
J [𝐡𝛼
(f , cos 𝜃d
)] = E
[|||X( f ) −𝐡H
𝛼
(f , cos 𝜃d
) 𝐲( f )|||
]
.
(.)
The second possibility is to use the distortion-based MSE:
Jd
[𝐡𝛼
(f , cos 𝜃d
)] = E
[|||X( f ) −𝐡H
𝛼
(f , cos 𝜃d
) 𝐱( f )|||
]
.
(.)
The minimization of J [𝐡𝛼
(f , cos 𝜃d
)] with respect to 𝛼( f ) leads to
𝛼( f ) = 𝜙X( f ).
(.)
Substituting this value into (.), we get the conventional Wiener beamformer:
𝐡W
(f , cos 𝜃d
) = 𝜙X( f )𝚽−
𝐲( f )𝐝(f , cos 𝜃d
) .
(.)
By minimizing Jd
[𝐡𝛼
(f , cos 𝜃d
)] with respect to 𝛼( f ), we obtain
𝛼( f ) =

𝐝H (f , cos 𝜃d
) 𝚽−
𝐲( f )𝐝(f , cos 𝜃d
)
(.)
and substituting the previous result into (.) gives the classical MVDR beamformer:
𝐡MVDR
(
f , cos 𝜃d
)
=
𝚽−
𝐲( f )𝐝
(
f , cos 𝜃d
)
𝐝H (f , cos 𝜃d
) 𝚽−
𝐲( f )𝐝(f , cos 𝜃d
).
(.)

312
Fundamentals of Signal Enhancement and Array Signal Processing
Another approach is to ﬁnd the beamformer that minimizes (.). Then, the beam-
former output will be an estimate of V( f ). The matrix 𝚽−
𝐲( f )𝚽𝐱( f ) has M −
eigenvalues equal to , since its rank is equal to . Let 𝐭( f ), 𝐭( f ), … , 𝐭M( f ) be the
corresponding eigenvectors. The beamformer:
𝐡𝜶,V( f ) = 𝐓∶M( f )𝜶( f ),
(.)
where
𝐓∶M( f ) = [ 𝐭( f )
𝐭( f )
⋯
𝐭M( f ) ]
(.)
is a matrix of size M × (M −) and
𝜶( f ) =
[ 𝛼( f )
𝛼( f )
⋯
𝛼M( f ) ]T ≠𝟎
(.)
is a vector of length M −, which minimizes (.), since
|||𝛾ZX
[𝐡𝜶,V( f )]|||

= ||𝛾ZX,min( f )||
= .
(.)
Therefore, the estimates of V( f ) and X( f ) are, respectively,
̂V,𝜶( f ) = 𝐡H𝜶,V( f )𝐲( f )
(.)
= 𝐡H𝜶,V( f )𝐯( f )
and
̂X𝜶( f ) = Y( f ) −̂V,𝜶( f )
(.)
= 𝐡H𝜶( f )𝐲( f ),
where
𝐡𝜶( f ) = 𝐢i −𝐡𝜶,V( f )
(.)
is the equivalent ﬁlter for the estimation of X( f ). We can express (.) as
̂X𝜶( f ) = X( f ) + V( f ) −𝐡H𝜶,V( f )𝐯( f ).
(.)
We see that the previous estimate is distortionless since the desired signal is not ﬁltered
at all.
There is at least one interesting way to ﬁnd 𝜶( f ). It is obtained from the power of the
residual noise:
Jr
[𝐡𝜶,V( f )] = E
[|||V( f ) −𝜶H( f )𝐓H
∶M( f )𝐯( f )|||
]
.
(.)
The minimization of the previous expression with respect to 𝜶( f ) gives
𝜶( f ) = 𝐓H
∶M( f )𝚽𝐯( f )𝐢i.
(.)
www.ebook3000.com

Adaptive Beamforming
313
As a result,
𝐡𝜶,V( f ) = 𝐓∶M( f )𝐓H
∶M( f )𝚽𝐯( f )𝐢i
(.)
and
𝐡𝜶( f ) = [𝐈M −𝐓∶M( f )𝐓H
∶M( f )𝚽𝐯( f )] 𝐢i.
(.)
By using the properties of the joint diagonalization, it can easily be shown that
𝐡𝜶( f ) = 𝐡MVDR
(f , cos 𝜃d
) .
(.)
This is another interesting way to write the MVDR beamformer.
8.6.2.2
Coherence Between Beamformer Output and Noise Signal
Now, we consider the MSC between Z( f ) and V( f ). A maximal (resp. minimal) MSC
implies that Z( f ) is an estimate of V( f ) [resp. X( f )].
The rank of the matrix 𝜙V( f )𝚽−
𝐲( f )𝝆𝐯V( f )𝝆H
𝐯V( f ) = 𝚽−
𝐲( f )𝚽𝐯C( f ), where 𝚽𝐯C( f ) =
𝜙V( f )𝝆𝐯V( f )𝝆H
𝐯V( f ), is equal to , so its only nonnull and positive eigenvalue is
𝜆,V( f ) = 𝜙V( f )𝝆H
𝐯V( f )𝚽−
𝐲( f )𝝆𝐯V( f ),
(.)
the corresponding eigenvector of which is
𝐭,V( f ) =
𝚽−
𝐲( f )𝝆𝐯V( f )
√
𝝆H
𝐯V( f )𝚽−
𝐲( f )𝝆𝐯V( f )
.
(.)
As a result, the beamformer that maximizes (.) is
𝐡𝛽,V( f ) = 𝛽( f )𝚽−
𝐲( f )𝝆𝐯V( f ),
(.)
where 𝛽( f ) ≠is an arbitrary complex number and the maximum coherence is
|||𝛾ZV,max( f )|||

= 𝜆,V( f ).
(.)
This beamformer output gives an estimate of V( f ):
̂V,𝛽( f ) = 𝐡H
𝛽,V( f )𝐲( f ).
(.)
We deduce that the estimate of the desired signal is
̂X𝛽( f ) = Y( f ) −̂V,𝛽( f )
(.)
= 𝐡H
𝛽( f )𝐲( f ),

314
Fundamentals of Signal Enhancement and Array Signal Processing
where
𝐡𝛽( f ) = 𝐢i −𝐡𝛽,V( f )
(.)
is the equivalent beamformer for the estimation of X( f ). This beamformer will always
distort the desired signal since 𝐡H
𝛽( f )𝐱( f ) ≠.
One way to ﬁnd 𝛽( f ) is from the MSE between X( f ) and ̂X𝛽( f ), or, equivalently, V( f )
and ̂V,𝛽( f ):
J [𝐡𝛽,V( f )] = E
[|||V( f ) −𝐡H
𝛽,V( f )𝐲( f )|||
]
.
(.)
Indeed, the optimization of the previous expression leads to
𝛽( f ) = 𝜙V( f ).
(.)
Therefore, we have
𝐡𝛽,V( f ) = 𝜙V( f )𝚽−
𝐲( f )𝝆𝐯V( f )
(.)
and the equivalent beamformer for the estimation of X( f ) is
𝐡𝛽( f ) =
[
𝐈M −𝚽−
𝐲( f )𝚽𝐯C( f )
]
𝐢i
(.)
=
[
𝐈M −𝚽−
𝐲( f )𝚽𝐯( f )
]
𝐢i
= 𝐡W
(f , cos 𝜃d
) ,
which is the classical Wiener beamformer.
The other way to ﬁnd 𝛽( f ) is from the power of the residual noise:
Jr
[
𝐡𝛽,V( f )
]
= E
[|||V( f ) −𝐡H
𝛽,V( f )𝐯( f )|||
]
.
(.)
In this case, we easily ﬁnd the minimum noise (minN) beamformer for the estimation
of X( f ):
𝐡minN( f ) =
⎧
⎪
⎨
⎪⎩
𝐈M −
𝚽−
𝐲( f )𝚽𝐯C( f )𝚽−
𝐲( f )𝚽𝐯( f )
tr
[
𝚽−
𝐲( f )𝚽𝐯( f )𝚽−
𝐲( f )𝚽𝐯C( f )
]
⎫
⎪
⎬
⎪⎭
𝐢i.
(.)
This beamformer will reduce more noise than 𝐡W
(
f , cos 𝜃d
)
but it will introduce much
more distortion.
Let 𝐭,V( f ), 𝐭,V( f ), … , 𝐭M,V( f ) be the eigenvectors corresponding to the M −null
eigenvalues of the matrix 𝚽−
𝐲( f )𝚽𝐯C( f ). Let us form the beamformer:
𝐡𝜷( f ) = 𝐓∶M,V( f )𝜷( f ),
(.)
www.ebook3000.com

Adaptive Beamforming
315
where
𝐓∶M,V( f ) = [ 𝐭,V( f )
𝐭,V( f )
⋯
𝐭M,V( f ) ]
(.)
is a matrix of size M × (M −) and
𝜷( f ) =
[ 𝛽( f )
𝛽( f )
⋯
𝛽M( f ) ]T ≠𝟎
(.)
is a vector of length M −. It can be veriﬁed that 𝐡𝜷( f ) minimizes (.), since
||||
𝛾ZV
[
𝐡𝜷( f )
]||||

= |||𝛾ZV,min( f )|||

= .
(.)
Therefore, the beamformer output can be considered as an estimate of the desired
signal:
̂X𝜷( f ) = 𝐡H
𝜷( f )𝐲( f ).
(.)
The MSE between X( f ) and ̂X𝜷( f ) is then
J
[
𝐡𝜷( f )
]
= E
[|||X( f ) −𝜷H( f )𝐓H
∶M,V( f )𝐲( f )|||
]
.
(.)
The minimization of the previous expression gives
𝜷( f ) = 𝐓H
∶M,V( f )𝚽𝐱( f )𝐢i.
(.)
We deduce a reduced-rank Wiener beamformer:
𝐡RRW
(f , cos 𝜃d
) = 𝐓∶M,V( f )𝐓H
∶M,V( f )𝚽𝐱( f )𝐢i
(.)
= 𝜙X( f )𝐓∶M,V( f )𝐓H
∶M,V( f )𝐝(f , cos 𝜃d
) .
We can also minimize the residual noise subject to the distortionless constraint:
min
𝜷( f )
𝜷H( f )𝐓H
∶M,V( f )𝚽𝐯( f )𝐓∶M,V( f )𝜷( f )
subject to 𝜷H( f )𝐓H
∶M,V( f )𝐝
(
f , cos 𝜃d
)
= .
(.)
We ﬁnd that the optimal solution is
𝐡LCMV,
(f , cos 𝜃d
) =
𝐏𝐯( f )𝐝(f , cos 𝜃d
)
𝐝H (f , cos 𝜃d
) 𝐏𝐯( f )𝐝(f , cos 𝜃d
),
(.)
where
𝐏𝐯( f ) = 𝐓∶M,V( f )
[
𝐓H
∶M,V( f )𝚽𝐯( f )𝐓∶M,V( f )
]−
𝐓H
∶M,V( f ).
(.)

316
Fundamentals of Signal Enhancement and Array Signal Processing
The ﬁlter 𝐡LCMV,
(f , cos 𝜃d
) is a particular form of the LCMV beamformer since it places
a null at the coherent component of the noise signal.
Problems
8.1 Show that the narrowband MSE can be expressed as
J
[
𝐡( f )
]
= 𝜙X( f ) + 𝐡H( f )𝚽𝐲( f )𝐡( f ) −𝜙X( f )𝐡H( f )𝐝
(
f , cos 𝜃d
)
−𝜙X( f )𝐝H (f , cos 𝜃d
) 𝐡( f ).
8.2 Show that the MSEs are related to the diﬀerent performance measures by
Jd
[
𝐡( f )
]
Jn
[𝐡( f )] = iSNR( f ) × 𝜉n
[𝐡( f )] × 𝜐d
[𝐡( f )]
= oSNR [𝐡( f )] × 𝜉d
[𝐡( f )] × 𝜐d
[𝐡( f )] .
8.3 Show that by minimizing the narrowband MSE, J
[
𝐡( f )
]
, we obtain the Wiener
beamformer:
𝐡W
(f , cos 𝜃d
) = 𝜙X( f )𝚽−
𝐲( f )𝐝(f , cos 𝜃d
) .
8.4 Show that the Wiener beamformer can be written as
𝐡W
(
f , cos 𝜃d
)
=
iSNR( f )
+ iSNR( f )𝚪−
𝐲( f )𝐝
(
f , cos 𝜃d
)
.
8.5 Show that the Wiener beamformer can be expressed as a function of the statistics
of the observation and noise signals by
𝐡W
(f , cos 𝜃d
) =
[
𝐈M −𝚽−
𝐲( f )𝚽𝐯( f )
]
𝐢i.
8.6 Using the Woodbury identity, show that the inverse of 𝚽𝐲( f ) is given by
𝚽−
𝐲( f ) = 𝚽−
𝐯( f ) −
𝚽−
𝐯( f )𝐝(f , cos 𝜃d
) 𝐝H (f , cos 𝜃d
) 𝚽−
𝐯( f )
𝜙−
X ( f ) + 𝐝H (f , cos 𝜃d
) 𝚽−
𝐯( f )𝐝(f , cos 𝜃d
).
8.7 Show that the Wiener beamformer can be written as
𝐡W
(
f , cos 𝜃d
)
=
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
−M + tr [𝚽−
𝐯( f )𝚽𝐲( f )]𝐢i.
www.ebook3000.com

Adaptive Beamforming
317
8.8 Show that by minimizing the narrowband MSE of the residual noise, Jr
[𝐡( f )],
subject to the distortionless constraint, we obtain the MVDR beamformer:
𝐡MVDR
(f , cos 𝜃d
) =
𝚽−
𝐯( f )𝐝
(
f , cos 𝜃d
)
𝐝H (f , cos 𝜃d
) 𝚽−
𝐯( f )𝐝(f , cos 𝜃d
).
8.9 Using the Woodbury identity, show that the MVDR beamformer can be expressed
as a function of the statistics of the observation by
𝐡MVDR
(f , cos 𝜃d
) =
𝚪−
𝐲( f )𝐝(f , cos 𝜃d
)
𝐝H (
f , cos 𝜃d
)
𝚪−
𝐲( f )𝐝
(
f , cos 𝜃d
).
8.10 Show that by minimizing the narrowband desired signal distortion index with the
constraint that the narrowband noise reduction factor is equal to a positive value,
we obtain the tradeoﬀbeamformer:
𝐡T,𝜇
(f , cos 𝜃d
) = 𝜙X( f ) [𝚽𝐱( f ) + 𝜇𝚽𝐯( f )]−𝐝(f , cos 𝜃d
) ,
where 𝜇> is a Lagrange multiplier.
8.11 Show that the tradeoﬀbeamformer can be written as
𝐡T,𝜇
(
f , cos 𝜃d
)
=
𝜙X( f )𝚽−
𝐯( f )𝐝(f , cos 𝜃d
)
𝜇+ 𝜙X( f )𝐝H (f , cos 𝜃d
) 𝚽−
𝐯( f )𝐝(f , cos 𝜃d
)
=
𝚽−
𝐯( f )𝚽𝐲( f ) −𝐈M
𝜇−M + tr [𝚽−
𝐯( f )𝚽𝐲( f )]𝐢i.
8.12 Show that for
a) 𝜇= , the tradeoﬀbeamformer is identical to the Wiener beamformer:
𝐡T,
(f , cos 𝜃d
) = 𝐡W
(f , cos 𝜃d
)
b) 𝜇= , the tradeoﬀbeamformer is identical to the MVDR beamformer:
𝐡T,
(f , cos 𝜃d
) = 𝐡MVDR
(f , cos 𝜃d
)
c) 𝜇> , the tradeoﬀbeamformer, compared to the Wiener beamformer, gives
lower residual noise at the expense of higher desired signal distortion.

318
Fundamentals of Signal Enhancement and Array Signal Processing
8.13 Show that the tradeoﬀbeamformer can be written as
𝐡T,𝜇
(f , cos 𝜃d
)
=
[
(−𝜇)𝐝(f , cos 𝜃d
) 𝐝H (f , cos 𝜃d
) + 𝜇+ iSNR( f )
iSNR( f )
𝚪𝐲( f )
]−
× 𝐝
(
f , cos 𝜃d
)
.
8.14 Show that the tradeoﬀbeamformer can be written as
𝐡T,𝜇
(f , cos 𝜃d
) =
HW( f )𝚪−
𝐲( f )𝐝(f , cos 𝜃d
)
𝜇+ (−𝜇)HW( f )𝐝H (f , cos 𝜃d
) 𝚪−
𝐲( f )𝐝(f , cos 𝜃d
).
8.15 Show that the broadband array gains of the tradeoﬀ, MVDR, and Wiener beam-
formers are related by
≤(𝐡MVDR
) ≤(𝐡W
) ≤(𝐡T,𝜇
)
for 𝜇≥, and
≤(𝐡MVDR
) ≤(𝐡T,𝜇
) ≤(𝐡W
)
for ≤𝜇≤.
8.16 Show that the maximum array gain is given by
max
(f , cos 𝜃d
) = 𝜙V( f )𝐝H (f , cos 𝜃d
) 𝚽−
𝐯( f )𝐝(f , cos 𝜃d
) .
8.17 Show that the maximum array gain beamformer, 𝐡max
(f , cos 𝜃d
), which maxi-
mizes the array gain, is given by
𝐡max
(
f , cos 𝜃d
)
= 𝜍( f )𝚪−
𝐲( f )𝐝
(
f , cos 𝜃d
)
,
where 𝜍( f ) ≠is an arbitrary frequency-dependent complex number.
8.18 Show that by minimizing the narrowband MSE of the residual noise, Jr
[𝐡( f )],
subject to the constraint 𝐂H (f , 𝜃d, 𝜃∶N
) 𝐡( f ) = 𝐢c, we obtain the LCMV beam-
former:
𝐡LCMV
(
f , cos 𝜃d
)
= 𝚽−
𝐯( f )𝐂
(
f , 𝜃d, 𝜃∶N
)
× [𝐂H (f , 𝜃d, 𝜃∶N
) 𝚽−
𝐯( f )𝐂(f , 𝜃d, 𝜃∶N
)]−𝐢c.
8.19 Show that the LCMV beamformer can be written as
𝐡LCMV
(f , cos 𝜃d
) = 𝚪−
𝐲( f )𝐂(f , 𝜃d, 𝜃∶N
)
×
[
𝐂H (f , 𝜃d, 𝜃∶N
) 𝚪−
𝐲( f )𝐂(f , 𝜃d, 𝜃∶N
)]−
𝐢c.
www.ebook3000.com

Adaptive Beamforming
319
8.20 Show that the single-channel Wiener gain HW( f ) is related to the pseudo-
coherence matrix, 𝚪𝐲( f ), of the observations by
HW( f ) =
𝐝H (f , cos 𝜃d
) [𝚪𝐲( f ) −𝚪,𝜋( f )] 𝐝(f , cos 𝜃d
)
M−𝐝H (f , cos 𝜃d
) 𝚪,𝜋( f )𝐝(f , cos 𝜃d
)
.
8.21 Show that the MSC between Z( f ) and X( f ) plus the MSC between Z( f ) and V( f )
is equal to :
|||𝛾ZX
[𝐡( f )]|||

+ |||𝛾ZV
[𝐡( f )]|||

≤.
8.22 Show that maximization of the MSC between Z( f ) and X( f ) yields the ﬁlter:
𝐡𝛼
(
f , cos 𝜃d
)
= 𝛼( f )𝚽−
𝐲( f )𝐝
(
f , cos 𝜃d
)
,
where 𝛼( f ) ≠is an arbitrary complex number.
8.23 Show that with the ﬁlter 𝐡𝛼
(f , cos 𝜃d
), the narrowband output SNR is related to
the MSC between Z( f ) and X( f ) by
|||𝛾ZX,max
(
f , cos 𝜃d
)|||

=
oSNR [𝐡𝛼
(f , cos 𝜃d
)]
+ oSNR [𝐡𝛼
(f , cos 𝜃d
)].
8.24 Show
that
the
ﬁlter
𝐡𝛼
(
f , cos 𝜃d
)
that
minimizes
the
distortion-based
MSE,Jd
[𝐡𝛼
(f , cos 𝜃d
)], is identical to the MVDR beamformer:
𝐡MVDR
(
f , cos 𝜃d
)
=
𝚽−
𝐲( f )𝐝(f , cos 𝜃d
)
𝐝H (f , cos 𝜃d
) 𝚽−
𝐲( f )𝐝(f , cos 𝜃d
).
References
1 J. Benesty, J. Chen, and Y. Huang, Microphone Array Signal Processing. Berlin,
Germany: Springer-Verlag, .
2 J. Capon, “High resolution frequency-wavenumber spectrum analysis,” Proc. IEEE,
vol. , pp. –, Aug. .
3 R. T. Lacoss, “Data adaptive spectral analysis methods,” Geophysics, vol. ,
pp. –, Aug. .
4 J. N. Franklin, Matrix Theory. Englewood Cliﬀs, NJ: Prentice-Hall, .
5 A. Booker and C. Y. Ong, “Multiple constraint adaptive ﬁltering,” Geophysics, vol. ,
pp. –, June .
6 O. Frost, “An algorithm for linearly constrained adaptive array processing,” Proc. IEEE,
vol. , pp. –, Jan. .
7 R. Zelinski, “A microphone array with adaptive post-ﬁltering for noise reduction in
reverberant rooms,” in Proc. IEEE ICASSP, vol. , , pp. –.

320
Fundamentals of Signal Enhancement and Array Signal Processing
8 J. Meyer and K. Uwe Simmer, “Multi-channel speech enhancement in a car
environment using Wiener ﬁltering and spectral subtraction,” in Proc. IEEE ICASSP,
vol. , , pp. –.
9 I. A. McCowan and H. Bourlard, “Microphone array post-ﬁlter based on noise ﬁeld
coherence,” IEEE Trans. Speech, Audio Process., vol. , pp. –, Nov. .
10 S. Lefkimmiatis and P. Maragos, “A generalized estimation approach for linear and
nonlinear microphone array post-ﬁlters,” Speech Communication, vol. , pp. –,
.
11 H. L. van Trees, Optimum Array Processing: Part IV of Detection, Estimation, and
Modulation Theory. New York, NY: John Wiley & Sons, Inc., .
12 G. Bienvenu and L. Kopp, “Adaptivity to background noise spatial coherence for high
resolution passive methods,” in Proc. IEEE ICASSP, , pp. –.
13 R. O. Schmidt, “Multiple emitter location and signal parameter estimation,” IEEE Trans.
Antennas Propag., vol. AP-, pp. –, Mar. .
www.ebook3000.com

321
9
Differential Beamforming
Diﬀerential beamforming is a subcategory of classical ﬁxed beamforming. Diﬀerential
beamformers have two great advantages. The ﬁrst is that the corresponding beam-
patterns are almost frequency invariant, which is extremely important when we deal
with broadband signals. The second is that they give the highest gains in diﬀuse noise.
These two characteristics make diﬀerential beamforming very useful and practical
in many applications. However, the main drawback of this approach is white noise
ampliﬁcation. In this chapter, we derive and describe diﬀerential beamformers of
diﬀerent orders. We explain the advantages as well as the main problems of this method.
We give many design examples. Finally, we show how to deal with the white noise
ampliﬁcation problem.
9.1
Signal Model, Problem Formulation, and Array Model
Again, we consider the signal model of Chapters and , which consists of a unique
desired source impinging on a ULA of M omnidirectional sensors. The observation
vector is then []
𝐲( f ) =
[ Y( f )
Y( f )
⋯
YM( f ) ]T
= 𝐱( f ) + 𝐯( f )
= 𝐝(f , cos 𝜃d
) X( f ) + 𝐯( f ),
(.)
where Ym( f ) is the mth sensor signal, 𝐱( f ) = 𝐝(f , cos 𝜃d
) X( f ),
𝐝(f , cos 𝜃d
) = [ 
e−𝚥𝜋f 𝛿cos 𝜃d∕c
⋯
e−𝚥(M−)𝜋f 𝛿cos 𝜃d∕c ]T
(.)
is the steering vector, X( f ) is the desired source signal, and 𝐯( f ) is the additive noise
signal vector of length M.
To ensure that diﬀerential beamforming takes place, the following two assumptions
are made [–]:
i) The sensor spacing, 𝛿, is much smaller than the wavelength, 𝜆= c∕f ; that is, 𝛿≪𝜆
(this implies that f 𝛿≪c). This assumption is required so that the true acoustic
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing

322
Fundamentals of Signal Enhancement and Array Signal Processing
pressure diﬀerentials can be approximated by ﬁnite diﬀerences of the sensors’
outputs.
ii) The desired source signal propagates from the angle 𝜃d = (endﬁre direction).
Therefore, (.) becomes
𝐲( f ) = 𝐝(f , ) X( f ) + 𝐯( f ),
(.)
and, at the endﬁre, the value of the beamformer beampattern should always be equal
to (or maximal).
Assumption (i) also implies that we can make a good approximation of the exponential
function that appears in the steering vector with the ﬁrst few elements of its series
expansion, so frequency-invariant beamforming may be possible. Because of the sym-
metry of the steering vector, the only directions in which we can design any desired
beampatterns are at the endﬁres (and 𝜋); in other directions, the beampattern design
is very limited; that is why assumption (ii) is of great importance.
With the conventional linear approach, the beamformer output is simply []:
Z( f ) =
M
∑
m=
H∗
m( f )Ym( f )
(.)
= 𝐡H( f )𝐲( f )
= 𝐡H( f )𝐝(f , ) X( f ) + 𝐡H( f )𝐯( f ),
where Z( f ) is, in general, the estimate of the desired signal, X( f ), and 𝐡( f ) is the
beamformer of length M. In our context, the distortionless constraint is wanted:
𝐡H( f )𝐝(f , ) = .
(.)
This means that the value of the beamformer beampattern is equal to at 𝜃= and
smaller than at 𝜃≠.
In this chapter, we examine diﬀerential sensor arrays (DSAs) of diﬀerent orders.
9.2
Beampatterns
We recall that the beampattern or directivity pattern, which describes the sensitivity
of the beamformer to a plane wave impinging on the array from the direction 𝜃, is
deﬁned as
[𝐡( f ), cos 𝜃] = 𝐝H (f , cos 𝜃) 𝐡( f )
(.)
=
M
∑
m=
Hm( f )e𝚥(m−)𝜋f 𝛿cos 𝜃∕c.
www.ebook3000.com

Differential Beamforming
323
The frequency-independent beampattern of a theoretical Nth-order DSA is well
known. It is deﬁned as []:
(𝐚N, cos 𝜃) =
N
∑
n=
aN,n cosn 𝜃
(.)
= 𝐚T
N𝐩(cos 𝜃) ,
where aN,n, n = , , … , N are real coeﬃcients and
𝐚N =
[ aN,
aN,
⋯
aN,N
]T ,
𝐩(cos 𝜃) = [ 
cos 𝜃
⋯
cosN 𝜃]T ,
are vectors of length N + . The diﬀerent values of the coeﬃcients aN,n, n = , , … , N
determine the diﬀerent directivity patterns of the Nth-order DSA. It may be convenient
to use a normalization convention for the coeﬃcients. For that, in the direction of the
desired signal – that is, for 𝜃= – we would like the beampattern to be equal to ; that
is, (𝐚N, ) = . Therefore, we have
N
∑
n=
aN,n = .
(.)
As a result, we may choose the ﬁrst coeﬃcient as
aN,= −
N
∑
n=
aN,n.
(.)
Since cos 𝜃is an even function, so is (𝐚N, cos 𝜃). Therefore, on a polar plot,

(
𝐚N, cos 𝜃
)
is symmetric about the axis −𝜋and any DSA beampattern design can be
restricted to this range. All useful beampatterns have at least one null in some direction.
It follows from (.) that an Nth-order directivity pattern has at most N (distinct) nulls
in this range.
9.3
Front-to-back Ratios
The front-to-back ratio (FBR) is deﬁned as the ratio of the power of the output of the
array for signals propagating from the front-half plane to the output power for signals
arriving from the rear-half plane []. This ratio, for the spherically isotropic (diﬀuse)
noise ﬁeld, is mathematically deﬁned as []:
[𝐡( f )] = ∫
𝜋∕

|||[𝐡( f ), cos 𝜃]|||

sin 𝜃d𝜃
∫
𝜋
𝜋∕
|||[𝐡( f ), cos 𝜃]|||

sin 𝜃d𝜃
(.)

324
Fundamentals of Signal Enhancement and Array Signal Processing
=
𝐡H( f )𝚪,𝜋∕( f )𝐡( f )
𝐡H( f )𝚪𝜋∕,𝜋( f )𝐡( f ),
where
𝚪,𝜋∕( f ) = ∫
𝜋∕

𝐝(f , cos 𝜃) 𝐝H (f , cos 𝜃) sin 𝜃d𝜃,
(.)
𝚪𝜋∕,𝜋( f ) = ∫
𝜋
𝜋∕
𝐝(f , cos 𝜃) 𝐝H (f , cos 𝜃) sin 𝜃d𝜃.
(.)
Now, let us compute the entries of the matrix:
𝚪𝜓,𝜓( f ) = 𝜓,𝜓∫
𝜓
𝜓
𝐝
(
f , cos 𝜃
)
𝐝H (
f , cos 𝜃
)
sin 𝜃d𝜃,
(.)
where ≤𝜓≤𝜓≤𝜋and
𝜓,𝜓=

∫
𝜓
𝜓
sin 𝜃d𝜃
(.)
=

cos 𝜓−cos 𝜓
is a normalization term. The (i, j)th element (with i, j = , , … , M) of 𝚪𝜓,𝜓( f ) can be
written as
[
𝚪𝜓,𝜓( f )
]
ij = 𝜓,𝜓∫
𝜓
𝜓
e −𝚥𝜋f (i−)𝜏cos 𝜃e 𝚥𝜋f (j−)𝜏cos 𝜃sin 𝜃d𝜃
= 𝜓,𝜓∫
𝜓
𝜓
e 𝚥𝜋f (j−i)𝜏cos 𝜃sin 𝜃d𝜃
= −𝜓,𝜓∫
cos 𝜓
cos 𝜓
e 𝚥𝜋f (j−i)𝜏udu
= 𝜓,𝜓∫
cos 𝜓
cos 𝜓
e 𝚥𝜋f (j−i)𝜏udu,
(.)
where 𝜏= 𝛿∕c. Therefore, we deduce that
[𝚪𝜓,𝜓( f )]
ij = 𝜓,𝜓
e𝚥𝜋f (j−i)𝜏cos 𝜓−e𝚥𝜋f (j−i)𝜏cos 𝜓
𝚥𝜋f (j −i)𝜏
,
(.)
with
[𝚪𝜓,𝜓( f )]
mm = , m = , , … , M.
(.)
www.ebook3000.com

Differential Beamforming
325
As a result, the elements of the M×M matrices 𝚪,𝜋∕( f ) and 𝚪𝜋∕,𝜋( f ) are, respectively,
[
𝚪,𝜋∕( f )
]
ij = e𝚥𝜋f (j−i)𝜏−
𝚥𝜋f (j −i)𝜏
(.)
and
[
𝚪𝜋∕,𝜋( f )
]
ij = −e−𝚥𝜋f (j−i)𝜏
𝚥𝜋f (j −i)𝜏
,
(.)
with [𝚪,𝜋∕( f )]
mm = [𝚪𝜋∕,𝜋( f )]
mm = , m = , , … , M.
For the spherically isotropic noise ﬁeld, the frequency-independent FBR of a theoret-
ical Nth-order DSA is deﬁned as []:

(
𝐚N
)
= ∫
𝜋∕

(𝐚N, cos 𝜃) sin 𝜃d𝜃
∫
𝜋
𝜋∕
(𝐚N, cos 𝜃) sin 𝜃d𝜃
.
(.)
9.4
Array Gains
From Chapter , we know that the array gain is given by
[𝐡( f )] =
|||𝐡H( f )𝐝(f , )|||

𝐡H( f )𝚪𝐯( f )𝐡( f ),
(.)
where 𝚪𝐯( f ) is the pseudo-coherence matrix of 𝐯( f ).
The WNG is directly deduced from (.) by taking 𝚪𝐯( f ) = 𝐈M. We obtain

[
𝐡( f )
]
=
|||𝐡H( f )𝐝(f , )|||

𝐡H( f )𝐡( f )
(.)
and we can easily show that the maximum WNG is
max = M.
(.)
The DF, which is the array gain in the diﬀuse (spherically isotropic) noise ﬁeld, is
given by
[𝐡( f )] =
|||𝐡H( f )𝐝
(
f , 
)|||

𝐡H( f )𝚪,𝜋( f )𝐡( f )
(.)

326
Fundamentals of Signal Enhancement and Array Signal Processing
and the maximum DF is
max( f ) = 𝐝H (f , ) 𝚪−
,𝜋( f )𝐝(f , ) .
(.)
We also have []:
lim
𝛿→max( f ) = M.
(.)
For the spherically isotropic noise ﬁeld, the frequency-independent DF of a theoreti-
cal Nth-order DSA is deﬁned as []:
(𝐚N
) =
(𝐚N, )

∫
𝜋

(𝐚N, cos 𝜃) sin 𝜃d𝜃
.
(.)
9.5
Examples of Theoretical Differential Beamformers
The most well-known and frequently studied Nth-order DSA beampatterns are the
dipole, the cardioid, the hypercardioid, and the supercardioid. In the following, we show
how they are obtained.
The Nth-order dipole has a unique null, with multiplicity N in the direction 𝜋∕. Its
beampattern is then given by
N,Dp (cos 𝜃) = cosN 𝜃,
(.)
implying that aN,N = and aN,N−= aN,N−= ⋯= aN,= .
The Nth-order cardioid has a unique null with multiplicity N in the direction 𝜋. Its
beampattern is then given by
N,Cd (cos 𝜃) = 
N (+ cos 𝜃)N
(.)
=
N
∑
n=
N!
Nn!(N −n)! cosn 𝜃,
implying that
aN,n =
N!
Nn!(N −n)!, n = , , … , N.
(.)
The coeﬃcients of the Nth-order hypercardioid can be obtained by maximizing the
DF, (𝐚N
), given in (.). It can be shown that []:

(
𝐚N
)
=
𝐚T
N𝟏𝟏T𝐚N
𝐚T
N𝐇N𝐚N
,
(.)
www.ebook3000.com

Differential Beamforming
327
where
𝟏= [ 

⋯
]T
is a vector of length N + and 𝐇N is a Hankel matrix – of size (N + ) × (N + ) – the
elements of which are given by
[𝐇N
]
ij =
{

+ i + j,
if i + j even
,
otherwise
,
(.)
with i, j = , , … , N. In (.), we notice the generalized Rayleigh quotient. Therefore,
the vector 𝐚N that maximizes 
(
𝐚N
)
is the eigenvector corresponding to the maximum
eigenvalue of the matrix 𝐇−
N 𝟏𝟏T:
𝐚N,max =
𝐇−
N 𝟏
𝟏T𝐇−
N 𝟏.
(.)
As a result, the beampattern of the Nth-order hypercardioid is
N,Hd (cos 𝜃) =
𝟏T𝐇−
N 𝐩(cos 𝜃)
𝟏T𝐇−
N 𝟏
.
(.)
The coeﬃcients of the Nth-order supercardioid can be obtained by maximizing the
FBR, (𝐚N
), deﬁned in (.). It can be shown that []:

(
𝐚N
)
=
𝐚T
N𝐇′′
N𝐚N
𝐚T
N𝐇′
N𝐚N
,
(.)
where 𝐇′
N and 𝐇′′
N are two Hankel matrices – of size (N + ) × (N + ) – the elements of
which are given by, respectively,
[𝐇′
N
]
ij = (−)i+j
+ i + j
(.)
and
[𝐇′′
N
]
ij =

+ i + j,
(.)
with i, j = , , … , N. Let us denote by 𝐚′
N,max the eigenvector corresponding to the
maximum eigenvalue of 𝐇′−
N 𝐇′′
N. Then, 𝐚′
N,max maximizes the FBR and the beampattern
of the Nth-order supercardioid is
N,Sd (cos 𝜃) =
𝐚′T
N,max𝐩(cos 𝜃)
𝐚′T
N,max𝐩()
.
(.)

328
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−10 dB
−10 dB
−10 dB
Figure 9.1 First-order directivity patterns: (a) dipole, (b) cardioid, (c) hypercardioid, and
(d) supercardioid.
The best-known ﬁrst-order directivity patterns are expressed as
,Dp (cos 𝜃) = cos 𝜃,
(.)
,Cd (cos 𝜃) = 
+ 
cos 𝜃,
(.)
,Hd (cos 𝜃) = 
+ 
cos 𝜃,
(.)
,Sd (cos 𝜃) =
√
−

+ −
√


cos 𝜃.
(.)
Figure .shows these diﬀerent polar beampatterns. What exactly is shown are the
values of the magnitude squared beampattern in decibels; that is, log(𝐚N, cos 𝜃).
The most useful second-order directivity patterns are given by
,Dp (cos 𝜃) = cos𝜃,
(.)
www.ebook3000.com

Differential Beamforming
329
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
Figure 9.2 Second-order directivity patterns: (a) dipole, (b) cardioid, (c) hypercardioid, and
(d) supercardioid.
,Cd (cos 𝜃) = 
+ 
cos 𝜃+ 
cos𝜃,
(.)
,Hd (cos 𝜃) = −
+ 
cos 𝜃+ 
cos𝜃,
(.)
,Sd (cos 𝜃) =


(
+
√

) +
√

+
√

cos 𝜃+


(
+
√

) cos𝜃.
(.)
Figure .depicts the diﬀerent second-order directivity patterns given above.
The most important third-order directivity patterns are expressed as
,Dp (cos 𝜃) = cos𝜃,
(.)
,Cd (cos 𝜃) = 
+ 
cos 𝜃+ 
cos𝜃+ 
cos𝜃,
(.)

330
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−30 dB
−40 dB
−20 dB
−20 dB
−30 dB
−40 dB
Figure 9.3 Third-order directivity patterns: (a) dipole, (b) cardioid, (c) hypercardioid, and
(d) supercardioid.
,Hd (cos 𝜃) = −
−
cos 𝜃+ 
cos𝜃+ 
cos𝜃,
(.)
,Sd (cos 𝜃) ≈.+ .cos 𝜃+ .cos𝜃+ .cos𝜃.
(.)
Figure .depicts the diﬀerent third-order directivity patterns given above.
The approach to designing DSAs described in this chapter is based, mostly, on the
obvious observation that any useful theoretical frequency-independent DSA beampat-
tern has a one at the angle 𝜃= and a number of nulls in some speciﬁc directions
(with 𝜃≫). In the most obvious design, which is also the conventional way to
do diﬀerential beamforming, the number of sensors is equal to the order plus one
that is, M = N + .
www.ebook3000.com

Differential Beamforming
331
9.6
First-order Design
9.6.1
Principle
First-order DSAs are designed with two sensors. In this case, we have exactly two
constraints to fulﬁll. The ﬁrst constraint is the distortionless response (a one at the angle
𝜃= ) and the second constraint is a null in the interval < 𝜃≤𝜋. Thus, these two
constraints can be written as
𝐝H (f , ) 𝐡( f ) = ,
(.)
𝐝H (f , 𝛼,
) 𝐡( f ) = ,
(.)
where 𝛼,= cos 𝜃,is given by design (a null at the angle 𝜃,) with −≤𝛼,< . We
can express (.)–(.) as
[
𝐝H (f , )
𝐝H (
f , 𝛼,
)
]
𝐡( f ) =
[ 
e𝚥𝜋f 𝜏

e𝚥𝜋f 𝜏𝛼,
]
𝐡( f )
=
[


]
.
(.)
The last expression is a linear system of two equations and two unknowns, for which
the solution is
𝐡( f ) =

−e𝚥𝜋f 𝜏(−𝛼,)
[

−e−𝚥𝜋f 𝜏𝛼,
]
.
(.)
Substituting (.) into (.), we ﬁnd that the beampattern is
[𝐡( f ), cos 𝜃] = −e𝚥𝜋f 𝜏(cos 𝜃−𝛼,)
−e𝚥𝜋f 𝜏(−𝛼,) .
(.)
Using assumption (i) and the approximation:
ex ≈+ x,
(.)
we can approximate (.) as
[𝐡( f ), cos 𝜃] ≈

−𝛼,
cos 𝜃−
𝛼,
−𝛼,
,
(.)
which resembles the theoretical ﬁrst-order DSA. Most importantly, the beampattern
is frequency invariant. This is a useful feature since, as we can see, diﬀerential beam-
forming tends to lead to broadband beamformers, which are important in applications
dealing with broadband signals such as speech.
It is not hard to ﬁnd that the DF is
[𝐡( f )] =
−cos
[
𝜋f 𝜏
(
−𝛼,
)]
−sinc (𝜋f 𝜏
) cos (𝜋f 𝜏𝛼,
).
(.)

332
Fundamentals of Signal Enhancement and Array Signal Processing
Using the approximations:
cos x ≈−x
,
(.)
sinc x ≈−x
,
(.)
the DF becomes
[𝐡( f )] ≈
(−𝛼,
)
𝛼
,+ 

.
(.)
We observe that the DF is almost frequency independent as long as 𝛿is small. Also,
the value of 𝛼,that maximizes (.) is equal to −
, which corresponds to the
hypercardioid and leads to a DF of ; this is the maximum possible DF for M = .
The WNG is
[𝐡( f )] = 

|||−e𝚥𝜋f 𝜏(−𝛼,)|||

(.)
= −cos [𝜋f 𝜏
(−𝛼,
)] ,
which we can approximate as
[𝐡( f )] ≈

[𝜋f 𝜏
(−𝛼,
)].
(.)
Some observations are in order. First, the WNG is very much frequency dependent.
Second, the WNG is much larger at high than at low frequencies. Third, the WNG
can be smaller than , especially at low frequencies, implying white noise ampliﬁcation.
Finally, it is obvious that the WNG is maximized for 𝛼,= −, which corresponds to
the cardioid.
9.6.2
Design Examples
In this section, important particular cases of ﬁrst-order DSAs with two sensors are
numerically described. Depending on the value of 𝛼,we ﬁnd four useful ﬁrst-order
DSAs:
●dipole: 𝛼,= 
●cardioid: 𝛼,= −
●hypercardioid: 𝛼,= −

●supercardioid: 𝛼,= −
√

−
√
.
Figure .displays the patterns – with 𝐡( f ) deﬁned as in (.) – of the ﬁrst-order
dipole, cardioid, hypercardioid, and supercardioid for a low frequency (f = .kHz)
and a small value of 𝛿(𝛿= cm). Figure .shows the patterns for a high frequency
(f = kHz) and a small value of 𝛿(𝛿= cm). As long as the sensor spacing is small, the
beampatterns of the ﬁrst-order DSAs are frequency independent.
www.ebook3000.com

Differential Beamforming
333
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−10 dB
−10 dB
−10 dB
Figure 9.4 Beampatterns of the first-order DSAs for f = 0.5 kHz and 𝛿= 1 cm: (a) dipole, (b) cardioid,
(c) hypercardioid, and (d) supercardioid.
Figures .and .display the patterns of the ﬁrst-order dipole, cardioid, hypercar-
dioid, and supercardioid for a value of 𝛿equal to cm. In this case, the sensor spacing
is too large, which causes deterioration of the beampatterns at high frequencies.
Figure .shows plots of the DF, [𝐡( f )], as a function of frequency, for the dipole,
cardioid, hypercardioid, and supercardioid and several values of 𝛿. Corresponding plots
of the WNG, 
[
𝐡( f )
]
, as a function of frequency are depicted in Figure .. We
observe that increasing the sensor spacing enables us to increase the WNG, especially
at low frequencies. Accordingly, if we do not want to amplify the white (or sensor)
noise, the sensor spacing must be large. However, a large value of 𝛿is in conﬂict
with the DSA assumption, which states that 𝛿should be small. Therefore, there is
always a tradeoﬀbetween white noise ampliﬁcation, especially at low frequencies, and
a frequency-independent directivity pattern at high frequencies. The sensor spacing
should be selected according to this compromise.

334
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−10 dB
−10 dB
−10 dB
Figure 9.5 Beampatterns of the first-order DSAs for f = 7 kHz and 𝛿= 1 cm: (a) dipole, (b) cardioid,
(c) hypercardioid, and (d) supercardioid.
9.7
Second-order Design
9.7.1
Principle
Any second-order DSA can be realized with three sensors. Therefore, we assume that
we have exactly three sensors. As a result, we have three constraints to fulﬁll, with the
ﬁrst one being, as usual, at the angle 𝜃= . We deduce that the general linear system of
equations to design any second-order diﬀerential array is
⎡
⎢
⎢⎣
𝐝H (f , )
𝐝H (f , 𝛼,
)
𝐝H (f , 𝛼,
)
⎤
⎥
⎥⎦
𝐡( f ) =
⎡
⎢
⎢⎣

𝛽,
𝛽,
⎤
⎥
⎥⎦
,
(.)
where −≤𝛼,= cos 𝜃,< , −≤𝛼,= cos 𝜃,< , 𝛼,≠𝛼,, −≤𝛽,≤,
and −≤𝛽,≤. The parameter 𝛼,i is a chosen direction and 𝛽,i is its corresponding
www.ebook3000.com

Differential Beamforming
335
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−10 dB
−10 dB
−10 dB
Figure 9.6 Beampatterns of the first-order DSAs for f = 0.5 kHz and 𝛿= 4 cm: (a) dipole, (b) cardioid,
(c) hypercardioid, and (d) supercardioid.
value on the given desired beampattern. We should always privilege the zeroes of the
beampattern.
Let us denote by
𝐕( f ) =
⎡
⎢
⎢⎣
𝐝H (f , )
𝐝H (f , 𝛼,
)
𝐝H (f , 𝛼,
)
⎤
⎥
⎥⎦
=
⎡
⎢
⎢⎣

v( f )
v
( f )

v( f )
v
( f )

v( f )
v
( f )
⎤
⎥
⎥⎦
(.)
the × Vandermonde matrix that appears in (.), where v( f ) = e𝚥𝜋f 𝜏, v( f ) =
e𝚥𝜋f 𝜏𝛼,, and v( f ) = e𝚥𝜋f 𝜏𝛼,. From the decomposition 𝐕−( f ) = 𝐔( f )𝐋( f ) [], where

336
Fundamentals of Signal Enhancement and Array Signal Processing
−10 dB
−10 dB
−10 dB
−10 dB
−20 dB
−20 dB
−10 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−20 dB
−30 dB
−40 dB
−30 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−10 dB
−10 dB
−20 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−30 dB
Figure 9.7 Beampatterns of the first-order DSAs for f = 7 kHz and 𝛿= 4 cm: (a) dipole, (b) cardioid,
(c) hypercardioid, and (d) supercardioid.
𝐔( f ) =
⎡
⎢
⎢⎣

−v( f )
v( f )v( f )


−[v( f ) + v( f )]



⎤
⎥
⎥⎦
(.)
and
𝐋( f ) =
⎡
⎢
⎢
⎢
⎢⎣




v−v

v−v


(v−v
) (v−v
)

(v−v
) (v−v
)

(v−v
) (v−v
)
⎤
⎥
⎥
⎥
⎥⎦
,
(.)
In some matrices, we drop the dependency on f to simplify the presentation.
www.ebook3000.com

Differential Beamforming
337
0
2
4
6
8
−6
−4
−2
0
2
4
6
0
2
4
6
8
−6
−4
−2
0
2
4
6
0
2
4
6
8
−6
−4
−2
0
2
4
6
0
2
4
6
8
−6
−4
−2
0
2
4
6
f (kHz)
(a)
(b)
(c)
(d)
f (kHz)
f (kHz)
f (kHz)
[h1( f )] (dB)
[h1( f )] (dB)
[h1( f )] (dB)
[h1( f )] (dB)
Figure 9.8 DF of the first-order DSAs as a function of frequency, for several values of 𝛿: 𝛿= 1 cm (solid
line with circles), 𝛿= 2 cm (dashed line with asterisks), 𝛿= 3 cm (dotted line with squares), and
𝛿= 4 cm (dash-dot line with triangles). (a) Dipole, (b) cardioid, (c) hypercardioid, and (d) supercardioid.
we ﬁnd that the inverse of 𝐕( f ) is
𝐕−( f ) =
⎡
⎢
⎢
⎢
⎢
⎢
⎢⎣
vv
(v−v
) (v−v
)
−
vv
(v−v
) (v−v
)
vv
(v−v
) (v−v
)
−
v+ v
(
v−v
) (
v−v
)
v+ v
(
v−v
) (
v−v
)
−
v+ v
(
v−v
) (
v−v
)

(v−v
) (v−v
)
−

(v−v
) (v−v
)

(v−v
) (v−v
)
⎤
⎥
⎥
⎥
⎥
⎥
⎥⎦
.
(.)
This inverse can be of great help in designing second-order DSAs. We deduce that the
beamformer is
𝐡( f ) = 𝐔( f )𝐋( f )
⎡
⎢
⎢⎣

𝛽,
𝛽,
⎤
⎥
⎥⎦
.
(.)
While this approach is very general, it is not applicable to beampatterns that have a
zero with multiplicity greater than . Let us show how to design a beampattern that has
a zero, 𝛼,, with multiplicity . The theoretical DSA beampattern of such a case is

338
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
8
−25
−20
−15
−10
−5
0
5
0
2
4
6
8
0
2
4
6
8
0
2
4
6
8
f (kHz)
f (kHz)
f (kHz)
f (kHz)
−25
−20
−15
−10
−5
0
5
−25
−20
−15
−10
−5
0
5
−25
−20
−15
−10
−5
0
5
[h1( f )] (dB)
[h1( f )] (dB)
[h1( f )] (dB)
[h1( f )] (dB)
(a)
(b)
(c)
(d)
Figure 9.9 WNG of the first-order DSAs as a function of frequency, for several values of 𝛿: 𝛿= 1 cm
(solid line with circles), 𝛿= 2 cm (dashed line with asterisks), 𝛿= 3 cm (dotted line with squares), and
𝛿= 4 cm (dash-dot line with triangles). (a) Dipole, (b) cardioid, (c) hypercardioid, and (d) supercardioid.

(
𝛼,, 𝛼
)
=

(−𝛼,
)
(
𝛼−𝛼,
),
(.)
where 𝛼= cos 𝜃. It is clear that the derivative of (𝛼,, 𝛼) with respect to 𝛼at 𝛼,is
d
(
𝛼,, 𝛼
)
d𝛼
|||||𝛼=𝛼,
= .
(.)
Applying this property to the beamformer beampattern, we get
d
[
𝐡( f ), 𝛼
]
d𝛼
|||||𝛼=𝛼,
= 𝚥𝜋f 𝜏
[𝚺𝐝(f , 𝛼,
)]H 𝐡( f ) = ,
(.)
where
𝚺= diag (, , )
(.)
www.ebook3000.com

Differential Beamforming
339
is a diagonal matrix. From (.), we deduce the constraint equation:
[𝚺𝐝(f , 𝛼,
)]H 𝐡( f ) = .
(.)
Combining the distortionless constraint, the null constraint in the direction 𝛼,; that is,
𝐝(f , 𝛼,
) 𝐡( f ) = ,
(.)
and (.), we obtain
⎡
⎢
⎢⎣
𝐝H (f , )
𝐝H (
f , 𝛼,
)
[
𝚺𝐝
(
f , 𝛼,
)]H
⎤
⎥
⎥⎦
𝐡( f ) =
⎡
⎢
⎢⎣



⎤
⎥
⎥⎦
.
(.)
It is straightforward to see that the solution is
𝐡,( f ) =

[
−e𝚥𝜋f 𝜏(−𝛼,)
]
⎡
⎢
⎢⎣

−e−𝚥𝜋f 𝜏𝛼,
e−𝚥𝜋f 𝜏𝛼,
⎤
⎥
⎥⎦
.
(.)
Because of the diﬀerent particular constraints, it is obvious that the beampattern has
the form:

[
𝐡,( f ), cos 𝜃
]
=
[
−e𝚥𝜋f 𝜏(cos 𝜃−𝛼,)
]
[
−e𝚥𝜋f 𝜏(−𝛼,)
].
(.)
With assumption (i) and the approximation in (.), we can rewrite this beampattern
as

[
𝐡,( f ), cos 𝜃
]
≈

(−𝛼,
)
(
cos 𝜃−𝛼,
),
(.)
which is the expected result.
We ﬁnd that the WNG is
[𝐡,( f )] = 

|||−e𝚥𝜋f 𝜏(−𝛼,)|||

(.)
= 

{−cos [𝜋f 𝜏
(−𝛼,
)]},
which can be approximated as
[𝐡,( f )] ≈

[𝜋f 𝜏
(−𝛼,
)].
(.)
The WNG of the beamformer with second-order design is much worse than the WNG
of the beamformer with ﬁrst-order design.

340
Fundamentals of Signal Enhancement and Array Signal Processing
9.7.2
Design Examples
In this section, we design and compare two second-order DSAs. The ﬁrst is a second-
order cardioid with 𝐡,( f ) and 𝛼,= −, which has a unique multiple null at 𝜃= 𝜋. The
second DSA is a second-order cardioid with 𝐡( f ), 𝛼,= −, 𝛽,= , 𝛼,= , 𝛽,= ,
which has two distinct nulls at 𝜃= 𝜋
and 𝜋.
Figures .and .display the patterns of the two second-order cardioids for low
and high frequencies and two values of 𝛿. As long as the sensor spacing is small, the
beampatterns of the second-order DSAs are frequency independent. When the sensor
spacing is too large, the beampatterns at high frequencies deteriorate.
Figure .shows plots of the DFs of the two second-order cardioids, [𝐡,( f )] and

[
𝐡( f )
]
, as a function of frequency for several values of 𝛿. Corresponding plots of the
WNG, [𝐡,( f )] and [𝐡( f )], as a function of frequency are depicted in Figure ..
We observe that the DF of the second-order cardioid with two distinct nulls is higher
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
Figure 9.10 Beampatterns of the second-order cardioid, h2,0( f), with a unique multiple null at 𝜃= 𝜋,
for low and high frequencies, and two values of 𝛿: (a) f = 0.5 kHz, 𝛿= 1 cm, (b) f = 7 kHz, 𝛿= 1 cm, (c)
f = 0.5 kHz, 𝛿= 4 cm, and (d) f = 7 kHz, 𝛿= 4 cm.
www.ebook3000.com

Differential Beamforming
341
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−10 dB
−20 dB
−30 dB
−40 dB
−20 dB
Figure 9.11 Beampatterns of the second-order cardioid, 𝗵2( f), with two distinct nulls at 𝜃= 𝜋
2 and 𝜋,
for low and high frequencies, and two values of 𝛿: (a) f = 0.5 kHz, 𝛿= 1 cm, (b) f = 7 kHz, 𝛿= 1 cm,
(c) f = 0.5 kHz, 𝛿= 4 cm, and (d) f = 7 kHz, 𝛿= 4 cm.
than that of the second-order cardioid with a unique multiple null, but at the expense of
lower WNG. Furthermore, similar to the ﬁrst-order DSAs, increasing the sensor spacing
enables the WNG to be increased, especially at low frequencies. However, a large value
of 𝛿contradicts the DSA assumption, which results in deterioration of the beampatterns
at high frequencies. Therefore, the value of 𝛿should be a compromise between white
noise ampliﬁcation at low frequencies and a frequency-independent directivity pattern
at high frequencies.
9.8
Third-order Design
9.8.1
Principle
We start this section by deriving an important family of third-order diﬀerential beam-
formers, the beampatterns of which have three distinct nulls. This can be done with

342
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
8
−10
−5
0
5
10
0
2
4
6
8
−10
−5
0
5
10
f (kHz)
f (kHz)
[h2,0( f )] (dB)
[h2( f )] (dB)
(a)
(b)
Figure 9.12 DF of second-order DSAs as a function of frequency, for several values of 𝛿: 𝛿= 1 cm
(solid line with circles), 𝛿= 2 cm (dashed line with asterisks), 𝛿= 3 cm (dotted line with squares), and
𝛿= 4 cm (dash-dot line with triangles). (a) Second-order cardioid, 𝗵2,0( f), with a unique multiple null
at 𝜃= 𝜋, and (b) second-order cardioid, 𝗵2( f), with two distinct nulls at 𝜃= 𝜋
2 and 𝜋.
f (kHz)
f (kHz)
0
2
4
6
8
−50
−40
−30
−20
−10
0
10
0
2
4
6
8
−50
−40
−30
−20
−10
0
10
[h2( f )] (dB)
[h2,0( f )] (dB)
(a)
(b)
Figure 9.13 WNG of second-order DSAs as a function of frequency, for several values of 𝛿: 𝛿= 1 cm
(solid line with circles), 𝛿= 2 cm (dashed line with asterisks), 𝛿= 3 cm (dotted line with squares), and
𝛿= 4 cm (dash-dot line with triangles). (a) Second-order cardioid, 𝗵2,0( f), with a unique multiple null
at 𝜃= 𝜋, and (b) second-order cardioid, 𝗵2( f), with two distinct nulls at 𝜃= 𝜋
2 and 𝜋.
exactly four omnidirectional sensors. It is clear that the linear system of four equations
tailored for the derivation of such beamformers is
⎡
⎢
⎢
⎢⎣
𝐝H (f , )
𝐝H (f , 𝛼,
)
𝐝H (f , 𝛼,
)
𝐝H (
f , 𝛼,
)
⎤
⎥
⎥
⎥⎦
𝐡( f ) =
⎡
⎢
⎢
⎢⎣




⎤
⎥
⎥
⎥⎦
,
(.)
where −≤𝛼,= cos 𝜃,< , −≤𝛼,= cos 𝜃,< , −≤𝛼,= cos 𝜃,< , and
𝛼,≠𝛼,≠𝛼,. We denote by
www.ebook3000.com

Differential Beamforming
343
𝐕( f ) =
⎡
⎢
⎢
⎢⎣
𝐝H (f , )
𝐝H (f , 𝛼,
)
𝐝H (
f , 𝛼,
)
𝐝H (f , 𝛼,
)
⎤
⎥
⎥
⎥⎦
=
⎡
⎢
⎢
⎢⎣

v( f )
v
( f )
v
( f )

v( f )
v
( f )
v
( f )

v( f )
v
( f )
v
( f )

v( f )
v
( f )
v
( f )
⎤
⎥
⎥
⎥⎦
(.)
the × Vandermonde matrix that appears in (.), where v( f ) = e𝚥𝜋f 𝜏, v( f ) =
e𝚥𝜋f 𝜏𝛼,, v( f ) = e𝚥𝜋f 𝜏𝛼,, and v( f ) = e𝚥𝜋f 𝜏𝛼,. Because of the structure of the vector
on the right-hand side of (.), we only need to compute the ﬁrst column of 𝐕−( f ) to
ﬁnd 𝐡( f ). Using the decomposition 𝐕−( f ) = 𝐔( f )𝐋( f ) [], the matrix 𝐔( f ), and the
ﬁrst column of 𝐋( f ), we ﬁnd that the ﬁrst column of 𝐕−( f ) is
𝐕−(
f ; ∶, 
)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢⎣
vvv
(
v−v
) (
v−v
) (
v−v
)
−
vv+ vv+ vv
(v−v
) (v−v
) (v−v
)
v+ v+ v
(v−v
) (v−v
) (v−v
)
−

(v−v
) (v−v
) (v−v
)
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥⎦
.
(.)
From the previous expression, we easily ﬁnd that the solution is
𝐡( f ) =

[
−e𝚥𝜋f 𝜏(−𝛼,)
] [
−e𝚥𝜋f 𝜏(−𝛼,)
] [
−e𝚥𝜋f 𝜏(−𝛼,)
]
×
⎡
⎢
⎢
⎢⎣

−e−𝚥𝜋f 𝜏𝛼,−e−𝚥𝜋f 𝜏𝛼,−e−𝚥𝜋f 𝜏𝛼,
e−𝚥𝜋f 𝜏(𝛼,+𝛼,) + e−𝚥𝜋f 𝜏(𝛼,+𝛼,) + e−𝚥𝜋f 𝜏(𝛼,+𝛼,)
−e−𝚥𝜋f 𝜏(𝛼,+𝛼,+𝛼,)
⎤
⎥
⎥
⎥⎦
.
(.)
Now, let us derive diﬀerential beamformers with beampatterns having a unique null
in the direction 𝛼,with multiplicity . Using the facts that
d
[
𝐡( f ), 𝛼
]
d𝛼
|||||𝛼=𝛼,
= 𝚥𝜋f 𝜏
[𝚺𝐝(f , 𝛼,
)]H 𝐡( f ) = 
(.)
and
d
[
𝐡( f ), 𝛼
]
d𝛼
|||||𝛼=𝛼,
= (𝚥𝜋f 𝜏
)[𝚺𝐝(f , 𝛼,
)]H 𝐡( f ) = ,
(.)

344
Fundamentals of Signal Enhancement and Array Signal Processing
where
𝚺= diag (, , , )
(.)
is a diagonal matrix, we easily ﬁnd that the linear system to solve is
⎡
⎢
⎢
⎢
⎢⎣
𝐝H (f , )
𝐝H (f , 𝛼,
)
[𝚺𝐝(f , 𝛼,
)]H
[𝚺𝐝(f , 𝛼,
)]H
⎤
⎥
⎥
⎥
⎥⎦
𝐡( f ) =
⎡
⎢
⎢
⎢⎣




⎤
⎥
⎥
⎥⎦
.
(.)
We deduce that the solution is
𝐡,( f ) =

[
−e𝚥𝜋f 𝜏(−𝛼,)
]
⎡
⎢
⎢
⎢⎣

−e−𝚥𝜋f 𝜏𝛼,
e−𝚥𝜋f 𝜏𝛼,
−e−𝚥𝜋f 𝜏𝛼,
⎤
⎥
⎥
⎥⎦
.
(.)
The beampattern corresponding to the beamformer 𝐡,( f ) is
[𝐡,( f ), cos 𝜃] =
[
−e 𝚥𝜋f 𝜏(cos 𝜃−𝛼,)
]
[
−e 𝚥𝜋f 𝜏(−𝛼,)
]
(.)
and can be approximated as
[𝐡,( f ), cos 𝜃] ≈

(
−𝛼,
)
(cos 𝜃−𝛼,
),
(.)
which is identical to the theoretical third-order DSA beampattern with a unique null
with multiplicity .
The WNG is

[
𝐡,( f )
]
= 

|||−e𝚥𝜋f 𝜏(−𝛼,)|||

(.)
= 

{
−cos
[
𝜋f 𝜏
(
−𝛼,
)]},
which we can approximate as
[𝐡,( f )] ≈

[𝜋f 𝜏
(−𝛼,
)].
(.)
The generalization of the beamformers 𝐡( f ) and 𝐡,( f ) to any order is
straightforward.
www.ebook3000.com

Differential Beamforming
345
It is also possible to derive diﬀerential beamformers directly from some of the
performance measures. There are two possibilities.
The ﬁrst beamformer is obtained by maximizing the DF as deﬁned in (.). Consid-
ering the distortionless constraint, we easily get the hypercardioid of order M −:
𝐡Hd( f ) =
𝚪−
,𝜋( f )𝐝
(
f , 
)
𝐝H (f , ) 𝚪−
,𝜋( f )𝐝(f , ),
(.)
which is the superdirective beamformer described in Chapter .
The second diﬀerential beamformer is obtained by maximizing the FBR as deﬁned in
(.). If we denote by 𝐭( f ) the eigenvector corresponding to the maximum eigenvalue
of the matrix 𝚪−
𝜋∕,𝜋( f )𝚪,𝜋∕( f ) and taking into account the distortionless constraint,
we get the supercardioid of order M −:
𝐡Sd( f ) =
𝐭( f )
𝐝H (
f , 
)
𝐭( f )
.
(.)
9.8.2
Design Examples
In this section, we design and compare four third-order DSAs. The ﬁrst is a third-order
cardioid with 𝐡,( f ) and 𝛼,= −, and has a unique multiple null at 𝜃= 𝜋. The second
DSA is a third-order DSA with 𝐡( f ), 𝛼,= , 𝛼,= −
, and 𝛼,= −, and has
three distinct nulls at 𝜃= 𝜋
, 𝜋
and 𝜋. The third and fourth DSAs are, respectively, the
third-order hypercardioid with 𝐡Hd( f ) and the third-order supercardioid with 𝐡Sd( f ).
Figures .–.display the patterns of the four third-order DSAs for low and high
frequencies and two values of 𝛿. As long as the sensor spacing is small, the beampatterns
of the third-order DSAs are frequency independent. When the sensor spacing is too
large, the beampatterns at high frequencies deteriorate.
Figure .shows plots of the DFs of the four third-order DSAs, [𝐡,( f )], [𝐡( f )],
[𝐡Hd( f )], and [𝐡Sd( f )], as a function of frequency for several values of 𝛿. Corre-
sponding plots of the WNG, [𝐡,( f )], [𝐡( f )], [𝐡Hd( f )], and [𝐡Sd( f )], as
a function of frequency are depicted in Figure .. We observe that the highest DF
is obtained with the third-order hypercardioid, but at the cost of the lowest WNG.
The highest WNG is obtained with the third-order cardioid that has a unique multiple
null, but at the cost of the lowest DF. The DF of the third-order cardioid with three
distinct nulls is higher than that of the third-order cardioid with a unique multiple null,
but at the expense of lower WNG. Furthermore, similar to the ﬁrst- and second-order
DSAs, increasing the sensor spacing enables the WNG to be increased, especially at
low frequencies. However, a large value of 𝛿contradicts the DSA assumption, which
results in deterioration of the beampatterns at high frequencies. Therefore, the value of
𝛿should be a compromise between white noise ampliﬁcation at low frequencies and a
frequency-independent directivity pattern at high frequencies.

346
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−10 dB
−20 dB
−30 dB
−40 dB
Figure 9.14 Beampatterns of the third-order cardioid, 𝗵3,0( f), with a unique multiple null at 𝜃= 𝜋, for
low and high frequencies, and two values of 𝛿: (a) f = 0.5 kHz, 𝛿= 1 cm, (b) f = 7 kHz, 𝛿= 1 cm,
(c) f = 0.5 kHz, 𝛿= 4 cm, and (d) f = 7 kHz, 𝛿= 4 cm.
9.9
Minimum-norm Beamformers
9.9.1
Principle
In the three previous sections, we could see that the major drawback of DSAs is white
noise ampliﬁcation. As the order increases, the ampliﬁcation of white noise worsens.
The best way to deal with this fundamental problem is to disconnect the order of the
DSAs from the number of sensors and increase the latter for a ﬁxed order. Consequently,
we can use this degree of freedom to maximize the WNG [].
We know from the previous sections that any DSA of order N can be designed by
solving the linear system of N + equations:
𝐃
(
f , 𝜶
)
𝐡( f ) = 𝜷,
(.)
www.ebook3000.com

Differential Beamforming
347
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−20 dB
−10 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
Figure 9.15 Beampatterns of the third-order DSA, 𝗵3( f), with three distinct nulls at 𝜃= 𝜋
2 , 2𝜋
3 , and 𝜋,
for low and high frequencies, and two values of 𝛿: (a) f = 0.5 kHz, 𝛿= 1 cm, (b) f = 7 kHz, 𝛿= 1 cm,
(c) f = 0.5 kHz, 𝛿= 4 cm, and (d) f = 7 kHz, 𝛿= 4 cm.
where
𝐃
(
f , 𝜶
)
=
⎡
⎢
⎢
⎢⎣
𝐝H (f , )
𝐝H (f , 𝛼N,
)
⋮
𝐝H (f , 𝛼N,N
)
⎤
⎥
⎥
⎥⎦
(.)
is the constraint matrix of size (N + ) × M, M is the number of sensors,
𝐝
(
f , 𝛼N,n
)
=
[ 
e−𝚥𝜋f 𝜏𝛼N,n
⋯
e−𝚥(M−)𝜋f 𝜏𝛼N,n ]T ,
n = , , … , N
(.)

348
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
−20 dB
−30 dB
−40 dB
Figure 9.16 Beampatterns of the third-order hypercardioid, 𝗵Hd( f), for low and high frequencies, and
two values of 𝛿: (a) f = 0.5 kHz, 𝛿= 1 cm, (b) f = 7 kHz, 𝛿= 1 cm, (c) f = 0.5 kHz, 𝛿= 4 cm, and
(d) f = 7 kHz, 𝛿= 4 cm.
is a steering vector of length M,
𝐡( f ) =
[ H( f )
H( f )
⋯
HM( f ) ]T
(.)
is a ﬁlter of length M, and
𝜶= [ 
𝛼N,
⋯
𝛼N,N
]T ,
(.)
𝜷=
[ 
𝛽N,
⋯
𝛽N,N
]T ,
(.)
are vectors of length N + containing the design coeﬃcients of the directivity pattern.
In previous sections, only the case M = N + was considered. This is also the case in
all known approaches in the literature []. But, obviously from (.), nothing prevents
us from taking M > N + .
www.ebook3000.com

Differential Beamforming
349
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−20 dB
−30 dB
−30 dB
−40 dB
−40 dB
−10 dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−10 dB
−20 dB
−10 dB
−20 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
Figure 9.17 Beampatterns of the third-order supercardioid, 𝗵Sd( f), for low and high frequencies, and
two values of 𝛿: (a) f = 0.5 kHz, 𝛿= 1 cm, (b) f = 7 kHz, 𝛿= 1 cm, (c) f = 0.5 kHz, 𝛿= 4 cm, and
(d) f = 7 kHz, 𝛿= 4 cm.
Now, assume that M ≥N + , then we can maximize the WNG subject to (.):
min
𝐡( f ) 𝐡H( f )𝐡( f ) subject to 𝐃
(
f , 𝜶
)
𝐡( f ) = 𝜷.
(.)
Obviously, the solution of the above problem is
𝐡MN
(
f , 𝜶, 𝜷
)
= 𝐃H (
f , 𝜶
) [
𝐃
(
f , 𝜶
)
𝐃H (
f , 𝜶
)]−𝜷,
(.)
which is the minimum-norm solution of (.). The vectors 𝜶and 𝜷of length N + 
determine the beampattern and the order of the DSA. Basically, the lengths of these vec-
tors determine (roughly) the order of the DSA while their values determine the beam-
pattern. Meanwhile, the length, M, of the minimum-norm beamformer, 𝐡MN
(f , 𝜶, 𝜷),

350
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
8
−10
−5
0
5
10
(a)
(b)
(c)
(d)
15
0
2
4
6
8
−10
−5
0
5
10
15
0
2
4
6
8
−10
−5
0
5
10
15
0
2
4
6
8
−10
−5
0
5
10
15
f (kHz)
f (kHz)
f (kHz)
f (kHz)
[h3,0( f )] (dB)
[h3( f )] (dB)
[hHd( f )] (dB)
[hSd( f )] (dB)
Figure 9.18 DF of third-order DSAs as a function of frequency, for several values of 𝛿: 𝛿= 1 cm (solid
line with circles), 𝛿= 2 cm (dashed line with asterisks), 𝛿= 3 cm (dotted line with squares), and
𝛿= 4 cm (dash-dot line with triangles). (a) Third-order cardioid, 𝗵3,0( f), with a unique multiple null at
𝜃= 𝜋, (b) third-order DSA, 𝗵3( f), with three distinct nulls at 𝜃= 𝜋
2 , 2𝜋
3 , and 𝜋, (c) third-order
hypercardioid with 𝗵Hd( f), and (d) third-order supercardioid with 𝗵Sd( f).
can be much larger than N + , which will help make it robust against white noise
ampliﬁcation. In this case, the WNG should approach M and the order of the DSA
may not be equal to N anymore, but the Nth-order DSA fundamental constraints will
always be fulﬁlled. Because of this, the resulting shape of the directivity pattern may be
slightly diﬀerent than that obtained with M = N + .
It is easy to see that the beampattern, the WNG, and the DF of the minimum-norm
beamformer are, respectively,

[
𝐡MN
(
f , 𝜶, 𝜷
)
, cos 𝜃
]
= 𝐝H (
f , cos 𝜃
)
𝐡MN
(
f , 𝜶, 𝜷
)
(.)
= 𝐝H (f , cos 𝜃) 𝐃H (f , 𝜶) [𝐃(f , 𝜶) 𝐃H (f , 𝜶)]−𝜷,

[
𝐡MN
(
f , 𝜶, 𝜷
)]
=

𝜷T [
𝐃
(
f , 𝜶
)
𝐃H (
f , 𝜶
)]−𝜷
,
(.)
www.ebook3000.com

Differential Beamforming
351
0
2
4
6
8
−50
−40
−30
−20
−10
0
10
−50
−40
−30
−20
−10
0
10
−50
−40
−30
−20
−10
0
10
−50
−40
−30
−20
−10
0
10
0
2
4
6
8
0
2
4
6
8
0
2
4
6
8
(a)
(b)
(c)
(d)
f (kHz)
f (kHz)
f (kHz)
f (kHz)
[h3,0( f )] (dB)
[hHd( f )] (dB)
[h3( f )] (dB)
[hSd( f )] (dB)
Figure 9.19 WNG of third-order DSAs as a function of frequency, for several values of 𝛿: 𝛿= 1 cm
(solid line with circles), 𝛿= 2 cm (dashed line with asterisks), 𝛿= 3 cm (dotted line with squares), and
𝛿= 4 cm (dash-dot line with triangles). (a) Third-order cardioid, 𝗵3,0( f), with a unique multiple null at
𝜃= 𝜋, (b) third-order DSA, 𝗵3( f), with three distinct nulls at 𝜃= 𝜋
2 , 2𝜋
3 , and 𝜋, (c) third-order
hypercardioid with 𝗵Hd( f), and (d) third-order supercardioid with 𝗵Sd( f).
and
[𝐡MN
(f , 𝜶, 𝜷)] =

𝐡H
MN
(f , 𝜶, 𝜷) 𝚪,𝜋( f )𝐡MN
(f , 𝜶, 𝜷).
(.)
In the same way, we can design a robust DSA with a beampattern having a null in the
direction 𝛼N,with multiplicity N. The constraint equation is
𝐃
(
f , 𝛼N,
)
𝐡( f ) = 𝐢,
(.)

352
Fundamentals of Signal Enhancement and Array Signal Processing
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−20 dB
−20 dB
−20 dB
Figure 9.20 Beampatterns of a third-order DSA with three distinct nulls, 𝗵MN (f, 𝜶, 𝜷), for low and high
frequencies, and two values of M: (a) f = 0.5 kHz, M = 4, (b) f = 7 kHz, M = 4, (c) f = 0.5 kHz, M = 8,
and (d) f = 7 kHz, M = 8.
where
𝐃
(
f , 𝛼N,
)
=
⎡
⎢
⎢
⎢
⎢
⎢⎣
𝐝H (f , )
𝐝H (f , 𝛼N,
)
[𝚺𝐝(f , 𝛼N,
)]H
⋮
[𝚺N−𝐝(f , 𝛼N,
)]H
⎤
⎥
⎥
⎥
⎥
⎥⎦
(.)
is a matrix of size (N + ) × M, 𝐢is the ﬁrst column of the (N + ) × (N + ) identity
matrix, 𝐈N+, and
𝚺= diag (, , … , M −)
(.)
www.ebook3000.com

Differential Beamforming
353
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
180°
0°
30°
60°
120°
150°
180°
210°
240°
300°
330°
(a)
(b)
(c)
(d)
0dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−10 dB
−20 dB
−30 dB
−40 dB
−10 dB
−20 dB
−30 dB
−40 dB
0dB
0dB
0dB
90°
90°
90°
270°
270°
270°
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−10 dB
Figure 9.21 Beampatterns of a third-order cardioid, 𝗵MN,0
(f, 𝛼3,1
), with 𝛼3,1 = −1, for low and high
frequencies, and two values of M: (a) f = 0.5 kHz, M = 4, (b) f = 7 kHz, M = 4, (c) f = 0.5 kHz, M = 8,
and (d) f = 7 kHz, M = 8.
is a diagonal matrix. Assuming that M ≥N + , the maximization of the WNG subject
to (.) leads to the minimum-norm beamformer:
𝐡MN,
(
f , 𝛼N,
)
= 𝐃H

(
f , 𝛼N,
) [
𝐃
(
f , 𝛼N,
)
𝐃H

(
f , 𝛼N,
)]−𝐢.
(.)
9.9.2
Design Examples
In this section, we demonstrate the eﬀectiveness of the minimum-norm ﬁlter in the
design of robust DSAs. Fundamentally, we exploit the fact that we have many more
sensors than the order of the DSA. We design and compare two third-order DSAs with
diﬀerent numbers of sensors. The ﬁrst is a a third-order DSA with three distinct nulls
with 𝐡MN
(f , 𝜶, 𝜷). In this scenario, we have

354
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
8
4
5
6
7
8
9
10
11
0
2
4
6
8
4
5
6
7
8
9
10
11
f (kHz)
f (kHz)
(a)
(b)
[hMN,0 ( f,α3,1)] (dB)
[hMN ( f,α, β)] (dB)
Figure 9.22 DF of third-order DSAs with minimum-norm filters as a function of frequency, for different
values of M: M = 4 (solid line with circles), M = 6 (dashed line with asterisks), M = 8 (dotted line with
squares), and M = 10 (dash-dot line with triangles). (a) Third-order DSA with three distinct nulls,
𝗵MN (f, 𝜶, 𝜷), and (b) third-order cardioid, 𝗵MN,0
(f, 𝛼3,1
), with 𝛼3,1 = −1.
f (kHz)
f (kHz)
0
2
4
6
8
−50
−40
−30
−20
−10
0
10
0
2
4
6
8
−50
−40
−30
−20
−10
0
10
(a)
(b)
[hMN,0 ( f,α3,1)] (dB)
[hMN ( f,α, β)] (dB)
Figure 9.23 WNG of third-order DSAs with minimum-norm filters as a function of frequency, for
different values of M: M = 4 (solid line with circles), M = 6 (dashed line with asterisks), M = 8 (dotted
line with squares), and M = 10 (dash-dot line with triangles). (a) Third-order DSA with three distinct
nulls, 𝗵MN (f, 𝜶, 𝜷), and (b) third-order cardioid, 𝗵MN,0
(f, 𝛼3,1
), with 𝛼3,1 = −1.
𝜶=
[


−

−
]T
,
(.)
𝜷= [ 


]T .
(.)
The second DSA is a third-order cardioid with 𝐡MN,
(f , 𝛼,
) and 𝛼,= −. In both
cases, the interelement spacing is 𝛿= mm.
Figures .and .display the patterns of the two minimum-norm third-order
DSAs for low and high frequencies, and two values of M. At low frequencies, the
www.ebook3000.com

Differential Beamforming
355
Table 9.1 Differential beamformers.
Beamformer
First-order
𝐡( f ) =

−e𝚥𝜋f 𝜏(−𝛼,)
[

−e−𝚥𝜋f 𝜏𝛼,
]
Second-order
𝐡( f ) = 𝐔( f )𝐋( f )
⎡
⎢
⎢
⎢⎣

𝛽,
𝛽,
⎤
⎥
⎥
⎥⎦
𝐡,( f ) =

[
−e𝚥𝜋f 𝜏(−𝛼,)
]
⎡
⎢
⎢
⎢⎣

−e−𝚥𝜋f 𝜏𝛼,
e−𝚥𝜋f 𝜏𝛼,
⎤
⎥
⎥
⎥⎦
Third-order
Equation .
𝐡,( f ) =

[
−e𝚥𝜋f 𝜏(−𝛼,)
]
⎡
⎢
⎢
⎢
⎢
⎢⎣

−e−𝚥𝜋f 𝜏𝛼,
e−𝚥𝜋f 𝜏𝛼,
−e−𝚥𝜋f 𝜏𝛼,
⎤
⎥
⎥
⎥
⎥
⎥⎦
Hypercardioid
𝐡Hd( f ) =
𝚪−
,𝜋( f )𝐝(f , )
𝐝H (f , ) 𝚪−
,𝜋( f )𝐝(f , )
Supercardioid
𝐡Sd( f ) =
𝐭( f )
𝐝H (f , ) 𝐭( f )
Minimum-norm
𝐡MN
(f , 𝜶, 𝜷) = 𝐃H (f , 𝜶) [𝐃(f , 𝜶) 𝐃H (f , 𝜶)]−𝜷
𝐡MN,
(f , 𝛼N,
) =
𝐃H

(f , 𝛼N,
) [𝐃
(f , 𝛼N,
) 𝐃H

(f , 𝛼N,
)]−𝐢
patterns for M = look similar to the patterns for M = . At high frequencies, the
patterns for M = look less directional than the patterns for M = .
Figure .shows plots of the DFs of the two third-order DSAs, [𝐡MN
(f , 𝜶, 𝜷)] and

[
𝐡MN,
(
f , 𝛼,
)]
, as a function of frequency for several values of M. Corresponding
plots of the WNG, [𝐡MN
(f , 𝜶, 𝜷)] and [𝐡MN,
(f , 𝛼,
)], as a function of frequency
are depicted in Figure ..
For M = , the DF is almost constant up to kHz. As M increases, the frequency range
for which the DF is constant decreases, but at high frequencies we can get much higher
WNG than at low frequencies. Increasing the number of sensors enables the WNG to
be increased. However, as the number of sensors increases, the DF at high frequencies
decreases. Furthermore, for a given number of senors, the DF of the third-order DSA
with three distinct nulls is higher than that of the third-order cardioid with a unique
multiple null, but at the expense of lower WNG.
Table .summarizes all DSAs described in this chapter.

356
Fundamentals of Signal Enhancement and Array Signal Processing
Problems
9.1 Using the deﬁnition of the frequency-independent DF of a theoretical Nth-order
DSA (.), show that
(𝐚N
) =
𝐚T
N𝟏𝟏T𝐚N
𝐚T
N𝐇N𝐚N
,
where 𝟏is a vector of ones, and 𝐇N is a Hankel matrix.
9.2 Show that the coeﬃcients of the Nth-order hypercardioid are given by
𝐚N,max =
𝐇−
N 𝟏
𝟏T𝐇−
N 𝟏.
9.3 Using the deﬁnition of the frequency-independent FBR of a theoretical Nth-order
DSA (.), show that

(
𝐚N
)
=
𝐚T
N𝐇′′
N𝐚N
𝐚T
N𝐇′
N𝐚N
,
where 𝐇′
N and 𝐇′′
N are Hankel matrices.
9.4 Show that the beampattern of the Nth-order supercardioid is
N,Sd (cos 𝜃) =
𝐚′T
N,max𝐩(cos 𝜃)
𝐚′T
N,max𝐩()
,
where 𝐚′
N,max is the eigenvector corresponding to the maximum eigenvalue of
𝐇′−
N 𝐇′′
N.
9.5 Show that the directivity pattern of the ﬁrst-order hypercardioid can be expressed
as
,Hd (cos 𝜃) = 
+ 
cos 𝜃.
9.6 Show that the directivity pattern of the ﬁrst-order supercardioid can be expressed
as
,Sd (cos 𝜃) =
√
−

+ −
√


cos 𝜃.
9.7 Show that the directivity pattern of the second-order hypercardioid can be
expressed as
,Hd (cos 𝜃) = −
+ 
cos 𝜃+ 
cos𝜃.
www.ebook3000.com

Differential Beamforming
357
9.8 Show that the directivity pattern of the second-order supercardioid can be
expressed as
,Sd (cos 𝜃) =


(
+
√

) +
√

+
√

cos 𝜃+


(
+
√

) cos𝜃.
9.9 Show that the directivity pattern of the third-order hypercardioid can be
expressed as
,Hd (cos 𝜃) = −
−
cos 𝜃+ 
cos𝜃+ 
cos𝜃.
9.10 Show that the directivity pattern of the third-order supercardioid can be
expressed as
,Sd (cos 𝜃) ≈.+ .cos 𝜃+ .cos𝜃+ .cos𝜃.
9.11 Show that the beampattern, the DF, and the WNG of the ﬁrst-order DSA can be
approximated as
[𝐡( f ), cos 𝜃] ≈

−𝛼,
cos 𝜃−
𝛼,
−𝛼,
,
[𝐡( f )] ≈
(−𝛼,
)
𝛼
,+ 

,
[𝐡( f )] ≈

[𝜋f 𝜏
(−𝛼,
)].
9.12 Show that the inverse of the Vandermonde matrix 𝐕( f ) that appears in (.) is
given by
𝐕−( f ) =
⎡
⎢
⎢
⎢
⎢
⎢
⎢⎣
vv
(v−v
) (v−v
)
−
vv
(v−v
) (v−v
)
vv
(v−v
) (v−v
)
−
v+ v
(v−v
) (v−v
)
v+ v
(v−v
) (v−v
)
−
v+ v
(v−v
) (v−v
)

(v−v
) (v−v
)
−

(v−v
) (v−v
)

(v−v
) (v−v
)
⎤
⎥
⎥
⎥
⎥
⎥
⎥⎦
.
9.13 Show that in the case of a second-order DSA with a zero of multiplicity in the
beampattern:
a) the beamformer is given by
𝐡,( f ) =

[
−e𝚥𝜋f 𝜏(−𝛼,)
]
⎡
⎢
⎢⎣

−e−𝚥𝜋f 𝜏𝛼,
e−𝚥𝜋f 𝜏𝛼,
⎤
⎥
⎥⎦
,

358
Fundamentals of Signal Enhancement and Array Signal Processing
b) the beampattern can be written as
[𝐡,( f ), cos 𝜃] ≈

(−𝛼,
)
(cos 𝜃−𝛼,
),
c) the WNG can be approximated as
[𝐡,( f )] ≈

[𝜋f 𝜏
(−𝛼,
)].
9.14 Show that the ﬁrst column of the inverse of the Vandermonde matrix 𝐕( f ) that
appears in (.) is given by
𝐕−(
f ; ∶, 
)
=
⎡
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢
⎢⎣
vvv
(v−v
) (v−v
) (v−v
)
−
vv+ vv+ vv
(v−v
) (v−v
) (v−v
)
v+ v+ v
(v−v
) (v−v
) (v−v
)
−

(v−v
) (v−v
) (v−v
)
⎤
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥
⎥⎦
.
9.15 Show that the third-order DSA beamformer is given by
𝐡( f ) =

[
−e𝚥𝜋f 𝜏(−𝛼,)
] [
−e𝚥𝜋f 𝜏(−𝛼,)
] [
−e𝚥𝜋f 𝜏(−𝛼,)
]
×
⎡
⎢
⎢
⎢⎣

−e−𝚥𝜋f 𝜏𝛼,−e−𝚥𝜋f 𝜏𝛼,−e−𝚥𝜋f 𝜏𝛼,
e−𝚥𝜋f 𝜏(𝛼,+𝛼,) + e−𝚥𝜋f 𝜏(𝛼,+𝛼,) + e−𝚥𝜋f 𝜏(𝛼,+𝛼,)
−e−𝚥𝜋f 𝜏(𝛼,+𝛼,+𝛼,)
⎤
⎥
⎥
⎥⎦
.
9.16 Show that in the case of a third-order DSA with a zero of multiplicity in the
beampattern:
a) the beamformer is given by
𝐡,( f ) =

[
−e𝚥𝜋f 𝜏(−𝛼,)
]
⎡
⎢
⎢
⎢⎣

−e−𝚥𝜋f 𝜏𝛼,
e−𝚥𝜋f 𝜏𝛼,
−e−𝚥𝜋f 𝜏𝛼,
⎤
⎥
⎥
⎥⎦
,
b) the beampattern can be approximated as

[
𝐡,( f ), cos 𝜃
]
≈

(−𝛼,
)
(
cos 𝜃−𝛼,
),
www.ebook3000.com

Differential Beamforming
359
c) the WNG can be approximated as
[𝐡,( f )] ≈

[𝜋f 𝜏
(−𝛼,
)].
9.17 Show that for M ≥N + , the minimum-norm beamformer maximizes the WNG
subject to 𝐃
(
f , 𝜶
)
𝐡( f ) = 𝜷, and is given by
𝐡MN
(
f , 𝜶, 𝜷
)
= 𝐃H (
f , 𝜶
) [
𝐃
(
f , 𝜶
)
𝐃H (
f , 𝜶
)]−𝜷.
9.18 Show that the beampattern, the WNG, and the DF of the minimum-norm
beamformer are given by
[𝐡MN
(f , 𝜶, 𝜷) , cos 𝜃] = 𝐝H (f , cos 𝜃) 𝐃H (f , 𝜶) ×
[𝐃(f , 𝜶) 𝐃H (f , 𝜶)]−𝜷,
[𝐡MN
(f , 𝜶, 𝜷)] =

𝜷T [𝐃(f , 𝜶) 𝐃H (f , 𝜶)]−𝜷
,
[𝐡MN
(f , 𝜶, 𝜷)] =

𝐡H
MN
(f , 𝜶, 𝜷) 𝚪,𝜋( f )𝐡MN
(f , 𝜶, 𝜷).
9.19 Show that the minimum-norm beamformer whose beampattern has a null in the
direction 𝛼N,with multiplicity N is given by
𝐡MN,
(f , 𝛼N,
) = 𝐃H

(f , 𝛼N,
) [𝐃
(f , 𝛼N,
) 𝐃H

(f , 𝛼N,
)]−𝐢.
References
1 J. Benesty, J. Chen, and Y. Huang, Microphone Array Signal Processing. Berlin,
Germany: Springer-Verlag, .
2 G. W. Elko and J. Meyer, “Microphone arrays,” in Springer Handbook of Speech
Processing, J. Benesty, M. M. Sondhi, and Y. Huang (eds). Berlin, Germany:
Springer-Verlag, , Chapter , pp. –.
3 G. W. Elko, “Superdirectional microphone arrays,” in Acoustic Signal Processing for
Telecommunication, S. L. Gay and J. Benesty (eds). Boston, MA: Kluwer Academic
Publishers, , Chapter , pp. –.
4 J. Benesty and J. Chen, Study and Design of Diﬀerential Microphone Arrays. Berlin,
Germany: Springer-Verlag, .
5 J. Chen, J. Benesty, and C. Pan “On the design and implementation of linear diﬀerential
microphone arrays,” J. Acoust. Soc. Am., vol. , pp. –, Dec. .
6 R. N. Marshall and W. R. Harry, “A new microphone providing uniform directivity over
an extended frequency range,” J. Acoust. Soc. Am., vol. , pp. –, .
7 A. I. Uzkov, “An approach to the problem of optimum directive antenna design,”
Comptes Rendus (Doklady) de l’Academie des Sciences de l’URSS, vol. LIII, no. ,
pp. –, .

361
10
Beampattern Design
We again assume that we have a uniform linear array (ULA). Because of the symmetry
of the steering vector associated with a ULA, the only directions where we can
design a symmetric beampattern are at the endﬁres (i.e., and 𝜋). Since we are
interested in frequency-invariant beampatterns, the distance between two succes-
sive sensors must be small, as explained in Chapter . This makes sense since, con-
trary to many approaches proposed in the literature, we can now design any desired
frequency-invariant symmetric beampattern without any speciﬁc constraints. There-
fore, the beampatterns that we outline in this chapter are similar to those obtained with
diﬀerential sensor arrays (DSAs). After revisiting the deﬁnitions of the beampatterns
and showing some relationships between them, we explain the diﬀerent techniques for
beampattern design.
10.1
Beampatterns Revisited
From Chapter , we know that the beampattern corresponding to a ﬁlter 𝐡( f ), of length
M, applied to a ULA is
[𝐡( f ), cos 𝜃] = 𝐝H (f , cos 𝜃) 𝐡( f )
(.)
=
M
∑
m=
Hm( f )e𝚥f m cos 𝜃,
where we deﬁne
f m = 𝜋𝛿
c (m −)f
(.)
= 𝜋𝜏(m −)f
to simplify the notation. We recall that 𝐡( f ) is designed so that the array looks in the
direction 𝜃= (or 𝜃= 𝜋). For a ﬁxed 𝐡( f ), it is obvious that [𝐡( f ), cos 𝜃] is even and
periodic with respect to the variable 𝜃:

[
𝐡( f ), cos (−𝜃)
]
= 
[
𝐡( f ), cos 𝜃
]
(.)
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing
www.ebook3000.com

362
Fundamentals of Signal Enhancement and Array Signal Processing
and
[𝐡( f ), cos (𝜃+ 𝜋)
] = [𝐡( f ), cos 𝜃] .
(.)
As a result, the analysis and design of a desired beampattern is limited to 𝜃∈[, 𝜋].
Let (𝜃) be a real even periodic function with period 𝜋and such that ∫𝜋
|(𝜃)| d𝜃
exists. In this case, it is well known that (𝜃) can be written in terms of its Fourier cosine
series []:
(𝜃) =
∞
∑
n=
bn cos (n𝜃) ,
(.)
where
⎧
⎪
⎪
⎨
⎪
⎪⎩
b= 
𝜋∫
𝜋

(𝜃) d𝜃
bi = 
𝜋∫
𝜋

(𝜃) cos (i𝜃) d𝜃,
i ≥
.
Now, if we limit this series to order N, (𝜃) can be approximated by [, ]:
(𝐛N, cos 𝜃) =
N
∑
n=
bN,n cos (n𝜃)
(.)
= 𝐛T
N𝐩C (cos 𝜃) ,
where bN,n, n = , , … , N are real coeﬃcients and
𝐛N = [ bN,
bN,
⋯
bN,N
]T ,
𝐩C (cos 𝜃) =
[ 
cos 𝜃
⋯
cos (N𝜃) ]T ,
are vectors of length N+. The function (𝐛N, cos 𝜃) is, in fact, a very general deﬁnition
of a frequency-independent directivity pattern of order N. It is very much related to the
directivity pattern of the Nth-order DSA deﬁned in Chapter :

(
𝐚N, cos 𝜃
)
=
N
∑
n=
aN,n cosn 𝜃
(.)
= 𝐚T
N𝐩(cos 𝜃) ,
and any DSA beampattern can be designed with 
(
𝐛N, cos 𝜃
)
. Indeed, we know from
the usual trigonometric identities that
cosn 𝜃=
∑
i
b(n, i) cos [(n −i) 𝜃] ,
(.)

Beampattern Design
363
where b(n, i) are binomial coeﬃcients. Substituting (.) into (.), we deduce that
any DSA beampattern can be written as a general beampattern, (𝐛N, cos 𝜃). It is well
known that
cos (n𝜃) = Tn (cos 𝜃) ,
(.)
where Tn (⋅) is the nth Chebyshev polynomial of the ﬁrst kind [], which has the
recurrence relation:
Tn+(cos 𝜃) = cos 𝜃× Tn (cos 𝜃) −Tn−(cos 𝜃) ,
(.)
with
{
T(cos 𝜃) = 
T(cos 𝜃) = cos 𝜃
.
Thus, cos (n𝜃) can be expressed as a sum of powers of cos 𝜃. Consequently, any gen-
eral beampattern can be written as a DSA beampattern. We can then conclude that
(𝐛N, cos 𝜃) and (𝐚N, cos 𝜃) are strictly equivalent. An even more general deﬁnition
of a frequency-independent beampattern with orthogonal polynomials can be found in
the paper by Pan et al. []. Basically, this shows that any even periodic function (here
a desired beampattern) can be designed or approximated by its Fourier cosine series,
which also corresponds to the theoretical Nth-order DSA beampattern.
For convenience, we give the relations between the coeﬃcients bN,n, n = , , … , N
of (𝐛N, cos 𝜃) and the coeﬃcients aN,n, n = , , … , N of (𝐚N, cos 𝜃) for the ﬁrst
three orders:
●N = : b,= a,, b,= a,;
●N = : b,= a,+
a,
, b,= a,, b,=
a,
; and
●N = : b,= a,+
a,
, b,= a,+
a,
, b,=
a,
, b,=
a,
.
Now, in order to be able to design any desired beampattern, 
(
𝐛N, cos 𝜃
)
, with
[𝐡( f ), cos 𝜃], where 𝐡( f ) needs to be found accordingly, we have to approximate
the exponential function that appears in (.) in terms of Chebyshev polynomials, as
will become clearer soon. Since the complex-valued exponential function is inﬁnitely
diﬀerentiable and even with respect to the variable 𝜃, we can ﬁnd the complex-valued
coeﬃcients cn, n = , , , … such that
e𝚥f m cos 𝜃= lim
N→∞
N
∑
n=
cn cos (n𝜃) .
(.)
By limiting the above series to a ﬁxed N, we propose to ﬁnd the coeﬃcients cn,
n = , , … , N, in the best possible way in a least-squares error (LSE) sense, by
minimizing the criterion:
LSE (𝐜N
) = 
𝜋∫
𝜋

||||||
e−𝚥f m cos 𝜃−
N
∑
n=
c∗
n cos (n𝜃)
||||||

d𝜃
(.)
www.ebook3000.com

364
Fundamentals of Signal Enhancement and Array Signal Processing
= 
𝜋∫
𝜋

|||e−𝚥f m cos 𝜃−𝐜H
N𝐩C (cos 𝜃)|||

d𝜃
= −𝐯H
C
(
𝚥f m
)
𝐜N −𝐜H
N𝐯C
(
𝚥f m
)
+ 𝐜H
N𝐌C𝐜N,
where
𝐜N = [ c
c
⋯
cN
]T ,
𝐯C
(
𝚥f m
)
= 
𝜋∫
𝜋

e𝚥f m cos 𝜃𝐩C (cos 𝜃) d𝜃,
𝐌C = 
𝜋∫
𝜋

𝐩C (cos 𝜃) 𝐩T
C (cos 𝜃) d𝜃.
The minimization of the LSE criterion gives the optimal solution:
𝐜N = 𝐌−
C 𝐯C
(
𝚥f m
)
.
(.)
Let us have a closer look at 𝐯C
(
𝚥f m
)
and 𝐌C. The elements of the vector 𝐯C
(
𝚥f m
)
are
[
𝐯C
(
𝚥f m
)]
n+= 
𝜋∫
𝜋

e𝚥f m cos 𝜃cos (n𝜃) d𝜃
(.)
= In
(
𝚥f m
)
= 𝚥nJn
(
f m
)
,
with n = , , … , N, where
In (z) = 
𝜋∫
𝜋

ez cos 𝜃cos (n𝜃) d𝜃
(.)
is the integral representation of the modiﬁed Bessel function of the ﬁrst kind [] and
Jn (z) = 𝚥−n
𝜋∫
𝜋

e𝚥z cos 𝜃cos (n𝜃) d𝜃
(.)
= 𝚥−nIn (𝚥z)
is the integral representation of the Bessel function of the ﬁrst kind []. The elements of
the matrix 𝐌C are
[𝐌C
]
i+,j+= 
𝜋∫
𝜋

cos (i𝜃) cos (j𝜃) d𝜃,
(.)

Beampattern Design
365
with i, j = , , … , N. It can be checked that
⎧
⎪
⎨
⎪⎩
[𝐌C
]
,= ,
[𝐌C
]
i+,i+= 
,
i ≥
[
𝐌C
]
i+,j+= ,
i ≠j
.
This is a consequence of the fact that Chebyshev polynomials are orthogonal. Therefore,
the matrix 𝐌C is diagonal:
𝐌C = diag
(
, 
, … , 

)
.
(.)
We deduce that the exponential function given in (.) can be expressed as []:
e𝚥f m cos 𝜃= J
(
f m
)
+ 
∞
∑
n=
𝚥nJn
(
f m
)
cos (n𝜃)
=
∞
∑
n=
𝚥nJn
(
f m
)
cos (n𝜃) ,
(.)
where
𝚥n =
{
,
n = 
𝚥n,
n = , , … , N
.
Equation .is actually the well-known Jacobi–Anger expansion [, ], which repre-
sents an expansion of plane waves into a series of cylindrical waves. Using (.) in the
deﬁnition of the beampattern corresponding to 𝐡( f ), we obtain
[𝐡( f ), cos 𝜃] =
M
∑
m=
Hm( f )e𝚥f m cos 𝜃
=
M
∑
m=
Hm( f )
∞
∑
n=
𝚥nJn
(
f m
)
cos (n𝜃)
=
∞
∑
n=
cos (n𝜃)
[ M
∑
m=
𝚥nJn
(
f m
)
Hm( f )
]
.
(.)
If we limit the expansion to the order N, [𝐡( f ), cos 𝜃] can be approximated by
N
[
𝐡( f ), cos 𝜃
]
=
N
∑
n=
cos (n𝜃)
[ M
∑
m=
𝚥nJn
(
f m
)
Hm( f )
]
.
(.)
For m = , f = , so that J
(
f 
)
= and Jn
(
f 
)
= , n = , , … , N. We will see how
to use (.) in order to design any desired symmetric beampattern or, equivalently,
any desired DSA beampattern of any order. Next, we explain the diﬀerent approaches
used.
www.ebook3000.com

366
Fundamentals of Signal Enhancement and Array Signal Processing
10.2
Nonrobust Approach
In the nonrobust approach, it is always assumed that the number of sensors is equal to
the order plus : M = N + . This is how all DSA beampatterns have been traditionally
designed [, ]. Because of this relation between the number of sensors and the DSA
order, the white noise ampliﬁcation problem gets much worse quickly as the order
increases; in this sense, this technique is a nonrobust one.
The beampattern in (.) can be rewritten as
M−
[
𝐡( f ), cos 𝜃
]
=
M−
∑
i=
cos (i𝜃) 𝐛
T
i ( f )𝐡( f ),
(.)
where M ≥and
𝐛i( f ) = 𝚥i
[
Ji
(
f 
)
Ji
(
f 
)
⋯
Ji
(
f M
) ]T
.
(.)
In the proposed beampattern design, we would like to ﬁnd the ﬁlter 𝐡( f ) in such a
way that M−
[𝐡( f ), cos 𝜃] is an (M−)th-order frequency-invariant DSA beampattern;
that is,
M−
[𝐡( f ), cos 𝜃] = (𝐛M−, cos 𝜃) ,
(.)
where (𝐛M−, cos 𝜃) is deﬁned in (.). By simple identiﬁcation, we easily ﬁnd that
𝐁M−( f )𝐡( f ) = 𝐛M−,
(.)
where
𝐁M−( f ) =
⎡
⎢
⎢
⎢
⎢⎣
𝐛
T
( f )
𝐛
T
( f )
⋮
𝐛
T
M−( f )
⎤
⎥
⎥
⎥
⎥⎦
(.)
is an M × M matrix. Assuming that 𝐁M−( f ) is a full-rank matrix, we ﬁnd that the
nonrobust ﬁlter for beampattern design is
𝐡NR( f ) = 𝐁
−
M−( f )𝐛M−.
(.)
Let us take the example of M = . It is easy to check that

[𝐡( f ), cos 𝜃] = H( f ) + J
(
f 
)
H( f ) + 𝚥J
(
f 
)
H( f ) cos 𝜃,
(.)

(
𝐛, cos 𝜃
)
= b,+ b,cos 𝜃.
(.)

Beampattern Design
367
Identifying the two previous expressions, we get
H,NR( f ) =
b,
𝚥J
(
f 
)
(.)
and
H,NR( f ) = −J
(
f 
)
H,NR( f ) + b,.
(.)
Therefore, with this approach, we can design any ﬁrst-order DSA beampattern.
Depending on the values of b,and b,we ﬁnd four useful ﬁrst-order DSAs:
●dipole: b,= and b,= 
●cardioid: b,= 
and b,= 

●hypercardioid: b,= 
and b,= 

●supercardioid: b,=
√
−

and b,= −
√


.
Figure .displays the patterns – with 𝐡NR( f ) deﬁned in (.) – of the ﬁrst-order
dipole, cardioid, hypercardioid, and supercardioid for f = kHz and 𝛿= .cm.
Comparing the patterns of Figures .and ., we observe that the designed patterns
have less explicit nulls than the corresponding ﬁrst-order directivity patterns. This
is due to the Jacobi–Anger series approximation. Figure .shows plots of the DF,
[𝐡NR( f )], as a function of frequency, for the dipole, cardioid, hypercardioid, and
supercardioid, and several values of 𝛿. Corresponding plots of the WNG, [𝐡NR( f )], as
a function of frequency are depicted in Figure .. We observe that for a small sensor
spacing, the ﬁrst-order DSAs give an approximately constant DF while the WNG is
negative. The white noise ampliﬁcation is especially high at low frequencies. Increasing
the sensor spacing enables the WNG to be increased, but reduces the DF, especially at
high frequencies. A large value of 𝛿contradicts the DSA assumption, which results in
deterioration of the beampatterns at high frequencies.
10.3
Robust Approach
In the robust scenario, the number of sensors is greater than the DSA order plus :
M > N + . By taking advantage of the fact that we have many more sensors than the
order, we can control white noise ampliﬁcation; in this sense, this technique is a robust
one. Again, we would like to ﬁnd the ﬁlter 𝐡( f ) in such a way that N
[
𝐡( f ), cos 𝜃
]
is an
Nth-order frequency-invariant DSA beampattern; that is,
N
[𝐡( f ), cos 𝜃] = (𝐛N, cos 𝜃) .
(.)
By simple identiﬁcation, we easily ﬁnd that
𝐁N( f )𝐡( f ) = 𝐛N,
(.)
www.ebook3000.com

368
Fundamentals of Signal Enhancement and Array Signal Processing
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.1 Beampatterns of the nonrobust first-order DSAs: (a) dipole, (b) cardioid, (c) hypercardioid,
and (d) supercardioid. M = 2, 𝛿= 0.5 cm, and f = 1 kHz.
where
𝐁N( f ) =
⎡
⎢
⎢
⎢
⎢⎣
𝐛
T
( f )
𝐛
T
( f )
⋮
𝐛
T
N( f )
⎤
⎥
⎥
⎥
⎥⎦
(.)
is now an (N + ) × M matrix. Assuming that 𝐁
H
N( f ) is a full-column rank matrix
and taking the minimum-norm solution of (.), we ﬁnd that the robust ﬁlter for
beampattern design is
𝐡R( f ) = 𝐁
H
N( f )
[
𝐁N( f )𝐁
H
N( f )
]−
𝐛N.
(.)

Beampattern Design
369
0
2
4
6
8
−6
−4
−2
0
2
4
6
f (kHz) 
0
2
4
6
8
f (kHz) 
0
2
4
6
8
f  (kHz) 
0
2
4
6
8
f  (kHz) 
(a)
(b)
(c)
(d)
   [hNR( f )] (dB)
   [hNR( f )] (dB)
   [hNR( f )] (dB)
−6
−4
−2
0
2
4
6
   [hNR( f )] (dB)
−6
−4
−2
0
2
4
6
−6
−4
−2
0
2
4
6
Figure 10.2 DF of the nonrobust first-order DSAs as a function of frequency, for M = 2 and several
values of 𝛿: 𝛿= 0.1 cm (solid line with circles), 𝛿= 1 cm (dashed line with asterisks), 𝛿= 2 cm (dotted
line with squares), and 𝛿= 3 cm (dash-dot line with triangles). (a) Dipole, (b) cardioid,
(c) hypercardioid, and (d) supercardioid.
Let us take the example of the ﬁrst-order case (N = ) with M > . We still want
to ﬁnd the coeﬃcients Hm( f ), m = , , … , M in such a way that 
[
𝐡( f ), cos 𝜃
]
=

(𝐛, cos 𝜃). It is not hard to get
[
J
(
f 
)
J
(
f 
)
⋯
J
(
f M
) ] ⎡
⎢
⎢
⎢⎣
H( f )
H( f )
⋮
HM( f )
⎤
⎥
⎥
⎥⎦
=
b,
𝚥
(.)
and
H( f ) +
M
∑
i=
J
(
f i
)
Hi( f ) = b,.
(.)
www.ebook3000.com

370
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
8
f (kHz) 
0
2
4
6
8
f (kHz) 
0
2
4
6
8
f  (kHz) 
0
2
4
6
8
f  (kHz) 
(a)
−50
−40
−30
−20
−10
0
10
(c)
−50
−40
−30
−20
−10
0
10
(b)
−50
−40
−30
−20
−10
0
10
(d)
−50
−40
−30
−20
−10
0
10
   [hNR( f )] (dB)
   [hNR( f )] (dB)
   [hNR( f )] (dB)
   [hNR( f )] (dB)
Figure 10.3 WNG of the nonrobust first-order DSAs as a function of frequency, for M = 2 and several
values of 𝛿: 𝛿= 0.1 cm (solid line with circles), 𝛿= 1 cm (dashed line with asterisks), 𝛿= 2 cm
(dotted line with squares), and 𝛿= 3 cm (dash-dot line with triangles). (a) Dipole, (b) cardioid,
(c) hypercardioid, and (d) supercardioid.
Taking the minimum-norm solution of (.), it is clear that the ﬁlter coeﬃcients are
as follows:
Hi,R( f ) =
J
(
f i
)
b,
𝚥∑M
j=J

(
f j
), i = , , … , M
(.)
and
H,R( f ) = −
M
∑
i=
J
(
f i
)
Hi,R( f ) + b,.
(.)
The robust ﬁlter, 𝐡R( f ), the components of which are given in (.) and (.), is the
minimum-norm ﬁlter for the design of ﬁrst-order DSA beampatterns. The WNG with
𝐡R( f ) should be much better than that with 𝐡NR( f ).
Figures .–.display the patterns – with 𝐡R( f ) deﬁned in (.) – of the ﬁrst-
order dipole, cardioid, hypercardioid, and supercardioid for f = kHz, 𝛿= .cm,

Beampattern Design
371
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.4 Beampatterns of the robust first-order dipole for f = 1 kHz, 𝛿= 0.5 cm, and several values
of M: (a) M = 2, (b) M = 4, (c) M = 6, and (d) M = 8.
and several values of M. Figure .shows plots of the DF, 
[
𝐡R( f )
]
, as a function
of frequency, for the dipole, cardioid, hypercardioid, and supercardioid, and several
values of M. Corresponding plots of the WNG, [𝐡R( f )], as a function of frequency
are depicted in Figure .. We can see that the WNG is considerably improved as M
increases, while the beampatterns and the DFs do not change much. It is clear that
the WNG with 𝐡R( f ) is much better than that with 𝐡NR( f ). The larger the number of
sensors, the more robust is the ﬁrst-order DSA against white noise ampliﬁcation.
10.4
Frequency-invariant Beampattern Design
Let us deﬁne the criterion:
JFI
[
𝐡( f )
]
= 
𝜋∫
𝜋

|||
[
𝐡( f ), cos 𝜃
]|||

d𝜃
(.)
= 𝐡H( f )𝚪C( f )𝐡( f ),
www.ebook3000.com

372
Fundamentals of Signal Enhancement and Array Signal Processing
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.5 Beampatterns of the robust first-order cardioid for f = 1 kHz, 𝛿= 0.5 cm, and several
values of M: (a) M = 2, (b) M = 4, (c) M = 6, and (d) M = 8.
where
𝚪C( f ) = 
𝜋∫
𝜋

𝐝(f , cos 𝜃) 𝐝H (f , cos 𝜃) d𝜃.
(.)
The (i, j)th (with i, j = , , … , M) element of the M × M matrix 𝚪C( f ) can be computed
as
[
𝚪C( f )
]
i,j = 
𝜋∫
𝜋

e𝚥𝜋f (j−i)𝜏cos 𝜃d𝜃
(.)
= I
[
𝚥𝜋f (j −i)𝜏
]
.

Beampattern Design
373
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.6 Beampatterns of the robust first-order hypercardioid for f = 1 kHz, 𝛿= 0.5 cm, and
several values of M: (a) M = 2, (b) M = 4, (c) M = 6, and (d) M = 8.
In order to design a frequency-invariant beampattern, we can minimize JFI
[
𝐡( f )
]
subject to (.):
min
𝐡( f ) 𝐡H( f )𝚪C( f )𝐡( f ) subject to 𝐁N( f )𝐡( f ) = 𝐛N.
(.)
We easily ﬁnd that the corresponding ﬁlter is
𝐡FI( f ) = 𝚪−
C ( f )𝐁
H
N( f )
[
𝐁N( f )𝚪−
C ( f )𝐁
H
N( f )
]−
𝐛N.
(.)
When it comes to white noise ampliﬁcation, the ﬁlter 𝐡FI( f ) is usually much worse than
the previous two derived ﬁlters 𝐡NR( f ) and 𝐡R( f ).
www.ebook3000.com

374
Fundamentals of Signal Enhancement and Array Signal Processing
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.7 Beampatterns of the robust first-order supercardioid for f = 1 kHz, 𝛿= 0.5 cm, and
several values of M: (a) M = 2, (b) M = 4, (c) M = 6, and (d) M = 8.
To give a better compromise for the level of white noise ampliﬁcation, we can use the
following ﬁlter:
𝐡FI,𝜖( f ) = 𝚪−
C,𝜖( f )𝐁
H
N( f )
[
𝐁N( f )𝚪−
C,𝜖( f )𝐁
H
N( f )
]−
𝐛N,
(.)
where
𝚪C,𝜖( f ) = 𝚪C( f ) + 𝜖𝐈M,
(.)
with 𝜖≥being the regularization parameter. It is clear that 𝐡FI,( f ) = 𝐡FI( f ) and
𝐡FI,∞( f ) = 𝐡R( f ).
Figures .–.display the patterns – with 𝐡FI,𝜖( f ) deﬁned in (.) – of the ﬁrst-
order dipole, cardioid, hypercardioid, and supercardioid for f = kHz, 𝛿= .cm,
M = , and several values of 𝜖. Figure .shows plots of the DF, [𝐡FI,𝜖( f )], as

Beampattern Design
375
0
2
4
6
8
−6
−4
−2
0
2
4
6
f (kHz) 
0
2
4
6
8
f (kHz) 
0
2
4
6
8
f  (kHz) 
0
2
4
6
8
f  (kHz) 
(a)
(b)
(c)
(d)
−6
−4
−2
0
2
4
6
   [hR( f )] (dB)
   [hR( f )] (dB)
   [hR( f )] (dB)
   [hR( f )] (dB)
−6
−4
−2
0
2
4
6
−6
−4
−2
0
2
4
6
Figure 10.8 DF of the robust first-order DSAs as a function of frequency, for 𝛿= 0.5 cm and several
values of M: M = 2 (solid line with circles), M = 4 (dashed line with asterisks), M = 6 (dotted line with
squares), and M = 8 (dash-dot line with triangles). (a) Dipole, (b) cardioid, (c) hypercardioid, and
(d) supercardioid.
a function of frequency, for the dipole, cardioid, hypercardioid, and supercardioid,
and several values of 𝜖. Corresponding plots of the WNG, [𝐡FI,𝜖( f )], as a function
of frequency are depicted in Figure .. We can see that the WNG is considerably
improved as 𝜖increases, while the beampatterns and the DFs do not change much. The
larger the value of 𝜖, the more robust is the frequency-invariant ﬁrst-order DSA against
white noise ampliﬁcation, but at the expense of less explicit nulls.
10.5
Least-squares Method
Let us deﬁne the error signal between the array beampattern and the desired directivity
pattern:

[
𝐡( f ), cos 𝜃
]
= 
[
𝐡( f ), cos 𝜃
]
−
(
𝐛N, cos 𝜃
)
(.)
= 𝐝H (
f , cos 𝜃
)
𝐡( f ) −𝐩T
C (cos 𝜃) 𝐛N.
www.ebook3000.com

376
Fundamentals of Signal Enhancement and Array Signal Processing
0
2
4
6
8
f (kHz) 
0
2
4
6
8
f (kHz) 
0
2
4
6
8
f  (kHz) 
0
2
4
6
8
f  (kHz) 
(a)
−50
−40
−30
−20
−10
0
10
(c)
−50
−40
−30
−20
−10
0
10
   [hR( f )] (dB)
(b)
−50
−40
−30
−20
−10
0
10
(d)
−50
−40
−30
−20
−10
0
10
   [hR( f )] (dB)
   [hR( f )] (dB)
   [hR( f )] (dB)
Figure 10.9 WNG of the robust first-order DSAs as a function of frequency, for 𝛿= 0.5 cm and several
values of M: M = 2 (solid line with circles), M = 4 (dashed line with asterisks), M = 6 (dotted line with
squares), and M = 8 (dash-dot line with triangles). (a) Dipole, (b) cardioid, (c) hypercardioid, and
(d) supercardioid.
Then, the least-squares (LS) method consists of minimizing the LSE criterion:
LSE [𝐡( f )] = 
𝜋∫
𝜋

|||[𝐡( f ), cos 𝜃]|||

d𝜃
(.)
= 𝐡H( f )𝚪C( f )𝐡( f ) −𝐡H( f )𝚪𝐝𝐩C( f )𝐛N
−𝐛T
N𝚪H
𝐝𝐩C( f )𝐡( f ) + 𝐛T
N𝐌C𝐛N,
where
𝚪𝐝𝐩C( f ) = 
𝜋∫
𝜋

𝐝
(
f , cos 𝜃
)
𝐩T
C (cos 𝜃) d𝜃,
(.)
and 𝚪C( f ) and 𝐌C are deﬁned in (.) and (.), respectively. The minimization of
(.) gives the LS ﬁlter:
𝐡LS( f ) = 𝚪−
C ( f )𝚪𝐝𝐩C( f )𝐛N.
(.)

Beampattern Design
377
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.10 Beampatterns of the frequency-invariant first-order dipole for f = 1 kHz, 𝛿= 0.5 cm,
M = 6, and several values of 𝜖: (a) 𝜖= 0, (b) 𝜖= 10−5, (c) 𝜖= 10−3, and (d) 𝜖= 0.1.
It is also easy to ﬁnd the regularized LS ﬁlter:
𝐡LS,𝜖( f ) = 𝚪−
C,𝜖( f )𝚪𝐝𝐩C( f )𝐛N.
(.)
Another more useful idea is to minimize the LSE criterion subject to the distortionless
constraint []:
min
𝐡( f ) LSE
[
𝐡( f )
]
subject to 𝐡H( f )𝐝
(
f , 
)
= .
(.)
We easily obtain the constrained LS (CLS) ﬁlter:
𝐡CLS( f ) = 𝐡LS( f ) −
−𝐝H (f , ) 𝐡LS( f )
𝐝H (f , ) 𝚪−
C ( f )𝐝(f , )𝚪−
C ( f )𝐝
(
f , 
)
.
(.)
www.ebook3000.com

378
Fundamentals of Signal Enhancement and Array Signal Processing
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.11 Beampatterns of the frequency-invariant first-order cardioid for f = 1 kHz, 𝛿= 0.5 cm,
M = 6, and several values of 𝜖: (a) 𝜖= 0, (b) 𝜖= 10−5, (c) 𝜖= 10−3, and (d) 𝜖= 0.1.
A more robust version is the regularized CLS ﬁlter is:
𝐡CLS,𝜖( f ) = 𝐡LS,𝜖( f ) −
−𝐝H (f , ) 𝐡LS,𝜖( f )
𝐝H (f , ) 𝚪−
C,𝜖( f )𝐝(f , )𝚪−
C,𝜖( f )𝐝
(
f , 
)
.
(.)
The error signal deﬁned in (.) can also be expressed as

[
𝐡( f ), cos 𝜃
]
=
∞
∑
i=
cos (i𝜃) 𝐛
T
i ( f )𝐡( f ) −
N
∑
i=
bN,i cos (i𝜃)
(.)
=
N
∑
i=
cos (i𝜃) 𝐛
T
i ( f )𝐡( f ) −
N
∑
i=
bN,i cos (i𝜃)
+
∞
∑
i=N+
cos (i𝜃) 𝐛
T
i ( f )𝐡( f ).

Beampattern Design
379
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.12 Beampatterns of the frequency-invariant first-order hypercardioid for f = 1 kHz,
𝛿= 0.5 cm, M = 6, and several values of 𝜖: (a) 𝜖= 0, (b) 𝜖= 10−5, (c) 𝜖= 10−3, and (d) 𝜖= 0.1.
Using the constraint 𝐁N( f )𝐡( f ) = 𝐛N [or, equivalently, 𝐛
T
i ( f )𝐡( f ) = bN,i, i =
, , … , N] in the ﬁrst element on the right-hand side of the previous expression, the
error simpliﬁes to
[𝐡( f ), cos 𝜃] =
∞
∑
i=N+
cos (i𝜃) 𝐛
T
i ( f )𝐡( f ).
(.)
Therefore, the (constrained) LSE criterion is also
LSE [𝐡( f )] = 
𝜋∫
𝜋

|||||
∞
∑
i=N+
cos (i𝜃) 𝐛
T
i ( f )𝐡( f )
|||||

d𝜃.
(.)
www.ebook3000.com

380
Fundamentals of Signal Enhancement and Array Signal Processing
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.13 Beampatterns of the frequency-invariant first-order supercardioid for f = 1 kHz,
𝛿= 0.5 cm, M = 6, and several values of 𝜖: (a) 𝜖= 0, (b) 𝜖= 10−5, (c) 𝜖= 10−3, and (d) 𝜖= 0.1.
Using (.), the criterion deﬁned in (.) can be expressed as
JFI
[𝐡( f )] = 
𝜋∫
𝜋

|||[𝐡( f ), cos 𝜃] + (𝐛N, cos 𝜃)|||

d𝜃
(.)
= 
𝜋∫
𝜋

||||||
∞
∑
i=N+
cos (i𝜃) 𝐛
T
i ( f )𝐡( f ) +
N
∑
i=
bN,i cos (i𝜃)
||||||

d𝜃.
Using the orthogonality property of the Chebyshev polynomials, the previous expres-
sion simpliﬁes to
JFI
[𝐡( f )] = LSE [𝐡( f )] + 
𝜋∫
𝜋

|||(𝐛N, cos 𝜃)|||

d𝜃,
(.)

Beampattern Design
381
0
2
4
6
8
0
1
2
3
4
5
6
7
f (kHz)
0
2
4
6
8
f (kHz)
0
2
4
6
8
f  (kHz)
0
2
4
6
8
f (kHz)
(c)
0
1
2
3
4
5
6
7
(a)
0
1
2
3
4
5
6
7
(b)
    [hFI,∊( f )] (dB)
    [hFI,∊( f )] (dB)
    [hFI,∊( f )] (dB)
    [hFI,∊( f )] (dB)
0
1
2
3
4
5
6
7
(d)
Figure 10.14 DF of the frequency-invariant first-order DSAs as a function of frequency, for 𝛿= 0.5 cm,
M = 6, and several values of 𝜖: 𝜖= 0 (solid line with circles), 𝜖= 10−5 (dashed line with asterisks),
𝜖= 10−3 (dotted line with squares), and 𝜖= 0.1 (dash-dot line with triangles). (a) Dipole, (b) cardioid,
(c) hypercardioid, and (d) supercardioid.
where the second term on the right-hand side of (.) does not depend on 𝐡( f ). This
shows that minimizing JFI
[
𝐡( f )
]
subject to the constraint 𝐁N( f )𝐡( f ) = 𝐛N is equivalent
to minimizing LSE [𝐡( f )] subject to the same constraint.
Figures .displays the patterns – with 𝐡LS,𝜖( f ) deﬁned in (.) – of the ﬁrst-order
supercardioid for f = kHz, 𝛿= .cm, M = , and several values of 𝜖. Corresponding
plots of the ﬁrst-order supercardioid, obtained with 𝐡CLS,𝜖( f ) – as deﬁned in (.) –
are depicted in Figure .. Figure .shows plots of the DFs, [𝐡LS,𝜖( f )] and

[
𝐡CLS,𝜖( f )
]
, as a function of frequency, for the ﬁrst-order supercardioid and several
values of 𝜖. Corresponding plots of the WNGs, [𝐡LS,𝜖( f )] and [𝐡CLS,𝜖( f )], as
a function of frequency are depicted in Figure .. We observe that the WNG is
considerably improved as 𝜖increases, while the beampatterns and the DFs do not
change much as long as 𝜖is not too large. The larger is 𝜖, the more robust are the
regularized LS and CLS ﬁrst-order DSAs against white noise ampliﬁcation, but at the
expense of less explicit nulls.
www.ebook3000.com

382
Fundamentals of Signal Enhancement and Array Signal Processing
−50
−40
−30
−20
−10
0
10
0
2
4
6
8
0
2
4
6
8
0
2
4
6
8
0
2
4
6
8
(c)
−50
−40
−30
−20
−10
0
10
(a)
−50
−40
−30
−20
−10
0
10
(d)
−50
−40
−30
−20
−10
0
10
(b)
f (kHz)
f  (kHz)
f  (kHz)
f (kHz)
    [hFI,∊( f )] (dB)
    [hFI,∊( f )] (dB)
    [hFI,∊( f )] (dB)
    [hFI,∊( f )] (dB)
Figure 10.15 WNG of the frequency-invariant first-order DSAs as a function of frequency, for
𝛿= 0.5 cm, M = 6, and several values of 𝜖: 𝜖= 0 (solid line with circles), 𝜖= 10−5 (dashed line with
asterisks), 𝜖= 10−3 (dotted line with squares), and 𝜖= 0.1 (dash-dot line with triangles). (a) Dipole,
(b) cardioid, (c) hypercardioid, and (d) supercardioid.
10.6
Joint Optimization
Here, of course, we assume that M > N +. This gives us much more ﬂexibility to design
beampatterns with diﬀerent compromises thanks to the array redundancy.
We denote by 𝐡′( f ), the ﬁlter of length N + , which is equal to the ﬁlter 𝐡NR( f )
derived in Section .with N += M. We are interested in the class of ﬁlters of length
M(> N + ), whose form is
𝐡( f ) = 𝐇′( f )𝐠( f ),
(.)
where 𝐇′( f ) is a matrix of size M × (M −N), with
𝐇′H( f ) =
⎡
⎢
⎢
⎢⎣
𝐡′H( f )
𝟎×(M−N−)

𝐡′H( f )
𝟎×(M−N−)
⋮
⋱
𝟎×(M−N−)
𝐡′H( f )
⎤
⎥
⎥
⎥⎦
,
(.)

Beampattern Design
383
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.16 Beampatterns of the regularized LS first-order supercardioid for f = 1 kHz, 𝛿= 0.5 cm,
M = 6, and several values of 𝜖: (a) 𝜖= 0, (b) 𝜖= 10−5, (c) 𝜖= 10−3, and (d) 𝜖= 0.1.
𝐡′( f ) = 𝐡NR( f ), and 𝐠( f ) ≠𝟎is a ﬁlter of length M−N. The fundamental property of the
class of ﬁlters deﬁned in (.) is that they preserve the nulls of 𝐡′( f ) = 𝐡NR( f ). Indeed,
if 𝜃is a null of 𝐡′( f ), it can be veriﬁed that, thanks to the structure of the steering vector,
we have
𝐡H( f )𝐝(f , cos 𝜃
) = 𝐠H( f )̃𝐝(f , cos 𝜃
) × = ,
(.)
where
̃𝐝
(
f , cos 𝜃
)
=
[ 
e−𝚥𝜋f 𝜏cos 𝜃
⋯
e−𝚥(M−N−)𝜋f 𝜏cos 𝜃]T .
(.)
At this point, it is important to mention that what characterizes the diﬀerent array
beampatterns is the diﬀerent directions of their nulls; so when the nulls are preserved,
the shape of the beampatterns is also mostly preserved. Now, we can adjust the ﬁlter
www.ebook3000.com

384
Fundamentals of Signal Enhancement and Array Signal Processing
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.17 Beampatterns of the regularized CLS first-order supercardioid for f = 1 kHz, 𝛿= 0.5 cm,
M = 6, and several values of 𝜖: (a) 𝜖= 0, (b) 𝜖= 10−5, (c) 𝜖= 10−3, and (d) 𝜖= 0.1.
𝐠( f ) and its dimension to improve the WNG and/or the frequency invariance of the
beampatterns.
At 𝜃= , we have
𝐇′H( f )𝐝(f , ) = [ 
e−𝚥𝜋f 𝜏
⋯
e−𝚥(M−N−)𝜋f 𝜏]T
(.)
= ̃𝐝(f , ) .
As a result, the distortionless constraint for the ﬁlter 𝐡( f ) or, equivalently, the ﬁlter
𝐠( f ) is
𝐡H( f )𝐝(f , ) = 𝐠H( f )̃𝐝(f , ) = .
(.)

Beampattern Design
385
0
2
4
6
8
f  (kHz)
0
2
4
6
8
f (kHz)
0
1
2
3
4
5
6
7
(a)
    [hLS,∊( f )] (dB)
0
1
2
3
4
5
6
7
(b)
    [hCLS,∊( f )] (dB)
Figure 10.18 DF of first-order supercardioids as a function of frequency, for 𝛿= 0.5 cm, M = 6, and
several values of 𝜖: 𝜖= 0 (solid line with circles), 𝜖= 10−5 (dashed line with asterisks), 𝜖= 10−3 (dotted
line with squares), and 𝜖= 0.1 (dash-dot line with triangles). (a) Regularized LS and (b) regularized CLS.
−50
−40
−30
−20
−10
0
10
0
2
4
6
8
f  (kHz)
0
2
4
6
8
f (kHz)
(a)
(b)
    [hLS,∊( f )] (dB)
−50
−40
−30
−20
−10
0
10
    [hCLS,∊( f )] (dB)
Figure 10.19 WNG of first-order supercardioids as a function of frequency, for 𝛿= 0.5 cm, M = 6, and
several values of 𝜖: 𝜖= 0 (solid line with circles), 𝜖= 10−5 (dashed line with asterisks), 𝜖= 10−3 (dotted
line with squares), and 𝜖= 0.1 (dash-dot line with triangles). (a) Regularized LS and (b) regularized CLS.
Using (.), we can express the WNG and the beampattern as, respectively,
[𝐡( f )] =
|||𝐡H( f )𝐝
(
f , 
)|||

𝐡H( f )𝐡( f )
=
|||𝐠H( f )̃𝐝
(
f , 
)|||

𝐠H( f )𝐇′H( f )𝐇′( f )𝐠( f )
= [𝐠( f )]
(.)
www.ebook3000.com

386
Fundamentals of Signal Enhancement and Array Signal Processing
and
[𝐡( f ), cos 𝜃] = 𝐝H (f , cos 𝜃) 𝐡( f )
= 𝐝H (f , cos 𝜃) 𝐇′( f )𝐠( f )
= 
[
𝐠( f ), cos 𝜃
]
.
(.)
With the proposed approach, the best way to improve the robustness of the ﬁlter with
respect to white noise ampliﬁcation is to maximize the WNG as given in (.):
min
𝐠( f ) 𝐠H( f )𝐇′H( f )𝐇′( f )𝐠( f ) subject to 𝐠H( f )̃𝐝(f , ) = .
(.)
We obtain the maximum WNG (MWNG) ﬁlter:
𝐠MWNG( f ) =
[𝐇′H( f )𝐇′( f )]−̃𝐝(f , )
̃𝐝H (
f , 
) [
𝐇′H( f )𝐇′( f )
]−̃𝐝
(
f , 
).
(.)
As a result, the global MWNG ﬁlter is
𝐡MWNG( f ) = 𝐇′( f )𝐠MWNG( f ).
(.)
This ﬁlter is equivalent to the robust ﬁlter, 𝐡R( f ), derived in Section .. While
𝐡MWNG( f ) greatly improves the WNG, the designed beampattern diverges from the
desired one as the frequency increases.
Figure .displays the patterns – with 𝐡MWNG( f ) as deﬁned in (.) – of the ﬁrst-
order supercardioid for f = kHz, 𝛿= .cm, and several values of M. Figure .
shows plots of the DF and WNG, 
[
𝐡MWNG( f )
]
and 
[
𝐡MWNG( f )
]
, as a function of
frequency, for the ﬁrst-order supercardioid and several values of M. We observe that
the WNG is considerably improved as M increases, while the beampatterns and the
DFs do not change much.
Let us deﬁne the error signal between the array beampattern and the desired direc-
tivity pattern:
[𝐡( f ), cos 𝜃] = [𝐡( f ), cos 𝜃] −(𝐛N, cos 𝜃)
(.)
= 𝐝H (f , cos 𝜃) 𝐇′( f )𝐠( f ) −𝐩T
C (cos 𝜃) 𝐛N
= [𝐠( f ), cos 𝜃] .
The LSE criterion can be expressed as
LSE [𝐠( f )] = 
𝜋∫
𝜋

|||[𝐠( f ), cos 𝜃]|||

d𝜃
(.)
= 𝐠H( f )𝐇′H( f )𝚪C( f )𝐇′( f )𝐠( f ) −𝐠H( f )𝐇′H( f )𝚪𝐝𝐩C( f )𝐛N
−𝐛T
N𝚪H
𝐝𝐩C( f )𝐇′( f )𝐠( f ) + 𝐛T
N𝐌C𝐛N.

Beampattern Design
387
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.20 Beampatterns of the MWNG first-order supercardioid for f = 1 kHz, 𝛿= 0.5 cm, and
several values of M: (a) M = 3, (b) M = 4, (c) M = 6, and (d) M = 8.
0
2
4
6
8
0
1
2
3
4
5
6
7
0
2
4
6
8
−50
−40
−30
−20
−10
0
10
f (kHz)
f  (kHz)
(a)
(b)
  [hMWNG( f )] (dB)
  [hMWNG(f )] (dB)
Figure 10.21 (a) DF and (b) WNG of the MWNG first-order supercardioid as a function of frequency, for
𝛿= 0.5 cm and several values of M: M = 3 (solid line with circles), M = 4 (dashed line with asterisks),
M = 6 (dotted line with squares), and M = 8 (dash-dot line with triangles).
www.ebook3000.com

388
Fundamentals of Signal Enhancement and Array Signal Processing
In order to get frequency-invariant beampatterns, we can minimize the LSE criterion
subject to the distortionless constraint:
min
𝐠( f ) LSE [𝐠( f )]
subject to 𝐠H( f )̃𝐝(f , ) = ,
(.)
from which we deduce the constrained LS (CLS) ﬁlter:
𝐠CLS( f ) = 𝐠LS( f ) +
−̃𝐝H (
f , 
)
𝐠LS( f )
̃𝐝H (
f , 
)
𝐑−( f )̃𝐝(
f , 
)𝐑−( f )̃𝐝(f , ) ,
(.)
where
𝐠LS( f ) = 𝐑−( f )𝐇′H( f )𝚪𝐝𝐩C( f )𝐛N
(.)
is the LS ﬁlter obtained by minimizing LSE
[
𝐠( f )
]
and
𝐑( f ) = 𝐇′H( f )𝚪C( f )𝐇′( f ).
(.)
As a result, the global CLS ﬁlter is
𝐡CLS,( f ) = 𝐇′( f )𝐠CLS( f ).
(.)
This ﬁlter is mostly equivalent to 𝐡CLS( f ), as derived in Section .. While 𝐡CLS,( f )
leads to very nice frequency-invariant responses, it suﬀers severely from white noise
ampliﬁcation.
Figures .displays the patterns – with 𝐡CLS,( f ) as deﬁned in (.) – of the ﬁrst-
order supercardioid for f = kHz, 𝛿= .cm, and several values of M. Figure .
shows plots of the DF and WNG, 
[
𝐡CLS,( f )
]
and 
[
𝐡CLS,( f )
]
, as a function of
frequency, for the ﬁrst-order supercardioid and several values of M. We observe that
the beampatterns and the DFs are approximately frequency invariant, but the WNG is
very low, and becomes even worse as M increases.
In order to give a compromise between the WNG and frequency-invariant beam-
patterns, we should jointly optimize the two previous approaches. Let us deﬁne the
criterion:
Jℵ
[𝐠( f )] = ℵLSE [𝐠( f )] + (−ℵ)𝐠H( f )𝐇′H( f )𝐇′( f )𝐠( f ),
(.)
where ℵ∈[, ] controls the tradeoﬀbetween the WNG and the error beampattern.
Taking into account the distortionless constraint, the optimization problem is
min
𝐠( f ) Jℵ
[𝐠( f )]
subject to 𝐠H( f )̃𝐝(f , ) = .
(.)
We ﬁnd that the tradeoﬀﬁlter is
𝐠T,ℵ( f ) = 𝐠U,ℵ( f ) +
−̃𝐝H (f , ) 𝐠U,ℵ( f )
̃𝐝H (f , ) 𝐑−
ℵ( f )̃𝐝(f , )𝐑−
ℵ( f )̃𝐝
(
f , 
)
,
(.)

Beampattern Design
389
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.22 Beampatterns of the CLS first-order supercardioid for f = 1 kHz, 𝛿= 0.5 cm, and several
values of M: (a) M = 3, (b) M = 4, (c) M = 6, and (d) M = 8.
0
2
4
6
8
0
1
2
3
4
5
6
7
0
2
4
6
8
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
f (kHz)
f (kHz)
(a)
(b)
    [hCLS,2 ( f )] (dB)
    [hCLS,2 ( f )] (dB)
Figure 10.23 (a) DF and (b) WNG of the CLS first-order supercardioid as a function of frequency, for
𝛿= 0.5 cm and several values of M: M = 3 (solid line with circles), M = 4 (dashed line with asterisks),
M = 6 (dotted line with squares), and M = 8 (dash-dot line with triangles).
www.ebook3000.com

390
Fundamentals of Signal Enhancement and Array Signal Processing
−20 dB
−30 dB
−40 dB
180°
(a)
(b)
(c)
(d)
−10 dB
−10 dB
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
−20 dB
−30 dB
−40 dB
180°
−10 dB
0°
30°
60°
120°
150°
210°
240°
300°
330°
90°
270°
−20 dB
−30 dB
−40 dB
0 dB
Figure 10.24 Beampatterns of the jointly optimized first-order supercardioid for f = 1 kHz,
𝛿= 0.5 cm, M = 6, and several values of ℵ: (a) ℵ= 0, (b) ℵ= 0.5, (c) ℵ= 0.9, and (d) ℵ= 0.99.
where
𝐠U,ℵ( f ) = ℵ𝐑−
ℵ( f )𝐇′H( f )𝚪𝐝𝐩C( f )𝐛N
(.)
is the unconstrained ﬁlter obtained by minimizing Jℵ
[𝐠( f )] and
𝐑ℵ( f ) = ℵ𝐑( f ) + (−ℵ)𝐇′H( f )𝐇′( f ).
(.)
Consequently, the global tradeoﬀﬁlter from the proposed joint optimization is
𝐡T,ℵ( f ) = 𝐇′( f )𝐠T,ℵ( f ).
(.)
Obviously, in the two extreme cases, we have 𝐡T,( f ) = 𝐡MWNG( f ) and 𝐡T,( f ) =
𝐡CLS,( f ).
Figure .displays the patterns – with 𝐡T,ℵ( f ) as deﬁned in (.) – of the ﬁrst-
order supercardioid for f = kHz, 𝛿= .cm, M = , and several values of ℵ.

Beampattern Design
391
0
2
4
6
8
0
1
2
3
4
5
6
7
0
2
4
6
8
−30
−25
−20
−15
−10
−5
0
5
10
f  (kHz)
f (kHz)
(a)
(b)
    [hT,    ( f )] (dB)
    [hT,    ( f )] (dB)
Figure 10.25 (a) DF and (b) WNG of the jointly optimized first-order supercardioid as a function of
frequency, for 𝛿= 0.5 cm, M = 6, and several values of ℵ: ℵ= 0 (solid line with circles), ℵ= 0.5
(dashed line with asterisks), ℵ= 0.9 (dotted line with squares), and ℵ= 0.99 (dash-dot line with
triangles).
Table 10.1 Filters for beampattern design.
Filter
Nonrobust
𝐡NR( f ) = 𝐁
−
M−( f )𝐛M−
Robust
𝐡R( f ) = 𝐁
H
N( f )
[
𝐁N( f )𝐁
H
N( f )
]−
𝐛N
Frequency invariant
𝐡FI( f ) = 𝚪−
C ( f )𝐁
H
N( f )
[
𝐁N( f )𝚪−
C ( f )𝐁
H
N( f )
]−
𝐛N
𝐡FI,𝜖( f ) = 𝚪−
C,𝜖( f )𝐁
H
N( f )
[
𝐁N( f )𝚪−
C,𝜖( f )𝐁
H
N( f )
]−
𝐛N
Least squares
𝐡LS( f ) = 𝚪−
C ( f )𝚪𝐝𝐩C( f )𝐛N
𝐡LS,𝜖( f ) = 𝚪−
C,𝜖( f )𝚪𝐝𝐩C( f )𝐛N
𝐡CLS( f ) = 𝐡LS( f )−
−𝐝H (f , ) 𝐡LS( f )
𝐝H (f , ) 𝚪−
C ( f )𝐝(f , )𝚪−
C ( f )𝐝(f , )
𝐡CLS,𝜖( f ) = 𝐡LS,𝜖( f )−
−𝐝H (f , ) 𝐡LS,𝜖( f )
𝐝H (f , ) 𝚪−
C,𝜖( f )𝐝(f , )𝚪−
C,𝜖( f )𝐝(f , )
𝐡CLS,( f ) = 𝐇′( f )𝐠CLS( f )
Maximum WNG
𝐡MWNG( f ) =
𝐇′( f ) [𝐇′H( f )𝐇′( f )]−̃𝐝(f , )
̃𝐝H (f , ) [𝐇′H( f )𝐇′( f )]−̃𝐝(f , )
Joint optimization
𝐡T,ℵ( f ) = 𝐇′( f )𝐠T,ℵ( f )
Figure .shows plots of the DF and WNG, [𝐡T,ℵ( f )] and [𝐡T,ℵ( f )], as a function
of frequency, for the ﬁrst-order supercardioid and several values of ℵ. We observe that
ℵgives a compromise between the WNG and frequency-invariant beampatterns. The
DF at high frequencies is improved as ℵincreases, while the WNG is signiﬁcantly
www.ebook3000.com

392
Fundamentals of Signal Enhancement and Array Signal Processing
higher than that with 𝐡CLS,( f ). Compared to the CLS ﬁlter, the jointly optimized ﬁlter
is considerably more robust against white noise ampliﬁcation, but leads to slightly less
frequency-invariant responses.
To conclude this chapter, we present in Table .most of the ﬁlters outlined for
beampattern design.
Problems
10.1 Show that the minimization of the LSE criterion yields
𝐜N = 𝐌−
C 𝐯C
(
𝚥f m
)
.
10.2 Show that the elements of the vector 𝐯C
(
𝚥f m
)
are
[
𝐯C
(
𝚥f m
)]
n+= 𝚥nJn
(
f m
)
,
where Jn (z) is the Bessel function of the ﬁrst kind.
10.3 Show that the elements of the matrix 𝐌C are
[𝐌C
]
i+,j+= 
𝜋∫
𝜋

cos (i𝜃) cos (j𝜃) d𝜃.
10.4 Prove the Jacobi–Anger expansion:
e𝚥f m cos 𝜃=
∞
∑
n=
𝚥nJn
(
f m
)
cos (n𝜃) ,
where
𝚥n =
{
,
n = 
𝚥n,
n = , , … , N
.
10.5 Show that the beampattern can be approximated by
N
[
𝐡( f ), cos 𝜃
]
=
N
∑
n=
cos (n𝜃)
[ M
∑
m=
𝚥nJn
(
f m
)
Hm( f )
]
.
10.6 Show that with the nonrobust ﬁlter, 𝐡NR( f ), the ﬁrst-order beampattern is given
by

[𝐡( f ), cos 𝜃] = H( f ) + J
(
f 
)
H( f ) + 𝚥J
(
f 
)
H( f ) cos 𝜃.

Beampattern Design
393
10.7 Show that the minimum-norm ﬁlter for the design of ﬁrst-order DSA beampat-
terns is given by
Hi,R( f ) =
J
(
f i
)
b,
𝚥∑M
j=J

(
f j
), i = , , … , M,
H,R( f ) = −
M
∑
i=
J
(
f i
)
Hi,R( f ) + b,.
10.8 Show that by minimizing JFI
[𝐡( f )] subject to 𝐁N( f )𝐡( f ) = 𝐛N and 𝐡H( f )𝐡( f ) =
𝛿𝜖, we obtain the ﬁlter:
𝐡FI,𝜖( f ) = 𝚪−
C,𝜖( f )𝐁
H
N( f )
[
𝐁N( f )𝚪−
C,𝜖( f )𝐁
H
N( f )
]−
𝐛N,
where 𝚪C,𝜖( f ) = 𝚪C( f ) + 𝜖𝐈M.
10.9 Show that the LSE between the array beampattern and the desired directivity
pattern can be written as
LSE [𝐡( f )] = 𝐡H( f )𝚪C( f )𝐡( f ) −𝐡H( f )𝚪𝐝𝐩C( f )𝐛N
−𝐛T
N𝚪H
𝐝𝐩C( f )𝐡( f ) + 𝐛T
N𝐌C𝐛N.
10.10 Show that by minimizing the LSE with a constraint on the coeﬃcients, we obtain
the regularized LS ﬁlter:
𝐡LS,𝜖( f ) = 𝚪−
C,𝜖( f )𝚪𝐝𝐩C( f )𝐛N.
10.11 Show that by minimizing the LSE subject to the distortionless constraint and a
constraint on the coeﬃcients, we obtain the regularized CLS ﬁlter:
𝐡CLS,𝜖( f ) = 𝐡LS,𝜖( f ) −
−𝐝H (
f , 
)
𝐡LS,𝜖( f )
𝐝H (
f , 
)
𝚪−
C,𝜖( f )𝐝
(
f , 
)𝚪−
C,𝜖( f )𝐝(f , ) .
10.12 Show that with the constraint 𝐁N( f )𝐡( f ) = 𝐛N, the error signal between the
array beampattern and the desired directivity pattern can be expressed as

[
𝐡( f ), cos 𝜃
]
=
∞
∑
i=N+
cos (i𝜃) 𝐛
T
i ( f )𝐡( f ).
10.13 Using the orthogonality property of the Chebyshev polynomials, show that the
criterion JFI
[𝐡( f )] can be expressed as
JFI
[𝐡( f )] = LSE [𝐡( f )] + 
𝜋∫
𝜋

|||(𝐛N, cos 𝜃)|||

d𝜃,
www.ebook3000.com

394
Fundamentals of Signal Enhancement and Array Signal Processing
where
LSE
[
𝐡( f )
]
= 
𝜋∫
𝜋

|||||
∞
∑
i=N+
cos (i𝜃) 𝐛
T
i ( f )𝐡( f )
|||||

d𝜃.
10.14 Show
that
the
ﬁlters
deﬁned
in
(.)
preserve
the
nulls
of
𝐡′( f ) = 𝐡NR( f ); that is, if 𝜃is a null of 𝐡′( f ), then
𝐡H( f )𝐝(f , cos 𝜃
) = 𝐠H( f )̃𝐝(f , cos 𝜃
) × = ,
where
̃𝐝(f , cos 𝜃
) = [ 
e−𝚥𝜋f 𝜏cos 𝜃
⋯
e−𝚥(M−N−)𝜋f 𝜏cos 𝜃]T .
10.15 Show that by maximizing the WNG subject to the distortionless constraint, we
obtain the MWNG ﬁlter:
𝐡MWNG( f ) =
𝐇′( f ) [𝐇′H( f )𝐇′( f )]−̃𝐝(f , )
̃𝐝H (f , ) [𝐇′H( f )𝐇′( f )]−̃𝐝(f , ).
10.16 Show that by minimizing Jℵ
[
𝐠( f )
]
subject to the distortionless constraint, we
obtain the tradeoﬀﬁlter:
𝐠T,ℵ( f ) = 𝐠U,ℵ( f ) +
−̃𝐝H (f , ) 𝐠U,ℵ( f )
̃𝐝H (
f , 
)
𝐑−
ℵ( f )̃𝐝
(
f , 
)𝐑−
ℵ( f )̃𝐝(f , ) ,
where
𝐠U,ℵ( f ) = ℵ𝐑−
ℵ( f )𝐇′H( f )𝚪𝐝𝐩C( f )𝐛N
is the unconstrained ﬁlter obtained by minimizing Jℵ
[𝐠( f )] and
𝐑ℵ( f ) = ℵ𝐑( f ) + (−ℵ)𝐇′H( f )𝐇′( f ).
References
1 H. F. Davis, Fourier Series and Orthogonal Functions. New York: Dover, .
2 L. Zhao, J. Benesty, and J. Chen, “Optimal design of directivity patterns for endﬁre
linear microphone arrays,” in Proc. IEEE ICASSP, , pp. –.
3 L. Zhao, J. Benesty, and J. Chen, “Design of robust diﬀerential microphone arrays with
the Jacobi–Anger expansion,” Applied Acoustics, vol. , pp. –, Sep. .
4 M. Abramowitz and I. A. Stegun (eds), Handbook of Mathematical Functions with
Formulas, Graphs, and Mathematical Tables. New York, NY: Dover, .
5 C. Pan, J. Benesty, and J. Chen, “Design of robust diﬀerential microphone arrays with
orthogonal polynomials,” J. Acoust. Soc. Am., vol. , pp. –, Aug. .

Beampattern Design
395
6 D. Colton and R. Krees, Inverse Acoustics and Electromagnetic Scattering Theory, nd
edn. Berlin, Germany: Springer-Verlag, .
7 A. Cuyt, V. B. Petersen, B. Verdonk, H. Waadeland, and W. B. Jones, Handbook of
Continued Fractions for Special Functions. Berlin, Germany: Springer-Verlag, .
8 G. W. Elko, “Superdirectional microphone arrays,” in Acoustic Signal Processing for
Telecommunication, S. L. Gay and J. Benesty (eds). Boston, MA: Kluwer Academic
Publishers, , Chapter , pp. –.
9 J. Benesty and J. Chen, Study and Design of Diﬀerential Microphone Arrays. Berlin,
Germany: Springer-Verlag, .
www.ebook3000.com

397
11
Beamforming in the Time Domain
This chapter is concerned with beamforming in the time domain, which has the
advantage of being more intuitive than beamforming in the frequency domain.
Furthermore, the approach depicted here is broadband in nature. We describe the
time-domain signal model that we adopt and explain how broadband beamforming
works. Then we deﬁne many performance measures that are essential for the derivation
and analysis of broadband beamformers. Some measures are only relevant for ﬁxed
beamforming while others are more relevant for adaptive beamforming. Finally, we
show in great detail how to derive three classes of time-domain beamformers: ﬁxed,
adaptive, and diﬀerential.
11.1
Signal Model and Problem Formulation
We consider a desired broadband source signal, x(t), in the far-ﬁeld that propagates in
an anechoic acoustic environment, and impinges on a ULA consisting of M omnidirec-
tional sensors, where the distance between two successive sensors is equal to 𝛿. Sensor 
is chosen as the reference. In this scenario, the signal measured at the mth sensor is given
by []:
ym(t) = x [t −Δ −fs𝜏m
(cos 𝜃d
)] + vm(t)
(.)
= xm(t) + vm(t), m = , , … , M,
where Δ is the propagation time from the position of the source (desired signal), x(t),
to sensor , fs is the sampling frequency,
𝜏m
(cos 𝜃d
) = (m −)𝛿cos 𝜃d
c
(.)
is the delay between the ﬁrst and mth sensors, 𝜃d is the direction, c is the speed of the
waves in the medium, and vm(t) is the noise picked up by the mth sensor. For the sake
of simplicity, we assume that
≤fs𝛿cos 𝜃d
c
∈Z.
(.)
Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing

398
Fundamentals of Signal Enhancement and Array Signal Processing
This clearly restricts 𝜃d, but simpliﬁes the signal model. In what follows, we generalize
the signal model when assumption (.) is not satisﬁed. Under this assumption, we can
express (.) as
ym(t) = 𝐠T
m
(
cos 𝜃d
)
𝐱′ (t −Δ) + vm(t),
(.)
where
𝐠m
(cos 𝜃d
) = [ 
⋯



⋯
]T
(.)
is a vector of length Lg ≥fs𝜏m
(cos 𝜃d
)+, the [fs𝜏m
(cos 𝜃d
) + ]th component of which
is equal to and
𝐱′ (t −Δ) =
[ x (t −Δ)
x (t −Δ −)
⋯
x
[
t −Δ −fs𝜏m
(
cos 𝜃d
)]
⋯
x
(
t −Δ −Lg + 
) ]T .
(.)
The vector 𝐠m
(cos 𝜃d
) is a -sparse vector and the position of the depends on both 𝜃d
and m, with
𝐠
(cos 𝜃d
) = [ 

⋯
]T .
(.)
By considering Lh successive time samples of the mth sensor signal, (.) becomes a
vector of length Lh:
𝐲m(t) = 𝐆m
(
cos 𝜃d
)
𝐱(t −Δ) + 𝐯m(t),
(.)
where
𝐆m
(cos 𝜃d
) =
⎡
⎢
⎢
⎢⎣
𝐠T
m
(cos 𝜃d
)


⋯


𝐠T
m
(cos 𝜃d
)

⋯

⋮
⋮
⋱
⋮



⋯
𝐠T
m
(cos 𝜃d
)
⎤
⎥
⎥
⎥⎦
(.)
is a Sylvester matrix of size Lh × L, with L = Lg + Lh −,
𝐱(t −Δ) =
[ x (t −Δ)
x (t −Δ −)
⋯
x (t −Δ −L + ) ]T
(.)
is a vector of length L, and
𝐯m(t) = [ vm(t)
vm(t −)
⋯
vm(t −Lh + ) ]T
(.)
is a vector of length Lh. Figure .illustrates the multichannel signal model in the time
domain. By concatenating the observations from the M sensors, we get the vector of
length MLh:
www.ebook3000.com

Beamforming in the Time Domain
399
+
v1(t)
+
vM(t)
G1 (cos θd)
GM (cos θd)
Vector stack
...
...
x (t−Δ)
y(t)
x1(t)
xM(t)
y1(t)
yM(t)
Figure 11.1 Multichannel signal model in the time domain.
𝐲(t) = [ 𝐲T
(t)
𝐲T
(t)
⋯
𝐲T
M(t) ]T
= 𝐆(cos 𝜃d
) 𝐱(t −Δ) + 𝐯(t)
(.)
= 𝐱(t) + 𝐯(t),
where
𝐆(
cos 𝜃d
)
=
⎡
⎢
⎢
⎢⎣
𝐆
(cos 𝜃d
)
𝐆
(cos 𝜃d
)
⋮
𝐆M
(cos 𝜃d
)
⎤
⎥
⎥
⎥⎦
(.)
is a matrix of size MLh × L,
𝐯(t) = [ 𝐯T
(t)
𝐯T
(t)
⋯
𝐯T
M(t) ]T
(.)
is a vector of length MLh, and
𝐱(t) =
[ 𝐱T
(t)
𝐱T
(t)
⋯
𝐱T
M(t) ]T
= 𝐆(cos 𝜃d
) 𝐱(t −Δ) ,
(.)
with 𝐱m(t) = 𝐆m
(cos 𝜃d
) 𝐱(t −Δ).
From (.), we deduce that the correlation matrix (of size MLh × MLh) of 𝐲(t) is
𝐑𝐲= E
[
𝐲(t)𝐲T(t)
]
(.)
= 𝐑𝐱+ 𝐑𝐯
= 𝐆(cos 𝜃d
) 𝐑𝐱𝐆T (cos 𝜃d
) + 𝐑𝐯,
where 𝐑𝐱, 𝐑𝐯, and 𝐑𝐱are the correlation matrices of 𝐱(t), 𝐯(t), and 𝐱(t −Δ), respectively.
We always assume that 𝐑𝐯has full rank. However, to fully exploit the spatial information,

400
Fundamentals of Signal Enhancement and Array Signal Processing
as in the frequency domain, the matrix 𝐑𝐱= 𝐆
(
cos 𝜃d
)
𝐑𝐱𝐆T (
cos 𝜃d
)
must be rank
deﬁcient. Since the size of 𝐆(
cos 𝜃d
)
is MLh ×L and the size of 𝐑𝐱is L×L, the condition
for that is
MLh > L
(.)
or, equivalently,
Lh >
Lg −
M −.
(.)
We see that as M increases, the minimal value of Lh decreases.
Our objective is to design all kinds of time-domain or broadband beamformers with
a real-valued spatiotemporal ﬁlter of length MLh:
𝐡=
[ 𝐡T

𝐡T

⋯
𝐡T
M
]T ,
(.)
where 𝐡m, m = , , … , M are temporal ﬁlters of length Lh.
To generalize the signal model when assumption (.) is not satisﬁed, we resort to
Shannon’s sampling theorem [, ], which implies that
xm(t) = x [t −Δ −fs𝜏m
(cos 𝜃d
)]
(.)
=
∞
∑
n=−∞
x (t −Δ −n) sinc [n −fs𝜏m
(cos 𝜃d
)]
≈
P
∑
n=−P−Lh+
x (t −Δ −n) sinc [n −fs𝜏m
(cos 𝜃d
)]
for P ≫fs𝜏m
(cos 𝜃d
). Hence, we can simply redeﬁne 𝐱(t −Δ) as a vector of length
L = P + Lh with
𝐱(t −Δ) =
[
x
(
t −Δ + P + Lh −
)
x
(
t −Δ + P + Lh −
)
⋯
x (t −Δ −P) ]T
(.)
and redeﬁne 𝐆m
(
cos 𝜃d
)
as a Toeplitz matrix of size Lh × L with the elements:
[
𝐆m
(
cos 𝜃d
)]
i,j = sinc
[
−P −Lh + −i + j −fs𝜏m
(
cos 𝜃d
)]
,
(.)
where i = , … , Lh, j = , … , L.
www.ebook3000.com

Beamforming in the Time Domain
401
11.2
Broadband Beamforming
By applying the spatiotemporal ﬁlter, 𝐡, to the observation signal vector, 𝐲(t), we obtain
the output of the broadband beamformer, as illustrated in Figure .:
z(t) =
M
∑
m=
𝐡T
m𝐲m(t)
(.)
= 𝐡T𝐲(t)
= xfd(t) + vrn(t),
where
xfd(t) =
M
∑
m=
𝐡T
m𝐆m
(cos 𝜃d
) 𝐱(t −Δ)
(.)
= 𝐡T𝐆
(
cos 𝜃d
)
𝐱(t −Δ)
is the ﬁltered desired signal and
vrn(t) =
M
∑
m=
𝐡T
m𝐯m(t)
(.)
= 𝐡T𝐯(t)
is the residual noise. We deduce that the variance of z(t) is
𝜎
z = 𝐡T𝐑𝐲𝐡
(.)
= 𝜎
xfd + 𝜎
vrn,
where
𝜎
xfd = 𝐡T𝐆(cos 𝜃d
) 𝐑𝐱𝐆T (cos 𝜃d
) 𝐡
(.)
= 𝐡T𝐑𝐱𝐡
is the variance of xfd(t) and
𝜎
vrn = 𝐡T𝐑𝐯𝐡
(.)
is the variance of vrn(t).
+
v(t)
h
T
G (cos θd)
x (t−Δ)
x(t)
y(t)
z(t)
Figure 11.2 Block diagram of broadband beamforming in the time domain.

402
Fundamentals of Signal Enhancement and Array Signal Processing
In principle, any element of the vector 𝐱(t −Δ) can be considered as the desired
signal. Therefore, from (.), we see that the distortionless constraint is
𝐡T𝐆
(
cos 𝜃d
)
= 𝐢T
l ,
(.)
where 𝐢l is the lth column of the L × L identity matrix, 𝐈L.
11.3
Performance Measures
In this section, we deﬁne all relevant performance measures for the derivation and
analysis of ﬁxed and adaptive beamformers in the time domain. For ﬁxed beamforming
only, since we are concerned with broadband signals, we assume for convenience that
the source signal, x(t), is white; this way, the whole spectrum is taken into account.
Since sensor is the reference, the input SNR is computed from the ﬁrst Lh compo-
nents of 𝐲(t) as deﬁned in (.): 𝐲(t) = 𝐱(t) + 𝐯(t). We easily ﬁnd that
iSNR =
tr
(
𝐑𝐱
)
tr (𝐑𝐯
)
(.)
=
𝜎
x
𝜎
v
,
where 𝐑𝐱and 𝐑𝐯are the correlation matrices of 𝐱(t) and 𝐯(t), respectively, and 𝜎
x
and 𝜎
vare the variances of x(t) and v(t), respectively.
The output SNR is obtained from (.). It is given by
oSNR
(
𝐡)
=
𝜎
xfd
𝜎
vrn
(.)
=
𝐡T𝐆(cos 𝜃d
) 𝐑𝐱𝐆T (cos 𝜃d
) 𝐡
𝐡T𝐑𝐯𝐡
=
𝜎
x
𝜎
v
×
𝐡T𝐆
(
cos 𝜃d
)
𝐆T (
cos 𝜃d
)
𝐡
𝐡T𝚪𝐯𝐡
,
where
𝚪𝐯=
𝐑𝐯
𝜎
v
(.)
is the pseudo-correlation matrix of 𝐯(t). The third line of (.) is valid for ﬁxed
beamforming only. We see from (.) that the array gain is
(𝐡) =
oSNR
(
𝐡)
iSNR
(.)
=
𝐡T𝐆
(
cos 𝜃d
)
𝐆T (
cos 𝜃d
)
𝐡
𝐡T𝚪𝐯𝐡
.
www.ebook3000.com

Beamforming in the Time Domain
403
The white noise gain (WNG) is obtained by taking 𝚪𝐯= 𝐈MLh in (.), where 𝐈MLh is
the MLh × MLh identity matrix:

(
𝐡)
=
𝐡T𝐆(cos 𝜃d
) 𝐆T (cos 𝜃d
) 𝐡
𝐡T𝐡
.
(.)
We deﬁne the broadband beampattern or broadband directivity pattern as
|||
(
𝐡, cos 𝜃
)|||

= 𝐡T𝐆(cos 𝜃) 𝐆T (cos 𝜃) 𝐡.
(.)
In the time domain, the deﬁnition of the directivity factor (DF) is

(
𝐡
)
=
|||(𝐡, cos 𝜃d
)|||


∫
𝜋

|||(𝐡, cos 𝜃)|||

sin 𝜃d𝜃
(.)
=
𝐡T𝐆(cos 𝜃d
) 𝐆T (cos 𝜃d
) 𝐡
𝐡T𝚪T,,𝜋𝐡
,
where
𝚪T,,𝜋= 
∫
𝜋

𝐆(cos 𝜃) 𝐆T (cos 𝜃) sin 𝜃d𝜃
(.)
is a matrix of size MLh×MLh, which is the equivalent form of 𝚪,𝜋(f ) in the time domain.
Note that an explicit expression for 𝚪T,,𝜋is not available. In practice, we compute the
DF in the time domain directly from the ﬁrst line of (.) with numerical integration.
In the same manner, we deﬁne the broadband front-to-back ratio (FBR) as

(
𝐡
)
=

∫
𝜋∕

|||(𝐡, cos 𝜃)|||

sin 𝜃d𝜃

∫
𝜋
𝜋∕
|||(𝐡, cos 𝜃)|||

sin 𝜃d𝜃
(.)
=
𝐡T𝚪T,,𝜋∕𝐡
𝐡T𝚪T,𝜋∕,𝜋𝐡
,
where
𝚪T,,𝜋∕= 
∫
𝜋∕

𝐆(cos 𝜃) 𝐆T (cos 𝜃) sin 𝜃d𝜃,
(.)
𝚪T,𝜋∕,𝜋= 
∫
𝜋
𝜋∕
𝐆(cos 𝜃) 𝐆T (cos 𝜃) sin 𝜃d𝜃.
(.)

404
Fundamentals of Signal Enhancement and Array Signal Processing
Now, let us deﬁne the error signal between the estimated and desired signals:
e(t) = z(t) −𝐢T
l 𝐱(t −Δ)
(.)
= xfd(t) + vrn(t) −𝐢T
l 𝐱(t −Δ) .
This error can be rewritten as
e(t) = ed(t) + en(t),
(.)
where
ed(t) = xfd(t) −𝐢T
l 𝐱(t −Δ)
(.)
=
[
𝐆T (
cos 𝜃d
)
𝐡−𝐢l
]T 𝐱(t −Δ)
and
en(t) = vrn(t)
(.)
= 𝐡T𝐯(t)
are, respectively, the desired signal distortion due to the beamformer and the residual
noise. Therefore, the MSE criterion is
J (𝐡) = E [e(t)]
(.)
= 𝜎
x −𝐡T𝐆(cos 𝜃d
) 𝐑𝐱𝐢l + 𝐡T𝐑𝐲𝐡
= Jd
(𝐡) + Jn
(𝐡) ,
where
Jd
(
𝐡
)
= E
[
e
d(t)
]
(.)
= [𝐆T (cosd 𝜃) 𝐡−𝐢l
]T 𝐑𝐱
[𝐆T (cosd 𝜃) 𝐡−𝐢l
]
= 𝜎
x𝜐d
(
𝐡
)
and
Jn
(𝐡) = E [e
n(t)]
(.)
= 𝐡T𝐑𝐯𝐡
=
𝜎
v
𝜉n
(
𝐡
),
with
𝜐d
(𝐡) =
E
{[xfd(t) −𝐢T
l 𝐱(t −Δ)
]}
𝜎
x
(.)
=
[
𝐆T (
cosd 𝜃
)
𝐡−𝐢l
]T 𝐑𝐱
[
𝐆T (
cosd 𝜃
)
𝐡−𝐢l
]
𝜎
x
www.ebook3000.com

Beamforming in the Time Domain
405
being the desired signal distortion index and
𝜉n
(
𝐡
)
=
𝜎
v
𝐡T𝐑𝐯𝐡
(.)
being the noise reduction factor. We deduce that
Jd
(
𝐡
)
Jn
(
𝐡
) = iSNR × 𝜉n
(𝐡) × 𝜐d
(𝐡)
(.)
= oSNR (𝐡) × 𝜉d
(𝐡) × 𝜐d
(𝐡) ,
where
𝜉d
(𝐡) =
𝜎
x
𝐡T𝐑𝐱𝐡
(.)
is the desired signal reduction factor.
11.4
Fixed Beamformers
In this section, we show how to derive the most conventional time-domain ﬁxed
beamformers from the WNG and the DF.
11.4.1
Delay and Sum
The classical delay-and-sum (DS) beamformer in the time domain is derived by maxi-
mizing the WNG subject to the distortionless constraint. This is equivalent to
min
𝐡𝐡T𝐡subject to 𝐡T𝐆(cos 𝜃d
) = 𝐢T
l .
(.)
We easily obtain
𝐡DS
(cos 𝜃d
) = 𝐆(cos 𝜃d
) [𝐆T (cos 𝜃d
) 𝐆(cos 𝜃d
)]−𝐢l.
(.)
Therefore, the WNG is
[𝐡DS
(cos 𝜃d
)] =

𝐢T
l
[𝐆T (cos 𝜃d
) 𝐆(cos 𝜃d
)]−𝐢l
.
(.)
It can be checked that the matrix product 𝐆T
m
(cos 𝜃d
) 𝐆m
(cos 𝜃d
) is a diagonal matrix,
the elements of which are or . As a result, the matrix 𝐆T (cos 𝜃d
) 𝐆(cos 𝜃d
) =
∑M
m=𝐆T
m
(cos 𝜃d
) 𝐆m
(cos 𝜃d
) is also a diagonal matrix the elements of which are
between and M. We conclude that the position of the in 𝐢l must coincide with the

406
Fundamentals of Signal Enhancement and Array Signal Processing
position of the maximum element of the diagonal of 𝐆T (
cos 𝜃d
)
𝐆
(
cos 𝜃d
)
. In this case,
we have

[
𝐡DS
(
cos 𝜃d
)]
= M
(.)
and
𝐡DS
(cos 𝜃d
) = 𝐆(cos 𝜃d
) 𝐢l
M.
(.)
In the rest, it is always assumed that the position of the in 𝐢l is chosen such that
𝐢T
l
[𝐆T (cos 𝜃d
) 𝐆(cos 𝜃d
)]−𝐢l = ∕M.
Example ..
Consider a ULA of M sensors. Suppose that a desired signal impinges
on the ULA from the direction 𝜃d. Assume that fs = kHz, P = , and Lh = .
Figures .–.show broadband beampatterns, |||
[
𝐡DS
(
cos 𝜃d
)
, cos 𝜃
]|||, for diﬀerent
source directions 𝜃d and several values of M and 𝛿. The main beam is in the direction
of the desired signal, 𝜃d. As the number of sensors, M, increases, or as the intersensor
0
30
60
90
120
150
180
−14
−12
−10
−8
−6
−4
−2
0
0
30
60
90
120
150
180
−14
−12
−10
−8
−6
−4
−2
0
0
30
60
90
120
150
180
−14
−12
−10
−8
−6
−4
−2
0
0
30
60
90
120
150
180
−14
−12
−10
−8
−6
−4
−2
0
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(a)
(b)
(c)
(d)
hDS
(dB)
(cos θd) , cos θ
hDS
(dB)
(cos θd) , cos θ
hDS
(dB)
(cos θd) , cos θ
hDS
(dB)
(cos θd) , cos θ
Figure 11.3 Broadband beampatterns of the DS beamformer for 𝜃d = 90◦, and several values of M
and 𝛿: (a) M = 10, 𝛿= 1 cm, (b) M = 30, 𝛿= 1 cm, (c) M = 10, 𝛿= 3 cm, and (d) M = 30, 𝛿= 3 cm.
www.ebook3000.com

Beamforming in the Time Domain
407
0
30
60
90
120
150
180
−16
−14
−12
−10
−8
−6
−4
−2
0
0
30
60
90
120
150
180
−16
−14
−12
−10
−8
−6
−4
−2
0
0
30
60
90
120
150
180
−16
−14
−12
−10
−8
−6
−4
−2
0
0
30
60
90
120
150
180
−16
−14
−12
−10
−8
−6
−4
−2
0
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(a)
(b)
(c)
(d)
h DS
(dB)
(cos θd) , cos θ
h DS
(dB)
(cos θd) , cos θ
h DS
(dB)
(cos θd) , cos θ
h DS
(dB)
(cos θd) , cos θ
Figure 11.4 Broadband beampatterns of the DS beamformer for 𝜃d = 45◦, and several values of M
and 𝛿: (a) M = 10, 𝛿= 1 cm, (b) M = 30, 𝛿= 1 cm, (c) M = 10, 𝛿= 3 cm, and (d) M = 30, 𝛿= 3 cm.
spacing, 𝛿, increases, the width of the main beam decreases, and the values obtained for
𝜃≠𝜃d become lower. Figure .shows plots of the DF, [𝐡DS
(cos 𝜃d
)], and the WNG,
[𝐡DS
(cos 𝜃d
)], as a function of 𝛿for 𝜃d = ◦and several values of M. As the number
of sensors increases, both the DF and the WNG of the DS beamformer increase. For a
given M, the DF of the DS beamformer increases as a function of 𝛿.
■
11.4.2
Maximum DF
Let 𝐭
(cos 𝜃d
) be the eigenvector corresponding to the maximum eigenvalue,
𝜆
(cos 𝜃d
), of the matrix 𝚪−
T,,𝜋𝐆(cos 𝜃d
) 𝐆T (cos 𝜃d
). It is obvious that the maximum
DF beamformer is
𝐡max
(cos 𝜃d
) = 𝜍𝐭
(cos 𝜃d
) ,
(.)
where 𝜍≠is an arbitrary real number, and the maximum DF is
max
(cos 𝜃d
) = 𝜆
(cos 𝜃d
) .
(.)

408
Fundamentals of Signal Enhancement and Array Signal Processing
0
30
60
90
120
150
180
−16
−14
−12
−10
−8
−6
−4
−2
0
0
30
60
90
120
150
180
−16
−14
−12
−10
−8
−6
−4
−2
0
0
30
60
90
120
150
180
−16
−14
−12
−10
−8
−6
−4
−2
0
0
30
60
90
120
150
180
−16
−14
−12
−10
−8
−6
−4
−2
0
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(a)
(b)
(c)
(d)
h DS
(dB)
(cos θd) , cos θ
h DS
(dB)
(cos θd) , cos θ
h DS
(dB)
(cos θd) , cos θ
h DS
(dB)
(cos θd) , cos θ
Figure 11.5 Broadband beampatterns of the DS beamformer for 𝜃d = 0◦, and several values of M and
𝛿: (a) M = 10, 𝛿= 1 cm, (b) M = 30, 𝛿= 1 cm, (c) M = 10, 𝛿= 3 cm, and (d) M = 30, 𝛿= 3 cm.
0.5
1
1.5
2
2.5
3
3.5
4
0
2
4
6
8
10
0.5
1
1.5
2
2.5
3
3.5
4
8
10
12
14
16
18
δ (cm)
δ (cm)
(a)
(b)
h DS (cos θd) (dB)
h DS (cos θd) (dB)
Figure 11.6 (a) DF and (b) WNG of the DS beamformer as a function of 𝛿for 𝜃d = 90◦and several
values of M: M = 10 (solid line with circles), M = 20 (dashed line with asterisks), M = 30 (dotted line
with squares), and M = 40 (dash-dot line with triangles).
www.ebook3000.com

Beamforming in the Time Domain
409
Therefore,
max
(cos 𝜃d
) ≥(𝐡) , ∀𝐡.
(.)
While 𝐡max
(cos 𝜃d
) maximizes the DF, it cannot be distortionless.
11.4.3
Distortionless Maximum DF
To ﬁnd the distortionless maximum DF beamformer, we need to minimize the denom-
inator of the DF subject to the distortionless constraint in the numerator of the DF:
min
𝐡𝐡T𝚪T,,𝜋𝐡subject to 𝐡T𝐆
(
cos 𝜃d
)
= 𝐢T
l .
(.)
Then, it is clear that the distortionless maximum DF beamformer is
𝐡mDF
(cos 𝜃d
) = 𝚪−
T,,𝜋𝐆(cos 𝜃d
) [
𝐆T (cos 𝜃d
) 𝚪−
T,,𝜋𝐆(cos 𝜃d
)]−
𝐢l.
(.)
We deduce that the corresponding DF is
[𝐡mDF
(cos 𝜃d
)] =

𝐢T
l
[
𝐆T (cos 𝜃d
) 𝚪−
T,,𝜋𝐆(cos 𝜃d
)]−
𝐢l
.
(.)
Example ..
Returning to Example .., we now employ the distortionless maxi-
mum DF beamformer, 𝐡mDF
(cos 𝜃d
), given in (.). Figures .–.show broadband
beampatterns, |||
[
𝐡mDF
(
cos 𝜃d
)
, cos 𝜃
]|||, for diﬀerent source directions 𝜃d and several
values of M and 𝛿. The main beam is in the direction of the desired signal, 𝜃d. As
the number of sensors, M, increases, or as the intersensor spacing, 𝛿, increases, the
width of the main beam decreases, and the values obtained for 𝜃≠𝜃d generally
become lower. Figure .shows plots of the DF, [𝐡mDF
(cos 𝜃d
)], and the WNG,
[𝐡mDF
(cos 𝜃d
)], as a function of 𝛿for 𝜃d = ◦and several values of M. Compared
to the DS beamformer, the distortionless maximum DF beamformer gives higher DF,
but lower WNG (cf. Figures .and .). For a suﬃciently small 𝛿, as the number of
sensors increases, both the DF and the WNG of the DS beamformer increase. For a given
M and a suﬃciently small 𝛿, the DF of the distortionless maximum DF beamformer
increases as a function of 𝛿. The WNG of the distortionless maximum DF beamformer
is signiﬁcantly lower than dB, which implies that the distortionless maximum DF
beamformer ampliﬁes the white noise.
■
11.4.4
Superdirective
The time-domain superdirective beamformer is simply a particular case of the distor-
tionless maximum DF beamformer, where 𝜃d = and 𝛿is small. We get
𝐡SD = 𝚪−
T,,𝜋𝐆
(
𝐆T𝚪−
T,,𝜋𝐆
)−
𝐢l,
(.)

410
Fundamentals of Signal Enhancement and Array Signal Processing
0
30
60
90
120
150
180
−20
−15
−10
−5
0
0
30
60
90
120
150
180
−20
−15
−10
−5
0
−20
−15
−10
−5
0
0
30
60
90
120
150
180
0
30
60
90
120
150
180
−20
−15
−10
−5
0
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(b)
(a)
(c)
(d)
hmDF
(dB)
   (cos θd) , cos θ
hmDF
(dB)
   (cos θd) , cos θ
hmDF
(dB)
   (cos θd) , cos θ
hmDF
(dB)
   (cos θd) , cos θ
Figure 11.7 Broadband beampatterns of the distortionless maximum DF beamformer for 𝜃d = 90◦,
and several values of M and 𝛿: (a) M = 10, 𝛿= 1 cm, (b) M = 30, 𝛿= 1 cm, (c) M = 10, 𝛿= 3 cm, and
(d) M = 30, 𝛿= 3 cm.
where 𝐆= 𝐆(cos ). The corresponding DF is

(
𝐡SD
)
=

𝐢T
l
(
𝐆T𝚪−
T,,𝜋𝐆
)−
𝐢l
.
(.)
This gain should approach Mfor a small value of 𝛿.
Following the ideas of Cox et al. [, ], we can easily derive the time-domain robust
superdirective beamformer:
𝐡R,𝜖= 𝚪−
T,,𝜋,𝜖𝐆
(
𝐆T𝚪−
T,,𝜋,𝜖𝐆
)−
𝐢l,
(.)
where
𝚪T,,𝜋,𝜖= 𝚪T,,𝜋+ 𝜖𝐈MLh,
(.)
with 𝜖≥. We see that 𝐡R,= 𝐡SD and 𝐡R,∞= 𝐡DS ().
www.ebook3000.com

Beamforming in the Time Domain
411
−25
−25
−25
−20
−15
−10
−5
0
−20
−15
−10
−5
0
−25
−20
−15
−10
−5
0
−20
−15
−10
−5
0
(a)
(b)
(c)
(d)
0
30
60
90
120
150
180
0
30
60
90
120
150
180
θ (deg)
θ (deg)
0
30
60
90
120
150
180
0
30
60
90
120
150
180
θ (deg)
θ (deg)
hmDF
(dB)
  (cos θd) , cos θ
hmDF
(dB)
  (cos θd) , cos θ
hmDF
(dB)
  (cos θd) , cos θ
hmDF
(dB)
  (cos θd) , cos θ
Figure 11.8 Broadband beampatterns of the distortionless maximum DF beamformer for 𝜃d = 45◦,
and several values of M and 𝛿: (a) M = 10, 𝛿= 1 cm, (b) M = 30, 𝛿= 1 cm, (c) M = 10, 𝛿= 3 cm, and
(d) M = 30, 𝛿= 3 cm.
Example ..
Returning to Example .., we now employ the robust superdirec-
tive beamformer, 𝐡R,𝜖, given in (.). Figure .shows broadband beampatterns,
||||

(
𝐡R,𝜖, cos 𝜃
)||||
, for M = , 𝛿= cm, and several values of 𝜖. The main beam is in the
direction of the desired signal, 𝜃d = . As the value of 𝜖increases, the width of the main
beam increases, and the sidelobe level also increases (lower DF). Figure .shows
plots of the DF, 
(
𝐡R,𝜖
)
, and the WNG, 
(
𝐡R,𝜖
)
, as a function of 𝛿for several values
of 𝜖. For a given 𝛿, as the value of 𝜖increases, the WNG of the robust superdirective
beamformer increases at the expense of a lower DF. For a given 𝜖and a suﬃciently
small 𝛿, both the DF and the WNG of the robust superdirective beamformer increase
as a function of 𝛿.
■
11.4.5
Null Steering
We assume that we have an undesired source impinging on the array from the direction
𝜃n ≠𝜃d. The objective is to completely cancel this source while recovering the desired

412
Fundamentals of Signal Enhancement and Array Signal Processing
−25
−35
−20
−30
−15
−10
−5
0
−25
−35
−20
−30
−15
−10
−5
0
−25
−35
−20
−30
−15
−10
−5
0
−25
−35
−20
−30
−15
−10
−5
0
(a)
0
30
60
90
120
150
180
θ (deg)
(b)
0
30
60
90
120
150
180
θ (deg)
hmDF
(dB)
   (cos θd) , cos θ
hmDF
(dB)
   (cos θd) , cos θ
hmDF
(dB)
   (cos θd) , cos θ
hmDF
(dB)
   (cos θd) , cos θ
(d)
0
30
60
90
120
150
180
θ (deg)
(c)
0
30
60
90
120
150
180
θ (deg)
Figure 11.9 Broadband beampatterns of the distortionless maximum DF beamformer for 𝜃d = 0◦, and
several values of M and 𝛿: (a) M = 10, 𝛿= 1 cm, (b) M = 30, 𝛿= 1 cm, (c) M = 10, 𝛿= 3 cm, and
(d) M = 30, 𝛿= 3 cm.
0.5
1
1.5
2
2.5
3
3.5
4
10
15
20
25
30
0.5
1
1.5
2
2.5
3
3.5
4
−95
−90
−85
−80
−75
−70
−65
−60
δ (cm)
δ (cm)
(a)
(b)
h mDF (cos θd) (dB)
h mDF (cos θd) (dB)
Figure 11.10 (a) DF and (b) WNG of the distortionless maximum DF beamformer as a function of 𝛿for
𝜃d = 0◦and several values of M: M = 10 (solid line with circles), M = 20 (dashed line with asterisks),
M = 30 (dotted line with squares), and M = 40 (dash-dot line with triangles).
www.ebook3000.com

Beamforming in the Time Domain
413
−25
−20
−30
−15
−10
−5
0
(a)
(b)
(c)
(d)
0
30
60
90
120
150
180
θ (deg)
−25
−20
−30
−15
−10
−5
0
0
30
60
90
120
150
180
θ (deg)
−25
−20
−30
−15
−10
−5
0
0
30
60
90
120
150
180
θ (deg)
−25
−20
−30
−15
−10
−5
0
0
30
60
90
120
150
180
θ (deg)
hR,ϵ, cos θ) (dB)
(
hR,ϵ, cos θ) (dB)
(
hR,ϵ, cos θ) (dB)
(
hR,ϵ, cos θ) (dB)
(
Figure 11.11 Broadband beampatterns of the robust superdirective beamformer for M = 10,
𝛿= 1 cm, and several values of 𝜖: (a) 𝜖= 10−5, (b) 𝜖= 10−3, (c) 𝜖= 0.1, and (d) 𝜖= 1.
2
0
4
6
8
10
12
14
(a)
(b)
−30
−40
−20
−10
0
10
0.5
1
1.5
2
2.5
3
3.5
4
δ (cm)
0.5
1
1.5
2
2.5
3
3.5
4
δ (cm)
h R,ϵ (dB)
h R,ϵ (dB)
Figure 11.12 (a) DF and (b) WNG of the robust superdirective beamformer as a function of 𝛿for
M = 10 and several values of 𝜖: 𝜖= 10−5 (solid line with circles), 𝜖= 10−3 (dashed line with asterisks),
𝜖= 0.1 (dotted line with squares), and 𝜖= 1 (dash-dot line with triangles).

414
Fundamentals of Signal Enhancement and Array Signal Processing
source impinging on the array from the direction 𝜃d. Then, it is obvious that the
constraint equation is
𝐂T (𝜃d, 𝜃n
) 𝐡=
[
𝐢l
𝟎
]
,
(.)
where
𝐂(𝜃d, 𝜃n
) = [ 𝐆(cos 𝜃d
)
𝐆(cos 𝜃n
) ]
(.)
is the constraint matrix of size MLh × L and 𝟎is the zero vector of length L.
Depending on what we desire, there are diﬀerent ways to achieve the goal explained
above. We present two of these methods.
The ﬁrst obvious beamformer is obtained by maximizing the WNG and by taking
(.) into account:
min
𝐡𝐡T𝐡subject to 𝐂T (𝜃d, 𝜃n
) 𝐡=
[
𝐢l
𝟎
]
.
(.)
From this criterion, we ﬁnd the minimum-norm (MN) beamformer:
𝐡MN
(cos 𝜃d
) = 𝐂(𝜃d, 𝜃n
) [𝐂T (𝜃d, 𝜃n
) 𝐂(𝜃d, 𝜃n
)]−[
𝐢l
𝟎
]
,
(.)
which is also the minimum-norm solution of (.).
The other beamformer is obtained by maximizing the DF and by taking (.) into
account:
min
𝐡𝐡T𝚪T,,𝜋𝐡subject to 𝐂T (
𝜃d, 𝜃n
)
𝐡=
[
𝐢l
𝟎
]
.
(.)
We easily ﬁnd the null steering (NS) beamformer:
𝐡NS
(
cos 𝜃d
)
= 𝚪−
T,,𝜋𝐂
(
𝜃d, 𝜃n
)
×
[
𝐂T (𝜃d, 𝜃n
) 𝚪−
T,,𝜋𝐂(𝜃d, 𝜃n
)]−[
𝐢l
𝟎
]
.
(.)
Example ..
Consider a ULA of M sensors. Suppose that a desired signal impinges
on the ULA from the direction 𝜃d = ◦, and an undesired interference impinges on the
ULA from the direction 𝜃n = ◦. Assume that fs = kHz, P = , and Lh = .
Figure .shows broadband beampatterns, |||[
𝐡MN
(
cos 𝜃d
)
, cos 𝜃
]|||, for several
values of M and 𝛿. Clearly, the beam is in the direction of the desired signal, 𝜃d, and
the null is in the direction of the interfering signal, 𝜃n. As the number of sensors, M,
increases, or as the intersensor spacing, 𝛿, increases, the width of the main beam and
the level of the sidelobe decrease. Figure .shows plots of the DF, 
[
𝐡MN
(
cos 𝜃d
)]
,
and the WNG, [𝐡MN
(cos 𝜃d
)], as a function of 𝛿for several values of M. For a small 𝛿,
www.ebook3000.com

Beamforming in the Time Domain
415
−50
−50
−40
−30
−20
−10
0
−40
−30
−20
−10
0
0
−50
−40
−30
−20
−10
0
−50
−40
−30
−20
−10
0
30
60
90
120
150
180
θ (deg)
0
(a)
(b)
(c)
(d)
30
60
90
120
150
180
θ (deg)
0
30
60
90
120
150
180
θ (deg)
0
30
60
90
120
150
180
θ (deg)
h MN
(dB)
(cos θd) , cos θ
h MN
(dB)
(cos θd) , cos θ
h MN
(dB)
(cos θd) , cos θ
h MN
(dB)
(cos θd) , cos θ
Figure 11.13 Broadband beampatterns of the MN beamformer for 𝜃d = 0◦, 𝜃n = 90◦, and several
values of M and 𝛿: (a) M = 20, 𝛿= 2 cm, (b) M = 40, 𝛿= 2 cm, (c) M = 20, 𝛿= 4 cm, and (d) M = 40,
𝛿= 4 cm.
both the DF and the WNG increase as M increases. However, for a large 𝛿, the DF and
the WNG of the MN beamformer are less sensitive to M, if M is suﬃciently large. For a
given M and small 𝛿, both the DF and the WNG of the MN beamformer increase as a
function of 𝛿.
Figure .shows broadband beampatterns, |||
[
𝐡NS
(
cos 𝜃d
)
, cos 𝜃
]|||, for several
values of M and 𝛿. Here again, the beam is in the direction of the desired signal, and the
null is in the direction of the interfering signal. As the number of sensors, M, increases,
or as the intersensor spacing, 𝛿, increases, the width of the main beam and the level
of the sidelobe decrease. Figure .shows plots of the DF, [𝐡NS
(cos 𝜃d
)], and the
WNG, [𝐡NS
(cos 𝜃d
)], as a function of 𝛿for several values of M. For a small 𝛿, both
the DF and the WNG of the NS beamformer increase as M increases. For a given M
and small 𝛿, the DF of the NS beamformer increases as a function of 𝛿. Compared
with the MN beamformer, the NS beamformer gives higher DF, but lower WNG. The
WNG of the NS beamformer is signiﬁcantly lower than dB, which implies that the NS
beamformer ampliﬁes the white noise.
■

416
Fundamentals of Signal Enhancement and Array Signal Processing
1
2
3
4
5
6
0
2
4
6
8
10
1
2
3
4
5
6
−5
0
5
10
15
20
(a)
(b)
δ (cm)
δ (cm)
h MN (cos θd) (dB)
h MN(cos θd) (dB)
Figure 11.14 (a) DF and (b) WNG of the MN beamformer as a function of 𝛿, for 𝜃d = 0◦, 𝜃n = 90◦, and
several values of M: M = 10 (solid line with circles), M = 20 (dashed line with asterisks), M = 30 (dotted
line with squares), and M = 40 (dash-dot line with triangles).
−50
−40
−30
−20
−10
0
(a)
(b)
(c)
(d)
−50
−40
−30
−20
−10
0
−40
−30
−20
−10
0
−50
−50
−40
−30
−20
−10
0
0
30
60
90
120
150
180
θ (deg)
0
30
60
90
120
150
180
θ (deg)
0
30
60
90
120
150
180
θ (deg)
0
30
60
90
120
150
180
θ (deg)
hNS
(dB)
(cos θd) , cos θ
hNS
(dB)
(cos θd) , cos θ
hNS
(dB)
(cos θd) , cos θ
hNS
(dB)
(cos θd) , cos θ
Figure 11.15 Broadband beampatterns of the NS beamformer for 𝜃d = 0◦, 𝜃n = 90◦, and several
values of M and 𝛿: (a) M = 20, 𝛿= 2 cm, (b) M = 40, 𝛿= 2 cm, (c) M = 20, 𝛿= 4 cm, and (d) M = 40,
𝛿= 4 cm.
www.ebook3000.com

Beamforming in the Time Domain
417
1
2
3
4
5
6
10
15
20
25
30
1
2
3
4
5
6
−95
−90
−85
−80
−75
−70
−65
(a)
(b)
δ (cm)
δ (cm)
h NS (cos θd) (dB)
h NS (cos θd) (dB)
Figure 11.16 (a) DF and (b) WNG of the NS beamformer as a function of 𝛿, for 𝜃d = 0◦, 𝜃n = 90◦, and
several values of M: M = 10 (solid line with circles), M = 20 (dashed line with asterisks), M = 30 (dotted
line with squares), and M = 40 (dash-dot line with triangles).
Table 11.1 Fixed beamformers in the time domain.
Beamformer
Delay-and-sum
𝐡DS
(cos 𝜃d
) = 𝐆(cos 𝜃d
) 𝐢l
M
Maximum DF
𝐡max
(cos 𝜃d
) = 𝜍𝐭
(cos 𝜃d
) , 𝜍≠
Distortionless max. DF
𝐡mDF
(cos 𝜃d
) = 𝚪−
T,,𝜋𝐆(cos 𝜃d
) ×
[
𝐆T (cos 𝜃d
) 𝚪−
T,,𝜋𝐆(cos 𝜃d
)]−
𝐢l
Superdirective
𝐡SD = 𝚪−
T,,𝜋𝐆
(
𝐆T𝚪−
T,,𝜋𝐆
)−
𝐢l
Robust SD
𝐡R,𝜖= 𝚪−
T,,𝜋,𝜖𝐆
(
𝐆T𝚪−
T,,𝜋,𝜖𝐆
)−
𝐢l
Minimum norm
𝐡MN
(cos 𝜃d
) =
𝐂(𝜃d, 𝜃n
) [𝐂T (𝜃d, 𝜃n
) 𝐂(𝜃d, 𝜃n
)]−
[
𝐢l
𝟎
]
Null steering
𝐡NS
(cos 𝜃d
) = 𝚪−
T,,𝜋𝐂(𝜃d, 𝜃n
) ×
[
𝐂T (𝜃d, 𝜃n
) 𝚪−
T,,𝜋𝐂(𝜃d, 𝜃n
)]−
[
𝐢l
𝟎
]
In Table ., we summarize all the time-domain ﬁxed beamformers derived in this
section.
11.5
Adaptive Beamformers
Most of the adaptive beamformers are easily derived from the time-domain MSE
criterion deﬁned in (.). Below, we give some important examples.

418
Fundamentals of Signal Enhancement and Array Signal Processing
11.5.1
Wiener
From the minimization of the MSE criterion, J
(
𝐡
)
, we ﬁnd the Wiener beamformer:
𝐡W
(cos 𝜃d
) = 𝐑−
𝐲𝐆(cos 𝜃d
) 𝐑𝐱𝐢l
(.)
= 𝐑−
𝐲𝐆
(
cos 𝜃d
)
𝐑𝐱𝐆T (
cos 𝜃d
)
𝐢
= 𝐑−
𝐲𝐑𝐱𝐢,
where 𝐢is a vector of length MLh whose all elements are except for one entry, which
is equal to in the appropriate position. This Wiener beamformer can be rewritten as
𝐡W
(cos 𝜃d
) =
(
𝐈MLh −𝐑−
𝐲𝐑𝐯
)
𝐢.
(.)
This expression depends on the statistics of the observations and noise.
Determining the inverse of 𝐑𝐲from (.) with the Woodbury identity, we get
𝐑−
𝐲= 𝐑−
𝐯−𝐑−
𝐯𝐆
(
cos 𝜃d
)
×
[
𝐑−
𝐱+ 𝐆T (cos 𝜃d
) 𝐑−
𝐯𝐆(cos 𝜃d
)]−
𝐆T (cos 𝜃d
) 𝐑−
𝐯.
(.)
Substituting (.) into (.) leads to another useful formulation of the Wiener
beamformer:
𝐡W
(cos 𝜃d
) = 𝐑−
𝐯𝐆(cos 𝜃d
)
×
[
𝐑−
𝐱+ 𝐆T (cos 𝜃d
) 𝐑−
𝐯𝐆(cos 𝜃d
)]−
𝐢l.
(.)
The output SNR with the Wiener beamformer is greater than the input SNR but the
estimated desired signal is distorted. This distortion is supposed to decrease when the
number of sensors increases.
Example ..
Consider a ULA of M sensors. Suppose that a desired signal, x(t), with
the autocorrelation sequence:
E [x(t)x(t′)] = 𝛼|t−t′|, −< 𝛼< 
impinges on the ULA from the direction 𝜃d = ◦. Assume that an undesired white
Gaussian noise interference, u(t), impinges on the ULA from the direction 𝜃n = ◦,
u(t) ∼(, 𝜎
u
), which is uncorrelated with x(t). In addition, the sensors contain
thermal white Gaussian noise, wm(t) ∼(, 𝜎
w
), the signals of which are mutually
uncorrelated. The noisy received signals are given by ym(t) = xm(t) + vm(t), m =
, … , M, where vm(t) = um(t) + wm(t), m = , … , M are the interference-plus-noise
signals.
www.ebook3000.com

Beamforming in the Time Domain
419
The elements of the L × L matrix 𝐑𝐱are
[𝐑𝐱
]
i,j = 𝛼|i−j|, i, j = , … , L.
The MLh × MLh correlation matrix of 𝐱(t) is
𝐑𝐱= 𝐆(cos 𝜃d
) 𝐑𝐱𝐆T (cos 𝜃d
) .
Since the interference is in the broadside direction, the MLh × MLh correlation matrix
of 𝐯(t) is
𝐑𝐯= 𝟏M ⊗𝜎
u𝐈Lh + 𝜎
w𝐈MLh,
where ⊗is the Kronecker product and 𝟏M is an M × M matrix of all ones.
To demonstrate the performance of the Wiener beamformer, we choose fs = kHz,
𝛿= cm, 𝛼= ., 𝜎
w = .𝜎
u, P = , and Lh = . Figure .shows
plots of the array gain, [𝐡W
(cos 𝜃d
)], the noise reduction factor, 𝜉n
[𝐡W
(cos 𝜃d
)], the
desired signal reduction factor, 𝜉d
[𝐡W
(cos 𝜃d
)], and the desired signal distortion index,
𝜐d
[
𝐡W
(
cos 𝜃d
)]
, as a function of the input SNR, for diﬀerent numbers of sensors, M.
For a given input SNR, as the number of sensors increases, the array gain and the noise
reduction factor increase, while the desired signal reduction factor and the desired
signal distortion index decrease.
Figure .shows broadband beampatterns, |||[𝐡W
(cos 𝜃d
) , cos 𝜃]|||, for diﬀerent
numbers of sensors, M. The main beam is in the direction of the desired signal, 𝜃d, and
there is a null in the direction of the interference, 𝜃n. As the number of sensors increases,
the width of the main beam decreases, and the null in the direction of the interference
becomes deeper.
■
11.5.2
MVDR
From the optimization of the criterion:
min
𝐡𝐡T𝐑𝐯𝐡subject to 𝐡T𝐆
(
cos 𝜃d
)
= 𝐢T
l ,
(.)
we ﬁnd the MVDR beamformer:
𝐡MVDR
(
cos 𝜃d
)
= 𝐑−
𝐯𝐆
(
cos 𝜃d
) [
𝐆T (
cos 𝜃d
)
𝐑−
𝐯𝐆
(
cos 𝜃d
)]−
𝐢l.
(.)
It can be shown that the MVDR beamformer is also
𝐡MVDR
(cos 𝜃d
) = 𝐑−
𝐲𝐆(cos 𝜃d
) [
𝐆T (cos 𝜃d
) 𝐑−
𝐲𝐆(cos 𝜃d
)]−
𝐢l.
(.)
This formulation is more useful in practice as it depends on the statistics of the
observations only.

420
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
10
12
14
16
18
20
22
−5
0
5
10
15
10
12
14
16
18
20
22
−5
0
5
10
15
0
0.5
1
1.5
2
2.5
−5
0
5
10
15
−70
−60
−50
−40
−30
−20
−10
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(a)
(b)
(c)
(d)
d hW (cos θd) (dB)
d hW (cos θd) (dB)
n hW (cos θd) (dB)
hW (cos θd) (dB)
Figure 11.17 (a) The array gain, (b) the noise reduction factor, (c) the desired signal reduction factor,
and (d) the desired signal distortion index of the Wiener beamformer as a function of the input SNR,
for different numbers of sensors, M: M = 4 (solid line with circles), M = 6 (dashed line with asterisks),
M = 10 (dotted line with squares), and M = 15 (dash-dot line with triangles).
We always have
oSNR [𝐡MVDR
(cos 𝜃d
)] ≤oSNR [𝐡W
(cos 𝜃d
)] .
(.)
Also, with the signal model given in (.), the MVDR beamformer does not distort the
desired signal. However, in practice, since this model does not include reverberation,
𝐡MVDR
(
cos 𝜃d
)
may no longer be distortionless.
Example ..
Returning to Example .., we now employ the MVDR beam-
former, 𝐡MVDR
(
cos 𝜃d
)
, given in (.). Figure .shows plots of the array gain,
[𝐡MVDR
(cos 𝜃d
)], the noise reduction factor, 𝜉n
[𝐡MVDR
(cos 𝜃d
)], the desired signal
reduction factor, 𝜉d
[𝐡MVDR
(cos 𝜃d
)], and the MSE, J [𝐡MVDR
(cos 𝜃d
)], as a function
of the input SNR, for diﬀerent numbers of sensors, M. For a given input SNR, as the
number of sensors increases, the array gain and the noise reduction factor increase,
while the MSE decreases.
Figure .shows broadband beampatterns, |||
[
𝐡MVDR
(
cos 𝜃d
)
, cos 𝜃
]|||, for diﬀerent
numbers of sensors, M. The main beam is in the direction of the desired signal, 𝜃d, and
www.ebook3000.com

Beamforming in the Time Domain
421
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(b)
(a)
(c)
(d)
hW
(dB)
   (cos θd) , cos θ
hW
(dB)
   (cos θd) , cos θ
hW
(dB)
   (cos θd) , cos θ
hW
(dB)
   (cos θd) , cos θ
−40
−35
−30
−25
−20
−15
−10
−5
0
−40
−35
−30
−25
−20
−15
−10
−5
0
−40
−35
−30
−25
−20
−15
−10
−5
0
−40
−35
−30
−25
−20
−15
−10
−5
0
Figure 11.18 Broadband beampatterns of the Wiener beamformer for different numbers of sensors,
M: (a) M = 4, (b) M = 6, (c) M = 10, and (d) M = 15.
there is a null in the direction of the interference, 𝜃n. As the number of sensors increases,
the width of the main beam decreases, the null in the direction of the interference
becomes deeper, and the level of the sidelobe decreases.
■
11.5.3
Tradeoff
The easiest way to compromise between desired signal distortion and noise reduction
is to optimize the criterion:
min
𝐡Jd
(
𝐡
)
subject to Jn
(
𝐡
)
= ℵ𝜎
v,
(.)
where < ℵ< to ensure that we get some noise reduction. By using a Lagrange
multiplier, 𝜇> , to adjoin the constraint to the cost function, we get the tradeoﬀ
beamformer:
𝐡T,𝜇
(
cos 𝜃d
)
= 𝐑−
𝐯𝐆
(
cos 𝜃d
)
×
[
𝜇𝐑−
𝐱+ 𝐆T (cos 𝜃d
) 𝐑−
𝐯𝐆(cos 𝜃d
)]−
𝐢l.
(.)

422
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
10
12
14
16
18
20
22
−5
0
5
10
15
10
12
14
16
18
20
22
−5
0
5
10
15
0
–0.5
1
0.5
0
−5
0
5
10
15
−40
−25
−30
−35
−20
−5
−10
−15
iSNR(dB)
iSNR(dB)
iSNR(dB)
iSNR(dB)
(a)
(b)
(c)
(d)
h MVDR (cos θd) (dB)
h MVDR (cos θd) (dB)
h MVDR (cos θd) (dB)
h MVDR (cos θd) (dB)
J
n
d
Figure 11.19 (a) The array gain, (b) the noise reduction factor, (c) the desired signal reduction factor,
and (d) the MSE of the MVDR beamformer as a function of the input SNR, for different numbers of
sensors, M: M = 4 (solid line with circles), M = 6 (dashed line with asterisks), M = 10 (dotted line with
squares), and M = 15 (dash-dot line with triangles).
We can see that for:
●𝜇= , 𝐡T,
(cos 𝜃d
) = 𝐡W
(cos 𝜃d
), which is the Wiener beamformer
●𝜇= , 𝐡T,
(
cos 𝜃d
)
= 𝐡MVDR
(
cos 𝜃d
)
, which is the MVDR beamformer
●𝜇> , the result is a beamformer with low residual noise at the expense of high desired
signal distortion (as compared to Wiener)
●𝜇< , the result is a beamformer with high residual noise and low desired signal
distortion (as compared to Wiener).
Example ..
Returning to Example .., we now employ the tradeoﬀbeam-
former, 𝐡T,𝜇
(cos 𝜃d
), given in (.). Figure .shows plots of the array gain,

[
𝐡T,𝜇
(cos 𝜃d
)]
, the noise reduction factor, 𝜉n
[
𝐡T,𝜇
(cos 𝜃d
)]
, the desired signal reduc-
tion factor, 𝜉d
[
𝐡T,𝜇
(cos 𝜃d
)]
, and the desired signal distortion index, 𝜐d
[
𝐡T,𝜇
(cos 𝜃d
)]
,
as a function of the input SNR, for M = and several values of 𝜇. For a given input
SNR, the higher the value of 𝜇, the higher are the array gain and the noise reduction
www.ebook3000.com

Beamforming in the Time Domain
423
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
θ (deg)
θ (deg)
θ (deg)
θ (deg)
−40
−35
−30
−25
−20
−15
−10
−5
0
−40
−35
−30
−25
−20
−15
−10
−5
0
−40
−35
−30
−25
−20
−15
−10
−5
0
−40
−35
−30
−25
−20
−15
−10
−5
0
(b)
(a)
(c)
(d)
hMVDR
(dB)
    (cos θd) , cos θ
hMVDR
(dB)
    (cos θd) , cos θ
hMVDR
(dB)
    (cos θd) , cos θ
hMVDR
(dB)
    (cos θd) , cos θ
Figure 11.20 Broadband beampatterns of the MVDR beamformer for different numbers of sensors, M:
(a) M = 4, (b) M = 6, (c) M = 10, and (d) M = 15.
factor, but at the expense of higher desired signal reduction factor and higher desired
signal distortion index.
Figure .shows broadband beampatterns,
||||

[
𝐡T,𝜇
(
cos 𝜃d
)
, cos 𝜃
]||||
, for M = 
and several values of 𝜇. The main beam is in the direction, 𝜃d, of the desired signal, and
there is a null in the direction of the interference, 𝜃n.
■
11.5.4
Maximum SNR
Let us denote by 𝐭′

(
cos 𝜃d
)
the eigenvector corresponding to the maximum eigenvalue,
𝜆′

(cos 𝜃d
), of the matrix 𝐑−
𝐯𝐆(cos 𝜃d
) 𝐑𝐱𝐆T (cos 𝜃d
). It is clear that the beamformer:
𝐡max
(cos 𝜃d
) = 𝜍𝐭′

(cos 𝜃d
) ,
(.)
where 𝜍≠is an arbitrary real number, maximizes the output SNR, as deﬁned in (.).
With the maximum SNR beamformer, 𝐡max
(
cos 𝜃d
)
, the output SNR is
oSNR [𝐡max
(cos 𝜃d
)] = 𝜆′

(cos 𝜃d
)
(.)

424
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
−5
0
5
10
15
18
18.5
19
19.5
20
18
18.5
19
19.5
20
20.5
21
21.5
−5
0
5
10
15
0
0.5
1
1.5
−5
0
5
10
15
−70
−60
−50
−40
−30
−20
−10
iSNR(dB)
iSNR(dB)
iSNR(dB)
iSNR(dB)
h T,μ(cos θd) (dB)
h T,μ(cos θd) (dB)
ξn
h T,μ(cos θd) (dB)
ξd
(a)
(b)
(c)
(d)
h T,μ(cos θd) (dB)
d
Figure 11.21 (a) The array gain, (b) the noise reduction factor, (c) the desired signal reduction factor,
and (d) the desired signal distortion index of the tradeoff beamformer as a function of the input SNR,
for M = 10 and several values of 𝜇: 𝜇= 0.5 (solid line with circles), 𝜇= 1 (dashed line with asterisks),
𝜇= 2 (dotted line with squares), and 𝜇= 5 (dash-dot line with triangles).
and
oSNR [𝐡max
(cos 𝜃d
)] ≥oSNR (𝐡) , ∀𝐡.
(.)
The parameter 𝜍can be found by minimizing distortion or the MSE. Substituting (.)
into (.) we obtain
J
(
𝐡) = 𝜎
x −𝜍𝐭′T

(cos 𝜃d
) 𝐆(cos 𝜃d
) 𝐑𝐱𝐢l+
𝜍𝐭′T

(cos 𝜃d
) 𝐑𝐲𝐭′

(cos 𝜃d
) .
(.)
Therefore, the value of 𝜍that minimizes the MSE is given by
𝜍=
𝐭′T

(cos 𝜃d
) 𝐆(cos 𝜃d
) 𝐑𝐱𝐢l
𝐭′T

(
cos 𝜃d
)
𝐑𝐲𝐭′

(
cos 𝜃d
) .
(.)
Example ..
Returning to Example .., we now employ the maximum SNR
beamformer, 𝐡max
(cos 𝜃d
), given in (.) with the value of 𝜍that minimizes the MSE.
www.ebook3000.com

Beamforming in the Time Domain
425
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(b)
(a)
(c)
(d)
−30
−25
−20
−15
−10
−5
0
−30
−25
−20
−15
−10
−5
0
−30
−25
−20
−15
−10
−5
0
−30
−25
−20
−15
−10
−5
0
(c)
(d)
hT,μ
(dB)
   (cos θd) , cos θ
hT,μ
(dB)
   (cos θd) , cos θ
hT,μ
(dB)
   (cos θd) , cos θ
hT,μ
(dB)
   (cos θd) , cos θ
Figure 11.22 Broadband beampatterns of the tradeoff beamformer for M = 10 and several values of
𝜇: (a) 𝜇= 0.5, (b) 𝜇= 1, (c) 𝜇= 2, and (d) 𝜇= 5.
Figure .shows plots of the array gain, [𝐡max
(cos 𝜃d
)], the noise reduction factor,
𝜉n
[𝐡max
(cos 𝜃d
)], the desired signal reduction factor, 𝜉d
[𝐡max
(cos 𝜃d
)], and the desired
signal distortion index, 𝜐d
[
𝐡max
(
cos 𝜃d
)]
, as a function of the input SNR, for diﬀerent
numbers of sensors, M. For a given input SNR, as the number of sensors increases, the
array gain and noise reduction factor increase, while the desired signal reduction factor
and desired signal distortion index decrease.
Figure .shows broadband beampatterns, |||[𝐡max
(cos 𝜃d
) , cos 𝜃]|||, for diﬀerent
numbers of sensors, M. The main beam is in the direction of the desired signal, 𝜃d, and
there is a null in the direction of the interference, 𝜃n. As the number of sensors increases,
the null in the direction of the interference becomes deeper.
■
11.5.5
LCMV
We assume that we have an undesired source impinging on the array from the direction
𝜃n ≠𝜃d. The objective is to completely cancel this source while recovering the desired
source impinging on the array from the direction 𝜃d. Then, it is obvious that the
constraint equation is identical to the one given in (.).

426
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
−5
0
5
10
15
−5
0
5
10
15
−5
0
5
10
15
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(a)
(b)
(c)
(d)
h max(cos θd) (dB)
20
21
22
23
24
25
26
27
28
−5
−4
−3
−2
−1
0
12
14
16
18
20
22
24
26
1
2
3
4
5
6
7
8
9
hmax(cos θd) (dB)
ξd
hmax(cos θd) (dB)
d
(dB)
hmax(cos θd)
ξn
Figure 11.23 (a) The array gain, (b) the noise reduction factor, (c) the desired signal reduction factor,
and (d) the desired signal distortion index of the maximum SNR beamformer as a function of the input
SNR, for different numbers of sensors, M: M = 4 (solid line with circles), M = 6 (dashed line with
asterisks), M = 10 (dotted line with squares), and M = 15 (dash-dot line with triangles).
The above problem is solved by minimizing the MSE of the residual noise, Jr
(
𝐡
)
,
subject (.):
min
𝐡𝐡T𝐑𝐯𝐡subject to 𝐂T (
𝜃d, 𝜃n
)
𝐡=
[
𝐢l
𝟎
]
(.)
The solution to this optimization problem gives the well-known LCMV beamformer
[, ]:
𝐡LCMV
(cos 𝜃d
) = 𝐑−
𝐯𝐂(𝜃d, 𝜃n
)
×
[
𝐂T (𝜃d, 𝜃n
) 𝐑−
𝐯𝐂(𝜃d, 𝜃n
)]−[
𝐢l
𝟎
]
,
(.)
which depends on the statistics of the noise only.
www.ebook3000.com

Beamforming in the Time Domain
427
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
θ (deg)
θ (deg)
θ (deg)
θ (deg)
−30
−40
−50
−20
−10
0
−30
−40
−50
−20
−10
0
−30
−40
−50
−20
−10
−30
−40
−50
−20
−10
0
0
(b)
(a)
(c)
h
(dB)
   (cos θd) , cos θ
max
h
(dB)
   (cos θd) , cos θ
max
h
(dB)
   (cos θd) , cos θ
max
h
(dB)
   (cos θd) , cos θ
max
(d)
Figure 11.24 Broadband beampatterns of the maximum SNR beamformer for different numbers of
sensors, M: (a) M = 4, (b) M = 6, (c) M = 10, and (d) M = 15.
It can be shown that a more useful formulation of the LCMV beamformer is
𝐡LCMV
(cos 𝜃d
) = 𝐑−
𝐲𝐂(𝜃d, 𝜃n
)
×
[
𝐂T (
𝜃d, 𝜃n
)
𝐑−
𝐲𝐂
(
𝜃d, 𝜃n
)]−[
𝐢l
𝟎
]
.
(.)
This depends on the statistics of the observations only, which should be easy to estimate.
Example ..
Returning to Example .., we now employ the LCMV beam-
former, 𝐡LCMV
(
cos 𝜃d
)
, given in (.). Figure .shows plots of the array gain,
[𝐡LCMV
(cos 𝜃d
)], the noise reduction factor, 𝜉n
[𝐡LCMV
(cos 𝜃d
)], the desired signal
reduction factor, 𝜉d
[𝐡LCMV
(cos 𝜃d
)], and the MSE, J [𝐡LCMV
(cos 𝜃d
)], as a function
of the input SNR, for diﬀerent numbers of sensors, M. For a given input SNR, as the
number of sensors increases, the array gain and the noise reduction factor slightly
increase.
Figure .shows broadband beampatterns, |||
[
𝐡LCMV
(
cos 𝜃d
)
, cos 𝜃
]|||, for dif-
ferent numbers of sensors, M. The main beam is in the direction of the desired

428
Fundamentals of Signal Enhancement and Array Signal Processing
−5
0
5
10
15
−5
0
5
10
15
−5
0
5
10
15
−5
0
5
10
15
iSNR (dB)
iSNR (dB)
iSNR (dB)
iSNR (dB)
(a)
(b)
(c)
(d)
24.25
24.3
24.35
24.4
24.45
24.5
24.55
24.6
24.65
24.25
24.3
24.35
24.4
24.45
24.5
24.55
24.6
24.65
−1
−0.5
0
0.5
1
−40
−35
−30
−25
−20
−15
h LCMV (cos θd) (dB)
h LCMV (cos θd) (dB)
ξn
h LCMV (cos θd) (dB)
ξd
h LCMV (cos θd) (dB)
J
Figure 11.25 (a) The array gain, (b) the noise reduction factor, (c) the desired signal reduction factor,
and (d) the MSE of the LCMV beamformer as a function of the input SNR, for different numbers of
sensors, M: M = 30 (solid line with circles), M = 35 (dashed line with asterisks), M = 40 (dotted line
with squares), and M = 45 (dash-dot line with triangles).
signal, 𝜃d, and there is a null in the direction of the interference, 𝜃n. In particular,
|||[𝐡LCMV
(cos 𝜃d
) , cos 𝜃]||| is for 𝜃= 𝜃d, and is identically zero for 𝜃n.
■
In Table ., we summarize all the time-domain adaptive beamformers derived in
this section.
11.6
Differential Beamformers
As we usually do in diﬀerential beamforming, we assume in this section that the
interelement spacing, 𝛿, is small and the desired source signal propagates from the
endﬁre; that is, 𝜃d = . To simplify the presentation, we write 𝐆m (cos ) = 𝐆m.
11.6.1
First Order
It is well known that the design of a ﬁrst-order diﬀerential beamformer requires at least
two sensors [, ]. First, we assume that we have exactly two sensors (M = ). In this
www.ebook3000.com

Beamforming in the Time Domain
429
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(a)
(c)
−30
−40
−50
−20
−10
0
−30
−40
−50
−20
−10
0
−30
−40
−50
−20
−10
−30
−40
−50
−20
−10
0
0
h
(dB)
   (cos θd) , cos θ
LCMV
h
(dB)
   (cos θd) , cos θ
LCMV
(b)
(d)
h
(dB)
   (cos θd) , cos θ
LCMV
h
(dB)
   (cos θd) , cos θ
LCMV
Figure 11.26 Broadband beampatterns of the LCMV beamformer for different numbers of sensors, M:
(a) M = 30, (b) M = 35, (c) M = 40, and (d) M = 45.
Table 11.2 Adaptive beamformers in the time domain.
Beamformer
Wiener
𝐡W
(cos 𝜃d
) = 𝐑−
𝐯𝐆(cos 𝜃d
) ×
[
𝐑−
𝐱+ 𝐆T (cos 𝜃d
) 𝐑−
𝐯𝐆(cos 𝜃d
)]−
𝐢l
MVDR
𝐡MVDR
(cos 𝜃d
) = 𝐑−
𝐯𝐆(cos 𝜃d
) ×
[
𝐆T (cos 𝜃d
) 𝐑−
𝐯𝐆(cos 𝜃d
)]−
𝐢l
Tradeoﬀ
𝐡T,𝜇
(cos 𝜃d
) = 𝐑−
𝐯𝐆(cos 𝜃d
) ×
[
𝜇𝐑−
𝐱+ 𝐆T (cos 𝜃d
) 𝐑−
𝐯𝐆(cos 𝜃d
)]−
𝐢l, 𝜇≥
Maximum SNR
𝐡max
(cos 𝜃d
) = 𝜍𝐭′

(cos 𝜃d
) , 𝜍≠
LCMV
𝐡LCMV
(cos 𝜃d
) = 𝐑−
𝐯𝐂(𝜃d, 𝜃n
) ×
[
𝐂T (𝜃d, 𝜃n
) 𝐑−
𝐯𝐂(𝜃d, 𝜃n
)]−
[
𝐢l
𝟎
]

430
Fundamentals of Signal Enhancement and Array Signal Processing
case, we have two constraints to fulﬁll; the distortionless one given in (.) and a
constraint with a null in the direction 𝜃∈
[
𝜋
, 𝜋
]
:
𝐡T𝐆
(
cos 𝜃
)
= 𝟎T.
(.)
Combining these two constraints together, we get the following linear system to solve
[
𝐆T

𝐆T

𝐆T

(cos 𝜃
)
𝐆T

(cos 𝜃
)
] [
𝐡
𝐡
]
=
[
𝐢l
𝟎
]
(.)
or, equivalently,
𝐂T
,
(𝜃
) 𝐡,= 𝐢,
(.)
where 𝐂T
,
(𝜃
) is a matrixof size L×Lh. Since L = Lg +Lh −≥Lh, we deduce from
(.) the least-squares (LS) ﬁlter:
𝐡,;LS =
[
𝐂,
(
𝜃
)
𝐂T
,
(
𝜃
)]−
𝐂,
(
𝜃
)
𝐢.
(.)
The performance of this beamformer may not be satisfactory in practice as far as the
WNG is concerned.
Let us assume that the number of sensors is given and equal to M > . We still have
two constraints to fulﬁll and the linear system to solve is now
[
𝐆T

𝐆T

⋯
𝐆T
M
𝐆T

(cos 𝜃
)
𝐆T

(cos 𝜃
)
⋯
𝐆T
M
(cos 𝜃
)
] ⎡
⎢
⎢
⎢⎣
𝐡
𝐡
⋮
𝐡M
⎤
⎥
⎥
⎥⎦
= 𝐢
(.)
or, equivalently,
𝐂T
,M
(𝜃
) 𝐡,M = 𝐢,
(.)
where 𝐂T
,M
(𝜃
) is a matrix of size L × MLh. We can always ﬁnd the length Lh in such
a way that MLh = L:
Lh = 
Lg −
M −.
(.)
In this case, 𝐂T
,M
(𝜃
) is a square matrix and the solution to (.) is exact:
𝐡,M;E = 𝐂−T
,M
(
𝜃
)
𝐢.
(.)
The subscript corresponds to the diﬀerential beamformer order and the subscript corresponds to the
number of sensors.
www.ebook3000.com

Beamforming in the Time Domain
431
If the value of Lh given in (.) is not an integer, we can always take it such as MLh > L.
As a consequence, we get the minimum-norm (MN) ﬁlter:
𝐡,M;MN = 𝐂,M
(
𝜃
) [
𝐂T
,M
(
𝜃
)
𝐂,M
(
𝜃
)
+ 𝜖𝐈L
]−
𝐢,
(.)
where 𝜖≥is the regularization parameter.
Example ..
In this example, we demonstrate the MN ﬁlter in the design of the
robust dipole (𝜃= 𝜋∕) and cardioid (𝜃= 𝜋). We choose fs = kHz, 𝛿= cm,
P = , and 𝜖= −.
Figure .shows plots of the DF, 
(
𝐡,M;MN
)
, and the WNG, 
(
𝐡,M;MN
)
, of
the ﬁrst-order dipole as a function of Lh for several values of M. From this ﬁgure, we
can choose an appropriate length Lh that is suﬃciently large to maintain high DF and
WNG. Figure .shows broadband beampatterns,
||||

(
𝐡,M;MN, cos 𝜃
)||||
, of the ﬁrst-
order dipole for Lh = and several values of M.
Figure .shows plots of the DF, 
(
𝐡,M;MN
)
, and the WNG, 
(
𝐡,M;MN
)
, of
the ﬁrst-order cardioid as a function of Lh for several values of M. Again, from this
ﬁgure we can choose an appropriate length Lh. Figure .shows broadband beam-
patterns,
||||

(
𝐡,M;MN, cos 𝜃
)||||
, of the ﬁrst-order cardioid for Lh = and several values
of M.
■
10
20
30
40
50
10
20
30
40
50
–12
–10
–8
–6
–4
–2
0
2
4
−25
−20
−15
−10
−5
0
5
10
(a)
(b)
h1, M;MN) (dB)
(
h1, M;MN) (dB)
(
L
L
Figure 11.27 (a) DF and (b) WNG of the first-order dipole as a function of Lh for several values of M:
M = 4 (solid line with circles), M = 6 (dashed line with asterisks), M = 8 (dotted line with squares), and
M = 10 (dash-dot line with triangles).

432
Fundamentals of Signal Enhancement and Array Signal Processing
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(a)
(c)
−30
−40
−50
−20
−10
0
−30
−40
−50
−20
−10
0
−30
−40
−50
−20
−10
−30
−40
−50
−20
−10
0
0
(b)
(d)
h1, M;MN, cos θ)  (dB)
(
h1, M;MN, cos θ)  (dB)
(
h1, M;MN, cos θ)  (dB)
(
h1, M;MN, cos θ)  (dB)
(
Figure 11.28 Broadband beampatterns of the first-order dipole for Lh = 25 and several values of M:
(a) M = 4, (b) M = 6, (c) M = 8, and (d) M = 10.
10
20
30
40
50
10
20
30
40
50
–20
–15
–10
–5
0
5
−20
−15
−10
−5
0
5
10
(a)
(b)
L
L
h1,M;MN) (dB)
(
h1,M;MN) (dB)
(
Figure 11.29 (a) DF and (b) WNG of the first-order cardioid as a function of Lh for several values of M:
M = 4 (solid line with circles), M = 6 (dashed line with asterisks), M = 8 (dotted line with squares), and
M = 10 (dash-dot line with triangles).
www.ebook3000.com

Beamforming in the Time Domain
433
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
0
30
60
90
120
150
180
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(a)
(c)
−30
−40
−50
−20
−10
0
−30
−40
−50
−20
−10
0
−30
−40
−50
−20
−10
−30
−40
−50
−20
−10
0
0
(b)
(d)
h1, M;MN, cos θ)  (dB)
(
h1, M;MN, cos θ)  (dB)
(
h1, M;MN, cos θ)  (dB)
(
h1, M;MN, cos θ)  (dB)
(
Figure 11.30 Broadband beampatterns of the first-order cardioid for Lh = 25 and several values of M:
(a) M = 4, (b) M = 6, (c) M = 8, and (d) M = 10.
11.6.2
Second Order
The design of a second-order diﬀerential beamformer requires at least three sensors and
exactly three constraints. For M = , we need to solve the linear system:
⎡
⎢
⎢⎣
𝐆T

𝐆T

𝐆T

𝐆T

(cos 𝜃
)
𝐆T

(cos 𝜃
)
𝐆T

(cos 𝜃
)
𝐆T

(cos 𝜃
)
𝐆T

(cos 𝜃
)
𝐆T

(cos 𝜃
)
⎤
⎥
⎥⎦
⎡
⎢
⎢⎣
𝐡
𝐡
𝐡
⎤
⎥
⎥⎦
=
⎡
⎢
⎢⎣
𝐢l
𝛼𝐢l
𝛼𝐢l
⎤
⎥
⎥⎦
,
(.)
where 𝜃, 𝜃∈
[
𝜋
, 𝜋
]
, with 𝜃≠𝜃, are the directions in which attenuations are desired,
and 𝛼, 𝛼, with ≤𝛼, 𝛼≤, are the attenuation parameters. Equivalently, we can
express (.) as
𝐂T
,
(𝜃∶
) 𝐡,= 𝐢
(𝛼∶
) ,
(.)
where 𝐂T
,
(𝜃∶
) is a matrix of size L × Lh. We deduce the LS solution:
𝐡,;LS =
[
𝐂,
(𝜃∶
) 𝐂T
,
(𝜃∶
)]−
𝐂,
(𝜃∶
) 𝐢
(𝛼∶
) .
(.)

434
Fundamentals of Signal Enhancement and Array Signal Processing
For M > , the linear system in (.) becomes
𝐂T
,M
(𝜃∶
) 𝐡,M = 𝐢
(𝛼∶
) ,
(.)
where
𝐂T
,M
(
𝜃∶
)
=
⎡
⎢
⎢
⎢⎣
𝐆T

𝐆T

⋯
𝐆T
M
𝐆T

(
cos 𝜃
)
𝐆T

(
cos 𝜃
)
⋯
𝐆T
M
(
cos 𝜃
)
𝐆T

(cos 𝜃
)
𝐆T

(cos 𝜃
)
⋯
𝐆T
M
(cos 𝜃
)
⎤
⎥
⎥
⎥⎦
(.)
is a matrix of size L × MLh. We can always ﬁnd the length Lh in such a way that
MLh = L:
Lh = 
Lg −
M −.
(.)
In this scenario, 𝐂T
,M
(
𝜃∶
)
is a square matrix and the solution to (.) is exact:
𝐡,M;E = 𝐂−T
,M
(𝜃∶
) 𝐢
(𝛼∶
) .
(.)
If the value of Lh given in (.) is not an integer, we can always take it such as MLh >
L. As a consequence, we get the MN ﬁlter:
𝐡,M;MN = 𝐂,M
(𝜃∶
) [
𝐂T
,M
(𝜃∶
) 𝐂,M
(𝜃∶
) + 𝜖𝐈L
]−
𝐢
(𝛼∶
) ,
(.)
where 𝜖≥is the regularization parameter.
Example ..
In this example, we demonstrate the MN ﬁlter in the design of the
robust second-order cardioid (𝜃= 𝜋∕, 𝜃= 𝜋, 𝛼= 𝛼= ). We choose fs = kHz,
𝛿= cm, P = , and 𝜖= −.
Figure .shows plots of the DF, 
(
𝐡,M;MN
)
, and the WNG, 
(
𝐡,M;MN
)
, of the
second-order cardioid as a function of Lh for several values of M. From this ﬁgure,
we can choose an appropriate length Lh that is suﬃciently large to maintain high DF
and WNG. Figure .shows broadband beampatterns,
||||

(
𝐡,M;MN, cos 𝜃
)||||
, of the
second-order cardioid for Lh = and several values of M.
■
11.6.3
General Order
From what we have shown in the two previous subsections, it is straightforward to
design any diﬀerential beamformer of order N
≥. We may consider two cases:
N = M −and N < M −.
www.ebook3000.com

Beamforming in the Time Domain
435
10
20
30
40
50
10
20
30
40
50
−35
−20
−25
−30
−15
−10
−5
0
−15
−10
−5
0
5
10
(a)
(b)
h2, M ;MN) (dB)
(
h2, M ;MN) (dB)
(
L
L
Figure 11.31 (a) DF and (b) WNG of the second-order cardioid as a function of Lh for several values of
M: M = 4 (solid line with circles), M = 6 (dashed line with asterisks), M = 8 (dotted line with squares),
and M = 10 (dash-dot line with triangles).
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
(a)
(b)
(c)
(d)
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
θ (deg)
θ (deg)
θ (deg)
θ (deg)
h2, M ;MN, cos θ)  (dB)
(
h2, M ;MN, cos θ)  (dB)
(
h2, M ;MN, cos θ)  (dB)
(
h2, M ;MN, cos θ)  (dB)
(
Figure 11.32 Broadband beampatterns of the second-order cardioid for Lh = 25 and several values of
M: (a) M = 4, (b) M = 6, (c) M = 8, and (d) M = 10.

436
Fundamentals of Signal Enhancement and Array Signal Processing
The number of constraints is exactly equal to N + , so the constraint matrix of size
(N + )L × MLh is deﬁned as
𝐂T
N,M
(
𝜃∶N
)
=
⎡
⎢
⎢
⎢⎣
𝐆T

𝐆T

⋯
𝐆T
M
𝐆T

(cos 𝜃
)
𝐆T

(cos 𝜃
)
⋯
𝐆T
M
(cos 𝜃
)
⋮
⋮
⋱
⋮
𝐆T

(cos 𝜃N
)
𝐆T

(cos 𝜃N
)
⋯
𝐆T
M
(cos 𝜃N
)
⎤
⎥
⎥
⎥⎦
,
(.)
where 𝜃n ∈(, 𝜋] , n = , , … , N, with 𝜃≠𝜃≠⋯≠𝜃N, are the directions in which
attenuations are desired.
For N = M −, we can derive the LS beamformer:
𝐡M−,M;LS =
[
𝐂M−,M
(𝜃∶N
) 𝐂T
M−,M
(𝜃∶N
)]−
× 𝐂M−,M
(
𝜃∶N
)
𝐢N
(
𝛼∶N
)
,
(.)
where
𝐢N
(𝛼∶N
) = [ 𝐢T
l
𝛼𝐢T
l
⋯
𝛼N𝐢T
l
]T
(.)
is a vector of length NL and 𝛼n, n = , , … , N, are the attenuation parameters, with
≤𝛼n ≤.
For N < M−, it is always possible to ﬁnd the length Lh in such a way that MLh = NL:
Lh = N
Lg −
M −N .
(.)
As a result, we ﬁnd the exact ﬁlter:
𝐡N,M;E = 𝐂−T
N,M
(𝜃∶N
) 𝐢N
(𝛼∶N
) .
(.)
By taking MLh > NL, we can obtain the MN ﬁlter:
𝐡N,M;MN = 𝐂N,M
(𝜃∶N
) [
𝐂T
N,M
(𝜃∶N
) 𝐂N,M
(𝜃∶N
) + 𝜖𝐈(N+)L
]−
× 𝐢N
(
𝛼∶N
)
,
(.)
where 𝜖≥is the regularization parameter.
Example ..
In this example, we demonstrate the MN ﬁlter in the design of a third-
order diﬀerential beamformer with three distinct nulls (𝜃= 𝜋∕, 𝜃= 𝜋∕, 𝜃=
𝜋, 𝛼= 𝛼= 𝛼= ). We choose fs = kHz, 𝛿= cm, P = , and 𝜖= −.
Figure .shows plots of the DF, 
(
𝐡,M;MN
)
, and the WNG, 
(
𝐡,M;MN
)
, of a
third-order diﬀerential beamformer as a function of Lh for several values of M. From
this ﬁgure, we can choose an appropriate length Lh that is suﬃciently large to maintain
high DF and WNG. Figure .shows broadband beampatterns,
||||

(
𝐡,M;MN, cos 𝜃
)||||
,
for Lh = and several values of M.
■
www.ebook3000.com

Beamforming in the Time Domain
437
10
20
30
40
50
0
1
2
3
4
5
6
7
8
(a)
(b)
10
20
30
40
50
−30
−25
−20
−15
−10
−5
0
h3, M ; MN) (dB)
(
h3, M ; MN) (dB)
(
L
L
Figure 11.33 (a) DF and (b) WNG of a third-order differential beamformer with three distinct nulls
(𝜃1 = 𝜋∕2, 𝜃2 = 3𝜋∕4, 𝜃3 = 𝜋) as a function of Lh for several values of M: M = 4 (solid line with circles),
M = 6 (dashed line with asterisks), M = 8 (dotted line with squares), and M = 10 (dash-dot line with
triangles).
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
(a)
(b)
(c)
(d)
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
θ (deg)
θ (deg)
θ (deg)
θ (deg)
h 3, M ;MN, cos θ)  (dB)
(
h 3, M ;MN, cos θ)  (dB)
(
h 3, M;MN, cos θ)  (dB)
(
h 3, M ;MN, cos θ)  (dB)
(
Figure 11.34 Broadband beampatterns of a third-order differential beamformer with three distinct
nulls (𝜃1 = 𝜋∕2, 𝜃2 = 3𝜋∕4, 𝜃3 = 𝜋) for Lh = 30 and several values of M: (a) M = 4, (b) M = 6, (c) M = 8,
and (d) M = 10.

438
Fundamentals of Signal Enhancement and Array Signal Processing
11.6.4
Hypercardioid
Traditionally, the hypercardioid is derived from the DF deﬁnition. Here, the hyper-
cardioid of order N
=
M −is obtained by maximizing the DF as deﬁned in
(.) and taking into account the distortionless constraint. We get the superdirective
beamformer:
𝐡Hd = 𝚪−
T,,𝜋𝐆
(
𝐆T𝚪−
T,,𝜋𝐆
)−
𝐢l.
(.)
Therefore, the hypercardioid of order N = M −and the superdirective beamformer
are identical.
11.6.5
Supercardioid
Traditionally, the supercardioid is derived from the FBR deﬁnition []. Next, we show
how to derive it in our context.
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
(a)
(b)
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
0
30
60
90
120
150
180
−50
−40
−30
−20
−10
0
h Sd, 1
(dB)
, cos θ)
(
h Sd, 4
(dB)
, cos θ)
(
θ (deg)
θ (deg)
θ (deg)
θ (deg)
(c)
(d)
hSd, 10
(dB)
, cos θ)
(
h Sd, 7
(dB)
, cos θ)
(
Figure 11.35 Broadband beampatterns of the third-order supercardioid for several values of Q:
(a) Q = 1, 
(
𝗵Sd,1
)
= 285, 980, (b) Q = 4, 
(
𝗵Sd,4
)
= 7, 194, (c) Q = 7, 
(
𝗵Sd,7
)
= 6, 457, and
(d) Q = 10, 
(
𝗵Sd,10
)
= 5, 994.
www.ebook3000.com

Beamforming in the Time Domain
439
Table 11.3 Differential beamformers in the time domain.
Beamformer
First order
𝐡,;LS =
[
𝐂,
(𝜃
) 𝐂T
,
(𝜃
)]−
𝐂,
(𝜃
) 𝐢
𝐡,M;E = 𝐂−T
,M
(
𝜃
)
𝐢
𝐡,M;MN = 𝐂,M
(𝜃
) [
𝐂T
,M
(𝜃
) 𝐂,M
(𝜃
)]−
𝐢
Second order
𝐡,;LS =
[
𝐂,
(
𝜃∶
)
𝐂T
,
(
𝜃∶
)]−
𝐂,
(
𝜃∶
)
𝐢
(
𝛼∶
)
𝐡,M;E = 𝐂−T
,M
(𝜃∶
) 𝐢
(𝛼∶
)
𝐡,M;MN = 𝐂,M
(
𝜃∶
) [
𝐂T
,M
(
𝜃∶
)
𝐂,M
(
𝜃∶
)]−
𝐢
(
𝛼∶
)
General order
𝐡M−,M;LS =
[
𝐂M−,M
(𝜃∶N
) 𝐂T
M−,M
(𝜃∶N
)]−
× 𝐂M−,M
(
𝜃∶N
)
𝐢N
(
𝛼∶N
)
𝐡N,M;E = 𝐂−T
N,M
(𝜃∶N
) 𝐢N
(𝛼∶N
)
𝐡N,M;MN = 𝐂N,M
(𝜃∶N
)
×
[
𝐂T
N,M
(𝜃∶N
) 𝐂N,M
(𝜃∶N
)]−
𝐢N
(𝛼∶N
)
Hypercardioid
𝐡Hd = 𝚪−
T,,𝜋𝐆
(
𝐆T𝚪−
T,,𝜋𝐆
)−
𝐢l
Supercardioid
𝐡Sd,Q = 𝐓Q
(
𝐓T
Q𝐆𝐆T𝐓Q
)−
𝐓T
Q𝐆𝐢l
Let 𝐭, 𝐭, … , 𝐭Q be the eigenvectors corresponding to the Q largest eigenvalues,
𝜆, 𝜆, … , 𝜆Q, of the matrix 𝚪−
T,𝜋∕,𝜋𝚪T,,𝜋∕, with 𝜆≥𝜆≥⋯≥𝜆Q ≥. We consider
beamformers of the form:
𝐡= 𝐓Q𝐚,
(.)
where
𝐓Q = [ 𝐭
𝐭
⋯
𝐭Q
]
(.)
is a matrix of size MLh × Q and 𝐚≠𝟎is a vector of length Q. Now, we ﬁnd 𝐚in such a
way that 𝐡from (.) is distortionless. Substituting (.) into (.), we ﬁnd
𝐚=
(
𝐓T
Q𝐆𝐆T𝐓Q
)−
𝐓T
Q𝐆𝐢l.
(.)
As a result, the supercardioid of order M −is
𝐡Sd,Q = 𝐓Q
(
𝐓T
Q𝐆𝐆T𝐓Q
)−
𝐓T
Q𝐆𝐢l.
(.)

440
Fundamentals of Signal Enhancement and Array Signal Processing
Note that the FBR as deﬁned in (.) decreases as Q increases:

(
𝐡Sd,Q
)
≥
(
𝐡Sd,Q+
)
.
(.)
Example ..
In this example, we demonstrate the third-order supercardioid with
a ULA of M = sensors. We choose fs = kHz, 𝛿= cm, P = , and Lh = .
Figure .shows broadband beampatterns,
||||

(
𝐡Sd,Q, cos 𝜃
)||||
, for several values of Q.
It can be observed that as Q increases, the FBR decreases.
■
In Table ., we summarize all the time-domain diﬀerential beamformers derived in
this section.
Problems
11.1 Show that the MSE can be expressed as
J (𝐡) = 𝜎
x −𝐡T𝐆(cos 𝜃d
) 𝐑𝐱𝐢l + 𝐡T𝐑𝐲𝐡.
11.2 Show that the desired signal distortion index can be expressed as
𝜐d
(𝐡) =
[𝐆T (cosd 𝜃) 𝐡−𝐢l
]T 𝐑𝐱
[𝐆T (cosd 𝜃) 𝐡−𝐢l
]
𝜎
x
.
11.3 Show that the MSEs are related to the diﬀerent performance measures by
Jd
(𝐡)
Jn
(𝐡) = iSNR × 𝜉n
(
𝐡
)
× 𝜐d
(
𝐡
)
= oSNR
(
𝐡
)
× 𝜉d
(
𝐡
)
× 𝜐d
(
𝐡
)
.
11.4 Show that by maximizing the WNG subject to the distortionless constraint, we
obtain the DS beamformer:
𝐡DS
(cos 𝜃d
) = 𝐆(cos 𝜃d
) 𝐢l
M.
11.5 Show that the WNG of the DS beamformer, [𝐡DS
(cos 𝜃d
)], is equal to M.
11.6 Show that the maximum DF beamformer is given by
𝐡max
(
cos 𝜃d
)
= 𝜍𝐭
(
cos 𝜃d
)
,
where 𝐭
(cos 𝜃d
) is the eigenvector corresponding to the maximum eigenvalue
of the matrix 𝚪−
T,,𝜋𝐆
(
cos 𝜃d
)
𝐆T (
cos 𝜃d
)
and 𝜍≠is an arbitrary real number.
www.ebook3000.com

Beamforming in the Time Domain
441
11.7 Show that the maximum DF is given by
max
(
cos 𝜃d
)
= 𝜆
(
cos 𝜃d
)
,
where 𝜆
(cos 𝜃d
) is the maximum eigenvalue of the matrix 𝚪−
T,,𝜋𝐆(cos 𝜃d
) 𝐆T (cos 𝜃d
).
11.8 Show that by maximizing the DF subject to the distortionless constraint, we
obtain the distortionless maximum DF beamformer:
𝐡mDF
(
cos 𝜃d
)
= 𝚪−
T,,𝜋𝐆
(
cos 𝜃d
) [
𝐆T (
cos 𝜃d
)
𝚪−
T,,𝜋𝐆
(
cos 𝜃d
)]−
𝐢l.
11.9 Show that the DF of the distortionless maximum DF beamformer is given by
[𝐡mDF
(cos 𝜃d
)] =

𝐢T
l
[
𝐆T (
cos 𝜃d
)
𝚪−
T,,𝜋𝐆
(
cos 𝜃d
)]−
𝐢l
.
11.10 Show that by maximizing the DF subject to the constraint:
𝐂T (
𝜃d, 𝜃n
)
𝐡=
[
𝐢l
𝟎
]
,
we obtain the NS beamformer:
𝐡NS
(
cos 𝜃d
)
= 𝚪−
T,,𝜋𝐂
(
𝜃d, 𝜃n
)
×
[
𝐂T (
𝜃d, 𝜃n
)
𝚪−
T,,𝜋𝐂
(
𝜃d, 𝜃n
)]−[
𝐢l
𝟎
]
.
11.11 Show that by minimizing the MSE, J (𝐡), we obtain the Wiener beamformer:
𝐡W
(
cos 𝜃d
)
= 𝐑−
𝐲𝐆
(
cos 𝜃d
)
𝐑𝐱𝐆T (
cos 𝜃d
)
𝐢.
11.12 Show that the Wiener beamformer can be written as
𝐡W
(cos 𝜃d
) = 𝐑−
𝐯𝐆(cos 𝜃d
)
×
[
𝐑−
𝐱+ 𝐆T (cos 𝜃d
) 𝐑−
𝐯𝐆(cos 𝜃d
)]−
𝐢l.
11.13 Show that the MVDR beamformer is given by
𝐡MVDR
(cos 𝜃d
) = 𝐑−
𝐯𝐆(cos 𝜃d
) [
𝐆T (cos 𝜃d
) 𝐑−
𝐯𝐆(cos 𝜃d
)]−
𝐢l.
11.14 Show that the MVDR beamformer can be rewritten as
𝐡MVDR
(
cos 𝜃d
)
= 𝐑−
𝐲𝐆
(
cos 𝜃d
) [
𝐆T (
cos 𝜃d
)
𝐑−
𝐲𝐆
(
cos 𝜃d
)]−
𝐢l.

442
Fundamentals of Signal Enhancement and Array Signal Processing
11.15 Show that the tradeoﬀbeamformer is given by
𝐡T,𝜇
(cos 𝜃d
) = 𝐑−
𝐯𝐆(cos 𝜃d
)
×
[
𝜇𝐑−
𝐱+ 𝐆T (cos 𝜃d
) 𝐑−
𝐯𝐆(cos 𝜃d
)]−
𝐢l,
where 𝜇> is a Lagrange multiplier.
11.16 Show that for 𝜇> , the tradeoﬀbeamformer 𝐡T,𝜇
(cos 𝜃d
), compared to Wiener
beamformer, obtains low residual noise at the expense of high desired signal
distortion.
11.17 Show that the beamformer that maximizes the output SNR is given by
𝐡max
(cos 𝜃d
) = 𝜍𝐭′

(cos 𝜃d
) ,
where 𝐭′

(cos 𝜃d
) is the eigenvector corresponding to the maximum eigenvalue
of the matrix 𝐑−
𝐯𝐆(cos 𝜃d
) 𝐑𝐱𝐆T (cos 𝜃d
) and 𝜍≠is an arbitrary real number.
11.18 Show that the maximum SNR beamformer that minimizes the MSE is given by
𝐡max
(
cos 𝜃d
)
=
𝐭′

(cos 𝜃d
) 𝐭′T

(cos 𝜃d
) 𝐆(cos 𝜃d
) 𝐑𝐱𝐢l
𝐭′T

(cos 𝜃d
) 𝐑𝐲𝐭′

(cos 𝜃d
)
.
11.19 Show that by minimizing the MSE of the residual noise subject to the constraint:
𝐂T (𝜃d, 𝜃n
) 𝐡=
[
𝐢l
𝟎
]
,
we obtain the LCMV beamformer:
𝐡LCMV
(cos 𝜃d
) = 𝐑−
𝐯𝐂(𝜃d, 𝜃n
)
×
[
𝐂T (
𝜃d, 𝜃n
)
𝐑−
𝐯𝐂
(
𝜃d, 𝜃n
)]−[
𝐢l
𝟎
]
.
11.20 Show that the LCMV beamformer can be written as
𝐡LCMV
(cos 𝜃d
) = 𝐑−
𝐲𝐂(𝜃d, 𝜃n
)
×
[
𝐂T (
𝜃d, 𝜃n
)
𝐑−
𝐲𝐂
(
𝜃d, 𝜃n
)]−[
𝐢l
𝟎
]
.
11.21 Show that the supercardioid of order M −is given by
𝐡Sd,Q = 𝐓Q
(
𝐓T
Q𝐆𝐆T𝐓Q
)−
𝐓T
Q𝐆𝐢l,
www.ebook3000.com

Beamforming in the Time Domain
443
where 𝐓Q
=
[ 𝐭
𝐭
⋯
𝐭Q
], and 𝐭, 𝐭, … , 𝐭Q are the eigenvectors
corresponding to the Q largest eigenvalues of the matrix 𝚪−
T,𝜋∕,𝜋𝚪T,,𝜋∕.
11.22 Show that with the supercardioid, 𝐡Sd,Q, the FBR decreases as Q increases, i.e.,

(
𝐡Sd,Q
)
≥
(
𝐡Sd,Q+
)
.
References
1 J. Benesty, J. Chen, and Y. Huang, Microphone Array Signal Processing. Berlin,
Germany: Springer-Verlag, .
2 C. E. Shannon, “Communications in the presence of noise,” Proc. IRE, vol. , pp. –,
Jan. .
3 A. J. Jerri, “The Shannon sampling theorem. Its various extensions and applications: a
tutorial review,” Proc. IEEE, vol. , pp. –, Nov. 
4 H. Cox, R. M. Zeskind, and T. Kooij, “Practical supergain,” IEEE Trans. Acoust., Speech,
Signal Process., vol. ASSP-, pp. –, Jun. .
5 H. Cox, R. M. Zeskind, and M. M. Owen, “Robust adaptive beamforming,” IEEE Trans.
Acoust., Speech, Signal Process., vol. ASSP-, pp. –, Oct. .
6 A. Booker and C. Y. Ong, “Multiple constraint adaptive ﬁltering,” Geophysics, vol. ,
pp. –, Jun. .
7 O. Frost, “An algorithm for linearly constrained adaptive array processing,” Proc. IEEE,
vol. , pp. –, Jan. .
8 J. Benesty and J. Chen, Study and Design of Diﬀerential Microphone Arrays. Berlin,
Germany: Springer-Verlag, .
9 G. W. Elko, “Superdirectional microphone arrays,” in Acoustic Signal Processing for
Telecommunication, S. L. Gay and J. Benesty (eds). Boston, MA: Kluwer Academic
Publishers, .
10 R. N. Marshall and W. R. Harry, “A new microphone providing uniform directivity over
an extended frequency range,” J. Acoust. Soc. Am., vol. , pp. –, .

445
Index
a
adaptive beamformer
, 
frequency domain

LCMV, frequency domain
, 
LCMV, time domain

maximum array gain, frequency
domain

maximum SNR, time domain

minimum noise, frequency
domain

MVDR, frequency domain
, ,

MVDR, time domain

reduced-rank Wiener, frequency
domain

time domain

tradeoﬀ, frequency domain

tradeoﬀ, time domain

Wiener, frequency domain
, 
Wiener, time domain

adaptive beamforming

frequency domain

time domain

additive noise

analysis window
, 
anechoic

angular frequency

array

array gain
, 
broadband

narrowband

time domain

array processing

array signal processing
, 
b
basis

beamformer

frequency domain

time domain

beamforming
, 
frequency domain
, 
time domain
, 
beamforming ﬁlter

beampattern
, , 
beampattern design

frequency invariant

joint optimization

least squares

nonrobust

robust

Bessel function of the ﬁrst kind

binomial coeﬃcient

blocking matrix

broadband
beamformer

beamforming

beampattern

directivity factor

directivity pattern

front-to-back ratio

white noise gain

broadside
, 
c
cardioid

Chebyshev polynomial of the ﬁrst
kind

clutter

Fundamentals of Signal Enhancement and Array Signal Processing, First Edition.
Jacob Benesty, Israel Cohen, and Jingdong Chen.
© John Wiley & Sons Singapore Pte. Ltd. Published by John Wiley & Sons Singapore Pte. Ltd.
Companion website: www.wiley.com/go/benesty/arraysignalprocessing
www.ebook3000.com

446
Index
coherence function

complex gain

constraint Wiener gain
single channel, frequency domain
,

controlled distortion ﬁlter
multichannel, spectral domain

multichannel, time domain

correlation matrix
, 
cross-correlation

d
delay-and-sum (DS)
, 
desired signal

adaptive beamforming, frequency
domain

beamforming, time domain

multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

single channel, frequency domain

single channel, spectral domain

single channel, time domain

desired signal cancellation

desired signal distortion

adaptive beamforming, frequency
domain

beamforming, time domain

multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

single channel, frequency domain

single channel, time domain

desired signal distortion index

adaptive beamforming,
broadband

adaptive beamforming,
narrowband

beamforming, time domain

multichannel, broadband
, 
multichannel, fullmode

multichannel, narrowband

multichannel, spectral mode

multichannel, time domain

single channel, broadband

single channel, fullmode

single channel, narrowband

single channel, spectral mode

single channel, time domain

desired signal reduction factor
adaptive beamforming, broadband

adaptive beamforming,
narrowband

beamforming, time domain

multichannel, broadband
, 
multichannel, fullmode

multichannel, narrowband

multichannel, spectral mode

multichannel, time domain

single channel, broadband
, 
single channel, fullmode

single channel, narrowband

single channel, spectral mode

single channel, time domain

DFT matrix
, 
diﬀerential beamformer
ﬁrst-order design

ﬁrst order, time domain

frequency domain

general order, time domain

hypercardioid

hypercardioid, time domain

minimum norm

second order, time domain

second-order design

supercardioid

supercardioid, time domain

third-order design

time domain

diﬀerential beamforming
, 
diﬀerential sensor array (DSA)

dipole

direction-of-arrival (DOA)

directivity factor (DF)
, 
Nth-order DSA

directivity pattern
, 
Dirichlet kernel

discrete Fourier transform (DFT)
,

distortionless constraint

distortionless ﬁlter
, 
DOA estimation


Index
447
e
echo

eigenvalue

eigenvalue decomposition
, 
desired signal correlation matrix

noise correlation matrix

eigenvector

endﬁre

endﬁre array

error signal

adaptive beamforming, frequency
domain

beamforming, time domain

multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

single channel, frequency domain

single channel, time domain

f
farﬁeld

ﬁltered desired signal

adaptive beamforming, frequency
domain

beamforming, time domain

ﬁxed beamforming

multichannel, frequency domain

multichannel, spectral domain

multichannel, STFT domain

multichannel, time domain

single channel, spectral domain

single channel, time domain

ﬁltered noise signal
single channel, spectral domain

ﬁnite-impulse-response (FIR)
ﬁlter

ﬁxed beamformer
, 
distortionless maximum DF, time
domain

DS

DS, time domain

frequency domain

maximum DF

maximum DF, time domain

minimum norm

minimum norm, time domain

null steering

null steering, time domain

robust superdirective

robust superdirective, time
domain

superdirective

superdirective, time domain

time domain

ﬁxed beamforming

frequency domain

time domain

Fourier cosine series

front-to-back ratio (FBR)

Nth-order DSA

g
gain
single channel, frequency domain

single channel, spectral domain

single channel, STFT domain

general subspace ﬁlter
multichannel, spectral domain

multichannel, time domain

generalized Rayleigh quotient
, ,
, , 
generalized sidelobe canceller (GSC)

h
harmonic
, , , 
hypercardioid

i
ideal binary mask

identity ﬁlter

multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

single channel, fullmode

single channel, time domain

impulse response

inclusion principle

inﬁnite noise reduction ﬁlter

input SINR

input SIR

www.ebook3000.com

448
Index
input SNR
adaptive beamforming,
broadband

adaptive beamforming,
narrowband

beamforming, time domain

ﬁxed beamforming

multichannel, broadband
, 
multichannel, fullmode

multichannel, narrowband
, 
multichannel, spectral mode

multichannel, time domain

single channel, broadband
, 
single channel, fullmode

single channel, narrowband
, 
single channel, spectral mode

single channel, time domain

interference
, 
j
Jacobi-Anger expansion

jamming

joint diagonalization
, , , ,
, , , 
l
Lagrange multiplier
, 
LCMV ﬁlter
multichannel, frequency domain

least-squares error (LSE)

linear array model

linear convolution

linear ﬁltering

adaptive beamforming, frequency
domain

ﬁxed beamforming

multichannel, frequency domain

multichannel, time domain

single channel, time domain

linearly constrained minimum variance
(LCMV)

LSE criterion
, 
m
magnitude squared coherence
(MSC)

magnitude squared coherence function
(MSCF)

magnitude subtraction method

maximum SINR ﬁlter

maximum SNR ﬁlter
multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain
, 
single channel, spectral domain

single channel, time domain

mean-squared error (MSE)

minimum MSE (MMSE)
single channel, narrowband

single channel, time domain

minimum SNR ﬁlter
single channel, spectral domain

minimum statistics
, 
minimum variance distortionless response
(MVDR)

minimum-norm ﬁlter
, 
minimum-norm solution
, 
modiﬁed Bessel function of the ﬁrst
kind

MSE criterion
, 
adaptive beamforming, frequency
domain

beamforming, time domain

multichannel, broadband

multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

single channel, broadband
, 
single channel, fullmode

single channel, narrowband

single channel, spectral mode

single channel, time domain

multiple signal classiﬁcation

multiplicative transfer function
(MTF)

MUSIC

MVDR ﬁlter
multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

single channel, time domain

n
noise

noise reduction
, 
multichannel, broadband


Index
449
multichannel, frequency domain

single channel, broadband

single channel, frequency domain

single channel, time domain

noise reduction factor
adaptive beamforming, broadband

adaptive beamforming,
narrowband

beamforming, time domain

multichannel, broadband

multichannel, fullmode

multichannel, narrowband

multichannel, spectral mode

multichannel, time domain

single channel, broadband

single channel, fullmode

single channel, narrowband

single channel, spectral mode

single channel, time domain

noise rejection

noise signal

multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

single channel, frequency domain

single channel, spectral domain

single channel, time domain

Nth-order DSA beampattern

cardioid

dipole

hypercardioid

supercardioid

normalized correlation matrix

nullspace

null steering
, 
o
optimal ﬁlter

LCMV

maximum SINR

maximum SIR

multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

MVDR

single channel, time domain

tradeoﬀ

Wiener

optimal gain
single channel, frequency domain

orthogonal matrix

orthogonal projector

orthonormal vector

output SINR
, 
output SIR

output SNR
adaptive beamforming,
broadband

adaptive beamforming,
narrowband

beamforming, time domain

ﬁxed beamforming

multichannel, broadband
, 
multichannel, fullmode

multichannel, narrowband

multichannel, spectral mode

multichannel, time domain

single channel, broadband
, 
single channel, fullmode

single channel, narrowband

single channel, spectral mode

single channel, time domain

overlap-add (OLA)

p
parametric Wiener gain
single channel, frequency domain

partially normalized coherence
function
, 
partially normalized coherence
vector
, 
performance measure

adaptive beamforming, frequency
domain

beamforming, time domain

ﬁxed beamforming

multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

single channel, frequency domain

single channel, spectral domain

single channel, time domain

www.ebook3000.com

450
Index
power pattern

power subtraction method

projection matrix

projection operator

pseudo-coherence matrix
, 
pseudo-correlation matrix

r
radar

regularization

residual interference
, 
residual noise
, 
adaptive beamforming, frequency
domain
, 
beamforming, time domain
, 
ﬁxed beamforming

multichannel, frequency domain
,

multichannel, spectral domain
,

multichannel, STFT domain

multichannel, time domain
, 
single channel, frequency domain

single channel, time domain
, 
reverberation

s
short-time Fourier transform (STFT)
,

signal enhancement
, , 
frequency domain

multichannel, frequency domain
,

multichannel, spectral domain

multichannel, STFT domain

multichannel, time domain
, 
single channel, frequency domain

single channel, spectral domain

single channel, STFT domain

single channel, time domain
, 
spatial domain

time domain

signal-to-interference-plus-noise ratio
(SINR)

signal-to-interference ratio (SIR)

signal-to-noise ratio (SNR)

SNR estimation

sonar
active

passive

sonography

spatial aliasing

spatial correlation matrix

spatial ﬁltering

spatial linear ﬁlter

spatial linear ﬁltering

spatiotemporal ﬁlter

speckle

spectral coherence

spectrogram

speech enhancement

spherically isotropic noise
,
, 
squared Pearson correlation coeﬃcient
(SPCC)

steering vector
, , 
noise reduction

subspace

supercardioid

supergain

Sylvester matrix

synthesis window

t
temporal aliasing

temporal correlation matrix

temporal ﬁlter

temporal frequency

tradeoﬀﬁlter

multichannel, frequency domain

multichannel, spectral domain

multichannel, time domain

single channel, time domain

tradeoﬀgain
single channel, frequency domain

transformed ﬁlter

transformed identity ﬁlter
, 
u
ultrasound

underwater acoustic signal
enhancement


Index
451
uniform linear array (ULA)
, ,
, 
unitary matrix

v
Vandermonde matrix
, 
variance

w
wavelength

white noise gain (WNG)
, ,
, 
Wiener ﬁlter
, , 
multichannel, frequency domain

multichannel, spectral domain

multichannel, STFT domain

multichannel, time domain

single channel, time domain

Wiener ﬁltering

Wiener gain
single channel, frequency domain
,

single channel, spectral domain

single channel, STFT domain

Woodbury’s identity
, , ,
, 
www.ebook3000.com

