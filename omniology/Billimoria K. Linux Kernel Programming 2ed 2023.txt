
Linux Kernel Programming
Copyright © 2022 Packt Publishing
All rights reserved. No part of this book may be reproduced, stored in
a retrieval system, or transmitted in any form or by any means,
without the prior written permission of the publisher, except in the
case of brief quotations embedded in critical articles or reviews.
Every effort has been made in the preparation of this book to ensure
the accuracy of the information presented. However, the information
contained in this book is sold without warranty, either express or
implied. Neither the author, nor Packt Publishing, and its dealers
and distributors will be held liable for any damages caused or alleged
to be caused directly or indirectly by this book.
Packt Publishing has endeavored to provide trademark information
about all of the companies and products mentioned in this book by
the appropriate use of capitals. However, Packt Publishing cannot
guarantee the accuracy of this information.
Early Access Publication: Linux Kernel Programming
Early Access Production Reference: B18477
Published by Packt Publishing Ltd.
Livery Place
35 Livery Street
Birmingham
B3 2PB, UK
ISBN: 978-1-80323-222-5

www.packt.com

Table of Contents
1. Linux Kernel Programming, Second Edition: A practical guide to
kernel internals, writing kernel modules, and synchronization
2. 1 Kernel Workspace Setup
I. Join our book community on Discord
II. Technical requirements
III. Running Linux as a guest VM
i. Selecting a Linux distro and kernel
IV. Installing an x86_64 Linux guest
i. Turn on your x86 system's virtualization extension
support 
ii. Allocate sufficient space to the disk
iii. Using pre-built Linux VM images
iv. Setting up OSBoxes Ubuntu 22.04 as a guest OS
v. Installing QEMU and a cross toolchain
vi. A few remaining tips when running the VM
vii. Experimenting with the Raspberry Pi
V. Additional useful projects
i. Using the Linux man pages
ii. Locating and using the Linux kernel documentation
iii. Static analysis tools for the Linux kernel
iv. Linux Trace Toolkit next generation
v. The procmap utility
vi. Simple Embedded ARM Linux System FOSS project
vii. Modern tracing and performance analysis with eBPF
viii. The LDV - Linux Driver Verification - project
VI. Summary
VII. Questions
VIII. Further reading

Linux Kernel Programming, Second
Edition: A practical guide to kernel
internals, writing kernel modules,
and synchronization
Welcome to Packt Early Access. We’re giving you an exclusive
preview of this book before it goes on sale. It can take many months
to write a book, but our authors have cutting-edge information to
share with you today. Early Access gives you an insight into the latest
developments by making chapter drafts available. The chapters may
be a little rough around the edges right now, but our authors will
update them over time.
You can dip in and out of this book or follow along from start to
finish; Early Access is designed to be flexible. We hope you enjoy
getting to know more about the process of writing a Packt book.
1. Chapter 1: Kernel Workspace Setup
2. Chapter 2: Building the 5.x Linux Kernel from Source - Part 1
3. Chapter 3: Building the 5.x Linux Kernel from Source - Part 2
4. Chapter 4: Writing Your First Kernel Module - LKMs Part 1
5. Chapter 5: Writing Your First Kernel Module - LKMs Part 2
6. Chapter 6: Kernel Internals Essentials - Processes and Threads
7. Chapter 7: Memory Management Internals - Essentials
8. Chapter 8: Kernel Memory Allocation for Module Authors - Part
1
9. Chapter 9: Kernel Memory Allocation for Module Authors - Part
2
10. Chapter 10: The CPU Scheduler - Part 1
11. Chapter 11: The CPU Scheduler - Part 2
12. Chapter 12: Kernel Synchronization - Part 1
13. Chapter 13: Kernel Synchronization - Part 2

1 Kernel Workspace Setup

Join our book community on Discord
https://packt.link/CyberSec
Hello, and welcome to this book on learning Linux kernel programming. To get the most out of this
book, it is very important that you first set up the workspace environment that we will be using
throughout the book. This chapter will teach you exactly how to do this and get started.
We will install a recent Linux distribution, preferably as a Virtual Machine (VM), and set it up to
include all the required software packages. We will also clone this book's code repository on GitHub, and
learn about a few useful projects that will help along this journey.
Right at the outset, something I like to emphasize, is this: the best way to learn something is to do so
empirically – not taking anyone's word on anything at all, but trying it out and experiencing it for
yourself. Hence, this book gives you many hands-on experiments and kernel code examples that you can
and indeed must try out yourself; this will greatly aid in your making real progress, learning deeply and
understanding various aspects of Linux kernel and driver development. So, remember:
Be Empirical!
Right, let's begin!
This chapter will take you through the following topics, which will help set up your working
environment:
Running Linux as a guest VM
Installing an x86_64 Linux guest
Additional useful projects
Technical requirements
You will need a modern – and preferably powerful - desktop PC or laptop. Ubuntu Desktop specifies
"recommended minimum system requirements" for the installation and usage of the distribution here:
https://help.ubuntu.com/community/Installation/SystemRequirements. I’d suggest you go with a
system well beyond the minimum recommendation, as powerful a system as you can afford to use. This
is as performing tasks such as building a Linux kernel from source is a very memory- and CPU-intensive
process. It should be pretty obvious – the more RAM, CPU power and disk space the host system has,
the better!
Like any seasoned kernel developer, I would say that working on a native Linux system is best. However,
for the purposes of this book, we cannot assume that you will always have a dedicated native Linux box
available to you. So, we shall assume that you are working on a Linux guest. Working within a guest VM
also adds an additional layer of isolation and thus safety. Of course, the downside is performance –
working on a high spec native Linux box can be up to twice as fast when compared to working on a VM!
Cloning our code repository: The complete source code for this book is freely available on GitHub at
https://github.com/PacktPublishing/Linux-Kernel-Programming_2E. You can clone and work on it by

cloning the git  tree, like so:
git clone https://github.com/PacktPublishing/Linux-Kernel-Programming_2E
The source code is organized chapter-wise. Each chapter is represented as a directory – for example,
ch1/  has the source code for this chapter. The root of the source tree has some code that is common to
all chapters, such as the source files convenient.h , klib_llkd.c , as well as others.
For efficient code browsing, I would strongly recommend that you always index the code base(s) with
ctags  and/or cscope . For example, to set up the ctags  index, just cd  to the root of the source tree and
type ctags -R .
Unless noted otherwise, the code output we show in the book is the output as seen on an x86_64
Ubuntu 22.04 LTS guest VM (running under Oracle VirtualBox 6.1). You should realize that due to
(usually minor) distribution – and even within the same distributions but differing versions –
differences, the output shown in the book may not perfectly match what you see on your Linux
system.
Running Linux as a guest VM
As discussed previously, a practical and convenient alternative to using a native Linux system is to
install and use the Linux distribution as a guest OS on a VM.
Selecting a Linux distro and kernel
It's key that you install a recent and well supported Linux distribution, along with a (custom-built)
recent long-term Linux kernel. Very briefly, for the purpose of this book, here’s what we’ll select:
Linux kernel version: 5.10.y LTS (longterm); End Of Life (EOL) is December 2026
Linux distribution (or distro): Ubuntu 22.04 LTS (‘Jammy Jellyfish’); free security and maintenance
updates guaranteed until April 2027, EOL is April 2032
Hypervisor for the VM: Oracle VirtualBox 6.1.x (runs on the host system).
Our reasoning is simple: all of these are Open Source Software (OSS) with, as of this writing,
sufficiently long end-of-life dates, ensuring their continued support and viability for a pretty long while.
You’ll of course get all details as we go along; for the Ubuntu VM installation details, the sections
Installing an x86_64 Linux guest and Setting up OSBoxes Ubuntu 22.04 as a guest OS covers it. The
Linux kernel versions, what they entail and actually building a custom kernel is covered in depth in the
following two chapters; relax, we’ll get there.
Of course, running Linux on a native system has definite performance advantages. For the purpose of
this book, though, we can’t assume you have a dedicated spare native Linux system, so we’ll go with
running Linux as a VM; it’s also safer and helps avoid unpleasant data loss or other surprises. The fact is
when working at the level of the kernel, abruptly crashing the system (and the data loss risks that arise
thereof) is actually a commonplace occurrence. For the hypervisor, I recommend using Oracle
VirtualBox 6.x (or the latest stable version) or other virtualization software, such as VMware
Workstation.
Both of these are freely available. It's just that the code for this book has been tested on VirtualBox
6.1.x. Oracle VirtualBox is considered Open Source Software (OSS) and is licensed under the GPL v2
(the same as the Linux kernel). You can download it
from https://www.virtualbox.org/wiki/Downloads. Its documentation can be found
here: https://www.virtualbox.org/wiki/End-user_documentation.
The host system – the one where the hypervisor runs - should be either MS Windows 10 or later (of
course, even Windows 7 will work), a recent Linux distribution (for example, Ubuntu or Fedora), or

macOS.
More Choices
The distro we choose to use – the Ubuntu 22.04 LTS Desktop – is the version of choice for this book, at
least. The two primary reasons for this are straightforward:
Ubuntu Linux is one of the, if not the, most popular Linux (kernel) development workstation
environments in industry use today.
We cannot always, for lack of space and clarity, show the code/build output of multiple
environments in this book. Hence, we have typically chosen to show the output as seen on the
x86_64 Ubuntu 22.04 LTS Desktop.
Ubuntu 20.04 - or even 18.04 LTS - Desktop are good choices too (they have Long-Term
Support (LTS) as well), and everything should work. To download it,
visit https://www.ubuntu.com/download/desktop.
Some other Linux distributions that can also be considered include the following:
CentOS 9 Linux (not CentOS Stream): CentOS Linux is a distribution that's essentially a clone
of the popular enterprise server distribution from RedHat (RHEL 9, in our case). You can download
it from here: https://www.centos.org/download/.
Fedora Workstation: Fedora is a very well-known FOSS Linux distribution as well. You can
think of it as being a kind of test-bed for projects and code that will eventually land up within
RedHat's enterprise products. Download it from https://getfedora.org/ (download the Fedora
Workstation image).
Raspberry Pi as a target: It's really best to refer to the official documentation to set up your
Raspberry Pi (Raspberry Pi documentation: https://www.raspberrypi.org/documentation/). It's
perhaps worth noting that Raspberry Pi kits are widely available that come completely pre-installed
and with some hardware accessories as well. We cover more on using the Raspberry Pi as a target in
a later section.
BeagleBone Black (BBB) as a target: The BBB, like the Raspberry Pi, is an extremely popular
embedded ARM SBC for hobbyists and pros. You can get started here:
https://beagleboard.org/black. The System Reference Manual for the BBB can be found
here: https://cdn.sparkfun.com/datasheets/Dev/Beagle/BBB_SRM_C.pdf. Though we typically
don't present examples running on the BBB, nevertheless, it's a valid embedded Linux system that,
once properly set up, you can run this book's code on.
Of course, for more advanced readers, you’ll realize that the Linux system to use is really up to you.
Running an as-light-as-possible custom Linux system on a QEMU (emulated) standard PC is a
choice as well.
Before we conclude our discussion on selecting our software distribution for the book, here are a few
more points to note:
These distributions are, in their default form, FOSS and non-proprietary, and free to use as an end
user.
Though our aim is to be Linux distribution-neutral, the book’s code has only been tested on an
x86_64 guest running Ubuntu 22.04 LTS and "lightly" tested on the ARM-based (both ARM-32 and
ARM-64) Raspberry Pi boards typically running the Debian GNU/Linux 11 (bullseye) Linux OS.
We will, as far as is possible, use a recent (as of the time of writing) stable longterm (LTS)
Linux kernel version 5.10 for our custom kernel builds and code runs. Being a longterm kernel
with an EOL date of December 2026, the 5.10 kernel series is an excellent choice to run on and learn
with.
It is interesting to know that the 5.10 longterm kernels will indeed have a long lifespan; from
December 2020 right up to December 2026! This is good news: this book's content thus remains
current and valid for years to come!

It's important to realize, for maximized security (with the latest defenses and fixes), that you
must run the most recent longterm kernel possible for your project or product.
Now that we have chosen our Linux distribution, and/or hardware boards and VMs, it's time we install
the guest along with a user account and essential software packages.
So, let's get started by installing our Linux guest (for the impatient, something to point out – an easier,
quicker way to get started is to simply use pre-built Linux VM images! We show you how in the section
Using pre-built Linux VM images).
Installing an x86_64 Linux guest
Here, I won't delve into the minutiae of installing Linux as a guest on Oracle VirtualBox, the reason
being that this installation is not directly related to Linux kernel development. There are many ways to
set up a Linux VM; we really don't want to get into the details and the pros and cons of each of them
here.
But if you are not familiar with this, don't worry. For your convenience, here are some excellent
resources that will help you out:
From Ubuntu: How to run Ubuntu Desktop on a virtual machine using VirtualBox:
https://ubuntu.com/tutorials/how-to-run-ubuntu-desktop-on-a-virtual-machine-using-virtualbox
A clearly written tutorial entitled Install Linux Inside Windows Using VirtualBox by Abhishek
Prakash (It's FOSS!, August 2019): https://itsfoss.com/install-linux-in-virtualbox/.
An alternate, similarly excellent resource is Install Ubuntu on Oracle
VirtualBox: https://brb.nci.nih.gov/seqtools/installUbuntu.html.
Also, you can look up useful resources for installing a Linux guest on VirtualBox in the Further reading
section at the end of this chapter. 
Nevertheless, it's important to point out a few key details involved; while you install the Linux VM, keep
the following things in mind.
Turn on your x86 system's virtualization extension support 
Installing a 64-bit Linux guest requires that CPU virtualization extension support (Intel VT-x or AMD-
SV) be turned on within the host system's basic input/output system (BIOS) settings. Worry not,
this is a one-time thing. Let's see how to do this:
1. Our first step is to ensure that our host CPU(s) supports virtualization:
There are two broad ways to check this while on a Windows host:
1. One, run the Task Manager app and switch to the Performance tab. Below the CPU graph, you will
see, among several other things, Virtualization, with Enabled or Disabled following it.
2. A second way to check on Windows systems is to open a Command window (cmd). In Command
Prompt, type systeminfo  and press Enter. Among the output seen will be
the Virtualization Enabled in firmware  line. It will be followed by either Yes  or No .
3. To check this while on a Linux host, from Terminal, issue the following commands (processor
virtualization extension support: vmx  is the check for Intel processors, smv  is the check for AMD
processors):
           egrep --color "vmx|svm" /proc/cpuinfo
For Intel CPUs, the vmx  flag will show up (in color) if virtualization is supported. In the case of AMD
CPUs, svm  will show up (in color). With this, we know that our CPU supports virtualization.
Hang on though; in order to use it, we need to enable it in the computer BIOS.

1. Enter the host system’s BIOS by pressing Del or F12 while booting; the precise key to press can vary
with the OEM and/or the BIOS. Please refer to your system's manual to see which key to use. Search
for terms such as Virtualization  or Virtualization Technology (VT-x) . Here is an example for
Award BIOS:
Figure 1.1 – Setting the BIOS Virtualization option to the Enabled state
2. Now, choose to use hardware virtualization in VirtualBox's Settings  menu for your VM. To do this,
click on System  and then Acceleration . After that, check the boxes, as shown in the following
screenshot:

Figure 1.2 – Enabling hardware virtualization options within the VirtualBox VM settings on a Linux
host
This is an example of how to enable your host processor's hardware virtualization features for optimal
performance.
Allocate sufficient space to the disk
For most desktop/laptop systems, allocating a gigabyte of RAM and two CPUs to the guest VM should be
sufficient.
However, when allocating space for the guest's disk, please be generous. Instead of the usual/default 8
GB suggested, I strongly recommend you make it 50 GB or even more. Of course, this implies that the
host system has more disk space than this available! Further, you can specify this amount to be
dynamically allocated or allocated on-demand. The hypervisor will "grow" the virtual disk optimally,
not giving it the entire space to begin with.
Using pre-built Linux VM images
The OSBoxes (OSB) project allows you to freely download and use prebuilt VirtualBox (as well as
VMware) images for popular Linux distributions. See their site here:
https://www.osboxes.org/virtualbox-images/.
In our case, you can download a prebuilt x86_64 Ubuntu 22.04 (as well as others) Linux image here:
https://www.osboxes.org/ubuntu/. It comes with the VirtualBox Guest Additions (see the following
section for details) preinstalled!
What the heck are VirtualBox Guest Additions?
For best performance, it's important to install the Oracle VirtualBox Guest Additions as well
within the guest VM. These are essentially para-virtualization accelerator software, which
greatly helps with optimizing performance (especially with regard to disk / network I/O, and
graphics).
The default username/password is osboxes/osboxes.org .
In this book, I’ll use the OSBoxes prebuilt Ubuntu 22.04 LTS as my primary VM. It’s
advantageous: once downloaded, you’re essentially good to go! Further, it comes with the VirtualBox
Guest Additions virtual CD image. The only (slight) downside: it’s rather large, the 7zip compressed
image - the one we download - is 2.6 GB in size; when uncompressed, it expands to approximately 8.6
GB (further, it’s set up so that it can grow - storage is allocated dynamically).
Setting up OSBoxes Ubuntu 22.04 as a guest OS
The only tweaks we’ll need to make within our spanking new Ubuntu VM is:
1. Install the VirtualBox Guest Additions
2. Set up a new user account named c2kp
3. Install other required software packages
Let’s perform these steps!
Step 1. Install the VirtualBox Guest Additions
1. Start up your OSB Ubuntu 22.04 VM (from within the VirtualBox app)
2. Log in to your Linux guest as the user osboxes  (recall that the default password is osboxes.org )
within the (default) graphical environment

3. A prerequisite to installing the Guest Additions: we must first install some minimal packages; let’s
do so. In the Terminal app, type (it’s possible you’ll have to wait until an ongoing automated /
unattended upgrade completes):
sudo apt update 
sudo apt upgrade   // if required 
sudo apt install gcc make perl build-essential dkms linux-headers-$(uname -r) ssh -y
(The last command should be typed on one line. Also, the -y  option switch has apt assume a yes answer
to all prompts; careful though, this could be dangerous in other circumstances.)
1. From VirtualBox’s menu select Devices | Insert Guest Additions CD image...  . Now a “virtual”
CD shows up; note the pathname of its mount point (you can use df  on the Terminal app to do so);
on my system, it happens to be /media/osboxes/VBox_GAs_6.1.26 .
2. Now, within the Terminal application, do this:
sudo /media/osboxes/VBox_GAs_6.1.26/VBoxLinuxAdditions.run 
[...]
Follow the onscreen prompts; the VirtualBox Guest Additions (mostly kernel modules) are installed via
this script and all you have to do once it’s done is reboot the VM.
1. On Oracle VirtualBox, to ensure that you have access to any shared folders you might have set up,
you need to set the guest account to belong to the vboxsf  group; you can do so like this (once done,
you'll need to log in again, or sometimes even reboot, to have this take effect):
sudo usermod -G vboxsf -a ${USER}
Good going, let’s move onto the next step.
Step 2. Set up a new user account named c2kp
1. Okay, setting up a new user account via the CLI is easy:
sudo useradd –m c2kp –s /bin/bash 
sudo passwd c2kp
Look up the man page on useradd  to understand the options passed. A screenshot showing the action
follows:

Figure 1.3 - Setting up our new c2kp account on the OSB Ubuntu Linux VM
This creates a new account named c2kp , along with the skeleton home directory (and it’s entries) and
sets up the password as well (I specified the password as ‘welcome’ - hence the BAD PASSWORD...
warning; please do provide a secure password). It automatically creates a group of the same name as
well, which will be your primary group.
On a Debian-based distro like this one, as the default account, osboxes , belongs to the groups adm  and
sudo  (and /etc/sudoers  allows it), you can exploit using the sudo  command and thus run stuff as root
(superuser); you simply have to enter your own password when prompted. Note, of course, that on
production systems, stuff like this raises security concerns and will typically be constrained if not
altogether disabled.
1. So, for our account c2kp  to run stuff as root (to use sudo ), which is important, we need to make it a
member of the groups adm  and sudo :
sudo usermod -a -G adm,sudo c2kp
Let’s verify it worked:
$ egrep -w "adm|sudo" /etc/group 
adm:x:4:syslog,osboxes,test1,c2kp 
sudo:x:27:osboxes,c2kp
Yes indeed! c2kp is now a member of groups adm  and sudo .
Wait, why’s our user account named c2kp?
Ah, though you’d never ask. In the world of recreational running (jogging), there's a really well known
program to get people off their behinds; its named Couch To 5 Kilometers, abbreviated as C25K
(http://www.c25k.com/). In a similar vein, let’s go with Couch To Kernel Programmer or c2kp ! (Hey,
it’s Linux, we prefer to keep account names in lowercase; also, take the name with a pinch of salt - I
know you’re smart!).

Great; log out and, from now onward, I’d suggest you always log in to the guest as the user c2kp . A
screenshot of the VirtualBox app in the foreground and our OSBoxes guest in the background follows:
Figure 1.4 - Screenshot of the VirtualBox app and our OSBoxes Ubuntu guest
You can see we’re logged in as c2kp . As my host system (it’s also running Linux!) is quite powerful, I
assign 4 CPU cores and 2 GB of RAM to the guest.
Let's now move on to a key step: actually installing software components on our Linux guest system so
that, in the coming chapters, you can learn and write Linux kernel code on the system!
Step 3. Install required software packages
The packages that are installed by default when you use a typical Linux desktop distribution, such as any
recent Ubuntu, Debian, CentOS, or Fedora Linux system, will likely include the minimal set required by
a systems programmer: the native toolchain, which includes the GCC compiler along with headers, and
the make  utility/packages.
In this book, though, we are going to learn how to write kernel-space code using a VM and/or a target
system running on a foreign processor (ARM-32 and/or AArch64 being the typical cases). To effectively
develop kernel code on these systems, we will need to install additional software packages.
Right, first of all, we’ll assume you’re running an x86_64 Ubuntu VM on VirtualBox with the Guest
Additions installed. This is indeed the case when using the OSBoxes prebuilt Ubuntu image. (Just in
case you still need to install them, no problem; refer the section Step 1. Install the VirtualBox Guest
Additions. Also, this tutorial has you covered: How to Install VirtualBox Guest Additions in Ubuntu:
https://www.tecmint.com/install-virtualbox-guest-additions-in-ubuntu/.)

Next, let's cover the installation of some required packages.
Hey, there’s an easier way: I’ve provided a bash script in the book’s GitHub repo that will install all
required packages; it’s here: https://github.com/PacktPublishing/Linux-Kernel-
Programming_2E/blob/main/ch1/pkg_install4ubuntu_lkp.sh. Do ensure you clone the code
repository and work on the code examples and assignments as you go along!
To install the packages, take the following steps:
1. Within the Ubuntu VM, logged in as the user c2kp , first do the following: sudo apt update
2. Now, to install the required packages for building the Linux kernel, run the following command in a
single line:
sudo apt install -y \ 
bison build-essential flex libncurses5-dev ncurses-dev \ 
libelf-dev libssl-dev tar util-linux xz-utils
1. To install the packages required for work we'll do in other parts of this book, run the following
command in a single line:
sudo apt install -y \ 
bc bpfcc-tools bsdextrautils \ 
  clang cppcheck cscope curl exuberant-ctags \ 
fakeroot flawfinder \ 
git gnome-system-monitor gnuplot hwloc indent \ 
libnuma-dev linux-headers-$(uname -r) linux-tools-$(uname -r) \ 
man-db net-tools numactl openjdk-18-jre  openssh-server \ 
perf-tools-unstable psmisc python3-distutils  \ 
rt-tests smem sparse stress sysfsutils \ 
tldr-py trace-cmd tree tuna virt-what
Recall that the installation of gcc , make , and perl  is done first (see the section Step 1. Install the
VirtualBox Guest Additions) so that the Oracle VirtualBox Guest Additions can be properly installed
straight after.
The disk space taken up by installing these packages (at least on my VM) is in the region of 1.75 GB.
This book, at times, mentions that running a program on another CPU architecture – typically
ARM-32 or AArch64 – might be a useful exercise. If you want to try (interesting!) stuff like this – I
urge you to do so! - please read on; otherwise, feel free to skip ahead to the Additional useful
projects section.
Do note that the book’s GitHub repo does evolve; do a git pull  every once in a while, to get the latest
version...
Installing QEMU and a cross toolchain
One way to try things on an ARM machine is to actually do so on a physical ARM-based SBC; for
example, the Raspberry Pi is a very popular choice. In this case, the typical development workflow is to
first build the ARM code on your x86_64 host system. But to do so, we need to install a cross
toolchain – a set of tools allowing you to build software on one host CPU such that it executes on a
different target CPU. An x86_64 host building programs for an ARM target is a very common case, and
indeed is our use case here. Details on installing the cross compiler follow shortly.
Often, an alternate way to just trying things out is to have an ARM/Linux system emulated – this
alleviates the need for hardware! To do so, we recommend using the superb QEMU project
(https://www.qemu.org/).
To install the required QEMU packages, do the following (takes up close to half a gigabyte disk space on
Ubuntu):
For installation on Ubuntu, use the following:

sudo apt install qemu-system-arm
For installation on Fedora, use the following:
sudo dnf install qemu-system-arm-<version#>
To get the version number on Fedora, just type the preceding command and after typing the required
package name (here, qemu-system-arm- ), press the Tab key twice. It will auto-complete, providing a list
of choices. Choose the latest version and press Enter.
Installing a cross compiler
If you intend to write a C program that is compiled on a certain host system but must execute on another
(foreign) target system, then you need to compile it with what's known as a cross compiler or cross
toolchain. For example, in our use case, we want to work – develop code - on an x86_64 host machine.
The host can even be an x86_64 guest system, no issues, but the code will run on an ARM-32 target.
We shan’t dig further into the specifics of installing a cross toolchain here and now, as we practically
require this – and explain it in depth – in a later chapter (Chapter 3, Building the 5.x Linux Kernel from
Source - Part 2 in the section Step 2 – installing a cross-toolchain).
A reasonable question you might have at this point - why are we setting up a cross toolchain in the first
place? Yes, though we don’t make use of it just now (after all, this is the ‘setup the workspace’ material),
we definitely shall later; in Chapters 3, 5 and 11, where you’ll be configuring and cross-compiling a Linux
kernel – and kernel modules - for the ARM processor! Relax, we’ll get there and dig into the details then.
Installing and using a cross toolchain might require some reading up for newbie users. You can visit the
Further reading section where I have placed a few useful links that will surely be of great help.
A few remaining tips when running the VM
Sometimes, when the overhead of using the X Window System (or Wayland) GUI (for graphical display)
is too high, especially on a guest machine, it's preferable to simply work in console mode. You can do so
by appending 3  (the run level) to the kernel command line via the bootloader. However, working in
console mode within VirtualBox may not be that pleasant an experience (for one, the clipboard is
unavailable, and the screen size and fonts are less than desirable). Thus, doing a remote login
(via ssh , putty , or equivalent) into the VM from the host system can be a great way to work (one that I
use most of the time).
Next, remember to update the VM regularly and when prompted. This is an essential security
requirement. You can do so manually by using the following: 
sudo /usr/bin/update-manager
Finally, to be safe, please do not keep any important data on the guest VM. We will be working on kernel
development. Crashing the guest kernel can be pretty commonplace. While this usually does not cause
data loss, you can never tell! To be safe, always back up any important data.
Experimenting with the Raspberry Pi
The Raspberry Pi is a very popular credit card-sized (or smaller, as with the Raspberry Pi Zero boards)
Single-Board Computer (SBC), much like a small-factor PC that has USB ports, a microSD card,
HDMI, audio, Ethernet, GPIO, and more. It’s used for learning, by hobbyists, for prototyping and for
several real-world products as well. The System on Chip (SoC) that powers it is from Broadcom, and
in it is an ARM core or cluster of cores.
Though not mandatory, of course, in this book, we strive to also test and run our code on some of these
embedded form-factory systems (the Raspberry Pi Zero W and the Raspberry Pi 4 Model B boards).

Running your code on different target architectures is always a good eye-opener to possible defects, and
helps with testing, and learning. I encourage you to do the same.
Figure 1.5 – The Raspberry Pi 4 with a USB-to-RS232 TTL UART serial adapter cable attached to its
GPIO pins
You can work on the Raspberry Pi target either using a digital monitor/TV via HDMI as the output
device and a traditional keyboard/mouse over its USB ports or, more commonly for developers, over a
remote shell via ssh . The SSH approach, though, does not cut it in all circumstances. Having a serial
console on the Raspberry Pi helps, especially when doing stuff like kernel bring-up and debugging.
I would recommend that you check out the following article, which will help you set up a USB-to-
serial connection, thus getting a console login to the Raspberry Pi from a PC/laptop: WORKING ON
THE CONSOLE WITH THE RASPBERRY
PI, kaiwanTECH: https://kaiwantech.wordpress.com/2018/12/16/working-on-the-console-with-
the-raspberry-pi/.
Of course, my Linux Kernel Debugging book (Packt, August 2022), covers kernel debugging
tools and techniques in-depth; do check it out.
To set up your Raspberry Pi, please refer to the official
documentation: https://www.raspberrypi.org/documentation/. As of this writing, my Raspberry Pi
system runs the "official" Debian Linux for Raspberry Pi; it’s called the Raspberry Pi OS (it used to be

called Raspbian) and sports a very recent 5.15 based Linux kernel. (Later, in the following two chapters,
you’ll not only learn how to build your own custom Linux kernel, but also one specifically for the
Raspberry Pi!).
On the console (or a Terminal window) of the Raspberry Pi, to look up version details, we run the
following commands:
rpi $ lsb_release -a 
No LSB modules are available. 
Distributor ID: Debian 
Description:    Debian GNU/Linux 11 (bullseye) 
Release: 11 
Codename: bullseye 
rpi $ uname –a 
Linux rpi4gui 5.15.32-v8+ #1538 SMP PREEMPT Thu Mar 31 19:40:39 BST 2022 aarch64 GNU/Linux 
rpi $ 
Quick tip
There are several interesting commands to query hardware/software info; try the
hostnamectl, ls{cpu|pci|usb} ; next, specific to x86: hwinfo, lshw ; specific to the Raspberry
Pi OS: raspinfo  commands for even more details.
Also, of course, no reason you have to confine yourself to the Raspberry Pi family; there are several other
excellent prototyping / evaluation boards available. One that springs to mind is the popular
BeagleBone Black (BBB) board.
In fact, for professional development and product work, the Raspberry Pi is perhaps not the best
choice, for several reasons... a bit of googling will help you understand this. Having said that, as a
learning and prototyping environment it's hard to beat, with the strong community (and tech
hobbyist) support it enjoys.
Several modern choices of microprocessors for embedded Linux (and much more) are
discussed and contrasted in this excellent in-depth article: SO YOU WANT TO BUILD AN
EMBEDDED LINUX SYSTEM?, Jay Carlson, Oct 2020 : https://jaycarlson.net/embedded-
linux/; do check it out.
By now, I expect that you have set up Linux as a guest machine (or are using a native "test" Linux box)
and have cloned the book's GitHub code repository. So far, we have covered some information regarding
setting up Linux as a guest (as well as optionally using boards such as the Raspberry Pi or the
BeagleBone).
Congratulations! This completes the software setup, and your kernel journey begins! Now, let's check
out a few additional and useful projects to complete this chapter. It's certainly recommended that you
read through these as well.
Additional useful projects
This section brings you details of some additional miscellaneous projects that you might find very useful
indeed. In a few appropriate places in this book, we refer to or directly make use of some of them, thus
making them important to understand.
Let's get started with the well-known and important Linux man pages project.
Using the Linux man pages
You must have noticed the convention followed in most Linux/Unix literature:
The suffixing of user commands with (1)  – for example, gcc(1)  or gcc.1
System calls with (2)  – for example, fork(2)  or fork().2

Library APIs with (3)  – for example, pthread_create(3)  or pthread_create().3
As you are no doubt aware, the number in parentheses (or after the period) denotes the section of the
manual (the man pages) that the command/API in question belongs to. A quick check with man(1) ,
via the man man  command (that's why we love Unix/Linux!) reveals the sections of the Unix/Linux
manual:
$ man man 
[...] 
A section, if provided, will direct man to look only in that section of the manual. [...] 
       The table below shows the section numbers of the manual followed by the types of pages the
       1   Executable programs or shell commands 
       2   System calls (functions provided by the kernel) 
       3   Library calls (functions within program libraries) 
       4   Special files (usually found in /dev) 
       5   File formats and conventions eg /etc/passwd 
       6   Games 
       7   Miscellaneous (including macro packages and conventions), e.g. man(7), groff(7) 
       8   System administration commands (usually only for root) 
       9   Kernel routines [Non standard] 
[...]
So, for example, to look up the man page on the stat(2)  system call, you would use the following:
man 2 stat           # (or: man stat.2)
At times though, the man  pages are simply too detailed to warrant reading through when a quick answer
is all that's required. Enter the tldr  project – read on!
The tldr variant
While we're discussing man  pages, a common annoyance is that the man  page on a command is, at times,
too large. Take the ps(1)  utility as an example. It has a really large man  page as, of course, it has a huge
number of option switches. Wouldn't it be nice, though, to have a simplified and summarized "common
usage" page? This is precisely what the tldr  pages project aims to do.
TL;DR literally means Too Long; Didn't Read.
In the tldr project’s own words: “The tldr pages are a community effort to simplify the beloved man
pages with practical examples” (I love the wording – the beloved man pages; indeed!).
The tldr project seems to be pretty popular, with a large number of spin-offs, implementing the same
idea in different ways. Check these out:
The main website: https://tldr.sh/
The tldr wiki site with various clients: https://github.com/tldr-pages/tldr/wiki/tldr-pages-clients
Practically, let’s use it via the superb web client: https://tldr.ostera.io/.
Using the tldr web client
Head over to the web client (https://tldr.ostera.io/), simply type in the command name (I used tar )
and see the result instantly pop up:
Very interesting, the URL now becomes https://tldr.ostera.io/tar (meaning, you can append a command
name to the URL and it’ll just work; lovely.). Well, a picture’s worth a thousand words:

Figure 1.6 – A screenshot of the web tldr client utility in action
Using the tldr CLI client
A couple of steps to follow to get the tldr CLI running on our Ubuntu guest:
1. Install it:
sudo apt install -y tldr
1. Update it (internally, this step clones a git repo and populates stuff under ~/.local/share/tldr )
tldr --update
Done; use it on the shell; for example, tldr tar .
Earlier, recall, with respect to APIs, that we said that userspace system calls fall under section 2 of the
man pages, library subroutines under section 3, and kernel APIs under section 9. Given this, then, in this
book, why don't we specify the, say, printk  kernel function (or API) as printk(9)  – as man man  shows

us that section 9  of the manual is Kernel routines? Well, it's fiction, really (at least on today's Linux): no
man pages actually exist for kernel APIs! So, how do you get documentation on the kernel APIs and so
on? That's just what we will briefly delve into in the following section.
Locating and using the Linux kernel documentation
The community has developed and evolved the Linux kernel documentation into a good state over many
years of effort. The latest version of the kernel documentation, presented in a nice and modern "web"
style, can always be accessed online here: https://www.kernel.org/doc/html/latest/.
Of course, as we will mention in the next chapter, the kernel documentation is always available for
that kernel version within the kernel source tree itself, within the directory named Documentation/ .
As just one example of the online kernel documentation, see the following partial screenshot of the page
on Core Kernel Documentation/Basic C Library
Functions (https://www.kernel.org/doc/html/latest/core-api/kernel-api.html#basic-c-library-
functions):
Figure 1.7 – Partial screenshot showing a small part of the modern online Linux kernel documentation
As can be gleaned from the screenshot, the modern documentation is pretty comprehensive. It even
advises you that the simple_strtoull()  API’s considered obsolete, and to use the kstrtoull()  API
instead.
Generating the kernel documentation from source

You can literally generate the full Linux kernel documentation from within the kernel source tree in
various popular formats (including PDF, HTML, LaTeX, EPUB, or XML), in a Javadoc or Doxygen-
like style. The modern documentation system used internally by the kernel is called Sphinx.
Using make help  within the kernel source tree will reveal several documentation targets, among
them htmldocs , pdfdocs , and more. So, you can, for example, cd  to the kernel source tree and
run make pdfdocs  to build the complete Linux kernel documentation as PDF documents (the PDFs, as
well as some other meta-docs, will be placed in Documentation/output/latex ). The first time, at least,
you will likely be prompted to install several packages and utilities (we don't show this explicitly).
Don't worry if the preceding details are not crystal clear yet. I suggest you first read Chapter
2, Building the 5.x Linux Kernel from Source – Part 1, and Chapter 3, Building the 5.x Linux Kernel
from Source – Part 2, and then revisit these details.
Static analysis tools for the Linux kernel
Static analysers are tools that, by examining the source code, attempt to identify potential errors within
it. They can be tremendously useful to you as the developer, though you must learn how to "tame" them
– in the sense that they can result in false positives.
Several useful static analysis tools exist. Among them, the ones that are more relevant for Linux kernel
code analysis include the following:
Sparse: https://sparse.wiki.kernel.org/index.php/Main_Page
Coccinelle: http://coccinelle.lip6.fr/ (requires the ocaml  package installed)
Smatch: http://smatch.sourceforge.net/, http://repo.or.cz/w/smatch.git
Besides them, these are general-purpose C/C++ static analyzers that can be useful as well:
Flawfinder (geared toward finding security issues): https://dwheeler.com/flawfinder/
Cppcheck: https://github.com/danmar/cppcheck
For example, to install and try Sparse, do the following:
sudo apt install sparse 
cd <kernel-src-tree> 
make C=1 CHECK="/usr/bin/sparse"
Of course, there are also several high-quality commercial static analysis tools available. Among them are
the following:
SonarQube: https://www.sonarqube.org/ (a free and open-source community edition is available)
Coverity Scan: https://scan.coverity.com/
Klocwork: https://www.meteonic.com/klocwork
clang is a compiler frontend to GCC that is becoming popular even for kernel builds; it has a static
analysis component as well.
Static analysis tools can save the day. Time spent learning to use them effectively is time well spent!
Linux Trace Toolkit next generation
A superb tool for tracing and profiling is the powerful Linux Tracing Toolkit next
generation (LTTng) toolset, a Linux Foundation project. LTTng allows you to trace both userspace
(applications) and/or the kernel code paths in minute detail. This can tremendously aid you in
understanding where performance bottlenecks occur, as well as aiding you in understanding the overall
code flow and thus in debugging scenarios and learning about how the code actually performs its tasks.
In order to learn how to install and use it, I refer you to its very good documentation here:
https://lttng.org/docs (try https://lttng.org/download/ for installation for common Linux

distributions).
It’s also highly recommended that you install the Trace Compass GUI:
https://www.eclipse.org/tracecompass/. It provides an excellent GUI for examining and interpreting
LTTng's output.
Trace Compass minimally requires a Java Runtime Environment (JRE) to be installed as well.
We’ve installed one on our Ubuntu 22.04 LTS system – the openjdk-18-jre package.
As an example (I can't resist!), here's a screenshot of a capture by LTTng being "visualized" by the
superb Trace Compass GUI. Here, I show a couple of hardware interrupts (IRQ lines 1 and 130, the
interrupt lines for the i8042 and Wi-Fi chipset, respectively, on my native x86_64 system):
Figure 1.8 – Sample screenshot of the Trace Compass GUI; samples recorded by LTTng showing IRQ
lines 1 and 130
The pink color in the upper part of the preceding screenshot represents the occurrence of a hardware
interrupt. Underneath that, in the IRQ vs Time tab (it's only partially visible), the interrupt distribution
is seen. (In the distribution graph, the y axis is the time taken; interestingly, the network interrupt
handler – in red – seems to take very little time, the i8042 keyboard/mouse controller chip's handler –
in blue – takes more time, even – in this case at least - exceeding 200 microseconds).
Disclaimer: among the next few utilities/projects mentioned, I am the primary author of the procmap
and SEALS project efforts.
The procmap utility
Visualizing the complete memory map of the kernel Virtual Address Space (VAS) as well as any
given process's user VAS is what the procmap  utility is designed to do.
The description on its GitHub page sums it up:
“It outputs a simple visualization of the complete memory map of a given process in a vertically-tiled
format ordered by descending virtual address. The script has the intelligence to show kernel and

userspace mappings as well as calculate and show the sparse memory regions that will be present. Also,
each segment or mapping is scaled by relative size (and color-coded for readability). On 64-bit systems,
it also shows the so-called non-canonical sparse region or 'hole' (typically close to a whopping 16,384 PB
on the x86_64).”
The utility includes options to see only kernel space or userspace, verbose and debug modes, the ability
to export its output in convenient CSV format to a specified file, as well as other options. It has a kernel
component as well and currently works (and auto-detects) on x86_64, AArch32, and Aarch64 CPUs.
Do note, though, that this utility is still under development; there are several caveats. Feedback and
contributions are most appreciated!
Download/clone it from https://github.com/kaiwan/procmap:
Figure 1.9 – A partial screenshot of the procmap utility's output, showing only the top portion of kernel
VAS on x86_64
We make good use of this utility in Chapter 7, Memory Management Internals - Essentials.

Simple Embedded ARM Linux System FOSS project
SEALS or Simple Embedded ARM Linux System is a very simple "skeleton" Linux base system
running on an emulated ARM machine. It provides a primary Bash script that asks the end user what
functionality they want via a menu, then accordingly proceeds to cross-compile a Linux kernel for ARM,
and then creates and initializes a simple root filesystem. It can then call upon QEMU ( qemu-system-arm )
to emulate and run an ARM platform (the Versatile Express CA-9 is the default board emulated). The
useful thing is, the script builds the target kernel, the root filesystem, and the root filesystem image file,
and sets things up for boot. It even has a simple GUI (or console) frontend, to make usage a bit simpler
for the end user. The project's GitHub page is here: https://github.com/kaiwan/seals/. Clone it and give
it a try... I definitely recommend you have a look at its wiki section pages
at https://github.com/kaiwan/seals/wiki for help.
Modern tracing and performance analysis with eBPF
An extension of the well-known Berkeley Packet Filter or BPF, eBPF is the extended BPF. (FYI, at
times it's referred to simply as BPF, dropping the 'e' prefix; here we’ll explicitly use the term eBPF).
Very briefly, BPF used to provide the supporting infrastructure within the kernel to effectively trace
network packets. eBPF is a very recent kernel innovation – available only from the Linux 4.0 kernel
onward. It extends the BPF notion, allowing you to trace much more than just the network stack. eBPF is
essentially virtual machine technology, allowing one to write (small) programs and run them in a safe
isolated environment within the kernel! In effect, eBPF and its frontends are a really modern and
powerful approach to tracing and performance analysis on Linux systems, even in production.
To use eBPF, you will need a system with the following:
Linux kernel 4.0 or later
Kernel support for BPF (https://github.com/iovisor/bcc/blob/master/INSTALL.md#kernel-
configuration)
The BCC or bpftrace  frontends installed (link to install them on popular Linux
distributions: https://github.com/iovisor/bcc/blob/master/INSTALL.md#installing-bcc)
Root access on the target system
Using the eBPF kernel feature directly is very hard, so there are several easier front ends to use. Among
them, BCC and bpftrace  are regarded as very useful. Check out the following link to a picture that
opens your eyes to just how many powerful BCC tools are available to help trace different Linux
subsystems and
hardware: https://github.com/iovisor/bcc/blob/master/images/bcc_tracing_tools_2019.png.
You can install the BCC tools for your regular host Linux distro by reading the installation
instructions here: https://github.com/iovisor/bcc/blob/master/INSTALL.md. Why not on our
guest Linux VM? You can, when running a distro kernel (such as an Ubuntu- or Fedora-supplied
kernel). The reason: the installation of the BCC toolset includes (and depends upon) the installation
of the linux-headers-$(uname -r)  package; this linux-headers package exists only for distro kernels
(and not for our custom 5.10 kernel that we shall often be running on the guest).
The main site for BCC can be found at https://github.com/iovisor/bcc. We shall make use of a little of
the eBPF tooling in some later chapters.
FYI, the book Linux Kernel Debugging, Packt, August 2022, covers using LTTng, Trace Compass,
KernelShark, ftrace, trace-cmd, procmap, and many more debugging tools and techniques in-depth.
The LDV - Linux Driver Verification - project
The Russian Linux Verification Center, founded in 2005, is an opensource project; it has specialists in,
and thus specializes in, automated testing of complex software projects. This includes comprehensive
test suites, frameworks, and detailed analyses (both static and dynamic) being performed on the core

Linux kernel as well as on the primarily device drivers within the kernel. This project puts a great deal of
focus on the testing and verification of kernel modules as well, which many similar projects tend to skim.
Of particular interest to us here is the Online Linux Driver Verification Service page
(http://linuxtesting.org/ldv/online?action=rules); it contains a list of a few verified Rules (Figure 1.10):
Figure 1.10 – Screenshot of the 'Rules' page of the Linux Driver Verification (LDV) project site
By glancing through these rules, we'll be able to not only see the rule but also instances of actual cases
where these rules were violated by driver/kernel code within the mainline kernel, thus introducing bugs.
The LDV project has successfully discovered and fixed (by sending in patches in the usual manner)
several driver/kernel bugs. In a few of the upcoming chapters, we shall mention instances of these LDV
rule violations (for example, memory leakage, Use After Free (UAF) bugs, and locking violations)
having been uncovered, and (probably) even fixed.
Here are some useful links on the LDV website:
The Linux Verification Center home page; http://linuxtesting.org/
Linux Kernel Space Verification; http://linuxtesting.org/kernel
Online Linux Driver Verification Service page with verified
Rules : http://linuxtesting.org/ldv/online?action=rules
Problems in Linux Kernel page; lists over 400 issues found in existing drivers (mostly fixed as
well); http://linuxtesting.org/results/ldv
Summary
In this chapter, we covered in detail the hardware and software requirements to set up an appropriate
development environment for beginning to work on Linux kernel programming. In addition, we
mentioned the basics and provided links, wherever appropriate, for setting up a Raspberry Pi device,
installing powerful tools such as QEMU (and a cross toolchain), and so on. We also threw some light on
other "miscellaneous" tools and projects that you, as a budding kernel and/or device driver developer,
might find useful, as well as information on how to begin looking up kernel documentation.
In this book, we definitely recommend and expect you to try out and work on kernel code in a hands-on
fashion – remember, always be empirical! To do so, you must have a proper kernel workspace

environment set up, which we have successfully done in this chapter.
Now that our environment is ready, let's move on and explore the brave world of Linux kernel
development! The next two chapters will teach you how to download, extract, configure, and build a
Linux kernel from source.
Questions
As we conclude, here is a list of questions for you to test your knowledge regarding this chapter's
material: https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions. You
will find some of the questions answered in the book's GitHub
repo: https://github.com/PacktPublishing/Linux-Kernel-
Programming/tree/master/solutions_to_assgn.
Further reading
To help you delve deeper into the subject with useful materials, we provide a rather detailed list of online
references and links (and at times, even books) in a Further reading document in this book's GitHub
repository. The Further reading document is available
here: https://github.com/PacktPublishing/Linux-Kernel-
Programming/blob/master/Further_Reading.md.

